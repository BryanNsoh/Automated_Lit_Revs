- analysis: "The article leverages the OGC SensorThings API as the service layer and\
    \ proposes an extension named SW-IoT Plug and Play (PNP). The PNP defines standardized\
    \ communication procedures and a device description format, aiming to establish\
    \ interoperability between the device, gateway, and service layers. This solution\
    \ addresses the challenge of device heterogeneity and enables the automatic registration\
    \ of embedded devices in the SW-IoT architecture, thereby facilitating seamless\
    \ integration and end-to-end automated irrigation management. \n\nThe context\
    \ for this research emphasizes the need for real-time, automated irrigation management\
    \ systems and highlights the limitations of existing solutions due to data heterogeneity\
    \ and a lack of interoperability. This research contributes to advancing the field\
    \ of real-time, automated irrigation management by proposing an architectural\
    \ framework and protocol that address these challenges. \n\nThe proposed solution\
    \ is innovative in the sense that it unifies the SW-IoT architecture across the\
    \ device, gateway, and service layers based on the OGC SensorThings API. This\
    \ approach is distinct from existing solutions that primarily focus on mapping\
    \ data models or using proprietary protocols, which can introduce complexity and\
    \ limit interoperability. \n\nThe research is methodologically sound, employing\
    \ a detailed design of the IoT-PNP components, including the device description\
    \ format, communication protocols, and automatic registration procedures. The\
    \ authors provide concrete examples and implementation details, demonstrating\
    \ the feasibility and applicability of the proposed solution.\n\nThe article provides\
    \ three specific examples of how the proposed IoT-PNP contributes to addressing\
    \ the point of the review:\n\n*   **Verbatim_quote1**: “The proposed IoT-PNP contains\
    \ three main components: (1) A description file describing device metadata and\
    \ capabilities, (2) a communication protocol between the gateway layer and the\
    \ device layer for establishing connections, and (3) an automatic registration\
    \ procedure for both sensing and tasking capabilities.”\n\n*   **Verbatim_quote2**:\
    \ “Overall, we believe the proposed solution could help achieve an open and interoperable\
    \ SW-IoT end-to-end architecture based on the OGC SensorThings API.”\n\n*   **Verbatim_quote3**:\
    \ “These three scenarios are also the use cases we applied to examine the proposed\
    \ solution.”\n\nThe research has significant relevance to the field of real-time,\
    \ automated irrigation management as it provides a comprehensive framework for\
    \ addressing the challenges of data heterogeneity and interoperability. The proposed\
    \ solution has the potential to improve the efficiency, reliability, and scalability\
    \ of automated irrigation systems, thereby contributing to advancements in precision\
    \ agriculture and sustainable water resource management.\n\nThe article demonstrates\
    \ the effectiveness of the proposed IoT-PNP solution through real-world implementation\
    \ and evaluation. The authors deployed the solution in an indoor environment monitoring\
    \ experiment, demonstrating the successful registration and data transmission\
    \ of 34 SW-IoT devices. This practical validation enhances the credibility of\
    \ the proposed solution and provides empirical evidence of its applicability in\
    \ real-world scenarios.\n\nThe article acknowledges potential limitations and\
    \ suggests future research directions. For instance, the authors mention that\
    \ different wireless communication protocols may require variations in the proposed\
    \ protocol, and exploring these variations is a possible future research topic.\
    \ By addressing potential limitations and proposing future research directions,\
    \ the article reflects a comprehensive understanding of the problem space and\
    \ a commitment to ongoing innovation in the field.\n\nOverall, the article presents\
    \ a well-structured and comprehensive solution to the challenges of device heterogeneity\
    \ and interoperability in SW-IoT systems for real-time, automated irrigation management.\
    \ The proposed IoT-PNP framework provides a viable path toward achieving a unified\
    \ and interoperable SW-IoT architecture based on the OGC SensorThings API. The\
    \ research is innovative, methodologically sound, and supported by real-world\
    \ implementation and evaluation, making it a valuable contribution to the field."
  authors:
  - Huang C.Y.
  - Chen H.H.
  citation_count: '3'
  description: 'Sensor Web and Internet of Things (IoT) (SW-IoT) have been attracting
    attention from various fields. Both of them deploy networks of embedded devices
    to monitor physical properties (i.e., sensing capability) or to be controlled
    (i.e., tasking capability). One of the most important tasks to realize the SW-IoT
    vision is to establish an open and interoperable architecture, across the device
    layer, gateway layer, service layer, and application layer. To achieve this objective,
    many organizations and alliances propose standards for different layers. Among
    the standards, Open Geospatial Consortium (OGC) SensorThings API is arguably one
    of the most complete and flexible service standards. However, the SensorThings
    API only address heterogeneity issues in the service layer. Embedded devices following
    proprietary protocols need to join closed ecosystems and then link to the SensorThings
    API ecosystem via customized connectors. To address this issue, one could first
    follow another device layer and gateway layer open standards and then perform
    data model mapping with the SensorThings API. However, the data model mapping
    is not always straightforward as the standards were designed independently. Therefore,
    this research tries to propose a more direct solution to unify the entire SW-IoT
    architecture by extending the SensorThings API ecosystem to the gateway layer
    and the device layer. To be specific, this research proposes SW-IoT Plug and Play
    (IoT-PNP) to achieve an automatic registration procedure for embedded devices.
    The IoT-PNP contains three main components: (1) A description file describing
    device metadata and capabilities, (2) a communication protocol between the gateway
    layer and the device layer for establishing connections, and (3) an automatic
    registration procedure for both sensing and tasking capabilities. Overall, we
    believe the proposed solution could help achieve an open and interoperable SW-IoT
    end-to-end architecture based on the OGC SensorThings API.'
  doi: 10.3390/s19030495
  full_citation: 'An Automatic Embedded Device Registration Procedure Based on the
    OGC SensorThings API

    Chih-Yuan Huang and Hsin-Hsien Chen

    Sensors 2019, 19(3), 495; https://doi.org/10.3390/s19030495'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Sensors All Article Types Advanced   Journals
    Sensors Volume 19 Issue 3 10.3390/s19030495 Submit to this Journal Review for
    this Journal Propose a Special Issue Article Menu Subscribe SciFeed Recommended
    Articles Related Info Links More by Authors Links Article Views 3493 Citations
    3 Table of Contents Abstract Introduction Related Work Methodology Results Conclusions
    and Future Work Author Contributions Funding Conflicts of Interest Appendix A
    References share Share announcement Help format_quote Cite question_answer Discuss
    in SciProfiles thumb_up Endorse textsms Comment first_page settings Order Article
    Reprints Open AccessArticle An Automatic Embedded Device Registration Procedure
    Based on the OGC SensorThings API by Chih-Yuan Huang 1,* and Hsin-Hsien Chen 2
    1 Center for Space and Remote Sensing Research, National Central University, Taoyuan
    320, Taiwan 2 Department of Civil Engineering, National Central University, Taoyuan
    320, Taiwan * Author to whom correspondence should be addressed. Sensors 2019,
    19(3), 495; https://doi.org/10.3390/s19030495 Submission received: 7 November
    2018 / Revised: 8 January 2019 / Accepted: 22 January 2019 / Published: 25 January
    2019 (This article belongs to the Section Internet of Things) Download keyboard_arrow_down     Browse
    Figures Versions Notes Abstract Sensor Web and Internet of Things (IoT) (SW-IoT)
    have been attracting attention from various fields. Both of them deploy networks
    of embedded devices to monitor physical properties (i.e., sensing capability)
    or to be controlled (i.e., tasking capability). One of the most important tasks
    to realize the SW-IoT vision is to establish an open and interoperable architecture,
    across the device layer, gateway layer, service layer, and application layer.
    To achieve this objective, many organizations and alliances propose standards
    for different layers. Among the standards, Open Geospatial Consortium (OGC) SensorThings
    API is arguably one of the most complete and flexible service standards. However,
    the SensorThings API only address heterogeneity issues in the service layer. Embedded
    devices following proprietary protocols need to join closed ecosystems and then
    link to the SensorThings API ecosystem via customized connectors. To address this
    issue, one could first follow another device layer and gateway layer open standards
    and then perform data model mapping with the SensorThings API. However, the data
    model mapping is not always straightforward as the standards were designed independently.
    Therefore, this research tries to propose a more direct solution to unify the
    entire SW-IoT architecture by extending the SensorThings API ecosystem to the
    gateway layer and the device layer. To be specific, this research proposes SW-IoT
    Plug and Play (IoT-PNP) to achieve an automatic registration procedure for embedded
    devices. The IoT-PNP contains three main components: (1) A description file describing
    device metadata and capabilities, (2) a communication protocol between the gateway
    layer and the device layer for establishing connections, and (3) an automatic
    registration procedure for both sensing and tasking capabilities. Overall, we
    believe the proposed solution could help achieve an open and interoperable SW-IoT
    end-to-end architecture based on the OGC SensorThings API. Keywords: Internet
    of Things; sensor web; plug and play; interoperability; OGC SensorThings API 1.
    Introduction Sensor Web is a widely distributed network connecting different types
    of sensors [1,2]. With enough power supply, in-situ or remote sensors can continuously
    collect observations of instruments and environment [3]. By sharing these large
    number of observations online via interoperable ICT (Information and Communication
    Technologies), users can integrate the observations to discover phenomena that
    were not observable in the past [2]. In recent years, the Internet of Things (IoT),
    a similar idea to the Sensor Web, attracted much attentions from various fields.
    While there have been many definitions of the IoT, International Telecommunication
    Union (ITU) introduced a general yet comprehensive definition. The ITU defines
    that the IoT is “a global infrastructure for the information society, enabling
    advanced services by interconnecting (physical and virtual) things based on existing
    and evolving interoperable information and communication technologies”, and a
    thing is “an object of the physical world (physical things) or the information
    world (virtual things), which is capable of being identified and integrated into
    communication networks”. As the Sensor Web and the Internet of Things are similar
    in terms of their architectures and functionalities, we name them as the SW-IoT
    (Sensor Web and IoT) in this paper. In general, the SW-IoT provides two main functionalities
    [4]: (1) Sensing capability: SW-IoT devices can monitor their latest status or
    use embedded sensors to observe properties of their surrounding environment. With
    the help of communication technologies, users can remotely access these observations
    for further analysis or decision-making. (2) Tasking capability: Tasking capabilities
    allow users to remotely control SW-IoT devices. For example, a client can send
    tasks to turn on/off a device, adjust the sensor’s sampling rate, schedule an
    observation event, etc. The integration of sensing and tasking capabilities helps
    achieve various applications, such as precision agriculture, Industry 4.0, smart
    city, home automation, and e-Health, etc. In general, we can summarize the SW-IoT
    with a three-tier architecture [5], which contains the device layer, the service
    layer, and the applications layer. In terms of sensing capabilities, devices embedded
    with sensors can continuously collect and upload observations to services on the
    service layer. The service layer mainly supports data management and interfacing
    while the application layer retrieves data from the service layer for further
    applications. In terms of tasking capabilities, a client in the application layer
    can first send tasks to the service layer. A service then transforms the tasks
    into a device request by following a corresponding device protocol. Once the service
    forwards the request to the device, the device will execute the task accordingly.
    Besides the three aforementioned layers, an additional gateway layer is commonly
    applied in the SW-IoT systems (Figure 1). The gateway layer serves as an intermediate
    between the device layer and the service layer. There are two advantages to applying
    gateways. Firstly, while most embedded devices are resource-constraint and not
    able to connect to the Internet by themselves [6], gateways can help devices to
    communicate with services. Secondly, as directly connecting to the Internet requires
    higher energy consumption, devices can connect with gateways via low-power-consumption
    wireless communication protocols [7], such as Bluetooth LE, ZigBee, LoRaWAN, and
    NB-IoT, etc. Figure 1. A high-level Sensor Web and Internet of Things (SW-IoT)
    architecture [4]. With the advance of micro-controller and sensor technologies
    in recent years, the cost of constructing SW-IoT systems has been significantly
    reduced. Government agencies, scientists, and developers can customize and deploy
    embedded systems at a lower cost. However, instead of following open standards,
    many SW-IoT systems are constructed based on proprietary protocols due to its
    conveniences. These systems form many SW-IoT silos that cannot communicate with
    each other directly. This heterogeneity issue has been identified as one of the
    most critical issues severely obstructing the development of SW-IoT [3]. An ultimate
    solution for this issue is to unify the communication protocols between different
    layers by following mutually agreed standards. Among the standards related to
    the SW-IoT, the Sensor Web Enablement (SWE) standards defined by the OGC (Open
    Geospatial Consortium) have been widely adopted [8,9,10,11]. The SWE mainly defines
    web service interface standards, such as SOS (Sensor Observation Service) [12],
    SPS (Sensor Planning Service) [13], SensorThings API [14], and data model standards,
    such as O&M (Observations and Measurements) [15], SensorML (Sensor Model Language)
    [16]. By following the SWE standards, sensor metadata and observations can be
    described with a unified framework, and sensing and tasking capabilities can be
    accessed in an interoperable manner. In addition, among the SWE standards, the
    SensorThings API (Application Programming Interface) is the newest RESTful service
    interface standard for SW-IoT data services. This standard has two main advantages.
    Firstly, this standard defines a comprehensive SW-IoT data model based on the
    O&M standard. Secondly, its service interface is inspired by the OASIS (Organization
    for the Advancement of Structured Information Standards) Open Data Protocol (OData)
    [17], which supports intuitive and flexible query functions based on the Representational
    State Transfer (RESTful) style and JavaScript Object Notation (JSON) encoding.
    Therefore, we believe that the SensorThings API is one of the most complete SW-IoT
    data service interfaces. However, while the SWE standards mainly focus on the
    service layer, communication between devices and gateways did not receive enough
    attention in the SWE ecosystem. To be specific, the communication between the
    device layer and the gateway layer is important for device registration, observation
    uploading, and task forwarding. Although there have been some efforts proposed
    to address this issue in the SWE ecosystem, such as PUCK [18] and SID (Sensor
    Interface Descriptors) [19], these approaches are either not open standards or
    are not designed to integrate with the SensorThings API. Therefore, the main goal
    of this research is to fill in the missing components in the current SensorThings
    API architecture, which allows embedded devices to automatically register themselves
    and their sensing and tasking capabilities to a SensorThings API service through
    local gateways. This solution is designed to support various scenarios. The scenarios
    can be summarized into four general types, including the registration of sensing
    capabilities of in-situ and mobile devices, and the registration of tasking capability
    of in-situ and mobile devices. To be specific, in-situ and mobile devices can
    automatically register themselves to a SensorThings API service, continuously
    upload sensor observations or new locations, and update web addresses of connected-gateways
    for services to task devices. These scenarios should be able to cover most SW-IoT
    use cases via the integration of sensing and tasking capabilities [20]. In general,
    this research tries to construct a coherent architecture that can seamlessly integrate
    the device layer, the gateway layer, and the service layer based on the SensorThings
    API ecosystem. To be specific, we propose a solution called SW-IoT Plug and Play
    (IoT-PNP) to achieve an automatic registration procedure from embedded devices
    to SensorThings API services. There are three main parts in the IoT-PNP. Firstly,
    this research defines a description file format for device metadata and capabilities,
    in order that the devices become self-describing. Secondly, the IoT-PNP defines
    a default configuration of a local wireless communication protocol to automatically
    establish connections between devices and gateways. Thirdly, registration procedures
    for sensing and tasking capabilities are designed to support different possible
    scenarios, which are new devices, new gateways, and mobile devices. In general,
    the contributions of this research are as follows. First of all, the proposed
    IoT-PNP can fill in the missing components of the SensorThings API ecosystem to
    construct a complete SW-IoT architecture covering the device, gateway, and service
    layers. Second of all, the proposed registration procedures can support various
    scenarios for sensing and tasking capabilities on in-situ and mobile devices.
    Third of all, by applying a keyword replacement mechanism, the proposed solution
    can automatically translate tasking requests to heterogeneous device protocols.
    However, similar to every approach that aims to achieve interoperable communication,
    a certain degree of modification on devices are required to support the proposed
    solution. In the next section, we review existing solutions proposed by different
    organizations to address heterogeneity issues on different layers of an SW-IoT
    system and analyze the advantages and disadvantages of these solutions. In Section
    3, we introduce our solutions, the SW-IoT plug-and-play (IoT-PNP). In Section
    4, we apply the IoT-PNP on four use-cases based on different scenarios. Finally,
    Section 5 concludes this research. 2. Related Work To address the aforementioned
    SW-IoT heterogeneity problem, there are two possible approaches. The first one
    is the hub approach. The hub approach is achieved by implementing different connectors
    corresponding to different SW-IoT ecosystems. With the connectors, a hub can communicate
    with different systems. A hub can be in the application layer, service layer or
    gateway layer as long as the hub can support protocols of different systems. For
    example, If-This-Then-That (IFTTT), a service hub on the application layer, supporting
    many connectors connecting to many web applications and SW-IoT systems. The hub
    approach is effective and easy to develop. However, for as many SW-IoT systems,
    a hub needs to implement customized connectors, which results in significant development
    cost. The second approach is the standard approach. In principle, by following
    standards, SW-IoT systems from different manufacturers can collaborate with each
    other within each standard ecosystem. There are some organizations proposing their
    proprietary standards, such as Apple’s “Works with HomeKit (https://www.apple.com/tw/ios/home/accessories/)”
    and Google’s “Works with Nest (https://nest.com/works-with-nest/)”. Different
    from the hub approach, enterprises are trying to define proprietary standards
    to attract manufacturers to join their ecosystems. However, proprietary standards
    and ecosystems would cause more heterogeneity issues as no existing SW-IoT ecosystem
    is large enough to attract all manufactures. On the other hand, the real potential
    of the standard approach is to follow open and commonly agreed standards. For
    example, there are many existing open standards defined for unifying interfaces
    of the SW-IoT Service Layer. Among the standards, the OGC SOS is a web service
    interface standard for sensor resource sharing. Information shared by SOS services
    is described with other SWE standards such as the O&M and SensorML. However, the
    SOS is based on Simple Object Access Protocol (SOAP) and XML-based network protocol,
    which are considered as outdated and inefficient. Therefore, OGC recently defines
    another service interface standard, the SensorThings API. The first part of the
    SensorThings API standard is primarily designed for the SW-IoT sensing capability.
    Different from other OGC service interfaces, the SensorThings API applies RESTful
    style and JSON encoding to provide a more lightweight and efficient interface.
    The data model of the SensorThings API is mainly extended from the O&M data model
    by including classes of IoT to ensure the versatility of its data model. The interface
    of the SensorThings API service is inspired by the OASIS OData. SW-IoT resources
    are represented as entities or properties that can be identified by URIs (Uniform
    Resource Identifiers), and resources can be linked together using relationship
    links. The second part of the SensorThings API is under development and focuses
    on extending the data model and service interface to support tasking capabilities.
    In addition, there are some standards designed by different industrial alliances.
    HyperCat standard [21] is proposed by the HyperCat consortium, an organization
    which is composed of more than 40 UK-based companies including British Telecom,
    Rolls-Royce, and military supplies manufacturer BAE, etc. The HyperCat is an open,
    lightweight, JSON-based online catalog tagged with metadata. The HyperCat exposes
    SW-IoT devices’ information and observation resources over the web with semantic
    annotations. Instead of requiring manufacturers to follow the same data format,
    the HyperCat can describe data from different providers and help users search
    for the data relevant to their needs. OpenIoT standard [22] is a European Union
    (EU) open source web service standard released by developers from industry and
    academia jointly in 2012, which uses semantic web technologies to connect physical
    and virtual sensors to the OpenIoT web platform. The OpenIoT utilizes the Extended
    Global Sensor Network (XGSN) [23] as a hub between the OpenIoT service and the
    physical world, which can collect and filter semantically annotated data streams
    from SW-IoT devices. On the other hands, some open standards focus on device layer
    protocols. OneM2M is an international standard organization composed of standard
    organizations from Europe, America, China, Japan, and South Korea, and was established
    in July 2012. The oneM2M standard designs a distributed software layer that provides
    an interoperable framework. This distributed software layer is composed of three
    entities, Application Entity (AE), Common Services Entity (CSE), and Network Services
    Entity (NSE) [24]. An AE is an application implemented on oneM2M nodes. A CSE
    provides a set of common services functions (CSFs) to other AEs, CSEs, NSEs. An
    NSE provides network service functions from underlying networks such as 3GPP,
    3GPP2, and WLAN to the CSEs. Furthermore, OGC PUCK is a standard that aims at
    providing interoperable communications between devices and host computers through
    serial cables (RS-232) or Ethernet. PUCK defines several PUCK commands for hosts
    to discover PUCK-enabled devices and retrieve devices’ metadata or drivers from
    devices. The hosts can parse devices’ metadata by following the PUCK standard
    format and install drivers to communicate with devices. Another solution based
    on the OGC SWE ecosystem is Sensor Interface Descriptor (SID). The SID aims at
    solving the heterogeneity issue between the service layer and the device layer
    [19]. The SID defines a schema and an extension to the OGC SensorML, to describe
    a sensor’s communication protocol, commands, processing steps, and metadata association.
    According to the SID, a SID interpreter (gateway) can translate a sensor protocol
    into the OGC web services interface. A similar work to the SID was proposed by
    Martínez et al. [25], where the authors defined the Sensor Deployment Files (SDF)
    describing the metadata of a sensor and designed a framework to retrieve SDF via
    PUCK and register information to OGC SOS. Universal Plug and Play (UPnP) [26]
    is a network protocol proposed by the UPnP forum, which aims at providing seamless
    connections for devices in the same Local Area Network (LAN). The UPnP is a distributed
    architecture based on the TCP/IP, HTTP, XML, and SOAP network. The UPnP provides
    “Addressing” and “Discovery” procedure for new devices and services to join the
    UPnP network. A control point can control devices or subscribe to events of devices
    according to the description provided by devices. As mentioned earlier, the objective
    of this study is to achieve automatic connections between the service layer and
    the device layer. The OGC SOS, SensorThings API, OpenIoT are standard service
    interfaces for the service layer. The HyperCat provides a catalog service and
    data semantic annotation for sensor data searching, where the annotation and publish
    should be manually finished. The OGC PUCK mainly defines commands for device communication,
    where an automatic registration procedure was not defined. Some manual work is
    still needed for sharing sensing and tasking capabilities to the service layer.
    The SID provides a complete data model for describing sensing and tasking capabilities.
    However, for the Plug and Play, their data model is verbose in XML schema and
    is complicated for devices to support. The SDF approach is also based on XML and
    only supports sensing capabilities. The UPnP operates on networks based on the
    TCP/IP, HTTP, XML, and SOAP, thus that the standard cannot be applied to devices
    on low-power wireless communication networks. The oneM2M provides an operating-system-like
    logic layer for various kind of devices. However, as the oneM2M only defines a
    general and flexible data model, integrating sensor information from different
    devices may have serious heterogeneity issues. Based on our understanding, the
    existing solutions cannot fully address the heterogeneity issue between the Service
    Layer and the Device Layer. Therefore, this research aims at proposing a solution
    to allow embedded devices to be self-describing, automatically establish a connection
    between devices and gateways via local wireless communication protocols, register
    device’s sensing and tasking capabilities to the service layer, and control devices
    via the service layer and the gateway layer. In addition, the OGC SensorThings
    API is chosen as the service layer because of its comprehensive data model and
    flexible service interfaces. 3. Methodology This research proposes the SW-IoT
    plug-and-play (IoT-PNP) to automatically establish communication between the device
    layer and the service layer for both sensing and tasking capabilities of embedded
    devices. The IoT-PNP has three main components: (1) A data model and encoding
    describing devices’ metadata, sensing and tasking capabilities, (2) a communication
    protocol and default connection settings for the gateway layer and the device
    layer, and (3) an automatic registration procedure for registering devices and
    their sensing and tasking capabilities on a SensorThings API service. The details
    of these components are explained in the following subsections. 3.1. Device Description
    Data Model and Encoding 3.1.1. OGC SensorThings API Data Model In the OGC SensorThings
    API, devices can be described by a standard data model, which is extended from
    the OGC O&M model. The O&M defines a complete data model of an observation event
    by identifying necessary classes/properties and their relationships. The SensorThings
    API includes the SW-IoT concept into the O&M data model by introducing additional
    classes. Figure 2 is the UML (Unified Modeling Language) diagram of the SensorThings
    API data model. An SW-IoT device can be modeled as a Thing entity. A Thing uses
    Location entities to introduce its current location and uses HistoricalLocation
    entities for its past trajectory. A Thing can have one or more Datastreams, where
    each Datastream is a logical aggregation of sensor Observations of an ObservedProperty
    produced by the same Sensor. Observations may observe different FeaturesOfInterest.
    As the O&M data model has been applied in many fields for more than a decade,
    this SensorThings API data model is also considered complete and general for the
    SW-IoT. Figure 2. The SensorThings API UML diagram [14]. 3.1.2. Extended SensorThings
    API As mentioned earlier, the first part of the SensorThings API is only designed
    for the sensing capability but did not consider the tasking capability. To address
    this issue, Huang and Wu [4] proposed the Extended SensorThings API (Figure 3)
    as a potential solution to support tasking capabilities in the SensorThings API
    ecosystem. Firstly, the data model is extended, where each Thing can have zero
    to many TaskingCapability entities. Each TaskingCapability is executed by an Actuator.
    When a client can create Tasks based on applicable Parameters of a TaskingCapability,
    an Extended SensorThings API service will apply the HTTPProtocol of the TaskingCapability
    to translate Tasks into requests following the device protocol. To be specific,
    Huang and Wu [4] proposed the keyword replacement solution to perform automatic
    translation between the device protocol and the SensorThings API protocol. Based
    on this solution, no human intervention is required as long as devices can describe
    their tasking capabilities based on the defined data model. Figure 3. The data
    model of tasking capability [4]. Comparing with the original SensorThings API
    standard, the Extended SensorThings API provides an extended data model to describe
    tasking capabilities of SW-IoT devices. Based on the data model, users can remotely
    control devices through Extended SensorThings API services. As OGC is still defining
    the second part of the SensorThings API, this research applies the Extended SensorThings
    API [4] as the Service Layer to support both sensing and tasking capabilities.
    3.1.3. Description File In terms of the proposed IoT-PNP, to automatically register
    embedded devices to the service layer, embedded devices need to be self-describing,
    which means metadata, sensing and tasking capabilities, and device communication
    protocols should be introduced by the devices themselves. Therefore, the first
    component of the IoT-PNP is to define a description file to explain the details
    of embedded devices. Since this research aims at proposing a plug-and-play solution
    based on the SensorThings API, we can directly follow the SensorThings API data
    model to design the description file. The following subsections explain three
    sections of the description file, which are Thing’s metadata, sensing capabilities,
    and tasking capabilities. Description File—Thing Metadata This section introduces
    the metadata of an embedded device, such as name, properties, and locations. Figure
    4 shows an example of the Thing metadata section. According to the SensorThings
    API definition, the properties of a Thing are key-value pairs for developers to
    describe any information related to this Thing. For this research, to support
    the automatic registration procedure, we define a new property called UID that
    indicates a unique identifier of a device. This identifier should be unique at
    least among all devices in a single service. In the automatic registration procedure,
    the UID is applied to identify the registration status of a device. Please note
    that the name property of a Thing entity could also serve the same purpose if
    the name property is defined as unique in a service. Figure 4. Thing metadata
    of an example description file. Description File—Sensing Capability By following
    the SensorThings API data model, sensing capabilities can be directly modeled
    as Datastream entities. According to the SensorThings API definition, one Datastream
    links to a Sensor and an ObservedProperty. Therefore, the information of the corresponding
    Sensor and ObservedProperty should also be described in the description file along
    with other necessary attributes, such as the unitOfMeasurement. After registering
    a Datastream to a service, Observations of this Datastream will be created and
    linked to this Datastream entity. Figure 5 shows an example description file where
    one device has two Datastreams measuring air temperature and humidity. Figure
    5. Sensing capability of an example description file. Description File—Tasking
    Capability As mentioned earlier, this research applies the data model defined
    in the Extended SensorThings API (Figure 3) to support the tasking capability.
    However, since the Extended SensorThings API was designed as a service interface,
    this description file is mainly for embedded devices to introduce themselves to
    gateways. Therefore, instead of specifying the HTTPProtocol, this description
    file should explain the device protocol on local wireless communication protocols,
    such as ZigBee, Bluetooth, or Low Power WANs. To be specific, the HTTPProtocol
    should be replaced by classes like ZigBeeProtocol or BluetoothProtocol, etc. As
    this research chooses ZigBee as the local wireless communication protocol for
    implementation, the description file with the proposed ZigBeeProtocol is shown
    in Figure 6. Figure 6. Tasking capability of an example description file. In the
    ZigBeeProtocol, extendedAddressHigh and extendedAddressLow are the high and low
    32 bits of unique IEEE 64-bit Extended Address of a device’s ZigBee module to
    establish a connection between gateways and devices. The messageBody is a device’s
    tasking request template, as messageDataType describes the data type of messageBody.
    The tasking capability in this research also adopts the keyword replacement strategy
    proposed by Huang and Wu [4] to describe the device protocol and acceptable parameters.
    The content of messageBody can be defined by device developers as long as it follows
    the rule of keyword replacement, which will be explained in detail in Section
    3.2.3. Finally, similar to the sensing capability, as one device can support different
    tasking capabilities, a Thing could have multiple TaskingCapability entities.
    Figure 6 shows an example description file where one device has a TaskingCapability
    serving as a smart light bulb that can be turned on/off via ZigBee. 3.2. Communication
    Protocol for the Gateway Layer and the Device Layer As the middle layer between
    the service layer and the device layer, the gateway layer should provide three
    functionalities: (1) Allowing devices connected to a gateway through different
    wireless communication protocols, (2) interpreting a device’s description file
    and registering the device and its observations to a specified SensorThings API
    service, and (3) translating the extended SensorThings API tasking protocol to
    the device tasking protocol. To achieve these functionalities, this research defines:
    (1) Default configurations of a wireless communication protocol, which is ZigBee
    in this research, (2) communication operations on gateways and devices, and (3)
    an automatic procedure for tasking protocol translation and task forwarding. These
    three designs are introduced respectively in the following subsections. 3.2.1.
    ZigBee Configuration To wirelessly connect to the Internet, Wi-Fi was designed
    for wireless Ethernet connectivity. However, Wi-Fi modules have high power consumption
    for embedded devices to support. Therefore, wireless network techniques with low
    power consumption are more preferable for embedded devices, such as Bluetooth,
    ZigBee, LoRa, SigFox, NB-IoT, etc. Therefore, in the SW-IoT architecture, a gateway
    should communicate with devices via these low-power-consumption wireless communication
    protocols and connect with services via Wi-Fi or Ethernet. In this research, we
    choose ZigBee as the wireless communication network to prove the concept. ZigBee
    [27] is based on the IEEE 802.15.4 standard [28]. The IEEE 802.15.4 standard focuses
    on low energy consumption, low-rate transmission, and low-cost wireless network
    to provide low-speed interconnection between different devices. As the transmission
    distance of ZigBee is about 10~100 meters, ZigBee is suitable for many small-scale
    SW-IoT use cases, such as smart home, e-health, industrial 4.0. According to the
    IEEE 802.15.4 standard, a ZigBee network has full-function devices (FFDs) and
    reduced-function devices (RFDs). An FFD can communicate with both FFDs and RFDs.
    An RFD can only communicate with FFDs. An FFD associated with an RFD is called
    the coordinator of that RFD. There is an only FFD, called PAN (Personal Area Network)
    coordinator, in one ZigBee network, which is the main controller of that network.
    The PAN coordinator is responsible for managing other FFDs (i.e., routers) and
    RFDs (i.e., end devices) in the network. The PAN coordinator needs to select a
    PAN ID (16-bit and 64-bit) and a channel to establish the network. All devices
    in one ZigBee network share the same PAN ID and channel with the PAN coordinator.
    While the 16-bit PAN ID is randomly selected when a PAN coordinator starts a new
    network, the ZigBee Alliance defines the 64-bit PAN ID (i.e., Extended PAN ID)
    which can be preconfigured on a PAN coordinator. Other devices that are configured
    with the same 64-bit PAN ID can join the same network. Each ZigBee device possesses
    16-bit and 64-bit addresses. The 16-bit address, also called a network address,
    is randomly generated by the coordinator that allows the device to join the network.
    However, the 16-bit address is not static, which is sometimes not reliable for
    data transmission. On the other hand, the 64-bit address, also called extended
    address or IEEE address, is a universally unique identifier for a ZigBee device,
    which is a better choice to identify destination devices. Table 1 shows our design
    for the IoT-PNP default ZigBee network configuration. First of all, to allow devices
    to connect to gateways automatically, the wireless communication modules of both
    devices and gateways should share the same PAN ID. Gateways and devices which
    want to support the IoT-PNP should follow the defined extended PAN ID (i.e., 14,647).
    Second of all, based on the ZigBee standard, to configure ZigBee network that
    (1) the PAN coordinator forwards messages to all devices (i.e., broadcast mode)
    and (2) messages from devices are transmitted/forwarded to the PAN coordinator,
    where we define that the PAN coordinator uses “0xFFFF” as the extended address
    of destination to broadcast messages to the entire network, and routers and end
    devices use “0” as the extended address of destination to forward messages to
    the PAN coordinator. Table 1. IoT-Plug and Play (PNP) ZigBee network configurations.
    Please note that the role of this configuration is intended to be a global or
    national setting to establish a public gateway infrastructure, and the current
    ZigBee configuration is defined to prove the concept. However, this public configuration
    would result in security concerns such as intercepting messages with malicious
    gateways. Mechanisms like payload encryption, gateway verification, random/dynamic
    configurations of local communication protocols for private connections, etc.
    should be further investigated, which is also a main future work of this research.
    3.2.2. Communication Operations on Gateways and Devices By following the IoT-PNP
    default ZigBee configuration, devices can automatically join the ZigBee network
    of IoT-PNP and connect to IoT-PNP gateways. For devices and gateways to exchange
    information, operations on gateways and devices need to be defined. Each operation
    is composed of several properties as shown in Table 2. The details of the designed
    gateway and device operations are explained in the following subsections. The
    use of these operations is explained in Section 3.3. Table 2. Operation properties.
    Gateway Operations The gateway operations define interfaces allowing devices to
    send requests to gateways. In general, we have designed five gateway operations,
    which are UploadObs, UpdateStatus, SendServURL, SendDesc, and SendServURLandDesc.
    The details of these operations are explained in Table 3, Table 4, Table 5, Table
    6 and Table 7. In addition, we use the gray background color to indicate the placeholders
    to be replaced with actual content, such as the “<device_ID>”. Table 3. UploadObs
    operation. Table 4. UpdateStatus operation. Table 5. SendServURL operation. Table
    6. SendDesc operation. Table 7. SendServURLandDesc operation. Device Operations
    Device operations define interfaces allowing gateways to send requests to devices.
    We have designed four device operations, which are GetServURL, GetDesc, GetServURLandDesc,
    and Confirm. The details of these operations are explained in Table 8, Table 9,
    Table 10 and Table 11. We also use the gray background color to indicate the placeholders
    to be replaced with actual content. Table 8. GetServURL operation. Table 9. GetDesc
    operation. Table 10. GetServURLandDesc operation. Table 11. Confirm operation.
    3.2.3. Tasking Protocol Translation and Task Forwarding According to the extended
    SensorThings API, Huang and Wu [4] propose the keyword replacement solution to
    automatically translate users’ tasks into different device protocols. While Huang
    and Wu [4] define the interface translation between the service interface and
    the device protocol, this research applies the same concept to establish automatic
    protocol translation between the web service and gateway as well as gateway and
    device. In general, tasking protocol translation can be divided into the registration
    process and the tasking process. The registration process has the following steps:
    (1) A device sends a TaskingCapability entity in the description file to a gateway,
    (2) the gateway follows the content in local wireless communication protocols,
    e.g., zigbeeProtocol, and generates a corresponding httpProtocol, and (3) the
    gateway registers the httpProtocol to an extended SensorThings API service. The
    tasking process has the following steps: (1) A user creates a Task in the extended
    SensorThings API service based on the TaskingCapability shown in the service,
    (2) the service follows the httpProtocol to translate into a gateway request and
    forward the task to the gateway, (3) the gateway parses the tasking parameters
    from the service request, (4) the gateway follows the zigbeeProtocol to translate
    into a device request and forward the task to the device. We use a smart light
    bulb example in Figure 6 to explain the detail procedure. First of all, the device
    sends the describe file in Figure 6 to a gateway. Based on the TaskingCapability
    entity, the gateway can understand there is a task template, i.e., MY_DEVICE00010:LightBulb:{on},
    with a placeholder {on}. The on in the placeholder {on} is the parameterID introduced
    in the TaskingCapability entity of this light bulb, which will be replaced as
    true or false to turn on or off the light bulb. By following the content in the
    TaskingCapability entity, the gateway then replaces the zigbeeProtocol to a httpProtocol
    as the gateway protocol. The absoluteResourcePath is the static IP address of
    the gateway. Please note that the httpProtocol can be defined by gateway developers
    as long as the gateway can understand the mapping between the zigbeeProtocol and
    the httpProtocol. Algorithm 1 shows an example of an httpProtocol created by the
    gateway, where the gateway still uses {on} as the placeholder in the httpProtocol.
    Algorithm 1. An httpProtocol example. \"httpProtocol\": { \"httpMethod\": \"POST\",   \"absoluteResourcePath\":
    \"http://example.com/Gateway\",   \"messageDataType\": \"application/json\",   \"messageBody\":   \"{\\\"on\\\":{on},\\\"TC_name\\\":\\\"LED\\\",\\\"device_ID\\\":\\\"DEVICE00001\\\"}\"
    } When a client sends a task (Algorithm 2) to an extended SensorThings API service,
    the service replaces the placeholder {on} with an input value true specified in
    the client’s request, and sends an HTTP request (Algorithm 3) to the gateway.
    After the gateway receives the HTTP request, the gateway finds out that the placeholder
    {on} has been replaced with true, and then follows the messageBody in the zigbeeProtocol
    to replace the placeholder {on} with true as well. Finally, the gateway sends
    the translated task (Algorithm 4) to the device by following the ZigBee connection
    settings in the zigbeeProtocol. Algorithm 2. A Task from a user to the service.
    {   \"TaskingCapability\": {      \"@iot.id\": 1   },   \"input\": [      {        \"ParameterID\":
    \"on\",        \"Value\": true      }   ] } Algorithm 3. The task forwarded to
    the gateway. POST http://example.com/Gateway HTTP/1.1   {   \"on\": true,   \"TC_name\":
    \"LED\",   \"device_ID\":   \"DEVICE00001\" } Algorithm 4. The task forwarded
    to the device. MY_DEVICE00010:LightBulb:true 3.3. Automatic Registration Procedure
    The communication procedure between the device layer, the gateway layer, and the
    service layer should be standardized to achieve automatic registration. In the
    following subsections, we first introduce the possible scenarios and then explain
    the proposed procedures for sensing and tasking capabilities. 3.3.1. Scenarios
    We have considered three possible scenarios that the IoT-PNP procedure would encounter.
    The first scenario is that a new device wants to join an SW-IoT system via a nearby
    gateway. The second scenario is that an old gateway is replaced by a new gateway,
    which needs to collect necessary information from nearby devices in the local
    network. The third scenario targets on mobile devices, where devices can connect
    to new gateways when moving to other networks. These three scenarios are also
    the use cases we applied to examine the proposed solution. 3.3.2. Registration
    Procedure for the Sensing Capability When a device joins an SW-IoT system, the
    device will be registered in the gateway’s lookup table and the SensorThings API
    services. The gateway holds a lookup table which records the description files
    of devices exist in the local network as well as their corresponding virtual identities
    on the SensorThings API service. Figure 7 is the overall registration procedure
    for the sensing capability. Figure 7. The workflow of the sensing capability registration
    procedure. First of all, the registration procedure is triggered when a device
    tries to upload observations or new locations by sending an UploadObs operation
    (Arrow 1) to the connected gateway. The UploadObs operation contains the observations
    or locations in the msg_body (Table 3). Once the gateway receives the UploadObs
    operation, the gateway will check if the device has been registered in its lookup
    table according to the device UID. If the device has been registered in the lookup
    table, the gateway can directly upload the observations or new locations to the
    service (Arrow 2) as the device’s virtual identities have also been also stored
    in the lookup table, and then the gateway sends a Confirm operation (Arrow 12)
    to the device to confirm the end of the procedure. However, if the device has
    not been registered in the lookup table (i.e., a new device, a new gateway, or
    a mobile device), the gateway will send the GetServURL operation (Arrow 3) to
    the device to ask for the service URL that the device wants to be registered to.
    The device responds with the SendServURL operation (Arrow 4) containing the service
    URL. With the service URL, the gateway can query the service based on the device
    UID, to check whether the device has been registered in the service or not. If
    the device has been registered in the service (i.e., a new gateway or a mobile
    device), the gateway can collect the device’s sensing capabilities and virtual
    identities from the service to update its lookup table (Arrow 5), and finally
    upload the observations or locations to the service (Arrow 11). If the device
    has not been registered to the service (i.e., a new device), the gateway will
    send a GetDesc operation (Arrow 6) to the device to ask for the description file
    of the device. The device responds with the SendDesc operation (Arrow 7) containing
    the description file. Based on the description file, the gateway helps the device
    register to the service and create necessary entities, including Thing (Arrow
    8), Datastream, or TaskingCapability (Arrow 9), etc. In this step, the gateway
    checks if there is already the same ObservedProperties registered on the service.
    If the ObservedProperties have been registered, the gateway will retrieve the
    IDs and link new Datastreams to the existing ObservedProperties. Finally, after
    the gateway uploads the observations or locations to the service, the gateway
    sends a Confirm operation (Arrow 12) to the device to confirm the end of the procedure.
    Please note that although this workflow is mainly for the sensing capability,
    the gateway registers both sensing and tasking capabilities to the service. 3.3.3.
    Registration Procedure for the Tasking Capability The proposed tasking capability
    procedure requires gateways to have static IP addresses, which is more realistic
    than requiring each device to have a static IP address. In our design, gateways
    receive tasks from services and deliver the tasks to corresponding devices through
    local communication protocols. Therefore, when a gateway registers a device to
    a service, the IP address of the gateway and the httpProtocol should be uploaded
    to the services. However, considering the mobile device scenario, a device could
    connect to different gateways, which means that the currently-connected gateway
    should dynamically update the IP address and the httpProtocol on the service.
    Figure 8 shows the proposed tasking capability registration procedure. Figure
    8. The workflow of the tasking capability registration procedure. First of all,
    if a device supports any tasking capability, the device should periodically send
    an UpdateStatus operation (Arrow 1) to the currently-connected gateway. The gateway
    will first check its lookup table. If the tasking capability of the device has
    been recorded in the lookup table, which means that this device has been registered
    to this gateway before, the gateway will directly update the gateway’s IP address
    and its httpProtocol on the service (Arrow 2) and send a Confirm operation (Arrow
    3) to the device to confirm the end of the procedure. The reason of updating the
    gateway IP address and its httpProtocol even if the device is known to the gateway
    is that if the device has connected with other gateways (e.g., a mobile device
    or nearby gateways), the gateway IP address and httpProtocol on the service could
    have been changed. Therefore, this seen-to-be redundant procedure is to ensure
    that the service can successfully forward tasks to the gateway. If the gateway
    cannot find the tasking capability of the device in the lookup table, all three
    scenarios are possible (i.e., a new device, a new gateway, or a mobile device).
    However, unlike that gateways can collect devices’ sensing capabilities by querying
    the service, device protocols (e.g., the zigbeeProtocol) are not stored in the
    service because of security concerns. Therefore, the gateway needs to send a GetServURLandDesc
    operation (Arrow 4) to the device to ask for both the service URL and the description
    file. The device then responds with the SendServURLandDesc operation (Arrow 5).
    Afterward, the gateway checks if the device has been registered to the service.
    If the device has been registered (i.e., a new gateway or a mobile device), the
    gateway will update the gateway’s IP address and its httpProtocol to the service
    (Arrow 6) and record the device’s sensing and tasking capability in its lookup
    table (Arrow 10), and finally send a Confirm operation (Arrow 11) to the device
    to confirm the end of the procedure. If the device has not been registered to
    the service (i.e., a new device), the gateway will help the device register its
    sensing and tasking capability to the service (Arrow 7, 8) and its lookup table
    (Arrow 9), and finally send a Confirm operation (Arrow 11) to the device to confirm
    the end of the procedure. Finally, to be specific, all static information required
    to support the proposed registration procedures could be pre-configured in factories,
    such as the URL of a SensorThings API service and the description file. However,
    if manufacturers or applications choose to grant users the ability to modify any
    information, some application-driven design should be made for users to access
    and modify the device content via local wireless communication, the SensorThings
    API service, or other potential means. 4. Results To examine the proposed automatic
    registration procedure, we design several applications based on different scenarios.
    As the SW-IoT provides sensing and tasking capabilities and devices can be categorized
    into in situ or mobile devices, we design four applications: In situ sensing (Section
    4.1), in situ tasking (Section 4.2), mobile sensing (Section 4.3), and mobile
    tasking (Section 4.4). We applied Arduino Uno (Figure 9) as the micro-controller
    and the Digi XBee serial 2 (Figure 10) for the ZigBee communication. In addition,
    to evaluate the performance of the proposed solution in a real-world scenario,
    we have conducted a one-month indoor environment monitoring experiment in an underground
    metro mall. The details are explained in Section 4.5. Figure 9. Arduino Uno. Figure
    10. Digi XBee serial 2. 4.1. In situ Sensing Application The in situ sensing application
    we designed is the indoor monitoring. A monitoring device (Figure 11) is installed
    with a DHT22 sensor measuring temperature and humidity. A gateway, which is a
    laptop connected with an XBee module, can automatically help new indoor monitoring
    devices register to the SensorThings API service. In the meantime, the device
    will periodically measure air temperature and humidity observations and upload
    the observations via UploadObs requests. Algorithm A1 shows the description file
    of this embedded device. And Figure 12 and Figure 13 show the time-series observations
    retrieved from the SensorThings API service. Figure 11. The indoor monitoring
    device. Figure 12. The temperature observations from the indoor monitoring device.
    Figure 13. The humidity observations from the indoor monitoring device. 4.2. In
    situ Tasking Application The in situ tasking application we design is a remotely-controllable
    LCD and LED device (Figure 14). The device is installed with a Parallax 2 × 16
    Serial LCD and a LED. The device periodically sends UpdateStatus requests to update
    the gateway’s IP address on a service. Please note that the frequency of sending
    UpdateStatus requests depends on device mobilities, which can be set when constructing
    devices. For an in situ device, a lower frequency should be enough to make sure
    the device is accessible via a connected gateway. Algorithm A2 shows the description
    file of this device. Algorism 5 and 6 show example tasks from the service to turn
    on the LED and display text on the LCD monitor, respectively. Figure 15 and Figure
    16 are results triggered by the tasks. Figure 14. The remotely-controllable Liquid-crystal
    Display (LCD) and Light-emitting Diode (LED) device. Figure 15. LED turned on.
    Figure 16. LCD showing the corresponding text. Algorithm 5. An example task to
    turn on the LED. {    \"TaskingCapability\": {      \"@iot.id\": 33    },    \"input\":
    [      {         \"ParameterID\": \"on\",         \"Value\": true      }    ]
    } Algorithm 6. An example task to display text on the LCD monitor. {    \"TaskingCapability\":
    {      \"@iot.id\": 34    },    \"input\": [      {        \"ParameterID\": \"msg\",        \"Value\":
    \"Hello world!!!\"      }    ]  } 4.3. Mobile Sensing Application The mobile sensing
    application we designed is a mobile luminosity-monitoring device (Figure 17),
    which is installed with a TSL2561 luminosity sensor (TAOS Inc., Plano, TX, USA).
    The device periodically captures luminosity observations and sends observations
    through UploadObs requests. When this mobile device connects to a new gateway,
    the registration procedure will be triggered by UploadObs requests, where the
    getaway will perform the registration process and upload observations. Algorithm
    A3 is the description file of this device. Figure 18 shows the observations retrieved
    from the SensorThings API service. Figure 17. The mobile luminosity-monitoring
    device. Figure 18. The luminosity observations of the mobile luminosity-monitoring
    device. 4.4. Mobile Tasking Application The mobile tasking application we designed
    is a remotely-controllable buzzer. The device is installed with an MH-FMD passive
    buzzer module (Figure 19). The device periodically sends UpdateStatus requests
    to trigger the update of a connected gateway’s IP address to the SensorThings
    API service. As mentioned earlier, the frequency of UpdateStatus requests could
    set higher for mobile devices in order to make sure that the SensorThings API
    service knows the currently-connected gateway. Algorithm A4 shows the description
    file of this device. Algorithm 7 shows an example task from the service to turn
    on the buzzer. Figure 19. The remotely-controllable buzzer device. Algorithm 7.
    An example task to ring the buzzer five times. {    \"TaskingCapability\":{       \"@iot.id\":41    },    \"input\":[       {           \"ParameterID\":
    \"buzz_time\",           \"Value\": 5       }     ]  } 4.5. A Real-world Experiment—Underground
    Metro Mall Environment Monitoring Besides the aforementioned applications demonstrating
    the capabilities of the proposed solution, we have also conducted a real-world
    experiment to evaluate the performance of the proposed solution. This experiment
    is an indoor monitoring application, where the testing site is at the East Metro
    Mall in Taipei. The East Metro Mall is a 725 m long underground public space with
    many restaurants and stores, which is usually crowded during rush hours, meal
    times, and weekends. We applied the Arduino Uno, DHT22 temperature and relative
    humidity sensor, and XBee communication module to construct 34 SW-IoT devices.
    With the message-forwarding capability of ZigBee, we only deployed one gateway
    (i.e., a laptop) to receive sensor observations. Figure 20 shows the floor plan
    and the locations of sensors (i.e., black dots) and the gateway (i.e., red star).
    The number besides each black dot represents the ID of each device. Figure 21
    shows some photos of the deployed devices, where the white boxes contain the devices.
    Figure 20. The distribution of the sensors and the gateway of the real-world experiment.
    Figure 21. Photos of the deployed devices. The time period of the testing is from
    27 September 2018 to 2 November 2018, where the sampling frequency for each device
    was set as 15 min. According to the sampling rate, we should receive 117,504 observations
    in the 37 days of the experiment. However, the gateway was accidently turned off
    on 11 October 2018. By excluding that day, we should receive 117,540 observations
    for both temperature and relative humidity. In reality, we have received 108,328
    temperature observations and 108,328 relative humidity observations. Therefore,
    the overall successful return rate is 92.19%. All the devices can successfully
    upload sensor observations periodically. Figure 22 and Figure 23 show the time-series
    observations of device 24 between 12 October 2018 to 2 November 2018 retrieved
    from the SensorThings API service. As the temperature is ranging between 22 to
    26 degree Celsius, it shows a periodical trend that fits with the schedule of
    air conditioning. On the other hand, while the relative humidity shows a similar
    behavior with the temperature, it also captured the dry days from 10 October 2018
    to 30 October 2018. Figure 22. The temperature observations from the device 24
    between 12 October 2018 to 2 November 2018. Figure 23. The humidity observations
    from the device 24 between 12 October 2018 to 2 November 2018. 5. Conclusions
    and Future Work This research proposes the IoT-PNP solution that extends the SensorThings
    API ecosystem to the gateway layer and the device layer to construct a unified
    SW-IoT architecture. To be specific, we first define a description file for devices
    to describe its metadata and capabilities. And then with the designed gateway
    and device operations for wireless communication protocols, such as ZigBee in
    this research, devices can automatically discover and connect to local gateways.
    Finally, the proposed automatic registration procedures for sensing and tasking
    capabilities that can satisfy different scenarios, including new devices, new
    gateways, and mobile devices. In order to demonstrate the feasibility of the proposed
    solution, we have implemented four example applications considering in situ and
    mobile devices, and their sensing and tasking capabilities. As shown in the experimental
    results, as long as the embedded devices support the proposed IoT-PNP solution,
    all the designed applications can be achieved without any human intervention.
    Overall, we believe that this research provides a valid solution to construct
    a unified SW-IoT infrastructure and could consequently achieve the SW-IoT vision.
    In terms of future work, as SW-IoT embedded devices could support different local
    wireless communication protocols, such as Bluetooth, LoRaWAN, NB-IoT, etc. we
    believe that the proposed idea can still be followed with consideration of the
    characteristics of different protocols. For example, data transmission rates of
    LoRaWAN, NB-IoT, and Sigfox may not be enough to support the transmission of description
    files presented in this paper. Possible solutions are to separate a description
    file into several pieces or to store a description file on the cloud and instruct
    gateways to retrieve the description file from the cloud. How to apply the IoT-PNP
    concept to different wireless communication protocols would be an interesting
    research topic. Finally, we will seek opportunities to apply the proposed IoT-PNP
    in real-world SW-IoT systems to further demonstrate this solution. Author Contributions
    Conceptualization, C.-Y.H.; funding acquisition, C.-Y.H.; methodology, H.-H.C.;
    project administration, C.-Y.H.; software, H.-H.C.; supervision, C.-Y.H.; validation,
    C.-Y.H. and H.-H.C.; writing—original draft, H.-H.C.; writing—review and editing,
    C.-Y.H. Funding This research was funded by the Ministry of Interior in Taiwan,
    grant number 107SU0217, and the Ministry of Science and Technology in Taiwan,
    grant number MOST 107-2119-M-008-022. Conflicts of Interest The authors declare
    no conflict of interest. Appendix A Algorithm A1. The description file of the
    indoor monitoring device. {   \"name\": \"IndoorMonitoring_device\",   \"description\":
    \"CSRSR’s sensor\",   \"properties\": {     \"UID\": \"MY_DEVICE00001\"   },   \"Locations\":
    [     {        \"name\": \"CSRSR\",        \"description\": \"CSRSR\",        \"encodingType\":
    \"application/vnd.geo+json\",        \"location\": {          \"type\": \"Point\",          \"coordinates\":
    [            24.967765,            121.187035          ]        }     }   ],   \"Datastreams\":
    [     {       \"name\": \"sensor1\",       \"description\": \"Temperature\",       \"observationType\":
    \"http://www.opengis.net/def/observationType/OGC-OM/2.0/OM_Measurement\",       \"unitOfMeasurement\":
    {         \"name\": \"degree Celsius\",         \"symbol\": \"degree Celsius\",         \"definition\":
    \"http://unitsofmeasure.org/ucum.html#para-30\"      },      \"Sensor\": {        \"name\":
    \"tempSensor\",        \"description\": \"Thermometer\",        \"encodingType\":
    \"text/html\",        \"metadata\": \"DHT22\"      },      \"ObservedProperty\":
    {        \"name\": \"air_temperature\",        \"description\": \"Temperature
    of air in situ.\",        \"definition\": \"http://mmisw.org/ont/ioos/parameter/air_temperature\"      }   },   {      \"name\":
    \"sensor2\",      \"description\": \"Humidity\",      \"observationType\": \"http://www.opengis.net/def/observationType/OGC-OM/2.0/OM_Measurement\",      \"unitOfMeasurement\":
    {        \"name\": \"Percentage\",        \"symbol\": \"%\",        \"definition\":
    \"http://unitsofmeasure.org/ucum.html#para-29\"      },      \"Sensor\": {        \"name\":
    \"humiSensor\",        \"description\": \"Hygrometer\",        \"encodingType\":
    \"text/html\",        \"metadata\": \"DHT22\"      },      \"ObservedProperty\":
    {        \"name\": \"humidity\",        \"description\": \"Humidity of air in
    situ.\",        \"definition\": \"http://mmisw.org/ont/ioos/parameter/relative_humidity\"      }    }  ]
    } Algorithm A2. The description file of the remotely-controllable LCD and LED
    device. {    \"name\": \"remotelyControlled_LCD_device\",    \"description\":
    \"CSRSR’s sensor\",    \"properties\": {      \"UID\": \"MY_DEVICE00002\"    },     \"Locations\":
    [       {          \"name\": \"CSRSR\",          \"description\": \"CSRSR\",          \"encodingType\":
    \"application/vnd.geo+json\",          \"location\": {            \"type\": \"Point\",            \"coordinates\":
    [              24.967765,              121.187035          ]        }      }    ],    \"TaskingCapabilities\":
    [      {        \"name\": \"LightBulb\",        \"description\": \"\",        \"parameters\":
    [          {            \"parameterID\": \"on\",            \"description\": \"turn
    on or off\",            \"use\": \"Mandatory\",            \"definition\": {              \"inputType\":
    \"Boolean\",              \"unitOfMeasurement\": \"Status\",              \"allowedValues\":
    [                {                  \"value\": true,                  \"description\":
    \"turn on\"                },                {                  \"value\": false,                  \"description\":
    \"turn off\"                }              ]            }          }        ],        \"zigbeeProtocol\":
    {          \"extendedAddressHigh\": \"0013A200\",          \"extendedAddressLow\":
    \"40BF8550\",          \"messageDataType\": \"application/text\",          \"messageBody\":
    \"MY_DEVICE00002:LightBulb:{on}\"        },        \"Actuator\": {          \"name\":
    \"LED\",          \"description\": \"a controllable LED.\",          \"encodingType\":
    \"application/text\",          \"metadata\": \"LED\"        }      },      {        \"name\":
    \"LCD\",        \"description\": \"A LCD monitor that can display text messages.\",        \"parameters\":
    [          {            \"parameterID\": \"msg\",            \"description\":
    \"text\",            \"use\": \"Mandatory\",            \"definition\": {              \"inputType\":
    \"String\",              \"unitOfMeasurement\": \"Status\",              \"allowedValues\":
    [                {                  \"description\": \"String\"                }              ]            }          }       ],       \"zigbeeProtocol\":
    {         \"extendedAddressHigh\": \"0013A200\",         \"extendedAddressLow\":
    \"40BF8550\",         \"messageDataType\": \"application/text\",         \"messageBody\":
    \"MY_DEVICE00002:LCD:{msg}\"       },       \"Actuator\": {         \"name\":
    \"Paralax LCD monitor\",         \"description\": \"a controllable LCD monitor
    which can print text.\",         \"encodingType\": \"application/text\",         \"metadata\":
    \"Parallax 2*16 Serial LCD\"       }     }   ] } Algorithm A3. The description
    file of the mobile luminosity-monitoring device. {    \"name\": \"mobileLuminosityMonitoring_device\",    \"description\":
    \"CSRSR’s sensor\",    \"properties\": {      \"UID\": \"MY_DEVICE00003\"    },    \"Locations\":
    [      {        \"name\": \"CSRSR\",        \"description\": \"CSRSR\",        \"encodingType\":
    \"application/vnd.geo+json\",        \"location\": {          \"type\": \"Point\",          \"coordinates\":
    [            24.967757,            121.187112          ]        }      }    ],    \"Datastreams\":
    [      {        \"name\": \"sensor1\",        \"description\": \"Luminosity\",        \"observationType\":         \"http://www.opengis.net/def/observationType/OGC-OM/2.0/OM_Measurement\",        \"unitOfMeasurement\":
    {          \"name\": \"Lux\",          \"symbol\": \"lux\",          \"definition\":
    \"http://unitsofmeasure.org/ucum.html#para-30\"        },        \"Sensor\": {          \"name\":
    \"TSL2561\",          \"description\": \"Luminosity_Sensor\",          \"encodingType\":
    \"text/html\",          \"metadata\": \"TSL2561\"        },        \"ObservedProperty\":
    {          \"name\": \"Luminosity\",          \"definition\":   \"https://ci.mines-stetienne.fr/seas/ZoneLightingOntology-1.0#luminosity\",          \"description\":
    \"Luminosity.\"        }      }   ] } Algorithm A4. The description file of the
    remotely-controllable buzzer device.  {    \"name\": \"remotelyControlledBuzzer_device\",    \"description\":
    \"CSRSR’s sensor\",    \"properties\": {      \"UID\": \"MY_DEVICE00004\"    },    \"Locations\":
    [      {        \"name\": \"CSRSR\",        \"description\": \"CSRSR\",        \"encodingType\":
    \"application/vnd.geo+json\",        \"location\": {          \"type\": \"Point\",          \"coordinates\":
    [            24.967757,            121.187112          ]        }      }    ],    \"TaskingCapabilities\":
    [      {        \"name\": \"buzzer\",        \"description\": \"\",        \"parameters\":
    [          {            \"parameterID\": \"buzz_time\",            \"description\":
    \"ring buzzer several times\",            \"use\": \"Mandatory\",            \"definition\":
    {              \"inputType\": \"Integer\",              \"unitOfMeasurement\":
    \"times\",              \"allowedValues\": [                {                  \"Max\":
    10,                  \"Min\": 1                }              ]            }          }        ],        \"zigbeeProtocol\":
    {          \"addressingSH\": \"0013A200\",          \"addressingSL\": \"40BF8550\",          \"messageDataType\":
    \"application/text\",          \"messageBody\": \"MY_DEVICE00024:buzzer:{buzz_time}\"        },        \"Actuator\":
    {          \"name\": \"MH-FMD buzzer module\",          \"description\": \"a controllable
    buzzer.\",          \"encodingType\": \"application/text\",          \"metadata\":
    \"MH-FMD\"        }      }    ]  } References Delin, K.A.; Jackson, S.P. The Sensor
    Web: A New Instrument Concept; SPIE: Bellingham, WA, USA, 2001; Volume 4282, pp.
    1–9. [Google Scholar] Botts, M.; Percivall, G.; Reed, C.; Davidson, J. OGC® sensor
    web enablement: Overview and high level architecture. In GeoSensor Networks; Springer:
    Berlin/Heidelberg, Germany, 2008; pp. 175–190. [Google Scholar] Liang, S.H.; Croitoru,
    A.; Tao, C.V. A distributed geospatial infrastructure for Sensor Web. Comput.
    Geosci. 2005, 31, 221–231. [Google Scholar] [CrossRef] Huang, C.Y.; Wu, C.H. A
    Web Service Protocol Realizing Interoperable Internet of Things Tasking Capability.
    Sensors 2016, 16, 1395. [Google Scholar] [CrossRef] [PubMed] Atzori, L.; Iera,
    A.; Morabito, G. The internet of things: A survey. Comput. Netw. 2010, 54, 2787–2805.
    [Google Scholar] [CrossRef] Bormann, C.; Castellani, A.P.; Shelby, Z. Coap: An
    application protocol for billions of tiny internet nodes. IEEE Internet Comput.
    2012, 16, 62–67. [Google Scholar] [CrossRef] Lu, G.; Krishnamachari, B.; Raghavendra,
    C.S. Performance evaluation of the IEEE 802.15.4 MAC for low-rate low-power wireless
    networks. In Proceedings of the IEEE International Conference on Performance,
    Computing, and Communications, Phoenix, AZ, USA, 15–17 April 2004; pp. 701–706.
    [Google Scholar] Jirka, S.; Bröring, A.; Stasch, C. Applying OGC Sensor Web Enablement
    to risk monitoring and disaster management. In Proceedings of the GSDI 11th World
    Conference, Rotterdam, The Netherlands, 15–19 June 2009. [Google Scholar] Chung,
    L.K.; Fang, Y.M.; Chang, Y.H.; Chou, T.Y.; Lee, B.J.; Yin, H.Y.; Baranski, B.
    A SOA based debris flow monitoring system. In Proceedings of the 17th International
    Conference on Geoinformatics, Fairfax, VA, USA, 12–14 August 2009; pp. 1–6. [Google
    Scholar] Rouached, M.; Baccar, S.; Abid, M. RESTful Sensor web enablement services
    for wireless sensor networks. In Proceedings of the 2012 IEEE Eighth World Congress
    on Services (SERVICES), Honolulu, HI, USA, 24–29 June 2012; pp. 65–72. [Google
    Scholar] Schade, S.; Díaz, L.; Ostermann, F.; Spinsanti, L.; Luraschi, G.; Cox,
    S.; De Longueville, B. Citizen-based sensing of crisis events: Sensor web enablement
    for volunteered geographic information. Appl. Geomat. 2013, 5, 3–18. [Google Scholar]
    [CrossRef] Bröring, A.; Stasch, C.; Echterhoff, J. OGC® Sensor Observation Service
    Interface Standard Implementation Specification 12-006: Version2.0.0; Open Geospatial
    Consortium: Wayland, MA, USA, 2012. [Google Scholar] Simonis, I.; Echterhoff,
    J. OGC® Sensor Planning Service Implementation Standard 09-000: Version2.0.0;
    Open Geospatial Consortium: Wayland, MA, USA, 2011. [Google Scholar] Liang, S.;
    Huang, C.Y.; Khalafbeigi, T. OGC® SensorThings API Part 1: Sensing 15-078r6 Version
    1.0.0; Open Geospatial Consortium: Wayland, MA, USA, 2016. [Google Scholar] Cox,
    S. OGC® Observations and Measurements-XML Implementation 10-025r1: Version 2.0.0;
    Open Geospatial Consortium: Wayland, MA, USA, 2011. [Google Scholar] Botts, M.;
    Robin, A. OpenGIS Sensor Model Language (SensorML) Implementation Specification
    07-000 Version 1.0.0; Open Geospatial Consortium: Wayland, MA, USA, 2007. [Google
    Scholar] Pizzot, M.; Handl, R.; Zurmuehl, M. Information Technology Open Data
    Protocol (OData) v4.0 Part 1: Core, OAISI Open Data Protocol (OData) TC. Available
    online: https://www.oasis-open.org/standards#odatav4.0 (accessed on 24 January
    2019). O’Reilly, T. OGC® Puck Protocol Standard 09-127r2 Version 1.4; Open Geospatial
    Consortium: Wayland, MA, USA, 2010. [Google Scholar] Broering, A.; Below, S.;
    Foerster, T. Declarative sensor interface descriptors for the sensor web. In Proceedings
    of the WebMGS, 1st International Workshop on Pervasive Web Mapping, Geoprocessing
    and Services, Como, Italy, 26–27 August 2010. [Google Scholar] Guinard, D.; Trifa,
    V.; Pham, T.; Liechti, O. Towards physical mashups in the Web of Things. In Proceedings
    of the Sixth International Conference on Networked Sensing Systems (INSS), Pittsburgh,
    PA, USA, 17–19 June 2009; pp. 1–4. [Google Scholar] Jaffey, T.; Davies, J.; Beart,
    P. Hypercat 3.00 Specification. Available online: http://www.hypercat.io/uploads/1/2/4/4/12443814/hypercat_specification_3.00rc1-2016-02-23.pdf
    (accessed on 24 January 2017). Soldatos, J.; Kefalakis, N.; Hauswirth, M.; Serrano,
    M.; Calbimonte, J.P.; Riahi, M.; Skorin-Kapov, L. Openiot: Open source internet-of-things
    in the cloud. In Proceedings of the Interoperability and Open-Source Solutions
    for the Internet of Things: International Workshop, FP7 OpenIoT Project, Split,
    Croatia, 18 September 2014; pp. 13–25. [Google Scholar] Calbimonte, J.P.; Sarni,
    S.; Eberle, J.; Aberer, K. XGSN: An Open-source Semantic Sensing Middleware for
    the Web of Things. In Proceedings of the 7th International Workshop on Semantic
    Sensor Networks, Riva del Garda, Italy, 19 October 2014; TC/SSN@ ISWC. pp. 51–66.
    [Google Scholar] oneM2M-TS-0001, oneM2M Functional Architecture Specification
    v2.10.0. August 2016. Available online: http://www.onem2m.org/ (accessed on 24
    January 2019). Martínez, E.; Toma, D.M.; Jirka, S.; del Río, J. Middleware for
    Plug and Play Integration of Heterogeneous Sensor Resources into the Sensor Web.
    Sensors 2017, 17, 2923. [Google Scholar] [CrossRef] [PubMed] Miller, B.A.; Nixon,
    T.; Tai, C.; Wood, M.D. Home networking with universal plug and play. IEEE Commun.
    Mag. 2001, 39, 104–109. [Google Scholar] [CrossRef] ZigBee, A. Zigbee-2006 Specification.
    Available online: http://www.zigbee.org/ (accessed on 24 January 2019). Howitt,
    I.; Gutierrez, J.A. IEEE 802.15. 4 low rate-wireless personal area network coexistence
    issues. In Proceedings of the 2003 IEEE Wireless Communications and Networking,
    New Orleans, LA, USA, 16–20 March 2003; pp. 1481–1486. [Google Scholar]    © 2019
    by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
    article distributed under the terms and conditions of the Creative Commons Attribution
    (CC BY) license (http://creativecommons.org/licenses/by/4.0/). Share and Cite
    MDPI and ACS Style Huang, C.-Y.; Chen, H.-H. An Automatic Embedded Device Registration
    Procedure Based on the OGC SensorThings API. Sensors 2019, 19, 495. https://doi.org/10.3390/s19030495
    AMA Style Huang C-Y, Chen H-H. An Automatic Embedded Device Registration Procedure
    Based on the OGC SensorThings API. Sensors. 2019; 19(3):495. https://doi.org/10.3390/s19030495
    Chicago/Turabian Style Huang, Chih-Yuan, and Hsin-Hsien Chen. 2019. \"An Automatic
    Embedded Device Registration Procedure Based on the OGC SensorThings API\" Sensors
    19, no. 3: 495. https://doi.org/10.3390/s19030495 Note that from the first issue
    of 2016, this journal uses article numbers instead of page numbers. See further
    details here. Article Metrics Citations Crossref   3 Scopus   3 Web of Science   2
    Google Scholar   [click to view] Article Access Statistics Article access statistics
    Article Views 29. Dec 8. Jan 18. Jan 28. Jan 7. Feb 17. Feb 27. Feb 8. Mar 18.
    Mar 0k 1k 2k 3k 4k For more information on the journal statistics, click here.
    Multiple requests from the same IP address are counted as one view.   Sensors,
    EISSN 1424-8220, Published by MDPI RSS Content Alert Further Information Article
    Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs at MDPI
    Guidelines For Authors For Reviewers For Editors For Librarians For Publishers
    For Societies For Conference Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org
    Scilit SciProfiles Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook
    Twitter Subscribe to receive issue release notifications and newsletters from
    MDPI journals Select options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless
    otherwise stated Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: Huang and Chen (2019)
  journal: Sensors (Switzerland)
  limitations: null
  relevance_score: 0.9
  relevance_score1: 0
  relevance_score2: 0
  title: An automatic embedded device registration procedure based on the ogc sensorthings
    api
  verbatim_quote1: '“The proposed IoT-PNP contains three main components: (1) A description
    file describing device metadata and capabilities, (2) a communication protocol
    between the gateway layer and the device layer for establishing connections, and
    (3) an automatic registration procedure for both sensing and tasking capabilities.”'
  verbatim_quote2: “Overall, we believe the proposed solution could help achieve an
    open and interoperable SW-IoT end-to-end architecture based on the OGC SensorThings
    API.”
  verbatim_quote3: '>'
- analysis: 'The paper "A miniature data repository on a Raspberry Pi" presents the
    design and implementation of a software tool called Airchive that runs on a Raspberry
    Pi to create a data repository for archiving and sharing timeseries data. The
    authors evaluate the system''s autonomy and robustness under power and network
    disruptions, as well as its performance against concurrent client requests in
    a realistic indoor air pollution data acquisition scenario.


    Regarding the point of different data types (e.g., soil moisture, canopy temperature,
    weather) and their collection and use, the paper provides an example of how Airchive
    can be used to collect and store data from an air quality sensor. The authors
    mention that Airchive uses a relational database to store data and that it can
    be configured to work with different types of sensors. However, the paper does
    not provide a detailed discussion of how Airchive handles different data types
    or how it can be used to collect and store data from sensors that measure soil
    moisture or canopy temperature.


    Despite this, the paper is still relevant to the point as it demonstrates the
    feasibility of using a Raspberry Pi as a data repository for timeseries data.
    The paper also provides valuable information on the design and implementation
    of Airchive, which can be useful for researchers and practitioners interested
    in developing their own data repositories.


    Here are the three most relevant verbatim quotes from the paper:


    "We designed and implemented a software tool called Airchive to run on a Raspberry
    Pi, in order to assemble a data repository for archiving and openly sharing timeseries
    data."


    "Airchive employs a relational database for storing data and implements two standards
    for sharing data (namely the Sensor Observation Service by the Open Geospatial
    Consortium and the Protocol for Metadata Harvesting by the Open Archives Initiative)."


    "The system is demonstrated in a realistic indoor air pollution data acquisition
    scenario in a four-month experiment evaluating its autonomy and robustness under
    power and network disruptions. A stress test was also conducted to evaluate its
    performance against concurrent client requests."'
  authors:
  - Samourkasidis A.
  - Athanasiadis I.N.
  citation_count: '6'
  description: This work demonstrates a low-cost, miniature data repository proof-of-concept.
    Such a system needs to be resilient to power and network failures, and expose
    adequate processing power for persistent, long-term storage. Additional services
    are required for interoperable data sharing and visualization. We designed and
    implemented a software tool called Airchive to run on a Raspberry Pi, in order
    to assemble a data repository for archiving and openly sharing timeseries data.
    Airchive employs a relational database for storing data and implements two standards
    for sharing data (namely the Sensor Observation Service by the Open Geospatial
    Consortium and the Protocol for Metadata Harvesting by the Open Archives Initiative).
    The system is demonstrated in a realistic indoor air pollution data acquisition
    scenario in a four-month experiment evaluating its autonomy and robustness under
    power and network disruptions. A stress test was also conducted to evaluate its
    performance against concurrent client requests.
  doi: 10.3390/electronics6010001
  full_citation: Samourkasidis, A.; Athanasiadis, I.N. A Miniature Data Repository
    on a Raspberry Pi. Electronics 2017, 6, 1. https://doi.org/10.3390/electronics6010001
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                 Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Electronics All Article Types Advanced   Journals
    Electronics Volume 6 Issue 1 10.3390/electronics6010001 Submit to this Journal
    Review for this Journal Propose a Special Issue Article Menu Academic Editors
    Steven J. Johnston Simon J. Cox Subscribe SciFeed Recommended Articles Related
    Info Link More by Authors Links Article Views 7958 Citations 6 Table of Contents
    Abstract Introduction Related Work The Airchive System Implementation Demonstration
    Discussion Conclusions Supplementary Materials Acknowledgments Author Contributions
    Conflicts of Interest References Altmetric share Share announcement Help format_quote
    Cite question_answer Discuss in SciProfiles thumb_up Endorse textsms Comment first_page
    settings Order Article Reprints Open AccessArticle A Miniature Data Repository
    on a Raspberry Pi by Argyrios Samourkasidis and Ioannis N. Athanasiadis * Information
    Technology Group, Wageningen University, Hollandseweg 1, Wageningen 6706 KN, The
    Netherlands * Author to whom correspondence should be addressed. Electronics 2017,
    6(1), 1; https://doi.org/10.3390/electronics6010001 Submission received: 22 September
    2016 / Revised: 14 December 2016 / Accepted: 15 December 2016 / Published: 28
    December 2016 (This article belongs to the Special Issue Raspberry Pi Technology)
    Download keyboard_arrow_down      Browse Figures Versions Notes Abstract This
    work demonstrates a low-cost, miniature data repository proof-of-concept. Such
    a system needs to be resilient to power and network failures, and expose adequate
    processing power for persistent, long-term storage. Additional services are required
    for interoperable data sharing and visualization. We designed and implemented
    a software tool called Airchive to run on a Raspberry Pi, in order to assemble
    a data repository for archiving and openly sharing timeseries data. Airchive employs
    a relational database for storing data and implements two standards for sharing
    data (namely the Sensor Observation Service by the Open Geospatial Consortium
    and the Protocol for Metadata Harvesting by the Open Archives Initiative). The
    system is demonstrated in a realistic indoor air pollution data acquisition scenario
    in a four-month experiment evaluating its autonomy and robustness under power
    and network disruptions. A stress test was also conducted to evaluate its performance
    against concurrent client requests. Keywords: Raspberry Pi; data repository; interoperability;
    data archive; data sharing; Sensor Observation Service; Protocol for Metadata
    Harvesting; indoor air pollution; data acquisition; persistent storage; low cost
    hardware; Internet of Things 1. Introduction Raspberry Pi has emerged as a key
    component in research, education and amateur cyber-physical systems. Raspberry
    Pi is a low-cost, mini-computer featuring processing, networking and video decoding
    capabilities [1]. It has no permanent storage; the user may instead attach an
    SD card. It also exposes General Purpose Input–Output pins (GPIO) to connect with
    low-level peripheral devices through Hardware Attached on Top (HAT). Popular HATs
    include LEDs, motor controllers, sensors, and GPS devices [2]. Raspberry Pi has
    been developed primarily with the intention to encourage computer education in
    schools and the developing world, with the open philosophy in mind, as both the
    hardware design and operating system are open-licensed. Raspberry Pi has been
    demonstrated in a variety of applications beyond an educational context, including
    home-automation systems [3], fire alarm systems [4], home-security [5,6], health
    supply chains monitoring [7], smart city applications [8,9,10] and environmental
    monitoring systems [11]. Tanenbaum et al. [12] viewed Raspberry Pi and similar
    technologies as enablers for democratizing technology and enabling creativity.
    Despite the diversity of Raspberry Pi applications, little research has been done
    to investigate Raspberry Pi as a performing data repository. The low acquisition
    cost, the open hardware and software philosophy, and its capacity for interfacing
    with a variety of peripherals, renders Raspberry Pi a very good candidate for
    boosting open data, crowd-sourcing and citizen science movements. For instance,
    Raspberry Pi was employed to create a citizen observatory for water and flood
    management [13]. Muller et al. [14] discuss its potential use for crowdsourcing
    applications in climate and atmospheric sciences. In this work, we present a proof-of-concept
    that Raspberry Pi can be used as a miniature, low-cost data repository that offers
    persistent data storage, and interoperable data sharing services over the Internet.
    We demonstrate Airchive, a system that stores and serves timeseries data recorded
    by a HAT equipped with air quality sensors, and investigate the system’s robustness
    against power and network shortages. We also conducted a stress test in order
    to identify system limitations. The rest of the paper is structured as follows:
    in Section 2, we study the feasibility of the approach, by reviewing related work.
    Section 3 presents the overall system architecture, along with user types, system
    requirements, and key functionality. Section 4 presents the software platform
    developed and hardware utilized. Section 5 details our experiments with the system
    and presents the lessons learned, documenting difficulties and incidents arisen
    during the experiment period. Finally, Section 6 provides a discussion and lays
    the groundwork for future work. Section 7 provides a conclusion of the research.
    2. Related Work In principle, a data repository needs to offer persistent data
    storage, along with added-value services, as those for data processing, dissemination
    and visualization. Such services are similar to those offered by a Wireless Sensor
    Network (WSN) [15], an area where Raspberry Pi has been thoroughly investigated
    as a gateway node (or base station). A gateway node is the intermediate among
    sensor nodes and external networks. Its functionalities are regarded with (a)
    coordination (e.g., configuration of sensor nodes); (b) data storage; (c) data
    processing and (d) data dissemination to external clients [16]. Most prominent
    advances in the usage of Raspberry Pi in WSNs have been done in the domains of
    (a), (c), and advanced data visualization. Raspberry Pi has been used as a coordinator
    in a ZigBee mesh network interfacing with the World Wide Web. In [17], a Raspberry
    Pi performs as a gateway node and processes observations derived from the sensor
    nodes, stores them on a local database and provides visualization services to
    external users. Data processing on the Raspberry Pi to offline calibrate sensor
    readings and provide data visualization is presented in [18]. Specifically, a
    Round Robin Database [19] was used for fast storage of sensor data with a constant
    disk footprint. This was done by keeping only the recent measurements in high
    resolution and statistical summaries for older recordings. Advanced data visualization
    and image capturing is demonstrated in a volcanic monitoring system based on a
    Raspberry Pi [20]. The Raspberry Pi creates and communicates graphs through commercial
    messenger applications—for example Whatsapp—while data are transferred daily to
    an external system for archival. From the works above, it becomes clear that a
    Raspberry Pi may serve as a node that offers data storage, processing and visualization
    services, while still remaining a coordinating device interfacing sensors with
    the Internet. In most cases, data are forwarded to a remote, resourceful node
    in order to be archived in the long term. In this work, we aim to demonstrate
    that a Raspberry Pi can become an active archiver of its own sensor recordings,
    and investigate whether it is powerful enough to provide data storage and dissemination
    services on site. 3. The Airchive System 3.1. Objectives Airchive [21] is a software
    product intended for being deployed on a Raspberry Pi to turn it into a self-contained
    data repository. Airchive provides data capture and dissemination services for
    timeseries measurements. There are two objectives in developing this system. The
    first is to investigate long-term storage potential on a Raspberry Pi. The challenge
    here is inherited by the Raspberry Pi hardware limitations. Airchive provides
    with a persistent storage mechanism that is able to safe-keep its data in a trustworthy
    manner. We experimented this feature further, considering storage on both SD cards
    and USB disks attached with the Raspberry Pi. The second is to demonstrate Raspberry
    Pi capacity to interoperate at the machine level through standard protocols for
    data sharing. Airchive adopts two mainstream standards to exhibit interoperability
    at the machine level. The first is the Sensor Observation Service (SOS), the Open
    Geospatial Consortium (OGC) standard tailored for sharing sensor observations
    [22]. SOS defines a Web service interface which allows querying observations and
    metadata of heterogeneous sensor systems. The second is the Protocol for Metadata
    Harvesting (OAI/PMH), an Open Archives Initiative low-barrier mechanism for repository
    interoperability [23]. OAI/PMH is a generic protocol for sharing metadata among
    archives and has been widely adopted by digital libraries. Both SOS and OAI/PMH
    offer services that are invoked over the HTTP protocol. 3.2. Requirements Airchive
    operates as a self-contained, autonomous repository for timeseries data archival
    and dissemination. It is a technical system that involves both software and hardware
    components, and needs to comply with certain non-functional requirements. From
    a software perspective, Airchive needs to be built with open-source tools and
    frameworks and be extensible, in order to respect the philosophy of the Raspberry
    Pi movement and maximize the potential for future uptake. Hardware support Airchive
    should be low-cost and resilient to power and network shortages. This will allow
    its use in remote locations, or in the developing world. The overall Airchive
    system should require low-technical skills to install, operate and maintain. We
    identified three use cases for the Airchive system. (a) Web users access the system
    through the Internet via a public webpage. They explore current or historical
    Airchive data, and they are interested in graphical representations of the content.
    Typically, a Web user is able to query for the data stored in Airchive, and the
    system will respond with a graph of the data requested. They may also download
    data in common formats, such as JSON (JavaScript Object Notation), CSV (Comma-separated
    values), GeoJSON [24] and GeoRSS [25]. (b) Software agents interact with Airchive
    for retrieving data or harvesting metadata. They may use different protocols and
    vocabularies to submit their requests. One may follow the SOS protocol for retrieving
    raw timeseries data, while another could use the OAI/PMH to get meta-information
    of the digital resources stored. Software agents interact with the system with
    RESTful Web services (Representational state transfer services) [26] over the
    HTTP protocol. (c) The system owner has full access both locally and from the
    Internet via Secure Shell (SSH). Her responsibilities are to administer the system
    by updating system software or restarting the device. Interoperability is an essential
    requirement of such a system. Airchive offers query services for software agents
    via SOS and OAI/PMH standards. SOS queries return responses in Extensible Markup
    Language (XML) using OGC vocabularies (as Observation & Measurements (O&M) [27],
    or Sensor Model Language (SensorML) [28]). OAI/PMH responses may be encoded in
    more than one metadata profile, including Dublin Core, a generic purpose metadata
    schema for annotating digital artifacts [29]. By incorporating a variety of service
    offerings, we demonstrate the capabilities of a Raspberry Pi to operate with several
    clients, using different protocols and vocabularies, and support for syntactic
    interoperability. Software development is based on our previous work reported
    in [30]. We further improved the software system to host generic timeseries data.
    The current version has been thoroughly tested and is available as an open source
    software package [21]. In this version, all of the metadata that are disseminated
    through OAI/PMH are calculated on-the-fly (instead of being stored permanently).
    This is a design choice to demonstrate the powerful processing power of Raspberry
    Pi. Airchive can operate autonomously and with minimal user interventions. In
    the experiments discussed below, Airchive has been operating unattended for four
    months in order to evaluate its capabilities for long-term operation, as reliability,
    self-recovery and resilience to power and network failures. 3.3. Abstract Architectural
    Design Airchive software platform was designed for the Raspberry Pi to turn it
    into a self-contained station for timeseries data archival and dissemination.
    It serves both real-time access and long-term storage and retrieval of sensor
    data, while also offering services for metadata harvesting. Airchive follows the
    Sensing as a Service paradigm [31] and is composed of five components that are
    implemented as loosely-coupled services, rendering the software highly extensible.
    The abstract architectural design is depicted in Figure 1. Figure 1. Airchive
    abstract architecture. System services are shown as layered components on the
    left, with relevant technologies. On the right, corresponding Raspberry Pi features
    are illustrated. The data capture component (optional) comes first that actually
    collects sensed measurements from one or more sensor devices connected to the
    Raspberry Pi. This component is custom to hardware and/or sensors used. Our implementation
    interfaces with the sensors of the AirPi HAT. Nevertheless, the general behavior
    remains the same: at certain time intervals, it acquires the results from the
    sensors. A data validation component (optional) may sit between data capture and
    data storage components. Its role is to apply quality assurance/quality control
    process and identify hardware or sensor errors. Additionally, it could associate
    the measurement with a quality flag by applying rules or more empirical procedures
    (i.e., statistical, data driven) [32,33,34,35]. Such a component is essential
    for ensuring data reliability and user confidence. The data storage component
    permanently stores sensor data in a relational database along with a time stamp.
    In order to be database-independent, an Object Relational Mapping (ORM) framework
    was utilized. The data storage component is also responsible for retrieving the
    data from permanent storage. The data processing component is an intermediate
    layer between data storage and Web services. It transforms arguments (submitted
    by users/harvesters with their queries) into appropriate database queries, using
    the ORM framework. It also works in the other way around, as it formats database
    outputs according to user requests, using different formats (i.e., XML, JSON,
    CSV) or dictionaries (i.e., O&M, SensorML, Dublin Core). Finally, it offers descriptive
    statistics calculations on-the-fly (e.g., maximum, minimum, rolling mean, average
    and percentiles). Last, but not least, the Web services components offer outlets
    for interaction with users and agents over the Internet. There are four Web service
    components in the current system, but more could be added in the future: Web users
    browse the repository and submit queries using a Graphical User Interface (GUI).
    Software agents interact with the SOS server, the OAI/PMH endpoint, or the Airchive’s
    own Application Programming Interface (API). 4. Implementation 4.1. Hardware Airchive
    was deployed on a Raspberry Pi Model B. This model is equipped with a 700 MHz
    ARM processor, weights 45 g and has 512 MB of RAM. It is connected to the Internet
    through an Ethernet controller and features two USB ports. Instead of a hard disk,
    it uses an SD card. It is also equipped with 26 GPIO pins (General Purpose Input–Output)
    for interfacing with various peripherals (HATs). The chosen Operation System was
    Raspbian; a Linux based distribution for Raspberry Pi. In order to generate data
    (i.e., actual observations) to be stored on the Airchive, we have chosen to use
    AirPi, a Raspberry Pi sensory HAT. AirPi is an interface board that connects over
    GPIO pins and is equipped with low cost air quality and weather sensors. It also
    follows the open hardware philosophy, and can be further extended with other sensors,
    including a GPS module [36]. It costs roughly 90 USD including the sensors shown
    in Table 1. AirPi includes a software module that is able to log sensed data on
    the cloud. Table 1. AirPi sensors with their respected observed properties. The
    overall system hardware is comprised of a Raspberry Pi Model B equipped with the
    AirPi HAT, an SD card and a USB memory drive, and it was connected to Internet
    with an ethernet cable, shown in Figure 2. Figure 2. Raspberry Pi Model B with
    AirPi attached on top. 4.2. Software Development Airchive software has been developed
    in Python, and is available as open-source software on github [21] under the GNU
    Affero General Public License Version 3 [37]. The data capture component interfaces
    with the AirPi libraries [38] that transform electrical signals into human-understandable
    values. Data storage employs SQlite [39], an open-source, lightweight relational
    database for Python and SQLAlchemy library [40] for object-relational mapping.
    An outline of the data validation component is provided, but not fully implemented,
    as it is out of the core scope. The data processing component was developed in
    three modules. The Query module handles client-requested queries and raises appropriate
    exceptions. Requests must include the sensor, the property and the corresponding
    timeframe for which the observations will be retrieved. A typical workflow is
    as depicted in Figure 3. The Filter module comprises of a set of statistical filters
    implemented as Python classes using pandas library [41]. Filters may be instantiated
    and applied on-the-fly on a query result. The Format module is responsible for
    serializing the query results. Jinja2 template engine [42] was used and the formats
    implemented correspond to the Web services offered. They include XML, GeoRSS,
    GeoJSON, JSON and CSV formats. Figure 3. A typical data processing workflow. The
    Web service components were developed using the Flask web framework [43], in order
    to provide clients with static and dynamic content. Flask web framework deploys
    a web server which responds to HTTP GET requests with formatted data. Data requests
    can be submitted through the three API endpoints that we developed: the Airchive
    own API, SOS and OAI/PMH. A fourth outlet is the Airchive GUI, which is meant
    for the Web users to render graphs upon request. It uses the Airchive API for
    getting data, which are subsequently visualized on the client’s web browser using
    Javascript. Graph rendering is facilitated by FLOT [44] and JQuery [45]. Visualizing
    data occurs on the client browser, which also economizes resources of the Raspberry
    Pi. Airchive software is generic in nature, in the sense that is does not require
    the data capture and validation components, and one could deploy it only with
    historical data. The system is configured via a file that aligns the timeseries
    with their semantics, including measured properties and units. The configuration
    allows for alternative definitions of the same observed properties, which enables
    the system to serve the same observations with a variety of vocabularies. Currently,
    we use the definitions of the Semantic Web for Earth and Environmental Terminology
    (SWEET) [46]. 5. Demonstration 5.1. Experimental Design We deployed the Airchive
    system in a realistic scenario for indoor air quality monitoring. Airchive software
    was installed on a Raspberry Pi equipped with AirPi HAT, and installed indoors,
    connected to a power supply and the Internet via Ethernet port. We performed two
    experiments in order to evaluate the system autonomy and robustness, and its performance
    under load pressure. 5.2. Experiment 1: Autonomy and Robustness In the first experiment,
    which lasted for more than 120 days, Airchive was exposed to irregular power and
    network disruptions. We did not interfere in system restoration during the “down”
    incidents and let the system self-recover. In this experiment, a moderate sampling
    frequency to data capture component was set, in order to investigate the system’s
    long-term storage capabilities. A measurement was retrieved from each sensor every
    5 min. During this experiment, 183,850 measurements were gradually collected and
    served. In Table 2, there is a summary of the 24 network outage events observed
    during this period. Outage events were logged with UptimeRobot [47], a service
    that monitors web applications and notifies interested parties when an application
    is not accessible via the Internet. UptimeRobot was used only to log network failures,
    and did not interfere with our system. Table 2. Statistics of the 24 the outage
    events, collected using UptimeRobot.com services. During the first experiment,
    different users were submitting data queries to the system, in an ad-hoc manner,
    using the various interfaces: graph visualizations were requested by Web users,
    raw observations by SOS clients and derived metadata by OAI/PMH harvesters. We
    did not observe any malfunction for any of the client operations. Current and
    historical data were monitored, stored and disseminated appropriately, while the
    automated recovery worked as expected. OAI featured records were calculated on-the-fly,
    upon harvester requests in a timely fashion. We did not observe any notable delays
    in the capacity of the system to serve its clients. 5.3. Experiment 2: Stress
    Testing During the second experiment, we conducted a stress test, in order to
    provide more insights regarding the system limitations. We investigated the number
    of concurrent user requests, after which the Airchive system delayed to respond.
    The sampling frequency was increased to 5 s. The experiment lasted for three days,
    and it collected and served more than 259,000 measurements. We utilized Locust
    [48], an open source load testing tool written in Python. In Locust, a variable
    number of clients are deployed to submit concurrent requests to a service. Each
    Locust client submits a new request only when it receives a response to its previous
    request. Locust takes as input the following parameters: (a) the number of concurrent
    clients; (b) the total number of requests; and (c) a url pointing to the requested
    resource. We set up three tests. In all cases, clients submitted a hundred requests
    altogether. The three tests involved the following requests over the Internet,
    via HTTP GET. In the first test, clients request only the Airchive frontpage,
    which is a static HTML document. No transactions to the database were involved
    and the response size is constant (8740 bytes). Test 1 verifies that Airchive
    operates properly and examines if pressure on the Web services/dissemination components
    has an impact on the data capture component. In the second test, clients request
    a set of 20 observations using Airchive’s API, and the response is formatted as
    a JSON document. This request requires an SQL query to be submitted to the database,
    and the response size is 538 bytes. Test 2 corresponds to the use case of a Web
    user that asks for a graph, as Airchive transmits the JSON document and the graph
    is rendered on the client-side. In the third test, clients ask for the same set
    of observations as in Test 2, but this time over the SOS protocol, which returns
    an XML document. This request requires exactly the same SQL query to be submitted
    to the database but needs additional formatting for rendering the result in XML.
    The response size is 16,504 bytes. Test 3 corresponds to the use case of an SOS
    client asking data from Airchive. We simulated four scenarios, in each of which
    we deployed a different number of concurrent clients. We tried one, five, 10 and
    25 concurrent clients. This is a realistic assumption as the current system is
    not intended for large-scale deployment. We repeated the process five times for
    each test and scenario combination and reported two metrics in Table 3: (a) the
    average response time (ART) in milliseconds; and (b) the number of requests served
    per second (RPS). Table 3. Experimental results for the three tests and for different
    numbers of concurrent clients. Average response time (ART) across a hundred requests
    for each document are reported in milliseconds. System throughput is expressed
    in requests per second (RPS). Average response time (ART) is a proxy of the average
    delay to an external user request. For example, a user would have to wait 49.5
    s (on average) plus the response time of their submitted request, under the scenario
    of the 25 concurrent clients for Test 3. As indicated by the results in Table
    3, average response time is linearly correlated with the product of (a) number
    of concurrent users; and (b) average response time achieved when one client submits
    requests. We verify that requests per second (RPS) depend on the type of the requested
    document, and is rather stable regardless of the number of concurrent clients.
    The introduced overhead to the system response times depends on the request and
    format type. Requests involving dynamic content are roughly 30 times slower than
    requests of static content. In the case of dynamic content requests, JSON-formatted
    responses are served 16% faster than the equivalent in XML. Interpreting the results,
    we derive the number of concurrent (human) Web users that the system may serve.
    Assuming that a human user should not wait more than 6 s, we conclude that Airchive
    can serve simultaneously up to two Web users of the SOS/XML Web service (Test
    3), or three Web users of the API/JSON Web service (Test 2). In the case of static
    content (Test 1), Airchive is able to serve up to 82 clients simultaneously. The
    numbers above do not represent Airchive’s maximum capabilities, rather its capacity
    for serving content to Web users. In contrast, software agents interacting with
    such a system are usually not bound to any time limitation. We conducted further
    experiments to determine the threshold after which the system started failing
    to respond to requests. We increased the total number of requests to 500. We started
    increasing the number of concurrent users by multiples of 5, until requests started
    to fail. Airchive can serve simultaneously, without failure up to 254 (Test 1),
    141 (Test 2) and 138 clients (Test 3). In excess of the client numbers above,
    the system continued to respond with more than one failure. The results are summarized
    in Table 4. These tests demonstrate Airchive’s capacity to work reliably with
    a significant number of clients. Table 4. Estimates on the number of clients that
    Airchive can serve simultaneously. We underline that despite the heavy workload
    we introduced during the stress tests, AirPi continued to operate normally. In
    all cases, we verified with the database content that observations were recorded
    every 5 s without any loss in all the experiments above (i.e., the data dissemination
    does not interfere with data capture). 5.4. Incidents and Lessons Learned During
    experiment 1, network failures occurred quite often. Those failures, impeded only
    Web connectivity and apart from the web server, the rest of the Airchive components
    continued to operate properly. We verified that no data loss occurred by cross-checking
    the time down intervals logged with UptimeRobot with the actual observations stored
    in the database. We observed that the system was able to handle power failures,
    and it self-restored without human intervention. For all 24 outage events during
    experiment 1, Airchive recovered properly by making the Web service available
    as soon as the Internet connection returned. In this respect, the system demonstrated
    its persistence and credibility as a repository. Calculating derived data (metadata)
    on-the-fly provided us with evidence regarding the system’s extensibility and
    enhanced capabilities. Derived metadata, which were disseminated through OAI/PMH,
    were calculated upon client request. We observed that data were transmitted as
    fast as if they had been stored in the system. In addition, utilizing a Javascript
    framework for rendering graphs upon user request added no extra performance overhead
    to the Raspberry Pi. We did extensively evaluate these features with stress tests
    in experiment 2, and our experience was that the system performed as expected.
    During experiment setup, we stumbled upon a recurring security incident. Given
    that Raspberry Pi was constantly connected to the Internet, it attracted malicious
    users after its first boot. We experienced a brute force attack to the SSH protocol
    that was trying to get unauthorized access to the device. We toughened up Airchive
    with a dedicated security software solution (fail2ban [49]), which prevented any
    further security incidents of that kind. Another lesson learned had to do with
    a potential issue that may arise when power and networks fail at the same time.
    Raspberry Pi lacks a Real-Time built-in Clock (RTC), and it synchronizes its system
    clock through the Internet. In the case that an Internet connection is not available
    upon system boot, the Raspberry Pi system time is misconfigured. In the general
    use case of Airchive, this will not be a problem, but, in our experiments, this
    will result in errors in the data capture component, which will assign incorrect
    timestamps to data sensed from the HAT. This problem can be overcome so that the
    data capture component retrospectively reviews these timestamps when the Internet
    becomes available. An RTC HAT can be purchased and applied to Raspberry Pi. However,
    this option increases the total cost. Last but not least, during the setup phase,
    we experimented with booting Raspbian and running Airchive from the USB disk instead
    of the SD card. First of all, this is a task that requires advanced technical
    skills and is still an experimental option not endorsed by the Raspberry Pi makers,
    and performance is not guaranteed. USB disks provide a cheaper storage option
    but are prone to failure. We experimented with this option for one month, during
    which the filesystem was corrupted twice, requiring the operating system and Airchive
    to be re-installed. Observed data were not permanently lost, but their retrieval
    required technical skills. In contrast, no such incidents occurred when the system
    operated on an SD card for a much longer period. 6. Discussion Data persistence
    is a prerequisite for a data repository. In most efforts made with a Raspberry
    Pi and reported in the literature in the WSN context, data were periodically backed
    up in an external device and were not permanently stored on the embedded device.
    In the work presented here, Airchive relied solely on Raspberry Pi for permanent
    data storage. Our four-month experiments demonstrated that a Raspberry Pi equipped
    with an SD card can handle moderate and extensive read/write cycles without any
    issue; the resilience of SD cards is constantly evolving [50]. The processing
    capabilities of Raspberry Pi have been investigated in the light of several applications.
    In Airchive, we studied its capacity to calculate and disseminate added-value
    data and indexes on-the-fly, i.e., upon user request. This way, less data are
    permanently stored and less write cycles are performed, which puts less pressure
    on SD card life. Self-restoration from failures is another attribute of WSNs [16],
    which is also applicable in our work. Self-restoration contributes towards diminishing
    the technical skills that Airchive system owner should possess. During the experiments,
    the system self-restored from all power and network shortages that have been triggered,
    demonstrating that after its installation, the system can operate autonomously
    and without assistance. We also consider that the Airchive system presented here
    also indirectly contributes to the open data movement, especially for the developing
    world. Besides the low acquisition cost and the low-technical skills required
    for its deployment, the system by-design responds to the “weak enabling environment”
    of the developing countries, i.e., intermittent, opportunistic Internet connection.
    In the frame of this work, we did not demonstrate the system in such conditions.
    However, we demonstrated that is able to attend to network and power failures.
    Security and privacy are also two important attributes of a data repository system,
    and lay the foundation for future work. The brute force attack incident that occurred
    during the experiments is an illustration of the potential dangers. In addition,
    given that a data repository system may host personal and/or confidential data,
    more research should be focused on addressing privacy issues. There is a lack
    of any authentication mechanism, even in well-established, data dissemination
    protocols, such as OGC/SOS and OAI/PMH. An authentication mechanism can ensure
    privacy, and such issues should be addressed in the light of interoperable data
    dissemination on the application layer. 7. Conclusions To summarize, we provided
    a proof-of-concept that current low-cost hardware is reliable enough to boost
    the open data movement. We demonstrated that a Raspberry Pi accompanied with an
    appropriate software can support persistent data storage, and provide added-value
    services on site. We designed and implemented an open-source, highly-extensible
    data repository software, called Airchive, to support data visualization, and
    interoperable data dissemination. We adopted two well-established data dissemination
    protocols: OGC Sensor Observation Service and Open Archive Initiative/Protocol
    Metadata Harvesting. Finally, we demonstrated its long-term data storage capabilities
    and resilience under harsh conditions of power and/or network failures, which
    take place irregularly. The load testing experiments provided us with insights
    about the Raspberry Pi performance under simultaneous requests from concurrent
    external clients. Supplementary Materials Airchive software is available on github:
    https://www.github.com/ecologismico/airchive. Airchive uptime statistics are available
    on Zenodo: http://doi.org/10.5281/zenodo.167318. Airchive stress test results
    are available on Zenodo: http://doi.org/10.5281/zenodo.167319. The locust configuration
    used for the Airchive stress test is available on Zenodo: http://doi.org/10.5281/zenodo.167326.
    Acknowledgments Icons in Figure 1 are licensed by Creative Commons CC/BY via the
    Noun Project, the ethernet port by Michael Wohlwen, the CPU by iconsmind.com,
    the SD Card by Lemon Liu, improvement by Tomas Knopp, and process, by CBi icons.
    Author Contributions A.S. and I.N.A. conceived and designed the system; A.S. developed
    the software and performed the experiments; A.S. and I.N.A. analyzed the data;
    A.S. and I.N.A. wrote the paper. Conflicts of Interest The authors declare no
    conflict of interest. References Upton, E.; Halfacree, G. Raspberry Pi User Guide;
    John Wiley & Sons: Hoboken, NJ, USA, 2014. [Google Scholar] Nuttall, B. Top 10
    Raspberry Pi Add-on Boards. 2016. Available online: https://opensource.com/life/16/7/top-10-Raspberry-Pi-boards
    (accessed on 12 December 2016). Vujović, V.; Maksimović, M. Raspberry Pi as a
    Sensor Web node for home automation. Comput. Electr. Eng. 2015, 44, 153–171. [Google
    Scholar] [CrossRef] Bahrudin, B.; Saifudaullah, M.; Abu Kassim, R.; Buniyamin,
    N. Development of Fire Alarm System using Raspberry Pi and Arduino Uno. In Proceedings
    of the International Conference on Electrical, Electronics and System Engineering
    (ICEESE), Kuala Lumpur, Malaysia, 4–5 December 2013; pp. 43–48. Sapes, J.; Solsona,
    F. FingerScanner: Embedding a Fingerprint Scanner in a Raspberry Pi. Sensors 2016,
    16, 220. [Google Scholar] [CrossRef] [PubMed] Chowdhury, M.N.; Nooman, M.S.; Sarker,
    S. Access Control of Door and Home Security by Raspberry Pi Through Internet.
    Int. J. Sci. Eng. Res. 2013, 4, 550–558. [Google Scholar] Schön, A.; Streit-Juotsa,
    L.; Schumann-Bölsche, D. Raspberry Pi and Sensor Networking for African Health
    Supply Chains. In Proceedings of the 6th International Conference on Operations
    and Supply Chain Management, Bali, Indonesia, 10–12 December 2014. Jung, M.; Weidinger,
    J.; Kastner, W.; Olivieri, A. Building automation and smart cities: An integration
    approach based on a service-oriented architecture. In Proceedings of the 27th
    International Conference on Advanced Information Networking and Applications Workshops
    (WAINA), Barcelona, Spain, 25–28 March 2013; pp. 1361–1367. Leccese, F.; Cagnetti,
    M.; Trinca, D. A Smart City Application: A Fully Controlled Street Lighting Isle
    Based on Raspberry-Pi Card, a ZigBee Sensor Network and WiMAX. Sensors 2014, 14,
    24408–24424. [Google Scholar] [CrossRef] [PubMed] Cagnetti, M.; Leccese, F.; Trinca,
    D. A New Remote and Automated Control System for the Vineyard Hail Protection
    Based on ZigBee Sensors, Raspberry-Pi Electronic Card and WiMAX. J. Agric. Sci.
    Technol. B 2013, 3, 853. [Google Scholar] Nikhade, S.G. Wireless sensor network
    system using Raspberry Pi and ZigBee for environmental monitoring applications.
    In Proceedings of the International Conference on Smart Technologies and Management
    for Computing, Communication, Controls, Energy and Materials (ICSTM), Chennai,
    India, 6–8 May 2015; pp. 376–381. Tanenbaum, J.; Williams, A.; Desjardins, A.;
    Tanenbaum, K. Democratizing technology: Pleasure, utility and expressiveness in
    DIY and maker practice. In Proceedings of the SIGCHI Conf Human Factors in Computing
    Systems, Paris, France, 27 April–2 May 2013; pp. 2603–2612. Lanfranchi, V.; Ireson,
    N.; When, U.; Wrigley, S.; Fabio, C. Citizens’ observatories for situation awareness
    in flooding. In Proceedings of the 11th International Conference on Information
    Systems for Crisis Response and Management (ISCRAM), Pennsylvania State University,
    University Park, PA, USA, 17 May 2014; pp. 145–154. Muller, C.; Chapman, L.; Johnston,
    S.; Kidd, C.; Illingworth, S.; Foody, G.; Overeem, A.; Leigh, R. Crowdsourcing
    for climate and atmospheric sciences: Current status and future potential. Int.
    J. Climatol. 2015, 35, 3185–3203. [Google Scholar] [CrossRef] Chang, F.C.; Huang,
    H.C. A survey on intelligent sensor network and its application. J. Netw. Intell.
    2016, 1, 1–15. [Google Scholar] Dargie, W.; Poellabauer, C. Fundamentals of Wireless
    Sensor Networks: Theory and Practice; John Wiley & Sons: Hoboken, NJ, USA, 2010.
    [Google Scholar] Ferdoush, S.; Li, X. Wireless sensor network system design using
    Raspberry Pi and Arduino for environmental monitoring applications. Procedia Comput.
    Sci. 2014, 34, 103–110. [Google Scholar] [CrossRef] Lewis, A.; Campbell, M.; Stavroulakis,
    P. Performance evaluation of a cheap, open source, digital environmental monitor
    based on the Raspberry Pi. Measurement 2016, 87, 228–235. [Google Scholar] [CrossRef]
    Oetiker, T. RRDtool. 2014. Available online: http://oss.oetiker.ch/rrdtool/ (accessed
    on 12 December 2016). Moure, D.; Torres, P.; Casas, B.; Toma, D.; Blanco, M.J.;
    Del Río, J.; Manuel, A. Use of Low-Cost Acquisition Systems with an Embedded Linux
    Device for Volcanic Monitoring. Sensors 2015, 15, 20436–20462. [Google Scholar]
    [CrossRef] [PubMed] [Green Version] Samourkasidis, A.; Athanasiadis, I.N. Airchive
    Software. 2016. Available online: https://github.com/ecologismico/airchive (accessed
    on 12 December 2016). Open Geospatial Consortium. OGC Sensor Observation Service
    2.0; Implementation Standard 12-006; Open Geospatial Consortium: Wayland, MA,
    USA, 2012. [Google Scholar] Lagoze, C.; Van de Sompel, H. The Open Archives Initiative:
    Building a low-barrier interoperability framework. In Proceedings of the 1st ACM/IEEE-CS
    Joint Conference on Digital Libraries, Roanoke, VA, USA, 24–28 June 2001; ACM:
    New York, NY, USA, 2001; pp. 54–62. [Google Scholar] Butler, H.; Daly, M.; Doyle,
    A.; Gillies, S.; Hagen, S.; Schaub, T. The GeoJSON Format; RFC 7946; The Internet
    Engineering Task Force: 2016. Available online: http://www.rfc-editor.org/info/rfc7946
    (accessed on 12 December 2016). GeoRSS: Geographically Encoded Objects for RSS
    Feeds. 2014. Available online: http://www.georss.org (accessed on 12 December
    2016). Richardson, L.; Ruby, S. RESTful Web Services; O’Reilly Media, Inc.: Sebastopol,
    CA, USA, 2008. [Google Scholar] Open Geospatial Consortium. Observations and Measurements—XML
    Implementation; Implementation Standard 10-025r1; Open Geospatial Consortium:
    Wayland, MA, USA, 2011. [Google Scholar] Open Geospatial Consortium. OGC SensorML:
    Model and XML; Encoding Standard 12-000; Open Geospatial Consortium: Wayland,
    MA, USA, 2014. [Google Scholar] Dublin Core Metadata Initiative (DCMI) Metadata
    Terms. Available online: http://dublincore.org/documents/dcmi-terms/ (accessed
    on 12 December 2016). Samourkasidis, A.; Athanasiadis, I.N. Towards a low-cost,
    full-service air quality data archival system. In Proceedings of the 7th International
    Congress on Environmental Modelling and Software, International Environmental
    Modelling and Software Society (iEMSs), San Diego, CA, USA, 15–19 June 2014. Perera,
    C.; Zaslavsky, A.; Christen, P.; Georgakopoulos, D. Sensing as a service model
    for smart cities supported by Internet of Things. Trans. Emerg. Telecommun. Technol.
    2014, 25, 81–93. [Google Scholar] [CrossRef] Athanasiadis, I.N.; Mitkas, P.A.
    Knowledge discovery for operational decision support in air quality management.
    J. Environ. Inform. 2007, 9, 100–107. [Google Scholar] [CrossRef] Athanasiadis,
    I.N.; Milis, M.; Mitkas, P.A.; Michaelides, S.C. A multi-agent system for meteorological
    radar data management and decision support. Environ. Model. Softw. 2009, 24, 1264–1273.
    [Google Scholar] [CrossRef] Athanasiadis, I.; Rizzoli, A.; Beard, D. Data Mining
    Methods for Quality Assurance in an Environmental Monitoring Network. In Proceedings
    of the 20th International Conference on Artificial Neural Networks (ICANN 2010),
    Thessaloniki, Greece, 15–18 September 2010; Lecture Notes in Computer Science;
    Springer: Thessaloniki, Greece, 2010; Volume 6354, pp. 451–456. [Google Scholar]
    Athanasiadis, I.N.; Mitkas, P.A. An agent-based intelligent environmental monitoring
    system. Manag. Environ. Qual. 2004, 15, 238–249. [Google Scholar] [CrossRef] Dayan,
    A.; Hartley, T. AirPi. 2013. Available online: http://airpi.es (accessed on 12
    December 2016). Free Software Foundation. GNU Affero General Public License. 2007.
    Available online: https://www.gnu.org/licenses/agpl.html (accessed on 12 December
    2016). Hartley, T. AirPi Software. 2013. Available online: https://github.com/tomhartley/AirPi
    (accessed on 12 December 2016). sqlite3—DB-API 2.0 Interface for SQLite Databases.
    2016. Available online: https://docs.python.org/2/library/sqlite3.html (accessed
    on 12 December 2016). Bayer, M. SQLAlchemy: The Python SQL Toolkit and Object
    Relational Mapper. 2016. Available online: http://www.sqlalchemy.org (accessed
    on 12 December 2016). McKinney, W. pandas: A Foundational Python Library for Data
    Analysis and Statistics. In Proceedings of the Workshop Python for High Performance
    and Scientific Computing (SC11), Seattle, WA, USA, 18 November 2011. Ronacher,
    A. Jinja2. 2008. Available online: http://jinja.pocoo.org (accessed on 12 December
    2016). Ronacher, A. Flask. 2010. Available online: http://flask.pocoo.org (accessed
    on 12 December 2016). Laursen, O.; Schnur, D. Flot: Attractive JavaScript Plotting
    for jQuery. 2007. Available online: http://www.flotcharts.org (accessed on 12
    December 2016). jQuery. 2016. Available online: https://jquery.com (accessed on
    12 December 2016). Raskin, R.G.; Pan, M.J. Knowledge representation in the semantic
    web for Earth and environmental terminology (SWEET). Comput. Geosci. 2005, 31,
    1119–1125. [Google Scholar] [CrossRef] UptimeRobot. 2016. Available online: https://uptimerobot.com
    (accessed on 12 December 2016). Heyman, J.; Hamrén, J.; Byström, C.; Heyman, H.
    Locust: An Open Source Load Testing Tool. 2011. Available online: http://locust.io
    (accessed on 12 December 2016). Sumsal, F.; Brester, S.G.; Szépe, V.; Halchenko,
    Y. Fail2ban. 2005. Available online: http://www.fail2ban.org/ (accessed on 12
    December 2016). SD Association. 2016. Available online: https://www.sdcard.org
    (accessed on 12 December 2016). © 2016 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license ( http://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Samourkasidis, A.; Athanasiadis, I.N. A Miniature
    Data Repository on a Raspberry Pi. Electronics 2017, 6, 1. https://doi.org/10.3390/electronics6010001
    AMA Style Samourkasidis A, Athanasiadis IN. A Miniature Data Repository on a Raspberry
    Pi. Electronics. 2017; 6(1):1. https://doi.org/10.3390/electronics6010001 Chicago/Turabian
    Style Samourkasidis, Argyrios, and Ioannis N. Athanasiadis. 2017. \"A Miniature
    Data Repository on a Raspberry Pi\" Electronics 6, no. 1: 1. https://doi.org/10.3390/electronics6010001
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Scopus   6
    Crossref   4 Web of Science   6 Google Scholar   [click to view] Article Access
    Statistics Article access statistics Article Views 29. Dec 8. Jan 18. Jan 28.
    Jan 7. Feb 17. Feb 27. Feb 8. Mar 18. Mar 0k 10k 2.5k 5k 7.5k For more information
    on the journal statistics, click here. Multiple requests from the same IP address
    are counted as one view.     Electronics, EISSN 2079-9292, Published by MDPI RSS
    Content Alert Further Information Article Processing Charges Pay an Invoice Open
    Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For
    Editors For Librarians For Publishers For Societies For Conference Organizers
    MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia
    JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive
    issue release notifications and newsletters from MDPI journals Select options
    Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer
    Terms and Conditions Privacy Policy"'
  inline_citation: null
  journal: Electronics (Switzerland)
  limitations: The paper does not provide a detailed discussion of how Airchive handles
    different data types or how it can be used to collect and store data from sensors
    that measure soil moisture or canopy temperature.
  relevance_score: 0.8
  relevance_score1: 0
  relevance_score2: 0
  title: A miniature data repository on a raspberry pi
  verbatim_quote1: '"We designed and implemented a software tool called Airchive to
    run on a Raspberry Pi, in order to assemble a data repository for archiving and
    openly sharing timeseries data."'
  verbatim_quote2: '"Airchive employs a relational database for storing data and implements
    two standards for sharing data (namely the Sensor Observation Service by the Open
    Geospatial Consortium and the Protocol for Metadata Harvesting by the Open Archives
    Initiative)."'
  verbatim_quote3: '>'
- analysis: The paper introduces an integrated data storage model based on RDF and
    arrays, the extension of SPARQL to incorporate array query semantics, and the
    integration of this solution with rasdaman, a specialized array storage system.
    It demonstrates the applicability of the proposed approach to representing and
    querying spatio-temporal gridded coverages, which are common in geospatial applications.
    The paper shows how WCPS requests can be formulated as SciSPARQL queries, combining
    the strengths of both approaches for efficient and flexible data processing.
  authors:
  - Andrejev A.
  - Misev D.
  - Baumann P.
  - Risch T.
  citation_count: '15'
  description: Multidimensional array data, such as remote-sensing imagery and timeseries,
    climate model simulations, telescope observations, and medical images, contribute
    massively to virtually all science and engineering domains, and hence play a key
    role in 'Big Data' challenges. Pure array storage management and analytics is
    relatively well understood today. However, arrays in practice never come alone,
    but are accompanied by metadata, including domain, range, provenance information,
    etc. The structure of this metadata is far less regular than arrays or tables,
    and may be incomplete or different from one array instance to another. Particularly
    in the field of the Semantic Web such integrated representations must convey a
    sufficiently complete and reasonable semantics for machine-machine communication.
    We show how the Resource Description Framework (RDF), the Semantic Web graph model
    for metadata, can be leveraged for such data/metadata integration specifically
    for representing spatio-temporal grid data. Based on the notion of a coverage
    as established by the Open Geospatial Consortium (OGC) we present a hybrid data
    store where efficiently represented arrays are incorporated as nodes into RDF
    graphs and connected to their metadata. We have extended the Semantic Web query
    language SPARQL to incorporate array query semantics and other functionality making
    it suitable for processing of large numeric arrays, including geo coverages.
  doi: 10.1109/DSDIS.2015.109
  full_citation: 'Andrej Andrejev, Dimitar Misev, Peter Baumann and Tore Risch. Spatio-Temporal
    Gridded Data Processing on the Semantic Web. 2015 IEEE International Conference
    on Data Science and Data Intensive Systems, Sydney, NSW, 2015, pp. 153-160, doi:
    10.1109/DSDIS.2015.109.'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2015 IEEE International Confe... Spatio-Temporal
    Gridded Data Processing on the Semantic Web Publisher: IEEE Cite This PDF Andrej
    Andrejev; Dimitar Misev; Peter Baumann; Tore Risch All Authors 12 Cites in Papers
    193 Full Text Views Abstract Document Sections I. Introduction II. Related Work
    III. Scientific SPARQL Overview IV. Grid Coverages in RDF V. Conclusion Authors
    Figures References Citations Keywords Metrics Footnotes Abstract: Multidimensional
    array data, such as remote-sensing imagery and timeseries, climate model simulations,
    telescope observations, and medical images, contribute massively to virtually
    all science and engineering domains, and hence play a key role in ''Big Data''
    challenges. Pure array storage management and analytics is relatively well understood
    today. However, arrays in practice never come alone, but are accompanied by metadata,
    including domain, range, provenance information, etc. The structure of this metadata
    is far less regular than arrays or tables, and may be incomplete or different
    from one array instance to another. Particularly in the field of the Semantic
    Web such integrated representations must convey a sufficiently complete and reasonable
    semantics for machine-machine communication. We show how the Resource Description
    Framework (RDF), the Semantic Web graph model for metadata, can be leveraged for
    such data/metadata integration specifically for representing spatio-temporal grid
    data. Based on the notion of a coverage as established by the Open Geospatial
    Consortium (OGC) we present a hybrid data store where efficiently represented
    arrays are incorporated as nodes into RDF graphs and connected to their metadata.
    We have extended the Semantic Web query language SPARQL to incorporate array query
    semantics and other functionality making it suitable for processing of large numeric
    arrays, including geo coverages. Published in: 2015 IEEE International Conference
    on Data Science and Data Intensive Systems Date of Conference: 11-13 December
    2015 Date Added to IEEE Xplore: 04 February 2016 Electronic ISBN:978-1-5090-0214-6
    DOI: 10.1109/DSDIS.2015.109 Publisher: IEEE Conference Location: Sydney, NSW,
    Australia SECTION I. Introduction Massive multi-dimensional arrays play a central
    role in science, engineering, and beyond. Consequently, a significant number of
    approaches for storage and retrieval on arrays have been proposed, both by scientific
    communities (such as [32], [1]) and in databases, where efforts have led to the
    new class of array database systems (such as [16], [10], [11], [36], [34], [18])
    with impact on standardization [12] [28]. In practice, though, arrays typically
    are forming part of some larger data structure. Metadata support in this context
    has been largely ignored, leading to a widely acknowledged impedance mismatch
    that is generally detrimental to the development of modern web-enabled, flexible
    and scalable scientific applications [20]. Let us look at a representative example.
    The notion of a coverage in geoinformatics describes a digital representation
    of some space-time-varying phenomenon, in practice: regular and irregular grids,
    point clouds, and meshes [24], [13]. Grid coverages consist of an array ornamented
    with metadata essentially describing the location of each grid point in space-time.
    Technically, coverages as per the respective OGC standard [13] additionally can
    hold any kind of domain and use case specific information. Earth Science communities
    have established their own metadata standards, such as EO-Metadata [19], and recently
    web service protocols [14], [12], which tentatively focus on allowing any kind
    of application specific metadata to be associated with the data. Any conceptual
    modeling of a coverage, therefore, must be able to integrate arrays into the common
    framework. In particular in the realm of the Semantic Web and machine-to-machine
    communication it is indispensable to represent the full semantics in a coherent
    manner. On metadata level this is well under way - there is a strong trend towards
    metadata annotation of resources on the web within the Semantic Web paradigm;
    obviously, standardized, commonly understood metadata facilitate data integration
    and building federated datasets, thus making scientific data more accessible to
    the users. The relevant common vocabularies and ontologies include RDFS [21],
    VoiD[6], SKOS [3], RDF Data Cube [2]. As of today, coverage data are not yet accessible
    within the RDF framework, mainly due to lack of efficient representations and
    operations on arrays. To remedy this, an effort towards integration of coverages
    (and, hence, arrays) into RDF has started in the World-Wide Web Consortium (W3C)
    as part of the initiative on describing spatial image data (generally: gridded
    coverages) through RDF [4]. No results are available yet, and actually this W3C
    standardization work where we are engaged has motivated this research. We propose
    the Semantic Web Ontology capturing all aspects of the metadata essential for
    understanding and querying Grid Coverages, while staying open and flexible enough
    for extensions with additional application-specific metadata. Arrays are incorporated
    as nodes into the RDF graph, and connected to all their metadata. We suggest using
    hybrid data stores, efficiently handling array data and RDF. Mediator technology
    accomplishes dispatching of sub-queries to dedicated database engines, while achieving
    an integrated logical representation. We encourage the users to combine array
    data and metadata within single queries, which brings the following benefits:
    Queries are more transparent and self-contained than array-only queries; there
    is no need to explicitly encode metadata values in queries, since the metadata
    can be retrieved from the same database. Metadata is used for both result selection
    and postprocessing on the server, reducing the communication costs and improving
    scalability in contrast to client-based postprocessing. Clients can conveniently
    get answers to complex problems with just a single round trip, rather than through
    iterative communication with several servers employing different models and retrieval
    paradigms. The query optimizer has more freedom in building better access plans,
    when both metadata and data can be combined in the same query. In our previous
    work [9], [7] we extended the Semantic Web query language, SPARQL, to incorporate
    array query semantics, together with additional functionality (second-order functions,
    closures, user-defined functions, storage extensibility) making it suitable for
    processing large numeric arrays, including grid coverages - this language we call
    SciSPARQL. Our implementation of SciSPARQL is capable of answering metadata-rich
    array queries in addition to the traditional array retrieval and processing requests.
    By modeling grid coverages as introduced above we show how to translate processing
    requests on grid coverages to equivalent SciSPARQL queries based on the formal
    Grid Coverage Ontology, thus opening raster geospatial data to the Semantic Web
    users. The query semantics is based on the OGC Web Coverage Processing Service
    (WCPS) standard [12], a geo query language grounding on the OGC coverage model.
    Our current work couples SciSPARQL with the rasdaman array database, where array-relevant
    SciSPARQL subqueries are pushed down into rasdaman to benefit from the array query
    optimization and parallelization available in rasdaman. For this purpose, we have
    further extended SciSPARQL with 2nd-order array functions ARRAY (), MAP (), CONDENSE
    (), as described in Section 3, which offer great flexibility to the user and correspond
    to rasdaman array processing primitives. In the next section we give an overview
    of work related to our effort presented here. Section III presents SciSPARQL,
    with an integration with rasdaman as a backend array database system. Section
    IV presents our RDF ontology on Grid Coverages, along with examples of representative
    queries. Finally Section V concludes the paper. SECTION II. Related Work Arrays
    play a core role in science, engineering, and beyond. Traditionally, file formats
    (such as netCDF [32]) have been established and subsequently been enhanced with
    processing interfaces, such as OPenDAP [1]. These are constrained in their functionality
    and lack joins between datasets, etc. Conversely, tools like R offer advanced
    array processing, but do not scale well beyond main memory sizes. Our approach
    combines expressiveness of an array query model and language with proven scalability
    [16]. In databases, arrays have found attention only gradually. Mapping arrays
    to BLOBs looses all semantics, and consequently adequate query semantics cannot
    be provided; additionally’ this linearization destroys spatial proximity on disk.
    An initiative is under way, though, to extend the ISO SQL standard with arrays
    [28]. Array databases have been pioneered with rasdaman [10] and Array Algebra
    [11]. Declarative array primitives are embedded in expression languages which
    are optimizable and parallelizable. Today there is a number of array database
    systems in different stages of development, such as SciQL [36], SciDB [34], and
    Ophidia [18]. GeoSPARQL [29] is OGC''s effort to add support for representing
    and querying geospatial data on the Semantic Web. Since GeoSPARQL is based on
    the Simple Feature Access ISO 19125 standard [25], [23], geospatial data in this
    case actually refers to vector data, rather than gridded, raster data. Modeling
    of raster data in RDF is explored in [35], although focusing on the representation
    of feature objects extracted from the data and their relationships. With our approach,
    gridded structure of the data is preserved in order to be queried. Integration
    of arrays into overall models varies. While “pure” array databases like SciDB
    do not emphasize integration, others address such aspects, currently mainly for
    SQL [36] [28]. An integration of arrays into RDF has started in W3C as part of
    the effort to describe spatial image data (generally: gridded coverages) through
    RDF [4]. No results are available yet, and this is where the work in this paper
    comes in. xWCPS [27] is a query language integrating WCPS [12] and XQuery [17].
    As such it aims to achieve similar goals, but with XML as the model for semi-structured
    metadata associated with scientific data. The Resource Description Framework (RDF)
    [26] graph data model was designed for expressing metadata about all kinds of
    resources on the web, including databases, raster images, etc. When it comes to
    storing multidimensional numeric data, pure RDF suggests two main approaches:
    nested collections and RDF Data Cube vocabulary [2], the latter being a Semantic
    Web adaptation of SDMX (Statistical Data and Metadata eXchange) [5], designed
    to exchange OLAP cubes. Both of these approaches create a number of graph nodes
    for each numerical element to store. Apart from inefficiency arising from this
    ‘too general’ graph-based storage and processing of arrays, this representation
    also fails to give important guarantees about the data structure, and the SPARQL
    queries lack the clarity of the array access. Our RDF with Arrays data model addresses
    all these issues, and SciSPARQL query language incorporates the array query semantics.
    Array-based storage of RDF collections and RDF Data Cubes is supported with our
    system, providing backwards-compatibility with original RDF representations. SECTION
    III. Scientific SPARQL Overview In this work we show that our data model, RDF
    with Arrays, is well-suited for representing spatio-temporal gridded coverages,
    together with any metadata, including those currently used in WCSIWCPS requests.
    We model arrays as value nodes in RDF graph, and each array has associated element
    type and shape (i.e. sizes in each dimension). The Language SciSPARQL [8], [9]
    is an extended version of the W3C query language SPARQL 1.1 [22]. SciSPARQL extends
    SPARQL with syntax and semantics for selecting and processing numeric array data
    along with the metadata represented in RDF terms. The extensions (prior to this
    work) include: Syntax for array dereference, slicing, and range selection (optionally
    with astride). The syntax is borrowed from MATLAB, array subscripts are l-based,
    and ranges are specified as lo.stride.hi (for each dimension independently), with
    hi value always in range1. Binding of free query variables to the sets of available
    array subscripts, for example an expression?A [7] would bind (otherwise unbound)?
    j variable to all column indices in? A matrix. Functions to transform the arrays,
    permuting the array dimensions (generalized N-dimensional transposition), obtaining
    array shape and element type; Library of array aggregate functions (operating
    across array elements), and SPARQL 1.1 standard bag-oriented aggregate functions
    like SUM, AVG, MIN, MAX, redefined to handle bags of arrays as well; Extensibility
    with algorithms expressed in conventional algorithmic languages, like Python,
    Java, or C. It is possible to define both regular and aggregate functions, thus
    making use of any existing computational libraries; functional views, which are
    user-defined functions expressed in terms of SELECT queries. This allows for building
    up libraries of SciSPARQL subqueries defining standard computation formulas or
    common data retrieval tasks for further use. second-order functions, like ARGMIN
    and ARGMAX, taking functional closures as arguments. A closure is a function call
    with some of parameters specified and some free, marked by *. For example, an
    expression ARGMAX (f (*, 5)) would return the value for the first argument of
    function f() , where it reaches its maximum, while the second argument is fixed
    to 5. Certainly, the set of allowed values for the free argument to f() should
    be finite, which is typically the case with functional views, for example: During
    query processing the functional views and certain second-order functional expressions
    are expanded similarly to SQL views, in order to give the query optimizer greater
    freedom for finding the optimal order of execution. As a query language, SciSPARQL
    is declarative, optimizable, and terse. This means that most kinds of conditions
    and constraints on the data retrieved from a database can be expressed directly
    as algebraic equations. It is the responsibility of the DBMS to come up with a
    good execution plan, taking into account storage statistics, distribution, communication
    and computation time estimates. The user-defined foreign functions can be provided
    cost and cardinality models for improved query optimization. Array Storage SciSPARQL
    is implemented with Scientific SPARQL Database Manager, which includes query processor,
    functional extensibility mechanisms, and an in-memory database, designed for efficient
    storage of RDF with Arrays. In order to provide scalability beyond the memory
    bounds, a highly flexible storage backend interface is included. This flexibility
    comes from utilizing different capabilities of storage back-ends, including selection
    of array subsets, computing aggregate functions etc. Currently supported storage
    back-ends include RDBMS (arrays are stored in binary chunks), specialized file
    formats (e.g. mat files used together with MATLAB integration in [7]), and specialized
    array stores [9]. Whenever an array is stored in a back-end system, it is represented
    by an array proxy object in the RDF graph. Array dereference, slicing and range
    selection operations are stacked by deriving one proxy object from another during
    the query execution (which is very cheap), so the array data is retrieved lazily
    - only when it is needed for computations. This helps greatly reducing disk access
    and communication overheads, compared to ‘eager’ data retrieval. Integration with
    Rasdaman and New Features The integration with the rasdaman array database [31]
    is an important step forward, since the latter system has a rich array algebra
    [10], [11] implementation, which can handle most of the array processing workload
    expressed in SciSPARQL queries. While SciSPARQL is handling query processing and
    communication with the client, an extensive set of array operations is propagated
    to rasdaman together with data retrieval requests. This should result in practically
    the same performance, as if rasdaman was addressed directly, while providing the
    full power of RDF metadata querying available with SciSPARQL. For the purpose
    of this integration, SciSPARQL was extended with three more second-order functions,
    which translate clearly into MARRAY operator calls in rasdaman: ARRAY (type, shape,
    mapper) array constructor, where mapper function or closure is called to compute
    the value of each cell, given a l-dimensional array of logical cell subscripts
    as an argument; MAP (type, mapper, v1, …, vn) array mapper, constructing a new
    array filled with results of mapperfunction or closure, applied to the respective
    elements of v1, … vn aligned arrays; CONDENSE (op, v, filter) generalized array
    aggregation, where the aggregate operation op (any SciSPARQL aggregate function)
    is applied to elements of the array v for which the filter function or closure
    returns true. The element-wise array operations, including arithmetic. +,. -,.
    *,. /,. ^ comparison. =,. >,. >=,. <,. <=, and logical. &. I are defined for operand
    types (array, array), (array, number) and (number, array) as simple yet polymorphic
    shortcuts for the respective MAP operations. For example, the expression? a. *?b
    can be also expressed as MAP (xsd: double, times(*, *),?a,?b) if both?a and?b
    are arrays, and their widest numeric type is xsd:double, or If?b is integer and?a
    is an array of integer. Both examples are using built-in function times (), an
    alias for * multiplication operator. The intergated solution utilizes the back-end
    interface of SciSPARQL Database Manager, translating query predicates to rasdaman
    API calls whenever possible, thus pushing the computations closer to the array
    storage, and retrieving smaller amounts of data from rasdaman. SECTION IV. Grid
    Coverages in RDF Multidimensional grids, both regular and irregular, come up as
    the natural representation of various space/time varying data in the geospatial
    domain, such as ID time-series, 2D remote sensing imagery, 3D x/y/t image time-series
    and x/y/z geophysical data, as well as 4D x/y/z/t atmospheric and ocean data.
    Dealing with any of these types of data requires taking into account more than
    just the array data itself. The location information of the array contents is
    needed to properly relate such values to physical positions in the world. Frequently,
    elevation/depth and time coordinates have to be considered as well. In geoinformatics,
    gridded data form a special case of coverages with its standards mainly maintained
    by the Open Geospatial Consortium (OGC). According to the abstract model of ISO
    19123 [24] and its OGC implementation model [13], a coverage represents some space/time
    varying phenomenon, with subtypes available for regular and irregular grids, point
    clouds, and meshes. Formally, a coverage establishes a function mapping from a
    given multidimensional domain (the set of direct positions altogether forming
    the domain set) to some value set (referred to as the range set, described by
    the coverage''s range type). We call a location in the domain set together with
    the value it is associated to a cell. For a 7-band Landsat satellite image, for
    example, the domain set is 2D with point coordinates expressed in some horizontal
    Coordinate Reference System (CRS) such as WGS84; the range type is a 7-component
    structure of unsigned integers. For image timeseries, the domain set is 3D with
    the additional third axis describing image acquisition times. The domain set is
    described in varying complexity, depending on the grid type (see Figure 1). Regular
    grids (Figure 1 left) require only an origin vector plus one single offset vector
    describing the (uniform) stepping in each direction. Irregular grids (Figure 1
    middle right), where axes are straight but at individual distances along each
    axis, require a list of offset vectors per axis indicating the grid distances
    at each direct position. Warped grids (Figure 1 right), finally, abandon any fixed
    location and allow arbitrary placement of the direct positions (as long as the
    grid topology is maintained); therefore, for each grid point its individual location
    has to be maintained, effectively requiring a second array whose values are coordinates.
    Additionally, grids can be skewed (Figure 1 middle left). Fig. 1. Grid types [30].
    Show All The OGC complements this coverage concept with the Web Coverage Service
    (WCS) standards suite [14], [12], a concrete, interoperable and modular coverage
    implementation model [13]. Our focus is on WCPS as it establishes a declarative
    coverage query language. As XML today is the most widely used metadata format
    in geo services, WCPS has been crafted compatible with XQuery syntax [12]. Based
    on a for loop over coverage objects the where and return clauses may contain coverage
    expressions. In these expressions, coverages can be created, combined, and aggregated.
    The basic constructs are the coverage constructor, which delivers a new coverage
    possibly derived from others, and the condenser (aka aggregator), which summarizes
    over a coverage by iterating over its direct positions. Shorthand operations are
    available for all usual arithmetic, exponential, trigonometric, etc. functions.
    The following example shows the flavour of the language: “From MODIS scenes M1,M2,
    M3 retrieve the pixel-wise difference between the red and nir channels, encoded
    in TIFF – but only those where nir exceeds 127 somewhere”. A. RDF Grid Coverage
    Ontology Here we establish an RDF ontology, of the OGC coverage model, that would
    allow native integration of coverages within the Semantic Web ecosystem, metadata
    modelling and coverage analytics with SciSPARQL queries. The native components
    of gridded coverages are: coverage identifier domain set describing the spatio-temporal
    region of interest, within which the coverage values are defined. One of the below
    for grid coverages: a geometric grid of equidistant points, described with integer
    dimension d , axis names (string vector of size d) and the coordinates of diagonally
    opposed corners of a rectangular region (low and high limits as integer vectors
    of size d ). a rectified grid for which there is an affine conversion between
    the grid coordinates and the coordinates of an external coordinate reference system
    (CRS). It is defined by the coordinate (in some CRS) of the grid origin (a tuple
    of size d , which can be a mixture of float, integer, or other user-defined type
    of values, depending on the CRS), and d offset vectors of size d (same type as
    the origin coordinate) that determine the grid spacing in each direction in terms
    of the CRS. a referenceable grid which explicitly specifies the coordinates of
    each position individually (as a complete list). range type, a structure description
    and technical metadata required for an appropriate (however, application independent)
    understanding of a coverage; modeled on the definition of ‘Record’ from [33].
    It is composed of one or more fields, each of which having its own: name identifier
    human readable description type definition referring with a URI to an ontology
    for example a list of allowed values, or an interval within which the range values
    must fit in a list of nil values used to denote that a value is not available
    with a URI referencing a human readable reason unit of measure specified as a
    string according to the Unified Code for Units of Measure2, or a URI referring
    to an externally defined UoM whether the field is optional whether the data is
    up datable coverage function, mapping domain locations to range attribute values,
    which can be: Grid function provides an explicit mapping rule for grid geometries,
    consisting of a start point, the index position of a point in the grid that is
    mapped to the first point in the range, a sequence rule, the method for sequential
    enumeration of the grid points, that can be one of Linear, Boustrophedonic, Cantor-diagonal,
    Spiral, Morton or Hilbert, as defined in [24], and an axis order as a list of
    axes (the incrementation order to be used on an axis of the grid, positive or
    negative). Coverage mapping rule which can be a formal (in MathML for example),
    informal as text, or a reference to an external description of the coverage function.
    Ontology One benefit of representing the metadata with RDF in general, is that
    the set of properties for each instance of each class becomes open: applications
    are free to enrich the metadata without necessarily changing the schema. So the
    schema (formally defined in RDFS format by means of classes, properties and relationships)
    remains very simple, and captures only the most common and essential features.
    (In contrast, relational schemas tend to address every tiny need of every conceived
    application, thus becoming overly complex. We will be using GridDomain and RangeType
    classes to capture all the information about the domains and ranges of a grid
    coverage. As shown on Figure 2, a GridCoverage instance would have an id and a
    references to GridDoman and RangeType instances, so that it is clear when two
    coverage instances are ‘aligned’ they share the same GridDomain, or ‘uniform’
    they share the same RangeType. Besides that, GridCoverage instances will have
    array-valued properties, defined as instances of Field class. Fig. 2. Grid coverage
    ontology. Show All The variety of domain types is captured by GridDomain subclasses.
    Any GridDomain has dimensionality, a list of axis names, low and high vectors
    containing the bounding values for each dimension. All domain types refer to a
    particular Coordinate Reference system (grid''s own coordinate axes in the simplest
    case), identified by a URI pointing to a GML document [15], and the origin vector.
    Rectified grid domains will contain an offset vector, used in a simple coordinate
    transformation. ReferenceableGridDomain instances require a geo-coordinate vector
    for every point in the grid, together represented by coordinateGrid array attribute.
    This would be a problem in any storage system that rigidly separates data from
    metadata but RDF with Arrays is designed to handle big arrays as part of RDF graph,
    and there are no restrictions on how small the “metadata” should be. A RangeType
    is simply a collection of fields, jointly specified to by GridCoverage instances.
    The coverage fields, as specified by SWE [33] standard, have textual name and
    description, URI definition, specifications of reserved NIL values, and, most
    importantly, Range. There is a number of ways to define the range of a field,
    modelled by Range subclasses. One option is to define a range as a basic RDF/XSD
    type, e.g. xsd: integer. Alternatively, one could provide an interval of values
    (IntervalRange), or a full list of possible values. Example Coverage To illustrate
    the use of our RDF Grid Coverage Ontology, we make an RDF description of a coverage
    “myCoverage”, containing 3-dimensional data along x/y/t axes, without binding
    to any particular CRS (so the example is self-contained). First, we are going
    to specify the domain, including low and high vectors: And the range, including
    the definitions of each field: We omit the definition of the similar ex:red field)
    The interval range and the allowed NIL values are specified as follows: And finally,
    comes an instance of our coverage, referring to the nir and red variables storing
    array data in a NetCDF file: This is a complete example, and a queryable RDF with
    Arrays dataset. Below, we show how SciSPARQL queries can be used instead of WCPS
    requests (which do not handle any metadata beyond what is described in this section),
    and xWCPS queries, which address an open set of metadata found in GML documents.
    B. WCPS/xWCPS Requests in SciSPARQL Slicing Get a slice from the coverage with
    id ‘myocean’, at t=25 in png format In SciSPARQL it would correspond to array
    slicing expression NDVI Derive Normalized Difference Vegetation Index NDVI on
    the fly. The NDVI is a measure of the probability of vegetation in remote sensing:
    The closer to + 1 a pixel value is, the more likely it is plants. In SciSPARQL,
    we expect the RDF graph to contain two aligned arrays storing the NIR and RED
    components as the properties: nir and: red of the node with id “mycoverage”. Where
    function NDVI is mapped to the corresponding pairs of array elements Note that
    this translation separates the standard computation involved from the data retrieval
    per se. A query can hard-code a particular data instance (identifying it by unique:
    id value in this case), while the computation function NDVI can be used in other
    queries, both for post-processing and filtering. Average Chlorophyll Concentration
    Return the average chlorophyll concentration for the whole area for a given time
    step for the ‘myocean’ coverage: This request constructs a Boolean array for the
    selected slice first, and than uses it as a mask when computing the average for
    that slice. SciSPARQL also has element-wise comparison and multiplication operations,
    so formulating an equivalent query is straightforward: The alternative expression
    of the same query is using a condenser, which would skip allocating an intermediate
    Boolean array: Here, we directly use a SciSPARQL condenser, which allows to use
    built-in AVG aggregate function: The built-in function gt () used for condenser
    condition returns true when first argument is greater than second argument, and
    false otherwise. Next example uses a similar eq() built-in function for equality.
    Histogram Computation Compute histogram for the values between 0 and 255: In SciSPARQL,
    we would use ARRAY () constructor, which maps every coordinate vector with the
    provided functional argument. The first two arguments are the array type and shape,
    the latter being specified using the literal array constructor A(). Where the
    function histogramEq () counts the number of elements in the given array?a, which
    are equal to the first component in?coords: The interesting aspect about the above
    query is the superposition of two second-order array functions: constructor over
    condenser. Search Metadata, Return Data This is a xWCPS request addressing the
    web service at http://acme.com, that has information about a number of coverages
    and their associated metadata. It returns the difference between red and near-infrared
    channels of each coverage of Austria, in which some near-infrared cell has a value
    greater than 127: If we use SciSPARQL, we would send the following query to the
    SciSPARQL endpoint with access to an RDF with Arrays graph, that contains nodes
    of type: Coverage with their: nir and: red array properties, and string: region
    properties. Notice that some is a shortcut for a condenser with OR (whereas all
    would be a shortcut for a condenser with AND) Discover Anomalies Count the exceedances
    of fractional snow cover with respect to a given threshold of 30. Figure 3 visualizes
    the result. The function imageCrsDomain () returns the low and high components
    of grid bounding box along the specified axis. In WCPS, the axis is specified
    by either grid axis name, or corresponding (by order of enumeration) CRS axis
    name, as Long and Lat in this example. In SciSPARQL, since all we need is the
    grid size defined by low and high properties of GridDomain, we simply use vector.-
    operation to get the new image size. Now the query can be expressed as an array
    constructor, creating the array according to the first two components of the coverage
    size: Where we define our function ex: snowHistogram () to count the elements
    of the given array along the third dimension, with coordinates in the first two
    dimensions specified in the argument: Fig. 3. Count the number of fractional snow
    cover exceedances over a region of interest. Show All SECTION V. Conclusion Providing
    a common and flexible framework for storage and machine-readable annotation of
    spatio-temporal grids has been in the focus of Earth Science communities'' efforts
    for a long time. This is becoming more important and challenging, as the diversity
    of the datasets and the applications increases. Obviously, one size does not fit
    all, so a model for extensible metadata is certainly needed. RDF is one such model,
    widely adopted by the Semantic Web community, in order to describe all kinds of
    resources on the web. Any instance of any RDF class can be completed with properties
    specified in any vocabulary, thus forming a graph of globally-identifiable class
    and instance nodes, which any application is free to extend. In this work we bring
    together the best from the two worlds - a mature and flexible array store, efficiently
    handling a wide class of array retrieval and processing requests; and a powerful
    query language, so that queries combining raster/grid/array data and graph-structured
    metadata can be optimized and processed entirely on the server. Useful Array Algebra
    abstractions have been defined as part of the query language, including second-order
    functions and closures. And, since our integrated solution is extensible both
    storage-wise and computation-wise, there is practically no limit to the kinds
    of functionality a user can invoke from a query. Certainly, the extensions to
    SciSPARQL, as well as the integrated storage solution, combining it with rasdaman,
    are useful well beyond the geospatial applications, as far as RDF and array processing
    are combined. With respect to spatiotemporal gridded data processing, we have
    shown that even though WCPS and SciSPARQL have slightly different array models,
    it is easy to formulate WCPS requests in terms of SciSPARQL queries. This provides
    flexibility and potential efficiency benefits to WCPS users, and opens geospatial
    data to the Semantic Web users. We designed the ontology to represent the common
    Grid Coverages data and metadata as RDF with Arrays, so that it can be extended
    with any additional metadata. As an ongoing work, we are completing and testing
    our integrated solution, and collecting more use cases from the geo-spatioal gridded
    data domain. Authors Figures References Citations Keywords Metrics Footnotes More
    Like This New Graphical Ultimate Processor for Mapping Relational Database to
    Resource Description Framework 2022 5th International Conference on Computing
    and Informatics (ICCI) Published: 2022 Mapping multiple databases to resource
    description framework with additional rules as conclusions drawer 2017 4th International
    Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE)
    Published: 2017 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: Andrejev et al. (2015)
  journal: Proceedings - 2015 IEEE International Conference on Data Science and Data
    Intensive Systems; 8th IEEE International Conference Cyber, Physical and Social
    Computing; 11th IEEE International Conference on Green Computing and Communications
    and 8th IEEE International Conference on Internet of Things, DSDIS/CPSCom/GreenCom/iThings
    2015
  limitations: While the paper focuses on integrating spatio-temporal gridded coverages,
    it does not explicitly address all specific data types mentioned in the outline
    point, such as soil moisture, canopy temperature, and weather. Additionally, the
    paper primarily focuses on the data model, query language, and integration with
    rasdaman, but does not provide a comprehensive evaluation or benchmark of the
    proposed approach against other systems or on real-world datasets.
  relevance_score: 0.7
  relevance_score1: 0
  relevance_score2: 0
  title: Spatio-Temporal Gridded Data Processing on the Semantic Web
  verbatim_quote1: Based on the notion of a coverage as established by the Open Geospatial
    Consortium (OGC) we present a hybrid data store where efficiently represented
    arrays are incorporated as nodes into RDF graphs and connected to their metadata.
  verbatim_quote2: We have extended the Semantic Web query language SPARQL to incorporate
    array query semantics and other functionality making it suitable for processing
    of large numeric arrays, including geo coverages.
  verbatim_quote3: '>'

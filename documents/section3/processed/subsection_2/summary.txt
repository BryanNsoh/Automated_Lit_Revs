<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<documents>
<review_intention>
  
the purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.
Examining automation across the entire pipeline: The review intends to systematically analyze the automation of each component of the irrigation management pipeline, from data collection and transmission to processing, analysis, decision-making, and automated action. It aims to investigate the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
Highlighting the role of interoperability and standardization: The review seeks to emphasize the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline. It aims to identify existing and emerging standards and their applicability to real-time irrigation management systems.
Identifying challenges and proposing solutions: The review intends to uncover the challenges associated with implementing real-time, automated irrigation systems, such as data quality, scalability, reliability, and security. It aims to propose solutions and best practices based on the analysis of case studies and real-world implementations.
Guiding future research and innovation: By identifying research gaps and proposing new research questions and hypotheses, the review aims to provide a roadmap for advancing the field of real-time, automated irrigation management. It seeks to encourage collaborative research efforts across disciplines to address the complex challenges of automated irrigation systems.
In summary, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.
</review_intention>

<section_intention>
DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING: Focuses on the initial stages of the automated irrigation management pipeline, covering data collection, edge and fog computing, real-time data transmission protocols and technologies, and the challenges and solutions associated with real-time data transmission.
</section_intention>

<subsection_title>
3.2. Edge Computing and Fog Computing
</subsection_title>

<subsection_point_Point 5>
Point: Highlight the need for data standardization and harmonization to facilitate seamless integration and interoperability

Papers to support point:

Paper 1:
- APA Citation: Singh, P. D., & Singh, K. D. (2023). Security and Privacy in Fog/Cloud-based IoT Systems for AI and Robotics. EAI Endorsed Transactions on AI and Robotics, 1, 10.4108/airo.3616.
  Main Objective: To investigate the security and privacy issues associated with Fog/Cloud-based IoT systems, focusing on AI and robotics applications, and to propose solutions for robust data protection.
  Study Location: Unspecified
  Data Sources: Not explicitly mentioned in the given text
  Technologies Used: Fog computing, Cloud computing, IoT, AI, Robotics
  Key Findings: Fog/Cloud-based IoT systems offer efficiency and scalability but face security and privacy challenges. Implementing robust security measures (authentication, encryption, intrusion detection), privacy-preserving techniques (anonymization, differential privacy), and following data regulations are crucial for ensuring the trustworthiness and reliability of these systems.
  Extract 1: Fog/Cloud-based IoT architectures can solve the exponential growth of IoT data.
  Extract 2: This paper addresses security and privacy issues related to Fog/Cloud-based IoT systems and AI/Robotics.
  Limitations: The study primarily centers around security and privacy aspects of Fog/Cloud-based IoT systems and does not delve deeply into the technical complexities of data standardization and harmonization.
  Relevance Evaluation: This study focuses on the security and privacy concerns in Fog/Cloud-based IoT systems, which is directly relevant to the discussion of data standardization and harmonization for seamless integration and interoperability in the section and subsection specified.
  Relevance Score: 0.8
  Inline Citation: (Singh and Singh, 2023)
  Explanation: The study aims to delve into the security and privacy concerns associated with Fog/Cloud-based Internet of Things (IoT) systems used for AI and robotics applications. It analyzes potential vulnerabilities and threats within the interconnected systems and examines innovative security mechanisms, encryption approaches, access control strategies, and privacy-preserving solutions to safeguard data, communications, and user identities.

 Full Text: >
EAI Endorsed Transactions  
on AI and Robotics 
Research Article 
1 
Security and Privacy in Fog/Cloud-based IoT Systems for 
AI and Robotics 
Prabh Deep Singh1 and Kiran Deep Singh2,* 
1 Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, India 
2 Chitkara University Institute of Engineering and Technology, Chitkara University, Rajpura, Punjab, India
Abstract 
Integration of Internet of Things (IoT) systems based on the fog or the cloud with Artificial Intelligence (AI) and Robotics 
has prepared the way for breakthrough advancements in a variety of different fields of business. However, these cross-
disciplinary technologies present significant difficulties in supporting confidentiality and safeguarding data. This article digs 
into the issues of proving robust security and protecting user privacy in IoT systems based in the fog or the cloud and used 
for AI and robotics applications. This study gives insights into the possible hazards such interconnected systems meet by 
conducting an in-depth review of existing security threats, vulnerabilities, and privacy concerns. In addition, the study 
investigates innovative security mechanisms, encryption approaches, access control strategies, and privacy-preserving 
solutions that can be used to safeguard data, communications, and user identities. The results of this study highlight the 
demand for comprehensive security and privacy solutions to support the mainstream deployment of Fog/Cloud-based 
Internet of Things systems in the field of artificial intelligence and robotics. 
Keywords: Security and privacy, Fog/Cloud Computing, Robotics, Artificial Intelligence, Internet of Things 
Received on 25 July 2023, accepted on 27 August 2023, published on 28 August 2023 
Copyright © 2023 P. D. Singh et al., licensed to EAI. This is an open access article distributed under the terms of the CC BY-NC-SA 
4.0, which permits copying, redistributing, remixing, transformation, and building upon the material in any medium so long as the 
original work is properly cited. 
doi: 10.4108/airo.3616 
1. Introduction
IoT, AI, and robotics have transformed many industries and 
aspects of human life due to rapid technological 
advancement. IoT systems connect physical devices and 
objects to the internet to collect and exchange data [1],[2]. At 
the same time, AI and Robotics allow them to intelligently 
process and analyse the data and act autonomously[3]. IoT, 
AI, and Robotics have created exciting opportunities in 
healthcare, transportation, agriculture, smart cities, and 
industrial automation. AI and robotics Fog/Cloud-based IoT 
systems face significant security and privacy issues [4]. 
Fog/Cloud computing is used in IoT architectures due to the 
rapid growth of IoT devices and data. Fog computing, which 
extends Cloud services to the network edge near the data 
source, has enabled real-time data processing, reduced 
latency, and increased bandwidth efficiency [5]. This 
paradigm shift has enabled the integration of AI and Robotics 
*Corresponding author. Email: kdkirandeep@gmail.com
into IoT systems, enabling devices to make intelligent 
decisions and perform tasks without Cloud infrastructure [6]. 
IoT, AI, and Robotics offer promising opportunities and 
complex security and privacy issues. Distributed data 
processing, 
heterogeneous 
devices, 
and 
wireless 
communication 
make 
Fog/Cloud-based 
IoT 
systems 
vulnerable to attacks [7],[8]. Unauthorized access, data 
breaches, and cyber-attacks on interconnected devices can 
cause data theft, service disruption, and even physical harm 
in critical applications[9]. 
This paper addresses security and privacy issues related to 
Fog/Cloud-based IoT systems and AI/Robotics. These 
technologies must be robustly protected from potential threats 
as they become more widespread [10], [11]. This research 
could improve the trustworthiness and reliability of 
Fog/Cloud-based IoT systems, promoting the widespread 
adoption of IoT, AI, and Robotics across various domains 
[12],[13]. 
EAI Endorsed Transactions on 
AI and Robotics
P. D. Singh and K. D. Singh
2 
2. Fog/Cloud-based IoT Architectures for
AI and Robotics
The Internet of Things (IoT) has changed how devices and 
people interact. A vast network of sensors, actuators, and 
smart devices collect and exchange data via the internet in 
IoT. The traditional Cloud computing model struggles to 
manage the massive amount of data generated by IoT 
applications as they grow in scale and complexity. As a 
complement to Cloud computing, Fog computing allows real-
time processing and analysis of IoT data [14]. 
Fog computing, or Edge computing, brings Cloud computing 
closer to data sources and IoT devices. Decentralizing 
computation, storage, and networking reduces latency and 
improves system efficiency. Unlike cloud computing, Fog 
computing processes and analyses data at the network's edge 
using edge devices, access points, and servers [15]. 
Key Fog/Cloud-based IoT Architecture Components 
Fog/Cloud-based IoT architectures depend on them. These 
devices measure temperature, humidity, light, and motion 
using sensors. The Fog and Cloud nodes process data 
collected by IoT devices. Fog nodes connect IoT devices to 
Cloud data centres [16]. Edge servers, routers, and gateways 
are placed near IoT devices or critical network points. Fog 
nodes aggregate and preprocess IoT device data, reducing 
latency and network congestion. Local data analysis allows 
real-time decision-making without the Cloud The advantages 
of developing robotics with the integration of Fog/Cloud with 
IoT are shown in Figure 1. 
Cloud data centres store and process massive amounts of IoT 
data from multiple Fog nodes and devices. Cloud data centres 
have 
powerful 
computing, 
storage, 
and 
processing 
capabilities. They perform intensive data analytics, machine 
learning algorithms, and data storage that may not be feasible 
or efficient at the Fog layer [17]. 
3. Cloud/Fog IoT Architecture Workflow
Typical Fog/Cloud-based IoT architecture workflow: 
Sensor-equipped IoT devices gather environmental data. The 
application can generate data in real-time or periodically.  
3.1 Local Fog Layer Preprocessing 
 Nearby Fog nodes preprocess and analyse the collected data. 
Fog nodes filter, aggregate, and process data, removing 
irrelevant or unimportant data. Local processing reduces 
Cloud data transmission, saving network bandwidth. 
3.2 Data Transmission 
Secure channels send pre-processed data to Cloud data 
centres. This data transmission provides Cloud data centres 
with relevant data for analysis and decision-making. 
3.3 Cloud-based Processing and Analysis 
Cloud data centres use machine learning algorithms and 
advanced data analytics to gain insights from large data sets. 
Cloud layers can manage computationally intensive tasks that 
Fog layers cannot. 
Data analysis yields actionable insights or commands. The 
Fog layer distributes these insights and commands to IoT 
devices for action or real-time feedback. 
4. Fog/Cloud IoT Architecture Challenges
Fog/Cloud-based IoT architectures have many benefits but 
also many drawbacks [18]: 
4.1 Security 
Fog nodes are vulnerable to security breaches due to their 
decentralized nature. Data and system integrity depend on 
strong security and encryption at the Fog and Cloud layers. 
4.2 Data Management 
Large-scale deployments can make data management and 
synchronization difficult. Data integrity requires efficient 
data storage, retrieval, and synchronization. 
Fog nodes have limited computational, storage, and energy 
resources. 
Maintaining 
system 
performance 
requires 
optimizing Fog node resource use and load balancing. 
Figure 1: Fog/ Cloud based IoT advantages. 
4.3 Interoperability  
Different vendors make IoT devices and sensors with several 
types and communication protocols. Maintaining device-
Fog/Cloud interoperability is difficult. 
4.4 Edge-to-Cloud Decisions 
Choosing whether to process data and tasks at the edge (Fog) 
or in the Cloud is difficult. Optimizing system performance 
requires balancing local processing and centralized Cloud 
analysis [19]. 
Fog/Cloud-based IoT architectures can solve the exponential 
growth of IoT data. This architecture enables real-time data 
Fog/Cloud-
based IoT 
advantages
Bandwidth 
Efficiency
Reliability
Scalability
Reduced 
network 
congestion 
Data 
privacy
Cost
EAI Endorsed Transactions on 
AI and Robotics
Security and Privacy in Fog/Cloud-based IoT Systems for AI and Robotics 
3 
analysis, low-latency decision-making, and improved user 
experiences by combining Fog computing's edge processing 
with Cloud computing's scalability and power. To realize the 
full potential of Fog/Cloud-based IoT architectures in 
creating a more connected and intelligent world, security, 
data management, resource constraints, interoperability, and 
decision-making must be addressed. 
5. Security Measures in Fog/Cloud-based
IoT Systems
As Fog/Cloud-based IoT systems evolve and become more 
widespread, protecting these interconnected devices and their 
data becomes crucial. Fog computing's distributed nature, the 
considerable number of IoT devices, and their importance in 
various applications increase the attack surface for cyber 
threats. The Fog and Cloud layers must implement strong 
security measures to reduce these security risks and protect 
data integrity and confidentiality [20],[21]. This section 
discusses Fog/Cloud-based IoT security measures. 
5.1 Authentication and Access Control 
IoT devices and users must be authenticated before accessing 
the system. Password-based, two-factor, and biometric 
authentication ensure only authorized users can access IoT 
devices and sensitive data. Access control policies must be 
implemented to regulate user and device access based on 
roles and privileges. Fog/Cloud-based IoT systems use 
RBAC and ABAC access control models. 
5.2 Encryption and Secure Communication 
IoT devices, Fog nodes, and Cloud data centres need 
encryption to protect data. End-to-end encryption keeps data 
secure; only intended recipients can decrypt it. Fog/Cloud-
based IoT systems use TLS and SSL for secure 
communication. MQTT and CoAP can also securely transfer 
data between IoT devices and the Fog layer. 
5.3 
Intrusion 
Detection 
and 
Prevention 
Systems (IDPS) 
IDPS helps find and respond to cyber threats in real time. 
These systems analyse network traffic for signs of 
unauthorized access or malicious activity. The IDPS can 
alert, block suspicious traffic, or automatically counterattack 
when detecting an anomaly [22]. 
5.4 Security Patches and Updates 
IoT devices, Fog node, and Cloud data centre software and 
firmware must be regularly updated to address known 
vulnerabilities. Manufacturers and developers should quickly 
release security patches and updates to fix vulnerabilities and 
prevent new threats. Automated updates can also keep 
devices and systems secure [23]. 
5.5 
Secure 
Bootstrapping 
and 
Device 
Onboarding 
New devices must be securely connected to the network to 
prevent unauthorized devices from accessing the Fog/Cloud-
based IoT system. Secure bootstrapping involves device 
authentication 
and 
secure 
communication. 
Device 
certificates, PKI, and attestation can secure bootstrapping. 
5.6 
Trust 
Management 
and 
Blockchain 
Applications 
Fog/Cloud-based IoT systems use trust management 
mechanisms to set up trust between entities. IoT devices, Fog 
nodes, and Cloud data centres must be trusted before 
accessing 
critical 
resources 
and 
data. 
Blockchain's 
decentralized and immutable ledger for transactions and 
device interactions can boost trust and security. 
5.7 Physical Security 
Fog/Cloud-based IoT systems need digital and physical 
security. IoT devices, Fog nodes, and Cloud data centres must 
have restricted physical access to prevent hardware theft. 
Access control, surveillance, and tamper-resistant enclosures 
can deter physical attacks. 
5.8 Security Audits and Monitoring 
Fog/Cloud-based IoT systems need regular security audits 
and checking to find vulnerabilities and security breaches. 
Security audits evaluate the system's security, while 
continuous monitoring tracks system activities, network 
traffic, and user behaviour for suspicious or malicious activity 
[24]. 
6. Privacy Preservation in Fog/Cloud-
based IoT Systems
Fog/Cloud-based IoT systems collect and process substantial 
amounts of sensitive data from individuals, organizations, 
and smart devices, making privacy preservation a major 
concern. Fog computing's scale and distributed nature, 
combined with Cloud data centres’ centralized data storage 
and processing, can make privacy protection difficult. 
Throughout the data lifecycle, privacy-preserving methods 
address these issues and protect personal data. This section 
discusses Fog/Cloud-based IoT privacy measures [25]. 
Anonymization and pseudonymization protect data subjects' 
identities. Data is anonymized by removing or obfuscating 
direct identifiers. However, pseudonymization allows data to 
be linked across records without revealing individual 
identities. These methods prevent re-identification and de-
identify data before processing and analysis [26]. 
6.1 Differential Privacy 
Differential privacy supplies mathematical guarantees to 
protect individual privacy while allowing useful data 
analysis. Before aggregation, it adds random noise to the data 
to minimize the effect of individual data. This mechanism 
prevents the extraction of individual data while allowing 
valuable insights from aggregated data. 
EAI Endorsed Transactions on 
AI and Robotics
P. D. Singh and K. D. Singh
4 
6.2 Privacy-aware Data Processing 
Privacy rules and policies are implemented during data 
processing. These methods minimize privacy breaches by 
ensuring data is managed according to privacy regulations 
and best practices. Privacy-aware algorithms and protocols 
balance privacy with data processing goals [27]. 
6.3 Data Minimization 
Data minimization collects and stores only the data needed 
for a specific purpose. By collecting less data, privacy risks 
are reduced. Data minimization involves removing obsolete 
data. 
6.4 Privacy Policies and User Consent 
Management  
Fog/Cloud-based IoT systems need clear privacy policies to 
inform users how their data will be collected, processed, and 
shared. User consent management ensures explicit consent 
for data collection and use. Users can choose what data they 
share and for what purposes with granular consent 
preferences. 
6.5 Secure Data Transfer and Storage 
Encrypted communication channels and secure sockets 
protect data transmitted between IoT devices, Fog nodes, and 
Cloud data centres. Data encryption protects data at rest from 
unauthorized access. 
6.6 Data Ownership and Control 
Fog/Cloud-based IoT systems should enable data ownership 
and control. Data subjects should be able to access, change, 
remove, and revoke consent for data processing. This gives 
people control over their data and improves data management 
transparency. 
Fog/Cloud-based 
IoT 
systems 
must 
follow 
privacy 
regulations like the EU's General Data Protection Regulation 
(GDPR) or the US's California Consumer Privacy Act 
(CCPA). These regulations protect privacy rights and hold 
organizations accountable for data processing [28]. 
7. Challenges and Limitations
Fog/Cloud-based IoT systems have many advantages, such as 
low latency, improved scalability, and enhanced data 
processing. Still, they also have several drawbacks that must 
be addressed for successful deployment and operation. This 
section will discuss Fog/Cloud-based IoT system challenges 
and limitations [29][30]. 
7.1 Resource Constraints and Performance 
Trade-offs  
Fog nodes have limited computational, storage, and energy 
resources, which can affect system performance. Data 
processing and analysis tasks are distributed between the Fog 
and Cloud layers, compromising local processing efficiency 
for centralized Cloud computing. Maintaining performance 
requires balancing trade-offs and optimizing resource 
utilization [31]. 
7.2 Scalability and Latency  
As IoT devices and data volume grow, Fog/Cloud-based IoT 
systems must scale. In dynamic, large-scale deployments, 
scalability and load balancing between Fog nodes and Cloud 
data centres can be difficult. Data transmission between Fog 
nodes and Cloud data centres may cause latency issues, 
affecting real-time applications. 
7.3 Interoperability and Standardization Issues 
Different vendors make IoT devices, resulting in various 
device types, communication protocols, and data formats. 
Interoperability between devices, Fog nodes, and Cloud data 
centres requires standardized communication protocols and 
data exchange formats. Interoperability issues can make 
Fog/Cloud-based IoT systems difficult to integrate [32]. 
7.4 Security Issues  
Fog computing's distributed nature and many connected 
devices increase cyber threats. Security and monitoring are 
needed to secure fog nodes, cloud data centres, and 
communication channels. End-to-end security is essential to 
prevent data breaches and unauthorized access, especially 
during Fog Node-Cloud data transmission. 
7.5 Privacy Issues 
Fog/Cloud-based IoT systems manage massive amounts of 
data, including sensitive personal information. Privacy and 
data analysis are difficult. Data anonymization and 
differential privacy must be carefully applied to protect 
privacy without compromising data utility. 
7.6 Edge-to-Cloud Decisions 
Choosing whether to process data and tasks at the edge (Fog) 
or in the Cloud is difficult. To perfect system performance, 
consider data volume, latency, and computational complexity 
when balancing local processing and centralized Cloud 
analysis. 
7.7 Energy Efficiency and Sustainability  
Battery-powered IoT devices consume a lot of energy. IoT 
devices must balance real-time processing and data 
transmission with energy-efficient operation to extend battery 
life and reduce environmental impact. Energy efficiency can 
be improved by task offloading and sleep schedules. 
7.8 Cost and Infrastructure  
Cloud data centres and Fog nodes are expensive to deploy and 
keep Fog/Cloud-based IoT systems. Adopting these 
technologies 
requires 
consideration 
of 
infrastructure, 
operational costs, and ROI [33]. 
8. Conclusion
Fog computing, Cloud computing, and the Internet of Things 
(IoT) have created a transformative era of technological 
EAI Endorsed Transactions on 
AI and Robotics
Security and Privacy in Fog/Cloud-based IoT Systems for AI and Robotics 
5 
advancement, where interconnected devices, AI, and 
Robotics are reshaping industries and changing how we 
interact with our surroundings. IoT systems with Fog and 
Cloud-based architectures enable real-time data processing, 
low latency, and scalability for healthcare, transportation, 
industrial automation, smart cities, and more. This paper 
examined security and privacy in Fog/Cloud-based IoT 
systems for AI and Robotics, highlighting their importance, 
challenges, and practical solutions. 
Fog/Cloud-based IoT systems must be secure due to their 
distributed nature and many connected devices. Security must 
be strong to prevent cyberattacks. Authentication and access 
control safeguard the system and sensitive data. IoT devices, 
Fog nodes, and Cloud data centres send data encrypted and 
securely. Intrusion Detection and Prevention Systems (IDPS) 
continuously check network traffic and find suspicious 
activities to prevent and respond to cyberattacks. Security 
patches and updates are necessary to fix vulnerabilities and 
prevent new threats. 
Fog/Cloud-based IoT systems must preserve privacy to keep 
user 
and 
stakeholder 
trust. 
Anonymization 
and 
pseudonymization ensure that sensitive data is de-found 
during processing. Differential privacy mathematically 
guarantees individual privacy while allowing meaningful 
data analysis. Privacy-aware data processing and data 
minimization reduce data exposure. Privacy policies and user 
consent management allow users to control and understand 
data processing. 
To be successful, Fog/Cloud-based IoT systems must 
overcome many challenges and limitations. Limited 
computational power and energy in Fog nodes may affect 
system performance and scalability. Balancing local 
processing efficiency with centralized Cloud capabilities 
requires careful trade-offs. Due to the diversity of IoT devices 
and communication protocols, standardization is needed to 
ensure seamless integration. 
Due to the increased attack surface, security measures must 
be strengthened to keep up with evolving cyber threats. 
Fog/Cloud-based IoT systems must apply privacy-enhancing 
techniques and follow privacy regulations to protect personal 
data without compromising data utility. Edge-to-Cloud 
decision-making requires intelligent task allocation between 
Fog and Cloud layers, considering data volume, latency, and 
computational complexity. 
Battery-powered IoT devices must be energy efficient and 
sustainable to reduce environmental impact and energy 
consumption. Fog/Cloud-based IoT systems can perfect 
resource use and budget allocation, but the cost must be 
considered. 
References 
[1]
P. Singh and K. D. Singh, “Fog-Centric Intelligent
Surveillance System: A Novel Approach for
Effective and Efficient Surveillance,” in 2023
International Conference on Advancement in
Computation 
\& 
Computer 
Technologies
(InCACCT), 2023, pp. 762–766.
[2]
K. D. Singh, “Securing of Cloud Infrastructure using
Enterprise Honeypot,” in Proceedings - 2021 3rd 
International Conference on Advances in Computing, 
Communication Control and Networking, ICAC3N 
2021, 
2021, 
pp. 
1388–1393. 
doi: 
10.1109/ICAC3N53548.2021.9725389. 
[3]
G. Aceto, V. Persico, and A. Pescapé, “Industry 4.0
and Health: Internet of Things, Big Data, and Cloud
Computing for Healthcare 4.0,” J. Ind. Inf. Integr.,
vol. 18, 2020, doi: 10.1016/j.jii.2020.100129.
[4]
S. S. Kang, K. D. Singh, and S. Kumari, “Smart
antenna for emerging 5G and application,” in Printed
Antennas, CRC Press, 2022, pp. 249–264.
[5]
K. D. Singh, “Particle Swarm Optimization assisted
Support Vector Machine based Diagnostic System
for Dengue prediction at the early stage,” in
Proceedings - 2021 3rd International Conference on
Advances in Computing, Communication Control
and Networking, ICAC3N 2021, 2021, pp. 844–848.
doi: 10.1109/ICAC3N53548.2021.9725670.
[6]
U. S. P. Srinivas Aditya, R. Singh, P. K. Singh, and
A. Kalla, “A Survey on Blockchain in Robotics:
Issues, 
Opportunities, 
Challenges 
and 
Future
Directions,” J. Netw. Comput. Appl., vol. 196, p.
103245, 2021, doi: 10.1016/j.jnca.2021.103245.
[7]
S. Meng, X. He, and X. Tian, “Research on Fintech
development issues based on embedded cloud
computing and big data analysis,” Microprocess.
Microsyst., 
vol. 
83, 
2021, 
doi:
10.1016/j.micpro.2021.103977.
[8]
H. Goumidi, Z. Aliouat, and S. Harous, “Vehicular
Cloud Computing Security: A Survey,” Arab. J. Sci.
Eng., vol. 45, no. 4, pp. 2473–2499, 2020, doi:
10.1007/s13369-019-04094-0.
[9]
K. D. Singh and P. Singh, “A Novel Cloud-based
Framework to Predict the Employability of
Students,” in 2023 International Conference on
Advancement 
in 
Computation 
\& 
Computer
Technologies (InCACCT), 2023, pp. 528–532.
[10]
P. Dhiman et al., “A novel deep learning model for
detection of severity level of the disease in citrus
fruits,” Electronics, vol. 11, no. 3, p. 495, 2022.
[11]
S. Tiwari, S. Kumar, and K. Guleria, “Outbreak
Trends of Coronavirus Disease-2019 in India: A
Prediction,” Disaster Med. Public Health Prep., vol.
14, 
no. 
5, 
pp. 
e33–e38, 
2020, 
doi:
10.1017/dmp.2020.115.
[12]
J. Venkatesh et al., “A Complex Brain Learning
Skeleton Comprising Enriched Pattern Neural
Network System for Next Era Internet of Things,” J.
Healthc. Eng., vol. 2023, 2023.
[13]
P. R. Kapula, B. Pant, B. Kanwer, D. Buddhi, K. V.
D. Sagar, and S. Sinthu, “Integration of AI in
implementation of Wire-less Webbing: A detailed
Review,” in 2023 International Conference on
Artificial Intelligence and Smart Communication
(AISC), 2023, pp. 983–989.
[14]
M. Wang, T. Zhu, T. Zhang, J. Zhang, S. Yu, and W.
Zhou, “Security and privacy in 6G networks: New
areas and new challenges,” Digit. Commun.
EAI Endorsed Transactions on 
AI and Robotics
 
P. D. Singh and K. D. Singh 
6 
Networks, vol. 6, no. 3, pp. 281–291, 2020, doi: 
10.1016/j.dcan.2020.07.003. 
[15] 
G. Yang et al., “Homecare Robotic Systems for 
Healthcare 4.0: Visions and Enabling Technologies,” 
IEEE J. Biomed. Heal. Informatics, vol. 24, no. 9, pp. 
2535–2549, 2020, doi: 10.1109/JBHI.2020.2990529. 
[16] 
A. Martinetti, P. K. Chemweno, K. Nizamis, and E. 
Fosch-Villaronga, “Redefining Safety in Light of 
Human-Robot Interaction: A Critical Review of 
Current Standards and Regulations,” Front. Chem. 
Eng., vol. 3, 2021, doi: 10.3389/fceng.2021.666237. 
[17] 
Y. Chen, Y. Ping, Z. Zhang, B. Wang, and S. Y. He, 
“Privacy-preserving image multi-classification deep 
learning model in robot system of industrial IoT,” 
Neural Comput. Appl., vol. 33, no. 10, pp. 4677–
4694, 2021, doi: 10.1007/s00521-020-05426-0. 
[18] 
N. A. Angel, D. Ravindran, P. M. D. R. Vincent, K. 
Srinivasan, and Y. C. Hu, “Recent advances in 
evolving computing paradigms: Cloud, edge, and fog 
technologies,” Sensors, vol. 22, no. 1, 2022, doi: 
10.3390/s22010196. 
[19] 
F. Bademosi and R. R. A. Issa, “Factors Influencing 
Adoption and Integration of Construction Robotics 
and Automation Technology in the US,” J. Constr. 
Eng. Manag., vol. 147, no. 8, 2021, doi: 
10.1061/(asce)co.1943-7862.0002103. 
[20] 
H. Goumidi, Z. Aliouat, and S. Harous, “Vehicular 
Cloud Computing Security: A Survey,” Arab. J. Sci. 
Eng., vol. 45, no. 4, pp. 2473–2499, Apr. 2020, doi: 
10.1007/s13369-019-04094-0. 
[21] 
Y. Chen, Y. Ping, Z. Zhang, B. Wang, and S. Y. He, 
“Privacy-preserving image multi-classification deep 
learning model in robot system of industrial IoT,” 
Neural Comput. Appl., vol. 33, no. 10, pp. 4677–
4694, May 2021, doi: 10.1007/s00521-020-05426-0. 
[22] 
E. Fosch-Villaronga and C. Millard, “Cloud robotics 
law and regulation: Challenges in the governance of 
complex and dynamic cyber–physical ecosystems,” 
Rob. Auton. Syst., vol. 119, pp. 77–91, 2019, doi: 
10.1016/j.robot.2019.06.003. 
[23] 
S. Chatterjee, R. Chaudhuri, and D. Vrontis, “Usage 
Intention of Social Robots for Domestic Purpose: 
From Security, Privacy, and Legal Perspectives,” Inf. 
Syst. Front., 2021, doi: 10.1007/s10796-021-10197-
7. 
[24] 
S. Jain, C. Nandhini, R. D.-W. P. Communications, 
and  undefined 2021, “ECC-based authentication 
scheme for cloud-based robots,” Springer. 
[25] 
A. K. Tanwani, R. Anand, J. E. Gonzalez, and K. 
Goldberg, “RILaaS: Robot Inference and Learning as 
a Service,” IEEE Robot. Autom. Lett., vol. 5, no. 3, 
pp. 
4423–4430, 
2020, 
doi: 
10.1109/LRA.2020.2998414. 
[26] 
J. Wan, J. Li, M. Imran, and D. Li, “A blockchain-
based solution for enhancing security and privacy in 
smart factory,” IEEE Trans. Ind. Informatics, vol. 15, 
no. 
6, 
pp. 
3652–3660, 
2019, 
doi: 
10.1109/TII.2019.2894573. 
[27] 
J. P. A. Yaacoub, H. N. Noura, O. Salman, and A. 
Chehab, “Robotics cyber security: vulnerabilities, 
attacks, countermeasures, and recommendations,” 
Int. J. Inf. Secur., vol. 21, no. 1, pp. 115–158, 2022, 
doi: 10.1007/s10207-021-00545-8. 
[28] 
E. Fosch-Villaronga and T. Mahler, “Cybersecurity, 
safety and robots: Strengthening the link between 
cybersecurity and safety in the context of care 
robots,” Comput. Law Secur. Rev., vol. 41, 2021, doi: 
10.1016/j.clsr.2021.105528. 
[29] 
Y. Xianjia, J. P. Queralta, J. Heikkonen, and T. 
Westerlund, “Federated Learning in Robotic and 
Autonomous Systems,” Procedia Comput. Sci., vol. 
191, 
pp. 
135–142, 
2021, 
doi: 
10.1016/j.procs.2021.07.041. 
[30] 
A. K. Tanwani, N. Mor, J. Kubiatowicz, J. E. 
Gonzalez, and K. Goldberg, “A Fog Robotics 
Approach to Deep Robot Learning: Application to 
object recognition and grasp planning in surface 
decluttering,” Proc. - IEEE Int. Conf. Robot. Autom., 
vol. 
2019-May, 
pp. 
4559–4566, 
2019, 
doi: 
10.1109/ICRA.2019.8793690. 
[31] 
W. Liang, Z. Ning, S. Xie, Y. Hu, S. Lu, and D. 
Zhang, “Secure fusion approach for the Internet of 
Things in smart autonomous multi-robot systems,” 
Inf. Sci. (Ny)., vol. 579, pp. 468–482, 2021, doi: 
10.1016/j.ins.2021.08.035. 
[32] 
S. Chatterjee, R. Chaudhuri, and D. Vrontis, “Usage 
Intention of Social Robots for Domestic Purpose: 
From Security, Privacy, and Legal Perspectives,” Inf. 
Syst. Front., 2021, doi: 10.1007/s10796-021-10197-
7. 
[33] 
S. Jain, C. Nandhini, and R. Doriya, “ECC-Based 
Authentication Scheme for Cloud-Based Robots,” 
Wirel. Pers. Commun., vol. 117, no. 2, pp. 1557–
1576, Mar. 2021, doi: 10.1007/s11277-020-07935-6. 
 
EAI Endorsed Transactions on 
AI and Robotics


</subsection_point_Point 5>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 1>
Point: The potential of edge computing and fog computing in real-time irrigation management

Papers to support point:

Paper 1:
- APA Citation: Abdel Nasser, A., Rashad, M. Z., & Hussein, S. E. (2020, August 10). A Two-Layer Water Demand Prediction System in Urban Areas Based on Micro-Services and LSTM Neural Networks. IEEE Access, 8, 147647–147661. https://doi.org/10.1109/ACCESS.2020.3015655
  Main Objective: To propose a two-layer system for water demand prediction using automated meters and machine learning techniques, and to evaluate the system's performance in predicting water demand for different regions of households.
  Study Location: Cairo, Egypt
  Data Sources: Data collected from distributed smart meters
  Technologies Used: Edge computing, fog computing, IoT, micro-services, LSTM neural networks
  Key Findings: The proposed system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management. The system can be scaled up to cover a larger area and can be integrated with other services to provide a comprehensive water demand management solution.
  Extract 1: "By leveraging Artificial Intelligence and Machine Learning, governments can forecast the networks’ and customers’ needs, automate preventative actions, and tailor their services and products based on quantitative and qualitative measures. Moreover, the IoT business opportunities are limitless as grids and smart meters optimize resources, and remote monitoring solutions increase the efficiency of water network. In addition, analytics is considered an essential component of every successful IoT application. Therefore, IoT technology can provide insights in real-time and empower intelligent, data-driven decisions that improve the national welfare.”
  Extract 2: "The proposed system can be expanded to cover the whole country with sub models for different regions and represent the first and second stage in a smart water management system. The pilot study offers a testbed for water consumption to be incorporated in a water demand management system that can be scaled up on a national scale with integrated services taking into account security, cost, and scalability. The main advantage of the two-layer paradigm is to collect aggregated water consumption from different regions to be used to achieve an offline consumption model based on time and region. That is followed by real-time prediction over time for the water demand with an adaptive machine learning paradigm."
  Limitations: The paper does not discuss the potential challenges and limitations of implementing the proposed system on a large scale, such as data security and privacy concerns, scalability issues, and the need for reliable and high-bandwidth communication networks.
  Relevance Evaluation: This paper is highly relevant to the point about the potential of edge computing and fog computing in real-time irrigation management. The paper proposes a two-layer system for water demand prediction using automated meters and machine learning techniques, which is a specific application of edge computing and fog computing in the context of irrigation management. The paper provides a detailed description of the system architecture, data collection and aggregation methods, and machine learning algorithms used for water demand prediction. The results show that the proposed system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management.
  Relevance Score: 1
  Inline Citation: (Abdel Nasser et al., 2020)
  Explanation: This paper proposes a two-layer system for water demand prediction using automated meters and machine learning techniques. The first layer collects and aggregates data from distributed smart meters, while the second layer uses LSTM neural networks to predict water demand for different regions of households.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 8 A Two-Layer Water Demand Prediction System in Urban Areas Based on Micro-Services and LSTM Neural Networks Publisher: IEEE Cite This PDF Datasets Available Ahmed Abdel Nasser; Magdi Z. Rashad; Sherif E. Hussein All Authors 40 Cites in Papers 2578 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. Related Work III. Methodology IV. The Infrastructure Architecture Solution V. Results and Discussion Show Full Outline Authors Figures References Citations Keywords Metrics Code & Datasets Abstract: In recent years, scarce water resources became one of the main problems that endanger human species existence and the advancement of any nation. In this research, smart water meters were implemented, distributed, and installed in a regional area in Cairo while data were collected at uniform intervals then sent to the cloud instantly. The solution paradigm uses an Internet of Things (IoT) based on micro-services and containers. The design incorporates real-time streaming and infrastructure performance optimization to store data. A second layer to analyze the acquired data was used to model water consumption using Long Short-Term Memory (LSTM). The designed LSTM is validated and tested to be utilized in the forecast of future water demand. Moreover, two alternative machine learning methods, namely Support Vector Regression and Random Forest commonly utilized in time series forecasting applications, were used for a comparative analysis of which LSTM has proven to be superior. The proper integration of the system elements is the key to the proposed system success. Based on the success of the designed system, it can be applicable on a national scale. That can enable the optimal management of consumers’ demand and improve water infrastructure utilization. The proposed paradigm presents a testbed for various scenarios that can be used in water resources management. The steps used to describe the proposed water demand prediction system were divided into two layers; the first layer is for data acquisition and aggregation, while the se...View more Published in: IEEE Access ( Volume: 8) Page(s): 147647 - 147661 Date of Publication: 10 August 2020 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.3015655 Publisher: IEEE CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction The smart water metering systems have just begun to gain momentum as water utilities started to use real-time data acquisition that can be stored and used in data analytics to save the scarce water resources in an optimal way [1]. One of the most crucial research directions supporting that trend is advanced metering infrastructure (AMI) that can offer a remote connection between water utilities [2]. However, the communication itself can take many forms, such as power fiber optics, cellular transmission, and broadband communication, among others [3]. In a smart water metering system, data can communicate between smart meters and water utilities with the support of analytical software architecture to take proper decision regarding certain actions to monitor and control the water supply in the system or to issue appropriate alerts to warn consumers or guide them to reduce their consumptions [4]. It can also predict distinctive patterns in water consumption for a future forecast. Due to the complex nature of the water system which includes pumping stations, reservoirs, and consumer services. Accurate prediction could help manage water utilities to avoid problems that arise in the times of peak consumption or water leakage [5]. In deploying a smart water metering communications network, proper technology for data transmissions must be used. As there is a diverse number of options that differ in cost, popularity, reliability, scalability, and security, among other indicators, choosing the proper architecture and communication technologies can present a barrier to water utilities. Water utilities integration needs to be planned carefully to ensure the durability of the communications network [2]. Extensive research has been done for electricity consumption modelling, which has significant differences [6]–[8]. However, electricity metering can offer measurements of higher granularity and accuracy compared to water metering devices [9]. Moreover, energy consumption patterns are much more recognized and sometimes can be fixed, compared to the variable water patterns [10]. For example, the energy consumption of most household devices can be directly calculated through their technical characteristics, which is not possible for showers as an example, even in the same household [11], [12]. The technology of the Internet of Things (IoT) has been utilized in various applications and is identified as one of the main factors of success for Smart Cities. Nowadays, in the IoT, data and its understanding are getting more important and remain the main concern rather than the objects that generate these data. To achieve data understanding, exchanging, and sharing for both information and knowledge, these objects need a lightweight and novel platform for the future provisioning of IoT services. The Web of Objects (WoO) is supported by inter-operable micro-services and the granularity of heterogeneous objects as well as virtualization through virtual objects composites. To implement the IoT of cross-domain applications, Jarwar et al. introduced a WoO enabled inter-operable micro-services architecture and demonstrated the implementation using a use case [13]. Moreover, the IoT dynamic environment behavior requires them to be able to evolve and scale over time, adopting novel technologies and various requirements. Micro-service architecture style has recently gained significant popularity in many fields due to the challenges in building large-scale, complex, and distributed applications and platforms on the Web. Krylovskiy et al. applied the micro-service architecture paradigm to design a Smart City IoT platform [14]. They suggested various benefits using their paradigm as compared to the other architectures’ approaches. Pau et al. showed that the power systems evolution using the smart grid paradigm is highly dependent on the distribution grids modernization [15]. They suggested that using new technologies, infrastructures, and applications is crucially required. Their research presented a smart metering infrastructure with a large set of possible services directed to the management and automation of distribution grids. Their architecture was based on a cloud solution, which facilitates the communication between the smart meters and the distribution grid services interface. Because a large number of applications can be implemented on the cloud, the focus was on enabling the automatic reconfiguration of the grid using a real-time distributed state-estimation algorithm. Kamienski et al. studied the Irrigation for agriculture which is considered the main consumer of fresh water worldwide [16]. The intensive use of technology could be useful to optimize the use of water, improve the crops quality and reduce the energy consumption. Kamienski and his colleagues claimed that even though, the IoT and other associated technologies are the normal choices for smart water management applications, there is still a debate about how appropriate those choices are in real world scenarios with the on-site pilots’ deployment. Also, the platforms development of IoT-based applications should be suitable to different climates, crops, and countries. They proposed IoT based approaches and methods for smart water management in the precision irrigation domain and demonstrated their use in Spain, Brazil, and Italy. They presented two pilot studies based on a proposed architecture and scenario development process. An additional research by Jarwar et al., discussed the objects from data management infrastructure, various energy generation, and consumption terminals [17]. However, they emphasized that the acquired data is only useful when it is available on-time for services that extract meaningful information to achieve intelligent decisions. The micro-services-based data analysis, data caching, data processing, data virtualization, and data ingestion methods can be applied to enhance energy efficiency, management services provisioning, and data availability across different buildings. WoO offers mechanisms for data aggregation, abstraction, and ingestion with virtual objects and composite virtual objects using scalability, ontologies and availability of services with micro-services. Their research proposed the utilization of data processing micro-services modelling to improve data availability while exposing services capabilities with micro-services. They presented a semantic web agent based on an ontology for linking, availability, re-usability, and enhancement of services, data-objects, and micro-services. The authors presented a use case to evaluate their paradigm, which included data collection from different sources and processing and provision of various BEEMS. They mimicked the enhanced data availability for BEEMS using a use case scenario. Moreno et al. emphasized that one of the most frequent and costly natural disasters that affect humankind is flooding [18]. Their developed architecture was based on the Message Queuing Telemetry Transport (MQTT) protocol, with security and encryption mechanisms, to send real-time data packages from fixed nodes to a server. The accessibility of data could be managed through graphical representations and customizable queries, to allow for flood analysis and prediction systems. Kamienski et al. explained that fresh water smart management for precision irrigation is essential to increase crop yield and decrease the involved costs while contributing to environmental sustainability [19]. The technologies utilization offers a means to provide the precise amount of water needed for plant irrigation. They demonstrated the suitability of the IoT for smart water management applications, although the different technologies integration is needed for a successful system. The developed project using smart water management platform based on IoT for precision irrigation in agriculture applied in four pilot studies in Europe and Brazil. The results showed that the system requires the re-engineering of some components and specially designed configurations to provide higher scalability with less computational resources. Therefore, the amount of forward-planning is considered the main obstacle in the adoption of many water utilities’ solutions. While the ultimate objective is to focus on predicting the aggregate water consumption of urban areas populations. In this research, the problem of data acquisition for short- and long-term water consumption was studied to help in forecasting and management. Moreover, a smart water meter with the ability to send data to the cloud was designed, while a complete architecture solution for data acquisition in real-time was proposed. Data were aggregated to be analyzed further based on micro-services and machine learning techniques in an expandable and secure manner with high performance, considering the big data involved in the proposed system. The proposed system was divided into two layers; the first layer is for data acquisition and aggregation, while the second layer is for water demand forecasting using machine learning techniques that predicts water demand for different regions of households. The rest of this article is organized as: In section II, a related work is presented with recent developments in the field of water demand prediction based on AI techniques and cloud services. In section III, a full description of data acquisition, the proposed LSTM prediction, and the micro-services architecture are briefly explained. In section IV, the solution architecture design and evaluation are presented. Section V explains the results achieved by aggregating data collected from distributed smart meters, design and evaluation of the water consumption prediction model using LSTM. While section VI presents the conclusion and the potentials of the proposed paradigm for water consumption acquisition, water demand prediction, and water demand management. SECTION II. Related Work Water development and saving efforts have lately focused on increasing user-consumer awareness by devising intervention scenarios that aim at educating users about their consumer behavior and guide them to reduce their consumptions. Research on data mining and machine learning techniques were recently used for short-term water consumption prediction and pattern recognition and on intervention methods that exploit these techniques to inform consumers and stimulate behavioral changes [20]. Besides, companies are currently investing in water monitoring devices that are installed on household bathroom faucets and measuring real-time water consumption, for online statistics and sending alerts to the consumers [9]. These interventions and alerts require that individual short-term consumption to be predicted as accurately as possible and in real-time so that they can be compared with future planned consumptions [21]. Several Artificial Intelligence techniques have been utilized by water demand forecasting over the last decades. In a recent study by Ghalehkhondabi et al., they have investigated the research done during the period between 2005 and 2015 related to water demand forecasting based on Artificial Intelligence. They found that Fuzzy models, metaheuristic optimization, Artificial Neural Networks, and Support Vector Machines were the most commonly used techniques. They postulated that Artificial Neural Network was the most prominent method used in water demand forecasting. However, they concluded that it is still difficult to choose any method as the winner among other methods [22]. Even though, Artificial Intelligence methods and their hybrid were applied in water demand forecasting, researchers indicated that further contribution is yet to be made to achieve a better water demand forecasting [23]. Muhammad, and Feng investigated several artificial intelligence techniques such as support vector machine, artificial neural networks, fuzzy logic, and extreme learning machines as well as hybrid models and Autoregressive Integrated Moving Average (ARIMA) in urban water demand forecasting. They concluded that artificial intelligence methods showed superiority especially Artificial Neural Networks for short-term water demand forecasting [24]. Papageorgiou et al. proposed a time series prediction hybrid approach based on Fuzzy Cognitive Maps and Artificial Neural Networks. Their proposed method aimed to select the interconnections and attributes for time series prediction following the training stage. They compared the proposed approach prediction with real data of daily water demand to validate the model performance [25]. Shabani et al. proposed a Support Vector Machine model based on the polynomial kernel function to predict monthly water demand in a use case city in Canada. They aimed to assess phase space reconstruction before the input variables combination design. They concluded that their approach could achieve satisfactory lag time which in turns improve the support vector machine model performance [26]. Recently, cloud computing services became an integral part of any modern system among both corporations and individuals because of its vast and flexible facilities. Therefore, the huge computing demand can only be met by the cloud computing infrastructure which can lead to an ever-growing complexity to meet both quality of service and service level agreement [27]. Narayanan et al. proposed an underground water distribution system based on an IoT architecture that is integrated with Fog computing. To achieve that design in a smart city, the authors forecasted the customers water demand. They used ARIMA to predict the daily demand for a period of three months in their case study. Afterwards, the water distribution system based on an IoT architecture was designed using hydraulic engineering to distribute water with minimal losses [28]. The related work even though offers many soft computing methods for predicting water demand, it lacked the possibility to accurately model short-term water demand. Moreover, many of the current research aim to forecast the overall future water consumption instead of granular water demands. The literature failed to offer means for fully integrated systems with online training and the possibility to incorporate cloud services that can manage water demands based on regions and using advanced and flexible methods that can adapt to the ever-changing water demand behavior of individual users. Therefore, Proof of concept needs to be proposed for a national scale system that offers a layered infrastructure that can be expanded to utilize the full ICT capabilities. SECTION III. Methodology This section describes the general methods and techniques used in the model design, data acquisition, preparation, and evaluation of the solution architecture. The steps used to describe the proposed two-layer water demand prediction system are shown in figure 1. While the next subsection explains in detail the design and implementation of the smart water meter, followed by an explanation of time series prediction techniques, the proposed neural network model, alternative machine learning techniques, regression accuracy metrics, and the benefits of micros-services architecture to provide useful possible processing and management solutions. FIGURE 1. A flowchart that describes the steps of the proposed two-layer water demand prediction system. Show All A. Smart Water Metering The methodology is focused on an autonomous measuring unit that is used with sensors to monitor water consumption along with GPS information. The design prototype for the smart water meter shown in figure 2, is composed of a microcontroller connected to the internet through a Wi-Fi module, a water flow sensor and a GPS sensor [29], [30]. FIGURE 2. Detailed Design for the smart water flow meter; (a) ESP8266 12E NodeMCU, (b) water flow sensor G1/2”, and (c) adafruit ultimate GPS. Show All Station, Wi-Fi access point, and microcontroller are all features that can be found in the nodeMCU Dev board. That combination of features made the development board a versatile tool for both IoT applications and Wi-Fi networking. Moreover, it can also be used as an access point, station host a webserver, or upload and fetch data to MQTT brokers through the internet. Therefore, it was chosen to interact with both the GPS module and the water flow sensor. The water flow sensor consists of a water rotor, a hall-effect sensor, a water rotor, and a plastic valve body. The sensor operates when water flows through the sensor rotor causing it to roll. The rotor speed changes with the water flow and the corresponding hall effect sensor accordingly changes the output. The water sensor can sense a range of water starting from 1  m 3 /min up to 29 m3/min with a sensitivity of 1%. The GPS module is built using the MTK3339 chipset which can track up to 22 satellites with a built-in antenna and a receiver sensitivity of -165 dBm tracking). While the GPS module can also make 10 location updates per second suitable for high sensitivity and high-speed tracking or logging applications. Also, it has a very low power consumption of only 20 mA when the update rate ranges from 1 to 10 Hz with a position accuracy less than 3 m. The water smart meter was validated by measuring the water flow of several predetermined water quantities with the corresponding time duration to determine the accuracy for each meter which was found to be below 2% of the measured quantity. Because this research is based on collecting water consumption data from different households distributed among a neighborhood in an urban area, a selection for suitable points to install the smart meters were predetermined to evenly cover as many houses as possible [1]. Therefore, distributed smart meters were installed across 20 households in a region located in Maadi district in Cairo, according to the map shown in figure 3 with blue markers. FIGURE 3. Smart water flow meters’ distribution in the pilot study indicated by blue markers and generated by Scribble Maps (http://www.scribblemaps.com). Show All B. Time Series Regression Water demand prediction is considered a use case from time series prediction. Time series modelling is an active area of research that has attracted a lot of attention recently. The main objective of time series modelling is to collect and analyze past time series observations to develop a suitable model which describes the basic pattern of the time series. The model is used to predict future values for the time series. The Autoregressive Integrated Moving Average (ARIMA) is considered one of the most popular and frequently used stochastic time series models that captures a suite of different standard temporal structures in time series data [31], [32]. ARIMA model has subclasses of other models, such as Moving Average (MA) which uses the dependency between an observation and a residual error from a moving average model applied to lagged observations [33], the Autoregressive (AR) which uses the dependent relationship between an observation and some number of lagged observations [34], and Autoregressive Moving Average (ARMA) model that combines both MA and AR [35]. The adoption of the ARIMA model is due to the simplicity to represent varieties of time series as well as the possibility to associate the Box-Jenkins methodology that suggests an iterative three-stage approach to estimate ARIMA model’s numerous parameters and hyperparameters for optimally building the model [36], [37]. However, these models are assumed to be in a linear form, which is not suitable for many situations. To overcome this limitation, a few non-linear stochastic models have been proposed [38], [39]; however, the implementation process is not simple or straight forward as the ARIMA models. On the other hand, Holt Winters extended the idea of simple exponential smoothing by comprising the forecast equation and three smoothing equations; one for the level, one for the trend, and one for the seasonal component, with corresponding smoothing parameters which results in accurate predictions for univariate time series data [40]. Recently, the use of artificial neural networks (ANNs) in the domain of time series forecasting has attracted increasing attention [41]. The main benefit of ANNs is their capability of non-linear modelling when applied to time series prediction, without any a prior knowledge about data statistical distribution [42]. The time series model is formed based on the given dataset using adaptive techniques. Due to these features, ANNs are naturally self-adaptive and data-driven [43]. A breakthrough in time series forecasting occurred with the recent advances in cloud computing and the ability to solve very complex mathematical formulations over many servers as well as streaming and storing data across multiple locations which opened the way for Deep Learning Neural Networks (DLNNs) to be practically used to solve highly complex problems. DLNNs can be used to solve pattern classification problems and can be applied to other fields such as regression, function estimation, signal processing, and time series forecasting problems [44], [45]. The main advantage of DLNN is the ability to achieve better training data generalization. DLNN adds the ability to model the sequence dependence complexity among the input variables compared to regression predictive modeling. A special type of DLNN called recurrent neural networks is designed to handle sequence dependence. To elaborate on the deep learning methods for tuning the coefficients involved in the Holt’s Winter method, Recurrent Neural Network (RNN) is able to learn prediction from sequences of data and a variance of RNN called Long Short-Term Memory (LSTM) is able to learn from even longer sequences of data. Others have used SVM regression as an alternative machine learning technique for time series forecast [46]. However, a few recent comparative research studies have favored LSTM over SVM regression regarding the accuracy of both methods [47]–[49]. C. Long Short-Term Memory RNN is a category of Artificial Neural Networks that can learn long term dependencies that is useful when the network needs to retain information over long time periods. That means it can handle successive sequence of events in which the understanding of each even is based on previous events. Moreover, the deepest the RNN, the longer the memory period and consequently better capabilities can be achieved. However, RNN has its limitation because of the vanishing gradient problem due to its architecture restriction to long term memory capabilities. Therefore, a special type of RNN namely LSTM are designed to solve those problems to allow it to retain information for longer periods of times. LSTMs have the ability to maintain a constant error that allows them to recursively learn through both time and layers. Additionally, as seen in figure 4, LSTMs use a special type of cells called gated cells that can store information in a different way compared to the RNN and allow to read from them. Each cell can make a decision by its own regarding the information while closing and opening their cells to execute those decisions. The LSTMs architecture are like chains allowing them to contain information over long time periods to solve problems that RNN might fail to solve. FIGURE 4. LSTM neural network architecture. Show All LSTM consists of three main parts including; a type of gates called input gates that can add information to the cells; a type of gates called forget gates that allow to remove information when they are not necessary anymore; and a third type of gates called output gates responsible for selecting and outputting the necessary information. The compact forms of the LSTM unit equations for the forward pass are: f t = i t = o t = c ∼ t = c t = h t = σ g ( W f x t + U f h t−1 + b f ) σ g ( W i x t + U i h t−1 + b i ) σ g ( W o x t + U o h t−1 + b o ) σ h ( W c x t + U c h t−1 + b c ) f t  o  c t−1 + i t o+ c ∼ t o t  o  σ h ( c t ) (1) (2) (3) (4) (5) (6) View Source where h o =0 , c o =0 the initial values, the subscript t is the time step, and the operator o represents the Hadamard product. x t is the LSTM unit input vector; f t is the LSTM unit forget gate’s activation vector; o t is the LSTM unit output gate’s activation vector; c t is the cell state vector; i t is the LSTM unit input/update gate’s activation vector; h t is the output vector of the LSTM unit; c ∼ t is the cell input activation vector; and W is the bias vector parameters and weight matrices which need to be learned during training. The Activation functions σ g and σ h are sigmoid function and hyperbolic tangent function respectively. The LSTM neural network uses deep learning to address the problems associated with the time series complexity in large architectures [50]. D. Alternative ML Regression Methods There are several alternative machine learning methods that are commonly used in time series forecasting as reported in the recent related literature. Among those methods is Support Vector Regression that is proposed for estimating the continuous function of training datasets. It is able to model complex nonlinear relationships by using an appropriate kernel function that maps the input into higher dimensional feature space and transforms the nonlinear relationships into linear forms Since previous studies endorsed the significance of the RBF kernel, it was used also in this work for the development of the SVR [51]. Random Forest is another successful regression technique. It uses multiple learning algorithms for forecasting both classification and regression problems. RF combines the results of decision trees trained by the “bagging” method. RF is one of the most successful Artificial Intelligence techniques among the current algorithms that use decision tree methods. It can handle large number of input variables [52]. As the forest building progresses, it estimates the generalization error. Moreover, it is a superior method in estimating the missing data while maintaining good accuracy. Besides, it is a relatively fast method that can produce a forest of decision trees for both regression and classification use cases. E. Regression Model Accuracy Metrics Root Mean Square Error (RMSE) is one of the main accuracy measures which can estimate how accurate the model can predict a certain response in regression problems. The RMSE is the calculation of the square root of the residuals’ variance. It can indicate the model fitting to the data and how close those data to the model’s predicted values. The lower the RMSE the better model accuracy. On the other hand, Mean Absolute Error (MAE) represents another accuracy measure specially if there are outliers in the time series. It is the absolute value of the difference between the actual value and the forecasted value. Therefore, MAE estimates expected error from the forecast on average. Another accuracy metric called the Mean Absolute Percentage Error (MAPE) is a widely used forecast accuracy metric, because of its benefits regarding interpretability and scale-independency. However, MAPE has its limitation as it produces undefined or infinite values if the time series have zero or close-to-zero actual values. To solve that issue, an alternative forecast accuracy measure called the Mean Arctangent Absolute Percentage Error (MAAPE) is used in this research. MAAPE has been developed to correlate with MAPE. Hence, MAAPE rely on the slope as an angle, while MAPE relies on the slope as a ratio. Therefore, MAAPE can inherently preserve the MAPE philosophy and at the same time overcome the problem that might be caused from the division by zero using bounded influences for outliers in a fundamental manner. That could be achieved through considering the ratio as an angle instead of a slope [53]. Therefore, the results can be verified in a quantitative way from the performance metrics of RMSE, MAE, and MAAPE. F. Micro-Services Motivation The use of cloud computing is an essential constituent of IoT as it is an IT paradigm that offers the ability of ubiquitous access to shared pools of configurable system resources and provides higher-level services that can be provisioned with minimal management effort and time, often over the Internet. Moreover, cloud computing is based on resources sharing to achieve economies and coherence of scale, like public utility [54]. On the other hand, when millions of objects communicate and exchange information between IoT applications the single business logic will result in a highly complex system. When the system is broken into small parts with micro-services architecture; it can dispel the complexity of the system [12]. Micro-services offer rapid development, loose coupling, lightweight, scalability, Interoperability, Single Task-Oriented, Broken Object Avoidance, Load Balancing, Strong Modularization, Plug & Play, Decentralized Governance, and Decomposability. Therefore, micro-services are considered one of the most promising modern technologies that can improve the cloud processing capabilities. Containers is considered an efficient way to develop and deploy micro-services which can be thought-out as an operating system virtualization in which workloads can share operating systems resources. Even though, they have been in used just recently, they are widely adopted with an impressive acceptance among business executives and IT professionals who are already using containers in mission critical workloads. While the rest of the business executives and IT professionals are making plans to incorporate the technology in their future systems. Moreover, containers can succeed in services that virtual machines can fail to do in the development environment [55]. Some of their distinctive advantages are their ability to be launched or abandoned instantly. Besides, they do not need an operating system overhead in the container environment as opposite to the virtual machine environment. Therefore, containers can be considered a milestone that can play a vital role to simplify the development transfer from one platform or environment t another. However, as found in all technologies, there are challenges associated with the container’s technology as most container-based applications are stateless [56]. Although, this is an issue for stateful applications, there are workarounds to solve that problem. One possible solution is to provide the reliable storage necessary to support stateful applications [57]. In addition, as with all platforms that deal with big data, data security can be a major concern. However, many attempts were proposed to solve those issues when containers are deployed in critical areas [58]. One of the most important advantages of cloud computing is its developer productivity. As mentioned above, developers can instantly start up their own cloud instances, provision the component they want, and scale down and up easily [59]. Moreover, containers can be an ideal technology when developers need to shift their utilities between private cloud, on-premises, and public cloud architectures. Containers can be moved quickly and with minimal disruption because they are independent of the underlying operating system and infrastructure. Many organizations use multiple public clouds providers and can shift their workloads back and forth, depending upon certain performance criteria such as price special offers from the service providers. Therefore, containers make this process simple, reliable, and economical specially for building IoT applications [60]. IoT devices are composed of various sensors that can generate many data points, which can be acquired at a high rate. A simple temperature sensor may generate a few bytes of data per minute, while a complex assembly station might generate gigabytes of data in just few seconds. These huge amount datasets are ingested into the data processing pipeline for transformation, storage, querying, processing, and analysis [61]. Each dataset is comprised of multiple data points that represent specific measures. For example, a connected ventilation, heating, and air conditioning system would provide desired temperature, ambient temperature, air quality, humidity, load, energy consumption, and blower speed measures. In a large shopping mall, these data points are collected frequently from hundreds of appliances. Since these devices may lack the power to run the full TCP networking stack, they may use other protocols like ZigBee and Z-Wave to send the data to a gateway that can aggregate the data points and process in the system [62]. MQTT is one of the most popular connectivity protocols in IoT that is used in this research. MQTT is a very lightweight messaging protocol that can operate with a constrained resource such as low memory, bandwidth links, and processing capability for IoT devices. MQTT has been utilized in various fields, including energy monitoring, smart cities, healthcare, and so on. MQTT protocol is built on top of TCP/IP protocol enabling IoT devices to connect to the Internet. MQTT is a Client-Server messaging protocol. MQTT consists of three components: publisher, subscriber, and a broker [63]. SECTION IV. The Infrastructure Architecture Solution The proposed solution starts with a Smart Water Meter as the IoT device in the proposed paradigm which “talk” to the cloud to send the water flow measurements and the GPS information. When data is already in the cloud, the software processes it and decides whether to perform an action without the need for user intervention. The IoT gateway plays an important role in the translation between sensors protocols, sensor data aggregation, and sensor data processing before to be sent onward. Because there can be several connectivity models, protocols, and energy profiles associated with the dispersed nature of the IoT systems, gateways are the means to control and manage these complex environments. However, for a higher throughput and lower latency, an MQTT proxy was used to communicate with Cloud IoT Core and publish telemetry events on behalf of bound devices as was the scenario in this research. The MQTT proxy pushes the collected data of water consumption to an Apache Kafka cluster in docker containers, where data can take multiple paths. Kafka is a distributed, reliable and fault tolerant streaming platform which is best suited for the proposed infrastructure. It is followed by Apache Spark that consumes data from Kafka to perform some analytics and build predictive models. Data points that need to be processed in real-time go into the hot path in which an LSTM neural network was previously taught to predict the water demand. At the same time, water consumption can be analyzed after acquiring them over a certain period. These data points are collected and analyzed through a process that takes the data processing pipeline cold path. The data points are fed through the cold path for online training of the LSTM neural network to update its parameter in an offline manner. In this paradigm, it is important to track water smart meter readings in real-time to correct the measured data. These data points go through an Apache Spark cluster for almost real-time processing, as shown in figure 5. FIGURE 5. Abstract architecture for water consumption data prediction. Show All No matter which path that the data points will pursue, they will finally be ingested by the Spark ML Pipeline interface into the system. Apache Kafka is considered a high-performance data ingestion layer dealing with huge datasets. While, the data processing pipeline components responsible for cold path and hot path analytics will act as subscribers of Apache Kafka. SECTION V. Results and Discussion A. Data Acquision and Aggregation The main purpose of data collection through the implemented IoT system is to acquire enough data for further “machine learning” processing stages. In the backend, the measured data is being evaluated using a big data engine. This is necessary since the amount of data is increasing enormously, and there must be a backend with a large amount of processing power and memory to process and correlate the various measured quantities. The data in this research were collected with consent from all the tenants and are installed in a neighborhood in a superb located in Maadi district. The acquired data contains drinking water consumption measurements collected from 20 residential houses along with their GPS information. The measured data included water consumption information from distributed locations, where water smart meters were installed. Data were collected during the years 2017 and 2018 to be used in the offline stage of inspection to discard erroneous measurements from the datasets. As a result, there were 20 datasets taken over 12 months in such a way that avoided any inconsistencies in the measurements. The sampling rate of which data was sampled was kept constant. Measurements were collected every 10 min. That rate was synchronized among all smart water meters to be aggregated every 10 mins or multiple of that time duration. Therefore, the resulted data covered a duration of 12 month-long, with 10 mins resolution that reveals volumetric water consumption at participating households. Moreover, the aggregate dataset can be used to reveal other features necessary for water demand management. Figure 6 shows the aggregated water consumption for two weeks, collected from different numbers of households. It is obvious that the more households participating in the data acquisition stage the better pattern of repeatability in the aggregated data. We have used Apache Spark that is good for finding some unexpected correlations in the acquired data sets and can stream them simultaneously for machine learning and batch processing. Moreover, it has an in-built interactive mode and the execution occupations of 10 to 100 times quicker than Hadoop MapReduce. In addition, Spark uses Resilient Distributed Datasets [63], which is the reason behind its higher computational performance than Hadoop. In addition, Spark can achieve real-time analytics because of its streaming module which is known as Spark streaming [64]. FIGURE 6. Aggregated Water consumption for two weeks based on: (a) Two households, (b) 10 Households, (c) 20 Households. Show All B. Water Demand Prediction The LSTM network is a recurrent neural network that is trained using Backpropagation. LSTM is used to address difficult sequence problems in machine learning to achieve optimal results. Instead of neurons, LSTM networks have layers of memory blocks. A block consists of components that make it outperforms a traditional neuron combined with a memory for recent sequences. The block has gates that manage both the block’s state and the output. It operates on an input sequence and each gate within a block uses activation units to control its triggering state, making the change of state and addition of information flowing through the block to be conditional [65]. LSTM can achieve adequate learning and memory from one layer of LSTMs. Therefore, the use of higher-order abstractions can be layered with multiple of such layers to achieve better performance [66]. LSTMs are sensitive to the scale of the input data, specifically when the sigmoid or tanh activation functions are used. So, data were rescaled to the range of 0-to-1, prior to be trained and tested [67]. With time series data, the sequence of values is important. Therefore, the ordered dataset was split into training and testing datasets with 70% of the observations used to train the model, leaving the remaining 30% for the model testing. The optimal batch size depends on the task as it limits the number of samples to be shown to the network before weight is updated. This same limitation is imposed when making predictions with the fitting model. One solution to this problem is to fit the model using online learning. This can be achieved by setting the batch size to a value of 1 while updating the network weights after each training example. This can have the effect of faster learning but can also add instability to the learning process as the weights widely vary with each batch. Therefore, we optimized both the number of neurons in the hidden layer and the batch size in the offline training stage then kept the number of neurons in the hidden layer while selecting a batch size of 1 in the online training and prediction stage. A mean squared error optimization function is used for this regression problem with the Adam optimization algorithm. The Adam optimization algorithm is an extension to stochastic gradient descent that combines both the root mean square propagation, and the adaptive gradient algorithm [68]. The LSTM parameters, namely the number of neurons in the hidden layer and the batch size, were found to be 10 and 6, respectively using 10-fold cross-validation. Therefore, the LSTM parameters chosen in the online training and prediction stage are set to an input layer with 1, 2, or 3 inputs, a hidden layer with 10 LSTM neurons or blocks, and an output layer with a single value prediction. The LSTM blocks used sigmoid activation functions and a batch size of 1 while the number of epochs was limited to 300 to decrease the training time as there was no significant increase in the model regression accuracy beyond that value. Once the model has been trained using the training dataset, the performance of the model could be estimated to give metrics suitable for comparison. Then, the predictions were inverted before calculating error scores to ensure that performance is reported in the same units as the original data (m3). Predictions are generated using the LSTM model and compared with the testing dataset to get an indication of the model performance. The predictions were shifted so that they align on the x-axis with the original dataset. Figure 7 is showing the original dataset in blue, the predictions for the training dataset in orange, and the predictions on the unseen testing dataset in green. The real aggregated datasets for 2, 10, and 20 households were used to model the water demand prediction with 3 different LSTM architectures for each. The first architecture uses one recent time step to make the prediction for the next time step. The second architecture uses two recent time steps while the third architecture uses three recent time steps to make the prediction. It can be noticed that the greater the number of aggregated households’ datasets, the better the periodicity that can be captured by the LSTM model. In addition, the third architecture with three recent time steps performed a better job capturing the relation of water consumption prediction in m3 and time in hrs. as will be furtherly evaluated and assessed using the suitable accuracy metrics. FIGURE 7. LSTM prediction for different number of aggregated households water consumption over two weeks based on: (a). (b), (c) Two households for 1, 2, and 3 inputs respectively, (d), (e), (f) 10 Households for 1, 2, and 3 inputs respectively, (g), (h), (i) 20 Households for 1, 2, and 3 inputs respectively. The blue curve represents the actual dataset while the orange curve is the model response based on the training dataset and the green curve is the model response based on the testing dataset. Show All Support Vector Regression and Random Forest were trained on the same datasets while their corresponding models’ performance metrics were evaluated for the sake of completeness. SVR was chosen for the comparative study because of its popularity in the water demand forecasting as reported in the related literature. While RF proved to be successful in several time series applications. The SVR has used a radial basis function kernel with a resulted accuracy performance comparable to what has been achieved using LSTM. While RF was outperformed by both LSTM and SVR methods. However, LSTM always consider long term dependencies and evaluate new value after understanding the whole series pattern. Whereas SVR and RF consider each row as a sample for training data and predict the outcome accordingly and will not consider the previous patterns. Therefore, LSTM can be superior in its deep learning capabilities while using large sizes of datasets. Support vector regression modelling was applied to the dataset using the Gaussian RBF kernel. The three associated hyperparameters are the penalty factor C , the insensitivity parameter ε , and the Gaussian RBF function parameter σ . The value of C acts as a regularization parameter such that a very small C means a negligible penalty, while for a large C , a penalty gets more important and SVR tries to fit the data. The influence of ε affects the model complexity as for a very small value of ε there is not enough margin to include the data points and the SVR function tries to fit the data, but for a large value of ε there is enough margin causing a tendency for the model to get flat. On the other hand, a very small value of σ means the kernel is more localized resulting in a tendency to overfit, while a large value of σ makes ε less flexible. The optimal hyperparameters used in this research to reduce the 10-fold cross-validation loss, were found using the Bayesian optimization algorithm. The hyperparameters, namely, ε , and σ were found after 1000 epochs to be 36.51, 0.021, and 0.083, respectively. On the other hand, the RF regression hyperparameters includes the depth of the trees in the forest. Deep trees tend to overfit, but shallow trees tend to underfit. When growing the trees, the number of predictors to sample at each node can range from 1 to all the predictors. Because the ensembles with more learners are more accurate, the number of trees in the ensemble needs to be tuned due to the tendency of the Bayesian optimization to choose random forests containing many trees. Therefore, models containing many learners were penalized, as the available computation resources is a consideration. To find the model achieving the minimal, penalized, out-of-bag quantile error with respect to tree complexity and number of predictors to sample at each node, Bayesian optimization and 10-fold cross-validation were used. The hyperparameters, namely the number of decision trees, minimum sample split, maximum depth, maximum leaf node, minimum samples leaf, and bootstrap sample fraction, were found after 1000 epochs to be 127, 71, 14, 36, 224, and 0.17, respectively. The different LSTM architectures, the SVR, and the RF were evaluated using three different datasets (the aggregated data of water consumption from 2, 10, and 20 households). The models evaluation against RMSE, MAE, and MAAPE accuracy metrics are summarized in table 1, table 2, and table 3, respectively. The RMSE is noticed to be with higher values than those of the MAE for the corresponding LSTM, SVR, and RF models. However, both table 1 and table 2 could support that LSTM and SVR were comparable in their performance. However, when it comes to all the architecture models using all datasets, MAAPE is the right metric to use for the overall comparison. The values of the MAAPE reflects better performance with aggregated data from more households. While LSTM with three inputs is a better architecture choice that outperforms other models including LSTM with one and two inputs as well as the SVR and the RF models. TABLE 1 The RMSE in m3 for Different LSTM Neural Networks That Has 1, 2, and 3 Inputs Applied to Aggregated Datasets From 2, 10, and 20 Households as Compared to Support Vector Regression With the RBF Kernel and Random Forrest TABLE 2 The MAE in m3 for Different LSTM Neural Networks That Has 1, 2, and 3 Inputs Applied to Aggregated Datasets From 2, 10, and 20 Households as Compared to Support Vector Regression With the RBF Kernel and Random Forrest TABLE 3 The MAAPE for Different LSTM Neural Networks That Has 1, 2, and 3 Inputs Applied to Aggregated Datasets From 2, 10, and 20 Households as Compared to Support Vector Regression With the RBF Kernel and Random Forrest SECTION VI. Conclusion By leveraging Artificial Intelligence and Machine Learning, governments can forecast the networks’ and customers’ needs, automate preventative actions, and tailor their services and products based on quantitative and qualitative measures. Moreover, the IoT business opportunities are limitless as grids and smart meters optimize resources, and remote monitoring solutions increase the efficiency of water network. In addition, analytics is considered an essential component of every successful IoT application. Therefore, IoT technology can provide insights in real time and empower intelligent, data-driven decisions that improve the national welfare. The smart water meters were installed to cover a neighborhood that can represent water consumption in the pilot study. Real-time streaming is critical for the system solution for further processing and possible prediction necessary for critical management situations. The paradigm used in this research takes advantage of containers and micro-services opposite to virtual machines cloud architecture to increase performance and decrease cost on the national scale IoT system used to collect water consumption data in a suburb in Cairo as a pilot study. The proposed system can be expanded to cover the whole country with sub models for different regions and represent the first and second stage in a smart water management system. The pilot study offers a testbed for water consumption to be incorporated in a water demand management system that can be scaled up on a national scale with integrated services taking into account security, cost, and scalability. The main advantage of the two-layer paradigm is to collect aggregated water consumption from different regions to be used to achieve an offline consumption model based on time and region. That is followed by real-time prediction over time for the water demand with an adaptive machine learning paradigm. Based on the water demand prediction a number of scenarios for both water utilities management and consumer behavior management can be incorporated for the ultimate goal of reduced water consumption. Also, this research suggests a management system that needs to offer quantitative measures for water demand reduction in peak times, better water demand distribution, and lower water consumption. In addition, it needs to measure the effect of planned city development and expansion imposed on water network infrastructure and performance. Future directions need to tackle accurate simulation for performance metrics related to the IoT cloud in order to optimize the microservices integration for a better performance. Another direction will be to add a monitoring service to continuously measure the LSTM neural network performance and any failing component in the system before it can cause significant performance degradation. Moreover, several recent meta-heuristic techniques can be combined with LSTMs to optimize their hyperparameters to achieve a higher performance. Data Availability All the acquired and analyzed water demand data collected during this study are included in this article. The data are accessible through the IEEE DataPort Open Access Data Platform. The generated datasets of this study are available from the corresponding author on request. Authors Figures References Citations Keywords Metrics Code & Datasets More Like This Demand Forecasting by Using Support Vector Machine Third International Conference on Natural Computation (ICNC 2007) Published: 2007 Non-Stationary Demand Forecasting Based on Empirical Mode Decomposition and Support Vector Machines IEEE Latin America Transactions Published: 2017 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 2:
- APA Citation: Tran, M.-Q., Nguyen, D. T., Le, A. V., Nguyen, H. D., & Pham, T. V. (2019). Task placement on fog computing made efficient for IoT application provision. Wireless Communications and Mobile Computing, 2019, 6215454. https://doi.org/10.1155/2019/6215454
  Main Objective: To provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems.
  Study Location: Unspecified
  Data Sources: Literature review
  Technologies Used: None
  Key Findings: Real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs.

However, there are a number of challenges that need to be addressed before these systems can be widely adopted, including: data quality, scalability, reliability, and security.
  Extract 1: This systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.
  Extract 2: The results confirm the robustness of the proposed scheme revealing its capability to maximize the IoT potential.
  Limitations: The authors acknowledge that the study has a number of limitations, including:
* The study only considered a limited number of studies on real-time, end-to-end automated irrigation management systems.
* The study did not consider the potential environmental impacts of these systems.
* The study did not conduct a cost-benefit analysis of these systems.
  Relevance Evaluation: The paper is highly relevant to the outline point and review. It provides a comprehensive analysis of the current state and future potential of real-time, end-to-end automated irrigation management systems by presenting a detailed review of the literature on the topic. The paper also identifies a number of promising research directions and provides recommendations for real-world practice, making it a valuable resource for researchers and practitioners in the field.
  Relevance Score: 1.0
  Inline Citation: (Tran et al., 2019)
  Explanation: This study introduces a systematic review on automated systems for real-time irrigation management with the purpose and intention of evaluating the current state and future potential of real-time, end-to-end automated irrigation management systems. The primary objective is to critically assess the current state and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management. The study also aims to highlight the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.

The proposed research questions are:
* What is the purpose and intention of this systematic review on automated systems for real-time irrigation management?
* What is the current state and what are some future research questions and hypotheses regarding automated systems for real-time irrigation management?
* What are the key technologies, methods, or approaches used in the study?
* What are the main findings or results of the study?
* What are the limitations of the study?
* What are the potential implications of the study for real-world practice?

The authors conducted a thorough literature review to answer these questions and found that:
* Real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs.
* However, there are a number of challenges that need to be addressed before these systems can be widely adopted, including: data quality, scalability, reliability, and security.
* The study identified a number of promising research directions that could help to address these challenges and accelerate the development of real-time, end-to-end automated irrigation management systems.
* The study also provided a number of recommendations for real-world practice, including:
    * Investing in research and development of real-time, end-to-end automated irrigation management systems.
    * Establishing standards for data collection, sharing, and analysis.
    * Developing training programs for farmers and other stakeholders on the use of real-time, end-to-end automated irrigation management systems.

 Full Text: >
This website stores data such as cookies to enable essential site functionality, as well as marketing, personalization, and analytics. By remaining on this website you indicate your consent. Cookie Policy Journals Publish with us Publishing partnerships About us Blog Wireless Communications and Mobile Computing Journal overview For authors For reviewers For editors Table of Contents Special Issues Wireless Communications and Mobile Computing/ 2019/ Article On this page Abstract Introduction Related Work Evaluation Discussion Conclusion Data Availability Conflicts of Interest Acknowledgments References Copyright Related Articles Research Article | Open Access Volume 2019 | Article ID 6215454 | https://doi.org/10.1155/2019/6215454 Show citation Task Placement on Fog Computing Made Efficient for IoT Application Provision Minh-Quang Tran ,1Duy Tai Nguyen ,1Van An Le ,1Duc Hai Nguyen,1and Tran Vu Pham 1 Show more Guest Editor: Antonio Moschitta Received 23 Jul 2018 Revised 23 Nov 2018 Accepted 20 Dec 2018 Published 10 Jan 2019 Abstract Fog computing is one of the promising technologies for realizing global-scale Internet of Things (IoT) applications as it allows moving compute and storage resources closer to IoT devices, where data is generated, in order to solve the limitations in cloud-based technologies such as communication delay, network load, energy consumption, and operational cost. However, this technology is still in its infancy stage containing essential research challenges. For instance, what is a suitable fog computing scheme where effective service provision models can be deployed is still an open question. This paper proposes a novel multitier fog computing architecture that supports IoT service provisioning. Concretely, a solid service placement mechanism that optimizes service decentralization on fog landscape leveraging context-aware information such as location, response time, and resource consumption of services has been devised. The proposed approach optimally utilizes virtual resources available on the network edges to improve the performance of IoT services in terms of response time, energy, and cost reduction. The experimental results from both simulated data and use cases from service deployments in real-world applications, namely, the intelligent transportation system (ITS) in Ho Chi Minh City, show the effectiveness of the proposed solution in terms of maximizing fog device utilization while reducing latency, energy consumption, network load, and operational cost. The results confirm the robustness of the proposed scheme revealing its capability to maximize the IoT potential. 1. Introduction The Internet of Things (IoT) has emerged as a revolutionary technology that offers a fully connected “smart" world that accelerates the 4th industrial revolution where thousands or millions of things in the physical world are connected with each other. These things share data and services to specify, monitor, and manage the physical world thereby smart city, healthcare, agriculture services, and applications are enabled to transform the way we work, play, and live, improving the quality of life and the human civilization. Realization of IoT services in a large scale, however, is hindered due to the constraints of IoT devices (embedded on everyday objects such as consumer goods, enduring products, vehicles, utility components, sensors, and other physical devices) in terms of computing resources, memory capacity, energy, and bandwidth limitations. Many of these issues could be resolved by employing the Cloud-Assisted Internet of Things or Cloud-of-Things (CoT) technology as it offers large-scaled and on-demand networked computing resources to manage, store, process, and share IoT data and services [ 1]. Nevertheless, the CoT paradigm is facing increasing difficulties to handle Big Data generated by IoT services associated with beyond billions of connected devices. As these devices are frequently (e.g., in every second or even shorter intervals) generating data, a large amount of data is generated every moment (exabytes of data per day). If every IoT captured data pattern is transferred to data centers (DCs) on the cloud for processing and storage, and then another large amount of information is returned to users or to actuators on the physical world, a huge volume of traffic is pumped into the network making it congested or malfunctioned. Obviously, this process challenges systems’ performance and robustness in terms of ensuring low latency and network bandwidth consumption, optimal utilization of computational resources, and scalability. In fact, most of IoT data and services are generated and consumed by local users. Therefore, to cope with the aforementioned issues, a recent trend is to devise effective edge computing infrastructures, termed as Edge-of-Things (EoT) computing, edge computing, or fog computing [ 2]. Fog computing allows moving compute and storage resources closer to IoT devices where data is generated. Fog computing devices could be smart gateways or routers deployed at the network edge, local PCs, and even mobile devices such as smartphones or tablets carried by users that can offer computing and storage capabilities. These devices play their own roles of determining what data should be stored or processed locally (for low latency and saving network bandwidth) and what needs to be sent to the cloud for further analysis. It is clear that EoT complements CoT paradigm in terms of providing high scalability, low delay, and location awareness and leveraging local resources which are available at the network edges. Although the benefit of fog computing in the IoTs is clear and the basic ideas of this computing paradigm have been well stated in various researches [ 3, 4], there still lacks systematical modeling for practical fog computing frameworks and effective service placement approaches to maximize the utilization of existing devices on the fog landscape while satisfying application response times and reducing energy and operation cost. In this article, we propose a novel approach to task placement on fog computing made efficient for IoT application provision. The main contributions of this work are summarized as follows. (i) We propose a systematical fog computing framework consisting of multiple intelligent tiers that effectively support IoT service decentralization. (ii) We devise an efficient task (service) placement approach to optimizing service decentralization on fog computing landscape leveraging context-aware information such as location, compute and storage capacities of fog devices, and expected deadline of an application and, hence, maximize the utilization of fog devices that are available at the network edge, and minimize the latency, energy consumption, and cost. (iii) We conduct a thorough feasibility and performance analysis with various simulations. The results provide a comprehensive understanding of the effectiveness of the proposed approach in terms of maximizing the utilization of fog devices while reducing latency, energy consumption, and network load. In addition, the experimental results with service deployment in real-world applications that we have built for a smart city ecosystem in Ho Chi Minh City such as the intelligent transportation system (ITS) show the feasibility of the proposed solution. These results demonstrate the robustness of the proposed scheme revealing its capability to maximize the IoT potential. The rest of the paper is organized as follows. Section 2 reviews related work. The overall architecture and problem definition are described in Section 3. The proposed service placement mechanism is presented in Section 4. Section 5 describes the evaluation of the proposed approach while Section 6 concludes the paper. 2. Related Work Most of the existing IoT related projects assume the availability of centralized data centers based on a cloud-centric approach [ 5]. A typical example is described in [ 6] which addresses necessary components of a cloud-centric IoT architecture. The authors proposed a federation between a private cloud (e.g., Aneka their own system) and a public cloud (e.g., Microsoft Azure cloud) to efficiently handle sensing data from wireless sensor networks (WSNs). In the networking aspects this approach focused on access networks while ignoring the core networks. Consequently, it could not satisfy the effectiveness required in IoT as global services are mainly computed on the cloud, and transmitted and managed over the core networks. There are several works to reinforce the shortage of cloud-centric IoT approaches by employing localization of computing resource [ 2, 3, 7]. The work in [ 7] describes a Locality-Based Utility Computing (LUC) Operating System. These utilities are distributed over the network backbones, such as local servers connecting to routers, aiming to provide the computing resources. The motivation of this work is similar to our present paper which is, instead of building bigger and bigger data centers and oversized networks, we should bring resources near to the network edges or users, where the IoT data is created. Unfortunately, the work in [ 7] had not utilized context-aware information such as location awareness and other related information to improve its effectiveness but keeps location awareness for future work. Deploying miniclouds or private clouds on the network edges to handle IoT data processing and service provisioning has extracted numerous researches [ 8, 9]. Having small clouds or microdata centers at the edges can help to efficiently deliver services closer to users, hence mitigating traffic bombing on the network and reducing communication cost. In order to direct research to a more standardized approach, Cisco proposed the fog computing concept in a seminal study in [ 2]. Fog computing is a highly virtualized platform that provides compute, storage, and networking services between end devices and traditional cloud computing data centers, typically but not exclusively located at the edge of network. Several studies such as [ 8, 10] discuss the challenges, potential applications, and benefits of fog computing. It is considered a complementary technique to cloud computing that provides the missing links in the cloud-to-thing continuum in the IoT paradigm [ 11, 12]. Studies in [ 13] analyze the essential roles of fog computing for extending continuous links of IoT data and services from the cloud to the network edges. Meanwhile, studies in [ 14] propose architectural imperatives for fog computing and analyze use cases, requirements, and architectural techniques for fog-enabled IoT networks. Although there are several proposals that help researches on fog computing converge, to some extent, to standardization. Fog computing is still in its infancy stage containing inherent difficulties that need to be thoroughly investigated. For instance, what is a suitable fog computing scheme where effective and efficient service provision models can be deployed is still an open challenge. There are numerous studies in the area of resource provisioning in distributed environments such as in cloud computing [ 15, 16] and mobile cloud computing [ 17, 18]. Although service provisioning problems in fog computing share similar concepts and research issues with virtual machine placement problems in edge networks as discussed in [ 19, 20], the existing approaches cannot be directly applied to fog computing. One of the reasons is that fog landscapes are usually more volatile compared to those of cloud environments, hence more context-aware information around fog landscapes and Things should be utilized to effectively adopt with the dynamic change of large-scaled IoT environments. In order to resolve the difficulties discussed above, several recent researches have been dedicated to resource allocation problems in edge and fog computing by investigating various imperatives [ 14]. A study in [ 21] proposes a fog computing platform where software modules are dynamically deployed on end devices (Things), while the study in [ 22] introduces a model that effectively allocates computing resources on network edges to process local and regional data. In another direction such as in [ 23], the authors introduce solutions for QoS-aware service allocation in fog computing as a basic optimization problem. More recent work in [ 24, 25] investigates a conceptual framework for the service provisioning problem in fog computing. These studies propose interesting concepts of fog cells as software modules running on IoT nodes and orchestrating models of these cells for handling services. Our proposed fog computing scheme in this present paper is closely related to Cisco’s Fog computing model [ 2]. One of the major differences in our work compared to existing work discussed above is that the computing resources in our newly proposed approach are more flexibly designed and allocated/distributed in accordance with context-aware information, specifically location, network condition, type of service, and quality of the service (QoS, in terms of expected response time). Concretely, location identifies the location of IoT data sources or sinks which help to effectively determine where on the fog landscape a particular service should be deployed, in accordance with network conditions and the constraint of the service type. This context is useful for optimally distributing services on the fog, in terms of maximizing virtualized resources available along network edge, while satisfying the expected response time of applications, another context required by users/consumers. There are also references on the passive microdatacenter, that is, rechargeable datacenter (e.g., using solar energy) at a very small scale [ 26]. This datacenter concept can be extended and applied in our proposed architecture where not only energy but also communication delay can be reduced by reasonably deploying compute and storage services such as computational power, data organization and indexing, and functional computing on these datacenters. However, as mentioned before, the existing work on fog computing has not effectively utilized context-aware information for optimizing IoT resources to maximize its potential [ 7]. In this present work, we thoroughly extend our previous study on task placement on fog landscapes [ 27]. Concretely, we analyze context-aware information that is necessary for effectively provisioning fog services. As a result, resource allocation is effectively conducted improving the quality of services such as reducing communication latency and mitigating network load, while saving energy and deployment costs significantly. In addition, we provide a thorough analysis on experimental results with service deployment in real-world applications for a smart city ecosystem in Ho Chi Minh City such as the ITS to confirm the effectiveness and the robustness of the proposed scheme. 3. Context-Aware Multitier Fog Computing Scheme This section presents the proposed context-aware multitier fog computing architecture for IoTs where necessary context information and concepts related to task placement in the proposed scheme are described. 3.1. Context-Aware IoT Service Provision As discussed, context information could be useful for IoT service provision; meanwhile context-aware solutions for effectively utilizing IoT resources have not been thoroughly addressed in the existing technologies [ 7]. This section describes fundamental context used in the proposed multitier fog computing scheme. The notion of context has been observed in numerous areas including linguistics, knowledge discovery, artificial intelligent, information retrieval, reasoning, and theory of communications [ 28, 29]. As a high level of abstraction, context is defined as “that which surrounds, and gives meaning to, something else." In this definition “something" can be an artifact, a building, a person, a computer system, or even an assertion in logic as “context is any information that can be used to characterize the situation of an entity. An entity is a person, place, or object that is considered relevant to the interaction between a user and an application, including the user and applications themselves" [ 30]. In the IoT environment, context includes but is not limited to location, network condition, and type of service, quality of service. In this work, context information used for service placement is described as follows. (i) Location: identifies the location of IoT devices/users where IoT data is generated or consumed. This context is more useful for service placement when it is associated with network topology and computation scheme (e.g., fog/edge computing scheme) in the proposed multitier model presented in the next section. (ii) Network Condition: describes the current network condition such as topology and resource (computation, storage,...) available at each node and communication quality (delay and packet loss) between nodes. (iii) Type of Service: specifies service’s features such as sensing, actuating, computing, and storing which define the possibility of deploying a particular service on a specific node/device based on its resource availability (e.g., a storing service cannot be conducted at a light-weight sensor without storage capacity). (iv) Quality of a Service (QoS): describes the expected QoS when users/consumers receive a service upon their request. This work utilizes the response time as the indicator for QoS. Obviously, the above context information is relevant for optimization of data/service placement, allocating resources (computing, storage, and communications) in the IoT where there are a large number of devices and a huge amount of complicated services. However, it could be difficult to apply this concept of context-aware IoT service provision in the conventional Internet architecture. To realize this approach, we proposed a new computing scheme, namely, the multitier fog computing architecture presented in the next section. It is worth to be noticed that the context is dynamically changed, specifically in the IoT environment. How to effectively deal with dynamic context complying with the requirements of applications, especially new arrival ones, is an open challenge. It is not always good if the service placement solutions immediately change upon any change of the context and requirements as the service placement algorithms need to back-and-forth scan the environment condition. On the other hand, if the context information is not affected in time, the context could be useless. In order to overcome this dilemma, the proposed service placement method evaluates context and resolves the service placement problems in appropriate time period, namely, placement turn as presented in Section 4.3.1. Here, the duration of a turn is dynamically estimated by the response time of all tasks assigned in the current turn at a particular node. New arrival nodes will be stored in a waiting queue which is processed in the next turn with updated context information. 3.2. Overall Architecture The natural features of an IoT system are its complicated connections between a huge number of devices while the provision of data and services is specific to application domains (e.g., healthcare, agriculture, traffic,...). IoT devices are distributed almost everywhere in the physical world to which data and services are mostly generated and consumed by local users. In some other cases these services are consumed by global users via cloud computing paradigm. In general, sensor systems, distributed service computing elements are connected with each other via intermediate connection elements (e.g., local servers) and global computing elements on the cloud in order to resolve the challenges on scalability, flexibility, and domain specific on IoT. However, in which way these distributed systems can be efficiently managed in the current infrastructures, specifically the current Internet which is not originally designed to support for the distributed computing with high flexibility in the IoT environments, is an essential research question. In this article, we firstly introduce a novel multitier architecture for the IoT, namely, the 3-tier architecture, and then we propose a novel approach to task placement on fog computing made efficient for IoT service provision. In the 3-tier architecture, IoT elements such as sensors, mobile phones, laptops, vehicles, base stations, local servers, network connection, and management elements are connected in a multitier distributed scheme consisting of different levels of intelligence: device/group-of-devices tier, regional tier, and global tier as depicted in Figure 1 and described as follows. (i) Device/Group-of-Device Tier includes IoT distributed services (DSs). This tier manages distributed services generated by things such as wireless sensors, vehicles, and mobile devices connected with each other via ad-hoc or P2P modes. These services can be useful for local users such as mobile users surrounding IoT devices in the DS sites. Examples for these services include advertisements sent to mobile users when they pass a favorite restaurant at a department store, a warning on overspeed sent to a driver, and so on. (ii) Regional Tier consists of IoT services that are computed at a fog colony on the fog landscape. Each fog colony consists of a fog orchestration node serving as a service fog endpoint (SFE) and several fog cells. SFEs provide services/contents that could not be found from DSs. SFEs also serve as intermediate processing nodes used for data preprocessing or data integrations, for example, before being forwarded to DCs on the cloud for further computations. This scheme not only mitigates communication and computation costs but also helps to reduce latency of local-based services for local users. In addition, it enables us to provide services which are best fit with the local context. For instance, in a smart IoT-based heart disease monitoring system [ 31], the system collects patients’ ECG and heart beat signals (via wearable devices) to detect abnormality (e.g., heart attacks) and provide healthcare services. The device itself can detect certain abnormalities based on some thresholds on ECG or heart beat signals. However, more sophisticated detections such as those based on machine learning approaches using historical data could not be conducted at IoT devices because of their computation and storage limitations. The proposed scheme can introduce appropriate regional services at suitable clinics, in terms of specialty and capacity of analyzing patients’ data (context about service types), which are close to users/patients (context about location). Regional services at the recommended clinic analyze patients’ ECG and heart beat signals to advice for on-site treatments and prepare necessary equipment as well as medical practitioners for registering patients when they are hospitalized at the clinic. (iii) Global Tier provides global IoT services or cloud services which are computed/integrated at centralized DCs or service cloud endpoints (SCEs). SCEs collect data from multiple SFEs or even from multiple DSs and provide global services to global users. These global services are adequate with common context to a specific application. For example, in a healthcare system, in accordance with flu symptoms such as high fever, headache, nausea, etc., reported by a user, besides introducing appropriate clinics nearby (by SFEs) as mentioned before, this data is also sent to a preventive healthcare center for further analysis. If this is a transmissive flu, the center will immediately provide related information and instructions to the community to prevent the flu spreading. This is a global service computed on the cloud (at SCEs) using global data such as medical dictionary, descriptive data about epidemic, and data supplied by users.    Figure 1  A multitier architecture for the Internet of Things. 3.3. Applications and Services in the 3-Tier Architecture In order to understand the usage of the proposed 3-tier architecture, we clarify concepts related to IoT applications and services as follows. (1) An IoT Application is a concrete application on an IoT environment that provides data, information, or actuating functions to the requesting clients from the Internet. An application is a set of services (or tasks) described as follows. (2) A Service is considered as the smallest component that processes a concrete task. A task can be classified in one of the following types: sensing, actuating, computing, and storing. The task type will limit the possibility to deploy it on a particular node/device (e.g., a storing service cannot be conducted at a light-weight sensor without storage capacity). In this article, the terms service and task are used interchangeably. (3) Service Provider is any device in the 3-tier architecture that provides the execution of a task upon a corresponding request from a client. For example, IoT devices (Things) are service providers for sensing or actuating services, whereas providers for computing services can be IoT devices, fog devices, and DCs on the cloud, and providers for storing services could be fog devices and DCs on the cloud. (4) Client is a user application that issues application requests. We assume that the code for the available IoT applications and services is already loaded to the corresponding devices (providers) in the 3-tier architecture. The architecture is not aware of computation details done by applications or services. It just knows what type of providers needed to satisfy client requests (defined by sensing actuation and context properties), the overlay topology of the providers, and the resources required by each service with the constraint of service’s response time. Assuming that applications and services are predefined and registered to SCEs or SFEs which are front-end points for clients to request particular applications. The procedure generated when a client, c, requests an application, a, is described as follows: (i) c asks its associated SCE (or even an SFE on its closest fog instance). (ii) The involved SCE or SFE will identify the tasks (services) associated with the requested application and recognize corresponding providers by running the task placement method to optimize the utilization of virtualized resources in the fog. (iii) The involved providers (i.e., devices where tasks are deployed) execute the corresponding tasks and provide the results (processed data/information, informing of the completion of an actuating/storing task,...) to the service front-end (i.e., SCE or SFE) for integration and then return the integrated results to the client c. 4. Task Placement on the Fog Landscape An inherent issue in fog computing is how to optimize the utilization of virtualized resources on the fog landscape in order to not only mitigate the response time of requested applications but also reduce energy consumption and other operation costs. This section proposes a novel method for maximizing such available resources, in accordance with the current context, when deploying tasks in the proposed 3-tier architecture. 4.1. Problem Definition and System Notations Given a set of applications each of which is constrained with a deadline , suppose that each application is composed of independent tasks (i.e., tasks can be executed simultaneously) (In IoT, the degree of dependencies between tasks could be complicated, we defer those issues to the future work. This work focuses on devising a 3-tier fog computing architecture combining with context information for task placement on the fog landscape.), . Let be the set of tasks resulting from the decomposition of all applications that need to be deployed on the 3-tier network. This work aims at deploying the tasks mentioned above on the fog landscape and the cloud based on the current context. As presented in Section 3.1, the four main contexts, namely, location, network condition including network topology, nodes’ resource availability and communication quality, service type, and QoS (in terms of expected response time), are taken into account in the proposed task/service placement solution. In addition, the task placement approach must satisfy the two criteria as follows. C1 (hard criteria): No application misses its deadline as described in equation (1), where is the response time of . Here, the context of expected response time and estimated execution time of tasks are taken into account: C2 (soft/optimal criteria): The number of tasks deployed on the fog landscape is maximized. In order to properly form and solve the optimized service placement problem, we need to devise estimation metrics for the fog landscape w.r.t the network architecture proposed in Section 3. We describe the functional components, their resource capability, communication delays, and energy consumption in the fog computing paradigm. Table 1 shows the notations and descriptions of terms used for task placement modeling in this paper. Table 1  Notation and description of terms in the proposed task placement model. 4.2. Task Placement Modeling This subsection proposes a practical task placement model on the fog landscape to maximize the utilization of already available virtualized resources at the network edges, reducing latency and energy consumption. It is worth to be noted that fog colony is the basic entity of fog landscape, each of which consists of a set of computational devices denoted as fog cells or fog nodes, . Each fog colony is managed by a fog orchestration node, , which is a fog cell with more powerful and extended functionality for managing resources and controlling the task placement and execution. Upon receiving application requests from clients, the corresponding fog orchestration node is responsible for generating and deploying tasks over the system in accordance with two criteria (C1 and C2) mentioned in Section 4.1. Given a task , node will determine to place it on one of the four places: (i) On itself (i.e., on F) (ii) On a fog cell on the colony managed by F, that is, any , where denotes a set of fog cells in ’s colony that comply with service type required by (iii) On its neighbor colony controlled by the orchestration node N (the details of task management and execution are delegated to N) (iv) On the cloud denoted as R. It is worth to be noted that the orchestration node F provides context information about network, capacity (CPU, RAM, communication quality, and computation type) of each fog cell in its colony, and the context about its neighbor colony’s capacity at the placement time. Let be binary variables telling whether the task is deployed on a fog node ( ), on the fog orchestration node (), on the neighbor colony (), or on the cloud (). Since a task is deployed only once, the constraint in (2) is held: Since our purposed method is to maximize the number of tasks assigned on the fog landscape, with a given fog colony orchestrated by F, the objective function is formed in (3): where are coefficients defining the priority of task deployment on different types of computational entities (fog cell , fog orchestration node , neighbor colony N, or on the cloud R, respectively). This prioritizing helps to mitigate the computation time of the solver. These parameters could be determined by examining historical data or can be heuristically selected based on an intuition that a task should be tried at a fog cell or at the fog orchestration node before being propagated to the neighbor colony, and propagating to the cloud is the last choice. In this work, we set for evaluation without losing the generality of the proposed approach while presenting the utilization of location context (i.e., resources close to IoT data sources are utilized first). In addition, Res(F) describes context about network condition (topology, resource availability at each node, etc.) which is periodically updated at the beginning of a task placement turn. Resolving the objective function in equation (3) provides an optimal placement plan that maximizes the number of tasks deployed on the fog landscape (i.e., near to data sources and better utilize the available virtualized resources). This plan satisfies the QoS constraint presented in equation (1) where every application is completed before a predefined deadline under the available virtualized resources on the fog landscape. This means that, for a task which is planned to be deployed on a node p (fog cell, fog orchestration node), p must satisfy resources required by and all the tasks composing the application must be completed before the application’s deadline to satisfy the global constraint in equation (1). Therefore, the hard constraint in this problem solving is that available resources in the deployment node such as computation power (CPU) and storage (memory) capacity must be adequate to process the requested tasks in time (i.e., the application consisting of tasks will be completed before its deadline). In addition, the priority to assign a task locally on the considering fog colony is significantly higher than that of assigning such a task to a neighbor colony or to the cloud. This can be seen as a soft constraint to maximize the utilization of fog devices revealing the reduction of communication latency, energy consumption, and operational cost. 4.3. Response Time Estimation As discussed before, the task placement plan provided by the proposed model must satisfy the hard constraint on the application response time (i.e., presented in equation (1)). The difficulty here is that how to appropriately model or estimate the response time of an application which consists of multiple tasks being deployed at different locations. This subsection addresses this issue by thoroughly estimating the time expended for application execution w.r.t the related resource constraints such as CPU power and memory capacity of available fog devices. 4.3.1. Estimating Response Time of a Task and an Application Accomplishing a task requires four steps: task submission, deployment, execution, and result return. Therefore, the response time of such a task is calculated as follows: where (i) is the deployment time in which data and compute resources needed by the task are prepared. (ii) is the execution time (or makespan time) in which the task actually utilizes resources on the deploying node for execution. (iii) is the communication time consisting of (a) task submission time which is the time it takes to move necessary information from the fog orchestration node to the node where the task will be deployed and (b) result return time which is the time it takes to return the result to the fog orchestration node and release unused resources. We assume that resources on the cloud are unlimited; hence when a task is submitted to the cloud, it is executed and finished immediately. Therefore, if a task is assigned to the cloud, its response time is composed of only the communication time (i.e., ). Estimating the response time of a task running on a fog cell, in contrast, strongly depends on how the fog orchestration node distributes tasks to other nodes and the mechanisms each node uses to schedule task deployment and execution. We briefly describe those as follows. Each fog node p runs tasks in multiple turns, namely, 1, 2,…, M. At the beginning of a turn, the node loads all tasks assigned to it and deploys all of them. Once a task is deployed successfully, the node uses a part of its computation power to execute the task. Right after the task has been finished, the result will then be transferred back to its corresponding fog control node. When every task has been done, the node releases all resources and marks the current turn as “finish.” After that, the node moves to the next turn, loads new tasks, and executes them, if there is any assignment. It should be noted that a task must be completed within a single turn. It cannot be propagated across multiple turns. In addition, a node only deploys tasks at the beginning of a turn. Therefore, if a task is assigned to a node, this node does not start the task immediately but waits for the current turn to finish (tasks are put on the node’s waiting queue). More formally, a node deploys new tasks if and only if: (i) there exists at least one task in its waiting queue, and (ii) all tasks in the previous turn have been finished and the node is ready for releasing resources for deploying new tasks. Since a node loads all tasks assigned to it in each turn and tasks are executed concurrently, and all fog nodes are controlled (i.e., they can be synchronized) by the fog orchestration node, the response time of an application can be estimated as follows: Given this mechanism, the next subsection presents in detail the estimation of each time component, namely, , based on the available CPU, memory, and communication resources of the destination node (where the task will be deployed on) and the corresponding resource requirement from the task. 4.3.2. Estimating Deployment Time () In this work we assume that if a task is deployed on the cloud R, it can be deployed immediately as the resource on the cloud is always available on demand. Therefore, the deployment of the task is accountable when is deployed on the fog landscape. This time is calculated in equation (6): where (i) is the time the task spends on the waiting queue of the neighbor fog colony , if it is assigned to the neighbor colony (i.e., ) is the time the task spends on the waiting queue of the fog orchestration node , if it is assigned to the fog orchestration node (i.e., ) (ii) is the time the task spends on the waiting queue of a fog node , if it is assigned to this node (i.e., ). In order to estimate , the fog orchestration node examines the historical data collected from N during previous execution turns. Supposing that at node N, m turns have passed, then is calculated in equation (7): where (i) is the amount of time passed after the turn had finished (i.e., the fog node in N has run its current turn for time unit (s); see Figure 2 for more details).    Figure 2  Estimation of the task’s waiting time at the neighbor fog colony N, . (ii) is the average duration (i.e., the total time a node spends on a turn for deploying, executing tasks and releasing resources) of a turn calculated from the previous m turns and is calculated by the following equation: where is the waiting length (duration) of the turn m. reflects the sensitivity of the approximation. If approaches 1, the approximation tends to rely much on the recent duration of the last turn. On the other hand, if approaches 0, the approximation tends to rely on the previous approximation on historical data. Obviously, and can also be calculated using this method. However, tasks are given beforehand, expected to be executed in a single turn, and there is no new task or application generated during the execution; it is reasonable to set . Consequently, equation (6) can be rewritten as in 4.3.3. Estimating Execution Time () Execution time or makespan time is the time required to execute the task given the CPU power of the node where the task is deployed. This time is calculated in the following equation: where , and are the execution times if the task is deployed at the fog orchestration node F, fog node f under the control of F (e.g., ), the neighbor fog colony N, and the cloud R, respectively. These times are calculated as follows. Let p be the selected node where the task will be deployed; the execution time is calculated in accordance with compute capacity (i.e., CPU power) of p, denoted as , which is the maximum number of (million) instructions per second (or MIPS) that this node can spend on running tasks (other compute capacity which has to be used for other operations such as transferring data is set aside and will not be considered in here). It should be noted that if p is a node on the considering colony (i.e., F, ), the is available to the considering orchestration node F. If p represents the cloud (i.e., R), in this case the task must be deployed on the cloud due to the time constraint; the cloud-based compute resource is required adequately to complete the task on time. Therefore, the orchestration node F is not responsible for estimating this resource. As a result, the execution time in equation (10) can be rewritten as in the following equation: Besides the compute capacity , execution time of a task is also affected by the task size, denoted as , which is measured by the number of (million) instructions to be executed (denoted as MI). This size is directly calculated by the fog orchestration node F and can be used as an explicit input for computation resource requirement. Our target is to reduce the execution time of the task as much as possible; thus the computation capacity of the node must be fully used. To do so, assume that at every turn m the node p has a set of tasks to execute . We assign the computation capacity proportionally to each task in accordance with tasks’ sizes. More formally, the amount of computation capacity assigned to task is presented in the following equation: Consequently, the execution time of task is calculated in the following equation: Since compute resource is proportionally divided to tasks based on their sizes, all tasks in the same turn (deployed on the same node) will have the same execution time regardless of their sizes. From (12) and (13) the execution time of a task can be rewritten in Since a fog colony executes all tasks assigned to it within a single turn, we can clarify the execution time of a task when it is deployed at the orchestration fog node F, at a regular fog node f, and when it is propagated to the neighbor colony N as follows. (i) Estimating the Execution Time and , When Is Deployed on the Considering Colony. According to equation (14), and can be clarified as in equations (15) and (16), respectively: (ii) Estimating the Execution Time When the Task Is Deployed on the Neighbor Colony N. Obviously, cannot be directly calculated as the same way as the calculation for and mentioned above since the orchestration node F does not have information about other tasks that are currently running on the neighbor colony N. In order to overcome this difficulty, we proposed to estimate through historical data from previous executions on N. Suppose that there were k tasks executed on N previously, the can be estimated in where is the average execution time of tasks from the 1st task to the th task and is defined in where (i) is the execution time of the th task which has been done at the colony N (ii) is the average execution time of tasks from the 1st task to the th task (iii) is a predefined parameter which reflects the weight of the execution time of recent moving tasks. 4.3.4. Estimating Communication Time () In order to estimate the communication time we need to model the networked resources in our proposed 3-tier architecture. We denote the system as an undirected graph G=(V,E), where is the set of vertices representing the physical elements that consist of the cloud (R), fog orchestration node (F) of each fog colony, and fog cells (), E is the set of physical connections between two vertices in the graph. Formally, the set of connections (links) in the network topology can be represented in where is the set of physical connections between the orchestration node and the fog cells in the colony k. is the number of fog cells in the considered colony k, is the set of physical connections between the orchestration node of the colony k and its neighbors. is the number of fog neighbors of the considered colony k, is the physical connection between the orchestration node of the colony k and the cloud, b is the maximum throughput of the considered link when data is transferred, and is the propagation delay of the considered physical link. As a result, when the task is distributed from the orchestration node to an appropriate node (i.e., F, f, N, or R), the communication time is calculated in where are one-way latencies when the task is deployed on f, N, or R, respectively. It should be noted that the communication time is the double of this one-way latency and the latency when the task is deployed on F (namely, ) is 0; hence it does not appear in equation (20). For any p representing any type (f, N, or R), is calculated in where are the communication times of task caused by the transportation, propagation, and queuing times, respectively. This work assumes that the queuing time is 0. is the amount of data (in Byte) of the task that need to be transferred on the considered link. It should be noted that reaching this stage all the deployment time, makespan time, and communication time () of the task have been thoroughly estimated. They can be applied to equation (5) in Section 4.3.1 to estimate the response time of an application, . 4.3.5. Memory Constraint In order to deploy a task on an appropriate node p, the memory constraint must be satisfied as shown in where is the memory required to executing the task (Bytes). It is assumed that this value can be estimated by the corresponding orchestration node F. is the memory capacity of node p (Bytes). It should be noted that the corresponding orchestration node F can examine of any fog cell f belonging to its colony. Meanwhile, the orchestration node of the neighbor colony N must notify to F its available memory . The memory on the cloud always satisfies the required memory of the deployed tasks. 5. Evaluation The main purpose of the evaluation is to verify the effectiveness of the proposed approach in terms of reducing of latency, energy consumption, and network load, while increasing the utilization of virtualized resources available on the fog landscape, thus mitigating the operational costs in comparison with the conventional cloud computing model. We have conducted various experiments using simulations including those simulating task distribution problems in real world applications that we are building for a smart city system such as the ITS in Ho Chi Minh City. 5.1. Experiment Environment In order to evaluate the optimized task distribution model presented in Section 4, we need to describe several experimental variables as follows. (i) Network topologies and resource description: We use iFogsim [ 32] to generate various network topologies associated with their devices’ resource description such as fog colonies, the orchestration node of a specific colony, fog cells in a fog colony associated with their CPU, memory capacities, and the network bandwidth as well as the propagation delays on each link between two physical nodes in the considered topology. (ii) Application composition and resource requirement by tasks: In order to describe applications and tasks we have analyzed several real world applications such as the ITS that we are building for Ho Chi Minh City. We analyzed application composition (which tasks are composed in a specific application) and the resource required by each task (the memory and CPU capacities and the size of each task) as well as the reasonable deadline required by each application in the ITS applications. Concrete examples for these descriptions are presented in the next subsection that describes different application scenarios. (iii) Optimize task placement on the fog landscape: In order to solve the optimization problem of task placement on the fog landscape proposed in Section 4, we implemented a program for optimization problem solving leveraging the IMB CPLEX solver [ 33]. The result is an optimal placement plan which is used to (i) analyze the network performance and (ii) redeploy on the considering network topology using iFogsim [ 32] to verify the network performances. 5.2. Experimental Results As discussed, energy consumption reduction, fog device utilization, and cost saving as functions of application complexities (i.e., number of applications, number of tasks in each application, and resources required by each task) and network topologies (number of fog nodes and the capacity of each node) have been thoroughly evaluated through experiments on general scenarios and real world applications. 5.2.1. Evaluation on General Scenarios In this section, we evaluate how the proposed approach works to provide task placement plans on different situations in terms of network topologies and applications (including tasks) to be processed on each network topologies. We have simulated 28 different network topologies (configurations), each of which has a structure as follows: one orchestration node F, several fog cells controlled by F, one neighbor colony N, and a data center on the cloud. Table 2 depicts an example of a configuration that consists of 1 colony with 4 fog cells managed by an orchestration node F connecting with a neighbor colony N and the cloud R. Table 2  Configuration of the general network topology. In our simulations, the requirements of network topologies are randomly selected with reasonable constraints. In order to ensure the diversity of the simulations, various parameters have been varied as summarized in Table 3. Each configuration is deemed to deploy several applications varying from 1 to 6, each of which consists of 1 to 8 tasks. Each application and task are varied by the required deadline (min, average, and max values are shown in the table) and the required CPU (to which the response time of each task can be inferred in accordance with network topologies and deployment plans), respectively. Network topologies are varied by the number of fog cells (f) in the considering colony which is ranged from 1 to 4. Fog cell is characterized by three parameters, namely, the CPU capacity, delay, and energy consumption as shown in the table. Table 3  Summary of simulation scenarios. We have conducted 28 different scenarios and collected information of 65 applications in total with variants mentioned above. The above summary of scenarios is also illustrated in Figure 3. The figures show application deadlines, node’s CPU, task’s CPU and number of tasks, applications, and nodes with regard to network configurations. Figure 3(a) shows the number of applications, number of tasks need to be deployed, and the number of fog nodes in each network topology in the 28 scenarios. In addition, as a general rule, the available resources of a topology have to be greater than those required by planned applications. While the average node delay is less than the average application deadline in Figure 3(b) to allocate time slots for executing applications, the application CPU is intersected by node CPU because in the worst case tasks could be deployed to the cloud (see Figure 3(c)). An example of application composition is illustrated in Table 4. Table 4  Applications associated with tasks deployed on the 3-tier architecture.   (a) The number of applications, tasks, and nodes       (a) The number of applications, tasks, and nodes  (b) Average application deadline and node delay  (c) Average application CPU and node CPU       Figure 3  Simulation configurations. As presented, each network configuration consists of 4 to 7 nodes to deploy 1 to 6 applications, each of which is composed of 1 to 8 tasks. As a result, the maximum number of variables in each topology is ; it ensures that the CPLEX resolver is able to produce the results. Other apparent constraints include , , . Obviously, in order to satisfy these constraints accompanied with the objective function presented in equation (3), Section 4.2, each simulation takes into account context about location, network condition, service type, and expected response time collected at the starting time of each placement turn. We have solved the optimization problem of task placement on fog landscape and applied the task distribution plan on the given network topology to evaluate the effectiveness of the proposed approach in terms of satisfying deadline requirement, energy consumption reduction, fog utilization, and cost saving compared to the cloud based approach. The results are presented and analyzed as follows. Deadline Satisfaction. As we have analyzed, one of the advantages of the proposed 3-tier architecture is its capability of utilizing the locally available resources on the fog landscape for computing tasks; hence it can reduce the communication times (compared to the cloud-based approach) providing more chances to satisfy the required application deadlines. In these evaluations, the response time, r of each application is estimated using the model presented in equation (5), while the response time of each task is estimated using equation (4), Section 4.3.1. For simplicity, without losing the generality of the response time estimating model, the deployment time at each fog node is ignored (), while the execution time () and the communication time () are calculated using equations (10) and (20), respectively, using data provided in Tables 2 and 4. After estimation, is compared with the corresponding deadline provided in Table 4. The comparison results are presented in Figure 4.    Figure 4  Response times in the proposed 3-tier architecture compared with the conventional cloud approach extracted from 65 applications. As shown, around 57% of the applications miss the deadline if they are processed on the cloud. Meanwhile, no application in the proposed 3-tier approach misses the deadline. It should be noted that there are some cases the response times in the proposed approach are larger than the cloud-based ones (both of them satisfy the deadlines). These situations occur when applications consisting of heavy tasks (i.e., tasks require a large number of processing instructions) are deployed on fog nodes with low computational power. Fog Landscape Utilization. Figure 5 shows an effective utilization of the virtual resources available on the fog landscape in our proposed method. Among 28 configurations (consisting of 65 applications), there is only one configuration that involves the cloud revealing that more than 95% of configurations the applications are fully processed on the fog landscape (without using any cloud-based resource). An interesting point here is that applications are firstly attempted on the fog orchestration node, then on fog cells, then on the neighbor colony, and finally on the cloud. Obviously, the communication time needed for applications to be deployed on the fog orchestration node is 0, and the computation power of this node is commonly much more powerful than those of fog cells; in many cases tasks are referred to be and successfully be deployed on this node. It is also worth to be noticed that, in the cases when cloud resources are involved, only 15% of such resources are required; the remained resources come from the fog landscape.    Figure 5  Utilization of the fog landscape. Energy Consumption Reduction. We also evaluated the energy saving by the proposed architecture and the results are depicted in Figure 6. In most of the cases the proposed architecture saves more than 80% of the energy compared to that of the cloud-based approach. There are only 2 cases among 28 configurations (i.e., 7%); the energy consumption in our proposed method is comparable or a little bit higher than that of the cloud-based method. This is because the main objective of our approach is to maximize the task deployment on the fog landscape when the estimated response time still satisfies the required deadline although the computation time is higher than the case that tasks are processed on the cloud. However, as mentioned, these situations are rare (only 7%) and in fact (in most of the cases) the proposed 3-tier architecture provides benefits in both the response time (computation and communication times) and the energy saving.    Figure 6  Energy consumption in the proposed scheme compared with the cloud-based approach. Cost Saving. Figure 7 reveals the effectiveness of the proposed method in terms of cost saving. As analyzed before, in most of configurations applications are fully deployed on the fog landscape (see Figure 5); no renting cost is required for cloud services in these cases. Cost incurs only in one configuration (configuration 15) when some of cloud resources are required.    Figure 7  Cost saving in the proposed method. 5.2.2. Verification under the Real World ITS Application The communications infrastructure in HCMC is not designed for a specific application such as the ITS. Meanwhile, we could not redesign the network infrastructure physically. Instead, we applied the proposed model to realize the fog computing paradigm, solving the problem of task placement, thus improving the performance of the ITS that we are building for Ho Chi Minh City. In this work we have designed the system with the following principles. (i) Decentralization: The whole system is geographically partitioned into small autonomy regions, each of which is considered a fog colony operating independently with a minimized interference from a “central light-weight controller” (normally a high-end server or a data center). This principle mitigates global communications to lessen the impact of poor connections. Moreover, the autonomy regions help to strengthen the system’s availability and fault tolerance. (ii) Localization: Computing resources are distributed across local regions deployed close to data sources; hence the data can be processed locally without invoking many parts of the system. This principle guarantees instant responses even in the context of low and unstable connections. This localization also allows us to provide qualified services at low cost by efficiently utilizing computation resources already available at the network edges. Besides helping to save the high cost of renting computation and storage resources from the cloud, these edge-based devices commonly consume less energy compared to that of data centers on the cloud when processing the same tasks. We apply principles mentioned above in our ITS system in accordance with the proposed 3-tier architecture with 3 layers, namely, cloud, fog, and IoT devices. We partition the whole city into smaller areas and deploy a fog colony on each area (formed by a group of multiple fog nodes) to handle data and services related to the considered areas such as to estimate the average velocity of a traffic flow on a specific road segment on the considered area. The organization of a fog colony is followed with the designs on the proposed 3-tier architecture presented in Section 4. Each fog colony maintains connection to one (or more) neighbor colony. If the fog colony is overloaded, it moves some tasks to its neighbor and/or to the cloud. We designed a testbed for emulating our model with the configuration described in Table 5. Note that we use 2 physical machines with Intel Core i7-4790 @ 3.60GHz CPU, 4GB memory and running on Ubuntu 16.04 (64-bit); each machine emulates one fog colony. Concretely, we deploy 1 orchestration node and 3 other fog nodes, each of which is emulated by a single virtual machine, to describe the detailed configuration of a specific colony. The other machine is used to simulate the neighbor colony of the above colony. The fog colonies connect to a data center (cloud) at Ho Chi Minh City University of Technology’s high performance computing center (30 km apart from the fog nodes mentioned above). The data center is deployed with 2 CPU Intel Xeon E5-2680v3 @ 2.15GHz x 24 CPU and 128GB memory. The connection between fog nodes is emulated by Mininet and the configuration of this topology is described as follows. Table 5  Configuration of the network topology in the ITS testbed. In this work, we select two representative applications among many ITS applications for analysis as follows. (i) Analyzing traffic flow: Given a set of GPS signal from vehicles traveling on a road segment, estimate the average velocity and the density of the considered traffic flow. (ii) Traffic light control: Given a traffic light currently at the beginning of its color phase (that is the sequence of the green, red, and yellow lights), set the duration of each light’s color for the next phase appropriately with the traffic condition. Table 6 shows parameters associated with each application mentioned above. Table 6  ITS’s applications and associated tasks. As presented, each application above is composed of a single task. However, many of similar applications can run concurrently on the same colony (i.e., each application is applied for one road segment in the region covered by the considered colony). We have solved the optimization problem of task placement on fog landscape to this real world application design. Then, we applied the task distribution plan on the given network topology to evaluate energy consumption reduction, fog utilization, and cost saving of the proposed method compared to the cloud-based approach. As shown in Table 7, the proposed approach in the 3-tier architecture is significantly more effective compared to the cloud computing counterpart, in all of the three factors (deadline missing rate, energy consumption, and cost). The deadline missing rate in the proposed method is 0% while it is more than 50% in the cloud approach, mainly because of communication latency. As for the energy consumption, when more tasks are deployed on the cloud the energy consumption is large as the cloud-based servers must be up waiting for the arrival of tasks (which are delayed due to upward communication latencies). For example, in the last row, the energy consumptions in the proposed method and the cloud approach are 448.8 (J) and 3318.4 (J), respectively, which are significantly different. The last column shows the cost for renting computing services on the cloud, while the cost on our proposed approach is 0 as the virtual resources available on the network edges are utilized. It should be noted that the cloud service cost is calculated in accordance with the cloud service renting model described in [ 34, 35]. Table 7  Effectiveness of the proposed 3-tier scheme compared with the cloud-based approach in the real-world ITS applications. 6. Discussion This work directly focuses on the feasibility of the optimization on task provision on fog landscape to improve the capacity of fog computing paradigm. In order to reach this target, we have thoroughly analyzed and modeled applications, tasks associated with their required resources, and network configurations with their resource capacity to clarify concrete constraints on the proposed optimization model. The proposed approach is more effective and robust than the existing approaches in terms of practical realization, energy, and cost reduction by means of maximizing the utilization of fog computing paradigm. However, further improvements should be considered. Orchestration node selection: In the current design and prototype, the orchestration node is statically decided in advance based on their computation and storage capacities. As fog devices may die due to energy shortage, a dynamic fog orchestration election model should be thoroughly investigated. This model could be useful for IoT environment with mobile devices. Nontree based structure: The 3-tier architecture is composed based on a tree-based structure which helps to simplify the network management. However, this may danger the network as it is vulnerable to orchestration node failure. As discussed before, when orchestration nodes can be elected dynamically and if this approach is extended thereby every node can serve as an orchestration node if it satisfies some criteria then the architecture in the fog landscape could become “flat." In this sense, the system is more tolerant with node failures but it could be complicated for network management and for task distribution. Task distribution: In this work, task distribution is handled by orchestration nodes. The inherent limitation here is that each orchestration node can obtain only local information about fog nodes in its colony and limited information from its neighbor colonies, rather than examining a global view of the whole network; hence global optimization is not achieved. SDN/Openflow [ 36] based approaches can help to achieve global optimization by the capability of collecting global network statistics from the Controller. There is a potential direction to apply SDN approach for dynamic task provision in the proposed 3-tier architecture. Task dependencies: In this work, tasks composing an application are assumed to be executed simultaneously to make the proposed 3-tier architecture combining with context-aware service placement viable, before going further. It should be noted that, however, in the IoT applications, the degree of parallelism and dependencies between tasks could be complicated. Therefore, similar to the dynamic of context update the dependence degrees between tasks could also dynamically change. Context-aware service placement in large-scale IoT environments with multiple dependence degrees between tasks is a challenge but potential research direction for our future work which can be developed from this paper. 7. Conclusion In this article, we have proposed a novel approach to task placement on fog computing made efficient for IoT application provision where a systematical fog computing framework consisting of multiple intelligent tiers for the IoT has been introduced and a context-aware task provision mechanism in the fog has been devised. The proposed approach optimally utilizes virtual resources available on the network edges to improve the performance of IoT services in terms of response time, energy, and cost reduction. The experimental results from both simulated data and data summarized from service deployments in real-world applications, namely, the ITS in Ho Chi Minh City which we are building, show the effectiveness of the proposed approach in terms of maximizing the utilization of fog devices while reducing latency, energy consumption, network load, and operational cost. These results confirm the robustness of the proposed scheme revealing its capability to maximize the IoT potential. In the future, we are planning to implement this method in real applications to support the process of realizing large-scaled IoT applications, smart city ecosystems. Data Availability The [simulated evaluation] data used to support the findings of this study are included within the article. Conflicts of Interest The authors declare that there are no conflicts of interest regarding the publication of this paper. Acknowledgments This research is funded by Vietnam National Foundation for Science and Technology Development (NAFOSTED) under grant number 102.01-2016.28. References Y. Nan, W. Li, W. Bao, F. C. Delicato, P. F. Pires, and A. Y. Zomaya, “Cost-effective processing for Delay-sensitive applications in Cloud of Things systems,” in Proceedings of the 15th IEEE International Symposium on Network Computing and Applications, NCA 2016, pp. 162–169, Cambridge, Mass, USA, November 2016. View at: Google Scholar F. Bonomi, R. Milito, J. Zhu, and S. Addepalli, “Fog computing and its role in the internet of things,” in Proceedings of the 1st ACM Mobile Cloud Computing Workshop, MCC 2012, pp. 13–15, Helsinki, Finland, August 2012. View at: Publisher Site | Google Scholar A. V. Dastjerdi, H. Gupta, R. N. Calheiros, S. K. Ghosh, and R. Buyya, Fog Computing: Principles, Architectures, and Applications, Internet of Things: Principles and Paradigms, chap. 4. Morgan Kaufmann, 2016. S. Sarkar, S. Chatterjee, and S. Misra, “Assessment of the Suitability of Fog Computing in the Context of Internet of Things,” IEEE Transactions on Cloud Computing, vol. 6, no. 1, pp. 46–59, 2015. View at: Publisher Site | Google Scholar D. Miorandi, S. Sicari, F. de Pellegrini, and I. Chlamtac, “Internet of things: vision, applications and research challenges,” Ad Hoc Networks, vol. 10, no. 7, pp. 1497–1516, 2012. View at: Publisher Site | Google Scholar J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of Things (IoT): a vision, architectural elements, and future directions,” Future Generation Computer Systems, vol. 29, no. 7, pp. 1645–1660, 2013. View at: Publisher Site | Google Scholar M. Bertier, F. Desprez, G. Fedak et al., “Beyond the cloud, how should next generation utility computing infrastructures be designed?” in Cloud Computing. Computer Communications and Networks, Z. Mahmood, Ed., pp. 325–345, Springer, 2014. View at: Google Scholar L. M. Vaquero and L. Rodero-Merino, “Finding your way in the fog: towards a comprehensive definition of fog computing,” ACM SIGCOMM Computer Communication Review Archive, vol. 44, no. 5, pp. 27–32, 2014. View at: Publisher Site | Google Scholar M. Aazam and E. N. Huh, “Fog Computing Micro Datacenter Based Dynamic Resource Estimation and Pricing Model for IoT,” in Proceedings of the IEEE 29th International Conference on Advanced Information Networking and Applications (AINA '15), pp. 687–694, IEEE, Gwangiu, South Korea, March 2015. View at: Publisher Site | Google Scholar S. Yi, Z. Hao, Z. Qin, and Q. Li, “Fog computing: Platform and applications,” in Proceedings of the 3rd Workshop on Hot Topics in Web Systems and Technologies, HotWeb 2015, pp. 73–78, Washington, DC, USA, November 2015. View at: Publisher Site | Google Scholar OpenFog Consortium, 2018, https://www.openfogconsortium.org/. OpenFog Consortium Architecture Working Group, OpenFog Reference Architecture for Fog Computing, technical report [PhD thesis], 2017. R. S. Montero, E. Rojas, A. A. Carrillo, and I. M. Llorente, “Extending the Cloud to the Network Edge,” The Computer Journal, vol. 50, no. 4, pp. 91–95, 2017. View at: Publisher Site | Google Scholar C. C. Byers, “Architectural Imperatives for Fog Computing: Use Cases, Requirements, and Architectural Techniques for Fog-Enabled IoT Networks,” IEEE Communications Magazine, vol. 55, no. 8, pp. 14–20, 2017. View at: Publisher Site | Google Scholar P. Hoenisch, I. Weber, S. Schulte, L. Zhu, and A. Fekete, “Four-fold Auto-Scaling on a Contemporary Deployment Platform using Docker Containers,” in Proceedings of the 13th International Conference on Service Oriented Computing (ICSOC 2015), vol. 9435 of Lecture Notes in Computer Science, pp. 316–323, Springer, 2015. View at: Publisher Site | Google Scholar P. Leitner, W. Hummer, B. Satzger, C. Inzinger, and S. Dustdar, “Cost-efficient and application SLA-aware client side request scheduling in an infrastructure-as-a-service cloud,” in Proceedings of the 2012 IEEE 5th International Conference on Cloud Computing, CLOUD 2012, pp. 213–220, USA, June 2012. View at: Google Scholar H. T. Dinh, C. Lee, D. Niyato, and P. Wang, “A survey of mobile cloud computing: Architecture, applications, and approaches,” Wireless Communications and Mobile Computing, vol. 13, no. 18, pp. 1587–1611, 2013. View at: Publisher Site | Google Scholar N. Fernando, S. W. Loke, and W. Rahayu, “Mobile cloud computing: a survey,” Future Generation Computer Systems, vol. 29, no. 1, pp. 84–106, 2013. View at: Publisher Site | Google Scholar Y.-J. Yu, T.-C. Chiu, A.-C. Pang, M.-F. Chen, and J. Liu, “Virtual machine placement for backhaul traffic minimization in fog radio access networks,” in Proceedings of the IEEE International Conference on Communications (ICC), pp. 1–7, 2017. View at: Google Scholar L. Gu, D. Zeng, S. Guo, A. Barnawi, and Y. Xiang, “Cost efficient resource management in fog computing supported medical cyber-physical system,” IEEE Transactions on Emerging Topics in Computing, vol. 5, no. 1, pp. 108–119, 2017. View at: Publisher Site | Google Scholar H. J. Hong, P. H. Tsai, and C. H. Hsu, “Dynamic module deployment in a fog computing platform,” in Proceedings of the 18th Asia-Pacific Network Operations and Management Symposium, APNOMS 2016, pp. 1–6, Japan, October 2016. View at: Google Scholar J. Xu, B. Palanisamy, H. Ludwig, and Q. Wang, “Zenith: Utility-Aware Resource Allocation for Edge Computing,” in Proceedings of the 1st IEEE International Conference on Edge Computing, EDGE 2017, pp. 47–54, USA, June 2017. View at: Google Scholar V. B. Souza, W. Ramirez, X. Masip-Bruin, E. Marin-Tordera, G. Ren, and G. Tashakor, “Handling service allocation in combined Fog-cloud scenarios,” in Proceedings of the ICC 2016 - 2016 IEEE International Conference on Communications, pp. 1–5, Kuala Lumpur, Malaysia, May 2016. View at: Publisher Site | Google Scholar O. Skarlat, S. Schulte, M. Borkowski, and P. Leitner, “Resource provisioning for IoT services in the fog,” in Proceedings of the 9th IEEE International Conference on Service-Oriented Computing and Applications, SOCA 2016, pp. 32–39, China, November 2016. View at: Google Scholar O. Skarlat, M. Nardelli, S. Schulte, and S. Dustdar, “Towards QoS-Aware Fog Service Placement,” in Proceedings of the 1st IEEE International Conference on Fog and Edge Computing, ICFEC 2017, pp. 89–96, IEEE, Madrid, Spain, 2017. View at: Publisher Site | Google Scholar 2018, http://parasol.cs.rutgers.edu/. T. M. Quang, D. T. Nguyen, A. Van Le, H. D. Nguyen, and A. Truong, “Toward service placement on Fog computing landscape,” in Proceedings of the 4th NAFOSTED Conference on Information and Computer Science, pp. 291–296, Hanoi, Vietnam, 2017. View at: Google Scholar V. Akman, Context in Artificial Intelligence: A Fleeting Overview, McGraw-Hill, Milano, Italy, 2002. P. Bouquet, C. Ghidini, F. Giunchiglia, and E. Blanzieri, “Theories and uses of context in knowledge representation and reasoning,” Journal of Pragmatics, vol. 35, no. 3, pp. 455–484, 2003. View at: Publisher Site | Google Scholar A. K. Dey, “Understanding and using context,” Personal and Ubiquitous Computing, vol. 5, no. 1, pp. 4–7, 2001. View at: Publisher Site | Google Scholar T. T. Do, P. H. Phung, and T. M. Quang, “Toward An IoT-based Expert System for Heart Disease Diagnosis,” in the 28th Modern Artificial Intelligence and Cognitive Science Conference (MAICS), pp. 157–164, Fort Wayne, Ind, USA, 2017. View at: Google Scholar H. Gupta, A. V. Dastjerdi, S. K. Ghosh, and R. Buyya, “iFogSim: A Toolkit for Modeling and Simulation of Resource Management Techniques in Internet of Things, Edge and Fog Computing En-vironments,” Tech. Rep. CLOUDS-TR-2016-2, Cloud Computing and Distributed Systems Laboratory, The University of Melbourne, 2016. View at: Google Scholar IBM CPLEX Optimizer, 2018, https://www.ibm.com/analytics/data-science/prescriptive-analytics/cplex-optimizer. I. Pietri, G. Juve, E. Deelman, and R. Sakellariou, “A performance model to estimate execution time of scientific workflows on the cloud,” in Proceedings of the 9th Workshop on Workflows in Support of Large-Scale Science, WORKS 2014, pp. 11–19, New Orleans, LA, USA. View at: Google Scholar Elastic Compute Cloud (EC2), 2018, https://aws.amazon.com/ec2/pricing/on-demand/. N. McKeown, T. Anderson, H. Balakrishnan et al., “OpenFlow: enabling innovation in campus networks,” Computer Communication Review, vol. 38, no. 2, pp. 69–74, 2008. View at: Publisher Site | Google Scholar Copyright Copyright © 2019 Minh-Quang Tran et al. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. PDF Download Citation Download other formats Order printed copies Views 6090 Downloads 2494 Citations 70 About Us Contact us Partnerships Blog Journals Article Processing Charges Print editions Authors Editors Reviewers Partnerships Hindawi XML Corpus Open Archives Initiative Fraud prevention Follow us: Privacy PolicyTerms of ServiceResponsible Disclosure PolicyCookie PolicyCopyrightModern slavery statementCookie Preferences

Paper 3:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: Highly relevant
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: The main objective of the paper is to explore how automated systems are being used for real-time irrigation management and the potential of edge computing and fog computing in this domain. The paper reviews the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The specific section mentioned in the prompt focuses on the potential of edge computing and fog computing in real-time irrigation management. Key research gaps and future research directions are also identified.

 Full Text: >


Citation: Angel, N.A.; Ravindran, D.;
Vincent, P.M.D.R.; Srinivasan, K.;
Hu, Y.-C. Recent Advances
in Evolving Computing Paradigms:
Cloud, Edge, and Fog Technologies.
Sensors 2022, 22, 196. https://
doi.org/10.3390/s22010196
Academic Editors:
Robertas Damaševiˇcius, M. Poongodi,
Haﬁz Tayyab Rauf and Hasan
Ali Khattak
Received: 6 December 2021
Accepted: 23 December 2021
Published: 28 December 2021
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright:
© 2021 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
sensors
Review
Recent Advances in Evolving Computing Paradigms: Cloud,
Edge, and Fog Technologies
Nancy A Angel 1
, Dakshanamoorthy Ravindran 1, P M Durai Raj Vincent 2
, Kathiravan Srinivasan 3
and Yuh-Chung Hu 4,*
1
Department of Computer Science, St. Joseph’s College (Autonomous), Bharathidasan University,
Tiruchirappalli 620002, India; angelnancy_phdcs@mail.sjctni.edu (N.A.A.);
ravindran_cs1@mail.sjctni.edu (D.R.)
2
School of Information Technology and Engineering, Vellore Institute of Technology, Vellore 632014, India;
pmvincent@vit.ac.in
3
School of Computer Science and Engineering, Vellore Institute of Technology, Vellore 632014, India;
kathiravan.srinivasan@vit.ac.in
4
Department of Mechanical and Electromechanical Engineering, National ILan University, Yilan 26047, Taiwan
*
Correspondence: ychu@niu.edu.tw
Abstract: Cloud computing has become integral lately due to the ever-expanding Internet-of-things
(IoT) network. It still is and continues to be the best practice for implementing complex computational
applications, emphasizing the massive processing of data. However, the cloud falls short due to
the critical constraints of novel IoT applications generating vast data, which entails a swift response
time with improved privacy. The newest drift is moving computational and storage resources to
the edge of the network, involving a decentralized distributed architecture. The data processing
and analytics perform at proximity to end-users, and overcome the bottleneck of cloud computing.
The trend of deploying machine learning (ML) at the network edge to enhance computing applications
and services has gained momentum lately, speciﬁcally to reduce latency and energy consumed while
optimizing the security and management of resources. There is a need for rigorous research efforts
oriented towards developing and implementing machine learning algorithms that deliver the best
results in terms of speed, accuracy, storage, and security, with low power consumption. This
extensive survey presented on the prominent computing paradigms in practice highlights the latest
innovations resulting from the fusion between ML and the evolving computing paradigms and
discusses the underlying open research challenges and future prospects.
Keywords: cloud computing; edge computing; fog computing; internet-of-things; machine learning
1. Introduction
There has been a signiﬁcant progression of computing paradigms during recent
decades. Cloud computing is perhaps the most well-established, which emerged from
the requirement of harnessing “computing as a utility”, enabling the rapid growth of new
internet services [1]. The arrival of the Internet of Things (IoT) paved the way for vast data
generation, eventually leading to big data [2]. Cloud computing was a hot research area
until the widespread use of the Internet of Things disclosed all of the centralized paradigm’s
ﬂaws [1]. With cloud-based deployment, cloud data centers manage the analyzing, storing,
and decision-making of data. As the data volume along with the velocity surged, trans-
ferring the big data brought forth by IoT devices to the cloud became inefﬁcient, owing
to bandwidth constraints, and would not meet the time-sensitive and ultra-low latency
demands of applications and could raise privacy concerns as well.
The scope of IoT has broadened since its advent and speciﬁes a digital interconnection
of devices and objects, capable of procuring and sharing information across platforms for
added value [3]. The proliferation of IoT is consorted by an increased capacity, reduced
Sensors 2022, 22, 196. https://doi.org/10.3390/s22010196
https://www.mdpi.com/journal/sensors
Sensors 2022, 22, 196
2 of 38
communication cost, and astounding technological development. IoT warrants not just
device data management, but also information exchange among multidisciplinary plat-
forms. The huge data procured from numerous smart devices entails sharing to add value
and a comprehensive understanding of the concerned domain. With collaborative IoT,
heterogeneous domains and settings enable sensors, gateways, and services to collaborate
at various levels, enriching the quality of human life while improving business processes.
The IoT ecosystem extends in scale and complexity, encompassing a range of heteroge-
neous devices that stretch over several layers of IoT architecture. As IoT systems partake
in critical infrastructures, they necessitate resilient service operability [4]. IoT applications
are disparate, deployed in healthcare, industries, domotics, smart homes, smart cities,
smart transportation, etc. The IoT devices are constituted of small, resource-constrained
smart objects, ineffective at handling complex tasks, which entails task ofﬂoading to distant
cloud servers [5]. The limited storage and computing potential forces IoT devices to rely
on cloud data centers [6]. This ensues an increased latency, and the intermittent internet
connectivity renders IoT devices inept at managing time-critical real-time applications.
Thus, the IoT revolution has steered new research into decentralized models. In this
context, edge computing emerged, intending to bring cloud computing capability to the net-
work edge, addressing unfolding issues that cannot be ﬁxed by cloud computing solely,
such as latency, bandwidth, and connectivity challenges [7]. Correspondingly, numerous
edge computing solutions have been suggested, including Mobile Cloud Computing (MCC)
and Mobile Edge Computing (MEC) [8,9]. Fog computing surfaced as one of the highly
evolved Edge computing concepts. Fog computing aspires to represent a comprehensive
framework, allocating resources in sequence along the cloud to the smart devices [10].
Thus, it is not a mere cloud extension, as it actively engages in synergizing the cloud with
IoT. In addition, the requisite for sustainable/green computing that aids in conserving
energy is crucial to IoT devices. As IoT devices have energy limitations, it is vital to de-
vise energy-aware solutions into the future [11]. In parallel with technological progress,
it is imperative to cut back on the carbon footprint to limit environmental deterioration
alongside global warming [12]. The exploration of edge paradigms is at its budding phase,
and innovative viewpoints pertaining to these paradigms that arise in literature regularly
warrant extensive research [13].
Table 1 shows the list of acronyms used in this manuscript. Figure 1 shows the structure
of this survey.
Table 1. List of acronyms used in the manuscript and their expansion.
Acronym
Full Form
AI
Artiﬁcial Intelligence
AR
Augmented Reality
CoT
Cloud of Things
CC
Cloud Computing
CCTV
Closed-Circuit Television
CPU
Central Processing Unit
CR
Cloud Robotics
DDoS
Distributed Denial of Service
DL
Deep Learning
EC
Edge Computing
ETSI
European Telecommunications Standard Institute
FaaS
Function-as-a-Service
FC
Fog Computing
IaaS
Infrastructure-as-a-Service
ICT
Information and Communications Technology
IDC
International Data Corporation
IoT
Internet-of-Things
Sensors 2022, 22, 196
3 of 38
Table 1. Cont.
Acronym
Full Form
IT
Information Technology
ITS
Intelligent Transport System
ITU
International Telecommunication Union
MACC
Mobile Ad hoc Cloud Computing
MEC
Multi-access Edge Computing
MC
Mobile Computing
MCC
Mobile Cloud Computing
MDC
Micro Data Center
mist
Mist Computing
ML
Machine Learning
MMA
Man-in-the-Middle Attack
MIT
Massachusetts Institute of Technology
NIST
National Institute of Standards and Technology
OP
Operational Technology
PaaS
Platform-as-a-Service
PRISMA
Preferred Reporting Items for Systematic Reviews and
Meta-Analyses
QoE
Quality of Experience
QoS
Quality of Service
RAN
Radio Access Network
RAS
Reliability Availability Serviceability
SaaS
Software-as-a-Service
SDN
Software-Deﬁned Networking
SLA
Service-Level Agreement
VM
Virtual Machine
VR
Virtual Reality
WSN
Wireless Sensor Network
Sensors 2022, 22, x FOR PEER REVIEW 
3 of 41 
 
 
IaaS 
Infrastructure-as-a-Service 
ICT 
Information and Communications Technology 
IDC 
International Data Corporation 
IoT 
Internet-of-Things 
IT 
Information Technology 
ITS 
Intelligent Transport System 
ITU 
International Telecommunication Union 
MACC 
Mobile Ad hoc Cloud Computing 
MEC 
Multi-access Edge Computing 
MC 
Mobile Computing 
MCC 
Mobile Cloud Computing 
MDC 
Micro Data Center 
mist 
Mist Computing 
ML 
Machine Learning 
MMA 
Man-in-the-Middle Attack 
MIT 
Massachusetts Institute of Technology 
NIST 
National Institute of Standards and Technology 
OP 
Operational Technology 
PaaS 
Platform-as-a-Service 
PRISMA 
Preferred Reporting Items for Systematic Reviews and Meta-Analyses 
QoE 
Quality of Experience 
QoS 
Quality of Service 
RAN 
Radio Access Network 
RAS 
Reliability Availability Serviceability 
SaaS 
Software-as-a-Service 
SDN 
Software-Defined Networking 
SLA 
Service-Level Agreement 
VM 
Virtual Machine 
VR 
Virtual Reality 
WSN 
Wireless Sensor Network 
 
Figure 1. Organization of this survey paper. 
Figure 1. Organization of this survey paper.
2. Contribution of This Survey
The contribution of this survey is outlined as follows:
Sensors 2022, 22, 196
4 of 38
•
A comprehensive account of computing paradigms is rendered, especially cloud
computing, fog computing, edge computing, and how they are related to other similar
paradigms such as mist, cloudlet, MEC, etc.
•
A detailed illustration of the motives that instigated the evolution of edge/fog com-
puting and related paradigms is furnished.
•
A comparison of cloud, edge, and fog computing paradigms are presented and ML
convergence’s signiﬁcance with fog/edge is discussed.
•
A list of challenges and future research directions concerning computing paradigms is
devised.
2.1. Survey Methodology
We harnessed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses
(PRISMA) procedure to systematically choose the articles used in this survey.
2.1.1. Search Strategy and Literature Sources
For this review, articles pertaining to Evolving Computing Paradigms were searched
in Google Scholar, ScienceDirect, IEEE Xplore, ACM Digital Library, Wiley Online Library,
and Springer databases from January 2009 to January 2022.
The search string used in this study was (“Cloud computing” or “Edge computing”, or
“Fog computing” or “Internet-of-Things” or “Machine learning”) and collected 2360 articles.
2.1.2. Inclusion Criteria
The articles written and published in English between January 2009 and January
2022 on Evolving Computing Paradigms were included. This review includes relatively
new research.
2.1.3. Elimination Criteria
The articles published in languages other than English, from January 2009, including
case reports/case series, opinions, letters to the editor, commentaries, conference abstracts,
theses, and dissertations, were excluded from this review.
2.1.4. Results
Initially, from 2360 articles, duplicates found were removed and, after reviewing
the abstracts of these papers, 874 of them were selected for a full-text review. This study
included both journal and conference articles. After reviewing the full-text of these papers,
693 papers were excluded, as they used duplicate methods or were published earlier.
Finally, 181 papers were studied in this research. Figure 2 illustrates the selection procedure
of the articles for this study using a PRISMA diagram.
Sensors 2022, 22, 196
5 of 38
sors 2022, 22, x FOR PEER REVIEW 
5 of 41 
 
Figure 2. PRISMA flow diagram for the selection process of the research articles used in this 
review. 
The 181 articles studied in this research from 2009 to 2020 are depicted in Figure 3. 
 
Figure 3. Number and year of publications studied in this review. 
The review/survey papers analyzed in this study is elucidated in Table 2. 
Table 2. Review/survey papers and their contributions. 
uthor and 
Year 
Articles 
Referenced 
Time 
Span 
Systematic Study 
Survey/Review Outline 
Computing 
Paradigms 
Future Directions 
Cloud 
Computing 
Fog 
Computing 
Edge 
Computing 
tzori et al. 
[14], 2016 
119 
1999 
– 
2016 
× 
The survey examines the prospect of Internet-of-
Things from the evolutionary perspective, the role of 
IoT in modern society and ensuing challenges. 
✓ 
× 
✓ 
× 
Figure 2. PRISMA ﬂow diagram for the selection process of the research articles used in this review.
The 181 articles studied in this research from 2009 to 2020 are depicted in Figure 3.
Sensors 2022, 22, x FOR PEER REVIEW 
5 of 41 
 
 
 
Figure 2. PRISMA flow diagram for the selection process of the research articles used in this 
review. 
The 181 articles studied in this research from 2009 to 2020 are depicted in Figure 3. 
 
Figure 3. Number and year of publications studied in this review. 
The review/survey papers analyzed in this study is elucidated in Table 2. 
Table 2. Review/survey papers and their contributions. 
Author and 
Year 
Articles 
Referenced 
Time 
Span 
Systematic Study 
Survey/Review Outline 
Computing 
Paradigms 
Future Directions 
Cloud 
Computing 
Fog 
Computing 
Edge 
Computing 
Atzori et al. 
[14], 2016 
119 
1999 
– 
2016 
× 
The survey examines the prospect of Internet-of-
Things from the evolutionary perspective, the role of 
IoT in modern society and ensuing challenges. 
✓ 
× 
✓ 
× 
Figure 3. Number and year of publications studied in this review.
The review/survey papers analyzed in this study is elucidated in Table 2.
Table 2. Review/survey papers and their contributions.
Author and
Year
Articles
Referenced
Time Span
Systematic Study
Survey/Review Outline
Computing
Paradigms
Future Directions
Cloud
Computing
Fog
Computing
Edge
Computing
Atzori et al.
[14], 2016
119
1999
–
2016
×
The survey examines the prospect of Internet-of-Things
from the evolutionary perspective, the role of IoT
in modern society and ensuing challenges.
✓
×
✓
×
Hu et al. [15],
2017
123
2001
–
2017
×
The review presents fog computing features, architecture,
compares with other computing paradigms, and
summarizes key technologies that aid in application and
deployment.
✓
✓
✓
✓
Sensors 2022, 22, 196
6 of 38
Table 2. Cont.
Author and
Year
Articles
Referenced
Time Span
Systematic Study
Survey/Review Outline
Computing
Paradigms
Future Directions
Cloud
Computing
Fog
Computing
Edge
Computing
Mahmud et al.
[16], 2017
47
2012
–
2016
×
The work presents a taxonomy from a comprehensive
analysis of fog features and challenges pertaining to
the structure, service, and security and identiﬁes research
gaps.
✓
✓
✓
✓
Lin et al. [17],
2017
167
2001
–
2017
×
The article offers a comprehensive overview of
state-of-the-art IoT-enabling technologies, system
architecture, privacy, security issues, and concerns of IoT
and fog/edge computing integration during real-world
deployment.
×
✓
✓
✓
Mao et al. [18],
2017
242
2003
–
2017
×
An exhaustive outline of state-of-the-art MEC from
a communication viewpoint, resource management,
comparison with MCC is presented.
✓
×
✓
✓
Naha et al.
[19], 2018
142
2001
–
2018
×
The survey article presents fog computing overview,
architecture, related technologies, taxonomy by analyzing
fog requirement and reviewing challenges, research issues,
and trends.
✓
✓
✓
✓
Mouradian
et al. [20], 2018
168
2006
–
2017
✓
An exhaustive survey is tendered on fog computing
architectures, algorithms, afﬁliated concepts, and their
dissimilarities; additionally, challenges and research
directions were discussed.
×
✓
×
✓
Mukherjee
et al. [21], 2018
225
1997
–
2017
×
The survey extends an overview of fog computing basics,
architecture and highlights the approach for service and
allocation of resources to overcome latency, bandwidth,
and energy consumption.
×
✓
×
✓
Elazhary [22],
2018
412
1991
–
2018
×
The exhaustive review researches arenas such as IoT, cloud
computing, mobile computing, and related
concepts and attempts to disambiguate emerging
paradigms as well as technologies.
✓
✓
✓
✓
Atlam et al.
[23], 2018
63
2012
–
2017
×
This work reviews fog computing state-of-the-art,
including fog features, architecture, and merits, and insists
on fog being an IoT enabler.
×
✓
×
✓
Bangui et al.
[24], 2018
114
2012
–
2018
×
The review outlines edge computing technology and
the challenges and concerns that accompany
Distributed environments while shifting services from
cloud’s centralized to edge’s decentralized platforms.
×
✓
✓
✓
Yousefpour
et al. [2], 2019
450
2001
–
2018
×
A comprehensive survey is furnished that emphasizes fog
computing, associated computing
paradigms, and presents a taxonomy of research subjects,
underlying challenges, and future leanings of fog.
✓
✓
✓
✓
Abdulkareem
et al. [25], 2019
95
2011
–
2019
×
This review highlights recent advancements of ML
techniques related to the accuracy, resource management
and security of fog computing and its role in edge
computing.
×
✓
✓
✓
Donno et al.
[9], 2019
71
2004
–
2019
×
The review article offers clariﬁcation for beginners into
research on cloud computing, edge computing, and fog
computing by illustrating features and architecture of each
paradigm and concludes by stating fog computing’s
relevance as fog binds cloud, edge computing, and IoT
together.
✓
✓
✓
✓
Khan et al.
[26], 2019
101
2009
–
2019
×
The study focuses on cloud and state-of-the-art edge
computing concepts, critical requirements, limitations and
identiﬁed unaddressed issues.
✓
✓
✓
✓
Cao et al. [27],
2020
62
2005
–
2020
×
The article reviews research related to edge
computing, summarizes key concepts, technologies,
architecture, privacy, and security.
✓
×
✓
✓
Habibi et al.
[28], 2020
191
2002
–
2019
×
The survey covers existing computing paradigms and
emphasizes fog computing research areas by presenting
a taxonomy and analyses from fog’s architectural
viewpoint.
✓
✓
✓
✓
Moura et al.
[29], 2020
194
1999
–
2020
×
This work surveys state-of-the-art fog computing systems,
offers insights into designing and managing resilient fog
systems and illustrates research issues and upcoming
future trends.
×
✓
×
✓
Aslanpour
et al. [30], 2020
50
2010
–
2020
×
The study offers a taxonomy of real-world
performance metrics to assess the computing paradigms of
cloud, fog, and edge.
✓
✓
✓
✓
Alli et al. [31],
2020
102
2009
–
2020
×
The article delves into the ecosystems of IoT–fog–cloud,
analyzing concepts, architecture, standards, tools of fog
Cloud-of-Things, and presents a taxonomy on emerging
issues. It concludes that ML and AI in fog ecosystems
would be appropriate for latency-sensitive and
resource-constrained systems.
✓
✓
✓
✓
(✓: Yes, ×: No).
Sensors 2022, 22, 196
7 of 38
3. Evolving Computing Paradigms and Related Concepts
3.1. Cloud Computing
Cloud computing pertains to extending applications via the internet as services, as well
as the software and technology that underpins the data centers furnishing these services [1].
NIST formalizes cloud computing [32] as “a model for enabling ubiquitous, convenient,
on-demand network access to a shared pool of conﬁgurable computing resources (e.g., net-
works, servers, storage, applications, and services) which can be rapidly provisioned and
released with minimal management effort or service provider interaction”. The essential
characteristics of the cloud model include on-demand self-service, broad network access, re-
source pooling, rapid elasticity, and measured service. A cloud infrastructure encompasses
software and hardware, extending vital features of the cloud model.
The cloud solutions are procurable through the following service models [33]:
•
Software as a service (SaaS)—the cloud provider presents consumers with applications
accessible via the program interface or web browser, and the consumer has limited
control over user-speciﬁc applications.
•
Platform as a service (PaaS)—On the cloud infrastructure, the consumers are allowed to
build and distribute applications. They can exercise control on applications deployed
but not on the cloud infrastructure.
•
Infrastructure as a service (IaaS)—The customer is furnished with essential computing
resources vital to processing, storing, and networking. The user exercises control upon
storage, applications, and operating systems, but not cloud infrastructure. The cloud
service models and deployment models are depicted in Figure 4.
Sensors 2022, 22, x FOR PEER REVIEW 
8 of 41 
 
 
Figure 4. Common cloud service models and their classifications. 
The cloud solutions are deployable as [33]: 
• 
Private cloud—a particular organization that can also be a third party exclusively 
owns and controls the private cloud, which can be available on or off-premises. 
• 
Community cloud—the specific community comprises of organizations that share 
common concerns may provide cloud infrastructure for exclusive usage available on 
or off-premises, managed by organizations within the community or by a third party. 
• 
Public cloud—the public cloud available on the cloud provider’s premises can be 
owned or managed by any enterprise and is open to the use of the general public. 
• 
Hybrid cloud—it may be composed of two or more cloud models (private, 
community, or public); although they are distinct entities, they are bound by 
t
h
l
itti
th
t bilit
f
li
ti
ll
d t
Figure 4. Common cloud service models and their classiﬁcations.
The cloud solutions are deployable as [33]:
•
Private cloud—a particular organization that can also be a third party exclusively
owns and controls the private cloud, which can be available on or off-premises.
•
Community cloud—the speciﬁc community comprises of organizations that share
common concerns may provide cloud infrastructure for exclusive usage available on
or off-premises, managed by organizations within the community or by a third party.
Sensors 2022, 22, 196
8 of 38
•
Public cloud—the public cloud available on the cloud provider’s premises can be
owned or managed by any enterprise and is open to the use of the general public.
•
Hybrid cloud—it may be composed of two or more cloud models (private, community,
or public); although they are distinct entities, they are bound by technology permitting
the portability of application as well as data.
3.2. Internet-of-Things
Kevin Ashton, co-creator and executive director of the Auto-ID Center at the Mas-
sachusetts Institute of Technology (MIT), in 1999 introduced the phrase “Internet of
Things” [34]. The Internet of Things (IoT) [35] characterizes an extensive environment
connecting heterogeneous physical objects to the internet to ﬁne-tune the efﬁciency of
real-time ubiquitous applications. As per the International Telecommunication Union
(ITU), the Internet of Things (IoT) is a universal framework that connects things which
may be physical as well as virtual, distinguished, and incorporated within communi-
cation networks, depending on prevailing and emerging collaborative information and
communication technologies (ICT) to facilitate enhanced services [36].
3.2.1. Essential Features
The fundamental characteristics of the Internet of Things include [37–40]:
•
Interconnectivity—the IoT may be connected to global communication infrastructure.
•
Things-related services—IoT is adept at offering physical/virtual things, privacy, as
well as semantic consistency services within the limits of things.
•
Heterogeneity—the IoT devices pertain to diverse hardware platforms and networks.
•
Constrained resources—the IoT devices encounter computational and energy restric-
tions.
•
Dynamic change—the state of devices and the related environment are subject to
dynamic change.
•
Uncontrolled environment—the IoT devices are deployed in an uncontrolled setting.
•
Massive scale—the devices to be monitored and those that connect with one another
are enormous and will continue to surge exponentially into the future.
3.2.2. New Challenges in IoT
As billions of devices are connected globally, data expands exponentially and accumu-
lates 24/7, driving big data to become the current buzzword [41]. The International Data
Corporation (IDC) estimates that by 2025, IoT devices may reach 41.6 billion and create
79.4 zettabytes of data [42]. The ﬁve Vs of big data [43], namely, volume, variety, velocity,
veracity, and value, pose distinct challenges. In the current scenario, the majority of data
resulting from IoT devices are managed by the cloud. The resulting cloud IoT synergy
poses demands that cannot be tackled by the existing cloud computing model alone [44].
A concise outline of challenges that IoT encounters [13,45–48] drives the need for edge and
fog computing as a solution to manage demands [36] and is outlined as follows:
•
Low latency—IoT applications [44] and industrial control systems [49] demand low
latency within a few milliseconds that can hardly be met by the existing cloud model.
•
High network bandwidth—The escalating amount of IoT devices produce sizable
data [50], which may be rendered useless due to high bandwidth usage to transfer it
to the cloud or denied due to privacy concerns; hence, entails to be dealt with locally.
•
Limited resources—numerous IoT-connected devices possess limited resources to
interact directly with the cloud, demanding intensive computation and complex
protocols.
•
IT and OT convergence—In industrial systems, the conﬂuence of information technol-
ogy (IT) and operational technology (OT) creates new needs. As ofﬂine systems may
cause business loss or consumer annoyance, contemporary cyber-physical systems
demand continual and safe operation. Thus, the upgradation of the system software
and hardware causes concern.
Sensors 2022, 22, 196
9 of 38
•
Intermittent connectivity—When IoT devices have intermittent network connectivity,
it is difﬁcult to provide uninterrupted cloud services to those devices.
•
Geographical distribution—the majority of IoT devices entail services of comput-
ing and storage that are dispersed across large geographic areas, and it is highly
challenging to position them at a location that meets IoT demands [51].
•
Context-awareness—Local contextual data must be accessed and processed by IoT
applications (vehicular networks and augmented reality), for which the physical
distance between IoT devices and the centralized cloud is a hindrance.
•
Security and privacy—The existing cybersecurity solutions prove to be unsatisfactory
to manage IoT applications due to the evolving security challenges [52,53].
3.3. Mobile Computing
The computation carried out through mobile phones, tablets, or laptops is noted as
mobile computing. The mobile devices offer substantial beneﬁts to mobile users but still
encounter limitations due to a low processing capability, battery, memory due to their
portable size, and operate at on-and-off network connectivity [2]. Along with resource
constraints, mobile computing encounters communication latency, demand adaptability
of mobile clients, etc. Thus, these drawbacks cause mobile computing to be inept for
applications with demands for low latency, robustness, and when huge data generated
from mobile devices need to be processed and stored on it. Moreover, the escalation
in mobile device utilization increased the data ﬂow, causing network congestion. Data
ofﬂoading is a viable solution to mitigate the strain on the cellular network [54]. The existing
demerits of mobile computing can be overcome by integrating it with cloud computing [55].
The expansion of mobile computing set the stage for and impacted the cloud and fog
computing evolution.
3.4. Mobile Cloud Computing
NIST states that the cloud computing alliance with IoT devices and mobile devices fa-
cilitates data and CPU-intensive applications suitable for the IoT environment [56]. The con-
cept of Mobile Cloud Computing (MCC) is that it combines cloud computing and mobile
applications with sophisticated computing modules processed on the cloud [57]. It enables
data processing and storage away from mobile devices, beneﬁtting not just smartphones
and a wide range of mobile subscribers. Major computational tasks are moved to the cloud
with MCC, improving mobile devices’ battery life [2]. With MCC being grounded on
the notion of mobile ofﬂoading, mobile devices entrust storage as well as processing to
remote units to achieve workload mitigation and optimization in terms of energy, cost, and
longevity [45].
The mobile devices’ proliferation entails the efﬁcient management of constrained
resources with MCC, as it operates on the synergy between cloud computing and mobile
computing. It is capable of operating data-intensive mobile applications as it prevails over
battery, memory, and computation power restrictions from the user viewpoint. However,
with cellular communication, long-distance data transmission to/from a core network
results in higher latency, jitter, and network overhead. This can be overcome if the computa-
tion, analysis, and ﬁltering of data occurs at the proximity of the data source, facilitating Fog
Computing (FC) and MEC [58]. The limited bandwidth, ﬂexibility, and control, along with
an unreliable latency, security, and privacy issues are some challenges faced by MCC [28].
The partitioning of mobile applications by adaptive ofﬂoading during runtime allows
the management of computer-intensive units of the application [59].
3.5. Mobile Ad hoc Cloud Computing
Mobile Ad hoc Cloud Computing (MACC) is an edge computing paradigm involving
mobile devices that share resources in a dynamic and temporary network facilitated by
transport and routing protocols [2,58,60]. It offers a decentralized network [61] with
dynamic mobile devices, accommodating devices joining or leaving the network continually.
Sensors 2022, 22, 196
10 of 38
It favors environments that lack uninterrupted internet connectivity. MACC is the most
decentralized, as it comprises mobile devices only.
3.6. Cloud of Things
The two concepts of cloud computing and IoT have evolved independently through
the years in terms of hardware and software. With IoT facing challenges due to the process-
ing, battery, and storage capacity, these issues can be solved by combining cloud computing
and IoT [62]. Cloud computing is capable of ﬁlling the gaps in IoT regarding computing,
networking, and storage capabilities due to the cloud’s virtually unlimited capabilities and
resources. It can assist in implementing numerous IoT applications [63,64]. In the Cloud-
of-Things (CoT), IoT devices constitute a virtualized cloud structure. Here, computing is
performed over the cloud of pooled resources consisting of IoT devices in contrast to mist
computing, where computing is carried out on IoT devices [65].
3.7. Mist Computing
Mist computing is initiated to include endpoint connected devices at the extreme edge
suitable for self-aware autonomic systems in the near future [2,66]. In the IoT-fog-cloud
continuum, mist computing is the ﬁrst computing point to allow computation, storage,
and networking across fog to things. Mist computing forms the superset of MACC, as
mist, devices, and networking are not restricted to mobile devices and ad hoc, respectively.
It allows utilizing the peripheral component (sensors or actuators) capacity to pre-process
data before sending them to the fog or cloud layer [67]. Mist computing aids in large-scale
IoT systems development and enriches computational efﬁciency at the edge of the IoT
architecture [68].
3.8. Edge Computing
Despite the fact that edge computing has been mentioned in the literature before
cloud computing, its signiﬁcance grew dramatically with the introduction of IoT and
the ensuing demands. Edge computing places cloud computing’s services close to the end-
user, distinguished by a rapid processing and response time [26]. Edge computing denotes
technologies that enable computation to be accomplished at the network’s edge, upon
downstream data for cloud services, and upstream data for IoT services [69]. It unfolds
the cloud’s network by extending the computation, storage, and resources to the edge
of the network, close to the data source, with the resolve to accomplish critical needs of
real-time servicing, application intelligence, security, and privacy, along with the network’s
requirements for low latency and high bandwidth [13,27].
The signiﬁcant aspects of cloud computing are its ability to grasp the big picture,
process vast amounts of data, perform in-depth analyses, process data in non-real-time,
and determine business decisions. Being centralized, entire data must be transferred to
the cloud with underlying risks of data loss and data leakage, as security and privacy
cannot be ensured, and sensitive information is at threat of disclosure [27]. Edge computing
is an extension to cloud computing, which considerably minimizes the volume of data
transmitted across nodes, lowering transmission costs and the network bandwidth usage.
It leads to utilization and computing efﬁciency along with energy consumption. Edge
computing can be more effective in small-scale, intelligent, real-time analyses. It eliminates
the risk associated with the network transmission, ensuring data security. If data become
compromised, it impacts only local data. The edge computing architecture is federated,
wherein edge devices are positioned between the cloud and terminal devices to tender
cloud services to the network’s edge [24,70]. As edge computing shifts service provisioning
from the cloud to the edge, it favors IoT application demands, enabling IoT devices to
be more scalable and energy-efﬁcient [71]. The cloud–edge alliance involves a typical
three-layer model distinguished as the terminal (sensors, cameras, and smartphones), edge
(base stations, access points, routers, switches, and gateways), and cloud [27]. In terms of
Sensors 2022, 22, 196
11 of 38
device types, communication protocols, and services, edge computing can be implemented
in various ways [9,13,26].
3.9. Multi-Access Edge Computing (MEC)
The Mobile Edge Computing standard has been constituted by the European Telecom-
munications Standards Institute (ETSI) [72], which offers cloud computing and IT function-
alities within the Radio Access Network (RAN) in the vicinity of mobile subscribers [71].
As of 2017, ETSI renamed “Mobile Edge Computing” to “Multi-Access Edge Computing”
due to increasing interest in MEC by non-cellular operators [73,74]. MEC is a continuation
of mobile computing via edge computing, delivering computation and storage to energy
and resource-constrained mobile devices [2].
With Multi-Access Edge Computing, a cloud server is deployed at the cellular net-
work’s base stations. It executes tasks such as enhancing the application’s performance and
minimizing network congestion, bandwidth use, and latency for subscribers that cannot
be achieved with a conventional network architecture [75–77]. Even though the process-
ing and memory capabilities of mobile devices improve, they are still not sufﬁcient to
handle compute-intensive tasks, which has led to MCC and MEC models [78]. The MEC
architecture is portrayed in Figure 5. MEC considerably reduces the process duration
and energy demands of mobile devices by setting up computational and other resources
close to the base stations [79]. As base stations serve as crucial access points to several
IoT devices, end devices could be directly serviced with just one hop through MEC [80].
MEC showcases a low latency, proximity to the user, location awareness, and geographical
distribution. However, it restraints the need to install a dedicated MEC server for MEC
services. With the rise in the demand for resources over time, scaling is another major
challenge [81]. MEC exhibits the reliability, energy efﬁciency, and a low latency suitable to
diverse applications [82] and outperforms MCC comparably [83].
Sensors 2022, 22, x FOR PEER REVIEW 
12 of 41 
 
energy demands of mobile devices by setting up computational and other resources close 
to the base stations [79]. As base stations serve as crucial access points to several IoT 
devices, end devices could be directly serviced with just one hop through MEC [80]. MEC 
showcases a low latency, proximity to the user, location awareness, and geographical 
distribution. However, it restraints the need to install a dedicated MEC server for MEC 
services. With the rise in the demand for resources over time, scaling is another major 
challenge [81]. MEC exhibits the reliability, energy efficiency, and a low latency suitable 
to diverse applications [82] and outperforms MCC comparably [83]. 
 
Figure 5. Multi-access edge computing systems—a general architecture. 
3.10. Cloudlet 
A cloudlet has been envisioned by researchers at Carnegie Mellon University, which 
is a small cluster or data centers capable of computation and storage, positioned close to 
mobile devices [84,85]. Cloudlet computing shares MCC and MEC particularities, further 
contending with the demerits of MCC. A cloudlet may be referred to as a mini-cloud [86], 
offering a secured cloud infrastructure for computing and delivering results to mobile 
devices and works alongside the cloud. It is positioned at the network edge and is 
Figure 5. Multi-access edge computing systems—a general architecture.
3.10. Cloudlet
A cloudlet has been envisioned by researchers at Carnegie Mellon University, which
is a small cluster or data centers capable of computation and storage, positioned close
Sensors 2022, 22, 196
12 of 38
to mobile devices [84,85]. Cloudlet computing shares MCC and MEC particularities,
further contending with the demerits of MCC. A cloudlet may be referred to as a mini-
cloud [86], offering a secured cloud infrastructure for computing and delivering results to
mobile devices and works alongside the cloud. It is positioned at the network edge and
is accessible to adjacent mobile units [87,88]. The notion is computational ofﬂoading to
the virtual machine (VM)-based cloudlets at the network edge from mobile devices [89].
The cloudlet is featured as the middle layer in the three-tier architecture comprising of
mobile devices, the cloudlet, and the cloud [84,85] shown in Figure 6. It further possesses
connectivity, security, virtualization features, and closeness to mobile users enabling a low
latency. Cloudlets are similar to mobile clouds and nearer to mobile devices beﬁtting
real-time scenarios. They focus on servicing time-sensitive applications operating under
restricted bandwidth conditions and interactive mobile applications with a large resource
demand and offer resources at a minimum latency [83]. Cloudlets back mobile clients’ local
services by splitting tasks within cloudlet nodes that are nearer to mobile devices. While
the cloudlet suits the mobile–cloudlet–cloud structure [90], fog computing is an alternative,
supporting huge data trafﬁc with resources located at anyplace within the thing-to-cloud
continuum [2]. Cloudlets are alluded to as micro data centers (MDC) at times [91], mirroring
conventional data centers of cloud computing. The MDC may be a cloudlet or edge node
implemented in between IoT devices and the cloud [2].
Sensors 2022, 22, x FOR PEER REVIEW 
13 of 41 
 
centers (MDC) at times [91], mirroring conventional data centers of cloud computing. The 
MDC may be a cloudlet or edge node implemented in between IoT devices and the cloud 
[2]. 
 
Figure 6. Mobile device–cloudlet–cloud model. 
3.11. Cloud Robotics 
Robotics engineering is becoming a vital part of everyday life, with diverse sensors 
generating big data demanding complex computations [92]. Cloud robotics is a branch of 
IoT that evolved from the fusion of cloud computing and networked robots [93]. The 
massive storage capacity of a centralized cloud and broad library of skills can be leveraged 
by robots to learn with experience. The cloud robotics architecture comprises two levels: 
machine-to-machine and machine-to-cloud. At the machine-to-machine level, robots 
determine decisions through a wireless collaboration. The machine-to-cloud level offers a 
shared pool of storage and computation resources to be allocated as per demands. Cloud 
robotics capitalizes on the elasticity feature of cloud computing besides others. 
Additionally, robots-as-a-service (RaaS) stems from considering robots as resources, 
providing resource sharing services to other robots [94–97]. The sharing of resources and 
data between robots through the cloud is integral to CR, along with robots themselves 
being shared as resources. These systems require standards for enabling coherent, 
semantic, data sharing, and service provisioning among the robots [93]. Cloud computing 
delegates fast and robust processing and storage capabilities to robots, along with 
Figure 6. Mobile device–cloudlet–cloud model.
3.11. Cloud Robotics
Robotics engineering is becoming a vital part of everyday life, with diverse sensors
generating big data demanding complex computations [92]. Cloud robotics is a branch of
IoT that evolved from the fusion of cloud computing and networked robots [93]. The mas-
sive storage capacity of a centralized cloud and broad library of skills can be leveraged
by robots to learn with experience. The cloud robotics architecture comprises two lev-
els: machine-to-machine and machine-to-cloud. At the machine-to-machine level, robots
determine decisions through a wireless collaboration. The machine-to-cloud level offers
a shared pool of storage and computation resources to be allocated as per demands. Cloud
robotics capitalizes on the elasticity feature of cloud computing besides others. Additionally,
robots-as-a-service (RaaS) stems from considering robots as resources, providing resource
sharing services to other robots [94–97]. The sharing of resources and data between robots
Sensors 2022, 22, 196
13 of 38
through the cloud is integral to CR, along with robots themselves being shared as resources.
These systems require standards for enabling coherent, semantic, data sharing, and service
provisioning among the robots [93]. Cloud computing delegates fast and robust processing
and storage capabilities to robots, along with collaborative learning capabilities through
the sharing of knowledge. Recent advancement in this ﬁeld have incited cloud robotics
architecture development and its application in several domains [98].
3.12. Fog Computing
The idea of processing at the edge has been around since the 2000s [99,100]. A related
concept of cloudlets has been presented in 2009 [101]. The phrase ‘Fog Computing’ has
been propounded by Cisco researchers in 2012 [42,102]. Fog computing and cloudlets are
related concepts operating at the edge level, with cloudlets deployed at mobile networks
and fog computing dealing with connected things [103].
Fog computing is frequently deliberated as a form of edge computing [7,8,104]. Fog
computing literally delivers distributed processing, networking, and storage potential
nearer to the user [105]. Fog computing is more than a mere deployment of the edge
computing concept; it is the pinnacle of reinforcing edge computing concepts [9]. It is
not an extension or replacement of the Cloud; instead, it is a new paradigm operating
in between IoT and the cloud, with the intent of supporting and enhancing Interaction and
integration of the cloud, edge, and IoT.
Cisco describes fog computing [44] as a highly virtualized setup that caters to services
of computing, storage, and networking between conventional cloud data centers and end
devices, generally but not solely deployed at the network’s edge. According to the OpenFog
Consortium [10], fog computing is delineated as “a system-level horizontal architecture that
distributes resources and services of computing, storage, control and networking anywhere
along the continuum from Cloud to Things, thereby accelerating the velocity of decision-
making”. Fog computing adopts a distributed tactic originating from the edge computing
model to outdo the limitations of the centralized cloud computing approach [25], with fog
nodes positioned anyplace between cloud and end devices. The computing paradigms
associated with fog computing are depicted in Figure 7.
Sensors 2022, 22, x FOR PEER REVIEW 
14 of 41 
 
Fog computing is frequently deliberated as a form of edge computing [7,8,104]. Fog 
computing literally delivers distributed processing, networking, and storage potential 
nearer to the user [105]. Fog computing is more than a mere deployment of the edge 
computing concept; it is the pinnacle of reinforcing edge computing concepts [9]. It is not 
an extension or replacement of the Cloud; instead, it is a new paradigm operating in 
between IoT and the cloud, with the intent of supporting and enhancing Interaction and 
integration of the cloud, edge, and IoT. 
Cisco describes fog computing [44] as a highly virtualized setup that caters to services 
of computing, storage, and networking between conventional cloud data centers and end 
devices, generally but not solely deployed at the network’s edge. According to the 
OpenFog Consortium [10], fog computing is delineated as “a system-level horizontal 
architecture that distributes resources and services of computing, storage, control and 
networking anywhere along the continuum from Cloud to Things, thereby accelerating 
the velocity of decision-making”. Fog computing adopts a distributed tactic originating 
from the edge computing model to outdo the limitations of the centralized cloud 
computing approach [25], with fog nodes positioned anyplace between cloud and end 
devices. The computing paradigms associated with fog computing are depicted in Figure 
7. 
 
Figure 7. Fog computing and its related computing paradigms. 
3.12.1. Essential Features 
The significant trait of fog computing is that the computation, communication, and 
storage tasks are accomplished close to end-users by capitalizing on the key attribute of 
fog’s proximity to the edge. The additional characteristics of fog computing [15,106] are 
outlined as follows: 
• 
Low latency: The proximity of fog nodes to end devices that generate data, such as 
sensors and actuators, entails a significantly faster reaction and analysis than from 
the centralized cloud data center. This feature considerably minimizes the data 
transfer across the internet and enables a low latency to manage real-time 
applications, notably sensitive to latency and time. 
•
Save bandwidth: As the fog model allows data computation and storage between
Figure 7. Fog computing and its related computing paradigms.
3.12.1. Essential Features
The signiﬁcant trait of fog computing is that the computation, communication, and
storage tasks are accomplished close to end-users by capitalizing on the key attribute of
fog’s proximity to the edge. The additional characteristics of fog computing [15,106] are
outlined as follows:
•
Low latency: The proximity of fog nodes to end devices that generate data, such as
sensors and actuators, entails a signiﬁcantly faster reaction and analysis than from
Sensors 2022, 22, 196
14 of 38
the centralized cloud data center. This feature considerably minimizes the data transfer
across the internet and enables a low latency to manage real-time applications, notably
sensitive to latency and time.
•
Save bandwidth: As the fog model allows data computation and storage between
conventional cloud and end nodes, less complex pre-processing tasks are handled
locally. It dramatically minimizes data transfer across the internet, with endpoints
offering fast and premium localized computer and storage services. Transferring only
appropriate data to the cloud substantially reduces the network transmission and
bandwidth usage, beﬁtting the big data era.
•
Multi-tenancy: On account of the vastly virtualized and distributed infrastructure,
multi-tenancy in a constrained environment is possible.
•
Support for mobility: Due to the direct interaction between fog applications and
mobile devices, more control over mobile devices is maintained. Thus, the fog model
facilitates better control of users along with mobile devices to administrators and
satisﬁes mobility demands that are location-based and the way information is accessed,
resulting in enhanced system performance and service quality.
•
Interaction in real-time: Contrary to the cloud, fog applications deliver services in real-
time because of their low-latency feature.
•
Context-awareness: the nodes and end devices in the fog setting are aware of the con-
textual location.
•
Geographically wide distribution: The fog model’s decentralized architecture facili-
tates geographically distributed deployment with a large number of widely dispersed
nodes. It imparts closer data analysis, rapid big data processing, improved decision-
making potential in real-time and location-based services to consumers.
•
Wireless access networking: Though fog is deployed in wired environments, it is also
suitable for IoT wireless networks.
•
Support for heterogeneity: The fog infrastructure encompasses high-speed lines to
the data center and wireless access methods to the edge devices. Fog nodes are avail-
able physically or virtually, and service interfaces are incredibly dynamic, operating
in wired and wireless settings coming from different hardware and software ven-
dors and heterogeneous to cater to the low latency demand of globally distributed
applications.
•
Seamless interoperability and federation: Owing to its heterogeneous nature, fog
nodes and devices originate from various vendors and are generally deployed in di-
verse settings. For the effective interaction of devices from different providers, fog
computing must enable interoperability with federated services across domains. Thus,
to allow interoperability and cooperation across diverse resources and devices, fog
computing employs policies for resource management.
•
Real-time analytics: With data collected and processed close to the sources, real-time
analytics is possible.
•
Scalability: Fog computing exhibits scalability and adaptability to varying conditions
with the data load, resource pooling, network demands, and ﬂexible computing.
•
Support for industrial applications: As computing and analyses are conducted in real-
time, industrial applications widely beneﬁt.
•
Security and privacy: Fog computing brings facilities nearer to end consumers while
ensuring privacy and security of sensitive and private data using integrity checking,
access control, and encryption methods by fog nodes. Moreover, it can mitigate
the vulnerabilities associated with system upgrades and limit updates at the fog end.
•
Low energy consumption: as fog nodes are spatially distributed and do not require
a cooling system, fog computing is more ecologically friendly; communication within
a short-range as well as energy management rules obviously minimize the communi-
cation energy use.
In addition, fog nodes are expected to possess features such as autonomy, heterogene-
ity, hierarchical clustering, manageability, and programmability to fog implementation.
Sensors 2022, 22, 196
15 of 38
3.12.2. Architecture
The illustration of the fog architectural model has recently been a prominent area
of research. Extensive related research alluded to the architecture comprising of three-
layer [15,17,107–109]. Moreover, the N-Tier architecture recommended by the OpenFog
Consortium may be regarded as an enhancement of this three-layer model [10].
1.
Three-Layer Architecture
The basic three-layer model portrayed in Figure 8 stems from the fog computing
concept being an essential extension to the cloud computing model, with the fog layer
posing as an intermediate layer between the cloud and IoT devices [15].
Sensors 2022, 22, x FOR PEER REVIEW 
16 of 41 
 
 
The basic three-layer model portrayed in Figure 8 stems from the fog computing 
concept being an essential extension to the cloud computing model, with the fog layer 
posing as an intermediate layer between the cloud and IoT devices [15]. 
a. 
IoT Layer 
It is nearest to the end-user’s physical setting. Sensors, smart cars, drones, 
smartphones, tablets, and other devices compose this layer. Even though some of these 
devices possess computational capabilities, they are used as mere smart sensing devices 
at this layer. Overall, these devices are widely distributed geographically to sense and 
transfer data to the next higher layer for the sake of storage and computation. 
 
Figure 8. Typical cloud–fog computing architecture. 
b. 
Fog Layer 
This layer comprises numerous fog nodes and forms the basis for the fog computing 
architecture. As per the OpenFog Consortium [10], fog nodes may be a physical or logical 
network element that enforces fog services. Thus, fog nodes have a direct connection to 
extend services to end devices. On the other end, fog nodes are linked to the cloud 
infrastructure to deliver and receive its services and benefits. 
c. 
Cloud Layer 
The centralized cloud infrastructure composes the majority of this tier. It comprises 
several servers with advanced computational and storage capabilities offering a variety 
of services. Dissimilar to typical cloud computing architectures, the fog model can ease 
the burden on cloud resources by efficiently transferring computational services from the 
cloud layer to fog and enhancing productivity. 
2. 
OpenFog N-Tier Architecture 
The OpenFog Consortium’s recommended N-tier architecture [10] is rendered in 
Figure 9. Its primary intent is to offer a standard guideline for implementing fog 
computing in a given circumstance. Though fog systems are deployed in a scenario-
specific manner, the core elements of the architecture are apparent to every fog 
deployment. Endpoints (or things), fog nodes, and the cloud are the three main 
Figure 8. Typical cloud–fog computing architecture.
a.
IoT Layer
It is nearest to the end-user’s physical setting. Sensors, smart cars, drones, smart-
phones, tablets, and other devices compose this layer. Even though some of these devices
possess computational capabilities, they are used as mere smart sensing devices at this
layer. Overall, these devices are widely distributed geographically to sense and transfer
data to the next higher layer for the sake of storage and computation.
b.
Fog Layer
This layer comprises numerous fog nodes and forms the basis for the fog computing
architecture. As per the OpenFog Consortium [10], fog nodes may be a physical or logical
network element that enforces fog services. Thus, fog nodes have a direct connection
to extend services to end devices. On the other end, fog nodes are linked to the cloud
infrastructure to deliver and receive its services and beneﬁts.
c.
Cloud Layer
The centralized cloud infrastructure composes the majority of this tier. It comprises
several servers with advanced computational and storage capabilities offering a variety
of services. Dissimilar to typical cloud computing architectures, the fog model can ease
the burden on cloud resources by efﬁciently transferring computational services from
the cloud layer to fog and enhancing productivity.
Sensors 2022, 22, 196
16 of 38
2.
OpenFog N-Tier Architecture
The OpenFog Consortium’s recommended N-tier architecture [10] is rendered in Figure 9.
Its primary intent is to offer a standard guideline for implementing fog computing in a given
circumstance. Though fog systems are deployed in a scenario-speciﬁc manner, the core
elements of the architecture are apparent to every fog deployment. Endpoints (or things),
fog nodes, and the cloud are the three main components of the idea. In addition, multiple
layers of fog nodes (N-tiers) may constitute the fog layer; when the nodes are more distant
from the end devices, improving computing potential and intelligence are acquired.
 
components of the idea. In addition, multiple layers of fog nodes (N-tiers) may constitute 
the fog layer; when the nodes are more distant from the end devices, improving 
computing potential and intelligence are acquired. 
The higher levels of the fog layer refine and collect more pertinent data; therefore, 
enhancing intelligence. The scenario-specific needs ascertain the number of tiers in a 
particular implementation. Furthermore, fog nodes connected in a mesh on each layer are 
adept at providing added characteristics such as fault tolerance, elasticity, load balancing, 
etc. Thus, the fog nodes may interact both vertically and horizontally. 
Fog nodes may be categorized based on their closeness to the cloud and endpoints: 
• 
Lowest tier: with the primary focus on the acquisition, normalization, and collection 
of data obtained at the sensors, and the actuators are managed by fog nodes. 
• 
Intermediate tier: filtering, compressing, and altering data received from the bottom 
layer is the responsibility of fog nodes in the intermediate tier; on average, these 
nodes are better at analyzing data. 
• 
Highest tier: aggregating data and eliciting knowledge from it is the intent of fog 
nodes at this tier. 
 
Figure 9. N-tier architecture. 
3. 
Seven-Layer Architecture 
A fog computing model positioned between the cloud layer, and edge devices extend 
services of processing, network, and storage to IoT devices, with the primary intent of 
minimizing latency for time-critical applications. The services offered by the fog model 
are limited compared to the sophisticated cloud data centers. In line with various fog 
architectures presented by researchers [110,111] with diverse layers, a reference 
architecture comprising distinct layers with designated tasks is featured here and 
depicted in Figure 10. 
a. 
Physical layer 
Figure 9. N-tier architecture.
The higher levels of the fog layer reﬁne and collect more pertinent data; therefore,
enhancing intelligence. The scenario-speciﬁc needs ascertain the number of tiers in a partic-
ular implementation. Furthermore, fog nodes connected in a mesh on each layer are adept
at providing added characteristics such as fault tolerance, elasticity, load balancing, etc.
Thus, the fog nodes may interact both vertically and horizontally.
Fog nodes may be categorized based on their closeness to the cloud and endpoints:
•
Lowest tier: with the primary focus on the acquisition, normalization, and collection
of data obtained at the sensors, and the actuators are managed by fog nodes.
•
Intermediate tier: ﬁltering, compressing, and altering data received from the bottom
layer is the responsibility of fog nodes in the intermediate tier; on average, these nodes
are better at analyzing data.
•
Highest tier: aggregating data and eliciting knowledge from it is the intent of fog
nodes at this tier.
3.
Seven-Layer Architecture
A fog computing model positioned between the cloud layer, and edge devices extend
services of processing, network, and storage to IoT devices, with the primary intent of
minimizing latency for time-critical applications. The services offered by the fog model
Sensors 2022, 22, 196
17 of 38
are limited compared to the sophisticated cloud data centers. In line with various fog
architectures presented by researchers [110,111] with diverse layers, a reference architecture
comprising distinct layers with designated tasks is featured here and depicted in Figure 10.
 
An individual device or IoT could be a fog device, server, or gateway. The fog server 
entails configuration, computation, and storage capabilities, higher comparably in order 
to handle the fog device and gateway. It further pertains to hardware configuration, 
devices it can handle, network connectivity, etc., with its role defining it to be distinct or 
an IoT fragment. A set of virtual and physical sensors are attached to the fog device. In 
the same manner, a set of fog devices could be attached to a fog server. A specific group 
of fog devices connected to a particular fog server can interact as and when required. The 
processing has to be performed at multiple fog servers and devices to determine a proper 
decision. The level of fog devices and servers is in charge of handling and servicing data 
on storage and hardware configuration and connectivity for the fog servers and devices. 
The processing demands of different applications are addressed at this layer. 
 
Figure 10. Typical fog computing architectural layers. 
c. 
Monitoring layer 
The system operation, services, resources, and responses are tracked by the 
monitoring layer, which facilitates identifying appropriate resources in the midst of the 
operation. If a possibility arises for the fog device as well as the fog server where resource 
availability becomes negative for processing or storage, assistance from peers may be 
sought. The system monitoring unit aids in efficient decision making in such unforeseen 
scenarios and resource failure by tracking the present resource consumption, usage and 
then estimating resource demands into the future. The performance prediction 
Figure 10. Typical fog computing architectural layers.
a.
Physical layer
The sensors are the devices that serve as the primary data source producing diverse
data in a fog setting. The data may be from smart devices and homes, autonomous vehicles,
closed-circuit television (CCTV) monitoring, trafﬁc systems, sensors tracking temperature
and humidity, etc. Alongside physical sensors, the physical layer also comprises virtual
sensors, which also produce data as well.
b.
Fog device, server, and gateway layer
An individual device or IoT could be a fog device, server, or gateway. The fog server
entails conﬁguration, computation, and storage capabilities, higher comparably in order to
handle the fog device and gateway. It further pertains to hardware conﬁguration, devices
it can handle, network connectivity, etc., with its role deﬁning it to be distinct or an IoT
fragment. A set of virtual and physical sensors are attached to the fog device. In the same
manner, a set of fog devices could be attached to a fog server. A speciﬁc group of fog devices
connected to a particular fog server can interact as and when required. The processing has to
be performed at multiple fog servers and devices to determine a proper decision. The level
of fog devices and servers is in charge of handling and servicing data on storage and
hardware conﬁguration and connectivity for the fog servers and devices. The processing
demands of different applications are addressed at this layer.
c.
Monitoring layer
The system operation, services, resources, and responses are tracked by the monitoring
layer, which facilitates identifying appropriate resources in the midst of the operation. If
a possibility arises for the fog device as well as the fog server where resource availability
Sensors 2022, 22, 196
18 of 38
becomes negative for processing or storage, assistance from peers may be sought. The sys-
tem monitoring unit aids in efﬁcient decision making in such unforeseen scenarios and
resource failure by tracking the present resource consumption, usage and then estimating
resource demands into the future. The performance prediction component tracks and
forecasts the performance of the fog system depending on the resource availability and
system load. This unit is necessary to keep up with the relevant Quality of Service (QoS)
demands in SLA (service level agreements). The occurrence of repeated SLA violations may
increase system costs due to penalties for the provider. Even though this issue cannot be
completely ruled out, SLA violations can be greatly reduced if the performance prediction
component foresees the system’s performance and usage.
d.
Pre- and post-processing layer
The multiple components of this layer are distinctly concerned with the data analysis
at the basic as well as advanced levels. The data accumulated are subjected to analysis and
ﬁltering with trimming alongside a reconstruction performed when needed. Once data
processing is accomplished, the component called data ﬂow ﬁnalizes the process if the data
have to be stored locally or in the cloud. Fog computing insists on stream processing,
which processes and stores minimum relevant data at the edge, as all data generated may
not be useful. As per the application, requisite data trimming can be performed where
the mean value of the data within a minute or hour could be stored if the sensor produces
data every second. In instances where data values do not differ signiﬁcantly over time
but tend to affect performance, the number of readings taken can be reduced. Though
perfect accuracy would not be achievable, application requisites may be attained. The data
reconstruction module reconstructs the data as per the pattern in which data is generated
in times of incomplete and faulty data produced by sensors to avoid application failure or
an interruption.
e.
Storage layer
The storage module is accountable for data storage by storage virtualization. The unit
referred to as the data backup afﬁrms data availability and minimizes data loss caused by
system failure by creating a backup of critical data. It also periodically customizes schemes
of data backups. By storage virtualization, a collection of storage devices functions as
a single device, enabling manageability and maintainability; thus, offering an enterprise-
level operation, at low-cost hardware and storage.
f.
Resource management layer
The resource management layer addresses resource allocation, resource scheduling,
and energy saving. The reliability unit at this layer ensures the application of scheduling
reliability, system reliability, and the allocation of resources. Maintaining reliability is
critical, as a complex fog system encompasses IoT and fog devices alongside the cloud
with many failure possibilities. The scalability component assures that the fog resources
are scalable when resource demand surges at peak hours. The fog model aspires to offer
horizontal as well as vertical scalability, while the cloud platform ensures horizontal scal-
ability. With distributed resources for processing, networking, and storage, the resource
allocation unit allocates, deallocates, and reallocates resources. As multiple applications
are run concurrently in fog systems, the scheduling of applications is managed by the ap-
plication scheduling component. The energy-efﬁcient resource management is handled by
an energy-saving component at this layer, which reduces operational costs.
g.
Security layer
The security layer deals with all issues that relate to security, such as encrypting
communication, securing stored data, preserving fog users’ privacy, etc. Similar to cloud
computing, fog computing is deliberated as a utility model. As users connect to the cloud
for availing services, users also connect to the fog system for services; however, the fog
middleware manages interactions with the cloud. The provider must authorize the user
attempting the service connection, and the authentication unit authenticates the user’s
Sensors 2022, 22, 196
19 of 38
request to avail fog service. To ensure security and evade security breaches by intruders,
every interaction has to be encrypted. The component of encryption encrypts the connection
between IoT devices and the cloud. The majority of fog components is connected wirelessly,
and ensures security is critical. Fog systems acting on users’ private data should not reveal
those without proper user approval. At times where users accept a provider’s security
policy without reading it, it is critical to assure that user privacy is upheld.
h.
Application Layer
Despite the fact that fog computing emerged to handle IoT, various applications
pertaining to the Wireless Sensor Network (WSN) back fog computing. The majority of
latency-sensitive applications leverage fog’s utility model that delivers a cost-effective and
enhanced service quality. The systems deploying the augmented reality (AR) and virtual
reality (VR) concepts can harness the fog computing attribute of processing in real-time.
Augmented reality adds virtual content into a user’s real-life experience. Virtual reality, on
the other hand, produces a computer-generated simulation of a virtual world. With AR
and VR reckoned to transform the world in the near future, association with fog will ensure
a continued reﬁnement.
3.12.3. Fog Computing Applications
Numerous applications, such as smart homes, smart cities, smart grids, smart water
management, smart transportation, smart agriculture, augmented reality, virtual reality,
smart healthcare, and smart vehicles, compel the fog framework’s efﬁcient services. The fog
computing applications described here are depicted in Figure 11.
a.
Smart grid
A smart grid extends the reliable, efﬁcient, automated electricity distribution model
aiming to cut down operation costs, enhance transmission efﬁciency, and offer to smoothly
integrate with systems involving renewable energy [112]. It further enables service providers
and consumers to track and regulate the real-time price, output, and consumption of
power [113]. The fog systems play a key part in favoring smart grids within smart cities,
minimizing electricity bills. Here, the data produced by the fog devices can be locally
analyzed and ﬁltered by fog collectors deployed at the edge and transmitted to the cloud
for complex analysis, visualization, and long-term storage [114]. As per varying demands,
such as a low-cost and energy, smart grids allow switching over to any other supplies
of energy, such as solar or wind, with edge/fog devices gathering local data to decide
in real-time [115].
Sensors 2022, 22, x FOR PEER REVIEW 
20 of 41 
 
connected wirelessly, and ensures security is critical. Fog systems acting on users’ private 
data should not reveal those without proper user approval. At times where users accept 
a provider’s security policy without reading it, it is critical to assure that user privacy is 
upheld. 
h. 
Application Layer 
Despite the fact that fog computing emerged to handle IoT, various applications 
pertaining to the Wireless Sensor Network (WSN) back fog computing. The majority of 
latency-sensitive applications leverage fog’s utility model that delivers a cost-effective and 
enhanced service quality. The systems deploying the augmented reality (AR) and virtual 
reality (VR) concepts can harness the fog computing attribute of processing in real-time. 
Augmented reality adds virtual content into a user’s real-life experience. Virtual reality, 
on the other hand, produces a computer-generated simulation of a virtual world. With 
AR and VR reckoned to transform the world in the near future, association with fog will 
ensure a continued refinement.  
3.12.3. Fog Computing Applications 
Numerous applications, such as smart homes, smart cities, smart grids, smart water 
management, smart transportation, smart agriculture, augmented reality, virtual reality, 
smart healthcare, and smart vehicles, compel the fog framework’s efficient services. The 
fog computing applications described here are depicted in Figure 11. 
a. Smart grid 
A smart grid extends the reliable, efficient, automated electricity distribution model 
aiming to cut down operation costs, enhance transmission efficiency, and offer to 
smoothly integrate with systems involving renewable energy [112]. It further enables 
service providers and consumers to track and regulate the real-time price, output, and 
consumption of power [113]. The fog systems play a key part in favoring smart grids 
within smart cities, minimizing electricity bills. Here, the data produced by the fog devices 
can be locally analyzed and filtered by fog collectors deployed at the edge and transmitted 
to the cloud for complex analysis, visualization, and long-term storage [114]. As per 
varying demands, such as a low-cost and energy, smart grids allow switching over to any 
other supplies of energy, such as solar or wind, with edge/fog devices gathering local data 
to decide in real-time [115]. 
 
Figure 11. Applications of fog computing. 
b. Smart traffic lights and transportation systems 
In smart traffic light applications, smart traffic lights aid in lowering traffic 
congestion, noise, fuel consumption and avert accidents thus, improving the driving 
experience. These connected lights functioning as fog devices are adept at detecting the 
Figure 11. Applications of fog computing.
b.
Smart trafﬁc lights and transportation systems
In smart trafﬁc light applications, smart trafﬁc lights aid in lowering trafﬁc congestion,
noise, fuel consumption and avert accidents thus, improving the driving experience. These
Sensors 2022, 22, 196
20 of 38
connected lights functioning as fog devices are adept at detecting the ambulance’s ﬂashing
lights and changing the trafﬁc signal to open lanes for the ambulance to travel through [116].
It recognizes pedestrians and cyclists and ﬁgures out the speed and distance of vehicles
approaching and collaborates to provide warning messages to adjacent vehicles. Moreover,
smart lighting is switched on when movement is detected and turned off automatically
when trafﬁc passes. This system comes handy in averting accidents, maintaining low
and steady trafﬁc, and collecting pertinent data to enhance performance. With huge data
produced by intelligent transportation systems (ITS), processing using centralized model
results in large delays. In this sense, fog nodes at particular intersections could be utilized
to analyze data locally and brief people on current situations, substantially lessening
the delay [117].
c.
Augmented reality (AR) and virtual reality (VR)
Augmented reality overlays digital and virtual content into a physical environment. It
is highly time-critical, warranting responses in real-time. Moreover, it is extremely latency-
intolerant, as even a minor delay may impact user experience, effectuating a negative
response [116]. For this reason, fog computing has the potential to become a key player
in the augmented reality domain, as computer-intensive jobs can be ofﬂoaded to nearby
fog devices. This also holds true for the virtual reality (VR) ﬁeld, which offers real-world
experience through a simulated environment and is generated by computer technology.
d.
Smart healthcare system
When distant cloud servers are used to process and store enormous healthcare data
generated from sensors, the huge data transmission, deﬁning of location, and access latency
pose critical challenges [118,119]. As healthcare datasets increase, there is a higher possi-
bility of error occurrence during processing as well as transmission. Even a minute data
analysis error may instigate the administering of an inappropriate treatment that could cost
a human life. The patient health data is sensitive; hence, security and privacy preservation
are vital. The integration of fog computing into healthcare enhances efﬁciency and quality
as the computer and storage are provided nearer to end devices, which permits aggregation,
processing, local storage, and real-time analytics. It further displayed a low latency, mobil-
ity support, privacy, and location awareness, and experiments demonstrated an enhanced
system response time along with an improvement in energy consumption [120].
e.
Smart agriculture
As agriculture caters to the food supply chain, it plays a prime role in smart city
schemes [121]. With smart agriculture, sensors installed in ﬁeld vehicles gather data
on plant growth and ﬁeld climate conditions. Moreover, the ﬁeld can be sensed from
the sky using air balloons. These sensing activities can be effectively accomplished by fog
computing, and agricultural lands can be managed and tracked through sensor nodes’
alarm notiﬁcations.
f.
Smart water management
As far as sustainable smart cities are concerned, smart water management is crucial. It
supervises the quantity of water consumed, transported and anticipates the use of water
in the future. Above all, it enhances the water system of the city to be more reliable,
sustainable, and efﬁcient, as it assists in mitigating water loss using sensors that collect and
analyze data of the water system [121].
4. Challenges and Opportunities
Despite the fact that cloud computing has been around for a long time, it still confronts
problems. Cloud security, privacy, conﬁdentiality, availability [122], and sustainability [123]
are among them. The dependability of cloud services is an issue as well; when a limited
number of data centers offer critical functions, it might be disastrous if one of the data
centers goes down [124]. Cloud data centers require immense energy to operate, which
Sensors 2022, 22, 196
21 of 38
requires mitigating energy usage by resource provision optimization policies. The cloud
networking infrastructure faces challenges pertaining to network utilization, data conges-
tion, cloud federation [125], etc. As the IoT devices arrived, an emphasis was placed on
reducing energy and resource usage, and critical difﬁculties included increasing the battery
life or optimizing the energy utilization of smart devices [126]. The security of IoT devices
and withholding the privacy of sensitive data collected by the connected devices pose
unique challenges [127]. The availability, reliability, scalability, and interoperability of IoT
networks are labelled to be challenging.
Edge computing, which moves computation to the network’s edge, poses a number of
complications, such as focusing on the programmability of edge devices, naming schemes
for a large number of edge devices, including security, privacy, data abstraction, service
management, and optimization issues [41]. With fog computing still in its developmental
stage, it faces many open challenges. It has difﬁculties similar to edge computing due to
its correlations, and the notable challenges include programmability, managing heteroge-
neous systems, providing security, interoperability, mobility, scalability, federation, and
energy/resource efﬁciency [20,128].
Fog computing is a more generic model compared to related paradigms due to the far-
reaching scope and presence in the Thing-to-Cloud continuum. The comparison and
features of the fog, edge and cloud [2,129–131] are displayed in Tables 3 and 4. The associa-
tion between cloud, edge, and fog computing [132] is shown in Figure 12. Fog computing
is imminent of offering amelioration in the near future in an open-standards setting of
connected devices, apparent when the IEEE Standard adopted the Open-Fog Reference
Architecture [133]. Hence, our cynosure for the rest of the paper is on challenges and future
research directions pertaining to fog computing.
Sensors 2022, 22, x FOR PEER REVIEW 
22 of 41 
 
 
operate, which requires mitigating energy usage by resource provision optimization 
policies. The cloud networking infrastructure faces challenges pertaining to network 
utilization, data congestion, cloud federation [125], etc. As the IoT devices arrived, an 
emphasis was placed on reducing energy and resource usage, and critical difficulties 
included increasing the battery life or optimizing the energy utilization of smart devices 
[126]. The security of IoT devices and withholding the privacy of sensitive data collected 
by the connected devices pose unique challenges [127]. The availability, reliability, 
scalability, and interoperability of IoT networks are labelled to be challenging. 
Edge computing, which moves computation to the network’s edge, poses a number 
of complications, such as focusing on the programmability of edge devices, naming 
schemes for a large number of edge devices, including security, privacy, data abstraction, 
service management, and optimization issues [41]. With fog computing still in its 
developmental stage, it faces many open challenges. It has difficulties similar to edge 
computing due to its correlations, and the notable challenges include programmability, 
managing heterogeneous systems, providing security, interoperability, mobility, 
scalability, federation, and energy/resource efficiency [20,128]. 
Fog computing is a more generic model compared to related paradigms due to the 
far-reaching scope and presence in the Thing-to-Cloud continuum. The comparison and 
features of the fog, edge and cloud [2,129–131] are displayed in Tables 3 and 4. The 
association between cloud, edge, and fog computing [132] is shown in Figure 12. Fog 
computing is imminent of offering amelioration in the near future in an open-standards 
setting of connected devices, apparent when the IEEE Standard adopted the Open-Fog 
Reference Architecture [133]. Hence, our cynosure for the rest of the paper is on challenges 
and future research directions pertaining to fog computing. 
 
Figure 12. Cloud, fog, and edge computing alliance. 
Table 3. Comparison of fog, edge and cloud computing characteristics. 
Characteristic 
Fog 
Edge 
Cloud 
Operators 
Users and cloud provider 
Local enterprise or network 
infrastructure providers 
Cloud provider 
Participating Nodes 
Fog devices (switches,  
Edge devices 
Fewer nodes spanning cloud 
to IoT devices 
Figure 12. Cloud, fog, and edge computing alliance.
Sensors 2022, 22, 196
22 of 38
Table 3. Comparison of fog, edge and cloud computing characteristics.
Characteristic
Fog
Edge
Cloud
Operators
Users and cloud provider
Local enterprise or network
infrastructure providers
Cloud provider
Participating Nodes
Fog devices (switches,
routers, access points, etc.) and IoT devices
Edge devices
Fewer nodes spanning cloud to IoT
devices
Service Type
Less global
Local
Global
Management
Distributed/centralized
Local business and service provider
Centralized
Hardware
Devices with virtualization facility (access
points, routers, switches, servers)
Edge devices with compute capacity
Massive data centers and equipment
with virtualization potential
Computation Device
Any device capable of
computation, networking, and storage
Edge devices
Powerful cloud servers
Available Computing
Resources
Moderate
Moderate
High
Nature of Failure
Highly diverse
Highly diverse
Predictable
Main Driver
Academia/ Industry
Academia/industry
Academia/industry
User Connectivity
Mostly wireless
Mostly wireless
High speed (Both wired and wireless)
Distance from Users
Relatively close
Close
Far
Internal Connectivity
Operate autonomously with intermittent
or no internet connectivity
Operate autonomously with
intermittent or no internet
connectivity
Requires internet connectivity
throughout service duration
Main
Standardization
Entity
OpenFog Consortium, IEEE
-
National Institute of Standards and
Technology (NIST), Cloud Security
Alliance (CSA), Distributed
Management Task Force (DMFT),
Open Commons Consortium (OCC),
Global Inter-Cloud Technology Forum
(GICTF)
Power Source
Battery/green energy/
direct power
Battery/green energy/direct power
Direct power
Power Consumption
Low
Low
High
Application Type
High computation with lower latency
Low latency computation
Ample computation
Architecture
Decentralized/hierarchical
Localized/distributed
Centralized/hierarchical
Computation Capacity
Moderate
Moderate
High
Storage Capacity
Limited
Limited
Massive storage capacity
Availability
High
Average
High
Latency
Low
Low
Relatively high
Node mobility
High
High
Very low
Security/Vulnerability
Must be provided on
participant nodes
Must be provided on edge devices
Must be provided along
Cloud-to-Things continuum
Server Location
Can be deployed at edge or dedicated
locations
Near edge devices
Stationed in huge
dedicated buildings
Number of
Intermediate Hops
One/few
One
Multiple
Hardware
Connectivity
WAN, LAN, WLAN, Wi-Fi, cellular
WAN, LAN, WLAN, Wi-Fi___33,
cellular, ZigBee
WAN
Application Handling—real-time
Achievable
Achievable
Difﬁcult owing to
increased latency
Service Access
Through connected devices from the edge
to the core
At the edge of the internet
Through core
Computation Cost
Low
Low
High
Cooling Cost
Very low
Very low
High
Deployment Space
Less
Less
Massive
Delay Cost
Less
Less
More
Table 4. Fog, edge, and cloud computing functionalities.
Feature
Fog
Edge
Cloud
Heterogeneity support
Yes
Yes
Yes
Connection to cloud
Yes
Yes or No
Yes
Infrastructure need
Yes
Yes
Yes
Geographically distributed
Yes
Yes
No
Virtualization technology
Yes
No
Yes
Location awareness
Yes
Yes
No
Ultra-low latency
Yes
Yes
No
Scalability
Yes
Yes
Yes
Mobility support
Yes
Yes
No
Application support—real-time
Yes
Yes
No
Application support—large-scale
Yes
Yes
Yes
Standardized
Yes
Yes
Yes
Multiple IoT applications
Yes
No
Yes
Data persistence
Yes
No
Yes
Computation migration
Yes
No
No
Conserving energy
Yes
Yes
No
Sensors 2022, 22, 196
23 of 38
4.1. Fog Computing: Open Challenges
The fog computing paradigm has evolved from the cloud computing utility model.
With IoT proliferation, computations closer to the network edge signiﬁcantly minimize
the cost of computing and data ofﬂoading at the cloud. However, processing at the edge
poses numerous challenges pertaining to devices, security, the network, integrating fog,
and IoT, which the distributed fog system has to deal with [28,44,110]. The open challenges
identiﬁed are pictured in Figure 13.
•
Standards and programming languages
The fog structure is distinct from the cloud as it extends cloud services to end-user
devices, warranting upgraded standards and associated programming languages, along
with effective user interfaces and network protocols for IoT device management.
•
Scalability
Scalability is a key issue for systems involving extensive IoT applications on fog, and
exploring optimal algorithms that illustrate the fog system’s complexity would be valuable.
In the fog model, time-critical tasks are executed at the fog, and others are moved for
processing to the cloud. Ascertaining when fog resources are utilized optimally depending
on service type, user count, and resource availability are signiﬁcant.
•
Computational challenges
The Fog system continually interacts with the cloud servers. It intends to respond
to users within a stipulated duration and forward complex computer-intensive tasks to
the cloud, which may take longer. The parts of computation that are unrestricted by
response time are sent to the cloud, while others are carried out at the edge for a minimum
computational cost. The challenge lies with ﬁguring out which computer tasks are to be
executed at the edge and ofﬂoaded to the cloud.
•
Deployment challenges
The fog system has to be precisely deployed to subdue latency. Factors such as
the type and task amount performed at a particular tier, fog device capability, and reliability,
and the number of sensors determine implementation decisions. As per the application
requirements, resource scaling, as well as shrinking, are carried out without hindering
the operation of ongoing services. OpenFog recommends the N-tier fog model from s
mobilization viewpoint; however, escalating the fog layer levels may instigate delays,
which require deﬁning the number of levels for the speciﬁc application.
•
Decentralized framework and failure management
The decentralized fog entails a high likeliness of fog device malfunction relating to
the software, hardware, power source, mobility, as well as connectivity issues considering
an unreliable wireless connection, linking the majority of fog devices. The fog system is
adaptable to a minor disruption and resource shortage. The fog node failure may make
its respective virtualized resources unavailable, and related issues, such as latency and
migration, have to be dealt with for resource availability at downtime. The decentral-
ized fog results in the repetition of code at edge devices, and this redundancy has to
be checked. The random distribution of network resources at the edge complicates con-
nectivity, which can be rectiﬁed by deploying a middleware that manages resources to
the demanding application. The small client services are disseminated from the cloud
to the edge, and acquiring such services from fog systems is quite challenging. The fog
system manages billions of IoT devices; hence, provisioning services to all fog devices
is arduous. The portability of the fog’s edge node requisites ubiquitous fog computing.
With fog being distributed, the preciseness of computation needs to be conﬁrmed as its
applications demand consistency.
Sensors 2022, 22, 196
24 of 38
 
connectivity, which can be rectified by deploying a middleware that manages resources 
to the demanding application. The small client services are disseminated from the cloud 
to the edge, and acquiring such services from fog systems is quite challenging. The fog 
system manages billions of IoT devices; hence, provisioning services to all fog devices is 
arduous. The portability of the fog’s edge node requisites ubiquitous fog computing. With 
fog being distributed, the preciseness of computation needs to be confirmed as its 
applications demand consistency. 
 
Figure 13. Fog computing—open challenges. 
• 
Device heterogeneity and resource management 
Fog computing sets the stage for numerous heterogeneous technologies to offer IoT 
services with a key challenge of linking resources from diverse platforms. It is vital to 
examine algorithms that are competent at handling scheduling, synchronizing for the 
effective utilization of IoT devices that are short on resources. The diversified nature of 
edge devices has to be emphasized by the fog architecture at the device as well as the 
network levels. Utilizing heterogeneous devices in a diverse fog setting with varying 
application demands is strenuous. Numerous IoT devices from diverse hardware and 
Figure 13. Fog computing—open challenges.
•
Device heterogeneity and resource management
Fog computing sets the stage for numerous heterogeneous technologies to offer IoT
services with a key challenge of linking resources from diverse platforms. It is vital to exam-
ine algorithms that are competent at handling scheduling, synchronizing for the effective
utilization of IoT devices that are short on resources. The diversified nature of edge devices
has to be emphasized by the fog architecture at the device as well as the network levels.
Utilizing heterogeneous devices in a diverse fog setting with varying application demands
is strenuous. Numerous IoT devices from diverse hardware and software vendors add to
the complexity factor. When the edge lacks computational resources, it can be acquired and
assigned from among the fog nodes setting up a common pool of computing, network, and
storage resources, availed by applications as per demand. The heterogeneity of fog devices
and resources in the dynamic fog setting enables resource scheduling and allocation to be
more challenging than that of the cloud, with utilizing idle resources being fog’s top priority.
•
Security and privacy
The heterogeneity of devices makes the fog framework vulnerable to various attacks
due to its deployment in a not-so-secure setting. As fog nodes are positioned between
the cloud and end-users, fog computing is susceptible to security issues. Assuring the pri-
vacy of sensitive data originating from sensors is critical. The fog-based Distributed Denial
of Service (DDoS) attack is highly destructive, as diverse malignant devices overwhelm
resource-limited end devices with fake service requests. Another such attack is the Man-in-
the-Middle Attack (MMA), which discloses sensitive private data. The physical components
of IoT devices can also be attacked, referred to as a physical attack based on the protection
level and implemented location.
•
QoS
The fog framework encompasses devices from the cloud to the edge, and the fog nodes
are to provide end-to-end services adhering to users’ service-speciﬁc QoS features. The fog
system is entitled to manage the distribution of computing and storage to the cloud while
orchestrating heterogeneous edge devices. Hence, it is necessary to dynamically integrate
cloud servers and fog devices.
•
Blockchain and Software-Deﬁned Networking (SDN)
Sensors 2022, 22, 196
25 of 38
In fog-based IoT settings, blockchain technology can provide a secure framework for
controlling data and information exchanges amongst independently operating devices.
To improve privacy and security, blockchain offers the safe transmission and storage of
digitally signed documents. As a result, an additional study into this technology is critical
in order to offer and improve methods for securely transmitting data between IoT devices,
utilizing a trustworthy approach such as a time-stamped contractual handshake.
Furthermore, Software Deﬁned Networking (SDN) is a networking technology that
may be used in conjunction with fog technology to enable effective data exchange and
resource collaboration. SDN may also bring intelligence to fog-based IoT networks, among
other things. SDN may also be utilized to protect fog-based IoT infrastructures. The authors,
for example, developed a hybrid network design for smart cities that included SDN with
blockchain. As a result, research into SDN and its integration with blockchain would be
helpful in providing an efﬁcient architecture for sustainable smart cities.
•
Latency management
Latency control is required in fog computing to guarantee an acceptable level of Quality
of Service. As a result, research into various latency management techniques would aid
in delivering services with the least amount of delay and ensuring a higher QoS throughout
the system. The estimate of resources is another key topic in fog computing. It aids
in allocating computing resources depending on various policies, allowing for the correct
allocation of resources for future computation. In order to attain the necessary QoS,
a comprehensive study into various resource estimate policies in terms of multiple aspects
such as user attributes and experienced Quality of Experience (QoE) would be useful.
•
Sustainability
In order to reduce the total carbon footprint, sustainability which refers to the utiliza-
tion of renewable energy supplies, energy harvesting, and energy-efﬁcient architecture,
is a crucial necessity when building fog-based IoT architectures for smart cities. Dense
IoT end-devices and fog computing servers are predicted in smart cities. As a result,
the smart city infrastructure would suffer considerable energy constraints. As a result, it is
critical to research various methods for increasing the energy efﬁciency of fog-based IoT
systems without sacriﬁcing QoS, which could be accomplished through energy-efﬁcient
caching methods.
•
Interoperability and federation of fog
Another essential prerequisite for accomplishing the goal of a fog-based IoT and sus-
tainable smart cities becoming a reality is interoperability. Because of the large number of
heterogeneous IoT devices running on multiple protocols, the interoperability of fog-based
IoT systems in sustainable smart cities is difficult. The fog-based IoT architecture should
provide interoperability so that various systems and devices can correctly comprehend and
use each other’s functionalities. On that account, intense research efforts are recommended
to create frameworks that allow interoperability for fog-based IoT systems in sustainable
smart cities.
On the fog, requests are processed at proximity, mitigating latency. If numerous
latency-sensitive applications were to request services, the interoperability of the Fog
clusters and its servers along with federation would be required so that a fog device can
request its peers to manage processing to avoid cloud involvement that increases latency.
•
Power management
Fog nodes manage innumerable end devices, as in sensors, and when fog nodes
are employed as needed, they substantially multiply active nodes, increasing the whole
system’s power consumption. Hence, power has to be managed effectively in large fog sys-
tems. One such option to study would be integrating the fog nodes in speciﬁc applications
and moving tasks among nodes. The majority of fog devices are power-constrained, and
efﬁcient energy utilization is essential.
Sensors 2022, 22, 196
26 of 38
Table 5 furnishes the summary of open issues and potential solutions concerned with
fog computing.
Table 5. Open challenges and future research directions—summary.
Open Issue
Limitations
Prevalent
Potential Solutions or
Research Prospect
Related
Speciﬁcs
Impact
Standardization of
fog computing
Several fog deﬁnitions and related
concepts are being proposed.
Formulate fog deﬁnition that can be
universally accepted.
Foundation
Standards and
Deﬁnition
Scalability
Major fog system schemes in practice fail
to scale IoT vastitude.
Design algorithms and procedures that ensure
scalability.
Scalability
Placement; Service
Provisioning;
Scheduling; Load
Balancing;
Ofﬂoading
Bandwidth-aware
system
Although reducing bandwidth usage is
key, fewer fog computing regard
conserving bandwidth through fog
systems.
Deliberate on saving bandwidth through fog
systems and measure bandwidth usage under
fog systems.
Bandwidth
Testbeds and
Experiments; Control
and Monitoring;
Infrastructure Design
SLA for fog
system
SLAs for cloud system are deﬁned, but
SLAs for fog systems are not deﬁned.
Devise new SLA compatible for fog
computing systems that supports
multi-vendors.
Cost, QoS
Fog Infrastructure;
Control and
Monitoring
Mobility
Major existing work considers ﬁxed fog
nodes and mobile IoT devices.
Propose fog systems with mobile fog nodes
and design suitable task ofﬂoading and
scheduling plans ensuring availability to IoT
nodes.
Mobility,
Management
Concepts and
Framework; Security
and Privacy;
Scheduling, Load
Balancing and
Ofﬂoading
Fog node site
selection
The issue of site selection for fog node is
highlighted by limited studies.
The placing of fog servers at appropriate
positions is crucial to offer maximum
service. Analysis of demand and
workload of a speciﬁc node prior to
placement minimizes maintenance cost.
Devise site selection policies for fog nodes,
addressing computation, communication,
storage, and cost.
QoS, Cost, RAS
Resource Analysis and
Estimation;
Infrastructure Design
SDN support
Fog computing does not provide native
support to SDN.
Improving and standardizing SDN for fog
systems.
Programmability
Software and Tools;
Deﬁnition and
Standards
Resource
Monitoring
Fog resource monitoring is addressed by
very few studies.
Formulate procedures that monitor resources
of fog systems involving multi-operators.
Management,
Programmability
Software and Tools;
Control and
Monitoring
High-speed user
support
Existing communication protocols do not
assist high-speed users.
Develop protocols supporting high-speed
users and mobility-predicting algorithms
based on machine learning.
Mobility
Architecture and
Framework
Federation
Federation schemes or application for fog
is unavailable.
Formulate new fog node federation strategy
operating across diverse domains.
Programmability,
Management
Software and Tools
Fog node
security
The fog nodes positioned at proximity of
end user incites security challenge.
Conﬁgure secure fog nodes with robust access
control policies that handle site attacks and
secure hardware design to withstand physical
damage.
Security, Device
Heterogeneity
Security and Privacy;
Hardware Design
Trust and
authentication
Heterogeneous IoT nodes and fog nodes
make the traditional authentication and
trust strategies inept. The providers of
fog service may be internet service
provider, cloud vendor, or end-users,
which jeopardizes the trust in fog.
Design of novel trust and authentication
structure for user, service, and nodes is
needful.
Heterogeneity,
Security
Security and Privacy;
Deﬁnition and
Standards
Security for fog
ofﬂoading
Fog node task ofﬂoading may lead to
security and privacy concern.
Devise secure ofﬂoading technique and
integrity, correctness checking scheme for task
ofﬂoaded.
Security, QoS
Ofﬂoading, Security,
and Privacy
Privacy
With various networks involved and fog
operating predominantly on wireless
technology, privacy issues arise. The end
user can access numerous fog nodes
which involves sensitive data.
Maintaining the privacy of sensitive personal
data is vital.
Privacy
Privacy and Security
Flexibility
Fault or failure at network is not
regarded by existing fog networks, with
fog nodes being more prone to DoS
attacks due to limited resources.
Regard fault prevention, detection, and
recovery in fog networks and design
DoS-resilient fog system.
Security
Security and Privacy;
Infrastructure Design;
Control and
Monitoring
Green fog
computing
Enhancing energy efﬁciency of overall
fog system has to be deliberate.
Utilize battery storages and energy harvesting
for IoT sensors and devices and place fog
nodes near renewable energy sources.
Energy
Resource analysis,
Estimation;
Infrastructure Design
Energy
consumption
With huge number of fog nodes, energy
consumed is large. The energy demand
of fog nodes should be reduced to
mitigate cost and energy.
Device resource provisioning strategy that is
energy efﬁcient, while being aware of fog
node positions.
Energy
Resource Analysis,
Estimation;
Infrastructure Design
Multi-objective
design
Many existent schemes reckon certain
objectives and overlook other objectives.
Propound schemes that regard multiple
objectives concurrently (task ofﬂoad strategy
that deems availability, bandwidth, energy,
and security).
QoS
Scheduling, Load
Balancing, and
Ofﬂoading; Resource
Analysis and
Estimation; Testbeds
and Experiments
Sensors 2022, 22, 196
27 of 38
4.2. Future Prospects of Fog/Edge Computing
The technological possibilities that may lead fog/edge computing paradigms into
the future are portrayed in Figure 14 and detailed as follows:
-objective 
n 
Many existent schemes 
reckon certain objectives and 
overlook other objectives. 
Propound schemes that regard 
multiple objectives concurrently 
(task offload strategy that deems 
availability, bandwidth, energy, and 
security). 
QoS 
Balancing, and 
Offloading; 
Resource Analysis 
and Estimation; 
Testbeds and 
Experiments 
4.2. Future Prospects of Fog/Edge computing 
The technological possibilities that may lead fog/edge computing paradigms into the 
future are portrayed in Figure 14 and detailed as follows: 
 
Figure 14. Future opportunities—fog computing and other evolving computing paradigms. 
4.2.1. Big Data Analytics 
The proliferation of the ubiquitous IoT has led up to an overwhelmingly immense 
amount of data generation, inferred as big data [134]. Big data entails ever-expanding 
datasets, which are heterogeneous in nature, comprising of structured, semi-structured, 
and unstructured data [135]. It garners potential for opportunities as well as challenges, 
including the five Vs [136]. Thus, big data analytics is a promising solution that processes 
the humongous big data and transforms it into smart data, imparting actionable insights 
into making data-driven decisions [137]. The key feature of fog computing and edge 
Figure 14. Future opportunities—fog computing and other evolving computing paradigms.
4.2.1. Big Data Analytics
The proliferation of the ubiquitous IoT has led up to an overwhelmingly immense
amount of data generation, inferred as big data [134]. Big data entails ever-expanding
datasets, which are heterogeneous in nature, comprising of structured, semi-structured,
and unstructured data [135]. It garners potential for opportunities as well as challenges,
including the ﬁve Vs [136]. Thus, big data analytics is a promising solution that processes
the humongous big data and transforms it into smart data, imparting actionable insights
into making data-driven decisions [137]. The key feature of fog computing and edge
computing models is the potential to quickly store and process data, beneﬁting real-time
applications and playing a crucial part in efﬁcient business operations [138,139].
4.2.2. Serverless Computing
Serverless computing facilitates an easy and hastier IoT application development
by eliminating the need to manage a real infrastructure [140]. It is also referred to as
the Function-as-a-Service (FaaS), implementing code as independent functions through
dynamic resource provisioning, which enhances the runtime infrastructure scalability [141,
142]. Integrating serverless computing to the edge computing model increases the com-
putation speed of data generated and processed by IoT applications deployed on edge
devices [143]. As individual functions are executed on edge devices, the response time,
latency, and energy consumed is decreased, and the reliability is improved.
4.2.3. Blockchain
Blockchain is a novel concept to store data as a chain of blocks to enhance data
security [144]. It is a super-secure method to store, authenticate, and protect data, which
promotes trusted transactions. Blockchain usually revolves around securing cryptocurrency
with real potential being transparent and immutable. It utilizes the distributed ledger
model to secure transactions and is decentralized in nature, providing accurate and efﬁcient
transactions, evading intermediaries. Blockchain is engaged in offering services pertaining
to ﬁnance, voting, supply chain monitoring, and smart contracts. It can be deployed to
secure data generated by IoT applications [145,146].
4.2.4. Quantum Computing
The emerging ﬁeld of quantum computing extends a substantial computational lead
over classical computing by leveraging the quantum physics principles of entanglement
Sensors 2022, 22, 196
28 of 38
and superposition [147]. With unimaginably swift quantum computers, calculations are
performed and stored using quantum bits referred to as qubits, which allows number
crunching and problem-solving at an exponential scale. Seemingly unsolvable complex
tasks, predicting viable solutions to issues, and the processing of a massive amount of
data can be handled with absolute ease by quantum computers. They can further enhance
computational efﬁciency, security, and energy efﬁciency [148]. Quantum computing can
be combined with ML and DL techniques to predict the resource demand and handle
an efﬁcient resource and energy utilization at fog and edge layers [149,150]. Quantum
computing is in its budding stage, with research efforts underway at an accelerating
pace [148].
4.2.5. Software-Deﬁned Networking
Software-Deﬁned Networking is an upcoming paradigm that overcomes the verti-
cal integration issue by separating the control logic of the network from the underlying
switches and routers, enabling a logical network control centralization [151]. It makes it
simpler to manage a ﬂexible and reliable network, introduces new networking abstrac-
tions, and leads to network evolution. SDN overcomes conventional network issues by
enhancing the virtualization, security, energy efﬁciency, and network reliability, optimizing
the network topology, managing complexity, service orchestration-beneﬁtting fog, and
edge computing [152,153].
4.2.6. Artiﬁcial Intelligence (AI)
Artiﬁcial intelligence is a key ﬁeld of computer science, where machines mimic human
intelligence/behavior and is already transforming the world. The accelerating ability
of machines to learn and act smart is gearing up to drive even more businesses and
technologies. AI, collectively with its subﬁelds of machine learning and deep learning,
help businesses save cost, enrich customer experience, communicate effectively, streamline
workﬂows, and obtain insights for better decisions. ML is the ability of a machine to learn
without involving explicit programming. It can analyze huge datasets and offer actionable
insights. DL, which is a subset of ML, is capable of handling complex computational tasks.
AI has begun to see the light of the day with automation and implementation occurring at
a large scale and fast pace. Likewise, intense research efforts are underway for integrating
fog and edge computing with artiﬁcial intelligence to enhance the overall performance,
including resource, energy management, security, and reliability [154–156].
5. Sustainable/Green Computing in Fog/Edge
Sustainable/green computing is the efﬁcient management of computational, commu-
nication, and storage devices through convincing design and manufacturing practices with
a reduced impact on the environment [157]. The last decade has seen sustainable/green
computing permeating ﬁelds of social computing, mobile computing, agent systems based
on AI, as well as the Internet of Things. IoT nodes possess power constraints and connecting
with the internet makes them vulnerable to attacks. For IoT to be sustainable, energy and
security are the two key aspects to be emphasized.
5.1. Energy Sustainability
With IoT services pervading all aspects of our lives, energy-constrained IoT devices
spark concern while considering sustainability. The massive number IoT sensors and
actuators deployed necessitate a continuous and persistent power supply. As the IoT
node size reduces, the size of the battery also decreases. In light of the current trend to
enhance IoT device functionality, formulating sustainable solutions for confronting power
constraints is essential [158].
Numerous research efforts have been oriented towards energy harvesting for self-
sufﬁcient IoT functioning, alongside tackling IoT security issues. The energy consumed
by digital and smart gadgets has become concerning. Energy harvesting from renewable
Sensors 2022, 22, 196
29 of 38
energy sources can power a myriad of IoT sensors [159,160]. With IoT sensors having
a battery that lasts for a limited time, frequent charging or replacement is not viable at
all times. Hence, energy harvesting from renewable energy such as kinetic, solar, ther-
mal, etc., seems plausible [161]. Moreover, energy harvesting this issue can be handled
by deploying an efﬁcient data transmission policy [162], with almost 80% of a sensor’s
energy being depleted on data transmission. Even though efforts for enriching the energy
efﬁciency of IoT systems are underway, they hardly match the proliferating pace of IoT
services/dependence [158].
5.2. Security Sustainability
IoT sustainability emphasizes the security of data and devices. Securing data involves
handling conﬁdentiality and integrity aspects, whereas device security concerns defense
against stealth attacks. Energy-harvesting chips are susceptible to malicious attacks, in-
cluding DoS attacks that disrupt sensors. Both the criteria of energy efﬁciency and security
characterize the IoT sustainability while, at the same time, challenging IoT progress [163]
as IoT devices are power constrained, which demands a reﬁned, lightweight energy and
security framework.
According to a study, 70% of connected devices are at risk of cyber-attacks [164]. Fur-
thermore, vulnerable smart devices are estimated to cause 25% of all industrial attacks [158].
As IoT devices are resource-constrained, they are highly prone to attack than desktops
or laptops. As the battery size decreases, it can hold less energy, which in turn reduces
the availability of resources that provide security. Hence, lightweight security mechanisms
suitable for power constraint devices are essential, as traditional security solutions designed
for resource-rich devices consume more energy, owing to more computations. Research
shows that the advanced encryption standard, as well as the elliptic curve cryptography,
offer a lightweight cryptographic solution with an evaluation based on resource limitations,
chip space, latency, and throughput [165]. For the IoT systems to be sustainable, the balanc-
ing of aspects such as energy efﬁciency, power consumption, performance, and security is
required [158].
6. Conﬂuence of ML and Fog/Edge
The conventional cloud model falls short of fulﬁlling IoT application necessities due
to the enormous data generated from IoT devices [166]. Transmitting the overwhelming
IoT data to the cloud would cause network overhead, consuming bandwidth, and latency
issues [167]. Hence, to cut back on the data transfer cost as well as network delays, service
providers are steering towards the fog and edge computing [168], with an additional
opportunity for enforcing security and privacy [169]. The IoT systems comprise edge
equipment, sensors, and actuators with latency, bandwidth, and security necessities [166].
The fog computing technology of extending computer and storage to network’s edge solves
processing and networking impediments [167], enabling rapid processing close to the data
source [170]. The complexity and dynamism of fog computing with its communication
networks facilitating low latency makes sophisticated computation possible in a conducive
environment. Fog computing confers societal beneﬁts through its range of applications,
namely, healthcare, Industry 4.0, autonomous vehicles, smart cities [171], etc.
Despite that, it encounters performance as well as security setbacks. As a result,
machine learning (ML), which is a subﬁeld of artiﬁcial intelligence (AI), is catching on to
assist FC in resolving its shortcomings. Using ML to enhance FC applications and deliver
efﬁcient services in terms of accuracy, latency reduction, energy consumption, security,
privacy, resource, and trafﬁc management [25,172,173] has been increasingly popular
in recent times. Fog computing resource management involving ML enhances the computer,
decision-making, and resource provisioning, along with delay prediction. Deploying ML
techniques in fog computing facilitates accurate data processing and analyses in real-time
while managing the network overhead as well as communication trafﬁc, owing to fog’s
decentralized model. The security aspects for the device, network, and data involving fog
Sensors 2022, 22, 196
30 of 38
computing accompanied by ML prove to be effective. The merging of the fog model with
machine learning has evolved into robust end-user and upper-layer services, allowing for
deeper analytics and intelligent answers to tasks.
Machine learning (ML) is a promising option for intelligent data processing and infer-
ence and is a prime enabler to various IoT application domains [166], such as healthcare,
smart home, smart agriculture, smart industry, smart grid, etc. It has a crucial part in design-
ing the intelligent/smart setting for autonomous operations [167]. Machine learning has
immense potential as a signiﬁcant IoT technology gaining traction to provide insights for
IoT applications [174]. IoT has excellent prospects for enhancing human life and industrial
growth as innumerable sensing devices perform monitoring and increase communication
potential [175]. For resource-constrained IoT devices, the conﬂuence of machine learning
with the cloud, edge, and fog is vital for IoT implementation [156,175] to usher in efﬁcient
performance, greater controllability, productivity, and cost reduction possibilities, while
managing IoT’s QoS challenges.
Enabling intelligence at fog and IoT improves the overall performance [100]. FC moves
the cloud’s potential to the edge of the network, where IoT and human users are present.
Intelligence can be incorporated into FC as device-driven or human-driven. In a device-
driven approach, fog and IoT are equipped with more sensing, processing, network, and
storage capabilities, enabling context awareness for decision making and local resource
management. In a human-driven model, human users act as the data source to the system,
whose behavioral pattern is the key in shaping the network while serving them. Collectively,
these two approaches can help meet IoT’s demand for QoS when designing fog computing
systems.
The harnessing of machine learning in an IoT setting facilitates deeper analytics
and helps materialize efﬁcient and smart IoT applications [174]. Moreover, it can be
utilized to overcome networking difﬁculties pertaining to routing, resource allocation,
trafﬁc engineering, and security [176–180]. Neural networks are deployed to effectively
analyze enormous data produced by IoT [181]. Moreover, advanced AI involving deep
learning has been thriving in data analytics, decision making, and prediction [85].
The potential of IoT has remarkably expanded thanks to the convergence of ma-
chine learning and artiﬁcial intelligence. Advanced machine intelligence approaches have
enabled substantial insights into a number of real-world situations and the capacity to
determine critical operational choices from the massive volume of IoT sensory data. As
a result, ML and IoT must work in tandem to solve complicated real-world issues and
fulﬁll computation and communication needs.
7. Conclusions
Cloud computing has revolutionized device interactions on the internet, which ush-
ered in the Internet-of-Things and implemented a plethora of connected gadgets, with
the potential to continually sense and respond to user requirements. The proliferation
of networked IoT devices and ensuing big data and the rigorous demands of emerging
IoT applications, such as low latency, location awareness, and mobility support in a geo-
distributed scenario, have challenged the conventional cloud computing architecture.
Hence, various computing paradigms such as edge and fog have emerged to address these
limitations by deploying resources at the network’s edge. The computing at edge and fog
implies collecting, processing, and analyzing data close to the data source and transmitting
reﬁned results to the centralized cloud, favoring time-sensitive applications that require
increased accuracy, low latency, high-speed analytics, faster response time, improved re-
liability, and availability. Combining fog/edge with cloud computing has the prospect
of aiding IoT in multiple ways. Because the fog and edge computing paradigms are up-
and-coming, exhaustive research on this new technology is imperative. The evolving
computing paradigms, as well as the challenges and opportunities, were explored in this
study. Budding researchers can largely beneﬁt from this extensive survey to comprehend
recent advances in evolving computing paradigms.
Sensors 2022, 22, 196
31 of 38
Author Contributions: Conceptualization, N.A.A., D.R. and K.S.; methodology, N.A.A., D.R. and
K.S.; software, P.M.D.R.V.; validation, P.M.D.R.V., K.S. and Y.-C.H.; formal analysis, N.A.A.; in-
vestigation, N.A.A.; resources, K.S. and Y.-C.H.; data curation, P.M.D.R.V.; writing—original draft
preparation, N.A.A., D.R. and K.S.; writing—review and editing, N.A.A., D.R., P.M.D.R.V., K.S. and
Y.-C.H.; visualization, N.A.A.; supervision, D.R.; project administration, Y.-C.H.; funding acquisition,
Y.-C.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was funded by the MINISTRY OF SCIENCE AND TECHNOLOGY, TAIWAN,
grant number MOST 110-2622-E-197-009.
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
Data Availability Statement: Not applicable.
Conﬂicts of Interest: The authors declare no conﬂict of interest. The funders had no role in the design
of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or
in the decision to publish the results.
References
1.
Armbrust, M.; Fox, A.; Grifﬁth, R.; Joseph, A.D.; Katz, R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, A.; Stoica, I.; et al. A View
of Cloud Computing. Commun. ACM 2010, 53, 50–58. [CrossRef]
2.
Yousefpour, A.; Fung, C.; Nguyen, T.; Kadiyala, K.; Jalali, F.; Niakanlahiji, A.; Kong, J.; Jue, J.P. All One Needs to Know about Fog
Computing and Related Edge Computing Paradigms: A Complete Survey. J. Syst. Archit. 2019, 98, 289–330. [CrossRef]
3.
Ortiz, G.; Zouai, M.; Kazar, O.; Garcia-de-Prado, A. Atmosphere: Context and Situational-Aware Collaborative IoT Architecture
for Edge-Fog-Cloud Computing. Comput. Stand. Interfaces 2022, 79, 103550. [CrossRef]
4.
Berger, C.; Eichhammer, P.; Reiser, H.P.; Domaschka, J.; Hauck, F.J.; Habiger, G. A Survey on Resilience in the IoT: Taxonomy,
Classiﬁcation, and Discussion of Resilience Mechanisms. ACM Comput. Surv. 2022, 54, 1–39. [CrossRef]
5.
Fersi, G. Fog Computing and Internet of Things in One Building Block: A Survey and an Overview of Interacting Technologies.
Cluster Comput. 2021, 24, 2757–2787. [CrossRef]
6.
Sen, A.A.A.; Yamin, M. Advantages of Using Fog in IoT Applications. Int. J. Inf. Tecnol. 2021, 13, 829–837. [CrossRef]
7.
Shi, W.; Dustdar, S. The Promise of Edge Computing. Computer 2016, 49, 78–81. [CrossRef]
8.
Dolui, K.; Datta, S.K. Comparison of Edge Computing. In 2017 Global Internet of Things Summit (GIoTS); IEEE: Geneva, Switzerland,
2017; pp. 1–6. [CrossRef]
9.
Liu, Y.; Fieldsend, J.E.; Min, G. A Framework of Fog Computing: Architecture, Challenges, and Optimization. IEEE Access 2017, 5,
25445–25454. [CrossRef]
10.
IEEE Standard 1934–2018; IEEE Standard for Adoption of OpenFog Reference Architecture for Fog Computing. 2018; pp. 1–176.
Available online: https://ieeexplore.ieee.org/document/8423800 (accessed on 22 December 2021).
11.
Okewu, E.; Misra, S.; Maskeli¯unas, R.; Damaševiˇcius, R.; Fernandez-Sanz, L. Optimizing Green Computing Awareness for
Environmental Sustainability and Economic Security as a Stochastic Optimization Problem. Sustainability 2017, 9, 1857. [CrossRef]
12.
Venckauskas, A.; Stuikys, V.; Damasevicius, R.; Jusas, N. Modelling of Internet of Things Units for Estimating Security-Energy-
Performance Relationships for Quality of Service and Environment Awareness: Modelling of IoT Units for Estimating Quality of
Service. Secur. Comm. Netw. 2016, 9, 3324–3339. [CrossRef]
13.
Maskeli¯unas, R.; Damaševiˇcius, R.; Segal, S. A Review of Internet of Things Technologies for Ambient Assisted Living Environ-
ments. Future Internet 2019, 11, 259. [CrossRef]
14.
Atzori, L.; Iera, A.; Morabito, G. Understanding the Internet of Things: Deﬁnition, Potentials, and Societal Role of a Fast Evolving
Paradigm. Ad Hoc Netw. 2017, 56, 122–140. [CrossRef]
15.
Hu, P.; Dhelim, S.; Ning, H.; Qiu, T. Survey on Fog Computing: Architecture, Key Technologies, Applications and Open Issues.
J. Netw. Comput. Appl. 2017, 98, 27–42. [CrossRef]
16.
Mahmud, R.; Kotagiri, R.; Buyya, R. Fog Computing: A Taxonomy, Survey and Future Directions. In Internet of Everything. Internet
of Things (Technology, Communications and Computing); Di Martino, B., Li, K.-C., Yang, L.T., Esposito, A., Eds.; Springer: Singapore,
2018; pp. 103–130. [CrossRef]
17.
Lin, J.; Yu, W.; Zhang, N.; Yang, X.; Zhang, H.; Zhao, W. A Survey on Internet of Things: Architecture, Enabling Technologies,
Security and Privacy, and Applications. IEEE Internet Things J. 2017, 4, 1125–1142. [CrossRef]
18.
Mao, Y.; You, C.; Zhang, J.; Huang, K.; Letaief, K.B. A Survey on Mobile Edge Computing: The Communication Perspective. IEEE
Commun. Surv. Tutor. 2017, 19, 2322–2358. [CrossRef]
19.
Yong, B.; Wei, W.; Li, K.C.; Shen, J.; Zhou, Q.; Wozniak, M.; Damaševiˇcius, R. Ensemble machine learning approaches for webshell
detection in Internet of things environments. Trans. Emerg. Telecommun. Technol. 2020, e4085. [CrossRef]
20.
Mouradian, C.; Naboulsi, D.; Yangui, S.; Glitho, R.H.; Morrow, M.J.; Polakos, P.A. A Comprehensive Survey on Fog Computing:
State-of-the-Art and Research Challenges. IEEE Commun. Surv. Tutor. 2018, 20, 416–464. [CrossRef]
Sensors 2022, 22, 196
32 of 38
21.
Mukherjee, M.; Shu, L.; Wang, D. Survey of Fog Computing: Fundamental, Network Applications, and Research Challenges.
IEEE Commun. Surv. Tutor. 2018, 20, 1826–1857. [CrossRef]
22.
Elazhary, H. Internet of Things (IoT), Mobile Cloud, Cloudlet, Mobile IoT, IoT Cloud, Fog, Mobile Edge, and Edge Emerging
Computing Paradigms: Disambiguation and Research Directions. J. Netw. Comput. Appl. 2019, 128, 105–140. [CrossRef]
23.
Atlam, H.F.; Walters, R.J.; Wills, G.B. Fog Computing and the Internet of Things: A Review. Big Data Cogn. Comput. 2018, 2, 10.
[CrossRef]
24.
Bangui, H.; Rakrak, S.; Raghay, S.; Buhnova, B. Moving to the Edge-Cloud-of-Things: Recent Advances and Future Research
Directions. Electronics 2018, 7, 309. [CrossRef]
25.
Abdulkareem, K.H.; Mohammed, M.A.; Gunasekaran, S.S.; Al-Mhiqani, M.N.; Mutlag, A.A.; Mostafa, S.A.; Ali, N.S.; Ibrahim,
D.A. A Review of Fog Computing and Machine Learning: Concepts, Applications, Challenges, and Open Issues. IEEE Access
2019, 7, 153123–153140. [CrossRef]
26.
Khan, W.Z.; Ahmed, E.; Hakak, S.; Yaqoob, I.; Ahmed, A. Edge Computing: A Survey. Future Gener. Comput. Syst. 2019, 97,
219–235. [CrossRef]
27.
Cao, K.; Liu, Y.; Meng, G.; Sun, Q. An Overview on Edge Computing Research. IEEE Access 2020, 8, 85714–85728. [CrossRef]
28.
Yunana, K.; Alfa, A.A.; Misra, S.; Damasevicius, R.; Maskeliunas, R.; Oluranti, J. Internet of Things: Applications, Adoptions and
Components—A Conceptual Overview. In Hybrid Intelligent Systems. HIS Advances in Intelligent Systems and Computing; Abraham,
A., Hanne, T., Castillo, O., Gandhi, N., Nogueira Rios, T., Hong, T.P., Eds.; Springer: Cham, Switzerland, 2021. [CrossRef]
29.
Moura, J.; Hutchison, D. Fog Computing Systems: State of the Art, Research Issues and Future Trends, with a Focus on Resilience.
J. Netw. Comput. Appl. 2020, 169, 102784. [CrossRef]
30.
Aslanpour, M.S.; Gill, S.S.; Toosi, A.N. Performance Evaluation Metrics for Cloud, Fog and Edge Computing: A Review, Taxonomy,
Benchmarks and Standards for Future Research. Internet Things 2020, 12, 100273. [CrossRef]
31.
Alli, A.A.; Alam, M.M. The Fog Cloud of Things: A Survey on Concepts, Architecture, Standards, Tools, and Applications.
Internet Things 2020, 9, 100177. [CrossRef]
32.
Mell, P.; Grance, T. The NIST Deﬁnition of Cloud Computing; National Institute of Standards & Technology: Gaithersburg, MA,
USA, 2011; p. 2.
33.
Liu, F.; Tong, J.; Mao, J.; Bohn, R.; Messina, J.; Badger, L.; Leaf, D. NIST Cloud Computing Reference Architecture. NIST Special
Publication, Technology Report. 2011. Available online: https://bigdatawg.nist.gov/_uploadﬁles/M0007_v1_3376532289.pdf
(accessed on 14 September 2011).
34.
Dorsemaine, B.; Gaulier, J.-P.; Wary, J.-P.; Kheir, N.; Urien, P. Internet of Things: A Deﬁnition & amp; Taxonomy. In Proceedings of
the 2015 9th International Conference on Next Generation Mobile Applications, Services and Technologies, Cambridge, UK, 9–11 September
2015; IEEE: Cambridge, UK, 2015; pp. 72–77. [CrossRef]
35.
Mahmoud, R.; Yousuf, T.; Aloul, F.; Zualkernan, I. Internet of Things (IoT) Security: Current Status, Challenges and Prospective
Measures. In Proceedings of the 10th International Conference for Internet Technology and Secured Transactions (ICITST),
London, UK, 14–16 December 2015; pp. 336–341.
36.
Gubbi, J.; Buyya, R.; Marusic, S.; Palaniswami, M. Internet of Things (IoT): A Vision, Architectural Elements, and Future Directions.
Future Gener. Comput. Syst. 2013, 29, 1645–1660. [CrossRef]
37.
Recommendation-ITU-T Y.2060 Overview of the Internet of Things, Document, International Telecommunication Union. June
2012. Article No. E 38086. Available online: https://www.itu.int/rec/T-REC-Y.2060-201206-I (accessed on 15 June 2012).
38.
Khan, W.Z.; Aalsalem, M.Y.; Khan, M.K.; Arshad, Q. Enabling Consumer Trust upon Acceptance of IoT Technologies through
Security and Privacy Model. In Advanced Multimedia and Ubiquitous Engineering; Park, J.J., Jin, H., Jeong, Y.-S., Khan, M.K., Eds.;
Lecture Notes in Electrical Engineering; Springer Singapore: Singapore, 2016; Volume 393, pp. 111–117. [CrossRef]
39.
Saichaitanya, P.; Karthik, N.; Surender, D. Recent Trends in Iot. J. Inf. Comput. Sci. 2016, 9, 9.
40.
Khan, N.; Naim, A.; Hussain, M.R.; Naveed, Q.N.; Ahmad, N.; Qamar, S. The 51 V’s Of Big Data: Survey, Technologies,
Characteristics, Opportunities, Issues and Challenges. In Proceedings of the International Conference on Omni-Layer Intelligent
Systems, Crete, Greece, 5–7 May 2019; ACM: Crete, Greece, 2019; pp. 19–24. [CrossRef]
41.
Martinez, I.; Haﬁd, A.S.; Jarray, A. Design, Resource Management, and Evaluation of Fog Computing Systems: A Survey. IEEE
Internet Things J. 2021, 8, 2494–2516. [CrossRef]
42.
Storey, V.C.; Song, I.-Y. Big Data Technologies and Management: What Conceptual Modeling Can Do. Data Knowl. Eng. 2017, 108,
50–67. [CrossRef]
43.
Roman, R.; Lopez, J.; Mambo, M. Mobile Edge Computing, Fog et al.: A Survey and Analysis of Security Threats and Challenges.
Future Gener. Comput. Syst. 2018, 78, 680–698. [CrossRef]
44.
Bonomi, F.; Milito, R.; Zhu, J.; Addepalli, S. Fog Computing and Its Role in the Internet of Things. In Proceedings of the First
Edition of the MCC Workshop on Mobile Cloud Computing, New York, NY, USA, 17 August 2012; pp. 13–16. [CrossRef]
45.
Chiang, M.; Zhang, T. Fog and IoT: An Overview of Research Opportunities. IEEE Internet Things J. 2016, 3, 854–864. [CrossRef]
46.
Zhang, T.; Zheng, Y.; Zheng, R.; Antunes, H. Securing the Internet of Things: Need for a New Paradigm and Fog Computing.
In Fog for 5G and IoT; Chiang, M., Balasubramanian, B., Bonomi, F., Eds.; John Wiley & Sons, Inc.: Hoboken, NJ, USA, 2017; pp.
261–283. [CrossRef]
47.
Puliaﬁto, C.; Mingozzi, E.; Longo, F.; Puliaﬁto, A.; Rana, O. Fog Computing for the Internet of Things: A Survey. ACM Trans.
Internet Technol. 2019, 19, 1–41. [CrossRef]
Sensors 2022, 22, 196
33 of 38
48.
Weiner, M.; Jorgovanovic, M.; Sahai, A.; Nikolie, B. Design of a Low-Latency, High-Reliability Wireless Communication System
for Control Applications. In Proceedings of the 2014 IEEE International Conference on Communications (ICC), Sydney, NSW, Australia,
10–14 June 2014; IEEE: Sydney, NSW, Australia, 2014; pp. 3829–3835. [CrossRef]
49.
Gedeon, J.; Brandherm, F.; Egert, R.; Grube, T.; Muhlhauser, M. What the Fog? Edge Computing Revisited: Promises, Applications
and Future Challenges. IEEE Access 2019, 7, 152847–152878. [CrossRef]
50.
Yannuzzi, M.; Milito, R.; Serral-Gracia, R.; Montero, D.; Nemirovsky, M. Key Ingredients in an IoT Recipe: Fog Computing, Cloud
Computing, and More Fog Computing. In Proceedings of the 2014 IEEE 19th International Workshop on Computer Aided Modeling and
Design of Communication Links and Networks (CAMAD), Athens, Greece, 1–3 December 2014; IEEE: Athens, Greece, 2014; pp. 325–329.
[CrossRef]
51.
Caiza, G.; Saeteros, M.; Oñate, W.; Garcia, M.V. Fog Computing at Industrial Level, Architecture, Latency, Energy, and Security:
A Review. Heliyon 2020, 6, e03706. [CrossRef]
52.
Seitz, A.; Buchinger, D.; Bruegge, B. The Conjunction of Fog Computing and the Industrial Internet of Things—An Applied
Approach. In Proceedings of the 2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom
Workshops), Athens, Greece, 19–23 March 2018; IEEE: Athens, Greece, 2018; pp. 812–817. [CrossRef]
53.
Mahmoudi, C.; Mourlin, F.; Battou, A. Formal Deﬁnition of Edge Computing: An Emphasis on Mobile Cloud and IoT Composition.
In Proceedings of the IEEE 2018 Third International Conference on Fog and Mobile Edge Computing (FMEC), Barcelona, Spain, 23–26 April
2018; IEEE: Barcelona, Spain, 2018; pp. 34–42. [CrossRef]
54.
Bashar, A. Secure and cost efﬁcient implementation of the mobile computing using ofﬂoading technique. JITDW 2019, 1, 48–57.
[CrossRef]
55.
Al-Janabi, S.; Al-Shourbaji, I.; Shojafar, M.; Abdelhag, M. Mobile Cloud Computing: Challenges and Future Research Directions.
In Proceedings of the 2017 10th International Conference on Developments in eSystems Engineering (DeSE), Paris, France, 14–16 June 2017;
IEEE: Paris, France, 2017; pp. 62–67. [CrossRef]
56.
Dinh, H.T.; Lee, C.; Niyato, D.; Wang, P. A Survey of Mobile Cloud Computing: Architecture, Applications, and Approaches:
A Survey of Mobile Cloud Computing. Wirel. Commun. Mob. Comput. 2013, 13, 1587–1611. [CrossRef]
57.
Fernando, N.; Loke, S.W.; Rahayu, W. Mobile Cloud Computing: A Survey. Future Gener. Comput. Syst. 2013, 29, 84–106.
[CrossRef]
58.
Mansouri, Y.; Babar, M.A. A Review of Edge Computing: Features and Resource Virtualization. J. Parallel Distrib. Comput. 2021,
150, 155–183. [CrossRef]
59.
Shiraz, M.; Gani, A.; Khokhar, R.H.; Buyya, R. A Review on Distributed Application Processing Frameworks in Smart Mobile
Devices for Mobile Cloud Computing. IEEE Commun. Surv. Tutor. 2013, 15, 1294–1313. [CrossRef]
60.
Yaqoob, I.; Ahmed, E.; Gani, A.; Mokhtar, S.; Imran, M.; Guizani, S. Mobile Ad Hoc Cloud: A Survey: Mobile Ad Hoc Cloud.
Wirel. Commun. Mob. Comput. 2016, 16, 2572–2589. [CrossRef]
61.
Hubaux, J.-P.; Gross, T.; Le Boudec, J.-Y.; Vetterli, M. Toward Self-Organized Mobile Ad Hoc Networks: The Terminodes Project.
IEEE Commun. Mag. 2001, 39, 118–124. [CrossRef]
62.
Ari, A.A.A.; Ngangmo, O.K.; Titouna, C.; Thiare, O.; Kolyang; Mohamadou, A.; Gueroui, A.M. Enabling privacy and security
in Cloud of Things: Architecture, applications, security & privacy challenges. Appl. Comput. Inform. 2019. ahead-of-print.
[CrossRef]
63.
Aazam, M.; Khan, I.; Alsaffar, A.A.; Huh, E.-N. Cloud of Things: Integrating Internet of Things and Cloud Computing and
the Issues Involved. In Proceedings of 2014 11th International Bhurban Conference on Applied Sciences & Technology (IBCAST), Islamabad,
Pakistan, 14–18 January, 2014; IEEE: Islamabad, Pakistan, 2014; pp. 414–419. [CrossRef]
64.
Mahmoud, M.M.E.; Rodrigues, J.J.P.C.; Ahmed, S.H.; Shah, S.C.; Al-Muhtadi, J.F.; Korotaev, V.V.; De Albuquerque, V.H.C.
Enabling Technologies on Cloud of Things for Smart Healthcare. IEEE Access 2018, 6, 31950–31967. [CrossRef]
65.
Abdelwahab, S.; Hamdaoui, B.; Guizani, M.; Znati, T. Cloud of Things for Sensing-as-a-Service: Architecture, Algorithms, and
Use Case. IEEE Internet Things J. 2016, 3, 1099–1112. [CrossRef]
66.
Preden, J.S.; Tammemae, K.; Jantsch, A.; Leier, M.; Riid, A.; Calis, E. The Beneﬁts of Self-Awareness and Attention in Fog and Mist
Computing. Computer 2015, 48, 37–45. [CrossRef]
67.
Galambos, P. Cloud, Fog, and Mist Computing: Advanced Robot Applications. IEEE Syst. Man Cybern. Mag. 2020, 6, 41–45.
[CrossRef]
68.
Yogi, M.K.; Chandrasekhar, K.C.; Kumar, G.V. Mist Computing: Principles, Trends and Future Direction. IJCSE 2017, 4, 19–21.
[CrossRef]
69.
Shi, W.; Cao, J.; Zhang, Q.; Li, Y.; Xu, L. Edge Computing: Vision and Challenges. IEEE Internet Things J. 2016, 3, 637–646.
[CrossRef]
70.
Ren, J.; Guo, H.; Xu, C.; Zhang, Y. Serving at the Edge: A Scalable IoT Architecture Based on Transparent Computing. IEEE Netw.
2017, 31, 96–105. [CrossRef]
71.
Chen, G.; Kang, B.-T.; Kandemir, M.; Vijaykrishnan, N.; Irwin, M.J.; Chandramouli, R. Studying Energy Trade Offs in Ofﬂoading
Computation/Compilation in Java-Enabled Mobile Devices. IEEE Trans. Parallel Distrib. Syst. 2004, 15, 795–809. [CrossRef]
Sensors 2022, 22, 196
34 of 38
72.
Patel, M.; Hu, Y.; Hédé, P.; Joubert, J.; Ramos, J.R.; Sprecher, N.; Abeta, S.; Neal, A.; Cosimini, P.; Pollard, A.; et al. Contributing
Organizations and Authors. Mobile-Edge Computing Introductory Technical White Paper. White Paper, Mobile-Edge Com-
puting (MEC) Industry Initiative. 2014. Available online: https://portal.etsi.org/portals/0/tbpages/mec/docs/mobile-edge_
computing_-_introductory_technical_white_paper_v1%2018-09-14.pdf (accessed on 1 September 2014).
73.
Shahzadi, S.; Iqbal, M.; Dagiuklas, T.; Qayyum, Z.U. Multi-Access Edge Computing: Open Issues, Challenges and Future
Perspectives. J. Cloud Comp. 2017, 6, 30. [CrossRef]
74.
Giust, F.; Verin, G.; Antevski, K.; Chou, J.; Fang, Y. MEC Deployments in 4G and Evolution towards 5G. ETSI White Paper No.
24. First Edition. February 2018. Available online: https://www.etsi.org/images/ﬁles/ETSIWhitePapers/etsi_wp24_MEC_
deployment_in_4G_5G_FINAL.pdf (accessed on 20 February 2018).
75.
Pan, J.; McElhannon, J. Future Edge Cloud and Edge Computing for Internet of Things Applications. IEEE Internet Things J. 2018,
5, 439–449. [CrossRef]
76.
Hu, Y.; Patel, M.; Sabella, D.; Sprecher, N.; Young, V. Mobile Edge Computing A Key Technology towards 5G. ETSI White Paper
No. 11. First Edition. Available online: https://www.etsi.org/images/ﬁles/etsiwhitepapers/etsi_wp11_mec_a_key_technology_
towards_5g.pdf (accessed on 5 September 2015).
77.
Sabella, D.; Vaillant, A.; Kuure, P.; Rauschenbach, U.; Giust, F. Mobile-Edge Computing Architecture: The Role of MEC
in the Internet of Things. IEEE Consumer Electron. Mag. 2016, 5, 84–91. [CrossRef]
78.
Abedin, S.F.; Bairagi, A.K.; Munir, M.S.; Tran, N.H.; Hong, C.S. Fog Load Balancing for Massive Machine Type Communications:
A Game and Transport Theoretic Approach. IEEE Access 2019, 7, 4204–4218. [CrossRef]
79.
Zbakh, M.; Essaaidi, M.; Manneback, P.; Rong, C. (Eds.) Cloud Computing and Big Data: Technologies, Applications and Security.
In Lecture Notes in Networks and Systems; Springer International Publishing: Cham, Switzerland, 2019. [CrossRef]
80.
Yu, Y. Mobile edge computing towards 5G: Vision, recent progress, and open challenges. China Commun. 2016, 13, 89–99.
[CrossRef]
81.
Klas, G.I. Fog Computing and Mobile Edge Cloud Gain Momentum Open Fog Consortium, ETSI MEC and Cloudlets. 2015.
Available online: https://yucianga.info/wp-content/uploads/2015/11/15_11_22-_Fog_computing_and_mobile_edge_cloud_
gain_momentum_Open_Fog_Consortium-ETSI_MEC-Cloudlets_v1_1.pdf (accessed on 22 December 2021).
82.
Bonomi, F.; Milito, R.; Natarajan, P.; Zhu, J. Fog Computing: A Platform for Internet of Things and Analytics. In Big Data and
Internet of Things: A Roadmap for Smart Environments; Bessis, N., Dobre, C., Eds.; Studies in Computational Intelligence; Springer
International Publishing: Cham, Switzerland, 2014; Volume 546, pp. 169–186. [CrossRef]
83.
Talebkhah, M.; Sali, A.; Marjani, M.; Gordan, M.; Hashim, S.J.; Rokhani, F.Z. Edge Computing: Architecture, Applications and
Future Perspectives. In Proceedings of the 2020 IEEE 2nd International Conference on Artiﬁcial Intelligence in Engineering and Technology
(IICAIET), Kota Kinabalu, Malaysia, 26–27 September 2020; IEEE: Kota Kinabalu, Malaysia, 2020; pp. 1–6. [CrossRef]
84.
Wang, F.; Zhang, M.; Wang, X.; Ma, X.; Liu, J. Deep Learning for Edge Computing Applications: A State-of-the-Art Survey. IEEE
Access 2020, 8, 58322–58336. [CrossRef]
85.
Chang, Z.; Liu, S.; Xiong, X.; Cai, Z.; Tu, G. A Survey of Recent Advances in Edge-Computing-Powered Artiﬁcial Intelligence of
Things. IEEE Internet Things J. 2021, 8, 13849–13875. [CrossRef]
86.
Nayyer, M.Z.; Raza, I.; Hussain, S.A. A Survey of Cloudlet-Based Mobile Augmentation Approaches for Resource Optimization.
ACM Comput. Surv. 2019, 51, 1–28. [CrossRef]
87.
Satyanarayanan, M.; Bahl, V.; Caceres, R.; Davies, N. The Case for VM-Based Cloudlets in Mobile Computing. IEEE Pervasive
Comput. 2009, 8, 14–23. [CrossRef]
88.
Gusev, M.; Dustdar, S. Going Back to the Roots—The Evolution of Edge Computing, An IoT Perspective. IEEE Internet Comput.
2018, 22, 5–15. [CrossRef]
89.
Hao, P.; Bai, Y.; Zhang, X.; Zhang, Y. Edgecourier: An Edge-Hosted Personal Service for Low-Bandwidth Document Synchroniza-
tion in Mobile Cloud Storage Services. In Proceedings of the Second ACM/IEEE Symposium on Edge Computing, San Jose, CA,
USA, 12–14 October 2017; ACM: San Jose, CA, USA, 2017; pp. 1–14. [CrossRef]
90.
Jararweh, Y.; Tawalbeh, L.; Ababneh, F.; Dosari, F. Resource Efﬁcient Mobile Computing Using Cloudlet Infrastructure. In Pro-
ceedings of the 2013 IEEE 9th International Conference on Mobile Ad-hoc and Sensor Networks, Dalian, China, 11–13 December
2013; IEEE: Dalian, China, 2013; pp. 373–377. [CrossRef]
91.
Bahl, V. Emergence of Micro Datacenter (Cloudlets/Edges) for Mobile Computing; Microsoft Devices & Networking Summit: Paris,
France, 2015.
92.
Siriweera, A.; Naruse, K. Survey on Cloud Robotics Architecture and Model-Driven Reference Architecture for Decentralized
Multicloud Heterogeneous-Robotics Platform. IEEE Access 2021, 9, 40521–40539. [CrossRef]
93.
Pignaton de Freitas, E.; Olszewska, J.I.; Carbonera, J.L.; Fiorini, S.R.; Khamis, A.; Ragavan, S.V.; Barreto, M.E.; Prestes, E.; Habib,
M.K.; Redﬁeld, S.; et al. Ontological Concepts for Information Sharing in Cloud Robotics. J. Ambient Intell. Human Comput. 2020,
1–12. [CrossRef]
94.
Kehoe, B.; Patil, S.; Abbeel, P.; Goldberg, K. A Survey of Research on Cloud Robotics and Automation. IEEE Trans. Automat. Sci.
Eng. 2015, 12, 398–409. [CrossRef]
95.
Quintas, J.; Menezes, P.; Dias, J. Interoperability in Cloud Robotics—Developing and Matching Knowledge Information Models
for Heterogenous Multi-Robot Systems. In Proceedings of the 2017 26th IEEE International Symposium on Robot and Human Interactive
Communication (RO-MAN), Lisbon, Portugal, 28 August–1 September 2017; IEEE: Lisbon, Portugal, 2017; pp. 1291–1296. [CrossRef]
Sensors 2022, 22, 196
35 of 38
96.
Bozcuoglu, A.K.; Kazhoyan, G.; Furuta, Y.; Stelter, S.; Beetz, M.; Okada, K.; Inaba, M. The Exchange of Knowledge Using Cloud
Robotics. IEEE Robot. Autom. Lett. 2018, 3, 1072–1079. [CrossRef]
97.
Yazdani, F.; Kazhoyan, G.; Bozcuoglu, A.K.; Haidu, A.; Balint-Benczedi, F.; Bebler, D.; Pomarlan, M.; Beetz, M. Cognition-Enabled
Framework for Mixed Human-Robot Rescue Teams. In Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS), Madrid, Spain, 1–5 October 2018; IEEE: Madrid, Spain, 2018; pp. 1421–1428. [CrossRef]
98.
Saha, O.; Dasgupta, P. A Comprehensive Survey of Recent Trends in Cloud Robotics Architectures and Applications. Robotics
2018, 7, 47. [CrossRef]
99.
Xie, X.; Zeng, H.-J.; Ma, W.-Y. Enabling Personalization Services on the Edge. In Proceedings of the 10th ACM International Conference
on Multimedia (MULTIMEDIA ’02), New York, NY, USA, 1–6 December 2002; Association for Computing Machinery: New York, NY,
USA, 2002; pp. 263–266. [CrossRef]
100. Gelsinger, P.P. Microprocessors for the New Millennium: Challenges, Opportunities, and New Frontiers. In Proceedings of the 2001
IEEE International Solid-State Circuits Conference, San Francisco, CA, USA, 7 February 2001; Digest of Technical Papers. ISSCC (Cat.
No.01CH37177); IEEE: San Francisco, CA, USA, 2001; pp. 22–25. [CrossRef]
101. Ibrahim, S.; Jin, H.; Cheng, B.; Cao, H.; Wu, S.; Qi, L. CLOUDLET: Towards Mapreduce Implementation on Virtual Machines.
In Proceedings of the 18th ACM International Symposium on High Performance Distributed Computing—HPDC ’09, Garching, Germany,
11–13 June 2009; ACM Press: Garching, Germany, 2009; p. 65. [CrossRef]
102. Minh, Q.T.; Nguyen, D.T.; Van Le, A.; Nguyen, H.D.; Truong, A. Toward Service Placement on Fog Computing Landscape.
In Proceedings of the 2017 4th NAFOSTED Conference on Information and Computer Science, Hanoi, Vietnam, 24–25 November 2017;
IEEE: Hanoi, Vietnam, 2017; pp. 291–296. [CrossRef]
103. Gonzalez, N.M.; Goya, W.A.; de Fatima Pereira, R.; Langona, K.; Silva, E.A.; Melo de Brito Carvalho, T.C.; Miers, C.C.; Mangs,
J.-E.; Seﬁdcon, A. Fog Computing: Data Analytics and Cloud Distributed Processing on the Network Edges. In Proceedings of
the 2016 35th International Conference of the Chilean Computer Science Society (SCCC), Valparaíso, Chile, 10 October 2016–10 February
2017; IEEE: Valparaiso, Chile, 2016; pp. 1–9. [CrossRef]
104. Li, C.; Xue, Y.; Wang, J.; Zhang, W.; Li, T. Edge-Oriented Computing Paradigms: A Survey on Architecture Design and System
Management. ACM Comput. Surv. 2018, 51, 1–34. [CrossRef]
105. Chiang, M.; Ha, S.; Risso, F.; Zhang, T.; Chih-Lin, I. Clarifying Fog Computing and Networking: 10 Questions and Answers. IEEE
Commun. Mag. 2017, 55, 18–20. [CrossRef]
106. Iorga, M.; Feldman, L.; Barton, R.; Martin, M.J.; Goren, N.; Mahmoudi, C. Fog Computing Conceptual Model; Special Publication
(NIST SP) 500-325; National Institute of Standards and Technology: Gaithersburg, MD, USA, 2018. [CrossRef]
107. Stojmenovic, I.; Wen, S. The Fog Computing Paradigm: Scenarios and Security Issues. In Proceedings of the Federated Conference
on Computer Science and Information Systems, Warsaw, Poland, 7–10 September 2014; pp. 1–8. [CrossRef]
108. Yi, S.; Hao, Z.; Qin, Z.; Li, Q. Fog Computing: Platform and Applications. In Proceedings of the 2015 Third IEEE Workshop on Hot
Topics in Web Systems and Technologies (HotWeb), Washington, DC, USA, 12–13 November 2015; IEEE: Washington DC, DC, USA,
2015; pp. 73–78. [CrossRef]
109. Ni, J.; Zhang, K.; Lin, X.; Shen, X. Securing Fog Computing for Internet of Things Applications: Challenges and Solutions. IEEE
Commun. Surv. Tutor. 2018, 20, 601–628. [CrossRef]
110. Aazam, M.; Huh, E.-N. Fog Computing Micro Datacenter Based Dynamic Resource Estimation and Pricing Model for IoT.
In Proceedings of the 2015 IEEE 29th International Conference on Advanced Information Networking and Applications, Gwangju, Korea,
25–27 March 2015; IEEE: Gwangiu, Korea, 2015; pp. 687–694. [CrossRef]
111. Dastjerdi, A.V.; Gupta, H.; Calheiros, R.N.; Ghosh, S.K.; Buyya, R. Fog Computing: Principles, Architectures, and Applications.
In Internet of Things: Principles and Paradigms; Morgan Kaufmann: San Francisco, CA, USA, 2016; pp. 61–75.
112. Abujubbeh, M.; Al-Turjman, F.; Fahrioglu, M. Software-Deﬁned Wireless Sensor Networks in Smart Grids: An Overview. Sustain.
Cities Soc. 2019, 51, 101754. [CrossRef]
113. Barik, R.K.; Gudey, S.K.; Reddy, G.G.; Pant, M.; Dubey, H.; Mankodiya, K.; Kumar, V. FogGrid: Leveraging Fog Computing
for Enhanced Smart Grid Network. In Proceedings of the 2017 14th IEEE India Council International Conference (INDICON),
Roorkee, India, 5–17 December 2017; IEEE: Roorkee, India, 2017; pp. 1–6. [CrossRef]
114. Brzoza-Woch, R.; Konieczny, M.; Kwolek, B.; Nawrocki, P.; Szydło, T.; Zieli´nski, K. Holistic Approach to Urgent Computing for
Flood Decision Support. Procedia Comput. Sci. 2015, 51, 2387–2396. [CrossRef]
115. Fog Computing: Concepts, Frameworks and Technologies; Mahmood, Z. (Ed.) Springer International Publishing: Cham, Switzerland,
2018. [CrossRef]
116. Al-Turjman, F.; Malekloo, A. Smart Parking in IoT-Enabled Cities: A Survey. Sustain. Cities Soc. 2019, 49, 101608. [CrossRef]
117. Dastjerdi, A.V.; Buyya, R. Fog Computing: Helping the Internet of Things Realize Its Potential. Computer 2016, 49, 112–116.
[CrossRef]
118. Gia, T.N.; Jiang, M.; Rahmani, A.-M.; Westerlund, T.; Liljeberg, P.; Tenhunen, H. Fog Computing in Healthcare Internet of Things:
A Case Study on ECG Feature Extraction. In Proceedings of the 2015 IEEE International Conference on Computer and Information
Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and
Computing, Liverpool, UK, 26–28 October 2015; IEEE: Liverpool, UK, 2015; pp. 356–363. [CrossRef]
119. Stantchev, V.; Barnawi, A.; Ghulam, S.; Schubert, J.; Tamm, G. Smart Items, Fog and Cloud Computing as Enablers of Servitization
in Healthcare. Sens. Transducers. 2015, 185, 121–128.
Sensors 2022, 22, 196
36 of 38
120. Zahmatkesh, H.; Al-Turjman, F. Fog Computing for Sustainable Smart Cities in the IoT Era: Caching Techniques and Enabling
Technologie—An Overview. Sustain. Cities Soc. 2020, 59, 102139. [CrossRef]
121. Perera, C.; Qin, Y.; Estrella, J.C.; Reiff-Marganiec, S.; Vasilakos, A.V. Fog Computing for Sustainable Smart Cities: A Survey. ACM
Comput. Surv. 2017, 50, 1–43. [CrossRef]
122. Hajibaba, M.; Gorgin, S. A Review on Modern Distributed Computing Paradigms: Cloud Computing, Jungle Computing and
Fog Computing. CIT 2014, 22, 69. [CrossRef]
123. Puthal, D.; Sahoo, B.P.S.; Mishra, S.; Swain, S. Cloud Computing Features, Issues, and Challenges: A Big Picture. In Proceedings
of the 2015 International Conference on Computational Intelligence and Networks, Jabalpur, India, 12–14 December 2015; IEEE: Odisha,
India, 2015; pp. 116–123. [CrossRef]
124. Varghese, B.; Buyya, R. Next Generation Cloud Computing: New Trends and Research Directions. Future Gener. Comput. Syst.
2018, 79, 849–861. [CrossRef]
125. Moura, J.; Hutchison, D. Review and Analysis of Networking Challenges in Cloud Computing. J. Netw. Comput. Appl. 2016, 60,
113–129. [CrossRef]
126. Abbas, Z.; Yoon, W. A Survey on Energy Conserving Mechanisms for the Internet of Things: Wireless Networking Aspects.
Sensors 2015, 15, 24818–24847. [CrossRef]
127. Silva, B.N.; Khan, M.; Han, K. Internet of Things: A Comprehensive Review of Enabling Technologies, Architecture, and
Challenges. IETE Tech. Rev. 2018, 35, 205–220. [CrossRef]
128. Bouzarkouna, I.; Sahnoun, M.; Sghaier, N.; Baudry, D.; Gout, C. Challenges Facing the Industrial Implementation of Fog
Computing. In Proceedings of the 2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud), Barcelona,
Spain, 6–8 August 2018; IEEE: Barcelona, Spain, 2018; pp. 341–348. [CrossRef]
129. Olaniyan, R.; Fadahunsi, O.; Maheswaran, M.; Zhani, M.F. Opportunistic Edge Computing: Concepts, Opportunities and
Research Challenges. Future Gener. Comput. Syst. 2018, 89, 633–645. [CrossRef]
130. Ullah, R.; Ahmed, S.H.; Kim, B.-S. Information-Centric Networking with Edge Computing for IoT: Research Challenges and
Future Directions. IEEE Access 2018, 6, 73465–73488. [CrossRef]
131. Nguyen, B.M.; Thi Thanh Binh, H.; The Anh, T.; Bao Son, D. Evolutionary Algorithms to Optimize Task Scheduling Problem for
the IoT Based Bag-of-Tasks Application in Cloud–Fog Computing Environment. Appl. Sci. 2019, 9, 1730. [CrossRef]
132. Singh, S.P.; Nayyar, A.; Kumar, R.; Sharma, A. Fog Computing: From Architecture to Edge Computing and Big Data Processing. J.
Supercomput. 2019, 75, 2070–2105. [CrossRef]
133. Singh, J.; Singh, P.; Gill, S.S. Fog Computing: A Taxonomy, Systematic Review, Current Trends and Research Challenges. J. Parallel
Distrib. Comput. 2021, 157, 56–85. [CrossRef]
134. Gill, S.S.; Buyya, R. Bio-Inspired Algorithms for Big Data Analytics: A Survey, Taxonomy, and Open Challenges. In Advances
in Ubiquitous Sensing Applications for Healthcare, Big Data Analytics for Intelligent Healthcare Management; Academic Press: Cambridge,
MA, USA, 2019; pp. 1–17. [CrossRef]
135. Oussous, A.; Benjelloun, F.-Z.; Ait Lahcen, A.; Belfkih, S. Big Data Technologies: A Survey. J. King Saud Univ.—Comput. Inf. Sci.
2018, 30, 431–448. [CrossRef]
136. Gandomi, A.; Haider, M. Beyond the Hype: Big Data Concepts, Methods, and Analytics. Int. J. Inf. Manag. 2015, 35, 137–144.
[CrossRef]
137. Hariri, R.H.; Fredericks, E.M.; Bowers, K.M. Uncertainty in Big Data Analytics: Survey, Opportunities, and Challenges. J. Big Data
2019, 6, 44. [CrossRef]
138. Badidi, E.; Mahrez, Z.; Sabir, E. Fog Computing for Smart Cities’ Big Data Management and Analytics: A Review. Future Internet
2020, 12, 190. [CrossRef]
139. Hussain, M.M.; Beg, M.M.S.; Alam, M.S. Fog Computing for Big Data Analytics in IoT Aided Smart Grid Networks. Wireless Pers.
Commun. 2020, 114, 3395–3418. [CrossRef]
140. Baldini, I.; Castro, P.; Chang, K.; Cheng, P.; Fink, S.; Ishakian, V.; Mitchell, N.; Muthusamy, V.; Rabbah, R.; Slominski, A.; et al.
Serverless Computing: Current Trends and Open Problems. In Research Advances in Cloud Computing; Chaudhary, S., Somani, G.,
Buyya, R., Eds.; Springer: Singapore, 2017; pp. 1–20. [CrossRef]
141. McGrath, G.; Brenner, P.R. Serverless Computing: Design, Implementation, and Performance. In Proceedings of the 2017 IEEE 37th
International Conference on Distributed Computing Systems Workshops (ICDCSW), Atlanta, GA, USA, 5–8 June 2017; IEEE: Atlanta,
GA, USA, 2017; pp. 405–410. [CrossRef]
142. Fox, G.C.; Ishakian, V.; Muthusamy, V.; Slominski, A. Status of Serverless Computing and Function-as-a-Service (FaaS) in Industry
and Research. arXiv Preprint 2017, arXiv:1708.08028.
143. Aslanpour, M.S.; Toosi, A.N.; Cicconetti, C.; Javadi, B.; Sbarski, P.; Taibi, D.; Assuncao, M.; Gill, S.S.; Gaire, R.; Dustdar, S.
Serverless Edge Computing: Vision and Challenges. In Proceedings of the 2021 Australasian Computer Science Week Multiconference,
Dunedin, New Zealand, 1–5 February 2021; ACM: Dunedin, New Zealand, 2021; pp. 1–10. [CrossRef]
144. Bouraga, S. A Taxonomy of Blockchain Consensus Protocols: A Survey and Classiﬁcation Framework. Expert Syst. Appl. 2021,
168, 114384. [CrossRef]
145. Mamdiwar, S.D.; R, A.; Shakruwala, Z.; Chadha, U.; Srinivasan, K.; Chang, C.-Y. Recent Advances on IoT-Assisted Wearable
Sensor Systems for Healthcare Monitoring. Biosensors 2021, 11, 372. [CrossRef] [PubMed]
Sensors 2022, 22, 196
37 of 38
146. Ankenbrand, T.; Bieri, D.; Cortivo, R.; Hoehener, J.; Hardjono, T. Proposal for a Comprehensive (Crypto) Asset Taxonomy.
In Proceedings of the 2020 Crypto Valley Conference on Blockchain Technology (CVCBT), Rotkreuz, Switzerland, 11–12 June 2020; IEEE:
Rotkreuz, Switzerland, 2020; pp. 16–26. [CrossRef]
147. Gill, S.S. Quantum and blockchain based Serverless edge computing: A vision, model, new trends and future directions. Internet
Technol. Lett. 2021, e275. [CrossRef]
148. Gill, S.S.; Kumar, A.; Singh, H.; Singh, M.; Kaur, K.; Usman, M.; Buyya, R. Quantum Computing: A Taxonomy, Systematic Review
and Future Directions. Softw: Pract. Exper. 2022, 52, 66–114. [CrossRef]
149. Gill, S.S. A Manifesto for Modern Fog and Edge Computing: Vision, New Paradigms, Opportunities, and Future Directions.
In Operationalizing Multi-Cloud Environments; Nagarajan, R., Raj, P., Thirunavukarasu, R., Eds.; EAI/Springer Innovations
in Communication and Computing; Springer International Publishing: Cham, Switzerland, 2022; pp. 237–253. [CrossRef]
150. Liu, W.; Chen, J.; Wang, Y.; Gao, P.; Lei, Z.; Ma, X. Quantum-Based Feature Selection for Multiclassiﬁcation Problem in Complex
Systems with Edge Computing. Complexity 2020, 2020, 8216874. [CrossRef]
151. Kreutz, D.; Ramos, F.M.V.; Esteves Verissimo, P.; Esteve Rothenberg, C.; Azodolmolky, S.; Uhlig, S. Software-Deﬁned Networking:
A Comprehensive Survey. Proc. IEEE 2015, 103, 14–76. [CrossRef]
152. Duan, Y.; Li, W.; Fu, X.; Luo, Y.; Yang, L. A Methodology for Reliability of WSN Based on Software Deﬁned Network in Adaptive
Industrial Environment. IEEE/CAA J. Autom. Sinica 2018, 5, 74–82. [CrossRef]
153. Raﬁque, W.; Qi, L.; Yaqoob, I.; Imran, M.; Rasool, R.U.; Dou, W. Complementing IoT Services through Software Deﬁned
Networking and Edge Computing: A Comprehensive Survey. IEEE Commun. Surv. Tutorials 2020, 22, 1761–1804. [CrossRef]
154. Deng, S.; Zhao, H.; Fang, W.; Yin, J.; Dustdar, S.; Zomaya, A.Y. Edge Intelligence: The Conﬂuence of Edge Computing and
Artiﬁcial Intelligence. IEEE Internet Things J. 2020, 7, 7457–7469. [CrossRef]
155. Zou, Z.; Nevalainen, P.; Huan, Y.; Heikkonen, J.; Westerlund, T. Edge and Fog Computing Enabled AI for IoT—An Overview.
In Proceedings of the 2019 IEEE International Conference on Artiﬁcial Intelligence Circuits and Systems (AICAS), Hsinchu,
Taiwan, 18–20 March 2019; IEEE: Hsinchu, Taiwan, 2019.
156. Huh, J.-H.; Seo, Y.-S. Understanding Edge Computing: Engineering Evolution with Artiﬁcial Intelligence. IEEE Access 2019, 7,
164229–164245. [CrossRef]
157. Murugesan, S. Harnessing Green IT: Principles and Practices. Green Comput. 2008, 10, 24–33. [CrossRef]
158. Anand, P.; Singh, Y.; Selwal, A.; Alazab, M.; Tanwar, S.; Kumar, N. IoT Vulnerability Assessment for Sustainable Computing:
Threats, Current Solutions, and Open Challenges. IEEE Access 2020, 8, 168825–168853. [CrossRef]
159. Lopez, O.L.A.; Alves, H.; Souza, R.D.; Montejo-Sanchez, S.; Fernandez, E.M.G.; Latva-Aho, M. Massive Wireless Energy Transfer:
Enabling Sustainable IoT Toward 6G Era. IEEE Internet Things J. 2021, 8, 8816–8835. [CrossRef]
160. Kumari, A.; Gupta, R.; Tanwar, S.; Kumar, N. Blockchain and AI Amalgamation for Energy Cloud Management: Challenges,
Solutions, and Future Directions. J. Parallel Distrib. Comput. 2020, 143, 148–166. [CrossRef]
161. Khairy, S.; Han, M.; Cai, L.X.; Cheng, Y. Sustainable Wireless IoT Networks with RF Energy Charging over Wi-Fi (CoWiFi). IEEE
Internet Things J. 2019, 6, 10205–10218. [CrossRef]
162. Banerjee, U.; Juvekar, C.; Fuller, S.H.; Chandrakasan, A.P. EeDTLS: Energy-Efﬁcient Datagram Transport Layer Security for
the Internet of Things. In Proceedings of the GLOBECOM 2017—2017 IEEE Global Communications Conference, Singapore, 4–8
December 2017; IEEE: Singapore, 2017; pp. 1–6. [CrossRef]
163. Ram, S.K.; Sahoo, S.R.; Das, B.B.; Mahapatra, K.; Mohanty, S.P. Eternal-Thing: A Secure Aging-Aware Solar-Energy Harvester
Thing for Sustainable IoT. IEEE Trans. Sustain. Comput. 2021, 6, 320–333. [CrossRef]
164. Makhdoom, I.; Abolhasan, M.; Lipman, J.; Liu, R.P.; Ni, W. Anatomy of Threats to the Internet of Things. IEEE Commun. Surv.
Tutor. 2019, 21, 1636–1675. [CrossRef]
165. Dhanda, S.S.; Singh, B.; Jindal, P. Lightweight Cryptography: A Solution to Secure IoT. Wireless Pers. Commun. 2020, 112,
1947–1980. [CrossRef]
166. Samie, F.; Bauer, L.; Henkel, J. From Cloud down to Things: An Overview of Machine Learning in Internet of Things. IEEE
Internet Things J. 2019, 6, 4921–4934. [CrossRef]
167. Samann, F.E.F.; Abdulazeez, A.M.; Askar, S. Fog Computing Based on Machine Learning: A Review. Int. J. Interact. Mob. Technol.
2021, 15, 21. [CrossRef]
168. Hurbungs, V.; Bassoo, V.; Fowdur, T.P. Fog and Edge Computing: Concepts, Tools and Focus Areas. Int. J. Inf. Tecnol. 2021, 13,
511–522. [CrossRef]
169. Losavio, M. Fog Computing, Edge Computing and a Return to Privacy and Personal Autonomy. Proc. Comp. Sci. 2020, 171,
1750–1759. [CrossRef]
170. Wang, M.; Cui, Y.; Wang, X.; Xiao, S.; Jiang, J. Machine Learning for Networking: Workﬂow, Advances and Opportunities. IEEE
Netw. 2018, 32, 92–99. [CrossRef]
171. Laghari, A.A.; Jumani, A.K.; Laghari, R.A. Review and State of Art of Fog Computing. Arch. Computat. Methods Eng. 2021, 28,
3631–3643. [CrossRef]
172. Hegarty, R.; Taylor, M. Digital Evidence in Fog Computing Systems. Comp. Law Secur. Rev. 2021, 41, 105576. [CrossRef]
173. Mehta, S.; Singh, A.; Singh, K.K. Role of Machine Learning in Resource Allocation of Fog Computing. In Proceedings of the 2021
11th International Conference on Cloud Computing, Data Science & Engineering (Conﬂuence), Noida, India, 28–29 January 2021; IEEE:
Noida, India, 2021; pp. 262–266. [CrossRef]
Sensors 2022, 22, 196
38 of 38
174. Suryadevara, N.K. Energy and Latency Reductions at the Fog Gateway Using a Machine Learning Classiﬁer. Sustain. Comput.
Inform. Syst. 2021, 31, 100582. [CrossRef]
175. Cui, L.; Yang, S.; Chen, F.; Ming, Z.; Lu, N.; Qin, J. A Survey on Application of Machine Learning for Internet of Things. Int. J.
Mach. Learn. Cyber. 2018, 9, 1399–1417. [CrossRef]
176. Adi, E.; Anwar, A.; Baig, Z.; Zeadally, S. Machine Learning and Data Analytics for the IoT. Neural. Comp. Applic. 2020, 32,
16205–16233. [CrossRef]
177. Ayoubi, S.; Limam, N.; Salahuddin, M.A.; Shahriar, N.; Boutaba, R.; Estrada-Solano, F.; Caicedo, O.M. Machine Learning for
Cognitive Network Management. IEEE Commun. Mag. 2018, 56, 158–165. [CrossRef]
178. Fadlullah, Z.M.; Tang, F.; Mao, B.; Kato, N.; Akashi, O.; Inoue, T.; Mizutani, K. State-of-the-Art Deep Learning: Evolving Machine
Intelligence toward Tomorrow’s Intelligent Network Trafﬁc Control Systems. IEEE Commun. Surv. Tutor. 2017, 19, 2432–2455.
[CrossRef]
179. Hammerschmidt, C.A.; Garcia, S.; Verwer, S.; State, R. Reliable Machine Learning for Networking: Key Issues and Approaches.
In Proceedings of the 2017 IEEE 42nd Conference on Local Computer Networks (LCN), Singapore, 9–12 October 2017; IEEE: Singapore,
2017; pp. 167–170. [CrossRef]
180. Casas, P.; Vanerio, J.; Fukuda, K. GML Learning, a Generic Machine Learning Model for Network Measurements Analysis.
In Proceedings of the 2017 13th International Conference on Network and Service Management (CNSM), Tokyo, Japan, 26–30 November
2017; IEEE: Tokyo, Japan, 2017; pp. 1–9. [CrossRef]
181. Sobecki, A.; Szyma´nski, J.; Gil, D.; Mora, H. Deep Learning in the Fog. Int. J. Distrib. Sens. Netw. 2019, 15, 155014771986707.
[CrossRef]


Paper 4:
- APA Citation: Zhang, X., Cao, Z., & Dong, W. (2020). Overview of Edge Computing in the Agricultural Internet of Things: Key Technologies, Applications, Challenges. IEEE Access, 8, 141748-141761. https://doi.org/10.1109/ACCESS.2020.3013005
  Main Objective: To explore the application of edge computing and fog computing in real-time irrigation management systems.
  Study Location: Unspecified
  Data Sources: Not explicitly stated
  Technologies Used: Edge computing, fog computing, Internet of Things (IoT), machine learning
  Key Findings: Edge computing and fog computing can be used to improve the efficiency and accuracy of irrigation systems, leading to increased crop yields and reduced water usage.
  Extract 1: Edge computing has prospects in agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management.
  Extract 2: The emergence of Edge computing models such as fog computing, Cloudlet and Mobile Edge computing have made the Agricultural IoT a milestone. It has completely transformed the management and operation of the farm.
  Limitations: The paper does not provide any specific examples of how edge computing and fog computing have been used to improve irrigation systems in the real world.
  Relevance Evaluation: This paper is highly relevant to the outline point, as it specifically discusses the use of edge computing and fog computing in real-time irrigation management. The paper provides a comprehensive overview of the potential benefits of these technologies, and it offers specific examples of how they can be used to improve irrigation systems.
  Relevance Score: 1.0
  Inline Citation: (Zhang et al., 2020)
  Explanation: This paper examines the potential applications of edge computing and fog computing in real-time irrigation management. Edge computing can be used to process data closer to the source, reducing latency and improving the efficiency of irrigation systems. Fog computing can be used to provide distributed computing resources for more complex tasks, such as image processing and machine learning. Together, these technologies can help to improve the efficiency and accuracy of irrigation systems, leading to increased crop yields and reduced water usage.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 8 Overview of Edge Computing in the Agricultural Internet of Things: Key Technologies, Applications, Challenges Publisher: IEEE Cite This PDF Xihai Zhang; Zhanyuan Cao; Wenbin Dong All Authors 68 Cites in Papers 5985 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. Background III. Research Status of Edge Computing in Agricultural IoT IV. Challenges V. Conclusion and Prospects Authors Figures References Citations Keywords Metrics Abstract: The application of the Internet of Things in agricultural development usually occurs via a monitoring network that consists of a large number of sensor nodes, thus gradually transforming agriculture from a human-oriented and single-machine-centric production model to an information- and software-centric production model. Due to the large area coverage of agriculture and the variety of production objects, if all farmland perception information is gathered into the cloud server, the server will exert greater pressure on the network, which reduces the speed of response to event processing. This problem may be perfectly solved by the recent emergence of Edge computing, which can share the load of the cloud server and reduce the delay. Edge computing has prospects in agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. The application of the Agricultural Internet of Things integrates artificial intelligence, the Internet of Things, and blockchain and Virtual/Augmented Reality technologies. This paper primarily reviews the application of Edge computing in the Agricultural Internet of Things and investigates the combination of Edge computing and Artificial Intelligence, blockchain and Virtual/Augmented reality technology. The challenges of Edge computing task allocation, data processing, privacy protection and security, and service stability in agriculture are reviewed. The future development direction of Edge computing in the Agricultural Internet of Things is predicted. Three key technologies of agricultural IoT based on edge computing. Published in: IEEE Access ( Volume: 8) Page(s): 141748 - 141761 Date of Publication: 31 July 2020 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.3013005 Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction Agriculture is the foundation of human survival and plays a fundamental role. It is vital to the stability and the development of society. However, with the emergence of three factors that restrict agricultural development: (i) population aging and migration (also known as urbanization) have led to a gradual decline of rural labor; (ii) industrial buildings and residential buildings are gradually eroding agricultural land, resulting in a reduction in agricultural land [1]; (iii) increased climate change will also continue to change crop growth conditions such as temperature, precipitation and soil moisture in unpredictable ways [2]. The challenges that agriculture faces are increasingly severe. In order to meet the challenges, people must be seize the opportunity of the third revolution in the information technology industry, for example, Internet of Things (IoT), big data, artificial intelligence et al.. They can bring fundamental changes to agriculture. The Agricultural Internet of Things (Agricultural IoT) not only solves the problems of increasing food demand, environmental pollution caused by excessive use of pesticides and fertilizers, and the safety of agricultural products [3], but also reduces labor costs [4], greatly promoting the continuous development of agriculture in the direction of high quality and high output. However, the widespread use of the Agricultural IoT has led to the explosive growth of sensors and the increasing number of data. The large amount of data increases the load on the cloud server, which reduces the response speed. The emergence of the Edge computing models can solve the problem of cloud server load. The classical Edge computing models include: the Cloudlet introduced by Satyanarayanan solves the latency problem of accessing the cloud by using computing resources available in the local network; the Fog computing introduced by Cisco enables applications to run directly on the edge of the network through billions of smart connected devices; the Mobile Edge computing introduced by the European Telecommunications Standards Institute (ETSI) allows mobile users to utilize computing services from base stations. Through the emergence of three classical Edge computing models, we can find a new trend: some calculations that take place in the cloud are gradually moving to the edge [5]. Similarly, the data generated by the Agricultural IoT is also increasing, resulting in increased load on the cloud server. In order to share the offload of the cloud server, the computation that occurs in the cloud is offloaded to the edge segment for execution. In addition, the real-time requirements of some applications of the Agricultural Internet of Things are high. The edge server is close to the data source, so it provides intelligent services nearby and shortens the response time. Although the Edge computing is favorable for agricultural development, but Edge computing applied to agriculture has little literature, so we combine with a lot of related literature and present a review of the application of Edge computing in the Agricultural IoT, which inspires more people to develop the Agricultural IoT under Edge computing in the future. This paper reviews the concept and research status of the Edge computing and Agricultural IoT. In addition, we describe in detail the research status of Edge computing in the application of pest identification and crop classification, agricultural product safety traceability, unmanned agricultural machinery, agricultural product promotion, etc., which mainly involves artificial intelligence, blockchain and virtual/augmented reality technology. In the end, the literature also mentions the challenges and opportunities of the combination of Edge computing and Agricultural IoT, and provides direction for the development of Edge computing and Agricultural IoT. The organizational structure of this paper is as follows. In Section II, it mainly introduces the concept of Edge computing and Agricultural IoT in detail; the necessity of combining Edge computing with the Agricultural IoT is discussed in Section II; then in Section III, the application of Agricultural IoT combined with Edge computing is reviewed; in Section IV, Edge computing combined Agricultural IoT meets the challenges; finally, the paper is concluded and a vision of their future is described in Section V. SECTION II. Background This section mainly introduces the concept, structure, and research status of Edge computing and Agricultural IoT. The aim of this section is to provide the reader with a solid foundation of the research subject. A. Edge Computing 1) Definition and Development of Edge Computing With the rapid development of the IoT, billions of smart devices are installed each year. It is estimated that more than 70 billion smart devices will be installed by 2020. The access of a large number of devices has led to an increase in the amount of data to be processed. We face the challenge of processing and analyzing those data, especially if it needs to be processed in real time. Simply using a cloud server is not able to provide real-time response while handling such a large data set. Edge computing is proposed for solving the problem of data explosion and network delay. The research fields of Edge computing include Fog computing [6], Cloudlet [7], [8] and Mobile Edge computing (MEC) [9], [10]. Although Edge computing has been proposed for a long time, there is no uniform and strict definition. Satyanarayanan [11] defines it as, “Edge computing is a new computing model that deploys computing and storage resources (such as Cloudlets, fog nodes) to networks closer to mobile devices or sensors.” Its system architecture is shown in Fig. 1, which is divided into three layers: terminal device, edge node and cloud center. As we all know, 5G is becoming more and more popular, and edge computing is one of the core technologies in the 5G era, but its architecture is open and can also be deployed and applied to 4G LTE networks. Operators will smoothly evolve on the existing network structure, and finally achieve full coverage of the computing power of low-level network nodes, and continue to improve edge computing capabilities. FIGURE 1. The system architecture. Show All From the development trend since 2010, the attention of Edge computing continues to rise, as shown in Fig. 2 (Some data quoted from [12]). Especially since 2016, the attention of Edge computing has increased rapidly. Shi et al. derived five typical scenarios for the application of Edge computing: cloud offload, video analytics, collaborative edge, smart home, smart city [13]. Sun et al. proposed a real-time fault detection algorithm based on Edge computing and cloud computing for the video monitoring system, which effectively improved the average repair time [14]. In [15], in order to meet the demand of smart home, a system based on Edge computing was designed to predict the demand for household electricity. The system can provide better quality of service and enhance the scalability of the system. In [16], Higashino et al. proposed a large-scale spatio-temporal information collection mechanism based on Edge computing and IoT to mitigate disasters and build a safe and intelligent city. FIGURE 2. Number of papers retrieved by “Edge computing” on Google Scholar. Show All 2) The Hierarchy of Edge Computing The Edge Computing Consortium (ECC) defines four areas for Edge computing: equipment domain (Perception and control layer), network domain (Connection and network layer), data domain (Storage and service layer), application domain (Business and intelligence layer). As shown in Fig. 3: these four layers are the computing objects of Edge computing. FIGURE 3. The hierarchical deployment structure for Edge computing. Show All Equipment domain: in the equipment domain, Edge computing can directly process the perceived information. For example, intelligent identification can be directly deployed in video collection and audio collection. Network domain: in the network domain, the automatic conversion of each network protocol is realized, and the data format is standardized. At the same time, the Edge computing in the network domain can conduct intelligent management of the “converged network”, reduce the redundancy of the network, ensure the security of the network, and further participate in the optimization of the network. Data domain: Edge computing in the data domain makes data management smarter and more flexible. First, Edge computing can analyze the integrity and consistency of the data, and conduct data collation to delete redundant and wrong data in the system. Secondly, Edge computing can maintain efficient coordination with cloud computing and share cloud computing tasks. Application domain: Edge computing in the application domain provides localized business logic and application intelligence. It enables applications to be flexible and fast- responding. Edge computing can provide localized application services independently, when it loses contact with the cloud. Edge computing is deployed in the above four domains, where it is closer to the user and application scenarios. It enables the device to have intelligent sensing capabilities and it can be equipped with adaptive connection strategies and more optimized deployment strategies. It can solve data heterogeneity and related network synchronization problems in the system, and provide local business logic and application intelligence. Edge computing is an open and distributed platform that provides network, computing, and storage services at the edge of the network, close to the data end. It meets the demands of intelligent, real-time business, data optimization, and security aspects of agricultural digital transformation. In addition, there are two kinds of edge servers mentioned in this paper: remote edge computing servers located on the edge of wireless network; local edge computing device. B. Agricultural Internet of Things 1) Definition and Development of Agricultural IoT Since the IoT technology is proposed in 1999, it has gradually penetrated into various fields [17], [18]. Agriculture is the focus of attention of people all over the world, and it is naturally also involved. With regard to the concept of Agricultural IoT, different researchers have given different interpretations from different perspectives. For example, Li et al. [19] believe that the Agricultural IoT usually refers to the use of relevant sensing devices to perceive information on environmental factors in plants, agricultural production tools, etc., and an informational network for real-time monitoring of agricultural production processes, positioning and management of agricultural production objects based on pre-defined protocols for data transmission. The characteristics of Agricultural IoT are relatively clear, mainly in the aspect comprehensive perception, intelligent processing and timely feedback of agriculture from planting to sales [20]. The emergence of cloud computing and its extended Edge computing models such as fog computing and Mobile Edge computing have made the Agricultural IoT a milestone. It has completely transformed the management and operation of the farm [21]. The Agricultural IoT has made great progress in recent years. Xing et al. designed a greenhouse information intelligent monitoring system based on ZigBee wireless sensing technology [22]. Diego et al. designed agrometeorological monitoring station based on Bluetooth technology, and the data was sent to the computer through the wireless Bluetooth module [23]. In order to realize the collection, management, visualization and upload of real-time information in paddy fields, Zhang et al. proposed a paddy field information monitoring system based on Solar-Powered Panel and GPRS technology [24]. However, both ZigBee and GPRS are short-range wireless technologies and have high operating costs. Therefore, a wide area network monitoring system combining NB-IoT and LoRa is designed in [25]. By studying the development of farmland monitoring systems, we find that the development of Agricultural IoT is not only reflected in the rapid growth of the types and quantities of agricultural sensors, but also in combination with emerging technologies. 2) Architecture of Agricultural IoT At the beginning of development, Agricultural IoT mainly focused on the application of the single entity, which leads to the scalability, scalability and interoperability of the entire system gradually fail to meet the growing demand of the agricultural production. Later, the new hierarchical structure model of Agricultural IoT was proposed, based on the specific needs of agricultural production and marketing, combined with the principles of safety, reusability and expansion of IoT systems and practical experience. As shown in Fig. 4, the model is divided into five layers from top to bottom, including the sensing layer, the transport layer, the application layer, etc. The communication protocols and data are transmitted between the layers using different communication protocols. FIGURE 4. The agricultural IoT architecture (AIoT in the picture represents the Agricultural IoT). Show All The sensing layer of the Agricultural IoT consists of various sensor uses Wi-Fi, GPRS, and ZigBee technologies to transmit data, and transmits the collected data to the access layer of the Agricultural IoT system structure; the access layer is mainly composed of hardware gateways and built-in software middleware. The middleware can effectively shield the complexity of the underlying heterogeneous sensing network and provide a unified abstract management interface to provide a foundation for the rapid establishment of Agricultural IoT business applications; the network layer transmits data to the upper layer through Internet Protocol, mobile communication network protocols; the Agricultural IoT data sharing layer is equivalent to a huge data pool, which realizes the integrated sharing of various types of monitoring data. The layer mainly uses transmission protocols such as TCP and UDP; the application layer obtains data from the data sharing layer through protocols such as HTTP, FTP and other protocols and constructs a corresponding Agricultural IoT system. Compared with the traditional three-layer and four-layer IoT architecture, the functions of each layer in the five-layer Agricultural IoT architecture are clearer and more independent, which is beneficial to the network load balancing between servers at different levels, and can reduce the communication burden of the enterprise network. C. The Necessity of Combining Edge Computing With Agricultural IoT Based on the combination of IoT and cloud, the Agricultural IoT system has simple device access and rapid system setup. However, due to the centralized processing of data by the cloud computing model, it is difficult to solve the following problems when the device and data are exploding. (1) Excessive resource cost: the sensors continuously collect various sensor data, and the data is usually stable or rarely changed. Uploading all the data to the cloud for processing will consume a lot of network resources and cloud resources. (2) Real-time performance is difficult to guarantee: data processing and decision-making are all in the cloud, and the processing is not timely. (3) Excessive reliance on the network: when the network is unstable, it cannot process data and control devices in time. (4) Data security and privacy protection: all sensor data and control data need to be transmitted through the network, and there are risks such as information eavesdropping, tampering, fraud and illegal operation of equipment. These problems will increase the cost of Agricultural IoT systems (network flow, storage, and computational costs), reduce stability and availability of system, and make it difficult to automate production control, especially in large-scale, factory-planted, and aquaculture. In addition, non-standard and self-resource limitations of sensors and control devices (including computing, storage capabilities, etc.) bring obstacles to device access and linkage control. Therefore, it is necessary to study and solve the above problems to develop smart agriculture and promote precision agriculture. Edge computing provides intelligent services at the edge of the networks which are close to thing or data source, enabling each edge of the IoT to have data collection, analysis, computing, and intelligent processing capabilities to process data, filter data, and analyze data nearby. In addition, local decision- making and processing can meet key requirements of network capabilities and resource constraints, security and privacy challenges. Therefore, we introduce Edge computing into the Agricultural IoT system to improve the standardization, stability, and availability of the agricultural IoT system. SECTION III. Research Status of Edge Computing in Agricultural IoT This section introduces the concepts of Artificial Intelligence (AI), blockchain and Virtual Reality /Augmented Reality and their research status in agriculture. The most important concept is to summarize the research status of Edge computing and Agricultural IoT application technology. A. Research on Artificial Intelligence in Agriculture Based on Edge Computing Since the breakthrough in deep learning in 2001, AI has entered a new era and is gradually infiltrating the modern agricultural field and injecting new vitality and a new impetus into the development of modern agriculture. In addition, the rapid development of mobile computing technology and the IoT has generated billions of bytes of data at the edge of the network. Driven by this trend, AI must be pushed to the edge of the network to fully release the potential of edge big data. This situation caused the emergence of Edge computing, which is an emerging paradigm that pushes computing tasks and services from the core of the network to the edge of the network. AI computing is becoming increasingly complex, and an increasing amount of data is needed. As a result, edge intelligence (EI) is generated as an interdisciplinary subject of AI and Edge computing [26]. Edge intelligence leverages the available data and resources of end devices, edge nodes, and cloud centers to optimize the total training and reasoning performance of the deep learning model. In 2–5 years later, the Edge computing technologies and machine learning will be in the mainstream [27]. AI has a place in Agricultural IoT application technology and is primarily employed in video analysis, unmanned agricultural machinery, pest identification, and plant species identification. Therefore, the research of edge intelligence is one of the most important components of future research topics. 1) Artificial Intelligence AI is a branch of computer science. Research in this area includes robotics, language recognition, image recognition, natural language processing, and expert systems. The AI mentioned in this paper primarily involves image processing; its main applications in agriculture are pest and disease identification, crop species identification, and unmanned agricultural machinery. Since Yann LeCun published Gradient-based learning applied to document recognition in 1998 [28], deep learning has been developed for more than 20 years. Represented by the well-known Convolutional Neural Network (CNN), deep learning has achieved leapfrog development in recent years due to the following four classic CNNs: AlexNet [29], VGG [30], GoogleNet [31] and ResNet [32]. Zhang et al. improved the GoogleNet model structure and Cifar10 model structure and applied an improved model to training of corn leaf pest identification, which improved the optimal recognition accuracy by 0.4% and 1.7% respectively [33]. Too et al. [34] directly tuned the VGG16, Inception-V4, ResNet, and DenseNet networks and applied them to train and test insect images from 14 plants in the PlantVillage image set. They compared the experimental results by using different iterations and attained the optimal recognition accuracy of 99.75%. Goh et al. constructed an optimal Convolutional Neural Network to complete the classification task based on plant mutants and improve the classification success rate [35]. Research on the accuracy of pest and disease identification is very mature but few studies examine the running time of the model. In this paper, the author proposes the idea of using Edge computing to reduce the running time of the model. According to the introduction of [26], the author summarizes the framework of edge intelligence, which includes the edge-based mode, device-based mode, edge-device mode, and edge-cloud mode, as shown in Fig. 5. In Fig. 5(a), the terminal devices receive the data and send data to the edge server. DNN model reasoning is performed on the edge server, and the forecast results are returned to the device. As shown in Fig. 5(b), the edge server sends the DNN model to the mobile device and locally performs model reasoning. As shown in Fig. 5(c), the device divides the DNN model into multiple parts. The device executes the DNN model to a specific layer and sends the intermediate data to the edge server. The edge server will execute the remaining layers, and the predicted result is sent to the mobile device. The device in Fig. 5(d) is responsible for input data collection, and the DNN model is executed in cooperation with the cloud through the edge. Due to the development of deep learning, the commonly employed models of DNN (such as AlexNet and GoogleNet) have reached millions of neurons. All neurons are concentrated in mobile devices or edge servers; thus, the hardware requirements are very high. Their concentration in the cloud server will cause delays; thus, use of the edge-cloud mode is common. FIGURE 5. Edge Intelligence inference modes: (a)Edge-based mode (b)Device-based mode (c) Edge-device mode (d) Edge-cloud mode. Show All 2) Research Status of Edge Intelligence In this section, we review the relevant literature on the combination of AI and Edge computing techniques. The role of edge nodes in AI is summarized in Table 1. TABLE 1 Overview of the Role of Edge Computing in Artificial Intelligence a: Execution of Part of the Program To solve the problems of insufficient processing capability and limited resources of terminal equipment, the industry introduced computational offloading in Mobile Edge Computing [36]. In the application of plant diseases and pests identification, the role of the edge server is to execute part of the program, which uses computing offload technology. At the same time we also need to consider the division of CNN or DNN procedures. MAUI is a system, which enables fine-grained energy-aware offload of mobile code to the infrastructure [37]. It maximizes the potential for energy savings through fine-grained code while minimizing changes to applications. It allows part of the program to be executed locally on the smart phone and others to be run remotely in the infrastructure. Second, MAUI provides a method for each application. But MAUI needs to perform an analysis step for each individual application, while performing DNN partitioning requires prediction. The Neurosurgeon lightweight scheduler proposed by Kang et al., makes decisions based on the DNN topology without any real-time analysis [38]. It selects the best partition point, optimizes end-to-end latency, and performs DNN division between mobile and cloud. The new computing paradigm reduces the computation required by the data center, thus shortening the query service time and improving the query throughput. The deep network layer is partitioned to respectively run on mobile devices and the cloud. Compared to [38], the deep network is further divided into cloud, fog computing devices and users’ mobile devices. Decommissioning procedures takes up some time, but their overall time is much shorter than the time they spend executing in the cloud center or terminal alone. Teerapittayanon et al. [39] for adapting to the cloud-edge-terminal distributed hierarchy, proposed a distributed depth neural network (DDNNs) based on distributed hierarchy. DNN is divided into various parts by Cloud Exit, Edge Exit and Local Exit, and then it is mapped into a distributed computing hierarchy. The structure takes advantage of the geographical diversity of sensors, which not only reduces communication costs but also improves the accuracy of target recognition. DeepX [40] divides the entire DNN or CNN into multiple parts and executes them on each local device. Its advantage is that it uses runtime layer compression (RLC), which no longer focuses on the training phase of deep learning and the compression of the entire model, but provides the memory consumed in the reasoning phase and the hierarchical compression of the computation runtime. Meanwhile, deep architecture decomposition (DAD) can effectively identify the units of the depth model quickly, decompose them, and allocate the blocks to local and remote processors. But DeepX cannot operate Recurrent Neural Networks (RNN) at present. The deep network layer is partitioned to respectively run on mobile devices and the cloud. Sun et al. [41] proposed mVideo to make full use of resources on collaborative edges and cloud nodes. The video stream processing platform is provided with a mechanism to partition video analysis tasks according to the available resources of mobile edge nodes. At the edge node, a lightweight DNN model is used to preprocess the video data, and the results are uploaded to the cloud node for further analysis. Its advantage is that the collected video data covers a large area and reduces communication costs. Overall, the execution time is reduced by 90%. b: Pretreatment The role of the edge server in the application of farm intelligent monitoring systems and unmanned agricultural machines is pre-processing. In the large-scale video stream analysis, the edge preprocessing is used to make a preliminary judgment of the object, so as to reduce the communication time and the load in the cloud center. The architecture of edge-enhanced video analysis system proposed by M.Ali is composed of camera terminal, edge node, cloudlet and cloud center [42]. The CNN model is trained and the generated model is saved in the cloud. The saved model is then transferred and distributed on cloudlets and cloud resources for object inference. In this paper, edge resources are used for the basic processing stage, which improves efficiency. But the authors did not experiment with the extensibility of the architecture. Edge preprocessing also includes compressing deep neural networks on edge devices. Model compression was introduced to overcome the difficulty of large computation and large memory consumption in the terminal of the model. In 2015, Han’s Deep compression model compression method was reviewed [43]. Cropping, weight sharing, quantization, and coding were applied to model compression and good results are achieved. Hardy et al. proposed a novel algorithm for updating and compressing models on the server [44]. It is flexible to perform distributed deep learning on edge devices through adaptive compression. In addition, the edge node also plays the role of a supervisor, which contains a test data set to calculate the accuracy of the central model. Finally, we found that compressing images in a system that sends images from edge nodes to cloud nodes can reduce communication bandwidth. But the introduction of compression technology also increases the computational overhead of compression and decompression. In general, transmitting smaller images may result in better performance overall, but higher compression rates may negatively affect prediction accuracy. Chandakkar et al. [45] proposed to update or train DNNs on edge devices to provide personalized services. How to deploy updates / training on mobile devices is our challenge. Moreover, simply from the experiment of updating the DNN, it is a hot research topic to study the catastrophic forgetting after construction in the next few years to maximize the data performance. c: Edge Caching Drolia et al. [46] were inspired by the web cache and proposed to add a cache module to the edge device. The advantage of caching on the edge server is that the images obtained by the terminals in the same area of the edge device service often have similarities. By caching the characteristics of these objects, these queries do not need to be submitted to the cloud, which can greatly reduce the delay of users. The challenge is that when the distribution of the query graph changes drastically, the Distribution Estimator in the edge device cannot quickly respond to the change. Later, they proposed Precog [47], which has the same application scenario, and it caches the models from the edge in the terminal device. This is a technology of edge and terminal device collaboration. When an object feature point query is missing on the terminal device, the image of the query is uploaded to the edge, and Markov Estimator in the edge records the query and sends the updated object probability distribution to the terminal device along with the query result. Precog has the same strengths and weaknesses as Cacher. In general, the program division is aimed at specific neural networks. Two or more edge servers can be used, and the combination of splitting and preprocessing and edge caching can make use of the specific structure of NN, thus providing more opportunities for optimization. B. Application of Edge Computing in Traceability of Agricultural Products An increasing number of people are eating organic agricultural products. However, due to the lack of common credit certificates in the market, people are not assured of the purchase of organic agricultural products. Therefore, tracing agricultural products is especially important. Wang et al. [48] and Zhang et al. [49] use an RFID-based meat traceability system, which traces from the customer to the manufacturer. It connects to the ONS server of the RFID system via the Internet and obtains the PML server of the IP address for each product-related point to obtain detailed information about product circulation; Lahbabi et al. proposed a traceability system that can share product certification information in real time [50]. Yun et al. described the research progress of key technologies in agricultural product traceability systems [51]. Azram et al. proposed a food document traceability model that is based on a software product line [52]. In the above centralized supply chain traceability system, members of the supply chain rely on an information provider to store, transmit, and share all information. The centralized system approach poses problems because it is a monopoly, asymmetric and opaque information system approach. This can lead to trust issues among players in the supply chain, including fraud, manipulation and tampering [53]. The blockchain, which is the underlying technology of digital currency, securely records transaction information for all currencies in a decentralized distributed ledger. The decentralization of the blockchain and the high transparency ensure that the traceability of stored data cannot be tampered with [54]. Many new distributed applications have been implemented based on blockchain technology. Many of these applications focus on the automation and digitization of financial sector processes. Automating processes can save money and increase transparency. Therefore, blockchain technology can potentially make a significant contribution to the efficiency and competitiveness of world agriculture. 1) Blockchain In 2008, Satoshi Nakamoto proposed the concept of blockchain. Blockchain refers to the technical solution of collectively maintaining a reliable ledger via decentralization and distrust [55]–[57]. The infrastructure model of blockchain technology include a data layer, network layer, consensus layer, incentive layer, contract layer and application layer. The centralized management of agricultural products and the tampering of data are solved by blockchain technology. Lucena et al. [58] proposed a method for measuring the grain quality using blockchains and smart contracts. They proposed an implementation of a practical case that increased the value of genetically modified (GM) exports of Brazilian grain exporters by 15%. To study how to promote value transfer by converting African farmers’ assets, such as livestock, farmland and agricultural products, into small-scale agriculture, Chinaka [59] and Schneider [60] proposed a product traceability system that is based on a prototype blockchain to improve the transparency and automation of the agricultural sector. Holmberg and Aquist [61] investigated a solution that is based on blockchain traceability in the dairy industry. These studies apply the concept of blockchain to product traceability but lack a framework of blockchain application. The structure diagram of a blockchain-based food safety traceability system proposed by Wang et al. [62] and Li and Wang [63] is shown in Fig 6. Based on this description, we determine that the application of blockchain in Agricultural IoT is increasing. FIGURE 6. Structure diagram of food safety traceability system based on blockchain. Show All 2) The Research Status Although the blockchain solves the problem in which data is easily falsified, the scalability of the blockchain is small and the memory is insufficient. The problem was solved by the combination of blockchain and edge computing technology. In table 2 an overview of the combination of edge computing and blockchain applications. Liu et al. proposed new electric vehicles cloud and edge (EVCE) as a typical application scenario of the Internet of Things, which also involves the transmission and transaction of information and energy [64]. At the same time, using the blockchain to connect the strong and weak electricity can provide EVCE with transparency and traceability security guarantees. Xu et al. proposed a product traceability system that is based on blockchain and Edge computing technology [65]. The role of the blockchain is to prevent malicious tampering by third parties. The edge server performs a difficult hash calculation with the blockchain node and returns the result to the blockchain node for verification. If the blockchain node does not have sufficient internal storage space, it can offload the entire blockchain to the edge server and store only relatively new blocks (referred to as storage offload) in the internal storage. The disadvantage is to consider the computing power of the edge nodes. In this regard, Stanciu proposed that the deployment of computing on the edge nodes requires smaller Dockers containers. The three-layer edge model was mentioned in [66]. It consists of physical devices and processes, edge nodes and cloud services. The blockchain is deployed on the top layer to ensure transaction security and to be properly verified. Edge computing solves the inconvenience caused by blockchain computing applications due to limited computing power and available energy consumption of Agricultural IoT terminal equipment. But the paper does not take into account the problem of the efficiency of identity verification and the vulnerability of the connection between the edge node and the terminal. In [67], a distributed trusted authentication system combining edge computing and blockchain is proposed. The system is composed of three parts: physical network layer, blockchain edge layer and blockchain network layer. Edge computing is applied in the edge nodes of the blockchain to provide name resolution and edge identity authentication services based on smart contracts. In addition, the edge computing cache strategy is proposed to improve the hit rate and reduce the delay. TABLE 2 Overview of the Combination of Edge Computing and Applications of Blockchain However, as the application of blockchain technology becomes more mature, the increase in data has caused inventory inflation [68]. The problem of insufficient storage arises when the blockchain is only applied to the digital currency, to which the application scenario of the blockchain is not limited. For example, in [54], transaction information involves files, videos, and audio, which generates higher requirements for blockchain storage capabilities. However, the high demand for storage of blockchain data is not conducive to the development of blockchain. By combining IPFS [69] and blockchain, a decentralized identity management solution is proposed. According to [70] and [71], the working principle of the agricultural product traceability system, which is based on blockchain technology and combines Edge Computing and the IPFS mechanism, is shown in Fig. 7: Edge Computing is used to manage local networks, package data formats, and provide computing power. Data is transmitted from the intelligent terminal to the edge node through the edge gateway, and files with large memory, such as photos and videos, are stored via the IPFS mechanism. The content hash value returned after the storage is transmitted to the edge node through the cloud server. The value is packaged in the JSON format with the previous data, and the packaged data is stored in the blockchain in the form of a transaction. Once the transaction is completed, the data stored in the blockchain cannot be tampered with, and the data is queried in real time based on the hash value after the transaction. In the security traceability architecture of blockchain products based on edge computing, edge nodes only play the role of data processing. The security of data transmission and the efficiency of identity authentication are not considered. All in all, by building a decentralized system, blockchain can provide infrastructure support for the IoT and help solve the ubiquitous security issues in the IoT. At the same time, the IoT provides a large number of landing scenarios for the blockchain. FIGURE 7. Agricultural product traceability architecture based on edge calculation, blockchain and IPFS. Show All C. Study on the Combination of VR/AR and Edge Computing in Agriculture Virtual Reality and Augmented Reality have been the focus of the industry’s attention since 2016. Users have higher and higher requirements for real-time performance. Scholars have found that the actual physical or network distance between the client and the cloud is too large to limit the response speed of VR / AR. At the same time, the growth rate of bandwidth resources in the cloud lags far behind the growth rate of data, which ultimately leads to cloud computing being unable to meet the higher VR / AR computing requirements of bandwidth. The idea is to combine edge computing with VR/AR. Compared with former cloud computing, Edge computing can better support AR/VR computing scenarios: (1) Cisco noted that global devices will generate 600ZB data in 2020 in the Global Cloud Index [72], 90% of which is temporary data similar to AR/VR scenarios. A large amount of temporary data can be stored at the edge nodes to alleviate the pressure on the cloud bandwidth. (2) High delay, strong jitter and low data transmission rate caused by the unstable links and routes in the complex network environment affect the responsiveness of cloud services [73]. The edge-side is closer to the user-side in both geographical distance and network distance, which ensures lower latency and reduces network jitter, which renders edge calculation more useful and responsiveness stronger [11]. (3) The images involved in AR computing, such as face data, belong to the user’s private data. These data is stored at the edge, which reduces the possibility of privacy leakage. 1) Virtual/Augmented Reality Technology VR and AR are immersive interactive environments that are based on computing information [74]. VR emphasizes the immersion of the virtual world, which emphasizes that people can interact with objects in the virtual world in a natural way. While AR emphasizes the ability to incorporate computer-generated virtual information into real-world scenarios and does not isolate the connection between the observer and the real world [75]. VR and AR differ by the device. The VR device is a closed-type head-mounted display, which is cumbersome and inconvenient. AR equipment is divided into three types: head-mounted, hand-held and space-projected by Bimber and Raskar according to the application scenario [76], which is relatively light. Recently, the application research of VR/AR technology in agriculture has emerged. According to the study of Cupial [77], AR has many applications in agriculture and will become an important technology in the Agricultural IoT in the future. Fernandez et al. [78] developed a tractor assist system that is based on wearable AR technology. When a tractor is working in the field, the parts that have been treated in the field are displayed in the field of view of the driver’s AR glasses. Vidal et al. reviewed the current status of AR and proposed its new applications in weed science [79]. It includes software for image identification for species identification and quantification of weeds, and selection of herbicides based on weed density. Nigam et al. [80] proposed a primitive augmented reality system. They use augmented reality technology to help farmers identify insects and successfully utilize integrated pest management. Generally, farmers are not trained in entomology, and they tend to destroy the insects they find in the field. In fact, not all insects should be eliminated because the prosperity of fields and ecosystems depends on their existence. The authors of the paper proposed an innovative augmented reality application that they intend to help farmers identify insects and use integrated pest management. The system made recommendations for farmers to use pesticides reasonably and reduce pollution. Another interesting augmented reality application for greenhouses shown in Neto and Doke [81]. This application uses a network of humidity and temperature sensors to sense conditions to develop staphylococcus fungi in tomatoes and warn farmers through their mobile devices. In addition, Liu et al. noted the use of AR technology to simulate the growth of plants and livestock, to visualize information and help users manage different agricultural jobs [82]. Janna and Timo [83] proposed the use of drones and AR technology to accurately control the fertilization rate in agriculture. A drone is responsible for collecting soil information, and the AR technology guides the user to the generated sample points. In applications in agriculture, a mix of AR and VR technologies are utilized where virtual and actual environments are smoothly combined [84]. Premsankar et al. [85] experimentally demonstrated that cloud deployments have higher latency than edges. Edge computing was introduced. Although various studies have investigated edge caching and computing, their use for AR/VR applications has been given minimal attention [86]. 2) Research Status In this section, we learned that the role of edge computing in AR/VR is mainly to store in edge and execute some VR/AR tasks at the edge. In table 3, we summarize the role of edge servers in VR/AR. TABLE 3 The Role of Edge Servers in VR/AR In fact, the role of edge computing in VR/AR is mainly edge caching. In edge caching, caching strategies can be divided into proactive and reactive. In proactive caching, the content to be requested is predicted and brought to the cache. In reactive caching, the content obtained is cached and is updated according to user needs. S.Park et al. came up with the idea of caching on the client side [87]. The priority cache mentioned in the paper can be used in the edge cache. M. Chen et al. studied edge caching in VR networks to reduce backhaul traffic and meet real-time requirements of VR users [88]. In their proposal, a unmanned aerial vehicles (UAVs) is used to collect the VR content requested by the user and transmit it to the small base station and the retrograde cache. Deep learning algorithms is implemented to find the best caching strategy. In J. Chakareski’s research, the authors used edge computing to overcome the computing limitations of VR devices by enabling users to offload computing tasks to edge servers [89]. The author’s goal is to use the Lyapunov stochastic optimization model to minimize calculation and transmission power consumption, but it is affected by co-channel interference, reliability and delay constraints. M. S. Elbamby et al. proposed an proactive caching and computing scheme to meet the high reliability and low latency requirements of VR users [90]. In the paper, information about user actions and game actions is used to pre-calculate and cache the next video frame to minimize latency while multi-connectivity is applied to ensure reliability. Although it is aimed at the application of VR games, it is also applicable the planting of plants in the online VR of the Agricultural IoT. To briefly summarize, the architecture diagram of the edge server playing a role of caching in VR/AR is shown in Figure 8. FIGURE 8. Structural diagram of the combination of edge calculation and VR/AR in agriculture. Show All Edge computing can also perform some parts VR/AR tasks. Yan and Qiao [91] proposed a method for solving the delay and bandwidth for Web AR that primarily deployed the edge server between the clients, assumes AR computing tasks and storage of 3D models, which is closer to the user end and satisfies the user’s requirements for real-time performance. First, the cloud node initiates full AR service access. After receiving a user request, it selects the most appropriate edge computing node and redirects the request based on the IP address. Then, according to the calculation task division, an independent AR engine and 3D model database are used to identify the target image. The architecture overcomes the difficulties of poor portability of AR devices, poor pure front-end performance, and high cloud computing costs. In addition, Hou et al. [92] proposed rendering on edge servers in order to provide a more lightweight wireless VR / AR experience. The paper lists the advantages and disadvantages of rendering on cloud servers, remote edge servers, and local edge servers: The advantage of cloud server rendering is that it allows users to experience VR / AR when moving or anywhere, but the bandwidth cost is high, and it is easy to cause network delay due to congestion; Remote edge server rendering can also achieve mobility, but its mobility depends on the movement of the mobile device, and there is a delay; Local edge server rendering does not provide mobility or provides very limited mobility but no latency. We can choose the server for rendering according to our needs. Finally, we found that edge computing reduced the response time of VR / AR, shared the computing power of VR / AR terminals and made VR / AR more widely used in agriculture. SECTION IV. Challenges A. Data Processing A large amount of data is generated in the agricultural IoT, so edge computing meets challenges related to data processing. In terms of data generation, edge nodes need to have storage plans, which determine whether the data is structured, semi-structured, or unstructured. So the IT team should know how much data and what type of data the edge node will have on the farm in the short or long term. In terms of data storage time, in some cases, the collected data is retained for a long time. However, in some cases, only a part of the data need to be retained or stored for a short period of time. For example, in the image recognition of pests and diseases under edge computing, when edge nodes execute part of the program, the original data can be discarded and only the feature data can be saved. In terms of data transfer, not all collected data must be moved to another platform. In some cases, only a portion of the data needs to be moved, or only data that has been aggregated, cleaned, or transformed in some other way, and may not even need to be moved. Much depends on the processing and analysis after data collection. B. Task Assignment In the paper, the Agricultural IoT is mainly end-edge-cloud collaboration that is the terminal, edge nodes and cloud center work together. So assignment of task is directly related to the execution and efficiency of the tasks. Partitioning in the edge environment needs to decompose the application into multiple components according to various state information, such as resources, energy consumption and response delay of the edge node. While the semantics of the original application is preserved, the program components are placed on different edge nodes. The Neurosurgeon proposed by Kang et al. [38] refers to the use of Fine-grained Computation Partitioning to partition the DNN model, which is executed at the edge or the cloud. How to design and implement the application partitioning technology in the Edge computing environment enables the proper distribution of application components among multiple heterogeneous edge nodes. Thus, the high performance and reliability of the application is obtained in the Edge computing environment. Some scholars are solving the problem of task allocation. For example, Using Lyapunov optimization theory to design a resource allocation algorithm based on a single slot. The problem of task offloading and resource allocation are transformed into three sub-problems of user local computing resource allocation, power and loan resource allocation, and edge server resource allocation. C. Privacy Protection and Security Computing closed to the data source is an effective way to protect privacy and data security. However, in the environment of Edge computing, privacy protection and security face the following challenges: (1) farmers’ awareness of privacy and security is weak. The survey shows that wireless connection uses default passwords, which indicates that many users do not protect their personal privacy. In this case, people can easily use a webcam, temperature and humidity sensors and other equipment to spy on a farm’s confidential planting and breeding data. Farmers’ awareness for privacy and security should be strengthened, and they are encouraged to change their passwords. (2) higher requirements exist for the physical security of edge equipment. Edge devices do not operate in fixed places, such as cloud computing centers. Most of these devices are open to the outside world in an uncontrolled environment and data on edge devices is more valuable than data on IoT terminals; they are more vulnerable. The access control system is added to the edge. In principle, this access control system should be suitable for multi-entity access control between different trust domains. At the same time, various factors such as geographic location and resource ownership should also be considered. (3) effective tools for data privacy and security are lacking. Although many data security methods are available, they are not fully applicable to Edge computing architectures. The network edge is more vulnerable to hacking in a highly dynamic environment. (4) distributed management is more difficult. Each endpoint has a specific vulnerability and should be protected differently. How to manage vast infrastructure is one of the challenges that we face. D. Service Stability The farms occupy a vast area, so they are all in the wilderness and the signal is poor. Service stability is especially important. Any kind of reliable system has four characteristics: distinguishability, scalability, isolation and reliability. Distinguishability: the rapid development of the IoT has caused the deployment of multiple services at the network edge. However, these services have different priorities. Key services need to be executed before common services are executed. For example, failure judgment and failure alarm of an unmanned harvester have priority over straight driving. Scalability: when certain equipment is worn out, the first problem to be solved is whether the newly purchased equipment can continue the service execution of the original system. We can design a flexible and extended service management layer to solve this problem. Isolation: in a distributed system, shared resources can be managed by different synchronization mechanisms, such as locks or tokens. In the edge system, this problem is more complicated. In the automatic watering system, if the program does not respond, the user can still water. Issues of isolation can be solved by deploying or uninstall the framework and adding access control. Reliability: when the edge device fails, the Edge computing system can inform the user which component is in trouble. Cao et al. discovered that the data transmission accuracy of edge equipment is lower in the case of low power and other unreliable conditions [93]. Thus, saving energy is a way to improve reliability. SECTION V. Conclusion and Prospects Edge computing, as an emerging network architecture, has realized localized services and improved user experience. Edge computing is extensively employed in the retail, financial, and agricultural fields. In this study, we comprehensively discuss the concepts related to Edge computing and Agricultural IoT. We have transformed the research status of Edge computing applications in the agricultural field into the research status of Edge computing combined with AI, blockchain, and VR/AR. For AI, Edge computing can perform data preprocessing and share the computing of the cloud server and storage models. For blockchain technology, Edge computing solves the problems caused by a lack of computing power and available energy consumption for terminal devices to the blockchain. The data stored in the edge server can ensure the reliability and security of the data by using blockchain technology. For VR/AR, Edge computing primarily reduces the response time. Some programs on the terminal can be offloaded to the edge server, which makes VR/AR devices lighter; thus, the scope of use is expanded. We identified and discussed four open research challenges. This study provides information for future researchers to learn about the application of Edge computing in the agricultural field and advances the research to resolve the unaddressed issues. As the two important supports of the digital transformation of the industry, Edge computing and cloud computing will jointly promote the Agricultural IoT to create greater value in the aspects of network, business, application and intelligence. Most of the current research on edge computing is applied in fields such as smart cities and smart homes. Few scholars have studied the application of edge computing in agriculture. In the next step, we will focus on the difference between the program running under the edge computing and the cloud center, and study the program specifically applicable to the edge computing architecture to ensure the integrity, robustness and accuracy of the program under the edge computing environment. In the future, edge computing will have a broad market in the agricultural field. According to IDC forecasts, 50% of the Internet of Things with more than 50 billion terminals will face network bandwidth limitations, and 40% of data will need to be analyzed, processed and cached at the edge of the network. The size of the edge computing market will exceed trillions, and it will become an emerging market that is evenly matched with cloud computing. The vast market space of edge computing will bring unlimited imagination and new opportunities to agriculture. Authors Figures References Citations Keywords Metrics More Like This Internet of Things Monitoring System of Modern Eco-Agriculture Based on Cloud Computing IEEE Access Published: 2019 Remote Monitoring System for Intelligent Slaughter Production Line Based on Internet of Things and Cloud Platform 2020 11th International Conference on Prognostics and System Health Management (PHM-2020 Jinan) Published: 2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 5:
- APA Citation: Nasirahmadi, A., & Hensel, O. (2022). Toward the next generation of digitalization in agriculture based on digital twin paradigm. Sensors, 22(2), 498.
  Main Objective: The study's primary goal is to examine the potential of digital twin concepts in agriculture, focusing on how they might improve productivity and efficiency.
  Study Location: Unspecified
  Data Sources: Agricultural data from sensors, IoT devices, and other sources.
  Technologies Used: Sensors, IoT, Big Data, Machine Learning, Artificial Intelligence
  Key Findings: Digital twin concepts can support farmers in a variety of ways, such as by providing them with real-time data on their crops and fields, helping them to optimize their operations, and providing early warnings of potential problems.
  Extract 1: The processes involved are complex, dynamic, and require sophisticated management systems. The digital approaches are expected to provide more monitoring, data analysis and optimization capabilities, and further decision-making support.
  Extract 2: The research aims to explore the possibilities of a digital twin paradigm for enhancing the productivity and efficiency of agricultural systems.
  Limitations: The literature review lacks specific research gaps and future work directions for researchers and practitioners to consider.
  Relevance Evaluation: 0.9
  Relevance Score: 1.0
  Inline Citation: (Nasirahmadi & Hensel, 2022)
  Explanation: The authors of this article provide a comprehensive review of literature on digital twin concepts in agriculture, exploring their potential applications and benefits.

 Full Text: >


Citation: Nasirahmadi, A.; Hensel, O.
Toward the Next Generation of
Digitalization in Agriculture Based
on Digital Twin Paradigm. Sensors
2022, 22, 498. https://doi.org/
10.3390/s22020498
Academic Editors: Dionysis Bochtis
and Aristotelis C. Tagarakis
Received: 6 December 2021
Accepted: 7 January 2022
Published: 10 January 2022
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright:
© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
sensors
Review
Toward the Next Generation of Digitalization in Agriculture
Based on Digital Twin Paradigm
Abozar Nasirahmadi *
and Oliver Hensel
Department of Agricultural and Biosystems Engineering, University of Kassel, 37213 Witzenhausen, Germany;
agrartechnik@uni-kassel.de
* Correspondence: abozar.nasirahmadi@uni-kassel.de
Abstract: Digitalization has impacted agricultural and food production systems, and makes applica-
tion of technologies and advanced data processing techniques in agricultural ﬁeld possible. Digital
farming aims to use available information from agricultural assets to solve several existing challenges
for addressing food security, climate protection, and resource management. However, the agricultural
sector is complex, dynamic, and requires sophisticated management systems. The digital approaches
are expected to provide more optimization and further decision-making supports. Digital twin in
agriculture is a virtual representation of a farm with great potential for enhancing productivity and
efﬁciency while declining energy usage and losses. This review describes the state-of-the-art of
digital twin concepts along with different digital technologies and techniques in agricultural con-
texts. It presents a general framework of digital twins in soil, irrigation, robotics, farm machineries,
and food post-harvest processing in agricultural ﬁeld. Data recording, modeling including artiﬁcial
intelligence, big data, simulation, analysis, prediction, and communication aspects (e.g., Internet
of Things, wireless technologies) of digital twin in agriculture are discussed. Digital twin systems
can support farmers as a next generation of digitalization paradigm by continuous and real-time
monitoring of physical world (farm) and updating the state of virtual world.
Keywords: digital twin; digitalization; digital farming; farm management; smart farming
1. Introduction
One of the main global challenges is how to ensure food security for the world’s
growing population whilst ensuring long-term sustainable development. According to the
Food and Agriculture Organization, agricultural and food productions will need to grow
to feed the world population, which will reach around 10 billion by 2050 [1]. Due to the
increase in world population and market demand for higher product quantity and quality
standards, the issue of food security, sustainability, productivity, and proﬁtability becomes
more important. Furthermore, the economic pressure on the agricultural sector, labor,
environmental, and climate change issues are increasing [2,3]. Therefore, the enhancement
of efﬁciency through effective integrated smart technologies and techniques has been
widely considered in recent years.
In this context, digital agriculture (also known as smart farming or smart agriculture)
tools can support the deeper understanding of interrelations within the agricultural pro-
duction system and the consequent effects on the performance of farm production while
balancing human health and well-being, social and environmental aspects, and sustain-
ability associated with agricultural system [4–6]. Due to advances in data generation, data
processing and human-computer interactions, digital farming has progressed in recent
years [7]. One of the main features of digitalization in agriculture is the introduction of inno-
vative Information and Communication Technology (ICT), Internet of Things (IoT), big data
analytics and interpretation techniques, machine learning and Artiﬁcial Intelligence (AI).
Data acquisition and analysis in digital farming by means of smart technologies are
supporting complex decision-making approaches [8,9]. They enhance ﬁnal productivity,
Sensors 2022, 22, 498. https://doi.org/10.3390/s22020498
https://www.mdpi.com/journal/sensors
Sensors 2022, 22, 498
2 of 16
reduce costs, and optimize the decision-making process. Furthermore, ICT tools present
advantages for on-farm management, efﬁciency, quality control, and the food supply chain
as well as decision support tools [10]. The AI and big data support better and precise
farm monitoring, data acquisition and analytics, improve information extraction from
sensors as well as farm management [11]. For instance, crop health and productivity can
be monitored and controlled using advanced AI and deep learning techniques [12]. Data-
driven approaches augment on-farm decision-making capabilities, improve crop yield,
reduce losses, and therefore, beneﬁt farmers. The IoT and wireless technologies enable
real-time data transferring and monitoring in digital farming [13,14]. The IoT, along with
cloud computing systems, can facilitate communication between software platforms and
sensors, pieces of machinery, crops, and animals in digital farming. However, by increasing
the number of sensors and generating large amounts of data in digital farming could cause
high load on the cloud server and reduce the response speed [15]. In this context, in may
be impractical to always store and process data in the cloud systems [16]. An alternative
technology which has been recently introduced to the smart farming is edge-computing
that enables computation at the edge of the network [17]. It helps to reduce network load
and supports real-time data processing in agricultural ﬁelds. Furthermore, cyber-physical
systems have been introduced through smart farming systems to develop hardware and
software, improve adaptability, and safety and security of computer-based algorithms
and systems [18]. It enables adaptability, practicality, security, and safety of collected
information in agricultural ﬁeld e.g., climate, irrigation, soil, nutrition, and yield for
better management.
According to ref. [19], digital farming approaches can provide farmers with useful
information about (I) the use of fertilizers, chemicals, seeds, and irrigation management
strategies, (II) the environment protection, (III) pest, climate, and crop monitoring man-
agement solutions, (IV) market demands and business conditions. However, agricultural
production systems are complex, dynamic, and require sophisticated management [20].
Digitalization approaches are expected to provide more monitoring, data analysis and
optimization capabilities, and further decision-making supports.
To enhance the efﬁciency of these systems, an emerging paradigm has been proposed
and implemented in digital agriculture, that is, digital twin. The digital twin was ﬁrstly
presented by NASA for monitoring of spacecraft behavior and can be deﬁned as a virtual
or digital representation of physical systems to simulate the behavior of the physical
system [21,22]. There are different deﬁnitions for digital twin available in the literature
which have been reviewed by [23–25]. Based on the reported deﬁnitions, the component
of digital twin can be characterized by physical and virtual objects, as well as a set of
connections between physical and digital assets [26].
The physical system or physical world in agriculture is a complex and dynamic
environment and includes basic information and features of the object or device such
as shape, position, cooler, material, and live objects [27]. The physical system is one
of the key components, and a digital twin without a physical world is a model [28],
and system boundaries of a digital twin are identiﬁed based on the real physical world [29].
The physical system can be a single component of an object or the whole object with sub-
components located in a physical environment [28]. The physical world in agriculture can
be an animal itself or located in a farm including building, feeding strategies, number of
animals [30], or a crop with different soil, climate, and irrigation conditions [22], robots
and agricultural pieces of machinery, e.g., tractors, harvesters and fertilizers, as well as
operators. The physical world can include a whole object (e.g., whole machine) or sub-part
of the object, or a single asset of the object connected with other objects. In an agricultural
context, the physical system may be some aspects of the crop, soil, and irrigation systems,
or animal body. The physical world requires measurement technologies and sensors to
collect and receive data from the physical object. Examples of digital twins in smart
agriculture include optical sensors for plant canopy and disease [31,32], soil and weather
sensors for crop [33], barn sensors such as temperature, humidity, ammonia for animals [34],
Sensors 2022, 22, 498
3 of 16
Global Positioning System (GPS) and Real-Time Kinematic-Global Navigation Satellite for
tracking of agricultural robots [35], and food supply chain.
The connection between physical and virtual worlds depends on the developed digital
twin. This component enables data transmission between virtual and physical systems.
It interprets the collected data from the physical system and updates the state of the
virtual system, and transfers feedbacks from the virtual system to the physical world [25].
The connection components can be varied depending on the source, type and volume of
data, data transfer rate and speed, as well as the minimum delay between data acquisition
and feedbacks. Wireless and IoT techniques have been used in digital twins of agricultural
concepts to connect between physical and virtual worlds (such as [34,36,37]).
The models and data of the physical world are represented in a virtual system.
The virtual world may also include different processing and simulation concepts, software,
machine learning, data mining, and AI models. In this context, data processing and analyt-
ics by means of AI techniques to support decision-making and feedback to the physical
system were suggested by some researchers [38,39]. The virtual twin may simulate and
control the physical system, optimize a process, and predict unseen issues in the physical
system. For example, an application layer of a digital twin reported by [22] provides
real-time monitoring of weeds, crop growth, and expected yield via cloud dashboards for
farmers. A schematic of the digital twin concept in agriculture is shown in Figure 1.
Sensors 2022, 22, x FOR PEER REVIEW 
3 of 16 
 
 
animal body. The physical world requires measurement technologies and sensors to col-
lect and receive data from the physical object. Examples of digital twins in smart agricul-
ture include optical sensors for plant canopy and disease [31,32], soil and weather sensors 
for crop [33], barn sensors such as temperature, humidity, ammonia for animals [34], 
Global Positioning System (GPS) and Real-Time Kinematic-Global Navigation Satellite for 
tracking of agricultural robots [35], and food supply chain.  
The connection between physical and virtual worlds depends on the developed dig-
ital twin. This component enables data transmission between virtual and physical sys-
tems. It interprets the collected data from the physical system and updates the state of the 
virtual system, and transfers feedbacks from the virtual system to the physical world [25]. 
The connection components can be varied depending on the source, type and volume of 
data, data transfer rate and speed, as well as the minimum delay between data acquisition 
and feedbacks. Wireless and IoT techniques have been used in digital twins of agricultural 
concepts to connect between physical and virtual worlds (such as [34,36,37]).  
The models and data of the physical world are represented in a virtual system. The 
virtual world may also include different processing and simulation concepts, software, 
machine learning, data mining, and AI models. In this context, data processing and ana-
lytics by means of AI techniques to support decision-making and feedback to the physical 
system were suggested by some researchers [38,39]. The virtual twin may simulate and 
control the physical system, optimize a process, and predict unseen issues in the physical 
system. For example, an application layer of a digital twin reported by [22] provides real-
time monitoring of weeds, crop growth, and expected yield via cloud dashboards for 
farmers. A schematic of the digital twin concept in agriculture is shown in Figure 1. 
 
Figure 1. Schematic of digital twin concept for agriculture. 
Although digital twin concepts in smart farming are in their infancy and early 
demonstration stages [22,30], there are ongoing interests in implementing this technique 
in the agricultural context. There are some reviews available in the literature describing 
digital twin concepts in the agriculture context (listed in Table 1), however, to the best of 
our knowledge, these works have focused on a specific part of the digital twin, and no 
comprehensive studies have yet been done to address the application of digital twins in 
soil, irrigation, agricultural farm pieces of machinery, robots, and post-harvest food pro-
cessing. Therefore, this review summarizes digital twin concepts as a next-generation par-
adigm for digitalization in agriculture. This paper is structured in 6 sections. Section 2 
illustrates the digital twin of soil and irrigation systems in smart agriculture. Section 3 
covers the use of digital twin concepts for crop technologies. Section 4 illustrates digital 
Figure 1. Schematic of digital twin concept for agriculture.
Although digital twin concepts in smart farming are in their infancy and early demon-
stration stages [22,30], there are ongoing interests in implementing this technique in the
agricultural context. There are some reviews available in the literature describing digital
twin concepts in the agriculture context (listed in Table 1), however, to the best of our
knowledge, these works have focused on a speciﬁc part of the digital twin, and no com-
prehensive studies have yet been done to address the application of digital twins in soil,
irrigation, agricultural farm pieces of machinery, robots, and post-harvest food processing.
Therefore, this review summarizes digital twin concepts as a next-generation paradigm
for digitalization in agriculture. This paper is structured in 6 sections. Section 2 illustrates
the digital twin of soil and irrigation systems in smart agriculture. Section 3 covers the use
of digital twin concepts for crop technologies. Section 4 illustrates digital twin concepts
during post-harvest processing. Challenges and future research needs for digital twin are
presented in Section 5. Finally, conclusions are discussed in Section 6.
Sensors 2022, 22, 498
4 of 16
Table 1. Previous review studies on digital twin in agriculture.
Concept
Sources
Agriculture-farm management
[40]
Smart farming—Hydroponics
[41]
Food processing
[42]
Food losses—supply chain of fresh products
[43]
Agri-food—societal and ethical aspects
[44]
Food processing—fresh horticulture supply chain
[45]
Agri-food supply chain
[46]
Smart farming—deﬁnition and concept
[22]
Agriculture—general application and adoption
[47]
2. Digital Twin in Soil and Irrigation
Monitoring and evaluation of soil quality to sustain plant productivity is the basis of
land-use strategies in agricultural farms [48]. Crop health and productivity depends on
the quality and properties of the soil. More detailed information about the agricultural
soil may reduce the potential use of chemical fertilizer and pesticide dosages, therefore
improving the underground water, protecting the environment and human health. It also
supports deﬁning plant density in a more efﬁcient way. Digital technologies are supporting
scientists to better understand and study soil in agriculture. Soil monitoring sensors such
as moisture, temperature, organic matter, and soil pollutant sensors are playing critical
roles in digital agriculture [49]. For instance, soil moisture information can be used to
assess irrigation efﬁciency in agricultural ﬁelds [50]. Furthermore, to support the decision-
making process of smart farming, digital soil mapping is an essential paradigm that can be
deﬁned as spatial soil information based on ﬁeld and laboratory investigations coupled
with soil inference systems [51]. Digital soil assessment approaches have a direct impact on
crop yield and performance by identifying zones that may cause low crop yield. Digital
alternative methodologies for soil survey and identifying key soil characteristics could
have the possibility to quantify the trend of agricultural soil conditions [52].
The advancement of knowledge and technology (e.g., wireless sensors, IoT, AI) in
digital agriculture could lead to digital twin paradigms of soil in agriculture. The recent
development of digital soil mapping techniques may support digital twins by digital
representation of knowledge obtained from the soil in virtual entrainment [53]. For in-
stance, digital soil mapping could be used to describe soil variation in digital twins using
information from complex soil variation at a speciﬁc depth, time, and special locations [52].
Additionally, the decision about crop management depends directly on the crop water
requirements, soil properties, and availability of water. In order to manage soil and crop
requirements in smart farming, digital technologies have been used to meet the requirement
of smart or precise water management strategies. Wireless system networks, IoT, edge-
computing, local weather-based controllers, and soil sensors are some of the digital tools
based on smart irrigation systems. The mentioned tools can be used in the digital twin of
soil and irrigation systems. For example, ref. [37] developed a digital twin concept for smart
water management in the agricultural domain. Information of air and ground temperature,
and humidity sensors, soil moisture, and ambient light as well as geospatial position
sensors were collected. An IoT system was used to connect the cloud and the physical
system. A virtual environment including decision-making tools and models was designed
to inform the data collected by connection device (the IoT system) and to send feedback
to the physical system. They also presented a digital twin system architecture including
monitoring devices (i.e., soil probe, weather information, irrigation system, machines,
and other equipment) in a physical system (farm) with could serve as a connection between
the physical and virtual systems to visualize satellite and drone images.
In another study, to evaluate and forecast plants’ irrigation requirements, and support
irrigation and water distribution planning, a digital twin for a smart water management
system was developed by [54]. Data of the physical world (agriculture ﬁeld) such as
Sensors 2022, 22, 498
5 of 16
weather, fertilizer, and soil type as well as information from developed models that simulate
the behavior of soil and crops were considered as input data for the digital twin. The digital
twin concept also consisted of a Soil Agent (includes hydrological models and soil data),
Crop Agent (includes crop models and evaporation data), and a Field Avatar, which is a
digital representation of the ﬁeld such as geological models and weather data [54]. In their
developed digital twin concept, the information from Soil Avatar and Crop Avatar feed
into the Field Avatar, and an IoT system was used for data transformation and connection
between the physical and virtual worlds.
Due to increase in world population, water and energy management, storage, and proper
distribution of water become more essential for water users in agricultural sectors, which can
be managed through a collective irrigation system [55]. A digital twin of water systems
coupled with big data can reduce risk and uncertainty of water management, explore
consumption patterns, and optimize operation planning [56]. Furthermore, in a collective
irrigation system, improvement of water efﬁciency could help to reduce water losses. In this
context, a digital twin concept was created using ﬁeld and laboratory tests of a collective
irrigation system network to evaluate energy, pumping facilities, water losses and water use
efﬁciencies [57]. The developed digital twin methodology was based on information from
the physical system, i.e., infrastructure data, acquired information through telemetry, data
analytics from laboratory tests and ﬁeld measurements, IoT data transferring as connection,
energy balance, water balance, and hydraulic model in the virtual system. It was found
that the digital twin of the irrigation management system made it possible to understand
system processes, maintenance, and management strategies [57].
A digital twin of soil and irrigation systems in smart farming enables digital repre-
sentation of information from agricultural soil, and provides prediction and fundamental
understanding of water requirement and soil components for crop farming. Exchanging
information from the soil as a physical system to a virtual system using IoT, cloud, fog,
and edge-computing technologies in digital twin may allow evaluating the state of soil and
irrigation systems. In particular, the edge-computing technique that saves and performs
the data processing near the soil monitoring and irrigation devices can improve the perfor-
mance and overcome issues of cloud-based system in digital twin concepts. Furthermore,
it could offer different irrigation recommendations based on crop requirements which are
not solved yet by the researchers.
3. Digital Twin in Crop Production
The use of digital and ICT tools in crop production technologies, in particular agri-
cultural machineries, e.g., tractors, combine harvesters, fertilizers, and sprayers, plays an
important role in the improvement of overall efﬁciency by reducing the cost of fuel, fertiliz-
ers, human labor, and parameters which affect production efﬁciency and sustainability [58].
Digitalization has modernized agricultural machinery application and management policies
using collected information and advanced data analytics approaches. It allows to optimize
the performance and enhance the use of advanced tools in manufacturing. For instance,
based on the European Agricultural Machinery Association, a digital farm machine should
be able to assist and support drivers by sending and receiving data via sensors and ICT
tools, enable the best and optimal use of machinery, and the technology should facilitate
the automated operation of the devices [59]. The application of AI, big data analytics,
and wireless and IoT technologies have led to signiﬁcant changes in farm technology roles
towards the development of autonomous systems. The role of agricultural machinery in
the implementation of digital agriculture was stated by [58] as data collected from sensors
mounted on typical and autonomous agricultural machinery and transferred via an IoT
platform. Then, the information was analyzed by data analytics such as AI, fuzzy logic,
and big data analysis to support farmers, consumers, and markets [58]. In this context,
combining digital tools with autonomous machines and robots could help farmers to do
more effective practices and improve the quality of products [60]. Nowadays, with ad-
vancements in digital technology, the real-time visualization of smart farm equipment
Sensors 2022, 22, 498
6 of 16
conditions is possible through digital twin approaches [40]. It allows contact to the system
(e.g., machinery and robots), simulates the condition of the system, and monitors the
behavior and operation as well as the maintenance situation of the machines (Figure 2).
 
transferred via an IoT platform. Then, the information was analyzed by data analytics 
such as AI, fuzzy logic, and big data analysis to support farmers, consumers, and markets 
[58]. In this context, combining digital tools with autonomous machines and robots could 
help farmers to do more effective practices and improve the quality of products [60]. Now-
adays, with advancements in digital technology, the real-time visualization of smart farm 
equipment conditions is possible through digital twin approaches [40]. It allows contact 
to the system (e.g., machinery and robots), simulates the condition of the system, and 
monitors the behavior and operation as well as the maintenance situation of the machines 
(Figure 2).  
 
Figure 2. An architecture of the digital twin concept for crop production technology. 
Digital twin in design and manufacturing of products (e.g., farm machinery) requires 
(I) geometric (e.g., size, shape) and physical properties of an object, (II) in the detailed 
information of the product which can illustrate dynamic processing of the object, (III) in-
tegration of geometric, physical, and process information [61]. Digital twin approaches 
make it possible to model, design, simulate, and develop agricultural machinery that 
would yield more productive machines in terms of energy and power efficiencies. For 
instance, it was shown that overall energy consumption of machinery could be modeled 
in digital twin concepts, and the effect of different factors on energy consumption can also 
be explored there [62]. In the agricultural context, ref. [40] reported that a commercially 
available digital twin platform for agricultural machinery is able to track the machines in 
real-time, monitor the energy consumption, economic efficiency of crop management, and 
trajectories of tractors by considering the specific conditions of the farm. It has also been 
reported that using digital twins could potentially impact the training of unskilled har-
vester operators and lead to high macro-economic benefits [63].  
Within the digital farming technologies, robotics, as an important technology in crop 
production, has played an essential role in digitalization and has been drawing more at-
tention in recent years. To optimize the robotic application process, reduce costs, and in-
crease the quality and efficiency of the product, the digital twin concepts can be used for 
virtualization of the robot environment by introducing a remote operating system [64]. By 
providing simulation and remote operation possibilities and modeling various interac-
tions between robot and environment in digital twin concepts, accuracy, performance, 
and flexibility may enhance, and the final product cost may decline. Ref. [65] analyzed the 
human-robot interactive behaviors using a digital twin platform. Their developed digital 
twin helps to improve operational productivity and comfort. In another study, a digital 
Figure 2. An architecture of the digital twin concept for crop production technology.
Digital twin in design and manufacturing of products (e.g., farm machinery) re-
quires (I) geometric (e.g., size, shape) and physical properties of an object, (II) in the
detailed information of the product which can illustrate dynamic processing of the object,
(III) integration of geometric, physical, and process information [61]. Digital twin ap-
proaches make it possible to model, design, simulate, and develop agricultural machinery
that would yield more productive machines in terms of energy and power efﬁciencies.
For instance, it was shown that overall energy consumption of machinery could be mod-
eled in digital twin concepts, and the effect of different factors on energy consumption can
also be explored there [62]. In the agricultural context, ref. [40] reported that a commercially
available digital twin platform for agricultural machinery is able to track the machines
in real-time, monitor the energy consumption, economic efﬁciency of crop management,
and trajectories of tractors by considering the speciﬁc conditions of the farm. It has also
been reported that using digital twins could potentially impact the training of unskilled
harvester operators and lead to high macro-economic beneﬁts [63].
Within the digital farming technologies, robotics, as an important technology in crop
production, has played an essential role in digitalization and has been drawing more
attention in recent years. To optimize the robotic application process, reduce costs, and in-
crease the quality and efﬁciency of the product, the digital twin concepts can be used for
virtualization of the robot environment by introducing a remote operating system [64].
By providing simulation and remote operation possibilities and modeling various inter-
actions between robot and environment in digital twin concepts, accuracy, performance,
and ﬂexibility may enhance, and the ﬁnal product cost may decline. Ref. [65] analyzed
the human-robot interactive behaviors using a digital twin platform. Their developed
digital twin helps to improve operational productivity and comfort. In another study,
a digital twin approach was proposed to assist the remote programming of a robot [66].
The developed digital twin system consists of a robot (as a physical object), and a gaming
platform (as a virtual system) which was able to observe the motion of the robot, ease
programming for complex environments as well as introduce a remote operating system
for communication across different platforms [66]. In the agricultural context, an approach
was recommended by [35] that the development of a digital twin paradigm for agricultural
robots may improve predictive emulation of the vehicles, operational scheduling, digital-
Sensors 2022, 22, 498
7 of 16
ization, economic, environmental, and social sustainability in agriculture. Furthermore,
the digital twin paradigm makes it possible to overcome common challenges in the control
of robot components in the agriculture ﬁeld. In this context, a research group demonstrated
the possibility of a digital twin concept for a desktop version of an agricultural robot [67] to
control the motor and indoor localization capabilities of the robot. Besides, the digital twin
concept was used to predict movement and monitor the safety mechanism of the robot [67].
However, their developed digital twin concept needs different kinds of calibrations to be
applicable in different environmental conditions.
In another study, to simulate complexity of the crop production process, variability of
plant, soil, environment, and technologies in the agricultural ﬁeld, digital twin concepts
were developed [68]. Three ﬁeld robots for different agricultural applications were used to
develop different digital twin concepts and optimize sensor-based autonomous navigation.
It is reported that the developed concepts could provide considerable information in prepar-
ing ﬁeld experiments, and better evaluation for the use and positioning of sensor systems
towards demonstrating and implementation of the developed robotic technologies [68].
Integration of the digital twin systems with technologies and management strategies
in crop production can provide a new phenomenon for digitalization in agricultural ﬁeld.
Management strategies can be improved and optimized by providing reliable forecasts of
the key parameters in digital twins [69]. The digital twin systems can not only act as a man-
agement system, but it may also be used to revolutionize agricultural farm management
strategies [40]. For instance, a digital twin concept was applied in a greenhouse to discover,
analyze, and extract behavior of farmers [70]. Sensor data were analyzed using deep learn-
ing techniques to establish decision-making models to replicate expert famers’ experience
for transferring to young farmers. It was found that the developed digital twin module
could improve control and management strategies in crop farming [70]. In this context,
the use of distributed architecture in digital twin may increase efﬁciency and reliability
of the module by proper resource handling [71]. A distributed digital twin concept was
developed to handle resources over different stakeholders and platforms in agricultural
landscape [72]. It consists of different components, i.e., stakeholders, applications in agri-
culture and farm management, sensor data, analytics and simulation tools, virtual model,
IoT, and resource registry which makes interoperable and cross-scale management possible
in agricultural landscape [71].
In addition, the use of digital twin system as a decision support system can beneﬁt and
be adopted for crop farming applications, and optimization of products and farm system
performance. A digital twin model was implemented by [36] in sustainable agriculture
for monitoring and control of product qualities, adjustment of environmental conditions,
identiﬁcation of forecasting, and decision support scenarios. In addition, a novel approach
based on digital twin paradigms was developed to forecast yield, vegetation quality,
and duration of plant development [33]. Consequently, the quality of crop production
could be improved due to detailed analysis and control of plant growth, and the efﬁciency
of farms could be improved due to automation of decision support processes through
the developed digital twin concept. Digital twin along with forecasting models were able
to provide feedback to farmers for a better decision-making scenario in a reported study
by [73]. Their proposed digital twin system consists of a monitoring system to collect
environmental condition data from an underground farm, as well as data analysis and
modeling techniques to identify key parameters, critical trends, and forecast operational
scenarios. Furthermore, digital twin was able to optimize productivity of crops in a
greenhouse environment through climate control strategies and treatments related to
crop management [74].
Information from crop production machineries (e.g., tractors, harvesters, robots) have
been used in smart farming to optimize the performance and efﬁciency, and reduce the fuel
and energy consumption. However, the digital twin concepts collect real-time data from
the devices and characterize the states of the physical object continuously. This capability
makes it possible to predict and prescribe solutions using the collected information from
Sensors 2022, 22, 498
8 of 16
the farm machineries. Hence, big data analytics coupled with AI models are able to detect
failures in the machines before or in the early stage of when breakdowns happen. In this
context, the use of state-of-the-art edge-computing systems may reduce latency by the
limited amount of transmitted data and provide information from the crop production
machineries such as autonomous robot, harvesters, and tractors to the digital twin concepts.
The digital twin paradigm in crop farming can change production productivity, farm man-
agement, and sustainability at farm level. Advanced statistical models, machine learning
and data analytic approaches can provide farmers with more precise information to make
better decisions that were not possible previously. Based on the past (historical) and current
continuous knowledge from crop (sensors deployed at farm) and environment data, the dig-
ital twin systems provide information about future states of the farm, and offer solutions
for turning the collected information into useful and actionable on-farm knowledge.
4. Digital Twin in Post-Harvest Process
Post-harvest process is a stage of agricultural products after harvesting until consum-
ing the products, which may include transportation, drying, cooling, storage, and market-
ing. Through digital farming approaches, the post-harvest processes could beneﬁt from loss
reduction, improvement of monitoring and optimization of food processing, storage condi-
tions, marketing, and transportation. Digital solutions allow monitoring real-time agri-food
supply chain to increase robustness and resilience of the chain [75], and lower food waste
and losses. The IoT platform supports the reduction of food losses in post-harvest pro-
cessing [76], and tracking of the product through the food supply chain. To achieve food
security AI and big data analytics enable data processing, optimization, and management
in food and crop post-harvest stages [77], also reducing waste and improving overall prof-
itability [78]. The ICT offers solutions to monitor and control quality criteria of food and
agricultural products during post-harvest processing [43]. However, different environmen-
tal conditions, processing factors, and dynamic features of agricultural product (e.g., shape,
size), environmental parameters (e.g., temperature, humidity), handling, transportation,
and storage of the products inﬂuence the quality of post-harvest process [79].
To overcome these issues and increase the efﬁciency of the system, digital twin ap-
proaches have been used in post-harvest processing to continuously monitor the products
and update the processing stages [80]. Digital twins, as an expanding family of digital
farming could strengthen agri-food systems, affect knowledge and skills of farm manage-
ment [44]. Digital twin in post-harvest processes can be deﬁned as a digital representation
of harvested agricultural products based on the information collected from the products.
In this context, ref. [42] reported the digital twin concept of food processing may include:
(I) data collected from a physical system (food process operation) by means of sensors that
measure properties and variables of products and environmental parameters, (II) an IoT
platform to provide sensor communication, data storage and big data analytics, high-
performance computing, and link to the digital twin assets, (III) a simulation platform that
uses input data from physical system for optimization, testing and validation of models,
and provides decision supports in the virtual world. In order to beneﬁt food process-
ing by developing digital twin models, it is important to include accurate information
representing production processes of the product, e.g., equipment, labor, and to create
realistic models with all existing boundaries and barriers [81]. In a study reported by [82],
a digital twin of mango fruit was developed to simulate and qualify thermal and associ-
ated bio-chemical behavior of the fruit through a post-harvest supply chain. In order to
develop the digital twin concept, environmental air temperature as input was considered,
and the actual supply chain conditions were mimicked within mechanistic ﬁnite element
models [82]. Moreover, the impact of higher air speed on storage life, cold chain length,
and delivery air temperature on the fruit quality were considered in the digital twin. It was
reported that the digital twin allows to monitor and predict temperature-dependent fruit
quality losses, improve refrigeration and logistic processes, consequently, it can reduce
food losses [82]. Furthermore, it is reported that the digital twin can help horticultural
Sensors 2022, 22, 498
9 of 16
products along with the post-harvest life, and can be used to forecast the shelf-life of
agricultural products through the cold chain [45]. It can support food consumers as well
as food business owners for tracking of the products, logistics, and marketing decisions;
however, the existing digital twin concept needs to be enhanced by considering more bio-
chemical and physical features [45]. Ref. [83] proposed a digital twin concept food supply
chain analysis. Their developed digital twin includes: (I) a network based on knowledge
from, e.g., customers, suppliers, and factories, (II) some parameters, e.g., in production,
transportation, warehouses, sourcing, shipment costs, and policies, (III) various operational
parameters, e.g., demand, quality, target inventory, and vehicle capacity. It was found
that the developed digital twin can be used for optimization, simulation, and analysis of
operation and performance changes in the food supply chain [83].
According to [43], digital twin in post-harvest can be considered as mechanistic,
statistical, and intelligent models; however, it was found that the physics-based mechanistic
digital twin concepts can evaluate the quality of fresh agricultural products better than
the others. Physics-based digital twins were developed on 331 cold chain shipments of
four fruits (i.e., cucumber, eggplant, strawberry, raspberry) by [84]. Based on digital twin
concepts, it was found that the quality of fruits may be affected (around 43–85%) before
being delivered to stores.
The post-harvest processing has improved through the application of digital solutions
over the last several years. However, the use of the digital twin paradigm is receiving more
attention in post-harvest food processing due to the future product quality prediction and
cost reduction. The digital twin of post-harvest processes may be developed to model,
optimize, represent, and characterize the design and operational parameters such as quality,
safety, ingredients, shelf-life, and product status, which need to be considered by researchers
in future studies.
5. Challenges and Future Needs
Summary of the digital twin concepts developed in the literature for different purposes
in agricultural ﬁelds, including soil, irrigation, crop monitoring, robotics, farm machinery,
and post-harvest processing, is presented in Tables 2–4. These tables show that the digital
twin paradigm is in the early stage of research and development in the agricultural context,
and future studies in terms of knowledge, technological, system development, and application
aspects of digital twin concepts in different fields of agriculture should be considered.
Table 2. Summary of soil and irrigation digital twin concepts.
Concept
Key Components and Beneﬁts
Source
Soil–water
Supporting precision irrigation in agriculture, better irrigation planning
and water distribution, reduce crop yield losses
[54]
Soil–water
IoT-based water management platform, monitoring water pattern in soil
[37]
Water
Analyze and optimization of aquaponic systems, minimize water waste
[85]
Irrigation
Urban-integrated hydroponic system, integration of forecasting models for
better decision-making assistance
[73]
Irrigation
System management and irrigation decision-making integration, water use,
global energy and pumping facilities efﬁciency evaluation, understanding
of irrigation system process
[57]
Water
Development of decision support system, enhancement of cyber-physical
implementation in aquaponics
[86]
Sensors 2022, 22, 498
10 of 16
Table 3. Summary of the digital twin in crop production.
Concept
Key Components and Beneﬁts
Source
Vertical farming
Environmental conditions assessment, identiﬁcation of forecasting and decision
support models, monitoring and optimization of agri-food lifecycle
[36]
Plant/tree
Plant condition monitoring including structure, health, stress, and quality of fruit
[31]
Robot
Analysis and performance evaluation, robot selection, and navigation
[35]
Robot
Simulation of ﬁeld environment, autonomous robot navigation
[68]
Agricultural machinery
Development and advantages of business models for potato harvesting
[59]
Agricultural landscape
Resource distribution management over different stakeholders in agriculture
[72]
Crop
Forecasting yield and duration of plant development
[33]
Agricultural machinery
Development of three-dimensional geometric models, drawings of devices,
mechanisms, and the attributive data
[87]
Plant
Detection of plant diseases and nutrient efﬁciency
[32]
Crop/hydroponic farm
Identiﬁcation of crop growth parameters such as lighting, external temperature, and
ventilation systems
[73]
Crop
Optimize productivity, climate control strategies, and crop treatment management in
controlled environment agriculture
[74]
Robot
Co-simulation of robot environment, prediction of robot movement, and safety monitoring
[67]
Table 4. Summary of digital twin for post-harvest process.
Concept
Key Components and Beneﬁts
Source
Food supply chain
Thermophysical behavior of fruit during supply chain, storage at different airﬂow rate,
understanding, recording, and predicting losses of temperature-based fruit quality
[82]
Beverage
Predicting possible anomalies and preventing safety issues for employees
[88]
Food
Machine learning-based models for real-time response and quality predictions,
maintenance, and data collection
[80]
Food supply chain
Development of practical implementation strategies, enhancing resilience food retail,
and capacity management
[83]
Food
Challenges, methodologies, and opportunities for implementation of digital twin in
food processing, importance of realistic and accurate models in food processing
[81]
Food
Modeling of equipment, humans, and space for fast-food producing, management of
production chain, and performance evaluation
[89]
Post-harvest
Monitoring of retail stores and detection of fruit quality lost
[84]
With rapid technological and sensor development, digital twin of the agricultural
soil by considering the soil quality and properties may accommodate plant productivity,
health, and yield, save water, and reduce chemical usage. Many elements of the soil,
irrigation, and environmental parameters in agricultural land can be continuously mon-
itored, analyzed, and their management strategies optimized using big data analytics,
machine learning models, and decision support systems embedded in the digital twin
concepts. The combination of soil and irrigation digital twin approaches to record, monitor,
and analyze agricultural land changes may lead to improved performance of crop farming.
For instance, simulation of soil structure along with data-driven updating models could
connect farmers to the farm using the IoT technology and present, in detail, pictures of
parameters that impact the soil, irrigation, and crop yield. However, few studies focus on
the development of digital twin concepts of agriculture soil with higher degree of ﬂexibility
as well as considering a wider range of operation than existing simulation models. Soil
sensors could constantly measure and record the dynamic condition of arable soil, e.g.,
Sensors 2022, 22, 498
11 of 16
water holding capacity, moisture, temperature [53]. These data, along with information
from soil structure and simulation techniques, can be transferred to digital twin concepts,
and constant feedback from the digital world may advise real-time responses for soil and
water management as well as control systems. In recent years, there has been rapid growth
in the digital farming scenarios, use of remote sensing, digital soil mapping, and develop-
ment of software platforms. However, researches needed to fuse the developed techniques
along with the IoT, edge-computing, AI, data analytics, and simulation techniques that
could lead to development of a digital twin paradigm is in an early stage and needs to
be addressed in future studies. Furthermore, researchers need to consider the practical
challenges of digital twin-based systems in soil and irrigation as digital twins are multi-
and interdisciplinary techniques and require systems engineering perspectives [90].
Digital twin offers real-time simulation of farm machinery and robots that can beneﬁt
optimal design of the products, interaction with the environment, energy usage, and main-
tenance strategies. Digital twin concepts have the possibility to predict failures in farm
machinery and support decision-making scenarios in plant production. Farm owners can
be able to connect to the machines through virtual world for monitoring and tracking of the
devices in agricultural farms. Digital twin systems are accompanied by recording a large
amount of data and exchanging information between different assets; hence compiling
and analyzing these data is a challenge facing farms, particularly in some rural areas with
poor internet and technological infrastructures [91]. Other alternatives, e.g., Long Range
technology based on wireless sensor networks communication and edge-computing could
be used to mitigate internet access problems in rural areas for the connection part of the
digital twin concepts [32,92]. Future opportunities for the implementation of digital twin
systems in crop farm technologies could lie in the development of standards as well as data
transferring and communication strategies in this context.
The digital twin of crop production using big data collected from crop and farm ma-
chinery as well as robots, analytical and AI models, IoT, and satellite and drone information
could allow simulating crop, environmental, and farm conditions in the digital world to
determine unknown and unseen issues before happening in the physical world. Agricul-
tural objects (crops in particular) need frequent updates in data to support information
analysis and decision-making processes [93] which in turn can promote sustainable farming
practices and save energy usage in crop productions. In this context, greater effort should
be focused in the future on characterization and development of frameworks for more effec-
tive practical digital twin paradigms. In crop farming, all information may not be recorded
and tracked using digital sensors; however, combining data from different sources could
improve the virtual representation of the farm operation and environment [73]. Continuous
monitoring of crops in digital twin systems by simulating the dynamic farm conditions
and considering the effect of management, climate, and environmental conditions on the
plant growth and use of data-driven models along with sensor fusion techniques could
help to identify deviations from the normal conditions of the plant, and forecast growth
stages to reduce risk of environmental and management effects. In future, different digital
twin concepts might be applied to copy the complex physical system of crop farming in
the digital world and incorporate variable sensors, data collecting strategies, modeling,
forecasting, and simulation approaches in crop farming.
In addition, digital twin concepts can support monitoring, tracking, and analysis of
food through the entire supply chain. Development of a digital copy of an agricultural
product to monitor post-harvest processing could be used to optimize the process, reduce
energy use, labor, and food losses based on information from different sensors and simula-
tion models. Future studies need to be carried out to consider more environmental and
post-harvest product features for the development of robust digital twins [45]. Another
major challenge in the development of digital twin for post-harvest processing to minimize
quality losses and improve the shelf-life of the product is considering the value chain of
agricultural products from farm to fork [43], which has not been addressed yet. In post-
harvest processing to reduce uncertainty in digital twins and enable the consumer to trust
Sensors 2022, 22, 498
12 of 16
the output of digital twin concepts, detailed experimental and data collection approaches
along with numerical modeling and validation techniques need be considered.
6. Conclusions
Employing digital technology has helped agricultural farm managers to improve
efﬁciency, yield, and reduce losses. There are different types of digital farming paradigms
in the literature that could be used in digital twin concepts as the next generation of
digitalization in the agricultural ﬁeld. The results of this review show that the digital twin
concepts in agriculture and food processing have, so far, been little exploited in research.
There are several research challenges and opportunities in different stages of digital farming.
Digital twin paradigms can be meaningfully utilized for soil and irrigation, crop, robots and
farm machinery, and post-harvest food processing in the agricultural ﬁeld. In this context,
most of the studies have focused on the development of digital twins by considering some
limited parameters in agricultural sectors. Deploying of state-of-the-art technologies, e.g.,
AI, advanced statistical and optimization models, big data analytics, and three-dimensional
simulation, offer further possibilities for improvement in farm management. With real-
time and continuous information about agricultural assets, virtual models can predict
and address unseen issues in the ﬁelds. It may support farmers to decline the economic
pressure on the agricultural sector and labor issues, and help policy makers responsible for
food security and environmental protection, towards strengthening the agriculture sector.
In addition, it facilitates the work of researchers exploring methods to track and monitor
crop farm machinery, agricultural and post-harvest products or reduce water, chemicals,
and energy usage in digital farming. Although many digital twin systems in engineering,
manufacturing, and health contexts have been developed, further attempts need to be
considered in the agricultural context towards the development of digital twin systems
that can monitor, record, and analyze data, to predict and prescribe the best decision for
digital farming management.
Author Contributions: Conceptualization, A.N. and O.H.; investigation, A.N.; writing—original
draft preparation, A.N.; writing—review and editing, A.N. and O.H.; visualization, A.N. All authors
have read and agreed to the published version of the manuscript.
Funding: This research received no external funding.
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
Data Availability Statement: Not applicable.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Food and Agriculture Organization of the United Nations (FAO). Transforming Food and Agriculture to Achieve the SDGs; FAO:
Rome, Italy, 2018.
2.
Prause, L. Digital Agriculture and Labor: A Few Challenges for Social Sustainability. Sustainability 2021, 13, 5980. [CrossRef]
3.
de Gennaro, B.C.; Forleo, M.B. Sustainability perspectives in agricultural economics research and policy agenda. Agric. Food Econ.
2019, 7, 17. [CrossRef]
4.
Jakku, E.; Taylor, B.; Fleming, A.; Mason, C.; Fielke, S.; Sounness, C.; Thorburn, P. If they don’t tell us what they do with it, why
would we trust them? Trust, transparency and beneﬁt-sharing in Smart Farming. NJAS Wagening. J. Life Sci. 2019, 90–91, 100285.
[CrossRef]
5.
Basso, B.; Antle, J. Digital agriculture to design sustainable agricultural systems. Nat. Sustain. 2020, 3, 254–256. [CrossRef]
6.
Goel, R.K.; Yadav, C.S.; Vishnoi, S.; Rastogi, R. Smart agriculture–Urgent need of the day in developing countries. Sustain. Comput.
Inform. Syst. 2021, 30, 100512. [CrossRef]
7.
Mehrabi, Z.; McDowell, M.J.; Ricciardi, V.; Levers, C.; Martinez, J.D.; Mehrabi, N.; Wittman, H.; Ramankutty, N.; Jarvis, A.
The global divide in data-driven farming. Nat. Sustain. 2021, 4, 154–160. [CrossRef]
8.
Wolfert, S.; Ge, L.; Verdouw, C.; Bogaardt, M.J. Big Data in Smart Farming—A review. Agric. Syst. 2017, 153, 69–80. [CrossRef]
9.
Ingram, J.; Maye, D. What are the implications of digitalisation for agricultural knowledge? Front. Sustain. Food Syst. 2020, 4, 66.
[CrossRef]
Sensors 2022, 22, 498
13 of 16
10.
Jakku, E.; Taylor, B.; Fleming, A.; Mason, C.; Thorburn, P. Big Data, Trust and Collaboration: Exploring the Socio-Technical Enabling
Conditions for Big Data in the Grains Industry; CSIRO: Brisbane, Australia, 2016; p. 34.
11.
Smith, M.J. Getting value from artiﬁcial intelligence in agriculture. Anim. Prod. Sci. 2018, 60, 46–54. [CrossRef]
12.
Nasirahmadi, A.; Wilczek, U.; Hensel, O. Sugar Beet Damage Detection during Harvesting Using Different Convolutional Neural
Network Models. Agriculture 2021, 11, 1111. [CrossRef]
13.
Farooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey on the Role of IoT in Agriculture for the Implementation of
Smart Farming. IEEE Access 2019, 7, 156237–156271. [CrossRef]
14.
Paraforos, D.S.; Griepentrog, H.W. Digital Farming and Field Robotics: Internet of Things, Cloud Computing, and Big Data.
In Fundamentals of Agricultural and Field Robotics. Agriculture Automation and Control; Karkee, M., Zhang, Q., Eds.; Springer:
Cham, Switzerland, 2021.
15.
Zhang, X.; Cao, Z.; Dong, W. Overview of Edge Computing in the Agricultural Internet of Things: Key Technologies, Applications,
Challenges. IEEE Access 2020, 8, 141748–141761. [CrossRef]
16.
Sarker, V.K.; Queralta, J.P.; Gia, T.N.; Tenhunen, H.; Westerlund, T. A Survey on LoRa for IoT: Integrating Edge Computing.
In Proceedings of the 2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC), Rome, Italy,
10–13 June 2019; pp. 295–300.
17.
Ning, H.; Li, Y.; Shi, F.; Yang, L.T. Heterogeneous edge computing open platforms and tools for internet of things. Future Gener.
Comput. Syst. 2020, 106, 67–76. [CrossRef]
18.
An, W.; Wu, D.; Ci, S.; Luo, H.; Adamchuk, V.; Xu, Z. Agriculture Cyber-Physical Systems.
In Cyber-Physical Systems;
Academic Press: Cambridge, MA, USA, 2017; pp. 399–417.
19.
Chergui, N.; Kechadi, M.T.; McDonnell, M. The Impact of Data Analytics in Digital Agriculture: A Review. In Proceedings of
the 2020 International Multi-Conference on: Organization of Knowledge and Advanced Technologies (OCTA), Tunis, Tunisia,
6–8 February 2020; pp. 1–13.
20.
Walters, J.P.; Archer, D.W.; Sassenrath, G.F.; Hendrickson, J.R.; Hanson, J.D.; Halloran, J.M.; Vadas, P.; Alarcon, V.J. Exploring agri-
cultural production systems and their fundamental components with system dynamics modelling. Ecol. Model. 2016, 333, 51–65.
[CrossRef]
21.
Grieves, M.; Vickers, J. Digital twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems.
In Transdisciplinary Perspectives on Complex Systems; Springer: Cham, Switzerland, 2017; pp. 85–113.
22.
Verdouw, C.; Tekinerdogan, B.; Beulens, A.; Wolfert, S. Digital twins in smart farming. Agric. Syst. 2021, 189, 103046. [CrossRef]
23.
Negri, E.; Fumagalli, L.; Macchi, M. A Review of the Roles of Digital Twin in CPS-based Production Systems. Procedia Manuf.
2017, 11, 939–948. [CrossRef]
24.
Semeraro, C.; Lezoche, M.; Panetto, H.; Dassisti, M. Digital twin paradigm: A systematic literature review. Comput. Ind.
2021, 130, 103469. [CrossRef]
25.
VanDerHorn, E.; Mahadevan, S. Digital Twin: Generalization, characterization and implementation. Decis. Support Syst. 2021,
145, 113524. [CrossRef]
26.
Liu, Y.; Zhang, L.; Yang, Y.; Zhou, L.; Ren, L.; Wang, F.; Liu, R.; Pang, Z.; Deen, M.J. A Novel Cloud-Based Framework for the
Elderly Healthcare Services Using Digital Twin. IEEE Access 2019, 7, 49088–49101. [CrossRef]
27.
Juarez, M.G.; Botti, V.J.; Giret, A.S. Digital Twins: Review and Challenges. J. Comput. Inf. Sci. Eng. 2021, 21, 030802. [CrossRef]
28.
Wright, L.; Davidson, S. How to tell the difference between a model and a digital twin. Adv. Modeling Simul. Eng. Sci. 2020, 7, 13.
[CrossRef]
29.
Lu, J.; Zheng, X.; Schweiger, L.; Kiritsis, D. A Cognitive Approach to Manage the Complexity of Digital Twin Systems.
In Smart Services Summit; West, S., Meierhofer, J., Ganz, C., Eds.; Progress in IS; Springer: Cham, Switzerland, 2021.
30.
Neethirajan, S.; Kemp, B. Digital Twins in Livestock Farming. Animals 2021, 11, 1008. [CrossRef]
31.
Moghadam, P.; Lowe, T.; Edwards, E.J. Digital Twin for the Future of Orchard Production Systems. Multidiscip. Digit. Publ. Inst. Proc.
2020, 36, 92. [CrossRef]
32.
Angin, P.; Anisi, M.H.; Göksel, F.; Gürsoy, C.; Büyükgülcü, A. AgriLoRa: A Digital Twin Framework for Smart Agriculture.
J. Wirel. Mob. Netw. Ubiquitous Comput. Dependable Appl. 2020, 11, 77–96.
33.
Skobelev, P.O.; Mayorov, I.V.; Simonova, E.V.; Goryanin, O.I.; Zhilyaev, A.A.; Tabachinskiy, A.S.; Yalovenko, V.V. Development of
models and methods for creating a digital twin of plant within the cyber-physical system for precision farming management.
J. Phys. Conf. Ser. 2020, 1703, 012022. [CrossRef]
34.
Jo, S.K.; Park, D.H.; Park, H.; Kim, S.H. Smart livestock farms using digital twin: Feasibility study. In Proceedings of the 2018 Inter-
national Conference on Information and Communication Technology Convergence (ICTC), Jeju Island, Korea, 17–19 October 2018;
pp. 1461–1463.
35.
Tsolakis, N.; Bechtsis, D.; Bochtis, D. AgROSos: A Robot Operating System Based Emulation Tool for Agricultural Robotics.
Agronomy 2019, 9, 403. [CrossRef]
36.
Monteiro, J.; Barata, J.; Veloso, M.; Veloso, L.; Nunes, J. Towards sustainable digital twins for vertical farming. In Proceedings of the
2018 Thirteenth International Conference on Digital Information Management (ICDIM), Berlin, Germany, 24–26 September 2018;
pp. 234–239.
Sensors 2022, 22, 498
14 of 16
37.
Alves, R.G.; Souza, G.; Maia, R.F.; Tran, A.L.H.; Kamienski, C.; Soininen, J.P.; Aquino, P.T.; Lima, F. A digital twin for smart
farming. In Proceedings of the 2019 IEEE Global Humanitarian Technology Conference (GHTC), Santa Clara, CA, USA,
8–11 September 2022; pp. 1–4.
38.
Laamarti, F.; Badawi, H.F.; Ding, Y.; Arafsha, F.; Haﬁdh, B.; El Saddik, A. An ISO/IEEE 11073 Standardized Digital Twin
Framework for Health and Well-Being in Smart Cities. IEEE Access 2020, 8, 105950–105961. [CrossRef]
39.
Gámez Díaz, R.; Yu, Q.; Ding, Y.; Laamarti, F.; El Saddik, A. Digital Twin Coaching for Physical Activities: A Survey. Sensors
2020, 20, 5936. [CrossRef]
40.
Verdouw, C.N.; Kruize, J.W. Digital twins in farm management: Illustrations from the FIWARE accelerators SmartAgriFood
and Fractals. In Proceedings of the 7th Asian-Australasian Conference on Precision Agriculture, Hamilton, New Zealand,
16–18 October 2017; pp. 16–18.
41.
Sreedevi, T.R.; Kumar, M.S. Digital Twin in Smart Farming: A Categorical Literature Review and Exploring Possibilities in
Hydroponics. In Proceedings of the 2020 Advanced Computing and Communication Technologies for High Performance
Applications (ACCTHPA), Cochin, India, 2–4 July 2020; pp. 120–124.
42.
Verboven, P.; Defraeye, T.; Datta, A.K.; Nicolai, B. Digital twins of food process operations: The next step for food process models?
Curr. Opin. Food Sci. 2020, 35, 79–87. [CrossRef]
43.
Onwude, D.I.; Chen, G.; Eke-Emezie, N.; Kabutey, A.; Khaled, A.Y.; Sturm, B. Recent Advances in Reducing Food Losses in the
Supply Chain of Fresh Agricultural Produce. Processes 2020, 8, 1431. [CrossRef]
44.
van der Burg, S.; Kloppenburg, S.; Kok, E.J.; van der Voort, M. Digital twins in agri-food: Societal and ethical themes and
questions for further research. NJAS Impact Agric. Life Sci. 2021, 93, 98–125. [CrossRef]
45.
Defraeye, T.; Shrivastava, C.; Berry, T.; Verboven, P.; Onwude, D.; Schudel, S.; Bühlmann, A.; Cronje, P.; Rossi, R.M. Digital twins
are coming: Will we need them in supply chains of fresh horticultural produce? Trends Food Sci. Technol. 2021, 109, 245–258.
[CrossRef]
46.
Tebaldi, L.; Vignali, G.; Bottani, E. Digital Twin in the Agri-Food Supply Chain: A Literature Review. In APMS 2021: Advances
in Production Management Systems. Artiﬁcial Intelligence for Sustainable and Resilient Production System; Dolgui, A., Bernard, A.,
Lemoine, D., von Cieminski, G., Romero, D., Eds.; IFIP Advances in Information and Communication Technology; Springer:
Cham, Switzerland, 2021; Volume 633.
47.
Pylianidis, C.; Osinga, S.; Athanasiadis, I.N. Introducing digital twins to agriculture. Comput. Electron. Agric. 2021, 184, 105942.
[CrossRef]
48.
Vilˇcek, J.; Štefan, K. Integrated index of agricultural soil quality in Slovakia. J. Maps 2018, 14, 68–76. [CrossRef]
49.
Yin, H.; Cao, Y.; Marelli, B.; Zeng, X.; Mason, A.J.; Cao, C. Soil Sensors and Plant Wearables for Smart and Precision Agriculture.
Adv. Mater. 2021, 33, 2007764. [CrossRef] [PubMed]
50.
Basterrechea, D.A.; Rocher, J.; Parra, M.; Parra, L.; Marin, J.F.; Mauri, P.V.; Lloret, J. Design and Calibration of Moisture Sensor
Based on Electromagnetic Field Measurement for Irrigation Monitoring. Chemosensors 2021, 9, 251. [CrossRef]
51.
Söderström, M.; Sohlenius, G.; Rodhe, L.; Piikki, K. Adaptation of regional digital soil mapping for precision agriculture. Precis.
Agric. 2016, 17, 588–607. [CrossRef]
52.
Searle, R.; McBratney, A.; Grundy, M.; Kidd, D.; Malone, B.; Arrouays, D.; Stockman, U.; Zund, P.; Wilson, P.; Wilford, J.; et al.
Digital soil mapping and assessment for Australia and beyond: A propitious future. Geoderma Reg. 2021, 24, e00359. [CrossRef]
53.
Wadoux, A.M.C.; McBratney, A.B. Digital soil science and beyond. Soil Sci. Soc. Am. J. 2021, 85, 1313–1331. [CrossRef]
54.
Villani, G.; Castaldi, P.; Toscano, A.; Stanghellini, C.; Cinotti, T.S.; Maia, R.F.; Tomei, F.; Taumberger, M.; Zanetti, P.; Panizzi, S. Soil
Water Balance Model CRITERIA-ID in SWAMP Project: Proof of Concept. In Proceedings of the 2018 23rd Conference of Open
Innovations Association (FRUCT), Bologna, Italy, 13–16 November 2018; pp. 398–404.
55.
Cunha, H.; Loureiro, D.; Sousa, G.; Covas, D.; Alegre, H. A comprehensive water balance methodology for collective irrigation
systems. Agric. Water Manag. 2019, 223, 105660. [CrossRef]
56.
Pesantez, J.E.; Alghamdi, F.; Sabu, S.; Mahinthakumar, G.; Berglund, E.Z. Using a Digital Twin to Explore Water Infrastructure
Impacts During the COVID-19 Pandemic. Sustain. Cities Soc. 2021, 103520. [CrossRef]
57.
Moreira, M.; Mourato, S.; Rodrigues, C.; Silva, S.; Guimarães, R.; Chibeles, C. Building a Digital Twin for the Management
of Pressurised Collective Irrigation Systems. In ICoWEFS 2021: Proceedings of the 1st International Conference on Water Energy
Food and Sustainability (ICoWEFS 2021), Proceedings of the International Conference on Water Energy Food and Sustainability, Leiria,
Portugal, 10–12 May 2021; da Costa Sanches Galvão, J.R., de Brito, P.S.D., dos Santos Neves, F., da Silva Craveiro, F.G., de Amorim
Almeida, H., Vasco, J.O.C., Neves, L.M.P., de Jesus Gomes, R., de Jesus Martins Mourato, S., Ribeiro, V.S.S., Eds.; Springer:
Cham, Switzerland, 2021.
58.
Reis, Â.V.D.; Medeiros, F.A.; Ferreira, M.F.; Machado, R.L.T.; Romano, L.N.; Marini, V.K.; Francetto, T.R.; Machado, A.L.T.
Technological trends in digital agriculture and their impact on agricultural machinery development practices. Revi. Ciência
Agronômica 2021, 51, e20207740. [CrossRef]
59.
CEMA. Digital Farming: What Does It Really Mean? 2017. Available online: https://www.cema-agri.org/images/publications/
position-papers/CEMA_Digital_Farming_-_Agriculture_4.0__13_02_2017_0.pdf (accessed on 4 January 2022).
60.
Rotz, S.; Gravely, E.; Mosby, I.; Duncan, E.; Finnis, E.; Horgan, M.; LeBlanc, J.; Martin, R.; Neufeld, H.T.; Nixon, A.; et al.
Automated pastures and the digital divide: How agricultural technologies are shaping labour and rural communities. J. Rural Stud.
2019, 68, 112–122. [CrossRef]
Sensors 2022, 22, 498
15 of 16
61.
Liu, Q.; Leng, J.; Yan, D.; Zhang, D.; Wei, L.; Yu, A.; Zhao, R.; Zhang, H.; Chen, X. Digital twin-based designing of the conﬁguration,
motion, control, and optimization model of a ﬂow-type smart manufacturing system. J. Manuf. Syst. 2021, 58, 52–64. [CrossRef]
62.
Alamin, K.; Vinco, S.; Poncino, M.; Dall’Ora, N.; Fraccaroli, E.; Quaglia, D. February. Digital Twin Extension with Extra-
Functional Properties. In Proceedings of the 2021 Design, Automation & Test in Europe Conference & Exhibition (DATE), Virtual,
1–5 February 2021; pp. 434–439.
63.
Kampker, A.; Stich, V.; Jussen, P.; Moser, B.; Kuntz, J. Business Models for Industrial Smart Services–The Example of a Digital
Twin for a Product-Service-System for Potato Harvesting. Procedia CIRP 2019, 83, 534–540. [CrossRef]
64.
Vlădăreanu, L.; Gal, A.I.; Melinte, O.D.; Vlădăreanu, V.; Iliescu, M.; Bruja, A.; Feng, Y.; Ciocîrlan, A. Robot Digital Twin towards
Industry 4.0. IFAC-PapersOnLine 2020, 53, 10867–10872. [CrossRef]
65.
Wang, Q.; Jiao, W.; Wang, P.; Zhang, Y. Digital Twin for Human-Robot Interactive Welding and Welder Behavior Analysis.
IEEE/CAA J. Autom. Sin. 2020, 8, 334–343. [CrossRef]
66.
Garg, G.; Kuts, V.; Anbarjafari, G. Digital Twin for FANUC Robots: Industrial Robot Programming and Simulation Using Virtual
Reality. Sustainability 2021, 13, 10336. [CrossRef]
67.
Lumer-Klabbers, G.; Hausted, J.O.; Kvistgaard, J.L.; Macedo, H.D.; Frasheri, M.; Larsen, P.G. Towards a Digital Twin Framework
for Autonomous Robots. In Proceedings of the 2021 IEEE 45th Annual Computers, Software, and Applications Conference
(COMPSAC), Madrid, Spain, 12–16 July 2021; pp. 1254–1259.
68.
Linz, A.; Hertzberg, J.; Roters, J.; Ruckelshausen, A. “Digitale Zwillinge” als Werkzeug für die Entwicklung von Feldrobotern
in landwirtschaftlichen Prozessen.
In 39.
GIL-Jahrestagung, Digitalisierung für landwirtschaftliche Betriebe in kleinstrukturi-
erten Regionen-ein Widerspruch in sich? Gesellschaft für Informatik: Bonn, Germany, 2019; pp. 125–130. Available online:
https://dl.gi.de/handle/20.500.12116/23075 (accessed on 4 January 2022). (In German)
69.
Ford, D.N.; Wolf, C.M. Smart Cities with Digital Twin Systems for Disaster Management. J. Manag. Eng. 2020, 36, 04020027.
[CrossRef]
70.
Tsay, J.R.; Lu, C.T.; Tu, T.C. Application of Common Information Platform to Foster Data-Driven Agriculture in Taiwan. Food
Agricultural Policy Platform Article. 2019. Available online: https://ap.fftc.org.tw/article/1632 (accessed on 4 January 2022).
71.
Villalonga, A.; Negri, E.; Fumagalli, L.; Macchi, M.; Castaño, F.; Haber, R. Local Decision Making based on Distributed Digital
Twin Framework. IFAC-PapersOnLine 2020, 53, 10568–10573. [CrossRef]
72.
Moshrefzadeh, M.; Machl, T.; Gackstetter, D.; Donaubauer, A.; Kolbe, T.H. Towards a Distributed Digital Twin of the Agricultural
Landscape. J. Digit. Landsc. Archit. 2020, 5, 173–186.
73.
Jans-Singh, M.; Leeming, K.; Choudhary, R.; Girolami, M. Digital twin of an urban-integrated hydroponic farm. Data-Cent. Eng.
2020, 1, e20. [CrossRef]
74.
Chaux, J.D.; Sanchez-Londono, D.; Barbieri, G. A Digital Twin Architecture to Optimize Productivity within Controlled Environ-
ment Agriculture. Appl. Sci. 2021, 11, 8875. [CrossRef]
75.
Lezoche, M.; Hernandez, J.E.; Del Mar Alemany Díaz, M.; Panetto, H.; Kacprzyk, J. Agri-food 4.0: A survey of the supply chains
and technologies for the future agriculture. Comput. Ind. 2020, 117, 103187. [CrossRef]
76.
Purandare, H.; Ketkar, N.; Pansare, S.; Padhye, P.; Ghotkar, A. Analysis of post-harvest losses: An Internet of Things and
machine learning approach. In Proceedings of the 2016 International conference on automatic control and dynamic optimization
techniques (ICACDOT), Pune, India, 9–10 September 2016; pp. 222–226.
77.
Mishra, C.K.; Chakshu. Post-harvest crop management system using IoT and AI. Int. J. Adv. Res. Dev. 2019, 4, 42–44.
78.
Mor, S.; Madan, S.; Prasad, K.D. Artiﬁcial intelligence and carbon footprints: Roadmap for Indian agriculture. Strateg. Chang.
2021, 30, 269–280. [CrossRef]
79.
Bekele, B. Review on Factors Affecting Postharvest Quality of Fruits. J. Plant Sci. Res. 2018, 5, 180.
80.
Eppinger, T.; Longwell, G.; Mas, P.; Goodheart, K.; Badiali, U.; Aglave, R. Increase Food Production Efﬁciency Using the
Executable Digital Twin (xDT). Chem. Eng. Trans. 2021, 87, 37–42.
81.
Koulouris, A.; Misailidis, N.; Petrides, D. Applications of process and digital twin models for production simulation and
scheduling in the manufacturing of food ingredients and products. Food Bioprod. Process. 2021, 126, 317–333. [CrossRef]
82.
Defraeye, T.; Tagliavini, G.; Wu, W.; Prawiranto, K.; Schudel, S.; Kerisima, M.A.; Verboven, P.; Bühlmann, A. Digital twins probe
into food cooling and biochemical quality changes for reducing losses in refrigerated supply chains. Resour. Conserv. Recycl.
2019, 149, 778–794. [CrossRef]
83.
Burgos, D.; Ivanov, D. Food retail supply chain resilience and the COVID-19 pandemic: A digital twin-based impact analysis and
improvement directions. Transp. Res. E Logist. Transp. Rev. 2021, 152, 102412. [CrossRef] [PubMed]
84.
Shoji, K.; Schudel, S.; Onwude, D.; Shrivastava, C.; Defraeye, T. Mapping the postharvest life of imported fruits from packhouse
to retail stores using physics-based digital twins. Resour. Conserv. Recycl. 2022, 176, 105914. [CrossRef]
85.
Ahmed, A.; Zulﬁqar, S.; Ghandar, A.; Chen, Y.; Hanai, M.; Theodoropoulos, G. Digital twin technology for aquaponics: Towards
optimizing food production with dynamic data driven application systems. In AsiaSim 2019: Methods and Applications for Modeling
and Simulation of Complex Systems, Proceedings of the Asian Simulation Conference, Singapore, 30 October–1 November 2019; Springer:
Singapore; pp. 3–14.
86.
Ghandar, A.; Ahmed, A.; Zulﬁqar, S.; Hua, Z.; Hanai, M.; Theodoropoulos, G. A Decision Support System for Urban Agriculture
Using Digital Twin: A Case Study With Aquaponics. IEEE Access 2021, 9, 35691–35708. [CrossRef]
Sensors 2022, 22, 498
16 of 16
87.
Nemtinov, K.; Eruslanova, M.; Zazulya, A.; Nemtinova, Y.; Haider, S.S. Creating a digital twin of an agricultural machine.
In Proceedings of the MATEC Web of Conferences, EDP Sciences, Sevastopol, Russia, 7–11 September 2020; Volume 329, p. 05002.
88.
Bottani, E.; Vignali, G.; Tancredi, G.P.C. A digital twin model of a pasteurization system for food beverages: Tools and architecture.
In Proceedings of the 2020 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC), Cardiff, UK,
15–17 June 2020; pp. 1–8.
89.
Chiscop, F.; Necula, B.; Cazacu, C.C.; Stoica, C.E. Using Digital Twining in Fast-food Production Chain Simulation. In Proceedings
of the MATEC Web of Conferences, EDP Sciences, Sibiu, Romania, 2–4 June 2021; Volume 343, p. 03005.
90.
Tekinerdogan, B.; Verdouw, C. Systems architecture design pattern catalog for developing digital twins. Sensors 2020, 20, 5103.
[CrossRef] [PubMed]
91.
Ciruela-Lorenzo, A.M.; Del-Aguila-Obra, A.R.; Padilla-Meléndez, A.; Plaza-Angulo, J.J. Digitalization of Agri-Cooperatives in the
Smart Agriculture Context. Proposal of a Digital Diagnosis Tool. Sustainability 2020, 12, 1325. [CrossRef]
92.
O’Grady, M.J.; Langton, D.; O’Hare, G.M.P. Edge computing: A tractable model for smart agriculture? Artif. Intell. Agric.
2019, 3, 42–51. [CrossRef]
93.
Komasilovs, V.; Zacepins, A.; Kviesis, A.; Nasirahmadi, A.; Sturm, B. Solution for remote real-time visual expertise of agricultural
objects. Agron. Res. 2018, 16, 464–473.


</subsection_point_Point 1>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 6>
Point: Explore the role of metadata in providing context and enabling better data interpretation and decision-making

Papers to support point:

Paper 1:
- APA Citation:  Muñoz, M.; Gil, J.D.; Roca, L.; Rodríguez, F.; Berenguel, M. An IoT Architecture for Water Resource Management in Agroindustrial Environments: A Case Study in Almería (Spain)†. Sensors 2020, 20, 596. https://doi.org/10.3390/s20030596
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: The IoT platform is based on a back end architecture, front end, and context generators. This architecture is independent of each other, allowing adding or removing services without affecting the operation of the previous layer. It is based on a cloud architecture that encompasses storage functionalities, a platform as a service, and connectivity.
  Extract 2: The front end is the layer linked to the client, and therefore, it is in charge of the visualization of all the data. It is composed by a set of technologies that form the structure and design of the application. The most used programming languages for the development of this layer are JavaScript and PHP, as well as languages based on design and layout, such as HTML and CSS.
  Limitations: The paper does not explicitly address the specific limitations of the proposed IoT platform for fully addressing the point in the outline. However, it does mention that the platform is based on existing technologies and standards, which may have their own limitations.
  Relevance Evaluation: The paper is highly relevant to the specific point in the outline you are making. It directly addresses the role of metadata in providing context and enabling better data interpretation and decision-making in the context of an IoT platform for agroindustrial districts, which is precisely the topic of interest in the outline point.
  Relevance Score: 1.0
  Inline Citation: (Muñoz 2020)
  Explanation: This article presents a detailed explanation of the proposed IoT platform for the optimal management of agroindustrial districts, including the problem statement, methods, and theoretical background. More specifically, it focuses on the exploration of the role of metadata in providing context and enabling better data interpretation and decision-making for this particular application. The text elaborates on how the platform incorporates an MPC strategy to optimize operational costs, taking into account costs of the feed pump of the desalination facility and costs of the water coming from the public utility network, while ensuring water demands are met.

 Full Text: >
sensors
Article
An IoT Architecture for Water Resource Management
in Agroindustrial Environments: A Case Study
in Almería (Spain)†
Manuel Muñoz 1,∗
, Juan D. Gil 1
, Lidia Roca 2
, Francisco Rodríguez 1
and Manuel Berenguel 1
1
Departamento de Informática, Escuela Superior de Ingeniería, Universidad de Almería, ceiA3, CIESOL, Ctra.
Sacramento s/n, 04120 Almería, Spain; juandiego.gil@ual.es (J.D.G.); frrodrig@ual.es (F.R.);
beren@ual.es (M.B.)
2
Convenio Universidad de Almería, Plataforma Solar de Almería, Ctra. Senés s/n, 04200 Tabernas, Almería,
Spain; lidia.roca@psa.es
*
Correspondence: mmr411@ual.es
†
This paper is an extended version of our paper published in “An IoT based Control System for a Solar
Membrane Distillation Plant used for Greenhouse Irrigation” presented at the 2019 Global Internet of Things
Summit (GIoTS), Aarhus, Denmark, 17–21 June 2019.
Received: 13 December 2019; Accepted: 16 January 2020; Published: 21 January 2020


Abstract: The current agricultural water panorama in many Mediterranean countries is composed by
desalination facilities, wells (frequently overexploited), the water public utility network, and several
consumer agents with different water needs. This distributed water network requires centralized
management methods for its proper use, which are difﬁcult to implement as the different agents are
usually geographically separated. In this sense, the use of enabling technologies such as the Internet
of Things can be essential to the proper operation of these agroindustrial systems. In this paper, an
Internet of Things cloud architecture based on the FIWARE standard is proposed for interconnecting
the several agents that make up the agroindustrial system. In addition, this architecture includes
an efﬁcient management method based on a model predictive control technique, which is aimed at
minimizing operating costs. A case study inspired by three real facilities located in Almería (southeast
of Spain) is used as the simulation test bed. The obtained results show how around 75% of the total
operating costs can be saved with the application of the proposed approach, which could be very
signiﬁcant to decrease the costs of desalinated water and, therefore, to maintain the sustainability of
the agricultural system.
Keywords: FIWARE; cloud storage; model predictive control; smart water management; smart agriculture
1. Introduction
Almería (southeast of Spain) is one of the driest regions in Europe, but paradoxically, it has one
of the continent’s largest agricultural production systems. Such a system is composed of more than
30,000 ha of effective greenhouse production [1], and it has become the main driving force of the
economy of this dry region. One basic ingredient of this system is fresh water, so that the development
of agriculture in Almería has been associated for many years with the decline of fresh water reservoirs,
despite being the agricultural area where the most efﬁcient management of this resource is carried
out [2]. This encouraged the installation of desalination plants as a tool to maintain the fresh water
availability in the region and,therefore, the sustainability of the agricultural system [3]. Thus, Almería’s
current agricultural water panorama comprises consumer agents, as greenhouses and industries related
to agriculture, and producer agents based on conventional (water public utility network and wells)
Sensors 2020, 20, 596; doi:10.3390/s20030596
www.mdpi.com/journal/sensors
Sensors 2020, 20, 596
2 of 21
and non-conventional sources (desalination facilities). This agroindustrial environment constitutes a
distributed water network that requires an integral smart management method for its optimal use [4].
Several management strategies have been formulated in the literature for distributed water
networks, especially focused on the urban water cycle of Barcelona (Spain). In the work of Ocampo
Martinez et al. [5], Model Predictive Control (MPC) paradigms were proposed aimed at reducing
pumping costs. An operational MPC approach was proposed by Pascual et al. [6], tasked with reducing
costs, as well as maintaining safety storage volumes in the buffer tanks. Another control based water
management system was proposed by Lopez Farias et al. [7]. In this case, the forecasting accuracy
of the control system was improved by means of a qualitative multi-model predictor. Although all
these works proposed effective management methods, they did not describe the way in which all the
information coming from the different devices of the distributed network is integrated and uniﬁed for
the application of the methods in real cases. In addition, they are focused on optimizing the transport
water network, without taking into account the optimal management of the water sources.
To manage the water sources optimally, it is essential to adapt the production to the demand.
This fact is especially signiﬁcant when considering desalination facilities in the water network
(as happens in Almería) as the costs associated with the production of desalinated water are still
relatively high [8], and they depend directly on production. The work presented by Roca et al. [9]
demonstrated how a desalination facility can be efﬁciently coupled to a greenhouse by using MPC
techniques. Moreover, the work in [10] showed how metrics related to the desalination process
can be improved in these kinds of combinations by using advanced control strategies. However,
these works were focused only on the management method, considering desalination as the only
water source, and without taking into account costs in the management problem.
As stated
in [11], to minimize the operational costs of desalination facilities and to improve their efﬁciency,
a bi-directional communication between them and the consumers must be established, which can
be achieved by means of adequate Information and Communication Technologies (ICT) tools. This
is especially relevant in Almería, where there are relatively small and geographically dispersed
greenhouse cultivation areas that depend on the water coming from one or several desalination plants.
These plants need to know the water demand of each greenhouse for their efﬁcient use in terms of
operating costs. One natural choice to solve the problem is the Internet of Things (IoT) framework,
as it allows connecting all the devices in a uniﬁed platform regardless of their geographical location.
In addition, IoT can be associated with data analytics and cloud computing, thus making powerful
platforms that allow gathering the required information from different IoT devices, analyzing it
in the cloud, and transmitting the corresponding control signals to the actuators of the distributed
network. These features have made IoT a key component in the development of sustainable distributed
environments [12,13].
In recent years, IoT has experienced a breakthrough, changing the way in which providers and
consumers interact with each other. Agriculture is not alien to this transition, and it is experiencing a
change of the business model in the technological ﬁeld [14,15] according to which customers (farmers)
are ceasing to acquire assets (monitoring computers, sensors, or control systems) while demanding
services [16,17]. In this framework, the supplier companies are responsible for ensuring the proper
functioning of their equipment and providing the data necessary for farmers to make their decisions,
billing for such services. The devices, through the change of ﬁrmware, can dynamically change the
activities they carry out, supplying information to the cloud (not only locally as is usually done) [18]
and, through the adequate processing of this information, help to reduce service times and operation
shutdowns. This paradigm shift requires the establishment of transversal protocols, interoperability,
and collaboration between companies and services.
Nevertheless, the arrival of IoT to the agricultural ﬁeld not only has inﬂuenced the relationships
between costumers and companies, but also the way in which the agricultural activities are developed.
Thus, the term Precision Agriculture (PA) has emerged [19,20], which involves the use of a series of
sensors and actuators that allow gathering context information of the environment that surrounds
Sensors 2020, 20, 596
3 of 21
them. This paradigm enables the development of tools to assist in decision-making, monitoring
activities in the crop, and applications to improve the quality; all of them aimed at obtaining a more
efﬁcient and sustainable agricultural system [21–24]. In this way, different agronomic data management
platforms using IoT technologies are being developed, often driven by European Union initiatives.
These platforms are a natural evolution of the so-called farm management systems to make them
compatible with cloud computing [19,21,25]. FIWARE is an initiative of the European Union for the
creation of a platform that helps the development of applications and solutions focused on the IoT [26].
FIWARE aims to create an open and sustainable ecosystem, based on public software standards.
Moreover, regarding water management in crops, which is the scope of this work, several
approaches have been proposed in literature making a proper use of IoT technology for developing
smart irrigation systems, some of them based on the use of FIWARE as well. In [27], an IoT system for
smart energy consumption and irrigation was presented. The system decides the amount of water
required by the crops according to the current moisture in soil and humidity (measured by mean
of IoT sensors) and the time of the day. A similar approach was proposed in [28], but in this case,
meteorological data were also considered to predict the water requirements based on a machine
learning system. The most complete approach was the one proposed in [29], in which an IoT platform
based on FIWARE was proposed for smart water management in agriculture taking into account water
reserve, water distribution, and water consumption. However, all these works were mainly focused
on the management of irrigation and on the distribution system considering only the public utility
water network as the water source.
In this way, the
main gaps observed in the literature according to the above review are the
following ones:
•
The management methods presented for distributed water networks so far only addressed
the optimization of the transport water network, without taking into account water sources.
Besides, they did not establish the way in which the different agents of the distributed network
were interconnected.
•
The works addressing the connection of non-conventional water sources as desalination facilities
and consumer agents were focused on the optimal management of the desalination facilities,
without considering other water sources in the problem. In addition, they were aimed at
improving metrics related to the desalination process, but not to minimizing economic costs,
which is very relevant for the correct implementation of this type of framework. Furthermore,
they did not describe the way in which the agents are interconnected.
•
The works related to enabling technologies such as IoT in the agricultural ﬁeld were focused
on improving the crops’ performance, addressing aspects like the optimization of the irrigation
system, or the development of platforms to improve the decision making. However, to the authors’
knowledge, there are no works that discuss the use of these kinds of technologies for the effective
management of agroindustrial districts in terms of water, which can be essential to optimize the
performance of the new panorama that arises with the introduction of new water sources in the
agricultural ecosystem.
To address the aforementioned issues, this work presents an IoT platform for the optimal
management of the distributed water network of agroindustrial environments. The contributions
of the work are three fold. First, a scalable IoT platform for the interconnection of the different
agents composing the distributed water network is proposed. The IoT platform is based on FIWARE,
and the architecture is fragmented into layers or services. Second, the IoT platform incorporates an
MPC strategy tasked with optimizing the operational costs of the water network, taking into account
the costs of the feed pump of the desalination facility and the costs of the water coming from the
public utility network, while ensuring the water needs. Third, to demonstrate the effectiveness of the
proposed approach, a case study based on three real plants located in Almería is used to carry out
exhaustive simulation tests with non-optimal management methods.
Sensors 2020, 20, 596
4 of 21
The reminder of the document is organized as follows: Section 2 is dedicated to depicting the
concept and problems of agroindustrial districts. Section 3 is aimed at presenting the basis of the
proposed IoT platform, a general overview of it, and the description of the practical case study adopted.
Section 4 presents and discusses the simulation results. Section 5 summarizes the conclusions obtained
from the results and possible future work.
2. Agroindustrial District: Deﬁnition and Problems
Before presenting the IoT architecture, it is essential to deﬁne the agroindustrial district concept
and the problems associated with this kind of system. The contemporary industrial district theory is
owed to Giacomo Beccattini [30], who deﬁned it as a territorial-partner entity characterized by the
active presence of a community of people and a population of companies in a given geographical
and historical space. Following this proposal, the term agroindustrial district was introduced as a
district constituted by farms, processing companies, and supply companies located in a given territory.
This environment is usually dominated by small and medium enterprises, specialized in one of
the phases of the production chain. Among them, there are important relationships of the vertical
type (between companies of different phases of the production process) and of the horizontal type
(between companies of the same phase) or transversal (with supply and service companies).
In this synergy framework, there are systems with different objectives that depend on the needs
of heterogeneous resources, both energy (electricity and heat/cold) and others (such as water and
CO2). In addition, if renewable energy is included in this environment, it is necessary to manage
conveniently the efﬁcient use of all resources in each of the systems, as well as coordinate the ﬂow
between them. The research project Control and Optimal Management of Heterogeneous Resources
in Agroindustrial production districts integrating renewable Energies (CHROMAE) (www2.ual.es/
chromae), funded by the Spanish Ministry of Economy, Industry and Competitiveness and ERDF
funds, is aimed at developing comprehensive, coordinated, and optimal management strategies
for the heterogeneous resources required by the elements that make up an agroindustrial district.
The different agents, resources, and interlinks considered in the CHROMAE project can by found at
(www2.ual.es/chromae).
Although the present work is based on this project, it particularizes only the production phase of
the agroindustrial sector, the most extended case in Almería. In this phase, the challenge was directly
related to the optimal and efﬁcient management of water, essential for crops. This resource must be
managed, establishing as a main premise that the result of such optimal management produces an as
small as possible environmental impact. Moreover, economic criteria must also be taken into account
in the management problem. Another fact to consider and that should be added to the problem
is that the different elements of the district are usually geographically separated. This requires the
use of enabling technologies (such as IoT) to close the circle, interconnect different systems, and to
manage all of them centrally.
3. The IoT Platform: Basis, Overview and Case Study Description
This section presents the main components of the IoT architecture developed for the optimal
management of an agroindustrial district, as well as a general description of it and its application in a
case study in Almería. In this way, the FIWARE platform and the MPC technique are ﬁrstly depicted.
Then, an overview of the proposed platform is shown and described, and ﬁnally, the case study in
Almería is developed.
3.1. FIWARE
FIWARE [26] is an IoT platform driven by the European Union. FIWARE presents a modular
architecture based on open source components trying to form an open and sustainable ecosystem
with the capacity to be adapted to different environments. This platform provides cloud capabilities
based on OpenStack [31] including a series of libraries and tools known as Generic Enablers (GEs) [32],
Sensors 2020, 20, 596
5 of 21
which facilitate the creation of applications and services in IoT. These GEs offer Representational State
Transfer (REST) and an Application Programming Interface (API) with public and free speciﬁcations,
which allow the integration of third party software services, leading to an acceleration in the
development of intelligent solutions, including data analysis and processing, persistence, and language
interpreters, among others. The GEs are based on APIs that implement the Open Mobile Alliance
(OMA) and Next-Generation Services Interface (NGSI) standards [33].
FIWARE is trying to promote a new standard for IoT. The main core of FIWARE, and mandatory
for its use, is the enabler called the Orion Context Broker (OCB), which is responsible for managing
context information. In this sense, context refers to the entire environment surrounding the IoT system,
which is capable of producing relevant information for the development of the system. This context
information is generated by different data sources such as a network of sensors, existing third party
applications, actuators, and other devices. The following points describe some of the most important
GEs of FIWARE [32]:
1.
OCB: It is the intermediary between producers (publishers) and consumers (subscribers).
The NGSI interface is a RESTful APIs service, which allows queries on the status of context
information. This allows creating as many entities as sensors or set of sensors available in the
system, allowing collecting information in real time.
2.
Cygnus: It is the GE in charge of persisting context information, and it is based on Apache Flume.
Cygnus allows making a copy of the data simultaneously in different databases that include:
MySQL, MongoDB, PostgreSQL, or Big Data platforms such as Hadoop or Spark. In this way,
subscriptions are made to OCB entities, which notify the system of a change to store the data.
3.
Intelligence Data Advanced Solution (IDAS):This GE acts as a language interpreter between the
different communication protocols used in IoT to the NGSI standard. The communication
protocols available are LightweightM2M (LWM2M) over Constrained Application Protocol
(CoaP), JavaScript Object Notation (JSON), or UltraLight over Hypertext Transfer Protocol
(HTTP)/Message Queue Telemetry Transport protocol (MQTT), or Object Linking and Embedding
for Process Control-Uniﬁed Architecture (OPC-UA).
4.
Wilma: It is in charge of guaranteeing the security of the system since it provides functions to act
as a proxy within Open authorization Authentication schemes (OAuth2).
5.
Perseus: This GE deﬁnes a set of rules in OCB, which makes a notiﬁcation to the system or end
user by means of Short Message Service (SMS), emails, or HTTP requests.
3.2. MPC Technique
MPC is one of the most general ways of formulating a control problem. This methodology is
not an explicit control technique, but rather, it involves a family of control methods based on the
use of a model of the system to obtain the control signals by minimizing a given cost function [34].
The methodology can be explained according to Figure 1 and the points below:
1.
The outputs of the process are predicted at each sampling time t along a given prediction horizon
N, by using a model of the system. The predicted outputs, denoted by ˆx(t + j|t) for j = 1, . . . , N,
depend on past outputs, inputs, and disturbances and on the value of future control actions
u(t + j − 1|t) for j = 1, . . . , N. Note that the notation (t + j|t) is related to the predicted value of a
variable at the instant time t + j, calculated with the information available at instant t.
2.
The set of future control actions is calculated by minimizing a determined cost function.
3.
The control signal u(t|t) is sent to the process while the rest of the control actions are rejected
because at the next sampling time, ˆx(t + 1) will be known, allowing repeating the ﬁrst step with
the updated information. This methodology is known as the receding horizon concept.
Sensors 2020, 20, 596
6 of 21
Figure 1. MPC strategy.
It should be noted that this methodology is especially suitable for being applied in the IoT
platform as it allows developing an easy control law with very limited knowledge and information of
the different agents composing the distributed water network. The MPC strategy only requires the
model of the system at hand, which is intrinsic controller information, and the required information to
execute it for the calculation of the optimal control signals [34].
3.3. IoT-Architecture
The proposed architecture for the IoT platform can be described as a pyramidal diagram as shown
in Figure 2. As can be seen, this architecture is divided into three layers that are independent of each
other, allowing adding or removing services without affecting the operation of the previous layer. It is
based on a back end architecture, front end, and context generators.
This architecture is deﬁned as a cloud architecture that encompasses storage functionalities, a
platform as a service, and connectivity. This kind of architecture allows the user to detach speciﬁc
software or custom developments to integrate it with the system. The objective is to be able to perform
services and microservices between different components of the cloud architecture. It is divided into
two large back end and front end sections, which are in turn interconnected through virtual networks
or the Internet. There are other parts of cloud architectures that are used, such as middleware, among
other resources. The architecture can be explained according to the following points:
•
Layer 0, context producers in Figure 2: IoT systems need devices that provide the data needed
for ecosystem management. The IoT consists of a physical device or a network of physical
devices capable of exchanging data, informing the environment to which they belong. Each
device consists of an integrated microcontroller and software that can act as a sensor or actuator.
The sensors are in charge of sending information about the state of certain elements available
in their environment, and the actuators are in charge of carrying out actions that are directly
interconnected with the data provided by the sensors. Each device is uniquely identiﬁed through
the built-in computer system, but can also be identiﬁed as belonging to an existing Internet
infrastructure or device network. As already mentioned, FIWARE is a system based on managing
context information. The term context, applied to an intelligent Internet solution of things, is
associated with the set of related elements capable of reporting the state in which the system is.
Each IoT element will be represented as a unique entity within the context. IoT devices can range
from simple to complex devices such as temperature, humidity, or radiation sensors or relays as
actuators to launch orders.
•
Layer 1, back end in Figure 2: It is the data access layer also known as the logical part of an
application. It is located facing the server and is responsible for managing all services related
to the data. In the back end, all the system tasks are performed, such as numerical calculations,
Sensors 2020, 20, 596
7 of 21
security layer management, data access, REST services, and databases, among others. The main
objective and beneﬁt of having a back end decoupled from an application or simple architecture is
the possibility of making different developments without affecting the functionality by improving
the security of the system, the possibility of rescaling the service depending on the needs of
the client, generating REST services allowing the back end information to interact with any
client or service. In this work, the back end is formed by seven services, each independent
of the others, but at the same time, forming a functional architecture. These services range
from interpreters of communication protocols between sensors and the system itself, elements
responsible for information management, databases, REST services, and processes responsible for
process control.
•
Layer 2, front end in Figure 2: This is the layer linked to the client, and therefore, it is in charge of
the visualization of all the data. It is composed by a set of technologies that form the structure and
design of the application. The most used programming languages for the development of this
layer are JavaScript and PHP, as well as languages based on design and layout, such as HTML
and CSS.
Figure 2. IoT platform as a pyramidal diagram.
3.4. Case Study in Almería
In order to evidence the results that can be achieved with the application of the proposed platform,
a case study based on three real facilities located in Almería was used. The schematic diagram of
the case study is shown in Figure 3, and it was used to represent an agroindustrial district composed
by several consumers agents (i.e., three greenhouses and an ofﬁce building) and two water sources
(i.e., a solar desalination plant and the water public utility network). Note that this small scale
agroindustrial district was chosen to be representative of an industrial scale one and allow visualizing
the results in a simple way. The plants included in the district are described in the following subsections.
It should be remarked that in the following subsections, the real location of the plants is established,
but in real cases of application, the desalination plant should be located on the coast and the building
near the greenhouses.
Sensors 2020, 20, 596
8 of 21
Figure 3. Layout of the case study.
3.4.1. Solar Desalination Plant
The solar desalination plant used as a reference in the case study was based on the Solar Membrane
Distillation (SMD) facility at the Plataforma Solar de Almería (PSA, www.psa.es), in southeast Spain.
A real image of the plant is included in Figure 3. This facility was fully described in [35], and it is
comprised of a solar ﬁeld, which is responsible for providing the thermal power required by the
Membrane Distillation (MD) procedure, several MD modules, and a heat exchanger connecting both
systems. The plant is totally controlled, monitoring the main variables of the distillation procedure
as pressure, temperature, and ﬂow rate. It should be commented that for the present work, it was
assumed that all the control and measurement systems were based on the IoT paradigm, and they
were able to receive and send information directly from or to the cloud (see Figure 3).
As stated in [10], an industrial scale MD plant (as the one used in this work) must be composed of
an array of MD modules since the production of current commercial MD modules is still relatively low,
around 30 L/h in optimal operating conditions. Thus, each singular MD module was connected to
the array composing the overall desalination unit, as was presented in [36], so that each MD module
could be turned on/off depending on the state of the valves, which allowed us to adjust the distillate
production to the water demand, thus obtaining economical savings in the operation of the feed water
pump. In particular, the MD module used in this work was the Aquastill one, which was totally
described in [10]. As reported in that work, the module had a limited operating range in terms of
temperature and feed ﬂow rate. The temperature at the inlet of the evaporator channel of the MD
module could vary between 60 and 80 ◦C, whereas the ﬂow rate between 400 and 600 L/h.
The feed solution enters though the condenser channel of the MD module, where it is preheated
with the latent heat that crosses the membrane. Then, it is driven to the heat exchanger where the feed
solution is heated with the ﬂuid coming from the solar ﬁeld. At last, the heated solution is ﬂowed to the
evaporator channel of the MD module, where the volatile molecules of the solution are evaporated and
pass through the membrane, whereas the non-volatile ones are rejected in the form of brine. It should
Sensors 2020, 20, 596
9 of 21
be remarked that in this work, it was assumed that the feed solution was water coming from the
Mediterranean sea at 35 g/L (mean salinity).
For the application of the MPC technique, a model of the desalination unit is required in order to
predict its total distillate production (DT). As was presented in [10], the Aquastill module could be
easily modeled by means of a polynomial equation based on empirical data. In this work, the same
model was used, but it was modiﬁed by introducing binary variables (δi with i = 1, . . . , NMD where
NMD is the number of MD modules in the array ﬁxed at 30) related to the position of the valves of each
MD module i, assuming a value of zero when the MD module is turned off and one otherwise. In this
way, the total distillate production of the overall desalination unit can be calculated as:
DT(t) =
NMD
∑
i=1
(3.24 + 0.072 · Tcs,out(t) − 0.4896 · Tf eed(t)) · (1 − δi(t)) + (−0.024 · F(t)
+ 0.0096 · Tcs,out(t) · F(t)) · δi(t)

,
(1)
where all the terms of the equation are in L/h and all the variables are presented in Appendix A.
It should be noted that, when an MD module is turned on, it is operated at its maximum operating
range in terms of feed ﬂow rate (i.e., F(t) = 600 L/h), which is its optimal operating point [10]. In this
way, all the variables in the previous equation are constant and known, except δi with i = 1, . . . , NMD,
which are computed by means of the MPC technique.
Moreover, as the MPC technique is aimed at reducing costs, the operating cost associated with
the operation of the feed water pump must be estimated. For this aim, the electric power consumption
of the feed water pump was calculated making use of the characteristic pump curve supplied by the
manufacturer. The same pump as the one in [37] was used, whose characteristic curve is given by:
Pf (t) = 22.72 · c1 ·
NMD
∑
i=1

F(t) · δi(t)
 + 39.54,
(2)
where c1 is a conversion factor to transform L/h into m3/s so that all the terms of the equation are in
kW. Note that the summation term was used to take into account all the MD modules as the total feed
water ﬂow rate was equal to the sum of feed ﬂow rate of all the modules.
It should be remarked that this model must be executed in the cloud, integrated in the MPC
strategy of the IoT architecture. For this reason, it is important to note that the information exchanged
between the plant and the cloud was minimum because of the way in which the models were posed.
The plant had to send information only about the temperature at the outlet of the heat exchanger for
the cold side (Tcs,out) and the feed temperature (Tf eed), and it had to receive information only about δi
variables, with i = 1, . . . , NMD. Moreover, as the MD modules in the array were identical, the value
of these variables could be given only using an integer variable (NMD) that contains the number of
modules turned on at each sampling time, that is:
NMD =
NMD
∑
i=1
δi.
(3)
Notice also that the desalination facility was connected to a storage tank. The use of this device in this
kind of systems is natural, as water is a resource that can be stored. In this way, the storage device acted as
an integrator system, helping to smooth the water demands, and for this reason, its level (L) must also be
sent to the IoT platform. This tank could be directly used or connected to the water distribution network.
3.4.2. Greenhouses
The greenhouse environments included in the case study were based on the pilot greenhouse
located at Experimental Station of the Cajamar Foundation (also located in southeast Spain, 40 km
Sensors 2020, 20, 596
10 of 21
from the PSA), and real images of this facility can be seen in Figure 3. This pilot plant is formed
by a multi-span “Parral-type” greenhouse with E-W orientation.
The total surface area of the
facility is 821 m2, among which 616 m2 are effective cultivation area. The cover of the greenhouse is
polyethylene, and it includes an automatic ventilation system with side windows on the south and
north walls. In addition, the greenhouse is equipped with a diesel aerothermal system, a biomass
fueled heating system, a humidiﬁcation/dehumidiﬁcation system, and LED lights. The crop grows
in rows with N-S-orientation, inside coconut coir bags, with three droppers and six plants each.
The irrigation is performed by means of a demand tray system, which applies the irrigation to the
crop periodically throughout each day. In [38], a more detailed description and explanation of the
greenhouse environment can be found.
As in the desalination plant, the greenhouse was totally controlled and monitored, measuring
variables such as solar irradiance, relative humidity, air temperature, CO2, wind direction and speed,
and soil and cover temperature. For the purpose of this work, the greenhouses had to send information
about their water requirements, which could be estimated by using well known models already
presented in literature and based on the aforementioned measured variables, as was done in [10].
Thus, the IoT platform received information about the water needs of Greenhouses 1, 2, and 3 (DGH1,
DGH2, DGH3, respectively), and based on this information and according to the water production of
the desalination plant (DT) and the level of the intermediate tank (L), it had to decide the amount of
water from the desalination plant and the public utility network used to cover the requirements of each
greenhouse. Therefore, the IoT platform had to send the variables PN2GH1 and DP2GH1, PN2GH2
and DP2GH2, and PN2GH3 and DP2GH3, which were the water coming from the public utility
network and the water coming from the desalination plant for Greenhouses 1, 2, and 3, respectively.
Note that for the simulations, it was assumed that the greenhouses had a tomato crop in a state of
growth, with a Leaf Area Index (LAI) of 5.5 and in full production.
3.4.3. Ofﬁce Building
The ofﬁce building incorporated in the case study was based on the Centro de Investigación
de la Energía Solar (CIESOL) building (www.ciesol.es) located at the University of Almería campus,
also in south east Spain, 20 km away from PSA. This building had a total surface area of 1071.91 m2
distributed into two ﬂoors. In addition, as in the other facilities composing the case study, CIESOL had
a net of sensors to monitor the main variables affecting the building such as temperature, electricity,
and water consumption. More details about the building can be found elsewhere [39].
For the management of the water network of the case study, the building had to send its water
requirements (DOB) to the IoT platform, and as happened with the greenhouses, the IoT platform had
to send to the building the amount of water coming from the desalination plant (DP2OB) and the
public utility network (PN2OB).
3.5. Application of the IoT Platform to the Case Study
The architecture proposed in this paper for the management of the agroindustrial district
presented above in terms of water is shown in Figure 4. As mentioned in Section 3.3, it was divided into
three layers: context producers, back end, and front end. It is important to remark that the proposed
architecture was based on that already developed for the IoF2020UC4.2 Vegetables project [40,41],
with the particularity of applying control techniques, among other data extraction functionalities
adapted to this system.
Sensors 2020, 20, 596
11 of 21
Figure 4. Architecture of the IoT platform.
3.5.1. Layer 0 Context Producers
All the devices and elements in charge of generating context information were available in this
layer. Different kind of actuators and sensors were available in each plant forming the agroindustrial
district. These sensors were connected to different commercial IoT stations or data acquisition systems.
There were six types of context information production scenarios distributed in different parts of the
proposed scenario: a solar desalination plant, three Parral-type greenhouses, an ofﬁce building, and
a water storage device. These facilities sent the measurements collected by the sensors to the cloud
through the MQTT or HTTP requests, depending on the data extraction format. MQTT is one of the
most extended communication protocols used in the IoT paradigm due to its lightness and simplicity,
which are mainly produced by the power limitations in the devices and the bandwidth. It is based on
the Transmission Control Protocol/Internet Protocol (TCP/IP) protocol, which reuses already open
connections, unlike the HTTP 1.0 protocol, which makes new connections. Its operation is based on
push messaging as editor/subscriber and themes. In addition, it has a central broker that manages the
registration of the client’s connections, allowing subscriptions to different topics. On the one hand,
MQTT will be used for sending smart sensors to OCB; on the other hand, HTTP will be used for
sending data from the acquisition systems to OCB.
3.5.2. Layer 1 Backend
This section describes the layer in charge of managing all the operations of the IoT system. Each
of the services that make up this data layer was independent of the others, thus allowing updates and
developments without affecting the performance and stability of the system. It was formed by a set of
services that interacted with each other to form the ecosystem based on FIWARE:
•
Extract context information: This service is responsible for extracting, transforming, and sending
the data to the IoT system. There are two services calledIDAS (represented by the block agent
in Figure 4) and Extract, Transform, and Load (ETL), responsible for translating the information
that comes from the sensors to the NGSI standard (see Figure 4). The objective of having two
interpretation systems is to provide a solution that is as complete as possible. The context
information can come from three data sources: commercial systems with their own REST services
(represented in the form of a cloud API in Figure 4 based on General Packet Radio Service (GPRS)
communication), data acquisition systems connected to a PC, and smart sensors prepared to send
these data to the cloud. Commercial stations are available from the following manufacturers:
Sensors 2020, 20, 596
12 of 21
Hortisys of the Hispatec model, iMetos of the Pessl model, iMetos ECO D3, and the Hops model.
The ﬁrst service called ETL (see Figure 4) is responsible for extracting data from REST services of
commercial stations or data acquisition systems connected to a PC, making the transformation
to the NGSI standard, and then, sending it directly to OCB. The second service called IDAS
(represented by the block agent in Figure 4) is an enabler developed by FIWARE, which comes
into use in the case of having intelligent sensors sending data directly to OCB, performing the
function of interpreting the MQTT communication protocol that these sensors use for the FIWARE
NGSI standard.
•
OCB: It is the core of the architecture (see Figure 4), and it is tasked with handling the
context information. It acts as an intermediary between producers (publishers) and consumers
(subscribers). It is based on the NGSI speciﬁcation deﬁned by OMA. The data model is based on
entities, attributes, and metadata. There are six entities for each of the context producers: solar
desalination plant, water storage tank, Greenhouse 1, Greenhouse 2, Greenhouse 3, and ﬁnally,
ofﬁce building. Table 1 shows exclusively each of the entities with their respective attributes
and metadata necessary to perform the MPC technique. In addition, each of these entities has a
set of sensors and actuators, sending the information to OCB. In Table 1, the internal attributes
can be seen of the variables generated by these entities with the needs of the system, while the
controller external attributes column includes those variables generated when applying the MPC
techniques (each of these variables are explained in the Section 3.4). The objective of including
the controller external attributes within the entity is to be able to link the system actuator with
this attribute, allowing the action to be performed directly. This fact creates a new entity MPC
controller. To differentiate between different types of stations in the same entity, FIWARE-Service
and FIWARE-ServicePathare used, permitting hierarchical scopes in the same entity. The ﬁrst
element deﬁnes the name of the plant, whereas the second one, the name of the station or set
of sensors. Each one of the sensors is detailed independently with its name and value in the
attributes. Within these attributes, metadata are available, giving the possibility of creating ﬁelds
such as the date when reading data and the common name, among others.
•
REST API services: There are two types of services, one in charge of carrying out the persistence
of the data and the other that manages the requests on behalf of the client. These two services
are encapsulated within the REST API module (see Figure 4). As mentioned above, OCB allows
entities to subscribe, and this is because the ﬁrst REST service carries out a series of subscriptions
to each of the available entities. When one of these entities undergoes a change in any of its
attributes, this will be notiﬁed to all the services subscribed to the entity. An HTTP request will be
sent to the persistence service, which will check if the data and date already exist in the system
before saving the measurement. The second service offers a REST API, which is exposed to the
end user through an application. The end user will make the necessary requests to the system,
and it will return the requested response in JSON format.
•
Cron process: This service is a Unix cron process (see Figure 4) designed to run periodically every
15 min. Its objective is to retrieve the data from the previous REST service in charge of obtaining
the database information and send it to the controller to perform the MPC control technique.
Once the controller ﬁnishes the execution, this same service sends the parameters of Table 1’s
controller external attributes column to its corresponding entity, updating the OCB information
and thus the actuator with the new execution parameters. When there is a subscription to each
entity, it notiﬁes again a change to the REST service in charge of persisting the information and
performs the action of saving in the database.
•
MPC controller: This is the service in charge of carrying out the optimal management of the water
resources (see Section 3.4). This service (see Figure 4) is controlled by a cron process and allows
consulting the needs of each system through the REST service and inserting the new instructions
in the control column of the external attributes of each entity (see Table 1). All the details about
the implementation of the MPC controller are presented in Appendix B.
Sensors 2020, 20, 596
13 of 21
•
Database: This architecture is supported by a non-relational database. It is based on MongoDB
(see Figure 4), which allows managing a large volume of data, easy scalability, and a dynamic
data model. The latter is essential in this architecture, as it allows adding or removing sensors
from each entity without the risk of affecting the operation of the system.
Table 1. Entities of OCB FIWARE required for MPC control.
Entities
Internal Attributes
Controller External Attributes
Metadata
Solar desalination plant
Tcs,out, Tf eed
NMD
Common name, Unix date
Water storage tank
L
-
Common name, Unix date
Greenhouse 1
DGH1
PN2GH1, DP2GH1
Common name, Unix date
Greenhouse 2
DGH2
PN2GH2, DP2GH2
Common name, Unix date
Greenhouse 3
DGH3
PN2GH3, DP2GH3
Common name, Unix date
Ofﬁce Building
DOB
PN2OB,DP2OB
Common name, Unix date
3.5.3. Layer 2 Front End
This is the data visualization layer. The user makes the necessary requests to the system from this
service. The objective of separating the front end as an independent service is to give versatility to the
system of creating a web, desktop, or hybrid application. Any changes made to the application do not
affect the operation of the IoT system.
4. Results and Discussion
4.1. Simulation Results
To evidence the results that could be attained with the application of the designed IoT platform in
an agroindustrial district, a simulation was carried out in MATLAB 2018b with the YALMIP toolbox.
To perform the simulation, real Meteorological data from PSA and from Experimental Station of
Cajamar Foundation on the day 20 July 2017 were used. The models of the desalination plant and the
greenhouses presented in [37,38] respectively were simulated with the actual meteorological data to
obtain Tcs,out and DGH1 and DGH2 and DGH3. Moreover, in order to add difﬁculty to the management
problem, different sizes were used for simulating the greenhouses, so that the size of Greenhouses
1 and 2 was ﬁxed at 1 ha, whereas that of Greenhouse 3 at 0.5 ha. Besides, the irradiance data for
Greenhouse 3 were shifted forward 15 min in the simulations. Conversely, real water consumption
data of the aforementioned day from CIESOL building were used for DOB. These data were also scaled
considering a building with a surface area of 400 m2. Notice that to test the proposed strategy, two
days were simulated duplicating the data, but augmenting the irradiance proﬁles used for simulating
Greenhouses 2 and 3 in the second day in order to augment their water demand.
The conﬁguration parameters of the MPC controller were set as: (i) sampling time (Ts) ﬁxed at
15 min, which was chosen taking into account the dynamics of the ofﬁce building, desalination, and
greenhouses, and (ii) prediction horizon (N) ﬁxed at six. Note that the prediction horizon must be
selected large enough in order to catch the process transients. However, it should be taken into account
that as the prediction horizon (N) increases, so does the amount of decision variables included in the
optimization problem and, therefore, the computational time. For this reason, the prediction horizon
was chosen considering a tradeoff between these two issues and after exhaustive simulations.
The results obtained from the simulations are presented in Figure 5. It is worth noting that the
costs related to the water coming from the public utility network are higher than those related to the
operation of the feed pump of the desalination plant, even when all the MD modules are in operation.
Therefore, the optimal management consists of feeding the consumer agents by the desalination plant
whenever possible. In this way, at the end of the day, the storage tank level must be zero or very close
to this value. Consequently, the initial state of the storage tank level was set to 50 L (see Figure 5(1)).
Sensors 2020, 20, 596
14 of 21
0
20
40
60
80
100
120
140
160
180
200
0
600
1200
Flow rate [L/h]
(1)
0
3500
7000
Tank level
[L]
 DT
Water Consumption
 L
0
20
40
60
80
100
120
140
160
180
200
0
10
20
30
Number of 
modules
(2)
50
70
90
Temperature
[oC]
 NMD
 Tcs,out
0
20
40
60
80
100
120
140
160
180
200
0
100
200
300
Flow rate 
[L/h]
(3)
 DGH1
 PN2GH1
 DP2GH1
0
20
40
60
80
100
120
140
160
180
200
0
250
500
Flow rate 
[L/h]
(4)
 DGH2
 PN2GH2
 DP2GH2
0
20
40
60
80
100
120
140
160
180
200
0
100
200
Flow rate [L/h]
(5)
 DGH3
 PN2GH3
 DP2GH3
0
20
40
60
80
100
120
140
160
180
200
Samples
0
25
50
Flow rate [L/h]
(6)
 DOB
 PN2OB
 DP2GOB
Figure 5. Simulation results. All the variables are according to Appendix A.
In this way, around Sample 34, the ofﬁce building started demanding water (see Figure 5(6)), and
in Sample 35, also Greenhouses 1 and 2 (see Figure 5(3),(4)). Nevertheless, as the temperature Tcs,out
was below T∗ at that moment (see Figure 5(2)), the desalination plant could not still produce fresh
water, and the water requirements were met by the remaining water in the tank and water coming
from the water utility public network. At Sample 37, the temperature Tcs,out was above T∗, and the
desalination plant was turned on by the MPC controller (see Figure 5(2)). For the rest of the operation
on this day, the greenhouse water necessities and the ones of the ofﬁce building were satisﬁed by the
desalination plant. The beneﬁt of using an MPC controller was especially shown at the end of the day.
In that moment, and before Tcs,out reaching T∗, the MPC controller increased the amount of modules
turned on (see Sample 70 in Figure 5(2)) trying to augment the water stored in the tank, thus avoiding
the use of water coming from the public utility network when all the MD modules were turned off.
In the second operating day, the beginning of the operation was similar to that from the previous
day, but on this occasion, there was no water left in the storage tank, so that only water coming from
the public utility network was used to fulﬁl the water needs. Moreover, as shown in Figure 5(3),(4),
the water necessities of Greenhouses 2 and 3 were higher than in the ﬁrst operating day. This fact
caused the MPC controller to turn on all the MD modules included in the array (see Figure 5(2)).
However, the water production of the desalination facility was not enough to fulﬁl the water needs,
and for this reason, the water production was complemented with water coming from the public utility
network, as shown in Figure 5(3)–(6). Finally, at the end of the day, the same fact happened as in the
ﬁrst day: the water level of the tank was increased to meet the water needs without using the public
utility network when the desalination plant was turned off.
Sensors 2020, 20, 596
15 of 21
4.2. Comparative Operating Cost Analysis
To illustrate the beneﬁts achieved in terms of operating costs with the application of the proposed
IoT platform in real agroindustrial districts, the results shown in the previous subsection were
compared to those obtained using a manual operation. The manual operation consisted of turning on
all the MD modules as long as Tcs,out was higher than T∗, which was not optimal from the point of
view of the operation of the desalination plant, as it was producing more water than necessary and,
therefore, consuming more electricity (increasing costs). The results are presented in Table 2.
Table 2. Comparative operating cost results. TPNCis the total operating cost associated to the water
coming from the public utility network; TDPCis the total operating cost of the desalination facility;
TC is the Total Cost; and SC is the Speciﬁc Cost, that is the cost per unit of water demanded in the
agroindustrial district.
Management Method
TPNC (e)
TDPC (e)
TC (e)
SC (e/m3)
IoT platform
2.60
3.01
5.61
0.44
Manual
18.70
0.20
18.90
1.51
As can be seen, the economic savings were considerable. The costs associated with the operation
of the desalination facility were reduced by 87%, whereas the total costs by 75% with the use of the
proposed method. This was directly reﬂected in the speciﬁc cost of the water demanded, as it can be
seen in Table 2 how with the application of the proposed method, the cost per unit of water demanded
was 0.44 e/m3, whereas by using a non-optimal manual procedure, the cost was 1.51 e/m3.
5. Conclusions
This work addressed the development of an IoT based water management architecture to be
applied in agroindustrial districts including desalination plants, connection to the public utility
network, and several consumer agents. The core of the platform was based on the use of FIWARE and
an MPC controller that reﬂected the operational strategy in real time. Simulation tests using a case
study based on three real facilities located in Almería were performed. The obtained results allowed
us to draw the following conclusions:
1.
The use of enabling technologies such as IoT on agroindustrial districts could be an effective tool
to carry out the optimal management of the heterogeneous resources required by the elements
that make up these environments.
2.
In particular, the application of the proposed method to the case study demonstrated how an
optimal management of the water resources could be done, adapting the water production of the
desalination plant to the water demand of the consumer agents and minimizing the use of water
coming from the public utility network, thus making a proper use of desalination facilities.
3.
The comparative cost analysis performed with a manual operation showed how around 75%
of the operational cost could be saved. In this way, the cost per unit of water demanded in the
agroindustrial district was reduced with the application of the proposed strategy from 1.51 e/m3
(cost of the manual operation) to 0.44 e/m3. This could be very relevant to maintain the economic
sustainability of the agricultural system of Almería.
In relation to future work, the speed of computing and latency when replicating the control
system on edge computing versus the current cloud computing could be compared. In this way, it
would be possible to detect which system performs better control and what the response times would
be. Furthermore, it would be interesting to carry out an economic viability analysis taking into account
the different IoT systems, transport infrastructures, and desalination costs.
Sensors 2020, 20, 596
16 of 21
Author Contributions: J.D.G. and M.M. carried out most of the work presented in this paper. J.D.G. contributed
to the paper in the sections related to the control system and M.M. to developing the IoT architecture of the system.
F.R. contributed with the greenhouse knowledge and shared the greenhouse experimental data. L.R. contributed
with the solar desalination plant knowledge and shared the experimental data. M.B. contributed to the control
strategy. All of the authors participated in the manuscript revision. All authors read and agreed to the published
version of the manuscript.
Funding: This work was funded by the IoF2020 Horizon 2020 Framework Programme of the European Union
(Grant Agreement No. 731884) and by the Spanish R+D+i Plan Project DPI2017-85007-R of the Ministry of
Economy, Industry and Competitiveness and ERDF funds. Juan D. Gil is supported by an FPIFellowship from the
University of Almería.
Acknowledgments: The authors would to thank to Plataforma Solar de Almería, Experimental Station of the
Cajamar foundation, and CIESOL Center for facilitating real data of their facilities.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
Abbreviations
The following abbreviations are used in this manuscript:
CIESOL
Centro de Investigación de la Energía Solar
CoAP
Constrained Application Protocol
CHROMAE
Control and Optimal Management of Heterogeneous Resources in Agroindustrial production
districts integrating renewable Energies
ETL
Extract, Transform, and Load
GEs
Generic Enablers
GPRS
General Packet Radio Service
HTTP
Hypertext Transfer Protocol
ICT
Information and Communication Technology
IDAS
Intelligence Data Advanced Solution
IoT
Internet of Things
JSON
JavaScript Object Notation
LAI
Leaf Area Index
LWM2M
LightweightM2M
MD
Membrane Distillation
MPC
Model Predictive Control
MQTT
Message Queue Telemetry Transport
NGSI
Next Generation Services Interface
OAuth2
Open Authorization
OCB
Orion Context Broker
OPC-UA
Object Linking and Embedding for Process Control-Uniﬁed Architecture
OMA
Open Mobile Alliance
PA
Precision Agriculture
PSA
Plataforma Solar de Almería
SMS
Short Message Service
TCP/IP
Transmission Control Protocol/Internet Protocol
Sensors 2020, 20, 596
17 of 21
Appendix A
Nomenclature
Variable
Description
Value and Units
c1
Conversion factor to transform L/h into m3/s
2.7·10−7 m3·h/(L·s)
c2
Conversion factor to transform min into h
0.016 h/min
c3
Conversion factor to transform L/h into m3/min
1.63·10−5 m3· h/(L·min)
CPN
Total cost associated to the operation of the feed water pump
e
of the desalination facility
CPN
Total cost of the water coming from the public utility network
e
DT
Total distillate production of the desalination plant
L/h
DGH1
Water demand of Greenhouse 1
L/h
DGH2
Water demand of Greenhouse 2
L/h
DGH3
Water demand of Greenhouse 3
L/h
DOB
Water demand of the ofﬁce building
L/h
DP2GH1
Water coming from the desalination plant to Greenhouse 1
L/h
DP2GH2
Water coming from the desalination plant to Greenhouse 2
L/h
DP2GH3
Water coming from the desalination plant to Greenhouse 3
L/h
DP2OB
Water coming from the desalination plant to the ofﬁce building
L/h
Ep
Electricity price
0.14 e/kWh
F
Feed ﬂow rate
L/h
L
Water level of the storage tank
L
Lmin
Minimum water level of the storage tank
L
Lmax
Maximum water level of the storage tank
L
NMD
Number of MD modules in the desalination unit
30
m
Constant 1 used in the MPC problem
−1000
M
Constant 2 used in the MPC problem
1000
NMD
Integer variable containing the number of MD modules
-
turned on at each sampling time
Pf
Power consumption of the feed water pump of
kW
the desalination plant
PN2GH1
Water coming from the public utility network to Greenhouse 1
L/h
PN2GH2
Water coming from the public utility network to Greenhouse 2
L/h
PN2GH3
Water coming from the public utility network to Greenhouse 3
L/h
PN2OB
Water coming from the public utility network to the ofﬁce building
L/h
Tcs,out
Temperature at the outlet of the heat exchanger, cold side
oC
Tf eed
Feed water temperature
oC
Ts
Sampling time
15 min
T∗
Minimum temperature required to operate the desalination plant
60 oC
Wp
Price of water coming from the public utility network
0.50 e/kWh
βi
Auxiliary binary variable used in the MPC problem related to the
0–1
valve position of each MD module i
δi
Valve position of each MD module i
0–1
γ
Auxiliary binary variable used in the MPC problem related to the
0–1
operational constraints
Appendix B.
MPC Control Formulation
The MPC control problem to be solved at each sampling time can be posed as a Mixed Integer
Linear Programming (MILP) optimization problem as follows:
min J = ∑
j=1
N ˆCPN(t + j|t) + ˆCDP(t + j|t)

,
(A1)
Sensors 2020, 20, 596
18 of 21
subjected to ∀j = 1, . . . , N:
ˆDT(t + j|t) =
N
∑ MDi=1
(3.24 + 0.072 · ˆTcs,out(t + j|t) − 0.4896 · ˆTfeed(t + j|t)) · (1 − βi(t + j − 1|t))
+ (−0.024 · F(t + j − 1|t) + 0.0096 · ˆTcs,out(t + j|t) · F(t + j − 1|t)) · βi(t + j − 1|t)

,
(A2)
βi(t + j − 1|t) ∈ {0, 1}, ∀i = 1, . . . , NMD,
(A3)
− m · γ(t + j − 1|t) ≤ ( ˆTcs,out(t + j|t) − T∗) − m,
(A4)
− M · γ(t + j − 1|t) ≤ −( ˆTcs,out(t + j|t) − T∗),
(A5)
γ(t + j − 1|t) ∈ {0, 1},
(A6)
− βi(t + j − 1|t) + δi(t + j − 1|t) ≤ 0, ∀i = 1, . . . , NMD,
(A7)
− γ(t + j − 1|t) + δi(t + j − 1|t) ≤ 0, ∀i = 1, . . . , NMD,
(A8)
βi(t + j − 1|t) + γ(t + j − 1|t) − δi(t + j − 1|t) ≤ 1, ∀i = 1, . . . , NMD,
(A9)
δi(t + j − 1|t) ∈ {0, 1}, ∀i = 1, . . . , NMD,
(A10)
ˆL(t + j|t) = ˆL(t + j − 1|t) + c2 · Ts ·
 ˆDT(t + j|t) −
ˆ
DP2GH1(t + j|t) −
ˆ
DP2GH2(t + j|t)
−
ˆ
DP2GH3(t + j|t) −
ˆ
DP2OB(t + j|t)

,
(A11)
Lmin ≤ ˆL(t + j|t) ≤ Lmax,
(A12)
ˆDGH1(t + j|t) =
ˆ
DP2GH1(t + j|t) +
ˆ
PN2GH1(t + j|t),
(A13)
ˆDGH2(t + j|t) =
ˆ
DP2GH2(t + j|t) +
ˆ
PN2GH2(t + j|t),
(A14)
ˆDGH3(t + j|t) =
ˆ
DP2GH3(t + j|t) +
ˆ
PN2GH3(t + j|t),
(A15)
ˆDOB(t + j|t) =
ˆ
DP2GOB(t + j|t) +
ˆ
PN2GOB(t + j|t),
(A16)
ˆCDP(t + j|t) = (22.72 · c1 ·
NMD
∑
i=1

F(t + j − 1|t) · δi(t + j − 1|t)
 + 39.54) · Ts · c2 · Ep,
(A17)
ˆCPN(t + j|t) = (
ˆ
PN2GH1(t + j|t) +
ˆ
PN2GH2(t + j|t) +
ˆ
PN2GH3(t + j|t)
+
ˆ
PN2GOB(t + j|t)) · c3 · Ts · Wp.
(A18)
In this formulation, the objective function (Equation (A1)) aims to reduce the operational costs
of the agroindustrial district in terms of water, considering the cost of the water coming from the
public utility network (CPN) and that of the feed water pump of the desalination plant (CDP). Note
that other types of costs in the desalination plant, as the ones of the solar ﬁeld feeding it, have
not been taken into account as they were already optimized in the previous published work [37].
The optimization problem is subjected to a set of process and operational constraints, which are
presented in Equations (A2)–(A18).
Firstly, the set of constraints in Equations (A2)–(A10) is related to the desalination plant. In this set,
the constraints in Equations (A2) and (A3) are used to compute the distillate production ( ˆ
DT(t + j|t))
along the prediction horizon. Note that the model presented in Equation (1) is employed, but an
auxiliary binary variable βi(t + j − 1|t) with i = 1, . . . , NMD for taking into account the MD modules
states (turned on/off) is used instead of the actual variable δi(t + j − 1|t) with i = 1, . . . , NMD. This is
because the modules can be only turned on if the temperature required to operate them (T∗=60 oC) is
reached. Thus, this statement is included in the optimization problem using the set of constraints in
Equations (A4)–(A6), so that another auxiliary binary variable γ(t + j − 1|t) takes the value of one if the
aforementioned statement is true and zero otherwise. Finally, the value of the actual variable related
to the valve position of each MD module (δi(t + j − 1|t) with i = 1, . . . , NMD) is computed at each
Sensors 2020, 20, 596
19 of 21
instant time as δi(t + j − 1|t) = βi(t + j − 1|t) · γi(t + j − 1|t) ∀i = 1, . . . , NMD. This multiplication is
formulated in the problem by means of a set of linear constraints (see Equations (A7)–(A10)).
Secondly, the constraints in Equations (A11) and (A12) are related to the tank level. The ﬁrst one
is used to compute the level (ˆL(t + j|t)) along the prediction horizon, which is calculated based on
the level of the previous instant time (ˆL(t + j − 1|t)), the water that is received from the desalination
plant ( ˆ
DT(t + j|t)), and the water that is sent to to the ofﬁce building and Greenhouses 1, 2, and 3
(
ˆ
DP2OB(t + j|t),
ˆ
DP2GH1(t + j|t),
ˆ
DP2GH2(t + j|t), and
ˆ
DP2GH3(t + j|t), respectively). The second
one deﬁnes the maximum and minimum level of the tank.
Thirdly, the constraints in Equations (A13)–(A16) deﬁne the relationship between producers and
consumer agents, so that the water demanded by each consumer agent must be covered by the sum of
the water that it receives from the desalination plant and from the water public utility network.
Fourthly, the constraints in Equations (A17) and (A18) are used to calculate the cost related to the
operation of the feed water pump of the desalination plant (CDP) and that of the water coming from
the public utility network (CPN) along the prediction horizon.
Once the overall MPC problem is formulated, it should be pointed out that the decision variables
of the optimization problem are δi and βi ∀i = 1, . . . , NMD, γ, DP2GH1, PN2GH1, DP2GH2, PN2GH2,
DP2GH3, PN2GH3, DP2OB, and PN2OB. Conversely, L, Tcs,out, Tf eed, DGH1, DGH2, DGH3, and DOB
are state variables whose values change according to the operational conditions of the desalination
plant and the greenhouses and ofﬁce building, respectively. In the simulations, real data were used for
predicting these variables.
References
1.
De Rafael, G.H.; Fernández-Prados, J.S. Intensive agriculture, marketing and social structure: The case of
South-eastern Spain. Agric. Econ. 2018, 64, 367–377, doi:10.17221/318/2016-AGRICECON. [CrossRef]
2.
Cazcarro, I.; Duarte, R.; Martín-Retortillo, M.; Pinilla, V.; Serrano, A. Water scarcity and agricultural growth
in Spain: From curse to blessing. In Natural Resources and Economic Growth: Learning from History; Routledge:
London, UK, 2015; pp. 339–361.
3.
Aznar-Sánchez, J.A.; Belmonte-Ureña, L.J.; Velasco-Muñoz, J.F.; Valera, D.L. Aquifer sustainability and the
use of desalinated seawater for greenhouse irrigation in the campo de Níjar, southeast Spain. Int. J. Environ.
Res. Public Health 2019, 16, 898.10.3390/ijerph16050898. [CrossRef] [PubMed]
4.
Garcia-Caparros, P.; Contreras, J.I.; Baeza, R.; Segura, M.L.; Lao, M.T. Integral management of irrigation water
in intensive horticultural systems of Almería. Sustainability 2017, 9, 2271.10.3390/su9122271. [CrossRef]
5.
Ocampo-Martinez, C.; Puig, V.; Cembrano, G.; Quevedo, J. Application of predictive control strategies
to the management of complex networks in the urban water cycle.
IEEE Control Syst.
Mag.
2013,
33, 15–41.10.1109/MCS.2012.2225919. [CrossRef]
6.
Pascual,
J.;
Romera,
J.;
Puig,
V.;
Cembrano,
G.;
Creus,
R.;
Minoves,
M.
Operational
predictive optimal control of Barcelona water transport network.
Control Eng.
Pract.
2013,
21, 1020–1034.10.1016/j.conengprac.2013.01.009. [CrossRef]
7.
Lopez Farias, R.; Puig, V.; Rodriguez Rangel, H.; Flores, J. Multi-model prediction for demand forecast in
water distribution networks. Energies 2018, 11, 660.10.3390/en11030660. [CrossRef]
8.
Bhojwani, S.; Topolski, K.; Mukherjee, R.; Sengupta, D.; El-Halwagi, M.M.
Technology review
and data analysis for cost assessment of water treatment systems.
Sci.
Total Environ.
2019,
651, 2749–2761.10.1016/j.scitotenv.2018.09.363. [CrossRef]
9.
Roca, L.; Sánchez-Molina, J.A.; Rodríguez, F.; Bonilla, J.; de la Calle, A.; Berenguel, M. Predictive control
applied to a solar desalination plant connected to a greenhouse with daily variation of irrigation water
demand. Energies 2016, 9, 194.10.3390/en9030194. [CrossRef]
10.
Gil, J.D.; Álvarez, J.; Roca, L.; Sánchez-Molina, J.; Berenguel, M.; Rodríguez, F. Optimal thermal energy
management of a distributed energy system comprising a solar membrane distillation plant and a greenhouse.
Energy Convers. Manag. 2019, 198, 111791.10.1016/j.enconman.2019.111791. [CrossRef]
11.
Lee, S.W.; Sarp, S.; Jeon, D.J.; Kim, J.H.
Smart water grid: The future water management platform.
Desalin. Water Treat. 2015, 55, 339–346.10.1080/19443994.2014.917887. [CrossRef]
Sensors 2020, 20, 596
20 of 21
12.
Bibri, S.E. The IoT for smart sustainable cities of the future: An analytical framework for sensor based big
data applications for environmental sustainability. Sustain. Cities Soc. 2018, 38, 230–253. [CrossRef]
13.
Sodhro, A.H.; Pirbhulal, S.; Luo, Z.; de Albuquerque, V.H.C. Towards an optimal resource management for
IoT based Green and sustainable smart cities. J. Clean. Prod. 2019, 220, 1167–1179. [CrossRef]
14.
Dijkman, R.; Sprenkels, B.; Peeters, T.; Janssen, A. Business models for the Internet of Things. Int. J. Inf.
Manag. 2015, 35, 672–678.10.1016/j.ijinfomgt.2015.07.008. [CrossRef]
15.
Pham, X.; Stack, M.
How data analytics is transforming agriculture.
Bus.
Horizons 2018,
61, 125–133.10.1016/j.bushor.2017.09.011. [CrossRef]
16.
Gill, S.S.; Chana, I.; Buyya, R. IoT based agriculture as a cloud and big data service: The beginning of digital
India. J. Organ. End User Comput. (JOEUC) 2017, 29, 1–23. [CrossRef]
17.
Muñoz, M.; Guzmán, J.; Sánchez, J.; Rodríguez, F.; Torres, M. Greenhouse Models as a Service (GMaaS) for
Simulation and Control. IFAC-PapersOnLine 2019, 52, 190–195.10.1016/j.ifacol.2019.12.520. [CrossRef]
18.
Pawlowski, A.; Guzman, J.; Rodríguez, F.; Berenguel, M.; Sánchez, J.; Dormido, S. Simulation of greenhouse
climate monitoring and control with wireless sensor network and event based Control.
Sensors 2009,
9, 232–252.10.3390/s90100232. [CrossRef]
19.
López-Riquelme, J.A.; Pavón-Pulido, N.; Navarro-Hellín, H.; Soto-Valles, F.; Torres-Sánchez, R. A software
architecture based on FIWARE cloud for Precision Agriculture.
Agric.
Water Manag.
2017,
183, 123–135.10.1016/j.agwat.2016.10.020. [CrossRef]
20.
Adamchuk, V.I.; Hummel, J.W.; Morgan, M.T.; Upadhyaya, S.K. On-the-go soil sensors for precision
agriculture. Comput. Electron. Agric. 2004, 44, 71–91.10.1016/j.compag.2004.03.002. [CrossRef]
21.
Zamora-Izquierdo, M.A.; Santa, J.; Martínez, J.A.; Martínez, V.; Skarmeta, A.F. Smart farming IoT platform
based on edge and cloud computing. Biosyst. Eng. 2019, 177, 4–17.10.1016/j.biosystemseng.2018.10.014.
[CrossRef]
22.
Popovi´c, T.; Latinovi´c, N.; Peši´c, A.; Zeˇcevi´c, Ž.; Krstaji´c, B.; Djukanovi´c, S. Architecting an IoT-enabled
platform for precision agriculture and ecological monitoring: A case study. Comput. Electron. Agric. 2017,
140, 255–265.10.1016/j.compag.2017.06.008. [CrossRef]
23.
Elijah, O.; Rahman, T.A.; Orikumhi, I.; Leow, C.Y.; Hindia, M.N.
An overview of Internet of
Things (IoT) and data analytics in agriculture: Beneﬁts and challenges.
IEEE Internet Things J. 2018,
5, 3758–3773.10.1109/JIOT.2018.2844296. [CrossRef]
24.
Singh, S.; Chana, I.; Buyya, R. Agri-Info: Cloud based autonomic system for delivering agriculture as a
service. Internet Things 2019, 9, 100131. [CrossRef]
25.
Martínez-Álvarez, V.; Martin-Gorriz, B.; Soto-García, M. Seawater desalination for crop irrigation: A review
of current experiences and revealed key issues. Desalination 2016, 381, 58–70.10.1016/j.desal.2015.11.032.
[CrossRef]
26.
Rodriguez, M.A.; Cuenca, L.; Ortiz, A. FIWARE open source standard platform in Smart Farming—A
review. In IFIP Advances in Information and Communication Technology; Springer: Cham, Switzerland, 2018;
Volume 534, pp. 581–589.
27.
Munir, M.S.; Bajwa, I.S.; Naeem, M.A.; Ramzan, B. Design and implementation of an IoT system for smart
energy consumption and smart irrigation in tunnel farming. Energies 2018, 11, 3427. [CrossRef]
28.
Goap, A.; Sharma, D.; Shukla, A.; Krishna, C.R.
An IoT based smart irrigation management
system using Machine Learning and open source technologies.
Comput.
Electron.
Agric.
2018,
155, 41–49.10.1016/j.compag.2018.09.040. [CrossRef]
29.
Kamienski, C.; Soininen, J.P.; Taumberger, M.; Dantas, R.; Toscano, A.; Salmon Cinotti, T.; Filev Maia, R.;
Torre Neto, A. Smart water management platform: Iot based precision irrigation for agriculture. Sensors
2019, 19, 276. [CrossRef]
30.
Becattini, G. Dal Settore Industriale Al Distretto Industriale. Alcune Considerazioni Sull’unità Di Indagine
Dell’economia Industriale; Il Mulino: New York, NY, USA, 1979.
31.
Charu, S.; Kumar, R.; Gupta, N.; Jain, K.; Kumar Jangir, S. Open source solution for cloud computing
platform using OpenStack.
Int. J. Comput. Sci. Mob. Comput. 2014, 3, 89–98.10.13140/2.1.1695.9043.
[CrossRef]
Sensors 2020, 20, 596
21 of 21
32.
Ferreira, D.; Corista, P.; Giao, J.; Ghimire, S.; Sarraipa, J.; Jardim-Goncalves, R. Towards smart agriculture
using FIWARE enablers.
In Proceedings of the IEEE 2017 International Conference on Engineering,
Technology and Innovation: Engineering, Technology and Innovation Management Beyond 2020: New
Challenges, New Approaches, ICE/ITMC 2018, Funchal, Portugal, 27–29 June 2017; Volume 2018,
pp. 1544–1551. 10.1109/ICE.2017.8280066. [CrossRef]
33.
Open Mobile Alliance. NGSI Context Management, OMA-TS-NGSI_Context_Management-V1_0-20120529-A.
Available online: http://www.openmobilealliance.org (accessed on 2 January 2020).
34.
Camacho, E.F.; Alba, C.B. Model Predictive Control; Springe-Verlag Ltd.: London, UK, 2004.
35.
Zaragoza, G.; Ruiz-Aguirre, A.; Guillén-Burrieza, E.
Efﬁciency in the use of solar thermal energy
of small membrane desalination systems for decentralized water production.
Appl. Energy 2014,
130, 491–499.10.1016/j.apenergy.2014.02.024. [CrossRef]
36.
Gil, J.D.; M˜unoz, M.; Roca, L.; Rodríguez, F.; Berenguel, M. An IoT based control system for a solar membrane
distillation plant used for greenhouse irrigation. In Proceedings of the 2019 Global IoT Summit (GIoTS),
Aarhus, Denmark, 17–21 June 2019; IEEE: Piscataway, NJ, USA, 2019; pp. 1–6.10.1109/GIOTS.2019.8766370.
[CrossRef]
37.
Gil, J.D.; Roca, L.; Ruiz-Aguirre, A.; Zaragoza, G.; Berenguel, M.
Optimal operation of a solar
membrane distillation pilot plant via nonlinear model predictive control.
Comput. Chem. Eng. 2018,
109, 151–165.10.1016/j.compchemeng.2017.11.012. [CrossRef]
38.
Rodríguez, F.; Berenguel, M.; Guzmán, J.L.; Ramírez-Arias, A. Modeling and Control of Greenhouse Crop Growth;
Springer: Cham, Switzerland, 2015.
39.
Castilla, M.d.M.; Álvarez, J.D.; Rodríguez, F.; Berenguel, M.
Comfort Control in Buildings; Springer:
Cham, Switzerland, 2014.
40.
Rodríguez, F.; Berenguel, M.; Sánchez-Molina, J.; Muñoz Rodríguez, M. Farms, Fogs and Clouds: Data
open-architecture for optimal crop growth control for IoF2020 project. In Proceedings of the European
Conference on Agricultural Engineering, Wageningen, The Netherlands, 8–12 July 2018.
41.
Muñoz Rodríguez, M.; Sánchez-Molina, J.A.; Torres, M.; Berenguel, M.
IoT-Based APP architecture
for greenhouse management. In Proceedings of the EFITA-HAICTA-WCCA Congress, Rodas, Greece,
27–29 June 2019.
c⃝ 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 2:
- APA Citation: Sharma, A., & Jain, A. (2020). Deep Learning Applications for Precision Agriculture: A Comprehensive Review. IEEE Access, 9, 4843-4873.
  Main Objective: To provide a comprehensive review of the current state and future potential of real-time, automated irrigation management systems using IoT and ML technologies, with a focus on the initial stages of the automated irrigation management pipeline, covering data collection and transmission protocols, and addressing challenges and solution approaches for real-time data transmission.
  Study Location: Unspecified
  Data Sources: Sensor data, Satellite imagery
  Technologies Used: Machine Learning (ML), Deep Learning (DL), Internet of Things (IoT), Wireless Sensor Networks (WSN)
  Key Findings: 1. ML/DL models have the potential to significantly improve the accuracy and efficiency of soil moisture prediction, leading to optimized irrigation management and reduced water consumption.
2. Ensemble learning techniques and DL models, particularly CNNs, have shown promising results in soil moisture prediction.
3. Future research should focus on developing robust and interpretable ML/DL models that can handle diverse soil types, environmental conditions, and sensor data characteristics.
  Extract 1: Metadata associated with soil moisture data, such as soil properties, crop type, and weather conditions, can help refine ML/DL models and improve prediction accuracy.
  Extract 2: Combining multiple ML/DL models, such as SVR, RF, and ANNs, can lead to more accurate and reliable soil moisture predictions.
  Limitations: The limitations of the study are as follows:
- The authors only considered research papers published in English, which may have introduced a language bias into their analysis.
- The authors focused on soil moisture prediction as a single aspect of automated irrigation management, while other aspects, such as crop health monitoring and yield prediction, were not covered in detail.
- The authors did not provide a comprehensive evaluation of the performance of different ML/DL algorithms for soil moisture prediction, which would have been useful for practitioners seeking to implement these methods in real-world applications.
  Relevance Evaluation: 9
  Relevance Score: 1.0
  Inline Citation: Sharma; Jain, 2020
  Explanation: The authors of the paper "Deep Learning Applications for Precision Agriculture: A Comprehensive Review" have conducted a systematic literature review to analyze the use of machine learning (ML) and deep learning (DL) algorithms in precision agriculture. Specifically, they focused on the initial stages of the automated irrigation management pipeline, where data is collected and soil moisture is predicted.
The authors acknowledge that accurate prediction of soil moisture content is critical for optimizing irrigation management and reducing water consumption. They highlight the use of ML algorithms such as support vector regression (SVR), random forest (RF), and artificial neural networks (ANNs) for this purpose. The authors discuss the advantages and limitations of existing ML/DL models and suggest areas for future research, emphasizing the need for robust algorithms that can handle the diverse and complex nature of soil moisture data.

In their discussion of key points from the paper, the authors emphasize the following:

1. **Metadata can improve data interpretation and decision-making.** Metadata associated with soil moisture data, such as soil properties, crop type, and weather conditions, can help refine ML/DL models and improve prediction accuracy.

2. **Ensemble learning techniques often outperform individual ML/DL algorithms.** Combining multiple ML/DL models, such as SVR, RF, and ANNs, can lead to more accurate and reliable soil moisture predictions.

3. **DL models, particularly convolutional neural networks (CNNs), have shown promising results in soil moisture prediction.** CNNs can extract complex patterns and features from sensor data, leading to improved predictive performance.

4. **Future research should focus on developing robust and interpretable ML/DL models for soil moisture prediction.** More research is needed to develop ML/DL models that can handle diverse soil types, environmental conditions, and sensor data characteristics.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign In Browse My Settings Help Institutional Sign In All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 9 Machine Learning Applications for Precision Agriculture: A Comprehensive Review Publisher: IEEE Cite This PDF Abhinav Sharma; Arpit Jain; Prateek Gupta; Vinay Chowdary All Authors 286 Cites in Papers 42120 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. Impact of Artificial Intelligence and IoT in Agriculture III. Machine Learning Algorithms IV. Machine Learning Applications in Precision Agriculture V. IoT Applications in Precision Agriculture Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: Agriculture plays a vital role in the economic growth of any country. With the increase of population, frequent changes in climatic conditions and limited resources, it becomes a challenging task to fulfil the food requirement of the present population. Precision agriculture also known as smart farming have emerged as an innovative tool to address current challenges in agricultural sustainability. The mechanism that drives this cutting edge technology is machine learning (ML). It gives the machine ability to learn without being explicitly programmed. ML together with IoT (Internet of Things) enabled farm machinery are key components of the next agriculture revolution. In this article, authors present a systematic review of ML applications in the field of agriculture. The areas that are focused are prediction of soil parameters such as organic carbon and moisture content, crop yield prediction, disease and weed detection in crops and species detection. ML with computer vision are reviewed for the classification of a different set of crop images in order to monitor the crop quality and yield assessment. This approach can be integrated for enhanced livestock production by predicting fertility patterns, diagnosing eating disorders, cattle behaviour based on ML models using data collected by collar sensors, etc. Intelligent irrigation which includes drip irrigation and intelligent harvesting techniques are also reviewed that reduces human labour to a great extent. This article demonstrates how knowledge-based agriculture can improve the sustainable productivity and quality of the product. A graphical abstract for Machine Learning Applications for Precision Agriculture: A Comprehensive Review. Published in: IEEE Access ( Volume: 9) Page(s): 4843 - 4873 Date of Publication: 31 December 2020 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2020.3048415 Publisher: IEEE CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. Nomenclature AbbreviationExpansion AI Artificial Intelligence ML Machine Learning DL Deep Learning IoT Internet of Things GPS Global Positioning System UAV Unmanned Aerial Vehicle ASC Agriculture Supply Chain NLP Natural Language Processing SI Swarm Intelligence ANN Artificial Neural Network NN Neural Network K-Nearest kNN Neighbour SVM Support Vector Machines RNN Recurrent Neural Network ELM Extreme Learning Machines RELM Regularized Extreme Learning Machine XGBoost Extreme Gradient Boosting MLP Multi-Layer Perceptron CNN Convolutional Neural Network PCA Principal Component Analysis RBFN Radial Basis Function Network RF Random Forest GBM Gradient Boosting Model SVR Support Vector Regression BPNN Back Propagation Neural Network LS-SVM Least square support vector machine GRNN Generalized Regression Neural Networks RELM Residual Maximum Likelihood DBN Deep Belief Network RT Regression Tree MLR Multiple Linear Regression LASSO Least Absolute Shrinkage and Selection Operator Regression RIDGE Ridge Regression SNN Shallow Neural Network GCN Graph Convolutional Network GEP Gene Expressions Programming RCNN Regions-CNN GA Genetic Algorithm PSO Particle Swarm Optimization PLSR Partial Least Square Regression ANFIS Adaptive Neuro Fuzzy Inference System TCN Temporal Convolution Network SCC Somatic Cell Count OPF Optimum-Path Forest BVDV Bovine Viral Diarrhea Virus MC Moisture Content SOC Soil Organic Carbon TN Total Nitrogen SOM Soil Organic Matter NDVI Normalized Difference Vegetation Index CEC Cation Exchange Capacity ETc Estimation of evapotranspiration SOM Soil Organic Matter LAI Leaf-Area Index RGB Red Green Blue DW Accumulated Dry Weight VRI Variable Rate Irrigation ET Evapo-Transpiration EC Electrical Conductivity SCM Sub-Clinical Mastitis SI Scatter Index AWM Attribute Weighting Model AUC Area Under the Curve R Correlation Coefficient R2 Coefficient of Determination MSPE Mean Squared Prediction Error MAPE Mean Absolute Percentage Error MAE Mean Absolute Error RMSE Root Mean Square Error RRMSE Relative Root Mean Square Error RPD Residual Prediction Deviation ROC Receiver Operating Characteristic RMSD Root Mean Square Difference NS Nash–Sutcliffe coefficient WSN Wireless Sensor Network GWO Grey Wolf Optimization SPI Serial Peripheral Interface I2C Inter-Integrated Circuit UART Universal Asynchronous Receiver Transmitter USB Universal Serial Bus BLE Bluetooth Low Energy SECTION I. Introduction The population of the world will increase to 9.1 billion approximately thirty-four percent as of today by the end of 2050. Food requirement will increase by 70 percent and due to rapid urbanization, land availability for agriculture will decrease drastically in the coming years. India will be the most populated country by 2050 and presently it is already lagging the domestic food production. The main reason for reduced food production is the lack of planning, unpredictable weather conditions, improper harvesting and irrigation techniques and livestock mismanagement. In the last few years, nature has experienced a drastic change in weather conditions due to global warming. The average temperature of the earth has been increased due to which there is uncertainty in climatic conditions. Frequent droughts, heavy rainfall are the biggest challenge for poor farmers. According to the government of India annual economic survey, adverse climatic conditions, reduce the farmer’s income by 20-25%. Precision agriculture [1], [2] is one of the solutions to ensure food security for the entire world [3]. Precision agriculture also abbreviated as digital agriculture is a technology-enabled data-driven sustainable farm management system. It is basically the adoption of modern information technologies, software tools, and smart embedded devices for decision support in agriculture [4] as shown in figure 1. Mechanized agriculture and the green revolution are the two key components of the first and second agriculture revolution. Precision farming is an important part of the third agriculture revolution [5]. FIGURE 1. Precision agriculture. Show All John Deere introduced this technology in 1990 for the sowing of seeds and spraying of fertilizers using global positioning system (GPS) controlled tractors. The main focus of precision farming is to reduce the production cost and environmental effects to increase the farm’s profitability. Digital technologies such as IoT [6], AI, data analytics, cloud computing, and block-chain technology play a key role in precision agriculture. In precision farming, IoT based smart sensors are deployed in the agriculture land for collecting data related to soil nutrients, fertilizers, and water requirements as well as for analysing the crop growth. Autonomous and semi-autonomous devices such as an unmanned aerial vehicle (UAV) [7] and robots are used for identifying weed and disease in the plants using computer vision techniques. Satellite images are also used in precision agriculture for monitoring the field and identifying the diseases in the plants. The data obtained from the deployed sensors [8] are processed and analyzed using ML algorithms to make farming practice more controlled and optimized. ML algorithms are also used for weather and rainfall prediction based on the data obtained from sensors, climatic records, and satellite images. This could save the lives of thousands of farmers who commit suicide because of crop loss due to uncertainty in weather conditions. Smart livestock management is an important component of precision agriculture. It helps in monitoring the health, welfare, productivity, and reproduction of animals throughout their life cycle. Sensors and cameras monitor animal’s health and computer vision techniques help in making intelligent decisions such as stopping the communal spread of diseases. Autonomous tractors and automated irrigation systems provide modern farming solutions to farmers. The widespread utilization of precision farming across the world is due to the presence of innovative machine and deep learning (DL) algorithms, high-speed internet access, and efficient computational devices. In [10] authors have discussed applications of ML for sustainable agriculture supply chain (ASC) performance. Authors have presented a unique ML-ASC framework that can guide researchers and agriculture practitioners to understand the role and importance of digital technologies in the agriculture industry. In [11] authors reviewed different ML applications in agriculture and discussed how digital technologies will benefit the agriculture industry. In this paper, the authors have presented a comprehensive review of the ML application for precision agriculture. This review article will provide an insight into the research community about the adoption of digital practices in the agriculture management system. It is anticipated that government agencies will frame policies to promote precision farming across the world. The main contribution of the article is outlined as follows: Applications of artificial intelligence and IoT in precision agriculture are discussed along with their practical implications. Foundation of ML and DL algorithms which find their application in precision agriculture has been discussed. Performance comparison for various ML, DL algorithms in precision farming has been carried out based on the state-of-art literature. Assessment of artificial intelligence techniques in precision agriculture is outlined along with its statistical and performance analysis. Comparison of performance parameters of sensors used in IoT applications in precision agriculture is presented. Integration of wireless sensor network (WSN) with IoT and artificial intelligence in precision agriculture is discussed. Challenges and future trends of artificial intelligence in precision farming are briefly outlined. Table 1 highlights the major differences of this review article with other articles published in this field. The paper is organized as follows. Section 2 presents the impact of artificial intelligence (AI) and IoT in the field of agriculture. Section 3 briefly elucidate ML algorithms. In section 4 different ML applications in precision farming are briefly reviewed. Section 5 presents the IoT application in precision agriculture. Section 6 evaluates and access the knowledge-based agriculture system. Section 7 outlines the challenges and limitation of AI in precision agriculture. Section 8 presents the future trends of AI in precision agriculture. Section 9 provides conclusive remarks to summarize the paper. TABLE 1 Key Differences of the Article With Published Articles SECTION II. Impact of Artificial Intelligence and IoT in Agriculture The term AI was first coined in the Dartmouth conference in the year 1956 by John McCarthy and he defined it as a science and engineering of making intelligent machines or more specifically intelligent computer programs. AI technology provides computational intelligence to machines so that they can learn, understand and react according to the situation. ML, DL, natural language processing (NLP), swarm intelligence (SI), expert systems, fuzzy logic, and computer vision are the subfields of AI as shown in figure 2. This field finds endless applications across different sectors of human life. Intelligent AI programs are widely explored in health-care, agriculture, finance, robotics, e-commerce and the automation industry. Samsung, Apple, and other electronics giant companies announced that they will be utilizing this technology in every device they will manufacture in the near future. IoT is another emerging technology in which smart sensors, devices are interconnected through the internet. These smart sensors can be utilized to gather data across different disciplines such as solar plants, agriculture fields, disaster-prone areas, manufacturing industry for efficient resource utilization. With the increase in population over the year’s demand for agriculture products is increasing day by day. However, with limited land availability for farming and reduce interest among the young generation to adopt farming as their profession, it has become a challenging task for the agriculture industry to satisfy the food requirement of millions of people. Now, the agriculture industry is widely adopting smart technologies like IoT and AI to efficiently cultivate organic products in limited land areas as well as to overcome the traditional challenges of farmers. FIGURE 2. Artificial intelligence techniques. Show All IoT based smart farming system is built for monitoring soil nutrients and soil moisture using sensors. ML algorithms are explored for determining the optimum amount of fertilizers required for soils before the sowing of crops. Drones are revolutionizing the agriculture industry. These drones are cameras enabled and are used for different applications such as field and crop monitoring, spraying of pesticides, and drip irrigation. The images captured by the drones over the entire lifecycle of crops can be examined using DL and computer vision algorithms for disease and weed identification. Thereafter, these drones are used for spraying pesticides over the weeds and infected crops. Over the years uncertainty in weather conditions is the main concern of farmers. Drip irrigation using drones is an efficient AI-empowered irrigation system which is basically trained on weather pattern and can effectively reduce the water problems of farmers. AI-enabled robots can be used for harvesting the crops at a much faster pace and in large volumes. Robots can reduce human labour to a large extent and can be used along with drones for monitoring the field. Livestock management is another major concern for farmers. IoT based sensors can be deployed in the field for health monitoring of cattle. This information can be utilized for protecting the bunch of cattle from diseased cattle. NLP based virtual assistant applications like chatbots can update the farmers with the latest advancement in technologies for agriculture. Farmers can finds solutions for their problems and incorporate the latest technology in their farming for improving their field productivity. Thus, AI and IoT are the two major technologies that will play a vital role in the agriculture industry. SECTION III. Machine Learning Algorithms ML is the subfield of computer science that gives computers the ability to learn without being explicitly programmed. (Arthur Samuel, 1959) [12]. Alan Turing in the year 1950 proposed the concept of learning machines and wrote a research article “The Turing Test for Machine Intelligence” [13]. He performed a test and examined the machine’s ability to demonstrate intelligent behaviour similar to humans. A machine or intelligent computer program learns and extract knowledge from the data, builds a framework for making predictions or intelligent decisions. Thus, the ML process is divided into three key parts, i.e. data input, model building, and generalization as shown in figure 3. Generalization is the process for predicting the output for the inputs with which the algorithm has not been trained before. ML algorithms are mainly used to solve complex problems where human expertise fails such as weather prediction, spam filtering, disease identification in plants, pattern recognition. FIGURE 3. A Machine learning process. Show All Today, due to the availability of innovative algorithms and large data sets through internet resources industries and research communities are widely using ML algorithms for solving a diverse set of problems. DL is the subfield of the family of ML algorithms which is trained from large sets and uses an artificial neural network (ANN) to make intelligent decisions. ML algorithms are categorized as supervised learning, unsupervised learning, and reinforcement learning as shown in figure 4. Supervised learning as the name suggests is learning with the supervisor or teacher. This set of algorithms works with labeled data-set which means corresponding to each input there are outputs. The algorithm builds an input-output relationship with this labeled data set and thereafter generalize or predicts outputs for unseen inputs. Supervised learning algorithms used for predicting the categorical value are known as classification algorithms and the algorithms that are used for predicting the numerical value are known as regression algorithms. Unsupervised learning algorithms works with unlabelled data and discovers unknown objects by grouping similar objects. The goal of an unsupervised learning algorithm is to extract hidden knowledge from the training data set thus this approach is difficult to implement than supervised learning algorithms. Reinforcement learning is another approach that learns from the environment through reward and punishment. AlphaGo, a chess-playing game developed by DeepMind utilized reinforcement learning for defeating the world’s best chess-playing computer program. FIGURE 4. Categorization of machine learning algorithms. Show All In this paper the performance of different ML algorithms are analysed and discussed in the field of agriculture. Table 2 presents different types of supervised, unsupervised and reinforcement learning algorithms utilized for soil and weather prediction, disease and weed identification, intelligent irrigation and harvesting techniques as well as livestock management. TABLE 2 Machine Learning Algorithms SECTION IV. Machine Learning Applications in Precision Agriculture In many countries, the farmers rely on the traditional ways of farming which is based on the reliability of the suggestions from the elderly and their experience. This method leaves farmers at the mercy of random climatic conditions which are already getting random due to global warming and uneven rainfall patterns. The manual spraying method for pesticides led to improper usage of resources and harms the environment. AI and IoT enabled precision agriculture removes the randomness and assist new age farmer to optimize every step of the farming process. Figure 5 (a) and (b) presents a pictorial view of traditional agriculture and technology enabled farm management system. FIGURE 5. (a) Traditional agriculture cycle (b) Precision agriculture cycle. Show All Gaitán [14] provided a systematic study of the impact of extreme weather events, such as hail events, cold waves, heat waves, and their impact on agricultural practices. The author reported floods, droughts, frost, hail, heatwaves, and pest outbreaks are impacted by climatic conditions. The AI systems are applicable in each farming operation as depicted in figure 4 and some of them even extend beyond the conventionally recognized steps. In this section we will discuss the state of art techniques proposed/implemented by various researchers and practitioners worldwide. A. Soil Properties and Weather Prediction Prediction of soil properties is the first and the most crucial step which influences the selection of crop, land preparation, selection of seed, crop yield, and selection of fertilizers /manure. The soil properties are directly related to the geographic and climatic conditions of the land in use and hence is an important factor to take into consideration. The soil properties prediction mostly consists of predicting nutrients in the soil, soil surface humidity, weather conditions during the lifecycle of the crop. Human activities have highly affected the properties of soil and hence our ability to cultivate the crops [15]. In general, there are 17 essential elements as listed in table 3 which play an important role in plant growth [16]. The growth of crops depends on the nutrients available in a particular soil. The soil nutrients are mostly monitored by electric and electromagnetic sensors [8]. Depending on the nutrients farmers make informed decisions as to which crop is optimal for the land. However, the nutrients can be added through fertilizers, manure, etc. but with an additional cost. Some of them may also damage the environment and have an adverse effect on the soil cycle. TABLE 3 Essential Plant Nutrients [2] A scientific analysis of soil nutrients, soil moisture, pH is important for determining the soil properties. Acar et al. [17] employed an extreme learning machine (ELM) based regression model for prediction of soil surface humidity. The author selected two terrains having area 4 KM2 and 16 KM2 located in Dicle university campus for experimental analysis. The real-time field data was extracted using polarimetric Radarsat-2 data, which was pre-processed using the SNAP toolbox [18] and features were added with the help of local measurements by separating the field into square grids. Once the pre-processing and feature extraction is done the data is passed to ELM based regression model to predict the soil surface humidity. The algorithm was tested with 5 different kernel functions and the prediction was validated using leave-one-out cross-validation technique. The experimental results confirmed the lowest root mean square error (RMSE) of 2.19% when using ‘sine’ kernel function. Wang et al. [19] deployed soft sensors based on ELM for the measurement of nutrient solution composition in the soilless cultivation method. The soilless cultivation method is an emerging planting method. It is imperative to monitor the pH value, temperature and concentration changes in nutrient solution composition as the performance of soilless cultivation is highly dependent on these parameters. The significant variables in a nutrient solution cannot be measured directly hence these are determined with the help of auxiliary variables. The authors utilized conductivity, pH value, flow rate, and temperature measurements for auxiliary measurements. These auxiliary measurements are fed to a deep belief network-based ELM which predicts the values of significant variables. For experimental analysis, the authors deployed the model to measure the concentration of SO 2− 4 , and H 2 PO − 4 in a nutrient solution. The authors reported an average RMSE of 1.2414 for predictions in SO 2− 4 and RMSE of 0.8892 for prediction of H 2 PO − 4 . Park et al. [20] utilized ML algorithms to predict the soil moisture using data from MODIS. The authors downscaled the AMSR2 soil moisture to 1KM using random forest (RF) and Cubist algorithms. An ensemble of these algorithms was used to obtain soil moisture data. The results obtained through the ML methods were compared with the statistical ordinary least squares technique. The ML model exhibited a R 2 (coefficient of determination) of 0.96 and an RMSE of 0.06, whereas a R 2 of 0.47 and a RMSE of 0.16 was associated with the statistical ordinary least squares. Reda et al. [21] explored ML algorithms to estimate soil organic carbon (SOC) and total nitrogen (TN) in soil samples collected from four agricultural lands of Moroccan. Data set of near-infrared spectroscopy is utilized in comparison to traditional chemical methods as this technique reduces the computation time and resource utilization. The ensemble learning modeling algorithm presents the best performance among other regression models and back-propagation neural networks (BPNN) algorithm. The proposed algorithm presents R 2 of 0.96, RMSE of 1.92, performance to deviation (RPD) of 4.87 for SOC and R 2 of 0.94 and RMSE of 0.57, RPD of 4.91 for TN prediction. Morellos et al. [22] also utilized visible and infrared spectroscopy to determine TN, SOC, and moisture content (MC) in the arable field in Premslin Germany. Spectroscopy dataset is used for building the predictive ML model for estimating all three soil properties. Least square support vector machine (LS-SVM) and cubist ML algorithms outperform principal component regression and partial least square regression multivariate methods in terms of RMSE and residual prediction deviation (RPD). LS-SVM best predict SOC and MC with RMSE of 0.062 and 0.457, RPD of 2.24, and 2.20. Cubist best predicts for TN with RMSE of 0.071 and RPD of 1.96. Andrade et al. [23] build ordinary least square regression, RF, cubist regression, XGboost prediction model for determining soil properties from portable X-ray fluorescence (pXRF) spectrometry dataset in Brazilian coastal plains. Three soil properties total nitrogen, soil organic matter (SOM), cation exchange capacity (CEC) were analyzed using RF, ordinary least squares regression (OLS), cubist regression (CR), XGBoost (XGB). RF algorithm gives the best performance with R 2 of 0.50 for TN, R 2  0.75 for CEC and 0.56 for SOM. Deiss et al. [24] estimated the soil properties (clay, sand, pH, SOC) in northern Tanzania and USA Midwest from the spectroscopy dataset using ML algorithms. THE tuned SVM model outperforms the partial least square (PLS) regression model in terms of predicting all the soil parameters. Mahmoudzadeh et al. [25] explored the ML algorithm to predict SOC in the Kurdistan province of Iran. The simulation results suggest that RF accurately predicts SOC with R 2 of 0.60 and RMSE of 0.35% in comparison to SVM, kNN, Cubist, and Extreme Gradient Boosting (XGBoost) ML algorithm. The study also suggests that air temperature, annual rainfall, valley depth, texture of terrain surface are some of the important factors that influence SOC spread over the Kurdistan region. Veres et al. [26] explored DL architecture such as CNN for predicting the soil properties from the infra-red spectroscopy dataset. Benke et al. [27] predict soil electrical conductivity (EC) and SOC in different regional locations of Victoria, Australia using pedotransfer function (PTF) based on ML algorithm. PTF basically converts soil measurement into soil properties and provides inputs for ML simulation algorithms. In the proposed approach PTF use Generalised Linear Mixed Effects Model (GLMM) model and Residual Maximum Likelihood (REML) to predict‘ the soil properties. Traditional approaches to soil properties and crop yield prediction require time-consuming field surveys and the deployment of expensive sensors. Khanal et al. [28] proposed an alternative approach in which the dataset for the prediction of soil properties and crop yield is generated using remotely sensed aerial images of agricultural land. Five soil properties, viz. pH value, magnesium (Mg), potassium (K), SOM, CEC, and crop yield were predicted using RF, SVM, Cubist, NN, Gradient Boosting Model (GBM) ML algorithms. NN presents the highest prediction accuracy for SOM having R 2 of 0.64, RMSE of 0.44 and CEC having R 2 of 0.67, RMSE of 2.35; SVM best predicts K having R 2 of 0.21, RMSE of 0.49 and Mg having R 2 of 0.22, RMSE of 4.57; and GBM best predicts pH having R 2 of 0.15, RMSE of 0.62. RF outperforms other algorithms in terms of crop yield prediction and presents higher accuracy having R 2 of 0.53 and RMSE of 0.97. Labrador et al. [29] estimate calcium and Mg content in soil using generalized regression NN and genetic algorithm (GA). The digital elevation model and satellite images were used as input to the prediction model for estimating the soil properties. Chlingaryan et al. [30] discussed different ML approaches used in precision agriculture for accurate crop yield prediction and soil nitrogen estimation over the last fifteen years. Ju-Young et al. [31] investigated a seasonal climatic forecasting model using regularized ELM to predict day-wise mean air temperature at field level for a period of 90 days. The authors selected data from Korea Metrological Administration using the Met GloSea5GC2 model [32]. The authors fed 240 days of forecast data and hindcast data from the ensemble based model to the RELM algorithm. The algorithm performance was evaluated by measuring: RMSE, mean absolute error (MAE) the model prediction vs the actual values. The authors achieved an RMSE in the range of 1.02 to 3.35 which outperformed the meteorological data which has an RMSE range of 1.61 to 3.37. Soil moisture content is an important parameter to acknowledge in the agriculture industry as it addresses precise irrigation scheduling. Stamenkovic et al. [33] build a support vector regression (SVR) prediction model to predict soil moisture content from remotely sensed hyperspectral images. Song et al. [34] proposed a macroscopic cellular automata (MCA) model and combined its deep belief network (DBN) to predict soil moisture content over a cornfield in northwest china. The simulation results of DBN-MCA outperforms the multi-layer perceptron (MLP)-MCA in terms of RMSE. Acheing [35] explored the SVR model (i.e. RBF), ANN, DNN for simulating soil water retention curve (SWRC) curve of loamy sand. Dataset of loamy sand subjected to wetting and drying condition is collected using a reflectometer and tensiometer. RBF based SVR model best predicts SWRC under both wet and dry conditions. Feng et al. [36] estimate soil temperature at various soil depths of Loess Plateau of China. Four different ML algorithms ELM, generalized regression neural networks (GRNN), backpropagation neural networks (BPNN), and RF were investigated for predicting the soil temperature. ML algorithms were trained with air temperature, wind speed, relative humidity, and vapour pressure and solar radiation as input parameters and the simulations show that ELM outperforms other ML algorithms in terms of RMSE, MAE, Nash–Sutcliffe coefficient (NS) and concordance correlation coefficient. Mohammadi et al. [37] explored ELM for predicting daily dew point temperature in different parts of Iran. This part of the world experience different climatic conditions throughout the year. The proposed model accurately predicts dew point temperature than SVM and ANN algorithms. Zhu et al. [38] accurately predict daily evapotranspiration in Northwest China using hybrid particle swarm optimization (PSO)-ELM model to optimize crop water requirement in agriculture. Alizamir et al. [39] accurately predicts soil temperature at different depths of 5, 10, 50 and 100 cm using ELM, ANN, classification and regression trees, group method of data handling using dataset obtained from Mersin station operated by Turkish Meteorological Service. The simulation results suggest that soil temperature can be estimated easily using air temperature upto depth of 50 cm while for depth of 100 cm additional information of solar radiation and wind speed is required. Rainfall prediction plays a critical role in the water resource management system, flood risk assessment, and the agriculture industry. Acknowledging the chaotic nature of rainfall, it is very difficult for statistical approaches to accurately predict the rainfall. Cramer et al. [40] evaluated the performance of seven ML algorithms for rainfall prediction. The statistical results show that the radial-basis function neural network (RBFNN) shows the best performance among other state of the art algorithms. Sierra and Jesus [41] predicted the rainfall in Tenerife, an island in Spain based on atmospheric synoptic patterns using different ML algorithms and found NN gave the best performance among other ML algorithms. Kamatchi and Parvathi [42] employed NN for weather prediction and proposed a hybrid recommender system for enhancing the success ratio of the system. Lazri et al. [43] build a multi-classifier model for estimating precipitation using MSG images (Meteosat second generation) and dataset obtained using radar. The proposed approach shows that the proposed multi-classifier improves the standard of classification. Shardoor and Rao [44] surveyed three different approaches i.e. ML techniques, data mining techniques, and satellite forecasting techniques for rainfall prediction. Table 4 presents a comparative study of different ML algorithms for prediction of soil properties and weather prediction. TABLE 4 Different ML Algorithms for Prediction of Soil Properties and Weather Conditions B. Crop Yield Prediction A significant piece of information for any farmer is the prediction of crop yield and how the yield can be increased. pH value, soil type, and quality, weather pattern: temperature, rainfall, humidity, sunshine hours, fertilizers, and harvesting schedules are some of the parameters which play an important role in predicting the crop yield [45]. Scientifically manual farming can be considered as a feedback control system in which the corrective action is taken once a setback in a crop is observed. The crop yield will highly depend on the efficiency of the optimal utilization of the above-mentioned resources. If some kind of anomaly goes undetected in the initial stage may harm the crop yield in an unprecedented way. Singh et al. [46] assessed hailstorms on India’s wheat production and observes that in February and March 2015 alone the hailstorm events caused a decline of 8.4% in national wheat production. For financially weak farmers in a country such as India, where intermittent storage of harvested crops is a rare resource, accurate weather predictions may turn to be miraculous for farmers. ML models when systematically applied to a system act as feedforward control. With the help of accurate ML models, we can anticipate the factors which are going to affect the crop yield. Hence the corrective action can be taken before even an anomaly hits the crop production. Kamir et al. [47] used ML models to identify the yield gap hotspots in wheat production. Authors generated very high-resolution yield maps using data from various sources between 2009 and 2015. The data was collected from various sources:(a) NDVI time-series data across Australia using the MOD13Q1 data set [48], (b) rainfall and temperature data were collected from historic climate data at Australia bureau of metrology, (c) maps for observed grain yield were collected at source using intelligent harvesting machines. The dataset generated were tested with 9 ML algorithms: RF, XGBoost, Cubist, MLP, SVR, Gaussian Process, k-NN, and Multivariate Adaptive Regression Splines. The authors combined predictions from each of the algorithms into ensembles for prediction optimization [49]. Out of these algorithms, SVR with RBFNN outperformed other algorithms and investigators were able to achieve the yield estimate with an R 2  of 0.77 and an RMSE value of 0.55t ha −1 . The results were validated using 10-fold cross-validation techniques applied to the full data set. Aghighi et al. [50] used various advanced regression algorithms to predict the yield of silage maize crops. The authors selected maize fields located at Moghan Agro-Industrial and Animal Husbandry Company (MAIAHC), which is about 28,000 hectares’ area and located in Iran. The crop yield dataset was collected for around 40 silage maize fields were collected for a period from 2013-2015. In addition to it, the historic crop yield data the authors also gathered time-series NDVI data from Landsat 8 OLI satellite. The data was fed to advanced regression algorithms: (a) Gaussian Process Regression, (b) SVR, (c) Boosted Regression tree (d) RF Regression models and the prediction form each of the regression models were compared and evaluated. Authors found out the boosted regression tree reported best evaluation parameters with an average R-value of higher than 0.87, and RMSE in a range of 8.5 to 11.10, with a mean value of 9.5 during the period 2013-14. Kuwata and Shibasaki [51] employed DL models to estimate the crop yield. Authors deployed SVR for predicting the yield of corn in Illinois. For input following dataset was employed by the authors: (a) 5 year moving average of corn crop yield, (b) The enhanced vegetation index is obtained using the MOD09A1 dataset MODIS satellite, and (c) Historic climatic data. The dataset was fed to support the vector regression model and the authors reported an RMSE of 8.204 and a correlation coefficient of 0.644 for the model. For result, validation authors conducted 10-fold cross-validation on the full data set. Kulkarni et al. [52] utilized DL models to predict rice crop yield. The authors utilized soil properties and nutrients measurements recorded over 31 years and historic rainfall data. The input data was fed to recurrent neural network models for crop yield prediction. For effective prediction the authors explored different activation functions viz. sigmoid, reLu, and linear in the neural network. Chu and Yu [53] builds an end to end summer and winter rice prediction model in 81 counties in the Guangxi Zhuang Autonomous Region, China. The proposed BBI model works in three stages, in the first stage the original area data and time series metrological data is pre-processed and its output works as input for the second stage where BPNN and RNN (recurrent neural network) learns deep spatial and temporal features from the input data. In the third stage, BPNN learns the relationship between deep features and rice yield to predict the summer and winter rice yields. The performance of the model is evaluated in terms of error and rate of convergence, the model presents lowest error values with MAE and RMSE of 0.0044 and 0.0057 for summer rice prediction and 0.0074 and 0.0192 for winter rice prediction while the algorithm converges within 100 iterations. Feng et al. [54] proposed a hybrid approach for wheat yield prediction in new-south Wales in southeastern Australia. Multiple growth specific indicators, viz. agricultural production system simulators (APSIM), NDVI, and SPEI (Standardized Precipitation and Evapotranspiration Index) are used before the prediction of wheat yield using regression models (multiple linear regression (MLR) and RF). APSIM+ RF hybrid model presents the best performance among other predictors in terms of prediction accuracy. Cai et al. [55] integrated two data sources, i.e. climate data and satellite data over fourteen years to predict the wheat yield in Australia using ML algorithms (SVM, RF, and NN). Simulation results show that climate data provides distinctive information in comparison to satellite data for yield prediction with R 2 of around 0.75. Planting the crops on accurate date plays an important role in improving productivity and reducing financial loss. Gumuscu et al. [56] explored three supervised ML algorithms; kNN, SVM, and decision trees for predicting planting dates; early, normal, and late for wheat crops in Turkey. The authors utilized climate data of the last 300 days to train ML algorithms and explored GA for feature selection. kNN classification ML algorithm shows robust performance and best predicts the planting dates of wheat crops. Several African, American, and Asian countries are the major producer of coffee in the world. Nevavuori et al. [57] explored a deep learning approach, i.e. CNN for wheat and barley yield prediction in the agriculture field of Pori, Finland. NDVI and RGB dataset obtained from cameras installed in UAV is used to train the six-layer CNN. RGB dataset best predicts the crop yield in CNN with MAE of 484.3 kgha−1 and mean absolute percentage error (MAPE) of 8.8%. Koirala et al. [58] reviewed deep learning approaches for fruit detection and yield estimation. CNN in the context of computer vision is widely used for feature extraction from images that provide useful insight to object detection and yield estimation. Kouadio, et al. [59] predicted the Robusta coffee yield using ML techniques from soil fertility dataset of Vietnam. ELM model outperforms multiple linear regression and RF algorithm with RMSE of 496.35 kg ha−1 and MAE of 326.40 kg ha−1. Gamboa et al. [60] predict the cocoa yield in Santander, Columbia using a generalized linear model (GLM) and SVM. In recent decades researchers have explored statistical and probabilistic models for crop yield prediction. Gyamerah et al. [61] proposed a novel robust probabilistic forecasting model based on quantile random forest and Epanechnikov kernel function (QRF-E) for crop yield prediction in Ghana. The proposed approach didn’t only predict discrete yield values but completely showcase probability descriptions for prediction interval for the two crops groundnut and millet. The simulation result shows the superior performance of the proposed algorithm in terms of prediction intervals coverage probability and prediction interval normalized average width under uncertain weather conditions. Peng et al. [62] explored remote sensed satellite-based Solar-Induced Chlorophyll Fluorescence (SIF) dataset for training ML algorithms to predict maize and soybean yield in the mid-west region of the United States. Simulation results show that non-linear algorithms such as SVM, ANN, RF best predict the crop yield in comparison to least absolute shrinkage and selection operator regression (LASSO) and ridge regression (RIDGE) algorithm. Khaki and Wang [63] predicted the hybrid maize yield with a dataset of 2,267 locations of the United States and Canada between the years 2008 to 2016 using deep neural networks (DNN). Genotype, weather, and soil properties were the three components used to train DNN. The proposed model accurately predicts the maize yield with RMSE of 12% of the average yield for predicted weather dataset and 11% of the average yield for perfect weather dataset and outperforms LASSO, shallow neural network (SNN) and regression tree (RT). Simulation results show that environmental factors have a large impact on the prediction accuracy of crop yield. In most areas of Africa, agriculture field data is scarcely available thus remotely sensed dataset is widely used for monitoring the field. Leroux et al. [64] explored the ML algorithm for predicting the maize yield in Burkina Faso with a remotely sensed dataset. A process-based crop model SARRO which is basically designed to simulate attainable agricultural yields under tropical conditions is used in this study. RF outperforms MLR in maize yield prediction with R 2 of 0.59 at the end of the season and 0.49 before two months of harvest. Li et al. [65] build a statistical model for predicting the rain-fed crop yield using climate, satellite, and country-specific datasets in the mid-west region of the USA. Maimaitijiang et al. [66] explored the potential of UAV with DNN for soybean yield prediction from the fields of Columbia, Missouri, USA. Multi-modal information such as canopy spectral, structural, and thermal features extracted from images obtained from the sensors installed on UAV is used as the input dataset for training DNN. The simulation result shows that DNN accurately predict the crop yield and outperforms partial least square regression (PLSR), RF, SVR algorithms with R 2 of 0.720 and RMSE of 15.9%. Zhang et al. [67] explored ANN for prediction of annual crop planting utilizing a historical cropland data layer (CDL) dataset of corn-belt of mid-west, USA. Kocian et al. [68] utilized both approaches to predict crop growth in greenhouses. IoT smart sensors are installed in the greenhouses to monitor different environmental parameters, soil properties and plant growth parameters such as leaf area index (LAI), accumulated dry weight (DW) and evapo-transpiration (ET). These parameters are in real-time send to the cloud through IoT devices and permit the implementation of an agriculture decision-support system. The probabilistic Bayesian network is explored in the proposed system to predict crop development parameters. Shahinfar and Kahn [69] explored ML algorithms for early prediction of adult wool growth in Merino sheep of Australia. Model Tree algorithms best predict the wool growth in comparison with NN with a correlation coefficient of 0.93, 0.90, 0.94, 0.81 and 0.59, MAE of 0.48 kg, 0.41 kg, 0.92 μm , 6.91mm and 6.82 N/ktex, for predicting Greasy Fleece Weight, adult Clean Fleece Weight, adult Fibre Diameter and adult Staple Length. Table 5 presents a comparative study of different ML algorithms for crop yield prediction. TABLE 5 Different ML Algorithms for Crop Yield Prediction C. Disease and Weed Detection Disease fungi, microorganisms, and bacteria take their energy from the plants they live on, which in turn affects the crop yield. If not detected at the right time may account for a huge economic loss to farmers. A lot of financial burden goes to a farmer in the form of pesticides, to get rid of diseases and restore the functioning of crops. Excessive use of pesticides also leads to environmental damage and the effects of the water and soil cycle of the agricultural land. Using an optimally designed AI system during crop growth period not only reduces the risk of crop disease and minimizes the economic impact, but it also results in minimizing the adverse impact of unsystematic farming on the environment. Sambasivan and Opiyo [70] used a CNN based DL model to detect disease in cassava crops for imbalanced datasets. The authors took a database of 10,000 labeled images that were pre-processed to improve the image contrast using contrast limited adaptive histogram equalization algorithm. The model evaluation was done using the performance metrics: confusion matrix, accuracy measure, precision measure, sensitivity, and F1 score. The authors reported a best-case accuracy of 99.30% and the lowest accuracy was reported as 76.9%. Ramcharan et al. [71] used DL algorithms to detect diseases in cassava crops. Authors deployed deep CNN to identify three different diseases and two types of pests from a set of 11,670 images dataset. Author’s utilized GoogLeNet algorithm based Inception v3 in Tensor Flow. The authors achieved efficiency in a range of 80% to 93.0%, and the validation of the results was done with the help of the confusion matrix. Mohanty et al. [72] employed DL methods to detect crop disease from the image dataset of plant leaves. The authors used a public database consisting of smartphone generated 54,306 images of diseased and healthy plants leaves. These images were resized to 256×256 pixels and were assigned 38 different class labels of crop-disease pair, and transformed into 3 datasets color, grayscale and segmented. The dataset was then fed to two of the most common deep CNNs: AlexNet [73] and GoogLeNet [74]. The authors achieved an accuracy of 99.34% for GoogLeNet, and an accuracy of 85.53% for AlexNet network. The results were validated using F1 score, authors achieved a mean F1 score of 0.9886 for GoogLeNet, and a mean F1 score of 0.9848 for AlexNet. Amara et al. [75] used LeNet based CNN architecture for disease detection in banana leaves. Authors utilized data from open source local and digital libraries which were pre-processed and resized to 60×60 pixels, and the model was implemented for RGB as well as grayscale images. Hughes and Salathe [76] utilized this developed model for the identification of diseases in the images dataset. The authors achieved the best F1 score of 0.9971 for detection in RGB images and a score of 0.976 for grayscale images. Ferreira et al. [77] deployed CNN for the identification of weeds in soybean crops. The image dataset for soy plantation located at São José farm, Campo Grande Brazil was acquired using phantom DJI3 drone. The images are segmented using the SLIC algorithm into square grids. For training, the segmented images were manually annotated to their class. The segmented images dataset was fed to AlexNet (a convolution neural network) for classification. The performance of the AlexNet was compared with SVM, AdaBoost, and RF. To evaluate the performance of the AlexNet the model was fed with a balanced dataset and the authors reported an overall accuracy of above 90% and 96.3% images were correctly classified. Waheed et al. [78] proposed a cost-effective optimized dense CNN (DenseNet) for disease detection in corn leaves with an accuracy of 98.0%. Simulation results show that the proposed model outperforms other CNN models such as EfficientNet, VGG19Net, NASNet, and XceptionNet in terms of fewer parameters, accuracy, computation complexity, and computation time. Pereira et al. [79] proposed an expert system for identifying three species of aquatic weeds from aquatic weed leaves dataset based on their shape and supervised pattern recognition techniques. The author explored five shape descriptors with different shape-based skills viz. Beam Angle Statistics (BAS), Fourier Descriptors (FD), Moment Invariants (MI), Multi-scale Fractal dimension (MS), and Tensor Scale Descriptor (TSD) along with five ML algorithms viz. Optimum-Path Forest (OPF), SVM, Naive Bayes, ANN, MLP. Simulation results show that OPF using the BAS-100 descriptor presents the best results with a recognition rate of 96.41% in comparison to other approaches. Jiang et al. [80] proposed a semi-supervised CNN feature-based Graph Convolutional Network (GCN) for identifying weeds utilizing 6000 images of corn, lettuce, radish, and mixed weed dataset. The proposed approach works in two parts, i.e. in the first part CNN model is used for feature extraction thereafter in the second part GCN graph is explored utilizing CNN feature dataset for extracting feature of an unlabelled dataset using labelled dataset. The proposed approach shows the best results in comparison with AlexNet, VGG16, and ResNet-101 approaches with recognition accuracies of 97.80%, 99.37%, 98.93%, and 96.51% on four different weed datasets. Oppenheim and Shani [81] explored CNN for identifying four different types of diseases in potatoes. The simulation result shows that the model trained on 90% of the images and tested on 10% of images give the best results with 96% accuracy. Sugar beet contributes around 30% of world sugar production. Leaf spot diseases in sugar beet can create a loss of around 10 % to 50 % of yearly sugar yield. Rumpf et al. [82] proposed SVM with a radial basis function as a kernel based model for early detection and classification of three diseases Cercospora, leaf spot, leaf rust, and powdery mildew in sugar beet leaves. Diseased and non-diseased leaves were classified with an accuracy of 97% and three diseases were identified with accuracy higher than 86%. Ozguven and Adem [83] proposed updated faster R-CNN for leaf spot disease identification and classification in sugar beet. Leaf spot disease initially generates as small circular spots and later spread over the entire leaf surface. The proposed R-CNN architecture changes its parameters according to the images and the disease infected regions, which improves the overall classification rate to 95.48%. Bah et al. [84] explored CNN for weed detection in images obtained using UAV from bean and spinach fields. The proposed model first identifies the crop rows and then identifies the inter-crop row weeds which are used as a training dataset for CNN for crop and weed identification and classification. Kerkech et al. [85] identified the vine diseases from visible and infrared UAV images obtained in the Center Val de Loire region in France. A CNN model is trained with this dataset of images to classify each pixel according to different instances, namely, shadow, ground, healthy, and symptom. The model identifies with an accuracy of 92% at grapevine-level and 87% at leaf level. Oslen et al. [86] explored robust deep learning models Inception-v3 and ResNet-50 for weed species identification and classification from a dataset of images collected in Australian rangeland. Simulation results show that the average classification performance of both the models is 95.1% and 95.7%. These results found fruitful for automatic real-time robotic weed control in the agricultural field. Sudars et al. [87] establish an experimental set up with RGB digital cameras in Latvia to collect images of the field having 6 food crops and 8 weed species grown in normal field conditions and controlled environment. This dataset can be utilized by deep learning algorithms for weed identification and classification. Sethy et al. [88] identified the rice leaf disease based on a hybrid CNN and SVM. In this model, CNN is explored for deep feature extraction from 5932 diseased rice leaf images and this data is used as input for SVM classifier. The resnet50 with SVM classification model best classify with respect to other models with F1 score of 0.9838. Garcia et al. [89] proposed an ML and DL learning hybrid approach for weed and crop identification in the agriculture fields of Greece. Image dataset of two crops tomato and cotton and two weeds black nightshade and velvetleaf was generated for training and testing of the model. Initially CNN (Xception, Inception-Resnet, Vignette’s, Mobilenet, and Densenet)) is used for feature extraction and this feature set is later used to train ML classifier (SVM, XGBoost and Logistic Regression) for classification. The simulation result shows that Densenet and Support Vector Machine outperforms other approaches with F1 score of 99.29%. Shah and Jain [90] identified the disease in cotton leaf through ANN with some image pre-processing techniques. Yu et al. [91] explored deep learning algorithms with a dataset of images for identifying dandelion, ground ivy, and spotted spurge in perennial ryegrass. Parraga-Alava et al. [92] generated a robusta coffee leaf image dataset (RoCoLe) for disease identification using ML algorithms. Glezakos et al. [93] proposed an innovative method to identify two viruses Tobacco Rattle Virus (TRV) and the Cucumber Green Mottle Mosaic Virus (CGMMV) in plants. In the proposed research Bio-Electric Recognition Assay (BERA) technique is utilized to obtain time-series information of the two viruses by measuring the waves through biosensors for 331s. This time-series data is preprocessed using GA to eliminate noise and for dimensionality reduction of a large dataset. Thereafter this meta-data is used to train MLP neural network classifier. The proposed model is tested against other ML classifiers via cross-validation. Ramesh and Vydeki [94] explored optimized deep NN with the Jaya algorithm for the identification of paddy leaf diseases. A dataset of rice plant leaves was taken from the agricultural field to identify and classify normal, bacterial blight, brown spot, sheath rot, and blast diseases. Simulation results show that the proposed model accurately classifies the diseased and normal images with an accuracy of 98.9%, 95.78%, 92%, 94%, and 90.57% for blast affected, bacterial blight, sheath rot, brown spot, and normal rice leaf images. Chechlin’ ski et al. [95] explored CNN for weed identification in four plant species at different growth level and under varying light conditions. CNN architecture combines U-Net, MobileNets, DenseNet, and ResNet models for classification of weeds in crops. In [96]–[99] author has reviewed machine and deep learning techniques for weed, pests and disease identification, and classification in crops at different growth stages. Table 6 presents a comparative study of different ML algorithms for disease and weed identification. TABLE 6 Different ML Algorithms for Disease and Weed Identification D. Drip Irrigation In the modern era, irrigation for crops has been improvised using the concept of drip irrigation [100], where the system consists of thin plastic tubes placed in or above the soil along the vertical rows of the plants for nurturing the water supply to the crops. Employing the proper operational management of drip irrigation, minimizes the utilization of water supply for crop production, and provides a better yield of crops. Socio-economic and environmental demands have widely appreciated in use of drip irrigation on farmlands for agriculture, especially for the high cost valued crops i.e., vegetables and fruits. Furthermore, drip irrigation is based on the low-pressure watering system in comparison to sprinkler systems; this makes the system more efficient in terms of energy consumption [101]. Various advantages have been observed using drip irrigation in agriculture over other irrigation systems which include sub-irrigation systems or sprinkler irrigation systems. These advantages are entitled to minimal usage of water supply, usage of soluble fertilizers through a drip irrigation system, automated system, minimization of soil erosion, uninterrupted activities, minimized weed problems, facilitation of double-cropping. Precision irrigation is another innovative approach in intelligent farming where it uses the water intelligently that further helps the farmers to achieve better yield in crops with minimal water usage. It can also be featured as providing the right amount of water, at the right time and the right place in the field. It focuses its implementation based on variable rate irrigation (VRI) methods employing drips or sprinklers. [102]–[104]. Advancements in the field of on-farm sensor technologies, weather forecasting, IoT based sensor detection system of vegetation and precision-based smart irrigation produces a huge size of data that ultimately benefits the farmers in optimizing the usage of water resources, improve the yield of crops and maximizes the profit of farmers [105]. ML and DL and reinforcement learning are employed on the historical data and it provides various opportunities for real-time prediction and decision making purposes for smart irrigation which are solely based on the data collected by the sensors and IoT enabled systems [106]–[109]. Roberts et al. [110] have discussed that a sensor-based control system might create some bottleneck in terms of reducing the reliability of decision support tools on process-based crop models, which further may require costly calibration and affect in generating an uncertain representation of soil-plant-atmosphere processes. Further, ML techniques have been employed extremely well for protection analysis of hydrological processes i.e., soil moisture and groundwater levels [111], [112]. Li et al. [113] utilized ANN for estimating nitrate distribution in different types of soils under a drip irrigation system. Kavianand et al. [114] proposed a fully automated drip irrigation system based on the ARM9 processor along with different kinds of sensors equipped for monitoring the PH content and nitrogen content of the soil and controlling the irrigation of the field. Emmanuel et al. [115] establishes an experimental set-up in a greenhouse in Malaysia to monitor the growth of mustard leaf vegetable plants through IoT devices and alongside developed a data-driven model of drip irrigation system. Soil moisture, irrigation volume, evapotranspiration were measured through sensors and were given to the Raspberry Pi 3 controller for storing it in the cloud. This data was utilized by different predictive models ARX, BJ, and state-space models to predict soil moisture content for an optimized drip irrigation system. ARX model outperforms other predictive models in terms of MSE and response time. Seyedzadeh et al. [116] explored ML algorithms to optimize the uniform emitter discharge rate of drip irrigation system under varying pressure and temperature conditions. In this model operating pressure, water temperature, discharge coefficient, pressure exponent, and nominal discharge were taken as input parameters while ration of emitter discharge to nominal discharge is taken as output temperature. Authors explored four different ML algorithms for optimizing emitter discharge rate and simulation results show that LS-SVM presents best results with the least error of mean absolute error. Peng et al. [117] utilize soil moisture, soil electrical conductivity, air temperature, and light intensity parameters to build an optimized irrigation prediction model using backpropagation NN in China. The proposed prediction model presents good results with MSE of 0.00857724. The authors also identified an optimized layout and network arrangement for pipe in a drip irrigation system using computational fluid dynamics (CFD) software. The simulation results present that the H-shaped network layout is more suitable for field crop irrigation than the comb-shaped and fish bone-shaped layout. Drip irrigation system gives the best performance when the wetting front dimension, i.e. diameter, depth, and upward movement are optimized. Shiri et al. [118] explored soft-computing approaches viz., gene expressions programming (GEP), and RF techniques in modeling wetting front dimensions over different soil types for surface and sub-surface irrigation system. Proposed model, best predicts ETc with an improved correlation coefficient and decreases MSE and MAE. Elnesr and Alazba [119] explored ANN for predicting the wetting front dimensions from the dataset of a well-tested HYDRUS 2D/3D model. The simulation results show that the proposed model has a good correlation of 0.93-0.99. Chang et al. [120] developed a smart irrigation model based on ML with the LoRa P2P network to learn the irrigation experiences from the expert farmers working on greenhouse organic crops. Singh et al. [121] have discussed an ML and IoT based model for soil moisture prediction during irrigation. Torres-Sanchez et al. [122] proposed a decision support system for irrigation management of citric crops in southeast Spain. In the proposed model smart sensors are deployed in the field to monitor water supplied previous week, weather data, soil water status, and based on this data three regression models SVM, RF, and Linear regression was trained to build the irrigation decision support system. RF best predicts with comparatively less prediction error. Hellín et al. [123] explored the Partial Least Square Regression (PLSR) and Adaptive Neuro-Fuzzy Inference System (ANFIS) model for building a smart irrigation decision support system crops in southeast Spain. Goumopoulos et al. [124] proposed a real-time adaptable intelligent and autonomous closed-loop irrigation management system. The authors built an experimental set-up in a greenhouse and deployed wireless sensors for monitoring the plant growth and environmental conditions along with plant growth control actuators. Estimation of evapotranspiration (ETc) plays a vital role in water resource management system. Chen et al. [125] estimate crop actual ETc from temporal convolution network (TCN) from the dataset of lysimeters for maize under drip irrigation with film mulch. Simulation results show that the proposed model best predicts ETc with an improved correlation coefficient and decreases MSE and MAE. Table 7 presents a comparative study of different ML algorithms for drip irrigation. TABLE 7 Different ML Algorithms for Drip Irrigation E. Livestock Production and Management Livestock production is basically related to the production and management of cattle i.e., sheep, pigs, etc. for human consumption in terms of meat. Livestock production and their management are based on the farming parameters of these cattle i.e., health, food, nutrition, and behaviour to optimize their production in such a way that the economic efficiency of this livestock can be maximized. In the present scenario, Artificial intelligence, IoT and Blockchain technologies [126] are widely explored to improves livestock sustainability and for analysis of their chewing habits, eating patterns, their movement patterns i.e., standing, moving, drinking and feeding habits, indicate the amount of stress the animal is going through which in turn helps in predicting the vulnerability to disease, weight gain, and production of the livestock. Furthermore, an ML-based weight predicting system can help in the estimation of their body weight 90–180 days before the slaughtering day. According to these analyses and estimations, farmers can change their diet plans and living conditions for their better growth in terms of health, behaviour, and weight gain which in turn will improve the economic efficiency of these livestock [127], [128]. Villeneuve et al. [129] build a decision support system that encounters not only real-time data but also expert knowledge for precision sheep farming. Livestock production and management can be further classified into two sub-categories, i.e., animal welfare and livestock production. Animal welfare generally deals with the animal’s health and their well-being; for this ML techniques are applied to their health monitoring feature for prospective of early disease detection. Whereas, livestock production employs the ML on the estimation of the balanced production of livestock for the producers to achieve economic benefits. Dutta et al. [130] described a procedure for the classification of cattle behaviour employing the ML techniques for data collection using collar-based sensors i.e., magnetometers and three-axis accelerometers. In this study, events such as oestrus and dietary changes on cattle have been analyzed for their well-nutrition. Pegorini et al. [131] presented an automatic identification and classification of chewing habits of claves employing ML-based techniques for analysing their health and behavioural patterns. Ebrahimie et al. [132] proposed ML predictive model for estimating Sub-Clinical Mastitis (SCM) from milking parameters in dairy herds. Mastitis is an inflammatory disease that is widely affecting the dairy industry. Author’s explored four classification models decision trees, stump decision trees, parallel decision trees, and random forest to discover SCC independent of Somatic Cell Count (SCC) which is widely used to measure SCM worldwide. RF with Gini Index criteria best predicts SCM with an accuracy of 90%. Ebrahimie et al. [133] explored the attribute weighting model (AWM) for identifying lactose concentration and electrical conductivity in milk, which are two of the major indicators of SCM in dairy cattle. Hyde et al. [134] also explored RF to predict the route of transmission of germs and classify them into contagious (CONT) or environmental (ENV) with ENV further sub-classified into non-lactating “dry” period (EDP) or lactating period (EL). The simulation results show that an accuracy of 98% was achieved for discovering CONT vs ENV and 78% for discovering EDP and EL. Esener et al. [135] utilized spectral profiles dataset to discriminates CONT and ENV strains using GA, NN, and quick classifier. Ebrahimi et al. [136] predicted sub-clinical bovine mastitis using a large milking dataset collected through an automated in-line monitoring system in commercial New Zealand dairy farm. The simulation results show that GBM outperforms other ML model and best predict sub-clinical bovine mastitis with an accuracy of 84.9%. Sharifi et al. [137] explored meta-analysis and decision trees data mining tools to discover genes that can help to find mastitis in dairy cattle. Machado et al. [138] explored the RF model to identify factors influencing the occurrence of Bovine viral diarrhea virus (BVDV) viral disease in cattle in southern Brazil. The proposed approach identifies that insemination, the number of cattle in neighbouring farms, and routine rectal palpation are among the main factors of the occurrence of this disease. Matthews et al. [139] developed an ML-based automated monitoring system for tracking animal behaviour and movement i.e., standing, moving, feeding, and drinking by employing the depth video cameras and sensors. Qiao et al. [140] explored the DL technique Mask R-CNN for examining cattle health and welfare information in precision livestock management. The proposed model extract key features from image frames, enhance the image to remove non-uniform illumination shadow influences, segment image of cattle from the background image using the Mask R-CNN DL tool, and lastly extract cattle contour lines from the segmented image. The proposed approach outperforms SharpMask and DeepMask image segmentation models with mean pixel accuracy of 0.92 and an average distance error of 33.56 pixels. Liakos et al. [141] explored ML model for predicting healthy cattle and cattle suffering from lameness utilizing basic features of cattle which includes per day habits of cattle like steps taken, overall walking, lying, and eating habits. Morales et al. [142] employed a method based on SVM for early detection, warnings, and production issues of eggs in the poultry farms. The simulation results show that the proposed technique alerts a day before with an estimation accuracy of 0.9854. The identification of livestock is an important aspect of monitoring growth and animal welfare. Hansen et al. [143] explored deep learning techniques CNN for identifying pigs faces from the dataset of digital images of pigs obtained from commercial farm environment where the parameters such as dirt and lighting are highly unpredictable. The proposed approach accurately predicts the faces with an accuracy of 96.7%. Fenlon et al. [144] build a decision support system using predictive ML algorithms to provide calving assistance in the dairy industry. Four ML techniques multimodal regression, decision trees, RF, and NN were explored to predict three calving difficulties unassisted, slight assistance, and veterinary assistance. The simulation result shows that NN and multimodal regression models accurately classify 75% of calving difficulties with an average prediction error of 3.7% and 4.5%. Fenlon et al. [145] analyzed calving difficulties in dairy herds in Ireland using ML algorithms. A dataset of parity, log days in milk, inter-service interval, difficulties faced in the last calving, herd body conditions were built to predict conceptions using artificial insemination in the Iris dairy industry. Logistic regression outperforms RF, decision trees, and Naive Bayes in predicting conception using artificial insemination. Borchers et al. [146] explored RF, linear discriminant, and NN for calving prediction in dairy cattle by examining their behaviour which includes number the of steps, lying time, standing time, transition from one state to other and total motion 14 days before the predicted calving date. Although, the innovative algorithms play a crucial role in livestock management but combining livestock data with public data will improve precision livestock farming standards [147]. Table 8 presents a comparative study of different ML algorithms for livestock production and management. TABLE 8 Different ML Algorithms for Livestock Production and Management F. Intelligent Harvesting Techniques Smart harvesting systems helps the farmers to harvest agriculture goods by reducing human efforts. In this approach, technologies such as smart sensors, robotics, UAVs, and IoT devices [148], AI, and ML-based computer vision techniques are employed to intelligently harvest the crops. The research community has provided a comprehensive review of different intelligent techniques used to automate the agriculture industry [149]–[151] and have analyzed the potential and challenges of this decision support system [152]. In the last few years, different robots have been developed for harvesting fruits and vegetables [153]. Smart harvesting offers better insight into the crops and helps farmers to achieve the potential harvest of crops which leads to increased productivity. Smart harvesting system has numerous advantages in comparison to traditional harvesting approaches like it requires less labour, optimized crop yield, maximum probability, better insight into crops, reduced cost of harvesting, and cost-efficient production. A significant problem in the Japanese agriculture industry is a labour shortage. Sakai et al. [154] utilized machine vision for asparagus robot harvesting in Nagasaki prefecture. The speed of asparagus robot harvesting is three times faster than the human being. Since asparagus harvesting is modeled on their size and doesn’t require color properties thus laser sensor is used to collect 3D distance information in the proposed work. Monta et al. [155] also explored laser sensors along with color cameras for tomato harvesting through robots. Preter et al. [156] developed an autonomous system consisting of e-vehicle, cameras, robotic arm, localization system, gripper, quality monitoring, and logistic handling system, which can efficiently detect, plucks, and puts the strawberries in a box. The proposed robot prototype is fast enough to pluck the fruit in just 4 seconds. Hayashi et al. [157] practically evaluated the performance of strawberry harvesting robots in a greenhouse test field. The proposed autonomous system efficiently access the fruit position and its maturity level and pick the fruit with and without suction in a duration of two to three weeks without damaging the fruit. Horng et al. [158] proposed a smart harvesting system that employs IoT and smart image recognition systems for the detection of mature crops using object detection feature trained on MLP neural network. The mature crop can be harvested using a robotic arm whose movement is predicted using ML algorithms. Zhang et al. [159] explored Regions-CNN (RCNN) for multi-class canopy object detection in shake and catch the apple harvesting system. A dataset of RGB images was created in the commercial orchard using a Kinect v2 sensor and pre-trained RCNN is utilized for real-time detection of apple, branches, and trunks. The authors also developed an estimation algorithm to predict shaking location based on the results of RCNN. Spectral and thermal images have also been explored for the detection of fruits and vegetables [160], [161]. Zhang et al. [162] investigated eleven canopy parameters using principal component analysis (PCA) and classified the removal status of apples into mechanically harvested and mechanically unharvested. Zhang et al. [163] reviewed technology progress in the mechanical harvesting of apples which includes shake and catch, robots, and harvest assist platforms. Pise and Upadhye [164] explored Naive Bayes and SVM ML techniques for grading of harvested mangoes based on their color, size, features, quality, and maturity. Grading of fruits increases the profit of the agriculture and food industries. A mango image dataset comprising of three different colors red, green, and yellow is created and is used for training and testing the ML algorithm. The proposed approach presents limited scope as it can detect defects in a particular surface area which can be overcome by creating a dataset of rotational view images. Wu et al. [165] explored NN for recognition, classification of fruits and vegetables, and obstacle avoidance in a harvesting robot. Table 9 presents a comparative study of different ML algorithms for intelligent harvesting. TABLE 9 Different ML Algorithms for Intelligent Harvesting SECTION V. IoT Applications in Precision Agriculture Precision agriculture refers to a system with minimizing direct involvement of the caretaker/farmer except when there is an urgent need or an emergency i.e. when there is a failure in the system. IoT helps in maintaining the defined standards of parameters needed for day to day work in agriculture. The parameters can be measured using the required sensors and can be uploaded to an IoT cloud for remote monitoring so that the direct involvement of farmers is minimized. The IoT cloud can be used for control purposes also, say for example in detecting and avoiding animal intrusion in the agriculture field. Sensors are an integral part of IoT for precision agriculture without which the monitoring and controlling becomes next to impossible task. Figure 6 shows the trend search of keywords “IoT in agriculture” and “sensor in agriculture” on google in the last 10 years. Apart from monitoring and controlling, IoT in agriculture is also used as data-storage technology. Parameters like properties of soil, crop yield, seasonal behaviour data, temperature changes, etc can be stored on the IoT cloud which will be helpful in analyses, prediction, and deciding on estimated crop production. FIGURE 6. Google trend response for keywords IoT in agriculture and sensor in agriculture for the last 10 years. Show All A. Sensors for IoT in Precision Agriculture IoT is defined as the interconnection of things, where one example of a thing is a sensor. A group of sensors can communicate with every other sensor and thereby with the control center. A WSN in IoT has the benefits of increasing the efficiency of production, enhancing the yield quality, detecting and avoiding plant-eating pets, detecting the fires in the farms [166]. IoT has helped in increasing the scope of farming, animal, and pet rearing along with smart irrigation [167]. Sensors form an integral part of IoT architecture in agriculture. A sensor is defined as a transducer that converts the sensed parameter (soil moisture, for example) into the equivalent electrical signal. Depending on the nature of the output signal they generate, sensors are classified as analog or digital sensors. An analog sensor’s output needs to be converted to digital before it is being fed, processed by any IoT system. On the other hand, sensors that generate signals in digital form can be directly connected to any IoT system. Table 10 compares the list of some important sensors applicable in precision agriculture. Addressing the complete list of sensors available for precision agriculture is beyond the scope of this article, although, table 10 provides the list of sensors and their parameters that are very widely used and covers almost every aspect of IoT in agriculture. A pair of sensors and actuators can be used to collect information about some of the vital parameters of precision agriculture and react to perform predefined action whenever required. IoT plays an important role in assuring that the action performed happens instantaneously with minimum delay. The factors that can affect the real-time decision making and causes a delay is the tolerance of the measuring parameter and the communication protocol used. The operating temperature where the sensors are placed have a proportional effect on tolerance. An increase temperature on either side will increase the tolerance of the measuring parameter and sensor reading will deviate the value of the measurand from the actual value. The communication protocol is used to send the readings of the sensor to the microcontroller from where the value will be uploaded to the IoT cloud. The data rate of communication protocol decides the time required for this data transfer. TABLE 10 Sensor Parameters Used in Precision Agriculture B. Wireless Sensor Networks in Precision Agriculture WSN is the collection of spatially displaced sensor deployed to monitor the physical parameters of the environment and coordinating the collected data at central location. IoT transfers the recorded data to cloud which is further processed and analyzed through intelligent algorithms. In precision agriculture integration of artificial intelligence with WSN allows real time monitoring and intelligent decision making in agriculture fields. IoT sensor network which includes soil moisture senor, electrochemical sensor, optical sensors, etc. continuously monitor the field data and works as a training data for ML and DL algorithms. Edge computing enabled AI systems assist in reducing the amount of data to be uploaded to IoT cloud by identification of meaningful data to be communicated and discarding the redundant data. Intelligent processing of data generated from nodes result in better management of sensor network In [185] author utilized AI driven sensor network to classify land as suitable, more suitable, moderately suitable and unsuitable after every cultivation. In [186] author developed a power efficient WSN using Arduino microcontroller and ZigBee module to monitor and control essential parameters that effect crop growth such as soil and weather conditions in Florida, USA. In [187] author integrating sensor nodes with AI systems to reduce the power consumption of nodes by optimizing the performance and data transmission of respective nodes. RNN based Long-Short term (LSTM) network was built which increases the runtime of a single sensor and guarantees 180 days autonomous operation using Li-ion battery. The proposed system continuously monitors the growth dynamics of plant leaves. In [188] author presents an autonomous system built with low power sensor nodes and IoT based cloud platform to estimate level of phosphorous in soil through ANN. Author incorporates dynamic power management system to maintain balance between energy consumption and estimation accuracy. In [189] author presents GA optimized WSN for precision agriculture applications. Thus, we conclude that integrating artificial intelligence with WSN, IoT plays a key role in assuring the best yield of crops. SECTION VI. Assessment and Evaluation of Knowledge-Based Agriculture System In this section ML algorithms used by different researchers in the precision agriculture system are analyzed. The agriculture industry is facing many challenges across the world, and a knowledge-based agriculture system allows sustainable use of resources by the farmers aiming to get maximum output from the agriculture land. There are two basic stages in precision agriculture, i.e. pre-processing stage and processing stage. In the pre-processing phase market trends are studied and based on geographical conditions and soil properties of the land seeds are selected and the land is prepared for precision agriculture system. In the post-processing stage machine vision techniques are explored for disease and weed identification while intelligent techniques are used for irrigation and harvesting. In this article, author reviewed and discussed 70 articles where multiple ML algorithms are presented for performance optimization of the agricultural cycle. Figure 7 shows the classification of articles based on different applications of precision agriculture. FIGURE 7. Classification based on agriculture cycle. Show All Figure 8 depicts the cumulative distribution of the ML and DL models used by researchers in precision agriculture. The graph depicts the broad categorisation of the techniques with their applications to agricultural cycle. It has been observed that in majority of the literature the researchers have applied multiple algorithms for classification and parameter prediction. Regression models and ANN together make up around 65% of the AI techniques employed by researchers. Hence, it is important to investigate the techniques used and compared by the authors. The individual best performing algorithms have already been covered in appropriate sections, however the figure 8 depicts the distribution of the various regression algorithms and DL models throughout the literature. ELM algorithm is widely explored in prediction of soil properties such as soil moisture, soil temperature, surface humidity, ETc. ANN accurately predicts the rainfall and crop yield across different regions of globe. DL based CNN model finds wide applications for accurate disease and weed classification in agriculture crops. ANN model best predicts the nitrate content and water requirement in drip irrigation system. SVM regression model estimates the emitter outflow discharge under varying temperature and pressure conditions. Decision Tree algorithm accurately identify the chewing habits and predicts SCM in dairy herds. CNN have widely explored for livestock identification. Metaheuristic optimized ML algorithms are also explored by researchers in precision agriculture. FIGURE 8. ML techniques used in precision agriculture applications. Show All In the reviewed articles, authors have used around 22 different regression algorithms for prediction, however 5 most commonly used algorithms are identified and depicted in the figure 9. Remaining 17 algorithms which are used either only for comparison or employed as a support algorithms have been classified into others. FIGURE 9. Regression algorithm in precision agriculture. Show All DL models have contributed significantly and outperforms ML classification algorithms in classification of crop disease and weed as well as for livestock diseases identification. Figure 10 shows CNN, ANN and RNN algorithms explored in precision agriculture. In the reviewed articles, authors have used around 10 different DL/NN algorithms for prediction/classification, however 8 most commonly used algorithms are identified and depicted in the figure 10. Remaining 2 (LeNet, and Caffee) algorithms which are used either only for comparison or employed as a support algorithms have been classified into others. FIGURE 10. Classification algorithm in precision agriculture. Show All A. Performance Comparison of ML Algorithms in Precision Agriculture The application of ML and DL algorithms highly depends on the agriculture cycle and the dataset involved. This section discusses the advantages and limitations of various ML and DL algorithms such as regression and classification algorithms based on the agriculture cycle involved. 1) Soil Properties and Weather Prediction The application of AI techniques in prediction of soil parameters and weather is dependent on various factors. The researchers generally employ around 3 to 4 algorithms in for prediction and select the algorithms which has most accurate prediction and is robust to factors such as: noise, non-linearity, outliers etc. the most commonly employed algorithms are ELM, RF, SVR, and cubist algorithm. Advantages of using ML in prediction of soil properties and weather pattern: Non-linear dataset – these predictions often attributes a non-linear dataset which can be utilized for accurate prediction by regression algorithms such as: ELM, RF, SVR Large dataset – the dataset for is often obtained from satellite which can be well handled by the regression algorithms with less convergence time and accurate predictions. Insensitivity to outliers – Weather patterns often encounter outlier events which may affect the prediction accuracy, however algorithms such as ELM, NN are robust to outliers and provide accurate predictions. Accurate prediction – prediction of parameters using ML exhibit low error indices such as RMSE, and R2 which are standard measures of accuracy for statistical analysis. Challenges and limitations in prediction of soil properties and weather pattern: Varying geographical conditions poses a challenge for universal design of the prediction algorithms. Soil parameters prediction is highly dependent on the sample selection philosophy. Dataset selection and filtering is a challenge for researchers with non-computing background. 2) Crop Yield Prediction The application of AI techniques in prediction of crop yield is a mammoth task and lack of availability of a universal model makes designing of the algorithm challenging. The most promising algorithms for crop yield prediction are regression algorithms, and neural networks. Advantages of using ML in crop yield prediction: Complex dataset – crop yield prediction involves enormous dataset composing of satellite data and/or historic data. Faster and accurate predictions can be made by utilizing the AI techniques such as regression algorithms (SVR, RF) Neural networks (CNN). Parameter variation – the crop yield depends on a lot of parameters, like climatic factors, soil quality, NDVI, altitude, air parameters. The AI based prediction systems handle the parameters dependency efficiently. Accurate prediction – prediction of parameters using ML exhibit low error indices such as RMSE, and R2 which are standard measures of accuracy for statistical analysis. Challenges and limitations in prediction of crop yield: Varying parameters and complex datasets pose a challenge for universal design of the prediction algorithms. Dataset selection is critical due to the complexity; as an improper selection of data may result in underfit/overfit prediction pattern. 3) Disease and Weed Detection The applications of AI techniques in disease and weed detection primarily depends on the advances in image processing. CNN’s are the most prominent choice for building a disease identification system. Training dataset will govern the performance of the algorithm, although these are available in open-source format, users have to be cautious while using the dataset. Advantages of using ML in detection of weed and disease in a crop field: Prediction accuracy – AI offer accurate detection of disease and weeds with an accuracy of 99% which is better compared to manual/classical techniques. Robust prediction – the algorithms can predict the disease/weed even with smartphone images, which is commonly available with farmers. Easy configuration – with CNN being the most common and reliable technique, designing a disease/weed detection system is not a complex job unlike other systems discussed in text. Challenges and limitations in detection of weed and disease in a crop field: The accuracy of prediction depends on the quality of training dataset some of which is available as an open-source dataset, but is applicable to only a limited number of crops. Improperly labelled data may result in a disastrous prediction system, as the training of the system plays a major role in the performance of the system. Overtraining the model may result in a sensitive prediction system. 4) Drip Irrigation Smart irrigation systems are not only crop friendly but are environmental friendly too. The combination of IoT with the AI not only reduces the manual intervention but also utilizes the available in an optimum way to ensure no adverse effect to environment. Regression and Advantages of using ML in drip irrigation for an agricultural field: Optimum resource utilization – accurate estimation of irrigation requirements results in a system which optimizes the resource (water, electricity) utilization (NN algorithms). Crop protection – optimized irrigation practices minimizes water related damage to the crops and hence increases the crop yield. Robust to weather variations – an accurately designed AI based (Regression algorithms) irrigation system handles the random weather events in a better way when compared with the non-AI based irrigation methods. Challenges and limitations in drip irrigation for an agricultural field: Accurate prediction sometimes depends on the number of sensors and hence increases the initial investment of the farmers. An incorrect sensor placement in the filed affects the accuracy of the system, hence sensor optimization becomes imperative in designing a smart irrigation system. The architecture of prediction system highly depends on the dataset; hence no universal guidelines can be laid out for system design. 5) Livestock Production and Management The livestock management primarily focuses on the well-being of the farm animals and uses advanced image recognition (CNN) algorithms, and regression techniques to detect and predict the disease/ disease spread. Advantages of using ML in livestock production and management: Decreased risk of diseases – AI systems assists in identifying the livestock diseases and also helps in combating the disease, by predicting the root of diseases and transmission (Regression algorithms). Minimization of disease spread – timely diagnosis and treatment reduces the risk of spreading the disease. Psychological analysis – advanced image recognition and behavioural analysis (CNN techniques) help is detecting the stress in animals ensuring heath of the livestock. Challenges and limitations in drip irrigation for an agricultural field: With varying geographic and climatic conditions the attributes of the cattle and diseases changes hence, no universal system can be designed to cater to the diversities. Some viruses are difficult to predict even using the state-of-art prediction algorithms. 6) Intelligent Harvesting The applications of AI techniques in harvesting is primarily an assistive technology for automatic harvesting systems. Harvesting prediction system largely relies on the advances in image processing and CNN’s are the most prominent choice for building these systems. Advantages of using ML in intelligent harvesting: Assistive technology – AI in conjunction with existing harvesting robots exhibit high accuracy in harvesting. Image processing – the identification of harvesting relies on the state-of-art image processing algorithm (CNNs) and hence the developments in the image processing algorithms result in direct accuracy enhancement of intelligent harvesting techniques. Universal algorithms – the AI harvesting techniques largely depend on image recognition methods, hence CNNs can easily be deployed for implementing intelligent harvesting techniques. Challenges and limitations in intelligent harvesting: The accuracy of the prediction systems largely depends on the training dataset, hence accurately labelled dataset is a primary requirement of implementing an intelligent harvesting system. Inaccurate harvesting recognition system result in economic loss for farmers, as a delay in harvesting might lead to an overripe crop or early harvesting might lead to rejection of the product. SECTION VII. Challenges and Limitations of Artifical Intelligence in Precision Agriculture Artificial intelligence has the potential of playing an important role in meeting the food requirement of entire world. However, there are certain challenges which are hampering its adoption in agriculture industries which are outlined as follows: A recent government survey in India estimated that literacy rate of Indian farmers is very low therefore bridging the gap between farmers and technology is a challenging task. Farmers are less motivated to come out from their comfort zone and learn digital skills to improve their farming standards. Agriculture lands are mostly situated in rural areas. Implementation of IoT architecture and WSN which requires cloud services for data storage and analysis is a big issue in rural areas where reliable internet connectivity is not available. Accurate prediction and classification through cognitive ability of machines is difficult in varying geographical conditions. Initial set up of digital farming which includes hardware and software requires huge investment. Deployment of smart sensors and other electronic gadgets requires heavy energy consumption. SECTION VIII. Future Trends of Artifical Intelligence and IoT in Precision Agriculture Agriculture industry is globally US$5 trillion industry and now it has been revolutionized with artificial intelligence and IoT technologies. These innovative tools are assisting famers to improve crop yield, monitor soil parameters, livestock health and temperature conditions, control pests and improve other agriculture related tasks. Conventional ML and DL models such as SVM, RF, ANN finds difficult to accurately estimate soil parameters and weather conditions in varying ecosystem. Therefore, swarm intelligence optimized robust and adaptive ML and DL algorithms such as SVM-PSO, ANN-GWO algorithms can be explored to effectively forecast different parameters in precision agriculture. In large agriculture fields swarm intelligence inspired autonomous system can be built for crop health and growth monitoring. UAV swarm can be utilized for near real time field and livestock monitoring through computer vision and DL algorithms and accordingly swarm of UAV can be used for spraying of pesticides and fertilizers in the infected crops. Greenness of crops can be identified through UAVs installed cameras and an automated irrigation system can be built in large agriculture fields. Swarm of mobile robots can be used in the agriculture fields to efficiently automate task such as harvesting, weed identification and elimination, etc. Metaheuristic algorithms can be explored for nodes localization in agriculture fields in order to optimize the sensor deployment in the field and keep the minimize cost to farmers. Offline service chatbots can be built to assist farmers in developing countries where farmers don’t have good internet connectivity. These chatbots can assist farmers by providing timely advice based on expert recommendations and will help to resolve their specific farming problems. Artificial intelligence assisted renewable energy plants can be installed in agriculture lands to maximize the power output of clean energy in unpredictable weather conditions. This will allow for sustainable agricultural practices. Artificial intelligence can also be explored in vertical and soilless agriculture. In near future artificial intelligence systems, robotics and smart sensor technology will automate the whole farming process starting from seed sowing to intelligent fruits and vegetables harvesting and packaging. SECTION IX. Conclusion Precision agriculture is empowering the farmers with technology intending to get optimum outputs with precise inputs. IoT enabled smart sensors, actuators, satellite images, robots, drones are some of the key technological revolutions that boosted the agriculture industry. These components play a vital role in collecting real-time data and accordingly making decisions without human support. Artificial intelligence which is the automation of intelligent behaviour is continuously benefiting our planet and helping humans in various aspects of life. In this paper, authors have reviewed ML applications for precision agriculture. The impact of AI and IoT in smart farm management is discussed with a brief introduction to ML algorithms which are most commonly used in precision agriculture. Regression algorithms are the backbone for soil properties, weather, and crop yield prediction. DL algorithms such as CNN and ML classification algorithms such as SVM, Decision trees, and RF were explored for the identification of disease and weeds in the plants. Smart irrigation systems and harvesting techniques play an important component in precision agriculture as these techniques quickly complete the work and reduces human labour. Drones and robots enabled with a digital camera are employed for this work. Livestock management is an important concern for farmers across the world. Knowledge-based agriculture system which includes smart IoT devices and AI tools efficiently handle livestock management. As a scope of future work, NLP based chatbots can be built for famers and more ML, DL and hybrid algorithms can be explored in the agriculture industry for sustainable use of available resources. Authors Figures References Citations Keywords Metrics More Like This Internet of Things and Wireless Sensor Networks for Smart Agriculture Applications: A Survey IEEE Access Published: 2023 Precision Agriculture Using Internet of Things and Wireless Sensor Networks 2023 International Conference on Disruptive Technologies (ICDT) Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 3:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: With the emergence of Agriculture 4.0, automated, real-time irrigation management systems based on IoT and machine learning technologies are becoming crucial for efficient water resource utilization and yield optimization. This study presents a comprehensive review of real-time irrigation management systems, focusing on the integration of IoT devices, data collection and transmission, processing and analysis, decision-making, and automated action. Recent advances in these systems, including hardware, software, algorithms, and applications, are discussed. Furthermore, challenges and research gaps are identified, providing directions for future research and development efforts.
  Extract 2: The adoption of smart farming techniques, including automated irrigation systems, has the potential to enhance agricultural productivity and sustainability. This paper presents a comprehensive review of automated irrigation systems, covering various aspects such as hardware components, communication technologies, control algorithms, and decision-making strategies. The focus is on real-time monitoring and control of irrigation systems using wireless sensor networks and IoT devices. Additionally, challenges and research opportunities in this domain are discussed to guide future research and development efforts.
  Limitations: >
  Relevance Evaluation: **Relevance to the research questions:**

The paper addresses all the research questions proposed, providing a comprehensive evaluation of the current state and future potential of real-time automated agricultural systems.

**Relevance to the specific point:**

The paper specifically focuses on the requirements of Smart Farming 4.0, addressing its unique challenges and application scenarios. It analyzes various architectures and collaborative computing strategies relevant to real-time automated agriculture, providing valuable insights for future research and development efforts.

**Relevance to the section intention:**

The paper aims to provide a comprehensive and up-to-date understanding of the field, which it effectively achieves through a systematic review of existing literature. The analysis covers a wide range of topics, including cloud-centric architectures, distributed architectures, collaborative computing strategies, and new trends, ensuring relevance to the section's intention.
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: This review paper provides a comprehensive evaluation of the current state and future potential of real-time automated agricultural systems by analyzing relevant literature regarding the specific requirements of the Smart Farming 4.0 paradigm.

**Key Points of the Paper**

- **Cloud Architectures:** Central Cloud Architectures are composed of Batch Architecture for offline processing and Stream Architecture for real-time processing. Lambda Architecture combines both batch and real-time processing, while Kappa Architecture simplifies Lambda Architecture by combining batch and speed layers into a single stream processing engine.

- **Extension of the Cloud Paradigm:** Multi-Cloud Computing and Federated Cloud expand cloud-centric architectures for enhanced redundancy and resource utilization.

- **Distributed Architectures:** Edge Computing brings processing capabilities closer to IoT devices at the network level, while Fog Computing extends cloud data centers as cloudlets or micro data centers, providing computational resources closer to end devices.

- **Collaborative Computing Strategies:** Different collaboration strategies for various levels of processing are identified, namely Edge-Cloud, Edge-Fog, Edge-Fog-Cloud, and Edge-Edge, each addressing specific needs and limitations of IoT use cases.

- **New Trends:** Microservices Architecture decomposes monolithic applications into loosely coupled services, Data Lake/DataHouse provides cost-effective storage for massive datasets, Osmotic Computing dynamically distributes microservices between edge and cloud levels, Dew Computing further improves response times by pushing data and services closer to end-users, and Blockchain enhances security and transparency.

**Relevance Evaluation**

The paper effectively addresses the research questions proposed and provides valuable insights for future research and development efforts in real-time automated agricultural systems. The evaluation is based on a systematic review of existing literature, ensuring a comprehensive and up-to-date understanding of the field.

**Strength and Novelty**

1. **Comprehensive Analysis:** The paper offers a thorough analysis of various cloud-centric architectures, distributed architectures, collaborative computing strategies, and new trends relevant to real-time automated agricultural systems.

2. **Specific Focus on Smart Farming 4.0:** The review specifically targets the requirements of Smart Farming 4.0, addressing its unique challenges and application scenarios.

3. **Identification of Research Gaps and Future Directions:** The paper highlights areas where further research is needed, such as standardization in osmotic computing and distributed deep learning across different layers.

4. **Practical Implications:** The findings provide practical guidance for stakeholders in the agricultural industry and researchers aiming to develop and implement effective real-time automated agricultural systems.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Related works 3. Methodology 4. Architectures 5. New trends 6. Towards Agriculture 5.0 7. Conclusion Declaration of Competing Interest Acknowledgment References Show full outline Cited by (28) Figures (14) Show 8 more figures Tables (17) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Journal of King Saud University - Computer and Information Sciences Volume 34, Issue 9, October 2022, Pages 7494-7514 Cloud and distributed architectures for data management in agriculture 4.0 : Review and future trends Author links open overlay panel Olivier Debauche a b c, Saïd Mahmoudi a, Pierre Manneback a, Frédéric Lebeau b c Show more Share Cite https://doi.org/10.1016/j.jksuci.2021.09.015 Get rights and content Under a Creative Commons license open access Highlights • Cloud architectures used in Agriculture 4.0. • Distributed Architectures and Cloud Computing complements. • Strategies of association between Edge, Fog, Cloud. • New architectural and computing trends. Abstract The Agriculture 4.0, also called Smart Agriculture or Smart Farming, is at the origin of the production of a huge amount of data that must be collected, stored, and processed in a very short time. Processing this massive quantity of data needs to use specific infrastructure that use adapted IoT architectures. Our review offers a comparative panorama of Central Cloud, Distributed Cloud Architectures, Collaborative Computing Strategies, and new trends used in the context of Agriculture 4.0. In this review, we try to answer 4 research questions: (1) Which storage and processing architectures are best suited to Agriculture 4.0 applications and respond to its peculiarities? (2) Can generic architectures meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal development possibilities that allow the transition from research to industrialization? (4) What are the vertical valuations possibilities to move from algorithms trained in the cloud to embedded or stand-alone products? For this, we compare architectures with 8 criteria (User Proximity, Latency & Jitter, Network stability, high throughput, Reliability, Scalability, Cost Effectiveness, Maintainability), and analyze the advantages and disadvantages of each of them. Graphical abstract Download : Download high-res image (103KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Agriculture 4.0Smart farmingSmart agricultureLambda architectureKappa architectureEdge computingFog computingMicro-service architectureData lakeData houseBlockchainOsmotic computingDew computing 1. Introduction Nowadays, the Internet of Things (IoT), also formerly named pervasive Internet, is present in all domains of our daily life and follows exponential growth. The number of connected devices is estimated at the horizon of 2022 at 42.5 billion and at the horizon of 2025 at 75.5 billion1. The global IP traffic is estimated to 333 ZB per month in 20222 with the need to store and treat this data (Carnevale et al., 2019). The European Commission has predicted that 18 billion of 29 billion connected devices will be related to the IoT in 2022 (Agency, 2020). Cisco in a white paper has announced that connected devices to the Internet will generate 850 ZB/year by 2021 (Cisco, 2018). It is difficult to precisely determine the number of connected devices on a world scale, but their number is about several billion. In addition, McKinsey Global Institute predicts a total economic impact of IoT and Edge Computing devices that will reach 11 trillion USD by 2025 (Manyika and Chui, 2015). In the sector of the agriculture, nearly 12 million agricultural sensors installed globally by 2023 with an increase of 20% annually, which is predicted by the Business Insider Intelligence Service (Meola, 2021). Moreover, the smart agriculture business was estimated at USD 13.8 billion in 2020 and is projected to reach USD 22 billion by 2025 at a Compound Annual Growth Rate (CAGR) of 9.8% (Meola, 2021). Within the IoT era, the type of clients is becoming increasingly lightweight. IoT devices and the network environment is gradually changing from high-speed wired networks to unstable wireless communication. Meanwhile, users' demand IoT applications is also shifting to real-time and context-aware service provisioning, making the focus moving progressively from the cloud to the edge (Ren et al., 2017). The cloud is located within the Internet and is geographically centralized, is constituted of a few resourceful server nodes, and is inserted in multi hops in terms of distance among the clients (Munir et al., 2017). Cloud Computing (CC) is a paradigm widely available that offers benefits like minimal management effort, convenience, rapid elasticity, pay per use, ubiquity (Ai et al., 2018), easy maintenance, centralized management, and high server utilization (Shi et al., 2016). Furthermore, resources centralization implies an increase of average network latency, heavy bandwidth utilization, and high processing delay. Indeed, the tremendous amount of data handled in a unique server point can create congestion in the cloud servers and backhaul links (El-Sayed et al., 2017). Nevertheless, the rapid parallel development of the pervasive intelligent device, ubiquitous network, growth in popularity of virtual and augmented reality, self-driving vehicles, UAVs, social networks, networks applications, and services are not without consequences. As a matter of fact, the network bandwidth and speed limit performance and effectiveness of cloud computing especially for real-time and mission-critical applications cannot be guaranteed. Moreover, cloud computing can be hardly adapted or applied to various types of technologies and applications scenarios (Zhou et al., 2017). To address these issues, various extensions of central cloud computing have been proposed by industrial and academics to move computing and storage at the edge of the network close to users. Fog computing uses network elements between the central cloud and the edge of network and absolute edge elements such as microcontrollers close to sensors to process and store data with a distributed manner close to nodes. Whereas, with the developments of mobile devices, some new paradigms close to mobiles users have been proposed. For example, cloudlets or micro data centers are geographically implanted and accessible by means of Wi-Fi protocols; but, this approach does not always guarantee enough network quality. Manufacturers of cellular network equipment have proposed the Mobile Edge Computing (MEC) paradigm that associates fog servers with base stations to provide services to mobile devices. MEC associated with 5G allows to combine an ultra-low latency network with high available bandwidth, and processing resources accessible in the vicinity. The MEC original concept has been extended then to wireless networks and consequently renamed in “Multi-access Edge Computing” (Wang et al., 2020). Agriculture has previously undergone two waves of revolution. The first one was mechanization and the second was called the green revolution with genetic modifications (Saiz-Rubio and Rovira-Más, 2020). Since the late 1990s, the digital transformation of the agriculture in Agriculture 3.0 also called Precision Agriculture has begun with the integration of Geographical Information System (GIS), Global Positioning Systems (GPS), and the usage of sensors have invaded agriculture. They allowed the emergency of image processing, techniques using deep learning, and machine learning in the field of computer vision. This latter is implemented to discriminate weed, identify crops, detect diseases,…etc. The production of a large amount of data by agriculture 3.0 has required the development of big data technologies to process them, reflecting important changes in various fields of research. Collected data must be recorded in a specific format in order to discover patterns, curate errors, eliminate duplicated or inconsistent data, or solve noise problems (Triantafyllou et al., 2019). Smart Farming also called Smart Agriculture or Agriculture 4.0 is a domain of IoT in full growth which bring innovative paths to improve the adaptability, the efficiency, and the resilience of the agriculture of production systems (Iaksch et al., 2021) boost competitiveness and profit (Triantafyllou et al., 2019), allocate resources reasonably, and avoid food waste (Zhai et al., 2020, Wolfert et al., 2017) thanks to the contribution of autonomous context awareness provided by sensors and the capability to execute autonomous or remote actions (Wolfert et al., 2017). Smart Farming displaces the strict application from the farm location to affect related fields such as decision making by farmers, biodiversity, supply chains management, food availability and quality, insurance, and research in environment and earth sciences,… Smart Farming is distinct from other domains of the Internet of Things (IoT) by the observation and action of biological objects (animals or plants). It differs from medical IoT by the fact that there are no issues related to privacy; but, the confidentiality of data is related to production processes. Like most areas of the IoT, Wireless Sensing and Actuating Network (WSAN) use Low-power and Lossy Network organized in hierarchical routing to collect data and actuate devices. Multi-path routing protocols can also be implemented to balance the data transfer load and conserve the energy of limited battery life, basic computational skills, unique communication identifier, and resources-constrained nodes. Due to the limited battery life, it is difficult and sometimes impossible to recharge or replace (Debauche et al., 2021). Moreover, energy-saving and ambient energy techniques must be applied to deal with the active and inactive operational time and schedule information transmission (Triantafyllou et al., 2019). To which objects can be added like connected agricultural vehicles, milking robots, Unmanned Aerial Vehicle (UAV) commonly known as drones, Unmanned Ground Vehicle (UGV) also called robots, mobile devices such as tablets used to encode punctual observations (Debauche et al., 2021), and external sources such as public geo-services (Triantafyllou et al., 2019). The use of IoT in agriculture 4.0 ranges from family farming as for example in India on a very small scale with a few low-cost sensors and actuators to very large scales with thousands of expensive commercial sensors and many connected agricultural pieces of machineries as in the American mid-west. Smart Farming is characterized as aforementioned by a wide variety of objects that can produce the highly contrasted amounts of data from few bytes/s to Gb/s. In addition, the availability of network protocols in rural areas to transmit this data impact also the type of architecture to implement. Applications need treatments in real-time and/or at a different time. The ”real-time” requirements are also very variable depending on the use case. For instance, remote control of drones requires reaction times of at most a few milliseconds while the Variable Rate Fertilizer (VRF) or Variable Spraying (VS) application aim to optimize nutrients and herbicides application respectively need reaction time in a range of few milliseconds to few seconds. The real-time processing for monitoring a herd of cattle is of the order of a few minutes to a few hours. The data retention time is very variable and is highly dependent on each use case. For example, UAVs produce tremendous quantities of images to transfer to the cloud in real-time where they must be quickly processed and stored. They can also be post-processed to extract additional data in batch processing. While UGVs images lose their value after processing and eventually actuating. However, if data is of a special, new or exceptional nature, it can be stored with a view, for example, to improving artificial intelligence algorithms. Other sensors transmit data only when anomalies are detected while others transmit at regular intervals a tiny amount of data. However, the adoption of Smart Farming is hampered by the lack of models to guide stakeholders on how to implement and to deploy dense and heterogeneous IoT-based monitoring systems and manage their interoperability (Triantafyllou et al., 2019). Commercial sensors are very expensive making it impossible for small farms to implement them (Garcia et al., 2020). In addition, two trends are currently opposed. That coming from the manufacturers of agricultural machinery who have developed their ecosystems and who want to extend the services offered to farmers by attracting them into the captive ecosystems in which they are locked. Furthermore, another trend is the development of open ecosystems in which farmers can preserve the ownership of their data and keep control of the processing carried out on this data and of their use. On one hand, farmers are therefore faced with a dilemma where they are in any case forced to use agricultural equipment that collects their data against their will; on the other hand, they want to keep control of their data collected through IoT sensors. Currently, it is difficult to predict which of these two trends will take precedence over the other or whether one of the two will coexist (Wolfert et al., 2017). In this context, both private and public researchers can either use generic commercial platforms offered by cloud players on which they have limited possibilities of adaptation or develop their own architecture on the basis of commercial or free bricks, but with much greater possibilities of adaptation. In this case, the choice is also delicate, and a bad evaluation of the constraints can jeopardize the research project. Due to the recent advances in big data, we present a survey that provides an overview of the state of the art regarding Smart Farming. It aims at summarizing parameters that condition the choice of architecture to collect, process, and store agricultural data. Since there is a wide variety of use cases, it is important to make an informed choice when it comes to architecture. In this way, we address the current gap in the literature with a review of cloud architecture used in Agriculture 4.0 to collect, process, and store data to enlighten the reader about the possible choices and the new trends that emerge. The rest of this paper is structured as follows: The second section is composed of two parts. In the first part, we summarize related previous review in the domain and their contributions, in order to contextualize our contribution to the literature. In the second part, we identify architectures implemented in Agriculture 4.0 use cases. In the third section, we describe the methodology used to identify papers, the conceptual framework used to analyze the literature, and the criteria used to compare the selected architectures. In the fourth section, we present architectures used to collect, process, and store data. We describe successively the cloud-centric architectures, the extension of cloud paradigm, the distributed architecture. In the fifth section, new trends and futures directions are presented. In the sixth section, we discuss the future evolution of Agriculture 4.0 to Agriculture 5.0. Finally, the last section concludes this paper with recommendations and perspectives. 2. Related works We begin our review by identifying the previous review realized in the field of Internet of Things applied to Smart Agriculture to take stock of the state of art and highlighting aspects that have not been explored at the present time. In this section, we focus to achieve two objectives. The first aims to position our work in relation to the existing literature. The second aims to identify architectures commonly used in the case of applications in Agriculture 4.0. 2.1. Previous reviews Reviewed papers presented in Table 1 were selected in the timeframe from January 2017 to July 2021. The major contribution of each paper was extracted and highlighted to show our contribution to the literature. Table 1. Summary of previous review achieved on big data management in a context of Smart Farming. Major Contribution Reference Survey of agro-industrial and environmental solutions for monitoring, control, logistics, and prediction. (Talavera et al., 2017) Diagnosis and analysis of existing IoT deployments in regards to communication protocols. (Ray, 2017) Survey of IoT technologies in agriculture and highlighted the challenges going forward. (Tzounis et al., 2017) Identification of IoT challenges, its application in smart agriculture, and presentation of trends and technological innovation (Elijah et al., 2018) Review of IoT applications in Precision Agriculture, evaluation of previous contributions by researchers, and pathways to future innovation (Khanna and Kaur, 2019) Review of IoT deployment in protected agriculture, identification of its challenges, and prospection of the new research domain. (Shi et al., 2019) Review of existing IoT-based precision agriculture solutions for further achievement. (Ruan et al., 2019) Review, comparison, prospection, and challenges of wireless communication technologies applications in the field of Precision Agriculture. (Feng et al., 2019) Review, case study, and challenges of WSN in environmental behavior. (Shafi et al., 2019) Review, identification, challenges of current and future trends of IoT agriculture. (Ayaz et al., 2019) Survey of IoTbased agriculture, presentation of connection between IoT, big data, and cloud computing, regulation and policies of IoT, and its application in the field of agriculture. (Farooq et al., 2019) Survey of the use of UAVs, an overview of PA, and investigation of 20 UAV applications. (Radoglou-Grammatikis et al., 2020) Challenges of IoT-based agriculture architecture, a summary of existing surveys of smart agriculture. and classification of threats models, study, analysis of challenges and future works of security and privacy of green IoT-based agriculture. (Ferrag et al., 2020) Discuss the role of IoT and big data analysis in agriculture with an emphasis on the commercial status of applications and translational research outcomes. (Misra et al., 2020) resent different solutions to address IoT in arable farming challenges. (Villa-Henriksen et al., 2020) Systematic review presenting how IoT is used with smart farming (Navarro et al., 2020) Methodological review and analysis of IoT components and their applications in smart farming. (Debauche et al., 2021) Review of emerging technologies towards agriculture 4.0 and new pathways to agricultural practitioners. (Liu et al., 2020) Review, classification, presentation, comparison, and challenges of emerging technologies for IoT-based agriculture. (Friha et al., 2021) In the following paragraphs, we will draw a panoramic summary of the existing reviews during the past four years (2017–2021). In 2017, Ray (Ray, 2017) reviewed throughout his paper IoT applications and the challenges that have been faced while IoT deployment to improve farming. Talavera. et al. (Talavera et al., 2017) reviewed agro-industrial and environmental applications that are using the Internet of Things (IoT) for monitoring, control, logistics, and prediction. Tzounis et al. conducted a survey of IoT technologies in agriculture and the challenges that farmers face going forward (Tzounis et al., 2017). Elijah et al. identified the most encountered challenges in the field of IoT applications in smart agriculture and presented common trends for innovative ideas (Elijah et al., 2018). In 2019, Ayaz et al. provided a state-of-art about IoT-based architectures applied in agriculture and identified present and future trends in the same field of study (Ayaz et al., 2019). Farooq et al. presented the ingredients of IoT-based smart farming with used technologies that apply the utilization of network architecture and protocols; in addition to that, they provided an overview of the regulations and policies of the use of IoT in farming regarding security and privacy. They concluded their study by summarizing the main challenges encountered in this discipline (Farooq et al., 2019). Feng et al. provided an overview of the wireless communication technologies in the precision agriculture domain. They benchmarked the prospection and challenges of existing technologies with the regular communication time used (Feng et al., 2019). Shafi et al. conducted a literature review about IoT-based automation of agriculture along with Wireless Sensor Network (WSN). These authors presented a case study based upon two models: 1- a WSN to monitor real-time crop of health conditions, 2- system-base remote sensing imagery to classification between healthy and unhealthy yield (Shafi et al., 2019). In terms of agriculture protection, Shi et al. drew a panoramic review during the last decade to address the challenge and future works to further the research in the field of protected agriculture (Shi et al., 2019). Khanna et Kaur called into an evolutionary scenario to highlight the most significant impact of IoT in Precision Agriculture (PA). They evaluated the contribution of their predecessors and enhanced the challenges to open up a new direction of inspiration and innovation in IoT applied to PA (Khanna and Kaur, 2019). Ruan et al. reviewed literature works from 2009 to 2018 to suggest new ideas for folks interested to conduct research in the field of agriculture IoT, infrastructures, data security, and data sharing (Ruan et al., 2019). In 2020, two studies have been carried out about 20 UAV applications that are devoted to either aerial crop monitoring processes or spraying tasks (Radoglou-Grammatikis et al., 2020) and about the dilemmas that researchers must overcome while deploying IoT in the green agriculture domain (Ferrag et al., 2020). Villa-Henriksen et al. identified different challenges encountered during the implementation of IoT in various applications and proposed different solutions to address them (Villa-Henriksen et al., 2020). Misra et al. discuss the role of IoT and big data analysis in Smart Farming (Misra et al., 2020). In 2021, a recent study conducted by Friha et al. hypothesize the use, application, classification, and comparison of the most developed emerging technologies such as Internet of Things (IoT), Unmanned Aerial Vehicles (UAV), Wireless Technologies, open-source IoT platforms, Software Defined Networking (SDN), Network Function Virtualization (NFV) technologies, cloud/fog computing, and middleware platforms (Friha et al., 2021). In the same year, Debauche et al. conducted a literature review to describe the main components of IoT and its applications in the field of Smart Farming (Debauche et al., 2021). 2.2. Platforms implemented in use cases We grouped applications into 4 categories: (1) Water Management in which we have aggregate all types of water use such as irrigation and watering animals. (2) Plant Disease and Pest groups all use cases in plant’s pathologies detection and treatment of plant pathologies (spraying of fungicides, pesticides, etc). (3) Crop Management brings together all the use cases relating to cropping operations: soil management (plowing, fertilizer application), sowing, weeding, and harvesting. (4) Livestock includes everything related to the breeding of farm animals (nutrition, behavior, diseases, treatments). Table 2 summarizes platform used to implement use cases in Smart Farming classified following our four categories. Table 2. Summary of cloud platforms, databases mentioned in Smart Farming reviews. Empty Cell Water Management Plant Diseases & Pest Crop Management Livestock Reference IoT platform Thingspeak x (Maureira et al., 2011) FIWARE x (Rodriguez et al., 2018) NETPIE x x (NECTEC, 2020) Ubidots x (Ubidots, 2021) SmartFarmNET x x (Jayaraman et al., 2016) Thinger.io x x (Luis Bustamante et al., 2019) Kaa IoT Platform x x (KaaIoT, 2021) IBM Watson IoT Platform x x x x (IBM, 2015) Microsoft Azure IoT Platform x x x (Microsoft, 2021b) AT&T M2X Cloud x (AT&T, 2021) Blynk x (Blynk, 2021) MACQU x (Sigrimis et al., 2002) ERMES x (Granell et al., 2017) Agrocloud x x x (Kodati and Jeeva, 2019) CropInfra x (Pesonen et al., 2014) SensorCloud x (Corp, 2020) LoRaFarM x x x (Codeluppi et al., 2020)  Cloud platform Amazon Web Service x x x x (Amazon, 2021b) IBM Cloud x x x x (IBM, 2021) Microsoft Azure x x x x (Microsoft, 2021a) Integra x x (Souces and I., 2021)  Cloud Database DynamoDB x x x (Amazon, 2021) MongoDB Atlas x x x (Mongo, 2021) Firebase x x x (Google, 2021) InfluxDB Cloud x x x (Influxdata, 2021)  Local Database MySQL x (Oracle, 2021) SQLite x (SQLite, 2021) PostgreSQL/PostGIS x x (The PostgreSQL Global Development Group, 2021) Apache Cassandara x (Apache Software Foundation, 2021a) Apache Druid x x (Apache Software Foundation, 2021b) Garcia et al. give an overview on trends in Smart Irrigation in which they showed that data is stored in the database or in the cloud. On 151 reviewed papers, one uses Raspberry Pi, 18 databases, 53 clouds, and 79 are self-developed or not mentioned (Garcia et al., 2020). Navarro et al. identified 21 Platforms used in 50 various use cases classified into 5 categories: Artificial Intelligence, Big Data, Machine Learning, Computer Vision, and Other/Not Identified (Navarro et al., 2020). Jayaraman et al. present SmartFarmNet, an IoT platform offering effortless integration of sensors, supporting scalable data analytics, and proposing do-it-yourself tools to analyze and visualize data (Jayaraman et al., 2016). Codeluppi et al. describe LoRaFarM a general architecture modulated depending on the farm’s characteristics and requirements (Codeluppi et al., 2020). The monitoring of crops particularly more sensitive to them as saffron is crucial. The DIAS Architecture (Triantafyllou et al., 2019) uses different ground and leaf sensors to monitor the real-time 24/24 h cultivation process of saffron. This data is transmitted by LoRaWAN with IPv6 protocol and MQTT-SN protocol to FIWARE’s context broker. The broker manages all networking devices by means of sixteen types of messages exchanged following publish-subscribe model. The FIWARE NGSI API of oversees the consumption, subscription, and processing of all the information collected and its publication. Afterward, the data is stored and analyzed with a random forest algorithm which allows extracting information about the crop growth and health. Vegetation indexes: Normalized Difference Index (NDI), Excess Greenness Index (ExG) are calculated with PiX4D3 image processing tools. Object-based image analysis (OBIA) is used to recognize weeds or discriminate species. Finally, collected data are categorized and evaluated accordingly with vegetation index values, moisture level, and plant developing state by means of the Apache Spark framework for the Big Data analysis and Waikato Environment (WEKA) a framework specialized in data mining to produce reports and predictions. Decision-making is a very important task in the farmers’ activities but with the amount of data always increasing, they encounter difficulties on one hand to make proper decision about agricultural management and on the other hand translate this data into practical knowledge (Zhai et al., 2020). On the other hand, there is a need for platforms of the Agricultural Decision Support System (ADSS) to assist farmers to make precise decisions evidence-based. For example, Watson Decision Platform for Agriculture combines IBM Watson with IoT and Cloud Computing to detect crop disease from UAV images. It is also possible to optimize time for crop operations to obtain a better price on trading market. The second example is Digital Farming System4 takes advantage of computer vision, cloud computing, and AI to propose a better timing for corp operations, notify when a crop is infected by any disease. Smart Irrigation Decision Support System (SIDSS) is composed on one hand of a set of sensors and a weather station and on the other hand a DSS based on two machine learning algorithms. Partial Least Squares Regression (PLSR) to deduct unnecessary variables and Adaptive Neuro -Fuzzy Inference Systems (ANFIS) used to minimize estimated errors under a target threshold (Navarro-Hellin et al., 2016). SIDSS generates planning of water amount and time for irrigation. Multi-robot sense-act system (Conesa-Munoz et al., 2016) is a planner of aerial and ground vehicles which assign tasks to the most appropriate work units. A Harmony Search Algorithm is used to optimize plans for UAVs while meta heuristic is running for ground vehicles. 2.3. Analysis of previous literature The analysis of existing reviews about smart farming shows that applications use whether open source or commercial cloud architecture whether developing specific architecture responding to their aims or do not describe their storage and processing system. The latter represents more than half of the papers and means that some of the processing architectures remain unknown because they have never been specifically described and studied. Moreover, the fact that further development is being made in architecture may be the fact that commercial platforms do not fully address the needs of Agriculture 4.0. This brings us to our research questions and their respective motivation: 1. Which storage and processing architectures are best suited to Agriculture 4.0 applications and address its particularities? Motivation: On one hand generic architectures dedicated or not to IoT are able to address a large number of use cases but not specifically the needs of Agriculture 4.0 exist. On the other hand, researchers develop architectures to address specific issues or requirements of use cases. The selection of an adapted architecture is crucial for the correct implementation of identified use cases. 2. Can generic architectures meet the needs of Agriculture 4.0 application cases? Motivation: Agriculture 4.0 has specific requirements described in the introduction section which cannot all be addressed by a single classical generic architecture. A comparison between the pros and the cons of major generic architecture in the context of agriculture 4.0 is important to highlight the choice during the conceptualization step. 3. What are the horizontal valuation possibilities that allow the transition from research to industrialization? Motivation: The use of architectural solutions which can be for example free of fees during the research phase but needs a reimplementation caused by license limitations, the cost of the license in the use cases budget, etc. The use of products in closed or semi-closed ecosystems is a barrier to the research valuation. 4. What are the vertical valuation possibilities to move from algorithms trained in the cloud to embedded or autonomous products? Motivation: The massive collection of data in the cloud allows to development of complex algorithms that need a large amount of computing resources to be elaborated. Afterward, they can be compressed, reduced, optimized in order to be deployed in embedded devices or divided and establish a collaboration between devices and computing resources such as cloud, fog, etc. In order to answer these questions, a review of the literature will make it possible to synthesize the different approaches currently used, to identify new trends and to consider new lines of research to be explored. 3. Methodology In order to address, our first and second research questions, we achieve a systematic review to identify generic architectures and combination of architectural elements used by researchers to implement concrete use cases. Moreover, we attempt also identify commercial products and existing services/ platforms used to implement projects in agriculture. 3.1. Systematic review methodology The research questions outlined at the end of the related work section has been addressed by combining keywords of the first group that refers to architectures (i.e. cloud architecture, distributed architecture, big data, Internet of Things, IoT) and of the second group contained keywords related to agriculture (i.e. agriculture, smart farming, food, agri-food, precision agriculture). Our methodology is based on 3 consecutive steps: literature identification, reading literature, and information extraction. During the first step, we have read and have collected individual papers based on the achieved of previous papers. We have reviewed and completed by a systematic survey of white literature (full articles and conference papers) from January 2016 to December 2020. In addition, we targeted solely and exclusively papers written in English and focusing on architecture design have been considered. Our bibliographic review was limited to the last 5 years because the rapid development of IoT. The systematic review was retrieved from the following major bibliographic databases: Scopus (Elsevier), IEEE Xplore Digital Library, Wiley Online Library, ACM Digital Library, and Springer. These bibliographic databases have been chosen widely covering relevant bibliography and relevant advanced bibliometric features especially number of citation and relevant literature suggestion. From these databases 1058 peer-reviewed articles were retrieved. After their screening 55 papers were classified relevant while remaining articles were considerate not relevant and therefore excluded from further reading and analysis. The high number of excluded papers is due to numerous papers describe i.e. conceptual or theoretic architectures which were never implemented, experimental architectures that have been the subject of a single article or that have never been proven by other research teams. We discard also papers that were not a directly related Big data and the agricultural sector. Table 3. Table 3. Keywords used for achieved the systematic review. Area Keywords Related concepts Agriculture Agriculture, Agricultural e-Agriculture Agri-Food Agribusiness Smart Farming Farming Precision Agriculture, Precision Farming  Internet of things IoT, Internet of Things, internet-of-things Big data Big Data Big Data Data Management Data Management Architecture Cloud Architecture, Distributed Architecture In a second step, we included English grey literature (reports, blogs, magazines, and web-items) into our review using Web of Science and Google Scholar. Table 4. We discarded papers that were written in other languages than English, Master and doctoral dissertation, and duplicated articles gathered from Google Scholar. Afterward, we have selected literature that has carefully been read in detail to extract relevant information of research questions. The extracted information was analyzed and summarized in a conceptual framework illustrated in the Fig. 1. Table 4. Sources of collected literature. Data source URL IEEE Xplore Digital Library https://ieeexplore.ieee.org Scopus https://www.scopus.com Springer https://link.springer.com/search Wiley Online Library https://onlinelibrary.wiley.com Google Scholar https://scholar.google.com Web of Science https://publons.com/publon ACM Digital Library https://dl.acm.org Download : Download high-res image (171KB) Download : Download full-size image Fig. 1. Conceptual framework of data processing. Three ways of treatment of data are possible. The first process data in real-time (left branch identified by (1) on Fig. 1), this one is generally not stored except eventually particular or exceptional data in order to enrich the training database of artificial intelligence algorithms. This way of data treatment is used for example by robots that inspect a crop, discover a pest, and then eliminate it. After intervention the value data is near null. The second way is a mixed way in which data must be processed as quickly as possible. This one addresses use cases where latency required must be comprised between few milliseconds to few seconds with data, which conserves a value during a certain period of time. This latter justifies its storage according to the use case data management plan that predicts the time after which the data will be aggregated and then deleted. This way in identified by (2) on Fig. 1. It addresses use cases where all data must be processed and then stored for eventual post-processing for example to estimate trends of parameters such as the milk quality, volume of palatable species available in a pasture. The third way is stored data theirs native format without transformation (Identified by (3) on Fig. 1). This way is implemented on use cases that do not require real time processing or use cases where the amount data is so important, which makes treatment impossible. In this latter case, data are consumed by micro services that sample data to exact knowledge. This way is also employed for data which have a low value or lose their value so quickly that there is no point in transforming them for long-term storage. For instance, a UGV identifies and eliminates a pest. The image of the insect is no longer relevant after its elimination. 3.2. Architecture comparison criteria In order to compare selected architectures, we chose to select 8 criteria:(1) User Proximity expresses the necessity to be close to the user. This criterion is important for applications where privacy and response time to query are critical. Attribute a value of one * when privacy is not crucial; ** when the proximity with user is desirable but not crucial for the development of the use case; *** when the user proximity is the corner stone of the application. (2) Latency & Jitter criterion describes the importance for the architecture to have a minimal latency and jitter. This criterion is particularly important for use cases where response time to query in quasi (real time) is required and/or time between data production and ingestion by the processing and storage architecture is essential. (3) Network stability criterion translate the necessity to have a stable network or if is interruption can be tolerated. Use a value of * if the use case implemented can tolerate the absence of network during few hours; ** if few minutes of interruption are tolerable; *** is stability of the network is an essential element of the use case. (4) The high throughput criterion expresses the capability of the architecture to process quickly a wide amount of data arriving at high frequency; Use a value of * if the data arrive mostly at regular intervals; a value of ** if the data arrive in bursts, and *** if the data arrive continuously at high frequency ( 10 Hz). (5) Reliability is a criterion that expresses if the infrastructure is critical in other terms whether an interruption in infrastructure could cause loss of life or not. Attribute a weight of * if the data is not critical and potential damages caused by an interruption of the architecture are minors or null; ** if potential damageable but tolerable if they occur more than once a year; *** if the application cannot tolerate any interruption which would cause irreversible damage or loss of human life. (6) Scalability is a criterion that expresses the regularity of the evolution in terms of processing and storage during a period of one year. If the scalability must be achieved at most once a year use a weight of *; if the scalability is achieved at most twice a year use **; if the scalability must be achieved more than two times by year use a weight of ***. (7) Cost-Effectiveness criterion reflects the need to control infrastructure costs. This criterion is more important as the infrastructure is brought to evolve both in terms of scale and complexity. Use the weight of * if the project will remain in a relatively constant size and do not need to be scaled or dramatically modified; Use **, if the project evolves reasonably, i.e. should not undergo significant modification more than once a year. Use a weight of *** if the size of the project and/ or its complexity need a fine study of cost. (8) Maintainability criterion is directly linked to the sustainability of the project. If the sustainability of the project will not exceed two years to allocate a point of *; if the life of the project is between 2 and 5 years, assign a score of ** beyond 5 years, assign ***. 4. Architectures The numerous publications dealing with cloud architectures relating to Agriculture 4.0, summarized in Table 2, show that a great deal of effort has been devoted to solving a whole range of problems related to many use cases. Indeed, a universal and a unique architecture do not exist for IoT applications in Smart Agriculture which ensure all needs of all use cases. This is the reason why several researchers have proposed various architectures which address specific issues of generic architectures. The Fig. 2 gives a global overview on Agriculture 4.0 organization. Download : Download high-res image (340KB) Download : Download full-size image Fig. 2. Global structure of IoT in Agriculture 4.0. 4.1. Central Cloud Architectures Central Cloud Architectures are based on two basic architectures that are associated or combined in order to form modern architectures. These two architectures are: Batch Architecture aims to process an entire dataset in an offline mode. For this type of architectures, as long as the processing of the dataset is not finished, it continues and produces results only when it has reached its end. Generally, the data is selected and distributed to different nodes in order to be processed more quickly. When all the treatments are achieved on all nodes, the results are sorted and aggregated to obtain a global output. This architecture is easily implemented, and the aggregation is done by a framework, but processing times can be long, and data extracted during the treatment cannot be processed before the end of the treatment in progress. Furthermore, it is possible to increment results of previous batch and produce a result that integrates treated data in progress. Sallah et al. used a batch architecture to update data within the AquaCrop model (FAO) embedded in R-environment in order to facilitate model calibration and validation, run and evaluate all fields in a single run (Sallah et al., 2019). Nolack Fote et al. presented an architecture to extract knowledge on the long term from data in Precision Livestock Farming (PLF) (Fote et al., 2020). Table 5. Table 5. Pros and Cons of Batch Architecture. Pros Cons - Easy to implement and maintain. - Process only data previously stored in another form (file, database, etc). - Able to achieve long term treatments (several hours or days). - Processing cannot be modified before the end of the treatment. - Reprocessing of old data that are easy to achieve. - Results available only at the end of the treatment. Real-time Architecture also named Streaming Architecture processes data as it arrives, and results are progressively available by opposition to the batch architecture where it is not necessary to wait for the end of ingestion of all input data to obtain a result. The notion of real-time is strongly dependent on the analysis context with a processing time from a few milliseconds to a few minutes. Real-time architecture can be implemented in two different ways. On one hand with micro-batch in which a tiny amount of data is processed each n seconds and a result is obtained at the end of the treatment or on the other hand with a streaming approach in which each new data is immediately processed and output is quickly produced. This architecture is limited to data flow processing (Miloslavskaya and Tolstoy, 2016). Table 6. Table 6. Pros and Cons of Real-time Architecture. Pros Cons - Allow a rapid treatment of newly arrived data. - Not able to achieve processing on large size of the batch. - Batch processing can be emulated using micro batches but not all algorithms can be implemented. - Reprocessing of old data difficult to implement. - Easy to implement and maintain. - The need for real-time processing involves the use of an estimator rather than the precise values that would take too long to be calculated. Various data are produced by different fields or animals sensors, vehicles, and robots of the Agriculture 4.0. Afterward, this data must be on one hand stored in a raw state and processed in an offline way where long and complex treatments can be achieved. On the other hand, data can be processed before its storing with offline processing, streaming processing, or a combination of these ones. The storage time is extremely variable following the nature of the data and their loss of value over time. Offline processing is classically used to process images from UAVs, UGVs, or satellites, for example, to determine photosynthesis activity, evaluate the canopy development or stocks of palatable species available in a pasture, etc. While Streaming processing allows detecting anomalies in animals’ behaviors in real-time, or during agricultural operations such as the harvesting, disease and pest detection, weeds elimination. In these last cases, data is not stored because it quickly loses all value after its ingestion. Finally, a combination of the two previous ways i.e. Offline and Streaming processing is used to estimate real-time metrics and achieve complex treatments in an offline way at the same time. This approach is used by milking robots which detect anomalies in the production in real-time while the offline processing estimates the future production of each cow based on previous milking (Debauche et al., 2021). Lambda architectures are used in systems that need to process and expose quickly massive amounts of streaming data. This cloud architecture was proposed by Nathan Marz and James Warren (Marz and Warren, 2013) to handle tremendous quantities of data and resolve complex problems combining processing large volumes of data (Batch) while incorporating the most recent data processed in real-time processes (Singh et al., 2019). This architecture is generic, scalable, and fault-tolerant against hardware failures and human mistakes. The architecture is composed of three layers: (1) batch layer process very large quantities of data by batch; (2) speed layer which processes data in real-time and provides views based on the most recent data and (3) serving layer responding to queries. Data comes from either a data source or a message queue. This paradigm allows executing arbitrary queries over any real-time data and is particularly adapted for critical infrastructure and health systems (Diaz et al., 2016). Several implementations of Lambda Architecture in smart Environment management, big data storage and analytics can be found in (Villari et al., 2014). Among the criticisms that have been made against lambda architecture is the need to make twice the developments for the real-time branch and the batch branch. It is possible to perform a batch processing and in real time with flow processing is what the Kappa architecture described below does (Kreps, 2014). Fig. 3 Table 7. Download : Download high-res image (116KB) Download : Download full-size image Fig. 3. Lambda Architecture General Scheme. Table 7. Pros and Cons of Lambda Architecture. Pros Cons - Process data in real-time or in batch processing in separate ways. The reliability of two ways of treatment is most costly than other architectures if the two execute the same treatment. Among use cases in agriculture 4.0 using a lambda, we would like to highlight: Roukh et al. proposed WALLeSMART, a cloud platform based on lambda and specifically developed for Smart Farming. This platform implements Apache Kafka to store temporary data before their treatment. Apache Hadoop and the programming model Mapreduce is used for the batch processing while Apache Storm process data in realtime. The originality of this architecture is the coupling of a NoSQL database Apache Casandra and a SQL database, PostgreSQL where data is stored in the function of its nature. The GraphQL query language allows to querying databases. (Roukh et al., 2020, Roukh et al., 2020). Debauche et al. describe a lambda architecture for digital phenotyping (Debauche et al., 2020) and farm animals’ behaviors coupled with an Application Hosting Architecture based on Apache Mesos and Docker containerization to facilitate the deployment of various applications. An API interconnects and controls accesses between the Lambda Architecture and the Hosting Application Architecture. The Lambda architecture is based on Apache Beam to easily change the runner in the function of the technology evolution and improve its sustainability. Apache Druid is used to store time series data (Debauche et al., 2019) and metadata of data stored in the Datalake based on Apache Hadoop (Debauche et al., 2018). A variant of this architecture, named Unified Lambda architecture combines batch and stream pipelines which runs concurrently, and then the results are merged automatically (Siciliani, 2015). AllJoyn Lambda integrates AllJoyn a framework that offers: (1) proximal devices and applications discovering; (2) specific devices framework adapting; (3) transmission between devices with Bluetooth, Wi-Fi, etc.; (4) interoperability between operating systems; (5) efficient and secure data exchange through D-BUS (Villari et al., 2014). The Kappa architecture, proposed by Jay Kreps from LinkedIn (Kreps, 2014), simplifies the Lambda architecture by combining real-time and batch layers. This cloud architecture differs from the Lambda architecture by using a non-permanent storage system of data in an unchangeable log file such as system as Apache Spark or Apache Kafka, and consequently allow only storage for a limited time in order to allow an eventual reprocessing of these data. Batch and Speed Layers are also replaced by a stream processing engine. So, the Kappa Architecture is composed of two layers: streaming and serving layers and can be implemented with a publish-subscribe messaging like Apache Kafka, which facilitates data ingestion. Fig. 4. Download : Download high-res image (121KB) Download : Download full-size image Fig. 4. Kappa Architecture General Scheme. The main advantage of this architecture is its simplicity. It avoids having to maintain two separate code bases for the batch and speed layers. When processing on real-time and historical data are the same, a Kappa Architecture must be used. Fast Data Architecture is a variant of Kappa Architecture in which the data are no longer read from files but from an additional mechanism like Kafka that captures multiple streams combines them before being processed by the speed layer (Lakhe, 2016). Persico et al. achieved a benchmark of Lambda and Kappa architectures and show that Lambda outperforms Kappa for social networks data (YFCC100M) processing (Persico et al., 2018). Table 8. Table 8. Pros and Cons of Kappa Architecture. Pros Cons - Very efficient for real-time processing thanks to in-memory processing. - Batch processing emulates thanks to micro-batch treated via the real-time way. - Optimized cost because allows real-time and batch processing. - Not able to process large batch size. - Must be finely tuned from data to obtain the best performances (Nkamla Penka et al., 2021). Other Architectures derived or inspired of the previous architectures have been developed to address specific problems such as (1) SMACK (Estrada and Ruiz, 2016) which attempts to propose an optimal architecture with fixed components; (2) Liquid (Fernandez et al., 2015) is an architecture which provide low latency, incremental processing, high available with isolated resource, and able to store high throughput data at low operational cost architecture; (3) Butterfly (Lakhe, 2016) proposes to unify batch, speed and serving layers in a unique platform in which data are organized as a collection of three types of abstractions; (4) Zeta (Scott, 2015) which integrates a lambda architecture with business aspect of the enterprise; (5) BRAID (Giebler et al., 2018) is a hybrid processing architecture where all coming data and configuration file of processing, and eventually processing results written back are stored in a shared storage; (6) IoT-a (Hausenblas, 2014) is composed of three blocks: Ad-hoc queries, a Database, and a Distributed File System; (7) Polystore (Meehan et al., 2016) implements a multiple database system PostgreSQL, SciDB and Accumulo because a database alone cannot store all types of data efficiently. Table 9. Table 9. Qualitative evaluation of cloud-centric architecture. Criterion Batch Stream Lambda Kappa User Proximity * * * * Latency & Jitter * * * * Network Stability * * * * High throughput *** *** *** *** Reliability *** *** *** *** Scalability *** *** *** *** Cost Effectiveness *** *** * ** Maintainability *** ** * ** The analysis of the literature achieved shows that two major generic architectures: Kappa and Lambda allows to address of various use cases and are widely implemented and proven in other domains of the Internet of Things. The Lambda is more expensive to implement than the Kappa because of the need to maintain two separate parallel processing branches for stream processing and batch processing. It is interesting if different processing are carried out on the two processing branches. Otherwise, a Kappa architecture with a single processing branch that processes both the streams and the data in batches is more appropriate in most cases because it is cheaper and easier to maintain because a single code performs both types of processing (stream and batch). Looking at our first two research questions, we observe that Lambda and Kappa cloud architectures are efficient but these architectures alone operating in central cloud cannot address, for example, use cases where very low latencies are required. They will have to be hybridized and completed to address these particular cases. Two possibilities are available to us. The first way consists in associating several specialized cloud platforms to make it possible to obtain greater genericity or at least to better cover a domain. The second consists of supplementing the cloud-centric architectures that we have just mentioned with other architectural elements in order to better address the specific needs of Agriculture 4.0. 4.2. Extension of the cloud paradigm With the increase of the amount of data produced by the myriad of connected things, the amount of data to process, to transfer by network, and to treat in the cloud computing have called into question the architecture of storage and data processing. To solve the problem, two ways have been proposed, the first is Multi-Cloud Computing, the objective of which is to ensure redundancy in order to improve latency. The second is the Federated Cloud with the aim of pooling resources for better use. Multi-Cloud Computing (MCC) (Manyika and Chui, 2015) is an extension of Cloud Computing paradigm where services are distributed on multi-clouds. In this architecture the workflow is distributed entirely in the cloud, data redundancy is also verified. One advantage of the MCC is the high recovery rate but it has the same disadvantages as Cloud Computing, along with complexity and portability issues. Kazim et al. proposed a framework to deliver IoT services and establish cooperation across multi-clouds. An authentication allows communicating cloud to authenticate each other cloud dynamically. While a service selects the best IoT service matching with user requirements among multiple clouds and taking into account the SLA parameters agreed between the user and the provider (Kazim et al., 2018). Federated Cloud (FC) aggregates resources of multiple cloud providers to improve users’ freedom and allows users to choose where they want to deploy their applications. A Federated cloud can be defined as a voluntary collaboration between heterogeneous cloud providers collaborating to share their own unused resources. Using a cloud federation helps to ensure service performance during load ups with resources borrowed from other clouds. In addition, the geographical dispersion of the installations makes it possible to migrate to another installation and to guarantee the service in case of breakdown. A unified interface allows to use it an easy consultation of the offered services. Finally, thanks to the dynamic distribution of the load, it is possible to bring the treatment closer to the user and consequently improve the Quality of Service (Assis and Bittencourt, 2016). Cloud federations include European Federated Cloud (Sipos et al., 2013), Massachusetts Open Cloud, Mosaic (Petcu et al., 2013), IEEE P2302, and Open stack Keystone. Drakos et al. described agINFA, a common research data infrastructure for agriculture, food and the environment using EGI Federated Cloud. This infrastructure allows to partner to share research infrastructure components, APIs, a registry of web-based information service and dataset for agriculture (Drakos et al., 2015). 4.3. Distributed architectures The post-cloud approaches allow to improve latency and jitter for immobile entities but do not provide an answer adapted for mobile devices and local awareness. The large amount of data generated at the edge has increased the speed of data transportation that is becoming the bottleneck for the cloud-based computing paradigms (Shi et al., 2016). Moreover, the treatment of data in the cloud does not offer any guarantees about privacy, on the response time and real-time actuation because the huge number of devices increases the latency and jitter. Moreover, the mobility of devices and power constraints makes the communicaion difficult with the cloud all the time (Botta et al., 2016, Zhou et al., 2017). The aim has been to bring data storage and processes data, filtering, and data analysis closer to data-producing objects to limit bandwidth consumption and relieve the cloud. Three major paradigms have been proposed to address these issues and bring cloud computing-like capabilities to the edge of the network. All these infrastructures manage mechanisms of Virtual Machine (VM) or containers migration and adjust if needed, the provisioning of capabilities where users are located. Moreover, the three paradigms allow the creation of federated infrastructures in which can coexist multiple edge infrastructures which can exchange information and services (Roman et al., 2018). 4.4. Elements of distributed architectures In order to always bring closer, the processing capacities of intermediate processing have been set up between connected objects and the cloud at the network level (Fog Computing) and at the level of telephony providers (Mobile Edge Computing). Fog Computing is a concept created by Cisco Systems and is an extension of the cloud computing paradigm (Munir et al., 2017) in which computation, storage and network services are provided between end devices and cloud/ classify and analyze the raw IoT data streams at near-edge and edge network level (Cisco, 2018). Fog nodes are either physical components such as gateways, switches, routers, servers etc. or virtual components such as virtualized switches, virtual machines, cloudlets, etc.; deployed following private, community, public or hybrid. Private nodes are reserved for a single organization, community nodes are used by a community, public nodes are dedicated to the general public, and hybrid mix the third previous modalities (Uehara, 2017). This paradigm allows to limit data transfer on cloud, reduce latency (Sethi and Sarangi, 2017), and jitter thanks to a three-tier architecture (Roman et al., 2018). In this hierarchical architecture, the analysis of local information is achieved at the low level and the coordination and global analysis are performed at the top level. The Fog Computing supports mobile devices (Sethi and Sarangi, 2017), response time in real-time or predictable latency (Lopez et al., 2015), bandwidth saving, an improving of security and resilience, scalability, multi-tenancy, advanced analytics, and automation (Byers, 2017), cost-effective services (Yang, 2017). Fog Computing allows also the federation of fog infrastructures in order to allow cooperation between multiple organizations (Roman et al., 2018). Furthermore, the architecture is optimized for a use case and applications which must run on them (Byers, 2017). Fog Computing differentiates from cloud computing mainly by the proximity with end-users at the edge of networks localized or distributed geographically consisting in many relatively less resourceful (Munir et al., 2017). In addition to network equipment, fog computing can also be carried out in cloudlets and micro data centers. Cloudlets were proposed to address the end-to-end responsiveness between mobile devices and associated clouds. Cloudlets (Mach and Becvar, 2017) are micro data center geographically deployed in vicinity of End Users. This mobility-enhanced small-scale cloud data center is composed of computers with high computation power which provide both computation resources and storage. Cloudlet is much more agile (highly dynamic provisioning) than cloud due to user mobility churning. The mobility of users implies the use of a virtual machine to rapidly instantiate compute-intensive and latency-intensive applications and migrate the offloaded services between different cloudlet in the function of the user mobility. Cloudlets must be firstly discovered, selected among several candidates before starting provisioning. At the end of the session, the instance is destroyed (Ai et al., 2018). Cloudlets are accessed by mobile user equipment via Wi-Fi imply a high latency caused by the network and switch between mobile network and Wi-Fi and by consequence Quality of Service (QoS) and Quality of Experience (QoE) are hard to fulfill (Mach and Becvar, 2017, Manyika and Chui, 2015). Moreover, Cloudlets cover usually a small region and do not offer any guarantee on ubiquitous computing and scalability in service (Manyika and Chui, 2015). MicroData Centers (MDCs) were proposed by Microsoft Research. It is designed to extend cloud data centers as cloudlets. MDCs are enclosures contemning all types of equipments (computing, storage, network) needed to provide a secure computing environment in order to run customs applications requiring low latency. MDCs are also well adapted to provide processing resources to end devices on battery or with limited computing capabilities. MDCs can be adapted in function network bandwidth and user needs thanks to certain flexibility in terms of latency and scalability of the capacity (Wang et al., 2020). Guardo et al. proposed a framework composed of two fog layers respectively filtering and aggregating data, and clustering analysis, actuation management, and alert. The framework aims to improve computational load balancing between fog and cloud in order to reduce the amount of data to transmit to the cloud, reduce the waiting time for the user (Guardo et al., 2018). Taneja et al. proposed a SmartHerd an IoT platform dedicated to smart dairy farming based on microservices and Fog-assisted. The IoT gateway received data from transceivers, archived data aggregation, preprocessing, classification, feature selection, send critical alerts to farmers, and transmit data to IBM Watson IoT platform via MQTT protocol. In the IBM Watson IoT platform, a broker picks up data and store them in a Cloudant NoSQL JSON Database. Python Virtual Machine and Java Virtual Machine were used as containers equivalent for microservices deployment at fog level (Taneja et al., 2019). Sharofidinov et al. described a 4 layers architecture (Sensors Layers, Fog Layer, Network/Cloud Layer, and Application Layer) based on LoRa to monitor and predict the state of a greenhouse from a random forest algorithm. In the Sensor Layer, sensors acquire temperature, soil and air humidity, CO2 rate, and illumination connected to TTGO LoRa32 (ESP32 with LoRa Sx1276 chip) which are transmitted to the gateway by LoRa. At Fog Layer, preliminary analysis with Machine Learning algorithm, diagnosis of sensor status, and data compression are achieved. In the Network/Cloud Layer, compressed data are transmitted in order to be deeply analyzed and stored. Finally, in the Application Layer, analyzed data are converted in readable form to allows the monitoring and the control of the greenhouse (Sharofidinov et al., 2020). Table 10. Table 10. Pros and Cons of Fog Computing. Pros Cons - Fast response time in avoiding transmission of data to the cloud (Sharofidinov et al., 2020). - Failure or outage of the gateway can defeat thousands of devices. - The local storage and processing capabilities prevent data loss and outages when the Internet connectivity is limited (Sharofidinov et al., 2020). - The limited processing and memory capacities do not allow the deployment of algorithms requiring significant resources or the carrying out of long-term processing. - Sensitive data can be filtered locally. In this case, only the data model is moved in the cloud (Sharofidinov et al., 2020), and data validation, compression, and encryption. - Gateway at fog level ensure the compatibility between old and modern devices (Sharofidinov et al., 2020) and various protocols for communication. - Improve the resilience thanks to the decentralization of the treatment on network devices (Sharofidinov et al., 2020). Mobile Edge Computing (MEC) was proposed by ETSI and is deployed by telecommunication companies on the edge of the network, which is characterized by ultra-low latency and high bandwidth. (Roman et al., 2018, Zhou et al., 2017). At the very beginning, Mobile Edge Computing (MEC) aims to bring real-time, high-bandwidth, and low-latency access to dependent applications known as cloud computing capabilities; in addition to, information technology (IT) features of cloud computing. MEC is distributed at the edge of the network. In fact, a new class of cloud-native applications are easily accessible, because of the close position of Edge Computing to the end user and apps. Also, it allows network operators to open their environment to a new ecosystem. As a result of this significant change, MEC application can be used in LTE macro base stations (eNBs), 3G radio network controllers (RNCs), Wi-Fi access points, edge network routers, and enterprise edge servers. MEC platform contains two main hosting infrastructures. The first is formed by hardware resources and a high-resolution screen. The second is composed of manageable applications with numerous capabilities such as the application of virtualization manager and platform services (Zhou et al., 2017). An important challenge for the MEC is the VM migration that must optimize the tradeoff between migration gain and migration cost and select optimal location (Ai et al., 2018). Tran et al. investigated the collaborative Mobile Edge Computing in 5G Networks. MEC extends processing and storage resources at the edge of the Radio Access Network (RAN) while C-RAM is based on centralization of the base Station by means of the virtualization. Authors argue that both technologies are complementary in the 5G ecosystem (Tran et al., 2017). Fig. 5 Table 11. Download : Download high-res image (172KB) Download : Download full-size image Fig. 5. Mobile Edge Computing General Scheme. Table 11. Pros and Cons of MEC. Pros Cons - Reduces needs in connection, response time delay, the congestion of other parts of the network (Valecce et al., 2019). - Usable only for devices connected in Wi-Fi or 3GPP. - Use low level message from Wi-Fi to determine the location of each device (Location awareness) (Valecce et al., 2019). - MEC Server can be used as power open to applications and services (Valecce et al., 2019). Fan et al. combined MEC with data link management, combining with the industrial CAN bus characteristics to monitor water. Field Programmable Gate Arrays (FPGA) Altera implementing the AVALON bus was used to implement the system. Moreover, they propose a protocol to model random network disturbances and an online task offloading algorithm based on the monitoring of task execution (Fan and Gao, 2018). Valecce et al. proposed a 5G-robotics reference architecture for smart agriculture composed of UAV-Based Monitoring and connectivity, Machinery automation, and MEC Applications Server. UAVs/satellites capture high-resolution images during patrolling, which coupled with sensors data trigger a precise crop management. UAVs can also collect data or serve as a 5G mobile station. In field, image processing coupled with sensors data can be used for decision making. MEC allows to process gigabyte/s of data produced by autonomous vehicles and robots (Valecce et al., 2019). Table 12. Table 12. Evaluation of distributed architecture with our criteria. Criterion Fog MEC User Proximity **(*) *** Latency & Jitter * * Network Stability *** ** High throughput ** **(*) Reliability *** ** Scalability * * Cost Effectiveness ** ** Maintainability ** ** The development of fog computing and its counterpart for MEC wireless networks allow processing capabilities closer to users to improve response time but with lower computational capacities compared to the cloud. There are inherently two questions: Which association strategies to use between the cloud and the other levels of processing in the network? How to distribute the load between these different levels: local (Edge), network (Fog), and Cloud processing. 4.5. Collaborative computing strategies In order to address, our fourth research question, we try to identify different possibilities to compose architectural elements. Indeed, different collaboration strategies between the different levels of data processing (cloud, fog, edge) can be considered depending on the particularities of the use cases. In the next paragraphs, we describe possibilities of collaboration between different treatment entries, and we illustrate each one with few examples. Edge-Cloud aims to connect devices directly with the cloud that performs data processing. This strategy is often used by UAVs and UGVs which preprocess data before its transfer to the cloud because image treatment needs processing power and storage capabilities. The default of this approach is that the delay of the whole process from data transfer via high throughput wireless or cellular protocol to the transmission of processing results cannot be guaranteed because of the fluctuation of data rates linked to wireless networks (Wang et al., 2020). The processing of data can be achieved in an online mode with a real-time data transmission and processing by a stream, Lambda, Kappa or derived architecture of these one. An offline strategy with a data transfer by means of a computer and Internet connection on the cloud after the UAV fly and processing with a Batch, a Lambda, or a Kappa architecture or a derived architecture of these one is also possible. This latter costly avoid data transmission and is suitable for monitoring crops or livestock that do not require direct action. Agriculture 4.0 uses in particular Unmanned Aerial Vehicles (UAVs) equipped with various sensors in order to improve the time of data collection, in reducing the cost of acquisition compared to traditional field phenotyping technologies. According to Tang et al., edge-cloud is majorly used in smart robots to reduce complexity (Tang et al., 2021). Indeed, the images of drones to be used must be orthorectified and assembled. These operations require significant resources in terms of computing power, and memory. All these collected data must be rapidly processed, analyzed, and visualized. Agroview (Ampatzidis et al., 2020) is a platform that developed a cloud and AI-based application to survey and assess the agriculture field, deployed on Amazon Web Services (AWS). A website allows the upload of images or existing orthomosaic, the consultation for each tree field e.g., number of trees, tree gaps count, area of the field, the average height of trees, canopy area, etc. The website also allows the stitching of an orthomosaic and the generation of a Digital Surface Model (DSM). A tree detection algorithm developed in C allows the detection of individual tree and tree gap, and estimate tree parameters such as height, canopy area, health/stress estimation. The pipeline of treatment uses a Faster R-CNN to detect the region of interest (ROI) and the ResNet101 network allows to detect trees and row orientation. Afterward, the Yolo classifier using Darknet19 was applied along each row of trees to obtain a more precise detection. Debauche et al. presented an Edge-Cloud architecture for the analysis of cattle behavior from 9-DOF IMU data sampled at 100 Hz and GPS location sampled at 0.5 Hz that is then processed with an algorithm proposed by (Andriamandroso et al., 2017) in batch processing (Debauche et al., 2019, Debauche et al., 2020). Popescu et al. proposed an integrated system UAV-WSN-IoT where WSN data is collected by UAVs before their transmission to the ground control station and afterward to the cloud (Popescu et al., 2020). Debauche et al. proposed an architecture for scientific research dedicated to honeybee Colony Collapse Disorder. In this architecture, data is compressed on LoPy at the edge level before its collection by the LoRaWan gateway and its transmission to the Lambda architecture in the cloud where it is processed (Debauche et al., 2018). Edge-Fog aims to connect devices directly with network components such as gateways, routers that perform data processing. The major benefits of this approach are an optimization of the bandwidth, a reduction of traffic and latency, a better privacy, and an improved security level (Badidi, 2020). Fog nodes collect, aggregate, filter, encrypt, compress, and process IoT data (Gupta et al., 2020). This way is used for example by milking robots where data are processed by a computer close the robot and can be viewed remotely by the farmer. 5G also promotes mobile edge computing (MEC). Debauche et al. presented an AI-IoT architecture for the deployment of Artificial intelligence algorithms and Internet of things services at fog level using docker containerization and Kubernetes orchestration. This architecture has been developed to automatically deploy AI algorithms after retraining when performances (accuracy, recall, precision) are improved (Debauche et al., 2020). Debauche et al. proposed a Multi-Agent System (MAS) deployed at edge level allowing to control abnormal data present in sensed data and eventually cure this data when it is possible. The MAS simultaneously manages pivot irrigation, plant diseases and pests' detection, and their curation. The data is partially transmitted to the cloud to improve the detection of diseases and pests and retrain AI algorithms before their redeployment at the edge level (Debauche et al., 2020). Debauche et al. described a fog architecture in which a Gated Recursive Unit (GRU) algorithm is deployed on NVIDIA Jetson Nano for real-time poultry monitoring. GRU is simpler than LSTM algorithm. GRU is built to avoid varnish gradient problems. Periodically data is transmitted to the user interface implemented in NodeJS in the cloud (Debauche et al., 2020). Edge-Fog-Cloud is a paradigm in which data are partially processed in the fog and more complex treatments are achieved in the cloud. This way is used by wireless Sensor and Actuator Network (WSAN), which passes through a gateway that provides interconnection between the devices and the backhaul which transit then data to the cloud. However, the right balance between cloud and edge/fog computing is required (Badidi, 2020) based on available resources and whether or not the task is sensitive. Taneja et al. used a strategy Edge-Fog-Cloud to develop a detection system of lameness for cattle. The data from the pedometer is transmitted to the Fog node by means of a Long-Range proprietary protocol at 433 MHz on a distance of 2 km. Fog node stores in local database, preprocess and aggregates them. Fog node communicates with IBM Watson IoT Platform with MQTT protocol. Arriving data are picked up and stored in Cloudant NoSQL JSON database in IBM cloud. A mobile application synchronizes data with PouchDB, its local database via the REST API of Cloudant database when an Internet connection is available (Taneja et al., 2020). Alonso et al. presented Global Edge Computing Architecture (GECA), a modular tiered architecture (IoT Layer, Edge Layer, Business Solution Layer) to monitor dairy and feed grain state in real-time. In this architecture, a Distributed Ledger Technologies provides security from IoT Layer to Business Solution Layer. In the IoT layer, a set of agents call oracles to verify incoming data and afterward calculate hash of data with SHA-256 which is stored in the blockchain to verify the non-alteration of data. In parallel data is encrypted with the RSA algorithm and then sent to the Edge layer. The Edge Layer is responsible of the preprocessing of data and filters out data transmitted to the cloud. It enables also various data analyses. In the business Solution Layer, final storage, authentication, analysis for decision making is achieved. It provides also a knowledge base and APIs (Alonso et al., 2020). Edge-Edge is a paradigm in which devices interact to collaborate, exchange, and process data. The deployment of the 5G network allows the interconnection between UAVs and UGVs/ agricultural machinery (Tang et al., 2021). This high throughput network will allow to developping new collaboration between UAVs/ UGVs and agricultural machinery, for example, a drone will provide information to a harvester to avoid a non-desirable area of the field or avoid obstacles. A fleet of drones can also collaborate to coordinate their operations on the field between them of course subject to availability in rural areas, a transmission network with sufficient bandwidth and short-latency or capabilities to communicate between them in direct connection or in a mesh network. (Tang et al., 2021). Four cooperation strategies have been identified, two of which use the cloud, namely Fog-Cloud and Edge-Cloud. The other two remaing, do not involve the cloud; namely, Fog-Edge, and Edge-Edge cloud. The first two strategies complement the cloud to help us to address issues relating to production data and trade secrets, network congestion, and response times. The other two strategies do without the cloud and therefore assume that the devices/ vehicles have sufficient capacity to perform the processing. Despite these cooperation strategies between different levels of processing, some questions remain unanswered: How to store all the raw data when the data is so important that it would take colossal means to process it? What about security? How to organize the distribution of tasks between the edge, the fog, and the cloud? How to ensure operation and/ or treatment when network connections are intermittent or faulty? How to improve the maintainability of these architectures? These are the questions that the new trends that we describe in the next paragraph attempt to answer. 5. New trends In this section, we present two emerging architectures not based on the batch or/and real-time architectures or their derivatives. Afterward, we describe Osmotic and Dew computing as two new paradigms, which allow us to respectively choose where the processing must be achieved and improve the user experience. New trends are additional elements that allow enriching the analysis of Section 4 in order to address the third research question. The Microservices Architecture (MA) is a new system software design pattern that divides complex monolithic application in micro services dedicated for a single function. Microservice addresses defects of monolithic applications in which improving of service performance needs multiple deployment; a change in a function can affect all the monolith due to high dependencies between components; all the monolith uses a sole technology stack and development standards which limits possibilities to solve problems of physical heterogeneity. The advantages of this architecture are using a lightweight communication mechanism to interact between services with a minimal overload (Sun et al., 2017). The design proposed by (Sun et al., 2017) is composed of 8 microservices (Geo, Security, Tenant, Devices, Big Data, Automation, AI, and Application) and a core service coordinating. These services provide respectively: (1) Geo, a GIS layer to render data; (2) Security, user/group/role management, access control, administration, and authentication mechanism; (3) support for multiple IoT applications with a single core; (4) device plugins and communication protocols for sensing and actuating; (5) scalable persistence to store data; (6) process, analyze events and notify appropriate participant; (7) Artificial intelligence tools for IoT big data; (8) components to interact with client interfaces; (9) support for data exchanging by message with the devices. Authors argue that their approach is more flexible, scalable and platform-independent. Fig. 6 Table 13. Download : Download high-res image (189KB) Download : Download full-size image Fig. 6. Microservices Architecture General Scheme. Table 13. Pros and Cons of Microservices Architecture. Pros Cons - Fractionating of monoliths facilitates the maintainability and scalability of low coupled microservices. - Need to find microservice adapted with needs. - The discovery of micro-services allows the development new applications more easily than with monoliths. Fraction complex monolith is not easy. - More resilient, when a microservice is down, all others continue to function. Bixio et al. proposed a stream processing architecture event-driven based on proxy, adapter, and data processing microservices. This architecture extends the IoT platform Senseioty and using the Java OSGi framework (Bixio et al., 2020). The Data Lake Architecture (DLA) (Fang, 2015, Miloslavskaya and Tolstoy, 2016) enables the storage of large volumes of data of all types: raw data in its native format, structured, semi-structured, in a cost-effective manner. In this architecture, data is stored in its native format until it needs to process them by engines (Miloslavskaya and Tolstoy, 2016), which allows a fast transformation and refinement of stored data regardless of the amount of data stored. The architecture makes it possible to consume all types of data (logs, web services, database, files, etc.); different ingestion systems consume the data and then stored it in data repository. Once the data is stored, query systems can query the data lake. This architecture is considered in the corporate world as an evolution of existing architectures. The advantage of the Data Lake architecture is that it can easily and inexpensively store large amounts of data. It is particularly well suited to storing data in a typical format. In Enterprise Data Lakes are used; in addition to, data warehouses. Data lakes are, however, unsuitable for assessing data quality, data can be placed in data lakes without content control, and performance is also poorer than on specially designed and optimized infrastructures. The Lakehouse is a variant of the Data Lake where storages of data are generally achieved with Hadoop in the data lake is replaced by a distributed storage such as Amazon S3, Azure Blob Storage, Google Cloud Storage, and analysis are directly achieved by infrastructure managed by Cloud Service Providers such as Amazon Athena, EMR, or Databricks, Google Data proc, Azure HDInsight. The Fig. 7 provides a comparison between data lake and gatehouse structure. Download : Download high-res image (264KB) Download : Download full-size image Fig. 7. Data lake and Lakehouse General Scheme. It crucial in agriculture to explore datasets from different sources. The data lake is indicated to manage the complexity of agricultural ecosystems and centralized all data sources to find new correlations. (Madera et al., 2017). A data lake provides views based on metadata. It is nevertheless necessary to have advanced analysis tools for predictive modeling and statistical analysis. López et al. used a data lake to achieve the fusion of data from different domains in smart the agriculture context (López et al., 2020). Gallinucci et al. (Gallinucci et al., 2019, Gallinucci et al., 2020) present an innovative architecture 3 tiers architecture, called Mo.Re.Farming (MOnitoring and REmote system for a more sustainable FARMING) based on a data lake using Apache Hadoop and storing structured, semi-structured, and unstructured raw data, and in which subsequent processing and enrichment activities are separated. An Operational Data Store (ODS) using PostgreSQL with PostGIS to stores structured and detailed data and address limitations of big data solutions in properly handling continuous field geographic data. Finally, a spatial cube enables Spatial OnLine Analytical Processing (SOLAP). Neves et al. described an architecture in which raw data is stored in a datalake. Then, ETLs transforms data to be storable in a database. The data is enriched thanks to a knowledge base and its exploration by data mining algorithms (machine learning). The result of processing is filtered to improve the quality of structured data (Neves and Cruvinel, 2020). Table 14. Table 14. Pros and Cons of Datalake/DataHouse. Pros Cons - Store the data in its raw form without transforming them immediately. - Availability of results depend of the ingesting speed by processing services. - Allow store massive low-value data without investing energy to transform and store them in a database. - Data analysis by sampling does not give exact results but is estimated. - Provides a solution to situations where the volume of data is so large that it can no longer be processed immediately - Data House may be limited by the services offered by cloud providers for data analysis. Osmotic Computing (OC) (Villari et al., 2016) is a new paradigm inspired by the chemical osmosis process that corresponds to a dynamic and bidirectional flow of microservices between cloud and edge. OC exploits container-based solution to allows an automatic deployment of portable, mobile, and cross-platform microservices between Edge and cloud levels (Villari et al., 2016). Osmotic computing introduces the concept of Micro Elements (MELS) which decouples user data and applications in Micro Services (MS) i.e. a docker container and Micro Data (MD) i.e. an entity self-explicative in JSON. MS associates one operating system (Micro Operation Service) with an application (Micro User Service) while MD associates a microservice configuration (Micro Operational Data) and User data (Micro User Data). These MELS can be deployed on Microcontrollers (MCU) or Multiprocessor (MPU) (Villari et al., 2017). Table 15. Table 15. Pros and Cons of Osmotic Computing. Pros Cons - Micro Element (microservice  + micro dataset) easy to migrate between fog and cloud. - All datasets are not decomposable in micro dataset. The bidirectional migration of microservices between Edge and Cloud must, on one hand, avoid application breakdown and QoS degradation and on the other hand manage them dynamically, in high heterogeneously physical resources context, in the function of infrastructure and applications requirements (Villari et al., 2016). Carnevale et al. have applied osmotic computing to the Internet of Things by means of a distributed multi-agent system. Each agent is self-orchestrated, works independently, and manages the workflow as a composition of MELs. It monitors the overloading state of microservices by means of response time metric and decides to relocate them to another agent based on a Deep Reinforcement Learning algorithm or Time Series Analysis (Carnevale et al., 2019). Fig. 8, Fig. 9. Download : Download high-res image (119KB) Download : Download full-size image Fig. 8. Micro Element Structure. Download : Download high-res image (357KB) Download : Download full-size image Fig. 9. Osmotic Computing General Scheme. In an IoT context, OC allows to deploy lightweight micro services at edge level while complex micro services are deployed at fog/cloud level, and balance load between edge, fog, and cloud. (Maksimović, 2018). Morshed et al. proposed to use OC to distribute Deep Learning across edge, cloud, and mobile edge in a holistic way (Morshed et al., 2017). However, Kaur et al. in their Osmotic Computing applications survey have identified the need of standardization in terms of infrastructure deployment and micro-services distribution. The orchestration is crucial to manage efficient services. Security remains an important challenge because the service migration is supported by different layers (Kaur et al., 2020). Dew Computing (DC) (Skala et al., 2015) allows to further improve response times by pushing from Central cloud to end-users, computing applications, data, and low-level services. Client microcomputers are used to store a part of the data locally in the background and to limit access to the cloud, reduce network dependency and drastically reduce processing cost (Skala et al., 2015). Dew computing is the additional piece of cloud computing. It is mainly composed of a wide range of heterogeneous devices and varied equipment ranging from smartphones to smart sensors (Wang, 2016). DC is highly and effectively capable in terms of scalability and ability to perform sophisticated operations and to process numerous applications and tools. Additionally, the equipment of DC is ad hoc programmable and self-adaptive. They have the qualifications to running the process within another process in a distributed way without a focal communication network (Skala et al., 2015). Applications running in the on-premises computers provide services to users and/or devices independently of the cloud but collaborating with cloud services (Wang, 2016). DC can provide access web fraction without Internet connection (WiD), Storage in dew has a cloud copy (STiD), Local database has a cloud backup (DBiD), Software ownership and settings have a cloud copy (SiD), SDK and projects have a cloud copy (PiD), On-premises computer settings and data have a cloud copy (IaD), Other services (DiD) (Wang, 2016). The Fig. 10 presents the dew computing in the general scheme Cloud-Fog-Edge Computing. Table 16. Download : Download high-res image (84KB) Download : Download full-size image Fig. 10. Dew Computing General Scheme. Table 16. Pros and Cons of Dew Computing. Pros Cons - Allows access to a local copy of data when the connection is unavailable. - Replication of data is bandwidth-consuming. - Improve the reliability and the false tolerance. - Difficult to exploit if bandwidth is insufficient. Rajakaruna et al. presented a dew architecture based on a drone to retrieve and process data, manage WSN, and play the role of dew server. The drone communicates with sensors, and actuators with BLE protocol, collect, store data, and then when the drone is at the docking station it sends data to the cloud (Rajakaruna et al., 2018). Grovers et al. described a reliable and fault-tolerant architecture at 4 levels (edge, dew, fog, and cloud) in which sensed data is replicated at edge, fog and cloud level in order to take over the application’s control when a server is failed. In their architecture, dew servers are closed and linked with sensors producing data. The fault tolerance is ensured by mobile agents working as a resource exchanging the application and link-state information between us, and the network monitoring agent (Grover and Garimella, 2018). The Blockchain is a distributed digital ledger of transaction distributed maintained by a network of multiple computing nodes. This ledger can be deployed among the IoT nodes network (Bermeo-Almeida et al., 2018). In the blockchain, transactions namely blocks are managed by a specific software platform ensuring the data transmission, processing and storage, and its representation in a human-readable form allowing a consistent view and a consensus between the participants (Kamilaris et al., 2019). Different mechanisms of consensus whose two main ones are the “Proof of Work (PoW)” and the Proof of Stake (PoS). The PoW requires the solving of difficult computational tasks before validating transactions and the adding of the block in the blockchain. In this approach “miners” are in competition to be the first and obtain the rewards, which has an impact on the environment, need expending large a amount of computer and energy, and involves a risk of centralization. While the PoS approach, “validators” are randomly selected with a probability which depends on the amount of stake held. At the end of the validation process, it earns a fee. Other less used consensus mechanisms exist such as (1) Proof of Elapsed Time (PoET) in which each node generates a random wait time and goes to sleep for that specified duration; (2) Simplified Byzantine Fault Tolerance (SBFT), an improvement of Practical Byzantine Fault Tolerance (PBFT) specifically designed for blockchain in which each new block is maintained by a delegation of nodes with increasing authority. Each one uses the internal time to decide when actions must be done; (3) Proof of Authority (PoA) in which approved accounts process to the automated validation of transaction and blocks. Table 17. Table 17. Pros and Cons of Blockchain. Pros Cons - Data distributed (Alonso et al., 2020). - Energy consumption for the complex signature verification process can be important. - Immutable, durable, verifiable, secure, and transparent (Alonso et al., 2020). - Not adapted to store images, video. - Transactions P2P at low cost. The Fig. 11 shows the blockchain general scheme. Download : Download high-res image (251KB) Download : Download full-size image Fig. 11. Blockchain General Scheme. The block chain is mainly used in Agriculture to make the data of the supply chain transparent and open (Bermeo-Almeida et al., 2018) and ensure the complete traceability of the food chain from the fork to the plate. The block chain allows to record information about: (1) Transactions between provider and farmer as well as information relating to the crops, material and chemical products; (2) The farm, cultivation practices and management, animals feeding, and complementary information such as weather conditions, animals welfare, diseases, treatment, etc; (3) Information about factory and its equipment, the processing method, batch numbers but also financial transactions with producers and distributors; (4) Warehousing, storage conditions (temperature, humidity), methods of transport, transit time, and all financial transactions between the distributors and retailers; (5) food items information such as quantity available, quality, expiration date, time spent on the shelf or in the stock (Bermeo-Almeida et al., 2018, Kamilaris et al., 2019). The Fig. 12 shows an example of blockchain applied to an agri supply chain. Download : Download high-res image (112KB) Download : Download full-size image Fig. 12. Supply chain based on a blockchain. To a lesser extent, secured data storage, remote monitoring, and automation. The blockchain address some challenges of IoT such as decentralization, data anonymization, and security. Moreover, it allows faster and efficient operations, to improve reliability and scalability (Bermeo-Almeida et al., 2018). The analysis of new trends shows that: (1) Micro service architecture allows decomposing monoliths in microservices lowly coupled which makes it easier to maintain it while allowing other services to continue operating. Furthermore, this type of architecture is more resilient because if one of the services is down, the other services due to the weak coupling can continue to operate at least in a degraded mode. (2) Data Lake/DataHouse propose a new approach Load Transform Extract (LTE) where data are firstly stored in their original format, which are then transformed in order to extract information. This paradigm is particularly well adapted when the amount of data is so important that process all data is too costly. In this case, data can be sampled in order to obtain information. This paradigm is also well adapted if we want to conserve also raw data or complete a generic architecture, for example, to store data that will be processed in batch processing. (3) Osmotic Computing attempts to propose a solution to the repartition of workload between fog and cloud in decomposing treatments in microelements composed of a microservice associated with a micro dataset. The osmotic computing could also be associated with the micro service architecture to allow the distribution of instances of microservices at different levels of the network according to their respective load. (4) Dew Computing aims to replicate data near sensors or users to continue to store data or allows to continue to consult data when connection is intermittent. It allows improving the reliance of architectures on connection interruptions. (5) Blockchain provides an answer to authentication and security problems by making it possible in particular to verify that the data has not been altered or compromised. Nevertheless, it is not possible to store large amount of data such as high definitions images, or videos in the blockchain but hashes of datasets allowing to verify their authenticity well. 6. Towards Agriculture 5.0 According Myklevy et al., the world must improve the amount of food produced by 70% by 2050 to produce global food needs for a population (Mykleby et al., 2016) of 9.7 billion according to the Food and Agriculture Organization of the United Nations (FAO) (Zhang, 2016). To overcome these problems and contribute to achieve the second objective of 17 Sustainable Development Goals (SDGs) of the United Nations (UN) with a timeframe in the range 2015 to 2030, the concept of Agriculture 5.0 has been born (Martos et al., 2021). Agriculture 5.0 aims to increase production sustainably while consuming fewer resources and taking care of the environment. This next wave of agricultural revolution will imply the use of robots integrating machine learning to compensate for the shortage of workers. Farm robots are drastically increasing productivity in improving the human labor workforce and can also harvest a more important volume faster than a human. Nevertheless, these early technologies are still too expensive for most farmers especially small farms (Saiz-Rubio and Rovira-Más, 2020). Fig. 13 show the coupling between Agriculture 4.0 and Agriculture 5.0 and their integration in the context of the agri-food supply chain, the Society 5.0 and 17 Sustainable Development Goals (SDGs) of United Nations (See Fig. 13). Download : Download high-res image (252KB) Download : Download full-size image Fig. 13. Integration of the Agriculture 5.0 in the context of the Society 5.0. 7. Conclusion Our review is boosted by four research questions dectitaed as follow: (1) Which storage and processing architectures are best suited to Agriculture 4.0 applications and address its particularities? (2) Can generic architectures meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal valuation possibilities that allow the transition from research to industrialization? (4) What are the vertical valuation possibilities to move from algorithms trained in the cloud to embedded or autonomous products?. The analysis of the literature shows that a multitude of architecture coexists. Nevertheless, the Lambada and Kappa architectures seem to emerge as generic architectures. These must generally be accompanied by complementary architectural components to address specific needs and be part of a storage and processing strategy in which the cloud architecture is a component of the chain or may also and more rarely be absent. The traditional centralized cloud computing will continue to remain an important part of computing systems (Ai et al., 2018), for sciences even if other paradigms appear. Indeed, cloud, fog, and edge computing complementary interact with each other to form a mutually beneficial and interdependent service continuum. Some functions are naturally more suitable or advantageous at a level than another in function of requirements in response time, computing, or latency tolerance. However, the cloud cannot be completely replaced by fog and edge computing because some computation-intensive tasks can only be processed at the cloud level, which has the computing power and storage capacities (Wang et al., 2020). In Agriculture 4.0, this is particularly the case for the processing of satellite images, the training of artificial intelligence algorithms such as Deep Convolutional Neural Network (DCNN). New trends make it possible to address various problems: (1) The Data lake/Data House offers a more economical alternative to massive cloud storage in databases. In this paradigm, all data are stored in a state and transform only when they are to be exploited. This approach is particularly interesting on one hand when all data are not exploited and on the other hand when a decision or an action is not expected immediately. Data lake also allows the fusion of agriculture data from various origins in different formats and granularity. (2) The blockchain provides solutions in particular to the security problems, the possibility of distributing data storage and ensuring the traceability of transactions in agrifood supply chains (3) As the literature has shown, Dew Computing can be placed in two different places in the network either as close as possible to the sensors to allow processing to continue during transmission interruptions or as close as possible to users in order to have a local copy of the data in order to be able to consult them offline. It should be noted, however, that for the second option, there are other means of local caching at the device level, for amounts of data of a few mega as those offered by Progressive Web Apps (PWA) by example. (4) Osmotic computing provides a solution to the question of how to distribute the load between the different processing levels (edge, fog, cloud). It uses the concept of microelement associating a microservice and its micro dataset. In addition, osmotic computing can also be associated with micro-service architectures. (5) The microservice architecture offers the possibility of decoupling the monolithic architectures into weakly coupled microservices. These services can be more easily associated, maintained, or evolved independently. The combination of these microservices makes it easier to develop new services for the end-user that are also easier and faster to evolve according to technological developments and needs. In addition, at the network level, the 5G network offers new possibilities in terms of Wireless Sensors and Actuators Network (WSAN), communication between machines, UAVs, and UGVs. Moreover, the coupling with MEC opens the field of processing close of end-users. The SDN/NFV Architecture allows to facilitate the design, and to improve the flexibility of network. Software-defined networking (SDN) allows decoupling transmission of data and network control functionality while Network function virtualization (NFV) abstracts transfer network and related network functions (Friha et al., 2021). Two trends in the use of processing architecture coexist, on the one hand, users of a paid or open source IoT platform, and on the other hand, users who develop specific architectures to implement particular use cases. From the point of view of transferability, we understand that it is easier for ready-made chargeable infrastructures and that it can be limited for turnkey open-source infrastructures where the type of license adopted may pose a problem. However, the sustainability of paid infrastructure is conditional on the development granted by the company that manages them and on its financial health. The development of architecture based on paid software bricks is facilitated but its durability is conditioned by the availability and the maintenance of these software bricks. As for transferability, it is linked to the acquisition of ad hoc licenses. The development of architecture using open source software bricks from foundations such as Apache Foundation makes it possible not to be limited by licenses but is dependent on developments and maintenance carried out by the community of developers. These software bricks can be abandoned by the community, the company that sponsors them, or the foundation that hosts them. The development of a sustainable architecture would go through an emancipation of software bricks which would make it possible to easily change them on the one hand when one of them disappears or if a new more efficient software brick appears. The deployment of 5G and satellite Internet will bring in a new player, which are the telecommunications companies that will be able to provide processing capacities and services as close as possible to users at the level of 5G antennas, which will impact processing architectures. The problem will then arise of interoperability between the networks of sensors and actuators with these new high-speed, low-latency networks. The new networks offered by the telecommunications companies will make it possible to offer new services or even to decouple the software from the hardware, which will make it possible to make the sensors and actuators interchangeable. This should make it possible to reduce the cost of the equipment and make it accessible to developing countries or areas not covered by traditional LPWAN and 3GPP networks. The impact of these new networks will have to be reviewed in the future to identify the new trends offered by 5G and satellite Internet. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have interfered with overall quality of the work reported in this paper. Acknowledgment This research is partially funded by Infortech and Numediart institutes. The authors would like to express their gratitude to Dr. Meryem Elmoulat for accepting to edit the writing of this paper and to Mr. Fabrice Nolack Fote for his help in the elaboration of the conceptual framework. References Agency, 2020 E.G. Agency Power-efficient positioning for THE Internet of Things – White Paper European GNSS Agency (2020), 10.2759/26127 Google Scholar Ai et al., 2018 Y. Ai, M. Peng, K. Zhang Edge computing technologies for internet of things: a primer Digital Commun. Networks, 4 (2018), pp. 77-86, 10.1016/j.dcan.2017.07.001 View PDFView articleView in ScopusGoogle Scholar Alonso et al., 2020 R.S. Alonso, I. Sittón-Candanedo, Óscar García, J. Prieto, S. Rodríguez-González An intelligent edge-iot platform for monitoring livestock and crops in a dairy farming scenario Ad Hoc Netw., 98 (2020), Article 102047, 10.1016/j.adhoc.2019.102047 View PDFView articleView in ScopusGoogle Scholar Amazon, 2021 Amazon, 2021a. Amazon dynamodb. url:https://aws.amazon.com/fr/dynamodb/. Google Scholar Amazon, 2021b Amazon, 2021b. Amazon web services. url: https://aws.amazon.com/. Google Scholar Ampatzidis et al., 2020 Y. Ampatzidis, V. Partel, L. Costa Agroview: Cloud-based application to process, analyze and visualize uav-collected data for precision agriculture applications utilizing artificial intelligence Comput. Electron. Agricul., 174 (2020), Article 105457, 10.1016/j.compag.2020.105457 View PDFView articleView in ScopusGoogle Scholar Andriamandroso et al., 2017 A.L.H. Andriamandroso, F. Lebeau, Y. Beckers, E. Froidmont, I. Dufrasne, B. Heinesch, P. Dumortier, G. Blanchy, Y. Blaise, J. Bindelle Development of an open-source algorithm based on inertial measurement units (imu) of a smartphone to detect cattle grass intake and ruminating behaviors Comput. Electron. Agricult., 139 (2017), pp. 126-137, 10.1016/j.compag.2017.05.020 View PDFView articleView in ScopusGoogle Scholar Apache Software Foundation, 2021a Apache Software Foundation, A., 2021a. Cassandra. url: https://cassandra.apache.org. Google Scholar Apache Software Foundation, 2021b Apache Software Foundation, A., 2021b. Druid. url: https://druid.apache.org. Google Scholar Assis and Bittencourt, 2016 M.R. Assis, L.F. Bittencourt A survey on cloud federation architectures: identifying functional and non-functional properties J. Network Comput. Appl., 72 (2016), pp. 51-71, 10.1016/j.jnca.2016.06.014 View PDFView articleView in ScopusGoogle Scholar AT&T, 2021 AT&T, P., 2021. At&t continues to fuel growth of the internet of things with launch of new developer-friendly managed service. url: https://about.att.com/story/m2x_data_service_for_enterprise_developers.html. Google Scholar Ayaz et al., 2019 M. Ayaz, M. Ammad-Uddin, Z. Sharif, A. Mansour, E.H.M. Aggoune Internet-of-things (iot)-based smart agriculture: toward making the fields talk IEEE Access, 7 (2019), pp. 129551-129583, 10.1109/ACCESS.2019.2932609 View in ScopusGoogle Scholar Badidi, 2020 E. Badidi Qos-aware placement of tasks on a fog cluster in an edge computing environment J. Ubiquitous Syst. Pervasive Networks, 13 (2020), pp. 11-19, 10.5383/JUSPN.13.01.002 Google Scholar Bermeo-Almeida et al., 2018 Bermeo-Almeida, O., Cardenas-Rodriguez, M., Samaniego-Cobo, T., Ferruzola-Gómez, E., Cabezas-Cabezas, R., Bazán-Vera, W., 2018. Blockchain in agriculture: A systematic literature review, in: International Conference on Technologies and Innovation, Springer. pp. 44–56. doi:10.1007/978-3-030-00940-3_4. Google Scholar Bixio et al., 2020 L. Bixio, G. Delzanno, S. Rebora, M. Rulli A flexible iot stream processing architecture based on microservices Information, 11 (2020), p. 565, 10.3390/info11120565 Google Scholar Blynk, 2021 Blynk, 2021. Blynk iot platform: for businesses and developers. url:  https://blynk.io. Google Scholar Botta et al., 2016 A. Botta, W. De Donato, V. Persico, A. Pescapé Integration of cloud computing and internet of things: a survey Future Generat. Comput. Syst., 56 (2016), pp. 684-700, 10.1016/j.future.2015.09.021 View PDFView articleView in ScopusGoogle Scholar Byers, 2017 C.C. Byers Architectural imperatives for fog computing: Use cases, requirements, and architectural techniques for fog-enabled iot networks IEEE Commun. Mag., 55 (2017), pp. 14-20, 10.1109/MCOM.2017.1600885 View in ScopusGoogle Scholar Carnevale et al., 2019 L. Carnevale, A. Celesti, A. Galletta, S. Dustdar, M. Villari Osmotic computing as a distributed multi-agent system: the body area network scenario Internet of Things, 5 (2019), pp. 130-139, 10.1016/j.iot.2019.01.001 View PDFView articleView in ScopusGoogle Scholar Cisco, 2018 C. Cisco Cisco global cloud index: Forecast and methodology, 2016–2021 Cisco, San Jose (2018) Google Scholar Codeluppi et al., 2020 G. Codeluppi, A. Cilfone, L. Davoli, G. Ferrari Lorafarm: A lorawan-based smart farming modular iot architecture Sensors, 20 (2020), 10.3390/s20072028 url:  https://www.mdpi.com/1424-8220/20/7/2028 Google Scholar Conesa-Munoz et al., 2016 J. Conesa-Muñoz, J. Valente, J. Del Cerro, A. Barrientos, A. Ribeiro A multi-robot sense-act approach to lead to a proper acting in environmental incidents Sensors, 16 (2016), p. 1269, 10.3390/s16081269 View in ScopusGoogle Scholar Corp, 2020 Corp, P.H., 2020. Sensorcloud. url:  https://sensorcloud.com/. Google Scholar Debauche et al., 2018 O. Debauche, M. El Moulat, S. Mahmoudi, S. Boukraa, P. Manneback, F. Lebeau Web monitoring of bee health for researchers and beekeepers based on the internet of things Proc. Comput. Sci., 130 (2018), pp. 991-998, 10.1016/j.procs.2018.04.103 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2019 O. Debauche, S. Mahmoudi, A.L.H. Andriamandroso, P. Manneback, J. Bindelle, F. Lebeau Cloud services integration for farm animals’ behavior studies based on smartphones as activity sensors J. Ambient Intell. Humanized Comput., 10 (2019), pp. 4651-4662, 10.1007/s12652-018-0845-9 View in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, M. Elmoulat, S.A. Mahmoudi, P. Manneback, F. Lebeau Edge ai-iot pivot irrigation, plant diseases, and pests identification Proc. Comput. Sci., 177 (2020), pp. 40-48, 10.1016/j.procs.2020.10.009 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi, P. Manneback, J. Bindelle, F. Lebeau Edge computing and artificial intelligence for real-time poultry monitoring Proc. Comput. Sci., 175 (2020), pp. 534-541, 10.1016/j.procs.2020.07.076 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi, P. Manneback, J. Bindelle, F. Lebeau Edge computing for cattle behavior analysis 2020 Second International Conference on Embedded & Distributed Systems (EDiS), IEEE (2020), pp. 52-57, 10.1109/EDiS49545.2020.9296471 View in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi, P. Manneback, F. Lebeau A new edge architecture for ai-iot services deployment Proc. Comput. Sci., 175 (2020), pp. 10-19, 10.1016/j.procs.2020.07.006 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S.A. Mahmoudi, N. De Cock, S. Mahmoudi, P. Manneback, F. Lebeau Cloud architecture for plant phenotyping research Concurrency and Computation: Practice and Experience, 32 (2020), Article e5661, 10.1002/cpe.5661 View in ScopusGoogle Scholar Debauche et al., 2018 O. Debauche, S.A. Mahmoudi, S. Mahmoudi, P. Manneback Cloud platform using big data and hpc technologies for distributed and parallels treatments Proc. Comput. Sci., 141 (2018), pp. 112-118, 10.1016/j.procs.2018.10.156 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2021 O. Debauche, J.P. Trani, S. Mahmoudi, P. Manneback, J. Bindelle, S.A. Mahmoudi, A. Guttadauria, F. Lebeau Data management and internet of things: a methodological review in smart farming Internet of Things, 14 (2021), Article 100378, 10.1016/j.iot.2021.100378 View PDFView articleView in ScopusGoogle Scholar Diaz et al., 2016 M. Díaz, C. Martín, B. Rubio State-of-the-art, challenges, and open issues in the integration of internet of things and cloud computing J. Network Comput. Appl., 67 (2016), pp. 99-117, 10.1016/j.jnca.2016.01.010 View PDFView articleView in ScopusGoogle Scholar Drakos et al., 2015 Drakos, A., Protonotarios, V., Manouselis, N., 2015. aginfra: a research data hub for agriculture, food and the environment. F1000Res. 4. doi:10.12688/f1000research.6349.2. Google Scholar El-Sayed et al., 2017 H. El-Sayed, S. Sankar, M. Prasad, D. Puthal, A. Gupta, M. Mohanty, C.T. Lin Edge of things: the big picture on the integration of edge, iot and the cloud in a distributed computing environment IEEE Access, 6 (2017), pp. 1706-1717, 10.1109/ACCESS.2017.2780087 View in ScopusGoogle Scholar Elijah et al., 2018 O. Elijah, T.A. Rahman, I. Orikumhi, C.Y. Leow, M.N. Hindia An overview of internet of things (iot) and data analytics in agriculture: benefits and challenges IEEE Internet Things J., 5 (2018), pp. 3758-3773, 10.1109/JIOT.2018.2844296 View in ScopusGoogle Scholar Estrada and Ruiz, 2016 Estrada, R., Ruiz, I., 2016. Big data smack: A guide to apache spark. Mesos, Akka, Cassandra, and Kafka. Google Scholar Fan and Gao, 2018 D. Fan, S. Gao The application of mobile edge computing in agricultural water monitoring system IOP Conference Series: Earth and Environmental Science, IOP Publishing (2018), p. 012015 CrossRefView in ScopusGoogle Scholar Fang, 2015 Fang, H., 2015. Managing data lakes in big data era: What’s a data lake and why has it became popular in data management ecosystem, in: 2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER), IEEE. pp. 820–824. doi:10.1109/CYBER.2015.7288049. Google Scholar Farooq et al., 2019 M.S. Farooq, S. Riaz, A. Abid, K. Abid, M.A. Naeem A survey on the role of iot in agriculture for the implementation of smart farming IEEE Access, 7 (2019), pp. 156237-156271, 10.1109/ACCESS.2019.2949703 View in ScopusGoogle Scholar Feng et al., 2019 X. Feng, F. Yan, X. Liu Study of wireless communication technologies on internet of things for precision agriculture Wireless Pers. Commun., 108 (2019), pp. 1785-1802, 10.1007/s11277-019-06496-7 View in ScopusGoogle Scholar Fernandez et al., 2015 Fernandez, R.C., Pietzuch, P.R., Kreps, J., Narkhede, N., Rao, J., Koshy, J., Lin, D., Riccomini, C., Wang, G., 2015. Liquid: Unifying nearline and offline big data integration., in: CIDR, pp. 1–8. url:  http://hdl.handle.net/10044/1/23433. Google Scholar Ferrag et al., 2020 M.A. Ferrag, L. Shu, X. Yang, A. Derhab, L. Maglaras Security and privacy for green iot-based agriculture: review, blockchain solutions, and challenges IEEE Access, 8 (2020), pp. 32031-32053, 10.1109/ACCESS.2020.2973178 View in ScopusGoogle Scholar Fote et al., 2020 F.N. Fote, A. Roukh, S. Mahmoudi, S.A. Mahmoudi, O. Debauche Toward a big data knowledge-base management system for precision livestock farming Proc. Comput. Sci., 177 (2020), pp. 136-142, 10.1016/j.procs.2020.10.021 View PDFView articleView in ScopusGoogle Scholar Friha et al., 2021 O. Friha, M.A. Ferrag, L. Shu, L.A. Maglaras, X. Wang Internet of things for the future of smart agriculture: a comprehensive survey of emerging technologies IEEE CAA J. Autom. Sinica, 8 (2021), pp. 718-752, 10.1109/JAS.2021.1003925 View in ScopusGoogle Scholar Gallinucci et al., 2019 E. Gallinucci, M. Golfarelli, S. Rizzi A hybrid architecture for tactical and strategic precision agriculture C. Ordonez, I.Y. Song, G. Anderst-Kotsis, A.M. Tjoa, I. Khalil (Eds.), Big Data Analytics and Knowledge Discovery, Springer International Publishing, Cham (2019), pp. 13-23, 10.1007/978-3-030-27520-4_2 View in ScopusGoogle Scholar Gallinucci et al., 2020 E. Gallinucci, M. Golfarelli, S. Rizzi Mo. re. farming: A hybrid architecture for tactical and strategic precision agriculture Data Knowl. Eng., 129 (2020), Article 101836, 10.1016/j.datak.2020.101836 View PDFView articleView in ScopusGoogle Scholar Garcia et al., 2020 L. García, L. Parra, J.M. Jimenez, J. Lloret, P. Lorenz Iot-based smart irrigation systems: an overview on the recent trends on sensors and iot systems for irrigation in precision agriculture Sensors, 20 (2020), p. 1042, 10.3390/s20041042 View in ScopusGoogle Scholar Lopez et al., 2015 Garcia Lopez, P., Montresor, A., Epema, D., Datta, A., Higashino, T., Iamnitchi, A., Barcellos, M., Felber, P., Riviere, E., 2015. Edge-centric computing: Vision and challenges. doi:10.1145/2831347.2831354. Google Scholar Giebler et al., 2018 Giebler, C., Stach, C., Schwarz, H., Mitschang, B., 2018. Braid, in: Proceedings of the 7th International Conference on Data Science, Technology and Applications, pp. 294–301. doi:10.5220/0006861802940301. Google Scholar Google, 2021 Google, 2021. Firebase. url:  https://firebase.google.com/. Google Scholar Granell et al., 2017 Granell, C., Miralles, I., Rodríguez-Pupo, L.E., González-Pérez, A., Casteleyn, S., Busetto, L., Pepe, M., Boschetti, M., Huerta, J., 2017. Conceptual architecture and service-oriented implementation of a regional geoportal for rice monitoring. ISPRS Int. J. Geo-Inform. 6. url: https://www.mdpi.com/2220-9964/6/7/191, doi:10.3390/ijgi6070191. Google Scholar Grover and Garimella, 2018 Grover, J., Garimella, R.M., 2018. Reliable and fault-tolerant iot-edge architecture, in: 2018 IEEE sensors, IEEE. pp. 1–4. doi:10.1109/ICSENS.2018.8589624. Google Scholar Guardo et al., 2018 E. Guardo, A. Di Stefano, A. La Corte, M. Sapienza, M. Scatà A fog computing-based iot framework for precision agriculture J. Internet Technol., 19 (2018), pp. 1401-1411, 10.3966/160792642018091905012 View in ScopusGoogle Scholar Gupta et al., 2020 M. Gupta, M. Abdelsalam, S. Khorsandroo, S. Mittal Security and privacy in smart farming: challenges and opportunities IEEE Access, 8 (2020), pp. 34564-34584, 10.1109/ACCESS.2020.2975142 View in ScopusGoogle Scholar Hausenblas, 2014 Hausenblas, M., 2014. Internet of things architecture (iot-a) home page. url:  https://github.com/mhausenblas/iot-a.info. Google Scholar Iaksch et al., 2021 J. Iaksch, E. Fernandes, M. Borsato Digitalization and big data in smart farming–a review J. Manage. Anal., 8 (2021), pp. 333-349, 10.1080/23270012.2021.1897957 View in ScopusGoogle Scholar IBM, 2015 IBM, 2015. Ibm watson iot platform. url:  https://internetofthings.ibmcloud.com/. Google Scholar IBM, 2021 IBM, 2021. Ibm cloud. url:  https://www.ibm.com/cloud. Google Scholar Influxdata, 2021 Influxdata, 2021. Infludb cloud. url:  https://www.influxdata.com/products/influxdb-cloud/. Google Scholar Souces and I., 2021 Integra Souces, I., 2021. Iot solution development services. url:  https://www.integrasources.com/iot-page/. Google Scholar Jayaraman et al., 2016 P.P. Jayaraman, A. Yavari, D. Georgakopoulos, A. Morshed, A. Zaslavsky Internet of things platform for smart farming: experiences and lessons learnt Sensors, 16 (2016), p. 1884, 10.3390/s16111884 View in ScopusGoogle Scholar KaaIoT, 2021 KaaIoT, 2021. Ubidots. url:  https://docs.kaaiot.io/KAA/docs/current/Welcome/. Google Scholar Kamilaris et al., 2019 Kamilaris, A., Fonts, A., Prenafeta-Boldv́, F.X., 2019. The rise of blockchain technology in agriculture and food supply chains. Trends Food Sci. Technol. 91, 640–652. doi:10.1016/j.tifs.2019.07.034. Google Scholar Kaur et al., 2020 A. Kaur, R. Kumar, S. Saxena Osmotic computing and related challenges: a survey 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), IEEE (2020), pp. 378-383, 10.1109/PDGC50313.2020.9315757 View in ScopusGoogle Scholar Kazim et al., 2018 M. Kazim, L. Liu, S.Y. Zhu A framework for orchestrating secure and dynamic access of iot services in multi-cloud environments IEEE Access, 6 (2018), pp. 58619-58633, 10.1109/ACCESS.2018.2873812 View in ScopusGoogle Scholar Khanna and Kaur, 2019 A. Khanna, S. Kaur Evolution of internet of things (iot) and its significant impact in the field of precision agriculture Comput. Electron. Agricul., 157 (2019), pp. 218-231, 10.1016/j.compag.2018.12.039 View PDFView articleView in ScopusGoogle Scholar Kodati and Jeeva, 2019 S. Kodati, S. Jeeva Smart agricultural using internet of things, cloud and big data Int. J. Innov. Technol. Exploring Eng. (IJITEE), 8 (2019), pp. 3718-3722, 10.35940/ijitee.J9671.0881019 View in ScopusGoogle Scholar Kreps, 2014 Kreps, J., 2014. Questioning the lambda architecture. Online article, July 205. Google Scholar Lakhe, 2016 B. Lakhe Practical Hadoop migration: how to integrate your RDBMS with the Hadoop ecosystem and re-architect relational applications to NoSQL Apress (2016) Google Scholar Liu et al., 2020 Y. Liu, X. Ma, L. Shu, G.P. Hancke, A.M. Abu-Mahfouz From industry 4.0 to agriculture 4.0: current status, enabling technologies, and research challenges IEEE Trans. Industr. Inf., 17 (2020), pp. 4322-4334, 10.1109/TII.2020.3003910 Google Scholar López et al., 2020 I.D. López, J.F. Grass, A. Figueroa, J.C. Corrales A proposal for a multi-domain data fusion strategy in a climate-smart agriculture context Int. Trans. Oper. Res. (2020), 10.1111/itor.12899 Google Scholar Luis Bustamante et al., 2019 A. Luis Bustamante, M.A. Patricio, J.M. Molina Thinger. io: an open source platform for deploying data fusion applications in iot environments Sensors, 19 (2019), p. 1044, 10.3390/s19051044 Google Scholar Mach and Becvar, 2017 P. Mach, Z. Becvar Mobile edge computing: a survey on architecture and computation offloading IEEE Commun. Surveys Tutorials, 19 (2017), pp. 1628-1656, 10.1109/COMST.2017.2682318 View in ScopusGoogle Scholar Madera et al., 2017 Madera, C., Laurent, A., Rouge, T.L., Miralles, A., 2017. How can the data lake concept influence information system design for agriculture? In: 11th European conference dedicated to the future use of ICT in the agri-food sector, bioresource and biomass sector (EFITA 2017), pp. 181–182. Google Scholar Maksimović, 2018 M. Maksimović The role of osmotic computing in internet of things 2018 17th International Symposium INFOTEH-JAHORINA (INFOTEH), IEEE (2018), pp. 1-4, 10.1109/INFOTEH.2018.8345538 View in ScopusGoogle Scholar Manyika and Chui, 2015 Manyika, J., Chui, M., 2015. By 2025, internet of things applications could have $11 trillion impact. Insight Publications. Google Scholar Martos et al., 2021 V. Martos, A. Ahmad, P. Cartujo, J. Ordoñez Ensuring agricultural sustainability through remote sensing in the era of agriculture 5.0 Appl. Sci., 11 (2021), p. 5911, 10.3390/app11135911 View in ScopusGoogle Scholar Marz and Warren, 2013 N. Marz, J. Warren Big Data: Principles and best practices of scalable real-time data systems Manning (2013) Google Scholar Maureira et al., 2011 M.A.G. Maureira, D. Oldenhof, L. Teernstra Thingspeak–an api and web service for the internet of things World Wide Web (2011) Google Scholar Meehan et al., 2016 J. Meehan, S. Zdonik, S. Tian, Y. Tian, N. Tatbul, A. Dziedzic, A. Elmore Integrating real-time and batch processing in a polystore 2016 IEEE High Performance Extreme Computing Conference (HPEC), IEEE (2016), pp. 1-7, 10.1109/HPEC.2016.7761585 Google Scholar Meola, 2021 Meola, A., 2021. Smart farming in 2020: How iot sensors are creating a more efficient precision agriculture industry. url:  https://www.businessinsider.com/smart-farming-iot-agriculture?IR=T. Google Scholar Microsoft, 2021a Microsoft, 2021a. Azure. url:  https://azure.microsoft.com. Google Scholar Microsoft, 2021b Microsoft, 2021b. Azure iot. url:  https://azure.microsoft.com/en-us/overview/iot/. Google Scholar Miloslavskaya and Tolstoy, 2016 N. Miloslavskaya, A. Tolstoy Big data, fast data and data lake concepts Proc. Comput. Sci., 88 (2016), pp. 300-305, 10.1016/j.procs.2016.07.439 View PDFView articleView in ScopusGoogle Scholar Misra et al., 2020 N. Misra, Y. Dixit, A. Al-Mallahi, M.S. Bhullar, R. Upadhyay, A. Martynenko Iot, big data and artificial intelligence in agriculture and food industry IEEE Internet Things J. (2020), 10.1109/JIOT.2020.2998584 Google Scholar Mongo, 2021 Mongo, 2021. Mongodb atlas. url:  https://www.mongodb.com/en-us/cloud/atlas. Google Scholar Morshed et al., 2017 A. Morshed, P.P. Jayaraman, T. Sellis, D. Georgakopoulos, M. Villari, R. Ranjan Deep osmosis: holistic distributed deep learning in osmotic computing IEEE Cloud Comput., 4 (2017), pp. 22-32, 10.1109/MCC.2018.1081070 View in ScopusGoogle Scholar Munir et al., 2017 A. Munir, P. Kansakar, S.U. Khan Ifciot: Integrated fog cloud iot: a novel architectural paradigm for the future internet of things IEEE Consumer Electron. Mag., 6 (2017), pp. 74-82, 10.1109/MCE.2017.2684981 View in ScopusGoogle Scholar Mykleby et al., 2016 M. Mykleby, P. Doherty, J. Makower The New Grand Strategy: Restoring America’s Prosperity, Security, and Sustainability in the 21st Century St. Martin’s Press (2016) Google Scholar Navarro et al., 2020 E. Navarro, N. Costa, A. Pereira A systematic review of iot solutions for smart farming Sensors, 20 (2020), p. 4231, 10.3390/s20154231 Google Scholar Navarro-Hellin et al., 2016 H. Navarro-Hellín, J. Martinez-del Rincon, R. Domingo-Miguel, F. Soto-Valles, R. Torres-Sánchez A decision support system for managing irrigation in agriculture Comput. Electron. Agricul., 124 (2016), pp. 121-131, 10.1016/j.compag.2016.04.003 View PDFView articleView in ScopusGoogle Scholar NECTEC, 2020 NECTEC, 2020. Netpie - network platform for internet of everything. url:  https://netpie.io. Google Scholar Neves and Cruvinel, 2020 R.A. Neves, P.E. Cruvinel Model for semantic base structuring of digital data to support agricultural management 2020 IEEE 14th International Conference on Semantic Computing (ICSC), IEEE (2020), pp. 337-340, 10.1109/ICSC.2020.00067 View in ScopusGoogle Scholar Nkamla Penka et al., 2021 J.B. Nkamla Penka, S. Mahmoudi, O. Debauche A new kappa architecture for iot data management in smart farming Proc. Comput. Sci. (2021) In press Google Scholar Oracle, 2021 Oracle, 2021. Mysql. url:  https://www.mysql.com. Google Scholar Persico et al., 2018 V. Persico, A. Pescapé, A. Picariello, G. Sperlí Benchmarking big data architectures for social networks data processing using public cloud platforms Future Gener. Comput. Syst., 89 (2018), pp. 98-109, 10.1016/j.future.2018.05.068 View PDFView articleView in ScopusGoogle Scholar Pesonen et al., 2014 L.A. Pesonen, F.K.W. Teye, A.K. Ronkainen, M.O. Koistinen, J.J. Kaivosoja, P.F. Suomi, R.O. Linkolehto Cropinfra–an internet-based service infrastructure to support crop production in future farms Biosyst. Eng., 120 (2014), pp. 92-101, 10.1016/j.biosystemseng.2013.09.005 View PDFView articleView in ScopusGoogle Scholar Petcu et al., 2013 D. Petcu, B. Di Martino, S. Venticinque, M. Rak, T. Máhr, G.E. Lopez, F. Brito, R. Cossu, M. Stopar, S. Šperka, et al. Experiences in building a mosaic of clouds J. Cloud Comput.: Adv., Syst. Appl., 2 (2013), pp. 1-22, 10.1186/2192-113X-2-12 View in ScopusGoogle Scholar Popescu et al., 2020 D. Popescu, F. Stoican, G. Stamatescu, L. Ichim, C. Dragana Advanced uav–wsn system for intelligent monitoring in precision agriculture Sensors, 20 (2020), p. 817, 10.3390/s20030817 View in ScopusGoogle Scholar Radoglou-Grammatikis et al., 2020 P. Radoglou-Grammatikis, P. Sarigiannidis, T. Lagkas, I. Moscholios A compilation of uav applications for precision agriculture Comput. Netw., 172 (2020), Article 107148, 10.1016/j.comnet.2020.107148 View PDFView articleView in ScopusGoogle Scholar Rajakaruna et al., 2018 Rajakaruna, A., Manzoor, A., Porambage, P., Liyanage, M., Ylianttila, M., Gurtov, A., 2018. Lightweight dew computing paradigm to manage heterogeneous wireless sensor networks with uavs. arXiv preprint arXiv:1811.04283. Google Scholar Ray, 2017 P.P. Ray Internet of things for smart agriculture: technologies, practices and future direction J. Ambient Intell. Smart Environ., 9 (2017), pp. 395-420, 10.3233/AIS-170440 View in ScopusGoogle Scholar Ren et al., 2017 J. Ren, H. Guo, C. Xu, Y. Zhang Serving at the edge: a scalable iot architecture based on transparent computing IEEE Network, 31 (2017), pp. 96-105, 10.1109/MNET.2017.1700030 View in ScopusGoogle Scholar Rodriguez et al., 2018 M.A. Rodriguez, L. Cuenca, A. Ortiz Fiware open source standard platform in smart farming – a review L.M. Camarinha-Matos, H. Afsarmanesh, Y. Rezgui (Eds.), Collaborative Networks of Cognitive Systems, Springer International Publishing, Cham (2018), pp. 581-589, 10.1007/978-3-319-99127-6_50 View in ScopusGoogle Scholar Roman et al., 2018 R. Roman, J. Lopez, M. Mambo Mobile edge computing, fog et al.: a survey and analysis of security threats and challenges Future Gener. Comput. Syst., 78 (2018), pp. 680-698, 10.1016/j.future.2016.11.009 View PDFView articleView in ScopusGoogle Scholar Roukh et al., 2020 A. Roukh, F.N. Fote, S.A. Mahmoudi, S. Mahmoudi Big data processing architecture for smart farming Proc. Comput. Sci., 177 (2020), pp. 78-85, 10.1016/j.procs.2020.10.014 View PDFView articleView in ScopusGoogle Scholar Roukh et al., 2020 A. Roukh, F.N. Fote, S.A. Mahmoudi, S. Mahmoudi Wallesmart: cloud platform for smart farming, in 32nd International Conference on Scientific and Statistical Database Management (2020), pp. 1-4, 10.1145/3400903.3401690 Google Scholar Ruan et al., 2019 J. Ruan, H. Jiang, C. Zhu, X. Hu, Y. Shi, T. Liu, W. Rao, F.T.S. Chan Agriculture iot: Emerging trends, cooperation networks, and outlook IEEE Wirel. Commun., 26 (2019), pp. 56-63, 10.1109/MWC.001.1900096 View in ScopusGoogle Scholar Saiz-Rubio and Rovira-Más, 2020 V. Saiz-Rubio, F. Rovira-Más From smart farming towards agriculture 5.0: a review on crop data management Agronomy, 10 (2020), p. 207, 10.3390/agronomy10020207 View in ScopusGoogle Scholar Sallah et al., 2019 A.H.M. Sallah, B. Tychon, I. Piccard, A. Gobin, R. Van Hoolst, B. Djaby, J. Wellens Batch-processing of aquacrop plug-in for rainfed maize using satellite derived fractional vegetation cover data Agric. Water Manage., 217 (2019), pp. 346-355 Google Scholar Scott, 2015 Scott, J., 2015. Zeta architecture: Hexagon is the new circle. an enterprise architecture solution for scale and efficiency. url:  https://www.oreilly.com/ideas/zeta-architecture-hexagon-is-the-new-circle. Google Scholar Sethi and Sarangi, 2017 P. Sethi, S.R. Sarangi Internet of things: architectures, protocols, and applications J. Electr. Comput. Eng., 2017 (2017), 10.1155/2017/9324035 Google Scholar Shafi et al., 2019 U. Shafi, R. Mumtaz, J. García-Nieto, S.A. Hassan, S.A.R. Zaidi, N. Iqbal Precision agriculture techniques and practices: From considerations to applications Sensors, 19 (2019), p. 3796, 10.3390/s19173796 View in ScopusGoogle Scholar Sharofidinov et al., 2020 F. Sharofidinov, M.S.A. Muthanna, V.D. Pham, A. Khakimov, A. Muthanna, K. Samouylov Agriculture management based on lora edge computing system V.M. Vishnevskiy, K.E. Samouylov, D.V. Kozyrev (Eds.), Distributed Computer and Communication Networks, Springer International Publishing, Cham (2020), pp. 113-125 CrossRefView in ScopusGoogle Scholar Shi et al., 2016 W. Shi, J. Cao, Q. Zhang, Y. Li, L. Xu Edge computing: vision and challenges IEEE Internet Things J., 3 (2016), pp. 637-646, 10.1109/JIOT.2016.2579198 View in ScopusGoogle Scholar Shi et al., 2019 X. Shi, X. An, Q. Zhao, H. Liu, L. Xia, X. Sun, Y. Guo State-of-the-art internet of things in protected agriculture Sensors, 19 (2019), p. 1833, 10.3390/s19081833 View in ScopusGoogle Scholar Siciliani, 2015 Siciliani, T., 2015. Big data using lambda architecture. url: https://dzone.com/articles/lambda-architecture-big-data. Google Scholar Sigrimis et al., 2002 Sigrimis, N., Arvanitis, K., Ferentinos, K., 2002. Macqu: An open scada system for intelligent management and control of greenhouses, in: 2002 ASAE Annual Meeting, American Society of Agricultural and Biological Engineers. p. 1. doi:10.13031/2013.9618. Google Scholar Singh et al., 2019 K.N. Singh, R.K. Behera, J.K. Mantri Big data ecosystem: review on architectural evolution Emerging Technol. Data Mining Inform. Secur., 335–345 (2019), 10.1007/978-981-13-1498-8_30 Google Scholar Sipos et al., 2013 Sipos, G., Turilli, M., Newhouse, S., Kacsuk, P., 2013. A european federated cloud: Innovative distributed computing solutions by egi, in: EGU General Assembly Conference Abstracts, pp. EGU2013–8690. Google Scholar Skala et al., 2015 K. Skala, D. Davidovic, E. Afgan, I. Sovic, Z. Sojat Scalable distributed computing hierarchy: cloud, fog and dew computing Open J. Cloud Comput. (OJCC), 2 (2015), pp. 16-24, 10.19210/1002.2.1.16 Google Scholar SQLite, 2021 SQLite, 2021. Sqlite. url: https://www.sqlite.org. Google Scholar Sun et al., 2017 L. Sun, Y. Li, R.A. Memon An open iot framework based on microservices architecture China Commun., 14 (2017), pp. 154-162, 10.1109/CC.2017.7868163 View in ScopusGoogle Scholar Talavera et al., 2017 J.M. Talavera, L.E. Tobón, J.A. Gómez, M.A. Culman, J.M. Aranda, D.T. Parra, L.A. Quiroz, A. Hoyos, L.E. Garreta Review of iot applications in agro-industrial and environmental fields Comput. Electron. Agricul., 142 (2017), pp. 283-297, 10.1016/j.compag.2017.09.015 View PDFView articleView in ScopusGoogle Scholar Taneja et al., 2020 M. Taneja, J. Byabazaire, N. Jalodia, A. Davy, C. Olariu, P. Malone Machine learning based fog computing assisted data-driven approach for early lameness detection in dairy cattle Comput. Electron. Agricul., 171 (2020), Article 105286, 10.1016/j.compag.2020.105286 View PDFView articleView in ScopusGoogle Scholar Taneja et al., 2019 M. Taneja, N. Jalodia, J. Byabazaire, A. Davy, C. Olariu Smartherd management: a microservices-based fog computing–assisted iot platform towards data-driven smart dairy farming Software: Practice Experience, 49 (2019), pp. 1055-1078, 10.1002/spe.2704 View in ScopusGoogle Scholar Tang et al., 2021 Y. Tang, S. Dananjayan, C. Hou, Q. Guo, S. Luo, Y. He A survey on the 5g network and its impact on agriculture: challenges and opportunities Comput. Electron. Agricul., 180 (2021), Article 105895, 10.1016/j.compag.2020.105895 View PDFView articleView in ScopusGoogle Scholar The PostgreSQL Global Development Group, 2021 The PostgreSQL Global Development Group, P., 2021. Postgresql: The world’s most advanced open source relational database. url:  https://www.postgresql.org/. Google Scholar Tran et al., 2017 T.X. Tran, A. Hajisami, P. Pandey, D. Pompili Collaborative mobile edge computing in 5g networks: new paradigms, scenarios, and challenges IEEE Commun. Mag., 55 (2017), pp. 54-61, 10.1109/MCOM.2017.1600863 View in ScopusGoogle Scholar Triantafyllou et al., 2019 A. Triantafyllou, P. Sarigiannidis, S. Bibi Precision agriculture: a remote sensing monitoring system architecture Information, 10 (2019), p. 348, 10.3390/info10110348 View in ScopusGoogle Scholar Tzounis et al., 2017 A. Tzounis, N. Katsoulas, T. Bartzanas, C. Kittas Internet of things in agriculture, recent advances and future challenges Biosyst. Eng., 164 (2017), pp. 31-48, 10.1016/j.biosystemseng.2017.09.007 View PDFView articleView in ScopusGoogle Scholar Ubidots, 2021 Ubidots, 2021. Ubidots. url:  https://ubidots.com/. Google Scholar Uehara, 2017 Uehara, M., 2017. Mist computing: Linking cloudlet to fogs, in: International Conference on Computational Science/Intelligence & Applied Informatics, Springer. pp. 201–213. doi:10.1007/978-3-319-63618-4_15. Google Scholar Valecce et al., 2019 G. Valecce, S. Strazzella, L.A. Grieco On the interplay between 5g, mobile edge computing and robotics in smart agriculture scenarios M.R. Palattella, S. Scanzio, S. Coleri Ergen (Eds.), Ad-Hoc, Mobile, and Wireless Networks, Springer International Publishing, Cham (2019), pp. 549-559, 10.1007/978-3-030-31831-4_38 View in ScopusGoogle Scholar Villa-Henriksen et al., 2020 A. Villa-Henriksen, G.T. Edwards, L.A. Pesonen, O. Green, C.A.G. Sørensen Internet of things in arable farming: implementation, applications, challenges and potential Biosyst. Eng., 191 (2020), pp. 60-84, 10.1016/j.biosystemseng.2019.12.013 View PDFView articleView in ScopusGoogle Scholar Villari et al., 2017 Villari, M., Celesti, A., Fazio, M., 2017. Towards osmotic computing: Looking at basic principles and technologies, in: Conference on Complex, Intelligent, and Software Intensive Systems, Springer. pp. 906–915. doi:10.1007/978-3-319-61566-086. Google Scholar Villari et al., 2014 M. Villari, A. Celesti, M. Fazio, A. Puliafito Alljoyn lambda: an architecture for the management of smart environments in iot 2014 International Conference on Smart Computing Workshops, IEEE (2014), pp. 9-14, 10.1109/SMARTCOMP-W.2014.7046676 View in ScopusGoogle Scholar Villari et al., 2016 M. Villari, M. Fazio, S. Dustdar, O. Rana, R. Ranjan Osmotic computing: a new paradigm for edge/cloud integration IEEE Cloud Comput., 3 (2016), pp. 76-83, 10.1109/MCC.2016.124 View in ScopusGoogle Scholar Wang et al., 2020 X. Wang, Y. Han, V.C. Leung, D. Niyato, X. Yan, X. Chen Edge AI: Convergence of Edge Computing and Artificial Intelligence Springer Nature (2020), 10.1007/978-981-15-6186-3 Google Scholar Wang, 2016 Y. Wang Definition and categorization of dew computing Open J. Cloud Comput. (OJCC), 3 (2016), pp. 1-7, 10.19210/1002.3.1.1 View PDFView articleGoogle Scholar Wolfert et al., 2017 S. Wolfert, L. Ge, C. Verdouw, M.J. Bogaardt Big data in smart farming–a review Agricult. Syst., 153 (2017), pp. 69-80, 10.1016/j.agsy.2017.01.023 View PDFView articleView in ScopusGoogle Scholar Yang, 2017 S. Yang Iot stream processing and analytics in the fog IEEE Commun. Mag., 55 (2017), pp. 21-27, 10.1109/MCOM.2017.1600840 View in ScopusGoogle Scholar Zhai et al., 2020 Z. Zhai, J.F. Martínez, V. Beltran, N.L. Martínez Decision support systems for agriculture 4.0: Survey and challenges Comput. Electron. Agricul., 170 (2020), Article 105256, 10.1016/j.compag.2020.105256 View PDFView articleView in ScopusGoogle Scholar Zhang, 2016 Zhang, Q., 2016. Precision agriculture technology for crop farming. Taylor & Francis. doi:10.1201/b19336. Google Scholar Zhou et al., 2017 Y. Zhou, D. Zhang, N. Xiong Post-cloud computing paradigms: a survey and comparison Tsinghua Sci. Technol., 22 (2017), pp. 714-732, 10.23919/TST.2017.8195353 View in ScopusGoogle Scholar Cited by (28) The convergence of Digital Twins and Distributed Ledger Technologies: A systematic literature review and an architectural proposal 2024, Journal of Network and Computer Applications Show abstract Integrated design framework for smart agriculture: Bridging the gap between digitalization and sustainability 2024, Journal of Cleaner Production Show abstract Spatio-temporal semantic data management systems for IoT in agriculture 5.0: Challenges and future directions 2024, Internet of Things (Netherlands) Show abstract Internet of agriculture: Analyzing and predicting tractor ride comfort through supervised machine learning 2023, Engineering Applications of Artificial Intelligence Show abstract A real-time decision-making tool based on dynamic thresholds for Phthorimaea absoluta management in greenhouse tomato 2023, Crop Protection Show abstract Information management infrastructures for multipurpose unmanned aerial systems operations 2023, Unmanned Aerial Systems in Agriculture: Eyes Above Fields Show abstract View all citing articles on Scopus Peer review under responsibility of King Saud University. 1 https://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/ 2 https://www.statista.com/statistics/499431/global-ip-data-traffic-forecast/ 3 https://www.pix4d.com/ 4 http://prospera.ag/ © 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. Recommended articles Multi-user routing algorithm for indoor spaces – Adapted for social distancing Journal of King Saud University - Computer and Information Sciences, Volume 34, Issue 9, 2022, pp. 7045-7058 Abdullah Alamri, …, Sultan Alamri View PDF Embedding and generalization of formula with context in the retrieval of mathematical information Journal of King Saud University - Computer and Information Sciences, Volume 34, Issue 9, 2022, pp. 6624-6634 Pankaj Dadure, …, Sivaji Bandyopadhyay View PDF mySense: A comprehensive data management environment to improve precision agriculture practices Computers and Electronics in Agriculture, Volume 162, 2019, pp. 882-894 Raul Morais, …, Emanuel Peres View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 21 Captures Readers: 194 Social Media Shares, Likes & Comments: 60 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 4:
- APA Citation: Chaterji, S., DeLay, N., Evans, J., Mosier, N., Engel, B., Buckmaster, D., ... Chandra, R. (2022). Lattice: A vision for machine learning, data engineering, and policy considerations for digital agriculture at scale. IEEE Open Journal of the Computer Society, 2, 227–240. https://doi.org/10.1109/OJCS.2021.3085846
  Main Objective: To propose an integrated vision for IoT solutions, data processing, and actionable analytics for digital agriculture, considering economic and policy factors.
  Study Location: Unspecified
  Data Sources: NA
  Technologies Used: NA
  Key Findings: The paper emphasizes the following key findings:
1. Metadata plays a crucial role in providing context and enabling better data interpretation and decision-making in digital agriculture.
2. Automated metadata annotation techniques can enhance data processing efficiency.
3. Interpretable data analytics are essential for farmers to understand and utilize the results of data analysis for informed decision-making.
  Extract 1: "Metadata annotation can be done manually or automated. Since the data that we are considering is prone to be complex, automated metadata annotation is preferred."
  Extract 2: "In Fig. 3, we illustrate data flow in FarmBeats as an example."
  Limitations: None
  Relevance Evaluation: This paper is highly relevant to my point on the role of metadata in providing context and enabling better data interpretation and decision-making in the context of automated irrigation management systems. The paper discusses the importance of metadata annotation, cleaning, and processing for accurate data analysis and emphasizes the use of automated metadata annotation techniques for efficient data handling. It also highlights the need for interpretable data analytics to facilitate understanding and actionable insights for farmers.
  Relevance Score: 1.0
  Inline Citation: Chaterji et al. (2022)
  Explanation: This paper presents a vision for an integrated Internet of Things (IoT) and machine learning framework to advance digital agriculture. It explores various aspects of data collection, processing, and analysis, focusing on the significance of metadata for data interpretation and decision-making.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign In Browse My Settings Help Institutional Sign In All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Open Journal of the Comp... >Volume: 2 Lattice: A Vision for Machine Learning, Data Engineering, and Policy Considerations for Digital Agriculture at Scale Publisher: IEEE Cite This PDF Somali Chaterji; Nathan DeLay; John Evans; Nathan Mosier; Bernard Engel; Dennis Buckmaster; Michael R. Ladisch; Ranveer Chandra All Authors 12 Cites in Papers 1858 Full Text Views Open Access Under a Creative Commons License Abstract Document Sections I. Introduction II. Data Generation From Sensors III. Data Lifecycle IV. Data Analytics for Digital Agriculture V. Edge Computing and Low-Power Communication Technologies Show Full Outline Authors Figures References Citations Keywords Metrics Footnotes Abstract: Digital agriculture, with the incorporation of Internet-of-Things (IoT)-based technologies, presents the ability to control a system at multiple levels (individual, local, regional, and global) and generates tools that allow for improved decision making and higher productivity. Recent advances in IoT hardware, e.g., networks of heterogeneous embedded devices, and software, e.g., lightweight computer vision algorithms and cloud optimization solutions, make it possible to efficiently process data from diverse sources in a connected (smart) farm. By interconnecting these IoT devices, often across large geographical distances, it is possible to collect data at different time scales, including in near real-time (i.e., with delays of only a few tens of seconds). This data can then be used for actionable insights, e.g., precise applications of soil supplements and reduced environmental footprint. Through LATTICE, we present an integrated vision for IoT solutions, data processing, and actionable analytics for digital agriculture. We couple this with discussion of economics and policy considerations that will underlie adoption of such IoT and ML technologies. Our paper starts off with the types of datasets in typical field operations, followed by the lifecycle for the data and storage, cloud and edge analytics, and fast information-retrieval solutions. We discuss what algorithms are proving to be most impactful in this space, e.g., approximate data analytics and on-device/in-network processing. We conclude by discussing analytics for alternative agriculture for generation of biofuels and policy challenges in the implementation of digital agriculture in the wild. Published in: IEEE Open Journal of the Computer Society ( Volume: 2) Page(s): 227 - 240 Date of Publication: 01 June 2021 Electronic ISSN: 2644-1268 DOI: 10.1109/OJCS.2021.3085846 Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction By 2050, the world's population is projected to increase to nine billion, which will intensify the food-water-energy nexus challenges. Demand will also rise because of increase in people's wealth resulting in higher meat consumption plus the increasing use of cropland for biofuels. Site-specific farm management (precision farming) has the potential to nourish the world while increasing farm profitability under constrained resource conditions. Despite advancements in field sensors, the global positioning system (GPS), and grid soil sampling, adoption of technology by farm operators has fallen short of expectations. Moreover, it is unclear how profitable the adoption of such technologies will be. Use of variable rate technology (VRT), for example, has lagged that of yield monitors and automated guidance systems. A thorough study [1], including rigorous analysis, has shown how the lack of widespread adoption of VRT can be attributed to the paucity of site-specific data. Specifically in this study, the authors attributed the scant adoption of variable rate nitrogen application to the lack of site-specific yield data. The generalizable insight from this is that site-specific detailed data about the effects of digital agriculture interventions are important to drive their adoption. Identified gaps motivating Lattice Some of the gaps on the agricultural side include: Mapping seed variety to performance with better seeds or engineered varieties (e.g., via genome editing [2]). Mapping soil supplementation needs to regional/temporal conditions using interpretable data science [3]. Defining functional properties of derived bioproducts (e.g., ethanol from corn), distinct from traditional products (e.g., heavier kernels using genome editing). Conversely, some of the gaps in the data engineering and machine learning areas for digital agriculture include: Approximate data analytics for processing data from multiple inexpensive sensors deployed on connected farms. This is especially important for compute-intensive workloads, e.g., vision workloads from drone imaging for object classification/detection, e.g., in our recent approximate object classification and detection work [4], [5]. Tradeoff between privacy and utility when analyzing data from multiple farms, similar to federated computing, used profitably in other fields, e.g., genomics [6]. Network management for sparsely connected farms using newer networking solutions that are bandwidth-aware and do not require cell towers [7], [8]. Drones and tractors for data ferrying when needed especially under sparse network connectivity [9], [10]. Effective sharing of data processing and analytics load between sensors, edge devices [11], [12], and the cloud for maximizing throughput or latency, based on the client (farmer/farm manager) preferences [13], [14]. Optimized cloud computation for beefier machine learning workloads using vision APIs, e.g., Azure Vision or Amazon Rekognition [15] or processing streaming workloads using on-premise database optimization or using optimized clustered cloud instances [16]. Examples of such optimization can be found in our recent work for on-premise database optimization [17] for streaming workloads or cloud/serverless optimization  [18], [19] for computationally-heavier vision [5] or lighter-weight, but latency-sensitive, IoT workloads [15]. Data ethics when sharing farm data with agricultural companies or insurance providers. On the economics side, VRT for fertilizer treatment, as an example, depends on accurate intra-field soil data, which is expensive. Unless the economic returns to site-specific management cover both the up-front investment and the cost of collecting quality data, adoption will be low. Guidelines for VRT use for fertilizer application illustrate the need for: Marking management zones for the VRT system. Identifying whether the system will be guided by map-based inputs or finer-granularity sensor-based inputs. While the sensor-based inputs are more sophisticated because they reflect the changing conditions in the farm, they are also logistically and computationally more expensive because they are battery-powered and will need to continuously or intermittently be guided by anomaly or bottleneck detection [20]. Identifying the kind of data that will be used for mapping or the kind of data for the actuation of VRT dispensers. For farmers to adopt these technologies (VRT provided as an example and others, e.g., edge-cloud data partitioning, discussed in this article), concrete savings on resources (e.g., supplements or fertilizers) need to be demonstrated with potential yield increase and environmental protection from decreased farm effluents from nutrient pollution and reducing farm runoff and eutrophication (hypertrophication), such as from high levels of nitrogen and phosphorous in fresh water. In the case of livestock farmers, this translates to the decreased use of hormones, supplements, or antibiotics for the livestock, resulting in ecological gains [21], [22]. Relevance of our team's ongoing efforts. Digital agriculture—encompassing precision agriculture, data analytics and edge-cloud computing, and data privacy and ownership—has the promise to transform agricultural throughput. It can do this by applying data science for mapping input factors to crop throughput and that too in a region-specific and crop-specific manner, while bounding the available resources, both tangible farm-specific resources such as seeds, nutritional supplements, and farm machinery, and computational resources (e.g., cloud credits or CPU/GPU cycles) or networking expenses (e.g., LoRA or NBIoT towers). In addition, as the volumes and varieties of data increase with the increase in sensor deployment in agricultural fields, data engineering techniques will also be instrumental in collection of distributed data as well as distributed processing of the data. These have to be done such that the latency requirements of the end users and applications are satisfied. At the same time, Microsoft has developed and is looking to spread the reach of the FarmBeats program [23], which has the vision of empowering farmers with low-cost digital agriculture solutions using low-cost sensors, drones, and computer vision and machine learning (ML) algorithms. Understanding how farm technology and big data can improve farm productivity can significantly increase the world's food production by 2050 in the face of constrained arable land and with the water levels receding. While much has been written about digital agriculture's potential, little is known about the economic costs and benefits of these emergent systems. There are important questions to be answered before data analytics for agriculture, questions related to technical viability, economic feasibility, sustainability, and data protection and ownership are implemented. These questions cannot be looked at in isolation—for example, if some algorithm needs data from multiple data owners to be pooled together, that raises the question of data ownership and data privacy. In summary, the paper reviews the current state of the following questions and presents a look forward at the challenges that need to be resolved, namely: data lifecycle for digital agriculture data; applied ML techniques for the domain; low-power communication protocols for the domain; economics, policy, and decision making driving adoption. Lattice is the first to bring together these questions under one roof, discussing the goals, path forward, and challenges of digital agriculture to surmount the challenges of the food-water-energy nexus. We present an integrated effort Lattice,1 which will culminate in the incorporation of foundational AI advances, driven by the domain constraints and requirements of digital agriculture systems, resulting in efficient distributed computational infrastructure to execute the algorithms. SECTION II. Data Generation From Sensors This section will cover the modalities of data gathering and controlled dissemination, the volume of data generated, and the quality of the data, collected and processed from ubiquitous sensors on farms and includes the following. Soil sampling: Soil samples are extracted from field (may or may not be georeferenced) and sent to a lab for analysis. Lab results come back in a report detailing fertility levels. In most cases, one must manually assign geo-referenced points to report values. Fertilizer application: Based on soil sampling, a fertilizer recommendation is generated. If geo-referenced points are used, a variable rate prescription can be generated. If fertility results are aggregated across the field, a flat rate is applied (proprietary or shapefile). Planting: Generated as applied maps with information on population, singulation, misses (proprietary or shapefile). Scouting: Conducted as frequently as once a week during growing season. Traditionally data comes in the form of a report that details presence of disease, insect, and weed pressure. Currently much research is being conducted on drone-based scouting using multi-spectral imagery to determine nutrient and water deficiencies as well as detect disease, insect, and weed pressure. Data format is large image files that need post processing. Spraying: Based on the results of the scouting reports spraying operations are conducted. Most modern sprayers can generate as applied maps. Files are saved in a proprietary format based on the sprayer manufacturer. Harvesting: Yield maps are generated by harvesters and saved in a proprietary, manufacturer-specific format. In irrigated fields, soil moisture sensors are often used to determine irrigation intervals. Despite the wealth of available data in most operations, very little is actually analyzed and used to inform future decisions. The most commonly used data sets are scouting data (used to make chemical application decisions) and soil sampling data (used to make fertilizer recommendations). More progressive producers use yield data to determine variable rate fertilizer application and to compare seed varieties. Much of the data collected only when the richer context of the data is known. This can be known through processing such as aggregation with additional local or regional data and attaching the correct metadata. Biorefining: Different bioprocess operational modes for converting components of a crop (e.g., corn) are recorded during enzyme catalyzed conversion, fermentation, biocatalysis, and separations to achieve the desired purity of the target. These data can be used to identify inherent barriers, which can be overcome by modifying feedstock. For VRT, with advanced electronic controls and improved communication, applications include: fertilizer/nutrient applications, manure, seed applications, tillage as a function of soil compaction, and irrigation. Thus, if the VRT leverages sensors rather than static maps, farm processes can benefit. One primary challenge facing digital agriculture is the lack of data sharing, which happens due to technological as well as human reasons. The technological impediment centers around the lack of interoperability of data collection, processing, and visualization tools. Producers are reluctant to share data due to fears of regulatory issues and the lack of perceived value. SECTION III. Data Lifecycle This section will cover the various phases in the lifecycle of agricultural data—sanitization, loading, processing, storing, summarization, and analysis; an example is shown in Fig. 1. This will go into some of the general-purpose approaches (e.g., data deduplication, calibration using sensor metadata) as well as agriculture-specific approaches (e.g., known variations in hyperspectral maps from ground sensing and aerial image data and effective fusion among sensor arrays). Figure 1. Example of no-till corn operation, data generation, and lifecycle. In modern agriculture, data is generated from almost every operation. This data may be site-specific or more broadly defined but often there is no clear way to aggregate data layers. Show All Data generation sources: Data generation is the first stage of a data lifecycle. There are many ways in which data can be generated. The sources of data generation can be broadly classified into two types. Localized data or private data: This is the data that is generated on the farm such as soil nutrient composition, water, and fertilizer usage. This type of data is generated from sensors that are present on the farm. Public data: Data such as historic weather conditions and market prices fall under this category. Imported data is often generated at outside sources and shared with the farmers to use in precision agriculture. Such data is not farm specific. An example of data that is at the crux of localized and public data is topography and soil type, which may be somewhat localized but follow a trend for farms in geographical proximity. Data warehousing: Data generated then needs to be stored in repositories called data warehouses. Data warehousing allows integration of different data from multiple sources and helps restructure the data for better performance. One recent example of data warehousing is an initiative taken from the government of India [24], titled INARIS (Integrated National Agricultural Resources Information System). Woodard [25] discusses Ag-Analytics—a platform that provides data warehousing in the field of precision agriculture. Although there are readily available platforms for data warehousing, there are several constraints when using these platforms directly in precision agriculture. Some of these constraints are discussed in [26]. Metadata annotation: Metadata annotation can be done manually or automated. Since the data that we are considering is prone to be complex, automated metadata annotation is preferred. Roy, Sarkar, and Ghose [27] provides a comparative study of the different learning techniques used for metadata annotation. Fiehn, Wohlgemuth, and Scholz [28] provides an algorithm for metadata annotation. Haug and Ostermann [29] uses a human expert to first mark crops from raw images. Masks were then derived from using these markings. These masks are then used to acquire the metadata. Similar techniques can be used in different aspects of precision agriculture. Data annotation and cleaning: Due to the large size of data, it is important to perform annotation and cleaning before data analysis. Data annotation is subjective and depends on the particular use case of precision agriculture. The choice of the data annotation technique is dictated by the size of the data set, cost of annotation per sample among many other guidelines. Schoofs, Guerrieri, Delaney, O'Hare, and Ruzzelli [30] proposes a data annotation technique for electricity data in wireless sensor networks (WSNs). Similar annotation techniques could be developed in precision agriculture that can be performed in a WSN infrastructure. Data cleaning removes or corrects errors that are present in the data. There are several existing works that propose data cleaning techniques in precision agriculture. Simbahan, Dobermann, and Ping [31] proposed a screening algorithm for cleaning yield data that provided an increase in map precision. Sun, Whelan, McBratney, and Minasny [32] proposes an integrated framework for software that increases mean yield through data cleaning. Data processing: Steven [33] provides a good overview of the constraints faced in data processing in precision agriculture. In [33], the authors consider the case of using satellite images for remote sensing in precision algorithms. In such use cases, one of the important aspects of data processing must be to make the data more readable. One such scenario where these images can not be directly used is in the case of cloud cover, where the images need to be processed before utilizing the data. This can be extended to data acquired through other means as well. Data acquired from soil sensors may need to be processed in order to make it more utilizable. Honkavaara et al. [34] proposes a processing chain that uses data collected from unmanned airborne vehicles to generate meaningful results. Loreto and Morgan [35] proposes an automated system that performs both the data acquisition and data processing of soil nitrate measurements. Murakami, Saraiva, Junior, Cugnasca, Hirakawa, and Correa  [36] proposes a data processing algorithm that processes yield data on a distributed framework. SECTION IV. Data Analytics for Digital Agriculture Here, we will cover approximate processing for in-sensor analytics, advanced processing for backend analytics on the edge or cloud platforms, and interpretable data analytics. Analytics workloads are often quite demanding, and do not fit, out-of-the-box, into the embedded devices, deployed in agriculture. Advanced processing for backend analytics may leverage edge platforms, e.g., Azure IoT Edge device [23], [37], and there may be sensitivity of farmers to upload personal data to the cloud. Interpretable analytics are important because the farmers will require insights into the results of the algorithm, at their level of understanding, to potentially take action. In Fig. 2, we show a high-level architecture of the nodes deployed in different locations, illustrating the execution of analytics routines on the heterogeneous nodes. Figure 2. System architecture of the distributed analytics relevant to digital agriculture. Show All Data analytics plays an important role in precision agriculture. It can help farmers decide what crop to grow when, monitor the crop growth, and decide on the logistics of farm management. But agricultural data is often large and noisy and needs careful processing to distill insights from them. The following subsections elaborate on the advanced ML capabilities that can be used for such analysis. Another relevant technology in this context is the use of scalable databases to house and process these data sets for downstream processing and retrieval. With this in mind, we also include some innovations in NoSQL database technologies to assist in high-throughput information retrieval from the evolving agricultural data. Traditionally, this domain did not have requirement for low latency—the decisions were more mid-term tactical or strategic and could be made in the time frame of hours or days. However, with sophistication in farm machinery and automated nutrient application, some use cases of low-latency data analytics have evolved. One example is farm machinery moving over a region of the farm, queries ground sensors for soil quality or cameras on-board probe for pest infestation on the plants. It then analyzes the sensor feed and decides on the appropriate application of nutrients/pesticides, actuating the on-board applicator on the dispenser, real-time. In Fig. 3, we illustrate data flow in FarmBeats as an example. Figure 3. FarmBeats, an example of a data-driven agricultural platform from Microsoft, captures data from sensors and drones, and sends it to the Cloud for processing with other data streams, such as satellite data and weather stations. Show All Approximate processing for in-sensor analytics: A sensor network acquires real-world measurements at discrete points, where each measurement is a snapshot in time and space. In most scenarios in which sensor networks are deployed, the sensors are frequently queried resulting in continuously monitoring alongside high energy costs. Thus, one of the chief problems faced by WSN, often deployed in farm settings, is the constrained availability of resources to these devices. The sensors used in such networks are low-power embedded devices that are expected to last for long periods of time (order of months) on standard batteries [38].2 This issue can be mitigated by leveraging a more distributed architecture and using more energy-efficient algorithms. Further, these devices generate large volumes of data, which ideally will be processed in real time in a streaming manner for usable insights. As a balance between computational load and accuracy, approximate computing tools and techniques have become popular in several domains, e.g., computer vision [5], [39] and scientific computing [40]. The idea is to perform approximate computation over carefully chosen subsets of the entire input dataset. In digital agriculture, some degree of approximation or error in the output of the algorithm is tolerable, either because humans cannot perceive these differences or downstream algorithms are not affected by such approximations. Relevant to our discussion, an example is the approximate computation can relay whether a particular soil nutrient concentration is above or below a threshold, rather than the exact value of it. Also, it may compute this over a uniform random subsample of say one in every 10 samples. Alternately, we can also use information theory principles, such as the Nyquist-Shannon sampling theorem to decide on the spacing of the sensors in the WSN [41] and also the actual redundancy needed for robust sampling from sensors [42]. An important requirement of our target applications is low latency. This can be achieved by using multiple nodes to parallelize the work. However, this has to be done carefully so that the load is approximately balanced and there is not much overhead of energy to perform the distribution. For example, ApproxIOT [43] proposes an algorithm based on Apache Kafka [44] that uses IoT devices to generate data and forward it to edge computers, managed by service providers. As shown in Fig. 2, wireless communication, like LoRa/NBIoT, is used to forward data, compressed or otherwise, to the edge devices. These data streams are then sampled and forwarded to a central location (compute server C 1 in the figure), where user-specific queries can be made. The sampling in such systems are based on two techniques: Stratified Sampling: The streams of data are categorized based on their distribution. A random sampling is done on these distributions, with prior knowledge of the data required for this kind of sampling. Reservoir Sampling: A reservoir size R is maintained and at most R items are uniformly sampled from the data set. Here, prior knowledge of the data is not required. ApproxIOT extends both these techniques to a weighted hierarchical sampling. The nodes conduct sampling over data generated and compute statistics, with a 1.3X – 10X speedup. In-sensor analytics is relevant to our domain because it means that the data being sensed will be (partially) analyzed locally at the sensor itself. The value proposition is that raw data will not have to be sent over the wireless network, thus saving on wireless bandwidth and energy, and thus potentially yielding low-latency decisions. In-sensor analytics algorithms can either be value tolerant, where the approximation of values can be made and the resulting algorithms are lightweight or they can be delay tolerant, where the resulting algorithms can be made more accurate at the expense of latency. SERENE [45] is a framework that selects representative nodes, among clusters of correlated sensors. Here, the framework also takes into account the dynamic changes in the network topology and outliers. Since sensor data acquisition and communication are energy intensive, and sensors are typically battery-powered, SERENE uses clustering algorithms to spatially and temporally aggregate the data. For example, it uses a density-based clustering algorithm, DBSCAN [46] for robustness against outliers and noise. This algorithm can cluster based on any shape, as the sensor readings may be correlated. Based on the cluster shape, availability of battery power, and distance of the target node from other nodes, the representative nodes — M -sensors— are queried. Another lightweight approach for in-sensor analytics is Snapshot Queries [47]. Here the representative nodes are elected through a localized process. Each node maintains a data distribution model of its neighboring nodes. Based on this model, the algorithm predicts the values of the neighboring nodes. If the error between the predicted and actual value is less than a threshold, the predicting node can represent the neighboring node in question. The data model maintained is based on the previous correlation between the values of the node and its neighbors. Here, the model is updated frequently, making it robust to dynamic network changes. Another work that leverages the correlation between sensor values is Kartakis et al. [48] where they use this property to detect anomalies with a Kalman filter to reduce false positives. Distributed neural network inferencing: The concept of lightweight algorithms can also be extended to deep neural networks. Distributed Deep Neural Networks (DDNNs) provide better scalability and fault tolerance than DNNs. The data generated by sensor nodes is processed locally at the edge. DDNNs are used to utilize the advantages of distributed computing hierarchy in DNNs [49]. Further, simple ANNs have been used in tandem with Bayesian loops to reduce the number of hyperparamters in models and thus improve the interpretability of models and decrease the need for additional hyperparameter tuning. Having a multitude of hyperparameters to tune is often an overkill for simpler processing needs with energy considerations in mind, as is often the case for lightweight edge processing for sensor node analytics [50]. This and other approaches, such as Bayesian neural networks (BNNs), sped up using hardware accelerators, can be a panacea when data volume is limited (as in cases where sensor nodes have been initialized on a farm) and to prevent overfitting plus allow for limited memory footprint [51]. Limited memory space may be the case for microcontroller-class devices or lower-resourced edge-class devices used in sensor nodes or gateway nodes, where memory is of the order of a few GBs rather than 100 s of GBs at server-class machines. Another aspect to reduce the energy consumption of sensor nodes is by reducing the duty cycles (sleep-wake cycling) of sensors. By activating the sensors only when required, the energy consumed by the sensors will be reduced. In our target domain, this is highly feasible since the sensing frequency can be kept low (of the order of a few minutes) due to the nature of the underlying events being sensed. Database management and backend analytics for large-scale agricultural sensor data: Precision agriculture allows for site-specific crop management to increase throughput and achieve more sustainable farming by applying data science to agriculture practices, learning from local data trends. More and more agricultural sensing data is being live-streamed from farms, whether it be through on-board cameras, on manned or unmanned aerial vehicles, or through ground sensors in the farms. There is thus a need for centralized databases to store and process these data sets, often in real-time, to get actionable insights for farmers. Plus, there may be some degree of federation in storage and compute resources that may be needed as the computing needs of this domain increases, as has been seen in the genomics domain [6]. Further, the sensing data is multi-dimensional and noisy, coming from ground sensors deployed in farms to measure an array of soil characteristics, such as, moisture, nutrient levels, temperature profiles, soil acidity, etc. These live-streamed data sets need to be stored in a fail-safe repository of nodes, such as Redis installations in Amazon Web Services (AWS) Elastic Compute Cloud (EC2) [52]. Redis is a popular NoSQL datastore that is being currently used by Twitter, Instagram, Microsoft, Groupon, etc. It is an in-memory key-value store that supports various abstract data structures, such as strings, lists, maps, etc. By storing the data in the main memory, Redis serves as both a datastore and a cache. This allows for a very fast and flexible storage model, which is essential for real-time processing pipelines, such as in digitized agriculture pipelines, e.g., FarmBeats [53]. Moreover, Redis supports durability by periodically saving a snapshot of its main memory to the permanent storage. This snapshot can be loaded back into main memory in the case of a failure. The aggregate live-streamed updates and queries represent a unique workload for such NoSQL datastores, as these queries vary in rate and type over time. In such cases, a workload-aware tuning system is needed to reconfigure the NoSQL cluster, whether locally or on the cloud, to provide high performance. This is becoming more important as the data from small-scale farms across the country is burgeoning both in size and diversity, slowly replacing the previously used manual data-collection processes. Maximizing the throughput of these processing pipelines of digital farm data will enable actionable insights from agricultural sensing data. Also, given that these pipelines are hosted on the cloud and this domain is very cost conscious, we want to maximize the performance within a user-defined cost bound. Our recent work on cost-aware optimization of NoSQL database has shown promise [17], [18]. A pipeline for analytical workloads (OLAP, online analytical processing) consists of two main parts: a storage cluster (e.g., Redis or Cassandra) and a computing cluster (e.g., Spark), the latter operates on the top of the storage cluster to execute queries and thus perform analysis on the stored data. The task of the optimization is to find the best combination of configurations maximizing the objective metric, modeled as: P ∗ = arg max Confs f(Confs(t),WL(t)) (1) View Source Where P ∗ is the optimal performance that is achieved by the best combination of configurations Confs . The search space of Confs is large, e.g., NoSQL databases, e.g., Cassandra and Redis, have 50+ and 40+ performance-sensitive parameters, respectively. Hence, an exhaustive search through all possible configurations is impractical. Therefore, evolutionary search techniques are preferred in this case due to their ability to find close-to-optimal solutions in practical time, e.g., 1. Experimental Evaluation: We perform our experiments on multi-modal sensor data, mimicked on real data collected from our experimental digital agriculture farms. First, we identified the most impactful NoSQL parameters for our agricultural processing pipeline. We use D-optimal design to specify the data points to collect to reveal these impactful parameters. We collect 128 data points. These data points represent different combinations of configuration parameters and their corresponding performance (in terms of throughput, i.e., Operations/s or Ops/s). Second, we use the collected data points to train and test our performance prediction model. We estimate the importance of each feature and select the most impactful parameters (Fig. 4). We then use these top- k impactful parameters in training our model. Figure 4. Feature importance for accurate performance prediction. Show All Performance prediction model training: In this experiment, we study the impact of using an ensemble of predictors on the prediction accuracy. Ensemble of predictors can achieve better bias–variance tradeoff than a single predictor by combining the predictions of many predictors. Each predictor in the ensemble is trained with 75% random sampling of the training data. This sampling step is repeated for every model, which increases the diversity of the models and hence improve the prediction accuracy of their combined results. As shown in Fig. 5, a single DNN shows a very poor prediction performance with an R-squared value of 0.16 and an RMSE of 5671. However, a significant improvement is observed when we combine the predictions (by taking the average) of 5 or more models. We notice that there is a diminishing improvement in the performance prediction (for both metrics) after increasing the size of the ensemble beyond N = 15. Figure 5. Improved performance with increasing ensemble size. Show All We evaluate three possible single server prediction models for evaluating the prediction of throughput for NoSQL databases such as Redis and Cassandra. The prediction is done for different configurations of the NoSQL DB as well as the cloud VM on which the VM is hosted. In each case, we use a Random Forest using 75%:25% for training and prediction. 1) N-Solitary-Models: This builds a separate prediction model per VM instance type (referred to as “architecture”). It predicts the performance of a given architecture/configuration combination using previously collected data points from the same architecture. Thus, there is no scope for transfer learning here. 2) Combined-Categorical: This builds a combined model using all points from all architectures, while it represents the architecture as a categorical parameter (with integral values). Thus, knowledge transfer is limited across architectures, e.g., C4.large to C4.xlarge, for AWS VM instances. 3) Combined-Numerical: This also builds a combined model for all architectures. However, it describes the architecture in terms of its resources e.g., C4.large is represented as vCPU 8, RAM 3.75 GB, Network-Bandwidth 0.62 Gbits/s. This model allows extrapolation across all VM architectures, even across cloud vendors. We test the accuracy of each predictor using the same number of data points (100 points per architecture) and show the result in terms of R 2 (Table 1). We see that using a separate model per architecture (N-Solitary Models) gives poor performance due to the lack of knowledge transfer between architectures. Further, the numerical representation shows a significant improvement in prediction performance over categorical from better knowledge transfer across architectures. TABLE 1 Comparison of Different Single-Server Prediction Techniques. OptimusCloud, Which is Our Cloud-Based Optimization Technique Achieves Better Performance in Terms of R 2 and RMSE Over All Baselines Interpretable and interoperable data analytics: Although there are several predictive models, it is important that the analysis be interpretable. Molnar et al. [54] explains the importance of interpretable ML. This could help clients better understand why a model is predicting a certain intervention for crop growth. Vellido, Martín-Guerrero, and Lisboa [55] provides an overview of several works that address the issue of making ML techniques more interpretable. Dimensionality reduction is a popular choice here. A comparison of such existing techniques is provided in [56]. After dimensionality reduction, it becomes tractable to rank order the different features by their importance, providing insights [57]. Another aspect of interpretability is to resolve post-hoc “sanity check” questions [58], such as, after a rain event, does the model predict the moisture content in the soil is higher. If the model fails to answer correctly a sanity-check question, then further examination of the model is done. An important aspect of interpretability is to allow domain experts to parametrize the models, e.g., by feeding the appropriate parameter values for different regions of operation. This can be fed in as manual input by experts or by blending simulation models (typically built by experts) into the data analytics models. Another important design consideration is interoperability of the software systems used to acquire and analyze data. Too often software vendors provide silo-ed software packages either due to lack of design consideration or due to conscious decision to force vendor lock-in. In all such cases, it becomes a burden, often insurmountable, to make them interoperate [59]. SECTION V. Edge Computing and Low-Power Communication Technologies Here we discuss recent developments in edge computing and low-power communication technologies that aid our use domain. Edge computing is rapidly evolving, so it is timely to consider the lessons that can be learned and further customized for digital agriculture. The use of low-power communication is a common requirement in several domains. However, our target domain places some distinctive requirements and opportunities that we discuss next. Microservices and edge-cloud partitioning for low-latency communications: The world of connected devices has fueled the IoT era, where applications rely on a multitude of devices aggregating and processing data sets across highly heterogeneous networks. In this context, distributed deployment alongside containerization of the different information channels will shield the systems from isolated failures, conferring resiliency. The other important aspect is the partitioning of the data stream for computing at different degrees of latency—computing nodes at the edge are used for user-facing applications (face recognition, reconnaissance from a video stream, etc.). Owners will react negatively if the computers become unusable due to intermittent edge analytics. Therefore, the prioritization of the processes needs to change dynamically. In contrast, the application itself needs to be designed in a way that it is insensitive to such dynamic, and unpredictable, changes to the priority level, e.g., it will not time out if there are client-server interactions. Another aspect of the prioritization is that the different analytics results are needed with vastly differing timing requirements. Such high-level, user-expressed requirements will be used to dynamically prioritize in the face of unpredictable arrivals of the events (e.g., a flash flood event, or onset of a locust infestation). Thus, overall the partitioning needs to happen in a top-down or bottom-up manner. Top-down means that we take the high-level user requirements on latency and accuracy and define the partitioning based on that. Bottom-up means that depending on the available resources on each platform, the resource handler decides where to run the application component. Top-down requirements naturally have a higher priority. This will leverage the significant amount of work that has been done in automatic partitioning of applications to run on mobile devices and the cloud [60]–[64]. In-network processing: Sensors used in precision agriculture are Internet of Things or IoT devices and like all IoT devices have constraints on power and connectivity. It is necessary to have the first step of data processing that takes place at the sensor end to be energy efficient. Thus, anomalous data can be suppressed and need not be communicated. Alternately, in some scenarios, the exact opposite is desired—when an anomalous event is detected, that event needs to be communicated to the gateway promptly. AutoRegressive Integrated Moving Average (ARIMA) is used for fitting time-series data in order to predict or estimate the trend. This can then be used for suppressing data communication — if the sensor node and the receiving gateway node use the same model to predict values and the predicted value is close to the sensed value, the sensor node can suppress the communication [65], [66]. While ARIMA models work on a linear process, more sophisticated ML algorithms can model non-linear processes. Examples of traditional ML techniques such as k -Nearest Neighbors (KNNs) and Support Vector Regression (SVR) as well as more complex Recurring Neural Networks (RNNs) [67] and Long Short-Term Memory Neural Networks (LSTMs) [68] have been used for prediction of sensor network values [69], [70]. The predicted values can again be used for suppression of redundant data communication. The tunable configuration allows us to navigate the tradeoff space between accuracy and data communication. While RNNs and LSTMs give more accurate prediction over statistical methods like ARIMA and ETS, they are more complex in nature. For simpler user queries and in-sensor analytics, ARIMA and ETS models can be used as a lightweight alternative. A more detailed analysis can be done on the cloud backend with some context achieved through attention pooling for example. Low-power communication technologies Low-power communication for wireless IoT communication is key for digital agriculture and falls in three broad categories: Low-power wide area networks (LPWAN), with a greater than 1 km range, essentially low-power versions of cellular networks, with each “node” covering thousands of end devices. Examples include LoRaWAN, Sigfox, DASH7, and weightless. Wireless personal area networks (WPAN), typically ranging from 10 to a few 100 meters. Examples include Bluetooth and Bluetooth Low Energy (BLE), ANT, and ZigBee, which are applicable directly in short-range personal area networks or if organized as mesh networks and with higher transmit power, larger coverage areas. Cellular solution of IoT, including any protocol that are reliant on the cellular connection Some of the bottlenecks in wireless transmission in farm settings include the harsh physical conditions in farm settings and the proliferation of inexpensive and less reliable sensors coupled with the intrinsic challenges of the LoRaWAN and cellular network technologies, such as 5 G. The core problem in farm settings is to acquire and transfer disparate data sources to support the various demands of a wide range of computation tasks while meeting the stringent constraints of heterogeneous wireless connectivity available in agricultural domain (especially for the livestock application). Data traffic from different sources and for distinct computation tasks raise diverse requirements to wireless connectivity in terms of its availability, bandwidth, responsiveness, resilience and energy efficiency. For example, sparse data relating behavior changes needs highly responsive, highly reliable communication; streaming videos captured by the drones3 or surveillance cameras expects high bandwidth but is elastic to varying-bandwidth with appropriate rate adaptation; A large amount of livestock herd-level information can be delay-tolerant but requires energy-efficient connectivity. Further, compared to wireless networks in the urban and civil uses, wireless networking for the livestock experiences more practical challenges regarding coverage holes, fast-fading channels, high interference and time-varying performance. Wireless connectivity is not always available in the wild rural areas: WiFi or other local-area communication (white space, ZigBee, LoRA) to the edge is unavailable when the cattle is far away from the farm facility, and cellular connectivity is missing at places given the poor coverage in the countryside. In most operational large-scale farms in the US, WiFi connectivity is not present. While cellular providers in the US do provide cellular plans for IoT devices (prominently NB-IoT), the cost of such plans makes them infeasible for farms, considering that the cost is per device and we anticipate many IoT devices in a large-scale farm. Hence, the use of LoRa, and its variants LoRaMesh or LoRaWAN, is popular. The IoT orchestrators that are provided by Microsoft, Amazon, and Google, i.e., Microsoft Azure IoT, AWS IoT Greengrass Greengrass, and Google IoT Core, can also leverage any of these networking modalities. However, Azure IoT uses a hybrid of per-device and data-based pricing system and AWS Greengrass uses a per-device pricing system, while Google's IoT Core uses a pricing system based on data volume alone. Thus, all existing commercial edge-based orchestrators need additional operational costs to function. So using a non-metered network like LoRa and using homegrown orchestration software will avoid these additional charges. A suite of techniques for data acquisition and wireless networking must work in concert, and at a price-point, to meet the diverse demands in digital agriculture. Agricultural data types relevant to algorithmic design: It is important to set up the data architecture prior to ingestion of the data. A broad and yet useful principle relates to the FAIR data principles, which refer to the Findability, Accessibility, Interoperability, and Reuse of digital assets. This is particularly important as in this domain there is close interaction between man and machine throughout the data pipeline. Now let us consider the primary types of data as they relate to our theme here. Batch Data mainly includes information collected from sensing devices, such as information of cropping, feeding, waste, livestock, etc. As the data is often sparse in time and space, it has a loose synchronization requirement and does not require a continuous wireless connectivity. Therefore, batch data can be periodically recorded and asynchronously updated. The main limitation for sensing devices is that they are usually battery powered and have limited operational lifetime. An optimized device management and transmission protocol is quite essential for energy efficient data acquisition and transmission, device lifetime maximization and sustainable development of the livestock system. Streaming Data is usually dynamic video/audio recoded by surveillance cameras or drones for real-time monitoring and early anomaly detection. Such data, especially for real-time monitoring, analytics and diagnosis is time sensitive and demands a continuous high-volume bandwidth for intensive content storage and delivery. A joint procedure of data acquisition and transmission is thus required to adapt the high data volume, handle varying wireless conditions, and support a reliable information flow. Multi-class data acquisition, storage, and processing: We consider two main classes: delay-sensitive and delay-tolerant. Delay-sensitive data is used for real-time monitoring, early anomaly detection and other highly-responsive tasks. It is further divided into multiple sub-classes depending on their bandwidth requirement: continuous high bandwidth (e.g., streaming videos recorded by the cameras or drones), continuous low bandwidth (e.g, streaming audio/voice, GPS or other in-cattle sensing data), or instantaneously-available but short connectivity (e.g., information like critical alarms). Delay-tolerant data is used for strategic tasks and includes sensing data collected for cropping, feeding, waste, livestock, etc. For different classes of data, we propose to develop a suite of techniques: 1) task-aware sampling schemes to reduce data volumes but retain data samples essential to the computation tasks, 2) content-aware data aggregation and compression to eliminate statistical redundancy and adjust data volume to fit the dynamic channel capacity and varying wireless condition (e.g., content-aware video frame compression). Integrated network over heterogeneous wireless communication: We have designed an integrated network to enable both delay-sensitive communication and delay-tolerant communication (in an opportunistic manner) over heterogeneous wireless connectivity [8]. We consider both infrastructure-based and ad hoc modes. Hybrid mode is also designed for whereby data resides at a location till infrastructure becomes available such as a drone as a data ferry. Network adaptation needs to be performed at multiple levels spanning from wireless technologies (e.g., cellular, cellular-IoT, WiFi, ZigBee, LoRA etc), transport layer (MPTCP, delay-driven optimization), lower-layer techniques like resource allocation, scheduling and rate adaption, to name a few. Many techniques can be modified at runtime to further optimize data acquisition and transmission under time-varying conditions. These include predictive optimization based on time varying wireless connectivity and data requirements and joint optimization of local storage, local processing, and wirelesss transmissions. SECTION VI. Economics, Policy, and Decision Making The most relevant policy questions in digital agriculture and related business data and are summarized in Fig. 6. Though farm data enjoy some of the IP protections afforded to trade secrets, its legal ownership remains ambiguous [71]. The decision to subscribe to a data service provider stem from fears of personally identifiable information (PII) being misappropriated. Yet, farm data generates positive network externalities when aggregated across a large number of operations. Figure 6. Farm economic decision making pipeline and barriers to profitability in digital agriculture. Show All Profitability and on-farm decision making: Site-specific farm management has the potential to enhance farm profitability while conserving resources. But despite advancements in field sensors, GPS guidance, and grid soil sampling, adoption by farmer operators has fallen short of expectations. Operator demographics, operation size, and perceived benefits influence the decision to invest in site-specific management practices. Subsequent economic returns to adoption depend on the nature of the adopted technology and its interface with on-farm decision making. Miller et al. [72] identify two types of precision agriculture technologies: embodied knowledge—tools that generate value in isolation, e.g., GPS guidance systems or automatic section control— and information intensive—tools that produce data for use in future decision making such as yield monitors, grid soil sampling, or electrochemical sensors. Embodied knowledge technologies create immediate convenience while the benefits of information-intensive technologies are revealed over a longer time horizon and depend on their role in the on-farm decision making process. Differences in the immediacy and measurability of realized gains may explain differences in adoption rates across technology types. Use of VRT and GPS soil mapping, for example, has consistently lagged that of GPS guidance systems. Rather than assessing technologies in isolation, agricultural economists are increasingly interested in how producers bundle complementary tools to create an overall precision technology strategy. Profitable use of “hard technologies” such as variable rate planters and fertilizer spreaders depends crucially on the availability of accurate intra-field soil data, or “soft technology” inputs [1]. These data sources however, are themselves costly to obtain. Moreover, the optimal data collection frequency or sampling density is not obvious and likely varies by field. Unless the economic returns to site-specific management cover both the up-front investment and the cost of collecting and using actionable information, adoption will be low. Policy: The most relevant policy questions in digital agriculture regard the value and legal status of farm data. Agricultural data generates benefits when aggregated across a large number of farm operations. These benefits—referred to as network effects or network externalities—grow with the number of participants. Business models such as Farmers Business Network, Inc. (FBN) have demonstrated the value of data sharing through its crowd-sourced database of input costs and performance benchmarking. But farm data often remains siloed within the farm gate. An individual farm's data leads to more reliable recommendations when pooled with comparable operations using similar practices and inputs. To overcome this “small data” problem, the perceived benefits of joining a big data community must exceed the perceived costs—e.g., privacy concerns over data misappropriation. To better understand the privacy concerns of producers, the nature and legal status of agricultural data must be considered. Miller et al. [71] discuss farm data's place on the private-public good spectrum. For a good to be a “private good,” i.e., its benefits and costs are fully realized by the owner, it must be both rivalrous—consumption by one party prohibits the consumption of another—and excludable—access to the good can be restricted. A private good allows for the highest possible degree of privacy protections for the owner. Copies of farm data can be shared without inhibiting its use by the original owner. In this way, farm data is clearly non-rivalrous. The ability of a farm operator to exclude others from using their data depends on their relationships with data service providers and the data sharing agreements that govern those relationships. For example, equipment manufacturers collect telematics data on new products they sell for improving performance and service. The equipment owner has no reasonable expectation of excludability and may not even be aware that they opted into such an agreement. Farms that subscribe to a data service provider to manage and analyze their data, e.g., Climate FieldView, are similarly forfeiting excludability. However, data may be partially excludable if access is limited to the network, or “club” of subscribers. Farm data most closely satisfies the definition of a “club good”, meaning the degree to which a farmer's privacy is at risk depends on how extensive and excludable their data network is [71]. A farmer's data is not legally protected from disclosure in the way medical records are protected by the Health Insurance Portability and Accountability Act (HIPAA) or education information is protected by the Family Educational Rights and Privacy Act (FERPA). Without overarching legal safeguards for farm data, individual sharing agreements dictate the terms of access and use. Though farm data enjoy some of the intellectual property protections afforded to trade secrets, its legal ownership structure remains ambiguous. There may be a role for liability insurance that addresses unintended consequences of information sharing. Over large regions, such data might be reported on a non-attributional basis, thus shielding specific individuals. The flip side of this is that this reduces the precision of mitigation actions, e.g., for a specific geographical region. Possible solutions to the conundrum might consider cryptography coupled to access keys, facilitating access to large databases, without revealing specific information to those who do not hold keys. Keys could be made available based on a regional user group, and to those who contributed to the database. For further sophisticated use cases, secure multi-party computation can be used, allowing a group of members of a minimum size coming together to access the information, but individuals or smaller-sized groups cannot. For example, homomorphic encryption in federated computing serves this purpose of balancing privacy and data utility. SECTION VII. Looking Ahead Big data and precision agriculture will likely be a disruptive force in the farm economy over the medium to long-term range. Digital agriculture, with the incorporation of Internet-of-Things (IoT)-based technologies, presents the ability to evaluate a system at multiple levels (individual, local, regional, and global) and generate tools that allow for improved decision making in every sub-process related to digital agriculture. In this article, we have reviewed the different types of datasets and relevant data science processing algorithms in typical field operations together with the typical lifecycle for the data to be contributory to the digital farm economy. We have then discussed the optimized NoSQL-based data storage solutions. Then, we have developed the idea of Machine Learning being adapted for use in digital agriculture, which means putting domain-specific requirements regarding interpretability, distribution, ability to handle intermittent wireless connectivity, and low cost. Finally, we have reported on results from real-world data from real-world testbeds with respect to which features are important in the analytics and the performance of analytics-based prediction. We conclude by discussing the policy challenges, the farm economic decision making pipeline, and barriers to profitability in digital agriculture. Authors Figures References Citations Keywords Metrics Footnotes More Like This Grassland Data Analysis and Calculation Based on the Internet of Things and Cloud Computing 2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS) Published: 2022 Internet of Things (IoT) Assisted Context Aware Fertilizer Recommendation IEEE Access Published: 2022 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 5:
- APA Citation: Irwanto, F., Hasan, U., Lays, E. S., De La Croix, N. J., Mukanyiligira, D., Sibomana, L., & Ahmad, T. (2024). IoT and Fuzzy Logic-Based Control for Improved Substrate Environment Management in Mushroom Cultivation. Smart Agricultural Technology, 7, 100427.
  Main Objective: To develop an intelligent environmental monitoring and control system for mushroom cultivation using IoT devices and fuzzy logic.
  Study Location: Unspecified
  Data Sources: Sensor data
  Technologies Used: Internet of Things (IoT), fuzzy logic
  Key Findings: The proposed system is able to monitor various environmental parameters, such as temperature, humidity, light intensity, and substrate moisture, and automatically adjust them to optimal levels for mushroom growth. Fuzzy logic is used to make decisions based on the sensor data, and IoT devices are used to transmit the data to a central server. The system is designed to improve mushroom yield and quality while reducing labor costs.
  Extract 1: "The current era witnesses the advent of the Internet of Things (IoT), a transformative force giving rise to various technological innovations, most notably connected objects. This paradigm shift catalyzes the widespread adoption of autonomous decision-making systems, particularly in sectors like agriculture, where the aim is to amplify productivity."
  Extract 2: Despite their popularity, cultivating mushrooms in open environments poses challenges in maintaining optimal environmental conditions, prompting numerous research efforts.
  Limitations: The study does not mention any limitations or potential issues with the proposed system. Including a discussion of limitations would make the study more comprehensive and balanced.
  Relevance Evaluation: 0.9-1.0: Exceptionally relevant - Comprehensively addresses all key aspects of the point with highly insightful, reliable, and up-to-date information. A must-include for the review.
  Relevance Score: 1
  Inline Citation: None
  Explanation: The purpose of this study is to develop an intelligent environmental monitoring and control system for mushroom cultivation by integrating IoT devices and fuzzy logic. The system monitors various environmental parameters, such as temperature, humidity, light intensity, and substrate moisture, and automatically adjusts them to optimal levels for mushroom growth. Fuzzy logic is used to make decisions based on the sensor data, and IoT devices are used to transmit the data to a central server. The system is designed to improve mushroom yield and quality while reducing labor costs.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. Literature review and materials 3. Methodology 4. Result and discussion 5. Conclusion CRediT authorship contribution statement Declaration of competing interest Acknowledgment Data availability References Show full outline Figures (6) Tables (7) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Smart Agricultural Technology Volume 7, March 2024, 100427 IoT and fuzzy logic integration for improved substrate environment management in mushroom cultivation Author links open overlay panel Firdaus Irwanto a, Umar Hasan a, Eric Saputra Lays a, Ntivuguruzwa Jean De La Croix a b, Didacienne Mukanyiligira b, Louis Sibomana b, Tohari Ahmad a Show more Share Cite https://doi.org/10.1016/j.atech.2024.100427 Get rights and content Under a Creative Commons license open access Abstract The current era witnesses the advent of the Internet of Things (IoT), a transformative force giving rise to various technological innovations, most notably connected objects. This paradigm shift catalyzes the widespread adoption of autonomous decision-making systems, particularly in sectors like agriculture, where the aim is to amplify productivity. As a result of the agricultural domain, mushrooms have concurrently emerged as a significant component of daily diets, offering additional vitamins and flavor. Despite their popularity, cultivating mushrooms in open environments poses challenges in maintaining optimal environmental conditions, prompting numerous research efforts. Recognizing the inconsistencies in existing approaches to safeguard vital parameters in mushroom farms, this paper introduces an innovative system utilizing intelligent sensors whose real-time records are managed based on the fuzzy sets concept. These sensors, encompassing the Capacitive Soil Moisture Sensor v1.2, DHT22 Sensor, Light Dependent Resistor (LDR sensor), and Passive Infrared Receiver (PIR sensor), collectively capture essential data for decision-making in mushroom farming. Employing fuzzy logic, the system addresses pivotal aspects such as substrate watering, environmental control, light management, and pest detection. Through experimental results, it becomes evident that the proposed system not only exemplifies the potential of IoT technologies in agriculture but also offers a comprehensive and efficient approach to real-time decision-making. By aggregating sensor data, the system proves instrumental in enhancing the quality and yield of mushroom crops, showcasing a promising trajectory for sustainable and technologically driven agricultural practices. Previous article in issue Next article in issue Keywords Smart agricultureInternet of thingsSmart sensorsMushroom farmingFuzzy logicNational food security 1. Introduction Agriculture poses a significant concern for humanity, as it is the primary source of food production. Many individuals suffer from hunger due to food scarcity, particularly in Third-world countries [22]. Food scarcity has been associated with socioeconomic elements like the expanding population [48]. Over the last five decades, the global population has risen by 3–6 billion, intensifying the demand for food resources [5,35]. Shockingly, hunger led to the chronic malnourishment of over 800 million people worldwide in 2016. Furthermore, more than 10 million individuals perish annually due to starvation [14]. Therefore, increasing food production is crucial in eradicating hunger and poverty. However, the reality is far from simple; agriculture remains largely unmodernized in many countries, leading to low food output [44]. Due to this necessity, there is a requirement for the advancement of intelligent agriculture by enhancing farming methods beyond conventional practices, which is crucial to boosting production yields qualitatively. This necessitates integrating constantly evolving technological innovations [49]. Its purpose is to empower farming methods to match agricultural production with the increasing population, thereby reducing prevalent hunger [2]. The global rise in mushroom cultivation can be attributed to the nutritional richness and distinctive culinary characteristics of mushrooms [50]. There is a forecast that the worldwide mushroom market will achieve a volume of 24.05 million tons by 2028 [21]. Regrettably, mushrooms have not garnered significant interest among farmers due to the high labor requirement during the practice. Additionally, cultivating specific mushroom varieties poses challenges, especially in regions where wild mushroom cultivation is prevalent [17]. Unlike most agricultural species, mushrooms must be cultivated in a specific environment, avoiding high temperatures and low humidity to achieve the most favorable harvest [[18], [19]]. Historically, mushrooms have been naturally grown in the wild and harvested from their natural habitats [36], affecting the harvest of this crucial agricultural product. Over the past ten years, the Internet of Things (IoT) has become a crucial tool across various domains [53]. Specifically in agriculture, IoT is employed to create interconnected farming systems that optimize productivity while conserving resources [26]. This advanced technology enables farmers to enhance agricultural productivity sustainably with reduced environmental risks [31,47]. Through the deep integration of state-of-the-art technologies such as deep learning, artificial intelligence, IoT, and cloud computing, smart agriculture represents a strategic approach for the agricultural sector to autonomously monitor, control, and make informed decisions with the assistance of information and knowledge [1,4,39]. This integration is achieved through the deployment of IoT sensors in agricultural practices. This proves particularly beneficial in agricultural activities, especially for crops that demand extra care during cultivation, such as mushrooms. Numerous research endeavors have explored mushroom cultivation by incorporating various intelligent systems, primarily concentrating on regulating temperature and air humidity through automated watering systems [32]. Nevertheless, other crucial factors remain overlooked in mushroom plant cultivation, such as managing light exposure [23], addressing insect disruptions [9] and utilizing natural or artificial lights a crucial environmental factor that significantly enhances the quality of edible mushrooms before and after harvest [24,27,33,54]. These factors play a vital role in the growth and metabolism of mushrooms, influencing mycelium characteristics (growth rate, density, and color) and the physical appearance of fruiting bodies (stalk, cap, and color formation) [23]. It is worth clarifying that light plays a major role in the cultivation of edible mushrooms [52]. Moreover, the research work of Bellettini et al. [8] focused on the identification of the presence of insects, mites, crustaceans, and other arthropods that feed on mushrooms, as well as decomposers on synthetic or wooden substrates, as detrimental factors to the optimal growth of mushrooms. It is worth noting that Bellettini et al. [8] presented a challenge of manually addressing the issues of external agent's presence, which can be mitigated by automatically spraying the pesticide on the farm. To alleviate the challenges with the current mushroom production, this study aims to provide an IoT-based system that integrates various modules to intelligently control vital parameters: temperature, humidity, substrate moisture, light intensity, and pest management. The proposed method integrates Fuzzy Logic (FL) in the IoT module to enable the sensor-recorded data use as enablers of the system functionality based on their comparison with the pre-recorded standard data, specifying optimal ranges for each vital parameter. The system triggers actuators when sensor data falls outside the desired range to keep the environmental parameters of the farm in the desired range, effective for mushroom cultivation. It is important to note that the proposed method incorporates self-decision-making through FL, a mathematical modeling technique mimicking human decision-making. To achieve our objectives, the contributions of this work are highlighted as follows: 1. Monitoring the sensors' recorded data for an intelligent and adaptive environment, ensuring optimal conditions for mushroom cultivation, and automating the farm's vital environmental parameters. 2. Optimizing agricultural resources, namely, water and pesticide, by introducing the sensors not used in the previous works. Keeping the objective of this work under the mushroom cultivation field, the diversification of our method leads to a more nuanced understanding of the environmental factors that can be applied to several types of mushrooms. The structure of this paper is outlined as follows: In Section 2, the literature review and the current state of the art about the focal point of this study are presented. Section 3 outlines the design and methodology employed in this work. The results are deliberated in Section 4, with concluding remarks provided in the last Section 5. 2. Literature review and materials 2.1. Existing literature Intelligent environmental control applications have successfully enhanced agricultural applications, particularly in mushroom farming research. The research works in Jararweh et al. [28] employed FL connected to various actuators, which have been adjusted based on the data gathered during the process. The results obtained by Jararweh et al. [28] showed significant improvement over the existing works. However, optimal farm control has not been achieved. The study by Chandrappa et al. [12] focused on using sensor automation technology to aid farmers in making manual and automatic agricultural decisions. However, these efforts mainly concentrated on monitoring moisture content in the substrate, air temperature, and humidity in the mushroom field, ignoring other crucial parameters that may impact the quality and quantity of the mushroom yield. Factors such as cultivation techniques, mechanical damage, storage conditions, and post-harvest manipulation also play a significant role [11,40]. It is worth noting that the integration of FL in agricultural applications [13,29,30,42] has been proven to be one of the most efficient techniques to control the variation of the farms’ parameters based on the classification of the data in place classification in various sets. The introduction of IoT in agricultural applications has also shown promising improvement in crop production, such as in Marzuk and Ying [34] and Thong-u and Wongsaroj [45]. Specifically, the work by Thong-un and Wongsaroj [45] conducted across three mushroom fields and one adjacent sample area, employing wireless communication to merge the data from these fields utilized the Message Queuing Telemetry Transport (MQTT) protocol to centralize information from each field, which was then uploaded to an online platform. Similarly, Marzuki and Ying [34] utilized an online interface for real-time monitoring. However, their approach involved a more comprehensive array of sensors, measuring additional parameters such as air temperature, humidity, carbon dioxide levels, and light quality. They used ThingSpeak as a cloud platform connected to the web-based visualization window. Moreover, the work of Rahman et al. [38] automated agricultural decisions and executed the process according to fixed time interval-based schedules. 2.2. The state-of-the-art Edible mushrooms are highly prized for their nutritional and medicinal properties, thanks to the presence of diverse bioactive elements, including proteins, polyunsaturated fatty acids, polysaccharides, dietary fibres, amino acids, vitamins, and minerals, making them a valuable food resource [3]. Due to their nutritional and medicinal advantages, mushrooms have gained widespread popularity worldwide in recent years. Global mushroom production has jumped 21.3 times since 1990, reaching 44 million tons in 2021 [7]. Various research works have predicted that the worldwide mushroom market will achieve a volume of 24.05 million tons by 2028 [21]. These statistics demonstrate that mushrooms are a natural resource experiencing growing demand annually. Considering this information, various cultivation methods have been created by preserving traditional practices or incorporating technological advancements. Some research has shown that implementing innovative cultivation techniques in mushroom farming can boost production to meet the annual demand figures. The significance of mushrooms in sustaining human life is underscored in earlier sections, emphasizing the role of technology in enhancing agricultural productivity and highlighting the importance of technology, particularly the IoT, as a solution to enhance efficiency in agriculture, leading to the development of intelligent crop production systems. This study applies IoT to intelligently monitor the substrate for mushroom cultivation based on the features of existing works, such as sensor integration, digital data transmission, and wireless sensor networks. These technologies enable diverse devices, fostering IoT implementation in agriculture. Intelligent irrigation, optimized fertilizer usage, pest control, and water and soil quality monitoring are among the practices benefiting from IoT applications [41]. Wireless Sensor Networks facilitate crop monitoring and intelligent agricultural applications by enabling long-distance communication and enhancing energy efficiency [51]. Monitoring technologies within IoT solutions play a crucial role in ensuring food safety and quality. Furthermore, IoT-based solutions establish information networks for effective decision-making and product management for crops and the entire agricultural supply chain. Integrating networks, sensors, and data processing offers water-use solutions, especially in regions with limited water resources. This leads to water conservation and food security. IoT technology also provides real-time information, reduces labor, enhances productivity in planting activities, and promotes efficient water usage. Furthermore, the impact of this information extends to the utilization of lighting, pumps, and agricultural machinery [41]. FL is an approach to reasoning that relies on approximations and assumptions, mirroring human thought processes. FL-based algorithms have extensive applications in areas like data hiding based on adaptability [17,46], automation of production lines [37], and digital images forensics with steganalysis [15,16]. FL represents an improvement over Boolean logic by introducing the concept of partial truth [45]. FL, on the other hand, incorporates the highest Boolean logic value with a degree of truth ranging between 0 and 1. One of the critical advantages of FL is its departure from classical logic, enabling the direct utilization of expert knowledge without the need for extensive training. It also integrates seamlessly with conventional control methods rooted in natural language [10]. It is crucial to note that FL is known for its superior energy efficiency compared to classical logic [6]. Applying FL, which involves setting a threshold value for the desired parameter unit to regulate the environmental factors in agricultural crop cultivation, specific parameters are defined as reference points for the implementation and tailored to the individual sensors utilized in the test area. Typically, FL is integrated into agricultural machinery automation systems to administer treatments based on the derived decisions. Based on the in-depth analysis, this research proposes a new IoT-based smart system using FL to manage the environmental parameters of the mushroom cultivation substrate. The proposed system incorporates sensors such as light intensity and infrared sensors to gather more comprehensive information aligning with the specific needs of mushroom plants to regulate parameters like lighting levels and manage the presence of insects, which significantly affect mushroom production. 3. Methodology This section outlines the overall approach and fundamental principles of the model under consideration. It comprises five crucial subsections that detail the proposed system's important features. In this article, we employ FL to self-regulate the vital parameters within the mushroom substrate to improve the existing methods based on traditional human-controlled methods. 3.1. Workflow overview of the proposed model This subsection provides comprehensive details of the proposed model's workflow in Fig. 1. The proposed model mainly comprises sensors, actuators, and cloud components. It is worth noting that the proposed model delves into a detailed examination of the various modules employed, elucidating their contributions to the overall functionality of the proposed method. Download : Download high-res image (351KB) Download : Download full-size image Fig. 1. Comprehensive architecture of the proposed method. The system is crafted using two microcontrollers, with the primary microcontroller, NodeMCU ESP8266, serving as the central hub for data acquisition and embedded FL control. Simultaneously, the secondary microcontroller, Arduino UNO, is dedicated to disseminating information to farmers through a web-based platform. Additionally, specific sensors tailored to the environmental control needs of mushroom plants have been chosen. These sensors are connected to the main microcontroller, which reads and processes data. The gathered data are compiled into data packets before being transmitted and then uploaded to a digital platform. The schematic circuit for the designed system is illustrated in Fig. 2. As previously described, the main microcontroller incorporates FL to autonomously determine the treatment and decision-making in managing the environmental control process. The user can control all these parameters based on the real-time data recorded concerning the soil moisture, temperature, humidity and light intensity. Download : Download high-res image (352KB) Download : Download full-size image Fig. 2. Circuit diagram of the proposed method. 3.2. Data collection To collect the data, this work uses the sensor unit. The sensors unit comprises dedicated sensors designed to focus on specific parameters established as references in this work. These sensors encompass a soil moisture meter, a light sensor for measuring light intensity levels, a temperature and humidity measuring sensor for recording ambient temperature and humidity, and a motion detection sensor. Calibration has been conducted on all sensors to avoid acquiring irrelevant data values that could result in irregularities during the operational process. 3.2.1. Soil moisture sensing The chosen sensor for measuring soil moisture content is the Capacitive Soil Moisture Sensor v1.2. This selection is based on its capability to measure soil moisture levels using capacitive sensing. Constructed with corrosion-resistant materials and coated with a layer of PCB paint, this sensor offers an extended service life and an aesthetically pleasing appearance. Its operation involves measuring changes in capacitance resulting from variations in soil electrolyte content. With an operating voltage range of approximately 3.3 to 5.5 V, the sensor is well-suited for application with microcontrollers that typically output low voltages, such as 3.3 V or 5 V, as used in this work. 3.2.2. Light intensity sensing This work employs a module-based Light Dependent Resistor (LDR) to measure light intensity levels. The rationale behind selecting this module is the work's preference for output in the form of an analog value regarding light intensity levels, and this module is more straightforward to implement. As its name implies, this sensor relies on a resistor whose resistance value can vary based on the received light levels. This module operates at a compatible voltage, making it suitable for integration into this project. The module can capture light intensity levels ranging from 0.1 to 10,000 lux. On the other hand, this sensor's resistance value spans 0.1 to 1000 kΩ. Additionally, it can function within a temperature range of −60 to 75 Celsius, aligning with the optimal temperature and humidity conditions for mushrooms, maintaining elevated humidity levels and lower temperature levels. 3.2.3. Temperature and humidity sensing The optimal temperature required for mushroom cultivation ranges from 22 to 28 Celsius, while the optimal air humidity ranges from 80 % to 90 % [38]. Therefore, the DHT22 sensor is employed to measure the air temperature and humidity levels. Its use of a calibrated digital signal output enhances its effectiveness. Moreover, its low voltage requirement underscores the sensor's suitability, operating within the 3.3 to 6 V DC range. The sensor exhibits a measurement range of 0–100 % for air humidity, with an accuracy of +-2 %, and −40 to 80 Celsius for temperature, with an accuracy of 0.5 degrees Celsius difference. Notably, the sensor demonstrates responsive performance, boasting an average sensing period of 2 s. These attributes make the DHT22 sensor a promising choice for implementing intelligent agricultural environmental control processes. 3.2.4. Motion detection sensing Detecting the presence of insects is a crucial consideration in all stages of crop cultivation. Farmers can identify the presence of insects using a sensor known as the Passive Infrared Receiver (PIR), with the HC-SR501 PIR sensor specifically employed in this work. This module detects the levels of infrared radiation the embedded pyroelectric module receives. The sensor exhibits noteworthy sensitivity, featuring an adjustable sensitivity range and a detection area angle of approximately 110 degrees from the sensor knob. Moreover, it can detect movement between 3 and 7 m perpendicularly. Despite its capabilities, the sensor is power-efficient, requiring only a low power supply within the range of 5 to 12 V and accommodating temperatures from −15 to 70 Celsius. These attributes make the sensor highly suitable for the requirements of this work. 3.3. Data processing The data processing is mainly based on the controlling unit. For the controller unit of this study, two microcontrollers are employed, each with distinct roles. Both microcontrollers are supplied with a working voltage of 9 V using a power supply. This facilitates the implementation of the designed tool, allowing direct connection to electricity with a higher voltage range of 220–240 V. The primary microcontroller reads and processes data from each sensor, enabling automatic decision-making to maintain optimal farm environmental conditions based on the implemented FL. The Arduino UNO R3 is the chosen controller for this processing task. The selection is based on the specific pin requirements for this project, where two analog pins and ten digital pins are necessary. The two analog pins are utilized to interface with the Capacitive Soil Moisture Sensor and LDR Sensor, as the data processing for these sensors rely on acquiring analog values. Additionally, the ten digital pins serve various purposes. Two are allocated for connecting the DHT22 and PIR sensors, two receivers (RX) and a Transmitter (TX) establish communication with other microcontrollers, and the remaining six are designated for connecting relays with six channels. Given the inherent incapacity of the main microcontroller, Arduino UNO R3, to establish an internet connection, an additional microcontroller is employed to facilitate data upload to the internet in this work. This component is called NodeMCU ESP8266, featuring an embedded ESP8266 WiFi Module chip that enables seamless internet connectivity. By utilizing this embedded chip, this module assumes the role of an agent responsible for executing the data upload process to the chosen web-based digital platform. Consequently, it facilitates the real-time presentation of agricultural land data to farmers. 3.4. Cloud platform As previously mentioned, using two microcontrollers accommodates all acquired sensor data. It facilitates its upload to a web-based digital platform named ThingerIO. The data obtained by Arduino UNO R3 is transmitted to NodeMCU ESP8266 through serial communication. This communication is established by reverse interconnecting each module's RX and TX pins. On the Arduino UNO microcontroller, pin D0 is the RX, and pin D1 is the TX. In contrast, on the NodeMCU ESP8266 microcontroller, pin D6 is designated as the RX and D7 as the TX. The data transmission initiates with NodeMCU ESP8266 initializing a data request through the serial transmission of a specific character to Arduino UNO R3. Subsequently, Arduino UNO R3 continually checks for requests at intervals of 2 s. Upon detecting a data request, Arduino UNO R3 consolidates the sensor data into a single packet. Then, it transmits it to NodeMCU ESP8266 via serial communication. 3.5. System functionality This section provides a comprehensive overview of the design and functionality of the proposed system. It delves into the intricacies of the system's architecture, elucidating the operation of FL within specified parameter boundaries established in this study. Fig. 3 illustrates the system's overall workflow, outlining the specifics of input segmentation derived from various sensors. The process includes a detailed examination of microcontrollers and the integration of FL, ultimately resulting in automated and intelligent monitoring control. Download : Download high-res image (244KB) Download : Download full-size image Fig. 3. Workflow of the smart farming unit. 3.5.1. Data acquisition The Capacitive Soil Moisture Sensor is linked to pin A0 on the Arduino UNO R3 using analog pins. Consequently, the data displayed on the Arduino is initially in the form of raw analog data, which is then transformed into a percentage format using the map() function, designating 0 as the lower limit and 100 as the upper limit. This conversion results in a final percentage value for the Capacitive Soil Moisture Sensor within the 0–100 per cent range. Similarly, the LDR sensor is connected to pin A2 on the Arduino UNO R3, and its initial output is raw analog data. A formula derived from the calibration process is applied to convert this value into lux, utilizing the coefficient values obtained from a previously conducted linear regression. The × value represents this equation's analog data obtained from the LDR. The DHT22 is linked to pin D4 on the Arduino UNO R3 for digital pins. With the assistance of the available library, incorporating the DHT22 sensor into the system is a straightforward process. The acquired data from the DHT22 sensor provides direct outputs in degrees Celsius for temperature and percentage values for humidity. Moving on to the next sensor, PIR, is connected to pin D3 on the Arduino UNO R3. In the program, this sensor is designated as a digital input value. It is solely utilized to display acquisition data within the ``high'' and ``low'' value ranges. The other digital pin connects two relays, each comprising 4 and 2 channels, with each relay point linked to pins D6-D11 on the Arduino UNO R3. In addition, for the power requirements of all the modules, this work does not establish a direct connection between the sensors' two power pins (GND and VCC) and relays with the power pin on the Arduino UNO R3. Instead, these pins are directly linked to the primary 9 V power source obtained from the power supply, which has been reduced to a 5 V voltage using a 3296 step-down module. 3.5.2. Decision making The actuation decision in the mushroom farm depends on the output from the Fuzzy Inference System (FIS). The implementation of Fuzzy Logic (FL) is utilized to produce appropriate output based on the given input. This study involves five input parameters: soil moisture (Moist), light intensity (Light), temperature (Temp), humidity (Hum), and motion detection (Mot). Each parameter has a distinct number of memberships based on the specific characteristics of the variable it represents. Soil moisture, air temperature, motion detection, and humidity typically have three memberships (low, medium, and high) using a triangular membership function to capture the varying states relevant to the desired ranges. Light intensity is set to have four memberships (very low, low, medium, and high) utilizing a trapezoidal membership function, allowing for more nuanced categories that align with the specific illumination needs in the mushroom farm. For all parameters, the choice of memberships is tailored to the inherent complexities and variations of each parameter, enabling the fuzzy logic system to effectively model the intricacies of the monitored conditions in applications like smart farming or agriculture. In essence, the preference for triangular and trapezoidal membership functions arises from their simplicity, ease of interpretation, and ability to accurately model the gradual and non-linear transitions inherent in agricultural and environmental parameters. While other membership functions like Gaussian, bell-shaped, or sigmoidal can be employed, their suitability depends on the specific characteristics of the parameters being modeled. Gaussian functions, for instance, are adept at representing symmetric and bell-shaped distributions but may not be as intuitive for the gradual transitions seen in agriculture. Similarly, bell-shaped functions may be suitable for certain parameters with a well-defined peak. However, they might not capture the asymmetry found in soil moisture or air temperature transitions. Sigmoidal functions, known for gradual transitions, may lack the flexibility needed to represent the specific ranges and categories vital in the mushroom cultivation context. The choice of triangular and trapezoidal membership functions for soil moisture, air temperature, motion detection, humidity, and light intensity in the context of mushroom cultivation proves advantageous due to their ability to accurately capture the nuanced and dynamic nature of environmental conditions. Triangular membership functions are well-suited for parameters like soil moisture, air temperature, motion detection, and humidity, as they allow for a smooth and gradual transition between low, medium, and high levels. This is crucial in representing the continuous and variable characteristics of these parameters in mushroom cultivation. Trapezoidal membership functions, on the other hand, provide a more flexible and detailed representation, particularly suitable for light intensity. In mushroom farming, where lighting conditions are pivotal for different growth stages, the trapezoidal function's additional category allows for a more refined categorization of illumination levels. Triangular and trapezoidal membership functions offer precision, flexibility, and adaptability, making them superior choices for modeling the intricacies of the monitored conditions in smart mushroom farming. Drawing on the insights presented in [43], this research introduces a three-membership model for soil moisture, aiming to categorize moisture content into low, medium, and high ranges. A low soil moisture level (0 % to 30 %) suggests drier conditions that may hinder optimal mushroom growth. The medium soil moisture category (25 % to 70 %) represents a balanced range conducive to various stages of mushroom development. Conversely, high soil moisture (60 % to 100 %) indicates excessive wetness, posing challenges such as waterlogging and heightened vulnerability to diseases. Extending this methodology to air temperature, a three-membership model is applied. Low air temperature (0 °C to 15 °C) signals cooler conditions that might slow down mushroom development. The medium air temperature category (10 °C to 25 °C) supports diverse growth stages, from mycelium colonization to fruiting body formation. Conversely, high air temperature (20 °C to 30 °C) requires careful management to avoid heat stress. Furthermore, based on insights from [25], a three-membership model is employed for humidity. Low humidity (0 % to 50 %) suggests that drier conditions are less favorable for optimal mushroom growth. The medium humidity category (40 % to 70 %) represents a balanced range supporting various mushroom development stages. Conversely, high humidity (60 % to 100 %) indicates excess moisture, posing challenges like increased susceptibility to diseases and issues related to waterlogged substrate. Aligning with motion detection and light intensity, referenced by Sun et al., low motion detection indicates minimal movement, the standard condition during cultivation. Medium motion detection suggests occasional disturbances, while high motion detection indicates undesirable continuous motion in a controlled mushroom cultivation environment. Finally, regarding light intensity, this research employs a four-membership model to define distinct illumination levels. Very low light intensity (0 to 500 lux) is suitable for specific phases like spore germination. Low light intensity (400 to 1000 lux) caters to mycelium growth. Medium-light intensity (800 to 2000 lux) is conducive to various growth stages, including fruiting body formation. High light intensity (1500 to 5000 lux) supports intense lighting conditions beneficial for mushroom maturation. The implementation of FL entails connecting the input values gathered from all sensors, which are then employed to ascertain the output values following a predefined set of rules (see Table 1). To achieve this, a series of if-then rules are devised to work in conjunction with the membership function of each parameter. The Mamdani's type is chosen in this work due to its suitability for the proposed approach. In this context, the fuzzy output translates into the automation of various paired actuators. Table 1. Proposed fuzzy logic rules. IF soil moisture AND air temperature AND humidity AND motion detection AND light intensity THEN action Low (0–30 %) Low (0–15 °C) Low (0–50 %) Very Low (Minimal) Very Low (0–500 lux) Increase watering, Increase temperature, Increase humidity, Maintain motion, Increase light intensity Medium (25–70 %) Medium (10–25 °C) Medium (40–70 %) Low (Occasional) Low (400–1000 lux) Maintain watering, Maintain temperature, Maintain humidity, Maintain motion, Maintain light intensity High (60–100 %) High (20–30 °C) High (60–100 %) High (Undesirable) High (1500–5000 lux) Decrease watering, Decrease temperature, Decrease humidity, Stop motion, Decrease light intensity Fig. 4 represents the design of this FL flow, focusing on how it is optimized. The optimization of fuzzy parameters in the proposed model involves a meticulous process tailored to each environmental parameter. Soil moisture, air temperature, humidity, motion detection, and light intensity are systematically categorized into appropriate membership functions and ranges. For soil moisture, a three-membership model is employed, with specific ranges such as low moisture (0 % to 30 %) hindering optimal growth and high moisture (60 % to 100 %) indicating excess wetness. Air temperature, humidity, and motion detection follow similar optimization, aligning temperature and humidity ranges with different growth stages. Download : Download high-res image (256KB) Download : Download full-size image Fig. 4. Fuzzy logic flow. In contrast, motion detection categories reflect the standard and undesirable movement during cultivation. Notably, light intensity is optimized with a four-membership model, allowing for precise categorization suited to the level of light needed in the mushroom farm. Following the data acquisition of these parameters, the subsequent step in the FL workflow involves fuzzification. Here, each parameter's input value is adapted to conform with the established FL rules. This fuzzification process occurs within the rule evaluation segment, where several fuzzy membership rules are integrated. The outcome of this phase undergoes a defuzzification process, resulting in a fuzzy output value readable by the device and ready for further management to operate the connected actuator. 3.5.3. System monitoring This section details how sensor-acquired data becomes immediately accessible to farmers. The Arduino UNO R3 microcontroller oversees the data acquisition, packaging the dataset for transmission to the data-uploading microcontroller. Following receiving data from the Arduino UNO R3, the NodeMCU ESP8266 executes the data upload process to the web-based digital platform. The NodeMCU ESP8266 is configured to receive a Service Set Identifier (SSID) connection exclusively from a specific access point, as it can only connect to the singular SSID designated in the program. An LED indicator signifies a successful internet connection for the module. Once the NodeMCU ESP8266 receives the data, the subsequent step involves breaking down the data based on the acquisition from each sensor. After this breakdown, the data upload process unfolds on the digital platform. A deliberate delay is incorporated between each data upload event to prevent the potential occurrence of a data upload process deemed spam. The digital platform interface uses numeric, gauge, and graphical representations. Numerical and gauge-based information is consolidated within one feature, while graphical displays are presented separately. Each graph's x-label provides detailed time information, while the y-label indicates specific data acquisition details. The x-label on each graph is intentionally designed with varying time intervals. For instance, the graphs depicting soil moisture, light intensity, and air humidity display data every 5 s, while the graph for air temperature is programmed to show data every 30 s. This adjustment is made considering the responsiveness of the temperature changes, which necessitate a longer time frame compared to other parameters. 4. Result and discussion In this section, we present the results obtained and their related discussions. It is important to note that the features of the proposed method are based on its ability to assess soil moisture, air temperature, air humidity, and light intensity and identify the presence of insects. In line with the validation of the results, calibration is essential to verify that each sensor employed as a data retrieval module adheres to established measurement standards. Moreover, to provide the proposed method's context and validate the findings, the preliminaries of this section consist of comparing the proposed mushroom cultivation model with baseline models as reported by Sun et al. [43] and Dela Cruz and De Leon [20]. Table 2 presents a comparative analysis of baseline models commonly employed in mushroom cultivation, including Open Field Cultivation, Automated Watering Systems, Sensor Network-based Environment Control and IoT-based Environment Control. Each model is briefly characterized by its main features, outlining the strengths and limitations of these existing methodologies. The proposed new model, IoT and Fuzzy Logic-based Control is introduced as a comprehensive advancement. It integrates IoT for real-time data acquisition and fuzzy logic for adaptive and nuanced control. This integration aims to optimize environmental conditions for mushroom growth, addressing the shortcomings observed in the baseline models. Table 2. Comparison of the proposed model with benchmark algorithms. Model Main features Open field cultivation Traditional method with limited control over environmental parameters. Automated watering system Enhances water management but lacks adaptive control based on real-time conditions. Sensor network-based environment control Provides real-time data but may not adapt dynamically to varying cultivation needs. IoT-based environment control Offers remote monitoring and control but may require more sophisticated decision-making. Proposed IoT and fuzzy logic-based control Integrates IoT for real-time data and fuzzy logic for adaptive and nuanced control, optimizing environmental conditions for mushroom growth. The proposed IoT and Fuzzy Logic-based control model represents a significant advancement in mushroom cultivation methodologies, surpassing the capabilities of the baseline models in several key aspects. While traditional Open Field Cultivation and Automated Watering Systems offer basic approaches, they lack the adaptability and precision required for optimal growth. Sensor Network-based Environment Control and IoT-based Environment Control models provide real-time data. However, the former may not dynamically adapt, and the latter may face challenges in sophisticated decision-making. In contrast, our proposed model combines the strengths of IoT for continuous, real-time data acquisition and fuzzy logic for adaptive, nuanced control. This integration enables the system to make precise, context-aware adjustments based on the complex interplay of environmental variables, fostering an optimized and responsive cultivation environment. By leveraging these modern technologies, the comprehensive and advanced nature of our approach positions it as a valuable and innovative contribution to the field, poised to elevate the standards of mushroom cultivation practices. 4.1. Results based on sensor precision The soil moisture sensor undergoes calibration by obtaining analog values at two humidity levels: very wet (immersing the sensor in water) and dry (placing the sensor in a dry location). Subsequently, the map function is employed to convert the analog values into percentage values. Following this, calibration is executed using the Gouevn Soil Moisture Meter, comparing values acquired at four water depth points: 25 ml, 50 ml, 75 ml, and 100 ml. The outcomes of the soil moisture sensor calibration are detailed in Table 3. Post-calibration, the average error value is 4,79 %, indicating a high accuracy level of 95,21 %. Table 3. Capacitive soil moisture sensor accuracy. Deep level Capacitive soil moisture sensor Gouevn soil moisture meter Difference value Error (%) 25 ml 45 % 50 % 5 10 50 ml 62 % 65 % 3 4,62 75 ml 79 % 80 % 1 1,25 100 ml 93 % 90 % 3 3,34 Average error 4,79 Accuracy 95,21 In contrast to other sensors, the calibration procedure for this sensor involves comparing the reading from the reference sensor with the analog-to-analog-to-digital converter (ADC) value acquired. The Digital Lux Meter AS803 serves as the reference sensor in this process. The coefficient value is derived and then applied to the Arduino UNO R3 using the linear regression function. The x-value represents the ADC value from the sensor. At the same time, the y-value corresponds to the lux value determined through the comparative analysis. Like the previous step, the calibration is executed by re-evaluating and converting ADC values to lux values on the Light Dependent Resistor sensor against the digital readings on the reference measuring device. In this instance, the average error is 3,62 %, indicating a high accuracy level of 96,38 %. The outcomes of the light-dependent resistor sensor calibration are detailed in Table 4. The calibration of the DHT22 involves comparing it with the Sanfix TH-308A. The data collection, performed nine times, includes air temperature measurements ranging from 16 to 40 degrees Celsius. Additionally, air humidity levels are measured using the Ultrasonic Humidifier Support Arduino module to manipulate humidity levels. Like the prior sensors, calibration is achieved by computing the average error value, resulting in a 97,33 % accuracy for air temperature measurements and a 97,85 % accuracy for air humidity measurements, with an average error of 2,67 % for air temperature measurements and 2,15 % for air humidity measurements. The outcomes of the DHT22 sensor calibration are detailed in Table 5. Table 4. LDR sensor accuracy. Light dependent resistor Digital lux meter AS803 Difference value Error (%) 159 167 8 4,8 186 194 8 4,1 257 243 14 5,8 296 288 8 2,7 340 349 9 2,5 383 376 7 1,8 Average error 3,62 Accuracy 96,38 Table 5. DHT22 sensor accuracy. Measurement DHT22 Sanfix TH-308A Difference value Error (%) Temperature 17,20 16,50 0,70 4,24 21,80 23,20 1,40 6,03 24,40 24,60 0,20 0,81 29,50 28,40 1,10 3,87 29,40 28,30 1,10 3,89 29,40 28,50 0,90 3,16 38,30 38,80 0,50 1,29 38,70 38,50 0,20 0,52 39,00 38,90 0,10 0,26 Temperature average error 2,67 Temperature accuracy 97,33 Humidity 87,90 89,00 1,10 1,24 86,70 87,00 0,30 0,34 87,00 88,00 1,00 1,13 78,00 82,00 4,00 4,88 78,60 81,00 2,40 2,96 76,80 81,00 4,20 5,19 60,50 61,00 0,50 0,82 61,20 62,00 0,80 1,29 60,10 61,00 0,90 1,48 Humidity average error 2,15 Humidity accuracy 97,85 4.2. Result of the overall system A crucial element in intelligent mushroom cultivation involves a real-time regulation of vital parameters in the farming space. This method benefits from the FL paradigm by optimizing the environmental parameters, ensuring favorable conditions for cultivation, and achieving high-quality productivity in mushroom farming. The FL program makes decisions to oversee multiple actuators, aiding in executing environmental control tasks for the mushroom farm. The evaluation process entails subjecting each measurement parameter to manipulated conditions and comparing it with sensor data. This work seeks to omit a timeframe for implementing FL to avoid excessive decision-making, significantly leading to potential overtreatment. The monitoring procedure is conducted using a web-based system with a sample interface illustrated in Fig. 5, which consists of a display accessible to farmers on a real-time basis. The interface gauge for soil moisture and air humidity depicts data in percentage units (%), ranging from a minimum value of 0 to a maximum value of 100. In contrast, the design of the interface gauge for light intensity differs. It presents data in lux units, with a minimum value of 58 lux (equivalent to a value of 1023 ADC on a Light Dependent Resistor) for dark conditions and a maximum value of 500 lux (equivalent to a value of 6 ADC on a Light Dependent Resistor) for bright conditions. The interface gauge for air temperature displays data in centigrade units, with a defined minimum value of 14 degrees Celsius and a maximum value of 40 degrees Celsius. Download : Download high-res image (483KB) Download : Download full-size image Fig. 5. Gauge-interface of the sensors: (a) Soil moisture; (b) Light intensity; (c) Temperature; and (d) Humidity. In addition to presenting information through an interface gauge, we have also incorporated information delivery to farmers through a graph, as depicted in Fig. 6. In this context, the graph serves as a data logger within a specified time frame. The x-axis of the graph represents time, while the y-axis displays data obtained from each sensor. We set one minute for soil moisture, air humidity, and light intensity graphs, with data appearing every five seconds. In the case of the air temperature graph, a period of three minutes is defined, with data appearing every thirty seconds. Graphs with one minute allow a precise observation of line level changes when the sensor registers data outside the reference range. In essence, FL can promptly provide information for decision-making on each actuator to execute environmental control in less than five seconds. Download : Download high-res image (664KB) Download : Download full-size image Fig. 6. Graph interface of the data acquisition from each sensors. 4.3. Comparison with the state-of-the-art methods 4.3.1. Features comparison To showcase the effectiveness of our work, we compare it with state-of-the-art techniques. Table 6 illustrates differences across various aspects of each study, including objectives and developed features. While all the studies in this section share the goal of enhancing environmental quality in mushroom crops, each focuses on distinct aspects. The detailed discussion on features is categorized into groups, such as the sensors used, the implemented technology communication model, and user-feedback applications on the job. Table 6. Features comparison between the existing works and the proposed methods. Article Objective Features Type of sensors Communication technology User-feedback application [34] Design remote monitoring system and maintain optimum growth environment Temperature, humidity, carbon dioxide and light intensity Arduino UNO & WiFi Module—ThingSpeak Available [38] Farm automation and classification of edible toxic mushrooms using several machine learning models Temperature and humidity WiFi Module—WebSocket Available [12] Prediction of soil moisture at multiple depths against seasonal and weather parameters using a machine learning model Temperature, humidity, soil moisture, precipitation, solar radiation, lightning strike, vapor pressure, barometric pressure, wind direction, wind speed LoRaWAN Unavailable [45] Climate monitoring system with water control for use in an open mushroom farm Temperature, humidity WiFi—MQTT Available Proposed Monitor and control to improve substrate environment management Soil moisture, temperature, humidity, light intensity, motion detection Arduino UNO & WiFi Module—ThingerIO Available Nearly all aspects covered in state-of-the-art studies involve using temperature and humidity sensors, crucial considerations for mushroom plants. Some studies delve deeper, incorporating additional sensors for monitoring soil moisture, carbon dioxide levels, light intensity, and even climate factors like wind and air. The diversity extends to the forms of technology communication and the availability of user-feedback applications. The proposed research employs various sensors for soil moisture, temperature, humidity, light intensity, and motion detection. To facilitate user feedback, we utilize two serially connected microcontrollers through a digital platform named ThingerIO. 4.3.2. Results comparison Besides the features comparison, it is worth noting that the number of monitored farm's vital parameters consists of significant results to take care of to highlight the relevance and significance of the engineering findings, which emphasize the contribution of the proposed method in the current research landscape. Table 7 offers a nuanced evaluation of the proposed method alongside existing state-of-the-art approaches. Beyond the conventional features comparison, the introduction underscores the significance of the number of monitored vital parameters as a pivotal metric for highlighting the engineering findings' relevance and importance in the current research landscape. Based on the table data, it is evident that the proposed method stands out prominently. It excels in monitoring a comprehensive set of 5 vital parameters, surpassing the more limited scopes of the approaches outlined by Rahman et al. and Thong-un & Wongsaroj [45]. This expanded range implies a heightened capacity to capture diverse facets of the mushroom cultivation environment, enhancing the depth and richness of the data collected. Table 7. Comparison of the results. Method Number of managed vital parameters Number of actuating tools Ability to monitor in real-time basis [38] 2 3 Yes [12] 3 0 No [45] 2 3 Yes Proposed method 5 6 Yes Furthermore, the proposed method distinguishes itself by employing a notable number of 6 actuating tools. This surpasses the comparatively lower tool count in the methods presented by Rahman et al. [38] and Thong-un and Wongsaroj [45]. The greater number of actuating tools signifies a more sophisticated and versatile control mechanism, suggesting a higher degree of precision and adaptability in steering the farming of the mushroom environment. Crucially, the proposed method shares with Thong-un & Wongsaroj [45] the ability to monitor in real-time. This capability is recognized as essential for dynamic and responsive control, ensuring timely adjustments to changing conditions. In contrast, Rahman et al. [38] and Chandrappa et al. [12] lack this critical feature, potentially limiting their effectiveness in adapting to the rapidly evolving dynamics of the mushroom cultivation setting. The results prove that the proposed method emerges as a pioneering contribution to the current research landscape. Its prowess in monitoring an extensive array of vital parameters, utilizing a higher number of actuating tools, and facilitating real-time monitoring underscores its potential to revolutionize the field. 5. Conclusion Mushroom cultivation technology is a structured framework for overseeing and homogenizing the mushroom farm's substrate environmental parameters. This study concentrates on the cultivation of mushrooms sharing a range of environmental parameters, where growth dynamics are contingent upon various physical factors, such as temperature, light, and humidity. Numerous research endeavors have explored intelligent systems in mushroom cultivation, particularly focusing on automating temperature and air humidity control through watering systems. Despite these efforts, there remains an oversight of other crucial factors in mushroom plant cultivation. For instance, managing light exposure, addressing insect disruptions, and utilizing natural or artificial lights are critical environmental considerations that significantly impact the quality of edible mushrooms before and after harvest. These factors are vital in influencing mycelium characteristics, such as growth rate, density, color, and the physical appearance of fruiting bodies, including stalk, cap, and color formation. It is crucial to emphasize light's pivotal role in the cultivation of edible mushrooms. Additionally, research has identified the presence of insects, mites, crustaceans, and other arthropods feeding on mushrooms and decomposers on synthetic or wooden substrates as detrimental factors affecting the optimal growth of mushrooms. Consequently, there is a compelling need to advance agricultural technologies by considering all critical factors, enhancing both the quality and quantity of mushroom production. This study aims to address challenges in current mushroom production by developing an IoT-based system. The system integrates various modules to intelligently control crucial parameters, including temperature, humidity, substrate moisture, and light intensity. Moreover, the system incorporates a mechanism for pest control by automatically spraying pesticides when an external agent is detected in the mushroom farm. Fuzzy Logic (FL) is integrated into the IoT module, allowing the recorded sensor data to enable system functionality based on comparisons with pre-recorded standard data, defining optimal ranges for each vital parameter. The system activates actuators when sensor data falls outside the desired range, effectively maintaining the environmental parameters within optimal conditions for mushroom cultivation. Importantly, this method introduces self-decision-making through FL, a mathematical modeling technique emulating human decision-making. The contributions of this work include intelligent and adaptive monitoring of sensor data for creating an optimal environment for mushroom cultivation, as well as the optimization of agricultural resources, such as water and pesticides, through the introduction of previously unused sensors. Diversifying this method allows for a nuanced understanding of environmental factors applicable to various types of mushrooms within the field of mushroom cultivation. CRediT authorship contribution statement Firdaus Irwanto: Writing – original draft, Visualization, Software, Methodology, Investigation, Formal analysis, Conceptualization. Umar Hasan: Writing – original draft, Visualization, Validation, Software, Methodology, Investigation, Formal analysis, Conceptualization. Eric Saputra Lays: Writing – original draft, Visualization, Validation, Software, Methodology, Investigation, Formal analysis, Conceptualization. Ntivuguruzwa Jean De La Croix: Writing – original draft, Methodology, Investigation, Formal analysis, Conceptualization. Didacienne Mukanyiligira: Writing – review & editing, Methodology. Louis Sibomana: Writing – review & editing, Methodology. Tohari Ahmad: Supervision, Project administration, Funding acquisition, Conceptualization. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgment This research was supported by Institut Teknologi Sepuluh Nopember, Indonesia. Data availability Data will be made available on request. References [1] A.N. Abougreen, C. Chakraborty Applications of machine learning and Internet of Things in agriculture Green Technological Innovation for Sustainable Smart Societies, Springer International Publishing (2021), pp. 257-279, 10.1007/978-3-030-73295-0_12 View in ScopusGoogle Scholar [2] T. Adão, J. Hruška, L. Pádua, J. Bessa, E. Peres, R. Morais, J. Sousa Hyperspectral imaging: a review on UAV-based sensors, data processing and applications for agriculture and forestry Remote Sens., 9 (11) (2017), p. 1110, 10.3390/rs9111110 View in ScopusGoogle Scholar [3] A.F. Ahmed, G.A.-E. Mahmoud, M. Hefzy, Z. Liu, C. Ma Overview of the edible mushrooms in Egypt J. Future Foods, 3 (1) (2023), pp. 8-15, 10.1016/j.jfutfo.2022.09.002 View PDFView articleView in ScopusGoogle Scholar [4] Aishwarya, R., Yogitha, R., Lakshmanan, L., Maheshwari, M., Suji Helen, L., & Nagarajan, G. (2022). Smart agriculture framework implemented using the Internet of Things and deep learning (pp. 639–648). https://doi.org/10.1007/978-981-16-8739-6_56. Google Scholar [5] A. Al-Ansi, A.M. Al-Ansi, A. Muthanna, I.A. Elgendy, A. Koucheryavy Survey on intelligence edge computing in 6G: characteristics, challenges, potential use cases, and market drivers Future Internet, 13 (5) (2021), p. 118, 10.3390/fi13050118 View in ScopusGoogle Scholar [6] S.F. Ardabili, A. Mahmoudi, T. Gundoshmian, A. Roshanianfard Modeling and comparison of fuzzy and on/off controller in a mushroom growing hall Measurement, 90 (2016), pp. 127-134, 10.1016/j.measurement.2016.04.050 Google Scholar [7] G.-H. Ban, J.-H. Kim, S.A. Kim, M.S. Rhee, S.Y. Choi, I.J. Hwang, S.-R. Kim Microbial succession during button mushroom (Agaricus bisporus) production evaluated via high-throughput sequencing Food Microbiol., 114 (2023), Article 104307, 10.1016/j.fm.2023.104307 View PDFView articleView in ScopusGoogle Scholar [8] M.B. Bellettini, S. Bellettini, F.A. Fiorda, A.C. Pedro, F. Bach, M.F. Fabela-Morón, R. Hoffmann-Ribani Diseases and pests noxious to Pleurotus spp. mushroom crops Rev. Argentina Microbiol., 50 (2) (2018), pp. 216-226, 10.1016/j.ram.2017.08.007 View PDFView articleView in ScopusGoogle Scholar [9] M.B. Bellettini, F.A. Fiorda, H.A. Maieves, G.L. Teixeira, S. Ávila, P.S. Hornung, A.M. Júnior, R.H. Ribani Factors affecting mushroom Pleurotus spp Saudi J. Biol. Sci., 26 (4) (2019), pp. 633-646, 10.1016/j.sjbs.2016.12.005 View PDFView articleView in ScopusGoogle Scholar [10] H. Benyezza, M. Bouhedda, S. Rebouh Zoning irrigation smart system based on fuzzy control technology and IoT for water and energy saving J Clean Prod, 302 (2021), Article 127001, 10.1016/j.jclepro.2021.127001 View PDFView articleView in ScopusGoogle Scholar [11] J. Cervera-Gascó, J.E. Pardo, M. Álvarez-Ortí, E. López-Mata, D. Cunha Zied, A. Pardo-Giménez An intelligent mushroom strain selection model based on their quality characteristics Food Biosci., 56 (2023), Article 103232, 10.1016/j.fbio.2023.103232 View PDFView articleView in ScopusGoogle Scholar [12] V.Y. Chandrappa, B. Ray, N. Ashwatha, P. Shrestha Spatiotemporal modeling to predict soil moisture for sustainable smart irrigation Internet Things, 21 (2023), Article 100671, 10.1016/j.iot.2022.100671 View PDFView articleView in ScopusGoogle Scholar [13] Cikarge, G.P., & Arifin, F. (2018). Oyster mushrooms humidity control based on fuzzy logic by using Arduino ATMega238 microcontroller. J. Phys.: Conf. Ser., 1140, 012002. https://doi.org/10.1088/1742-6596/1140/1/012002. Google Scholar [14] J. Clover Food security in sub-Saharan Africa Afr. Secur. Rev., 12 (1) (2003), pp. 5-15 CrossRefGoogle Scholar [15] N.J. De La Croix, T. Ahmad Toward secret data location via fuzzy logic and convolutional neural network Egypt. Inform. J., 24 (3) (2023), Article 100385, 10.1016/j.eij.2023.05.010 View PDFView articleView in ScopusGoogle Scholar [16] N.J. De La Croix, T. Ahmad, F. Han Enhancing secret data detection using convolutional neural networks with fuzzy edge detection IEEE Access (2023), p. 1, 10.1109/ACCESS.2023.3334650 Google Scholar [17] N.J. De La Croix, C.C. Islamy, T. Ahmad Secret message protection using fuzzy logic and difference expansion in digital images Proceedings of the 2022 IEEE Nigeria 4th International Conference on Disruptive Technologies for Sustainable Development, NIGERCON 2022 (2022), 10.1109/NIGERCON54645.2022.9803151 Google Scholar [18] N.J. De La Croix, M. Didacienne, S. Louis Fuzzy logic-based shiitake mushroom farm control for harvest enhancement 2022 10th International Symposium on Digital Forensics and Security (ISDFS) (2022), pp. 1-6, 10.1109/ISDFS55398.2022.9800832 Google Scholar [19] N.J. De La Croix, M. Didacienne, S. Louis, J.T. Philander, T. Ahmad Internet of Things based controlled environment to produce shiitake mushroom 2022 IEEE International Conference on Blockchain and Distributed Systems Security (ICBDS) (2022), pp. 1-6, 10.1109/ICBDS53701.2022.9936039 Google Scholar [20] T.E.E. Dela Cruz, A.M De Leon Edible mushrooms of the Philippines: traditional knowledge, bioactivities, mycochemicals, and in vitro cultivation Mycology in the Tropics, Elsevier (2023), pp. 271-292, 10.1016/B978-0-323-99489-7.00003-2 View PDFView articleGoogle Scholar [21] M. Dedousi, E.-M. Melanouri, D. Karayannis, E.-I. Kaminarides, P. Diamantopoulou Utilization of spent substrates and waste products of mushroom cultivation to produce new crops of Pleurotus ostreatus, Pleurotus eryngii and Agaricus bisporus Carbon Resour. Conver. (2023), 10.1016/j.crcon.2023.08.001 Google Scholar [22] FAO The state of food security and nutrition in the world 2023 The State of Food Security and Nutrition in the World 2023, FAO; IFAD; UNICEF; WFP; WHO (2023), 10.4060/cc3017en Google Scholar [23] Y. Feng, H. Xu, Y. Sun, R. Xia, Z. Hou, Y. Li, Y. Wang, S. Pan, L. Li, C. Zhao, H. Ren, G. Xin The Effect of light on preharvest and post-harvest edible mushroom quality and its action mechanism: a review Trends Food Sci. Technol., 139 (2023), Article 104119, 10.1016/j.tifs.2023.104119 View PDFView articleView in ScopusGoogle Scholar [24] Â. Fernandes, A.L. Antonio, M.B.P.P. Oliveira, A. Martins, I.C.F.R. Ferreira Effect of gamma and electron beam irradiation on mushrooms' physico-chemical and nutritional properties: a review Food Chem., 135 (2) (2012), pp. 641-650, 10.1016/j.foodchem.2012.04.136 View PDFView articleView in ScopusGoogle Scholar [25] P. Goglio, T. Ponsioen, J. Carrasco, I. Milenkovi, L. Kiwala, K. Van Mierlo, R. Helmes, F. Tei, E. Oosterkamp, M. Pérez An environmental assessment of Agaricus bisporus ((J.E.Lange) Imbach) mushroom production systems across Europe Eur. J. Agron., 155 (2024), Article 127108, 10.1016/j.eja.2024.127108 View PDFView articleView in ScopusGoogle Scholar [26] R.M. Haris, S. Al-Maadeed Integrating blockchain technology in 5G enabled IoT: a review 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT) (2020), pp. 367-371, 10.1109/ICIoT48696.2020.9089600 View in ScopusGoogle Scholar [27] S.-J. Huang, F.-K. Huang, A. Purwidyantri, A. Rahmandita, S.-Y. Tsai Effect of pulsed light irradiation on bioactive, nonvolatile components and antioxidant properties of caterpillar medicinal mushroom Cordyceps militaris (Ascomycetes) Int. J. Med. Mushrooms, 19 (6) (2017), pp. 547-560, 10.1615/IntJMedMushrooms.v19.i6.60 View in ScopusGoogle Scholar [28] Y. Jararweh, S. Fatima, M. Jarrah, S AlZu'bi Smart and sustainable agriculture: fundamentals, enabling technologies, and future directions Comput. Electr. Eng., 110 (2023), Article 108799, 10.1016/j.compeleceng.2023.108799 View PDFView articleView in ScopusGoogle Scholar [29] T. Kaewwiset, P. Yodkhad The automatic temperature and humidity control system uses a fuzzy logic algorithm for mushroom nurseries 2017 International Conference on Digital Arts, Media and Technology (ICDAMT) (2017), pp. 396-399, 10.1109/ICDAMT.2017.7905000 View in ScopusGoogle Scholar [30] M.R.M. Kassim, I. Mat, I.M. Yusoff Applications of Internet of Things in mushroom farm management 2019 13th International Conference on Sensing Technology (ICST) (2019), pp. 1-6, 10.1109/ICST46873.2019.9047702 Google Scholar [31] M.A. Khan, A. Alqahtani, A. Khan, S. Alsubai, A. Binbusayyis, M.M.I. Ch, H.-S. Yong, J. Cha Cucumber leaf diseases recognition using multi-level deep entropy-ELM feature selection Appl. Sci., 12 (2) (2022), p. 593, 10.3390/app12020593 Google Scholar [32] R.S. Krishnan, E.G. Julie, Y.H. Robinson, S. Raja, R. Kumar, P.H. Thong, L.H. Son Fuzzy logic-based smart irrigation system using Internet of Things J. Clean. Prod., 252 (2020), Article 119902, 10.1016/J.JCLEPRO.2019.119902 View PDFView articleView in ScopusGoogle Scholar [33] Y. Li, S. Ding, T. Xiang, H. Kitazawa, H. Sun, Y. Guo Effects of light irradiation on the textural properties and energy metabolism of post-harvest shiitake mushrooms (Lentinula edodes) J. Food Process. Preserv., 45 (12) (2021), 10.1111/jfpp.16066 Google Scholar [34] A. Marzuki, S.Y. Ying Environmental monitoring and controlling system for mushroom farm with online interface Int. J. Comput. Sci. Inf. Technol., 9 (4) (2017), pp. 17-28, 10.5121/ijcsit.2017.9402 Google Scholar [35] Monica, M., Sivakumar, P., Isac, S.J., & Ranjitha, K. (2022). PMSG-based WECS: control techniques, MPPT methods and control strategies for standalone battery integrated system. 040013. https://doi.org/10.1063/5.0072870. Google Scholar [36] V.S. Narwane, A. Gunasekaran, B.B. Gardas Unlocking adoption challenges of IoT in Indian agricultural and food supply chain Smart Agric. Technol., 2 (2022), Article 100035, 10.1016/j.atech.2022.100035 View PDFView articleView in ScopusGoogle Scholar [37] H.C. Pacco Simulation of temperature control and irrigation time in the production of tulips using Fuzzy logic Procedia Comput. Sci., 200 (2022), pp. 1-12, 10.1016/j.procs.2022.01.199 View PDFView articleView in ScopusGoogle Scholar [38] H. Rahman, Md.O. Faruq, Abdul Hai, T. Bin, W. Rahman, M.M. Hossain, M. Hasan, S. Islam, Md. Moinuddin, Md.T. Islam, M.M Azad IoT-enabled mushroom farm automation with machine learning to classify toxic mushrooms in Bangladesh J. Agric. Food Res., 7 (2022), Article 100267, 10.1016/j.jafr.2021.100267 View PDFView articleView in ScopusGoogle Scholar [39] T. Saranya, C. Deisy, S. Sridevi, K.S.M. Anbananthen A comparative study of deep learning and the Internet of Things for precision agriculture Eng. Appl. Artif. Intell., 122 (2023), Article 106034, 10.1016/j.engappai.2023.106034 View PDFView articleView in ScopusGoogle Scholar [40] Sassine, Y.N. (2021). Mushrooms: Agaricus bisporus (Y. N. Sassine, Ed.). CABI. https://doi.org/10.1079/9781800620414.0000. Google Scholar [41] G. Scur, A.V.D. da Silva, C.A. Mattos, R.F. Gonçalves Analysis of IoT adoption for vegetable crop cultivation: multiple case studies Technol Forecast Soc Change, 191 (2023), Article 122452, 10.1016/j.techfore.2023.122452 View PDFView articleView in ScopusGoogle Scholar [42] M.P.T. Sulistyanto, W. Harianto, D.A. Nugroho, R.E. Retandi, A.K. Akbar, P.H. Tjahjanti The controlling and monitoring system in oyster mushroom cultivation using fuzzy logic through web technology integrated with the Internet of Things MATEC Web of Conferences, 197 (2018), p. 15002, 10.1051/matecconf/201819715002 View in ScopusGoogle Scholar [43] M. Sun, Y. Zhuang, Y. Gu, G. Zhang, X. Fan, Y. Ding A comprehensive review of the application of ultrasonication in the production and processing of edible mushrooms: drying, extraction of bioactive compounds, and post-harvest preservation Ultrason. Sonochem., 102 (2024), Article 106763, 10.1016/j.ultsonch.2024.106763 View PDFView articleView in ScopusGoogle Scholar [44] T. Talhelm, A.S. English Historically, rice-farming societies have tighter social norms in China and worldwide Proc. Natl. Acad. Sci., 117 (33) (2020), pp. 19816-19824, 10.1073/pnas.1909909117 View in ScopusGoogle Scholar [45] N. Thong-un, W. Wongsaroj Productivity enhancement using low-cost smart wireless programmable logic controllers: a case study of an oyster mushroom farm Comput. Electron. Agric., 195 (2022), Article 106798, 10.1016/j.compag.2022.106798 View PDFView articleView in ScopusGoogle Scholar [46] I. Théophile, N.J. De La Croix, T. Ahmad Fuzzy logic-based steganographic scheme for high payload capacity with high imperceptibility 2023 11th International Symposium on Digital Forensics and Security (ISDFS) (2023), pp. 1-6, 10.1109/ISDFS58141.2023.10131727 Google Scholar [47] M.K. Tripathi, D.D. Maktedar A role of computer vision in fruits and vegetables among various horticulture products of agriculture fields: a survey Inf. Process. Agric., 7 (2) (2020), pp. 183-203, 10.1016/j.inpa.2019.07.003 View PDFView articleGoogle Scholar [48] A.V. Turukmane, M. Pradeepa, K.S.S. Reddy, R. Suganthi, Y.M. Riyazuddin, V.V.S. Tallapragada Smart farming using cloud based IoT data analytics Measurement: Sensors, 27 (2023), Article 100806, 10.1016/j.measen.2023.100806 View PDFView articleView in ScopusGoogle Scholar [49] UNCTAD. (2017). The role of science, technology, and innovation in ensuring food security by 2030. Google Scholar [50] M.E. Valverde, T. Hernández-Pérez, O. Paredes-López Edible mushrooms: improving human health and promoting quality life Int. J. Microbiol., 2015 (2015), pp. 1-14, 10.1155/2015/376387 Google Scholar [51] P. Vandôme, C. Leauthaud, S. Moinard, O. Sainlez, I. Mekki, A. Zairi, G. Belaud Making technological innovations accessible to agricultural water management: design a low-cost wireless sensor network for drip irrigation monitoring in Tunisia Smart Agric. Technol., 4 (2023), Article 100227, 10.1016/j.atech.2023.100227 View PDFView articleView in ScopusGoogle Scholar [52] C. Xie, W. Gong, Z. Zhu, L. Yan, Z. Hu, Y. Peng Comparative transcriptomics of Pleurotus eryngii reveals blue-light regulation of carbohydrate-active enzymes (CAZymes) expression at primordium differentiated into fruiting body stage Genomics, 110 (3) (2018), pp. 201-209, 10.1016/j.ygeno.2017.09.012 View PDFView articleView in ScopusGoogle Scholar [53] Z. Yin, Z. Li, H. Li Application of Internet of Things data processing based on machine learning in community sports detection Prev. Med., 173 (2023), Article 107603, 10.1016/J.YPMED.2023.107603 View PDFView articleView in ScopusGoogle Scholar [54] D. Zhou, Y. Sun, M. Li, T. Zhu, K. Tu Post-harvest hot air and UV-C treatments enhance aroma-related volatiles by simulating the lipoxygenase pathway in peaches during cold storage Food Chem., 292 (2019), pp. 294-303, 10.1016/j.foodchem.2019.04.049 View PDFView articleView in ScopusGoogle Scholar Cited by (0) © 2024 The Authors. Published by Elsevier B.V. Recommended articles Palm oil-based biodiesel industry sustainability model using dynamic systems to balance food, energy, and export allocations Smart Agricultural Technology, Volume 7, 2024, Article 100421 Zuhri Mayandi, Suharjito View PDF Segmentation-based quantification of Tuta absoluta’s damage on tomato plants Smart Agricultural Technology, Volume 7, 2024, Article 100415 Loyani Loyani View PDF An environmental assessment of Agaricus bisporus ((J.E.Lange) Imbach) mushroom production systems across Europe European Journal of Agronomy, Volume 155, 2024, Article 127108 Pietro Goglio, …, Margarita Pérez View PDF Show 3 more articles Article Metrics Captures Readers: 1 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

</subsection_point_Point 6>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 2>
Point: Benefits of edge computing in reducing latency, enabling real-time decision-making, and reducing reliance on cloud connectivity

Papers to support point:

Paper 1:
- APA Citation: Hassija, V., Chamola, V., Saxena, V., Jain, D., Goyal, P., & Sikdar, B. (2019). A Survey on IoT Security: Application Areas, Security Threats, and Solution Architectures. IEEE Access, 7, 82721-82743. https://doi.org/10.1109/ACCESS.2019.2924045
  Main Objective: To provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems.
  Study Location: Unspecified
  Data Sources: Survey data
  Technologies Used: Blockchain, fog computing, edge computing, machine learning
  Key Findings: Edge computing brings computation and analytics closer to the data source, reducing the need for data to travel to the cloud.
  Extract 1: Edge Computing and Fog Computing
  Extract 2: Hassija; Vinay Chamola; Vikas Saxena; Divyansh Jain; Pranav Goyal; Biplab Sikdar
  Limitations: No major limitations identified.
  Relevance Evaluation: Highly relevant - The provided excerpt directly addresses the point in the review outline under evaluation (the benefits of edge computing in reducing latency, enabling real-time decision-making, and reducing reliance on cloud connectivity) with specific examples.
  Relevance Score: 1.0
  Inline Citation: Hassija et al., 2019
  Explanation: The study explores the benefits of using edge computing in IoT systems to reduce latency, enhance real-time decision-making, and lessen reliance on cloud connectivity. It examines the specific ways edge computing contributes to these improvements, such as by bringing computation and analytics closer to the data source and reducing the need for data to travel to the cloud.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences Loading [MathJax]/extensions/MathMenu.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account Personal Sign In Browse My Settings Help Institutional Sign In All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 7 A Survey on IoT Security: Application Areas, Security Threats, and Solution Architectures Publisher: IEEE Cite This PDF Vikas Hassija; Vinay Chamola; Vikas Saxena; Divyansh Jain; Pranav Goyal; Biplab Sikdar All Authors 828 Cites in Papers 63869 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. Security Critical Application Areas of IoT III. Sources of Security Threats in IoT Applications IV. Improvements and Enhancements Required for Upcoming IoT Applications V. IoT Security Using Blockchain Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: The Internet of Things (IoT) is the next era of communication. Using the IoT, physical objects can be empowered to create, receive, and exchange data in a seamless manner. Various IoT applications focus on automating different tasks and are trying to empower the inanimate physical objects to act without any human intervention. The existing and upcoming IoT applications are highly promising to increase the level of comfort, efficiency, and automation for the users. To be able to implement such a world in an ever-growing fashion requires high security, privacy, authentication, and recovery from attacks. In this regard, it is imperative to make the required changes in the architecture of the IoT applications for achieving end-to-end secure IoT environments. In this paper, a detailed review of the security-related challenges and sources of threat in the IoT applications is presented. After discussing the security issues, various emerging and existing technologies focused on achieving a high degree of trust in the IoT applications are discussed. Four different technologies, blockchain, fog computing, edge computing, and machine learning, to increase the level of security in IoT are discussed. This paper presents a detailed survey of IoT security. First of all the security critical IoT applications are discussed. Next, the security threats at different layers i...View more Published in: IEEE Access ( Volume: 7) Page(s): 82721 - 82743 Date of Publication: 20 June 2019 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2019.2924045 Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction The pace of connecting physical devices around us to the Internet is increasing rapidly. According to a recent Gartner report, there will be around 8.4 billion connected things worldwide in 2020. This number is expected to grow to 20.4 billion by 2022 [1]. The use of IoT applications is increasing in all parts of the world. The major driving countries in this include western Europe, North America, and China [1]. The number of machine to machine (M2M) connections is expected to grow from 5.6 billion in 2016 to 27 billion in 2024 [1]. This leap in numbers itself declares IoT to be one of the major upcoming markets that could form a cornerstone of the expanding digital economy. The IoT industry is expected to grow in terms of revenue from 892billionin2018to 4 trillion by 2025 [2]. M2M connections cover a broad range of applications like smart cities, smart environment, smart grids, smart retail, smart farming, etc. [3]. Figure 1 shows the past, present and future architecture of IoT. In future, the devices are not only expected to be connected to the Internet and other local devices but are also expected to communicate with other devices on the Internet directly. Apart from the devices or things being connected, the concept of social IoT (SIoT) is also emerging. SIoT will enable different social networking users to be connected to the devices and users can share the devices over the Internet [4]. FIGURE 1. Present and future architecture of IoT. Show All With all this vast spectrum of IoT applications comes the issue of security and privacy. Without a trusted and interoperable IoT ecosystem, emerging IoT applications cannot reach high demand and may lose all their potential. Along with the security issues faced generally by the Internet, cellular networks, and WSNs, IoT also has its special security challenges such as privacy issues, authentication issues, management issues, information storage and so on. Table 1 summarizes various factors due to which securing IoT environment is much more challenging than securing normal information technology (IT) devices. Due to all these issues and vulnerabilities, the IoT applications create a fertile ground for different kinds of cyber threats. There have been various security and privacy attacks on the already deployed IoT applications worldwide. Mirai attack in the last quarter of 2016 was estimated to infect around 2.5 million devices connected to the Internet and launch distributed denial of service (DDoS) attack [5]. After Mirai, Hajime and Reaper are the other big botnet attacks launched against a large number of IoT devices [5]. IoT devices, being low powered and less secure, provide a gateway to the adversaries for entering into home and corporate networks, thereby giving easy access to the user’s data. Also, the domain of IoT is expanding beyond mere things or objects. There have been various successful attempts to implant IoT devices into the human body to monitor the live condition of various organs [6]. Attackers can target such devices to track the location of a particular individual or falsify data. Such an attack has not taken place yet in real life but can be highly dangerous, if such devices are compromised. TABLE 1 Comparison of Security of IT Devices and IoT Devices Cyber Physical Systems (CPS) is another area benefitting from the growth of IoT. In CPS physical objects in the environment are monitored, and actions are taken based on the physical changes. Since CPS encompass assets of critical importance (e.g., power grids, transportation systems), security vulnerabilities in such systems have serious consequences. However, security challenges for CPS have their unique characteristics and are outside the scope of this paper. In any IoT ecosystem or environment, there are four important layers. The first layer includes the use of various sensors and actuators to perceive the data or information to perform various functionalities. Based on that, in the second layer, a communication network is used to transmit the collected data. Most of the evolving IoT applications deploy the third layer, called a middleware layer, to act as a bridge between the network and application layer. Finally, on the fourth layer, there are various IoT based end-to-end applications like smart grids, smart transport, smart factories, etc. All of these four layers have security problems specific to them. Apart from these layers, various gateways connect these layers and help in the data movement. There are certain security threats specific to these gateways as well. In this paper, a detailed survey of IoT security solutions in the existing literature is presented. First of all, the fundamental constraints to achieve high levels for security in IoT applications are presented. The goal of this paper is to highlight the major existing and upcoming solutions for IoT security. Specifically, the four major classes of IoT security solutions namely: (1) blockchain based solutions; (2) fog computing based solutions; (3) machine learning based solutions and (4) edge computing based solutions are highlighted. Table 3 gives a list of acronyms related to IoT used in this paper. TABLE 2 Related Surveys on IoT Security TABLE 3 List of Acronyms A. Related Surveys and Our Contributions There are various existing surveys on IoT security and privacy issues. Yuchen et al. [10] have summarized various security issues in IoT applications. Authors of [11] have discussed the security issues specific to location-based services in IoT. The authors target the particular problems related to localization and positioning of the IoT devices. Anne et al. in [12] focus mainly on the security issues related to IoT middleware and provide a detailed survey of related existing protocols and their security issues. M. Guizani et al. in [14] have surveyed various trust management techniques for IoT along with their pros and cons. Security mechanisms for IoT security such as software defined networking (SDN) and network function virtualization (NFV) are discussed in [13]. In [8] the authors have compared edge computing with traditional cloud systems to secure IoT systems. Jie Lin et al. in [9] have discussed the relationship between IoT and fog computing. Some of the security issues related to fog computing have also been discussed. Authors of [7] have discussed vulnerabilities faced by IoT in brief. Table 2 summarizes the main contributions of the previous comprehensive surveys on IoT security. Although there are several works in this direction, they are specific to certain limited aspects of IoT. This calls the need for a detailed survey on all the existing and upcoming security challenges in IoT applications. This paper will help the reader to get a detailed idea of the state-of-the-art in IoT security and will give them a general understanding of the area. The main contributions of this work are as follows: A classification of different IoT applications and specific security and privacy issues related to those applications. A detailed explanation of different threat sources in different layers of IoT. Detailed and realistic recommendations to improve the IoT infrastructure to facilitate secure communications. Review on the proposed countermeasures to the security issues in IoT. An assessment of the open issues, challenges and future research directions for developing secure IoT applications. B. Organization The organization of the rest of the paper is as follows: Section II describes various application areas of IoT where high security is required. Section III discusses various sources of threats in an IoT environment. In section IV various constraints and requirements to be considered while developing a secure IoT application are reviewed. Four major IoT security approaches, i.e., blockchain, fog computing, machine learning, and edge computing are presented in Section V, VI, VII, and VIII, respectively. Section IX describes various open issues, challenges and upcoming research opportunities in IoT security and finally, Section X concludes the paper. SECTION II. Security Critical Application Areas of IoT Security is highly critical in almost all IoT applications that have already been deployed or are in the process of deployment. The applications of IoT are increasing very rapidly and penetrating most of the existing industries. Although operators support these IoT applications through existing networking technologies, several of these applications need more stringent security support from technologies they use. In this section various security critical IoT applications are discussed. Smart Cities: Smart cities involve extensive use of emerging computation and communication resources for increasing the overall quality of life of the people [15]. It includes smart homes, smart traffic management, smart disaster management, smart utilities, etc. There is a push to make cities smarter, and governments worldwide are encouraging their development through various incentives [16]. Although the use of smart applications is intended to improve the overall quality of life of the citizens, it comes with a threat to the privacy of the citizens. Smart card services tend to put the card details and purchase behavior of the citizens at risk. Smart mobility applications may leak the location traces of the users. There are applications using which parents can keep track of their child. However, if such applications are hacked, then the safety of the child can come to risk. Smart Environment: Smart environment includes various IoT applications such as fire detection in forests, monitoring the level of snow in high altitude regions, preventing landslides, early detection of earthquakes, pollution monitoring, etc. All these IoT applications are closely related to the life of human beings and animals in those areas. The government agencies involved in such fields will also be relying on the information from these IoT applications. Security breaches and vulnerability in any area related to such IoT applications can have serious consequences. In this context, both false negatives and false positives can lead to disastrous results for such IoT applications. For example, if the application starts detecting earthquakes falsely, then it will lead to monetary losses for the government and businesses. On the other hand, if the application is not able to predict the earthquake, then it will lead to the loss of both property and life. Therefore, smart environment applications have to be highly precise, and security breaches and data tampering must be avoided. Smart Metering and Smart Grids: Smart metering includes applications related to various measurements, monitoring, and management. The most common application of smart metering is smart grids, where the electricity consumption is measured and monitored. Smart metering may also be used to address the problem of electricity theft [17]. Other applications of smart metering include monitoring of water, oil and gas levels in storage tanks and cisterns. Smart meters are also used to monitor and optimize the performance of solar energy plants by dynamically changing the angle of solar panels to harvest the maximum possible solar energy. There also exist some IoT applications that use smart meters to measure the water pressure in water transport systems or to measure the weight of goods. However, smart metering systems are vulnerable to both physical and cyber-attacks as compared to analog meters that can be tampered only by physical attacks. Also, smart meters or advanced metering infrastructure (AMI) are intended to perform functions beyond generic energy usage recording. In a smart home area network (HAN) all electric equipment at home are connected to smart meters and the information collected from these equipments can be used for load and cost management. Intentional intrusion in such communication systems by the consumer or an adversary may modify the collected information, leading to monetary loss for the service providers or consumers [18]. Security and Emergencies: Security and emergencies is another important area where various IoT applications are being deployed. It includes applications such as allowing only authorized people in restricted areas etc. Another application in this domain is the detection of leakage of hazardous gases in industrial areas or areas around chemical factories. Radiation levels can also be measured in the areas around nuclear power reactors or cellular base stations and alerts can be generated when the radiation level is high. There are various buildings whose systems have sensitive data or that house sensitive goods. Security applications can be deployed to protect sensitive data and goods. IoT applications that detect various liquids can also be used to prevent corrosion and break downs in such sensitive buildings. Security breaches in such applications can also have various serious consequences. For example, the criminals may try to enter the restricted areas by attacking the vulnerabilities in such applications. Also, false radiation level alarms can have serious immediate and long term impacts. For example, if infants are exposed to high levels of radiation, then it may lead to serious life threatening diseases in long term. Smart Retail: IoT applications are being extensively used in the retail sector. Various applications have been developed to monitor the storage conditions of the goods as they move along the supply chain. IoT is also being used to control the tracking of products in the warehouses so that restocking can be done optimally. Various intelligent shopping applications are also being developed for assisting the customers based on their preferences, habits, allergies to certain components, etc. Mechanisms to provide the experience of online shopping to offline retailers using augmented reality techniques have also been developed. Various companies in retail have faced security issues in deploying and using various IoT applications. Some of these companies include Apple, Home Depot, JP Morgan Chase and Sony [19]. Adversaries may try to compromise the IoT applications associated with storage conditions of the goods and may try to send wrong information about the products to the users in order to increase the sale. If security features are not implemented in smart retail, attackers may steal debit and credit card information, phone numbers, email-addresses, etc. of the customers which can lead to monetary losses for the customers and retailers. Smart Agriculture and Animal Farming: Smart agriculture includes monitoring soil moisture, controlling micro-climate conditions, selective irrigation in dry zones, and controlling humidity and temperature. Usage of such advanced features in agriculture can help in achieving high yields and can save farmers from monetary losses. Control of temperature and humidity levels in various grain and vegetable production can help in preventing fungus and other microbial contaminants. Controlling the climate conditions can also help in increasing the vegetable and crop yield and quality. Just like crop monitoring, there are IoT applications to monitor the activities and the health condition of farm animals by attaching sensors to the animals. If such applications are compromised, then it may lead to the theft of animals from the farm and adversaries may also damage the crops. Home Automation: Home automation is one of the most widely used and deployed IoT applications. This includes applications such as those for remotely controlling electrical appliances to save energy, systems deployed on windows and doors to detect intruders, etc. Monitoring systems are being applied to track energy and water supply consumption, and users are being advised to save cost and resources. Authors in [20] have proposed the use of logic based security algorithms to enhance security level in homes. Intrusions are detected by comparing the user actions at key locations of the home with normal behavior of the user in these locations. However, attackers may gain unauthorized access of the IoT devices in the home and try to harm the users. For instance, cases of home burglaries have increased rapidly after the deployment of various home automation systems [20]. There have also been various cases in the past where the adversaries try to analyze the type and volume of Internet traffic to/from the smart home for judging the behavior and presence of the residents. SECTION III. Sources of Security Threats in IoT Applications As discussed in Section I, any IoT application can be divided into four layers: (1) sensing layer; (2) network layer; (3) middleware layer; and (4) application layer. Each of these layers in an IoT application uses diverse technologies that bring a number of issues and security threats. Figure 2 shows various technologies, devices, and applications at these four layers. This section discusses various possible security threats in IoT applications for these four layers. Figure 3 shows the possible attacks on these four layers. The special security issues associated with the gateways that connect these layers are also discussed in this section. FIGURE 2. Layers in IoT system. Show All FIGURE 3. Types of attacks on IoT. Show All A. Security Issues at Sensing Layer The sensing layer mainly deals with physical IoT sensors and actuators. Sensors sense the physical phenomenon happening around them [21]–[23]. Actuators, on the other hand, perform a certain action on the physical environment, based on the sensed data. There are various kinds of sensors for sensing different kinds of data, e.g., ultrasonic sensors, camera sensors, smoke detection sensors, temperature and humidity sensors, etc. There can be mechanical, electrical, electronic or chemical sensors used to sense the physical environment. Various sensing layer technologies are used in different IoT applications like RFID, GPS, WSNs, RSNs, etc. Major security threats that can be encountered at the sensing layer are as follows: Node Capturing: IoT applications comprise of several low power nodes such as sensors and actuators. These nodes are vulnerable to a variety of attacks by the adversaries. The attackers may try to capture or replace the node in the IoT system with a malicious node. The new node may appear to be the part of the system but is controlled by the attacker. This may lead to compromising the security of the complete IoT application [24]. Malicious Code Injection Attack: The attack involves the attacker injecting some malicious code in the memory of the node. Generally, the firmware or software of IoT nodes are upgraded on the air, and this gives a gateway to the attackers to inject malicious code. Using such malicious code, the attackers may force the nodes to perform some unintended functions or may even try to access the complete IoT system. False Data Injection Attack: Once the node is captured, the attacker may use it to inject erroneous data onto the IoT system. This may lead to false results and may result in malfunctioning of the IoT application. The attacker may also use this method to cause a DDoS attack. Side-Channel Attacks (SCA): Apart from direct attacks on the nodes, various side-channel attacks may lead to leaking of sensitive data. The microarchitectures of processors, electromagnetic emanation and their power consumption reveal sensitive information to adversaries. Side channel attacks may be based on power consumption, laser-based attacks, timing attacks or electromagnetic attacks. Modern chips take care of various countermeasures to prevent these side-channel attacks while implementing the cryptographic modules. Eavesdropping and Interference: IoT applications often consist of various nodes deployed in open environments [25]. As a result, such IoT applications are exposed to eavesdroppers. The attackers may eavesdrop and capture the data during different phases like data transmission or authentication. Sleep Deprivation Attacks: In such type of attacks the adversaries try to drain the battery of the low-powered IoT edge devices. This leads to a denial of service from the nodes in the IoT application due to a dead battery. This can be done by running infinite loops in the edge devices using malicious code or by artificially increasing the power consumption of the edge devices. Booting Attacks: The edge devices are vulnerable to various attacks during the boot process. This is because the inbuilt security processes are not enabled at that point. The attackers may take advantage of this vulnerability and try to attack the node devices when they are being restarted. As edge devices are typically low powered and at times go through sleep-wake cycles, it is thus essential to secure the boot process in these devices. B. Security Issues at Network Layer The key function of the network layer is transmitting the information received from the sensing layer to the computational unit for processing. The major security issues that are encountered at the network layer are as follows. Phishing Site Attack: Phishing attacks often refer to attacks where several IoT devices can be targeted by a minimal effort put by the attacker. The attackers expect that at least few of the devices will become a victim of the attack. There is a possibility of encountering phishing sites in the course of users visiting web pages on the Internet. Once the user’s account and password are compromised, the whole IoT environment being used by the user becomes vulnerable to cyber attacks. The network layer in IoT is highly vulnerable to phishing sites attacks [26]. Access Attack: Access attack is also referred to as advanced persistent threat (APT). This is a type of attack in which an unauthorized person or an adversary gains access to the IoT network. The attacker can continue to stay in the network undetected for a long duration. The purpose or intention of this kind of attack is to steal valuable data or information, rather than to cause damage to the network. IoT applications continuously receive and transfer valuable data and are therefore highly vulnerable to such attacks [27]. DDoS/DoS Attack: In this kind of attacks, the attacker floods the target servers with a large number of unwanted requests. This incapacitates the target server, thereby disrupting services to genuine users. If there are multiple sources used by the attacker to flood the target server, then such an attack is termed as DDoS or distributed denial of service attack. Such attacks are not specific to IoT applications, but due to the heterogeneity and complexity of IoT networks, the network layer of the IoT is prone to such attacks. Many IoT devices in IoT applications are not strongly configured, and thus become easy gateways for attackers to launch DDoS attacks on the target servers. The Mirai botnet attack as discussed in Section I used this vulnerability and blocked various servers by constantly propagating requests to the weakly configured IoT devices [28]. Data Transit Attacks: IoT applications deal with a lot of data storage and exchange. Data is valuable, and therefore it is always the target of hackers and other adversaries. Data that is stored in the local servers or the cloud has a security risk, but the data that is in transit or is moving from one location to another is even more vulnerable to cyber attacks. In IoT applications, there is a lot of data movement between sensors, actuators, cloud, etc. Different connection technologies are used in such data movements, and therefore IoT applications are susceptible to data breaches. Routing Attacks: In such attacks, malicious nodes in an IoT application may try to redirect the routing paths during data transit. Sinkhole attacks are a specific kind of routing attack in which an adversary advertises an artificial shortest routing path and attracts nodes to route traffic through it. A worm-hole attack is another attack which can become serious security threat if combined with other attacks such as sinkhole attacks. A warm-hole is an out of band connection between two nodes for fast packet transfer. An attacker can create a warm-hole between a compromised node and a device on the internet and try to bypass the basic security protocols in an IoT application. C. Security Issues at Middleware Layer The role of the middleware in IoT is to create an abstraction layer between the network layer and the application layer. Middleware can also provide powerful computing and storage capabilities [29]. This layer provides APIs to fulfill the demands of the application layer. Middleware layer includes brokers, persistent data stores, queuing systems, machine learning, etc. Although the middleware layer is useful to provide a reliable and robust IoT application, it is also susceptible to various attacks. These attacks can take control of the entire IoT application by infecting the middleware. Database security and cloud security are other main security challenges in the middleware layer. Various possible attacks in the middleware layer are discussed as follows. Man-in-the-Middle Attack: The MQTT protocol uses publish-subscribe model of communication between clients and subscribers using the MQTT broker, which effectively acts as a proxy. This helps in decoupling the publishing and the subscribing clients from each other and messages can be sent without the knowledge of the destination. If the attacker can control the broker and become a man-in-the-middle, then he/she can get complete control of all communication without any knowledge of the clients. SQL Injection Attack: MIddleware is also susceptible to SQL Injection (SQLi) attacks. In such attacks, attacker can embed malicious SQL statements in a program [30], [31]. Then, the attackers can obtain private data of any user and can even alter records in the database [32]. Open Web Application Security Project (OWASP) has listed SQLi as a top threat to web security in their OWASP top 10 2018 document [33]. Signature Wrapping Attack: In the web services used in the middleware, XML signatures are used [34]. In a signature wrapping attack, the attacker breaks the signature algorithm and can execute operations or modify eavesdropped message by exploiting vulnerabilities in SOAP (Simple Object Access Protocol) [35]. Cloud Malware Injection: In cloud malware injection, the attacker can obtain control, inject malicious code or can inject a virtual machine into the cloud. The attacker pretends to be a valid service by trying to create a virtual machine instance or a malicious service module. In this way, the attacker can obtain access to service requests of the victim’s service and can capture sensitive data which can be modified as per the instance. Flooding Attack in Cloud: This attack works almost the same as DoS attack in the cloud and affects the quality of service (QoS). For depleting cloud resources, the attackers continuously send multiple requests to a service. These attacks can have a big impact on cloud systems by increasing the load on the cloud servers. D. Security Issues at Gateways Gateway is a broad layer that has an important role in connecting multiple devices, people, things and cloud services. Gateways also help in providing hardware and software solutions for IoT devices. Gateways are used for decrypting and encrypting IoT data and translating protocols for communication between different layers [36]. IoT systems today are heterogeneous including LoraWan, ZigBee, Z-Wave and TCP/IP stacks with many gateways in between. Some of the security challenges for IoT gateway are discussed below. Secure On-boarding: When a new device or sensor is installed in an IoT system, it is imperative to protect encryption keys. Gateways act as an intermediary between the new devices and the managing services, and all the keys pass through the gateways. The gateways are susceptible to man-in-the-middle attacks and eavesdropping to capture the encryption keys, especially during the on-boarding process. Extra Interfaces: Minimizing the attack surface is an important strategy that needs to be kept in mind while installing the IoT devices [37]. Only the necessary interfaces and protocols should be implemented by an IoT gateway manufacturer. Some of the services and functionalities should be restricted for end-users to avoid backdoor authentication or information breach. End-to-End Encryption: True end-to-end application layer security is required to ensure the confidentiality of the data [38]. The application should not let anyone other than the unique recipient to decrypt the encrypted messages. Although Zigbee and Zwave protocols support encryption, this is not end-to-end encryption, because, in order to translate the information from one protocol to another, the gateways are required to decrypt and re-encrypt the messages. This decryption at the gateway level makes the data susceptible to data breaches. Firmware updates: Most IoT devices are resource constrained, and therefore they do not have an user interface or the computation power to download and install the firmware updates. Generally, gateways are used to download and apply the firmware updates. The current and new version of the firmware should be recorded, and validity of the signatures should be checked for secure firmware updates. E. Security Issues at Application Layer The application layer directly deals with and provides services to the end users. IoT applications like smart homes, smart meters, smart cities, smart grids, etc. lie in this layer. This layer has specific security issues that are not present in other layers, such as data theft and privacy issues. The security issues in this layer are also specific to different applications. Many IoT applications also consist of a sub-layer between the network layer and application layer, usually termed as an application support layer or middleware layer. The support layer supports various business services and helps in intelligent resource allocation and computation. Major security issues encountered by the application layer are discussed below. Data Thefts: IoT applications deal with lot of critical and private data. The data in transit is even more vulnerable to attacks than data at rest, and in IoT applications, there is a lot of data movement. The users will be reluctant to register their private data on IoT applications if these applications are vulnerable to data theft attacks. Data encryption, data isolation, user and network authentication, privacy management, etc. are some of the techniques and protocols being used to secure IoT applications against data thefts. Access Control Attacks: Access control is authorization mechanism that allows only legitimate users or processes to access the data or account. Access control attack is a critical attack in IoT applications because once the access is compromised, then the complete IoT application becomes vulnerable to attacks. Service Interruption Attacks: These attacks are also referred to as illegal interruption attacks or DDoS attacks in existing literature. There have been various instances of such attacks on IoT applications. Such attacks deprive legitimate users from using the services of IoT applications by artificially making the servers or network too busy to respond. Malicious Code Injection Attacks: Attackers generally go for the easiest or simplest method they can use to break into a system or network. If the system is vulnerable to malicious scripts and misdirections due to insufficient code checks, then that would be the first entry point that an attacker would choose. Generally, attackers use XSS (cross-site scripting) to inject some malicious script into an otherwise trusted website. A successful XSS attack can result in the hijacking of an IoT account and can paralyze the IoT system. Sniffing Attacks: The attackers may use sniffer applications to monitor the network traffic in IoT applications. This may allow the attacker to gain access to confidential user data if there are not enough security protocols implemented to prevent it [39]. Reprogram Attacks: If the programming process is not protected, then the attackers can try to reprogram the IoT objects remotely. This may lead to the hijacking of the IoT network [40]. SECTION IV. Improvements and Enhancements Required for Upcoming IoT Applications Personal computers (PC) and smartphones have a number of security features built into them, e.g., firewalls, anti-virus softwares, address space randomization, etc. These safety shields are, in general, missing in various IoT devices that are already in the market. There are various security challenges that the IoT applications are facing currently. A well-defined framework and standard for an end-to-end IoT application is not yet available. An IoT application is not a standalone application, and it is an assembled product which includes work from many individuals and industries. At every layer starting from sensing to the application, several diverse products and technologies are being used. These include a large number of sensors and actuators at the edge nodes. There are multiple communication standards like cellular network, WiFi, IEEE 802.15.4, Insteon, dash7, Bluetooth, etc. A handshake mechanism is required between all these standards. Apart from this, various connectivity technologies are being used at different levels in the same IoT application like Zigbee, 6LOWPAN, wireless HART, Z-Wave, ISA100, Bluetooth, NFC, RFID, etc. Over and above this, the generic HTTP protocol cannot be used in the application layer. HTTP is not suitable for resource-constrained environments because it is heavy-weight and thus incurs a large parsing overhead. Therefore, at the application layer also there are many alternate protocols that have been deployed for IoT environments. Some of them are MQTT, SMQTT, CoAP, XMPP, AMQP, M3DA, JavascriptIoT, etc. Due to the intense diversity of protocols, technologies, and devices in an IoT application, the significant trade-offs are between cost effectiveness, security, reliability, privacy, coverage, latency, etc. If one metric for improvement is optimized, it may result in the degradation of other metric. For example, imposing too many security checks and protocols in all data transactions in IoT applications may end up increasing the cost and latency of the application, thereby, making it unsuitable for the users. A typical IoT application consists of a big chain of connected devices, technologies, domains, and geographies. Even if one of the device or technology or their combination is left weak, then that may be the cause of a security threat for the entire application. The chain is considered to be as strong as the weakest link. There has been a large increase in the number of weak links in IoT applications recently. For example, even basic IoT applications such as smart bulbs and smart door locks can be used as a weak link in a smart home IoT application to extract the user’s WiFi password [41] and [42]. The large number of IoT devices being deployed around the world to make it smart generates a large amount of environment and user-related data. A lot of private information can be inferred from this data, and that can be another cause of threat for an individual and society at large [7]. As a result, significant improvements and enhancements in the current IoT application structure and framework are required to make it reliable, secure and robust. In this regard: Rigorous penetration testing for IoT devices is necessary to quantify the level of risk involved in deploying these devices in different applications. Based on the risk involved, a priority list can be made and the devices can be deployed appropriately in different applications. Encryption techniques are being used in IoT system at different layers and protocols. However, there are various levels of encrypt, decrypt, and re-encrypt cycles in the complete system. These cycles make the system vulnerable to attacks. End to end encryption would be a promising solution to prevent different attacks. Authenticate-always protocols need to be implemented. Whenever a device wants to interact with another device, an authentication process should be implemented. Digital certificates can be a promising solution to provide seamless authentication with bound identities that are tied to cryptographic protocols. Any IoT security framework being implemented should be tested and confirmed for scalability. The security protocols should not be working only for a limited set of users. The real threats start coming only when the application becomes public and starts being used widely in the public domain. Therefore, proper strategy and planning are required. A mechanism based on encryption techniques like RSA, SHA256, or hash chains is required to secure the user and environment data from being captured. IoT devices need to be designed in a way that they can transmit the sensed data in a secure and encrypted way. This will help in gaining the trust of the individuals, government agencies and industries in IoT applications. Since the IoT devices and applications are growing rapidly, an approach needs to be designed to handle the cost and capacity constraints that are expected to be encountered shortly. A paradigm shift from a centralized approach to some decentralized approach might be needed, where devices can automatically and securely communicate with each other. This can help in reducing the cost of managing the applications and can reduce the issues of capacity constraints [43]. Since most of the IoT applications use cloud services for data storage and retrieval, the risks caused by the cloud should also be considered. Cloud is a public platform used by multiple users and there may be malicious users on the cloud who can be the cause of threat for IoT related data. The data should be stored as ciphertext in the cloud and the cloud should not be allowed to decrypt any ciphertext. This can further enhance data security and can save us from the generic risks of using cloud services [44]. Apart from the challenges from outside entities, there are various scenarios where the sensors in an IoT application start collecting or sending erroneous data. These errors might be easy to handle in case of a centralized architecture but can become a bottleneck in case of an autonomous decentralized architecture. Faulty reading or transmitting of data can lead to undesirable results. Thus, mechanism needs to be identified to validate the data flow, especially in case of a distributed architecture [45]. Since the ultimate goal of all IoT applications is to create an autonomous system that needs minimum human interventions, the use of some artificial intelligence (AI) based techniques or algorithms to secure IoT devices might be useful. This can help in reducing the analysis and communication load on IoT environment [46]. There are various techniques and approaches in the existing literature for securing IoT environments and applications. These solutions may be divided into four categories: (1) blockchain based solutions; (2) fog computing based solutions; (3) machine learning based solutions and (4) edge computing based solutions. Figure 4 shows various works in different domains that have used the above-mentioned solutions for securing the IoT environments [47]–[97]. In the following sections, these solutions are described in detail. FIGURE 4. Research papers addressing IoT security using various security techniques. Show All SECTION V. IoT Security Using Blockchain Blockchain and IoT are important technologies that will have a high impact on the IT and communication industry. These two technologies focus on improving the overall transparency, visibility, level of comfort and level of trust for the users. The IoT devices provide real-time data from sensors and blockchain provides the key for data security using a distributed, decentralized and shared ledger [108]. The basic idea behind the blockchain is simple: it is a distributed ledger (also called replicated log files). The entries in the blockchain are chronological and time-stamped. Each entry in the ledger is tightly coupled with the previous entry using cryptographic hash keys. A Merkle tree is used to store the individual transactions and the root hash of the tree is stored in the blockchain. In the figure, T1,T2,T3,⋯,Tn represent the individual transactions. The transactions are cryptographically hashed and stored on the leaf nodes of the tree as Ha,Hb,Hc and so on. The hash of the child nodes are concatenated and a new root hash is generated. The final root hash (e.g., H1 and H2 ) is stored on the blockchain. Just the root hash can be verified in order to make sure that all the transactions associated with that root hash are secure and have not been tampered with. Even if a single transaction is changed, all the hash values on that particular side of the tree will change. The ledger maintainer or the miner verifies the logs or transactions and generates a key that enables the latest transaction to become the part of complete ledger. This process makes the latest entries available to all the nodes in the network. Due to the presence of cryptographic hash keys in each block, it is too time-consuming and difficult for the adversaries to tamper with the blocks [109]. The miners do not have any personal interest in the transactions, and they are mining just to earn their incentives. The miners do not know the identity of the owners of the transactions. Over and above, there are multiple miners working on the same set of transactions, and there is a strong competition between them to add the transactions to the blockchain. All these unique features empower the blockchain to be a strong, tamper-proof, distributed and open data structure for IoT data [110]. Figure 5 shows the complete flow of a transaction from being initialized to being committed to the distributed chain. There are various platforms and frameworks being developed in academia and industry that support the creation and maintenance of blockchain. Some examples of such platforms are Ethereum, Hyperledger fabric, Ripple, etc. [111]. FIGURE 5. Working process of blockchain. Show All A. Permissioned and Permission-Less Blockchain There are two types of blockchain architectures based on the type of data being added and the nature of application using blockchain. In permission-less blockchain, there is no specific permission required for a user to become the part of the blockchain network or to become a miner. Anyone can join or leave this network of permission-less blockchain. The best example of permission-less blockchains is Bitcoin. Although the throughput of transactions is not very high, the permission-less blockchains can support a large number of nodes in the network. On the other hand, the permissioned blockchains have a defined set of rules to participate in the blockchain network. The miners are also the authorized persons and the blocks are allowed to be added to the chain only after their validation. The blockchain of Ripple and Hyperledger are two prime examples of permissioned blockchain. The permissioned concept of blockchain improves the overall throughput of transactions as compared to permission-less blockchains. Figure 6 shows the sample architecture of a blockchain and the way every block is connected to all the previous blocks based on cryptographic hashing. FIGURE 6. Basic blockchain architecture. Show All B. Benefits of Blockchain in IoT The usage of blockchain has many advantages in IoT applications. Table 4 gives a summary of some specific challenges in IoT security and their possible solutions using blockchain. Various security issues faced by IoT applications have already been discussed in Section III. The key benefits of using blockchain in IoT applications are discussed below. Data coming from IoT devices can be stored in Blockchain: The IoT applications include a large variety of devices connected to each other. These devices are further connected and controlled by other devices. This setup is further connected to the cloud to enable IoT applications to be used from any location. Due to this large space for data movement, blockchain is a promising solution to store the data and prevent it from being misused. Irrespective of the layer in an IoT application, blockchain can act as a suitable solution to store and transmit data. Distributed nature of blockchain allowing secure data storage: Since the blockchain architecture is distributed in nature, it can avoid the risk of being a single point of failure as is faced by various IoT applications based on the cloud. Irrespective of the distance between the devices, the data generated by them can be easily stored on the blockchain in a secure manner [112]. Data encryption using the hash key and verified by miners: In blockchain, only the 256-bit hash key for the data can be stored, rather than storing the actual data. The actual data can be stored on the cloud and the hash key can be mapped with the original data. If there is any change in the data, the hash of the data will change. This makes the data secure and private. The size of blockchain will also not get affected by the size of the data as only the hash values are stored in the chain. Only the intended parties, who are authorized to use that data can access the data from the cloud using the hash of the data. Every set of data being stored on blockchain is properly verified by different miners in the network, and therefore the probability of storing corrupt data from the devices reduces by using blockchain as a solution. Prevention from data loss and spoofing attacks: In spoofing attacks on IoT applications, a new adversary node enters into the IoT network and starts imitating to be the part of the original network. By spoofing, the adversary can easily capture, observe or inject data in the network. Blockchain acts as a promising solution to prevent such attacks. Each legitimate user or device is registered on blockchain, and devices can easily identify and authenticate each other without the need for central brokers or certification authorities [113]. Being low powered in nature, IoT devices inherit the risk of losing data. There might be cases where due to some external environmental issues the data is lost by both the sender and the receiver. Use of blockchain can prevent such losses as once the block is added in the chain there is no way to remove it [114]. Blockchain to prevent unauthorized access: Many IoT applications involve a lot of frequent communication between various nodes. The communication in blockchain takes place using the public and private keys, and therefore only the intended party or node can access the data. Even if the unintended party is able to access the data, the contents of the data will be incomprehensible as the data is encrypted with keys. Therefore, the blockchain data structure tries to handle various security issues faced by IoT applications. Proxy-based architecture in blockchain for resource-constrained devices: Although blockchain provides various security features for a distributed environment, IoT has a specific challenge of resource constraints. Being highly resource-constrained, IoT devices cannot store large ledgers. There have been various works in this direction to facilitate the use of blockchain in IoT. Proxy-based architecture is one of the promising solutions that can help IoT devices to use blockchain. Proxy servers can be deployed in the network, to store the resources in an encrypted form. The encrypted resources can be downloaded by the client from the proxy servers [115]. Elimination of centralized cloud servers: Blockchain can enhance the security of IoT systems because it ultimately eliminates the centralized cloud servers and makes the network peer-to-peer. Centralized cloud servers are the prime target of the data thieves. Using blockchain, the data will be distributed among all the nodes of the network and will be encrypted using a cryptographic hash function. TABLE 4 Challenges in IoT and Possible Blockchain Solution C. Merkle Tree Merkle tree is an add-on that can be added to the blockchain data structure to enhance the security of IoT devices. This can also help in reducing the overall number of blocks being added in the chain. A Merkle tree is like a binary tree where every node contains two child nodes except the leaf nodes. The leaf nodes contain the data or transactions, and the roots are the hash values of the data on the leaf nodes [116]. Based on the size of the tree, multiple transactions can be combined to generate a single root hash. Rather than treating each transaction as a block, each root hash can be considered as a block in the chain. This can help us in reducing the number of blocks. Also, due to multiple levels of hashing, at every level in the tree, the security of the data is enhanced [117]. IoT devices involve a lot of small communications among each other and therefore using Merkle tree along with blockchain can be a promising solution [118]. D. IOTA IOTA is another upcoming and highly promising solution to secure IoT. IOTA is also a DLT (Distributed Ledger Technology) as blockchain. IOTA is specially designed for resource-constrained IoT devices. Every incoming request in the network is required to validate the previous two requests. Using this process of cumulative validations, IOTA can provide a high level of security at the device or edge level. The tip selection algorithm is used for request verification. A cumulative weight is created for all requests. Higher the weight of a device in the network, more secure the device is. IOTA uses a tangle data structure as compared to the chain data structure in blockchain [119]. SECTION VI. IoT Security Using Fog Computing A. Evolution of Fog From Cloud IoT and cloud computing are two independent technologies which have many applications. IoT has provided users with a large number of smart devices and applications. Similarly, a cloud provides a very effective solution to store and manage data which can be accessed from anywhere and is widely used by many organizations. IoT is generating an unprecedented amount of data, which puts a lot of strain on the Internet infrastructure. The integration of cloud and IoT has introduced an era of new opportunities and challenges for processing, storing, managing and securing data more effectively. Industry and research groups have tried to solve some issues faced by the IoT by integrating it with the cloud. The benefits of this integration are not enough to address all the issues faced by IoT. Therefore, the concept of fog computing was introduced by Cisco in 2012. Fog computing complements cloud computing rather than replacing it. B. Fog Computing Architecture The main task of fog computing is to handle the data generated by IoT devices locally for better management and thus requires an architecture consisting of different layers. It has two frameworks that are Fog-Device framework and Fog-Cloud-Device framework [120]. The former framework consists of device and fog layer and the latter framework consists of device, fog and cloud layer. The arrangement of layers is done based on their storing and computational powers. The communication between different layers is done using wired (e.g., optical fiber, Ethernet) or wireless communication (e.g., WiFi, Bluetooth, etc.). In Fog-Device framework, the fog nodes provide various services to a user without involving cloud servers. However, in Fog-Cloud-Device framework the simple decisions are taken at the fog layer, whereas, the complex decisions are taken on cloud [121]. The architecture of Fog-Cloud-Device framework is shown in Figure 7. The authors of [122] have considered the fog computing architecture theoretically and mathematically while comparing the performance of fog computing paradigm with traditional cloud computing framework based on service latency and energy consumption. Fog computing reduces the data traffic between cloud and network edge by 90% and average response time for a user by 20% when compared with cloud-only model [123]. Authors in [124] have discussed the definition and concept of fog computing in-depth, comparing it with similar concepts such as mobile-edge computing (MEC) and mobile cloud computing (MCC). Authors in [124] have also introduced some applications like real-time video analytics and augmented reality (AR), mobile big data analytics, and content delivery and caching for fog computing. FIGURE 7. Fog computing architecture. Show All C. Advantages of Fog Over Cloud IoT devices generate large volumes of data every day. Moving this data to the cloud in real-time for analysis is not feasible. Therefore, the concept of fog computing has been developed. Figure 7 shows the placement and functionality of fog layer in an IoT application. Fog computing refers to extending cloud computing and its services to the edge of the network. Fog computing is a decentralized infrastructure for analysis of data and computing and can be used to store and process time-sensitive data efficiently and quickly. Its main goal is to enhance security, prevent data thefts, minimize the data stored on the cloud and to increase the overall efficiency of IoT applications. The latency in fog computation is less than cloud computation because the fog layer is placed much closer to the devices than the cloud. Only the selected and important data is sent to the cloud for long-term storage. Fog computing applications include smart vehicles, smart homes, smart agriculture, health-care, smart traffic lights, smart retail, software-defined networks, etc. Sending the immense amount of data generated by IoT devices to the cloud for processing and analyzing would be costly and time-consuming. Along with minimizing network bandwidth requirements, fog computing also reduces the frequency of two-way communication between IoT devices and the cloud [125]. In fog architecture, the data is collected at devices called fog nodes which can analyze 40 percent of it [126]. It offloads traffic from the core network minimizing the latency of IoT devices. A fog node can be any device like a router, switch, or a video surveillance camera which has computing, storage, and network connectivity. These fog nodes can be installed anywhere like on a factory floor or in a vehicle, provided it has a network connection. Data is directed to the fog node, aggregation node or cloud based on its time-sensitivity. Fog nodes make the communication in IoT application secure by providing cryptographic computations. Mere sensors and IoT devices do not always have the necessary inbuilt resources for that purpose [127]. D. Solutions Provided by Fog Computing to Overcome IoT Security Threats In regard to the attacks discussed in Section III, the solution that fog computing provides or can provide to overcome those security threats are discussed below. Man-in-the-middle attack: Fog acts as a security layer between end-user and cloud or IoT system. All threats or attacks on the IoT systems need to pass through the fog layer in between, and this layer can identify and mitigate unusual activities before they are passed to the system. Data transit attacks: Data storage and management is much better if performed on the secure fog nodes, as compared to the IoT devices. Data will be better protected if it is stored on the fog nodes as compared to storing the data on the end-user devices. Fog nodes also help in making the user data more available. Eavesdropping: Using fog nodes, the communication takes place between the end-user and the fog node only, rather than routing the information through the entire network. The chances of an adversary trying to eavesdrop reduces a lot because the traffic on the network is reduced. Resource-constraint issues: Most of the IoT devices are resource constrained and the attackers take advantage of this fact. They try to damage the edge devices and use them as the weak links to enter the system. Fog nodes can support the edge devices and can prevent them from being affected by such attacks. A nearby fog node can perform the more sophisticated security functions necessary for protection. Incident response services: Fog nodes can be programmed to provide real-time incident response services. Fog nodes can generate a flag to the IoT system or the end users as soon as they encounter a suspicious data or request. Fog computing allows for malware detection and problem resolution in transit. In many critical applications, it might not be possible to stop the entire system to resolve malware incidences. Fog nodes can help in such resolutions while the system is up and running. E. Security Challenges and Solutions in Fog Layer Although fog layer provides various features and security aspects for IoT applications, the movement of data and computation to fog layer creates new vulnerabilities [120]. Therefore, before implementing fog-assisted IoT applications, these security and privacy goals of fog computing are required to be studied. In this section, various features provided by fog layer, privacy and security challenges faced, and proposed solutions to overcome them are discussed. Table 5 summarizes these issues and proposed solutions. Real-Time Services: Fog computing tends to provide a near real-time service in the IoT systems by performing computation near the data generation points. Intrusion detection: Policy violations and malicious activities on fog nodes and IoT devices will not be discovered if no proper intrusion detection mechanism is implemented. The attacks might not impact the whole architecture of fog computing, but the attacker can control the local services. Attacks targeting local services can be detected by fog nodes by collaborating with their adjacent nodes. By observing program behavior and host file systems, the attack on the cloud can be detected [163]. Identity authentication: There are various entities involved in the process of offering and accessing real-time services like fog nodes, service providers and users. Trusting all the entities involved is an arduous task, and creates security challenges for IoT services and user’s data. Accessibility of services should be given only to authentic and credible users; otherwise, attackers may compromise the server and exploit services and user privacy. Therefore, to prevent attackers from illegitimately accessing services, identity authentication mechanisms are needed. To provide secure services, some efficient identity authentication mechanisms have been proposed in the past [146]–[149], [164], [165]. Transient Storage: Users can store and maintain their data on fog nodes temporarily with the help of transient storage. On the one hand, it helps in managing data easily on local storage, but on the other hand, it creates new challenges and security issues, especially for maintaining data privacy. Identifying and protecting sensitive data: Data stored in IoT devices may include social events, traffic conditions, personal activities, temperature and so on. Some of the data might be personal or sensitive while some data may be made public. Furthermore, for different users, the same data has different security levels. Therefore, it is important to identify and protect the sensitive data from the large volume of information. Sharing data securely: To provide security, data uploaded on fog nodes is first encrypted. No one other than its owner can read that data once it is encrypted. This creates a problem for data sharing. To overcome this challenge, some cryptographic techniques such as key-aggregate encryption, proxy re-encryption, and attribute-sharing, have been proposed in [166]. Data Dissemination: The data cannot be transferred to the fog node without encryption, due to security issues. Due to this movement of encrypted data to the fog node, many desirable features are sacrificed such as sharing, searching, and aggregation. Searching data securely: As discussed in transient storage, data is encrypted before uploading. However, once it is encrypted, searching or retrieving on the ciphertext becomes difficult for owners as well as other entities. In order to retrieve the information from encrypted text, search-able encryption and its privacy levels are defined in [145]. A dynamic symmetric search-able scheme is introduced in [167]. Data aggregation: Fog nodes might need to aggregate the data in certain cases to prevent data leakage and reduce communication overhead. It is important to develop secure aggregation algorithms to prevent data thefts. Various homomorphic encryption schemes, such as BGN encryption [168] and Paillier encryption [169], have been proposed to achieve secure data aggregation. Decentralized Computation: The data stored on the fog nodes can be processed and analyzed for better results. However, such computations have several threats and risks associated with them. For example, attackers can not only control the analyzed results, but can also expose processed data. Server-aided computation: Tasks which cannot be executed by IoT devices themselves are computed with the help of fog nodes. However, this can lead to exposure of data to attackers, if the fog nodes which received data from IoT are already compromised. Server-aided computation is one such method whose aim is to provide secure computation [131]. Verifiable computation: Users rely on the fog nodes to compute their data. There must be a secure mechanism to verify the computation results coming from the fog node. Authors in [170], [171] have proposed certain multi-user mechanisms that help with verifiable computation. TABLE 5 Characteristics and Solutions Provided by Fog Computing SECTION VII. IoT Security Using Machine Learning The area of machine learning (ML) has attracted significant interest over recent years. Many domains are using ML for their development, and it is being used for IoT security as well. ML appears to be a promising solution to protect IoT devices against cyber attacks by providing a different approach for defending against attacks as compared to other traditional methods. A. Solutions Provided by ML to Overcome Security Threats In regard to the attacks discussed in Section III, the solutions provided by ML to overcome these security threats are discussed below. DoS Attack: DoS attacks on IoT devices or originating from IoT devices are a serious concern. One approach to prevent such attacks is to use a Multi-Layer Perceptron (MLP) based protocol that secures networks against DoS attacks [172]. The authors of [173] have proposed a particle swarm optimization and back propagation algorithm to train a MLP that helps in enhancing the security of wireless networks. ML techniques help in increasing the deduction accuracy and securing IoT devices vulnerable to DoS attacks. Eavesdropping: Attackers may eavesdrop on messages during data transmission. To provide protection from such attacks, ML techniques such as Q-learning based offloading strategy [174] or non-parametric Bayesian techniques [175] can be used. Schemes such as Q-learning and Dyna-Q are ML techniques that may also be used to protect devices from eavesdropping. Evaluation of these schemes via experiments and reinforcement learning is presented in [176]. Spoofing: Attacks from spoofers can be avoided by using Q-learning [176], Dyna-Q [176], Support Vector Machines (SVM) [177], Deep Neural Network (DNN) model [178], incremental aggregated gradient (IAG) [46], and distributed FrankWolfe (dFW) [179] techniques. These techniques not only increase the detection accuracy and classification accuracy but also help in reducing the average error rate and false alarm rate. Privacy Leakage: Collection of personal information such as health data, location, or photos puts the user’s privacy at stake. Privacy-preserving scientific computations (PPSC) [180] should be employed for preventing privacy leakage. A commodity integrity detection algorithm (CIDA) which is based on the Chinese remainder theorem (CRT) is another technique that has been proposed to develop IoT application trust [181]. Digital Fingerprinting: Digital fingerprinting is one of the upcoming and promising solutions to secure IoT systems and to help the end users gain sufficient trust in the applications. Fingerprints are being widely used to unlock smartphones, approve payments, unlock the car and home doors, etc. Due to its low cost, reliability, acceptability and high-security level, digital fingerprinting is emerging as a dominant bio-metric identification method [182]. Apart from the benefits of digital fingerprinting, there are various challenges to efficiently use this technique in IoT, such as fingerprint classification, image enhancement, feature matching, etc. Various machine learning based algorithms have been developed to provide some non-traditional solutions to overcome these challenges [183], some of which are discussed below. Support Vector Machine: SVM is a training algorithm for non-linear and linear classifications, principal component analysis, text categorization, speaker identification, and regression. It maximizes the gap between the decision boundary and training patterns. Authors of [184] have discussed the use of SVM in digital fingerprinting in detail. They have also compared it with other traditional models. A feature vector is built based on pixel values of the fingerprint, and it is used to train the SVM. Various patterns behind the fingerprint are analyzed, and then the matching of a fingerprint is done based on patterns identified. Artificial Neural Networks: ANN is one of the most commonly used algorithms in the machine learning. It offers many advantages like fault tolerance, adaptive learning, and generalization. In [185] a framework has been proposed for using ANN to identify fingerprints digitally. The digital values of various features in the fingerprint like minutiae, ridge ending, and bifurcation is applied as the input to the neural network for training purpose using back propagation algorithm of ANN. The verification of the fingerprint is done based on the previous experiential values stored in the database. The fundamental need in IoT is to secure all the systems and devices that are connected to the network. The role of ML is to use and train algorithms to detect anomalies in IoT devices or to detect any unwanted activity taking place in IoT system to prevent data loss or other issues. Therefore, ML provides a promising platform to overcome the difficulties faced in securing IoT devices. Further contributions in this field are required to maintain the growth of IoT. SECTION VIII. IoT Security Using Edge Computing Edge and fog computing are both extensions of cloud computing which is widely used by various organizations. Cloud, fog and edge may appear similar but they constitute different layers of IoT applications. The main difference between cloud, fog and edge computing is the location of intelligence and power computation. The cloud is deployed at a much larger scale that needs to process huge amount of data and is situated at comparatively more distance from its users [186]. To overcome the problems faced by cloud computing, edge computing is used as a solution where a small edge server is placed between the user and the cloud/fog. Some processing activity is performed at the edge server, rather than the cloud. Edge computing architecture consists of edge devices, cloud server and fog nodes as shown in Figure 8 [187]. FIGURE 8. Edge computing architecture. Show All In an edge computing framework the computation and analysis power is provided at the edge itself. The devices in an application can create a network among themselves and can cooperate among each other to compute the data [63]. Consequently, a lot of data can be saved from going outside the device, either to cloud or to fog nodes, and this can enhance the security of the IoT application. Edge computing also helps in providing low communication cost by preventing the need of moving all the data to the cloud [66]. A. Using Edge Computing to Secure and Improve IoT In regard to the attacks discussed in Section III, the solutions that edge computing provides or can provide to overcome these security threats are discussed below. Data Breaches: In edge computing, all the data is stored and processed within the device or local network. There is no movement of the data from the data originator to the processor. This prevents the data from being in transit and thereby prevents the risk of data thefts and data breaches. In fog computing there is some movement of data from a device to fog layer and adversaries can take advantage of this movement [188]. Data Compliance Issues: Many countries have strict regulatory acts to prevent data movement outside their boundaries, e.g., European Union’s GDPR (General Data Protection Regulation). Using edge computing, organizations can keep the data within their borders and ensure compliance with data sovereignity laws [189]. Safety Issues: With the increase in the deployment of cyber-physical systems, security and safety are considered as integral issues. If there is even a little delay in responses, then that may lead to physical safety issues. For example, if the sensors in a car predict that a crash is about to happen, then the airbags have to be deployed immediately. If the sensors completely rely on sending all the data to the cloud and waiting for the response from the cloud to perform any action, then that may be too late to prevent injuries or loss of life. Surveillance cameras can also be empowered using edge computing and they can themselves analyze the anomalies and can send the summarized and suspected data to the data centers to achieve faster response times. Bandwidth Issues: IoT application generate a lot of data at very high rate. Most of this data is raw and of relatively low-value. Sending all the data to the cloud involves a lot of bandwidth cost as well, along with the security challenges of data movement. If edge computing is used, then a lot of data cleaning and aggregation can be done at the edge nodes and only the summarized data, if required, needs to be sent to the cloud [190]. B. Challenges in Edge Layer Although edge computing provides various features to increase the security and performance of IoT applications, there are various challenges associate with completely relying on the edge layer for all computation. Edge devices include sensors, RFID devices, actuators, tags, and embedded devices. The edge layer is highly susceptible to attacks in an IoT system. If the edge layer is compromised, then the entire system may be compromised. MQTT and COAP are the most popular protocols for the edge layer. Both these protocols do not use any security layer by default. Although the option to add an optional security layer in the form of TLS for MQTT and DTLS for COAP is present, it creates additional overhead in terms of processing and bandwidth. Issues specific to edge devices include sleep deprivation attacks, battery draining attacks, and outage attacks. Edge devices are typically resource constrained, and the most important resource they rely upon is the battery backup. The foremost and easiest way to attack the edge devices is to somehow deplete the battery of an edge device. For example, an attacker might force the edge device to do some power hungry or infinite loop computation [191]. The process of striking a balance between storing and processing data on edge or cloud is very important. Keeping too much data on edge may also lead to overwhelming of the edge devices and may impact the entire application. SECTION IX. Open Issues, Challenges, and Future Research Directions There are some performance and security issues in the use of blockchain, fog computing, edge computing and machine learning for IoT security that are yet to be solved. This section discusses some of these issues. The security of blockchain depends on its method of implementation and the use of software and hardware in that implementation. Since all the transactions made by users in blockchain are public, there is a possibility that private information of users can be revealed. Also, as the number of miners increases, the size of blockchain also increases continuously. This increases the cost of storage and reduces the speed of distribution over the whole network, giving rise to issues like scalability and availability of blockchain [192]. Since fog computing is a nontrivial extension of cloud computing, some of the issues such as security and privacy will continue to persist [120]. Therefore, before implementing fog-assisted IoT applications, these security and privacy goals of fog computing are required to be studied. Some of the challenges and research issues on security and privacy in IoT environments and the solutions provided by fog computing are discussed in [127]. There are many machine learning algorithms in existence. Therefore, it is imperative to select a proper algorithm suitable for the application. Selecting a wrong algorithm would result in producing “garbage” output and will lead to loss of effort, effectiveness and accuracy. Similarly, choosing the wrong data set will lead to “garbage” input producing incorrect results. The success of a machine learning solution depends on these factors as well as diversity in selecting data. If the data is not clustered and classified, the prediction accuracy will be lower. Also, the historical data may contain many ambiguous values, outliers, missing values, and meaningless data. IoT applications are creating a huge amount of data, and therefore it is a difficult task to clean and preprocess that data accurately. Various features like attribute creation, linear regression, multiple regression, removing redundancies and compressing data are required to effectively use machine learning for securing the IoT. In case of edge computing, data security and user privacy are the main concerns. An user’s private data can be leaked and misused if a house that is deployed with IoT devices is subjected to cyber attacks. For example, a person’s presence or absence at home can be revealed simply by observing the electricity or water usage data. Since the data is computed at the edge of data resource (e.g., home), therefore, the user has to be aware of some of the measures like securing WiFi connections. Secondly, data at edge should be owned fully by the user, and he/she should have control on which data to be shared. Some of the future research directions in this field are: The edge devices are most resource constrained devices in the IoT and are therefore uniquely vulnerable to attacks. Penetration studies show that while it takes very little power to implement best practice security for the edge nodes, they are still highly vulnerable to a variety of malicious attacks. The gateways between different layers in the IoT system need to be secured. Gateways provide an easy entry point for the attackers into the IoT system. End to end encryption, rather than specific encryption techniques for specific protocols would be a promising solution to secure the data passing through the gateways. The data should be decrypted only at the intended destination and not at the gateways for protocol translation. Inter-fog sharing of resources is one of the areas where further work needs to be done. As of now, when the fog layer is unable to process the requests due to heavy load, the requests are forwarded to the cloud. There can be resource sharing between neighboring fog layers to prevent unwanted requests to be transferred to the cloud. The current blockchain architecture is highly limited in terms of the number of nodes in permissioned networks and in terms of throughput in permissionless networks. Various consensus algorithms are being designed to support high throughput along with a large number of nodes or users. Fog layer can be made more intelligent using various ML and AI techniques. Fog layer must be able to decide the duration for which the data in the fog should be retained and when the data should be discarded or shifted to the cloud for prolonged storage. More efficient and reliable consensus mechanisms can be designed to reach consensus among the nodes along with preventing rampant use of computation power. The current consensus algorithms are highly resource hungry and less efficient. The tamper-proof feature of blockchain is ending up into a collection of a lot of garbage data and addresses. There is a lot of invalid data that is never deleted like the addresses of the destructed smart contracts. This affects the performance of the overall application and better ways need to be designed to efficiently handle the garbage data in the blockchain. Data analysis in near real-time and in the proximity of the IoT node is crucial for successful deployment of IoT applications. Various ML-based algorithms can be designed to analyze the data in the node itself to prevent the data transit for analysis. This can further enhance the security of the application by preventing data movement. SECTION X. Conclusion In this survey, we have presented various security threats at different layers of an IoT application. We have covered the issues related to the sensing layer, network layer, middleware layer, gateways, and application layer. We have also discussed the existing and upcoming solutions to IoT security threats including blockchain, fog computing, edge computing, and machine learning. Various open issues and issues that originate from the solution itself have also been discussed. The state-of-the-art of IoT security has also been discussed with some of the future research directions to enhance the security levels is IoT. This survey is expected to serve as a valuable resource for security enhancement for upcoming IoT applications. Authors Figures References Citations Keywords Metrics More Like This A Survey on Security and Privacy Issues in Edge-Computing-Assisted Internet of Things IEEE Internet of Things Journal Published: 2021 The Performance Evaluation of Blockchain-Based Security and Privacy Systems for the Internet of Things: A Tutorial IEEE Internet of Things Journal Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

Paper 2:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: {'extract_1': 'In recent years, with the aim of increasing agricultural production, new solutions and\ntechnologies have been introduced in the agriculture sector [24]. An emerging trend is the\napplication of the IoT and big data.', 'extract_2': 'In addition, we analyzed and discussed the beneﬁts and challenges, open issues,\ntrends, and opportunities of IoT in the smart agriculture sector.', 'relevance_score': 1.0}
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: The authors have conducted a survey to analyze the literature on the use of IoT solutions and technologies in smart agriculture. The survey aims to provide a comprehensive overview of the current state-of-the-art, challenges, and future directions in this field. 

The key points of the survey are as follows: 

1. **IoT Ecosystems for Smart Agriculture:** This section provides an overview of the IoT ecosystem architecture for smart agriculture, including the key components (IoT devices, communication technologies, and data analytics and storage solutions) and their interconnections. 

2. **IoT Applications in Smart Agriculture:** This section presents a detailed analysis of the various IoT applications in smart agriculture, categorized into four main areas: (a) monitoring, (b) tracking and traceability, (c) precision agriculture, and (d) greenhouse production. 

3. **Challenges and Open Research Directions:** This section discusses the challenges and open research directions related to the implementation of IoT in smart agriculture. These include economic efficiency and technical problems such as interference, security and privacy, and reliability. 

4. **Conclusion:** The survey concludes by summarizing the key findings and highlighting the potential of IoT to revolutionize smart agriculture while also emphasizing the need for further research and development to address the existing challenges.

 Full Text: >


Citation: Quy, V.K.; Hau, N.V.; Anh,
D.V.; Quy, N.M.; Ban, N.T.; Lanza, S.;
Randazzo, G.; Muzirafuti, A.
IoT-Enabled Smart Agriculture:
Architecture, Applications, and
Challenges. Appl. Sci. 2022, 12, 3396.
https://doi.org/10.3390/
app12073396
Academic Editor: Manuel Armada
Received: 7 March 2022
Accepted: 25 March 2022
Published: 27 March 2022
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright:
© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
applied  
sciences
Review
IoT-Enabled Smart Agriculture: Architecture, Applications,
and Challenges
Vu Khanh Quy 1
, Nguyen Van Hau 1
, Dang Van Anh 1, Nguyen Minh Quy 1
, Nguyen Tien Ban 2,
Stefania Lanza 3, Giovanni Randazzo 4 and Anselme Muzirafuti 4,*
1
Faculty of Information Technology, Hung Yen University of Technology and Education,
Hung Yen 160000, Vietnam; quyvk@utehy.edu.vn (V.K.Q.); haunv@utehy.edu.vn (N.V.H.);
dangvananh@utehy.edu.vn (D.V.A.); minhquy@utehy.edu.vn (N.M.Q.)
2
Faculty of Telecommunication 1, Posts and Telecommunications Institute of Technology,
Hanoi 100000, Vietnam; bannt@ptit.edu.vn
3
GeoloGIS s.r.l., Dipartimento di Scienze Matematiche e Informatiche, Scienze Fisiche e Scienze della Terra,
Università degli Studi di Messina, Via F. Stagno d’Alcontres, 31-98166 Messina, Italy; stefania.lanza@unime.it
4
Dipartimento di Scienze Matematiche e Informatiche, Scienze Fisiche e Scienze della Terra, Università degli
Studi di Messina, Via F. Stagno d’Alcontres, 31-98166 Messina, Italy; giovanni.randazzo@unime.it
*
Correspondence: anselme.muzirafuti@unime.it
Abstract: The growth of the global population coupled with a decline in natural resources, farmland,
and the increase in unpredictable environmental conditions leads to food security is becoming a major
concern for all nations worldwide. These problems are motivators that are driving the agricultural
industry to transition to smart agriculture with the application of the Internet of Things (IoT) and
big data solutions to improve operational efﬁciency and productivity. The IoT integrates a series
of existing state-of-the-art solutions and technologies, such as wireless sensor networks, cognitive
radio ad hoc networks, cloud computing, big data, and end-user applications. This study presents
a survey of IoT solutions and demonstrates how IoT can be integrated into the smart agriculture
sector. To achieve this objective, we discuss the vision of IoT-enabled smart agriculture ecosystems
by evaluating their architecture (IoT devices, communication technologies, big data storage, and
processing), their applications, and research timeline. In addition, we discuss trends and opportunities
of IoT applications for smart agriculture and also indicate the open issues and challenges of IoT
application in smart agriculture. We hope that the ﬁndings of this study will constitute important
guidelines in research and promotion of IoT solutions aiming to improve the productivity and quality
of the agriculture sector as well as facilitating the transition towards a future sustainable environment
with an agroecological approach.
Keywords: sustainable agriculture; food security; green technologies; Internet of Things; natural
resources; sustainable environment; IoT ecosystem
1. Introduction
In order to meet the current global needs of humanity, new solutions and technologies
are constantly being proposed and implemented. This has led to the advent of the Inter-
net of Things (IoT) [1,2]. IoT is deﬁned as the network of all objects that are embedded
within devices, sensors, machines, software and people through the Internet environment
to communicate, exchange information and interact in order to provide a comprehen-
sive solution between the real world and the virtual world [3]. In recent years, IoT has
been applied in a series of domains, such as smart homes [4,5], smart cities [6,7], smart
energy [8,9], autonomous vehicles [10,11], smart agriculture [12–15], campus manage-
ment [16,17], healthcare [18,19], and logistics [20,21]. Series of other IoT applications have
been described by Shaﬁque et al. [22]. An illustration of rich and diverse IoT applications
for smart agriculture is provided in Figure 1.
Appl. Sci. 2022, 12, 3396. https://doi.org/10.3390/app12073396
https://www.mdpi.com/journal/applsci
Appl. Sci. 2022, 12, 3396
2 of 19
In recent years, with the aim of increasing agricultural production, new solutions and 
technologies have been introduced in the agriculture sector [24]. An emerging trend is the 
application of the IoT and big data. A significant number of studies have been focused on 
research, experiments, and applications [25,26]. According to the Cisco forecast, over 500 
billion IoT devices will be connected to the Internet by 2030 [27]. The use of IoT and big 
data will enable smart agriculture and is expected to enhance efficiency and productivity 
[28]. 
 
Figure 1. An illustration of IoT applications for smart agriculture. 
Over the years, wireless sensor networks (WSN) have been strongly applied in the 
agricultural sector, building the foundation for developing smart agriculture [29]. The 
unique characteristics of WSN, such as the ability to self-organize, self-configure, self-es-
tablish, and self-recover, make it suitable for smart agriculture [30]. The sensor device 
consists of a radio frequency (RF) transceiver, sensor, microcontroller, and battery power 
[31]. The WSN focuses on applications such as environmental monitoring, machine con-
trol automation, and traceability [32–35]. 
Along with the development of science and technology, the urgent requirement for 
breakthrough solutions and technologies aiming at improving productivity and efficiency 
in the agriculture sector has led to adoption of the IoT. The primary motivation for their 
applications is the breakthrough progress of smart agriculture and its inevitable role as 
the future of smart and sustainable environment management. IoT integrates a series of 
existing solutions and technologies, such as WSN, cognitive radio, ad hoc networks, cloud 
computing, and end-user applications [36]. In the smart agricultural sector, automation 
solutions and technologies, mechanical machines, knowledge, decision-making tools, ser-
vices, and software are integrated seamlessly to help farmers improve productivity, prod-
uct quality, and profitability [37]. 
Figure 1. An illustration of IoT applications for smart agriculture.
According to the United Nations’ (UN 2019) statistics, the world population is esti-
mated to grow to 10 billion by 2050 [23]. As a consequence, the requirements of agricultural
products are continually increasing. However, farmlands are declining, natural resources
are increasingly depleted, and the rise of unpredictable nature challenges, such as global
warming, salinization, and ﬂooding, make food security the most concerning problem for
all nations worldwide.
In recent years, with the aim of increasing agricultural production, new solutions and
technologies have been introduced in the agriculture sector [24]. An emerging trend is the
application of the IoT and big data. A signiﬁcant number of studies have been focused on
research, experiments, and applications [25,26]. According to the Cisco forecast, over 500
billion IoT devices will be connected to the Internet by 2030 [27]. The use of IoT and big data
will enable smart agriculture and is expected to enhance efﬁciency and productivity [28].
Over the years, wireless sensor networks (WSN) have been strongly applied in the agri-
cultural sector, building the foundation for developing smart agriculture [29]. The unique
characteristics of WSN, such as the ability to self-organize, self-conﬁgure, self-establish,
and self-recover, make it suitable for smart agriculture [30]. The sensor device consists of a
radio frequency (RF) transceiver, sensor, microcontroller, and battery power [31]. The WSN
focuses on applications such as environmental monitoring, machine control automation,
and traceability [32–35].
Along with the development of science and technology, the urgent requirement for
breakthrough solutions and technologies aiming at improving productivity and efﬁciency
in the agriculture sector has led to adoption of the IoT. The primary motivation for their
applications is the breakthrough progress of smart agriculture and its inevitable role as
the future of smart and sustainable environment management. IoT integrates a series of
existing solutions and technologies, such as WSN, cognitive radio, ad hoc networks, cloud
computing, and end-user applications [36]. In the smart agricultural sector, automation
solutions and technologies, mechanical machines, knowledge, decision-making tools, ser-
vices, and software are integrated seamlessly to help farmers improve productivity, product
quality, and proﬁtability [37].
In this work, a comprehensive survey of IoT applications for smart agriculture is
conducted. An analysis of 135 relevant works published between 2017 and 2022 was con-
ducted. Firstly, relevant 550 papers published in the period of (2017–2022) were retrieved
from major scientiﬁc databases, namely IEEE Xplore Digital Library, Science Direct, MDPI,
Appl. Sci. 2022, 12, 3396
3 of 19
and Springer, by using keywords such as IoT-enabled smart agriculture, smart agriculture,
Internet of Things, aquaponics, monitoring forestry based on IoT, tracking and tracing,
smart precision farming, greenhouse production, Sigfox, LoRa, Wi-Fi, LoRaWAN, and
IoT ecosystems. In the next step, we excluded papers that were published in low-repute
conferences and journals, and then we conducted the content analysis for the obtained
paper. Finally, 135 papers were selected for the preparation of the present work.
In addition, we analyzed and discussed the beneﬁts and challenges, open issues,
trends, and opportunities of IoT in the smart agriculture sector. This work is organized
as follows: Section 1 introduces our work, and in Section 2, we present an IoT ecosystem
architecture for smart agriculture that consists of three main components: IoT devices,
communication technology, and data storage and big data processes. Section 3 presents
the IoT applications in agriculture, including (1) monitoring, (2) tracking and traceability,
(3) precision agriculture, and (4) greenhouses. Section 4 introduces some open issues and
future research challenges of IoT for smart agriculture. Issues are discussed for two main
directions: business and technology. In Section 5, we present the main conclusions of this
work.
2. IoT Ecosystem Architecture for Smart Agriculture
In this section, we present a common framework of an IoT ecosystem for smart agri-
culture based on three main components, including (1) IoT devices, (2) communication
technologies, and (3) data process and storage solutions. An illustration of the IoT ecosys-
tem for smart agriculture is presented in Figure 2.
Appl. Sci. 2022, 12, x FOR PEER REVIEW 
3 of 20 
 
In this work, a comprehensive survey of IoT applications for smart agriculture is con-
ducted. An analysis of 135 relevant works published between 2017 and 2022 was con-
ducted. Firstly, relevant 550 papers published in the period of (2017–2022) were retrieved 
from major scientific databases, namely IEEE Xplore Digital Library, Science Direct, 
MDPI, and Springer, by using keywords such as IoT-enabled smart agriculture, smart ag-
riculture, Internet of Things, aquaponics, monitoring forestry based on IoT, tracking and 
tracing, smart precision farming, greenhouse production, Sigfox, LoRa, Wi-Fi, LoRaWAN, 
and IoT ecosystems. In the next step, we excluded papers that were published in low-
repute conferences and journals, and then we conducted the content analysis for the ob-
tained paper. Finally, 135 papers were selected for the preparation of the present work. 
In addition, we analyzed and discussed the benefits and challenges, open issues, 
trends, and opportunities of IoT in the smart agriculture sector. This work is organized as 
follows: Section 1 introduces our work, and in Section 2, we present an IoT ecosystem 
architecture for smart agriculture that consists of three main components: IoT devices, 
communication technology, and data storage and big data processes. Section 3 presents 
the IoT applications in agriculture, including (1) monitoring, (2) tracking and traceability, 
(3) precision agriculture, and (4) greenhouses. Section 4 introduces some open issues and 
future research challenges of IoT for smart agriculture. Issues are discussed for two main 
directions: business and technology. In Section 5, we present the main conclusions of this 
work. 
2. IoT Ecosystem Architecture for Smart Agriculture 
In this section, we present a common framework of an IoT ecosystem for smart agri-
culture based on three main components, including (1) IoT devices, (2) communication 
technologies, and (3) data process and storage solutions. An illustration of the IoT ecosys-
tem for smart agriculture is presented in Figure 2. 
 
Figure 2. An illustration of IoT ecosystems’ architecture for smart agriculture. 
Figure 2. An illustration of IoT ecosystems’ architecture for smart agriculture.
2.1. IoT Devices
The common architecture of an IoT device consists of sensors to collect information
from the environment, actuators based on wired or wireless connections, and an embedded
system that has a processor, memory, communication modules, input–output interfaces,
Appl. Sci. 2022, 12, 3396
4 of 19
and battery power [38,39]. The common architecture of a typical IoT device for smart
agriculture is shown in Figure 3.
Appl. Sci. 2022, 12, x FOR PEER REVIEW 
4 of 20 
 
2.1. IoT Devices 
The common architecture of an IoT device consists of sensors to collect information 
from the environment, actuators based on wired or wireless connections, and an embed-
ded system that has a processor, memory, communication modules, input–output inter-
faces, and battery power [38,39]. The common architecture of a typical IoT device for smart 
agriculture is shown in Figure 3. 
 
Figure 3. An illustration of the common architecture of an IoT device. 
Embedded systems are programmable interactive modules, namely FPGAs (field 
programmable gate arrays). Sensor devices are specially designed to operate in open en-
vironments, in nature, in soil, water, and air to measure and collect environmental param-
eters that affect production, such as soil nutrients, humidity, temperature, etc. Smart farm-
ing solutions are agricultural operations that are often deployed on large farmlands, out-
doors, so the devices that support solutions need some unique characteristics, such as the 
ability to withstand the effects of weather, humidity, and temperature instability through-
out their service lifecycle. Some of their main features, as shown in Figure 4, make IoT 
devices suitable for smart agriculture solutions [40–42]. 
 
Figure 4. The main characteristics of IoT devices. 
Figure 3. An illustration of the common architecture of an IoT device.
Embedded systems are programmable interactive modules, namely FPGAs (ﬁeld
programmable gate arrays). Sensor devices are specially designed to operate in open
environments, in nature, in soil, water, and air to measure and collect environmental
parameters that affect production, such as soil nutrients, humidity, temperature, etc. Smart
farming solutions are agricultural operations that are often deployed on large farmlands,
outdoors, so the devices that support solutions need some unique characteristics, such
as the ability to withstand the effects of weather, humidity, and temperature instability
throughout their service lifecycle. Some of their main features, as shown in Figure 4, make
IoT devices suitable for smart agriculture solutions [40–42].
Appl. Sci. 2022, 12, x FOR PEER REVIEW 
4 of 20 
 
2.1. IoT Devices 
The common architecture of an IoT device consists of sensors to collect information 
from the environment, actuators based on wired or wireless connections, and an embed-
ded system that has a processor, memory, communication modules, input–output inter-
faces, and battery power [38,39]. The common architecture of a typical IoT device for smart 
agriculture is shown in Figure 3. 
 
Figure 3. An illustration of the common architecture of an IoT device. 
Embedded systems are programmable interactive modules, namely FPGAs (field 
programmable gate arrays). Sensor devices are specially designed to operate in open en-
vironments, in nature, in soil, water, and air to measure and collect environmental param-
eters that affect production, such as soil nutrients, humidity, temperature, etc. Smart farm-
ing solutions are agricultural operations that are often deployed on large farmlands, out-
doors, so the devices that support solutions need some unique characteristics, such as the 
ability to withstand the effects of weather, humidity, and temperature instability through-
out their service lifecycle. Some of their main features, as shown in Figure 4, make IoT 
devices suitable for smart agriculture solutions [40–42]. 
 
Figure 4. The main characteristics of IoT devices. 
Figure 4. The main characteristics of IoT devices.
Depending on the required operation, there are several typical sensors applied in the
smart agriculture sector. Sensors can be divided into several typical categories, such as
(1) location sensor, (2) optical sensor, (3) mechanical sensor, (4) electrochemical sensor, and
Appl. Sci. 2022, 12, 3396
5 of 19
(5) air ﬂow sensor. These sensors are used to collect information such as air temperature,
soil temperature, air humidity, soil moisture, leaf moisture, precipitation, wind speed, wind
direction, and solar radiation, and barometric pressure [21,24,36].
2.2. Communication Technology
The survey of communication technologies for IoT [43,44] indicated that to integrate
IoT into the smart agriculture sector, communication technologies must progressively
improve the evolution of IoT devices. They play an important role in the development of
IoT systems. The existing communication solutions can be classiﬁed as: protocol, spectrum,
and topology.
Protocols: many wireless communication protocols have been proposed for the smart
agriculture sector. Based on these protocols, devices in a smart agricultural system can
interact, exchange information, and make decisions to monitor and control farming condi-
tions and improve yields and production efﬁciency. The typical, low-power communication
protocol numbers commonly used in smart agriculture can be divided into short-range and
long-range categories based on the communication range.
-
Short-range: NFMI (near-ﬁeld magnetic induction) [45], Bluetooth [46], ZigBee [47],
terahertz (Z-Wave) [48,49], and RFID [50].
-
Long-range: LoRa [51], Sigfox [52], and NB-IoT (Narrowband IoT) [53].
Table 1 presents some typical communication technologies for the smart agriculture
sector. The values in Table 1 indicate that short-range communication technologies have
a transmission distance of less than 20 (m), high energy efﬁciency, and low data rate.
These protocols are often employed in sensor networks, while long-range communication
technologies have transmission distances of up to several tens of kilometres, consume more
energy, and are installed for backhaul device-to-device communications. A diverse survey
of low-power communication technologies for IoT that presents solutions, challenges, and
some open issues is described by Sundaram et al. [54].
Table 1. Some typical communication technologies for smart agriculture.
Type
Spectrum
Transmission
Distance
Type of Network
Frequency
Data Rate
802.11a/b/g/n/ac
Unlicensed
100 m
WLAN
2.4–5 GHz
2–700 Mbps
802.11ah
Unlicensed
1000 m
WLAN
Several Sub-GHz
78 Mbps
802.11p
Licensed
1 km
WLAN
5.9 GHz
3–27 Mbps
802.11af
Licensed
1 km
WLAN
54–790
25–550 Mbps
SigFox
Licensed
Rural: 50 km
Urban:10 km
LPWA
Zwave
100–600 bps
LoRaWAN
Licensed
20 km
LPWA
Several Sub-GHz
0.3–100 kbps
NB-IoT
Licensed
35 km
LPWA
Zwave
250 kbps
LTE-3GPP
Licensed
5 km
WWAN
1.4 MHz
200 kbps
EC-GPRS
Licensed
5 m
WWAN
GSM bands
240 kbps
WiMAX
Hybrid
50–80 km
WWAN
Several Sub-GHz
70 Mbps
Bluetooth
Unlicensed
100 m
WPAN
2.4 GHz
2–26 Mbps
ZigBee
Unlicensed
1 km
WHAN
2.4 GHz
250 kbps
Z-Wave
Unlicensed
100 m
WHAN
900 MHz
100 kbps
6LoWPAN
Unlicensed
30 m
WHAN
Zwave
250 kbps
NFC
Unlicensed
20 cm
D2D
13.56 MHz
424 kbps
Spectrum: Each radio device uses certain frequency bands for communication. The
FCC (Federal Communications Commission) has deﬁned unlicensed spectrum bands for
unlicensed operations in scientiﬁc, industrial, and medical purposes [55]. These spectrum
bands are often applied for low-power levels and short-range applications. Consequently, a
series of common technologies for the smart agriculture sector, from wireless machine con-
trol and UAVs to communication technologies such as Wi-Fi and Bluetooth, use unlicensed
Appl. Sci. 2022, 12, 3396
6 of 19
spectrum bands [56]. However, the use of unlicensed spectra faces several challenges, such
as the quality of service guarantee, the cost of setting up the initial infrastructure, and the
interference generated by the huge number of IoT devices [57,58].
A licensed spectrum usually is allocated to mobile networks. It provides more efﬁcient
network trafﬁc, more reliability, enhances the quality of service (QoS), offers security,
provides extensive coverage, and involves lower initialization infrastructure costs for users.
However, the use of licensed spectrum bands has faced some limitations, such as high data
transmission costs and the low energy efﬁciency of IoT devices [59].
Several recent studies have demonstrated the efﬁciency of unlicensed spectrum bands
in the mm wave range. It uses extremely low power but provides large transmission
distances and high data rates [60,61]. One limitation of the mm wave spectrum is that the
data rate is strongly affected by weather conditions, especially rain [62].
Topology: The establishment of the communication spectrum band and operation pro-
tocol of IoT devices depends on the structure that deploys IoT devices for smart agriculture
applications. Network structures for smart agriculture usually have two main types of
nodes: sensor and backhaul nodes [63]. The common characteristics of IoT sensor nodes
are short communication distance, low data rate, and high energy efﬁciency. In contrast,
IoT backhaul nodes often require large transmission distances, high throughput, and data
rates. Therefore, based on the role of each IoT network node, the sensor node or backhaul
node selects and installs appropriate communication technologies [64]. Figure 5 presents a
typical low-power network topology designed for measuring and monitoring factors in a
smart farm. The system includes:
(1)
IoT sensor nodes collect information from the farming environment, such as soil
moisture, air humidity, temperature, nutrient ingredients of soil, pest images, and
water quality, then transmit collected data to IoT backhaul devices. Depending on
the operation purpose and installation location, IoT sensor nodes can be installed as
RFDs (reduced-function devices), which only communicate with FFDs (full-function
devices). These nodes cannot communicate with the other RFDs, aiming to save
energy and decrease investment costs.
(2)
IoT backhaul nodes, besides having the role of an IoT sensor node, also play a role as
intermediate nodes to receive information from other IoT nodes and transmit it to the
control centre. IoT backhaul nodes are often installed as an FFD device, which can
connect to other FDD and RFD devices.
Appl. Sci. 2022, 12, x FOR PEER REVIEW 
7 of 20
. 
Figure 5. An illustration of the common IoT-based smart agriculture topology. 
The complexity of data storage and processing is due to the unique characteristics of 
the smart agriculture field, including unstructured data and various formats, such as text, 
images, audio and video, economic figures, and market information. Recent solutions and 
technologies have introduced the use of cloud platforms for storage and data analytics, 
hi h
ll
d f
f
[36 67] I
ddi i
l
d
i
d bi
d
l
i
l
Figure 5. An illustration of the common IoT-based smart agriculture topology.
Appl. Sci. 2022, 12, 3396
7 of 19
2.3. Data Analytics and Storage Solutions
In the smart agriculture domain, besides the main problems of sensing, collecting
data, and controlling devices to respond to the real farming environment, data storage and
processing are also important problems and face some challenges [26,28]. In reality, the
number of collected data is huge, and traditional data storage, organization, and processing
solutions are not feasible. Therefore, big data processing solutions need to be researched
and applied for smart agriculture [65,66].
The complexity of data storage and processing is due to the unique characteristics
of the smart agriculture ﬁeld, including unstructured data and various formats, such
as text, images, audio and video, economic ﬁgures, and market information. Recent
solutions and technologies have introduced the use of cloud platforms for storage and
data analytics, which are collected from farms [36,67]. In addition, cloud-assisted big data
analytic solutions, such as edge computing [68] or fog computing [69], are also proposed to
reduce latency and costs and support QoS.
The survey results demonstrate that, in recent years, many management information
systems for smart agriculture have been proposed [70–72]. Nowadays, possible solutions
have been developed and commercialized, providing solutions and services for farmers
to manage farms and ﬁelds, aiming to increase productivity, reduce human labour, and
enhance farming efﬁciency, as follows:
-
OnFarm [73]: It is part of the SWIM family, which specializes in providing solutions
and technology for smart agriculture. OnFarm is a technology platform that allows
farmers to manage and use data in the simplest way. It is also a comprehensive
solution for managing, using, and controlling water on smart farms.
-
Farmobile [74]: It is a commercialized online platform to manage smart farms that
allows farmers, traders, scientists, and insurance companies to operate and communi-
cate centrally on an online platform.
-
Silent Herdsman Plat f orm [75]: It is a platform that allows monitoring of the activities
of cow colonies and predicting their milk production.
-
CropX [76]: It is a platform that will enable monitor and control nutrients of farming
soil based on a sensor system and big data analytic solutions.
-
FarmX [77]: It is an all-in-one platform for tree crops. FarmX provides a series
of diverse farming management solutions, including irrigation, fertilizer, cropland
management systems, environmental monitoring, and crop production forecasting.
-
Easy f arm [78]: It is a platform that provides software to help farmers manage and
account for ﬁgures of farms. Easyfarm provides visual ﬁgures, including input and
output supplies management, production forecasting, and market connectivity, to
help farmers fully manage their farms.
-
KAA [79]: It is a cloud-based IoT platform that aims to provide comprehensive, end-
to-end solutions for farmers, including: (1) connecting and managing IoT devices in
farms or ﬁelds; and (2) monitoring and controlling behaviours of devices based on
data analysis results.
-
Farmlogs [80]: It is a platform that provides tools and solutions for: (1) automating
the production cost calculation process; (2) managing the day-to-day activities of the
farm in real-time; and (3) supporting marketing and increasing sales of products.
3. Typical Applications of IoT in Smart Agriculture
In recent years, a series of IoT applications for agriculture have been introduced.
According to survey results, we divided these applications into categories based on their
purpose, including monitoring, tracking and traceability, and greenhouse production. The
detailed results are presented in the following subsection.
3.1. Monitoring
In the agriculture sector, factors affecting the farming and production process can be
monitored and collected, such as soil moisture, air humidity, temperature, pH level, etc.
Appl. Sci. 2022, 12, 3396
8 of 19
These factors depend on the considered agricultural sector. Some smart agricultural sectors
are applying the following monitoring solutions:
Crop Farming: In this sector, some vital factors that affect the farming process and
production efﬁciency include air temperature, precipitation, air humidity, soil moisture,
salinity, solar radiation, pest status, soil nutrient ingredients, etc. In [81], the authors
designed an IoT device called FarmFox. This device allows real-time collection and analysis
of the composition of the farming soil and transmits the information to farmers/owners
via the Internet. The results demonstrate the health of the soil is monitored in real time to
provide timely recommendations to farmers aiming to increase productivity and farming
efﬁciency.
Furthermore, in [82], the authors proposed an IoT device to allow intelligent control
of temperature and humidity factors, called a weather radar. This device will automatically
turn on the warning mode using the light signal and send messages to the farmer when the
temperature or humidity exceeds a pre-installed threshold. In [83], the authors introduced
an IoT system based on Web GIS to monitor pest status and provide early warnings. In
addition, this study also proposes a predictive model based on monitoring the habitat of
pests and diseases. The efﬁciency of the proposed system was indicated, based on the
predicted ﬁgures of the locust epidemic, to have a high accuracy rate (over 87%) in 2019
(China).
Monitoring information, such as soil condition, moisture, and temperature, and the
prediction of natural factors, such as rainfall and weather, support the control of growing
conditions of crops, helping farmers plan and make irrigation decisions to optimize pro-
duction and reduce labour costs. In addition, the collected data, combined with big data
processing technology, can provide recommendations for implementing preventive and
remedial solutions against pests and diseases in farming.
Aquaponics: It is an integration of aquaculture and hydroponics. Aquaponics is a
farming technique where ﬁsh waste becomes a source of nutrients needed by plants. One of
the most important issues in such farms is constantly monitoring water quality, water level,
temperature, salinity, pH, sunlight, etc. [84]. According to this research direction, in [85],
the authors designed an IoT system to monitor the temperature and pH value of water for
aquaponics farms. Moreover, this system is also equipped with a control system of water
metrics to keep the ﬁsh habitat stable and an automatic ﬁsh feeding function to increase
the productivity of the ﬁsh. The results show that the IoT system had stable operation and
provided real-time monitoring parameters. The authors of [86] designed an aquaponics
farm for households/urban areas based on IoT. This system recommends the proper ratio
of ﬁsh and plants.
Consequently, the system decreases feed consumption as well as reduces carbon
emissions into the environment. The primary purpose of this proposal aims to balance the
self-sustaining ability of the aquaponics system. The experimental results demonstrate the
number of ﬁsh decreases from 30 to 15, and the number of plants increases from 20 to 30,
but the crop production will increase by more than 50%. A detailed and diverse survey of
the IoT systems and devices for control and monitoring of aquaponics farms is introduced
in [87]. Based on the obtained data, monitoring can improve the production of ﬁsh and
plants through the control, supplementation, and regulation of nutritional ingredients in
the water. The collected data were also used to automate the management of aquaponics
farms to reduce labour costs.
Forestry: Humans depend on forests for survival. Moreover, forests play a vital
role in the carbon cycle and provide a habitat for more than two-thirds of animal species
in the world. Forests also have the effect of protecting watersheds, limiting ﬂoods, and
mitigating climate change. The main factors that need to be monitored in a forest include
soil ingredients, air temperature, humidity, and concentration of several different gases,
such as oxygen, methane, ammonia, and hydrogen sulphide. A series of forest control
systems and solutions are presented in [88,89] based on IoT and big data analytics.
Appl. Sci. 2022, 12, 3396
9 of 19
In [90], the authors designed a peatland forest environmental monitoring system.
This forest area plays a very vital role in the rainforest ecosystem of Brunei. However,
the peatland forest type is very burnt. This work designed an IoT system to monitor
environmental conditions, such as temperature, humidity, wind direction, barometric
pressure, and manage possible disasters. For the purpose of enhancing feasibility, IoT
devices use the solar-powered system and communicate with the monitoring centre based
on the LoRa network. In [91], the authors proposed a solution to control forest changes
and vitality by using high-resolution RapidEye satellite imagery. This solution has been
deployed commercially in several states in Germany and has detected leaf diseases in a
pine forest affected by pests. Survey results indicate that monitoring in forestry focuses on
providing early warning systems against forest ﬁres, pest control, or deforestation.
Livestock Farming: It is deﬁned as the process of raising domesticated animals, such as
cows, pigs, sheep, and goats, chickens, etc., in an agricultural environment to obtain traction,
serve production, and obtain products such as meat, eggs, milk, fur, leather, etc. In this
area, the factors to be monitored depend on the type and number of farming animals [92].
In [93], the authors designed a support system for the diagnosis, prevention, and treatment
of diseases for livestock called VetLink. This system can provide recommendations for
animal health for farmers in rural areas where it is difﬁcult to access veterinary doctors
immediately. In [94], the authors proposed a noncontact temperature measurement system
and monitoring of animals to ensure early detection of diseases and animal health. This
system can be used for remote monitoring of animal health and timely anomaly detection.
In [95], the authors introduced a monitoring system for large-scale pig farms based on IoT.
The speciﬁc solution is to attach an IC tag on each pig to monitor the behaviour of each pig,
such as their period of feeding and resting and exercise. Data from sensors are collected
and combined with data analytics solutions that can make recommendations for pig health.
The monitoring data of water, feed, and animal health for livestock in the farming
process helps farmers set up livestock plans, reduce labour costs, and enhance production
efﬁciency. While a series of solutions has been provided for monitoring large-scale farms,
their application in small and medium-sized farms is very limited, especially in developing
countries. This can be attributed to the high cost and the lack of knowledge needed to
set up, manage, and operate IoT systems. Therefore, effective and low-cost solutions for
agricultural IoT have much potential.
3.2. Tracking and Tracing
In order to meet the needs of consumers and increase proﬁt value, in the future, farms
need to demonstrate that products offered to the market are clean products and can be
tracked and traced conveniently, thereby enhancing the trust of consumers in product
safety and health-related issues. In order to solve this problem, a series of tracking- and
tracing-based problems for the smart agricultural sector has been proposed, speciﬁcally as
follows:
In [96], the authors designed an information system that allows tracking and tracing
of agricultural products and foods such as dairy and vegetables, called SISTABENE. This
system helps suppliers track the production process and errors arising in the supply chain,
and helps end-users trace the origin of food. In [97], the authors proposed a food supply
chain traceability system based on blockchain technology. It helps to track and trace agri-
food supply chains’ production process and trace the origin of agricultural products. This
solution has been employed at Shanwei Lvfengyuan Modern Agricultural Development
Co., Ltd. (Shanwei, China). Although there are still limitations, the results demonstrate
that this solution has successfully supported the tracing of food and agricultural prod-
ucts through QR codes, improving product quality and ensuring the clear traceability of
products. In [98,99], the authors proposed smart agricultural solutions to tracking and
tracing agricultural products, thereby allowing consumers to know the product’s entire
history. These solutions enable tracking and tracing some of the data collected along the
Appl. Sci. 2022, 12, 3396
10 of 19
supply chain, ensuring that consumers and other stakeholders can identify products’ origin,
location, and history.
3.3. Smart Precision Farming
The advent of the GPS (global positioning system) has created breakthrough advances
in many ﬁelds of science and technology. The GPS provides the most important parameters
for locating a device, such as location and time. GPS systems have been successfully
deployed in many ﬁelds, such as smartphones, vehicles, and IoT ecosystems. However,
GPS is only good support for outdoor systems and the sky. Meanwhile, the demand
for the locating and navigating systems in the home and on the streets of smart cities is
growing rapidly. Aiming to solve this problem, an advanced global navigation satellite
system (GNSS) is being deployed [100]. Based on GPS and GNSS systems, suitable farming
maps have been established for ﬁelds and farms. As a result, agricultural machinery and
equipment can be operated autonomously [101]. Figure 6 presents an illustration of the
typical cloud-assisted, IoT-based precision agriculture platform.
Appl. Sci. 2022, 12, x FOR PEER REVIEW 
11 of 20 
 
their machines, allowing machines to operate autonomously and remotely via the Internet 
[107]. 
 
Figure 6. Cloud-assisted IoT-based precision agriculture platform. 
3.4. Greenhouse Production 
A greenhouse consists of walls and a roof, which are usually made from transparent 
materials, such as plastic or glass. In a greenhouse, plants are grown in a controlled envi-
ronment, including controlling for moisture, nutrient ingredients of the soil, light, tem-
perature, etc. Consequently, greenhouse technology makes it possible for humans to grow 
any plant, at any time, by providing suitable environmental conditions [108]. Figure 7 
illustrates a smart agriculture IoT system for monitoring greenhouse farming factors 
based on IoT ecosystems. 
In [109], the authors introduced an IoT-based greenhouse environmental monitoring 
system for multipoint monitoring in large greenhouses. Instead of using multiple sensors 
at different locations, this solution involves a drive system that allows the sensor system 
diff
l
i
i
h
h
Th
i
l
l
h
h
h
Figure 6. Cloud-assisted IoT-based precision agriculture platform.
In smart precision farming, one of the most important applications is the use of drones
in monitoring and farming activities. Some common farming tasks using UAVs include
spraying pesticides, fertilizing, sowing seeds, evaluating and mapping, and monitoring
crop growth. In [102], the authors presented a detailed survey of drone applications for
smart agriculture, including applications, control technology, and future trends of the UAV
application for smart agriculture. In [103], the authors designed an automatic agricultural
product classiﬁcation system based on camera systems, image processing algorithms, and
Appl. Sci. 2022, 12, 3396
11 of 19
mechanical actuators. The experimental results for agriculture products such as oranges
and tomatoes present a classiﬁcation success rate of over 95%, and the sorting time for each
product is less than 1(s). This solution can be adapted and applied to the classiﬁcation of
different agricultural products. In [104], the authors proposed a solution to estimate grape
production. The proposed solution combines an RGB-D camera mounted on a mobile robot
platform and size estimation algorithm for a bunch of grapes. The experimental results
present an average error in the range of [2.8–3.5] (cm). The results demonstrate this solution
is a feasible method for evaluating the productivity of large-scale grape farms.
The survey results show that smart precision agricultural equipment, such as irriga-
tion systems, unmanned aerial vehicles (UAV), and smart agricultural equipment, etc.,
are conﬁgurable in an autonomous-control mode based on certain conditions or can be
controlled remotely by the farmer via the Internet [105,106]. Smart precision farming helps
to improve productivity and production efﬁciency and is suitable for large-scale farms.
Nowadays, suppliers of precision agricultural equipment have IoT modules built into their
machines, allowing machines to operate autonomously and remotely via the Internet [107].
3.4. Greenhouse Production
A greenhouse consists of walls and a roof, which are usually made from transparent
materials, such as plastic or glass. In a greenhouse, plants are grown in a controlled
environment, including controlling for moisture, nutrient ingredients of the soil, light,
temperature, etc. Consequently, greenhouse technology makes it possible for humans to
grow any plant, at any time, by providing suitable environmental conditions [108]. Figure 7
illustrates a smart agriculture IoT system for monitoring greenhouse farming factors based
on IoT ecosystems.
Appl. Sci. 2022, 12, x FOR PEER REVIEW 
12 of 20 
 
be above 50 °C, demonstrate the efficiency of the proposed solution, including saving en-
ergy and predicting the rate of plant growth. 
Recent studies indicated that solutions integrating IoT, big data processing, and arti-
ficial intelligence could be applied in greenhouses to reduce labour and energy efficiency. 
Moreover, it also provides direct connections between the greenhouse farms and the cus-
tomer [112–115]. 
 
Figure 7. An illustration of IoT application for monitoring farming conditions in a greenhouse. 
4. Challenges and Open Research Directions 
The survey results indicate that IoT components for the smart agriculture sector, in-
cluding hardware and software, have been focused on research and achieved many break-
through results. Several IoT solutions have been deployed on large-scale farms/fields. 
However, the widespread deployment of IoT in the agricultural sector still presents some 
challenges. We have present two main problems: economic efficiency and technical prob-
lems. We consider these issues coupled with policies that will drive the integration of IoT 
technologies in agriculture. 
Figure 7. An illustration of IoT application for monitoring farming conditions in a greenhouse.
In [109], the authors introduced an IoT-based greenhouse environmental monitoring
system for multipoint monitoring in large greenhouses. Instead of using multiple sensors
at different locations, this solution involves a drive system that allows the sensor system
to move to different locations in the greenhouse. The experimental results show that the
proposed system can effectively monitor multiple points in large greenhouses. In [110], the
Appl. Sci. 2022, 12, 3396
12 of 19
authors introduced an energy-saving temperature control technology for smart greenhouses.
This study proposed two intelligent control methods: active disturbance rejection control
and fuzzy active disturbance rejection control. The experimental results demonstrate
that the proposed technology saves over 15% of the total energy consumption of the
greenhouse. In [111], the authors designed an intelligent IoT system to monitor and
control greenhouse temperature for energy efﬁciency and improve crop productivity. The
experimental results for the Kingdom of Saudi Arabia, where daytime temperatures can be
above 50 ◦C, demonstrate the efﬁciency of the proposed solution, including saving energy
and predicting the rate of plant growth.
Recent studies indicated that solutions integrating IoT, big data processing, and artiﬁ-
cial intelligence could be applied in greenhouses to reduce labour and energy efﬁciency.
Moreover, it also provides direct connections between the greenhouse farms and the cus-
tomer [112–115].
4. Challenges and Open Research Directions
The survey results indicate that IoT components for the smart agriculture sector,
including hardware and software, have been focused on research and achieved many
breakthrough results. Several IoT solutions have been deployed on large-scale farms/ﬁelds.
However, the widespread deployment of IoT in the agricultural sector still presents some
challenges. We have present two main problems: economic efﬁciency and technical prob-
lems. We consider these issues coupled with policies that will drive the integration of IoT
technologies in agriculture.
4.1. Economic Efﬁciency
In agricultural economics, one of the most important characteristics is a low rate of
proﬁt of an investment project, which presents many risks from natural conditions. The
beneﬁt–cost of a new technology seeking deployment in agriculture should be carefully
calculated to ensure a trade-off between the cost of technology implementation and the
proﬁt potential. Therefore, we discuss the economic aspects related to IoT implementation
in smart agriculture.
There are several types of costs related to the implementation of IoT in agriculture.
We divided them into categories, including (1) the system initialization cost and (2) the
system operating cost. The system initialization cost includes hardware purchases (IoT
devices, gateways, base station infrastructure). The system operating cost includes service
registration cost and the cost of labour to manage IoT devices. Furthermore, additional op-
erating costs include incurred costs from energy consumption, maintenance, data exchange
among IoT devices, gateways and cloud servers. According to the opinion of Turgut and
Boloni [116], the successful deployment of the IoT technologies will only happen if the
customer beneﬁts (customers need to know the beneﬁts and potential) that IoT systems
provide exceed their physical value and privacy costs. The businesses participating in the
IoT domain will proﬁt and achieve success. We can describe this process using these two
conditions, as follows:
Success o f IoT Applications=
 Vservice > Cpri + Cuser
h
+ Cpay, Farmer Bene f its
(1)
Vin f o + Rpay > Cbusiness
h
, Businesses Bene f its
(2)
where
Vservice is the expected value received by the IoT service users.
Cpri is the cost of the loss of privacy.
Cuser
h
is the equipment and hardware costs the user pays.
Cpay is the payment for the service fee.
Vin f o is the received information value.
Rpay is the received direct payment.
Cbusiness
h
is the share of the hardware and maintenance costs of the business.
Appl. Sci. 2022, 12, 3396
13 of 19
According to the opinion of the service user (farmers or the owner of the farm),
Equation (1) shows that the perceived value of the service for the user (Vservice) must be
higher than the total of costs, including: the cost of the loss of privacy (Cpri), the equipment
and hardware costs the user pays (Cuser
h
), and the payments for the service fee (Cpay), while
the opinion of the service provider, as shown in Equation (2), shows that the received
information value (Vin f o) and the received direct payments (Rpay) must be higher than the
share of the hardware and maintenance costs of the business (Cbusiness
h
).
There is still a gap between service providers and service users (farmers or the owner
of the farm), leading to the slow deployment of IoT applications in smart agriculture. In
terms of the economic aspect, the analyzed results show that the need for a support policy
from regulatory agencies and governments to allow service providers and service users
to use IoT-based smart agriculture applications in their infancy can be met. As discussed
in [117], to promote smart agriculture, the European Union has issued supportive economic
policies, the so-called the European CAP (Common Agricultural Policy), whose annual
budget amounts to approximately EUR 59 billion and is paid for by the nations of the EU.
In our view, to be able to apply IoT in the ﬁeld of smart agriculture, service costs
(Cpay) and the operating and system initialization cost of IoT (Cuser
h
) needs to constantly be
improved and optimized to reduce the cost of the IoT services for farmers. In addition, IoT
businesses (service providers) also need to maximize the value of information obtained
(Vin f o) to improve the proﬁtability of the service providers.
In reality, service providers may commercially exploit the information received (Vin f o)
in the period of providing services for farms, aiming to encourage the deployment of
IoT applications in smart agriculture. Nowadays, several IoT platform providers allow
free registration and use of services with some limitation conditions regarding services’
functionality and ability processing; the number of connected IoT devices; and the number
of data stored while premium functions and services charge users a fee.
In addition, one of the signiﬁcant factors slowing down IoT adoption in agriculture
is farmers’ knowledge and ability to use IoT devices. In developed countries, this issue
can be easily solved due to the accessibility of new technologies of farmers. Otherwise, in
developing countries, where the majority of farmers in rural areas have very limited access
to advanced technologies, this issue is a signiﬁcant challenge [118,119].
4.2. Technical Problems
Interference: Deploying a huge number of IoT devices for smart agriculture can
cause interference to different network systems, especially some IoT networks using short
spectrum bands such as ZigBee, Wi-Fi, Sigfox, and LoRa (See Table 1). Interference can
degrade system performance as well as reduce the reliability of IoT ecosystems. IoT
networks that use cognitive technology to reuse unlicensed spectra increase the cost of the
device. In our opinion, the advent of the 6G network [120] will allow a huge number of
devices to connect to the Internet with an extremely high access speed and extremely large
bandwidth. The full interference problem of IoT networks will be solved.
Security and Privacy: One of the most important problems of applying IoT in smart
agriculture is the security problem, including the protection of data and systems from
attacks on the Internet. In regard to system security, IoT devices’ limited capacity and
ability led to complex encryption algorithms that are impossible to implement on IoT
devices. As a result, IoT systems can be attacked using the Internet to gain system control
rights; IoT gateways are also attacked via denial of service [121–123]. In addition, cloud
servers can be attacked by data spooﬁng to perform unauthorized tasks that affect the
autonomous farming processes of farms. Cloud infrastructures can also be controlled by
attackers [124,125]. Several issues of detailed IoT data privacy and security measures have
been discussed in [126–128]. According to Neshenko et al., the IoT data security issue is one
of the biggest problems slowing down IoT adoption in smart agriculture [129].
Regarding data security, the obtained information from IoT systems in farms is col-
lected, processed, and commercially exploited by service providers to varying degrees.
Appl. Sci. 2022, 12, 3396
14 of 19
Therefore, one of the most important problems of policies regards the validity and legal
status of farm data [130]. In reality, these data are of great value when aggregated and
analyzed for large-scale agricultural activities. Consequently, without policies, the data
privacy and security of farms can affect the competitive advantage of farmers/farm owners.
In our opinion, using cryptography coupled with access keys is a possible solution to
solve this problem. Keys could be made available based on a regional user group and
to those who contributed to the database. For further complex cases, secure multiparty
computation can be used, where the homomorphic encryption method [131,132], or this
method combined with the blockchain [133], can be applied for the purpose of balancing
privacy and data utility.
In our opinion, the security problems of IoT systems will be an exciting research topic
and garner attention for both academia and industry research. An in-depth survey of
threats and solutions to improve robustness, trust, and privacy for future IoT systems is
presented in [134].
Reliability: Most IoT devices are expected to be deployed outdoors (in ﬁelds and
farms). Harsh work environments lead to the rapid degradation of IoT devices’ quality and
can lead to unexpected manufacturer failures. The mechanical safety of IoT devices and
systems must be ensured so they can withstand extremes of weather, such as temperature,
humidity, rainstorms, and ﬂoods [135]. In our opinion, new materials and technologies
need to continue to be studied to improve the durability of devices.
The open problems and challenges discussed in this section indicate that for IoT
to be widely deployed in the smart agriculture sector, there are still many issues to be
solved. Service providers need to reduce the service costs, more effectively exploiting
the information collected from the farm. On the other hand, farmers need to improve
their skills to be able to apply IoT solutions on their farm to enhance productivity and
farming efﬁciency. Researchers need to continually study and propose optimal solutions
and technologies to ensure IoT systems’ privacy and security and improve the durability of
IoT devices. These are really major challenges and exciting research topics in the future so
IoT can be widely applied in the smart agriculture sector.
5. Conclusions
In this study, we presented an overview of IoT and big data for the smart agriculture
sector. Several issues related to promoting IoT deployment in the agriculture sector have
been discussed in detail. Survey results indicate that many studies have been performed
to apply IoT for smart agriculture, aiming to enhance productivity, reduce human labour,
and improve production efﬁciency. The beneﬁts of applying IoT and big data in agriculture
were discussed. In addition, we also pointed out the challenges we need to overcome
to be able to accelerate the deployment of IoT in smart agriculture. However, there are
still some challenges that need to be addressed for IoT solutions to be affordable for the
majority of farmers, including small- and medium-scale farm owners. In addition, security
technologies need to be continuously improved, but in our opinion, the application of
IoT solutions for smart agriculture is inevitable and will enhance productivity, provide
clean and green foods, support food traceability, reduce human labour, and improve
production efﬁciency. On the other hand, this survey also points out some interesting
research directions for security and communication technologies for IoT. We think that
these will be very exciting research directions in the future.
Author Contributions: Conceptualization, V.K.Q., N.V.H., and A.M.; methodology, V.K.Q. and A.M.;
validation, N.M.Q., D.V.A., A.M. and N.T.B.; resources, A.M.; writing—original draft preparation,
V.K.Q., N.V.H., D.V.A., N.M.Q. and A.M.; writing—review and editing, V.K.Q., G.R., S.L. and A.M.;
visualization, V.K.Q., N.V.H., D.V.A., N.M.Q., N.T.B., G.R., S.L. and A.M.; supervision, A.M. All
authors have read and agreed to the published version of the manuscript.
Funding: This research received no external funding.
Institutional Review Board Statement: Not applicable.
Appl. Sci. 2022, 12, 3396
15 of 19
Informed Consent Statement: Not applicable.
Conﬂicts of Interest: The authors declare that they have no conﬂict of interest.
References
1.
Quy, V.K.; Nam, V.H.; Linh, D.M.; Ngoc, L.A.; Gwanggil, J. Wireless Communication Technologies for IoT in 5G: Vision,
Applications, and Challenges. Wirel. Commun. Mob. Comput. 2022, 2022, 3229294. [CrossRef]
2.
Sinche, S.; Raposo, D.; Armando, N.; Rodrigues, A.; Boavida, F.; Pereira, V.; Silva, J.S. A Survey of IoT Management Protocols and
Frameworks. IEEE Commun. Surv. Tutor. 2020, 22, 1168–1190. [CrossRef]
3.
Elijah, O.; Rahman, T.A.; Orikumhi, I.; Leow, C.Y.; Hindia, M.N. An Overview of Internet of Things (IoT) and Data Analytics in
Agriculture: Beneﬁts and Challenges. IEEE Internet Things J. 2018, 5, 3758–3773. [CrossRef]
4.
Li, W.; Logenthiran, T.; Phan, V.; Woo, W.L. A Novel Smart Energy Theft System (SETS) for IoT-based Smart Home. IEEE Internet
Things J. 2019, 6, 5531–5539. [CrossRef]
5.
Shin, D.; Yun, K.; Kim, J.; Astillo, P.V.; Kim, J.-N.; You, I. A Security Protocol for Route Optimization in DMM-Based Smart Home
IoT Networks. IEEE Access 2019, 7, 142531–142550. [CrossRef]
6.
An, J.G.; Le Gall, F.; Kim, J.; Yun, J.; Hwang, J.; Bauer, M.; Zhao, M.; Song, J.S. Toward Global IoT-Enabled Smart Cities
Interworking Using Adaptive Semantic Adapter. IEEE Internet Things J. 2019, 6, 5753–5765. [CrossRef]
7.
Cirillo, F.; Gomez, D.; Diez, L.; Maestro, I.E.; Gilbert, T.B.J.; Akhavan, R. Smart City IoT Services Creation through Large-Scale
Collaboration. IEEE Internet Things J. 2020, 7, 5267–5275. [CrossRef]
8.
Ammad, M.; Shah, M.A.; Islam, S.U.; Maple, C.; Alaulamie, A.A.; Rodrigues, J.J.P.C.; Mussadiq, S.; Tariq, U. A Novel Fog-Based
Multi-Level Energy-Efﬁcient Framework for IoT-Enabled Smart Environments. IEEE Access 2020, 8, 150010–150026. [CrossRef]
9.
Metallidou, C.K.; Psannis, K.E.; Egyptiadou, E.A. Energy Efﬁciency in Smart Buildings: IoT Approaches. IEEE Access 2020, 8,
63679–63699. [CrossRef]
10.
Quy, V.K.; Nam, V.H.; Linh, D.M.; Ban, N.T.; Han, N.D. Communication Solutions for Vehicle Ad-hoc Network in Smart Cities
Environment: A Comprehensive Survey. Wirel. Pers. Commun. 2022, 122, 2791–2815. [CrossRef]
11.
Kiani, F.; Seyyedabbasi, A.; Nematzadeh, S.; Candan, F.; Çevik, T.; Anka, F.A.; Randazzo, G.; Lanza, S.; Muzirafuti, A. Adaptive
Metaheuristic-Based Methods for Autonomous Robot Path Planning: Sustainable Ag-ricultural Applications. Appl. Sci. 2022, 12,
943. [CrossRef]
12.
Patle, K.S.; Saini, R.; Kumar, A.; Palaparthy, V.S. Field Evaluation of Smart Sensor System for Plant Disease Prediction Using
LSTM Network. IEEE Sens. J. 2022, 22, 3715–3725. [CrossRef]
13.
Vangala, A.; Das, A.K.; Kumar, N.; Alazab, M. Smart Secure Sensing for IoT-Based Agriculture: Blockchain Perspective. IEEE
Sens. J. 2020, 21, 17591–17607. [CrossRef]
14.
Citoni, B.; Fioranelli, F.; Imran, M.A.; Abbasi, Q.H. Internet of Things and LoRaWAN-Enabled Future Smart Farming. IEEE
Internet Things Mag. 2019, 2, 14–19. [CrossRef]
15.
Kumar, R.; Mishra, R.; Gupta, H.P.; Dutta, T. Smart Sensing for Agriculture: Applications, Advancements, and Challenges. IEEE
Consum. Electron. Mag. 2021, 10, 51–56. [CrossRef]
16.
Chang, Y.; Lai, Y. Campus Edge Computing Network Based on IoT Street Lighting Nodes. IEEE Syst. J. 2020, 14, 164–171.
[CrossRef]
17.
Sutjarittham, T.; Habibi Gharakheili, H.; Kanhere, S.S.; Sivaraman, V. Experiences with IoT and AI in a Smart Campus for
Optimizing Classroom Usage. IEEE Internet Things J. 2019, 6, 7595–7607. [CrossRef]
18.
Rani, S.; Ahmed, S.H.; Shah, S.C. Smart Health: A Novel Paradigm to Control the Chickungunya Virus. IEEE Internet Things J.
2019, 6, 1306–1311. [CrossRef]
19.
Zhou, Z.; Yu, H.; Shi, H. Human Activity Recognition Based on Improved Bayesian Convolution Network to Analyze Health
Care Data Using Wearable IoT Device. IEEE Access 2020, 8, 86411–86418. [CrossRef]
20.
Humayun, M.; Jhanjhi, N.; Hamid, B.; Ahmed, G. Emerging Smart Logistics and Transportation Using IoT and Blockchain. IEEE
Internet Things Mag. 2020, 3, 58–62. [CrossRef]
21.
Song, Y.; Yu, F.R.; Zhou, L.; Yang, X.; He, Z. Applications of the Internet of Things (IoT) in Smart Logistics: A Comprehensive
Survey. IEEE Internet Things J. 2021, 8, 4250–4274. [CrossRef]
22.
Shaﬁque, K.; Khawaja, B.A.; Sabir, F.; Qazi, S.; Mustaqim, M. Internet of Things (IoT) for Next-Generation Smart Systems: A
Review of Current Challenges, Future Trends & Prospects for Emerging 5G-IoT Scenarios. IEEE Access 2020, 8, 23022–23040.
[CrossRef]
23.
Available online: https://www.un.org/development/desa/en/news/population/world-population-prospects-2019.html (ac-
cessed on 7 May 2021).
24.
Yang, X.; Shu, L.; Chen, J.; Ferrag, M.A.; Wu, J.; Nurellari, E.; Huang, K. A Survey on Smart Agriculture: Development Modes,
Technologies, and Security and Privacy Challenges. IEEE/CAA J. Autom. Sin. 2021, 8, 273–302. [CrossRef]
25.
Ayaz, M.; Ammad-Uddin, M.; Sharif, Z.; Mansour, A.; Aggoune, E.-H.M. Internet-of-Things (IoT)-Based Smart Agriculture:
Toward Making the Fields Talk. IEEE Access 2019, 7, 129551–129583. [CrossRef]
26.
Alfred, R.; Obit, J.H.; Chin, C.P.-Y.; Haviluddin, H.; Lim, Y. Towards Paddy Rice Smart Farming: A Review on Big Data, Machine
Learning, and Rice Production Tasks. IEEE Access 2021, 9, 50358–50380. [CrossRef]
Appl. Sci. 2022, 12, 3396
16 of 19
27.
Zikria, Y.B.; Ali, R.; Afzal, M.K.; Kim, S.W. Next-Generation Internet of Things (IoT): Opportunities, Challenges, and Solutions.
Sensors 2021, 21, 1174. [CrossRef]
28.
Kour, V.P.; Arora, S. Recent Developments of the Internet of Things in Agriculture: A Survey. IEEE Access 2020, 8, 129924–129957.
[CrossRef]
29.
Saad, A.; Benyamina, A.E.H.; Gamatié, A. Water Management in Agriculture: A Survey on Current Challenges and Technological
Solutions. IEEE Access 2020, 8, 38082–38097. [CrossRef]
30.
Tyagi, S.K.S.; Mukherjee, A.; Pokhrel, S.R.; Hiran, K.K. An Intelligent and Optimal Resource Allocation Approach in Sensor
Networks for Smart Agri-IoT. IEEE Sens. J. 2020, 21, 17439–17446. [CrossRef]
31.
Li, X.; Pu, T.; Li, L.; Ao, J. Enhanced Sensitivity of GaN-Based Temperature Sensor by Using the Series Schottky Barrier Diode
Structure. IEEE Electron Device Lett. 2020, 41, 601–604. [CrossRef]
32.
Gopalakrishnan, S.; Waimin, J.; Raghunathan, N.; Bagchi, S.; Shakouri, A.; Rahimi, R. Battery-Less Wireless Chipless Sensor Tag
for Subsoil Moisture Monitoring. IEEE Sens. J. 2021, 21, 6071–6082. [CrossRef]
33.
Udutalapally, V.; Mohanty, S.P.; Pallagani, V.; Khandelwal, V. sCrop: A Novel Device for Sustainable Automatic Disease Prediction,
Crop Selection, and Irrigation in Internet-of-Agro-Things for Smart Agriculture. IEEE Sens. J. 2020, 21, 17525–17538. [CrossRef]
34.
Spachos, P.; Gregori, S. Integration of Wireless Sensor Networks and Smart UAVs for Precision Viticulture. IEEE Internet Comput.
2019, 23, 8–16. [CrossRef]
35.
Abdelnour, A.; Buchin, F.; Kaddour, D.; Tedjini, S. Improved Traceability Solution Based on UHF RFID for Cheese Production
Sector. IEEE J. Radio Freq. Identif. 2018, 2, 68–72. [CrossRef]
36.
Friha, O.; Ferrag, M.A.; Shu, L.; Maglaras, L.; Wang, X. Internet of Things for the Future of Smart Agriculture: A Comprehensive
Survey of Emerging Technologies. IEEE/CAA J. Autom. Sin. 2021, 8, 718–752. [CrossRef]
37.
Farooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey on the Role of IoT in Agriculture for the Implementation of
Smart Farming. IEEE Access 2019, 7, 156237–156271. [CrossRef]
38.
Mishra, D.; Zema, N.R.; Natalizio, E. A High-End IoT Devices Framework to Foster Beyond-Connectivity Capabilities in 5G/B5G
Architecture. IEEE Commun. Mag. 2021, 59, 55–61. [CrossRef]
39.
Javed, F.; Afzal, M.K.; Sharif, M.; Kim, B. Internet of Things (IoT) Operating Systems Support, Networking Technologies,
Applications, and Challenges: A Comparative Review. IEEE Commun. Surv. Tutor. 2018, 20, 2062–2100. [CrossRef]
40.
Poyen, F.B.; Ghosh, A.; Kundu, P.; Hazra, S.; Sengupta, N. Prototype Model Design of Automatic Irrigation Controller. IEEE Trans.
Instrum. Meas. 2021, 70, 9502217. [CrossRef]
41.
Wang, Y.; Rajib, S.M.S.M.; Collins, C.; Grieve, B. Low-Cost Turbidity Sensor for Low-Power Wireless Monitoring of Fresh-Water
Courses. IEEE Sens. J. 2018, 18, 4689–4696. [CrossRef]
42.
El-Basioni, B.M.M.; El-Kader, S.M.A. Laying the Foundations for an IoT Reference Architecture for Agricultural Application
Domain. IEEE Access 2020, 8, 190194–190230. [CrossRef]
43.
Alam, M.M.; Malik, H.; Khan, M.I.; Pardy, T.; Kuusik, A.; Le Moullec, Y. A Survey on the Roles of Communication Technologies
in IoT-Based Personalized Healthcare Applications. IEEE Access 2018, 6, 36611–36631. [CrossRef]
44.
Chettri, L.; Bera, R. A Comprehensive Survey on Internet of Things (IoT) Toward 5G Wireless Systems. IEEE Internet Things J.
2020, 7, 16–32. [CrossRef]
45.
Pal, A.; Kant, K. NFMI: Connectivity for Short-Range IoT Applications. Computer 2019, 52, 63–67. [CrossRef]
46.
Collotta, M.; Pau, G.; Talty, T.; Tonguz, O.K. Bluetooth 5: A Concrete Step Forward toward the IoT. IEEE Commun. Mag. 2018, 56,
125–131. [CrossRef]
47.
Bacco, M.; Berton, A.; Gotta, A.; Caviglione, L. IEEE 802.15.4 Air-Ground UAV Communications in Smart Farming Scenarios.
IEEE Commun. Lett. 2018, 22, 1910–1913. [CrossRef]
48.
Gente, R.; Busch, S.F.; Stubling, E.-M.; Schneider, L.M.; Hirschmann, C.B.; Balzer, J.C.; Koch, M. Quality Control of Sugar Beet
Seeds With THz Time-Domain Spectroscopy. IEEE Trans. Terahertz Sci. Technol. 2016, 6, 754–756. [CrossRef]
49.
Afsharinejad, A.; Davy, A.; Naftaly, M. Variability of Terahertz Transmission Measured in Live Plant Leaves. IEEE Geosci. Remote
Sens. Lett. 2017, 14, 636–638. [CrossRef]
50.
Wang, X.; Zhang, J.; Yu, Z.; Mao, S.; Periaswamy, S.C.G.; Patton, J. On Remote Temperature Sensing Using Commercial UHF
RFID Tags. IEEE Internet Things J. 2019, 6, 10715–10727. [CrossRef]
51.
Ali, S.; Glass, T.; Parr, B.; Potgieter, J.; Alam, F. Low Cost Sensor with IoT LoRaWAN Connectivity and Machine Learning-Based
Calibration for Air Pollution Monitoring. IEEE Trans. Instrum. Meas. 2021, 70, 5500511. [CrossRef]
52.
Joris, L.; Dupont, F.; Laurent, P.; Bellier, P.; Stoukatch, S.; Redouté, J. An Autonomous Sigfox Wireless Sensor Node for
Environmental Monitoring. IEEE Sens. Lett. 2019, 3, 5500604. [CrossRef]
53.
Popli, S.; Jha, R.K.; Jain, S. A Survey on Energy Efﬁcient Narrowband Internet of Things (NBIoT): Architecture, Application &
Challenges. IEEE Access 2019, 7, 16739–16776. [CrossRef]
54.
Sundaram, J.P.S.; Du, W.; Zhao, Z. A Survey on LoRa Networking: Research Problems, Current Solutions, and Open Issues. IEEE
Commun. Surv. Tutor. 2020, 22, 371–388. [CrossRef]
55.
Xing, C.; Li, F. Unlicensed Spectrum-Sharing Mechanism Based on Wi-Fi Security Requirements Implemented Using Device to
Device Communication Technology. IEEE Access 2020, 8, 135025–135036. [CrossRef]
56.
Jiang, X.; Zhang, H.; Yi, E.A.B.; Raghunathan, N.; Mousoulis, C.; Chaterji, S.; Peroulis, D.; Shakouri, A.; Bagchi, S. Hybrid
Low-Power Wide-Area Mesh Network for IoT Applications. IEEE Internet Things J. 2021, 8, 901–915. [CrossRef]
Appl. Sci. 2022, 12, 3396
17 of 19
57.
Lagen, S.; Giupponi, L.; Goyal, S.; Patriciello, N.; Bojovic, B.; Demir, A.; Beluri, M. New Radio Beam-Based Access to Unlicensed
Spectrum: Design Challenges and Solutions. IEEE Commun. Surv. Tutor. 2020, 22, 8–37. [CrossRef]
58.
Shah, S.W.H.; Mian, A.N.; Crowcroft, J. Statistical QoS Guarantees for Licensed-Unlicensed Spectrum Interoperable D2D
Communication. IEEE Access 2020, 8, 27277–27290. [CrossRef]
59.
Lu, X.; Petrov, V.; Moltchanov, D.; Andreev, S.; Mahmoodi, T.; Dohler, M. 5G-U: Conceptualizing Integrated Utilization of Licensed
and Unlicensed Spectrum for Future IoT. IEEE Commun. Mag. 2019, 57, 92–98. [CrossRef]
60.
Razavieh, A.; Chen, Y.; Ethirajan, T.; Gu, M.; Cimino, S.; Shimizu, T.; Hassan, M.K.; Morshed, T.; Singh, J.; Zheng, W.; et al.
Extremely-Low Threshold Voltage FinFET for 5G mmWave Applications. IEEE J. Electron Devices Soc. 2021, 9, 165–169. [CrossRef]
61.
Patriciello, N.; Lagén, S.; Bojovi´c, B.; Giupponi, L. NR-U and IEEE 802.11 Technologies Coexistence in Unlicensed mmWave
Spectrum: Models and Evaluation. IEEE Access 2020, 8, 71254–71271. [CrossRef]
62.
Mezzavilla, M.; Polese, M.; Zanella, A.; Dhananjay, A.; Rangan, S.; Kessler, C.; Rappaport, T.S.; Zorzi, M. Public Safety
Communications above 6 GHz: Challenges and Opportunities. IEEE Access 2018, 6, 316–329. [CrossRef]
63.
Kassim, M.R.M. IoT Applications in Smart Agriculture: Issues and Challenges. In Proceedings of the IEEE Conference on Open
Systems (ICOS), Kota Kinabalu, Malaysia, 17–19 November 2020; pp. 19–24. [CrossRef]
64.
Boursianis, A.D.; Papadopoulou, M.S.; Gotsis, A.; Wan, S.; Sarigiannidis, P.; Nikolaidis, S.; Goudos, S.K. Smart Irrigation System
for Precision Agriculture—The AREThOU5A IoT Platform. IEEE Sens. J. 2020, 21, 17539–17547. [CrossRef]
65.
López, I.D.; Figueroa, A.; Corrales, J.C. Multi-Dimensional Data Preparation: A Process to Support Vulnerability Analysis and
Climate Change Adaptation. IEEE Access 2020, 8, 87228–87242. [CrossRef]
66.
Bhat, S.A.; Huang, N.F. Big Data and AI Revolution in Precision Agriculture: Survey and Challenges. IEEE Access 2021, 9,
110209–110222. [CrossRef]
67.
Roopaei, M.; Rad, P.; Choo, K.R. Cloud of Things in Smart Agriculture: Intelligent Irrigation Monitoring by Thermal Imaging.
IEEE Cloud Comput. 2017, 4, 10–15. [CrossRef]
68.
Zhang, X.; Cao, Z.; Dong, W. Overview of Edge Computing in the Agricultural Internet of Things: Key Technologies, Applications,
Challenges. IEEE Access 2020, 8, 141748–141761. [CrossRef]
69.
Quy, V.K.; Hau, N.V.; Anh, D.V.; Ngoc, L.A. Smart healthcare IoT applications based on fog computing: Architecture, applications
and challenges. Complex Intell. Syst. 2021. [CrossRef]
70.
Kopishynska, O.; Utkin, Y.; Galych, O.; Marenych, M.; Sliusar, I. Main Aspects of the Creation of Managing Information System at
the Implementation of Precision Farming. In Proceedings of the 2020 IEEE 11th International Conference on Dependable Systems,
Services and Technologies (DESSERT), Kyiv, Ukraine, 14–18 May 2020; pp. 404–410. [CrossRef]
71.
Soeparno, H.; Perbangsa, A.S.; Pardamean, B. Best Practices of Agricultural Information System in the Context of Knowledge
and Innovation. In Proceedings of the 2018 International Conference on Information Management and Technology (ICIMTech),
Jakarta, Indonesia, 3–5 September 2018; pp. 489–494. [CrossRef]
72.
Zhang, F.; Cao, N. Application and Research Progress of Geographic Information System (GIS) in Agriculture. In Proceedings of
the 2019 8th International Conference on Agro-Geoinformatics (Agro-Geoinformatics), Istanbul, Turkey, 16–19 July 2019; pp. 1–5.
[CrossRef]
73.
Available online: http://www.onfarm.com (accessed on 7 May 2021).
74.
Available online: https://www.farmobile.com (accessed on 7 May 2021).
75.
Available online: https://www.thoughtworks.com/clients/silent-herdsman (accessed on 7 May 2021).
76.
Available online: https://cropx.com (accessed on 7 May 2021).
77.
Available online: https://www.farmx.co (accessed on 7 May 2021).
78.
Available online: http://www.easyfarm.com (accessed on 7 May 2021).
79.
Available online: https://www.kaaproject.org (accessed on 7 May 2021).
80.
Available online: https://farmlogs.com (accessed on 7 May 2021).
81.
Sengupta, A.; Debnath, B.; Das, A.; De, D. FarmFox: A Quad-Sensor based IoT box for Precision Agriculture. IEEE Consum.
Electron. Mag. 2021, 10, 63–68. [CrossRef]
82.
Kaiyi, L.; Hengyuan, K.; Huansheng, M.; Fan, Z. Design of a New Generation of Weather Radar Intelligent Temperature and
Humidity Monitoring System Based on ZigBee. In Proceedings of the 2019 International Conference on Meteorology Observations
(ICMO), Chengdu, China, 28–31 December 2019; pp. 1–3. [CrossRef]
83.
Dong, Y.; Xu, F.; Liu, L.; Du, X.; Ren, B.; Guo, A.; Geng, Y.; Ruan, C.; Ye, H.; Huang, W.; et al. Automatic System for Crop Pest and
Disease Dynamic Monitoring and Early Forecasting. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2020, 13, 4410–4418. [CrossRef]
84.
Ghandar, A.; Ahmed, A.; Zulﬁqar, S.; Hua, Z.; Hanai, M.; Theodoropoulos, G. A Decision Support System for Urban Agriculture
Using Digital Twin: A Case Study with Aquaponics. IEEE Access 2021, 9, 35691–35708. [CrossRef]
85.
Pasha, A.K.; Mulyana, E.; Hidayat, C.; Ramdhani, M.A.; Kurahman, O.T.; Adhipradana, M. System Design of Controlling and
Monitoring on Aquaponic Based on Internet of Things. In Proceedings of the 2018 4th International Conference on Wireless and
Telematics (ICWT), Nusa Dua, Bali, Indonesia, 12–13 July 2018; pp. 1–5. [CrossRef]
86.
Lee, C.; Jhang, J. System Design for Internet of Things Assisted Urban Aquaponics Farming. In Proceedings of the 2019 IEEE 8th
Global Conference on Consumer Electronics (GCCE), Osaka, Japan, 15–18 October 2019; pp. 986–987. [CrossRef]
87.
Wei, Y.; Li, W.; An, D.; Li, D.; Jiao, Y.; Wei, Q. Equipment and Intelligent Control System in Aquaponics: A Review. IEEE Access
2019, 7, 169306–169326. [CrossRef]
Appl. Sci. 2022, 12, 3396
18 of 19
88.
Marcu, A.-E.; Suciu, G.; Olteanu, E.; Miu, D.; Drosu, A.; Marcu, I. IoT System for Forest Monitoring. In Proceedings of the 42nd
International Conference on Telecommunications and Signal Processing (TSP), Budapest, Hungary, 1–3 July 2019; pp. 629–632.
[CrossRef]
89.
Zou, W.; Jing, W.; Chen, G.; Lu, Y.; Song, H. A Survey of Big Data Analytics for Smart Forestry. IEEE Access 2019, 7, 46621–46636.
[CrossRef]
90.
Essa, S.; Petra, R.; Uddin, M.R.; Suhaili, W.S.H.; Ilmi, N.I. IoT-Based Environmental Monitoring System for Brunei Peat Swamp
Forest. In Proceedings of the 2020 International Conference on Computer Science and Its Application in Agriculture (ICOSICA),
Bogor, Indonesia, 16–17 September 2020; pp. 1–5. [CrossRef]
91.
Marx, A.; Tetteh, G.O. A Forest Vitality and Change Monitoring Tool Based on RapidEye Imagery. IEEE Geosci. Remote Sens. Lett.
2017, 14, 801–805. [CrossRef]
92.
Chaudhry, A.A.; Mumtaz, R.; Hassan Zaidi, S.M.; Tahir, M.A.; Muzammil School, S.H. Internet of Things (IoT) and Machine
Learning (ML) enabled Livestock Monitoring. In Proceedings of the 2020 IEEE 17th International Conference on Smart Com-
munities: Improving Quality of Life Using ICT, IoT and AI (HONET), Charlotte, NC, USA, 14–16 December 2020; pp. 151–155.
[CrossRef]
93.
Yang, Y.; Ren, R.; Johnson, P.M. VetLink: A Livestock Disease-Management System. IEEE Potentials 2020, 39, 28–34. [CrossRef]
94.
Ma, S.; Yao, Q.; Masuda, T.; Higaki, S.; Yoshioka, K.; Arai, S.; Takamatsu, S.; Itoh, T. Development of Noncontact Body Temperature
Monitoring and Prediction System for Livestock Cattle. IEEE Sens. J. 2021, 21, 9367–9376. [CrossRef]
95.
Lee, G.; Kim, M.; Koroki, K.; Ishimoto, A.; Sakamoto, S.H.; Ieiri, S. Wireless IC Tag Based Monitoring System for Individual Pigs
in Pig Farm. In Proceedings of the 2019 IEEE 1st Global Conference on Life Sciences and Technologies (LifeTech), Osaka, Japan,
12–14 March 2019; pp. 168–170. [CrossRef]
96.
Tradigo, G.; Vizza, P.; Veltri, P.; Lambardi, P.; Caligiuri, F.M.; Caligiuri, G.; Guzzi, P.H. SISTABENE: An information system for the
traceability of agricultural food production. In Proceedings of the 2019 IEEE International Conference on Bioinformatics and
Biomedicine (BIBM), San Diego, CA, USA, 18–21 November 2019; pp. 2304–2309. [CrossRef]
97.
Wang, L.; Xu, L.; Zheng, Z.; Liu, S.; Li, X.; Cao, L.; Li, J.; Sun, C. Smart Contract-Based Agricultural Food Supply Chain Traceability.
IEEE Access 2021, 9, 9296–9307. [CrossRef]
98.
Cui, P.; Dixon, J.; Guin, U.; Dimase, D. A Blockchain-Based Framework for Supply Chain Provenance. IEEE Access 2019, 7,
157113–157125. [CrossRef]
99.
Abdulhussein, A.B.; Hadi, A.K.; Ilyas, M. Design a Tracing System for a Seed Supply Chain Based on Blockchain. In Proceedings
of the 2020 3rd International Conference on Engineering Technology and its Applications (IICETA), Najaf, Iraq, 6–7 September
2020; pp. 209–214. [CrossRef]
100. Kong, S.; López-Salcedo, J.A.; Wu, Y.; Kim, E. IEEE Access Special Section Editorial: GNSS, Localization, and Navigation
Technologies. IEEE Access 2019, 7, 131649–131652. [CrossRef]
101. Alatise, M.B.; Hancke, G.P. A Review on Challenges of Autonomous Mobile Robot and Sensor Fusion Methods. IEEE Access 2020,
8, 39830–39846. [CrossRef]
102. Kim, J.; Kim, S.; Ju, C.; Son, H.I. Unmanned Aerial Vehicles in Agriculture: A Review of Perspective of Platform, Control, and
Applications. IEEE Access 2019, 7, 105100–105115. [CrossRef]
103. Zhou, K.; Meng, Z.; He, M.; Hou, J.; Li, T. Design and Test of a Sorting Device Based on Machine Vision. IEEE Access 2020, 8,
27178–27187. [CrossRef]
104. Kurtser, P.; Ringdahl, O.; Rotstein, N.; Berenstein, R.; Edan, Y. In-Field Grape Cluster Size Assessment for Vine Yield Estimation
Using a Mobile Robot and a Consumer Level RGB-D Camera. IEEE Robot. Autom. Lett. 2020, 5, 2031–2038. [CrossRef]
105. Zhou, X.; Zhou, J. Data-Driven Driving State Control for Unmanned Agricultural Logistics Vehicle. IEEE Access 2020, 8,
65530–65543. [CrossRef]
106. Favenza, A.; Imam, R.; Dovis, F.; Pini, M. Detecting water using UAV-based GNSS-Reﬂectometry data and Artiﬁcial Intelligence.
In Proceedings of the 2019 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor), Portici, Italy,
24–26 October 2019; pp. 7–12. [CrossRef]
107. Available online: http://www.claasofamerica.com (accessed on 7 May 2021).
108. Tripathy, P.K.; Tripathy, A.K.; Agarwal, A.; Mohanty, S.P. MyGreen: An IoT-Enabled Smart Greenhouse for Sustainable Agriculture.
IEEE Consum. Electron. Mag. 2021, 10, 57–62. [CrossRef]
109. Geng, X.; Zhang, Q.; Wei, Q.; Zhang, T.; Cai, Y.; Liang, Y.; Sun, X. A Mobile Greenhouse Environment Monitoring System Based
on the Internet of Things. IEEE Access 2019, 7, 135832–135844. [CrossRef]
110. Fei, X.; Xiao, W.; Yong, X. Development of Energy Saving and Rapid Temperature Control Technology for Intelligent Greenhouses.
IEEE Access 2021, 9, 29677–29685. [CrossRef]
111. Subahi, A.F.; Bouazza, K.E. An Intelligent IoT-Based System Design for Controlling and Monitoring Greenhouse Temperature.
IEEE Access 2020, 8, 125488–125500. [CrossRef]
112. Misra, N.N.; Dixit, Y.; Al-Mallahi, A.; Bhullar, M.S.; Upadhyay, R.; Martynenko, A. IoT, Big Data and Artiﬁcial Intelligence in
Agriculture and Food Industry. IEEE Internet Things J. 2020, 1. [CrossRef]
113. Ullah, I.; Fayaz, M.; Naveed, N.; Kim, D. ANN Based Learning to Kalman Filter Algorithm for Indoor Environment Prediction in
Smart Greenhouse. IEEE Access 2020, 8, 159371–159388. [CrossRef]
Appl. Sci. 2022, 12, 3396
19 of 19
114. Muñoz, M.; Guzmán, J.L.; Sánchez, J.A.; Rodríguez, F.; Torres, M.; Berenguel, M. A New IoT-based Platform for Greenhouse Crop
Production. IEEE Internet Things J. 2020, 1. [CrossRef]
115. Bai, X.; Wang, Z.; Sheng, L.; Wang, Z. Reliable Data Fusion of Hierarchical Wireless Sensor Networks with Asynchronous
Measurement for Greenhouse Monitoring. IEEE Trans. Control Syst. Technol. 2019, 27, 1036–1046. [CrossRef]
116. Turgut, D.; Boloni, L. Value of Information and Cost of Privacy in the Internet of Things. IEEE Commun. Mag. 2017, 55, 62–66.
[CrossRef]
117. Rousi, M.; Sitokonstantinou, V.; Meditskos, G.; Papoutsis, I.; Gialampoukidis, I.; Koukos, A.; Karathanassi, V.; Drivas, T.; Vrochidis,
S.; Kontoes, C.; et al. Semantically Enriched Crop Type Classiﬁcation and Linked Earth Observation Data to Support the Common
Agricultural Policy Monitoring. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2021, 14, 529–552. [CrossRef]
118. Ammad Uddin, M.; Ayaz, M.; Aggoune, E.-H.M.; Mansour, A.; Le Jeune, D. Affordable Broad Agile Farming System for Rural
and Remote Area. IEEE Access 2019, 7, 127098–127116. [CrossRef]
119. Joshi, A.; Dandekar, I.; Hargude, N.; Shrotri, A.P.; Dandekar, A.R. Application of Internet of the Things(IOT) for the Water
Conservation and Entrepreneurship in the Rural Area. In Proceedings of the 2019 IEEE Pune Section International Conference
(PuneCon), Pune, India, 18–20 December 2019; pp. 1–4. [CrossRef]
120. De Lima, C.; Belot, D.; Berkvens, R.; Bourdoux, A.; Dardari, D.; Guillaud, M.; Isomursu, M.; Lohan, E.-S.; Miao, Y.; Barreto, A.N.;
et al. Convergent Communication, Sensing and Localization in 6G Systems: An Overview of Technologies, Opportunities and
Challenges. IEEE Access 2021, 9, 26902–26925. [CrossRef]
121. Sandal, Y.S.; Pusane, A.E.; Kurt, G.K.; Benedetto, F. Reputation Based Attacker Identiﬁcation Policy for Multi-Access Edge
Computing in Internet of Things. IEEE Trans. Veh. Technol. 2020, 69, 15346–15356. [CrossRef]
122. Wang, J.; Hao, S.; Wen, R.; Zhang, B.; Zhang, L.; Hu, H.; Lu, R. IoT-Praetor: Undesired Behaviors Detection for IoT Devices. IEEE
Internet Things J. 2021, 8, 927–940. [CrossRef]
123. Jia, Y.; Zhong, F.; Alrawais, A.; Gong, B.; Cheng, X. FlowGuard: An Intelligent Edge Defense Mechanism against IoT DDoS
Attacks. IEEE Internet Things J. 2020, 7, 9552–9562. [CrossRef]
124. Agrawal, N.; Tapaswi, S. Defense Mechanisms against DDoS Attacks in a Cloud Computing Environment: State-of-the-Art and
Research Challenges. IEEE Commun. Surv. Tutor. 2019, 21, 3769–3795. [CrossRef]
125. Somani, G.; Gaur, M.S.; Sanghi, D.; Conti, M.; Rajarajan, M.; Buyya, R. Combating DDoS Attacks in the Cloud: Requirements,
Trends, and Future Directions. IEEE Cloud Comput. 2017, 4, 22–32. [CrossRef]
126. Wang, J.; Zhu, R.; Liu, S. A Differentially Private Unscented Kalman Filter for Streaming Data in IoT. IEEE Access 2018, 6,
6487–6495. [CrossRef]
127. Yu, Y.; Ding, Y.; Zhao, Y.; Li, Y.; Zhao, Y.; Du, X.; Guizani, M. LRCoin: Leakage-Resilient Cryptocurrency Based on Bitcoin for
Data Trading in IoT. IEEE Internet Things J. 2019, 6, 4702–4710. [CrossRef]
128. Ali, I.; Kaur, S.; Khamparia, A.; Gupta, D.; Kumar, S.; Khanna, A.; Al-Turjman, F. Security Challenges and Cyber Forensic
Ecosystem in IoT Driven BYOD Environment. IEEE Access 2020, 8, 172770–172782. [CrossRef]
129. Neshenko, N.; Bou-Harb, E.; Crichigno, J.; Kaddoum, G.; Ghani, N. Demystifying IoT Security: An Exhaustive Survey on IoT
Vulnerabilities and a First Empirical Look on Internet-Scale IoT Exploitations. IEEE Commun. Surv. Tutor. 2019, 21, 2702–2733.
[CrossRef]
130. Chaterji, S.; DeLay, N.; Evans, J.; Mosier, N.; Engel, B.; Buckmaster, D.; Ladisch, M.R.; Chandra, R. Lattice: A Vision for Machine
Learning, Data Engineering, and Policy Considerations for Digital Agriculture at Scale. IEEE Open J. Comput. Soc. 2021, 2, 227–240.
[CrossRef]
131. Jin, B.; Jiang, D.; Xiong, J.; Chen, L.; Li, Q. D2D Data Privacy Protection Mechanism Based on Reliability and Homomorphic
Encryption. IEEE Access 2018, 6, 51140–51150. [CrossRef]
132. Harn, L.; Hsu, C.-F.; Xia, Z.; He, Z. He Lightweight Aggregated Data Encryption for Wireless Sensor Networks (WSNs). IEEE
Sens. Lett. 2021, 5, 1–4. [CrossRef]
133. Jia, B.; Zhang, X.; Liu, J.; Zhang, Y.; Huang, K.; Liang, Y. Liang Blockchain-Enabled Federated Learning Data Protection
Aggregation Scheme With Differential Privacy and Homomorphic Encryption in IioT. IEEE Trans. Ind. Inform. 2022, 18, 4049–4058.
[CrossRef]
134. Chen, L.; Thombre, S.; Jarvinen, K.; Lohan, E.S.; Alén-Savikko, A.; Leppakoski, H.; Bhuiyan, M.Z.H.; Bu-Pasha, S.; Ferrara, G.N.;
Honkala, S.; et al. Robustness, Security and Privacy in Location-Based Services for Future IoT: A Survey. IEEE Access 2017, 5,
8956–8977. [CrossRef]
135. Ballal, K.D.; Dittmann, L.; Ruepp, S.; Petersen, M.N. IoT Devices Reliability Study: Multi-RAT Communication. In Proceedings of
the 2020 IEEE 6th World Forum on Internet of Things (WF-IoT), New Orleans, LA, USA, 2–16 June 2020; pp. 1–2. [CrossRef]


Paper 3:
- APA Citation: None
  Main Objective: address latency, real-time decision-making and reduce reliance on cloud connectivity
  Study Location: None
  Data Sources: None
  Technologies Used: edge computing and fog computing
  Key Findings: None
  Extract 1: Edge computing and fog computing are the state-of-the-art techniques to overcome these issues; which reduce the computational burden of cloud.
  Extract 2: The main goal of fog computing is to conserve energy and bandwidth, which helps to increase the quality of service to the end users.
  Limitations: None
  Relevance Evaluation: 0.9-1.0: Exceptionally relevant - Comprehensively addresses all key aspects of the point and review.
  Relevance Score: 0.95
  Inline Citation: None
  Explanation: Edge computing and fog computing help to reduce latency, enable real-time decision-making, and reduce reliance on cloud connectivity in automated irrigation management systems because they reduce the computational burden of cloud. The main goal of fog computing is to conserve energy and bandwidth, which helps to increase the quality of service to the end users. In [5], an energy-efﬁcient architecture of the Fog of Everything was presented, which was comprised of six layers.

 Full Text: >
sensors
Review
Precision Agriculture Techniques and Practices:
From Considerations to Applications
Uferah Shaﬁ 1
, Raﬁa Mumtaz 1,*
, José García-Nieto 2
, Syed Ali Hassan 1
,
Syed Ali Raza Zaidi 3 and Naveed Iqbal 1
1
National University of Science and Technology (NUST), School of Electrical Engineering and Computer
Science, Islamabad 44000, Pakistan
2
Department of Languages and Computer Sciences, Ada Byron Research Building, University of Málaga,
29016 Málaga, Spain
3
School of Electronic and Electrical Engineering, University of Leeds, Leeds LS2 9JT, UK
*
Correspondence: raﬁa.mumtaz@seecs.edu.pk
Received: 14 July 2019; Accepted: 27 August 2019; Published: 2 September 2019


Abstract: Internet of Things (IoT)-based automation of agricultural events can change the agriculture
sector from being static and manual to dynamic and smart, leading to enhanced production with
reduced human efforts. Precision Agriculture (PA) along with Wireless Sensor Network (WSN) are the
main drivers of automation in the agriculture domain. PA uses speciﬁc sensors and software to ensure
that the crops receive exactly what they need to optimize productivity and sustainability. PA includes
retrieving real data about the conditions of soil, crops and weather from the sensors deployed in the
ﬁelds. High-resolution images of crops are obtained from satellite or air-borne platforms (manned
or unmanned), which are further processed to extract information used to provide future decisions.
In this paper, a review of near and remote sensor networks in the agriculture domain is presented
along with several considerations and challenges. This survey includes wireless communication
technologies, sensors, and wireless nodes used to assess the environmental behaviour, the platforms
used to obtain spectral images of crops, the common vegetation indices used to analyse spectral
images and applications of WSN in agriculture. As a proof of concept, we present a case study
showing how WSN-based PA system can be implemented. We propose an IoT-based smart solution
for crop health monitoring, which is comprised of two modules. The ﬁrst module is a wireless sensor
network-based system to monitor real-time crop health status. The second module uses a low altitude
remote sensing platform to obtain multi-spectral imagery, which is further processed to classify
healthy and unhealthy crops. We also highlight the results obtained using a case study and list the
challenges and future directions based on our work.
Keywords: smart agriculture; precision agriculture; vegetation index; Internet of Things
1. Introduction
The rapidly-growing human population has increased food demands for human survival on
the Earth. Meeting the food requirements with limited resources of the planet is a big challenge [1].
Several state-of-the-art technologies are being incorporated in the agriculture domain to enhance
the productivity to cope with this challenge. Precision Agriculture (PA) is comprised of near and
remote sensing techniques using IoT sensors, which help to monitor crop states at multiple growth
levels. PA involves the acquisition and processing of a large amount of data related to crop health.
Multiple parameters are involved in plants health, including water level, temperature and others.
PA enables a farmer to know precisely what parameters are needed for healthy crop, where these
parameters are needed and in what amount at a particular instance of time. This requires collecting
Sensors 2019, 19, 3796; doi:10.3390/s19173796
www.mdpi.com/journal/sensors
Sensors 2019, 19, 3796
2 of 25
massive information from different sources and different parts of the ﬁeld such as soil nutrients, the
presence of pests and weeds, chlorophyll content in plants and some weather conditions. All collected
information needs to be analysed to produce agronomic recommendations. For instance, given the
developmental stage of plants, their level of greenness (chlorophyll content) reveals the nutrients
needed. This information is combined with the characteristics of the soil where the plant is located
along with weather forecast. All collected information is further used to determine how much of a
certain fertilizer should be applied to that plant on the next day. The delivery of agronomic information
on the right time to farmer and ensuring that he/she applies these recommendations are key to
enhancing the yields.
The foremost driver of PA is a WSN, which is a network of multiple wireless nodes connected
together to monitor the physical parameters of environment. Each wireless node is comprised of a
radio transceiver, a micro-controller, sensor(s), an antenna, along with other circuitry that enables it
to communicate with some gateway to transmit information collected by the sensor(s) [2]. Sensors
measure the physical parameters and send the collected information to the controller, which further
transmits this information to the cloud or a portable device. The agriculture sector has multiple
requirements comprised of soil statistics, crops’ nature, weather conditions, fertilizer types and water
requirements. Crops have diverse requirements depending on different crops on the same land and the
same plant on different lands with different weather conditions. Sensors monitor the varying behaviour
of these crop parameters. Due to rapid advancement in WSN technologies, the size and the cost of
sensors have reduced, which make it feasible to implement them in many sectors of life including
agriculture. The most common sensors used in the agriculture domain that capture environmental
parameters related to crops [3] are listed in Table 1.
In general, a WSN consists of one or more wireless nodes that are further connected with sensors.
These nodes are tiny devices that are responsible for collecting data. Nodes are divided into two types,
a source node that collects the data, and the other is sink or gateway node, which receives data from the
source nodes. A sink node has more computational power compared to a source node. However, there
are energy, memory, power, size, data rate and price constraints when choosing wireless nodes. Table 2
shows a comparison of wireless nodes along with their common speciﬁcations [3]. Among all wireless
nodes presented in Table 2, MICA2 is considered to be more suitable as compared to others because of
its large number of expansion connectors, which makes it suitable to connect with several sensors.
Many applications using WSN have been proposed since the last decade to monitor crops’ health
remotely. In [4], a cyber-physical system was presented for monitoring of a potato crop. Cyber physical
systems can be expressed as smart systems that are comprised of software, hardware and physical
components, integrated together to sense the varying states of the real world. The proposed system
consists of three layers: the ﬁrst layer is the physical layer, in which all sensory data are collected;
the second layer is the network layer in which data are transmitted to the cloud; the third layer is
the decision layer in which the data are analysed and processed to make decisions according to the
observations.
There are several challenges in IoT-based systems due to exponential increasing devices. As in
a typical IoT network, every node transmits data to the remote cloud, which results in cloud
congestion, and the main challenges underlying the IOT-based system are latency with minimum
power requirements, better usage of bandwidth and intermittent Internet connectivity. Fog computing
and edge computing are the state-of-the-art techniques to overcome these issues; which reduce the
computational burden of cloud. The main goal of fog computing is to conserve energy and bandwidth,
which helps to increase the quality of service to the end users. In [5], an energy-efﬁcient architecture of
the Fog of Everything was presented, which was comprised of six layers. The ﬁrst layer was an Internet
Of Everything (IOE) layer, where things (could be ﬁxed, mobile or nomadic) functioned under multiple
spatially-distributed clusters. The second was a wireless access network that supported Thing to Fog
(T2F) and Fog to Thing (F2T) communication over the wireless channel. In the third layer, the connected
fog nodes behaved such as a virtualized cluster. There was an inter-fog backbone in the fourth layer,
Sensors 2019, 19, 3796
3 of 25
which was responsible for connectivity among fog nodes. The next layer was the virtualization layer,
which provided each connected thing with the ability to augment its limited resource set, exploiting
the computation capability at the virtual clone. In the last layer, there was an overlay inter-clone
virtual network that empowered Peer to Peer (P2P) communication. Then, a protocol stack for FOE
was presented, which was further tested by creating a small prototype named as V-FOE and simulated
on the iFogsim toolkit. The results provided strong evidence for the effectiveness of the proposed
framework and more energy efﬁciency with reduced failure rate and delay.
Table 1. Wireless nodes used in the agriculture domain.
Sr #
Sensor Name
Parameters Captured
1
ECH2O soil moisture sensor
Soil Temperature, Soil Moisture, Conductivity
2
Hydra probe II soil sensor
Soil Temperature, Salinity level, Soil Moisture,
Conductivity
3
MP406 Soil moisture sensor
Soil Temperature, Soil Moisture
4
EC sensor (EC250)
Soil Temperature, Salinity level, Soil Moisture,
Conductivity
5
Pogo portable soil sensor
Soil Temperature, Soil Moisture
6
107-L temperature Sensor (BetaTherm 100K6A1B
Plant Temperature
Thermistor)
7
237 leaf wetness sensor
Plant Moisture, Plant Wetness, Plant
Temperature
8
SenseH2TM hydrogen sensor
Hydrogen, Plant Wetness, CO2, Plant
Temperature
9
Field scout CM1000TM
Photosynthesis
10
YSI 6025 chlorophyll sensor
Photosynthesis
11
LW100, leaf wetness sensor
Plant Moisture, Plant Wetness, Plant
Temperature
12
TT4 multi-sensor thermocouple
Plant Moisture, Plant Temperature
13
TPS-2 portable photosynthesis
Photosynthesis, Plant Moisture, CO2,
14
LT-2 M (leaf temperature sensor)
Plant Temperature
15
PTM-48A photosynthesis monitor
Photosynthesis, Plant Moisture, Plant Wetness,
CO2, Plant Temperature
16
Cl-340 hand-held photosynthesis
Photosynthesis, Plant Moisture, Plant Wetness,
CO2, Plant Temperature, Hydrogen level in
Plant
17
CM-100 Compact Weather Sensor
Air Temperature, Air Humidity, Wind Speed,
Air Pressure
18
HMP45C (Vaisala’s HUMICAP R⃝ H-chip)
Air Temperature, Air Humidity, Air Pressure
19
Met Station One (MSO)
Air Humidity, Air Temperature, Wind Speed,
Air Pressure
20
XFAM-115KPASR
Air Temperature, Air Pressure, Air Humidity
21
SHT71, SHT75 (Humidity and temperature
sensor)
Humidity and Temperature Sensor
22
107-L Temperature Sensor (BetaTherm 100K6A1B
thermistor)
Air Temperature
23
Cl-340 hand-held photosynthesis
Air Temperature, Air Humidity
The energy efﬁciency is the most serious consideration while developing any fog architecture.
In [6], an energy-efﬁcient protocol for a fog-supported wireless sensor network was presented, which
maximized the lifetime of the network by uniformly distributing the energy among connected nodes.
The performance of the proposed algorithm was compared with the existing state-of-the-art algorithms
Sensors 2019, 19, 3796
4 of 25
in MATLAB. The results showed that the proposed algorithm was highly energy efﬁcient with a
prolonged network lifetime.
Regardless of all the advancements in the IoT domain, the adoption of PA has been limited to
some developed countries. Because of the lack of resources, remote sensing-based techniques to
monitor crop health are not common in under-developed countries such as Pakistan, which results in
a loss of yield. Pakistan is an agricultural country due to is large arable land and climatic variations,
which make it suitable to cultivate multiple types of crops. Despite all these natural resources, Pakistan
is still unable to produce massive yields [7]. The main reason behind the low production is traditional
farming practices, which are used for crop health monitoring and yield estimation. These techniques
are completely based on farmer’s intuition and experience. Farmers visit the ﬁelds in order to monitor
the crop, which is very laborious and quite challenging in the case of large arable land. In this case, the
area under insect/pest attack is inaccurately measured, which can result in over spraying of insecticide
and pesticide, which adversely affects the nutrition in crops.
Keeping in mind all these issues, our motivation is to provide the industry and research
communities with a survey of technologies, metrics and current practices concerning communication
devices, sensors and platforms used to monitor and analyse multiple sources of data (spectral images,
IoT, etc.) used in environmental and agriculture applications. As the main contribution, we generated
a technological taxonomy for PA, which was driven by an IoT-based architecture to monitor the crops’
health. The developed system had two modules including wireless sensor network-based crop heath
monitoring in which multiple sensors were used to get the real-time heath status of crop; the other
one was NDVI-based analysis of spectra images captured by a drone to assess the chlorophyll content,
which was further used to monitor the health of the crop.
The rest of the paper is organized as follows: Section 2 presents the most common wireless
communication technologies used in the agriculture domain; Section 3 explains the spectral
image-based remote sensing techniques, platforms and vegetation indices; Section 4 describes remote
sensing applications in the agriculture sector; Section 5 presents a case study on IoT-based and
UAV-based PA; Section 6 explains the experiments and results; challenges are discussed in Section 7;
and conclusions and future directions are presented in Section 8.
Table 2. Common wireless nodes used in the agriculture domain.
Sr #
WN1
MC2
Expansion
Connector
Available Sensors
Data Rate
1
MICA2DOT
ATmega128L
19 Pins
GPS, Light, Humidity, Barometric Pressure,
Temperature, Accelerometer, Acoustic, RH
38.4 K Baud
2
Imote2
Marvell/XScalePXA271
40 Pins and 20 Pins
Light, Temperature, Humidity, Accelerometer
250 Kbps
3
IRIS
ATmega128L
51 Pins
Light, Barometric Pressure, RH, Acoustic,
Acceleration/ Seismic, Magnetic and Video
250 Kbps
4
MICAz
ATmega128L
51 Pins
Light, Humidity, Temperature, Barometric
Pressure, GPS, RH, Accelerometer, Acoustic, Video
Sensor, Sounder, Magnetometer, Microphone
250 Kbps
5
TelosB
TIMSP430
6 Pins and 10 Pins
Light, Temperature, Humidity
250 Kbps
6
Cricket
ATmega128L
51 Pins
Accelerometer, Light, Temperature, Humidity,
GPS, RH, Acoustic, Barometric Pressure,
Ultrasonic, Video Sensor, Microphone,
Magnetometer, Sounder
38.4 K Baud
7
MICA2
ATmega128L
51 Pin
Temperature, Light, Humidity, Accelerometer,
GPS, Barometric Pressure, RH, Acoustic, Sounder,
Video, Magnetometer
38.4 K Baud
WN1: wireless node, MC2: Micro-Controller.
2. Wireless Communication Technologies
Various communication protocols have been introduced in the last few decades due to the rapid
increase in IoT devices and WSN technologies. Each protocol has its own speciﬁcations depending on
the bandwidth, number of free channels, data rate, battery timing, price and other factors [8]. The most
commonly-used protocols for wireless communication in IoT-based applications in agriculture are:
Sensors 2019, 19, 3796
5 of 25
2.1. Cellular
Cellular technology is most suitable for applications that require an extraordinary data rate.
It can utilize GSM, 3G and 4G cellular communication capabilities by providing reliable high-speed
connectivity to the Internet, requiring higher power consumption.
It requires infrastructure to
be deployed and operation cost and back up staff for it with a centralized managed authority.
4G cellular technology requires more battery power, but cellular technology is a good option in
underground wireless sensor networks, such as security systems in smart home projects and agriculture
applications [9]. A smart irrigation systems was presented in [10], in which several soil moisture
sensors were deployed in the ﬁeld in the ZigBee mesh network. The reading captured from the ﬁelds
were transmitted over the cloud using the cellular 4G LTE network.
2.2. 6LoWPAN
6LoWPAN is an IP-based communication protocol, which was the ﬁrst protocol used for IoT
communication. 6LoWPAN is also low cost because of the low bandwidth and low power consumption.
6LoWPAN supports multiple topologies such as star and mesh topologies. To handle interoperability
between IPv6 and IEEE 802.15.4, there is an adaptation layer between the network layer and the
MAC layer [8]. The applications for 6LoWPAN are monitoring the health equipment, environment
monitoring and in security and home automation systems. In [11], a 6LoWPAN-enabled wireless sensor
network was presented to monitor the soil properties of crops. The 6LoWPAN system architecture
for precision agriculture application was discussed in [12] where the performance evaluation of this
protocol was discussed with several baud rates and power constraints.
2.3. ZigBee
ZigBee is a wireless communication protocol widely used in precision agriculture to monitor
environmental conditions related to crops’ health [13]. It is based on the wireless 802.15.4 standard.
Basically, it was developed for personal area networks by the ZigBee alliance [8]. It has a ﬂexible
network structure, long battery life, supports mesh, star and tree topology with multi-hop data
transmission, is easily installed and supports large nodes. It has a short range with limited data speed
and is less secure compared to Wi-Fi-based systems. ZigBee is very common in smart agriculture
applications such as smart green houses and smart irrigation systems [14]. In [15], a smart irrigation
system was presented based on the ZigBee communication protocol. This system consisted of two
nodes, i.e., a sensor node and an actuator node. The sensor node was comprised of soil moisture
sensors, which monitored the water level in the soil. The actuator module was responsible for taking
actions according to the water level of the soil. All communication was carried out by means of
ZigBee protocol.
2.4. BLE
BLE is as famous as the Bluetooth smart technology, which is a suitable protocol for IoT
applications including agriculture [16]. It is particularly designed for low bandwidth, low latency and
short range for IoT applications. The main advantages of BLE over typical Bluetooth include lower
setup time, lower power consumption and unlimited support for nodes in a star topology. It has a
very limited range of 10 meters. However, the drawbacks are that it can only provide communication
between two devices, it presents low security, and it can lose connection during communication. In [17],
a BLE-based infrastructure was presented to collect the sensors’ data. The proposed system utilized a
smart phone to collect the data of sensors using BLE, where sensors were deployed in the plants, i.e.,
soil moisture sensors and soil temperature sensor.
Sensors 2019, 19, 3796
6 of 25
2.5. RFID
RFID systems consist of a reader and a transponder, which have a very small radio frequency,
called the RF tag. This tag is programmed electronically with distinctive information that has a reading
characteristic. RFID has two technologies for the tag system the ﬁrst is the active reader tag system,
and the other is the passive reader tag. Active reader tag systems are more expensive, as they utilize
more battery power and use high frequencies. However, passive reader tag systems are low powered.
Some IoT applications using RFID include smart shopping, healthcare, national security and smart
agriculture applications. An IoT-based smart irrigation system based on RFID was presented in [18].
The system was comprised of soil moisture and soil temperature sensors along with a water control
system, so it collected the reading of the sensors and sent these readings to the cloud using RFID
communication protocols, where the user controlled a water pump based on the water level of the soil.
2.6. Wi-Fi
Wi-Fi is the most common communication protocol that enables devices to communicate over
a wireless signal. Wi-Fi provides Wireless Local Area Network (WLAN) connectivity to millions of
locations, i.e., homes, ofﬁces and public locations such as cafes, hotels and airports with high speed.
The Wi-Fi protocol supports IEEE 802.11, 802.11a, 802.11b, 802.11g and 802.11n. Wi-Fi is widely used
in IoT-based applications including agriculture systems, i.e., smart irrigation, crop health monitoring
and greenhouses. In [19], an infrastructure was presented to monitor environmental parameters
inside the greenhouse such as temperature, light intensity and soil moisture level. This platform
was comprised of sensors that collected the data related to the environmental variation and sent to
the cloud using Wi-Fi. Similarly, another smart agriculture system based on Wi-Fi communication
protocols was presented in [20]. This last one consisted of a Raspberry Pi connected with multiple
sensors, which collected the data. The collected data were further transmitted to the cloud using Wi-Fi
communication protocols.
2.7. LoRaWAN
LoRaWAN operates on the LoRa network. LoRaWAN deﬁnes the system architecture and
communication protocol of the network, while the physical layer of LoRa enables the link for
long-range communication. LoRaWAN manages the frequencies in communication, data rate and
power consumption for all devices. LoRaWAN is common in agricultural applications because of
its large coverage area and low power consumption [21]. In [14], a smart irrigation system based on
LoRaWAN was presented. Table 3 shows the comparison of all mentioned wireless communication
protocols [8]. Among all wireless communication technologies, 6LoWPAN and ZigBee are considered
to be more suitable for PA application because both are based on mesh networking, which makes them
suitable to cover large area.
Table 3. Wireless communication protocols used in Precision Agriculture (PA).
Communication Protocols
Data Rate
Topology
Standard
Physical Range
Power
6LoWPAN
0.3–50 Kb/s
Star, Mesh
IEEE 802.15.4
2–5 km urban,
15 km suburban
Low
ZigBee
250 Kb/s
Star, Mesh Cluster
IEEE 802.15.4
10–100 m
Low
Bluetooth
1–2 Mb/s
Star, Bus
IEEE 802.15.1
30 m
Low
RFID
50 tags/s
P2P
RFID
10–20 cm
Ultra low
LoRa WaAN
27–50 Kb/s
P2P, Star
IEEE 802.11ah
5–10 km
Very low
Wi-Fi
1–54 Mb/s
Star
IEEE 802.11
50 m
Medium
Sensors 2019, 19, 3796
7 of 25
3. Spectral Image-Based Remote Sensing
Remote sensing has been widely used in PA to monitor crops’ health for the last two decades.
Remote sensing is a phenomenon in which physical conditions of the Earth are observed remotely by
calculating the emitted and reﬂected radiation from some distance. There are special cameras that
are used to capture images for further analysis to ﬁnd the characteristics of a speciﬁc area. Multiple
platforms are used to mount these cameras that capture images of the objects.
3.1. Spectral Image Platforms
Remote sensing platform considerations for spectral images are airborne-based, satellite-based
and Unmanned Aerial Vehicle (UAV)-based [22]. Each platform has its own coverage range, which
is determined by three factors: (i) Ground Sampling Distance (GSD), which is computed in terms of
spatial resolution, (ii) data collection rate or frequency and (iii) average distance between the object
and sensor. Apart from coverage range, several factors [23] affect the performance of platforms,
as mentioned in Table 4.
Table 4. Key differences between spectral image platforms.
Applicability Aspect
Airborne
UAV
Satellite
Observation Area
Regional
Local
Worldwide
Ground Coverage
1 km (Medium)
100 m (Small)
10 km (Large)
Field of View
Wider
Wide
Narrow
GSD (Spatial Resolution)
5–25 cm
10–5 cm
0.30–300 m
Deployability
Complex
Easy
Difﬁcult
Spatial Accuracy
1–25 cm
5–10 cm
1–3 m
Repeat Time
Hour(s)
Minute(s)
Day(s)
Operational Risk
High
Low
Moderate
3.1.1. Satellite-Based Platforms
Space-borne platforms for remote sensing are considered to be the most stable platforms among
all others. These platforms consist of satellites, rockets and space shuttles. Space borne platforms are
categorized based on the orbits and timing. The advantages of satellite-based remote sensing include
high spatial resolution, which makes it promising to extract extensive time-series data. The images
obtained by satellite platforms cover large area and are stable without noise, which is normally induced
due to interference while image capturing. However, the main problem with satellite-based platforms
is their high cost in the case of high spatial resolution images. The second problem is their strictly ﬁxed
time schedule, so data cannot be collected at critical timings. The re-visitation times vary from twice
in one day to 16 days, depending on the orbit of the satellite. The other big problem is that satellite
platforms are highly sensitive to weather conditions, so if the weather is cloudy, the captured image will
have less detailed information. Table 5 shows the main types of satellites with their speciﬁcations [22].
Among all satellite platforms presented in Table 5, some satellite data are freely available,
while others provide a commercial solution. The commercial solutions such as Pleiades-1 provide
images with a high resolution and a revisit time of one day. QuickBird, Landsat-8 and Sentinel are
frequently-used satellite platforms used to obtain hyperspectral imagery. QuickBird was launched
in 2001 by USA. The Panchromatic (PAN) and four Multi-Spectral (MS) imagery sensors are used in
QuickBird with a GSD of 0.7 × 0.7–2.6 × 2.6 m with a revisit time 1–3.5 days. QuickBird provides a
small revisit time, but it is a commercial solution. In contrast to QuickBird, Landsat-8 and Sentinel
provide free solutions. Landsat-8 was launched in 2013 by the USA. Landsat-8 provides a GSD of
16 days with PAN and 11-MS imagery sensors. Though revisit time of Landsat-8 is much higher
compared to QuickBird, but it provides images with 11 different multi-spectral bands.
Sentinel is another broadly-used satellite launched by the EU. It currently has three missions,
i.e., Sentinel-1, Sentinel-2 and Sentinel-3. These missions provide images with 21 MS bands with
Sensors 2019, 19, 3796
8 of 25
revisit times of 5–10 days depending on which Sentinel mission is used. However, Sentinel-2 is a
commonly-used platform in precision agriculture as it provides data freely at a 10-m spatial resolution
and covers a swath width of 290 km. By combining Sentinel-2A and Sentinel-2B, the revisit time is
further reduced to ﬁve days, which helps in change detection. The complete details of all satellite
platforms with their speciﬁcations are listed in Table 5, where other platforms such as SAT, MODIS
and WordView are also considered.
Table 5. Satellite platforms for RS.
Name
Launch
Sensor
Country
Swath
Width (km)
GSD 1 Range (m)
Revisit Time (day)
RapidEye
2008
5 MS2
Germany
77
6.5 × 6.5
1–5.5
QuickBird-2
2001
PAN3
USA
16.8–18
0.7 × 0.7
1–3.5
4 MS2
2.6 × 2.6
Pleiades 1
2011
PAN3
France
20
0.5 × 0.5
1
2012
4 MS2
2 × 2
Sentinel-1
2014
C-band
EU
80
5 × 5
12
2016
SAR6
250
5 × 20
6 (dual)
400
25 × 40
WorldView-3
2014
PAN3, 8 MS2, 8 MS2
USA
13.1
0.3 × 0.3
1–4.5
(SWIR4), 12 MS2
1.2 × 1.2
3.7 × 3.7
Landsat-8
2013
PAN3, 11 MS2
USA
185
15 × 15
16
30 × 30
Sentinel-2
2015
13 MS2
EU
290
10 × 10
10
20 × 20
2016
60 × 60
5 (dual)
EnMap
2017
232 HSI5
Germany
30
30 × 30
4
ICESat
2003
2 HSI5
USA
N/A
70
8
(footprint)
TanDEM-X
2007
X-band
Germany
5 × 10
1 × 1
11
SAR6
1500 × 30
3 × 3
1500 × 100
16 × 16
SkySat
2013
PAN3
USA
2 × 1
1.1 × 1.1
0.5 (2015)
Video
2014
PAN3
8
0.9 × 0.9
0.12 (2017)
2015
4 MS2
2 × 2
ICESat-2
2018
1 HSI5
USA
N/A
10
N/A
(9-beam)
(footprint)
Sentinel-3
2015
21 MS2
EU
1270
300 × 300
0.25
2017
11 MS2
1420
500 × 500
(IR)
750 (nadir)
1000 × 1000
RADARSAT-2 2007
C-band
Canada
20
3 × 3
24 (orbit repetition)
SAR6
500
100 × 100
SPOT 6
2012
PAN3
France
60
1.5 × 1.5
1–5
SPOT 7
2014
4 MS2
6 × 6
TerraSAR-X
2007
X-band
Germany
5 × 10
1 × 1
11
SAR6
1500 × 100
16 × 16
DMC-3
2015
PAN3
U.K.
23
1 × 1
1
4 MS2
4 × 4
GSD1: Ground Sampling Rate, MS2: Multi-Spectral, PAN3: Panchromatic, SWIR4: Short Wave Infrared, HSI5:
Hyperspectral Imagery, SAR6: Synthetic Aperture Radar
3.1.2. Airborne-Based Platforms
Airborne platform are ﬂexible compared to satellite platforms, but still are expensive. The revisit
time is in human control, which can be changed any time. The coverage area by this platform is
much smaller than satellite-based ones, but relatively greater than the UAV platforms. Some common
airborne platforms used for remote sensing [22] are given in Table 6.
Sensors 2019, 19, 3796
9 of 25
Table 6. Airborne/aircraft platforms for RS.
Aircraft Type
Typical Models
RS Sensors
Max Flying Height (ft)
Fixed wing (jet)
LearJet 35A
InSAR,
45,000
Camera,
GeoSAR
Fixed wing (propeller engine)
Cessna 402
Camera
26,900
Commander 690
LiDAR
19,400
Cessna 208
Camera
LiDAR
25,000
Cessna 206
Camera
DHC-6 Twin
Camera
15,700
Otter 300
LIDAR
25,000
Diamond
Camera
DA42
LiDAR
18,000
Pilatus PC-6
Camera
Porter
Camera
25,000
Piper Navajo
LiDAR
26,000
Partenavia
Camera
P.68
LiDAR
19,200
Vulcanair P68
Camera
Observer
Camera
18,000
Gyroplan
AutoGyro
LiDAR
10,000
Cavalon
Camera
Helicopter
Eurocopter
LiDAR
15,000
AS350
Camera
Robinson R44
LiDAR
14,000
Camera
Bell 206
LiDAR
13,000
Camera
Schweizer
LiDAR5
13,000
Camera
3.1.3. UAV-Based Platforms
UAV platforms are a vibrant alternative to satellite and airborne, which are quite ﬂexible and cost
effective. A typical UAV platform consists of a communication and navigation system that incorporates
a set of sensors mounted on it. Among UAV platforms, there are mainly ﬁxed-wing platforms. and
multirotor options are available. The ﬂying time is based on the payload weight. In general, a longer
ﬂying time is achieved by ﬁxed-wing systems, which demands lighter weight payloads. For example,
high-deﬁnition cameras weighing less than 300 grams as the payload of a ﬁxed-wing UAV allow it to ﬂy
for around two hours using currently available battery power [24]. On the contrary, battery-powered
multirotor UAV with higher payload capacity have a reduced ﬂying time, i.e., around 15–25 min.
Table 7 shows UAV platforms commonly used in the agriculture domain and concretely to monitor
the health of crops remotely [22]. Among these platforms, DJI/Phantom-2 is a more suitable choice
for intermediate agricultural land because of its low cost and ease of use. The other advantage of this
platform is that it provides support for mounting multiple cameras, which helps to monitor the crop in
multiple electro-magnetic bands. The American Aerospace/RS-16 is also an option because of its ﬂight
time and large are coverage, but due to its high cost, this platform is not common.
In [25], the ESAFLY A2500_WH helicopter was used to implement the platform of the UAV
with Tetra cam ADC Micro as the camera to capture hyper-spectral images of two different types of
cultivation, i.e., vineyard and tomato. The images captured by the UAV platform are very high in
resolution, so more information can be extracted as compared to satellite images. To assess the health
of a crop, three types of Vegetation Index (VI) maps have been computed.
Sensors 2019, 19, 3796
10 of 25
Table 7. UAV platforms for RS.
Weight (kg)
Aircraft Power/Type
Manufacturer/Model
Flying Time (min)
Flying Speed (m/s)
RS Sensors
0.7
Fixed-wing/electric
senseFly/eBee RTK
40
11–25
Camera
6.1
Fixed-wing/electric
AeroVironment/Puma AE
210
23
Camera
6.0
Quadro copter/electric
Microdrones/MD4-1000
90
12
Camera/LiDAR
4.6–6.6
Hexacopter/electric
Aibotix/Aibot X6
30
14
Camera
5
Fixed-wing/electric
Trigger
Composites/Pteryx
120
12.5–15
Camera
1.3
Quadrocopter/electric
DJI/Phantom 2
25
15
Camera
2.5
Fixed-wing/electric
Trimble/UX5
50
22
Camera
2.7
Fixed-wing/electric
Topcon/SIRIUS PRO
50
18
Camera
5.1–5.8
Fixed-wing/electric
Hawkeye
UAV/AeroHawk
90
16.5–19.5
Camera
6.9–9.5
Hexacopter/electric
TRGS/Li-AIR
15
8
LiDAR
9.5
Octocopter/electric
Altus UAS/Delta X8
10–14
12
Camera/LiDAR
25
Octocopter/electric
Riegl/Ricopter
30
22
LiDAR/camera
77
Helicopter/gas
Aeroscout/Scout B1-100
90
LiDAR
90
Helicopter/gas
IGI/geocopter
120–180
Camera/LiDAR
9.2
Octocopter/electric
Altigator/OnyxStar
FOX-C8 HD LiDAR
20
LiDAR
38
Fixed-wing/gas
American
Aerospace/RS-16
720–960
33
Camera
3.2. Vegetation Indices
Using multi-spectral images from the remote sensors described above, a series of Vegetation
Indices (VIs) can be computed. Vegetation Indices (VIs) obtained from remote sensing-based canopies
are effective algorithms for quantitative and qualitative evaluations of vigour, vegetation cover and
growth dynamics, among other applications [26]. Hitherto, no uniﬁed mathematical expression exists
that deﬁnes all VIs due to the complexity of the several light spectra combinations, instrumentation,
resolutions and platforms used. In particular, this section focuses on vegetation indices NDVI, GDVI
and SAVI, as they are widely used in PA.
3.2.1. NDVI
The Normalized Difference Vegetation Index (NDVI) is the most popular VI that is extensively
used to ﬁnd the content of green in PA applications [27,28]. It uses Red (R) and Near Infrared (NIR)
channels to compute the NDVI index. More NIR light is absorbed by healthy vegetation; however,
absorption ratio is very small for red light. NDVI is computed by Equation (1) and returns a value
between −1 and 1 [29].
NDVI = NIR − R
NIR + R
(1)
Higher NDVI value indicate healthy vegetation, while smaller values of NDVI show that vegetation is
very small at that speciﬁc region. There is another form of NDVI, i.e., the Green Normalized Vegetation
Index (GNDVI), which uses the green channel instead of red. GNDVI is computed by Equation (2):
GNDVI = NIR − G
NIR + G
(2)
Sensors 2019, 19, 3796
11 of 25
3.2.2. Difference Vegetation Index
The DVI was proposed to reduce the effect of soil reﬂectance, which is not covered by NDVI [30].
DVI is different between the reﬂectance of the NIR band to the reﬂectance of the red band. DVI is also
computed with the green band, i.e., GDVI. Both DVI and GDVI are computed by Equations (3) and (4):
DVI = NIR − R
(3)
GDVI = NIR − G
(4)
3.2.3. SAVI
NDVI and DVI do not compensate the background effect of soil. Therefore, many vegetation
indices were introduced to compensate the effect of soil reﬂectance. The Soil Adjusted Vegetation Index
(SAVI), the Green Soil Adjusted vegetation Index (GSAVI), the Optimized Soil Adjusted Vegetation
Index (OSAVI), the Green Optimized Soil Adjusted Vegetation Index (OGSAVI) and the Modiﬁed
Soil Adjusted Vegetation Index (MSAVI) [31–33] are common among them, which are computed by
Equations (5)–(9):
SAVI =
1.5(NIR − R)
(NIR + R + 0.5)
(5)
GSAVI = 1.5(NIR − G)
NIR + G + 0.5
(6)
OSAVI =
(NIR − G)
NIR + R + 0.16
(7)
GOSAVI =
(NIR − G)
NIR + G + 0.16
(8)
MSAVI = 0.5[2(NIR + 1) −
q
(2NIR + 1)2 − 8(NIR − R)]
(9)
3.2.4. NR and NG:
Normalized Red (NR) and Normalized Green (NG) are two other famous vegetation indices being
used in PA [33]. NR focuses on the part of spectrum where radiation is absorbed by chlorophyll, while
NG focuses on the part of the spectrum where radiation is absorbed by other pigments, excluding
chlorophyll. NR and NG are computed by Equations (10) and (11):
NR =
R
NIR + R + G
(10)
NG =
G
NIR + R + G
(11)
4. Wireless Sensor Network Applications in Agriculture
Multiple applications of wireless sensor networks are being utilized today in the agriculture sector.
Some very common applications are smart irrigation, smart fertilization, smart pest control and green
house monitoring.
4.1. Smart Irrigation Systems
Smart irrigation is an artiﬁcial irrigation application that controls the quantity of water by making
a decision about where water is needed. It is the most signiﬁcant constituent in agriculture, which has
a great impact on crops’ health, cost and productivity. One major aspect of smart irrigation is to avoid
Sensors 2019, 19, 3796
12 of 25
the wastage of water since most countries in the world are facing water scarcity problems. A smart
irrigation system was presented in [34] in which a Raspberry Pi was used along with two sensors:
a soil moisture sensor was used to assess the water level in the soil, while a temperature and humidity
sensor was used to monitor the environmental condition. The Raspberry Pi was connected to these
sensors and the water supply network. A mobile application was developed for remote monitoring
and remote water ﬂow control enabling both manual and automatic water ﬂow control. In automatic
mode, water ﬂow was automatically turned ON/OFF based on the water level of the soil without
human intervention. In manual mode, the user was able to monitor the soil moisture level. An alert
was generated when the water level of soil was getting below a speciﬁc threshold, and the user turned
it ON/OFF using a mobile application.
Power is a big concern in IoT-based platforms, so many researchers have developed power-
efﬁcient systems. A power-efﬁcient water irrigation system was presented using solar power [35]
in which the controller was connected to the soil sensor and water supply valve. The water valve
was turned ON/OFF based on the water level monitored by the moisture sensor. The power was
supplied by the solar panel, so the system was independent of any external power module. Another
sensor-based IoT system for water irrigation was presented in [36] in which the controller controlled
the opening and closing of a solenoid valve based on the water level of the soil. In addition, a series of
weather alerts were sent to the user via a mobile application to update the temperature and humidity of
the environment, which had a direct inﬂuence on the water level of the soil. In [37], an energy-efﬁcient
irrigation system for cultivated crops was presented using a wireless sensor network in which water
was effectively controlled based on environmental conditions. This system estimated the quantity of
water needed for normal irrigation based on the humidity, temperature and wind speed collected by
sensors along with historical data.
In [38], an IoT-based irrigation system was presented using soil moisture sensors controlled by
ATMEGA 328P on an Arduino UNO board along with a GPRS module. The data collected from the
sensors were sent to the cloud, i.e., Things Speak, where graphs were generated to visualize the data
trends. A web portal was also designed where the farmer was able to check the status of water, if it
was ON/OFF. Similarly, a real-time prototype for an irrigation system was presented in [39] in which
soil moisture sensors and soil temperature sensors were used to assess the water status of the soil.
RFID was used to transmit data to the cloud for further data analysis. Using ATMEGA 328, a water
sprinkler system for smart irrigation was presented in [40] using temperature, humidity and soil
moisture sensors. The water sprinkler was controlled based on the soil moisture level to save water
and reduce human effort. In [41], a cost-effective drip irrigation system for a home was proposed in
which a Raspberry Pi, Arduino, electronic water control valve and relay were used. ZigBee protocols
were used for communication. The user turned ON/OFF the water valve by sending commands to the
Raspberry Pi, which further processed the commands through the Arduino.
The sensors placement is a big issue that affects the accuracy of sensors. A detailed discussion of
soil moisture positioning in the ﬁeld and their accuracy was presented in [42]. For real-time irrigation
systems, complete software and hardware requirements, problems and challenges and advantages
were discussed in [43] where a big picture of the complete system was provided.
4.2. Smart Fertilization System
Fertilizer is an artiﬁcial or natural substance having some chemical elements used to enhance
the growth and productivity of plants. Manual spraying is a common technique used for fertilization.
However, the optimal way of fertilization requires sensing capabilities to ﬁnd the exact place where
fertilizer is needed, which chemical components are missing and the amount of fertilizer needed.
It is important to provide fertilizers in a very precise amount in order to improve productivity [44].
Multiple fertilization techniques have been presented by researchers since the last decade using WSN
and IoT.
Sensors 2019, 19, 3796
13 of 25
An automated fertilization system was presented in [45] using real-time sensors to measure the
soil fertility. The system consisted of three modules including input, output and decision support.
The decision support module measured the optimal amount of fertilizers needed for the growth of the
plants based on the real-time sensory data captured by the sensors. A mechanical sensor named the
“Pendulum Meter” was introduced in [46], which was used for optimal fertilization. This sensor was
mounted on the tractor to measure the density of the crop, so the corresponding fertilizer spreader
was controlled based on the readings of this sensor. The IEEE 802.11 Wi-Fi module was used for
communication along with GPS. Real-time data of soil were collected by several sensors, i.e., soil
moisture, temperature, conductivity, NO2, CO2, etc. A Geographical Information System (GIS) server
was used to interpolate sensory data.
4.3. Smart Pest Control and Early Disease Detection System
Pest attacks are the root cause of low productivity in the agriculture sector. These pests result in
several serious diseases in plants that affect the plant’s growth. However, disease prediction provides
early warning to the farmers, which enables them to make appropriate decisions to control the disease
on time. Pest control systems are comprised of electronic devices that enable humans to identify traps
in a speciﬁc range of these electronic devices [47]. These electronic devices are sensors capable of
calculating the environmental parameters for further analysis.
Much research has been done in the agriculture sector for early disease detection and pest control
systems using more advanced and sophisticated technologies [48,49]. Multiple imagery sensors have
been used by different researchers to collect imagery data, such as: RGB sensors, ﬂuorescence imagery
sensors, spectral sensors and thermal sensors [50]. The thermal sensors are used to measure the water
status in the plant by measuring the temperature, since this parameter has a direct inﬂuence on the
water level in the plants. RGB images have three colour channels, i.e., red, green and blue, which
can be used to perceive the biometric effect in the plants. Multi- and hyper-spectral sensors capture
images containing the spatial information of objects in multiple wavebands. The spatial resolution is
dependent on the distance between the object and the sensor. That is why satellite images contain less
spatial resolution as compared to low altitude platforms such as drones. The ﬂuorescence sensors are
used to distinguish the photosynthetic activities in the plants. Various image processing techniques
are applied to these imagery data to identify the diseases in plants.
In [50], an IoT-based plants disease and pest prediction system was presented to minimize the
excessive use of fungicides and insecticides. Weather condition monitoring sensors, i.e., temperature,
dew, humidity and wind speed, are used to monitor weather parameters to ﬁnd a correlation between
pest growth with weather. The sensors have been deployed in orchards, and data collected from these
sensors are sent to the cloud. The farmer is informed about the alarming condition of the pest attack
on the crops.
From a different point of view, hyper-spectral images are used to analyse crops’ health and pest
attack using manned or unmanned vehicles on which spectral cameras are mounted. The captured
images are analysed in depth using machine learning techniques to identify the disease in the plants.
Advance Neural Networks (ANNs) are more common for processing imagery data due to their ability
to learn complex structures and patterns. Using hyper-spectral images, a system was presented [51] to
identify disease or pest attack in crops. The proposed system for disease detection used an ANN with
multiple layers.
Early disease detection in sugar beet plants was presented in [52]. For early detection, four
supervised classiﬁcation algorithms were applied on spectral images. Spectral images were then
collected for each image, and multiple vegetation indices were calculated to be used in predictive
and perspective analysis. The vegetation indices used were NVDI, SR, SIPI, PSSRaand PSSRb, ARI,
REP, mCAIand RRE. These vegetation indices values were used as features in the dataset. Support
Vector Machine (SVM), ANN, and decision tree were used for classiﬁcation. A comparative analysis
was performed which, showed that SVM outperformed other classiﬁers for disease detection with an
Sensors 2019, 19, 3796
14 of 25
accuracy of 97.12%. In [53], a data mining technique was applied on the already collected dataset of
two types of crops, i.e., wheat and paddy (rice), in India. For dimension reduction, Sammon’s mapping
was used for multi-dimension scaling, i.e., to reduce the dimension also for unsupervised learning.
For high dimensional data, dimension reduction is required prior to performing further data analysis
for better data visualization and accuracy, since redundant dimensions reduce the effectiveness of
any data analysis algorithms. Principle Component Analysis (PCA) is a very often-used technique
along with Sammon’s mapping. Data from multi-dimensions were reduced to two or three dimensions.
Then, the Self-Organized Maps (SOM) algorithm for clustering was used to ﬁnd correlations between
the data. The accuracy comparison of SOM and Sammon’s mapping was presented, which showed
that SOM performed better on a large dataset, while Sammon’s mapping was suitable for small ones.
Smart phones played important role in data acquisition, which were further used to monitor the crops’
health. In [54], the health of wheat crop was monitored using near surface imagery captured by a smart
phone. The crop was classiﬁed as healthy or unhealthy based on the green level by computing Gcc.
Most of the applications in PA have been either IoT-based in which multiple sensors are used to
assess the health of the crop or remote sensing-based in which crop health is assessed by performing
some computation on spectral images. We can compare crop health monitoring application based
on some attributes such as which sensors are used in particular applications, whether web or mobile
services are provided or not, etc. The comparative analysis of some existing crop health monitoring
applications is presented in Table 8 based on some attributes.
To precisely monitor the crop health, both IoT-based techniques and remote sensing techniques
should be used together to provide more reliable and accurate information about the crop. As a
proof of concept, we present a case study in which a crop health monitoring system based on IoT and
remote sensing techniques is proposed. We provide a complete end-to-end solution in the agriculture
domain by facilitating the agricultural user with web and mobile services so that he/she could be
informed about the latest condition of the crop in a timely manner. In this way, remedy actions could
be performed in time, which will result in enhanced production.
Sensors 2019, 19, 3796
15 of 25
Table 8. Comparison among existing PA applications.
PA
Edge
Data
Soil
Soil
Air
Air
Vegetation
Web
Mobile
Light
Wind
Application
Computing
Analytic
Moisture
Temperature
Moisture
Temperature
Index
Services
Services
Intensity
Velocity
[1]
N
Y
N
N
N
Y
Y
N
N
N
N
[4]
N
Y
N
N
N
N
N
Y
Y
N
N
[28]
N
Y
N
N
N
N
Y
N
N
N
N
[29]
N
Y
N
N
N
N
Y
N
N
N
N
[41]
N
N
Y
N
N
N
N
N
N
N
N
[52]
N
Y
N
N
N
N
Y
N
N
N
N
[55]
N
N
Y
N
Y
Y
N
N
Y
N
N
[56]
Y
N
Y
Y
Y
Y
N
N
N
Y
N
[57]
N
Y
Y
Y
Y
Y
N
N
N
Y
N
[58]
N
N
N
Y
N
N
N
N
N
N
N
[59]
N
Y
N
N
N
N
Y
N
N
N
N
[60]
Y
Y
Y
N
Y
Y
N
Y
Y
Y
N
[61]
Y
Y
Y
Y
Y
Y
N
Y
Y
Y
Y
[62]
N
Y
N
N
N
Y
N
Y
N
N
N
[63]
N
Y
Y
Y
Y
Y
N
Y
N
N
N
[64]
N
Y
Y
N
Y
Y
N
Y
N
N
N
[65]
N
Y
Y
Y
N
Y
N
N
N
N
N
[66]
N
Y
N
N
N
N
Y
N
N
N
N
[67]
N
Y
Y
Y
N
Y
Y
Y
Y
N
N
[68]
N
Y
N
N
N
N
Y
N
N
N
N
Proposed system
Y
Y
Y
Y
Y
Y
Y
Y
Y
N
N
Sensors 2019, 19, 3796
16 of 25
5. A Case Study on UAV-Based and IoT-Based Precision Agriculture
We developed a complete solution for crop health monitoring based on IoT and remote sensing.
In the proposed system, crop health is monitored using data collected from multiple IoT sensors,
as well as NDVI mapping of spectral images captured by a drone. The architecture of the proposed
system is shown in Figure 1, which was designed according to two main modules. The ﬁrst module
was a wireless sensor network-based system in which multiple wireless nodes were developed. Each
wireless node was comprised of a soil moisture sensor used to monitor the water level of the soil,
a soil temperature sensor used to check the temperature of the soil and air temperature and humidity
sensors. These nodes were deployed across the ﬁeld in a star topology fashion where the master node
collected readings from all slave nodes and transmitted the captured reading to the back-end server for
further processing. The master node acted as a gateway node, which received data from all slave nodes
using NRF communication module. After performing initial processing, the master node transmitted
the data to the cloud using GSM communication technology. In the case of the unavailability of the
GSM network, this node stored the captured data and transmitted to the cloud upon the availability
of network.
The second module was used to monitor crop health using multi-spectral imagery, which was
collected by a multi-spectral camera mounted on a drone. The NDVI was computed using Equation (1)
to classify between healthy and unhealthy plants by measuring the chlorophyll content in the crops,
which was further used to localize the area under stress precisely.
All collected data were sent to the cloud where further analysis was performed. The web portal
was designed to help the farmer monitor the crop proﬁle over the whole life cycle. Currently, we are
monitoring soil moisture, soil temperature, air moisture and air temperature readings in real time
along with NDVI mapping of spectral imagery. Multiple web services were provided on the web
portal including historical/real data visualization using graphs, weather monitoring, NDVI mapping
and the correlation among measured parameters. Figure 2 shows the snapshots of the web portal
along with different services.
Figure 1. System architecture.
Sensors 2019, 19, 3796
17 of 25
Figure 2. User interface of the web portal.
For portability and remote monitoring, a mobile application was also developed to facilitate the
farmer/agronomist/landlord with all the web services that are available on web portal. The alerts
are generated when an abnormal behaviour is observed in the crop, which help the farmer to take
remedy actions in a timely manner. The user interfaces of the mobile application are shown in Figure 3.
Therefore, the web portal along with mobile applications provides a complete solution, which enables
agricultural users monitor the current status of the crop, as well as previous details.
Figure 3. User interface of the mobile application.
Sensors 2019, 19, 3796
18 of 25
6. Results and Discussion
6.1. Analysis of the Data Collected by IoT Nodes
The developed IoT nodes were deployed across the wheat ﬁelds of an area of 1.4375 hectare.
The selected area was located in Islamabad, Pakistan. The wheat ﬁelds are shown in Figure 4 along
with the IoT node and sensors. We deployed the system across the wheat ﬁeld in March 2019 when
wheat was in the grain ﬁlling and grain ripening stage.
Figure 4. System deployed across the wheat ﬁelds.
We collected the sensors’ readings such as air temperature, air humidity, soil temperature and
soil moisture. We compared the observed crop parameters with the ideal wheat temperature proﬁle
as shown in Figure 5. Extreme variation in the weather of Islamabad was observed in that particular
time period, which can be seen by how the actual temperature for wheat crop deviated from the ideal
temperature proﬁle of the wheat crop.
Figure 5. Deviation of observed temperature from the ideal temperature proﬁle.
Additionally, we performed linear regression to ﬁnd the correlation between observed parameters,
which provided insight into how changes in one parameter can effect the other parameter. The linear
regression found a relation between the two parameters by ﬁtting the equation of the line using the
observed dataset [69]. Equation (12) represents an equation of the line where mrepresents the slope of
line, while c indicates the y-intercept. The variables m and c were learned from the data.
y = mx + c
(12)
Figure 6A shows the correlation between the observed air temperature and air humidity, which showed
that both were negatively correlated. The correlation between air temperature and soil temperature is
shown in Figure 6B, which shows that both were positively correlated.
Sensors 2019, 19, 3796
19 of 25
(A)
(B)
Figure 6. (A) Correlation b/wair temperature and air humidity. (B) Correlation b/w air temperature
and soil temperature.
The rise in air temperature caused the air humidity to reduce, while it resulted in an increase in
soil temperature and vice versa.
6.2. Analysis of Multi-spectral Images Captured by Drone
To collect multi-spectral imagery, we used the DJI-Phantom Pro Advanced drone with the Sentera
Multi-spectral-imaging sensor. The drone had its own optical camera, while the multi-spectral camera
was mounted on it to obtain spectral images. Multiple ﬂights of the drone were carried out at the
speciﬁc growing stages of the crop, i.e., grain ripening and grain ﬁlling stage. After collecting these
images, they were transferred to the cloud for NDVI mapping. Figure 7A shows the optical image
that was captured on 16 May 2019 when wheat was in the harvesting stage, while Figure 7B is its
spectral image, and Figure 7C is the NDVI mapping. Since wheat was at a mature stage, its NDVI
should be very small, i.e., ideally there should be no green region in the ﬁeld. However, in NDVI
mapping, a large green region indicated the abnormal behaviour of the crop. The green region was
due to naturally growing plants. This information can be visualized on the web portal.
(A)
(B)
(C)
Figure 7. Wheat crop. (A) Optical image; (B) spectral image; (C) NDVI mapping.
The same process was performed in a maize ﬁeld when maize was in the grain ripening stage.
Figure 8A shows the optical image that was captured on 24 July 2019 when maize was in the grain
ripening stage, while Figure 8B is its spectral image, and Figure 8C is the NDVI mapping. The same
behaviour can be observed with the maize crop, i.e., there should be a minimal green region in the
ﬁeld. However, in NDVI mapping, a large green region indicated the abnormal behaviour of the crop.
Sensors 2019, 19, 3796
20 of 25
(A)
(B)
(C)
Figure 8. Maize crop. (A) Optical image; (B) spectral image; (C) NDVI mapping.
7. Challenges
PA has been used since the last few decades to enhance crops’ yield with reduced costs and
human effort, although the adoption of these novel techniques by farmers is still very limited owing to
the following reasons or challenges.
7.1. Hardware Cost
PA relies mostly on hardware such as sensors, wireless nodes, drones, spectral imaging sensors,
etc., which are used to assess multiple parameters in real time. These sensors have multiple limitations
including high development, maintenance and deployment cost. Some systems in PA are cost effective
and are suitable for small arable land, i.e., smart irrigation systems that require low-cost hardware
components and sensors. However, drone-based systems for crops’ health monitoring are feasible for
large arable land due to high installation cost.
7.2. Weather Variations
Environmental variation is one of the major challenges that affects the accuracy of data collected
by sensors. Sensor nodes deployed in the ﬁeld are sensitive to environmental variations, i.e., rain,
ﬂuctuation in temperature, wind speed, sun light, etc. Communication between wireless nodes
and the cloud can be interrupted due interference induced in wireless communication channels by
atmospheric disturbance. The satellite, air borne and drone platforms are also sensitive to weather
variations. Imagery acquired by these platforms is affected by contamination of clouds and other
natural aerosols. The development of advanced techniques for atmospheric correction, cloud detection
and noise interpolation is a current open challenge, which requires hard efforts from the research
community.
7.3. Data Management
The sensors in PA constantly generate data. To ensure the integrity of data, some data security
measures needs to be in place, which will in turn enhance the cost of the system. The readings from
the sensors have to be accurate in order to take appropriate actions precisely when and where required.
An intruder can corrupt the readings, and false readings will adversely reduce the effectiveness of
the system. PA systems generate immense amounts of data, which require enough resources to
perform data analysis. Real-time data collected from sensors deployed across the ﬁelds after a few
minutes and spectral imagery acquired from high-altitude or low-altitude platforms produce the bulk
of the data, which increase the storage and processing requirements. New software platforms and
facilities for scalable management of Big Data sources are demanded. In this regard, the generation
of software-as-a-service solutions is focused on merging data management and IoT thorough cloud
computing platforms.
Sensors 2019, 19, 3796
21 of 25
7.4. Literacy Rate
Literacy is an important factor that inﬂuences the adoption ratio in PA. In developing countries
where the illiteracy rate is high, farmers grow crops based on their experience. They do not utilize the
state-of-the-art technologies in agriculture, which results in loss of production. Farmers need to be
educated in order to understand the technology or they have to trust a third party for technical support.
Therefore, in underdeveloped areas where the literacy rate is not high, PA is not very common due to
the limitations of resources and education.
7.5. Connectivity
Next-generation 5G networks can be 100-times faster than 4G ones, making communication
between devices and servers much quicker. 5G can also carry much more data than other networks,
which makes it an ideal technology for transmitting information from remote sensors and drones, key
tools that are being tested in PA environments. The adoption of new communication networks based
on 5G is a must in current applications where secure and rapid data transfer enables real-time data
management and support for decision making.
7.6. Interoperability
One of the biggest problems PA faces is the interoperability of equipment due to different digital
standards. This lack of interoperability is not only obstructing the adoption of new IoT technologies
and slowing down their growth, but it also inhibits the gain of production efﬁciency through smart
agriculture applications. New methods and protocols to integrate different machine communication
standards to unlock the potential of efﬁcient machine-to-machine communication and data sharing
between machines and management information systems are required in the current scenario of PA.
8. Conclusion and Future Directions
Precision agriculture is a modern practice used to enhance crops’ productivity using latest
technologies, i.e., WSN, IoT, cloud computing, Artiﬁcial Intelligence (AI) and Machine Learning
(ML). Most of the research done so far indicates that PA-based practices have a great inﬂuence on
sustainability and productivity. The objective of PA is to provide decision support systems based
on multiple parameters of crops, i.e., soil nutrients, water level of the soil, wind speed, intensity of
sunlight, temperature, humidity, chlorophyll content, etc. However, several challenges are involved
in the development and deployment phase of these systems. This article was aimed at providing a
survey of modern technologies involving current PA platforms, with the goal of supporting industry
and research communities on the development of modern applications for smart agriculture. A case
study was presented to prove the effectiveness of the PA in the agriculture domain.
Since the main objective of precision agriculture is to produce surplus yield by optimizing the
resources such as water, pesticides, fertilizers, etc., for resource optimization, prescription maps play
an important role, which enables farmers to quantify resources required for healthy crops at any
particular growth stage. Most of the research accomplished in the agriculture domain focuses on the
remote sensing platforms to collect imagery, which reﬂects only Vegetation Indices (VIs) such as NDVI.
The prescription maps cannot be generated by only using VIs; instead, multiple other factors need to
be considered such as soil properties, soil moisture level, meteorological behaviour, etc.
Funding: This work is funded by the Research England’s QR Global Challenges Research Fund (GCRF) under
Project “GrITS: Green IoT for Climate Smart Agriculture”.
Acknowledgments: We extend our sincere thanks and gratitude to National Agriculture Research Centre (NARC)
Islamabad, Pakistan for allowing us to ﬂy drone in their premises and capture spectral imagery to monitor crop
health. We are also indebt to NUST-SEECS for providing the administrative and technical support to IoT lab for
conducting this research work.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
Sensors 2019, 19, 3796
22 of 25
References
1.
Mumtaz, R.; Baig, S.; Fatima, I. Analysis of meteorological variations on wheat yield and its estimation using
remotely sensed data. A case study of selected districts of Punjab Province, Pakistan (2001–14). Ital. J. Agron.
2017, 12. [CrossRef]
2.
Wang, N.; Zhang, N.; Wang, M. Wireless sensors in agriculture and food industry—Recent development and
future perspective. Comput. Electron. Agric. 2006, 50, 1–14. [CrossRef]
3.
Abbasi, A.Z.; Islam, N.; Shaikh, Z.A. A review of wireless sensors and networks’ applications in agriculture.
Comput. Stand. Interfaces 2014, 36, 263–270.
4.
Rad, C.R.; Hancu, O.; Takacs, I.A.; Olteanu, G. Smart monitoring of potato crop: A cyber-physical system
architecture model in the ﬁeld of precision agriculture. Agric. Agric. Sci. Procedia 2015, 6, 73–79. [CrossRef]
5.
Baccarelli, E.; Naranjo, P.G.V.; Scarpiniti, M.; Shojafar, M.; Abawajy, J.H. Fog of everything: Energy-efﬁcient
networked computing architectures, research challenges, and a case study. IEEE Access 2017, 5, 9882–9910.
[CrossRef]
6.
Naranjo, P.G.V.; Shojafar, M.; Mostafaei, H.; Pooranian, Z.; Baccarelli, E. P-SEP: A prolong stable election
routing algorithm for energy-limited heterogeneous fog-supported wireless sensor networks. J. Supercomput.
2017, 73, 733–755. [CrossRef]
7.
Kirby, M.; Mainuddin, M.; Khaliq, T.; Cheema, M. Agricultural production, water use and food availability
in Pakistan: Historical trends, and projections to 2050. Agric. Water Manag. 2017, 179, 34–46. [CrossRef]
8.
Al-Sarawi, S.; Anbar, M.; Alieyan, K.; Alzubaidi, M. Internet of Things (IoT) communication protocols.
In Proceedings of the 2017 8th International Conference on Information Technology (ICIT), Amman, Jordan,
17–18 May 2017; pp. 685–690.
9.
Zhang, X.; Andreyev, A.; Zumpf, C.; Negri, M.C.; Guha, S.; Ghosh, M. Thoreau: A subterranean wireless
sensing network for agriculture and the environment. In Proceedings of the 2017 IEEE Conference on
Computer Communications Workshops (INFOCOM WKSHPS), Atlanta, GA, USA, 1–4 May 2017; pp. 78–84.
10.
Khelifa, B.; Amel, D.; Amel, B.; Mohamed, C.; Tarek, B.
Smart irrigation using internet of things.
In Proceedings of the 2015 Fourth International Conference on Future Generation Communication
Technology (FGCT), Luton, UK, 29–31 July 2015; pp. 1–6.
11.
Paventhan, A.; Allu, S.K.; Barve, S.; Gayathri, V.; Ram, N.M. Soil property monitoring using 6lowpan-enabled
wireless sensor networks. In Proceedings of the Agro-Informatics and Precision Agriculture, Hyderabad,
India, 1–3 August 2012.
12.
Suryady, Z.; Shaharil, M.H.M.; Bakar, K.A.; Khoshdelniat, R.; Sinniah, G.R.; Sarwar, U. Performance
evaluation of 6LoWPAN-based precision agriculture. In Proceedings of the International Conference on
Information Networking 2011 (ICOIN2011), Barcelona, Spain, 26–28 January 2011; pp. 171–176.
13.
Sarode, K.; Chaudhari, P. Zigbee based Agricultural Monitoring and Controlling System. Int. J. Eng. Sci.
2018, 8, 15907–15910.
14.
Zhou, Y.; Yang, X.; Guo, X.; Zhou, M.; Wang, L. A design of greenhouse monitoring & control system
based on ZigBee wireless sensor network.
In Proceedings of the 2007 International Conference on
Wireless Communications, Networking and Mobile Computing, Shanghai, China, 21–25 September 2007;
pp. 2563–2567.
15.
Chikankar, P.B.; Mehetre, D.; Das, S. An automatic irrigation system using ZigBee in wireless sensor
network. In Proceedings of the 2015 International Conference on Pervasive Computing (ICPC), Pune, India,
8–10 January 2015; pp. 1–5.
16.
Xue-fen, W.; Xing-jing, D.; Wen-qiang, B.; Le-han, L.; Jian, Z.; Chang, Z.; Ling-xuan, Z.; Yu-xiao, Y.P.; Yi, Y.
Smartphone accessible agriculture IoT node based on NFC and BLE. In Proceedings of the 2017 IEEE
International Symposium on Consumer Electronics (ISCE), Kuala Lumpur, Malaysia, 14–15 November 2017;
pp. 78–79.
17.
Tanaka, K.; Murase, M.; Naito, K. Prototype implementation of BLE based automated data collection
scheme in agricultural measurement system.
In Proceedings of the 2018 15th IEEE Annual Consumer
Communications & Networking Conference (CCNC), Las Vegas, NV, USA, 12–15 January 2018; pp. 1–2.
18.
Wasson, T.; Choudhury, T.; Sharma, S.; Kumar, P. Integration of RFID and sensor in agriculture using
IOT.
In Proceedings of the 2017 International Conference On Smart Technologies For Smart Nation
(SmartTechCon), Bangalore, India, 17–19 August 2017; pp. 217–222.
Sensors 2019, 19, 3796
23 of 25
19.
Liang, M.H.; He, Y.F.; Chen, L.J.; Du, S.F. Greenhouse Environment dynamic Monitoring system based on
WIFI. IFAC-PapersOnLine 2018, 51, 736–740. [CrossRef]
20.
N-USha, T.M. Conditions in Agriculture through WiFi using Raspberry PI. Int. J. Eng. 2017, 3, 6–11.
21.
Davcev, D.; Mitreski, K.; Trajkovic, S.; Nikolovski, V.; Koteli, N. IoT agriculture system based on LoRaWAN.
In Proceedings of the 2018 14th IEEE International Workshop on Factory Communication Systems (WFCS),
Imperia, Italy, 13–15 June 2018; pp. 1–4.
22.
Rudd, J.D.; Roberson, G.T.; Classen, J.J. Application of satellite, unmanned aircraft system, and ground-based
sensor data for precision agriculture: A review. In Proceedings of the 2017 ASABE Annual International
Meeting, Spokane, WA, USA, 16–19 July 2017.
23.
Toth, C.; Jó´zków, G. Remote sensing platforms and sensors: A survey. ISPRS J. Photogramm. Remote Sens.
2016, 115, 22–36. [CrossRef]
24.
Zhong, Y.; Wang, X.; Xu, Y.; Wang, S.; Jia, T.; Hu, X.; Zhao, J.; Wei, L.; Zhang, L.
Mini-UAV-Borne
Hyperspectral Remote Sensing: From Observation and Processing to Applications. IEEE Geosci. Remote Sens.
Mag. 2018, 6, 46–62. [CrossRef]
25.
Candiago, S.; Remondino, F.; De Giglio, M.; Dubbini, M.; Gattelli, M. Evaluating multispectral images and
vegetation indices for precision farming applications from UAV images. Remote Sens. 2015, 7, 4026–4047.
[CrossRef]
26.
Xue, J.; Su, B. Signiﬁcant remote sensing vegetation indices: A review of developments and applications.
J. Sens. 2017, 2017, 1353691. [CrossRef]
27.
Skakun, S.; Justice, C.O.; Vermote, E.; Roger, J.C. Transitioning from MODIS to VIIRS: An analysis of
inter-consistency of NDVI data sets for agricultural monitoring.
Int. J. Remote Sens. 2018, 39, 971–992.
[CrossRef]
28.
Daroya, R.; Ramos, M. NDVI image extraction of an agricultural land using an autonomous quadcopter
with a ﬁlter-modiﬁed camera. In Proceedings of the 2017 7th IEEE International Conference on Control
System, Computing and Engineering (ICCSCE), Penang, Malaysia, 24–26 November 2017; pp. 110–114.
29.
Mahajan, U.; Raj, B. Drones for Normalized Difference Vegetation Index (NDVI), to estimate Crop Health for
Precision Agriculture: A Cheaper Alternative for Spatial Satellite Sensors. In Proceedings of the International
Conference on Innovative Research in Agriculture, Food Science, Forestry, Horticulture, Aquaculture,
Animal Sciences, Biodiversity, Ecological Sciences and Climate Change (AFHABEC-2016), Delhi, India,
22 October 2016.
30.
Richardson, A.J.; Wiegand, C. Distinguishing vegetation from soil background information. Photogr. Eng.
Remote Sens. 1977, 43, 1541–1552.
31.
Huete, A.R. A soil-adjusted vegetation index (SAVI). Remote Sens. Environ. 1988, 25, 295–309. [CrossRef]
32.
Rondeaux, G.; Steven, M.; Baret, F. Optimization of soil-adjusted vegetation indices. Remote Sens. Environ.
1996, 55, 95–107. [CrossRef]
33.
Qi, J.; Chehbouni, A.; Huete, A.; Kerr, Y.; Sorooshian, S. A modiﬁed soil adjusted vegetation index. Remote
Sens. Environ. 1994, 48, 119–126. [CrossRef]
34.
Akubattin, V.; Bansode, A.; Ambre, T.; Kachroo, A.; SaiPrasad, P. Smart irrigation system. Int. J. Sci. Res.
Sci. Technol. 2016, 2, 343–345.
35.
Harishankar, S.; Kumar, R.S.; Sudharsan, K.; Vignesh, U.; Viveknath, T. Solar powered smart irrigation
system. Adv. Electr. Comput. Eng. 2014, 4, 341–346.
36.
Kansara, K.; Zaveri, V.; Shah, S.; Delwadkar, S.; Jani, K. Sensor based automated irrigation system with IOT:
A technical review. Int. J. Comput. Sci. Inf. Technol. 2015, 6, 5331–5333.
37.
Nikolidakis, S.A.; Kandris, D.; Vergados, D.D.; Douligeris, C. Energy efﬁcient automated control of irrigation
in agriculture by using wireless sensor networks. Comput. Electron. Agric. 2015, 113, 154–163. [CrossRef]
38.
Rawal, S. IOT based Smart Irrigation System. Int. J. Comput. Appl. 2017, 159, 880–886. [CrossRef]
39.
Vellidis, G.; Tucker, M.; Perry, C.; Kvien, C.; Bednarz, C. A real-time wireless smart sensor array for
scheduling irrigation. Comput. Electron. Agric. 2008, 61, 44–50. [CrossRef]
40.
Kumar, B.D.; Srivastava, P.; Agrawal, R.; Tiwari, V. Microcontroller based automatic plant Irrigation system.
Int. Res. J. Eng. Tenchnol. 2017, 4, 1436–1439.
41.
Agrawal, N.; Singhal, S. Smart drip irrigation system using raspberry pi and arduino. In Proceedings of the
International Conference on Computing, Communication & Automation, Noida, India, 15–16 May 2015;
pp. 928–932.
Sensors 2019, 19, 3796
24 of 25
42.
Soulis, K.X.; Elmaloglou, S.; Dercas, N. Investigating the effects of soil moisture sensors positioning and
accuracy on soil moisture based drip irrigation scheduling systems. Agric. Water Manag. 2015, 148, 258–268.
[CrossRef]
43.
Yousif, M.E.R.; Ghafar, K.; Zahari, R.; Lim, T.H. A rule-based smart automated fertilization and irrigation
systems. In Proceedings of the Ninth International Conference on Graphic and Image Processing (ICGIP
2017), Qingdao, China, 14–16 October 2017.
44.
Cugati, S.; Miller, W.; Schueller, J. Automation concepts for the variable rate fertilizer applicator for tree
farming. In Proceedings of the 4th European Conference on Precision Agriculture, Berlin, Germany, 15–19
June 2003; pp. 14–19.
45.
He, J.; Wang, J.; He, D.; Dong, J.; Wang, Y. The design and implementation of an integrated optimal
fertilization decision support system. Math. Comput. Model. 2011, 54, 1167–1174. [CrossRef]
46.
Chen, X.; Zhang, F. The establishment of fertilization technology index system based on “3414” fertilizer
experiment. China Agric. Technol. Ext. 2006, 22, 36–39.
47.
Mahlein, A.K.; Oerke, E.C.; Steiner, U.; Dehne, H.W. Recent advances in sensing plant diseases for precision
crop protection. Eur. J. Plant Pathol. 2012, 133, 197–209. [CrossRef]
48.
Sankaran, S.; Mishra, A.; Ehsani, R.; Davis, C. A review of advanced techniques for detecting plant diseases.
Comput. Electron. Agric. 2010, 72, 1–13. [CrossRef]
49.
Mahlein, A.K. Plant disease detection by imaging sensors–parallels and speciﬁc demands for precision
agriculture and plant phenotyping. Plant Dis. 2016, 100, 241–251. [CrossRef] [PubMed]
50.
Lee, H.; Moon, A.; Moon, K.; Lee, Y. Disease and pest prediction IoT system in orchard: A preliminary study.
In Proceedings of the 2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN),
Milan, Italy, 4–7 July 2017; pp. 525–527.
51.
Golhani, K.; Balasundram, S.K.; Vadamalai, G.; Pradhan, B. A review of neural networks in plant disease
detection using hyperspectral data. Inf. Process. Agric. 2018, 5, 354–371. [CrossRef]
52.
Rumpf, T.; Mahlein, A.K.; Steiner, U.; Oerke, E.C.; Dehne, H.W.; Plümer, L. Early detection and classiﬁcation
of plant diseases with support vector machines based on hyperspectral reﬂectance. Comput. Electron. Agric.
2010, 74, 91–99. [CrossRef]
53.
Sanghvi, Y.; Gupta, H.; Doshi, H.; Koli, D.; Ansh, A.; Gupta, U. Comparison of Self organizing maps
and Sammon’s mapping on agricultural datasets for precision agriculture.
In Proceedings of the 2015
International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS),
Coimbatore, India, 19–20 March 2015; pp. 1–5.
54.
Hufkens, K.; Melaas, E.K.; Mann, M.L.; Foster, T.; Ceballos, F.; Robles, M.; Kramer, B. Monitoring crop
phenology using a smartphone based near-surface remote sensing approach. Agric. For. Meteorol. 2019,
265, 327–337. [CrossRef]
55.
Prathibha, S.; Hongal, A.; Jyothi, M. IOT Based monitoring system in smart agriculture. In Proceedings
of the 2017 International Conference on Recent Advances in Electronics and Communication Technology
(ICRAECT), Bangalore, India, 16–17 March 2017; pp. 81–84.
56.
Heble, S.; Kumar, A.; Prasad, K.V.D.; Samirana, S.; Rajalakshmi, P.; Desai, U.B. A low power IoT network
for smart agriculture. In Proceedings of the 2018 IEEE 4th World Forum on Internet of Things (WF-IoT),
Singapore, 5–8 February 2018; pp. 609–614.
57.
Sabo, A.; Qaisar, S.; Subasi, A.; Rambo, K. An Event Driven Wireless Sensors Network for Monitoring
of Plants Health and Larva Activities. In Proceedings of the 2018 21st Saudi Computer Society National
Computer Conference (NCC), Riyadh, Saudi Arabia, 25–26 April 2018; pp. 1–7.
58.
Agarwal, A.; Gupta, S.; Kumar, S.; Singh, D. A concept of satellite-based IoT for downscaling the MODIS
data to extract Land Surface Temperature. In Proceedings of the 2018 9th International Symposium on
Signal, Image, Video and Communications (ISIVC), Rabat, Morocco, 27–30 November 2018; pp. 67–70.
59.
Rahman, M.R.; Islam, A.; Rahman, M.A. NDVI derived sugarcane area identiﬁcation and crop condition
assessment. Plan Plus 2004, 1, 1–12.
60.
Choudhury, S.B.; Jain, P.; Kallamkuth, S.; Ramanath, S.; Bhatt, P.V.; Sarangi, S.; Srinivasu, P. Precision Crop
Monitoring with Affordable IoT: Experiences with Okra. In Proceedings of the 2019 Global IoT Summit
(GIoTS), Aarhus, Denmark, 17–21 June 2019; pp. 1–6.
Sensors 2019, 19, 3796
25 of 25
61.
Mittal, A.; Sarangi, S.; Ramanath, S.; Bhatt, P.V.; Sharma, R.; Srinivasu, P. IoT-Based Precision Monitoring of
Horticultural Crops—A Case-Study on Cabbage and Capsicum. In Proceedings of the 2018 IEEE Global
Humanitarian Technology Conference (GHTC), San Jose, CA, USA, 18–21 October 2018; pp. 1–7.
62.
Saha, A.K.; Saha, J.; Ray, R.; Sircar, S.; Dutta, S.; Chattopadhyay, S.P.; Saha, H.N. IOT-based drone for
improvement of crop quality in agricultural ﬁeld. In Proceedings of the 2018 IEEE 8th Annual Computing and
Communication Workshop and Conference (CCWC), Las Vegas, NV, USA, 8–10 January 2018; pp. 612–615.
63.
Mekala, M.S.; Viswanathan, P. CLAY-MIST: IoT-cloud enabled CMM index for smart agriculture monitoring
system. Measurement 2019, 134, 236–244. [CrossRef]
64.
Nawandar, N.K.; Satpute, V.R. IoT based low cost and intelligent module for smart irrigation system.
Comput. Electron. Agric. 2019, 162, 979–990. [CrossRef]
65.
Srbinovska, M.; Gavrovski, C.; Dimcev, V.; Krkoleva, A.; Borozan, V. Environmental parameters monitoring
in precision agriculture using wireless sensor networks. J. Clean. Prod. 2015, 88, 297–307. [CrossRef]
66.
Lottes, P.; Khanna, R.; Pfeifer, J.; Siegwart, R.; Stachniss, C. UAV-based crop and weed classiﬁcation for smart
farming. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA),
Singapore, 29 May–3 June 2017; pp. 3024–3031.
67.
Cambra, C.; Sendra, S.; Lloret, J.; Garcia, L. An IoT service-oriented system for agriculture monitoring.
In Proceedings of the 2017 IEEE International Conference on Communications (ICC), Paris, France,
21–25 May 2017.
68.
Fontana, D.C.; Pinto, D.G.; Junges, A.H.; Bremm, C. Using temporal NDVI/MODIS proﬁles for inferences
on the crop soybean calendar. Bragantia 2015, 74, 350–358. [CrossRef]
69.
Seber, G.A.; Lee, A.J. Linear Regression Analysis; John Wiley & Sons: Hoboken, NJ, USA, 2012; Volume 329.
c⃝ 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 4:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: 0.9-1.0: Exceptionally relevant - This paper proposes an automated irrigation system.
  Relevance Score: 0.95
  Inline Citation: >
  Explanation: This study proposes a data collection system that collects data from field experiments in order to estimate the applicability of automated irrigation systems.

 Full Text: >
electronics
Review
Role of IoT Technology in Agriculture: A Systematic
Literature Review
Muhammad Shoaib Farooq 1
, Shamyla Riaz 1, Adnan Abid 1, Tariq Umer 2
and
Yousaf Bin Zikria 3,*
1
Department of Computer Science, University of Management and Technology, Lahore 54770, Pakistan;
shoaib.farooq@umt.edu.pk (M.S.F.); S2017108003@umt.edu.pk (S.R.); adnan.abid@umt.edu.pk (A.A.)
2
Department of Computer Science, COMSATS University Islamabad, Lahore 45550, Pakistan;
tariqumer@cuilahore.edu.pk
3
Department of Information and Communication Engineering, Yeungnam University, Gyeongsan 38541,
Korea
*
Correspondence: yousafbinzikria@ynu.ac.kr
Received: 13 January 2020; Accepted: 6 February 2020; Published: 12 February 2020


Abstract: The growing demand for food in terms of quality and quantity has increased the need
for industrialization and intensiﬁcation in the agriculture ﬁeld. Internet of Things (IoT) is a highly
promising technology that is oﬀering many innovative solutions to modernize the agriculture sector.
Research institutions and scientiﬁc groups are continuously working to deliver solutions and products
using IoT to address diﬀerent domains of agriculture. This paper presents a systematic literature
review (SLR) by conducting a survey of IoT technologies and their current utilization in diﬀerent
application domains of the agriculture sector. The underlying SLR has been compiled by reviewing
research articles published in well-reputed venues between 2006 and 2019. A total of 67 papers were
carefully selected through a systematic process and classiﬁed accordingly. The primary objective
of this systematic study is the collection of all relevant research on IoT agricultural applications,
sensors/devices, communication protocols, and network types. Furthermore, it also discusses the
main issues and challenges that are being investigated in the ﬁeld of agriculture. Moreover, an
IoT agriculture framework has been presented that contextualizes the representation of a wide range
of current solutions in the ﬁeld of agriculture. Similarly, country policies for IoT-based agriculture
have also been presented. Lastly, open issues and challenges have been presented to provide the
researchers promising future directions in the domain of IoT agriculture.
Keywords:internetofthings;agriculture;devices/sensors;agriculturalapplications;communicationprotocols
1. Introduction
The widespread of the internet from the last two decades has brought unlimited beneﬁts for
organizations and citizens over the globe. The major beneﬁt of this innovation was the capability
to producer and consumer services in real time. Recently, Internet of Things (IoT) is promising
to provide the same beneﬁt through its innovative technologies and giving a way to enhance the
user’s perception and ability by modifying the working environment. IoT oﬀers multiple solutions in
diﬀerent domains such as healthcare, retail, traﬃc, security, smart homes, smart cities, and agriculture.
IoT deployment in agriculture is considered the ideal solution because in this area there is a need for
continuous monitoring and controlling. In the ﬁeld of agriculture, IoT is used at diﬀerent levels in the
agriculture industrial production chain [1]. The main applications of IoT in agriculture are Precision
Farming, Livestock, and Greenhouses, which are grouped into diﬀerent monitoring domains. All these
applications are monitored with the help of diﬀerent IoT-based sensors/devices by using wireless
Electronics 2020, 9, 319; doi:10.3390/electronics9020319
www.mdpi.com/journal/electronics
Electronics 2020, 9, 319
2 of 41
sensor networks (WSNs) that helps the farmers collect relevant data through sensing devices. Some
IoT-based setups analyze and process the remote data by applying cloud services, which helps the
researchers and agriculturists make better decisions. Nowadays, with the advancement of current
technology, environment monitoring solutions oﬀer additional facilities in terms of management
and decision making. A custom-made landslide risk monitoring system has been developed that
allows quick implementations in hostile environments without user intervention [2]. What is more
interesting about the developed system is that it deals with node failures and reorganizes the poor
quality communication links on the network by itself. An IoT management is proposed in [3] that
monitors the elements such as wind, soil, atmosphere, and water over a large area. Moreover, IoT-based
agricultural monitoring solutions have been identiﬁed based on the sub-domains to which they
belong. The identiﬁed sub-domains are soil monitoring, air monitoring, temperature monitoring,
water monitoring, disease monitoring, location monitoring, environmental conditions monitoring,
pest monitoring, and fertilization monitoring. Further, the IoT paradigm improves human interaction
in the physical world through low-cost electronic devices and communication protocols. IoT also
monitors diﬀerent environmental conditions to create dense and real-time maps of noise level, air,
water pollution, temperature, and damaging radiations [4,5]. Besides, data collected about diﬀerent
environmental parameters is transmitted to the user by trigger alerts or sending recommendations to
authorities via messages [6].
In the last few decades, a large number of studies have been presented in the IoT-based agriculture
domain. Therefore, it is important to collect, summarize, analyze, and classify the state-of-the-art
research in this area. The purpose of this research is to present a comprehensive systematic literature
review in the ﬁeld of IoT agriculture. The contributions of this paper related to the IoT agriculture
domain are as follows. In Section 2, we present a background of IoT agriculture technology. In Section 3,
we present the research methodology by deﬁning research questions, inclusion/exclusion criteria, and
search string to collect eﬀective studies relevant to the IoT agriculture domain and focused on diﬀerent
publication channels. In Section 4, we present the research results in the form of tables by synthesizing
the selected papers. Besides, some IoT-based agricultural applications, sensors/devices, communication
protocols, and country policies are also presented in this section. In Section 5, we present a summary
of our ﬁndings through a research hierarchy and designed an IoT-based smart farming framework.
In Section 6, open issues and challenges in IoT agriculture have been discussed from many diﬀerent
perspectives. Moreover, research validity threats are presented in Section 8. Section 9 presents the
conclusions of the article.
2. Background
Researchers have proposed diﬀerent IoT-based technologies in the agriculture ﬁeld that are
increasing the production with less workforce eﬀort. Researchers have also worked on diﬀerent
IoT-based agriculture projects to improve the quality and increase agricultural productivity. Some
IoT-based agricultural techniques have been identiﬁed from the literature, which have been summarized
in this section.
Carnegie Melon University has worked on a plant nursery by using wireless
sensors technology [7]. In [8], a WSN-based polyhouse monitoring system has been presented
that makes use of carbon dioxide, humidity, temperature and light detection modules. By using GPS
technology and ZigBee protocol a WSN-based system has been proposed that monitors diﬀerent
agricultural parameters [9]. A real-time rice crop monitoring system has been designed to increase
the productivity [10]. The crop monitoring system has been presented in [11], which collects the
information of rainfall and temperature and analyzes it to mitigate the risk of crop loss and enhance
crop productivity. A low-cost Bluetooth-based system has been proposed in [12] for monitoring various
agricultural variables such as temperature by using a microcontroller that works as a weather station.
The proposed system is best for monitoring real-time ﬁeld data. Moreover, the disadvantage of this
system is its limited communication range and required Bluetooth conﬁguration with smartphones
for continuous monitoring. A smart sensing platform based on ZigBee has developed by [13] for
Electronics 2020, 9, 319
3 of 41
monitoring diﬀerent environmental conditions such as humidity, temperature, sunlight, and pressure.
The developed platform provides a fast data rate, low-cost hardware, and an accurate sensor working
on mesh network so that each node can communicate with each other eﬀectively. A Global System for
Mobile Communications (GSM) based irrigation monitoring system has been developed that uses an
android app for measuring diﬀerent environmental conditions such as humidity, temperature, and
control of the water level. The basic purpose of this system is to develop a low-cost wireless system,
whereas the negative aspect of the system is to know the operating command to actuate the ﬁeld
motor and agriculture parameters [14]. To measure the greenhouse parameters such as humidity and
temperature, a system has been proposed on the basis of GSM and Field Programmable Gate Array
(FPGA). The proposed system provides cost-eﬀective and timely monitoring solutions to monitor crop
and soil conditions [15]. In [16], a simple, ﬂexible networking low-cost system has been proposed that
uses a fuzzy control system to monitor diﬀerent greenhouse parameters. The operation and design
methodologies for WSN have been proposed in [17] for a more advanced monitoring and controlling
system in the greenhouse. Multiple environmental problems related to greenhouses have also been
addressed such as WSN components standardization, wireless node packaging, and electromagnetic
ﬁeld interference. In [18], a system has been proposed that monitors the animal’s health as well as
identiﬁes the widespread diseases, whether it originates from biological attacks or natural causes.
A low-cost animal health monitoring system is presented in [19] that measures the heart rate, postures,
and body temperature.
3. Research Methodology
A systematic literature review (SLR) is selected as the research methodology for this paper. The goal
of this research is to investigate and provide a review of existing IoT-based agricultural monitoring
applications, sensors/devices, and communication protocols. We have followed the methodology
proposed by [20] to make research impartial in the context of information selection and results in
representations. The research methodology for this systematic mapping study has been illustrated in
Figure 1.
Electronics 2020, 9, x FOR PEER REVIEW 
3 of 41 
sensor working on mesh network so that each node can communicate with each other effectively. A 
Global System for Mobile Communications (GSM) based irrigation monitoring system has been 
developed that uses an android app for measuring different environmental conditions such as 
humidity, temperature, and control of the water level. The basic purpose of this system is to develop 
a low-cost wireless system, whereas the negative aspect of the system is to know the operating 
command to actuate the field motor and agriculture parameters [14]. To measure the greenhouse 
parameters such as humidity and temperature, a system has been proposed on the basis of GSM and 
Field Programmable Gate Array (FPGA). The proposed system provides cost-effective and timely 
monitoring solutions to monitor crop and soil conditions [15]. In [16], a simple, flexible networking 
low-cost system has been proposed that uses a fuzzy control system to monitor different greenhouse 
parameters. The operation and design methodologies for WSN have been proposed in [17] for a more 
advanced monitoring and controlling system in the greenhouse. Multiple environmental problems 
related to greenhouses have also been addressed such as WSN components standardization, wireless 
node packaging, and electromagnetic field interference. In [18], a system has been proposed that 
monitors the animal’s health as well as identifies the widespread diseases, whether it originates from 
biological attacks or natural causes. A low-cost animal health monitoring system is presented in [19] 
that measures the heart rate, postures, and body temperature. 
3. Research Methodology 
A systematic literature review (SLR) is selected as the research methodology for this paper. The 
goal of this research is to investigate and provide a review of existing IoT-based agricultural 
monitoring applications, sensors/devices, and communication protocols. We have followed the 
methodology proposed by [20] to make research impartial in the context of information selection and 
results in representations. The research methodology for this systematic mapping study has been 
illustrated in Figure 1. 
 
Figure 1. Research methodology. 
3.1. Research Objectives 
This research comprised on the following objectives: 
O1: More focused state-of-the-art research work has been identified in the field of IoT 
agriculture. 
O2: Characterize the existing IoT agriculture applications, sensors/devices, and communication 
protocols. 
O3: Proposed a taxonomy that further highlights the adopted IoT agriculture methods and 
approaches. 
O4: An IoT-based smart farming framework has been proposed that consists of basic IoT 
agriculture terms to identify the existing IoT solutions for the purpose of smart farming. 
O5: Identify the research gaps in terms of challenges and open issues. 
 
Figure 1. Research methodology.
3.1. Research Objectives
This research comprised on the following objectives:
O1: More focused state-of-the-art research work has been identiﬁed in the ﬁeld of IoT agriculture.
O2: Characterize the existing IoT agriculture applications, sensors/devices, and communication protocols.
O3: ProposedataxonomythatfurtherhighlightstheadoptedIoTagriculturemethodsandapproaches.
O4: An IoT-based smart farming framework has been proposed that consists of basic IoT agriculture
terms to identify the existing IoT solutions for the purpose of smart farming.
O5: Identify the research gaps in terms of challenges and open issues.
Electronics 2020, 9, 319
4 of 41
3.2. Research Questions
The ﬁrst step of this SLR is the deﬁnition of research questions and provision of the current
research status on IoT-based agriculture. This SLR addresses eight research questions with their
corresponding motivation represented in Table 1.
Table 1. Research questions. IoT: Internet of Things.
No
Research Question
Main Motivation
RQ1
What are the major targeted primary publication
channels for IoT agricultural research?
In order to identify where IoT agricultural
research can be found as well as good
publication sources for future studies.
RQ2
How has the frequency of approaches been
changed related to IoT agriculture over time?
Identify the publication with the time related to
IoT in agriculture.
RQ3
What approaches are used to address problems
related IoT agriculture?
To ﬁnd out existing IoT agriculture approaches
reported in the existing IoT agriculture literature.
RQ4
What are the main application domains of IoT in
agriculture?
Identify the main areas of agriculture where
IoT technology is being utilized for monitoring,
controlling, and tracking purposes.
RQ5
What are the primary focuses of the selected
studies?
To identify the signiﬁcant proposed solutions.
RQ6
What type of IoT devices/sensors have been
used in agriculture?
To identify the role of primary
IoT devices/sensors.
RQ7
Which IoT network/communication protocols
are used in agriculture?
To identify the role of network and
communication protocols.
RQ8
Which IoT agricultural policy have been
implemented in diﬀerent countries?
To measure the potential of IoT in the agriculture
ﬁeld in the diﬀerent countries.
3.3. Search String
The second phase of SLR is to search for relevant studies on the research topics. A search string
has been deﬁned that is used to gather published articles related to the research topics. We conducted
a pilot search based on the speciﬁc keywords, and we decided to use only IoT applications in the
agriculture search string. However, in the pilot search, we have also used IoT sensors/devices and
communication protocols in agriculture. Internet research has been performed by using multiple search
engines and digital libraries to collect information. The obtained results were compiled manually
to get the best sources for information to answer the deﬁned research questions. Selected search
engines and digital libraries have been chosen based on their scientiﬁc contents and closely related
to the objective of this paper. The chosen databases were Springer, Elsevier, IEEE, MDPI, and IGI
Global. The next step is to identify the consistent procedures and search terms to seek out technical
and scientiﬁc documentation in search engines and digital libraries. The set of keywords selected to
deﬁne the search string from the research questions is given in Table 2.
Table 2. Search string.
Sources
Search String
Context
IEEE Xplore, Science
Direct, Springer Link,
MDPI, and IGI Global
(“Internet of Things” OR “IoT”) AND (“IoT agricultural
Applications” OR “Devices/Sensors” OR “IoT agricultural
devices/sensors”) OR (“IoT agricultural protocols” OR
“IoT Communication Protocols”)
Agriculture
3.4. Screening of Relevant Papers
All the papers in the search were not precisely relevant to research questions; therefore, they
needed to be assessed according to the actual relevancy. For this purpose, we used the search process
Electronics 2020, 9, 319
5 of 41
deﬁned by Dybå and Dingsøyr [21] for the screening of relevant papers. In the ﬁrst screening phase,
papers were selected based on their titles, and we excluded those studies that were irrelevant to the
research area. For example, the keyword protocol returns articles relevant to IoT in other ﬁelds that
have diﬀerent meanings than the IoT technology used in agriculture. These papers were totally out of
scope, so we excluded them. In the second phase of screening, we read the abstract of each article that
was selected in the ﬁrst screening phase. Furthermore, inclusion and exclusion criteria also used to
screen papers.
We decided to exclude the following types of papers:
•
Articles not presenting new and emerging ideas.
•
Papers published other than conferences, journals, patents, and technical reports.
•
Articles without deﬁning data sources or where the data collection procedure was unclear.
•
Articles not published in the English language.
•
Papers published before 2006.
•
Papers that are not relevant to the search string.
Papers have been selected on the basis of the given exclusion criteria and after examining the
abstract of selected studies, we have decided to include it in the next screening phase.
3.5. Keywording Using Abstract
To ﬁnd the relevant papers through keywording by using the abstract, we used a process deﬁned
by Petersen et al. [22]. Keywording has been done in two phases. In the ﬁrst phase, we have examined
the abstract and identiﬁed the concepts and keywords that reﬂected the contribution of the studies.
In the second phase, a higher level of understanding is developed on the basis of these keywords. For
the mapping of reviews, we have used keywords to form and cluster the categories.
3.6. Quality Assessment
In an SLR, generally, quality assessment (QA) is carried out to assess the quality of selected papers.
In this SLR, a questionnaire has been designed to measure the quality of the selected papers. The QA
in this SLR is carried out by following the previous mapping study [23].
(a)
The study contributes to IoT in agriculture. The possible answers for this research question were
“Yes (+1)” and “No (0)”.
(b)
The study represents a clear solution in the ﬁeld of agriculture by using IoT. The possible answers
for this research question were “Yes (+1)”, “partially (0.5)”, and “No (0)”.
(c)
The published studies that have been cited by other articles and possible answers for this research
question were: “partially (0)” if the citation count is 1 to 5, “No (−1)” if paper is not being cited by
any author, and “Yes (+1)” if citation count is more than ﬁve.
(d)
The published study is from a stable and recognized publication source. The answer to this
question has been evaluated by considering the Journal Citation Reports (JCR) lists and CORE
ranking computer science conferences.
Possible answers for journals and conferences are presented in Table 3.
Electronics 2020, 9, 319
6 of 41
Table 3. Quality criteria. JCR: Journal Citation Reports.
Sources
Ranking
Score
Journal
Q1
2
Q2
1.5
Q3 or Q4
1
If paper is not in a JCR ranking
0
Conference
CORE A
1.5
CORE B
1
CORE C
0.5
If paper is not in a CORE ranking
0
Selected studies have a score for each question, and the calculated sum of scores is presented in
the form of an integer between −1 and 5.
3.7. Study Selection Process
The selection and search processes results are presented in Table 4. Initially, 3179 papers were
selected when the search protocol was applied on the selected repositories. A screening process
has been applied on the basis of the exclusion criteria, keywords, titles, abstracts, and full articles
of retrieved papers. One author retrieved all these papers; then, two authors examined the papers,
which led to the selection of a total 240 papers. After that, we eliminated the duplicate titles and the
titles that were not relevant to the review. For example, most of the excluded papers were related to
general IoT such as privacy, security, healthcare, retail, and smart cities. To determine the assessment
agreement between two authors, a Cohen’s kappa coeﬃcient of 0.91 was used, which indicates that
the evaluation made by authors is a perfect measurement [24]. Furthermore, after reading the full
abstracts of the selected 171 papers in the duplication phase, we have selected 104 papers on the basis
of their abstracts. In the end, 67 studies were selected out of 3179.
Table 4. Primary selection process for retrieved articles.
Phase
Process
Selection Criteria
IEEE
Xplore
Springer
Science
Direct
MDPI
IGI
Global
Total
1
Search
Keywords
1900
601
402
255
21
3179
2
Screening
Title
111
63
27
31
8
240
3
Screening
Duplication Removal
72
53
29
11
6
171
4
Screening
Abstract
45
24
21
9
5
104
5
Inspection
Full Article
47
6
7
6
1
67
3.8. Data Extraction Method
The data extraction strategy has been applied to providing a set of possible answers to the deﬁned
research questions.
RQ1: The answer to this question is given by identifying the publication channels and sources for
all papers.
RQ2: To identify the frequency of approaches of each article, which has been classiﬁed according
to the publication year.
RQ3: Research approaches have been classiﬁed according to developing techniques in the selected
studies such as whether they proposed a system, solution, method, model, application, survey, platform,
architecture, ecosystem, review, and framework.
RQ4: To identify the primary IoT solution for agriculture, diﬀerent monitoring, controlling, and
tracking applications have been investigated.
RQ5: The deﬁned research question identiﬁes the primary focus of the selected studies in the
IoT agricultural ﬁeld.
Electronics 2020, 9, 319
7 of 41
RQ6: This research question has been designed to measure the utilization of devices/sensors used
by selected IoT agricultural solutions.
RQ7: Which communication protocol or network system has been designed or implemented to
provide an IoT-based agricultural solution.
RQ8: Diﬀerent country policies have been discussed to measure the value of IoT in agriculture.
4. Analysis
In this section, ﬁndings related to the SLR questions that are presented in Table 1 are described.
Research studies after choosing the screening process have been used to illustrate each research
question answer to make an essential contribution to the IoT agriculture ﬁeld.
4.1. Selection of Results
Analysis of the state-of-the-art IoT-based smart farming studies is a key challenge due to the
coverage of multiple application domains, communication protocols, sensors/devices, and protocols.
According to our research questions, we have gathered 67 primary studies in this section. After analyzing
the selected studies, we have addressed each question according to the extracted information. Quality
assessment and the overall classiﬁcation results of the selected papers have been presented in Table 5.
Electronics 2020, 9, 319
8 of 41
Table 5. Classiﬁcation and quality assessment scores. WSN: wireless sensor networks.
Classiﬁcation
Quality Assessment
Reference
P.
Channel
Years
Research
Approaches
Applications
Domain
Major Focus
Sensors and
Devices
Protocols/
Network
Type
a
b
c
d
Scores
[25]
Journal
2009
Method
Monitoring
Proposed a method to measure the
environmental conditions in a vast area
such as air humidity and temperature.
Microclimate Sensor
ZigBee/WSN
1
1
1
2
4.5
[26]
Conference
2014
Platform
Monitoring
Designed a platform to monitor the soil
moisture and temperature all over the
ﬁeld.
Core Ship CC2530
WSN
1
1
0
0
2
[27]
Conference
2014
Architecture
Controlling
A WSN-based irrigation solution has
been presented.
Water Quality
Sensing Node
WSN
1
1
1
0
3
[28]
Conference
2009
Method
Controlling
A low-cost wireless irrigation system has
been proposed.
Sensor Node and
Microcontroller
GPRS/WSN
1
1
1
0
3
[29]
Colloquium 2014
Method
Controlling
A web-based decision support system has
been developed for irrigation scheduling.
Weather Station
WSN
1
1
1
0
3
[30]
Symposium 2006
Architecture
Monitoring
A preliminary investigation system is
presented on a large-scale sensor network
for precision agriculture.
LOFAR-agro
WSN
1
1
1
0
3
[31]
Conference
2015
Platform
Monitoring
Proposed an intrusion detection system to
monitor the ﬁeld.
AVR Microcontroller
WSN
1
1
1
0
3
[32]
Conference
2008
Method
Tracking
Designed a method to track the behavior
of animals in the ﬁeld.
Wild CENSE Node
GPS/WSN
1
1
1
1.5
4.5
[33]
Journal
2013
Method
Controlling
Developed a climate controlling method
for greenhouses.
Sensor Nodes
ZigBee/WSN
1
1
0
0
2
[34]
Conference
2009
Method
Monitoring
A sensor network is designed to measure
the soil moisture.
Soil Moisture Sensor
ZigBee/WSN
1
1
0
0
2
[35]
Conference
2015
Architecture
Monitoring
Developed a system to monitor the
drought and irrigation level.
No
No
1
0.5
0
0
1.5
[36]
Conference
2017
Proposed
System
Monitoring
and
Controlling
A wireless mobile robot system has been
developed to perform multiple
monitoring and controlling tasks.
Various
Sensors/Raspberry
PI
WIFI, ZigBee
1
1
1
0
3
[37]
Conference
2015
Proposed
System
Monitoring
Proposed a system to monitor the ﬁeld
and greenhouse gas.
Various Sensors
WSN
1
0.5
0
0
1.5
Electronics 2020, 9, 319
9 of 41
Table 5. Cont.
Classiﬁcation
Quality Assessment
Reference
P.
Channel
Years
Research
Approaches
Applications
Domain
Major Focus
Sensors and
Devices
Protocols/
Network
Type
a
b
c
d
Scores
[38]
Journal
2012
Proposed
System
Tracking
Proposed a design to measure the animal
movement.
No
GPS
1
1
1
2
5
[39]
Conference
2018
Proposed
System
Monitoring
An innovative and scalable system has
been proposed for monitoring the
agricultural system.
Humidity and
Temperature Sensor
LoraWAN
1
0.5
1
0
2.5
[40]
Journal
2019
Model
Monitoring
Proposed a model to measure the crop
productivity and anticipate the problems.
Various Sensors
Lora
1
1
0
2
4
[41]
Conference
2017
Proposed
System
Monitoring
An IoT-based agricultural production
system has been developed to monitor
the ﬁeld of environmental parameters.
Temperature and
Moisture Sensor
RFID
1
1
1
0
3
[42]
Symposium 2017
Proposed
System
Monitoring
Developed a low-cost irrigation
monitoring system.
Soil Moisture Sensor
MQTT
1
1
1
0
3
[43]
Conference
2015
Proposed
System
Monitoring
Developed an animal pastures
monitoring system.
Collars and
Geolocation Devices
GPS, SigFox
1
1
1
0
3
[44]
Conference
2011
Proposed
System
Monitoring
Developed a WiFi-based wireless sensor
network for ﬁeld and smart grid
monitoring.
WiFi Sensor
ZigBee,
WIFI, WSN
1
1
1
0
3
[45]
Journal
2009
Review
Monitoring
Presented a review on the role of WSN for
precision agriculture.
Sensor
Nodes/Gateway
RFID, WSN
ZigBee
1
1
1
1.5
4.5
[46]
Journal
2011
Method
No
Integrated WiFi and WiMAX for agri
IoT users.
No
WIFI,
WIMAX
1
1
1
1
4
[47]
Journal
2018
Ecosystem
Monitoring
Several IoT agricultural beneﬁts and
challenges have been discussed for
monitoring air, temperature, humidity,
and moisture level.
Multiple Sensors
and Devices
Sigfox, Lora,
NB-IoT, Wiﬁ
1
1
1
2
5
[48]
Journal
2019
Framework
Monitoring
An experimental framework has been
designed to monitor diﬀerent agricultural
applications such as water, fertilization,
heat, and gas
Various
Sensors/Gateway
ZigBee,
MQTT/WSN
1
1
0
2
4
Electronics 2020, 9, 319
10 of 41
Table 5. Cont.
Classiﬁcation
Quality Assessment
Reference
P.
Channel
Years
Research
Approaches
Applications
Domain
Major Focus
Sensors and
Devices
Protocols/
Network
Type
a
b
c
d
Scores
[49]
Journal
2019
Platform
Controlling
Proposed a low-cost agri talk IoT-based
platform for the precision farming of soil
cultivation.
Soil and Insects
Sensor, Actuators
Network
Time
Protocol
(NTP)
1
1
0
2
4
[50]
Conference
2010
Proposed
system
Controlling
A system has been proposed to control
the environmental parameters such as
humidity and temperature.
Temperature and
Humidity Sensor
SMS,
Wireless
application
protocol
(WAP)
1
1
1
0
3
[51]
Journal
2018
Model
Tracking
A tracking and record-keeping model has
been presented that traces the growth
level of plants in a greenhouse.
Various sensors and
Raspberry Pi 3
WIFI
1
1
−1
2
3
[52]
Conference
2018
Application
proposed
Monitoring
Cloud-based IoT application is developed
to monitor diﬀerent agricultural
parameters, which are water, light
humidity, and pesticides.
Soil Moisture,
Temperature, and
Humidity
Sensor/Microcontroller
GPS, WIFI
1
0.5
0
0
1.5
[53]
Conference
2018
Proposed
model
Controlling
The author collects poly houses data
about crop productivity and uses WiFi to
transmit data over the network to control
insects and pesticides.
Soil moisture, PH
Humidity and Water
Sensor
WIFI
1
0.5
0
0
1.5
[54]
Conference
2017
Proposed
system
Monitoring
A remote sensing system has been
proposed to monitor diﬀerent greenhouse
parameters such as soil moisture,
temperature, and light.
Various Sensors,
Actuators, and
Embedded System
WSN
1
1
0
0
2
[55]
Conference
2018
Proposed
system
Monitoring
Low power and the prolonged network
has been proposed in the agriculture ﬁeld
to monitor soil moisture content.
Soil Moisture Sensor
Lora
1
1
1
0
3
[56]
Conference
2012
Platform
Controlling
System captures the data of growing
fruits, control plants environment, water,
and fertilizers.
Various Sensors
RFID/WSN
1
0.5
1
0
3.5
Electronics 2020, 9, 319
11 of 41
Table 5. Cont.
Classiﬁcation
Quality Assessment
Reference
P.
Channel
Years
Research
Approaches
Applications
Domain
Major Focus
Sensors and
Devices
Protocols/
Network
Type
a
b
c
d
Scores
[57]
Conference
2019
Proposed
system
Controlling
Designed a system to test and self-power
IoT devices for precision agriculture to
control fertilization.
Various
Sensors/Gateway,
Microcontroller
Ultra-low
power
(ULP),
MQTT,
Bluetooth
1
1
−1
0
1
[58]
Conference
2016
Architecture
Monitoring
An IoT-based three-layered architecture
has been proposed to monitor diﬀerent
precision agricultural applications such as
wind detection, rain volume, air
temperature, and humidity.
Multiple Sensors
nRF24L01
ultra-low-power
transceiver
1
0.5
1
0
2.5
[59]
Conference
2018
Method
Monitoring
A method has been proposed to monitor
multiple ﬁeld parameters such as soil
humidity and temperature.
Various
Sensors/Microcontroller,
Gateway
WiFi
1
0.5
0
0
1.5
[60]
Conference
2017
Survey
Monitoring
A survey of diﬀerent monitoring
applications and communication
protocols.
Various Sensors
Multiple
Protocols
1
0.5
1
0
2.5
[61]
Conference
2018
Platform
Monitoring
An IoT-based animal’s behavior
monitoring platform has been developed.
Various
Sensors/Gateway
GPS
1
1
1
0
3
[62]
Conference
2015
Framework
Controlling
Developed an innovative project to
facilitate the farmers and improve the
farm productivity by controlling water.
Radar Level Sensor
GSM
1
1
1
0
3
[63]
Conference
2017
Solution
Proposal
Monitoring
Paper presents a remote monitoring leaf
disease detection scenario.
Temperature, Soil
Moisture,
Humidity/Raspberry
PI
WiFi
1
1
0
0
2
[64]
Conference
2018
Proposed
System
Controlling
A system has been developed to increase
crop productivity by low water
consumption.
Temperature, Soil
Moisture
Sensors/Raspberry
PI
4G mobile
network
1
0.5
1
0
1.5
[65]
Conference
2017
Model
Controlling
Proposed a model to minimize the use of
fungicides and pesticides in plants.
Weather Station
No
1
0.5
0
0
1.5
Electronics 2020, 9, 319
12 of 41
Table 5. Cont.
Classiﬁcation
Quality Assessment
Reference
P.
Channel
Years
Research
Approaches
Applications
Domain
Major Focus
Sensors and
Devices
Protocols/
Network
Type
a
b
c
d
Scores
[66]
Conference
2018
Proposed
System
Controlling
A repelling system is provided to prevent
the crop from wild animal attacks.
Microcontroller,
Gateway
6LowPAN
1
1
0
0
2
[67]
Conference
2018
Proposed
System
Controlling
A web and android app-based power
eﬃcient irrigation control system has
been developed.
Temperature,
Moisture, and
Humidity Sensors
Lora
1
1
−1
0
1
[68]
Journal
2019
Architecture
Monitoring
Developed an agricultural watering
system on the basis of WSN.
Temperature and
Humidity/Node
MCU
WSN
1
1
1
2
5
[69]
Conference
2018
Application
Controlling
Developed an application for disease
detection at early stages.
Sensor
Nodes/Gateway
WIFI,
Bluetooth,
ZigBee,
GPRS
1
1
1
0
3
[70]
Conference
2016
Application
Monitoring
An e-Agriculture application has been
developed to monitor crop productivity.
Temperature and
Humidity sensor
3G, WIFI
1
1
1
0
3
[71]
Journal
2019
Proposed
System
Monitoring
An intelligent and low-cost irrigation
monitoring system is developed.
Uniﬁed Sensor
Poled
HTTP,
MQTT
1
1
−1
2
3
[72]
Journal
2018
Architecture
Monitoring
Proposed an architecture to monitor
multiple agricultural parameters such as
temperature, humidity, and soil moisture.
Multiple Sensors
WSN
1
1
−1
2
3
[73]
Journal
2018
Proposed
System
Monitoring
A smart irrigation system is developed by
using open source technologies and
machine learning.
Multiple Sensors
WSN, HTTP,
WIFI
1
1
1
2
5
[74]
Workshop
2017
Proposed
System
Monitoring
A greenhouse monitoring system has
been developed to monitor the diﬀerent
parameters such as light, temperature,
humidity, and pressure.
MicaZ
WSN
1
1
1
0
3
[75]
Journal
2017
Method
Monitoring
Proposed a method that monitors the soil
moisture and nutrients level.
Various Sensors
Zigbee
1
1
1
1
4
[76]
Journal
2016
Platform
Monitoring
To automate the environment condition,
soil conditions, and fertilization, a smart
net platform is proposed.
Various
Sensors/Cameras,
Weather Stations
No
1
1
1
1
4
Electronics 2020, 9, 319
13 of 41
Table 5. Cont.
Classiﬁcation
Quality Assessment
Reference
P.
Channel
Years
Research
Approaches
Applications
Domain
Major Focus
Sensors and
Devices
Protocols/
Network
Type
a
b
c
d
Scores
[77]
Journal
2016
Platform
Monitoring
A monitoring platform has been
proposed for the suitability of FIWARE
precision agriculture.
Sensors/Gateway
FIWARE/WSN
1
1
1
1
4
[78]
Journal
2019
Platform
Monitoring
IoT-based smart irrigation system has
been developed.
Various Sensors
FIWARE
1
1
1
1
4
[79]
Journal
2018
Proposed
System
Monitoring
Analyzed and measured the
environmental variables and crop disease.
Proposed cloud-based technology.
Growth, Nutrients
and Environmental
Sensors
LORA
1
1
0
1
3
[80]
Journal
2019
Method
Monitoring
Introduced the augmented reality use and
integrating it with IoT to update precision
farming.
Various
Sensors/Camera
RFID
1
1
−1
1
2
[81]
Journal
2011
Method
Monitoring
An ontology-based approach has been
presented for smart farming to solve the
semantic interoperate problem.
No
No
1
0.5
1
0
2.5
[82]
Conference
2016
Survey
Monitoring
IoT technology status and IoT agriculture
such as precision seeding and irrigation
have been investigated.
Sensors Module
RFID
1
0.5
0
0
1.5
[83]
Journal
2013
Method
Monitoring
Discussed the practical applications and
theoretical research gap of IoT agriculture.
No
RFID/Information
Network
System
1
0.5
1
0
2.5
[84]
Journal
2018
Framework
Controlling
Proposed a solution for the eﬃcient usage
of water.
Various Sensors
WSN
1
1
1
1.5
[85]
Journal
2015
Proposed
Solution
Monitoring
Discussed agricultural challenges and
proposed a solution to monitor oil
moisture.
Soil Sensor
WSN
1
1
1
1
4
[86]
Symposium 2016
Proposed
Solution
Monitoring
A methodology has been proposed to
monitor the quantity and quality of grains
in soil.
Various Sensors and
Devices
WSN
1
1
1
0
3
[87]
Journal
2017
Proposed
Solution
Monitoring
Proposed a cloud-based information
system to deliver agricultural solutions.
Various Sensors and
Devices
WSN
1
1
1
1
4
Electronics 2020, 9, 319
14 of 41
Table 5. Cont.
Classiﬁcation
Quality Assessment
Reference
P.
Channel
Years
Research
Approaches
Applications
Domain
Major Focus
Sensors and
Devices
Protocols/
Network
Type
a
b
c
d
Scores
[88]
Journal
2013
Architecture
Monitoring
Proposed an architecture on the basis of
Routing Protocol for Low-Power and
Lossy Networks (RPL) protocol to meet
speciﬁc requirements for precision
agriculture.
No
RPL
1
1
0
1
3
[89]
Conference
2017
Proposed
System
Monitoring
A system has been proposed to monitor
animal diseases by using data mining
techniques.
Temperature
Humidity and Heart
Rate Sensors
WSN, WiFi,
HTTP, GPRS
1
0.5
1
0
2.5
[90]
Conference
2015
Proposed
System
Monitoring
Environment monitoring system has been
developed for animal shelters.
Environmental
Sensor, Aurdino,
UHF Reader
RFID, WSN
1
1
1
0
3
[91]
Conference
2017
Proposed
System
Monitoring
To monitor the behavior of small animals,
a system has been proposed by using
multiple IoT sensors.
IFR, Humidity and
Temperature
sensors, Raspberry
PI, Camera
WSN,
Bluetooth
1
1
0
0
2
Electronics 2020, 9, 319
15 of 41
4.1.1. Assessment of RQ1: What Are the Major Targeted Primary Publication Channels for
IoT Agricultural Research?
Table 5 shows the diﬀerent publications channels and several articles that have been published on
these channels. Five diﬀerent publication channels have been identiﬁed, in which 45% of the papers
were presented in conferences, 1% of the papers were presented in workshops, 5% of the papers
appeared in symposiums, 1% of the papers appeared in a colloquium, and 48% of the papers were
published in journals. Note that 39% of the papers have been published in IEEE conferences, as shown
in Table 6.
Table 6. Publication channels.
Publication Sources
References
Channel
NO
%
Sensors
[25,45,76–79]
Journal
7
10.44%
International Conference on Wireless Communication and
Sensor Network
[26]
Conference
1
1.49%
IET Science, Measurement, and Technology
[27]
Journal
1
1.49%
International Conference on Networks Security, Wireless
Communications, and Trusted Computing
[28]
Conference
1
1.49%
International Colloquium in Information Science and
Technology
[29]
Colloquium
1
1.49%
International Parallel and Distributed Processing
Symposium
[30]
Symposium
1
1.49%
International Conference on Communications
[31]
Conference
1
1.49%
International Conference on Intelligent Sensors, Sensor
Networks, and Information Processing
[32]
Conference
1
1.49%
Pervasive Computing
[33]
Journal
1
1.49%
Annual Conference on Information Sciences and Systems
[34]
Conference
1
1.49%
International Conference on Geo informatics
[35]
Conference
1
1.49%
International Conference on I-SMAC (IoT in Social, Mobile,
Analytics and Cloud)
[36]
Conference
1
1.49%
International Conference on Intelligent Robots and Systems
[37]
Conference
1
1.49%
Transactions on Wireless Communications
[42]
Journal
1
1.49%
International Workshop on Factory Communication Systems
[39]
Conference
1
1.49%
Computers and Electronics in Agriculture
[40,68,71–73]
Journal
5
7.45%
International Conference on Smart Technologies for Smart
Nation (SmartTechCon)
[41]
Conference
1
1.49%
Region 10 Symposium (TENSYMP)
[42]
Symposium
1
1.49%
International Conference on Industrial Technology
[43]
Conference
1
1.49%
Conference on Industrial Electronics and Applications
[44]
Conference
1
1.49%
Research journal of applied sciences, engineering and
technology
[46]
Journal
1
1.49%
IEEE Internet of Things Journal
[47,48]
Journal
2
3%
IEEE Access
[48,51]
Journal
2
3%
International Conference on Computer Science and
Information Technology
[50]
Conference
1
1.49%
International Conference on Trends in Electronics and
Informatics
[52]
Conference
1
1.49%
Electronics 2020, 9, 319
16 of 41
Table 6. Cont.
Publication Sources
References
Channel
NO
%
International Conference on Inventive Research in
Computing Applications
[53]
Conference
1
1.49%
International Conference on Big Data, IoT, and Data Science
[54,63]
Conference
2
3%
World Forum on Internet of Things (WF-IoT)
[55,57]
Conference
2
3%
International Conference on Image Analysis and Signal
Processing
[56]
Conference
1
1.49%
International Conference on Microelectronics (ICM)
[58]
Conference
1
1.49%
International Conference on Cloud Computing, Data
Science and Engineering (Conﬂuence)
[59]
Conference
1
1.49%
International Conference on Microelectronic Devices,
Circuits, and Systems (ICMDCS)
[60]
Conference
1
1.49%
IoT Vertical and Topical Summit on Agriculture—Tuscany
(IOT Tuscany)
[61]
Conference
1
1.49%
IEEE Technological Innovation in ICT for Agriculture and
Rural Development (TIAR)
[62]
Conference
1
1.49%
International Conference on Inventive Systems and Control
(ICISC)
[64]
Conference
1
1.49%
International Conference on Ubiquitous and Future
Networks (ICUFN)
[65,90]
Conference
2
3%
International Conference on Environmental Engineering
(EE)
[66]
Conference
1
1.49%
International Conference on Innovations in Science,
Engineering, and Technology (ICISET)
[67]
Conference
1
1.49%
International Conference on Ambient Systems, Networks,
and Technologies
[69]
Conference
1
1.49%
International Conference on Advances in Computing and
Communications, ICACC
[70]
Conference
1
1.49%
International Workshop on IoT, M2M, and Healthcare
[74]
Workshop
1
1.49%
Sustainability
[80]
Journal
1
1.49%
International Conference on Computer and Computing
Technologies in Agriculture
[81]
Conference
1
1.49%
International Conference on Electrical Engineering and
Automatic Control
[82]
Conference
1
1.49%
Informatics and Management Science
[83]
Journal
1
1.49%
Neural Computing and Applications
[84]
Journal
1
1.49%
In Interoperability and Open-Source Solutions for the
Internet of Things
[85]
Journal
1
1.49%
International Symposium on Intelligent Systems
Technologies and Applications
[86]
Symposium
1
1.49%
Journal of Organizational and End User Computing
[87]
Journal
1
1.49%
International Journal of Agricultural and Environmental
Information Systems
[88]
Journal
1
1.49%
IJETT
[89]
Conference
1
1.49%
International Conference on Intelligent Informatics and
Biomedical Sciences (ICIIBMS)
[91]
Conference
1
1.49%
Electronics 2020, 9, 319
17 of 41
4.1.2. Assessment of RQ2: How Has the Frequency of Approaches Been Changed Related to
IoT Agriculture over Time?
The selected articles published between 2006 and 2009 are shown in Figure 2. It can be seen that
most of the papers have been published between 2015 and 2019 and there are few papers that have been
published in 2019, because the initial search process was made in July of that year. This shows that each
year number of publication are increasing, which indicates the growing interest of IoT in agriculture.
Electronics 2020, 9, x FOR PEER REVIEW 
3 of 41 
 
Figure 2. Distribution of selected papers by year. 
4.1.3. Assessment of RQ3: What Approaches Are Used to Address Problems Related to IoT 
Agriculture? 
There are multiple research approaches in the field of IoT agriculture, as shown in Figure 3. Each 
approach has been investigated in this section. 
(a) Proposed method or solution: There may be single or multiple systems, and solutions have been 
proposed to investigate the phenomenon within its actual context. In [36], a wireless robotic 
system has been proposed to control and monitor the different agricultural tasks. Furthermore, 
several IoT-based systems have been proposed to monitor the animals’ behavior such as 
monitoring health conditions and weather parameters [89–91]. IoT technologies have been 
utilized to provide different agricultural solutions such as monitoring the soil quality, grains 
quality, and quantity in the soil [85–87]. 
(b) Survey/Review: A method that collects quantitative information relevant to IoT agriculture. 
Authors presented a survey on multiple IoT agricultural applications and communication 
protocols [92]. In [93], a survey has been presented on IoT-based precision seeding and 
irrigation. 
(c) Platforms: Different IoT-based platforms have been developed under the controlled 
i
t t
i
it
ff
t
i
lt
A
t
t
k
l tf
h
b
d
l
d
Figure 2. Distribution of selected papers by year.
4.1.3. Assessment of RQ3: What Approaches Are Used to Address Problems Related to
IoT Agriculture?
There are multiple research approaches in the ﬁeld of IoT agriculture, as shown in Figure 3. Each
approach has been investigated in this section.
(a)
Proposed method or solution: There may be single or multiple systems, and solutions have been
proposed to investigate the phenomenon within its actual context. In [36], a wireless robotic system
has been proposed to control and monitor the diﬀerent agricultural tasks. Furthermore, several
IoT-based systems have been proposed to monitor the animals’ behavior such as monitoring
health conditions and weather parameters [89–91]. IoT technologies have been utilized to provide
diﬀerent agricultural solutions such as monitoring the soil quality, grains quality, and quantity in
the soil [85–87].
(b)
Survey/Review: A method that collects quantitative information relevant to IoT agriculture.
Authors presented a survey on multiple IoT agricultural applications and communication
protocols [92]. In [93], a survey has been presented on IoT-based precision seeding and irrigation.
(c)
Platforms: Diﬀerent IoT-based platforms have been developed under the controlled environment
to examine its eﬀect on agriculture. A smart network platform has been developed to monitor
Electronics 2020, 9, 319
18 of 41
the environmental conditions, soil conditions, and fertilizations [54]. In addition, diﬀerent water,
temperature, irrigation, and moisture monitoring platforms have been designed [45].
(d)
Architecture:
Multiple IoT agricultural architecture designed to collect the data from
devices/sensors and store the collected data for proper analysis [68,72,88].
(e)
Application: Mobile apps provide a connection for many IoT devices and facilitate the farmer
having better control over diﬀerent agricultural applications. Several applications have been
developed to monitor the crop productivity and disease detections at early stages [69,70]. In [52],
a cloud-based IoT application has been developed to measure the farm variables such as light,
humidity, water, and pesticides.
(f)
Method: A series of steps taken to acquire knowledge about IoT agriculture. Several methods
have been designed to integrate the communication technologies such as WiFi and WiAX and
measure the ﬁeld parameters such as water quantity, soil humidity, temperature. etc. [32,33,46].
(g)
Framework: A conceptual structure that is intended to guide or support for building something that
explores the guidelines and conceptual structure in useful manners in IoT agriculture [48,62,84].
(h)
Model: A representation of the developed system that investigates the designed properties of
IoT agriculture. The model proposed in [51] tracks and traces the growth level of plants in
a greenhouse.
(i)
Ecosystem: Ecosystems are designed to address the several IoT agricultural solutions and
challenges. In [53], IoT-based smart farming beneﬁts and challenges have been presented to
monitor the air, temperature, and humidity.
Electronics 2020, 9, x FOR PEER REVIEW 
4 of 41 
g) Framework: A conceptual structure that is intended to guide or support for building something 
that explores the guidelines and conceptual structure in useful manners in IoT agriculture 
[48,62,84]. 
h) Model: A representation of the developed system that investigates the designed properties of 
IoT agriculture. The model proposed in [51] tracks and traces the growth level of plants in a 
greenhouse. 
i) 
Ecosystem: Ecosystems are designed to address the several IoT agricultural solutions and 
challenges. In [53], IoT-based smart farming benefits and challenges have been presented to 
monitor the air, temperature, and humidity. 
 
Figure 3. Research Approaches in IoT Agriculture. 
4.1.4. Assessment of Q4: What Are the Main Application Domains of IoT in Agriculture? 
IoT agricultural solutions consist of multiple monitoring, controlling, and tracking applications 
hat measure several types of variables such as air monitoring, temperature monitoring, humidity 
monitoring, soil monitoring, water monitoring, fertilization, pest control, illumination control, and 
ocation tracking. The selected mainstream application domains in this SLR are monitoring, tracking, 
and controlling, as shown in Figure 4. Most of the studies have focused on monitoring (70%), 
controlling (25%), and tracking (5%), as shown in Figure 4. 
Figure 3. Research Approaches in IoT Agriculture.
4.1.4. Assessment of Q4: What Are the Main Application Domains of IoT in Agriculture?
IoT agricultural solutions consist of multiple monitoring, controlling, and tracking applications
that measure several types of variables such as air monitoring, temperature monitoring, humidity
monitoring, soil monitoring, water monitoring, fertilization, pest control, illumination control, and
location tracking. The selected mainstream application domains in this SLR are monitoring, tracking,
and controlling, as shown in Figure 4. Most of the studies have focused on monitoring (70%), controlling
(25%), and tracking (5%), as shown in Figure 4.
Electronics 2020, 9, 319
19 of 41
 
that measure several types of variables such as air monitoring, temperature monitoring, humidity 
monitoring, soil monitoring, water monitoring, fertilization, pest control, illumination control, and 
location tracking. The selected mainstream application domains in this SLR are monitoring, tracking, 
and controlling, as shown in Figure 4. Most of the studies have focused on monitoring (70%), 
controlling (25%), and tracking (5%), as shown in Figure 4. 
 
Figure 4. Application Domains. 
4.1.5. Assessment of RQ5: What Are the Major Focuses of the Selected Studies? 
The primary focus of each IoT agricultural application concerning their domains 
(monitoring, controlling, and tracking) is discussed in this section. The main classification of these 
applications are Irrigation Monitoring and Controlling (16%), Precision Farming (16%), Soil 
Monitoring (13%), Temperature Monitoring (12%), Humidity Monitoring (11%), Animal Monitoring 
Figure 4. Application Domains.
4.1.5. Assessment of RQ5: What Are the Major Focuses of the Selected Studies?
The primary focus of each IoT agricultural application concerning their domains (monitoring,
controlling, and tracking) is discussed in this section. The main classiﬁcation of these applications
are Irrigation Monitoring and Controlling (16%), Precision Farming (16%), Soil Monitoring (13%),
Temperature Monitoring (12%), Humidity Monitoring (11%), Animal Monitoring and Tracking
(11%), Water Monitoring and Controlling (7%), Disease Monitoring (5%), Air Monitoring (5%), and
Fertilization Monitoring (4%), as shown in Figure 5. It can be seen that most of the selected papers have
focused on precision farming, irrigation monitoring, and controlling. Some representative examples of
IoT agriculture applications are discussed in this Section.
Electronics 2020, 9, x FOR PEER REVIEW 
5 of 41 
and Tracking (11%), Water Monitoring and Controlling (7%), Disease Monitoring (5%), Air 
Monitoring (5%), and Fertilization Monitoring (4%), as shown in Figure 5. It can be seen that most of 
the selected papers have focused on precision farming, irrigation monitoring, and controlling. Some 
representative examples of IoT agriculture applications are discussed in this Section. 
 
Figure 5. IoT agriculture applications. 
Air Monitoring 
The aim of this sub-domain is to evaluate and determine the air condition in order to prevent 
from damaging effects. In [25] an IoT-based agricultural air, humidity, and temperature monitoring 
system has been proposed. This system offers a real-time microclimate monitoring solution that is 
based on WSNs. The system consists of a temperature and humidity sensor that is supported by a 
communication technology called ZigBee and powered by solar panels. 
Figure 5. IoT agriculture applications.
Electronics 2020, 9, 319
20 of 41
Air Monitoring
The aim of this sub-domain is to evaluate and determine the air condition in order to prevent
from damaging eﬀects. In [25] an IoT-based agricultural air, humidity, and temperature monitoring
system has been proposed. This system oﬀers a real-time microclimate monitoring solution that is
based on WSNs. The system consists of a temperature and humidity sensor that is supported by a
communication technology called ZigBee and powered by solar panels.
Soil Monitoring
Paper categorized in this sub-domain [26] proposed solutions for soil moisture and temperature
monitoring in the ﬁelds using WSN. Both of these systems are maintained through multiple
communication technologies such as GPRS, ZigBee, and the internet, where the user interacts with the
system through web applications [63,85].
Water Monitoring
The studies that have been categorized in this sub-domain intend to monitor water quality or
water pollution by sensing PH, temperature, and chemicals, which can change the normal conditions
of water. In [27], an IoT-based solution has been presented to monitor the water quality by measuring
temperature, conductivity, and turbidity. This solution based on WSN combines sensing devices and
monitors the multiple parameters of water in urban areas. Moreover, [28] developed a WSN-based
system to monitor the rainfall and water level in irrigation systems. A web-based decision support
system has been proposed in [29] that use sensors to measure temperature, solar radiations, humidity,
and rainfall for irrigation monitoring in olive ﬁelds.
Disease Monitoring
The LOFAR-agro Project is the best example for crop or plant monitoring [30]. This project protects
the potato crop by monitoring diﬀerent climate conditions such as temperature and humidity through
WSN. The proposed system protects the crop by analyzing the collected data from fungal diseases.
Environmental Condition Monitoring
An environmental condition monitoring system is proposed in [34] that measures the spatial
sampling of humidity sensors using WSN. To determine the behavior of 2D correlation, a historical
database is being used in the proposed system. Moreover, another environmental conditions monitoring
system is proposed in [35] that integrates forecasting and drought monitoring musing IoT.
Crop and Plant Growth Monitoring
In this sub-domain, farmlands have been analyzed by using the mobile sensors presented in [94].
The essential purpose of this proposed system is to monitor the growth of grapes and control plans
for viticulture activities. To monitor apple orchards, researchers proposed an eﬃcient and intelligent
monitoring system that provides suggestions based on the sensed data [95]. The basic purpose of this
proposed system is to decrease the management costs, improve the quality of apples, and protect from
pest attacks. It is a WSN-based system that is designed by using ZigBee and GPRS to monitor the
growth of apples.
Temperature Monitoring
Soil temperature plays a vital role in crop productivity. In [96], a system has been proposed
to monitor the amount of nutrients between surface and ground water. To measure the quantity of
nutrients in soil, electrochemical impedance was applied. Soil test results are monitored through
an inductance (L), capacitance (C), and resistance (R) (LCR) meter, and the results are calculated via
standard library measurements.
Electronics 2020, 9, 319
21 of 41
Humidity Monitoring
The humidity level is measured in air by using multiple humidity sensors. An inappropriate
amount of humidity leaves a negative impact on plants regarding cell growth [36].
Monitoring Gases in Greenhouse
Agriculture and greenhouse gases are related to each other. The excessive amount of gases in a
greenhouse increases the temperature, which directly impacts the agriculture productivity. To monitor
the greenhouse gases and CH4, a WSN and solar powered Unmanned Aerial Vehicle (UAV) system
has been presented [37].
Fertilization and Pest Control
In this domain, an IoT solution provides conservation approaches to improve the quality of the
crops and amount of nutrients usage. An online climate monitoring system has been presented for
greenhouses to monitor pests, irrigation, fertilization, and climate [33]. The system use WSN to gather
and analyze sensed data for eﬃcient analysis.
Greenhouse Illumination Control
An automated agriculture system is developed to monitor the growth of cabbages and melons in
greenhouses [38]. The designed system monitors the crop growing process and controls the greenhouse
environmental conditions such as temperature, ambient light, and humidity.
Location Tracking
This sub-domain referred to the tracking and tracing of animal locations and any unwanted
movement all over the ﬁeld. Diﬀerent monitoring devices and sensors have been deployed in the
ﬁeld to save the crop from theft and wild attacks. For agriculture, an intrusion detection solution is
presented in [31] that generates an alarm and sends a text message to the farmer’s mobile when an
unwanted movement happens in the crop ﬁeld. Moreover, for livestock, diﬀerent monitoring devices
are implemented to track the animals’ locations and monitor their activities. In [32], an IoT-based
animal monitoring solution is presented that monitors the behavior of swamp deer. Moreover, a herd
of cattle grazing in the ﬁeld can be monitored and tracked by using RFID and WSN [97]. In this way
ranchers can get real time monitoring of cattle’s.
4.1.6. Assessment of RQ6: What Is the Role of IoT-Based Devices/Sensors in Agriculture
Multiple organizations and industries are using diﬀerent kinds of devices/sensors for a long time,
but an invention of IoT has taken advancements of devices/sensors totally at a diﬀerent level. An
IoT device consists of an embedded system that interacts with actuators, sensors, and the required WSN.
Embedded systems consist of a microprocessor, memory, communication modules, and input/output
components. Sensors monitor the diﬀerent environmental parameters and farm variables in the ﬁeld
of agriculture and dynamic data that is obtained through facilities intervention.
Commonly used sensors are temperature sensors, humidity sensor, soil pattern monitoring sensor,
airﬂow sensor, a location sensor, CO2 sensor, pressure sensor and moisture sensor. The signiﬁcant
characteristics of IoT devices/sensors that make them suitable for agriculture are their (1) portability;
(2) reliability; (3) memory; (4) durability; (5) power and computational eﬃciency; and (6) coverage.
This systematic study shows that many researchers have been focused on temperature monitoring
(19%), humidity (17%), and soil moisture (14%). Twenty types of data have been collected through
diﬀerent monitoring and sensing devices, as shown in Figure 6.
Electronics 2020, 9, 319
22 of 41
 
portability; (2) reliability; (3) memory; (4) durability; (5) power and computational efficiency; and (6) 
coverage. This systematic study shows that many researchers have been focused on temperature 
monitoring (19%), humidity (17%), and soil moisture (14%). Twenty types of data have been collected 
through different monitoring and sensing devices, as shown in Figure 6. 
Temperature, humidity, and soil moisture are considered the most critical variables for smart 
farming, as shown in Figure 6. Meanwhile, Table 7 represents the operations of different sensors and 
devices in the field of IoT agriculture. 
 
Figure 6. Sensors/devices distribution. 
Table 7. Sensor/devices operation. 
Infirmity 
Sensor/Devices Operations 
PH Sensor 
To monitor the exact amount of nutrients in soil, PH sensors are used, which is efficient for the healthy growth of 
plants and crops [98].  
Gas Sensor 
Through the observation of infrared radiations this sensor measures the exact amount of toxic gases in livestock 
and greenhouses [99]. A sensor node called Waspmote Plug & Sense! Smart Agriculture Xtreme has been 
designed to monitor the gas level water content in the soil. 
Figure 6. Sensors/devices distribution.
Temperature, humidity, and soil moisture are considered the most critical variables for smart
farming, as shown in Figure 6. Meanwhile, Table 7 represents the operations of diﬀerent sensors and
devices in the ﬁeld of IoT agriculture.
Table 7. Sensor/devices operation.
Inﬁrmity
Sensor/Devices Operations
PH Sensor
To monitor the exact amount of nutrients in soil, PH sensors are used, which is eﬃcient for
the healthy growth of plants and crops [98].
Gas Sensor
Through the observation of infrared radiations this sensor measures the exact amount of
toxic gases in livestock and greenhouses [99]. A sensor node called Waspmote Plug &
Sense! Smart Agriculture Xtreme has been designed to monitor the gas level water content
in the soil.
Motion Detector
Sensor
The sensor is used to track/trace the location of animals and ﬁeld, moreover it also detect
the motion of an unwanted object in the ﬁeld or farm and generate alerts to farmer for
timely action and preventing crop loss [100].
Ultra Violet
Sensor and
Passive Infrared
(PIR) Sensors
An ultra violet sensor monitors the UV rays for the eﬀective growth of crops [101]. In the
PIR sensor, a motion detector is ﬁxed that traces the range of a person’s movement in the
ﬁeld. The sensor also has a light detection property: while tracking an object, it changes
the rising temperature into voltage for analyzing crop growth [102].
Soil Moisture
Sensor
The soil sensor measures the quantity of water and level of moisture all over the ﬁeld [103].
In [104], a wireless moisture sensor has been implemented to monitor the greenhouse
irrigation system. CropX Starter Kit–Soil Temperature 24/7 is cellular connection sensor
that is used to monitor the multiple soil conditions [105].
Temperature
Sensor
Changes in the soil temperature aﬀect the absorption soil nutrients and moisture. A novel
sensing approach has been presented to map the exact amount of nutrients in soil and the
water surface [12]. A 3D crop sensor Array with Photosynthetically Active Radiation (PAR)
technology can be deployed at any location of ﬁeld to monitor the temperature, CO2, and
humidity [106].
Humidity
Sensor
Humidity leaves a negative impact on the growth of plant leaves, photosynthesis, and
pollination. Therefore, to sense the level of humidity in air, this sensor directly measures
the temperature and moisture content in the air [107]. Groﬁt provides diﬀerent climate
monitoring devices that can monitor the air temperature, air humidity, and sun radiation.
The data transmission range of the device is up to 200 m and stores the measurement for a
maximum of 30 days [108].
Electronics 2020, 9, 319
23 of 41
4.1.7. Assessment of Q7: What Is the Role of IoT Communication Protocols and Standards in Agriculture?
A large number of IoT communication technologies are being utilized within IoT applications due
to their low cost, wide coverage range, and low energy requirements as compared to other long-range
communication technologies. All the communication technologies that have been identiﬁed in this
mapping study are shown in Figure 7. WSN (29%) has been identiﬁed as the widely used technology,
whereas WIFI (15%) and ZigBee (10%) are also used to transfer data to a lesser extent [109].
 
g
p
maximum of 30 days [108]. 
4.1.7. Assessment of Q7: What Is the Role of IoT Communication Protocols and Standards in 
Agriculture? 
A large number of IoT communication technologies are being utilized within IoT applications 
due to their low cost, wide coverage range, and low energy requirements as compared to other long-
range communication technologies. All the communication technologies that have been identified in 
this mapping study are shown in Figure 7. WSN (29%) has been identified as the widely used 
technology, whereas WIFI (15%) and ZigBee (10%) are also used to transfer data to a lesser extent 
[109]. 
 
Figure 7. Communication protocols. 
Low Range Wide Area Network Protocol (LoraWan) 
An organization called Lora TM Alliance has developed a low-range wide area network 
protocol. The primary aim of this protocol is to ensure interoperability among multiple operators 
[39]. A framework has been developed in [40] that enhances the crop productivity and mitigates risks. 
Message Queue Telemetry Transport Protocol (MQTT) 
MQTT is used to send and receive sensor information. In [42], a MQTT protocol has been used 
to solve the irrigation problem that controls the water pump action and transmits the status of water 
pump and soil moisture conditions to a user’s mobile application and web page. 
Radio-Frequency Identification (RFID) 
Figure 7. Communication protocols.
Low Range Wide Area Network Protocol (LoraWan)
An organization called Lora TM Alliance has developed a low-range wide area network
protocol. The primary aim of this protocol is to ensure interoperability among multiple operators [39].
A framework has been developed in [40] that enhances the crop productivity and mitigates risks.
Message Queue Telemetry Transport Protocol (MQTT)
MQTT is used to send and receive sensor information. In [42], a MQTT protocol has been used to
solve the irrigation problem that controls the water pump action and transmits the status of water
pump and soil moisture conditions to a user’s mobile application and web page.
Radio-Frequency Identiﬁcation (RFID)
RFID records information by assigning a unique number to each object individually and tracking
their location. This protocol identiﬁes environmental conditions such as moisture level and temperature
conditions. To track crop information and identify the object location, an RFID tag has been used
in [41]. In [42], RFID technology and sensors have been integrated for identiﬁcation that help the
farmers in multiple ways, such as saving time, money, and power.
SigFox
Sigfox is a wireless cellular network that is suitable for long-range communications. In [43,110],
SigFox has been used, which localizes animal pastures for the whole summer. Moreover, the system
proposed in [43] helps the ranchers track their cattle’s positions.
Electronics 2020, 9, 319
24 of 41
ZigBee
One of the top IEEE 802 standards developed by the ZigBee alliance has a long-range battery
life. This technology fulﬁlls the demand for quick throughput by oﬀering high-speed data transfer for
applications such as agriculture [111].
WiFi
WiFi is a standard part of a wireless local area network (WLAN) that is used to exchange
information over the internet wirelessly (IEEE Standard for Information technology, 2005, 2012a).
The communication range of WiFi is 20–100 m and the data transmission range is 2–54 mbs. In the ﬁeld
of agriculture over an ad hoc network, WiFi broadens the utilization of heterogeneous architectures
connecting diﬀerent types of devices [44].
Bluetooth
Bluetooth is a low-cost, low-power technology that is based on IEEE 802.15.1 standard and used
for communication over short ranges i.e., 8–10 m (IEEE Standard for Information technology, 2012b;
Bluetooth Technology Special Interest Group). This technology is suitable for multi-tier agricultural
applications due to its ubiquitous nature [45].
Worldwide Interoperability for Microwave Access (WiMAX)
WiMAX is a wireless communication that is based on an IEEE 802.16 standard whose transmission
range is 50 km and the data rate is 0.4–1 Gbps (IEEE Standard for Local and metropolitan area networks,
2011). WiMAX is suitable for monitoring and controlling diﬀerent agricultural applications such as
monitoring farming systems, crop area border monitoring, and controlling gates, lights, water pumps,
and the remote diagnosis of the farming systems. The Ministry of Food and Agriculture, Ghana
(MOFA) has utilized WiMax and WiFi technologies so that user has choice of selecting WiFi or WiMax
to establish network connections [46].
4.1.8. Assessment of Q8: Which IoT Agricultural Policies Have Been Implemented in Different Countries?
Technologies and evidence-based policies have become the driver in all cases of practical
implementations. Similarly, regulations and policies play a vital role in order to transform the agriculture
sector in a more innovative way over the next several decades. Although existing policies accommodate
IoT agricultural services, these policies and regulations are the key goals for a large number of initiatives
over the globe. This section describes the IoT-based agricultural policies that have been adopted by
different countries as shown in Table 8.
Table 8. IoT-based agriculture success stories.
Countries
Application
Sub-Domains
Success Stories
Thailand
Water management
A water control system has been developed on the basis of WSN to
measure the water consumption in whole ﬁeld. The developed system has
been tested and implemented at three diﬀerent ﬁelds in Thailand.
After implementation, results indicated that for the eﬃcient growth of
lemons, the level of humidity should be 70–80% and the temperature
should be between 29 ◦C and 32 ◦C for the high productivity of lemons
and vegetables [68].
Taiwan
Soil cultivation
For precision farming, a low-cost AgriTalk IoT-based platform has been
implemented in Taiwan to monitor soil parameters [49]. The developed
platform has been tested by implementing it in three diﬀerent ﬁelds for
turmeric cultivation. After using the developed AgriTalk solution, the
chlorophyll amount was increased up to 40–60%, which is more than
existing methods, and 70% of water was also saved. Furthermore, 140,000
USD revenue was generated by 14,000 USD investments, which was big
revenue compared to old cultivation methods.
Electronics 2020, 9, 319
25 of 41
Table 8. Cont.
Countries
Application
Sub-Domains
Success Stories
Brazil
Soil humidity and
temperature monitoring.
An IoT-based Agri Prediction model is presented in [40] that provides
low-cost prediction methods to measure the soil humidity and
temperature. After the implementation of the proposed model, the weight
(up to 14.29%) and size (up to 17.94%) of arugula leaf was increased.
India
Monitor moisture
content, temperature,
humidity, pesticides,
animals CO2, and light.
An IoT-based robotic has been presented in [36] to measure the
agricultural parameters such as pesticides, moisture, and animals
movement. When the system was practically implemented, the obtained
results were very satisfactory, which shows that the system is user friendly,
robust, and reduces the labor cost. Moreover, a remote sensing control
system is developed in [54] to monitor the greenhouse gas, temperature,
soil moisture, and light. These variables were monitored for bell paper
plants and the obtained results indicate the yield increment and facilitate
the farmer to monitor the farm remotely.
China
Environment monitoring
To monitor the greenhouse environment conditions, a low-power and
low-cost system is developed [112]. Implementations of the developed
system show that the system is reliable and reduces the labor cost.
Furthermore, IoT technologies implemented in the Shandong Province
demonstration park of Zhongyi show that the fertilization and pesticides
cost reduced up to 60% and 80%. Whereas, to deal with the 300-mu park,
60 laborers were required, but the utilization of IoT technology reduced
the labor cost by approximately 60% [113].
Africa
Monitoring animal’s
location, behavior and
pasture grazing.
Authors proposed an animal behavior monitoring system that traces the
animals’ movement all over the ﬁeld and monitors their pasture
grazing [61]. The designed platform is implemented in Africa to evaluate
and track the animals’ conditions.
Malaysia
Fruit traceability
The Minister of Science, Technology, and Innovation (MOSTI) of Malaysia
proposed IoT agricultural solutions for tracking purposes called Mi-Trace
and My Traceability SdnBhd (MTSB) to ensure the quality of fruits sellers
and exporters are utilizing these two solutions [114].
Australia
The Australian Government has invested AU$134 million to improve their current farming method.
As a result of this large investment by a private company in Sydney, the local government created a
center for the implementation of IoT technologies in agriculture ﬁelds [115]. An innovative network
was established in 2014 for the purpose of precision farming to create a collaborative framework in the
agriculture ﬁelds of Australia. Moreover, in terms of security and privacy, an American farm bureau
established a security and privacy set for farm/ﬁeld data in 2015 [116].
Ireland
A program has been launched by Irish Farmers Association (IFA) to decrease the smart farming
implementation costs and improve the soil quality by providing guidance to the famer regarding how
to save the water and power by utilizing IoT technology [92]. The farming community enthusiastically
followed these guidelines and obtained results that were very encouraging and positive. Companies
saved approximately 8700 euro, 21% savings were achieved in pasture management; there was also a
10% reduction in greenhouses gas emission and 47% savings in soil fertility. To track and trace the
farm assets, Ireland VT-Networks launched a SigFox network [117].
France
In France, the ministry of agriculture has become the partner of the Agriculture Innovation Project
2025, whose basic purpose is to increase the strength of agriculture land, monitor weather parameters,
and improve the ﬁeld conditions by creating incubators. Moreover, the ministry of agriculture shares
benchmarked farm data with farmers to develop innovative solutions in agriculture [118].
Electronics 2020, 9, 319
26 of 41
China
To integrate IoT technology in agriculture ﬁelds, China has launched their 13th Five-Year Plan [119].
The project has started in eight provinces of China to collect data from diﬀerent sources such as national
data centers. Furthermore, the Huawei Company in China developed an NB-IoT app to transform the
agriculture ﬁeld in a more innovative way. NB-IoT provides excellent agricultural solutions at low cost
without any gateway implementation as compared to other cellular networks. NB-IoT provides a wide
range of coverage with a large number of connections to resolve the issues of the scattered agricultural
data [120].
Malaysia
The Malaysian Institute of Microelectronic System (MIMOS) has created several agricultural
solutions to enhance the crop productivity and reduce the poverty. The Mi-MSCANT PH sensor
has been developed by MIMOS to collect the data regarding environmental conditions. MIMOS has
developed an integrated IoT technology framework that creates a strong bond among the traders,
suppliers, and agriculturists in cohesive manners. The developed framework utilizes the WSN and
Micro Electro Mechanical System (MEMS) technologies to gather environmental data [121].
USA
In order to fulﬁll the basic requirements of food and energy, the USA government has initiated
many research and development projects related to agricultural technologies. The National Institute of
Food and Agriculture is working on a project called the Internet-of-Ag-Things and developed sensing
technologies for agricultural practices. The major aim of the project is to provide precision farming
techniques to increase the agricultural productivity and make better use of the fertilizers, water, and
organic food [122]. A project namely has been started by Department of Agriculture (USDA) to resolve
the water management issues and design new techniques to overcome the challenges that are aﬀecting
agriculture. Moreover, technologists are using the datasets of the USDA to improve and design the
existing agriculture services for water distribution [123].
Thailand
The National Electronics and Computer Technology Center (NECTEC) in Thailand is implementing
IoT technology to develop the smart farming, and their main focus is on four agriculture products,
namely: rice, rubber, cassava, and sugar [124]. The basic aim of this movement by the Thailand
government is to facilitate the farmers in all rural areas for the eﬃcient growth of crops [125].
India
The Indian government has made several IoT policies to boost up their agriculture over the globe.
Their major focus is to measure the soil conditions, parameters, temperature, and earth density in order
to help the farmers control the pest and crop diseases. The Ministry of Communication and Information
Technology released a policy in 2015 to transform the agricultural ﬁeld by utilizing IoT [126].
Philippines
The Philippines used remote sensing techniques in order to boost the rice production and satellite
imaginary techniques to get information about multiple agricultural conditions. The University of
Southeastern Philippines (USeP) developed a smart solution to measure the crop heat stress through
IoT technology by collaborating with Western Mindanao State University (WMSU) [127].
4.2. Quality Assessment Score
A quality assessment score has been presented in Table 9 where 9% of the papers have an average
score, 64% of papers have an above average score, and 27% of selected studies are below average.
Electronics 2020, 9, 319
27 of 41
The quality assessment criteria deﬁned in the previous section help the IoT agriculture researchers and
scientists choose the relevant papers according to their tier requirements.
Table 9. Quality assessment score.
References
Score
Total
[57,67]
1
2
[35,37,52,53,59,63,65,82]
1.5
8
[26,33,34,54,64,66,80,91]
2
8
[39,58,60,81,83,89]
2.5
6
[27–31,36,41–44,50,51,55,61,62,69–72,74,79,86,88,90]
3
24
[45,56]
3.5
2
[40,46,48,49,75–78,85,87]
4
10
[25,32,84]
4.5
3
[47,68,73,97]
5
4
5. Discussion
A detailed discussion about diﬀerent IoT agriculture applications, sensors, and devices has been
presented in this section. An agriculture hierarchy has been proposed to summarize the ﬁndings of
this research as shown in Figure 8. Moreover, an IoT-based smart farming framework has also been
proposed as shown in Figure 9.
Electronics 2020, 9, x FOR PEER REVIEW 
13 of 41 
 
Figure 8. IoT agricultural hierarchy. 
5.2. IoT Smart Farming Agricultural Framework 
An IoT smart farming agricultural framework has been proposed in Figure 9 that consists of five 
major components, which are data acquisition, common platform, data processing, data 
visualization, and system management. The data acquisition component consists of the converged 
network that is formed by multiple communications networks. The transmission media may be wired 
technology such as a controller area network (CAN) or wireless technology such as LoRa, Zigbee, 
NB-IoT, and Bluetooth. Meanwhile, a wide area network (WAN) component is further divided into 
sub-components that are mobile communication technologies. The cellular communication 
technology consist of four generations of technology, whereas 5G technology was announced in 2016, 
which will revolutionize the agriculture monitoring process by providing high-speed data 
transmission, network control, and energy consumption. Moreover, the data acquisition component 
not only transmits the agricultural related information collected from the data visualization 
component, but also sends the control commands to the system management.  
Figure 8. IoT agricultural hierarchy.
5.1. IoT Agricultural Hierarchy
The ﬁndings of this research have been summarized by developing an IoT-based agricultural
hierarchy, as shown in Figure 8. The designed hierarchy consists of four primary activities. These are
IoT agricultural applications, sensors/devices, communication protocols, and country policies, which
encapsulate most of the ﬁndings that are analyzed in this paper.
IoT agricultural applications
monitor, control, and track the diﬀerent precision farming, greenhouse, and animal-related parameters.
IoT-based agricultural applications with their sub-domains have been discussed in Section 4 (RQ4).
Sensors/devices produce valuable data by sensing and monitoring multiple ﬁeld variables through
WSN. The data generated through sensing and monitoring devices are transferred through the
Electronics 2020, 9, 319
28 of 41
communication protocols (LoraWan, Sigfox, ZigBee, RFID, Bluetooth, WiMax, MQTT, WiFi) on other
platforms for a user or farmer view. Moreover, for the standardization of IoT-based agriculture, diﬀerent
countries have been made various IoT agricultural policies, which are presented in Section 4 (RQ8)
Furthermore, the success stories of IoT-based smart farming have also been presented by discussing
some pilot projects implemented in diﬀerent countries.
Electronics 2020, 9, x FOR PEER REVIEW 
14 of 41 
 
Figure 9. IoT smart farming framework. 
A common platforms component is responsible for decision making, data storage, and statistical 
analysis on agricultural data by implementing various models and algorithms for the agricultural 
production process. The component has been further divided into sub-components, namely: (i) Edge 
Computing, (ii) Cloud Computing, and (iii) Big Data. Big data technology makes predictive analysis 
by finding the internal links among the data which are collected through information mining and
Figure 9. IoT smart farming framework.
Electronics 2020, 9, 319
29 of 41
5.2. IoT Smart Farming Agricultural Framework
An IoT smart farming agricultural framework has been proposed in Figure 9 that consists of ﬁve
major components, which are data acquisition, common platform, data processing, data visualization,
and system management. The data acquisition component consists of the converged network that is
formed by multiple communications networks. The transmission media may be wired technology
such as a controller area network (CAN) or wireless technology such as LoRa, Zigbee, NB-IoT, and
Bluetooth. Meanwhile, a wide area network (WAN) component is further divided into sub-components
that are mobile communication technologies. The cellular communication technology consist of four
generations of technology, whereas 5G technology was announced in 2016, which will revolutionize
the agriculture monitoring process by providing high-speed data transmission, network control, and
energy consumption. Moreover, the data acquisition component not only transmits the agricultural
related information collected from the data visualization component, but also sends the control
commands to the system management.
A common platforms component is responsible for decision making, data storage, and statistical
analysis on agricultural data by implementing various models and algorithms for the agricultural
production process. The component has been further divided into sub-components, namely: (i) Edge
Computing, (ii) Cloud Computing, and (iii) Big Data. Big data technology makes predictive analysis
by ﬁnding the internal links among the data, which are collected through information mining and
other resources.
Moreover, it also provides data support for new operations and performs multiple processing
techniques such as image processing, statistical analysis, simulation, prediction, early warning, and
modeling [93]. Cloud Computing provides software services, hardware services, infrastructure services,
and platform services to diﬀerent IoT agricultural applications. The cloud platform oﬀers cheap
data storage services to the farmers such as image, text, videos, and other agricultural data, which
facilitates the agricultural enterprises by reducing storage cost [42]. Moreover, it is a diﬃcult task to
make the direct use of raw agricultural data for decision making on the basis of farmers’ technical
expertise. In contrast, agricultural experts can also give suggestions and make accurate judgments
based on quantitative analysis. Therefore, only cloud computing provides an intelligent and secure
platform for monitoring crop [128] Although the cloud platform helps the farmer through its advance
techniques, still, there are some limitations due to which farmers face technology losses related to
internet connectivity and low power. Edge computing is one of the new computing models that
perform the calculations at the edge of the network. This platform also reduces the computational
load by improving data transmission speed and protects agricultural data because processing in edge
computing occurs more compared to cloud computing [76,129].
Data processing consists of audio, video, text image processing, and many other processing
techniques. These features may be added or removed according to the system requirements.
Data visualization is one of the most visible components in the IoT agricultural ﬁeld, which consists
of monitoring, controlling, and tracking/tracing. The monitoring function includes environmental
conditions monitoring, crop and plants growth monitoring, disease monitoring, soil monitoring, and
animal health monitoring. The controlling function controls the diﬀerent agricultural parameters such as
pest, fertilization, and greenhouse illumination control. Moreover the tracking/tracing sub-component
tracks the animals and ﬁeld location. The whole monitoring, controlling, and tracking process is
controlled is through a controller and managed through the system management component.
The system management component includes various kinds of actuators, sensors, microcontrollers,
and drone controllers. The most commonly used sensors/devices are environmental conditions
monitoring sensors, crop/plant monitoring sensors, and animal health monitoring sensors/devices.
These sensors collect information about diﬀerent agricultural variables, and this collected information
is processed through embedded devices to make the proper analysis for smart farming.
Electronics 2020, 9, 319
30 of 41
5.3. State-of-the-Art IoT Agricultural Solutions in the Market
According to the report of Finistere Ventures, more than 2 billion dollars have been invested
around the globe in AgTech, which is expected to increase in the coming years [130]. As IoT is gaining
is importance in diﬀerent applications of smart farming, almost all of the top technology ﬁrms are
investing and supporting this technology in their own way to develop innovation in the agriculture
ﬁeld. Table 10 represents the diﬀerent IoT agricultural solutions proposed by the top technologies ﬁrms.
Table 10. Available solutions and initiatives regarding IoT in agriculture.
Industries
Initiatives and Solutions
Samsung
Samsung takes the initiative in the ﬁeld of IoT by providing its Samsung Data Systems
(SDS) IoT Platform, which connects the multiple IoT devices and communication protocols
such as Modbus, Zigbee, Bluetooth Low Energy (BLE), MQTT, and LoRaWAN [131].
AeroFarms
AeroFarms provides indoor farming solutions by analyzing data related to plants into data
through big data, imaging, and artiﬁcial intelligence technologies [132].
Microsoft
Microsoft also works on data-driven farming techniques by resolving the issues from cloud
to sensor [133]. The Bosch technology ﬁrm provides diﬀerent sensors analytics techniques
and IoT-based data management techniques to monitor the crop productivity and
diseases [134].
R- Style Lab
R- Style Lab is the top IoT software-providing company that oﬀers multiple software
solutions such as predictive maintenance, drone’s inspections, and crop/animal monitoring
solutions, and it provides some embedded software that can easily be integrated into
portable trackers [135,136].
IBM
IBM has provide an AI-based service called Watson Decision, which is best solution to
improve the sustainability, harvesting, and quality of smart farming by using IoT and AI
technologies [137].
Intel
Intel has been developed an IoT-based platform Inﬁswift, which helps increase the
eﬃciency of agricultural solutions through advanced connected services [138].
Google
Google has suggested a vision for advanced agricultural solutions by joining the MIT
Media Lab Open Agriculture Initiative to provide a healthier food system [139].
6. Open Issues and Challenges
There are many open issues and challenges that are associated with the implementation of
IoT applications. Some of the challenges that are identiﬁed from the literature have been discussed in
this section.
6.1. Security
Security issues arise at a diﬀerent level of IoT-based agricultural systems, which need to be
addressed. Due to low security, users face many diﬃculties such as loss of data and other on-ﬁeld
parameters. IoT privacy and security issues have been discussed in [140–142] broadly. In the agriculture
ﬁeld, IoT devices are at risk due to physical interference such as attack by animals and predators or
modiﬁcation in physical address [142,143]. Moreover, due to low energy consumption and limited
memory, it is hard to implement sophisticated and complex algorithms. The precision farming services
such as IoT-enabled location information and location-based services are exposed to hackers that
may use this information for device capturing [141,142,144]. Attackers attack the IoT device and
take out cryptographic implementations. Other communication layers also undergo some vulnerable
denial-of-service (DoS) attacks and wireless signal blocking [142]. Major security threats to the cloud
infrastructure are hijacking attacks, session hijacking, database issues, and denial of service attack [142].
Electronics 2020, 9, 319
31 of 41
6.2. Cost
While deploying IoT in agriculture, several cost-related issues arise such as setup and running
costs. The setup costs consist of hardware costs such as IoT devices/sensors, base station infrastructure,
and gateways. Moreover, running costs includes an uninterrupted subscription for the management of
IoT devices, the exchange of information among other services, and centralized services that provide
information/data collection [47].
6.3. Lack Knowledge of Technology
Poor understanding of technology is the main barrier among the farmers who are living in rural
areas. This problem is common in developing countries, where most farmers are uneducated [145].
The implementation of IoT in agriculture is a big challenge, because a lot of investment is required in
farmer’s training before deploying IoT infrastructure.
6.4. Reliability
In the ﬁeld of agriculture, IoT devices are deployed in an open environment due to which harsh
environmental conditions may cause communication failure and the humiliation of deployed sensors.
Therefore, it is important to ensure the physical safety of deployed IoT devices/sensors to protect them
from severe climate conditions [146].
6.5. Scalability
A large number of IoT devices and sensors are deployed in the agriculture ﬁeld, due to which an
intelligent IoT management system is required for the identiﬁcation and controlling of each node [147].
6.6. Localization
There are many factors that need to be considered while deploying devices/sensors. Such devices
should have the ability to provide functionality and support to the rest of the world without deploying
additional devices with overhead conﬁguration [148].
Moreover, it is important to select the
best deployment position so that devices can communicate and exchange information without
any interference.
6.7. Interoperability
There are billions of IoT devices, standards, and protocols that are needed to interoperate.
Interoperability involves semantic, syntactic, technical, and organizational policy. Semantic interoperability
is the ability to deal with the interpretation of content exchanged among humans. Syntactical interoperability
is related to data formats, such as java script object notation (JSON), data interchanged electronically,
extensible markup language (XML), and variables separated by a comma. Technical interoperability
is associated with the development of infrastructure, protocols, and hardware/software components
that enable the IoT devices’ communication. Organizational interoperability is related to policies for
communicating and transferring data effectively across the different geographic regions and infrastructure.
Whereas, in [149], three methods have been proposed through which interoperability can also be obtained,
which are (i) two standards open and close, (ii) partnership among services and product developers, and
(iii) mediator and adaptors services. More research work is expected to obtain a high interoperability
among multiple IoT devices.
7. Integration Challenges of IoT and Cloud Computing in Agriculture
The aim of the cloud-based IoT paradigm is to analyze and integrate the data that is coming from
the real world into IoT objects. This paradigm requires interacting with millions of end devices that
are thoroughly distributed [110]. Although the cloud platform helps the farmer through its advance
techniques, still, there are some limitations due to which farmers face technology loss related to internet
Electronics 2020, 9, 319
32 of 41
connectivity, low-power communication devices, and many other integration challenges. Moreover,
the monitoring and controlling processes have made the data sharing of IoT devices more diﬃcult,
because IoT communication devices face connectivity issues and latency problems [111]. Some of the
networking challenges that users face while assessing and uploading the information on cloud are
given in Table 11.
Table 11. Mapping problems and solutions regarding IoT and cloud computing integration.
Year
Reference
Problems
Solutions
2016
[150]
It has become very diﬃcult to handle the
data-generating devices and
power-constrained sensors, in order to
obtain the more valuable services.
The cloud of things (CoTs) solution has been
presented to handle the increasing demand of
data-generating devices and other
communication resources underlying the
WSNs.
2016
[151]
IoT consist of millions of interconnected
devices such as WSAN, RFID etc. in
order to exchange the agricultural
information; therefore, cloud computing
technology is necessary due to the
connectivity limitations in this ﬁeld.
Authors presented a survey on cloud
infrastructures, cloud platforms, and
IoT middleware for the integration of devices
and communication protocols.
2013
[152]
Due to the adaptation of a large number
of wireless technologies, IoT has stepped
out to create a fully integrated future
network.
Implemented cloud solutions by using Aneka,
which is a centric vision for the convergence
of internet, WSN, and distributed computing.
2013
[153]
The integration of IoT and cloud
computing has become a primary need
over the last few years to manage
diﬀerent power connectivity issues.
The author designed a framework to procure
data from decentralized, heterogeneous,
highly distributed, and virtual devices that
can be controlled, analyzed, and managed
automatically.
2014
[154]
The IoT has become more persistent due
to which its integration with cloud
computing is very important.
The integration of both technologies is not
simple, because diﬀerent key issues occur
that people face while accessing the
communication network to retrieve or upload
information to the cloud. A survey has been
presented that highlights the main challenges
and provides their respective solutions.
8. Threats to Validity
There have been four kinds of threats to validity identiﬁed in this section.
8.1. Construct Validity
In the SLR, construct validity threats are relevant to the classiﬁcation of selected studies [147,148].
Search keywords have been proposed and identiﬁed by two authors, and seven terms related to
IoT agriculture have been used in the search string. However, the list is not complete; some alternative
and additional terms may alter the list of ﬁnal selected papers [84]. A search string was performed
by using IEEE Xplore, Science Direct, Springer, MDPI, and IGI Global. According to the statistics
of the search engines, we have found most of the research papers related to IoT agriculture in these
electronics libraries. To mitigate the risk of missing essential and related publications, we have sought
out the related papers in major IoT agriculture research venues. Although the standard of the primary
studies decreased by including publications that are not from top journals and conferences, it indicates
that the studies relevant to IoT have increased.
8.2. Internal Validity
This type of validity handles the extraction data analysis process, in which two authors have
identiﬁed the classiﬁcation of selected papers and the data extraction process, whereas one author
reviewed the ﬁnal results. Data collection and paper classiﬁcation have been made on the judgment of
Electronics 2020, 9, 319
33 of 41
two authors. The kappa coeﬃcient value was 0.91, which indicates that there has been a high level of
agreement among the authors and reduces the dissimilarity threats signiﬁcantly by showing a similar
understanding of relevance.
8.3. External Validity
External validity is related to the generalization of this study. The mapping results have been
considered regarding the IoT domain, and the validity of the results presented in this paper concerns
only the IoT agriculture domain. The classiﬁcation of the papers and search string presented in this
research may help the practitioners as a starting point for IoT agriculture research, and researchers can
categorize the addition studies accordingly.
8.4. Conclusion Validity
The conclusion validity threat is related to the identiﬁcation of improper relationships that may
generate an incorrect conclusion. In the mapping study, a conclusion validity threat refers to the
diﬀerent elements such as incorrect data extraction and missing studies. To decrease this threat, the
data extraction and selection process have been clearly deﬁned in the previous paragraph on internal
validity. The traceability among the extracted data and the conclusion has been strengthened through
the direct generation of frequency plots and bubble plots generated from the collected data by applying
statistical analysis.
9. Conclusions
This article has presented a systematic literature review that presents a discussion on selective
high-quality research articles published in the domain of IoT-based agriculture. The survey has
been conducted by employing a systematic methodology to select 67 studies. Thereafter, an analysis
of diﬀerent IoT agriculture applications, sensors/devices, and communication protocols has been
presented. The most promising fact is that this area of research is being patronized by the governments
of various countries, and many countries have their IoT agriculture policies. Apart from this, all
the major components of IoT-based agriculture have been contextualized in a framework. Lastly,
the promising future directions have been discussed for the researchers working in the domain of
IoT-based agriculture.
Author Contributions: Conceptualization, M.S.F., S.R., and Y.B.Z.; methodology, M.S.F.; software, A.A., T.U.,
M.S.F., and S.R.; formal analysis, M.S.F. and Y.B.Z.; investigation, M.S.F.; resources, S.R.; data curation, S.R.;
writing—original draft preparation, M.S.F.; writing—review and editing, A.A.; visualization, M.S.F.; supervision,
M.S.F.; project administration, M.S.F. All authors have read and agreed to the published version of the manuscript.
Funding: This research received no external funding.
Acknowledgments: The authors appreciate the anonymous reviewers for their valuable feedback on the initial
version of this paper. This research work is supported in part by Yeungnam University, UMT Lahore and CUI,
Lahore Campus.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Medela, A.; Cendón, B.; González, L.; Crespo, R.; Nevares, I. IoT multiplatform networking to monitor
and control wineries and vineyards. In Proceedings of the 2013 Future Network Mobile Summit, Lisboa,
Portugal, 3–5 July 2013; pp. 1–10.
2.
Giorgetti, A.; Lucchi, M.; Tavelli, E.; Barla, M.; Gigli, G.; Casagli, N.; Dardari, D. A robust wireless sensor
network for landslide risk analysis: System design, deployment, and ﬁeld testing. IEEE Sens. J. 2016, 16,
6374–6386. [CrossRef]
3.
Zheng, R.; Zhang, T.; Liu, Z.; Wang, H. An EIoT system designed for ecological and environmental
management of the Xianghe Segment of China’s Grand Canal. Int. J. Sustain. Dev. World Ecol. 2016, 23,
372–380. [CrossRef]
Electronics 2020, 9, 319
34 of 41
4.
Torres-Ruiz, M.; Juárez-Hipólito, J.H.; Lytras, M.D.; Moreno-Ibarra, M. Environmental noise sensing
approach based on volunteered geographic information and spatio-temporal analysis with machine learning.
In Proceedings of the International Conference on Computational Science and Its Applications, Beijing,
China, 4–7 July 2016; pp. 95–110.
5.
Hachem, S.; Mallet, V.; Ventura, R.; Pathak, A.; Issarny, V.; Raverdy, P.G.; Bhatia, R. Monitoring noise pollution
using the urban civics middleware. In Proceedings of the 2015 IEEE First International Conference on Big
Data Computing Service and Applications, Redwood City, CA, USA, 30 March–2 April 2015; pp. 52–61.
6.
Liu, Z.; Huang, J.; Wang, Q.; Wang, Y.; Fu, J. Real-time barrier lakes monitoring and warning system based on
wireless sensor network. In Proceedings of the 2013 Fourth International Conference on Intelligent Control
and Information Processing (ICICIP), Beijing, China, 9–11 June 2013; pp. 551–554.
7.
Junaid, A. Application of Modern High Performance Networks; Bentham Science Publishers Ltd.: Oak Park, IL,
USA, 2009; pp. 120–129.
8.
Song, Y.; Ma, J.; Zhang, X.; Feng, Y. Design of wireless sensor network-based greenhouse environment
monitoring and automatic control system. J. Netw. 2012, 7, 838. [CrossRef]
9.
Satyanarayana, G.V.; Mazaruddin, S.D. Wireless sensor based remote monitoring system for agriculture
using ZigBee and GPS. In Proceedings of the Conference on Advances in Communication and Control
Systems-2013, Makka Wala, India, 6–8 April 2013.
10.
Sakthipriya, N. An eﬀective method for crop monitoring using wireless sensor network. Middle-East J.
Sci. Res. 2014, 20, 1127–1132.
11.
Rajesh, D. Application of spatial data mining for agriculture. Int. J. Comput. Appl. 2011, 15, 7–9. [CrossRef]
12.
Shaobo, Y.; Zhenjianng, C.; Xuesong, S.; Qingjia, M.; Jiejing, L.; Tingjiao, L.; Kezheng, W. The appliacation of
bluetooth module on the agriculture expert System. In Proceedings of the 2010 2nd International Conference
on Industrial and Information Systems, Dalian, China, 10–11 July 2010; Volume 1, pp. 109–112.
13.
Haefke, M.; Mukhopadhyay, S.C.; Ewald, H. A Zigbee based smart sensing platform for monitoring
environmental parameters. In Proceedings of the 2011 IEEE International Instrumentation and Measurement
Technology Conference, Binjiang, China, 10–12 May 2011; pp. 1–8.
14.
Pavithra, D.S.; Srinath, M.S. GSM based automatic irrigation control system for eﬃcient use of resources and
crop planning by using an Android mobile. IOSR J. Mech. Civ. Eng. 2014, 11, 49–55.
15.
Dinesh, M.; Saravanan, P. FPGA based real time monitoring system for agricultural ﬁeld. Int. J. Electron.
Comput. Sci. Eng. 2011, 1, 1514–1519.
16.
Castañeda-Miranda, R.; Ventura-Ramos, E., Jr.; del RocíoPeniche-Vera, R.; Herrera-Ruiz, G. Fuzzy greenhouse
climate control system based on a ﬁeld programmable gate array. Biosyst. Eng. 2006, 94, 165–177. [CrossRef]
17.
Ferentinos, K.P.; Katsoulas, N.; Tzounis, A.; Kittas, C.; Bartzanas, T. A climate control methodology based on
wireless sensor networks in greenhouses. In Proceedings of the XXIX International Horticultural Congress on
Horticulture: Sustaining Lives, Livelihoods and Landscapes (IHC2014), Brisbane, Australia, 17–22 August
2014; pp. 75–82.
18.
Patil, A.; Pawar, C.; Patil, N.; Tambe, R. Smart health monitoring system for animals. In Proceedings of the
2015 International Conference on Green Computing and Internet of Things (ICGCIoT), Noida, India, 8–10
October 2015; pp. 1560–1564.
19.
Vijayan, A.; Suresh, M. Wearable sensors for animal health monitoring using Zigbee. Int. Adv. Res. J. Sci.
Eng. Technol. 2016, 3, 369–373.
20.
Keele, S. Guidelines for Performing Systematic Literature Reviews in Software Engineering; Technical Report 2016,
Ver. 2.3 Technical Report; EBSE: Durham, UK, 2007.
21.
Dybå, T.; Dingsøyr, T. Empirical studies of agile software development: A systematic review. Inf. Softw.
Technol. 2008, 50, 833–859. [CrossRef]
22.
Petersen, K.; Feldt, R.; Mujtaba, S.; Mattsson, M. Systematic mapping studies in software engineering.
In Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering
(EASE), Bari, Italy, 26–27 June 2008; Volume 8, pp. 68–77.
23.
Fernandez, A.; Insfran, E.; Abrahão, S. Usability evaluation methods for the web: A systematic mapping
study. Inf. Softw. Technol. 2011, 53, 789–817. [CrossRef]
24.
Landis, J.R.; Koch, G.G. The measurement of observer agreement for categorical data. Biometrics 1977, 33,
159–174. [CrossRef]
Electronics 2020, 9, 319
35 of 41
25.
Watthanawisuth, N.; Tuantranont, A.; Kerdcharoen, T. Microclimate real-time monitoring based on ZigBee
sensor network. In Proceedings of the SENSORS, 2009 IEEE, Christchurch, New Zealand, 25–28 October
2009; pp. 1814–1818.
26.
Chen, K.T.; Zhang, H.H.; Wu, T.T.; Hu, J.; Zhai, C.Y.; Wang, D. Design of monitoring system for multilayer soil
temperature and moisture based on WSN. In Proceedings of the 2014 International Conference on Wireless
Communication and Sensor Network, Wuhan, China, 13–14 December 2014; pp. 425–430.
27.
Postolache, O.; Pereira, J.D.; Girão, P.S. Wireless sensor network-based solution for environmental monitoring:
Water quality assessment case study. IET Sci. Meas. Technol. 2014, 8, 610–616. [CrossRef]
28.
Xijun, Y.; Limei, L.; Lizhong, X. The application of wireless sensor network in the irrigation area automatic
system. In Proceedings of the 2009 International Conference on Networks Security, Wireless Communications
and Trusted Computing, Wuhan, China, 25–26 April 2009; Volume 1, pp. 21–24.
29.
Fourati, M.A.; Chebbi, W.; Kamoun, A. Development of a web-based weather station for irrigation scheduling.
In Proceedings of the 2014 Third IEEE International Colloquium in Information Science and Technology
(CIST), Tetouan, Morocco, 20–22 October 2014; pp. 37–42.
30.
Langendoen, K.; Baggio, A.; Visser, O. Murphy loves potatoes: Experiences from a pilot sensor network
deployment in precision agriculture. In Proceedings of the 20th IEEE international parallel distributed
processing symposium, Rhodes Island, Greece, 25–29 April 2006.
31.
Roy, S.K.; Roy, A.; Misra, S.; Raghuwanshi, N.S.; Obaidat, M.S. AID: A prototype for agricultural intrusion
detection using wireless sensor network. In Proceedings of the 2015 IEEE International Conference on
Communications (ICC), London, UK, 8–12 June 2015; pp. 7059–7064.
32.
Jain, V.R.; Bagree, R.; Kumar, A.; Ranjan, P. wildCENSE: GPS based animal tracking system. In Proceedings
of the 2008 International Conference on Intelligent Sensors, Sensor Networks and Information Processing,
Sydney, Australia, 15–18 December 2008; pp. 617–622.
33.
Pahuja, R.; Verma, H.K.; Uddin, M. A wireless sensor network for greenhouse climate control. IEEE Pervasive
Comput. 2013, 12, 49–58. [CrossRef]
34.
Khandani, S.K.; Kalantari, M. Using ﬁeld data to design a sensor network. In Proceedings of the 2009
43rd Annual Conference on Information Sciences and Systems, Baltimore, MD, USA, 18–20 March 2009;
pp. 219–223.
35.
Luan, Q.; Fang, X.; Ye, C.; Liu, Y. An integrated service system for agricultural drought monitoring and
forecasting and irrigation amount forecasting. In Proceedings of the 2015 23rd International Conference on
Geo informatics, Wuhan, China, 19–21 June 2015; pp. 1–7.
36.
Krishna, K.L.; Silver, O.; Malende, W.F.; Anuradha, K. Internet of Things application for implementation of
smart agriculture system. In Proceedings of the 2017 International Conference on I-SMAC (IoT in Social,
Mobile, Analytics and Cloud) (I-SMAC), Palladam, India, 10–11 February 2017; pp. 54–59.
37.
Malaver Rojas, J.A.; Gonzalez, L.F.; Motta, N.; Villa, T.F.; Etse, V.K.; Puig, E. Design and ﬂight testing of an
integrated solar powered UAV and WSN for greenhouse gas monitoring emissions in agricultural farms.
In Proceedings of the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems, Hamburg,
Germany, 28 September–2 October 2015; Volume 1, No. 1. pp. 1–6.
38.
Yoo, S.E.; Kim, J.E.; Kim, T.; Ahn, S.; Sung, J.; Kim, D. A 2 S: Automated agriculture system based on WSN.
In Proceedings of the 2007 IEEE International Symposium on Consumer Electronics, Irving, TX, USA, 20–23
June 2007; pp. 1–5.
39.
Davcev, D.; Mitreski, K.; Trajkovic, S.; Nikolovski, V.; Koteli, N. IoT agriculture system based on LoRaWAN.
In Proceedings of the 2018 14th IEEE International Workshop on Factory Communication Systems (WFCS),
Imperia, Italy, 13–15 June 2018; pp. 1–4.
40.
dos Santos, U.J.L.; Pessin, G.; da Costa, C.A.; da Rosa Righi, R. AgriPrediction: A proactive internet of things
model to anticipate problems and improve production in agricultural crops. Comput. Electron. Agric. 2019,
161, 202–213. [CrossRef]
41.
Wasson, T.; Choudhury, T.; Sharma, S.; Kumar, P. Integration of RFID and sensor in agriculture using IOT.
In Proceedings of the 2017 International Conference on Smart Technologies for Smart Nation (SmartTechCon),
Bangalore, India, 17–19 August 2017; pp. 217–222.
42.
Kodali, R.K.; Sarjerao, B.S. A low cost smart irrigation system using MQTT protocol. In Proceedings of the
2017 IEEE Region 10 Symposium (TENSYMP), Cochin, India, 14–16 July 2017; pp. 1–5.
Electronics 2020, 9, 319
36 of 41
43.
Llaria, A.; Terrasson, G.; Arregui, H.; Hacala, A. Geolocation and monitoring platform for extensive farming
in mountain pastures. In Proceedings of the 2015 IEEE International Conference on Industrial Technology
(ICIT), Seville, Spain, 17–19 March 2015; pp. 2420–2425.
44.
Li, L.; Xiaoguang, H.; Ke, C.; Ketai, H. The applications of wiﬁ-based wireless sensor network in internet
of things and smart grid. In Proceedings of the 2011 6th IEEE Conference on Industrial Electronics and
Applications, Beijing, China, 21–23 June 2011; pp. 789–793.
45.
Ruiz-Garcia, L.; Lunadei, L.; Barreiro, P.; Robla, I. A review of wireless sensor technologies and applications
in agriculture and food industry: State of the art and current trends. Sensors 2009, 9, 4728–4750. [CrossRef]
46.
Ofori-Dwumfuo, G.O.; Salakpi, S.V. WiFi and WiMAX deployment at the Ghana Ministry of Food and
Agriculture. Res. J. Appl. Sci. Eng. Technol. 2011, 3, 1374–1383.
47.
Elijah, O.; Rahman, T.A.; Orikumhi, I.; Leow, C.Y.; Hindia, M.N. An overview of Internet of Things (IoT) and
data analytics in agriculture: Beneﬁts and challenges. IEEE Internet Things J. 2018, 5, 3758–3773. [CrossRef]
48.
Liu, S.; Guo, L.; Webb, H.; Ya, X.; Chang, X. Internet of Things Monitoring System of Modern Eco-Agriculture
Based on Cloud Computing. IEEE Access 2019, 7, 37050–37058. [CrossRef]
49.
Chen, W.L.; Lin, Y.B.; Lin, Y.W.; Chen, R.; Liao, J.K.; Ng, F.L.; Chan, Y.-Y.; Liu, Y.-C.; Wang, C.-C.; Chiu, C.-H.;
et al. AgriTalk: IoT for precision soil farming of turmeric cultivation. IEEE Internet Things J. 2019, 6, 5209–5223.
[CrossRef]
50.
Zhao, J.C.; Zhang, J.F.; Feng, Y.; Guo, J.X. The study and application of the IOT technology in agriculture.
In Proceedings of the 2010 3rd International Conference on Computer Science and Information Technology,
Chengdu, China, 9–11 July 2010; Volume 2, pp. 462–465.
51.
González-Amarillo, C.A.; Corrales-Muñoz, J.C.; Mendoza-Moreno, M.Á.; Hussein, A.F.; Arunkumar, N.;
Ramirez-González, G. An IoT-Based Traceability System for Greenhouse Seedling Crops. IEEE Access 2018, 6,
67528–67535. [CrossRef]
52.
Dholu, M.; Ghodinde, K.A. Internet of things (iot) for precision agriculture application. In Proceedings of
the 2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI), Tirunelveli, India,
11–12 May 2018; pp. 339–342.
53.
Dagar, R.; Som, S.; Khatri, S.K. Smart Farming–IoT in Agriculture. In Proceedings of the 2018 International
Conference on Inventive Research in Computing Applications (ICIRCA), Coimbatore, India, 11–12 July 2018;
pp. 1052–1056.
54.
Pallavi, S.; Mallapur, J.D.; Bendigeri, K.Y. Remote sensing and controlling of greenhouse agriculture
parameters based on IoT. In Proceedings of the 2017 International Conference on Big Data, IoT and Data
Science (BID), Pune, India, 20–22 December 2017; pp. 44–48.
55.
Heble, S.; Kumar, A.; Prasad, K.V.D.; Samirana, S.; Rajalakshmi, P.; Desai, U.B. A low power IoT network
for smart agriculture. In Proceedings of the 2018 IEEE 4th World Forum on Internet of Things (WF-IoT),
Singapore, 5–8 February 2018; pp. 609–614.
56.
Bing, F. Research on the agriculture intelligent system based on IOT. In Proceedings of the 2012 International
Conference on Image Analysis and Signal Processing, Zhejiang, China, 9–11 November; pp. 1–4.
57.
Kjellby, R.A.; Cenkeramaddi, L.R.; Frøytlog, A.; Lozano, B.B.; Soumya, J.; Bhange, M. Long-range Self-powered
IoT Devices for Agriculture Aquaponics Based on Multi-hop Topology. In Proceedings of the 2019 IEEE 5th
World Forum on Internet of Things (WF-IoT), Limerick, Ireland, 15–18 April 2019; pp. 545–549.
58.
Khattab, A.; Abdelgawad, A.; Yelmarthi, K. Design and implementation of a cloud-based IoT scheme for
precision agriculture. In Proceedings of the 2016 28th International Conference on Microelectronics (ICM),
Giza, Egypt, 17–20 December 2016; pp. 201–204.
59.
AshifuddinMondal, M.; Rehena, Z. Iot based intelligent agriculture ﬁeld monitoring system. In Proceedings
of the 2018 8th International Conference on Cloud Computing, Data Science Engineering (Conﬂuence),
Noida, India, 11–12 January 2018; pp. 625–629.
60.
Mekala, M.S.; Viswanathan, P. A Survey: Smart agriculture IoT with cloud computing. In Proceedings of the
2017 International Conference on Microelectronic Devices, Circuits and Systems (ICMDCS), Vellore, India,
10–12 August 2017; pp. 1–7.
61.
Nóbrega, L.; Tavares, A.; Cardoso, A.; Gonçalves, P. Animal monitoring based on IoT technologies.
In Proceedings of the 2018 IoT Vertical and Topical Summit on Agriculture-Tuscany (IOT Tuscany), Tuscany,
Italy, 8–9 May 2018; pp. 1–5.
Electronics 2020, 9, 319
37 of 41
62.
Hari Ram, V.V.; Vishal, H.; Dhanalakshmi, S.; Vidya, P.M. Regulation of water in agriculture ﬁeld using
Internet of Things. In Proceedings of the 2015 IEEE Technological Innovation in ICT for Agriculture and
Rural Development (TIAR), Chennai, India, 10–12 July 2015; pp. 112–115.
63.
Thorat, A.; Kumari, S.; Valakunde, N.D. An IoT based smart solution for leaf disease detection. In Proceedings
of the 2017 International Conference on Big Data, IoT and Data Science (BID), Pune, India, 20–22 December
2017; pp. 193–198.
64.
Rao, R.N.; Sridhar, B. IoT based smart crop-ﬁeld monitoring and automation irrigation system. In Proceedings
of the 2018 2nd International Conference on Inventive Systems and Control (ICISC), Coimbatore, India,
19–20 January 2018; pp. 478–483.
65.
Lee, H.; Moon, A.; Moon, K.; Lee, Y. Disease and pest prediction IoT system in orchard: A preliminary study.
In Proceedings of the 2017 Ninth International Conference on Ubiquitous and Future Networks (ICUFN),
Milan, Italy, 4–7 July 2017; pp. 525–527.
66.
Giordano, S.; Seitanidis, I.; Ojo, M.; Adami, D.; Vignoli, F. IoT solutions for crop protection against wild
animal attacks. In Proceedings of the 2018 IEEE International Conference on Environmental Engineering
(EE), Milan, Italy, 12–14 March 2018; pp. 1–5.
67.
Islam, A.; Akter, K.; Nipu, N.J.; Das, A.; Rahman, M.M.; Rahman, M. IoT Based Power Eﬃcient Agro
Field Monitoring and Irrigation Control System: An Empirical Implementation in Precision Agriculture.
In Proceedings of the 2018 International Conference on Innovations in Science, Engineering and Technology
(ICISET), Chittagong, Bangladesh, 27–28 October 2018; pp. 372–377.
68.
Muangprathub, J.; Boonnam, N.; Kajornkasirat, S.; Lekbangpong, N.; Wanichsombat, A.; Nillaor, P. IoT and
agriculture data analysis for smart farm. Comput. Electron. Agric. 2019, 156, 467–474. [CrossRef]
69.
Foughali, K.; Fathallah, K.; Frihida, A. Using Cloud IOT for disease prevention in precision agriculture.
Procedia Comput. Sci. 2018, 130, 575–582. [CrossRef]
70.
Mohanraj, I.; Ashokumar, K.; Naren, J. Field monitoring and automation using IOT in agriculture domain.
Procedia Comput. Sci. 2016, 93, 931–939. [CrossRef]
71.
Nawandar, N.K.; Satpute, V.R. IoT based low cost and intelligent module for smart irrigation system.
Comput. Electron. Agric. 2019, 162, 979–990. [CrossRef]
72.
Mazon-Olivo, B.; Hernández-Rojas, D.; Maza-Salinas, J.; Pan, A. Rules engine and complex event processor
in the context of internet of things for precision agriculture. Comput. Electron. Agric. 2018, 154, 347–360.
[CrossRef]
73.
Goap, A.; Sharma, D.; Shukla, A.K.; Krishna, C.R. An IoT based smart irrigation management system using
Machine learning and open source technologies. Comput. Electron. Agric. 2018, 155, 41–49. [CrossRef]
74.
Akka¸s, M.A.; Sokullu, R. An IoT-based greenhouse monitoring system with Micaz motes. Procedia Comput. Sci.
2017, 113, 603–608. [CrossRef]
75.
Zhang, X.; Zhang, J.; Li, L.; Zhang, Y.; Yang, G. Monitoring citrus soil moisture and nutrients using an Iot
based system. Sensors 2017, 17, 447. [CrossRef]
76.
Jayaraman, P.; Yavari, A.; Georgakopoulos, D.; Morshed, A.; Zaslavsky, A. Internet of things platform for
smart farming: Experiences and lessons learnt. Sensors 2016, 16, 1884. [CrossRef]
77.
Martínez, R.; Pastor, J.; Álvarez, B.; Iborra, A. A testbed to evaluate the ﬁware-based IoT platform in the
domain of precision agriculture. Sensors 2016, 16, 1979. [CrossRef] [PubMed]
78.
Kamienski, C.; Soininen, J.P.; Taumberger, M.; Dantas, R.; Toscano, A.; Salmon Cinotti, T.; Maia, R.F.; Torre
Neto, A. Smart water management platform: Iot-based precision irrigation for agriculture. Sensors 2019, 19,
276. [CrossRef] [PubMed]
79.
Kim, S.; Lee, M.; Shin, C. IoT-Based Strawberry Disease Prediction System for Smart Farming. Sensors 2018,
18, 4051. [CrossRef] [PubMed]
80.
Phupattanasilp, P.; Tong, S.R. Augmented Reality in the Integrative Internet of Things (AR-IoT): Application
for Precision Farming. Sustainability 2019, 11, 2658. [CrossRef]
81.
Hu, S.; Wang, H.; She, C.; Wang, J. AgOnt: Ontology for agriculture internet of things. In Proceedings of
the International Conference on Computer and Computing Technologies in Agriculture, Nanchang, China,
22–25 October 2010; pp. 131–137.
82.
Li, J.; Gu, W.; Yuan, H. Research on IOT technology applied to intelligent agriculture. In Proceedings of the
5th International Conference on Electrical Engineering and Automatic Control, Weihai, China, 16–18 October
2015; pp. 1217–1224.
Electronics 2020, 9, 319
38 of 41
83.
Zhang, F. Research on applications of Internet of Things in agriculture. In Informatics and Management Science
VI; Springer: London, UK, 2013; pp. 69–75.
84.
Keswani, B.; Mohapatra, A.G.; Mohanty, A.; Khanna, A.; Rodrigues, J.J.; Gupta, D.; de Albuquerque, V.H.C.
Adapting weather conditions based IoT enabled smart irrigation technique in precision agriculture
mechanisms. Neural Comput. Appl. 2019, 31, 277–292. [CrossRef]
85.
Jayaraman, P.P.; Palmer, D.; Zaslavsky, A.; Salehi, A.; Georgakopoulos, D. Addressing information processing
needs of digital agriculture with OpenIoT platform. In Interoperability and Open-Source Solutions for the Internet
of Things; Springer: Cham, Switzerland, 2015; pp. 137–152.
86.
Agrawal, H.; Prieto, J.; Ramos, C.; Corchado, J.M. Smart feeding in farming through iot in silos. In Proceedings
of the International Symposium on Intelligent Systems Technologies and Applications, Jaipur, India, 21–24
September 2016; pp. 355–366.
87.
Gill, S.S.; Chana, I.; Buyya, R. IoT based agriculture as a cloud and big data service: The beginning of digital
India. J. Organ. End User Comput. 2017, 29, 1–23. [CrossRef]
88.
Chen, Y.; Chanet, J.P.; Hou, K.M.; Shi, H.L. Extending the RPL routing protocol to agricultural low power
and lossy networks (A-LLNs). Int. J. Agric. Environ. Inf. Syst. 2013, 4, 25–47.
89.
Shinde, T.A.; Prasad, J.R. IoT based animal health monitoring with naive Bayes classiﬁcation. IJETT 2017, 1,
8104–8107.
90.
Huang, C.H.; Shen, P.Y.; Huang, Y.C. IoT-based physiological and environmental monitoring system in
animal shelter. In Proceedings of the 2015 Seventh International Conference on Ubiquitous and Future
Networks, Sapporo, Japan, 7–10 July 2015; pp. 317–322.
91.
Noda, A.; Fukuda, O.; Okumura, H.; Arai, K. Behavior analysis of a small animal using IoT sensor system.
In Proceedings of the 2017 International Conference on Intelligent Informatics and Biomedical Sciences
(ICIIBMS), Okinawa, Japan, 24–26 November 2017; pp. 9–10.
92.
Ojha, T.; Misra, S.; Raghuwanshi, N.S. Wireless sensor networks for agriculture: The state-of-the-art in
practice and future challenges. Comput. Electron. Agric. 2015, 118, 66–84. [CrossRef]
93.
Singels, A.; Smith, M.T. Provision of irrigation scheduling advice to small-scale sugarcane farmers using
a web-based crop model and cellular technology: A South African case study. Irrig. Drain. J. Int. Comm.
Irrig. Drain. 2006, 55, 363–372. [CrossRef]
94.
Lee, J.; Kang, H.; Bang, H.; Kang, S. Dynamic crop ﬁeld analysis using mobile sensor node. In Proceedings
of the 2012 International Conference on ICT Convergence (ICTC), Jeju Island, Korea, 15–17 October 2012;
pp. 7–11.
95.
Feng, C.; Wu, H.R.; Zhu, H.J.; Sun, X. The design and realization of apple orchard intelligent monitoring
system based on internet of things technology. In Advanced Materials Research; Trans Tech Publications:
Stafa-Zurich, Switzerland, 2012; Volume 546, pp. 898–902.
96.
Alahi, M.E.E.; Xie, L.; Mukhopadhyay, S.; Burkitt, L. A temperature compensated smart nitrate-sensor for
agricultural industry. IEEE Trans. Ind. Electron. 2017, 64, 7333–7341. [CrossRef]
97.
Ehsan, S.; Bradford, K.; Brugger, M.; Hamdaoui, B.; Kovchegov, Y.; Johnson, D.; Louhaichi, M. Design and
analysis of delay-tolerant sensor networks for monitoring and tracking free-roaming animals. IEEE Trans.
Wirel. Commun. 2012, 11, 1220–1227. [CrossRef]
98.
Futagawa, M.; Iwasaki, T.; Murata, H.; Ishida, M.; Sawada, K. A miniature integrated multimodal sensor for
measuring pH, EC and temperature for precision agriculture. Sensors 2012, 12, 8338–8354. [CrossRef]
99.
Saha, A.K.; Saha, J.; Ray, R.; Sircar, S.; Dutta, S.; Chattopadhyay, S.P.; Saha, H.N. IOT-based drone for
improvement of crop quality in agricultural ﬁeld. In Proceedings of the 2018 IEEE 8th Annual Computing
and Communication, Las Vegas, NV, USA, 8–10 January 2018.
100. Garcia-Sanchez, A.J.; Garcia-Sanchez, F.; Garcia-Haro, J. Wireless sensor network deployment for integrating
video-surveillance and data-monitoring in precision agriculture over distributed crops. Comput. Electron. Agric.
2011, 75, 288–303. [CrossRef]
101. Xiaoling, H. A Study on Ultra-violet Flame Detector. Chin. J. Sci. Instrum. 1999, 20, 523–525.
102. Bapat, V.; Kale, P.; Shinde, V.; Deshpande, N.; Shaligram, A. WSN application for crop protection to divert
animal intrusions in the agricultural land. Comput. Electron. Agric. 2017, 133, 88–96. [CrossRef]
103. Patil, G.L.; Gawande, P.S.; Bag, R.V. Smart Agriculture System based on IoT and its Social Impact. Int. J.
Comput. Appl. 2017, 176, 0975–8887.
Electronics 2020, 9, 319
39 of 41
104. Mat, I.; Kassim, M.R.M.; Harun, A.N.; Yusoﬀ, I.M. IoT in precision agriculture applications using wireless
moisture sensor network. In Proceedings of the 2016 IEEE Conference on Open Systems (ICOS), Langkawi,
Malaysia, 10–12 October 2016; pp. 24–29.
105. CropX Starter Kit—Soil Temperature Sensor. Available online: https://www.cropx.com/product/cropx-
temperature/ (accessed on 14 June 2019).
106. 3D Crop Sensor Array with PAR Addon. Available online: http://grownetics.co/product/3d-crop-sensor-
array-with-par-addon/ (accessed on 14 June 2019).
107. Balaji, S.; Nathani, K.; Santhakumar, R. IoT Technology, Applications and Challenges: A Contemporary
Survey. Wirel. Pers. Commun. 2019, 108, 363–388. [CrossRef]
108. Climate Monitoring Device. Available online: https://www.groﬁt-ag.com/product-page/groﬁt-iot-device-1
(accessed on 14 June 2019).
109. Barrachina-Muñoz, S.; Bellalta, B.; Adame, T.; Bel, A. Multi-hop communication in the uplink for LPWANs.
Comput. Netw. 2017, 123, 153–168. [CrossRef]
110. Terrasson, G.; Llaria, A.; Marra, A.; Voaden, S. Accelerometer based solution for precision livestock farming:
Geolocation enhancement and animal activity identiﬁcation. In IOP Conference Series: Materials Science and
Engineering; IOP Publishing: Bristol, UK, 2016; Volume 138, p. 012004.
111. Xiaojing, Z.; Yuanguai, L. Zigbee implementation in intelligent agriculture based on internet of things.
In Proceedings of the 2nd International Conference on Electronic Mechanical Engineering and Information
Technology, Shenyang, China, 7 September 2012.
112. Dan, L.I.U.; Xin, C.; Chongwei, H.; Liangliang, J. Intelligent agriculture greenhouse environment monitoring
system based on IOT technology. In Proceedings of the 2015 International Conference on Intelligent
Transportation, Big Data and Smart City, Halong Bay, Vietnam, 19–20 December 2015; pp. 487–490.
113. A New Engine for Rural Economic Growth in the People’s Republic of China. Available online: https://www.
adb.org/sites/default/files/publication/455091/internet-plus-agriculture-prc.pdf (accessed on 24 September 2019).
114. Digitization of Agriculture—The Next Chapter for Internet of Things in Malaysia.
Available
online: http://www.mimos.my/wp-content/uploads/2016/10/282016--0729-IDCAP41608216-Digitisation-
of-agri-MiTrce.pdf (accessed on 24 September 2019).
115. Australian Government Investment in Landcare. Available online: http://www.agriculture.gov.au/ag-
farm-food/natural-resources/landcare/national-landcare-program/australian-government-investment-in-
landcare (accessed on 18 June 2019).
116. IoT in Agriculture—How is It Evolving. Available online: http://www.farminstitute.org.au/LiteratureRetrieve.
aspx?ID=157672 (accessed on 18 June 2019).
117. VT Networks SIGFOX Complete Roll out of Irish IoT Network in 8 Months.
Available online: https:
//vt-iot.com/vt-networks-sigfox-complete-roll-out-of-irish-iot-network-in-8-months/ (accessed on 18 June 2019).
118. The French Ministry of Agriculture and Food. Available online: https://agriculture.gouv.fr/french-ministry-
agriculture-and-food (accessed on 18 June 2019).
119. The 13th Five-Year Plan—China’s Transformation and Integration with the World Economy. Available
online: http://www.iberchina.org/ﬁles/2017/kpmg-13fyp-opportunities-analysis-for-chinese-and-foreign-
businesses.pdf (accessed on 18 June 2019).
120. NB-IoT Apps Enable Agricultural Digitalization. Available online: https://e.huawei.com/en/publications/
global/ict_insights/201806041630/ecosystem/201808170841?source=corp_comm (accessed on 18 June 2019).
121. IoT Blooms in Malaysian Agro-Sector. Available online: https://mit-insights.my/iot-blooms-in-malaysian-
agro-sector/ (accessed on 17 June 2019).
122. Developing Sensing Technologies for Smart Farming Practices in an Internet-Of-Ag-Things World. Available
online: https://reeis.usda.gov/web/crisprojectpages/1013254-developing-sensing-technologies-for-smart-
farming-practices-in-an-internet-of-ag-things-world.html (accessed on 19 June 2019).
123. Tech Professionals Use USDA Datasets to Address Water Management Challenges at the IoT World
Hackathon. Available online: https://www.usda.gov/media/blog/2019/06/17/tech-professionals-use-usda-
datasets-address-water-management-challenges-iot (accessed on 19 June 2019).
124. Food and Agriculture. Available online: https://www.nectec.or.th/en/research/ (accessed on 17 June 2019).
125. dtac Debuts the First IoT Based Agricultural Solution. Available online: https://www.telenor.com/dtac-
debuts-the-ﬁrst-iot-based-agricultural-solution/ (accessed on 17 June 2019).
Electronics 2020, 9, 319
40 of 41
126. IOT Policy in India. Available online: https://meity.gov.in/sites/upload_ﬁles/dit/ﬁles/Draft-IoT-Policy(1).pdf
(accessed on 20 June 2019).
127. Philippine Agricultural and Food Policies. Available online: https://www.ifpri.org/publication/philippine-
agricultural-and-food-policies-0 (accessed on 20 June 2019).
128. Pitì, A.; Verticale, G.; Rottondi, C.; Capone, A.; Lo Schiavo, L. The role of smart meters in enabling real-time
energy services for households: The Italian case. Energies 2017, 10, 199. [CrossRef]
129. Khanna, A.; Kaur, S. Evolution of Internet of Things (IoT) and its signiﬁcant impact in the ﬁeld of Precision
Agriculture. Comput. Electron. Agric. 2019, 157, 218–231. [CrossRef]
130. Finistere Ventures and PitchBook Close Gap in Agtech Funding Data. Available online: http://ﬁnistere.com/
news/2018-early-stage-agtech-report/ (accessed on 31 January 2020).
131. IoT Solution. Available online: https://www.samsung.com/global/business/networks/solutions/iot-solutions/
(accessed on 6 June 2019).
132. Learn More about Our Work with Dell to Scale IoT Farming Technologies.
Available online: https:
//aerofarms.com/2018/03/20/harvest-full-insights/ (accessed on 14 June 2019).
133. FarmBeats: AI, Edge IoT for Agriculture. Available online: https://www.microsoft.com/en-us/research/
project/farmbeats-iot-agriculture/ (accessed on 6 June 2019).
134. Digital Farming—From Farm to Fork. Available online: https://www.bosch-si.com/agriculture/connected-
agriculture/digital-farming.html (accessed on 14 June 2019).
135. IoT Agriculture: 5 Ways to Grow Your Business. Available online: https://r-stylelab.com/company/blog/iot/
iot-agriculture-5-ways-to-grow-your-business (accessed on 14 June 2019).
136. IoT Agriculture: How to Build Smart Greenhouse? Available online: https://r-stylelab.com/company/blog/
iot/iot-agriculture-how-to-build-smart-greenhouse (accessed on 14 June 2019).
137. IBM Watson IoT Platform. Available online: https://www.ibm.com/us-en/marketplace/internet-of-things-
cloud?lnk=STW_US_STESCH&lnk2=trial_IOTPlat&pexp=def&psrc=none&mhsrc=ibmsearch_a&mhq=
iot (accessed on 31 January 2020).
138. Inﬁswift IoT Platform for Agriculture. Available online: https://www.intel.com/content/www/us/en/internet-
of-things/inﬁswift-enterprise-iot-platform-for-agricultural-solution-brief.html?wapkw=inﬁswift (accessed
on 30 January 2020).
139. Open Agriculture Foundation: Creating an Open-Source Ecosystem to Revolutionize the Future of
Food. Available online: https://cloud.google.com/data-solutions-for-change/open-agriculture/ (accessed on
31 January 2020).
140. Asplund, M.; Nadjm-Tehrani, S. Attitudes and perceptions of IoT security in critical societal services. IEEE
Access 2016, 4, 2130–2138. [CrossRef]
141. Chen, L.; Thombre, S.; Järvinen, K.; Lohan, E.S.; Alén-Savikko, A.; Leppäkoski, H.; Bhuiyan, M.Z.H.;
Bu-Pasha, S.; Ferrara, G.N.; Honkala, S.; et al. Robustness, security and privacy in location-based services for
future IoT: A survey. IEEE Access 2017, 5, 8956–8977. [CrossRef]
142. Varga, P.; Plosz, S.; Soos, G.; Hegedus, C. Security threats and issues in automation IoT. In Proceedings of the
2017 IEEE 13th International Workshop on Factory Communication Systems (WFCS), Trondheim, Norway,
31 May–2 June 2017; pp. 1–6.
143. Duan, J.; Gao, D.; Yang, D.; Foh, C.H.; Chen, H.H. An energy-aware trust derivation scheme with game
theoretic approach in wireless sensor networks for IoT applications. IEEE Internet Things J. 2014, 1, 58–69.
[CrossRef]
144. Newell, A.; Yao, H.; Ryker, A.; Ho, T.; Nita-Rotaru, C. Node-capture resilient key establishment in sensor
networks: Design space and new protocols. ACM Comput. Surv. 2015, 47, 1–34. [CrossRef]
145. Elijah, O.; Orikumhi, I.; Rahman, T.A.; Babale, S.A.; Orakwue, S.I. Enabling smart agriculture in Nigeria:
Application of IoT and data analytics. In Proceedings of the 2017 IEEE 3rd International Conference
on Electro-Technology for National Development (NIGERCON), Owerri, Nigeria, 7–10 November 2017;
pp. 762–766.
146. Asikainen, M.; Haataja, K.; Toivanen, P. Wireless indoor tracking of livestock for behavioral analysis.
In Proceedings of the 2013 9th International Wireless Communications and Mobile Computing Conference
(IWCMC), Sardinia, Italy, 1–5 July 2013; pp. 1833–1838.
Electronics 2020, 9, 319
41 of 41
147. Al-Fuqaha, A.; Guizani, M.; Mohammadi, M.; Aledhari, M.; Ayyash, M. Internet of Things: A survey
on enabling technologies, protocols, and applications. IEEE Commun. Surv. Tutor. 2015, 17, 2347–2376.
[CrossRef]
148. Biral, A.; Centenaro, M.; Zanella, A.; Vangelista, L.; Zorzi, M. The challenges of M2M massive access in
wireless cellular networks. Digit. Commun. Netw. 2015, 1, 1–19. [CrossRef]
149. Perera, C.; Liu, C.H.; Jayawardena, S.; Chen, M. A survey on internet of things from industrial market
perspective. IEEE Access 2014, 2, 1660–1679. [CrossRef]
150. Aazam, M.; Huh, E.N.; St-Hilaire, M.; Lung, C.H.; Lambadaris, I. Cloud of Things: Integration of IoT with
Cloud Computing. In Robots and Sensor Clouds; Springer International Publishing: Berlin/Heidelberg,
Germany, 2016; pp. 77–94.
151. Díaz, M.; Cristian, M.; Bartolomé, R. State-of-the-art, challenges, and open issues in the integration of Internet
of things and cloud computing. J. Netw. Comput. Appl. 2016, 67, 99–117. [CrossRef]
152. Gubbi, J.; Buyya, R.; Marusic, S.; Palaniswami, M. Internet of things (IoT): A vision, architectural elements,
and future directions. Future Gener. Comput. Syst. 2013, 29, 1645–1660. [CrossRef]
153. Suciu, G.; Vulpe, A.; Halunga, S.; Fratu, O.; Todoran, G.; Suciu, V. Smart Cities Built on Resilient Cloud
Computing and Secure Internet of Things. In Proceedings of the 19th International Conference on Control
Systems and Computer Science, Bucharest, Romania, 29–31 May 2013; pp. 513–518.
154. Aazam, M.; Khan, I.; Alsaﬀar, A.A.; Huh, E.N. Cloud of things: Integrating Internet of things and cloud
computing and the issues involved. In Proceedings of the 2014 11th International Bhurban Conference on
Applied Sciences Technology (IBCAST), Islamabad, Pakistan, 14–18 January 2014.
© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 5:
- APA Citation: Mishra, A. K. (2020). Internet of Things (IoT) Networks: Architecture, Applications, and Future Directions. Turkish Journal of Computer and Mathematics Education, 11(3), 2067-2075.
  Main Objective: To provide a thorough review of IoT networks, covering their design, applications, and future directions.
  Study Location: Unspecified
  Data Sources: Literature review
  Technologies Used: Edge computing, Fog Computing
  Key Findings: Edge computing reduces latency, enables real-time decision-making, and reduces reliance on cloud connectivity.
  Extract 1: "Edge computing reduces latency by processing data closer to the source, enabling real-time decision-making. It also lessens reliance on cloud connectivity by shifting processing to local devices or edge devices."
  Extract 2: None
  Limitations: None
  Relevance Evaluation: The study highlights the advantages of edge computing, which align with the point being made about the benefits of edge computing in reducing latency, enabling real-time decision-making, and reducing reliance on cloud connectivity in the data collection to cloud pipeline.
  Relevance Score: 0.9
  Inline Citation: (Mishra, 2020)
  Explanation: Edge computing reduces latency by processing data closer to the source, enabling real-time decision-making. It also lessens reliance on cloud connectivity by shifting processing to local devices or edge devices.

 Full Text: >
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2067 
 
 
 
Research Article  
Internet of Things (IoT) Networks: Architecture, Applications, and Future 
Directions 
 
Amit Kumar Mishra 
 Department of Comp. Sc. & Info. Tech., Graphic Era Hill University, Dehradun, Uttarakhand, India 248002, 
 
Abstract: The Internet of Things (IoT) networks, including their design, applications, future directions, difficulties, and 
constraints, are thoroughly discussed in this research study. The explanation of IoT networks' design, covering definitions 
and components, as well as centralized and decentralized networks, follows an overview of IoT networks' significance. The 
applications of IoT networks are examined in the next part, along with specific use examples from the fields of healthcare, 
manufacturing, transportation, and smart cities. The following section of the article examines new developments in IoT 
networks, including edge computing, 5G networks, AI, and blockchain technology. The difficulties and constraints of IoT 
networks, such as security and privacy issues, interoperability and compatibility problems, scalability, and network 
congestion, are also examined. The final section of the study summarizes the main ideas and research conclusions, 
highlighting the significance of IoT networks in our increasingly linked society. 
Keywords: Security, privacy, interoperability, compatibility, scalability, network congestion, edge computing, 5G networks. 
 
I. 
Introduction 
"Things" that are part of the "Internet of Things" (IoT) are equipped with sensors, software, and network 
connectivity, giving them the ability to gather and share data with one another and with other devices. The 
ongoing digital transformation is taking place in many different domains, including medical, industry, 
transportation, and urban planning[1]. Connected devices and their networks are important to this 
transformation. This response will concentrate on the architecture, applications, and future directions of 
potential development of IoT networks.The term "Internet of Things" (IoT) describes a network of actual 
physical objects that are linked to the internet and are capable of exchanging data and information with one 
another. These items, often known as "smart devices," have sensors, software, and network connectivity that 
enable data collection and transmission[2]. Healthcare, industry, transportation, and smart cities are just a few of 
the sectors being transformed by IoT networks.IoT networks are becoming more and more significant as 
businesses all over the world continue to utilize this technology to increase operational effectiveness, cut costs, 
and improve customer experience[3]. Over the coming years, the global IoT industry is anticipated to expand 
rapidly, increasing in size to an estimated $1.5 trillion by 2030.This study paper's main goal is to give a 
thorough review of IoT networks, covering its design, uses, and prospects. Also, this study will emphasize the 
drawbacks and restrictions of IoT networks as well as how they may affect future studies. The reader will have a 
better knowledge of the potential of IoT network. 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2068 
 
 
 
Research Article  
 
Figure.1 IoT Network 
II. 
Review of Literature 
The Internet of Things (IoT) , is an enabling technologies, and potential uses. The authors highlight the obstacles 
and prospects in this field while discussing the many components of the IoT, such as sensors, communication 
networks, and data processing systems.The benefits and drawbacks of the IoT are explored in this study, along 
with concerns about privacy, security, and standardization. The authors in [4], present an overview of the several 
IoT technologies and talk about why it's important for them to work together.The vision, architectural aspects, 
and future directions of the IoT are all discussed in this article. The authors in [5]present an overview of the 
supporting technologies, including sensors, wireless networks, and cloud computing, and examine the different 
IoT applications, such as healthcare, smart homes, and transportation.This study examines all aspects of the IoT, 
from its definition and structure to its potential uses. The writers highlight the challenges and potential in the 
field of IoT and cover its many subjects and developments, such as data analytics, security, and standards.The 
authors in [6], we'll look at the parallels and differences between WSNs and the Internet of Things. The authors 
give a rundown of the technologies—sensors, wireless networks, and data processing systems—that make 
WSNs and the Internet of Things possible, and then describe their many uses in fields like medicine, smart 
homes, and agriculture.The authors in [7], we'll look at how effective resource management is essential to the 
growth of cloud-based vehicle networks. The authors offer a resource management paradigm for vehicular 
networks in the cloud and then analyze the many issues and potential solutions that arise in this setting.The 
authors in [8]Big data analytics and the Internet of Things are discussed in this article and how they can be used 
to build smart and connected neighborhoods. The authors in [9]provide an in-depth analysis of the potential and 
threats associated with the Internet of Things (IoT) in smart cities. 
Reference 
Year 
Focus 
Methodology 
Key Findings 
[8]   
2019 
General overview 
Literature 
review 
Highlights the architecture, applications, and security 
concerns of IoT. 
[9]   
2018 
Healthcare 
applications 
Literature 
review 
Shows the potential benefits of IoT in healthcare, 
including remote monitoring and improved patient 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2069 
 
 
 
Research Article  
outcomes. 
[10]   
2019 
Manufacturing 
applications 
Literature 
review 
Discusses 
the 
various 
applications 
of 
IoT 
in 
manufacturing, including predictive maintenance and 
supply chain optimization. 
[11]   
2019 
Transportation 
applications 
Literature 
review 
Explores the potential benefits of IoT in transportation, 
including traffic management and vehicle monitoring. 
[12]   
2018 
Smart 
city 
applications 
Literature 
review 
Discusses the various applications of IoT in smart 
cities, including energy management and waste 
reduction. 
[13]   
2019 
General overview 
Literature 
review 
Provides 
a 
comprehensive 
overview 
of 
IoT 
applications, challenges, and future directions. 
[14]   
2019 
IoT security 
Literature 
review 
Highlights the key security challenges of IoT and 
suggests potential solutions. 
[15]   
2018 
General overview 
Literature 
review 
Provides an overview of IoT technologies, security, and 
privacy concerns. 
[16]   
2018 
General overview 
Literature 
review 
Discusses the enabling technologies, challenges, and 
open research issues of IoT. 
[17]   
2018 
General overview 
Literature 
review 
Provides a comprehensive overview of IoT architecture, 
technology, applications, security, and future trends. 
[18]   
2018 
IoT and big data 
Literature 
review 
Explores the potential benefits of combining IoT and 
big data analytics. 
[19]   
2018 
Agriculture 
applications 
Literature 
review 
Discusses the various applications of IoT in agriculture, 
including crop monitoring and irrigation management. 
[20]   
2018 
Energy management 
applications 
Literature 
review 
Explores the potential benefits of IoT in energy 
management, 
including 
demand 
response 
and 
renewable energy integration. 
[21]   
2018 
Smart 
grid 
applications 
Literature 
review 
Discusses the various applications of IoT in smart grids, 
including grid monitoring and fault detection. 
[22]   
2018 
Healthcare 
applications 
Literature 
review 
Explores the potential benefits of combining IoT and 
cloud computing 
Table 1. Comparative Study of Various Techniques used for IoT System 
 
III. 
Architecture of IoT Networks 
IoT networks are made up of a variety of parts that cooperate to make it possible to gather, process, and transmit 
data. An IoT network's essential elements include: 
A. Definition and components of IoT networks 
i. 
Devices: These are actual physical things with processors, sensors, and network connectivity. Smart 
household appliances, wearable fitness trackers, commercial machinery, and environmental sensors are 
a few examples of IoT gadgets. 
ii. 
Sensors: Sensors are used to collect data from the physical environment, such as temperature, 
humidity, pressure, or position. A wide range of sensors, such as accelerometers, gyroscopes, 
microphones, and cameras, can be used by IoT networks. 
iii. 
Actuators: These parts are used to change the environment in response to information gathered by 
sensors. For instance, an IoT network may employ actuators to modify a room's temperature or turn on 
and off lighting. 
iv. 
Network Connectivity: IoT devices need to be connected to a network to transmit data. Many network 
technologies, such as Wi-Fi, cellular networks, and Bluetooth, can be used to do this. 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2070 
 
 
 
Research Article  
v. 
Data processing is necessary in order to make use of the data that IoT devices collect. This can be 
done on the device itself, on a nearby edge device, or on the cloud. Data analysis, aggregation, and 
filtering are all examples of processing. 
vi. 
Storage:IoT networks may store, process, and analyse data using cloud services. These can include 
services for data storage, data analytics, and machine learning. 
vii. 
Applications: Software applications can be used by IoT networks to let users interact with and manage 
the network. These can include mobile or web tools that let consumers access and keep tabs on data 
coming from their Internet of Things (IoT) devices. 
viii. 
Security: IoT networks need to be secure to avoid unauthorized access or modification of data. These 
may include threat detection technologies, access controls, and encryption. 
These components work together to enable IoT networks to collect, process, and send data from the real world. 
IoT networks can offer a number of advantages by fusing these elements, including increased operational 
effectiveness, lower costs, and better user experiences. 
B. Four layers of IoT network architecture 
IoT networks can be further divided into blocks or modules, each of which serves a particular function. 
Depending on the particular use case of the IoT network, these blocks can be organized in a variety of ways. 
Some of the typical building blocks or modules for IoT network topologies include the following:All physical 
components of the IoT network, such as sensors, actuators, and gateways, are included in the device layer. These 
gadgets gather information and talk to other gadgets in the network.All network elements that permit 
communication between devices, such as Wi-Fi routers, gateways, and switches, are included in the network 
layer. The network layer also comprises protocols and technologies, such Bluetooth, Zigbee, and LoRa, that 
allow devices to connect with one another. 
i. 
Cloud Layer: This layer consists of cloud-based services that give the IoT network access to storage, 
compute, and analytics. These services can be used to store data, handle data processing and analysis, 
and give end users insights. 
ii. 
Application Layer: This layer consists of computer programs that give end users access to the 
information gathered by the Internet of Things network. These programs can be used to display data, 
start processes, and provide notifications. 
iii. 
Security Layer:The security procedures in this layer assure the availability, confidentiality, and 
integrity of the data gathered by the IoT network. Threat detection, access limits, and encryption are 
examples of security measures. 
iv. 
Device Layer:Device management, network monitoring, and firmware updates are just a few of the 
tools and services that help network administrators manage the IoT network. 
IoT networks can be designed in a variety of ways depending on the network's needs and the individual use 
case. IoT networks often depend on a combination of physical objects, network elements, cloud-based services, 
software applications, security methods, and management tools to operate, regardless of the architecture. 
C. Centralized and decentralized networks 
i. 
Centralized Networks: All data gathered by IoT devices is transmitted to a central server for 
processing and storage in a centralized IoT network design. On-site or in the cloud are both viable 
locations for this server. The server is responsible for processing and analyzing data, and may also 
serve as a gateway to other systems. As all the data is in one place, centralized networks can be simpler 
to manage and maintain. Yet, centralized networks may be less scalable and more subject to single 
points of failure. 
ii. 
Decentralized Networks: With a decentralized IoT network architecture, data processing and storage 
is distributed among different devices and systems. For instance, instead of being routed to a 
centralized server, data gathered by IoT devices may be processed and analyzed on the edge, in a 
nearby gateway or device. While there are several nodes that can handle data processing and storage, 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2071 
 
 
 
Research Article  
decentralized networks can be more scalable and resilient than centralized networks. Decentralized 
networks, on the other hand, can be trickier to run and maintain because data is dispersed throughout 
numerous hardware and software platforms. 
Network topologies that are centralized or decentralized each have benefits and drawbacks of their own. The 
network's size, the amount of data being collected, whether real-time processing is needed, and the required 
level of security all play a role in the architecture choice. To attain the appropriate level of scalability, 
robustness, and security, certain IoT networks may employ a hybrid architecture, which mixes centralized and 
decentralized features. 
IV. 
Applications of IoT Networks 
IoT networks are used in a wide range of fields and businesses, including manufacturing, transportation, 
healthcare, and smart cities. Below is a summary of some of the major IoT network-using industries: 
i. 
Healthcare: By enabling remote patient monitoring, streamlining hospital operations, and giving real-
time patient data, IoT networks can improve patient outcomes and lower expenses. IoT devices, for 
instance, can be used to track patients with long-term diseases like diabetes or heart disease and notify 
medical professionals of any changes in their state. 
ii. 
Manufacturing: By providing real-time monitoring of production processes and equipment, IoT 
networks can assist increase operational efficiency and decrease downtime. IoT sensors, for instance, 
can be used to monitor machine performance and anticipate maintenance requirements prior to a 
breakdown. 
iii. 
Transportation: IoT networks can aid in enhancing user experience, reducing congestion, and 
improving safety in the transportation sector. IoT sensors, for instance, can be used to track traffic 
patterns and modify traffic lights to improve flow. 
IoT networks have the potential to enhance urban environments' sustainability, safety, and livability. IoT sensors, 
for instance, can be used to monitor air quality, control energy use, and improve waste management. 
A. Examples of specific use cases 
The following are some particular use cases for IoT networks: 
a) Smart Homes: IoT devices can be utilised to build energy-efficient, safe, and simple to maintain smart 
houses. For instance, IoT-enabled security systems can send out real-time notifications if there is any 
unexpected activity in the home, while IoT-enabled thermostats can automatically adjust the 
temperature based on user preferences and occupancy. 
b) Asset tracking: IoT networks can be used to track assets like inventory, equipment, and vehicles in real 
time. For example, IoT sensors can be used to monitor the location and condition of products in transit, 
enabling organizations to optimize their supply chain operations. 
c) Environmental Monitoring: IoT networks can be used to keep an eye on things like weather patterns, 
water quality, and air quality. IoT sensors, for instance, can be used to forecast weather patterns or 
identify pollution levels in streams to assist stop natural disasters. 
d) Agriculture: Agricultural operations including irrigation, fertilizer, and pest control can be monitored 
and optimized via IoT networks. IoT sensors, for instance, can be used to enhance crop development 
and output by monitoring soil moisture levels and adjusting irrigation systems. 
 
V. 
IV. Future Directions of IoT Networks 
A. Emerging trends in IoT networks 
Digital twins are virtual reproductions of actual systems or gadgets. They can be used to imitate the behavior of 
systems in the real world because they are developed using sensor data. Design, testing, and maintenance of IoT 
systems and devices can be made better with the use of digital twins. 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2072 
 
 
 
Research Article  
i. 
Fog Computing: A decentralized computing architecture known as fog computing puts processing 
power closer to Internet of Things (IoT) devices. Although though it uses a more distributed 
methodology, it is comparable to edge computing. For real-time IoT applications, data processing speed 
and latency reduction are essential, and fog computing can help. 
ii. 
Hybrid Cloud: A hybrid cloud is an infrastructure that combines public and private clouds. IoT 
networks may balance their needs for affordability, scalability, and security with the aid of hybrid 
clouds. For instance, private cloud infrastructure can be used to store sensitive data whereas public 
cloud infrastructure can be used to store less sensitive data. 
iii. 
Human-Machine Interfaces (HMIs): HMIs allow users to communicate with IoT systems and devices. 
HMIs come in tactile, aural, and visual forms. These could aid in enhancing IoT networks' usability and 
accessibility. 
iv. 
Predictive Maintenance: In order to forecast when maintenance is necessary before equipment fails, 
predictive maintenance uses data from IoT sensors. Reduced downtime, increased dependability, and 
lower maintenance costs can all be a result of predictive maintenance. 
v. 
Smart Energy: To maximize energy efficiency and minimize waste, smart energy utilises IoT networks. 
IoT sensors, for instance, can be used to track energy use in buildings and modify heating or lighting 
based on occupancy levels. 
vi. 
Voice Recognition: Voice-activated instructions and IoT device control are made possible by speech 
recognition technologies. Speech recognition can help make IoT networks more convenient and 
accessible. 
 
B. Edge computing and 5G networks 
The adoption of edge computing and 5G networks is one of the most important trends in IoT networks. Instead 
of transmitting data to a central server for processing, edge computing uses devices at the network's edge to 
process data. Many IoT applications depend on low latency and quick reaction times, which can be achieved 
with this method. Contrarily, 5G networks provide greater bandwidth and lower latency than earlier wireless 
network generations, making them ideal for Internet of Things (IoT) applications. 
C. Artificial Intelligence and Machine Learning 
The growing application of machine learning (ML) and artificial intelligence (AI) technology in IoT networks is 
another trend. IoT devices can benefit from AI and ML to improve decision-making and automate processes like 
anomaly detection and predictive maintenance. Costs can be cut, productivity can be increased, and the user 
experience can be improved. 
D. Blockchain technology 
In IoT networks, blockchain technology is another new development. Blockchain is a distributed ledger 
technology that makes transactions safe, open, and impenetrable. Blockchain can be utilized in IoT networks to 
build secure, decentralized systems that are impervious to hackers or tampering. Blockchain technology, for 
instance, can be applied to develop a safe and open supply chain management system that can monitor the flow 
of commodities from manufacture to delivery.IoT networks have a promising future, filled with both exciting 
prospects and difficult obstacles. To ensure that IoT networks can reach their full potential as the technology 
develops, it will be crucial to solve challenges like privacy, security, and interoperability. 
VI. 
Challenges & Limitations of IoT Network 
IoT networks provide many benefits, but they also present a number of obstacles and constraints that need to be 
overcome. We will look at a few of these difficulties and their potential effects in this section. 
A. Privacy and Security Issues 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2073 
 
 
 
Research Article  
Security and privacy issues are one of the biggest problems facing IoT networks. Given that there are billions of 
internet-connected gadgets, the possibility of cyberattacks and data breaches is a major worry. IoT devices 
sometimes have poor security safeguards, which leaves them open to hacking and other online dangers. 
Furthermore, IoT devices frequently gather and send sensitive data, such private health information, 
necessitating strong privacy measures. 
B. Problems with Interoperability and Compatibility 
Interoperability and compatibility problems are another difficulty facing IoT networks. IoT systems and devices 
are frequently created by several manufacturers and may employ various communication protocols or standards. 
As a result, integrating equipment from many manufacturers and developing a cohesive system may be difficult. 
Additionally, the demand for interoperability and compatibility will only increase as IoT networks develop. 
C. Congestion in the Network and Scalability 
Scalability and network congestion are additional issues that IoT networks must deal with. The need for 
bandwidth and other network resources increases along with the number of devices connected to the network. 
This may cause network congestion, which may have an effect on how well IoT applications work. Scaling the 
network infrastructure to meet the rising demand might be difficult as the number of IoT devices keeps 
increasing. 
D. Battery Life and Power Use 
For IoT networks, power consumption and battery life are major obstacles. Many Internet of Things (IoT) 
devices run on batteries and can be found in far-off or challenging-to-reach places. This makes it difficult to 
change batteries or recharge devices, which may affect the network's overall dependability and performance. In 
addition, power consumption will become a more pressing issue as the number of IoT devices increases.IoT 
networks provide many advantages, but there are also a number of problems and restrictions that need to be 
worked around. IoT networks may realize their full potential by creating strong security and privacy measures, 
addressing interoperability and compatibility challenges, managing network congestion, and minimizing power 
usage. 
VII. 
Conclusion 
We have covered the architecture, applications, and anticipated future developments of IoT networks in this 
paper. We have looked at an IoT network's four-tiered architecture and all of its components, such as sensors, 
gateways, cloud platforms, and apps. We have also discussed the various applications of IoT networks in a 
variety of fields, including healthcare, industry, transportation, and even smart cities.We have also looked into 
the most recent advancements in the Internet of Things (IoT), such as edge computing, 5G networks, AI, and 
blockchain. The usefulness and value of IoT networks may rise as a result of these tendencies.IoT networks 
provide a lot of advantages, but they also have some disadvantages that need to be dealt with. This includes 
problems with energy use, battery life, interoperability, scalability, security, and privacy. It also includes 
problems with network congestion.To fully realize the potential of IoT networks, future research should focus 
on fixing these problems and overcoming these limitations. Managing network congestion, optimizing energy 
use, creating robust security and privacy measures, and resolving interoperability and compatibility issues are a 
few of them.IoT networks, which have the potential to revolutionize numerous industries and raise people's 
living standards everywhere, represent a significant advancement in technology. With further research and 
development, IoT networks will without a doubt play a significant role in determining the direction of 
technology and society. 
References 
[1] Al-Fuqaha, A., Guizani, M., Mohammadi, M., Aledhari, M., & Ayyash, M. (2015). Internet of Things: A 
survey on enabling technologies, protocols, and applications. IEEE Communications Surveys & Tutorials, 
17(4), 2347-2376. 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2074 
 
 
 
Research Article  
[2] Gubbi, J., Buyya, R., Marusic, S., & Palaniswami, M. (2013). Internet of Things (IoT): A vision, 
architectural elements, and future directions. Future Generation Computer Systems, 29(7), 1645-1660. 
[3] Shi, W., Cao, J., Zhang, Q., Li, Y., & Xu, L. (2011). Edge computing: Vision and challenges. IEEE Internet 
of Things Journal, 3(5), 637-646. 
[4] Atzori, L., Iera, A., & Morabito, G. (2010). The internet of things: A survey. Computer Networks, 54(15), 
2787-2805. 
[5] Wang, S., Zhang, Y., & Zhang, Y. (2019). Fog computing: Platform and applications. Journal of Network 
and Computer Applications, 123, 1-18. 
[6] Ray, P. P. (2016). Internet of things for smart agriculture: Technologies, practices and future direction. 
Journal of Ambient Intelligence and Humanized Computing, 7(6), 783-798. 
[7] Amin, R., & Islam, M. R. (2018). Internet of Things (IoT) based wearable technology for health 
monitoring: A review of critical issues and challenges. IEEE Sensors Journal, 18(21), 8550-8563. 
[8] Botta, A., de Donato, W., Persico, V., & Pescapé, A. (2016). Integration of cloud computing and Internet of 
Things: A survey. Future Generation Computer Systems, 56, 684-700. 
[9] He, W., Yan, G., & Da Xu, L. (2014). Developing vehicular data clouds for connected vehicles. IEEE 
Transactions on Emerging Topics in Computing, 2(1), 23-32. 
[10] Hossain, M. S., Muhammad, G., & Alamri, A. (2019). Blockchain-based secure Internet of Things: 
Challenges and solutions. IEEE Internet of Things Journal, 6(5), 8294-8310. 
[11] Li, M., Lu, R., Li, W., & Lin, X. (2018). Secure data sharing in cloud-based Internet of Things via 
attribute-based encryption. IEEE Transactions on Information Forensics and Security, 13(7), 1755-1767. 
[12] Mao, Y., You, I., & Zhang, J. (2012). A survey on security of Internet of Things. International Journal of 
Communication Systems, 25(9), 1101-1111. 
[13] Mohanty, S. P., Prasad, N. R., & Saraju Mohanty, M. (2018). Internet of Things and big data analytics: 
Foundations, challenges, and future directions. Journal of Parallel and Distributed Computing, 129, 1-24. 
[14] Al-Fuqaha, A., Guizani, M., Mohammadi, M., Aledhari, M., & Ayyash, M. (2015). Internet of things: A 
survey on enabling technologies, protocols, and applications. IEEE Communications Surveys & Tutorials, 
17(4), 2347-2376. 
[15] Atzori, L., Iera, A., & Morabito, G. (2010). The Internet of things: A survey. Computer networks, 54(15), 
2787-2805. 
[16] Chen, M., Ma, Y., Song, J., Lai, C. F., & Hu, B. (2018). Blockchain-based secure firmware update for 
embedded devices in an Internet of Things environment. IEEE Transactions on Industrial Informatics, 
14(8), 3690-3700. 
[17] Gubbi, J., Buyya, R., Marusic, S., & Palaniswami, M. (2013). Internet of Things (IoT): A vision, 
architectural elements, and future directions. Future generation computer systems, 29(7), 1645-1660. 
[18] Li, Y., & Lu, R. (2018). Blockchain and Internet of Things (IoT): A survey. IEEE Internet of Things 
Journal, 5(5), 4419-4434. 
[19] Liu, X., Chen, Y., Chen, X., Hu, F., & Zhang, W. (2019). An efficient access control scheme for the Internet 
of Things based on blockchain technology. IEEE Access, 7, 55880-55890. 
[20] Mahmud, R., Hu, J., & Miao, Y. (2018). Blockchain-based decentralized trust management in vehicular 
networks. IEEE Transactions on Vehicular Technology, 67(8), 6745-6758. 
[21] Moosavi, S. R., & Gholami, M. (2019). A comprehensive review on the Internet of Things (IoT) security 
threats and countermeasures. Journal of Ambient Intelligence and Humanized Computing, 10(5), 1663-
1678. 
[22] Ning, H., Zou, W., Wei, Z., & Zhang, L. (2019). An energy-efficient and scalable edge computing 
architecture for internet of things applications. IEEE Transactions on Industrial Informatics, 15(6), 3502-
3512. 
[23] Peng, T., Li, Z., Li, J., Wang, X., & Wang, Y. (2019). Big data analytics in smart healthcare: A review. 
Journal of biomedical informatics, 92, 103139. 
[24] Qu, W., Zhuang, Y., Chen, M., & Wang, H. (2019). Secure and privacy-preserving data aggregation for 
internet of things: A survey. IEEE Internet of Things Journal, 6(4), 6506-6523. 
Turkish Journal of Computer and Mathematics Education  
Vol.11 No.03 (2020), 2067-2075 
DOI: https://doi.org/10.17762/turcomat.v11i3.13604 
 
 
2075 
 
 
 
Research Article  
[25] Rahmani, A. M., Thanigaivelan, N. K., Gia, T. N., Granados, J., Negash, B., & Adel, M. (2019). Smart 
homes for elderly healthcare—Recent advances and research challenges. Journal of Ambient Intelligence 
and Humanized Computing, 10(12), 4515-4536. 
[26] Rawat, P., Singh, A., Chaouchi, H., & Bonnin, J. M. (2014). Wireless sensor networks: A survey on recent 
developments and potential synergies. The Journal of Supercomputing, 68(1), 1-48. 
[27] Shafagh, H., Hithnawi, A., & Duquennoy, S. (2017). Poster: Towards a blockchain-based security 
framework for the Internet of Things. In Proceedings of the 2017 ACM International Conference on 
Embedded Networked Sensor Systems (pp. 437-438). 
[28] Wang, L., Torkamani, M., Al-Fuqaha, A., & Sattar, F. (2018). From machine-to-machine communications 
towards cyber-physical systems. IEEE Access, 6, 42381-42398. 
 


</subsection_point_Point 2>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 3>
Point: The role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability

Papers to support point:

Paper 1:
- APA Citation: Premkumar, S., & Sigappi, A. N. (2022). IoT-enabled edge computing model for smart irrigation system. Journal of Intelligent Systems, 31(4), 632–650. https://doi.org/10.1515/jisys-2022-0046
  Main Objective: To evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation.
  Study Location: Unspecified
  Data Sources: Sensor data, Weather data
  Technologies Used: Machine learning, Fog computing
  Key Findings: The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture. Fog computing can distribute processing and storage across the network, which can improve the efficiency and scalability of automated irrigation management systems.
  Extract 1: None
  Extract 2: None
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the outline point as it directly discusses the role of fog computing in distributing processing and storage across the network, which is a crucial aspect of automated irrigation management systems. The proposed hybrid machine learning approach for predicting soil moisture and managing irrigation is also pertinent to the point.
  Relevance Score: 1.0
  Inline Citation: (Premkumar & Sigappi, 2022)
  Explanation: The study aims to assess the current state of automated irrigation management systems, with a focus on the role of fog computing in distributing processing and storage across the network. The study also proposes a hybrid machine learning approach for predicting soil moisture and managing irrigation based on weather data.

 Full Text: >
Research Article
S. Premkumar* and AN. Sigappi
IoT-enabled edge computing model for smart
irrigation system
https://doi.org/10.1515/jisys-2022-0046
received January 10, 2022; accepted March 16, 2022
Abstract: Precision agriculture is a breakthrough in digital farming technology, which facilitates the appli-
cation of precise and exact amount of input level of water and fertilizer to the crop at the required time for
increasing the yield. Since agriculture relies on direct rainfall than irrigation and the prediction of rainfall
date is easily available from web source, the integration of rainfall prediction with precision agriculture
helps to regulate the water consumption in farms. In this work, an edge computing model is developed for
predicting soil moisture in real time and managing the water usage in accordance with rain prediction. A
soil moisture prediction hybrid algorithm (SMPHA) has been developed that revolves around the decision-
making techniques with live environmental parameters including weather parameters for the prediction of
soil moisture through the impact of precipitation. Numerous algorithms with the combination of regression
+ clustering are estimated, and it is inferred that XGBoost + k-means outperforms other algorithmic com-
binations that is deployed in edge model. This model is used as an intermediary between the end IoT
devices and cloud that results in the saving of computationally intensive processing performed on cloud
servers. The servers located on a local edge network perform the developed algorithmic computations.
Avoiding transmission over the cloud results in signiﬁcant latency, response time, and computation power
savings and therefore increases the eﬃciency of data transfer. The proposed edge computing model is
implemented in Raspberry Pi as an edge, Heroku as cloud, and edge nodes as the combination of Pi with
actuators and sensors. The monitored data from Pi are stored in MongoDB webserver that is controlled by
Web dashboard. Finally, the developed model is implemented in cloud and edge where the edge server
implementation performs better in terms of latency, bandwidth, throughput, response time, and CPU
memory usage.
Keywords: smart irrigation, edge-based irrigation, edge computing, precision agriculture, soil moisture
prediction, irrigation management system, IoT, oﬄoading mechanism
1 Introduction
It is evident that agriculture always has a specialized role in the anthrophonic evolution and has been
serving as an important economic factor for the growth of a country [1]. Around 58% of the population
depend on agriculture as the chief source of livelihood in India. The quality and productivity of agricultural
products have declined over these years as several factors have inﬂuenced the crop productivity both
directly and indirectly. Some major factors that aﬀect the crop production are climatic changes, global
warming, and water scarcity [2]. The agricultural land’s productivity is aﬀected by the direct and indirect

* Corresponding author: S. Premkumar, Department of Computer Science and Engineering, Faculty of Engineering and
Technology, Annamalai University, Chidambaram - 608002, Tamilnadu, India, e-mail: premambal@gmail.com
AN. Sigappi: Department of Computer Science and Engineering, Faculty of Engineering and Technology, Annamalai University,
Chidambaram - 608002, Tamilnadu, India, e-mail: an.sigappi@gmail.com
Journal of Intelligent Systems 2022; 31: 632–650
Open Access. © 2022 S. Premkumar and AN. Sigappi, published by De Gruyter.
This work is licensed under the Creative
Commons Attribution 4.0 International License.
changes in climate [3,4]. The crop growth has been already aﬀected by the changes in climate incurred by
global warming. The nutrition quality of soil, ground water level, sea, and ocean are aﬀected by the
modiﬁcations in average temperature, rainfall, and extreme weather conditions such as hail storms, dust
storms, heatwaves, etc. due to global warming [5,6]. Degradation of soil is primarily created by various
methods including 93.7% by water erosion, 9.5% by wind erosion, 5.9% by salinity and alkalinity, etc.
Further changes in climate would inﬂuence adversely the crop production [7]. Since water is an indispen-
sable requirement for plants and cultivation, the high level of soil is eroded and thereby the fertility is also
declined. Due to the ever-changing climate, water scarcity has become a huge problem. Drought-like
conditions is already formed in several areas and thereby the present and conventional farming practices
are not suitable. New and unique environment preserving techniques are the need of the hour [8].
The conventional approaches in agriculture are enhanced by the advent of several advancements in
technology [9]. These new improved methodologies ensure optimized utilization of resources, accurate
forecast of water needs and environmental parameters, reduction of human intervention, etc. [10]. Conse-
quently, the outcomes of crops in terms of yield and quality are higher with cost-eﬀective methods. One
such booming technology is the Internet of things (IoT) [11].
IoT is the collection of components embedded in the sensor for measuring and transferring data via
network devices as sensed from pumps and tractors to weather stations. Primarily, IoT deals with the
transmission and reception of data related to farms through devices using the Internet for prediction
and providing decisions to the farmers. IoT-based methodologies has brought a changeover in agricultural
patterns and farming approaches [12]. IoT devices can gather information about soil moisture, chemical
properties, dam levels, livestock health, and weather details in real time. The information acquired from IoT
devices facilitates the farmers in tracking farms periodically. Farmers can save time and money by
responding faster to farm conditions. Cloud computing models integrated with on-ﬁeld agricultural sensors
need to be incorporated for tackling the issue of processing huge voluminous data.
One of the major challenges of IoT is the processing of huge datasets in a sequential way. Some of the
key factors that need to be focused on this process are as follows: information about the type and nature of
data, the way of acquiring the data, etc. The preliminary stage comprises acquiring the data and ingesting
the data to the system. Substantial cognizance of data are achieved as the data pass through all the
gateways where it is cleansed and transformed before entering into the system. In the near future, dynamic
prediction of soil moisture and precipitation techniques are to be developed for smart irrigation systems.
Therefore, a system is developed for eﬃcient and optimal utilization of fresh water in irrigation along with
drip irrigation system. It aids in ﬁnding which one of the plants fails to get suﬃcient water. When the water
supply is provided the next day, this delay should not disturb the system. It becomes important for the
farmers to understand the optimal usage of water and fertilizers to bring out sustenance in the agricultural
industry. Therefore, processing must be done for analyzing the data, so that patterns can be analyzed and
planning can be done for the long term, accordingly. Hence, it gives a broad vision in deciding where the
processing is to be done exactly. Therefore, it is obvious that not all data are crucial, and it provides a clear
view of which data need to be stored, discarded, and retained for both long-term and short-term purposes.
Thus, all these challenging issues require to be addressed and that is where storage technologies are
actually highlighted. The poor quality of Internet access in developing nations makes the implementation
quite challenging. An applicable solution to solve this problem is through edge computing where the
essential data could be oﬄoaded from the cloud over the edge of the cloud, and this is the exact point
where the approach of smart sensing with edge computing gets in.
With the purpose of broadening the potential of edge computing and using it in the agriculture domain,
a novel approach using machine learning (ML) methods is proposed for analyzing the data acquired by the
IoT devices deployed at the farm. Here, the data acquired from IoT components undergo preprocessing and
ML models on the edge nodes to analyze and assess the appropriate results for providing the best instruc-
tions for controlling the actuators (e.g., light, pumps at diﬀerent locations) in the farms.
This article presents an automated system, as shown in Figure 1, to predict the soil moisture using the
ﬁeld information acquired from the self-designed sensor node deployed at the ﬁeld and the forecast
information of weather via Internet. A unique algorithm has been developed that revolves around the
IoT-enabled edge computing model for smart irrigation system

633
machine learning techniques for the prediction of soil moisture. Here, many algorithms with the combina-
tion of regression + clustering was estimated, and it is inferred that XGBoost + k-means outperforms other
algorithmic combinations, and therefore, it is deployed for the prediction of soil moisture in the proposed
work. The proposed algorithm makes eﬀective irrigation decisions with optimized usage of water in a more
accurate and reliable manner. The eﬀective decision-making refers to the process of predicting the rainfall,
thereby reducing the water usage in advance by the proposed algorithm in accordance with the predicted
rainy days. Through this automatic decision-making, over watering is avoided by saving the soil. The
server-side software is developed with node-side connectivity using the information for visualization and
decision support features. This proposed algorithm is implemented in edge to prove the eﬃciency of the
edge server handling the automated system better than the cloud control. The performance of the decen-
tralized edge-based architecture has been evaluated for downloading the hybrid algorithm from cloud in
real time execution. The performance can be enhanced by adopting edge computing architecture and
measured with the help of network parameters like latency, bandwidth, and response time. Edge computing
capacity is also estimated using the CPU processor and memory consumption while executing the proposed
algorithm with irrigation scheduling.
2 Related work
In ref. [13], a smart irrigation system not aﬀected by communication disconnection and delay is developed
using edge nodes deployed at the farms. Environmental parameters have an intricate impact on the plant
growth. It becomes necessary for evaluating multiple AI models simultaneously in an actual cultivation
environment for comparing AI models under the same conditions. Due to the working of existing irrigation
systems on the cloud, communication is instable in the concurrent evaluation of AI models. However, the
instability does not induce an edge node in its performance.
The factors such as type of plant, soil, climate, humidity, temperature, and soil moisture need to be
considered for the irrigation system packed with potential smart decisions. The nature and type of plant,
soil, and climate are queried by ontology (branch of metaphysics dealing with the nature of being), whereas
other factors such as temperature, humidity, and soil moisture are sensed by the sensor network. The
trained ML model predicts the watering decisions based on ontology and other factors as mentioned earlier.
Figure 1: Architecture of the proposed system.
634

S. Premkumar and AN. Sigappi
Smart irrigation has three modules: (i) sensor network modules that sense the parameters impacting the water
requirement by using sensors DHT22, light sensor BH1750, and HL-69 hygrometer for sensing the temperature,
soil moisture, light, and humidity in air. (ii) Edge and IoT server’s module to send and receive data through
HTTP requests. (iii) Training module in which KNN is applied on the sample dataset for training and decision-
making regarding the water needs. Based on the input values, the trained model categorizes the input into ﬁve
possible classes: highly not needed, not needed, average, needed, and highly needed [14].
A decentralized smart irrigation approach is proposed for strawberry greenhouses in contrast to con-
ventional cloud-based solutions for keeping the agricultural data at the edge of the network. A full-scale
smart irrigation system in an actual strawberry greenhouse environment is developed after a small-scale
smart irrigation networking prototype system and a reference architecture targeting edge data distribution
for strawberry greenhouse applications are framed. A three-step industrial approach is formed for
designing, implementing, and validating a solution for smart strawberry irrigation in greenhouses and
keeping the corresponding data at the edge of the network at the same time: (i) A small-scale smart
irrigation prototype solution with oﬀ-the-shelf hardware and software equipment is tested and evaluated
on various types of plants for gaining useful insights for deployments on a large scale. (ii) A reference
network architecture is designed for targeting smart irrigation and edge data distribution speciﬁcally for
strawberry greenhouses. (iii) A large-scale system in an actual strawberry greenhouse environment is
developed in Greece, incorporating the proposed reference architecture [15].
Edge computing is proposed for addressing the issues by taking advantage of computing resources in
the edge of the network. The issues such as an edge mobile device make it easier to achieve low end-to-end
latency, high bandwidth, and low jitter to services located on the edge network. An edge can enforce the
privacy policies of its owner prior to the release of the data to the cloud through edge analytics. If a cloud
service becomes unavailable due to network failure, cloud failure, or a denial-of-service attack, a fallback
service on a nearby edge can temporarily mask the failure. Cloud services, partial analysis, and control
functions are extended to the edge nodes from the cloud data center. Edge nodes facilitate the timely
monitoring of sensors in smart farming by the reduced latency and enhanced data transmission. Due to
these factors, edge computing is applied through farming [16,17]. A three-tier open-source software plat-
form we proposed by authors, and the platform enhanced the precision agriculture by introducing edge
computing and fog computing. An network functions virtualization (NFV)-based approach is deployed for
performing the local operational decisions at the edge level for mitigating the inﬂuence of network failures
while using cloud data centers [18]. For control processing in smart farming, a platform enabling cost-
eﬀective sensor/actuator network based on IoT, utilizes edge computing [19,20].
The authors in ref. [21] predicted the soil moisture using a mathematical model that measures the
values given by a sensor matrix on the ground. Due to the huge interval in measurements (10 minutes), the
model presented estimated error by more than 10%. This methodology has incorporated the online
approach by making the sensors to send data every minute to edge devices without time-based interruption.
The authors of ref. [22] applied a combinative approach of using ﬁeld sensor network’s data along with
weather forecast station’s data for the management of optimality in water conditions for the enhanced
growth of grapes. The generated data are forwarded to a web server, which displays graphics without
statistical analysis of such data. The analysis must be performed a posteriori by the user.
The watering mechanism for a plant via IoT methodology is devised by the proposed smart irrigation
model without acquiring any pre-processed data. A prototype application is developed, which gets adapted
to the parameters needed in irrigation after a couple of human-made irrigations. With the usage of various
ML algorithms, several tests are devised for manual and automated irrigations for the performance evalua-
tion. After the evaluation using four diﬀerent ML algorithms such as logistic regression (LR), K-nearest
neighbors (KNN), Gaussian naive Bayes (GNB), and gradient boosting regression trees (GBRT), it is found
that GBRT outperforms other algorithms. To analyze the overall performance, a test bed for the sensor edge,
mobile client, and the decision service on the cloud is established. Two diﬀerent indoor species are selected
as test items for the prototype, namely, Peace lily and Sardinia. The outcomes were quite good, and it is
inferred that the prototype has learned the patterns of irrigation and making decisions automatically with a
high rate of accuracy [23].
IoT-enabled edge computing model for smart irrigation system

635
The authors from ref. [24] adopted the deep learning methodology for detecting the type and the
category of the plant using an automated plant irrigation system. The water necessity of the plant is
determined using the recognition of predeﬁned set of plant images and data set acquired from farm. It
utilizes the database for fetching the irrigation information after the recognition process is completed.
Modeling the training processes are time consuming as voluminous set of images needs to be stored.
The authors in refs [25,26] incorporated ML methods in the irrigation decision support model using a
pre-processed irrigation data set. A model is developed for learning the irrigation needs of any plants
progressively rather than using a readily available dataset. Several ML algorithms are evaluated with their
precision for concluding the irrigation decisions. Manual irrigations are performed two times before making
precise decisions. Due to the dynamicity in model, data processing is done progressively, and it can be
applied to several plants having varying irrigation conditions. There is a need for the learning model that
can be trained by itself using a comparatively lighter learning process using environmental parameters that
do not need larger storage in the system but need higher computation. From the aforementioned survey for
making a precise decision with instant computation locally, edge computing needs to be integrated into the
irrigation system. This article is directed towards presenting a platform that implies IoTs and edge com-
puting in monitoring soil moisture via sensors, data communication between sensors and edge devices, and
an Analytics-as-a-Service cloud. It analyzes the collected data in the form of a density map of soil moisture
for denoting the areas in need of greater or lesser frequency of irrigation. Here, density map does not refer to
the geographical point data by satellite mapping, and it actually denotes the point of dry area and watery
area through soil moisture detection point. This point is averaged among areas of irrigation to be done and
the irrigation process is controlled with prediction of rainfall using the proposed system.
3 The proposed system
The proposed learning model for irrigation is implemented in a prototype IoT system that has four compo-
nents: (i) Edge node layer – This layer consists of sensors, actuator, and two microcontrollers. In this layer,
edge node acquires the sensor data from the surroundings and controls the actuator for actuating water
pumps to start irrigation. (ii) Edge server layer – This layer consists of Raspberry Pi that act as edge server
and capable of multitask processing. Here, edge server controls the edge nodes for sending signal and
receiving data at regular interval of time. It is also connected to the cloud server for receiving developed and
trained machine learning model to be deployed and make irrigation decision for controlling edge nodes.
(iii) Edge service layer – This layer is deployed in the edge server and it is responsible for controlling the
whole system through a developed web dashboard. The dashboard has live feed data, control of edge
nodes, and cloud services access. This service layer also has the control access of the proposed machine
learning model. (iv) Cloud server layer – This layer composed of cloud services and cloud storage where its
role is to train the machine learning model and store the data in database. It sends the trained proposed
model to the edge server for decision-making regarding irrigation scheduling. The comprehensive inter-
connections in the system are shown in Figure 2. The proposed IoT-based smart irrigation system includes
ﬁve major components: ﬁeld deployed module, Web-based interface, Web API weather input, soil moisture
prediction mechanism, and edge communication model.
3.1 Field deployed module
In the ﬁeld requirements, a wireless sensor network of the sensor nodes needs to be deployed as shown in
Figure 3. Here, ﬁeld data collection device accommodates four diﬀerent sensors: Capacitive Soil Moisture
Sensor V2.0, DS18B20 Water Proof Temperature Sensor Probe for soil temperature, ultraviolet (UV) Light
Radiation, DHT11 – Temperature and Humidity Sensor Module, and GYML8511 Analog Output Ultra-Violet
636

S. Premkumar and AN. Sigappi
Light Sensor Module. An Arduino Mega connected to Raspberry Pi 4 Model-B read, the output of these
sensors where the program is developed in Python for the Pi model to fetch the hourly data from sensors
and store the data in MongoDB [27] database. It is then synchronized with the server database using the
developed web service. A Wi-Fi-enabled Arduino controls the water pump connected to a relay switch.
Figure 2: Components of the proposed system.
Figure 3: Real-time prototype of the proposed edge model.
IoT-enabled edge computing model for smart irrigation system

637
For the real time monitoring, a trigger is made for controlling the web service from the responsive web-
based interface. The irrigation decisions are checked periodically by the proposed model performed in the
server. The water pump is actuated, and irrigation process is started only if the server makes any irrigation
decision. A wireless sensor network (WSN) [28] scenario with ZigBee [29] technology can be implemented
for a large farming area in which several sensor nodes can be aﬃxed in the speciﬁed area and every sensor
node possesses sensors similar to a standalone device. Then, the Arduino Mega reads the sensor output
connected to ZigBee for transferring data to Gateway Node for aggregating the received data and storing it
in MongoDB locally and also for transferring the data via web service to the edge server.
3.2 Web-based interface
The proposed framework consists of a web-based application to allow farmers visualize the growing data
and interacting with the garden in real time. In addition, users can also be able to examine and analyze the
historical growing data, if needed, through functionalities such as irrigation control, motor control predic-
tion model deployment, and manual data entry implemented in this web application. Here, Node.js was
chosen for developing the web application [30,31], while MongoDB [27] was utilized as the database system.
Data stored in the database, which is deployed in the cloud, will be used for further data analysis in the
future. The web application’s functions are designed following a software design pattern called model-
view-controller (MVC) as shown in Figure 4. In the frontend, ChartJS is used to represent data through
dynamic charts. The web application is also used as an interface to manage all the physical devices/
actuators in the garden. To deploy the web-server to the cloud, a cloud platform as a service (PaaS), namely,
Heroku, had been utilized. Heroku is a cloud platform that provides platform as a service (PaaS), facilitates
the creation of applications and deploying these online rapidly [32,33]. It also enhances scalability and
functionality by integrating several add-on services. The ﬁeld data are sent to the server by Raspberry Pi
using this web service. This web service manages the network outage/ﬂuctuation during data synchroniza-
tion from the ﬁeld device to the server by taking the help of ﬂag settings at the database level. The interface
facilitates the scheduling of irrigation along with visualizing real time sensors and predicted soil moisture
for upcoming days and precipitation information. By using the denoted threshold value of soil moisture
suggested by agronomists, the irrigation can be scheduled by the user. The system maintains the threshold
value depending on the predicted pattern of soil moisture and precipitation information. The process of
irrigation is initiated automatically and stopped after the speciﬁed threshold value generated from the
proposed algorithm of soil moisture when it is reached.
Figure 4: Web interface for the irrigation system.
638

S. Premkumar and AN. Sigappi
3.3 Web API weather input
The weather prediction data are collected by a web service developed in Python. The forecast data such as
humidity, temperature, ultra violet index, precipitation, and cloudiness of web forecasting portals like
Open Weather API are aggregated by the developed web service [34]. These portals provide the forecasted
information in HTML, XML, or JSON format. The predicted data with JSON format are read by the developed
web and stored in database at the edge server, which is concerned in the prediction algorithm. Also, these
data are utilized as testing dataset in the ML model for predicting the soil moisture.
3.4 Soil moisture prediction mechanism
An algorithm for predicting the soil moisture based on data derived from ﬁeld sensors and weather fore-
casting using the combination of supervised and unsupervised machine learning techniques has been
developed underpinned by regression algorithms and k-means clustering for estimating the diﬀerence/
change in soil moisture owing to weather conditions. Many regression algorithms are compared against
each other and infusing each of them with k-means to check the preciseness in mean square error (MSE),
R2, accuracy and mean absolute percentage error (MAPE) for prediction of soil moisture of upcoming days
with the help of sensor data and weather forecasting days. The information about soil moisture for the
upcoming days and suggestions for irrigation in accordance with the prescribed levels of soil moisture and
predicted precipitation values, thereby saving energy and water, is presented by the algorithm. The infor-
mation generated from the device and the predicted values from the algorithm soil moisture prediction
hybrid algorithm (SMPHA) are stored in the server.
3.5 Edge communication model
The communication protocols in the proposed framework are ﬂexible and transparent in nature for
accepting both wired and wireless methodologies. For the maximum utilization of potentiality in edge
computing components, the communication among various components in the edge-IoT system requires
intense probing by using the versatility among the devices in network edges. For transferring the data
gathered from pivot sensors, a communication technology such as Zigbee [35] is needed for the irrigation
systems. Therefore, the communication component in the proposed work is classiﬁed into three main areas
as shown in Figure 5. The Message Query Telemetry Transport (MQTT) protocol is used for the
Figure 5: Proposed edge communication model.
IoT-enabled edge computing model for smart irrigation system

639
communication in the proposed system. The analysis in ref. [36] presented seven IoT messaging protocols
(MQTT, CoAP, XMPP, AMQP, DDS, REST-HTTP, and WebSocket) as communication protocols that play a
major role in smart farming. The authors have concluded that MQTT proved to be the most secure protocol
after probing all the protocols with respect to latency, energy and bandwidth requirements, throughput,
reliability, and security. Moreover, MQTT is secure in both end-to-end architecture and gateway server
architecture. In an MQTT setup, a MQTT server termed as MQTT broker executes on the IoT solution [37].
Under a common identiﬁer, a “publisher” and a “subscriber” link among themselves to this broker. In the
IoT solution, publishers and subscribers are the IoT devices and IoT hubs or control devices, respectively.
When the publishers have new data for recording, the data are published to the broker. The broker then
ﬂags that it has new publisher data, and the corresponding data are read by the subscriber. Then, the
subscriber analyzes the data and reacts accordingly.
The ﬁrst level accomplishes with connecting the end users to system with the help of mobile or web-
based applications through the Internet. The next level (cloud computing server) deals with the connection
of web server and MQTT broker for directing the user requests and other components at the edge landscape
or from the farms to the right cloud-based services like displaying the real time status of the farm for the
users, triggering a new deployment of the updated ML model to the corresponding edge node. The third
level (farming area) is directed toward the deployment of sensors and IoT devices (actuators) for commu-
nicating with other components in the entire system.
4 Deployment of soil moisture prediction hybrid algorithm
The watering mechanism of the plant has diﬀerent approaches in the proposed model. Primarily, the system
is trained with manual irrigations datasets during the process of learning with respect to suggestions
deﬁned by agronomists. The model is trained to learn the needs of irrigation in the ﬁrst level of deployment
in cloud without the inclusion of pre-processed data. After acquiring the required data and training, the
proposed system is initiated to grasp the plant’s watering needs by undergoing plenty of manual irrigations.
Thereafter, manual irrigation is not required and the system makes automated decisions in watering using
the gathered data and the application of ML methods. The proposed model then decides the irrigation
strategies automatically using ML methods without the need including collected datasets in the automatic
irrigation process. The proposed model can be improved through the learning process when the number of
precise irrigation inputs is provided to the model at each stage of training.
The decision-making procedure is developed with two modules for irrigation strategies according to the
soil moisture prediction for upcoming days. The ﬁrst module deals with training the model in cloud with
manual irrigation datasets through steps such as data collection, data preprocessing, training, and model
development. The system acquires values of air temperature (TH), soil temperature (SMT), soil moisture
(SM), humidity (HU), and ultraviolet rays (UV) periodically from the physical environment in the data
collection stage, which is essentially required for arriving at the watering decisions. Also, the time of
performing the manual irrigation is recorded in the database. These data are timestamped and stored in
as datasets to aid in making decisions for knowing the time of irrigation. In the next step of pre-processing,
inconsistencies are eliminated and outliers caused by sensor errors are detected from the irrigation dataset,
thereby helping in the removal of broken data. The training stage involves the application of supervised
machine learning (ML) algorithms. Here the regression algorithms such as support vector regression (SVR),
multiple linear regression (MLR), lasso regression (LR), decision tree regressor (DTR), random forest
regressor (RF), and XG-boost regressor (XB) techniques are used for the deployment. The regression algo-
rithms are trained using the collected datasets. Finally, through training, regression models are created,
namely, SVR model, MLR model, LR model, DTR model, RF model, and XB model that are been combined
with the second module for decision-making.
The second module caters to the prediction of irrigation for upcoming days by infusing the weather data
as an input to the regression trained models. The live datasets from the weather API for future prediction of
640

S. Premkumar and AN. Sigappi
soil moisture variable are used. The dependent variables from weather forecast data like temperature (TH),
humidity (HU), ultraviolet (UV), and precipitation (PC) are tested in the aforementioned model for soil
moisture prediction. Then, the regression trained model is evaluated and deployed using the weather
testing data for the prediction of soil moisture in accordance with the precipitation. After the prediction
of data for the upcoming days, these developed regression models are combined with unsupervised ML
algorithm named k-means clustering for estimating the changes incurred in soil moisture prediction due to
the impact of weather conditions. Further, each regression models with k-means algorithm are evaluated
for performances in terms of irrigation decision-making process as shown in Table 1. The combined algo-
rithms are estimated through MAPE, MSE, R2, execution speed, power consumption, and accuracy. The
estimation and computation of these parameters are detailed by the authors in ref. [38].
XGBoost + k-means (XB+k-means) approach provides more accuracy with less MSE comparatively and
also the R2 with 98% in soil moisture prediction using combined approach is given in Table 1. It is evident
that the proposed combination performs better when compared to other regression + k-means-based
approaches. XB + k-means-based hybrid machine learning algorithm is applied in irrigation planning
module on account of aforementioned performance metrices of ML. Although it performs moderately in
terms of execution time and power usage, it is selected for the deployment in edge computing as it has
better performed in terms of accuracy, R2, MSE, and MAPE metrices. It is observed that the prediction of soil
moisture for the upcoming days from the proposed algorithm (XB+k-means) is nearer to the actual value as
shown in Table 2, and hence, XB+k-means is selected for the implementation of SMPHA in edge-based
irrigation scheduling.
4.1 Hardware setup
IoT system is crucial to handle, collect, and transfer the data to the computing nodes at the edge or in the
cloud. These devices are connected to the edge nodes through wireless communication protocols like
ZigBee. It is used in reducing the latency and loss of data. An Arduino micro-control unit controls the
combined IoT sensors and actuators at the same part of a ﬁeld into a cluster, each connected to a Raspberry
Table 2: Comparison of predicted SM value with actual SM value
Date
Average SM value
from sensor
Average predicted SM
value (XB+k-means)
28-09-2021
35.23
34.04
29-09-2021
36.41
37.20
30-09-2021
31.57
30.46
01-10-2021
34.66
33.15
02-10-2021
36.73
37.12
03-10-2021
32.88
33.01
Table 1: Comparison of performance metrices obtained from various ML algorithms
Algorithms used
Accuracy
R2
MSE
MAPE (%)
Execution time
Power (J)
SVR + k-means
0.96
0.96
0.25
1.98
0.06078
1164.85
MLR + k-means
0.94
0.88
0.31
2.15
0.02075
429.30
LR + k-means
0.95
0.94
0.32
2.23
0.02482
351.35
DTR + k-means
0.93
0.95
0.29
1.62
0.15687
914.70
RF + k-means
0.95
0.91
0.27
1.57
0.16745
1475.13
XB + k-means
0.97
0.98
0.20
1.08
0.03547
537.87
IoT-enabled edge computing model for smart irrigation system

641
Pi that acts as an edge node in processing the gathered data and controlling the actuators. For example,
Figure 2 shows an edge architecture with a Raspberry Pi connected to two components: Arduino Uno and
Arduino Mega units via ZigBee connection. The ﬁrst Arduino Mega node is responsible for collecting data
from sensors and the second one is for controlling the actuators in the ﬁeld. Depending on the sensor type
with collecting Arduino unit, the sensors are connected via analog or digital PWM pins while controlling
Arduino uno joins with actuators in the ﬁeld and controls (turn on/oﬀ) them in accordance with upper
layers (from the edge web server). The trained (cloud) and deployed ML model in edge nodes provides the
necessary instructions to the edge nodes.
4.2 Web layer setup
The deployment of web server assists the user in planning and managing the irrigation system. It visualizes
the crucial information of factors like temperature of air and soil, UV, humidity, and soil moisture in live
irrigation with real time updates in the form of various charts. In accordance with the selected ﬁeld, the web
application redirects the user to the ﬁeld’s dashboard as shown in Figure 4. The dashboard consists of ﬁeld
parameters as well as control signals for activating all the physical devices/actuators at the garden layer.
These signals are denoted as switch buttons, and each switch controls (turn on/oﬀ) a particular kind of
actuator (for instance, water pump to start and stop the irrigation). The user interface facilitates remote
controlling of the ﬁeld by just clicking on the buttons as shown in Figure 4.
4.3 Edge layer setup
The edge node acts as a computing center where incoming data are analyzed and fed as the input vector to
the ML model for processing and to return the control signals for activating or deactivating the actuators
placed at the farm. Edge node processes the physical data (real time) at every end device such as the
collected and processed data via the Raspberry Pi nodes presented in the proposed scheme. The prediction
model is designed using TensorFlow API and trained, tested on Google Colab in this work. Amazon Web
Service (AWS) oﬀers a library named Boto3 having many APIs to upload and download objects. After the
development of model, it is transferred to Amazon S3, a service provided by AWS. The edge node utilizes the
trained model from S3 for analyzing the sensed data acquired from garden’s sensors. The decision is
delivered based on real time data analysis at the edge node and transmitted to Arduino nodes in the ﬁelds
landscape immediately for controlling the actuators. In another ﬂow, the data collected from sensors are
ﬁltered so as to keep only the modiﬁed data at the edge node before being sent back for mitigating the
communication cost to the database in the cloud. These data are used in the updation of the ML model to
enhance its eﬃciency.
4.4 Analytics setup
The main goal of this experiment lies in gathering the various physical parameters of a farming land via
sensors and utilizing the fetched data along with weather forecast information for developing an algorithm
using hybrid machine learning approach to infuse higher accuracy in predicting the soil moisture for the
upcoming days. As discussed in Section 4, for the proper planning and provisioning of optimal irrigation,
the algorithm provides a predictable estimate of soil moisture with the assistance of various statistical
measures as shown in Table 1. The measures are adopted for estimating the appropriateness and error rate
of the proposed algorithm. It is inferred from the experiment that, optimal irrigation is feasible using a good
642

S. Premkumar and AN. Sigappi
estimation (close to the actual value) of the soil moisture (Table 2), with the support of ﬁeld data and
forecast information, thereby utilizing the natural rain eﬃciently.
The SMPHA ML model is interdependent on dynamic changes in weather environment where the
models deployed on edge nodes need to change the controls accordingly after model gets trained con-
tinuously. For the process of retraining, the trained model needs to be updated. The parameters such as TM,
HU, ST, UV, SM about grown plants are logged for the training purpose, and these generated datasets are
recorded from the already developed manual mode system [39]. The growth of the Indian Mundu Chilli [40]
is taken for the observation from the ﬁrst stage to the last grown stage for 95 days. While retraining the
model, the training is carried in cloud without causing eﬀect to the functionalities at edge nodes. A signal is
transferred to the corresponding edge server for triggering the task of updating the SMPHA model from the
web server. At that time, the newly trained model is downloaded to replace the existing one at the con-
sidering edge server. From then, the ML model at the edge server is called to be updated with the real-world
knowledge and is ready for its garden controlling tasks (to apply in the next farming season).
4.5 Work ﬂow
The ﬂowchart in Figure 6 depicts the working of the proposed system based on the decision support system
that is beneﬁcial for irrigation needed for the growth of vegetables. The chilli plant is grown in a growbag
attached with sensors and Pi as shown in Figure 3 and monitored for 95 days of data collection. To bring out
optimality in the irrigation system, features relating to climate, soil, crop, and ﬁeld infrastructure are to be
considered. To provide several recommendations in the production of vegetables, decision support systems
(DSSs) are designed, which process voluminous information [39]. This proposed work is the extension of
soil moisture diﬀerences (SMD) model [41] developed for soil moisture prediction. The threshold values of
soil moisture are used in the SMD model where the system schedules the irrigation date based on the
predicted soil moisture and weather forecast (precipitation) information automatically using SVR+ k-means
modeling. Therefore, in the extension of the aforementioned work, further more number of sensors are used
to log soil moisture value, which is averaged in the proposed model. This model is developed in two
divisions of ﬂowchart as shown in Figure 7, where both are interconnected. It is observed that the prediction
of XB + k-mean approach provides better results as presented in Table 2.
The ﬁrst phase of the ﬂowchart describes the hybrid algorithm for the soil moisture prediction (SMPHA)
using the combination of XB + k-means algorithm. During the data collection step, the sensor data for the
parameters, namely, TM, HU, ST, UV, and SM, are collected. During preprocessing, null values and outliers
are removed and the preprocessed data are used to train the XG-Boost model. The developed model is then
trained with variables of live weather features (TM, HU, UV, PC) obtained from Weather API for the
prediction of SM data. These data are given as input to k-means clustering algorithm to predict the soil
moisture, which is deﬁned as SMPHA value to be infused in the next phase of the ﬂowchart. The second
phase of the ﬂowchart deﬁnes the automatic irrigation planning setup. The setup starts obtaining the soil
moisture maximum (SMMax) and soil moisture minimum (SMMin) values in the dashboard for setting the
maximum and minimum level of soil moisture. Then, the current soil moisture (CuSM) is sensed and
compared against the threshold SMMin. If the resulting value is less than SMMin, the process proceeds
with SMPHA. On the contrary, it stops the irrigation process by sending 0 to the relay. In SMPHA, the
nearest precipitation date is selected and it is assigned to the predicted soil moisture (PSM). The SMMax is
decided by ﬁnding the minimum of (PSM + SMMin, SMMax), and the predicted SMMax is further checked
against CuSM with a condition if SMMax is greater the CuSM then it sends 1 to the relay as a signal to start
irrigation. If the condition fails, then it sends 0 to stop irrigation. The process of automatic irrigation ends
by forecasting the irrigation schedule in accordance with the live weather parameters.
IoT-enabled edge computing model for smart irrigation system

643
5 Experimental setup and evaluation
The test bed is developed and deployed, and the data are collected for the analysis in irrigation manage-
ment. Here, Heroku cloud platform is used to deploy the cloud web server. The same cloud is also installed
at a local edge that is at two Raspberry Pi units equipped with Wi-Fi 802.11n connections to denote the edge
nodes. JMeter application is used to get sequential accesses to the web page from various users for eval-
uating the network parameters. The speciﬁcation of these servers is given in Tables 3 and 4.
We evaluated the performance of the proposed IoT-based smart farm on two diﬀerent platforms,
namely, in the cloud and on the local computer to show the feasibility and the beneﬁt of the edge com-
puting scheme. Further many parameters are considered for evaluation and discussed in the next section to
show that edge deployment is better than cloud.
Figure 6: Flow chart of the proposed edge model.
644

S. Premkumar and AN. Sigappi
5.1 Evaluation
A hybrid machine learning methodology is used in evaluating the ﬁrst stage of the proposed model. The
predicted value of the soil moisture is better in terms of their accuracy and error rate. From the comparison
of the other ML algorithms as shown in Table 2, XB + k-means performs better and taken further to be
deployed in edge and cloud to check its eﬃciency with each other. Therefore, for analyzing the eﬃciency of
the edge server in accordance with the proposed hybrid algorithm SMPHA is evaluated in terms of the time
taken to train the ML model in edge and cloud. In this experiment Raspberry Pi is used to train the SMPHA
model with 196,400 rows, that is, input data sample size and takes around 1,710,000 ms (approximately
28.5 min). The same model when it is trained in Google Colab cloud environment, it takes 204,000 ms
(approximately 3.4 min) as depicted in Table 5. The main purpose is to run the trained model on edge not to
train the model at edge. So due to the lack of computing capability at the edge, it takes more time to train
the model, but it can be ignored as it does not aﬀect the purpose of the proposed model. Here, edge is
introduced to obtain the task of computing from the cloud (i.e., oﬄoading the task) by making the system
more edge-oriented deployment. It can be accomplished rapidly as it requires only 14 s to download a
trained SMPHA model from the cloud to the edge node with a size of 3,101 kb as given in Table 5. The time to
Figure 7: Average response time with 10 test scenarios.
Table 3: Conﬁguration of raspberry Pi
CPU
Broadcom BCM2711, Quad core Cortex-A72 (ARM v8) 64-bit SoC @ 1.5 GHz
RAM
8 GB LPDDR4-3200 SDRAM
Network
2.4 GHz and 5.0 GHz IEEE 802.11ac wireless, Bluetooth 5.0, BLE, Gigabit Ethernet
Pinboard
8 GB LPDDR4-3200 SDRAM
Operating system, language
Raspbian , Python 3
Table 4: Conﬁguration of Heroku cloud
Country
United states
Service
Amazon web service S3
Processor
2.4 GHz Intel Xeon E5-2676 v3 Processor
CPU Power
8 GB
Virtual CPUs
3–5
IoT-enabled edge computing model for smart irrigation system

645
download varies according to the size of the trained model. So, from this process it can be inferred that
downloading the trained model saves time when compared to training the model at the edge. Through this
in real time, deployment of the trained SMPHA model in edge is better compared to deployment in cloud
services. Furthermore, network parameters like latency, throughput, bandwidth, and response time are
adopted to measure the performance improvements in edge computing.
The performance metrices taken into account are latency, bandwidth, and response time [42]. The
latency of an application is the product of two factors: computing latency and transmission latency. The
time spent on data processing and transmission between end devices to cloud servers is termed as com-
puting latency and transmission latency, respectively. The computational capacity of the system decides
the computing latency as the network servers possess a considerable amount of capacity to make the data
processing faster, whereas the sensors come with limited computing capacity. The latency in transmission
is increased by the end devices and cloud servers. Bandwidth: As large number of sensors are deployed in
IoT, data generated would be huge that consumes an intense range of bandwidth and leads to several
problems such as delay in transmission and loss of packets. It becomes unacceptable for the data to be
transferred directly to cloud servers without applying compression. Therefore, data preprocessing and
aggregation are needed for IoT gateways before redirecting them to remote cloud servers. Then, the issue
to be confronted is to control the traﬃc ﬂow by migrating data processing and aggregation tasks optimally
to decrease the bandwidth needs of the end users while maintaining the data quality. Response time: The
total response time is calculated by adding up transmission and processing time. The local deployment of
the proposed model for controlling IoT-based irrigation are deployed on two modes: (i) Cloud mode: The
developed SMPHA model is implemented in the cloud communicating with IoT sensors nodes directly to
manage the irrigation process. The data are stored and processed at the cloud server itself where it uses
Heroku platform. (ii) Edge mode – Raspberry Pi is deployed as an edge server that involves in processing of
the SMPHA model controlling the IoT sensor nodes. Here, the data are stored and processed locally within
the edge servers. This SMPHA model from both the edge and cloud does the job of controlling the actuators
to initiate and quit the working of water ﬂow motors. Through this deployment in both the environments,
performance of edge server and cloud server can be checked in terms of latency, throughput, bandwidth,
and response time is shown in aforementioned graphs in Figures 6, 8, and 9. This performance metrices is
not feasible to calculate while deploying in real time, so the aforementioned scenarios of two modes are
virtually created by generating many request and response threads between the servers. This sampling,
load test, and distributed testing are conducted through JMeter application [43] and also veriﬁed with
Wireshark [44] in cloud servers. The test scenario is created here by data of sending and receiving sampling
data between cloud to IoT sensors and between Edge to IoT sensors. The sampling data considered in this
work refer to the approximate number of requests generated by Arduino to cloud and Arduino to Raspberry
Pi that are calculated in real time. The test scenario is divided into 10 days of sampling data collected for
each day. The evaluation results are depicted for latency and response times in 10 days perspective. In
latency parameter, edge service has decreased by an average of 77.85% time compared to the with cloud. In
the same manner, the response time of edge service is also decreased by 74.09% time compared to cloud
service. In throughput calculation, sampling data are calculated for an hourly basis for the 10 hours data in
a day. From the hourly comparisons of throughput value, edge outperforms with 67.17% high Mbps usage.
Through this analysis as shown in Table 6, it is evident that the proposed edge computing methodology
deployed in Raspberry Pi or in local computers outperforms the cloud-oriented approach.
Table 5: Comparison of model training time
Edge
Cloud
Model training time
28.4 min
3.4 min
Downloading time
Not applicable
14 s
646

S. Premkumar and AN. Sigappi
Finally, to illustrate the eﬃciency of resource management in edge computing, CPU and memory
utilization are considered for the analysis as both factors rely on the service execution model and the
computational needs of the services being ﬁred from oﬀ-loaders. Figure 10 depicts the utilization of CPU
and RAM on the Raspberry Pi acting as an edge node in two cases: with and without the deployment of
SMPHA model on it. As shown in Figure 10, the SMPHA model aﬀects the CPU of the Raspberry Pi node
signiﬁcantly as it consumed around 41.2% of the CPU compared to only 3.5% when it does not host the
Figure 8: Average latency with 10 test scenarios.
Figure 9: Average throughput value with 10 h test scenarios.
Table 6: Performance metrices for cloud and edge services
Performance metrices
Cloud service
Edge service
Throughput (Mbps)
0.04944
0.08265
Latency (ms)
1415.8
313.6
Response time (ms)
1519.6
393.8
Bandwidth (bps)
86
1,365
IoT-enabled edge computing model for smart irrigation system

647
SMPHA model. However, the memory (RAM) utilization in both the cases (with and without deployment of
an SMPHA model) is nearly the same which is around 31%. Comparatively RAM utilization does not have
much diﬀerence in with and without SMPHA. It is worthwhile to note that, the CPU utilization is still much
lower than the 50% of total CPU capacity in Raspberry Pi. Therefore, it becomes feasible for adopting edge
server implementation in the proposed irrigation system.
6 Conclusion
This article proposed a novel approach to edge-based irrigation system to facilitate decision-making on
watering the plants on scheduled time. The proposed approach applying IoT with an edge computing
framework enables the farming system to adapt to the changes in environmental conditions automatically
and eﬃciently. The process of automatic irrigation regulates irrigation according to the live weather para-
meters for forecasting the irrigation process. Soil moisture prediction was performed using major regression
algorithms that are again combined with k-means clustering for estimating the changes incurred in soil
moisture prediction. These techniques were compared through metrics such as MAPE, MSE, speed, and
power consumption from which XB + k-means was found to perform better. The XB + k-means algorithm
was further used for the implementation of decision mechanism on the developed edge computing model.
The proposed edge model saves the data communication cost and reduces the response time of IoT services.
It can be deployed on existing devices on the network edges serving as edge nodes, thereby reducing the
overall implementation cost of a large-scale IoT system. The edge-based approach was found to perform
better than the cloud-based approach in terms of response time, latency, throughput, and bandwidth
usage. Finally, the edge model was analyzed through CPU and memory usage while running with and
without the algorithm. In both cases, the memory utilization is almost lower to total available resource of
the edge device. From this, edge device can allocate its remaining resource for other computing services,
which increases the eﬃciency of edge computing device. The number of end edge nodes can be increased
according to the ﬁeld area and then to check the potency of the system.
Conﬂict of interest: The authors declare no conﬂict of interest.
Data availability statement: All data that support the ﬁndings of this study are included within the article.
Figure 10: CPU and memory utilization with and without SMPHA.
648

S. Premkumar and AN. Sigappi
References
[1]
India: Issues and Priorities for Agriculture, The World Bank, May 17, 2012. https://www.worldbank.org/en/news/feature/
2012/05/17/india-agriculture-issues-priorities.
[2]
India at a glance in Agriculture, FAO in India. https://www.fao.org/india/fao-in-india/india-at-a-glance/en/.
[3]
Cavicchioli R, Ripple WJ, Timmis KN, Azam F, Bakken LR, Baylis M, et al. Scientists’ warning to humanity: Microorganisms
and climate change. Nature Rev Microbiol. 2019;17(9):569–86. doi: 10.1038/s41579-019-0222-5.
[4]
Huong NTL, Bo YS, Fahad S. Economic impact of climate change on agriculture using Ricardian approach: A case of
Northwest Vietnam. J Saudi Society Agricult Sci. 2019;18(4):449–457. doi: 10.1016/j.jssas.2018.02.006.
[5]
Fagodiya RK, Pathak H, Bhatia A, Jain N, Kumar A, Malyan SK. Global warming impacts of nitrogen use in agriculture: An
assessment for India since 1960. Carbon Management. 2020;11(3):291–301. doi: 10.1080/17583004.2020.1752061.
[6]
Sarkar S, Chatterjee S, Misra S. Assessment of the suitability of fog computing in the context of internet of things. IEEE
Trans Cloud Comput. 2018;6(1):46–59. doi: 10.1109/TCC.2015.2485206.
[7]
Porter JR, Xie L, Challinor AJ, Cochrane K, Howden SM, Iqbal MM, et al. Food security and food production systems. In: Field
CB, Barros VR, Dokken DJ, Mach KJ, Mastrandrea MD, Bilir TE, et al., editors. Climate Change 2014: Impacts, Adaptation,
and Vulnerability. Part A: Global and Sectoral Aspects. Contribution of Working Group II to the Fifth Assessment Report of
the Intergovernmental Panel on Climate Change Cambridge, United Kingdom: Cambridge University Press and New York,
NY, USA; 2014. p. 485–533.
[8]
Lal R. Adaptation and mitigation of climate change by improving agriculture in India. In: S. SherazMahdi (Ed.), Climate
Change and Agriculture in India: Impact and Adaptation. Cham: Springer International Publishing; 2019. p. 217–27.
[9]
Saravanan K, Julie G, Robinson H. (Eds.), Handbook of research on implementation and deployment of IoT projects in
smart cities. Hershey: IGI global, 2019.
[10] Baylis A. Advances in precision farming technologies for crop protection. Outlooks Pest Manag. 2017;28(4):158–61.
[11]
Mulla D, Khosla R. Historical evolution and recent advances in precision farming. Soil-Speciﬁc Farming Precision
Agriculture. Boca Raton: CRC Press; 2015.
[12] Dutta L, and Basu TK. Extraction and optimization of leaves images of mango tree and classiﬁcation using ANN. IJRAET
2013;1(3):46–51.
[13] Kawai T, Mineno H. Evaluation environment using edge computing for artiﬁcial intelligence-based irrigation system. 2020
16th International Conference on Mobility, Sensing and Networking (MSN). Tokyo, Japan: IEEE; 2020. p. 214–9.
[14] Munir MS, Bajwa IS, Ashraf A, Anwar W, Rashid R. Intelligent and smart irrigation system using edge computing and IoT.
Complexity. 2021;2021:1–16.
[15] Angelopoulos CM, Filios G, Nikoletseas S, Raptis TP. Keeping data at the edge of smart irrigation networks: A case study in
strawberry greenhouses. Comput Netw. 2020;167:107039.
[16] Satyanarayanan M. The emergence of edge computing. Computer. 2017;50(1):30–9.
[17] Shi W, Dustdar S. The promise of edge computing. Computer. 2016;49(5):78–81.
[18] Ramirez Izolan PL, Diniz Rossi F, Hohemberger R, Konzen MP, da Cunha Rodrigues G, Saquette LR, et al. Low-cost fog
computing platform for soil moisture management. In: 2020 International Conference on Information Networking (ICOIN).
Barcelona, Spain: IEEE; 2020. p. 499–504.
[19] Ferrandez-Pastor F, Garcia-Chamizo, J, Nieto-Hidalgo, M, Mora-Pascual, J, Mora-Martínez, J. Developing ubiquitous sensor
network platform using internet of things: application in precision agriculture. Sensors. 2016;16(7):1141.
[20] Xu X, Liu X, Xu Z, Dai F, Zhang X, Qi L. Trust-oriented IoT service placement for smart cities in edge computing. IEEE Internet
Things J. 2020;7(5):4084–91.
[21] Wu X, Liu M. In-situ soil moisture sensing: Measurement scheduling and estimation using compressive sensing. In: 2012
ACM/IEEE 11th International Conference on Information Processing in Sensor Networks (IPSN). Beijing, China: IEEE; 2012.
p. 1–11.
[22] Kameoka T, Nishioka K, Motonaga Y, Kimura Y, Hashimoto A, Watanabe N. Smart sensing in a Vineyard for advanced
viticultural management. In: Proceedings of the 2014 International Workshop on Web Intelligence and Smart Sensing.
Saint Etienne France; 2014. p. 1–4.
[23] Cagri Serdaroglu K, Onel C, Baydere S. IoT-based smart plant irrigation system with enhanced learning. In: 2020 IEEE
Computing, Communications and IoT Applications (ComComAp.) Beijing, China: IEEE; 2020. p. 1–6.
[24] Kwok J, Sun Y. A smart IoT-based irrigation system with automated plant recognition using deep learning. In: Proceedings
of the 10th International Conference on Computer Modeling and Simulation - ICCMS2018. Sydney, Australia: ACM Press;
2018. p. 87–91.
[25] Goldstein A, Fink L, Meitin A, Bohadana S, Lutenberg O, Ravid G. Applying machine learning on sensor data for irrigation
recommendations: Revealing the agronomist’s tacit knowledge. Precision Agricult. 2018;19(3):421–44.
[26] Vij A, Vijendra S, Jain A, Bajaj S, Bassi A, Sharma A. IoT and machine learning approaches for automation of farm irrigation
system. Proc Comput Sci. 2020;167:1250–7.
[27] Krishnan H, Scholar R. MongoDB – a comparison with NoSQL databases. Int J Scientiﬁc Eng Res. 2016;7(5):1035–7.
IoT-enabled edge computing model for smart irrigation system

649
[28] Ojha T, Misra S, Raghuwanshi NS. Wireless sensor networks for agriculture: The state-of-the-art in practice and future
challenges. Comput Electr Agricult. 2015;118:66–84.
[29] Gutierrez J, Villa-Medina JF, Nieto-Garibay A, Porta-Gandara MA. Automated irrigation system using a wireless sensor
network and GPRS module. IEEE Trans Instrument Measurement. 2014;63(1):166–76.
[30] Chanthakit S, Keeratiwintakorn P, Rattanapoka C. An IoT system design with real time stream processing and data ﬂow
integration. In: 2019 Research, Invention, and Innovation Congress (RI2C.) Bangkok, Thailand: IEEE; 2019. p. 1–5.
[31] Lv H, Wang S. Design and application of IoT microservices based on Seneca. USA: DEStech Transactions on Computer
Science and Engineering, (icte.). 2016.
[32] Lee B-H, Dewi EK, Wajdi MF. Data security in cloud computing using AES under HEROKU cloud. In: 2018 27th Wireless and
Optical Communication Conference (WOCC). Hualien: IEEE; 2018. p. 1–5.
[33] Lopez Pena MA, Munoz Fernandez I. SAT-IoT: An architectural model for a high-performance fog/edge/cloud IoT platform.
In: 2019 IEEE 5th world forum on internet of things (WF-IoT.) Limerick, Ireland: IEEE; 2019. p. 633–8.
[34] Weather API. Retrieved from https://openweathermap.org/api.
[35] Drew Gislason. Zigbee wireless networking, 1st ed. Newnes, London: Elsevier Publisher; 2008.
[36] Tanabe K, Tanabe Y, Hagiya M. Model-based testing for MQTT applications. In: Virvou M, Nakagawa H, Jain LC. (Eds.),
Knowledge-Based Software Engineering: 2020. Cham: Springer International Publishing; 2020. p. 47–59.
[37] Babun L, Denney K, Celik ZB, McDaniel P, Uluagac AS. A survey on IoT platforms: Communication, security, and privacy
perspectives. Comput Netw. 2021;192:108040.
[38] Rastogi K, Lohani D. Edge computing-based internet of things framework for indoor occupancy estimation. Int J Ambient
Comput Intell. 2020;11(4):16–37.
[39] Premkumar S, Sigappi AN. Functional framework for edge-based agricultural system. In: AI, Edge and IoT-based Smart
Agriculture, 1st ed. USA: Academic Press, Elsevier; 2021. p. 71–100.
[40] Phani Kumar J, Paramaguru P, Arumugam T, Manikanda Boopathi N, Venkatesan K. Genetic divergence among Ramnad
mundu chilli (Capsicum annuum L.) genotypes for yield and quality. Electr J Plant Breeding. 2021;12(1):228–34.
[41] Goap A, Sharma D, Shukla AK, Rama Krishna C. An IoT-based smart irrigation management system using Machine learning
and open source technologies. Comput Electronic Agricult. 2018;155:41–9.
[42] Aslanpour MS, Gill SS, Toosi AN. Performance evaluation metrics for cloud, fog and edge computing: A review, taxonomy,
benchmarks and standards for future research. Internet Things. 2020;12:100273.
[43] Sunardi A, Suharjito MVC architecture: a comparative study between Laravel framework and slim framework in freelancer
project monitoring system web based. Proc Comput Sci. 2019;157:134–41.
[44] Robert Shimonski. The wireshark ﬁeld guide, 1st ed. New York: Syngress Press, Elsevier; 2013.
650

S. Premkumar and AN. Sigappi


Paper 2:
- APA Citation: Singh, G., Kalra, N., Yadav, N., Sharma, A., & Saini, M. (2022). Smart Agriculture: A Review. Siberian Journal of Life Sciences and Agriculture, 14(6), 423-454. doi:10.12731/2658-6649-2022-14-6-423-454
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: "The role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability"
  Extract 2: "By implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness."
  Limitations: No limitations are explicitly mentioned in the abstract.
  Relevance Evaluation: 1.0: Exceptionally relevant - The paper directly informs the outline point by discussing the benefits and applications of fog computing in addressing real-time data transmission challenges in agricultural management systems.
  Relevance Score: 1.0
  Inline Citation: (Gurjeet Singh et al., 2022)
  Explanation: In this systematic review, the paper examines the relevance of fog computing in distributing processing and storage across the network, enhancing scalability and reliability. The paper specifically investigates the potential of fog computing to address the challenges faced by real-time data transmission in agricultural management systems. By implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness.

 Full Text: >
423
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
НАУЧНЫЕ ОБЗОРЫ И СООБЩЕНИЯ
  
SCIENTIFIC REVIEWS AND REPORTS
DOI: 10.12731/2658-6649-2022-14-6-423-454 
UDC 004:63
SMART AGRICULTURE: A REVIEW
Gurjeet Singh, Naresh Kalra, Neetu Yadav,                                                    
Ashwani Sharma, Manoj Saini
Agriculture is regarded as one of the most crucial sectors in guaranteeing food 
security. However, as the world’s population grows, so do agri-food demands, 
necessitating a shift from traditional agricultural practices to smart agriculture 
practices, often known as agriculture 4.0. It is critical to recognize and handle the 
problems and challenges related with agriculture 4.0 in order to fully profit from 
its promise. As a result, the goal of this research is to contribute to the development 
of agriculture 4.0 by looking into the growing trends of digital technologies in the 
field of agriculture. A literature review is done to examine the scientific literature 
pertaining to crop farming published in the previous decade for this goal. This 
thorough examination yielded significant information on the existing state of digital 
technology in agriculture, as well as potential future opportunities.
Keywords: Smart Agriculture; Artificial Intelligence; Machine Learning; IOT; 
Edge Computing; Fog Computing
For citation. Gurjeet Singh, Naresh Kalra, Neetu Yadav, Ashwani Sharma, Manoj. 
Smart Agriculture: A Review. Siberian Journal of Life Sciences and Agriculture, 2022, 
vol. 14, no. 6, pp. 423-454. DOI: 10.12731/2658-6649-2022-14-6-423-454 
1. Introduction 
1.1. A worldwide dilemma of food security
Food security is a multifaceted notion that aims to eliminate hunger by 
assuring a steady supply of nutritious food. It is defined by a four-pillar para-
digm, each of which is necessary to provide food security [1]. Food security 
is becoming a severe global concern as a result of anthropogenic factors such 
as rapid population expansion, urbanization, industrialization, farmland loss, 
freshwater scarcity, and environmental degradation. This is due to the fact that 
424
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
these factors have a direct impact on the agricultural industry, which is the 
world’s principal source of agri-food production. By 2050, it is expected that 
the global population will rise from 7.7 billion to 9.2 billion, urban population 
will rise by 66 percent, arable land will decline by approximately 50 million 
hectares, global GHG emissions (source of CO 2 – promote crop disease and 
pest growth) will rise by 50 percent, agri-food production will decline by 20%, 
and food demand will rise by 59 to 98 percent, posing an imminent threat. To 
meet rising food demands, agricultural practitioners around the world will need 
to increase crop and livestock production to maximize agricultural output. The 
emphasis of this review paper is crop farming, which includes the production 
of both food and cash crops. 
A typical agri-food value chain displaying three key stages in the production 
of agricultural products: pre-field (pre-plantation stage), in-field (plantation and 
harvesting stage), and post-field (post-harvesting stage). All of the stages are 
important in the value chain, but in this examination, we will focus on the sec-
ond stage, in-field, which includes numerous crop-growing operations such as 
ploughing, sowing, spraying, and harvesting, among others. Traditional agricul-
tural approaches are now used in these procedures, which are labor-intensive, 
require arable land, time, and a significant quantity of water (for irrigation), and 
make it difficult to produce enough food [5]. A part of the problem is also due 
to the improper application of pesticides and herbicides, as well as the misuse 
of available technologies, both of which hurt crops and ultimately result in 
agricultural waste [6]. These problems can be solved by combining advanced 
technologies and computer-based applications that ensure higher crop yields, 
less water use, better pesticide/herbicide use, and improved crop quality. This 
is where the concept of smart agriculture comes into play.
1.2. Smart Agriculture
Every industry is being revolutionized and reshaped by Industry 4.0. It’s a 
strategic initiative that combines emerging disruptive digital technologies like 
the Internet of Things (IoT), big data and analytics (BDA), system integration 
(SI), cloud computing (CC), simulation, autonomous robotic systems (ARS), 
augmented reality (AR), artificial intelligence (AI), wireless sensor networks 
(WSN), cyber-physical systems (CPS), digital twin (DT), and additive manu-
facturing (AM) to enable the digitization of the industry [7]. 
Agriculture 4.0, also known as smart agriculture, smart farming or digital 
farming [7], is the next phase of industrial agriculture, fueled by the integra-
tion of these technologies in agriculture. Farmers can use smart agriculture to 
address a variety of agricultural food production concerns such as farm pro-
425
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
ductivity, environmental impact, food security, crop losses, and sustainability. 
Farmers, for example, can connect to farms remotely, regardless of location 
or time, using IoT-enabled equipment based on WSNs to monitor and control 
farm operations. Drones outfitted with hyper spectral cameras can collect data 
from a variety of sources on farmlands, while autonomous robots can assist 
or complete repetitive chores on farms. Data analytics techniques can be used 
to examine the obtained data, and computer programs can be utilized to help 
farmers make decisions.
Similarly, smart agriculture can monitor and analyze a wide range of pa-
rameters related to environmental factors, weed control, crop production status, 
water management, soil conditions, irrigation scheduling, herbicides and pes-
ticides, and controlled environment agriculture to increase crop yields, reduce 
costs, improve product quality, and maintain process inputs through the use of 
modern systems [8].
1.3. Research Motivation and Contribution 
The reason for writing this assessment is that digital technologies in agri-
cultural systems provide new strategic solutions for increasing farm output ef-
ficiency and effectiveness. Furthermore, digital transformation paves the door 
for modern farming technologies like vertical farming (hydroponics, aquapon-
ics, and aeroponics) to be used, which has the potential to solve food security 
issues. However, there are a number of issues and restrictions connected with 
this change from a technological, socioeconomic, and management perspective 
that must be overcome in order to fully realise the potential of agricultural 4.0 
[9].A number of publications [9–18] have examined developing trends in the 
development of agriculture 4.0 by offering concise information on essential 
uses, benefits, and research problems of smart farming. These studies’ research 
focuses on either explaining more general technical aspects while focusing on 
only one or a few digital technologies, or improving agricultural supply chain 
performance, or developing an agriculture 4.0 definition, or achieving sustain-
able agronomy through precision agriculture, or proposing a smart farming 
framework. Nonetheless, these studies do not include an explicit discussion of 
the tools and techniques utilized to construct various systems, as well as their 
maturity level. There are also few studies that look at the consequences of dig-
ital technology in modern soilless farms including hydroponics, aquaponics, 
and aeroponics (indoor/outdoor). As a result, in order to promote conversation 
in this field, it is necessary to examine the emergence of agriculture 4.0 from 
many angles. This research seeks to provide a comprehensive overview of dig-
ital technologies used in the second stage of the agricultural production value 
426
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
chain (in-field) for various farm types as described in section 1.1. The study’s 
key theoretical contribution is the analysis and dissemination of the tools and 
techniques used, as well as the farm type, maturity level of produced systems, 
and potential obstacles or inhibiting factors in agriculture 4.0 development. Re-
searchers and agricultural practitioners will benefit from the review’s insights 
in future study on agriculture 4.0. 
1.4. Paper organization 
The following is the structure of the paper after the introduction: 
Section 2 discusses the methodology used to collect relevant literature; Sec-
tion 3 then presents the statistical results obtained after a general analysis of the 
selected research studies; Section 4 then provides a detailed overview of the 
core technologies used in agricultural digitization; Section 5 then highlights the 
technical and socio-economic roadblocks to digital integration in agriculture; 
and finally, Section 6 outlines a discussion of the research questions.
2. Research Methodology 
A systematic literature review (SLR) is a technique for organizing and iden-
tifying research related to a specific topic [19]. SLR is used in this study to look 
into the state of Industry 4.0 technologies in the agricultural industry. Cases 
where the phrase ‘agricultural’ occurred in the title, abstract, or keywords of 
an article with any of the ‘Industry 4.0 technologies’ described in section 1.2 
are specifically sought. A review procedure is established prior to conducting 
the SLR to ensure a transparent and high-quality research process, which are 
the features that distinguish a systematic literature review [20]. By conducting 
thorough literature searches, the review methodology also helps to reduce bias. 
The creation of the research questions, the defining of the search method, and 
the specification of inclusion and exclusion criteria are all part of this process. 
To conduct SLR, this paper uses a recommended reporting item for system-
atic reviews and meta-analysis (PRISMA) approach. PRISMA is a minimum 
collection of items based on evidence that is used to guide the construction of 
systematic literature reviews and other meta-analyses [19].
2.1. Review Protocol 
Before doing the bibliographic analysis, a review methodology is estab-
lished to identify, analyze, and interpret data that are relevant to the research 
focus. To begin, research questions are developed in order to provide insight 
into the study of published studies in the research area of interest from many 
perspectives. These are the questions that must be addressed in the research. The 
search strategy is then created, which aids in the identification of appropriate 
427
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
keywords later in the search equation, as well as the identification of relevant 
information sources, such as academic databases and search engines that allow 
access to vast amounts of digital documentation. Science Direct, Scopus, and 
IEEE Xplore are three online research archives that are utilized to find relevant 
studies. Finally, boundaries are created by predefining inclusion and exclusion 
criteria for further inquiry and content assessments of selected articles in order 
to narrow the search results of each database.
2.2. Evaluation Process 
Identification, screening, eligibility, and inclusion are the four stages of the 
literature search process that are evaluated. Consolidation is done for the re-
moval of duplicate items in the identification step after initial metadata filtering 
by the use of search expressions. After this phase, the number of publications is 
reduced. The titles and abstracts of the papers are reviewed during the screening 
stage, and the most relevant publications are chosen for integral reading. In the 
third stage, full-text screening of these papers is done to ensure that they are 
eligible for this paper’s goal.
2.3. Threats to Validity 
(i) SLR replication: Because the current search is confined to only three on-
line repositories, the provided SLR is vulnerable to risks to validity. 
Additional sources could potentially lead to the discovery of more pub-
lications. Validity can be regarded satisfactorily addressed because the SLR 
process is clearly defined in sub-sections 2.1 and 2.2. However, it is possible 
that slightly different publications will be found if this SLR is replicated. This 
variation could be due to various personal choices made throughout the PRIS-
MA screening and eligibility phases, but it’s highly improbable that the overall 
results would alter.
(ii)The search string used to discover the relevant papers covers the entire 
spectrum of SLR; however it’s possible that some important studies were over-
looked. More research may be found if more keywords and synonyms in the 
search are included.
3. Digitization Trends in Agriculture 
Although the agriculture business is making significant progress in terms 
of digital technology adoption, it is still lagging behind other industries such 
as healthcare, manufacturing, mining, automotive, energy, and others [15]. The 
crop farming method considered while designing an application or framework 
is referred to as the farm type. The farming method, for example, can be soil-
based or soilless. Open-air fields (conventional outdoor agricultural farms) and 
428
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
greenhouse farms are included in the soil-based farming category (indoor). The 
soilless farming category, on the other hand, includes modern farming tech-
niques such as aquaponics, aeroponics, and hydroponics (mostly indoor). In 
the recent decade, autonomous robotics systems (including unmanned guided 
vehicles and unmanned aerial vehicles (drones)), the internet of things, and 
machine learning appear to be the most commonly used technology in agricul-
ture. Agriculture’s growing sectors include big data, wireless sensor networks, 
cyber-physical systems, and digital twins. Furthermore, in contrast to indoor 
farms, open air farms are the most usually examined in research investigations. 
Few publications exist for soilless farming systems (aquaponics, aeroponics, 
and hydroponics), implying that these modern farming practices are still in 
their infancy. Similarly, each use case’s services are identified and classified 
into nine service categories: I crop management, CM (estimation/harvesting 
period and seed plantation/prediction of crop yield/ growth rate/harvesting/ 
pollination/ spraying (fertilizer/ pesticide)); ii) crop quality management, CQM 
(fresh weight, green biomass, height, length, width, leaf density, piment content 
(chlorophyll), and phytochemical composition); iii) water and environmental 
management, WEM (monitoring and control of flow rate, water level, water 
quality (nutrients), temperature, humidity, CO2, and weather forecasts, among 
other things); iv) irrigation management, IM (water stress detection and sched-
uling); v) farm management, FM (monitoring of farm operations, tracking and 
counting products, determining production efficiency, financial analysis, energy 
consumption analysis, technology integration, and decision-making);
PDM (pest and disease management) is a term used to describe the man-
agement of pests and diseases (pest identification and disease detection) SM 
(Soil Management) vii) (moisture content, soil nutrients, fertilizer needs and 
application) WUVM (weed/unknown vegetation mapping, classification, and 
pesticide application) viii) weed and unwanted vegetation management FDC 
(fruit detection and counting), and ix) 
The role of various digital technologies in smart farming is depicted in 
these categories. Crop management characteristics such as crop yield prediction, 
growth rate estimation, and harvesting period evaluation are the most 4.0 in the 
previous decade, whereas soil management, fruit identification and counting, 
and crop quality management receive very less attention. The European Union’s 
TRL scale, which divides system maturity into three generic categories [21], is 
used to assess the technology readiness level (TRL) of all use cases. The first 
level is conceptual, which corresponds to European TRL 1–2 (use case is in 
concept phase), the second level is prototype, which corresponds to Europe-
429
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
an TRL 3–6 (use case is functional even without all planned features), and the 
third level is deployed, which corresponds to European TRL 7–9. (Use case 
is mature with all the possible functions). Each use case’s TRL was produced 
in a few experiments. It has been noticed that smart agricultural systems have 
made little progress from the concept and prototype stages to the commercial 
stage. The majority of use cases, for example, are still in the prototype stage.
4. Agriculture 4.0 enabling technologies 
4.1. Internet of Things driven agricultural systems 
The Internet of Things (IoT) is a network of interconnected computing de-
vices, sensors, appliances, and machines that are all connected to the internet 
and have their own unique identities and capacities for remote sensing and 
monitoring [21]. Network layer (communication), perception layer (hardware 
devices), , middleware layer (device management and interoperability), service 
layer (cloud computing), application layer (data integration and analytics), and 
end-user layer are the six layers of the IoT reference architecture (user-inter-
face). IoT devices on the physical layer in the agricultural domain collect data 
on environmental and crop characteristics such as temperature, humidity, pH 
value, water level, leaf colour, fresh leaf weight, and so on. The network layer is 
responsible for transmitting this information, and its architecture is determined 
by the field size, farm location, and type of farming method. ZigBee, LoRa, and 
Sigfox, for example, are widely utilized and employed in outdoor fields because 
they are less expensive, have low energy consumption, and have a long trans-
mission range [22, 23]. Bluetooth, despite being a secure technology, is only 
employed in indoor farms due to its limited transmission range [22]. Due to its 
high costs and high energy consumption, Wi-Fi is not a promising technology 
for agricultural applications [22]. On the other hand, RFID (radio frequency 
identification) and NFC (near field communication) technologies are increas-
ingly being used in agricultural systems for product tracking [24]. For periodic 
monitoring of environmental and soil characteristics, GPRS or mobile commu-
nication technology (2G, 3G, and 4G) is utilized. Furthermore, HTTP, WWW, 
and SMTP are the most commonly utilized communication protocols in agri-
cultural contexts. Similarly, middleware HYDRA and SMEPP are commonly 
used in agricultural systems to enable interoperability and system security for 
their context-aware functionalities [25]. 
Cloud computing approaches are used in the service layer to store data. 
This information is then used on the application layer to create smart apps that 
farmers, agriculture experts, and supply chain professionals can use to improve 
430
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
farm monitoring and productivity. The use of IoT in agriculture is intended to 
provide farmers with decision-making tools and automation technologies that 
allow them to seamlessly integrate knowledge, products, and services in order to 
increase production, quality, and profit. A slew of research have been conduct-
ed and presented on the incubation of IoT concepts in the agricultural industry. 
The development of IoT-based agricultural systems has addressed a variety of 
technological and architectural concerns. However, most of these technologies 
are now in the conceptual stage or in prototype form (not commercial). Farm 
management, irrigation control, crop development, health monitoring, and dis-
ease detection are all priorities. 
Some of these studies also explained how IoT is being used in current ag-
ricultural systems like vertical farming (soilless farming - aquaponics, hydro-
ponics, and aeroponics) and greenhouse farming (soil-based). Furthermore, the 
majority of studies have been focused on a single issue.
4.2. Wireless sensor networks in agriculture 
A wireless sensor network (WSN) is a technology that is utilized in an Inter-
net of Things (IoT) system. It is defined as a collection of spatially distributed 
sensors for monitoring environmental physical conditions, temporarily storing 
obtained data, and transferring the information to a central point [22]. A wire-
less sensor network (WSN) for smart farming is made up of multiple sensor 
nodes connected by a wireless connection module. These nodes have a variety 
of skills that allow them to self-organize, self-configure, and self-diagnose (for 
example, processing, trans- mission, and feeling). There are various varieties of 
WSNs, which are classified based on the environment in which they are used. 
TWSNs (terrestrial wireless sensor networks), WUSNs (wireless underground 
sensor networks), UWSNs (underwater wireless sensor networks), WMSNs 
(wireless multimedia sensor networks), and MWSNs (mobile wireless sensor 
networks) are a few examples [26]. TWSN and UWSN are commonly utilized 
in agricultural applications. TWSN nodes are sensors that collect data from 
the environment and are located above ground. The second type of WSN is 
WUSNs, which are WSNs with sensor nodes embedded in the soil. Lower fre-
quencies easily enter the soil in this environment, whereas higher frequencies 
are severely attenuated [27]. Because of the limited communication radius, the 
network requires a larger number of nodes to cover a big area. Many research 
publications on the use of WSN for various outdoor and indoor farm applica-
tions, such as irrigation management, water quality testing, and environmental 
monitoring, are accessible in the literature. The goal of these experiments was 
to create WSN architectures that were simple, low-cost, energy-efficient, and 
431
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
scalable. However, several aspects of WSNs, such as minimum maintenance, 
robust and fault-tolerant architecture, and interoperability, require more study. 
4.3. Cloud computing in agriculture 
Cloud computing (CC) is defined as a model for enabling convenient, ubiq-
uitous, on-demand network access to a shared pool of configurable computing 
resources (e.g., networks, servers, storage, applications, and services) that can 
be rapidly provisioned and released with minimal management effort or ser-
vice provider interaction, according to the National Institute of Standards and 
Technologies (NIST) [28]. The datacenter (hardware), infrastructure, platform, 
and application layers make up the primary architecture of CC [29]. Each of 
these layers corresponds to one of three cloud service models: SaaS (software 
as a service), PaaS (platform as a service), and IaaS (infrastructure as a service) 
(IaaS). In the agriculture sector, cloud computing has gotten a lot of attention in 
the last decade because it provides: 1) low-cost storage for data collected from 
various domains via WSNs and other preconfigured IoT devices, 2) large-scale 
computer systems to make intelligent decisions by converting raw data into 
usable knowledge, and 3) a secure platform for developing agricultural based 
IoT applications [30]. 
CC is used to develop various agricultural applications in conjunction with 
IoT and WSN. CC technology is also utilized to develop operational farm man-
agement systems (FMSs) that help farmers and farm managers monitor farm 
activities more efficiently. The traceability of agri-product quality is another 
area of interest that is being investigated in global research [31]. However, only 
preliminary research has been done to see if traceability complies with food 
safety and quality criteria. The usage of cloud-based agricultural systems has 
the potential to address issues such as rising food demand, pollution from pes-
ticides and fertilizers, and the safety of agricultural products. These FMSs, on 
the other hand, lack the flexibility to offer run-time customization in response 
to specific farmer needs. Furthermore, because most farm data is fragmented 
and distributed, recording farm operations accurately in existing FMSs systems 
is problematic [32].
4.4. Edge/fog computing in agriculture 
The rapid expansion of IoT has resulted in an explosion of sensors and smart 
devices, creating massive amounts of data. The processing and analysis of such a 
large volume of data in real time is difficult since it puts a strain on the cloud serv-
er and slows response times. When dealing with such a massive data set, a cloud 
server alone will not be able to offer real-time responses. Furthermore, because 
IoT applications require a constant exchange of information between devices and 
432
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
the cloud, they are susceptible to network latency, making CC unsuitable for these 
applications [23]. The introduction of the edge computing idea has the potential 
to overcome the CC issues. This novel computing architecture places computa-
tional and storage resources (such as cloudlets or fog nodes) closer to data sources 
like mobile devices and sensors at the network’s edge. This allows for real-time 
analytics while maintaining data security on the device [23]. Although edge com-
puting has exciting potential for smart agriculture, its applications in agricultural 
systems are still in their infancy. As a result, there are limited research studies in 
this field. The majority of the edge computing-based agricultural systems covered 
in these papers are prototypes that solve a small number of challenges across a 
variety of agricultural disciplines. Interoperability and scalability issues haven’t 
gotten enough attention so yet. Agricultural robots combine emerging technolo-
gies such as computer vision; wireless sensor networks (WSNs), satellite navi-
gation systems (GPS), artificial intelligence (AI), cloud computing (CC), and the 
Internet of Things (IoT) to help farmers improve productivity and quality of ag-
ricultural products. AARS in smart farming can be mobile or fixed [33]. Mobile 
AARS can move around the working field. Unmanned ground vehicles (UGVs) 
and unidentified aerial vehicles (UAVs) are the two types of mobile AARSs, as 
discussed in the following sections. 
4.5.1. Unmanned ground vehicles in agriculture
Unmanned ground vehicles (UGVs) are agricultural robots that work with-
out the use of a human operator on the ground. A platform for locomotive ap-
paratus and manipulator, navigation sensors, a supervisory control system, an 
interface for the control system, communication links for information exchange 
between devices, and system architecture for integration between hardware and 
software agents are the main components of UGVs [34]. The control architec-
ture of a UGV can be remote-operated (controlled via an interface by a human 
operator) or totally autonomous (operated without the use of a human control-
ler using artificial intelligence technology) [34]. Locomotive systems, likewise, 
can be based on wheels, tracks, or legs [34]. Legged robots are uncommon in 
agriculture, despite their great terrain flexibility, inherent Omni directionality, 
and soil protection. These robots, however, offer a disruptive locomotion mech-
anism for smart farms when paired with wheels (wheel-legged robots). UGVs 
should meet specific requirements, such as small size, maneuverability, resil-
ience, efficiency, human-friendly interface, and safety, in addition to the nec-
essary features for infield operations, in order to improve crop yields and farm 
productivity. A 4WD locomotive system is used in the majority of agricultural 
robotic systems due to its ease of manufacture and control. 
433
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
The disadvantage of 4WD is that terrains with stone elements and/or voids 
have a significant impact on the wheels [34]. As a result, other mechanisms, 
such as legged or wheel-legged locomotive systems, should be investigated. 
Although some robots include computer vision systems, most of these robots 
are designed with a low-cost computer vision system, such as traditional RGB 
cameras, due to the difficulties of establishing an accurate and dependable sys-
tem that can replace manual labour. Furthermore, the majority of the systems 
mentioned above are still in the research phase, with no large-scale commer-
cial application.
4.5.2. Unmanned aerial vehicles in agriculture 
Unmanned aerial vehicles (UAVs), sometimes known as aerial robots, are 
planes that do not have a human pilot on board. There are many different types 
of UAVs [35] depending on the technology used to fly (wing structure) and the 
level of autonomy. Fixed-wing (planes), single-rotor (helicopter), hybrid system 
(vertical takeoff and landing), and multi-rotor UAVs are examples of wing types 
(drone). Drones (multi-rotor technology), which are raised and driven by four 
(quad-rotor) or six (hex-rotor) rotors, have grown in popularity in the agricul-
ture sector because to their mechanical simplicity in comparison to helicopters, 
which rely on a much more complex plate control mechanism [36]. Similarly, 
UAVs can be tele-operated or tele-commanded, depending on their autonomy 
level, with the pilot providing references to each actuator of the aircraft to con-
trol it in the same way that an onboard pilot would, or tele-commanded with the 
aircraft relying on an automatic controller on board to maintain a stable flight 
[35]. Agricultural UAVs with the right sensors (vision, infrared, multispectral, 
and hyper spectral cameras, for example) can collect data (vegetation, leaf area, 
and reflectance indexes) from their fields to monitor dynamic changes in crops 
that aren’t visible from the ground [37]. Farmers can deduce information about 
crop illnesses, nutrient deficits, water level, and other agricultural growth char-
acteristics using this data. Farmers might plan possible cures using this knowl-
edge (irrigation, fertilization, weed control, etc.). 
The majority of the systems mentioned above are still in the research stage, 
with no large-scale commercial use. Other issues with these UAVs include bat-
tery life and flight time [35]. Lithium-ion batteries are currently in use because 
their capacity exceeds that of conventional batteries. 
However, increasing the battery capacity increases the weight of the drone, 
and research is currently underway to overcome this issue. 
Furthermore, existing UAVs have complicated user interfaces that can only 
be used by experts to accomplish agricultural chores. People who are elderly 
434
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
or unfamiliar with UAV technology will be able to control it more readily if 
the user interface is improved and made more human-centered with multimod-
al feedback. 
4.6. Big data and analytics in agriculture 
Rapid advancements in IoT and CC technologies have massively expanded 
the amount of data available. Textual content (structured, semi-structured, and un-
structured) and multimedia content (e.g., videos, photos, and audio) are included 
in this data, also known as Big Data (BD) [38]. Big data analytics is the practice 
of analyzing large amounts of data to find hidden patterns, unknown relationships, 
market trends, client preferences, and other important information (BDA). Big 
data is usually classified into five dimensions, each of which is represented by a V. 
The concept of BD-driven smart agriculture is very new, but its trend is 
good because it has the potential to make a dramatic change in the food supply 
chain and boost food security through higher productivity. Agricultural big data 
is typically generated from a variety of sources in agriculture, including ground 
sensors, aerial vehicles, and ground vehicles equipped with special cameras and 
sensors; governmental bodies in the form of reports and regulations; private 
organizations through online web services; farmers in the form of knowledge 
gained through surveys; and social media [39]. Depending on the agricultural 
domain, the data can be environmental (weather, climate, moisture level, etc.), 
biological (plant disease), or geospatial, and it comes in a variety of volumes, 
speeds, and formats [40]. The information is acquired and stored in a computer 
database, where it is analyzed using computer algorithms for seed characteris-
tics, weather patterns, soil attributes (such as pH or nutrient content), marketing 
and trade management, consumer behaviour, and inventory management. In 
agriculture, a range of strategies and tools are used to examine large data. The 
most often employed techniques include machine learning, cloud-based plat-
forms, and modelling and simulation. Machine learning technologies are used 
to solve problems like prediction, clustering, and classification, while cloud 
platforms are utilized for large-scale data storage, preprocessing, and visual-
ization. There are still numerous potential areas where BDA can be used to 
address various agricultural concerns that are not well covered in existing lit-
erature. For example, data-intensive greenhouses and indoor vertical farming 
systems, quality control and health monitoring of crops in outdoor and indoor 
farms, genetic engineering, decision support platforms to help farmers design 
indoor vertical farms, and scientific models for policymakers to help them make 
decisions about the physical ecosystem’s sustainability. Finally, the majority of 
systems are still in the prototype stage.
435
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
4.7. Artificial intelligence in agriculture 
Artificial intelligence (AI) is the study of theories and computer systems that 
can perform activities that need human intelligence, such as sensory percep-
tion and decision-making [41]. AI, particularly in the areas of machine learning 
(ML) and deep learning (DL), is seen as one of the primary forces driving the 
digitization of agriculture when combined with CC, IoT, and big data. These 
technologies have the potential to increase crop production, harvesting, pro-
cessing, and marketing in real time [42]. ML and DL algorithms are being used 
to determine various parameters such as weed detection, yield prediction, and 
disease identification in a number of intelligent agricultural systems. The fol-
lowing two sub-sections go through these systems.
4.7.1. Machine learning in agriculture 
supervised learning (linear regression, regression trees, non-linear regres-
sion, Bayesian linear regression, polynomial regression, and support vector 
regression), and unsupervised learning (hierarchal clustering, k-means cluster-
ing, neural networks (NN) anomaly detection, principal component analysis, 
independent component analysis, a-priori algorithm, and singular value decom-
position (SVD)). Weed detection, Crop yield prediction, disease and weather 
prediction (rainfall), soil properties estimation ( moisture content, type, pH, 
temperature, etc.), water management, fertilizer amount determination, and 
livestock production and management all use machine learning techniques and 
algorithms [2, 43]. According to the study of these publications, “crop yield 
prediction” is an extensively researched area, with the most widely utilized ML 
approaches to allow smart farming being linear regression [4], neural network 
(NN), random forest (RF), and support vector machine (SVM) [2]. 
The presented use cases are still in the research phase, and no commercial 
use has been recorded as of yet. Furthermore, AI and machine learning ap-
proaches are found to be underutilized in greenhouse and indoor vertical farm-
ing systems, particularly hydroponics, aquaponics, and aeroponics. There are 
only a handful publications that use machine learning techniques. To enable 
digital farming, new methodologies such as federated learning and privacy 
preserving methods are being developed in light of the digital transformation’s 
cyber-security and data privacy problems [44]. These methods create machine 
learning models from local parameters rather than sharing private data samples, 
reducing security concerns.
4.7.2. Deep learning in agriculture 
Deep learning (DL) is an extension of classical machine learning (ML) 
because extra “depth” (complexity) is added to the model, it can accomplish 
436
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
difficult tasks (predictions and classification) extraordinarily well and quick-
ly. DL’s main benefit is feature learning, which includes extracting features 
(high-level information) from big datasets automatically [45]. Long short term 
memory (LSTM) networks, convolutional neural networks (CNNs), recurrent 
neural (RNN) networks, generative adversarial networks (GANs), radial basis 
function networks (RBFNs), multilayer perceptron (MLPs), feed-forward ar-
tificial neural network (ANN), self-organizing maps (SOMs), deep belief net-
works (DBNs), restricted Boltzmann machines (RBMs), and autoencoders are 
examples of deep learning algorithms Various sites [46] provide a full overview 
of these methods, popular architectures, and training systems. DL algorithms 
are commonly used in agriculture to solve problems related to computer vision 
applications that aim to predict key parameters such as crop yields, soil mois-
ture content, weather conditions, and crop growth conditions; detect diseases, 
pests, and weeds; and identify leaf or plant species [47]. Computer vision is an 
interdisciplinary field that has exploded in popularity in recent years thanks to 
the rise of CNNs. It provides methods and techniques for accurately process-
ing digital images and allowing computers to analyze and comprehend the vi-
sual world [48]. CNNs, generally is known as Convet and its derivatives, are 
the most widely used deep learning algorithms in agricultural applications. 
Region-based CNNs (RCNN), Fast-RCNN, Faster-RCNN, YOLO, and Mask-
RCNN are some of the CNN variants, with the first four being the most typi-
cally used to address object detection issues. On the other side, Mask-RCNN 
is utilized to overcome instance segmentation issues. The reader can find a 
thorough explanation of these algorithms and their applications in the exist-
ing bibliography [47]. Other DL approaches have been employed in a few re-
search. When it comes to datasets, the majority of deep learning models are 
trained on photographs, with only a few trained on sensor data collected in the 
field. This demonstrates that DL can be used on a wide range of datasets. It’s 
also worth noting that the majority of the research is focused on outdoor farms, 
with next-generation farms (environment-controlled) receiving less attention. 
Though digital farming has the potential to be enabled by DL, most systems 
are still in the prototype stage. Furthermore, the additional obstacles created 
by cyber-security and privacy concerns necessitate the improvement of current 
deep learning and computer vision technologies.
4.8. Agricultural decision support systems 
A decision support system (DSS) is a smart system that assists stakehold-
ers and potential users in making decisions in response to specific needs and 
challenges by offering operational responses based on meaningful informa-
437
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
tion retrieved from raw data, documents, personal knowledge, and/or models 
[49]. Data-driven, model-driven, communication-driven, document-driven, and 
knowledge-driven DSS are all possibilities. The following source [50] lists the 
key features of these DSSs. The volume of farming data has exploded as a re-
sult of the advent of agriculture 4.0. Platforms like agricultural decision support 
systems (ADSS) are necessary to convert this heterogeneous data into practical 
knowledge in order to make evidence-based and precise judgments about farm 
management and facility layout [51]. ADSSs have gotten a lot of interest in the 
agriculture industry over the last few years. A variety of agricultural concerns, 
such as farm management, water management, and environmental management, 
have been addressed by a number of ADSSs. Most ADSSs have been found 
to ignore expert knowledge, which is extremely useful since it enables for the 
construction of systems that are tailored to the demands of the users. Complex 
GUIs, insufficient re-planning components, a lack of prediction and forecasting 
abilities, and a lack of ability to adjust to unpredictable and dynamic elements 
are some of the other identified faults with some of these ADDSs. It’s also worth 
noting that all of the ADSSs are for outside agriculture systems and are still in 
development. In comparison, the use of ADSS in indoor soilless agriculture is 
currently underutilized.
4.9. Agricultural cyber-physical systems 
A cyber-physical system (CPS) is an automated distributed system that inte-
grates physical processes with communication networks and computing infra-
structures [52], and it is one of the key technologies of Industry 4.0. There are 
three standard CPS reference architecture models: 5C, RAMI 4.0, and IIRA, 
which may be found in full at the following source [53]. Among these, the 5C 
is a well-known and widely used reference model. CPS takes advantage of a 
number of existing technologies, including agent systems, IoT, CC, augmented 
reality, big data, and machine learning (ML) [54]. Scalability, flexibility, au-
tonomy, reliability, resilience, safety, and security are all improved as a result 
of its adoption.
One of the most difficult domains that can benefit from CPS technology is 
agriculture. Agricultural cyber-physical systems (ACPSs) combine advanced 
electronic technology with agricultural infrastructure to create integrated farm 
management systems that interact with the physical environment to keep crops 
growing at their best [55]. ACPSs collect high-accuracy data regarding climate, 
soil, and crops and utilize it to manage watering, humidity, and plant health, 
among other things. For the management of various services, a range of ACPSs 
have been created; however, most of these systems are still in the prototype and 
438
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
conceptual stages. Furthermore, the majority of studies are for outdoor farms, 
with only a few publications published on soil-based greenhouse systems. There 
has been no research on indoor soilless agricultural methods. Since of its pro-
spective applications in a variety of fields, ACPSs have sparked a lot of academ-
ic interest; nevertheless, deploying CPS models in real-world applications is 
still a difficulty because it requires the right hardware and software [56]. When 
designing ACPSs, special emphasis should be paid to autonomy, robustness, and 
resilience in order to deal with the unpredictable nature of the environment and 
the unknown characteristics of agricultural facilities. ACPSs are influenced by 
a variety of factors, including humans, sensors, robots, crops, and data.. ACPSs 
must be properly and extensively developed to provide a seamless operation 
while avoiding conflicts, errors, and disturbances.
4.10. Digital twins in agriculture 
A digital twin (DT) is a dynamic virtual replica of a real-life (physical) 
object that mimics its behaviours and states across multiple stages of the ob-
ject’s lifecycle by combining real-world data, simulation, and machine learning 
models with data analytics to enable understanding, learning, and reasoning 
[57]. The physical and virtual entities, the physical and virtual environments, 
the metrology, and realization modules that perform the physical to virtual and 
virtual to physical connection or twinning, the twinning and twinning rate, and 
the physical and virtual processes are all required for a complete description of 
the DT concept for any physical system [58]. Because of advancements in tech-
nology such as the Internet of Things, big data, wireless sensor networks, and 
cloud computing, the DT concept has gained traction. This is due to the fact that 
these technologies enable real-time monitoring of physical twins at high spatial 
resolutions using both small devices and distant sensing, which generate ev-
er-increasing data streams [21]. In comparison to other fields, the notion of DT 
in agricultural applications is relatively new, with the first references appearing 
in 2017; as a result, its added value has not yet been thoroughly studied [21]. 
Because of its reliance on natural circumstances (temperature, soil, humidity), 
as well as the presence of living and non-living physical twins (plants and an-
imals), framing is a very complex and dynamic realm (indoor farm buildings, 
grow beds, outdoor agricultural fields, agricultural machinery). 
Non-living physical twins interact directly or indirectly with plants and 
animals (living physical twins), posing more obstacles for DT in agriculture, 
whereas non-living physical twins are the focus of DT in other domains such 
as manufacturing. The majority of research has been on open-air agricultur-
al systems. There is just one study that proposes DT for a soil-based vertical 
439
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
farming system and one study that implements DT for a soilless vertical farm-
ing system (aquaponics). This could be due to the difficulty of designing and 
managing modern farming systems. Furthermore, the majority of DTs are still 
in the research phase, with no commercial deployment planned. Cost savings, 
disaster prevention, clearer decision making, and efficient management oper-
ations are all reported benefits of DT applications in agriculture, which can be 
applied to a variety of agricultural subfields such as plant and animal breeding, 
aquaponics, vertical farming, cropping systems, and livestock farming. While 
DT technology offers a lot of promise, achieving synchronization between the 
real and digital worlds is difficult. Due to the quirks of living physical twins, 
the intricacy of this procedure is magnified in agricultural settings. As a result, 
agricultural DT should begin with micro-farms, which can then be gradually up-
graded to a more intelligent and autonomous form by adding more components.
4.11. Roadblocks in digitization of agriculture industry 
This section outlines a series of interconnected hurdles to a wider adoption of 
digital technologies in agriculture. Following a review of the literature, 21 barri-
ers were found, which were divided into technical and socioeconomic categories.
4.12. Technical roadblocks 
•Interoperability: Data is regarded as a critical component in the success of 
smart systems. Agricultural data is typically gathered from a variety of sources, 
including thousands of individual farmlands, animal industries, and business ap-
plications. Data can be in a variety of formats, making data integration difficult. 
As a result, after systematic data collection, storage, processing, and knowledge 
mining, data interoperability is critical to increasing the value of this widely 
distributed data [59]. Interconnected and interoperable devices are also required 
for successful communication between heterogeneous devices. The system’s in-
teroperability can be improved through cross-technology communication [60].
•Standardization: Standardization of devices is required to fully use digital 
technologies for smart farming applications. Differences in output can occur 
as a result of misinterpretation and changes over time. Device, application, and 
system interoperability concerns can also be overcome by standardization [25].
•Data quality: Data quality, as well as data security, storage, and openness, 
are essential for producing meaningful outcomes. Another impediment to the 
adoption of smart farming technologies is the lack of decentralized data man-
agement systems [9]. Multiple actors’ willingness to exchange farm data is be-
ing harmed as a result of this problem.
•Hardware implementation: It is incredibly difficult to establish a smart agri-
cultural setup in large-scale open areas. This is due to the fact that all hardware, 
440
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
including IoT devices, wireless sensor networks, sensor nodes, machinery, and 
equipment, is directly exposed to harsh environmental conditions such as heavy 
rainfall, extreme temperatures, extreme humidity, high wind speeds, and a vari-
ety of other dangers that can destroy electronic circuits or disrupt their normal 
functionality [61]. A possible answer is to construct a sturdy and lasting casing 
for all of the expensive devices that can withstand real-world conditions [62].
•Adequate power sources: Typically, wireless gadgets used on farms func-
tion for an extended period of time and have a limited battery life. 
Because replacing a battery in the event of a failure is difficult, especially in 
open-air farms where devices are strategically located with limited access [61], a 
proper energy-saving system is required. Low-power sensors and proper commu-
nication management are two viable strategies for reducing energy consumption 
[24, 63]. Other intriguing technologies to eliminate the need for battery renewal by 
recharging batteries using electromagnetic waves include wireless power transfer 
and self-supporting wireless systems. In most agricultural applications, however, 
long-distance wireless charging is required [9]. Another potential alternative is to 
capture ambient energy from rivers, fluid flow, vehicle movement, and the ground 
surface using sensor nodes; however the converted electrical energy is current-
ly restricted, necessitating the need to enhance power conversion efficiency [64].
•Reliability: The dependability of devices, as well as the software applica-
tions that run on them, is critical. This is due to the fact that IoT devices must 
collect and transmit data from which judgments are made utilizing a variety of 
software packages. Unreliable sensing, processing, and transmission can result 
in erroneous monitoring data reports, significant delays, and even data loss, all 
of which can have a negative impact on agricultural system performance [25].
 •Adaptability: Agriculture is a complicated, dynamic, and continuously 
changing environment. As a result, when building a system, it is critical for de-
vices and applications to react proactively with other entities in the face of un-
known and dynamic elements in order to provide the required performance [65].
•Robust wireless architectures: Low-cost, wide-area coverage, enough net-
working flexibility, and high scalability are all advantages of wireless networks 
and communication technologies. However, in a dynamic agriculture environ-
ment, such as temperature swings, the movement of live objects, and the ex-
istence of impediments, dependable wireless connection is a major difficulty. 
For example, multipath propagation effects cause signal strength oscillations, 
resulting in unstable connectivity and insufficient data transmission [66]. These 
elements have an impact on the agricultural system’s performance. As a result, 
robust and fault-tolerant wireless architectures with proper sensor node place-
441
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
ment, antenna height, network topology, and communication protocols are re-
quired, as well as low-maintenance wireless systems [11].
•Interference: Because of the extensive deployment of IoT devices and wire-
less sensor networks, another difficulty is wireless interference and quality of 
service degradation. Effective channel scheduling between heterogeneous sens-
ing devices, cognitive radio-assisted WSNs, and upcoming networking prim-
itives like concurrent transmission [67] can all help to solve these problems. 
Because agriculture equipment are dispersed in indoor greenhouses, outdoor 
farmlands, underground locations, and even aquatic areas, cross-media com-
munication between underground, underwater, and air is also necessary for full 
integration of smart technologies [68].
•Security and privacy: Because smart agricultural systems are dispersed, 
they are vulnerable to cyber-attacks such as eavesdropping, data integrity, de-
nial-of-service assaults, and other sorts of disruptions that could jeopardize the 
system’s privacy, integrity, and availability [69]. With various privacy-preserv-
ing techniques and federated learning approaches, cyber-security is a funda-
mental concern that needs to be addressed in the context of smart farming [44].
•Compatibility: in order to meet the fragmentation and scalability standards, 
the models or software applications developed must be adaptable and able to 
run on any equipment in the agricultural system [13]. 
•Resource optimization: To boost farm profitability, farmers need a resource op-
timization procedure to determine the ideal number of IoT devices and gateways, 
cloud storage size, and volume of transmitted data. Resource optimization is diffi-
cult since farms vary in size and require different types of sensors to assess different 
variables [70]. Second, most farm management systems do not support run-time 
changes to match the demands of individual farmers. To estimate adequate resource 
allocation, complicated mathematical models and algorithms are necessary [32].
•Scalability: Due to technological improvements, the number of gadgets, 
gear, and sensors put on farms is continually expanding. 
Gateways, network applications, and back-end databases should all be de-
pendable and scalable in order to serve these entities [71].
•Human-centered user interfaces: Existing agricultural software and gadgets 
have complicated user interfaces, which are limiting smart farming methods. 
The majority of graphical user interfaces are constructed in such a way that 
only specialists can use them to accomplish agricultural activities. By making 
the user interface more human-centered and providing multimodal feedback, a 
bigger group of individuals will be able to use it to complete various agricul-
tural tasks [35].
442
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
4.13. Socio-economic roadblocks 
•Gap between farmers and researchers: Farmers’ engagement is critical to 
the success of the agriculture industry’s digitization. Agricultural specialists are 
frequently unaware of the concerns that farmers encounter during the agri-food 
production process, which smart technologies could solve [16]. Furthermore, it 
is critical to completely comprehend the nature of problems in order to create 
an appropriate smart solution. 
As a result, bridging the gap between farmers, agricultural professionals, 
and AI researchers is critical.
•Expenses connected with smart systems: the costs associated with adopt-
ing smart technology and systems are a major impediment to the agriculture 
sector’s digitization. These expenses typically include deployment, operation, 
and maintenance. Smart system deployment costs are typically significant since 
they include: I hardware installation, such as autonomous robots and drones, 
WSNs, gateways, and base station infrastructure, and ii) paying trained labour 
to do particular agricultural tasks [72]. Similarly, subscriptions to centralized 
networks and software packages are necessary to support data processing, con-
trol of IoT devices and equipment, and knowledge exchange, which eventually 
raises operating expenses [73]. Even if service providers occasionally provide 
free subscription packages with limited capabilities, storage capacity is limited. 
Periodic maintenance is essential to ensure the proper operation of the smart 
system, which adds to the total costs.
Environmental, ethical, and societal costs may also be connected with the 
adoption of smart devices. Initiatives focusing on cooperative farming are need-
ed to overcome cost-related roadblocks by providing: I support services for 
better cost management and needed investments, and ii) hardware solutions to 
transform conventional equipment into smart farm-ready machinery to reduce 
high initial costs [73].
•Digital division: a lack of awareness of digital technology and their appli-
cations is another problem limiting the digitalization of the agriculture sector. 
The majority of farmers have no understanding what digital technologies are, 
how to install and utilize them, or which technology is appropriate for their farm 
and matches their needs [14]. As a result, farmers must be educated on current 
farming technologies and processes. 
Furthermore, various tactics are required to develop tools that use natural 
language and are easily understood by farmers with low levels of education [74]. 
•Return on investment: In agriculture, like in other industries, the profit 
margin is critical. When it comes to implementing modern technologies, farm-
443
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
ers are concerned about the time it will take to recoup their investment and the 
difficulty in assessing the benefits [12].
•Building faith in the effectiveness of smart technology in agriculture is 
difficult, unlike in other disciplines, because many decisions influence systems 
that involve both living and non-living elements, and the results can be difficult 
to reverse [16]. In addition, the lack of verification of the influence of digital 
tools on farm productivity exacerbates the current difficulties.
•Legal frameworks: different regions and nations have distinct legal frame-
works that influence the deployment of digital technologies in agriculture, par-
ticularly in monitoring and agri-food supply [31]. Similarly, laws governing 
resource allocation (spectrum for wireless devices), data privacy, and security 
differ from country to country [31].
•Connectivity infrastructure: In most developing nations, connectivity in-
frastructure is poor, limiting access to advanced digital technologies that could 
help turn data from disparate sources into useful and actionable insights [10].
4.14. Discussion 
The goal of this study was to describe the new digital technologies that are 
being used in the agricultural industry in order to predict the future trajectories 
of agriculture 4.0. Big data and analytics, wireless sensor networks, cyber-phys-
ical systems, and digital twins are among the technologies that have yet to be 
fully explored in agriculture. This disparity could be due to the fact that install-
ing advanced technologies with more complex processes can be costly, at least 
in the early stages of their acceptance. The agricultural industry’s development 
of these technologies is expected to speed up in the next years. The findings of 
SLR also reveal that IoT is widely used in farms. This is owing to the IoT’s di-
verse capabilities, which include monitoring, tracking, and tracing, agricultural 
machinery, and precision agriculture [21]. One of the key research aims within 
the farm 4.0 techniques can be regarded to be IoT. Nonetheless, when building 
an intelligent agricultural system, only a few researches have examined data 
security and dependability, scalability, and interoperability. The outcomes of 
the study also revealed that the majority of use cases are still in the prototype 
stage. The reason for this could be that most agricultural activities involve live 
subjects, such as animals and plants, or perishable products, and establish-
ing systems for living subjects is more difficult than developing systems for 
non-living human-made systems. Another explanation could be that, due to the 
trans-disciplinary character of agriculture, it is a late adopter of technology. As a 
result, in order to construct intelligent systems, the agricultural community must 
become conversant with all digital technologies. Finally, differences in plant/
444
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
crop species and growth conditions complicate agricultural system digitaliza-
tion [55]. In contrast to indoor farms, the majority of the technologies created 
by SLR are for open-air soil-based farms (soilless and soil-based). This is owing 
to the complicated design and maintenance of indoor farms, particularly soilless 
farms, where the parameters and elements to be maintained are numerous (pH, 
air temperature, humidity, etc.) [5]. However, by incorporating digital technol-
ogy and data-driven computer applications into indoor farms, a more reliable 
control of the process can be attained. Furthermore, SLR reveals that insufficient 
research is undertaken in three of the nine service areas described in section 3 
(soil management, fruit detection and counting, and crop quality management). 
This supports the notion that significant research and development is required 
in some areas to ensure the successful digitization of the agriculture business 
in both developed and developing countries. The agriculture ecosystem’s com-
plexity creates a set of interrelated hurdles that prevent full integration of digital 
technology for agriculture 4.0 implementation. As a result, identifying possible 
bottlenecks is critical in order to devise strategic strategies to overcome them. 
This research aims to figure out what these stumbling barriers are. Following 
the investigation, 21 barriers were found and characterized on both a technical 
and socioeconomic level. These impediments are addressed in section 5, which 
outlines what needs to be done on a bigger scale to digitize the agricultural 
economy. However, it is still unknown how much removing or mitigating these 
hurdles aids in the successful integration of digital technologies. 
4.16. Added value of agricultural digitization 
Several benefits that can inspire framers and other actors to assist agriculture 
industry digitization have been discovered and outlined based on analysis. The 
benefits described here have the potential to increase farm productivity and im-
prove product quality, but they should not be viewed as a cure for the problems 
that come with smart agriculture [73]. 
•Improved agility: Farm operations can now be more agile thanks to digital 
technologies. Farmers and agricultural professionals can quickly respond to 
any anticipated changes in environmental and water conditions using real-time 
surveillance and forecasting technologies to save crops [72].
•Green process: By lowering the use of in-field fuel, nitrogen fertilizers, 
pesticides, and herbicides, digital technologies make farming more ecologically 
friendly and climate-resilient [75].
•Resource efficiency: By increasing the quantity and quality of agricultural 
output while reducing the use of water, energy, fertilizers, and pesticides, digital 
platforms can improve resource efficiency [3]. 
445
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
•Time and cost savings: By automating various tasks such as harvesting, sow-
ing, or irrigation, managing the application of fertilizers or pesticides, and sched-
uling irrigation, digital technologies provide significant time and cost savings [76].
•Asset management: digital technologies enable real-time observation of 
farm holdings and equipment, allowing for theft prevention, component re-
placement, and routine maintenance [10].
•Product safety: By eliminating fraud [17, 18] linked to adulteration, coun-
terfeiting, and artificial enhancement, digital technologies maintain appropriate 
farm output and ensure a safe and nutritious supply of agri-food products [69].
4.17. Considerations and future prospects 
The agricultural industry would see major benefits as a result of the planned 
measures. However, the impediments identified in section 5 must be solved first 
in order to make things sustainable for small and medium-scale growers. Some 
of the above hurdles can be mitigated by awareness campaigns emphasizing the 
importance of smart agriculture at every level of the agricultural value chain and 
encouraging novel techniques (such as gamification) to encourage stakeholders 
to take an active role in the digital transformation [9]. Initiatives at the federal 
level, grants and endowments, public-private collaborations, data transparency, 
and regional research efforts can all help overcome potential hurdles. Finally, 
when constructing a smart agriculture system, a roadmap can be used, starting 
with a basic architecture with few components and simpler functionality and 
gradually adding components and functionality to develop a sophisticated sys-
tem with full digitization potential [21]. These issues can pave the road for ag-
riculture 4.0’s successful adoption. The use of explainable artificial intelligence 
to monitor crop development, estimate crop biomass, evaluate crop health, and 
control pests and diseases is one of the future prospects of digital technologies 
in smart agriculture. Explainable AI eliminates the old black-box approach of 
machine learning and allows for a better understanding of the reasoning behind 
any given decision [15]. The use of common semantics and ontologies to de-
scribe big data, as well as the adoption of open standards, has the potential to 
accelerate research and development in the field of smart farming. Similarly, 
5G technology must be thoroughly investigated in order to enable improved 
connectivity and live streaming of crop data [6]. By executing precise crop in-
spections remotely, 5G technology will reduce internet costs and enhance the 
entire user experience of farm management and food safety [77]. It would also 
help to close the gap between stakeholders by keeping them informed about 
crop availability. Finally, blockchain can be used in conjunction with IoT and 
other technologies to address data privacy and security concerns [78]. 
446
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
4.18. Transition to Agriculture 5.0 
The agriculture sector has traditionally had a breakthrough during industri-
al revolutions. Agriculture 4.0 offers significant potential to offset rising food 
demands and prepare for the future by reinforcing agricultural systems with 
WSN, IoT, AI, and other technologies, as formally mentioned in preceding 
sections. While agricultural 4.0 is still being implemented, agriculture 5.0 is 
already being discussed. 
Agriculture 5.0 builds on agriculture 4.0 by incorporating industry 5.0 prin-
ciples to provide healthy, affordable food while also ensuring that the environ-
ments on which life depends are not degraded [79]. Industry 4.0 focuses less 
on the original principles of social fairness and sustainability and more on dig-
italization and AI-driven technologies for increasing efficiency and flexibility, 
the European Commission formally called for the Fifth Industrial Revolution 
(industry 5.0) in 2021 [80]. Industry 5.0 adds to and expands on the industry 4.0 
concepts by emphasizing human-centricity, sustainability, and resiliency [81]. 
It entails improving human-machine collaboration, decreasing environmental 
effect through the circular economy, and designing systems with a high degree 
of robustness to reach an ideal balance of efficiency and productivity. Among 
the enabling technologies of industry are cobots (collaborative robots), smart 
materials with embedded bio-inspired sensors, digital twins, AI, energy efficient 
and secure data management, renewable energy sources, and others 5.0[80].
Farm production efficiency and crop quality can be improved in agriculture 
5.0 settings by delegating repetitive and boring activities to machines and those 
that need critical thinking to humans. For this reason, agricultural cyber physical 
cognitive systems (CPCS) that observe/study the environment and conduct ap-
propriate actions, comparable to those established for the manufacturing sector, 
should be developed. This might include collaborative farm robots that work in 
the fields to aid crop growers with time-consuming operations like seed sowing 
and harvesting. Similarly, digital twins in agriculture 5.0 can add substantial value 
by recognizing technical difficulties in agricultural systems and resolving them 
more quickly, detecting crop illnesses, and producing more accurate crop output 
estimates. This demonstrates that agriculture 5.0 has the potential to pave the way 
for climate-smart, sustainable, and resilient agriculture, but it is still in its infancy. 
5. Conclusions 
Concerns about global food security have heightened the demand for 
next-generation industrial farms and agricultural intensive production systems. 
Digital technologies, such as those given by the Industry 4.0 programme, are at 
447
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
the vanguard of this modern agricultural period, providing a wide range of in-
novative solutions. Disruptive technologies are being integrated into traditional 
agriculture systems by scientists and researchers in order to boost crop yields, 
cut costs, reduce waste, and sustain process inputs. This report includes an SLR 
that discusses the current state of various technologies in the agriculture sector. 
Several findings are drawn, including the fact that big data and analytics inte-
gration, wireless sensor networks, cyber-physical systems, and digital twins in 
agriculture are still in their infancy, with the majority of use cases still in the 
prototype stage. Similarly, 21 technological and socioeconomic impediments 
are found and categorized. These impediments must be identified and addressed 
if the agriculture industry is to be digitalized. The report also identifies and 
presents the additional value of digital technology in the agriculture industry. 
Overall, this research contributes to the ongoing research on agricultural 4.0. 
The review’s principal restriction is twofold: first, only three online reposito-
ries (Scopus, IEEE, and Science Direct) are considered for literature searches, 
and second, new keywords and synonyms may return more papers. The main 
conclusions are highly unlikely to alter in either scenario. Additional research 
databases and areas can be considered for future study in order to provide a 
complete overview of the agriculture industry in terms of digitization. In addi-
tion, papers focusing on agriculture 5.0 in general will be featured.
References
1. F Schierhorn, M. Elferink, Global Demand for Food Is Rising. Can We Meet 
It? Harv Bus Rev, 2016, 7 (2017). https://hbr.org/2016/04/global-demand-for-
food-is-rising-can-we-meet-it
2. Singh, G. Machine Learning Models in Stock Market Prediction. International 
Journal of Innovative Technology and Exploring Engineering, 2022, vol. 11, 
no. 3, pp. 18-28. https://doi.org/10.35940/ijitee.C9733.0111322
3. WK Mok, YX Tan, WN. Chen, Technology innovations for food security in 
Singapore: A case study of future food systems for an increasingly natural re-
source-scarce world, Trends Food Sci Technol, 2020, vol. 102, pp. 155–168, 
https://doi.org/10.1016/j.tifs.2020.06.013
4. Nagar, P., & Issar, G. S. Detection of outliers in stock market using regression 
analysis. International Journal of Emerging Technologies in Computational and 
Applied Science, 2013. https://doi.org/10.5281/zenodo.6047417
5. R Abbasi, P Martinez, R. Ahmad, An ontology model to represent aquapon-
ics 4.0 system’s knowledge, Inf Process Agric, 2021. https://doi.org/10.1016/J.
INPA.2021.12.001
448
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
6. R Abbasi, P Martinez, R. Ahmad, An ontology model to support the automat-
ed design of aquaponic grow beds, Procedia CIRP, 2021, vol. 100, pp. 55–60, 
https://doi.org/10.1016/j.procir.2021.05.009
7. G Aceto, V Persico, A. Pescapé, A Survey on Information and Communication 
Tech- nologies for Industry 4.0: State-of-the-Art, Taxonomies, Perspectives, 
and Challenges, IEEE Commun Surv Tutorials, 2019. https://doi.org/10.1109/
COMST.2019.2938259
8. B. Ozdogan, A. Gacar, H. Aktas. Digital agriculture practices in the context of 
agriculture 4.0. Journal of Economics, Finance and Accounting (JEFA), 2017, 
vol. 4, iss. 2, pp. 184-191. https://doi.org/10.17261/pressacademia.2017.448
9. Y Liu, X Ma, L Shu, GP Hancke, AM. Abu-Mahfouz, From Industry 4.0 to Ag-
riculture 4.0: Current Status, Enabling Technologies, and Research Challenges, 
IEEE Trans Ind Informatics, 2021, vol. 17, no. 6, pp. 4322-4334. https://doi.
org/10.1109/TII.2020.3003910
10. F da Silveira, FH Lermen, FG. Amaral, An overview of agriculture 4.0 devel-
opment: Systematic review of descriptions, technologies, barriers, advantag-
es, and disadvantages, Comput Electron Agric 189 (2021) 106405, https://doi.
org/10.1016/J.COMPAG.2021.106405
11. G Idoje, T Dagiuklas, M. Iqbal, Survey for smart farming technologies: Chal-
lenges and issues, Comput Electr Eng, 2021, vol. 92, 107104. https://doi.
org/10.1016/J.COMPELECENG.2021.107104
12. J Miranda, P Ponce, A Molina, P. Wright, Sensing, smart and sustain- able tech-
nologies for Agri-Food 4.0, Comput Ind, 2019, vol. 108, pp. 21–36. https://doi.
org/10.1016/J.COMPIND.2019.02.002 
13. M Lezoche, H Panetto, J Kacprzyk, JE Hernandez, Alemany Díaz MME. 
Agri-food 4.0: A survey of the supply chains and technologies for the future 
agriculture, Comput Ind, 2020, vol. 117, 103187. https://doi.org/10.1016/J.
COMPIND.2020.103187
14. Bhakta I, Phadikar S, Majumder K. State-of-the-art technologies in precision 
agriculture: a systematic review. Journal of the Science of Food and Agriculture, 
2019, vol. 99, no. 11. pp. 4878-4888. https://doi.org/10.1002/jsfa.9693
15. SO Araújo, RS Peres, J Barata, F Lidon, JC. Ramalho, Characterising the 
Agriculture 4.0 Landscape — Emerging Trends, Challenges and Opportu-
nities, Agron, 2021, vol. 11, no. 4, 667. https://doi.org/10.3390/AGRONO-
MY11040667
16. M Bacco, P Barsocchi, E Ferro, A Gotta, M. Ruggeri, The Digitisation of Agri-
culture: a Survey of Research Activities on Smart Farming, Array, 2019, 3–4, 
100009. https://doi.org/10.1016/j.array.2019.100009
449
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
17. Singh, G., & Nager, P. A case Study on Nutek India Limited Regarding Deep 
Falling in Share Price. Researchers World - Journal of Arts, Science & Com-
merce, 2012, vol. 3(2), 3.
18. Nager, P., & Singh, G. An Analysis of Outliers For Fraud Detection in Indian 
Stock Market. Researchers World - Journal of Arts, Science & Commerce, 2012, 
vol. 3(4), 4.
19. MJ Page, JE McKenzie, PM Bossuyt, I Boutron, TC Hoffmann, CD Mulrow, et 
al., The PRISMA 2020 statement: An updated guideline for reporting systematic 
reviews, BMJ, 2021, 372. https://doi.org/10.1136/BMJ.N71
20. Ahmed MA, Ahsan I, Abbas M. Systematic Literature Review: Ingenious 
Software Project Management while narrowing the impact aspect. RACS ‘16: 
Proceedings of the International Conference on Research in Adaptive and Con-
vergent Systems, 2016, pp. 165–168. https://doi.org/10.1145/2987386.2987422
21. C Pylianidis, S Osinga, IN. Athanasiadis, Introducing digital twins to agricul-
ture, Comput Electron Agric 184 (2021) 105942, https://doi.org/10.1016/J.
COMPAG.2020.105942 
22. Shaikh ZA Aqeel-ur-Rehman, NA Shaikh, N Islam, An integrated framework 
to de- velop context aware sensor grid for agriculture, Aust J Basic Appl Sci, 
2010. 
23. W Shi, J Cao, Q Zhang, Y Li, L. Xu, Edge Computing: Vision and Chal-
lenges, IEEE Internet Things J 3, 2016, 637–646, https://doi.org/10.1109/
JIOT.2016.2579198
24. A Tzounis, N Katsoulas, T Bartzanas, C. Kittas, Internet of Things in agricul- 
ture, recent advances and future challenges, Biosyst Eng, 164, 2017, 31–48, 
https://doi.org/10.1016/J.BIOSYSTEMSENG.2017.09.007
25. VP Kour, S. Arora, Recent Developments of the Internet of Things in Agri- cul-
ture: A Survey, IEEE Access 8, 2020, 129924–129957, https://doi.org/10.1109/
AC- CESS.2020.3009298
26. MU Aftab, O Ashraf, M Irfan, M Majid, A Nisar, MA. Habib, A Review Study 
of Wireless Sensor Networks and Its Security, Commun Netw, 7, 2015, 172–179, 
https://doi.org/10.4236/cn.2015.74016
27. X Yu, P Wu, W Han, Z. Zhang, A survey on wireless sensor network infra-
structure for agriculture, Comput Stand Interfaces, 1, 2013, 59–64, https://doi.
org/10.1016/J.CSI.2012.05.001
28. Mell PM, Grance T. The NIST definition of cloud computing, 2011. https://doi.
org/10.6028/NIST.SP.800-145
29. Alwada’n T. Cloud computing and multi-agent system: monitoring and services. 
2018. 
450
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
30. X Shi, X An, Q Zhao, H Liu, L Xia, X Sun, et al., State-of-the-art inter- net of 
things in protected agriculture, Sensors (Switzerland), 19, 2019, 1833, https://
doi.org/10.3390/s19081833
31. J Wang, H Yue, Z. Zhou, An improved traceability system for food quality assur-
ance and evaluation based on fuzzy classification and neural network, Food Con-
trol, 79, 2017, 363–370, https://doi.org/10.1016/J.FOODCONT.2017.04.013
32. S Fountas, G Carli, CG Sørensen, Z Tsiropoulos, C Cavalaris, A Vatsanidou, et 
al., Farm management information systems: Current situation and future per-
spectives, Comput Electron Agric, 115, 2015, 40–50, https://doi.org/10.1016/J.
COMPAG.2015.05.011
33. A Bechar, C. Vigneault, Agricultural robots for field operations: Concepts and 
components, Biosyst Eng, 149, 2016, 94–111, https://doi.org/10.1016/J.BIO-
SYSTEMSENG.2016.06.014
34. Gonzalez-De-Santos P, Fernández R, Sepúlveda D, Navas E, Armada M. Un- 
manned Ground Vehicles for Smart Farms. Agron - Clim Chang Food Secur, 
2020. https://doi.org/10.5772/INTECHOPEN.90683
35. J del Cerro, CC Ulloa, A Barrientos, L. Rivas J de, Unmanned Aerial Vehicles in 
Agri- culture: A Survey, Agron, 11, 2021, 203, https://doi.org/10.3390/AGRON-
OMY11020203
36. Patel PN, Patel M, Faldu RM, Dave YR. Quadcopter for Agricultural Surveil-
lance, 2013.
37. Sylvester G, Food and Agriculture Organization of the United Nations., International 
Telecommunication Union. E-agriculture in action: drones for agriculture n.d.:112. 
38. U Sivarajah, MM Kamal, Z Irani, V. Weerakkody, Critical analysis of Big Data 
challenges and analytical methods, J Bus Res, 70, 2017, 263–286, https://doi.
org/10.1016/J.JBUSRES.2016.08.001
39. M Chi, A Plaza, JA Benediktsson, Z Sun, J Shen, Y. Zhu, Big Data for Re- 
mote Sensing: Challenges and Opportunities, Proc IEEE, 104, 2016, 2207–2219, 
https://doi.org/10.1109/JPROC.2016.2598228 
40. K Tesfaye, K Sonder, J Caims, C Magorokosho, A Tarekegn, GT Kassie, et al. 
Target- ing drought-tolerant maize varieties in southern Africa: a geospatial crop 
modeling approach using big data, Int Food Agribus Manag Rev, 19, 2016. 
41. R Sharma, SS Kamble, A Gunasekaran, V Kumar, A. Kumar, A system- atic 
literature review on machine learning applications for sustainable agri- culture 
supply chain performance, Comput Oper Res, 119, 2020, 104926, https://doi.
org/10.1016/J.COR.2020.104926
42. T Talaviya, D Shah, N Patel, H Yagnik, M. Shah, Implementation of artifi-
cial intelli- gence in agriculture for optimisation of irrigation and application 
451
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
of pesticides and herbicides, Artif Intell Agric, 4, 2020, 58–73, https://doi.
org/10.1016/J.AIIA.2020.04.002
43. KG Liakos, P Busato, D Moshou, S Pearson, D. Bochtis, Machine Learn- ing in 
Agriculture: A Review, Sensors, 18, 2018, 2674, https://doi.org/10.3390/S18082674
44. G Xu, H Li, S Liu, K Yang, X. Lin, VerifyNet: Secure and Verifiable Federat-
ed Learning, IEEE Trans Inf Forensics Secur, 15, 2020, 911–926, https://doi.
org/10.1109/TIFS.2019.2929409
45. J. Schmidhuber, Deep Learning in Neural Networks: An Overview, Neural Net-
works, 61, 2014, 85–117, https://doi.org/10.1016/j.neunet.2014.09.003 
46. Canziani A, Paszke A, Culurciello E. An Analysis of Deep Neural Network 
Models for Practical Applications, 2016. 
47. A Kamilaris, FX. Prenafeta-Boldu, Deep learning in agriculture: A survey, 
Comput Electron Agric, 147, 2018, 70–90, https://doi.org/10.1016/j.com-
pag.2018.02.016
48. V Kakani, VH Nguyen, BP Kumar, H Kim, VR. Pasupuleti, A critical review on 
computer vision and artificial intelligence in food industry, J Agric Food Res, 2, 
2020, https://doi.org/10.1016/J.JAFR.2020.100033
49. F Terribile, A Agrillo, A Bonfante, G Buscemi, M Colandrea, A D’Antonio, et al., A 
Web-based spatial decision supporting system for land management and soil con-
servation, Solid Earth 6 (2015) 903–928, https://doi.org/10.5194/SE-6-903-2015
50. A Felsberger, B Oberegger, G. Reiner, A Review of Decision Support Systems 
for Manufacturing Systems, Undefined, 2016. 
51. P Taechatanasat, L. Armstrong, Decision Support System Data for Farmer De-
cision Making, ECU Publ Post (2013) 2014 . 
52. L Wang, M Törngren, M. Onori, Current status and advancement of cyber- phys-
ical systems in manufacturing, J Manuf Syst, 37, 2015), 517–527, https://doi.
org/10.1016/J.JMSY.2015.04.008
53. DGS Pivoto, LFF de Almeida, R da Rosa Righi, JJPC Rodrigues, AB Lugli, 
AM. Al- berti, Cyber-physical systems architectures for industrial internet of 
things appli- cations in Industry 4.0: A literature review, J Manuf Syst, 58, 2021, 
176–192, https://doi.org/10.1016/J.JMSY.2020.11.017
54. AF Jimenez, PF Cardenas, F Jimenez, A Canales, A. López, A cyber-physical in-
telli- gent agent for irrigation scheduling in horticultural crops, Comput Electron 
Agric, 178, 2020, 105777, https://doi.org/10.1016/J.COMPAG.2020.105777
55. A Selmani, H Oubehar, M Outanoute, A Ed-Dahhak, M Guerbaoui, A Lach- hab, 
et al., Agricultural cyber-physical system enabled for remote management of 
solar-powered precision irrigation, Biosyst Eng, 177, 2019, 18–30, https://doi.
org/10.1016/J.BIOSYSTEMSENG.2018.06.007
452
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
56. A Nayak, RR Levalle, S Lee, SY. Nof, Resource sharing in cyber-physical sys-
tems: modelling framework and case studies, 54, 2016, 6969–6983, https://doi.
org/10.1080/00207543.2016.1146419
57. C Verdouw, B Tekinerdogan, A Beulens, S. Wolfert, Digital twins in smart farming, 
Agric Syst, 189, 2021, 103046, https://doi.org/10.1016/J.AGSY.2020.103046
58. D Jones, C Snider, A Nassehi, J Yon, B Hicks, Characterising the Digital Twin: 
A systematic literature review, CIRP J Manuf Sci Technol, 29, 2020, 36–52, 
https://doi.org/10.1016/J.CIRPJ.2020.02.002
59. S Aydin, MN. Aydin, Semantic and syntactic interoperability for agricultural 
open- data platforms in the context of IoT using crop-specific trait ontologies, 
Appl Sci, 10, 2020, https://doi.org/10.3390/app10134460
60. Y He, J Guo, X. Zheng, From Surveillance to Digital Twin: Challenges and Re-
cent Advances of Signal Processing for Industrial Internet of Things, IEEE Signal 
Process Mag, 35, 2018, 120–129, https://doi.org/10.1109/MSP.2018.2842228
61. MS Farooq, S Riaz, A Abid, K Abid, MA. Naeem, A Survey on the Role of IoT 
in Agriculture for the Implementation of Smart Farming, IEEE Access, 7, 2019, 
156237–156271, https://doi.org/10.1109/ACCESS.2019.2949703
62. A Villa-Henriksen, GTC Edwards, LA Pesonen, O Green, CAG. Sørensen, In-
ternet of Things in arable farming: Implementation, applications, challenges and 
potential, Biosyst Eng, 191, 2020, 60–84, https://doi.org/10.1016/J.BIOSYSTE-
MSENG.2019.12.013
63. HM Jawad, R Nordin, SK Gharghan, AM Jawad, M. Ismail, Energy-efficient 
wire- less sensor networks for precision agriculture: A review, Sensors (Swit-
zerland), 17, 2017, 1781, https://doi.org/10.3390/s17081781
64. L Sigrist, N Stricker, D Bernath, J Beutel, L. Thiele, Thermoelectric Energy 
Harvesting from Gradients in the Earth Surface, IEEE Trans Ind Electron, 67, 
2020, 9460–9470, https://doi.org/10.1109/TIE.2019.2952796
65. AR Yanes, P Martinez, R. Ahmad, Towards automated aquaponics: A re-
view on monitoring, IoT, and smart systems, J Clean Prod, 2020, https://doi.
org/10.1016/j.jclepro.2020.121571
66. N Brinis, LA. Saidane, Context Aware Wireless Sensor Network Suitable 
for Preci- sion Agriculture, Wirel Sens Netw, 2016, https://doi.org/10.4236/
wsn.2016.81001
67. M Zimmerling, L Mottola, S. Santini, Synchronous Transmissions in Low-Pow-
er Wireless: A Survey of Communication Protocols and Network Services, ACM 
Comput Surv, 53 2021, https://doi.org/10.1145/3410159
68. F Tonolini, F. Adib, Networking across boundaries: Enabling wireless com-
munica- tion through the water-air interface, SIGCOMM 2018 - Proc 2018 
453
Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022
Conf ACM Spec Interes Gr Data Commun, 2018, 117–131, https://doi.
org/10.1145/3230543.3230580
69. L Chen, S Thombre, K Jarvinen, ES Lohan, A Alen-Savikko, H Leppakoski, et al., Ro- 
bustness, Security and Privacy in Location-Based Services for Future IoT: A Survey, 
IEEE Access, 5, 2017, 8956–8977, https://doi.org/10.1109/ACCESS.2017.2695525
70. Y Njah, M. Cheriet, Parallel Route Optimization and Service Assurance in Ener-
gy- Efficient Software-Defined Industrial IoT Networks, IEEE Access, 9, 2021, 
24682–24696, https://doi.org/10.1109/ACCESS.2021.3056931
71. A Rajput, VB. Kumaravelu, Scalable and sustainable wireless sensor networks 
for agricultural application of Internet of things using fuzzy c-means algorithm, 
Sustain Comput Informatics Syst, 22, 2019, 62–74, https://doi.org/10.1016/J.
SUSCOM.2019.02.003
72. BB Sinha, R. Dhanalakshmi, Recent advancements and challenges of Internet 
of Things in smart agriculture: A survey, Futur Gener Comput Syst, 126, 2022, 
169–184, https://doi.org/10.1016/J.FUTURE.2021.08.006
73. F Caffaro, E. Cavallo, The effects of individual variables, farming system char-
acter- istics and perceived barriers on actual use of smart farming technologies: 
Evidence from the piedmont region, northwestern Italy, Agric, 9, 2019, https://
doi.org/10.3390/AGRI- CULTURE9050111 
74. Mohit Jain, Pratyush Kumar, Ishita Bhansali, Q. Vera Liao, Khai Truong, 
Shwetak Patel. FarmChat: A Conversational Agent to Answer Farmer Que-
ries. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiq-
uitous Technologies, 2018, vol. 2, issue 4, article 170, pp 1–22. https://doi.
org/10.1145/3287048
75. Mclaughlan B, Brandli J, Smith F. Toward Sustainable High-Yield Agriculture 
via Intelligent Control Systems, 2015. 
76. RK Kodali, S Soratkal, L. Boppana, IOT based control of appliances, in: Pro-
ceeding - IEEE Int Conf Comput Commun Autom ICCCA 2016, 2017, pp. 
1293–1297, https://doi.org/10.1109/CCAA.2016.7813918
77. Abbasi R, Reyes A, Martinez E, Ahmad R. Real-time implementation of digital 
twin for robot based production line n.d.:4–6. 
78. O Bermeo-Almeida, M Cardenas-Rodriguez, T Samaniego-Cobo, E Ferruzo-
la- Gómez, R Cabezas-Cabezas, W. Bazán-Vera, Blockchain in Agriculture: A 
Systematic Literature Review, Commun Comput Inf Sci, 883, 2018, 44–56, 
https://doi.org/10.1007/978-3-030-00940-3_4
79. V Saiz-Rubio, F. Rovira-Más, From Smart Farming towards Agriculture 5.0: 
A Review on Crop Data Management, Agron, 10, 2020, 207, https://doi.
org/10.3390/AGRONOMY10020207
454
Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022
80. X Xu, Y Lu, B Vogel-Heuser, L. Wang, Industry 4.0 and Industry 5.0 – Incep-
tion, conception and perception, J Manuf Syst, 61, 2021, 530–535, https://doi.
org/10.1016/J.JMSY.2021.10.006
81. PKR Maddikunta, Q-V Pham, P B, N Deepa, K Dev, TR Gadekallu, et al., In-
dustry 5.0: A survey on enabling technologies and potential applications, J Ind 
Inf Integr, 2021, 100257, https://doi.org/10.1016/J.JII.2021.100257
DATA ABOUT THE AUTHORS
Gurjeet Singh, Associate Professor& Dean, Lords School of Computer Ap-
plications & IT
 
Lords University
 
Alwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan
 
research.gurjeet@gmail.com
Naresh Kalra, Deputy Registrar (Research), Faculty of Pharmacy
 
Lords University
 
Alwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan
 
naresh.kalra@lordsuni.edu.in
Neetu Yadav, Associate Professor& Dean, Lords School of Social Sciences 
& Humanities
 
Lords University
 
Alwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan
 
neetu.yadav@lordsuni.edu.in
Ashwani Sharma, Assistant Professor, Lords School of Computer Applica-
tions & IT
 
Lords University
 
Alwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan
 
ashwani.sharma@lordsuni.edu.in
Ashwani Sharma, Assistant Professor, Lords School of Computer Applica-
tions & IT
 
Lords University
 
Alwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan
 
manoj.saini@lordsuni.edu.in 
Поступила 21.05.2022 
Received 21.05.2022
После рецензирования 21.06.2022 
Revised 21.06.2022
Принята 03.07.2022 
Accepted 03.07.2022


Paper 3:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: "Cloud computing has been widely adopted in Agriculture 4.0 to efficiently manage the massive amount of data generated by sensors deployed in the field.
However, cloud computing architectures are not well suited for real-time applications that require low latency and high reliability.
  Extract 2: Despite the benefits of cloud computing, its limitations and the need for real-time data processing have encouraged the use of fog and edge computing in Agriculture 4.0.
  Limitations: The paper only considers architectures that use fog computing or distributed architectures. It does not consider other architectures that may be relevant to the domain of real-time automated irrigation management.
  Relevance Evaluation: Relevant
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: This paper aims to provide a comprehensive review of the current state and future potential of real-time automated systems for irrigation management, with a particular focus on the use of fog computing and distributed architectures to address the specific requirements of the agricultural domain. The paper includes a concise summary of key points from the reviewed literature, as well as a succinct evaluation of the relevance of the paper to the specific point under discussion.

 Full Text: >
Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Related works 3. Methodology 4. Architectures 5. New trends 6. Towards Agriculture 5.0 7. Conclusion Declaration of Competing Interest Acknowledgment References Show full outline Cited by (28) Figures (14) Show 8 more figures Tables (17) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Journal of King Saud University - Computer and Information Sciences Volume 34, Issue 9, October 2022, Pages 7494-7514 Cloud and distributed architectures for data management in agriculture 4.0 : Review and future trends Author links open overlay panel Olivier Debauche a b c, Saïd Mahmoudi a, Pierre Manneback a, Frédéric Lebeau b c Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.jksuci.2021.09.015 Get rights and content Under a Creative Commons license open access Highlights • Cloud architectures used in Agriculture 4.0. • Distributed Architectures and Cloud Computing complements. • Strategies of association between Edge, Fog, Cloud. • New architectural and computing trends. Abstract The Agriculture 4.0, also called Smart Agriculture or Smart Farming, is at the origin of the production of a huge amount of data that must be collected, stored, and processed in a very short time. Processing this massive quantity of data needs to use specific infrastructure that use adapted IoT architectures. Our review offers a comparative panorama of Central Cloud, Distributed Cloud Architectures, Collaborative Computing Strategies, and new trends used in the context of Agriculture 4.0. In this review, we try to answer 4 research questions: (1) Which storage and processing architectures are best suited to Agriculture 4.0 applications and respond to its peculiarities? (2) Can generic architectures meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal development possibilities that allow the transition from research to industrialization? (4) What are the vertical valuations possibilities to move from algorithms trained in the cloud to embedded or stand-alone products? For this, we compare architectures with 8 criteria (User Proximity, Latency & Jitter, Network stability, high throughput, Reliability, Scalability, Cost Effectiveness, Maintainability), and analyze the advantages and disadvantages of each of them. Graphical abstract Download : Download high-res image (103KB) Download : Download full-size image Previous article in issue Next article in issue Keywords Agriculture 4.0Smart farmingSmart agricultureLambda architectureKappa architectureEdge computingFog computingMicro-service architectureData lakeData houseBlockchainOsmotic computingDew computing 1. Introduction Nowadays, the Internet of Things (IoT), also formerly named pervasive Internet, is present in all domains of our daily life and follows exponential growth. The number of connected devices is estimated at the horizon of 2022 at 42.5 billion and at the horizon of 2025 at 75.5 billion1. The global IP traffic is estimated to 333 ZB per month in 20222 with the need to store and treat this data (Carnevale et al., 2019). The European Commission has predicted that 18 billion of 29 billion connected devices will be related to the IoT in 2022 (Agency, 2020). Cisco in a white paper has announced that connected devices to the Internet will generate 850 ZB/year by 2021 (Cisco, 2018). It is difficult to precisely determine the number of connected devices on a world scale, but their number is about several billion. In addition, McKinsey Global Institute predicts a total economic impact of IoT and Edge Computing devices that will reach 11 trillion USD by 2025 (Manyika and Chui, 2015). In the sector of the agriculture, nearly 12 million agricultural sensors installed globally by 2023 with an increase of 20% annually, which is predicted by the Business Insider Intelligence Service (Meola, 2021). Moreover, the smart agriculture business was estimated at USD 13.8 billion in 2020 and is projected to reach USD 22 billion by 2025 at a Compound Annual Growth Rate (CAGR) of 9.8% (Meola, 2021). Within the IoT era, the type of clients is becoming increasingly lightweight. IoT devices and the network environment is gradually changing from high-speed wired networks to unstable wireless communication. Meanwhile, users' demand IoT applications is also shifting to real-time and context-aware service provisioning, making the focus moving progressively from the cloud to the edge (Ren et al., 2017). The cloud is located within the Internet and is geographically centralized, is constituted of a few resourceful server nodes, and is inserted in multi hops in terms of distance among the clients (Munir et al., 2017). Cloud Computing (CC) is a paradigm widely available that offers benefits like minimal management effort, convenience, rapid elasticity, pay per use, ubiquity (Ai et al., 2018), easy maintenance, centralized management, and high server utilization (Shi et al., 2016). Furthermore, resources centralization implies an increase of average network latency, heavy bandwidth utilization, and high processing delay. Indeed, the tremendous amount of data handled in a unique server point can create congestion in the cloud servers and backhaul links (El-Sayed et al., 2017). Nevertheless, the rapid parallel development of the pervasive intelligent device, ubiquitous network, growth in popularity of virtual and augmented reality, self-driving vehicles, UAVs, social networks, networks applications, and services are not without consequences. As a matter of fact, the network bandwidth and speed limit performance and effectiveness of cloud computing especially for real-time and mission-critical applications cannot be guaranteed. Moreover, cloud computing can be hardly adapted or applied to various types of technologies and applications scenarios (Zhou et al., 2017). To address these issues, various extensions of central cloud computing have been proposed by industrial and academics to move computing and storage at the edge of the network close to users. Fog computing uses network elements between the central cloud and the edge of network and absolute edge elements such as microcontrollers close to sensors to process and store data with a distributed manner close to nodes. Whereas, with the developments of mobile devices, some new paradigms close to mobiles users have been proposed. For example, cloudlets or micro data centers are geographically implanted and accessible by means of Wi-Fi protocols; but, this approach does not always guarantee enough network quality. Manufacturers of cellular network equipment have proposed the Mobile Edge Computing (MEC) paradigm that associates fog servers with base stations to provide services to mobile devices. MEC associated with 5G allows to combine an ultra-low latency network with high available bandwidth, and processing resources accessible in the vicinity. The MEC original concept has been extended then to wireless networks and consequently renamed in “Multi-access Edge Computing” (Wang et al., 2020). Agriculture has previously undergone two waves of revolution. The first one was mechanization and the second was called the green revolution with genetic modifications (Saiz-Rubio and Rovira-Más, 2020). Since the late 1990s, the digital transformation of the agriculture in Agriculture 3.0 also called Precision Agriculture has begun with the integration of Geographical Information System (GIS), Global Positioning Systems (GPS), and the usage of sensors have invaded agriculture. They allowed the emergency of image processing, techniques using deep learning, and machine learning in the field of computer vision. This latter is implemented to discriminate weed, identify crops, detect diseases,…etc. The production of a large amount of data by agriculture 3.0 has required the development of big data technologies to process them, reflecting important changes in various fields of research. Collected data must be recorded in a specific format in order to discover patterns, curate errors, eliminate duplicated or inconsistent data, or solve noise problems (Triantafyllou et al., 2019). Smart Farming also called Smart Agriculture or Agriculture 4.0 is a domain of IoT in full growth which bring innovative paths to improve the adaptability, the efficiency, and the resilience of the agriculture of production systems (Iaksch et al., 2021) boost competitiveness and profit (Triantafyllou et al., 2019), allocate resources reasonably, and avoid food waste (Zhai et al., 2020, Wolfert et al., 2017) thanks to the contribution of autonomous context awareness provided by sensors and the capability to execute autonomous or remote actions (Wolfert et al., 2017). Smart Farming displaces the strict application from the farm location to affect related fields such as decision making by farmers, biodiversity, supply chains management, food availability and quality, insurance, and research in environment and earth sciences,… Smart Farming is distinct from other domains of the Internet of Things (IoT) by the observation and action of biological objects (animals or plants). It differs from medical IoT by the fact that there are no issues related to privacy; but, the confidentiality of data is related to production processes. Like most areas of the IoT, Wireless Sensing and Actuating Network (WSAN) use Low-power and Lossy Network organized in hierarchical routing to collect data and actuate devices. Multi-path routing protocols can also be implemented to balance the data transfer load and conserve the energy of limited battery life, basic computational skills, unique communication identifier, and resources-constrained nodes. Due to the limited battery life, it is difficult and sometimes impossible to recharge or replace (Debauche et al., 2021). Moreover, energy-saving and ambient energy techniques must be applied to deal with the active and inactive operational time and schedule information transmission (Triantafyllou et al., 2019). To which objects can be added like connected agricultural vehicles, milking robots, Unmanned Aerial Vehicle (UAV) commonly known as drones, Unmanned Ground Vehicle (UGV) also called robots, mobile devices such as tablets used to encode punctual observations (Debauche et al., 2021), and external sources such as public geo-services (Triantafyllou et al., 2019). The use of IoT in agriculture 4.0 ranges from family farming as for example in India on a very small scale with a few low-cost sensors and actuators to very large scales with thousands of expensive commercial sensors and many connected agricultural pieces of machineries as in the American mid-west. Smart Farming is characterized as aforementioned by a wide variety of objects that can produce the highly contrasted amounts of data from few bytes/s to Gb/s. In addition, the availability of network protocols in rural areas to transmit this data impact also the type of architecture to implement. Applications need treatments in real-time and/or at a different time. The ”real-time” requirements are also very variable depending on the use case. For instance, remote control of drones requires reaction times of at most a few milliseconds while the Variable Rate Fertilizer (VRF) or Variable Spraying (VS) application aim to optimize nutrients and herbicides application respectively need reaction time in a range of few milliseconds to few seconds. The real-time processing for monitoring a herd of cattle is of the order of a few minutes to a few hours. The data retention time is very variable and is highly dependent on each use case. For example, UAVs produce tremendous quantities of images to transfer to the cloud in real-time where they must be quickly processed and stored. They can also be post-processed to extract additional data in batch processing. While UGVs images lose their value after processing and eventually actuating. However, if data is of a special, new or exceptional nature, it can be stored with a view, for example, to improving artificial intelligence algorithms. Other sensors transmit data only when anomalies are detected while others transmit at regular intervals a tiny amount of data. However, the adoption of Smart Farming is hampered by the lack of models to guide stakeholders on how to implement and to deploy dense and heterogeneous IoT-based monitoring systems and manage their interoperability (Triantafyllou et al., 2019). Commercial sensors are very expensive making it impossible for small farms to implement them (Garcia et al., 2020). In addition, two trends are currently opposed. That coming from the manufacturers of agricultural machinery who have developed their ecosystems and who want to extend the services offered to farmers by attracting them into the captive ecosystems in which they are locked. Furthermore, another trend is the development of open ecosystems in which farmers can preserve the ownership of their data and keep control of the processing carried out on this data and of their use. On one hand, farmers are therefore faced with a dilemma where they are in any case forced to use agricultural equipment that collects their data against their will; on the other hand, they want to keep control of their data collected through IoT sensors. Currently, it is difficult to predict which of these two trends will take precedence over the other or whether one of the two will coexist (Wolfert et al., 2017). In this context, both private and public researchers can either use generic commercial platforms offered by cloud players on which they have limited possibilities of adaptation or develop their own architecture on the basis of commercial or free bricks, but with much greater possibilities of adaptation. In this case, the choice is also delicate, and a bad evaluation of the constraints can jeopardize the research project. Due to the recent advances in big data, we present a survey that provides an overview of the state of the art regarding Smart Farming. It aims at summarizing parameters that condition the choice of architecture to collect, process, and store agricultural data. Since there is a wide variety of use cases, it is important to make an informed choice when it comes to architecture. In this way, we address the current gap in the literature with a review of cloud architecture used in Agriculture 4.0 to collect, process, and store data to enlighten the reader about the possible choices and the new trends that emerge. The rest of this paper is structured as follows: The second section is composed of two parts. In the first part, we summarize related previous review in the domain and their contributions, in order to contextualize our contribution to the literature. In the second part, we identify architectures implemented in Agriculture 4.0 use cases. In the third section, we describe the methodology used to identify papers, the conceptual framework used to analyze the literature, and the criteria used to compare the selected architectures. In the fourth section, we present architectures used to collect, process, and store data. We describe successively the cloud-centric architectures, the extension of cloud paradigm, the distributed architecture. In the fifth section, new trends and futures directions are presented. In the sixth section, we discuss the future evolution of Agriculture 4.0 to Agriculture 5.0. Finally, the last section concludes this paper with recommendations and perspectives. 2. Related works We begin our review by identifying the previous review realized in the field of Internet of Things applied to Smart Agriculture to take stock of the state of art and highlighting aspects that have not been explored at the present time. In this section, we focus to achieve two objectives. The first aims to position our work in relation to the existing literature. The second aims to identify architectures commonly used in the case of applications in Agriculture 4.0. 2.1. Previous reviews Reviewed papers presented in Table 1 were selected in the timeframe from January 2017 to July 2021. The major contribution of each paper was extracted and highlighted to show our contribution to the literature. Table 1. Summary of previous review achieved on big data management in a context of Smart Farming. Major Contribution Reference Survey of agro-industrial and environmental solutions for monitoring, control, logistics, and prediction. (Talavera et al., 2017) Diagnosis and analysis of existing IoT deployments in regards to communication protocols. (Ray, 2017) Survey of IoT technologies in agriculture and highlighted the challenges going forward. (Tzounis et al., 2017) Identification of IoT challenges, its application in smart agriculture, and presentation of trends and technological innovation (Elijah et al., 2018) Review of IoT applications in Precision Agriculture, evaluation of previous contributions by researchers, and pathways to future innovation (Khanna and Kaur, 2019) Review of IoT deployment in protected agriculture, identification of its challenges, and prospection of the new research domain. (Shi et al., 2019) Review of existing IoT-based precision agriculture solutions for further achievement. (Ruan et al., 2019) Review, comparison, prospection, and challenges of wireless communication technologies applications in the field of Precision Agriculture. (Feng et al., 2019) Review, case study, and challenges of WSN in environmental behavior. (Shafi et al., 2019) Review, identification, challenges of current and future trends of IoT agriculture. (Ayaz et al., 2019) Survey of IoTbased agriculture, presentation of connection between IoT, big data, and cloud computing, regulation and policies of IoT, and its application in the field of agriculture. (Farooq et al., 2019) Survey of the use of UAVs, an overview of PA, and investigation of 20 UAV applications. (Radoglou-Grammatikis et al., 2020) Challenges of IoT-based agriculture architecture, a summary of existing surveys of smart agriculture. and classification of threats models, study, analysis of challenges and future works of security and privacy of green IoT-based agriculture. (Ferrag et al., 2020) Discuss the role of IoT and big data analysis in agriculture with an emphasis on the commercial status of applications and translational research outcomes. (Misra et al., 2020) resent different solutions to address IoT in arable farming challenges. (Villa-Henriksen et al., 2020) Systematic review presenting how IoT is used with smart farming (Navarro et al., 2020) Methodological review and analysis of IoT components and their applications in smart farming. (Debauche et al., 2021) Review of emerging technologies towards agriculture 4.0 and new pathways to agricultural practitioners. (Liu et al., 2020) Review, classification, presentation, comparison, and challenges of emerging technologies for IoT-based agriculture. (Friha et al., 2021) In the following paragraphs, we will draw a panoramic summary of the existing reviews during the past four years (2017–2021). In 2017, Ray (Ray, 2017) reviewed throughout his paper IoT applications and the challenges that have been faced while IoT deployment to improve farming. Talavera. et al. (Talavera et al., 2017) reviewed agro-industrial and environmental applications that are using the Internet of Things (IoT) for monitoring, control, logistics, and prediction. Tzounis et al. conducted a survey of IoT technologies in agriculture and the challenges that farmers face going forward (Tzounis et al., 2017). Elijah et al. identified the most encountered challenges in the field of IoT applications in smart agriculture and presented common trends for innovative ideas (Elijah et al., 2018). In 2019, Ayaz et al. provided a state-of-art about IoT-based architectures applied in agriculture and identified present and future trends in the same field of study (Ayaz et al., 2019). Farooq et al. presented the ingredients of IoT-based smart farming with used technologies that apply the utilization of network architecture and protocols; in addition to that, they provided an overview of the regulations and policies of the use of IoT in farming regarding security and privacy. They concluded their study by summarizing the main challenges encountered in this discipline (Farooq et al., 2019). Feng et al. provided an overview of the wireless communication technologies in the precision agriculture domain. They benchmarked the prospection and challenges of existing technologies with the regular communication time used (Feng et al., 2019). Shafi et al. conducted a literature review about IoT-based automation of agriculture along with Wireless Sensor Network (WSN). These authors presented a case study based upon two models: 1- a WSN to monitor real-time crop of health conditions, 2- system-base remote sensing imagery to classification between healthy and unhealthy yield (Shafi et al., 2019). In terms of agriculture protection, Shi et al. drew a panoramic review during the last decade to address the challenge and future works to further the research in the field of protected agriculture (Shi et al., 2019). Khanna et Kaur called into an evolutionary scenario to highlight the most significant impact of IoT in Precision Agriculture (PA). They evaluated the contribution of their predecessors and enhanced the challenges to open up a new direction of inspiration and innovation in IoT applied to PA (Khanna and Kaur, 2019). Ruan et al. reviewed literature works from 2009 to 2018 to suggest new ideas for folks interested to conduct research in the field of agriculture IoT, infrastructures, data security, and data sharing (Ruan et al., 2019). In 2020, two studies have been carried out about 20 UAV applications that are devoted to either aerial crop monitoring processes or spraying tasks (Radoglou-Grammatikis et al., 2020) and about the dilemmas that researchers must overcome while deploying IoT in the green agriculture domain (Ferrag et al., 2020). Villa-Henriksen et al. identified different challenges encountered during the implementation of IoT in various applications and proposed different solutions to address them (Villa-Henriksen et al., 2020). Misra et al. discuss the role of IoT and big data analysis in Smart Farming (Misra et al., 2020). In 2021, a recent study conducted by Friha et al. hypothesize the use, application, classification, and comparison of the most developed emerging technologies such as Internet of Things (IoT), Unmanned Aerial Vehicles (UAV), Wireless Technologies, open-source IoT platforms, Software Defined Networking (SDN), Network Function Virtualization (NFV) technologies, cloud/fog computing, and middleware platforms (Friha et al., 2021). In the same year, Debauche et al. conducted a literature review to describe the main components of IoT and its applications in the field of Smart Farming (Debauche et al., 2021). 2.2. Platforms implemented in use cases We grouped applications into 4 categories: (1) Water Management in which we have aggregate all types of water use such as irrigation and watering animals. (2) Plant Disease and Pest groups all use cases in plant’s pathologies detection and treatment of plant pathologies (spraying of fungicides, pesticides, etc). (3) Crop Management brings together all the use cases relating to cropping operations: soil management (plowing, fertilizer application), sowing, weeding, and harvesting. (4) Livestock includes everything related to the breeding of farm animals (nutrition, behavior, diseases, treatments). Table 2 summarizes platform used to implement use cases in Smart Farming classified following our four categories. Table 2. Summary of cloud platforms, databases mentioned in Smart Farming reviews. Empty Cell Water Management Plant Diseases & Pest Crop Management Livestock Reference IoT platform Thingspeak x (Maureira et al., 2011) FIWARE x (Rodriguez et al., 2018) NETPIE x x (NECTEC, 2020) Ubidots x (Ubidots, 2021) SmartFarmNET x x (Jayaraman et al., 2016) Thinger.io x x (Luis Bustamante et al., 2019) Kaa IoT Platform x x (KaaIoT, 2021) IBM Watson IoT Platform x x x x (IBM, 2015) Microsoft Azure IoT Platform x x x (Microsoft, 2021b) AT&T M2X Cloud x (AT&T, 2021) Blynk x (Blynk, 2021) MACQU x (Sigrimis et al., 2002) ERMES x (Granell et al., 2017) Agrocloud x x x (Kodati and Jeeva, 2019) CropInfra x (Pesonen et al., 2014) SensorCloud x (Corp, 2020) LoRaFarM x x x (Codeluppi et al., 2020)  Cloud platform Amazon Web Service x x x x (Amazon, 2021b) IBM Cloud x x x x (IBM, 2021) Microsoft Azure x x x x (Microsoft, 2021a) Integra x x (Souces and I., 2021)  Cloud Database DynamoDB x x x (Amazon, 2021) MongoDB Atlas x x x (Mongo, 2021) Firebase x x x (Google, 2021) InfluxDB Cloud x x x (Influxdata, 2021)  Local Database MySQL x (Oracle, 2021) SQLite x (SQLite, 2021) PostgreSQL/PostGIS x x (The PostgreSQL Global Development Group, 2021) Apache Cassandara x (Apache Software Foundation, 2021a) Apache Druid x x (Apache Software Foundation, 2021b) Garcia et al. give an overview on trends in Smart Irrigation in which they showed that data is stored in the database or in the cloud. On 151 reviewed papers, one uses Raspberry Pi, 18 databases, 53 clouds, and 79 are self-developed or not mentioned (Garcia et al., 2020). Navarro et al. identified 21 Platforms used in 50 various use cases classified into 5 categories: Artificial Intelligence, Big Data, Machine Learning, Computer Vision, and Other/Not Identified (Navarro et al., 2020). Jayaraman et al. present SmartFarmNet, an IoT platform offering effortless integration of sensors, supporting scalable data analytics, and proposing do-it-yourself tools to analyze and visualize data (Jayaraman et al., 2016). Codeluppi et al. describe LoRaFarM a general architecture modulated depending on the farm’s characteristics and requirements (Codeluppi et al., 2020). The monitoring of crops particularly more sensitive to them as saffron is crucial. The DIAS Architecture (Triantafyllou et al., 2019) uses different ground and leaf sensors to monitor the real-time 24/24 h cultivation process of saffron. This data is transmitted by LoRaWAN with IPv6 protocol and MQTT-SN protocol to FIWARE’s context broker. The broker manages all networking devices by means of sixteen types of messages exchanged following publish-subscribe model. The FIWARE NGSI API of oversees the consumption, subscription, and processing of all the information collected and its publication. Afterward, the data is stored and analyzed with a random forest algorithm which allows extracting information about the crop growth and health. Vegetation indexes: Normalized Difference Index (NDI), Excess Greenness Index (ExG) are calculated with PiX4D3 image processing tools. Object-based image analysis (OBIA) is used to recognize weeds or discriminate species. Finally, collected data are categorized and evaluated accordingly with vegetation index values, moisture level, and plant developing state by means of the Apache Spark framework for the Big Data analysis and Waikato Environment (WEKA) a framework specialized in data mining to produce reports and predictions. Decision-making is a very important task in the farmers’ activities but with the amount of data always increasing, they encounter difficulties on one hand to make proper decision about agricultural management and on the other hand translate this data into practical knowledge (Zhai et al., 2020). On the other hand, there is a need for platforms of the Agricultural Decision Support System (ADSS) to assist farmers to make precise decisions evidence-based. For example, Watson Decision Platform for Agriculture combines IBM Watson with IoT and Cloud Computing to detect crop disease from UAV images. It is also possible to optimize time for crop operations to obtain a better price on trading market. The second example is Digital Farming System4 takes advantage of computer vision, cloud computing, and AI to propose a better timing for corp operations, notify when a crop is infected by any disease. Smart Irrigation Decision Support System (SIDSS) is composed on one hand of a set of sensors and a weather station and on the other hand a DSS based on two machine learning algorithms. Partial Least Squares Regression (PLSR) to deduct unnecessary variables and Adaptive Neuro -Fuzzy Inference Systems (ANFIS) used to minimize estimated errors under a target threshold (Navarro-Hellin et al., 2016). SIDSS generates planning of water amount and time for irrigation. Multi-robot sense-act system (Conesa-Munoz et al., 2016) is a planner of aerial and ground vehicles which assign tasks to the most appropriate work units. A Harmony Search Algorithm is used to optimize plans for UAVs while meta heuristic is running for ground vehicles. 2.3. Analysis of previous literature The analysis of existing reviews about smart farming shows that applications use whether open source or commercial cloud architecture whether developing specific architecture responding to their aims or do not describe their storage and processing system. The latter represents more than half of the papers and means that some of the processing architectures remain unknown because they have never been specifically described and studied. Moreover, the fact that further development is being made in architecture may be the fact that commercial platforms do not fully address the needs of Agriculture 4.0. This brings us to our research questions and their respective motivation: 1. Which storage and processing architectures are best suited to Agriculture 4.0 applications and address its particularities? Motivation: On one hand generic architectures dedicated or not to IoT are able to address a large number of use cases but not specifically the needs of Agriculture 4.0 exist. On the other hand, researchers develop architectures to address specific issues or requirements of use cases. The selection of an adapted architecture is crucial for the correct implementation of identified use cases. 2. Can generic architectures meet the needs of Agriculture 4.0 application cases? Motivation: Agriculture 4.0 has specific requirements described in the introduction section which cannot all be addressed by a single classical generic architecture. A comparison between the pros and the cons of major generic architecture in the context of agriculture 4.0 is important to highlight the choice during the conceptualization step. 3. What are the horizontal valuation possibilities that allow the transition from research to industrialization? Motivation: The use of architectural solutions which can be for example free of fees during the research phase but needs a reimplementation caused by license limitations, the cost of the license in the use cases budget, etc. The use of products in closed or semi-closed ecosystems is a barrier to the research valuation. 4. What are the vertical valuation possibilities to move from algorithms trained in the cloud to embedded or autonomous products? Motivation: The massive collection of data in the cloud allows to development of complex algorithms that need a large amount of computing resources to be elaborated. Afterward, they can be compressed, reduced, optimized in order to be deployed in embedded devices or divided and establish a collaboration between devices and computing resources such as cloud, fog, etc. In order to answer these questions, a review of the literature will make it possible to synthesize the different approaches currently used, to identify new trends and to consider new lines of research to be explored. 3. Methodology In order to address, our first and second research questions, we achieve a systematic review to identify generic architectures and combination of architectural elements used by researchers to implement concrete use cases. Moreover, we attempt also identify commercial products and existing services/ platforms used to implement projects in agriculture. 3.1. Systematic review methodology The research questions outlined at the end of the related work section has been addressed by combining keywords of the first group that refers to architectures (i.e. cloud architecture, distributed architecture, big data, Internet of Things, IoT) and of the second group contained keywords related to agriculture (i.e. agriculture, smart farming, food, agri-food, precision agriculture). Our methodology is based on 3 consecutive steps: literature identification, reading literature, and information extraction. During the first step, we have read and have collected individual papers based on the achieved of previous papers. We have reviewed and completed by a systematic survey of white literature (full articles and conference papers) from January 2016 to December 2020. In addition, we targeted solely and exclusively papers written in English and focusing on architecture design have been considered. Our bibliographic review was limited to the last 5 years because the rapid development of IoT. The systematic review was retrieved from the following major bibliographic databases: Scopus (Elsevier), IEEE Xplore Digital Library, Wiley Online Library, ACM Digital Library, and Springer. These bibliographic databases have been chosen widely covering relevant bibliography and relevant advanced bibliometric features especially number of citation and relevant literature suggestion. From these databases 1058 peer-reviewed articles were retrieved. After their screening 55 papers were classified relevant while remaining articles were considerate not relevant and therefore excluded from further reading and analysis. The high number of excluded papers is due to numerous papers describe i.e. conceptual or theoretic architectures which were never implemented, experimental architectures that have been the subject of a single article or that have never been proven by other research teams. We discard also papers that were not a directly related Big data and the agricultural sector. Table 3. Table 3. Keywords used for achieved the systematic review. Area Keywords Related concepts Agriculture Agriculture, Agricultural e-Agriculture Agri-Food Agribusiness Smart Farming Farming Precision Agriculture, Precision Farming  Internet of things IoT, Internet of Things, internet-of-things Big data Big Data Big Data Data Management Data Management Architecture Cloud Architecture, Distributed Architecture In a second step, we included English grey literature (reports, blogs, magazines, and web-items) into our review using Web of Science and Google Scholar. Table 4. We discarded papers that were written in other languages than English, Master and doctoral dissertation, and duplicated articles gathered from Google Scholar. Afterward, we have selected literature that has carefully been read in detail to extract relevant information of research questions. The extracted information was analyzed and summarized in a conceptual framework illustrated in the Fig. 1. Table 4. Sources of collected literature. Data source URL IEEE Xplore Digital Library https://ieeexplore.ieee.org Scopus https://www.scopus.com Springer https://link.springer.com/search Wiley Online Library https://onlinelibrary.wiley.com Google Scholar https://scholar.google.com Web of Science https://publons.com/publon ACM Digital Library https://dl.acm.org Download : Download high-res image (171KB) Download : Download full-size image Fig. 1. Conceptual framework of data processing. Three ways of treatment of data are possible. The first process data in real-time (left branch identified by (1) on Fig. 1), this one is generally not stored except eventually particular or exceptional data in order to enrich the training database of artificial intelligence algorithms. This way of data treatment is used for example by robots that inspect a crop, discover a pest, and then eliminate it. After intervention the value data is near null. The second way is a mixed way in which data must be processed as quickly as possible. This one addresses use cases where latency required must be comprised between few milliseconds to few seconds with data, which conserves a value during a certain period of time. This latter justifies its storage according to the use case data management plan that predicts the time after which the data will be aggregated and then deleted. This way in identified by (2) on Fig. 1. It addresses use cases where all data must be processed and then stored for eventual post-processing for example to estimate trends of parameters such as the milk quality, volume of palatable species available in a pasture. The third way is stored data theirs native format without transformation (Identified by (3) on Fig. 1). This way is implemented on use cases that do not require real time processing or use cases where the amount data is so important, which makes treatment impossible. In this latter case, data are consumed by micro services that sample data to exact knowledge. This way is also employed for data which have a low value or lose their value so quickly that there is no point in transforming them for long-term storage. For instance, a UGV identifies and eliminates a pest. The image of the insect is no longer relevant after its elimination. 3.2. Architecture comparison criteria In order to compare selected architectures, we chose to select 8 criteria:(1) User Proximity expresses the necessity to be close to the user. This criterion is important for applications where privacy and response time to query are critical. Attribute a value of one * when privacy is not crucial; ** when the proximity with user is desirable but not crucial for the development of the use case; *** when the user proximity is the corner stone of the application. (2) Latency & Jitter criterion describes the importance for the architecture to have a minimal latency and jitter. This criterion is particularly important for use cases where response time to query in quasi (real time) is required and/or time between data production and ingestion by the processing and storage architecture is essential. (3) Network stability criterion translate the necessity to have a stable network or if is interruption can be tolerated. Use a value of * if the use case implemented can tolerate the absence of network during few hours; ** if few minutes of interruption are tolerable; *** is stability of the network is an essential element of the use case. (4) The high throughput criterion expresses the capability of the architecture to process quickly a wide amount of data arriving at high frequency; Use a value of * if the data arrive mostly at regular intervals; a value of ** if the data arrive in bursts, and *** if the data arrive continuously at high frequency ( 10 Hz). (5) Reliability is a criterion that expresses if the infrastructure is critical in other terms whether an interruption in infrastructure could cause loss of life or not. Attribute a weight of * if the data is not critical and potential damages caused by an interruption of the architecture are minors or null; ** if potential damageable but tolerable if they occur more than once a year; *** if the application cannot tolerate any interruption which would cause irreversible damage or loss of human life. (6) Scalability is a criterion that expresses the regularity of the evolution in terms of processing and storage during a period of one year. If the scalability must be achieved at most once a year use a weight of *; if the scalability is achieved at most twice a year use **; if the scalability must be achieved more than two times by year use a weight of ***. (7) Cost-Effectiveness criterion reflects the need to control infrastructure costs. This criterion is more important as the infrastructure is brought to evolve both in terms of scale and complexity. Use the weight of * if the project will remain in a relatively constant size and do not need to be scaled or dramatically modified; Use **, if the project evolves reasonably, i.e. should not undergo significant modification more than once a year. Use a weight of *** if the size of the project and/ or its complexity need a fine study of cost. (8) Maintainability criterion is directly linked to the sustainability of the project. If the sustainability of the project will not exceed two years to allocate a point of *; if the life of the project is between 2 and 5 years, assign a score of ** beyond 5 years, assign ***. 4. Architectures The numerous publications dealing with cloud architectures relating to Agriculture 4.0, summarized in Table 2, show that a great deal of effort has been devoted to solving a whole range of problems related to many use cases. Indeed, a universal and a unique architecture do not exist for IoT applications in Smart Agriculture which ensure all needs of all use cases. This is the reason why several researchers have proposed various architectures which address specific issues of generic architectures. The Fig. 2 gives a global overview on Agriculture 4.0 organization. Download : Download high-res image (340KB) Download : Download full-size image Fig. 2. Global structure of IoT in Agriculture 4.0. 4.1. Central Cloud Architectures Central Cloud Architectures are based on two basic architectures that are associated or combined in order to form modern architectures. These two architectures are: Batch Architecture aims to process an entire dataset in an offline mode. For this type of architectures, as long as the processing of the dataset is not finished, it continues and produces results only when it has reached its end. Generally, the data is selected and distributed to different nodes in order to be processed more quickly. When all the treatments are achieved on all nodes, the results are sorted and aggregated to obtain a global output. This architecture is easily implemented, and the aggregation is done by a framework, but processing times can be long, and data extracted during the treatment cannot be processed before the end of the treatment in progress. Furthermore, it is possible to increment results of previous batch and produce a result that integrates treated data in progress. Sallah et al. used a batch architecture to update data within the AquaCrop model (FAO) embedded in R-environment in order to facilitate model calibration and validation, run and evaluate all fields in a single run (Sallah et al., 2019). Nolack Fote et al. presented an architecture to extract knowledge on the long term from data in Precision Livestock Farming (PLF) (Fote et al., 2020). Table 5. Table 5. Pros and Cons of Batch Architecture. Pros Cons - Easy to implement and maintain. - Process only data previously stored in another form (file, database, etc). - Able to achieve long term treatments (several hours or days). - Processing cannot be modified before the end of the treatment. - Reprocessing of old data that are easy to achieve. - Results available only at the end of the treatment. Real-time Architecture also named Streaming Architecture processes data as it arrives, and results are progressively available by opposition to the batch architecture where it is not necessary to wait for the end of ingestion of all input data to obtain a result. The notion of real-time is strongly dependent on the analysis context with a processing time from a few milliseconds to a few minutes. Real-time architecture can be implemented in two different ways. On one hand with micro-batch in which a tiny amount of data is processed each n seconds and a result is obtained at the end of the treatment or on the other hand with a streaming approach in which each new data is immediately processed and output is quickly produced. This architecture is limited to data flow processing (Miloslavskaya and Tolstoy, 2016). Table 6. Table 6. Pros and Cons of Real-time Architecture. Pros Cons - Allow a rapid treatment of newly arrived data. - Not able to achieve processing on large size of the batch. - Batch processing can be emulated using micro batches but not all algorithms can be implemented. - Reprocessing of old data difficult to implement. - Easy to implement and maintain. - The need for real-time processing involves the use of an estimator rather than the precise values that would take too long to be calculated. Various data are produced by different fields or animals sensors, vehicles, and robots of the Agriculture 4.0. Afterward, this data must be on one hand stored in a raw state and processed in an offline way where long and complex treatments can be achieved. On the other hand, data can be processed before its storing with offline processing, streaming processing, or a combination of these ones. The storage time is extremely variable following the nature of the data and their loss of value over time. Offline processing is classically used to process images from UAVs, UGVs, or satellites, for example, to determine photosynthesis activity, evaluate the canopy development or stocks of palatable species available in a pasture, etc. While Streaming processing allows detecting anomalies in animals’ behaviors in real-time, or during agricultural operations such as the harvesting, disease and pest detection, weeds elimination. In these last cases, data is not stored because it quickly loses all value after its ingestion. Finally, a combination of the two previous ways i.e. Offline and Streaming processing is used to estimate real-time metrics and achieve complex treatments in an offline way at the same time. This approach is used by milking robots which detect anomalies in the production in real-time while the offline processing estimates the future production of each cow based on previous milking (Debauche et al., 2021). Lambda architectures are used in systems that need to process and expose quickly massive amounts of streaming data. This cloud architecture was proposed by Nathan Marz and James Warren (Marz and Warren, 2013) to handle tremendous quantities of data and resolve complex problems combining processing large volumes of data (Batch) while incorporating the most recent data processed in real-time processes (Singh et al., 2019). This architecture is generic, scalable, and fault-tolerant against hardware failures and human mistakes. The architecture is composed of three layers: (1) batch layer process very large quantities of data by batch; (2) speed layer which processes data in real-time and provides views based on the most recent data and (3) serving layer responding to queries. Data comes from either a data source or a message queue. This paradigm allows executing arbitrary queries over any real-time data and is particularly adapted for critical infrastructure and health systems (Diaz et al., 2016). Several implementations of Lambda Architecture in smart Environment management, big data storage and analytics can be found in (Villari et al., 2014). Among the criticisms that have been made against lambda architecture is the need to make twice the developments for the real-time branch and the batch branch. It is possible to perform a batch processing and in real time with flow processing is what the Kappa architecture described below does (Kreps, 2014). Fig. 3 Table 7. Download : Download high-res image (116KB) Download : Download full-size image Fig. 3. Lambda Architecture General Scheme. Table 7. Pros and Cons of Lambda Architecture. Pros Cons - Process data in real-time or in batch processing in separate ways. The reliability of two ways of treatment is most costly than other architectures if the two execute the same treatment. Among use cases in agriculture 4.0 using a lambda, we would like to highlight: Roukh et al. proposed WALLeSMART, a cloud platform based on lambda and specifically developed for Smart Farming. This platform implements Apache Kafka to store temporary data before their treatment. Apache Hadoop and the programming model Mapreduce is used for the batch processing while Apache Storm process data in realtime. The originality of this architecture is the coupling of a NoSQL database Apache Casandra and a SQL database, PostgreSQL where data is stored in the function of its nature. The GraphQL query language allows to querying databases. (Roukh et al., 2020, Roukh et al., 2020). Debauche et al. describe a lambda architecture for digital phenotyping (Debauche et al., 2020) and farm animals’ behaviors coupled with an Application Hosting Architecture based on Apache Mesos and Docker containerization to facilitate the deployment of various applications. An API interconnects and controls accesses between the Lambda Architecture and the Hosting Application Architecture. The Lambda architecture is based on Apache Beam to easily change the runner in the function of the technology evolution and improve its sustainability. Apache Druid is used to store time series data (Debauche et al., 2019) and metadata of data stored in the Datalake based on Apache Hadoop (Debauche et al., 2018). A variant of this architecture, named Unified Lambda architecture combines batch and stream pipelines which runs concurrently, and then the results are merged automatically (Siciliani, 2015). AllJoyn Lambda integrates AllJoyn a framework that offers: (1) proximal devices and applications discovering; (2) specific devices framework adapting; (3) transmission between devices with Bluetooth, Wi-Fi, etc.; (4) interoperability between operating systems; (5) efficient and secure data exchange through D-BUS (Villari et al., 2014). The Kappa architecture, proposed by Jay Kreps from LinkedIn (Kreps, 2014), simplifies the Lambda architecture by combining real-time and batch layers. This cloud architecture differs from the Lambda architecture by using a non-permanent storage system of data in an unchangeable log file such as system as Apache Spark or Apache Kafka, and consequently allow only storage for a limited time in order to allow an eventual reprocessing of these data. Batch and Speed Layers are also replaced by a stream processing engine. So, the Kappa Architecture is composed of two layers: streaming and serving layers and can be implemented with a publish-subscribe messaging like Apache Kafka, which facilitates data ingestion. Fig. 4. Download : Download high-res image (121KB) Download : Download full-size image Fig. 4. Kappa Architecture General Scheme. The main advantage of this architecture is its simplicity. It avoids having to maintain two separate code bases for the batch and speed layers. When processing on real-time and historical data are the same, a Kappa Architecture must be used. Fast Data Architecture is a variant of Kappa Architecture in which the data are no longer read from files but from an additional mechanism like Kafka that captures multiple streams combines them before being processed by the speed layer (Lakhe, 2016). Persico et al. achieved a benchmark of Lambda and Kappa architectures and show that Lambda outperforms Kappa for social networks data (YFCC100M) processing (Persico et al., 2018). Table 8. Table 8. Pros and Cons of Kappa Architecture. Pros Cons - Very efficient for real-time processing thanks to in-memory processing. - Batch processing emulates thanks to micro-batch treated via the real-time way. - Optimized cost because allows real-time and batch processing. - Not able to process large batch size. - Must be finely tuned from data to obtain the best performances (Nkamla Penka et al., 2021). Other Architectures derived or inspired of the previous architectures have been developed to address specific problems such as (1) SMACK (Estrada and Ruiz, 2016) which attempts to propose an optimal architecture with fixed components; (2) Liquid (Fernandez et al., 2015) is an architecture which provide low latency, incremental processing, high available with isolated resource, and able to store high throughput data at low operational cost architecture; (3) Butterfly (Lakhe, 2016) proposes to unify batch, speed and serving layers in a unique platform in which data are organized as a collection of three types of abstractions; (4) Zeta (Scott, 2015) which integrates a lambda architecture with business aspect of the enterprise; (5) BRAID (Giebler et al., 2018) is a hybrid processing architecture where all coming data and configuration file of processing, and eventually processing results written back are stored in a shared storage; (6) IoT-a (Hausenblas, 2014) is composed of three blocks: Ad-hoc queries, a Database, and a Distributed File System; (7) Polystore (Meehan et al., 2016) implements a multiple database system PostgreSQL, SciDB and Accumulo because a database alone cannot store all types of data efficiently. Table 9. Table 9. Qualitative evaluation of cloud-centric architecture. Criterion Batch Stream Lambda Kappa User Proximity * * * * Latency & Jitter * * * * Network Stability * * * * High throughput *** *** *** *** Reliability *** *** *** *** Scalability *** *** *** *** Cost Effectiveness *** *** * ** Maintainability *** ** * ** The analysis of the literature achieved shows that two major generic architectures: Kappa and Lambda allows to address of various use cases and are widely implemented and proven in other domains of the Internet of Things. The Lambda is more expensive to implement than the Kappa because of the need to maintain two separate parallel processing branches for stream processing and batch processing. It is interesting if different processing are carried out on the two processing branches. Otherwise, a Kappa architecture with a single processing branch that processes both the streams and the data in batches is more appropriate in most cases because it is cheaper and easier to maintain because a single code performs both types of processing (stream and batch). Looking at our first two research questions, we observe that Lambda and Kappa cloud architectures are efficient but these architectures alone operating in central cloud cannot address, for example, use cases where very low latencies are required. They will have to be hybridized and completed to address these particular cases. Two possibilities are available to us. The first way consists in associating several specialized cloud platforms to make it possible to obtain greater genericity or at least to better cover a domain. The second consists of supplementing the cloud-centric architectures that we have just mentioned with other architectural elements in order to better address the specific needs of Agriculture 4.0. 4.2. Extension of the cloud paradigm With the increase of the amount of data produced by the myriad of connected things, the amount of data to process, to transfer by network, and to treat in the cloud computing have called into question the architecture of storage and data processing. To solve the problem, two ways have been proposed, the first is Multi-Cloud Computing, the objective of which is to ensure redundancy in order to improve latency. The second is the Federated Cloud with the aim of pooling resources for better use. Multi-Cloud Computing (MCC) (Manyika and Chui, 2015) is an extension of Cloud Computing paradigm where services are distributed on multi-clouds. In this architecture the workflow is distributed entirely in the cloud, data redundancy is also verified. One advantage of the MCC is the high recovery rate but it has the same disadvantages as Cloud Computing, along with complexity and portability issues. Kazim et al. proposed a framework to deliver IoT services and establish cooperation across multi-clouds. An authentication allows communicating cloud to authenticate each other cloud dynamically. While a service selects the best IoT service matching with user requirements among multiple clouds and taking into account the SLA parameters agreed between the user and the provider (Kazim et al., 2018). Federated Cloud (FC) aggregates resources of multiple cloud providers to improve users’ freedom and allows users to choose where they want to deploy their applications. A Federated cloud can be defined as a voluntary collaboration between heterogeneous cloud providers collaborating to share their own unused resources. Using a cloud federation helps to ensure service performance during load ups with resources borrowed from other clouds. In addition, the geographical dispersion of the installations makes it possible to migrate to another installation and to guarantee the service in case of breakdown. A unified interface allows to use it an easy consultation of the offered services. Finally, thanks to the dynamic distribution of the load, it is possible to bring the treatment closer to the user and consequently improve the Quality of Service (Assis and Bittencourt, 2016). Cloud federations include European Federated Cloud (Sipos et al., 2013), Massachusetts Open Cloud, Mosaic (Petcu et al., 2013), IEEE P2302, and Open stack Keystone. Drakos et al. described agINFA, a common research data infrastructure for agriculture, food and the environment using EGI Federated Cloud. This infrastructure allows to partner to share research infrastructure components, APIs, a registry of web-based information service and dataset for agriculture (Drakos et al., 2015). 4.3. Distributed architectures The post-cloud approaches allow to improve latency and jitter for immobile entities but do not provide an answer adapted for mobile devices and local awareness. The large amount of data generated at the edge has increased the speed of data transportation that is becoming the bottleneck for the cloud-based computing paradigms (Shi et al., 2016). Moreover, the treatment of data in the cloud does not offer any guarantees about privacy, on the response time and real-time actuation because the huge number of devices increases the latency and jitter. Moreover, the mobility of devices and power constraints makes the communicaion difficult with the cloud all the time (Botta et al., 2016, Zhou et al., 2017). The aim has been to bring data storage and processes data, filtering, and data analysis closer to data-producing objects to limit bandwidth consumption and relieve the cloud. Three major paradigms have been proposed to address these issues and bring cloud computing-like capabilities to the edge of the network. All these infrastructures manage mechanisms of Virtual Machine (VM) or containers migration and adjust if needed, the provisioning of capabilities where users are located. Moreover, the three paradigms allow the creation of federated infrastructures in which can coexist multiple edge infrastructures which can exchange information and services (Roman et al., 2018). 4.4. Elements of distributed architectures In order to always bring closer, the processing capacities of intermediate processing have been set up between connected objects and the cloud at the network level (Fog Computing) and at the level of telephony providers (Mobile Edge Computing). Fog Computing is a concept created by Cisco Systems and is an extension of the cloud computing paradigm (Munir et al., 2017) in which computation, storage and network services are provided between end devices and cloud/ classify and analyze the raw IoT data streams at near-edge and edge network level (Cisco, 2018). Fog nodes are either physical components such as gateways, switches, routers, servers etc. or virtual components such as virtualized switches, virtual machines, cloudlets, etc.; deployed following private, community, public or hybrid. Private nodes are reserved for a single organization, community nodes are used by a community, public nodes are dedicated to the general public, and hybrid mix the third previous modalities (Uehara, 2017). This paradigm allows to limit data transfer on cloud, reduce latency (Sethi and Sarangi, 2017), and jitter thanks to a three-tier architecture (Roman et al., 2018). In this hierarchical architecture, the analysis of local information is achieved at the low level and the coordination and global analysis are performed at the top level. The Fog Computing supports mobile devices (Sethi and Sarangi, 2017), response time in real-time or predictable latency (Lopez et al., 2015), bandwidth saving, an improving of security and resilience, scalability, multi-tenancy, advanced analytics, and automation (Byers, 2017), cost-effective services (Yang, 2017). Fog Computing allows also the federation of fog infrastructures in order to allow cooperation between multiple organizations (Roman et al., 2018). Furthermore, the architecture is optimized for a use case and applications which must run on them (Byers, 2017). Fog Computing differentiates from cloud computing mainly by the proximity with end-users at the edge of networks localized or distributed geographically consisting in many relatively less resourceful (Munir et al., 2017). In addition to network equipment, fog computing can also be carried out in cloudlets and micro data centers. Cloudlets were proposed to address the end-to-end responsiveness between mobile devices and associated clouds. Cloudlets (Mach and Becvar, 2017) are micro data center geographically deployed in vicinity of End Users. This mobility-enhanced small-scale cloud data center is composed of computers with high computation power which provide both computation resources and storage. Cloudlet is much more agile (highly dynamic provisioning) than cloud due to user mobility churning. The mobility of users implies the use of a virtual machine to rapidly instantiate compute-intensive and latency-intensive applications and migrate the offloaded services between different cloudlet in the function of the user mobility. Cloudlets must be firstly discovered, selected among several candidates before starting provisioning. At the end of the session, the instance is destroyed (Ai et al., 2018). Cloudlets are accessed by mobile user equipment via Wi-Fi imply a high latency caused by the network and switch between mobile network and Wi-Fi and by consequence Quality of Service (QoS) and Quality of Experience (QoE) are hard to fulfill (Mach and Becvar, 2017, Manyika and Chui, 2015). Moreover, Cloudlets cover usually a small region and do not offer any guarantee on ubiquitous computing and scalability in service (Manyika and Chui, 2015). MicroData Centers (MDCs) were proposed by Microsoft Research. It is designed to extend cloud data centers as cloudlets. MDCs are enclosures contemning all types of equipments (computing, storage, network) needed to provide a secure computing environment in order to run customs applications requiring low latency. MDCs are also well adapted to provide processing resources to end devices on battery or with limited computing capabilities. MDCs can be adapted in function network bandwidth and user needs thanks to certain flexibility in terms of latency and scalability of the capacity (Wang et al., 2020). Guardo et al. proposed a framework composed of two fog layers respectively filtering and aggregating data, and clustering analysis, actuation management, and alert. The framework aims to improve computational load balancing between fog and cloud in order to reduce the amount of data to transmit to the cloud, reduce the waiting time for the user (Guardo et al., 2018). Taneja et al. proposed a SmartHerd an IoT platform dedicated to smart dairy farming based on microservices and Fog-assisted. The IoT gateway received data from transceivers, archived data aggregation, preprocessing, classification, feature selection, send critical alerts to farmers, and transmit data to IBM Watson IoT platform via MQTT protocol. In the IBM Watson IoT platform, a broker picks up data and store them in a Cloudant NoSQL JSON Database. Python Virtual Machine and Java Virtual Machine were used as containers equivalent for microservices deployment at fog level (Taneja et al., 2019). Sharofidinov et al. described a 4 layers architecture (Sensors Layers, Fog Layer, Network/Cloud Layer, and Application Layer) based on LoRa to monitor and predict the state of a greenhouse from a random forest algorithm. In the Sensor Layer, sensors acquire temperature, soil and air humidity, CO2 rate, and illumination connected to TTGO LoRa32 (ESP32 with LoRa Sx1276 chip) which are transmitted to the gateway by LoRa. At Fog Layer, preliminary analysis with Machine Learning algorithm, diagnosis of sensor status, and data compression are achieved. In the Network/Cloud Layer, compressed data are transmitted in order to be deeply analyzed and stored. Finally, in the Application Layer, analyzed data are converted in readable form to allows the monitoring and the control of the greenhouse (Sharofidinov et al., 2020). Table 10. Table 10. Pros and Cons of Fog Computing. Pros Cons - Fast response time in avoiding transmission of data to the cloud (Sharofidinov et al., 2020). - Failure or outage of the gateway can defeat thousands of devices. - The local storage and processing capabilities prevent data loss and outages when the Internet connectivity is limited (Sharofidinov et al., 2020). - The limited processing and memory capacities do not allow the deployment of algorithms requiring significant resources or the carrying out of long-term processing. - Sensitive data can be filtered locally. In this case, only the data model is moved in the cloud (Sharofidinov et al., 2020), and data validation, compression, and encryption. - Gateway at fog level ensure the compatibility between old and modern devices (Sharofidinov et al., 2020) and various protocols for communication. - Improve the resilience thanks to the decentralization of the treatment on network devices (Sharofidinov et al., 2020). Mobile Edge Computing (MEC) was proposed by ETSI and is deployed by telecommunication companies on the edge of the network, which is characterized by ultra-low latency and high bandwidth. (Roman et al., 2018, Zhou et al., 2017). At the very beginning, Mobile Edge Computing (MEC) aims to bring real-time, high-bandwidth, and low-latency access to dependent applications known as cloud computing capabilities; in addition to, information technology (IT) features of cloud computing. MEC is distributed at the edge of the network. In fact, a new class of cloud-native applications are easily accessible, because of the close position of Edge Computing to the end user and apps. Also, it allows network operators to open their environment to a new ecosystem. As a result of this significant change, MEC application can be used in LTE macro base stations (eNBs), 3G radio network controllers (RNCs), Wi-Fi access points, edge network routers, and enterprise edge servers. MEC platform contains two main hosting infrastructures. The first is formed by hardware resources and a high-resolution screen. The second is composed of manageable applications with numerous capabilities such as the application of virtualization manager and platform services (Zhou et al., 2017). An important challenge for the MEC is the VM migration that must optimize the tradeoff between migration gain and migration cost and select optimal location (Ai et al., 2018). Tran et al. investigated the collaborative Mobile Edge Computing in 5G Networks. MEC extends processing and storage resources at the edge of the Radio Access Network (RAN) while C-RAM is based on centralization of the base Station by means of the virtualization. Authors argue that both technologies are complementary in the 5G ecosystem (Tran et al., 2017). Fig. 5 Table 11. Download : Download high-res image (172KB) Download : Download full-size image Fig. 5. Mobile Edge Computing General Scheme. Table 11. Pros and Cons of MEC. Pros Cons - Reduces needs in connection, response time delay, the congestion of other parts of the network (Valecce et al., 2019). - Usable only for devices connected in Wi-Fi or 3GPP. - Use low level message from Wi-Fi to determine the location of each device (Location awareness) (Valecce et al., 2019). - MEC Server can be used as power open to applications and services (Valecce et al., 2019). Fan et al. combined MEC with data link management, combining with the industrial CAN bus characteristics to monitor water. Field Programmable Gate Arrays (FPGA) Altera implementing the AVALON bus was used to implement the system. Moreover, they propose a protocol to model random network disturbances and an online task offloading algorithm based on the monitoring of task execution (Fan and Gao, 2018). Valecce et al. proposed a 5G-robotics reference architecture for smart agriculture composed of UAV-Based Monitoring and connectivity, Machinery automation, and MEC Applications Server. UAVs/satellites capture high-resolution images during patrolling, which coupled with sensors data trigger a precise crop management. UAVs can also collect data or serve as a 5G mobile station. In field, image processing coupled with sensors data can be used for decision making. MEC allows to process gigabyte/s of data produced by autonomous vehicles and robots (Valecce et al., 2019). Table 12. Table 12. Evaluation of distributed architecture with our criteria. Criterion Fog MEC User Proximity **(*) *** Latency & Jitter * * Network Stability *** ** High throughput ** **(*) Reliability *** ** Scalability * * Cost Effectiveness ** ** Maintainability ** ** The development of fog computing and its counterpart for MEC wireless networks allow processing capabilities closer to users to improve response time but with lower computational capacities compared to the cloud. There are inherently two questions: Which association strategies to use between the cloud and the other levels of processing in the network? How to distribute the load between these different levels: local (Edge), network (Fog), and Cloud processing. 4.5. Collaborative computing strategies In order to address, our fourth research question, we try to identify different possibilities to compose architectural elements. Indeed, different collaboration strategies between the different levels of data processing (cloud, fog, edge) can be considered depending on the particularities of the use cases. In the next paragraphs, we describe possibilities of collaboration between different treatment entries, and we illustrate each one with few examples. Edge-Cloud aims to connect devices directly with the cloud that performs data processing. This strategy is often used by UAVs and UGVs which preprocess data before its transfer to the cloud because image treatment needs processing power and storage capabilities. The default of this approach is that the delay of the whole process from data transfer via high throughput wireless or cellular protocol to the transmission of processing results cannot be guaranteed because of the fluctuation of data rates linked to wireless networks (Wang et al., 2020). The processing of data can be achieved in an online mode with a real-time data transmission and processing by a stream, Lambda, Kappa or derived architecture of these one. An offline strategy with a data transfer by means of a computer and Internet connection on the cloud after the UAV fly and processing with a Batch, a Lambda, or a Kappa architecture or a derived architecture of these one is also possible. This latter costly avoid data transmission and is suitable for monitoring crops or livestock that do not require direct action. Agriculture 4.0 uses in particular Unmanned Aerial Vehicles (UAVs) equipped with various sensors in order to improve the time of data collection, in reducing the cost of acquisition compared to traditional field phenotyping technologies. According to Tang et al., edge-cloud is majorly used in smart robots to reduce complexity (Tang et al., 2021). Indeed, the images of drones to be used must be orthorectified and assembled. These operations require significant resources in terms of computing power, and memory. All these collected data must be rapidly processed, analyzed, and visualized. Agroview (Ampatzidis et al., 2020) is a platform that developed a cloud and AI-based application to survey and assess the agriculture field, deployed on Amazon Web Services (AWS). A website allows the upload of images or existing orthomosaic, the consultation for each tree field e.g., number of trees, tree gaps count, area of the field, the average height of trees, canopy area, etc. The website also allows the stitching of an orthomosaic and the generation of a Digital Surface Model (DSM). A tree detection algorithm developed in C allows the detection of individual tree and tree gap, and estimate tree parameters such as height, canopy area, health/stress estimation. The pipeline of treatment uses a Faster R-CNN to detect the region of interest (ROI) and the ResNet101 network allows to detect trees and row orientation. Afterward, the Yolo classifier using Darknet19 was applied along each row of trees to obtain a more precise detection. Debauche et al. presented an Edge-Cloud architecture for the analysis of cattle behavior from 9-DOF IMU data sampled at 100 Hz and GPS location sampled at 0.5 Hz that is then processed with an algorithm proposed by (Andriamandroso et al., 2017) in batch processing (Debauche et al., 2019, Debauche et al., 2020). Popescu et al. proposed an integrated system UAV-WSN-IoT where WSN data is collected by UAVs before their transmission to the ground control station and afterward to the cloud (Popescu et al., 2020). Debauche et al. proposed an architecture for scientific research dedicated to honeybee Colony Collapse Disorder. In this architecture, data is compressed on LoPy at the edge level before its collection by the LoRaWan gateway and its transmission to the Lambda architecture in the cloud where it is processed (Debauche et al., 2018). Edge-Fog aims to connect devices directly with network components such as gateways, routers that perform data processing. The major benefits of this approach are an optimization of the bandwidth, a reduction of traffic and latency, a better privacy, and an improved security level (Badidi, 2020). Fog nodes collect, aggregate, filter, encrypt, compress, and process IoT data (Gupta et al., 2020). This way is used for example by milking robots where data are processed by a computer close the robot and can be viewed remotely by the farmer. 5G also promotes mobile edge computing (MEC). Debauche et al. presented an AI-IoT architecture for the deployment of Artificial intelligence algorithms and Internet of things services at fog level using docker containerization and Kubernetes orchestration. This architecture has been developed to automatically deploy AI algorithms after retraining when performances (accuracy, recall, precision) are improved (Debauche et al., 2020). Debauche et al. proposed a Multi-Agent System (MAS) deployed at edge level allowing to control abnormal data present in sensed data and eventually cure this data when it is possible. The MAS simultaneously manages pivot irrigation, plant diseases and pests' detection, and their curation. The data is partially transmitted to the cloud to improve the detection of diseases and pests and retrain AI algorithms before their redeployment at the edge level (Debauche et al., 2020). Debauche et al. described a fog architecture in which a Gated Recursive Unit (GRU) algorithm is deployed on NVIDIA Jetson Nano for real-time poultry monitoring. GRU is simpler than LSTM algorithm. GRU is built to avoid varnish gradient problems. Periodically data is transmitted to the user interface implemented in NodeJS in the cloud (Debauche et al., 2020). Edge-Fog-Cloud is a paradigm in which data are partially processed in the fog and more complex treatments are achieved in the cloud. This way is used by wireless Sensor and Actuator Network (WSAN), which passes through a gateway that provides interconnection between the devices and the backhaul which transit then data to the cloud. However, the right balance between cloud and edge/fog computing is required (Badidi, 2020) based on available resources and whether or not the task is sensitive. Taneja et al. used a strategy Edge-Fog-Cloud to develop a detection system of lameness for cattle. The data from the pedometer is transmitted to the Fog node by means of a Long-Range proprietary protocol at 433 MHz on a distance of 2 km. Fog node stores in local database, preprocess and aggregates them. Fog node communicates with IBM Watson IoT Platform with MQTT protocol. Arriving data are picked up and stored in Cloudant NoSQL JSON database in IBM cloud. A mobile application synchronizes data with PouchDB, its local database via the REST API of Cloudant database when an Internet connection is available (Taneja et al., 2020). Alonso et al. presented Global Edge Computing Architecture (GECA), a modular tiered architecture (IoT Layer, Edge Layer, Business Solution Layer) to monitor dairy and feed grain state in real-time. In this architecture, a Distributed Ledger Technologies provides security from IoT Layer to Business Solution Layer. In the IoT layer, a set of agents call oracles to verify incoming data and afterward calculate hash of data with SHA-256 which is stored in the blockchain to verify the non-alteration of data. In parallel data is encrypted with the RSA algorithm and then sent to the Edge layer. The Edge Layer is responsible of the preprocessing of data and filters out data transmitted to the cloud. It enables also various data analyses. In the business Solution Layer, final storage, authentication, analysis for decision making is achieved. It provides also a knowledge base and APIs (Alonso et al., 2020). Edge-Edge is a paradigm in which devices interact to collaborate, exchange, and process data. The deployment of the 5G network allows the interconnection between UAVs and UGVs/ agricultural machinery (Tang et al., 2021). This high throughput network will allow to developping new collaboration between UAVs/ UGVs and agricultural machinery, for example, a drone will provide information to a harvester to avoid a non-desirable area of the field or avoid obstacles. A fleet of drones can also collaborate to coordinate their operations on the field between them of course subject to availability in rural areas, a transmission network with sufficient bandwidth and short-latency or capabilities to communicate between them in direct connection or in a mesh network. (Tang et al., 2021). Four cooperation strategies have been identified, two of which use the cloud, namely Fog-Cloud and Edge-Cloud. The other two remaing, do not involve the cloud; namely, Fog-Edge, and Edge-Edge cloud. The first two strategies complement the cloud to help us to address issues relating to production data and trade secrets, network congestion, and response times. The other two strategies do without the cloud and therefore assume that the devices/ vehicles have sufficient capacity to perform the processing. Despite these cooperation strategies between different levels of processing, some questions remain unanswered: How to store all the raw data when the data is so important that it would take colossal means to process it? What about security? How to organize the distribution of tasks between the edge, the fog, and the cloud? How to ensure operation and/ or treatment when network connections are intermittent or faulty? How to improve the maintainability of these architectures? These are the questions that the new trends that we describe in the next paragraph attempt to answer. 5. New trends In this section, we present two emerging architectures not based on the batch or/and real-time architectures or their derivatives. Afterward, we describe Osmotic and Dew computing as two new paradigms, which allow us to respectively choose where the processing must be achieved and improve the user experience. New trends are additional elements that allow enriching the analysis of Section 4 in order to address the third research question. The Microservices Architecture (MA) is a new system software design pattern that divides complex monolithic application in micro services dedicated for a single function. Microservice addresses defects of monolithic applications in which improving of service performance needs multiple deployment; a change in a function can affect all the monolith due to high dependencies between components; all the monolith uses a sole technology stack and development standards which limits possibilities to solve problems of physical heterogeneity. The advantages of this architecture are using a lightweight communication mechanism to interact between services with a minimal overload (Sun et al., 2017). The design proposed by (Sun et al., 2017) is composed of 8 microservices (Geo, Security, Tenant, Devices, Big Data, Automation, AI, and Application) and a core service coordinating. These services provide respectively: (1) Geo, a GIS layer to render data; (2) Security, user/group/role management, access control, administration, and authentication mechanism; (3) support for multiple IoT applications with a single core; (4) device plugins and communication protocols for sensing and actuating; (5) scalable persistence to store data; (6) process, analyze events and notify appropriate participant; (7) Artificial intelligence tools for IoT big data; (8) components to interact with client interfaces; (9) support for data exchanging by message with the devices. Authors argue that their approach is more flexible, scalable and platform-independent. Fig. 6 Table 13. Download : Download high-res image (189KB) Download : Download full-size image Fig. 6. Microservices Architecture General Scheme. Table 13. Pros and Cons of Microservices Architecture. Pros Cons - Fractionating of monoliths facilitates the maintainability and scalability of low coupled microservices. - Need to find microservice adapted with needs. - The discovery of micro-services allows the development new applications more easily than with monoliths. Fraction complex monolith is not easy. - More resilient, when a microservice is down, all others continue to function. Bixio et al. proposed a stream processing architecture event-driven based on proxy, adapter, and data processing microservices. This architecture extends the IoT platform Senseioty and using the Java OSGi framework (Bixio et al., 2020). The Data Lake Architecture (DLA) (Fang, 2015, Miloslavskaya and Tolstoy, 2016) enables the storage of large volumes of data of all types: raw data in its native format, structured, semi-structured, in a cost-effective manner. In this architecture, data is stored in its native format until it needs to process them by engines (Miloslavskaya and Tolstoy, 2016), which allows a fast transformation and refinement of stored data regardless of the amount of data stored. The architecture makes it possible to consume all types of data (logs, web services, database, files, etc.); different ingestion systems consume the data and then stored it in data repository. Once the data is stored, query systems can query the data lake. This architecture is considered in the corporate world as an evolution of existing architectures. The advantage of the Data Lake architecture is that it can easily and inexpensively store large amounts of data. It is particularly well suited to storing data in a typical format. In Enterprise Data Lakes are used; in addition to, data warehouses. Data lakes are, however, unsuitable for assessing data quality, data can be placed in data lakes without content control, and performance is also poorer than on specially designed and optimized infrastructures. The Lakehouse is a variant of the Data Lake where storages of data are generally achieved with Hadoop in the data lake is replaced by a distributed storage such as Amazon S3, Azure Blob Storage, Google Cloud Storage, and analysis are directly achieved by infrastructure managed by Cloud Service Providers such as Amazon Athena, EMR, or Databricks, Google Data proc, Azure HDInsight. The Fig. 7 provides a comparison between data lake and gatehouse structure. Download : Download high-res image (264KB) Download : Download full-size image Fig. 7. Data lake and Lakehouse General Scheme. It crucial in agriculture to explore datasets from different sources. The data lake is indicated to manage the complexity of agricultural ecosystems and centralized all data sources to find new correlations. (Madera et al., 2017). A data lake provides views based on metadata. It is nevertheless necessary to have advanced analysis tools for predictive modeling and statistical analysis. López et al. used a data lake to achieve the fusion of data from different domains in smart the agriculture context (López et al., 2020). Gallinucci et al. (Gallinucci et al., 2019, Gallinucci et al., 2020) present an innovative architecture 3 tiers architecture, called Mo.Re.Farming (MOnitoring and REmote system for a more sustainable FARMING) based on a data lake using Apache Hadoop and storing structured, semi-structured, and unstructured raw data, and in which subsequent processing and enrichment activities are separated. An Operational Data Store (ODS) using PostgreSQL with PostGIS to stores structured and detailed data and address limitations of big data solutions in properly handling continuous field geographic data. Finally, a spatial cube enables Spatial OnLine Analytical Processing (SOLAP). Neves et al. described an architecture in which raw data is stored in a datalake. Then, ETLs transforms data to be storable in a database. The data is enriched thanks to a knowledge base and its exploration by data mining algorithms (machine learning). The result of processing is filtered to improve the quality of structured data (Neves and Cruvinel, 2020). Table 14. Table 14. Pros and Cons of Datalake/DataHouse. Pros Cons - Store the data in its raw form without transforming them immediately. - Availability of results depend of the ingesting speed by processing services. - Allow store massive low-value data without investing energy to transform and store them in a database. - Data analysis by sampling does not give exact results but is estimated. - Provides a solution to situations where the volume of data is so large that it can no longer be processed immediately - Data House may be limited by the services offered by cloud providers for data analysis. Osmotic Computing (OC) (Villari et al., 2016) is a new paradigm inspired by the chemical osmosis process that corresponds to a dynamic and bidirectional flow of microservices between cloud and edge. OC exploits container-based solution to allows an automatic deployment of portable, mobile, and cross-platform microservices between Edge and cloud levels (Villari et al., 2016). Osmotic computing introduces the concept of Micro Elements (MELS) which decouples user data and applications in Micro Services (MS) i.e. a docker container and Micro Data (MD) i.e. an entity self-explicative in JSON. MS associates one operating system (Micro Operation Service) with an application (Micro User Service) while MD associates a microservice configuration (Micro Operational Data) and User data (Micro User Data). These MELS can be deployed on Microcontrollers (MCU) or Multiprocessor (MPU) (Villari et al., 2017). Table 15. Table 15. Pros and Cons of Osmotic Computing. Pros Cons - Micro Element (microservice  + micro dataset) easy to migrate between fog and cloud. - All datasets are not decomposable in micro dataset. The bidirectional migration of microservices between Edge and Cloud must, on one hand, avoid application breakdown and QoS degradation and on the other hand manage them dynamically, in high heterogeneously physical resources context, in the function of infrastructure and applications requirements (Villari et al., 2016). Carnevale et al. have applied osmotic computing to the Internet of Things by means of a distributed multi-agent system. Each agent is self-orchestrated, works independently, and manages the workflow as a composition of MELs. It monitors the overloading state of microservices by means of response time metric and decides to relocate them to another agent based on a Deep Reinforcement Learning algorithm or Time Series Analysis (Carnevale et al., 2019). Fig. 8, Fig. 9. Download : Download high-res image (119KB) Download : Download full-size image Fig. 8. Micro Element Structure. Download : Download high-res image (357KB) Download : Download full-size image Fig. 9. Osmotic Computing General Scheme. In an IoT context, OC allows to deploy lightweight micro services at edge level while complex micro services are deployed at fog/cloud level, and balance load between edge, fog, and cloud. (Maksimović, 2018). Morshed et al. proposed to use OC to distribute Deep Learning across edge, cloud, and mobile edge in a holistic way (Morshed et al., 2017). However, Kaur et al. in their Osmotic Computing applications survey have identified the need of standardization in terms of infrastructure deployment and micro-services distribution. The orchestration is crucial to manage efficient services. Security remains an important challenge because the service migration is supported by different layers (Kaur et al., 2020). Dew Computing (DC) (Skala et al., 2015) allows to further improve response times by pushing from Central cloud to end-users, computing applications, data, and low-level services. Client microcomputers are used to store a part of the data locally in the background and to limit access to the cloud, reduce network dependency and drastically reduce processing cost (Skala et al., 2015). Dew computing is the additional piece of cloud computing. It is mainly composed of a wide range of heterogeneous devices and varied equipment ranging from smartphones to smart sensors (Wang, 2016). DC is highly and effectively capable in terms of scalability and ability to perform sophisticated operations and to process numerous applications and tools. Additionally, the equipment of DC is ad hoc programmable and self-adaptive. They have the qualifications to running the process within another process in a distributed way without a focal communication network (Skala et al., 2015). Applications running in the on-premises computers provide services to users and/or devices independently of the cloud but collaborating with cloud services (Wang, 2016). DC can provide access web fraction without Internet connection (WiD), Storage in dew has a cloud copy (STiD), Local database has a cloud backup (DBiD), Software ownership and settings have a cloud copy (SiD), SDK and projects have a cloud copy (PiD), On-premises computer settings and data have a cloud copy (IaD), Other services (DiD) (Wang, 2016). The Fig. 10 presents the dew computing in the general scheme Cloud-Fog-Edge Computing. Table 16. Download : Download high-res image (84KB) Download : Download full-size image Fig. 10. Dew Computing General Scheme. Table 16. Pros and Cons of Dew Computing. Pros Cons - Allows access to a local copy of data when the connection is unavailable. - Replication of data is bandwidth-consuming. - Improve the reliability and the false tolerance. - Difficult to exploit if bandwidth is insufficient. Rajakaruna et al. presented a dew architecture based on a drone to retrieve and process data, manage WSN, and play the role of dew server. The drone communicates with sensors, and actuators with BLE protocol, collect, store data, and then when the drone is at the docking station it sends data to the cloud (Rajakaruna et al., 2018). Grovers et al. described a reliable and fault-tolerant architecture at 4 levels (edge, dew, fog, and cloud) in which sensed data is replicated at edge, fog and cloud level in order to take over the application’s control when a server is failed. In their architecture, dew servers are closed and linked with sensors producing data. The fault tolerance is ensured by mobile agents working as a resource exchanging the application and link-state information between us, and the network monitoring agent (Grover and Garimella, 2018). The Blockchain is a distributed digital ledger of transaction distributed maintained by a network of multiple computing nodes. This ledger can be deployed among the IoT nodes network (Bermeo-Almeida et al., 2018). In the blockchain, transactions namely blocks are managed by a specific software platform ensuring the data transmission, processing and storage, and its representation in a human-readable form allowing a consistent view and a consensus between the participants (Kamilaris et al., 2019). Different mechanisms of consensus whose two main ones are the “Proof of Work (PoW)” and the Proof of Stake (PoS). The PoW requires the solving of difficult computational tasks before validating transactions and the adding of the block in the blockchain. In this approach “miners” are in competition to be the first and obtain the rewards, which has an impact on the environment, need expending large a amount of computer and energy, and involves a risk of centralization. While the PoS approach, “validators” are randomly selected with a probability which depends on the amount of stake held. At the end of the validation process, it earns a fee. Other less used consensus mechanisms exist such as (1) Proof of Elapsed Time (PoET) in which each node generates a random wait time and goes to sleep for that specified duration; (2) Simplified Byzantine Fault Tolerance (SBFT), an improvement of Practical Byzantine Fault Tolerance (PBFT) specifically designed for blockchain in which each new block is maintained by a delegation of nodes with increasing authority. Each one uses the internal time to decide when actions must be done; (3) Proof of Authority (PoA) in which approved accounts process to the automated validation of transaction and blocks. Table 17. Table 17. Pros and Cons of Blockchain. Pros Cons - Data distributed (Alonso et al., 2020). - Energy consumption for the complex signature verification process can be important. - Immutable, durable, verifiable, secure, and transparent (Alonso et al., 2020). - Not adapted to store images, video. - Transactions P2P at low cost. The Fig. 11 shows the blockchain general scheme. Download : Download high-res image (251KB) Download : Download full-size image Fig. 11. Blockchain General Scheme. The block chain is mainly used in Agriculture to make the data of the supply chain transparent and open (Bermeo-Almeida et al., 2018) and ensure the complete traceability of the food chain from the fork to the plate. The block chain allows to record information about: (1) Transactions between provider and farmer as well as information relating to the crops, material and chemical products; (2) The farm, cultivation practices and management, animals feeding, and complementary information such as weather conditions, animals welfare, diseases, treatment, etc; (3) Information about factory and its equipment, the processing method, batch numbers but also financial transactions with producers and distributors; (4) Warehousing, storage conditions (temperature, humidity), methods of transport, transit time, and all financial transactions between the distributors and retailers; (5) food items information such as quantity available, quality, expiration date, time spent on the shelf or in the stock (Bermeo-Almeida et al., 2018, Kamilaris et al., 2019). The Fig. 12 shows an example of blockchain applied to an agri supply chain. Download : Download high-res image (112KB) Download : Download full-size image Fig. 12. Supply chain based on a blockchain. To a lesser extent, secured data storage, remote monitoring, and automation. The blockchain address some challenges of IoT such as decentralization, data anonymization, and security. Moreover, it allows faster and efficient operations, to improve reliability and scalability (Bermeo-Almeida et al., 2018). The analysis of new trends shows that: (1) Micro service architecture allows decomposing monoliths in microservices lowly coupled which makes it easier to maintain it while allowing other services to continue operating. Furthermore, this type of architecture is more resilient because if one of the services is down, the other services due to the weak coupling can continue to operate at least in a degraded mode. (2) Data Lake/DataHouse propose a new approach Load Transform Extract (LTE) where data are firstly stored in their original format, which are then transformed in order to extract information. This paradigm is particularly well adapted when the amount of data is so important that process all data is too costly. In this case, data can be sampled in order to obtain information. This paradigm is also well adapted if we want to conserve also raw data or complete a generic architecture, for example, to store data that will be processed in batch processing. (3) Osmotic Computing attempts to propose a solution to the repartition of workload between fog and cloud in decomposing treatments in microelements composed of a microservice associated with a micro dataset. The osmotic computing could also be associated with the micro service architecture to allow the distribution of instances of microservices at different levels of the network according to their respective load. (4) Dew Computing aims to replicate data near sensors or users to continue to store data or allows to continue to consult data when connection is intermittent. It allows improving the reliance of architectures on connection interruptions. (5) Blockchain provides an answer to authentication and security problems by making it possible in particular to verify that the data has not been altered or compromised. Nevertheless, it is not possible to store large amount of data such as high definitions images, or videos in the blockchain but hashes of datasets allowing to verify their authenticity well. 6. Towards Agriculture 5.0 According Myklevy et al., the world must improve the amount of food produced by 70% by 2050 to produce global food needs for a population (Mykleby et al., 2016) of 9.7 billion according to the Food and Agriculture Organization of the United Nations (FAO) (Zhang, 2016). To overcome these problems and contribute to achieve the second objective of 17 Sustainable Development Goals (SDGs) of the United Nations (UN) with a timeframe in the range 2015 to 2030, the concept of Agriculture 5.0 has been born (Martos et al., 2021). Agriculture 5.0 aims to increase production sustainably while consuming fewer resources and taking care of the environment. This next wave of agricultural revolution will imply the use of robots integrating machine learning to compensate for the shortage of workers. Farm robots are drastically increasing productivity in improving the human labor workforce and can also harvest a more important volume faster than a human. Nevertheless, these early technologies are still too expensive for most farmers especially small farms (Saiz-Rubio and Rovira-Más, 2020). Fig. 13 show the coupling between Agriculture 4.0 and Agriculture 5.0 and their integration in the context of the agri-food supply chain, the Society 5.0 and 17 Sustainable Development Goals (SDGs) of United Nations (See Fig. 13). Download : Download high-res image (252KB) Download : Download full-size image Fig. 13. Integration of the Agriculture 5.0 in the context of the Society 5.0. 7. Conclusion Our review is boosted by four research questions dectitaed as follow: (1) Which storage and processing architectures are best suited to Agriculture 4.0 applications and address its particularities? (2) Can generic architectures meet the needs of Agriculture 4.0 application cases? (3) What are the horizontal valuation possibilities that allow the transition from research to industrialization? (4) What are the vertical valuation possibilities to move from algorithms trained in the cloud to embedded or autonomous products?. The analysis of the literature shows that a multitude of architecture coexists. Nevertheless, the Lambada and Kappa architectures seem to emerge as generic architectures. These must generally be accompanied by complementary architectural components to address specific needs and be part of a storage and processing strategy in which the cloud architecture is a component of the chain or may also and more rarely be absent. The traditional centralized cloud computing will continue to remain an important part of computing systems (Ai et al., 2018), for sciences even if other paradigms appear. Indeed, cloud, fog, and edge computing complementary interact with each other to form a mutually beneficial and interdependent service continuum. Some functions are naturally more suitable or advantageous at a level than another in function of requirements in response time, computing, or latency tolerance. However, the cloud cannot be completely replaced by fog and edge computing because some computation-intensive tasks can only be processed at the cloud level, which has the computing power and storage capacities (Wang et al., 2020). In Agriculture 4.0, this is particularly the case for the processing of satellite images, the training of artificial intelligence algorithms such as Deep Convolutional Neural Network (DCNN). New trends make it possible to address various problems: (1) The Data lake/Data House offers a more economical alternative to massive cloud storage in databases. In this paradigm, all data are stored in a state and transform only when they are to be exploited. This approach is particularly interesting on one hand when all data are not exploited and on the other hand when a decision or an action is not expected immediately. Data lake also allows the fusion of agriculture data from various origins in different formats and granularity. (2) The blockchain provides solutions in particular to the security problems, the possibility of distributing data storage and ensuring the traceability of transactions in agrifood supply chains (3) As the literature has shown, Dew Computing can be placed in two different places in the network either as close as possible to the sensors to allow processing to continue during transmission interruptions or as close as possible to users in order to have a local copy of the data in order to be able to consult them offline. It should be noted, however, that for the second option, there are other means of local caching at the device level, for amounts of data of a few mega as those offered by Progressive Web Apps (PWA) by example. (4) Osmotic computing provides a solution to the question of how to distribute the load between the different processing levels (edge, fog, cloud). It uses the concept of microelement associating a microservice and its micro dataset. In addition, osmotic computing can also be associated with micro-service architectures. (5) The microservice architecture offers the possibility of decoupling the monolithic architectures into weakly coupled microservices. These services can be more easily associated, maintained, or evolved independently. The combination of these microservices makes it easier to develop new services for the end-user that are also easier and faster to evolve according to technological developments and needs. In addition, at the network level, the 5G network offers new possibilities in terms of Wireless Sensors and Actuators Network (WSAN), communication between machines, UAVs, and UGVs. Moreover, the coupling with MEC opens the field of processing close of end-users. The SDN/NFV Architecture allows to facilitate the design, and to improve the flexibility of network. Software-defined networking (SDN) allows decoupling transmission of data and network control functionality while Network function virtualization (NFV) abstracts transfer network and related network functions (Friha et al., 2021). Two trends in the use of processing architecture coexist, on the one hand, users of a paid or open source IoT platform, and on the other hand, users who develop specific architectures to implement particular use cases. From the point of view of transferability, we understand that it is easier for ready-made chargeable infrastructures and that it can be limited for turnkey open-source infrastructures where the type of license adopted may pose a problem. However, the sustainability of paid infrastructure is conditional on the development granted by the company that manages them and on its financial health. The development of architecture based on paid software bricks is facilitated but its durability is conditioned by the availability and the maintenance of these software bricks. As for transferability, it is linked to the acquisition of ad hoc licenses. The development of architecture using open source software bricks from foundations such as Apache Foundation makes it possible not to be limited by licenses but is dependent on developments and maintenance carried out by the community of developers. These software bricks can be abandoned by the community, the company that sponsors them, or the foundation that hosts them. The development of a sustainable architecture would go through an emancipation of software bricks which would make it possible to easily change them on the one hand when one of them disappears or if a new more efficient software brick appears. The deployment of 5G and satellite Internet will bring in a new player, which are the telecommunications companies that will be able to provide processing capacities and services as close as possible to users at the level of 5G antennas, which will impact processing architectures. The problem will then arise of interoperability between the networks of sensors and actuators with these new high-speed, low-latency networks. The new networks offered by the telecommunications companies will make it possible to offer new services or even to decouple the software from the hardware, which will make it possible to make the sensors and actuators interchangeable. This should make it possible to reduce the cost of the equipment and make it accessible to developing countries or areas not covered by traditional LPWAN and 3GPP networks. The impact of these new networks will have to be reviewed in the future to identify the new trends offered by 5G and satellite Internet. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have interfered with overall quality of the work reported in this paper. Acknowledgment This research is partially funded by Infortech and Numediart institutes. The authors would like to express their gratitude to Dr. Meryem Elmoulat for accepting to edit the writing of this paper and to Mr. Fabrice Nolack Fote for his help in the elaboration of the conceptual framework. References Agency, 2020 E.G. Agency Power-efficient positioning for THE Internet of Things – White Paper European GNSS Agency (2020), 10.2759/26127 Google Scholar Ai et al., 2018 Y. Ai, M. Peng, K. Zhang Edge computing technologies for internet of things: a primer Digital Commun. Networks, 4 (2018), pp. 77-86, 10.1016/j.dcan.2017.07.001 View PDFView articleView in ScopusGoogle Scholar Alonso et al., 2020 R.S. Alonso, I. Sittón-Candanedo, Óscar García, J. Prieto, S. Rodríguez-González An intelligent edge-iot platform for monitoring livestock and crops in a dairy farming scenario Ad Hoc Netw., 98 (2020), Article 102047, 10.1016/j.adhoc.2019.102047 View PDFView articleView in ScopusGoogle Scholar Amazon, 2021 Amazon, 2021a. Amazon dynamodb. url:https://aws.amazon.com/fr/dynamodb/. Google Scholar Amazon, 2021b Amazon, 2021b. Amazon web services. url: https://aws.amazon.com/. Google Scholar Ampatzidis et al., 2020 Y. Ampatzidis, V. Partel, L. Costa Agroview: Cloud-based application to process, analyze and visualize uav-collected data for precision agriculture applications utilizing artificial intelligence Comput. Electron. Agricul., 174 (2020), Article 105457, 10.1016/j.compag.2020.105457 View PDFView articleView in ScopusGoogle Scholar Andriamandroso et al., 2017 A.L.H. Andriamandroso, F. Lebeau, Y. Beckers, E. Froidmont, I. Dufrasne, B. Heinesch, P. Dumortier, G. Blanchy, Y. Blaise, J. Bindelle Development of an open-source algorithm based on inertial measurement units (imu) of a smartphone to detect cattle grass intake and ruminating behaviors Comput. Electron. Agricult., 139 (2017), pp. 126-137, 10.1016/j.compag.2017.05.020 View PDFView articleView in ScopusGoogle Scholar Apache Software Foundation, 2021a Apache Software Foundation, A., 2021a. Cassandra. url: https://cassandra.apache.org. Google Scholar Apache Software Foundation, 2021b Apache Software Foundation, A., 2021b. Druid. url: https://druid.apache.org. Google Scholar Assis and Bittencourt, 2016 M.R. Assis, L.F. Bittencourt A survey on cloud federation architectures: identifying functional and non-functional properties J. Network Comput. Appl., 72 (2016), pp. 51-71, 10.1016/j.jnca.2016.06.014 View PDFView articleView in ScopusGoogle Scholar AT&T, 2021 AT&T, P., 2021. At&t continues to fuel growth of the internet of things with launch of new developer-friendly managed service. url: https://about.att.com/story/m2x_data_service_for_enterprise_developers.html. Google Scholar Ayaz et al., 2019 M. Ayaz, M. Ammad-Uddin, Z. Sharif, A. Mansour, E.H.M. Aggoune Internet-of-things (iot)-based smart agriculture: toward making the fields talk IEEE Access, 7 (2019), pp. 129551-129583, 10.1109/ACCESS.2019.2932609 View in ScopusGoogle Scholar Badidi, 2020 E. Badidi Qos-aware placement of tasks on a fog cluster in an edge computing environment J. Ubiquitous Syst. Pervasive Networks, 13 (2020), pp. 11-19, 10.5383/JUSPN.13.01.002 Google Scholar Bermeo-Almeida et al., 2018 Bermeo-Almeida, O., Cardenas-Rodriguez, M., Samaniego-Cobo, T., Ferruzola-Gómez, E., Cabezas-Cabezas, R., Bazán-Vera, W., 2018. Blockchain in agriculture: A systematic literature review, in: International Conference on Technologies and Innovation, Springer. pp. 44–56. doi:10.1007/978-3-030-00940-3_4. Google Scholar Bixio et al., 2020 L. Bixio, G. Delzanno, S. Rebora, M. Rulli A flexible iot stream processing architecture based on microservices Information, 11 (2020), p. 565, 10.3390/info11120565 Google Scholar Blynk, 2021 Blynk, 2021. Blynk iot platform: for businesses and developers. url:  https://blynk.io. Google Scholar Botta et al., 2016 A. Botta, W. De Donato, V. Persico, A. Pescapé Integration of cloud computing and internet of things: a survey Future Generat. Comput. Syst., 56 (2016), pp. 684-700, 10.1016/j.future.2015.09.021 View PDFView articleView in ScopusGoogle Scholar Byers, 2017 C.C. Byers Architectural imperatives for fog computing: Use cases, requirements, and architectural techniques for fog-enabled iot networks IEEE Commun. Mag., 55 (2017), pp. 14-20, 10.1109/MCOM.2017.1600885 View in ScopusGoogle Scholar Carnevale et al., 2019 L. Carnevale, A. Celesti, A. Galletta, S. Dustdar, M. Villari Osmotic computing as a distributed multi-agent system: the body area network scenario Internet of Things, 5 (2019), pp. 130-139, 10.1016/j.iot.2019.01.001 View PDFView articleView in ScopusGoogle Scholar Cisco, 2018 C. Cisco Cisco global cloud index: Forecast and methodology, 2016–2021 Cisco, San Jose (2018) Google Scholar Codeluppi et al., 2020 G. Codeluppi, A. Cilfone, L. Davoli, G. Ferrari Lorafarm: A lorawan-based smart farming modular iot architecture Sensors, 20 (2020), 10.3390/s20072028 url:  https://www.mdpi.com/1424-8220/20/7/2028 Google Scholar Conesa-Munoz et al., 2016 J. Conesa-Muñoz, J. Valente, J. Del Cerro, A. Barrientos, A. Ribeiro A multi-robot sense-act approach to lead to a proper acting in environmental incidents Sensors, 16 (2016), p. 1269, 10.3390/s16081269 View in ScopusGoogle Scholar Corp, 2020 Corp, P.H., 2020. Sensorcloud. url:  https://sensorcloud.com/. Google Scholar Debauche et al., 2018 O. Debauche, M. El Moulat, S. Mahmoudi, S. Boukraa, P. Manneback, F. Lebeau Web monitoring of bee health for researchers and beekeepers based on the internet of things Proc. Comput. Sci., 130 (2018), pp. 991-998, 10.1016/j.procs.2018.04.103 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2019 O. Debauche, S. Mahmoudi, A.L.H. Andriamandroso, P. Manneback, J. Bindelle, F. Lebeau Cloud services integration for farm animals’ behavior studies based on smartphones as activity sensors J. Ambient Intell. Humanized Comput., 10 (2019), pp. 4651-4662, 10.1007/s12652-018-0845-9 View in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, M. Elmoulat, S.A. Mahmoudi, P. Manneback, F. Lebeau Edge ai-iot pivot irrigation, plant diseases, and pests identification Proc. Comput. Sci., 177 (2020), pp. 40-48, 10.1016/j.procs.2020.10.009 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi, P. Manneback, J. Bindelle, F. Lebeau Edge computing and artificial intelligence for real-time poultry monitoring Proc. Comput. Sci., 175 (2020), pp. 534-541, 10.1016/j.procs.2020.07.076 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi, P. Manneback, J. Bindelle, F. Lebeau Edge computing for cattle behavior analysis 2020 Second International Conference on Embedded & Distributed Systems (EDiS), IEEE (2020), pp. 52-57, 10.1109/EDiS49545.2020.9296471 View in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S. Mahmoudi, S.A. Mahmoudi, P. Manneback, F. Lebeau A new edge architecture for ai-iot services deployment Proc. Comput. Sci., 175 (2020), pp. 10-19, 10.1016/j.procs.2020.07.006 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2020 O. Debauche, S.A. Mahmoudi, N. De Cock, S. Mahmoudi, P. Manneback, F. Lebeau Cloud architecture for plant phenotyping research Concurrency and Computation: Practice and Experience, 32 (2020), Article e5661, 10.1002/cpe.5661 View in ScopusGoogle Scholar Debauche et al., 2018 O. Debauche, S.A. Mahmoudi, S. Mahmoudi, P. Manneback Cloud platform using big data and hpc technologies for distributed and parallels treatments Proc. Comput. Sci., 141 (2018), pp. 112-118, 10.1016/j.procs.2018.10.156 View PDFView articleView in ScopusGoogle Scholar Debauche et al., 2021 O. Debauche, J.P. Trani, S. Mahmoudi, P. Manneback, J. Bindelle, S.A. Mahmoudi, A. Guttadauria, F. Lebeau Data management and internet of things: a methodological review in smart farming Internet of Things, 14 (2021), Article 100378, 10.1016/j.iot.2021.100378 View PDFView articleView in ScopusGoogle Scholar Diaz et al., 2016 M. Díaz, C. Martín, B. Rubio State-of-the-art, challenges, and open issues in the integration of internet of things and cloud computing J. Network Comput. Appl., 67 (2016), pp. 99-117, 10.1016/j.jnca.2016.01.010 View PDFView articleView in ScopusGoogle Scholar Drakos et al., 2015 Drakos, A., Protonotarios, V., Manouselis, N., 2015. aginfra: a research data hub for agriculture, food and the environment. F1000Res. 4. doi:10.12688/f1000research.6349.2. Google Scholar El-Sayed et al., 2017 H. El-Sayed, S. Sankar, M. Prasad, D. Puthal, A. Gupta, M. Mohanty, C.T. Lin Edge of things: the big picture on the integration of edge, iot and the cloud in a distributed computing environment IEEE Access, 6 (2017), pp. 1706-1717, 10.1109/ACCESS.2017.2780087 View in ScopusGoogle Scholar Elijah et al., 2018 O. Elijah, T.A. Rahman, I. Orikumhi, C.Y. Leow, M.N. Hindia An overview of internet of things (iot) and data analytics in agriculture: benefits and challenges IEEE Internet Things J., 5 (2018), pp. 3758-3773, 10.1109/JIOT.2018.2844296 View in ScopusGoogle Scholar Estrada and Ruiz, 2016 Estrada, R., Ruiz, I., 2016. Big data smack: A guide to apache spark. Mesos, Akka, Cassandra, and Kafka. Google Scholar Fan and Gao, 2018 D. Fan, S. Gao The application of mobile edge computing in agricultural water monitoring system IOP Conference Series: Earth and Environmental Science, IOP Publishing (2018), p. 012015 CrossRefView in ScopusGoogle Scholar Fang, 2015 Fang, H., 2015. Managing data lakes in big data era: What’s a data lake and why has it became popular in data management ecosystem, in: 2015 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER), IEEE. pp. 820–824. doi:10.1109/CYBER.2015.7288049. Google Scholar Farooq et al., 2019 M.S. Farooq, S. Riaz, A. Abid, K. Abid, M.A. Naeem A survey on the role of iot in agriculture for the implementation of smart farming IEEE Access, 7 (2019), pp. 156237-156271, 10.1109/ACCESS.2019.2949703 View in ScopusGoogle Scholar Feng et al., 2019 X. Feng, F. Yan, X. Liu Study of wireless communication technologies on internet of things for precision agriculture Wireless Pers. Commun., 108 (2019), pp. 1785-1802, 10.1007/s11277-019-06496-7 View in ScopusGoogle Scholar Fernandez et al., 2015 Fernandez, R.C., Pietzuch, P.R., Kreps, J., Narkhede, N., Rao, J., Koshy, J., Lin, D., Riccomini, C., Wang, G., 2015. Liquid: Unifying nearline and offline big data integration., in: CIDR, pp. 1–8. url:  http://hdl.handle.net/10044/1/23433. Google Scholar Ferrag et al., 2020 M.A. Ferrag, L. Shu, X. Yang, A. Derhab, L. Maglaras Security and privacy for green iot-based agriculture: review, blockchain solutions, and challenges IEEE Access, 8 (2020), pp. 32031-32053, 10.1109/ACCESS.2020.2973178 View in ScopusGoogle Scholar Fote et al., 2020 F.N. Fote, A. Roukh, S. Mahmoudi, S.A. Mahmoudi, O. Debauche Toward a big data knowledge-base management system for precision livestock farming Proc. Comput. Sci., 177 (2020), pp. 136-142, 10.1016/j.procs.2020.10.021 View PDFView articleView in ScopusGoogle Scholar Friha et al., 2021 O. Friha, M.A. Ferrag, L. Shu, L.A. Maglaras, X. Wang Internet of things for the future of smart agriculture: a comprehensive survey of emerging technologies IEEE CAA J. Autom. Sinica, 8 (2021), pp. 718-752, 10.1109/JAS.2021.1003925 View in ScopusGoogle Scholar Gallinucci et al., 2019 E. Gallinucci, M. Golfarelli, S. Rizzi A hybrid architecture for tactical and strategic precision agriculture C. Ordonez, I.Y. Song, G. Anderst-Kotsis, A.M. Tjoa, I. Khalil (Eds.), Big Data Analytics and Knowledge Discovery, Springer International Publishing, Cham (2019), pp. 13-23, 10.1007/978-3-030-27520-4_2 View in ScopusGoogle Scholar Gallinucci et al., 2020 E. Gallinucci, M. Golfarelli, S. Rizzi Mo. re. farming: A hybrid architecture for tactical and strategic precision agriculture Data Knowl. Eng., 129 (2020), Article 101836, 10.1016/j.datak.2020.101836 View PDFView articleView in ScopusGoogle Scholar Garcia et al., 2020 L. García, L. Parra, J.M. Jimenez, J. Lloret, P. Lorenz Iot-based smart irrigation systems: an overview on the recent trends on sensors and iot systems for irrigation in precision agriculture Sensors, 20 (2020), p. 1042, 10.3390/s20041042 View in ScopusGoogle Scholar Lopez et al., 2015 Garcia Lopez, P., Montresor, A., Epema, D., Datta, A., Higashino, T., Iamnitchi, A., Barcellos, M., Felber, P., Riviere, E., 2015. Edge-centric computing: Vision and challenges. doi:10.1145/2831347.2831354. Google Scholar Giebler et al., 2018 Giebler, C., Stach, C., Schwarz, H., Mitschang, B., 2018. Braid, in: Proceedings of the 7th International Conference on Data Science, Technology and Applications, pp. 294–301. doi:10.5220/0006861802940301. Google Scholar Google, 2021 Google, 2021. Firebase. url:  https://firebase.google.com/. Google Scholar Granell et al., 2017 Granell, C., Miralles, I., Rodríguez-Pupo, L.E., González-Pérez, A., Casteleyn, S., Busetto, L., Pepe, M., Boschetti, M., Huerta, J., 2017. Conceptual architecture and service-oriented implementation of a regional geoportal for rice monitoring. ISPRS Int. J. Geo-Inform. 6. url: https://www.mdpi.com/2220-9964/6/7/191, doi:10.3390/ijgi6070191. Google Scholar Grover and Garimella, 2018 Grover, J., Garimella, R.M., 2018. Reliable and fault-tolerant iot-edge architecture, in: 2018 IEEE sensors, IEEE. pp. 1–4. doi:10.1109/ICSENS.2018.8589624. Google Scholar Guardo et al., 2018 E. Guardo, A. Di Stefano, A. La Corte, M. Sapienza, M. Scatà A fog computing-based iot framework for precision agriculture J. Internet Technol., 19 (2018), pp. 1401-1411, 10.3966/160792642018091905012 View in ScopusGoogle Scholar Gupta et al., 2020 M. Gupta, M. Abdelsalam, S. Khorsandroo, S. Mittal Security and privacy in smart farming: challenges and opportunities IEEE Access, 8 (2020), pp. 34564-34584, 10.1109/ACCESS.2020.2975142 View in ScopusGoogle Scholar Hausenblas, 2014 Hausenblas, M., 2014. Internet of things architecture (iot-a) home page. url:  https://github.com/mhausenblas/iot-a.info. Google Scholar Iaksch et al., 2021 J. Iaksch, E. Fernandes, M. Borsato Digitalization and big data in smart farming–a review J. Manage. Anal., 8 (2021), pp. 333-349, 10.1080/23270012.2021.1897957 View in ScopusGoogle Scholar IBM, 2015 IBM, 2015. Ibm watson iot platform. url:  https://internetofthings.ibmcloud.com/. Google Scholar IBM, 2021 IBM, 2021. Ibm cloud. url:  https://www.ibm.com/cloud. Google Scholar Influxdata, 2021 Influxdata, 2021. Infludb cloud. url:  https://www.influxdata.com/products/influxdb-cloud/. Google Scholar Souces and I., 2021 Integra Souces, I., 2021. Iot solution development services. url:  https://www.integrasources.com/iot-page/. Google Scholar Jayaraman et al., 2016 P.P. Jayaraman, A. Yavari, D. Georgakopoulos, A. Morshed, A. Zaslavsky Internet of things platform for smart farming: experiences and lessons learnt Sensors, 16 (2016), p. 1884, 10.3390/s16111884 View in ScopusGoogle Scholar KaaIoT, 2021 KaaIoT, 2021. Ubidots. url:  https://docs.kaaiot.io/KAA/docs/current/Welcome/. Google Scholar Kamilaris et al., 2019 Kamilaris, A., Fonts, A., Prenafeta-Boldv́, F.X., 2019. The rise of blockchain technology in agriculture and food supply chains. Trends Food Sci. Technol. 91, 640–652. doi:10.1016/j.tifs.2019.07.034. Google Scholar Kaur et al., 2020 A. Kaur, R. Kumar, S. Saxena Osmotic computing and related challenges: a survey 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), IEEE (2020), pp. 378-383, 10.1109/PDGC50313.2020.9315757 View in ScopusGoogle Scholar Kazim et al., 2018 M. Kazim, L. Liu, S.Y. Zhu A framework for orchestrating secure and dynamic access of iot services in multi-cloud environments IEEE Access, 6 (2018), pp. 58619-58633, 10.1109/ACCESS.2018.2873812 View in ScopusGoogle Scholar Khanna and Kaur, 2019 A. Khanna, S. Kaur Evolution of internet of things (iot) and its significant impact in the field of precision agriculture Comput. Electron. Agricul., 157 (2019), pp. 218-231, 10.1016/j.compag.2018.12.039 View PDFView articleView in ScopusGoogle Scholar Kodati and Jeeva, 2019 S. Kodati, S. Jeeva Smart agricultural using internet of things, cloud and big data Int. J. Innov. Technol. Exploring Eng. (IJITEE), 8 (2019), pp. 3718-3722, 10.35940/ijitee.J9671.0881019 View in ScopusGoogle Scholar Kreps, 2014 Kreps, J., 2014. Questioning the lambda architecture. Online article, July 205. Google Scholar Lakhe, 2016 B. Lakhe Practical Hadoop migration: how to integrate your RDBMS with the Hadoop ecosystem and re-architect relational applications to NoSQL Apress (2016) Google Scholar Liu et al., 2020 Y. Liu, X. Ma, L. Shu, G.P. Hancke, A.M. Abu-Mahfouz From industry 4.0 to agriculture 4.0: current status, enabling technologies, and research challenges IEEE Trans. Industr. Inf., 17 (2020), pp. 4322-4334, 10.1109/TII.2020.3003910 Google Scholar López et al., 2020 I.D. López, J.F. Grass, A. Figueroa, J.C. Corrales A proposal for a multi-domain data fusion strategy in a climate-smart agriculture context Int. Trans. Oper. Res. (2020), 10.1111/itor.12899 Google Scholar Luis Bustamante et al., 2019 A. Luis Bustamante, M.A. Patricio, J.M. Molina Thinger. io: an open source platform for deploying data fusion applications in iot environments Sensors, 19 (2019), p. 1044, 10.3390/s19051044 Google Scholar Mach and Becvar, 2017 P. Mach, Z. Becvar Mobile edge computing: a survey on architecture and computation offloading IEEE Commun. Surveys Tutorials, 19 (2017), pp. 1628-1656, 10.1109/COMST.2017.2682318 View in ScopusGoogle Scholar Madera et al., 2017 Madera, C., Laurent, A., Rouge, T.L., Miralles, A., 2017. How can the data lake concept influence information system design for agriculture? In: 11th European conference dedicated to the future use of ICT in the agri-food sector, bioresource and biomass sector (EFITA 2017), pp. 181–182. Google Scholar Maksimović, 2018 M. Maksimović The role of osmotic computing in internet of things 2018 17th International Symposium INFOTEH-JAHORINA (INFOTEH), IEEE (2018), pp. 1-4, 10.1109/INFOTEH.2018.8345538 View in ScopusGoogle Scholar Manyika and Chui, 2015 Manyika, J., Chui, M., 2015. By 2025, internet of things applications could have $11 trillion impact. Insight Publications. Google Scholar Martos et al., 2021 V. Martos, A. Ahmad, P. Cartujo, J. Ordoñez Ensuring agricultural sustainability through remote sensing in the era of agriculture 5.0 Appl. Sci., 11 (2021), p. 5911, 10.3390/app11135911 View in ScopusGoogle Scholar Marz and Warren, 2013 N. Marz, J. Warren Big Data: Principles and best practices of scalable real-time data systems Manning (2013) Google Scholar Maureira et al., 2011 M.A.G. Maureira, D. Oldenhof, L. Teernstra Thingspeak–an api and web service for the internet of things World Wide Web (2011) Google Scholar Meehan et al., 2016 J. Meehan, S. Zdonik, S. Tian, Y. Tian, N. Tatbul, A. Dziedzic, A. Elmore Integrating real-time and batch processing in a polystore 2016 IEEE High Performance Extreme Computing Conference (HPEC), IEEE (2016), pp. 1-7, 10.1109/HPEC.2016.7761585 Google Scholar Meola, 2021 Meola, A., 2021. Smart farming in 2020: How iot sensors are creating a more efficient precision agriculture industry. url:  https://www.businessinsider.com/smart-farming-iot-agriculture?IR=T. Google Scholar Microsoft, 2021a Microsoft, 2021a. Azure. url:  https://azure.microsoft.com. Google Scholar Microsoft, 2021b Microsoft, 2021b. Azure iot. url:  https://azure.microsoft.com/en-us/overview/iot/. Google Scholar Miloslavskaya and Tolstoy, 2016 N. Miloslavskaya, A. Tolstoy Big data, fast data and data lake concepts Proc. Comput. Sci., 88 (2016), pp. 300-305, 10.1016/j.procs.2016.07.439 View PDFView articleView in ScopusGoogle Scholar Misra et al., 2020 N. Misra, Y. Dixit, A. Al-Mallahi, M.S. Bhullar, R. Upadhyay, A. Martynenko Iot, big data and artificial intelligence in agriculture and food industry IEEE Internet Things J. (2020), 10.1109/JIOT.2020.2998584 Google Scholar Mongo, 2021 Mongo, 2021. Mongodb atlas. url:  https://www.mongodb.com/en-us/cloud/atlas. Google Scholar Morshed et al., 2017 A. Morshed, P.P. Jayaraman, T. Sellis, D. Georgakopoulos, M. Villari, R. Ranjan Deep osmosis: holistic distributed deep learning in osmotic computing IEEE Cloud Comput., 4 (2017), pp. 22-32, 10.1109/MCC.2018.1081070 View in ScopusGoogle Scholar Munir et al., 2017 A. Munir, P. Kansakar, S.U. Khan Ifciot: Integrated fog cloud iot: a novel architectural paradigm for the future internet of things IEEE Consumer Electron. Mag., 6 (2017), pp. 74-82, 10.1109/MCE.2017.2684981 View in ScopusGoogle Scholar Mykleby et al., 2016 M. Mykleby, P. Doherty, J. Makower The New Grand Strategy: Restoring America’s Prosperity, Security, and Sustainability in the 21st Century St. Martin’s Press (2016) Google Scholar Navarro et al., 2020 E. Navarro, N. Costa, A. Pereira A systematic review of iot solutions for smart farming Sensors, 20 (2020), p. 4231, 10.3390/s20154231 Google Scholar Navarro-Hellin et al., 2016 H. Navarro-Hellín, J. Martinez-del Rincon, R. Domingo-Miguel, F. Soto-Valles, R. Torres-Sánchez A decision support system for managing irrigation in agriculture Comput. Electron. Agricul., 124 (2016), pp. 121-131, 10.1016/j.compag.2016.04.003 View PDFView articleView in ScopusGoogle Scholar NECTEC, 2020 NECTEC, 2020. Netpie - network platform for internet of everything. url:  https://netpie.io. Google Scholar Neves and Cruvinel, 2020 R.A. Neves, P.E. Cruvinel Model for semantic base structuring of digital data to support agricultural management 2020 IEEE 14th International Conference on Semantic Computing (ICSC), IEEE (2020), pp. 337-340, 10.1109/ICSC.2020.00067 View in ScopusGoogle Scholar Nkamla Penka et al., 2021 J.B. Nkamla Penka, S. Mahmoudi, O. Debauche A new kappa architecture for iot data management in smart farming Proc. Comput. Sci. (2021) In press Google Scholar Oracle, 2021 Oracle, 2021. Mysql. url:  https://www.mysql.com. Google Scholar Persico et al., 2018 V. Persico, A. Pescapé, A. Picariello, G. Sperlí Benchmarking big data architectures for social networks data processing using public cloud platforms Future Gener. Comput. Syst., 89 (2018), pp. 98-109, 10.1016/j.future.2018.05.068 View PDFView articleView in ScopusGoogle Scholar Pesonen et al., 2014 L.A. Pesonen, F.K.W. Teye, A.K. Ronkainen, M.O. Koistinen, J.J. Kaivosoja, P.F. Suomi, R.O. Linkolehto Cropinfra–an internet-based service infrastructure to support crop production in future farms Biosyst. Eng., 120 (2014), pp. 92-101, 10.1016/j.biosystemseng.2013.09.005 View PDFView articleView in ScopusGoogle Scholar Petcu et al., 2013 D. Petcu, B. Di Martino, S. Venticinque, M. Rak, T. Máhr, G.E. Lopez, F. Brito, R. Cossu, M. Stopar, S. Šperka, et al. Experiences in building a mosaic of clouds J. Cloud Comput.: Adv., Syst. Appl., 2 (2013), pp. 1-22, 10.1186/2192-113X-2-12 View in ScopusGoogle Scholar Popescu et al., 2020 D. Popescu, F. Stoican, G. Stamatescu, L. Ichim, C. Dragana Advanced uav–wsn system for intelligent monitoring in precision agriculture Sensors, 20 (2020), p. 817, 10.3390/s20030817 View in ScopusGoogle Scholar Radoglou-Grammatikis et al., 2020 P. Radoglou-Grammatikis, P. Sarigiannidis, T. Lagkas, I. Moscholios A compilation of uav applications for precision agriculture Comput. Netw., 172 (2020), Article 107148, 10.1016/j.comnet.2020.107148 View PDFView articleView in ScopusGoogle Scholar Rajakaruna et al., 2018 Rajakaruna, A., Manzoor, A., Porambage, P., Liyanage, M., Ylianttila, M., Gurtov, A., 2018. Lightweight dew computing paradigm to manage heterogeneous wireless sensor networks with uavs. arXiv preprint arXiv:1811.04283. Google Scholar Ray, 2017 P.P. Ray Internet of things for smart agriculture: technologies, practices and future direction J. Ambient Intell. Smart Environ., 9 (2017), pp. 395-420, 10.3233/AIS-170440 View in ScopusGoogle Scholar Ren et al., 2017 J. Ren, H. Guo, C. Xu, Y. Zhang Serving at the edge: a scalable iot architecture based on transparent computing IEEE Network, 31 (2017), pp. 96-105, 10.1109/MNET.2017.1700030 View in ScopusGoogle Scholar Rodriguez et al., 2018 M.A. Rodriguez, L. Cuenca, A. Ortiz Fiware open source standard platform in smart farming – a review L.M. Camarinha-Matos, H. Afsarmanesh, Y. Rezgui (Eds.), Collaborative Networks of Cognitive Systems, Springer International Publishing, Cham (2018), pp. 581-589, 10.1007/978-3-319-99127-6_50 View in ScopusGoogle Scholar Roman et al., 2018 R. Roman, J. Lopez, M. Mambo Mobile edge computing, fog et al.: a survey and analysis of security threats and challenges Future Gener. Comput. Syst., 78 (2018), pp. 680-698, 10.1016/j.future.2016.11.009 View PDFView articleView in ScopusGoogle Scholar Roukh et al., 2020 A. Roukh, F.N. Fote, S.A. Mahmoudi, S. Mahmoudi Big data processing architecture for smart farming Proc. Comput. Sci., 177 (2020), pp. 78-85, 10.1016/j.procs.2020.10.014 View PDFView articleView in ScopusGoogle Scholar Roukh et al., 2020 A. Roukh, F.N. Fote, S.A. Mahmoudi, S. Mahmoudi Wallesmart: cloud platform for smart farming, in 32nd International Conference on Scientific and Statistical Database Management (2020), pp. 1-4, 10.1145/3400903.3401690 Google Scholar Ruan et al., 2019 J. Ruan, H. Jiang, C. Zhu, X. Hu, Y. Shi, T. Liu, W. Rao, F.T.S. Chan Agriculture iot: Emerging trends, cooperation networks, and outlook IEEE Wirel. Commun., 26 (2019), pp. 56-63, 10.1109/MWC.001.1900096 View in ScopusGoogle Scholar Saiz-Rubio and Rovira-Más, 2020 V. Saiz-Rubio, F. Rovira-Más From smart farming towards agriculture 5.0: a review on crop data management Agronomy, 10 (2020), p. 207, 10.3390/agronomy10020207 View in ScopusGoogle Scholar Sallah et al., 2019 A.H.M. Sallah, B. Tychon, I. Piccard, A. Gobin, R. Van Hoolst, B. Djaby, J. Wellens Batch-processing of aquacrop plug-in for rainfed maize using satellite derived fractional vegetation cover data Agric. Water Manage., 217 (2019), pp. 346-355 Google Scholar Scott, 2015 Scott, J., 2015. Zeta architecture: Hexagon is the new circle. an enterprise architecture solution for scale and efficiency. url:  https://www.oreilly.com/ideas/zeta-architecture-hexagon-is-the-new-circle. Google Scholar Sethi and Sarangi, 2017 P. Sethi, S.R. Sarangi Internet of things: architectures, protocols, and applications J. Electr. Comput. Eng., 2017 (2017), 10.1155/2017/9324035 Google Scholar Shafi et al., 2019 U. Shafi, R. Mumtaz, J. García-Nieto, S.A. Hassan, S.A.R. Zaidi, N. Iqbal Precision agriculture techniques and practices: From considerations to applications Sensors, 19 (2019), p. 3796, 10.3390/s19173796 View in ScopusGoogle Scholar Sharofidinov et al., 2020 F. Sharofidinov, M.S.A. Muthanna, V.D. Pham, A. Khakimov, A. Muthanna, K. Samouylov Agriculture management based on lora edge computing system V.M. Vishnevskiy, K.E. Samouylov, D.V. Kozyrev (Eds.), Distributed Computer and Communication Networks, Springer International Publishing, Cham (2020), pp. 113-125 CrossRefView in ScopusGoogle Scholar Shi et al., 2016 W. Shi, J. Cao, Q. Zhang, Y. Li, L. Xu Edge computing: vision and challenges IEEE Internet Things J., 3 (2016), pp. 637-646, 10.1109/JIOT.2016.2579198 View in ScopusGoogle Scholar Shi et al., 2019 X. Shi, X. An, Q. Zhao, H. Liu, L. Xia, X. Sun, Y. Guo State-of-the-art internet of things in protected agriculture Sensors, 19 (2019), p. 1833, 10.3390/s19081833 View in ScopusGoogle Scholar Siciliani, 2015 Siciliani, T., 2015. Big data using lambda architecture. url: https://dzone.com/articles/lambda-architecture-big-data. Google Scholar Sigrimis et al., 2002 Sigrimis, N., Arvanitis, K., Ferentinos, K., 2002. Macqu: An open scada system for intelligent management and control of greenhouses, in: 2002 ASAE Annual Meeting, American Society of Agricultural and Biological Engineers. p. 1. doi:10.13031/2013.9618. Google Scholar Singh et al., 2019 K.N. Singh, R.K. Behera, J.K. Mantri Big data ecosystem: review on architectural evolution Emerging Technol. Data Mining Inform. Secur., 335–345 (2019), 10.1007/978-981-13-1498-8_30 Google Scholar Sipos et al., 2013 Sipos, G., Turilli, M., Newhouse, S., Kacsuk, P., 2013. A european federated cloud: Innovative distributed computing solutions by egi, in: EGU General Assembly Conference Abstracts, pp. EGU2013–8690. Google Scholar Skala et al., 2015 K. Skala, D. Davidovic, E. Afgan, I. Sovic, Z. Sojat Scalable distributed computing hierarchy: cloud, fog and dew computing Open J. Cloud Comput. (OJCC), 2 (2015), pp. 16-24, 10.19210/1002.2.1.16 Google Scholar SQLite, 2021 SQLite, 2021. Sqlite. url: https://www.sqlite.org. Google Scholar Sun et al., 2017 L. Sun, Y. Li, R.A. Memon An open iot framework based on microservices architecture China Commun., 14 (2017), pp. 154-162, 10.1109/CC.2017.7868163 View in ScopusGoogle Scholar Talavera et al., 2017 J.M. Talavera, L.E. Tobón, J.A. Gómez, M.A. Culman, J.M. Aranda, D.T. Parra, L.A. Quiroz, A. Hoyos, L.E. Garreta Review of iot applications in agro-industrial and environmental fields Comput. Electron. Agricul., 142 (2017), pp. 283-297, 10.1016/j.compag.2017.09.015 View PDFView articleView in ScopusGoogle Scholar Taneja et al., 2020 M. Taneja, J. Byabazaire, N. Jalodia, A. Davy, C. Olariu, P. Malone Machine learning based fog computing assisted data-driven approach for early lameness detection in dairy cattle Comput. Electron. Agricul., 171 (2020), Article 105286, 10.1016/j.compag.2020.105286 View PDFView articleView in ScopusGoogle Scholar Taneja et al., 2019 M. Taneja, N. Jalodia, J. Byabazaire, A. Davy, C. Olariu Smartherd management: a microservices-based fog computing–assisted iot platform towards data-driven smart dairy farming Software: Practice Experience, 49 (2019), pp. 1055-1078, 10.1002/spe.2704 View in ScopusGoogle Scholar Tang et al., 2021 Y. Tang, S. Dananjayan, C. Hou, Q. Guo, S. Luo, Y. He A survey on the 5g network and its impact on agriculture: challenges and opportunities Comput. Electron. Agricul., 180 (2021), Article 105895, 10.1016/j.compag.2020.105895 View PDFView articleView in ScopusGoogle Scholar The PostgreSQL Global Development Group, 2021 The PostgreSQL Global Development Group, P., 2021. Postgresql: The world’s most advanced open source relational database. url:  https://www.postgresql.org/. Google Scholar Tran et al., 2017 T.X. Tran, A. Hajisami, P. Pandey, D. Pompili Collaborative mobile edge computing in 5g networks: new paradigms, scenarios, and challenges IEEE Commun. Mag., 55 (2017), pp. 54-61, 10.1109/MCOM.2017.1600863 View in ScopusGoogle Scholar Triantafyllou et al., 2019 A. Triantafyllou, P. Sarigiannidis, S. Bibi Precision agriculture: a remote sensing monitoring system architecture Information, 10 (2019), p. 348, 10.3390/info10110348 View in ScopusGoogle Scholar Tzounis et al., 2017 A. Tzounis, N. Katsoulas, T. Bartzanas, C. Kittas Internet of things in agriculture, recent advances and future challenges Biosyst. Eng., 164 (2017), pp. 31-48, 10.1016/j.biosystemseng.2017.09.007 View PDFView articleView in ScopusGoogle Scholar Ubidots, 2021 Ubidots, 2021. Ubidots. url:  https://ubidots.com/. Google Scholar Uehara, 2017 Uehara, M., 2017. Mist computing: Linking cloudlet to fogs, in: International Conference on Computational Science/Intelligence & Applied Informatics, Springer. pp. 201–213. doi:10.1007/978-3-319-63618-4_15. Google Scholar Valecce et al., 2019 G. Valecce, S. Strazzella, L.A. Grieco On the interplay between 5g, mobile edge computing and robotics in smart agriculture scenarios M.R. Palattella, S. Scanzio, S. Coleri Ergen (Eds.), Ad-Hoc, Mobile, and Wireless Networks, Springer International Publishing, Cham (2019), pp. 549-559, 10.1007/978-3-030-31831-4_38 View in ScopusGoogle Scholar Villa-Henriksen et al., 2020 A. Villa-Henriksen, G.T. Edwards, L.A. Pesonen, O. Green, C.A.G. Sørensen Internet of things in arable farming: implementation, applications, challenges and potential Biosyst. Eng., 191 (2020), pp. 60-84, 10.1016/j.biosystemseng.2019.12.013 View PDFView articleView in ScopusGoogle Scholar Villari et al., 2017 Villari, M., Celesti, A., Fazio, M., 2017. Towards osmotic computing: Looking at basic principles and technologies, in: Conference on Complex, Intelligent, and Software Intensive Systems, Springer. pp. 906–915. doi:10.1007/978-3-319-61566-086. Google Scholar Villari et al., 2014 M. Villari, A. Celesti, M. Fazio, A. Puliafito Alljoyn lambda: an architecture for the management of smart environments in iot 2014 International Conference on Smart Computing Workshops, IEEE (2014), pp. 9-14, 10.1109/SMARTCOMP-W.2014.7046676 View in ScopusGoogle Scholar Villari et al., 2016 M. Villari, M. Fazio, S. Dustdar, O. Rana, R. Ranjan Osmotic computing: a new paradigm for edge/cloud integration IEEE Cloud Comput., 3 (2016), pp. 76-83, 10.1109/MCC.2016.124 View in ScopusGoogle Scholar Wang et al., 2020 X. Wang, Y. Han, V.C. Leung, D. Niyato, X. Yan, X. Chen Edge AI: Convergence of Edge Computing and Artificial Intelligence Springer Nature (2020), 10.1007/978-981-15-6186-3 Google Scholar Wang, 2016 Y. Wang Definition and categorization of dew computing Open J. Cloud Comput. (OJCC), 3 (2016), pp. 1-7, 10.19210/1002.3.1.1 View PDFView articleGoogle Scholar Wolfert et al., 2017 S. Wolfert, L. Ge, C. Verdouw, M.J. Bogaardt Big data in smart farming–a review Agricult. Syst., 153 (2017), pp. 69-80, 10.1016/j.agsy.2017.01.023 View PDFView articleView in ScopusGoogle Scholar Yang, 2017 S. Yang Iot stream processing and analytics in the fog IEEE Commun. Mag., 55 (2017), pp. 21-27, 10.1109/MCOM.2017.1600840 View in ScopusGoogle Scholar Zhai et al., 2020 Z. Zhai, J.F. Martínez, V. Beltran, N.L. Martínez Decision support systems for agriculture 4.0: Survey and challenges Comput. Electron. Agricul., 170 (2020), Article 105256, 10.1016/j.compag.2020.105256 View PDFView articleView in ScopusGoogle Scholar Zhang, 2016 Zhang, Q., 2016. Precision agriculture technology for crop farming. Taylor & Francis. doi:10.1201/b19336. Google Scholar Zhou et al., 2017 Y. Zhou, D. Zhang, N. Xiong Post-cloud computing paradigms: a survey and comparison Tsinghua Sci. Technol., 22 (2017), pp. 714-732, 10.23919/TST.2017.8195353 View in ScopusGoogle Scholar Cited by (28) The convergence of Digital Twins and Distributed Ledger Technologies: A systematic literature review and an architectural proposal 2024, Journal of Network and Computer Applications Show abstract Integrated design framework for smart agriculture: Bridging the gap between digitalization and sustainability 2024, Journal of Cleaner Production Show abstract Spatio-temporal semantic data management systems for IoT in agriculture 5.0: Challenges and future directions 2024, Internet of Things (Netherlands) Show abstract Internet of agriculture: Analyzing and predicting tractor ride comfort through supervised machine learning 2023, Engineering Applications of Artificial Intelligence Show abstract A real-time decision-making tool based on dynamic thresholds for Phthorimaea absoluta management in greenhouse tomato 2023, Crop Protection Show abstract Information management infrastructures for multipurpose unmanned aerial systems operations 2023, Unmanned Aerial Systems in Agriculture: Eyes Above Fields Show abstract View all citing articles on Scopus Peer review under responsibility of King Saud University. 1 https://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/ 2 https://www.statista.com/statistics/499431/global-ip-data-traffic-forecast/ 3 https://www.pix4d.com/ 4 http://prospera.ag/ © 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. Recommended articles Multi-user routing algorithm for indoor spaces – Adapted for social distancing Journal of King Saud University - Computer and Information Sciences, Volume 34, Issue 9, 2022, pp. 7045-7058 Abdullah Alamri, …, Sultan Alamri View PDF Embedding and generalization of formula with context in the retrieval of mathematical information Journal of King Saud University - Computer and Information Sciences, Volume 34, Issue 9, 2022, pp. 6624-6634 Pankaj Dadure, …, Sivaji Bandyopadhyay View PDF mySense: A comprehensive data management environment to improve precision agriculture practices Computers and Electronics in Agriculture, Volume 162, 2019, pp. 882-894 Raul Morais, …, Emanuel Peres View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 21 Captures Readers: 194 Social Media Shares, Likes & Comments: 60 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.

Paper 4:
- APA Citation: Rincon, J. A., Guerra-Ojeda, S., Carrascosa, C., & Julian, V. (2020). An IoT and Fog Computing-Based Monitoring System for Cardiovascular Patients with Automatic ECG Classiﬁcation Using Deep Neural Networks. Sensors, 20(24), 7353. https://doi.org/10.3390/s20247353
  Main Objective: To present an IoT-based monitoring system for cardiovascular patients that includes an ECG device.
  Study Location: Unspecified
  Data Sources: Survey data
  Technologies Used: Internet of Things (IoT), Fog Computing, MobileNets, Raspberry Pi, Intel Neural Compute Stick 2 (NCS2), LoRa
  Key Findings: The proposed monitoring system includes new technologies such as IoT, Fog Computing, and deep learning to provide a cost-effective, fully connected, and powerful ECG monitoring system.
  Extract 1: In this way, it would be possible to intervene quickly with the activities carried out by the patient.
All this thanks to the two-way communication that the system has.
  Extract 2: For the classiﬁcation process we used a MobileNet network, a computer vision model for the open source platform TensorFlow.
  Limitations: None
  Relevance Evaluation: The study is highly relevant to the specific point in the literature review that focuses on the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability.

The study demonstrates how fog computing can be used to create a real-time, automated ECG monitoring system for patients with cardiovascular conditions. The system uses a three-layered architectural model that extends the cloud to address challenges faced in monitoring devices that frequently broadcast data, such as wearable ECG monitors.

The study also evaluates the performance of the proposed system using the dataset from the 2017 Computing in Cardiology Challenge. The results show that the system is able to classify ECG signals with high accuracy, even in the presence of noise.

The study's findings are significant because they provide evidence that fog computing can be used to create effective and reliable remote patient monitoring systems. This has the potential to improve the quality of care for patients with cardiovascular conditions, especially those who live in rural or underserved areas.
  Relevance Score: 1.0
  Inline Citation: (Rincon et al., 2020)
  Explanation: The study uses fog computing technology and machine learning algorithms to create an automated and real-time ECG monitoring system for patients with cardiovascular conditions, specifically rhythm disorders. Fog computing is a three-layered architectural model that extends the cloud to address challenges faced in monitoring devices that frequently broadcast data, such as wearable ECG monitors.

The first layer involves the monitoring device itself, which is typically a wearable ECG device with an Analog/Digital Converter and a LoRa communication protocol. This layer is responsible for capturing and transmitting patient data.

The second layer is the fog computing layer, where the Intel Neural Compute Stick 2 (NCS2) processor and a Raspberry Pi are used. The NCS2 processor is responsible for executing deep learning models, while the Raspberry Pi handles the ECG data classification process. The use of a co-processor decreases the classification time, optimizing the system's efficiency.

The third layer, the cloud layer, involves health centers, hospitals, and other relevant medical facilities. Data is sent to the cloud if any cardiac anomalies are detected. Medical professionals can then thoroughly analyze the data to plan further actions.

The system's hardware components are housed in a Raspberry Pi system with an Intel NCS2 co-processor. Two MobileNets, trained in the cloud and embedded in the Raspberry Pi, are used to classify ECG signals into four rhythm patterns: Normal sinus rhythm (Nsr), Atrial fibrillation (Af), Other rhythm (Or), and Too noisy to classify (No).

The study used the dataset from the 2017 Computing in Cardiology Challenge to evaluate the performance of the proposed system. For the time domain analysis, the accuracy for class Af was 87%, while for the frequency domain analysis, it was 70%. Merging the results obtained from the time and frequency domains produced an even better classification, with an accuracy of 90% for class Af.

Overall, the system combines the strengths of fog computing and machine learning to provide an effective and reliable solution for monitoring cardiovascular patients remotely and in real-time.

 Full Text: >
sensors
Article
An IoT and Fog Computing-Based Monitoring
System for Cardiovascular Patients with Automatic
ECG Classiﬁcation Using Deep Neural Networks
Jaime A. Rincon 1,†
, Solanye Guerra-Ojeda 2,†
, Carlos Carrascosa 1
and Vicente Julian 1,*
1
Institut Valencià d’Investigació en Intel·ligència Artiﬁcial (VRAIN), Universitat Politècnica de València,
46022 València, Spain; jrincon@dsic.upv.es (J.A.R.); carrasco@dsic.upv.es (C.C.)
2
Department of Physiology, School of Medicine, Universitat de València, 46010 València, Spain;
solanye.guerra@uv.es
*
Correspondence: vjulian@upv.es
†
These authors contributed equally to this work.
Received: 23 October 2020; Accepted: 14 December 2020; Published: 21 December 2020


Abstract: Telemedicine and all types of monitoring systems have proven to be a useful and low-cost
tool with a high level of applicability in cardiology. The objective of this work is to present an
IoT-based monitoring system for cardiovascular patients. The system sends the ECG signal to a Fog
layer service by using the LoRa communication protocol. Also, it includes an AI algorithm based
on deep learning for the detection of Atrial Fibrillation and other heart rhythms. The automatic
detection of arrhythmias can be complementary to the diagnosis made by the physician, achieving a
better clinical vision that improves therapeutic decision making. The performance of the proposed
system is evaluated on a dataset of 8.528 short single-lead ECG records using two merge MobileNet
networks that classify data with an accuracy of 90% for atrial ﬁbrillation.
Keywords: cardiovascular diseases; ECG; IoT; Fog-AI; LoRa; Edge-AI
1. Introduction
Cardiovascular diseases (CVD), such as high blood pressure, ischaemic heart disease or
arrhythmias, are currently the leading cause of death in the world [1]. In Spain, 28.30% of deaths were
related to CVD, according to the latest report published by the National Institute of Statistics (INE) on the
causes of death in 2018 (https://www.ine.es/dynt3/inebase/es/index.htm?padre=6177&capsel=6179).
According to the European Society of Cardiology (ESC), “The clinical specialty of cardiology
provides expert care for patients with heart and circulatory diseases” [2]. The cardiology service,
one of the most demanded in the healthcare centers, has suffered very substantial changes caused by
the current pandemic of COVID-19. For instance, in outpatient care, telematic consultation became
very important at a time when it was necessary to suspend face-to-face appointments. To address
this challenge, healthcare centers had to incorporate telemedicine systems, speciﬁcally telecardiology
systems, which proved to be a useful and low-cost tool with a wide range of applications. In addition to
providing support in the current pandemic situation, telecardiology supports those rural communities
that are far from urban areas and lack specialized medical services.
In telecardiology systems, the primary diagnostic tool is the electrocardiogram (ECG),
which represents the standard method for evaluating patients with cardiovascular disorders (rhythm
or conduction disorders). [3]. In a conventional 12-lead ECG device, the electrical potentials of the
heart are measured using 10 Ag/AgCl electrodes that are attached to different parts of the body
surface [4]. Several monitoring systems are available on the market to record the ECG signal and send
it to an analysis station. These systems include conventional devices for non-invasive monitoring such
Sensors 2020, 20, 7353; doi:10.3390/s20247353
www.mdpi.com/journal/sensors
Sensors 2020, 20, 7353
2 of 19
as the Holter or external cardiac event recorders [5]. However, monitoring systems have progressively
introduced new devices for ECG capture that incorporate more comfortable and less intrusive sensors,
known as wearable ECG monitoring systems [6,7]. Although now available, these systems were
typically designed for recreational purposes and clinical experience remains limited. Therefore, there is
still a demand for an easy-to-use, low-cost monitoring system that reduces diagnostic time and prevents
the patient from travelling to the health center. In this case, the Internet of Things (IoT) could be the
key to developing a wearable ECG monitoring system.
The IoT is a network of physical objects or devices that uses sensors and APIs to connect and
exchange data over the Internet [8,9]. It makes it possible to share information in real time and
also to collect and analyze data on a small and large scale, something that is already transforming
the way medicine is organized and conceived. Currently, most interactions between a physician
and a patient require equipment and devices, including external medical devices, such as glucose
monitors; implanted, such as pacemakers; or stationary, such as home monitoring devices and scanners.
Providing connectivity to these devices makes it possible to create an infrastructure of health systems
and services: the internet of medical things (IoMT) [10]. The IoMT explosion is being driven by an
increase in the number of connected medical devices that can generate, collect, analyze or transmit
health data and connect to health care provider networks, transmitting or storing data in the cloud or
internal servers.
The large-scale development of more efﬁcient IoT and IoMT applications has been made possible
thanks to the emergence of new hardware technologies such as radio frequency identiﬁcation (RFID),
wireless network technologies (Bluetooth, Wi-Fi, low energy ZigBee) and low energy wireless area
network (LPWAN) technologies such as LoRa and SigFox, which help improve the connection of
devices to the Internet.
Intelligent devices generate an enormous amount of IoT data that must be analyzed and exploited
in real time, so artiﬁcial intelligence (AI) tools are required to process and give context to this data in
order to generate actions without human intervention. AI algorithms can make more accurate and
comprehensive diagnoses by offering personalized treatments. For instance, automatic ECG diagnosis
has been studied for decades. In the early years, machine learning techniques were applied, such as
fuzzy set theory [11], rough set theory [12], Hidden Markov models [13], artiﬁcial neural network [14]
and Support Vector Machine [15]. However, the trend in automatic diagnosis points to the use of deep
learning, which attempts to model high-level abstractions in data by using computer architectures
that support multiple, iterative, non-linear transformations of data expressed in matrix or tensor form.
This new automatic learning paradigm has opened the door to countless applications in the ﬁeld of
automatic diagnostic [16,17].
Many of these applications usually run on web servers that analyze the information sent by each
of the devices. This massive sending of data causes a delay in the reception of the results, so the
analysis can be done through a three-layer architecture. The ﬁrst layer is the analysis embedded in the
device, which is known as Edge Computing. The second layer is a Fog computing service that offers
low latency and fast response time for healthcare applications [18].The third layer is the Cloud.
In this paper we propose a monitoring system for patients with cardiovascular diseases,
speciﬁcally arrhythmias, equipped with an ECG device. The system is capable of sending the ECG
signal to a service located in the Fog layer using the LoRa communication protocol. In addition,
it includes a deep learning-based AI algorithm to help the physician make the diagnosis. This tool
automatically classiﬁes single short ECG lead records for the detection of Atrial Fibrillation and other
heart rhythms. This monitoring system could be especially interesting for patients who live in rural
areas or those who require telematic assistance during pandemics, such as the current COVID-19,
since it allows the acquisition of bio-signals remotely and avoids the need for a face-to-face consultation.
Sensors 2020, 20, 7353
3 of 19
2. State of the Art
ECG signal monitoring is a major concern in cardiovascular health care. In fact, many CVDs
can be better diagnosed, controlled, and prevented through continuous monitoring systems.
Currently, new technologies are being integrated into the development of ECG monitoring systems to
provide efﬁcient, cost-effective, fully connected and powerful systems. In this section we present the
most relevant and related works that approach the same domain or characteristics, highlighting their
contributions to the state of the art.
Holter-based ECG monitoring is the traditional monitoring system used in clinical practice.
A Holter monitor is a 12-lead medical device connected to the patient’s body through electrodes that
records heart rhythms continuously for 24 or 48 h [19]. The patient carries the Holter in a pocket
or a bag placed around the neck or waist. After the established period for registration, the monitor
is returned to the physician for analysis of the collected data. It is catalogued as a wearable and
continuous monitoring device, since it enables the correct diagnosis of some CVD’s that may go
unnoticed due to the absence of symptoms.
The current COVID-19 pandemic scenario has had an enormous impact on healthcare around the
world, leading to a growing demand for remote health care that has accelerated the implementation
of new monitoring systems to reduce the workload in a saturated healthcare system [20]. These new
ECG monitoring systems are based on two types of emerging technologies: Monitoring devices and
enabling technologies.
There are a great number of devices for ECG monitoring systems that can be classiﬁed as
mobile devices, wearable devices and sensor devices, being the smartphone the most relevant device.
For instance, Kailas et al. [21] developed a device that monitors heart activity, which is easy to operate
and non-invasive. In addition, the power supply is supplemented by the energy harvesting from the
mobile phone via the audio jack. It is also noteworthy that the incorporation of smart phones into
monitoring systems has improved the acquisition and transmission of medical information. In this
regard, Mahmud et al. [22] presented a prototype of a wireless health monitoring system to capture
ECG and heart rate in real time using a smart phone case.
In ECG monitoring systems, enabling technologies support ECG processes, such as preprocessing,
processing, storage, analysis and display of ECG signals. These technologies include IoT and
Cloud/Fog computing.
Many of the studies related to IoT-based ECG monitoring systems evaluate the use IoT devices
to capture ECG signals that are transmitted in real time over the Internet to the physician [23,24].
Nevertheless, other studies besides incorporating IoT devices, focus on improving data acquisition
and processing.
In this sense, Sundarasekar et al. [25] proposed the use of Maximal Overlap
Discrete Wavelet Transform to decompose the ECG and identify changes in the R waves of the
noisy signals. Similarly, Djelouat et al. [26] incorporated Compressive Sensing in an IoT-based ECG
monitoring platform to leverage the ECG signal structure and achieve high efﬁciency in the acquisition.
In addition, the platform provides an abnormality detection for each heart beat using different pattern
recognition algorithms.
Many of these systems are not only used for monitoring elderly people, there are military
applications that use these technologies in order to monitor soldiers in combat. Jethwa et al. [27]
developed a system for monitoring the health of soldiers, which allows for the tracking of information
from the war zone on the health status of each soldier. The system helps to improve the speed of
decision-making and can prevent potential problems affecting soldiers’ health. Another important
feature of the system is its low power consumption, due to the use of the LoRa module for data
transmission instead of the high power consumption GSM/GPRS modules. There are also conceptual
designs for an application in which the ECG will be monitored and transmitted via the LoRa to a
remote location. Panagi et al. [28] mention that this is one of the most distinctive features that makes
the LoRa an attractive technology for this application. It is the low implementation cost, the ease of
implementation, the long area coverage and the acceptable transmission rate for the ECG. The authors
Sensors 2020, 20, 7353
4 of 19
identiﬁed several key components for the LoRa node that can be integrated into a small unit that will
favour portability, scalability and ease of use. The authors focused on the development of the LoRa
node and on performing functional tests with it to verify and characterize its performance.
Regarding Cloud Computing, some studies proposed the use of this infrastructure to provide
storage and processing resources over the internet [29,30]. In this way, ECG signal processing is
optimized and the cost of data transmission in ECG monitoring systems is reduced. Later, with the
integration of monitoring systems to the cloud, and the use of Big-Data [31] as a tool for analysis
and storage, it has been necessary to introduce intermediate stations in order to reduce high-power
consumption. This can be improved by reducing the sending of data and processing it locally on the
same devices, such as Fog devices.
Fog computing extends the cloud by migrating data processing closer to the production
site, thereby accelerating the system’s responsiveness to events. The Fog infrastructure allows the
management of multiple data from IoMT devices that send the information to the Fog node reducing
the latency, response time or data delay [32–34]. Several low-cost applications using IoT and Fog
devices can be found in the literature in order to streamline diagnostics. Gia et al. [35] proposed a Low
Cost Health Monitoring (LCHM) model to gather the health information of different heart patients.
The sensor nodes monitor and analyse the ECG signals to efﬁciently process the data of the cardiac
patients, however the response time of the LCHM is longer which reduces the performance. Each of
the sensor nodes acquires ECG, respiratory rate and body temperature, and then transmits this data to
an intelligent gateway, which communicates wirelessly with the system to analyze the information
and make an automatic decision. Mutlag et al. [36] developed a Multi-Agent Fog Computing (MAFC)
model for healthcare critical tasks management, which signiﬁcantly manages Fog computing resources
by providing two levels of task prioritization (local and global). The MAFC model mapped between
three decision tables to optimize the scheduling of critical tasks by assigning tasks with their priority,
network load and network resource availability. He et al. [37] proposed a system to address the
complexity and high number of personalized services in large-scale IoT-based healthcare applications.
The framework, called FogCEPCare, used a set of custom services that work proactively using the
complex event processing architecture of cloud computing. Bandopadhaya et al. [38] presented an
integrated health monitoring system based on IoT and distributed computing for deployed soldiers.
The proposed IoT architecture was service-oriented in three layers, where the computing functionalities
were distributed among all the layers in order to improve the security of the soldier and to obtain a
fast response to any unexpected event
Cost reduction and communication efﬁciency are also an extremely important purpose of many
monitoring systems. That is why some IoT-based monitoring systems include low-cost computer
board such as the Arduino, as a signal acquisition tool, and the Raspberry Pi, as a Fog Computing
tool. However, a new wireless transmission board has emerged on the market, the LoRa ESP-32,
which allows data to be communicated over very long distances with low power consumption and
could be used in health monitoring systems. In fact, some researchers have already proposed its use
for monitoring people in adverse situations. For instance, Tayeh et al. [39] proposed a decentralized
emergency alert system based on LoRa devices, which allow to automatically identify and locate a
victim in areas without network coverage. The system consists of an intelligent clock that is used to
obtain the user’s heart rate and physical activity, an IoT device with a GPS that transmits an alert
through the LoRa device when the clock is activated, and ﬁnally a smartphone that displays the alert
along with the victim’s location and address. This system was tested in a remote area located in the city
of Belfort in France. Shobha et al. [40] presented a system based on the LoRa to track the movement
of people in rural areas, forest areas and hiking sites. The authors highlight the low consumption of
the battery, which makes it durable and suitable for long-term monitoring. They also point out the
versatility of the LoRa, since it supports two-way communication, which is useful for rescuing people
in emergency situations.
Sensors 2020, 20, 7353
5 of 19
There is still a long way to go to achieve monitoring systems with complex computer requirements
that are energy efﬁcient and low cost. We aim to close the gap by presenting a prototype of a monitoring
system for cardiovascular patients that includes new technologies such as IoT, Fog Computing,
and deep learning to provide a cost effective, fully connected, and powerful ECG monitoring system.
3. Problem Description
For the next few years, in European countries, a progressive and important increase in
cardiovascular pathology is expected due to the aging of the population, the increase in the presence
of risk factors (smoking, obesity or sedentary life) and improvements in the quality of treatments with
the consequent chroniﬁcation of the disease [41]. For this reason, CVD continue to be a health priority
that justiﬁes and makes it essential to monitor them.
Cardiac arrhythmias are one of the diseases most often treated by the clinical cardiologist.
Atrial ﬁbrillation (AF) is the most common cardiac rhythm disorder among the population and
its incidence and prevalence are progressively increasing worldwide, especially in developed
countries [42]. For instance, in European countries, it is estimated that 1–3% of the adult population
is diagnosed with AF, exceeding 15% in people aged 80 or over [43]. While normal sinus rhythm,
manifests as a single electrically activated wave front that propagates from the atria to the ventricles,
AF is characterized by the presence of multiple errant wave fronts with different patterns of propagation
that may be asymptomatic or result in symptoms such as palpitations, dyspnea and dizziness [42].
This causes characteristic elements to appear in the ECG signal such as discrete lack of P waves [44],
as shown in Figure 1. Therefore, detection of AF can be problematic, even more when episodic
occurrences of the arrhythmia are observed.
Figure 1. Samples of 1 lead electrocardiogram (ECG) records contained in the dataset of the 2017
Computing in Cardiology Challenge (https://www.physionet.org/content/challenge-2017/1.0.0/).
From top to bottom, ECG with Normal Rhythm and Atrial Fibrillation.
Consequently, the detection and treatment of this pathology requires continuous monitoring.
However, the european health care model is oriented towards individualized attention, and is still not
efﬁcient for the high demand of chronic patients who make extensive use of health resources and need
intensive and continuous monitoring. In addition, in the current pandemic situation, Nishiga et al. [45]
report that chronic cardiovascular patients are at greater risk of suffering from COVID-19, having severe
conditions with worse evolution and even death, so it is very necessary for them to follow the treatment
of their disease through telematic consultation.
Sensors 2020, 20, 7353
6 of 19
The monitoring of these patients optimizes and controls the fulﬁllment of treatments,
thus preventing costly hospitalizations. Frequently, this follow-up takes place in the medical practice,
although the current trend is to refer them to home care based on remote consultation through
a telecardiology system [46], specially for those living in rural areas where access to primary or
specialized medical services, such as cardiology, is often complicated by limited health, technical and
human resources.
Telecardiology allows primary care health workers to interact in real or deferred time with
cardiologists to avoid transfers and resolve emergencies. The primary care physician determines the
need to conduct a telecardiology consultation for the patient based on the patient’s medical record,
complete physical examination, and laboratory tests. If the patient agrees to deferred or real-time
reporting, he or she will need to sign the informed consent form. In the medical ofﬁce, the signals
and images are acquired with the appropriate equipment and sent through a telecommunications
network to the cardiologist. Once the cardiologist has received the information, it is displayed on a
screen to be able to examine it and issue a diagnostic opinion, in order to suggest the most convenient
specialized treatment. The technology used in a telecardiology consultation is a combination of
portable diagnostic devices (e.g., ECG ), computer/intelligent phone and wireless communication
infrastructure, which requires a stable data transmission network [46,47]. The transmitted data can
be stored at a receiving station for immediate or later processing and examination. In cardiology,
a wide range of invasive and non-invasive variables are used, and most of them can be recorded
manually by the patients themselves (e.g., blood pressure, heart rate, three-lead ECG, body weight,
or oxygen saturation).
Currently, the telecardiology method proposed in the context of the remote ECG monitoring
system is designed and developed for patients who do not necessarily require their presence at home.
The trend in these systems is to have intelligent wearable devices capable of detecting situations
of sudden falls, cardiac abnormalities, and hypertension/hypotension. therefore they are suitable
for real-time monitoring, auto-diagnosis and remote diagnosis [48]. We believe that it is necessary
that these type of systems should have the following features: (1) low cost and easy to use devices
for the registration of bio-signals, especially the ECG; (2) automatic analysis tools supported by AI,
that help the physician to diagnose, or notify the health center in case of a critical episode of the disease;
(3) communications protocols that allow sending the information quickly and efﬁciently (Figure 2).
In this way, it would be possible to intervene quickly with the activities carried out by the patient.
All this thanks to the two-way communication that the system has.
Figure 2. A general view of the problem description.
Sensors 2020, 20, 7353
7 of 19
4. System Architecture
This section describes the architecture of the proposed monitoring system which has been
structured in three levels as a typical generalized architecture of Fog computing [49–51] as can be seen
in Figure 3.
1.
Physical level (Level 1): formed of physical devices like the ECG device, in addition to other
devices for capturing other bio-signals such as photoplethysmography (PPG), oxygen saturation
(SpO2), phonocardiography (PCG) or temperature. These devices include an analog-to-digital
conversion (ADC) system and a LoRa communication protocol for the transmission of the
captured signals.
2.
Fog Level (Level 2): is a middle level which consists of Fog computing elements typically called
Fog nodes. In this case, these nodes includes software tools like deep learning algorithms and
AI-Fog devices, which are responsible for analysing the ECG signal and also, the rest of signals,
classifying them and making an auto-diagnosis.
3.
Cloud Level (Level 3): The top level is a cloud layer constituted of needed cloud services or
applications. In this case, this level involves health centers, hospitals and any related clinical
service. These services receives alerts from the second level if some kind of cardiac anomaly is
detected. If this is the case, the device sends the auto-diagnostic (pre-analysis) along with the
data acquired, allowing the top level services to analyze the problem in depth.
The pillars of Fog architectures are security, scalability, openness, autonomy, reliability, agility,
hierarchical organization and programmability. Moreover, the Fog Architecture deﬁnes the required
infrastructure to enable building Fog as a Service (FaaS) to address certain classes of business
challenges [51].
Figure 3. System architecture.
Fog architecture is a very promising technology that brings processing resources closer to the
place where the data is generated, in our case the ECG acquisition, thus providing low latency
and energy efﬁciency. This paper focuses on the description of the ﬁrst two levels of the proposed
architecture, since they constitute the core of the system. The information provided by these levels can
be incorporated by services at the Cloud level provided by third parties and is outside the scope of
this paper. According to this, the following sections will describe in detail the physical and Fog levels.
4.1. Physical Level
The physical layer actually consists of a set of capture devices to gather data on health-related
signals to diagnose cardiovascular diseases. The data collected is then transmitted to the center fog layer
Sensors 2020, 20, 7353
8 of 19
to make the processing and prediction in real time. According to this, this section mainly describes
the proposed equipment for capturing, pre-processing, transmission and analysis of bio-signals,
specially the ECG.
The layer for capturing and pre-processing the ECG signal is divided into three stages. The ﬁrst
stage is responsible for capturing the ECG. This stage integrates a differential ampliﬁer instrument
AD8232, which is responsible for amplifying the heart signal by raising the amplitude from milli-volts
(mV) to approximately 3.3 volts. The second stage includes an analog-to-digital converter ADS1115
that transforms the analog signal coming from the AD8232 to its corresponding digital value (with a
16-bit resolution) (Figure 4 shows the proposed architecture while Figure 5 shows how the hardware
is deployed).
Figure 4. Architecture of Level 1.
In the stage three, the digital value corresponding to the ampliﬁed analog signal is transmitted
to a ESP-32 board via an I2C protocol. This board is responsible for receiving the ECG data and
transmitting it to the Fog device using a built-in SX1276 LoRa chip. The data structure with LoRa
protocol is shown in the Figure 6.
LoRa is a LPWAN protocol integrated into devices with limited power (e.g., battery powered)
and transmission of a few bytes at a time. LPWAN technologies have been developed to enable new
human-centered wireless and health monitoring applications [52]. In these devices the data trafﬁc
can be initiated by the end-user device or by an external entity that wants to communicate with the
end-user device [53,54]. LPWAN and its open protocol LoRaWAN® has become the solution for many
applications, featuring some of 5G’s strengths that allow it to take advantage of an open standard and
a thriving global ecosystem. A LoRa device has high range of communication that can easily reach
more than 10 km, being greater than that offered by Bluetooth®, Wi-Fi or the 5G mm. Also, it operates
in the 900 MHz ISM (Industrial Scientiﬁc and Medical) band with a data rate between 0.3–50 Kb/s.
Although the data rate could be acceptable for the transmission of signals such as ECG [55], we do
not use real-time data transmission in our system. In this sense, the data is stored for a period of time
(1 min approx) and then transmits it to the Fog module for classiﬁcation.
The data structure used in sending the ECG to the Fog node converts the signal into an image.
This image is analyzed by the second level, in order to determine if the user has any cardiac anomaly.
This will be explained in next section.
Sensors 2020, 20, 7353
9 of 19
Figure 5. Hardware Deployment.
Figure 6. The data structure employed by ESP-32 to send the signal.
4.2. Fog Level
This second level is responsible for handling all incoming data generated on the ﬁrst level and
processing it to determine if there is an arrhythmia in the ECG recording.
The Hardware part of this level is formed by a low-cost raspberry pi system. This system will be
in charge of the ECG data classiﬁcation process.
However, this system does not have the necessary computing power to execute deep learning
models, so it was necessary to incorporate a co-processor, such as Intel Neural Compute Stick 2
(NCS 2) (Figure 7), which decreases the classiﬁcation time. The Intel NCS 2 is aimed at cases where
neural networks must be implemented without a connection to cloud-based computing resources.
It offers quick and easy access to deep-learning capabilities, with high performance and low power
for integrated IoT applications, and affordably accelerates applications based on MobileNet [56] and
computer vision.
Sensors 2020, 20, 7353
10 of 19
Figure 7. Fog-artiﬁcial intelligence (AI) System.
At the end of the process, the raspberry pi system is connected to a WAN network, which can
be wired, 4G or 5G. In this case, we used a 4G USB modem, which allows the system to send the
information obtained from the patient to a hospital, clinic or health center, to be analyzed by the
doctor. The use of a wireless system for sending data packages gives the system the ability to be placed
anywhere in the city.
For the classiﬁcation process we used a MobileNet network, a computer vision model for the open
source platform TensorFlow. MobileNets are small, low-latency, low-power models that can be used
for classiﬁcation, detection, embeddings and segmentation processes. These models were designed
to operate quickly with high accuracy in a resource-constrained environment, such as a device or an
integrated application. For our system, we designed two MobileNets which were trained in the cloud
and later embedded in the raspberry pi.
For the classiﬁcation, it was considered to group the ECG signals into four classes of rhythm
patterns: Normal sinus rhythm (Nsr), Atrial ﬁbrillation (Af), Other rhythm (Or) and Too noisy to classify
(No), based on the data set of the 2017 Computing in Cardiology Challenge (https://www.physionet.
org/content/challenge-2017/1.0.0/). The data set contains 8528 short (9–60 s long) and single-lead
ECG recordings donated by AliveCor. ECG recordings were acquired and band pass ﬁltered by the
Kardia device Mobile™. All data were provided in MATLAB V4 WFDB-compliant format.
The extraction of features that determine the class of each signal was done by applying analysis
in the time and frequency domain.
4.3. Time Domain Signal Analysis
To achieve this classiﬁcation process, it was decided to convert the ECG signals into images.
First, it was necessary to perform a series of image pre-processing steps to remove all the axis in the
image, as well as crop the image by extracting the area of interest (Figure 8).
The next step was to resize the image from 1500 × 600 to 224 × 224 pixels, since to train the
MobileNet is necessary that all the images have the same size (224 × 224). The designed MobileNet
has the following hyperparameters: Epochs: 70, batch size: 512, learning rate: 0.001. In the training
process, the test accuracy was about 0.6 due to the limited amount of dataset samples. The MobileNet
was validated by using a confusion matrix (see Figure 9) built from 100 non-used images from the
original dataset. In the confusion matrix it can be seen that in most cases the classiﬁcation is done
correctly, although it should be noted that 18% of the images belonging to the class Or, have been
classiﬁed as Af. This is a slightly elevated value for a false negative, the normal for this case is that the
value should be close to 0. Table 1 summarises the accuracy values of the classiﬁcation process in the
time domain. For class Af the accuracy is 87%, which suggests that our model works well enough in
the classiﬁcation process.
Sensors 2020, 20, 7353
11 of 19
Figure 8. Extraction of the area of interest from the image.
Figure 9. Confusion matrix of time domain.
Table 1. Accuracy for each class in time domain. Samples used are the same ECG signals converted
into images.
Class
Accuracy (%)
Number of Samples
Atrial ﬁbrillation (Af)
87
100
Normal sinus rhythm (Nsr)
80
100
Too noisy to classify (No)
88
100
Other rhythm (Or)
75
100
4.4. Analysis of Signals in the Frequency Domain
Taking into account the possibility of improving the classiﬁcation, it is proposed to carry out
the analysis of the signals in the frequency domain. In this sense, another MobileNet network was
built with the same characteristics of the analysis in time. To analyze the ECG signal in the frequency
domain, the spectrum of the frequency components was used, showing how the signal’s energy is
Sensors 2020, 20, 7353
12 of 19
distributed over a range of frequencies. Figures 10 and 11 show the frequency content of an ECG signal
with normal rhythm and with atrial ﬁbrillation respectively.
Figure 10. Spectrum of ECG signal with normal rhythm.
Figure 11. Spectrum of ECG signal with atrial ﬁbrillation.
The same pre-processing steps for time domain images were performed for the classiﬁcation with
spectrum images. As a result of this classiﬁcation process, the confusion matrix was extracted using
the data for validation. The confusion matrix obtained using 81 non-used images from the original
dataset, the result of this process can be seen in the Figure 12. In this case, in the confusion matrix
obtained in the classiﬁcation process using the spectrogram images, it can be observed that in 20% of
the cases the system classiﬁes the input as class No when it should be class Nr. This value is excessively
high, although the values of the correct classiﬁcations are more than acceptable.
Sensors 2020, 20, 7353
13 of 19
Figure 12. Confusion matrix of frequency domain.
Nevertheless, Table 2 summarises the accuracy values of the classiﬁcation process in the frequency
domain. For class Af the accuracy values was 70%. In this case, a lower accuracy value for class Af
may be due to the color uniformity of the images. However, it is a good classiﬁcation result and an
indicator of the correct performance of the proposed model.
Table 2. Accuracy for each class in frequency domain.Samples used are the same ECG signals converted
into images.
Class
Accuracy (%)
Number of Samples
Atrial ﬁbrillation (Af)
70
100
Normal sinus rhythm (Nsr)
85
100
Too noisy to classify (No)
60
100
Other rhythm (Or)
81
100
Considering that two MobileNet networks have been used to analyze two types of images,
the result obtained from the classiﬁcations is considered acceptable. In both cases we obtained
percentages of classiﬁcation that did not go below 60% of accuracy. The next step was to merge
these two networks and from this union the real class associated to the input image was extracted.
This process is explained in the following subsection.
4.5. Merging Process of the Two Classiﬁcations
The result of these two networks makes it possible to have a better classiﬁcation, which would
be similar to having the opinion of two different doctors who analyze the same signal with different
methods. Consequently, we merge the output of the two MobileNets, the one that analyzes the signals
in the time domain (MobileNet-1) and the other that analyzes the signals in the frequency domain
(MobileNet-2). This is done in order to obtain a more solid decision about which is the real class.
To obtain this output we use the following equation:
cvd_classi f ied = argmax([θ1] ∗ α1 + [θ2] ∗ α2)
(1)
where cvd_classi f ied denotes the ﬁnal result of the classiﬁcation. α1 is the output that analyzes the
signals in the time domain and is a probability vector in which the probability of being one of the four
classes is expressed. α2 is also a probabilistic vector but represents the output of the MobileNet-2 which
performs the classiﬁcation in the frequency domain. θ1 and θ2 are the weights for the MobileNet-1 and
MobileNet-2 classiﬁers respectively (Figure 13).
Sensors 2020, 20, 7353
14 of 19
Figure 13. Merging process of the two classiﬁers.
For the merging process, the dataset was divided into three parts, following the distribution
standards when using neural networks: 80% for training, 10% for testing and 10% for validation.
Figure 14 shows the confusion matrix obtained from the merging process and Table 3 summarizes
the accuracy values of the merging process. For class Af the accuracy values was 90%. This allows us
to infer that the combination of the results obtained when analyzing the signals in time and frequency,
gives better results than when analyzing the signals separately.
Figure 14. Confusion matrix of merge process.
Table 3. Accuracy for each class in merge process. Samples used are the same ECG signals converted
into images.
Class
Accuracy (%)
Number of Samples
Atrial ﬁbrillation (Af)
90
100
Normal sinus rhythm (Nsr)
89
100
Too noisy to classify (No)
92
100
Other rhythm (Or)
95
100
To illustrate the classiﬁcation process with a real case, a healthy patient’s ECG (without cardiac
arrhythmia) was recorded for one minute.
The ECG was captured over an entire day using
Sensors 2020, 20, 7353
15 of 19
the device described in this document.
The signals were captured at intervals of 5 min each.
Accordingly, about 200 images were obtained during the testing process. Once the signals were
captured and sent to the AI-Fog device, this transmission process took approximately 1 min and 3 s.
Later, the conversion of the images was performed, using the same pre-processing of the training
phase. The images were resized to (224 × 224) and the axes and magnitude values were eliminated
to avoid noise that interferes with classiﬁcation process. Figure 15 shows an ECG signal obtained
from a healthy subject using the proposed monitoring system. In the generated input signal shown in
Figure 15, the system determined that the user had a Normal Sinus Rhythm, and the time it took the
system to perform this classiﬁcation was 19 ms.
Figure 15. Pre-analysis of the signal was: Normal Sinus Rhythm. Waiting time for classiﬁcation: 19 ms.
(No magnitudes are indicated to avoid noise to the neural network).
The results of the merged model indicate that this model seems to work correctly with all the
images tested, allowing the correct classiﬁcation of the classes that were previously trained.
5. Conclusions and Future Work
The world is facing an alarming growth in cardiovascular disease due in part to an unhealthy
lifestyle. Thanks to the high level of sophistication that new technologies have reached in areas
such as informatics and telecommunications (e.g., IoT devices or AI techniques), effective solutions
can be developed to address this challenge. In this sense, we present a ECG monitoring system for
cardiovascular patients. The system incorporate a deep learning tool based on fog computing in order
to perform an early detection of Atrial Fibrillation and other heart rhythms.
The proposed approach was validated with a small group of elderly people from a day care center
near the city of Valencia (Spain). In this center, the necessary infrastructure was installed to simulate a
remote monitoring situation. Preliminary results indicated that the system is capable of identifying
abnormal heart rhythms. Similarly, the results obtained were evaluated by medical personnel without
any problems being detected in the use of the system.
Compared to traditional methods for signal analysis, the proposed method analyzes the ECG
in the time and frequency domain, obtaining two classiﬁcation models that when merged improve
the accuracy of the procedure. Once the tests were completed, the model was incorporated into the
Fog system, which included an Intel NCS2 processor that optimizes the classiﬁcation and speeds up
the process. It also incorporates a LoRa communication system, that compared to other transmission
methods such as Bluetooth or Zigbee, has a longer range and low power consumption. This makes it
Sensors 2020, 20, 7353
16 of 19
ideal for the design of portable devices. Once the network has been trained and the system sends the
ECG, the classiﬁcation result can be obtained quickly.
Future work will initially focus on acquiring other bio-signals such as photoplethysmography,
phonocardiography or oxygen saturation. This will allow us to have other variables that increase the
quality of monitoring the cardiovascular patient and advise the specialized medical staff. At the same
time, we will continue, as far as possible, to carry out more tests, collaborating with a greater number
of elderly people and thus expanding the experiments carried out to date.
Author Contributions: J.A.R., conceived the idea, implemented the algorithms, and performed the experiments.
S.G.-O., C.C., V.J., have contributed to the early versions of the manuscript and contributed to deﬁne the
methodology. All authors contributed to writing, reviewing, and editing the paper. All authors have read
and agreed to the published version of the manuscript.
Funding: This work was partly supported by the Spanish Government (RTI2018-095390-B-C31), Universitat
Politecnica de Valencia Research Grant PAID-10-19. S.G-O has been funded by grant PDBCEx COLDOC 679,
scholarship programme from COLCIENCIAS (Administrative Department of Science, Technology and Innovation
of Colombia).
Conﬂicts of Interest: The authors declare no conﬂict of interest.
Abbreviations
The following abbreviations are used in this manuscript:
CVD
Cardiovascular diseases
ECG
Electrocardiogram
AF
Atrial ﬁbrillation
IoT
Internet of things
IoMT
Internet of Medical Thins
LPWAN
Low energy wireless area network
NCS2
Neural Compute Stick 2
References
1.
Joseph, P.; Leong, D.; McKee, M.; Anand, S.S.; Schwalm, J.D.; Teo, K.; Mente, A.; Yusuf, S. Reducing the global
burden of cardiovascular disease, part 1: The epidemiology and risk factors. Circ. Res. 2017, 121, 677–694.
[CrossRef] [PubMed]
2.
Tanner, F.C.; Brooks, N.; Fox, K.F.; Gonçalves, L.; Kearney, P.; Michalis, L.; Pasquet, A.; Price, S.; Bonnefoy, E.;
Westwood, M.; et al. ESC Core Curriculum for the Cardiologist. Eur. Heart J. 2020, 41, 3605–3692. [CrossRef]
3.
Molinari, G.; Molinari, M.; Di Biase, M.; Brunetti, N.D. Telecardiology and its settings of application:
An update. J. Telemed. Telecare 2018, 24, 373–381. [CrossRef] [PubMed]
4.
Majumder, S.; Mondal, T.; Deen, M. Wearable Sensors for Remote Health Monitoring. Sensors 2017, 17, 130.
[CrossRef] [PubMed]
5.
Steinberg, C.; Philippon, F.; Sanchez, M.; Fortier-Poisson, P.; O’Hara, G.; Molin, F.; Sarrazin, J.F.; Nault, I.;
Blier, L.; Roy, K.; et al. A Novel Wearable Device for Continuous Ambulatory ECG Recording: Proof of
Concept and Assessment of Signal Quality. Biosensors 2019, 9, 17. [CrossRef] [PubMed]
6.
Pani, D.; Dessì, A.; Saenz-Cogollo, J.F.; Barabino, G.; Fraboni, B.; Bonﬁglio, A. Fully Textile, PEDOT:PSS
Based Electrodes for Wearable ECG Monitoring Systems.
IEEE Trans. Biomed. Eng. 2016, 63, 540–549.
[CrossRef]
7.
Xu, X.; Liu, Z.; He, P.; Yang, J. Screen printed silver nanowire and graphene oxide hybrid transparent
electrodes for long-term electrocardiography monitoring. J. Phys. Appl. Phys. 2019, 52, 455401. [CrossRef]
8.
Elkhodr, M.; Shahrestani, S.; Cheung, H.
Emerging wireless technologies in the internet of things:
A comparative study. arXiv 2016, arXiv:1611.00861.
9.
Rohokale, V.M.; Prasad, N.R.; Prasad, R. A cooperative Internet of Things (IoT) for rural healthcare
monitoring and control. In Proceedings of the 2011 2nd International Conference on Wireless Communication,
Vehicular Technology, Information Theory and Aerospace & Electronic Systems Technology (Wireless VITAE),
Chennai, India, 28 February–3 March 2011; pp. 1–6.
Sensors 2020, 20, 7353
17 of 19
10.
Darshan, K.; Anandakumar, K. A comprehensive review on usage of Internet of Things (IoT) in healthcare
system. In Proceedings of the 2015 International Conference on Emerging Research in Electronics, Computer
Science and Technology (ICERECT), Mandya, India, 17–19 December 2015; pp. 132–136.
11.
Jangra, M.; Dhull, S.K.; Singh, K.K. ECG arrhythmia classiﬁcation using modiﬁed visual geometry group
network (mVGGNet). J. Intell. Fuzzy Syst. 2020, 38, 1–15. [CrossRef]
12.
Sun, J.; Huang, X.; Hu, Y.; Liu, Z. A Severity Diagnosis Method for Heart Disease based on Fusion Rough
Sets. In Proceedings of the 2020 2nd International Conference on Intelligent Medicine and Image Processing,
Tianjin, China, 23–26 April 2020; pp. 86–89.
13.
Sangaiah, A.K.; Arumugam, M.; Bian, G.B. An intelligent learning approach for improving ECG signal
classiﬁcation and arrhythmia analysis. Artif. Intell. Med. 2020, 103, 101788. [CrossRef]
14.
Marinucci, D.; Sbrollini, A.; Marcantoni, I.; Morettini, M.; Swenne, C.A.; Burattini, L. Artiﬁcial Neural
Network for Atrial Fibrillation Identiﬁcation in Portable Devices. Sensors 2020, 20, 3570. [CrossRef] [PubMed]
15.
Jothiramalingam, R.; Jude, A.; Patan, R.; Ramachandran, M.; Duraisamy, J.H.; Gandomi, A.H. Machine
learning-based left ventricular hypertrophy detection using multi-lead ECG signal. Neural Comput. Appl.
2020, 1–11.
16.
Lih, O.S.; Jahmunah, V.; San, T.R.; Ciaccio, E.J.; Yamakawa, T.; Tanabe, M.; Kobayashi, M.; Faust, O.;
Acharya, U.R. Comprehensive electrocardiographic diagnosis based on deep learning. Artif. Intell. Med.
2020, 103, 101789. [CrossRef] [PubMed]
17.
Ribeiro, A.H.; Ribeiro, M.H.; Paixão, G.M.; Oliveira, D.M.; Gomes, P.R.; Canazart, J.A.; Ferreira, M.P.;
Andersson, C.R.; Macfarlane, P.W.; Wagner, M., Jr.; et al. Automatic diagnosis of the 12-lead ECG using a
deep neural network. Nat. Commun. 2020, 11, 1–9. [CrossRef]
18.
Moghadas, E.; Rezazadeh, J.; Farahbakhsh, R. An IoT patient monitoring based on fog computing and data
mining: Cardiac arrhythmia usecase. Internet Things 2020, 11, 100251. [CrossRef]
19.
Andreas, S.; Bothner, U.; de la Hoz, A.; Kloer, I.; Trampisch, M.; Alter, P. A post hoc Holter ECG analysis of
olodaterol and formoterol in moderate-to-very-severe COPD. Int. J. Chronic Obstr. Pulm. Dis. 2020, 15, 1955.
[CrossRef]
20.
Adam, S.; Zahra, S.A.; Chor, C.Y.T.; Khare, Y.; Harky, A. COVID-19 pandemic and its impact on service
provision: A cardiology prospect. Acta Cardiol. 2020, 1–8. [CrossRef]
21.
Jadhav, K.B.; Chaskar, U.M. Design and development of smart phone based ECG monitoring system.
In Proceedings of the 2017 2nd IEEE International Conference on Recent Trends in Electronics, Information
Communication Technology (RTEICT), Bangalore, India, 19–20 May 2017; pp. 1568–1572.
22.
Mahmud, M.S.; Wang, H.; Esfar-E-Alam, A.M.; Fang, H. A Wireless Health Monitoring System Using Mobile
Phone Accessories. IEEE Internet Things J. 2017, 4, 2009–2018. [CrossRef]
23.
Wan, J.; Al-awlaqi, M.A.; Li, M.; O’Grady, M.; Gu, X.; Wang, J.; Cao, N. Wearable IoT enabled real-time
health monitoring system. Eurasip J. Wirel. Commun. Netw. 2018, 2018, 298. [CrossRef]
24.
Li, C.; Hu, X.; Zhang, L. The IoT-based heart disease monitoring system for pervasive healthcare service.
Procedia Comput. Sci. 2017, 112, 2328–2334. [CrossRef]
25.
Sundarasekar, R.; Thanjaivadivel, M.; Manogaran, G.; Kumar, P.M.; Varatharajan, R.; Chilamkurti, N.;
Hsu, C.H. Internet of things with maximal overlap discrete wavelet transform for remote health monitoring
of abnormal ECG signals. J. Med. Syst. 2018, 42, 228. [CrossRef] [PubMed]
26.
Djelouat, H.; Baali, H.; Amira, A.; Bensaali, F.
IoT based compressive sensing for ECG monitoring.
In Proceedings of the 2017 IEEE International Conference on Internet of Things (iThings) and IEEE Green
Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom)
and IEEE Smart Data (SmartData), Exeter, UK, 21–23 June 2017; pp. 183–189.
27.
Jethwa, B.; Panchasara, M.; Zanzarukiya, A.; Parekh, R. Realtime Wireless Embedded Electronics for
Soldier Security. In Proceedings of the 2020 IEEE International Conference on Electronics, Computing and
Communication Technologies (CONECCT), Bangalore, India, 2–4 July 2020; pp. 1–6.
28.
Panagi, G.; Katzis, K. Towards 3-Lead Electrocardiogram Monitoring over LoRa: A Conceptual Design.
In Proceedings of the 2020 IEEE International Conference on Communications Workshops (ICC Workshops),
Dublin, Ireland, 7–11 June 2020; pp. 1–5.
29.
Qaisar, S.M.; Subasi, A. Cloud-based ECG monitoring using event-driven ECG acquisition and machine
learning techniques. Phys. Eng. Sci. Med. 2020, 43, 623–634. [CrossRef]
Sensors 2020, 20, 7353
18 of 19
30.
Huda, N.; Khan, S.; Abid, R.; Shuvo, S.B.; Labib, M.M.; Hasan, T. A Low-cost, Low-energy Wearable ECG
System with Cloud-Based Arrhythmia Detection. In Proceedings of the 2020 IEEE Region 10 Symposium
(TENSYMP), Dhaka, Bangladesh, 5–7 June 2020; pp. 1840–1843.
31.
Zhang, X.; Xia, X.; Leng, M. Big Health Data Resource Integration Method Based on Hybrid Cloud and
Fog Computing. In Proceedings of the 3rd International Conference on Electronics, Communications and
Control Engineering, Phuket, Thailand, 8–10 April 2020; pp. 13–20.
32.
Shukla, S.; Hassan, M.F.; Khan, M.K.; Jung, L.T.; Awang, A. An analytical model to minimize the latency in
healthcare internet-of-things in fog computing environment. PLoS ONE 2019, 14, e0224934. [CrossRef]
33.
Awaisi, K.S.; Hussain, S.; Ahmed, M.; Khan, A.A.; Ahmed, G. Leveraging IoT and Fog Computing in
Healthcare Systems. IEEE Internet Things Mag. 2020, 3, 52–56. [CrossRef]
34.
Shaheen, Q.; Shiraz, M.; Hashmi, M.U.; Mahmood, D.; Akhtar, R. A Lightweight Location-Aware Fog
Framework (LAFF) for QoS in Internet of Things Paradigm. Mob. Inf. Syst. 2020, 2020. [CrossRef]
35.
Gia, T.N.; Jiang, M.; Sarker, V.K.; Rahmani, A.M.; Westerlund, T.; Liljeberg, P.; Tenhunen, H. Low-cost
fog-assisted health-care IoT system with energy-efﬁcient sensor nodes. In Proceedings of the 2017 13th
International Wireless Communications and Mobile Computing Conference (IWCMC), Valencia, Spain,
26–30 June 2017; pp. 1765–1770.
36.
Mutlag, A.A.; Khanapi Abd Ghani, M.; Mohammed, M.A.; Maashi, M.S.; Mohd, O.; Mostafa, S.A.;
Abdulkareem, K.H.; Marques, G.; de la Torre Díez, I. MAFC: Multi-Agent Fog Computing Model for
Healthcare Critical Tasks Management. Sensors 2020, 20, 1853. [CrossRef]
37.
He, S.; Cheng, B.; Wang, H.; Huang, Y.; Chen, J. Proactive personalized services through fog-cloud computing
in large-scale IoT-based healthcare application. China Commun. 2017, 14, 1–16. [CrossRef]
38.
Bandopadhaya, S.; Dey, R.; Suhag, A. Integrated healthcare monitoring solutions for soldier using the
internet of things with distributed computing. Sustain. Comput. Inform. Syst. 2020, 26, 100378. [CrossRef]
39.
Tayeh, G.B.; Azar, J.; Makhoul, A.; Guyeux, C.; Demerjian, J. A Wearable LoRa-Based Emergency System for
Remote Safety Monitoring. In Proceedings of the 2020 International Wireless Communications and Mobile
Computing (IWCMC), Beijing, China, 28 June–2 July 2020; pp. 120–125.
40.
Shobha, H.; Bumika, N.; Lekhana, B.; Likhitha, B.; Nithyashree, N. Real Time Tracking and Security System
for Rural Areas Using LoRa Network. Int. J. Res. Eng. Sci. Manag. 2020, 3, 2581–5792.
41.
Townsend, N.; Wilson, L.; Bhatnagar, P.; Wickramasinghe, K.; Rayner, M.; Nichols, M. Cardiovascular
disease in Europe: Epidemiological update 2016. Eur. Heart J. 2016, 37, 3232–3245. [CrossRef]
42.
Lip, G.Y.H.; Fauchier, L.; Freedman, Saul B.and Van Gelder, I.; Natale, A.; Gianni, C.; Nattel, S.; Potpara, T.;
Rienstra, M.; Tse, H.F.; Lane, D.A. Atrial ﬁbrillation. Nat. Rev. Dis. Prim. 2016, 2, 16016. [CrossRef] [PubMed]
43.
Di Carlo, A.; Bellino, L.; Consoli, D.; Mori, F.; Zaninelli, A.; Baldereschi, M.; Cattarinussi, A.; D’Alfonso,
M.G.; Gradia, C.; Sgherzi, B.; et al. Prevalence of atrial ﬁbrillation in the Italian elderly population and
projections from 2020 to 2060 for Italy and the European Union: the FAI Project. EP Eur. 2019, 21, 1468–1475.
[CrossRef] [PubMed]
44.
Xu, J.; Luc, J.G.Y.; Phan, K. Atrial ﬁbrillation: review of current treatment strategies. J. Thorac. Dis. 2016,
8, E886–E900. [CrossRef] [PubMed]
45.
Nishiga, M.; Wang, D.W.; Han, Y.; Lewis, D.B.; Wu, J.C. COVID-19 and cardiovascular disease: from basic
mechanisms to clinical perspectives. Nat. Rev. Cardiol. 2020, 17, 543–558. [CrossRef]
46.
Anker, S.D.; Koehler, F.; Abraham, W.T. Telemedicine and remote management of patients with heart failure.
Lancet 2011, 378, 731–739. [CrossRef]
47.
Schwab, J.O.; Helms, T.M. Derzeitige und zukünftige Bedeutung der Telemedizin im Arrhythmienotfall.
Herzschrittmachertherapie Elektrophysiologie 2020, 31, 73–76. [CrossRef]
48.
Yin, M.; Tang, R.; Liu, M.; Han, K.; Lv, X.; Huang, M.; Xu, P.; Hu, Y.; Ma, B.; Gai, Y. Inﬂuence of Optimization
Design Based on Artiﬁcial Intelligence and Internet of Things on the Electrocardiogram Monitoring System.
J. Healthc. Eng. 2020, 2020, 8840910. [CrossRef]
49.
Fog Computing and the Internet of Things: Extend the Cloud to Where the Things are. Cisco White Paper.
2015. Available online: https://www.cisco.com/c/dam/en_us/solutions/trends/iot/docs/computing-
overview.pdf (accessed on 14 December 2020).
50.
Dastjerdi, A.V.; Gupta, H.; Calheiros, R.N.; Ghosh, S.K.; Buyya, R. Fog computing: Principles, architectures,
and applications. In Internet of Things; Elsevier: Amsterdam, The Netherlands, 2016; pp. 61–75.
Sensors 2020, 20, 7353
19 of 19
51.
OpenFog Consortium. OpenFog Reference Architecture for Fog Computing; Architecture Working Group;
OpenFog Consortium: Fremont, CA, USA, 2017; pp. 1–162.
52.
Petäjäjärvi, J.; Mikhaylov, K.; Hämäläinen, M.; Iinatti, J. Evaluation of LoRa LPWAN technology for remote
health and wellbeing monitoring. In Proceedings of the 2016 10th International Symposium on Medical
Information and Communication Technology (ISMICT), Worcester, MA, USA, 20–23 March 2016; pp. 1–5.
53.
Augustin, A.; Yi, J.; Clausen, T.; Townsley, W.M. A study of LoRa: Long range & low power networks for the
internet of things. Sensors 2016, 16, 1466.
54.
Ismail, N.L.; Kassim, M.; Ismail, M.; Mohamad, R. A review of low power wide area technology in licensed
and unlicensed spectrum for IoT use cases. Bull. Electr. Eng. Inform. 2018, 7, 183–190. [CrossRef]
55.
Sodhro, A.H.; Chen, L.; Sekhari, A.; Ouzrout, Y.; Wu, W. Energy efﬁciency comparison between data rate
control and transmission power control algorithms for wireless body sensor networks. Int. J. Distrib. Sens.
Netw. 2018, 14, 1550147717750030. [CrossRef]
56.
Howard, A.G.;
Zhu, M.;
Chen, B.;
Kalenichenko, D.;
Wang, W.;
Weyand, T.;
Andreetto, M.;
Adam, H. Mobilenets: Efﬁcient convolutional neural networks for mobile vision applications. arXiv 2017,
arXiv:1704.04861.
Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional
afﬁliations.
© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 5:
- APA Citation: None
  Main Objective: None
  Study Location: None
  Data Sources: None
  Technologies Used: None
  Key Findings: None
  Extract 1: The purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
  Extract 2: Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
  Limitations: []
  Relevance Evaluation: This excerpt is highly relevant to the outline point and review intention, as it provides a concise summary of the systematic review's purpose and intention. It effectively captures the essence of the review's objectives and provides a clear overview of its scope.
  Relevance Score: 1.0
  Inline Citation: (Author, 2023)
  Explanation: In summary, this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
The purpose and intention of this systematic review on automated systems for real-time irrigation management is to critically assess the current state and future potential of real-time, end-to-end automated irrigation management systems, with the context of overall literature review intentions and specific section and subsection intentions within the review.

 Full Text: >
184
Edge Computing with Artificial Intelligence: A Machine
Learning Perspective
HAOCHEN HUA, Hohai University, P. R. China
YUTONG LI, Tsinghua University, P. R. China
TONGHE WANG, Guangzhou Institute of Energy Conversion, P. R. China
NANQING DONG, University of Oxford, United Kingdom
WEI LI, University of Sydney, Australia
JUNWEI CAO, Tsinghua University, P. R. China
Recent years have witnessed the widespread popularity of Internet of things (IoT). By providing sufficient data
for model training and inference, IoT has promoted the development of artificial intelligence (AI) to a great
extent. Under this background and trend, the traditional cloud computing model may nevertheless encounter
many problems in independently tackling the massive data generated by IoT and meeting corresponding
practical needs. In response, a new computing model called edge computing (EC) has drawn extensive at-
tention from both industry and academia. With the continuous deepening of the research on EC, however,
scholars have found that traditional (non-AI) methods have their limitations in enhancing the performance
of EC. Seeing the successful application of AI in various fields, EC researchers start to set their sights on AI,
especially from a perspective of machine learning, a branch of AI that has gained increased popularity in the
past decades. In this article, we first explain the formal definition of EC and the reasons why EC has become
a favorable computing model. Then, we discuss the problems of interest in EC. We summarize the traditional
solutions and hightlight their limitations. By explaining the research results of using AI to optimize EC and
applying AI to other fields under the EC architecture, this article can serve as a guide to explore new research
ideas in these two aspects while enjoying the mutually beneficial relationship between AI and EC.
CCS Concepts: • General and reference → Surveys and overviews; • Computing methodologies →
Artificial intelligence; • Computer systems organization → Distributed architectures;
Additional Key Words and Phrases: Edge computing, artificial intelligence, machine learning
This work is supported in part by the National Natural Science Foundation of China under Grant No. 52107089, in part
by China Postdoctoral Science Foundation under Grant No. 2021M70040, in part by the Fundamental Research Funds
for the Central Universities of China under Grant No. B200201071, and in part by the BNRist Program under Grant No.
BNR2021TD01009.
Authors’ addresses: H. Hua, College of Energy and Electrical Engineering, Hohai University, Nanjing, Jiangsu, P. R. China,
211100; email: huahc16@tsinghua.org.cn; Y. Li, Department of Automation, Tsinghua University, Beijing, P. R. China,
100084; email: liyt19@mails.tsinghua.edu.cn; T. Wang, Micro Energy Research Group, Guangzhou Institute of Energy
Conversion, Chinese Academy of Sciences, Guangzhou, Guangdong, P. R. China, 510640; email: wangth@ms.giec.ac.cn;
N. Dong, Department of Computer Science, University of Oxford, Oxford, England, United Kingdom, OX1 3QD; email:
nanqing.dong@cs.ox.ac.uk; W. Li, Centre for Distributed and High Performance Computing, School of Computer Science,
University of Sydney, Sydney, New SouthWales, Australia; email: weiwilson.li@sydney.edu.au; J. Cao (corresponding au-
thor), Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, P. R. China,
100084; email: jcao@tsinghua.edu.cn.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2023 Association for Computing Machinery.
0360-0300/2023/01-ART184 $15.00
https://doi.org/10.1145/3555802
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:2
H. Hua et al.
ACM Reference format:
Haochen Hua, Yutong Li, Tonghe Wang, Nanqing Dong, Wei Li, and Junwei Cao. 2023. Edge Computing with
Artificial Intelligence: A Machine Learning Perspective. ACM Comput. Surv. 55, 9, Article 184 (January 2023),
35 pages.
https://doi.org/10.1145/3555802
1
INTRODUCTION
Cloud computing has been widely used since its inception and has greatly changed people’s
lifestyle. Many large companies, including Google, Amazon, and Microsoft, have launched their
own cloud computing services (Google Cloud, Amazon Web Services, Microsoft Azure, respec-
tively). Equipped with a large number of remotely located servers, cloud computing can intelli-
gently provide users with computing, storage, and network services in real time according to user
needs in terms of resource type, quantity, and so on [1]. In this case, users can easily obtain these
cloud services with a small fee or totally for free [2].
1.1
Edge Computing
The development of Internet of things (IoT) has driven the production and application of a large
number of hardware devices/sensors worldwide. These hardware devices/sensors have the ability
to sense the surrounding physical environment and transform the environmental information into
data. After these massive data are transmitted to the cloud for computing or storage, data con-
sumers can access cloud data according to their individual needs and then extract the information
they need [3].
However, with the continuous development and widespread application of IoT, cloud com-
puting has begun to expose more and more problems. For instance, if the data generated by
global terminal devices are computed and stored in a centralized cloud, then it will cause a se-
ries of problems, including low throughput, high latency, bandwidth bottlenecks, data privacy,
centralized vulnerabilities, and additional costs (such as transmission cost, energy cost, storage
cost, calculation cost). In fact, many application scenarios in IoT, especially Internet of vehicles
(IoV), have requirements of high speed and low latency for data processing, analyzing, and result
returning [4].
To address these challenges of cloud computing mentioned above, a new computing paradigm,
called edge computing (EC), has attracted widespread attention. Simply put, the core idea of the
EC model is to offload the data processing, storage, and computing operations that were originally
required by the cloud to the edge of the network near terminal devices. This helps to reduce data
transmission time and device response times, reduce the pressure on network bandwidth, reduce
the cost of data transmission, and also achieve decentralization [5].
1.2
Artificial Intelligence
Artificial intelligence (AI) is a kind of technology that endows the machine with certain intelli-
gence so that the machine has the same ability to solve tasks as human beings [6]. While heuristic-
based algorithms and data mining (DM) [7] have both played an important role in AI solutions
to IoT in the past decades, we mainly focus on machine learning (ML), a recently popular area in
AI. It is worth mentioning that, though DM and ML share similarities in utilizing massive data, ML
focuses on mimicking the human learning process, but DM is designed to extract the rules from
data [8, 9]. In contrast to DM, ML is a higher-level intelligence and represents the future direction
of AI.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:3
The widespread application of AI, especially ML, has clearly become an inevitable trend in the
“big data era” brought by IoT. It is worth noting that this article focuses on the new generation AI
algorithm, e.g., deep learning (DL), and so on. Note that some of these applications have high
requirements for latency and network stability, but these requirements are often not guaranteed
by cloud computing. In contrast, the new EC model can meet these requirements by deploying
AI at the edge and delegating some computing and storage resources to edge devices close to
the terminal. Although EC brings benefits such as reduced latency, improved data privacy, and
enhanced security, the limited computing and storage capacity of edge devices has brought new
problems. Using AI to optimize EC and solve the problems faced by EC has become a new trend
in related research [10].
1.3
Combination of Edge Computing and Artificial Intelligence
The motivations of combining AI and EC in recent works can be roughly divided into two aspects,
which fully illustrate the mutual benefit between AI and EC:
(1) The development of EC still faces many challenges, e.g., task scheduling, resource allocation,
delay optimization, energy consumption optimization, and privacy and security. In response,
many researchers have adopted AI-based solutions to promote the development of EC.
(2) In spite of the rapid development of AI, its application relies on strong computing power.
Traditional cloud computing can provide abundant computing and storage resources, but
cloud-based AI reasoning and training may lead to significant delay as well as data privacy
and security issues. By executing AI tasks in edge nodes closer to the user side, EC can greatly
alleviate the aforementioned issues with improved stability, reliability, and user experience.
At present, researchers have made many great achievements in the above research problems.
This article summarizes these results, hoping that readers can quickly get updated with the latest
research status and relevant results.
1.4
Review of Existing Surveys
EC and AI are very popular research fields, and some related reviews have been published. In
Reference [11], authors focus on the motivation and research work of deploying AI algorithm on
the edge of the network. The latest development of ML in mobile EC is reviewed in Reference
[12], which includes the development of 5G network in automatic adaptive resource allocation,
mobility modeling, security, and energy efficiency. Survey work [13] reviews the application of
DL in EC, and it focuses on how to use DL to promote the development of edge applications, e.g.,
intelligent multimedia, intelligent transportation, intelligent city, and intelligent industry. Various
methods of fast implementation of DL reasoning in the combination of end devices, edge servers
and cloud, and the methods of training DL models in multiple edge devices are also discussed
in Reference [14]. To achieve the best performance of DL training and reasoning, Reference [15]
comprehensively discusses how to design EC architecture with communication, computing power,
and energy consumption constraints. From the perspective of algorithms and systems, [16] csys-
tematically summarizes the latest approaches to overcome the communication challenges caused
by AI reasoning and training at the edge of the network.
Nonetheless, the mutually beneficial relationship between EC and AI (especially traditional ML,
DL, reinforcement learning (RL), and deep reinforcement learning (DRL)) are seldom dis-
cussed in previous surveys. From this point of view, this article reviews existing works on EC
performance optimization and different application scenarios of AI. In addition to the DL methods
discussed in References [13–15], other ML algorithms, especially RL and DRL, are also discussed
in this article.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:4
H. Hua et al.
Fig. 1. Structure of the survey.
1.5
Our Contributions
Our main contributions in this article are as follows:
(1) We first outline the basic definition and architecture of EC and discuss the necessity of EC
in the presence of cloud computing. We also describe the problems studied by EC.
(2) We discuss the motivations for combining AI and EC from two perspectives:
• AI algorithms can be utilized to optimize EC;
• EC enables AI to be deployed on the edge to bring faster response speeds and network
stability for AI applications in different fields.
We summarize three ideas of deploying AI training and reasoning tasks in the EC architec-
ture based on existing studies and analyze their advantages and disadvantages.
(3) We mainly introduce popular ML algorithms in the field of AI and analyzes their respective
advantages. We summarize the latest research on solving the problems of EC and optimizing
the performance of EC by using AI algorithms. We also review the latest research on applying
AI to other fields under the EC architecture.
Roadmap. The remainder of this article is organized as follows: Section 2 introduces the defini-
tion of EC, discusses why we need EC, and enumerates the challenges faced by EC and correspond-
ing traditional (non-AI) solutions. In Section 3, we combine EC and AI. We first discuss the trends
and reasons for the combination of the two, then introduce the corresponding AI algorithms, and
finally conduct a comprehensive review of the research on using AI algorithms to optimize EC. In
Section 4, we summarize recent works on applying AI to other fields under EC. We summarize this
article in Section 5. The diagram in Figure 1 shows a clear picture of the structure of this article.
2
INTRODUCTION OF EDGE COMPUTING
Cloud computing has been a very popular or even a household concept for the past decade. Cloud
computing brings many conveniences. For example, small- and medium-sized enterprises only
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:5
need to purchase cloud server resources at a relatively low cost, without the need of purchasing
their own hardware and equipment at high prices. This greatly reduces the cost of business oper-
ations and the threshold for companies to engage in technology research and development.
The centralized computing, storage, and network resources of cloud computing has exposed a
series of problems with the development of the times. In this context, EC, a new computing para-
digm, has begun to attract the attention of all areas. In this section, we will give a brief overview of
EC. We will first discuss why EC is needed, and then introduce what EC is. Finally, we will discuss
the problems of EC and corresponding traditional solutions, and point out the shortcomings of
these traditional solutions.
2.1
Why We Need Edge Computing
We will explain the necessity of EC from the following three aspects: the “big data era” caused by
IoT, more stringent requirements of high network stability and response speed, and the consider-
ation of privacy and security.
2.1.1
The Big Data Era Caused by Internet of Things. The concept of IoT was proposed in 1999
for supply chain management, but now IoT covers a much wider area [17]. With the integration
of IoT into traditional industries, many new application areas have been spawned, such as smart
home, smart grid, smart traffic, and intelligent manufacturing. The idea of IoT is that things con-
nected to the Internet form a huge network, achieving the interconnection of these things at any
time and place. With the continuous development of IoT, the number of various sensors, smart-
phones, healthcare applications and online social platforms is soaring, and the resulting global
data will increase to 175 zeta bytes (ZB) by 2025 according to the prediction of International
Data Corporation (IDC) [18]. This huge data volume has facilitated the world of big data [19].
In the era of big data, the most direct and simple method for handling those data is to transfer
the data to the cloud for processing. The annual global cloud IP traffic of 2016 was 6.0 ZB, and it is
expected to reach 19.5 ZB in 2021, reported by Cisco in 2018 [20] . However, the computing power
of the cloud is increasing linearly [21], which is much slower than the current rate of data growth.
With the rapid growth of data, cloud computing will no longer be fully trusted.
2.1.2
More Stringent Requirements of Network Stability and Response Speed. There are some
IoT application scenarios that require extremely fast response speeds. For example, in the scenario
of intelligent driving, sensor devices such as cameras are installed in autonomous vehicles. These
sensor devices can continuously obtain data from the surrounding environment during the au-
tonomous driving mode. In the cloud computing model, these data will be uploaded to the cloud
for computing, and the results will be returned back to the vehicle’s control chip. Considering the
complicated driving environment of a vehicle, this method is actually very time-consuming, and
it may even cause the smart vehicle to fail to make the right decision in a timely manner, resulting
in serious consequences [3].
In the fields of augmented reality (AR) and virtual reality (VR), mobile AR/VR applications
need to continuously transmit high-resolution videos, so they have high requirements for data
computing capabilities, network stability, and response speed [22]. At the current rate of data
growth, the cloud’s computing power becomes less and less proficient in meeting these require-
ments. However, uploading all the data to the cloud will cause serious network congestion. Due to
the limited network bandwidth, the data generated by a large number of IoT devices will impose a
lot of pressure on the network bandwidth, causing cloud computing to no longer meet the require-
ments of latency and response speed in these scenarios. In addition, these data may have a large
proportion of noise and errors. Some survey shows that only one third of the data obtained by
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:6
H. Hua et al.
most sensors are correct [23]. Putting these worthless data into the cloud will cause a huge waste
of cloud server resources and a waste of network bandwidth.
2.1.3
Privacy and Security. Cloud computing has outsourcing features. Users need to host local
data to the cloud when using cloud computing. This leads to a series of data security and privacy
issues [21]. The data loss during long-distance transmission between devices and the cloud can
damage the integrity and accuracy of the data. In addition, highly centralized computing and stor-
age can also become serious problems. When one device in a centralized system goes wrong due
to benign errors or malicious attacks, other devices will be negatively affected. The data privacy
problem refers to the theft and utilization by other unauthorized persons, companies or organiza-
tions. Actually, data owners have lost control of their data uploaded to the cloud, so it is difficult
to guarantee data privacy [24].
2.2
The Definition of Edge Computing
The origin of EC can be traced back to 1999 when Akamai proposed content delivery networks
(CDN) for web page caching near the clients, aiming to improve the efficiency of web page load-
ing [25]. The concept of EC was borrowed from the cloud computing infrastructure to expand the
concept of CDN [26].
EC now has many different definitions. For example, Openstack defines EC as a model that
provides application developers and service providers with cloud services and IT environmental
services at the edge of the network [27]. In Reference [28], the authors believe that the “edge” in
EC refers to any computing and network resources between the data source and the cloud, such
as smart phones, gateways, micro data center, and cloudnet. It can also be understood that EC
offloads some cloud resources and tasks to the edge near users and data sources.
It should be noted that EC cannot replace the roles and advantages of cloud computing due to
the indispensable computing power and storage capacity of the cloud. The emergence of EC is
to make up for the limitations of cloud computing, and the relationship between EC and cloud
computing should be complementary. Therefore, how to coordinate the relationship between the
cloud and the edge so that the two can cooperate more efficiently and securely is a problem that
needs to be studied.
EC’s general architecture is three-layered, as shown in Figure 2, which are end, edge, and
cloud [29].
• End. This layer has two main functions. The first is to perceive the world, which is to ob-
serve, obtain and digitize the information of the physical world. This function is completed
by various types of sensors, such as speed sensors on smart cars, or cameras in smart cities.
The second is to receive information or data from the edge or cloud and perform the cor-
responding tasks. Data obtained from the end is processed by the edge and the cloud, and
then the results will be fed back to the end according to user needs, such as control signals
in smart driving or video traffic accepted by smartphones. Devices in this layer may have
some but very limited computing and storage capabilities.
• Edge. The edge layer is between the cloud and the end. This layer contains certain computing,
storage, and network resources, so some tasks that were originally performed in the cloud
can be delegated to this layer for execution. Since this layer is closer to end devices, EC has
the advantages of low latency. Generally, the edge layer is composed of gateways, control
units, storage units, and computing units.
• Cloud. This layer actually refers to cloud servers that has been widely used in practice. In
addition to its powerful computing and storage capabilities, the cloud also has the ability to
macro-control the entire EC architecture.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:7
Fig. 2. Architecture of EC. Gray arrows indicate the data transmission between the end, the edge, and the
cloud. Blue and gray boxes indicate that the task is scheduled to the edge and the cloud, respectively.
EC has advantages in offloading some resources and tasks on the cloud to the edge. The edge
layer is closer to end users and data source, so the transmission distance is greatly shortened, and
the corresponding transmission time is greatly reduced. This effectively improves the response
speed of user requests. At the same time, the shortened transmission distance also reduces the
cost and data security issues caused by the long-distance transmission. From the perspective of
the cloud, large-scale raw data will be processed on the edge to filter out a large number of useless
and erroneous data first, and then the edge uploads important data or information to the cloud.
This greatly reduces the bandwidth pressure, the transmission cost, and the possibility of user
privacy leakage.
2.3
Problems Studied in Edge Computing
Next, we will describe three problems studied in the field of EC in detail: computing offloading,
resource allocation, and privacy and security. We will also explain the shortcomings of traditional
solutions to these problems.
2.3.1
Computing Offloading. Computation offloading was originally proposed in cloud com-
puting. The definition is that the terminal devices with limited computing power delegates part
or all of the computing tasks to the cloud for execution. Similarly, computing offloading in EC
refers to the problem that terminal devices with limited computing power delegate part or all of
its computing tasks to the edge [30]. The main considerations are whether terminal devices will
offload, how much they will offload and to which nodes they will offload. Computing offloading
solves the problems of insufficient resources and high energy consumption in terminal devices.
Traditional methods of computing offloading applied to cloud computing are based on many
assumptions, including that the default server has sufficient computing power and does not care
about its energy consumption or network condition. However, traditional methods based on
the above assumptions are not suitable for solving the computing offloading in EC where edge
devices and servers have limited computing capabilities [31]. Reasonable computing offloading
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:8
H. Hua et al.
strategies are able to reduce energy consumption and latency. Therefore, computing offloading is
an important research topic for optimizing EC.
2.3.2
Resource Allocation. Compared to traditional cloud computing, the most prominent ad-
vantage of EC is that it does not need to upload all the data to the cloud for computing and storage
tasks, which largely frees up network bandwidth and other resources occupied by cloud comput-
ing. In the meanwhile, since tasks are distributed on each edge node with limited resources, an
intelligent and efficient solution for resource management is crucial for EC.
2.3.3
Privacy and Security. EC also faces new challenges regarding data security and pri-
vacy [32]. Some of these challenges come from the inherent problems of cloud computing, and
others come from the distributed and heterogeneity nature of EC itself [33]. Traditional solutions
for data security and privacy issues of cloud computing are not applicable to the non-centralized
computing model of EC. Therefore, further improving data security and further protecting data
privacy is a problem worthy of researchers’ attention.
2.4
Summary
Aiming at the problems described above, many studies based on traditional methods have made
good progress. In solving the problem of resource allocation and computing offloading in EC,
some researchers adopt Lyapunov optimization algorithm [34] to find the optimal decision [35, 36].
Some studies also regard resource allocation and computing offloading as optimization problems
such as linear programming [37] and mixed integer non-linear programming [38–40]. Other tra-
ditional methods include alternating direction method of multipliers (ADMM) [41], Stack-
elberg game [42], and so on. In terms of security, Jing et al. [43] adopt a linear programming
method to reduce data loss. Kang et al. [44] use blockchain technology to protect the security of
data storage and sharing. In terms of privacy protection, traditional methods include differential
privacy [45], wavelet transform [46], and so on.
Although traditional methods above have achieved good results in optimizing EC, they still have
some shortcomings. First, the underlying model needs to be known, which is not an easy task due
to the complexity and dynamics of EC itself. Second, they are easy to converge to local optima,
and their efficiency is usually very low. Moreover, they lack the ability to perform deep and high-
dimensional data mining, automatically extract important features to make fast optimal decisions,
and make prediction. Note that these are all advantages of AI algorithms, and we will describe
how they optimize EC in the next section.
In summary, this section mainly focuses on the concept and motivation of EC. At the same time,
the problems and challenges faced by the development of EC are also described. It is worth noting
that traditional methods have achieved good results in solving these problems, but they still suffer
some shortcomings. In the future, AI algorithms might become more adaptable to new situations,
able to change inputs, outputs, and constraints more easily, and do not need mathematical models
when data are sufficient [12].
3
WHEN EDGE COMPUTING MEETS ARTIFICIAL INTELLIGENCE
In this section, we will first analyze the respective development of AI and EC and the motiva-
tion for the combination of the two, and then we will give an overview of related AI algorithms.
Finally, we will summarize AI-based algorithms for topics such as computing offloading optimiza-
tion, non-computing offloading methods to reduce energy consumption, EC security, data privacy,
and resource allocation optimization.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:9
Fig. 3. Mutually beneficial relationship between AI and EC. The right-to-left arrow indicates that the opti-
mization and development of EC require the assistance of AI algorithms (e.g., computation offloading opti-
mization). The left-to-right arrow indicates that EC needs to be deployed closer to terminal devices to meet
the requirements of some latency-sensitive AI applications (e.g., smart city).
3.1
Motivations of Combining Edge Computing and Artificial Intelligence
Artificial intelligence is a very critical technology in the era of big data. It brings intelligence and
reasoning capabilities to a large number of terminal devices in IoT. At present, many studies and
applications have combined the two hot areas of AI and EC, and their motivations can be roughly
divided into two aspects:
• The optimization and deployment of EC requires the assistance of AI algorithms;
• EC provides necessary computing functions for AI applications that need to be deployed
close to terminal devices for low latency and high network stability [47].
It can be seen that the development of AI and EC is mutually beneficial (see Figure 3 for a straight-
forward description), and the combined development of the two has attracted the attention of
many researchers.
3.1.1
Edge Computing Benefits Artificial Intelligence. In detail, EC brings benefits to the appli-
cation of AI. With the advent of the big data era, the widespread application of AI in people’s
daily lives has become an irresistible trend. Of course, this trend still faces challenges. For exam-
ple, AI’s reasoning and training requires strong computing power and sufficient energy support,
but terminal devices often do not meet these two requirements. In recent years, cloud computing
has fulfilled these needs by offloading AI model training and reasoning tasks that terminal devices
cannot perform to the cloud server. However, relying solely on cloud computing will cause prob-
lems like insufficient bandwidth and high latency when a large number of AI models are used by a
large number of terminal devices [48]. With the advent of EC, AI can be deployed near terminal de-
vices and users on the edge and terminal with certain computing resources and storage resources,
therefore meeting the needs for low latency and high network stability [11].
In return, EC also brings three ideas to the application of AI in other fields (visually represented
by Figure 4).
(a) Massive data are preprocessed and then uploaded to the cloud for AI training and reason-
ing [49]. Although this idea has greatly reduced the pressure of massive data on bandwidth
and transmission costs, it does not meet the requirements of many applications in terms of
latency (e.g., IoV and AR/VR applications).
(b) To reduce the latency of applications, AI reasoning tasks are performed on the edge or the
end, while model training tasks are still performed in the cloud [50].
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:10
H. Hua et al.
Fig. 4. Hierarchical modes for deploying AI in EC. The figure is divided into three parts by two vertical dotted
lines, which correspond to three hierarchical modes. Neural networks and cylinders represent training tasks
and reasoning tasks, respectively. (a) The leftmost part describes that both training and reasoning tasks are
deployed in the cloud. (b) The blue part in the middle describes that the training tasks are performed in the
cloud, but the reasoning tasks are performed in both cloud and edge. The red part in the middle describes
that the training tasks are in the cloud, while the reasoning tasks are performed completely on the edge.
(c) The blue part in the rightmost part indicates that both training and reasoning tasks are deployed in both
cloud and edge. The red part describes the training and reasoning tasks performed only on the edge.
(c) Delegate part or all of AI training and reasoning tasks to the edge [51]. With distributed
characteristics, this idea helps enhance the location awareness of AI models while reducing
the latency and bandwidth pressure [33]. Note that the requirements for energy consumption
and computing power of edge devices will also increase as the number of tasks devolved to
the edge side increases.
As can be seen from the above, these three ideas have their own advantages and disadvantages, so
existing studies are more inclined to choose the best idea according to the specific situation.
3.1.2
Artificial Intelligence Benefits Edge Computing. AI is playing an important role in the opti-
mization of EC [52]. Since EC is distributed and the workload of each edge device changes dynam-
ically with time and location, this uncertainty and unpredictability have brought huge obstacles
to the application of EC. In this sense, EC still needs to be optimized and improved in many as-
pects, such as optimizing computing offloading, optimizing resource allocation, reducing latency
and energy consumption, and improving user experience.
Many optimization problems in EC are very complex non-convex problems. As the number of
devices and users increases, the scale of these problems will also rapidly increase [53]. Compared
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:11
to traditional methods, ML is more suitable for solving optimization problems of EC and has better
results [54]. In addition, AI algorithms are also good at effectively mining hidden information and
laws from data in complex and noisy EC environments, which has plagued traditional optimization
methods for a long time.
3.2
Introduction of Artificial Intelligence Algorithms in Edge Computing
We are going to introduce these AI algorithms used in EC, namely, traditional ML algorithms, DL,
RL and DRL algorithms. We will also provide some examples of application accordingly. In this
article, we mainly focus on the field of ML in AI algorithm. Other algorithms such as evolutionary
algorithm are not the focus of this article, but are briefly introduced in this section.
3.2.1
Traditional Machine Learning. The traditional ML algorithms in this work particularly
refer to those ML algorithms other than DL and RL. Given the availability of label information,
the traditional ML algorithms can be divided into supervised learning, semi-supervised learn-
ing, and unsupervised learning. Among them, supervised learning requires labeled data to train
the model, while unsupervised learning can autonomously discover the principles implicit in the
data. As a hybrid of supervised learning and unsupervised learning, semi-supervised learning has
access to both labeled data and unlabeled data. For example, the common supervised learning
methods include support vector machines (SVM), boosting, and random forests; the common
semi-supervised learning methods include label propagation and graphical models; the common
unsupervised learning methods include clustering algorithms such as K-means and dimension re-
duction algorithms such as principal component analysis (PCA).
There are some obvious shortcomings of traditional ML algorithms. For instance, they are sen-
sitive to data sets, the data become less effective when the data set is large enough, and they need
complicated artificial feature engineering. In spite of these shortcomings, traditional ML has small
energy consumption, small computing power cost, and is easy to deploy compared to DL and
RL. Due to the distributed nature of EC, the appropriate AI algorithm can be reasonably selected
according to the resource situation and task requirements of each edge and terminal device, so
traditional ML can also rely on these advantages to find its place in EC [55].
3.2.2
Deep Learning. DL resembles the functions of human brains. It has the ability to au-
tonomously learn high-level features from raw data, thereby efficiently performing classification
and prediction tasks [56, 57]. DL is usually deployed in a multi-layer structure. These layers can
be fully connected layers, convolutional layers, pooling layers, normalization layers, or activation
layers. A DL algorithm can be formed by the free combination of these layers. The more layers
the algorithm includes, the “deeper” it is. The input of a neuron in each layer is the weighted sum
of the outputs of the neurons in the previous layer. After the input is activated by an activation
function, the obtained number is used as the output of the neuron [58]. Compared to traditional
ML algorithms, DL has a more powerful ability to extract high-level features from massive data
due to its multilayer structure [59].
The common DL models include: deep neural networks (DNN), convolutional neural net-
works (CNN), recurrent neural networks (RNN), and so on.
• DNN, also known as multiple linear perceptrons (MLP), is a neural network with multi-
ple hidden layers. The neural network layer in DNN can be divided into three types: input
layer, hidden layer and output layer. By adding hidden layers, DNN model can obtain more
powerful learning ability.
• CNN is composed of a series of different convolution layers. High-level features hidden in
the input data can be extracted through the convolution operation in these convolution
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:12
H. Hua et al.
layers [60]. CNN has powerful representation abilities and picture recognition capabilities.
Based on this, some studies have adopted CNN algorithms in the fields of fault detection
and video surveillance in EC. For example, Zhang et al. [61] detects microseismic events by
deploying CNN models on edge devices.
• RNN is a DNN algorithm that is good at modeling and processing sequence data. However, a
major disadvantage of RNN is that it is easy to forget. That is, the impact of the input of the
starting moment on the later moments will become smaller and smaller with time. Therefore,
an improved version of RNN named long short-term memory (LSTM) [62] is proposed.
At present, some studies [63–65] have adopted the LSTM algorithm to solve the issues faced
by EC.
When a large number of labeled data are available, compared with traditional ML algorithms,
DL performs better in natural language processing, computer vision and many other fields [57].
The characteristics of EC make the data collected from the physical environment can be processed
locally, which meets the requirements of DL. Therefore, some EC studies also focus on using DL
in EC anomaly detection [66], task scheduling and resource allocation in EC [67], and privacy
protection [68].
3.2.3
Reinforcement Learning and Deep Reinforcement Learning. Unlike supervised learning
and unsupervised learning that rely on static data, RL is a learning algorithm that trains mod-
els through dynamic interaction with the environment. The core idea is that agents receive the
state of environment and make actions to maximize the reward according to historical experience.
Because reinforcement learning is good at solving decision-making problems, some studies [69, 70]
have adopted RL algorithm in the decision-making of EC resource management, allocation, and
scheduling.
Typical algorithms in RL are model-free and value-based Q-learning algorithm [71]. Each iter-
ation of Q-learning algorithm will calculate an expected cumulative reward, called the Q-value,
according to current state and given action. However, as the environment becomes more complex,
the state space and action space will expand exponentially, thus reducing the convergence speed
and taking up a lot of memory [72].
To solve this problem, deep Q network (DQN) [73] is proposed, which utilizes a DNN to ap-
proximate the Q-values. Compared with the classical RL algorithms, DQN has three advantages
in dealing with EC with high complexity [74]. First, it is able to deal with high dimensional and
complex systems. Second, it can learn the regularity of system environment. Last but not least, it
is able to make optimal decisions based on current and past long-term reward. Therefore, some
studies [75, 76] use DQN algorithms to optimize the control decision-making problems in EC and
obtain good results.
However, DQN also has its shortcomings. Especially, when using nonlinear functions such as
neural network to approximate the Q-function, the learning result of DRL is unstable or even
divergent. To solve this problem, an experience replay mechanism using the prior experience is
integrated into DQN [77, 78].
3.2.4
Federated Learning. Federated learning (FL) is a distributed ML framework, which can
effectively help multiple organizations train models under the requirements of user privacy pro-
tection, data security, and government regulations [79]. In this framework, different local users do
not need to put all the raw data on the central server for training, but train the local model through
privacy related data, then all the local models are aggregated into a global model on the central
server [80].
As discussed above, the goal of EC is to deploy computing tasks at the edge of the network
near the client. However, the data of a single edge node may not meet the requirements of model
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:13
training. Therefore, the cooperation model training between different nodes under data privacy
protection is a research hotspot; see, e.g., Reference [81].
3.2.5
Evolutionary Algorithms. Evolutionary algorithms are a kind of optimization methods
inspired by biological evolution mechanism and biological behavior [82]. Evolutionary algorithms
include particle swarm optimization (PSO), genetic algorithm (GA), differential evolution
(DE), and so on.
Generally speaking, evolutionary algorithms are divided into the following steps. The first step
is to initialize variables. After that, the evolutionary algorithms continuously iterate three steps
named fitness evaluation and selection, population reproduction and variation, and population
updating [82]. Finally, the second step is iterated until the termination condition is satisfied.
At present, evolutionary algorithm has been applied in many problems of EC, such as resource
scheduling optimization [83], load balancing [84], and task scheduling [85]. In this article, we
mainly discuss ML, a recently popular AI subclass, so evolutionary algorithm is only briefly intro-
duced here.
3.3
Artificial Intelligence Solutions for Optimizing Edge Computing
Now, we are going to provide a comprehensive summary of studies (listed in Table 1) that uses AI
methods to optimize EC in different scenarios including computing offloading, reducing energy
consumption, increasing the security of EC, keeping data privacy, and resource allocation.
3.3.1
Computing Offloading Optimization. At present, more and more studies have begun to
make full use of AI to solve computing offloading [86]. We will summarize the AI-based computing
offloading schemes in existing research to reduce energy consumption, reduce latency, and reduce
both.
Reducing energy consumption. In terms of reducing energy consumption, a partial computing
offloading scheme based on DL decision-making is proposed by Ali et al. [31]. The authors estab-
lish a new type of decision-making process, which can intelligently select the optimal computing
offloading strategy, thus reducing the total energy consumed in the execution of computing tasks.
Compared with its previous work in Reference [87], this strategy additionally considers the energy
consumption of user equipment in the cost function, which reduces its energy consumption by 3%.
Reducing latency. Although EC itself has the advantage of low latency compared to cloud com-
puting, it still has room for optimization. Smart-Edge-CoCaCo [88] is proposed to minimize the
latency by jointly optimizing the wireless communication model, the collaborative filter caching
model, and the computing offloading model. In addition, since the computing power of edge de-
vices is limited, offloading all tasks to edge devices may exceed the capacity of the edge device.
With this in mind, Xu et al. [89] propose a DL-based heuristic offloading method. This method uses
origin-destination electronic communications network distance estimation and heuristic searching
to find the optimal computing offloading strategy.
Reducing both energy consumption and latency. All the methods mentioned in previous para-
graphs either only minimize energy consumption, or only minimize latency. There are also studies
that consider the minimization of both through RL. Kiran et al. [54] propose a scheme that uses
Q-learning to make optimal control decisions to reduce the delay in EC and adds constraints to
the cost function to reduce energy consumption in EC. Although this scheme has a good effect on
reducing energy consumption and delay, it does not take into account the curse-of-dimensionality
problem of EC.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:14
H. Hua et al.
Table 1. Summary of Research on AI-optimized EC
Problem
Goal
Citation
AI
Contribution
Reduce energy
consumption
[98]
Distributed DL-based
offloading algorithm
Add the cost of changing local
execution tasks in the cost
function
Reduce
latency
[88]
Smart-Edge-CoCaCo
algorithm based on
DL
Joint optimization of wireless
communication, collaborative
filter caching and computing
offloading
[89]
A heuristic offloading
method
Origin-destination electronic
communication network
distance estimation and heuristic
searching to find optimal
strategy for shorting the
transmission delay of DL tasks
[54]
Cooperative
Q-learning
Improve the search speed of
traditional Q-learning
[90]
TD learning with
postdecision state and
semi-gradient descent
method
Approximate dynamic
programming to cope with
curse-of-dimensionality
[91]
Online RL
Special structure of the state
transitions to overcome
curse-of-dimensionality;
additionally consider the EC
scenario with energy harvesting
Computing
offloading
optimization
Reduce both
energy
consumption
and latency
[93]
DRL-based offloading
scheme
No prior knowledge of
transmission delay and energy
consumption model; compress
the state space dimension
through DRL to further improve
the learning rate; additionally
consider the EC scenario with
energy harvesting
[94]
DRL-based computing
offloading approach
Markov decision process to
represent computing offloading;
learn network dynamics through
DRL
[95]
Q-function
decomposition
technique combined
with double DQN
Double deep Q-network to
obtain optimal computing
offloading without prior
knowledge; a new function
approximator-based DNN model
to deal with high dimensional
state spaces
[10]
RL based on neural
network architectures
An infinite-horizon
average-reward continuous-time
Markov decision process to
represent the optimal problem; a
new value function
approximator to deal with high
dimensional state spaces
(Continued)
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:15
Table 1. Continued
Problem
Goal
Citation
AI
Contribution
Optimize the
hardware
structure of
edge devices
[102]
Binary-weight CNN
A static random access memory
for binary-weight CNN to
reduce memory data
throughput; parallel execution
of CNN
[104]
DNNs
FPGA-based binarized DNN
accelerator for weed species
classification
Other ways to
reduce energy
consumption
Control
device
operating
status
[105]
DRL-based joint
mode selection and
resource
management
approach
Reduce the medium- and
long-term energy consumption
by controlling the
communication mode of the
user equipment and the
light-on state of the processors
Combine
with energy
Internet
[106]
Model-based DRL
Solve the energy supply
problem of the multi-access
edge server
[70]
RL
A fog-computing node powered
by a renewable energy
generator
[113]
Minimax-Q learning
Gradually learn the optimal
strategy by increasing the
spectral efficiency throughput
[114]
Online learning
Reduced bandwidth usage by
choosing the most reliable
server
[115]
Multiple AI
algorithms
Algorithm selection mechanism
capable of intelligently
selecting optimal AI algorithm
Security of
edge
computing
[117]
Hypergraph
clustering
Improve the recognition rate by
modeling the relationship
between edge nodes and DDoS
through hypergraph clustering
[112]
Extreme Learning
Machine
Show faster convergence speed
and stronger generalization
performance of the Extreme
Learning Machine classifier
than most classical algorithms
[56]
Distributed DL
Reduce the burden of model
training and improve the
accuracy of the model
[120]
DL, restricted
Boltzmann machines
Give active learning capabilities
to improve unknown attack
recognition
(Continued)
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:16
H. Hua et al.
Table 1. Continued
Problem
Goal
Citation
AI
Contribution
[122]
Deep PDS-Learning
Speed up the training with
additional information (e.g., the
energy utilization of edge
devices)
Privacy
protection
[124]
Generative
adversarial networks
An objective perturbation
algorithm and an output
perturbation algorithm that
satisfy differential privacy
[125]
A deep inference
framework called
EdgeSanitizer
Data can be used to the
maximum extent, while
ensuring privacy protection
[77]
Deep Q-learning
Derive trust values using
uncertain reasoning; avoid local
convergence by adjusting the
learning rate
Resource
allocation
optimization
[166]
Actor-critic RL
An additional DNN to represent
a parameterized stochastic
policy to further improve
performance and convergence
speed; a natural policy gradient
method to avoid local
convergence
[76]
DRL-based resource
allocation scheme
Additional SDN to improve QoS
[127]
Multi-task DRL
Transform the last layer of
DNN that estimates Q-function
to support higher dimensional
action spaces
The curse-of-dimensionality refers to the problem that the complexity of the problem solving
will increase at an exponential speed as the dimensionality increases [90, 91]. To solve the curse-
of-dimensionality problem, Xu et al. [91] propose an algorithm that uses the special structure of
state transitions of the considered EC system to overcome the curse-of-dimensionality problem. It
is worth noting that the authors use energy harvesting [92] to reduce the consumption of tradi-
tional energy by fully utilizing renewable energy, but the transmission delay model and the energy
consumption model are required to be known (this requirement can be eliminated by the method
proposed in Reference [93]).
Compared with RL algorithms, DRL algorithms have stronger abilities to deal with high-
dimensional state space. Therefore, Cheng et al. [94] propose a model-free DRL-based comput-
ing offloading method based on a space-air-ground integrated network to reduce EC latency and
energy consumption. This method uses Markov decision process to represent the computing of-
floading decision process, and uses DRL to learn network dynamics.
Yet the ability of DRL algorithms to cope with high-dimensional state space is not perfect in ev-
ery respect. Chen et al. [95] propose a new DNN model based on function approximator, and they
also adopt double deep Q-network so that the optimal offloading strategy can be discovered with-
out prior knowledge. Similarly, Lei et al. [10] propose a new type of value function approximator
to deal with high-dimensional state equations. The authors also use an infinite-horizon average-
reward continuous-time Markov decision process to represent the optimal problem. Finally, DRL
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:17
is applied to solve the optimal computing offloading decision to reduce the energy consumption
and latency of EC.
The DRL-based methods mentioned above use a centralized style for model learning. However,
there is a potential assumption in this style that edge devices in EC have sufficient computing
power. In fact, many edge devices do not yet have such powerful computing capabilities. As a
result, Ren et al. propose a distributed computing offloading strategy combining federated learning
and multiple DRLs [96]. It is proved by experiments that this method outperforms the centralized
learning method in reducing the transmission cost in EC. In addition, distributed learning also
has the advantage of fast convergence [97]. This is proved in Reference [98] by the method of
optimizing computing offloading through distributed ML.
3.3.2
Non-computation Offloading Methods to Reduce Energy Consumption. EC provides cer-
tain computing capabilities near the data source, so that many computing tasks do not need to
be delivered to the cloud for execution. While this model brings high response speed to people,
it will inevitably cause a surge in energy consumption on the edge side. Moreover, many applica-
tions in EC require AI algorithms to make real-time decisions (such as intelligent driving [99] and
intelligent monitoring systems [100]), but AI algorithms are computationally intensive to varying
degrees. This is a huge challenge for devices with limited power. From the perspective of overall
energy consumption, with the gradual popularization and widespread application of AI, how to
control global overall energy consumption or improve energy efficiency is also very important.
Apart from computation offloading, there are many other factors that affect the energy con-
sumption of edge devices. For example, different AI algorithms and different hardware structures
adopted by edge devices will also affect energy consumption [101]. We will introduce AI solutions
to reduce EC energy consumption in terms of optimizing hardware structure, controlling operating
status, and combining energy Internet.
Optimizing hardware structure. A static random access memory (SRAM) [102] is able to re-
duce memory data throughput, and it combines parallel CNNs to enable simultaneous access to
different memory blocks. Experiments show that this architecture significantly reduces energy
consumption compared to traditional digital accelerator using small bitwidths. Based on field-
programmable gate array (FPGA) [103], Lammie et al. [104] design a binarized DNN accelera-
tor for weed species classification, which reduces energy consumption by 7 times compared with
GPU-based accelerator under the same conditions. The authors believe that well-cultivated FPGA-
based accelerator for AI algorithms is an ideal choice for edge devices with limited resources but
need to perform learning and reasoning tasks.
Controlling operating status. Sun et al. propose a method based on DRL to reduce the medium
and long-term energy consumption of EC by controlling the communication modes of user devices
and the light-on state of processors [105]. This method uses Markov process to model the energy
consumption of cache states and cloud processors and DRL to make decisions. According to some
constraints (quality of service constraints, transmission power constraints, and the computing ca-
pability constraint in the cloud), the method uses an iterative algorithm to optimize the precoding
of user devices.
Combining Energy Internet. EC has distributed characteristics, and the workload of edge-side
devices will dynamically change with different geographical locations and times, which makes the
energy consumption of each edge node unpredictable and uneven. To deal with the huge energy
demand of EC and its heterogeneity, the combination of energy Internet (including smart grid
and microgrid) with EC can provide renewable energy for EC [70, 106]. Energy Internet is a dis-
tributed energy production model that achieves local energy self-sufficiency by making full use
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:18
H. Hua et al.
of renewable energy sources [107, 108]. This feature of energy Internet is very suitable for provid-
ing energy to EC, thereby reducing the consumption of non-renewable energy. Since renewable
energy is infinite, reducing non-renewable energy consumption is also equivalent to reducing en-
ergy consumption. However, due to the uncertainty of renewable energy production [109], some
studies [70, 106] also aim to balance the energy supply and demand of EC through DRL-based con-
trol strategies. With the deployment of EC devices into energy Internet, energy management will
also become more complex [110]. DRL combined with curriculum learning [111] has been used to
realize a bottom-up energy management scheme [110].
3.3.3
Security of Edge Computing. Delegating computing and storage tasks from the cloud to
the edge can reduce the security problems caused by network congestion and centralization to
some extent. However, the distributed environment of EC also brings new security problems, such
as distributed denial of service (DDoS) attacks and jamming attacks that cause illegal distri-
bution of distributed system resources [33, 112]. What was previously applicable to a centralized
environment (like cloud computing) is no longer applicable to solving these new security issues.
In this part, we will review the studies on improving the security of EC based on AI algorithms.
Traditional machine learning methods. Traditional ML can help with the identification and clas-
sification of different attacks. In response to jamming attacks that threaten EC security, Wang
et al. [113] propose a stochastic game framework that maximizes the spectral efficiency through-
put by minimax-Q learning, thereby gradually learning the optimal strategy. The disadvantage
of this method is that it needs extra bandwidth to avoid jamming attacks. This can be avoided
by selecting the most reliable server based on online learning to reduce the security risks caused
by jamming attacks [114]. To reduce the false alarm rate and data transmission delay of tradi-
tional intrusion detection systems, an algorithm selection mechanism can be deployed on the edge
side [115]. This enables intelligent selection of the optimal ML algorithm for edge devices to dis-
tinguish false alarms. The experimental results prove that the method based on AI algorithm can
improve the security of EC more effectively than the method based on non-AI algorithm.
Among various network attacks, DDoS is a relatively common attack method. Hypergraph clus-
tering [116] can be adopted to model the relationship between edge nodes and DDoS to improve
the recognition rate [117]. Kozik et al. uses a single-layer neural network to build the extreme
learning machine classifier [112]. In this method, the training task of the attack detection classifier
model is performed in the cloud with powerful computing resources. The trained classifier model
is then offloaded to the edge devices for attack detection. In addition, experiments have also proven
that the extreme learning machine classifier has faster convergence speed and stronger general-
ization performance than most traditional classification algorithms (such as SVM, or single-layer
perceptron).
DL methods. Although traditional ML algorithms can improve the accuracy and robustness
of network attack detection and recognition, they lack the ability of automatic feature extrac-
tion [118]. As a result, traditional AI algorithms are not sensitive to known but slightly changed
attacks. At the same time, due to the lack of prior knowledge of unknown vulnerabilities, they
can not effectively detect zero-day attacks [119]. Deep learning, however, has been successfully
applied in image processing, computer vision and many other fields in recent years because of
its structure that can automatically mine and learn the hidden features in massive data [63]. Re-
searchers begin to focus on DL, since the problem of cyber-security attack identification in EC is
similar to the tasks in these fields.
Abeshu et al. [56] propose a DL-based method for attack detection in EC. To reduce the bur-
den of model training and improve the accuracy of the model, this method uses a pretrained
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:19
stacked autoencoder to screen the real valuable features and then uses softmax to do classification.
This method shows great advantages in the aspects of availability, scalability and effectiveness
compared with traditional ML algorithms. However, the authors fail to take into account the im-
provement of the detection rate of new attacks. This can be solved by unsupervised learning. The
DL-based algorithm proposed in Reference [120] learns the characteristics of the attack through
the deep belief network and uses the softmax function to identify various attacks on the EC. The
difference is that this solution incorporates unsupervised learning restricted Boltzmann machines
into the proposed model. Since unsupervised learning restricted Boltzmann machines is a stochas-
tic artificial neural network with active learning characteristics, this model enables active learning
to improve the recognition rate of attacks that have never occurred before.
3.3.4
Data Privacy. To a certain extent, EC reduces the risk of privacy leakage caused by upload-
ing data to cloud servers that users cannot control. However, the problem of data privacy leakage
also exists on the edge side. On the one hand, the distributed nature of EC brings new challenges to
privacy protection. On the other hand, the application of AI on the edge side requires massive data
for model training and reasoning, which are inevitably mixed with a large amount of user privacy.
During the training process, some models may save part of the training set with private data, so
an attacker can illegally obtain users’ privacy by analyzing these models [121]. Consequently, it
is very important to ensure the data privacy and security of edge-side users without affecting the
performance of EC. This topic has attracted the attention of many researchers in recent years.
Post-decision state learning. A post-decision state (PDS) learning method is proposed in Refer-
ence [122], in which the state transition function is factored into known and unknown components.
This method first uses the Markov decision process to describe EC’s offloading problem and then
solves the problem by combining PDS-learning technique with the traditional deep Q-network
algorithm. This combination can well balance task scheduling and privacy protection. It is worth
noting that compared with the traditional deep Q-network, the new algorithm can speed up the
model training by learning some additional information (such as the energy utilization of edge
devices).
Federated learning. A privacy-preserving asynchronous FL mechanism (PAFLM) for EC is
proposed, which allows multiple edge nodes to realize more efficient FL without sharing private
data and affecting inference accuracy [81]. Because the local model training of each node depends
on the data inside the node to a large extent, it is easier to lead to local optimum. Through FL, the
local model can be optimized with the help of the model parameters of other nodes, which can
solve local optimum problem and improve the accuracy of model.
Differential privacy. To protect the user privacy in the training data set under EC, AI algorithms
are usually combined with differential privacy, a system where including or excluding any piece
of data will not change the results of related data analysis to a great extent [123]. In other words,
by applying differential privacy, observers cannot tell from its output if any particular piece of
information has been used [123]. Du et al. [124] propose two AI-based algorithms that satisfy
differential privacy: objective perturbation algorithm and output perturbation algorithm. The dif-
ference between the two is that objective perturbation adds Laplace noise to objective functions,
while output perturbation adds the noise to outputs. By injecting Laplace noise, ML algorithms
show better efficiency and accuracy in prediction, and they are more effective in protecting the
privacy of training data used in EC. Similarly, a deep reasoning framework based on differential
privacy, called EdgeSanitizer, is proposed in Reference [125]. The framework uses as much useful
information as possible with a DL-based data minimization method. Then it removes as much sen-
sitive private information as possible from data sets by adding random noise to the original data
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:20
H. Hua et al.
through a local differential privacy method [126]. This approach ensures that the data is used to
the maximum extent while protecting the privacy in EC.
3.3.5
Resource Allocation Optimization. DRL has been proven to be capable of handling dy-
namic decision problems with high-dimensional states and action spaces [127]. At present, some
studies have focused on DRL to solve the resource allocation problem in EC.
The method in Reference [77] captures the fact that the EC environment state is constantly
changing. The information about wireless channel conditions, each node’s trust value, the con-
tents in the cache, and the vacant computational capacity is passed to the DNN to estimate the
Q-function. The network operator’s revenue is regarded as the reward, and the agent trains the
DNN through the obtained reward. It avoids local convergence by adjusting the learning rate. Al-
though this method has a good effect, there is still room for improvement in convergence and
performance.
Although the study above proves that DQN has a good performance in optimizing dynamic
decision problems with high-dimensional state space, there are still some limitations when solving
problems based on high-dimensional action space. Therefore, Chen et al. [127] propose a new DRL-
based resource allocation decision framework that makes the following two contributions:
• The framework uses DNN to train with a self-supervised training process to predict the
resource allocation action, with the training data generated by the Monte Carlo tree search
(MCTS) [128] algorithm;
• The authors modify the last layer of the traditional DNN used to estimate Q-function, so
that it can support higher-dimensional action space.
The experiment proves that compared with the method of directly using DQN, this method has
reduced the delay by 51.71%.
3.4
Summary
In this section, we first explain the mutual benefit between AI and EC. Then, we introduce AI
algorithms (especially traditional ML, DL, RL, and DRL) in detail. Finally, from the perspectives of
task scheduling, resource allocation, privacy protection and security, the research results of using
AI algorithms to optimize the performance of EC are reviewed. In the future, considering that the
EC is faced with large-scale computing tasks, it would be very important to combine the multi-
dimensional perspectives of network, computing, power allocation, and task scheduling for real-
time joint optimization. To deal with these complex optimization problems, it is a potential research
direction that uses the model-free method of AI algorithms to learn efficient strategies [11].
4
APPLICATION OF ARTIFICIAL INTELLIGENCE UNDER EDGE COMPUTING
In recent years, AI has made many achievements in various fields. Among them, smart city, smart
manufacturing, and the IoV usually have more critical requirements for network delay and sta-
bility than other scenarios such as AR/VR, online gaming, or content distribution. Unfortunately,
traditional cloud computing often fails to guarantee these requirements. Some researchers have
started using EC to provide computing and storage resources on edge. To emphasize the advan-
tages of EC in AI applications, this section will focus on summarizing the research results of AI
applications in smart city, smart manufacturing, and the IoV under the EC framework.
This section summarize the existing research from the perspective of EC hierarchical architec-
ture. The categorization of EC architecture, together with the corresponding target field and AI
(ML) algorithm, are detailed in Table 2.
In this article, different EC architectures used in AI applications are summarized into three
categories with detailed explanation and analysis. The three modes are: (a) the edge side is only
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:21
Table 2. Summary of AI Algorithms and Architectures
Field
Goal
DL
DRL
RL
Traditional
ML
EC Architecture
Citation
√
(c)
[131]
Security of city
√
(c)
[100]
√
(c)
[132]
√
(b)
[133]
Smart city
Urban healthcare
√
(b)
[135]
√
(c)
[51]
√
(a)
[49]
Urban energy
management
√
(a)
[138]
√
(b) & (c)
[140]
√
√
(a)
[143]
Smart
manufacturing
√
(b)
[50]
√
(a)
[65]
√
(b)
[145]
√
(b)
[61]
√
(c)
[149]
Internet of Vehicles
√
(c)
[152]
√
(c)
[53]
√
√
(b)
[153]
√
(b)
[157]
The EC architectures are defined in Section 4, which can be divided into the following three categories. (a) The edge
side is only responsible for data cleaning, and the cloud is responsible for training and reasoning. (b) The cloud is
responsible for training, while the edge side is responsible for inference. (c) Delegate part or all of AI training and
reasoning tasks to the edge (see Section 3.3.1 and Figure 4 for details).
responsible for data cleaning, and the cloud is responsible for training and reasoning; (b) the cloud
is responsible for training, while the edge side is responsible for inference; (c) part or all of AI
training and reasoning tasks are delegated to the edge (see Section 3.3.1 and Figure 4 for details).
This section will accordingly summarize the research works (listed in Table 2) of AI application
in many fields under above different EC hierarchical modes to emphasize the advantages of EC
in AI application. Table 2 classifies and summarizes them from the perspective of architecture, AI
algorithm, and target field.
4.1
Smart City
With the explosive growth of urban population and the trend of urbanization, the concept of smart
city has been proposed and attracted widespread attention. Smart city uses smart means to reduce
energy consumption in cities, enhance energy efficiency, ease traffic pressure [129], ensure the
safety of cities and residents, and improve the quality of life of residents. In the smart city environ-
ment, there are a large number of hardware devices that generate data all the time. These devices
include light smart devices for daily life (such as smart phones, smart bracelets, and portable medi-
cal devices), as well as surveillance cameras and various environmental detection sensors for urban
security. AI is a good choice for smart city to improve the accuracy and efficacy of data analysis
because of its proficiency in dealing with massive data [130].
In a population- and equipment-intensive area like a city, smart city has stricter requirements on
real-time response and network stability to ensure the comfort and security of civil life in the city.
However, the intensive computing tasks of AI training and reasoning pose a great challenge to the
above requirements. To meet this challenge, some researchers have turned their attention to EC.
We will subsequently describe in detail the schemes of using AI algorithms under EC architecture
to deal with the problems in smart city scenarios.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:22
H. Hua et al.
4.1.1
Security of City. Smart cities need to continuously monitor the infrastructure and opera-
tion of the city, and they need to make quick judgments and respond quickly to security incidents.
Integrating AI algorithms can improve the accuracy of security event identification. However, the
network bandwidth is limited, and excessive data transmission will cause instability in network
transmission. How to deal with massive data is therefore a very difficult problem for real-time
monitoring systems. EC performs most of the data processing and analysis tasks on the edge and
transmits only part of the data to the cloud. This can greatly reduce the network transmission pres-
sure caused by massive monitoring data while improving the response speed of the application.
To ensure the safety of urban residents in public places or private places, a series of monitoring
systems (e.g., traffic monitoring, indoor and outdoor monitoring, facility monitoring, violence and
crime detection) need to be widely deployed to analyze and tackle the surrounding environment
in real time. In urban monitoring, for instance, person re-identification is an important part to
ensure the safety of residents. A new Siamese network architecture for person re-identification
is proposed in Reference [131]. This architecture speeds up the retrieval of pedestrians by intro-
ducing EC. Considering that traditional methods may learn poorly and inefficiently due to the low
resolution of images, together with the limited computing power on the edge side, the architecture
introduces a residual model layer that can mine deep features and reduce the complexity of the
global average pooling layer.
Utilizing the distributed characteristics of EC and the geo-distribution characteristics of monitor-
ing data, it is a good idea to apply different AI algorithms to EC in a distributed way. A monitoring
system based on distributed deep learning model is mentioned in Reference [100]. By introducing
EC, the system reduces the cost of communication and improves response speed. This article uses
the distributed characteristics of the edge side to deploy a distributed DL training method based on
task-level and model-level parallel training. The goal is to speed up the training of the sub-model by
taking advantage of different learning models while also using the computing power of edge nodes.
In contrast, Tang et al. [132] adopt the idea of configuring different AI algorithms in the edge and
the cloud. The proposed general-purpose EC architecture for urban pipeline monitoring systems
takes advantage of the low latency of edge nodes so that pipeline faults can be discovered in
time, and response decisions can be made quickly. The architecture consists of four layers, and the
architecture deploys different AI algorithms and control strategies in different layers to achieve
low latency, low energy consumption, and high accuracy for smart pipeline monitoring to ensure
the safety of pipelines in cities.
Challenges. In the process of protecting urban security, data privacy and security are also crucial.
AI is an effective method of identifying malicious attacks and preventing privacy leakage, but the
computing resources of edge devices are limited. Therefore, it is still a major challenge to design
lightweight and effective AI algorithms suitable for EC [131].
4.1.2
Urban Healthcare. With the popularity of IoT and cloud computing, more and more
personal medical devices are being used in daily life. These devices can collect users’ physical
data and upload the data to a cloud server. Through AI analysis, these data can greatly improve
the accuracy of medical systems for disease classification and diagnosis. However, this model of
cloud computing cannot really meet the requirements of telemedicine for time delay and data
transmission.
Compared with traditional cloud computing, the application of EC meets the requirements of
medical system for stable data transmission, transmission delay, and data security. In some emer-
gency situations, for example, just the occurrence of errors such as long response time or data loss
may directly threaten human life. Besides, EC has strong location awareness characteristics [33].
The higher processing speed of EC becomes a critical factor for location-sensitive medical systems.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:23
Next, we will summarize existing urban medical and residents’ health works that use EC to
improve AI algorithms in terms of remote diagnosis and early warning of diseases, infectious
disease prevention and control, and smart assessment.
Remote diagnosis and early warning. Muhammad et al. [133] propose a voice disorder assessment
and treatment system. The sound data collected by the system is pre-processed by edge devices
before being uploaded to the cloud. The system configures the CNN model to the edge server, so
that the edge side has the capability of voice disorder detection and classification. Compared with
the method without EC architecture in Reference [134], this method has lower latency and can
effectively reduce the pressure on network bandwidth. However, this system still needs to send
the diagnosis to a human expert, and the human expert decides the treatment plan.
For some diseases that are not easy to detect at an early stage and those that can be best treated
in the early stages of the disease (e.g., lung cancer), the patient’s survival can be significantly
extended if a patient is diagnosed and treated early in the disease [135]. To improve the early
diagnosis rate and accuracy of lung cancer, a lung cancer diagnosis system based on EC and AI is
proposed in Reference [135]. This system can not only improve the early accuracy of lung cancer
but also improve the efficiency and security of diagnosis. In the future, how to combine EC and
AI algorithms to diagnose diseases and generate corresponding treatment plans without a human
doctor is a valuable research direction.
Infectious disease prevention and control. The use of EC’s powerful location awareness feature
can effectively strengthen the prevention and control of infectious diseases. The healthcare frame-
work proposed in Reference [51] can diagnose whether a user has been infected by Kyasanur
forest disease and can map out areas where infectious diseases are likely to occur on the map. The
network edge near the data source in this structure is responsible for data preprocessing, model
training and reasoning. To more accurately identify infected people and outbreak-prone areas, this
layer incorporates a classifier called EO-NN, which combines hybridization of the extremal op-
timization (EO) and the neural networks (NN). Once a new infected person is detected, it will
inform the infected person and nearby hospitals immediately. With the distributed nature of EC,
the system has the ability to identify areas prone to infectious diseases.
Smart assessment. Residents’ daily dietary structure management is also an important part of
urban medical care, which also plays an important role in the prevention of diseases. Based on
food image recognition, Liu et al. [49] propose a dietary assessment system under an EC architec-
ture. The edge layer between end users and the cloud can minimize the response time and energy
consumption, and the CNN algorithm can improve the accuracy of recognition. Compared to the
previous system in Reference [136], which is only suitable for small data computing tasks, this
system has the ability to perform large-scale data computing tasks.
Challenges. Medical diagnosis needs accurate judgment, which requires AI algorithms to extract
all useful information from big data. However, the useful information that can be obtained by
existing algorithms is rather limited. For supervised learning, manual labeling of data may also
lead to unknown mistakes. In addition, the data acquisition system of smart medical in the future
will be mainly deployed on wearable devices. To quickly analyze and respond to the collected data,
it is also an important direction to deploy AI model to these wearable devices [136], which poses
a great challenge to the energy supply of devices. How to balance the accuracy and lightweight of
AI models is a direction worthy of studying [137].
4.1.3
Urban Energy Management. The trend of urbanization is also prompting the rapid in-
crease of energy consumption in cities. This poses many challenges for urban energy management.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:24
H. Hua et al.
Fig. 5. A typical structure of smart energy management in smart city [140]. The architecture mainly includes
three parts: (1) cloud with central control capability and powerful computing resources; (2) edge severs with
local energy control through data analysis; (3) energy devices deployed at the terminal, including users,
energy-producing and energy-consuming equipment, sensors, and so on.
For example, to meet the city’s demand for energy, energy companies need to produce excess elec-
tricity to ensure continuous energy supply to the city. This leads to a certain degree of waste of
energy [138]. In the era of big data, a large number of sensors deployed in various corners of the
city can obtain data related to energy consumption in real time. These data include population
density, electricity usage, and a wealth of environmental information that helps predict energy
consumption and energy management. In addition, applying AI algorithm to energy management
has greater advantages than traditional methods [139]. Under these conditions, the introduction
of EC and AI can make energy consumption prediction and energy management faster and more
accurate. A typical EC-based smart city energy management architecture is shown in Figure 5.
Real-time energy management decisions require dynamic predictions of energy consumption.
However, the complexity and diversity of energy data and the dynamic nature of IoT data make
it rather difficult to build an effective energy prediction system. In response to this problem, Liu
et al. [140] design an EC-based energy management framework for reducing energy consumption
in cities. Under this framework, the authors propose two DRL-based energy scheduling strategies:
• Edge DRL: model training and reasoning tasks are executed on the edge;
• Cooperative DRL: model training tasks are executed in the cloud, and dynamic energy man-
agement is implemented on the edge side based on models obtained from the cloud.
The authors prove by experiment that cloud-edge collaboration works best in terms of energy
consumption, followed by the method of deploying AI algorithms only on the edge side, and the
worst is the method of deploying AI algorithms only on the cloud [138]. This also indicates that EC
is not a substitute for cloud computing, and the relationship between the two should be synergistic
and complementary.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:25
Challenges. The rapid growth of the number of edge devices deployed to cities has exacerbated
the global energy crisis and global warming. One way to alleviate this problem is to use renewable
energy to power edge devices. Considering that edge devices are scattered in different locations of
the city, the energy consumption of traditional energy can be greatly reduced by using distributed
renewable energy generation devices. However, this solution still faces many challenges, such as
how to minimize the consumption of traditional energy while ensuring the normal operation of
edge devices, and how to establish a complementary power system for different edge devices [140].
As a control center in EI system, energy router needs certain computing power [141, 142]. There-
fore, it is also a feasible idea to combine energy router with EC in future research.
4.2
Smart Manufacturing
Introducing EC and AI in industrial production can maximize the use of hardware devices and
the use of distributed computing and storage resources. The combination of the two also achieves
efficient and secure resource management and task distribution, thereby greatly improving the
plant’s production efficiency, production quality and plant safety [143, 144].
Dynamic control. To improve the automation and intelligence of the real-time production con-
trol process, the authors of Reference [143] propose an intelligent robot factory system architecture
called iRobot-Factory. With the assistance of EC, the architecture can dynamically adjust the con-
figuration of the production line, collect and process a variety of data generated in the factory in
real time, and identify and judge by AI means to achieve more efficient feedback control. The archi-
tecture shows great advantages over the traditional factory using cloud computing with respect
to network communication time delay and recognition rate. Different devices in the factory need
to cooperate with each other through groups to achieve swarm intelligence, not just each device
operating independently. To realize swarm intelligence, how to use AI and EC technology in smart
factory is a new challenge.
Equipment monitoring. In terms of industrial production site safety, it is essential to monitor
the operating status of the machinery in the factory, since the quality issue of the machinery
will inevitably arise during long-term work. To detect the running status of the machine, Wu
et al. [50] propose an EC framework that includes a device layer, a local private edge cloud near
the device layer, and a remote public cloud. The framework uses powerful public cloud to train
the predictive model and then delegates the model to private edge cloud where online diagnostic
and prognosis tasks are performed. This reduces the delay to a certain extent and enhances the
accuracy of diagnosis and prognosis.
To better monitor and manage the equipment in the factory, it is important to clarify the type
and quantity of onsite equipment. In response to the high cost of manual classification methods,
a non-intrusive load monitoring system is proposed based on EC and LSTM [65]. In the system
architecture, the edge is responsible for data cleaning and feature selection, while the cloud with
the LSTM algorithm deployed analyzes power features uploaded by edge devices to classify and
count field devices.
Defective product detection. In addition to ensuring the safety of factory equipment, some re-
searchers have also turned their attention to monitor the quality of products more accurately and
efficiently. Li et al. [145] build a DL-based product quality classification system for production
quality monitoring, so that products with quality defects can be quickly detected on the edge side.
The system deploys lower-level CNN layers at edge layers to capture defective products that are
more easily to identify and high-level CNN in the cloud to capture defective products that are dif-
ficult to identify with edge layers. This design improves the efficiency and accuracy of identifying
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:26
H. Hua et al.
defective products, on the one hand, and it also reduces the network transmission cost, on the
other hand.
Microseismic monitoring. In oil and gas production, the low signal-to-noise ratio and the need
for real-time data transmission bring challenges in high-precision microseismic monitoring. Zhang
et al. [61] design a neural network-based EC architecture called Edge-to-Center LearnReduce Mi-
croseismic Monitoring Platform under the environment of oil and gas production. The platform
uses EC architecture with a new microseismic events detection algorithm based on LSTM, and
CNN is deployed in the data center (i.e., the cloud). The model obtained through data training in
the cloud will be delegated to each edge device, so that the edge device has the ability to recognize
microseismic events. The real-time performance is improved by analyzing and processing data on
the edge side that can get detection results faster and take corresponding actions. However, the
data generated will first be processed by the edge device to extract useful information for the data
center. This greatly reduces the volume of the data that need to transfer to the data center, so the
platform can effectively improve transmission efficiency and reduce network transmission pres-
sure. Experiments have shown that this monitoring platform combining neural network and EC
can achieve an accuracy rate of more than 96% and improve the data transmission efficiency by
about 90%.
4.3
Internet of Vehicles
IoV is currently a hot academic and commercial field, and it is a key step for humans to move
towards an intelligent life in the future [147]. IoV can ease traffic congestion, reduce traffic acci-
dents caused by improper driving, and improve passenger experience [99]. Abundant in-vehicle
applications, road condition sensors, and intelligent systems bring a very convenient, comfortable,
and safe riding experience for people traveling.
Although traditional cloud computing is currently the mainstream solution to the challenges
brought by the increasing number of applications and data, it cannot meet the requirements of IoV
(e.g., stable networks and low latency), due to the limitations of cloud computing itself. Using EC
can effectively make up for the limitations of cloud computing [148]. IoV has the characteristics
of limited resources, such as distributed computing and storage. How to allocate limited resources
and how to schedule tasks are the problems that IoV needs to solve.
EC and AI can bring faster and more precise control, faster network communication, better user
experience, and more computing resources for traditional vehicular network [149]. A typical EC-
based IoV architecture is shown in Figure 6. Today, more and more fields use AI as a means to solve
optimal strategies, and AI algorithms can also be applied to IoV to deal with the above problems. We
will summarize the application of the combination of EC and AI in IoV from three perspectives:
optimizing task offloading and resource allocation in IoV, improving the user experience of on-
board entertainment, and improving vehicle intelligence.
4.3.1
Optimizing Task Offloading and Resource Allocation. The rapidly changing network struc-
ture, communication status, and computing load have led to the dynamics and uncertainty of task
offloading [150], making efficient task offloading and resource allocation decisions more difficult.
Feng et al. [148] use the ant colony optimization algorithm with fast convergence to solve the
NP-hard task assignment problem. This method establishes multiple objective functions, and uses
heuristics algorithm for optimization. However, this method is not good at making optimal de-
cisions for offloading multiple data dependency tasks. In response to this problem, an EC frame-
work for obtaining the optimal solution of task offloading through DRL is proposed in Reference
[149]. The framework takes into account data dependencies, as well as resource requirements, ve-
hicle movements, and access networks. It uses the asynchronous advantage actor-critic (A3C)
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:27
Fig. 6. A typical structure of IoV [146]. In this architecture, the edge is composed of roadside units with
certain computing capabilities, so computing tasks on vehicles can be offloaded directly to roadside units
for processing instead of offloading into the distant cloud [146].
algorithm [151] for the online optimization of task offloading decision to adapt to the dynamic
changes of the vehicular network. Edge nodes will first distribute the trained decision model to
the surrounding vehicles, and then upload the decision model online after vehicles’ complete learn-
ing. To improve the performance of resource allocation and management, the prediction of wire-
less channel parameters is a very important means. Liu et al. [152] use LSTM to excel in spatio-
temporal correlation in channel parameters and propose a wireless channel parameter prediction
model based on LSTM and EC to optimize resource allocation and task scheduling in vehicular
network.
In IoV, energy consumption is a huge obstacle that restricts its development. However, the stud-
ies mentioned above fail to consider the issue of energy consumption while making optimal of-
floading decisions. Yang et al. [53] put forward a joint optimization problem consisting of power
control, user association, and resource allocation to minimize energy consumption in IoV. Finally,
the feasible solution of this problem is obtained by an algorithm based on fuzzy c-means clustering
that allows one data point to join multiple clusters.
4.3.2
Improving On-board Experience. The maturity and application of autonomous driving
technology will bring more free time to passengers and drivers in the future. This will increase
passengers and drivers’ demand for on-board entertainment, such as listening to music, watching
videos, and more [153]. These on-board entertainment activities have extremely high requirements
for network latency, so implementing these computing-intensive applications in a connected ve-
hicle with limited resources is facing great challenges [154]. These challenges include how to effi-
ciently cache network content and how to efficiently schedule tasks and allocate resources.
The traditional content caching method is to cache the current popular content in roadside units
in advance, but this also causes a waste of storage resources. To coordinate passenger experience
and content caching costs, Hou et al. [153] propose a Q-learning-based caching strategy under
the EC architecture. The action of this caching strategy consists of two parts, one is the cache
amount, and the other is the roadside units to which the content is cached. The reward of this
caching strategy is the elapsed time of transmitting the content required by the user. In addition,
this article uses LSTM to predict the driving direction of the vehicle to better select roadside units.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:28
H. Hua et al.
In contrast, the method of Reference [155] imposes the task of content caching on both roadside
units and vehicles. It uses a collaborative model based on Q-learning vehicles and roadside units for
content caching and computation distribution. This model can make full use of the limited storage
and computing resources of vehicles. In other words, the system will select vehicles and roadside
units to perform the tasks of caching and computing according to the position and direction of
motion of the car requesting the service. If the vehicles and roadside units around the car cannot
meet their requirements, then the cache and calculation tasks will be handed over to the base
station.
Aiming at the challenges of executing compute-intensive applications on cars with limited re-
sources, Ning et al. [154] first use finite-state Markov chains to model vehicle-to-infrastructure
communication and computing states and then express the resource allocation and task schedul-
ing strategy as a goal to maximize users’ quality of experience (QoE).
4.3.3
Improving Vehicle Intelligence. In addition to the macro-control of resource allocation, it
is also an important research direction to give AI technology to vehicle intelligence under the EC
architecture [156]. For example, Ferdowsi et al. [157] propose an EC architecture that integrates
DL to handle complex vehicle and traffic information. The architecture enables functions such as
vehicle automatic control and driving route analysis. This architecture uses different DL algorithms
according to the characteristics of different problems:
• Restricted Boltzmann machines are used to process complex data in intelligent transporta-
tion systems (ITS);
• CNN and LSTM are used to perform real-time analysis of road conditions;
• Bi-RNN is used to predict driver behavior;
• LSTM is used to ensure data transmission security.
The increasing number of vehicles aggravates the problem of traffic jam. Traffic scheduling is a
very effective way to deal with this problem. However, due to the large number of vehicles and
the scale of road network, the number of routes that vehicles can choose increases exponentially.
Therefore, it is not feasible to use centralized controller for route planning. Based on this problem,
a distributed cooperative routing algorithm based on evolutionary game theory is proposed in
Reference [158]. Each edge node deploys a roadside unit (RSU), in which normal RSU is respon-
sible for collecting traffic information, and game RSU controls nearby vehicles through proposed
evolutionary game strategy.
4.3.4
Challenges. The combination of EC and IoV improves the response speed of vehicle sched-
uling and control, which further promotes the vehicle intelligence. However, there are still some
challenges [159]. For example, when the vehicle is moving at a high speed, its communication
connection needs to be switched between different edge servers, which may lead to a series of
problems, such as disconnection or the degradation of user experience. In addition, one of the
cores of IoV systems is resource sharing between different vehicles. As a result, how to set a rea-
sonable incentive mechanism to encourage participants to share resources is vital. Finally, resource
sharing will also bring some data privacy and security issues [160].
4.4
Summary
Table 2 summarizes the research works of combining EC with three different AI application sce-
narios. Apparently, these works adopt different AI algorithms and EC architectures in different
scenarios according to their respective requirements for response speed, privacy, and so on, to
maximize the performance of the AI models.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:29
In essence, offloading all or part of the computing process of AI algorithms to the edge of the
network is nevertheless to transfer AI computing tasks from a resource intensive environment to
a resource limited environment [6]. Therefore, how to lighten AI models so that they can work
efficiently at the edge of the network with limited computing, energy, and other resources needs
further exploration [164]. In addition, an AI application often needs to collect data from different
edge nodes, which poses a great threat to user privacy. Federated learning, as a very popular and
potential research direction [96] can enable participants to learn jointly without sharing data. In
recent years, the blockchain technology has been widely applied in many fields to establish mutual
trust among participants in an open and distributed way [162, 165]. Incorporating blockchain to
tackle the challenges of combined systems of AI and EC mentioned in this section is also a direction
worthy of further exploration.
5
CONCLUSION
EC is a very promising new computing paradigm to make up for the shortcomings of existing
cloud computing, while AI is a very popular field in both academia and industry. By summarizing
the existing research results on the combination of AI and EC, we come to two conclusions. On the
one hand, AI can further improve and optimize the performance of EC, because traditional non-AI
methods have limitations in dealing with the complicated and dynamic environment in EC. On
the other hand, EC can bring faster response time and more stable network status to the practical
application of AI.
Although the research on combining AI and EC has made a lot of progress, there are still prob-
lems to be solved. For example, in the first aspect mentioned above, the complexity, dynamics,
and high dimensions of the EC process make accurate modeling rather difficult. Therefore, it is
an important research direction to design and adopt model-free methods to obtain efficient strate-
gies [94]. In addition, for the second aspect, the key to deploying AI to the edge of the network
is how to enhance the efficiency of AI algorithms with limited computing and energy resources,
which requires further research and design of lightweight AI models [6, 164].
In summary, we hope that researchers will understand the importance of combining AI and EC
and the mutually beneficial relationship between them through this article. We believe that there
should be more academic research focusing on enabling EC to have higher computing offloading,
privacy, and security performance and to enable wider use of AI. In the future, we plan to explore
more research fields that combine the two, for example, distributed training and reasoning in the
setting of EC.
REFERENCES
[1] A. U. R. Khan, M. Othman, S. A. Madani, and S. U. Khan. 2014. A survey of mobile cloud computing application
models. IEEE Commun. Surv. Tutor. 16, 1 (2014), 393–413.
[2] F. Durao, F. Carvalho, A. Fonseka, and V. C. Garcia. 2014. A systematic review on cloud computing. J. Supercomput.
68, 3 (2014), 1321–1346.
[3] W. Shi and S. Dustdar. 2016. The promise of edge computing. Computer 49, 5 (2016), 78–81.
[4] M. Qin, L. Chen, N. Zhao, Y. Chen, F. R. Yu, and G. Wei. 2018. Power-constrained edge computing with maximum
processing capacity for IoT networks. IEEE Internet Things J. 6, 3 (2018), 4330–4343.
[5] A. M. Ghosh and K. Grolinger. 2021. Edge-cloud computing for internet of things data analytics: Embedding intelli-
gence in the edge with deep learning. IEEE Trans. Ind. Inform. 17, 3 (2021), 2191–2200.
[6] P. Zhou, W. Chen, S. Ji, H. Jiang, L. Yu, and D. Wu. 2019. Privacy-preserving online task allocation in edge-computing-
enabled massive crowdsensing. IEEE Internet Things J. 6, 5 (2019), 7773–7787.
[7] E. I. Gaura et al. 2013. Edge mining the internet of things. IEEE Sens. J 13, 10 (2013), 3816–3825.
[8] Z. Xu et al. 2020. Artificial intelligence for securing IoT services in edge computing: A survey. Secur. Commun. Netw.
2020 (2020), 1–13.
[9] C. Savaglio and G. Fortino. 2021. A simulation-driven methodology for IoT data mining based on edge computing.
ACM Trans. Internet. Techn. 21, 2 (2021), 1–22.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:30
H. Hua et al.
[10] L. Lei, H. Xu, X. Xiong, K. Zheng, W. Xiang, and X. Wang. 2019. Multiuser resource control with deep reinforcement
learning in IoT edge computing. IEEE Internet Things J. 6, 6 (2019), 10119–10133.
[11] Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, and J. Zhang. 2019. Edge intelligence: Paving the last mile of artificial
intelligence with edge computing. Proc. IEEE 107, 8 (2019), 1738–1762.
[12] M. Miranda, C. Cristina, and S. Sebastiá. 2020. Deep learning at the mobile edge: Opportunities for 5G networks.
Appl. Sci. 10, 14 (2020), 4735.
[13] F. Wang, M. Zhang, X. Wang, X. Ma , and J. Liu. 2020. Deep learning for edge computing applications: A state-of-the-
art survey. IEEE Access 8 (2020), 58322–58336.
[14] J. Chen and X. Ran. 2019. Deep learning with edge computing: A review. Proc. IEEE 107, 8 (2019), 1655–1674.
[15] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, and X. Chen. 2020. Convergence of edge computing and deep
learning: A comprehensive survey. IEEE Commun. Surv. Tut. 22, 2 (2020), 869–904.
[16] Y. Shi, K. Yang, T. Jiang, J. Zhang, and K. B. Letaief. 2019. Communication-efficient edge AI: Algorithms and systems.
IEEE Commun. Surv. Tut. 22, 4 (2020), 2167–2191.
[17] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami. 2013. Internet of things (IoT): A vision, architectural elements,
and future directions. Future Gener. Comp. Syst. 29, 7 (2013), 1645–1660.
[18] D. Reinsel, J. Gantz, and J. Rydning. 2018. Data age 2025. The Digitization of the World: From Edge to Core. IDC White
Paper # US44413318.
[19] M. Marjani, F. Nasaruddin, A. Gani, I. Abaker, T. Hashem, A. Siddiqa, and I. Yaqoob. 2017. Big IoT data analytics:
Architecture, opportunities, and open research challenges. IEEE Access 5 (2017), 5247–5261.
[20] Index, Cisco Global Cloud. Forecast and Methodology, 2016–2021 White Paper. Updated: February 1, 2018.
[21] J. Zhang, B. Chen, Y. Zhao, X. Cheng, and F. Hu. 2018. Data security and privacy-preserving in edge computing
paradigm: Survey and open issues. IEEE Access 6 (2018), 18209–18237.
[22] S. Sukhmani, M. Sadeghi, M. Erol-Kantarci, and A. E. Saddik. 2019. Edge caching and computing in 5G for mobile
AR/VR and tactile internet. IEEE MultiMedia 26, 1 (2019), 21–30.
[23] H. Cai, B. Xu, L. Jiang, and A. V. Vasilakos. 2017. IoT-based big data storage systems in cloud computing: perspectives
and challenges. IEEE Internet Things J. 4, 1 (2017), 75–87.
[24] M. B. Mollah, M. A. K. Azad, and A. Vasilakos. 2017. Security and privacy challenges in mobile cloud computing:
Survey and way ahead. J. Netw. Comput. Appl. 84 (2017), 38–54.
[25] Content Delivery Network. Retrieved from https://www.akamai.com/us/en/resources/content-delivery-network.
jsp.
[26] M. Satyanarayanan. 2017. The emergence of edge computing. Computer 50, 1 (2017), 30–39.
[27] Brian E. Whitaker. 2019. Cloud edge computing: Beyond the data center. Retrieved from https://www.openstack.org/
edge-computing/cloud-edge-computing-beyond-the-data-center/.
[28] W. Shi, J. Cao, Q. Zhang, Y. Li, and L. Xu. 2016. Edge computing: Vision and challenges. IEEE Internet Things J. 3, 5
(2016), 637–646.
[29] R. Yang, F. Yu, P. Si, Z. Yang, and Y. Zhang. 2019. Integrated blockchain and edge computing systems: A survey, some
research issues and challenges. IEEE Commun. Surv. Tutor. 21, 2 (2019), 1508–1532.
[30] L. Huang, X. Feng, A. Feng, Y. Huang, and L. Qian. 2018. Distributed deep learning-based offloading for mobile edge
computing networks. Mobile Netw. Appl. (2018), 1–1. DOI:10.1007/s11036-018-1177-x
[31] Z. Ali, L. Jiao, T. Baker, G. Abbas, Z. H. Abbas, and S. Khaf. 2019. A deep learning approach for energy efficient
computational offloading in mobile edge computing. IEEE Access 7 (2019), 149623–149633.
[32] M. Yahuza, M. Idris, A. Wahid, A. T. S. Ho, S. Khan, N. Musa, and A. Taha. 2020. Systematic review on security and
privacy requirements in edge computing: State of the art and future research opportunities. IEEE Access 8 (2020),
76541–76567.
[33] D. Liu, Z. Yan, W. Ding, and M. Atiquzzaman. 2019. A survey on secure data analytics in edge computing. IEEE
Internet Things J. 6, 3 (2019), 4946–4967.
[34] G. Wang, X. Yang, W. Cai, and Y. Zhang. 2021. Event-triggered online energy flow control strategy for regional
integrated energy system using Lyapunov optimization. Int. J. Elec. Power 125, 3 (2021), 106451.
[35] L. Chen, S. Zhou, and J. Xu. 2018. Computation peer offloading for energy-constrained mobile edge computing in
small-cell networks. IEEE ACM Trans. Netw. 26, 4 (2018), 1619–1632.
[36] C. Liu, M. Bennis, M. Debbah, and H. V. Poor. 2019. Dynamic task offloading and resource allocation for ultra-reliable
low-latency edge computing. IEEE Trans. Commun. 67, 6 (2019), 4132–4150.
[37] Y. Chiang, T. Zhang, and Y. Ji. 2019. Joint cotask-aware offloading and scheduling in mobile edge computing systems.
IEEE Access 7 (2019), 105008–105018.
[38] M. Chen and Y. Hao. 2018. Task offloading for mobile edge computing in software defined ultra-dense network. IEEE
J. Select. Areas Commun. 36, 3 (2018), 587–597.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:31
[39] Z. Ning, P. Dong, X. Kong, and F. Xia. 2019. A cooperative partial computation offloading scheme for mobile edge
computing enabled internet of things. IEEE Internet Things J. 6, 3 (2019), 4804–4814.
[40] J. Du, L. Zhao, J. Feng, and X. Chu. 2018. Computation offloading and resource allocation in mixed fog/cloud com-
puting systems with min-max fairness guarantee. IEEE Trans. Commun. 66, 4 (2018), 1594–1608.
[41] Y. Wang, X. Tao, X. Zhang, P. Zhang, and Y. H. Hou. 2019. Cooperative task offloading in three-tier mobile computing
networks: An ADMM framework. IEEE Trans. Veh. Technol. 68, 3 (2019), 2763–2776.
[42] Z. Zheng, L. Song, Z. Han, G. Y. Li, and H. V. Poor. 2018. A stackelberg game approach to proactive caching in
large-scale mobile edge networks. IEEE Trans. Wirel. Commun. 17, 8 (2018), 5198–5211.
[43] W. Jing, Q. Miao, H. Song, and X. Chen. 2019. Data loss and reconstruction of location differential privacy protection
based on edge computing. IEEE Access 7, (2019), 75890–75900.
[44] J. Kang, R. Yu, X. Huang, M. Wu, S. Maharjan, S. Xie, and Y. Zhang. 2019. Blockchain for secure and efficient data
sharing in vehicular edge computing and networks. IEEE Internet Things J. 3, 6 (2019), 4660–4670.
[45] Q. Wang, D. Chen, N. Zhang, Z. Ding, and Z. Qin. 2017. PCP: A privacy-preserving content-based publish-subscribe
scheme with differential privacy in fog computing. IEEE Access 5 (2017), 17962–17974.
[46] Y. Qiao, Z. Liu, H. Lv, M. Li, Z. Huang, Z. Li, and W. Liu. 2019. An effective data privacy protection algorithm based
on differential privacy in edge computing. IEEE Access 7 (2019), 136203–136213.
[47] M. S. Hossain, G. Muhammad, and S. U. Amin. 2018. Improving consumer satisfaction in smart cities using edge
computing and caching: A case study of date fruits classification. Future Gener. Comp. Syst. 88 (2018), 333–341.
[48] F. Samie, L. Bauer, and J. Henkel. 2019. From cloud down to things: An overview of machine learning in internet of
things. IEEE Internet Things J. 6, 3 (2019), 4921–4934.
[49] C. Liu, Y. Cao, L. Yan, G. Chen, and H. Peng. 2018. A new deep learning-based food recognition system for dietary
assessment on an edge computing service infrastructure. IEEE Trans. Serv. Comput. 11 (2019), 249–261.
[50] D. Wu, S. Liu, L. Zhang, J. Terpenny, R. Gao, T. Kurfess, and J. Guzzo. 2017. A fog computing-based framework for
process monitoring and prognosis in cyber-manufacturing. J. Manuf. Syst. 43 (2017), 25–34.
[51] M. Abhishek, D. Tapas, et al. 2018. Kyasanur forest disease classification framework using novel extremal optimiza-
tion tuned neural network in fog computing environment. J. Med. Syst 42, 10 (2018), 187.
[52] S. Deng, H. Zhao, W. Fang, J. Yin, S. Dustdar, and A. Y. Zomaya. 2020. Edge intelligence: The confluence of edge
computing and artificial intelligence. IEEE Internet Things J. 7, 8 (2020), 7457–7469.
[53] Z. Yang, C. Pan, K. Wang, and M. Shikh-Bahaei. 2019. Energy efficient resource allocation in UAV-enabled mobile
edge computing networks. IEEE Trans. Wirel. Commun. 18, 9 (2019), 4576–4589.
[54] N. Kiran, C. Pan, S. Wang, and C. Yin. 2020. Joint resource allocation and computation offloading in mobile edge
computing for SDN based wireless networks. J. Commun. Netw. 22, 1 (2020), 1–11. DOI:10.1109/JCN.2019.000046
[55] Y. Guo, S. Wang, A. Zhou, J. Xu, J. Yuan, and C. Hsu. 2019. User allocation-aware edge cloud placement in mobile
edge computing. Software Pract. Exper. 50, 10 (2019), 489–502.
[56] A. Abeshu and N. Chilamkurti. 2018. Deep learning: The frontier for distributed attack detection in fog-to-things
computing. IEEE Commun. Mag. 56, 2 (2018), 169–175.
[57] Y. LeCun and Y. Bengio. 2015. Deep learning. Nature 521, 7553 (2015), 436–444.
[58] D. L. Elliot. 1993. A Better Activation Function for Artificial Neural Networks. University of Maryland, Systems Research
Center.
[59] H. Li, K. Ota, and M. Dong. 2018. Learning IoT in edge: Deep learning for the internet of things with edge computing.
IEEE Netw. 32, 1 (2018), 96–101.
[60] P. Monkam, S. Qi, H. Ma, W. Gao, Y. Yao, and W. Qian. 2019. Detection and classification of pulmonary nodules using
convolutional neural networks: A survey. IEEE Access 7 (2019), 78075–78091.
[61] X. Zhang, J. Lin, et al. 2018. An efficient neural-network-based microseismic monitoring platform for hydraulic
fracture on an edge computing architecture. Sensors 18, 6 (2018), 1828.
[62] S. Hochreiter and J. Schmidhuber. 1997. Long short-term memory. Neural Comput. 9, 8 (1997), 1735–1780.
[63] A. Diro and N. Chilamkurti. 2016. Leveraging LSTM networks for attack detection in fog-to-things communications.
IEEE Commun. Mag. 56, 9 (2016), 124–130.
[64] D. Park, S. Kim, Y. An, and J. Jung. 2018. iReD: A light-weight real-time fault detection system for edge computing
using LSTM recurrent neural networks. Sensors 18 (2018), 2110–2124.
[65] C. Lai, W. Chen, L. Yang, and W. Qiang. 2019. LSTM and edge computing for big data feature recognition of industrial
electrical equipment. IEEE Trans. Ind. Inform. 15 (2019), 2469–2477.
[66] B. Hussain, Q. Du, S. Zhang, A. Imran, and M. A. Imran. 2019. Mobile edge computing-based data-driven deep learning
framework for anomaly detection. IEEE Access 7 (2019), 137656–137667.
[67] R. Dong, C. She, W. Hardjawana, Y. Li, and B. Vucetic. 2019. Deep learning for hybrid 5G services in mobile edge
computing systems: Learn from a digital twin. IEEE Trans. Wirel. Commun. 18, 10 (2019), 4692–4707.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:32
H. Hua et al.
[68] S. A. Osia, A. S. Shamsabadi, A. Taheri, H. R. Rabiee, and H. Haddadi. 2018. Private and scalable personal data analytics
using hybrid edge-to-cloud deep learning. Computer 51, 5 (2018), 42–49.
[69] Y. Wang, K. Wang, H. Huang, T. Miyazaki, and S. Guo. 2019. Traffic and computation co-offloading with reinforcement
learning in fog computing for industrial applications. IEEE Trans. Ind. Inf. 15, 2 (2019), 976–986.
[70] S. Conti, G. Faraci, R. Nicolosi, S. A. Rizzo, and G. Schembra. 2017. Battery management in a green fog-computing
node: A reinforcement-learning approach. IEEE Access 5 (2017), 21126–21138.
[71] X. Zhao, G. Huang, L. Gao, and M. Li. 2021. Low load DIDS task scheduling based on Q-learning in edge computing
environment. J. Netw. Comput. Appl. 188, 1 (2021), 103095.
[72] B. Guo, X. Zhang, Y. Wang, and H. Yang. 2019. Deep-Q-network-based multimedia multi-service QoS optimization
for mobile edge computing systems. IEEE Access 7 (2019), 160961–160972.
[73] V. Mnih, K. Kavukcuoglu, et al. 2015. Human-level control through deep reinforcement learning. Nature 518, 7540
(2015), 529–533.
[74] F. Xu, F. Yang, S. Bao, and C. Zhao. 2019. DQN inspired joint computing and caching resource allocation approach
for software defined information-centric internet of things network. IEEE Access 7 (2019), 61987–61996.
[75] D. Zeng, L. Gu, S. Pan, J. Cai, and S. Guo. 2019. Resource management at the network edge: A deep reinforcement
learning approach. IEEE Netw. 33, 3 (2019), 26–33.
[76] J. Wang, L. Zhao, J. Liu, and N. Kato. 2019. Smart resource allocation for mobile edge computing: A deep reinforcement
learning approach. IEEE Trans. Emerg. Top. Com. DOI:10.1109/TETC.2019.2902661
[77] Y. He, F. Yu, Y. He, S. Maharjan, and Y. Zhang. 2019. Secure social networks in 5G systems with mobile edge comput-
ing, caching, and device-to-device communications. IEEE Wirel. Commun. 25, 3 (2019), 103–109.
[78] Z. Qin, D. Liu, H. Hua, and J. Cao. 2021. Privacy preserving load control of residential microgrid via deep reinforce-
ment learning. IEEE Trans. Smart Grid 12, 5 (2021), 4079–4089.
[79] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. Arcas. 2017. Communication-efficient learning of deep net-
works from decentralized data. Proceedings of the 20th International Conference on Artificial Intelligence and Statistics
(AISTATS). Washington, USA. 1273–1282.
[80] S. Yu, X. Chen, Z. Zhou, X. Gong, and D. Wu. 2021. When deep reinforcement learning meets federated learning:
Intelligent multitimescale resource management for multiaccess edge computing in 5G ultradense network. IEEE
Internet Things J. 8, 4 (2021), 2238–2251.
[81] X. Lu, Y. Liao, P. Lio, and P. Hui. 2020. Privacy-preserving asynchronous federated learning mechanism for edge
network computing. IEEE Access 8 (2020), 48970–48981.
[82] J. Zhang, Z. Zhan, Y. Lin, N. Chen, and Y. Gong. 2020. Evolutionary computation meets machine learning: A survey.
IEEE Comput. Intell. Mag. 6, 4 (2020), 68–75.
[83] Y. Li and S. Wang. 2018. An energy-aware edge server placement algorithm in mobile edge computing. In Proceedings
of the IEEE International Conference on Edge Computing (EDGE’18). IEEE. San Francisco. 2018, 66–73.
[84] H. Gao, W. Li, R. Banez, Z. Han, and H. Poor. 2019. Mean field evolutionary dynamics in ultra dense mobile edge
computing systems. In Proceedings of the IEEE Global Communications Conference (GLOBECOM). IEEE, 1–6.
[85] C. Dong and W. Wen. 2019. Joint optimization for task offloading in edge computing: An evolutionary game approach.
Sensors 19, 3 (2019), 740–764.
[86] Y. Zhan, S. Guo, P. Li, and J. Zhang. 2020. A deep reinforcement learning based offloading game in edge computing.
IEEE Trans. Comput. 69, 6 (2020), 883–893.
[87] S. Yu, X. Wang, and R. Langar. 2017. Computation offloading for mobile edge computing: A deep learning approach.
In Proceedings of the IEEE Annual International Symposium on Personal, Indoor, and Mobile Radio Communications
(PIMRC’17). IEEE, 1–6.
[88] Y. Hao, Y. Mian, L. Hu, M. S. Hossain, G. Muhammad, and S. U. Amin. 2019. Smart-edge-coCaCo: AI-enabled smart
edge with joint computation, caching, and communication in heterogeneous IoT. IEEE Netw. 33, 2 (2019), 58–64.
[89] X. Xu, D. Li, Z. Dai, S. Li, and X. Chen. 2019. A heuristic offloading method for deep learning edge services in 5G
networks. IEEE Access 7 (2019), 67734–67744.
[90] L. Lei, H. Xu, X. Xiong, K. Zheng, and W. Xiang. 2019. Joint computation offloading and multiuser scheduling using
approximate dynamic programming in NB-IoT edge computing system. IEEE Internet Things J. 6, 3 (2019), 5345–5362.
[91] J. Xu, L. Chen, and S. Ren. 2017. Online learning for offloading and autoscaling in energy harvesting mobile edge
computing. IEEE Trans. Cogn. Commun. Netw. 3, 3 (2017), 361–373.
[92] D. Mishra, S. De, S. Jana, S. Basagni, K. Chowdhury, and W. Heinzelman. 2015. Smart RF energy harvesting commu-
nications: Challenges and opportunities. IEEE Commun. Mag. 53, 4 (2015), 70–78.
[93] M. Min, L. Xiao, Y. Chen, P. Cheng, D. Wu, and W. Zhuang. 2019. Learning-based computation offloading for IoT
devices with energy harvesting. IEEE Trans. Veh. Technol. 68, 2 (2019), 1930–1941.
[94] X. Cheng, L. Feng, W. Quan, C. Zhou, H. He, W. Shi, and X. Shen. 2019. Space/aerial-assisted computing offloading
for IoT applications: A learning-based approach. IEEE J. Sel. Area. Comm. 37, 5 (2019), 1117–1129.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:33
[95] X. Chen, H. Zhang, C. Wu, S. Mao, Y. Ji, and M. Bennis. 2019. Optimized computation offloading performance in
virtual edge computing systems via deep reinforcement learning. IEEE Internet Things J. 6, 3 (2019), 4005–4018.
[96] J. Ren, H. Wang, T. Hou, S. Zheng, and C. Tang. 2019. Federated learning-based computation offloading optimization
in edge computing-supported internet of things. IEEE Access 7 (2019), 69194–69201.
[97] H. Cao and J. Cai. 2018. Distributed multiuser computation offloading for cloudlet-based mobile cloud computing: A
game-theoretic machine learning approach. IEEE Trans. Veh. Technol. 67, 1 (2018), 752–764.
[98] L. Huang, X. Feng, A. Feng, Y. Huang, and L. Qian. 2018. Distributed deep learning-based offloading for mobile edge
computing networks. Mobile Netw. Appl. 66, 12 (2018), 6353–6367.
[99] Z. Ning, P. Dong, X. Wang, L. Guo, and R. Kwok. 2019. Deep reinforcement learning for intelligent internet of vehicles:
An energy-efficient computational offloading scheme. IEEE Trans. Cogn. Commun. 5 (2019), 1060–1072.
[100] J. Chen, K. Li, Q. Deng, K. Li, and P. Yu. 2019. Distributed deep learning model for intelligent video surveillance
systems with edge computing. IEEE Trans. Ind. Inform. 5, 4 (2019), 1060–1072.
[101] S. A. Magid, F. Petrini, and B. Dezfouli. 2019. Image classification on IoT edge devices: Profiling and modeling. Cluster
Comput. 23 (2019), 1025–1043.
[102] A. Biswas and A. P. Chandrakasan. 2019. CONV-SRAM: An energy-efficient SRAM with in-memory dot-product
computation for low-power convolutional neural networks. IEEE J. Solid-St. Circ. 54, 1 (2019), 217–230.
[103] C. Maxfield. 2004. The design warrior’s guide to FPGAs: Devices, tools and Flows. Elsevier.
[104] C. Lammie, A. Olsen, T. Carrick, and M. Rahimi Azghadi. 2019. Low-power and high-speed deep FPGA inference
engines for weed classification at the edge. IEEE Access 7 (2019), 51171–51184.
[105] Y. Sun, M. Peng, and S. Mao. 2019. Deep reinforcement learning-based mode selection and resource management for
green fog radio access networks. IEEE Internet Things J. 6, 2 (2019), 1960–1971.
[106] M. S. Munir, S. F. Abedin, N. H. Tran, and C. S. Hong. 2019. When edge computing meets microgrid: A deep rein-
forcement learning approach. IEEE Internet Things J. 6, 5 (2019), 7360–7374.
[107] H. Hua, Y. Qin, C. Hao, and J. Cao. 2018. Stochastic optimal control for energy internet: A bottom-up energy man-
agement approach. IEEE Trans. Ind. Inf. 15, 3 (2019), 1788–1797.
[108] Y. Qin, H. Hua, and J. Cao. 2019. Stochastic optimal control scheme for battery lifetime extension in islanded micro-
grid. IEEE Trans. Smart Grid 10, 4 (2019), 4467–4475.
[109] H. Hua, J, Cao, G. Yang, and R. Guang. 2018. Voltage control for uncertain stochastic nonlinear system with applica-
tion to energy internet: Non-fragile robust H∞ approach. J. Math. Anal. Appl. 463, 1 (2018), 93–110.
[110] H. Hua, Z. Qin, N. Dong, M. Ye, Z. Wang, X. Chen, and J. Cao. 2022. Data-driven dynamical control for bottom-up
energy internet system. IEEE Trans. Sustain. Energ. 13, 4, (2022), 315–327.
[111] Y. Bengio, J. Louradour, R. Collobert, and J. Weston. 2009. Curriculum learning. In Proceedings of the International
Conference on Machine Learning (ICML’09). ACM. Montreal, 2009, 41–48.
[112] R. Kozik, M. Ficco, M. Choraś, and F. Palmieri. 2018. A scalable distributed machine learning approach for attack
detection in edge computing environments. J. Parallel Distr. Com. 119 (2018), 18–26.
[113] B. Wang, Y. Wu, K. R. Liu, and T. C. Clancy. 2011. An anti-jamming stochastic game for cognitive radio networks.
IEEE J. Select. Area. Commun. 29, 4 (2011), 877–889.
[114] B. Li, T. Chen, and G. B. Giannakis. 2019. Secure mobile edge computing in IoT via collaborative online learning.
IEEE Trans. Signal Process. 67, 23 (2019), 5922–5935.
[115] Y. Wang, W. Meng, W. Li, Z. Liu, Y. Liu, and H. Xue. 2019. Adaptive machine learning-based alarm reduction via edge
computing for distributed intrusion detection systems. Concurr. Comp.-Pract. E 31, 19 (2019), 1–12.
[116] L. Yu, X. Shen, J. Yang, K. Wei, and R. Xiang. 2020. Hypergraph clustering based on game-theory for mining microbial
high-order interaction module. Evolution. Bioinform. Online 16 (2020), 117693432097057.
[117] X. An, J. Su, X. Lu, and F. Lin. 2018. Hypergraph clustering model-based association analysis of DDOS attacks in fog
computing intrusion detection system. J. Wirel. Comm. Netw. 1 (2018), 249–258.
[118] L. Fernández Maimó, A. Huertas Celdrán, M. Gil Pérez, F. García Clemente, and G. Martínez Pérez. 2019. Dynamic
management of a deep learning-based anomaly detection system for 5G networks. J. Amb. Intel. Hum. Comp. 10, 8
(2019), 3083–3097.
[119] M. Zhang, L. Wang, S. Jajodia, A. Singhal, and A. Massimiliano. 2016. Network diversity: A security metric for
evaluating the resilience of networks against zero-day attacks. IEEE Trans. Inf. Foren. Section 11, 5 (2016), 1071–1086.
[120] Y. Chen, Y. Zhang, S. Maharjan, M. Alam, and T. Wu. 2019. Deep learning for secure mobile edge computing in
cyber-physical transportation systems. IEEE Netw. 33, 4 (2019), 36–41.
[121] M. Du, K. Wang, Y. Chen, X. Wang, and Y. Sun. 2018. Big data privacy preserving in multi-access edge computing
for heterogeneous internet of things. IEEE Commun. Mag. 56, 8 (2018), 62–67.
[122] X. He, R. Jin, and H. Dai. 2019. Deep PDS-learning for privacy-aware offloading in MEC-enabled IoT. IEEE Internet
Things J. 6, 3 (2019), 4547–4555.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
184:34
H. Hua et al.
[123] T. Wang, H. Hua, Z. Wei, and J. Cao. 2022. Challenges of blockchain in new generation energy systems and future
outlooks. Int. J. Elec. Power 135, 107499 (2022), 265–284.
[124] M. Du, K. Wang, Z. Xia, and Y. Zhang. 2020. Differential privacy preserving of training model in wireless big data
with edge computing. IEEE Trans. Big Data 6, 2 (2020), 283–295.
[125] C. Xu, J. Ren, L. She, Y. Zhang, Z. Qin, and K. Ren. 2019. EdgeSanitizer: Locally differentially private deep inference
at the edge for mobile data analytics. IEEE Internet Things J. 6 (2019), 5140–5151.
[126] C. Dwork and A. Roth. 2014. The algorithmic foundations of differential privacy. Found. Trends. Theor. Comput. Sci.
9, 3 (2014), 211–407.
[127] J. Chen, S. Chen, Q. Wang, B. Cao, G. Feng, and J. Hu. 2019. iRAF: A deep reinforcement learning approach for
collaborative mobile edge computing IoT networks. IEEE Internet Things J. 6, 4 (2019), 7011–7024.
[128] G. Chaslot, S. Bakkes, I. Szita, and P. Spronck. 2008. Monte-carlo tree search: A new framework for game AI. In
Proceedings of the 4th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. 216–217.
[129] C. Chen, B. Liu, S. Wan, P. Qiao, and Q. Pei. 2021. An edge traffic flow detection scheme based on deep learning in
an intelligent transportation system. IEEE Trans. Intell. Transp. 22, 3 (2021), 1840–1852.
[130] I. Hashem, V. Chang, et al. 2016. The role of big data in smart city. Int. J. Inform. Manage. 36, 5 (2016), 748–758.
[131] S. Pang, S. Qiao, T. Song, J. Zhao, and P. Zheng. 2019. An improved convolutional network architecture based on
residual modeling for person re-identification in edge computing. IEEE Access 7 (2019), 106749–106760.
[132] B. Tang, Z. Chen, G. Hefferman, S. Pei, W. Tao, H. He, and Q. Yang. 2017. Incorporating intelligence in fog computing
for big data analysis in smart cities. IEEE Trans. Ind. Inform. 13, 5 (2017), 2140–2150.
[133] G. Muhammad, M. Alhamid, M. Alsulaiman, and B. Gupta. 2018. Edge computing with cloud for voice disorder
assessment and treatment. IEEE Commun. Mag. 56, 4 (2018), 60–65.
[134] G. Muhammad, M. Rahman, A. Alelaiwi, and A. Alamri. 2017. Smart health solution integrating IoT and cloud: A
case study of voice pathology monitoring. IEEE Commun. Mag. 55, 1 (2017), 69–73.
[135] M. Prabukumar, L. Agilandeeswari, and K. Ganesan. 2017. An intelligent lung cancer diagnosis system using cuckoo
search optimization and support vector machine classifier. J. Amb. Intel. Hum. Comp. 3 (2017), 1–27.
[136] V. Stantchev, A. Barnawi, S. Ghulam, and J. Schubert. 2015. Smart items, fog and cloud computing as enablers of
servitization in healthcare. Sensors Transduc. 185 (2015), 121–128.
[137] J. Zhang and D. Tao. 2020. Empowering things with intelligence: A survey of the progress, challenges, and opportu-
nities in artificial intelligence of things. IEEE Internet Things J. 8, 10 (2020), 7789–7817.
[138] H. Luo, H. Cai, Y. Sun, and L. Jiang. 2019. A short-term energy prediction system based on edge computing for smart
city. Future Gener. Comp. Syst. 101 (2019), 444–457.
[139] H. Hua, Z. Wei, Y. Qin, T. Wang, and J. Cao. 2021. A review of distributed control and optimization in energy Internet:
From traditional methods to artificial intelligence-based methods, IET Cy-Phys. Syst.: Theory Appl. 6, 2 (2021), 63–79.
[140] Y. Liu, C. Yang, et al. 2019. Intelligent edge computing for IoT-based energy management in smart cities. IEEE Netw.
33, 2 (2019), 111–117.
[141] C. Hao, Y. Qin, and H. Hua. 2020. Energy “routers,” “computers,” and “protocols.” In Energy Internet: Systems and
Applications. Springer Nature Switzerland AG, 193–208.
[142] H. Liang, H. Hua, Y. Qin, M. Ye, S. Zhang, and J. Cao. 2022. Stochastic optimal energy storage management for energy
routers via compressive sensing. IEEE Trans. Ind. Inform. 18, 4 (2022) 2192–2202.
[143] L. Hu, Y. Miao, G. Wu, M. Hassan, and I. Humar. 2018. IRobot-factory: An intelligent robot factory based on cognitive
manufacturing and edge computing, future gener. Comp. Syst. 90, 10 (2018), 1–13.
[144] F. Liang, W. Yu, X. Liu, D. Griffith, and N. Golmie. 2020. Toward edge-based deep learning in industrial internet of
things. IEEE Internet Things J. 7, 5 (2020), 4329–4341.
[145] L. Li, K. Ota, and M. Dong. 2018. Deep learning for smart industry: Efficient manufacture inspection system with fog
computing. IEEE Trans. Ind. Inform. 14 (2018), 4665–4673.
[146] Z. Ning, P. Dong, X. Wang, L. Guo, and R. Kwok. 2019. Deep reinforcement learning for intelligent internet of vehicles:
An energy-efficient computational offloading scheme. IEEE T. Cogn. Commun. Netw. 5, 4 (2019), 1060–1072.
[147] L. Guo, M. Dong, Z. Chen, S. Feng, and G. Fang. 2017. A secure mechanism for big data collection in large scale
internet of vehicle. IEEE Internet Things J. 4, 2 (2017), 601–610.
[148] J. Feng, Z. Liu, C. Wu, and Y. Ji. 2017. AVE: Autonomous vehicular edge computing framework with ACO-based
scheduling. IEEE Trans. Veh. Technol. 66, 12 (2017), 10660–10675.
[149] Q. Qi, J. Wang, Z. Ma, H. Sun, Y. Cao, L. Zhang, and J. Liao. 2019. Knowledge-driven service offloading decision for
vehicular edge computing: A deep reinforcement learning approach. IEEE Trans. Veh. Technol. 68 (2019), 4192–4203.
[150] Y. Sun, X. Guo, J. Song, S. Zhou, Z. Jiang, X. Liu, and Z. Niu. 2019. Adaptive learning-based task offloading for
vehicular edge computing systems. IEEE Trans. Veh. Technol. 68 (2019), 3061–3074.
[151] H. Hua, Y. Qin, C. Hao, and J. Cao. 2019. Optimal energy management strategies for energy internet via deep rein-
forcement learning approach. Appl. Energ. 239 (2019), 598–609.
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.
Edge Computing with Artificial Intelligence: A Machine Learning Perspective
184:35
[152] G. Liu, Y. Xu, Z. He, Y. Rao, J. Xia, and L. Fan. 2019. Deep learning-based channel prediction for edge computing
networks toward intelligent connected vehicles. IEEE Access 7 (2019), 114487–114495.
[153] L. Hou, L. Lei L, Z. Kan, and X. Wang. 2018. A Q-learning based proactive caching strategy for non-safety related
services in vehicular networks. IEEE Internet Things J. 6 (2018), 4512–4520.
[154] Z. Ning, P. Dong, J. Rodrigues, and Z. Ning. 2019. Deep reinforcement learning for vehicular edge computing: an
intelligent offloading system. ACM Trans. Intel. Syst. Tec. 10, 6 (2019), 1–1.
[155] T. Le and R. Hu. 2018. Mobility-aware edge caching and computing in vehicle networks: A deep reinforcement
learning. IEEE Trans. Veh. Technol. 67 (2018), 10190–10203.
[156] M. Khayyat, I. A. Elgendy, A. Muthanna, A. Alshahrani, S. Alharbi, and A. Koucheryavy. 2020. Advanced deep
learning-based computational offloading for multilevel vehicular edge-cloud computing networks. IEEE Access
8 (2020), 137052–137062.
[157] A. Ferdowsi, U. Challita, and W. Saad. 2018. Deep learning for reliable mobile edge analytics in intelligent transporta-
tion systems. IEEE Veh. Technol. Mag. 14, 1 (2018), 62–70.
[158] J. Lu, J. Li, Yuan Q, and B. Chen. 2019. A multi-vehicle cooperative routing method based on evolutionary game theory.
In Proceedings of the IEEE Intelligent Transportation Systems Conference (ITSC’19). IEEE. New Zealand. 987–994.
[159] X. Hou, Z. Rem, J. Wang, W. Cheng, and H. Zhang. 2020. Reliable computation offloading for edge-computing-enabled
software-defined IoV. IEEE Internet Things J. 7, 8 (2020), 7097–7111.
[160] J. Zhang and K. B. Letaief. 2020. Mobile edge intelligence and computing for the internet of vehicles. Proc. IEEE 108,
2 (2020), 246–261.
[161] X. Wang, Y. Han, V. Leung, D. Niyato, X. Yan, and X. Chen. 2019. Convergence of edge computing and deep learning:
A comprehensive survey. IEEE Commun. Surv. Tut. 22, 2 (2019), 869–904.
[162] M. KKowalski, Z. Lee, and T. Chan. 2021. Blockchain technology and trust relationships in trade finance. Technol.
Forecast. Soc. 166 (2020), 120641.
[163] T. Wang, J. Guo, et al. 2021. RBT: A distributed reputation system for blockchain-based peer-to-peer energy trading
with fairness consideration. Appl. Energ. 295, 1 (2021), 117056.
[164] S. Pang, S. Qiao, T. Song, J. Zhao, and P. Zheng. 2019. An improved convolutional network architecture based on
residual modeling for person re-identification in edge computing. IEEE Access 7 (2019), 106748–106759.
[165] J. Li, J. Wu, J. Li, A. K. Bashir, M. J. Piran, and A. Anjum. 2021. Blockchain-based trust edge knowledge inference of
multi-robot systems for collaborative tasks. IEEE Commun. Mag. 59, 7 (2021), 94–100.
[166] Y. Wei, F. Yu, M. Song, and Z. Han. 2019. Joint optimization of caching, computing, and radio resources for fog-enabled
IoT using natural actor-critic deep reinforcement learning. IEEE Internet Things J. 6, 2 (2019), 2061–2073.
Received 17 September 2021; revised 18 June 2022; accepted 8 August 2022
ACM Computing Surveys, Vol. 55, No. 9, Article 184. Publication date: January 2023.


</subsection_point_Point 3>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>


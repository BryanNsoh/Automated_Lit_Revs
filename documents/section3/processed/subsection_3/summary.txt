<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<documents>
<review_intention>
  
the purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.
Examining automation across the entire pipeline: The review intends to systematically analyze the automation of each component of the irrigation management pipeline, from data collection and transmission to processing, analysis, decision-making, and automated action. It aims to investigate the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
Highlighting the role of interoperability and standardization: The review seeks to emphasize the importance of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline. It aims to identify existing and emerging standards and their applicability to real-time irrigation management systems.
Identifying challenges and proposing solutions: The review intends to uncover the challenges associated with implementing real-time, automated irrigation systems, such as data quality, scalability, reliability, and security. It aims to propose solutions and best practices based on the analysis of case studies and real-world implementations.
Guiding future research and innovation: By identifying research gaps and proposing new research questions and hypotheses, the review aims to provide a roadmap for advancing the field of real-time, automated irrigation management. It seeks to encourage collaborative research efforts across disciplines to address the complex challenges of automated irrigation systems.
In summary, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.
</review_intention>

<section_intention>
DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING: Focuses on the initial stages of the automated irrigation management pipeline, covering data collection, edge and fog computing, real-time data transmission protocols and technologies, and the challenges and solutions associated with real-time data transmission.
</section_intention>

<subsection_title>
3.3. Automation of Data Collection
</subsection_title>

<subsection_point_Point 3>
Point: Investigate the potential of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection

Papers to support point:

Paper 1:
- APA Citation: Nishiura, S., & Yamamoto, H. (2021). Large-term sensing system for agriculture utilizing UAV and wireless power transfer. In 2021 International Conference on Information Networking (pp. 1-6). IEEE.
  Main Objective: To develop a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields.
  Study Location: Unspecified
  Data Sources: Sensor data collected from stationary sensor nodes
  Technologies Used: Wireless sensor networks, wireless power transfer, drones (UAVs), image analysis, feedback control
  Key Findings: The proposed system successfully utilizes wireless power transfer to power sensor nodes, eliminating the need for batteries and reducing operational costs.
  Extract 1: "In this study, we have proposed a new sensor network system that autonomously collects data related to crop growth from sensor nodes installed in multiple points scattered over a vast farm. For eliminating the need for periodic battery replacement of the sensor node and reduces the cost of operating the system, the UAV flies over a vast farm and the stationary sensor nodes are operated using wireless power transfer from the UAV."
  Extract 2: "Through the experimental evaluation using the developed system, it has been confirmed that the UAV can accurately be controlled by the proposed feedback control to land near the sensor nodes, and that the sensor nodes can be operated by the wireless power transfer from the embedded system of the UAV."
  Limitations: None
  Relevance Evaluation: This paper is highly relevant to the point of focus, as it explores the potential of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection in automated irrigation management systems. The proposed system utilizes drones to autonomously collect data from sensor nodes using wireless power transfer, a novel approach that addresses the challenges of battery replacement and data transmission in large-scale irrigation systems.
  Relevance Score: 0.9
  Inline Citation: (Nishiura & Yamamoto, 2021)
  Explanation: This paper introduces a novel sensor network system that utilizes drones (UAVs) equipped with wireless power transfer technology to collect environmental data from stationary sensor nodes dispersed across vast agricultural fields. By eliminating the need for batteries in the sensor nodes, the system reduces operational costs and enhances the efficiency of data collection.

 Full Text: >
"This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2021 International Conference... Large-term sensing system for agriculture utilizing UAV and wireless power transfer Publisher: IEEE Cite This PDF Shota Nishiura; Hiroshi Yamamoto All Authors 4 Cites in Papers 307 Full Text Views Abstract Document Sections I. Introduction II. Related Works and Objectives of Our Study III. Proposed System IV. Performance Evalulation of Wireless Power Transfer V. Performance Evalulation of Landing Control Algorithm Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: In recent years, in order to improve crop production and quality of agricultural operations, an “agricultural remote monitoring system” have been attracting a lot of attention. The existing studies have proposed an agricultural remote monitoring systems using Wireless Sensor Network (WSN). In the existing system, the environmental information is collected from a large number of sensor nodes installed in the farm using a low-power wireless communications (e.g., ZigBee, LPWA). However, in these systems, even when the low-power wireless technology is utilized, it is difficult to run permanently on batteries because the battery capacity is not infinity. In addition, in the case of a large-scale field, a large number of intermediate nodes should be installed in the field, hence the installation and operation costs are high.On the other hand, a wireless power transfer technology is evolving and equipment which is capable of supplying power to places dozens of centimeters away has been available. In addition, Unmanned Aerial Vehicles (UAV) that can fly stably for a long time and has a large loading capacity has appeared.Therefore, in this study, we propose and develop a wide-area sensing system for large-scale farms using a UAV, a wireless power transfer technology, and an energy-saving short-range wireless communication system (i.e., Bluetooth Low Energy (BLE)). The UAV flies autonomously to the location of sensor nodes that are widely installed in the large farm for collecting the sensor data. Here, the UAV is designed to supply the power to the sensor node to measure and send the environmental information using the wireless power transfer technology. It eliminates the need for periodic battery replacement of the sensor node, which reduces the cost of operating the system.Through the experimental evaluation using the developed system, it has been confirmed that the UAV can accurately be controlled by the proposed feedback control to land near the sensor nodes, and that t... (Show More) Published in: 2021 International Conference on Information Networking (ICOIN) Date of Conference: 13-16 January 2021 Date Added to IEEE Xplore: 02 February 2021 ISBN Information: Print on Demand(PoD) ISSN: 1976-7684 DOI: 10.1109/ICOIN50884.2021.9333971 Publisher: IEEE Conference Location: Jeju Island, Korea (South) SECTION I. Introduction In recent years, in order to improve crop production and quality of agricultural operations and to reduce labor’s cost, an “agricultural remote monitoring system” for remotely observing the environmental condition of the farm and a “precision agriculture” that is a farming management concept based on observing, measuring and responding to inter and intra-field variability in crops have been attracting a lot of attention. So far, the existing studies have proposed an agricultural remote monitoring systems using Wireless Sensor Network (WSN) and remote sensing using Unmanned Aerial Vehicles (UAV). In the existing WSN-based system, the environmental information (e.g., temperature, humidity, illuminance) is collected from a large number of sensor nodes installed in the farm using a low-power wireless communications (e.g., ZigBee, LPWA). However, in these systems, even when the low-power wireless technology is utilized, it is difficult to run permanently on batteries because the battery capacity is not infinity. In addition, in the case of a large-scale field, a large number of intermediate nodes should be installed in the field, hence the installation and operation costs are high. On the other hand, a wireless power transfer technology is evolving and equipment which is capable of supplying power to places dozens of centimeters away has been available. In addition, UAVs that can fly stably for a long time and has a large loading capacity has appeared. Therefore, in this study, we propose and develop a wide-area sensing system for large-scale farms using UAV, a wireless power transfer technology, and an energy-saving short-range wireless communication system (i.e., Bluetooth Low Energy (BLE)). In the proposed system, the UAV flies autonomously to the location of sensor nodes that are widely installed in the large farm for collecting the sensor data. Here, the UAV is designed to supply the power to the sensor node to measure and send the environmental information using the wireless power transfer technology. The combination of the UAV and the wireless power transfer technology not only cover a wide area of several kilometers to dozens of kilometers but also eliminates the need for periodic battery replacement of the sensor node and reduces the cost of operating the system. SECTION II. Related Works and Objectives of Our Study A. WSN-based Remote Monitoring System for Agriculture Kassim and Patil have proposed and implemented a WSN system to remotely monitor temperature and humidity on the farm in real time [1] [2]. In addition, Fitriawan has evaluated performance (e.g., packet loss rate, throughput) of ZigBeebased WSNs in various communication types (e.g., one-to-one, many-to-one, multi-hop) and environments (e.g., indoor, outdoor) [3] [4]. In these existing studies, a large number of intermediate nodes should be installed for constructing a wide area WSN system, which results in high installation and operation costs. Especially, it is difficult to construct a wide-area agricultural remote monitoring system that covers a range of a few kilometers to dozens of kilometers because the throughput decreases as the number of hops in the communication path increases. Furthermore, even if the low-power wireless technology such as ZigBee and LPWA is utilized, the battery of the sensor node should sometimes be replaced because the battery capacity is not infinity. B. UAV-based Remote Sensing System In the existing studies, the UAV has been used for supporting agriculture [5] [6] [7]. Katsigiannis have used multispectral and thermal cameras to take aerial photographs to observe the vegetation and the water stress [8]. In addition, Rokhmana have used a high-resolution camera to take and analyze photos of the field to understand farmland area and growth variability [9]. However, these studies focus on analyzing images using high-priced cameras, and there is no consideration for utilizing UAV to efficiently collect environmental information. C. Objectives of This Study Based on the problems described in the previous sections, this study develops a new sensor network system utilizing the UAV equipped with not only a camera but also an embedded system with a short-range wireless communication (BLE) and a wireless power transfer module. The BLE module is used to collect the environmental information related to crop growth from sensor nodes installed at multiple locations of a large farm. In addition, by using wireless power transfer technology, the sensor nodes installed on the farm can be run without a battery, which eliminates a cost for periodic battery replacement. SECTION III. Proposed System Overview of our proposed system is shown in Fig.1. A main component of the system is an embedded system which controls flight of a UAV and supports a BLE communication and a wireless power transfer, a stationary sensor node which collects environmental information (e.g., temperature, humidity, illumination) on the farm, and a server that manages and analyzes the data collected by the UAV. When the embedded system receives a flight command from a terminal owned by the administrator, it sends a control command including the location information of the stationary sensor nodes to the UAV. Then, the UAV flies to the location of the stationary sensor node, takes a picture of the growth condition of the crop on the farm, and lands on the ground near the stationary sensor node. After the stationary sensor node is activated by being supplied power from a power transmission substrate of the wireless power transfer module mounted on the embedded system, It transmits the measured sensor data to the UAV using BLE communication. After the UAV finishes acquiring sensor data from all sensor nodes, it returns to the start point of the flight and sends the collected sensor data and the image pictures to the server via HTTP communication through wireless LAN. The server manages and analyzes the data received from the UAV, and provides the visualized data to the browser of the smartphone, tablet, and PC browsers. Fig. 1. Overview of Proposed System Show All Table I UAV Specifications A. Device/Functional Structure of the Proposed System In the following sections, we explain device and functional structure of the main components of the proposed system: a UAV with an embedded system, a stationary sensor node and a server. 1) UAV with Embedded System Device configuration of the embedded system is shown in Fig.2 and the appearance of the UAV is shown in Fig.3. The proposed system uses 3D Robotics’s 3DR SoLo as a UAV, which is capable of stable flight based on GPS coordinate and can be controlled by receiving the commands from the embedded system through the wireless LAN. The main specifications of the UAV are shown in Teb.I. In addition, the embedded system on the UAV is based on a Raspberry Pi 4 Model B, which is a single-board computer supporting Wi-Fi and Bluetooth. The UAV operates as an access point for a wireless LAN, and the embedded system connects to the UAV through the wireless LAN and controls the flight function of the UAV. This structure allows the embedded system to control the UAV even when the UAV flies away from the administrator beyond the limit of the communication distance of the wireless LAN. The embedded system is equipped with a Raspberry Pi Camera V2, an inexpensive camera module for capturing images of the lower part of the UAV, a HC-SR04 that is a ultrasonic sensor for accurately measuring the altitude of the UAV, and a MQS-1PXD-R1, power transmission substrate for supplying power to the stationary sensor nodes using wireless power transfer technology. 2) Stationary Sensor Node Device configuration of the stationary sensor node is shown in Fig.4 and the appearance is shown in Fig.5. The stationary sensor node installed on the farm is composed of a microcontroller supporting a BLE communication, Adafruit Feather nRF52840 Express. The microcontroller is equipped with a temperature and humidity sensor, and an illuminance sensor. In addition, the stationary sensor node is connected with a power receiving substrate of the wireless power transfer module, and is activated by a power supply from the UAV. After activated by the UAV, it measures the sensor data, and sends the measured sensor data to the UAV using BLE communication. The packet format of the sensor data is shown in Teb.II. Fig. 2. Device Configuration of Embedded System Show All Fig. 3. Appearance of UAV Show All 3) Server In the proposed system, we use a standard PC server as the server. The server centrally manages data of the environmental information on the farm and the images of crops using MySQL, and analyzes the data and images received from the embedded system to estimate the crop growth and weather conditions. Furthermore, it executes the HTTP server to provide the visualized data to the browser of the smartphone, tablet device, and PC so that the administrator can easily understand the condition of the farm. B. Algorithm for Autonomous Flight 1) Sensor Data Collection Using Wireless Power Transfer In this proposed system, the UAV is controlled based on the GPS coordinate and the result of the analysis of the image captured by the camera connected to the UAV so that it can land correctly on the stationary sensor node. After that, by supplying electric power from the UAV to the stationary sensor node using the wireless power transfer technology, the stationary sensor node can be configured without a battery. Fig. 4. Device Configuration of Stationary Sensor Node Show All Fig. 5. Appearance of Stationary Sensor Node Show All The flight and data acquisition procedure of the UAV is shown in Fig.6. First of all, when the UAV with the embedded system receives a flight control command that includes coordinate of the stationary sensor nodes from the administrator, it flies and moves to the position just above the stationary sensor node based on the GPS coordinate. The accuracy of coordinate measured by the GPS of the UAV is about 2 meters, hence the distance between the UAV and the sensor node is within the range of the BLE communication if the UAV is landed simply based on the coordinate of the GPS. However, if the UAV is apart such a distance from the stationary sensor node, it cannot supply enough power to the stationary sensor node to activate the measurement and BLE communication functions. Therefore, the embedded system analyzes the images taken by the camera mounted on the lower part of the UAV and controls the UAV using the landing algorithm of feedback control (see Section III.B.2) so that the UAV can land just above the stationary sensor node. At this time, if the distance between the power transmission substrate in the UAV and the power receiving substrate connected to the stationary sensor node is sufficiently short, power is supplied from the UAV to the stationary sensor node. Table II Packet Format of Environmental Information Fig. 6. Procedure for Acquiring Sensor Data Show All 2) Feedback Control of UAV Using Image Analysis After arriving in the sky above the sensor node based on the GPS coordinate, if the embedded system detects the shape of the power receiving substrate in the image taken by the camera, the UAV horizontally moves so that the power receiving substrate appears at the central point of the image. This process is repeated while lowering the altitude of the UAV until the wireless power transfer can be started. If the embedded system cannot detect the power receiving substrate in the captured image, the UAV increases the altitude and takes the image again. The detection procedure of the power receiving substrate is described below. In this study, in order to make the detection easier, a 25cm × 25cm piece of red drawing paper is pasted on the surface of the power receiving substrate of the sensor node, and the power receiving substrate is detected by applying color extraction and rectangular extraction process to the original images. First, the embedded system uses the color extraction based on the HSV model to extract only pixels of a specific color from the image. Next, the embedded system executes the rectangular extraction process for the pixels that are extracted by the color extraction process and calculates the center coordinate of the power receiving substrate. An example of the extraction process is shown in Fig.7. Next, the embedded system calculates the horizontal movement distance between the UAV and the central point of the sensor node, and moves to the position just above the sensor node. The actual distance per pixel in the image varies with the altitude of the UAV as shown in Fig.8. Therefore, the embedded system calculates the actual distance per pixel from the angle of view of the camera and the altitude of the UAV, and then calculates the horizontal distance to the center coordinate of the power receiving substrate. Here, the current altitude can be measured using a barometric pressure sensor which is standardly installed on the UAV, but the sensor cannot accurately measure the altitude. Therefore, the ultrasonic sensor is used to measure the altitude after the altitude of the UAV reaches the measurement range of the ultrasonic sensor (i.e., 3 meters). After that, the UAV lowers the altitude and is moved to the direction of the stationary sensor node for the calculated distance. This process is repeated until the distance is close enough to supply power to the sensor node using the wireless power transfer. Fig. 7. Example of Extraction Process Show All Fig. 8. Relationship Between Distance and Number of Pixels Show All SECTION IV. Performance Evalulation of Wireless Power Transfer In this section, we conduct preliminary experiments to evaluate the power supply performance of the wireless power transfer module used in this proposed system. A. Magnitude of Current Supplied by Wireless Power Transfer First, the magnitude of current supplied from the power transmission substrate to the power receiving substrate during wireless power transfer is investigated. In the proposed system, the power is supplied by the power transmission substrate with 1W/5V output when approaching the power receiving substrate of 40cm square. At this time, the amount of current supplied to the power receiving substrate is expected to vary depending on the distance between the substrates and the positional relationship. Therefore, the magnitude of current supplied in various positional relationships is measured. The experiment is conducted in a flat area in a room at Ritsumeikan University, where there is no metal around. In the experiment, the height of the power transmission substrate is fixed at 0, 2 and 4cm from the floor. The power transmission substrate is moved from the center of the power receiving substrate by every 1 cm in the lateral and diagonal directions as shown in Fig.9, and the magnitude of current supplied is measured at each point. Fig. 9. Evaluation of Wireless Power Transfer Module Show All Fig. 10. Evaluation of Wireless Power Transfer Module(lateral) Show All The results of the experiments when moving the power transmission substrate in the lateral and diagonal directions are shown in Figs.10 and 11, respectively. These figures show the relationship between the distance between the power transmission and receiving substrates and the magnitude of current. As shown in these figures, after the distance between the substrates increases beyond a certain distance, the magnitude of current supplied tends to decrease. In addition, the magnitude of current significantly decreases when the power transmission substrate passes near the edge of the receiving substrate (around 20cm in x-axis) because the coils are crowded around the periphery of the power receiving substrate and it is not possible to generate a stable induction current due to the positional relationship. By confirming the actual operation of the BLE module used in the proposed system, it is clarified that the module works fine within 31cm from the center of the power receiving substrate, except for the 20cm area mentioned above, when the height of the power transmission substrate is 2cm. Therefore, we can conclude that the UAV can provide sufficient power to the BLE module using the wireless power transfer by landing within an area of 62cm square. B. Packet Loss Rate during Wireless Power Transaction In this study, we prototype a stationary sensor node using the BLE module and evaluate the communication performance during wireless power transfer. This experiment is conducted in the ground at Ritsumeikan University. Fig. 11. Evaluation of Wireless Power Transfer Module(diagonal) Show All In this experiment, the stationary sensor node repeatedly transmits the packet of 20 bytes (maximum packet size of BLE) to the embedded system on the UAV 100 times during a wireless power transfer. This measurement is performed when the power transmission substrate is placed at various points within an area (i.e., 62cm square) where the wireless power transfer is successful. In the experiment, the embedded system can correctly receive all data packets with no data corruption or missing. Thus, it can be clarified that the wireless power transfer is useful to operate the stationary sensor node for collecting the environmental information. SECTION V. Performance Evalulation of Landing Control Algorithm In this section, we develop an embedded system installed on the UAV, and conduct a demonstration experiment to evaluate the effectiveness of the proposed landing control algorithm. A. Detection Accuracy of the Stationary Sensor Node by Image Analysis In this experiment, We firstly evaluate detection accuracy of the power receiving substrate of the stationary sensor node by image analysis. This experiment is conducted in the ground at Ritsumeikan University, and the altitude of the UAV is raised at 5m intervals and 20 images are taken at each altitude. Then, the images are analyzed for detecting the shape of the power receiving substrate, and the detection accuracy is evaluated at each altitude. Figure 12 shows the relationship between the altitude of the UAV and the detection rate of the stationary sensor node. From this figure, the detection rate tends to decrease as the altitude of the UAV increases. In addition, the detection rate of sensor nodes is stable when the altitude of the UAV is lower or equal to 20 meters. However, when the altitude exceeds 25 meters, the accuracy markedly decreases because the different objects can be detected as the sensor nodes. Here, when the altitude of the UAV is 20 meters, the image taken by the camera module can capture an area of about 20 meters square. Therefore, even if the measurement error of the GPS coordinate is about 5 meters, it is possible to keep the stationary sensor node within the angle of view of the camera module by navigating the UAV based on the GPS coordinate. Fig. 12. Detection Accuracy of the Sensor Nodes Using Image Analysis Show All Fig. 13. Effectiveness of Feedback Control using Image Analysis Show All B. Landing Accuracy of Feedback Control Algorithm In order to evaluate the effectiveness of the proposed feedback control algorithm, we compare the performance between the proposed algorithm and the simple GPS-based navigation in terms of the distance between the landing point and the center point of the sensor node. In addition, we confirm whether the wireless power transfer succeeds a landing point in each algorithm. This experiment is conducted on the same ground as the previous sections. The sensor node is installed at a position 30 meters away from the takeoff point of the UAV, and the UAV is controlled by the embedded system to land near the sensor node. In this evaluation, ten trials are performed for each method and the distance between the power transmission substrate and the power receiving substrate at the landing point is measured. Figure 13 shows the box plot of the measured distance in each method. As shown in this figure, the proposed method achieves an accurate navigation of the UAV, and the UAV can land on the position where the wireless power transfer is succeeded (i.e., the distance is shorter than 31 cm) with high probability. As a result, the proposed method landed in a position where wireless power transfer could be successful 6 times out of 10 trials. In the future, the feedback algorithm will be enhanced so that the landing procedure is repeated until the UAV can receive sensor data after landing. SECTION VI. Conclusion In this study, we have proposed a new sensor network system that autonomously collects data related to crop growth from sensor nodes installed in multiple points scattered over a vast farm. For eliminating the need for periodic battery replacement of the sensor node and reduces the cost of operating the system, the UAV flies over a vast farm and the stationary sensor nodes are operated using wireless power transfer from the UAV. Through the experimental evaluation using the developed system, it has been confirmed that the UAV can accurately be controlled by the proposed feedback control to land near the sensor nodes, and that the sensor nodes can be operated by the wireless power transfer from the embedded system of the UAV. In the future, we will consider enhancement of the feedback control algorithm so that the wireless power transfer is always succeeded and will propose a method to estimate the crop growth by collecting and analyzing sensor data during the actual crop growth stage. I would like to thank Mr. Toshio Masuyama for his cooperation in the study of wireless power supply technology. This study was supported by JSPS KAKENHI Grant Number JP19H04103. Authors Figures References Citations Keywords Metrics More Like This Wireless Communication of Buried IoT Sensors Utilizing Through the Soil Wireless Power Transfer for Precision Agriculture 2023 IEEE Wireless Power Technology Conference and Expo (WPTCE) Published: 2023 Wireless Power Transfer for 3D Printed Unmanned Aerial Vehicle (UAV) Systems 2018 IEEE Asia Pacific Conference on Postgraduate Research in Microelectronics and Electronics (PrimeAsia) Published: 2018 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 2:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: Investigate the potential of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection
  Extract 2: Wireless sensor networks have the potential to significantly improve the efficiency and effectiveness of irrigation management systems, providing real-time data collection, remote monitoring, and automated control capabilities.
  Limitations: >
  Relevance Evaluation: Highly relevant - The paper is directly related to the point of focus outlined in the prompt, which is about the use of wireless sensor networks and energy-efficient communication protocols for real-time, end-to-end automated irrigation management systems.
  Relevance Score: 0.9
  Inline Citation: >
  Explanation: This paper focuses on the initial stages of the automated irrigation management system and discusses the potential of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.

The authors provide a concise summary of the key points of a study they conducted to investigate the challenges and solutions associated with implementing real-time, end-to-end automated irrigation management systems using wireless sensor networks. They highlight the need for low power, energy-efficient communication protocols to minimize maintenance and operational costs, and discuss the advantages of using wireless sensor networks for this purpose.

Their analysis shows that wireless sensor networks have the potential to significantly improve the efficiency and effectiveness of irrigation management systems, providing real-time data collection, remote monitoring, and automated control capabilities. They envision a future where automated irrigation management systems using wireless sensor networks are widely adopted in agriculture, leading to increased crop yields, reduced water consumption, and improved sustainability.

 Full Text: >
"Skip to main content Skip to article Journals & Books Search Register Sign in Brought to you by: University of Nebraska-Lincoln View PDF Download full issue Outline Abstract Keywords 1. Introduction 2. IWSN layers and protocols 3. Standards used in IWSN 4. Multi-channel approaches and link quality estimation 5. WSN platforms, operating systems and simulators 6. Systematic mapping of IWSN researches 7. Discussion 8. Conclusion Acknowledgment References Vitae Show full outline Cited by (77) Figures (21) Show 15 more figures Tables (8) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show all tables Journal of Network and Computer Applications Volume 97, 1 November 2017, Pages 96-125 Review Survey and systematic mapping of industrial Wireless Sensor Networks Author links open overlay panel Diego V. Queiroz a c, Marcelo S. Alencar c, Ruan D. Gomes b, Iguatemi E. Fonseca d, Cesar Benavente-Peces a Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.jnca.2017.08.019 Get rights and content Abstract The Wireless Sensor Network (WSN) is an infrastructure comprised of sensing, computing, and communication devices, that obtain and process data to help understand the behavior of the monitored environment, and to react to events and phenomena that occur in it. The WSN can be used in domains such as agriculture, energy, industrial automation, medical health care, smart building, and so on. In industry, the characteristics of the wireless channel are different in comparison to other WSN environments, such as home and office environments. The use of WSN in industry is subject to typical problems of wireless communications, such as noise, shadowing, multipath fading and interference. In addition, the wireless channel in many industrial environments is non-stationary for a long term, which can cause abrupt changes in the characteristics of the channel over time. A set of standards was developed for industrial WSN, to overcome these limitations, such as WirelessHART, ISA100.11a, WIA-PA, and IEEE 802.15.4e. All the mentioned standards are based on the IEEE 802.15.4 physical layer, but define different mechanisms for the upper layers. However, according to recent publications, problems still can arise in the deployment of networks that follow the standards, because of multipath effects, and interference. This survey provides a structured overview of the standards used to implement industrial WSN, their advantages and drawbacks, and discusses the characteristics of the wireless channel in industrial environments. Finally, a systematic mapping is described, that presents results of publications about industrial WSN, and highlights important topics to be studied in this field. Previous article in issue Next article in issue Keywords Industrial Wireless Sensor NetworksSurveySystematic mapping 1. Introduction Traditionally, industrial monitoring systems work offline or use wired networks to transmit the information to a central station. In monitoring systems based on wired networks, the installation process of cables and sensors usually has higher cost than the sensors themselves (Lu and Gungor, 2009). Moreover, this approach has limited flexibility, which makes the process of installation and maintenance of the network more difficult and expensive. An alternative to implement systems that present lower cost, is the use of wireless networks, which have significant advantages, including high flexibility, reconfigurability, easy installation and maintenance (Gungor and Hancke, 2009). More specifically, the Wireless Sensor Networks (WSN) have other advantages, such as the ability of self-organization and local processing, appearing as a promising platform for the implementation of monitoring and controlling systems in industrial environments. The WSN nodes are equipped with sensors (or actuators), and present processing capabilities. They have resource constraints, with low processing power and, in some cases, restrictions in power consumption. In industry, sensors are deployed to monitor critical parameters such as vibration, temperature, pressure and motor efficiency (Delgado Gomes et al., 2013). The measurements obtained by the sensors are transmitted wirelessly to a sink node, which provides the information for analysis by a monitoring central, or to be used in control systems. In some cases, the acquired data is locally processed (at the end node) before transmission. A variety of information can be acquired by the WSN for different purposes, which allows taking appropriate decisions. Based on the obtained information, it is possible to fix or replace equipment before major losses occur. The use of WSN in industrial systems presents some challenges. Wireless networks use an inherently unreliable communication medium, which can be aggravated due to noise and interference in the spectrum band used for communication. Different types of interference sources for WSN can be found in industrial environments, such as welding equipment, microwave ovens, and other wireless communication devices (e.g. Wi-Fi or Bluetooth networks). In addition, in industrial environments there are machinery, and many metal objects and obstructions, as depicted in Fig. 1, which can affect the quality of the wireless channel. Thus, besides noise and interference, the communication channel is affected by heavy multipath propagation effects (Cheffena, 2012), which results in a high degree of attenuation in large and small scale (Tanghe et al., 2008). Download : Download high-res image (485KB) Download : Download full-size image Fig. 1. An example of industrial environment. Compared to other indoor and outdoor environments, the industrial ones are harsher due to the unpredictable variations of temperature, pressure, humidity, and so on. In addition, the wireless channel in many industries is non-stationary in the long term, which can cause abrupt changes in the characteristics of the channel over time (Agrawal et al., 2014). The lack of reliability makes it difficult to establish Quality of Service (QoS) guarantees. Since the industry intends to reduce the capital and operational expenditure without losing QoS (Kumar et al., 2014), the sensors need to be low cost, resulting in a set of restrictions, like low rate and low processing capabilities. Fig. 2 shows a general Industrial WSN (IWSN) configuration, in which the dashed arrows represent the wireless links of the End Nodes, and the solid arrows represent the links between the clustering nodes (Cluster Heads) and Sink Nodes. The Sink Nodes may have multiple wireless interfaces, each one using a different channel in order to allow simultaneous transmissions from the Cluster Heads. The End Nodes can communicate with a Sink Node using a single hop, or using multiple hops through a Cluster Head or intermediate routers (nodes illustrated in green). In this scenario, the intermediate routers are nodes that can act both as a sensoring device (end node), and as a router. The Final Processing Node is connected to the Sink Nodes, and is in charge of collecting and analyzing all the data received from the WSN. Usually the connection between the Sink Nodes and the Final Processing Node is done using a wired link. Download : Download high-res image (169KB) Download : Download full-size image Fig. 2. General Wireless Sensor Networks. The characterization of the industrial environments, to analyze interference sources, and propagation characteristics, is an important step in the development of new applications that use wireless networks, and to improve the current standards used to implement IWSN, such as the standards WirelessHART (Song et al., 2008), ISA100.11a (Petersen and Carlsen, 2011), WIA-PA (Silva and Guedes, 2014), and IEEE 802.15.4e (De Guglielmo et al.). Thus, experimental studies to analyze the performance of IWSN in real industrial environments can generate valuable information for the development of new techniques and protocols for IWSN. Fig. 3 shows the usual standards used to implement WSN. The ZigBee standard is not equipped to deal with multipath and interference problems in a satisfactory manner, since it does not implement any co-existence mechanism, and is based on the MAC protocol of IEEE 802.15.4 standard, which uses Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) with single-channel communication. Thus, ZigBee is not recommended to implement IWSN (Song et al., 2008, Akerberg et al., 2011). Due to the limitations of MAC protocol defined by IEEE 802.15.4 standard, new standards with a focus on industrial applications were proposed, such as WirelessHART, ISA100.11a, and WIA-PA. They use the physical layer of IEEE 802.15.4, but define different protocols for MAC layer that are based on Time Division Multiple Access (TDMA), channel hopping, or a combination of both mechanisms. Even defining mechanisms to deal with unreliability, these new protocols can face some problems. For example, when using channel hopping, the nodes usually switch to a new channel before each transmission. However, if a proper management of the blacklist is not made, the network performance can be significantly degraded (Grsu et al., 2016). Download : Download high-res image (216KB) Download : Download full-size image Fig. 3. Standardization of low-power and resource-constrained wireless technologies. To overcome the limitations of the IEEE 802.15.4 standard, IEEE created in 2008 the 802.15 Task Group 4e (TG4e) (Association, 2017) for redesigning the existing 802.15.4 Medium Access Control (MAC) protocols. The goal was to define a low-power multi-hop MAC protocol, capable of addressing the emerging needs of industrial applications. This improvement resulted in the IEEE 802.15.4e MAC standard document (Association, 2017), released in 2012. This standard uses many ideas from WirelessHART and ISA-100.11.a standards, including slotted access, shared and dedicated slots, multi-channel communication, and frequency hopping. Specifically, IEEE 802.15.4e extends the previous IEEE 802.15.4 standard by introducing five new MAC behavior modes, designed to support specific application domains (De Guglielmo et al.). Among the five modes, only Time-Slotted Channel Hopping (TSCH), Deterministic and Synchronous Multi-Channel Extension (DSME), and Low Latency Deterministic Network (LLDN) modes have been explored in the literature, until now (De Guglielmo et al.). Besides the aforementioned standards, that focus mainly on the MAC layer, other standardization efforts have been done with focus on other aspects of the network. Internet Engineering Task Force (IETF) has defined many protocols to integrate smart objects into the Internet, leading to the concept of Internet of Things (IoT). Some of the most important are IPv6 over Low power Wireless Personal Area Network (6LoWPAN) (Montenegro et al., 2010), Routing Protocol for Low power and Lossy networks (RPL) (Ancillotti et al., 2013) and Constrained Application Protocol (CoAP) (Al-Nidawi et al., 2015), that enables web applications on smart objects, and are depicted in Fig. 3. The concept of smart devices is closely linked to IoT, and Industrial IoT (IIoT) is the application of these technologies in industrial scenarios, such as in smart buildings, smart factories, and smart grids (Xu et al., 2014). It expands the traditional automation systems and industrial informatics systems into a much broader context (Yan et al., 2014). This survey has a focus on the lower layers of the WSN, however IoT topics is explored briefly in this survey. The literature presents a discussion about the use of a layered structure or a more flexible design, called cross-layer design (Karl and Willig, 2005). In Hill and Culler (2002), the authors discuss examples in which cross-layer optimization is particularly useful in WSN. However, other authors (Kawadia and Kumar, 2005) argue that imprudent use of cross-layer designs can lead to feedback loops, endangering both functionality and performance of the entire system. Clearly, these concerns should be considered, and it is necessary to pay attention in order to avoid such unexpected feedback loops. Indeed, in general all WSN are implemented using some structured design, with physical, MAC and link layer protocols. That is why the characteristics of the layers and their respective main protocols are described in this survey. There is a number of papers that describe specific layers and their different protocols for IWSN, such as MAC layer (Bachir et al., 2010, Huang et al., 2013, Kabara and Calle, 2012, Khanafer et al., 2014, Suriyachai et al., 2012, Teng and Kim, 2010, Zhao et al., 2012), network layer (Routing) (Al-Karaki and Kamal, 2004, Pantazis et al., 2013, Ehsan and Hamdaoui, 2012, Tunca et al., 2014, Goyal and Tripathy, 2012, Patil and Biradar, 2012, Hao et al., 2012, Zanjireh and Larijani, 2015), and a few papers that focus on Transport Layer (Rathnayaka and Potdar, 2013, Obaidat and Misra, 2015). The physical layer is the same for all the standards usually used to implement IWSN (defined in the IEEE 802.15.4 standard). The different standards define different MAC protocols, and some of them define protocols for the network and application layers. In this survey, the usual role of the five layers is discussed in Section 2, giving more focus on network, MAC and physical layers aspects. Some surveys for IWSN are available in literature, and an exhaustive list can be found in (Gungor and Hancke, 2009, Kumar et al., 2014, Wang and Jiang,, Bal, 2014, Zand et al., 2012, Christin et al., 2010, Baronti et al., 2007). In Gungor and Hancke (2009), the authors discuss the challenges of IWSN, radio technologies, and gives a brief overview of the standards. In Kumar et al. (2014), the IWSN standards are discussed, including the functions of Transport, Routing and MAC layers. The paper in Wang and Jiang has a focus on the most popular IWSN standards: ZigBee, WirelessHART, WIA-PA, and ISA100.11a. Their technical features, plus some security aspects are discussed. In Bal (2014), the author summarizes the literature and application examples of IWSN. The paper in Zand et al. (2012) provides an overview of the technologies in IWSN, the requirements of process automation and problems from the PHY layer. In Christin et al. (2010), the authors address QoS and Security aspects of industrial automation, and in Baronti et al. (2007), energy efficiency, networking, data management and security are mentioned, but not specifically focused in industrial environments. The objective of this survey is to provide a contemporary look at the current state of the art in IWSN, and discuss the still-open research issues. The main wireless standards used to implement IWSN, the communication layers, and the characteristics of wireless channels in industrial environments are discussed. In addition, this paper provides an insight on the various wireless motes and platforms available in the market, a discussion about Operating Systems (OS) for low-end devices, and about the network simulators that implement models for WSN. At the end of this survey, a systematic mapping is described, in order to provide an overview of the researches performed on the IWSN topic, which can help the researchers to identify important gaps in the existing approaches, as well as promising research directions. To the best of our knowledge, there is currently no systematic study providing a broad panorama about what has been investigated so far and what are the open issues about this subject. In comparison to the cited survey articles, the main contributions of the present survey are: • It provides a view on the WSN domain from an industrial perspective, and discusses the standards adapted to this environment; • It reviews the important aspects of the wireless channel in industrial environments, regarding path loss, multipath fading, shadowing, and interference problems; • It provides a detailed analyses on the two main layers that impact the reliability (PHY and MAC layers), and their protocols; • It presents the different motes commercially available, and for research purposes; • Reviews the OS and simulators designed for low-power wireless devices, and discusses a model adapted to simulate industrial environments; • It performs a systematic mapping that provides a background of IWSN in order to appropriately position new research activities, and to suggest areas for further investigation. The remainder of this survey is organized as follows. Section 2 presents the layers and protocols of a WSN, and the solutions that can be used to mitigate the communication problems in such environments. Section 3 introduces the standards used to implement IWSN, and their characteristics. The use of multiple channels and link quality estimation for WSN is discussed in Section 4. In Section 5, the platforms, operating systems, and simulators are discussed, giving special attention to the simulation of WSN in industrial environments. Section 6 describes a systematic mapping of the relevant papers on IWSN, and Section 7 discusses the main challenges of IWSN, and possible open issues. Finally, this survey is concluded in Section 8. 2. IWSN layers and protocols Using a top-down approach, this section discusses the layers and their main protocols that can be used to implement IWSN. The list is not intended to be exhaustive, but illustrative, since there are several papers that have already somehow discussed the most used protocols for WSN. The section begins with the application layer, and then go down to transport, network, MAC and physical layers, with a special attention to network, MAC and physical layers, discussing protocols suitable for IWSN, and to the characteristics of the wireless channels in industrial environments. 2.1. Application layer The application layer provides the designer with a high-level programming model for describing the system behavior. Industrial automation applications provide control, conservation, efficiency, and safety. They extend existing manufacturing and process control systems reliably, improve asset management by continuous monitoring of critical equipment, reduce energy costs through optimized manufacturing processes, and help to identify inefficient operation or poorly performing equipment (Sohraby et al., 2007). After solving synchronization, storage and complex channel requirements at lower layers, the communication at the application layer is reduced down to a basic message-passing and memory access primitives. This canonical set of primitives can then be further implemented on a given target communication architecture by the following layers of the communication stack (Gajski et al., 2009). Based on the specific requirements, IWSN applications can be classified into three groups (Erdelj et al., 2013): • Environmental sensing: covers the problems of air, water, material pollution, fire, flood or landslide monitoring, and hazardous environments; • Condition monitoring: covers the problems of structure and human condition monitoring (buildings, constructions, machine condition, and healthcare applications); • Process automation: covers information regarding the resources for the production and service provision, besides production performance monitoring, evaluation and improvements. In the application layer, one must define the reliability and latency requirements in order to correctly choose and configure the lower layer protocols to satisfy those defined by the application. Concerns such as the impact of the propagation environment, operation lifetime, heterogeneity of data collected, autonomous operation, maintainability, reliability, and security, are found usually in the other layers, and they are discussed in the next sections. The application deals indirectly with these problems. 2.2. Transport layer The transport layer sits on top of the network layer, and together, they are responsible for transmitting messages between communication endpoints over the network of logical links and transducers. The goals of the transport protocols include congestion and flow control, fair allocation of bandwidth, reliability, packet-loss recovery, energy efficiency, and heterogeneous application support. There are several transport protocols in literature, and it is difficult to compare the performance of them, since each one was tested in different simulation environments, without a standard set of simulation/experimental settings. Hence, there is a number of classifications for the protocols. In Obaidat and Misra (2015), for example, the authors classify the transport protocols into three categories: Congestion Control, Reliability, and Hybrid. For the first category, some examples are CCF, CODA, and SIPHON; in the second category, some examples are GARUDA, PSFQ, and Tiny TCP/IP. For the last category, there are ART, ESRT and STCP protocols as examples. In Rathnayaka and Potdar (2013), the authors classify the protocols into three classes, in which the first class supports both congestion control and reliability. The protocols in this class are ART, CRRT, and . The second class corresponds to the protocols that support only reliability, and comprehends DTC, GARUDA, and RMST. The last class supports only congestion control, and includes ARC, CCF, CODA, and Fusion. It is known that Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are inappropriate for WSN due to many constraints in terms of throughput and energy efficiency (Wang et al., 2005). UDP does not offer reliability, flow and congestion controls, and TCP reduces the transmission rate when congestion occurs. In general, the most common technique in congestion detection is the use of buffer occupancy. Depending on the topology, the network might have to perform data buffering in intermediate transducers. In order to reduce the required sizes of these buffers, the transport layer splits large messages into smaller packets. Packets are transferred one at a time from station to station, such that intermediate stations only have to buffer one packet, rather than the whole message, at any time (Gajski et al., 2009). If the application requires synchronous data transfers and if there are buffers in the path between endpoints, the transport layer will have to perform additional end-to-end synchronization, by exchanging acknowledge messages at the end of each message. Reliability in the context of transport protocols refers to the successful delivery of each segment that the sources generate to the ultimate destination. Some protocols detect the congestion based on the reliability parameters. The use of factors such as time to recovering or the loss or successful reception of packets as parameters, is not always feasible, since a transmission failure may occur due to other factors different from congestion (e.g. problems in the channel quality). In such cases, the false detection of congestion may force a rate reduction, which influences negatively the network performance (Rathnayaka and Potdar, 2013). Some examples of transport layer protocols that are used in IWSN can be found in WirelessHART and ISA100.11a standards. The transport layer of WirelessHART cooperate with the network layer to provide secure and reliable end-to-end communication for network devices. A transport table is used to support end-to-end acknowledged transactions, with automatic retries. It uses a MASTER bit to identify whether the device is a MASTER or a SLAVE, and along with the corresponding sequence number, this table also buffers the payload of the last request (in MASTER mode) or response (in SLAVE mode). Thus, it allows the device to resend the request or response when the retry timer expires (Song et al., 2008). The transport layer of ISA100.11a provides connectionless services, which extends UDP over IPv6 with optional compression, as defined by the IETF 6LoWPAN specification (Nixon,). The extension includes better data integrity checks and additional authentication, and encryption mechanisms. ISA100.11a does not support acknowledged transactions at the transport layer. Due to the strict energy requirements imposed by end-to-end reliability mechanisms, and the lack of a clear proposal for reliable transport in Low power and Lossy Networks (LLN), the use of UDP and retransmission control mechanisms at application layer is an important trade-off between energy cost and reliability, when considering the integration of sensors into the Internet, in IETF CoAP applications (Palattella et al., 2013). 2.3. Network layer The routing algorithms are essentially used to determine good paths. The design of routing protocols for WSN must consider the power and resource limitations of the network nodes, the time-varying quality of the channel, and the possibility for packet losses and delay variations. Most of the routing protocols designed for WSN consider energy efficiency as the main design goal, with the assumption that the QoS requirements are more relaxed (Ehsan and Hamdaoui, 2012). However, in many industrial applications, reducing energy consumption is not prioritized as much as reliability, since critical processes could be compromised by a low reliability and availability of the network communications if IWSNs are unreliable. Under these constraints minimizing energy consumption will be in vain (Yu et al., 2017). The network protocols can be divided into three classes: • First class: is related to data-centric protocols, and in this class, there are Sensor Protocols for Information via Negotiation (SPIN), Cougar, Directed Diffusion, Rumor Routing and Gradient-Based Routing (GBR) protocols; • Second class: is related to hierarchical routing protocols. In this class, there are the Low-Energy Adaptive Clustering Hierarchy (LEACH), Power-Efficient Gathering in Sensor Information Systems (PEGASIS), Threshold sensitive Energy Efficient sensor Network (TEEN) protocols; • Third class: is based on location. In this class, there are as examples Geographical and Energy Aware Routing (GEAR), Geographic Adaptive Fidelity (GAF), Minimum Energy Communication Network (MECN) protocols. Regarding routing protocols for multi-channel networks, although traditional routing protocols do not account for channel diversity (Draves et al., 2004), some were proposed in the literature. There are solutions in which the nodes use a single interface, and each node has a default channel for receiving data. In this case, a node with a packet to transmit has to switch to the channel of the receiver before transmitting data, however sometimes the impact of switching latency might make this idea unfeasible. Other solutions for multi-hop networks support multiple interfaces at each node. Some of them use shortest-path routes, which may not be suitable for multi-channel networks (Draves et al., 2004) because the shortest-path algorithm might select a path without ensuring that the hops are on different channels. Although it is possible implementing multi-channel protocols in network layer, it depends on the architecture of the network. Multi-channel approaches are more commonly found in MAC layer. Concerning the network layer of WirelessHART, it is based on a mesh network with redundant routes. This feature, which is not found in ZigBee, for example, increases the reliability, and fault tolerance (Delgado Gomes et al., 2013, Song et al., 2008). A network administrator defines the routes at the network manager, and this centralized unit is also responsible for setting the frequency hopping sequence, and the time scheduling among all nodes of the network, ensuring the correct operation of the TDMA mechanism. Although the use of redundant routes is not supported by the network protocol of ZigBee standard, protocols that use redundant routes can also be implemented in radios that are fully compliant with IEEE 802.15.4. WirelessHART uses four kinds of routing methods to ensure reliable communication: Graph, Source, Superframe, and Proxy Routing. In Graph Routing, the Network Manager creates a table that establishes connections to the devices, but the metric used to decide the neighborhood of the nodes is not specified in the standard (Silva et al.,, Han et al., 2011). In Source Routing, the Network Manager puts into the packet all the required information for routing, but this method is used only for network diagnosis, because if a node fails, the packet will be lost. Superframe Routing is similar to Graph Routing, however the links can only use established superframes, which allows isolating the traffic, but limits the amount of available links. The Proxy Routing is a Graph Routing used by devices when they are put into the network (Silva et al.). While the devices do not receive the security keys from the Network Manager, the Proxy Routing will be used. In Xia et al. (2017), the authors focus on routing in mixed-criticality industrial systems, and considers both Source Routing and Graph Routing. When the system is in low-criticality mode, Source Routing considers the schedulability of each flow, but when errors or exceptions occur, the system switches to high-criticality mode, and network routing turns to Graph Routing to guarantee that important flows can be scheduled. This approach intends to improve high-critical flows schedulability and analyze the schedulability of system. In Quang and Kim (2012), the authors proposed a two-hop neighbor information-based gradient routing on IWSNs. According to their simulation results, high deadline delivery success ratio can be achieved. Other work (Quang and Kim, 2014) presented a cluster-based throughput-aware routing protocol for IWSNs to decrease latency. In this protocol, the synchronization of the whole network is not required, making it suitable for a large-scale network, but extra-equipped cluster heads are needed, increasing the cost of deployment. All these protocols aim for real-time performance in IWSNs, but high reliability is not their main focus. In order to work in mission-critical WSNs, and provide reliable and deadline-constrained communication, it has been shown that flooding for routing might be one feasible alternative (Yu et al., 2017, Soyturk and Altilar, 2008). Different from traditional routing protocols, a flooding-based routing allows multipath diversity, and due to the broadcast nature of wireless medium, ACK packets can be avoided to shorten the transmission latency, and all adjacent nodes of a transmitting node may overhear the packets, so packet forwarding can be more flexible. In Yu et al. (2017), an enhanced version of the flooding-based routing protocol (REALFLOW) is presented to fulfill the strict requirements of mission-critical industrial applications. The drawback of this protocol is that it only supports one sink, and longer measurements in different industrial environments need to be performed to confirm the performance of this approach. Despite the advantages of flooding method, it may produce excessive amounts of redundant traffic, and unnecessary packet forwarding may occur. Several researches on flooding-based routing have been done, but most of them can only support uplink transmission from a node to a sink, which is a strong limitation when implementing IWSN. The network layer in ISA100.11a utilizes 6LoWPAN, and the compatibility with IPv6 allows the devices to connect to the Internet (Kumar et al., 2014). In its network, it is possible for server/client pairs to generate IPv6 packets, which are forwarded through 6LoWPAN edge routers to 6LoWPAN-enabled devices. This router performs the adaptation from IPv6 format to a 6LoWPAN format that can be understood by the devices. The ISA100.11a mesh forwards the IP-based packets to the destination according to routing information configured in the Data Link Layer (DLL) header. The IPv6 packets fragmentation and reassembling are performed in the 6LoWPAN adaptation layer (Nixon). In order to design a routing solution for IP-based (IPv6) LLN, IETF Routing Over Low power and Lossy networks (ROLL) Working Group1 was formed. After evaluating OSPF, IS-IS, AODV, and OLSR protocols, and finding that none of them satisfied the routing requirements for LLN, the group specified the RPL.2 The RPL in based on the IPv6 routing architectural framework, as it is suitable for time varying link loss characteristics, and have low CPU and memory requirements (Tripathi et al., 2010). The authors in Ko et al. (2011) describe how 6LoWPAN and RPL implementations from TinyOS and Contiki operating systems were used together in the same network, even though the two implementations were developed independent of each other. TinyOS and Contiki are described in Section 5.1. The objective of RPL is to build a network topology on top of an LLN that includes multiple partially overlapping link-layer broadcast domains. RPL builds multiple Destination-Oriented Directed Acyclic Graphs (DODAG), each one rooted at a different sink, which are tree-based network topologies where all the links are oriented in such a way that no cycles exist (Ancillotti et al., 2013). Each RPL node can be part of at most one DODAG. This implies that DODAGs are not overlapping, and their union, called a DAG, is a partition covering the entire network topology. In addition, the protocol introduces the concept of a RPL instance, in which DODAGs within the same instance share the same routing metrics and constraints, and multiple RPL instances can run independent of each other within a single network topology. This enables traffic prioritization through the differentiation of traffic forwarding techniques. When building the network topology, each router identifies a stable set of parents on a path towards the DODAG root, and associates itself to a preferred parent, based on an Objective Function (OF) (Gaddour and Koubâa, 2012). The OF defines how RPL nodes translate one or more metrics into ranks, and how to select and optimize routes in a DODAG. It is responsible for rank computation based on specific routing metrics (e.g. delay, link quality, connectivity etc.), and for specifying routing constraints and optimization objectives. The design of efficient OFs is still an open research issue. There is a draft3 that proposed the use of Expected Transmission Count (ETX) as the path selection criteria in RPL routing. The metric ETX is discussed in more details in Section 4.2. Other important routing protocol for data collection is the Collection Tree Protocol (CTP) (Colesanti and Santini). It computes any-cast routes to a single or a small number of designated sinks in a WSN. While the CTP specification (Fonseca et al.) describes protocol packet formats and interoperability requirements, several aspects are left open for specific implementations, such as the timings for routing and forwarding packets. The CTP uses routing messages (beacons) for tree construction and maintenance, and data messages to report application data to the sink. Its standard implementation consists of three main logical software components: Routing Engine (RE), Forwarding Engine (FE), and Link Estimator (LE). The RE sends and receives beacons, to create and update the routing table. This engine is instantiated in each node, and the routing table is filled using the information extracted from the beacons. Besides the identification of the nodes and their neighbors, the table has a metric (ETX) indicating the quality of the connection to a node that might be a potential parent. The FE is in charge of forwarding data packets which may either come from the application layer of the same node or from neighboring nodes (Colesanti and Santini). In addition, it is responsible for detecting and repairing routing loops as well as suppressing duplicate packets. The LE determines the inbound and outbound quality of 1-hop communication links. There is an implementation of CTP for the Castalia Simulator,4 and the current distribution of TinyOS (2.1.2) also includes an implementation of this protocol. Castalia simulator is better described in Section 5.2. 2.4. MAC Layer MAC protocols play an important role in ensuring an effective WSN data communication service. Although many MAC protocols have been developed for wireless networks, many of them are not suitable for WSN because they were not designed with energy conservation as main concern (Zhao et al., 2012). Nevertheless, energy efficiency cannot be the only design concern. Traditionally, issues such as delay, throughput, robustness, scalability, stability, and fairness have dominated the design of MAC protocols (Sohraby et al., 2007). There is a number of classifications of MAC protocols for WSN in the literature. There are classifications according to contention- and schedule-based protocols, or random access, slotted access, frame-based, and hybrid protocols. In this paper, the classification of MAC protocols are into contention-based, contention-free (scheduled-based) and hybrid protocols. In contention-based protocols, the devices access the shared channel in asynchronous manner, and they compete for it whenever there are packets in their buffers to be sent. Their drawback is energy inefficiency due to idle listening, collisions, overheading, and control packet overhead (Durresi, 2005), although they provide good scalability required by WSN to support the node changes. The contention-free protocols are based on scheduling, and their advantages include the absence of collision and few control-packet overheads required to maintain the synchronization among the nodes. Their disadvantage occurs when new nodes are added or removed. For that, it is required re-establishment of routing and restart of the network, which affect network stability. In addition, fixed time slot in the packet exchange restricts the network's adaptability to traffic variations. When the fixed time slot is long but traffic load is low, energy-efficiency will be reduced. When the fixed time slot is short but traffic load is heavy, the end-to-end delay will be prolonged (Zhao et al., 2012) The hybrid version of MAC protocols might be designed to switch its behavior between contention- and scheduled-based protocols according to the traffic characteristics. In Zheng et al. (2016), the authors propose a novel MAC protocol defined as wireless arbitration (WirArb) which grants each user channel access based on their different priority levels. This protocol supports multiple users and each user is pre-assigned a specific arbitration frequency, which decides the order of channel access, ensuring that the user with the highest priority will immediately gain channel access and we can guarantee a deterministic behavior. The results show that the proposed solution outperforms TDMA-based WSNs in terms of latency, throughput and channel utilization. Additionally, given the potential existence of critical processes in industrial environments, assigning different priority levels to nodes is a suitable strategy in IWSN. Some authors have proposed novel MAC protocols for real-time communication based on the physical layer of the IEEE 802.15.4 standard (Flammini et al., 2009, Bartolomeu et al., 2017, Franchino and Buttazzo, 2017, Correia et al., 2015). Other works have evaluated the performance of the protocols defined in the standards for IWSN (Grsu et al., 2016, Jeong and Lee, 2012, Lee and Jeong, 2012, Alderisi et al., 2015, Juc et al., 2016) or proposed mechanisms to improve the performance of these protocols (Du and Roussos, 2011, Du and Roussos, 2013, Anwar et al., 2016, Patti et al., 2014, Patti and Lo Bello, 2016, Sahoo et al.,, Serizawa et al., 2017, Gomes et al., 2017). Flammini et al. (2009) proposed a MAC protocol based on CSMA/CA and TDMA for networks with star topology. The communication is controlled by a network coordinator using beacon frames. The structure defined for the protocol is similar to the one used in the DSME, which includes a contention access period (using CSMA/CA) for acyclic communication (e.g. network management packets), and a contention-free period, based on TDMA, for periodic communication. One limitation of the protocol is that only two channels are used in the whole network, the Communication Channel (CC), and the Backup Channel (BC). The coordinator defines the channels, and the decision is based on the Received Signal Strength Indicator (RSSI) measurements to identify the channels with the lower level of noise. The coordinator informs to the nodes using the beacon if the CC or the BC channel must be used for data transmission in each cycle. The channels are chosen based on the channel quality estimation given by the measurements of the noise at the coordinator. Multipath problems cannot be assessed through measurements of the noise floor. In addition, the protocol is not capable to deal with spatial variations in the quality of the channels. Bartolomeu et al. (2017) proposed the Wireless Flexible Time Triggered (WFTT) protocol, for networks with strict time constraints. The WFTT is based on the bandjacking technique, in which the communication medium is occupied by a noise generator in a synchronized way, to avoid the interference from neighboring contention-based communication technologies, such as Wi-Fi networks. Only external interference caused by radios that use contention-based MAC protocols (e.g. CSMA/CA) were considered. Interference problems from radios that use contention-free protocols, or other equipment (e.g. microwave ovens) are not avoided by the protocol. The WFTT also uses beacons (the trigger packets), but only one channel is used to transmit the trigger packets, which is a single point of failure. In addition, the protocol is not capable to deal with multipath problems that can affect the quality of the links. All the end-nodes also use the same channel for communication, but the same channel can present different characteristics for different nodes, due to the spatial variations in the quality of the channel, and the diverse spatial allocation of the nodes which leads to different channel qualities. The Wireless Budget Sharing Token (WBuST) protocol is proposed in Franchino and Buttazzo (2017). The WBuST is a hybrid MAC protocol with contention-based communication and contention-free communication. In WBuST, the network is divided into clusters, and each cluster has a coordinator. Different channels are used in different clusters to avoid collisions, and inside a cluster, the communication occurs based on a structure called Communication Window (CW). Subsequent CWs are separated by beacon frames, transmitted periodically by the cluster's coordinator. The communication between different clusters is made through the coordinators, which allows building networks with different topologies (e.g. star or cluster-tree). The main limitation of the MAC protocol proposed in Franchino and Buttazzo (2017) is the absence of a channel diversity mechanism to deal with the problems that can affect the quality of the links over time, such as interference and fading problems. Even different channels are used for different clusters, all communication inside the clusters occurs using only one channel, which is a single point of failure. Correia et al. (2015) proposed the DynMAC protocol, which uses dynamic channel reconfiguration. The MAC protocol is based on TDMA, and the channel to be used by all nodes in the network (the global best channel) is defined by the sink node of the network, using information collected from the nodes of the network, through RSSI samples or the Packet Error Rate (PER) calculated by the nodes. The main limitation of the DynMAC protocol is the use of only one channel in all network. The evaluation of the protocol was made using a simplistic simulation model (unit disk graph radio model), and with a short distance between nodes. Besides, the experiments were not performed in a realistic environment. This protocol could work well in a scenario where external interference are the only source of link quality disturbance. However, in industrial environments, fading and shadowing also need to be considered, as well as the link asymmetry, and the spatial and temporal variations that can occur in the link quality in such environments, as can be seen in experiments described in Agrawal et al. (2014), Gomes et al., 2017b, Tanghe et al. (2008). 2.5. Physical layer A prerequisite to deploy WSN for monitoring and control in the process industries is the knowledge of the propagation characteristics of the radio channel, which helps to better characterize the variations in the transmitter signals due to the propagation environment. In industry, variability in the characteristics of the channels may be observed due to the multipath profile of the environment. Multipath problems are caused by reflection, diffraction, and scattering of electromagnetic fields. Besides that, multipath and shadowing are caused by large and small-scale fading due to the presence of many objects (usually made with metallic materials), and interference occurs, possibly caused by other wireless networks (Tanghe et al., 2008). The random movements of people or objects such as robots and trucks may cause time-varying effects in the wireless channel. If the aforementioned propagation effects are not taken into account, they can significantly degrade the performance of WSN in industry. Indoor radio propagation channels have been extensively studied, and to justify the modeling, many measurement campaigns have been conducted in different buildings (Olofsson et al., 2016). The intention is to characterize the radio channel properties and to build statistical models that can be used for system design. Previous investigations show that the channel gains in indoor environments can often be well described by Log-normal, Rayleigh, Rice, Nakagami models (Hashemi et al., 1994), but the best distribution is dependent on the environment. 2.5.1. Wireless channel models In industrial environments, there is a high degree of attenuation at large and small scale. Large-scale fading is the result of signal attenuation due to signal propagation over large distances and diffraction around large objects in the propagation path. The parameter that characterizes the large-scale fading is the path loss. Path loss is caused by the attenuation of the signal along the propagation path and is expressed as the ratio between the transmitted and received power (Cheffena, 2016). Eq. (1), called Log-Distance Path Loss, shows the path loss in for a distance d between transmitter and receiver. (1) In this log-distance path loss model, the average received power decreases logarithmically with distance. The parameter n represents the path loss exponent, which may vary depending on the environment. The path loss in the distance d depends on n and on the path loss at the reference distance . can be determined by the equation . is the wavelength of the carrier. There is a variation in the power of received signal, depending on where the measurement is made. To capture this variation, a random variable of Gaussian distribution in dB with zero mean and standard deviation is added to Eq. (2), which is called Log-normal Shadowing. (2) Like n, is also dependent on the environment. In Tanghe et al. (2008), experiments were conducted to determine both n and log-normal shadowing in industrial environments in the frequencies 900, 2400 and 5200 MHz. Besides path loss, one should also examine the small-scale fading in industrial environments. Small-scale fades are related to the rapid changes in signal strength over a small area or time interval due to multipath. In Tanghe et al. (2008), studies have been conducted about the temporal variation in the level of energy in the channels. This variation is linked especially to the movement of obstacles around transmitter and receiver, and is due to the changes of the multipath profile over time. The results of the experiments presented in Tanghe et al. (2008) validated the use of Rice distribution as a model for the temporal attenuation. This distribution describes the attenuation on a small scale when there is a stationary dominant signal and random components overlap to this main component (Rappaport, 2001). Studies were done to determine K factor of Rice in the related scenarios. The distribution of K values obtained in all the measurements are correspondent to a Log-normal distribution, with a mean value of 12 dB and standard deviation of 5.4 dB. Rice factor is obtained according to Eq. (3), and the probability density function of Rice distribution is shown in Eq. (4). (3) (4) represents the part that does not vary along the time, relative to the power of the stationary component, and is the variable part due to movements which change the multipath components patterns. In the industrial environments studied in Tanghe et al. (2008), there was a high value of K if compared to that found in office environments. This can be explained by the open nature of the industrial buildings, and the large number of reflective materials. Thus, there are many invariant rays on the environment and only a small part of the multipath profile is affected by moving objects. Although Rice distribution has been validated in Tanghe et al. (2008), measurement performed in Sexton et al. (2005) shows different distributions for various locations of indoor industrial environment, in which most of them presented Nakagami-m characteristics while some presented Log-normal and Rayleigh characteristics. In Olofsson et al. (2016), through extensive measurements performed at three different factory buildings, the fading characteristics for mobile transceivers behaved like Rayleigh or close to Rayleigh distribution, but for fixed transceivers, the use of a single fading distribution is not enough to characterize the different environments. It is clear that a single distribution cannot be used to analyze the received signal power. Thus, more measurements in different industrial environments are needed to model properly the envelope distribution of the received signal, especially when the network is meant to be deployed for a long time duration. In Hashemi (1993), despite the movement of people and equipment in the environment, over a short interval of time the channel can be regarded as wide-sense stationary or quasi stationary. In a measurement campaign in Gomes et al. (2015) performed by the authors of this survey, in which part of the industry is depicted in Fig. 1, it is observed that the properties of a link could change dramatically over long periods because of motion in the environment. Fig. 4 shows abrupt changes in the link characteristics during 30 min using one link. Fig. 5 expands the same experiment to 50 h with three different links. In the experiments, a star network was settled connecting three nodes, which are monitoring three motors simultaneously, and the three nodes communicate with the same sink node, using the same channel. Some of the observed changes are due to movements of different objects around the nodes in the measurement site. Download : Download high-res image (125KB) Download : Download full-size image Fig. 4. RSS measurements (in dBm) for 30 min with Link 1. Download : Download high-res image (275KB) Download : Download full-size image Fig. 5. Experiment with three links during 50 h. 2.5.2. Root Mean Square delay spread profile and coherence bandwidth Some studies were carried out to verify the Root Mean Square (RMS) delay spread and the maximum excess delay spread in industrial environments. The authors in Stenumgaard et al. (2012), (2013) observed the characteristics of three types of industrial environments: very reflective, absorptive, and environments that fit between reflective and absorptive. The results showed that reflective environments present much more multipath components and present greater RMS delay spread in all the channels studied. In 2.4 GHz frequency, for example, the mean excess delay was 86 ns in a reflective environment, and 42 ns in an absorptive environment. The RMS delay spread was 294.19 ns and 28.9 ns, respectively. The coherence bandwidth of a channel is the frequency range ( ) at which a channel is correlated. Two signals transmitted in frequencies separated more than are affected differently by the channel (Proakis, 1995). The coherence bandwidth can be defined as (Varela and Sanchez, 2001), in which is a factor that can vary according to the power delay profile; when the correlation between frequencies is greater than 90%, can be equal to 50, or equal to 5 when the correlation between frequencies is greater than 50% (MacLeod et al., 2005). The variable is the RMS delay spread in seconds, therefore considering , and for an industrial environment (Stenumgaard et al., 2013), . While the standard specifies 5 MHz channels, only approximately 2 MHz of the channel is consumed with the occupied bandwidth, so for this scenario, the channels are uncorrelated in frequency. For outdoor environments, the RMS delay spread is higher compared to that found in indoor industrial environments. For mobile radio channels, the delay is in the order of microseconds, and indoors the delays are in the order of nanoseconds (Rappaport, 2001). As the radios used in WSN have a relatively low symbol rate, intersymbol interference may not be a problem for these indoor networks. For example, the IEEE 802.15.4 standard has a symbol rate of 62.5 kbaud in 2.4 GHz band, which represents a symbol period of 16 μs. Fig. 6 shows RSS values obtained in other experiment performed by the authors of this survey inside an industrial environment with transmitter and received nodes, 30 m away, without line of sight and several obstructions and metal objects (Gomes et al., 2017a). Download : Download high-res image (294KB) Download : Download full-size image Fig. 6. RSS measurements (in dBm) in channel 11 and channel 19. When the nodes were tuned to channel 11, the Packet Reception Rate (PRR) was around 91%, and when the nodes were tuned to channel 19, the PRR was around 51%. Therefore, even without considering interference, changing the channel may improve the quality of the communication due to the different characteristics of the channels at the same time. 2.5.3. Noise and electromagnetic interference As discussed in Section 1, due to the increasing number of applications using wireless technologies, the spectrum available for communication tends to become more congested, increasing interference, and reducing the QoS of networks that coexists in the same environment. Thereat, the static spectrum allocation approaches tend not to work satisfactorily in such a congested channel. Mechanisms allowing smarter use of the spectrum should be developed to mitigate the problems related to the interference of coexisting networks. Some studies were carried out to identify possible sources of interference in different environments. In Chilo et al. (2009), the authors conducted a study on the intensity of the electric field, and the Amplitude Probability Distribution (APD) of noise in a paper industry. The APD allows analyzing the percentage of time an impulse signal exceeds a certain threshold. The results show that the most common equipment that can cause interference in 2.4 GHz band are microwave ovens, industrial heaters, radiofrequency lighting systems and welding equipment. However, these devices are not always present in the industry. Other sources of interference, usually found in industrial environments, are electric motors, frequency inverters, and wireless communication equipment, such as cordless phones and wireless local area network equipment. Some sources of interference, especially those related to industrial equipment, such as motors and frequency inverters, are present in the range of a few hundred MHz, which may disturb communication in proprietary systems that use this frequency range, but do not interfere with systems that use the 2.4 GHz ISM band (Stenumgaard et al., 2013, Stenumgaard et al., 2012). In Angskog et al. (2010), the authors verified the frequency bands affected by a set of sources of interference. The results showed that combustion engines and welding equipment cause interference only below 1 GHz. In Delgado Gomes et al. (2012), an experimental study was carried out to verify the correlation between packet loss rate and mean power in the IEEE 802.15.4 radio channel subject to interference from an IEEE 802.11 network and a microwave oven. The results showed that these sources of interference significantly increase the energy level in the channels, having a direct influence on the communication performance of the radios. In some scenarios, the packet loss rate of IEEE 802.15.4 radios has reached 90% when subjected to interference of an IEEE 802.11 network. When subjected to microwave oven interference, the worst case packet loss rate was around 50% when the IEEE 802.15.4 radios were operating on channels 21 and 23. A certain correlation was observed between the mean power level in the channel and the packet loss rate. However, the relationship between mean power and packet loss rate is different for each type of interference source. In this way, more elaborated metrics needs to be developed to accurately estimate the channel quality. In Lima-Filho et al. (2012), experiments were performed to investigate the impact of an IEEE 802.11 network and a microwave oven on the performance of a WSN for monitoring of motors in an industrial environment. Similar results to those described in Delgado Gomes et al. (2012) were observed, with the packet loss rate reaching about 90% when the WSN was subject to interference from the IEEE 802.11 network. In Guo et al. (2012), experiments are described to verify the influence of the distance between transmitter and receiver, and between sensor nodes and sources of interference (Bluetooth, IEEE 802.11 and microwave oven) in a building environment. A packet loss rate of up to 25% was observed due to the interferences of the IEEE 802.11 network and microwave oven, for the scenarios under consideration. The interference from the Bluetooth radios was very small. This is due to the frequency hopping mechanism defined by the IEEE 802.15.1 standard, which uses 79 channels of 1 MHz over the 2.4 GHz band. 3. Standards used in IWSN Many communication technologies for low-power wireless networking were developed to maintain the completely industrial process running in a reliable and efficient condition. The IEEE 802.15.4 standard is among the most prominent communication technologies for low-power wireless networks. In addition, it has been used as a baseline for other standard communication protocols/models, such as WirelessHART and 6LoWPAN (Tennina et al., 2013). The IEEE 802.15.4 standard is designed for WSN requiring low cost, low power, low data rate (up to some few hundred of kbps), and scalability. If compared to IEEE 802.11 and IEEE 802.15.1, IEEE 802.15.4 is more suitable for the industrial device monitoring system requiring long lifetime nodes powered by battery because of the low power consumption, longer battery life and lower cost (Gungor and Hancke, 2013). However, the IEEE 802.15.4 standard is not suitable for industry requirements (Akerberg et al., 2011) due to the use of CSMA/CA instead of TDMA (Zheng et al., 2016), and the use of a single channel in the whole network. Although several papers have described the standards used in industry (Song et al., 2008, Baronti et al., 2007, Silva et al.,, Tennina et al., 2013, Kim et al., 2008, Petersen and Carlsen, 2011, Rezha and Shin, 2014, Zhong et al., 2010, Lee, 2006, Huang et al., 2009, Du et al., 2015, Misic and Misic, 2008, Kiyumi et al., 2015, Alderisi et al., 2015), it is still important to mention the main characteristics and drawbacks of each one. This section describes the four main standards used in IWSN, and based on the IEEE 802.15.4 PHY layer, besides the amendment IEEE 802.15.4e. 3.1. IEEE 802.15.4 The IEEE 802.15.4 standard has been designed to specify the PHY and MAC sublayers for Low-Rate Wireless Personal Area Networks (LR-WPAN) for the low-cost devices communications with a short range and low power consumption. ZigBee is perhaps the most well-known example of wireless products on the market that utilize the 802.15.4 standard (Gungor and Hancke, 2013). At PHY, the standard defines three frequency bands: 2450 MHz (16 channels), 915 MHz (10 channels), and 868 MHz (1 channel), all using the Direct Sequence Spread Spectrum (DSSS) access mode. The 2450 MHz band employs Offset Quadrature Phase Shift Keying (O-QPSK) for modulation with a data rate of 250 kbps, while the 868 and the 915 MHz bands make use of Binary Phase Shift Keying (BPSK), supporting 20 and 40 kbps, respectively. Experimental studies described in Lee (2006) showed that the actual maximum bit rate in 2450 MHz frequency band is around 153 kbit/s. This reduced value is due to the mechanism used for collision avoidance in the MAC layer (CSMA/CA). The standard defines two types of nodes, Reduced Function Devices (RFD) and Full Function Devices (FFD). FFD implements the full IEEE 802.15.4 protocol stack, and RFD implements a subset of the protocol stack. FFD can be a coordinator, a gateway or a router, and RFD is a simple end device in charge of sensing and actuating tasks. When acting as a network coordinator, a FFD node may send beacons that provide synchronization, communication, and coordination. Beacon and non-beacon modes are discussed below (Bartolomeu et al., 2016). In a ZigBee network, the standard defines three types of topology: star, peer-to-peer, and cluster-tree, as illustrated in Fig. 7. In the star topology, a unique node operates as a Personal Area Network (PAN) coordinator, and is a node to which all sensing information is sent. One disadvantage of star topology is its very limited coverage while addressing a large-scale WSN, leading to scalability problems. Some solutions mitigated this problem by using multihop and multiple channels, which are discussed later in this survey. Download : Download high-res image (135KB) Download : Download full-size image Fig. 7. Topologies used in IEEE 802.15.4 networks. The point-to-point, also called mesh topology, includes a coordinator as well, however the communication paradigm in this topology is decentralized, in which each node can directly communicate with any other node within its range. This improves flexibility but it is more complex to provide. It allows multiple hops to route data from any node to any other node. The cluster-tree topology is a special case of point-to-point network where there is a single routing path between any pair of nodes. There is only one coordinator, which identifies the entire network and one router per cluster. Any of the FFD can act as a router providing synchronization services to other devices and routers (Tennina et al., 2013). The IEEE 802.5.4 MAC layer defines two operating modes: beacon-enabled and non-beacon mode. In beacon-enabled mode, the coordinator sends periodic beacon frames to synchronize the rest of the nodes. Synchronization enables dynamic duty-cycle management, allowing nodes to save their energy by entering in the sleep mode. These energy saving periods enable the extension of the network lifetime, which is one of the most important requirements of WSN, but it affects latency. In addition, in beacon-enabled mode the synchronization allows the dynamic reservation of guaranteed bandwidth, through allocation of Guaranteed Time Slots (GTS) in the superframe contention free period. However, managing the synchronization mechanism throughout the cluster-tree networks is a very challenging task, since the larger the network is, the more collision problems can occur. In beacon-enabled mode, medium access can also be ruled by CSMA/CA, as well as in non-beacon mode, but the former uses the slotted version and the later uses the unslotted one. The time interval between two beacon frames is called the Beacon Interval (BI), or Superframe, and is divided into an active period and an optional inactive period. During the inactive period, nodes can be kept in sleep mode to conserve their energy. The length of the active period is the Superframe Duration (SD) which contains 16 time slots (from 0 to 15) with the same duration (Buratti et al., 2011). The 16 time slots in the superframe are subdivided into smaller slots known as the Backoff Period (BP) (Shafiullah Khanet al, 2013). The IEEE 802.15.4 MAC layer achieves duty-cycle operations by setting two system parameters, (BO) and (SO) to achieve low power consumption for ZigBee devices (Huang et al., 2009). The first one specifies the period during which the coordinator can communicate the beacon frames. The second one specifies the duration of the active portion plus the beacon frame (Khanafer et al., 2014, Queiroz et al., 2017). The value of BO is related to the BI, and SO is related to SD, in which (Du et al., 2015). If BO is set to 15, the value of SO is ignored and beacon frames will not be sent except upon request (Khanafer et al., 2014). As depicted in Fig. 8, the active period comprises Contention Access Period (CAP) and Contention Free Period (CFP) (Zhan et al., 2016). During CAP, nodes use the slotted CSMA/CA algorithm to access the channel. During CFP, up to seven GTS can be allocated by the coordinator for each superframe, which allow the node to communicate on the timeslot that is dedicated exclusively to it Du et al. (2015). A node with an assigned GTS has full access to the channel during its GTS. Nodes activity during it should be completed before the start of the next GTS or the end of the CFP (Khanafer et al., 2014). Download : Download high-res image (260KB) Download : Download full-size image Fig. 8. Superframe of IEEE 802.15.4, adapted from Misic and Misic (2008). Performing the analysis about the researches over IEEE 802.15.4 in 2016 and January 2017 using the “IEEE 802.15.4” term in the keyword field, in IEEE Xplore were found 64 papers, in ScienceDirect were found 20, and in ACM Digital were found six documents. From all those documents, around 50% are research papers focused on ZigBee. Some of the topics found are related as follows: • Throughput measurement and performance improvement of IEEE 802.15.4 under interference, including channel utilization scheme; • Techniques of cooperative communication and network coding to mitigate electromagnetic noise, channel coding for energy and temperature monitoring, calculation of optimum transmit power employing cooperative relaying, protocols for cooperative sensing, and implementation of selection cooperation; • Relaying partner, and partner selection algorithms for improving the network lifetime; • ZigBee based sensor networks in cloud technology; • Dynamic multi-channel allocation mechanism; • Security issues like PHY layer attacks and public key steganography; • Determining the main CSMA parameters for adequate performance, accurate and efficient modeling of 802.15.4 unslotted CSMA/CA through event chains computation, including algorithm that adapts the CSMA/CA parameter setting to the time-varying operating conditions, and energy conservation scheme and energy consumption analysis of the unslotted CSMA/CA; • Performance and lifetime study of clusters interconnected in a linear structure; • Available bandwidth as a routing metric in ad-hoc networks; • Technique to reduce the collisions and to prevent simultaneous data transmission; • Performance analysis of IEEE 802.15.4 superframe structure with the inactive period; • Construction of Cluster-Tree networks based on the beacon mode. Interference, techniques of cooperative communication and energy efficiency seem to have been the main concerns regarding this standard recently. 3.2. WirelessHART WirelessHART is a wireless communication standard designed to meet the needs for process automation applications (Gungor and Hancke, 2013). It was the first open standard specifically designed for wireless communication in process measurement and control applications (Song et al., 2008), and was officially presented by HART Communication Foundation in 2007, with the restriction of being compatible to the existing HART devices by adding wireless communication capability to the HART protocol. The WirelessHART specification was approved by the International Electrotechnical Commission (IEC) as a full international standard (IEC 62591) in March 2010. WirelessHART is a secure and TDMA-based wireless mesh networking technology operating in 2.4 GHz ISM radio band. Actually, it uses the Time Synchronized Mesh Protocol (TSMP) (Kumar et al., 2014, Pister and Doherty, 2008), which was developed by Dust Networks for MAC and network layer functions. Before WirelessHART is released, there were some standards for office and manufacturing automation, such as ZigBee IEEE 802.15.4 standard and Bluetooth. However, they could not meet the stringent requirements of industrial applications. ZigBee does not have built-in frequency hopping techniques to mitigate interference and multipath problems, and Bluetooth assumes quasi-static star network, which is not scalable to be used in large process control systems (Song et al., 2008). At PHY layer, WirelessHART adopts the IEEE 802.15.4-2006 standard, and has its own time-synchronized MAC layer that uses frequency hopping, and channel blacklisting. The network layer supports self-organizing and self-healing mesh networking techniques (Grimaldi et al., 2016). In addition, it supports both direct connection between device and gateway (star topology) and connections over multiple hops (mesh topology). Each network device must be able to function as source, sink and router (Kim et al., 2008). WirelessHART networks are centralized, with strict timing requirements managed by a central network manager that is used to configure the routing and schedule information. Fig. 9 shows an example of a WirelessHART network. Download : Download high-res image (280KB) Download : Download full-size image Fig. 9. Example of WirelessHART network. Following are the main devices and components of a WirelessHART network (Foundation, 2007): • Gateway: a network Access Point (AP) that connects the WirelessHART network to a plant automation network, allowing the data to flow between them; • Network Manager: an application that manages the network and its devices. The communication with the devices is command-oriented, and it is responsible for scheduling, device list management, and collecting statistical information about performance, fault detection, and network formation. The logic used by the manager for path construction and link scheduling is not explicitly specified and it is left to the final user (Grimaldi et al., 2016); • Security Manager: an application that is in charge of generating, storing, and managing join, network, and session keys; • Field Devices: sensor and actuator nodes; • Router: in theory, the use of routers is not required, since the field devices are configured automatically with routing mechanisms. However, its use could lead to redundant paths to the Gateway, preventing field devices from being used for message routing, and thereby increasing power consumption; • Handheld: device used to configure and monitor the field devices. As seen in Fig. 10, WirelessHART has a limitation of 15 frequency channels (11–25), in which channel 26 is not used for regulatory issues in some countries. At MAC layer, the communication must be done within a 10 ms (data + acknowledgment) time slot, and sequences of time slots form a superframe. Each transmission between two nodes must occur in a time slot in one of the 15 channels using the unicast method. Each superframe has two kinds of slots: dedicated slot at the beginning of every superframe, and shared slots for the rest of the superframe. During shared slots, the devices must compete with each other to communicate. Download : Download high-res image (208KB) Download : Download full-size image Fig. 10. Superframe structure of WirelessHART, adapted from Silva et al.. After sending the packets, the devices waits for an ACKnowledgement (ACK). If it is not received, they will wait a random period and send the packet again. According to WirelessHART, the MAC sublayer uses TDMA to perform link scheduling during the dedicated slots period, and during shared slots period, the MAC sublayer uses slotted ALOHA. To ensure packet delivery, nodes can use three time slots in each superframe. The first two time slots are used for transmission and retransmission (in case of the first attempt fails) on a predefined route. The third slot is used to transmit the same packet using a different route (Wu et al., 2016). Since each slot uses a different channel, in this scenario each packet can be transmitted up to three times within the same superframe using different parameters (route or channel), so that the link becomes robust to problems that affects specific channels or routes. The application layer is based on HART commands protocol, and these commands are used by the different entities in the network to join, write/read data, etc. For security issues, WirelessHART uses Advanced Encryption Standard (AES) with 128 bits block Ciphers, similar to the ZigBee standard. To handle coexistence and interference efficiently, IWSN standards employ many spectrum management techniques (Akerberg et al., 2011). A Clear Channel Assessment (CCA) is performed before data transmission to ensure that the channel is free to use. In WirelessHART, CCA reports a busy medium if a signal compliant with IEEE 802.15.4 PHY modulation and spreading characteristics is detected. Each transmission uses a different channel, and Fig. 10 depicts frequency hopping mechanisms for four data streams in 200 ms (20 slots). To improve the WirelessHART communication, the HART Communication Protocol and Foundation (HCF) developed a document for best practices (HART Communication). In general, the following rules are established: • Each field device should have at least three neighbors. The third neighbor acts as a backup if one of the two primary paths is unavailable; • The gateway should have at least five neighbors. It works with less nodes, but for better resilience, five is the minimum value; • At least 25% of the network devices should reach the gateway in large networks. Regarding recent researches about WirelessHART, using the three main research databases (IEEE Xplore, ScienceDirect, and ACM Digital), a simple filter with the term set in the keyword field, and considering the year 2016, and the first month of 2017, 22 documents were found in IEEE Xplore, four in ScienceDirect, and one in ACM Digital. The papers focus on performance analysis, data aggregation techniques to guarantee energy-efficient and real-time communication, RF power modulation technique to reduce energy consumption, delay effects on the control system's performance, autonomous diagnostic tool, filtered feedback PID5 control, long network lifetime with Graph Routing, and WirelessHART adaptor for process control applications. Reliable graph routing is well described in Han et al. (2011), in which the authors present efficient algorithms to construct them, and describe the recovery mechanisms in the event of component failures. The main advantage is that, based on these graphs, data link layer communication schedules are generated to achieve end-to-end real-time performance. 3.3. ISA100.11a The International Society of Automation (ISA) initiated a work on a family of standards to implement wireless systems for industrial automation and control applications. The main purpose of ISA-100 committee is to provide a family of standards for industrial wireless networks, and ISA100.11a is the first standard of the family. It was released in 2009, and describes a mesh network designed to provide secure wireless communication to process control. It received the IEC approval as international standard (IEC 62734) in 2011. An ISA100.11a device have one or more of the following tasks (Standard, 2009), as depicted in Fig. 11: • (I/O): the devices can provide or use data through sensors or actuators. They do not have routing capabilities; • : it acts like a proxy, routing the data toward the gateway; • : high level routing, increasing the throughput of the network as long as more sub-networks are created. The communication between them uses the 6LoWPAN. It is also responsible for tunneling; • : a device (router) may enable other devices to join a specific network; • : a device may provide an interface between the field devices and the plant automation network; • : an application that is in charge of the network tasks; • : an application that, in cooperation with the system manager, is responsible for the generation, storage and distribution of the necessary security keys and is also supposed to manage authentication; • : a device (router) responsible to maintain the master time source for the system; • : device used to configure, test, and monitor the field devices. Download : Download high-res image (269KB) Download : Download full-size image Fig. 11. Example of ISA100.11a network. Similar to WirelessHART, PHY layer is based on the IEEE 802.15.4 standard, and is designed to support a maximum of 50-100 devices in the network (Petersen and Carlsen, 2011). ISA100.11a standard uses frequency hopping and channel blacklisting to reduce the interference effects, and applies different methods for frequency hopping called slotted, slow, and hybrid hopping, as depicted in Fig. 12. In slotted hopping, each communication occurs in a different frequency. There is an order to be followed to optimize the coexistence with IEEE 802.11 and WirelessHART standards, but it is possible to choose the channels following a specific sequence (Silva et al.). In slow hopping, the devices change its channels at specific intervals (100–400 ms), and is used by devices that lost synchronization. For coexistence issues, it is recommended to use the channels 15, 20 and 25 in the slow hopping. The hybrid hopping uses both techniques to optimize the sending of alarms and retransmissions. Download : Download high-res image (403KB) Download : Download full-size image Fig. 12. Different frequency hopping profiles of ISA100.11a, adapted from Rezha and Shin (2014). The standard uses 16 channels (11–26), but the channel 26 is optional. At MAC layer, it combines TDMA with CSMA in order to use the advantages of both techniques, and defines routing at this layer. The time slots have 10 ms or 12 ms, and duration can be dedicated or shared. The dedicated slots are used for contention-free communications, and in the shared slots, the media access uses an exponential backoff algorithm, similar to CSMA/CA. The MAC layer is divided into three sublayers: MAC Sublayer, MAC Extension, and Upper Data Link Layer. The first one is a subset of IEEE 802.15.4, the second adds new characteristics related to CSMA/CA, TDMA, and frequency hopping (Silva et al.), and the third one is in charge of routing at MAC layer. Similar to WirelessHART, a security manager exists in ISA100.11a embedded with the system manager and gateway on the same physical device. The security feature is optional in ISA100.11a to provide greater flexibility and improve battery life, and the end-to-end security is performed in the transport layer (Petersen and Carlsen, 2011). In Serizawa et al. (2017), a mechanism called Adaptive Channel Diversity (ACD) is proposed for ISA100.11a networks. In the proposed protocol, the network is divided into groups, and the end-nodes inside the same group share the time-slots allocated to the group. The ACD mechanism use information about the quality of the channels to avoid using channels affected by interference sources. The communication duration is divided into four time segments, where three of them are dedicated to the ACD mechanism, which incurs in a high overhead. The solution described in Serizawa et al. (2017) has the same limitations of the solution described in Du and Roussos (2013); Du and Roussos (2011), since only interference problems are considered. Besides, many time slots are dedicated to the ACD mechanism, which increase the overhead of the protocol and the latency of the network. Using the same filter performed for WirelessHART with the three research databases and the term ISA100.11a set in the keyword field, during the year 2016 and the first month of 2017, in IEEE Xplore were found four documents IEEE Xplore, one in ScienceDirect, and none in ACM Digital. Among those papers, only two focus on specifically ISA100.11a. The first one studies Adaptive Channel Diversity (ACD) method, and the other one evaluates the performance of networks that follow the standard. 3.4. WIA-PA There is a few papers published about the WIA-PA (Wireless Networks for Industrial Automation and Process Automation) standard, if compared to the aforementioned ones. It is the Chinese standard of industrial wireless communication architecture and specification for process automation. It was accepted by IEC in 2008 and was called IEC/PAS 62601. WIA-PA standard adopts IEEE 802.15.4 PHY without modification in order to co-exist with the IEEE 802.15.4-based systems. It is designed for measuring, monitoring and open-loop control of industrial processes (Zhong et al., 2010), which correspond to the classes 3–5 of the industrial process automation applications defined by the ISA100 committe (Standard, 2009). Class 0 is for critical and time-sensitive applications, which requires less than 10 ms latency in a deterministic manner. The standard supports a hierarchical network topology that combines standard mesh topologies with five kinds of devices: host computer, gateway, routing, field and handheld devices. The data link sub-layer protocol based on the IEEE 802.15.4 MAC protocol, with some additional features such as frequency hopping, packet aggregation/disaggregation, and time synchronization. Similar to ZigBee, WIA-PA implements beaconing, superframe structure, and the time slot duration is configurable. WIA-PA uses a hybrid protocol based on CSMA/TDMA, and uses three frequency-hopping mechanisms to increase the reliability and throughput: Adaptive Frequency Switching, Adaptive Frequency Hopping, and Time Slot Hopping (Silva and Guedes, 2014). Performing the same analysis about the researches over WIA-PA in 2016 and January 2017, in IEEE Xplore there were found two papers, and only one of them is focused specifically on WIA-PA. None of the other databases have found results. The only paper found studies a TR0696 WAN management protocol for the standard. 3.5. IEEE 802.15.4.e As mentioned in the previous subsection, one of the main concerns when designing a WSN is the energy efficiency. This is because the devices are battery-powered and the replacement of batteries is difficult or expensive. Besides energy, other requirements must be considered such as scalability, reliability and timeliness, in which the last two are critical issues for industrial and healthcare applications (De Guglielmo et al.). Several studies investigated the performance of IEEE 802.15.4 networks (Khanafer et al., 2014, Baronti et al., 2007, Tennina et al., 2013, Lee, 2006, Buratti et al., 2011, Zhan et al., 2016, Du et al., 2015, Huang et al., 2009, Misic and Misic, 2008, Eady, 2007, Kiyumi et al., 2015), and they highlighted the limitations of the standard, which makes it not suitable for applications that have stringent requirements of latency and reliability in harsh environments. One of the main limitations is that, unlike ISA100.11a and WirelessHART, the IEEE 802.15.4 MAC uses a single channel and does not have a frequency hopping mechanism to mitigate the effects of interference and multipath. To overcome these limitations, the IEEE 802.15.4e standard was developed. WirelessHART, ISA100.11a, and IEEE 802.15.4e standards introduce scheduling-based MAC protocols to provide a guaranteed access or bounded latency, and adopt packet-level frequency hopping to improve the reliability of the wireless links. IEEE 802.15.4e standard defines five MAC protocols (behavior modes), DSME, TSCH, LLDN, AMCA and BLINK. For AMCA and BLINK modes, it provides only a brief description of them, therefore they are not discussed in this paper. In general, the improvements of IEEE 802.15.4e are regarding support to multi-channel communication, more flexible superframe (DSME), and the use of a contention-free channel access mechanism based on TDMA (it decreases collision, and allows minimizing the energy consumption). In the following topics, the details of the three main modes are outlined. 3.5.1. Deterministic and Synchronous Multi-channel Extension (DSME) This mode is intended to support industrial and commercial applications with stringent timeliness and reliability requirements. Similar to IEEE 802.15.4 beacon mode, in DSME the time is divided into CAP and CFP, as depicted in Fig. 13. Slot 0 is used to transmit Enhanced Beacons (EB), and CAP begins after the EB and ends before slot 9. The other seven slots belongs to CFP, and each one in CFP represents a DSME-GTS, used when there is traffic whose latency must be predictable. During the entire CAP, the frames are sent using only one channel and the nodes are required to be on. To obtain more GTSs and save energy in this case, DSME provides a mechanism called CAP Reduction. When it is enabled, only the first superframe of each multi-superframe presents the CAP, while in the other superframes, the CAP is omitted and the CFP has 15 DSME-GTS. Download : Download high-res image (183KB) Download : Download full-size image Fig. 13. Example of a superframe structure for a DSME network. In DSME, the coordinators transmit periodically EB to keep the nodes synchronized and to allow other nodes to join the network. BI is composed of several superframes, which do not have inactive periods, and are divided into 16 equally spaced slots. Inside BI, it is possible to define cycles of repeated superframes called multi-superframes. During CAP, the nodes use a slotted CSMA/CA algorithm to access the channel, and in CFP, the nodes use GTS. The difference from IEEE 802.15.4 standard is that DSME extends the number of GTS time slots and uses multiple channels. In addition, it can accommodate periodic and event-driven traffics by adopting a versatile multi-superframe structure. Beacon scheduling and slot allocation are performed in a distributed manner, without depending on a central device. The links between two nodes can be dedicated, so neighboring nodes can communicate in a point-to-point way. Since each pair of nodes can allocate and deallocate GTS slots, DSME is able to adapt to the variations in the generated traffic and to the changes of the network topology over time. DSME also supports the option of Group ACKnowledgement (GACK) that allows putting together the ACK of multiple data frames into a single ACK frame in order to improve the energy efficiency. Concerning GACK, it is used when the nodes have to send periodic traffic to the coordinator. In this case, the coordinator uses a single DSME-GTS to put together all the ACK from frames received in the previous DSME-GTS in just one frame. This mechanism brings two advantages, energy efficiency and latency reduction, since the retransmissions are done inside the same multi-superframe. During the same GTS, multiple transmissions can be accommodated using different channels. Each superframe inside a multi-superframe has a different ID, and each DSME-GTS has an ID according to its position inside CFP. DSME mode defines two types of channel diversity: frequency hopping, and channel adaptation. Fig. 14 shows two examples of scheduling for the CFP period, using frequency hopping in (a), and channel adaptation in (b). When using the first one, the nodes receive packets in different channels, depending on the channel offset of the node, on the slot ID, on the superframe ID, and on the sequence number of the EB sent by the coordinator. For example, in Fig. 14(a), Node 1 receives a packet using Channel 0 in the first time slot, using Channel 1 in the second time slot, and so on. The nodes that receive packets inside the same superframe need to have different channel offsets, in order to avoid collisions. Download : Download high-res image (158KB) Download : Download full-size image Fig. 14. Channel diversity mechanisms defined for DSME networks. When using the channel adaptation as the channel diversity technique, a pair of nodes communicate using the same channel while the channel quality is good enough in terms of signal-to-noise ratio. In order to use this mechanism, it is necessary to evaluate the quality of the links continuously. Besides the two mechanisms, a novel hybrid approach was developed and simulated in Gomes et al. (2017c), that uses both channel hopping and channel adaptation. The simulated results showed that the hybrid approach outperformed the other two approaches for the scenario studied in the paper. In addition, the experiments showed that the use of channel adaptation is better than channel hopping for the transmission of unicast packets, when the quality of the links is monitored continuously. However, for packets transmitted in broadcast by the coordinator, the use of channel hopping is a good alternative to deal with the spatial variation in the quality of the channels. The time structure in DSME is almost the same as IEEE 802.15.4, including the parameter macMultisyperframeOrder (MO), that determines the duration of multi-superframes, in which . In Table 1, SMS stands for the number of Superframes in a Multi-Superframe, MSBI means the number of Multi-Superframes in a BI, and MSD is Multi-Superframe Duration. Table 1. MAC parameters with multi-superframe. Parameters Value SMS superframes MSBI multi-superframes MSD aBaseSuperframeDuration symbols Each EB has a special field called DSME PAN Descriptor Information Element that contains the information of the superframe structure such as BO, SO and MO, and other options like GACK, CAP Reduction, etc. The SO value influences the duration of time slot, and MO determines the number of DSME-GTS available in each multi-superframe and influences the latency. It also transmits a DSME-Beacon Allocation Notification command during CAP to inform its neighbors about the slot allocation. In the case of beacon collision, the coordinator uses a Deferred Beacon option to reduce the probability of collision. When this option is activated, the coordinator performs a CCA before sending the beacon. To avoid the same EB slot to be assigned to multiple nodes, a DSME-Beacon Collision Notification is sent to the other node to choose a different EB slot. The experiments described in Jeong and Lee (2012) and Lee and Jeong (2012) evaluated the performance of DSME mode in comparison to the beacon-enabled mode of the IEEE 802.15.4. The experiments verified that, in some scenarios, the throughput of the IEEE 802.15.4e DSME network can be 12 times higher than the IEEE 802.15.4 beacon-enabled network, and with a lower energy consumption, due to the use of a TDMA-based medium access. In the experiments, frequency hopping was used but no dynamic management of the blacklist was employed. In Sahoo et al., a novel MAC protocol for networks with start topology, based on DSME mode of the IEEE 802.15.4e, is proposed, with the goal of reducing the discovery time, and to optimize the bandwidth usage. To reduce the discovery time, it was proposed the use of additional beacon transmissions, in different channels. When a node attempts to join the network, a random channel is chosen, and the node waits for a beacon transmission in that channel. However, if the selected channel presents deep fading problems for the link between the new node and the coordinator, the time of access can be very high. This problem was not considered in the solution proposed on the paper. To optimize the bandwidth usage and reduce the delay, group ACK was employed using the beacon frames, and the nodes use the contention access periods to perform retransmissions instead of using dedicated time slots for retransmissions, as defined in the original algorithm of DSME (De Guglielmo et al.). One limitation of the work described in Sahoo et al. is that the channel diversity mechanisms of the DSME were not evaluated, which is a very important aspect to be taken into consideration in industrial applications. Regarding latest researches about DSME, using the same parameters described previously for the aforementioned standards, IEEE Xplore and ScienceDirect databases found one paper, and ACM Digital found none. One paper is regarded a survey of IEEE 802.15.4e, and the other one performs an energy consumption and performance analysis of TSCH and DSME. 3.5.2. Time Slotted Channel Hopping (TSCH) The TSCH mode was developed for applications of process automation, and like DSME, TSCH uses EB, works in star, tree and mesh topologies, and employs frequency hopping mechanism. Different from DSME, which uses a periodic multi-superframe structure, TSCH uses periodic slotframe, dedicated time slots instead of time slot during CFP, and CSMA/CA with shared time slots instead of contention-based channel access (during CAPs). In addition, TSCH does not implement GACK. In TSCH, each node obtains information of synchronization, frequency hopping sequence, time slot and slotframe through EB. The slotframe contains either contention-based or contention-free time slots. The time slots assignment to the devices within the slotframe may initially be communicated through a beacon, but usually the higher network layers configure them when the device joins the network (Alderisi et al., 2015). Fig. 15 shows an example of link schedule, in which there are 4 time slots, 5 channel offsets and 8 transmissions, thanks to the multi-channel approach of TSCH. In the example, there are two for dedicated links (D A and B C) and shared links (C D and E F). Download : Download high-res image (165KB) Download : Download full-size image Fig. 15. Example of TSCH slot frame. Since all devices share common time and channel information, devices may hop over the entire channel space to minimize the negative effects of multipath fading and interference, and do so in a slotted way to avoid collisions, minimizing the need for retransmissions. Through time synchronization and frequency hopping, TSCH enables high reliability while maintaining very low duty cycles, and this guarantees energy efficiency. The hopping sequence is defined by an ID, the sequence length, and an ordered list of channels. A link between communicating devices is identified by a pair time slot/channel offset. Shared links are intentionally assigned to multiple devices for transmission. This can lead to collisions and result in a transmission failure detected by a missing ACK, but a retransmission backoff algorithm (CSMA/CA algorithm) is implemented for shared links, to reduce the probability of repeated collisions. There are differences between IEEE 802.15.4 CSMA/CA, and TSCH CSMA/CA algorithm (De Guglielmo et al.). The first difference is that in TSCH, besides being optional, CCA is not used to prevent collisions, but to avoid transmitting a packet if there is strong external interference. Other difference is regarding the parameter macMaxCSMABackoffs, which is not used in TSCH. The packet is dropped only if it reaches the maximum number of retransmissions (macMaxFrameRetries). Regarding the backoff mechanism, it is activated only after the node has experienced a collision. In TSCH, the backoff unit duration, instead of of IEEE 802.15.4, corresponds to a shared slot. In Grsu et al. (2016), an experiment was performed to analyze the performance of a TSCH network inside an aircraft cabin, with external interference caused by Wi-Fi networks. In the experiments, the PER was equal to 35% when using the 16 available channels, due to the influence of interference on the link. In general, when fewer channels were used, the PER was lower, as the interference level decreases. For example, when using only one channel, the one less affected by the interference sources, the PER was equal to 5%. However, to operate using only one channel per link, an appropriate mechanism is needed to estimate the quality of the channels continuously and to dynamically configure the blacklist, which can generate a remarkable overhead. In Alderisi et al. (2015), a comparison between DSME and TSCH in process automation scenarios is described. Simulations were performed to verify the delay, reliability, and scalability of each mode. The TSCH presented better results for small networks, with up to 30 nodes. For larger networks, with more than 30 nodes, the DSME presented better results. The simulations described in Alderisi et al. (2015) used realistic parameters for the log-normal shadowing, but the effect of fading and the non-stationary characteristics of the wireless channel were not considered. In addition, only the channel hopping mechanism of the DSME were analyzed. In Juc et al. (2016), other comparison between DSME and TSCH is described, in terms of energy consumption and performance. In the scenarios under consideration, the energy consumption of DSME was slightly better than TSCH, as well as the performance. In applications that send less data, the TSCH wastes bandwidth, due to the fixed size of the time slots. In the experiments described in Juc et al. (2016) only channel hopping was considered. The use of adaptive frequency hopping for TSCH networks was proposed in Du and Roussos (2011); Du and Roussos (2013), to avoid using channels affected by interference sources. In this approach, two time slots in each cycle are used to perform readings of RSSI values. Based on these measurements, the blacklist is updated to avoid the channels with a high level of interference. The experiments were conducted considering different sizes for the blacklist. The higher the size of the blacklist, the better the communication performance. This result corroborates the results presented in Grsu et al. (2016). However, this type of behavior only occurs if an adequate monitoring of the quality of the channels is performed, in order to properly configure the blacklist in real-time. One limitation of the approach presented in Du and Roussos (2011); Du and Roussos (2013) is that only interference problems are considered. Other aspects that can affect the quality of the links are not considered, such as shadowing and fading. Besides, the channel quality monitoring is performed by all nodes and using time slots that could be used for communication, which incurs in a high overhead, and increases the latency. Regarding recent researches about TSCH, there are more papers about this mode than DSME. In IEEE Xplore database, 19 papers were found, in ScienceDirect were found two papers, and ACM Digital, four results were found. Some of the topics are related as follows: • Optimal scheduling policy for reliability and energy efficiency considering opportunistic forwarding at MAC and routing layers (Huynh et al., 2017), and energy consumption analysis of TSCH-enabled platforms for the IIoT (Boccadoro et al., 2016); • Decentralized broadcast-based scheduling for dense multi-hop TSCH networks (Municio and Latré, 2016), simple distributed scheduling with collision detection (Muraoka et al., 2016), and scheduling implementations for real WSN applications (Sempere-Paya et al., 2016); • Centralized, model-based beacon scheduling algorithms (De Guglielmo et al., 2016), and scheduling for data collection in multi-hop TSCH networks (Chen et al., 2016); • Autonomous version of 6TiSCH7 to guarantee flow isolation (Theoleyre and Papadopoulos, 2016), real time requirements in IIoT through 6TiSCH (Divya Darshini et al., 2016), and distributed PID-based scheduling for 6TiSCH networks (Domingo-Prieto et al., 2016); • Localized scheduling for end-to-end delay constrained Low Power Lossy networks with 6TiSCH (Hosni et al., 2016); • Packet replication through path diversity (de Armas et al., 2016); • Simulation study about the effect of interference on in-vehicle networks using TSCH link (Tavakoli et al., 2016); • Experimental and performance evaluation of TSCH CSMA-CA algorithm (De Guglielmo et al., 2017); • Analysis of co-located IEEE TSCH networks regarding interference and coexistence (Ben Yaala et al., 2016); The most researched issues regarding TSCH have been related to scheduling policies, energy efficiency, multi-hop networks, 6TiSCH and IIoT. 3.5.3. Low Latency Deterministic Network (LLDN) Few studies have addressed LLDN so far. This mode is intended for applications such as factory automation and robot control, which require very low latency and high determinism. Communication in LLDN mode occurs according to a structure called superframe. Each superframe starts with a beacon packet transmitted in broadcast by the coordinator, and it is followed by up to two timeslots used for management (optional). After that, several dedicated timeslots are defined for transmission of the end nodes. When only one node is associated to a timeslot, it is not necessary to use an address, since the node can be identified by the timeslot ID, which is already known by the coordinator. Therefore, it is possible to transmit smaller packets and reduce network latency. Different from TSCH and DSME, it does not implement EB and there is no multi-channel mechanism. Similar to DSME, it implements GACK, and similar to TSCH, the channel access is performed by dedicated time slots and uses a version of CSMA/CA in shared time slots. The dedicated time slots are accessed using a TDMA approach, and the timeslots are smaller than those used in TSCH and DSME. Differently from TSCH and DSME, LLDN has been designed only for star topologies, in which a number of nodes need periodically to send data to a central sink. Since communication takes place based on TDMA, communication between end nodes and the network coordinator (central node of star topology) is collision-free, so that it is possible to ensure good communication quality. However, communication channel problems related to shadowing, multipath, interference, or asymmetry can degrade network performance. In addition, due to the use of a star topology, it may be difficult to accommodate a network with many nodes. A possible solution to this problem is to use a multi-transceiver coordinator node and divide the network into groups that use a common channel. Strategies for link quality estimation and channel allocation that are discussed in Section 4.2, can be used to improve the QoS of such networks. An implementation of the LLDN described in Anwar et al. (2015) uses IEEE 802.15.4 compliant radios, and is aimed to verify the feasibility of implementing applications that require intervals of up to 10 ms between the reception of two new values of a sensor. In a scenario where the sensor nodes send 2 bytes of payload, it was possible to accommodate eight end nodes, with a maximum delay between the reception of two packets of 9.996 ms. In a scenario where the sensor nodes send 4 bytes of payload, it was possible to accommodate seven end nodes, with a maximum delay of 9.536 ms. One limitation of the analysis performed in Anwar et al. (2015) is that the experiments were performed in a controlled environment, without external interference, and with the nodes positioned very close to each other. Thus, the packet delivery rate was 100% throughout the experiments. In a real industrial environment, it may be practically impossible to achieve a packet delivery rate of 100%, and in this case, latency values may be worse in practice than those shown in the article. Some authors have proposed channel diversity techniques and multi-channel communication for LLDN networks. In Patti et al. (2014), a multi-channel protocol based on LLDN, called MC-LLDN, was proposed. MC-LLDN aims to increase the scalability of LLDN networks through the use of a multi-level topology (tree), data aggregation and communication using multiple channels. In this way, it is possible to accommodate simultaneous transmissions in the network, in different channels. With data aggregation in the routers, less timeslots need to be dedicated for packet forwarding to the coordinator, which causes a large reduction in latency. The limitation of MC-LLDN is that the channels are allocated statically to the subnetworks, which makes the protocol unable to cope with the variations that may occur in channel quality over time. The protocol proposed in Patti and Lo Bello (2016) is an evolution of MC-LLDN, called PriMuLa, which incorporates adaptive selection of channels for the subnets. One limitation of PriMuLa, which is due to the characteristics of LLDN networks, is that the same channel is allocated to all nodes on the same subnet. However, spatial variations in channel quality may occur, as well as asymmetry problems. In addition, to perform dynamic channel selection, a link quality estimation mechanism must be used that operates in real time and does not cause overhead on the sensor nodes. The simulations to evaluate PriMuLa were performed considering only shadowing problems, through the use of realistic parameters for the log-normal shadowing model. However, other problems that may affect the quality of the links, such as the non-stationarity behavior of the wireless channel in industrial environments, were not considered. Among the main modes of IEEE 802.15.4e, LLDN is the least researched, showing only three papers in IEEE Xplore database, one survey about IEEE 802.15.4e in which LLDN is discussed, presented by ScienceDirect database, and none in ACM Digital database. Two of them are specific about LLDN; they study priority-aware multi-channel adaptive framework, and tackling mobility in low latency deterministic multihop issues. 4. Multi-channel approaches and link quality estimation Due to variations in channel characteristics that occur over long periods of time in industry, as discussed in Section 1, in order for the network to continue operating with a certain level of QoS in a long term, it may be necessary to employ strategies for dynamic channel allocation. Therefore, it is important to consider the use of multi-channel protocols in MAC layer, to mitigate the aforementioned problems. 4.1. Multi-channel protocols Multi-channel protocols can be divided into static, dynamic and semi-dynamic (Soua and Minet, 2015). This classification takes into account that only the sink nodes may have multiple transceivers. 4.1.1. Static protocols Static approaches are the simplest to implement, since no synchronization mechanism is required to ensure communication between nodes during network operation. Moreover, there is no overhead related to channel switching in these mechanisms. Although these protocols allow optimizing the network during its deployment, they are not able to adapt to variations in channel characteristics over time, since its configuration is performed only at the beginning of the network. One example of static protocol is Tree-Based Multi-Channel Protocol (TMCP) (Wu et al., 2008). It divides the network into disjoint sub-trees (or clusters), having the sink node as root. To construct the sub-trees, it applies a breadth-first search algorithm. After that, orthogonal channels are allocated to each subtree. The algorithm allows increasing the overall throughput by means of simultaneous transmission in different sub-trees. The drawback is that it is not able to eliminate the interference between nodes of the same subtree. In addition, dynamic variations in channel quality are not taken into account, and some assigned channels may present poor quality in certain periods of time, which would prevent the use of these channels in some moments. 4.1.2. Dynamic protocols In this category, the protocols use multiple channels simultaneously, in order to reduce collisions through scheduling strategies. These strategies prevent the same channel from being used at the same time slot by nodes that can cause interference with each other. Such protocols require a synchronization mechanism to ensure that the transmitter and receiver are on the same channel during the communication. The drawback occurs when broadcast packets are sent, and when new nodes are added. WirelessHART, ISA100.11a, and TSCH standards use the dynamic approach. As an example of dynamic protocol is Y-MAC (Kim et al., 2008). It is a TDMA-based multi-channel MAC protocol that avoids redundant channel assignment by not allocating fixed channels to the nodes. When a traffic burst occurs, a receiver and potential senders hop to one of the other available channels, according to the hopping sequence. If each node has an exclusive send time slot in two-hop neighborhood, collision-free access to the medium is guaranteed. An alternative to the use of synchronization mechanisms in nodes is the asynchronous approach, with the use of a control channel. In this case, broadcast can also be supported through the control channel (Incel, 2011). This strategy has the advantage of not requiring clock synchronization between the sensor nodes, but presents a limitation due to the overhead of the negotiation process in the control channel, since periodically, the nodes need to listen to the control channel waiting for some message that indicates the start of a frame for data exchange. When nodes are waiting for control messages, the other channels remain idle. Another disadvantage is the bottleneck regarding the control channel, which may present low quality at certain moments, especially in dynamic environments. In dynamic protocols, usually the channel is chosen before each transmission. However, in order to improve the performance of the network, some mechanism for link quality estimation is necessary, and a correct management of the blacklist in each period. Link quality estimation is discussed in Section 4.2. 4.1.3. Semi-dynamic protocols There are several semi-dynamic protocols (Soua and Minet, 2015), but the most relevant and studied are MMSN (Zhou et al., 2006) and EM-MAC (Tang et al., 2011). The Multi-Frequency Media Access Control for Wireless Sensor Networks (MMSN) protocol consists of frequency assignment and media access aspects. The frequency assignment is used to assign different frequencies, or evenly allocate available frequencies if there are more neighbors than available frequencies, to nodes that have potential communication conflicts. It allows users to choose 1 of 4 available frequency assignment strategies. In media access design, nodes that have potential conflicts coordinate to access the shared physical frequencies, in a distributed way. The Dynamic Multichannel Energy-Efficient MAC Protocol for Wireless Sensor Networks (EM-MAC) is a multichannel asynchronous duty-cycling MAC protocol initiated by the receiver, where a node sends a wake-up beacon to notify potential senders that it is awake and ready to receive data packets. It does not require nodes to synchronize their clocks, does not use a common control channel, and does not explicitly exchange channel and wake-up schedules. Instead, every node independently decides its own pseudo-random channel-switching behavior and wake-up times. In this category, channel exchange and simultaneous transmission in different channels are allowed, but the exchanges occur less frequently. In some approaches, receivers are associated to fixed channels, whereas transmitters change to the channel of each receiver when have packets to transmit. In this case, a synchronization mechanism may also be required if the receiver changes the channel over time. In Saifullah et al. (2014), the authors proposed three approaches for channel allocation in order to minimize conflicts among simultaneous transmissions. The first approach is based on the receiver, in which the channels are allocated to the receivers of the network. The second approach is based on the connections between the nodes, in which the channels are allocated for each link between two nodes, so that the same node can receive packets through different channels, from different transmitters. The two approaches aimed to make the network free from channel conflict, without interference due to simultaneous transmissions on the same channel. In both cases, the network was modeled as a graph, and an interference graph was created, in which the edges represent nodes that interfere with each other. After modeling the interference graph, an algorithm of graph coloring can be used to minimize the number of channels being used, in which the channels are modeled as the colors in the algorithm. The third approach aims to minimize the maximum level of interference at the nodes. This approach also uses an interference graph, and the algorithms are distributed and executed iteratively. The strategy first performs a static and distributed channel allocation phase in order to reduce collisions. After this phase, the protocol can work dynamically, when a connection-based approach is used. However, this approach has no mechanisms to adapt to dynamic variations in the network. 4.2. Link quality estimation To maintain a certain level of QoS over long periods of time, it may be necessary to employ dynamic channel allocation strategies. The allocation must take into account the network topology to avoid neighboring subnets using the same or adjacent channels, and some mechanism to estimate the quality of the channels, since there may be spatial variations in the quality of the channels. Besides the ability to choose the best channel, the mechanism must allow fast network synchronization in case of channel switching. Experiments performed in Amzucu et al. (2014) with static nodes, found that a channel switch can lead up to 30 dB of difference in the received power. The channel quality estimators are the basis of several routing protocols, topology control, and dynamic channel allocation mechanisms (Baccour et al., 2012). In Gungor and Korkmaz (2012), there is an example of routing protocol that uses quality estimators, called CTP. It takes into account the asymmetry of the channels, and was discussed in Section 2.3. The estimators must have good reactivity to changes and maintain good stability. Some of them are based on hardware through the Link Quality Indicator (LQI) and RSSI, others, in software (packet delivery ratio, amount of retransmissions, and so on). All packets received by IEEE 802.15.4 radios have an associated RSSI and LQI value, however RSSI can also be obtained independent of packet reception. In this case, the transceiver performs a channel energy scan, regardless of the source. Any device that generates noise and interference influences its value. LQI, on the other hand, can only be measured during packet reception, since its metric is based on the analysis of the first symbols of received packets. RSSI is more stable than LQI, except for very reflective environments, which present greater small-scale attenuation due to multipath fading (Baccour et al., 2012). Regarding the software-based estimators, they use information obtained from upper layers, such as PRR, and Required Number of Packet Transmissions (RNP). The use of metrics based on PRR allows a good estimation for links with a very high or very low quality, but presents some problems in intermediate links. When retransmission is used, PRR-based metrics may overestimate the link quality, since it does not consider the number of transmission attempts before a successful reception. RNP-based metrics estimate the required number of packet transmissions until a successful reception. The ETX and Four-Bit (FB) are examples of RNP-based estimators (Gomes et al., 2017b). The ETX estimator (De Couto et al., 2003) is initiated by the receiver, and when it estimates the PRR in both directions, it takes into consideration the link asymmetry. In order to calculate the PRR of the backward and forward links, probe broadcast packets are used, causing overhead in all nodes of the network and extra traffic. The FB estimator (Fonseca et al., 2007) is initiated by the sender and uses four bits of information. The first bit is obtained from the physical layer in order to identify the quality of the channel in a received packet. The second bit (ACK bit) is obtained from the link layer, and considers both forward and backward links. The last two bits are obtained from the network layer, and are useful for route decisions (Baccour et al., 2012). The ACK bit is determined using data packets and probe broadcast packets that are combined to compute an estimate of the ETX. The F-LQE estimator (Baccour et al., 2015) is initiated by the receiver and is based on fuzzy logic. It uses four metrics to characterize the link: packet delivery (SPRR), stability (SF), asymmetry (ASL), and channel quality (SNR or LQI). The first metric is the PRR filtered with an EWMA filter. The stability metric is the coefficient of variation of PRR. The third metric uses the PRR calculated in the neighbor nodes, and these values in each node are acquired using probe broadcast packets, and sent together with data packets. The calculus of SNR is performed using two values of RSSI, one sampled from a received packet, and other value sampled after the packet reception to obtain the noise floor. After that, both values are subtracted to obtain the SNR. The Opt-FLQE estimator (Rekik et al., 2015) is a modification of F-LQE to improve the reactivity and reduce the computational complexity. It uses a metric obtained at the sender, the Smoothed RNP (SRNP), instead of SF. The SRNP values are sent together with data packets to allow the receiver to calculate the Opt-FLQE metric. Other solution for LQE, called Lightweight Packet Error Discriminator (LPED) (Barac et al., 2014), uses Forward Error Correction (FEC) to perform channel diagnosis, and the information obtained from received data packets. LPED is capable of identifying fading or interference problems in the wireless channel, but does not provide metrics to assess the link quality in terms of a network performance indicator, such as PRR or RNP (Eskola and Heikkilä, 2016). This may lead the network to make changes in the routes or channels due to rapid variations in the quality of the channels, which causes instability in the protocol. The use of FEC can be useful also to recover some corrupted packets, but when good channels or routers are picked, the SNR is increased, and then the use of FEC may not be advantageous. In Gungor and Korkmaz (2012), a simulation study was performed to compare PRR, RNP, WMEWMA, ETX, and FB on the CTP protocol for smart grid environments. The results showed that ETX and FB presented a better performance in such harsh environments, since only both estimators consider the link asymmetry among the evaluated LQEs. In the experiments described in Baccour et al. (2015), F-LQE outperformed ETX and FB, and in Rekik et al. (2015), a performance analysis showed that OptFLQE is more reactive than F-LQE, while still being more reliable for smart grid environments. In Rekik et al. (2016), Opt-FLQE was compared to ETX and FB on the RPL routing protocol for smart-grid environments, and the simulations showed that Opt-FLQE outperformed ETX and FB for all evaluated metrics. In Gomes et al., 2017b the authors proposed a Link Quality Estimator (LQE) for IWSN, and a new type of node, the LQE node, that estimates the link quality in real-time, using RSSI, and information obtained from received data packets. The proposed LQE is capable of capturing the effects of multipath, interference, and link asymmetry. Experiments were performed in a real industrial environment using IEEE 802.15.4 radios, and models were developed to allow the use of RSSI samples to proper estimate the link quality. A comparison was performed with the Opt-FLQE, and the results showed that the estimator described in Gomes et al., 2017b is more accurate and reactive for the type of environment in study. Different from other LQEs in literature, in the proposed LQE the sensor nodes do not need to send broadcast probe packets. Besides, using the LQE node, the other nodes of the WSN do not need to stop their operation to monitor the link quality. In this solution, no overhead is imposed on the end nodes, and there is no dependence on the size of the packets, as in LPED, for example. 5. WSN platforms, operating systems and simulators The terms sensor node, Wireless Node (WN), Smart Dust, mote, and Commercial Off-The-Shelf (COTS) mote are used somewhat interchangeably in the industry; the most general terms used here are sensor node and mote. The sensor nodes usually have one or more sensor units, a power supply run by batteries or connected to the power distribution company, a processing unit used to handle onboard data processing/storage/encryption/digital modulation, a transceiver, which combines radio transmitter/receiver, and is connected to the antenna, as depicted in Fig. 16(a). Download : Download high-res image (263KB) Download : Download full-size image Fig. 16. Hardware (a) and software (b) components, from Sohraby et al. (2007). The processors in wireless sensors are commonly referred as microcontrollers (MCU), and some of the characteristics why these MCU are especially suited to embedded systems are their flexibility in connecting with other devices (like sensors), their instruction set enabled to time-critical signal processing, and their typically low power consumption. In addition, they are freely programmable and hence very flexible (Karl and Willig, 2005). Besides these characteristics, MCU have the ability to reduce their power consumption by going into sleep states where only parts of the controller are active. MCU that are used in several wireless sensor node prototypes include the Atmel processor or Texas Instrument's MSP430 (Instruments, 2004). Table 2 shows some examples and characteristics of MCU from both Atmel and Texas Instruments. Table 2. WSN Platforms and characteristics. Platform mica2 mica2dot micaz tmote sky telosB MCU Atmel Atmega 128 L Atmel Atmega 128 L Atmel Atmega 128 L Texas Instruments MSP430 Texas Instruments MSP430 Clock 8 MHz 4 MHz 7.37 MHz 8 MHz 8 MHz RAM (Kbytes) 4 4 4 10 10 Flash Memory 128 128 128 48 48 Radio Chipcon CC1000 315/433/868/916 MHz 38.4 Kbauds Chipcon CC1000 315/433/868/916 MHz 38.4 Kbauds Chipcon CC2420 2.4 GHz 250Kbps IEEE 802.15.4 Chipcon CC2420 2.4 GHz 250Kbps IEEE 802.15.4 Chipcon CC2420 2.4 GHz 250Kbps IEEE 802.15.4 Max Range 150–300 m 150–300 m 75–100 m 75–100 m 75–100 m OS TinyOS TinyOS TinyOS TinyOS/Contiki TinyOS/Contiki Concerning the transceiver, currently popular product series include, for example, the RFM TR1001, the Chipcon CC1000 and CC2420, and the Infineon TDA525x family. The TR1000 family of radio transceivers from RF Monolithics is available for the 916 MHz and 868 MHz frequency range. It is intended for short-range radio communication with up to 115.2 kbps (Monolithics, 2000). Mica motes use RFM TR1000 transceiver and contain a set of hardware accelerators. Chipcon CC1000 operates between 300 and 1000 MHz, programmable in steps of 250 Hz. It uses FSK as modulation, provides RSSI, and has programmable output power. It is possible to use it in frequency hopping protocols (Instruments, 2009). CC2420 (Instruments, 2014) implements PHY layer as prescribed by the IEEE 802.15.4 standard with the required support for the MAC of this standard. The transceiver operates in 2.4 GHz band and features the required DSSS modem, resulting in a data rate of 250 kbps. The Infineon TDA 525x family provides flexible, single-chip, energy-efficient transceivers. Naturally, embedded software has to fulfill resource requirements, and the requirements are related to constraints such as limited memory consumption, available computing power, consumable energy, power dissipation, and so on. Embedded systems can be programmed in a wide variety of languages like assembly, C, C++, and Java. They differ in many aspects, such as the abstraction level at which the program is written and with that the granularity of control over the processor. Connected to the hardware of the sensor nodes, there are the following main software subsystems, as depicted in Fig. 16(b): • Operating System (OS): designed to run on types of devices that are severely constrained in memory, power, processing power, and communication bandwidth. Contiki and TinyOS are two examples of this kind of OS. Contiki is an open source OS for IoT, and connects tiny low-cost, low-power microcontrollers to the Internet. TinyOS is an open source, BSD-licensed operating system designed for low-power wireless devices. It provides useful software abstractions, also called Hardware Abstraction Layer (HAL), of the underlying device hardware (Amjad et al., 2016). Table 3 describes the OS for resource-constrained devices; Table 3. Operating systems. Name Architecture Scheduler Model Supported MCU Language License Network Stacks Real-time Support TinyOS Monolithic Cooperative Event- driven AVR, MSP430 nesC BSD BLIP (Berkeley Low-power IP stack) No Contiki Monolithic Cooperative/ Preemptive Event-driven, Protothreads AVR, MSP430, ARM C BSD uIP, RIME Partial OpenWSN Monolithic Cooperative Event-driven MSP430, ARM Cortex-M C BSD OpenWSN No RIOT Monolithic/Layered/Microkernel Preemptive, tickless Multi-threading AVR, MSP430, ARM7, ARM Cortex-M, x86 C, C++ LGPLv2 GNRC (Generic), OpenWSN Yes FreeRTOS Microkernel Cooperative/Preemptive Multi-threading AVR, MSP430, ARM, x86 C Modified GPL None Yes • Drivers: the sensor and communication drivers are the software modules that manage basic functions of the sensor, and the details of the radio channel transmission link, including clocking and synchronization, signal encoding, bit recovery, bit counting, signal levels, and modulation transceivers; • Mini-applications: data processing, signal-value storage and manipulation applications. They are supported at the node level for in-network processing; • Communication Processors: manage the communication functions, including routing, packet buffering and forwarding, topology maintenance, medium access control and encryption. 5.1. Operating systems This section analyzes existing WSN operating system, and the following list presents the main OS used for WSN: 5.1.1. TinyOS It is one of the first OS specifically designed for WSN. Its architecture consists of a scheduler and a set of connected components (Dargie and Poellabauer, 2010). Components are classified into configuration components and modules. The former specifies how two or more modules are connected with each other, and the latter are the basic building blocks of a TinyOS program. The composition of multiple configurations into a single executable code produces a TinyOS application. In TinyOS, scheduled tasks are based on FIFO principle, and TinyOS architecture is effective for tasks that are of short duration. Resource allocation in TinyOS is optimized by adopting a static memory allocation, which avoids the extra overhead associated with dynamic allocation. 5.1.2. Contiki It is another open source OS specifically designed for WSN. The Contiki kernel is event-driven like TinyOS, and the system includes protothreads that provide a thread-like programming abstraction but with a very small memory overhead. Protothreads in Contiki are a combination of some features of events and threads. They can be viewed as lightweight (stackless) threads, but they can also be viewed as interruptible tasks in event-based programming (Dunkels et al., 2006). Contiki provides IP communication, both for IPv4 and IPv6. The uIP embedded IP stack is used by hundreds of companies in systems such as freighter ships, satellites and oil drilling equipment. The idea of using IP communication in low-power WSN has led to an IETF standard and an international industry alliance - IP for Smart Objects (IPSO) Alliance (IPSO Alliance - promoting the use of IP for Smart Objects8). One of the interesting features of the Contiki OS is its support of dynamic loading and reconfiguration of services. This is achieved by defining services, service interfaces, service stubs, and a service layer. Services are to Contiki what modules are to TinyOS (Dargie and Poellabauer, 2010). Contiki includes several add-ons and libraries providing communication functionalities (Watteyne et al., 2012). The most relevant is the ContikiMAC (Dunkels,), a CSMA/CA preamble-sampling MAC using periodical wake-ups to listen for packet transmissions from neighbors. The μIPv6 library provides 6LoWPAN and RPL routing functionality. The transport layer implements both UDP and a lightweight version of TCP. Contiki also implements CoAP, similar to OpenWSN. 5.1.3. OpenWSN Another example of OS is Berkeley OpenWSN (Watteyne et al., 2012) which have primarily implemented their proposed communication protocols in TinyOS. Berkeley OpenWSN is an open source stack intending to implement low-power wireless standards such as IEEE 802.15.4e, 6LoWPAN, RPL and CoAP. It is rooted in the new IEEE 802.15.4e TSCH. Among the platforms that can run OpenWSN are GINA (AT86RF231), TelosB (CC2420), LPC (AT86RF231), and K20 (AT86RF231). The micro-controller of the first two platforms are developed by Texas Instruments, and the last two are NXP and Freescale, respectively. 5.1.4. RIOT It was developed with focus on the requirements of IoT (Baccelli et al., 2013). RIOT is a microkernel-based RTOS with multi-threading support, using an architecture inherited from FireKernel (Will et al., 2009). The OS is written in C and the applications and libraries are implemented in C++. RIOT features several network stacks, including its own implementation of the full 6LoWPAN stack (GNRC stack), a port of the 6TiSCH stack OpenWSN, and a port of the information centric networking stack CCN-lite (Hahm et al.) 5.2. Network simulators There is a number of network simulators (Wehrle et al., 2010) developed for several environments. The four main simulators that support simulation of LR-WPAN are described in this section. They are very used in the literature because of the resources provided. They are TOSSIM, COOJA, NS2/NS3 and OMNeT++. Regarding OMNeT++, this paper gives a special attention to one of its frameworks, Castalia, because of its realistic model based on CC2420 and CC1000 radio transceivers, and the wireless channel model developed by the authors of this survey to simulate IWSN. 5.2.1. TOSSIM It is a simulator with the specific goal of transparently running TinyOS applications (Wehrle et al., 2010). The component-oriented software architecture of TinyOS supports integration into a simulator, in which a hardware abstraction is provided by software components with specific interfaces, which are enforced at compile time. The simulation is event-driven and radio communication is modeled with bit error rates for each uni-directional link. The radio model is quite simplistic, not describing accurately interference caused by simultaneous transmissions. The simulator is also missing some other features such as mobility models. 5.2.2. COOJA It is a WSN simulator based on the Contiki OS. It is a Java-based simulator that executes native code by making Java Native Interface (JNI) calls from the Java environment to a compiled Contiki system. COOJA provides both the OS emulation and the instruction set emulation in a single framework. The MSPSim (Eriksson et al., 2009) is used as the instruction set simulator, and is also written in Java. It supports the Texas Instruments MSP430 microcontroller and includes some hardware peripherals such as sensor, communication ports, LEDs, and sound devices. 5.2.3. NS2/NS3 NS2 is an event-driven object-oriented network simulator whose simulations are realized in C++ language and object-oriented Tcl (OTcl). The NS3 simulator is an improvement of NS2, and is, as its predecessor, developed in the C++ but OTcl is neglected in favor of C++ (network models) and the Python language (optional). NS3 is a robust simulator developed for Internet systems, but it does not have very large focus on the lower layers of the protocols stack. NS3 has a LR-WPAN project in constant development9 to simulate WSN. It has several models implemented, including 6LoWPAN, RPL models. 5.2.4. OMNeT++ The Objective Modular Network Testbed simulation environment is an open-source discrete-event tool based on C++ and used for the simulations of communication networks, multiprocessors, and various distributed systems. It consists of modules that communicate with each other using message passing. Simple modules can be grouped together to form more complex compound modules. A user defines the structure of a module using OMNeT++ topology description language NED. It is often quoted as a discrete event simulator, but in fact, it is a software that supports various simulation models and frameworks such as the INET Framework, MiXiM and Castalia. Model frameworks are developed independent of the simulation framework, and follow their own release cycles. • INET Framework is an open-source communication networks simulation package, which contains models for several Internet protocols: UDP, TCP, SCTP, IP, IPv6, Ethernet, PPP, IEEE 802.11, MPLS, OSPF, and others. The INET Framework also contains emulation capabilities; • MiXiM supports wireless and mobile simulations. It provides detailed models of the wireless channel (fading, etc.), wireless connectivity, mobility models, models for obstacles and many communication protocols especially at the MAC level. Furthermore, it provides a user-friendly graphical representation of wireless and mobile networks, and supports debugging; • Castalia is a simulator for WSN, Body Area Networks and generally, networks of low-power embedded devices. Researchers and developers can use it to test their distributed algorithms and protocols in a realistic wireless channel and radio model (CC1000 and CC2420). Castalia uses the log-normal shadowing model as one of the ways to model average path loss. It also models temporal variation of path loss as an effort to capture fading phenomena in changing environments. Considering simulators with focus on industrial environments, some papers described simulation studies of IWSN (Du et al., 2015, Alderisi et al., 2015), but none of them considered the non-stationary characteristics of the wireless channel for a long term, neither the uncorrelation between different channels. In Gomes et al. (2017a), it is described a simple and reliable model to simulate multi-channel protocols for IWSN that captures the effects of fading, shadowing, and the non-stationary characteristics of the channel. It also considers the differences in the characteristics of the different channels, and the asymmetry of the links. In Gomes et al. (2017a), the MAC protocols CSMA/CA and TSCH were evaluated using the proposed model. It was integrated into the open source simulator Castalia. 6. Systematic mapping of IWSN researches WSNs are becoming increasingly popular, especially in industrial environments. Several researches have been conducted to investigate such environments and the standards used to improve the QoS, as discussed in the previous sections. According to Google Trends, depicted in Fig. 17, the term ZigBee, if compared to the other terms of standards, WirelessHART, 802.15.4e, and ISA100.11a, is by far the most researched term in Google tool, but it has been decreasing in interest since its peak in March 2005, as depicted in Fig. 17a). ZigBee was conceived in 1998, standardized in 2003, and revised in 2006. In a comparison shown in this Figure, the other standards do not even appear in the graphic. Download : Download high-res image (436KB) Download : Download full-size image Fig. 17. Google Trends on the terms WirelessHART, 802.15.4e, ISA100.11a, and ZigBee. When ZigBee is removed from the graph, the other standards can be easily visualized in Fig. 17b). It can be seen that, like ZigBee, WirelessHART has been decreasing in interest as a search term since June 2010. This graph also shows when the three standards began to be researched with WirelessHART in April 2007, 802.15.4e and ISA100.11a standards around March 2008. Officially presented in July 2009, ISA100.11a has not drawn the attention of researchers as much as WirelessHART, and officially presented in 2007, WirelessHART remains as one of the main standards researched. Since IEEE 802.15.4e defines improvements of IEEE 802.15.4 standard, it tends to draw more attention of researchers in the future, going against the decline of the other standards. Regarding scientific research, usually when trying to perform it, a researcher starts his work conducting primary studies, which is an empirical study that investigates a specific question. In the next step, the researcher leaves for secondary study, which reviews all primary studies related to a specific research question, in order to integrate and synthetize the evidence related to a specific research question. A systematic mapping is a form of secondary study performed to obtain a comprehensive overview of a given research topic, identify research gaps, and collect evidences to commission future research. Being a widespread methodology in areas such as medicine, the first works in systematic mapping connected to information technology emerged with software engineering. The first step to start this kind of study is setting a topic to be mapped, and then identifying the research questions. Based on these questions, one must create search strings and submit them to scientific search engines. The results must be analyzed according to inclusion and exclusion criteria defined in the study protocols. The last step is the classification of the works following a predefined taxonomy displaying results in graphs and tables. In order to achieve this goal, studies published in recent journals, and conferences available at three relevant electronic databases were collected and analyzed, namely: IEEE Xplore, ScienceDirect, and ACM Digital. The protocol is organized as follows: • Setting Scheme: in this case, the theme was set to ”industrial wireless sensor networks”; • Search Strings: for this mapping, the automatic search process is used. The semantics used for the search was: ((“Abstract”: industrial wireless sensor networks) AND industry industrial wireless). The papers lists are stored, and the results are listed in Table 4; Table 4. Results found in each database. Database Total % S1 S2 Filtered % IEEE Xplore 516 71.6 192 116 86 ScienceDirect 50 6.9 26 5 4 ACM Digital Library 155 21.5 22 13 10 TOTAL 721 100 240 134 100 • Steps (S): the filtering is performed in two steps. In the first step (S1), the title, abstract and keywords are analyzed according to the search string. Once this step is concluded, the second step (S2) is regarding a full analysis of the paper, and takes into consideration the selection criteria listed as follows; • Selection Criteria: they were used to evaluate each retrieved primary study. The main goal is the inclusion of potentially relevant studies to answer the Research Questions (RQ), and exclude those that are irrelevant, duplicated, and not written in English. These selection criteria were used to filter the papers in the second step (S2). The following Inclusion and Exclusion Criteria (IC and EC) were considered:IC: papers that present studies about IWSN and experiments inside this environment regarding the communication issues;EC1: papers that do not present results and do not have industry as the main concern;EC2: subjects and technologies that were not discussed in this paper, such as Multimedia Sensor Networks, Software-Defined Networking (SDN), Big Data, Cloud Computing, Wireless Nano Sensor Networks, Open Communication protocol for Ad hoc Reliable industrial Instrumentation (OCARI), industrial control systems which use Network Control System (NCS) and Supervisory Control and Data Acquisition (SCADA), Data-muling, Service-Oriented Architecture (SOA), DECT (Digital Enhanced Cordless Telecommunications), Crowdsourcing-based Industrial Sensing Intelligence (CISI), energy harvesting systems, technologies unsuitable for industrial monitoring such as Bluetooth, 802.11, and Arduino, general-purpose security issues, and connection to wired systems;EC3: automation applications cover a broad domain from industrial automation, home automation to automation in body area networks, and have specific real-time requirements differing from each other depending on the criticality of the application. Therefore, all the issues regarding automation applications are excluded, except for the industrial applications;EC4: underwater monitoring has been extensively researched, but since this environment is outdoor and differs from the common industrial environment, it is excluded;EC5: studies that are table of contents, tutorial, editorial, keynote talk, Ph.D. forum abstract, or summary of conference. • Research Questions (RQ): RQ1 - How are the distributed publications over the years about IWSN, considering S1 papers? RQ2 - Who are the researchers with the largest amount of published works, considering S1 papers? RQ3 - Which are the main Journals and Conferences that publish most papers about IWSN, considering S1 papers? Considering S2 papers, the following RQ were defined: RQ4 - Which are the main standards used in IWSN? RQ5 - Which type of analysis is performed by the papers, experiments, simulations, or both? Among the simulators used, which are the most used? RQ6 - Regarding the devices and OS, which are the most used? Although the mentioned standards are used in industry and most of them were designed for this environment, not always the papers have this environment as focus, so those that did not consider the research in it were discarded. The first RQ relates to the distribution of publications over the years. In Fig. 18, it is shown that researches about IWSN began around 2004. The original version of 802.15.4 PHY was developed in 2003, with revisions from 2006. The peak in 2016 of papers published can be explained because of improvements regarding the IEEE 802.15.4-2011 standard, and the new concepts of IoT and IIoT. The concept of IIoT in manufacturing came up, and leads to the fourth industrial revolution, the so-called Industry 4.0 (smart factory), which in 2013 had its final report presented. Although seven articles were found in 2017, they were not included in this chart because the year has not yet been finalized. Download : Download high-res image (145KB) Download : Download full-size image Fig. 18. Papers published per year about IWSN after S1. The RQ2 is regarding the researchers who most published papers in literature about IWSN, and the result is illustrated in Table 5. According to the search string, the authors are listed ordered by the number of contributions. This list is limited to 16 researchers, but it does not mean that other authors have not contributed somehow, and does not mean that some of them are more important than the others, but this list aims to help other researchers to draw their studies to the research object in question. In addition, the listed authors may have contributed with other papers not filtered in this systematic mapping. The results intend only to create a statistical view of researches developed and their authors. Table 5. Number of contributions by author. Researcher Papers Mikael Gidlund 17 Johan Akerberg 7 Gerhard P. Hancke 6 Tingting Zhang 6 Bin Lu 5 Filip Barac 5 Mats Bjorkman 5 Chenyang Lu 5 Abdullah Al-Yami 4 Emiliano Sisinni 4 Peng Zeng 4 Xiaotong Zhang 4 James Brown 4 Pedro Furtado 4 Utz Roedig 4 Chengjie Wu 4 Regarding RQ3, Table 6 lists the most relevant IEEE Journals and Conferences that published papers about IWSN, Table 7 lists the ACM papers, and Table 8 lists ScienceDirect ones. Table 6. Main Journals and Conferences from IEEE Xplore regarding industrial issues after S1. Acronym Type Name Total Papers % TII Journal IEEE Transactions on Industrial Informatics 14 of 51 27 TIE Journal IEEE Transactions on Industrial Electronics 7 of 51 13 IECON Conference Conference of IEEE Industrial Electronics 8 of 141 5.6 INDIN Conference IEEE International Conference on Industrial Informatics 8 of 141 5.6 ETFA Conference Conference on Emerging Technologies and Factory Automation 5 of 141 3.5 ICIT Conference IEEE International Conference on Industrial Technology 5 of 141 3.5 WCICA Conference World Congress on Intelligent Control and Automation 4 of 141 2.8 ISIE Conference International Symposium on Industrial Electronics 3 of 141 2.1 Table 7. Main Journals and Conferences from ACM regarding industrial issues after S1. Acronym Type Name Total Papers % TECS Journal ACM Transactions on Embedded Computing Systems 3 of 5 60 TOSN Journal ACM Transactions on Sensor Networks 2 of 5 40 ICUIMC Conference International Conference on Ubiquitous Information Management and Communication 2 of 17 11.7 IWCMC Conference International Conference on Wireless Communications and Mobile Computing 2 of 17 11.7 Table 8. Main Journals and Conferences from ScienceDirect regarding industrial issues after S1. Type Name Total Papers % Journal Computers in Industry 4 of 18 22.2 Journal Ad Hoc Networks 2 of 18 11.1 Journal Computers&Industrial Engineering 1 of 18 5.5 Conference International Federation of Automatic Control 2 of 7 28.5 In order to answer RQ4, Fig. 19 depicts the most used standards in industrial environments, and ZigBee leads the list, followed by WirelessHART. This can be explained because ZigBee is much older than WirelessHART, since in 2007 it was the main standard researched. Although the massive use of ZigBee, in Barac et al. (2015) new researches found that none of those standards were able to deal with industrial applications with stringent timing requirements. To overcome this problem, IEEE 802.15.4e was developed, and it is shown in third place after WirelessHART. The study of IEEE 802.15.4e tends to increase along the years because of its strategies to deal with Multipath Fading and Attenuation (MFA) and interference requirements. Download : Download high-res image (128KB) Download : Download full-size image Fig. 19. Main standards used in IWSN. Concerning RQ5, according to Fig. 20 a), most papers performed simulations more than experiments. Only 13% performed experiments after simulations, in order to corroborate with the results presented by the simulations. More important than simulations, the experiments have the ability to validate in real environments or with real devices, the implementation of the proposed solution. When considering the simulations, Fig. 20b) depicts the main used simulators. It is shown that Matlab, OPNET and NS2, followed by QualNet, Simulink and OMNeT++ are the most used tools to simulate protocols and environments for IWSNs. Matlab allows implementation of algorithms and interfacing with programs written in other languages, including C, C++, etc., so it is very used across industry and academia. Download : Download high-res image (191KB) Download : Download full-size image Fig. 20. Type of analysis performed by the papers and main simulators used in them. In the case of papers, instead of NS3, the most used version is its previous one. This can be explained by some reasons: the latest version of NS2 was released in late 2011 (2.35) with several improvements, and remains in active use and maintained; the differences between NS2 and NS3 are numerous, and NS2 scripts do not run within NS3. Therefore, for researchers that are used to NS2, changing to NS3 requires study and adaptation, which is not always possible in a short time. Although NS3 has improved models, NS2 still remains as a good option to test models and algorithms. OPNET was a software business that provided performance management for computer networks and applications. Its company was founded in 1986 and went public in 2000. In October 2012, OPNET was acquired by Riverbed Technology. Prior this acquisition, it had an OPNET Modeler (now Riverbed Modeler), a software tool for computer network modeling and simulation. Since the tool is not free-of-charge, it was not included in this paper. Regarding the devices and OS asked in RQ6, depicted in Fig. 21, the most used platforms are TelosB, CC2420, MicaZ, IRIS and Tmote Sky. Several platforms features Chipcon CC2420 radio by Texas Instruments for wireless communications, such as Tmote Sky, Zolertia Z1, MicaZ, TelosB, and others, but some papers that used it were not specific in defining which exact platforms they used, so it was separated when the platform was not explicit. Concerning the OS, TinyOS is by large the most popular OS for IWSN because of its support for several platforms. Contiki, which is the second of the list, is more suitable for IIoT, and since there are several papers with focus on real-time communications, FreeRTOS also appeared in the list. Download : Download high-res image (215KB) Download : Download full-size image Fig. 21. Most used devices in the papers and Operating Systems. 7. Discussion There are many studies about the IWSN challenges, which have been discussed in the previous sections. In this section, some examples of potential approaches to deal with the challenges are discussed. Some of the approaches are as follows: 7.1. Resource constraints UWB (Ultra-WideBand) is a form of radio transmission that creates short pulses of low-energy radiation (Zeng et al., 2015). The width of the pulse gives it the property of generating radio energy over a wide frequency range, with very low energy, at any frequency. This allows UWB to overlap other radio bands such as Wi-Fi and the other services in the 2.4 GHz ISM band without interfering. Generally, other radio modulation schemes such as DSSS will see UWB as just impulse noise, which they easily filter out. Since UWB uses pulses, it is capable of being detected over a much longer range than other signal forms. Pulses signals also tend to penetrate solid objects better than continuous wave signals. Low-energy radiation requires less transmit power and results in longer battery life for battery-powered devices. The peculiar characteristics of the UWB radio technique offer new solutions and opportunities for industrial wireless application (Paso et al., 2013). Other important topic regarding resource constraints is the cooperation mechanism to reduce energy consumption at the cost of an acceptable reduced throughput. TDMA-based multihop mesh networks with cooperation mechanism is an example of approach that has not been much researched (Iqbal et al., 2017). The use of data aggregation is another research topic to be explored (Dobslaw et al., 2015). It significantly improves the end-to-end contention and energy efficiency compared to single packet transmissions. In combination with techniques such as redundant relays, re-transmission, hybrid and hierarchical network structures, multiple channel communication and slot-reuse, data aggregation can play a crucial role in making wireless networks for industrial applications practically feasible. 7.2. Dynamic topologies and dynamic solutions When considering the dynamic characteristics of industrial environments, it is important to think about dynamic solutions to guarantee the quality of communications (Collotta et al., 2012). There are researches about dynamic and distributed topology control with self-organizing properties, and decentralized dynamic topology control algorithms capable to construct tree-based topologies for use in performance critical applications. Other options are regarding dynamically allocated GTS slots, dynamic time division multiple access, and dynamically update sampling times. The first one can be configured to deal with sporadic and periodic events. With the use of an implicit decision used in deallocation/deflation, the control traffic is kept low resulting in low battery consumption. The second one considers a cluster topology, and in the inter-cluster part, a quick assign algorithm and a dynamic maximum link algorithm can be developed to meet the quick networking or minimum frame size requirements. The last one intends to ensure a better possible management of critical situations regardless of network protocol (since it may work at application level of protocol stack) and topology used. Other issue regarding dynamic solutions to provide reliability is the creation of redundant links dynamically. An example of a protocol that provides redundancy for industrial applications is RWCP (Reliable Wireless Communication Protocol) (Yu and Feng, 2009). 7.3. Real-time constraints Several papers address real-time constraints in IWSN. When errors or exceptions occur, high-criticality flows must be guaranteed reliably and in real time, and only a few works focus on mixed-criticality industrial systems. In this case, one option to solve this problem is optimizing the scheduling policy of mixed criticality IWSN. Other option is using an end-to-end delay analysis approach for fixed priority scheduling in mixed criticality in standards such as WirelessHART networks, which can be used to determine whether all flows can be delivered to destinations within their deadline. Other research direction is the creation of a real-time multi-channel process control monitoring system, such as in Blevins et al. (2015). Some papers propose multi-channel process monitoring algorithms that brings a balance between timeliness and throughput by increasing in number of operating channels. Regarding clustering strategy to deal with real-time constraints, one alternative is partitioning a network into a nonfixed number of nonoverlapping clusters according to the communication network topology and measurements distribution. 7.4. Security There are not much studies in the literature related to security issues in IWSN. Many industrial applications including equipment monitoring, environment monitoring, and industrial automation may be susceptible to different kinds of attacks. The peculiarities of industrial networks restrict the use of classical approaches to security (Cheminod et al., 2013). The cognition and reconfigurability of cognitive radios central to their functioning introduce a new class of security concerns distinct to those evident in conventional wireless networks (Fragkiadakis et al., 2013). Ensuring reliability and providing adequate security in these crucial services provided by WSNs will reinforce their acceptability as a viable and dependable technology in the factory and industrial domain. 7.5. Quality of service Since sensor data are typically time-sensitive, it is important to receive the data at the sink in a timely manner. Several are the researches intended to maintain QoS of communications in IWSNs. Some study adaptive frequency hopping approaches that allow IWSN to switch cognitively working channels for high transmission reliability. Adaptive frequency hopping (AFH) is a good topic to be researched, since it reduces the probability of inefficient frequency hopping, e.g., hopping from good channels to bad ones. Other topic is autonomous channel switching design, in which each accessed sensor autonomously equalizes the local channel occupations within its range of spectrum sensing without overhead on exchanging the sensors’ spectrum sensing reports. Other works study synchronization protocols, such as Flooding Time Synchronization Protocol (FTSP), and tighter time synchronization. The first one has high synchronization precision in WSN, and can be improved according to the characteristics of IWSN. The second one gives less latency, better bandwidth utilization, less jitter on the application. Regarding cluster topologies, one issue to be studied is the optimized aggregators selection problem. Clustering sensor nodes is an effective technique to achieve in-network aggregation in WSN, and the selection of a few aggregators from the sensor nodes can significantly reduce the data collection cost. Other research topics to guarantee QoS are delay-aware scheduling algorithms, and link state dependent scheduling, such as in Hong et al. (2015). The first one adds time slots for retransmission to each link in order to satisfy required reliability. Furthermore, by sharing retransmission slots among different flows, the method achieves the required reliability and forwarding delay while suppressing increase in the number of allocated slots. The second one allows the nodes to gather samples of the channel quality in order to generate prediction sets from the sample sets in independent slots. Using the prediction sets, nodes only wake up to transmit/receive during scheduled slots that are predicted to be clear and sleep during scheduled slots that may potentially cause a transmitted signal to fade. 8. Conclusion In this paper, an overview of the most relevant technologies and the various facts (configurability) concerning the deployment of WSN in harsh environments has been performed. Among such a kind of environments, the industrial one is one of the most relevant due to the increasing role of WSNs in industry. Furthermore, the analysis has taken into account the experiments and simulation results to discuss the various issues which particularly appear in IWSN. First, the paper discusses some general facts regarding IWSN such as layers and protocols as an introduction, to the particular case of the various standards used in IWSN. Then the discussion focuses on the most extended and used standards in IWSN with special emphasis on the IEEE 802.15.4 standard, and its amendment IEEE 802.15.4e. One of the particularities of ISWN is the channel behavior that suffers from various typical disturbances: interference from other systems operating in the same band, deep multipath fading, noise and shadowing strong attenuation. Given such a harsh transmission media, appropriate protocols should be developed to improve the network reliability and reach the maximum network throughput while preserving a moderate power consumption although this is not the main constraint but channel availability and reliability. One of the main conclusion that can be drawn from the research shown in this paper is that DSME protocol is a good alternative to implement IWSN if compared to the beacon-enabled mode of the IEEE 802.15.4 standard. Although it is based on the latter, some improvements have been included, such as the use of multiple channels in the CFP (GTS). The best protocol to choose depends on the application requirements. For example, for applications that require very low latencies, the use of LLDN mode and star topology may be more appropriate. When comparing the performance of DSME vs. TSCH in IWSN, the first one shows a slightly better performance, lower energy consumption and higher spectral efficiency. On the other hand, TSCH performance is improved when using adaptive frequency hopping to avoid the use of channels affected by interferences (with low quality). Another relevant issue in the development of ISWN is the use of the appropriate OS. While TelosB remains as a good choice in the development and deployment of IWSN other OS like Contiki, which is gaining popularity because it supports dynamic loading and reconfiguration of services, and OpenWSN are being increasingly used in ISWN implementation. A key parameter that characterizes an OS for ISWN is the low-power operation. An ISWN implementation should take into consideration some performance parameters, among them the required bandwidth and transmission power. The lower the transmit power the longer the battery life. Protocols and media access impact the required transmit power. TDMA-based multihop mesh networks with cooperation mechanism seems to be a proper framework for this goal. An IWSN shows dynamic characteristics, which are typical in industrial environments. In consequence, in order to optimize the overall network throughput and guarantee a high reliability appropriate dynamic topologies and dynamic solutions are required. The most common techniques are dynamically allocating GTS slots, dynamic time division multiple access, and dynamically update sampling times. The most appropriate solution depends on several network parameters. Currently, real-time constraints focus on mixed-criticality industrial systems. Various solutions have been developed where the which showed to be more effective are optimizing the scheduling policy and the end-to-end delay analysis approach for fixed priority scheduling. Security is a critical service in ISWN. The use of new and flexible protocols provides cognition and reconfigurability of cognitive radios central to their functioning, which introduces a new class of security challenges. Acknowledgment The authors would like to thank the support of the Institute for Advanced Studies in Communications (Iecom), the Brazilian Council for Research and Development (CNPq), the Coordination for the Improvement of Higher Education Personnel (CAPES), and Erasmus Mundus SMART2 Project. References Agrawal et al., 2014 Agrawal, P., Ahlen, A., Olofsson, T., Gidlund, M., 2014. Characterization of long term channel variations in industrial wireless sensor networks. In: IEEE International Conference on Communications, pp. 1–6. doi:10.1109/ICC.2014.6883285. Google Scholar Agrawal et al., 2014 P. Agrawal, A. Ahlen, T. Olofsson, M. Gidlund Long term channel characterization for energy efficient transmission in industrial environments IEEE Trans. Commun., 62 (8) (2014), pp. 3004-3014, 10.1109/TCOMM.2014.2332876 View in ScopusGoogle Scholar Akerberg et al., 2011 Akerberg, J., Gidlund, M., Bjorkman, M., 2011. Future research challenges in wireless sensor and actuator networks targeting industrial automation. In: 2011 Proceedings of the 9th IEEE International Conference on Industrial Informatics, IEEE, pp. 410–415.doi:10.1109/INDIN.2011.6034912. Google Scholar Alderisi et al., 2015 Alderisi, G., Patti, G., Mirabella, O., Bello, L.L., 2015. Simulative assessments of the IEEE 802.15.4e DSME and TSCH in realistic process automation scenarios. In: 2015 IEEE Proceedings of the 13th International Conference on Industrial Informatics (INDIN), IEEE, pp. 948–955. doi:10.1109/INDIN.2015.7281863. Google Scholar Al-Karaki and Kamal, 2004 J. Al-Karaki, A. Kamal Routing techniques in wireless sensor networks: a survey IEEE Wirel. Commun., 11 (6) (2004), pp. 6-28, 10.1109/MWC.2004.1368893 Google Scholar Al-Nidawi et al., 2015 Al-Nidawi, Y., Yahya, H., Kemp, A.H., 2015. Impact of mobility on the IoT MAC infrastructure: IEEE 802.15.4e TSCH and LLDN platform. In: 2015 IEEE 2nd World Forum on Internet of Things (WF-IoT), IEEE, 2015, pp. 478–483. doi:10.1109/WF-IoT.2015.7389101. Google Scholar Amjad et al., 2016 M. Amjad, M. Sharif, M.K. Afzal, S.W. Kim TinyOS-new trends, comparative views, and supported sensing applications: a review IEEE Sens. J., 16 (9) (2016), pp. 2865-2889, 10.1109/JSEN.2016.2519924 View in ScopusGoogle Scholar Amzucu et al., 2014 D.M. Amzucu, H. Li, E. Fledderus Indoor radio propagation and interference in 2.4 GHz wireless sensor networks: measurements and analysis Wirel. Personal. Commun., 76 (2) (2014), pp. 245-269, 10.1007/s11277-014-1694-2 View in ScopusGoogle Scholar Ancillotti et al., 2013 E. Ancillotti, R. Bruno, M. Conti The role of the RPL routing protocol for smart grid communications IEEE Commun. Mag., 51 (1) (2013), pp. 75-83, 10.1109/MCOM.2013.6400442 View in ScopusGoogle Scholar Angskog et al., 2010 Angskog, P., Karlsson, C., Coll, J.F., Chilo, J., Stenumgaard, P., 2010. Sources of disturbances on wireless communication in industrial and factory environments. In: 2010 Asia-Pacific International Symposium on Electromagnetic Compatibility, IEEE, pp. 281–284. doi:10.1109/APEMC.2010.5475862. Google Scholar Anwar et al., 2015 M. Anwar, Y. Xia, Y. Zhan TDMA based IEEE 802.15.4 for low latency deterministic control applications IEEE Trans. Ind. Inform. (2015), p. 1, 10.1109/TII.2015.2508719 View in ScopusGoogle Scholar Anwar et al., 2016 M. Anwar, Y. Xia, Y. Zhan Tdma-based ieee 802.15.4 for low-latency deterministic control applications IEEE Trans. Ind. Inform., 12 (1) (2016), pp. 338-347, 10.1109/TII.2015.2508719 View in ScopusGoogle Scholar Association, 2017 I.S. Association, IEEE 802.15 WPAN Task Group 4e (TG4e), 2017. URL 〈http://www.ieee802.org/15/pub/TG4e.html〉. Google Scholar Baccelli et al., 2013 Baccelli, E., Hahm, O., Günes, M., Wahlisch, M., Schmidt, T., 2013. RIOT OS: Towards an OS for the Internet of Things. In: 2013 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), IEEE, pp. 79–80. doi:10.1109/INFCOMW.2013.6970748. Google Scholar Baccour et al., 2012 N. Baccour, A. Koubâa, L. Mottola, M.A. Zúñiga, H. Youssef, C.A. Boano, M. Alves Radio link quality estimation in wireless sensor networks ACM Trans. Sens. Netw., 8 (4) (2012), pp. 1-33, 10.1145/2240116.2240123 Google Scholar Baccour et al., 2015 N. Baccour, A. Koubâa, H. Youssef, M. Alves Reliable link quality estimation in low-power wireless networks and its impact on tree-routing Ad Hoc Netw., 27 (2015), pp. 1-25, 10.1016/j.adhoc.2014.11.011 View PDFView articleView in ScopusGoogle Scholar Bachir et al., 2010 A. Bachir, M. Dohler, T. Watteyne, K.K. Leung MAC essentials for Wireless Sensor Networks IEEE Commun. Surv. Tutor., 12 (2) (2010), pp. 222-248, 10.1109/SURV.2010.020510.00058 View in ScopusGoogle Scholar Bal, 2014 Bal, M., 2014. Industrial applications of collaborative Wireless Sensor Networks: A survey. In: 2014 IEEE Proceedings of the 23rd International Symposium on Industrial Electronics (ISIE), IEEE, pp. 1463–1468. doi:10.1109/ISIE.2014.6864830. Google Scholar Barac et al., 2014 F. Barac, S. Caiola, M. Gidlund, E. Sisinni, T. Zhang Channel diagnostics for Wireless Sensor Networks in harsh industrial environments IEEE Sens. J., 14 (11) (2014), pp. 3983-3995, 10.1109/JSEN.2014.2356972 View in ScopusGoogle Scholar Barac et al., 2015 Barac, F., Gidlund, M., Zhang, T., 2015. PREED: Packet REcovery by Exploiting the Determinism in Industrial WSN Communication. In: 2015 International Conference on Distributed Computing in Sensor Systems, IEEE, pp. 81–90. doi:10.1109/DCOSS.2015.8. Google Scholar Baronti et al., 2007 P. Baronti, P. Pillai, V.W. Chook, S. Chessa, A. Gotta, Y.F. Hu Wireless sensor networks: a survey on the state of the art and the 802.15.4 and ZigBee standards Comput. Commun., 30 (7) (2007), pp. 1655-1695, 10.1016/j.comcom.2006.12.020 View PDFView articleView in ScopusGoogle Scholar Bartolomeu et al., 2016 P. Bartolomeu, M. Alam, J. Ferreira, J. Fonseca Survey on low power real-time wireless MAC protocols J. Netw. Comput. Appl., 75 (2016), pp. 293-316, 10.1016/j.jnca.2016.09.004 View PDFView articleView in ScopusGoogle Scholar Bartolomeu et al., 2017 P. Bartolomeu, M. Alam, J. Ferreira, J. Fonseca Implementation and analysis of wireless flexible time-triggered protocol Hybrid. Wirel. Ad Hoc Netw., 58 (2017), pp. 36-53, 10.1016/j.adhoc.2016.11.016 View PDFView articleView in ScopusGoogle Scholar Ben Yaala et al., 2016 Ben Yaala, S., Theoleyre, F., Bouallegue, R., 2016. Performance study of co-located IEEE 802.15.4-TSCH networks: Interference and coexistence. In: 2016 IEEE Symposium on Computers and Communication (ISCC), IEEE, pp. 513–518. doi:10.1109/ISCC.2016.7543790. Google Scholar Blevins et al., 2015 Blevins, T., Chen, D., Han, S., Nixon, M., Wojsznis, W., 2015. Process Control over Real-Time Wireless Sensor and Actuator Networks. In: 2015 IEEE Proceedings of the 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems, IEEE, pp. 1186–1191. doi:10.1109/HPCC-CSS-ICESS.2015.141. Google Scholar Boccadoro et al., 2016 Boccadoro, P., Barile, M., Piro, G., Grieco, L.A., 2016. Energy consumption analysis of TSCH-enabled platforms for the Industrial-IoT. In: 2016 IEEE 2nd International Forum on Research and Technologies for Society and Industry Leveraging a better tomorrow (RTSI), IEEE, pp. 1–5. doi:10.1109/RTSI.2016.7740596. Google Scholar Buratti et al., 2011 Buratti, C., Martalò, M., Ferrari, G., Verdone, R., 2011. Sensor Networks with IEEE 802.15.4 Systems, Signals and Communication Technology, Springer Berlin Heidelberg. doi:10.1007/978-3-642-17490-2. Google Scholar Cheffena, 2012 M. Cheffena Industrial wireless sensor networks: channel modeling and performance evaluation EURASIP J. Wirel. Commun. Netw., 2012 (1) (2012), pp. 1-8, 10.1186/1687-1499-2012-297 Google Scholar Cheffena, 2016 M. Cheffena Propagation channel characteristics of industrial wireless sensor networks [wireless corner IEEE Antennas Propag. Mag., 58 (1) (2016), pp. 66-73, 10.1109/MAP.2015.2501227 View in ScopusGoogle Scholar Cheminod et al., 2013 M. Cheminod, L. Durante, A. Valenzano Review of security issues in industrial networks IEEE Trans. Ind. Inform., 9 (1) (2013), pp. 277-293, 10.1109/TII.2012.2198666 View in ScopusGoogle Scholar Chen et al., 2016 Chen, T.-S., Kuo, S.-Y., Kuo, C.-H., 2016. Scheduling for Data Collection in Multi-hop IEEE 802.15.4e TSCH Networks. In: 2016 International Conference on Networking and Network Applications (NaNA), IEEE, pp. 218–221. doi:10.1109/NaNA.2016.23. Google Scholar Chilo et al., 2009 Chilo, J., Karlsson, C., Angskog, P., Stenumgaard, P., 2009. EMI disruptive effect on wireless industrial communication systems in a paper plant. In: 2009 IEEE International Symposium on Electromagnetic Compatibility, IEEE, pp. 221–224. doi:10.1109/ISEMC.2009.5284581. Google Scholar Christin et al., 2010 D. Christin, P.S. Mogre, M. Hollick Survey on wireless sensor network technologies for industrial automation: the security and quality of service perspectives Future Internet, 2 (2) (2010), pp. 96-125, 10.3390/fi2020096 View in ScopusGoogle Scholar Colesanti and Santini, Colesanti, U., Santini, S., 2011. The Collection Tree Protocol for the Castalia Wireless Sensor Networks Simulator, Technical Report Nr. 729. URL 〈https://sing.stanford.edu/gnawali/ctp/colesanti11ctp.pdf〉. Google Scholar Collotta et al., 2012 Collotta, M., Gentile, L., Pau, G., Scata, G., 2012. A dynamic algorithm to improve industrial Wireless Sensor Networks management. In: IECON 2012 - Proceedings of the 38th Annual Conference on IEEE Industrial Electronics Society, IEEE, pp. 2802–2807. doi:10.1109/IECON.2012.6389451. Google Scholar Correia et al., 2015 L.H. Correia, T.-D. Tran, V.N. Pereira, J.C. Giacomin, J.M.S. Silva Dynmac: a resistant {MAC} protocol to coexistence in wireless sensor networks Comput. Netw., 76 (2015), pp. 1-16 View PDFView articleView in ScopusGoogle Scholar Dargie and Poellabauer, 2010 W. Dargie, C. Poellabauer Fundamentals of Wireless Sensor Networks John Wiley&Sons, Ltd (2010), 10.1002/9780470666388 Google Scholar de Armas et al., 2016 de Armas, J., Tuset, P., Chang, T., Adelantado, F., Watteyne, T., Vilajosana, X., 2016. Determinism through Path Diversity: Why Packet Replication Makes Sense. In: 2016 International Conference on Intelligent Networking and Collaborative Systems (INCoS), IEEE, pp. 150–154. doi:10.1109/INCoS.2016.105. Google Scholar De Couto et al., 2003 De Couto, D.S.J., Aguayo, D., Bicket, J., Morris, R., 2003. A high-throughput path metric for multi-hop wireless routing. In: Proceedings of the 9th annual international conference on Mobile computing and networking - MobiCom '03, ACM Press, New York, New York, USA, pp. 134. doi:10.1145/938985.939000. Google Scholar De Guglielmo et al., 2016 D. De Guglielmo, S. Brienza, G. Anastasi IEEE 802.15.4e: A survey Comp Commun. (2016), 10.1016/j.comcom.2016.05.004 Google Scholar De Guglielmo et al., 2016 De Guglielmo, D., Brienza, S., Anastasi, G., 2016. A Model-based Beacon Scheduling algorithm for IEEE 802.15.4e TSCH networks. In: 2016 IEEE Proceedings of the 17th International Symposium on A World of Wireless, Mobile and Multimedia Networks (WoWMoM), IEEE, pp. 1–9. doi:10.1109/WoWMoM.2016.7523517. Google Scholar De Guglielmo et al., 2017 D. De Guglielmo, B. Al Nahas, S. Duquennoy, T. Voigt, G. Anastasi Analysis and experimental evaluation of IEEE 802.15.4e TSCH CSMA-CA algorithm IEEE Trans. Veh. Technol., 66 (2) (2017), pp. 1573-1588, 10.1109/TVT.2016.2553176 View in ScopusGoogle Scholar Delgado Gomes et al., 2012 R. Delgado Gomes, M. Aurelio Spohn, A. Cavalcante Lima, E. Gomes dos Anjos, F. Antonio Belo Correlation between spectral occupancy and packet error rate in IEEE 802.15.4-based industrial Wireless Sensor Networks IEEE Lat. Am. Trans., 10 (1) (2012), pp. 1312-1318, 10.1109/TLA.2012.6142478 View in ScopusGoogle Scholar Delgado Gomes et al., 2013 R. Delgado Gomes, M. Oliveira Adissi, A. Cavalcante Lima-Filho, M.A. Spohn, F. Antônio Belo On the Impact of local processing for motor monitoring systems in industrial environments using Wireless Sensor Networks Int. J. Distrib. Sens. Netw., 2013 (2013), pp. 1-14, 10.1155/2013/471917 Google Scholar Divya Darshini et al., 2016 Divya Darshini, B., Paventhan, A., Krishna, H., Pahuja, N., 2016. Enabling real time requirements in industrial IoT through IETF 6TiSCH. In: 2016 International Conference on Internet of Things and Applications (IOTA), IEEE, pp. 121–124. doi:10.1109/IOTA.2016.7562707. Google Scholar Dobslaw et al., 2015 Dobslaw, F., Gidlund, M., Zhang, T., 2015. Challenges for the use of data aggregation in industrial Wireless Sensor Networks. In: 2015 IEEE International Conference on Automation Science and Engineering (CASE), IEEE, pp. 138–144. doi:10.1109/CoASE.2015.7294052. Google Scholar Domingo-Prieto et al., 2016 M. Domingo-Prieto, T. Chang, X. Vilajosana, T. Watteyne Distributed PID-Based scheduling for 6TiSCH networks IEEE Commun. Lett., 20 (5) (2016), pp. 1006-1009, 10.1109/LCOMM.2016.2546880 View in ScopusGoogle Scholar Draves et al., 2004 Draves, R., Padhye, J., Zill, B., 2004. Routing in multi-radio, multi-hop wireless mesh networks. In: Proceedings of the 10th annual international conference on Mobile computing and networking - MobiCom ’04, ACM Press, New York, New York, USA, p. 114. doi:10.1145/1023720.1023732. Google Scholar Du and Roussos, 2011 Du, P., Roussos, G., Adaptive channel hopping for wireless sensor networks. In: Mobile and Wireless Networking (iCOST), 2011 International Conference on Selected Topics in, 2011, pp. 19–23. doi:10.1109/iCOST.2011.6085828. Google Scholar Du and Roussos, 2013 Du, P., Roussos, G., 2013. Spectrum-aware wireless sensor networks. In: 2013 IEEE Proceedings of the 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC), pp. 2321–2325. doi:10.1109/PIMRC.2013.6666532. Google Scholar Du et al., 2015 W. Du, D. Navarro, F. Mieyeville Performance evaluation of IEEE 802.15.4 sensor networks in industrial applications Int. J. Commun. Syst., 28 (10) (2015), pp. 1657-1674, 10.1002/dac.2756 View in ScopusGoogle Scholar Dunkels et al., 2006 Dunkels, A., Schmidt, O., Voigt, T., Ali, M., 2006. Protothreads: simplifying event-driven programming of memory-constrained embedded systems. In: Proceedings of the 4th international conference on Embedded networked sensor systems - SenSys '06, ACM Press, pp. 29. doi:10.1145/1182807.1182811. Google Scholar Dunkels, Dunkels, A. The ContikiMAC Radio Duty Cycling Protocol, SICS Technical Report T2011:13. URL 〈http://soda.swedish-ict.se/5128/1/contikimac-report.pdf〉. Google Scholar Durresi, 2005 Durresi, A., 2005. Architectures for Heterogeneous Wireless Sensor Networks Invited Paper. In: 2005 IEEE Proceedings of the 16th International Symposium on Personal, Indoor and Mobile Radio Communications, vol. 2, IEEE, pp. 1289–1296. doi:10.1109/PIMRC.2005.1651649. Google Scholar Eady, 2007 Eady, F., 2007. Keep Running. In: Hands-On ZigBee, Elsevier, pp. 23–42. doi:10.1016/B978-012370887-8/50004-3. Google Scholar Ehsan and Hamdaoui, 2012 S. Ehsan, B. Hamdaoui A Survey on energy-efficient routing techniques with QoS assurances for wireless multimedia sensor networks IEEE Commun. Surv. Tutor., 14 (2) (2012), pp. 265-278, 10.1109/SURV.2011.020211.00058 View in ScopusGoogle Scholar Erdelj et al., 2013 Erdelj, M., Mitton, N., Natalizio, E., 2013. Applications of Industrial Wireless Sensor Networks. URL 〈http://www.crcnetbase.com/doi/abs/10.1201/b14072-2doi:10.1201/b14072-2〉. Google Scholar Eriksson et al., 2009 Eriksson, J., Österlind, F., Finne, N., Tsiftes, N., Dunkels, A., Voigt, T., Sauter, R., Marrón, P.J., 2009. COOJA/MSPSim: interoperability testing for wireless sensor networks. In: Proceedings of the Second International ICST Conference on Simulation Tools and Techniques, ICST, doi:10.4108/ICST.SIMUTOOLS2009.5637. Google Scholar Eskola and Heikkilä, 2016 M. Eskola, T. Heikkilä Classification of Radio Channel disturbances for industrial wireless sensor networks Ad Hoc Netw., 42 (2016), pp. 19-33, 10.1016/j.adhoc.2016.01.001 View PDFView articleView in ScopusGoogle Scholar Flammini et al., 2009 A. Flammini, D. Marioli, E. Sisinni, A. Taroni Design and implementation of a wireless fieldbus for plastic machineries IEEE Trans. Ind. Electron., 56 (2009), pp. 747-755 View in ScopusGoogle Scholar Fonseca et al., Fonseca, R., Gnawali, O., Jamieson, K., Kim, S., Levis, P., Woo, A., 2009. TEP 123: The Collection Tree Protocol, TinyOS Community. URL 〈http://www.btnode.ethz.ch/static_docs/tinyos-2.x/pdf/tep123.pdf〉. Google Scholar Fonseca et al., 2007 Fonseca, R., Gnawali, O., Jamieson, K., Levis, P., 2007. Four-bit wireless link estimation. In: Proceedings of the Sixth ACM Workshop on Hot Topics in Networks (HotNets-VI). Google Scholar Foundation, 2007 Foundation, H.C., HART Field Communication Protocol Specification, Revision 7.0, 2007. Google Scholar Fragkiadakis et al., 2013 A.G. Fragkiadakis, E.Z. Tragos, I.G. Askoxylakis A survey on security threats and detection techniques in cognitive radio networks IEEE Commun. Surv. Tutor., 15 (1) (2013), pp. 428-445, 10.1109/SURV.2011.122211.00162 View in ScopusGoogle Scholar Franchino and Buttazzo, 2017 G. Franchino, G. Buttazzo A power-aware {MAC} layer protocol for real-time communication in wireless embedded systems J. Netw. Comput. Appl., 82 (2017), pp. 21-34 View PDFView articleView in ScopusGoogle Scholar Gaddour and Koubâa, 2012 O. Gaddour, A. Koubâa RPL in a nutshell: a survey Comput. Netw., 56 (14) (2012), pp. 3163-3178, 10.1016/j.comnet.2012.06.016 View PDFView articleView in ScopusGoogle Scholar Gajski et al., 2009 D.D. Gajski, S. Abdi, A. Gerstlauer, G. Schirner Embedded System Design Springer, US (2009), 10.1007/978-1-4419-0504-8 Google Scholar Gomes et al., 2015 R. Gomes, I. Fonseca, M. Alencar Protocolos multicanais para redes de sensores sem fio industriais Rev. De. Tecnol. da Inf. e Comun., 5 (2) (2015), pp. 25-32, 10.12721/2237-5112/rtic.v5n2p25-32 Google Scholar Gomes et al., 2017 R.D. Gomes, D.V. Queiroz, I.E. Fonseca, M.S. Alencar A simulation model for industrial multi-channel Wireless Sensor Networks J. Commun. Inf. Syst., 32 (1) (2017), pp. 29-40, 10.14209/jcis.2017.4 Google Scholar Gomes et al., 2017 R.D. Gomes, D.V. Queiroz, A.C. Lima Filho, I.E. Fonseca, M.S. Alencar Real-time link quality estimation for industrial wireless sensor networks using dedicated nodes Ad. Hoc. Networks (2017), 10.1016/j.adhoc.2017.02.007 Google Scholar Gomes et al., 2017 Gomes, R.D., Alencar, M.S., Queiroz, D.V., Fonseca, I.E., Benavente-Peces, C., 2017c. Comparison Between Channel Hopping and Channel Adaptation for Industrial Wireless Sensor Networks. In: Proceedings of the 6th International Conference on Sensor Networks (Sensornets). Google Scholar Goyal and Tripathy, 2012 Goyal, D., Tripathy, M.R., 2012. Routing Protocols in Wireless Sensor Networks: A Survey. In: 2012 Proceedings of the Second International Conference on Advanced Computing&Communication Technologies, IEEE, pp. 474–480. doi:10.1109/ACCT.2012.98. Google Scholar Grimaldi et al., 2016 Grimaldi, S., Gidlund, M., Lennvall, T., Barac, F., 2016. Detecting communication blackout in industrial Wireless Sensor Networks. In: 2016 IEEE World Conference on Factory Communication Systems (WFCS), IEEE, pp. 1–8. doi:10.1109/WFCS.2016.7496502. Google Scholar Grsu et al., 2016 Grsu, M., Vilgelm, M., Zoppi, S., Kellerer, W., 2016. Reliable co-existence of 802.15.4e tsch-based wsn and wi-fi in an aircraft cabin. In: 2016 IEEE International Conference on Communications Workshops (ICC), pp. 663–668. doi:10.1109/ICCW.2016.7503863. Google Scholar Gungor and Hancke, 2009 V. Gungor, G. Hancke Industrial Wireless Sensor Networks: challenges, design principles, and technical approaches IEEE Trans. Ind. Electron., 56 (10) (2009), pp. 4258-4265, 10.1109/TIE.2009.2015754 View in ScopusGoogle Scholar Gungor and Hancke, 2013 V.C. Gungor, G.P. Hancke Industrial Wireless Sensor Networks: applications, Protocols, and Standards (1st edition), CRC Press, Inc. (2013) Google Scholar Gungor and Korkmaz, 2012 V.C. Gungor, M.K. Korkmaz Wireless link-quality estimation in smart grid environments Int. J. Distrib. Sens. Netw., 8 (2) (2012), p. 214068, 10.1155/2012/214068 View in ScopusGoogle Scholar Guo et al., 2012 W. Guo, W.M. Healy, M. Zhou Impacts of 2.4-GHz ISM Band Interference on IEEE 802.15.4 Wireless Sensor Network Reliability in Buildings IEEE Trans. Instrum. Meas., 61 (9) (2012), pp. 2533-2544, 10.1109/TIM.2012.2188349 View in ScopusGoogle Scholar Hahm et al., Hahm, O., Baccelli, E., Petersen, H., Tsiftes, N., Operating Systems for Low-End Devices in the Internet of Things: a Survey, IEEE Internet of Things Journal doi:10.1109/JIOT.2015.2505901. Google Scholar Han et al., 2011 Han, S., Zhu, X., Mok, A.K., Chen, D., Nixon, M., 2011. Reliable and Real-Time Communication in Industrial Wireless Mesh Networks. In: 2011 Proceedings of the 17th IEEE Real-Time and Embedded Technology and Applications Symposium, IEEE, pp. 3–12. doi:10.1109/RTAS.2011.9. Google Scholar Hao et al., 2012 J. Hao, B. Zhang, H. Mouftah Routing protocols for duty cycled wireless sensor networks: a survey IEEE Commun. Mag., 50 (12) (2012), pp. 116-123, 10.1109/MCOM.2012.6384460 View in ScopusGoogle Scholar HART Communication, HART Communication–Application Guide [Online–Accessed in 07-July-2017]. URL 〈https://www.fieldcommgroup.org/sites/default/files/technologies/hart/ApplicationGuide_r7.1.pdf〉. Google Scholar Hashemi et al., 1994 H. Hashemi, M. McGuire, T. Vlasschaert, D. Tholl Measurements and modeling of temporal variations of the indoor radio propagation channel IEEE Trans. Veh. Technol., 43 (3) (1994), pp. 733-737, 10.1109/25.312774 View in ScopusGoogle Scholar Hashemi, 1993 H. Hashemi The indoor radio propagation channel Proc. IEEE, 81 (7) (1993), pp. 943-968, 10.1109/5.231342 View in ScopusGoogle Scholar Hill and Culler, 2002 J. Hill, D. Culler Mica: a wireless platform for deeply embedded networks IEEE Micro, 22 (6) (2002), pp. 12-24, 10.1109/MM.2002.1134340 View in ScopusGoogle Scholar Hong et al., 2015 Hong, S., Hu, X.S., Gong, T., Han, S., 2015. On-Line Data Link Layer Scheduling in Wireless Networked Control Systems. In: 2015 Proceedings of the 27th Euromicro Conference on Real-Time Systems, IEEE, pp. 57–66. doi:10.1109/ECRTS.2015.13. Google Scholar Hosni et al., 2016 Hosni, I., Theoleyre, F., Hamdi, N., 2016. Localized scheduling for end-to-end delay constrained Low Power Lossy networks with 6TiSCH. In: 2016 IEEE Symposium on Computers and Communication (ISCC), IEEE, pp. 507–512. 10.1109/ISCC.2016.7543789doi:10.1109/ISCC.2016.7543789. Google Scholar Huang et al., 2009 Y.-K. Huang, A.-C. Pang, H.-N. Hung A comprehensive analysis of low-power operation for beacon-enabled IEEE 802.15.4 wireless networks IEEE Trans. Wirel. Commun., 8 (11) (2009), pp. 5601-5611, 10.1109/TWC.2009.081485 View in ScopusGoogle Scholar Huang et al., 2013 P. Huang, L. Xiao, S. Soltani, M.W. Mutka, N. Xi The evolution of MAC protocols in Wireless Sensor Networks: a survey IEEE Commun. Surv. Tutor., 15 (1) (2013), pp. 101-120, 10.1109/SURV.2012.040412.00105 View in ScopusGoogle Scholar Huynh et al., 2017 T. Huynh, F. Theoleyre, W.-J. Hwang On the interest of opportunistic anycast scheduling for wireless low power lossy networks Comput. Commun., 104 (2017), pp. 55-66, 10.1016/j.comcom.2016.06.001 View PDFView articleView in ScopusGoogle Scholar Incel, 2011 O.D. Incel A survey on multi-channel communication in wireless sensor networks Comput. Netw., 55 (13) (2011), pp. 3081-3099, 10.1016/j.comnet.2011.05.020 View PDFView articleView in ScopusGoogle Scholar Instruments, 2004 Instruments, T., 2004. MSP430×1xx Family User’s Guide, Texas Instruments product documentation. Google Scholar Instruments, 2009 Instruments, T., 2009. CC1000 Single Chip Very Low Power RF Transceiver, Chipcon Product Data Sheet, URL 〈http://www.ti.com/lit/ds/symlink/cc1000.pdf〉. Google Scholar Instruments, 2014 Instruments, T., 2014. CC2420 IEEE 802.15.4 2.4 GHz Zigbee RF Transceiver, Chipcon Product Data Sheet. URL 〈http://www.ti.com/lit/ds/symlink/cc2420.pdf〉. Google Scholar Iqbal et al., 2017 Z. Iqbal, K. Kim, H.-N. Lee A Cooperative Wireless Sensor Network for indoor industrial monitoring IEEE Trans. Ind. Inform., 13 (2) (2017), pp. 482-491, 10.1109/TII.2016.2613504 View in ScopusGoogle Scholar Jeong and Lee, 2012 Jeong, W.-C., Lee, J., 2012. Performance evaluation of ieee 802.15.4e dsme mac protocol for wireless sensor networks. In: Enabling Technologies for Smartphone and Internet of Things (ETSIoT), 2012 Proceedings of the First IEEE Workshop on, pp. 7–12. doi:10.1109/ETSIoT.2012.6311258. Google Scholar Juc et al., 2016 Juc, I., Alphand, O., Guizzetti, R., Favre, M., Duda, A., 2016. Energy consumption and performance of ieee 802.15.4e tsch and dsme. In: 2016 IEEE Wireless Communications and Networking Conference, pp. 1–7. doi:10.1109/WCNC.2016.7565006. Google Scholar Kabara and Calle, 2012 J. Kabara, M. Calle MAC protocols used by wireless sensor networks and a general method of performance evaluation Int. J. Distrib. Sens. Netw., 2012 (2012), pp. 1-11, 10.1155/2012/834784 Google Scholar Karl and Willig, 2005 H. Karl, A. Willig Protocols and Architectures for Wireless Sensor Networks Wiley (2005) Google Scholar Kawadia and Kumar, 2005 V. Kawadia, P. Kumar A cautionary perspective on cross-layer design IEEE Wirel. Commun., 12 (1) (2005), pp. 3-11, 10.1109/MWC.2005.1404568 View in ScopusGoogle Scholar Khanafer et al., 2014 M. Khanafer, M. Guennoun, H.T. Mouftah A Survey of Beacon-Enabled IEEE 802.15.4 MAC protocols in Wireless Sensor Networks IEEE Commun. Surv. Tutor., 16 (2) (2014), pp. 856-876, 10.1109/SURV.2013.112613.00094 View in ScopusGoogle Scholar Kim et al., 2008 Kim, A.N., Hekland, F., Petersen, S., Doyle, P., 2008. When HART goes wireless: Understanding and implementing the WirelessHART standard. In: 2008 IEEE International Conference on Emerging Technologies and Factory Automation, IEEE, pp. 899–907.doi:10.1109/ETFA.2008.4638503. Google Scholar Kim et al., 2008 Kim, Y., Shin, H., Cha, H., 2008. Y-MAC: An Energy-Efficient Multi-channel MAC Protocol for Dense Wireless Sensor Networks. In: 2008 International Conference on Information Processing in Sensor Networks (ipsn 2008), IEEE, pp. 53–63. doi:10.1109/IPSN.2008.27. Google Scholar Kiyumi et al., 2015 Kiyumi, R.A., Vural, S., Chuan Heng Foh, Tafazolli, R., 2015. A distributed sleep mechanism for energy-efficiency in non-beacon-enabled IEEE 802.15.4 networks. In: 2015 IEEE Proceedings of the 20th International Workshop on Computer Aided Modelling and Design of Communication Links and Networks (CAMAD), IEEE, pp. 237–241. doi:10.1109/CAMAD.2015.7390516. Google Scholar Ko et al., 2011 Ko, J., Eriksson, J., Tsiftes, N., Dawson-Haggerty, S., Terzis, A., Dunkels, A., Culler, D., 2011. Contikirpl and tinyrpl: Happy together. In: Proceedings of the workshop on Extending the Internet to Low power and Lossy Networks (IPSN 2011). Google Scholar Kumar et al., 2014 Kumar, A.A., S., Ovsthus, K., Kristensen, L.M., 2014. An Industrial Perspective on Wireless Sensor Networks - A Survey of Requirements, Protocols, and Challenges. IEEE Communications Surveys&Tutorials 16 (3) 1391–1412.doi:10.1109/SURV.2014.012114.00058. Google Scholar Lee and Jeong, 2012 Lee, J., Jeong, W.C., 2012. Performance analysis of ieee 802.15.4e dsme mac protocol under wlan interference. In: 2012 International Conference on ICT Convergence (ICTC), pp. 741–746. doi:10.1109/ICTC.2012.6387133. Google Scholar Lee, 2006 Jin-Shyan Lee Performance evaluation of IEEE 802.15.4 for low-rate wireless personal area networks IEEE Trans. Consum. Electron., 52 (3) (2006), pp. 742-749, 10.1109/TCE.2006.1706465 View in ScopusGoogle Scholar Lima-Filho et al., 2012 A.C. Lima-Filho, R.D. Gomes, M.O. Adissi, T.A. Borges da Silva, F.A. Belo, M.A. Spohn Embedded system integrated into a Wireless Sensor Network for online dynamic torque and efficiency monitoring in induction motors IEEE/ASME Trans. Mechatron., 17 (3) (2012), pp. 404-414, 10.1109/TMECH.2012.2187354 View in ScopusGoogle Scholar Lu and Gungor, 2009 Bin Lu, V. Gungor Online and remote motor energy monitoring and fault diagnostics Using Wireless Sensor Networks IEEE Trans. Ind. Electron., 56 (11) (2009), pp. 4651-4659, 10.1109/TIE.2009.2028349 View in ScopusGoogle Scholar MacLeod et al., 2005 MacLeod, H., Loadman, C., Chen, Zhizhang, 2005. Experimental Studies of the 2.4-GHz IMS Wireless Indoor Channel. In: Proceedings of the 3rd Annual Communication Networks and Services Research Conference (CNSR'05), IEEE, pp. 63–68. doi:10.1109/CNSR.2005.33. Google Scholar Misic and Misic, 2008 Misic, J., Misic, V.B., 2008. Operation of the IEEE 802.15.4 Network. In: Wireless Personal Area Networks, John Wiley&Sons, Ltd, pp. 17–38. doi:10.1002/9780470986424.ch2. Google Scholar Monolithics, 2000 Monolithics, R.F., 2000. TR1000 916.50 MHz Hybrid Transceiver. Google Scholar Montenegro et al., 2010 Montenegro, G., Kushalnagar, N., Hui, J., Culler, D., 2010. Transmission of IPv6 Packets over IEEE 802.15.4 Networks. URL 〈http://tools.ietf.org/html/rfc4944〉. Google Scholar Municio and Latré, 2016 Municio, E., Latré, S., 2016. Decentralized broadcast-based scheduling for dense multi-hop TSCH networks. In: Proceedings of the Workshop on Mobility in the Evolving Internet Architecture - MobiArch ’16, ACM Press, New York, New York, USA, pp. 19–24. doi:10.1145/2980137.2980143. Google Scholar Muraoka et al., 2016 K. Muraoka, T. Watteyne, N. Accettura, X. Vilajosana, K.S.J. Pister Simple distributed scheduling with collision detection in TSCH networks IEEE Sens. J., 16 (15) (2016), pp. 5848-5849, 10.1109/JSEN.2016.2572961 View in ScopusGoogle Scholar Nixon, 2012 M. Nixon A Comparison of WirelessHART and ISA100.11a Tech. Rep. URL. (2012) https://www.controlglobal.com/assets/12WPpdf/120904-emerson-wirelesshart-isa.pdf Google Scholar Obaidat and Misra, 2015 M.S. Obaidat, S. Misra Principles of Wireless Sensor Networks Cambridge University Press (2015) Google Scholar Olofsson et al., 2016 T. Olofsson, A. Ahlen, M. Gidlund Modeling of the fading statistics of Wireless Sensor Network channels in industrial environments IEEE Trans. Signal Process., 64 (12) (2016), pp. 3021-3034, 10.1109/TSP.2016.2539142 View in ScopusGoogle Scholar Palattella et al., 2013 M.R. Palattella, N. Accettura, X. Vilajosana, T. Watteyne, L.A. Grieco, G. Boggia, M. Dohler Standardized protocol stack for the internet of (important) things IEEE Commun. Surv. Tutor., 15 (3) (2013), pp. 1389-1406, 10.1109/SURV.2012.111412.00158 View in ScopusGoogle Scholar Pantazis et al., 2013 N.A. Pantazis, S.A. Nikolidakis, D.D. Vergados Energy-efficient routing protocols in Wireless Sensor Networks: a survey IEEE Commun. Surv. Tutor., 15 (2) (2013), pp. 551-591, 10.1109/SURV.2012.062612.00084 View in ScopusGoogle Scholar Paso et al., 2013 Paso, T., Haapola, J., Iinatti, J., 2013. Feasibility study of IEEE 802.15.4e DSME utilizing IR-UWB and S-Aloha. In: 2013 IEEE Proceedings of the 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC), IEEE, pp. 1863–1867. doi:10.1109/PIMRC.2013.6666446. Google Scholar Patil and Biradar, 2012 Patil, M., Biradar, R.C., 2012. A survey on routing protocols in Wireless Sensor Networks. In: 2012 Proceedings of the 18th IEEE International Conference on Networks (ICON), IEEE, pp. 86–91. doi:10.1109/ICON.2012.6506539. Google Scholar Patti and Lo Bello, 2016 G. Patti, L. Lo Bello A priority-aware multichannel adaptive framework for the IEEE 802.15.4e-LLDN IEEE Trans. Ind. Electron., 63 (10) (2016), pp. 6360-6370, 10.1109/TIE.2016.2573754 View in ScopusGoogle Scholar Patti et al., 2014 Patti, G., Alderisi, G., Bello, L.L., 2014. Introducing multi-level communication in the IEEE 802.15.4e protocol: The MultiChannel-LLDN. In: Proceedings of the 2014 IEEE Emerging Technology and Factory Automation (ETFA), IEEE, pp. 1–8. doi:10.1109/ETFA.2014.7005204. Google Scholar Petersen and Carlsen, 2011 S. Petersen, S. Carlsen WirelessHART versus ISA100.11a: the format war hits the factory floor IEEE Ind. Electron. Mag., 5 (4) (2011), pp. 23-34, 10.1109/MIE.2011.943023 View in ScopusGoogle Scholar Pister and Doherty, 2008 Pister, K.S.J., Doherty, L., 2008. Tsmp: Time synchronized mesh protocol. In: In Proceedings of the IASTED International Symposium on Distributed Sensor Networks (DSN08). Google Scholar Proakis, 1995 J. Proakis Digital Communications McGraw-Hill (1995) Google Scholar Quang and Kim, 2012 P.T.A. Quang, D.-S. Kim Enhancing real-time delivery of gradient routing for industrial Wireless Sensor Networks IEEE Trans. Ind. Inform., 8 (1) (2012), pp. 61-68, 10.1109/TII.2011.2174249 View in ScopusGoogle Scholar Quang and Kim, 2014 Pham Trab Anh Quang, Dong-Seong Kim Throughput-aware routing for industrial sensor networks: application to ISA100.11a IEEE Trans. Ind. Inform., 10 (1) (2014), pp. 351-363, 10.1109/TII.2013.2255617 View in ScopusGoogle Scholar Queiroz et al., 2017 Queiroz, D.V., Gomes, R.D., Benavente-Peces, C., 2017. Performance Evaluation of Default Active Message Layer (AM) and TKN15.4 Protocol Stack in TinyOS 2.1.2. In: Proceedings of the 6th International Conference on Sensor Networks, SCITEPRESS - Science and Technology Publications, pp. 69–79. doi:10.5220/0006204200690079. Google Scholar Rappaport, 2001 T. Rappaport Wireless Communications: Principles and Practice (2nd edition), Prentice Hall PTR (2001) Google Scholar Rathnayaka and Potdar, 2013 A.J.D. Rathnayaka, V.M. Potdar Review: wireless sensor network transport protocol: a critical review J. Netw. Comput. Appl., 36 (1) (2013), pp. 134-146, 10.1016/j.jnca.2011.10.001 View PDFView articleView in ScopusGoogle Scholar Rekik et al., 2015 Rekik, S., Baccour, N., Jmaiel, M., Drira, K., 2015. Low-Power link quality estimation in smart grid environments. In: 2015 International Wireless Communications and Mobile Computing Conference (IWCMC), IEEE, pp. 1211–1216. doi:10.1109/IWCMC.2015.7289255. Google Scholar Rekik et al., 2016 Rekik, S., Baccour, N., Jmaiel, M., Drira, K., 2016. Holistic link quality estimation-based routing metric for RPL networks in smart grids. In: 2016 IEEE Proceedings of the 27th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC), IEEE, pp. 1–6. doi:10.1109/PIMRC.2016.7794925. Google Scholar Rezha and Shin, 2014 F.P. Rezha, Soo Young Shin Performance analysis of ISA100.11a under interference from an IEEE 802.11b wireless network IEEE Trans. Ind. Inform., 10 (2) (2014), pp. 919-927, 10.1109/TII.2014.2307016 View in ScopusGoogle Scholar Sahoo et al., Sahoo, P.K., Pattanaik, S.R., Wu, S.-L. A novel ieee 802.15.4e dsme mac for wireless sensor networks. Sensors 17 (1). URL 〈http://www.mdpi.com/1424–8220/17/1/168 doi:10.3390/s17010168〉. Google Scholar Saifullah et al., 2014 A. Saifullah, Y. Xu, C. Lu, Y. Chen Distributed channel allocation protocols for Wireless Sensor Networks IEEE Trans. Parallel Distrib. Syst., 25 (9) (2014), pp. 2264-2274, 10.1109/TPDS.2013.185 View in ScopusGoogle Scholar Sempere-Paya et al., 2016 Sempere-Paya, V., Silvestre-Blanes, J., Todoli, D., Valls, M., Santonja, S., 2016. Evaluation of TSCH scheduling implementations for real WSN applications. In: 2016 IEEE Proceedings of the 21st International Conference on Emerging Technologies and Factory Automation (ETFA), IEEE, pp. 1–4. doi:10.1109/ETFA.2016.7733642. Google Scholar Serizawa et al., 2017 Y. Serizawa, R. Fujiwara, T. Yano, M. Miyazaki Reliable wireless communication technology of adaptive channel diversity (acd) method based on isa100.11a standard IEEE Trans. Ind. Electron., 64 (1) (2017), pp. 624-632, 10.1109/TIE.2016.2605619 View in ScopusGoogle Scholar Sexton et al., 2005 Sexton, D., Mahony, M., Lapinski, M., Werb, J., 2005. Radio Channel Quality in Industrial Wireless Sensor Networks. In: 2005 Sensors for Industry Conference, IEEE, pp. 88–94. doi:10.1109/SICON.2005.257875. Google Scholar Shafiullah Khanet al., 2013 Shafiullah Khan Al-Sakib Khan Pathan, Alrajeh, N.A., 2013. Wireless Sensor Networks: Current Status and Future Trends, CRC Press. Google Scholar Silva and Guedes, 2014 Silva, I., Guedes, L., 2014. IEC 62601: Wireless Networks for Industrial Automation - Process Automation (WIA-PA), pp. 1–17. doi:10.1201/b17365-41. Google Scholar Silva et al., Silva, I., Lopes, D., Duarte, A., Affonso, L., Aquino, L., Saito, K., 2013. Emerging Technologies For Wireless Industrial Networks: WirelessHART vs ISA100.11a (Portuguese), VII Congress Rio Automation. URL 〈http://www.dca.ufrn.br/~ivan/Artigos/rioautomacao.pdf〉. Google Scholar Sohraby et al., 2007 K. Sohraby, D. Minoli, T. Znati Wireless Sensor Networks: Technology, Protocols, and Applications Wiley (2007) Google Scholar Song et al., 2008 Song, J., Han, S., Mok, A., Chen, D., Lucas, M., Nixon, M., Pratt, W., 2008. WirelessHART: Applying Wireless Technology in Real-Time Industrial Process Control. In: 2008 IEEE Real-Time and Embedded Technology and Applications Symposium, IEEE, pp. 377–386. doi:10.1109/RTAS.2008.15. Google Scholar Soua and Minet, 2015 R. Soua, P. Minet Multichannel assignment protocols in wireless sensor networks: a comprehensive survey Pervasive Mob. Comput., 16 (2015), pp. 2-21, 10.1016/j.pmcj.2014.04.004 View PDFView articleView in ScopusGoogle Scholar Soyturk and Altilar, 2008 Soyturk, M., Altilar, D.T., 2008. Reliable real-time data acquisition for rapidly deployable mission-critical Wireless Sensor Networks. In: IEEE INFOCOM 2008 - IEEE Conference on Computer Communications Workshops, IEEE, pp. 1–6. doi:10.1109/INFOCOM.2008.4544659. Google Scholar Standard, 2009 I. 100.11a 2009 Standard, Wireless Systems for Industrial Automation: Process Control and Related Applications, 2009. Google Scholar Stenumgaard et al., 2012 P. Stenumgaard, J. Ferrer-Coll, P. Ängskog, J. Chilo Characterisation of highly absorbent and highly reflective radio wave propagation environments in industrial applications IET Commun., 6 (15) (2012), pp. 2404-2412, 10.1049/iet-com.2012.0028 Google Scholar Stenumgaard et al., 2013 P. Stenumgaard, J. Chilo, J. Ferrer-Coll, P. Angskog Challenges and conditions for wireless machine-to-machine communications in industrial environments IEEE Commun. Mag., 51 (6) (2013), pp. 187-192, 10.1109/MCOM.2013.6525614 View in ScopusGoogle Scholar Suriyachai et al., 2012 P. Suriyachai, U. Roedig, A. Scott A survey of MAC protocols for mission-critical applications in Wireless Sensor Networks IEEE Commun. Surv. Tutor., 14 (2) (2012), pp. 240-264, 10.1109/SURV.2011.020211.00036 View in ScopusGoogle Scholar Tang et al., 2011 Tang, L., Sun, Y., Gurewitz, O., Johnson, D.B., 2011. EM-MAC. In: Proceedings of the Twelfth ACM International Symposium on Mobile Ad Hoc Networking and Computing - MobiHoc ’11, ACM Press, New York, New York, USA, 2011, p. 1. doi:10.1145/2107502.2107533. Google Scholar Tanghe et al., 2008 E. Tanghe, W. Joseph, L. Verloock, L. Martens, H. Capoen, K. Herwegen, W. Vantomme The industrial indoor channel: large-scale and temporal fading at 900, 2400, and 5200 MHz IEEE Trans. Wirel. Commun., 7 (7) (2008), pp. 2740-2751, 10.1109/TWC.2008.070143 View in ScopusGoogle Scholar Tavakoli et al., 2016 Tavakoli, R., Nabi, M., Basten, T., Goossens, K., 2016. An Experimental Study of Cross-Technology Interference in In-Vehicle Wireless Sensor Networks. In: Proceedings of the 19th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems - MSWiM ’16, ACM Press, New York, New York, USA, pp. 195–204. doi:10.1145/2988287.2989141. Google Scholar Teng and Kim, 2010 Z. Teng, K.-I. Kim A survey on real-time MAC protocols in Wireless Sensor Networks Commun. Netw., 2 (2) (2010), pp. 104-112, 10.4236/cn.2010.22017 Google Scholar Tennina et al., 2013 Tennina, S., Koubâa, A., Daidone, R., Alves, M., Jurčík, P., Severino, R., Tiloca, M., Hauer, J.-H., Pereira, N., Dini, G., Bouroche, M., Tovar, E., 2013. IEEE 802.15.4 and ZigBee as Enabling Technologies for Low-Power Wireless Systems with Quality-of-Service Constraints, SpringerBriefs in Electrical and Computer Engineering, Springer Berlin Heidelberg. doi:10.1007/978-3-642-37368-8. Google Scholar Theoleyre and Papadopoulos, 2016 Theoleyre, F., Papadopoulos, G.Z., 2016. Experimental Validation of a Distributed Self-Configured 6TiSCH with Traffic Isolation in Low Power Lossy Networks. In: Proceedings of the 19th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems - MSWiM ’16, ACM Press, New York, New York, USA, pp. 102–110. doi:10.1145/2988287.2989133. Google Scholar Tripathi et al., 2010 Tripathi, J., de Olive, J.C., Vasseur, J.P., 2010. A performance evaluation study of RPL: Routing Protocol for Low power and Lossy Networks. In: 2010 Proceedings of the 44th Annual Conference on Information Sciences and Systems (CISS), IEEE, pp. 1–6. doi:10.1109/CISS.2010.5464820. Google Scholar Tunca et al., 2014 C. Tunca, S. Isik, M.Y. Donmez, C. Ersoy Distributed mobile sink routing for Wireless Sensor Networks: a survey IEEE Commun. Surv. Tutor., 16 (2) (2014), pp. 877-897, 10.1109/SURV.2013.100113.00293 View in ScopusGoogle Scholar Varela and Sanchez, 2001 M. Varela, M. Sanchez RMS delay and coherence bandwidth measurements in indoor radio channels in the UHF band IEEE Trans. Veh. Technol., 50 (2) (2001), pp. 515-525, 10.1109/25.923063 View in ScopusGoogle Scholar Wang and Jiang, Wang, Q., Jiang, J., Comparative Examination on Architecture and Protocol of Industrial Wireless Sensor Network Standards, IEEE Communications Surveys&Tutorials doi:10.1109/COMST.2016.2548360. Google Scholar Wang et al., 2005 Wang, C., Sohraby, K., Li, B., Tang, W., 2005. Issues of transport control protocols for wireless sensor networks. In: Proceedings of International Conference on Communications, Circuits and Systems (ICCCAS). Google Scholar Watteyne et al., 2012 T. Watteyne, X. Vilajosana, B. Kerkez, F. Chraim, K. Weekly, Q. Wang, S. Glaser, K. Pister OpenWSN: a standards-based low-power wireless development environment Trans. Emerg. Telecommun. Technol., 23 (5) (2012), pp. 480-493, 10.1002/ett.2558 View in ScopusGoogle Scholar Wehrle et al., 2010 Wehrle, K., Günes, M., Gross, J., 2010. Modeling and Tools for Network Simulation, Springer Berlin Heidelberg, doi:10.1007/978-3-642-12331-3. Google Scholar Will et al., 2009 Will, H., Schleiser, K., Schiller, J., 2009. A real-time kernel for wireless sensor networks employed in rescue scenarios. In: 2009 IEEE Proceedings of the 34th Conference on Local Computer Networks, IEEE, pp. 834–841. doi:10.1109/LCN.2009.5355049. Google Scholar Wu et al., 2008 Wu, Y., Stankovic, J.A., He, T., Lin, S., 2008. Realistic and Efficient Multi-Channel Communications in Wireless Sensor Networks. In: IEEE INFOCOM 2008 - Proceedings of the 27th Conference on Computer Communications, IEEE, pp. 1193–1201. doi:10.1109/INFOCOM.2008.175. Google Scholar Wu et al., 2016 Wu, C., Gunatilaka, D., Saifullah, A., Sha, M., 2016. Maximizing Network Lifetime of WirelessHART Networks under Graph Routing. In: International Conference on Internet of Things Design and Implementation. Google Scholar Xia et al., 2017 C. Xia, X. Jin, L. Kong, P. Zeng Bounding the demand of mixed-criticality industrial Wireless Sensor Networks IEEE Access, 5 (2017), pp. 7505-7516, 10.1109/ACCESS.2017.2654483 View in ScopusGoogle Scholar Xu et al., 2014 L.D. Xu, W. He, S. Li Internet of things in industries: a survey IEEE Trans. Ind. Inform., 10 (4) (2014), pp. 2233-2243, 10.1109/TII.2014.2300753 View in ScopusGoogle Scholar Yan et al., 2014 Hairong Yan, Yan Zhang, Zhibo Pang, Li Da Xu superframe planning and access latency of slotted MAC for industrial WSN in IoT environment IEEE Trans. Ind. Inform., 10 (2) (2014), pp. 1242-1251, 10.1109/TII.2014.2306776 View in ScopusGoogle Scholar Yu and Feng, 2009 Yu, Z., Feng, L., 2009. A Reliable Wireless Communication Protocol for Industrial Applications. In: 2009 Proceedings of the First International Conference on Information Science and Engineering, IEEE, pp. 2496–2499. doi:10.1109/ICISE.2009.147. Google Scholar Yu et al., 2017 K. Yu, M. Gidlund, J. Akerberg, M. Bjorkman Performance evaluations and measurements of the REALFLOW routing protocol in wireless industrial networks IEEE Trans. Ind. Inform., 13 (3) (2017), pp. 1410-1420, 10.1109/TII.2016.2587842 View in ScopusGoogle Scholar Zand et al., 2012 P. Zand, S. Chatterjea, K. Das, P. Havinga Wireless industrial monitoring and control networks: the journey so far and the road ahead J. Sens. Actuator Netw., 1 (3) (2012), pp. 123-152, 10.3390/jsan1020123 View in ScopusGoogle Scholar Zanjireh and Larijani, 2015 Zanjireh, M.M., Larijani, H., 2015. A Survey on Centralised and Distributed Clustering Routing Algorithms for WSNs. In: 2015 IEEE Proceedings of the 81st Vehicular Technology Conference (VTC Spring), IEEE, pp. 1–6. doi:10.1109/VTCSpring.2015.7145650. Google Scholar Zeng et al., 2015 W. Zeng, J. Zhang, Y. Li, P. Qu The study on media access control protocol for wireless network in library Int. J. Distrib. Sens. Netw., 11 (8) (2015), p. 792542, 10.1155/2015/792542 View in ScopusGoogle Scholar Zhan et al., 2016 Y. Zhan, Y. Xia, M. Anwar GTS size adaptation algorithm for IEEE 802.15.4 wireless networks Ad Hoc Netw., 37 (2016), pp. 486-498, 10.1016/j.adhoc.2015.09.012 View PDFView articleView in ScopusGoogle Scholar Zhao et al., 2012 Y.Z. Zhao, C. Miao, M. Ma, J.B. Zhang, C. Leung A survey and projection on medium access control protocols for wireless sensor networks ACM Comput. Surv., 45 (1) (2012), pp. 1-37, 10.1145/2379776.2379783 Google Scholar Zheng et al., 2016 T. Zheng, M. Gidlund, J. Akerberg WirArb: a New MAC protocol for time critical industrial wireless sensor network applications IEEE Sens. J., 16 (7) (2016), pp. 2127-2139, 10.1109/JSEN.2015.2504948 View in ScopusGoogle Scholar Zhong et al., 2010 Zhong, Tang, Mengjin, Cheng, Peng, Zeng, Hong. Wang, 2010. Real-time communication in WIA-PA industrial wireless networks. In: 2010 Proceedings of the 3rd International Conference on Computer Science and Information Technology, IEEE, pp. 600–605. doi:10.1109/ICCSIT.2010.5563532. Google Scholar Zhou et al., 2006 Zhou, G., Huang, C., Yan, T., He, T., Stankovic, J.A., Abdelzaher, T.F., 2006. MMSN: Multi-Frequency Media Access Control for Wireless Sensor Networks. In: Proceedings IEEE INFOCOM 2006. Proceedings of the 25TH IEEE International Conference on Computer Communications, IEEE, pp. 1–13. doi:10.1109/INFOCOM.2006.250. Google Scholar Cited by (77) Application of Artificial Immune Systems in Advanced Manufacturing 2022, Array Show abstract An overview on low energy wake-up radio technology: Active and passive circuits associated with MAC and routing protocols 2021, Journal of Network and Computer Applications Citation Excerpt : Environmental monitoring applications are mainly based on WSN which are worthy to perform the ability of a passive WuR method. It is a collaboration of many sensor nodes distributed all over a city (smart city Skouby and Lynggaard, 2014; Paradells et al., 2014) or it could be integrated into many other applications such as smart gate (Gamm et al., 2013), smart building (Benzaama et al., 2020; Grindvoll et al., 2012; Jacquemod et al., 2014; Queiroz et al., 2017), security systems (Jelicic et al., 2014; Magno et al., 2013), indoor localization (Simon et al., 2015; Zhang et al., 2011; Dai et al., 2013), WSN for urban area (Rashid and Rehmani, 2016), smart wildlife monitoring (Picco et al., 2015; Dressler et al., 2016b), green IoT (Deng et al., 2019), industrial internet of things (IIoT) (Lara et al., 2020), unmanned aerial vehicles/system (UAV/UAS) (Chen et al., 2019) (Toth and Jóźków, 2016) and many others. Another new sensor technology is the smart grid that includes communication, observation, control, and testing potentialities to the electricity grid in order to enhance the electricity reservoir chain. Show abstract Proactive fault-tolerant wireless mesh networks for mission-critical control systems 2021, Journal of Network and Computer Applications Citation Excerpt : Wireless networks provide a scalable and cost-effective solution for various Internet of Things (IoT) applications due to the prohibitively high cost and the practical difficulty of employing cables in a complex control environment (Kassab and Darabkh, 2020; Park et al., 2018; Elazhary, 2019). There is a strong pull from industrial control systems to apply wireless networks as critical infrastructure for enabling mission-critical control systems such as factory automation and power network protection (Luvisotto et al., 2019; Aalsalem et al., 2018; Queiroz et al., 2017). Mission-critical wireless networks must support the right decision at the right moment, even in the presence of unexpected congestion, network failures, or external manipulations of the environment (Park et al., 2018, 2021bib_Park_et_al_2018bib_Park_et_al_2021; Chakraborty et al., 2015). Show abstract A novel NSGA-II for coverage and connectivity aware sensor node scheduling in industrial wireless sensor networks 2020, Digital Signal Processing: A Review Journal Citation Excerpt : Over the last decade, wireless sensor networks (WSNs) have achieved enormous attention for their wide range of applications in multiple domains like large scale industries for monitoring various events, environment, agricultures, health care and surveillance [1]. Show abstract Rule-Driven Service Availability Assessment of Iwn with Dynamic Recovery Mechanism 2023, SSRN Fusion of Heterogeneous Industrial Wireless Networks: A Survey 2023, SSRN View all citing articles on Scopus Diego V. Queiroz received his BSc in Computer Science at University Center of João Pessoa (2005) and BSc in Technology of Computer Networks at Federal Institute of Education, Science and Technology of Paraíba (2008). He received his MSc in Informatics from Federal University of Paraíba (UFPB) in 2015, and currently is a Ph.D. student at Universidad Politécnica de Madrid and at Federal University of Campina Grande (UFCG). His research areas include: information security, computer networks, wireless communications and network simulators. Ruan D. Gomes received his B.S. degree in Computer Science from Federal University of Paraíba in 2010, his M.S. degree in Computer Science from Federal University of Campina Grande (UFCG) in 2012, and his D.Sc. degree in Electrical Engineering from UFCG in 2017. He currently works as a professor at the Federal Institute of Education, Science, and Technology of Paraíba, Campus Guarabira. He has experience in R&D projects, mainly in the fields of embedded systems, wireless sensor networks, and multimedia systems. Iguatemi E. Fonseca was born in Brazil, in 1974. He is currently an associate professor at the Informatics Center of the Federal University of Paraíba. He received the electronics engineering degree from the Federal University of Campina Grande (UFCG), Campina Grande, PB, Brazil, in 1999, and the M.Sc. and Ph.D. degrees from the State University of Campinas (Unicamp), Campinas, SP, Brazil, in 2001 and 2005, respectively, specializing in nonlinear fiber optics and its applications, optical network design with physical-layer impairments and Impairment-Aware RWA. His current research interests include areas of the Electrical Engineering and Computer Science as: i) Communications Networks (Optical Networks, Wireless Sensor Networks, Mobile Networks and IP Networks), working on topics as identification/models of traffic in computer networks, techniques for identification and mitigation of denial of service attacks, algorithms and protocols in Industrial Wireless Sensor Networks, WDM and elastic optical networks with QoS requirements, and design and simulation of photonics devices; ii) Design of simulators in virtual reality with applications in industry sectors, as energy sector. Marcelo S. Alencar was born in Serrita, Brazil in 1957. He received his Bachelor Degree in Electrical Engineering, from Universidade Federal de Pernambuco (UFPE), Brazil, 1980, his Master Degree from Universidade Federal da Paraíba (UFPB), Brazil, 1988 and his Ph.D. from the University of Waterloo, Department of Electrical and Computer Engineering, Canada, 1994. Marcelo S. Alencar has more than 35 years of engineering experience, and 26 years as an IEEE Member, currently as Senior Member. For 18 years he worked for the Department of Electrical Engineering, Federal University of Paraíba, where he was Full Professor and supervised more than 50 graduate and several undergraduate students. Since 2003, he is Chair Professor at the Department of Electrical Engineering, Federal University of Campina Grande, Brazil. He published 20 books and more than 420 papers in journals and conferences. He is columnist of the traditional newspaper Jornal do Commercio, in Recife, Brazil. Cesar Benavente-Peces is associate professor at the Universidad Politécnica de Madrid since 1991. He joined the Circuits and Systems Engineering Department at the E.U.I.T. Telecommunication in 1991, which became the ETS de Ingenieria y Sistemas de Telecomunicacion in 2014. Since 2014, he joined the Signal Theory and Communications Department. His research activity is developed in the Radio Engineering Research Group (GIRA) integrated with the Centro de Electronica Industrial (CEI) at the Universidad Politécnica de Madrid. Currently Prof. Benavente-Peces is coordinating the MSc. on Systems and Services Engineering for the Information Society. Highly involved in research project funded by public (regional, national and European calls) and contracts with the industry. Specialties: communication systems, MIMO systems, carrier and bit synchronization in digital modems, signal processing in communication systems, location based services and applications, applications integration, wireless sensor networks. 1 https://datatracker.ietf.org/wg/roll/. Access: 17/07/2017. 2 https://tools.ietf.org/html/rfc6550. Access: 17/07/2017. 3 http://tools.ietf.org/html/draft-gnawali-roll-etxof-00. Access: 17/07/2017. 4 http://code.google.com/archive/p/ctp-castalia/. Access: 17/07/2017. 5 A Proportional-Integral-Derivative controller (PID controller) is a control loop feedback mechanism (controller) commonly used in industrial control systems. 6 TR-069 (Technical Report 069) is a technical specification that defines an application layer protocol for remote management of end-user devices. 7 IPv6 over the TSCH mode. 8 https://www.ipso-alliance.org/. Access:17/07/2017. 9 http://www.nsnam.org/wiki/Lr-wpan. Access:17/07/2017. View Abstract © 2017 Elsevier Ltd. All rights reserved. Recommended articles Distributed cell selection for scheduling function in 6TiSCH networks Computer Standards & Interfaces, Volume 53, 2017, pp. 80-88 Thang Phan Duy, …, Younghan Kim View PDF An energy-efficient fault-aware core mapping in mesh-based network on chip systems Journal of Network and Computer Applications, Volume 105, 2018, pp. 79-87 Naresh Kumar Reddy Beechu, …, Nithin Kumar Yernad Balachandra View PDF Reliability modeling and analysis of communication networks Journal of Network and Computer Applications, Volume 78, 2017, pp. 191-215 Waqar Ahmad, …, Junaid Qadir View PDF Show 3 more articles Article Metrics Citations Citation Indexes: 71 Patent Family Citations: 1 Captures Readers: 171 Social Media Shares, Likes & Comments: 2 View details About ScienceDirect Remote access Shopping cart Advertise Contact and support Terms and conditions Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply."

Paper 3:
- APA Citation: Higashiura, Y., & Yamamoto, H. (2021). Large-scale farm sensing system using UAV and long-distance wireless communication. In 2021 International Conference on Information Networking (ICOIN) (pp. 1-6). IEEE.
  Main Objective: To design and evaluate a network system that utilizes UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands.
  Study Location: Unspecified
  Data Sources: Environmental data collected from sensor nodes
  Technologies Used: UAVs, LoRa communication, Sensor networks, Hamming code, TDMA, CSMA
  Key Findings: The proposed system can efficiently collect environmental data from a large network of sensor nodes distributed across vast farmland.
The use of UAVs as mobile gateways optimizes data collection and reduces travel distance and time.
The implementation of clustering and representative nodes further enhances data retrieval efficiency.
The utilization of a Hamming code ensures data integrity during transmission.
  Extract 1: "In this study, we have proposed a network system that can efficiently collect environmental information by moving the UAV with the function of the gateway to the location where communication with multiple sensor nodes becomes stable."
  Extract 2: "In addition, we have proposed a new communication method of efficiently collecting data from the cluster of the sensor nodes with less radio interference."
  Limitations: The study does not address the potential costs associated with deploying and maintaining a system involving UAVs and sensor networks across vast farmlands.
The paper also does not provide detailed information on the specific energy consumption and battery life of the UAVs used in the system.
The study does not explore the potential security risks and vulnerabilities associated with wireless data transmission in agricultural settings.
  Relevance Evaluation: This paper is highly relevant to the point of investigation, which centers on the potential of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection in automated irrigation systems. The study introduces an innovative approach utilizing UAVs as mobile gateways to establish communication with sensor nodes and optimize data collection over vast farmlands. This approach holds significant implications for the efficient management of irrigation systems, particularly in remote or hard-to-reach areas, and aligns well with the broader objectives of the literature review.
  Relevance Score: 0.9
  Inline Citation: (Higashiura & Yamamoto, 2021)
  Explanation: This research study proposes a novel farm management system that harnesses Unmanned Aerial Vehicles (UAVs) and the LoRa communication protocol to efficiently collect environmental data from a large network of sensor nodes distributed across vast farmland. The system's design is centered around the UAV serving as a mobile gateway, autonomously searching for optimal positions where it can establish stable communication with multiple sensor nodes dispersed over the farm. To enhance data retrieval efficiency, the nodes organize themselves into smaller clusters, each with a designated representative node, thereby reducing the UAV's travel distance and data collection time. Furthermore, a Hamming code is utilized to ensure data integrity amidst potential bit errors during transmission.

 Full Text: >
"This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Conferences >2021 International Conference... Large-scale farm sensing system using UAV and long-distance wireless communication Publisher: IEEE Cite This PDF Yoshihiro Higashiura; Hiroshi Yamamoto All Authors 1 Cites in Paper 133 Full Text Views Abstract Document Sections I. Introduction II. Related Works and Objectives of Our Study III. Proposed Farm Management System IV. Collecting Data From Clusters V. Performance Evaluation Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: In recent years, countries where agriculture is a major industry own vast tracts of farmland, and IoT system to improve the efficiency of farming operations on the vast farmland are attracting attention. In order to collect environmental information from anyway of the vast farmland, the construction of sensor networks using LPWA that enables long-distance communication has been attracting attention. However, many obstacles such as crops and agricultural machinery on the farm makes long-distance wireless communication difficult even when using the LPWA. In addition, even when the clear line of sight from the sensor nodes is ensured, the radio waves may interfere with each other, which makes the gateway impossible to receive the sensor data correctly. Therefore, in this research, we develop a sensor network system using an Unmanned Aerial Vehicle (UAV) that can move freely in the sky. The UAV works as a gateway to collect the sensor data from the sensor nodes and move autonomously for searching the locations where they can maintain good communication property from sensor nodes dispersed over a wide area of a large farm. Furthermore, in order to improve the efficiency of the sensor data retrieval, the sensor nodes within the same area of the farm construct clusters and select one representative node in each cluster. In addition, in order to prevent radio interference caused by simultaneous data transmission, the sensor nodes are implements media access control mechanism for LPWA. Published in: 2021 International Conference on Information Networking (ICOIN) Date of Conference: 13-16 January 2021 Date Added to IEEE Xplore: 02 February 2021 ISBN Information: Print on Demand(PoD) ISSN: 1976-7684 DOI: 10.1109/ICOIN50884.2021.9333946 Publisher: IEEE Conference Location: Jeju Island, Korea (South) SECTION I. Introduction In recent years, countries where agriculture is a major industry (e.g., countries in Southeast Asia) own vast tracts of farmland, and especially, the farmland of Vietnam occupies more than one third of the total land area of the country. In these countries, IoT (Internet of Things) system to improve the efficiency of farming operations on the vast farmland are attracting attention. On the other hand, in order to collect environmental information related to the growth condition of crops from anyway of the vast farmland, the construction of sensor networks using LPWA (Low-Power Wide-Area) has been attracting attention. The LPWA enables long-distance communication with low power consumption because the frequency band with good propagation characteristics (920/429 MHz band) is used. However, it is difficult to maintain a clear line of sight between the gateway (i.e., the central point of the sensor networks) and the sensor nodes on farms where there are many obstacles such as crops and agricultural machinery, hence it makes long-distance wireless communication difficult even when using the LPWA. In addition, even when the clear line of sight from the sensor nodes is ensured, if a large number of sensor nodes transmit sensor data at a time of their choosing, the radio waves may interfere with each other, which makes the gateway impossible to receive the sensor data correctly. Therefore, in this study, we develop a sensor network system using an Unmanned Aerial Vehicle (UAV) that can move freely in the sky. In the proposed system, the UAV works as a gateway to collect the sensor data from the sensor nodes and move autonomously for searching the locations where they can maintain good communication property from sensor nodes dispersed over a wide area of a large farm. In addition, the sensor node transmits the sensor data to the UAV through LoRa communication which is one type of the LPWA. In order to improve the efficiency of the sensor data retrieval, the sensor nodes within the same area of the farm construct clusters and select one representative node in each cluster. The representative node aggregates the environmental information received from the other nodes in the clusters and sends the aggregated information to the gateway (i.e., UAV). Furthermore, in order to prevent radio interference caused by simultaneous data transmission from the multiple sensor nodes, the TDMA (Time Division Multiple Access)-based media access control mechanism is adapted. In this mechanism, different time slots are assigned to the sensor nodes in the same cluster so as to transmit the environmental information to the representative node at a different timing. In addition, when choosing representative node in the cluster, the sensor nodes implements CSMA (Carrier Sense Multiple Access)based media access control mechanism. In this mechanism, each sensor node checks communication status of other nodes before starting the communication and autonomously decides an appropriate timing for exchanging the metric of deciding the representative node with others for preventing the interference. Furthermore, an error-correcting code is leveraged to correctly transmit the information between the sensor nodes and gateway even when the bit error occurs during the data transmission. SECTION II. Related Works and Objectives of Our Study A. Management System using LoRa Communication In the existing studies, the environmental observation systems utilizing LoRa for agriculture have been proposed so far. The objective of the existing system is to collect environmental information from sensor nodes installed on farms using LoRa communication [2] [3] [4] [5] [6] [7]. In the reference of [2] [4] [5] [6], various kinds of sensor data (e.g., temperature, humidity, etc.) are simultaneously measured inside the greenhouse and are transmitted to the base station using the LoRa communication to manage the condition of the farm. However, in these existing studies, the authors have not assumed a realistic condition where there are various types of obstacles (e.g., crops, agricultural machinery) which interfere with the long distance communication of LoRa. B. Localization System using Received Signal Strength In existing studies, an object localization system based on received signal strength is proposed [8] [9]. Especially, in our previous study, Andon et al. have proposed a system in which a UAV autonomously searches for a distressed person carrying a beacon transmitter (i.e., LoRa-supported device) in a mountainous area [10]. In this system, the UAV measures signal strength of the radio waves and estimates the direction of the distressed person who owns the beacon devices. Here, the authors have clarified that the fuselage of the UAV blocks radio waves and the received signal strength of radio waves arriving from a specific direction becomes large. However, the existing localization system of the previous study is focusing on only a single beacon device and does not search for an appropriate position where the communication quality to the multiple sensor nodes becomes good. C. Objectives of This Study This study proposes a farm management system that uses UAVs and LoRa communication for efficiently obtains the environmental information from a large number of sensor nodes deployed on the vast farm. In the proposed system, the UAV works as a gateway which collects the environmental information from the sensor nodes, and autonomously searches points where the gateway can achieve stable communications with multiple sensor nodes. In addition, the proposed system constructs clusters with nearby sensor nodes and chooses a representative node of each cluster. This mechanism can reduce the traveling distance of the UAV because the UAV needs to communicate with only the representative nodes for obtaining all environmental information of the farm. Furthermore, a Hamming code is utilized to correctly transmit the information between the sensor node and the gateway even when the bit error occurs during the data transmission. Fig. 1. Overview of the Proposed System Show All SECTION III. Proposed Farm Management System An overview of the proposed system is shown in Fig. 1. The proposed system consists of a sensor node equipped with a variety of sensors and a communication module (LoRa mini) capable of LoRa communication, an embedded system (Raspberry Pi 3) that controls the UAV and works as a gateway of the sensor nodes, and an analysis server that analyzes the environmental information collected by the UAV. The embedded system is attached to the UAV and supports the LoRa communication for receiving environmental information from the sensor nodes. In addition, the LoRa communication is utilized for finding an appropriate position at which stable communication to multiple sensor nodes is possible by measuring the received signal strength of the radio wave from the sensor node. A. Functional/Device Configuration of Proposed system The embedded system installed in the UAV has two modes: search mode and communication mode. In the search mode, the embedded system attempts to move to the position where the stable communication with the clusters of the sensor nodes based on the signal strength of radio waves received from the representative node of each cluster. In the communication mode, the embedded system attempts to collect all environmental information of the farm by communicating with the representative nodes of the clusters. The detailed procedure of the search and communication modes are described in Section III-C. The UAV used in this study is the 3D Robotics’s Solo which has a maximum payload of 450 g, hence it is suitable for installation of the embedded system. The configuration of the UAV used in this study is shown in Fig. 2. The embedded system is connected to the UAV through Wi-Fi connection and controls the flight of UAV and works as a controller of the UAV so that the UAV is allowed to fly autonomously without being limited by the distance from the start point. The sensor nodes have the function of measuring environmental information and of transmitting the measured data to the gateway when receiving requests from embedded system on the UAV. In addition, the sensor nodes build the cluster by autonomously selecting the representative node from them. The device configuration of the sensor node is shown in Fig. 3. The sensor node in this study is mainly composed of the a LoRa-supported microcontroller, LoRa mini developed by Dragino. For obtaining the environmental information, a DHT11 temperature/humidity sensor, a TSL2561 illuminance sensor and a 10HS soil moisture sensor are connected to the microcontroller. Fig. 2. Configuration of UAV Show All Fig. 3. Configuration of Sensor Node Show All Fig. 4. Network Structure of Proposed System Show All B. Communication Methods for Sensor Data using LoRa The network structure of the proposed method is shown in Fig. 4. In the proposed method, the UAV is the central point of the sensor network and communicates with only the representative node of each cluster consisting of the nearby sensor nodes. The representative node has the ability to collect measurement data from the other sensor nodes of the same cluster and transmits the collected data to the gateway when the UAV gets close to the cluster. In this section, data communication procedure among the sensor nodes and the gateway on the UAV is explained. The detailed procedure of the cluster configuration and media access control mechanism of the sensor nodes are explained in Section IV. After approaching to the cluster, the gateway (i.e., embedded system) on the UAV broadcasts the data collection request to the representative nodes within the communication range. The request packet includes a 1-byte in which the token (e.g., ID of the representative node) indicating the start of communication is recorded. After that, the sensor node sends the measured data to the gateway through the representative node. Fig. 5. Structure of Packet Show All Fig. 6. Overview of the Positioning Algorithm Show All The structure of the data packet sent from the sensor node is shown in Fig. 5. In the proposed system, the environmental information is represented in 16 bits and 6 bits of inspection bits are added to the packet for detecting and correcting the error in the packet based on Hamming code. For transmitting four kinds of environmental information (i.e., temperature, humidity, etc.), the data packet consists of the total of 11 bytes (88 bits). The gateway cannot only detect errors in the packet received from the sensor node, but also correct up to one-bit error by using Humming code with an even parity check. If the error can be detected but not be corrected, the gateway sends a retransmission request to the sensor node. After receiving the data packet, the environmental information is obtained by removing the inspection bits and is stored on the database managed locally by the gateway until the UAV returns to the start point. C. Positioning Algorithm of UAV for Communicating with Representative Nodes First, the farm manager sets up the observation area and flight path of the UAV to move around the management terminal (e.g., smartphone application). After that, while moving based on the flight path, the UAV searches for a location where it can communicate with one or more representative nodes of the clusters. The following part of this section explains the method of searching for an appropriate location for communicating with the representative nodes. Here, the proposed method assumes that the UAV can arrive at the position where it can receive the radio signal from the representative nodes by the guidance based on the GPS location information. The overview of the positioning algorithm of the UAV is shown in Fig. 6. The first step of the positioning algorithm is to exchange the beacon with the representative nodes to measure the received signal strength of the radio wave from each node. When arriving at the position where it can communicate with the representative nodes, the UAV rotates clockwise from the current direction of travel and acquires the strength of the received signal with the representative node at each 45-degree rotation. The angle with the strongest received signal strength from each node is estimated as the direction that the good communication with the node is capable. Fig. 7. The Approach Algorithm of Multiple Node Show All Fig. 8. Example of TDMA-based Data Collection Show All The overview of the proposed approach for considering multiple representative nodes is shown in the Fig. 7. If there is only one representative node in the vicinity, it moves 10 meters to the direction in which the node is presumed to be present. On the other hand, when there are multiple representative nodes in the vicinity, all nodes are set as the target and the UAV moves to the middle angle of the directions to the target nodes. The UAV repeats these processes until it is confirmed that it has been moved to the appropriate position. SECTION IV. Collecting Data From Clusters A. Data Collection from Multiple Sensor Nodes using TDMA A procedure example of the TDMA-based data collection from the sensor nodes is shown in Fig. 8. A representative node obtains the environmental information from the sensor nodes in the cluster and transmits the aggregated information to the gateway on the UAV. Here, the representative node assigns a different time slot to the sensor nodes between each other by broadcasting a token packet and each sensor node sends its own environmental information to the representative node only at a timing of the assigned time slot in order to avoid collisions of the data transmission among nodes. The sensor nodes are assigned unique identifiers that are incremented one by one (i.e., 1, 2, 3, …) when constructing the cluster (see Section IV-B). When receiving the request packet from the representative node, the sensor node waits for ID×T [ms] before starting to send the environmental information to the representative node. T is a time interval of data transmission from the sensor nodes, so the representative node can complete to receive the information from all sensor nodes in N×T [ms], and N is the maximum number of sensor nodes that can coexist in the same cluster. Here, T should carefully be decided because the shorter T than the appropriate value may result in the occurrence of the collision but the longer T increases the data collection time. After the estimated waiting time (i.e., N×T [ms]) is passed, the representative node aggregates all the received information and transmits that to the gateway. Fig. 9. Example of CSMA Operation Show All B. Cluster Construction Method utilizing CSMA-based Data Exchange For constructing the cluster of the sensor nodes, the representative node needs to be determined. Here, in order to decrease the flight distance of the UAV, the sensor node which is the closest to the start point of the UAV is selected as the representative node. Therefore, the square of the distance between the start point and the sensor node is used as an evaluation value and the sensor node with the smallest value is selected as the representative node. For selecting the representative node, the sensor nodes in the cluster exchange the evaluation values among them. However, before selecting the representative node, the TDMA-based data transmission cannot be used for exchanging the evaluation value because there is no central point (i.e., representative node) which assigns a time slot to the sensor nodes and makes them to start sending the data. Therefore, the exchange of the evaluation value is based on the CSMA (Carrier Sense Multiple Access)-based technique. A behavior example of the CSMA-based data exchange is shown in Fig. 9. First, each sensor node confirms whether other sensor nodes are transmitting the evaluation value or not by confirming the status of the data reception of LoRa. If any other sensor node is not communicating, the sensor node starts to broadcast its evaluation values to the cluster (e.g., Cases of Node:A and Node:B in Fig. 9). On the contrary, if other nodes are communicating, the sensor node waits for the time interval determined by random numbers (e.g., Case of Node:C in Fig. 9). After the time interval is passed, it checks the reception status again. Each sensor node in the cluster waits for receiving the evaluation values from all other sensor nodes and compares its own evaluation value with that of other nodes. If its own evaluation value is the smallest in the cluster, the sensor node judges to be suitable for the representative node and broadcast the evaluation value again. If not receiving any response from other nodes within the predetermined timeout time, the sensor node starts to behave as the representative node in the cluster. Fig. 10. Example of Placement of the Sensor Nodes Show All SECTION V. Performance Evaluation A. Evaluation of Time Required for Receiving All Data and Packet Delivery Rate 1) Evaluation Setup: In order to evaluate effectiveness of our proposed data transmission methods, we prototype a sensor node supporting TDMA-based data collection method and CSMA-based cluster construction method. In this evaluation, we measure the packet loss rate for receiving the environmental information from all sensor nodes using TDMA, and that for exchanging the evaluation value among all sensor nodes. An example of the placement of the sensor nodes is shown in Fig. 10. Four sensor nodes are placed as shown in this figure, and one sensor node with red color is selected as the representative node. In this evaluation, we evaluate a packet loss rate during the data transmission between the sensor node that is selected as the representative node and the other nodes. In this experiment, each sensor node transmits packets 50 times and each packet includes data of 11 bytes by assuming environmental information. For the TDMA-based method, the time interval of each data transmission is set to 100ms, hence the representative node requires N×100[ ms] for receiving packets from all sensor nodes in each data transmission. In addition, for CSMA-based method, the random number R for calculating the waiting time is selected from 0 to 30, hence the sensor node waits for R×35[ ms] when detecting the data transmission from other nodes. This experimental evaluation is performed at a ground in a campus of Ritsumeikan University. 2) Evaluation Result: Figure 11 shows the relationship between the number of sensor nodes and the packet loss rate when using each media access control method. As shown in this figure, the data transmission without using the media access control results in a large number of packet losses when multiple sensor nodes send the packets simultaneously. On the other hand, the CSMA-based method markedly decreases the number of packet losses compared with the method without using the media access control, and the TDMA-based method can avoid occurrence of the packet losses regardless of the number of sensor nodes. Based on the evaluation result mentioned above, we have decided to use the TDMA-based method for the representative node to collect all environmental information from the sensor nodes because the data transmission can avoid occurrence of the packet losses. On the other hand, the representative node has not been selected when the cluster of the sensor nodes is being constructed, hence the CSMA-based method is adopted for exchanging the evaluation value among the sensor nodes. Fig. 11. Number of Sensor Nodes vs. Packet Loss Rate Show All Fig. 12. Experimental Situation Show All B. Performance Evaluation of Autonomous Flight Algorithm 1) Evaluation Setup: This experimental evaluation is being conducted to evaluate the accuracy of the UAV’s movement to a position where the UAV can stably communicate with the representative nodes. In this evaluation, the UAV conducts ten trials of searching the position using the proposed autonomous flight algorithm, and the number of times that the UAV can correctly complete the search process and the time required to complete the search process are evaluated. In addition, we compare the performance of the proposed algorithm with the simple existing algorithm that randomly selects the moving direction of the UAV and continues to move to the same direction until the received signal strength of the radio wave from the targets does not decrease. This experimental evaluation is performed at a playground in a campus of Ritsumeikan University. The experimental situation of the evaluation is shown in Fig. 12. In this evaluation, the representative nodes are installed at two locations in the ground, and the start point of the UAV with the embedded system is 60 meters away from the representative nodes. Here, when the distance between the UAV and the representative node is shorter than 25m, the signal strength become larger than -96dBm in this experiment. Therefore, we assume that the 25m is sufficiently close enough to stably communicate between the UAV and the representative nodes, and -96dBm is set to the threshold of the signal strength. When the average signal strength of the radio waves transmitted from the representative nodes and received by the embedded system exceeds the threshold, the system judges that it can approach the appropriate position where the communication with the representative nodes is stable and completes the search process. 2) Evaluation Result: The evaluation results of the proposed algorithm and the random flight algorithm are summarized in Teb. I and Teb. II. The “◯” in the table indicates that the average signal strength of received radio waves exceeds the indicates threshold that value the search and the is failed search because is completed, the UAV and could the “not ×” get close to the representative node due to dead of the battery. As shown in this table, the proposed algorithm can successfully complete the search process with higher accuracy than the simple algorithm. On the other hand, the random flight requires shorter time for detecting the appropriate position than the proposed algorithm when the search process is successfully completed because the random algorithm measures the signal strength of radio wave only once for deciding the flight direction. Figures 13 and 14 show examples of flight path of the proposed and random algorithms. As shown in these figures, the proposed algorithm always selects appropriate directions for approaching the representative nodes, but the random algorithm frequently selects wrong directions. Therefore, in the vast farm where the UAV can go straight for a long time once the direction of the flight is decided, the proposed algorithm may result in better performance in terms of the time required for detecting the suitable position than the random algorithm. Table I Flight Accuracy of Proposed Algorithm Table II Flight Accuracy of Random Algorithm Fig. 13. Flight Path of UAV Using Proposed Algorithm Show All Fig. 14. Flight Path of UAV Using Random Algorithm Show All SECTION VI. Conclusions In this study, we have proposed a network system that can efficiently collect environmental information by moving the UAV with the function of the gateway to the location where communication with multiple sensor nodes becomes stable. In addition, we have proposed a new communication method of efficiently collecting data from the cluster of the sensor nodes with less radio interference. In the evaluation experiments, we evaluated the number of times the proposed autonomous flight algorithm was used to successfully approach a sensor node and the time required for the approach to the sensor node and showed the effectiveness of the proposed algorithm. In the future, we will consider a prediction method of future environmental information such as soil moisture on the farm based on the environmental information collected by the UAV. In addition, we will create a function to notify farm managers of feedback on the ingredients required for crops from the estimation results. Acknowledgement This study was supported by JSPS KAKENHI Grant Number JP19H04103. Authors Figures References Citations Keywords Metrics More Like This Unmanned Aerial Vehicles in Agriculture: A Review of Perspective of Platform, Control, and Applications IEEE Access Published: 2019 Unmanned Aerial Vehicles in Smart Agriculture: Applications, Requirements, and Challenges IEEE Sensors Journal Published: 2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."

Paper 4:
- APA Citation: Mehdizadeh, S., Ahmadi, H., Etedali, H. R., & Karami, E. (2020). Wireless sensor networks for precision agriculture: A comprehensive review of applications and challenges. Computers and Electronics in Agriculture, 172, 105363.
  Main Objective: To evaluate the potential of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection in automated irrigation management systems.
  Study Location: Unspecified
  Data Sources: Literature review
  Technologies Used: Wireless sensor networks, energy-efficient communication protocols
  Key Findings: - Wireless sensor networks offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems. 

- Energy-efficient communication protocols can significantly extend the lifespan of sensor nodes and ensure reliable data transmission in challenging environmental conditions.

- Careful consideration of data accuracy, energy consumption, and network reliability is crucial for designing effective WSNs for irrigation management.
  Extract 1: "Wireless sensor networks (WSNs) have emerged as a promising technology for automated data collection in precision agriculture due to their ability to monitor various environmental parameters and crop conditions in real-time." This study evaluates the performance of different WSN technologies and identifies energy-efficient communication protocols to optimize data collection for large-scale, long-term monitoring.
  Extract 2: "By carefully considering the trade-offs between data accuracy, energy consumption, and network reliability, it is possible to design WSNs that can effectively collect and transmit data in real-time, enabling timely irrigation decisions and improved crop yields."
  Limitations: The study focuses primarily on the technical aspects of data collection and does not delve into the economic or social implications of implementing large-scale WSNs for irrigation management.
  Relevance Evaluation: **Relevance Evaluation:** This paper is highly relevant to the specific point of investigation, as it directly addresses the potential of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection in automated irrigation systems. The study provides valuable insights into the challenges and solutions associated with real-time data collection, contributing to the understanding of the initial stages of the automated irrigation management pipeline.
  Relevance Score: 0.85
  Inline Citation: (Mehdizadeh et al., 2020)
  Explanation: **Explanation:** This paper explores the use of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection in the context of automated irrigation management systems. The study evaluates various sensor technologies and communication protocols to optimize data collection efficiency and reliability for real-time irrigation decision-making.

 Full Text: >

Paper 5:
- APA Citation: Al-Ali, A. R., Al-Sarayreh, M., & Salihi, H. (2023). Potential of Wireless Sensor Networks and Energy-Efficient Communication Protocols for Data Collection in Large-Scale, Long-Term Irrigation Systems. TechRxiv. https://www.techrxiv.org/articles/preprint/Potential_of_Wireless_Sensor_Networks_and_Energy_Efficient_Communication_Protocols_for_Data_Collection_in_Large_Scale_Long_Term_Irrigation_Systems/26133080
  Main Objective: To investigate the potential of wireless sensor networks and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems.
  Study Location: Unspecified
  Data Sources: Not specified
  Technologies Used: Wireless sensor networks, energy-efficient communication protocols
  Key Findings: Wireless sensor networks and energy-efficient communication protocols can significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. The use of WSNs and energy-efficient communication protocols can help to reduce the cost and complexity of data collection, making it more feasible to implement automated irrigation systems in large-scale, long-term applications.
  Extract 1: "Wireless sensor networks (WSNs) have been widely used for data collection in various applications due to their low cost, low power consumption, and easy deployment. However, the use of WSNs in large-scale, long-term irrigation systems presents several challenges, such as the need for long-range communication, energy efficiency, and data reliability. This paper investigates the potential of using WSNs for data collection in large-scale, long-term irrigation systems and proposes several energy-efficient communication protocols to improve the efficiency and reliability of data collection."
  Extract 2: "The proposed energy-efficient communication protocols can significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. The use of WSNs and energy-efficient communication protocols can help to reduce the cost and complexity of data collection, making it more feasible to implement automated irrigation systems in large-scale, long-term applications."
  Limitations: This paper focuses primarily on the potential of wireless sensor networks and energy-efficient communication protocols for data collection. It does not cover other aspects of data collection, such as data processing and analysis, or the integration of data collection with other components of an automated irrigation system.
  Relevance Evaluation: This paper is **highly relevant** to the point about investigating the potential of wireless sensor networks and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems. It directly addresses the key issues of network efficiency and reliability in the context of real-time irrigation management. The insights provided in this paper can be valuable for developing effective data collection strategies for automated irrigation systems.
  Relevance Score: 0.85
  Inline Citation: (Al-Ali et al., 2023)
  Explanation: This paper explores the potential of wireless sensor networks and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems. It discusses the challenges and opportunities of using wireless sensor networks and provides insights into energy-efficient communication protocols that can improve the efficiency and reliability of real-time data collection in irrigation management.

 Full Text: >
LOG IN SIGN UP TechRxiv 9,151,197 views 4,235,640 downloads About TechRxiv TechRxiv (pronounced "tech archive") is an open, moderated preprint server for unpublished research in the areas of engineering, computer science, and related technology. https://www.techrxiv.org/ Public Documents 9161 Members by author by title by keyword Filter All Sort by Most Recent BIOENGINEERING 867 COMMUNICATION, NETWORKING AND BROADCAST TECHNOLOGIES 2280 COMPONENTS, CIRCUITS, DEVICES AND SYSTEMS 1066 COMPUTING AND PROCESSING 3366 ENGINEERED MATERIALS, DIELECTRICS AND PLASMAS 248 ENGINEERING PROFESSION 543 FIELDS, WAVES AND ELECTROMAGNETICS 850 GENERAL TOPICS FOR ENGINEERS 647 GEOSCIENCE 268 NUCLEAR ENGINEERING 70 PHOTONICS AND ELECTROOPTICS 344 POWER, ENERGY AND INDUSTRY APPLICATIONS 1199 ROBOTICS AND CONTROL SYSTEMS 879 TRANSPORTATION 386 AEROSPACE 265 SIGNAL PROCESSING AND ANALYSIS 1947 The Effect of Multipath in Distributed Arrays with Time Reversal Hassna Ouassal and 2 more April 03, 2024 This article examines the effect of multipath channels on the performance of distributed arrays that employ time reversal. A model of the signal received from a distributed array is formulated, and a statistical analysis of the variation in signal power in the presence of phase noise and multipath is given. We present the impact these nonidealities have on received signal power, and we analyze the received power for three specific cases: continuous waveform, impulse waveform, and modulated rectangular pulse waveform in the presence of standard channel models. It is shown that for larger arrays in multipath channels, the change in power between coherent and incoherent states converges to the line-of-sight channel. It is further shown that in a line-of-sight channel time-reversal completely cancels unknown channel delays resulting in coherent signals from all nodes in a distributed array, while in a multipath channel only the main diagonal round-trip paths are coherent. Nevertheless, this additional benefit improves signal coherence in complex channels and can aide in distributed array synchronization using two-way time transfer. Disproof of Hodge Conjecture by Graph Theory Jihyeon Yoon April 02, 2024 Hodge conjecture is turned out to be false in extension of graph theory based on its algebraic attribute. Hash3D: Training-free Acceleration for 3D Generation Xingyi Yang and 1 more April 02, 2024 The evolution of 3D generative modeling has been notably propelled by the adoption of 2D diffusion models. Despite this progress, the cumbersome optimization process per se presents a critical hurdle to efficiency. In this paper, we introduce Hash3D, a universal acceleration for 3D generation without model training. Central to Hash3D is the insight that feature-map redundancy is prevalent in images rendered from camera positions and diffusion time-steps in close proximity. By effectively hashing and reusing these feature maps across neighboring timesteps and camera angles, Hash3D substantially prevents redundant calculations, thus accelerating the diffusion model's inference in 3D generation tasks. We achieve this through an adaptive grid-based hashing. Surprisingly, this feature-sharing mechanism not only speed up the generation but also enhances the smoothness and view consistency of the synthesized 3D objects. Our experiments covering 5 textto-3D and 3 image-to-3D models, demonstrate Hash3D's versatility to speed up optimization, enhancing efficiency by 1.3 ∼ 4×. Additionally, Hash3D's integration with 3D Gaussian splatting largely speeds up 3D model creation, reducing text-to-3D processing to about 10 minutes and image-to-3D conversion to roughly 30 seconds. The code is provided in https://github.com/Adamdad/hash3D. Area and Power Efficient Implementation of Configurable Ring Oscillator PUF Enas Abulibdeh and 4 more April 02, 2024 Physically Unclonable Function (PUF) is an emerging hardware security primitive that provides a promising solution for lightweight security. PUFs can be used to generate a secret key that depends on the random manufacturing process variation of the device for lightweight authentication and device identification. This work proposes an optimized version of the Configurable Ring Oscillator (CRO) PUF that aims to reduce power consumption and area overhead. The proposed design eliminates the duplication of ROs, reduces the switching activity, and introduces the inter-stage delay as an additional source of randomness. The proposed PUF has been implemented in 22nm FDSOI technology using the Synopsys tools. A comprehensive security analysis has been acquired utilizing Challenge-Response Pairs collected from 8 chips. Results show an average of 49.42%, 38.25%, 9.95%, and 45.5% for uniformity, diffuseness, reliability, and uniqueness, respectively. Compared with the state-of-the-art, the proposed design achieves an area and power reduction of 75% and 65.1%, respectively. With the proposed PUF delivering 10 32 CRPs, it is classified as a strong PUF. Additionally, the proposed design passes NIST tests and achieves an average prediction accuracy of 67.1% of machine learning modeling. A Hero Or A Killer? Overview Of Opportunities, Challenges, And Implications Of Text-T... Mijat Kustudic and 1 more April 02, 2024 SORA is a text-to-video model that can create videos based on simple user prompts. The model promises to revolutionize the way content is created. When SORA is released to the general public, it may transform a wide array of industries but also pose significant challenges and risks. This research aims to provide a comprehensive understanding of SORA's opportunities, challenges, and implications. It explores its potential applications in film-making, education, gaming, advertising, accessibility, healthcare, and social media content creation. Additionally, it delves into its potential challenges and risks, including misinformation, privacy concerns, bias, regulatory complexities, and dependence on technology. This research provides important recommendations to promote responsible deployment of the AI model. Advancements and Challenges in Robot Grasping and Manipulation for Aspiring Researche... Claudio Zito April 02, 2024 Robot grasping and manipulation represent pivotal aspects of robotics research with profound implications for the future of autonomous systems. This report delves into the intricacies of designing robotic hands, the hurdles in creating robust manipulation actions, and the advancements in the field that poised to catalyze a new era of autonomy. Drawing inspiration from science fiction's portrayal of robotics, we bridge the conceptual gap between fiction and ongoing real-world technical research, aiming to provide a comprehensive overview for students interested in robotics. Comprehensive 3GPP-Compatible Channel Model for FR2-2 Short-Range Communications for... Yusuke Koda and 3 more April 02, 2024 This paper proposes a comprehensive 3GPPcnaompatible channel model with statistical enhancement tailored for indoor short-range device-to-device (D2D) communications operating in the frequency range (FR) of 52.6-71.0 GHz termed FR2-2. Regardless of the existence of various channel models at this band for indoor communications, there will be a need for developing a channel model compatible with and understandable from the current 3GPP stochastic channel model (SCM) to facilitate the discussion in the 3GPP for developing such FR2-2 short-range D2D communication framework based on the fifthgeneration (5G) new radio (NR). Indeed, such a futuristic vision can be foreseen from the fact that the 3GPP is discussing the evolution of sidelink, referred to as a D2D communication framework; however, there are no 3GPP SCM-compatible channel models applicable to FR2-2 short-range D2D communications. To fill this void, we propose the channel model coined 3GPPCompFR2-InS that allows us to generate channel impulse responses (CIR) for computer simulations, which is suitable for various indoor short-range D2D communication scenarios while retailing the similarity in terms of the implementation policy of the 3GPP SCM. 3GPPCompFR2-InS is verified based on the real-world measurements at the 60 GHz band from the viewpoint of both the validity of the channel model parameters and that of the statistical behavior of the generated CIRs. Effective media models for wave propagation in prestressed fractured rocks with nonli... Li-Yun Fu and 3 more April 02, 2024 Stress-induced progressive deformations in fractured rocks with increasing effective pressure generally undergo nonlinear elastic (due to the closure of compliant pores), hyperelastic (due to residual stress), and inelastic (due to fracture growth) deformations prior to mechanical failure. Wave propagation in such rocks involves the complex interaction of fracture-and stress-induced changes in both velocity and anisotropy. With attention to nonlinear elastic and hyperelastic deformations, we incorporate acoustoelasticity into the traditional Hudson/Cheng models to describe the coupling of fracture-induced and stress-induced anisotropies. The resulting acoustoelastic Hudson model (AHM) is valid for the crack density smaller than 0.1 whereas the Padé AHM could handle higher crack densities. We extend the Padé AHM to consider the stress-induced crack closure with nonlinear elastic deformations by incorporating the dual-porosity model. These models approach the coupled anisotropies with different accuracies and computational complexities. The plane-wave analyses and effective-moduli calculations of stressed fractured rocks with varying crack densities determine the accuracy of these models under the isotropic (confining) and anisotropic (uniaxial and pure shear) prestress conditions. The relevant Thomsen parameters are applied to experimental data to validate the applicability. Finite-difference simulations are implemented to identify the contribution of different anisotropies through the variety of wavefronts, depending on fracture orientation, crack density, prestress mode and magnitude, and loading direction. Particular attention is paid to the anisotropic prestress, where the coupled anisotropies are constructive or destructive interference, strongly related to the relativity between fracture strike and loading direction. The stress-induced crack closure will reduce the fracture anisotropy so that the stress-induced background anisotropy dominates the shape of wavefronts with increasing prestress. Security and Reliability Performance of a Cooperative Network with Self-Sustaining No... Amit Patel and 1 more April 02, 2024 In this paper, we analyze the secrecy performance of a two-hop cooperative network consisting solely of energy-harvesting self-sustaining nodes drawing energy from a multi-antenna power beacon (PB). Performance of such networks is quite different from that with powered nodes. We consider optimal combining of the direct and relayed signals at the multi-antenna destination as well as the multi-antenna eavesdropper. Since availability of channel state information at the source is impractical in such networks, we assume fixed-rate signaling. To implement incremental signaling, we utilize feedback bits from the destination. Assuming practical nonlinear EH, exact and approximate expressions are derived for the secrecy outage probability of the selective decode-and-forward (SDF) and the incremental decode-and-forward (IDF) relaying schemes. It is demonstrated that IDF has much better secrecy performance than SDF just as with powered nodes. However, unlike with powered nodes, the secrecy performance is a convex function of the transmit power of PB. We propose a novel power back-off scheme to improve secrecy under different network operating conditions. The security-reliability trade-off (SRT) is analyzed to highlight the trade-off between outage and secrecy performance with the power back-off scheme. Simulation results validate the analytical expressions. Scalable Dynamic Spectrum Access with IEEE 1900.5.2 Spectrum Consumption Models Prasad Netalkar and 5 more April 03, 2024 Dynamic Spectrum Access (DSA) is a key mechanism for meeting the ever-increasing demand for emerging wireless services. DSA involves managing and assigning available spectrum resources in a way that minimizes interference and allows RF coexistence between heterogeneous devices and systems. Spectrum Consumption Models (SCMs)-defined in the IEEE 1900.5.2 standard, offer a mechanism for RF devices to: (i) declare the characteristics of their intended spectrum use and their interference protection needs; and (ii) determine compatibility (non-interference) with existing devices. In this paper, we propose a novel SCM-based Spectrum Deconfliction (SD) algorithm that dynamically configures RF operational parameters (e.g., center frequency and transmission power) of a target transmitter-receiver pair aiming to minimize interference with existing devices/systems. We also propose sequential and distributed DSA methods that use the SD algorithm for assigning spectrum in large-scale networks. To evaluate the performance of our methods in terms of computation time, spectrum assignment efficiency, and overhead, we use two custom-made simulation platforms. Finally, to experimentally demonstrate the feasibility of our methods, we build a proof-of-concept implementation in the NSF PAWR COSMOS wireless testbed. The results reveal the advantages of using SCMs and their capabilities to conduct spectrum assignments in dynamic and congested communication environments. Advanced Cardiovascular Health in a Quantum AI-driven Healthcare Framework Sarvapriya M Tripathi and 2 more April 02, 2024 With the advent of Healthcare 4.0, there is increased interest from researchers the world over in the application of modern, cutting-edge Artificial Intelligence (AI) and Quantum Artificial Intelligence (QAI) algorithms in solving healthcare challenges. The era of Quantum Computing (QC) promises to bring significant advancements in several areas of healthcare such that it may be sensible to give this hybrid Quantum/Classical paradigm its own name-Healthcare4Q. The potential of QC will extend the reach of Healthcare4Q with the help of diverse technologies such as quantum-enabled wearables, quantum-secure transfer and storage of data, and quantum computing at edge, fog, and cloud. All of these technologies promise to catapult Healthcare4Q to become the most capable healthcare framework in the advancement of medical innovations and improvement of patient care. An integral part of a person's health lies in cardiovascular health, and thus prioritizing and optimizing cardiovascular health remains vital to the broader goals of public health and healthcare sustainability. In this study, under the paradigm of Healthcare4Q, we propose a framework called the Quantum AIdriven Heart Health Framework (QAIHHF) that can provide advanced predictive intelligence to healthcare providers by utilizing historical and real-time data and processing capabilities proposed in Healthcare4Q. We show that when applied to various diagnostics and health indicators such as ECG data, the Quantum AI provides accuracy at a level equal to or higher as compared to the classical methods thus proving itself to be the critical component that will herald the era of Healthcare4Q. QCDC-DR-GA: Optimizing Container Loading and Unloading through Dual-Cycling and Docky... Md. Mahfuzur Rahman and 4 more April 01, 2024 This paper addresses the optimization of container unloading and loading operations at ports, integrating quaycrane dual-cycling (QCDC) with dockyard rehandle minimization. We present a unified model encompassing both operations: ship container unloading and loading by quay crane, and the other is reducing dockyard rehandles while loading the ship. We recognize that optimizing one aspect in isolation can lead to suboptimal outcomes due to interdependencies. Specifically, optimizing unloading sequences for minimal operation time may inadvertently increase dockyard rehandles during loading and vice versa. To address this NP-hard problem, we propose a hybrid genetic algorithm (GA) QCDC-DR-GA comprising 1dimensional and 2-dimensional GA components. Our model, QCDC-DR-GA, consistently outperforms four state-of-the-art methods in maximizing dual cycles and minimizing dockyard rehandles. Compared to those methods, it reduced 15-20% of total operation time for large vessels. Results underscore the inefficiency of separately optimizing QCDC and dockyard rehandles. Fragmented approaches, such as QCDC Scheduling Optimized by bi-level GA and GA-ILSRS (Scenario 2), show limited improvement compared to QCDC-DR-GA. As in GA-ILSRS (Scenario 1), neglecting dual-cycle optimization leads to inferior performance than our proposed QCDC-DR-GA. A Two-Stage Passive Matrix Addressing Method for Large-Scale Beam-Steering Arrays PengYuan Wang April 01, 2024 This letter proposes a passive matrix addressing method to dramatically reduce the number of controlling (biasing) lines for large-scale beam-steering arrays. Phase shifting of each radiation element is accomplished in two stages by the row and column biasing lines located at two stacked layers, which offer a pair of orthogonal wave vectors. For an antenna array with M rows and N columns, conventional direct addressing designs need M * N biasing lines, while the proposed method needs only M+N biasing lines to complete the full-space beam-steering. The proposed method simplifies the routing of control lines and the design of driving circuits. Both theoretical and numerical analyses are provided to validate this method. Efficient Twiddle Factor Generation for Post Quantum Cryptography FALCON-based Number... Ghada Alsuhli and 4 more April 01, 2024 Area and power-efficient hardware implementations are crucial for the widespread adoption of post-quantum cryptography (PQC) algorithms like FALCON. One of the main operations in FALCON is the Number Theoretic Transform (NTT), which needs to be performed with many prime numbers. Having one set of twiddle factors (TFs) for each prime makes storing all of these TFs impractical. In this paper, we propose an architecture for generating TFs on the fly for FALCON-oriented NTT, designed for area and power efficiency. Our approach dynamically generates TFs during NTT computations, significantly reducing on-chip memory requirements. The ASIC implementation results demonstrate significant improvements, with the proposed design reducing on-chip memory requirements by 99%, occupying 95% less area, and consuming 87.4% less power compared to the traditional ROM-based implementation. Furthermore, our design achieved a much higher maximum clock frequency, indicating superior performance in accessing twiddle factors. These findings highlight the potential of our proposed architecture for efficient hardware implementations of FALCON-based cryptographic systems. Enhancing Renewable Energy-Grid Integration by Optimally Placed FACTS Devices: The Ni... Nnaemeka Sunday Ugwuanyi and 5 more April 01, 2024 The global shift towards renewable energy (RE) sources, driven by climate change and fossil fuel depletion, encounters challenges in integrating intermittent sources like wind and solar power into existing grids. Developing countries, such as Nigeria, with weak grids, face significant limitations on RE penetration. This study focuses on enhancing RE grid integration in Nigeria by strategically deploying Flexible Alternating Current Transmission System (FACTS) devices. Results obtained from the Nigerian grid indicate that FACTS devices, particularly STATCOMs, can extend the penetration limit by 40%, enabling an additional 152 MW of wind energy to be integrated without jeopardizing system stability. Improved voltage profiles and enhanced stability highlight the effectiveness of FACTS devices in facilitating RE integration into weak grids. Thus, developing grids can accommodate more renewable energy without extensive reconfiguration of the power system architecture. Doppler Shift Distribution in Satellite Constellations Akram Al-Hourani April 01, 2024 Doppler shift has significant implications in Low Earth Orbit (LEO) constellations due to the rapid relative movement of satellites. This paper presents a novel approach based on stochastic geometry to capture the statistical distribution of Doppler shift in modern mega satellite constellations. We derive a simplified expression for both the Doppler shift s-curve and its maximum value, highlighting the dependency of Doppler shifts on the zenith angle of the closest approach during a satellite pass. Additionally, we present a stochastic model for the distribution of these zenith angles within the random constellation model. Furthermore, the statistical distribution of the Doppler bound is analytically formulated and validated through extensive Monte Carlo simulations of two major satellite constellations currently in orbit. Effect of Presenting Stiffness of Robot Hand to Human on Human-Robot Handovers Junya Yamamoto and 2 more April 01, 2024 In the present study, we focus on the object handover task as a major example of collaborative work between a human and a robot. To achieve a smooth handover between two different agents, their mutual communication is indispensable for understanding the other’s intentions. However, previous research has not dealt with a moment during handover in which a robot takes the object from a human grasp or in which a robot hands the object to the human. It should be noted that the performance during those phases is crucial to the success or failure of the tasks because slight changes in the kinematics of the relationship between hands or fingers and object result in significant changes in grasping status: the human may forcibly pull out the object while the robot is grasping it or drop the object. Therefore, this study aims to realize a smooth handover between a human and a robot, focusing on the moment of object handover. To this end, this paper proposes to present the stiffness of the robot hand to the human. We conducted the subject experiments to investigate the effect of this method on humans in the human-robot interaction. Experimental results show that this presentation method enables the worker to recognize the stiffness of the robot, which is difficult to recognize visually, thereby reducing the workload and allowing the worker to respond seamlessly to changes in the robot’s stiffness. VABAM: Variational Autoencoder for Amplitude-based Biosignal Augmentation within Morp... Junetae Kim and 2 more April 01, 2024 Pulsatile physiological signals, characterized by rhythmic fluctuations, are vital for assessing health conditions and are widely used in wellness devices and medical equipment. Despite their significance, models addressing domain-specific unmet needs and considerations have not been developed as much as in other fields. Therefore, building on the foundation of variational autoencoders, we introduce VABAM, a novel model for the amplitude-based synthesis of pulsatile physiological signals. The uniqueness of VABAM lies in its ability to maintain the morphological identity of signals throughout the synthesis process, achieved by integrating pass filter effects within the variational autoencoder architecture. To assess the effectiveness of the model, we developed three novel metrics based on joint mutual information. These metrics were aimed at evaluating the disentanglement of latent spaces, influence of ancillary information on signal morphologies, and controllability of amplitude-based synthesis within morphological identities. Comparative analyses demonstrated that VABAM and its variants were notably effective at preserving morphological integrity, highlighting their potential to minimize morphological distortions in physiological signal processing and their compatibility with artificial intelligence models employing frequency and amplitude features. Additionally, the proposed metrics, compatible with probabilistic models, were empirically proven to capture the characteristics of various models from multiple perspectives. ← Previous 1 2 3 4 5 6 7 8 9 … 508 509 Next → TechRxiv | Powered by Authorea.com Home About Submission Guidelines FAQs Terms of Use Privacy Policy Contact Us

</subsection_point_Point 3>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>

<subsection_point_Point 2>
Point: Explore the use of advanced sensing technologies, such as hyperspectral imaging and thermal sensing, for non-invasive plant stress detection

Papers to support point:

Paper 1:
- APA Citation: Triantafyllou, A., Sarigiannidis, P., & Bibi, S. (2019). Precision Agriculture: A Remote Sensing Monitoring System Architecture. Information, 10(11), 348.
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: The Sensor Layer is in charge of acquiring the data of the different climatic and soil variables involved in the growth and production of the crops. Data can be acquired either by ground sensors, located above or inside the soil, or by UAV sensors involving embedded cameras, location and other sensors.
  Extract 2: •	Optical Sensors/UAV Sensors: Optical sensors are usually embedded in UAVs and use light reflection information to measure the varying properties of soil and vegetation. In that case, the sensors acquire image data, which are further analyzed with photogrammetry techniques.
  Limitations: The paper does not provide specific details or experimental results on the performance of the proposed architecture with the use of advanced sensing technologies.
  Relevance Evaluation: Highly relevant - The paper directly addresses the outline point by discussing the use of advanced sensing technologies, such as hyperspectral imaging and thermal sensing, in the sensor layer of their proposed architecture for non-invasive plant stress detection.
  Relevance Score: 1.0
  Inline Citation: (Triantafyllou et al. 2019)
  Explanation: **Key Points of the Paper as They Relate to the Outline Point:**

This paper proposes a comprehensive reference architecture model for real-time, end-to-end automated irrigation management systems that can contribute to addressing the global food challenge. The model focuses on optimizing water resources and enhancing agricultural productivity through the efficient use of IoT and machine learning technologies.

**How the Paper Contributes to Addressing the Outline Point:**

The paper aligns with the outline point 'Explore the use of advanced sensing technologies, such as hyperspectral imaging and thermal sensing, for non-invasive plant stress detection.' by discussing the importance of advanced sensing technologies, such as hyperspectral and thermal imaging, in the sensor layer of the proposed architecture.

The paper highlights that these sensing technologies can provide non-invasive plant stress detection, which is crucial for early and accurate detection of plant health issues. This information can then be used by the system to adjust irrigation and other management practices in real-time, helping to optimize crop yields and reduce water usage.

 Full Text: >
  
information
Article
Precision Agriculture: A Remote Sensing Monitoring
System Architecture †
Anna Triantafyllou *
, Panagiotis Sarigiannidis *
and Stamatia Bibi *
Department of Electrical and Computer Engineering, University of Western Macedonia, Kozani 50100, Greece
* Correspondence: atriantafyllou@uowm.gr (A.T.); psarigiannidis@uowm.gr (P.S.); sbibi@uowm.gr (S.B.)
† This paper is an extended version of our paper published in International Workshop on IoT Applications and
Industry 4.0 (IoT4 2019), co-located with IEEE DCOSS 2019, Santorini Island, Greece.
Received: 29 September 2019; Accepted: 3 November 2019; Published: 9 November 2019


Abstract: Smart Farming is a development that emphasizes on the use of modern technologies in the
cyber-physical ﬁeld management cycle. Technologies such as the Internet of Things (IoT) and Cloud
Computing have accelerated the digital transformation of the conventional agricultural practices
promising increased production rate and product quality. The adoption of smart farming though is
hampered because of the lack of models providing guidance to practitioners regarding the necessary
components that constitute IoT-based monitoring systems. To guide the process of designing
and implementing Smart farming monitoring systems, in this paper we propose a generic reference
architecture model, taking also into consideration a very important non-functional requirement,
the energy consumption restriction. Moreover, we present and discuss the technologies that incorporate
the seven layers of the architecture model that are the Sensor Layer, the Link Layer, the Encapsulation
Layer, the Middleware Layer, the Conﬁguration Layer, the Management Layer and the Application
Layer. Furthermore, the proposed Reference Architecture model is exempliﬁed in a real-world
application for surveying Saffron agriculture in Kozani, Greece.
Keywords: Wireless Sensor Networks; Internet of Things; precision agriculture; smart farming;
communication technologies; Cloud Computing
1. Introduction
Presently, the digital transformation of the agricultural sector is considered a priority to face the
numerous challenges presented in the ﬁelds. Environmental monitoring and remote controlling in
agriculture is rapidly growing towards developing more productive and competitive agricultural
systems and tools. Precision Agriculture and Smart Farming can lead to this direction. These two terms
refer to the integration of advanced technologies into existing agricultural practices to achieve ﬁne-grid
crops management. Smart farming systems can provide to farmers meaningful environmental data
from the cultivation ﬁelds aiming to boost competitiveness and proﬁt. Almost every aspect of the
agricultural ﬁeld can beneﬁt from these kinds of technological advances ranging from planting and
irrigation processes to plant protection and harvesting methods.
The future of precision agriculture lies upon modern technological advancements and remote
sensing techniques using Unmanned Aerial Vehicles (UAV) and different kind of smart sensors. Sensors
are measuring devices that convert an external stimulus or else input signal, into an appropriately
measurable output signal. Sensor devices can transform a macroscopic size (light, power, pressure,
etc.) to an electrically measurable size. Once the electrical signal is processed, it is converted into a
standardized signal with certain characteristics. The sensor’s properties can be altered in a measurable
manner, either directly or indirectly by the exposure to a particular analyzer or change in environmental
conditions. UAVs are ﬂying vehicles that do not have a pilot on their spindle. Instead they ﬂy either
Information 2019, 10, 348; doi:10.3390/info10110348
www.mdpi.com/journal/information
Information 2019, 10, 348
2 of 25
autonomously or by means of remote control. Unmanned aircraft used for remote monitoring are part
of Unmanned Aerial Systems (UASs). UASs involve all necessary devices and procedures for UAV
operation, while managing data collection. UAVs enable Earth Observation (EO) towards improving
accuracy, executing more frequent and better monitoring of the ﬁelds and cover large (not easily
accessible) areas. Sensors and UAVs are a part of the Internet of Things (IoT) paradigm. The IoT is a
modern communication network involving the employment of a vast number of distributed smart
devices around a uniﬁed wide area network. Its basic characteristic stands upon the ability to recognize
and notify users instantly about real-time events by the use of smart objects. Smart objects-devices
have basic computational skills, constrained resources and unique identiﬁers for communication.
The adoption of smart farming though is hampered because of the lack of models providing
guidance to practitioners regarding the necessary components that constitute IoT-based monitoring
systems. The typically dense and heterogeneous nature of IoT deployments poses immense challenges
on interoperability among the desired components. However, an efﬁciently designed architecture based
on modern enhanced IoT technologies can pave the way into easily adopting and deploying smart
systems into our everyday life activities. The latest years a signiﬁcant number of efforts were presented
regarding the most suitable network structure and technologies for smart farming applications [1–9].
However, the architectural models presented in [1,7–9] were based only on static sensor nodes, ignoring
the advantage of UAVs in monitoring and failing to provide efﬁcient mapping of the ﬁeld to the
farmer. Furthermore, no prediction mechanisms were employed in [2] towards improving production.
Moreover, limited contribution was provided in [3–5] regarding energy saving and link layer IoT
technologies in farm management information systems, while the data-driven agricultural model
proposed in [6] did not discuss data security issues. In contrast to previous studies, the contribution
of this paper lies upon the presentation of a detailed architectural model for an advanced smart
farming monitoring system by using UAVs and taking into consideration energy-saving and security
requirements. This architectural model engages novel IoT technologies [10] and Wireless Sensor
Networks (WSNs) capabilities to provide a sufﬁcient view of precision agriculture. Furthermore,
the proposed architecture enables a combination of modern remote sensing techniques such as UAV
tracking, Global Positioning System (GPS) for location detection, Geographic Information Systems
(GIS), real-time monitoring with different types of sensors and intelligent input control systems. These
technologies have already been tested in various agricultural ﬁelds in different countries for the
cultivation of rice, wheat, tomatoes, vegetables, potatoes, ornamental ﬂowers, chilly, cacao, pepper,
corn, olives, apples, lemons, grape and others. By incorporating new technologies into agricultural
production and by using modern EO techniques growers will be able to manage their crops at a
different and more advanced kind of level in detail that was not possible a few years ago. This
paper is an extension of our work in [11]. Towards enhancing contribution a use case study is also
presented regarding an ongoing research project known as Drone Innovation in saffron Agriculture
Surveillance(DIAS). The DIAS architectural model is based on the proposed paradigm.
This paper is organized as follows. Section 2 presents an overview of the proposed smart farming
monitoring system architecture. In Section 3, the sensor layer is introduced, followed by the network
layer and its suitable protocols and technologies regarding communication, routing, encapsulation
techniques and interoperability mechanisms in Section 4. Section 5 is focused on the management
layer and the provided services of the proposed monitoring system, while Section 6 focuses on IoT
agricultural applications. Section 7 deals with energy-saving technologies and security mechanisms
that can be implemented in cooperation with networking technologies of the system. The use case
study of the DIAS architecture is presented in Section 8. Existing challenges are mentioned and
discussed in Section 9. Finally, Section 10 concludes this study.
2. The Architecture of a Smart Farming Monitoring System
A precision agriculture monitoring system consists mainly of the sensing agricultural parameters,
the identiﬁcation of sensing location and data gathering, the routing of data from crop ﬁeld to
Information 2019, 10, 348
3 of 25
control station for decision making, the actuation and control decision based on sensed data and the
visualization of results to the grower through an application. The architectural design of our model
follows the ISO/IEC 7498-1 standard or else known as the OSI Model [12], proposing a communication
system into seven abstraction layers. However, due the employment of IoT technologies and artiﬁcial
intelligence capabilities the basic agricultural layers are deﬁned as presented in Figure 1:
Figure 1. Remote Sensing System Architecture.
•
The Sensor Layer, referring to the Physical Layer of the OSI Model, includes all kinds of
crops sensors and smart objects for data collection and monitoring. Sensors can be placed
under ground(in the soil), on the crops or on UAVs [6]. Underground sensors are especially
manufactured to be water resistant and usually refer to measurements of moisture, pH and soil
chemical properties such as sulfur. UAV sensors measure environmental parameters such as
humidity, temperature, wind speed, luminosity or solar radiation. However, the most popular
kind of sensors to be placed on UAVs are thermal cameras. Thermal drones which use vision
Information 2019, 10, 348
4 of 25
imaging cameras have so many positive uses by detecting heat coming from almost all objects
and materials turning them into images and video.
•
The Link Layer, referring to the Data Link Layer of the OSI Model, constitutes of all available
networking and routing technologies between sensors for information exchange. To deploy
efﬁcient crop and ﬁeld management the IoT platform uses Wireless Sensor Networks (WSNs).
The use of WSN in smart farming systems provides immediate monitoring and optimization of
crop quality, while offering a potential for large area surveillance with high sampling densities.
The constant monitoring of a great number of environmental parameters by distributed sensor
nodes along the ﬁeld help the grower supervise and maintain optimal conditions to achieve
maximum productivity with remarkable energy savings.
•
The Encapsulation Layer, referring to the Network Layer of the OSI Model, focuses on the
establishment of smart sensor connection to the IPv6-based internet. This layer consists of
IoT networking encapsulation techniques and routing protocols to transform the regular WSN
network trafﬁc into smart information. In other words, the technologies of this layer enable the
cultivated ﬁeld sensory data to be encapsulated in IPv6 routing packets and be forwarded to the
according network server.
•
The Middleware Layer, referring to the Transport Layer of the OSI Model, uses different application
level transport protocols in order to forward the data generated from IoT sensor devices based on
different paradigms. It also provides interfaces that enable device communication for management
or actuation purposes. This layer facilitates the desired interoperability due to the existence of
diverse standards, which are endorsed by different entities.
•
The Conﬁguration Layer, referring to the Session and Presentation Layers of the OSI Model,
is situated between the Middleware Layer and the Management Layer. This layer is responsible
for gathering the raw data coming from the devices or other external services, curate, harmonize
and possibly aggregate them, so that they can be published as context information, or supplied
to upstream data processing algorithms or analytics. In addition, this layer is also capable of
sending actuation commands to the Middleware Layer. Finally, the Conﬁguration Layer may
also be capable of gathering data from other data sources, such as agricultural machinery or
public geo-services.
•
The Management Layer involves the processing and analysis of the collected data. In this layer
the most efﬁcient data management and data mining techniques are adopted to obtain accurate
predictions and support regarding ﬁeld operations such as optimized pesticide application,
disease detection, efﬁcient irrigation management. Data processing is supported by Decision
Support Systems (DSS) that take care of the overall management of available collected information
from the ﬁelds towards increasing productivity, optimizing crop yield, maintaining quality
and saving resources.
It is well known that farmers suffer great economic losses due to
incorrect weather forecasting or incorrect irrigation methods. Data analysis is the most important
component of IoT agricultural systems resulting in efﬁcient pesticide use and protection against
diseases. This layer can be considered to be an additional layer regarding the OSI Model enabling
artiﬁcial intelligence advancements to the overall system.
•
The Application Layer, referring to the Application Layer of the OSI Model, includes all
suitable application module interfaces for implementing fertilizer and irrigation control, disease
and animal detection, alerts regarding the cultivation process and visualization of statistical
data. This layer enables the farmer to monitor and manage his ﬁelds in a user-friendly way.
Data visualization techniques such as graphs, heatmaps, orthomosaics, and three-dimensional
models are employed, among others, to allow easy and intuitive representation of the knowledge
acquired from the ﬁeld monitoring. The farmer can inspect the results produced by the services
of the system and take action accordingly.
Information 2019, 10, 348
5 of 25
Energy-saving mechanisms and data privacy and security techniques are also considered to be
very important in the context of Smart farming and should be applied vertically in all the layers of
the architecture. To support the efﬁciency and effectiveness of a smart farming monitoring system
energy consumption should be kept under control. Due to the limited battery life and constrained
resources of sensor nodes, energy-saving techniques must be applied across the sensor and network
layer accordingly. Energy-saving techniques deal with the active and inactive operational time
in each sensor node, the scheduling of information transmission and the routing process of data
packets. Moreover, security mechanisms are vital for maintaining the privacy of the collected data and
safeguarding farmers’ personal information exchange.
3. The Sensor Layer
The Sensor Layer is in charge of acquiring the data of the different climatic and soil variables
involved in the growth and production of the crops. Data can be acquired either by ground sensors,
located above or inside the soil, or by UAV sensors involving embedded cameras, location and other
sensors. The Sensor Layer constitutes the cradle of modern EO approaches towards optimizing
decision support in remote sensing monitoring systems. EO monitoring of cultivation areas is
highly enhanced using autonomous UAVs. Popular EO techniques include satellite and radar-based
technologies [13] towards estimating basic biophysical parameters in the ﬁelds, such as Leaf Area
Index (LAI), crop height and water requirements [14,15]. According to [16] radar-based technologies
are used to enable the estimation of soil moisture spatial variability and can efﬁciently estimate LAI.
However, EO can achieve sturdy higher spatial resolutions only with calibration against accurate
ground truth instruments that measure at within ﬁeld scale resolutions. UAVs deploy EO via using
photogrammetry techniques enabling the generation of three-dimensional digital surface models of the
ﬁelds. In particular, autonomous, manual or GPS-based image acquisition, ortho-image generation and
image triangulation and geo-referencing based on navigation sensors are employed. More information
regarding these methods is provided in Sections 5 and 8.2. In the Sensor Layer each sensor sends the
acquired data in the cloud through a WSN. The WSN is made up of sensor nodes that operate under a
mesh or point-to-point topology, a coordinator node and a gateway. Each node in such a network is
connected to one or more sensors [17]. In precision agriculture the most important types of sensors for
measuring the different types of corps attributes are:
•
Optical Sensors/UAV Sensors: Optical sensors are usually embedded in UAVs and use light
reﬂection information to measure the varying properties of soil and vegetation. In that case,
the sensors acquire image data, which are further analyzed with photogrammetry techniques.
Object detectors and pattern recognition form the basic building block for extracting information
from the images. Such information may involve the vegetation and soil color, the moisture
content and temperature of soil and vegetation, the position, height, size and shape of vegetation
along with the level of chlorophyll. In this category we ﬁnd visible light sensors, multispectral
sensors, hyperspectral sensors and thermal sensors.
•
Electrochemical Sensors/Ground Sensors: These types of sensors acquire data regarding the
nutrient contents of soil and its associated pH. Electrodes in these sensors work by detecting
speciﬁc ions in the soil. Different families of electrochemical sensors can be recognized depending
on the electrical magnitude used for transduction of the recognition event: potentiometric, which
indicates change of membrane potential; conductometric, which indicates change of conductance;
impedimetric, which indicates change of impedance; and voltammetric or amperometric, which
indicates change of current for an electrochemical reaction with the applied voltage in the ﬁrst
case, or with time at a ﬁxed applied potential in the latter.
•
Location Sensors/UAV Sensors: Location sensors are usually embedded in UAVs and provide
spatial information regarding the positioning of an element. These types of sensors use signals
from GPS satellites to determine latitude, longitude, and altitude to within feet. Three satellites
minimum are required to triangulate a position. Precise positioning is the cornerstone of precision
Information 2019, 10, 348
6 of 25
agriculture. GPS integrated circuits such as the NJR NJG1157PCD-TE1 are a good example of
location sensors.
•
Weather Stations/Ground Sensors: Weather stations are free-standing units situated at different
locations throughout the cultivating ﬁelds. These stations measure various data for precision
agriculture such as airﬂow, seasonal rainfall, speed of wind, humidity level, direction of wind,
atmospheric pressure and solar radiation, etc. Weather stations are an important component
of EO technologies since they can provide daily agro-meteorological information regarding the
cultivating ﬁelds.
Summarizing the above, Table 1 presents the most frequently acquired data by sensors in the
agricultural domain. A sensor node consists of a radio transceiver with an internal antenna or a
connection to an external antenna, a micro-controller, an electronic circuit for interfacing with the
sensors and an energy source, usually a battery or a built-in energy harvested form. There are numerous
commercial models of micro-controllers to be used in precision agriculture applications. The most
popular ones are the Arduino, the Raspberry Pi, the Atmega328 and the LPC2148 boards. Accordingly,
commonly used wireless communication modules used are the XBee module, the WSN802G module
and the NRF24L01 module. A sensor node can vary in size and cost, depending on the complexity
of its capabilities. Size and cost constraints result in corresponding limitations on resources such as
energy, memory, computing speed, and bandwidth of communications. The types of sensors that are
mostly used in Smart farming monitoring systems are summarized in Table 2.
Table 1. Precision agriculture sensor data types.
Data Type
Sensor Type
Soil moisture and temperature
Ground sensors
Soil color
UAV sensors
Environmental humidity and temperature
Ground sensors or UAV sensors
Leaf-wetness
Ground sensors or UAV sensors
Electric conductivity
Electrochemical sensors
Wind speed and direction
Weather stations
Barometric pressure
Weather stations
Carbon dioxide
Electrochemical sensors
Ph value
Electrochemical sensors
Light intensity
Weather stations or Ground sensors
Solar radiation
Weather stations or Ground sensors
Rainfall
Weather stations
Size of crops
UAV sensors
Shape of crops
UAV sensors
Thickness of plant stem
UAV sensors
Latitude, longitude and altitude of the plants
Location sensors
Information 2019, 10, 348
7 of 25
Table 2. Precision agriculture sensor models.
Sensor Type
Sensor Model
Soil moisture sensor
10-HS,SY-HS-220, FC-28
Temperature sensor
LM35, SHT15, DS18B20
Humidity sensor
DHT22, DHT11
Electric conductivity sensor
DFR0300
Wind speed and direction sensor
SEN0170
Barometric pressure sensor
BMP180
Carbon dioxide sensor
CDM4161A, MHZ16
Ph sensor
MCP1525
Light sensor
TSL2561, BH1750
Solar radiation sensor
6450 TSR
Thermal sensors
ThermoMAP
4. The Network Layer
4.1. The Link Layer
In precision agriculture WSN communication protocols and technologies are used to support
the connection between sensor nodes in the network and to provide a channel for communication
between the coordinator node and the gateway. According to the type of application, such as precision
farming, ﬁeld irrigation management or greenhouse crop management, the sensor network topology
and communication demands may differ. Hardware and software characteristics may also affect
the choice of communication technology to be used between the nodes. Each node uses a routing
protocol [18] in the view of transferring the data collected to the coordinator node.
Based on many experimental studies on agricultural ﬁelds, there is not an ideal combination of a
speciﬁc communication technology and a routing protocol. Discovering and keeping up with routes in
WSNs is a quite demanding task since energy restrictions and alterations in node status, such as failure
may cause sudden changes in the network topology. It is a fact that the wireless routing solution for
agriculture applications should be highly energy-efﬁcient, scalable, and autonomous. Up until now
routing tactics proposed in the literature for WSNs employ speciﬁc methods such as data aggregation,
clustering, different node role assignment and data-centric methods.
The basic goal is to build each smart monitoring system upon application appropriate networking
technologies to operate efﬁciently with minimum energy consumption. Once the coordinator node
obtains the data it forwards the ﬂow of information to the gateway to reach the main server, where
the database is located. However, in some cases the coordinator node can be substituted by a base
station to obtain the collected data using a Wi-Fi connection as presented in [2], or another cellular
communication technology.
4.1.1. Precision Agriculture Communication Protocols
There is a wide variety of networking technologies suitable for the deployment of smart farming
applications. The most popular are the following:
•
The IEEE 802.15.4 standard is a widely used networking technology in precision agriculture and
deﬁnes the physical layer and the Media Access Control (MAC) technique in Low-Rate Wireless
Personal Area Networks (LR-WPANs).
•
ZigBee is another suitable technology for short range radio communication in the ﬁelds using
low-power devices capable of transmitting data over long distances using intermediate stations.
Information 2019, 10, 348
8 of 25
•
LoRa is a type of wireless conﬁguration that has been created to achieve long-range connections
for Low-power Wide Area Networks (LPWANs).
LoRAWAN is a protocol for managing
communication between LPWAN gateways and nodes.
•
Bluetooth Low Energy is a global personal area network protocol built for transmitting small
data pieces infrequently at low rates with signiﬁcantly low power consumption per bit.
•
RFID (Radio Frequency Identiﬁcation) is a different technology that uses radio signals to monitor
and identify in real time objects without requiring line-of-sight communication. An RFID
system includes a reader, a tag, and a host and is presented as ideal for ﬁeld monitoring in
multiple studies.
Moreover, the communication between sensor nodes and a base station can be supported by:
•
the Wi-Fi protocol, based on the IEEE 802.11 standard. This standard speciﬁes the set of media
access control (MAC) and physical layer (PHY) protocols for implementing wireless local area
network (WLAN) Wi-Fi computer communication in various frequencies.
•
the GSM (Global System for Mobile Communications), a standard developed by the European
Telecommunications Standards Institute (ETSI) to describe the protocols for second-generation
(2G) digital cellular networks used by mobile devices such as mobile phones and tablets.
•
the GPRS (General Packet Radio Service) technology standard that provides rapid sending and
receiving of data over the GSM mobile networks based on packet switching, a well-known
network transmission process.
•
the 2G, 3G and 4G (LTE) are respectively the 2nd, 3rd and 4th generation of GSM technology
aiming at higher speeds.
Table 3 summarizes the communication technologies adopted in smart farming systems according
to literature.
Table 3. Smart farming networking technologies.
Communication Technology
Data Rate
Frequency Band
Range
References
IEEE 802.15.4
20–250 Kbps
2400/915/868 MHz
10 m
[7]
IEEE 802.15.4-ZigBee
20–250 Kbps
2400/915/868 MHz
10–100 m
[19]
Wi-Fi-IEEE 802.11
450 Mbps
2.4 GHz–5 GHz
100 m
[2,20]
GPRS-2G GSM
64 Kbps
900 MHz–1800 MHz
100 m
[21]
3G
14.4 Kbps–2 Mbps
1.6–2 GHz
100 m
[21]
4G-LTE
100 Mbps–1 Gps
2–8 GHz
100 m
[14]
LoRa
0.3–50 Kbps
433,868,780,915 MHz
2–5 km
[1,22]
Bluetooth LE
1 Mbps
2.4 GHz–2.485 GHz
>100 m
[5]
RFID
400 Kbps
125 KHz–915 MHz
3 m
[23]
4.1.2. Precision Agriculture Routing Protocols
Data routing algorithms play an important role in WSNs by establishing the path of
communication for data exchange between sensor nodes and base stations on a network. A variety
of routing techniques have been proposed until now, aiming to achieve higher performance with
minimal power consumption. IoT and WSN routing protocols can be categorized according to network
structure and the way information will be disseminated through the network. A routing protocol can
belong to more than one category, aiming to satisfy as many performance metrics as possible.
According to the way by which routing decisions are made proactive and reactive routing
techniques can be used. Proactive routing (or table-driven) supports the periodic renewal and
updating of the routes and destinations that are formed between the nodes throughout the network.
On the other hand, reactive routing (or on demand) includes discovering routes on demand based
on the transmission of route request packets. The downside to reactive protocols is their latency,
since transmissions over unknown or expired routes face delays, for which either the application or
the routing protocol must account by buffering or dropping data.
Information 2019, 10, 348
9 of 25
Furthermore, according to WSN structure, routing algorithms can depend on neighbor nodes to
broadcast the collected information. Another popular technique is based on dividing the network into
clusters. Each cluster depends on a cluster head node to manage the routing of information between
other clusters or base stations. Hierarchical routing is the most popular routing method in smart
farming monitoring systems and soil parameter monitoring [23,24]. Multi-path routing protocols
can also be used to implement a smart farm monitoring system to balance the data transfer load and
conserved energy. Table 4 presents characteristic examples of routing protocols adopted in smart
farming systems according to literature.
Table 4. Smart farming routing protocols.
Routing Protocols
Category
Features
Destination-Sequenced
Distance Vector (DSVD)
Proactive
Route availability to all network destinations with
minimal delay.
Link Estimation Parent
Selection (LEPS)
Proactive
A map of the network is kept regarding the
interconnection of nodes.
Tiny Lightweight UNderlay
Ad-hoc Routing (TinyLunar)
Reactive
Provided
interfaces
help
to
form
route
characteristics.
Ad-hoc On-Demand
Distance Vector(AODV)
Reactive
Used in ZigBee communication protocol for
interconnection of sensor nodes.
Dynamic Source
Routing(DSR)
Reactive
A route on demand is formed when a transmission
node requests it.
Optimized Link State
Routing Protocol (OLSR)
Flat Routing
Information about the status of the nodes is used to
select the appropriate path for packet forwarding.
ProtoSense
Flat routing
Reliable retransmission of information using
conﬁrmation messages.
Periodic Threshold-Sensitive
Energy-Efﬁcient Sensor
Network (APTEEN)
Hierarchical
Routing
It takes into account energy saving and network
lifetime [24].
Location Routing Algorithm
with Cluster-Based Flooding
(LORA-CBF) [25]
Location-based
routing
It uses the ﬂood method in a hierarchical network
structure to route data packets.
4.2. The Encapsulation Layer
Most of the current agro-environmental monitoring applications are based on machine to
machine (M2M) communication support regarding real-time data transmission. There is a variety
of communication patterns to be used so that the terminal can receive the information necessary to
monitor the production. WSN technologies, enhanced by the IoT paradigm, enable smart sensor
communication and connection to the IPv6-based internet, by addressing the agricultural sensors
with IPv6 long addresses that can ﬁt in lightweight IoT data link frames. IoT can immensely improve
the autonomous capabilities of resourced-constrained nodes in a Low-power and Lossy Network
(LLN). An agricultural WSN is a LLN. In such a network, some of the nodes may have a direct
Internet connection to send and receive messages from the Internet. However, other nodes from the
same network, may lack that kind of ability due to hardware limitations, and require the use of the
Internet-connected nodes to access external services. Data exchange in a local context is also possible
without the necessity of transmitting data to the Internet. The task of discovering the routes and
allowing data messages to be transmitted among agricultural sensor nodes is performed by the routing
protocol. Due to this fact, in such networks, network performance is strongly related to how the
routing protocols use the limited hardware resources of the network device.
•
The 6LoWPAN [7,26] is the most popular network encapsulation protocol for precision agriculture
applications. It refers to the transmission of IPv6 protocol packets over Low-Power Wireless
Information 2019, 10, 348
10 of 25
Personal Area Networks. In a smart farming monitoring system, it is used by sensor devices that
are compatible with the IEEE802.15.4 standard for WSNs. 6LoWPAN efﬁciently encapsulates
IPv6 long headers in IEEE 802.15.4 small data frames for information exchange between sensor
nodes. The advantages of this protocol are that it uses a special header compression method and
a fragmentation process to reduce the transmission overhead [10].
•
The IPv6 over LoRa [27] implementation enables the transmission of IPv6 protocol packets over
LoRa links. If LoRaWAN is chosen for sensor node communication in a smart farming monitoring
system, LoRa is the MAC protocol responsible for establishing communication between the
LoRa gateway and the LoRa sensor end devices. In an agriculture monitoring system, the IPv6
adaptation enables the deployment of the IoT paradigm as a separate architectural layer. The basic
aim of this layer is to manage header compression and packet fragmentation to deal with the
requirements of LoRa modulation in the physical layer.
•
The IPv6 over 802.11ah [10] or Wi-Fi-ah (HaLow) is a low-power/low-rate protocol able to support
numerous sensor node devices on a single base station. This technology can be used for precision
agriculture by enabling wireless base stations in the ﬁeld to transmit data while also being energy
conservative. Wi-Fi-ah (HaLow) uses special characteristics of the 6LoWPAN technology for
effective transmission of IPv6 protocol packets over IEEE 802.11ah wireless networks.
•
RPL (IPv6 Routing over Low Power and Lossy Networks) [26] is the most popular IoT routing
protocol based on the distance vector routing technique. It is a proactive protocol that constructs
a speciﬁc graph able to direct all trafﬁc towards the sink node. RPL is the ideal routing protocol
for agricultural LLNs, since it can quickly create network routes between sensor nodes in the
ﬁeld, share routing knowledge and adapt the topology in an efﬁcient way. It is also efﬁcient for
multi-hop, many-to-one and one-to-one communication.
•
LOADng-IoT is another IoT routing protocol, proposed in [28] as an enhancement for reactive
protocol LOADng, which is considered to be the best current solution for LLNs. LOADng-IoT is
able to boost the process of route discovery, reduce the overhead of control messages, and improve
the network′s quality-of-service(QoS). In a smart farm monitoring system, this protocol will allow
sensor nodes without an Internet connection to forward their data packets to external Internet
services with much greater reliability and lower latency.
4.3. The Middleware Layer
The Middleware Layer is responsible for establishing and controlling the association between
IoT sensor devices. More speciﬁcally, the services of this layer include smart device management by
the use of different transport protocols to forward the generated data from the involved IoT devices.
Most of these transport standards use the Transmission Control Protocol (TCP) or the User Datagram
Protocol (UDP) for forwarding information. There is a wide variety of data protocols [29] that belong
to this layer towards developing an efﬁcient managing platform for smart ﬁeld devices. However,
choosing the most appropriate device management technology depends on software and hardware
speciﬁcations, network and technology architecture and communication standards being used in the
according system to achieve maximum and efﬁcient performance. In the view of using different kind of
smart entities in an agriculture monitoring system, the services of this architectural layer facilitate the
desired interoperability of the technologies introduced. All collected data will be stored on a remote
server and transmitted to the client machine through Application Programming Interfaces (APIs) that
provide web services for third-party users. APIs enable device communication in an application level
for different kinds of purposes and are based on different architectures to transfer data from the server
to the client.
•
The MQTT-SN (Message Queuing Telemetry Transport For Sensor Networks) is a messaging
protocol that facilitates device data collection and communication with servers using brokers.
A broker is a network entity which arranges transactions between other network entities. By using
the MQTT protocol, a precision agriculture monitoring system can enable smart sensor devices to
Information 2019, 10, 348
11 of 25
publish messages to a broker and/or subscribe to a broker in order to receive certain messages.
The exchanged messages will be organized by topics that act as a system for dispatching messages
to subscribers.
•
The CoAP (Constrained Application Protocol) is another popular protocol for IoT device
data management. CoAP is based on a request/response pattern of communication allowing
constrained devices to have web service functionalities. It is an HTTP-like web transfer protocol
with the ability to extend the Representational State Transfer (REST) architecture to Low-Power
Wireless Personal Area Networks (LoWPANs). REST is an architectural style for providing
standards between computer systems on the web, while distinguishing the concerns of client
and server.
•
The XMPP-IoT (Extensible Messaging and Presence Protocol) is an open technology for real-time
communication based on XML messages between connected devices and the available server.
XMPP can efﬁciently power instant messaging, collaboration and content syndication in a smart
farm monitoring system between all network entities.
•
Device and asset management in a precision agriculture monitoring system can also be
implemented using the Mihini [30] software.
Mihini is an open-source project by Eclipse
Technology that enables communication between an M2M server and the applications running
on an embedded gateway. M3DA is the protocol used for the transport of M2M data. M3DA can
allow user applications to exchange typed data/commands back and forth with an M2M server,
in a way that optimizes the use of bandwidth.
•
The OMA SpecWorks’s Lightweight M2M [31] is another device management protocol for M2M
or IoT devices. It can be used in a smart farming information system to efﬁciently transfer
service data from the network to resource-constrained devices. In contrast to traditional M2M
standards in which a device usually needs to keep up multiple stacks of technologies, protocols
and security services, the LwM2M scheme allows the existence of one stack of technology for
device management, not only on the level of the device itself, but also on the application level.
In addition, LwM2M is based on protocol and security standards from the Internet Engineering
Task Force (IETF).
•
The ONEM2M [32] technical speciﬁcation standards are an upcoming solution for device and
asset management in precision agriculture. ONEM2M is a middleware IoT platform that provides
functions and APIs for different service domains dealing with interoperability challenges. There
are commercial and open-source implementations of this technology.
•
A popular queuing protocol for enabling server connection in IoT is the AMQP (Advanced
Message Queuing Protocol). This open standard protocol can facilitate message orientation,
queuing, routing, reliability and security in precision agriculture applications.
•
Last but not least, the DDS (Data-Distribution Service) [33] is the ﬁrst open international M2M
standard directly addressing publish-subscribe communications for real-time and embedded
systems. This protocol has the advantage of providing fast data, event, and command exchange
among the IoT sensor nodes in a precision agriculture monitoring system.
4.4. The Conﬁguration Layer
The Conﬁguration Layer deals with protocols running on top of the IoT monitoring platform
allowing the exchange of data speciﬁed by its context regarding what is described, what was measured,
when, where, by what, the time of validity, ownership, and others. The main objective of this layer
is to curate, harmonize and aggregate the collected raw data, so that it can be published as context
information, or supplied to upstream data processing algorithms or analytics. It is also capable of
sending operational commands to the Middleware Layer. Context information is a term widely used
in IoT research and characterizes data that may come from existing systems, users, through mobile
applications, IoT smart devices, agricultural machinery or public geo-services. The Conﬁguration layer
uses an IoT broker to guarantee a common interpretation of information produced by heterogeneous
data sources that typically employ different data formats and ontologies, and therefore are unable to
Information 2019, 10, 348
12 of 25
directly share information among them. An IoT broker enables the forwarding of lower-level device
information to higher-level Thing Information.
•
Regarding precision agriculture applications, a popular context broker is implemented by the
FIWARE NGSI technology, named Orion Context Broker. FIWARE is a framework of open-source
platform components towards the deployment of the IoT paradigm. FIWARE NGSI is the FIWARE
version of the OMA NGSI, an API based on HTTP that enables the integration of components
and provides the basis for the interoperability and portability of IoT-enabled Smart Agriculture
applications [34]. NGSI is an information model developed by OMA SpecWorks to manage
context information with a meta-model based on entities, attributes and metadata. This protocol
manages data concerning context entities, such as the lifetime and quality of information.
•
The implementation of a smart farming monitoring system is greatly depended upon geo-services,
location detection tools and mapping technologies. In such systems, the exchange of geographical
information should be effortlessly accomplished between the involved network entities across
the web. The Open Geospatial Consortium-Web Feature Service (OGC-WFS) [35] constitutes a
desirable asset in formulating geographic information and offering direct ﬁne-grained access
at feature property level of the data to IoT sensor nodes in precision agriculture applications.
OGC offers various standards that can ease the way location data is exchanged and stored in
a smart farming system that is based on drone monitoring. Furthermore, the OpenGIS Web
Map Service Interface Standard (WMS) [35] can be efﬁciently used by UAVs, since it provides a
simple HTTP interface for requesting geo-registered map images from one or more distributed
geospatial databases.
5. The Management Layer
In a smart farming monitoring system, the basic component of intelligence is considered to be the
study and ﬁltering of the collected data. The use of EO techniques enable the advance of cultivation
procedures and increase productivity by providing the base layer for spatial information analysis and
monitoring of agricultural activities. A large percentage of smart agriculture applications are based
on simulators, commercial programs and speciﬁc programming languages for implementing and
controlling the data system. The Management layer uses modern software tools to efﬁciently satisfy
multiple tasks, presented in Table 5.
Information management is deployed so the farmer can consult, record and modify the
information collected by the sensors in tables, statistical graphs and interactive maps. In addition,
it can download daily, monthly and annual reports of historical data. However, the farmer can
mainly see the current data of the monitored variables of one or all the WSN nodes and consult the
history. The interaction with the network and services layer is achieved using an intermediate layer of
management logic [36]. WSN data will be stored in an online database [37].
The system also enables Big Data analytics in agriculture monitoring by using tools such as
the Apache Hadoop software and various Big Data hardware platforms [38] as possible resources.
Big Data refers to information assets characterized by such a high volume, velocity and variety
able to require speciﬁc technology and analytical methods for its transformation into value [39].
In precision agriculture smart applications, the collected data are recorded in a speciﬁc format,
to discover patterns, correct errors, eliminate duplicate and inconsistencies and to solve noise problems.
Big Data technologies are playing an essential role in modern farming systems, since predictive insights
are provided regarding optimizing the quality of the crop, minimizing environmental impact, reducing
costs, increasing proﬁt and generally optimizing production efﬁciency. In addition, Big Data enable the
management of real-time operational decisions and the redesign of business processes for advancing
the food supply chain.
Furthermore, the proposed architectural scheme promotes various data processing techniques that
upgrade the impact of EO technologies in agriculture. EO by satellite leads to the acquisition of regular
or spatially continuous data regarding large areas. It provides essential information on the functioning
Information 2019, 10, 348
13 of 25
of ﬁelds and on the causes of environmental change. UAVs enable EO by using photogrammetry
techniques to extract three-dimensional digital surface models of the ﬁeld, as well as orthophotographs.
One popular algorithm for this purpose is Structure from Motion (SfM) [40]. An orthophotograph
can be used to create a realistic map of the ﬁelds by measuring true distances and providing to the
farmer a clearer helpful view from the sky. Based on photographs, digital image processing tools,
such as Pix4Dmapper can calculate various vegetation indices that can lead to conclusions, either
on each photograph individually or after the production of orthophotos regarding the crops’ state.
Vegetation indices are mathematical quantitative combinations of the absorption and scattering of
plant in different bands of the electromagnetic spectrum [41]. Calculating vegetation indices will help
to identify useful crop characteristics concerning important biological and physical parameters of the
vegetation. The best-known vegetation index is the Normalized Difference Vegetation Index (NDVI),
which is the evolution of the vegetation index ratio and is calculated by the visible and near infrared
light reﬂected from the vegetation.
Last but not least, the smart agriculture monitoring system also performs data mining processes
based on tools such as the Apache Mahout Framework so as to identify and discover hidden patterns
in the collected data, once they are processed, in the form of reviews. In addition, Machine Learning
techniques will be used in the smart monitoring platform in order to estimate the extracted parameters
of the crops’ growth rate and also help to identify objects or animals trough the collected images by
using Object-Based Image Analysis (OBIA) [42]. Moreover, new machine learning models—algorithms
focused on data classiﬁcation [43,44]—can be used to minimize the size of redundant data and fasten
the analysis.
Table 5. Smart farming monitoring system services.
Service Type
Tools
Description
Information
management
Database
The central server database for storing and maintaining the sensor
collected data, management commands and application user
information.
Management logic
The process of managing the systems units, organizing and
displaying the evaluated data into a user-friendly way.
Big Data
analytics
Apache Hadoop
Framework
Complex process of examining large and varied data sets with an
intention to uncover meaningful and useful information that can
help in deriving conclusion and take decisions.
Big Data hardware
platforms
The
use
of
different
hardware
platforms
for
Big
Data
analytics according to the available hardware, scale-ability and
performance characteristics of each platform.
Data and Image
processing
Digital Image
processing
Vegetation Indexes calculation
Photogrammetry
techniques
Extracting three-dimensional digital surface or terrain models of
the ﬁeld and orthophotographs.
Machine learning
classiﬁcation
algorithms
Classiﬁcation of data to decrease the size of redundant
information and identify objects or animals.
Data mining
Apache Mahout
Framework
Systematic and sequential process of identifying hidden patterns
and information in a large dataset.
Object-Based Image
Analysis
Identify objects or animals through the collected images
Furthermore, all these services are hosted in the cloud to be able to access them remotely from
any geographical location.
Information 2019, 10, 348
14 of 25
6. The Application Layer
Based on the proposed precision agriculture monitoring system architecture, the farmer can
interact with the IoT applications of the system to remotely manage the cultivation process.
Such applications may concern any aspect of the agricultural ﬁeld ranging from planting and irrigation
processes to plant protection and harvesting methods [45]. The applications that can be adopted may
involve the fertilizer application, the weed mapping, the spraying process, the irrigation of the ﬁeld
and the alert system.
The Variable Rate Fertilizer (VRF) application has as a target to optimize the usage of nutrients by
deﬁning the amount of fertilizer applied based on the health of the plant. Variable rate fertilizer in
precision agriculture is an area of technology that focuses on the automated application of fertilizer to
a given landscape. The way in which the materials are applied is based on data that is collected by
sensors, maps, and GPS. VRF applications bring several beneﬁts related to savings on fertilizers and
chemicals, potential yield increase and environmental protection. In the same context is the Variable
Spraying application. These types of applications implement controllers that turn the herbicide
sprayers on and off. Usually variable spraying applications take into consideration information
coming from the weed mapping tools such as the weed locations. In that case the appropriate volume
of herbicide is estimated and applied in the ﬁeld based on the weed intensity.
The Weed Mapping application focuses on the visualization of the weed occurrences within
a certain crop ﬁeld with the help of mappings. The GPS receiver with an aerial vehicle generates
maps which show the weed occurrences. These weed maps can be combined with fertilizer maps
and yield maps. The IoT-based irrigation system use a micro-controller that serves as information
gateway receiving real-time information from soil moisture and temperature sensors placed on the
ﬁelds. Generally, a moisture/temperature threshold is speciﬁed based on which the micro-controller
automatically switches on the water pump. The micro-controller also has servo motors to ensure that
the area is uniformly irrigated. The entire system can be managed remotely by the end-user through
the dedicated application.
Alert/ notiﬁcation applications are also very popular in IoT-based precision agriculture. Producers
and agriculture companies implement IoT solutions for instantly tracking their crop ﬁelds. In this case,
the data coming from IoT devices is processed and transformed into knowledge properly visualized
for offering information regarding the health of the vegetation and the soil, the behavior patterns of
the plants, detect signs of disease on time, identify insects and harmful animals and instantly alert
producers about potential difﬁculties. This type of applications serves for storing and analyzing data,
providing producers with relevant recommendations.
The aforementioned applications aim at the efﬁcient ﬁeld and crop management to:
•
increase production efﬁciency
•
improve product quality
•
provide more efﬁcient use of chemicals in cultivation
•
manage pesticide amounts
•
reduce energy consumption
•
protect the soil
•
control water consumption and underground water amounts
The IoT-based agriculture applications can be implemented for an Android or Windows
smart-phone, a tablet or as a web application. The applications of IoT-based smart farming apart from
conventional, large farming operations, targets also other growing or common trends in agricultural
such as organic farming, family farming (complex or small spaces, particular cattle and/or cultures,
preservation of particular or high quality varieties etc.), and enhance highly transparent farming. Our
precision agriculture monitoring system can also beneﬁt the dry farming technique that encompass
speciﬁc agricultural techniques for the non-irrigated cultivation of crops. Furthermore, greenhouses
can use our architectural model to intelligently monitor as well as control the climate, eliminating the
need for manual intervention.
Information 2019, 10, 348
15 of 25
7. Energy-Saving Techniques and Security Mechanisms
7.1. Energy-Saving Technologies
In precision farming applications sensor nodes are usually powered by low-energy batteries that
are difﬁcult or impossible to recharge or replace. This is considered to be a major disadvantage to
maintain a real-time monitoring system. Energy-saving techniques is vital to maintain the system’s
efﬁciency in smart farming. This kind of techniques can provide battery life extension by reducing the
amount of communication between the nodes and the base station, while minimizing the redundant
data in the network. Energy preservation techniques for precision agriculture systems are presented as
a separate architectural level covering the sensing and networking procedures of smart farming.
In the Sensor layer, the proposed energy-saving approach is an on/off process which is based on
the selection of a subset of nodes that will remain active for a certain period of time, while others remain
inactive. Following this assumption, SWORD (sleep/wake on redundant data) is an energy preserving
scheme that can be used to collect data on soil moisture [19]. The SWORD algorithm performs data
control by removing redundant data so as to minimize energy consumption and increase the life of
sensor nodes in the network.
In the Network layer, data transmissions and receptions can also be scheduled based on the
sleep/awake periods of sensor nodes at predetermined intervals. For this purpose, A2S, an automated
agricultural precision tracking system can be used [46]. Based on this energy-saving technology,
whenever the sensing period is set by the application server, the sink node keeps the schedule and
it spreads the sleep order message over its network every sensing period. Each time a node receives
the sleep message, it sets the sleep timer’s end time to the value of the duration ﬁeld included in the
message. When the meter time ends, the node detects the environment and battery voltage level and
sends the data to the source. Then, he expects the next sleep request message.
Moreover, another energy-saving scheduling technique that can be deployed in the Network layer
involves the use of unmanned ﬂying vehicles in an agricultural crop monitoring system. Based on this
scheme, the node on the unmanned ﬂying vehicle wakes the ground nodes to retrieve the measured
data. To perform this function, a coded radio signal is sent via a transmitter to the ground nodes.
The nodes are in an inactive state, except for a small receiver waiting to receive the trigger signal.
Furthermore, taking advantage of APTEEN hierarchical routing protocol, a time division multiple
access technique can be implemented as a scheduling method. Based on this technique, messages are
sent to put some nodes in sleep mode so as to avoid packet collisions between sensor nodes belonging
to different clusters. In addition, carrier sense multiple access technique is another alternative method,
which is equally effective for avoiding collisions.
7.2. Security Mechanisms
Precision agriculture monitoring systems involve the exchange of sensitive information regarding
the cultivation process, the state of crops and personal data of authorized staff. It is of great importance
for such systems to be protected against cyber-attacks. An unauthorized entry of a malicious individual
in the system may cause great damage to the cultivation process or even acquire the farmers personal
information [47]. In the pursuit of safeguarding a smart farm monitoring system the conﬁdentiality
of data should be met. In addition, it is vital to ensure the reliability of the data and the ability to
conﬁrm that a message has not been tampered with, altered or changed while on the network. Also,
the services of resources offered by the network, or by a single sensor node must be available whenever
required and ﬁnally to be able to identify the origin of a message received. Basic security mechanisms
are already deployed by the combined IoT technologies in every architectural level of the proposed
smart monitoring system. However, there are more ways to increase the level of security in each
layer separately.
One popular way of providing physical layer security in WSN and IoT systems is cryptography.
Physical layer security refers to the inner security capabilities of the Sensor layer regarding the
Information 2019, 10, 348
16 of 25
randomness of wireless channels, the signal-to-noise ratio gaps or intended jamming. There are
three kinds of cryptographic methods used in WSNs, the symmetric and asymmetric ones and hash
functions. Hash functions are special mathematical functions which map a given input to a certain
output with a ﬁxed size. Well-known cryptographically secure hashes are the Secure Hash Algorithm-2
(SHA-2) and Advanced Encryption Standard (AES) algorithm. In symmetric cryptographic techniques,
a single shared key is used between the two communicating nodes both for encryption and decryption.
This key stays known only to the nodes of the network. On the other hand, in asymmetric cryptography,
a private key can be used to decrypt and sign data. A public key is also used to encrypt and verify data.
The private key needs to be kept conﬁdential while the public key can be published freely. Asymmetric
cryptographic techniques may use the RSA (Rivest–Shamir–Adleman) algorithm, the ECC (Elliptical
Curve Cryptography) algorithm or the pairing technique. Popular frameworks of symmetric and
asymmetric technique can be found in [48].
Regarding the Link layer of our proposed architecture security mechanisms focus against the
interception, modiﬁcation and fabrication of the exchanged data. Attack detection mechanisms can
be applied, such as the misbehavior-aware threshold detection scheme for LLNs proposed in [49].
In addition, secure routing protocols may be used such as SAR(Secure aware routing protocol), which is
based on on-demand protocol such as AODV or DSR and DPRAODV (Detection, Prevention and
ReactiveAODV) [50].
Middleware security mechanisms deal with unauthorized modiﬁcations that occur due to
transmission errors (accidental) and require the use of digital signatures. Digital signature schemes
are cryptographic schemes that include key generation algorithms, signing algorithms and signature
verifying algorithms. A digital signature is an authentication mechanism that enables the creator of the
message to attach a code that acts as a signature. The Digital Signature Algorithm (DSA), developed by
the National Institute of Standards and Technology, is one of many examples of a signing algorithm.
Access control is an important building block for the overall security of a precision agriculture
monitoring system. The IoT requires access control models that apply authorization policies across
a multitude of smart sensors. In a smart farm monitoring platform, authentication is required
to prevent authorized users from accessing resources in an unauthorized manner. For instance,
a worker in the ﬁelds is a legitimate user but does not have the access rights as the main administrator
farmer. Most importantly, access control prevents illegitimate users from gaining access to resources.
The Attribute-Based Access Control (ABAC) model is a technique that assigns attributes to each entity
in the system. The attributes may refer to either a user or a resource and are deﬁned as properties
of every entity to enable authentication. Another paradigm able to provide solid communication in
the application layer is the Role-Based Access Control model (RBAC) where a user is assigned as
administrator or ordinary user that predetermines access rights policies. In the Application layer,
each user can be authenticated by the use of passwords or a smart key card [51].
8. Use Case Study: The DIAS Architecture
The DIAS research project stands for Drone Innovation in saffron Agriculture Surveillance.
It is co-funded by the European Union and Greek national funds through the Operational Program
Competitiveness, Entrepreneurship, and Innovation. University of Western Macedonia (UOWM) in
cooperation with Kozani Saffron Producers Cooperative (KSPC) aims at developing an integrated
automated surveillance system for saffron cultivation.
This 24 h real-time saffron cultivation
surveillance system is relied on signal and image collecting and processing, which is derived from
advanced surveillance, risk identiﬁcation and early warning systems, based on integrated sensor
networks, and aerial unmanned vehicles.
8.1. Saffron Cultivation
The saffron cultivation is considered to be of extreme importance for the Western Macedonia
citizens, due to the activity over saffron cultivation by a large number of citizens, the limited farming
Information 2019, 10, 348
17 of 25
geography, the unique production process to plant the saffron seeds, and the unique production risk
that this operation faces. The only kind of saffron that is systematically cultivated around the world,
for at least ten centuries, is the edible saffron or as it known in scientiﬁc (botanical) terminology Crocus
Sativus Linneaus.
The cultivation process includes harvesting the ﬂowers, as presented in Figure 2, splitting the
stigmas and stamens from the petals, drying and sorting of saffron. The picking of 1000 ﬂowers is
process of a duration around 45–55 min, while additional 100 to 130 min are required for removing
the stigmas for drying. In total, 370 to 470 h are required to produce 1 kg of dried saffron [52].
The ﬂowers are picked exactly when they are fully bloomed, and the saffron strand or stigma is at its
reddest. The harvesting process begins shortly after dawn to minimize the further sunlight exposure
to the crops, since they may lose their color and even ﬂavor. Saffron cultivation requires dry soil
with speciﬁc levels of moisture, controlled irrigation and right amounts of nitrogen, phosphorus
and potassium. Cultivation is commonly disturbed by mice, moles and rats wrecking the stems.
Furthermore, fungi may cause speciﬁc diseases at the early stages of saffron growth.
Figure 2. Saffron harvesting.
The DIAS platform aims to improve the production process, by offering the ability of immediate
interference in case of animal, disease or wild weeds detection. The farmer will be able to monitor the
ﬁelds in real time and getting alerts in case of unwanted incidents regarding the state of the plants
during all cultivation period, while raising proﬁts. To satisfy these goals, the monitoring process will
be aligned speciﬁcally with the farmers concerns and actions during each month of cultivation as
presented in Figure 3.
Figure 3. Saffron cultivation yearly stages.
8.2. DIAS Architecture
The DIAS platform follows the architectural design of the proposed remote sensing monitoring
system. As presented in Figure 4 the DIAS system is consisted of seven architectural layers. In each
layer the most suitable aforementioned technologies are used towards achieving the overall system’s
efﬁcient performance and reliable operations. The saffron cultivation is a quite demanding and delicate
process requiring the deployment of tailor-based technologies and continuous crop monitoring to
avoid animal and disease interventions.
In the Sensor layer, quadcopter UAVs with thermal, hyperspectral and RGB cameras are being
used in cooperation with multiple wireless nodes equipped with various sensors for data collection
regarding the crops. Saffron cultivation monitoring requires the study of small sized crops and
the notice of minimal crop state variations during each month. To select the desired information
UAVs must ﬂy in a certain distance and place for a speciﬁc period of time and by using different
Information 2019, 10, 348
18 of 25
position angles. Quadcopter UAVs is considered to be the best choice for saffron monitoring since
they have rotary wings, which provide them with the ability of maneuverability, while also ﬂying
in low speed. Regarding RGB cameras, they are ideal since saffron cultivation requires the capture
of data-images in different weather conditions avoiding inadequate or excessive exposure of the
image. Using multispectral or hyperspectral sensors, UAVs can also obtain information related to
spectral absorption and reﬂection of the crops in several bands. This quite useful since the provided
information can then be used to calculate vegetation indices and monitor the state of saffron crops
based on them. On the other hand, thermal imaging detects speciﬁc levels of radiation and translates
it into a grayscale image, using brighter and darker shades of heat representation. This ability is also
essential in saffron cultivation since the ﬁelds are regularly trampled by animals that are not being
detected on time in before they cause any damage. The DIAS monitoring system uses different ground
and on-leaf sensors to collect useful data for improving the cultivation process. More speciﬁcally,
environmental humidity and temperature is evaluated since saffron requires speciﬁc conditions to
prosper. Additionally, the levels of luminosity, leaf-wetness, soil moisture, pH and wind speed are also
of great importance. Furthermore, the amounts of nitrogen, phosphorus and potassium in the soil can
have a severe impact on the plant’s growth, as well as the moisture levels in the soil. The farmer will
be able to predict production loss efﬁciently due to a round knowledge of the saffron ﬁelds condition
and even intervene with possible treatments to change its course for the better.
Regarding the Link and Encapsulation layer, sensor data exchange in the DIAS platform is enabled
by the LoRaWAN technology and the IPv6 protocol. LoRa technology offers several advantages.
The LoRa physical layer uses ISM bands 868 and 915 MHz—frequencies that are free to use anywhere
in the world. In addition, LoRa devices consume very little power making it ideal for battery-powered
devices and it can also transmit and receive data for up to 15 km in suburban areas and 5 km in
urban areas. Another advantage of LoRa is its high network capacity. In LoRaWAN, a single gateway
can accommodate 1000 end-node devices. On the other hand, IPv6 offers large addressing space
and has built-in support for network auto-conﬁguration. In the DIAS platform, each sensor node
is characterized by its own IP address and uses a power saving scheduling and routing protocol to
transmit the collected data to the nearest LoRa Gateway. The information to be exchanged is encrypted
before transmission. Each LoRa gateway forwards the information to the according network router for
Internet access and data storage to the system’ database. UAVs’ data transmission and communication
is enabled by the IEEE 802.11ah networking standard in cooperation with the IPv6 protocol, to forward
the collected images to the network server as well.
In the Middleware layer, the DIAS platform will employ the MQTT-SN protocol. MQTT-SN
enables the management of all DIAS networking devices through message exchanges coordinated by
the FIWARE’s context broker. It is essential to maintain the monitoring’s system reliability towards
achieving meaningful data collection. Based on this protocol, the exchanged messages can be organized
by topics and importance regarding device management commands, transmission requests initiated by
a higher layer and data acquisition. Sixteen number of message types are supported and transmitted
in an asynchronous way of communication by the publish-subscribe model. TCP and UDP will also be
used as transport protocols. MQTT is ideal for the DIAS system since it excels in smart sensor device
communication on a wide area network, due to the publish/subscribe architecture with the broker
in the middle. MQTT is also very useful if the bandwidth is limited to enhance network reliability
and availability.
In the according Conﬁguration layer, all saffron ﬁeld collected data will be grouped and
formulated to reach the information management unit. This layer facilitates the FIWARE NGSI
API so to produce the desired information model of the acquired ﬁeld data based on efﬁcient
context management.
The FIWARE’s Orion Context Broker has powerful features enhancing
the capabilities and performance of the DIAS monitoring system such as enabling asynchronous
application notiﬁcations. The basic operations of the current layer include enabling the publication,
Information 2019, 10, 348
19 of 25
consumption, subscription and processing of all the information relevant to the crops and the
cultivation process in the DIAS platform.
Figure 4. The DIAS architecture.
The Management layer constitutes the basic operation center of the DIAs platform. It stores,
maintains, analyzes the collected data and produces predictions for the progress of the crops growth
rate and statistics regarding they current state. According to the commands acquired from the user of
the platform in the highest architectural layer, the information management logic initiates the according
processes. Data processing includes the use of the Random Forest machine learning classiﬁcation
algorithm for direct extraction of conclusions regarding the growth and health of vegetation. This
algorithm is directly applied on the data of the images acquired by the UAVs, evaluating the RGB
Information 2019, 10, 348
20 of 25
colors and the intensity of each pixel. The Random Forest scheme performs very well with high
dimensionality and can handle binary features, categorical features, and numerical features. This
method is chosen since very little pre-processing is required and the data does not need to be rescaled
or transformed. Digital image processing of geospatially corrected aerial images (orthophotographs)
focuses on producing the according vegetation indexes for evaluating the state of saffron plants. Two
kind of vegetation indexes will be calculated by the PiX4D image processing tool. Vegetation indexes
derived from multispectral information, such as NDVI will enable the detection of unhealthy or sparse
vegetation that reﬂects more visible light and less near infrared light, making it easy to monitor the
growth and health of saffron crops. On the other hand, regarding the use of RGB-based Vegetation
Indices, Excess Greenness Index (ExG) is based on the assumption that saffron plants will display a
clear high degree of greenness, while soil being the only background element. Finally, the Normalized
Difference Index (NDI) will be also used since it can enable the separation of saffron plants from
soil and residue background images, using only green and red channels. Spectral information can
help signiﬁcantly in assessing a lot biological and physical characteristics of the saffron crops. Any
kind of wild weeds or animal detection based on thermal imaging in the ﬁelds initiates alerts for
immediate intervention and is taken into consideration as a note in the cultivation calendar created by
the platform for the farmer. For this purpose, the OBIA algorithm is also used to recognize weeds or
discriminate species. Object-based image analysis is based on the comparison between sets of similar
pixels called image objects in measures of spectral properties (i.e., color), size, shape, and texture,
as well as context. The OBIA algorithm is chosen since it is more suited to landscape-scale analyses
and can ﬁlter out meaningless information and assimilate other pieces of information into a single
object. After processing, all the collected sensor data are categorized and evaluated in accordance with
the desired vegetation index values, moisture levels and general plant state for each month during
the cultivation process. For these tasks, the DIAS platform employs powerful and well-known tools,
the Apache Spark Framework focusing on Big Data analytics and the WEKA (Waikato Environment)
Framework specializing in data mining tasks. The evaluation results will point out the vulnerable
spots in the ﬁeld with helpful statistical graphs and suggest possible solutions to the farmer, such as
the use of fertilizer.
In the Application Layer, each user can access the DIAS platform by using his/her own unique
password. According to their authority and activities in the saffron ﬁeld the users have different access
rights in the DIAS platform. A user may be the administrator of the platform, a representative of the
KSPC board, a farmer or a worker in the ﬁelds. For instance, a worker can only observe the evaluation
results in order to aid the farmer in treating the plant growth, while the KSPC representative can
add observation notes, can schedule and initiate sensor data collection in a speciﬁc ﬁeld and also
manage the ﬂight plan of UAVs. On the other hand, the platform administrator is only one who can
add new users and new saffron ﬁelds for cultivation to be observed in the system. Access in the
DIAS platform is forbidden for non-authorized users. In the Application layer, the management of
the four basic operational units of the DIAS system can be initiated. These are the Visualization Unit,
the Data Management Unit, the Prediction Unit and the Data collection Unit. By entering the Data
collection Unit, a user can initiate sensor data collection in a selected ﬁeld or modify existing data
in the platform. By entering the Data Management Unit, the user can evaluate orthophotographs
and calculate vegetation indexes according to speciﬁc data in a speciﬁc saffron ﬁeld with the help of
Pix4DMapper tool. The Visualization Unit is related to the presentation of statistical results and graphs
regarding each saffron ﬁeld, while the Prediction Unit employs the aforementioned data mining tools
to produce a sufﬁcient evaluation of the collected data. All system information is stored in the central
server database.
Based on the acquired and processed data, farmers can produce statistics regarding the progress in
saffron production and avoid ﬁnancial loss, while improving the quality of the crops and accomplishing
a considerable rise in production.
Information 2019, 10, 348
21 of 25
8.3. Beneﬁts and Costs
Greece is the second largest saffron producing country, with an average output of 4 tons of p.a.
during the last four decades, most of which is directed in export markets. The establishment of the
‘Kozani Saffron Producers Cooperative’ marked the beginning of a good decade for this product
with production reaching its height record of more than 12 tons in 1982 [53]. Nevertheless, in the
period following Greece’s accession to the European Community, farmers began abandoning saffron
cultivation. This fact resulted in a signiﬁcant decrease in yield with an average yield of 800 g per
stremma (1 ha = 10 stremmas = 1000 m2 ). However, this trend seems to be reversed since 2010 and
currently yields vary around 1 ton per stremma. Currently, Greek saffron price is about 1200 euros per
Kg. Nearly 5000 spots are needed to produce 100 g of red saffron. The average produce per acre is 6 kg
of dried stigmas (red product). The lower production of the plant is on the ﬁrst year of the plantation,
while the highest on the third and the fourth.
In the year of 2015, a study in Greek saffron cultivation resulted that farm managers need
to address the efﬁciency of input use and raise capital and labor productivities to maintain
competitiveness [53]. The saffron quality is determined by the color, ﬂavor and size of the stigmas.
The DIAS platform aims to upgrade proﬁt earnings by the adoption of new technologies, ensuring
ﬂower picking at appropriate time in a proper collection material at an appropriate age. Animal
intrusions in the ﬁelds, causing a huge loss in production, will be prevented and crops diseases will
be detected in time. The overall equipment cost is considered to be a safe investment for farmers
since most of the technologies involved are open source and the initial cost of the related hardware
and software can be shared across producers. Currently, the DIAS initiative is under construction
and no experimental results are available to conﬁrm the proposed objectives. However, in Table 6
we present the production rate of Greek Saffron as recorded in [53], while in Table 7 an average
estimation is provided regarding the increase in cultivation operations by adopting the DIAS platform.
These percentages are the estimations provided by two of the producers whose ﬁelds participate in
the pilot study. The estimations show that on average the farmers calculate an increase of around
20% in production, this percentage is in accordance to other types of cultivations such as olives and
potatoes [54].
The use of the DIAS project can offer a signiﬁcant increase in saffron production. Nevertheless,
since no pilots have been implemented yet in the project, the Return on Investment (ROI) is difﬁcult to be
estimated. An investment of time and money from the DIAS consortium is required to investigate how
the data gathered from UAVs can connect to and affect other things that are happening on the ﬁelds.
Saffron growers need that information to provide context and create a correlation regarding causes
and effects. At that point ROI becomes signiﬁcant promoting UAVs as a part of the desired solution
and not as the solution itself. Furthermore, due to shared costs between project partners, ROI becomes
a collective performance measure that can be estimated only when each member has acquired the
according technological beneﬁts. A complex proﬁtability study is required to specify the precision
service offerings, as presented in [55,56]. Each partner in the DIAS project owns and offers different
assets in this endeavor, thus calculating the overall ROI of UAV usage from the side of farmers is not
yet possible.
Table 6. Greek saffron cultivation economic estimation in one year.
Average production results
2200 euros
Average produced yield
1.8 Kgs
Average labor cost of annual working hours
145 euros per 1000 m2
Average cultivated land
15,000 m2
Information 2019, 10, 348
22 of 25
Table 7. Economic estimation for Greek saffron cultivation via using the DIAS platform in one year.
DIAS platform hardware and software equipment cost
45,000 euros
Average increase in production results in euros
10%
Average increase in produced yield in Kgs per 1000 m2
20%
Average increase in saffron quality per 1000 m2
25%
9. Challenges
The implementation and maintenance of a monitoring system in precision agriculture faces
several challenges. The greatest challenge in the sensor layer is for sensor nodes to achieve efﬁcient and
continuous operation for a long time in a natural environment, while taking into account the climate
change and wildlife interventions. The battery life of sensor nodes is not considered satisfactory,
and it is necessary to design and implement energy-saving protocols with the highest possible
system performance among other precautions. In addition, depending on the type of application,
the supported agricultural work and the implementation technologies, the problems that arise can be
differentiated. For instance, the use of sensors and controllers from different manufacturers prevents
communication between them and makes it more difﬁcult to interconnect with other agricultural
components. Also, the sensor inertia phenomenon was observed in a high-speed WSN due to non-steep
changes in humidity and soil temperature.
In the network layer, the basic challenges regarding the operation of a crop monitoring system
with WSN and IoT technologies include the limited computational capabilities of sensor nodes.
The restricted memory of the nodes disables them to handle large amounts of communication data
and cluster-based interconnection procedures. Due to this fact, long data queues are created in each
node, leading to greater delay in transmissions. The same outcome can be triggered by the long
communication distance of sensor nodes. One major issue that routing algorithms must deal with in
such cases is the high level of energy consumption, which leads to a reduction in the overall viability
of the network. In precision agriculture monitoring systems routing protocols should offer minimum
delay, be able to provide efﬁcient services in many sensor nodes, while taking into account the limited
resources. They should also be capable of accepting all sorts of environments including severe and loss
environments, while providing information security and privacy. Most routing protocols use some
localization technique to obtain knowledge concerning their locations. The performance of the routing
protocol is a function of network size and transmission media. Therefore, transmission media of good
quality enhances the network performance directly.
However, in many cases the failure of such advanced monitoring system may be due to the
geographic, cultural or socio-economic distance between system designers and the intended user
community. Cost is an important limiting factor in the implementation of such systems. The cost
depends to a great extent on the quality of the materials and the topology of the network.
10. Conclusions
This paper proposes the architectural components of a smart farming monitoring system, based on
modern IoT communication technologies and WSN capabilities, in cooperation with energy-saving
protocol schemes. A use case study based on the DIAS project is also presented, enhancing the reliability
and contribution of our model. The IoT agricultural applications enable farmers to collect and analyze
meaningful data. Large landowners and small farmers should welcome the potential of IoT market
for agriculture by installing smart technologies to increase competitiveness and sustainability in their
productions. The rapid growth of population forces farmers to meet the demand by implementing
agricultural IoT solutions in a prosperous manner. In the future, an in-depth study will be carried out
regarding the real-time performance of the proposed model in the DIAS project.
Information 2019, 10, 348
23 of 25
Author Contributions: Conceptualization, A.T., P.S. and S.B.; Methodology, A.T., P.S. and S.B.; Writing—original
draft, A.T.; Writing—review & editing, P.S. and S.B.
Funding: This research was co-funded by the European Union and Greek national funds through the Operational
Program Competitiveness, Entrepreneurship, and Innovation, grant number T1EDK-04873, project “Drone
innovation in Saffron Agriculture,” DIAS.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Guillermo, J.C.; García-Cedeño, A.; Rivas-Lalaleo, D.; Huerta, M.; Clotet, R. IoT Architecture Based on
Wireless Sensor Network Applied to Agricultural Monitoring: A Case of Study of Cacao Crops in Ecuador.
In Advances in Information and Communication Technologies for Adapting Agriculture to Climate Change II; Springer
International Publishing: Cham, Switzerland, 2019; pp. 42–57.
2.
Donzia, S.K.Y.; Kim, H.K.; Hwang, H.J. A Software Model for Precision Agriculture Framework Based on
Smart Farming System and Application of IoT Gateway. In Computational Science/Intelligence and Applied
Informatics; Lee, R., Ed.; Springer International Publishing: Cham, Switzerland, 2019; pp. 49–58. [CrossRef]
3.
Koksal, O.; Tekinerdogan, B. Architecture design approach for IoT-based farm management information
systems. Precis. Agric. 2018, 20, 926–958. [CrossRef]
4.
Kamilaris, A.; Gao, F.; Prenafeta-Boldu, F.X.; Ali, M.I. Agri-IoT: A semantic framework for Internet of
Things-enabled smart farming applications. In Proceedings of the 2016 IEEE 3rd World Forum on Internet of
Things (WF-IoT), Reston, VA, USA, 12–14 December 2016; pp. 442–447. [CrossRef]
5.
Ferrandez, J.; Manuel García-Chamizo, J.; Nieto-Hidalgo, M.; Mora-Pascual, J.; Mora-Martínez, J. Developing
Ubiquitous Sensor Network Platform Using Internet of Things: Application in Precision Agriculture. Sensors
2016, 16, 1141. [CrossRef] [PubMed]
6.
Vasisht, D.; Kapetanovic, Z.; Won, J.; Jin, X.; Chandra, R.; Sinha, S.; Kapoor, A.; Sudarshan, M.; Stratman, S.
FarmBeats: An IoT Platform for Data-Driven Agriculture. In Proceedings of the 14th USENIX Symposium on
Networked Systems Design and Implementation (NSDI 17), Boston, MA, USA, 27–29 March 2017; USENIX
Association: Berkeley, CA, USA, 2017; pp. 515–529;
7.
Ahmed, N.; De, D.; Hussain, I. Internet of Things (IoT) for Smart Precision Agriculture and Farming in Rural
Areas. IEEE Internet Things J. 2018, 5, 4890–4899. [CrossRef]
8.
Ji, M.; Yoon, J.; Choo, J.; Jang, M.; Smith, A. LoRa-based Visual Monitoring Scheme for Agriculture
IoT. In Proceedings of the 2019 IEEE Sensors Applications Symposium (SAS), Sophia Antipolis, France,
11–13 March 2019; pp. 1–6. [CrossRef]
9.
Ferrandez, J.; Manuel García-Chamizo, J.; Nieto-Hidalgo, M.; Mora-Martínez, J. Precision Agriculture Design
Method Using a Distributed Computing Architecture on Internet of Things Context. Sensors 2018, 18, 1731.
[CrossRef] [PubMed]
10.
Triantafyllou, A.; Sarigiannidis, P.; Lagkas, T.D. Network Protocols, Schemes, and Mechanisms for Internet
of Things (IoT): Features, Open Challenges, and Trends. Wirel. Commun. Mob. Comput. 2018, 2018, 5349894.
[CrossRef]
11.
Triantafyllou, A.; Tsouros, D.C. ; Sarigiannidis, P.; Bibi, S. An Architecture model for Smart Farming.
In Proceedings of the 15th International Conference on Distributed Computing in Sensor Systems (DCOSS),
Santorini Island, Greece, 29–31 May 2019; pp. 385–392. [CrossRef]
12.
International Organization for Standardization; ISO/IEC 7498-1: The Basic Model; Technical Report; 1994;
ISO Central Secretariat, Chemin de Blandonnet 8, CP 401 - 1214 Vernier, Geneva, Switzerland. Available
Online: https://www.iso.org/standard/20269.html (accessed on 5 November 2019).
13.
Vuolo, F.; D’Urso, G.; Michele, C.D.; Bianchi, B.; Cutting, M. Satellite-based irrigation advisory services:
A common tool for different experiences from Europe to Australia. Agric. Water Manag. 2015, 147, 82–95.
[CrossRef]
14.
Bauer, J.; Aschenbruck, N. Design and implementation of an agricultural monitoring system for smart
farming. In Proceedings of the 2018 IoT Vertical and Topical Summit on Agriculture—Tuscany (IOT Tuscany),
Tuscany, Italy, 8–9 May 2018; pp. 1–6. [CrossRef]
Information 2019, 10, 348
24 of 25
15.
Calera, A.; Campos, I.; Osann, A.; D’Urso, G.; Menenti, M. Remote Sensing for Crop Water Management:
From ET Modelling to Services for the End Users. Sensors 2017, 17, 1104. [CrossRef] [PubMed]
16.
Petropoulos, G.P.; Srivastava, P.K.; Piles, M.; Pearson, S. Earth Observation-Based Operational Estimation of
Soil Moisture and Evapotranspiration for Agricultural Crops in Support of Sustainable Water Management.
Sustainability 2018, 10, 181. [CrossRef]
17.
Anzola, J.; García Díaz, V.; Jiménez, A. WSN analysis in grid topology for potato crops for IoT. In Proceedings
of the 4th Multidisciplinary International Social Networks Conference, Bangkok, Thailand, 17–19 July 2017;
pp. 1–7. [CrossRef]
18.
Sarigiannidis, P.; Lagkas, T.; Bibi, S.; Ampatzoglou, A.; Bellavista, P. Hybrid 5G optical-wireless SDN-based
networks, challenges and open issues. IET Netw. 2017, 6, 141–148. [CrossRef]
19.
Jawad, H.M.; Nordin, R.; Gharghan, S.K.; Jawad, A.M.; Ismail, M.; Abu-AlShaeer, M.J. Power Reduction
with Sleep/Wake on Redundant Data (SWORD) in a Wireless Sensor Network for Energy-Efﬁcient Precision
Agriculture. Sensors 2018, 18, 3450. [CrossRef] [PubMed]
20.
Kone, C.T.; Haﬁd, A.; Boushaba, M. Performance Management of IEEE 802.15.4 Wireless Sensor Network for
Precision Agriculture. IEEE Sens. J. 2015, 15, 5734–5747. [CrossRef]
21.
Du, K.; Sun, Z.; Zheng, F.; Chu, J.; Ma, J. Monitoring System for Wheat Meterological Disasters using
Wireless Sensor Networks. In Proceedings of the 2017 ASABE Annual International Meeting, Spokane, WA,
USA, 16–19 July 2017. [CrossRef]
22.
Heble, S.; Kumar, A.; Prasad, K.V.V.D.; Samirana, S.; Rajalakshmi, P.; Desai, U.B. A low power IoT network
for smart agriculture. In Proceedings of the 2018 IEEE 4th World Forum on Internet of Things (WF-IoT),
Singapore, 5–8 February 2018; pp. 609–614. [CrossRef]
23.
Anurag, D.; Roy, S.; Bandyopadhyay, S. Agro-sense: Precision agriculture using sensor-based wireless mesh
networks. In Proceedings of the 2008 First ITU-T Kaleidoscope Academic Conference—Innovations in NGN:
Future Network and Services, Geneva, Switzerland, 12–13 May 2008; pp. 383–388. [CrossRef]
24.
El-kader, S.M.A.; El-Basioni, B.M.M. Precision farming solution in Egypt using the wireless sensor network
technology. Egypt. Inform. J. 2013, 14, 221–233. [CrossRef]
25.
Aquino-Santos, R.; González, A.; Edwards-Block, A.; Virgen Ortíz, R. Developing a New Wireless Sensor
Network Platform and Its Application in Precision Agriculture. Sensors 2011, 11, 1192–1211. [CrossRef]
[PubMed]
26.
Chen, Y.; Chanet, J.P.; Hou, K.M.; Shi, H.; de Sousa, G. A Scalable Context-Aware Objective Function (SCAOF)
of Routing Protocol for Agricultural Low-Power and Lossy Networks (RPAL). Sensors 2015, 15, 19507–19540.
[CrossRef] [PubMed]
27.
Weber, P.; Jäckle, D.; Rahusen, D.; Sikora, A. IPv6 over LoRaWANTM. In Proceedings of the 2016 3rd
International Symposium on Wireless Systems within the Conferences on Intelligent Data Acquisition and
Advanced Computing Systems (IDAACS-SWS), Offenburg, Germany, 26–27 September 2016; pp. 75–79.
[CrossRef]
28.
Sobral, J.V.V.; Rodrigues, J.J.P.C.; Rabêlo, R.A.L.; Saleem, K.; Furtado, V. LOADng-IoT: An Enhanced Routing
Protocol for Internet of Things Applications over Low Power Networks. Sensors 2019, 19, 150. [CrossRef]
[PubMed]
29.
Tukade, T.M.; Banakar, R. Data transfer protocols in IoT—An overview. Int. J. Pure Appl. Math. 2018,
118, 121–138.
30.
Mihini/M3DA Speciﬁcation. Available Online: https://wiki.eclipse.org/Mihini/M3DA_Speciﬁcation
(accessed on 5 November 2019).
31.
OMA LightweightM2M. Available Online: https://www.omaspecworks.org/what-is-oma-specworks/iot/
lightweight-m2m-lwm2m/ (accessed on 5 November 2019).
32.
oneM2M—Standards for M2M and the Internet of Things. Available Online: http://www.onem2m.org/
(accessed on 5 November 2019).
33.
DDS Foundation. Available Online: https://www.dds-foundation.org/what-is-dds-3/ (accessed on 5
November 2019).
34.
FIWARE NGSI. Available Online: https://forge.ﬁware.org/plugins/mediawiki/wiki/ﬁware/index.php/
FI-WARE_NGSI_Context_Management_tutorial (accessed on 5 November 2019).
35.
OGC Implementation Standards. Available Online: https://www.opengeospatial.org/docs/is (accessed on
5 November 2019).
Information 2019, 10, 348
25 of 25
36.
Eleftherakis, G.; Pappas, D.; Lagkas, T.; Rousis, K.; Paunovski, O.
Architecting the IoT Paradigm:
A Middleware for Autonomous Distributed Sensor Networks. Int. J. Distrib. Sens. Netw. 2015, 2015, 139735.
[CrossRef]
37.
Capella, J.V.; Campelo, J.C.; Bonastre, A.; Ors, R. A Reference Model for Monitoring IoT WSN-Based
Applications. Sensors 2016, 16, 1816. [CrossRef] [PubMed]
38.
Ryu, M.; Yun, J.; Miao, T.; Ahn, I.; Choi, S.; Kim, J. Design and implementation of a connected farm for smart
farming system. In Proceedings of the 2015 IEEE SENSORS, Busan, Korea, 1–4 November 2015; pp. 1–4.
[CrossRef]
39.
Wolfert, S.; Ge, L.; Verdouw, C.; Bogaardt, M.J. Big Data in Smart Farming—A review. Agric. Syst. 2017,
153, 69–80. [CrossRef]
40.
Westoby, M.; Brasington, J.; Glasser, N.; Hambrey, M.; Reynolds, J. ‘Structure-from-Motion’ photogrammetry:
A low-cost, effective tool for geoscience applications. Geomorphology 2012, 179, 300–314. [CrossRef]
41.
Huang, Y.; Reddy, K.N.; Fletcher, R.S.; Pennington, D. In Proceedings of the UAV Low-Altitude Remote
Sensing for Precision Weed Management. Weed Technol. 2018, 32, 2–6. [CrossRef]
42.
Huang, Y.; Chen, Z.X.; Tao, Y.U.; Huang, X.Z.; Gu, X.F. Agricultural remote sensing big data: Management
and applications. J. Integr. Agric. 2018, 17, 1915–1931. [CrossRef]
43.
Keswani,
B.;
Mohapatra,
A.G.;
Mohanty,
A.;
Khanna,
A.;
Rodrigues,
J.J.P.C.;
Gupta,
D.;
de Albuquerque, V.H.C. Adapting weather conditions based IoT enabled smart irrigation technique in
precision agriculture mechanisms. Neural Comput. Appl. 2019, 31, 277–292. [CrossRef]
44.
Hamouda, Y.E.M.; Msallam, M.M. Smart heterogeneous precision agriculture using wireless sensor network
based on extended Kalman ﬁlter. Neural Comput. Appl. 2019, 31, 5653–5669. [CrossRef]
45.
Cambra, C.; Sendra, S.; Lloret, J.; Garcia, L. An IoT service-oriented system for agriculture monitoring.
In Proceedings of the 2017 IEEE International Conference on Communications (ICC), Paris, France,
21–25 May 2017; pp. 1–6. [CrossRef]
46.
Yoo, S.; Kim, J.; Kim, T.; Ahn, S.; Sung, J.; Kim, D. A2S: Automated Agriculture System based on WSN.
In Proceedings of the 2007 IEEE International Symposium on Consumer Electronics, Irving, TX, USA,
20–23 June 2007; pp. 1–5. [CrossRef]
47.
Lagkas, T.; Argyriou, V.; Bibi, S.; Sarigiannidis, P. UAV IoT Framework Views and Challenges: Towards
Protecting Drones as “Things”. Sensors 2018, 18, 4015. [CrossRef] [PubMed]
48.
Sharma, G.; Bala, S.; Verma, A.K. Security Frameworks for Wireless Sensor Networks—Review. Procedia
Technol. 2012, 6, 978–987. [CrossRef]
49.
Pu, C.Energy Depletion Attack Against Routing Protocol in the Internet of Things. In Proceedings of the
2019 16th IEEE Annual Consumer Communications Networking Conference (CCNC), Las Vegas, NV, USA,
11–14 January 2019; pp. 1–4. [CrossRef]
50.
Savarimuthu, N.; Vijayalakshmi, K.; Padmapriya, V.
A Review of Network Layer Attacks and
Countermeasures in WSN. IJESC 2018, 10. [CrossRef]
51.
Beltran, V.; Skarmeta, A.F.
Overview of Device Access Control in the IoT and its Challenges.
IEEE Commun. Mag. 2019, 57, 154–160. [CrossRef]
52.
Kumar, R.; Singh, V.; Devi, K.; Sharma, M.; Singh, M.; Ahuja, P. State of Art of Saffron (Crocus sativus L.)
Agronomy: A Comprehensive Review. Food Rev. Int. 2008, 25, 44–85. [CrossRef]
53.
Melfou, K.; Loizou, E.; Oxouzi, E.; Papanagiotou, E. Economic Performance of Quality Labeled Saffron in
Greece. Procedia Econ. Financ. 2015, 24, 419–425. doi:10.1016/S2212-5671(15)00698-X. [CrossRef]
54.
van Evert, F.; Gaitán-Cremaschi, D.; Fountas, S.; Kempenaar, C. Can precision agriculture increase the
proﬁtability and sustainability of the production of potatoes and olives?
Sustainability 2017, 9, 1863.
[CrossRef]
55.
Erickson, B.; Widmar, D.A. 2015 Precision Agricultural Services Dealership Survey Results; Purdue University:
West Lafayette, IN, USA, 2015
56.
Baio, F.; Silva, S.; Camolese, H.; Neves, D. Financial analysis of the investment in precision agriculture techniques
on cotton crop. Eng. Agrícola 2017, 37, 838–847. [CrossRef]
c⃝ 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 2:
- APA Citation: Hossain, M. M., Rahman, M. A., Chaki, S., Ahmed, H., Haque, A., Tamanna, I., ... Ferdous, M. J. (2023). Smart-Agri: A Smart Agricultural Management with IoT-ML-Blockchain Integrated Framework. International Journal of Advanced Computer Science and Applications, 14(7), 985-996.
  Main Objective: To present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that addresses the challenges of efficient water resource utilization, enhanced productivity, and data security.
  Study Location: Unspecified
  Data Sources: Sensor data, agricultural field data
  Technologies Used: IoT, ML, Blockchain
  Key Findings: The proposed system integrates advanced sensing technologies, IoT, ML, and Blockchain to provide real-time monitoring and control of irrigation systems, enabling farmers to optimize water use, improve crop yield, and ensure data integrity and security.
  Extract 1: With the release of open-source Arduino devices and the availability of different sensors, it is now possible to build devices that can monitor soil moisture content and irrigate fields or landscapes as needed. Machine learning algorithms are used to assess various agricultural data and may readily forecast which decisions should be made to improve farmland productivity.
  Extract 2: In comparison to their previous farming ways, the farmer may easily combine ML and IoT into their farming and create an automated system that is more time effective and less risky.
  Limitations: None
  Relevance Evaluation: The paper is highly relevant to the specific point I am making in my literature review, which is to explore the use of advanced sensing technologies, such as hyperspectral imaging and thermal sensing, for non-invasive plant stress detection. The paper provides a comprehensive overview of the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and ML technologies, which is essential for understanding the context and significance of my specific point.
  Relevance Score: 1.0
  Inline Citation: (Hossain et al., 2023)
  Explanation: Md. Mamun Hossain et al. (2023) present an advanced Internet of Things (IoT)-Machine Learning (ML)-Blockchain integrated system for smart agricultural management. This system addresses key challenges in agriculture, such as efficient water resource utilization, enhanced productivity, and data security. The paper focuses on the initial stages of the automated irrigation management pipeline, particularly data collection, edge and fog computing, and real-time data transmission.

 Full Text: >
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
Smart-Agri: A Smart Agricultural Management with
IoT-ML-Blockchain Integrated Framework
Md. Mamun Hossain, Md. Ashiqur Rahman, Sudipto Chaki, Humayra Ahmed, Ahsanul Haque,
Iffat Tamanna, Sweety Lima, Most. Jannatul Ferdous, Md. Saifur Rahman
Department of Computer Science and Engineering,
Bangladesh University of Business and Technology, Dhaka, Bangladesh
Abstract—This paper presents intuitive directions for field
research by introducing a ground-breaking IoT-ML-driven in-
telligent farm management platform. This study’s main goal
is to address agricultural difficulties by providing a thorough,
integrated solution. This work makes a variety of important
contributions. By utilizing cutting-edge technology like IoT and
Machine Learning (ML), it first improves conventional farm
management procedures. Farmers now have the capacity to
remotely monitor and regulate irrigation management thanks to
sensor-based real-time data. Second, based on data gathered from
agricultural fields, our machine learning model offers improved
water control management and fertilizer use recommendations,
maximizing production while minimizing resource usage. The
suggested solution also uses blockchain technology to create a
safe, decentralized network that guarantees data integrity and
defends against threats. We also introduce energy harvesting
technology to address the issue of continuous energy supply for
IoT devices, which lessens the load on farmers by removing the
requirement for additional batteries. We achieved 89.5% accuracy
in our proposed machine learning model. The suggested model
would provide a variety of services to farmers, including pesticide
recommendations and water motor control via mobile applications
and a cloud database.
Keywords—Smart agriculture; machine learning; internet of
things; energy harvesting; blockchain technology
I.
INTRODUCTION
Without a doubt, agriculture is the most important source of
livelihood in Bangladesh. As the world’s population expands,
increased agricultural output is essential. The amount of
fresh water and appropriate fertilizer used in irrigation must
be raised in order to maintain enhanced farm productivity.
Unintentional water waste happens when water consumption
is not planned. Choosing the right fertilizer for a particular
farmland is likewise a difficult challenge for our farmers.
This demonstrates the urgent need for alternatives to reduce
water waste and appropriate fertilizer choices without placing
farmers under stress. In the Electronic age, agriculture is rapidly
becoming a data-intensive sector, with farmers collecting and
analyzing massive amounts of data from various sources (e.g.,
sensors, farming machinery, etc.) to obtain vital information
and become more efficient in production. Technology nowadays
has advanced a lot. With the help of Machine Learning and
IoT devices, a drastic change can be made possible in the
agricultural industry [1].
With the release of open-source Arduino devices and the
availability of different sensors, it is now possible to build
devices that can monitor soil moisture content and irrigate
fields or landscapes as needed. Machine learning algorithms
are used to assess various agricultural data and may readily
forecast which decisions should be made to improve farmland
productivity. In comparison to their previous farming ways,
the farmer may easily combine ML and IoT into their farming
and create an automated system that is more time effective
and less risky. Here, Fig. 1 depicts the difference between the
traditional system with the ML-based agricultural framework.
Wireless Sensor Networks(WSNs) technologies have a
major challenge with limited energy. Many research in WSNs
has also been focused on reliable energy supply to extend
the survival time of limited power sources in a network [2].
Energy harvesting techniques are used to overcome the energy-
scarcity problem of WSNs. Energy harvesting is a process in
which energy is obtained from the environment as renewable
energy sources like solar radiation, Radio Frequency (RF),
wind, geothermal, electromagnetic (EM) waves, hydro, etc.,
and is stored effectively for driving various applications systems
which may include wireless sensor networks (WSNs) [3] [4].
Therefore, it can be used to operate the devices of the embedded
system for a reliable energy supply.
Security is one of the most critical aspects of IoT, as it
deals with the protection of data and devices from unauthorized
access, use, disclosure, disruption, modification, or destruction
[5]. Encryption mechanisms are mostly used to ensure that
data is securely transmitted. But, regularly used encryption
algorithms such as DES, AES, and RSA will be heavy for small-
scale embedded systems. Therefore, blockchain technology can
be used as a lightweight calculation technique to reliably operate
and secure an IoT system[6] [7].
This paper presents the latest IoT-ML-driven intelligent agri-
cultural management and provides a substantial new research
direction. The central insight of this work is to offer possible
solutions to farming hazards while providing a combined
framework. Some significant contributions of this paper are
outlined as follows:
•
Smart Management: Traditional agricultural manage-
ment is strengthened with edge-cutting technologies
(i.e., IoT and Machine Learning).
•
Distant Monitoring and Controlling: Farmers can
monitor and control irrigation management from a
distance in terms of sensor-based real-time data.
•
Intelligent Decision Making: Our machine learning
model provides substantial water control management
www.ijacsa.thesai.org
985 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
Fig. 1. Architectural differences between traditional agricultural management
with IoT-ML-Blockchain based agricultural framework.
and fertilizer utilization direction for a minimum
resource with a maximum throughput based on the
data collected from the farming field.
•
Block chain Based Security System: Our proposed
solution uses blockchain technology to create a secure
and decentralized network that can ensure data integrity
and protect data from denial of service (DDoS) attacks,
and man-in-the-middle (MITM) attacks.
•
Energy Harvesting: To ensure a continuous energy
supply for the IoT system, we have introduced energy
harvesting technology which reduces the hassle for the
farmers of using extra batteries.
The rest of the paper is organized as follows: Section II
provides an overview of existing works related to our proposed
framework. Section III provides a detailed description of the
hardware that have used in this research. Section IV discusses
the proposed IoT-ML-based smart agricultural framework.
Section V discusses the blockchain-based security of our system.
Section VI presents the real-life implementation of our project.
Next, Section VII illustrates and analyzes the experimental
result from our machine learning models. Section VIII future
research directions in this field of research. Finally, Section IX
gives a brief conclusion.
II.
RELATED RESEARCH
Several ML-IoT-based researches and project works on
agriculture systems have been carried out till today.
In [8], For remote sensing and smart agriculture, Ullo et al.
presented a review of research on the developments in smart
sensors and IoT. They put forth some suggestions for IoT
advancements that will support researchers and agriculturalists
in their work.
In [9], Samuel et al. analyzed numerous techniques for crop
selection, crop sowing, weed detection, and system monitoring.
They have recommended different image processing methods
for weed and leaf detection and evaluated the benefits and
drawbacks of each. Drone implementation has been considered
for real-time monitoring and seed planting. However, no actual
implementation is shown in this research; they have only
reviewed several smart agricultural strategies.
In [10], they analyze soil moisture levels and apply auto
irrigation to the crops. In order to eliminate the need for human
involvement, this system also senses temperature, humidity, and
the presence of impediments in the targeted region. These data
are accessible to the user via mobile from the cloud. By giving
the motor driver the command YES/NO based on this data, the
user can control the operation of the motor.
In [11], they use a cloud-based architecture and the Internet
of Things to examine a smart irrigation system. This system
is designed to measure soil moisture and humidity and then
process this data in the cloud using a variety of machine-
learning techniques. Farmers receive accurate information
regarding water content regulations. If farmers apply smart
irrigation, they can reduce their water usage.
In [12], they use IoT and machine learning to predict
late blight disease in potatoes and tomatoes prior to the first
occurrence. This will send farmers a warning message on the
precise time to apply the protective pesticides.
In [13], for yield prediction, they present a hybrid ML
model using IoT. They use a two-tier ML approach named
aKNCN and ELM-mBOA.In the first tire, they estimate soil
quality and in the second tier, they predict the crop yield.
In agriculture, supply, and demand have always been crucial
issues for sustainable production management. To address
and provide a possible solution to this problem, M. Lee et
al. proposed an IoT-based controlled agricultural production
management [14]. The authors developed a decision support
system to predict specific criteria based on IoT-enabled sensor
data.
A cloud-based real-time data analysis model is proposed
in [15] instead of dew-point humidity. In this regard, they
designed a CMM index measurement model to evaluate the
crops’ comfort level of relative humidity levels.
To increase the crop production rate, real-time data analysis
based on an artificial model is proposed by Y. Zhou et al. in [16].
The current innovation trend expects farmers to use IoT and
technology to identify the organization of those difficulties they
face, such as water management deficiencies in agriculture
and productivity concerns. This research has attempted to
build dazzling agricultural cultivation patterns utilizing IoT
technologies. IoT has significantly improved agriculture by
analyzing various agricultural difficulties and issues.
An IOT-based intelligent technology for agriculture that can
sense soils and environmental factors was proposed by Abhijith
H. V. et al. in [17]. In order to identify the urgent needs for
optimal crop growth, they applied data mining techniques to
the sensed data.
Abraham et al. [18] create a proof-of-concept farm surveil-
lance system that employs IoT and deep learning to identify
www.ijacsa.thesai.org
986 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
farm encroachment.
The purpose of the study Wongpatikaseree et al. [19], is
to propose a traceability system, summarizing and presenting
observed data from the smart farm.
For smart farming, Deden Ardiansyah et al. [20] suggested
a WSN Server that can handle and optimize agricultural data.
They instantly store the data in the database, which is afterward
represented as a website and accessible through the Internet
network.
Automation in agriculture is a basic need for remote
control-based agricultural management to ensure sustainable
development in this field of research. In this regard, L.
Vijayaraja et al. proposed an IoT-based monitoring system
using wireless communication networks in [21]. The power
supply management used in this framework is entirely from the
renewable energy source that provides a cost-effective model
for sensor-based decision management in intelligent farming.
In [22], Yaw-Wen Kuo, et al. presented a Long-range IoT
system where they developed four types of IoT units based on
Long-range technology. They employed pH, ORP, and EC in
Type A and water, air, and humidity sensors in Type B. In type
C, the pump can be operated remotely, and in type D, a water
flow or water meter-controlling system is provided.
They presented a cloud service-based architecture in [23]
that includes a variety of services for farmers, including agri-
food-related services, financing, fostering, warehouse manage-
ment, etc. They have suggested interactive video conferencing,
voice-based services, text messaging, web portal services, and
more under the heading of cloud services.
A key component of practicing smart agriculture is precision
agriculture. In this context, Patil et al. [24] suggested a system
that measures soil moisture using sensors for temperature,
humidity, and soil moisture. Additionally, they offered various
methods for highlighting the issue of data loss.
In [25], Quasim et al. use blockchain techniques in smart
healthcare systems to ensure the security of healthcare data.
It provides the security, privacy, and efficiency of the data in
transmission between wearable sensors and Internet of Things
(IoT) devices.
In [26], Makhdoom et al. made a blockchain-based frame-
work for privacy-preserving and secure data sharing in smart
cities. The system secures data sharing by segmenting the
blockchain network into different channels, where each channel
consists of a limited number of authorized organizations and
handles a particular type of data, such as financial information,
health data, smart car data, or data related to smart energy.
Additionally, smart contracts contain access control rules that
regulate who has access to the data of users within a channel.
Many different types of intelligent agricultural systems were
developed in the earlier work. Some of these current systems
are tabulated in Table I.
III.
SYSTEM HARDWARE
To set up the IoT environment for a smart agricultural
system, we have selected a variety of hardware components,
including the ESP8266 Node MCU (Fig. 2) processing unit
and several sensors, including capacitive soil moisture (Fig. 3),
PH sensor (Fig. 4), MH-RD Rain Sensor (Fig. 5), and LDR
Sensor (Fig. 6). Our IoT system is powered by DC-DC power
converter (Fig. 9), solar energy harvesting components (Fig.
10), single-channel relay modules (Fig. 7), DC motors (Fig. 8),
etc.
A. Node MCU ESP8266
Fig. 2. Node MCU module.
Features1:
•
Operating Voltage: 3.3V
•
Input Voltage: 7-12V
•
Digital I/O Pins (DIO): 16
•
Clock Speed: 80 MHz
•
Small size module
B. Capacitive Soil Moister Sensor v1.0
Fig. 3. Soil moisture sensor.
Features2:
•
Operating Voltage: DC 3.3-5.5V
•
Output Voltage: DC 0-3.0V
•
Digital I/O Pins (DIO): 16
•
Analog output
•
Supports 3-Pin Sensor interface
C. PH Sensor(SEN-00239)
Features3:
•
Supply voltage: 5V
•
Current: 5-10 mA
•
Consumption: ≤ 0.5 W
•
Working temperature: 10-50◦C
www.ijacsa.thesai.org
987 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
TABLE I. PREVIOUS RESEARCH WORKS IN TERMS OF OBJECTIVES, USED TOOLS, AND POSSIBLE RESEARCH GAPS
Reference
Research Purpose
Used Technologies/Techniques
Focused Methods
Challenges/Research Gaps
[11]
IoT-Cloud based automated Ir-
rigation
Raspberry Pi, central cloud storage, soil
data set, machine learning techniques,
and mobile applications
Focused to measure soil moisture and
humidity and then process this data in
the cloud using a variety of machine
learning techniques
Farmers get information about water
only, no other necessary information.
[12]
IoT-based agriculture monitor-
ing system for predictive anal-
ysis
Air temperature sensor, air humidity
sensor, and soil moisture sensor, Micro-
controller Unit (NodeMCU), MQTT pro-
tocol, R-Pi 3 microcontroller, MYSQL
Focused to predict the late blight disease
in potatoes and tomatoes before the first
occurrence
Not fully automated, need human inter-
ference to apply the action
[14]
IoT-based agricultural produc-
tion System
Dual CDMA protocol, pH sensor, water
sensor, and temperature sensor
Focus on reliable agricultural production
management
Absence of dynamic data analysis model
[15]
IoT-Cloud based agricultural
monitoring system
Arduino UNO, temperature and humidity
sensors, Arduino Ethernet shield and
ThingSpeak cloud platform
Finding the index of thermal control
functions to find the comfort levels of
agricultural parameters
Sensor data processing time is slower
in terms of CMM-MIST measurement
algorithm.
[16]
Machine Learning based agri-
cultural management
Threat Model (TM), Deep Crop Map-
ping Model (DCMM), Random Forest
Regression Algorithm (RFRA)
An intelligent management to predict
soil moisture content based on the ML
architecture
The key challenge of this research is real-
time data processing
[17]
Intelligent technology for IOT-
based agriculture
PH sensor, temperature, rainfall, humid-
ity sensor, Predictive classification algo-
rithm, MatLab
Focused on the identification of urgent
needs for optimal crop growth
Prediction of specific need isn’t gained
properly
[18]
Comprehensive farm monitor-
ing system
Arduino Board, Node MCU, Sensors,
mobile App, machine learning, deep
learning
Centered on a surveillance system pro-
totype and an app-based remote admin-
istration solution
Remotely monitoring but not fully auto-
mated controlling
[19]
IoT-based Smart farming
Sensors, mobile technology, Wi-Fi, cloud
computing
Can measure soil temperature, soil
moister, humidity, pH and EC values
Human interaction, water wastage
[20]
Water management based on
IoT
Soil moisture, Wi-Fi segments
Real-time data monitoring for soil mois-
ture and remote data access
Low or excessive irrigation, and water
waste
[21]
IoT-based cost-effective agri-
cultural management
Moisture and Water sensors, Node MCU,
Solar panel and LCD display unit
Focused on the low-cost parameter while
ensuring a sustainable energy efficient
management
The key research gap of this work is
that this model is applicable for small
farming areas.
[22]
IoT platform has a long range
for controlling pumps and
monitoring agriculture
LP WAN, Base station, Ph sensor, Elec-
trical Conductivity sensor, Water Tem-
perature Sensor, GY39
Presented a complete IoT system includ-
ing the design of a remote unit and server
construction
It is required to conduct additional re-
search on the pH sensor because the data
that has been gathered is inaccurate and
collected from other vendors.
[23]
Cloud service architecture for
agriculture using IoT and Big
Data
Different Sensor, Central Cloud Database
Proposed a cloud-based architecture for
the agricultural industry that comprised
a range of services, including farm mon-
itoring, market-oriented service, agri-
business monitoring, etc.
Not implemented just proposed an archi-
tectural model.
[24]
AI in smart agriculture appli-
cations
Arduino UNO, Soil moisture sensor, Wi-
Fi module
Aimed to use a single moisture sensor
and make decisions, such as turning on or
off the pump, based on the data collected.
Discussing the disease of crop using
image analysis technique but no actual
implementation is shown.
Proposed
System
Smart
agricultural
system
based
on
an
IoT-ML-
Blockchain
Integrated
Framework
IoT devices, Mobile Application, Ma-
chine Learning, and Blockchain-based
security system
Focused on intelligent decision making,
Distant Controlling, Energy Harvesting,
and Security based smart agricultural
management system
Future target to ensure Low latency net-
work and high bandwidth transmission,
easy deployment of Networks elements
and Edge computing technology.
Fig. 4. PH Sensor with module.
Fig. 5. MH RD rain sensor.
D. MH-RD Rain Sensor
Features4:
•
Working voltage: 5V
•
Output format: Digital switching output (0 and 1)
•
With bolt holes for easy installation
•
Uses a wide voltage LM393 comparator
E. LDR (Light Dependent Resistor)
Features5:
•
Able to detect variable light resistance (50-100 K
Ohms)
1https : //components101.com/development − boards/nodemcu −
esp8266 − pinout − features − and − datasheet
2https : //how2electronics.com/interface − capacitive − soil −
moisturesensor − arduino/#Features038Specifications
3https
:
//www.techshopbd.com/detail/2576/PHSensorwith −
Moduletechshopbangladesh
4https : //components101.com/sensors/rain − drop − sensor −
module#%20value
5https
:
//www.indiamart.com/proddetail/ldr − light −
dependent − resistor − 18812839691.html
www.ijacsa.thesai.org
988 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
Fig. 6. Light dependent resistor.
•
Photo-resistor (photo-conductive cell)
•
Power Level: 200 W
•
Diameter: 3-20 mm
F. Single-Channel Relay Module
Fig. 7. Single-Channel relay module.
Features6:
•
Ground Voltage: 0 V
•
VCC: Provide input to the relay coil
•
Supply Voltage: 3.75 to 6 V
•
Current: 2 mA
•
Relay Maximum Current: 10 A
G. DC Motor 6V
Fig. 8. DC motor.
Features7:
•
Diameter of the motor: 23.5mm
•
Height: 30mm
•
Start voltage: 0.8V
•
Rated voltage: 6V
•
Non-charging current: 25mA
•
Speed: 2980 RPM
Fig. 9. Adjustable DC-DC power converter.
H. Adjustable DC-DC Power Converter (1.25V - 35V-3A)
Features8:
•
Input Voltage: 3.2V - 40VDC
•
Output Voltage: 1.25V - 35VDC
•
Max. Output Current: 3A
•
Max. Efficiency: 92
•
Output Ripple: ≤ 100mV
•
Switching Frequency: 65KHz
•
Operating Temperature: -45°C to +85°C
•
Dimensions: 43mm*21mm*14mm(l*w*h)
I.
MSP430 Solar Energy Harvesting Tool
Fig. 10. MSP430 solar energy harvesting development tool texas instruments
EZ430-RF2500-SEH.
Features9:
•
Battery-less operation
•
Functions in dim ambient light and 400+ transmissions
•
Adaptable to any RF network or sensor input
•
Inputs available for external harvesters (thermal, piezo,
2nd solar panel, etc.)
•
USB debugging and programming interface with ap-
plication backchannel to PC
•
18 available analog and communications input/output
pins
•
Highly integrated, ultra-low-power MSP430 MCU with
16-MHz performance
www.ijacsa.thesai.org
989 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
Fig. 11. Schematic pin configuration of our proposed framework.
IV.
PROPOSED FRAMEWORK
A. Circuit Diagram and Connections
We used Fritzing10, an open-source hardware online appli-
cation to make a schematic pin (Fig. 11) diagram of our smart
agriculture system.
We used ESP8266 NodeMCU V3, with an integrated WIFI
module as our processing hardware component. The system
connects an analog capacitive soil moisture sensor and an
analog pH sensor using multiplexing to the A0 analog input
of NodeMCU, a photo-resistor known as Light Dependent
Resistors (LDR) sensor to a D3 digital input, and a raindrop
sensor with rain board and control module to D0 input Pin. In
addition, the device is connected with a D3 output pin to a DC
5V micro submersible mini water pump with the relay. We used
6https : //components101.com/switches/5v − single − channel −
relay − module − pinout − features − applications − working
7https
:
//techshopbd.com/detail/248/DCMotor6Vtechshop −
bangladesh
8https : //techshopbd.com/detail/2067/Adjustable − DC − DC −
PowerConverter
9https
:
//www.radiolocman.com/op/device.html?di
=
66638&/eZ430 − RF2500 − SEH
10ıFritzing − circuitdesign, ȷhttps : //fritzing.org/
the NodeMCU’s 5V VU pin to power the Motor and Relay.
However the LDR Sensor and Rain Drop Sensor, only need
a 3.3V supply, the Capacitive Soil Moisture Sensor and pH
Sensor need 5V. The GND pin serves as the common ground
for every sensor. A solar panel system that is coupled to a
9-volt battery backup powers the system.
B. Working Principle
We have divided our proposed framework into different
subparts and each part’s working procedure is given below. The
overall working procedure is depicted in Fig. 12.
1) Collecting Data From Sensor: We used four different
types of sensors, including capacitive soil moisture sensors, pH
sensors, MH-RD rain sensors, and LDR sensors, to execute
smart IoT agriculture. We can estimate how much water is in
the soil with the aid of a soil moisture sensor. A pH sensor,
which ranges from 0 to 14, allows us to determine the water’s
acidity or alkalinity. Water turns acidic if the value falls below
7, else it is alkanoic. Consider levels 5.5 to 7 to be ideal for
growing crops. We can choose the best fertilizer for the soil
with the aid of a pH sensor.
Basically, a rain sensor is used to detect rain. A rain board
that can detect rain and a control module that can compare
www.ijacsa.thesai.org
990 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
Data from 
moisture, 
rain, 
daylight and 
pH sensors
Firebase Cloud 
Database
Dataset 
Extraction
Dataset 
Preprocessing
Train ML 
Model
ML Predicted 
Result
Monitor and 
Control via 
Mobile App
Perform actions 
whether on-off pump 
or apply suitable 
fertilizers
Node MCU Unit
Data from Node MCU to Firebase 
via Blockchain Network
Energy 
harvesting using 
solar panel
Fig. 12. Proposed IoT-ML-Blockchain framework for smart agricultural management.
analog and digital values are both included. The raindrop sensor
aids in our selection of how to operate the motor. The LDR
sensor, which is used to detect the presence of light, has also
been employed.
Now, each of these sensors is linked to a node MCU board
in our project, and data from the sensors is uploaded to the node
MCU board and shown on the serial monitor of the Arduino
UNO editor and
2) Sending Data to Cloud Server: The node MCU board
receives all sensor data, which we would love to save in the
cloud in order to control for remote distance. We have utilized
Firebase as a cloud server. We linked the Firebase authentication
and real-time database URL that we built for our project with
the Arduino UNO script in order to integrate Firebase with
Node MCU.
All data is sent as a parent-child combination to Firebase.
All of the sensor data is sent from the node MCU as a child
of Smart Irrigation, which we have constructed as Parent. The
Firebase stores the child value as a key-value pair.
3) Data Collection: The Firebase’s database contains all of
the sensor data, which is compiled as a CSV file. Four columns
make up our dataset: pH, LDR, Rain, and Moisture. Nearly
820 data are in our dataset. Only integer values are accepted in
the Moisture column here, whereas string values are accepted
in the Rain and LDR columns.
4) Data Pre-processing: Data can be often inconsistent.
Missing values or values out of range is typical. So, the dataset
needs some pre-processing before it can be used to train any
model [27]. For this reason, we have considered three such
cases.
•
Missing Value Handling: While exploring our dataset,
we observed humidity, raining status, daylight status,
and pH level fields with missing values. Therefore, we
have filled them with average values of the respective
field.
•
One Hot Decoder: Label encoding is simply the
process of converting each value in a column to a
number. By using label encoding, we have converted
the categorical text data into model-understandable
numerical data. We had to use the label encoding to
get our dataset ready for our model.
•
Abnormal Data Handling: Some data contain abnor-
mal values. For example, the range of the temperature
in our dataset falls between -20 to 30 degrees Celsius.
However, we have even found some data above and
below this range. Data tuples with these abnormalities
have been dropped from the dataset.
•
Normalization: Normalization is used to increase the
accuracy of models [28]. It is simply the process of
having all the data on the same scale. We have used
www.ijacsa.thesai.org
991 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
temperature, pressure, relative humidity, and pressure
as features to train our model. The features used
to teach a machine-learning algorithm have different
ranges of values. This can badly affect the machine’s
learning ability. To solve this problem, we have
standardized the feature values so that all the features
stand equal in their representation. By normalization,
all the feature values are mapped in the range between
0 and 1.
5) Machine Learning Model: The developed architecture is
a Neural Network (NN) based because of its great accuracy. The
fundamental advantage of NN over classical machine learning
models is that it recognizes significant traits automatically
and without human intervention. It’s a feed-forward NN with
parameters using the back-propagation algorithm and stochastic
gradient descent. Distinct processing layers serve different
purposes. The output of the feature map is produced by
conventional layers, which conduct linear convolution between
a series of input tensors and filters. The nonlinear transformation
is performed using the ReLU, which is the most widely
employed activation function. The activation function for the
fully connected layer to the end must be careful on the tasks.
Batch normalization and an activation layer are performed after
each convolution.
ReLU = max(0, X)
(1)
d(x) = activation(wx + b)
(2)
Dropout(x, p) = (x : prob., p) (x : prob., 1 − p)
(3)
S(x) =
1
1 + e−x
(4)
6) Mobile Application Development: A smart remote con-
trol application can ease our maximum task [29]. We have used
the MIT app inventor to make the mobile application that will
be connected to our system and by using this app we can do
the following task
•
Fertilizer Suggestion: By analyzing the pH value, the
app may suggest which fertilizer is best for a given
soil. The app will recommend some alkanoic fertilizer
if the pH value rises to help reduce the rising pH value
and vice versa. Algorithm 1 depicts how the fertilizer
is suggested in our system.
•
Visualization of Predicted Results: In order to predict
whether the motor would turn off or not based on
the moisture, LDR, and raindrop sensor values, we
construct a neural network model and link it with
our mobile app. Algorithm 2 depicts how the remote
controlling is done to control the motor in our system.
•
Remote Motor Controlling: The farmer can use the
app to control the motor from any distant or remote
Algorithm 1: Decision Making for Fertilizer Sugges-
tion
1. Initialize the pH sensor
2. Read data from pH sensor
3.if pH >= 6.5 && pH <= 7.5 then
Soil is balanced.
No fertilizer is recommended.
4.else if pH < 6.5 then
Soil is acidic.
Store the pH amount.
Find the level_id corresponding pH amount.
Search through the fertilizer data(in JSON format)
if level_id == keyofJSONdata then
Send the fertilizer name back to the user.
else
The result doesn’t match our dataset.
else
Soil is alkanoic
Store the pH amount
Find the level_id corresponding pH amount
Search through the fertilizer data(in JSON format)
if level_id == keyofJSONdata then
Send the fertilizer name back to the user
else
The result doesn’t match our dataset
Algorithm 2: Decision Making for Pump on/off
1. Initialize the Moisture, Rain, and LDR sensors.
2. Read data from each sensor.
3. Send the data to the server using an HTTP POST
request.
4. Apply machine learning to the collected data.
5. Retrieve the predicted result(PUMP ON/OFF).
6. Send Predicted results to the mobile phone.
7. Wait for user input from the mobile phone.
8. if user_action = true then
Send a signal to the node MCU board.
Perform action according to signal.
else
Wait for 300 seconds
Take an automated action according to the
predicted result (PUMP ON/OFF)
location based on the prediction outcome. When the
farmer presses the off button, it sends a value of 0 to
the firebase, which then passes this signal on to the
node MCU via the wifi module and sets the pin value
to the LOW, so turning off the motor.
V.
BLOCKCHAIN-BASED SMART-AGRI
Blockchain was described as a data structure using asym-
metric encryption algorithms and hash functions to ensure
that data tampering and forgery are impossible [30] [31] [32].
Every smart system needs to be taken under the shelter of a
security system to avoid getting an external attack. Our smart
agricultural system is public so any intruder can make attacks
such as DoS attacks to crash the system, and spoofing to alter
the control. In the IoT environment where high computational
encryption, decryption, and high-level security are not possible.
www.ijacsa.thesai.org
992 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
Therefore, We are implanting blockchain technologies into our
smart agricultural system through which we are capable to
maintain high throughput, low latency, low communication
cost, and tamper-proof and traceability. Blockchain refers to a
distributed ledger system where data or transactions are stored
in blocks that are connected to each other through making
hash which can not only serve as unique IDs but also prove
the integrity of the blocks. The hash of the previous block is
used to make a hash for the next block along with its data.
If any intruder wants to tamper or alter the block data, all
the consecutive block hash will be changed. Therefore, any
intruder attempts to alter the data or spoof the blockchain will
not be possible.
In this system, we consider nodeMCU, Firebase cloud, and
mobile app as nodes. In order to avoid altering data in the
network, we are using blockchain technology. When any node
wants to send data to other nodes, it encapsulates the data
into a block along with its hash values (SHA256) and nodeID
then adds it to the blockchain. All these nodes will contain the
blockchain locally. After adding the block, the node sends it
to the cloud through the network. We are not using any PoW,
PoS, or accountant selection algorithms which is not possible
because of a very small amount of nodes and our nodeMCU
has very limited capabilities to run these algorithms (Algorithm
3). When the block is sent to the cloud, I validate the block by
checking all the hashes of the previous block along with the
nodeID. If it gets any error, the node will consider the block
as from an attacker and reject the block from adding to the
chain. Fig. 13 depicts the blockchain in our system.
Fig. 13. Blockchain in the system.
VI.
IMPLEMENTATION
A. Hardware Implementation
Our Smart-agri system hardware demo showed in Fig. 14.
B. Mobile App Implementation
The interface of the mobile app that we developed in
the MIT App Inventor resembles (Fig. 15). The “Fertilizer
Suggestion" button can be found in the app. Depending on the
Algorithm 3: Blockchain-based data security in smart-
agri
1. Initialization
2. Read data
3. Block_Hash ← SHA256 (Previous_hash, data,
nodeId, timestamp, nonce)
4. Make a block (Block_hash, data, nonce, nodeID,
timestamp)
5. Add the block to the chain locally.
6. Send the block to the cloud.
7.if Block_hash = Previous_Hash then
Accept the block, then add it to the chain.
Send acknowledgment.
Fig. 14. Hardware set-up of our proposed framework.
pH sensor measurement, this button tells us whether the soil
is alkanoic or acidic when we click it. We used the decision
tree algorithm to determine the ideal fertilizer for a given soil
based on its quality.
The farmer can view the data from the moisture, raindrop,
and daylight sensors in our app. Our program uses a neural
network model that we built and implemented to forecast
whether the motor would be on or off. We can operate our
motor using the two buttons in our app labeled “ON" and
“OFF". The motor status in the firebase changes to 1 when we
press the “ON" button, and the firebase sends a signal to the
nodeMCU board, which then turns the motor on automatically.
And that is how we can use our mobile app to implement
remote control.
www.ijacsa.thesai.org
993 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
TABLE II. SYSTEM EVALUATION WITH THE EXISTING SYSTEMS
Reference
Remote Motor
Controlling
Energy
Har-
vesting
Customised
Mobile
Application
Machine
Learning
Integrated
Framework
Creating Own
Data set
Central Cloud
Database
pH based fer-
tilizer sugges-
tions
Blockchain
based
Security
Full au-
toma-
tion
[11]
×
×
✓
✓
×
✓
×
×
×
[12]
×
×
×
✓
×
×
×
×
×
[14]
×
×
×
✓
×
×
×
×
[16]
×
×
×
✓
✓
×
×
×
×
[17]
×
×
×
✓
×
×
✓
×
×
[18]
✓
×
✓
✓
×
×
✓
×
×
[19]
✓
×
✓
×
×
✓
×
×
×
[20]
✓
×
✓
×
×
×
×
×
✓
[21]
×
×
×
×
×
×
×
×
×
[22]
✓
×
✓
×
×
✓
×
×
×
[23]
✓
×
×
×
✓
✓
×
×
×
[24]
✓
×
✓
×
×
✓
×
×
×
Proposed
Method
✓
✓
✓
✓
✓
✓
✓
✓
✓
TABLE III. SUMMARY OF PROPOSED NEURAL NETWORK PERFORMANCE PARAMETERS
Epochs
Processing Time /msec
Binary Cross Entropy Validation Loss
Gradient Descent Neural Network Validation Accuracy
10
7
0.5478
0.8947
25
8
0.4525
0.8948
50
7
0.3766
0.8948
75
7
0.3462
0.8949
100
8
0.3376
0.8948
VII.
EXPERIMENTAL RESULT ANALYSIS
A. System Evaluation
In Table II, we have shown the difference between our
system and the existing systems. The criterion based on which
we have shown the differences are remote monitor control, data
visualization, customized mobile application, machine learning
integrated framework, creating own database, central cloud
database, pH-based fertilizer suggestions, Machine learning
model development, and full automation. The references from
[11] to [24] there is no such system that has implemented all the
criteria in their system. But we have successfully implemented
all the criteria in our systems.
B. Machine Learning Model Evaluation
Our deep learning neural network is implemented with
the help of our own dataset. We split the dataset into 80-20
ratios for training and validation purposes. The heat map of the
features columns is illustrated in Fig. 16. We fit our gradient
descent neural network within the data set. The input layer
of the neural network receives 3 input lines from the features
column, namely, rain status, moisture level, and daylight status
respectively. Then we add one dense layer with 16 neurons and
the activation function as ReLu. The next layer is a dropout
layer with a 20% drop rate. Next, we add another dense layer
with 8 neurons and apply the activation function as ReLu.
Then we add another dropout layer with a 20% drop rate.
Finally, for the output layer, we add another dense layer with
a single neuron with is satiable for binary classification (i.e.
motor on-off decision) with activation function as Sigmoid.
The experimental result of our model is represented in
Table III while showing the validation loss rate as binary cross
entropy and validation accuracy level in different epochs. Our
model successfully outcomes a stable level of accuracy for
the different epochs. We got almost 89.5% accuracy in our
experimental set-up.
VIII.
FUTURE RESEARCH DIRECTION
For future smart irrigation management, several issues must
be addressed as follows:
•
Low-latency in Real-Time Application: The moni-
toring and controlling mobile application must be able
to transmit real-time data to the farmers or its entity
while ensuring a low latency network.
•
High Bandwidth: To facilitate a buffer-less transmis-
sion, we need to ensure maximum bandwidth level to
the transmission process.
•
Connectivity: To meet the high communication de-
mands of future IoT-ML integrated irrigation systems,
reliable synchronization between linked autos would
be required.
•
Deployment of Network Elements: When a network
has a high enough number of nodes, its overall
performance increases. Because network equipment
deployment is costly, it is vital to have the required
number of network components up and running as
quickly as feasible.
•
Augmented Reality: AR is a multimedia application
that mixes real-world scenes into virtual scenes and
superimposes virtual scenes over real-world scenes to
supplement traditional real-image information. This
technology has the potential to help farmers become
more aware of the app’s functionality.
•
Edge Computing: This networking approach is built
on a network control layer that is logically centralized.
www.ijacsa.thesai.org
994 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
Fig. 15. Mobile application interface.
Fig. 16. Heat-Map of the features of our ML part.
It contributes to the creation of a dependable resource
management and traffic control system.
IX.
CONCLUSION
We have put forth an integrated solution that enables
farmers to solve the challenges that limit their production
and profitability by utilizing cutting-edge technologies like
machine learning (ML), the Internet of Things (IoT), and
blockchain. Through user-friendly mobile applications and
a secure cloud database, this model, implemented with a
generated database, offers helpful insights and recommendations
to farmers, including pesticide usage and water motor control.
Real-time monitoring and data collecting is made possible
by the integration of IoT devices, enabling accurate decision-
making and assuring optimal resource allocation. Incorpo-
rating blockchain technology also improves data traceability,
transparency, and integrity, fostering trust and accountability
throughout the agricultural ecosystem. Farmers may gain from
higher productivity, decreased expenses, and enhanced general
agricultural management by implementing our Smart-Agri
framework. They can obtain up-to-date, accurate information,
make decisions that will increase productivity and reduce
waste, and improve their agricultural techniques. We have
applied the gradient descent neural network model for water
control management and achieved up to 89.5% accuracy. In
addition, the suggested structure creates chances for cooperation,
information exchange, and market access, all of which help
the agricultural industry thrive and flourish sustainably.
In the future, the framework’s scalability, and its inter-
operability can all be explored through more research and
development in this area, along with potential problems like
connectivity problems and data privacy issues. We can build an
ecosystem that really revolutionizes the agriculture sector by
continually improving and building upon these technological
achievements, making it more intelligent, efficient, and robust
in the face of changing global issues.
ACKNOWLEDGMENT
We would like to acknowledge the support of the
Bangladesh University of Business and Technology and the
IoT lab for their suggestion and resource sharing.
REFERENCES
[1]
A. Rehman, T. Saba, M. Kashif, S. M. Fati, S. A. Bahaj, and H. Chaudhry,
“A revisit of internet of things technologies for monitoring and control
strategies in smart agriculture,” Agronomy, vol. 12, no. 1, p. 127, 2022.
[2]
M. Biswas, A. Rahman, M. S. Kaiser, S. Al Mamun, K. S. Ebne Mizan,
M. S. Islam, and M. Mahmud, “Indoor navigation support system for
patients with neurodegenerative diseases,” in Brain Informatics: 14th
International Conference, BI 2021, Virtual Event, September 17–19,
2021, Proceedings 14.
Springer, 2021, pp. 411–422.
[3]
H. Elahi, K. Munir, M. Eugeni, S. Atek, and P. Gaudenzi, “Energy
harvesting towards self-powered iot devices,” Energies, vol. 13, no. 21,
p. 5528, 2020.
[4]
A. Sabovic, A. K. Sultania, C. Delgado, L. De Roeck, and J. Famaey,
“An energy-aware task scheduler for energy-harvesting batteryless iot
devices,” IEEE Internet of Things Journal, vol. 9, no. 22, pp. 23 097–
23 114, 2022.
[5]
M. A. Rahman, H. Ahmed, and M. M. Hossain, “An integrated hardware
prototype for monitoring gas leaks, fires, and remote control via mobile
application,” International Journal of Advanced Computer Science and
Applications, vol. 13, no. 10, 2022.
[6]
K. Demestichas, N. Peppes, T. Alexakis, and E. Adamopoulou,
“Blockchain in agriculture traceability systems: A review,” Applied
Sciences, vol. 10, no. 12, p. 4113, 2020.
www.ijacsa.thesai.org
995 | P a g e
(IJACSA) International Journal of Advanced Computer Science and Applications,
Vol. 14, No. 7, 2023
[7]
O. Bermeo-Almeida, M. Cardenas-Rodriguez, T. Samaniego-Cobo,
E. Ferruzola-Gómez, R. Cabezas-Cabezas, and W. Bazán-Vera,
“Blockchain in agriculture: A systematic literature review,” in Technolo-
gies and Innovation: 4th International Conference, CITI 2018, Guayaquil,
Ecuador, November 6-9, 2018, Proceedings 4.
Springer, 2018, pp. 44–
56.
[8]
S. L. Ullo and G. R. Sinha, “Advances in iot and smart sensors for
remote sensing and agriculture applications,” Remote Sensing, vol. 13,
no. 13, p. 2585, 2021.
[9]
K. Malarvizhi, S. Karthik, M. G. SG et al., “Machine learning and
internet of things based smart agriculture,” in 2020 6th International
Conference on Advanced Computing and Communication Systems
(ICACCS).
IEEE, 2020, pp. 1101–1106.
[10]
J. Boobalan, V. Jacintha, J. Nagarajan, K. Thangayogesh, and S. Tamila-
rasu, “An iot based agriculture monitoring system,” in 2018 international
conference on communication and signal processing (ICCSP).
IEEE,
2018, pp. 0594–0598.
[11]
K. Phasinam, T. Kassanuk, P. P. Shinde, C. M. Thakar, D. K. Sharma,
M. Mohiddin, A. W. Rahmani et al., “Application of iot and cloud
computing in automation of agriculture irrigation,” Journal of Food
Quality, vol. 2022, 2022.
[12]
A. A. Araby, M. M. Abd Elhameed, N. M. Magdy, N. Abdelaal, Y. T.
Abd Allah, M. S. Darweesh, M. A. Fahim, H. Mostafa et al., “Smart iot
monitoring system for agriculture with predictive analysis,” in 2019 8th
International Conference on Modern Circuits and Systems Technologies
(MOCAST).
IEEE, 2019, pp. 1–4.
[13]
A. Gupta and P. Nahar, “Classification and yield prediction in smart
agriculture system using iot,” Journal of Ambient Intelligence and
Humanized Computing, pp. 1–10, 2022.
[14]
M. Lee, J. Hwang, and H. Yoe, “Agricultural production system based
on iot,” in 2013 IEEE 16Th international conference on computational
science and engineering.
IEEE, 2013, pp. 833–837.
[15]
M. S. Mekala and P. Viswanathan, “Clay-mist: Iot-cloud enabled cmm
index for smart agriculture monitoring system,” Measurement, vol. 134,
pp. 236–244, 2019.
[16]
Y. Zhou, Q. Xia, Z. Zhang, M. Quan, and H. Li, “Artificial intelligence
and machine learning for the green development of agriculture in the
emerging manufacturing industry in the iot platform,” Acta Agriculturae
Scandinavica, Section B—Soil & Plant Science, vol. 72, no. 1, pp.
284–299, 2022.
[17]
H. Abhijith, D. A. Jain, and U. A. A. Rao, “Intelligent agriculture
mechanism using internet of things,” in 2017 International Conference
on Advances in Computing, Communications and Informatics (ICACCI).
IEEE, 2017, pp. 2185–2188.
[18]
G. Abraham, R. Raksha, and M. Nithya, “Smart agriculture based on
iot and machine learning,” in 2021 5th International Conference on
Computing Methodologies and Communication (ICCMC).
IEEE, 2021,
pp. 414–419.
[19]
K. Wongpatikaseree, P. Kanka, and A. Ratikan, “Developing smart farm
and traceability system for agricultural products using iot technology,”
in 2018 IEEE/ACIS 17th International Conference on Computer and
Information Science (ICIS), 2018, pp. 180–184.
[20]
D. Ardiansyah, A. S. M. Huda, Darusman, R. G. Pratama, and
A. P. Putra, “Wireless sensor network server for smart agriculture
optimatization,” IOP Conference Series: Materials Science and
Engineering, vol. 621, no. 1, p. 012001, oct 2019. [Online]. Available:
https://doi.org/10.1088/1757-899x/621/1/012001
[21]
L. Vijayaraja, R. Dhanasekar, R. Kesavan, D. Tamizhmalar, R. Premku-
mar, and N. Saravanan, “A cost effective agriculture system based on
iot using sustainable energy,” in 2022 6th International Conference
on Trends in Electronics and Informatics (ICOEI).
IEEE, 2022, pp.
546–549.
[22]
Y.-W. Kuo, W.-L. Wen, X.-F. Hu, Y.-T. Shen, and S.-Y. Miao, “A lora-
based multisensor iot platform for agriculture monitoring and submersible
pump control in a water bamboo field,” Processes, vol. 9, no. 5, p. 813,
2021.
[23]
P. Srinivasulu, M. S. Babu, R. Venkat, and K. Rajesh, “Cloud service
oriented architecture (csoa) for agriculture through internet of things
(iot) and big data,” in 2017 IEEE international conference on electrical,
instrumentation and communication engineering (ICEICE). IEEE, 2017,
pp. 1–6.
[24]
R. K. Patil and S. S. Patil, “Cognitive intelligence of internet of things in
smart agriculture applications,” in 2020 IEEE Pune Section International
Conference (PuneCon).
IEEE, 2020, pp. 129–132.
[25]
M. T. Quasim, F. Algarni, A. A. E. Radwan, and G. M. M. Alshmrani, “A
blockchain based secured healthcare framework,” in 2020 International
Conference on Computational Performance Evaluation (ComPE). IEEE,
2020, pp. 386–391.
[26]
I. Makhdoom, I. Zhou, M. Abolhasan, J. Lipman, and W. Ni, “Privyshar-
ing: A blockchain-based framework for privacy-preserving and secure
data sharing in smart cities,” Computers & Security, vol. 88, p. 101653,
2020.
[27]
M. Rahaman, M. Chowdhury, M. A. Rahman, H. Ahmed, M. Hossain,
M. H. Rahman, M. Biswas, M. Kader, T. A. Noyan, and M. Biswas,
“A deep learning based smartphone application for detecting mango
diseases and pesticide suggestions,” International Journal of Computing
and Digital Systems, vol. 13, no. 1, pp. 1–1, 2023.
[28]
M. N. Rahaman, S. Chaki, M. S. Biswas, M. Biswas, S. Ahmed, M. J. N.
Mahi, and N. Faruqui, “Identifying the signature of suicidality: A
machine learning approach,” in THEETAS 2022: Proceedings of The
International Conference on Emerging Trends in Artificial Intelligence
and Smart Systems, THEETAS 2022, 16-17 April 2022, Jabalpur, India.
European Alliance for Innovation, 2022, p. 279.
[29]
M. A. R. Milon Biswas, H. Ahmed, A. Anis, and M. M. Hossain, “A
smartphone-based application for medical assistance of elderly patients,”
International Journal of Research and Innovation in Applied Science
(IJRIAS), vol. 7, no. 6, pp. 15–19, 2022.
[30]
Z. Zheng, S. Xie, H.-N. Dai, X. Chen, and H. Wang, “Blockchain
challenges and opportunities: A survey,” International journal of web
and grid services, vol. 14, no. 4, pp. 352–375, 2018.
[31]
Y. Yuan, F.-Y. Wang et al., “Blockchain: the state of the art and future
trends,” Acta Automatica Sinica, vol. 42, no. 4, pp. 481–494, 2016.
[32]
S. Ahmed, M. Biswas, M. Hasanuzzaman, M. J. N. Mahi, M. A. Islam,
S. Chaki, and L. Gaur, “A secured peer-to-peer messaging system based
on blockchain,” in 2022 3rd International Conference on Intelligent
Engineering and Management (ICIEM).
IEEE, 2022, pp. 332–337.
www.ijacsa.thesai.org
996 | P a g e


Paper 3:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: The purpose and intention of this systematic review on automated systems for real-time irrigation management can be interpreted as follows:
Addressing the global food challenge: The review aims to explore how automated, real-time irrigation management systems can contribute to the efficient use of water resources and enhance agricultural productivity to meet the growing demand for food.
  Extract 2: Evaluating the current state and future potential: The primary objective is to critically assess the current state of end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. The review also seeks to identify gaps and propose solutions for seamless integration across the automated irrigation management system to achieve fully autonomous, scalable irrigation management.
  Limitations: []
  Relevance Evaluation: 0.9-1.0: Exceptionally relevant - Comprehensively addresses all key aspects of the point you are making with highly insightful, reliable, and up-to-date information. A must-include for the review.
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: From your close reading of the paper, provide a concise explanation of the study's purpose and main objectives, using a maximum of 3 sentences.

 Full Text: >
agronomy
Review
A Review of Current and Potential Applications of
Remote Sensing to Study the Water Status of
Horticultural Crops
Deepak Gautam
and Vinay Pagay *
School of Agriculture, Food and Wine, The University of Adelaide, PMB 1, Glen Osmond, SA 5064, Australia;
deepak.gautam@adelaide.edu.au
* Correspondence: vinay.pagay@adelaide.edu.au; Tel.: +61-8-83130773
Received: 25 August 2019; Accepted: 9 January 2020; Published: 17 January 2020


Abstract: With increasingly advanced remote sensing systems, more accurate retrievals of crop water
status are being made at the individual crop level to aid in precision irrigation. This paper summarises
the use of remote sensing for the estimation of water status in horticultural crops. The remote
measurements of the water potential, soil moisture, evapotranspiration, canopy 3D structure, and
vigour for water status estimation are presented in this comprehensive review. These parameters
directly or indirectly provide estimates of crop water status, which is critically important for irrigation
management in farms. The review is organised into four main sections: (i) remote sensing platforms;
(ii) the remote sensor suite; (iii) techniques adopted for horticultural applications and indicators of
water status; and, (iv) case studies of the use of remote sensing in horticultural crops. Finally, the
authors’ view is presented with regard to future prospects and research gaps in the estimation of the
crop water status for precision irrigation.
Keywords: UAS; UAV; drone; unmanned; satellite; water stress; irrigation; vegetation index
1. Introduction
Understanding the water status of crops is important for optimal management and application
of water to accommodate for inter and intra-ﬁeld variability to achieve a speciﬁc target, such as
maximum water use eﬃciency, yield, quality, or proﬁtability [1,2]. The importance of optimal water
management in agriculture in semi-arid or arid regions has become increasingly important in light
of recent water scarcities through reduced allocations, as well as increased demand due to greater
areas under production [3,4]. Climate change is expected to further intensify the situation due to
the increased frequency of heatwaves and drought episodes [5]. Climate change coupled with the
necessity to increase food production due to an increase in global population has placed pressure on
horticultural sector to improve eﬃciencies in resources use, e.g., water, for sustainable farming [6–10].
Horticultural crops will have to produce more ‘crop-per-drop’ in the face of limited water resources.
Informed management of water resources whilst maintaining or increasing crop quality and yield are
the primary goals of irrigation scheduling in horticulture. These goals can be achieved by improving
our understanding of the water status of the crops at key phenological stages of development.
Traditional decision-making for irrigation of horticultural crops includes using information from
a combination of sources such as historical regimes, soil moisture measurements, visual assessments of
soil and/or crop, weather data including evapotranspiration (ET), and measurements of crop water
status using direct-, proximal- or remote-sensing techniques [11–13]. Some growers undertake routine
ground-based measurements, e.g., pressure chamber, for estimation of crop water status to make
decisions on irrigation [14–16]. These ground-based measurements are robust; however, destructive,
Agronomy 2020, 10, 140; doi:10.3390/agronomy10010140
www.mdpi.com/journal/agronomy
Agronomy 2020, 10, 140
2 of 35
cumbersome, and expensive to acquire a reasonable amount of data [14,16–18]. Consequently, the
measured leaf is assumed to represent the average population of leaves of the individual crop, and
a few crops are assumed to represent the average population of the entire irrigation block. As a
result, over- or under-watering can occur, which can lower yield and fruit quality [19–22]. This is
especially evident for non-homogenous blocks where spatial variability of soil and water status is
expected [23–25].
To address some of the limitations of ground-based measurements, remote measurement
techniques were introduced with capabilities to measure at higher spatial resolution, larger area, and
on a regular basis [26–29]. Remote sensing, in particular, unmanned aircraft systems (UAS), presents a
ﬂexible platform to deploy on-demand sensors as a tool to eﬃciently and non-destructively measure
crop water status [30]. Using thermal and spectral signatures, remote sensing techniques can be used
to characterise a crop’s water status. Knowledge of crop water status allows growers to more eﬃciently
schedule irrigation (i.e., when and how much water to apply). In this regard, UAS platforms provide a
convenient methodology to monitor the water status across a farm, both spatially and temporally at
the canopy level [31–33]. The spectral, spatial, and temporal ﬂexibility oﬀered by UAS-based remote
sensing may in future assist growers in irrigation decision-making [34,35].
This review provides an overview of the application of remote sensing to understand the
crop’s water status (e.g., leaf/stem water potential, leaf/canopy conductance), soil moisture, ET, and
physiological attributes, all of which can contribute to understanding the crop’s water status to
implement precision irrigation. Although the key focus of this review is UAS-based remote sensing,
a comparison has been undertaken with other remote sensing platforms, such as earth observation
satellites, which are being increasingly used to acquire similar information. In the following sections,
we provide an overview of the most common remote sensing platforms in horticulture, various sensors
used for remote sensing, and several predictive indices of crop water status. Two case studies of remote
sensing in horticultural crops, grapevine and almond, are then presented followed by an overview of
the current research gaps and future prospects.
2. Remote Sensing Platforms
Ground-based direct or proximal sensors acquire instantaneous water status measurement from
a spatial location. For decision-making purposes, the data is generally collected from multiple
locations across a ﬁeld, which allows geospatial interpolation, such as kriging, to be applied [36–38].
This scale of data collection is, however, cumbersome, ineﬃcient, and error-prone, especially for water
status measurements of large areas [17]. Monitoring and observing farms at a larger spatial scale
prompted the launch of several earth observation satellite systems that typically operate at an altitude
of 180–2000 km [39]. Manned high-altitude aircraft (operating within few km) and, more recently, UAS
(operating under 120 m) ﬁlled the spatial gap between high-resolution ground measurements and
relatively low-resolution satellite measurements [40,41]. In the context of water status estimation for
horticultural crops, all the aforementioned remote sensing platforms are utilised depending on the
user requirements [23,42,43]. Each remote sensing platform has its own advantage and shortcomings.
The decision to obtain remote sensing crop water status data from one or more of these platforms will
depend on the spatial and temporal resolution desired. Satellite and manned aircraft can be useful
for regional-scale characterisation, whereas UAS can be more useful to map the intra-ﬁeld variability.
Vehicle-based ground systems also possess similar measurement capabilities, like remote sensing,
however, at a smaller scale [44,45]. These systems can move within the horticultural rows obtaining
water status measurements of adjacent plants while the vehicle is moving, enabling them to cover a
relatively larger area as compared to ground-based direct measurements [46–48].
2.1. Satellite Systems
The use of satellite systems for remote sensing started with the launch of Landsat-1 in 1972 [39,49].
The subsequent launch of SPOT-1 in 1986 and Ikonos in 1999 opened the era of commercial satellite
Agronomy 2020, 10, 140
3 of 35
systems that resulted in rapid improvement in imaging performance, including spatial and spectral
resolution [50]. Continued launch of satellites from the same families, with newer sensor models
and improved capability, resulted in the formation of satellite constellations (e.g., Landsat, Sentinel,
SPOT, RapidEye, GeoEye/WorldView families). The satellite constellation substantially improved the
revisit cycle of the satellite system [51]. Recently, the miniature form of the satellite termed Nanosat or
Cubesat has been developed, which can be deployed on the same orbit in a large number (20s–100s),
enabling frequent and high-resolution data acquisition (e.g., Dove satellite from Planet Labs) [52].
The earth observation satellite system, such as Landsat, Sentinel, MODIS, RapidEye, and GeoEye,
have been used to study horticultural crops (Table 1). These satellite system oﬀer camera systems
with spectral bands readily available in visible, near infrared (NIR), short-wave infrared (SWIR), and
thermal infrared (TIR). The measurement in these bands provides opportunities to study a crop’s water
status indirectly via, for example, calculation of the normalised diﬀerence vegetation index (NDVI),
crop water stress index (CWSI), and ET [8–10] at the ﬁeld- and regional-scales.
Table 1. Some satellite systems that have been used to study the water status of horticultural crops.
Satellites
Band Numbers: Band Designation
Spatial Resolution (m)
Revisit Cycle
Landsat 7
8: V 3, NIR 1, SWIR 2, TIR 1, Pan 1
15–60
16 days
Landsat 8
11: C 1, V 3, NIR 1, SWIR 2, Pan 1, Ci 1, TIR 2
15–100
16 days
Sentinel-2
13: C 1, V 3, RE 3, NIR 2, WV 1, Ci 1, SWIR 2
10–60
5 days
Spot-6 and-7
5: Pan 1, V 3, NIR 1
1.5
1 day
RapidEye
5: V 3, NIR 1, RE 1
5
5.5 days
GeoEye-1
5: Pan 1, V 3, NIR 1
0.41–2
3 days
Note: Superscript integers 1, 2, 3 represent the number of bands; V = visible, NIR = near infrared, SWIR = short-wave
infrared, TIR = thermal infrared, Pan = panchromatic, C = coastal, Ci = cirrus, RE = red edge, WV = water vapour.
The reﬂected/emitted electromagnetic energy from the crop reaching the sensor is recorded at a
speciﬁc wavelength. The width of the observed wavelength expressed in full width at half maximum
(FWHM) is called spectral resolution. The number of observed bands and the spectral resolution
indicates the ability of the satellite to resolve spectral features on the earth’s surface. Commonly used
earth observation satellite systems possess between four and 15 bands with approximately 20–200 nm
FWHM spectral resolution. The bands are generally designated for the visible and NIR region with
extended capabilities in SWIR, TIR, as well as red edge region (Table 1). The most widely used band
combinations to study the water status of vegetation are the visible, NIR and TIR bands [23,25,53,54].
With the plethora of satellite systems currently available, user requirements on band combination
may be achieved by using multiple satellites. However, acquiring an extra or a narrower band to the
existing capabilities is not possible.
The ground distance covered per pixel of the satellite image is called the spatial resolution,
whereby, a higher spatial resolution indicates a smaller ground distance. Existing satellite systems,
due to their lower spatial resolution and large coverage, are suited to study larger regions [55]. For a
smaller observation area, such as a farm block, an irrigation zone, a single row of the horticultural crop,
or a single canopy, this spatial resolution is considered sub-optimal. Often, a pixel of the satellite image
comprises of multiple rows and multiple canopies of horticultural crops [42,56]. Thus, the spectral
response on a single pixel of the satellite image includes a mixed spectral signal from the canopy,
inter-row vegetation and/or bare soil. The mixed-pixel is particularly unavoidable in horticultural
crops with large inter-row surfaces, introducing errors in satellite-based estimations [42,56]. Improving
the spatial resolution from freely available Landsat/Sentinel satellites (spatial resolution 10–15 m) to
such as WorldView-3 (spatial resolution 0.3 m), does not necessarily resolve single canopies of many
horticultural crops.
Current satellite systems generally oﬀer a temporal resolution of about 1–2 weeks this resolution
corresponds to the satellite’s revisit interval (Table 1). For example, freely available Landsat-8 and
Sentinel-2 oﬀer revisit cycles of 16 and 5 days, respectively. Although the MODIS sensor on NASA’s
Agronomy 2020, 10, 140
4 of 35
Terra and Aqua satellites oﬀer a greater temporal resolution (1–2 days), its spatial resolution is relatively
coarse (250 m–1 km) to be valuable for horticulture [25]. The revisit cycle of satellites does not alone
represent the timeframe on which the data can be interpreted. For instance, post-data acquisition,
there are often delays in data transfer to the ground station, handling, and delivery to the end user.
The end user then needs to process the data before making an interpretation. Such processing can
be a combination of atmospheric, radiometric, and geometric corrections, where applicable [57,58].
Furthermore, as the agricultural applications of the satellite imagery are illumination sensitive and
weather dependent, conditions have to be optimal on the satellite revisit day to avoid data corruption
due to, for example, cloud cover [23,53]. Cloud corrupted data (~55% of the land area is covered by
cloud at any one time [59]) will require users to wait for the next revisit to attempt the data acquisition.
Time-series image fusion techniques, such as the spatial and temporal adaptive reﬂectance fusion
model, can improve the spatial and temporal resolution of the satellite data [60,61]. These fusion
techniques blend the frequent (however low-resolution) with higher-resolution (but infrequent) satellite
data [62,63]. The result combines the best aspects of multiple satellite systems to produce frequent and
higher-resolution data, which can be useful for timely monitoring of water status.
The clear advantage of the satellite system is the ability to capture data at a large scale and at an
aﬀordable cost (e.g., the user can download Landsat and Sentinel data for free). The compromise with
the satellite data is in spatial resolution, as well as the relatively long revisit cycle (in the order of days
to weeks), making the data less than ideal for speciﬁc applications, e.g., irrigation scheduling.
2.2. Manned Aircraft System
Operating within few kilometres above ground level, manned aircraft have been used to remotely
acquire agricultural data at higher spatial detail (compared to the satellites) and over a larger region
(compared to UAS) [42,64]. Light ﬁxed-wing aircraft and helicopters are the commonly used manned
aircraft employed in agricultural remote sensing. The ﬁxed-wing aircraft generally ﬂies higher and
faster, enabling the coverage of a larger area, whereas the helicopters are traditionally ﬂown lower
and slower, enabling a spatially detailed observation. A signiﬁcant advantage of the manned aircraft,
compared to UAS, lies in their ability to carry heavier high-grade sensors, such as AVIRIS, HyPlant,
HySpex SWIR-384, Specim AisaFENIX, and Riegl LMS Q240i-60 [65–67]. The use of manned aircraft is,
however, limited by high operational complexity, safety regulations, scheduling inﬂexibility, costs, and
product turnaround time. As a result, these platforms are barely used as compared to the recent surge
in the use of UAS, speciﬁcally for horticultural crops [68–70].
In horticulture, manned aircraft was used to characterise olive and peach canopy temperature
and water stress using speciﬁc thermal bands (10.069 µm and 12.347 µm) of a wideband (0.43–12.5 µm)
airborne hyperspectral camera system [71,72]. This work found moderate correlations (R2 = 0.45–0.57)
of ground vs. aerial olive canopy temperature measurements [72], and high correlations (R2 = 0.94)
of canopy temperature vs. peach fruit size (diameter) [71]. The advantage of manned aircraft for
remote sensing of a large region was highlighted in recent work that characterised regional-scale
grapevine (Vitis vinifera L.) water stress responses of two cultivars, Shiraz and Cabernet Sauvignon, in
Australia [64]. Airborne thermal imaging was able to discriminate between the two cultivars based on
their water status responses to soil moisture availability (Figure 1).
Agronomy 2020, 10, 140
5 of 35
Agronomy 2020, 10, 140 
5 of 35 
 
 
Figure 1. Water status of Shiraz and Cabernet Sauvignon under similar soil moisture as captured from 
manned aircraft [64]. 
2.3. Unmanned Aircraft Systems 
Both the fixed-wing and the rotary-wing variant of UASs are used in agricultural remote 
sensing. Each variant has its advantages and shortcomings vis-à-vis sensor payload, flexibility, and 
coverage. In this regard, the literature provides a list of state-of-the-art UAS [73], their categorisation 
[74], and overview of structural characteristics, as well as flight parameters [75], in the context of 
agricultural use. Depending on the number of rotors, a rotary-wing UAS can be a helicopter, a 
quadcopter, a hexacopter, or an octocopter, among others. Rotary-wing UAS are more agile and can 
fly with a higher degree of freedom [76], while fixed-wing UAS needs to be moving forward at a 
certain speed to maintain thrust. As a result, rotary-wing UAS provides flexibility and specific 
capabilities, such as hovering, vertical take-off and landing, vertical (up and down) motions, or return 
to the previous location. On the contrary, fixed-wing UAS fly faster, carry heavier payloads, and have 
greater flying time enabling coverage of larger areas in a single flight [77]. Recently developed fixed-
wing UAS with vertical take-off and landing capabilities, such as BirdEyeView FireFly6 PRO, Elipse 
VTOL-PPK, and Carbonix Volanti, captures the pros of both fixed-wing and rotary-wing, making 
them a promising platform for agricultural purposes. In the context of precision agriculture, the 
application of UAS, their future prospects, and knowledge gaps are discussed in [53,78–81]. While 
many horticultural crops have been studied using UAS technology, the most studied horticultural 
crops are vineyards [31,82–84], citrus [85,86], peach [32,33], olive [18,87,88], pistachio [89,90], and 
almond [91–94], among others [95–99]. Some of the UAS types used for water status studies of 
horticultural crops are shown in Figure 2. 
 
 
(a) 
(b) 
Figure 1. Water status of Shiraz and Cabernet Sauvignon under similar soil moisture as captured from
manned aircraft [64].
2.3. Unmanned Aircraft Systems
Both the ﬁxed-wing and the rotary-wing variant of UASs are used in agricultural remote sensing.
Each variant has its advantages and shortcomings vis-à-vis sensor payload, ﬂexibility, and coverage.
In this regard, the literature provides a list of state-of-the-art UAS [73], their categorisation [74], and
overview of structural characteristics, as well as ﬂight parameters [75], in the context of agricultural use.
Depending on the number of rotors, a rotary-wing UAS can be a helicopter, a quadcopter, a hexacopter,
or an octocopter, among others. Rotary-wing UAS are more agile and can ﬂy with a higher degree of
freedom [76], while ﬁxed-wing UAS needs to be moving forward at a certain speed to maintain thrust.
As a result, rotary-wing UAS provides ﬂexibility and speciﬁc capabilities, such as hovering, vertical
take-oﬀ and landing, vertical (up and down) motions, or return to the previous location. On the contrary,
ﬁxed-wing UAS ﬂy faster, carry heavier payloads, and have greater ﬂying time enabling coverage of
larger areas in a single ﬂight [77]. Recently developed ﬁxed-wing UAS with vertical take-oﬀ and landing
capabilities, such as BirdEyeView FireFly6 PRO, Elipse VTOL-PPK, and Carbonix Volanti, captures
the pros of both ﬁxed-wing and rotary-wing, making them a promising platform for agricultural
purposes. In the context of precision agriculture, the application of UAS, their future prospects,
and knowledge gaps are discussed in [53,78–81]. While many horticultural crops have been studied
using UAS technology, the most studied horticultural crops are vineyards [31,82–84], citrus [85,86],
peach [32,33], olive [18,87,88], pistachio [89,90], and almond [91–94], among others [95–99]. Some of
the UAS types used for water status studies of horticultural crops are shown in Figure 2.
Agronomy 2020, 10, 140 
5 of 35 
 
 
Figure 1. Water status of Shiraz and Cabernet Sauvignon under similar soil moisture as captured from 
manned aircraft [64]. 
2.3. Unmanned Aircraft Systems 
Both the fixed-wing and the rotary-wing variant of UASs are used in agricultural remote 
sensing. Each variant has its advantages and shortcomings vis-à-vis sensor payload, flexibility, and 
coverage. In this regard, the literature provides a list of state-of-the-art UAS [73], their categorisation 
[74], and overview of structural characteristics, as well as flight parameters [75], in the context of 
agricultural use. Depending on the number of rotors, a rotary-wing UAS can be a helicopter, a 
quadcopter, a hexacopter, or an octocopter, among others. Rotary-wing UAS are more agile and can 
fly with a higher degree of freedom [76], while fixed-wing UAS needs to be moving forward at a 
certain speed to maintain thrust. As a result, rotary-wing UAS provides flexibility and specific 
capabilities, such as hovering, vertical take-off and landing, vertical (up and down) motions, or return 
to the previous location. On the contrary, fixed-wing UAS fly faster, carry heavier payloads, and have 
greater flying time enabling coverage of larger areas in a single flight [77]. Recently developed fixed-
wing UAS with vertical take-off and landing capabilities, such as BirdEyeView FireFly6 PRO, Elipse 
VTOL-PPK, and Carbonix Volanti, captures the pros of both fixed-wing and rotary-wing, making 
them a promising platform for agricultural purposes. In the context of precision agriculture, the 
application of UAS, their future prospects, and knowledge gaps are discussed in [53,78–81]. While 
many horticultural crops have been studied using UAS technology, the most studied horticultural 
crops are vineyards [31,82–84], citrus [85,86], peach [32,33], olive [18,87,88], pistachio [89,90], and 
almond [91–94], among others [95–99]. Some of the UAS types used for water status studies of 
horticultural crops are shown in Figure 2. 
 
 
(a) 
(b) 
Figure 2. Cont.
Agronomy 2020, 10, 140
6 of 35
Agronomy 2020, 10, 140 
6 of 35 
 
 
 
(c) 
(d) 
Figure 2. Examples of unmanned aircraft systems (UAS) used to study water status in horticulture 
crops: (a) hexacopter equipped with RGB, multispectral and thermal camera at The University of 
Adelaide, Adelaide, Australia (b) quadcopter equipped with a thermal and multispectral camera 
[100], (c) fixed-wing aircraft used for GRAPEX project to carry RGB, thermal and monochrome camera 
with narrowband filters [101], and (d) helicopter used for various studies of crop water status 
[18,92,102]. 
UAS offers flexibility on spatial resolution, observation scale, spectral bands, and temporal 
resolution to collect data on any good weather day. However, like satellite and manned aircraft, the 
UAS is inoperable during precipitation, high winds, and temperatures. By easily altering the flying 
altitude, the UAS provides higher flexibility to observe a larger area with lower spatial resolution or 
smaller area with much greater detail [103]. Temporally, the UAS can be scheduled at a user-defined 
time at short notice, thus accommodating applications that are time-sensitive, such as capturing vital 
phenological stages of crop growth. Spectrally, UAS offer flexibility to carry on-demand sensors and 
interchangeability between sensor payloads; thus, any desired combination of sensors and spectral 
bands can be incorporated to target specific features. 
UAS-acquired image data requires post-processing before it can be incorporated into the grower 
decision-making process. Mosaicking of UAS images currently has a turnaround time of 
approximately one day to one week, subject to the size of the dataset, computational power, and 
spectral/spatial quality of the product [104,105]. Spectral quality of the data is of optimal importance, 
whereas the spatial quality can be of less importance, such as for well-established horticultural crops. 
Higher spectral quality demands calibration of the spectral sensors and correction of atmospheric 
effects. Following post-processing of aerial images, the UAS-based spectral data have shown to be 
highly correlated with ground-based data [82,102,106]. 
The most common UAS-based sensor types to study the crop water status are the thermal, 
multispectral and RGB, while hyperspectral and LiDAR (Light detection and ranging) sensors are 
used less often [23,79,107]. Spectral sensors provide the capability to capture broader physiological 
properties of the crop, such as greenness (related to leaf chlorophyll content and health) and biomass, 
that generally correlate with crop water status [82,108]. Narrower band spectral sensors provide 
direct insight into specific biophysical and biochemical properties of crops, such as via photochemical 
reflectance index (PRI) and solar-induced chlorophyll fluorescence (SIF), which reflects a plant’s 
photosynthetic efficiency [109,110]. Thermal-based sensors capture the temperature of the crop’s 
surface, which indicates the plant’s stress (both biotic and abiotic) [53]. Generally, digital RGB camera 
and LiDAR can be used to quantify 3D metrics, such as the plant size and shape, via 3D pointclouds 
with sufficient accuracy for canopy level assessment [111–118]. 
3. Remote Sensor Types 
3.1. Digital Camera 
A digital camera typically incorporates an RGB, modified RGB, and a monochrome digital 
camera. The lens quality of the camera determines the sharpness of the image, while the resolution 
Figure 2. Examples of unmanned aircraft systems (UAS) used to study water status in horticulture
crops: (a) hexacopter equipped with RGB, multispectral and thermal camera at The University of
Adelaide, Adelaide, Australia (b) quadcopter equipped with a thermal and multispectral camera [100],
(c) ﬁxed-wing aircraft used for GRAPEX project to carry RGB, thermal and monochrome camera with
narrowband ﬁlters [101], and (d) helicopter used for various studies of crop water status [18,92,102].
UAS oﬀers ﬂexibility on spatial resolution, observation scale, spectral bands, and temporal
resolution to collect data on any good weather day. However, like satellite and manned aircraft, the
UAS is inoperable during precipitation, high winds, and temperatures. By easily altering the ﬂying
altitude, the UAS provides higher ﬂexibility to observe a larger area with lower spatial resolution or
smaller area with much greater detail [103]. Temporally, the UAS can be scheduled at a user-deﬁned
time at short notice, thus accommodating applications that are time-sensitive, such as capturing vital
phenological stages of crop growth. Spectrally, UAS oﬀer ﬂexibility to carry on-demand sensors and
interchangeability between sensor payloads; thus, any desired combination of sensors and spectral
bands can be incorporated to target speciﬁc features.
UAS-acquired image data requires post-processing before it can be incorporated into the grower
decision-making process. Mosaicking of UAS images currently has a turnaround time of approximately
one day to one week, subject to the size of the dataset, computational power, and spectral/spatial
quality of the product [104,105]. Spectral quality of the data is of optimal importance, whereas the
spatial quality can be of less importance, such as for well-established horticultural crops. Higher
spectral quality demands calibration of the spectral sensors and correction of atmospheric eﬀects.
Following post-processing of aerial images, the UAS-based spectral data have shown to be highly
correlated with ground-based data [82,102,106].
The most common UAS-based sensor types to study the crop water status are the thermal,
multispectral and RGB, while hyperspectral and LiDAR (Light detection and ranging) sensors are
used less often [23,79,107]. Spectral sensors provide the capability to capture broader physiological
properties of the crop, such as greenness (related to leaf chlorophyll content and health) and biomass,
that generally correlate with crop water status [82,108]. Narrower band spectral sensors provide
direct insight into speciﬁc biophysical and biochemical properties of crops, such as via photochemical
reﬂectance index (PRI) and solar-induced chlorophyll ﬂuorescence (SIF), which reﬂects a plant’s
photosynthetic eﬃciency [109,110]. Thermal-based sensors capture the temperature of the crop’s
surface, which indicates the plant’s stress (both biotic and abiotic) [53]. Generally, digital RGB camera
and LiDAR can be used to quantify 3D metrics, such as the plant size and shape, via 3D pointclouds
with suﬃcient accuracy for canopy level assessment [111–118].
3. Remote Sensor Types
3.1. Digital Camera
A digital camera typically incorporates an RGB, modiﬁed RGB, and a monochrome digital camera.
The lens quality of the camera determines the sharpness of the image, while the resolution of the
Agronomy 2020, 10, 140
7 of 35
camera determines its spatial resolution and details within an image. The RGB camera uses broad
spectral bandwidth within the blue, green and red spectral region to capture energy received at the
visible region of the electromagnetic spectrum. The images are used to retrieve dimensional properties
of the crop, terrain conﬁguration, macrostructure of the ﬁeld, and the spatial information. Based on
the dimensional properties, such as size, height, perimeter, and area of the crown, the resource need
practices can be estimated [119–121]. Generally, a larger crop is expected to more quickly use available
water resources, resulting in crop water stress at a later stage of the season if irrigation is not suﬃcient.
The evolution of canopy structure within and between seasons can be useful to understand the spatial
variability within the ﬁeld and corresponding water requirements. The macro-structure of horticultural
crops, such as row height, width, spacing, crop count, the fraction of ground cover, and missing
plants, can be identiﬁed remotely, which can aid in the allocation of resources [113,122]. The terrain
conﬁguration in the form of a digital elevation model (DEM) generated from a digital camera can also
enable understanding of the water status in relation to the aspect and slope conﬁguration of the terrain.
3.2. Multispectral Camera
A multispectral camera oﬀers multiple spectral bands across the electromagnetic spectrum.
Most common airborne multispectral cameras have 4–5 bands which include rededge and NIR
bands in addition to the visible bands, R-G-B (e.g., Figure 3a,c). Conﬁgurable ﬁlter placement of
the spectral band is also available, which can potentially target certain physiological responses of
horticultural crops [102]. Spectrally, the airborne multispectral camera has been reported to perform
with consistency, producing reliable measurements following radiometric calibration and atmospheric
correction [123–125].
Their spatial resolution has been found to be suﬃcient for horticultural
applications enabling canopy level observation of the spectral response. For this reason, as well as
relatively low cost, multispectral cameras are used more frequently in horticulture applications.
Agronomy 2020, 10, 140 
7 of 35 
 
of the camera determines its spatial resolution and details within an image. The RGB camera uses 
broad spectral bandwidth within the blue, green and red spectral region to capture energy received 
at the visible region of the electromagnetic spectrum. The images are used to retrieve dimensional 
properties of the crop, terrain configuration, macrostructure of the field, and the spatial information. 
Based on the dimensional properties, such as size, height, perimeter, and area of the crown, the 
resource need practices can be estimated [119–121]. Generally, a larger crop is expected to more 
quickly use available water resources, resulting in crop water stress at a later stage of the season if 
irrigation is not sufficient. The evolution of canopy structure within and between seasons can be 
useful to understand the spatial variability within the field and corresponding water requirements. 
The macro-structure of horticultural crops, such as row height, width, spacing, crop count, the 
fraction of ground cover, and missing plants, can be identified remotely, which can aid in the 
allocation of resources [113,122]. The terrain configuration in the form of a digital elevation model 
(DEM) generated from a digital camera can also enable understanding of the water status in relation 
to the aspect and slope configuration of the terrain. 
3.2. Multispectral Camera 
A multispectral camera offers multiple spectral bands across the electromagnetic spectrum. Most 
common airborne multispectral cameras have 4–5 bands which include rededge and NIR bands in 
addition to the visible bands, R-G-B (e.g., Figure 3a,c). Configurable filter placement of the spectral 
band is also available, which can potentially target certain physiological responses of horticultural 
crops [102]. Spectrally, the airborne multispectral camera has been reported to perform with 
consistency, producing reliable measurements following radiometric calibration and atmospheric 
correction [123–125]. Their spatial resolution has been found to be sufficient for horticultural 
applications enabling canopy level observation of the spectral response. For this reason, as well as 
relatively low cost, multispectral cameras are used more frequently in horticulture applications. 
 
 
(a) 
(b) 
 
 
(c) 
(d) 
Figure 3. Some examples of sensors used on a UAS platform to study water status of horticultural 
crops: (a) A multispectral camera (Tetracam Mini-MCA-6, Tetracam, Inc., Chatsworth, CA, USA) 
[126]. (b) A thermal camera (FLIR TAU II, FLIR Systems, Inc., USA) [100,108]. (c) A multi-sensor 
camera setup with an RGB (Sony α7R III, Sony Electronics, Inc., Minato, Tokyo, Japan), a multispectral 
(MicaSense RedEdge, MicaSense Inc., Seattle, WA, USA), and a thermal (FLIR TAU II 640, FLIR 
Systems, Inc., USA) camera. (d) A micro-hyperspectral camera (Micro-Hyperspec, Headwall 
Photonics, MA, USA) [110]. 
Chlorophyll and cellular structures of vegetation absorb most of the visible light and reflect 
infrared light. The rise in reflectance between the red and NIR band is unique to live green vegetation 
and is captured by vegetation spectral index called NDVI (Table 2, Equation (3). Once the vegetation 
Figure 3. Some examples of sensors used on a UAS platform to study water status of horticultural
crops: (a) A multispectral camera (Tetracam Mini-MCA-6, Tetracam, Inc., Chatsworth, CA, USA) [126].
(b) A thermal camera (FLIR TAU II, FLIR Systems, Inc., USA) [100,108]. (c) A multi-sensor camera setup
with an RGB (Sony α7R III, Sony Electronics, Inc., Minato, Tokyo, Japan), a multispectral (MicaSense
RedEdge, MicaSense Inc., Seattle, WA, USA), and a thermal (FLIR TAU II 640, FLIR Systems, Inc., USA)
camera. (d) A micro-hyperspectral camera (Micro-Hyperspec, Headwall Photonics, MA, USA) [110].
Chlorophyll and cellular structures of vegetation absorb most of the visible light and reﬂect
infrared light. The rise in reﬂectance between the red and NIR band is unique to live green vegetation
and is captured by vegetation spectral index called NDVI (Table 2, Equation (3)). Once the vegetation
starts to experience stress (biotic and abiotic), its reﬂectance in the NIR region is reduced, while the
reﬂectance in the red band is increased. Thus, such stress is reﬂected in the vegetation proﬁle and
Agronomy 2020, 10, 140
8 of 35
easily captured by indices, such as NDVI. For this reason, NDVI has shown correlations with a wide
array of crops response including vigour, chlorophyll content, leaf area index (LAI), crop water stress,
and occasionally yield [34,82–84,127].
The rededge band covers the portion of the electromagnetic spectrum between the red and NIR
bands where reﬂectance increases drastically. Studies have suggested that the sharp transition between
the red absorbance and NIR reﬂection is able to provide additional information about vegetation and
its hydric characteristics [128]. Using the normalised diﬀerence red edge (NDRE) index, the rededge
band was found to be useful in establishing a relative chlorophyll concentration map [127]. Given the
sensitivity of NDRE, it can be used for applications, such as crops drought stress [107]. With regard to
the water use eﬃciency, a combination of vegetation indices (VIs) along with structural physiological
indices were found to be useful to study water stress in horticultural crops [34,82,129].
3.3. Hyperspectral
Hyperspectral sensors have contiguous spectral bands sampled at a narrower wavelength intervals
spanning from visible to NIR spectrum at a high to ultra-high spectral resolution (Figure 3d). Scanning
at contiguous narrow-band wavelengths, a hyperspectral sensor produces a three dimensional (two
spatial dimensions and one spectral dimension) data called hyperspectral data cube. The hyperspectral
data cube is a hyperspectral image where each pixel contain spatial information, as well as the entire
spectral reﬂectance curve [130]. Based on the operating principle and output data cube, hyperspectral
sensors for remote sensing can include a point spectrometer (aka spectroradiometer), whiskbroom
scanner, pushbroom scanner, and 2D imager (Figure 4) [130,131]. A point spectrometer, samples
within its ﬁeld of view solid angle to produce an ultra-high spectral resolution spectral data of a
point [130,132]. A whiskbroom scanner deploys a single detector onboard to scan one single pixel at a
time. As the scanner rotates across-track, successive scans form a row of the data cube, and as the
platform moves forward along-track, successive rows form a hyperspectral image [133]. A pushbroom
scanner deploys a row of spatially contiguous detectors arranged in the perpendicular direction of
travel and scans the entire row of pixels at a time. As the platform moves forward, the successive
rows form a two-dimensional hyperspectral image [40,134]. The 2D imager using diﬀerent scanning
techniques [130] captures hyperspectral data across the image scene [135,136]. The point spectrometer
oﬀers the highest spectral resolution and lowest signal-to-noise ratio (SNR) among the UAS-compatible
hyperspectral sensors [137,138].
Agronomy 2020, 10, 140 
8 of 35 
 
starts to experience stress (biotic and abiotic), its reflectance in the NIR region is reduced, while the 
reflectance in the red band is increased. Thus, such stress is reflected in the vegetation profile and 
easily captured by indices, such as NDVI. For this reason, NDVI has shown correlations with a wide 
array of crops response including vigour, chlorophyll content, leaf area index (LAI), crop water stress, 
and occasionally yield [34,82–84,127]. 
The rededge band covers the portion of the electromagnetic spectrum between the red and NIR 
bands where reflectance increases drastically. Studies have suggested that the sharp transition 
between the red absorbance and NIR reflection is able to provide additional information about 
vegetation and its hydric characteristics [128]. Using the normalised difference red edge (NDRE) 
index, the rededge band was found to be useful in establishing a relative chlorophyll concentration 
map [127]. Given the sensitivity of NDRE, it can be used for applications, such as crops drought stress 
[107]. With regard to the water use efficiency, a combination of vegetation indices (VIs) along with 
structural physiological indices were found to be useful to study water stress in horticultural crops 
[34,82,129]. 
3.3. Hyperspectral 
Hyperspectral sensors have contiguous spectral bands sampled at a narrower wavelength 
intervals spanning from visible to NIR spectrum at a high to ultra-high spectral resolution (Figure 
3d). Scanning at contiguous narrow-band wavelengths, a hyperspectral sensor produces a three 
dimensional (two spatial dimensions and one spectral dimension) data called hyperspectral data 
cube. The hyperspectral data cube is a hyperspectral image where each pixel contain spatial 
information, as well as the entire spectral reflectance curve [130]. Based on the operating principle 
and output data cube, hyperspectral sensors for remote sensing can include a point spectrometer (aka 
spectroradiometer), whiskbroom scanner, pushbroom scanner, and 2D imager (Figure 4) [130,131]. A 
point spectrometer, samples within its field of view solid angle to produce an ultra-high spectral 
resolution spectral data of a point [130,132]. A whiskbroom scanner deploys a single detector onboard 
to scan one single pixel at a time. As the scanner rotates across-track, successive scans form a row of 
the data cube, and as the platform moves forward along-track, successive rows form a hyperspectral 
image [133]. A pushbroom scanner deploys a row of spatially contiguous detectors arranged in the 
perpendicular direction of travel and scans the entire row of pixels at a time. As the platform moves 
forward, the successive rows form a two-dimensional hyperspectral image [40,134]. The 2D imager 
using different scanning techniques [130] captures hyperspectral data across the image scene 
[135,136]. The point spectrometer offers the highest spectral resolution and lowest signal-to-noise 
ratio (SNR) among the UAS-compatible hyperspectral sensors [137,138]. 
 
Figure 4. The data cube structure of different spectral sensors. The number of bands and resolution is 
shown as an example and does not indicate true sensor capability (adapted from [130]). 
Figure 4. The data cube structure of diﬀerent spectral sensors. The number of bands and resolution is
shown as an example and does not indicate true sensor capability (adapted from [130]).
In horticultural applications, hyperspectral data, due to the high resolution contiguous spectral
sampling, possesses tremendous potential to detect and monitor speciﬁc biotic and abiotic stresses [139].
Narrowband hyperspectral data was used to detect water stress using the measurement of ﬂuorescence
Agronomy 2020, 10, 140
9 of 35
and PRI over a citrus orchard [110]. PRI was identiﬁed as one of the best predictors of water stress for a
vineyard in a study that investigated numerous VIs using hyperspectral imaging [140]. High-resolution
thermal imagery obtained from a hyperspectral scanner was used to map canopy stomatal conductance
(gs) and CWSI of olive orchards where diﬀerent irrigation treatments were applied [18]. With the
large volume of spatial/spectral data extracted from the hyperspectral data cube, machine learning
will likely be adopted more widely in the horticultural environment to model water stress [141].
See Reference [54] for a comprehensive review of hyperspectral and thermal remote sensing to detect
plant water status.
3.4. Thermal
Thermal cameras use microbolometers to read passive thermal signals in the spectral range of
approximately 7–14 µm (Figure 3b). Small UAS are capable of carrying a small form-factor thermal
camera with uncooled microbolometers, which does not use an internal cooling mechanism and,
therefore, does not achieve the high SNR that can be found in cooled microbolometer-based thermal
cameras. An array of microbolometer detectors in the thermal camera receives a thermal radiation
signal and stores the signal on the corresponding image pixel as raw data number (DN) values.
The result is a thermal image where each pixel has an associated DN value, which can be converted to
absolute temperature. A representative list of commercial thermal cameras used on UAS platforms
and their applications with regard to agricultural remote sensing is found in the literature [23,53,73].
Thermal imagery enables the measurement of the foliar temperature of plants. The foliar temperature
diﬀerence between well-watered and water-stressed crops is the primary source of information for
water stress prediction using a thermal sensor [142]. When mounted on a remote sensing platform, the
canopy level assessment of crop water status can be performed on a large scale.
Thermal cameras are limited by their resolution (e.g., 640 × 512 is the maximum resolution of
UAS compatible thermal cameras in the current market) and high price-tag [53]. The small number of
pixels results in low spatial resolution limiting either the ability to resolve a single canopy or ability to
ﬂy higher and cover a larger area. If ﬂown at a higher altitude, the eﬀective spatial resolution may
be inadequate for canopy level assessment of some horticultural crops. For example, a FLIR Tau2
640 thermal camera with a 13 mm focal length when ﬂown at an altitude of approximately 120 m
results in a spatial resolution of 15.7 cm. For relatively large horticultural crops, such as grapevine,
almond, citrus, and avocado, the resolution at a maximum legal ﬂying altitude of 120 m in Australia
(for small-sized UAS) oﬀers an adequate spatial resolution to observe a single canopy.
Another challenge with the use of thermal cameras is the temporal drift of the DN values
within successive thermal images, especially with uncooled thermal cameras [143]. Due to the lack
of an internal cooling mechanism for the microbolometer detectors, DN values registered by the
microbolometers experience temporal drift i.e., the registered DN values for the same temperature
target will drift temporally. Thus, the thermal image can be unreliable especially when the internal
temperature of the camera is changing rapidly, such as during camera warmup period or during the
ﬂight when a gust of cool wind results in cooling of the camera. To overcome this challenge, the user
may need to provide suﬃcient startup time before operation (preferably 30–60 min) [102,143–145],
shield the camera to minimize the change in the internal temperature of the camera [142], calibrate the
camera [146–153], and perform frequent ﬂat-ﬁeld corrections.
3.5. Multi-Sensor
To carry multiple sensors, the total UAS payload needs to be considered that includes, in
addition to the sensors, an inertial measurement unit (IMU) and global navigation satellite system
(GNSS) for the georeferencing purpose [40,154]. Higher accuracy sensors tend to be heavier, and in
a multi-sensor scenario, the payload can quickly reach or even exceed the payload limit. This has
limited contemporary measurements in earlier multirotor UAS requiring separate ﬂights for each of
sensor [126]. The use of ﬁxed-wing UAS has allowed carrying higher payloads due to the much larger
Agronomy 2020, 10, 140
10 of 35
thrust-to-weight ratio as compared to a rotary-wing aircraft [155]. Similarly, recent advancement in
UAS technology and lightweight sensors have enabled multirotor (payload 5–6 kg readily available) to
onboard multi-sensors.
Water status of crops is a complex process inﬂuenced by a number of factors including the
physiology of the crop, available soil moisture, the size and vigour of the crop, and meteorological
factors [30,108,116,156,157]. For this reason, a multi-sensor platform is used to acquire measurements
of the diﬀerent aspects of the crop for water status assessment [34,102,108]. The most common
combination of sensors found in the literature is the RGB, multispectral (including rededge and NIR
bands) and thermal. Together, these sensors can be used to investigate the water status of the crop
using various indicators, such as PRI, CWSI, ﬂuorescence, and structural properties, with the aim of
improving the water use eﬃciency [102,110,158–160].
4. Techniques of Remote Sensing in Horticulture
4.1. Georeferencing of Remotely Sensed Images
Georeferencing provides a spatial reference to the remotely sensed images such that the pixels
representing crops or regions of interest on the images are correctly associated with their position on
Earth. The georeferencing process generally uses surveyed coordinate points on the ground, known
as ground control points (GCPs), to determine and apply scaling and transformation to the aerial
images [161]. Alternatively, instead of GCPs, the user can georeference aerial images by using the
accurate position of the camera, or by co-registration with the existing georeferenced map [105,162].
In the case of UAS-based images, the capture timing is scheduled to ensure a recommended
forward overlap (>80%) between successive images.
The ﬂight path is designed to ensure the
recommended side overlap (>70%) between images from successive ﬂight strips. Thus, the captured
series of images are processed using the Structure-from-Motion (SfM) technique to generate a 3D
pointcloud and orthomosaic [73,130] (see Figure 5). Commonly used SfM software to process the
remote sensing images are Agisoft PhotoScan and Pix4D. The commonly retrieved outputs from the
SfM software for assessment of horticulture crops include the orthomosaic, digital surface model
(DSM), DEM, and 3D pointcloud [113,126,163]. This technique of georeferencing can be applied to any
sensor that produces images, e.g., RGB, thermal, or multispectral cameras [126,164,165].
Agronomy 2020, 10, 140 
10 of 35 
 
sensor [126]. The use of fixed-wing UAS has allowed carrying higher payloads due to the much larger 
thrust-to-weight ratio as compared to a rotary-wing aircraft [155]. Similarly, recent advancement in 
UAS technology and lightweight sensors have enabled multirotor (payload 5–6 kg readily available) 
to onboard multi-sensors. 
Water status of crops is a complex process influenced by a number of factors including the 
physiology of the crop, available soil moisture, the size and vigour of the crop, and meteorological 
factors [30,108,116,156,157]. For this reason, a multi-sensor platform is used to acquire measurements 
of the different aspects of the crop for water status assessment [34,102,108]. The most common 
combination of sensors found in the literature is the RGB, multispectral (including rededge and NIR 
bands) and thermal. Together, these sensors can be used to investigate the water status of the crop 
using various indicators, such as PRI, CWSI, fluorescence, and structural properties, with the aim of 
improving the water use efficiency [102,110,158–160]. 
4. Techniques of Remote Sensing in Horticulture 
4.1. Georeferencing of Remotely Sensed Images 
Georeferencing provides a spatial reference to the remotely sensed images such that the pixels 
representing crops or regions of interest on the images are correctly associated with their position on 
Earth. The georeferencing process generally uses surveyed coordinate points on the ground, known 
as ground control points (GCPs), to determine and apply scaling and transformation to the aerial 
images [161]. Alternatively, instead of GCPs, the user can georeference aerial images by using the 
accurate position of the camera, or by co-registration with the existing georeferenced map [105,162]. 
In the case of UAS-based images, the capture timing is scheduled to ensure a recommended 
forward overlap (>80%) between successive images. The flight path is designed to ensure the 
recommended side overlap (>70%) between images from successive flight strips. Thus, the captured 
series of images are processed using the Structure-from-Motion (SfM) technique to generate a 3D 
pointcloud and orthomosaic [73,130] (see Figure 5). Commonly used SfM software to process the 
remote sensing images are Agisoft PhotoScan and Pix4D. The commonly retrieved outputs from the 
SfM software for assessment of horticulture crops include the orthomosaic, digital surface model 
(DSM), DEM, and 3D pointcloud [113,126,163]. This technique of georeferencing can be applied to 
any sensor that produces images, e.g., RGB, thermal, or multispectral cameras [126,164,165]. 
 
Figure 5. A typical workflow of structure-from-motion (SfM) to produce georeferenced products from 
UAS-based image sets and ground control points (adapted from [166,167]). SIFT = scale-invariant 
feature transform; ANN = approximate nearest neighbour; RANSAC = random sample consensus; 
Figure 5. A typical workﬂow of structure-from-motion (SfM) to produce georeferenced products from
UAS-based image sets and ground control points (adapted from [166,167]). SIFT = scale-invariant
feature transform; ANN = approximate nearest neighbour; RANSAC = random sample consensus;
CMVS = clustering views for multi-view stereo; PMVS = patch-based multi-view stereo; GCP = ground
control points.
Agronomy 2020, 10, 140
11 of 35
The complexity of georeferencing of hyperspectral observations depends on the sensor type, i.e.,
imaging or non-imaging. A non-imaging spectroradiometer relies on the use of a GNSS antenna and
an IMU for georeferencing the point observation [130,132,138,168]. An imaging hyperspectral camera,
generally, in addition to GNSS and IMU measurement, uses the inter-pixel relation in SfM to produce a
georeferenced orthomosaic [40,134,135,169,170].
4.2. Calibration and Correction of Remotely Sensed Images
Ensuring consistency, repeatability, and quality of the spectral observation requires stringent
radiometric, spectral, and atmospheric corrections [123,171–177]. Spectral and radiometric calibration
is performed in the spectral calibration facility in darkroom settings. The sensor’s optical properties
and shift in spectral band position are corrected during the spectral calibration process. Radiometric
calibration enables conversion of the recorded digital values into physical units, such as radiance.
Inﬁeld operation of the spectral sensor is inﬂuenced by variations in atmospheric transmittance
from thin clouds, invisible to the human observer. Changes in atmospheric transmittance aﬀect the
radiance incident on the plant. As a result, the change in acquired spectral response by the sensor
may not represent the change in plants response but the change in incident radiation on the plant.
The most common method to convert the spectral data to reﬂectance is by generating an empirical line
relationship between sensor values and spectral targets, such as a Spectralon® or calibration targets.
The use of downwelling sensors, such as a cosine corrector [137], or the use of a ground-based PAR
sensor enables absolute radiometric calibration to generate radiance [130].
The calibration of the broad wavelength multispectral sensor is generally less stringent than
the hyperspectral. Generally, multispectral sensors are used to compute normalised indices such
as NDVI. The normalised indices are relatively less inﬂuenced, although signiﬁcant, by the change
in illumination conditions which aﬀect the entire spectrum proportionally [29,101]. In this regard,
radiometric calibration of the multispectral camera has used a range of stringent to simpliﬁed, and
vicarious approaches [123,125,171,173,178–180]. Some multispectral cameras are equipped with a
downwelling light sensor, which is aimed at correcting for variations in atmospheric transmittance.
However, the performance of such downwelling sensors (without a cosine corrector) on multispectral
cameras have been reported to have directional variation resulting in unstable correction, indicating
the inability of the sensor to incorporate the entire hemisphere of diﬀused light [124,137].
The radiometric calibration of the thermal images is typically based on the camera’s DN to object
temperature curve, which provides the relationship between the DN of a pixel and a known object
temperature, usually of a black body radiator. Measurement accuracy and SNR of the camera under
varying ambient temperatures can be improved by using calibration shutters, which are recently
available commercially. Furthermore, for low measurement errors (under 1 ◦C), thermal data requires
consideration to the atmospheric transmittance [18,102]. Flying over a few temperature reference
targets placed on the ground reduces the temporal drift of the camera [142,143,181]. Temperature
accuracy within a few degrees was achieved by ﬂying over the targets three times (at the start, middle
and end of UAS operation) and using three separate calibration equations for each overpass [142].
Additionally, using the redundant information from multiple overlapping images, drift correction
models have been proposed, which lowered temperature error by 1 ◦C as compared to uncorrected
orthomosaic [152]. The manufacturer stated accuracies (generally ±5 ◦C) can be suﬃcient to access the
ﬁeld variability and to detect “hotspots” of water status. However, the aforementioned calibration and
correction of the thermal cameras are required for quantitative measurement as a goal [143]. In this
regard, current challenges and best practices for the operation of thermal cameras onboard a UAS is
provided in the literature [143].
4.3. Canopy Data Extraction
A key challenge in remote sensing of horticultural as compared to agricultural crops arises due
to the proportion of inter-row ground/vegetation cover and resulting mixed pixels. The proportion
Agronomy 2020, 10, 140
12 of 35
of the mixed pixels increases with the decrease in spatial resolution of the image. Most of the pixels
towards the edge of the canopy contain a blend of information originating from the sun-lit canopy,
shadowed leaves, and inter-row bare soil/cover crop. A further challenge can arise for some crops,
such as grapevine, due to overlapping of adjacent plants.
The canopy data from orthomosaic has been extracted using either a pixel-based or an object-based
approach. Earlier studies manually sampled from the centre of crop row which most likely eliminated
the mixed pixels [182]. In the pixel-based approach, techniques, such as applying global threshold
and masking, have been used. Binary masks, such as NDVI, eliminates non-canopy pixels from
the sampling [82,84]. Combining the NDVI mask with the canopy height mask can exclude the
pixels associated with non-vegetation, as well as vegetation that does not meet the height threshold.
The pixel-based approach, however, can result in inaccurate identiﬁcation of some crops due to pixel
heterogeneity, mixed pixels, spectral similarity, and crop pattern variability.
In the object-based approach, using object detection techniques, neighbouring pixels with
homogenous information, such as spectral, textural, structural, and hierarchical features, are grouped
into “objects”. These objects are used as the basis of object-based image analysis (OBIA) classiﬁcation
using classiﬁers, such as k-nearest neighbour, decision tree, support vector machine, random forest,
and maximum likelihood [122,183–185]. In the horticultural environment, OBIA has been adopted
to classify and sample from pure canopy pixels [119,122,186]. Consideration should be provided on
the number of features and their suitability for a speciﬁc application to reduce the computational
burden, as well as to maintain the accuracies. The generalisation of these algorithms for transferability
between study sites usually penalises the achievable accuracy. For details in object-based approach of
segmentation and classiﬁcation, readers are directed to literatures [122,183,185,187–189].
Other techniques found in the literature include algorithms, such as ‘Watershed’, which has been
demonstrated in palm orchards [82,190]. Vine rows and plants have been isolated and classiﬁed using
image processing techniques, such as clustering and skeletisation [188,191–193]. Similarly, the gridded
polygon, available in common GIS software, such as ArcGIS and QGIS, can be used in combination
with zonal statistics for this purpose. When working with the low-resolution images, co-registration
with the high-resolution images has been proposed, whereby, the high-resolution images enable better
delineation of the mixed pixels [194]. For this reason, spectral and thermal sensors, which are usually
low in resolution, are generally employed along with high-resolution digital cameras.
4.4. Indicators of Crop Water Status
A crop’s biophysical and biochemical attributes can be approximated using diﬀerent indices and
quantitative products. For example, CWSI is used to proxy leaf water potential (Ψleaf), stem water
potential (Ψstem), gs, and net photosynthesis (Pn) [83,100,195]. With regard to horticultural crops, water
status has been assessed using a number of spectral and thermal indices (Table 2).
Table 2. Commonly used vegetation and thermal indices to study the water status of horticultural crops.
Indicators
Sensor
Purpose
References
Tc, (Tc − Ta)
Thermal
Ψstem, gs, yield
[34,82,85,99,110]
Ig, I3
Thermal
Ψstem, gs
[82,196]
CWSI
Thermal
Ψleaf, Ψstem, gs, Pn, yield
[18,31,33,85,90,97,99,100,182,194,197–199]
(Tc − Ta)/NDVI
Thermal + multispectral
Ψstem, gs
[82,200]
NDVI
Multispectral
Ψstem, gs, yield, LAI, vigour
[34,56,82,86,182,201]
GNDVI
Multispectral
Ψstem, gs, yield
[34,82]
RDVI
Multispectral
Ψstem, gs
[82,86,182]
PRI
Multispectral
Ψleaf, gs
[86,110,182]
Fluorescence
Hyperspectral
Ψleaf, gs
[110]
WBI
Hyperspectral
Ψleaf, gs
[139,202,203]
SIF
Hyperspectral
Water stress
[204–206]
Note the acronyms: Tc = Canopy temperature, Ta = ambient temperature, Ig = conductance index, I3 = stomatal
conductance index, CWSI = crop water stress index, NDVI = normalised diﬀerence vegetation index, GNDVI = green
normalised diﬀerence vegetation index, RDVI = renormalized diﬀerence vegetation index, PRI = photochemical
reﬂectance index, Fluorescence = chlorophyll ﬂuorescence, WBI = water band index, SIF = solar-induced chlorophyll
ﬂuorescence, LAI = leaf area index.
Agronomy 2020, 10, 140
13 of 35
4.4.1. Canopy Temperature
A plant maintains its temperature by transpiring through the stomata to balance the energy
ﬂuxes in and out of the canopy. As the plant experience stress (both biotic and abiotic), the rate of
transpiration decreases, which results in higher canopy temperature (Tc), which can be a proxy to
understand the water stress in the plant [207]. In this regard, crop water stress showed a correlation
with canopy temperature extracted from the thermal image [208], which enables mapping the spatial
variability in water status [209]. Leaf/canopy temperature alone, however, does not provide a complete
characterisation of crop water status, for instance, an equally stressed canopy can be 25 ◦C or 35 ◦C,
depending on the current ambient temperature (Ta). Thus, canopy-to-air temperature diﬀerence
(Tc − Ta) was proposed, which showed a good correlation with the Ψstem, Ψleaf, and gs in horticultural
crops [85,99,182].
4.4.2. Normalised Thermal Indices
The CWSI, the conductance index (Ig) and the stomatal conductance index (I3) are thermal
indices most commonly used to estimate crop water status and gs [210–212]. These indices provide
similar information, however, use a diﬀerent range of numbers to represent the level of water stress.
The CWSI is normalised within zero and one, whereas Ig and I3 represent stress using numbers
between zero and inﬁnity. CWSI has been adopted most widely in horticultural applications to
assess the water status of crops, such as the grapevines [100,213], almond [91,198], citrus [85,110], and
others [18,87,99,214]. By normalising between the lower and upper limits of (Tc − Ta), the CWSI of the
canopy presents quantiﬁable relative water stress. The formula for CWSI computation is deﬁned as in
Equation (1) [208,212].
CWSI =
(Tc − Ta) − (Tc − Ta)LL
(Tc − Ta)UL − (Tc − Ta)LL
(1)
where (Tc − Ta)UL and (Tc − Ta)LL represent the upper and lower bound of (Tc − Ta) which are found in
the water-stressed canopy and well-watered canopy transpiring at the full potential (or maximum) rate,
respectively. Assuming a constant ambient temperature, Equation (1) can be simpliﬁed to Equation (2),
which is the most widely reported formulation of CWSI with regard to the horticultural remote sensing.
CWSI = (Tc − Twet)

Tdry − Twet

(2)
where Twet is the temperature of canopy transpiring at the maximum potential, and Tdry is the
temperature of the non-transpiring canopy. CWSI has been shown to be well-correlated with direct
measurements of crop water status in the horticultural environment [18,31,32,90,99]. In this regard,
a correlation of CWSI with various ground measurements, such as Ψleaf [18,31,197], Ψstem [33,90,194],
and gs [18,90,100], have been established. Diurnal measurements of CWSI compared with Ψleaf showed
the best correlation at noon [89,197,209].
CWSI is a normalised index, i.e., relative to a reference temperature range between Twet and Tdry,
which is speciﬁc to a region and crop type; thus, CWSI is not a universal quantitative indicator of crop
water status. For instance, a CWSI of 0.5 for two diﬀerent varieties of grapevines at diﬀerent locations
does not conclusively inform that they have equal or superior/inferior water status. Furthermore,
the degree of correlation can change depending on the isohydric/anisohydric response of crop [214]
where early/late stomatal closure aﬀects the indicators of water stress [110]. Moreover, phenological
stage aﬀects the relationship between remotely sensed CWSI and water stress [197]. Thus, water stress
in a diﬀerent crop, at a diﬀerent location and at a diﬀerent phenological stage, will have a unique
correlation with CWSI and, therefore, needs to be established independently.
There are multiple methods to measure the two reference temperatures, Twet and Tdry, which
could result in variable CWSI values depending on the method used. The ﬁrst method is to measure the
two reference temperatures on the crop of interest. Tdry can be estimated by inducing stomatal closure,
Agronomy 2020, 10, 140
14 of 35
which is the leaf temperature approximately 30 min after applying a layer of petroleum jelly e.g.,
Vaseline to both sides of a leaf. This eﬀectively blocks stomata and, therefore, impedes leaf transpiration.
Twet can be estimated by measuring leaf temperature approximately 30 s after spraying water on the
leaf, which emulates maximum transpiration [23,83]. The advantage of this method is that the stress
levels are normalised to actual plants response, whereas the necessity to repeat the measurement for
every test site after each ﬂight can be cumbersome. In an alternative (second) approach the range can
be established based on meteorological data e.g., setting Tdry to 5 ◦C above air temperature and Twet
measured from an artiﬁcial surface. This method is also limited to local scale and presents a problem
regarding the choice of material, which ideally needs to have similar to leaf emissivity, aerodynamic
and optical properties [54,87]. The third method uses the actual temperature measurement range
of the remote sensing image [33,97]. This method is simple to implement, however, works on the
assumption that the ﬁeld contains enough variability to contain a representative Twet and Tdry. Fourth,
the reference temperatures can be estimated by theoretically solving for the leaf surface energy balance
equations, however, are limited by the necessity to compute the canopy aerodynamic resistance [87].
Standard and robust Twet and Tdry measurements are needed to characterize CWSI with accuracy,
especially for temporal analysis [85,87,211]. The level of uncertainty due to the adaptation of diﬀerent
approaches for Twet and Tdry determination in the instantaneous and seasonal measurements of CWSI
is not known. Nonetheless, adopting a consistent approach, CWSI has been shown to be suitable for
monitoring the water status and making irrigation decisions of horticultural crops [31,85].
4.4.3. Spectral Indices
Crops reﬂectance properties convey information about the crop, for instance, a healthier crop has
higher reﬂectance in the NIR band. Most often, the bands are mathematically combined to form VIs,
which provide information on the crop’s health, growth stage, biophysical properties, leaf biochemistry,
and water stress [29,215–218]. Using multispectral or hyperspectral data, several Vis, such as green
normalised diﬀerence vegetation index (GNDVI), renormalised diﬀerence vegetation index (RDVI),
optimized soil-adjusted vegetation index (OSAVI), transformed chlorophyll absorption in reﬂectance
index (TCARI), and TCARI/OSAVI, amongst others [34,79,82], can be calculated that correlate with the
water stress of horticultural crops (see Table 2). The most widely studied VI in horticulture, in this
regard, is the NDVI (Equation (3)).
NDVI = Rnir − Rr
Rnir + Rr
(3)
where Rnir and Rr represent the spectral reﬂectance acquired at the NIR and red spectral regions,
respectively. In horticulture, NDVI has been used as a proxy to estimate the vigour, biomass, and water
status of the crop. A vigorous canopy with more leaves regulates more water, therefore remaining
cooler when irrigated [200] and experiencing early water stress when unirrigated. With regard to
irrigation, the broadband normalised spectral indices (such as NDVI) are suitable to detect spatial
variability and to identify the area that is most vulnerable to water stress. However, these indices are
not expected to change rapidly to reﬂect the instantaneous water status of plants that are needed to
make decisions on irrigation scheduling.
The multispectral indices along with complementary information in thermal wavelengths have
proven to be well suited to monitoring vegetation, speciﬁcally in relation to water stress [219]. The ratio
of canopy surface temperature to NDVI, deﬁned as temperature-vegetation dryness index (TVDI),
was found to be useful for the study of water status in horticultural crops. TVDI exploits the fact that
vegetation with larger NDVI will have a lower surface temperature unless the vegetation is under
stress. As most vegetation normally remains green after an initial bout of water stress, the TVDI is
more suited than NDVI for early detection of water stress as the surface temperature can rise rapidly
even during initial water stress [200].
Similarly, narrowband VIs that have been studied in relation to remote sensing of water status are
PRI and chlorophyll ﬂuorescence, which have been directly correlated to the crop Ψleaf, gs [110,182,204].
Agronomy 2020, 10, 140
15 of 35
Several hyperspectral indices to estimate water status have been identiﬁed [139]; however, their
application in remote sensing of horticultural crops is at its infancy. Hyperspectral indices speciﬁc to
water absorption bands around 900 nm, 1200 nm, 1400 nm, and 1900 nm may be used to detect the
water status of horticultural crops. The absorption features were found to be highly correlated with
plant water status [139]. Water band index (WBI), as deﬁned in Equation (4), has been shown to closely
track the changes in the plant water status of various crops [202,203].
WBI = R970
R900
(4)
Other water-related hyperspectral indices with potential application for horticultural crops can
be found in the literature [139,202,203]. Hyperspectral data possess the capability to reﬂect the
instantaneous water status of the plant, which can be useful for quantitative decision-making on
irrigation scheduling.
4.4.4. Soil Moisture
The moisture status of the soil provides an indication of the available water resource to the crop.
Soil moisture is traditionally measured indirectly using soil moisture sensors placed below the surface
of the soil. A key challenge with using soil moisture sensors are the spatial distribution of moisture,
both vertically and horizontally, to account for inherent ﬁeld-scale variability. For instance, the root
system of some horticultural crops, such as grapevine, is capable of accessing water up to 30 m deep,
while customer-grade soil moisture probes generally extend to 1.5 m in depth or less. Thus, soil
moisture probes do not capture all the water available to the crop as they are point measures and
not necessarily where the roots are located. Moreover, estimation of soil moisture across spatial and
temporal scales is of interest for various agricultural and hydrological studies. Optical, thermal, and
microwave remote sensing with their advantages relating to high spatial scale and temporal resolutions
could potentially be used for soil moisture estimation [220–222]. L-band microwave radiometry,
a component of synthetic aperture radar systems, has been shown to be a reliable approach to estimate
soil moisture via satellite-based remote sensing [223], such as using the ESA’s Soil Moisture and
Ocean Salinity (SMOS) [224] and NASA’s Soil Moisture Active Passive (SMAP) satellites [225,226].
The limitation of the SMOS and SMAP missions, with regard to horticultural application, is their
depth of retrieval (up to 5 cm) and spatial resolution (in the order of tens of kilometre) [227–229].
As an airborne application, the volumetric soil moisture has been estimated by analysing the SNR of
the GNSS interference signal [230,231]. With aforementioned capabilities, a combination of satellite
and airborne remote sensing may, in the future, be a reliable tool to map soil moisture across spatial,
temporal and depth scales.
4.4.5. Physiological Attributes
Using the SfM on remotely-sensed images, 3D canopy structure, terrain conﬁgurations, and canopy
surface models can be derived [113,114,119,186,232]. By employing a delineation algorithm on the 3D
models, the 3D attributes of the crops and macrostructure are determined more accurately [120,122,233].
Crop surface area and terrain conﬁguration (e.g., slope and aspect) may help to develop an optimal
resource management strategy. For example, crops located at a higher elevation within an irrigation
zone may experience a level of water stress due to the gravitational ﬂow of irrigated water.
Using the structural measurements, such as the canopy height, canopy size, the envelope of each
row, LAI, and porosity, among others, the water demand of the crop may be estimated. Generally,
larger canopies tend to require more water than smaller canopies with less leaf area [116,157]. Using
the temporal measurement of the plant’s 3D attributes, the vigour can be computed. Monitoring
crop vigour over the season and over subsequent years can provide an indication of its health and
performance, e.g., yield, within an irrigation zone. Canopy structure metrics are closely related to
horticultural tree growth and provide strong indicators of water consumption, whereby canopy size
Agronomy 2020, 10, 140
16 of 35
can be used to determine its water requirements [234]. Other 3D attributes, such as the crown perimeter,
width, height, area, and leaf density, have been shown to enable improved pruning of horticultural
plants [116,119].
LAI can be estimated using the 3D attributes obtained from remote sensing [114,157,201], whereby,
higher LAI is equivalent to more leaf layers, implying greater total leaf area and, consequently, canopy
transpiration. Leaf density, LAI, and exposed leaf area of a crop drive its water requirement and
productivity [235–237]. Knowledge of ﬁeld attributes, such as row and plant spacing, may assist in
inter-row surface energy balance to determine the irrigation need of the plant [238]. Combining the
structural properties with spectral VIs provide an estimation of biomass [239], which can serve as
another indicator of the plant’s water requirements. Although physiological attributes have been used
to understand plant water status and its spatial variability, they have not been directly applied to make
quantitative decisions on irrigation.
4.4.6. Evapotranspiration
The estimation of ET via remote sensing, numerical modelling, and empirical methods have been
extensively studied and reviewed in the literature [240–247]. These models are based on either surface
energy balance (SEB), Penman-Monteith (PM), Maximum entropy production (MEP), water balance,
water-carbon linkage, or empirical relationships.
SEB models are based on a surface energy budget in which the latent heat ﬂux is estimated as a
residual of the net radiation, soil heat ﬂux, and sensible heat ﬂux. The models are either one-source
(canopy and soil treated as a single surface for the estimation of sensible heat ﬂux) or two-source
(canopy and soil surfaces treated separately). Improvements over the original one-source SEB models
were in the form of Surface Energy Balance Algorithm for Land (SEBAL) algorithm [248,249] and
Mapping EvapoTranspiration with high Resolution and Internalized Calibration (METRIC) [249,250].
SEBAL oﬀers a simpliﬁed approach to collect ET data at both local and regional scales thereby increasing
the spatial scope, while METRIC uses the same (SEBAL) technique but auto-calibrates the model using
hourly ground-based reference ET (ETr) data [251]. As such, these and other (e.g., MEP) models rely
on accurate measurements of surface (e.g., canopy) and air temperatures, which can be erroneous
under non-ideal conditions, e.g., cloudy days. There is also a reliance on ground-based sensors to
capture ambient air temperatures required by the model.
Among the existing methods, FAO’s PM is the most widely adopted model to estimate reference
ET (ETref or ET0) [252]. The PM method uses incident and reﬂected solar radiation, emitted thermal
radiation, air temperature, wind speed, and vapour pressure to calculate ET0 [253]. Remote sensing
provides a cost-eﬀective method to estimate the ET0 at regional to global scales [241] by estimating
reﬂected solar and emitted thermal radiation. One of the advantages of using the PM approach is
that it is parametrised using micrometeorological data easily obtained from ground-based automatic
weather stations. However, PM suﬀers from the drawback that canopy transpiration is not dynamic
as inﬂuenced by soil moisture availability via stomatal regulation [241]. From a practical standpoint,
PM-derived ET0 estimates are used in conjunction with crop factors or crop coeﬃcients (kc), which are
closely related to the light interception of the canopy [254].
Crop evapotranspiration (ETc) is deﬁned as the product of kc and ET0. In the absence of accurate
ETc measurements, kc is an easy and practical means of getting reliable estimates of ETc using ET0 [255].
In this regard, studies have focused on the use of remote sensing to study spatial variability in kc and
ETc [101,256–258]. Thermal and NIR imagery can be used to compute kc and ETc as transpiration
rate is closely related to canopy temperature [259–261] and kc has been shown to correlate with
canopy reﬂectance [101,255]. Various thermal indices, such as CWSI, canopy temperature ratio, canopy
temperature above non-stressed, and canopy temperature above canopy threshold, can be used to
estimate ETc, where CWSI- based ETc was found to be the most accurate [24].
ET at a larger scale is typically estimated based on satellite remote sensing. The temporal resolution
of satellites is, however, low and inadequate for horticultural applications, such as irrigation scheduling
Agronomy 2020, 10, 140
17 of 35
(e.g., Landsat has a 16-day revisit cycle). In contrast, high temporal resolution satellites are coarse in
spatial resolution for ﬁeld-scale observations [25]. The daily or even instantaneous estimation of ETc at
the ﬁeld scale is crucial for irrigation scheduling and is expected to have great application prospects
in the future [240,259,262,263]. In this regard, the future direction of satellite-based ET estimates
may focus on temporal downscaling either by extrapolation of instantaneous measurement [264],
interpolation between two successive observations [201], data fusion of multiple satellites [25,260], and
spatial downscaling using multiple satellites [265–268]. An example of early satellite-based remote
sensing for ET is the MODIS Global Evapotranspiration Project (MOD16), which was established in
1999 to provide daily estimates of global terrestrial evapotranspiration using data acquired from a
pair of NASA satellites in conjunction with Algorithm Theoretical Based Documents (ATBDs) [269].
These estimates correlated well with ground-based eddy covariance ﬂux tower estimates of ET despite
diﬀerences in the uncertainties associated with each of these techniques.
UASs are being increasingly utilised to acquire multi-spectral and thermal imagery to compute
ET at an unprecedented spatial resolution [270,271]. Using high-resolution images, ﬁltering the
shadowed-pixel is possible, which showed signiﬁcant improvement in the estimation of ET in
grapevine [101]. Using high-resolution thermal and/or multispectral imagery, ET has been derived for
horticultural crops, such as grapevines [270] and olives [271]. The seasonal monitoring of ETc at high
spatial and temporal resolutions is of high importance for precision irrigation of horticultural crops in
the future [259].
5. Case Studies on the Use of Remote Sensing for Crop Water Stress Detection
The increasing prevalence of UAS along with low-cost camera systems has brought about much
interest in the characterisation of crop water status/stress during the growing season to inform orchard
or farm management decisions, in particular, irrigation scheduling [272,273]. Traditional methodologies
to assess crop water stress are constrained by limitations relating to large farm sizes and accompanying
spatial variability, high labour costs to collect data, and access to instrumentation that is both inexpensive
and portable [272]. The beneﬁts of precision agriculture [274], including through precision irrigation
practices [1], result in higher production eﬃciencies and economic returns through site-speciﬁc crop
management [275,276]. This approach has motivated the use of high-resolution imagery acquired
from remote sensing to identify irrigation zones [99,277]. The ﬁrst horticultural applications of UAS
platforms for crop water status measurement were in orange and peach orchards where both thermal
and multispectral-derived VIs, speciﬁcally the PRI, were shown to be well-correlated to crop water
status [102]. Here, we explore the use of remote sensing and accompanying image acquisition platforms
to characterise the spatial and temporal patterns of the water status of two economically important
horticultural crops, grapevine and almond.
5.1. Grapevine (Vitis spp.)
The characterisation of spatial variability in vine water status in a vineyard provides valuable
guidance on irrigation scheduling decisions [82], and this spatial variability can be eﬃciently
characterised by the use of remote sensing platforms [29]. The ﬁrst use of remote sensing in vineyards
for crop water stress detection was using manned aircraft ﬂown over an irrigated vineyard in Hanwood
(NSW) Australia where CWSI was mapped at a spatial resolution of 10 cm [278]. Subsequently, UAS
platforms began to be used in vineyards for vine water stress characterisation. Early work in this
crop used a fuel-based helicopter with a 29 cc engine and equipped with thermal (Thermovision
A40M) and multispectral (Tetracam MCA-6) camera systems [102]. The study observed strong (inverse)
relationships between (Tc − Ta) and gs. A related study showed strong correlations between thermal
and multispectral VIs, and traditional, ground-based measures of water status, such as Ψleaf and
gs [182]. In this study, normalised PRI was shown to have correlation coeﬃcients exceeding 0.8 versus
both Ψleaf and gs, indicating that remotely-sensed VIs can be reliable indicators of vine water status.
Thermal indices, such as (Tc − Ta) and CWSI, were also well-correlated to Ψleaf and gs at speciﬁc times of
Agronomy 2020, 10, 140
18 of 35
the day. The use of thermal indices, such as CWSI or Ig, requires reference temperatures (Twet, Tdry) or
non-water stressed baselines (NWSB) [279]. Due to the diﬃculty of obtaining reference temperatures or
NWSB using remote sensing, some authors have used the minimum temperature found from all canopy
pixels as Twet [199], and Ta + 5 ◦C as Tdry [213,280]. NWSB is typically obtained from well-watered
canopies, measuring (Tc − Ta) under a range of vapour pressure deﬁcit conditions [279]. Thermal water
stress indices have also shown to be useful to distinguish between water use strategies of diﬀerent
grapevine cultivars [83,281], which is useful for customising irrigation scheduling based on the speciﬁc
water needs of a given cultivar. More recently, studies have used UAS-based multispectral-based
VIs to train an artiﬁcial neural network (ANN) models to predict spatial patterns of Ψstem [84,282].
Using UAS-based multispectral data, the authors showed that ANN estimated Ψstem with higher
accuracy (RMSE lower than 0.15 MPa) as compared to the conventional multispectral indices based
estimation (RMSE over 0.32 MPa).
5.2. Almond (Prunus Dulcis)
Almonds are perennial nut trees grown in semi-arid climates and are reliant on irrigation
applications. Their water requirements are relatively high, with seasonal ETc exceeding 1000 mm [283].
The requirement for prudent irrigation management in the face of decreased water availability is
critical for maintaining tree productivity, yield, and nut quality [284]. Towards this goal, UAS-based
remote sensing has been used to characterise the spatial patterns of tree water status in almond
orchards. A UAS-based thermal camera was used to acquire tree the crown temperature data from
a California almond orchard; this temperature was used to determine the temperature diﬀerence
between crown and air (Tc − Ta) and compared to shaded leaf water potential (Ψsl) [92]. The study
found a strong negative correlation (R2 = 0.72) between (Tc − Ta) and Ψsl. The same authors conducted
a follow on study in Spain on several fruit tree species including almond. The negative relationship
(slope and oﬀset) between (Tc − Ta) and Ψstem was observed to vary based on the time of observation;
morning measurements had weak relationships, whereas afternoon measurements had stronger
relationships [99]. Their proposed methodology allowed for the spatial characterisation of orchard
water status on a single-tree basis, demonstrating the utility of UAS-based crop water stress data.
Beyond the characterisation of crop water stress for irrigation scheduling, there is an opportunity to
use this data to quantify the economic impact at a spatial level.
6. Future Prospective and Gaps in the Knowledge
Precision irrigation is a promising approach to increase farm water use eﬃciency for sustainable
production, including for horticultural crops [3,5,9,10,274,285]. It is envisioned that the future of
precision irrigation will incorporate UAS, manned aircraft, and satellite-based remote sensing platforms
alongside ground-based proximal sensors coupled with wireless sensor networks. The automation
of UAS technology will continue to develop further to a point that even novice users can adopt
the technology with ease. It is also expected that the data processing pipeline of remote sensing
images will become automated to be ‘ﬁt for purpose’ for crop water status measurements. The ideal
solution may lie in the use of satellites (or sometimes manned aircraft) for regional estimation and
planning [55,260], UAS for seasonal monitoring and zoning [32,100,197,286], proximal sensors for
continuous measurement [287], and artiﬁcial intelligence to derive decision-ready products [84,282]
that can be used for making irrigation scheduling decisions [31,288–295]. Continued technological
developments in this space will enable growers to acquire actionable data with ease, and eventually
transition towards semi-automated or fully-automated irrigation applications.
Remote sensing and current irrigation application technologies are limited in temporal and
spatial resolution, respectively. Although UAS technology can deliver sub-plant level spatially explicit
information of water status, the size of the management block is much coarser, typically over 10 m.
Hence, further improvements in variable rate application technologies, e.g., boom sprayers, or zoned
drip irrigation, are required to fully exploit high-resolution UAS measurements. Nonetheless, the
Agronomy 2020, 10, 140
19 of 35
required resolution of remote sensing should be guided by the underlying spatial variability of the crop.
For ﬁelds with relatively lower spatial variability, low/medium-resolution remote sensing imagery
may suﬃce for crop water status assessment [278,296,297].
Remote sensing provides an indirect estimate of plant water status using the regression-based
approach through several calculated reﬂectance indices. In comparison, physical and mechanistic
models, e.g., radiative transfer models and energy balance models, incorporate both direct and indirect
measures of the canopy, therefore establishing a basis for diﬀerences in plant water status. Using a
similar approach, predictions of crop water status using regression-based remote sensing models can
be improved by incorporating some direct auxiliary variables.
Further developments in thermal remote sensing are also expected, speciﬁcally, the advent of new
thermal and hybrid thermal-multispectral water status/stress indices that are more sensitive to canopy
transpiration. The most widely-adopted thermal index, CWSI, is an instantaneous measure that is
normalised to local weather conditions and inﬂuenced by genotype and phenotype. For example,
the relationship between CWSI and crop water status is inﬂuenced by environmental conditions
(e.g., high incident radiation and low humidity vs low incident radiation and high humidity) and
phenological stage [197,214,298]. As a result, corresponding ground-based measurements are required
for each temporal remote measurement to determine the correlation with water status. Hence, temporal
assessments of water status using thermal cameras will require the incorporation of meteorological
data along with the thermal response using novel indices.
In the area of satellite remote sensing, we foresee further developments on temporal downscaling
to achieve daily measurements. A higher temporal resolution may be achieved by fusion of multiple
satellite observations, such as freely available Landsat and Sentinel. Further reductions of temporal
resolution will require interpolation between two successive observations. Furthermore, temporal
models of water status could be developed to assist the interpolation to eventually satisfy the
requirements for irrigation scheduling [25,201,263]. The continued advancement and greater availability
of Nanosat/Cubesat may provide an alternate method to capture high-resolution data at a higher
a greater temporal resolution, which can be suitable to study the water status of horticultural
crops [299–301].
Crop water status is a complex phenomenon, which can be interpreted with respect to a
number of variables. These variables can include spectral response, thermal response, meteorological
data, 3D attributes of the canopy, and macrostructure of the block (farm).
Clearly, there is
an opportunity for a multi-disciplinary approach, potentially incorporating artiﬁcial intelligence
techniques which incorporate the aforementioned variables to provide a robust estimation of crop
water status [84,141,282,302,303]. Furthermore, with machine learning algorithms, hyperspectral
remote sensing will provide a wealth of data to estimate crop water status. A quantitative product,
such as SIF, derived from hyperspectral data will have the potential for direct quantiﬁcation of water
stress [204,205,304]. In this regard, the upcoming FLEX satellite mission [305,306] and recent advances
in aerial spectroradiometry [109,132,137,307–310] dedicated for observation of SIF may be unique and
powerful tools for high-value horticultural crops.
Multi-temporal images represent an excellent resource for seasonal monitoring of changes in crop
water status. Five to six temporal points of data acquisition at critical phenological stages of crop
development have been recommended for irrigation scheduling [31,32]. However, for semi-arid or arid
regions, irrigation is typically required multiple times per week. Acquisition and post-processing of
remote sensing data for actionable products multiple times a week is currently logistically unfeasible.
The fusion of UAS-based remote sensing data, continuous ground-based proximal or direct sensors,
including weather station data, can potentially inform daily estimates of water status at canopy level.
This approach will require predictive models, such as those based on machine learning algorithms, to
estimate the current and future water status of the crop. Eventually, growers would beneﬁt from the
knowledge of crop water requirements for the determination of seasonal irrigation requirements to
sustainably farm into the future.
Agronomy 2020, 10, 140
20 of 35
One vision for the future of precision irrigation is in automated pipelines to explicitly manage
irrigation water at the sub-block level. This automated pipeline would likely include remote and
proximal data acquisition and processing, prediction and interpretation of crop water status and
requirements, and subsequently, control of irrigation systems. Recent rapid developments in cloud
computing and wireless technology could assist in the quasi-real-time processing of the remote sensing
data soon after acquisition [311–313]. Eventually, automation and computational power will merge to
develop smart technology in which artiﬁcial intelligence uses real-time data analysis for diagnosis
and decision-making. Growers of the future will be able to take advantage of precise irrigation
recommendations using information sourced from a ﬂeet of UAS that map large farm blocks on a daily
schedule, continuous ground-based proximal and direct sensors, and weather stations. This data can be
stored on and accessed from the cloud almost instantaneously, used in conjunction with post-processing
algorithms for decision-making on optimised irrigation applications [311,314].
7. Conclusions
This paper provides a comprehensive review of the use of remote sensing to determine the water
status of horticultural crops. One of our objectives was to survey the range of remote sensing tools
available for irrigation decision-making. Earth observation satellite systems possess the required bands
to study the water status of vegetation and soil. Satellites are more suitable for scouting, planning,
and management of irrigation applications that involve large areas, and where data acquisition is
not time-constrained. Manned aircraft are sparingly used in horticultural applications due to the
cost, logistics, and speciﬁc expertise needed for the operation of the platform. UAS-based remote
sensing provides ﬂexibility in spatial resolution (crop level observation achievable), coverage (over
25 ha achievable in a single ﬂight), spectral bands, as well as temporal revisit. Routine monitoring of
horticultural crops for water status characterisation is, therefore, best performed using a UAS platform.
We envision a future for precision irrigation where satellites are used for planning, and UAS used in
conjunction with a network of ground-based sensors to achieve actionable products on a timely basis.
The plant’s instantaneous response to water stress can be captured using thermal cameras (via
indices, such as CWSI) and potentially narrow-band hyperspectral sensors (via, for example, SIF),
making them suitable to draw quantiﬁable decisions with regard to irrigation scheduling. Broadband
multispectral and RGB cameras capture the non-instantaneous water status of crops, making them
suitable for general assessment of crop water status. Integrated use of thermal and multispectral
imagery may be the simplest yet eﬀective sensor combinations to capture the overall as well as
instantaneous water status of the plant. With regard to irrigation scheduling, further developments
are required to establish crop-speciﬁc thresholds of remotely-sensed indices to decide when and how
much to irrigate.
Author Contributions: Performed the article review and prepared the original draft, D.G.; contributed to write
the case studies, V.P., and together with D.G. contributed to review and edit the manuscript. All authors have read
and agreed to the published version of the manuscript.
Funding: This research and the APC was funded by Wine Australia (Grant number: UA 1803-1.3).
Acknowledgments: The authors would like to acknowledge the funding body Wine Australia, The University of
Adelaide, and anonymous reviewers for their contribution.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Monaghan, J.M.; Daccache, A.; Vickers, L.H.; Hess, T.M.; Weatherhead, E.K.; Grove, I.G.; Knox, J.W. More
‘crop per drop’: constraints and opportunities for precision irrigation in European agriculture. J. Sci.
Food Agric. 2013, 93, 977–980. [CrossRef]
2.
Smith, R. Review of Precision Irrigation Technologies and Their Applications; University of Southern Queensland
Darling Heights: Queensland, Australia, 2011.
Agronomy 2020, 10, 140
21 of 35
3.
Piao, S.; Ciais, P.; Huang, Y.; Shen, Z.; Peng, S.; Li, J.; Zhou, L.; Liu, H.; Ma, Y.; Ding, Y.; et al. The impacts of
climate change on water resources and agriculture in China. Nature 2010, 467, 43. [CrossRef]
4.
Howden, S.M.; Soussana, J.-F.; Tubiello, F.N.; Chhetri, N.; Dunlop, M.; Meinke, H. Adapting agriculture to
climate change. Proc. Natl. Acad. Sci. USA 2007, 104, 19691–19696. [CrossRef]
5.
Webb, L.; Whiting, J.; Watt, A.; Hill, T.; Wigg, F.; Dunn, G.; Needs, S.; Barlow, E. Managing grapevines through
severe heat: A survey of growers after the 2009 summer heatwave in south-eastern Australia. J. Wine Res.
2010, 21, 147–165. [CrossRef]
6.
Datta, S. Impact of climate change in Indian horticulture-a review. Int. J. Sci. Environ. Technol. 2013, 2,
661–671.
7.
Webb, L.; Whetton, P.; Barlow, E. Modelled impact of future climate change on the phenology of winegrapes
in Australia. Aust. J. Grape Wine Res. 2007, 13, 165–175. [CrossRef]
8.
Wang, J.; Mendelsohn, R.; Dinar, A.; Huang, J.; Rozelle, S.; Zhang, L. The impact of climate change on China’s
agriculture. Agric. Econ. 2009, 40, 323–337. [CrossRef]
9.
Beare, S.; Heaney, A. Climate change and water resources in the Murray Darling Basin, Australia.
In Proceedings of the 2002 World Congress of Environmental and Resource Economists, Monterey, CA, USA,
24–27 June 2002.
10.
Khan, S.; Tariq, R.; Yuanlai, C.; Blackwell, J. Can irrigation be sustainable? Agric. Water Manag. 2006, 80,
87–99. [CrossRef]
11.
Droogers, P.; Bastiaanssen, W. Irrigation performance using hydrological and remote sensing modeling.
J. Irrig. Drain. Eng. 2002, 128, 11–18. [CrossRef]
12.
Ray, S.; Dadhwal, V. Estimation of crop evapotranspiration of irrigation command area using remote sensing
and GIS. Agric. Water Manag. 2001, 49, 239–249. [CrossRef]
13.
Kim, Y.; Evans, R.G.; Iversen, W.M. Remote sensing and control of an irrigation system using a distributed
wireless sensor network. IEEE Trans. Instrum. Meas. 2008, 57, 1379–1387.
14.
Ritchie, G.A.; Hinckley, T.M. The pressure chamber as an instrument for ecological research. In Advances in
Ecological Research; Elsevier: Amsterdam, The Netherlands, 1975; Volume 9, pp. 165–254.
15.
Smart, R.; Barrs, H. The eﬀect of environment and irrigation interval on leaf water potential of four
horticultural species. Agric. Meteorol. 1973, 12, 337–346. [CrossRef]
16.
Meron, M.; Grimes, D.; Phene, C.; Davis, K. Pressure chamber procedures for leaf water potential
measurements of cotton. Irrig. Sci. 1987, 8, 215–222. [CrossRef]
17.
Santos, A.O.; Kaye, O. Grapevine leaf water potential based upon near infrared spectroscopy. Sci. Agric.
2009, 66, 287–292. [CrossRef]
18.
Berni, J.A.J.; Zarco-Tejada, P.J.; Sepulcre-Cantó, G.; Fereres, E.; Villalobos, F. Mapping canopy conductance
and CWSI in olive orchards using high resolution thermal remote sensing imagery. Remote Sens. Environ.
2009, 113, 2380–2388. [CrossRef]
19.
Chaves, M.M.; Santos, T.P.; de Souza, C.; Ortuño, M.; Rodrigues, M.; Lopes, C.; Maroco, J.; Pereira, J.S.
Deﬁcit irrigation in grapevine improves water-use eﬃciency while controlling vigour and production quality.
Ann. Appl. Biol. 2007, 150, 237–252. [CrossRef]
20.
Bravdo, B.; Hepner, Y.; Loinger, C.; Cohen, S.; Tabacman, H. Eﬀect of irrigation and crop level on growth,
yield and wine quality of Cabernet Sauvignon. Am. J. Enol. Vitic. 1985, 36, 132–139.
21.
Matthews, M.; Ishii, R.; Anderson, M.; O’Mahony, M. Dependence of wine sensory attributes on vine water
status. J. Sci. Food Agric. 1990, 51, 321–335. [CrossRef]
22.
Reynolds, A.G.; Naylor, A.P. ‘Pinot noir’ and ‘Riesling’ grapevines respond to water stress duration and soil
water-holding capacity. HortScience 1994, 29, 1505–1510. [CrossRef]
23.
Alvino, A.; Marino, S. Remote sensing for irrigation of horticultural crops. Horticulturae 2017, 3, 40. [CrossRef]
24.
Kullberg, E.G.; DeJonge, K.C.; Chávez, J.L. Evaluation of thermal remote sensing indices to estimate crop
evapotranspiration coeﬃcients. Agric. Water Manag. 2017, 179, 64–73. [CrossRef]
25.
Semmens, K.A.; Anderson, M.C.; Kustas, W.P.; Gao, F.; Alﬁeri, J.G.; McKee, L.; Prueger, J.H.; Hain, C.R.;
Cammalleri, C.; Yang, Y.; et al. Monitoring daily evapotranspiration over two California vineyards using
Landsat 8 in a multi-sensor data fusion approach. Remote Sens. Environ. 2015, 185, 155–170. [CrossRef]
26.
Jackson, R.D. Remote sensing of biotic and abiotic plant stress. Annu. Rev. Phytopathol. 1986, 24, 265–287.
[CrossRef]
Agronomy 2020, 10, 140
22 of 35
27.
Moran, M.; Clarke, T.; Inoue, Y.; Vidal, A. Estimating crop water deﬁcit using the relation between surface-air
temperature and spectral vegetation index. Remote Sens. Environ. 1994, 49, 246–263. [CrossRef]
28.
Lamb, D.; Hall, A.; Louis, J. Airborne remote sensing of vines for canopy variability and productivity.
Aust. Grapegrow. Winemak. 2001, 449a, 89–94.
29.
Hall, A.; Lamb, D.; Holzapfel, B.; Louis, J. Optical remote sensing applications in viticulture-a review. Aust. J.
Grape Wine Res. 2002, 8, 36–47. [CrossRef]
30.
De Bei, R.; Cozzolino, D.; Sullivan, W.; Cynkar, W.; Fuentes, S.; Dambergs, R.; Pech, J.; Tyerman, S.
Non-destructive measurement of grapevine water potential using near infrared spectroscopy. Aust. J. Grape
Wine Res. 2011, 17, 62–71. [CrossRef]
31.
Bellvert, J.; Zarco-Tejada, P.J.; Marsal, J.; Girona, J.; González-Dugo, V.; Fereres, E. Vineyard irrigation
scheduling based on airborne thermal imagery and water potential thresholds. Aust. J. Grape Wine Res. 2016,
22, 307–315. [CrossRef]
32.
Bellvert, J.; Marsal, J.; Girona, J.; Gonzalez-Dugo, V.; Fereres, E.; Ustin, S.; Zarco-Tejada, P. Airborne thermal
imagery to detect the seasonal evolution of crop water status in peach, nectarine and Saturn peach orchards.
Remote Sens. 2016, 8, 39. [CrossRef]
33.
Park, S.; Ryu, D.; Fuentes, S.; Chung, H.; Hernández-Montes, E.; O’Connell, M. Adaptive estimation of crop
water stress in nectarine and peach orchards using high-resolution imagery from an unmanned aerial vehicle
(UAV). Remote Sens. 2017, 9, 828. [CrossRef]
34.
Espinoza, C.Z.; Khot, L.R.; Sankaran, S.; Jacoby, P.W. High resolution multispectral and thermal remote
sensing-based water stress assessment in subsurface irrigated grapevines. Remote Sens. 2017, 9, 961.
[CrossRef]
35.
Ezenne, G.I.; Jupp, L.; Mantel, S.K.; Tanner, J.L. Current and potential capabilities of UAS for crop water
productivity in precision agriculture. Agric. Water Manag. 2019, 218, 158–164. [CrossRef]
36.
Oliver, M.A.; Webster, R. Kriging: A method of interpolation for geographical information systems. Int. J.
Geogr. Inf. Syst. 1990, 4, 313–332. [CrossRef]
37.
Ha, W.; Gowda, P.H.; Howell, T.A. A review of downscaling methods for remote sensing-based irrigation
management: Part I. Irrig. Sci. 2013, 31, 831–850. [CrossRef]
38.
Ha, W.; Gowda, P.H.; Howell, T.A. A review of potential image fusion methods for remote sensing-based
irrigation management: Part II. Irrig. Sci. 2013, 31, 851–869. [CrossRef]
39.
Belward, A.S.; Skøien, J.O. Who launched what, when and why; trends in global land-cover observation
capacity from civilian earth observation satellites. ISPRS J. Photogramm. Remote Sens. 2015, 103, 115–128.
[CrossRef]
40.
Lucieer, A.; Malenovskỳ, Z.; Veness, T.; Wallace, L. HyperUAS—Imaging spectroscopy from a multirotor
unmanned aircraft system. J. Field Robot. 2014, 31, 571–590. [CrossRef]
41.
McCabe, M.F.; Rodell, M.; Alsdorf, D.E.; Miralles, D.G.; Uijlenhoet, R.; Wagner, W.; Lucieer, A.; Houborg, R.;
Verhoest, N.E.; Franz, T.E.; et al. The future of Earth observation in hydrology. Hydrol. Earth Syst. Sci. 2017,
21, 3879. [CrossRef]
42.
Matese, A.; Toscano, P.; Di Gennaro, S.; Genesio, L.; Vaccari, F.; Primicerio, J.; Belli, C.; Zaldei, A.; Bianconi, R.;
Gioli, B. Intercomparison of UAV, aircraft and satellite remote sensing platforms for precision viticulture.
Remote Sens. 2015, 7, 2971–2990. [CrossRef]
43.
Mancini, A.; Frontoni, E.; Zingaretti, P. Satellite and UAV data for Precision Agriculture Applications.
In Proceedings of the 2019 International Conference on Unmanned Aircraft Systems (ICUAS 2019), Atlanta,
GA, USA, 11–14 June 2019; pp. 491–497.
44.
Diago, M.P.; Bellincontro, A.; Scheidweiler, M.; Tardáguila, J.; Tittmann, S.; Stoll, M. Future opportunities
of proximal near infrared spectroscopy approaches to determine the variability of vineyard water status.
Aust. J. Grape Wine Res. 2017, 23, 409–414. [CrossRef]
45.
Gutierrez, S.; Diago, M.P.; Fernández-Novales, J.; Tardaguila, J. Vineyard water status assessment using
on-the-go thermal imaging and machine learning. PLoS ONE 2018, 13, e0192037. [CrossRef] [PubMed]
46.
Fernández-Novales, J.; Tardaguila, J.; Gutiérrez, S.; Marañón, M.; Diago, M.P. In ﬁeld quantiﬁcation and
discrimination of diﬀerent vineyard water regimes by on-the-go NIR spectroscopy. Biosyst. Eng. 2018, 165,
47–58. [CrossRef]
Agronomy 2020, 10, 140
23 of 35
47.
Diago, M.P.; Fernández-Novales, J.; Gutiérrez, S.; Marañón, M.; Tardaguila, J. Development and validation of a
new methodology to assess the vineyard water status by on-the-go near infrared spectroscopy. Front. Plant Sci.
2018, 9, 59. [CrossRef]
48.
Aquino, A.; Millan, B.; Diago, M.-P.; Tardaguila, J. Automated early yield prediction in vineyards from
on-the-go image acquisition. Comput. Electron. Agric. 2018, 144, 26–36. [CrossRef]
49.
Markham, B.L.; Helder, D.L. Forty-year calibrated record of earth-reﬂected radiance from Landsat: A review.
Remote Sens. Environ. 2012, 122, 30–40. [CrossRef]
50.
Toth, C.; Jó´zków, G. Remote sensing platforms and sensors: A survey. ISPRS J. Photogramm. Remote Sens.
2016, 115, 22–36. [CrossRef]
51.
Tyc, G.; Tulip, J.; Schulten, D.; Krischke, M.; Oxfort, M. The RapidEye mission design. Acta Astronaut. 2005,
56, 213–219. [CrossRef]
52.
Sweeting, M.N. Modern small satellites-changing the economics of space. Proc. IEEE 2018, 106, 343–361.
[CrossRef]
53.
Khanal, S.; Fulton, J.; Shearer, S. An overview of current and potential applications of thermal remote sensing
in precision agriculture. Comput. Electron. Agric. 2017, 139, 22–32. [CrossRef]
54.
Gerhards, M.;
Schlerf, M.;
Mallick, K.;
Udelhoven, T. Challenges and Future Perspectives of
Multi-/Hyperspectral Thermal Infrared Remote Sensing for Crop Water-Stress Detection: A Review.
Remote Sens. 2019, 11, 1240. [CrossRef]
55.
Ryan, S.; Lewis, M. Mapping soils using high resolution airborne imagery, Barossa Valley, SA. In Proceedings
of the Inaugural Australian Geospatial Information and Agriculture Conference Incorporating Precision
Agriculture in Australasia 5th Annual Symposium, Orange, NSW, Australia, 17–19 July 2001.
56.
Khaliq, A.; Comba, L.; Biglia, A.; Ricauda Aimonino, D.; Chiaberge, M.; Gay, P. Comparison of satellite and
UAV-based multispectral imagery for vineyard variability assessment. Remote Sens. 2019, 11, 436. [CrossRef]
57.
Jones, H.G.; Vaughan, R.A. Remote Sensing of Vegetation: Principles, Techniques, and Applications; Oxford
University Press: Oxford, UK, 2010.
58.
Thenkabail, P.S.; Lyon, J.G. Hyperspectral Remote Sensing of Vegetation; CRC Press: Boco Raton, FL, USA, 2016.
59.
King, M.D.; Platnick, S.; Menzel, W.P.; Ackerman, S.A.; Hubanks, P.A. Spatial and temporal distribution of
clouds observed by MODIS onboard the Terra and Aqua satellites. IEEE Trans. Geosci. Remote Sens. 2013, 51,
3826–3852. [CrossRef]
60.
Chen, X.; Liu, M.; Zhu, X.; Chen, J.; Zhong, Y.; Cao, X. “Blend-then-Index” or “Index-then-Blend”:
A Theoretical Analysis for Generating High-resolution NDVI Time Series by STARFM. Photogramm. Eng.
Remote Sens. 2018, 84, 65–73. [CrossRef]
61.
Yin, T.; Inglada, J.; Osman, J. Time series image fusion: Application and improvement of STARFM for land
cover map and production. In Proceedings of the 2012 IEEE International Geoscience and Remote Sensing
Symposium, Munich, Germany, 22–27 July 2012; pp. 378–381.
62.
Gevaert, C.M.; García-Haro, F.J. A comparison of STARFM and an unmixing-based algorithm for Landsat
and MODIS data fusion. Remote Sens. Environ. 2015, 156, 34–44. [CrossRef]
63.
Li, L.; Wang, X.; Li, M. Study on the fusion of MODIS and TM images using the spectral response function
and STARFM algorithm. In Proceedings of the 2011 International Conference on Image Analysis and Signal
Processing, Wuhan, China, 21–23 October 2011; pp. 171–176.
64.
Pagay, V.; Kidman, C.M. Evaluating Remotely-Sensed Grapevine (Vitis vinifera L.) Water Stress Responses
Across a Viticultural Region. Agronomy 2019, 9, 682. [CrossRef]
65.
Rascher, U.; Alonso, L.; Burkart, A.; Cilia, C.; Cogliati, S.; Colombo, R.; Damm, A.; Drusch, M.; Guanter, L.;
Hanus, J.; et al. Sun-induced ﬂuorescence—A new probe of photosynthesis: First maps from the imaging
spectrometer HyPlant. Glob. Chang. Biol. 2015, 21, 4673–4684. [CrossRef]
66.
Buckley, S.; Vallet, J.; Braathen, A.; Wheeler, W. Oblique helicopter-based laser scanning for digital terrain
modelling and visualisation of geological outcrops. Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2008,
37, 1–6.
67.
Pullanagari, R.; Kereszturi, G.; Yule, I. Mapping of macro and micro nutrients of mixed pastures using
airborne AisaFENIX hyperspectral imagery. ISPRS J. Photogramm. Remote Sens. 2016, 117, 1–10. [CrossRef]
68.
Haboudane, D.; Miller, J.R.; Tremblay, N.; Zarco-Tejada, P.J.; Dextraze, L. Integrated narrow-band vegetation
indices for prediction of crop chlorophyll content for application to precision agriculture. Remote Sens.
Environ. 2002, 81, 416–426. [CrossRef]
Agronomy 2020, 10, 140
24 of 35
69.
Miao, Y.; Mulla, D.J.; Randall, G.W.; Vetsch, J.A.; Vintila, R. Predicting chlorophyll meter readings with aerial
hyperspectral remote sensing for in-season site-speciﬁc nitrogen management of corn. Precis. Agric. 2007, 7,
635–641.
70.
Haboudane, D.; Miller, J.R.; Pattey, E.; Zarco-Tejada, P.J.; Strachan, I.B. Hyperspectral vegetation indices
and novel algorithms for predicting green LAI of crop canopies: Modeling and validation in the context of
precision agriculture. Remote Sens. Environ. 2004, 90, 337–352. [CrossRef]
71.
Sepulcre-Cantó, G.; Zarco-Tejada, P.J.; Jiménez-Muñoz, J.; Sobrino, J.; Soriano, M.; Fereres, E.; Vega, V.;
Pastor, M. Monitoring yield and fruit quality parameters in open-canopy tree crops under water stress.
Implications for ASTER. Remote Sens. Environ. 2007, 107, 455–470. [CrossRef]
72.
Sepulcre-Cantó, G.; Zarco-Tejada, P.J.; Jiménez-Muñoz, J.; Sobrino, J.; De Miguel, E.; Villalobos, F.J. Detection
of water stress in an olive orchard with thermal remote sensing imagery. Agric. For. Meteorol. 2006, 136,
31–44. [CrossRef]
73.
Colomina, I.; Molina, P. Unmanned aerial systems for photogrammetry and remote sensing: A review.
ISPRS J. Photogramm. Remote Sens. 2014, 92, 79–97. [CrossRef]
74.
Zecha, C.; Link, J.; Claupein, W. Mobile sensor platforms: Categorisation and research applications in
precision farming. J. Sens. Sens. Syst. 2013, 2, 51–72. [CrossRef]
75.
Urbahs, A.; Jonaite, I. Features of the use of unmanned aerial vehicles for agriculture applications. Aviation
2013, 17, 170–175. [CrossRef]
76.
Gautam, D.; Ha, C. Control of a quadrotor using a smart self-tuning fuzzy PID controller. Int. J. Adv. Robot.
Syst. 2013, 10, 380. [CrossRef]
77.
Shi, Y.; Thomasson, J.A.; Murray, S.C.; Pugh, N.A.; Rooney, W.L.; Shaﬁan, S.; Rajan, N.; Rouze, G.; Morgan, C.L.;
Neely, H.L.; et al. Unmanned aerial vehicles for high-throughput phenotyping and agronomic research.
PLoS ONE 2016, 11, e0159781. [CrossRef]
78.
Zhang, C.; Kovacs, J.M. The application of small unmanned aerial systems for precision agriculture: a review.
Precis. Agric. 2012, 13, 693–712. [CrossRef]
79.
Mulla, D.J. Twenty ﬁve years of remote sensing in precision agriculture: Key advances and remaining
knowledge gaps. Biosyst. Eng. 2013, 114, 358–371. [CrossRef]
80.
Huang, Y.; Thomson, S.J.; Hoﬀmann, W.C.; Lan, Y.; Fritz, B.K. Development and prospect of unmanned aerial
vehicle technologies for agricultural production management. Int. J. Agric. Biol. Eng. 2013, 6, 1–10.
81.
Zude-Sasse, M.; Fountas, S.; Gemtos, T.A.; Abu-Khalaf, N. Applications of precision agriculture in horticultural
crops. Eur. J. Hortic. Sci. 2016, 81, 78–90. [CrossRef]
82.
Baluja, J.; Diago, M.P.; Balda, P.; Zorer, R.; Meggio, F.; Morales, F.; Tardaguila, J. Assessment of vineyard
water status variability by thermal and multispectral imagery using an unmanned aerial vehicle (UAV).
Irrig. Sci. 2012, 30, 511–522. [CrossRef]
83.
Matese, A.; Baraldi, R.; Berton, A.; Cesaraccio, C.; Di Gennaro, S.F.; Duce, P.; Facini, O.; Mameli, M.G.;
Piga, A.; Zaldei, A. Estimation of water stress in grapevines using proximal and remote sensing methods.
Remote Sens. 2018, 10, 114. [CrossRef]
84.
Poblete, T.; Ortega-Farías, S.; Moreno, M.; Bardeen, M. Artiﬁcial neural network to predict vine water status
spatial variability using multispectral information obtained from an unmanned aerial vehicle (UAV). Sensors
2017, 17, 2488. [CrossRef]
85.
Gonzalez-Dugo, V.; Zarco-Tejada, P.J.; Fereres, E. Applicability and limitations of using the crop water stress
index as an indicator of water deﬁcits in citrus orchards. Agric. For. Meteorol. 2014, 198, 94–104. [CrossRef]
86.
Stagakis, S.; González-Dugo, V.; Cid, P.; Guillén-Climent, M.L.; Zarco-Tejada, P.J. Monitoring water stress
and fruit quality in an orange orchard under regulated deﬁcit irrigation using narrow-band structural and
physiological remote sensing indices. ISPRS J. Photogramm. Remote Sens. 2012, 71, 47–61. [CrossRef]
87.
Agam, N.; Cohen, Y.; Berni, J.A.J.; Alchanatis, V.; Kool, D.; Dag, A.; Yermiyahu, U.; Ben-Gal, A. An insight to
the performance of crop water stress index for olive trees. Agric. Water Manag. 2013, 118, 79–86. [CrossRef]
88.
Poblete-Echeverría, C.; Sepulveda-Reyes, D.; Ortega-Farias, S.; Zuñiga, M.; Fuentes, S. Plant water stress
detection based on aerial and terrestrial infrared thermography: A study case from vineyard and olive
orchard. In Proceedings of the XXIX International Horticultural congress on Horticulture: Sustaining Lives,
Livelihoods and Landscapes (IHC2014): International Symposia on Water, Eco-Eﬃciency and Transformation
of Organic Waste in Horticultural Production, Brisbane, Australia, 25 October 2016; pp. 141–146.
Agronomy 2020, 10, 140
25 of 35
89.
Testi, L.; Goldhamer, D.; Iniesta, F.; Salinas, M. Crop water stress index is a sensitive water stress indicator in
pistachio trees. Irrig. Sci. 2008, 26, 395–405. [CrossRef]
90.
Gonzalez-Dugo, V.; Goldhamer, D.; Zarco-Tejada, P.J.; Fereres, E. Improving the precision of irrigation in a
pistachio farm using an unmanned airborne thermal system. Irrig. Sci. 2015, 33, 43–52. [CrossRef]
91.
García-Tejero, I.F.; Rubio, A.E.; Viñuela, I.; Hernández, A.; Gutiérrez-Gordillo, S.; Rodríguez-Pleguezuelo, C.R.;
Durán-Zuazo, V.H. Thermal imaging at plant level to assess the crop-water status in almond trees (cv. Guara)
under deﬁcit irrigation strategies. Agric. Water Manag. 2018, 208, 176–186. [CrossRef]
92.
Gonzalez-Dugo, V.; Zarco-Tejada, P.; Berni, J.A.; Suárez, L.; Goldhamer, D.; Fereres, E. Almond tree canopy
temperature reveals intra-crown variability that is water stress-dependent. Agric. For. Meteorol. 2012, 154,
156–165. [CrossRef]
93.
Zhao, T.; Stark, B.; Chen, Y.; Ray, A.L.; Doll, D. Challenges in water stress quantiﬁcation using small
unmanned aerial system (sUAS): Lessons from a growing season of almond. J. Intell. Robot. Syst. 2017, 88,
721–735. [CrossRef]
94.
Zhao, T.; Doll, D.; Wang, D.; Chen, Y. A new framework for UAV-based remote sensing data processing and
its application in almond water stress quantiﬁcation. In Proceedings of the 2017 International Conference on
Unmanned Aircraft Systems (ICUAS 2017), Miami, FL, USA, 13–16 June 2017; pp. 1794–1799.
95.
Herwitz, S.; Johnson, L.; Dunagan, S.; Higgins, R.; Sullivan, D.; Zheng, J.; Lobitz, B.; Leung, J.; Gallmeyer, B.;
Aoyagi, M.; et al. Imaging from an unmanned aerial vehicle: agricultural surveillance and decision support.
Comput. Electron. Agric. 2004, 44, 49–61. [CrossRef]
96.
Furfaro, R.; Ganapol, B.D.; Johnson, L.; Herwitz, S. Model-based neural network algorithm for coﬀee ripeness
prediction using Helios UAV aerial images. In Remote Sensing for Agriculture, Ecosystems, and Hydrology VII;
International Society for Optics and Photonics: Bruges, Belgium, 2005; Volume 5976, p. 59760X.
97.
Park, S.; Nolan, A.; Ryu, D.; Fuentes, S.; Hernandez, E.; Chung, H.; O’connell, M. Estimation of crop
water stress in a nectarine orchard using high-resolution imagery from unmanned aerial vehicle (UAV).
In Proceedings of the 21st International Congress on Modelling and Simulation, Gold Coast, QLD, Australia,
29 November–4 December 2015; pp. 1413–1419.
98.
Bulanon, D.M.; Lonai, J.; Skovgard, H.; Fallahi, E. Evaluation of diﬀerent irrigation methods for an apple
orchard using an aerial imaging system. ISPRS Int. J. Geo-Inf. 2016, 5, 79.
99.
Gonzalez-Dugo, V.; Zarco-Tejada, P.; Nicolás, E.; Nortes, P.A.; Alarcón, J.; Intrigliolo, D.S.; Fereres, E. Using
high resolution UAV thermal imagery to assess the variability in the water status of ﬁve fruit tree species
within a commercial orchard. Precis. Agric. 2013, 14, 660–678. [CrossRef]
100. Santesteban, L.G.; Di Gennaro, S.F.; Herrero-Langreo, A.; Miranda, C.; Royo, J.B.; Matese, A. High-resolution
UAV-based thermal imaging to estimate the instantaneous and seasonal variability of plant water status
within a vineyard. Agric. Water Manag. 2017, 183, 49–59. [CrossRef]
101. Aboutalebi, M.; Torres-Rua, A.F.; Kustas, W.P.; Nieto, H.; Coopmans, C.; McKee, M. Assessment of diﬀerent
methods for shadow detection in high-resolution optical imagery and evaluation of shadow impact on
calculation of NDVI, and evapotranspiration. Irrig. Sci. 2018, 1, 1–23. [CrossRef]
102. Berni, J.A.; Zarco-Tejada, P.J.; Suárez, L.; Fereres, E. Thermal and narrowband multispectral remote sensing
for vegetation monitoring from an unmanned aerial vehicle. IEEE Trans. Geosci. Remote Sens. 2009, 47,
722–738. [CrossRef]
103. Candiago, S.; Remondino, F.; De Giglio, M.; Dubbini, M.; Gattelli, M. Evaluating multispectral images and
vegetation indices for precision farming applications from UAV images. Remote Sens. 2015, 7, 4026–4047.
[CrossRef]
104. Thomasson, J.A.; Shi, Y.; Olsenholler, J.; Valasek, J.; Murray, S.C.; Bishop, M.P. Comprehensive UAV
agricultural remote-sensing research at Texas AM University. In Autonomous Air and Ground Sensing Systems
for Agricultural Optimization and Phenotyping; International Society for Optics and Photonics: Baltimore, MD,
USA, 2016; Volume 9866, p. 986602.
105. Turner, D.; Lucieer, A.; Wallace, L. Direct georeferencing of ultrahigh-resolution UAV imagery. IEEE Trans.
Geosci. Remote Sens. 2014, 52, 2738–2745. [CrossRef]
106. Primicerio, J.; Di Gennaro, S.F.; Fiorillo, E.; Genesio, L.; Lugato, E.; Matese, A.; Vaccari, F.P. A ﬂexible
unmanned aerial vehicle for precision agriculture. Precis. Agric. 2012, 13, 517–523. [CrossRef]
107. Pajares, G. Overview and current status of remote sensing applications based on unmanned aerial vehicles
(UAVs). Photogramm. Eng. Remote Sens. 2015, 81, 281–330. [CrossRef]
Agronomy 2020, 10, 140
26 of 35
108. Di Gennaro, S.F.; Matese, A.; Gioli, B.; Toscano, P.; Zaldei, A.; Palliotti, A.; Genesio, L. Multisensor approach
to assess vineyard thermal dynamics combining high-resolution unmanned aerial vehicle (UAV) remote
sensing and wireless sensor network (WSN) proximal sensing. Sci. Hortic. 2017, 221, 83–87. [CrossRef]
109. Cendrero-Mateo, M.P.; Wieneke, S.; Damm, A.; Alonso, L.; Pinto, F.; Moreno, J.; Guanter, L.; Celesti, M.;
Rossini, M.; Sabater, N.; et al. Sun-induced chlorophyll ﬂuorescence III: Benchmarking retrieval methods
and sensor characteristics for proximal sensing. Remote Sens. 2019, 11, 962. [CrossRef]
110. Zarco-Tejada, P.J.; González-Dugo, V.; Berni, J.A.J. Fluorescence, temperature and narrow-band indices
acquired from a UAV platform for water stress detection using a micro-hyperspectral imager and a thermal
camera. Remote Sens. Environ. 2012, 117, 322–337. [CrossRef]
111. Harwin, S.; Lucieer, A. Assessing the accuracy of georeferenced point clouds produced via multi-view
stereopsis from Unmanned Aerial Vehicle (UAV) imagery. Remote Sens. 2012, 4, 1573–1599. [CrossRef]
112. Wallace, L.; Lucieer, A.; Malenovskỳ, Z.; Turner, D.; Vopˇenka, P. Assessment of forest structure using two
UAV techniques: A comparison of airborne laser scanning and structure from motion (SfM) point clouds.
Forests 2016, 7, 62. [CrossRef]
113. Weiss, M.; Baret, F. Using 3D point clouds derived from UAV RGB imagery to describe vineyard 3D
macro-structure. Remote Sens. 2017, 9, 111. [CrossRef]
114. Mathews, A.; Jensen, J. Visualizing and quantifying vineyard canopy LAI using an unmanned aerial vehicle
(UAV) collected high density structure from motion point cloud. Remote Sens. 2013, 5, 2164–2183. [CrossRef]
115. Stone, C.; Webster, M.; Osborn, J.; Iqbal, I. Alternatives to LiDAR-derived canopy height models for softwood
plantations: a review and example using photogrammetry. Aust. For. 2016, 79, 271–282. [CrossRef]
116. Wu, D.; Phinn, S.; Johansen, K.; Robson, A.; Muir, J.; Searle, C. Estimating changes in leaf area, leaf area
density, and vertical leaf area proﬁle for mango, avocado, and macadamia tree crowns using terrestrial laser
scanning. Remote Sens. 2018, 10, 1750. [CrossRef]
117. Rosell, J.R.; Llorens, J.; Sanz, R.; Arno, J.; Ribes-Dasi, M.; Masip, J.; Escolà, A.; Camp, F.; Solanelles, F.;
Gràcia, F.; et al. Obtaining the three-dimensional structure of tree orchards from remote 2D terrestrial LIDAR
scanning. Agric. For. Meteorol. 2009, 149, 1505–1515. [CrossRef]
118. Matese, A.; Di Gennaro, S.F. Technology in precision viticulture: A state of the art review. Int. J. Wine Res.
2015, 7, 69–81. [CrossRef]
119. Johansen, K.; Raharjo, T.; McCabe, M.F. Using multi-spectral UAV imagery to extract tree crop structural
properties and assess pruning eﬀects. Remote Sens. 2018, 10, 854. [CrossRef]
120. Tu, Y.-H.; Johansen, K.; Phinn, S.; Robson, A. Measuring canopy structure and condition using multi-spectral
UAS imagery in a horticultural environment. Remote Sens. 2019, 11, 269. [CrossRef]
121. Mu, Y.; Fujii, Y.; Takata, D.; Zheng, B.; Noshita, K.; Honda, K.; Ninomiya, S.; Guo, W. Characterization of
peach tree crown by using high-resolution images from an unmanned aerial vehicle. Hortic. Res. 2018, 5, 74.
[CrossRef]
122. De Castro, A.I.; Jiménez-Brenes, F.M.; Torres-Sánchez, J.; Peña, J.M.; Borra-Serrano, I.; López-Granados, F. 3-D
characterization of vineyards using a novel UAV imagery-based OBIA procedure for precision viticulture
applications. Remote Sens. 2018, 10, 584. [CrossRef]
123. Del Pozo, S.; Rodríguez-Gonzálvez, P.; Hernández-López, D.; Felipe-García, B. Vicarious radiometric
calibration of a multispectral camera on board an unmanned aerial system. Remote Sens. 2014, 6, 1918–1937.
[CrossRef]
124. Tu, Y.-H.; Phinn, S.; Johansen, K.; Robson, A. Assessing radiometric correction approaches for multi-spectral
UAS imagery for horticultural applications. Remote Sens. 2018, 10, 1684. [CrossRef]
125. Stow, D.; Nichol, C.J.; Wade, T.; Assmann, J.J.; Simpson, G.; Helfter, C. Illumination geometry and ﬂying
height inﬂuence surface reﬂectance and NDVI derived from multispectral UAS imagery. Drones 2019, 3, 55.
[CrossRef]
126. Turner, D.; Lucieer, A.; Watson, C. Development of an unmanned aerial vehicle (UAV) for hyper resolution
vineyard mapping based on visible, multispectral, and thermal imagery.
In Proceedings of the 34th
International Symposium on Remote Sensing of Environment, Sydney, Australia, 10–15 April 2011; p. 4.
127. Jorge, J.; Vallbé, M.; Soler, J.A. Detection of irrigation inhomogeneities in an olive grove using the NDRE
vegetation index obtained from UAV images. Eur. J. Remote Sens. 2019, 52, 169–177. [CrossRef]
128. Filella, I.; Penuelas, J. The red edge position and shape as indicators of plant chlorophyll content, biomass
and hydric status. Int. J. Remote Sens. 1994, 15, 1459–1470. [CrossRef]
Agronomy 2020, 10, 140
27 of 35
129. Zúñiga, C.E.; Khot, L.R.; Jacoby, P.; Sankaran, S. Remote sensing based water-use eﬃciency evaluation
in sub-surface irrigated wine grape vines. In Autonomous Air and Ground Sensing Systems for Agricultural
Optimization and Phenotyping; International Society for Optics and Photonics: Baltimore, MD, USA, 2016;
Volume 9866, p. 98660O.
130. Aasen, H.; Honkavaara, E.; Lucieer, A.; Zarco-Tejada, P. Quantitative remote sensing at ultra-high resolution
with uav spectroscopy: A review of sensor technology, measurement procedures, and data correction
workﬂows. Remote Sens. 2018, 10, 1091. [CrossRef]
131. Adão, T.; Hruška, J.; Pádua, L.; Bessa, J.; Peres, E.; Morais, R.; Sousa, J. Hyperspectral imaging: A review on
UAV-based sensors, data processing and applications for agriculture and forestry. Remote Sens. 2017, 9, 1110.
[CrossRef]
132. Gautam, D.; Watson, C.; Lucieer, A.; Malenovský, Z. Error budget for geolocation of spectroradiometer point
observations from an unmanned aircraft system. Sens. Switz. 2018, 18, 3465. [CrossRef] [PubMed]
133. Uto, K.; Seki, H.; Saito, G.; Kosugi, Y.; Komatsu, T. Development of a low-cost hyperspectral whiskbroom
imager using an optical ﬁber bundle, a swing mirror, and compact spectrometers. IEEE J. Sel. Top. Appl.
Earth Obs. Remote Sens. 2016, 9, 3909–3925. [CrossRef]
134. Suomalainen, J.; Anders, N.; Iqbal, S.; Roerink, G.; Franke, J.; Wenting, P.; Hünniger, D.; Bartholomeus, H.;
Becker, R.; Kooistra, L. A lightweight hyperspectral mapping system and photogrammetric processing chain
for unmanned aerial vehicles. Remote Sens. 2014, 6, 11013–11030. [CrossRef]
135. Iseli, C.; Lucieer, A. Tree species classiﬁcation based on 3d spectral point clouds and orthomosaics acquired
by snapshot hyperspectral UAS sensor. ISPRS-Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2019, 4213,
379–384. [CrossRef]
136. Hagen, N.A.; Kudenov, M.W. Review of snapshot spectral imaging technologies. Opt. Eng. 2013, 52, 090901.
[CrossRef]
137. Bendig, J.; Gautam, D.; Malenovsky, Z.; Lucieer, A. Inﬂuence of Cosine Corrector and UAS Platform Dynamics
on Airborne Spectral Irradiance Measurements. In Proceedings of the 2018 IEEE International Geoscience
and Remote Sensing Symposium (IGARSS 2018), Valencia, Spain, 22–27 July 2018; pp. 8822–8825.
138. Gautam, D. Direct Georeferencing and Footprint Characterisation of a Non-Imaging Spectroradiometer
Mounted on an Unmanned Aircraft System. Ph.D. Thesis, University of Tasmania, Hobart, Tasmania,
Australia, 2019.
139. Rodríguez-Pérez, J.R.; Riaño, D.; Carlisle, E.; Ustin, S.; Smart, D.R. Evaluation of hyperspectral reﬂectance
indexes to detect grapevine water status in vineyards. Am. J. Enol. Vitic. 2007, 58, 302–317.
140. Hurley, S.P.; Horney, M.; Drake, A. Using hyperspectral imagery to detect water stress in vineyards.
In Autonomous Air and Ground Sensing Systems for Agricultural Optimization and Phenotyping IV; International
Society for Optics and Photonics: Baltimore, MD, USA, 2019; Volume 11008, p. 1100807.
141. Loggenberg, K.; Strever, A.; Greyling, B.; Poona, N. Modelling water stress in a shiraz vineyard using
hyperspectral imaging and machine learning. Remote Sens. 2018, 10, 202. [CrossRef]
142. Gómez-Candón, D.; Virlet, N.; Labbé, S.; Jolivot, A.; Regnard, J.-L. Field phenotyping of water stress at tree
scale by UAV-sensed imagery: new insights for thermal acquisition and calibration. Precis. Agric. 2016, 17,
786–800. [CrossRef]
143. Kelly, J.; Kljun, N.; Olsson, P.-O.; Mihai, L.; Liljeblad, B.; Weslien, P.; Klemedtsson, L.; Eklundh, L. Challenges
and best practices for deriving temperature data from an uncalibrated UAV thermal infrared camera.
Remote Sens. 2019, 11, 567. [CrossRef]
144. Smigaj, M.; Gaulton, R.; Suarez, J.; Barr, S. Use of miniature thermal cameras for detection of physiological
stress in conifers. Remote Sens. 2017, 9, 957. [CrossRef]
145. Clarke, I. Thermal Infrared Remote Sensing from Unmanned Aircraft Systems (UAS) for Precision Viticulture.
Master’s Thesis, University of Tasmania, Hobart, Tasmania, Australia, 2014.
146. Daakir, M.; Zhou, Y.; Pierrot Deseilligny, M.; Thom, C.; Martin, O.; Rupnik, E. Improvement of
photogrammetric accuracy by modeling and correcting the thermal eﬀect on camera calibration. ISPRS J.
Photogramm. Remote Sens. 2019, 148, 142–155. [CrossRef]
147. Nugent, P.W.; Shaw, J.A. Calibration of uncooled LWIR microbolometer imagers to enable long-term ﬁeld
deployment. In Infrared Imaging Systems: Design, Analysis, Modeling, and Testing XXV; International Society
for Optics and Photonics: Baltimore, MD, USA, 2014; Volume 9071, p. 90710V.
Agronomy 2020, 10, 140
28 of 35
148. Budzier, H.; Gerlach, G. Calibration of uncooled thermal infrared cameras. J. Sens. Sens. Syst. 2015, 4,
187–197. [CrossRef]
149. Lin, D.; Maas, H.-G.; Westfeld, P.; Budzier, H.; Gerlach, G. An advanced radiometric calibration approach for
uncooled thermal cameras. Photogramm. Rec. 2018, 33, 30–48. [CrossRef]
150. Ribeiro-Gomes, K.; Hernández-López, D.; Ortega, J.F.; Ballesteros, R.; Poblete, T.; Moreno, M.A. Uncooled
thermal camera calibration and optimization of the photogrammetry process for UAV applications in
agriculture. Sensors 2017, 17, 173. [CrossRef]
151. Lin, D.; Westfeld, P.; Maas, H.G. Shutter-less temperature-dependent correction for uncooled thermal camera
under fast changing FPA temperature. Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci.—ISPRS Arch. 2017,
42, 619–625. [CrossRef]
152. Mesas-Carrascosa, F.J.; Pérez-Porras, F.; de Larriva, J.E.M.; Frau, C.M.; Agüera-Vega, F.; Carvajal-Ramírez, F.;
Martínez-Carricondo, P.; García-Ferrer, A. Drift correction of lightweight microbolometer thermal sensors
on-board unmanned aerial vehicles. Remote Sens. 2018, 10, 615. [CrossRef]
153. Torres-Rua, A. Vicarious calibration of sUAS microbolometer temperature imagery for estimation of
radiometric land surface temperature. Sensors 2017, 17, 1499. [CrossRef] [PubMed]
154. Bendig, J.; Bolten, A.; Bareth, G. Introducing a low-cost mini-UAV for thermal-and multispectral-imaging.
Int. Arch. Photogramm Remote Sens. Spat. Inf. Sci. 2012, 39, 345–349. [CrossRef]
155. Raymer, D. Aircraft Design: A Conceptual Approach; American Institute of Aeronautics and Astronautics, Inc.:
Reston, VA, USA, 2018.
156. Tardieu, F.; Simonneau, T. Variability among species of stomatal control under ﬂuctuating soil water status
and evaporative demand: modelling isohydric and anisohydric behaviours. J. Exp. Bot. 1998, 49, 419–432.
[CrossRef]
157. White, W.A.; Alsina, M.M.; Nieto, H.; McKee, L.G.; Gao, F.; Kustas, W.P. Determining a robust indirect
measurement of leaf area index in California vineyards for validating remote sensing-based retrievals.
Irrig. Sci. 2019, 37, 269–280. [CrossRef]
158. Zarco-Tejada, P.J.; Berni, J.A.; Suárez, L.; Sepulcre-Cantó, G.; Morales, F.; Miller, J.R. Imaging chlorophyll
ﬂuorescence with an airborne narrow-band multispectral camera for vegetation stress detection.
Remote Sens. Environ. 2009, 113, 1262–1275. [CrossRef]
159. Gago, J.; Douthe, C.; Florez-Sarasa, I.; Escalona, J.M.; Galmes, J.; Fernie, A.R.; Flexas, J.; Medrano, H.
Opportunities for improving leaf water use eﬃciency under climate change conditions. Plant Sci. 2014, 226,
108–119. [CrossRef]
160. Suárez, L.; Zarco-Tejada, P.J.; Sepulcre-Cantó, G.; Pérez-Priego, O.; Miller, J.; Jiménez-Muñoz, J.; Sobrino, J.
Assessing canopy PRI for water stress detection with diurnal airborne imagery. Remote Sens. Environ. 2008,
112, 560–575. [CrossRef]
161. Eugenio, F.; Marqués, F. Automatic satellite image georeferencing using a contour-matching approach.
IEEE Trans. Geosci. Remote Sens. 2003, 41, 2869–2880. [CrossRef]
162. Hugenholtz, C.; Brown, O.; Walker, J.; Barchyn, T.; Nesbit, P.; Kucharczyk, M.; Myshak, S. Spatial accuracy of
UAV-derived orthoimagery and topography: Comparing photogrammetric models processed with direct
geo-referencing and ground control points. Geomatica 2016, 70, 21–30. [CrossRef]
163. Matese, A.; Di Gennaro, S.F.; Berton, A. Assessment of a canopy height model (CHM) in a vineyard using
UAV-based multispectral imaging. Int. J. Remote Sens. 2017, 38, 2150–2160. [CrossRef]
164. Yahyanejad, S.; Misiorny, J.; Rinner, B. Lens distortion correction for thermal cameras to improve aerial
imaging with small-scale UAVs. In Proceedings of the 2011 IEEE International Symposium on Robotic and
Sensors Environments (ROSE 2011), Montreal, QC, Canada, 17–18 September 2011; pp. 231–236.
165. Maes, W.; Huete, A.; Steppe, K. Optimizing the processing of UAV-based thermal imagery. Remote Sens. 2017,
9, 476. [CrossRef]
166. Smith, M.; Carrivick, J.; Quincey, D. Structure from motion photogrammetry in physical geography.
Prog. Phys. Geogr. 2016, 40, 247–275. [CrossRef]
167. Westoby, M.J.; Brasington, J.; Glasser, N.F.; Hambrey, M.J.; Reynolds, J.M. ‘Structure-from-Motion’
photogrammetry: A low-cost, eﬀective tool for geoscience applications. Geomorphology 2012, 179, 300–314.
[CrossRef]
168. Gautam, D.; Lucieer, A.; Malenovský, Z.; Watson, C. Comparison of MEMS-based and FOG-based IMUs to
determine sensor pose on an unmanned aircraft system. J. Surv. Eng. 2017, 143. [CrossRef]
Agronomy 2020, 10, 140
29 of 35
169. Turner, D.; Lucieer, A.; McCabe, M.; Parkes, S.; Clarke, I. Pushbroom hyperspectral imaging from an
unmanned aircraft system (UAS)–geometric processingworkﬂow and accuracy assessment. ISPRS-Int. Arch.
Photogramm. Remote Sens. Spat. Inf. Sci. 2017, XLII-2/W6, 379–384. [CrossRef]
170. Fang, J.; Wang, X.; Zhu, T.; Liu, X.; Zhang, X.; Zhao, D. A Novel Mosaic Method for UAV-Based Hyperspectral
Images. In Proceedings of the 2019 IEEE International Geoscience and Remote Sensing Symposium (IGARSS
2019), Yokohama, Japan, 28 July–2 August 2019; pp. 9220–9223.
171. Tagle, X. Study of Radiometric Variations in Unmanned Aerial Vehicle Remote Sensing Imagery for Vegetation
Mapping. Master’s Thesis, Lund University, Lund, Sweden, 2017.
172. Kedzierski, M.; Wierzbicki, D.; Sekrecka, A.; Fryskowska, A.; Walczykowski, P.; Siewert, J. Inﬂuence of lower
atmosphere on the radiometric quality of unmanned aerial vehicle imagery. Remote Sens. 2019, 11, 1214.
[CrossRef]
173. Kelcey, J.; Lucieer, A. Sensor correction of a 6-band multispectral imaging sensor for UAV remote sensing.
Remote Sens. 2012, 4, 1462–1493. [CrossRef]
174. Maes, W.H.; Steppe, K. Perspectives for remote sensing with unmanned aerial vehicles in precision agriculture.
Trends Plant Sci. 2019, 24, 152–164. [CrossRef]
175. McCabe, M.F.; Houborg, R.; Lucieer, A. High-resolution sensing for precision agriculture:
from
Earth-observing satellites to unmanned aerial vehicles.
In Remote Sensing for Agriculture, Ecosystems,
and Hydrology XVIII; International Society for Optics and Photonics: Edinbrugh, UK, 2016; Volume 9998,
p. 999811.
176. Dinguirard, M.; Slater, P.N. Calibration of space-multispectral imaging sensors: A review. Remote Sens. Environ.
1999, 68, 194–205. [CrossRef]
177. Geladi, P.; Burger, J.; Lestander, T. Hyperspectral imaging: calibration problems and solutions. Chemom. Intell.
Lab. Syst. 2004, 72, 209–217. [CrossRef]
178. Iqbal, F.; Lucieer, A.; Barry, K. Simpliﬁed radiometric calibration for UAS-mounted multispectral sensor.
Eur. J. Remote Sens. 2018, 51, 301–313. [CrossRef]
179. Mamaghani, B.; Salvaggio, C. Multispectral Sensor Calibration and Characterization for sUAS Remote
Sensing. Sensors 2019, 19, 4453. [CrossRef] [PubMed]
180. Mamaghani, B.; Salvaggio, C. Comparative study of panel and panelless-based reﬂectance conversion
techniques for agricultural remote sensing. arXiv 2019, arXiv:191003734.
181. Jensen, A.M.; McKee, M.; Chen, Y. Calibrating thermal imagery from an unmanned aerial system-AggieAir.
In Proceedings of the 2013 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2013),
Melbourne, Australia, 21–26 July 2013; pp. 542–545.
182. Zarco-Tejada, P.J.; Victoria, G.-D.; Williams, L.; Suárez, L.; Berni, J.A.; Goldhamer, D.; Fereres, E. A PRI-based
water stress index combining structural and chlorophyll eﬀects: Assessment using diurnal narrow-band
airborne imagery and the CWSI thermal index. Remote Sens. Environ. 2013, 138, 38–50. [CrossRef]
183. Blaschke, T. Object based image analysis for remote sensing. ISPRS J. Photogramm. Remote Sens. 2010, 65,
2–16. [CrossRef]
184. De Castro, A.; Torres-Sánchez, J.; Peña, J.; Jiménez-Brenes, F.; Csillik, O.; López-Granados, F. An automatic
random forest-OBIA algorithm for early weed mapping between and within crop rows using UAV imagery.
Remote Sens. 2018, 10, 285. [CrossRef]
185. Peña-Barragán, J.M.; Ngugi, M.K.; Plant, R.E.; Six, J. Object-based crop identiﬁcation using multiple vegetation
indices, textural features and crop phenology. Remote Sens. Environ. 2011, 115, 1301–1316. [CrossRef]
186. Johansen, K.; Raharjo, T. Multi-temporal assessment of lychee tree crop structure using multi-spectral RPAS
imagery. ISPRS Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2017, XLII-2/W6, 165–170. [CrossRef]
187. Ma, L.; Li, M.; Ma, X.; Cheng, L.; Du, P.; Liu, Y. A review of supervised object-based land-cover image
classiﬁcation. ISPRS J. Photogramm. Remote Sens. 2017, 130, 277–293. [CrossRef]
188. Pádua, L.; Vanko, J.; Hruška, J.; Adão, T.; Sousa, J.J.; Peres, E.; Morais, R. UAS, sensors, and data processing
in agroforestry: a review towards practical applications. Int. J. Remote Sens. 2017, 38, 2349–2391. [CrossRef]
189. Torres-Sánchez, J.; López-Granados, F.; Peña, J.M. An automatic object-based method for optimal thresholding
in UAV images: Application for vegetation detection in herbaceous crops. Comput. Electron. Agric. 2015, 114,
43–52. [CrossRef]
190. Cohen, Y.; Alchanatis, V.; Prigojin, A.; Levi, A.; Soroker, V. Use of aerial thermal imaging to estimate water
status of palm trees. Precis. Agric. 2012, 13, 123–140. [CrossRef]
Agronomy 2020, 10, 140
30 of 35
191. Comba, L.; Gay, P.; Primicerio, J.; Aimonino, D.R. Vineyard detection from unmanned aerial systems images.
Comput. Electron. Agric. 2015, 114, 78–87. [CrossRef]
192. Nolan, A.; Park, S.; Fuentes, S.; Ryu, D.; Chung, H. Automated detection and segmentation of vine rows using
high resolution UAS imagery in a commercial vineyard. In Proceedings of the 21st International Congress
on Modelling and Simulation, Gold Coast, QLD, Australia, 29 November–4 December 2015; Volume 29,
pp. 1406–1412.
193. Bobillet, W.; Da Costa, J.-P.; Germain, C.; Lavialle, O.; Grenier, G. Row detection in high resolution remote
sensing images of vine ﬁelds. In Proceedings of the 4th European Conference on Precision Agriculture,
Berlin, Germany, 15–19 June 2003; pp. 81–87.
194. Poblete, T.; Ortega-Farías, S.; Ryu, D. Automatic coregistration algorithm to remove canopy shaded pixels in
UAV-borne thermal images to improve the estimation of crop water stress index of a drip-irrigated cabernet
sauvignon vineyard. Sensors 2018, 18, 397. [CrossRef]
195. Ihuoma, S.O.; Madramootoo, C.A. Recent advances in crop water stress detection. Comput. Electron. Agric.
2017, 141, 267–275. [CrossRef]
196. Jones, H.G. Use of infrared thermometry for estimation of stomatal conductance as a possible aid to irrigation
scheduling. Agric. For. Meteorol. 1999, 95, 139–149. [CrossRef]
197. Bellvert, J.; Marsal, J.; Girona, J.; Zarco-Tejada, P.J. Seasonal evolution of crop water stress index in grapevine
varieties determined with high-resolution remote sensing thermal imagery. Irrig. Sci. 2015, 33, 81–93.
[CrossRef]
198. García-Tejero, I.F.; Gutiérrez-Gordillo, S.; Ortega-Arévalo, C.; Iglesias-Contreras, M.; Moreno, J.M.;
Souza-Ferreira, L.; Durán-Zuazo, V.H. Thermal imaging to monitor the crop-water status in almonds
by using the non-water stress baselines. Sci. Hortic. 2018, 238, 91–97. [CrossRef]
199. Alchanatis, V.; Cohen, Y.; Cohen, S.; Moller, M.; Sprinstin, M.; Meron, M.; Tsipris, J.; Saranga, Y.; Sela, E.
Evaluation of diﬀerent approaches for estimating and mapping crop water status in cotton with thermal
imaging. Precis. Agric. 2010, 11, 27–41. [CrossRef]
200. Goetz, S. Multi-sensor analysis of NDVI, surface temperature and biophysical variables at a mixed grassland
site. Int. J. Remote Sens. 1997, 18, 71–94. [CrossRef]
201. Sun, L.; Gao, F.; Anderson, M.; Kustas, W.; Alsina, M.; Sanchez, L.; Sams, B.; McKee, L.; Dulaney, W.;
White, W.; et al. Daily mapping of 30 m LAI and NDVI for grape yield prediction in California Vineyards.
Remote Sens. 2017, 9, 317. [CrossRef]
202. Peñuelas, J.; Filella, I.; Biel, C.; Serrano, L.; Save, R. The reﬂectance at the 950–970 nm region as an indicator
of plant water status. Int. J. Remote Sens. 1993, 14, 1887–1905. [CrossRef]
203. Jones, C.L.; Weckler, P.R.; Maness, N.O.; Stone, M.L.; Jayasekara, R. Estimating water stress in plants
using hyperspectral sensing. In Proceedings of the 2004 ASAE Annual Meeting, Ottawa, ON, Canada,
1–4 August 2004; p. 1.
204. Aˇc, A.; Malenovskỳ, Z.; Olejníˇcková, J.; Gallé, A.; Rascher, U.; Mohammed, G. Meta-analysis assessing
potential of steady-state chlorophyll ﬂuorescence for remote sensing detection of plant water, temperature
and nitrogen stress. Remote Sens. Environ. 2015, 168, 420–436. [CrossRef]
205. Mohammed, G.H.; Colombo, R.; Middleton, E.M.; Rascher, U.; van der Tol, C.; Nedbal, L.; Goulas, Y.;
Pérez-Priego, O.; Damm, A.; Meroni, M.; et al. Remote sensing of solar-induced chlorophyll ﬂuorescence
(SIF) in vegetation: 50 years of progress. Remote Sens. Environ. 2019, 231, 111177. [CrossRef]
206. Panigada, C.; Rossini, M.; Meroni, M.; Cilia, C.; Busetto, L.; Amaducci, S.; Boschetti, M.; Cogliati, S.; Picchi, V.;
Pinto, F.; et al. Fluorescence, PRI and canopy temperature for water stress detection in cereal crops. Int. J.
Appl. Earth Obs. Geoinformation 2014, 30, 167–178. [CrossRef]
207. Jones, H.G.; Stoll, M.; Santos, T.; Sousa, C.D.; Chaves, M.M.; Grant, O.M. Use of infrared thermography for
monitoring stomatal closure in the ﬁeld: application to grapevine. J. Exp. Bot. 2002, 53, 2249–2260. [CrossRef]
208. Jackson, R.D.; Idso, S.B.; Reginato, R.J.; Pinter, P.J. Canopy temperature as a crop water stress indicator.
Water Resour. Res. 1981, 17, 1133–1138. [CrossRef]
209. Bellvert, J.; Zarco-Tejada, P.J.; Girona, J.; Fereres, E. Mapping crop water stress index in a ‘Pinot-noir’vineyard:
comparing ground measurements with thermal remote sensing imagery from an unmanned aerial vehicle.
Precis. Agric. 2014, 15, 361–376. [CrossRef]
210. Fuentes, S.; De Bei, R.; Pech, J.; Tyerman, S. Computational water stress indices obtained from thermal image
analysis of grapevine canopies. Irrig. Sci. 2012, 30, 523–536. [CrossRef]
Agronomy 2020, 10, 140
31 of 35
211. Jackson, R.D. Canopy temperature and crop water stress. In Advances in Irrigation; Elsevier: Amsterdam,
The Netherlands, 1982; Volume 1, pp. 43–85.
212. Idso, S.; Jackson, R.; Pinter, P., Jr.; Reginato, R.; Hatﬁeld, J. Normalizing the stress-degree-day parameter for
environmental variability. Agric. Meteorol. 1981, 24, 45–55. [CrossRef]
213. Möller, M.; Alchanatis, V.; Cohen, Y.; Meron, M.; Tsipris, J.; Naor, A.; Ostrovsky, V.; Sprintsin, M.; Cohen, S.
Use of thermal and visible imagery for estimating crop water status of irrigated grapevine. J. Exp. Bot. 2006,
58, 827–838. [CrossRef] [PubMed]
214. Egea, G.; Padilla-Díaz, C.M.; Martinez-Guanter, J.; Fernández, J.E.; Pérez-Ruiz, M. Assessing a crop water
stress index derived from aerial thermal imaging and infrared thermometry in super-high density olive
orchards. Agric. Water Manag. 2017, 187, 210–221. [CrossRef]
215. Bannari, A.; Morin, D.; Bonn, F.; Huete, A. A review of vegetation indices. Remote Sens. Rev. 1995, 13, 95–120.
[CrossRef]
216. Ballester, C.; Zarco-Tejada, P.; Nicolas, E.; Alarcon, J.; Fereres, E.; Intrigliolo, D.; Gonzalez-Dugo, V. Evaluating
the performance of xanthophyll, chlorophyll and structure-sensitive spectral indices to detect water stress in
ﬁve fruit tree species. Precis. Agric. 2018, 19, 178–193. [CrossRef]
217. Romero-Trigueros, C.; Nortes, P.A.; Alarcón, J.J.; Hunink, J.E.; Parra, M.; Contreras, S.; Droogers, P.; Nicolás, E.
Eﬀects of saline reclaimed waters and deﬁcit irrigation on Citrus physiology assessed by UAV remote sensing.
Agric. Water Manag. 2017, 183, 60–69. [CrossRef]
218. Zhao, T.; Stark, B.; Chen, Y.; Ray, A.; Doll, D. More reliable crop water stress quantiﬁcation using small
unmanned aerial systems (sUAS). IFAC-PapersOnLine 2016, 49, 409–414. [CrossRef]
219. Sandholt, I.; Rasmussen, K.; Andersen, J. A simple interpretation of the surface temperature/vegetation index
space for assessment of surface moisture status. Remote Sens. Environ. 2002, 79, 213–224. [CrossRef]
220. Wang, L.; Qu, J.J. Satellite remote sensing applications for surface soil moisture monitoring: A review.
Front. Earth Sci. China 2009, 3, 237–247. [CrossRef]
221. Colaizzi, P.D.; Barnes, E.M.; Clarke, T.R.; Choi, C.Y.; Waller, P.M. Estimating soil moisture under low frequency
surface irrigation using crop water stress index. J. Irrig. Drain. Eng. 2003, 129, 27–35. [CrossRef]
222. Ahmed, A.; Zhang, Y.; Nichols, S. Review and evaluation of remote sensing methods for soil-moisture
estimation. SPIE Rev. 2011, 2, 028001.
223. Kerr, Y.H. Soil moisture from space: Where are we? Hydrogeol. J. 2007, 15, 117–120. [CrossRef]
224. Kerr, Y.H.; Waldteufel, P.; Wigneron, J.-P.; Delwart, S.; Cabot, F.; Boutin, J.; Escorihuela, M.-J.; Font, J.; Reul, N.;
Gruhier, C.; et al. The SMOS mission: New tool for monitoring key elements ofthe global water cycle.
Proc. IEEE 2010, 98, 666–687. [CrossRef]
225. Entekhabi, D.; Njoku, E.G.; O’Neill, P.E.; Kellogg, K.H.; Crow, W.T.; Edelstein, W.N.; Entin, J.K.; Goodman, S.D.;
Jackson, T.J.; Johnson, J.; et al. The soil moisture active passive (SMAP) mission. Proc. IEEE 2010, 98, 704–716.
[CrossRef]
226. Yueh, S.; Entekhabi, D.; O’Neill, P.; Njoku, E.; Entin, J. NASA soil moisture active passive mission status
and science performance. In Proceedings of the 2016 IEEE International Geoscience and Remote Sensing
Symposium (IGARSS 2016), Beijing, China, 10–16 July 2016; pp. 116–119.
227. Piles, M.; Sánchez, N.; Vall-llossera, M.; Camps, A.; Martínez-Fernández, J.; Martínez, J.; González-Gambau, V.
A Downscaling Approach for SMOS Land Observations: Evaluation of High-Resolution Soil Moisture Maps
Over the Iberian Peninsula. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2014, 7, 3845–3857. [CrossRef]
228. Cui, C.; Xu, J.; Zeng, J.; Chen, K.-S.; Bai, X.; Lu, H.; Chen, Q.; Zhao, T. Soil moisture mapping from satellites:
An intercomparison of SMAP, SMOS, FY3B, AMSR2, and ESA CCI over two dense network regions at
diﬀerent spatial scales. Remote Sens. 2018, 10, 33. [CrossRef]
229. Peng, J.; Loew, A.; Merlin, O.; Verhoest, N.E. A review of spatial downscaling of satellite remotely sensed soil
moisture. Rev. Geophys. 2017, 55, 341–366. [CrossRef]
230. Roussel, N.; Darrozes, J.; Ha, C.; Boniface, K.; Frappart, F.; Ramillien, G.; Gavart, M.; Van de Vyvere, L.;
Desenfans, O.; Baup, F. Multi-scale volumetric soil moisture detection from GNSS SNR data: Ground-based
and airborne applications. In Proceedings of the 2016 IEEE Metrology for Aerospace (MetroAeroSpace),
Florence, Italy, 22–23 June 2016; pp. 573–578.
231. Yan, S.; Zhang, N.; Chen, N.; Gong, J. Feasibility of using signal strength indicator data to estimate soil
moisture based on GNSS interference signal analysis. Remote Sens. Lett. 2018, 9, 61–70. [CrossRef]
Agronomy 2020, 10, 140
32 of 35
232. Johansen, K.; Sohlbach, M.; Sullivan, B.; Stringer, S.; Peasley, D.; Phinn, S. Mapping banana plants from
high spatial resolution orthophotos to facilitate plant health assessment. Remote Sens. 2014, 6, 8261–8286.
[CrossRef]
233. Hall, A.; Louis, J.; Lamb, D.W. Low-resolution remotely sensed images of winegrape vineyards map spatial
variability in planimetric canopy area instead of leaf area index. Aust. J. Grape Wine Res. 2008, 14, 9–17.
[CrossRef]
234. Furness, G.; Magarey, P.; Miller, P.; Drew, H. Fruit tree and vine sprayer calibration based on canopy size and
length of row: unit canopy row method. Crop Prot. 1998, 17, 639–644. [CrossRef]
235. Rosell, J.; Sanz, R. A review of methods and applications of the geometric characterization of tree crops in
agricultural activities. Comput. Electron. Agric. 2012, 81, 124–141. [CrossRef]
236. Lee, K.; Ehsani, R. A laser scanner based measurement system for quantiﬁcation of citrus tree geometric
characteristics. Appl. Eng. Agric. 2009, 25, 777–788. [CrossRef]
237. Li, F.; Cohen, S.; Naor, A.; Shaozong, K.; Erez, A. Studies of canopy structure and water use of apple trees on
three rootstocks. Agric. Water Manag. 2002, 55, 1–14. [CrossRef]
238. Kustas, W.; Agam, N.; Alﬁeri, J.; McKee, L.; Prueger, J.; Hipps, L.; Howard, A.; Heitman, J. Below canopy
radiation divergence in a vineyard: Implications on interrow surface energy balance. Irrig. Sci. 2019, 37,
227–237. [CrossRef]
239. Bendig, J.V. Unmanned aerial vehicles (UAVs) for multi-temporal crop surface modelling. A new method for
plant height and biomass estimation based on RGB-imaging. Ph.D. Thesis, University of Cologne, Cologne,
Germany, 2015.
240. Gowda, P.H.; Chavez, J.L.; Colaizzi, P.D.; Evett, S.R.; Howell, T.A.; Tolk, J.A. ET mapping for agricultural
water management: present status and challenges. Irrig. Sci. 2008, 26, 223–237. [CrossRef]
241. Zhang, K.; Kimball, J.S.; Running, S.W. A review of remote sensing based actual evapotranspiration estimation.
Wiley Interdiscip. Rev. Water 2016, 3, 834–853. [CrossRef]
242. Liou, Y.-A.; Kar, S. Evapotranspiration estimation with remote sensing and various surface energy balance
algorithms—A review. Energies 2014, 7, 2821–2849. [CrossRef]
243. Courault, D.; Seguin, B.; Olioso, A. Review on estimation of evapotranspiration from remote sensing data:
From empirical to numerical modeling approaches. Irrig. Drain. Syst. 2005, 19, 223–249. [CrossRef]
244. Kalma, J.D.; McVicar, T.R.; McCabe, M.F. Estimating land surface evaporation: A review of methods using
remotely sensed surface temperature data. Surv. Geophys. 2008, 29, 421–469. [CrossRef]
245. Li, Z.-L.; Tang, R.; Wan, Z.; Bi, Y.; Zhou, C.; Tang, B.; Yan, G.; Zhang, X. A review of current methodologies
for regional evapotranspiration estimation from remotely sensed data. Sensors 2009, 9, 3801–3853. [CrossRef]
246. Marshall, M.; Thenkabail, P.; Biggs, T.; Post, K. Hyperspectral narrowband and multispectral broadband
indices for remote sensing of crop evapotranspiration and its components (transpiration and soil evaporation).
Agric. For. Meteorol. 2016, 218, 122–134. [CrossRef]
247. Maes, W.; Steppe, K. Estimating evapotranspiration and drought stress with ground-based thermal remote
sensing in agriculture: a review. J. Exp. Bot. 2012, 63, 4671–4712. [CrossRef]
248. Bastiaanssen, W.G.; Menenti, M.; Feddes, R.; Holtslag, A. A remote sensing surface energy balance algorithm
for land (SEBAL). 1. Formulation. J. Hydrol. 1998, 212, 198–212. [CrossRef]
249. Allen, R.; Irmak, A.; Trezza, R.; Hendrickx, J.M.; Bastiaanssen, W.; Kjaersgaard, J. Satellite-based ET estimation
in agriculture using SEBAL and METRIC. Hydrol. Process. 2011, 25, 4011–4027. [CrossRef]
250. Allen, R.G.; Tasumi, M.; Trezza, R. Satellite-based energy balance for mapping evapotranspiration with
internalized calibration (METRIC)—Model. J. Irrig. Drain. Eng. 2007, 133, 380–394. [CrossRef]
251. Allen, R.G.; Tasumi, M.; Morse, A.; Trezza, R.; Wright, J.L.; Bastiaanssen, W.; Kramber, W.; Lorite, I.;
Robison, C.W. Satellite-Based Energy Balance for Mapping Evapotranspiration with Internalized Calibration
(METRIC)-Applications. J. Irrig. Drain. Eng. 2007, 133, 395–406. [CrossRef]
252. Allen, R.G.; Pereira, L.S.; Raes, D.; Smith, M. FAO Irrigation and drainage paper No. 56. Rome Food Agric.
Organ. U. N. 1998, 56, e156.
253. Jackson, R.D.; Moran, M.S.; Gay, L.W.; Raymond, L.H. Evaluating evaporation from ﬁeld crops using airborne
radiometry and ground-based meteorological data. Irrig. Sci. 1987, 8, 81–90. [CrossRef]
254. Williams, L.; Ayars, J. Grapevine water use and the crop coeﬃcient are linear functions of the shaded area
measured beneath the canopy. Agric. For. Meteorol. 2005, 132, 201–211. [CrossRef]
Agronomy 2020, 10, 140
33 of 35
255. Jayanthi, H.; Neale, C.M.; Wright, J.L. Development and validation of canopy reﬂectance-based crop
coeﬃcient for potato. Agric. Water Manag. 2007, 88, 235–246. [CrossRef]
256. Samani, Z.; Bawazir, A.S.; Bleiweiss, M.; Skaggs, R.; Longworth, J.; Tran, V.D.; Pinon, A. Using remote sensing
to evaluate the spatial variability of evapotranspiration and crop coeﬃcient in the lower Rio Grande Valley,
New Mexico. Irrig. Sci. 2009, 28, 93–100. [CrossRef]
257. Kustas, W.P.; Anderson, M.C.; Alﬁeri, J.G.; Knipper, K.; Torres-Rua, A.; Parry, C.K.; Nieto, H.; Agam, N.;
White, W.A.; Gao, F.; et al. The grape remote sensing atmospheric proﬁle and evapotranspiration experiment.
Bull. Am. Meteorol. Soc. 2018, 99, 1791–1812. [CrossRef]
258. Kamble, B.; Kilic, A.; Hubbard, K. Estimating crop coeﬃcients using remote sensing-based vegetation index.
Remote Sens. 2013, 5, 1588–1602. [CrossRef]
259. Hou, M.; Tian, F.; Zhang, L.; Li, S.; Du, T.; Huang, M.; Yuan, Y. Estimating crop transpiration of soybean
under diﬀerent irrigation treatments using thermal infrared remote sensing imagery. Agronomy 2019, 9, 8.
[CrossRef]
260. Knipper, K.R.; Kustas, W.P.; Anderson, M.C.; Alﬁeri, J.G.; Prueger, J.H.; Hain, C.R.; Gao, F.; Yang, Y.;
McKee, L.G.; Nieto, H.; et al. Evapotranspiration estimates derived using thermal-based satellite remote
sensing and data fusion for irrigation management in California vineyards. Irrig. Sci. 2019, 37, 431–449.
[CrossRef]
261. Hoﬀmann, H.; Nieto, H.; Jensen, R.; Guzinski, R.; Zarco-Tejada, P.; Friborg, T. Estimating evapotranspiration
with thermal UAV data and two source energy balance models. Hydrol. Earth Syst. Sci. Discuss. 2016, 20,
697–713. [CrossRef]
262. Cammalleri, C.; Anderson, M.; Kustas, W. Upscaling of evapotranspiration ﬂuxes from instantaneous to
daytime scales for thermal remote sensing applications. Hydrol. Earth Syst. Sci. 2014, 18, 1885–1894.
[CrossRef]
263. Biggs, T.W.; Marshall, M.; Messina, A. Mapping daily and seasonal evapotranspiration from irrigated crops
using global climate grids and satellite imagery: Automation and methods comparison. Water Resour. Res.
2016, 52, 7311–7326. [CrossRef]
264. Chávez, J.L.; Neale, C.M.; Prueger, J.H.; Kustas, W.P. Daily evapotranspiration estimates from extrapolating
instantaneous airborne remote sensing ET values. Irrig. Sci. 2008, 27, 67–81. [CrossRef]
265. McCabe, M.F.; Wood, E.F. Scale inﬂuences on the remote estimation of evapotranspiration using multiple
satellite sensors. Remote Sens. Environ. 2006, 105, 271–285. [CrossRef]
266. Kustas, W.; Li, F.; Jackson, T.; Prueger, J.; MacPherson, J.; Wolde, M. Eﬀects of remote sensing pixel resolution
on modeled energy ﬂux variability of croplands in Iowa. Remote Sens. Environ. 2004, 92, 535–547. [CrossRef]
267. Hong, S.; Hendrickx, J.M.; Borchers, B. Eﬀect of scaling transfer between evapotranspiration maps derived
from LandSat 7 and MODIS images. In Targets and Backgrounds XI: Characterization and Representation;
International Society for Optics and Photonics: Orlando, FL, USA, 2005; Volume 5811, pp. 147–159.
268. Abiodun, O.O.; Guan, H.; Post, V.E.; Batelaan, O. Comparison of MODIS and SWAT evapotranspiration over
a complex terrain at diﬀerent spatial scales. Hydrol. Earth Syst. Sci. 2018, 22, 2775–2794. [CrossRef]
269. Justice, C.; Townshend, J.; Vermote, E.; Masuoka, E.; Wolfe, R.; Saleous, N.; Roy, D.; Morisette, J. An overview
of MODIS Land data processing and product status. Remote Sens. Environ. 2002, 83, 3–15. [CrossRef]
270. Nieto, H.; Bellvert, J.; Kustas, W.P.; Alﬁeri, J.G.; Gao, F.; Prueger, J.; Torres-Rua, A.; Hipps, L.E.; Elarab, M.;
Song, L. Unmanned airborne thermal and mutilspectral imagery for estimating evapotranspiration in irrigated
vineyards. In Proceedings of the 2017 IEEE International Geoscience and Remote Sensing Symposium
(IGARSS 2017), Fort Worth, TX, USA, 23–28 July 2017; pp. 5510–5513.
271. Ortega-Farías, S.; Ortega-Salazar, S.; Poblete, T.; Poblete-Echeverría, C.; Zúñiga, M.; Sepúlveda-Reyes, D.;
Kilic, A.; Allen, R. Estimation of olive evapotranspiration using multispectral and thermal sensors placed
aboard an unmanned aerial vehicle. Acta Hortic. 2017, 1150, 1–8. [CrossRef]
272. Gago, J.; Douthe, C.; Coopman, R.E.; Gallego, P.P.; Ribas-Carbo, M.; Flexas, J.; Escalona, J.; Medrano, H. UAVs
challenge to assess water stress for sustainable agriculture. Agric. Water Manag. 2015, 153, 9–19. [CrossRef]
273. Sepúlveda-Reyes, D.; Ingram, B.; Bardeen, M.; Zúñiga, M.; Ortega-Farías, S.; Poblete-Echeverría, C. Selecting
canopy zones and thresholding approaches to assess grapevine water status by using aerial and ground-based
thermal imaging. Remote Sens. 2016, 8, 822. [CrossRef]
274. McBratney, A.; Whelan, B.; Ancev, T.; Bouma, J. Future directions of precision agriculture. Precis. Agric. 2005,
6, 7–23. [CrossRef]
Agronomy 2020, 10, 140
34 of 35
275. Ferguson, R.; Rundquist, D. Remote sensing for site-speciﬁc crop management. In Precision Agriculture Basics;
Shannon, D.K., Clay, D.E., Kitchen, N.R., Eds.; American Society of Agronomy: Madison, WI, USA; Crop
Science Society of America: Madison, WI, USA; Soil Science Society of America: Madison, WI, USA, 2018;
pp. 103–118.
276. Florin, M.J.; McBratney, A.B.; Whelan, B.M. Extending site-speciﬁc crop management from individual ﬁelds
to an entire farm. In Proceedings of the Precision agriculture ’05, Proceedings of the 5th European Conference
on Precision Agriculture, Uppsala, Sweden, 9–12 June 2005; pp. 857–863.
277. Perea-Moreno, A.J.; Aguilera-Urena, M.J.; Merono-de Larriva, J.E.; Manzano-Agugliaro, F. Assessment of
the potential of UAV video image analysis for planning irrigation needs of golf courses. Water 2016, 8, 584.
[CrossRef]
278. Meron, M.; Tsipris, J.; Charitt, D. Remote mapping of crop water status to assess spatial variability of crop
stress. Precis. Agric. 2003, 405–410.
279. Idso, S.B. Non-water-stressed baselines: A key to measuring and interpreting plant water stress. Agric. Meteorol.
1982, 27, 59–70. [CrossRef]
280. Cohen, Y.; Alchanatis, V.; Meron, M.; Saranga, Y.; Tsipris, J. Estimation of leaf water potential by thermal
imagery and spatial analysis. J. Exp. Bot. 2005, 56, 1843–1852. [CrossRef] [PubMed]
281. Pagay, V.; Kidman, C.; Jenkins, A. Proximal and remote sensing tools for regional-scale characterisation of
grapevine water and nitrogen status in Coonawarra. Wine Vitic. J. 2016, 31, 42–47.
282. Romero, M.; Luo, Y.; Su, B.; Fuentes, S. Vineyard water status estimation using multispectral imagery from an
UAV platform and machine learning algorithms for irrigation scheduling management. Comput. Electron. Agric.
2018, 147, 109–117. [CrossRef]
283. Goldhamer, D.A.; Viveros, M.; Salinas, M. Regulated deﬁcit irrigation in almonds: eﬀects of variations in
applied water and stress timing on yield and yield components. Irrig. Sci. 2006, 24, 101–114. [CrossRef]
284. Girona, J.; Marsal, J.; Cohen, M.; Mata, M.; Miravete, C. Physiological, growth and yield responses of almond
(Prunus dulcis L ) to diﬀerent irrigation regimes. Acta Hortic. 1993, 335, 389–398. [CrossRef]
285. Sadler, E.; Evans, R.; Stone, K.; Camp, C. Opportunities for conservation with precision irrigation. J. Soil
Water Conserv. 2005, 60, 371–378.
286. Corbane, C.; Jacob, F.; Raclot, D.; Albergel, J.; Andrieux, P. Multitemporal analysis of hydrological soil surface
characteristics using aerial photos: A case study on a Mediterranean vineyard. Int. J. Appl. Earth Obs. Geoinf.
2012, 18, 356–367. [CrossRef]
287. Osroosh, Y.; Peters, R.T.; Campbell, C.S. Daylight crop water stress index for continuous monitoring of water
status in apple trees. Irrig. Sci. 2016, 34, 209–219. [CrossRef]
288. Osroosh, Y.; Peters, R.T.; Campbell, C.S.; Zhang, Q. Comparison of irrigation automation algorithms for
drip-irrigated apple trees. Comput. Electron. Agric. 2016, 128, 87–99. [CrossRef]
289. Lamm, F.R.; Aiken, R.M. Comparison of temperature-time threshold-and ET-based irrigation scheduling for
corn production. In Proceedings of the 2008 ASABE Annual International Meeting, Providence, RI, USA,
29 June–2 July 2008; p. 1.
290. O’Shaughnessy, S.A.; Evett, S.R.; Colaizzi, P.D.; Howell, T.A. A crop water stress index and time threshold
for automatic irrigation scheduling of grain sorghum. Agric. Water Manag. 2012, 107, 122–132. [CrossRef]
291. Bellvert, J.; Zarco-Tejada, P.; Gonzalez-Dugo, V.; Girona, J.; Fereres, E. Scheduling vineyard irrigation based
on mapping leaf water potential from airborne thermal imagery. In Precision Agriculture’13; Staﬀord, J.V., Ed.;
Springer: Cham, Switzerland, 2013; pp. 699–704.
292. Bellvert, J.; Girona, J. The use of multispectral and thermal images as a tool for irrigation scheduling in
vineyards. In The Use of Remote Sensing and Geographic Information Systems for Irrigation Management in
Southwest Europe; Erena, M., López-Francos, A., Montesinos, S., Berthoumieu, J.-P., Eds.; CIHEAM: Zaragoza,
Spain, 2012; pp. 131–137.
293. Erdem, Y.; ¸Sehirali, S.; Erdem, T.; Kenar, D. Determination of crop water stress index for irrigation scheduling
of bean (Phaseolus vulgaris L.). Turk. J. Agric. For. 2006, 30, 195–202.
294. Osroosh, Y.; Troy Peters, R.; Campbell, C.S.; Zhang, Q. Automatic irrigation scheduling of apple trees using
theoretical crop water stress index with an innovative dynamic threshold. Comput. Electron. Agric. 2015, 118,
193–203. [CrossRef]
295. Irmak, S.; Haman, D.Z.; Bastug, R. Determination of crop water stress index for irrigation timing and yield
estimation of corn. Agron. J. 2000, 92, 1221–1227. [CrossRef]
Agronomy 2020, 10, 140
35 of 35
296. Acevedo-Opazo, C.; Tisseyre, B.; Ojeda, H.; Ortega-Farias, S.; Guillaume, S. Is it possible to assess the spatial
variability of vine water status? OENO One 2008, 42, 203–219. [CrossRef]
297. Acevedo-Opazo, C.; Tisseyre, B.; Guillaume, S.; Ojeda, H. The potential of high spatial resolution information
to deﬁne within-vineyard zones related to vine water status. Precis. Agric. 2008, 9, 285–302. [CrossRef]
298. Petrie, P.R.; Wang, Y.; Liu, S.; Lam, S.; Whitty, M.A.; Skewes, M.A. The accuracy and utility of a low cost
thermal camera and smartphone-based system to assess grapevine water status. Biosyst. Eng. 2019, 179,
126–139. [CrossRef]
299. Woellert, K.; Ehrenfreund, P.; Ricco, A.J.; Hertzfeld, H. Cubesats: Cost-eﬀective science and technology
platforms for emerging and developing nations. Adv. Space Res. 2011, 47, 663–684. [CrossRef]
300. Kramer, H.J.; Cracknell, A.P. An overview of small satellites in remote sensing. Int. J. Remote Sens. 2008, 29,
4285–4337. [CrossRef]
301. McCabe, M.; Aragon, B.; Houborg, R.; Mascaro, J. CubeSats in Hydrology: Ultrahigh-Resolution Insights
Into Vegetation Dynamics and Terrestrial Evaporation. Water Resour. Res. 2017, 53, 10017–10024. [CrossRef]
302. Trombetti, M.; Riaño, D.; Rubio, M.; Cheng, Y.; Ustin, S. Multi-temporal vegetation canopy water content
retrieval and interpretation using artiﬁcial neural networks for the continental USA. Remote Sens. Environ.
2008, 112, 203–215. [CrossRef]
303. King, B.; Shellie, K. Evaluation of neural network modeling to predict non-water-stressed leaf temperature in
wine grape for calculation of crop water stress index. Agric. Water Manag. 2016, 167, 38–52. [CrossRef]
304. Shan, N.; Ju, W.; Migliavacca, M.; Martini, D.; Guanter, L.; Chen, J.; Goulas, Y.; Zhang, Y. Modeling canopy
conductance and transpiration from solar-induced chlorophyll ﬂuorescence. Agric. For. Meteorol. 2019, 268,
189–201. [CrossRef]
305. Moreno, J.; Goulas, Y.; Huth, A.; Middelton, E.; Miglietta, F.; Mohammed, G.; Nebdal, L.; Rascher, U.;
Verhof, W. Report for mission selection: CarbonSat ﬂex–An earth explorer to observe vegetation ﬂuorescence.
Eur. Space Agency 2015, 1330/2, 179–185.
306. Drusch, M.; Moreno, J.; Del Bello, U.; Franco, R.; Goulas, Y.; Huth, A.; Kraft, S.; Middleton, E.M.; Miglietta, F.;
Mohammed, G.; et al. The ﬂuorescence explorer mission concept-ESA’s Earth explorer 8. IEEE Trans. Geosci.
Remote Sens. 2017, 55, 1273–1284. [CrossRef]
307. Gautam, D.; Lucieer, A.; Watson, C.; McCoull, C. Lever-arm and boresight correction, and ﬁeld of view
determination of a spectroradiometer mounted on an unmanned aircraft system. ISPRS J. Photogramm.
Remote Sens. 2019, 155, 25–36. [CrossRef]
308. Garzonio, R.; Di Mauro, B.; Colombo, R.; Cogliati, S. Surface reﬂectance and sun-induced ﬂuorescence
spectroscopy measurements using a small hyperspectral UAS. Remote Sens. 2017, 9, 472. [CrossRef]
309. Gautam, D.; Lucieer, A.; Bendig, J.; Malenovský, Z. Footprint Determination of a Spectroradiometer Mounted
on an Unmanned Aircraft System. IEEE Trans. Geosci. Remote Sens. 2019, 1–12. [CrossRef]
310. Bendig, J.; Malenovskỳ, Z.; Gautam, D.; Lucieer, A. Solar-Induced Chlorophyll Fluorescence Measured
From an Unmanned Aircraft System: Sensor Etaloning and Platform Motion Correction. IEEE Trans. Geosci.
Remote Sens. 2019, 1–8. [CrossRef]
311. TongKe, F. Smart agriculture based on cloud computing and IOT. J. Converg. Inf. Technol. 2013, 8, 210–216.
312. Ojha, T.; Misra, S.; Raghuwanshi, N.S. Wireless sensor networks for agriculture: The state-of-the-art in
practice and future challenges. Comput. Electron. Agric. 2015, 118, 66–84. [CrossRef]
313. Hori, M.; Kawashima, E.; Yamazaki, T. Application of cloud computing to agriculture and prospects in other
ﬁelds. Fujitsu Sci. Tech. J. 2010, 46, 446–454.
314. Goap, A.; Sharma, D.; Shukla, A.; Krishna, C.R. An IoT based smart irrigation management system using
Machine learning and open source technologies. Comput. Electron. Agric. 2018, 155, 41–49. [CrossRef]
© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).


Paper 4:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: 0.9
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: The Future Factory is the result of the total reorganization, connection, and efﬁcient utilization of the means of production, including assets, processes, and people. It is less about the automation and digitization of individual elements or parts of the production process, and more about the connectivity or ties between a broad range of internal and external components and processes to enable real-time data sharing and information exchange, and intelligent feedback and responses between all nodes within the manufacturing ecosystem. The goal is to enable the achievement of smarter, quicker, and more efﬁcient solutions.

 Full Text: >
Citation: Anumbe, N.; Saidy, C.;
Harik, R. A Primer on the Factories of
the Future. Sensors 2022, 22, 5834.
https://doi.org/10.3390/s22155834
Academic Editor: Jorn Mehnen
Received: 6 June 2022
Accepted: 27 July 2022
Published: 4 August 2022
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright:
© 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed
under
the
terms
and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
sensors
Article
A Primer on the Factories of the Future
Noble Anumbe 1,2,*
, Clint Saidy 1,2 and Ramy Harik 1,2
1
Department of Mechanical Engineering, University of South Carolina, Columbia, SC 29201, USA
2
McNair Aerospace Center, University of South Carolina, Columbia, SC 29201, USA
*
Correspondence: anumbe@mailbox.sc.edu
Abstract: In a dynamic and rapidly changing world, customers’ often conﬂicting demands have con-
tinued to evolve, outstripping the ability of the traditional factory to address modern-day production
challenges. To ﬁx these challenges, several manufacturing paradigms have been proposed. Some of
these have monikers such as the smart factory, intelligent factory, digital factory, and cloud-based
factory. Due to a lack of consensus on general nomenclature, the term Factory of the Future (or Future
Factory) has been used in this paper as a collective euphemism for these paradigms. The Factory of
the Future constitutes a creative convergence of multiple technologies, techniques, and capabilities
that represent a signiﬁcant change in current production capabilities, models, and practices. Using
the semi-narrative research methodology in concert with the snowballing approach, the authors
reviewed the open literature to understand the organizing principles behind the most common smart
manufacturing paradigms with a view to developing a creative reference that articulates their shared
characteristics and features under a collective lingua franca, viz., Factory of the Future. Serving as a
review article and a reference monograph, the paper details the meanings, characteristics, techno-
logical framework, and applications of the modern factory and its various connotations. Amongst
other objectives, it characterizes the next-generation factory and provides an overview of reference
architectures/models that guide their structured development and deployment. Three advanced
communication technologies capable of advancing the goals of the Factory of the Future and rapidly
scaling advancements in the ﬁeld are discussed. It was established that next-generation factories
would be data rich environments. The realization of their ultimate value would depend on the ability
of stakeholders to develop the appropriate infrastructure to extract, store, and process data to support
decision making and process optimization.
Keywords: smart factory; advanced manufacturing; intelligent manufacturing; cyber manufactur-
ing; cyber physical systems; Internet of Things; Industry 4.0; artiﬁcial intelligence; data driven
manufacturing
1. Introduction
There is a burgeoning commitment by governments, industry, and academia to the
digital transformation of industry with a view to attaining the Future Factory. Though it
is still in its infancy, the Factory of the Future is one of the key constructs of Industry 4.0.
In this paper, it is envisioned as a highly connected, very intelligent, and broadly digitized
production facility. It represents the future state of a well-instrumented and fully con-
nected manufacturing entity sitting atop a cyber-physical framework. It is assumed to be
highly ﬂexible and extremely adaptable to production processes that rapidly accommodate
product customization. The competitive edge of the factory of the future is that it reaches
beyond the bounds of a traditional factory, which focuses on the rudimentary production
of physical products and extends its reach into such far-ﬂung functions such as production
planning, production scheduling, inventory management, supply chain logistics, and even
product design and development, all with limited human intervention. It is imperative to
understand past and present research trends to be able to fully understand and anticipate
the future of factories, and thus support the formulation of strategies for the diffusion of
Sensors 2022, 22, 5834. https://doi.org/10.3390/s22155834
https://www.mdpi.com/journal/sensors
Sensors 2022, 22, 5834
2 of 76
research ﬁndings and knowledge about the Factory of the Future. The purpose of this review
paper is to articulate and characterize this Factory of the Future. The paper seeks to inves-
tigate the meanings, characteristics, and technological underpinnings of the said Factory.
Speciﬁcally, this research aims at answering the following research questions: RQ1: What
is the Factory of the Future and what are its characteristics? What are the various reference
architectures, including descriptions of their components, constraints, interconnections,
and interactions that help deﬁne the Factory of the Future? What are the communication
technologies that would have the most impact on the development of the Factory of the
Future? Since the Factory of the Future is data-driven, what technologies and strategies exist
for seamlessly connecting all assets to enable the processing of data for intelligent decision
making? What are the key enabling technologies that underpin the Factory of the Future,
and how are they currently being applied? The rest of the paper is arranged as follows:
Section 2 lays a historical background for the evolution of manufacturing, beginning with
the ﬁrst industrial revolution when manpower was the state-of-art. It proceeds with a
system maturity model (i.e., Levels of System Sovereignty) that discriminates between
the different levels of factory autonomy. It wraps up with a synopsis on the concept of
Industry 4.0 and ends with an association between Industry 4.0 and the Future Factory.
Section 3 oultlines the research methodology, and Section 4 delves deeper into articulating
the concept of the Factory of the Future and its characteristics in the context of the man-
ufacturing ecosystem (MeS). Section 5 discusses the conceptual framework of a typical
Factory of the Future and the reference architectures which provide, in one model, vetted
and recommended nomenclatures, structures, and integrations of various aspects (IT, OT,
business, etc.) of an enterprise, necessary for the development or upgrade of the said
factory. Section 6 outlines three communication standards/technologies (OPC-UA, TSN,
and 5G mobile network) that would help shape the future of advanced manufacturing,
and Section 7 looks at practical techniques and technologies necessary for the integration
of the various assets within the factory with a view to enabling intra and inter-factory
communication. Section 8 is dedicated to the key enabling technologies that make the
Factory of the Future possible. The paper is concluded with a summary and conclusion in
Section 11.
2. A Historical Narrative: The Past, Present and Future of the Factory and Its Ecosystem
Historical context is necessary to understand the Factory of the Future. This section
provides a historical overview.
2.1. The Industrial Revolutions
Historical observers have reported a series of Industrial revolutions. These “industrial
revolutions” are frames of reference for the intersection of events and emergent technolo-
gies that often led to marked shifts in productivity, industry, and society. Each of the past
revolutions was driven by the emergence of new technologies and systematically resulted
in wholesale disruptions and concurrent transformations in industrial processes, manufac-
turing methodologies, business models, and the organization of capital and labor. These
shifts have not only resulted in global re-organization of the means of production, but also
in remarkable changes to the socio-political, cultural, and economic fortunes of nations.
We are currently in the dawn of the Fourth Industrial Revolution, and each of them can be
described as follows: (a) The First Industrial Revolution (circa 1760 to 1840): This was the
advent of mechanized production using coal, which resulted in the transition from muscle
power to mechanical power [1–4]. It was triggered by the invention of the stream engine,
and hydropower. It led to the emergence of the railroad construction industry. The major
contribution of this era was improved efﬁciency. (b) The Second Industrial Revolution (late
19th century (circa 1870) to early 20th century): The second Industrial revolution [5–7]
emerged in part due to the arrival of electric power and the advent of the assembly line. It
enabled mass production and kick-started the era of automation. (c) The Third Industrial Rev-
olution (Mid (circa 1969) to Late Twentieth Century): The third Industrial revolution [8–10]
Sensors 2022, 22, 5834
3 of 76
is otherwise known as the computer or digital revolution. Electronics and information
technology were key technologies of this era. The era heralded the rise of computer net-
works, the emergence of the Internet, and the arrival of robots. Automated production
was also a product of this era, mostly facilitated by the growth of machine control and
robots. (d) The Fourth Industrial Revolution: This era was marked by the ubiquity of physical
object representation in highly interactive virtual information networks [11,12], leading up
to the blurring of the boundaries between the physical and virtual worlds. This era [13]
characterized a shift in reliance on the client-server model to the adoption of ubiquitous
mobility that has come to catalyze the growth of smart things. Other remarkable elements
of this era include the growth of exponential technologies such as digital twins [14–20],
artiﬁcial intelligence (AI) [21–28], simulations [29–35], blockchain [36–41], big data and
analytics [42–46], augmented and virtual reality (AR, VR) [47–54], and robotics [55–61].
Industry 4.0 is a construct of the Fourth Industrial Revolution. It seeks to bring together
the various conceptual elements capable of framing the eminent transformation expected
from the collision of these technologies and the events they would likely trigger. The Fu-
ture Factory is one of many outcomes of this construct. Though industry watchers have
identiﬁed and focused on the four industrial revolutions referenced above, there are early
speculations about a ﬁfth industrial revolution. There is currently a lack of consensus on a
deﬁnition for this emerging revolution. However, current information suggests that the
main distinction between the Fourth and Fifth Industrial Revolutions could surround the
role of humans and the extent of their intervention in manufacturing. There are concerns
that the full realization of the Fourth Industrial Revolution could alienate humans. There is
therefore a strong debate being had around the idea of redeﬁning the role of humans in
the factory. This could mean bringing humans back as the central feature of the factory
through a deliberate emphasis on strong human–machine interaction.
2.2. Levels of System Sovereignty (L2S): A System Maturity Model
To evaluate the degrees of sovereignty of systems, machines, or other industrial
components for each of the four industrial periods, we propose a system maturity model
referred to as “Levels of System Sovereignty (L2IS). It shows the measure, state, or degree of
a system’s autonomy or its ability to self-govern, without human intervention. The model
divvies up the different stages of industrial (manufacturing) development based on the
degrees to which tasks, system control, and authority are split between humans and
machines (or more broadly, technology).
Humans and machines have always shared control or authority in a mutually com-
plimentary manner within the manufacturing space. What has varied is the degree of
autonomy (control, authority, or sovereignty) maintained by either party. Based on this
model, a factory (or any other qualifying industrial system) can be said to have at one of
four (4) sovereignty levels: mechanization, automation, semi-autonomy, or autonomy (Near
complete or full autonomy). Given this classiﬁcation, the higher the autonomy of a system,
the lower the demand for human-level intelligence or manual intervention. The model is
further discussed using Figure 1.
Figure 1. Diagram depicting the four industrial revolutions and degrees of system sovereignty.
Sensors 2022, 22, 5834
4 of 76
2.2.1. Mechanization
At this stage of industrialization, machines (often heavy industrial machinery) were
used to partially or completely do the work that was previously done using manual
labor. Manual labor here refers to work performed by humans without any tools or sup-
port. Mechanization was a distinct feature of the ﬁrst and second industrial revolutions.
Though machines became the work horses of the industry, they lacked control of their ac-
tions. Humans had total control of the machines and provided all the direction, instruction,
and information.
2.2.2. Automation
Automation enables a reduction in human intervention in the production process.
This is achieved through the predetermination of decision criteria, the development of sub-
process relationships, and related actions and the embodiment of those pre-determinations
in machines [62]. The integration of electronics, computers, control, and sensing elements
into mechanized systems at the onset of the third Industrial revolution made it possible
for machines to accept and execute instructions, giving them the ability to self-think, self-
dictate, or more accurately, self-move. Automation is derived from two Greek words
“autos” and “matos” meaning “self” and “thinking”, respectively. Notwithstanding the
etymology of the word, automated systems have no initiative. They still operate within
rule-based boundaries. They primarily execute pre-deﬁned tasks assigned to them by
humans—they just happen to execute them faster and more efﬁciently. The automation
category is also dominated by industrial machines and processes that are managed by
hierarchical, centralized, and rigid control systems. While they can be optimized for
increased efﬁciency, they are very difﬁcult to re-purpose and very poor at responding to
change. The consequence is that they are unable to correctly respond when faced with
unfamiliar situations, especially within dynamic environments, often necessitating the
inevitable intervention of humans. Notwithstanding, the advantage of automation is that it
reduces the demand for human (manual) intervention.
2.2.3. Semi-Autonomy
Most advanced factories today are at the “semi-autonomy” level. Semi-autonomous
systems feature programmable devices and machines. Unlike systems from the prior gener-
ation, they are smarter. They can better sense and understand their environments. Through
the Internet of Things (IoT), they can interact with other entities, share data/information,
and make some decisions within a volatile production environment leveraging machine/
deep learning (ML/DL)-based technologies. The factors that helped facilitate this level
of autonomy include the advent of the Internet, the maturation of computer networking
technologies, the growth of the Internet of Things (IoT), and the rise of cyber-physical
systems (CPS). Other factors include the cross-domain integration of modern operational
technologies (OT) and info-tech/communication systems and the broader integration of
advanced control devices (PLCs, PCs, PACs, etc.) into industrial systems.
2.2.4. Autonomy
Autonomy is the highest level of system control by non-human actors within the indus-
trial and manufacturing processes. It is the expected future state of the Factory of the Future,
a state where very limited human intervention would be required for the full functioning of
a factory [63–66]. Artiﬁcial intelligence (AI), which provides and represents computational
procedures for automated sensing, reasoning, learning, and decision making, would be a
critical part of autonomy in manufacturing [67]. At full maturation, the Factory of the Future
would be managed by intelligent heterarchical (i.e., non-hierarchical, or unranked) control
mechanisms, which would make it possible for the factory to respond well to volatility,
unpredictable disturbances, or sudden change within a dynamic environment. While we
are still years away from that day, there is the hope (think autonomous cars), that one day a
fully autonomous factory will be technologically feasible. A factory at this level of auton-
Sensors 2022, 22, 5834
5 of 76
omy would have the ability to execute work, predict failures, grow smarter, self-correct,
and if necessary, recover or compensate for failures with little or no explicit intervention
or instructions from a human. The attainment of this state would require the maturation
of autonomic systems, which would involve the embedding of advanced cognitive and
deep learning capabilities within multiple sub-systems inside the factory. The time frame
for attaining this maturation level would likely coincide with the era of artiﬁcial super
intelligence (ASI) or thereabout: the artiﬁcial intelligence level where the intelligence of a
computer would have equaled the intelligence of a human in virtually all areas, including
reasoning, planning, solving problems, thinking abstractly, comprehending complex ideas,
learning quickly, and learning from experience [68].
Currently, human involvement in autonomic systems is signiﬁcant. As hinted earlier,
the goal of achieving manufacturing systems autonomy is still far off. Many more years of
signiﬁcant technological advancements would be required. Until then, the Factory of the
Future will continue to exist within the wide chasm between automation and autonomy (i.e.,
Semi-autonomy). Full autonomy is a future goal that would require signiﬁcant embedding
of smart technologies within the manufacturing mainstream.
2.3. Industry 4.0 and the Future Factory
The term “Industry 4.0” (also spelled Industrie 4.0) has its origins in Germany [69]. It
has been a subject of great intellectual and economic discussion within academia, industry,
and government both locally and internationally [70]. It has also been a subject of multiple
studies in the open literature [71,72]. Discussions around it ﬁrst emerged in the litera-
ture sometime in November 2011 following a national strategic initiative by the German
government aimed at the digitization, integration, transformation, and standardization of
manufacturing. The US equivalent of this term is smart manufacturing [73,74]. Industrie
4.0 is a construct (idea or theory) of the Fourth Industrial Revolution that promotes the
digitization of manufacturing. It seeks to improve upon the advances achieved in the Third
Industrial Revolution, which included the adoption of computers and industrial automa-
tion. It is a step higher forward that includes the integration of interconnected systems of
intuitive, self-regulating, smart, and autonomous entities that seamlessly exchange data,
perform tasks, and work collaboratively. The goals of the upgrades are the improvement in
productivity, ﬂexibility, efﬁciency, and agility.
CPS [75] and IoT are the core technologies that make Industry 4.0 possible. Figure 2
shows the other enabling technologies that are contributing to its full realization. In the ﬁnal
report of the Industrie 4.0 working group entitled “Recommendations for implementing
the strategic initiative INDUSTRIE 4.0” commissioned by the German Federal Ministry
of Education and Research (BMBF) and aimed at securing the future of German manu-
facturing industry, Industrie 4.0 was deﬁned as, “networks of manufacturing resources
(manufacturing machinery, robots, conveyor and warehousing systems and production
facilities) that are autonomous, capable of controlling themselves in response to different
situations, self-conﬁguring, knowledge-based, sensor-equipped and spatially dispersed
and that also incorporate the relevant planning and management systems” [76]. Industry
4.0 encompasses a plurality of methodologies, technologies, and emergent trends [77].
At the very minimum, it is based on the technological concepts of cyber-physical systems
(CPS) and Internet of Things (IoT) [78]. It is expected that Industry 4.0 will result in
the exponential growth of data, improvement in operational effectiveness and a radical
transformation of the landscape within several industry segments that will result in the
development of new but nimble business models, build-out of highly customized products
and the creation of very customer-centric services [76,79,80]. Interoperability, information
transparency, technical assistance, and decentralized decision making were identiﬁed as
the four pillars of Industrie 4.0 necessary for the development of the smart factories [81].
Industry 4.0 as a concept is evolving. It is embracing newer paradigms, technologies,
and distinct arrangements and organizational structures for these assets. Beyond represent-
ing a technological transition from embedded systems to cyber-physical systems, it now
Sensors 2022, 22, 5834
6 of 76
refers to the networking, organization, and marshaling of intelligent objects (people, ma-
chines, and processes)—leveraging information, services, and communication technologies
to help achieve machine and system autonomy, decentralized intelligence, and production
optimization. Interoperability is about the ability of machines and other assets to seamlessly
connect and communicate with one another (i.e., share data and information). Information
transparency relates to the ability to access and acquire data and information and using
same to build virtual models of the physical device or system. Technical assistance speaks
to systems of non-human assets (robots, devices, and systems) working together to assist
humans in solving problems. Additionally, decentralized decision making refers to the
transfer of some resources and control to enable decision making at distributed locations
within the network without a need for consent from a central control hub [81].
Figure 2. Emerging technologies enabling the development of the Future Factory.
3. Research Methodology
The qualitative study of the Factory of the Future as a concept is a daunting prospect
due to its multi-dimensional and cross-disciplinary scope. It must therefore be understood
that a meaningful review of literature on the subject would require the interrogation of
multiple research streams that are spread across a variety of domains and disciplines.
3.1. Research Approach
Given the aforementioned, reliance on traditional review methodologies for data
collection, research trend tracking, knowledge syntheses, and objective viewpoint critique
can be challenging, to say the least. For this reason, the semi-systematic (narrative) review
approach was assumed to be a more realistic research approach. This approach caters to
our need to implement a multi-disciplinary and multi-domain based reviews of literature
in a less restrictive manner. This is in contrast to the traditional systematic review approach,
which is primarily focused on the systematic appraisal, and synthesizing of primary sources
around speciﬁc and narrowly scoped issues or topics. While a large portion of this review
focuses on peer reviewed literature, it also draws upon ﬁndings from the gray literature
(including industry reports, policy documents, white papers, etc.).
3.2. Search Goals
The authors’ primary search goal was to aggregate enough materials that could help
the research team understand the Factories of the Future and the emerging technologies that
are playing roles in making them smarter, faster, and more intuitive.
3.3. Data Sources
The primary data sources for this study included three digital sources, i.e., Google
Scholar, Web of Science, and Science Direct. To acquire the relevant articles, these sources
were searched using several keywords. Starting with relevant articles from our primary
search, we were able to track down other important (and sometimes obscure) articles
that did not show up in the preliminary searches using the snowballing search strategy.
Snowballing requires a set of initial articles, called seeds, to start the process. There are two
approaches to this methodology: backward snowballing, which selects papers referenced by
Sensors 2022, 22, 5834
7 of 76
the seeds, and forward snowballing, which selects papers that cite the seeds [82]. Snowballing
allows researchers to complement their primary set of relevant papers with additional
sources, often using the primary search results as the seeds or starting point. The additional
papers that result from the snowballing search are often papers that do not satisfy the origi-
nal search query or other relevant papers that are not present in the databases considered.
Grey literature and relatively dated research often fall within this category [83].
3.4. Search Methodology
The ﬁrst step was to search the data sources using certain keywords. Two main cate-
gories of keywords were generated. The ﬁrst related to different manufacturing paradigms.
This category included such keywords as “smart factory”, “intelligent factory”, “digital
factory”, “industry 4.0”, “advanced manufacturing”, etc. They were used to aggregate
content to enable an understanding of various aspects of the Factories of the Future, including
the foundational principles, underlying concepts, and applications. The second category
of key works related to the various emerging technologies that enable the Factories of the
Future. Examples of keywords used in this category are “artiﬁcial intelligence”, “cloud
computing”, “blockchain in manufacturing”, “big data in manufacturing”, “mixed reality”,
“augmented reality”, and “virtual reality”. The search was focused on qualitative studies
with abstracts or titles containing terms related to the different manufacturing paradigms
and the key enabling technologies driving them. Once the relevant papers had been ex-
tracted, the titles and abstracts of the articles were read for the initial screening. In the
third step, all the articles selected from the initial screening were thoroughly reviewed to
ensure their relevance to the subject areas. To ensure that other relevant articles that did
not satisfy the original search query or were not present in the databases used were not
omitted, snowballing was used in the next step. Search results from the database query
and snowballing search then made up the comprehensive list of papers from which the list
of principles, characteristics, and applications was prepared.
4. Understanding the Future Factory
As the traditional factory becomes increasingly unable to address the manufacturing
challenges of the 21st century, there is a need to to rethink the design of today’s manufac-
turing system. This would require the development of factories with capabilities which
radically improve the predictability, reliability, efﬁciency, and security of manufacturing
processes. This section explores the meaning and characteristics of a factory of this sort,
otherwise referred to as the Future Factory or the Factory of the Future.
4.1. The Future Factory in the Context of the Manufacturing Ecosystem (ME-S)
Accenture Global Strategy or Management Consultants) deﬁned the manufacturing
ecosystem as, “a network of industry players who work together to deﬁne, build, and execute
market-creating customer and consumer solutions; deﬁned by the depth and breadth of potential
collaboration among a set of players. The power of an ecosystem is that no single player owns or
operate all components of the solution, and the value the ecosystem generates is larger than the
combined value each of the players could contribute individually.” [84].
In the past, production literally happened “under one roof”. However, as products be-
came more sophisticated, and users demanded more affordable yet higher quality products,
it no longer makes sense to think of manufacturing as a one “factory-only” activity. Often,
no single entity owns or operates all elements of a manufacturing solution. Now more than
ever, every product that rolls off the conveyor relies on some form of third-party service
or technology. It is the case that producing high quality and cost-efﬁcient products and
services is dependent on partnering with other providers and cooperating with different
entities within the larger ecosystem, which incidentally is the key to efﬁciency. Due to
the technological changes that have occurred in the past three decades, technology now
has the power to reshape the production process by tightly connecting all relevant entities
(humans, machines, and applications) to enable the seamless ﬂow of the data required
Sensors 2022, 22, 5834
8 of 76
to provide the intelligence needed to drive efﬁciency. The goals of these networks are to
exchange information, provide support, and explore meaningful ways to achieve shared
objectives. These networks, loosely referred to manufacturing ecosystems (ME-S), often
include partners, factory workers, suppliers, vendors, contractors, and even customers.
Like a docking station, the manufacturing ecosystems (MES) is a hub on which the Future
Factory sits, enabling it to connect to an interdependent group of interrelated entities and
systems with which it routinely communicates and on which it depends for the supply of
information and resources. As the Future Factory (FF) relies on the concepts of information
and feedback, the seamless ﬂow of information from and to entities within the manufactur-
ing ecosystems (MES) is critical for its optimal performance. At an abstract level, each of the
entities within a manufacturing ecosystems (MES) can be represented as an object which
can be connected to one another and to various machines, devices, and sensors to help
extract valuable information. Entities participating in a manufacturing ecosystem have the
rare distinction of being able to access the decision making knowledge they need, when
they need it, because of the power of technology. Entities in a manufacturing ecosystem
collectively facilitate the transfer and eventual transformation of raw materials into ﬁnished
products. It is difﬁcult to fully understand the Future Factory (FF) in isolation from all
other entities within the future manufacturing ecosystems (ME-S). In many manufacturing
contexts, it is difﬁcult to separate manufacturing operations, for example, from the supply
chains that support them, setting the need to look at manufacturing through the prism of an
ecosystem. Ultimately, the resilience of the smart factories and the third-party systems that
support them will depend on reliable interactions between the two. Ultimately, the future
factory would be the result of the total reorganization, connection, and efﬁcient utilization
of the means of production, including assets, processes, and people. It is less about the
automation and digitization of individual elements or parts of the production process,
and more about the connectivity or ties between a broad range of internal and external
components and processes to enable real-time data sharing and information exchange,
and intelligent feedback and responses between all nodes within the manufacturing ecosys-
tem. The goal is to enable the achievement of smarter, quicker, and more efﬁcient solutions.
This would require seamless connection, efﬁcient data sharing, and reliable transfer of
information, in real-time, between different asset categories, including machine to machine
(M2M), machine to device (M2D), human to device (H2D), machine to virtual twin (M2VT),
factory to factory (F2F), factory to product (F2P), factory to human (F2H), and factory to
supply chain (F2SC) within the manufacturing ecosystem. Each asset on the networked
ecosystem is assigned an identity and connected to other assets in the network using
Industrial Internet of Things (IoT) protocols and technologies.
4.2. Describing the Factory of the Future
The emergence of the Factory of the Future has been necessitated by sweeping globaliza-
tion and unprecedented technological changes which have resulted in a very competitive
and dynamic global marketplace. The resultant volatility has given rise to short product
life-cycles, a “big ask” for on-demand production and increasing price pressures [85]. As a
result, traditional manufacturing, with all its advanced enhancements, is fundamentally
ill-equipped to meet the demand-pressures of the current environment. This state of affairs
has necessitated a rethinking of current manufacturing paradigms. To beneﬁt from the
on-going technology advancements within the manufacturing space, multiple actors (the
state, industry, and academia) are actively trying to shape the future of manufacturing,
hence the various national strategies, paradigms (smart factory, intelligent factory, Factory
of the Future, etc.), frameworks, and nomenclature proposals. An example of the modern
manufacturing system is the Cyber Manufacturing System (CMS)-refer to Figure 3. Its
backbone is the cyber-physical system (CPS) that enables data transparency, facilitates
reconﬁgurability, and promotes process optimization.
Sensors 2022, 22, 5834
9 of 76
Figure 3. Cyber Manufacturing Systems (CMS).
Incremental changes to traditional manufacturing paradigms are fundamentally inca-
pable of fully addressing modern manufacturing needs. As a result, manufacturing as a con-
cept needs to be fundamentally re-imagined. As a craft, it needs to be radically re-engineered.
Notwithstanding the obvious need and urgency to transform manufacturing as we know it,
there is no consensus around a fitting nomenclature for a factory that can serve as a replace-
ment for the traditional factory. In recent years, different manufacturing paradigms have
emerged, including (but not limited to) manufacturing concepts such as the Reconfigurable
Manufacturing System (RMS) [86–92], Flexible Manufacturing System (FMS) [93–100], dis-
tributed manufacturing [101–104], and cloud manufacturing [105–110]. In addition, terms
such as smart factory [111–116], intelligent factory [77,113,117–119,119–121], and digital
factory [122–126] represent emergent paradigms that seek to fulfill this need. However,
none has seemed adequate enough to capture the approval of a plurality of stakeholders
within the manufacturing community. This paper does not propose a unified nomencla-
ture but instead uses a generic term (i.e., Future Factory or Factory of the Future) to help
crystallize the general principles advocated by the most common advanced manufacturing
paradigms. Additionally, note that Factory of the Future and Future Factory have been used
interchangeably in this text and represent the future state of the factory during and beyond
the Fourth Industrial Revolution (4IR). Given that the end goals articulated by many of
these paradigms are similar, we will be drawing insights and inspiration from them to
help characterize the Factory of the Future. The concept of the Future Factory upends
the factors and elements of traditional manufacturing systems. The biggest challenge is
being able to clearly define what the Future Factory is and to then transition those concepts
effectively from theory to practice. For a start, the Future Factory is the nucleus of Industry
4.0 [127]. A proper articulation of the meaning of the Future Factory is heavily reliant on the
contextual and comprehensive understanding of Industry 4.0 concepts, which is the reason
why a Section 2.3 of this paper was dedicated to elaborating on Industry 4.0. The technical
foundation on which it stands is the selective and strategic integration and exploitation
of the unique advantages of a collection of emerging technologies, such as cyber-physical
production systems (CPPS)/cyber manufacturing systems (CMS), the Industrial Internet
of Things (IIoT), Internet of Systems (IoS), artificial intelligence (AI), smart robotics, cloud
computing, cybersecurity, and big data analytics. Thus, the Factory of the Future, as a
system of systems (SoS), should be designed to deliver key advantages that can potentially
address the challenges confronting traditional manufacturing in the age of speed, volatility,
and uncertainty [128]. While all the above-referenced technologies bring with them unique
capabilities, the structural underpinning or technical framework that supports the Factory
of the Future is the cyber-physical production system (CPPS). The future of manufacturing
necessitates increased flexibility in product customization, process monitoring, product
quality/process control, and service delivery. Hence, collaborative networks and cyber-
physical production systems (CPPS) have been identified as the future of industry [129].
Administrated interactions and information flow among machines, people, organizations,
and societies have been pursued as an ongoing research topic [130–132].
Sensors 2022, 22, 5834
10 of 76
Deﬁnition 1. Thus, a barebones deﬁnition of the Factory of the Future would be a dynamic and
highly integrated network of cyber-physical production systems (CPPS) that communicate or
interact with each other using the Industrial Internet of Things (IIoT) and the Internet of Services
(IoS). From an enterprise perspective, the Future Factory is a vertically and horizontally integrated
production system with an efﬁcient connection between itself and the supply chain that supports it.
Deﬁnition 2. Aptly named, the Future Factory is not an “end state”, but a constantly evolving
solution that continuously but strategically integrates new technologies and systems with the goal of
creating a resilient, stable, and efﬁcient system of systems (SoS) which can adapt to rapidly changing
manufacturing requirements, fulﬁll dynamic customer demands (in a timely and cost-effective
fashion), support customized mass production involving high variability (high product variety),
provide options for small lot sizes, adapt to disturbances, and rapidly respond to change or otherwise
recover from failure autonomously while eliminating the need for expensive post-process inspection.
The Factory of The Future would be a key driver of manufacturing competitiveness
across the globe because of the expectations of higher efﬁciency, lower production costs,
mass customization, adaptability, and ﬂexibility. Its true essence is the incremental im-
provements in how we design, manufacture, distribute, and service products.
The ﬁndings in this study must be seen in the light of some limitations. The ﬁrst of
these limitations is that it was performed using the semi-systematic or narrative review
approach, which is less rigorous than the systematic review approach. The reason for the
choice of the semi-systematic or narrative review approach was that the study involved
the intersection of diverse disciplines and multiple technologies, a reality that hinders
a full systematic review process [133]. The second limitation concerns the difﬁculty in
standardizing all advanced manufacturing systems and factory types in terms of differences
in paradigms, product types, production processes, automation levels, digitization levels,
etc. The authors made great efforts to capture the high-level principles that underline a
multiplicity of next-generation factory paradigms.
4.3. The Characteristics of the Future Factory
In its mature state, the Future Factory (FF) is envisioned as a production ecosystem
that operates autonomously (i.e., requiring little or no human intervention) in various
manufacturing operations, including production, logistics, prognostics, diagnostics, etc.
From a technical point of view, all of these are made possible by a technological framework
built using CPS, IoT, and intelligent decision support systems reliant on advanced analytics
and knowledge learning methodologies [134]. Figure 4 graphically illustrates some of the
most consequential characteristics of the Factory of the Future.
Characteristics of the Future Factory
Cognition
Self-Control
Self-Diagnosis
Connectedness
Integration
Horizontal
Integration
Vertical
Integration
End-To-End
Engineering
Interoperability
Consciousness
Agility
Context
Awareness
Modularity
Capacity for
Mass Customization
Figure 4. Characteristics of the Future Factory.
4.3.1. Cognition
The massive generation, analysis, and fusion of data (big data analytics) into manufac-
turing operations means that agents or entities of the factory possess cognitive capabilities
and can learn, plan, and interact, all while acting autonomously and in concert with
other entities.
Sensors 2022, 22, 5834
11 of 76
4.3.2. Self-Control
The Future Factory would be able to respond to changing business demands and
conditions in real-time [135]. It would have decision making and self-controlling abil-
ities, leveraging the factory’s ability to extract and analysis large amounts of customer
and machine data (cloud computing), and subsequently transmit useful information and
actionable intelligence on a need-to-know basis to the various entities within the network.
The ability of the production facility to have access to real-time information about changes
to the business environments can help the factory to adjust operations accordingly and
help reduce business uncertainties and meet customer demands. The ability of the factory
to self-control would be possible because of its decentralized architecture that allows for
the distributed storage and ﬂow of information. Data and information would ﬂow through
(to and from) a decentralized hierarchy that includes multiples localized systems, hubs,
machines, and related nodes within the network (including the products themselves).
4.3.3. Self-Diagnosis (Machine Health)
They also self-diagnose and repair identiﬁed malfunctions without halting production
or switching to a downtime mode.
4.3.4. Connectedness
Inter (and intra) connection, automation, and networking of assets within and between
various activity layers, including factories, the supply chain, and the community (IoT,
blockchain). This characteristic is further discussed in Section 4.4.
4.3.5. Agility
The factory of the future (smart factory) is ﬂexible and has adaptable production
processes [115].
4.3.6. Context Awareness
The Future Factory is context aware. Context awareness in this instance refers to a
system’s ability to self-sense, respond, adapt its behavior, and communicate based on in-
formation transmitted from its environment or gleaned from sensors embedded in several
nodes or entities within the system. Sensors have become affordable and ubiquitous across
factories and entire manufacturing ecosystems [136]. Key components of the system can
negotiate with each other to both request and profile functions [137]. With technologies such
as block-chain, radio frequency identification (RFID), and quick response code (QR code),
the smart factory can systematically identify and track assets, products, and people, both
spatially and temporally, making it possible for the factory to have real time knowledge of its
current state.
4.3.7. Modularity
Modularity is a property or quality of a manufacturing system that involves the
use of different modules (components or sub-systems) as the basis of design or construc-
tion [138]. In a modular system, modules can be quickly composed (composability) or
combined to form different conﬁgurations. Modularity is a need-based decentralization
of the production system using sub-systems that can later be recomposed into different
conﬁgurations [139]. Modularity reduces complexity. It helps break a system into different
degrees of interdependence and independence [140]. In a modular system, tweaking of one
or more components does not affect the functioning of all other components. Modularity
enables such advantages as quick adjustments in production capacity and functionality
(reconﬁgurable manufacturing systems (RMS)), higher throughput (dedicated manufac-
turing lines (DML)), and product variety using existing manufacturing systems (ﬂexible
manufacturing systems (FMS)) [141,142].
Sensors 2022, 22, 5834
12 of 76
4.3.8. Capacity for Mass Customization
Mass customization involves the efﬁcient, cost-effective, and speedy customization of
products and services at scale leveraging customer preferences (big data) [143–145]. This
would be facilitated by real-time communication between products and the production lines.
Traditional automatic identiﬁcation and transmission technologies such as radio frequency
identiﬁcation (RFID) and quick response code (QR code) can play roles in enabling products
and production lines to communicate in real-time. The information transmitted can be used,
for example, to address bespoke customer requests (product customization) or to control
the paths of products as they navigate through different manufacturing lines or stages.
4.4. Enabling Connectedness: Integration, Interoperability, and Consciousness
Of the eight characteristics of the Factory of the Future discussed in Section 4.3, con-
nectedness is perhaps the most fundamental. For this reason, we will be expounding on
the subject to help characterize the Future Factory. Unlike traditional factories, the Fu-
ture Factory is very robust, fully connected, and agile. It can synchronously learn and
adapt to changing conditions using information acquired from a constant ﬂow of pro-
cess and machine health data amassed from a variety of interconnected assets, processes,
and systems. All of these are made possible because of the system’s “connectedness”. The
connectedness of a factory is dependent on the degrees of integration, interoperability,
and consciousness of the system. Several researchers [71,146–148] have suggested that
these elements constitute key success factors for Industry 4.0 in general, and the Future
Factory (FF), in particular. Integration speaks to the tight combination, amalgamation,
or homogenization of the entire manufacturing network, and interoperability refers to the
ability of these tightly integrated systems and components to communicate or talk to each
other seamlessly and in real-time. Integration is central to interoperability. On the other
hand, consciousness speaks to the ability to be aware (or cognizant) and responsive to
one’s environment. Below, we will further discuss the three main functions elements of
consciousness: integration, interoperability, and consciousness.
4.4.1. Integration
Integration involves the tight linking of independent factories, processes, and product
lifecycles into a core network that can communicate with one another, and share data
as needed, while supporting distinct or shared technological and businesses objectives.
The goal of integration is to enable structural cohesion, seamless ﬂow of data, and the ability
of independent entities to access actionable information (technical or enterprise-related)
from an integrated network. The automation pyramid pictured in Figure 5 is a framework
that shows the different level of automation in a factory or industry. It represents a strategy
guide for the integration of technologies in a factory. The three different types of integration
identiﬁed in the ﬁnal report [75] of the Industrie 4.0 Working Group include (a) horizontal
integration through value networks, (b) end-to-end digital integration of engineering
across the entire value chain, and (c) vertical integration and networked manufacturing
systems. By integrating all systems, the most up-to-date processes and product data are
available at any time and can be shared with all entities (men, devices, and machines) on a
need-to-know basis to help facilitate planning, production, maintenance, logistics, supply
chain management, and customer service. Proper integration can result in a factory that is
innovative, proactive, and agile. Such a factory would be able to adapt to market changes
quickly, respond ﬂexibly and rapidly to changing customer demands, and achieve/maintain
competitive advantages over peers even in the most unpredictable business environment.
One of the main features of the Future Factory is the data-integrated core capable of
supporting truly automated value chains [105,149]. Currently, the degree of asset and
system integration within most factories is very limited. Though some have achieved
the full integration of the shop ﬂoor (ﬁeld level), loopholes still exist from the integration
layers up to the management level [150,151]. The goal of the Future factory is to connect all
Sensors 2022, 22, 5834
13 of 76
entities (machines, devices, people, systems, etc.) using standard communication protocols,
and therefore, enable seamless interaction between all parties.
(a)
Vertical integration: Vertical integration is the integration of all hierarchical physical
and informational subsystems within a factory to achieve a ﬂexible, self-managing
(autonomous), self-organized, and reconﬁgurable manufacturing system that can
respond to production uncertainties quickly, ﬂexibly, and effectively.
Figure 5. Automation pyramid.
For example, if a client requests speciﬁc product customizations, the business de-
velopment unit should not be on a call to engineering all day. All the information
requested by the engineering department will already have been logged in the ERP
system—essentially everyone has access to the same information (albeit different
versions on a need-to-know basis). With this this level of transparency and the seam-
less ﬂow of information, a vertically integrated system can be easily reconﬁgured
to produce the customized product or manufacture small-lot sizes, at short notice
without a signiﬁcant technical or ﬁscal penalty. The integration typically cuts across
different hierarchical stages beginning from the ﬁeld (factory ﬂoor) and going right
up to the enterprise resource planning (ERP) level. The joint implementation of all
three integration options can result in a fully integrated factory comprising digitally
connected entities (machines, people, products, and services). The overall goal is
the integration of all digitized physical assets into an ecosystem that includes all
elements of a local factory and all other entities or partners within their value chain.
The ecosystems resulting from these integrations enable increased autonomy for sys-
tem elements, decentralized control, improved efﬁciency, and transparency given the
seamless transmission of data and information between all entities.
(b)
Horizontal integration: Horizontal integration involves the digital connection of a fac-
tory to other external entities and processes across its value chain. It is illustrated in
Figure 6.This arrangement would include a digitally developed network of warehous-
ing systems, transportation assets, and production facilities that feature ICT-based
integration of everything from inbound logistics to production, marketing, outbound
logistics, and services [134]. The connectedness makes it possible for real time data to
be obtained, analyzed, and shared in real-time to facilitate rapid and accurate decision
making. All nodes on the network can have access (on a need-to-know basis) to
information about production status, inventory levels, available resources, and other
Sensors 2022, 22, 5834
14 of 76
critical information necessary for streamlined production. A factory so connected is
said to be horizontally integrated. Horizontal integration can take place at different
scales and at several levels. Optimal value can be created by a factory that can harness
value from data gleaned from activities and processes, both internal and external
to the factory. As part of the horizontal integration of a factory, suppliers, contrac-
tors, and even other factories, whether located in the same or different geographical
locations, can be connected into an efﬁcient ecosystem where there is seamless trans-
mission of data and information. The efﬁciency gained by this arrangement can be
mutually shared by all parties. For example, a factory can have regulated remote
access to a resource (machine, device, software, etc.) within a company in another lo-
cation. These outcomes can result in efﬁciency of scale, improvements in turn-around
time, and higher productivity levels. Other advantages include transparency, better
knowledge sharing, and improved communication.
(c)
End-to-end digital integration of engineering across the entire value chain: Though many
factories have successfully digitized different aspects of their businesses, some have
also ended up with segmented or siloed organizations where the systems of various
units are unable to talk to one another. Though most manufacturing processes are
supported by ICT, many of the systems and technologies that rely on them remain
static and inﬂexible [75]. The result is that information ﬂow is inhibited, throwing
manual transmission of data across the individual aspects back into the discussion.
Digitally connecting these different systems and technologies can be referred to as
End-to-end engineering integration. More broadly, it involves the digital integration
of all aspects of the value chain (sourcing, product development, production, logistics,
operations, marketing/sales, after-sale services, etc.) to enable the seamless ﬂow of
data across the network for the purpose of delivering real-time information about
production status to all stakeholders, enabling the development of new efﬁciency,
supporting product customization [152], streamlining of processes, and a reduction
in the unnecessary expenditure on manual activities. Figure 7 provides a graphical
illustration of end-to-end digital integration.
Figure 6. Horizontal Integration.
Sensors 2022, 22, 5834
15 of 76
Figure 7. End-to-end integration.
4.4.2. Interoperability
Interoperability is a very critical characteristic of the Future Factory, primarily because
it involves the ability of different entities (machines, devices, applications, etc.) to exchange,
process, and use data/information. Multiple deﬁnitions of interoperability exist [153–159]
in the literature, but they all distill down to the ability of two or more entities to receive,
process, and exchange content (data, information, or services) for their mutual interest,
in a timely manner, without distortions or any form of semantic inhibition. The goal of the
data, information, or service so exchanged is to help all parties to operate more effectively
together [153]. Abe Zeid et al. (2019) [160] outlined two approaches to interoperability,
i.e., syntactic and semantic: (a) Syntactic interoperability relates to data formats. The use of
standardized data formats can support interoperability. (b) Semantic interoperability is the
human interpretation of content. The commonly used standards for semantic interoperabil-
ity are XML and the Resource Deﬁnition Framework (RDF). The authors also identiﬁed
two types of interoperability: (a) Factory interoperability (vertical integration): The ability
of physical and informational subsystems within a factory to seamlessly communicate
with each other. (b) Cloud-manufacturing interoperability (horizontal integration): Cloud-
manufacturing interoperability is deﬁned as a form of horizontal interoperability where
virtual elements of the production process can communicate with one another. This is
broken down into three types: (1) Transport interoperability (related to the interoperability
of data transfer/exchange using different protocols, i.e., Representational State Transfer
(REST) over HyperText Transfer Protocol (HTTP), and Message Queuing Telemetry Trans-
port (MQTT) [161]. (2) Behavioral interoperability refers to the system’s response when faced
with multiple requests. (3) Policy Interoperability ensures cloud systems comply and conform
to standards of stated regulations and policies. A huge cost penalty (upwards of $1Bn)
was identiﬁed in the U.S. automotive industry due to the lack of interoperability across its
supply network [162]. Interoperability is required to make complete integration possible.
Challenges associated with interoperability remain the main constraint to the full
realization of Industry 4.0 within the manufacturing industry. For example, enterprise
interoperability is major hurdle for many businesses that currently own expensive legacy
equipment. Some of these organizations are reluctant to replace these equipment with
Sensors 2022, 22, 5834
16 of 76
newer assets because of the additional replacement costs, though they are open to getting
the beneﬁts of Industry 4.0 if it is possible to retain their existing assets [149]. Achieving in-
teroperability in this case would require retroﬁtting these assets so that they can seamlessly
communicate (or talk) to other assets (machines and devices). The ability of these assets to
communicate with related assets within an industrial network is enterprise interoperability.
4.4.3. Consciousness
Consciousness is the state of being aware of oneself and one’s environment. In the con-
text of the Factory of the Future, consciousness speaks to the ability of a the factory and/or
its respective elements (i.e., machines, robots,sensors, actuators, conveyors, products, etc.)
to be able to connect and exchange information automatically with other components or
systems within their ecosystem. It also includes the capabilities of predicting the behavior
of connected systems, reacting appropriately, and optimizing the processes that take place
within and around them. To make all of these feasible, conscious factories (including all
related systems, machines, and products) need to be equipped with the capacity to monitor,
detect, and control events. A factory that is conscious would be able to (for example) sense
machine component degradation autonomously. It would also be able to predict (without
prompting) a machine’s remaining useful life. Such a system would be self-aware and
could self-predict, self-conﬁgure, self-maintain, and self-organize.
4.5. From the Automation Pyramid to a Decentralized and Distributed Network
The automation pyramid i.e., Figure 5 is a representation of the different layers or
levels of automation in a factory. It helps graphically capture the integration of differ-
ent technologies and the inter and intra-level communication pathways between them.
A classical automation pyramid has ﬁve-level control layers that include the data, services,
and functionalities which are hierarchical and relatively rigid.
Given the advent of Industry 4.0 and all the recent technological changes, the rigid,
hierarchical model would not be adequate to represent the facts on the ground. Current
manufacturing trends reﬂects a complete shift in paradigm from the previous era. Smart
devices are ubiquitous within the manufacturing space, making embedded intelligence
available at the extremities. The connectedness of assets is also unprecedented due to the
advent of networking via open and global information networks such as the Industrial
Internet of Things (IIoT) and the Internet making IT/OT convergence easier.
This level of networking was unavailable in previous automation technologies. With a
variety of devices and machines connected in a mesh, laterally, horizontally, or vertically, it
is difﬁcult to tell in advance what device, process, or subsystem will interact with another
and in what manner. More so, the existence of predictive analytics at the edges now
makes responsive control possible without the need for clearance from monitors or assets
domiciled in layers “higher up” in the automation pyramid. Cloud technology and virtual
twinning also enable visualization of control. With such a preponderance technologies, easy
adaptability of individual assets and an unprecedented increase in the overall intelligence
of the system are easily realizable.
The classical automation pyramid is insufﬁcient to represent these new realities, and it
must be stressed that this hierarchical model is all but outdated. The attainment of the
vision and goals of Industry 4.0 require more ﬂexibility in the interconnectedness and
communication between assets of different categories irrespective of the control layer to
which they are currently assigned. It is for these reasons and more that there has been
growing interest by scholars and practitioners in a gradual dissolution of the classical
pyramid and the introduction of a more decentralized and distributed framework that
would serve as an update or outright replacement of the classical automation pyramid [163].
Figure 8 shows one such model, laid side by side with the classical automation pyramid.
The need for the realization of the full potential of Industry 4.0 requires these changes.
Traditionally, IT-based enterprise systems (such as the ERP and CRM) and operational
Sensors 2022, 22, 5834
17 of 76
technologies (MES and SCADA) lived on different islands (i.e., different layers on the
automation pyramid) with a ﬁrewall separating them.
Figure 8. Classical automation pyramid laid side by side with a CPS-based automation model.
While this model has worked well so far, it underutilized the potential value that inte-
grating the two layers (and having them talk to each other) would have created. For exam-
ple, data on customer complaints or preferences, maintenance data, and user behavior data
typically captured with Customer relationship management (CRM) applications could po-
tentially be useful in product redesign or improvement for product designers if they could
have ready access to those through the enterprise resource planning (ERP) applications.
On the other hand, the ISA95 (IEC 62264) standards play an important role in the
Factories of the Future. Apart from the network infrastructure that connects the ofﬁce ﬂoor to
the plant ﬂoor, information needs to be moved around the system to support manufacturing
business and operations. ISA-95 is the framework that models this information. It deﬁnes
the interface between control functions and other enterprise functions. It is technology-
agnostic and is completely distinct from the network infrastructure that supports its ﬂow.
Table 1 shows the various standards aligned to the ISA-95.
Table 1. Standards aligned to the ISA95 model.
ISA95 Model Levels
Tools
Standards
Enterprise Level
ERP
ISO 15704 Enterprise Architecture Requirements
ISO 20140 Automation Systems and Integration
ISO 19439 Enterprise Integration
ISO 19440 Enterprise Integration
OAGIS
BPMN, DMN, PMML
B2MML
MOM Level
MOM
IEC 62541, IEC 62837
IEC 62264 (ISA 95)
ISO 22400
OAGIS
PMML
DMIS, QIF
Sensors 2022, 22, 5834
18 of 76
Table 1. Cont.
ISA95 Model Levels
Tools
Standards
SCADA Level
HMI/DCS
IEC 62541 (OPC UA)
IEC 61512 (ISA 88)
Modbus
BatchML, PACKML
IEC 62541 (OPC UA)
Device Level
Field Device
MT Connect
IEC 61158 (EtherCAT, PROFINET)
IEC 61784
Modbus/Proﬁbus
PROFlenergy
IEC 62591/HART
IEC 62541(FDI)
5. Conceptual Frameworks and Reference Architectures
Levis A. (2009) [164] described a reference architecture as a layout, blueprint, or sketch
that “provides current or future descriptions of a ‘domain’ composed of components,
and their interconnections, actions, or activities those components perform, and the rules or
constraints for those activities”. Another very practical description of a reference architecture
is that proposed in the Systems Integration for Manufacturing Applications (SIMA) Back-
ground Study [165]. It reads as follows: “A reference architecture (a) pinpoints the functions
required to accomplish a set of objectives in each domain, (b) identiﬁes the types of systems
[components] that perform, or support human agents in performing, the activities that
implement those functions and (c) points out the nature and content of the interfaces
required among those systems”. The point of the reference architecture is to identify the
activities and the information ﬂows required to accomplish required functions and to be
able to standardize said activities to ensure their efﬁcient and effective performance. Essen-
tially, a reference architecture is a toolbox packed with recommended structures, relations,
and integration designed to guide practitioners towards solution approaches that meet
accepted industry best practices. Reference architectures typically minimize complexity,
since they anticipate and addresses salient questions that would otherwise arise, thereby
enabling practitioners to accelerate model development and deployment. They are usually
deﬁned at different levels of abstraction. They provide a common lingo or vocabulary that
serves as the basis for shared communication during implementation, helping emphasize
commonality amongst users. Typically, reference architectures also provide templates,
reusable designs, and industry best practices that serve as scaffolds and building blocks
(i.e., LEGO pieces) for new solutions. They also provide the interfaces (or APIs) and serve as
frameworks for interacting with outside elements or functions that are related but outside
the scope of the architecture. There are several reference architectures and standardization
efforts that have been completed or are underway. Nation states, industry groups, and or-
ganizations have been at the forefront of these efforts. The multiplicity of these efforts has
thrown up a patchwork of reference models with gaps and duplications. The challenge is
that of developing a smart manufacturing reference model that maps to the other reference
models and considers the peculiarities and interests of all major stakeholders. An ISO
and IEC joint working group was created to develop a standard reference model of that
sort. Starting in 2017, a joint working group (ISO-IEC JWG21) between ISO/TC184 (Au-
tomation systems and integration) and IEC TC65 (industrial-process measurement, control,
and automation) commenced work to help develop a common reference model for smart
manufacturing [166].
Some reference models include the Reference Architecture Model Industrie 4.0 (RAMI
4.0, Germany) [167], the Industrial Internet Reference Architecture (IIRA) [168], IBM In-
dustry 4.0 Architecture (IBM) [169–171], Smart Manufacturing Ecosystem (SME) [172],
Sensors 2022, 22, 5834
19 of 76
Intelligent Manufacturing System Architecture (IMSA, China) [173], Industrial Value Chain
Reference Architecture (IVRA, Japan) [174–176], Smart Manufacturing Standard Landscape
(SM2) [166], Scandinavian Smart Industry Framework (SSIF) [166], KSTEP cube model
(KSTEP, Korea) [166], NIST Smart Manufacturing Architecture [166,177,178] (NIST, USA),
Scandinavian Smart Industry Framework (SSIF) [166], and ISO-IEC Smart Manufacturing
Standard Landscape (SM2) [166] . As the industry begins to consolidate around certain ref-
erence architectures, smart manufacturing solutions developers, whose solutions have not
been developed and implemented on industrially accepted reference architectures, might
be faced with adoption challenges beginning in the very near future [179]. At the moment,
there are several simultaneous standardization efforts, championed by different countries
and organizations, that have been completed or are underway. The multiplicity of these
efforts has thrown up a patchwork of reference models with gaps and duplication among
them. The challenge is that of developing a smart manufacturing reference model that
maps to the other reference models and considers the peculiarities and interests of all major
stakeholders. An ISO and IEC Joint Working Group was created to develop a standard
Reference Model of that sort. Starting in 2017, a joint working group (ISO-IEC JWG21) be-
tween ISO/TC184 (automation systems and integration) and IEC TC65 (industrial-process
measurement, control, and automation) commenced work to help develop a common
reference model for smart manufacturing [166]. At the moment, two of the most cited
reference architectures are the Industrial Internet Reference Architecture (IIRA) developed by
the Industrial Internet Consortium (IIC) and the Reference Architectural Model for Industry 4.0
(RAMI 4.0) (IEC PAS 63088) developed by the “Plattform Industrie 4.0” (Germany). Note
that the Industrial Internet Consortium (IIC) is now the Industry IoT Consortium (as of
August 2021). While these two architectures are very similar and interoperable, as can be
seem in different studies in the open literature [180,181], we will be using RAMI 4.0 to
illustrate the idea of a reference architecture. This reasons for this choice are its relatively
high popularity and the fact that it was the basis for the development of several other
important reference architectures. It has also been successfully mapped with nationally devel-
oped reference architectures, including those of USA (NIST), China (IMSA), Japan (IVRA),
and even the Industrial Internet Consortium (IIC) (i.e., IIRA), and successfully introduced
in most national and international standardization committees and co-operations.
5.1. The Reference Architectural Model Industrie 4.0 (RAMI 4.0)
RAMI 4.0 [182,183] is a reference designation system that describes Industry 4.0’s space
using a cubic layer model. Quite simply, RAMI 4.0 is an architecture model of different
elements of Industry 4.0 (i.e., information technology (IT), manufacturing, and product life
cycle) integrated into a 3D layered model. The model makes it possible for the multiple
elements and different internal connections within the Industry 4.0 ecosystem to be broken
up as smaller subsystems and clearly represented in 3D [184,185].
Developed as part of the Platform Industrie 4.0 [167] working group’s standardization
efforts for Industry 4.0, RAMI 4.0 is a three-dimensional (3D) map that integrates several
elements and concepts of Industry 4.0 and how they relate to one another [186]. Different
components of the model are abstracted and linked to established automation standards,
such as IEC 62264, IEC 62890, and IEC 61512/ISA95. The model provides insight on how
to approach the deployment of Industry 4.0 in a structured manner. It can be used to
illustrate the different elements within the Factory of the Future, including classiﬁcation,
categorization, and logical groupings that provide insight on connections and potential data
and information routes. As a communication tool, it provides stakeholders a framework for
a common understanding and the exchange of ideas about the design and development of
Industry 4.0-based systems. The RAMI 4.0 model cube shown in Figure 9 you provides three
main axes for the dimensions of: (a) product life cycle and value stream (horizontal axis,
left), (b) hierarchy levels (horizontal axis, right), and (c) interoperability layer (vertical axis).
Sensors 2022, 22, 5834
20 of 76
Figure 9. Reference Architectural Model Industrie 4.0 (RAMI 4.0). Source: Plattform Industrie 4.0.
5.1.1. Horizontal Axis (Right)
The horizontal axis is orthogonal to the Life Cycle and Value Stream axis, and repre-
sents a hierarchy model of cyber-physical systems (CPS) management based on functional
considerations on a layer-by-layer basis. It stems from the international standard(s) IEC
62264/IEC 61512. The hierarchical layers were adopted from the classical automation
pyramid with enhancements that introduced the Product and Connected World categories
at the beginning and end of the layer stack, respectively. Level 0 represents intelligent
products. Level 1 and 2 are associated with the control and automation of the factory ﬂoor;
Level 3 is related to the management of manufacturing operations; Level 4 corresponds to
business planning and logistics; Level 5 is decision making systems at an enterprise level;
Level 6 is related to connections to the cloud and interactions with (external) entities and
associated stakeholders. The individual elements can be further described as follows:
(a)
Level 0 (Products): Refers to intelligent (communicating) products. They can interact
with users and makers with or without embedded sensors, labels, or tags. Data pulled
from these products enable product enhancement, maintenance, and future design im-
provements. Conversely, data can also be pushed to the products (example updates).
(b)
Level 1 (Field Device): The functional level comprising intelligent devices that enable
smart and intelligent control of machines and systems. It includes sensors, actuators
and all other devices required to protect, control, and monitor manufacturing systems
and processes. Process and machine health data can be pulled from these assets.
Actionable information can also be pushed to some (e.g., actuators).
(c)
Level 2 (Control Device): Represents industrial control systems that are responsible
for the logical control of ﬁeld devices. Examples include distributed control systems
(DCS) and programmable devices, prominent among which are the programmable
logic controllers (PLCs).
(d)
Level 3 ((Work Unit OR Station): A lower-level element in the manufacturing architec-
ture where production planning and scheduling (including supervision of machines)
based on events and processes are performed. This is usually done using supervisory
control tools such as supervisory control and data acquisition (SCADA).
Sensors 2022, 22, 5834
21 of 76
(e)
Level 4 (Work Centers): Work centers are the highest-level manufacturing elements that
perform and manage end-to-end manufacturing processes and functions, including
planning, scheduling, and production activities. They typically include process cells,
production units, production lines, and storage zones. Management execution systems
(MES) and manufacturing operations management (MOM) applications are used to
build traceable records of the manufacturing process, build supply chain visibility,
and keep track of information of everything from labor to materials, machine health,
product shipment, and job orders.
(f)
Level 5 (Enterprise): Strategic business decisions are made at this level. Enterprise
resource planning (ERP) tools are commonly used. The enterprise is a collection of
business functions operating together to set and implement and manage the realization
of strategic business imperatives.
(g)
Level 6 (Connected World:) This level is one of two enhancements to the traditional
automation pyramid. It is the level that enables connection to super-ordinate cloud
services, the Internet of Things (IoT), and the Internet of Services (IoS), helping link
assets in one organization to the assets in external organizations. The ﬂow of data
from the shop ﬂoor to plant operating systems (MES), business systems (enterprise
resource planning, ERP), and then the external world (e.g., other smart factories or
external elements of the value chain or supply chain).
5.1.2. Horizontal Axis (Left)
This axis represents life cycle and value stream and is based on IEC 62890 (i.e., life-
cycle management for systems and products) used in the industrial-process measurement,
control, and automation domains. It is focused on product life cycle and value stream.
The product life cycle captures the various stages a product undergoes, from its develop-
ment to when it is decommissioned or removed from the market. Value stream encompasses
all the actions or activities that culminate in the addition of value to a customer, from the
initial request to value realization. This axis emphases the extraction, processing, and uti-
lization of product life cycle information in addition to data capturing and utilization
from all activities that culminate in value creation. This information be captured through
digital representations of objects (products) using an administrative shell, an Industry
4.0 component. More on the administrative shell is in Section 7.1. The axis divides the
product development and the usage process into a type and an instance phase. One of
the design premises for type and an instance phase are the data type that can be captured
during each phase. When an asset (e.g., product) is in the development phase (i.e., idea,
research, design, development, testing, or analysis) it is in the type phase. As soon as it is
production (physically produced) or service, it becomes an identiﬁable entity of that type
and is transitioned to the instance phase. Once it transitions into production or service, it is
in the instance phase. The point of the delineation of the phases is that different data types
would need to be collected in different phases. For example, the necessary data required
during the research and development of a product (say a car) would be different from those
that need to be collected during its production or operation (i.e., while in use or in service).
An asset can be said to be in its type phase during its design (research and development).
Throughout the life of the asset, it is important that the relationship between the type
and its instances is maintained (i.e., an instance of the asset might be required to mirror its
type). Different data would need to be collected from the product at different phases in its
existence. Software products are a particular example where updates on the type are often
transmitted to the instance.
5.1.3. Vertical Axis
The vertical axis represents the six interoperability layers [184,185]. The interoperabil-
ity of the two horizontal components (left and right horizontal axes) can be considered
in the context of these six interoperability layers. As an information and communication
technology (ICT)-based representation system, it establishes a model for facilitating and
Sensors 2022, 22, 5834
22 of 76
implementing new features and choreographing the ﬂow of data between different layers.
The ﬁrst three layers (Business, Functional, and Information) are related to functionality,
and the lower three layers (Asset, Integration, and Communication) are associated with
technical implementation. The interoperability layers are described as follows:
(a)
Asset Layer: The aggregation of all physical instances of assets and components
required to provide functionality to the system. This would include physical objects,
such as sensors, actuators, and devices. It would also include humans, products,
plans, documents, applications etc.
(b)
Integration Layer: This layer manages the digital representations of physical assets
and is responsible for the transitions from the physical to the digital world. It contains
asset documentation, applications, and assets (i.e., HMI devices, QR-code readers,
sensors, control systems, etc.) that manage the transitions, generate events from assets
(e.g., equipment and machinery), and provide computer aided control of technical
processes, system drivers, and other collaterals.
(c)
Communication Layer: Responsible for data integration and standardization of
communication between the integration and the information layers. This layer in-
cludes standards, communication protocols, and services that support interoperability
and integration.
(d)
Information Layer: This level manages and stores data in an organized fashion. It
is associated with data services and standards that regulate the ﬂow and exchange
of information between components, services, and their functions. It also ensures
consistency in the integration of different data formats and interoperability between
components and services.
(e)
Functional Layer: This layer is responsible for production rules, decision making
logic, and the provisioning and management of the run time and modeling envi-
ronment for services that support business processes. It also hosts the descriptions
of functions and supports remote access serving as a platform for the horizontal
integration of various components and functions.
(f)
Business Layer: This level maps out the business model, links the various business
processes, and hosts the business rules that the system must follow. Said rules are
based on information drawn from the value stream, the supply chain, the regulatory
regime, and subsisting laws. It also orchestrates (or arranges) services in the functional
layer and receives events that help track the progress of business processes. Standard
run-times for executable business processes are essentially provided in both the
Functional and Business layers [187].
Notwithstanding its acceptance, RAMI 4.0 has not be widely implemented within
industry. However, it has made a lot of in-roads within research and academia. To better
illustrate the its utility, a few implementation examples and use cases have been included
from the open literature [175,188–193].
6. Communication Standards and Technologies of the Future
The Communication Layer and the ISO/OSI Layers: The communication layer is only
one of six layers in the vertical axis of the reference architectural model Industrie 4.0
(RAMI 4.0) [182,183]. Further treatment of this layer is being provided because of its
relevance. It can be considered a crucial aspect of the factory because it provides the
protocols and mechanisms necessary for the standardization of communication between
different networked elements.
The goal of this layer is to arrive at a uniﬁed data format that ensures interoperability
and to provide interfaces that can support data access: an outcome that would solve a
protracted bottleneck that has stymied Industry 4.0 adoption. As the communication layer
is heavily IT focused, it is complemented by the seven-layer International Organization
of Standardization/Open System Interconnection (ISO/OSI) model. Figure 10 shows a
graphical illustration of the seven OSI layers. The ISO/OSI model is a popular IT reference
model that deﬁnes the seven levels in a complete communication system.
Sensors 2022, 22, 5834
23 of 76
Figure 10. The seven OSI layers.
To enable multi-vendor interoperability and integration, it has adopted or recom-
mended certain open communication technologies or standards for each layer (refer to
Figure 10. Below we focus on only three that we think will have the most signiﬁcant
impact on the Future Factory. These include (a) The Open Platform Communication Uniﬁed
Architecture (OPC-UA), (b) Time-Sensitive Networking (TSN), and (c) the 5th Generation Mobile
Network (5G).
6.1. Open Platform Communication-Uniﬁed Architecture (OPC-UA)
Though not explicitly mandated, the Open Platform Communication Uniﬁed Ar-
chitecture (OPC-UA [IEC 62541]) protocol [194] is RAMI 4.0’s recommended approach
for implementing this layer due to its stability, scalability, and superior performance.
The recommendation, beyond being very practical, has also received numerous endorse-
ments [195–199] from stakeholders. As the standardized interface for communication
between numerous data sources, the OPC-UA has become the de facto communication
technology standard for many applications (both in industry and in academia) and is the
focus of on-going research [200,201]. Some great characteristics of OPC-UA are that it is
technology-independent, implements standard network protocols, and allows for easy
integration into pre-existing IT networks. It also satisﬁes standard communication security
requirements, supporting secure communication over VPN and across ﬁrewalls, through
which it can establish seamless client-to-server connectivity.
6.2. Time-Sensitive Networking (TSN)
The OT systems used in many factories require specialized networks and protocols.
Conversely, IT systems are typically general-purpose technology that rely on Ethernet
networks. The unpredictable trafﬁc patterns of the Ethernet-based “best effort” approach is
unsuitable for handling time-critical data. The real-time transmission of critical data (e.g.,
process data) that is necessary for real-time control within the industrial domain requires
latency guarantees that are not always available from Ethernet networks. The cycle time for
transmission of time-critical data can be very minute, or sometimes as small as one second.
This disparity in standards and protocols often creates complications that signiﬁcantly
impact IT/OT integration efforts. There is also the problem of data volume and veloc-
ity. With the ubiquity of devices and sensors today, the amount of data running through
some factories daily is enormous, sometimes overwhelming networks and storage sys-
tems. Though several real-time communication methods (such as Proﬁnet IRT, EtherCAT,
and SERCOS III), have been applied to address some of these problems, time-sensitive
networking (TSN) is clearly a better alternative. Not only does it close the technical gaps
between IT and OT, but it also addresses most other underlying challenges that have
bedeviled the industry for a long time. TSN is an adaptation of the Ethernet IEEE 802.1
standard. It was designed to support time-sensitive networking and enables real-time,
deterministic communication between networked assets. Figure 11, an adaption of the
Sensors 2022, 22, 5834
24 of 76
work of the Time-Sensitive Networking (TSN) IEEE 802.1 Task Group illustrates the four
main characteristics of TSN and the common standards in each category. The four main
components or characteristics of TSN include (1) resource management, (2) synchroniza-
tion, (3) reliability, and (4) latency. These characteristics deliver several beneﬁts, some of
which include: (a) Support for time synchronization; i.e., all networked resources have a
shared time reference. It is well-suited for the real-time control and the synchronization
of high-performance machines, plus it offers solutions for efﬁciently managing network
infrastructure with high bandwidth requirements. (b) Support for trafﬁc scheduling (i.e., all
networked resources observe the same rules for processing and forwarding packets within
speciﬁcally reserved time slots). With this arrangement, different data trafﬁc streams can
be transmitted from a single standard open Ethernet network without any delays. (c) The
ability to merge multiple industrial networks, including TCP/IP trafﬁc, into one single
physical wire. (d) The ability of mechanisms to temporarily interrupt the transmission of
regular Ethernet-based trafﬁc (i.e., based on the best-effort approach) to offer priority to
critical data that are necessary gaining time-sensitive insights into processes and assets.
(e) The ability to map across both the physical and data link layers, thereby reducing com-
plexity and making implementation/management easier. (f) Compatibility with general
purpose IT standards. TSN is a special type of Ethernet, and it is compatible with most
IT systems. Its functionalities can be integrated into one standard open Ethernet network
capable of supporting devices from different vendors, thereby ensuring interoperability
and integration.
TSN Components (Common Standards)
Latency
Frame Pre-emption (802.3br & 802.1Qbu)
Cyclic Queuing & Forwarding (802.1Qch)
Asynchronous Traﬃc Shaping (802.1Qcr)
Credit-based Shaper (802.1Qav)
Schedule Traﬃc (802.1Qbv)
Resource Management
Link-Local Registration Protocol (802.1CS)
Stream Reservation Protocol (802.1Qat)
TSN Conﬁguration (802.1Qcc)
YANG (802.1Qcp)
Reliability
Frame Replication & Elimination (802.1CB)
Per Stream Filtering & Policing (802.1Qci)
Reliability for time sync (802.1AS-Rev)
Path Control & Reservation (802.1Qca)
Synchronization
Timing & Synch. (802.1AS)
Figure 11. TSN components.
6.3. 5th Generation Mobile Network
The growing data trafﬁc and bandwidth demands that are currently outstripping the
ability of 4G (LTE) to cope because of the proliferation of smart devices, IoT devices and
sensors, etc., is creating the need for ultra-low end-to-end latency in a variety of industries,
including automotive and industrial automation industries [202]. The ability of 5G to de-
liver on these metrics is putting 5G in play within the industrial environment. 5G provides
end-to-end, ultra-reliable, and ultra-low latency connections [203,204], which can help
improve network efﬁciency in these settings. Several reviews [205–215] of 5G technology
exist in the open literature. The convergence of 5G, AI, and IoT will result in major transfor-
mations in industrial control and factory monitoring (i.e., condition monitoring and failure
prediction). With fast, efﬁcient cloud-native 5G connections, factories can strategically
redistribute computational power to allow for fast collection and processing of data with
rapid AI inference at the edges. On the other hand, networked devices and applications
can easily and reliably tap into edge resources without needing to access the core network.
The analysis of industrial processes can also be performed with high degrees of precision,
allowing for swift decision making whenever necessary. Given 5G’s promise of extremely
low latency (no jitters) and high data rates for video transmission, there is an expectation
of signiﬁcant growth in innovation around the development of immersive and integrated
media applications (e.g., mixed reality (MR), augmented reality (AR), and virtual reality
(VR) applications which are becoming ubiquitous on the shop ﬂoor and beyond).
The 3rd Generation Partnership Project (3GPPTM) is a joint project that brings together
several national standards development organizations (SDOs) with the goal of developing
technical speciﬁcations for third generation (3G) mobile systems. The three main service
Sensors 2022, 22, 5834
25 of 76
categories for 5G New Radio (NR) as deﬁned by the 3GPPTM are as follows: (a) Enhanced
Mobile Broadband (eMBB), (b) Ultra-Reliable Low-Latency Communications (URLLC),
and Massive Machine-Type Communications (mMTC).
(a)
Enhanced Mobile Broadband (eMBB) services are geared towards applications that
require high data rates across a wide coverage areas. Compared to 4G, they can
handle large payloads and are stable over an extended time interval. Complimentary
deployment of Enhanced Mobile Broadband (eMBB) alongside existing 4G broadband
services could enable substantial improvements in trafﬁc and the efﬁciency of the
industrial network at the core network level.
(b)
Ultra-Reliable Low-Latency Communications [URLLC] is almost deterministic in time
bounds on packet delivery. It is ideal for applications that require end-to-end security
and where reliability and speed are critical, though bandwidth might not be as much.
Mission-critical applications that require quick reaction times would fall into this
category. As 5G URLLC delivers ultra-low latency and guarantees against triggering
undesirable safety stops in production lines, it has been employed in automating
factory processes and related power systems. For example, it has been used to
run industry technical standards such as PROFINET. Industrial robots have become
ubiquitous on manufacturing ﬂoors. The transmission of time-critical communication
messages to them using Ultra-Reliable Low-Latency Communication (URLLC) might
be necessary to accommodate for instances where decision time for responding to
an incident or accident is almost non-existent. Combining 5G and MEC results in
a signiﬁcant reduction in network latency, which can improve the performance of
previously tethered-only AR/VR, haptic, and tactile-based applications.
(c)
Massive Machine-Type Communications (mMTC) is a service that provides mainly wire-
less connections to massive numbers (tens of billions) of network-enabled devices that
intermittently transmit payload sizes (small data packets) at low trafﬁc [216]. While
low transmission latency is not a requirement, it has low latency, is secure, is reliable,
and is scalable. As mMTC transmit small payload sizes at low transmission rates and
frequencies, they require lower energy consumption, making them well suited for
battery powered, low maintenance end devices (i.e., low-cost sensors, smart meters,
wearables, trackers, diverse monitoring devices, etc.). NB-IoT (narrowband IoT) and
Cat-M1 (operated at 1.4 MHz bandwidth) are two 3GPP standardized technologies
that support these network-enabled devices. NB-IoT supports ultra-low complexity
devices with very narrow bandwidth and data rate peaks of approximately, around
200 kHz and 250 kbs per second, respectively. Conversely, Cat-M1 supports relatively
more complex devices and operates at a bandwidth of 1.4 MHz, with lower latency
and better location and asset tracking capabilities. Both can also sleep for extended
periods and maintain excellent power-saving mode (PSM) abilities and extended
discontinuous reception [217].
5G can also be integrated with other communication standards for improved effects.
For example, to exact the optimal impact on industrial IoT services and wireless industrial
networking, 5G is best integrated into the Ethernet-based industrial network with TSN.
While dedicated to the control of data communication (synchronization and data stream
prioritization), TSN can also help forward critical process data, ensuring that they arrive in
time at different end points within the network. On the other hand, 5G can be dedicated to
the transmission of non-real-time-capable data (i.e., monitoring, predictive maintenance,
and energy optimization-type data, etc.).
7. Realizing the Promise of Industry 4.0 through the Digitization of Physical Assets
It is the case that there are often differences in device/equipment types (makes, models,
age e.g., legacy equipment), communication protocols employed, and interactions between
hardware, communication technologies, networking devices, and applications within
factories. Due to these differences, making all entities (equipment, devices, applications,
etc.) seamlessly talk to each other can be prohibitively difﬁcult. Relying on a vast array
Sensors 2022, 22, 5834
26 of 76
of sensing devices, communication facilities, and services [218], these disparate systems
generate and use large amounts of diverse and sometimes complex data types to perform
various functions. Building systems that effectively store, manage, and analyze these
data and ensure valuable use can be daunting. Two main hurdles need to be crossed to
make this happen. First, all assets need to be physically connected. That feat has been
achieved using technologies such as OPC-UA [219] (further discussed in Section 6.1 and
related technologies such as Proﬁbus/Proﬁnet [220]. The second challenge is making all
devices, irrespective of the “language” they speak, to both communicate and understand
one another. As has been acknowledged in earlier sections of this paper, one of the
key goals of the Industry 4.0 era is the digitization of industrial systems and processes
with a view to harnessing intelligence from them to help improve operational efﬁciency,
productivity, and value. However, the digitization of manufacturing systems requires the
efﬁcient connection of all assets within the production network and the seamless exchange
of data between assets. It also requires the development of information models that
can accurately describe all assets and information sources to enable semantic integration
and interoperable exchange of data between all assets [221]. The development of robust
data/information models is critical to realizing some of the more creative goals of the
Factory of the Future, such as plug-and-play automation of production modules, easy
reconﬁgurability of production systems to cater to small batch production of customized
products, and self-organization of the production line. The Factory of the Future, as a
highly dynamic environment, will feature ﬂuctuations in the number and variety of nodes
(assets). With the right technologies in place, adding, removing, rearranging, retroﬁtting,
or upgrading a network of assets would not be a hassle [222].
The practical significance of AAS is large, as it can be used to transform a factory into an
easily re-configurable manufacturing system (also known as plug and produce) [223,224] that
is flexible [225] and is capable of dynamically orchestrating and allocating resources [226]. It
can also have significant implications for preventive maintenance [227], product customiza-
tion, and the design and development of upgradable production lines and order-controlled
production. Implementing the AAS paradigm within a factory can make integration faster.
It can also mean faster ramp-down and ramp-up of production lines, and maximization of
production efﬁciency throughout the life cycle of a plant [228].
Though the promise of the digitization of production (Future Factory) is very com-
pelling, there is still concern about how to implement these ideas in concrete terms using
available technologies, techniques, and standards. It is instructive that whatever techniques
and standards are adopted must be ﬂexible enough to accommodate different device cate-
gories (age, variety, and types), application domains, and use cases, and must be able to
transcend organizational boundaries [229]. RAMI 4.0 and Industry 4.0 components are two
important and complementary constructs of Industry 4.0. They are both described in the
Reference Architecture Model Industrie 4.0 (DIN SPEC 91345) [167]. Section 5.1 provides
more details about RAMI 4.0. Industry 4.0 components, on the other hand, are made up of
two main parts: (1) the assets and (2) the asset administration shell (AAS). This is further
discussed in Section 7.1.
7.1. Industry 4.0 Components: Assets and the Asset Administration Shell (AAS)
I4.0 components (and especially asset administration shell (AAS)) is Industry 4.0’s
recommendation for tackling the aforementioned implementation challenges. The entire
idea of the I4.0 components is to encompass every asset within an administration shell.
7.1.1. Key Elements of Industry 4.0 Components:
Some of the key concepts or elements of Industry 4.0 components are outlined below:
(a)
Asset: An asset is anything (physical or non-physical) within the production system
that requires a connection to another asset or an Industry 4.0 solution, e.g., simple
devices, components, machines, assembly lines, or even entire production systems.
Other examples of assets include automation components, services, and even ap-
Sensors 2022, 22, 5834
27 of 76
plications/software platforms. Each asset within the production system must be
identiﬁable to the system (in the ﬁrst instance), and to all other assets (including
devices, systems, and services). To be considered compatible, each asset must have
a set of deﬁned properties and must be able to collect and share all relevant data to
similarly networked entities (other assets; stakeholders, e.g., companies participating
both in the value and supply chains) throughout its lifecycle. This means they each
need to read, interpret, and understand all asset data, including identity (asset type,
model number, etc.), operational status, and all other asset-related data.
(b)
Asset Administration Shell (AAS): Industrie 4.0 recommends the asset administration
shell (AAS) as an important building block of the Factory of the Future [75,186,230,231].
Multiple articles in the literature provide reviews on asset administration shells
(AAS) [232,233]. The asset administration shell (AAS) is a mechanism for digitally
representing physical assets and other abstract entities. In practice, it helps provide
descriptions of the properties and capabilities of an asset and serves as a platform for
interaction between the asset and other assets.
As an industrial application, a digital twin (DT) helps transform an asset to its digital
equivalent, serving as a bridge between a tangible asset and the virtual or IoT world.
A typical AAS holds identifying, operational, status, and technical information about
the asset it represents, over its lifetime. It contains the communication methods
and stores all asset related data [149]. Some of the information the AAS stores is
related to the conﬁguration of the asset, its maintenance record, or data related to its
connectivity with other devices. Diagrammatically, an asset is enclosed within an asset
administration shell (AAS), as shown in Figure 12.
Each asset in the production system has its own administration shell, i.e., Figure 12.
Two or more assets can be grouped into a unit [234]. The unit (much like an individual
asset) can map to its own administration shell. A common administration shell i.e.,
Figure 13 can be used to manage the communication of multiple asset administration
shells (AAS) at a higher hierarchical level. The conﬁguration shown in Figure 14 is
also suited for Factory-to-Factory communication. This architecture can allow the
transparent and seamless ﬂow of data between sister factories and other associated
assets within a value or supply chain Figure 15 shows a different conﬁguration of
assets, each mapped to its own administration shell, and connected to other assets
through open communication protocols to facilitate the seamless ﬂow of data
Beyond acting as a store for important asset data, the AAS also serves as a reliable and
consistent mechanism for managing data and related functions and services.
Figure 12. AAS showing an asset (3D Printer).
Sensors 2022, 22, 5834
28 of 76
Figure 13. Common intra-factory asset administration shell.
Figure 14. Common inter-factory (factory-to-factory) asset administration shell.
Figure 15. A network of assets wrapped in their AAS.
Sensors 2022, 22, 5834
29 of 76
7.1.2. The Anatomy of an Asset Administration Shell (AAS)
The Asset Administration Shell (AAS) is composed of a body and a header. Refer to
Figure 16, a metamodel of a typical (3D Printing machine) Asset Administration Shell (AAS).
The header contains identifying information that precisely describes the asset administration
shell and the represented assets, plus related asset utilization information. High-level
asset-related information stored in the header would include the asset descriptions, serial
numbers, manufacturers’ identiﬁcation, etc.
Figure 16. AAS metamodel for a 3D printer.
Other information could include information about the usage of the asset, its sub-
components, and other high-level details about the administration shell. The body, on the
other hand, contains information about the assets. It has two parts: a manifest and a
component manager. The manifest serves as a directory that lists different sub-models.
Sub-models (or partial models) are important features of the administration shell that
represent different aspects of the asset they represent; each sub-model is standardized
for each aspect of the asset, e.g., a description or capability of the asset. Each sub-model
contains a structured quantity of hierarchically organized properties that refer to the asset’s
data and functions (or capabilities). The properties have a standardized format based on
IEC 61360. On the other hand, the component manager (or resource manager) administers
the sub-models and helps link the information coming from the asset administration shell
(AAS) to the larger asset network through the Industrial Internet of Things (IIoT).
7.2. Seamless Transfer of Data: OPC-UA, AAS, and Companion Speciﬁcations
Data exchange between entities in an industrial network is a critical feature of the
Future Factory. The Open Platform Communications Uniﬁed Architecture (OPC UA) is an
important technology for machine-to-machine communication. It deﬁnes data transport
protocols and standardizes information modeling; however, OPC UA communication
alone is not sufﬁcient for seamless data exchange. Before OPC UA communication can
effectively occur, the content of the data to be exchanged must be clearly deﬁned. To make
communication feasible and seamless, companion models need to be mapped onto OPC UA.
OPC UA does not deﬁne data content but only serves as a framework for the description of
the meta model. Though OPC UA deﬁnes a base information model, the actual deﬁnition of
the data content for different domains is achieved using companion speciﬁcations or meta
model, of which there are several (40+). Companion speciﬁcations make the deﬁnition of
standardized exchanges possible within the framework of speciﬁc business functions. These
domain-speciﬁc models make it easier to achieve interoperability between equipment and
devices from different vendors. Companion information models follow standard syntax
described in XSD ﬁle (XML Schema Deﬁnition), and therefore present data in a form that
can be read by a computer program.
One such companion speciﬁcation is AutomationML, which focuses on the engineering
of automation systems. Thus, an implementation for a I4.0 components and its asset
Sensors 2022, 22, 5834
30 of 76
administration shell could potentially involve a technology combination involving the OPC
UA (IEC 62541) and AutomationML (IEC 62714).
Within a typical manufacturing environment, there are different kinds of equipment
from a diverse range of manufacturers, creating a situation where multiple communication
protocols are in play within the asset pool. This creates communication problems for enter-
prises if the goal is IIOT integration (i.e., networking the assets and having them “talk” to
one another), because until recently, different companies relied on different communication
protocols and applications which were not interoperable. OPC-UA was created to solve this
problem. and the adoption rate by industry has been impressive. It provides the additional
beneﬁts of secure communication (encryption and authentication) and a standardized
interface. OPC-UA solves the operational technology (OT) communication conundrum.
The Future Factory integrates previously independent and discrete systems transform-
ing them into a complex whole. It is literally the convergence of operational technology
(OT) and information technology (IT). There must be a way to connect OT to IT. However,
the IT and OT domains have signiﬁcant differences, and there are unresolved integration
and knowledge transfer challenges that need to be resolved. That is where the asset admin-
istration shell (AAS) comes in. It is the software/ﬁrmware component that transforms the
physical assets into digital ones (or Industry 4.0 assets). That data content stored in the AAS
is developed using the companion speciﬁcation (i.e., AutomationML). The combination of
OPC-UA and the AAS helps eliminate the discontinuity between the layers (OT and IT),
enabling the seamless ﬂow of data/information. Refer to Figure XYZ02 below.
7.3. Data Exchange: The Administration Shell and the Semantic Web
The AAS provides a consistent way of storing and managing all asset data, functions,
and services so that they are readily available for manipulation, publication, and exchange
between all network participants as required. Once connected, the AAS serves as a stan-
dardized and secure communication interface for sharing data and information about the
asset’s identity, operations, and status with the production system’s network. Using a
standard such as AutomationML, the AAS can be mapped to OPC UA, MQTT, or other
formats [188]. Due to its standardized design, AAS can integrate the knowledge and
semantics of multiple domains together, to help achieve component and cross-company
interoperability across the entire value stream.
Though the current data exchange process for many manufacturing applications
has greatly improved due to the use of predeﬁned structures and keys, any real-world
implementation is still dependent on laborious manual work. It requires a robust un-
derstanding of the AAS model, an appreciation of multiple terms/values, and time-
consuming/laborious data mapping [235]. To alleviate the burden, some scholars [236]
have recommended building a connection between current manufacturing-based data
provisioning models (such as AAS) and the semantic web. Great reasons to consider this
option is that sematic web representation formalisms such as RDF, RDF Schema, and OWL,
are more matured, have more advanced data integration and formalization capabilities,
and have the capacity to introduce logical reasoning to the asset administration shell (AAS).
For these reasons, information models developed using these frameworks would be use-
ful additions to information exchange systems [235] such as AAS. RDF and linked data
principles have been successfully used to integrate different data types [237–239]. They
are the basis for the development of semantic solutions or information models that have
proved effective for seamlessly linking I4.0 components with generated data [240], hence
helping improve the interoperability of production assets. To promote data exchange and
enable semantic interoperability, RDF-based information models are aligned to important
industry standards, such as RAMI [186] and IEC 62264 [241]. As a resource description
framework (RDF), a standard model for data interchange on the Web makes the generation
and transmission of data across networks easy. An additional beneﬁt of RDF is that it makes
data readily available on a standard interface using SPARQL3 (an RDF query language).
A group of researchers [236] proposed adding a semantic layer to the administrative shell.
Sensors 2022, 22, 5834
31 of 76
As part of the proposal, the RDF is included as a middle layer that can be deployed to
support interoperability between the data generated from both I4.0 components and legacy
systems. The researchers envision the establishment of RDF as a common communication
language (lingua franca) between assets within Industry 4.0.
8. Key Building Blocks, Technology Enablers, and Innovation Accelerators
Though many organizations now aspire to upgrade their manufacturing and business
operations into full-scale Factories of the Future, knowing where to start or even what
makes for an Industry 4.0-compliant factory is not always clear-cut. The fact remains
that applications or instances of the Future Factory are process-speciﬁc, and therefore vary
from one industry to another. However, there are certain elementary units or common
building blocks that show up in one form or the other in most conﬁgurations of these
factories. The number and variety of building blocks that constitute a speciﬁc Future Factory
conﬁguration will depend on the industry, and the unique process applications a company
seeks to improve or optimize with its operations and processes. Understanding these key
elements can prove helpful in properly characterizing Future Factories and smoothing the
transition for industrial adopters. Figure 17 shows some of the most important core and
periphery building blocks (or elements) of the Future Factory.
8.1. The Core Elements of the Factory of the Future
In the opinion of the authors, the trio cyber-physical systems (CPS), Industrial Internet
of Things (IIoT) and digital twins (DT) constitutes the bare-bone elements of the current
Factory of the Future. As will be shown later, several other technologies (including the cloud,
artiﬁcial intelligence, AR/VR, blockchain, etc.) can be wrapped around these to extend
the functionality, resilience, and integrity of the core elements or systems. Cyber-physical
systems (CPS) and the Internet of Things (IoT) both enable end-to-end connectivity and
support the transmission, transformation, and storage of data/information across different
levels of the factory. The similarities and differences between CPS and IoT have been the
subjects of many debates within the research community. NIST [242] performed an exten-
sive review of these debates based on several references in the open literature [243–248].
On the other hand, digital twinning enables the virtualization of the system to enable
data and information cloning and seamless transmission and manipulation. Based on our
analysis, the three foundational elements of the factory of the future are: (i) cyber-physical
systems (CPS), (ii) Industrial Internet of Things (IIoT), and (iii) digital twins (DT). These
elements are further discussed below:
Figure 17. Building blocks.
Sensors 2022, 22, 5834
32 of 76
8.1.1. Cyber-Physical Systems (CPS)
Baring the development of some more advanced system, the cyber-physical system
(CPS) will be a central feature of the Factories of the Future. The Factory of the Future is
essentially a network of cyber-physical systems (CPS). They bridge the cyber and physical
worlds seamlessly. In CPS, computational and physical systems are intertwined, with the
interaction between the duo being a convergence of computation, communication, and con-
trol. They also integrate sensing, control, networking, and computation into physical
objects and related infrastructure [249]. The roles and uses to which they can be applied
are virtually endless. Though things can get very complex, very quickly, multiple CPS
can be combined into a super CPS or what can be referred to as a system of systems (SoS).
CPS have been variously deﬁned: One deﬁnition is that they integrate computation with
physical processes, where embedded computers and networks monitor and control the
physical processes [249]; and the behavior of the system is deﬁned by both computational
and physical components [250]. Rajkumar et al. referred to them as physical and engineered
systems whose operations are monitored, coordinated, controlled, and integrated by a
computing and communication core. They have also been referred to as hybrid systems
that are simultaneously computational and physical [251]. Though there are different
interpretations of what constitutes a cyber-physical system (CPS), there is nonetheless an
agreement that they are the result of the integration of a computing nucleus and physical
systems; and the computing core, like a central intelligence entity, orchestrates (monitors,
coordinates, and controls) the operations of all elements’ nodes and entities within the
physical or engineered system. In recent times, cyber-physical systems have permeated
several elements of modern life.
There are multiple applications of CPS in a wide variety of industries. Some of these
applications can be seen in self-driving cars, smart grids, robotic systems, unmanned aerials
vehicles, advanced industrial control systems, and automatic pilot avionics [252]. In the
case of the self-driving car, also known as the autonomous vehicle (AV) or driverless car,
the computational core and the physical elements of the system are seamlessly incorporated
to achieve the effective monitoring, coordination, and control of the vehicle. As a complex
CPS, the vehicle combines a wide variety of physical nodes or sensors (GPS, radar, sonar,
odometer, etc.) to perceive its environment. The sensory data collected from these physical
assets are then analyzed and interpreted by advanced control systems to help identify
suitable navigation paths and avoid collisions autonomously. Some autonomous control
systems have even been able to make control decisions through knowledge acquired from
steering patterns of human drivers acquired from video feeds from mounted-cameras and
basic GPS-like maps. The seamless interaction of diverse components of the self-driving car
to create value with little or no human intervention is a model for what is possible in the
Future Factory (FF). Another relatable example is the smart phone, a mobile cyber-physical
system which is a sub-class of cyber-physical systems. The smart phone is a composition
of independently interacting physical components and a computing and communication
core. The operations of the smart phone are monitored, coordinated, controlled, and inte-
grated by the computing and communication core. The computational resources include a
robust processing capacity with a local storage facility. Plus, there are the mobile operating
system and smart phone applications. The physical components include several sensory
input and output devices, such as cameras, GPS chips, touch screens, speakers, micro-
phones, light sensors, and proximity sensors. The sensors gather distributed intelligence
about the environment, including monitoring physical and cyber-indicators such as touch
(touchscreen), sound (microphone), and the presence of nearby objects (proximity sensors).
The computing elements communicate, gather, and analyze data from the sensors, devel-
oping actionable intelligence useful for carrying out more accurate actions and tasks or
controlling or modifying the physical and cyber environments. A communication highway
between the smart phone and other CPS, and network connectivity that links the smart
phone and various servers and the cloud environment, are enabled by communication tech-
nologies such as WiFi, 4G, and EDGE. It is also important to note that there are structural
Sensors 2022, 22, 5834
33 of 76
similarities between CPS and the Internet of Things (IoT), such as the similar architecture;
however, a major distinction between the duo is that there is a higher level of co-ordination
between the computational and physical elements in CPS [253].
Smart manufacturing is a leading CPS application domain. As the backbone of most
smart manufacturing solutions, CPS are the subject of extensive reviews and research
work. For example, S.K Khaitan and J. D. McCalley [252] completed a literature survey on
design techniques and applications of cyber-physical systems (CPS). The survey covers
several important aspects, including the architecture and modeling of CPSs; simulation of
CPSs; and tools and programming of frameworks for CPS and their veriﬁcation, including
model checking techniques to verify the correctness of their cyber–physical composition.
Cyber-Physical Systems: Foundations, Principles and Applications [254] is a great resource for
understanding the core elements needed to design and build complex cyber-physical sys-
tems. It also provides useful application examples. Examples of the industrial applications
of CPS include the development of an automated warehouse system [255], the development
of an industrial product service system [256], and the development of Cloud-Based Dis-
tributed Process Planning (Cloud-DPP), a CPS-based system that was designed to enable
cloud-based distributed and adaptive process planning in a shared cyber workspace [257].
The system can generate machining process plans adaptively based on real-time informa-
tion from machines. Another CPS-based solution worth further investigating is the FESTO
pre-industrial system MiniProd, a multi-agent system running on EAS modules (modules
with embedded control) designed for easy reconﬁguration on-the-ﬂy and self-conﬁguration.
It is part of an effort to study the issues of autonomy and adaptability at operational levels
of the assembly system within the smart manufacturing domain [258–262]
8.1.2. Industrial Internet of Things (IIoT)
Generally, a device is considered an object (or “Thing”) if it can use sensors and
application programming interfaces (APIs) to connect, transmit, and exchange data over
the Internet. Other acceptable characteristics of IoT devices include excellent power man-
agement, the ability to self-diagnose, and the capacity for conﬁguration upgrades at low
Internet bandwidths and within domains with poor network connectivity. Hence, the Inter-
net of Things (IoT) is simply a growing network of billions of physical objects (or “Things”)
that are connected to the Internet or to other devices that can be connected to the Internet
themselves for the express purpose of data exchange or transmission. Almost every ﬁeld
of human endeavor can beneﬁt in some way from IoT integration. Fields as diverse as
agriculture, consumer electronics, and home appliance industries have already shown
varying levels of adoption. Though the IoT evolved from the IIoT, the “Industrial Internet”,
also known as “Machine to Machine (M2M)” or Industrial Internet of Things (IIoT), is a
much narrower or limited version of the Internet of Things (IoT).
It has been successfully applied to manufacturing and other high stakes industries,
such as aerospace, healthcare, defense, and energy. The “Industrial Internet” as a term was
originally coined by General Electric (GE) in 2012. It refers to a system of connected, albeit
uniquely identiﬁed devices, alongside intelligent analytics, that are able to transfer data
over a network without requiring human-to-human or human-to-computer interaction.
The connected devices are interrelated objects, including sensors, actuators, instruments,
and other networked assets, such as computing devices and digital and mechanical ma-
chines. While IIoT supports sophisticated devices with advanced analytics and automation
usually with high-risk impact, the high-volume general IoT uses simple applications and
focuses on value creation in the low-risk impact consumer experience space. So important
is the “Industrial Internet” that several organizations, including Bosch, DellEMC, General
Electric (GE), Huawei, Microsoft, and Purdue University (College of Engineering), came
together in 2014 to form the Industrial Internet Consortium to help accelerate the growth of
the Industrial Internet.
Sensors 2022, 22, 5834
34 of 76
8.1.3. Digital Twins
Digital twin technology is a key enabler for the digital transformation of the traditional
factory. One of the earliest references to “digital twins” as a concept dates to 2003, when
one was first introduced as a virtual, digital equivalent to a physical product by Dr. Michael
Grieves in the University of Michigan Executive Course on Product Lifecycle Management
(PLM) [263]. Other such early mentions can also be attributed to Främling et al. (2003) [264]
and Shafto et al. (2012) [265]. The digital twin has been variously defined as a sensor-enabled
digital model [266] or a digital replica of a physical entity [267] that “mirrors the life of
its corresponding [flying] twin” (Shafto et al., 2012) [265]; uses the best available physical
models, sensor updates, fleet history, etc.; and can simulate the health condition of the
physical twin, by continuously recording and tracking its condition during the utilization
stage (Lee et al., 2013). The digital twin is also defined by its abilities to perform real-time
optimization [268] and monitor and control its physical twin while being constantly updated
itself, using data received from the physical twin [269]. The synchronous existence of a
physical asset and its digital twin means that the boundaries between the physical and
the virtual worlds are effectively blurred, ensuring that data are transmitted seamlessly
between both entities [267]. Figure 18 is an example of an implementation of the digital twin
of a robot arm. Though a relatively nascent technology, digital twin technology represents
the next step in the development of intelligent products and is a key enabler in the digital
transformation of traditional manufacturing. It makes it possible for physical assets to take
on virtual identities and interact with other machines and people across diminished virtual
and physical boundaries. A digital twin (also known as a “living” simulation) mirrors the
current state of its corresponding physical asset and maintains its characteristics as the asset’s
exact virtual representation by constantly learning, refreshing, and updating itself through
inputs from human experts, machine-to-machine interaction, and continuous exchange
of data with key elements of the physical asset, including sensors, actuators, and the like.
The value of accurately capturing the current state of the asset is that critical outputs from
the emergent model can be fed back to help optimize the performance of the asset and serve
as a critical input into the simulation and prediction of the future state of the physical twin.
Digital twins can be used to perform system optimization. They can also serve as sandboxes
for testing new ideas or making informed production decisions. In such scenarios, they
can be used as simulators where the possible outcomes of multiple production scenarios
can be gamed, contemplated, or investigated before implementation to eliminate the cost
of actual production testing or avoid the impact on or disruption of on-going production.
They can also be used to evaluate the impact of modifying manufacturing parameters or
using a combination of system parameters in a manufacturing scenario. Think of this as a
typical of what-if analysis. The best performing options determined by the digital twin can
easily be deployed to the physical twin through embedded PLCs and/or microprocessors
for immediate implementation, saving time and cost.
Figure 18. An implementation of a digital twin.
Sensors 2022, 22, 5834
35 of 76
The digital twin is also gradually maturing into a technology that could ultimately
revolutionize structural health monitoring, anomaly detection, and the remote launching
of maintenance services that allow products to self-heal. On an even broader scale, digital
twins of different factories and those of their suppliers, contractors, etc., can be linked
to establish virtual supply chain networks. The main beneﬁt of the digital twin is its
ability to integrate previously disparate models into an integrated set of interoperating
sub-models that are able to communicate and transfer information with each other while
simultaneously drawing on multiple data sources, including historical data, comparable
data, and current (up-to-the-second data) to accurately mirror the state of the physical
twin, determine failure trends, estimate failure timing, and correctly interpolate results
that help predict its likely future states. The continuous monitoring of the system means
that multiple sensors (including smart sensors) positioned around the physical twin can
constantly feedback data that would contribute to maturing the models and improving
their accuracy and reliability. One of the challenges of the Factory of the Future is that it
will be comprised of hundreds (and in some cases, thousands) of machines and devices at
the edge. Updating the ﬁrmware, conﬁguration, or software in all these assets (machines
and devices), within multiple platforms, would be very challenging without some form
of automation. The digital twins of these physical assets (machines, devices, systems,
or systems of systems (SoS)) [270] can serve as remote centralized hubs or connection
boundaries for their wireless updates without physical human intervention. Another
advantage of digital twins is that they can be used for the remote co-ordination and
operation of machines, devices, and systems. Other possible uses are process monitoring
and product tracking, not to mention that they can provide reliable alert and notiﬁcation
system functionality both for the manufacturing ﬂoor and for supervisory and managerial
teams. They can also be used to support the provision of remote technical assistance,
equipment maintenance, and repair and other technical support activities in combination
with augmented and virtual reality technologies.
The digital twin as a concept and technology has a lot of promise in smart manufac-
turing. The main idea of the DT is the digitization and virtualization of physical assets to
enable the simulation of their real-time states through modeling, simulation, and analysis.
The capturing of the states thus enables a feedback loop that makes the prediction and
control of their future states and behavior possible [269]. Designing subsystems within
a smart manufacturing system can be relatively easy. However, designing a fully inte-
grated smart manufacturing system, complete with all its subsystems, can be very complex.
The complication arises from the difﬁculty in being able to predict the dynamics between
all the complex couplings that together make up the multi-ﬁeld physical system. To reduce
cost and minimize error and cost, designers can ﬂexibly understand system dynamics,
run what-if analysis, and redesign smart manufacturing systems using digital twins. J.
Leng et al. [271] proposed a framework to demonstrate how digital twin technologies are
integrated into smart manufacturing system (SMS) designs to create digital-twin-based
smart manufacturing system design (DT-SMSD). The framework referred to as the Function–
Structure–Behavior–Control–Intelligence–Performance (FSBCIP) framework could potentially
contribute to easing the complications in the process of concurrent SMS designing. Further
research is needed for the development of uniﬁed models that effectively imitate every
interaction and behavior of the all the manufacturing processes within the co-interacting
subsystems in a smart manufacturing system. Open-source technology and open archi-
tecture have been recognized as potential solutions to SMS design [271]. Violeta D. and
Wernher B, developed an implementation of the digital twin (DT) for a smart manufac-
turing application using an open-source approach. The Digital Twin Demonstrator (as it
is called) gave rise to a high-level micro-services architecture and includes a few build-
ing blocks, including data management modules, models, and services. In their work,
they also listed several commercial and open-source digital twin solutions that are worth
mentioning. Some of these include the digital twin (DT) of a jet engine by General Elec-
tric (GE) that enables pre-procurement and pre-construction conﬁguration of their wind
Sensors 2022, 22, 5834
36 of 76
turbines. This solution is based on the Predix platform [272]. Other DTL solutions in-
clude the PTC Windchill (smart PLM software), Build to Operate (aerospace and defense
manufacturing management software) [266], and DXC (performance prediction solution
for hybrid cars) [273]. Kamil Ž. et al. [274] discussed the creation of a digital twin for an
experimental assembly system that was based on a belt conveyor system. The system
also includes an automated line for quality checking. The paper provides a very good
look at the DT implementation for a smart factory solution. However, the authors also
reported data synchronization challenges (data transfer delays of up to one second) due
to the cloud platform’s lack of support for storage of customized digital twins. Liwen
Hu et al. [275] built a cloud-based digital twin (CBDT) using an information model and
MTConnect protocol. The CBDT provides usage predictions and estimation utilities to
improve efﬁcient resource use for cyber-physical cloud manufacturing systems. In 2020,
the Industrial Internet Consortium (IIC) released a white paper [276] that provided practical
guidance on digital twins, including the deﬁnitions, beneﬁts, architectures, and necessary
building blocks for their implementation. The paper describes the technical aspects of
digital twins, their design, standards and frameworks, and a high-level discussion of their
applications in various domains. It also illustrates how digital twins are used to tackle the
information silo problem within industry. First, the digital twin engine is used to centrally
collect data from the disparate parts of the manufacturing system. That information is
processed and then pushed to different parts of the system through integration interfaces,
such as application programming interfaces (APIs).
8.2. Peripheral Elements of the Factory of the Future
Key enabling technologies (KETs) are emerging: high-tech technologies and solutions
that have been permeating the traditional manufacturing industry, leading to industry-wide
transformations [277]. Using case studies from Germany, Michael Rüßmann et al. [278] were
able to identify the top nine technologies that constitute the building blocks of Industry
4.0. Several other authors have also identiﬁed similar technologies as major enablers
driving the technological revolution. In this work, we will be focusing on some of these.
The technologies and solutions that are the basis of our discussion include cyber-physical
systems, Industrial Internet of Things (IIoT), cybersecurity, digital twins, cloud computing,
artiﬁcial and cognitive intelligence, big data and analytics, blockchain, augmented reality,
3D printing (additive manufacturing), and autonomous robots. These technologies are
weaved into the fabric of the factory and improve the intelligence of the system. Figure 19
shows some of these technologies illustrated as layers.
Blockchain et. al.
Artiﬁcial Intelligence (AI)
Big Data Analytics
Cloud Computing
Cyber Security
Figure 19. Layers of transformative technologies shaping the Future Factory.
Sensors 2022, 22, 5834
37 of 76
The Industrial Internet of Things (IIoT) will emerge as an important feature of the
factory of the future. Currently, many Industrial facilities are increasingly reliant on the
Industrial Internet of Things (IIoT). The connection and exchange of data among sensors,
software, and other technologies that it make this possible help with the streamlining of
operations, performance optimization, predictive maintenance, remote process monitoring,
and online progress tracking. While the growth of the IIOT within the manufacturing
industry will enable manufacturers to operate at unmatched performance and revenue
levels, it will also create unprecedented susceptibility to cyberattacks in industrial systems
and networks, the main reason being that connectedness can create vulnerabilities, since
it opens more doors, exploitable touch points, and attack vectors or surfaces for not only
cybercriminals but other bad actors, including individuals, groups, and nation states who
might have ulterior motives or an axe to grind. The higher the number of devices and
sensors connected through networking and Internet protocol (IP) addressing, the more the
access gateways. Potential security breaches by malicious actors, or even insider threats,
can portend grave technical and business risks if not adequately addressed. These vul-
nerabilities have been exploited in the IoT domain in the past. For example, hundreds of
thousands of unsecured IoT devices were pulled into a botnet (codenamed Mirai) which
aggregated their processing power to carry out large-scale cyberattacks that momentarily
crippled major websites such as PayPal, Netﬂix, and Spotify. These cybersecurity chal-
lenges are even more complicated in the Industrial Internet of Things (IIoT) because both
information technology (IT) and operational technology (OT) systems are being pulled into
the Industrial Internet of Things (IIoT), even though operational technology (OP) systems
were predominantly closed systems until recently. Furthermore, information technology
systems have established cybersecurity protocols which do not work well with operational
technology (OT) systems [279]. Note that information technology systems as deﬁned in
this paper would include computers, computer networks, electronics, semiconductors,
and telecommunication systems; and operational technology (OT) systems include all
software and hardware systems focused on the physical aspects of industrial production,
including the monitoring and control of physical devices and machines. Operational tech-
nology (OT) systems are more likely to include outdated hardware components and legacy
applications that have not been updated for years. There is also the challenge of very
vulnerable communication protocols (i.e., Modbus and Proﬁnet) that are used to control
many sensors, controllers, and actuators. A March 2019 report by the Ponemon Institute
showed that 90% of organizations dependent on operational technology (OT) experienced
at least one major cyberattack within the previous two years [280]. Since it is unlikely that
companies will immediately upgrade their decades-old equipment that is still functional,
there is a need for more cybersecurity research and a paradigm shift to address most of
these security challenges.
8.2.1. Cloud Computing
The cloud has made it possible for data to be stored and accessed differently than was
previously. The emergence of the cloud is one of the main factors driving the development
of smart technologies. The cloud has forced a shift in the geography of data storage and
computation. When “cloud” is combined with “computing”, it takes on an even more
consequential meaning. Many scholars have attempted to provide some insight into the
meaning and consequences of cloud computing to technological change. Armbrust et al.
described cloud computing as, “both the applications delivered as services over the Internet
and the hardware and system software in the data centers that provide those services”.
Cloud computing has also been described as a unique computing paradigm that involves
the provision of ﬂexible, dynamically scalable, and often virtualized resources over the
Internet [281]. As cloud computing is based on an on-demand service delivery model,
it was referred to as a utility by a 2009 Berkeley Report, a reference that is not entirely
surprising, given that cloud computing has been previously referred to as utility computing.
Cloud computing is premised on the idea that IT services (computational power, storage,
Sensors 2022, 22, 5834
38 of 76
platform, and software) can be provided as utilities or services, much like electricity or
water. It features ubiquitous, on-demand, and scalable access to resources. Under this
arrangement, these resources are provisioned from a shared pool, obligating users to
only pay for resources consumed (pay-per-use model). It eliminates the need for users
to individually build and maintain complex infrastructure. The accessibility (location) to
cloud infrastructure and how it is deployed or controlled (proprietorship) and by whom,
vary from one cloud system to another. The four most common deployment models include
public, private, community, and hybrid. The suitability of each model would depend on
the speciﬁc needs of an organization. The cloud services are packaged in three main service
models, viz., (a) infrastructure as a service (IaaS), (b) platform as a service (PaaS), and (c) software
as a service (SaaS). Quality of service (QoS) requirements between providers and users ensure
that high-quality services are provided at competitive prices. Since the cloud is designed
as a network of virtual services, deliverable over the Internet, organizations can access
and deploy applications easily from any location. End-users (or last-mile consumers) can
also seamlessly access information or personal data remotely. Due to its almost unlimited
digital storage capacity, the cloud will be critical for the monitoring, tracking, management,
and storage of an almost endless stream of data ﬂowing from different nodes within the
Industrial Internet of Things (IIoT). Pairing the cloud and the Industrial Internet of Things
(IIOT) with a Future Factory enables the full integration of all key elements of the digital
manufacturing ecosystem, which can then result in data and information sharing that
should ultimately lead to gaining better understanding of how to improve productivity
and ramp-up efﬁciency.
In the context of manufacturing, data acquisition or capture primarily occurs at the
nodal level. It typically involves the autonomous capture of data from production equip-
ment, machines, devices, or systems using embedded or connected sensors and related
hardware. Large amounts and often expensive network bandwidth are required to transfer
massive amounts of data captured from devices to the central cloud for deep learning
(DL) model training and inference. Some results of inadequate network capacity when
confronted with massive amount of transferable data are low throughput, delayed transmis-
sion (i.e., high latency), and poor network performance. Latency, which is the round-trip
time required for data to be transferred to and from the cloud, needs to be as low as possible
for systems to function optimally within the manufacturing network.
The long-established trend of capturing and transferring data from the factory ﬂoor to
the cloud is increasingly becoming untenable due to the high latency and low bandwidth
issues associated with the massive amounts of data captured daily by the ever-growing
number of IoT devices now available within manufacturing ecosystems. Furthermore,
many time-sensitive operations within the factory have strict delay requirements (in some
cases, a few milliseconds) [282] that cannot be met by reliance on the centralized cloud.
Against this backdrop, it is instructive to look at the three levels at which storage and
computing can occur:
(a)
“Cloud-Only” Computing: Cloud services make it possible for businesses to increase
storage and computing capacities on-demand and on the ﬂy without the need to
invest in new infrastructure, applications, or IT personnel. Eliminating concerns
about the availability of IT resources enables companies to focus on innovation and
creating business value while simultaneously cutting down on maintenance and
administrative costs associated with managing their own IT infrastructure.
(b)
Fog Computing: Another compute paradigm that has since emerged is fog computing.
Hierarchically, it stands mid-way between the cloud and the edge and lives on the
LAN. Programmable fog nodes serve as trafﬁc hubs where decisions about the routing
of data, inter-node peer-to-peer (P2P) communication, and service orchestration are
made. They facilitate the decentralization of control and facilitate increase reliability,
efﬁciency, and ﬂexibility [283]. While fog computing and edge computing have
been treated in some texts as interchangeable terms or overlapping terminology, it is
important to clarify that they are indeed interrelated but also different in many ways.
Sensors 2022, 22, 5834
39 of 76
The OpenFog Consortium Architecture Working Group (now part of the Industrial
Internet Consortium), an academia–industry group dedicated to the acceleration of
the growth of the industrial Internet, called attention to some of the differences in a
report entitled “OpenFog Reference Architecture for Fog Computing” [284]. While
both computing paradigms bring processing power and intelligence closer to the data
source, the major difference between them comes down to where data processing is
performed. In the case of edge computing, data is processed directly on the devices
on which the sensors are embedded or attached, or on some gateway device within
their proximity. In the case of fog computing, processing is performed by processors
connected to the LAN (i.e., a micro-data center) or within a LAN hardware. In either
fog conﬁguration, processing occurs further away from the sensors and actuators than
in edge computing. Further to this, most edge devices only process data collected
at one touch point, whereas fog computing is about processing data aggregated
from multiple devices. Thus, the fundamental construct of the fog architecture is the
aggregation and high-level processing of data and the almost instantaneous return
transmission of the acquired intelligence.
(c)
Edge Computing: Edge computing has since emerged as a viable alternative to the
“cloud-only” or central cloud computing standard or architecture [285]. This dis-
tributed computing paradigm involves the transfer of computer power, networking,
application services, and data storage capabilities to where they are most needed,
which is at multiple decision points that are usually as close as possible to the data
sources [286,287]. It also enables dynamic monitoring and control of manufacturing
processes [288]. By building in ﬂexibility around where computations can be per-
formed and extending cloud computing standards to the far reaches of the edges of
the network, many of the latency, bandwidth, and data throughput issues that have
bedeviled cloud computing can be addressed [289]. The proliferation of edge comput-
ing as a concept has been facilitated by the growing adoption of faster networking
technologies, such as 5G wireless; the integration of edge devices into manufacturing
IT and OT networks; and the connecting of all these using IIoT. In this arrangement, al-
gorithms can now run locally on edge servers or gateways, and data can be processed
at a high level; then, some forms of analytics can be reported so that insights are
provided in real time and human and machine queries are responded to in seconds.
Some of this intelligence can be used to actuate other connected devices or systems
where necessary, and actionable results can be instantly made available to workers
on the factory ﬂoor and executives in ofﬁces. This is reminiscent of the autonomous
vehicle, whose systems require instant feedback to make travel decisions, even while
the vehicle is in motion, and in some cases even at high speed. Edge devices (nodes)
enable edge computing by providing entry points into manufacturing core networks.
They are usually mobile or ﬁxed assets, often embedded or connected to machines
or equipment. They are typically distributed throughout the factory ﬂoor and other
remote locations, such as nodes across a wide network or stars strewn across a dark
sky. Large IIoT operations, such as those in manufacturing facilities, typically host
hundreds (or even thousands) of edge devices (nodes), which together form a network
of edge devices that recognize and communicate with each other. The edge devices
continuously and autonomously collect, process, and broadcast data, which provides
signiﬁcant visibility and awareness about events across the network. Some edge
devices serve a dual purpose as sensing devices for capturing sensory information
and actuators that can trigger or control other devices or systems. Some common
examples of sensors and actuators in edge devices within manufacturing facilities
include: (a) Sensors: pressure and temperature sensors; real time location systems
(RTLS); cameras; near-ﬁeld communication (NFC) sensors; light, proximity, motion,
acoustics, and radio-frequency identiﬁcation (RFID) sensors; ultrasonic sensors; ﬂow
meters; and ﬂuid sensors. (b) Actuators: hydraulic and pneumatic ones, switches,
relays, programmable logic controllers (PLCs), motors, and light and acoustics actua-
Sensors 2022, 22, 5834
40 of 76
tors. Under the edge computing arrangement, data are processed, and analysis results
are distributed by the same device used to acquire it or by a nearby server instead
of a centralized cloud. The results of implementing edge architecture include the
ability to process and store data faster, improved application performance, low latency,
and signiﬁcant reductions in bandwidth cost. Notwithstanding, it is important to note
that edge computing does not eliminate the need for deeper data analytics, large data
storage facilities, and extended archival capabilities, all functions that the cloud is
better suited for. The main advantage of edge computing is its capacity to reduce the
compute requirements and data volume that must be transferred to data centers or
cloud-based locations within short notice. In the Future Factory, it is expected that
more complex data processing will be performed at the edge, as new system modules
that incorporate advanced artiﬁcial intelligence functionalities are built into them.
Edge computing has also helped in the management of many security and privacy
related concerns within industry.
Pending the development of better technologies and more advanced architectures,
the cloud computing/data analytics needs of the Future Factory can be met using a hybrid
architecture that relies on or one or more of the computing paradigms discussed above.
Examples of such hybrid architectures include:
(i)
“The Cloud-Only” model: In the cloud-only model, no intermediate processing of data
occurs. All data captured by multiple sensors are transmitted to the cloud, where 100%
of the processing occurs, before the results are pushed down to all the sources that
require the intelligence.
(ii)
The Cloud–Fog Computing model: In this model, data from multiple sensors and devices
are transmitted to the fog gateways. Depending on the urgency of the request, some
high-level processing of data occurs at the fog layer, and intelligence pushed back to the
various nodes (machines and humans) in real-time. Non-time-sensitive data and some
pre-processed data that require further (deep learning) processing are transmitted to
the cloud.
(iii) Cloud–Fog–Edge Computing Model: This is a massive, distributed computing infrastruc-
ture that consists of three inter-connected computing tiers (cloud, fog, and edge).
All data acquisition occurs at the logical extremes of the network using edge devices.
Some instant, high-level processing of data occurs at this tier (the edge) to provide time-
sensitive, real-time responses from entities (man and machine) at different nodes. In this
conﬁguration, the fog layer not only serves as a distribution hub for resources and services
between the edge and the cloud, but also stores and performs high-level data analysis
of data from multiple sensors at different edge locations while providing a low-latency
network connection for the transmission of data and responses back and forth between the
edge and the cloud. Unlike the edge, the fog layer is best suited for analytic operations that
require real-time analysis of data from multiple data sources (e.g., several edge devices).
The cloud tier is where the most robust deep learning processing operations occur. It is
the tier where all non-time sensitive and pre-processed data arrive for thorough, deep,
and ﬁnal analysis. The cloud also has massive and scalable data storage and archival capa-
bilities. Figure 20 aptly captures the Cloud-Fog-Edge layer architecture including related
infrastructure and services.
Sensors 2022, 22, 5834
41 of 76
Figure 20. Cloud–fog–edge layer architecture.
8.2.2. Big Data Analytics
Data are the fuel that drives digitally transformed factories and are fast becoming
the most consequential assets in manufacturing as the factory of the future begins to take
shape. As part of this digital transformation process, some manufacturing organizations
have been able to successfully connect their numerous fully automated manufacturing
facilities (alongside all their production equipment) located in different global sites into
a central cloud, resulting in manufacturing architectures that are IoT-native, fully digital
capable, and broadly cloud-based. These architectures, which can qualify as benchmarks
for Industry 4.0, enable seamless data sharing, collection, and exchange across enterprise
resource planning, manufacturing operations management, and production life-cycle man-
agement processes, thereby enabling coherent feedback systems that leverage data analysis
outputs for the optimization of manufacturing operations. These factories will plausibly
grow ever more intelligent due to the exponential amounts of sensed data that will ﬂow
into servers and data reservoirs because of the continued digitization of industrial assets.
However, no actual beneﬁt would accrue from the possession of these vast amounts of data
if they were not properly analyzed and the accruing intelligence distributed to all necessary
end-users and connected systems in formats that make sense to help improve processes,
productivity, and competitive advantages. Ultimately, deriving critical intelligence that
can help make correct inferences and consequently acquire optimal value from data would
require advanced analytics and the ability to effectively present results in formats that are
easily decipherable by appropriate systems or visualization formats that are meaningful
and can be effortlessly comprehended by end-users, both executives in the ofﬁces and
technical personnel (engineers, technicians, ﬁtters, etc.) on the shop and manufacturing
ﬂoor. Terms such as data warehouse, data lake, edge, modeling, and optimization, are all
examples of words associated with data analytics.
8.2.3. Artiﬁcial and Cognitive Intelligence
The Future Factory is a highly dynamic system that is comprised of several inter-
connected and sometimes co-dependent sub-systems that are subject to a wide variety of
nonlinear and stochastic activities [290,291]. These assets also generate huge amounts of
data which potentially contain useful operational and strategic business insights. Unfortu-
nately, only a fraction of these data are currently analyzed by various traditional factories,
due to operational and technical constraints. With the increasing complexity of today’s
factory, many traditional methods often used to address a lot of common production issues
(such as process variability, root cause analysis, early detection of quality defects, degra-
Sensors 2022, 22, 5834
42 of 76
dation monitoring, and process control) are becoming increasingly inadequate. Due to
its many successes in a variety of industries, artiﬁcial intelligence is increasingly looking
like a credible alternative for addressing a variety of manufacturing challenges because
of its robust portfolio of solutions and its incredible ability to process vast amounts of
manufacturing data, making it possible for companies to transition from reactive to highly
accurate proactive (and even predictive) decision making. Several research-based concepts,
mock-ups, test-bed prototypes, and even factory-ready artiﬁcial intelligence solutions have
been developed or built in recent years.
However, what exactly is artiﬁcial intelligence (AI)? Artiﬁcial intelligence (AI) is as an
inter-disciplinary discipline [292], a set of practices and a variety of systems or tools
that model and/or exhibit intelligent behaviors, such as perception, reasoning, decision
making, the ability to predict, and even the ability understand context. The mimicry of
human cognitive functions is at the core of artiﬁcial intelligence (AI). Reason, interaction,
and learning are the three key attributes of a typical artiﬁcial intelligence system. Due
to the implied similarities in intellect, comprehension, and abilities, artiﬁcial intelligence
(AI) is said to possess a certain kind of machine intelligence [293] that could equal and
possibly outmatch human intelligence [294] in certain respects. AI can either replace or
augment human abilities. While there are several sub-ﬁelds within artiﬁcial intelligence
(AI), (e.g., machine learning, deep learning, natural language processing, computer vision,
expert systems, cognitive computing, etc.) it is not easy to make clear distinctions between
them because of clear overlaps in their relationships. To better understand AI, we focus
on the two main sub-ﬁelds, i.e., machine learning (ML) and deep learning (DL), that drive
performance in all the other sub-ﬁelds.
ML has been dubbed the workhorse of artiﬁcial intelligence (AI), and its applications
are ubiquitous across multiple industries. It has been particularly useful as an effective tool
for evidence-based decision making [295]. Traditional ML involves a process of training a
system by exposing it to examples of desired input–output behavior instead of explicitly
programming it. ML is used to build assets or systems that can automatically improve
through experience. The way it does this is by learning from data. Learning from data
means being able to extract information accurately and quickly from raw data and to be
able to make reasonable inferences. To do this machine learning (ML) relies on different
purposes or task-speciﬁc algorithms. Figure 21 shows different types of traditional ML
algorithms. There are no one-size-ﬁts-all algorithms that can solve all ML problems. ML
algorithms exploit meaningful relationships within datasets to solve complex production
problems. In his 1959 paper [296], Arthur Lee Samuel, an American pioneer in the ﬁelds of
computer gaming and artiﬁcial intelligence, noted that, “A computer can be programmed
so that it will learn to play a better game of checkers than can be played by the person
who wrote the program”. This statement underscores the power of machine learning
(ML), i.e., its ability to learn what to, to do it automatically once the lesson is learned,
and to in fact, improve its performance and accuracy over time. Applied ML solutions do
not only learn from data but become more accurate and useful over time by leveraging
knowledge acquired from new data in the course of the use of the solution [297]. Vast
amounts of data are generated in manufacturing. A great advantage of machine learning
is that it can analyze large amounts of complex manufacturing data and quickly make
meaning of it. There are numerous reviews of machine learning (ML) and deep learning
(DL) techniques/applications in manufacturing [298–300]. The emergence of low-cost
computation, next-generation computing architecture (particularly graphics processing
units, GPUs), the availability of data, and the development of sophisticated algorithms are
at the root of the rapid advancements in machine learning (ML) [301].
Sensors 2022, 22, 5834
43 of 76
Figure 21. Machine learning (ML) algorithms’ acronyms: support vector machines (SVM), K-nearest
neighbors (KNN), logistic regression (LR), Naïve Bayes multinomial (NBM), principle component
analysis (PCA), singular value decomposition (SVD), frequent pattern-growth (FP-Growth).
Deep learning is a special type of machine learning (ML) that is based on artiﬁcial neu-
ral networks (ANN) [302]. The adjective “deep” in “deep learning” refers to the multiple
network layers that are common in DL. DL algorithms use neural networks with multiple
processing layers (often more than three layers) [303] that learn data representations at
multiple abstraction levels [304] by optimizing some unsupervised criteria [305]. After the
input layer, every subsequent layer within the network produces a distinct representation
of the observed patterns based on inputs received from the previous layer. Ultimately,
the algorithm achieves its results by progressively extracting high-level features from one
representational layer to another. This intuitive stepwise feature extraction process results
in slightly more abstract representation of the input data, the deeper into the neural network
the data ﬂows. Various deep learning (DL) approaches have been reviewed in the open
literature [302,305–308]. Deep learning (DL) is very scalable, and performance improves
markedly as more data become available. Some common deep learning (DL) application ar-
eas include computer vision [309,310], natural language processing (NLP) [311,312], speech
recognition , machine translation, etc. Of these, computer vision is perhaps one of the areas
where DL has had the most impact. Computer vision application areas, such as image clas-
siﬁcation, object detection, action recognition [313,314], motion/visual tracking [315,316],
semantic segmentation [317,318], and human pose estimation [319,320], are now common
on many factory ﬂoors, in the value chain, and in supply chains of many industries. The in-
crease in popularity of DL-based solutions is in part because of the astounding human-level
results they have delivered [304]. One of the major differences between traditional machine
learning (ML) and deep learning (DL) is in how representations are learned from the raw
data. Unlike traditional ML, DL can perform automatic feature extraction (i.e., feature learn-
ing) intuitively. While important features are manually extracted in traditional machine
learning (ML), deep learning (DL) achieves relatively higher accuracy classiﬁcations using
general-purpose learning procedures that rely on automatic extraction of high-level, non-
linear features from raw data, all with little or no human intervention. This is particularly
helpful considering that 80–90% of available data today are unstructured in nature.
Applications of Artiﬁcial Intelligence (AI) in Manufacturing: The typical manufactur-
ing system integrates several elements, including machinery (including machines, robots,
conveyors, tools, ﬁxtures, and related hardware), material handling systems, information
handling systems (computer systems), and human workers. All these systems, the tech-
nologies that drive them, the processes they support, and the strands that connect them can
all potentially be infused with AI solutions to increase efﬁciency and ensure the “optimal
control” of material ﬂow, efﬁcient use of energy, and ultimately, the cost-effective creation
of value. Amongst many beneﬁts, artiﬁcial intelligence (AI) eliminates or replaces time-
consuming and sometimes risky traditional practices, facilitates access to data, and enables
effective execution of manufacturing tasks.
Sensors 2022, 22, 5834
44 of 76
Artiﬁcial intelligence (AI) has domain-independent characteristics and has perme-
ated many industries. AI-based solutions have been implemented for all manufacturing
processes (design, production, maintenance, assembly, etc.) and the associated supply
chain [321,322]. It has the potential for game-changing impacts on manufacturing in the
long term.
AI technologies provide opportunities to maximize the value locked up in the vast
troves of data generated daily within factories [323]. It facilitates autonomous and in-
telligent analysis of real-time and historical data, enabling smart and informed decision
making [324]. This allows the factory and its sub-systems to respond in real-time to
changing demands and dynamic conditions streaming through the PLM systems [325,326].
The two aspects of manufacturing that have experienced the most infusion of artiﬁcial
intelligence (AI) solutions are machinery maintenance and quality. The most focus is di-
rected towards advancements in overall equipment efﬁciency (OEE), growth in production
yield, increases in uptime, and improvements in quality and consistency.
AI-based solutions enable automatic evaluation, monitoring, and real-time insight into
equipment condition to help minimize unplanned equipment downtime and expensive
maintenance costs. They are also able to forecast when operational equipment is likely
to fail to help guide maintenance scheduling. Artiﬁcial intelligence (AI) also provides
visibility across manufacturing cells, lines, and the supply chain.
It has been used for inspections [327–329], diagnosis [330], anomaly detection, and pre-
dictive maintenance [331,332]. To improve product quality, artiﬁcial intelligence (AI)
solutions have been used to automate defect detection processes by automatically verify-
ing product quality and providing insight into quality issues, hence reducing waste and
enabling production improvements. Many ML-based fault/defect detection [333–338] and
quality monitoring approaches [336] have been proposed in the literature. Several examples
of fault diagnostics [335,339–349] are also available in the literature. Bayesian approaches
that enable root cause analysis of quality issues [350,351] have also been proposed. It has
also been used for robotics [352,353], robot-inspired path planning [354], and managing
network trafﬁc in computer networks [355]. Different artiﬁcial intelligence (AI) strategies
have also been infused into manufacturing-based technologies, such as cybersecurity (Mal-
ware detection) [356,357] and augmented reality (AR) systems [358,359], to enable them to
operate more autonomously and intelligently.
Another area where AI has played a useful role in the factory is in the prognostics
and health management (PHM) of machinery [360]. The ability to detect deviations in the
normal operating conditions of industrial components is helpful for the timely prediction,
detection, and isolation of faults; and the prevention of costly and unplanned failures. Real-
time visibility about the health status of individual machines and the entire production
system provides immediate and long-term value to the production process. While the
combination of data availability and the adoption of traditional ML techniques in recent
years provided a lot of insights into component defects, root cause analysis, machine
degradation, and remaining useful life (RUL), the complexity of the manufacturing systems
has prompted a pivot to deep learning (DL) solutions, which are better able to handle the
complexity of input data, providing hierarchical representations [361].
AI has also supported intelligent control of manufacturing systems. The growing
complexity of controlled systems now means that no single control paradigm addresses the
issues prompting the use of hybrid control systems that sometimes include both discrete
event systems and continuous systems. To be effective, these hybrid control systems require
intelligent control methodologies [362–366] to be embedded within them.
Optimal system conﬁgurations, performance evaluations, material ﬂow modeling,
throughput, etc., are all within the purview of AI. Most factories contain highly integrated
systems comprising manufacturing cells, workstations, assembly lines, material handling
systems, and a network of multiple machines, robot, and conveyors that support the ﬂow
of materials and their processing/reﬁnement. These arrangements typically have ﬁnite
buffer capacity. These ﬁnite buffers and periodic system failures of unreliable machines,
Sensors 2022, 22, 5834
45 of 76
and uncertainties and inter-dependencies that make factory operations nonlinear and
stochastic [290,291], make the determination of optimal system conﬁgurations, performance
evaluations, material ﬂow modeling, etc., very challenging. A lot of work has been devoted
to the analysis of the dynamics and performance of manufacturing systems [31,291,367–369].
Some of these, such as the queuing theory and Markov chain-based analytical modeling
methods, have known limitations [367,369–371]. AI-based ML techniques appear to be
compensating for these shortcomings [291,369,372–375].
AI solutions have also been used in job scheduling. To meet mass customization re-
quirements, ﬂexible manufacturing systems (FMS) are designed to easily adapt to changes
in the type and quantity of products. A particular challenge that then arises during im-
plementation is the job dispatching problem: several product orders could be awaiting
processing within the same time window. Exact approaches (best for small-scale job dis-
patching problems) and heuristic-based methods (not very adaptive in highly dynamic
environments) have been traditionally used to address these issues. As for their limita-
tions, ML-based methods have been used to compensate for these deﬁciencies. Artiﬁcial
intelligence applications will play important roles in the transition to Factories of the Future.
More application examples are discussed below. These include a deep-learning-based
quality control solution used for defect detection in the assembly line [376] and an AI-based
(machine learning) and context-aware intrusion detection system [377]. Li, Bo-hu, et al. [26]
performed an entire review on applications of artiﬁcial intelligence in intelligent manu-
facturing. Within industry, several manufacturers have also implemented industrial AI in
their manufacturing ecosystems, moving from pilots to integration at scale. Referred to
as the “lighthouse factories”, these organizations have realized signiﬁcant ﬁnancial and
operational beneﬁts in the process [378,379].
8.2.4. Blockchain
This is a type of shareable ledger that runs atop a permissioned network [380]. It can
also be described as a distributed network of nodes, typically running on multiple servers
that feature a system of perpetually growing lists of trusted or veriﬁed asset transactions.
Depending on the way the system is set up, trust is distributed across nodes within the
network. These nodes are responsible for the veriﬁcation, authentication, and integrity of
block data before the ultimate inclusion of the new block into the growing chain. These con-
tinuously growing chain link of blocks is aptly referred to as a blockchain. Each block stores
data associated with an asset (i.e., person, place, or thing). The relationship between the
blocks is maintained through a mechanism that enables each block in the chain to inherit an
immutable hash of the prior block that it is connected to. A sransaction within a blockchain
is usually processed and stored without consultation with, approval of, or even the need for
a central trust authority [381]. One of the main reasons blockchain is an important building
block for a typical future factory is the fact that the data stored on it (e.g., transaction
details) are immutable or remain unchanged, unaltered, and indelible, which means that
the full history and data trails of all data, communications, and transactions are preserved,
thereby establishing data provenance. A typical blockchain system includes a network of
nodes that serves as a decentralized and trustless system which ensures data provenance
and the efﬁcient sharing of manufacturing (products and processes) information. It can be
set up as a decentralized and connected network of manufacturing assets and computing
nodes. This system will provide transparency, and audit the trail of assets and a third-party
veriﬁcation system of an organization’s manufacturing capacity, creating a mechanism for
operationalizing “smart contracts” between different parties or entities. It will be essential
for product customization and tracking of assets within a supply chain. Various factories
and their value chains might need to be connected in the factory of the future, in what
could be termed networked organizations and machines. In a typical network of the sort
suggested, multiple third-party entities might be involved in various aspects of the produc-
tion of a product, including receiving supplies (materials and spares), service provisioning,
product design, fabrication, and production. Other aspects might include product testing
Sensors 2022, 22, 5834
46 of 76
(validation/veriﬁcation), regulatory control, and shipment. Trustworthiness among the
disparate parties (factories, distributors, suppliers, regulators, and other stakeholders)
within such a network would be critical if all participants are to be at ease. Basic imple-
mentations of blockchain abound in the literature. Examples exist from healthcare [382],
intellectual property protection of a 3D print supply chain [383], and machine-to-machine
(M2M) interactions in the chemical industry where industrial plants trade electricity with
each other over a blockchain. In a certain instance, a central server which typically manages
information exchange and data authentication in an IoT system was replaced by blockchain
(BC) technology, hence eliminating risks of device spooﬁng, false authentication, and sev-
eral other security and privacy concerns [384]. Atin Angrish et al. [37] provided some great
insight into blockchains with a focus on manufacturing.
8.2.5. Mixed Reality
Mixed reality is a class of technologies that attempt to blend the physical and digital
worlds. Mixed reality operates on a spectrum: virtual reality (VR) and augmented reality
(AR) are the most prominent types. In this paper, we focus our attention on augmented
reality (AR), mainly because it likely has the greatest potential to proliferate in the factory of
the future. Augmented reality (AR) systems project context-sensitive [385] digital informa-
tion in 2D or 3D forms (i.e., texts, stats, maps, videos, images, animations, characters, etc.)
over real-life objects (the physical world) for the express purpose of providing additional
information, context, instructions, or guidance about said objects, or processes that the
objects are undergoing. They enable users to interact with real and synthetic elements
of the real and virtual worlds simultaneously [386]. As a human–computer interaction
tool, users (technicians, maintenance crew, etc.) can directly interact with the “extended”
information to make informed decisions. Augmented reality (AR) systems complement (or
augment) human abilities, providing users the guidance and support needed to complete
tasks correctly in a consistent and efﬁcient manner, leading to higher productivity, greater
accuracy, and a marked reduction in expensive reworking by ensuring tasks are performed
accurately, the ﬁrst time. User-friendly and intuitive human interfaces alongside rich,
appropriate, and context-aware content are factors critical for a great AR experience [387].
(a)
Types of Augmented Reality (AR) Systems: There are several types of augmented
reality (AR) systems, differentiated by application, functionality, or design. Of these,
four main types stand out: (a) Marker-based AR: AR systems of this class display
content (video, text, animation, 3D ﬁgures, etc.) on surfaces contingent with the
detection of a predeﬁned marker embedded on a static image (trigger photo) or a QR
code, often using AR devices such as smart phones. (b) Markerless AR: Unlike Marker-
based AR systems, they do not require physical markers for the overlay information
to be triggered. They merely scan their environments to get their bearings and are
generally guided by localization or positioning systems, such as GPS, accelerometers,
and digital compasses. (c) Projection-based AR works just like typical projectors. They
utilize image or video-based projection (with audio prompts, in some cases) to guide
the pace, direction, and “every step” of a process. They help operators or factory
workers through manual processes, enabling them to complete tasks quickly, efﬁ-
ciently, and consistently without recourse to hard-copy manuals and instructions. (d)
Superimposition-based AR relies on the object recognition technique to ﬁrst identify
an object and then replace it or a portion thereof with an equivalent augmented image.
An often-cited application of superimposition-based AR is in the medical ﬁeld, where
doctors sometimes superimpose live feeds (X-ray images) of a patient’s body part
directly from an X-ray machine unto the patient’s actual body to better understand
the internal condition of the body part.
(i)
Hardware Devices: Hardware devices are a necessary and integral part of aug-
mented reality (AR) systems. There are several types of AR devices in common
use. Some of these include handheld devices (HHD) [388–390] holographic
displays, head-mounted displays (HMD), smart glasses/lenses and virtual reti-
Sensors 2022, 22, 5834
47 of 76
nal displays (VRDs), mobile phones (including smart phones) [390], wearable
data-gloves [391], haptic devices [392], tablets, iPads, and computers.
(ii)
Software Systems: Software (or applications) also forms an important part of
AR systems. Of particular interest are (a) tracking and registration algorithms
and (b) development platforms (or content-creation applications). The primary
function of the tracking and registration algorithms is the alignment of the
two (real and virtual) environments or object categories. On the other hand,
development platforms are the applications used for the creation of AR content.
They include anything from low-level programming libraries to the more complex
AR applications that integrate features for sensor data acquisition and integration,
image, and audio rendering, and in some cases, even application engines.
(b)
Industrial Applications of Augmented Reality: Over the years, AR technology has
continued to mature. Since it can simulate processes, augment tasks, provide remote
assistance, enhance communication between teammates, and provide elaborate guid-
ance to users, it has demonstrated relevance to manufacturing amidst the on-going
re-imagination of the sector. There have been proposals [393], proof of concept studies,
and actual applications [394] in a wide array of industries [48,52]. Its successful appli-
cation at various manufacturing stages (planning, design [395,396], assembly [394,397],
maintenance, etc.) is particularly notable. It has also found applications in different
manufacturing processes and functions. A few of these are discussed below:
(i)
Interactions with Process Information: They have been used to digitally access
and interact with procedural and process information, including IIOT related
data [398] acquired in real-time, rather than relying on physical manuals and
paper documents. Some have been used to display augmented 3D images, mak-
ing it possible to view system components in multiple conﬁgurations, including
exploded, cross-sectional, and internal views. For example, internal views come
highly recommended for providing insights into the internal sections of opaque
structures or systems where accessibility or worker safety is an issue [399].
(ii)
Quality Control: AR systems are already playing a huge role in automated real-
time, in-production quality control. The mobile nature of most AR systems
supports the relocation of the quality control functions away from static (ﬁxed)
input locations to mobile terminals, permitting intermediate inspections, and fa-
cilitating the ﬂexible and cost-effective use of software license seats. The online,
real-time, and decentralized characteristics of the AR systems provide the added
advantage of instant access to and ﬂexible ﬂow of information to various manufac-
turing points where they are most needed. It also enables fast variance inspection,
continuous, real-time error reporting, and documentation. Finally, the instant
generation of enhanced quality assurance reports [400] immediately after the
completion of each instance of an inspection routine [401] is not a possibility.
(iii) Process Support, Training, and Simulation: AR technology has also been used to
assist technicians and operators working on mechanical or technical tasks such
as welding [402], machinery repair, and assembly operations, and even in con-
trolling robots [403,404]. Some AR inspection systems incorporate features that
provide graphic step-by-step instructions that can be used for process training.
The step-wise design of these routines ensure that processes are performed in a
consistent, accurate, and reliable manner. They can also be used as simulators for
practice runs to help users develop and perfect their skills, ensuring that manu-
facturing tasks and processes are carried out right the ﬁrst time. In the long-term,
this helps with limiting errors and eliminating the need for rework. This level of
expertise and dedication is useful for high-stress tasks where precision is critical.
(iv) Repair and Maintenance: The repair and maintenance of complex machinery will
be one of most consequential areas of AR application in manufacturing. Next
generation AR-inspired maintenance systems are becoming important elements
of the Factory of the Future [405]. They are now more often the products of the
Sensors 2022, 22, 5834
48 of 76
intersection of AI, IIoT, big data, and associated technologies and capabilities.
Excellent condition monitoring, combined with dynamic predictive modeling,
make for a successful predictive maintenance program. In the Factory of the
Future, technicians going about in the normal course of their daily duties can
be prompted by their wearable IAR devices (such as smart glasses or mobile
devices) about “just-beginning” maintenance problems, way in advance of actual
system or component failures. These AR systems not only detect and warn
operators and technicians about these anomalies, but also offer on-the-spot visual
analysis of the problem, display the service histories of the machinery, and deliver
step-wise service instructions to aid in their resolution. For off-site maintenance,
the AR systems can serve as remote collaboration tools where a technician can
contact each other, collaborate with colleagues for resolving tough problems,
or be remotely guided by a more experienced supervisor [406].
(v)
Collaborative Product Design and Prototyping: Almost all aspects of product de-
sign, for early to late stages, can now be collaboratively performed (end-to-end),
streamlined, sped-up, and optimized using AR. These stages include ideation,
conceptual design (encompassing generic functionality management [407]), pre-
liminary design, the interactive generation of models or virtual product pro-
totyping [397,406,408], design review, and evaluation [409]. Free-form surface
generation features in some AR applications have been used to support easy
creation of design alternatives and to enable parameter adjustments [407]. In au-
tomotive design, for example, AR-based design tools have been used to evaluate
multiple interior design options by simply overlaying different photo-realistic
3D car interior mock-ups over real cars [408], eliminating the need for physical
prototypes. AR-based design tools often generate sharable, high quality, 1:1
scale, photo-realistic 3D visualization of augmented design models that can be
converted into AR compatible format and transmittable to stakeholder’s devices
for easy and enhanced viewing. Availability and real-time remote access to these
models make collaboration easy. They are enabling stakeholders (both designers
and other collaborators, downstream in the product pipeline) to inspect and inter-
act with the design models, and provide timely and objective feedback for design
improvements, in advance of design approval and production [16]. The early
detection of ﬂaws facilitates design improvements and eliminates expensive
post-production redesign costs. Several user-friendly, computer-aided AR design
environments, such as ARCADE, are now available [410].
(c)
The Challenge with current AR Systems: Though there is growing interest in the
use of augmented reality (AR) as a support tool across industry [411,412], one draw-
back of most AR-based maintenance systems is that most applications are currently
passive and static in nature. They merely push information and provide no feedback
mechanism capable of ingesting, analyzing, and looping back explicit and implicit
user and environmental responses. A feedback system of this sort can enable the
output of targeted information to users, continuous process reﬁnement, and better
tailored solutions. Examples of responses (data points) that can be routed back to
through the feedback system include such data points as effectiveness of prior guid-
ance, the experience of users, or even the user actions or inactions that could help
preempt user intent. There is a need for more adaptive AR, with creative feedback
loops that can actively engage users and help them to solve problems more creatively.
Attempts have been made in the literature to spotlight this challenge and suggest
creative ways of solving this problem [413].
There are several applications of mixed reality in manufacturing, as already alluded
to. One of the earliest machinery maintenance and repair (laser-printer) mixed reality (MR)
applications was developed by Steve Feiner’s team at Columbia University in 1993 [414].
Mixed reality (MR) has also been used to develop an application for improving performance
in the execution of assembly tasks [415]. Applications of AR/MR for employee training and
Sensors 2022, 22, 5834
49 of 76
work on production lines [416], quality monitoring and inspection, maintenance, assembly,
and safety have been reported [417,418]. Boeing once used mixed reality for cable harness
design and the assembly of furniture, automobile door locks, and cockpit modules. This
resulted in marked improvements in their assembly process [419–421]. This is in agreement
with studies that show that mixed-reality-based techniques help reduce assembly process
errors by as much as 80% [422].
8.2.6. 3D Printing (Additive Manufacturing:)
3D printing (also referred to as additive manufacturing (AM)) has been referred to as
one of the major technologies of the 4th Industrial revolution [423] because of its potential
for massive disruption of the status quo across many industrial sectors [424]. Alongside
other disruptive technologies, such as IoT, cloud, big data/analytics, and AI, it is expected
that AM will create the necessary conditions for expedited processing, rapid prototyping,
customized production, and agile manufacturing. Additive manufacturing has various
deﬁnitions, but one of most descriptive is the one captured in the ISO/ASTM 52900 stan-
dard [425], which deﬁnes it as the “process of joining materials to make parts from 3D
model data, usually layer by layer, as opposed to subtractive manufacturing and formative
manufacturing methodologies”. Irrespective of what deﬁnition is accepted, the general
principle upon which this technology rests is the creation of 3D geometries through the
precise addition of basic building blocks, such as grains of powder or polymer ﬁlaments,
laid out as a series of cross sections, often layer by layer. This occurs with minimal ma-
terial waste and a nominal or limited need for post-processing [426]. The creation of
these 3D geometries is driven by digital instructions (geometric information) typically sent
from a computer (CAD model) to a printing head, nozzle, or related printing technology.
The instructions which are processed as points, lines, or areas help guide the direction and
rate of material deposition [427]. Over time, the technology has continuously matured,
getting to a point where it is now feasible to work with all sorts of materials, including
ABS plastic, photo-polymers, stereo-lithography materials (epoxy resins), metals (e.g.,
steel, titanium), wax, and even biological materials. There are seven categories of additive
manufacturing (AM) [428]. Each category includes several techniques, some of which are
well known within the AM community. The processes involved in the techniques differ
depending on the materials used and the mechanisms employed. They include (a) VAT
photo-polymerization, (b) material jetting (e.g., continuous on demand (CoD) and drop on
demand (DoD)), (c) binder Jetting, (d) material extrusion (fuse deposition modeling (FDM)),
(e) powder bed fusion (e.g., direct metal laser sintering (DMLS), electron beam melting
(EBM), selective heat sintering (SHS), selective laser melting (SLM), and selective laser sin-
tering (SLS)), (f) sheet lamination (ultrasonic additive manufacturing (UAM) and laminated
object manufacturing (LOM)), and (g) directed energy deposition (e.g., laser engineered net
shaping, directed light fabrication, direct metal deposition, 3D laser cladding).
Traditional manufacturing is generally expensive due to the high labor cost and
complicated set-up (machinery and process) requirements. Re-purposing and switching
product lines can take weeks, or even months. This contrasts with additive manufacturing,
which lends itself to quicker process adjustments and easier adaptation within a larger
production line. Furthermore, changing production speed or switching between products
can be easy and quick, and relatively fewer operational staff are often required to achieve
equivalent work outputs. Additive manufacturing (AM) has the potential to democratize
manufacturing on a global scale. It is cheaper and best suited for high-value, low-volume,
small, and short-run parts production. AM is well positioned to beneﬁt the growing
demand for product personalization and mass customization. They are also very useful
for creation of parts and structures with complex geometries and require ﬂexible designs.
Examples can be seen in machine parts, dental work (precise crowns and dentures), artwork,
customizable gifts, etc. In the live sciences, layers of living cells have been printed over
one another to create human skin. Some of these can potentially be surgically implanted
into other living materials to ﬁx complications on the bodies of burn victims. They are
Sensors 2022, 22, 5834
50 of 76
also being evaluated for skin product testing, to help reduce the controversial use of live
animals for biological tests. There is also an emerging consensus amongst researchers that
at some future time in the future, it will be possible to print human organs and increase
options for people on organ waiting lists.
In manufacturing, the fabrication of tools necessary for producing parts or components
is important. Agile tooling, a speciﬁc tooling approach which involves the efﬁcient and
cost-effective design and fabrication of tools such as molds, patterns, dies, jigs, and ﬁxtures,
is an important aspect of manufacturing-related tooling. The most popular agile tooling
techniques include die-casting, die-stamping, hydroforming, and thermoforming. Some
of these tooling has been produced at great turn-around times and at a fraction of their
regular costs, thanks to additive manufacturing (3D printing) processes. For example,
tools, typically created with the vacuum forming process, can now be produced faster,
more efﬁciently, and at lower costs using fused ﬁlament fabrication (FFM), an additive
manufacturing process. The ability to produce these tools faster would mean quicker
prototyping and shorter time to market. With the adoption of additive manufacturing
(AM), a Future Factory (central hub) can potentially ﬁll a demand for a replacement part
initiated by a customer, from a thousand miles away, in record time, without any shipping
requirements. An example of how this can play out is that a virtual 3D model of the
requested part, released by the Future Factory to a cloud location, becomes immediately
accessible to an authorized, out-sourced third-party 3D print location, closer to the customer.
Following a few clicks, the 3D model is printed and becomes available for immediate
customer pick-up. This arrangement will reduce wait times, accelerate production rates,
and eliminate shipping costs. It will also reduce time-to-market, making the creation of
products cheaper and more accessible.
Opportunities to combine evolutionary or genetic algorithms with 3D printing to
speed up design and determine parts with the best conﬁgurations for speciﬁc industrial
service are very numerous. Researchers from NYU [429] used genetic algorithms alongside
3D printing to determine the ideal wing shape for a fast-ﬂapping ﬂight. Mitra Asadi-
Eydivand et al. [430] also used 3D and evolutionary algorithms to determine the optimal
design of a scaffold. One of the biggest challenges that pervasive 3D printing will face
within the industrial space are the issues of the ownership and control of intellectual
property. For example, how will the owner of a design or electronic product speciﬁcations
be compensated once the ﬁles end up in the hands of a client? How can the distribution of
those ﬁles, once out of the owner’s control, be monitored? Some proponents have suggested
online marketplaces, brokers, or clearing houses that would serve the dual purposes of
regulating access to electronic speciﬁcations and managing compensations and payments
to intellectual property owners.
Applications of additive manufacturing (3D printing) are beginning to have real-life
impacts in a number of industries, including aerospace and defense (A&D), medicine,
the automotive industry, bio-medicine, etc. It has been used for manufacturing tooling (e.g.,
hand-tools for testing and assembly), light weight or highly complex parts/components,
spare parts, and functional prototypes. When used for complex parts, it is often the case
that only low volumes of the parts are required, and it is impractical or uneconomic to use
traditional manufacturing methods. Due to its advantages, such as the capacity for high
precision fabrication of complex geometry [431], the potential for signiﬁcant reductions in
material waste (material efﬁciency), and ﬂexibility in design, it has been an ideal solution
for fabricating light-weight parts in the aerospace industry. It is also used for ensuring
availability of spare parts [432] and the maintenance and repair of aerospace parts such as
wings, turbine blades, rocket parts, and other sophisticated components. It was used to
fabricate a complex injector head for the Ariane 6 launcher using selective laser melting
(SLM) technology and a nickel-based alloy. The Ariane 6 launcher was developed Ariane
Group, a joint venture between Safran and Airbus Group [433]. A number of manufacturers
(e.g., Ford) use 3D printing for fabricating tooling. AUDI (in conjunction with SLM Solution
Group AG) fabricated prototypes and spare parts using 3D printing [434]. Many other
Sensors 2022, 22, 5834
51 of 76
examples of the applications of 3D printing to save costs, speed up production, or execute
difﬁcult tasks abound in the open literature and industry
8.2.7. Autonomous Robotics
The factory of the future will have two employees: humans and robots. Of the two,
robots are expected to play a prominent role because of the high likelihood of a dispro-
portionate reliance on machines for industrial tasks as compared to humans. The word
“robot” is a Czech word that is literally interpreted “forced labor”. They are very useful for
tasks that require high levels of accuracy or are dangerous or repetitive. They bring to tasks
such beneﬁts as improved effectiveness, higher efﬁciency, and reliability. They can perform
tasks that humans cannot or should not (e.g., demeaning or dangerous tasks). Aside from
augmenting human efforts, they also create the ﬂexibility for under-utilized labor to be
replaced or re-assigned. Long term, they are relatively more cost effective and facilitate
higher productivity. There are different classes of robots, including commercial robots,
industrial robots, and service robots. The focus of this section is industrial robots. Industrial
Robots: ISO 8373:2012 deﬁnes an industrial robot as “an automatically controlled, repro-
grammable, multipurpose manipulator, programmable in three or more axes, which can be
either ﬁxed or mobile for use in industrial automation application”. The ability of Industrial
robots to perform high-precision work accurately, repeatably, and quickly is helping facto-
ries deliver high quality products and driving plant efﬁciency and proﬁtability. Industrial
robots will become ubiquitous across most manufacturing environments. As these already
highly productive robots are becoming AI enabled (AI robots) and fully integrated into the
data-rich manufacturing ecosystems, both sharing and receiving data/information with
other subsystems, it is easy to see why they will eventually become the workhorses of the
factory of the future. Over time, it is expected that AI will morph into more intelligent
systems with strong cognitive abilities. Robots are used for a variety of tasks within the
manufacturing space. Some of these include mechanical cutting, grinding, deburring, pol-
ishing, welding (i.e., arc welding, spot welding, etc.), and painting. Other common robot
tasks include picking, packing and palletizing, material handling, assembly, ﬁreﬁghting,
and patrolling of warehouses and storage areas.
Based on one classiﬁcation, three main types of robots operate within industrial
environments. These include: (a) traditional robots, (b) collaborative robots (cobots) and (c)
mobile robots.
(a)
Traditional Robots: The technologies underpinning traditional robots are generally
more mature. They generally have high payloads, have longer reaches, and are able
to achieve very high efﬁciency levels, even at high production speeds.
(b)
Collaborative Robots (Cobots): ISO 10218-2 deﬁned cobots as robots designed for direct
interaction with a human within a deﬁned collaborative workspace. Workspace
refers to the safeguarded space where the robot and a human can perform tasks
simultaneously during production operation. Generally, they are relatively easier to
program, enable more efﬁcient production adjustments, and can more ﬂexibly adapt to
new requirements than traditional robots. For implementation, they require minimal
changes to existing production layout and can be easily redeployed for different tasks,
as necessary. A deﬁning characteristic of these robots is that they work collaboratively
with human workers, without concerns for worker safety. They possess several
integrated safety features, including collision detection technologies, minimized pinch
points, safety-rated monitored stops, and well controlled force and speed. Human
workers can focus on tasks that require strong cognitive abilities, whereas the robots
can be assigned repetitive tasks and other activities that require precision or heavy
lifting. Robots that work alongside humans are referred to as cobots.
(c)
Mobile Robots: Mobile robots have a general awareness of their environment and the
ability to effectively navigate through it in the process of accomplishing assigned
tasks. While traditional robots are usually stationed at ﬁxed locations and are mostly
assigned tasks that do not require a lot of ﬂexibility. Mobile robots, on the other
Sensors 2022, 22, 5834
52 of 76
hand, are usually ambulatory and they are best suited for constantly changing factory
environments. Using their navigation systems, they transverse entire factory ﬂoors
autonomously, seamlessly integrating themselves into the manufacturing ecosystem.
They can stop, move, slow down, or navigate away from obstacles using sensory
information obtained from a wide array of localization and navigation sensors em-
bedded within their bodies or attached to their surfaces. Two main classes of robot
sensors exist, i.e., exteroceptive and proprioceptive sensors. Exteroceptive sensors
help the robots discern and understand their environments. Examples of exteroceptive
sensors include stereo cameras, pan/tilt/zoom cameras, lasers and 3D lidar systems,
projection-based systems, audio/video feedback systems, touch sensors (whiskers
or bump sensors), and GPS, proximity, and certiﬁed safety sensors. Then there are
proprioceptive sensors, which are sensors that gather information about the robot
itself. Examples of proprioceptive sensors include accelerometers, gyroscopes, mag-
netometers, compasses, wheel encoders, and temperature sensors). These sensors,
alongside accompanying algorithms, enable the mobile robots to both understand
and safely navigate their environments. For this reason, they are very safe to deploy
alongside human workers, with whom they sometimes work collaboratively, trans-
forming them from mere machines to fellow workers. The basic idea of the mobile
robot is essentially moving the robot to the work instead of moving the work to the
robot. Mobile robots would best beneﬁt such tasks as automated assembly, inspection,
painting, or welding of huge industrial components, such as airplane frames, large
engines, and giant offshore or space structures. Due to their large sizes, working on
such components with two or three stationary robots can be inadequate because of
the limitations on the reaches of such robots. Alternative courses of action could be
to either add more robots (a costly option) or employ mobile robots which are not
limited by reach due to their ability to move around the entire structure. Compared
to traditional robots, mobile robots are more ﬂexible and adaptable. Their ability to
maneuver through space and structures helps shorten throughput times, improving
efﬁciency and cutting down on production time. Mobile robots have a variety of
locomotion mechanisms [435,436], e.g., ﬂying (drones) [437], rolling, walking (legged),
swimming or water-based movement (underwater vehicle manipulator system) [438],
crawling, moving on tracks, and using propellers. Automated guided vehicles or au-
tomatic guided vehicles (AGVs) are amongst the most common mobile robots within
the manufacturing industry today. Additionally, they are poised to become even
more ubiquitous as adoption continues to grow. They are currently used for moving
materials, supplies, and products around manufacturing facilities. Unmanned aerial
vehicles (such as the drone) are the next set of robots that will grow in relevance
within manufacturing. They would be especially useful for picking up and dropping
items, and product and quality inspections, especially the inspection of equipment
or machinery at hard-to-reach locations (e.g., high elevation or dangerous locations)
using thermal and video cameras.
9. Discussion: Recommendations and Future Research Directions
Following our review of the literature, the dominant theme is the general idea that the
Factory of the Future is about data and the value that can be extracted from it to improve
operations and optimally create value. It is about networked or connected assets (ma-
chines, people, devices, networks, etc.), and the different communication technologies and
protocols that enable them talk to each other (communicate seamlessly). As a large infor-
mation network, the Factory of the Future, is about capturing raw data from said network
of connected assets (plus related manufacturing processes) and the transformation of the
acquired data into actionable intelligence [439,440], with a view of facilitating decision
making, optimizing manufacturing processes, sustainably producing goods and services,
and improving overall performance. Amongst many important qualities, intelligence and
cognition are machine characteristics that make a factory smart. They empower the factory
Sensors 2022, 22, 5834
53 of 76
with the ability to know, understand, interpret (correctly), and respond (effectively) to
events happening within and around it. Both characteristics can be developed if several
challenges “slow-walking” progress towards the full realization of the Factory of the Future
are addressed. Given that the Factory of the Future is a huge information network, most of
these problems are somehow related to processes (such as the collection, storage, analysis,
security, or analysis of data) or the protocols, frameworks, or technologies used to manage
the said processes. Some of these will be discussed below.
9.1. Communication Protocols and Technologies
The Factory of the Future contains a huge collection of networked assets. One of the big
challenges facing the discipline is how to make each of them “speak the same language” and
seamlessly communicate (back-and-forth) with one other. The emergence of the Industrial
Internet of Things (IIoT) [441] and open communication standards/platforms and advanced
advanced M2M communication protocols, such as the Open Platform Communication
Uniﬁed Architecture (OPC UA) [219,442,443] and MQ Telemetry Transport (MQTT), has
advanced data collection and synchronization efforts. A lot of research still needs to go into
developing new and improved communication standards and framework. There is also
room for developing protocols that are nimbler and easier to conﬁgure.
9.2. Digital Infrastructure
To become a completely connected system, the Factory of the Future has to be fully
integrated into extensively networked manufacturing supply chains. This would require
data-driven architectures capable of linking, at high ﬁdelity and accuracy, all data generated
at every stage of the manufacturing process and product life cycle. Currently, there are gaps
in the virtual infrastructure. A lot of research is required for building out systems, architec-
tures, and technologies that help interconnect different entities within the manufacturing
network, e.g., Factory-to-Factory communication.
9.3. Data Collection and Characterization
Data collection methods that are better linked or aligned with domain knowledge need
to be developed. It is also important to realize that for data to be valuable, its context must
be understood. Further manufacturing domain-based research in data contextualization
and linking methods, such as graph theory, category theory, and linked data, are critical.
The eventual democratization of these methods will also serve the industry well. Determin-
ing relationships between terms and concepts and extracting value from these relationships
should be further explored by domesticating research into semantic indexing techniques.
Frameworks that better connect concepts are required for more productive analytics of
multivariate data, especially at the network or system level. Overall, multi-disciplinary re-
search in natural language processing (NLP) will greatly beneﬁt the manufacturing domain
as we try to make sense of all the data we collect.
9.4. Virtualization
A major priority of the Factory of the Future is the seamless exchange of data between
all nodes within the manufacturing network in real time or near real-time. This will require
a level of decentralization that would make the hierarchical automation pyramid obsolete.
Virtualization of assets and the production process using technologies such as digital
twins, the asset administration shell (AAS) and data distribution services (DDS) will enable
bidirectional relations between physical assets and their cyber twins. The communication
pipeline between these twins will enable optimization, real-time remote monitoring, easy
and early identiﬁcation of failures and inefﬁciencies, optimization of production processes,
continuous improvement through simulations, etc. Notwithstanding the progress that
has already been made with the virtualization of assets, there are still a lot of challenges
yet to be addressed that will require some research work (basic and applied). One such
challenge is that of insufﬁcient synchronization capabilities. In many cases, simulation
Sensors 2022, 22, 5834
54 of 76
models are not (fully) accurate due to synchronization issues [444]. Simulation models
should not be distinguishable from their physical counterparts. There are also issues
around the prediction of the state of complex systems and the complexities around big data
collection, storage, and processing [16,445]. These challenges will require further research
work. The development of dedicated conceptual frameworks and reference models for
digital twins would also be helpful [444].
9.5. Interoperability
Interoperability and standards are a twin challenge affecting the realization of the
Factory of the Future. The proliferation of technologies, protocols, standards, and frameworks
has increased the need for interoperability at different levels and among different aspects
of the manufacturing ecosystem. Due to the lack of standardization early in the emergence
of Industry 4.0, many manufacturers, trade associations, and even nation states developed
proprietary solutions in the hope of taking advantage of the prime mover advantage and
possibly monopolizing the market. No players have been able to dominate any major
aspects of the industry. Contrary to this, a measure of controlled chaos has ensured, which
is currently exacting cost and speed penalties on the industry, making it difﬁcult for the
digitization process to proceed at scale. Several standards organizations, trade grounds,
and industry/government-led alliance initiatives have emerged to address some of the
challenges. The various types of interoperability are discussed in the literature [160]. There
is a need for interoperability on various fronts, including physical assets, in the transfer
and exchange of data, in the physical and functional architecture, etc. A lot of effort
is being put into developing standards and promoting interoperability. It would take
some time for some of the handwork to really pay off. Some of the most common smart
manufacturing architectures, reference models, and standards, along with the on-going
efforts, are widely available in the literature [177,446]. Currently, there appears to be a
haphazard approach to the development of solutions, and since most of the architectures,
frameworks, and reference models are still in the conceptual stages, their real-world
implementations (speciﬁc case studies) would be a signiﬁcant way to contribute to the
literature and the discipline.
9.6. IT/OT Security
Due to the IT–OT (information technology to operations technology) integration and
the proliferation of connected assets characteristic of the Factory of the Future, there are
major concerns about cybersecurity risks in smart manufacturing. The risks will only grow.
Each additional device introduces some extra level of marginal vulnerability, a situation
that collectively increases the risk of cyber-related compromise due to the growing number
of vulnerable endpoints. Known attacks have not only been directed at passive devices—
sensors, actuators etc.—but have also hit edge devices, PLCs, HMIs, and control systems
used to manage industrial operations. Beyond the known static attack vectors, the number
of stakeholders (employees, contractors, vendors, suppliers, clients, etc.) that have access
to the connected OT systems has also multiplied the potential vulnerabilities of the factory.
Many cyber-attacks have been reported within industrial and manufacturing facilities in
the recent past. In one case, hackers were able to gain control of the main network of a
German steel factory [447], through their corporate endpoints. In a different instance, using
a watering hole attack, the Remote Access Trojan (RAT) was used to compromise industrial
control systems with the energy sector [448]. There have also been cases of the modiﬁcation
of the operation of physical assets. An example is the Stuxnet [449] attack that targeted
physical assets at an Iranian nuclear facility. This computer worm speciﬁcally targeted
programmable logic controllers (PLCs), used to automate electromechanical processes. It
was reported to have even modiﬁed the operation of the connected motors by altering
their rotational speed. There was also the case of the suspected ‘logic bomb’ that exploded
the Trans-Siberian Pipeline [450]. The reports are almost endless. There have been several
research endeavors directed at addressing vulnerabilities in supervisory control and data
Sensors 2022, 22, 5834
55 of 76
acquisition (SCADA) networks [451–454]. Several research works have also been directed to
addressing intrusion detection issues in programmable logic controllers (PLCs) [455–459].
While there is a patch work of activities meant to deter these attacks, there are several
research opportunities in the cybersecurity of the Factory of the Future that need to be
explored to address the challenges holistically. For one, there is a need to develop secured
standards of communication that leverage the Internet as a gateway to bridge the IT–OT
divide. There is also potential for research work that promotes default cybersecurity
protections (i.e., secure by default and cybersecurity by design) in industrial architecture,
frameworks, and software/hardware solutions. As traditional threat detection techniques
and modalities are inadequate for addressing the threats within the smart manufacturing
domain, there is also a need to develop more advanced AI-enabled threat detection and
security analysis systems that can help detect vulnerabilities and respond autonomously.
The need for personnel with the right mix of skills has not been greater. As part of
measured directed at addressing the skills gap, curricula directed at addressing the security
of cyber-physical systems have been implemented [460–462]. More work clearly needs to
be done in this area. Experts with requisite skills in the ﬁelds of information security and
industrial control systems/production processes would be central to the effort to mitigating
the threats.
The Factory of the Future is a data-rich environment that harnesses intelligence from
multiple information streams, i.e., assets (including people), processes, and subsystems,
to help create value, new forms of production efﬁciency and ﬂexibility. Being able to realize
the goals of next-generation manufacturing will depend on solving a lot of the challenges
with the infrastructure (physical and digital) and processes required to protect the integrity
of data and optimally extract value from it. While the traditional factory relied on au-
tomation, the main goals in the development of next-generation factories are to anticipate
uncertainty and to ensure that the factory and its many sub-systems will be able to correctly
interpret and disruptions and respond appropriately with little or no human intervention.
The growth of artiﬁcial intelligence, and particularly the progress in the ﬁeld of natural
language processing (NLP), have made it possible to analyze data, extract meaning from
them, and determine appropriate actionable insights, all with no or limited human super-
vision. Though the current advancements in manufacturing technology require massive
investments, the long term value (cost reduction, speed to market, mass customization,
product personalization, etc.) will most certainly be worth the time and investment.
10. Implementations of the Factories of the Future
While there are still many challenges on the path of the full realization of the Factory
of the Future and the long-anticipated Fourth Industrial Revolution, many organizations
(academia, industry alliances, and companies) are already making massive strides in that
direction. Academia is very engaged with training and research in smart manufacturing
solutions. Event test beds for solution development and analysis are in use. Similar efforts
are underway in various research centers all over the world. Industry alliances are also
helping crystallize and achieve the smart manufacturing ideals and aspirations of their
corporate members. Some discussion on these fronts is given below.
10.1. Industry and Implementation of Smart Manufacturing Solutions
Within industry, many companies have been making transformative strides through
the digitization and virtualization of different aspects of their manufacturing processes.
Factories that have morphed into smart manufacturing systems with a full coupling of
all their subsystems are rare but remain the end goal. The most visible discussion about
industrial applications of smart manufacturing that has resulted in the realization of real
value centers was around the World Economic Forum’s Global Lighthouse Network, which
is a a platform to used to promote the development, replication, and scaling of smart
manufacturing solutions. It is comprised of companies (world-over) that have led the pack
in demonstrating the value (growth, productivity, resilience, and environmental sustainabil-
Sensors 2022, 22, 5834
56 of 76
ity) in transitioning to smart manufacturing. As at 2022, 103 manufacturing Lighthouses
have been identiﬁed, across the globe, from different industries. Examples of some of
the companies that have made the list include: Baoshan Iron and Steel (Shanghai, China),
AGCO (Marktoberdorf, Germany), Hitachi (Hitachi, Japan), Johnson and Johnson DePuy
Synthes (Suzhou, China), Micron (Singapore), Weichai (Weifang, China), Henkel (Düssel-
dorf, Germany), Petkim (Izmir, Turkey), Johnson and Johnson Vision Care (Jacksonville,
USA), and Groupe Renault (Curitiba, Brazil).
10.2. Industry Alliances and Research Institutes
National institutes/laboratories (such as the National Institute of Standards and Tech-
nology (NIST), Platform Industrie, CESMII, the United States’ National Institute on Smart
Manufacturing) and Industry alliances (such as the Industry IoT Consortium and Taiwan
Association of Machinery Industry (TAM)) are all examples of institutions working to
advance smart manufacturing goals. Some of these have test-beds that have contributed
signiﬁcantly to doing the required pre-work needed, in a solution-agnostic manner, be-
fore industry can scale the solutions. There are several smart manufacturing test-bed im-
plementations reported in the literature for different aspects of the manufacturing process
or operation [463–470]. The Industry IoT Consortium typically has several test-beds [471]
at any one time working on next-generation smart manufacturing solutions. Some speciﬁc
examples of their test beds include: the Smart Factory Machine Learning for Predictive
Maintenance Test-bed, the Smart Manufacturing Connectivity for Brown-Field Sensors,
the Smart Printing Factory Testbed, the Time-Sensitive Networks Test-bed, the Track and
Trace Test-bed, etc.
10.3. Smart Manufacturing in Academia
There is a lot of research (smart manufacturing-based) currently going on within
academia globally. The future work force is also being trained and equipped (sometimes
with real-life learning factories): for pilots, many test beds have been deployed for the
evaluation real-life solutions. Test-beds create platforms for researchers and practition-
ers to develop innovative smart manufacturing solutions in a ﬂexible and effective way.
The System-level Manufacturing and Automation Research Testbed (SMART) at the Uni-
versity of Michigan [472] and the University of Shefﬁeld AMRC, Factory 2050 (UK) are
but two examples. The “neXt Future Factory” laboratory at the University of South Car-
olina is part of the global value chain dedicated to advancing smart manufacturing. As a
research and development concern, the neXt Future Factory Lab located within the McNair
Aerospace Center is the center of gravity for advanced manufacturing at the University
of South Carolina (UofSC). The laboratory has a two-pronged approach that focuses ﬁrst
on research and development (R&D) and secondly on industry engagement. On the R&D
level, the laboratory is focused on determining the most optimal approaches for connecting
different manufacturing modules and enabling them to exchange information efﬁciently,
reliably, and quickly (Interoperability). Another issue of interest is to ﬁgure out efﬁcient
ways of connecting these modules securely and reliably to the Internet (connectivity and
cybersecurity). A third issue is how to effectively collect, manage, and analyze disparate
manufacturing datasets so that business intelligence can be gleaned from them in real-time.
This is important because we believe that data hold the necessary intelligence to inﬂuence
technology innovation, competitiveness, and productivity growth in the manufacturing
business. On the industry engagement vertical, our laboratory provides industry a secure
and advanced platform with which to investigate solutions, and build proof of concept
solutions and MVPs alongside our researchers and students, thereby de-risking their digital
transformation projects and improving product and process efﬁciency.
10.3.1. The “neXt Future Factory” Test Bed
Figure 22 shows the Future Factory test bed at University of South Carolina. This manu-
facturing test-bed (or functional mini-factory) is designed to support the study, exploration,
Sensors 2022, 22, 5834
57 of 76
maturation, and exploitation of manufacturing control elements, communication protocols,
and a variety of emerging technologies with a view to advancing smart manufacturing (and
related) objectives. The test bed is technology agnostic and relies on open standards for all
its communication and data modeling requirements. It also has a ﬂexible implementation
architecture that makes it possible for new technology to be easily integrated and tested.
This is to support the testing and maturation of new technologies and data strategies
through industry use cases. It also supports the rapid creation of different iterations of
product layouts to cater to the needs of diverse industrial products. The test-bed consists
of several Yaskawa robotic arms, conveyor belt systems, and an array of multi-vendor
and multi-platform equipment and devices, including programmable logic controllers
(PLCs), edge devices, human–machine interfaces (HMIs), cameras (FLIR, infrared, thermal),
sensors (wired and wireless), variable frequency drives (VFDs), actuators, etc. The various
modules of the test bed are connected to the Internet using the 4LTE and 5G networks.
Data transfer between automation devices within the test bed, and between the test bed
and some sister sites as part of our Factory-to-Factory project, is made possible through
the IEC 62541 standard OPC UA. The platform also has access to a multi-vendor array
of software applications that enable the real-time collection, ingestion, and visualization
of data, the implementation of advanced process simulations solutions, path planning,
ofﬂine robot arm programming, the development of visual inspection, AR/VR, digital twin
solutions, etc. In the future, we hope to be able to use the test-bed as a DevOps platform
for streamlining all development and operational processes, including coding, analytics,
modeling, deployment, updates, etc.
Figure 22. The neXt Future Factory Test Bed at University of South Carolina.
10.3.2. Collaborations
The laboratory has multiple academic and governmental agency partners that work to-
gether to advance various educational and policy goals. Besides providing our researchers
a forum to investigate different IT/OT phenomena and affording our students practical
training opportunities, the facility also showcases the opportunities inherent in digitiz-
ing manufacturing to help drive productivity, reduce defects, cut cost, and accelerate
time-to-market. We also work closely with some of the most innovative companies and
consultancies in the country, each bringing in their best minds and an interesting amalgam
of advanced technologies offerings (hardware and applications) to help address some of the
most challenging problems in the advanced manufacturing space. The test-bed provides
these industrial partners the platform to create different technology conﬁgurations, deploy
them in real-time, and explore their efﬁciencies without the possibility of disrupting pro-
duction, which helps them essentially de-risk the development of novel digital solutions.
Besides being a showcase for the technologies of partner companies, the laboratory also
Sensors 2022, 22, 5834
58 of 76
performs applied research and development for industry. All of these activities have created
interest within industry and driven different forms of business value, including enabling
strong customer engagement, in addition to interest in our scholarship and our students
(for employment), who are active participants in most of the R&D work.
11. Summary and Conclusions
This paper reviewed the meaning, essence, characteristics, and applications of the
Factory of the Future, alongside its key supporting technologies. As an Industry-4.0-enabled
manufacturing system, the Factory of the Future is ﬂexible, adaptive, and transparent and
is expected to replace the current (traditional) manufacturing system. The wide adoption
of the Factory of the Future and its ideals is expected to transform the traditional factory
from merely housing mechanical operations into an ultra-high-tech system that uses in-
novative smart technologies to improve production processes, reduce cost, encourage
mass customization, and enable the prediction of potential problems even before they
occur using predictive maintenance/analytics solutions. It will also support the efﬁcient
tracking of assets at each stage of the supply chain to improve asset visibility, control,
and insight, enabling advances in inventory management and supporting improvements in
logistics. The paradigm shift is clearly about making the manufacturing infrastructure and
its supporting ecosystems smarter, quicker, and nimbler, while using data as a critical asset
for self-optimization, self-adaptation, and competitive intelligence. The ability to ensure
that assets are connected and that they “talk to and learn from each other” seamlessly is a
deﬁning feature of the Factory of the Future and is made possible through the deployment
of machinery, components, and technologies in a manner that ensures their interoperabil-
ity and connectivity. Even though signiﬁcant advances have already occurred in recent
years, the goal of a fully digitized and highly networked manufacturing sector remains.
Many solutions are still in their early stages of development (aspirational, conceptual, pilot,
testbed, etc.). It is, however, noteworthy that a lot of progress is being made at the policy,
research and development (R&D), and implementation levels. As new technologies and
systems become available, it is critical for researchers and practitioners to continue to push
the technological envelopes to ensure the full transformation of signiﬁcant parts of the
manufacturing ecosystem. There is also the urgent need for all stakeholders, including the
governments and the organized private sector, to help with scaling some of the proven
solutions and ensure rapid industrial diffusion beyond the walls of research facilities,
test-beds, and well-funded factories.
Author Contributions: Conceptualization, methodology, validation, investigation, and writing
original draft preparation, N.A.; writing, review and editing, C.S.; supervision, & funding acquisition,
R.H. All authors have read and agreed to the published version of the manuscript’.
Funding: This research received no external funding and the APC was funded by University of
South Carolina.
Institutional Review Board Statement: Ethical approval was not required for this study.
Informed Consent Statement: Informed consent was not necessary for this study.
Data Availability Statement: Not applicable.
Acknowledgments: This material is based upon work supported by the National Science Foundation
under grant number 2119654 and the South Carolina Research Authority. Any opinions, ﬁndings,
and conclusions or recommendations expressed in this material are those of the author(s) and do
not necessarily reﬂect the views of the National Science Foundation or the South Carolina Research
Authority. Some of the images in this paper were designed using resources from Flaticon.com.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
Sensors 2022, 22, 5834
59 of 76
List of Acronyms
4IR
Fourth Industrial Revolution
AAS
Asset Administration Shell
AI
Artiﬁcial Intelligence
B2MML
Business to Manufacturing Markup Language
BatchML Batch Markup Language
BMBF
German Federal Ministry of Education and
Research
BPMN
Speciﬁcation-Business Process Model and Notation
CMS
Cyber Manufacturing Systems
CPS
Cyber-Physical Systems
CPPS
Cyber-Physical Production systems
CRM
Customer Relationship Management
DCS
Distributed Control System
DMIS
Dimensional Measuring Interface Standard
DMN
Decision Model and Notation
ERP
Enterprise Resource Planning
EtherCAT Ethernet for Control Automation Technology
F2H
Factory-to-Human
F2P
Factory-to-Product
F2SC
Factory-to-Supply Chain
FDI
Field Device Integration
FF
Future Factory
FoF
The Factory of the Future
FP-Growth Frequent Pattern-Growth
GPU
Graphical Processing Units
H2D
Human-to-Device
HART
Highway Addressable Remote Transducer
HMI
Human–Machine Interface
HTTP
HyperText Transfer Protocol
ICT
Information and communications technology
IEC
International Electro-technical Commission
IoT
Internet of Things
IIoT
Industrial Internet of Things
IoS
Internet of Services
ISO
International Organization for Standardization
IT/OT
Information Technology/Operational Technology
KNN
K-Nearest Neighbors
L2S
Levels of System Sovereignty
LR
Logistical Regression
M2D
Machine-to-Device
M2VT
Machine-to Virtual Twin
M2M
Machine-to-Machine
MDPI
Multidisciplinary Digital Publishing Institute
ME-S
Manufacturing Ecosystem
MES
Manufacturing Execution Systems
ML/DL
Machine Learning/Deep Learning
MOM
Manufacturing Operation Management
MQTT
Message Queuing Telemetry Transport
NBM
Naïve Bayes Multinomial
OAGIS
Open Applications Group Integration Speciﬁcation
OPC-UA Open Platform Communications-Uniﬁed
Architecture
PAC
Programmable Automation Controller
PACKML Packaging Machine Language
PC
Personal Computer
PCA
Principle Component Analysis
PLC
Programmable Logic Controller
PMML
Predictive Model Markup Language
QIF
Quality Information Framework
QR
Quick Response
REST
REpresentational State Transfer
RFID
Radio Frequency Identiﬁcation
RL
Reinforcement Learning
SCADA
Supervisory Control and Data Acquisition
SL
Supervised Learning
SVD
Singular Value Decomposition
SVM
Support Vector Machines
ISA
International Society of Automation
UL
Unsupervised Learning
References
1.
Deane, P.M.; Deane, P.M. The First Industrial Revolution; Cambridge University Press: Cambridge, UK, 1979.
2.
Crafts, N.F. The ﬁrst industrial revolution: A guided tour for growth economists. Am. Econ. Rev. 1996, 86, 197–201.
3.
Crafts, N. Explaining the ﬁrst Industrial Revolution: Two views. Eur. Rev. Econ. Hist. 2011, 15, 153–168. [CrossRef]
4.
Greasley, D.; Oxley, L. Causality and the ﬁrst industrial revolution. Ind. Corp. Chang. 1998, 7, 33–47. [CrossRef]
5.
Mokyr, J.; Strotz, R.H. The second industrial revolution, 1870–1914. Stor. dell’Econ. Mond. 1998, 21945, 1–14.
6.
Jevons, H.S. The second industrial revolution. Econ. J. 1931, 41, 1–18. [CrossRef]
Sensors 2022, 22, 5834
60 of 76
7.
Agarwal, H.; Agarwal, R. First Industrial Revolution and Second Industrial Revolution: Technological differences and the
differences in banking and ﬁnancing of the ﬁrms. Saudi J. Humanit. Soc. Sci. 2017, 2, 1062–1066.
8.
Janicke, M.; Jacob, K. A third industrial revolution. In Long-Term Governance for Social-Ecological Change; Routledge: New York,
NY, USA, 2013; pp. 47–71.
9.
Cooper, C.; Kaplinsky, R. Technology and Development in the Third Industrial Revolution; Routledge: London, UK, 2005.
10.
Heinonen, S.; Karjalainen, J.; Ruotsalainen, J. Towards the third industrial revolution. Finl. Findland Future Res. Cent. FFRC EBook
2015, 6, 2015.
11.
Posada, J.; Toro, C.; Barandiaran, I.; Oyarzun, D.; Stricker, D.; de Amicis, R.; Pinto, E.B.; Eisert, P.; Döllner, J.; Vallarino, I. Visual
Computing as a Key Enabling Technology for Industrie 4.0 and Industrial Internet. IEEE Comput. Graph. Appl. 2015, 35, 26–40.
[CrossRef]
12.
Kagermann, H.; Wahlster, W.; Helbig, J. Securing the Future of German Manufacturing Industry: Recommendations for
Implementing the Strategic Initiative Industrie 4.0. Final Report of the Industrie. 2013. Available online: https://www.din.de/
resource/blob/76902/e8cac883f42bf28536e7e8165993f1fd/recommendations-for-implementing-industry-4-0-data.pdf (accessed
on 5 June 2022).
13.
Xu, M.; David, J.M.; Kim, S.H. The fourth industrial revolution: Opportunities and challenges. Int. J. Financ. Res. 2018, 9, 90–95.
[CrossRef]
14.
Kritzinger, W.; Karner, M.; Traar, G.; Henjes, J.; Sihn, W. Digital Twin in manufacturing: A categorical literature review and
classiﬁcation. IFAC-PapersOnLine 2018, 51, 1016–1022. [CrossRef]
15.
Redelinghuys, A.; Basson, A.H.; Kruger, K. A six-layer architecture for the digital twin: A manufacturing case study implementa-
tion. J. Intell. Manuf. 2020, 31, 1383–1402. [CrossRef]
16.
Tao, F.; Zhang, H.; Liu, A.; Nee, A.Y. Digital twin in industry: State-of-the-art. IEEE Trans. Ind. Inform. 2018, 15, 2405–2415.
[CrossRef]
17.
Negri, E.; Fumagalli, L.; Macchi, M. A review of the roles of digital twin in CPS-based production systems. Procedia Manuf. 2017,
11, 939–948. [CrossRef]
18.
Fuller, A.; Fan, Z.; Day, C.; Barlow, C. Digital twin: Enabling technologies, challenges and open research. IEEE Access 2020,
8, 108952–108971. [CrossRef]
19.
Qi, Q.; Tao, F.; Zuo, Y.; Zhao, D. Digital twin service towards smart manufacturing. Procedia Cirp 2018, 72, 237–242. [CrossRef]
20.
Al Faruque, M.A.; Muthirayan, D.; Yu, S.Y.; Khargonekar, P.P. Cognitive digital twin for manufacturing systems. In Proceedings
of the 2021 Design, Automation & Test in Europe Conference & Exhibition (DATE), Grenoble, France, 1–5 February 2021;
pp. 440–445.
21.
Zeba, G.; Dabi´c, M.; ˇCiˇcak, M.; Daim, T.; Yalcin, H. Technology mining: Artiﬁcial intelligence in manufacturing. Technol. Forecast.
Soc. Chang. 2021, 171, 120971. [CrossRef]
22.
Chien, C.F.; Dauzère-Pérès, S.; Huh, W.T.; Jang, Y.J.; Morrison, J.R. Artiﬁcial intelligence in manufacturing and logistics systems:
algorithms, applications, and case studies. Int. J. Prod. Res. 2020, 58, 2730–2731. [CrossRef]
23.
Crandall, D.J. Artiﬁcial Intelligence and Manufacturing. Smart Factories: Issues of Information Governance. 2019; pp. 10–16.
Available online: https://policyinstitute.iu.edu/doc/mpi/smart-factories.pdf#page=12 (accessed on 5 June 2022).
24.
Bullers, W.I.; Nof, S.Y.; Whinston, A.B. Artiﬁcial intelligence in manufacturing planning and control. AIIE Trans. 1980, 12, 351–363.
[CrossRef]
25.
Arinez, J.F.; Chang, Q.; Gao, R.X.; Xu, C.; Zhang, J. Artiﬁcial intelligence in advanced manufacturing: Current status and future
outlook. J. Manuf. Sci. Eng. 2020, 142, 110804. [CrossRef]
26.
Li, B.H.; Hou, B.C.; Yu, W.T.; Lu, X.B.; Yang, C.W. Applications of artiﬁcial intelligence in intelligent manufacturing: A review.
Front. Inf. Technol. Electron. Eng. 2017, 18, 86–96. [CrossRef]
27.
Buchmeister, B.; Palcic, I.; Ojstersek, R. Artiﬁcial Intelligence in Manufacturing Companies And Broader: An Overview. DAAAM
International Scientiﬁc Book. 2019. Available online: https://daaam.info/sc-book-2019 (accessed on 5 June 2022).
28.
Lee, J.; Davari, H.; Singh, J.; Pandhare, V. Industrial Artiﬁcial Intelligence for industry 4.0-based manufacturing systems. Manuf.
Lett. 2018, 18, 20–23. [CrossRef]
29.
Mourtzis, D.; Doukas, M.; Bernidaki, D. Simulation in manufacturing: Review and challenges. Procedia Cirp 2014, 25, 213–229.
[CrossRef]
30.
Lugaresi, G.; Matta, A. Real-time simulation in manufacturing systems: Challenges and research directions. In Proceedings of
the 2018 Winter Simulation Conference (WSC), Gothenburg, Sweden, 9–12 December 2018; pp. 3319–3330.
31.
Negahban, A.; Smith, J.S. Simulation for manufacturing system design and operation: Literature review and analysis. J. Manuf.
Syst. 2014, 33, 241–261. [CrossRef]
32.
Hollocks, B. A well-kept secret? Simulation in manufacturing industry reviewed. Insight 1992, 5, 12–17.
33.
Hollocks, B.W. The impact of simulation in manufacturing decision making. Control Eng. Pract. 1995, 3, 105–112. [CrossRef]
34.
Ingemansson, A.; Bolmsjö, G.; Harlin, U. A survey of the use of the discrete-event simulation in manufacturing industry. In
Proceedings of the 10th International Manufacturing Conference, Singapore, 11–14 March 2002.
35.
McGinnis, L.F.; Rose, O. History and perspective of simulation in manufacturing. In Proceedings of the 2017 Winter Simulation
Conference (WSC), Las Vegas, NV, USA, 3–6 December 2017; pp. 385–397.
Sensors 2022, 22, 5834
61 of 76
36.
Abeyratne, S.A.; Monfared, R.P. Blockchain ready manufacturing supply chain using distributed ledger. Int. J. Res. Eng. Technol.
2016, 5, 1–10.
37.
Angrish, A.; Craver, B.; Hasan, M.; Starly, B. A case study for Blockchain in manufacturing: “FabRec”: A prototype for peer-to-peer
network of manufacturing nodes. Procedia Manuf. 2018, 26, 1180–1192. [CrossRef]
38.
Li, Z.; Barenji, A.V.; Huang, G.Q. Toward a blockchain cloud manufacturing system as a peer to peer distributed network
platform. Robot. Comput.-Integr. Manuf. 2018, 54, 133–144. [CrossRef]
39.
Kasten, J.E. Engineering and manufacturing on the blockchain: A systematic review. IEEE Eng. Manag. Rev. 2020, 48, 31–47.
[CrossRef]
40.
Ko, T.; Lee, J.; Ryu, D. Blockchain technology and manufacturing industry: Real-time transparency and cost savings. Sustainability
2018, 10, 4274. [CrossRef]
41.
Mohamed, N.; Al-Jaroodi, J. Applying blockchain in industry 4.0 applications. In Proceedings of the 2019 IEEE 9th annual
computing and communication workshop and conference (CCWC), Las Vegas, NV, USA, 7–9 January 2019; pp. 0852–0858.
42.
Belhadi, A.; Zkik, K.; Cherraﬁ, A.; Sha’ri, M.Y. Understanding big data analytics for manufacturing processes: insights from
literature review and multiple case studies. Comput. Ind. Eng. 2019, 137, 106099. [CrossRef]
43.
Dai, H.N.; Wang, H.; Xu, G.; Wan, J.; Imran, M. Big data analytics for manufacturing internet of things: opportunities, challenges
and enabling technologies. Enterp. Inf. Syst. 2020, 14, 1279–1303. [CrossRef]
44.
Sahoo, S. Big data analytics in manufacturing: A bibliometric analysis of research in the ﬁeld of business management. Int. J.
Prod. Res. 2021, 1–29. [CrossRef]
45.
Dubey, R.; Gunasekaran, A.; Childe, S.J.; Blome, C.; Papadopoulos, T. Big data and predictive analytics and manufacturing
performance: integrating institutional theory, resource-based view and big data culture. Br. J. Manag. 2019, 30, 341–361. [CrossRef]
46.
Bashar, A. Intelligent development of big data analytics for manufacturing industry in cloud computing. J. Ubiquitous Comput.
Commun. Technol. (UCCT) 2019, 1, 13–22.
47.
Ong, S.K.; Nee, A.Y.C.
Virtual and Augmented Reality Applications in Manufacturing; Springer Science & Business Media:
Berlin/Heidelberg, Germany, 2013.
48.
Ong, S.; Nee, A. A brief introduction of VR and AR applications in manufacturing. In Virtual and Augmented Reality Applications in
Manufacturing; Springer: Berlin/Heidelberg, Germany, 2004; pp. 1–11.
49.
Siedler, C.; Glatt, M.; Weber, P.; Ebert, A.; Aurich, J.C. Engineering changes in manufacturing systems supported by AR/VR
collaboration. Procedia CIRP 2021, 96, 307–312. [CrossRef]
50.
Fast-Berglund, Å.; Gong, L.; Li, D. Testing and validating Extended Reality (xR) technologies in manufacturing. Procedia Manuf.
2018, 25, 31–38. [CrossRef]
51.
Doolani, S.; Wessels, C.; Kanal, V.; Sevastopoulos, C.; Jaiswal, A.; Nambiappan, H.; Makedon, F. A review of extended reality (xr)
technologies for manufacturing training. Technologies 2020, 8, 77. [CrossRef]
52.
Ong, S.; Yuan, M.; Nee, A. Augmented reality applications in manufacturing: A survey. Int. J. Prod. Res. 2008, 46, 2707–2742.
[CrossRef]
53.
Nee, A.Y.; Ong, S.; Chryssolouris, G.; Mourtzis, D. Augmented reality applications in design and manufacturing. CIRP Ann.
2012, 61, 657–679. [CrossRef]
54.
Doil, F.; Schreiber, W.; Alt, T.; Patron, C. Augmented reality for manufacturing planning. In Proceedings of the Workshop on
Virtual Environments, Zurich, Switzerland, 22–23 May 2003, pp. 71–76.
55.
Goel, R.; Gupta, P. Robotics and industry 4.0. In A Roadmap to Industry 4.0: Smart Production, Sharp Business and Sustainable
Development; Springer: Berlin/Heidelberg, Germany, 2020; pp. 157–169.
56.
Bayram, B.; ˙Ince, G. Advances in Robotics in the Era of Industry 4.0. In Industry 4.0: Managing The Digital Transformation; Springer:
Berlin/Heidelberg, Germany, 2018; pp. 187–200.
57.
Heyer, C. Human-robot interaction and future industrial robotics applications. In Proceedings of the 2010 IEEE/RSJ International
Conference on Intelligent Robots and Systems, Taipei, Taiwan, 18–22 October 2010; pp. 4749–4754.
58.
Hägele, M.; Nilsson, K.; Pires, J.N.; Bischoff, R. Industrial robotics. In Springer Handbook of Robotics; Springer: Berlin/Heidelberg,
Germany, 2016; pp. 1385–1422.
59.
Parmar, H.; Khan, T.; Tucci, F.; Umer, R.; Carlone, P. Advanced robotics and additive manufacturing of composites: Towards a
new era in Industry 4.0. Mater. Manuf. Process. 2022, 37, 483–517. [CrossRef]
60.
Tantawi, K.H.; Sokolov, A.; Tantawi, O. Advances in industrial robotics: From industry 3.0 automation to industry 4.0 collaboration.
In Proceedings of the 2019 4th Technology Innovation Management and Engineering Science International Conference (TIMES-
iCON), Bangkok, Thailand, 11–13 December 2019; pp. 1–4.
61.
Li, M.; Milojevi´c, A.; Handroos, H. Robotics in manufacturing—The past and the present. In Technical, Economic and Societal Effects
of Manufacturing 4.0; Palgrave Macmillan: Cham, Switerland, 2020; pp. 85–95.
62.
Groover, M.P. Fundamentals of Modern Manufacturing: Materials, Processes, and Systems; J. Wiley & Sons: Hoboken, NJ, USA, 2007.
63.
Rosen, R.; Von Wichert, G.; Lo, G.; Bettenhausen, K.D. About the importance of autonomy and digital twins for the future of
manufacturing. Ifac-Papersonline 2015, 48, 567–572. [CrossRef]
64.
Pustišek, M.; Chen, M.; Kos, A.; Kos, A. Decentralized Machine Autonomy for Manufacturing Servitization. Sensors 2022, 22, 338.
[CrossRef] [PubMed]
Sensors 2022, 22, 5834
62 of 76
65.
Park, H. From Automation to Autonomy—A new trend for Smart Manufacturing. DAAAM International Scientiﬁc Book. 2013.
Available online: https://daaam.info/sc-book-2013 (accessed on 5 June 2022).
66.
Park, H.S.; Tran, N.H. Autonomy for smart manufacturing. J. Korean Soc. Precis. Eng. 2014, 31, 287–295. [CrossRef]
67.
Horvitz, E.; Selman, B. Interim report from the panel chairs: AAAI Presidential Panel on Long-Term AI Futures. In Singularity
Hypotheses; Springer: Berlin/Heidelberg, Germany, 2012; pp. 301–308.
68.
Pohl, J.
Artiﬁcial Super Intelligence:
Extinction or Nirvana.
Intern Symposium.
2015.
Available online:
https:
//www.researchgate.net/proﬁle/Jens-Pohl/publication/281748315_Artiﬁcial_Superintelligence_Extinction_or_Nirvana/
links/55f723c908aeafc8abfa21ca/Artiﬁcial-Superintelligence-Extinction-or-Nirvana.pdf (accessed on 5 June 2022).
69.
Almada-Lobo, F. The Industry 4.0 revolution and the future of Manufacturing Execution Systems (MES). J. Innov. Manag. 2015,
3, 16–21. [CrossRef]
70.
Liu, Y.; Xu, X. Industry 4.0 and cloud manufacturing: A comparative analysis. J. Manuf. Sci. Eng. 2017, 139, 034701. [CrossRef]
71.
Lu, Y. Industry 4.0: A survey on technologies, applications and open research issues. J. Ind. Inf. Integr. 2017, 6, 1–10. [CrossRef]
72.
Thames, L.; Schaefer, D. Industry 4.0: An overview of key beneﬁts, technologies, and challenges. In Cybersecurity for Industry 4.0;
Springer: Berlin/Heidelberg, Germany, 2017; pp. 1–33.
73.
Porter, M.E.; Heppelmann, J.E. How smart, connected products are transforming companies. Harv. Bus. Rev. 2015, 93, 96–114.
74.
Thoben, K.D.; Wiesner, S.; Wuest, T. “Industrie 4.0” and smart manufacturing—A review of research issues and application
examples. Int. J. Autom. Technol. 2017, 11, 4–16. [CrossRef]
75.
Kagermann, H.; Wahlster, W.; Helbig J. Recommendations for Implementing the Strategic Initiative INDUSTRIE 4.0: Securing the
Future of German Manufacturing Industry. Final Report of the Industrie 4.0 Working Group; Technical Report, Forschungsunion.
Available online: https://en.acatech.de/publication/recommendations-for-implementing-the-strategic-initiative-industrie-4-
0-ﬁnal-report-of-the-industrie-4-0-working-group/ (accessed on 5 June 2022).
76.
Henning Kagermann, P.D.W.W.; Helbig, D.J. Recommendations for Implementing the Strategic Initiative INDUSTRIE 4.0-Final Report
of the Industrie 4.0 Working Group; Technical Report; German Federal Ministry of Education and Research (BMBF): Bonn, Germany,
2013.
77.
Stock, T.; Seliger, G. Opportunities of sustainable manufacturing in industry 4.0. Procedia Cirp 2016, 40, 536–541. [CrossRef]
78.
Hermann, M.; Pentek, T.; Otto, B. Design Principles for Industrie 4.0 Scenarios: A Literature Review; Technische Universität Dortmund:
Dortmund, Germany, 2015.
79.
Kagermann, H. Chancen von Industrie 4.0 nutzen. In Industrie 4.0 in Produktion, Automatisierung und Logistik: Anwendung,
Technologien; ten Hompel, M., Vogel-Heuser, B., Bauernhansl, T., Eds.; Springer: Berlin/Heidelberg, Germany, 2014.
80.
Bitkom, F.I. Industrie 4.0–Volkswirtschaftliches Potenzial für Deutschland. Berlin/Stuttgart. 2014. Available online: https:
//www.produktionsarbeit.de/content/dam/produktionsarbeit/de/documents/Studie-Industrie-4-0-Volkswirtschaftliches-
Potential-fuer-Deutschland.pdf (accessed on 5 June 2022).
81.
2017: State of the IIoT-Key Trends and Predictions for the Industrial Internet of Things. Available online: https://www.opto22.
com/support/resources-tools/documents/2215-white-paper-state-of-the-iiot-2017 (accessed on 5 June 2022).
82.
Bezerra, F.; Favacho, C.H.; Souza, R.; de Souza, C. Towards supporting systematic mappings studies: An automatic snowballing
approach. In Proceedings of the Simpósio Brasileiro de Banco de Dados (SBBD), Curitiba, Brazil, 6–9 October 2014.
83.
van Haastrecht, M.; Sarhan, I.; Yigit Ozkan, B.; Brinkhuis, M.; Spruit, M. SYMBALS: A systematic review methodology blending
active learning and snowballing. Front. Res. Metrics Anal. 2021, 6, 33. [CrossRef] [PubMed]
84.
Michael Lyman, R.R.; Wright, O. Accenture Strategy: Cornerstone of Future Growth: Ecosystems; Technical Report; Accenture: Dublin,
Ireland, 2018.
85.
Gaub, H. Customization of mass-produced parts by combining injection molding and additive manufacturing with Industry 4.0
technologies. Reinf. Plast. 2016, 60, 401–404. [CrossRef]
86.
Prasad, D.; Jayswal, S. Reconﬁgurable manufacturing system–a new class of manufacturing system. Manag. Prod. Eng. Rev. 2019,
10, 37–47.
87.
Koren, Y. Reconﬁgurable manufacturing and beyond. In Proceedings of the CIRP 3rd International Conference on Reconﬁgurable
Manufacturing, Ann Arbor, MI, USA, 10 May 2005.
88.
Pansare, R.; Yadav, G.; Nagare, M.R. Reconﬁgurable manufacturing system: A systematic review, meta-analysis and future
research directions. J. Eng. Des. Technol. 2021. [CrossRef]
89.
Mehrabi, M.G.; Ulsoy, A.G.; Koren, Y. Reconﬁgurable manufacturing systems: Key to future manufacturing. J. Intell. Manuf. 2000,
11, 403–419. [CrossRef]
90.
Bi, Z.M.; Lang, S.Y.; Shen, W.; Wang, L. Reconﬁgurable manufacturing systems: The state of the art. Int. J. Prod. Res. 2008,
46, 967–992. [CrossRef]
91.
Koren, Y.; Heisel, U.; Jovane, F.; Moriwaki, T.; Pritschow, G.; Ulsoy, G.; Van Brussel, H. Reconﬁgurable manufacturing systems.
CIRP Ann. 1999, 48, 527–540. [CrossRef]
92.
ElMaraghy, H.A. Flexible and reconﬁgurable manufacturing systems paradigms. Int. J. Flex. Manuf. Syst. 2005, 17, 261–276.
[CrossRef]
93.
Shivanand, H. Flexible Manufacturing System; New Age International: New Delhi, India, 2006.
94.
Browne, J.; Dubois, D.; Rathmill, K.; Sethi, S.P.; Stecke, K.E. Classiﬁcation of ﬂexible manufacturing systems. FMS Mag. 1984,
2, 114–117.
Sensors 2022, 22, 5834
63 of 76
95.
Yadav, A.; Jayswal, S. Modelling of ﬂexible manufacturing system: A review. Int. J. Prod. Res. 2018, 56, 2464–2487. [CrossRef]
96.
MacCarthy, B.; Liu, J. A new classiﬁcation scheme for ﬂexible manufacturing systems. Int. J. Prod. Res. 1993, 31, 299–309.
[CrossRef]
97.
Stam, A.; Kuula, M. Selecting a ﬂexible manufacturing system using multiple criteria analysis. Int. J. Prod. Res. 1991, 29, 803–820.
[CrossRef]
98.
Florescu, A.; Barabas, S.A. Modeling and simulation of a ﬂexible manufacturing system—A basic component of industry 4.0.
Appl. Sci. 2020, 10, 8300. [CrossRef]
99.
Park, S.C. A methodology for creating a virtual model for a ﬂexible manufacturing system. Comput. Ind. 2005, 56, 734–746.
[CrossRef]
100. Greenwood, N.R. Implementing Flexible Manufacturing Systems; Springer: Berlin/Heidelberg, Germany, 1988.
101. Srai, J.S.; Kumar, M.; Graham, G.; Phillips, W.; Tooze, J.; Ford, S.; Beecher, P.; Raj, B.; Gregory, M.; Tiwari, M.K.; et al. Distributed
manufacturing: Scope, challenges and opportunities. Int. J. Prod. Res. 2016, 54, 6917–6935. [CrossRef]
102. Leitão, P. Agent-based distributed manufacturing control: A state-of-the-art survey. Eng. Appl. Artif. Intell. 2009, 22, 979–991.
[CrossRef]
103. Huang, C.Y. Distributed manufacturing execution systems: A workﬂow perspective. J. Intell. Manuf. 2002, 13, 485–497. [CrossRef]
104. Rauch, E.; Dallasega, P.; Matt, D.T. Distributed manufacturing network models of smart and agile mini-factories. Int. J. Agil. Syst.
Manag. 2017, 10, 185–205. [CrossRef]
105. Xu, X. From cloud computing to cloud manufacturing. Robot. Comput.-Integr. Manuf. 2012, 28, 75–86. [CrossRef]
106. Ren, L.; Zhang, L.; Wang, L.; Tao, F.; Chai, X. Cloud manufacturing: Key characteristics and applications. Int. J. Comput. Integr.
Manuf. 2017, 30, 501–515. [CrossRef]
107. Ren, L.; Zhang, L.; Tao, F.; Zhao, C.; Chai, X.; Zhao, X. Cloud manufacturing: From concept to practice. Enterp. Inf. Syst. 2015,
9, 186–209. [CrossRef]
108. Li, W.; Mehnen, J. (Eds.) Cloud Manufacturing: Distributed Computing Technologies for Global and Sustainable Manufacturing; Springer:
Berlin/Heidelberg, Germany, 2013.
109. Adamson, G.; Wang, L.; Holm, M.; Moore, P. Cloud manufacturing–a critical review of recent development and future trends. Int.
J. Comput. Integr. Manuf. 2017, 30, 347–380. [CrossRef]
110. He, W.; Xu, L. A state-of-the-art survey of cloud manufacturing. Int. J. Comput. Integr. Manuf. 2015, 28, 239–250. [CrossRef]
111. Hozdi´c, E. Smart factory for industry 4.0: A review. Int. J. Mod. Manuf. Technol. 2015, 7, 28–35.
112. Osterrieder, P.; Budde, L.; Friedli, T. The smart factory as a key construct of industry 4.0: A systematic literature review. Int. J.
Prod. Econ. 2020, 221, 107476. [CrossRef]
113. Lucke, D.; Constantinescu, C.; Westkämper, E. Smart factory-a step towards the next generation of manufacturing. In Manufactur-
ing Systems and Technologies for the New Frontier; Springer: Berlin/Heidelberg, Germany, 2008; pp. 115–118.
114. Wang, S.; Wan, J.; Zhang, D.; Li, D.; Zhang, C. Towards smart factory for industry 4.0: A self-organized multi-agent system with
big data based feedback and coordination. Comput. Netw. 2016, 101, 158–168. [CrossRef]
115. Radziwon, A.; Bilberg, A.; Bogers, M.; Madsen, E.S. The smart factory: Exploring adaptive and ﬂexible manufacturing solutions.
Procedia Eng. 2014, 69, 1184–1190. [CrossRef]
116. Shi, Z.; Xie, Y.; Xue, W.; Chen, Y.; Fu, L.; Xu, X. Smart factory in Industry 4.0. Syst. Res. Behav. Sci. 2020, 37, 607–617. [CrossRef]
117. Shaﬁq, S.I.; Velez, G.; Toro, C.; Sanin, C.; Szczerbicki, E. Designing intelligent factory: Conceptual framework and empirical
validation. Procedia Comput. Sci. 2016, 96, 1801–1808. [CrossRef]
118. Reimann, J.; Sziebig, G. The intelligent factory space–a concept for observing, learning and communicating in the digitalized
factory. IEEE Access 2019, 7, 70891–70900. [CrossRef]
119. Lu, B.; Shao, X.; Zhang, J.; Wang, L. Development strategy for intelligent factory in discrete manufacturing. Strateg. Study Chin.
Acad. Eng. 2018, 20, 44–50. [CrossRef]
120. Larrabee, G.B. The intelligent microelectronics factory of the future.
In Proceedings of the 1991 Proceedings IEEE/SEMI
International Semiconductor Manufacturing Science Symposium, Burlingame, CA, USA, 20–22 May 1991; pp. 30–34.
121. Erdogan, S.; Wahab, A. A Family of Reconﬁgurable Neurocomputers For The “Intelligent Factory”. In Proceedings of the IEEE
International Workshop on Emerging Technologies and Factory Automation, Melbourne, VIC, Australia, 11–14 August 1992;
pp. 369–374.
122. Bracht, U.; Masurat, T. The Digital Factory between vision and reality. Comput. Ind. 2005, 56, 325–333. [CrossRef]
123. Kuhn, W. Digital factory-simulation enhancing the product and production engineering process. In Proceedings of the 2006
Winter Simulation Conference, Monterey, CA, USA, 3–6 December 2006; pp. 1899–1906.
124. Worn, H.; Frey, D.; Keitel, J. Digital factory-planning and running enterprises of the future. In Proceedings of the 2000 26th Annual
Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics,
Control and Instrumentation. 21st Century Technologies, Nagoya, Japan, 22–28 October 2000; Volume 2, pp. 1286–1291.
125. Tchoffa, D.; Figay, N.; Ghodous, P.; Expósito, E.; Kermad, L.; Vosgien, T.; El Mhamedi, A. Digital factory system for dynamic
manufacturing network supporting networked collaborative product development.
Data Knowl. Eng. 2016, 105, 130–154.
[CrossRef]
126. Gregor, M.; Medvecky, S. Digital factory–theory and practice. In Engineering the Future; IntechOpen: London, UK 2010.
127. Lee, J. Smart factory systems. Informatik-Spektrum 2015, 38, 230–235. [CrossRef]
Sensors 2022, 22, 5834
64 of 76
128. Mabkhot, M.M.; Al-Ahmari, A.M.; Salah, B.; Alkhalefah, H. Requirements of the smart factory system: A survey and perspective.
Machines 2018, 6, 23. [CrossRef]
129. Panetto, H.; Iung, B.; Ivanov, D.; Weichhart, G.; Wang, X. Challenges for the cyber-physical manufacturing enterprises of the
future. Annu. Rev. Control 2019, 47, 200–213. [CrossRef]
130. Gierej, S. The framework of business model in the context of Industrial Internet of Things. Procedia Eng. 2017, 182, 206–212.
[CrossRef]
131. Dujovne, D.; Watteyne, T.; Vilajosana, X.; Thubert, P. 6TiSCH: Deterministic IP-enabled industrial internet (of things). IEEE
Commun. Mag. 2014, 52, 36–41. [CrossRef]
132. Lu, Y.; Asghar, M.R. Semantic communications between distributed cyber-physical systems towards collaborative automation for
smart manufacturing. J. Manuf. Syst. 2020, 55, 348–359. [CrossRef]
133. Wong, G.; Greenhalgh, T.; Westhorp, G.; Buckingham, J.; Pawson, R. RAMESES publication standards: Realist syntheses. BMC
Med. 2013, 11, 21.
134. Liu, C.; Jiang, P. A cyber-physical system architecture in shop ﬂoor for intelligent manufacturing. Procedia Cirp 2016, 56, 372–377.
[CrossRef]
135. Kusiak, A. Smart manufacturing. Int. J. Prod. Res. 2018, 56, 508–517. [CrossRef]
136. Zhang, Y.; Zhang, G.; Wang, J.; Sun, S.; Si, S.; Yang, T. Real-time information capturing and integration framework of the internet
of manufacturing things. Int. J. Comput. Integr. Manuf. 2015, 28, 811–822. [CrossRef]
137. Liu, X.F.; Shahriar, M.R.; Al Sunny, S.N.; Leu, M.C.; Hu, L. Cyber-physical manufacturing cloud: Architecture, virtualization,
communication, and testbed. J. Manuf. Syst. 2017, 43, 352–364. [CrossRef]
138. Kühnle, H.; Bitsch, G.
Smart manufacturing units.
In Foundations & Principles of Distributed Manufacturing; Springer:
Berlin/Heidelberg, Germany, 2015; pp. 55–70.
139. Davis, J. Cyberinfrastructure in Chemical and Biological Process Systems: Impact and Directions. Proc. NSF Workshop Rep.
2006. Available online: https://www.nsf.gov/awardsearch/showAward?AWD_ID=0645024&HistoricalAwards=false (accessed
on 5 June 2022).
140. Baldwin, C.Y.; Clark, K.B.; Clark, K.B. Design Rules: The Power of Modularity; MIT Press: Cambridge, MA, USA, 2000; Volume 1.
141. Singh, A.; Gupta, S.; Asjad, M.; Gupta, P. Reconﬁgurable manufacturing systems: Journey and the road ahead. Int. J. Syst. Assur.
Eng. Manag. 2017, 8, 1849–1857. [CrossRef]
142. Renzi, C.; Leali, F.; Cavazzuti, M.; Andrisano, A.O. A review on artiﬁcial intelligence applications to the optimal design of
dedicated and reconﬁgurable manufacturing systems. Int. J. Adv. Manuf. Technol. 2014, 72, 403–418. [CrossRef]
143. Wang, Y.; Ma, H.S.; Yang, J.H.; Wang, K.S. Industry 4.0: A way from mass customization to mass personalization production.
Adv. Manuf. 2017, 5, 311–320. [CrossRef]
144. Pech, M.; Vrchota, J. The Product Customization Process in Relation to Industry 4.0 and Digitalization. Processes 2022, 10, 539.
[CrossRef]
145. Anshari, M.; Almunawar, M.N.; Lim, S.A.; Al-Mudimigh, A. Customer relationship management and big data enabled:
Personalization & customization of services. Appl. Comput. Inform. 2019, 15, 94–101.
146. Lasi, H.; Fettke, P.; Kemper, H.G.; Feld, T.; Hoffmann, M. Industry 4.0. Bus. Inf. Syst. Eng. 2014, 6, 239–242. [CrossRef]
147. Song, X.; Wang, S.; Xie, P.; Wei, Z. Manufacturing Flexibility, Business Model Design, and Firm Performance. In Academy of
Management Proceedings; Academy of Management: Briarcliff Manor, NY, USA, 2017; Volume 2017, p. 13195.
148. Qin, J.; Liu, Y.; Grosvenor, R. A categorical framework of manufacturing for industry 4.0 and beyond.
Procedia Cirp 2016,
52, 173–178. [CrossRef]
149. Wang, L.; Törngren, M.; Onori, M. Current status and advancement of cyber-physical systems in manufacturing. J. Manuf. Syst.
2015, 37, 517–527. [CrossRef]
150. Azevedo, A.; Almeida, A. Factory templates for digital factories framework. Robot. Comput.-Integr. Manuf. 2011, 27, 755–771.
[CrossRef]
151. Ferreira, F.; Azevedo, A.; Faria, J.; Rojas, E. Virtual enterprise process management: An application to industrial maintenance. In
Working Conference on Virtual Enterprises; Springer: Berlin/Heidelberg, Germany, 2014; pp. 71–79.
152. Wang, S.; Wan, J.; Li, D.; Zhang, C. Implementing smart factory of industrie 4.0: An outlook. Int. J. Distrib. Sens. Netw. 2016,
12, 3159805. [CrossRef]
153. Morris, E.; Levine, L.; Meyers, C.; Place, P.; Plakosh, D. Systems of Systems Interoperability. SEI, Carnegie Mellon University, USA.
2004. Available online: https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=7045 (accessed on 5 June 2022).
154. Chituc, C.M.; Toscano, C.; Azevedo, A. Interoperability in Collaborative Networks: Independent and industry-speciﬁc initiatives–
The case of the footwear industry. Comput. Ind. 2008, 59, 741–757. [CrossRef]
155. Berre, A.J.; Hahn, A.; Akehurst, D.; Bezivin, J.; Tsalgatidou, A.; Vermaut, F.; Kutvonen, L.; Linington, P.F. State-of-the Art for
Interoperability Architecture Approaches. InterOP Network of Excellence-Contract no.: IST-508. 2004, Volume 11. Available online:
https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.9713&rep=rep1&type=pdf (accessed on 5 June 2022).
156. Curts, R.J.; Campbell, D.E. Architecture: The road to interoperability. In Command & Control Research & Technology Symposium
(CCRTS); US Naval War College: Newport, RI, USA, 1999.
157. Heiler, S. Semantic interoperability. ACM Comput. Surv. (CSUR) 1995, 27, 271–273. [CrossRef]
Sensors 2022, 22, 5834
65 of 76
158. Ford, T.C.; Colombi, J.M.; Graham, S.R.; Jacques, D.R. Survey on Interoperability Measurement; Technical Report; Air Force Institute
of Tech Wright-Patterson AFB OH: Greene County, OH, USA, 2007.
159. Kasunic, M. Measuring Systems Interoperability: Challenges and Opportunities; Technical Report; Carnegie-Mellon Univ Pittsburgh
Pa Software Engineering Inst: Pittsburgh, PA, USA, 2001.
160. Zeid, A.; Sundaram, S.; Moghaddam, M.; Kamarthi, S.; Marion, T. Interoperability in smart manufacturing: Research challenges.
Machines 2019, 7, 21. [CrossRef]
161. Information Technology-Message Queuing Telemetry Transport (MQTT) v3.1.1; Technical Report; ISO/IEC: Geneva, Switzerland, 2016.
162. Brunnermeier, S.; Martin, S. Interoperability Cost Analysis of the US Automotive Supply Chain; Center for Economics Research
(Research Triangle Institute): Research Triangle Park, NC, USA, 1999.
163. Vogel-Heuser, G.; Kegel, G.; K. Bender, K.; Wucherer, K. Global information architecture for industrial automation. Automa-
tisierungstechnische Praxis (ATP) 2009, 51, 108–115 [CrossRef]
164. Levis, A.H.; Rouse, W.B. Systems architecture. In Handbook of Systems Engineering and Management, 2nd ed.; Sage, A.P., Ed.; John
Wiley & Sons: Hoboken, NJ, USA, 2011; pp. 479–506.
165. Christopher, N.; Feng, S.C.; Fowler, J.E.; Frechette, S.P.; Jones, A.; Jurrens, K.; Lyons, K.; McLean, C.R.; Pratt, M.; Scott, H.A.; et al.
SIMA Reference Architecture Part 1: Activity Models; National Institute of Standards and Technology: Gaithersburg, MD, USA, 1996.
166. Han, S. A review of smart manufacturing reference models based on the skeleton meta-model. J. Comput. Des. Eng. 2020,
7, 323–336. [CrossRef]
167. DIN SPEC. 91345: 2016-04 Reference Architecture Model Industrie 4.0 (RAMI4. 0). DIN 2016, 4, 2016.
168. Lin, S.W.; Miller, B.; Durand, J.; Joshi, R.; Didier, P.; Chigani, A.; Torenbeek, R.; Duggal, D.; Martin, R.; Bleakley, G.; et al. Industrial
Internet Reference Architecture; Techonol Report; Industrial Internet Consortium (IIC): Boston, MA, USA 2015.
169. Amdahl, G.M.; Blaauw, G.A.; Brooks, F.P. Architecture of the IBM System/360. IBM J. Res. Dev. 1964, 8, 87–101. [CrossRef]
170. Nakagawa, E.Y.; Antonino, P.O.; Schnicke, F.; Capilla, R.; Kuhn, T.; Liggesmeyer, P. Industry 4.0 reference architectures: State of
the art and future trends. Comput. Ind. Eng. 2021, 156, 107241. [CrossRef]
171. Helmann, A.; Deschamps, F.; Loures, E. Reference architectures for Industry 4.0: Literature review. Adv Transdiscip Eng 2020,
12, 171–180.
172. Lu, Y.; Morris, K.C.; Frechette, S. Standards landscape and directions for smart manufacturing systems. In Proceedings of the
2015 IEEE International Conference on Automation Science and Engineering (CASE), Gothenburg, Sweden, 24–28 August 2015;
pp. 998–1005.
173. Wei, S.; Hu, J.; Cheng, Y.; Ma, Y.; Yu, Y. The essential elements of intelligent manufacturing system architecture. In Proceedings of
the 2017 13th IEEE Conference on Automation Science and Engineering (CASE), Xi’an, China, 20–23 August 2017; pp. 1006–1011.
174. Industrial Value Chain Initiative. Strategic Implementation of Smart Manufacturing Ecosystem by IVRA-Next Framework); Techonol
Report; Industrial Value Chain Initiative: Tokyo, Japan 2018.
175. Wang, Y.; Towara, T.; Anderl, R. Topological approach for mapping technologies in reference architectural model Industrie 4.0
(RAMI 4.0). In Proceedings of the World Congress on Engineering and Computer Science, London, UK, 5–7 July 2017; Volume 2,
pp. 25–27.
176. IVCI. Industrial Value Chain Reference Architecture. Hannover, Germany. 2017. Available online: http://www.iaeng.org/
publication/WCECS2017/WCECS2017_pp982-990.pdf (accessed on 5 June 2022).
177. Moghaddam, M.; Cadavid, M.N.; Kenley, C.R.; Deshmukh, A.V. Reference architectures for smart manufacturing: A critical
review. J. Manuf. Syst. 2018, 49, 215–225. [CrossRef]
178. Lu, Y.; Morris, K.C.; Frechette, S. Current Standards Landscape for Smart Manufacturing Systems; National Institute of Standards and
Technology, NISTIR: Gaithersburg, MD, USA, 2016.
179. Yli-Ojanperä, M.; Sierla, S.; Papakonstantinou, N.; Vyatkin, V. Adapting an agile manufacturing concept to the reference
architecture model industry 4.0: A survey and case study. J. Ind. Inf. Integr. 2019, 15, 147–160. [CrossRef]
180. Lin, S.W.; Murphy, B.; Clauer, E.; Loewen, U.; Neubert, R.; Bachmann, G.; Pai, M.; Hankel, M. Architecture Alignment and
Interoperability: An Industrial Internet Consortium and Plattform Industrie 4.0 Joint Whitepaper; White Paper; Industrial Internet
Consortium: Boston, MA, USA, 2017.
181. Pai, D. Interoperability between IIC Architecture & Industry 4.0 Reference Architecture for Industrial Assets. Tech. Rep. 2016, 1,
1–12.
182. Adolphs, P. RAMI 4.0. An architectural Model for Industrie 4.0. Plattform Industrie 4.0. 2015. Available online: https://ec.europa.
eu/futurium/en/system/ﬁles/ged/a2-schweichhart-reference_architectural_model_industrie_4.0_rami_4.0.pdf (accessed on 5
June 2022).
183. Hankel, M.; Rexroth, B. The reference architectural model industrie 4.0 (rami 4.0). ZVEI 2015, 2, 4–9.
184. Weber, C.; Königsberger, J.; Kassner, L.; Mitschang, B. M2DDM–a maturity model for data-driven manufacturing. Procedia Cirp
2017, 63, 173–178. [CrossRef]
185. Gröger, C.; Kassner, L.; Hoos, E.; Königsberger, J.; Kiefer, C.; Silcher, S.; Mitschang, B. The data-driven factory. In Proceedings
of the ICEIS 2016—18th International Conference on Enterprise Information Systems, Rome, Italy, 25–28 April 2016; Volume 1,
pp. 40–41.
Sensors 2022, 22, 5834
66 of 76
186. Adolphs, P.; Bedenbender, H.; Dirzus, D.; Ehlich, M.; Epple, U.; Hankel, M.; Heidel, R.; Hoffmeister, M.; Huhle, H.; Kärcher,
B.; et al.
Reference Architecture Model Industrie 4.0 (RAMI4. 0).
ZVEI and VDI, Status Report. 2015. Available on-
line: https://www.zvei.org/ﬁleadmin/user_upload/Presse_und_Medien/Publikationen/2016/januar/GMA_Status_Report_
Reference_Archtitecture_Model_Industrie_4.0_RAMI_4.0_/GMA-Status-Report-RAMI-40-July-2015.pdf (accessed on 5 June
2022).
187. Santos, C.; Mehrsai, A.; Barros, A.; Araújo, M.; Ares, E. Towards Industry 4.0: An overview of European strategic roadmaps.
Procedia Manuf. 2017, 13, 972–979. [CrossRef]
188. de Melo, P.F.S.; Godoy, E.P. Controller Interface for Industry 4.0 based on RAMI 4.0 and OPC UA. In Proceedings of the 2019 II
Workshop on Metrology for Industry 4.0 and IoT (MetroInd4.0 and IoT), Naples, Italy, 4–6 June 2019; pp. 229–234. [CrossRef]
189. Contreras, J.D.; Garcia, J.I.; Pastrana, J.D. Developing of Industry 4.0 Applications. Int. J. Online Eng. 2017, 13, 30–47. [CrossRef]
190. Pisching, M.A.; Pessoa, M.A.; Junqueira, F.; dos Santos Filho, D.J.; Miyagi, P.E. An architecture based on RAMI 4.0 to discover
equipment to process operations required by products. Comput. Ind. Eng. 2018, 125, 574–591. [CrossRef]
191. Melo, P.F.; Godoy, E.P.; Ferrari, P.; Sisinni, E. Open source control device for industry 4.0 based on RAMI 4.0. Electronics 2021,
10, 869. [CrossRef]
192. Hernández, E.; Senna, P.; Silva, D.; Rebelo, R.; Barros, A.C.; Toscano, C. Implementing RAMI-4.0 in production-a multi-case study.
In International Conference of Progress in Digital and Physical Manufacturing; Springer: Berlin/Heidelberg, Germany, 2019; pp. 49–56.
193. Schulte, D.; Colombo, A.W. Rami 4.0 based digitalization of an industrial plate extruder system: Technical and infrastructural
challenges. In Proceedings of the IECON 2017-43rd Annual Conference of the IEEE Industrial Electronics Society, Beijing, China,
29 October–1 November 2017; pp. 3506–3511.
194. González, I.; Calderón, A.J.; Figueiredo, J.; Sousa, J. A literature survey on open platform communications (OPC) applied to
advanced industrial environments. Electronics 2019, 8, 510. [CrossRef]
195. Luo, Z.; Hong, S.; Lu, R.; Li, Y.; Zhang, X.; Kim, J.; Park, T.; Zheng, M.; Liang, W. OPC UA-based smart manufacturing: System
architecture, implementation, and execution. In Proceedings of the 2017 5th International Conference on Enterprise Systems (ES),
Beijing, China, 22–24 September 2017; pp. 281–286.
196. Grüner, S.; Pfrommer, J.; Palm, F. RESTful industrial communication with OPC UA. IEEE Trans. Ind. Inform. 2016, 12, 1832–1841.
[CrossRef]
197. Derhamy, H.; Rönnholm, J.; Delsing, J.; Eliasson, J.; van Deventer, J. Protocol interoperability of OPC UA in service oriented
architectures. In Proceedings of the 2017 IEEE 15th International Conference on Industrial Informatics (INDIN), Emden, Germany,
24–26 July 2017; pp. 44–50.
198. Schleipen, M.; Gilani, S.S.; Bischoff, T.; Pfrommer, J. OPC UA & Industrie 4.0-enabling technology with high diversity and
variability. Procedia Cirp 2016, 57, 315–320.
199. Ye, X.; Hong, S.H. An AutomationML/OPC UA-based Industry 4.0 solution for a manufacturing system. In Proceedings of the
2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA), Turin, Italy, 4–7 September
2018; Volume 1, pp. 543–550.
200. Rocha, M.S.; Sestito, G.S.; Dias, A.L.; Turcato, A.C.; Brandão, D.; Ferrari, P. On the performance of OPC UA and MQTT for data
exchange between industrial plants and cloud servers. ACTA IMEKO 2019, 8, 80–87. [CrossRef]
201. Ferrari, P.; Flammini, A.; Rinaldi, S.; Sisinni, E.; Maffei, D.; Malara, M. Impact of quality of service on cloud based industrial IoT
applications with OPC UA. Electronics 2018, 7, 109. [CrossRef]
202. Lema, M.A.; Laya, A.; Mahmoodi, T.; Cuevas, M.; Sachs, J.; Markendahl, J.; Dohler, M. Business case and technology analysis for
5G low latency applications. IEEE Access 2017, 5, 5917–5935. [CrossRef]
203. Maier, M.; Chowdhury, M.; Rimal, B.P.; Van, D.P. The tactile internet: Vision, recent progress, and open challenges. IEEE Commun.
Mag. 2016, 54, 138–145. [CrossRef]
204. Simsek, M.; Aijaz, A.; Dohler, M.; Sachs, J.; Fettweis, G. 5G-enabled tactile internet. IEEE J. Sel. Areas Commun. 2016, 34, 460–473.
[CrossRef]
205. Bhushan, N.; Li, J.; Malladi, D.; Gilmore, R.; Brenner, D.; Damnjanovic, A.; Sukhavasi, R.T.; Patel, C.; Geirhofer, S. Network
densiﬁcation: The dominant theme for wireless evolution into 5G. IEEE Commun. Mag. 2014, 52, 82–89. [CrossRef]
206. Agiwal, M.; Roy, A.; Saxena, N. Next generation 5G wireless networks: A comprehensive survey. IEEE Commun. Surv. Tutor.
2016, 18, 1617–1655. [CrossRef]
207. Hossain, E.; Hasan, M. 5G cellular: Key enabling technologies and research challenges. IEEE Instrum. Meas. Mag. 2015, 18, 11–21.
[CrossRef]
208. Beyranvand, H.; Lévesque, M.; Maier, M.; Salehi, J.A.; Verikoukis, C.; Tipper, D. Toward 5G: FiWi enhanced LTE-A HetNets with
reliable low-latency ﬁber backhaul sharing and WiFi ofﬂoading. IEEE/ACM Trans. Netw. 2016, 25, 690–707. [CrossRef]
209. Mogensen, P.; Pajukoski, K.; Tiirola, E.; Vihriala, J.; Lahetkangas, E.; Berardinelli, G.; Tavares, F.M.; Mahmood, N.H.; Lauridsen,
M.; Catania, D.; et al. Centimeter-wave concept for 5G ultra-dense small cells. In Proceedings of the 2014 IEEE 79th Vehicular
Technology Conference (VTC Spring), Seoul, Korea, 18–21 May 2014; pp. 1–6.
210. Ploder, O.; Palaoro, N.; Etzlinger, B.; Springer, A. A cross-layer approach for ultra-low-latency machine type communication. In
Proceedings of the 2017 IEEE International Conference on Communications (ICC), Paris, France, 21–25 May 2017; pp. 1–6.
211. Dutta, S.; Mezzavilla, M.; Ford, R.; Zhang, M.; Rangan, S.; Zorzi, M. Frame structure design and analysis for millimeter wave
cellular systems. IEEE Trans. Wirel. Commun. 2017, 16, 1508–1522. [CrossRef]
Sensors 2022, 22, 5834
67 of 76
212. Luvisotto, M.; Pang, Z.; Dzung, D. Ultra high performance wireless control for critical applications: Challenges and directions.
IEEE Trans. Ind. Inform. 2016, 13, 1448–1459. [CrossRef]
213. Pﬂug, F.; Fingscheidt, T. Robust ultra-low latency soft-decision decoding of linear PCM audio. IEEE Trans. Audio Speech Lang.
Process. 2013, 21, 2324–2336. [CrossRef]
214. She, C.; Yang, C.; Quek, T.Q. Radio resource management for ultra-reliable and low-latency communications. IEEE Commun.
Mag. 2017, 55, 72–78. [CrossRef]
215. Durisi, G.; Koch, T.; Östman, J.; Polyanskiy, Y.; Yang, W. Short-packet communications over multiple-antenna Rayleigh-fading
channels. IEEE Trans. Commun. 2015, 64, 618–629. [CrossRef]
216. Mao, Y.; You, C.; Zhang, J.; Huang, K.; Letaief, K.B. A survey on mobile edge computing: The communication perspective. IEEE
Commun. Surv. Tutor. 2017, 19, 2322–2358. [CrossRef]
217. O’Connell, E.; Moore, D.; Newe, T. Challenges associated with implementing 5G in manufacturing. Telecom 2020, 1, 48–67.
[CrossRef]
218. Mikusz, M. Towards an understanding of cyber-physical systems as industrial software-product-service systems. Procedia Cirp
2014, 16, 385–389. [CrossRef]
219. Mahnke, W.; Leitner, S.H.; Damm, M. OPC Uniﬁed Architecture; Springer Science & Business Media: Berlin/Heidelberg, Germany,
2009.
220. Tovar, E.; Vasques, F. Real-time ﬁeldbus communications using Proﬁbus networks. IEEE Trans. Ind. Electron. 1999, 46, 1241–1251.
[CrossRef]
221. Petersen, N.; Halilaj, L.; Grangel-González, I.; Lohmann, S.; Lange, C.; Auer, S. Realizing an RDF-based information model for a
manufacturing company—A case study. In International Semantic Web Conference; Springer: Berlin/Heidelberg, Germany, 2017;
pp. 350–366.
222. Abele, E.; Wörn, A.; Fleischer, J.; Wieser, J.; Martin, P.; Klöpper, R. Mechanical module interfaces for reconﬁgurable machine tools.
Prod. Eng. 2007, 1, 421–428. [CrossRef]
223. Lang, D.; Friesen, M.; Ehrlich, M.; Wisniewski, L.; Jasperneite, J. Pursuing the vision of Industrie 4.0: Secure plug-and-produce by
means of the asset administration shell and blockchain technology. In Proceedings of the 2018 IEEE 16th International Conference
on Industrial Informatics (INDIN), Porto, Portugal, 18–20 July 2018; pp. 1092–1097.
224. Ye, X.; Jiang, J.; Lee, C.; Kim, N.; Yu, M.; Hong, S.H. Toward the Plug-and-Produce Capability for Industry 4.0: An Asset
Administration Shell Approach. IEEE Ind. Electron. Mag. 2020, 14, 146–157. [CrossRef]
225. Huang, Y.; Dhouib, S.; Malenfant, J. An AAS Modeling Tool for Capability-Based Engineering of Flexible Production Lines. In
Proceedings of the IECON 2021–47th Annual Conference of the IEEE Industrial Electronics Society, Toronto, ON, Canada, 13–16
October 2021; pp. 1–6.
226. Pisari´c, M.; Dimitrieski, V.; Vještica, M.; Krajoski, G.; Kapetina, M. Towards a ﬂexible smart factory with a dynamic resource
orchestration. Appl. Sci. 2021, 11, 7956. [CrossRef]
227. Cavalieri, S.; Salaﬁa, M.G. A model for predictive maintenance based on asset administration shell. Sensors 2020, 20, 6028.
[CrossRef]
228. Wagner, C.; Grothoff, J.; Epple, U.; Drath, R.; Malakuti, S.; Grüner, S.; Hoffmeister, M.; Zimermann, P. The role of the Industry 4.0
asset administration shell and the digital twin during the life cycle of a plant. In Proceedings of the 2017 22nd IEEE International
Conference on Emerging Technologies and Factory Automation (ETFA), Limassol, Cyprus, 12–15 September 2017; pp. 1–8.
229. Abramowicz, W.; Auer, S.; Heath, T. Linked data in business. Bus. Inf. Syst. Eng. 2016, 58, 323–326. [CrossRef]
230. Tantik, E.; Anderl, R. Integrated data model and structure for the asset administration shell in industrie 4.0. Procedia Cirp 2017,
60, 86–91. [CrossRef]
231. Watson, K. AutomationML-Industrie 4.0 Candidate Standard for Asset Model Engineering and Plug & Work. OMG Event
“Model Based Engineering, Automation and IoT in Smart Manufacturing. 2017. Available online: https://www.omg.org/events/ca-17
/special-events/mnf-pdf/Watson.pdf (accessed on 5 June 2022).
232. Arm, J.; Benesl, T.; Marcon, P.; Bradac, Z.; Schröder, T.; Belyaev, A.; Werner, T.; Braun, V.; Kamensky, P.; Zezulka, F.; et al.
Automated Design and Integration of Asset Administration Shells in Components of Industry 4.0.
Sensors 2021, 21, 2004.
[CrossRef]
233. Wei, K.; Sun, J.; Liu, R. A Review of Asset Administration Shell. In Proceedings of the 2019 IEEE International Conference on
Industrial Engineering and Engineering Management (IEEM), Macao, China, 15–18 December 2019; pp. 1460–1465.
234. Tantik, E.; Anderl, R. Potentials of the asset administration shell of Industrie 4.0 for service-oriented business models. Procedia
CIRP 2017, 64, 363–368. [CrossRef]
235. Bader, S.R.; Maleshkova, M. The semantic asset administration shell. In International Conference on Semantic Systems; Springer:
Berlin/Heidelberg, Germany, 2019; pp. 159–174.
236. Grangel-González, I.; Halilaj, L.; Coskun, G.; Auer, S.; Collarana, D.; Hoffmeister, M. Towards a semantic administrative shell
for industry 4.0 components. In Proceedings of the 2016 IEEE Tenth International Conference on Semantic Computing (ICSC),
Laguna Hills, CA, USA, 4–6 February 2016; pp. 230–237.
237. Langegger, A.; Wöß, W.; Blöchl, M. A semantic web middleware for virtual data integration on the web. In European Semantic
Web Conference; Springer: Berlin/Heidelberg, Germany, 2008; pp. 493–507.
Sensors 2022, 22, 5834
68 of 76
238. Bizer, C.; Becker, C.; Mendes, P.N.; Isele, R.; Matteini, A.; Schultz, A. Ldif-a Framework for Large-Scale Linked Data Integra-
tion. 2012. Available online: https://refubium.fu-berlin.de/bitstream/handle/fub188/14693/Schultz-et-al-LDIF-WWW2012-
DevTrack.pdf;jsessionid=9AAB1144C935C4FA351A789F5E80885A?sequence=1 (accessed on 6 June 2022).
239. Graube, M.; Pfeffer, J.; Ziegler, J.; Urbas, L. Linked Data as integrating technology for industrial data. Int. J. Distrib. Syst. Technol.
(IJDST) 2012, 3, 40–52. [CrossRef]
240. Främling, K.; Harrison, M.; Brusey, J.; Petrow, J. Requirements on unique identiﬁers for managing product lifecycle information:
Comparison of alternative approaches. Int. J. Comput. Integr. Manuf. 2007, 20, 715–726. [CrossRef]
241. IEC. 62264-1: Enterprise-Control System Integration–Part 1: Models and Terminology; IEC: Geneva, Switzerland, 2013.
242. Greer, C.; Burns, M.; Wollman, D.; Griffor, E. Cyber-Physical Systems and Internet of Things; National Institute of Standards and
Technology (NIST): Gaithersburg, MD, USA, 2019.
243. Cyber-Physical Systems Driving force for Innovation in Mobility, Health, Energy and Production, 2011. Acatech Position Paper.
Available online: https://en.acatech.de/publication/cyber-physical-systems-driving-force-for-innovation-in-mobility-health-
energy-and-production/ (accessed on 5 June 2022).
244. Ma, H.D. Internet of things: Objectives and scientiﬁc challenges. J. Comput. Sci. Technol. 2011, 26, 919–924. [CrossRef]
245. Miorandi, D.; Sicari, S.; De Pellegrini, F.; Chlamtac, I. Internet of things: Vision, applications and research challenges. Ad Hoc
Netw. 2012, 10, 1497–1516. [CrossRef]
246. Gubbi, J.; Buyya, R.; Marusic, S.; Palaniswami, M. Internet of Things (IoT): A vision, architectural elements, and future directions.
Future Gener. Comput. Syst. 2013, 29, 1645–1660. [CrossRef]
247. Törngren, M.; Bensalem, S.; Cengarle, M.; McDermid, J.; Passerone, R.; Sangiovanni-Vincentelli, A. Cyber-physical european
roadmap & Strategy. Cyber-Physical European Roadmap and Strategy D5. 1, Tech. Rep. 2014. Available online: http://cyphers.eu/
sites/default/ﬁles/d6.1+2-report.pdf (accessed on 5 June 2022).
248. Stojmenovic, I.; Zhang, F. Inaugural issue of ‘cyber-physical systems’. Cyber-Phys. Syst. 2015, 1, 1–4. [CrossRef]
249. Lee, E.A. Cyber physical systems: Design challenges. In Proceedings of the 2008 11th IEEE International Symposium on Object
and Component-Oriented Real-Time Distributed Computing (ISORC), Orlando, FL, USA, 5–7 May 2008; pp. 363–369.
250. Lee, E.A.; Seshia, S.A. Introduction to Embedded Systems: A Cyber-Physical Systems Approach; MIT Press: Cambridge, MA, USA,
2016.
251. Sha, L.; Gopalakrishnan, S.; Liu, X.; Wang, Q. Cyber-physical systems: A new frontier.
In Proceedings of the 2008 IEEE
International Conference on Sensor Networks, Ubiquitous, and Trustworthy Computing (sutc 2008), Taichung, Taiwan, 11–13
June 2008; pp. 1–9.
252. Khaitan, S.K.; McCalley, J.D. Design techniques and applications of cyberphysical systems: A survey. IEEE Syst. J. 2014, 9, 350–365.
[CrossRef]
253. Rad, C.R.; Hancu, O.; Takacs, I.A.; Olteanu, G. Smart monitoring of potato crop: A cyber-physical system architecture model in
the ﬁeld of precision agriculture. Agric. Agric. Sci. Procedia 2015, 6, 73–79. [CrossRef]
254. Song, H.; Rawat, D.B.; Jeschke, S.; Brecher, C. Cyber-Physical Systems: Foundations, Principles and Applications; Morgan Kaufmann:
New York, NY, USA 2016.
255. Basile, F.; Chiacchio, P.; Coppola, J.; Gerbasio, D. Automated warehouse systems: A cyber-physical system perspective. In
Proceedings of the 2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA), Luxembourg, 8–11
September 2015; pp. 1–4.
256. Wiesner, S.; Marilungo, E.; Thoben, K.D. Cyber-physical product-service systems–challenges for requirements engineering. Int. J.
Autom. Technol. 2017, 11, 17–28. [CrossRef]
257. Wang, L. An overview of function block enabled adaptive process planning for machining. J. Manuf. Syst. 2015, 35, 10–25.
[CrossRef]
258. Onori, M.; Lohse, N.; Barata, J.; Hanisch, C. The IDEAS project: Plug & produce at shop-ﬂoor level. Assem. Autom. 2012, 32,
124–134.
259. Ribeiro, L.; Barata, J.; Ferreira, J. An agent-based interaction-oriented shop ﬂoor to support emergent diagnosis. In Proceedings
of the 2010 8th IEEE International Conference on Industrial Informatics, Osaka, Japan, 13–16 July 2010; pp. 189–194.
260. Ferreira, P.; Lohse, N.; Ratchev, S. Multi-agent architecture for reconﬁguration of precision modular assembly systems. In
International Precision Assembly Seminar; Springer: Berlin/Heidelberg, Germany, 2010; pp. 247–254.
261. Ribeiro, L.; Barata, J.; Onori, M.; Hanisch, C.; Hoos, J.; Rosa, R. Self-organization in automation-the IDEAS pre-demonstrator. In
Proceedings of the IECON 2011-37th Annual Conference of the IEEE Industrial Electronics Society, Melbourne, VIC, Australia,
7–10 November 2011; pp. 2752–2757.
262. Onori, M.; Maffei, A.; Durand, F. The ideas plug & produce system. In Proceedings of the NewTech 2013 Advanced Manufacturing
Engineering and Technologies, Stockholm, Sweden, 27–30 October 2013; pp. 339–346.
263. Grieves, M. Virtually Perfect: Driving Innovative and Lean Products through Product Lifecycle Management; Space Coast Press: New
York, NY, USA 2011.
264. Främling, K.; Holmström, J.; Ala-Risku, T.; Kärkkäinen, M. Product Agents for Handling Information about Physical Objects.
Rep. Lab. Inf. Process. Sci. Ser. B TKO-B 2003, 153. Available online: https://www.academia.edu/download/43082106/B153.pdf
(accessed on 5 June 2022).
Sensors 2022, 22, 5834
69 of 76
265. Shafto, M.; Conroy, M.; Doyle, R.; Glaessgen, E.; Kemp, C.; LeMoigne, J.; Wang, L. Modeling, simulation, information technology
& processing roadmap. Natl. Aeronaut. Space Adm. 2012, 32, 1–38.
266. Grieves, M. Digital twin: Manufacturing excellence through virtual factory replication. White Pap. 2014, 1, 1–7.
267. El Saddik, A. Digital twins: The convergence of multimedia technologies. IEEE Multimed. 2018, 25, 87–92. [CrossRef]
268. Söderberg, R.; Wärmefjord, K.; Carlson, J.S.; Lindkvist, L. Toward a Digital Twin for real-time geometry assurance in individual-
ized production. CIRP Ann. 2017, 66, 137–140. [CrossRef]
269. Schroeder, G.N.; Steinmetz, C.; Pereira, C.E.; Espindola, D.B. Digital twin data modeling with automationml and a communication
methodology for data exchange. IFAC-PapersOnLine 2016, 49, 12–17. [CrossRef]
270. Guo, N.; Jia, C. Interpretation of cyber-physical systems whitepaper (2017). Inf. Technol. Stand. 2017, 4, 36–47.
271. Leng, J.; Wang, D.; Shen, W.; Li, X.; Liu, Q.; Chen, X. Digital twins-based smart manufacturing system design in Industry 4.0: A
review. J. Manuf. Syst. 2021, 60, 119–137. [CrossRef]
272. Predix, G. Predix: The Application Platform for Digital Industrial Solutions.
User Manual 2018. Available online: https:
//usermanual.wiki/m/c973d726f3ff05399ed19d085fa013709d3ac98f140d4ec8c79939b6401bf4a8.pdf (accessed on 5 June 2022).
273. Overton, J.; Brigham, J.C.
The Digital Twin: Data Driven Simulations Innovate the Manufacturing Process.
White Pap.
2017. Available online: http://www.dxc.technology/analytics/insights/1%38984-the_digital_twin_data_driven_simulations_
innovate_the_manufacturing_process (accessed on 5 June 2022).
274. Židek, K.; Pitel’, J.; Adámek, M.; Lazorík, P.; Hošovsk`y, A. Digital twin of experimental smart manufacturing assembly system
for industry 4.0 concept. Sustainability 2020, 12, 3658. [CrossRef]
275. Hu, L.; Nguyen, N.T.; Tao, W.; Leu, M.C.; Liu, X.F.; Shahriar, M.R.; Al Sunny, S.N. Modeling of cloud-based digital twins for
smart manufacturing with MT connect. Procedia Manuf. 2018, 26, 1193–1203. [CrossRef]
276. Industrial Internet Consortium. Digital Twins for Industrial Applications: Deﬁnition, Buisiness Values, Design Aspects, Standards
and Use Cases. IIC. 2020. Available online: https://www.researchgate.net/publication/339460951 (accessed on 5 June 2022).
277. Rittinghouse, J.W.; Ransome, J.F. Cloud Computing: Implementation, Management, and Security; CRC Press: Boca Raton, FL, USA,
2017.
278. Rüßmann, M.; Lorenz, M.; Gerbert, P.; Waldner, M.; Justus, J.; Engel, P.; Harnisch, M. Industry 4.0: The future of productivity and
growth in manufacturing industries. Boston Consult. Group 2015, 9, 54–89.
279. Biron, K.; Bazzaza, W.; Yaqoob, K.; Gawanmeh, A.; Fachkha, C. A big data fusion to proﬁle CPS security threats against
operational technology. In Proceedings of the 2020 IEEE 21st International Symposium on “A World of Wireless, Mobile and
Multimedia Networks” (WoWMoM), Cork, Ireland, 31 August–3 September 2020; pp. 397–402.
280. LLC, P.I. Cybersecurity in Operational Technology: 7 Insights You Need to Know. Technical Report, Tenable. 2019. Available
online: https://lookbook.tenable.com/ponemonotreport/ponemon-OT-report (accessed on 5 June 2022).
281. Furht, B.; Escalante, A. Handbook of Cloud Computing; Springer: Berlin/Heidelberg, Germany, 2010; Volume 3.
282. Weiner, M.; Jorgovanovic, M.; Sahai, A.; Nikolié, B. Design of a low-latency, high-reliability wireless communication system
for control applications. In Proceedings of the 2014 IEEE International Conference on Communications (ICC), Sydney, NSW,
Australia, 10–14 June 2014; pp. 3829–3835.
283. De Brito, M.S.; Hoque, S.; Steinke, R.; Willner, A. Towards programmable fog nodes in smart factories. In Proceedings of the
2016 IEEE 1st International Workshops on Foundations and Applications of Self* Systems (FAS* W), Augsburg, Germany, 12–16
September 2016; pp. 236–241.
284. OpenFog Consortium Architecture Working Group. OpenFog reference architecture for fog computing. OPFRA 2017, 20817, 162.
285. Bonomi, F.; Milito, R.; Zhu, J.; Addepalli, S. Fog computing and its role in the internet of things. In Proceedings of the First
Edition of the MCC Workshop on Mobile Cloud Computing, Helsinki, Finland, 17 August 2012; pp. 13–16.
286. Shi, W.; Cao, J.; Zhang, Q.; Li, Y.; Xu, L. Edge computing: Vision and challenges.
IEEE Internet Things J. 2016, 3, 637–646.
[CrossRef]
287. Dastjerdi, A.V.; Gupta, H.; Calheiros, R.N.; Ghosh, S.K.; Buyya, R. Fog computing: Principles, architectures, and applications. In
Internet of Things; Elsevier: Amsterdam, The Netherlands, 2016; pp. 61–75.
288. Pizo´n, J.; Lipski, J. Perspectives for fog computing in manufacturing. Appl. Comput. Sci. 2016, 12, 37–46.
289. Seitz, A.; Buchinger, D.; Bruegge, B. The conjunction of fog computing and the industrial internet of things-an applied approach.
In Proceedings of the 2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom
Workshops), Athens, Greece, 19–23 March 2018; pp. 812–817.
290. Chang, Q.; Ni, J.; Bandyopadhyay, P.; Biller, S.; Xiao, G. Supervisory factory control based on real-time production feedback. J.
Manuf. Sci. Eng. 2007, 129, 653–660. [CrossRef]
291. Li, J.; Meerkov, S.M. Production Systems Engineering; Springer Science & Business Media: Berlin/Heidelberg, Germany, 2008.
292. Tenenbaum, J.B.; Kemp, C.; Grifﬁths, T.L.; Goodman, N.D. How to grow a mind: Statistics, structure, and abstraction. Science
2011, 331, 1279–1285. [CrossRef]
293. Poole, D.; Mackworth, A.; Goebel, R. Computational Intelligence: A Logical Approach; Oxford University Press: Oxford, UK, 1998.
294. Stuart, R.; Peter, N. Artiﬁcial Intelligence—A Modern Approach, 3rd ed.; Pearson: New York, NY, USA 2016.
295. Jordan, M.I.; Mitchell, T.M. Machine learning: Trends, perspectives, and prospects. Science 2015, 349, 255–260. [CrossRef]
296. Samuel, A.L. Some studies in machine learning using the game of checkers. IBM J. Res. Dev. 2000, 44, 206–226. [CrossRef]
Sensors 2022, 22, 5834
70 of 76
297. Michalski, R.S.; Carbonell, J.G.; Mitchell, T.M. Machine Learning: An Artiﬁcial Intelligence Approach; Springer Science & Business
Media: Berlin/Heidelberg, Germany, 2013.
298. Sharp, M.; Ak, R.; Hedberg, T., Jr. A survey of the advancing use and development of machine learning in smart manufacturing.
J. Manuf. Syst. 2018, 48, 170–179. [CrossRef] [PubMed]
299. Nti, I.K.; Adekoya, A.F.; Weyori, B.A.; Nyarko-Boateng, O. Applications of artiﬁcial intelligence in engineering and manufacturing:
A systematic review. J. Intell. Manuf. 2022, 33, 1581–1601. [CrossRef]
300. Wang, J.; Ma, Y.; Zhang, L.; Gao, R.X.; Wu, D. Deep learning for smart manufacturing: Methods and applications. J. Manuf. Syst.
2018, 48, 144–156. [CrossRef]
301. Abadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G.S.; Davis, A.; Dean, J.; Devin, M.; et al. Tensorﬂow:
Large-scale machine learning on heterogeneous distributed systems. arXiv 2016, arXiv:1603.04467.
302. Schmidhuber, J. Deep learning in neural networks: An overview. Neural Netw. 2015, 61, 85–117. [CrossRef]
303. Rumelhart, D.E.; Hinton, G.E.; Williams, R.J. Learning representations by back-propagating errors. Nature 1986, 323, 533–536.
[CrossRef]
304. LeCun, Y.; Bengio, Y.; Hinton, G. Deep learning. Nature 2015, 521, 436–444. [CrossRef]
305. Bengio, Y. Learning Deep Architectures for AI; Now Publishers Inc.: Delft, The Netherlands 2009.
306. Bengio, Y. Deep learning of representations: Looking forward. In International Conference on Statistical Language and Speech
Processing; Springer: Berlin/Heidelberg, Germany, 2013; pp. 1–37.
307. Bengio, Y.; Courville, A.; Vincent, P. Representation learning: A review and new perspectives. IEEE Trans. Pattern Anal. Mach.
Intell. 2013, 35, 1798–1828. [CrossRef]
308. Deng, L. A tutorial survey of architectures, algorithms, and applications for deep learning. APSIPA Trans. Signal Inf. Process.
2014, 3. [CrossRef]
309. Krizhevsky, A.; Sutskever, I.; Hinton, G.E. Imagenet classiﬁcation with deep convolutional neural networks. Adv. Neural Inf.
Process. Syst. 2012, 25. [CrossRef]
310. Szegedy, C.; Liu, W.; Jia, Y.; Sermanet, P.; Reed, S.; Anguelov, D.; Erhan, D.; Vanhoucke, V.; Rabinovich, A. Going deeper with
convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Boston, MA, USA, 7–12 June
2015; pp. 1–9.
311. Collobert, R.; Weston, J.; Bottou, L.; Karlen, M.; Kavukcuoglu, K.; Kuksa, P. Natural language processing (almost) from scratch. J.
Mach. Learn. Res. 2011, 12, 2493–2537.
312. Sutskever, I.; Vinyals, O.; Le, Q.V. Sequence to sequence learning with neural networks. Adv. Neural Inf. Process. Syst. 2014, 27.
[CrossRef]
313. Lin, L.; Wang, K.; Zuo, W.; Wang, M.; Luo, J.; Zhang, L. A deep structured model with radius–margin bound for 3D human
activity recognition. Int. J. Comput. Vis. 2016, 118, 256–273. [CrossRef]
314. Cao, S.; Nevatia, R. Exploring deep learning based solutions in ﬁne grained activity recognition in the wild. In Proceedings of the
2016 23rd International Conference on Pattern Recognition (ICPR), Cancun, Mexico, 4–8 December 2016; pp. 384–389.
315. Ouyang, W.; Zeng, X.; Wang, X.; Qiu, S.; Luo, P.; Tian, Y.; Li, H.; Yang, S.; Wang, Z.; Li, H.; et al. DeepID-Net: Object detection
with deformable part based convolutional neural networks. IEEE Trans. Pattern Anal. Mach. Intell. 2016, 39, 1320–1334. [CrossRef]
316. Diba, A.; Sharma, V.; Pazandeh, A.; Pirsiavash, H.; Van Gool, L. Weakly supervised cascaded convolutional networks. In Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21–26 July 2017; pp. 914–922.
317. Long, J.; Shelhamer, E.; Darrell, T. Fully convolutional networks for semantic segmentation.
In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, Boston, MA, USA, 7–12 June 2015; pp. 3431–3440.
318. Noh, H.; Hong, S.; Han, B. Learning deconvolution network for semantic segmentation. In Proceedings of the IEEE International
Conference on Computer Vision, Santiago, Chile, 3–7 December 2015; pp. 1520–1528.
319. Chen, X.; Yuille, A.L. Articulated pose estimation by a graphical model with image dependent pairwise relations. Adv. Neural Inf.
Process. Syst. 2014, 27. [CrossRef]
320. Toshev, A.; Szegedy, C. Deeppose: Human pose estimation via deep neural networks. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, Columbus, OH, USA, 23–28 June 2014; pp. 1653–1660.
321. Baryannis, G.; Validi, S.; Dani, S.; Antoniou, G. Supply chain risk management and artiﬁcial intelligence: State of the art and
future research directions. Int. J. Prod. Res. 2019, 57, 2179–2202. [CrossRef]
322. Zhang, X.; Ming, X.; Liu, Z.; Yin, D.; Chen, Z.; Chang, Y. A reference framework and overall planning of industrial artiﬁcial
intelligence (I-AI) for new application scenarios. Int. J. Adv. Manuf. Technol. 2019, 101, 2367–2389. [CrossRef]
323. Aggour, K.S.; Gupta, V.K.; Ruscitto, D.; Ajdelsztajn, L.; Bian, X.; Brosnan, K.H.; Kumar, N.C.; Dheeradhada, V.; Hanlon, T.; Iyer, N.;
et al. Artiﬁcial intelligence/machine learning in manufacturing and inspection: A GE perspective. MRS Bull. 2019, 44, 545–558.
[CrossRef]
324. Tao, F.; Qi, Q.; Liu, A.; Kusiak, A. Data-driven smart manufacturing. J. Manuf. Syst. 2018, 48, 157–169. [CrossRef]
325. Zhang, Y.; Kwok, T.H. Design and interaction interface using augmented reality for smart manufacturing. Procedia Manuf. 2018,
26, 1278–1286. [CrossRef]
326. Yao, X.; Zhou, J.; Zhang, J.; Boër, C.R. From intelligent manufacturing to smart manufacturing for industry 4.0 driven by next
generation artiﬁcial intelligence and further on. In Proceedings of the 2017 5th International Conference on Enterprise Systems
(ES), Beijing, China, 22–24 September 2017; pp. 311–318.
Sensors 2022, 22, 5834
71 of 76
327. Yang, R.; Singh, S.K.; Tavakkoli, M.; Amiri, N.; Yang, Y.; Karami, M.A.; Rai, R. CNN-LSTM deep learning architecture for
computer vision-based modal frequency detection. Mech. Syst. Signal Process. 2020, 144, 106885. [CrossRef]
328. Park, J.K.; Kwon, B.K.; Park, J.H.; Kang, D.J. Machine learning-based imaging system for surface defect inspection. Int. J. Precis.
Eng. Manuf.-Green Technol. 2016, 3, 303–310. [CrossRef]
329. Ravikumar, S.; Ramachandran, K.; Sugumaran, V. Machine learning approach for automated visual inspection of machine
components. Expert Syst. Appl. 2011, 38, 3260–3266. [CrossRef]
330. Matei, I.; de Kleer, J.; Feldman, A.; Rai, R.; Chowdhury, S. Hybrid modeling: Applications in real-time diagnosis. arXiv 2020,
arXiv:2003.02671.
331. George, A.; Vidyapeetham, A.
Anomaly detection based on machine learning dimensionality reduction using PCA and
classiﬁcation using SVM. Int. J. Comput. Appl. 2012, 47, 5–8. [CrossRef]
332. Kroll, B.; Schaffranek, D.; Schriegel, S.; Niggemann, O. System modeling based on machine learning for anomaly detection and
predictive maintenance in industrial plants. In Proceedings of the 2014 IEEE Emerging Technology and Factory Automation
(ETFA), Barcelona, Spain, 16–19 September 2014; pp. 1–7.
333. Carbery, C.M.; Woods, R.; Marshall, A.H. A Bayesian network based learning system for modelling faults in large-scale
manufacturing. In Proceedings of the 2018 IEEE International Conference on Industrial Technology (ICIT), Lyon, France, 20–22
February 2018; pp. 1357–1362.
334. Wang, G.; Ledwoch, A.; Hasani, R.M.; Grosu, R.; Brintrup, A. A generative neural network model for the quality prediction of
work in progress products. Appl. Soft Comput. 2019, 85, 105683. [CrossRef]
335. Chen, L.; Han, W.; Li, H.T.; Xu, Z.K.; Zhang, J.W.; Cao, X. Long distance wireless fault diagnosis for photovoltaic modules based
on back propagation neural network. Int. J. Electr. Eng. Educ. 2020. [CrossRef]
336. Wuest, T.; Irgens, C.; Thoben, K.D. An approach to monitoring quality in manufacturing using supervised machine learning on
product state data. J. Intell. Manuf. 2014, 25, 1167–1180. [CrossRef]
337. Carbery, C.M.; Woods, R.; Marshall, A.H. A new data analytics framework emphasising preprocessing of data to generate insights
into complex manufacturing systems. Proc. Inst. Mech. Eng. Part C J. Mech. Eng. Sci. 2019, 233, 6713–6726. [CrossRef]
338. Peres, R.S.; Barata, J.; Leitao, P.; Garcia, G. Multistage quality control using machine learning in the automotive industry. IEEE
Access 2019, 7, 79908–79916. [CrossRef]
339. Appiah, A.Y.; Zhang, X.; Ayawli, B.B.K.; Kyeremeh, F. Long short-term memory networks based automatic feature extraction for
photovoltaic array fault diagnosis. IEEE Access 2019, 7, 30089–30101. [CrossRef]
340. Chen, S.; Leng, Y.; Labi, S. A deep learning algorithm for simulating autonomous driving considering prior knowledge and
temporal information. Comput.-Aided Civ. Infrastruct. Eng. 2020, 35, 305–321. [CrossRef]
341. Cho, K.H.; Jo, H.C.; Kim, E.s.; Park, H.A.; Park, J.H. Failure diagnosis method of photovoltaic generator using support vector
machine. J. Electr. Eng. Technol. 2020, 15, 1669–1680. [CrossRef]
342. Subrahmanya, N.; Shin, Y.C.; Meckl, P.H. A Bayesian machine learning method for sensor selection and fusion with application
to on-board fault diagnostics. Mech. Syst. Signal Process. 2010, 24, 182–192. [CrossRef]
343. Li, Y.; Zou, L.; Jiang, L.; Zhou, X. Fault diagnosis of rotating machinery based on combination of deep belief network and
one-dimensional convolutional neural network. IEEE Access 2019, 7, 165710–165723. [CrossRef]
344. Kateris, D.; Moshou, D.; Pantazi, X.E.; Gravalos, I.; Sawalhi, N.; Loutridis, S. A machine learning approach for the condition
monitoring of rotating machinery. J. Mech. Sci. Technol. 2014, 28, 61–71. [CrossRef]
345. Lei, Y.; Jia, F.; Lin, J.; Xing, S.; Ding, S.X. An intelligent fault diagnosis method using unsupervised feature learning towards
mechanical big data. IEEE Trans. Ind. Electron. 2016, 63, 3137–3147. [CrossRef]
346. Lu, W.; Liang, B.; Cheng, Y.; Meng, D.; Yang, J.; Zhang, T. Deep model based domain adaptation for fault diagnosis. IEEE Trans.
Ind. Electron. 2016, 64, 2296–2305. [CrossRef]
347. Mwedzi, N.A.; Nwulu, N.I.; Gbadamosi, S.L. Machine learning applications for ﬁre detection in a residential building. In
Proceedings of the 2019 IEEE 6th International Conference on Engineering Technologies and Applied Sciences (ICETAS), Kuala
Lumpur, Malaysia, 20–21 December 2019; pp. 1–4.
348. Zhang, X.; Chen, W.; Wang, B.; Chen, X. Intelligent fault diagnosis of rotating machinery using support vector machine with ant
colony algorithm for synchronous feature selection and parameter optimization. Neurocomputing 2015, 167, 260–279. [CrossRef]
349. Patel, R.A.; Bhalja, B.R. Condition monitoring and fault diagnosis of induction motor using support vector machine. Electr. Power
Components Syst. 2016, 44, 683–692. [CrossRef]
350. Liu, Y.; Jin, S. Application of Bayesian networks for diagnostics in the assembly process by considering small measurement data
sets. Int. J. Adv. Manuf. Technol. 2013, 65, 1229–1237. [CrossRef]
351. Sayed, M.S.; Lohse, N. Distributed Bayesian diagnosis for modular assembly systems—A case study. J. Manuf. Syst. 2013,
32, 480–488. [CrossRef]
352. Rost, A.; Schädle, S. The sls-generated soft robotic hand-an integrated approach using additive manufacturing and reinforcement
learning. In Proceedings of the 2013 12th International Conference on Machine Learning and Applications, Miami, FL, USA, 4–7
December 2013; Volume 1, pp. 215–220.
353. Mark, A. Reinforcement Learning: MDP applied to autonomous navigation. Mach. Learn. Appl. Int. J. 2017, 4, 1–10.
354. Eliseeva, O.; Kirk, T.; Samimi, P.; Malak, R.; Arróyave, R.; Elwany, A.; Karaman, I. Functionally Graded Materials through
robotics-inspired path planning. Mater. Des. 2019, 182, 107975. [CrossRef]
Sensors 2022, 22, 5834
72 of 76
355. Fan, Z.; Liu, R. Investigation of machine learning based network trafﬁc classiﬁcation. In Proceedings of the 2017 International
Symposium on Wireless Communication Systems (ISWCS), Bologna, Italy, 28–31 August 2017; pp. 1–6.
356. Milosevic, N.; Dehghantanha, A.; Choo, K.K.R. Machine learning aided Android malware classiﬁcation. Comput. Electr. Eng.
2017, 61, 266–274. [CrossRef]
357. Wei, L.; Luo, W.; Weng, J.; Zhong, Y.; Zhang, X.; Yan, Z. Machine learning-based malicious application detection of android. IEEE
Access 2017, 5, 25591–25601. [CrossRef]
358. Sahu, C.K.; Young, C.; Rai, R. Artiﬁcial intelligence (AI) in augmented reality (AR)-assisted manufacturing applications: A review.
Int. J. Prod. Res. 2021, 59, 4903–4959. [CrossRef]
359. Badesa, F.J.; Morales, R.; Garcia-Aracil, N.; Sabater, J.M.; Casals, A.; Zollo, L. Auto-adaptive robot-aided therapy using machine
learning techniques. Comput. Methods Programs Biomed. 2014, 116, 123–130. [CrossRef]
360. Yang, Q.; Liu, Y.; Chen, T.; Tong, Y. Federated machine learning: Concept and applications. ACM Trans. Intell. Syst. Technol.
(TIST) 2019, 10, 1–19. [CrossRef]
361. Geva, Amir B Hierarchical unsupervised fuzzy clustering IEEE Trans. Fuzzy Syst. 1999, 7, 723–733. [CrossRef]
362. Colgan, J.; Chin, H.; Danai, K.; Hayashi, S. On-line tool breakage detection in turning: A multi-sensor method. J. Eng. Ind. 1994,
116, 117–123. [CrossRef]
363. Emel, E.; Kannatey-Asibu, E., Jr. Tool failure monitoring in turning by pattern recognition analysis of AE signals. J. Eng. Ind.
1988, 110, 137–145. [CrossRef]
364. Du, R.; Yan, D.; Elbestawi, M. Time-frequency distribution of acoustic emission signals for tool wear detection in turning.
In Proceedings of the 4th World Meeting on Acoustic Emission and 1st International Conference on Acoustic Emission in
Manufacturing, Boston, MA, USA, 16–19 September 1991; pp. 269–285.
365. Dornfeld, D.A.; DeVries, M. Neural network sensor fusion for tool condition monitoring. CIRP Ann. 1990, 39, 101–105. [CrossRef]
366. Dornfeld, A,D. In process recognition of cutting states. JSME Int. J. Ser. C Dyn. Control. Robot. Des. Manuf. 1994, 37, 638–650.
[CrossRef]
367. Tan, B.; Gershwin, S.B. Analysis of a general Markovian two-stage continuous-ﬂow production system with a ﬁnite buffer. Int. J.
Prod. Econ. 2009, 120, 327–339. [CrossRef]
368. Wu, K.; McGinnis, L. Performance evaluation for general queueing networks in manufacturing systems: Characterizing the
trade-off between queue time and utilization. Eur. J. Oper. Res. 2012, 221, 328–339. [CrossRef]
369. Gershwin, S.B.; Werner, L.M. An approximate analytical method for evaluating the performance of closed-loop ﬂow systems
with unreliable machines and ﬁnite buffers. Int. J. Prod. Res. 2007, 45, 3085–3111. [CrossRef]
370. Colledani, M.; Gershwin, S.B. A decomposition method for approximate evaluation of continuous ﬂow multi-stage lines with
general Markovian machines. Ann. Oper. Res. 2013, 209, 5–40. [CrossRef]
371. Liu, Y.; Li, J.; Chiang, S.Y. Re-entrant lines with unreliable asynchronous machines and ﬁnite buffers: Performance approximation
and bottleneck identiﬁcation. Int. J. Prod. Res. 2012, 50, 977–990. [CrossRef]
372. Zou, J.; Chang, Q.; Lei, Y.; Arinez, J. Production system performance identiﬁcation using sensor data. IEEE Trans. Syst. Man
Cybern. Syst. 2016, 48, 255–264. [CrossRef]
373. Zou, J.; Chang, Q.; Arinez, J.; Xiao, G. Production performance prognostics through model-based analytical method and
recency-weighted stochastic approximation method. J. Manuf. Syst. 2018, 47, 107–114. [CrossRef]
374. Priore, P.; Ponte, B.; Puente, J.; Gómez, A. Learning-based scheduling of ﬂexible manufacturing systems using ensemble methods.
Comput. Ind. Eng. 2018, 126, 282–291. [CrossRef]
375. Ji, W.; Wang, L. Big data analytics based fault prediction for shop ﬂoor scheduling. J. Manuf. Syst. 2017, 43, 187–194. [CrossRef]
376. Ozdemir, R.; Koc, M. A Quality Control Application on a Smart Factory Prototype Using Deep Learning Methods. In Proceedings
of the 2019 IEEE 14th International Conference on Computer Sciences and Information Technologies (CSIT), Lviv, Ukraine, 17–20
September 2019; Volume 1, pp. 46–49. [CrossRef]
377. Park, S.; Li, G.; Hong, J. A study on smart factory-based ambient intelligence context-aware intrusion detection system using
machine learning. J. Ambient Intell. Humaniz. Comput. 2020, 11, 1405–1412. [CrossRef]
378. De Boer, E.; Leurent, H.; Widmer, A. Lighthouse manufacturers lead the way—Can the rest of the world keep up. McKinsey Q.
2019, 1, 1–8.
379. Betti, F.; de Boer, E.; Giraud, Y. Industry’s Fast-Mover Advantage: Enterprise Value from Digital Factories; World Economic Forum and
McKinsey & Company: Atlanta, GA, USA, 2020.
380. Vukoli´c, M. Rethinking permissioned blockchains. In Proceedings of the ACM Workshop on Blockchain, Cryptocurrencies and
Contracts, Abu Dhabi, United Arab Emirates, 2–6 April 2017; pp. 3–7.
381. Beck, R.; Stenum Czepluch, J.; Lollike, N.; Malone, S. Blockchain–the Gateway to Trust-Free Cryptographic Transactions. 2016.
Available online: https://www.researchgate.net/publication/302589859_BLOCKCHAIN_-_THE_GATEWAY_TO_TRUST-FREE_
CRYPTOGRAPHIC_TRANSACTIONS/stats (accessed on 5 June 2022).
382. Yue, X.; Wang, H.; Jin, D.; Li, M.; Jiang, W. Healthcare data gateways: Found healthcare intelligence on blockchain with novel
privacy risk control. J. Med. Syst. 2016, 40, 1–8. [CrossRef]
383. Holland, M.; Stjepandi´c, J.; Nigischer, C. Intellectual property protection of 3D print supply chain with blockchain technology.
In Proceedings of the 2018 IEEE International conference on engineering, technology and innovation (ICE/ITMC), Stuttgart,
Germany, 17–20 June 2018; pp. 1–8.
Sensors 2022, 22, 5834
73 of 76
384. Kumar, N.M.; Mallick, P.K. Blockchain technology for security issues and challenges in IoT. Procedia Comput. Sci. 2018,
132, 1815–1823. [CrossRef]
385. Azuma, R.; Baillot, Y.; Behringer, R.; Feiner, S.; Julier, S.; MacIntyre, B. Recent advances in augmented reality. IEEE Comput. Graph.
Appl. 2001, 21, 34–47. [CrossRef]
386. Haller, M.; Billinghurst, M.; Thomas, B. Emerging Technologies of Augmented Reality: Interfaces and Design: Interfaces and Design; IGI
Global: London, UK, 2006.
387. Berning, M.; Riedel, T.; Karl, D.; Schandinat, F.; Beigl, M.; Fantana, N. Augmented service in the factory of the future. In
Proceedings of the 2012 Ninth International Conference on Networked Sensing (INSS), Antwerp, Belgium, 11–14 June 2012;
pp. 1–2.
388. Hakkarainen, M.; Woodward, C.; Billinghurst, M. Augmented assembly using a mobile phone. In Proceedings of the 2008 7th
IEEE/ACM International Symposium on Mixed and Augmented Reality, Cambridge, UK, 15–18 September 2008; pp. 167–168.
389. Stutzman, B.; Nilsen, D.; Broderick, T.; Neubert, J. MARTI: Mobile augmented reality tool for industry. In Proceedings of the
2009 WRI World Congress on Computer Science and Information Engineering, Los Angeles, CA, USA, 31 March–2 April 2009;
Volume 5, pp. 425–429.
390. Xin, M.; Sharlin, E.; Sousa, M.C. Napkin sketch: Handheld mixed reality 3D sketching.
In Proceedings of the 2008 ACM
Symposium on Virtual Reality Software and Technology, Bordeaux, France, 27–29 October 2008; pp. 223–226.
391. Valentini, P.P. Interactive virtual assembling in augmented reality. Int. J. Interact. Des. Manuf. (IJIDeM) 2009, 3, 109–119. [CrossRef]
392. Chen, C.; Ong, S.; Nee, A.; Zhou, Y. Haptic-based interactive path planning for a virtual robot arm. Int. J. Interact. Des. Manuf.
(IJIDeM) 2010, 4, 113–123. [CrossRef]
393. Navab, N. Developing killer apps for industrial augmented reality. IEEE Comput. Graph. Appl. 2004, 24, 16–20. [CrossRef]
[PubMed]
394. Novak-Marcincin, J.; Barna, J.; Janak, M.; Novakova-Marcincinova, L.; Torok, J. Visualization of intelligent assembling process by
augmented reality tools application. In Proceedings of the 2012 4th IEEE International Symposium on Logistics and Industrial
Informatics, Smolenice, Slovakia, 5–7 September 2012; pp. 33–36.
395. Fruend, J.; Matysczok, C.; Radkowski, R. AR-based product design in automobile industry. In Proceedings of the First IEEE
International Workshop Agumented Reality Toolkit, Darmstadt, Germany, 29 September 2002; p. 2.
396. Gausenmeier, J.; Matysczok, C.; Radkowski, R. AR-based modular construction system for automobile advance development. In
Proceedings of the 2003 IEEE International Augmented Reality Toolkit Workshop, Tokyo, Japan, 7 October 2003; pp. 72–73.
397. Park, H.S.; Choi, H.W.; Park, J.W. Augmented reality based cockpit module assembly system. In Proceedings of the 2008
International Conference on Smart Manufacturing Application, Goyangi, Korea, 9–11 April 2008; pp. 130–135.
398. Fraga-Lamas, P.; Fernandez-Carames, T.M.; Blanco-Novoa, O.; Vilar-Montesinos, M.A. A review on industrial augmented reality
systems for the industry 4.0 shipyard. IEEE Access 2018, 6, 13358–13375. [CrossRef]
399. Kalkofen, D.; Veas, E.; Zollmann, S.; Steinberger, M.; Schmalstieg, D. Adaptive ghosted views for augmented reality.
In
Proceedings of the 2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), Adelaide, SA, Australia, 1–4
October 2013; pp. 1–9.
400. Flatt, H.; Koch, N.; Röcker, C.; Günter, A.; Jasperneite, J. A context-aware assistance system for maintenance applications in smart
factories based on augmented reality and indoor localization. In Proceedings of the 2015 IEEE 20th Conference on Emerging
Technologies & Factory Automation (ETFA), Luxembourg, 8–11 September 2015; pp. 1–4.
401. Loch, F.; Quint, F.; Brishtel, I. Comparing video and augmented reality assistance in manual assembly. In Proceedings of the 2016
12th International Conference on Intelligent Environments (IE), London, UK, 14–16 September 2016; pp. 147–150.
402. Aiteanu, D.; Hillers, B.; Graser, A. A step forward in manual welding: Demonstration of augmented reality helmet.
In
Proceedings of the Second IEEE and ACM International Symposium on Mixed and Augmented Reality, Tokyo, Japan, 10 October
2003; pp. 309–310.
403. Andersen, R.S.; Bøgh, S.; Moeslund, T.B.; Madsen, O. Task space HRI for cooperative mobile robots in ﬁt-out operations
inside ship superstructures. In Proceedings of the 2016 25th IEEE International Symposium on Robot and Human Interactive
Communication (RO-MAN), New York, NY, USA, 26–31 August 2016; pp. 880–887.
404. Fernández-Caramés, T.M.; Fraga-Lamas, P.; Suárez-Albela, M.; Vilar-Montesinos, M. A fog computing and cloudlet based
augmented reality system for the industry 4.0 shipyard. Sensors 2018, 18, 1798. [CrossRef] [PubMed]
405. Havard, V.; Baudry, D.; Louis, A.; Mazari, B. Augmented reality maintenance demonstrator and associated modelling. In
Proceedings of the 2015 IEEE Virtual Reality (VR), Arles, France, 23–27 March 2015; pp. 329–330.
406. Smparounis, K.; Mavrikios, D.; Pappas, M.; Xanthakis, V.; Viganò, G.P.; Pentenrieder, K. A virtual and augmented reality approach
to collaborative product design and demonstration. In Proceedings of the 2008 IEEE International Technology Management
Conference (ICE), Lisbon, Portugal, 23–28 June 2008; pp. 1–8.
407. Santos, P.; Graf, H.; Fleisch, T.; Stork, A. 3d interactive augmented reality in early stages of product design. In Proceedings of the
HCI International 2003, 10th Conference on Human-Computer Interaction, Crete, Greece, 23–27 June 2003; pp. 1203–1207.
408. Fründ, J.; Gausemeier, J.; Matysczok, C.; Radkowski, R. Using augmented reality technology to support the automobile
development. In International Conference on Computer Supported Cooperative Work in Design; Springer: Berlin/Heidelberg, Germany,
2004; pp. 289–298.
Sensors 2022, 22, 5834
74 of 76
409. Shen, Y.; Ong, S.K.; Nee, A.Y. Augmented reality for collaborative product design and development. Des. Stud. 2010, 31, 118–145.
[CrossRef]
410. Ng, L.X.; Ong, S.; Nee, A. Arcade: A Simuple and Fast Augmented Reality Computer-Aided Design Environment Using
Everyday Objects. 2010. Available online: http://www.iadisportal.org/digital-library/arcade-a-simple-and-fast-augmented-
reality-computer-aided-design-environment-using-everyday-objects (accessed on 5 June 2022).
411. Hannola, L.; Richter, A.; Richter, S.; Stocker, A. Empowering production workers with digitally facilitated knowledge processes–a
conceptual framework. Int. J. Prod. Res. 2018, 56, 4729–4743. [CrossRef]
412. Wang, X.; Ong, S.K.; Nee, A.Y. A comprehensive survey of augmented reality assembly research. Adv. Manuf. 2016, 4, 1–22.
[CrossRef]
413. Siew, C.Y.; Ong, S.K.; Nee, A.Y. A practical augmented reality-assisted maintenance system framework for adaptive user support.
Robot. Comput.-Integr. Manuf. 2019, 59, 115–129. [CrossRef]
414. Feiner, S.; MacIntyre, B.; Seligmann, D. Knowledge-based augmented reality. Commun. ACM 1993, 36, 53–62. [CrossRef]
415. Zaldívar-Colado, U.; Garbaya, S.; Tamayo-Serrano, P.; Zaldívar-Colado, X.; Blazevic, P. A mixed reality for virtual assembly.
In Proceedings of the 2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),
Lisbon, Portugal, 28 August–1 September 2017; pp. 739–744. [CrossRef]
416. Azuma, R.T. A survey of augmented reality. Presence Teleoperators Virtual Environ. 1997, 6, 355–385. [CrossRef]
417. Bottani, E.; Vignali, G. Augmented reality technology in the manufacturing industry: A review of the last decade. Iise Trans. 2019,
51, 284–310. [CrossRef]
418. Egger, J.; Masood, T. Augmented reality in support of intelligent manufacturing–a systematic literature review. Comput. Ind. Eng.
2020, 140, 106–195. [CrossRef]
419. Thomas, P.; David, W. Augmented reality: An application of heads-up display technology to manual manufacturing processes.
In Hawaii International Conference on System Sciences; ACM SIGCHI Bulletin: New York, NY, USA, 1992; Volume 2.
420. Grimm, P.; Haller, M.; Paelke, V.; Reinhold, S.; Reimann, C.; Zauner, R. AMIRE-authoring mixed reality. In Proceedings of the
First IEEE International Workshop Agumented Reality Toolkit, Darmstadt, Germany, 29 September 2002; p. 2.
421. Klinker, G.; Reiners, D.; Stricker, D.; Müller, S. Augmented Reality for Construction Tasks: Doorlock Assembly Applications. In
Proceedings of the International Workshop on Augmented Reality, San Francisco, CA, USA, 1 November 1998.
422. Tang, A.; Owen, C.; Biocca, F.; Mou, W. Comparative effectiveness of augmented reality in object assembly. In Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems, Lauderdale, FL, USA, 5–10 April 2003; pp. 73–80.
423. Schwab, K. The Fourth Industrial Revolution; World Economic Forum: Geneva, Switzerland, 2016; Volume 145.
424. Thompson, M.K.; Moroni, G.; Vaneker, T.; Fadel, G.; Campbell, R.I.; Gibson, I.; Bernard, A.; Schulz, J.; Graf, P.; Ahuja, B.; et al.
Design for Additive Manufacturing: Trends, opportunities, considerations, and constraints.
CIRP Ann. 2016, 65, 737–760.
[CrossRef]
425. ISO/ASTM 52900:2015; ASTM52900-15 Standard Terminology for Additive Manufacturing—General Principles—Terminology.
ASTM International: West Conshohocken, PA, USA, 2015.
426. Bikas, H.; Stavropoulos, P.; Chryssolouris, G. Additive manufacturing methods and modelling approaches: A critical review. Int.
J. Adv. Manuf. Technol. 2016, 83, 389–405. [CrossRef]
427. Bourell, D.; Kruth, J.P.; Leu, M.; Levy, G.; Rosen, D.; Beese, A.M.; Clare, A. Materials for additive manufacturing. CIRP Ann. 2017,
66, 659–681. [CrossRef]
428. Redwood, B.; Schöffer, F.; Garret, B. The 3D Printing Handbook: Technologies, Design and Applications; 3D Hubs: Amsterdam, The
Netherlands, 2017.
429. Asadi-Eydivand, M.; Solati-Hashjin, M.; Fathi, A.; Padashi, M.; Osman, N.A.A. Optimal design of a 3D-printed scaffold using
intelligent evolutionary algorithms. Appl. Soft Comput. 2016, 39, 36–47. [CrossRef]
430. Ramananarivo, S.; Mitchel, T.; Ristroph, L. Improving the propulsion speed of a heaving wing through artiﬁcial evolution of
shape. Proc. R. Soc. A 2019, 475, 20180375. [CrossRef]
431. Joshi, S.C.; Sheikh, A.A. 3D printing in aerospace and its long-term sustainability. Virtual Phys. Prototyp. 2015, 10, 175–185.
[CrossRef]
432. Wang, Y.C.; Chen, T.; Yeh, Y.L. Advanced 3D printing technologies for the aircraft industry: A fuzzy systematic approach for
assessing the critical factors. Int. J. Adv. Manuf. Technol. 2019, 105, 4059–4069. [CrossRef]
433. Soller, S.; Barata, A.; Beyer, S.; Dahlhaus, A.; Guichard, D.; Humbert, E.; Kretschmer, J.; Zeiss, W. Selective laser melting (SLM) of
Inconel 718 and stainless steel injectors for liquid rocket engines. In Proceedings of the Space Propulsion 2016 Proceedings, Roma,
Italy, 2–6 May 2016.
434. Petch, M. Audi Gives Update on Use of SLM Metal 3D Printing for the Automotive Industry. 3D Printing Industry 2018. Available
online: https://3dprintingindustry.com/news/audi-gives-update-use-slm-metal-3d-printing-automotive-industry-129376/
(accessed on 5 June 2022).
435. Chernousko, F. Locomotion Principles for Mobile Robotic Systems. Procedia Comput. Sci. 2017, 103, 613–617. [CrossRef]
436. Siegwart, R.; Nourbakhsh, I.R.; Scaramuzza, D. Introduction to Autonomous Mobile Robots; MIT Press: Cambridge, MA, USA, 2011.
437. Springer, P.J. Military Robots and Drones: A Reference Handbook; ABC-CLIO: Santa Barbara, CA, USA, 2013.
438. Wang, Y.; Jiang, S.; Yan, F.; Gu, L.; Chen, B. A new redundancy resolution for underwater vehicle–manipulator system considering
payload. Int. J. Adv. Robot. Syst. 2017, 14, 1729881417733934. [CrossRef]
Sensors 2022, 22, 5834
75 of 76
439. Kusiak, A. Smart manufacturing must embrace big data. Nature 2017, 544, 23–25. [CrossRef] [PubMed]
440. Wang, L. From intelligence science to intelligent manufacturing. Engineering 2019, 5, 615–618. [CrossRef]
441. Boyes, H.; Hallaq, B.; Cunningham, J.; Watson, T. The industrial internet of things (IIoT): An analysis framework. Comput. Ind.
2018, 101, 1–12. [CrossRef]
442. Enste, U.; Mahnke, W. OPC Uniﬁed Archit. 2011. Available online: https://doi.org/10.1016/j.compind.2018.04.015. (accessed on 5
June 2022).
443. Lehnhoff, S.; Rohjans, S.; Uslar, M.; Mahnke, W. OPC uniﬁed architecture: A service-oriented architecture for smart grids. In
Proceedings of the 2012 First International Workshop on Software Engineering Challenges for the Smart Grid (SE-SmartGrids),
Zurich, Switzerland, 3 June 2012; pp. 1–7.
444. Zipper, H. Real-Time-Capable Synchronization of Digital Twins. IFAC-PapersOnLine 2021, 54, 147–152. [CrossRef]
445. Altintas, Y.; Kersting, P.; Biermann, D.; Budak, E.; Denkena, B.; Lazoglu, I. Virtual process systems for part machining operations.
CIRP Ann. 2014, 63, 585–605. [CrossRef]
446. Li, Q.; Tang, Q.; Chan, I.; Wei, H.; Pu, Y.; Jiang, H.; Li, J.; Zhou, J. Smart manufacturing standardization: Architectures, reference
models and standards framework. Comput. Ind. 2018, 101, 91–106. [CrossRef]
447. Maiziere, T. Die Lage der It-Sicherheit in Deutschland 2014. Bundesamt für Sicherheit in der Informationstechnik. 2014. Available
online: https://www.bsi.bund.de/SharedDocs/Downloads/DE/BSI/Publikationen/Lageberichte/Lagebericht2014.pdf?__
blob=publicationFile&v=1#:~:text=F (accessed on 5 June 2022).
448. Hentunen, D.; Tikkanen, A. Havex Hunts for ICS/SCADA Systems; F-Secure: Helsinki, Finland, 2014.
449. Falliere, N.; Murchu, L.O.; Chien, E. W32. Stuxnet Dossier Version 1.4. Symantec Security Response.
2011. Available online:
https://www.wired.com/images_blogs/threatlevel/2011/02/Symantec-Stuxnet-Update-Feb-2011.pdf (accessed on 5 June 2022).
450. Rost, J.; Glass, R.L. The Dark Side of Software Engineering: Evil on Computing Projects; John Wiley & Sons: Hoboken, NJ, USA, 2011.
451. Igure, V.M.; Laughter, S.A.; Williams, R.D. Security issues in SCADA networks. Comput. Secur. 2006, 25, 498–506. [CrossRef]
452. Cárdenas, A.A.; Amin, S.; Lin, Z.S.; Huang, Y.L.; Huang, C.Y.; Sastry, S. Attacks against process control systems: Risk assessment,
detection, and response. In Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security,
Hong Kong, China, 22–24 March 2011; pp. 355–366.
453. Ericsson, G.N. Cyber security and power system communication—essential parts of a smart grid infrastructure. IEEE Trans.
Power Deliv. 2010, 25, 1501–1507. [CrossRef]
454. Ten, C.W.; Liu, C.C.; Manimaran, G. Vulnerability assessment of cybersecurity for SCADA systems. IEEE Trans. Power Syst. 2008,
23, 1836–1846. [CrossRef]
455. Malchow, J.O.; Marzin, D.; Klick, J.; Kovacs, R.; Roth, V. PLC Guard: A practical defense against attacks on cyber-physical systems.
In Proceedings of the 2015 IEEE Conference on Communications and Network Security (CNS), Florence, Italy, 28–30 September
2015; pp. 326–334.
456. Jin, C.; Valizadeh, S.; van Dijk, M. Snapshotter: Lightweight intrusion detection and prevention system for industrial control
systems. In Proceedings of the 2018 IEEE Industrial Cyber-Physical Systems (ICPS), St. Petersburg, Russia, 15–18 May 2018;
pp. 824–829.
457. Garcia, L.; Zonouz, S.; Wei, D.; De Aguiar, L.P. Detecting PLC control corruption via on-device runtime veriﬁcation.
In
Proceedings of the 2016 Resilience Week (RWS), Chicago, IL, USA, 16–18 August 2016; pp. 67–72.
458. Lei, C.; Donghong, L.; Liang, M. The Spear to Break the Security Wall of S7CommPlus; Blackhat USA: London, UK, 2017.
459. Ylmaz, E.N.; Ciylan, B.; Gönen, S.; Sindiren, E.; Karacayılmaz, G. Cyber security in industrial control systems: Analysis of DoS
attacks against PLCs and the insider effect. In Proceedings of the 2018 6th International Istanbul Smart Grids and Cities Congress
and Fair (ICSG), Istanbul, Turkey, 25–26 April 2018; pp. 81–85.
460. Morris, T.; Vaughn, R.; Dandass, Y.S. A testbed for SCADA control system cybersecurity research and pedagogy. In Proceedings
of the Seventh Annual Workshop on Cyber Security and Information Intelligence Research, Oak Ridge, TN, USA, 12–14 October
2011; p. 1.
461. Hahn, A.; Kregel, B.; Govindarasu, M.; Fitzpatrick, J.; Adnan, R.; Sridhar, S.; Higdon, M. Development of the PowerCyber SCADA
security testbed. In Proceedings of the Sixth Annual Workshop on Cyber Security and Information Intelligence Research, Oak
Ridge, TN, USA, 21–23 April 2010; pp. 1–4.
462. Luallen, M.E.; Labruyere, J.P. Developing a critical infrastructure and control systems cybersecurity curriculum. In Proceedings
of the 2013 46th Hawaii International Conference on System Sciences, Wailea, HI, USA, 7–10 January 2013; pp. 1782–1791.
463. Feng, Y.; Zhang, W.; Luo, X.; Zhang, B. A consortium blockchain-based access control framework with dynamic orderer node
selection for 5G-enabled industrial IoT. IEEE Trans. Ind. Inform. 2021, 18, 2840–2848. [CrossRef]
464. Falkenberg, R.; Masoudinejad, M.; Buschhoff, M.; Venkatapathy, A.K.R.; Friesel, D.; ten Hompel, M.; Spinczyk, O.; Wietfeld,
C. PhyNetLab: An IoT-based warehouse testbed. In Proceedings of the 2017 Federated Conference on Computer Science and
Information Systems (FedCSIS), Prague, Czech Republic, 3–6 September 2017; pp. 1051–1055.
465. Heymann, S.; Stojanovci, L.; Watson, K.; Nam, S.; Song, B.; Gschossmann, H.; Schriegel, S.; Jasperneite, J. Cloud-based plug
and work architecture of the IIC testbed smart factory Web. In Proceedings of the 2018 IEEE 23rd International Conference on
Emerging Technologies and Factory Automation (ETFA), Turin, Italy, 4–7 September 2018; Volume 1, pp. 187–194.
466. Al-Hawawreh, M.; Sitnikova, E. Developing a security testbed for industrial internet of things. IEEE Internet Things J. 2020,
8, 5558–5573. [CrossRef]
Sensors 2022, 22, 5834
76 of 76
467. Koroniotis, N.; Moustafa, N.; Schiliro, F.; Gauravaram, P.; Janicke, H. The SAir-IIoT Cyber Testbed as a Service: A Novel
Cybertwins Architecture in IIoT-Based Smart Airports. IEEE Trans. Intell. Transp. Syst. 2021, 1–14. [CrossRef]
468. AbdelHafeez, M.; Ahmed, A.H.; AbdelRaheem, M. Design and operation of a lightweight educational testbed for Internet-of-
Things applications. IEEE Internet Things J. 2020, 7, 11446–11459. [CrossRef]
469. Munoz, J.; Rincon, F.; Chang, T.; Vilajosana, X.; Vermeulen, B.; Walcarius, T.; Van de Meerssche, W.; Watteyne, T. OpenTestBed:
Poor man’s IoT testbed. In Proceedings of the IEEE INFOCOM 2019-IEEE Conference on Computer Communications Workshops
(INFOCOM WKSHPS), Paris, France, 29 April–2 May 2019; pp. 467–471.
470. Jayavel, K.; Venusamy, K.; Lavanya, G. Design and Implementation of IoT Testbed with Improved Reliability using Conditional
Probability Techniques. In Proceedings of the 2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics
and Cloud) (I-SMAC), Palladam, India, 7–9 October 2020; pp. 116–121.
471. Industry IoT Consortium (IIC) Testbeds. 2022. Available online: https://www.iiconsortium.org/test-beds/#:~:text=A%20
Testbed%20is%20a%20controlled,%2C%20services%2C%20or%20business%20development (accessed on 5 June 2022).
472. Kovalenko, I.; Saez, M.; Barton, K.; Tilbury, D. SMART: A system-level manufacturing and automation research testbed. Smart
Sustain. Manuf. Syst. 2017, 1, 1. [CrossRef]


Paper 5:
- APA Citation: 
  Main Objective: 
  Study Location: 
  Data Sources: 
  Technologies Used: 
  Key Findings: 
  Extract 1: 
  Extract 2: 
  Limitations: >
  Relevance Evaluation: Highly relevant - The paper focuses on the use of machine learning algorithms in IoT based healthcare applications and provides a comprehensive review of the current state-of-the-art, use cases, and future prospects. It covers a wide range of applications, from monitoring physiological parameters to automating tasks across the entire data pipeline, using advanced sensing technologies such as hyperspectral imaging and thermal sensing for non-invasive plant stress detection.
  Relevance Score: 1.0
  Inline Citation: >
  Explanation: This paper gives an in-depth review of the current state-of-the-art and future prospects of real-time, automated systems for monitoring physiological and medical parameters using IoT and ML technologies as well as examines the automation of tasks across the entire data pipeline from collection and transmission to processing and analysis. It explores the application of advanced sensing technologies such as hyperspectral imaging and thermal sensing for non-invasive plant stress detection. It also considers automation in data collection and transmission, data processing, analysis, and decision-making, and examines the deployment of real-time, automated irrigation systems.

 Full Text: >
This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising purposes. To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln Sign Out All Books Conferences Courses Journals & Magazines Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 9 A Review on the Role of Machine Learning in Enabling IoT Based Healthcare Applications Publisher: IEEE Cite This PDF Hemantha Krishna Bharadwaj; Aayush Agarwal; Vinay Chamola; Naga Rajiv Lakkaniga; Vikas Hassija; Mohsen Guizani; Biplab Sikdar All Authors 87 Cites in Papers 9353 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction II. General Architecture of H-IoT III. Overview of Algorithms IV. Diagnosis V. Prognosis and Spread Control Show Full Outline Authors Figures References Citations Keywords Metrics Abstract: The Internet of Things (IoT) is playing a vital role in the rapid automation of the healthcare sector. The branch of IoT dedicated towards medical science is at times termed as Healthcare Internet of Things (H-IoT). The key elements of all H-IoT applications are data gathering and processing. Due to the large amount of data involved in healthcare, and the enormous value that accurate predictions hold, the integration of machine learning (ML) algorithms into H-IoT is imperative. This paper aims to serve both as a compilation as well as a review of the various state of the art applications of ML algorithms currently being integrated with H-IoT. Some of the most widely used ML algorithms have been briefly introduced and their use in various H-IoT applications has been analyzed in terms of their advantages, scope, and possible improvements. Applications have been divided into the domains of diagnosis, prognosis and spread control, assistive systems, monitoring, and logistics. In healthcare, practical use of a model requires it to be highly accurate and to have ample measures against security attacks. The applications of ML algorithms in H-IoT discussed in this paper have shown experimental evidence of accuracy and practical usability. The constraints and drawbacks of each of these applications have also been described. Topic: AI and IoT Convergence for Smart Health Review on the Role of Machine Learning in Enabling IoT Based Healthcare Applications. Published in: IEEE Access ( Volume: 9) Page(s): 38859 - 38890 Date of Publication: 16 February 2021 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2021.3059858 Publisher: IEEE Funding Agency: CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation. SECTION I. Introduction The Internet of Things (IoT) has been the subject of great enthusiasm in the healthcare technology community over the last few years. The healthcare domain is of great practical importance and IoT opens up a wide spectrum of opportunities to make it better. Numerous contemporary medical devices and sensors can connect over various networks, which provides access to important information about patients’ conditions. This information can then be used for multiple purposes such as monitoring patients remotely, predicting illness and recovery through the greater insight into symptoms, and generally improving the diagnosis and treatment process via increased automation and portability. Due to the vast multitude of data generated in real-time by these devices and their complex nature, analysis using ML algorithms has proven to be of vital importance to H-IoT. These algorithms allow us to extract valuable information from the acquired data and draw useful inferences. Though ML models can provide great levels of accuracy when trained in the right environment, this is generally easier said than done. Various contemporary research efforts are aimed at finding out new areas of applications of ML algorithms to H-IoT systems, evaluating their suitability for these systems, and increasing the accuracy achieved by prediction and analysis models. Using ML based systems has numerous advantages. They can be trained using large volumes of data, termed as training data, and then, through inductive inference, they can assist clinical practice in assessing risk and designing treatment. These systems can reduce error by eliminating human elements from the system, and can perform repetitive jobs, thus improving efficiency compared to manual efforts. Physicians can be assisted by artificial intelligence (AI) that can learn information related to medical science from textbooks, journals, and clinical practices to consult and provide adequate patient care, which, for humans, is tedious. However, the inferences that a human mind can make are still missing in existing AI techniques. Monitoring, managing, and analysing medical reports become easier with integration of ML with IoT devices. Moreover, ML algorithms can process large sets of biological data and detect specific patterns and mutations involved in various diseases, which can accelerate the discovery of novel therapeutics. Health monitoring services and consulting can also be provided digitally by AI to a certain limit — being entitled as “health bots”. There are a few other studies surveying the role of ML in healthcare-IoT. A very important premise for modern systems is the use of fog and edge computing to reduce server load and low latency responses [1]. Greco et al. [2] discussed the gradual shift in the implementation of ML models from cloud towards the fog and edge for healthcare IoT. They discussed this change in architecture across applications such as analysis of physiological parameters and rehabilitation systems. Mutlag et al. [3] also discussed the scenario of growth in fog computing in the healthcare IoT domain. Deploying models closer to the end devices allows low latency and independence from network failures. Fog based applications have been thoroughly scrutinized and a spectrum of security implementations have been proposed for it [4]. Farahani et al. [5] surveyed various systems for applications such as population monitoring and assisted living. Rong et al. [6] reviewed some of the applications of AI in healthcare systems with case studies of epileptic seizures and filling of a dysfunctional urinary bladder. ML has also been used to predict the insurance medical costs as well [7], [8]. Lastly, the recent adoption of ML and blockchain in healthcare, its applications, followed by challenges and privacy concerns have also been surveyed [9], [10]. Although there are works in this direction, they are either too specifically focused on the architecture without consideration of the diversity in algorithms or focus on the model without discussing how the data is coming from the IoT system. Hence, it is necessary to review the various architectures for both the IoT systems and ML models to have a grasp over the recent developments. Through this paper, we have tried to cover this existing gap. The main contributions of this work are enumerated below: An overview of various prominent ML algorithms with particular focus on their applications and use cases in the healthcare-IoT industry has been provided. Detailed reviews of important applications of these algorithms in diagnosing patients with common ailments like cardiovascular and neurological disorders, diabetes, etc. and in automating the diagnosis process have been presented. The role of ML algorithms with IoT architecture in forecasting future stages of diseases and controlling the spread of epidemics has been surveyed. Assistive systems for the aid of the physically challenged, the mentally disabled and the elderly, that have the potential to greatly improve their quality of life, have been identified and reviewed. Futuristic ML-IoT based technologies that promise vast strides in making health monitoring systems more accessible and efficient, as well as technology that improves the overall process of obtaining healthcare has been studied. The rest of this paper is organized in the following manner, as shown in Figure 1. Section II provides the definition as well as general architecture of standard Healthcare-IoT frameworks. Section III provides a brief overview of the various AI algorithms currently being researched for use in the healthcare industry. Sections IV through VIII extensively cover reviews of the state of the art applications of these algorithms to H-IoT in the areas of diagnosis, prognosis and spread control, assistive systems, patient monitoring, and healthcare logistics, respectively. Finally, section IX provides the conclusion to the paper. FIGURE 1. Organization of this work. Show All SECTION II. General Architecture of H-IoT The implementation of IoT in healthcare originated from efforts to develop remote patient monitoring systems. The research on various applications of H-IoT has since been growing consistently, and contemporary research aims at incorporating IoT into various facets of healthcare, including disease spread control, effective automated diagnosis, and improved treatment. In this section, we define what a H-IoT system is, and briefly describe the various components of its architecture. Figure 2 shows the various classifications for different H-IoT applications described in literature. FIGURE 2. Applications of H-IoT. Show All A. Definition of H-IoT A healthcare IoT system can be defined as a network of all available health resources connected to each other for rapid transfer of data between them over the Internet [11]. This means that all healthcare resources like doctors, hospitals, rehabilitation centres and all medical devices and sensors along with the patients become interconnected with each other for continuous real-time data transfer. The various sensors coupled with applications that interpret their readings can detect anomalies and send patient data to medical practitioners/hospitals for diagnosis and analysis, after which corrective action can be prescribed and undertaken. For such a framework to exist and work smoothly, three primary requirements need to be met [12]: Interoperability: The wide range of devices being used in the framework should be able to cooperate among each other to enable the desired functionality. Bounded latency and reliability: For effective handling of emergencies and synchronised analysis of the huge amount of data, the transmission between the entities in the network must be fast and accurate. Privacy and security: Personal data being transmitted in an H-IoT framework is sensitive and should securely reach only the concerned entities, which necessitates having authentication and security measures in place. Various mechanisms for authorization and authentication of IoT devices are available using technologies such as encryption and physical unclonable functions [13]–[15]. B. Architecture of H-IoT An H-IoT system comprises of an end-to-end network typically consisting of three major layers of operation [16]: Data collection layer: This layer is responsible for the collection of medical data from various sensor devices attached to the patient/test subject that needs to be monitored/examined. Data storage layer: This layer is responsible for storage of big data collected from various sensors and transmitted through the Internet. Data processing layer: This layer analyzes the data stored in servers to generate the required response through application of computing algorithms. Also, the compilation and visualization of the results are done here. The implementation of these layers is enabled using the following technologies [11] as shown in Figure 3: Identification technology: For the nodes in the network of an H-IoT framework to access information and communicate with each other securely, each node must be identified uniquely through technologies such as a unique identifier (UID) [11]. Communication technology: Both short and long distance communications between the nodes in the H-IoT network require pathways. Long distance communication is undertaken through conventional means such as the Internet, while short distance communication separately requires specific technologies, preferably those that enable fast wireless communication like Bluetooth, Zigbee, RFID etc. Location technology: Global positioning system (GPS) enables the various nodes to accurately track each other’s geographical locations which is extremely important for certain use cases of H-IoT. Various other location tracking systems may also be required to compensate for instances of poor GPS connectivity [11]. Sensing technology: The data analyzed to draw inferences in an H-IoT system is generated by sensors. Therefore, sensing mechanisms that monitor real-time physiological changes in a patient’s body are imperative. A large variety of sensors are available for acquisition of such data, for instance, accelerometers for sensing linear acceleration, gyroscopes for measuring angular velocity, and electrocardiogram (ECG) sensors to measure electrical activity in the heart [16]. Evolution in sensor technology is directly related with evolution of H-IoT frameworks leading to more accurate predictions and lower costs. Application level architecture: Application level architectures such as service oriented architecture (SOA) [17] or representational state transfer (REST) allow the various devices in the system to perform independently of each other. Each device’s operations are properly defined and can be altered as and when required without compromising the interoperability of the system. FIGURE 3. H-IoT Technologies. Show All SECTION III. Overview of Algorithms This section provides a brief overview of prominent algorithms used in H-IoT, and a few examples of their H-IoT applications. In general, these algorithms can be divided into supervised and unsupervised learning algorithms, depending on whether the desired classification labels are provided in the input dataset (supervised) or not (unsupervised). Machine learning algorithms generally prefer labeled data, while deep learning algorithms are more adept at exploiting unlabeled data. A. Dimensionality Reduction Algorithms (DRA) DRA are a set of algorithms such as linear discriminant analysis (LDA) and principal component analysis (PCA) which take in large data sets as input, identify the correlations and patterns in them, and provide a much smaller data set (in terms of the number of dimensions) as output without losing any critical information previously provided. This removes inconsistencies, redundant data, and highly correlated features of the data. Dimensionality reduction is performed through the following steps: Standardization: each data point is scaled as: New variable = (original variable - mean of all variables of the feature)/(standard deviation of all variables of the feature). Computing the covariance matrix: [feature][feature ] T . Calculating the eigenvectors and eigenvalues. Computing the principal components. Significant promises have been made for diagnosis of Parkinson’s disease and breast cancer by combining IoT and DRA such as LDA [18]. The significance of a combination of IoT and DRA to boost diagnostic capabilities is well discussed in available literatures [19], [20]. B. Discriminant Analysis Discriminant analysis, which is an important type of DRA, projects data points to a space of lower dimensions such that the classes get separated appropriately into non-overlapping groups. Such classification is similar to multiple regression when only two groups are involved, but proves to get more complicated as the number of groups increases. In healthcare, discriminant analysis finds applications mainly in measuring disease prognosis and severity in a patient. LDA classifies by finding a linear combination of features, while a more general multiple discriminant analysis extends the same to a non-linear space. C. Linear Regression Linear regression is a modeling technique which uses linear approach for finding a relationship between a dependent variable and one or more independent variables. It is preferred in cases where only continuous independent variables exist. Many techniques for preparing a linear regression model exist, of which ordinary least squares and gradient descent method are most commonly used. The former tries to directly minimize the sum of squared error values to find out the coefficients, while the latter uses an iterative approach to minimizing the sum of squared residuals. D. Logistic Regression Logistic regression is a probability-based algorithm in which its sigmoid function acts as the cost function and assumes a value between zero and one. The sigmoid function is given by: f(x)= 1 1+ e −x . (1) View Source Logistic regression can be of two types. When the observations are to be classified into two classes, binary logistic regression is used, while more than two class classifications require the use of multinomial logistic regression. Using logistic regression is especially advantageous when the regression problem has a dichotomous dependent variable. E. Support Vector Machine This algorithm uses the concept of a classifying hyper-plane. The aim is to identify a plane that divides the dataset into two groups such that the gap between the data points in the two groups is maximized. This hyper-plane is said to have the maximum range. Data points falling on different sides of the hyper-plane are assigned to different groups. The dimension of the hyper-plane depends on the number of features. For features less than or equal to 2 in number, the hyper-plane is simply a line. It turns to a 2-D plane for 3 features, while picturing it for more than 3 features becomes difficult. SVMs are advantageous in that they are extremely resilient to overfitting problems. SVMs can not only work as linear classifiers, they can also use non-linear kernels to classify datasets using non-linear functions. Ginantra et al. [21] proposed a model that demonstrated an SVM classifier which outperformed other classifiers for identifying whether a person suffers from influenza-like illnesses (ILI) (i.e., acute respiratory infections). SVM is found to be the most accurate in location verification [22] without the requirement of channel characteristics data to operate. SVMs were also used to develop methods for solving the classification task of medical implant materials [23]. F. K Nearest Neighbors (KNN) KNN is a supervised learning method where objects are classified based on their similarity to certain features of other objects whose category is predetermined. Distances, mostly Euclidean, are calculated for the object whose category is determined to its k closest neighbors. That is the difference between the features of the neighbors is taken and summed to find the distance. The Euclidean distance is given by Eq. 2. Then, voting is done to determine the category in which the majority of the k nearest objects belong to. The value of k is determined through the process of parameter tuning. It is usually chosen to be around the square root of the total number of objects, and is generally an odd number to avoid the possibility of multiple categories getting equal votes. Distanc e 2 = (featur e 1,object −featur e 1,neighbor ) 2 +(featur e 2,object −featur e 2,neighbor ) 2 … +(featur e n,object −featur e n,neighbor ) 2 (2) View Source KNN is helpful for the classification of labeled data even when the training set is very small and is widely used in various applications. Ahmed [24] used KNN on data collected from IoT devices to predict heart attacks. It was used on data collected from 20 Kinect sensors to measure the positions of different joints in the body [25]. These were then passed through KNN classifiers used with both Euclidian and Minkowski distances to predict the user’s current activity. This has great potential for use in fitness measurement once classification is developed for a variety of activities. Azimi et al. [26] proposed to use multiple KNN imputations to estimate lost or missing data points collected to monitor pregnant women. This application can be reliably used, both as a medical B2C service or as a tool for research on maternal health. Hossain et al. [27] showcased another activity measurement application using long range wide area network (LoRaWAN) sensors and accelerometer for detection using KNN with an accuracy of 80%. G. K-Means K-means classifies objects based on whether or not they fall within the parameters of a certain class. Hence, the categories of classification are limited to “similar” and “dissimilar”. Euclidean distances are used to determine the centroid of the cluster for each category, and a new object is simply classified based on the distance from each cluster. This method finds its applications in numerous web engines and wireless sensor network (WSN) systems. K-means classification is also used in other diverse fields, ranging from using wearable sensor networks to detect injury among soldiers away from their posts during a war [28], to monitoring the ECG of patients using data collected through wearable IoT nodes [29]. Sood and Mahajan [30] proposed using similar technology to provide remote diagnostics for a chikungunya epidemic through fog computing and using fuzzy k-means to track the possibility of disease transmission. This is a tested method that may be expanded for COVID-19 tracking as well. Further, Kim et al. [31] demonstrated the use of k-means clustering on MRI images for information deduction to speed up the detection of brain tumors. H. Decision Tree A decision tree consists of three components: internal nodes, branches, and leaf nodes which represent features, decision rules, and outcomes, respectively. Gini index and entropy are two of the most widely used methods to classify data. Cho [32] used decision trees to track the location of persons during a pandemic. Xie et al. [33] used decision trees to develop a heartbeat classification algorithm that identifies premature ventricular contraction (PVC) to diagnose arrhythmia using amplitudes and intervals of heartbeat as features. I. Random Forest(RF) Decision trees adapt according to the particular data used for training them. The results obtained using a decision tree vary drastically if the training data is altered. This algorithm is computationally expensive. A local optima is generally calculated because going back is not possible once splitting occurs. Random forest method addresses these limitations. In this model, several decision trees are trained simultaneously to produce a single output. Such decision tree merging is called bagging. As an example, Al Hossain et al. [34] demonstrated the application of a random forest model that outperformed other models with 95% accuracy in predicting the number of people infected by influenza in public places. It shows a high accuracy due to its ability to combine the outputs of all decision trees. Gupta et al. [35] presented a random forest classifier that outperformed KNN, SVM, and decision tree with 77.8% accuracy in detection of abnormal crowd motion. J. Naive Bayes (NB) NB classification is conceptually based on the Bayes theorem. ‘Naive’ refers to the fact that all features are assumed to be independent of each other. The data is split into a feature matrix and a response vector. The rows of the feature matrix provide the whole data collection in terms of vectors, each of which represents the relative variable type. On the other hand, each row of the response vector represents an outcome class. Sadhukhan et al. [36] and Assery et al. [37] mentioned situations where NB outperformed all other classifiers to classify tweets that can help in managing the social networking issues in disaster or pandemic periods. K. Gradient Boosting & Adaboost In the general case of weak learners, the accuracy is just about as good as a random outcome generator. Thus, a good way to utilize them is to combine them through more than one ML algorithm to create a strong learner. This methodology of using multiple learners to train a model is also known as ensemble learning. Boosting is an ensemble learning method that creates decision boundaries for each weak learner and assigns each of the weights based on how accurately the boundaries classified or estimated the data. This is repeated till a satisfactory model is created. Adaboost gives each observation (for the first boundary) equal weight in the beginning and then keeps increasing the weights for the incorrectly classified objects and altering the boundaries accordingly until all observations are correctly classified. In gradient boosting, multiple boundaries (learners) are created one after the other such that each consecutive learner accounts for some errors of the previous one. Extreme gradient boosting can be used to predict heart patients’ irregular cycles with 92.1% accuracy [38]. Similarly, voice signals collected from wearables can be used to detect early signs of Parkinson’s disease [39], whereas predictive analytics can be used to diagnose diabetes in clients [40]. Constrained IoT devices can also be used to efficiently detect seizures [41]. L. Convolutional Neural Networks(CNN) CNN is a feed-forward network used in classification problems [42]. It breaks the input down into constituents and then passes them on to a convolution layer, which puts these parts into different combinations until some patterns emerge from them (convolution). A rectified linear unit (ReLU) layer then maps the input images against these patterns to form a rectified feature layer and passes them on to a pooling layer. The pooling layer reduces the map to give a pooled feature map, which is then flattened to form a linear vector and fed into a fully connected network to categorize the input. CNNs are used extensively in areas that require visual interpretation of images with a grid-like topology. Alhussein et al. [43] converted brain wave values received as a 2D time series to predict epileptic seizures and inform health authorities with immediacy. Ke et al. [44] proposed the use of raw electroencephalogram (EEG) to evaluate depression using lightweight CNN. Ciocca et al. [45] used images to recognize food and in turn, calories, which has applications in nutrition and fitness. Alhussein and Muhammad [46] used mobile healthcare frameworks to detect voice pathologies using deep learning on pitch tones. Bansal et al. [47] proposed a resnet based framework for lung cancer classification and 3D segmentation, achieving an accuracy of 92.7% for segmentation and 88.3% for detection using the LUNA16 dataset. M. Artificial Neural Networks An artificial neural network (ANN) is a ML model that mimics the learning process of the human brain: there exists an input layer that receives the data to be processed, several layers that process the data, and an output layer that gives the output. In ANNs, the hidden layers receive intermediate inputs, assign a random weight and bias to each of the inputs and calculate several weighted sums, which are then passed through layers with weights and sums, until they reach the last layer, which uses an activation function to determine the output. When the outputs are incorrect, they are fed back to the previous layers (back propagation) in accordance with a cost-function to alter the weights until answers are received with sufficient accuracy. ANNs are extremely dynamic and find applications in domains related to pattern recognition. Kim et al. [48] used an inconspicuous method of IR sensors placed throughout the house to monitor movement, bathroom time, sleep, and excursions to detect signs of depression among elderly people through processing information received over telecom data using ANN. Bhatia and Sood [49] proposed using back propagation ANN to predict probabilistic health state vulnerabilities during exercising. Sood and Mahajan [50] and Humayun [51] used a fog-layer framework to identify and control hypertension (BP) attacks, and to manage data pertaining to heart attacks in patients, respectively. Hassija et al. [52] worked on a neural network-based smart contract that was used in conjunction with a blockchain network to form a traffic estimation system. N. Reinforcement Machine Learning Reinforcement learning is based on the methodology by which infants learn to interpret the world around them. This comprises an agent, or the learner, who starts from a specific state in the environment, say S0. The agent then takes an action, A0, and the state updates to S1. If the action was in the correct direction, the environment rewards the agent with R1. This is repeated until the reward is maximized. It comprises of a set of algorithms such as Monte Carlo and Q Learning. Park et al. [53] discussed automated diagnostics of high volumes of patients through IoT wearables using Q learning. Zhao et al. [54] provided a novel method to route crowds in a smart city using reinforcement learning, a technology that may prove pivotal to lifting lockdowns during COVID-19 while keeping up with social distancing norms. Dourado et al. [55] used topographic images of the skull to detect strokes using a deep learning IoT model. Liu et al. [56] used similar models to detect lung cancer. O. Natural Language Processing(NLP) NLP refers to the application of ML algorithms for computers to understand and interpret natural human language, speech, and text. Its linguistic extraction features make it extremely easy to process and quantify unstructured information. The algorithm uses the following approach: Stemming and tokenization: breaking down words into root words and categorizing them. Semantic analysis and disambiguation: extracting the literal meaning of words used and breaking them down into context and intent. Topic modeling: understanding the domain of which the conversation is a part of. The most common libraries for NLP available today include Scikit-learn, NLTK, spaCY, and TextBlob. NLP applications go beyond their dependence on textual or image data to extract information and are hence used in widely varied applications, like food intake and nutrition tracking [57] and to evaluate the emotional response of the patient on medicine intake [58]. Amin et al. [59] proposed using NLP to evaluate speech, facial expressions, movement etc. in real-time through smart city networks to assess the patients and provide them with required emergency help. This technology also finds varied use in mental health applications [60], where NLP was used on data from both social media and IoT device data. P. Cognitive Automation Cognitive automation is a sub-element of AI. It uses advanced technologies like data mining, emotion recognition, NLP and cognitive reasoning with the objective of imitating human intelligence. Cognitive automation tries to imitate human intelligence using technology to solve problems. It acts as a catalyst mechanism behind efficient and improved responses generated by an AI device. Cognitive automation, by offering a more collective approach to H-IoT, helps in applications where a synchronised use of physiological and psychological systems is required for dealing with medical emergencies. Muhammad et al. [61] developed a 5G cognitive healthcare monitoring system that can revolutionise healthcare systems, especially in smart cities by running a data and a resource cognitive engine simultaneously. Alhussein et al. [43] studied cognitive IoT frameworks developed for the monitoring and diagnosis of epilepsy. SECTION IV. Diagnosis In this section, we present an overview of various use cases for diagnosis where AI and IoT based systems have been used or proposed. Diagnosis is generally carried out by the identification of the nature of an illness which the patient is currently facing by examination of the symptoms which are measured by sensors. Table 2 at the end of this section gives a brief summary of the reviewed publications that pertain to use cases of ML algorithms for diagnosis. TABLE 1 Results for MDCNN [65] TABLE 2 Use Cases of ML Algorithms for Diagnosis A. Cardiovascular Disorders Heart diseases are one of the major causes of mortality around the world. Predicting a heart disease is a complex task. However, the integration of IoT into healthcare systems has shown a remarkable way to monitor patients’ health and diagnose anomalies. The most commonly used sensors are for ECG, blood pressure, heart pulse and body temperature. ECG signals represent the electrical activity of the heart at rest. It can be used to draw inferences about the heart rate and rhythm, and can be useful for diagnosing the enlargement of the heart due to high blood pressure, elevated heart rate, and dysrhythmia or heart attacks. Figure 4 shows some of the most commonly used sensors related to cardiovascular diagnosis. FIGURE 4. Common sensors for cardiovascular diagnosis. Show All Gupta et al. [62] proposed using a ML based model to diagnose heart diseases by monitoring several parameters in real time, using wearable IoT technology. The aim of the study was to use real-time ECG, pulse and temperature monitoring as inputs to a trained prediction model to predict if the user is at risk for any heart disease or arrhythmia. The project was carried out in three phases: data pre-processing, model training phase, and prototyping for live prediction. In the first phase the electronic health records (EHR) dataset was consolidated, and the parameters considered relevant to the predictor were isolated. The values that were missing in the dataset were replaced with the most frequently occurring value (i.e., the mode) for each feature. A correlation assessment was done to determine the different parameters following very similar trends. Such trends which did not contribute in the learning of the model, and would simply add to the program complexity were removed (dimensionality reduction). In the second phase, the pre-processed dataset was split into training and testing sets followed by model training on the training dataset. Different classification algorithms namely KNN, SVM, NB, decision tree and random forest were evaluated for accuracy, hit rate, etc. The third phase included the hardware prototype development for collection of data and cloud connectivity, and most importantly, real time prediction. Using the ESP8266 WiFi supported development board, the AD8232 ECG sensor, HW01 pulse sensor and the MAX30205 temperature sensor, the node was connected to a laptop feeding continuous data into the trained model, along with other static data such as age, sex and sugar levels. After this, a laptop ran the model giving an 88.9% accurate judgement using KNN to identify if the patient was at risk for heart problems. Although this was a fairly simple method, more research needs to be done for improving the accuracy. Hence, this technology needs to be further developed with better training over time and better instrumentation for a broader real-time dataset. Taştan [63] reported similar studies by using only a real-time monitoring approach while Davis et al. [64] also accounted for the past health record of the patient. Khan [65] proposed an IoT healthcare system for evaluating heart diseases using the modified deep CNN (MDCNN). The data used for training and testing was collected from Framingham, the UCI ML Repository and public health dataset. A smartwatch and heart monitoring device were used to collect information about the blood pressure and ECG which were then transmitted to the server using LoRa. Based on this transmitted information, the MDCNN model classified the patient as having a normal or an abnormal heart condition, and alerted the doctor in case of an abnormality. This was also carried out in three stages: pre-processing, feature selection and classification. The first stage comprised of adding the missing attributes based on the patient’s age, blood pressure and cholesterol, removing redundancies, and separation of patients based on the type of chest pain they had: typical angina, atypical angina, non-anginal pain, and asymptomatic. The most important features for evaluating heart diseases were selected by using the mapping-based cuttlefish optimization algorithm (MCFA) [66]. Finally, for the classification stage, the weight values to be used in the model were optimized using the adaptive elephant herd optimization algorithm. For the actual prototype, an Omron HeartGuid-bp8000m was used to measure the resting blood pressure. However due to unavailability of wearable devices for the serum cholesterol and glucose levels, pseudo numbers were generated in a fixed range. Lastly, an AD8232 sensor was used for measuring the ECG data. A Raspberry Pi was used for interfacing which sent the data to the cloud using a SX1272 900MHz LoRa transmitter. The results from this study are given below in Table 1. Azariadi et al. [67] proposed heart diagnosis using ECG analysis and classification on an embedded IoT system. The model developed could be used with wearable sensors for ECG diagnosis, which allowed continuous monitoring around the clock. The proposed system had 4 steps: detection of the heartbeat, segmentation, feature extraction and classification. The MIT-BIH arrhythmia database was used for developing the classifier. Discrete wavelet transform was used for feature extraction while classification was done using SVM. The algorithm was later coded and implemented for Intel’s Galileo IoT board. The ECG signal was read and digitized at a sampling rate of 360 samples per second while analysis was done for every 3000 samples. The average accuracy was 97%. Wang et al. [68] proposed a model combining logistic regression and ANN for prediction of chronic diseases or risks by covering a case study of hypertension based on health risk assessment (HRA). The integrated model utilized data available to all from behavioral risk factor surveillance system (BRFSS) of centers of disease control and prevention (CDC). First the binary logistic regression was used to select risk elements having consequential p-values. While selecting the important risk elements, multi-factor logistic regression model integrated with partial maximum likelihood (PML) estimation and forward-step regression analysis was used on the experimentation data. As a result, eleven factors such as age, exercise, marriage, diabetes, income, body mass index, gender, smoking and drinking habits were chosen as the significant risk-factors. Then, multi layer perceptron (MLP) neural network was constructed and trained with back propagation (BP) algorithm for the specific factors to diagnose if an individual was enduring hypertension or not. Increasing the number of hidden layers in this MLP-NN model can escalate the precision of predictions. However, the number of hidden layers must be more than two-thirds of input factors [69]. The dataset was divided into training and testing sets with a ratio of 7:3. The accuracy varied from 71.91% to 72.12% when the number of hidden layers was increased from 8 to 11. Initially, the default threshold was assumed to be 0.5, which was changed with every training iteration. Experimental results have shown that the integrated model of ANN and logistic regression is better than any of the two acting individually. The future goals of this study are to involve more risk factors and training the data over more iterations for better prediction results. Acute coronary syndrome (ACS) is a serious medical condition due to the imbalance created among the metabolic needs in the body. This condition is characterized by chest pain that radiates to the neck and left arm. Medical professionals prescribe different laboratory tests and ECG based on patient conditions. Berikol et al. [70] studied building models for diagnosing ACS using the ML method for SVM with several patient attributes such as age, risk factors, sex, and cardiac enzymes’ presence. Berikol et al. [70] used the data of 228 patients with their medical history, clinical, laboratory, and imaging information to build a ML model. In this study, four methods were tested starting with SVM, NB, ANN, and logistic regression. The result showed that SVM had the highest precision in the patient group ranging from 19 years to 91 years. It was found that out of 228 patients, 99 were listed as with ACS and 129 as without ACS. SVM model gave 99.13% accurate predictions in diagnosing ACS. Diagnostics is a wide field and modern scientific methods are always evolving. This study showed the system can be integrated with medical departments for decision making in the future. However, the study was conducted on the patient history and ECG findings. Risk factors of patients were not included in the study which is a major limitation. Measuring pain may need a more practical approach than theoretical analysis. Finally, more real-time data is required for model training and real-time decision making. IoT systems are still developing and are bound to bring more technological changes. More data, research methods and advanced techniques will help improve the estimates for better accuracy in the future. In addition to ECG analysis which is being actively researched in, another challenge is development of wearable devices which can be used constantly and are financially viable. Modern wearable solutions can help to further enhance the process and bring a more sophisticated healthcare IoT system for improved decision making. B. Lung Cancer Lung cancer is the most common cancer with 1.76 million deaths in the year 2018 [71]. Valluru and Jeya [72] presented a model based on optimal SVM for classifying computerized tomography (CT) lung images with optimized SVM parameters to diagnose lung cancer. To improve the results of SVM, feature selection and parameter optimisation were done effectively. In this SVM, feature selection was done by modifying grey wolf optimization (GWO) algorithm integrated with genetic algorithm (GA). This experiment took place in 3 phases: testing for parameter optimization, feature selection, and optimal SVM. A set of experiments were carried out to explore the results in terms of feature selection and performance of classifier. The simulation follow-up distinctly defined the enhanced performance of the optimal SVM among the collated methods. GWO algorithm is classified into 4 types: alpha, beta, delta, and omega. GWO algorithm has 2 phases: exploration and exploitation. The exploration stage selects optimal solutions in the local database. Upon finding the optimal results, the search agents change their location based on the best solution procured. GWO-GA algorithm makes use of binary encoding which makes cooperation between attributes simpler. The solution of GA is taken in as the initial population of GWO algorithm. When a particular individual’s fitness level computes to be superior to that of GA, the GA gets replaced by said individual and then reinitializes. Therefore, GWO-GA algorithm gets executed until the terminating criteria is satisfied. Originally, the attributes are calculated using the optimal SVM, followed by categorization of images using an SVM classifier. To look for a hyperplane, classifier training is availed which distinguishes the negative samples from the positive samples. This complete process is a straightforward linearly separable problem in high dimensions, and the transformation is based on SVM’s kernel function. The presented procedure shows its better outcomes on every applied test image following multiple aspects. Above all, it achieves an average accuracy for classification of 93.54% which is clearly more than the compared methods, those being GA, BPSO and BDE. The detailed analysis experiments on the test images proved that the proposed procedure can be successfully applied in real time data analysis in hospitals and other healthcare institutions. This proposed algorithm can be further improved by the incorporation of deep learning models. C. Neurological Disorders For neurological disorders such as epilepsy and Alzheimer’s, EEG based monitoring is one of the most important ways in which smart healthcare systems can contribute to monitoring patients. EEG is a diagnostic method used to detect electrical signals in the brain using electrodes attached to the scalp. Another type of brain signal diagram that has not been extensively used for neurological diagnosis is magnetoencephalography (MEG). MEG signals are less attenuated as compared to EEG signals and is therefore a promising diagnostic tool. A cognitive IoT framework for EEG-based pathology detection was proposed by Amin et al. [59]. In this framework, the multimodal data from EEG electrodes was processed and sent to a cognitive system in the cloud which analyzed the patient’s state and transmitted this data to a deep learning system for detection of disease. The deep learning system used CNN and sent the results of classification back to the cognitive system which finally decided on the emergency response and sent it back to the medical professionals for further analysis. The model proposed by Amin et al. [59] used two popular CNN models separately to conduct two sets of experiments- the VGG-16 and the AlexNet models. The system with the VGG-16 model achieved an accuracy of 86.59% while the one with AlexNet achieved 87.32%, which are higher than those obtained by the state-of-the-art models. This shows future prospects of implementing smart IoT-cloud integrated deep learning frameworks in smart cities with the use of cognitive engines to overlook the decision making. Another study by Khalid et al. [73] aimed to provide a method for automating spike detection in MEG signal data. To differentiate between spike and non-spike signals, features are extracted using the common spatial patterns algorithm. These features were found to follow normal distribution. Thus, LDA was chosen as classification method. Since the LDA is being performed for two classes, namely spike and non-spike signals, the Fisher criterion [74] was maximized to provide predictors that separate the said classes. This method of classification was evaluated using leave-one-out cross-validation (LOOCV). The evaluation metrics used were sensitivity and specificity, which averaged for seven trials at 91.03% and 94.21% respectively. These results indicated that identification of MEG spikes using LDA is a promising approach to diagnose epilepsy. Apart from using classifier algorithm models for the classification of EEG data, computer aided diagnostics (CAD) can also rely on convoluted neural network (CNN) based models to classify EEG signals and classify them as normal, preictal, and seizure classes. As the EEG signals are non stationary and highly complex in nature, visual interpretation is rather difficult. Application of convoluted neural network models in the EEG data results in an automated detection of various classes of epilepsy. Acharya et al. [75] employed CNN to automatically classify EEG datasets into 3 classes. Acharya et al. [75] discussed models that used traditional CNN architecture consisting of convolutional layer, pooling layer and fully connected layer. The model also used two types of activation functions: rectified linear activation unit and Softmax. The model was evaluated on metrics including accuracy, specificity, and sensitivity. The CNN based model reported an accuracy of 88.67%, specificity of 90%, and sensitivity of 95%. Use of CNN models for EEG based classification shows promise; however, application of CNN to physiological signals is still a relatively unexplored area with scope for more research. D. Diabetes and Pancreatic Cancer Type 2 diabetes, which results in high amounts of blood sugar is one of the most widely affecting chronic diseases that can prove fatal if not kept in check. The incidence of diabetes is constantly increasing, with most individuals suffering from Type 2 diabetes mellitus often going undiagnosed. Efficient identification of undiagnosed diabetic individuals will lead to better and informed treatment of the disease and an overall reduced mortality rate. Han et al. [76] provided an identification model for undiagnosed patients of type 2 diabetes mellitus using SVMs. Due to the less comprehensible nature of SVMs, instead of directly using an SVM model, the tuned SVM model is used to extract support vectors that are in turn used to generate artificial data. Using this artificial data in a random forest model, rules were finally extracted to diagnose diabetes. This proposed model was tested based on three different scores: precision, F score and recall. The model was found to have a precision of 89.6%, outperforming the four other models that comparisons were drawn with, namely random forest, C4.5, NB tree, and back propagation neural network. The rule extraction ensemble approach using SVM with random forest improves the accuracy of the original SVM model. Han et al. [76] also used this ensemble approach since a black box model provided by an SVM will have less transparency in terms of the rules used to arrive at the prediction, which is especially unfavourable in medical diagnosis. CAD systems use computed tomography scans for automatic segmentation of various abdominal organs. Automatic segmentation of the pancreas is particularly challenging due to the organ location in the body and large variations in its shape and size. Statistical shape models that are used for other organs do not lead to accurate results for pancreas segmentation. A high accuracy pancreas segmentation method will lead to great improvements in analysing CT scans of diabetes and pancreatic cancer patients. Farag et al. [77] employed random forest classification for labeling of image-patches generated using over-segmentation. CT scan images are decomposed into meaningful regions called superpixels, which are then used to extract 46 patch-level image features for training a random forest classifier. The classification was conducted with 50 trees, such that minimum leaf size is 150. In an extension of the method, a cascade of two random forest classification frameworks were also formed. This method was evaluated using six-fold cross-validation. The evaluation metrics used were Dice similarity coefficient, Jaccard index, volumetric precision and volumetric recall. It was found that the response maps plotted corresponding to the classification and dense labelling show success in pancreas segmentation, with a 70.7% Dice coefficient and 57.9% Jaccard index. The major contribution of the proposed method is a computation time of 6–8 minutes per testing case compared to >10 hours for other methods. However, the superpixel generation process can lead to loss of boundaries that are of lower contrast and cause segmentation leakage. E. Chronic Kidney Disease Chronic kidney disease (CKD) is a global public health problem, affecting approximately 9.1% of the population worldwide resulting in 1.2 million deaths and was the 12th leading cause of death worldwide in 2017 [78]. Subasi et al. [79] did a comparative study of the diagnosis of CKDs using ML algorithms such as ANN, SVM, KNN, decision tree and random forest. Their models were trained using real datasets from the UCI ML Repository. Their dataset had 400 samples collected over a period of 2 months, with 250 positive and 150 negative for CKD. They used the 10-fold cross validation method, in which the dataset is divided into 10 mutually exclusive sets and used 9 of them for training and the last one for testing. This experiment was repeated 10 times. Random forest achieved 100% accuracy followed by decision tree with 99%. The F scores and precision of all the algorithms were compared, with random forest showing the best results. This report suggests that ML algorithms can indeed achieve accuracy levels sufficient for autonomous deployment without the need of human intervention. The paper did lack in considering aspects such as security and implementation in real world along with data collection methods. F. Miscellaneous 1) Chatbot Automated medical chatbots can be used to reduce healthcare charges as well as improve accessibility to medical knowledge and services. Srivastava and Singh [80] proposed a chatbot for providing diagnosis to patients based on their past diagnosis and information obtained over the conversation. While this may be considered immoral and susceptible to inaccuracy as the patient might incorrectly report symptoms, the chatbot is designed to ask the patient for clarification in case of ambiguity. Through the conversational cues about the symptoms, the correct symptoms were identified with a 71% precision and 65% recall. The conversational cues served as a preliminary step to collect information about the symptoms. Then the bot asked subsequent questions and led the conversation in a simple language without the use of medical jargon. It tried to diagnose the possible diseases by converting the provided information to queries and collect the possible solutions for the patient’s condition. Once the disease was identified, the bot estimated the seriousness of the disease and took action accordingly. It either suggested remedies and over-the-counter medication, or connected the patient to a doctor if the measure reached a pre-determined threshold. The bot could not be authorised to give prescriptions at that stage. The algorithm used pattern detection to guide itself through the conversation. For instance, if the patient entered “I am not feeling well” the bot recognised that the user had little or no idea what’s wrong, hence it started with standard responses asking if they were experiencing any pain etc. In the other scenario, if the patient was pregnant, for instance, then they already knew certain facts about their condition, and this is now added to the fact that they may be experiencing pains in their abdomen, which could mean different things, such as a complication, labour, or maybe just an upset stomach. Hence, the algorithm could give a more accurate response in shorter time. Using a permanent user profile, this technology was especially useful in geriatric care. If the elderly were living alone and they were not comfortable with modern technology, a Google Home or Amazon Alexa module acting like a simple conversational partner could remind them the schedule of their medications. It could even help them understand their body while simultaneously updating their medical profile and even alerting their healthcare provider in case of emergencies. This could be a more affordable solution to many households, than a registered live-in nurse. Owing to the critical nature of this application, for the initial testing stages, it is better for the technology to be trained by hospitalised patients, teaching it how to interpret conversational cues and correlate with their hospital records to assess the bot’s prediction accuracy. Out of all algorithms tests for classification, SVM is suitable for complex classification tasks [81], while KNN is faster but unable to handle highly complex tasks. 2) Automation Software Bohra et al. [82] proposed a system for automating health monitoring and prescription to a high extent. Here, software applications were generated for a user to interact with. In the backend, NB classifier was used to analyse the data given by the patient and respond with the respective medical diagnosis and prescription. It includes a Java Swing application which provides graphical user interface for the application to execute and interact with the user. For a healthy patient, the application provided the answer to the queries based on the keywords fed by the user. In case of an unhealthy patient, the patient inputs the symptoms, and the algorithm was implemented to figure out what diseases have the maximum probability of occurring (event A) based on the existing symptoms (event B). The most suitable algorithm for such analysis is Naive Bayes. In case the fitting probabilities were less than average, the case is presented to physicians, who then discussed and consulted the patient and that case was again stored in the database as reference. The application introduced through this facilitates consultation without physically being attended by the doctors. Some biometric techniques could also be integrated with the system in future, like heart beat and blood pressure measurement. Also, the system could be included with video calling feature for interaction between doctors and patients. This system would help patients in getting minor health issues resolved easily. Hence, a software which was initially used for classifying the effect of a medication on an individual, can be used to create a database of its effectiveness. This data could help in future to red flag any such product which may have a negative effect on majority of users. This methodology can be implemented on future recuperative devices that can be used as an channel that consumers can use, to express their feedback. Organizations profit by this regular criticism as this helps them to analyse and address the issue effective immediately. 3) 28 Day Mortality As the medical technology further develops, the number of parameters that provide information about the human physiological condition keep increasing, forming datasets of higher dimensions. This data is then used to develop ML models that diagnose abnormalities by classification. The high dimensional clinical datasets increase the complexity of classification and thereby lead to poor efficiency and performance. Keeping up with technology trends and the advent of edge and fog computing, it is worthwhile to invest in reducing computing load for basic broad classification and decision making. GAs have been used frequently for feature selection and reducing parameters to only the most significant ones. However, over time GAs have been falling short when there is a need to find and maintain multiple local optima. This led to the development of niche GAs (NGA). This algorithm can easily locate local peaks and hence present multiple optimisation solutions, or in this case multiple parameter reduction scenarios. However this method lacks adaptability to unknown datasets, which led to the improved NGAs (INGA) [83]. There are broadly two steps to take when extremely wide datasets need to be interpreted- feature extraction and feature selection. Feature extraction is used to reduce the dimension of data by transforming the original feature space into a new one of lower dimension. DRA such as independent component analysis (ICA), PCA and multidimensional scaling (MDS) are some commonly used algorithms. They work by methods functionally similar to finding a “best fit dimension” that is a 1-D line for a 2-dimensional dataset, and a plane for a 3-dimensional dataset. However, after dimension reduction, ICA, PCA and MDS generate new parameters whose significance is not always interpretive. The second step is feature selection, in which the optimal features are shortlisted such that they retain sufficient information for deriving useful decision models and conclusions. The principle behind NGA is application of the biological concept of a niche to the GA’s evolutionary computation. A distance parameter L is specified before the survival environment is shown. The L of NGA is set in advance, allowing only a single excellent individual solution in this distance from centre which is known as the niche radius. Setting the value of L requires some knowledge of the expected results. In many cases, it would be useful to pursue every trend/probable solution that can solve the problem differently, as medical expertise may not agree with the algorithm’s optimal solution. Hence an adaptive niching method was developed in conjunction to dynamically adjust an NGA algorithm’s radius to fit better with the dataset. The twin-space crowding genetic algorithm (TCGA) and game-theoretic genetic algorithm (GTGA) are often used for feature selection but they are incapable of obtaining the niche distance following evolution. Hence, there is a chance of eliminating the potentially excellent individuals [84], [85]. The INGA algorithm was benchmarked for accuracy on a dataset of sepsis patients to predict the “28-day mortality” where it outperformed any known DRA by yielding an accuracy of 92%. Such a system can yield a weighted solution for associating varying importance to the wide range of medical parameters that can greatly reduce diagnosis time and reduce the compute load on the cloud. SECTION V. Prognosis and Spread Control IoT has been a topic of great interest in the healthcare community over the last few years. Healthcare is an important domain and IoT opens up a wide spectrum of opportunities to make it better. In this section, we discuss how IoT has been used by researchers over the world to develop systems for monitoring, detecting, preventing and controlling the spread of various diseases. IoT is essentially a technology where various sensors are used to gather relevant information which are then analyzed over the Internet. This can be done using a single node or a network of nodes. This concept of gathering real time information makes IoT very relevant to today’s healthcare. Human body is one marvelous system and so are the ailments that arise in it. However as it may seem in any natural system, our body sends out information through innumerable signals which can provide us a host of information regarding it’s status. Thus, this information is of importance to any healthcare provider, as it decides the course of action to be taken to help a patient. IoT helps gather this information. Technologies such as ML helps us extract valuable information from it. The most common way to read health data of a person is through wearable devices and sensors. This could range from a smartwatch to read pulses to implants in specific regions of the body. These devices have access to first-hand information which can then be relayed to the endpoints or databases through the Internet. Indirect methods include the user inputting data using a smartphone [86]. In this section, we look at certain applications of IoT and ML techniques to control the spread of certain diseases, both infectious and non-infectious. Table 3 at the end of this section gives a brief summary of the reviewed publications that pertain to use cases of ML algorithms for prognosis and spread control. TABLE 3 Use Cases of ML Algorithms for Prognosis and Spread Control A. Cardiovascular Disorders Heart disease mortality rate is still increasing even though the technologies in the area have vastly improved in the last few decades. Therefore it is one of the most prevalent causes of death, especially in the elderly. Major factors that have been identified that lead to heart disease include high blood pressure, high cholesterol, smoking, diabetes, etc. An early and accurate prediction of the likelihood of a person developing heart disease can help not only decrease the mortality rate, but also prevents a vast majority of such cases by targeting the right subgroups of the population to bring in lifestyle changes in order to decrease their already higher chances of risk. Yadav et al. [87] developed a system to predict the onset of heart disease in patients in their early stages using the NB algorithm. The system’s easy to use graphical user interface and the requirement of a low number of records for the training of the NB classifier made this system especially useful. The data was obtained from the Cleveland hospital and consisted of 303 patients with their particulars of age, sex, ECG reports, blood pressure, etc. Input data was used in two forms, first to train the model and then test the remaining data to find the system efficacy. Results were obtained in binary form with 1 predicting the presence of heart disease and 2 predicting the absence of heart disease. Though the models showed high efficiency of 85%, further training on larger datasets is required before adopting in real life scenarios. Choi et al. [88] used NLP to obtain patient sentences (ordered sequences of various medical codes) as distributed vectors by using skip-gram method and classification methods such as logistic regression, neural network, SVM and KNN. Using skip-gram embedding, concept and encounter representations are generated from which patient vectors are then derived. These represented the patient’s medical history and are used to predict heart failure. Significant improvement in heart failure prediction was observed by the authors. Not only was the model using ML methods more accurate, but also the time taken to train this model was less as compared to other models. Out of SVM, logistic regression, MLP and KNN, KNN was found to benefit the most from the use of these medical concept vectors. B. Pulmonary Disorders The prevention of a pandemic outbreak requires early diagnosis. Pulmonary infections like the influenza virus have a long history of quickly turning into pandemics, with the most recent worldwide pandemic also being one that affects the respiratory system- the COVID-19 pandemic. Therefore, it is required that there is a system in place to identify and predict the occurrence of such diseases that might cause outbreaks before they actually take effect, since it is easier to control these diseases at an early stage than when they start spreading rapidly. Yin et al. [89] established a stacking model to make predictions on antigenic variants of the H1N1 influenza virus. They approached this by first classifying past cases as pandemic-based and epidemic-based. Entropy was calculated to find out the variation in strain mutation in different periods. Three different feature engineering methods, viz. residue-based method, ten regional band-based method, and five epitope region-based method were used to validate if the model was universally adhering. The stacking model used is conceptually similar to k-fold cross-validation and provides out-of-sample predictions for small and medium data-sets. Using neural networks, level 2 models were designed to get better results than a single level model. Rapid antigenic shifts can cause variants to occur, which make it tough to understand the effects of specific mutations on antigenicity. This model could be improved upon by taking into account more of crucial factors like climate and the human immune system. Prediction of cases of Acute Upper Respiratory Tract Infections (URTI) during its early stages is crucial to minimizing its adverse effects on infants and preventing fatality. In order to predict URTI cases, Ginantra et al. [21] collected URTI data from community health clinics in Indonesia and used KNN classifiers for prediction. The features used to classify comprise of various symptoms of the disease such as fever, headache and flu. Results obtained using a confusion matrix showed 97.4% sensitivity, 90% specificity, and 94.7% accuracy for the KNN classifier. López Pineda et al. [90] showed a promising application of NLP for the detection of influenza. Collection of data was done through free-text emergency department (ED) medical reports from 4 hospitals. The data comprised of: 468 reports on polymerise chain reaction (PCR) positive influenza patients in the period from January, 2010 to August, 2010; and 29,004 reports of patients NOT associated with a positive PCR test in the period July 1, 2010, to August 31, 2010. Topaz was used as the NLP parser to classify the data between non-acute, acute, and missing. The authors drew a comparison between the prediction capabilities of 7 different ML classifiers and an expert-built Bayesian classifier. Performance was evaluated using three different configurations with the aim to correctly deal with missing data. The performance of the NLP-finding-extraction system was measured using accuracy, recall, and precision scores. NB, logistic regression, SVM, and ANN algorithms all showed almost equally competent performance. The NB classifier was superior (BSS: 0.35, Area Under Curve (AUC): 0.93) due to having a lesser training time and not requiring pre-processing to treat missing values. It was concluded by the authors that ML classifiers showed performance superior to expert Bayesian classifiers for the given use case. C. Neurological Disorders Epilepsy is a fairly common neurological disorder that affects people of all ages across the globe. EEG is one of the most simplistic tools used to diagnose the disorder. EEG helps the doctors analyze the electrical activity of the brain, and any disruptions in this activity could be due to epilepsy. EEG reports are visually inspected by a diagnostician. However, visual inspection has certain limitations and can have a huge error margin, subjective to the competence of the doctor. Deployment of ML algorithms for classifying the risk levels of epilepsy from EEG data is a promising way out from the limitations of visual inspection. Performance of KNN classifiers in classifying the epilepsy risk levels were analyzed in detail by Manjusha and Harikumar [91]. Here, KNN stores all the sample datasets and new cases can be classified by measuring their similarity with the old cases. Authors of this work applied this algorithm to the power spectral density values with reduced dimensions for better outputs. Manjusha and Harikumar [91] used different parameters to calculate the efficiency of the KNN algorithm. KNN was evaluated on parameters such as classification perfection (83%), performance index (78%), sensitivity (90%), and specificity (93%). As researched by Birjandtalab et al. [92], KNN is very helpful in studying the nonlinear data, giving it an advantage over several other classification algorithms. However, KNN fails to solve the false alarm situation, KNN reports false alarms approximately 10% of the times. Thus, this statistics will have to be taken into account while deploying this algorithm. The high number of false alarm cases encountered in the use of KNN classifiers are undesirable, which is why an alternative to KNN for this application is necessary. Manjusha and Harikumar [91] discussed the use of k-means clustering algorithm as a classifier. k-means is a commonly used partitional clustering technique. Using this algorithm, different clusters of datasets can be created based on certain parameters, such that a given cluster has datasets with maximum similarity and different clusters will have minimum similarity. Authors analyzed the performance of k-means clustering algorithm on the same parameters as KNN [91]. k-means performed really well on the false alarm parameter, generating 0% false alarms, and 100% sensitivity. It’s correct classification percentage was close to 94. This shows k-means is a better algorithm than KNN for epilepsy risk level classification from EEG data. However, k-means fails to provide similar outputs when dimensions of input increase. It must be applied on dimensionally reduced data, which can be achieved by different dimension reducing methods. Another AI based framework used for classification based on EEG data is given by Amin et al. [59]. They proposed a cognitive healthcare framework that classifies a patient’s EEG signals as pathologic or normal and outlines the next steps to be taken. In the proposed model, various sensors are embedded in a patient’s vicinity to read body temperature, heartbeat, blood pressure, voice, facial expressions, body movement, and EEG. This data is sent to the cloud system through a WAN. Now, in the cloud, a cognitive engine is said to be working. It is to be noted that this engine was not implemented by the authors, nor its specifications given. It is said to have a backbone of AI and deep learning algorithms. Looking at the data, the engine decides whether to send the data for more analysis. If so, the data is sent to a classifier model (in the cloud system). CNN models VGG 16 and AlexNet are used for detection and classification. The results are sent back to the cognitive engine which then takes further steps if the patient’s signals are pathological. The patient as well as concerned healthcare professionals get an alert and also suggestions. As is seen in the work by Devi et al. [93], the use case of a cognitive system or engine was proposed, but it has not been implemented. This is because much has to be done to bring such a fool-proof system into existence. This remains one of the greatest challenges for implementing cognitive healthcare frameworks. The use of pre-ictal EEG data for the prediction and suppression of seizures in patients was demonstrated in [95]. A brain computer interface (BCI) developed in a cloud computing framework predicts seizure onset using CNN and then the required neurostimulatory signal is given to suppress the seizure. The combined use of cloud computing, proper preprocessing of data, and CNN results in the model outperforming other EEG prediction systems, displaying an accuracy of 96% and precision and sensitivity of 97% each. This system, although very accurate, is constrained by the requirement of large data storage and high computing capabilities. Another important and upcoming area of neurological application of AI is for Parkinson’s disease which is a progressive and chronic movement disorder. It can result in poor movement, balance, stiffness in arms and legs, trembling and speech disorder. Sixty thousand Parkinson’s cases are diagnosed in the US every year, while the number touches a million in India. No known cure is available, but early identification can help in patient management. Parkinson’s is a topic of active research with firms and researchers involved in drug development as well as monitoring systems [96]. Recently IBM along with Pfizer Inc. developed a new way to measure intensity of Parkinson’s by IoT based remote patient monitoring solutions [97]. Panda and Panda [98] addressed the issue of better classification of Parkinson’s using nodes. The data used is voice recordings from digital home virtual assistant devices. It is accumulated in a dataset called Lee Silverman Voice Therapy (LSVT) voice data. Feature extraction of the raw data was done using PCA. Post that, recorded features were fed to the three classifiers: NB, random forest and decision tree. In terms of speed of execution, NB was the fastest while in terms of performance, random forest gave best results. D. Physical Injuries Over 10% of the world’s deaths result from trauma caused by physical injuries [99]. When a physical injury causes too much blood loss, the oxygen supply to the body’s organs is not able to satisfy its demand. The body is said to be in hemorrhagic shock (HS) in such a situation. The severity of a hemorrhagic shock determines how urgently its treatment needs to be performed. In such a scenario, accurate prediction of hemorrhagic shock severity and the patient’s recovery from it is imperative to prioritize severe cases, so as to minimize the mortality rate. Lucas et al. [100] used logistic regression to model a prediction system that can predict whether a patient will recover from hemorrhagic shock after resuscitation, using rats as test subjects. The rats were classified into two groups based on whether they recovered from the HS or not. After extracting all features and discarding the irrelevant ones, a total of 69 features were used to form a feature vector using which three different classifiers were trained and tested. The scikit-learn python library was used for applying logistic regression. The performance of this logistic regression model was measured in [100] using three different metrics: mean cross-validation accuracy (using 10-fold validation), Younden’s J statistic, and Cohen’s kappa coefficient. The classifier with the reduced feature set, namely the final classifier, showed an accuracy of 0.833+−0.114 , with a Cohen’s kappa value of 0.617. The J value for the final classifier was 0.76. This classifier’s results outperformed a baseline classifier that represented currently used methodologies of using heart rate and mean arterial pressure, even when multiple experimental protocols were used. Although the proposed method in [100] shows promise, the size of the test dataset was small due to which it is difficult to say that it will show good results for all scenarios and cases. Among the various physical injuries people are vulnerable to, a deadly but preventable class that particularly stands out is injury caused by falls. Falls are much more frequent in the elderly and are especially dangerous to their relatively fragile anatomies. Fall risk is normally assessed through testaments of the subject or physical examinations. These are unreliable and incomplete. Non-linear SVM (NLSVM) along with some other algorithms were used for patient-specific fall prediction [43] and detection system [94]. Continuous observation and documentation, with prompt decision making set up is critical for fall prone patients as similar systems have been introduced for heart patients [101]. Saadeh et al. [94] proposed a system that senses the movements through a triaxial accelerometer sampling at 256 samples/s attached to the thigh. The acquired acceleration along three orthogonal axes is then sent via low energy Bluetooth interface to an FPGA. The acceleration is used to extract features. The offline NLSVM learner uses fall information of a patient to give personalized parameters that are uploaded to the processor. Figure 5 shows a visual representation of the architecture of the proposed system. The NLSVM classifier then processes the feature vector during runtime to decide whether it is a pre-fall case or not. To prevent false positives, three consecutive decisions are needed before the alarm is set off. The study was conducted with 20 subjects aged over 65, with over 100 instances of activities of daily living and falls. When validated using the Mobifall dataset, the model achieved a 97.8% sensitivity and 99.1% specificity, outperforming models using linear SVM, decision tree and KNN classifiers. FIGURE 5. Fall Detection System [94]. Show All E. Spread Control The current scenario of the world facing the uncontrollable spread of the coronavirus pandemic and its drastic repercussions has led to people realising the scale of the impact that such contagious diseases can have. Therefore a lot of research attention has been directed toward controlling the spread of such contagious diseases. Such pandemics cause not only a surge in patient numbers worldwide, but also lead to disruption of economies on a huge scale and drastically affect the quality of life due to their isolation requirements. State-of-the-art ML based models can prove extremely effective in predicting the consequent spread of a contagion and can thereby lead to accurate and early decision-making in response to it [102]. Lopez-Rincon et al. [103] proposed identification of SARS-CoV-2 using state of the art deep CNNs by automatic creation of features from genome sequencing. Genome sequence data from the 2019 repository novel coronavirus resource and NCBI repository was divided into two groups of 9:1 for training and testing. A 10-fold cross-validation scheme was used on this sample data. The experiments showed that the above approach successfully classifies SARS-CoV-2 and distinguishes it from other viruses of the coronavirus family. The identification itself proved to be 98% accurate while classification into different coronaviruses shows an accuracy of 98.75%, although the training of the model was conducted on a limited data-set and limited genome sequences were considered. Ebola is another extremely contagious disease that spreads rapidly. Since 2014, various parts of the world have experienced deadly outbreaks of this infection. Dominican Republic is still battling with the virus. Since it is infectious and can be spread from human to human, early detection and monitoring of infected patients is an important step in controlling the spread. Sareen et al. [104] proposed an IoT based cloud framework to control the spread of the virus. A system based on RFID (Radio Frequency Identification Device), wearable sensors, and cloud computing was given. Under the model, each patient is first registered using a mobile phone and thus gets a unique identification for future references. Data from body sensors is collected using the mobile phone through bluetooth. This data is sent to the cloud environment for analysis. It is classified using a decision tree approach, which classifies the user among six categories (determined using the state of the symptoms). Next, the user is classified using RFID and wireless body area network (WBAN). RFID detects close proximity interactions (CPI) between the patient and other people. If an uninfected person comes under CPI, an alert message is sent to him/her through mobile phone. In this identification, a proposed temporal network analysis was done using parameters such as clustering coefficient, centrality, and temporal path length. Based on the experiments conducted, the authors got a classification accuracy of 94% for synthetic data of 2 million patients. Further, other models of classification were tested. Random tree and NB gave accuracy of 50% and 53%, respectively. In an interesting work, Sato et al. [105] built an epidemic spread model using IoT technologies to monitor human mobility and contact data. They introduced the agent-based infections diffusion simulation using real human mobility data as a metapopulation network. Such simulations were found to be very important in controlling the spread of outbreaks such as Ebola. Adding to these methods, Chen et al. [106] sought out to develop a model to track dynamic changes in a network. This network could be an epidemic spread network. They proposed using mobile phone data to build their model. Synthetic data was used for classification. This is because deploying WBANs in areas affected is a big challenge. Also, for this to work, people should have RFID reader enabled mobile phones. Adding to that, patients are often not ready to carry a RFID tag. These are some challenges to be looked at. Righetto et al. [107] used rainfall as a variable to develop a prediction model for the spread of cholera in Haiti. The rainfall pattern acts as a marked Poisson process and the continuous rainfall events are processed as discrete events such that the mark represents the depth of the rainfall. The prediction of the spread of the disease is then done using k-means clustering. This model was limited in its accuracy to predict the evolution of new cases. The real-time improvements in the present situation were also not taken into account. Malaria is one of the challenging diseases in several parts of China, especially in Henan province. Wang et al. [108] conducted a study to evaluate the relationship between the diagnosis and complications emerging in patients with malaria disease. ML model based on decision tree was integrated for defining factors, frequencies, and nodes in the correlation among the healthcare institutions and malaria cases. The decision tree methodology was highly successful in building tree models with accuracy of 82.2% and 74.1% for the purpose of initial diagnosis and complications. This study will help to bridge the gap for decreasing future cases. The study further proposed a more simplified online system in combination with WeChat for evaluating malaria to keep a strict awareness about the different factors. Data were obtained from CDC, Zhengzhou City, the capital of Henan province, for conducting a study on malaria patients, starting from the year 2012 to 2017. All the decision tree methods were evaluated for studying the relation with classification and regression tree (CRT), chi-squared automatic interaction detection (CHAID), and statistical package for social sciences (SPSS) so as to increase model precision. Wang et al. [108] found that the malaria patient population studied was predominantly male (366 patients out of 371 total patients were male). The average age of patient came out to be 37 years, ranging from 17 to 67 years. There was no life lost in the study. P. falciaprum, with 319 cases, was the highest while fewer cases for Plasmodium malariae, Plasmodium ovale, and P. Vivax at 5, 13, and 34, respectively, were observed. However, this study was conducted on a very small dataset and requires more repeated trails, improvement, and assessment from the professional experts. Major factors that emerged from complications of imported malaria cases include less number of patients seeking medical advice and insufficient capacity in diagnosing malaria from the health institutions, mainly by the lower medical professionals. In another work by Kassé et al. [109], SVM classification was used for better prediction and control of a parasitic disease called Schistosomiasis or Bilharzia. It is said to affect more than 200 million people spread over 7 countries. A data collection module Wapsmote was used to collect data from various sensors (pH, temperature, radiation), which was then sent to a cloud database using GSM/3G/GP RS mobile network and an Ethernet network. Based on these inputs, an event detection algorithm using SVM was designed to assess transmission contamination risk. ILI or acute respiratory infections are among the main factors for mortality around the world. Common symptoms include fever above 38 °C, pharyngitis or cough, and these tend to get amplified during winters. As per the World Health Organization (WHO) estimate, there is a 5 to 10% increase in adult influenza-based cases and 20 to 30% increase in influenza-based cases globally in children every year. Studying the pattern of these outbreaks can help governments to minimize the impact of these diseases and implement preventive measures against them. Miller et al. [110] proposed methods to generate accurate forecast data for influenza outbreaks using smart thermometers. These were connected to a mobile application which can aggregate and store this data onto a cloud based platform for analysis. The data also included location of users using the GPS of their mobile phones. The authors tried to see the correlation between thermometer collected data and readings reported by the CDC. They developed a model for forecasting ILI activity up to three weeks in advance. Also, they analyzed the data to track fever duration and identify biphasic patterns. Further, they researched transmission of febrile illness in family members of users. To get the forecasts, they used a 52 week sliding training period and then evaluated predictions for next week. This was done iteratively to generate 68 such forecasts. The predictions were made using an autoregressive moving average of 52 weeks. This was done for two cases: the CDC data and the CDC data along with thermometer measurements. Then, these were compared to the lagged CDC data to get correlation of forecasted data with real data, forecast error, and forecast correlation using different time periods (1 week, 2 week lags). To analyze forecasting performance, a generalized linear model was used along with autoregressive components. It was found that thermometer readings were highly correlated with national ILI activity. Also, using thermometer readings, forecasts were improved in real time and upto 3 weeks in advance. Tapak et al. [111] investigated different ML methods of ANNs, SVM, and random forest series using root mean square errors (RMSE), intra-class correlation coefficient (ICC), and mean absolute errors (MAE) techniques for building models for influenza based outbreaks. Data for this study was taken from the FluNet tool developed by the World Health Organization for all the cases of influenza-related illness in Iran from the duration of January 2010 onward to February 2018. The study used 73483 influenza cases who had a fever of more than 38 ∘ C accompanied by cough. Models were built using multiple ML algorithms of ANN, SVM, and random forest time series to find values, insights, frequencies, and residuals. Tapak et al. [111] performed evaluation using RMSE, ICC, and MAE techniques on illness frequencies. Random forest test obtained the best result from all other techniques with RMSE = 22.78, MAE = 14.99 and ICC = 0.88 for the tests set. Positive results show that random forest technique of ML can be used for building models for predicting outbreaks and illness frequencies from influenza. However, the study is limited for not including factors of climatic parameters and weather conditions. Sentinel data from ILI is another limitation of this study. Thus, this information must be carefully evaluated before implementing this algorithm for predicting the outbreaks of ILI. SECTION VI. Assistive Systems Assistive systems are systems that act as rehabilitative frameworks or provide support in daily life for people with disabilities. These form an important class of applications for ML based IoT frameworks since a lot of these systems rely on accurate judgement of whether and to what extent the disabled person is able to perform a task. This could be anything from limb movement [112] (for which assistive systems may provide physical rehabilitation) to being able to hear properly (like cochlear implants). This section aims to discuss a few of the important applications in EEG and surface electromyography (sEMG) signal based assistive systems that require ML for the processing of these signals. Table 4 at the end of this section gives a brief summary of the reviewed publications that pertain to use cases of ML algorithms for assistive systems. TABLE 4 Use Cases of ML Algorithms for Assistive Systems A. EEG Based One of the most important applications of BCI devices is to help physically disabled patients transcend the limits of their disabilities and live a normal life [114]. This is achieved by providing them with BCI devices that they can control with their natural impulse so that no physical movement of their body parts is required to perform an action. Such implementation is made possible by using EEG signals from brain neurons as control for the systems. The recent advances being made in BCI technology form the foundation stone for next generation prosthetic implants. Such prosthetic implants and other BCI assistive systems can prove life-changing for persons with disabilities. Poorna et al. [115] looked into an application of analysis of EEG signals where it was used to gather ocular information (eye blinking) and classify it in such a way that it can be used for a control application. Control applications could be anything ranging from home automation to navigation. Such applications help people to overcome the barriers due to physical shortcomings to interact with the environment. In the said work, the emotive EPOC headset was used to obtain EEG signals corresponding to the closure of the eyes. The data gathered from EEG electrodes was in the form of small voltage (micro) signals. Thus, it was embedded with a lot of noise. To remove the same, pre-processing was done using PCA. For feature extraction, the spectral and cepstral features of the blinks were considered, giving a total of six parameters. For classification, three methods were used: quadratic discriminant analysis, ANN, and multi class SVM. Results stated that for combined feature classification, quadratic discriminant analysis gave the best accuracy of 81%. Zhang et al. [116] proposed the use of BCI integrated with a unified deep learning framework for various applications like making typing systems from EEG signal patterns and controlling robots for domestic assistance. Such systems are of paramount importance to speech and/or visually impaired people. The authors used RML for the classification of various EEG signal patterns. Using selective attention mechanism and long short-term memory, they aimed to make the system adaptive to the person using it. The framework was compared with state-of-the-art BCI frameworks and was seen to outperform them with an accuracy of 93.63%. ANNs such as multi-layer perception are one of the most popular classes of classifiers used in BCI. Poorna et al. [113] presented a comparison of various classifiers used in BCI. It has been concluded that ANN classifiers give superior classification accuracy as compared to other classifiers like KNN. While the KNN classified studies gave 96.06% accuracy [113], ANN gave 98.58% accuracy and also surpassed KNN in terms of sensitivity and specificity (94% and 98.89%, respectively, as compared to 87.42% and 97.61%, respectively, for KNN). Figure 6 shows the headset and electrode positions that were used in the literature. While the results presented [113] show ANN’s superiority, it must be noted that the different classifier performances were not studied under the same context. Therefore, the comparisons drawn are not objective and cannot be completely relied upon. FIGURE 6. (a) Emotiv Epoc headset used by Poorna et al. [113] (b) Electrode positions of Emotiv Epoc. Show All Classifying signals based on various EEG sensors is being actively researched. However using them for aiding patients with physical limitations is an open challenge in the field. B. SEMG Based An alternate to BCI by EEG sensors are surface sEMG signals, which are composed of electromyography and neural electrical signal on the skin surface of a shallow muscle. It can be detected from the sensors and can be linked to actuators to complete the action the patient is intending to carry out. Peng et al. [117] discussed gait phase detection to achieve normal movement of lower limb auxiliary robots using a kernel LDA based nonlinear fusion model. The complex stance and swing motion of lower limbs with realistic variations is a challenging model. After feature extraction and selection is done, LDA is used in gait phase recognition as it is efficient and robust against over-fitting. Similar to Novak et al. [119] who used a linear ensemble learning model, Peng et al. [117] also used a combination of learning techniques for optimal performance. In recent years, usage of softmax regression in neural networks with nonlinear fusion is preferred for multi-classification problems. Here, simple voting fusion and weighted fusion were compared with the non-linear fusion method of their novel approach which gave the best and final results. An accuracy of 92.5% in walking while performing cognitive tasks was achieved. As a real time application, an important performance metric is computational complexity. Their algorithms takes 90 ms which is fit for the application. Chen et al. [120] also discussed development of bionic legs and walking assist boots. Yang et al. [118] designed a smart wearable armband which uses sensors to record sEMG signals for hand gesture identification, and to transmit the information to a robotic arm for it to mimic these movements and help in stroke rehabilitation. The processing and classification of the data collected by these sensors is done using PCA. Six different sEMG features were employed for the classification process. This system achieves an accuracy of 96% in identifying the correct hand gesture made by the user. SECTION VII. Monitoring Continuous monitoring of a person’s health is gaining a lot of recognition since it can not only drastically reduce the mortality resulting from sudden emergencies, but also promote awareness about one’s own health and hence lead to a healthier lifestyle. This section aims to cover some major advances that are being researched about in this domain and that use ML as their backbone. Table 5 at the end of this section gives a brief summary of the reviewed publications that pertain to use cases of ML algorithms for monitoring applications. TABLE 5 Use Cases of ML Algorithms for Monitoring A. Cardiovascular Disorders A person’s blood pressure (BP) is a direct indicator of how healthy their heart is, and high BP (also known as hypertension) can lead to various heart diseases, as well as stroke, dementia, and a number of other serious complications. Hypertension patients are required to regularly monitor their blood pressure so that these complications can be minimized. Most blood pressure measurement devices today are not portable and use cuffs which can be inconvenient to use. Therefore, an accurate and portable continuous blood pressure monitoring system can prove to be extremely useful. Tabei et al. [121] presented a cuff-less approach to continuous BP measurement by using smartphone cameras to record photoplethysmogram (PPG) signals from a person’s fingertips and converting them to BP values using a simplified linear relationship. The parameters in this relationship are specific to the person whose BP is being calculated and are found using linear regression. The linear regression model is trained using LOOCV method. The trained model is tested, and the evaluated BP is compared to BP measured with an oscillometric blood pressure monitor. Tabei et al. [121] measured both the diastolic blood pressure (DBP) and the systolic blood pressure (SBP), the scatter plots, and correlations. Regression lines were drawn between the estimated and actual values for both of them which showed that there is a positive linear relationship between them. The MAE and standard deviation (SD) found for DBP were 2.98 and 2.49 mm of Hg, respectively, while those for SBP were 3.28 and 2.46 mm of Hg, respectively. These values lie below the universal standard [122] of MAE of 5 mm of Hg and SD of 8 mm of Hg, making the proposed method a practically usable approach. Ganesan and Sivakumar [123] proposed to gather real time information about patients using wearable IoT devices. This includes blood pressure, blood sugar, and ECG. To train the model, UCI database was used which includes the past logs of the medical data gathered from medical institutions. Post training, the model is tested for incoming data of patients. Classifiers used were J48, logistic regression, MLP and SVM. J48 gave better accuracy than logistic regression, though logistic regression performed better than MLP. An open issue in the area is building a model to train on various kinds of data. This is because patient status is obtained in various forms such as images, test records, graphs, etc. For the system to work properly, the model needs to identify the type of input, classify it, and normalize it with all available formats of input. Kakria et al. [124] developed a monitoring system, such as the one used in the above case. The data was collected using wearable sensors and smartphones. It was then made available to medical personnel through a dedicated interface. B. Neurological Disorders A stroke occurs when blood flow to a part of the brain stops. This deprives the brain of oxygen and essential nutrients leading to the death of brain cells. It may lead to paralysis, weakness, trouble in speaking or seeing, and even death. It’s no surprise that stroke comes in the top five causes of death worldwide. However, stroke is preventable if the risk factors are noted and acted upon in due time. Also, the monitoring of stroke patients can reduce the chances of it happening again. In an effort to provide a diagnostic prediction for stroke by patient monitoring, Ani et al. [125] used IoT and ML techniques. Wearable devices were used to check blood pressure and pulse rate of the patient. Additionally, a sugar sensor (to be operated by the patient) was used to take input of sugar level. The collected data was sent to a cloud storage to be stored and analyzed. The collected data was made available to caretakers and doctors through a web interface. Classification algorithms were used to generate prediction of risk factor of the patient. NB and random forest classifiers were used which had records of 191 patients with both positives and negatives along with attributes such as gender, age, blood pressure, sugar levels and heart rate. Random forest used multiple decision trees for the prediction. It divided the dataset into multiple subsets and each of them leads to a particular decision tree (classifier). Then, these were combined to give a single outcome. For the used dataset, random forest gave an accuracy of 93% while Bayes gave 90%. The challenges that lie ahead are designing better IoT based systems to gather critical parameters of a patient without the need for the patient to input the data himself/herself. Combining cognitive technology and IoT can significantly improve the healthcare system for remote monitoring. Al-hussein et al. [43] conducted a study for monitoring and diagnosing epileptic seizures using deep learning methods under the cognitive IoT healthcare framework. Cognitive healthcare-IoT (CHIoT) is the latest technology that offers a more collective approach for use in the healthcare industry. CHIoT empowers system for combining physiological and psychological applications for dealing with medical emergencies and quick response. A healthcare framework was proposed which uses wearable sensors to obtain signals, (primarily scalp EEG) and a cognitive engine based on deep CNN for extracting features followed by stacked autoencoder. The system does preliminary monitoring at the edge itself by monitoring the patient’s gestures, movements, facial expressions and EEG signals to determine the state and in case of possible seizures, sends the data to the cloud. In the cloud, the data is first converted into a 2D matrix with time as the horizontal parameter and electrode as vertical. Next, this 2D representation is passed to the deep CNN to simplify it, that is, represent it in lower dimensions. Traditional dimension reduction algorithms might not have proved effective as the EEG signals for seizure vary for different people. This model had 7 layers with convolution and max pooling blocks with a softmax output. The activation function was a combination of exponential linear units. This was followed by stacked autoencoder with 2 autoencoder layers and a softmax output. It had 1000 neurons in the input layer, 500 in next autoencoder layer, 200 in the next and finally a fully connected softmax with 2 classes. Training was done on CHB-MIT dataset which was collected at Children’s Hospital Boston having 686 multiple channel scalp EEG recordings collected from 23 patients. It had 198 positives with the seizure lasting about 25s in most of them. This model gave 99.5% overall accuracy and 93% average sensitivity which is better than most of the other models based on the same dataset. This inference was finally passed to professionals to decide what service to provide. Hadi et al. [126] proposed an interdisciplinary approach to achieve remote patient monitoring. In severe cases of seizures and strokes, timely action is crucial. Not all patients are fall-risk patients and need the convenience of travelling. The paper proposed use of both big data analytics for predicting strokes and ML algorithms for making the network robust and optimised. The network also served the dual purpose of locating patients in emergency situations too. The predictive algorithm utilised an ensemble of classifiers that take input from real time readings of vitals from body attached or nearby IoT sensors, as most implementations do, for better performance. It used decision tree, logistic regression, NB classifier in an ensemble system where a soft voting (SV) classifier resides. The ensemble system yielded up to 93% accuracy, a false positive rate of 2.8%, and a false negative rate of 11%. NB has been commonly used in disease risk prediction [127]. It incurs low computational complexity and does not require large datasets. Ballon [128] proposed a solution for patients with Parkinson’s disease. 3D sensors were used to measure movement and analyse reduced flexibility as the disease progressed. Mia et al. [129] used a NB classifier to predict coronary problems. The same classifier was utilized by many in Miranda et al. [127]. Its accuracy was validated to be more than 80%. C. Diabetes Apart from being able to analyze the raw clinical data, IoT can help doctors in monitoring the physical activities of patients using methods such as RML systems. For example, diabetes patients are required to live a lifestyle that promotes engagement in physical activities on a daily basis. With the help of patient monitoring systems, doctors can help patients increase the level of their physical activities. Importance of physical activities is often stressed upon by the doctors to their diabetic patients, but patients often fail to reform their lifestyle. RML systems hand doctors a method to promote healthy lifestyles to their patients. RML algorithms are able to observe the results of their actions and enhance their learning. Thus, these algorithms yield excellent results where data varies a lot. A mobile app that can run in the background of a patient’s phone was designed based on these algorithms [130]. RL algorithms were able to observe the daily physical activity of a patient and send them a SMS that would help increase the physical activity of the patient in the coming day [130]. Results of the RL algorithm based mobile app were studied [130] using a test group of patients and comparing the developments with a control group. Patients reported an increase in their physical activity after installing the mobile application. Moreover, variance analysis between initial performance and later performance of the app was statistically significant (Analysis of variance, P = 0.04), indicating that the app was continuously learning. Average HbA1c level of the patients was also improved by 0.28%. However, it should be noted that these methods lacks the level of accuracy that more dedicated systems have. Real time information of glucose levels in the blood is also of great importance to patients suffering from diabetes. Insulin therapy requires dynamic data of glucose levels. Traditional glucose level monitors require blood samples frequently in a day, which reduces patient comfort and compliance. ANN based models can help achieve the goal of predicting the future glucose levels of a patient. ANNs are particularly useful when working on data that is not linear and does not follow a set pattern. A predictor based on ANNs takes input from a continuous glucose monitor (CGM) and predicts the future glucose levels in the body. Pérez-Gandía et al. [131] discussed a predictor that takes the input from a CGM for the preceding 20 min and returns a predicted glucose level at a selected time in future. Pérez-Gandía et al. [131] evaluated the accuracy of the ANN model for calculating the RMSE and delay in prediction. Average RMSE was of around 14 min for different prediction horizon time, while the average prediction delay was close to 9 min. Since these models use the past CGM data, inaccuracies were observed whenever there is a sudden data change. D. Physical Injuries A smart healthcare-IoT architecture involves the development of mechanisms that can identify a user’s daily activities for a more personalized treatment. ML algorithms can lead to great advancements in recognizing user activity [133]. Negra et al. [134] proposed one such activity recognition system. This system works by calculating the quality of links between different nodes deployed around the user. The channel link quality is estimated by calculating the path loss between nodes to form the dataset, which is operated on by ML classifiers. The transmitting and receiving nodes may be on or off the person. The analysis concludes that the random forest classifier performs best for this application, proving to be the most accurate. As mentioned before, falls are a major area of concern among senior citizens. It has been found that over a third of people who are aged 65 and above fall, and most of these are recurrent cases [135]. This takes a huge toll on the elderly’s quality of life, and increases morbidity and mortality. Castaldo et al. [135] aimed to target a specific subgroup of patients, viz. hypertensive old citizens, to develop a fall prediction model based on heart rate variability (HRV) data using five different ML models, among which the NB algorithm is seen to work best. To avoid over-fitting, HRV features used in the models were shortlisted such that only relevant non-redundant features were included. A different dataset than the one used for minimizing features was used to train the models using 3-fold cross validation repeated 10 times and averaging the 10 estimates. A third dataset was used to test the trained models on the parameters of accuracy, specificity, sensitivity, and area under ROC curve (AUC-ROC). The model with the highest AUC-ROC has been selected as the best model. Out of the five models tested, multinomial NB outperformed all the other models with AUC value 70± 7.8, while NB stood second with AUC equal to 68± 7.5. While the other models showed acceptable specificity and accuracy, their sensitivity was low and therefore multinomial NB was concluded to be the best model for assessing the risk of first-time fallers in elderly hypertensive patients. Although the study resulted in showcasing that NB outperforms other algorithms when it comes to predicting first time fallers, the focus of the said study was only on hypertensive patients which may reduce its applicability in practical scenarios where not all old citizens are hypertensive. E. Miscellaneous 1) Emotion Recognition Emotions are a valid indicator of possible discomforts and state of the body and mind. Sentiment analysis through twitter and reddit posts is a common application of NLP. Some other methods for detection are to monitor facial expressions or speech for stress points. Tariq et al. [132] proposed a system for emotion recognition through speech analysis for old people in nursing homes using IoT and deep learning. The chosen emotions were: calm, happy, sad, angry, fearful, surprised and disgust. Figure 8 shows the architecture of the proposed system. The designed system consisted of a Raspberry pi 3 as edge device and MAX9814 electret microphone for audio capture. This specific model of microphone was chosen as it does not need additional components for amplification. The audio is sampled and stored on the Raspberry Pi from where it is transmitted to the server for classification. New audio recording are overwritten over older recordings due to memory constrains and at the server level the clip is trimmed into 3-second clips with data overlapping. Then data processing is done. The audio is first normalised, i.e., the volume is set to an optimal value by multiplying the sampled data points with an amplification factor. For the training set, the data was augmented by adding the same dataset with different amounts of time stretching or pitch shifting, or even dynamic range compression. Artificially creating a bigger training set for the classification model helps in boosting the accuracy of the model. The 80-20% rule was followed for splitting between training and testing data. A 2D CNN model was designed for the final classification that is speech emotion detection (SED). The first layer of the CNN starts off with 24 filters with a 5×5 shape, analysing the spectrogram data (in a 128×128 shape) output by a librosa library function. The size of the image is slowly waned down to a smaller size using pooling and strides. After a 65 node hidden layer, the final layer yields 10 results, that are the ten different emotions present in the database training and test set. After augmentation, an accuracy of 95% for females and 93% for men was reported. FIGURE 7. sEMG sensor. Show All FIGURE 8. Speech emotion detection system [132]. Show All 2) Cognitive Monitoring Systems The multimodal nature of smart patient-centric healthcare frameworks demands complex decision-making which has led many researchers to introduce cognitive behavior in the development of IoT frameworks [43]. The smart healthcare concept becomes even more relevant with the development of smart cities. The resources of a smart city can never be fully exploited without intelligent, i.e., cognitive machinery [137]. Therefore, notable research efforts are now being made in this direction [61]. Medical resources concentrated in big hospitals and medical institutions in urban areas can be utilized effectively if shared remotely with rural areas. Existing tele-medicine services, even the most efficient ones, fall short on this goal. While physiological diseases can be addressed by them to a good extent, psychological diseases lie way out of their scope. Implementing this distribution of medical resources across space and time to maximize their salvage value, is a challenge. Muhammad et al. [61] proposed the model for a 5G cognitive healthcare system which consists of two parts: a resource cognitive engine and a data cognitive engine with the network architecture tailored to enhance transfer speed on different communication modes. This opens new possibilities both in the physiological and psychological domains. The ability to recognize haptic movements (5G tactile internet) makes efficient transfer of a human’s actions over 5G wireless networks possible, in turn enabling remote surgery (physiological). Another application is the emotional state evaluation of patients with insomnia, depression, autism, etc. through data collected and metrics evaluated in real time (psychological). Muhammad et al. [61] used a test-bed which was a speech emotion recognition system with behavior feedback from EPIC-robot. Amin et al. [59] presented a similar cognitive engine that has been used in conjunction with a CNN to make binary classifications on pathology through processing of EEG signals. The cognitive engine was used to make intelligent decisions on the patient’s state before passing the EEG input to more involved processing on the CNN and after that, again to assess the patient’s state and notify the appropriate stakeholders. 3) Infant Health Monitoring Monitoring systems facilitating sensor fusion through IoT technologies and data processing algorithms are some of the most critical applications for healthcare and new use cases are constantly being proposed. One such case is for monitoring the condition of infants which is otherwise a challenge since their bodies are sensitive and developing. Mahmud et al. [136] proposed a framework for monitoring of preterm infants for prediction of bradycardia which refers to an abnormally slow heart rate that may lead to the heart not pumping sufficient oxygen-rich blood to the body. Monitoring and detection of instances of bradycardia in the newborn intensive care unit (NICU) is a good use case for well-being of these infants. Before this system, nurses had to maintain the progress reports themselves which is prone to errors and constrains. The proposed solution uses a multi GPU gradient extreme boosting algorithm on ECG signals. Infants that are born within a duration of 37 weeks are considered premature and they occur at a 10% rate worldwide [138]. For the proposed solution, a positive case of bradycardia was considered when the heart rate was less than 100 bps for more than 1.5 s. The used dataset had 633 bradycardia events which were divided in a 70:30 ratio for training and testing. The ECG signals in infants is characterized by the ventricular activity. Since the R wave usually has the highest amplitude, RR-intervals were used for measuring the inter-beat intervals (IBI). For the HRV, non linear components were also accounted for. To classify the event of an erratic/abnormal interval pattern, a customized extreme gradient boosting, XGBoost was utilized. For feeding the model, only the features which were significant to the label were taken [139], [140]. This produced a faster output as the dimensionality of the data decreased [141]. With an advanced model trained and reliably yielding good results, the model generated can be used to develop solutions for premature infant monitoring with data capture happening locally. Moreover, processing of data may be done at a local hospital level node or on a cloud framework depending on the latency requirements and patient privacy and ethical rules. Results showed the rate of detection of a true positive to be 87%. SECTION VIII. Logistics This section describes a few of the applications of ML that aim for the overall betterment of H-IoT systems by strengthening them in terms of logistics and security. Such advancements are particularly important since no healthcare system can be implemented without the security concerns accounted for and an upgrade in logistics leads a to better H-IoT system, no matter what the application [142], [143]. Table 6 at the end of this section gives a brief summary of the reviewed publications that pertain to use cases of ML algorithms for logistics. TABLE 6 Use Cases of ML Algorithms for Logistics A. Patient Prioritization EDs in hospitals often face a situation of overcrowding. Patients have to wait for several hours till a bed becomes available which has a negative impact on the patients’ health and overall mortality rate, while also affecting the hospital staff’s morale and efficiency. If the number of patients that are to be admitted in the hospital from the ED could be predicted using hospital records, such overcrowding could be foreseen and the hospitals would be able to prevent it and improve patient handling. Also, in situations of crisis which need a strong medical response such as the case of COVID-19, it is important to understand the need to be able to prioritize patients on the basis of their urgency, along with managing the response time, and making the work more efficient. Bagula et al. [144] proposed a solution for prioritizing the patients through a cloud based service as a public health service. It was based on the triage system which is a concept with terms and parameters determined by the World Health Organization. It aimed to ensure that patients at higher risk were treated first while keeping the optimum usage of medical resources as the top priority. The idea proposed was to use wearable tech and “health kiosks” to amass an almost real-time metric of who is more vulnerable and would require immediate medical assistance. As it is a cloud service, the medical data can be stored easily and accessed remotely at all times. This helps in providing a descriptive review of the history of the patient to the healthcare practitioners. This solution also facilitates participatory consultation, improving communication between various specialists for better diagnosis and treatment. For data collection, medical biosensors embedded in e-health kits provide a way of replacing the error-prone manual patient vital signs capture processes by more accurate automated procedures. For example, in the current COVID-19 pandemic [148], a contact-less IR temperature scanner can detect trends of community spread quickly, and possibly prevent fatalities. Such kiosks when paired with the government’s COVID tracking applications can track the location of high-risk people, and guide the authorities to provide better treatment and implement quarantine procedures. The system employed k-means clustering to assess the vital signs of the populace and group them in sets based on similarity of vital sign anomalies. For example, people with erratic pulse heartbeats will be in one cluster, people with low blood oxygen levels will be in another, etc. These clusters will have an assigned risk factor, which is effectively a weighted mean of the severity of the recorded vital sign anomalies as determined by the WHO. It was also proposed to deploy solar powered motes with a high capacity lithium ion battery UPS system. To make sure that the sensor reading fell withing acceptable ranges, the field readiness of the e-health sensors was tested. The ZigBee protocol was preferred over traditional Wi-Fi in terms of cost, while Wi-Fi does yield better range and spread. Graham et al. [149] provided an ED crowd prediction model using ML techniques, particularly by applying a decision tree model as well as a model that is an ensemble of multiple decision trees, namely gradient boosted machine. Various model parameters were tuned by performing five rounds of ten-fold cross validation over a custom tuning grid. Using the CARET package, which is a library with tuning and training frameworks, both the decision tree and the gradient boosted machine models were trained and tuned using dataset from hospitals in Ireland. Manikandan et al. [150] proposed a scheduling method, called the hash polynomial two-factor decision tree (HP-TDT) to classify patients as normal or critical, and thus increase scheduling efficiency and minimize response time. The HP-TDT model is carried out in three stages: registration phase, data collection phase, and scheduling phase. Compared to previously designed smart health monitors (SHM), the proposed system was more mathematically inclined, and was more efficient, taking more factors into consideration. Open address hashing (OAH) model is used to carry out the registration stage, which reduces the response time of key generation. Using OAH models, unique private and public keys are generated for each user and hospital, and these keys are passed through hash functions to generate unique registration codes. The next part of the design is data collection, from users and hospitals, which is maintained on clouds. To perform this, polynomial data collection (PDC) algorithm is used. Using PDC, two perfect shortest paths are computed along with a maximal disjoint path. An exponential calculation using polynomial distribution is performed over these attributes to identify the critical state. The final step is the two-factor decision tree scheduling. Creation of a decision tree model involves two steps: tree construction (splitting the tree based on attributes) and tree pruning (removing the extra unwanted branches which might lead to outliers). Hence, the corresponding decision tree is created based on the attribute values calculated in the previous method. The schedule is created on three basic conditions and their corresponding threshold values. If any of the threshold values are surpassed, the patient is termed as a critical case, otherwise a normal case. Manikandan et al. [150] presented an implementation using decision trees to reduce their response time while ensuring privacy. The sensor data for a patient is recorded and used to identify state of distress. Data from various sensors for a patient are attributes of the decision tree. Since fewer decisions are needed to classify a critical state, the number of operations is reduced for data collection when using the trained decision tree. Computational overhead is a significant factor for large scale systems. The experiment used a JAVA platform using Cloud Sim on healthcare data set 2019. It gives an improved scheduling efficiency of 14% and 33% as compared to other implementations [151], [152]. B. Security Due to limited resources, body sensor network devices are often susceptible to security flaws in protecting the sensitive personal health data. This has led to proposals of many methods for implementing security for WBANs that have been developed recently [153], [154]. Out of these, the biometric cryptosystem approach exploits physiological, behavioural and bio-metric traits, such a face recognition, iris scanning, fingerprint scanning, ECG, and PPG patterns. Sun and Lo [145] proposed a biometric cryptosystem (BCS) based on gait (walking pattern) signal energy variations for implantable and wearable devices using an ANN framework. The IEEE standard 802.15.6 operating mainly in the industrial, scientific, and medical (ISM) bands defined the WBAN. These channels are available for anyone with matched radio interface configurations, and can be easily intercepted through software defined radio. Thus, attackers can eavesdrop or even participate within the wireless communication networks amongst WBAN sensor nodes and disrupt the regular operations of the network with DDoS attacks or authentication attacks. Many prior attempts have been made to use solutions like voice and facial recognition to unlock smartphones. Gait detection is done by using inertial measurement units (IMU) which are embedded in many wearable devices. The signals from this device are notoriously inconsistent and hence this paper attempted to use ANNs to estimate the signal received at the chest to achieve better correlation between data gathered from other body positions like the wrist, thigh, head, etc. The neural network is trained by placing sensors on the chest and instructing the fitting algorithm to process the signals from the limbs or head to match the signal from the chest. The ANN architecture consists of an input layer, a hidden layer with 10 hidden nodes, and an output layer. To generate the actual key, a moving average (effectively a low pass filter) of the projected chest gait signal from the sensor in the watch is calculated, and by comparing the actual signal value with that moving average, the binary sequence is received. If the actual signal is larger than averaged signal, then the bit associated with that sample is 1 and vice versa for 0. This bit sequence was then re-sequenced, in the descending order of reliability, i.e. the amount of difference in the actual and averaged signal. This ANN yielded an authentication accuracy of 95% within 4 attempts and the number of the gait cycles required for generating one 128-bit key is sufficiently reduced compared with their previous work [155]. It provides immunity against many modern hacking attempts at extracting the security key such as a dictionary attack [145], [156], providing a highly secure channel as unique as a fingerprint and using very low computational power. Lin et al. [157] proposed a differential privacy protection model for body area networks, that ensured data availability whilst reducing the risk of privacy exposure. A case of ECG big data is taken and dynamic thresholds are used. Lastly, the EHR that are stored in cloud databases also needs to be securely stored. It is vital information such as allergies and past surgeries that may be misused by malicious agents. Hence, to safegaurd them, several blockchain based methods in conjunction with ML have also been proposed [154], [158]. C. Miscellaneous 1) Wireless Coexistence Devices equipped with wireless capability are widespread. An increased use of unlicensed wireless spectrum bands like 2.4 GHz ISM band makes medical devices operating on it susceptible to interference and malfunction. A lack of standardization for determining wireless coexistence prompted ANSI Accredited Standards Committee C63 to publish C63.27 Standard for Evaluation of Wireless Coexistence (2017) and Association for the Advancement of Medical Instrumentation to publish TIR69 (2017): a guidance for risk assessment of wireless coexistence for medical devices. Together, they give the testing methodology and risk assessment of using wireless technology to perform a medical function. Wireless coexistence testing is an iterative process to identify limits of parameters like time, frequency and distance within which medical equipment is safe to use while sharing radio spectrum resources with other systems. No detailed method of aggregation of experimental evaluation exists. Al Kalaa et al. [147] proposed determining likelihood of wireless coexistence by logistic regression. To mitigate overfitting, ‘least absolute shrinkage and selection operator’ feature selection was employed. The experiment was set up in a noise free environment. The system under test (Zigbee) and interfering system (IEEE 802.11n) maintained a line of sight. Performance of estimated logistic regression model was 92.72%. However, the hypothetical system model is applicable only to some protocols. Other medical applications include sensing ECG signals for tracking status of heart failure [159]. 2) Database Structuring Classifiers and clustering algorithms can be used to increase the efficiency of healthcare systems, but electronic clinical data is a must to help these algorithms operate. NLP addresses this problem. Several clinical practices rely on difficult-to-store-and-process manual data. If this data can be stored electronically, the efficiency can significantly increase. Any healthcare system has a lot of data in narrative form. Unless this database is structured, it cannot be used for any kind of analysis. NLP is a very effective algorithm for providing a structure to the databases of clinical practices. It converts a machine-readable narrative in structured form. Hripcsak et al. [146] had discussed the implementation of these algorithms to raw clinical data. Data from a total of 889,921 chest cardiographic reports were sorted using NLP algorithms and results were compared on the basis of manual coding of 150 reports. Accuracy of the algorithm was satisfactory in the research paper. NLP reported a sensitivity of 0.81 and a specificity of 0.99, making it at par with expert coders. SECTION IX. Conclusion In this review, we have covered the major applications and systems where AI and IoT are proposed for a safer, accurate, and predictive healthcare system. A general trend of shifting the information processing towards the edge has been observed in the discussed architectures. This is perhaps due to the growing availability of resources for edge and fog devices. Although the primary inferencing is still done mainly on the cloud, it is expected that this will also shift towards the edge with upcoming libraries such as TinyML and specialized hardware like Tensor processing units. Although many novel methods are being proposed, since the healthcare sector cannot afford false negatives and needs high accuracy, some systems cannot be feasibly implemented. Furthermore, security concerns of the patients about their privacy affect their trust and willingness to participate or use such applications. However, with proposals and implementation of applications that assure high data privacy and security, the trust and awareness of patients for these applications is expected to enhance in the near future. ACKNOWLEDGMENT (Hemantha Krishna Bharadwaj and Aayush Agarwal contributed equally to this work.) The statements made herein are solely the responsibility of the authors. Authors Figures References Citations Keywords Metrics More Like This A Survey of Voice Pathology Surveillance Systems Based on Internet of Things and Machine Learning Algorithms IEEE Access Published: 2020 The Internet of Things for healthcare monitoring: Security review and proposed solution 2014 Third IEEE International Colloquium in Information Science and Technology (CIST) Published: 2014 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.

</subsection_point_Point 2>

<previous_sections>

A systematic review of automated systems for real-time irrigation management

1. INTRODUCTION
The challenge of feeding a growing population with finite resources is becoming increasingly pressing. By 2050, the world population is expected to reach 9.7 billion, necessitating a 70% increase in food production (Falkenmark and Rockstrom, 2009). Irrigation plays a crucial role in enhancing crop yields and agricultural productivity to meet this growing demand. Studies have shown that irrigation can significantly increase crop water productivity, contributing to increased food production (Ali and Talukder, 2008; Playan and Mateos, 2005). However, water scarcity poses a significant challenge, with many regions facing water deficits and the need for improved water management practices (Falkenmark and Rockstrom, 2009). Optimizing irrigation schedules and doses based on crop requirements and environmental conditions is essential for maximizing yield and quality while minimizing water use (Zhang et al., 2024). The necessity of scalable water-efficient practices for increasing food demand cannot be overstated. Techniques such as regulated deficit irrigation, magnetically treated water, and the use of drought-tolerant crops like sorghum have shown promise in improving water productivity and ensuring food security (Mehmood et al., 2023; Putti et al., 2023; Hadebe et al., 2016). As the global food challenge intensifies, it is imperative to critically evaluate the current state and future potential of irrigation management systems to guide research, innovation, and implementation efforts towards fully autonomous, scalable solutions.

Despite the importance of irrigation in addressing the global food challenge, traditional irrigation management techniques, such as manual scheduling and timer-based systems, have significant limitations. These methods are often labor-intensive, inefficient, and less adaptable to changing conditions (Savin et al., 2023). Manual and timer-based scheduling can lead to high operational costs and inefficient water use (Raghavendra, Han, and Shin, 2023). The reliance on manual intervention and predetermined schedules limits their adaptability to changing environmental conditions, crop water requirements, and soil moisture levels (Kaptein et al., 2019). Sensor-based irrigation systems offer an alternative, enabling real-time adjustments based on soil water status measurements (Kaptein et al., 2019). However, the adoption of these systems in commercial settings has been limited, often requiring extensive input from researchers (Kim et al., 2014; Lea-Cox et al., 2018; Ristvey et al., 2018). The limitations of traditional irrigation management techniques highlight the need for scalable, automated solutions for greater efficiency in irrigation management. Automated systems that collect real-time data, analyze it, and make autonomous irrigation decisions can lead to improved water use efficiency and increased crop productivity (Champness et al., 2023; Wu et al., 2022). To fully understand the potential of automated systems, it is necessary to examine the automation of each part of the irrigation management pipeline and analyze the effectiveness and efficiency of integrated end-to-end solutions.

The emergence of smart irrigation management and IoT marks a significant shift from historical irrigation practices. Modern approaches rely on vast data and analysis algorithms, leveraging technologies such as remote sensing, sensor networks, weather data, and computational algorithms (Atanasov, 2023; Bellvert et al., 2023; Kumar et al., 2023). IoT plays a vital role in collecting vast amounts of data through sensors, data transmission, and tailored networks, enabling real-time monitoring and control of irrigation systems (Liakos, 2023; Zuckerman et al., 2024). These advancements in data collection and analysis have the potential to revolutionize irrigation management, allowing for more precise and efficient water use. However, challenges such as processing diverse data sources, data integration, and lack of integrated data analysis hamper the full benefit of IoT in irrigation management (Dave et al., 2023). The current fragmented approach in smart irrigation, focusing on individual components rather than the entire system, limits the potential for fully autonomous, real-time end-to-end irrigation management (Togneri et al., 2021). To address these challenges and fully realize the potential of smart irrigation management, there is a need for automating and integrating each section of the irrigation management pipeline, from sensor/weather data collection and transmission to processing, analysis, decision-making, and automated action (McKinion and Lemmon, 1985). This integration requires a thorough investigation of the role of interoperability and standardization in enabling seamless communication and compatibility between components within the automated irrigation management pipeline.

Machine learning (ML) plays a significant role in processing vast data, predicting plant stress, modeling climate effects, and optimizing irrigation in smart irrigation management systems. ML algorithms can analyze data collected from sensors and weather stations to determine optimal irrigation schedules (Vianny et al., 2022). However, the potential of ML is often constrained by manual steps, such as data interpretation, decision-making on irrigation timing and volume, and system adjustments. Automating ML integration to allow direct action from insights to irrigation execution, removing bottlenecks and achieving real-time adaptability, is crucial for fully autonomous irrigation management (Barzallo-Bertot et al., 2022). By integrating ML into automated systems, the irrigation management pipeline can become more seamless and efficient, enabling real-time decision-making and action based on data-driven insights. To achieve this level of automation and integration, it is essential to identify gaps and propose solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.

To achieve seamless integration across the automated irrigation management system, interoperability and standardization are critical. Interoperability allows different system components, such as sensors, actuators, and software, to communicate and exchange data effectively, while standardization ensures that data is represented in a consistent format (Santos et al., 2020). Standardized protocols and data formats are essential for achieving seamless integration and ensuring compatibility between components in real-time irrigation management systems (Robles et al., 2022; Hatzivasilis et al., 2018). Existing and emerging standards, such as OGC SensorThings API and ISO 11783, have applicability to real-time irrigation management systems (Hazra et al., 2021). However, challenges such as data quality, scalability, reliability, and security need to be addressed to fully realize the potential of interoperability and standardization in automated irrigation management systems (Hazra et al., 2021). Addressing these challenges is crucial for enabling the seamless integration of components within the automated irrigation management pipeline, which is essential for achieving fully autonomous, scalable irrigation management. A comprehensive evaluation of the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline is necessary to guide future research and implementation efforts.
The primary objective of this systematic review is to critically evaluate the current state and future potential of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies for enhancing agricultural water use efficiency and crop productivity.
Specific objectives include:
•	Examining the automation of each part of the irrigation management pipeline and the seamless integration of each section in the context of irrigation scheduling and management.
•	Analyzing the effectiveness and efficiency of integrated end-to-end automated irrigation systems.
•	Investigating the role of interoperability and standardization in enabling the integration of components within the automated irrigation management pipeline.
•	Identifying gaps and proposing solutions for seamless integration across the automated irrigation management system, aiming to achieve fully autonomous, scalable irrigation management.
By addressing these objectives, this systematic review aims to provide a comprehensive and critical evaluation of the current state and future potential of real-time, end-to-end automated irrigation management systems. Its intention is to guide future research, innovation, and implementation efforts to achieve fully autonomous, scalable irrigation management that can contribute to addressing the global food challenge.

2. REVIEW METHODOLOGY
•	Question-driven framework to guide the literature review of real-time, autonomous irrigation management systems
•	Key research questions posed, each with the motivation behind investigating them and a starting hypothesis to evaluate against the examined literature
•	Table presenting the major objectives, specific objectives, questions, motivations, and hypotheses
3. DATA COLLECTION TO CLOUD: AUTOMATION AND REAL-TIME PROCESSING
3.1. Irrigation management data
The success of automated irrigation management systems relies heavily on the collection, transmission, and analysis of various types of data. The most applicable data types for irrigation management include soil moisture, canopy temperature, weather data, and plant physiological parameters (Farooq et al., 2019; Li et al., 2019; Olivier et al., 2021; Evett et al., 2020). These data are typically collected from a range of sources, including in-field sensors, remote sensing platforms, weather stations, and manual measurements (Li et al., 2019; Karimi et al., 2018).
Soil moisture data is arguably the most critical type of data for irrigation management, as it directly reflects the water available to plants and can be used to determine the optimal timing and amount of irrigation (Olivier et al., 2021; Intrigliolo & Castel, 2006). Soil moisture sensors, such as tensiometers, capacitance probes, and time-domain reflectometry (TDR) sensors, can provide real-time measurements of soil water content at various depths (Farooq et al., 2019). These sensors can be deployed in a network configuration to capture spatial variability in soil moisture across a field (Karimi et al., 2018).
Canopy temperature data is another valuable type of data for irrigation management, as it can be used to assess plant water stress and adjust irrigation accordingly (Evett et al., 2020). Infrared thermometers and thermal cameras can be used to measure canopy temperature, which is influenced by factors such as air temperature, humidity, wind speed, and plant water status (Li et al., 2019). When plants experience water stress, they tend to close their stomata to reduce water loss, leading to an increase in canopy temperature (Evett et al., 2020). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
Weather data, including temperature, humidity, precipitation, wind speed, and solar radiation, are essential for predicting crop water requirements and scheduling irrigation events (Akilan & Baalamurugan, 2024). Weather stations equipped with various sensors can provide real-time measurements of these parameters, which can be used as inputs for crop water requirement models, such as the FAO-56 Penman-Monteith equation (Li et al., 2019). These models estimate crop evapotranspiration (ET) based on weather data and crop-specific coefficients, allowing for the calculation of irrigation requirements (Intrigliolo & Castel, 2006). By integrating weather data into automated irrigation systems, irrigation schedules can be dynamically adjusted based on changing environmental conditions, ensuring that crops receive the optimal amount of water at the right time (Akilan & Baalamurugan, 2024).
When collecting and utilizing these data types, several considerations must be taken into account, including the volume, frequency, format, and source of the data (Farooq et al., 2019). The volume of data generated by automated irrigation systems can be substantial, especially when high-resolution sensors are deployed at a large scale (Bastidas Pacheco et al., 2022). This necessitates the use of efficient data storage, processing, and transmission technologies to handle the data load (Farooq et al., 2019). The frequency of data collection is another important consideration, as it directly impacts the temporal resolution of the data and the ability to detect rapid changes in plant water status or environmental conditions (Bastidas Pacheco et al., 2022). Bastidas Pacheco et al. (2022) demonstrated that collecting full pulse resolution data from water meters provides more accurate estimates of event occurrence, timing, and features compared to aggregated temporal resolutions, highlighting the importance of selecting appropriate data collection frequencies to ensure the quality and usefulness of the data for irrigation management.
The format of the data is also crucial, as it determines the compatibility and interoperability of the data with various analysis tools and platforms (Farooq et al., 2019). Standardized data formats, such as JSON, XML, or CSV, can facilitate data exchange and integration between different components of the automated irrigation system (Zhang et al., 2023). The source of the data is another important consideration, as it can impact the reliability, accuracy, and spatial coverage of the data (Farooq et al., 2019). For example, in-field sensors provide highly localized measurements, while remote sensing platforms, such as satellites or drones, can provide data at larger spatial scales (Li et al., 2019). By combining data from multiple sources, automated irrigation systems can achieve a more comprehensive understanding of crop water requirements and optimize irrigation management accordingly (Farooq et al., 2019).
Data quality, accuracy, and reliability are paramount in irrigation management, as they directly impact the effectiveness of decision-making processes and the efficiency of water use (Gupta et al., 2020). Inaccurate or unreliable data can lead to suboptimal irrigation decisions, resulting in crop stress, yield losses, or wasted water resources (Ramli & Jabbar, 2022). Gupta et al. (2020) emphasized the critical importance of data security and privacy in smart farming systems, as the leakage of sensitive agricultural data can cause severe economic losses to farmers and compromise the integrity of the automated irrigation system. The authors also highlighted the need for robust authentication and secure communication protocols to prevent unauthorized access to smart farming systems and protect data in transit (Gupta et al., 2020).
Ramli and Jabbar (2022) addressed the challenges associated with implementing real-time, automated irrigation systems, including data quality, scalability, reliability, and security. They proposed solutions and best practices based on the analysis of case studies and real-world implementations, such as the use of redundant sensors, data validation techniques, and secure communication protocols (Ramli & Jabbar, 2022). The authors also emphasized the importance of regular maintenance and calibration of sensors to ensure the accuracy and reliability of the collected data (Ramli & Jabbar, 2022).
Researchers have investigated the use of data compression, aggregation, and filtering techniques to reduce bandwidth requirements and improve transmission efficiency in automated irrigation systems (Karim et al., 2023; Rady et al., 2020; Cui, 2023). Karim et al. (2023) explored the effectiveness of various data compression techniques, such as lossless and lossy compression algorithms, in reducing the size of data packets transmitted over wireless networks. The authors found that lossless compression techniques, such as Huffman coding and Lempel-Ziv-Welch (LZW), can significantly reduce data size without compromising data quality, while lossy compression techniques, such as JPEG and MP3, can further reduce data size by introducing acceptable levels of distortion (Karim et al., 2023).
Rady et al. (2020) developed a novel data compression algorithm specifically designed for irrigation data, which achieved significant compression ratios without compromising data quality. The authors demonstrated that their algorithm could reduce the amount of data transmitted over wireless networks, thereby improving the efficiency of the irrigation system and reducing costs (Rady et al., 2020). Cui (2023) investigated the use of data aggregation and filtering techniques to reduce the number of transmissions and save bandwidth in automated irrigation systems. The author proposed a data aggregation scheme that combines multiple sensor readings into a single value, such as the average soil moisture over a specified time interval, to reduce the frequency of data transmissions (Cui, 2023). Additionally, the author explored the use of data filtering techniques, such as Kalman filters and particle filters, to remove noise and outliers from sensor data, improving the accuracy and reliability of the transmitted information (Cui, 2023).
Data standardization and harmonization are crucial for facilitating seamless integration and interoperability between the various components of automated irrigation management systems (Zhang et al., 2023; Ermoliev et al., 2022). Zhang et al. (2023) developed a novel cyberinformatics technology called iCrop, which enables the in-season monitoring of crop-specific land cover across the contiguous United States. The authors highlighted the importance of data standardization and harmonization in the context of iCrop, as it allows for the efficient distribution of crop-specific land cover information based on the findable, accessible, interoperable, and reusable (FAIR) data principle (Zhang et al., 2023). By adopting standardized data formats and protocols, such as the Open Geospatial Consortium (OGC) standards, iCrop enables the seamless integration of various data sources and facilitates the interoperability of the system with other agricultural decision support tools (Zhang et al., 2023).
Ermoliev et al. (2022) proposed a linkage methodology for linking distributed sectoral/regional optimization models in a situation where private information is not available or cannot be shared by modeling teams. The authors emphasized the need for data standardization to enable decentralized cross-sectoral coordination and analysis, as it allows for the consistent representation and exchange of data between different models and stakeholders (Ermoliev et al., 2022). By adopting standardized data formats and interfaces, the proposed linkage methodology can facilitate the integration of various optimization models and support the development of comprehensive decision support systems for sustainable resource management (Ermoliev et al., 2022).
Metadata plays a vital role in providing context and enabling better data interpretation and decision-making in automated irrigation management systems (Jahanddideh-Tehrani et al., 2021). Metadata refers to the additional information that describes the characteristics, quality, and context of the primary data, such as the sensor type, calibration parameters, measurement units, and timestamp (Jahanddideh-Tehrani et al., 2021). Jahanddideh-Tehrani et al. (2021) highlighted the importance of metadata in water resources management, as it enables decision-makers to use the data to the best of its capabilities by understanding factors such as when water data was collected and what factors might have contributed to the measurements. The authors emphasized the need for standardized metadata formats and guidelines, such as the Dublin Core Metadata Initiative (DCMI) and the ISO 19115 standard, to ensure the consistency and interoperability of metadata across different water information systems (Jahanddideh-Tehrani et al., 2021).
In the context of automated irrigation management systems, metadata can provide valuable information about the data collection process, sensor performance, and environmental conditions that can aid in data interpretation and decision-making (Cota & Mamede, 2023). For example, metadata about the sensor type and calibration parameters can help assess the accuracy and reliability of the collected data, while metadata about the weather conditions and soil properties can provide context for interpreting the data and adjusting irrigation strategies accordingly (Cota & Mamede, 2023). By incorporating metadata into the data management and analysis pipeline of automated irrigation systems, decision-makers can make more informed and context-aware decisions, leading to improved water use efficiency and crop productivity (Jahanddideh-Tehrani et al., 2021).

3.2. Edge Computing and Fog Computing
Edge computing and fog computing have emerged as transformative technologies in the realm of real-time irrigation management systems, offering significant potential for improving efficiency, scalability, and reliability (Abdel Nasser et al., 2020; Tran et al., 2019). Edge computing refers to the practice of processing data near the edge of the network, close to the source of the data, while fog computing is a decentralized computing infrastructure that extends cloud computing capabilities to the network edge (Hassija et al., 2019). These technologies bring computation and analytics closer to the data source, reducing the need for data to travel to the cloud and enabling faster processing and decision-making (Hassija et al., 2019; Zhang et al., 2020).
The potential of edge computing and fog computing in real-time irrigation management is immense. Abdel Nasser et al. (2020) proposed a two-layer system for water demand prediction using automated meters and machine learning techniques, demonstrating the potential of edge computing in improving the efficiency and scalability of irrigation management. The system collects and aggregates data from distributed smart meters in the first layer, while the second layer uses LSTM neural networks to predict water demand for different regions of households. By leveraging edge computing, the system can achieve high accuracy in predicting water demand, which is essential for efficient irrigation management (Abdel Nasser et al., 2020).
Tran et al. (2019) conducted a comprehensive review of real-time, end-to-end automated irrigation management systems, highlighting the role of fog computing in addressing data transmission challenges and enabling seamless integration across the irrigation management pipeline. The authors emphasize that real-time, end-to-end automated irrigation management systems have the potential to significantly improve water efficiency, crop yields, and reduce labor costs. However, they also identify several challenges that need to be addressed, such as data quality, scalability, reliability, and security, which can be effectively tackled by implementing fog computing architectures (Tran et al., 2019).
Edge computing offers several benefits in real-time irrigation management systems, including reduced latency, real-time decision-making, and reduced reliance on cloud connectivity (Mishra, 2020; Zhang et al., 2020). By processing data closer to the source, edge computing enables faster response times and more efficient data handling (Mishra, 2020). Mishra (2020) highlights that edge computing reduces latency by processing data closer to the source, enabling real-time decision-making and lessening reliance on cloud connectivity by shifting processing to local or edge devices.
Zhang et al. (2020) explore the application of edge computing in agricultural settings, demonstrating its potential to improve the efficiency and accuracy of irrigation systems. The authors discuss how edge computing has prospects in various agricultural applications, such as pest identification, safety traceability of agricultural products, unmanned agricultural machinery, agricultural technology promotion, and intelligent management. They also emphasize that the emergence of edge computing models, such as fog computing, cloudlet, and mobile edge computing, has transformed the management and operation of farms (Zhang et al., 2020).
Fog computing plays a crucial role in distributing processing and storage across the network, enhancing the scalability and reliability of automated irrigation systems (Premkumar & Sigappi, 2022; Singh et al., 2022). Premkumar and Sigappi (2022) evaluate the current state of automated irrigation management systems and propose a hybrid machine learning approach for predicting soil moisture and managing irrigation. Their study emphasizes the potential of fog computing in distributing processing and storage across the network, improving the efficiency and scalability of irrigation systems. The proposed hybrid machine learning approach outperforms other machine learning algorithms in predicting soil moisture, demonstrating the effectiveness of fog computing in enhancing the performance of automated irrigation systems (Premkumar & Sigappi, 2022).
Singh et al. (2022) discuss the role of fog computing in distributing processing and storage across the network, enhancing scalability and reliability in agricultural management systems. The authors argue that by implementing fog computing, these systems can achieve faster data processing and response times, improving overall efficiency and effectiveness. They also highlight that fog computing can address the challenges faced by real-time data transmission in agricultural management systems, such as latency, bandwidth limitations, and data security (Singh et al., 2022).
The integration of edge and fog computing in real-time irrigation management systems is crucial for achieving fully automated, scalable, and reliable solutions. As the demand for autonomous irrigation management grows, these technologies will play a pivotal role in enabling faster decision-making, reduced latency, improved resource utilization, and seamless integration across the irrigation management pipeline (Tran et al., 2019; Zhang et al., 2020). By bringing computation and analytics closer to the data source and distributing processing and storage across the network, edge and fog computing can significantly enhance the efficiency and effectiveness of automated irrigation systems, contributing to the overall goal of addressing the global food challenge through optimized water resource management and increased agricultural productivity (Abdel Nasser et al., 2020; Premkumar & Sigappi, 2022; Singh et al., 2022).

3.3. Automation of Data Collection
The automation of data collection is a critical component in the development of real-time, end-to-end automated irrigation management systems that integrate IoT and machine learning technologies. It enables the efficient gathering of vital information about crop health, environmental conditions, and water requirements, which is essential for enhancing agricultural water use efficiency and crop productivity. Two key aspects of automated data collection are the use of advanced sensing technologies for non-invasive plant stress detection and the implementation of wireless sensor networks and energy-efficient communication protocols for large-scale, long-term data collection.
Advanced sensing technologies, such as hyperspectral imaging and thermal sensing, have emerged as powerful tools for non-invasive plant stress detection in automated irrigation management systems. These technologies provide valuable information about crop traits, enabling early and accurate detection of plant health issues (Triantafyllou et al., 2019). Triantafyllou et al. (2019) propose a comprehensive reference architecture model that incorporates advanced sensing technologies in the sensor layer for real-time plant stress detection, highlighting their importance in providing non-invasive plant stress detection. Similarly, Hossain et al. (2023) present a novel IoT-ML-Blockchain integrated framework for smart agricultural management that leverages advanced sensing technologies to optimize water use and improve crop yield, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
Hyperspectral imaging can capture subtle changes in plant physiology that are indicative of stress, while machine learning algorithms can be employed to extract meaningful patterns from the spectral data and classify different stress types (Araus et al., 2014). Thermal sensing can detect changes in canopy temperature, which is influenced by factors such as plant water status (Li et al., 2019). By monitoring canopy temperature and comparing it to reference values, automated irrigation systems can detect plant water stress and trigger irrigation events to maintain optimal plant health and productivity (Li et al., 2019).
The integration of advanced sensing technologies in automated irrigation management systems has the potential to revolutionize precision agriculture. Jiang et al. (2019) demonstrate the effectiveness of a deep learning-based model in accurately detecting leaf spot diseases, highlighting the importance of image augmentation and deep learning algorithms in enhancing the model's performance.
Wireless sensor networks (WSNs) and energy-efficient communication protocols have the potential to significantly improve the efficiency and reliability of data collection in large-scale, long-term irrigation systems. WSNs offer a cost-effective and scalable solution for real-time data collection in large-scale irrigation systems, providing remote monitoring and automated control capabilities (Mehdizadeh et al., 2020). Nishiura and Yamamoto (2021) propose a novel sensor network system that utilizes drones and wireless power transfer to autonomously collect environmental data from sensor nodes in vast agricultural fields, reducing operational costs and enhancing the efficiency of data collection. Similarly, Higashiura and Yamamoto (2021) introduce a network system that employs UAVs and LoRa communication to efficiently collect environmental data from sensor nodes distributed across large farmlands, optimizing data collection and reducing travel distance and time.
Energy-efficient communication protocols are crucial for ensuring reliable data transmission in challenging environmental conditions and extending the lifespan of sensor nodes (Mehdizadeh et al., 2020). Al-Ali et al. (2023) investigate the potential of WSNs and energy-efficient communication protocols for data collection in large-scale, long-term irrigation systems, discussing the challenges and opportunities of using these technologies to improve the efficiency and reliability of real-time data collection in irrigation management. Mehdizadeh et al. (2020) emphasize the need for careful consideration of factors such as data accuracy, energy consumption, and network reliability when designing effective WSNs for irrigation management, enabling timely irrigation decisions and improved crop yields.
The automation of data collection through the use of advanced sensing technologies and wireless sensor networks is essential for achieving fully autonomous, scalable irrigation management. By enabling non-invasive plant stress detection and large-scale, long-term data collection, these technologies contribute to the overall goal of optimizing water resource management and increasing agricultural productivity. The integration of these technologies in real-time, end-to-end automated irrigation management systems has the potential to enhance agricultural water use efficiency and crop productivity, ultimately contributing to the development of fully autonomous, scalable irrigation management solutions.

3.4: Real-Time Data Transmission Protocols and Technologies
Real-time data transmission is a critical component of automated irrigation management systems, as it enables the timely delivery of sensor data to the cloud for processing and decision-making. The exploration of suitable protocols and network architectures is essential for ensuring efficient and reliable data transmission in these systems, contributing to the overall goal of enhancing agricultural water use efficiency and crop productivity.
The Message Queuing Telemetry Transport (MQTT) protocol has emerged as a popular choice for real-time data transmission in IoT networks, including those used for automated irrigation management. MQTT is a lightweight, publish-subscribe protocol designed for constrained devices and low-bandwidth networks (Author, 2019). Its simplicity and low overhead make it well-suited for IoT applications where data transmission speed and energy efficiency are critical (Saranyadevi et al., 2022). MQTT provides three Quality of Service (QoS) levels, ensuring data reliability in real-time scenarios (Author, 2019). Chen et al. (2020) proposed novel algorithms to improve data exchange efficiency and handle rerouting in MQTT-based IoT networks for automated irrigation management systems. Their TBRouting algorithm efficiently finds the shortest paths for data transmission, while the Rerouting algorithm effectively handles the rerouting of topic-based session flows when a broker crashes. The combination of these algorithms can significantly improve the performance and reliability of automated irrigation management systems (Chen et al., 2020).
Client-server IoT networks, such as those based on MQTT, play a crucial role in real-time data transmission for automated irrigation management systems. In these networks, sensors and devices (clients) publish data to a central broker (server), which then distributes the data to subscribed clients (Verma et al., 2021). This architecture enables efficient data collection, processing, and dissemination, facilitating the integration of various components within the automated irrigation management pipeline. Verma et al. (2021) proposed an architecture for healthcare monitoring systems using IoT and communication protocols, which provides a comprehensive overview of existing approaches and highlights challenges and opportunities in the field. Although focused on healthcare, the insights from this study can be applied to automated irrigation management systems, emphasizing the importance of interoperability and standardization for seamless integration (Verma et al., 2021).
In addition to MQTT, other application layer protocols such as XMPP, CoAP, SOAP, and HTTP have been explored for real-time data transmission in IoT networks. Each protocol has its strengths and weaknesses, making them suitable for different applications and scenarios. XMPP (Extensible Messaging and Presence Protocol) is an open-standard protocol that supports real-time messaging, presence, and request-response services (Saint-Andre, 2011). CoAP (Constrained Application Protocol) is a specialized web transfer protocol designed for use with constrained nodes and networks in the Internet of Things (Shelby et al., 2014). SOAP (Simple Object Access Protocol) is a protocol for exchanging structured information in the implementation of web services, while HTTP (Hypertext Transfer Protocol) is the foundation of data communication for the World Wide Web (Fielding et al., 1999).
Motamedi and Villányi (2022) compared and evaluated wireless communication protocols for the implementation of smart irrigation systems in greenhouses, considering factors such as power consumption, range, reliability, and scalability. They found that ZigBee is the most suitable local communication protocol for greenhouse irrigation due to its large number of nodes and long range, while MQTT is the recommended messaging protocol for smart irrigation systems due to its TCP transport protocol and quality of service (QoS) options. GSM is a reliable and cost-effective global communication protocol for greenhouse irrigation, providing wide coverage and low cost (Motamedi & Villányi, 2022).
Syafarinda et al. (2018) investigated the use of the MQTT protocol in a precision agriculture system using a Wireless Sensor Network (WSN). They found that MQTT is suitable for use in IoT applications due to its lightweight, simple, and low bandwidth requirements. The average data transmission speed using the MQTT protocol was approximately 1 second, demonstrating its effectiveness for real-time data transmission in precision agriculture systems (Syafarinda et al., 2018).
The choice of application layer protocol for real-time irrigation management depends on factors such as data transmission speed, reliability, and energy efficiency. MQTT and RTPS (Real-Time Publish-Subscribe) are both suitable for real-time data transmission in IoT systems, but they have different strengths and weaknesses. MQTT is a better choice for applications that require low latency and high throughput, while RTPS is a better choice for applications that require high reliability and low latency (Sanchez-Iborra & Skarmeta, 2021). The exploration of MQTT and client-server IoT networks, along with the comparison of various application layer protocols, provides valuable insights into the suitability of these technologies for real-time data transmission in automated irrigation management systems.
In summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.

3.5. Challenges and Solutions in Real-Time Data Transmission
Following the exploration of data collection, processing at the edge and fog, and automation in previous sections, we now turn to the critical aspect of real-time data transmission. While essential for automated irrigation management, this stage presents unique challenges that must be addressed to ensure system efficiency and reliability.
Obstacles in Real-Time Data Transmission
Agricultural environments present unique challenges for real-time data transmission, directly impacting the effectiveness of automated irrigation systems. Environmental factors can significantly disrupt wireless communication. Adverse weather conditions such as heavy rain, fog, and high winds can weaken or even block radio signals, leading to data loss and compromised system performance. Physical obstacles like trees, buildings, and uneven terrain further complicate signal propagation, creating reliability issues (Jukan et al., 2017; Yi & Ji, 2014; Zhang, Chang & Baoguo, 2018). These environmental challenges necessitate robust communication protocols and network architectures that can ensure consistent and reliable data flow.
In addition to environmental factors, technical limitations also present significant obstacles. Large-scale agricultural operations often demand long-distance data transmission, which can be hindered by the limited range of certain wireless communication protocols. Network congestion, occurring when multiple sensors transmit data concurrently, can lead to delays and potential data loss, further complicating real-time decision-making (Hameed et al., 2020). To mitigate these issues, researchers have investigated the potential of cognitive radio networks (CRNs) and dynamic spectrum access (DSA) for optimizing spectrum utilization and reducing interference (Righi et al., 2017; Shafi et al., 2018; Trigka & Dritsas, 2022). CRNs enable devices to intelligently sense and adapt to the surrounding radio environment, dynamically adjusting transmission parameters to avoid interference and improve communication efficiency. DSA, on the other hand, facilitates the dynamic allocation of unused spectrum, enhancing spectrum utilization and reducing congestion.
Furthermore, data security and privacy are paramount concerns in real-time irrigation systems. The sensitive nature of agricultural data, such as crop yields and farm management practices, necessitates robust security measures to prevent unauthorized access and data breaches (Gupta et al., 2020). Implementing secure communication protocols, authentication mechanisms, and encryption techniques is essential to protect data integrity and ensure the trustworthiness of the system.
Investigating Data Optimization Techniques
To enhance the efficiency and reliability of real-time data transmission in automated irrigation systems, researchers have explored a range of data optimization techniques. Data compression techniques aim to reduce the size of data packets transmitted over the network, minimizing bandwidth requirements and improving transmission speed (Rady et al., 2020; Karim et al., 2023). Lossless compression algorithms, such as Huffman coding and LZW, preserve data integrity while effectively reducing data size, ensuring that no information is lost during transmission (Cui, 2023). Lossy compression algorithms, such as JPEG and MP3, offer higher compression ratios but introduce a controlled level of data loss, which may be acceptable for certain applications where some loss of precision is tolerable (Karim et al., 2023). The choice between lossless and lossy compression depends on the specific application and the trade-off between data size and accuracy.
Data aggregation techniques provide another effective approach to optimize data transmission. By aggregating multiple sensor readings into a single representative value, such as average soil moisture or temperature, the number of transmissions can be significantly reduced, conserving bandwidth and energy resources (Cui, 2023). This is particularly beneficial in large-scale irrigation systems where numerous sensors are deployed across vast areas, generating substantial amounts of data. Additionally, data filtering techniques play a crucial role in improving data quality and reliability. Kalman filters and particle filters can effectively remove noise and outliers from sensor data, ensuring that only accurate and relevant information is transmitted and used for decision-making (Cui, 2023). This is essential for preventing erroneous data from influencing irrigation decisions and potentially leading to suboptimal water management.
Sensor calibration, drift correction, and fault detection are essential for maintaining data accuracy and reliability (Dos Santos et al., 2023). Regular calibration ensures that sensors provide accurate measurements over time, while drift correction techniques account for gradual changes in sensor readings due to environmental factors or aging. Fault detection mechanisms can identify and address sensor malfunctions or anomalies, preventing erroneous data from influencing irrigation decisions and potentially harming crops or wasting water.
Addressing the Challenges
Effectively addressing the challenges in real-time data transmission requires a multifaceted approach that encompasses environmental, technical, and data-related considerations. Implementing robust and adaptive communication protocols is crucial for overcoming interference and signal degradation caused by weather conditions and physical obstacles. Selecting appropriate protocols, such as LoRa or ZigBee, with suitable range and penetration capabilities can ensure reliable data transmission in challenging agricultural environments (Motamedi & Villányi, 2022). Additionally, employing techniques like frequency hopping and error correction codes can further improve communication resilience and mitigate data loss.
Optimizing network architecture is another key consideration. Deploying a distributed network architecture with edge and fog computing capabilities can significantly enhance data processing and transmission efficiency (Abdel Nasser et al., 2020; Tran et al., 2019). Edge devices can perform initial data processing and aggregation tasks, reducing the amount of data transmitted to the cloud and minimizing latency, while fog nodes can provide additional processing power and storage closer to the data source, enhancing scalability and reliability. This distributed approach alleviates the burden on the central cloud server and allows for more responsive and efficient irrigation management.
Data optimization techniques play a vital role in reducing bandwidth requirements and improving transmission efficiency. The choice of data compression, aggregation, and filtering techniques should be tailored to the specific requirements of the irrigation system, considering factors such as data type, accuracy needs, and available bandwidth. By carefully selecting and implementing these techniques, the overall performance and effectiveness of real-time irrigation systems can be significantly enhanced, leading to more sustainable water management practices and improved agricultural productivity.
By addressing these challenges and implementing appropriate solutions, real-time data transmission can become a reliable and efficient component of automated irrigation systems, contributing to the overall goal of achieving sustainable and productive agriculture in the face of growing food demands and water scarcity.
n summary, real-time data transmission protocols and technologies play a vital role in the automation of irrigation management systems, enabling the efficient and reliable delivery of sensor data to the cloud for processing and decision-making. The exploration of MQTT and client-server IoT networks, along with the comparison of application layer protocols, highlights the importance of selecting suitable technologies based on factors such as data transmission speed, reliability, and energy efficiency. By leveraging these technologies, automated irrigation management systems can achieve seamless integration and contribute to the overall goal of enhancing agricultural water use efficiency and crop productivity.


</previous_sections>

</documents>
<instructions>


Use the information provided in the <documents> tags to write the next subsection of the research paper, following these steps:
1. Review the overall intention of the research paper, specified in the <review_intention> tag. Ensure the subsection you write aligns with and contributes to this overall goal.
2. Consider the specific intention for this subsection of the paper, stated in the <section_intention> tag. The content you write should fulfill this purpose. 
3. Use the title provided in the <subsection_title> tag as the heading for the subsection. 
4. Address each of the points specified in the </subsection_point_Point *> tags:
   a) Make a clear case for each point using the text provided in the "point" field.
   b) Support each point with evidence from the research papers listed in the corresponding "papers to support point" field.
   c) When citing a paper to support a point, include inline citations with the author name(s) and year, e.g. (Smith et al., 2020; Johnson and Lee, 2019; Brown, 2018). Cite all papers that strengthen or relate to the point being made.
   d) While making a point and citing the supporting papers, provide a brief explanation in your own words of how the cited papers support the point.
5. Ensure that both of the points from the <subsection_point> tags are fully addressed and supported by citations. Do not skip or combine any points.
6. After addressing the specified points, wrap up the subsection with a concluding sentence or two that ties the points together and relates them back to the <section_intention>.
7. Review the <Previous_sections> of the paper, and ensure that the new subsection you have written fits logically and coherently with the existing content. Add transition sentences as needed to improve the flow.
8. Proofread the subsection to ensure it is clear, concise, and free of grammatical and spelling errors. Maintain a formal academic tone and style consistent with the rest of the research paper.
9. Format the subsection using Markdown, including the subsection heading (using ## or the equivalent for the document), inline citations, and any other formatting needed for clarity and readability.
10. If any information is missing or unclear in the provided tags, simply do your best to write the subsection based on the available information. Do not add any information or make any points not supported by the provided content. Prioritize fully addressing the required points over hitting a specific word count.

The output should be a complete, well-organized, and properly cited subsection ready to be added to the research paper.

Begin your answer with a brief recap of the instructions stating what you will to optimize the quality of the answer. Clearly and briefly state the subsection you'll be working on and the points you'll be addressing. Then proceed to write the subsection following the instructions provided. 

Critical: 
- Do not include a conclusion or summary as the entry is in the middle of the document. Focus on addressing the points and supporting them with evidence from the provided papers. Ensure that the subsection is well-structured, coherent, and effectively contributes to the overall research paper.
- The subsection we are focusing on is: 3.6. IoT Network Architectures and Variable Rate Irrigation (VRI) for Real-Time Irrigation
- No need for sub-sub-sections. just provide paragraphs addressing each point. They should transition fluidly and narurally into each other.
- Ensure that the content is supported by the provided papers and that the citations are correctly formatted and placed within the text.
- Do not repeat content from the previous sections. Ensure that the information provided is new and relevant to the subsection being written.



</instructions>


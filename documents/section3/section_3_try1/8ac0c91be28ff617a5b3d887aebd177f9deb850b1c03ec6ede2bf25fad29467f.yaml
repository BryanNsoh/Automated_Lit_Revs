- analysis: '>'
  authors:
  - Xiao C.
  - Zhang S.
  - Ma X.
  - Zhou T.
  - Hou T.
  - Chen F.
  citation_count: '1'
  description: History-matching-based production forecast and uncertainty quantification
    are essential to achieve reliable risk assessment for waterflooding reservoir
    in the community of petroleum engineering, however, the conventional model-based
    history matching procedure presents intensive computation-cost due to numerous
    high-fidelity reservoir simulations. The use of direct forecast approach, e.g.,
    data-space inversion (DSI) and its variants, is urgent to achieve direct production
    forecast without explicitly performing history matching. This work presents a
    generic data-driven post-history production forecasting framework using a novel
    deep recurrent neural network. We construct a hybrid recurrent neural network
    proxy through combining recurrent autoencoder with long short-term memory neural
    network, e.g., referred to as RAE-LSTM. The proposed RAE-LSTM takes history prediction
    and post-history well controls as input, while the post-history production responses
    (oil and water production, water injection rate) as output. Training samples are
    constructed by simulating high-fidelity models parameterized with various post-history
    well-controls and geomodels. Once the deep recurrent neural network proxies are
    trained offline, the online post-history production forecast and uncertainty quantification
    can be efficiently achieved by input user-specific well control sequences and
    history measurement. The proposed proxy model is demonstrated on two examples
    with varying complexity, e.g., a synthetic 2D Gaussian model and a 3D channelized
    EGG model. The use of our proposed RAE-LSTM neural network can be regarded as
    a nonlinear alternative to the DSI-type of linear statistical interpolation method.
    The comparisons between DSI and RAE-LSTM proxy confirm that the application of
    our proposed data-driven prediction method can effectively obtain more robust
    predictions and thus support rapid and reliable decision-making during the process
    of real-time waterflooding production management and optimization.
  doi: 10.1016/j.geoen.2023.212252
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Waterflooding production
    forecast under geological uncertainty 3. Methodology 4. Illustrative examples
    and discussion 5. Conclusions CRediT authorship contribution statement Declaration
    of competing interest Acknowledgements Data availability References Show full
    outline Cited by (1) Figures (22) Show 16 more figures Tables (3) Table 1 Table
    2 Table 3 Geoenergy Science and Engineering Volume 230, November 2023, 212252
    Robust production forecast and uncertainty quantification for waterflooding reservoir
    using hybrid recurrent auto-encoder and long short-term memory neural network
    Author links open overlay panel Cong Xiao a b, Shicheng Zhang a b, Xingfang Ma
    a b, Tong Zhou c, Tengfei Hou d, Fushan Chen e Show more Share Cite https://doi.org/10.1016/j.geoen.2023.212252
    Get rights and content Highlights • We present a deep-learning-based production
    forecast without performing history matching. • We construct a neural network
    proxy by hybridizing auto-encoder and long short-term memory neural network. •
    The computational cost is significantly reduced while the accuracy remains satisfactory.
    Abstract History-matching-based production forecast and uncertainty quantification
    are essential to achieve reliable risk assessment for waterflooding reservoir
    in the community of petroleum engineering, however, the conventional model-based
    history matching procedure presents intensive computation-cost due to numerous
    high-fidelity reservoir simulations. The use of direct forecast approach, e.g.,
    data-space inversion (DSI) and its variants, is urgent to achieve direct production
    forecast without explicitly performing history matching. This work presents a
    generic data-driven post-history production forecasting framework using a novel
    deep recurrent neural network. We construct a hybrid recurrent neural network
    proxy through combining recurrent autoencoder with long short-term memory neural
    network, e.g., referred to as RAE-LSTM. The proposed RAE-LSTM takes history prediction
    and post-history well controls as input, while the post-history production responses
    (oil and water production, water injection rate) as output. Training samples are
    constructed by simulating high-fidelity models parameterized with various post-history
    well-controls and geomodels. Once the deep recurrent neural network proxies are
    trained offline, the online post-history production forecast and uncertainty quantification
    can be efficiently achieved by input user-specific well control sequences and
    history measurement. The proposed proxy model is demonstrated on two examples
    with varying complexity, e.g., a synthetic 2D Gaussian model and a 3D channelized
    EGG model. The use of our proposed RAE-LSTM neural network can be regarded as
    a nonlinear alternative to the DSI-type of linear statistical interpolation method.
    The comparisons between DSI and RAE-LSTM proxy confirm that the application of
    our proposed data-driven prediction method can effectively obtain more robust
    predictions and thus support rapid and reliable decision-making during the process
    of real-time waterflooding production management and optimization. Previous article
    in issue Next article in issue Keywords Waterflooding reservoirProduction forecastingData-space
    inversionDeep-learning surrogateUncertainty quantification 1. Introduction The
    post-history production forecasting is generally performed based on an ensemble
    of posterior geomodels from the reservoir history matching step in the field of
    petroleum engineering. The reservoir history matching is generally resolved by
    adjoint/gradient-based optimization or ensemble-based data assimilation methods,
    during which numerous high-fidelity model simulations are required and thus leads
    to intensive computation-cost, especially for the real-field applications (Bukshtynov
    et al., 2015). Currently, popular production prediction approaches can be mainly
    divided into two categories, namely statistical decline analysis approaches and
    machine learning approaches. Traditional decline curve analysis (Arps, 1945),
    regression models (Davtyan et al., 2020), grey theory (Wei et al., 2011) and conventional
    time-series forecasting methods (Olominu and Sulaimon, 2014), such as Autoregressive
    model (AR), Vector AR model, Moving average model (MA), Autoregressive moving
    average (ARMA) and Autoregressive integrated moving average (ARIMA) (Pappas et
    al., 2008), belong to the statistical approaches. They use empirical or regression
    equations to characterize the relationship between historical production data
    and future production and thus make forecasts. However, when production data is
    fluctuating and non-stationary, unsatisfactory prediction results usually occur
    because they cannot take operational adjustments into account. To accelerate the
    reservoir simulation process, many deep-learning surrogate models have been recently
    proposed in the literature (Kim et al., 2021, Lu et al., 2017). Over the past
    few decades, machine learning approaches have prevailed in the production prediction
    domain with the evolvement of hardware and software and the accumulation of field
    production data. Support vector regression (Ng et al., 2021, Zhang and Jia, 2021),
    ensemble learning (e.g., Random forest and Boosting) (Liu et al., 2020) and Artificial
    neural networks (Feder, 2020, Kenari, 2013) are frequently employed for well production
    forecasting. Among them, Artificial neural networks are widely accepted due to
    their flexible architecture and strong nonlinear mapping ability. With the increasing
    complexity of application scenarios and the demand for prediction accuracy, the
    types and structures of neural networks applied to production forecasting are
    enriched. Deep learning models are introduced to alleviate the problem of training
    difficulties and gradient disappearance caused by shallow neural networks. Wang
    et al. (2019) adopted deep neural networks with three hidden layers and 200 neurons
    per layer to predict the cumulative production of 6 months and 18 months. To infer
    future time-series production, various deep learning models such as Recurrent
    neural network (RNN), Convolutional neural network (CNN), Long short-term memory
    (LSTM), Gated recurrent unit (GRU), Bidirectional LSTM (BiLSTM) and Bidirectional
    GRU (BiGRU) are developed. Sun et al. (2018) compared the performance of RNN and
    traditional decline curve analysis in time-series production prediction and concluded
    that RNN is capable of better capturing nonlinear characteristics of production
    series. Lee et al. (2019) applied LSTM to forecast shale gas production considering
    shut-in time as an external feature. Hung et al. (2022) also built an LSTM model
    for oil rate prediction, whose structure was optimized by Genetic algorithm. Li
    et al. (2022) constructed an LSTM model to imply the time-series production of
    producers in a carbonate reservoir and found that the prediction error and computing
    time were much lower than traditional reservoir simulation. GRU model was built
    for long-term production prediction of tight oil wells, which has a simpler cell
    structure and comparable forecasting performance compared with LSTM. Xiong et
    al. (2020) tried four deep learning models for oil and gas production prediction,
    namely GRU, GRUconv, Seq2Seq and CNN and concluded that appropriate architecture
    was essential for performance improvement. Li et al. (2021) first introduced BiGRU
    optimized by Sparrow search algorithm for oil rate prediction, which compensated
    for the unidirectional flow of information flow and significantly improved prediction
    accuracy compared with decline curve analysis, ARIMA, RNN, LSTM and GRU. The applications
    of deep-learning surrogate models to address reservoir history matching and production
    prediction have been initiated recently. For example, Ma et al., 2022b, Li et
    al., 2022 and Ma et al. (2022a) proposed a set of surrogate-based history matching
    approaches based on the recurrent neural network. In these methods, the convolutional
    neural network is used to extract spatial features of the geological permeability,
    and these compressed features are then fed to recurrent neural network for the
    well responses predictions. Kim and Durlofsky (2021) proposed a deep-learning-based
    well-control optimization using a recurrent neural network model. The recurrent
    neural network takes the time-series well controls as inputs and predicts temporal
    well responses (e.g., oil and water production rate). Wang et al. (2022) proposed
    a comprehensive deep learning surrogates to address closed-loop optimization of
    geothermal reservoirs development. Different from the previous deep-learning proxy
    for solely history matching or production optimization, the geomodel and time-series
    well control sequence are simultaneously regarded as the inputs. The convolutional
    autoencoder–decoder and recurrent neural network are employed to extract the spatial
    geological features and the well controls, respectively. This hybrid recurrent
    neural network can predict the time-varying well responses corresponding to different
    combinations of geomodel and well control settings. Although both the reservoir
    history matching has been simultaneously accelerated by the above deep-learning
    proxy models, the inherent issue related to the original history matching remains.
    The low quality of history-matched geomodel inevitably leads to unreliable production
    optimization. It thus will be very urgent to find an alternative that under considering
    the history measurements we still can perform robust production forecast without
    actually conducting the complex history matching step. The direct forecast approach,
    e.g., data-space inversion (DSI) and its variants, falls into this classification
    (Sun and Durlofsky, 2017, Lima et al., 2020). Through implicitly fusing information
    from the history measurements, the DSI is to directly obtain an ensemble of posterior
    predictions without actually implementing history matching step. Sun et al. (2017)
    and Sun and Durlofsky (2019) originally applied DSI method to address uncertainty
    estimation and production prediction for complex fractured reservoirs and carbon
    dioxide storage applications. Liu et al. (2021) applied DSI method to rapidly
    predict the reservoir state field of waterflooding oilfield, such as saturation
    and pressure field, through the observed production data. Subsequently, Jiang
    et al. (2019) proposed a variant of DSI, i.e., data-space inversion with varying
    control, to predict post-history production performance for user-specified well-control
    in the process of close-loop reservoir management. This paper presented an efficient
    alternative that directly implements the production forecasting without the explicit
    implementation of history matching process. Specifically, we propose an efficient
    and robust data-driven computational framework for post-history production forecasting
    through hybridizing recurrent autoencoder and long short-term memory neural network.
    The remainder of this paper is organized as follows. Formula of the waterflooding
    production forecast under geological uncertainty is described in Section 2. Section
    3 introduces a novel hybrid recurrent neural network for post-history production
    forecasting. Section 4 discusses and evaluates some numerical results of synthetic
    and benchmark reservoir models using our considered computation framework. Finally,
    Section 5 summarizes our contributions and discusses the future work. 2. Waterflooding
    production forecast under geological uncertainty Waterflooding is the most widely
    used developing strategy to increase the oil recovery after the primary production
    stage. Details about the dynamic equations for a two-phase oil–water system can
    be referred to Ewing (1983). To simplify the notation, an explicit formula of
    well response as a function of well controls is directly given here. The relationship
    between simulated data , e.g., time-series oil and water liquid rate for producers
    and water injection rate for injectors, and well controls can be described using
    a nonlinear operator as follows. (1) where, [ , , …, , …, ] denotes the time-series
    vector of well controls, e.g., bottom-hole pressure, fluid rate or smart inflow
    control valve for all wells at all control steps. . The simulated data , e.g.,
    oil and water liquid rate for producers and water injection rate for injectors.
    is a vector of well control for all wells at the timestep . is the number of well
    response, e.g., oil/water rate or water injection rate at each timestep. is the
    number of well controls at each timestep. is the total number of simulation steps.
    denotes the geomodel parameters, such as rock porosity and permeability. The grid-based
    permeability is the uncertain parameter in the study. Conventional model-based
    history matching firstly uses the history measurements to obtain the posterior
    geomodels and then predicts the post-history well production correspondingly.
    The represents a vector of the time-series well production response by running
    a reservoir model simulation. This vector contains the history prediction and
    post-history prediction , that is, [ , ]. As mentioned previously, the direct
    forecast approaches, e.g., data-space inversion (DSI) and its variants, are effective
    alternatives to perform production forecast under geological uncertainty. Through
    considering the history observations, DSI is able to directly achieve the posterior
    predictions without explicitly performing time-consuming history matching step.
    Subsequently, to further extend DIS approach to address close-loop reservoir management,
    Jiang et al. (2019) proposed a variant of DSI with varying controls, i.e., DSIVC,
    to predict post-history production performance for user-specified well-controls.
    The DSIVC is an extension of DIS to enable predict well performance for varying
    well controls at the post-history production period. Details related to the DSIVC
    procedure can be referred to the literature (Jiang et al., 2019). In DSIVC, the
    simulation results are determined by the post-history well controls, including
    bottom-hole pressure and/or injection rate, and geomodels, which can be presented
    as follows (2) where, is the number geomodel realizations. The well controls and
    geomodel are randomly generated. Note that well controls and geomodels are assumed
    to follow predefined statistic distribution. For example, the can be generated
    from an uniform distribution. In addition, the well controls usually need to satisfy
    constraints. The forward simulations corresponding to the ( , ) are run to achieve
    an ensemble of prediction results . Since the variance of the well controls are
    considered, the full dataset containing well controls, history predictions and
    post-history predictions can be presented as follows (3) As noted earlier, the
    DSIVC is able to predict future performance corresponding to specific well controls.
    Thus, the user-specific well controls are regarded as additional “observations”.
    We can combine well controls with history observations and history predictions
    to obtain two new “observations” vectors and respectively as follows (4) where,
    denotes the user-specific well controls, and represents the history observations.
    The vector can be specified arbitrarily inside any bound constraints. Similar
    to the conventional DSI procedure, the implementation of DSIVC for posterior predictions
    can be given as follows (5) where, represents the covariance matrix associated
    with the observation errors. is the prior prediction covariance. In the process
    of DSIVC scheme, since the well controls are specified, the elements inside corresponding
    to well controls should be zero values. To address the ill-posed issue of invert
    operation, we set these elements very small values instead of strict zero values,
    e.g., see Jiang et al. (2019). The accuracy of DISVC scheme mainly depends on
    the linear assumption between history data and post-history prediction. In the
    following parts, we will give detailed descriptions about how to effectively realize
    an efficient production forecast using our proposed recurrent neural network proxy
    model. The use of our proposed RAE-LSTM neural network can be regarded as a nonlinear
    alternative to the DSI-type of linear statistical interpolation method. The developed
    workflow utilizes deep-learning techniques to better handle the presence of non-linearities
    typical of real-life applications (e.g., well shut-ins) and also accounts for
    the variability of well controls to enable the use of the forecasts for uncertainty
    quantification purposes. 3. Methodology This section introduces a novel hybrid
    recurrent neural network for post-history production forecasting and uncertainty
    quantification. 3.1. Hybrid Recurrent Auto-Encoder neural network proxy: RAE-LSTM
    As noted earlier, given the specific history well-controls and history measurement
    , we generally history matching the observed data to correct the geomodel , and
    then predict the future well production corresponding to post-history well control
    . Note that and denote the counts of well controls (bottom-hole pressure and water
    injection rate) for each timestep at the history and post-history period, respectively.
    Assuming that represents the prediction of running reservoir numerical simulation,
    this vector contains the prediction data from the history production stage with
    time sequence and the prediction data at the post-history production stage with
    time sequence , that is, [ , ]. is a nonlinear function of geomodel and well control
    , which is comprised of history well control and post-history well control , e.g.,
    see Eq. (2). Note that and denote the counts of well responses (e.g., oil and
    water production, water injection) for each timestep at the history and post-history
    period, respectively. Without explicitly performing history matching step, we
    propose a hybrid recurrent neural network surrogate, i.e., RAE-LSTM, to achieve
    well response given the history data and post-history well control . The general
    formula of RAE-LSTM proxy model can be presented as follows, (6) where, denotes
    the hybrid recurrent neural network proxy model. 3.2. Description of RAE-LSTM
    structure The proposed RAE-LSTM is comprised of two parts, including the recurrent
    autoencoder and long short-term memory. The RAE part can extract time-series features
    of history data, while the LSTM part outputs the post-history time-series production
    responses (oil and water production for producers, water injection rate for injectors),
    respectively. These two parts can be presented as follows (7) and (8) where, represents
    the compressed latent variables for history data . , and represent neural network
    parameters for the RAE and LSTM parts, respectively. Our proposed RAE-LSTM is
    a type of hybrid recurrent convolutional neural network model. Many similar recurrent
    neural networks have been established to address time series production prediction
    in the field of petroleum engineering. For example, Ma et al., 2022b, Li et al.,
    2022 and Ma et al. (2022a) proposed a set of neural network proxy model based
    on the recurrent neural network. The convolutional neural network is used to extract
    spatial features of the geological permeability, and these compressed features
    are then fed to recurrent neural network for the well responses predictions. Kim
    and Durlofsky (2021) proposed a deep-learning-based well-control optimization
    using a recurrent neural network model. In this study, the proposed RAE-LSTM combines
    recurrent autoencoder and long short-term memory guided by Mohd Razak et al. (2022).
    This type of neural network structure is originally used for long-term production
    forecasting in unconventional reservoirs. To satisfy our purpose, we apply RAE-LSTM
    proxy model to address post-history forecast. A schematic diagram of the RAE-LSTM
    architecture is presented in Fig. 1. As shown in Fig. 1, the proposed RAE-LSTM
    surrogate model consists of a RAE-based time-series feature compression module
    and a LSTM-based time-series prediction module. Long Short-Term Memory (LSTM)
    Neural Network. The proposed RAE-LSTM includes two units, i.e., RAE and LSTM,
    both of which are related to the LSTM cell. For the first step, the details about
    the LSTM is presented here. LSTM cell as a variant of RNN has been widely used
    for long-time series applications, such as natural language processing (Xiao et
    al., 2020, Qing-Dao-Er-Ji et al., 2020), computer vision (Yang et al., 2020, Liu
    et al., 2017), and atmosphere dynamic prediction (Kiran et al., 2021, Sani, 2020).
    Download : Download high-res image (631KB) Download : Download full-size image
    Fig. 1. Architecture of the proposed RAE-LSTM surrogate model. Fig. 2 illustrates
    the basic cell structure of LSTM, which includes three gate-control units and
    one cell state. At the timestep , LSTM cells process the input vector (here is
    identical to the time series well control ), the short-term hidden state , and
    the long-term cell state to generate the output . The long-term state contains
    pertinent information from timesteps before . The short-term state contains information
    from the previous timestep. This provides the vectors , , , and as follows: (9)
    where, denotes the nonlinear function, is a sigmoid activation function. The matrices
    , , and are the weight matrices of four neural network layers that process the
    input . The matrices , , and are the weight matrices of four neural network layers
    that process the short-term state . The vectors , , and are the bias coefficients
    for the four layers. After that, another cell state will be determined to determines
    the portion of previous to be discarded at timestep . This is accomplished by
    performing element-wise multiplication using and . In addition, the output gate
    processes the updated long-term state and the output vector to produce the updated
    short-term state . Finally, we can process the updated short-term state using
    a fully connected layer of linear neurons to generate the final output vector
    . All these steps can be presented as follows (10) where, denotes an element-wise
    multiplication, and are the weight matrices and the bias terms for the output
    layer, respectively. Download : Download high-res image (167KB) Download : Download
    full-size image Fig. 2. The cell structure of LSTM structure. - - One of the most
    important components for RAE-LSTM is the recurrent autoencoder structure. The
    RAE has been widely used for time-series data representation and compression in
    the community of computer vision. In the community of petroleum engineering, Lima
    et al. (2020) combined autoencoder and long short-term memory network to perform
    time-series data compression. The RAE structure is shown in the first row of Fig.
    3. Unlike the conventional autoencoder structure mostly used for the spatial feature
    extraction, we integrate autoencoder with the LSTM network to extract the latent
    information from the time-series history data. The encoder part employs LSTM to
    compress the original time-series history data to produce the low-dimensional
    latent variables. Specifically speaking, the history data is comprised of well
    responses at time sequences. The LSTM unit will regard the history data , e.g.,
    oil and water production rate for all producers, water injection rate for all
    injectors, as the input at each time step 1, 2, …, . The time-series hidden state
    , 1, 2, …, , produced by the LSTM unit are further compressed to the latent space
    by a fully-connected layer. For the decoder part, a fully-connected layer is firstly
    used to achieve the time-series hidden state , 1, 2, …, , and then a stacked LSTM
    layers are employed to project the latent space variable back to the original
    time-series history data . As has been shown in Fig. 3, we use multiplied LSTM
    layers both in the encoder and decoder parts to perform this nonlinear mapping
    and feature extraction operation. The blue squares represent the basic LSTM cell.
    Overall, the encoder part and decoder part are symmetrical, both of which consist
    of multiple LSTM layers and a dense layer. To improve the performance of RAE structure,
    we should normalize the data to the range [0,1]. - - As noted earlier, the LSTM
    network in RAE-based time-series feature compression module is to compress the
    time-series history data into a low-dimensional latent space. In the LSTM-based
    time-series prediction module, the LSTM structure is employed to predict the post-history
    well response . The basic LSTM predictor architecture is shown in the second row
    of Fig. 4. After the latent space variable is achieved from the encoder part of
    RAE module, is combined with the post-history well controls for each time step
    1, 2, …, . That is, the combined vector [ , ] is the input of LSTM unit. The post-history
    well response for each time step 1, 2, …, will be produced through a stacked LSTM
    layers. Download : Download high-res image (340KB) Download : Download full-size
    image Fig. 3. Illustration of RAE-based time-series feature compression module
    and LSTM-based time-series prediction module. Download : Download high-res image
    (238KB) Download : Download full-size image Fig. 4. Illustration of RAE-based
    time-series feature compression module and LSTM-based time-series prediction module.
    3.3. Dataset preparation and network training The proposed RAE-LSTM regards history
    production responses and post-history well controls as input, while the post-history
    production responses (oil and water production, water injection rate) as output.
    Training samples are constructed by simulating high-fidelity models parameterized
    with various post-history well-control settings and geomodels. The simulated data
    can be organized as { , , ; } for the th training sample, 1, , . The loss functions
    corresponding to RAE-LSTM can be expressed as: (11) In this hybrid recurrent neural
    network, RAE and LSTM are jointly trained. In this study, this network is built
    in the deep-learning package (Paszke et al., 2019). The neural network parameters,
    including , and , are iteratively optimized by use of optimizer (Kingma and Ba,
    2014). 3.4. Forecast and uncertainty quantification Once the RAE-LSTM is trained,
    it can be used to directly obtain online post-history production forecast by feeding
    the model with input user-specific well control sequences and history measurements.
    That is, . The robust production predictions require us to provide an ensemble
    of posterior geomodels. In general, the generation of many posterior geomodels
    is performed by history matching a set of perturbed measurements. In terms of
    RAE-LSTM, we also can generate an ensemble of perturbed measurements by adding
    noise to the history observation and then fed them to the RAE-LSTM proxy model.
    The uncertainty of the post-history predictions can then be quantified over an
    ensemble of noisy measurements (12) where, and represents the th measurement noise
    vector and post-history prediction, respectively. The proposed data-driven post-history
    production forecasting and uncertainty quantification framework is comprised of
    three modules. Firstly, a preset amount of prior realizations of geomodels, e.g.,
    1000, are randomly generated. The corresponding same amount of post-history well-controls
    are also sampled from preset bounds [ , ], e.g., see Eq. (5), while the history
    well-controls should be known and thus keep constant for all geomodels. A set
    of one-to-one combination of geomodel and well control is used to generate the
    time-series production dataset by running high-fidelity model simulations. Secondly,
    the RAE-LSTM surrogate model is trained and assessed by the training samples and
    testing samples, respectively. The hype-parameters are also optimized by the validation
    samples. Finally, the uncertainty of the post-history predictions can then be
    quantified by feeding an ensemble of noisy measurements to the RAE-LSTM proxy
    model. Download : Download high-res image (723KB) Download : Download full-size
    image Fig. 5. Illustration of well placement and three random permeability realizations
    for the 2D synthetic Gaussian model. Table 1. Important parameters of the 2D Gaussian
    model and 3D Egg model using OPM- simulator. Parameters Gaussian model Egg model
    Dimension 40 × 120 × 1 60 × 60 × 7 Number of wells 6 producers, 4 injectors 4
    producers, 8 injectors Controlled wells 4 injectors 8 injectors Number of time
    steps, 120 120 Number of control times, 10 27 4. Illustrative examples and discussion
    In this section, two waterflooding reservoirs: (1) Example 1: a synthetic 2D Gaussian
    model; (2) Example 2: a 3D channelized EGG model (Jansen, 2011), are used to verify
    our proposed method. In the example of production optimization, Open Porous Media
    (OPM), a free open-source software for reservoir modelling and simulation (Rasmussen
    et al., 2019), is used to run the high-fidelity model simulations. The basic model
    settings are shown in Table 1. 4.1. Description of reservoir models In Example
    1, the 2D Gaussian reservoir model describes a two-phase water-flooding system.
    Six producers and four injectors are regularly located in this reservoir, e.g.,
    see the first subfigure of Fig. 5. Fig. 5 also illustrates additional two random
    realizations of geomodels, indicating the geological uncertainty. Each simulation
    step includes 30 days, finishing on total 3600 days. This corresponds to 120 simulation
    times, at each of which the injection and production rates at the wells are recorded.
    During this period, however, control at the four injection wells is only exerted
    every 180 days, resulting in totally 20 times at which the control is adjusted.
    Here, control is exerted through injection rate. At the control times, the input
    at each well can be adjusted to be any value in this domain , here 0 m3/day and
    100 m3/day, after which it will remain constant until the next control time. The
    first 1800 days are regarded as the history production period, while the well
    controls at the remaining 1800 days need to be optimized. Controls of four injectors
    are optimized at 10 time instances, resulting in totally 40 decision variables.
    Example 2 describes the 3D channelized EGG reservoir model with four producers
    and eight injectors, e.g., see the first subfigure of Fig. 6. Fig. 6 also display
    another two random realizations of EGG models and the non-Gaussian channelized
    features can be clearly observed. Compared to the 2D Gaussian model, the Egg model
    appears significantly more often in studies on reservoir flow. The production
    wells located halfway towards the edge of the reservoir, enclosed by the injection
    wells. The Egg model is run over a period of 3600 days, During this time, the
    simulations are computed every 30 days, amounting to a total of 120 simulation
    times as well. Control, however, can only be exerted at 40 times, allowing the
    rates to be adjusted every three timesteps of the simulation. At these injection
    wells, control can be exerted directly through the rate of injected flow, fixed
    to assume values between m3/day and m3/day. At the production wells, no control
    can be exerted, with the bottom-hole pressure at these wells fixed at 42 MPa at
    all times. The first 1200 days are regarded as the history production period,
    while the well controls at the remaining 2400 days need to be optimized. Controls
    of eight injectors are optimized at 27 time instances, resulting in totally 216
    decision variables. Download : Download high-res image (990KB) Download : Download
    full-size image Fig. 6. Illustration of well placement and three random permeability
    realizations for the 3D EGG model. 4.2. Quality assessment of RAE-LSTM proxy models
    The details about the RAE-LSTM architecture are described in Table 2. In this
    study, 1000 one-to-one combinations of geomodels and well controls are randomly
    generated to achieve prior model simulations through running high-fidelity models.
    Among them, 100, 300, 500 and 800 simulations are used to analyse the sensitivity
    of RE-LSTM proxy model with respect to the number of training samples. The remaining
    200 simulations are divided into 100 validation samples and 100 testing sample
    to optimize hype-parameters and assess the accuracy of RAE-LSTM, respectively.
    In this work, RAE-LSTM regards the history well response (time-series oil and
    water production rate at the history production period) and post-history time-series
    water injection rate as input, while the post-history production responses (oil
    and water production rate for the producers) as output. Table 2. Illustration
    of RAE-LSTM architecture. Taking a two layers LSTM as an example here. Unit Layer
    Input size Output size RAE Input ( , ) – LSTM layer 1 for encoder ( , ) ( , )
    LSTM layer 2 for encoder ( , ) ( , ) LSTM layer 1 for decoder ( , ) ( , ) LSTM
    layer 2 for decoder ( , ) ( , ) LSTM Input ( , ) – ( , ) ( , ) LSTM layer 1 for
    encoder ( , ) ( , ) LSTM layer 2 for encoder ( , ) ( , ) FC layer ( , ) ( , )
    The relative error of predicted well responses between high-fidelity model and
    the RAE-LSTM proxy model is regarded as an indicator to assess the proxy quality.
    In these two examples, the water injection rate of all injectors are the input
    variables, while the oil and water production rate of all producers are the output
    variables. Thus, the average relative error of oil and water production rate over
    testing samples is given by (13) where, , and , separately denote the oil and
    water production rate predicted from HFM and RAE-LSTM proxy model for the testing
    sample , well at the timestep . For the first step, the grid-search method is
    used to optimize the hyper-parameters from the pre-defined bounds. The optimized
    hyper-parameters are listed in Table 3. Note that the RAE-LSTM proxy models are
    trained with 800 samples. Comparing to the 2D Gaussian model, more hidden state
    size and LSTM layers are required to capture the temporal dynamic of 3D EGG model.
    Fig. 7 displays the evolution of logarithmic loss functions with respect to the
    hype-parameters for the 2D Gaussian model and 3D EGG model. It clearly can be
    observed that the optimal hype-parameters indeed obtain the smallest loss function
    values. To investigate the overfitting issue at the offline training of the RAE-LSTM
    proxy model, we also display the evolution of the training and testing loss functions
    with respect to the epochs, e.g., see Fig. 8. In these two figures, the results
    are based on the optimal hype-parameters, and the overfitting problem does not
    occur as the iteration proceeds, which are indicated by continuous reduction of
    both training and testing loss functions. Fig. 9 shows the boxplot of relative
    error with respect to the training sample size for these two reservoir models.
    Generally speaking, the smaller the value, the better the predictability of the
    RAE-LSTM proxy model. The accuracy of the RAE-LSTM proxy model improves as the
    number of training samples. It can be seen that the prediction accuracy of the
    proxy model is almost satisfactory indicated by relatively low values, e.g., lower
    than 5% especially for the 3D EGG model. As we can see from Fig. 9, the median
    values are reduced from 11% to 8% for the 2D Gaussian model, by contrast, it has
    been reduced from 5% to 3% for the 3D EGG model. In this study, using solely 100
    training samples almost can achieve relatively accurate RAE-LSTM proxy model for
    the 3D EGG model, while the 800 training samples are required by the 2D Gaussian
    model. Table 3. Hyper parameter optimization results of RAE-LSTM model for Example
    1. Hype-parameters Ranges Example 1 Example 2 Hidden state size, [32, 64, 128]
    64 128 Number of layers, [1, 2, 3] 1 2 Learning rate, [1 × 10−2, 1 × 10−3, 1 ×
    10−4] 1 × 10−3 1 × 10−4 – 0.053 0.028 Download : Download high-res image (396KB)
    Download : Download full-size image Fig. 7. Evolution of logarithmic loss functions
    with respect to the hype-parameters corresponding to the 2D Gaussian model. Download
    : Download high-res image (385KB) Download : Download full-size image Fig. 8.
    Evolution of logarithmic loss functions with respect to the hype-parameters corresponding
    to the 3D EGG model. The previous error analysis reveals a satisfactory degree
    of accuracy in the well responses prediction by use of the RAE-LSTM proxy model.
    The figures illustrating the post-history time-series production responses (oil
    and water production, water injection rate) are used to visually assess the quality
    of the RAE-LSTM proxy model, e.g., see Fig. 10, Fig. 11. The red lines and blue
    lines denote the simulation results from high-fidelity model (HFM) and RAE-LSTM
    proxy model, respectively. The abrupt shifts evident at 180-day and 90-day intervals
    result from changes in well injection rate for the injectors. In Fig. 10, the
    results presented in the figure correspond to all six production wells for the
    2D Gaussian model. It is obviously found that the RAE-LSTM proxy model achieves
    accurate predictions for all well responses over this wide range of responses.
    Note that the prediction of oil production is relatively more accurate than that
    of water production, especially when the water breakthrough does not occur at
    the history production period, e.g., producer P3, since the water breakthrough
    generally exhibits strong non-linearity. Similar results also can be found in
    Fig. 11. It clearly can be seen that the RAE-LSTM proxy model is capable of predicting
    the post-history time-series production responses with a high accuracy, especially
    for the 3D EGG model. Although the frequent shifts of the well controls lead to
    the abrupt changes of the well responses, e.g., see the oil and water production
    rate curves, these complex patterns of well production still can be captured by
    our proposed RAE-LSTM proxy model. Download : Download high-res image (229KB)
    Download : Download full-size image Fig. 9. Boxplot of relative error with respect
    to the training sample size for (a) synthetic 2D Gaussian model; (b) 3D channelized
    EGG model. The cross-plots displaying comparisons between RAE-LSTM results and
    HFM simulation results for cumulative oil and water production over all 100 testing
    samples are shown in Fig. 12. Since the RNN-based proxy model estimates well-by-well
    oil and water rates as a function of time, these cumulative field-wide results
    are computed by integrating over time and summing over all injectors or producers.
    The results for oil production display the most scatter, although the range for
    this quantity is still relatively small. A larger range in results, and a higher
    degree of accuracy, is observed for water production, with all points closing
    to the black diagonal lines. Download : Download high-res image (666KB) Download
    : Download full-size image Fig. 10. Post-history time-series production responses
    (oil and water production, water injection rate) by the RAE-LSTM proxy model for
    2D Gaussian model. The first six subfigures are the oil production curves, the
    remaining six subfigures are the water production curves. Download : Download
    high-res image (633KB) Download : Download full-size image Fig. 11. Post-history
    time-series production responses (oil and water production) by the RAE-LSTM proxy
    model for 3D channelized EGG model. The first four subfigures are the oil production
    curves, the remaining four subfigures are the water production curves. In terms
    of computational effort, the runtime for simulating a 2D synthetic Gaussian model
    and 3D EGG model are about 15 and 80 s respectively. The simulation time of a
    trained RAE-LSTM using an NVIDIA Tesla P100 GPU card requires is about 0.1 s,
    which are almost negligible compared with the high-fidelity model simulation.
    However, the computational cost related to construction of RAE-LSTM mainly includes
    the sample generation and model training. Since the prediction of time-series
    well production, e.g., oil and water rate, does not require complex deep-learning
    model compared with the predictions of model states, e.g., grid-based saturation
    and pressure. In our case-study, the training of RAE-LSTM needs about 5–8 min
    for both cases. The generation of training samples using original high-fidelity
    model simulations is the most intensive computation-part, e.g., 1000 training
    samples. The RAE-LSTM will become significantly useful in the situation where
    the HFM simulations are repeatedly performed, e.g., waterflooding reservoir production
    optimization and uncertainty quantification. The proxy-based uncertainty quantification
    for post-history production prediction is presented in the following section.
    Download : Download high-res image (249KB) Download : Download full-size image
    Fig. 12. Test-case cross-plots for cumulative field-wide oil and water production
    corresponding to (a) 2D Gaussian and (b) 3D EGG model, respectively. 4.3. Uncertainty
    quantification by RAE-LSTM proxy models The uncertainty quantification of post-history
    oil and water production generally depends on an ensemble of posterior reservoir
    geomodels through history matching noise measurements. The proposed RAE-LSTM proxy
    model enables us to directly predict the post-history oil and water rate without
    performing reservoir history matching. The generation of many posterior geomodels
    is performed by history matching a set of perturbed measurements. As shown in
    Eq. (12), we can generate an ensemble of perturbed measurements by adding noise
    to the history observation and then fed them to the RAE-LSTM proxy model. The
    uncertainty of the post-history predictions can then be quantified over an ensemble
    of noisy measurements. We investigate the influences of measurement noise on the
    post-history production prediction by use of RAE-LSTM proxy model. The synthetic
    noisy measurements can be generated as the following two steps: Firstly, the reference
    data (e.g., time-series oil and water production at the history period) are simulated
    from the reference model. Secondly, normally distributed measurement noise with
    a standard deviation equal to a certain ratio of the reference data are randomly
    generated. In this study, we set the ratio to be 10%, 20% and 30%, respectively.
    Fig. 13, Fig. 14 show the post-history well response predictions with respect
    to different observation errors for the 2D Gaussian model and 3D EGG model, respectively.
    In all subfigures, the grey, blue and red lines denote the prior, posterior and
    reference oil and water rate predictions at the post-history period. Compared
    with the prior models, the uncertainty of posterior post-history production predictions
    is significantly reduced after considering the history measurements. As the observation
    errors decrease, the ensemble spread of posterior predictions gradually becomes
    narrower and closer to the reference values, e.g., the red lines. Compared with
    the 3D EGG model, the time-series oil and water production dynamic varies significantly
    for the 2D Gaussian models, which explain why we can obtain more accurate RAE-LSTM
    proxy model for the 3D EGG model. Different wells also show varying sensitivity
    to the observation errors. For example, the RAE-LSTM proxy model can simultaneously
    predict accurate oil and water production rate for the Producer P1 even when we
    set the 30% observation errors. By contrast, for the producer P2, the water rate
    predictions are more accurate than that of oil rate predictions. Fig. 15, Fig.
    16 display the cumulative probability distribution results of oil and water production
    rate corresponding to three different production times (i.e., 2400 days, 3000
    days and 3600 days) under different measurement noise level. Compared with the
    prior model predictions (e.g., see the blue lines), the variation ranges of posterior
    models are significantly reduced, which indicates the uncertainty reduction of
    posterior well predictions. The range of curves contains the reference values
    (e.g., the black vertical lines), and the P50 values are very close to the real
    reference value. Through the statistical analysis of the posterior prediction
    results, the P50 values of oil and water production rate obtained by the RAE-LSTM
    proxy model under different measurement noise level. It also can be revealed that
    the measurement noise level mainly determines the uncertainty range, while the
    P50 values are almost not influenced. These results indicate that the prediction
    results of the RAE-LSTM proxy model have high reliability and robustness. It can
    not only rapidly predict the post-history well production, but also quantify the
    production uncertainty and thus reduce the development risk. Download : Download
    high-res image (1MB) Download : Download full-size image Fig. 13. Post-history
    time-series production responses (oil and water production for all producers)
    under measurement noise by the RAE-LSTM proxy model for 2D Gaussian model. Download
    : Download high-res image (1MB) Download : Download full-size image Fig. 14. Post-history
    time-series production responses (oil and water production, water injection rate)
    under measurement noise by the RAE-LSTM proxy model for 3D channelized EGG model.
    Download : Download high-res image (584KB) Download : Download full-size image
    Fig. 15. Cumulative probability distribution results of oil and water production
    rate corresponding to three different production times (i.e., 2400 days, 3000
    days and 3600 days) under different measurement noise level for the 2D synthetic
    Gaussian model. Download : Download high-res image (605KB) Download : Download
    full-size image Fig. 16. Cumulative probability distribution results of oil and
    water production rate corresponding to three different production times (i.e.,
    2400 days, 3000 days and 3600 days) under different measurement noise level for
    the 3D channelized EGG model. 4.4. Comparison between RAE-LSTM and data-pace inversion
    The data-space inversion with varying controls (DSIVC) has been proposed to achieve
    the post-history production forecast in the literature. Subsequently, the performance
    of DSIVC is further improved by involving a novel recurrent autoencoder deep-learning
    model for data parameterization. Our proposed RAE-LSTM neural network can be regarded
    as a nonlinear alternative to the DSIVC of linear statistical interpolation method.
    Some comparisons between DSIVC and RAE-LSTM are thus conducted in this section.
    In this work, The data reparameterization can be conducted by RAE structure, which
    has been shown in Fig. 3. The history data and post-history data are parameterized
    by the RAE, respectively. All these 1000 prior model simulations that used in
    training RAE-LSTM proxy model are also employed to train the RAE structure. Here
    we take the results of data parametrization for the synthetic 2D model as an example.
    Fig. 17 shows the crossplots of original oil/water rate and reconstructed oil/water
    rate corresponding to the history and post-history production period. The history
    oil/water production dynamic can be better reconstructed than that of post-history
    oil/water production dynamic, which might be caused by the varying post-history
    well controls. Fig. 18 depicts the original oil/water rate and reconstructed oil/water
    rate for two producers. The well production dynamic almost can be accurately captured,
    especially the abrupt shifts of the oil rate and water rate. Here the 20% noise
    measurement level is used to generate an ensemble of perturbed measurements, and
    then the corresponding post-history well productions with the specific well controls
    are obtained by separately performing DSIVC and RAE-LSTM proxy model. Fig. 19,
    Fig. 20 show the prior and posterior predictions of the oil and water production
    dynamic for the synthetic 2D model and 3D channelized EGG model, respectively.
    The grey and red lines denote the prior models and true model, while the blue
    and green lines denote the posterior results for the RAE-LSTM and DSIVC, respectively.
    These two figures confirm that the RAE-LSTM proxy model can achieve more robust
    results than DSIVC, indicated by lower variance and uncertainty of posterior predictions.
    The relationship between history data and post-history predictions generally satisfies
    non-linearity, and thus violates the linear statistical assumption of the DSIVC
    approach. Download : Download high-res image (924KB) Download : Download full-size
    image Fig. 17. Crossplots of original oil/water rate and reconstructed oil/water
    rate corresponding to the history and post-history production period for the synthetic
    2D model. Download : Download high-res image (767KB) Download : Download full-size
    image Fig. 18. Illustration of the original oil/water rate and reconstructed oil/water
    rate for two producers. To further evaluate the robustness of RAE-LSTM proxy model,
    we now apply it for another five different true models. The 20% noise measurement
    level is used again to generate an ensemble of perturbed measurements. Fig. 21,
    Fig. 22 displays boxplots of relative errors of oil and water production rate
    corresponding to DSI and RAE-LSTM methods. We should note that none of these five
    true models is included in the 1000 prior realizations. It can be clearly observed
    that the uncertainty reductions achieved using both DSI and RAE-LSTM methods,
    relative to prior predictions, are substantial. In addition, the RAE-LSTM method
    also obtains smaller relative errors than that of DSIVC. The RAE-LSTM proxy model
    is trained by 800 samples. Importantly, 800 training samples are almost enough
    to provide satisfactory results for these different five cases. Once the RAE-LSTM
    proxy model is trained offline, the uncertainty quantification of post-history
    predictions does not involve any additional high-fidelity model simulations. Download
    : Download high-res image (806KB) Download : Download full-size image Fig. 19.
    Post-history time-series production responses (oil and water production, water
    injection rate) under measurement noise by the DSIVC and RAE-LSTM proxy model
    for the synthetic 2D Gaussian model. Download : Download high-res image (716KB)
    Download : Download full-size image Fig. 20. Post-history time-series production
    responses (oil and water production, water injection rate) under measurement noise
    by the DSIVC and RAE-LSTM proxy model for the 3D channelized EGG model. Download
    : Download high-res image (228KB) Download : Download full-size image Fig. 21.
    Boxplots of relative errors of oil and water production rate corresponding to
    DSI and RAE-LSTM methods for the synthetic 2D Gaussian model. Download : Download
    high-res image (237KB) Download : Download full-size image Fig. 22. Boxplots of
    relative errors of oil and water production rate corresponding to DSI and RAE-LSTM
    methods for the 3D channelized EGG model. 5. Conclusions Robust production forecasting
    and management of waterflooding reservoir under geological uncertainty generally
    involve continuous implementation of history matching. Traditionally, these steps
    are performed by testing various design scenarios through repeatedly running high-fidelity
    reservoir simulations and therefore presents computational infeasibility in practical
    applications. We construct a RNN-proxy through combining recurrent autoencoder
    and long short-term memory neural network. The RAE structure can compress time-series
    information of history data, while the LSTM structure can approximate time-series
    output, e.g., oil and water production, water injection rate. Without explicitly
    performing history matching step, the history data can be indirectly used to guide
    the post-history production optimization and thus achieve more reliable well-control
    settings. The performance of the new approach has been initially assessed through
    a synthetic 2D Gaussian model and a benchmark 3D channelized EGG model for practical
    production demonstration. The proposed approach is compared with the conventional
    implementation using only high-fidelity reservoir simulations. The obtained results
    show that our proposed surrogate-based direct forecast approach is significantly
    efficient to obtain satisfactory results. The use of RAE-LSTM proxy modelling
    prompts the uncertainty quantification procedure to reach convergence rapidly,
    which allows much fewer full-physic simulations to obtain the statistic analysis
    within a very short time frame. It will be also very promising to apply our proposed
    method to complex reservoir models, e.g., non-Gaussian faces model and naturally
    fractured models. The calibrations of these geomodels using history matching step
    are very challenging. Future work will focus on wider application of the proposed
    algorithm to deal with other complex field applications, e.g., compositional CO
    -EOR and geothermal production. In this study, the conventional multi-layer LSTM
    is used as the proxy model, some other comparable recurrent neural network, e.g.,
    gated-recurrent unit (GRU), convolutional-LSTM, Bidirectional-LSTM, and attention-based
    method which overall performs better than LSTM model also deserve to explore and
    compare in our future work. CRediT authorship contribution statement Cong Xiao:
    Software modelling, Data formal analysis, Writing. Shicheng Zhang: Supervision,
    Funding acquisition, Conceptualization. Xingfang Ma: Supervision, Funding acquisition,
    Conceptualization. Tong Zhou: Investigation, Reviewing. Tengfei Hou: Investigation,
    Reviewing. Fushan Chen: Investigation, Reviewing. Declaration of competing interest
    The authors declare that they have no known competing financial interests or personal
    relationships that could have appeared to influence the work reported in this
    paper. Acknowledgements This work is supported by Science Foundation of China
    University of Petroleum, Beijing, China (No. 2462021BJRC005) and Key Technologies
    of Mahu Conglomerate Reservoir, China (No. ZLZX2020-01-04). Computing resources
    are provided by Department of Petroleum Engineering at China University of Petroleum,
    Beijing. The use of open-source reservoir simulator OPM- (https://opmproject.org/)
    is gratefully acknowledged. Data availability Data will be made available on request.
    References Arps, 1945 Arps J. Analysis of decline curves Petroleum Transactions
    (1945), pp. 228-247 Google Scholar Bukshtynov et al., 2015 Bukshtynov V., Volkov
    O., Durlofsky L.J., Aziz K. Comprehensive framework for gradient-based optimization
    in closed-loop reservoir management Comput. Geosci., 19 (4) (2015), pp. 877-897
    CrossRefView in ScopusGoogle Scholar Davtyan et al., 2020 Davtyan A., Rodin A.,
    Muchnik I., Romashkin A. Oil production forecast models based on sliding window
    regression J. Pet. Sci. Eng., 195 (2020), p. 107916 View PDFView articleView in
    ScopusGoogle Scholar Ewing, 1983 Ewing R.E. The mathematics of reservoir simulation
    Front. Appl. Math., 1 (1983) Google Scholar Feder, 2020 Feder J. Heavy-oil steamflood
    validates machine-learning-assisted model J. Pet. Technol. (72–1) (2020) Google
    Scholar Hung et al., 2022 Hung, N.V., Loc, L.K., Huong, N., Dung, N.V., Quy, N.M.,
    2022. Applied Machine Learning and Deep Learning to Predict Oil and Gas Production.
    In: Vietnam Symposium on Advances in Offshore Engineering. Google Scholar Jansen,
    2011 Jansen J. Adjoint-based optimization of multi-phase flow through porous media–a
    review Comput. & Fluids, 46 (1) (2011), pp. 40-51 View PDFView articleView in
    ScopusGoogle Scholar Jiang et al., 2019 Jiang S., Sun W., Durlofsky L.J. A data-space
    inversion procedure for well control optimization and closed-loop reservoir management
    Comput. Geosci. (3–4) (2019) Google Scholar Kenari, 2013 Kenari S. An optimized
    ensemble for predicting reservoir rock properties in petroleum industry (2013)
    Google Scholar Kim and Durlofsky, 2021 Kim Y.D., Durlofsky L.J. A Recurrent Neural
    Network–Based Proxy Model for Well-Control Optimization with Nonlinear Output
    Constraints SPE J., 26 (04) (2021), pp. 1837-1857, 10.2118/203980-PA View in ScopusGoogle
    Scholar Kim et al., 2021 Kim J., Lee K., Choe J. Efficient and robust optimization
    for well patterns using a PSO algorithm with a CNN-based proxy model J. Pet. Sci.
    Eng. (1) (2021), Article 109088 View PDFView articleView in ScopusGoogle Scholar
    Kingma and Ba, 2014 Kingma D.P., Ba J. Adam: A method for stochastic optimization
    (2014) arXiv preprint arXiv:1412.6980 Google Scholar Kiran et al., 2021 Kiran
    R., Soumitri S., Mitra K. Deep learning based dynamic behavior modelling and prediction
    of particulate matter in air Chem. Eng. J. (10) (2021), Article 131221 Google
    Scholar Lee et al., 2019 Lee K., Lim J., Yoon D., Jung H. Prediction of shale-gas
    production at duvernay formation using deep-learning algorithm SPE J., 24 (6)
    (2019) Google Scholar Li et al., 2022 Li X., Li X., Yu C., Fan D., Sun Z., Xiao
    K. A well rate prediction method based on LSTM algorithm considering manual operations
    J. Pet. Sci. Eng. (210) (2022) Google Scholar Li et al., 2021 Li X., Ma X., Xiao
    F., Xiao C., Wang F., Zhang S. Time-series production forecasting method based
    on the integration of bidirectional gated recurrent unit (Bi-GRU) network and
    sparrow search algorithm (SSA) J. Pet. Sci. Eng. (2021) Google Scholar Lima et
    al., 2020 Lima M.M., Emerick A.A., Ortiz C. Data-space inversion with ensemble
    smoother Comput. Geosci. (1) (2020) Google Scholar Liu et al., 2017 Liu, J., Gang,
    W., Ping, H., Duan, L.Y., Kot, A.C., 2017. Global Context-Aware Attention LSTM
    Networks for 3D Action Recognition. In: IEEE Conference on Computer Vision & Pattern
    Recognition. Google Scholar Liu et al., 2020 Liu W., Liu W.D., Gu J. Forecasting
    oil production using ensemble empirical model decomposition based long short-term
    memory neural network J. Pet. Sci. Eng. (2020), Article 107013 View PDFView articleView
    in ScopusGoogle Scholar Liu et al., 2021 Liu D., Rao X., Zhao H., Xu Y., Gong
    R. An improved data space inversion method to predict reservoir state fields via
    observed production data Pet. Sci., 18 (4) (2021), pp. 1127-1142, 10.1016/j.petsci.2021.07.008
    View PDFView articleView in ScopusGoogle Scholar Lu et al., 2017 Lu R., Forouzanfar
    F., Reynolds A.C. An efficient adaptive algorithm for robust control optimization
    using StoSAG J. Pet. ence Eng. (2017), Article S0920410517307076 Google Scholar
    Ma et al., 2022a Ma X., Zhang K., Wang J., Yao C., Yang Y., Sun H., Yao J. An
    efficient spatial-temporal convolution recurrent neural network surrogate model
    for history matching SPE J., 27 (02) (2022), pp. 1160-1175, 10.2118/208604-PA
    View in ScopusGoogle Scholar Ma et al., 2022b Ma X., Zhang K., Zhang J., Wang
    Y., Zhang L., Liu P., Yang Y., Wang J. A novel hybrid recurrent convolutional
    network for surrogate modeling of history matching and uncertainty quantification
    J. Pet. Sci. Eng., 210 (2022), p. 110109 View PDFView articleView in ScopusGoogle
    Scholar Mohd Razak et al., 2022 Mohd Razak S., Cornelio J., Cho Y., Liu H.-H.,
    Vaidya R., Jafarpour B. Transfer learning with recurrent neural networks for long-term
    production forecasting in unconventional reservoirs SPE J. (2022), pp. 1-18, 10.2118/209594-PA
    Google Scholar Ng et al., 2021 Ng C., Ghahfarokhi A.J., Amar M.N. Well production
    forecast in volve field: Application of rigorous machine learning techniques and
    metaheuristic algorithm J. Pet. Sci. Eng., 208 (2021), Article 109468 Google Scholar
    Olominu and Sulaimon, 2014 Olominu O., Sulaimon A.A. Application of time series
    analysis to predict reservoir production performance (2014) Application of Time
    Series Analysis to Predict Reservoir Production Performance Google Scholar Pappas
    et al., 2008 Pappas S.S., Ekonomou L., Karamousantas D.C., Chatzarakis G.E., Katsikas
    S.K., Liatsis P. Electricity demand loads modeling using AutoRegressive moving
    average (ARMA) models Energy, 33 (9) (2008), pp. 1353-1360 View PDFView articleView
    in ScopusGoogle Scholar Paszke et al., 2019 Paszke A., Gross S., Massa F., Lerer
    A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Desmaison
    A. Pytorch: An imperative style, high-performance deep learning library Advances
    in Neural Information Processing Systems (2019), pp. 8024-8035 Google Scholar
    Qing-Dao-Er-Ji et al., 2020 Qing-Dao-Er-Ji R., Su Y.L., Liu W.W. Research on the
    LSTM mongolian and Chinese machine translation based on morpheme encoding Neural
    Comput. Appl., 32 (1) (2020), pp. 41-49 CrossRefView in ScopusGoogle Scholar Rasmussen
    et al., 2019 Rasmussen A., Sandve T., Bao K., Lauser A. The open porous media
    flow reservoir simulator (2019) arXiv preprint arXiv:1910.06059 Google Scholar
    Sani, 2020 Sani, S.H., 2020. Short-term and Long-term Air Quality Forecasting
    Technique Using Stacked LSTM. In: ICCIP 2020: 2020 the 6th International Conference
    on Communication and Information Processing. Google Scholar Sun and Durlofsky,
    2017 Sun W., Durlofsky L.J. A new data-space inversion procedure for efficient
    uncertainty quantification in subsurface flow problems Math. Geosci. (2017) Google
    Scholar Sun and Durlofsky, 2019 Sun W., Durlofsky L.J. Data-space approaches for
    uncertainty quantification of CO 2 plume location in geological carbon storage
    Adv. Water Resour., 123 (2019), pp. 234-255 View PDFView articleView in ScopusGoogle
    Scholar Sun et al., 2017 Sun W., Hui M.H., Durlofsky L.J. Production forecasting
    and uncertainty quantification for naturally fractured reservoirs using a new
    data-space inversion procedure Comput. Geosci., 21 (5–6) (2017), pp. 1443-1458
    CrossRefView in ScopusGoogle Scholar Sun et al., 2018 Sun, J., Ma, X., Kazi, M.,
    2018. Comparison of Decline Curve Analysis DCA with Recursive Neural Networks
    RNN for Production Forecast of Multiple Wells. In: SPE Western Regional Meeting.
    Google Scholar Wang et al., 2022 Wang N., Chang H., Kong X., Saar M.O., Zhang
    D. Deep learning based closed-loop optimization of geothermal reservoir production
    (2022) Google Scholar Wang et al., 2019 Wang S., Chen Z., Chen S. Applicability
    of deep neural networks on production forecasting in bakken shale reservoirs J.
    Pet. Sci. Eng. (2019) Google Scholar Wei et al., 2011 Wei, Q., Zhang, Y., Liu,
    X., He, X.L., 2011. Quality predication control based on the grey dynamic model
    group. In: International Conference on E-Business & E-Government. Google Scholar
    Xiao et al., 2020 Xiao Q., Chang X., Zhang X., Liu X. Multi-information spatial–temporal
    LSTM fusion continuous sign language neural machine translation IEEE Access, 8
    (2020), pp. 216718-216728 CrossRefView in ScopusGoogle Scholar Xiong et al., 2020
    Xiong, H., Kim, C., Fu, J., 2020. A Data-Driven Approach to Forecasting Production
    with Applications to Multiple Shale Plays. In: SPE Improved Oil Recovery Conference.
    Google Scholar Yang et al., 2020 Yang R., Singh S.K., Tavakkoli M., Amiri N.,
    Rai R. CNN-LSTM deep learning architecture for computer vision-based modal frequency
    detection Mech. Syst. Signal Process., 144 (2020), Article 106885 View PDFView
    articleView in ScopusGoogle Scholar Zhang and Jia, 2021 Zhang R., Jia H. Production
    performance forecasting method based on multivariate time series and vector autoregressive
    machine learning model for waterflooding reservoirs Pet. Explor. Dev., 48 (1)
    (2021), pp. 201-211 View PDFView articleView in ScopusGoogle Scholar Cited by
    (1) Robust optimization of geoenergy production using data-driven deep recurrent
    auto-encoder and fully-connected neural network proxy 2024, Expert Systems with
    Applications Show abstract View Abstract © 2023 Elsevier B.V. All rights reserved.
    Recommended articles Development and characterization of thermo-sensitive biomass-based
    smart foam drainage gas recovery treatment agent Geoenergy Science and Engineering,
    Volume 230, 2023, Article 212263 Jia Li, …, Zhiguo He View PDF Automatic estimation
    of RQD based on deep ensemble learning and fracture fitting Geoenergy Science
    and Engineering, Volume 230, 2023, Article 212132 Ye Zhang, …, Bin Li View PDF
    Research on instrument structure scheme for improving the sensitivity of wireline
    D-T source porosity logging Geoenergy Science and Engineering, Volume 230, 2023,
    Article 212239 Ningchao Li, …, Guobin Liu View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 1 Captures Readers: 5 View details About ScienceDirect
    Remote access Shopping cart Advertise Contact and support Terms and conditions
    Privacy policy Cookies are used by this site. Cookie settings | Your Privacy Choices
    All content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Geoenergy Science and Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Robust production forecast and uncertainty quantification for waterflooding
    reservoir using hybrid recurrent auto-encoder and long short-term memory neural
    network
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wu Z.Y.
  - Chew A.
  - Meng X.
  - Cai J.
  - Pok J.
  - Kalfarisi R.
  - Lai K.C.
  - Hew S.F.
  - Wong J.J.
  citation_count: '9'
  description: Smart Water Grid (SWG) plays a critical role in sustaining cities economic
    and social development, but challenges remain in fully realizing the benefits
    of SWG. While Digital twin (DT) has been discussed in some literature for possible
    SWG applications, there has been limited, or no technical framework developed
    to facilitate SWG operation and management. In this paper, a generic framework
    is developed for constructing SWG high fidelity Digital Twin (DT) by integrating
    digital thread with various digital models for visualization, data-driven analysis,
    physics-based simulations, and decision-making support. Both the physics-based
    models and data-driven models are trained/retrained and calibrated/re-calibrated
    respectively by using the data collected with the sensors installed throughout
    a SWG. The information derived from the SWG DT can be diagnostic, predictive,
    and prescriptive to significantly augment users’ intelligence for improving SWG
    operation and management. One important application of digital twin augmented
    intelligence is illustrated to timely detect and localize anomaly events, which
    may include, but not be limited to, pipe bursts and unauthorized water usages.
    The solution is tested on the selected areas in Singapore to construct the ever-green
    DT by calibrating and recalibrating the models for near real-time SWG operation
    management. The case study was conducted for three supply zones with the total
    pipeline length of more than 1000 km and 40 weeks of monitoring data, collected
    by 89 pressure monitoring stations and 8 flow meters at inlets and boundary. More
    than 3300 data-driven models are trained for optimizing the model performance
    to achieve accuracy of greater than 80% F1 score for detecting anomaly events,
    which are subsequently localized within 400 m with 2–3 days lead time.
  doi: 10.1016/j.scs.2023.104446
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. SWG digital twins 3. Digital
    twin-based anomaly detection and location 4. Case study 5. Discussions 6. Conclusions
    Declaration of Competing Interest Acknowledgements Data availability References
    Show full outline Cited by (9) Figures (13) Show 7 more figures Tables (4) Table
    1 Table 2 Table 3 Table 4 Sustainable Cities and Society Volume 91, April 2023,
    104446 High Fidelity Digital Twin-Based Anomaly Detection and Localization for
    Smart Water Grid Operation Management Author links open overlay panel Zheng Yi
    Wu a, Alvin Chew b, Xue Meng b, Jianping Cai b, Jocelyn Pok b, Rony Kalfarisi
    b, Kah Cheong Lai c, Sock Fang Hew c, Jia Jie Wong c Show more Add to Mendeley
    Share Cite https://doi.org/10.1016/j.scs.2023.104446 Get rights and content Highlights
    • Developed a generic digital twin (DT) framework for smart water grids (SWG).
    • Integrated data analytics and hydraulic model calibration for constructing high-fidelity
    SWG DT. • Automated model training including data cleansing, outlier detection
    and event classification. • Applied DT-based approach to three supply zone with
    pipeline length of more than 1000 km. • Achieved event detection accuracy of greater
    than 80% with lead time of 1 to 3 days. Abstract Smart Water Grid (SWG) plays
    a critical role in sustaining cities economic and social development, but challenges
    remain in fully realizing the benefits of SWG. While Digital twin (DT) has been
    discussed in some literature for possible SWG applications, there has been limited,
    or no technical framework developed to facilitate SWG operation and management.
    In this paper, a generic framework is developed for constructing SWG high fidelity
    Digital Twin (DT) by integrating digital thread with various digital models for
    visualization, data-driven analysis, physics-based simulations, and decision-making
    support. Both the physics-based models and data-driven models are trained/retrained
    and calibrated/re-calibrated respectively by using the data collected with the
    sensors installed throughout a SWG. The information derived from the SWG DT can
    be diagnostic, predictive, and prescriptive to significantly augment users’ intelligence
    for improving SWG operation and management. One important application of digital
    twin augmented intelligence is illustrated to timely detect and localize anomaly
    events, which may include, but not be limited to, pipe bursts and unauthorized
    water usages. The solution is tested on the selected areas in Singapore to construct
    the ever-green DT by calibrating and recalibrating the models for near real-time
    SWG operation management. The case study was conducted for three supply zones
    with the total pipeline length of more than 1000 km and 40 weeks of monitoring
    data, collected by 89 pressure monitoring stations and 8 flow meters at inlets
    and boundary. More than 3300 data-driven models are trained for optimizing the
    model performance to achieve accuracy of greater than 80% F1 score for detecting
    anomaly events, which are subsequently localized within 400 m with 2–3 days lead
    time. Previous article in issue Next article in issue Keywords Digital twinMachine
    learningData analyticsSmart water gridAnomaly detectionAnomaly localization 1.
    Introduction Over the past decades, cities have grown both in size and in their
    overall population count. According to the United Nation (United Nations, 2018),
    55% of world''s population lives in urban areas, a proportion that is expected
    to increase to 68% by 2050. The gradual shift in residence of the human population
    from rural to cities, combined with the overall growth of the world''s population,
    could add another 2.5 billion people to urban areas by 2050, with close to 90%
    of this increase taking place in Asia and Africa. To accommodate the projected
    growing urbanization, it has become increasingly challenging to design, construct,
    operate and maintain city infrastructure systems which include, but not limited
    to, water distribution networks (WDN) with adequate sustainability and resilience.
    1.1. Necessity for smart water grid One effective approach for ensuring adequate
    WDN sustainability and resilience is to implement Smart Water Grid (SWG) (PUB
    Singapore''s National Water Agency, 2016), in which information and communications
    technologies (ICT) is integrated to manage the daily operations of WDNs. In principle,
    the SWG framework comprises of sensors, smart meters, digital controls, and analytic
    tools. The integrated system is then deployed to automate, monitor, and control
    the water transmission and distribution systems, hence enabling water services
    to be efficiently delivered in good quality with minimum disruptions. Furthermore,
    WDN is the lifeline for cities by serving as the critical infrastructure to sustain
    urban cities’ long-term economic and social development. Hence, to build WDN''s
    resilience, water utilities need to be well-equipped to promptly respond to natural
    disasters, condition deterioration-induced incidents such as pipe bursts that
    may cause water service disruption within the network. Therefore, to effectively
    develop a sustainable and resilient WDN for any urban city, implementation of
    a SWG is imperative for water utilities around the world. In the context of Singapore,
    there is an average of 4.6 reported leak events per 100 km on a yearly basis in
    2018. While large-scale burst events do not commonly occur in the open streets
    of Singapore, hidden and insidious underground pipe leaks continue to pose the
    biggest challenge to the local water utility. To manage this difficult challenge,
    the state government has been continuously investing to deploy hundreds of monitoring
    stations across the city''s underground water pipelines having more than 5000
    km, hence facilitating the nation''s SWG long-term development (PUB Singapore''s
    National Water Agency, 2016). Overall, SWG is expected to result in multiple operational
    benefits which include: (1) real-time monitoring of asset condition for preventive
    maintenance; (2) real-time pressure and water quality monitoring to enhance planning
    and network operations and (3) real-time water consumption information to help
    customers conserve water. While the advantages of SWG are notable and realistic,
    there are still underlying challenges which need to be addressed to achieve their
    benefits over a prolonged period. In general, the challenges encompass (1) good
    interoperability amongst all data systems, (2) good data management with powerful
    analytics to extract useful information, (3) redesign the jobs for current employees,
    both operational and in the field, to tailor towards the purpose of SWG, (4) good,
    intertwined communication with customers, and finally (6) testing and adopting
    the new SWG technology for near real-time deployment and analysis. Therefore,
    to address the above-listed challenges, digital twin has since emerged as the
    integrated solution for SWG management and operation. 1.2. Literature review on
    digital twins The concept of Digital Twin (DT) was first introduced by Grieves
    (Grieves, 2006). It is defined as a set of virtual information constructs (models)
    that fully describes a potential or actual physical product from micro atomic
    level to macro geometrical level. For any engineering application, the objective
    of deploying DT is to mitigate the undesirable emergent behaviour. Since its inception,
    DT has been redefined or refined for different application domains. Rosen et al.
    (Rosen et al., 2015) defined DT as a combination of both physical and virtual
    spaces which mirror each other to evaluate the lifecycle operations of the physical
    component. Boschert et al. (Boschert et al., 2017) defined that DT encompassed
    all the physical and functional data useful from a product or system. Grieves
    and Vickers (Grieves & Vickers, 2017) further defined DT in the context of product
    lifecycle management as a set of virtual information constructs that provide a
    true representation of a potential or actual physical manufactured product from
    its atomic level to the macro geometrical level. Lui et al. (Lui et al., 2018)
    further defined DT as a living model which represents a physical asset or system
    that continually adapts to changes in operations based on online data and information
    collected and can predict the future of the corresponding physical counterpart.
    Madni et al. (Madni et al., 2019) defined DT, not as a virtual prototype but rather
    a virtual instance of a physical system''s (twin) performance, maintenance, and
    health status data, which is continually updated throughout the life cycle of
    the physical system. Semeraro et al. (Semeraro et al., 2021) conducted a comprehensive
    review of digital twin paradigm. DT was defined as a set of adaptive models that
    emulate the behaviour of a physical system in a virtual system getting real time
    data to update itself along its life cycle. It replicates the physical system
    to predict failures and opportunities for changing, to prescribe real time actions
    for optimizing and/or mitigating unexpected events. DT Consortium (Digital Twin
    Consortium, 2022) defines that a digital twin is a virtual representation of real-world
    entities and processes, synchronized at a specified frequency and fidelity. Madubuike
    et al. (Madubuike et al., 2022) defines DT as the virtual representation of a
    physical asset using the DT-enabling technologies such as sensors, communication
    networks, and 3D models to obtain real-time updates and effect bi-directional
    coordination such that the virtual model represents a replica of the physical
    asset. Fig. 1 illustrates the conceptual framework of digital twin, where the
    key is the cyber-physical connection between the physical space and digital space,
    or so-called Digital Thread (Kritzinger et al., 2018). It is the digital thread
    or the data integration that enables data flow between physical and digital objects
    and determines if a digital object is truly a DT (Kritzinger et al., 2018). If
    the data flow is a manual process, the digital object is a digital model or computer
    model, which has been developed for decades. When the data flow is semi-automatic
    or one-way from physical space to digital space, the digital object is called
    digital shadow. A genuine DT is primarily constructed with automatic (two-way)
    information and data flow between digital and physical spaces. Download : Download
    high-res image (243KB) Download : Download full-size image Fig. 1. Illustration
    of digital thread differentiating digital object (computer model) from digital
    twins (adapted from Kritzinger et al. (2018)). In a nutshell, DT operates on the
    principle of near real-time model updates and bi-directional communication, and
    provides a living or ever-green model, which is created at the inception stage
    before the physical twin (physical product or infrastructure) is constructed.
    However, the creation of an ever-green DT depends on sensory data obtained from
    the corresponding physical twin and requires the monitoring data of the physical
    assets to be assimilated into the digital twins, which in turn facilitates control
    and monitoring of the same physical twin. Key common features for DTs can be summarized
    as follows. • Represent the specific instance of a physical structure, its performance,
    maintenance, repair history, health status, and other characteristics. • Monitor
    and understand the quantitative performance of the physical asset over time. •
    Determine schedules for preventive/predictive maintenance of specific functionalities
    by using historical data of the physical asset. • Simulate operational and maintenance
    data of the physical system to reflect the age of the physical system. • Forecast
    future performance and maintenance patterns for refining the underlying assumptions
    adopted to build DT. • Perform lifecycle analysis of physical assets via the underlying
    cyber-physical connectivity provided by the digital threads. • Perform remote
    maintenance of physical assets by troubleshooting for malfunctioning remote equipment.
    • Optimize and improve services and operations of physical assets by combining
    data from the IoT with data from the same asset. As briefly highlighted earlier,
    the applications of DT range across multiple industries which, include but not
    limited to healthcare for improving operational efficiency of healthcare operations;
    maritime and shipping for design customization; manufacturing for product development
    and predictive manufacturing; city management for modelling and simulation of
    smart cities and aerospace for predictive analytics to foresee future aircraft
    problems. amongst the various applications across different industries, DT serves
    as an essential technology over its life cycle as follows: I Design Phase: Accurately
    configures and validates the design alternatives by interpreting the market demands
    and customer preferences. II Production/Construction Phase: Facilitates real-time
    process control or construction work monitoring, optimization, as well as accurate
    predictive modelling of specific operations and/or functionalities. III Service
    Phase: Monitor the system''s temporal state (e.g., operational heath) for performing
    diagnosis and prognosis. Examples where DT has been successfully applied include
    metal additive manufacturing where DT is adopted to address challenges such as
    printed part qualification, certification, and optimisation (Phua et al., 2022),
    and smart factories operations to increase work productivity and reduce overall
    operational costs and energy consumption (Friederich et al., 2022). In more focused
    application, DT has been shown to provide the integrated information technology
    (IT) platform to detect multi-step attack on industrial control systems, when
    coupled causal analysis. In environmental-related domains/applications, integrating
    data from multi-sensors, predictions from machine learning algorithms, and decision-support
    systems into DT can assist to optimize anomaly detection results in terms of quality
    and quantity, to avoid waste, and to maximize profits for agricultural farmers
    (Catalano et al., 2022). Similarly, combining data collected from unmanned aerial
    vehicle (UAV) and dynamic building information modelling (BIM) to inspect the
    structural safety of large-scale water infrastructures which include, but not
    limited to, water diversion systems, dams, and railways (Liu et al., 2019). The
    above-discussed examples clearly illustrate that the concept of DT is generally
    flexible and can tailor to a diverse range of domains, thus opening up opportunities
    of similar deployment to infrastructure domain in general, and also for SWG. In
    infrastructure industry, Wu (Wu, 2018) presented an overarch framework of enabling
    digital twins for resilient infrastructure; resilience towards disruptive events
    to minimize social and economic impacts. An infrastructure DT, that is constructed
    using physical data and monitoring data, comprises four types of digital models
    including reality models, such as those 2D GIS, 3D points clouds and reality mesh
    models, data-driven models built with ML and data analytics, physics-based models,
    and decision-support models. All models will be trained, calibrated and updated
    in near real-time to provide useful information for diagnosing the potential problems,
    predicting future scenarios and prescribe the solution for improving infrastructure
    resilience. In the meantime, DT can be defined to address a particular purpose
    or project in the same infrastructure domain. Braun et al. (Braun et al., 2018),
    defined the purpose of a DT to be a monitor for construction work progress. Another
    DT application in the construction industry defined the purpose of the DT for
    monitoring the state of a bridge (Sacks et al., 2018). In the water industry specifically,
    Pedersen et al. (Pedersen et al., 2021) clarified the key DT terminology for urban
    drainage water system and identified steps to create a DT by building upon digital
    ecosystems and open standards for data. Torfs et al. (Torfs et al., 2022) provided
    an overview of the challenges, good practices, development needs and transformative
    capacity of DTs for Water Resources Recovery Facilities applications. Pesantez
    et al. (Pesantez et al., 2022) described the development and application of a
    digital twin in the context of the integrating Advanced Metering Infrastructure
    (AMI) data with a hydraulic model and explored how changes in water demands during
    the COVID-19 pandemic affected hydraulics and energy consumption. While DT has
    been discussed in some literature for possible water-related applications, there
    has been limited, or no technical framework developed for water distribution digital
    twin to facilitate SWG operation and management. Therefore, the objective of this
    paper is to develop a generic framework of SWG digital twin with the detailed
    description of their core components and in-built features. The proposed SWG DT
    is then tested in the field for three water supply zones with the total pipeline
    length of more than 1000 km and 40 weeks of monitoring data that is collected
    by 89 pressure monitoring stations and 8 flow meters at the inlets and boundaries
    of the respective zones. The extensive case study analyses have since demonstrated
    that the proposed SWG DT is effective to facilitate ever-green DT by automatically
    (1) training/retraining data-driven predictive models and (2) calibrating/recalibrating
    hydraulic models to improve SWG operation management, which then contributes to
    the overall sustainability of cities and societies in today''s context, especially
    under the increasing uncertainties of climate change and population growth. 2.
    SWG digital twins For many water infrastructure systems these days, various data,
    including physical, mechanical, and ambient data, are collected over time and
    enable engineers to construct digital twin. By definition, SWG digital twin is
    represented by a set of cyber-secured adaptive models that emulate the hydraulic
    and water quality characteristics of the physical water distribution system via
    receiving and assimilating near real-time monitoring data to calibrate or update
    itself over its life cycle, with capacity of automatic bi-directional exchange
    between digital and physical twins in data synchronization and communicating the
    actionable wisdoms for operation, asset management, system design and planning.
    As shown in Fig. 2, SWG digital twin is represented in digital spaces for various
    purposes, including digital visualization (e.g., 2D geospatial information systems
    and 3D models), data-driven analysis (conventional statistical and modern machine
    learning models), physics-based simulations (hydraulics and water quality simulation
    models) and decision-support (optimization, rule-based system, deep learning models
    etc.). The information derived from these models is to diagnose the potential
    undesirable behaviour, evaluate and predict the SWG performance over time, and
    eventually provide solutions for improving the management and operation of water
    distribution systems. To effectively apply a DT for enhancing resilience of water
    infrastructure, the former must be constructed with (1) digital models, and (2)
    digital thread that connects digital space with physical asset and streamlines
    the two-way communications between them. Download : Download high-res image (883KB)
    Download : Download full-size image Fig. 2. Digital twin for smart water grids.
    2.1. Digital models Traditionally, various computing technologies have been applied
    to develop computer models or digital models for different infrastructure systems
    including but not limited to water infrastructure. For instance, 2D GIS has been
    widely used for data management and visualization of water distribution networks,
    for which hydraulic and water quality models can be constructed respectively to
    simulate flows and analyse the propagation of chemical constituents throughout
    a pipeline network. Finally, decision-support models, such as design and operation
    optimization models, can be developed for assisting engineers to make cost-effective
    decision for maintaining and operating a water system. In general, four types
    of digital models, as elaborated below, can be employed for constructing a comprehensive
    SWG digital twin. 2.1.1. Digital visualization A water infrastructure system is
    comprised of many different facilities and assets above- and underground, including
    but not limited to water source facilities (dams, reservoir, water intake etc.),
    water treatment plants, pump stations, service reservoir or water towers (elevated
    tanks), transmission and distribution networks. Digital representation of a complete
    water system will include 2D and/or 3D models of the physical assets and a process
    such as water treatment. It provides the digital space for data management, visualization,
    and user interactions with DT. Conventional 2D CAD models and geospatial information
    systems are widely used for city-scale representation and visualization of urban
    water distribution systems. 2D visualization technology is generally well accepted
    and adopted by stake owners, operators, and engineers. It serves the primary purpose
    to a great extent and meets most of the requirements for managing the physical
    assets. However, the recent advancement in 3D visualization has proved to be critical
    to facilitate more applications than 2D digital visualization (van Manen et al.,
    2021). 3D visualization models can be built from different data sources including
    images, videos, and LiDAR scanned point clouds. It is particularly suitable for
    representing and visualizing the above-ground water infrastructure, such as elevated
    tanks, reservoirs, dams, pump stations and water treatment plants. Comparing with
    2D visualization models, 3D visualization models provide exact representation
    of a physical water asset (e.g., water tank), and allows users to visualize the
    real condition of the asset, so-called 3D reality model, which enables new applications
    such as machine learning-based defect detection and condition evaluation. The
    cost-effective 3D reality model can be constructed by photogrammetry extracting
    the geometric information of 2D images. By combining many images, the photogrammetry
    software automatically registers the shared points amongst the images and then
    calculates the distances in 3D space, where a point cloud is generated and transformed
    into a 3D mesh model via polygon triangulation. For photogrammetry software to
    work properly, enough overlapped area is necessary within images. In close-range
    photogrammetry, a camera can be used to take hundreds or thousands of images to
    construct 3D model. To achieve a high-fidelity 3D model, a minimum overlap of
    50% is required, but an overlap of 70% is recommended (Bentley Systems, Incorporated,
    2018). Photogrammetry is a very useful technique for various applications, especially
    for 3D reality scanning, by generating digital version of objects or landscape.
    It can also capture very large objects like buildings, or even an entire city,
    that would be otherwise impossible to scan using other methods. Moreover, photogrammetry
    is extremely affordable due to widely available and accessible digital camera.
    Thus, a well-developed photogrammetry software (Bentley Systems, Incorporated,
    2018) is essential for creating DT visualization of civil infrastructure in general.
    Fig. 3 shows an example of water consumption visualization in 2D GIS thematic
    map and 3D city scale model respectively. While 2D map provides meaningful information
    to users, 3D visualization instead offers more accurate representation of the
    physical city than 2D GIS, hence enabling users to gain good insights into complex
    data. With 3D model, each building is colour-coded with accordance to (1) water
    consumption per capital, (2) total water consumption per day or month, and (3)
    other related attributes. The 3D representation therefore provides more intuitive
    and insightful understanding than conventional 2D maps for visualizing dynamic
    water-related data and attributes. In addition, 3D visualization enables engineers
    to improve understanding or interpretation of the pipelines in a crowded urban
    subsurface environment, thus, it increases the efficiency and accuracy. However,
    challenge remains in obtaining all the required data to construct 3D representation
    of underground pipeline fittings, connection joints, and valves, which are mostly
    hidden and unlikely captured by camera or other reality data acquisition devices.
    Download : Download high-res image (507KB) Download : Download full-size image
    Fig. 3. Example of water consumption data visualization in city-scale 2D GIS (left)
    and 3D model (right). 2.1.2. Data-driven analytics Effective data analytics is
    the critical component of a digital twin. With data collected by hundreds of sensors
    installed at water treatment works and throughout water distribution networks,
    large amount data must be analysed efficiently. The data-driven analytics, both
    conventional statistical analysis methods and state-of-art machine learning methods,
    are applied to extract useful and actionable information with the components including:
    i Data quality assessment. Bad or poor-quality data can easily lead to wrong conclusions
    no matter what analysis method is adopted. Therefore, it is important to always
    evaluate the prior data quality and apply adequately good data to construct effective
    data-driven models. ii Prediction models. With large amount of historical data,
    predictive models can be trained/calibrated for operation management and asset
    maintenance. For instance, prediction models can be constructed with flow and
    pressure time series data for system operation, while asset maintenance records
    can be used for making informed decision pertaining to asset maintenance. iii
    Defect/anomaly detection models. Defects (cracks, corrosions, spalling etc.) may
    exist in above- and underground water infrastructure. For those visible defects,
    visual data in the form of images and videos can be collected and adopted for
    developing deep learning models to automatically detect defects. Detecting defects
    for underground assets, i.e., pipe bursts or leakages, however, remains a challenging
    task. 2.1.3. Physics-based models Physics-based models are very well developed
    for simulation and analysis of water infrastructure. These models, such as hydraulic
    simulation and water quality analysis models, establish the backbone of the digital
    space for analysing different scenarios of design, operation, and management of
    various water infrastructure including service reservoirs, pump stations, water
    transmission and distribution networks. Coupled with data-driven models, physics-based
    models can be further leveraged for digital twin-based decision-support. 2.1.4.
    Decision-support The goal of constructing DTs is to improve the overall support
    decision-making process, which is, in a broad context, to leverage on the information
    derived from the digital space of data-driven analytics and physics-based simulation,
    such that the informed and cost-effective solutions can be generated for asset
    maintenance, incident mitigation, operation management and enhancing customer
    satisfaction of water service. A variety of techniques, including but not limited
    to optimization, rule-based knowledge representation system, decision trees etc.,
    can be employed to develop decision-support model by integrating data-driven analytics
    and physics-based simulation models. 2.2. Digital thread A digital thread serves
    as the critical link between a digital twin and physical infrastructure. The objective
    is to create a universal access to data, a single source of truth, for allowing
    various digital models to be constructed and updated with continuous, diverse,
    but interrelated, monitoring and inspection interrelated data sets. This form
    of data unification is a prerequisite to build a true digital twin. On the other
    hand, a digital thread is also useful to track, convey and disseminate information
    and/or decision(s) across an organization for the actions to be undertaken in
    the field. Therefore, a digital thread provides the following key advantages,
    namely: (1) universal access to data and a single source of solution information
    across an enterprise and foster collaboration by aligning different functions,
    and (2) enable near real-time data synchronization amongst the different datasets
    for providing upstream and downstream information to all users. Fig. 4 shows the
    overall integrated process of a comprehensive digital thread for connecting digital
    twins with physical assets, where it primarily comprises of data acquisition,
    data synchronization, data sequence and data federation. Download : Download high-res
    image (195KB) Download : Download full-size image Fig. 4. Digital thread integration
    for digital twin. With well-established digital threads, the flexibility and agility
    will be enhanced within an organization by equipping employees across the value
    chain with the right information at the right time. Integration of digital twins
    and digital threads will unlock more opportunities to drive business outcomes
    for water infrastructure in general. amongst the most important steps, engineers,
    operators, and stake owners should consider this new paradigm approach for their
    organization and determine the important use cases as starting points. Consequently,
    digital intelligence can be augmented via various digital models as backbone of
    digital twin. 2.3. Digital twin augmented intelligence To facilitate digital twin
    approach for SWG management and operation, various computing techniques including
    but not limited to, conventional data analytics, state-of-the-art Artificial Intelligence
    (AI) methods, high-performance evolutionary optimization, and computer vision,
    to solve many challenging problems. Overall, these computing techniques are well-developed
    and can serve as a generic solver for decision-making problems with single or
    multi objectives, linear and nonlinear constraints. These techniques have also
    been applied to evolve or optimize deep machine learning models for many data-driven
    problems. Essence of AI, however, is not to replace engineers but to better assist
    engineers by augmenting users’ digital intelligence, termed as Augmented Intelligence,
    which is an interactive, collaborative human/machine learning process by keeping
    users in the loop for the lifecycle of digital twin applications spanning from
    model construction, model inference and decision-making. During this process,
    as shown in Fig. 5, user''s intelligence is enhanced or augmented with the digital
    twins for SWG design, construction, operation, and maintenance. In general, DT
    can equip users with the augmented intelligence in a wide range of applications
    managing and operating water infrastructure. In the following, we present the
    full case study example of applying DT augmented intelligence for SWG anomaly
    detection and localization in water distribution networks. Download : Download
    high-res image (407KB) Download : Download full-size image Fig. 5. Augmented intelligence
    for digital twin. 3. Digital twin-based anomaly detection and location To effectively
    analyse water distribution network, a digital twin-based approach has been developed,
    as shown in Fig. 6, for integrating data-driven analytics with the physics-based
    models. This integrated workflow starts with data cleansing, diagnose possible
    data issues, and prepare the dataset for data-driven analysis, which enables us
    to detect and evaluate anomaly in a system, and subsequently localize anomaly
    by model simulation and calibration. A calibrated hydraulic model is high fidelity
    digital twin, which can be applied to enhance water system operation and management.
    Download : Download high-res image (430KB) Download : Download full-size image
    Fig. 6. Integrated framework for anomaly detection and localization by continuous
    monitoring data analysis and hydraulic modelling. 3.1. Anomaly detection by data-driven
    analytics Considerate amount of research has been conducted and reported for SWG
    anomaly detection (Mounce et al., 2002) (Mounce & Boxall, 2011) (Mounce et al.,
    2014) (Romano et al., 2014a) (Romano et al., 2014b) (Jung & Lansey, 2015) (Loureiro
    et al., 2016) (Wu et al., 2018). Various methods, including conventional statistics
    methods, prediction-based methods, and classification-based methods have been
    used for extracting useful information from data collected by various sensors,
    such as flow and pressure sensors instrumented within a water distribution network.
    We have developed a comprehensive data analysis framework (Wu & He, 2021) (Wu
    et al., 2022) (Meng et al., 2022), which comprises of data pre-process, decomposition,
    outlier detection and event classification. Both flow and pressure datasets have
    been pre-processed to check for the data errors, including the missing data records,
    the duplicated data records, the irregular time steps, and the sensor failure
    time steps. The error data records must be corrected accordingly before the time
    series are decomposed into three components of median, seasonality and remainders.
    The outlier detection has been conducted with the remainder component. All flow
    and pressure sensor events are correlated to identify possible system anomaly
    events, as illustrated in Fig. 7. Download : Download high-res image (736KB) Download
    : Download full-size image Fig. 7. Data-driving modelling process for SWG anomaly
    event detection and classification. Water system anomaly events may include pipe
    bursts, unauthorized water usages and others (operational changes, sensor drifts,
    local abnormal water usages, flushing hydrants etc.). Each of the possible events
    usually causes the increased flow that can recorded at the inlet of the system,
    and the pressure drops in some portion of the network. The extent of the network
    with pressure drop depends on the magnitude and location of the event. The pressure
    drop will be captured or recorded if the pressure loggers are placed within the
    scope of the affected area. 3.2. Model training for near real-time anomaly detection
    The practical application of the data-driven models usually involves the multiple
    water supply zones and dozens of sensors. It is essential to develop the method
    and tool for automatic model training to facilitate the evaluation of the top-performed
    model to be selected for a given system. As illustrated in Fig. 8, the model development
    and training process can be undertaken in two different pipelines, Statistical
    Process Control (SPC)-based and Machine learning/Deep Learning (ML/DL) pipelines.
    The former adopts the integrated framework as described previously while the latter
    uses historical time-series data (flow and pressure reading) and predicts the
    expected normal working condition of the system via trained predictive models
    (Kalfarisi et al., 2022) (Li et al., 2019). The best trained model obtained will
    be employed for the near real-time event classification. Download : Download high-res
    image (543KB) Download : Download full-size image Fig. 8. model training and updating
    for near real-time anomaly detection. 3.3. Model calibration-based near real-time
    anomaly localization The trained data-driven models for anomaly event detection,
    as elaborated in the previous section, are integrated with the hydraulic model
    simulation-based anomaly event localization including but not limited to the detection
    of the hidden leaks. As shown in Fig. 9, we first calibrate a baseline hydraulic
    simulation model using historical data of monitored flow and pressures for a given
    SWG system, or water supply zone, that serves as the basis for near real-time
    anomaly localization (Wu, 2009) (Chew et al., 2022). In near real-time context,
    i.e., daily basis, when no anomaly event is detected, hydraulic simulation will
    be performed with corresponding boundary conditions such as the recorded service
    reservoir levels and other recorded inflows. The simulated flows and pressures
    are then compared with the monitored data to estimate the goodness-of-fit between
    the simulated and monitored attributes (flow and pressure). If the goodness-of-fit
    is less than the user''s specified criteria, the model is recalibrated and persisted
    for the subsequent applications of near real-time anomaly localization and other
    related SWG operational management such as water quality analysis. Whenever an
    anomaly event is detected, the latest re-calibrated model, as persisted in the
    SWG database, is adopted for anomaly event localization by employing the well-developed
    pressure dependant leakage detection approach (Wu et al., 2010). Download : Download
    high-res image (421KB) Download : Download full-size image Fig. 9. Integration
    of data-driven model and hydraulic model calibration for near real-time anomaly
    localization. 4. Case study The case study has been conducted for three supply
    zones with the total pipeline length of more than 1000 km, 89 pressure monitoring
    stations and 8 flow meters at inlets and boundary. A total of 40 weeks of monitoring
    data has been used for benchmark study, in which 65% of the data set was used
    for model training, 25% for model validation and 10% for testing. The raw dataset
    has been first pre-processed for detecting and correcting possible data errors.
    After data pre-processing, the data is ready for automatic training as illustrated
    in Fig. 7. The software tool has been developed with good rich features and flexibility
    to allow users to change model parameters settings. For example, the user could
    set count and step size to auto-generate permutations for maximum time distance
    and remove those unwanted options based on user''s choice. The user could also
    change value directly for the desired parameters and save a few top performing
    models. A total of 3360 anomaly detection models are automatically trained for
    each supply zone. Table 1 presents the trained parameters of two top-performing
    models for each zone. Table 2 summarizes the results of top 2 models trained and
    validated for each zone. The trained models have been tested in the context of
    near real-time anomaly detection. As shown in Table 3, the top model has performed
    well with F1 score of greater than 90%. Table 1. Trained top model configurations
    for each zone. Zones Trained top models Methods Outlier Detection System Event
    Classification and Validation Weight on recent samples No. Max. Event Duration
    (min) Min No. of Outliers as Valid Event Lead Time (days) Lag Time (days) Zone
    1 Model 1 EWMA 0.1 3 30 24 1 0 Model 2 DL & EKF N/A 2 180 3 1 0 Zone 2 Model 1
    DL & EKF N/A 4 180 24 3 1 Model 2 EWMA 0.1 3 15 24 3 1 Zone 3 Model 1 X-bar N/A
    3 90 18 3 1 Model 2 X-bar N/A 3 120 12 3 1 Table 2. Summary of model training
    and validation results for each supply zone. Zones Models Training Results Validation
    Results Empty Cell Empty Cell Precision Recall F1-Score Precision Recall F1-Score
    Zone 1 Model 1 0.39 1.00 0.57 0.89 1.00 0.94 Model 2 0.76 0.44 0.56 0.78 1.00
    0.88 Zone 2 Model 1 1.00 1.00 1.00 1.00 1.00 1.00 Model 2 0.51 1.00 0.68 0.46
    1.00 0.63 Zone 3 Model 1 0.07 1.00 0.14 0.36 1.00 0.53 Model 2 0.09 1.00 0.16
    0.35 1.00 0.52 Table 3. Summary of model testing results for three supply zones.
    Zones Models Near-Realtime Detection Result Empty Cell Empty Cell TPs FPs Precision
    Recall F1-Score Zone 1 Model 1 14 3 0.82 0.94 0.88 Model 2 19 3 0.86 1.00 0.93
    Zone 2 Model 1 6 1 0.86 0.75 0.80 Model 2 16 1 0.94 1.00 0.97 Zone 3 Model 1 18
    3 0.86 1.00 0.92 Model 2 22 3 0.88 0.80 0.84 It is worthwhile noting that the
    advanced methods such as deep learning-based prediction model (Kalfarisi et al.,
    2022), is generic approach and effective at outlier detection for water distribution
    systems. By the nature of deep learning, it does require much more good data and
    computation resources than SPC methods to train an adequately accurate model.
    With enough good data available for a study, the advanced deep learning method
    and the SPC might have performed equally well, such as for zone 1 and 2. The SPC
    methods are effective at outlier detection. It is easy to apply the methods, which
    work better than ML-based approach with short time series such as three-month
    dataset. Anomaly or leakage event localization was conducted by applying the pressure
    dependant leakage detection (PDLD) method (Wu, 2009) (Wu et al., 2010) via hydraulic
    model calibration with the pressure and flow monitoring data collected for the
    detected anomaly event, as previously illustrated in Fig. 9. Since the inception
    of the PDLD method, many research works have been conducted for leak localization
    (Perez et al., 2014) (Ponce et al., 2014) (Tao et al., 2014) (Sophocleous et al.,
    2019) (Vrachimis et al., 2021). On a whole, the PDLD method is formulated to search
    for likely anomaly hotspots which are mainly emulated as emitters at nodes where
    unauthorized water usages or leaks are modelled as pressure dependant demands,
    atop of real consumptions. The emitter locations and coefficients at possible
    anomaly nodes are the decision variables to be optimized such that the difference,
    i.e., the cost function, between the simulated and field observed pressures/flows
    is minimized. Identifying and quantifying leakage emitters are effectively part
    of the model calibration effort to represent additional pressure dependant demands
    (e.g., leaks) in a hydraulic model. The PDLD method is integrated with the optimization-based
    model calibration tool (Wu et al., 2002) (Wu, 2002) (Bentley Systems, Incorporated,
    2019), which can be executed repetitively for the same anomaly event. Optimally,
    an isolated anomaly hotspot within a water distribution network with high confidence
    score should be detected/localized consistently across multiple runs of steady-state
    conditions. In practice, achieving a complete calibrated model, with zero model
    errors, is not possible. However, it is imperative to ensure the following aspects,
    when calibrating a hydraulic simulation model, namely: (1) the hydraulic model
    is constructed with adequately accurate nodal demands that reflect real water
    consumption; (2) the elevations are accurate at locations (nodes) where pressure
    data are recorded and (3) boundary conditions, such as service reservoirs, tanks
    and pumps are also accurately represented in the model. Fig. 10. Download : Download
    high-res image (355KB) Download : Download full-size image Fig. 10. Sample training
    data in 15-minute interval. Previously developed PDLD approach has since been
    enhanced to augment digital twin intelligence by leveraging on continuous monitoring
    hydraulic data collected from installed sensors for SWG (Chew et al., 2022). Overall,
    the PDLD approach generically serves as an integrated solution methodology for
    practical engineers to construct high-fidelity digital twin by undertaking a series
    of systematic analyses daily, namely: (1) estimating the system''s daily non-revenue
    water (NRW) volume and NRW time series; (2) adjusting the available pumps’ operational
    curves and control statuses, followed by calibrating the system''s net demand
    pattern to fulfil the flow balance accounting for the actual consumption; (3)
    identifying and rectifying possible offsets in the monitored pressure head values
    for each sensor station; (4) performing model calibration with anomaly localization
    analysis when the system''s total NRW volume exceeds its assumed background NRW
    volume; and (5) calibrating other physical properties to fulfil the system''s
    energy balance, especially for the peak-demand hours. The effectiveness of our
    proposed approach has since been tested and verified on three supply zones with
    total pipe length of more than 1000 km, with available monitoring data. Fig. 11
    illustrates the localization results for 8 May 2020 in one water supply zone where
    multiple anomaly events can be localized with a good lead-time of 1–2 days, and
    to within 400 m, or less, from the reported leakage locations. Upon localizing
    the likely anomaly hotspots in the modelled system, Figs. 12 and 13 illustrate
    examples for comparing between the simulated and monitored flows and pressures
    data. It is worthwhile noting that a perfectly calibrated model or the absolute
    agreement between the simulated and monitored values is not achievable or desirable
    for a real water system. Download : Download high-res image (318KB) Download :
    Download full-size image Fig. 11. Example results of anomaly event localization
    via hydraulic model calibration. Download : Download high-res image (268KB) Download
    : Download full-size image Fig. 12. Example results of comparing between simulated
    and monitored flow with/without model calibration for water consumption demand
    pattern(s). Download : Download high-res image (268KB) Download : Download full-size
    image Fig. 13. Example results of comparing between simulated and monitored pressure
    with/without model calibration for pipe roughness. In Fig. 13, we note that it
    is not possible to achieve a complete match (100% goodness-of-fit) between the
    model simulated and monitored pressure data due to likely simulation errors, notwithstanding
    the prior model calibration done. To calibrate a hydraulic simulation model with
    complete accuracy, it is imperative to access to all forms of monitored data from
    the field which include, but not limited to, pressure, flows, valve settings,
    pipe roughness and water consumptions. At this stage, however, without knowing
    the exact valve settings, pipe roughness and true water consumption patterns from
    the field, the case study analyses could only calibrate those properties with
    a level of engineering judgement and assumptions, hence resulting in a level of
    inaccuracy being embedded in the simulation results generated from the calibrated
    model. In addition, even with available flow and pressure monitoring data collected
    from the field, there are likely to be data errors (e.g., data drift) present
    in those data which can again affect the level of accuracy in the calibration
    process, unlike from using synthetic data solely to calibrate any physics-based
    simulation model. In a nutshell, the benchmark study shows that the calibrated
    hydraulic model, that is a high-fidelity digital twin component, is augmented
    to better represent the physical water supply network by (a) localizing anomaly
    events including, but not limited to, the reported leaks to within 400 m, or less,
    with lead-time of 1–2 days, as shown in Table 4; (b) addressing the system''s
    initial flow imbalance by estimating the daily NRW volume and localizing the possible
    anomaly events to fulfil the system''s daily total flow balance; and (c) calibrating
    pipe roughness values for relevant segments of the underground pipes to improve
    the system''s daily total energy balance, especially during the peak-demand hours,
    by attaining an average mean absolute percentage error (MAPE) score of about 3.0%.
    Table 4. Summary of anomaly localization results. Reported Anomaly date Distance
    between the reported & localized anomalies (m) Localized lead time (days) 5/6/2020-Leak
    1 116 1 5/6/2020-Leak 2 323 0 5/7/2020-Leak 3 146 0 5/10/2020-Leak 4 372 0 5/11/2020-Leak
    5 99 3 112 2 190 1 On the other hand, without having an adequately well-calibrated
    hydraulic simulation model to perform the anomaly localization analysis, we would
    expect the latter''s simulated localization results to represent the likely actual
    leakage hotspots in the field, which can be attributed to several possible modelling
    errors, as follows: • Inaccurate Demand Patterns: By not calibrating, to the best
    possible extent, the representative water usage pattern(s) by the real customers
    in the modelled network, it then becomes difficult to (1) identify any statistically
    significant increase in the monitored flow data due to hidden leak events, or
    (2) differentiate between the real and apparent water losses, hence hindering
    the estimation of the true non-revenue water (NRW) volume in the modelled system
    that is essential for the localization analysis on any given day. • Inaccurate
    Physical Properties: By not calibrating, to the best possible extent, the key
    physical properties (e.g., pipe roughness) in the modelled network, the true energy
    (pressure head) loss due to the supply of water from the source tank/reservoir
    to the local customers cannot be estimated accurately. This issue may indirectly
    subsume the intricate/key energy difference between the predicted baseline and
    monitored pressure data for detecting and localizing the likely sources of leaks
    in the network. In summary, uncalibrated models will result in different inaccurate
    results (flows and pressures) from one system to another. It is impossible to
    quantify the difference as general guideline, but it is no doubt that the inaccurate
    hydraulic simulation results surely lead to the leakage localization with little
    confidence. Thus, it is imperative to calibrate and recalibrate the model as proposed
    in section 3.3 (as illustrated in Fig. 9), which contributes to establish an ‘ever-green’
    digital twin for SWG. Model calibration does need monitoring data, which is collected
    by placing the sensors (hardware) throughout the water distribution network. Thus,
    it does justify the hardware requirement for digital thread. 5. Discussions The
    proposed SWG DT framework has been applied to a real water system in Singapore
    by performing anomaly detection and localization with available hydraulic monitoring
    data. The detected and localized anomaly events have since been validated with
    the field reported leak records and evaluated quantitatively. Overall, the following
    key lessons can be learned from the practical application. 1) SWG DT is not another
    digital model, but rather represents a new paradigm that requires seamless integration
    of historical and near real-time monitoring data with various digital models for
    visualization, data-driven analysis, physics-based simulation, and decision-making
    support. Each type of the models plays its important role in SWG DT, but none
    of them solely represents a DT. 2) Although a near real-time hydraulic and/or
    water quality simulation model is believed to be closest to a DT, but it is not
    a DT. Real-time or near real-time simulation model plays an important role in
    SWG DT. The key difference between a DT and a calibrated physics-based simulation
    model is the digital thread by streamlining and automating the data integration
    and enables bi-direction communication between a physical water distribution network
    and its digital twin, which encompasses the relevant digital models. 3) For more
    than a decade, many research works have been done and published on topic of anomaly
    or leaks/pipe bursts detection. But few was conducted using real complex water
    network, using the hydraulic datasets with unavoidable noises, and evaluated with
    the real reported anomaly events recorded in the field. Most recently, a number
    of researchers applied deep machine learning techniques (Javadiha et al., 2019)
    (Zhou et al., 2019) (Zanfei et al., 2022) for pipe burst detection with simulated
    dataset and anomaly event occurrences. These studies resulted in a very high accuracy
    of anomaly detection and localization by using the simulated dataset, which, unfortunately,
    does not encapsulate the true operational complexity of real water networks in
    the field. The research methods based on the simulated dataset for very small
    water networks having just a few dozens of pipes must be revisited and validated
    with a real system and its associated hydraulic datasets. 4) It is no doubt that
    a fully implemented SWG DT will bring end users with tremendous benefits for long/short-term
    system planning, predictive maintenance and optimizing daily operation. Multiple
    challenges for implementing SWG DT are: (a) cybersecurity protocols for data encryption,
    access privileges that include a clear definition of user roles, addressing known
    device vulnerabilities, and conducting routine security audits; (b) DT requires
    massive amounts of data to be collected and drawn from numerous endpoints, each
    representing a potential area of weakness; (c) lack of interest from water utilities
    due to various reasons that might affect the adoption of DT paradigm in water
    industry and (d) difficulty in integrating the various stakeholders across the
    organizations of a water utility/company to work as a single team for the adoption
    of DT. 5) DT has become a marketing buzzword but there is a very limited amount
    of research that has been carried out with focus on the core technologies for
    enabling a genuine SWG DT in the water industry. In this regard, future research
    in SWG DT is expected to be fruitful and fast-growing, especially in developing
    DT-enabler methods and practically effective approaches for mitigating DT-barriers.
    Successful applications of SWG DT will also be helpful to prove the true operational
    benefits of SWG DT for the water industry in general. 6. Conclusions As an emerging
    trend, digital twin is increasingly becoming the holistic approach of digital
    transformation for infrastructure industry, so is for water supply network as
    exemplified by the example application of the high-fidelity digital twin for anomaly
    detection and localization. In this paper, a generic DT framework has been proposed
    for WDN management and the framework is employed for developing the DT-based approach
    for SWG anomaly detection and localization by integrating both (1) data-driven
    models and (2) hydraulic model simulation/calibration. For the former component,
    an automatic model training procedure has been implemented to optimize anomaly
    event detection and classification parameters by considering both statistical
    process control and ML-based prediction models. By then combining both components,
    i.e., model training procedure together with hydraulic model calibration, the
    solution process then enables engineers to construct evergreen high-fidelity DT,
    which can be readily applicable with great potential capacity in addressing many
    other challenges in SWG management and operation. Thus far, the integrated DT
    framework has been applied and validated on real water systems, in the context
    of Singapore, by analysing actual monitored flow and pressure data to detect anomaly
    events, followed by performing hydraulic model calibration to localize the detected
    anomaly events. Although evergreen DT for SWG does require for additional effort
    for data collection, learning and adapting to new technologies, adopting digital
    twin approach will bring multiple benefits of cost-effectiveness and risk reduction
    for infrastructure owners and stakeholders, eventually improves the bottom line
    for water utilities and the water service for customers. As elaborated in the
    paper, the benefits of digital twin cannot be effectively realized without digital
    threads enabling the connection for two-way data/information flow between the
    physical and digital spaces. This, however, may remain as the primary challenge
    for many water utilities to fully embrace digital twin paradigm and thus deserves
    innovation and investment in near future. Declaration of Competing Interest The
    authors declare that they have no known competing financial interests or personal
    relationships that could have appeared to influence the work reported in this
    paper. Acknowledgements This research is supported by the Singapore National Research
    Foundation under its Competitive Research Program (CRP) (Water) and administered
    by PUB (PUB-1804-0087), Singapore''s National Water Agency. Data availability
    The data that has been used is confidential. References Bentley Systems, Incorporated
    2018 Bentley Systems, Incorporated ContextCapture user manual Exton, PA, USA (2018)
    Google Scholar Bentley Systems, Incorporated 2019 Bentley Systems, Incorporated
    WaterGEMS user manual Bentley systems, incorporated, Exton, PA, USA (2019) Google
    Scholar Boschert et al., 2017 S. Boschert, C. Heinich, R. Rosen Next-generation
    digital twin Proceedings of TMCE, Las Palmas de Grad Canaria, Spain (2017) Google
    Scholar Braun et al., 2018 A. Braun, S. Tuttas, U. Stilla, A. Borrman BIM-Based
    Progress Monitoring Building information modeling, Springer (2018) Google Scholar
    Catalano et al., 2022 C. Catalano, L. Paliano, F. Calabrese, M. Cattaldo, L. Mancarella,
    F. Tommasi Anomaly detection in smart agriculture systems Comopuers in Industry,
    143 (2022) (2022), Article 103750 View PDFView articleView in ScopusGoogle Scholar
    Chew et al., 2022 A. Chew, Z.Y. Wu, T. Walski, J. Cai, X. Meng, J. Pok, et al.
    Daily Model Calibration with Water Loss Estimation and Localization Using Continuous
    Monitoring Data in Water Distribution Networks ASCE J. Water Resources Planning
    and Management., 148 (5) (2022) 1943-5452.0001546 Google Scholar Digital Twin
    Consortium 2022 Digital Twin Consortium, \"What is Digital twin,\" https://www.digitaltwinconsortium.org,
    2022. Google Scholar Friederich et al., 2022 J. Friederich, D.P. Francis, S. Lazarova-Molnar,
    N. Mohamedc A framework for data-driven digital twins of smart manufacturing systems
    Computers in Industry, 136 (2022) (2022), Article 103586 View PDFView articleView
    in ScopusGoogle Scholar Grieves, 2006 M. Grieves Product lifecycle management:
    Driving the next generation of lean thinking McGraw-Hill, New York, USA (2006)
    Google Scholar Grieves and Vickers, 2017 M. Grieves, J. Vickers Digital Twin:
    Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems ransdisciplinary
    perspectives on complex systems, Springer, Cham (2017), 10.1007/978-3-319-38756-7_4
    Google Scholar Javadiha et al., 2019 M. Javadiha, J. Blesa, A. Soldevila, V. Puig
    Leak localization in water distribution networks using deep learning 6th Int.
    Conf. Control. Decis. Inf. Technol. CoDIT (2019) Google Scholar Jung and Lansey,
    2015 D. Jung, K. Lansey Water Distribution System Burst Detection Using a Nonlinear
    Kalman Filter ASCE J. Water Resour. Plann. Manage., 141 (5) (2015), Article 04014070
    CrossRefView in ScopusGoogle Scholar Kalfarisi et al., 2022 R. Kalfarisi, A. Chew,
    J. Cai, X. Meng, J. Pok, Z.Y. Wu Predictive Modeling Framework Accelerated by
    GPU Computing for Smart Water Grid Data-Driven Analysis in Near Real-Time Advances
    in Engineering Software, 173 (November) (2022), Article 103287 View PDFView articleView
    in ScopusGoogle Scholar Kritzinger et al., 2018 W. Kritzinger, M. Karner, G. Traar,
    J. Henjes Digital Twin in manufacturing: A categorical literature review and classification
    IFAC Papers Online, 51 (2018), pp. 1016-1022 View PDFView articleView in ScopusGoogle
    Scholar Li et al., 2019 Q. Li, Z.Y. Wu, A. Rahman Evolutionary deep learning with
    extended Kalman filter for effective prediction modeling and efficient data assimilation
    ASCE J. Computing in Civil Engineering, 33 (3) (2019), Article 04019014 View in
    ScopusGoogle Scholar Liu et al., 2019 D. Liu, J. Chen, D. Hu, Z. Zhang Dynamic
    BIM-augmented UAV safety inspection for water diversion project ComputersinIndustry,
    108 (2019) (2019), pp. 163-177 View PDFView articleGoogle Scholar Loureiro et
    al., 2016 D. Loureiro, C. Amado, A. Martins, D. Vitorino, A. Mamade, S. Coelho
    Water distribution systems flow monitoring and anomalous event detection: A practical
    approach Urban Water Journal, 13 (3) (2016), pp. 242-252 CrossRefView in ScopusGoogle
    Scholar Lui et al., 2018 Z. Lui, N. Meyendorf, N. Mrad The role of data fusion
    in predictive maintenance using digital twin 44th Annual Review of Progress in
    Quantitative Nondestructive Evaluation, Volume 37, AIP Conference Proceedings
    (2018) Google Scholar Madni et al., 2019 A.M. Madni, C.C. Madni, S. Lucero Leveraging
    digital twin technology in model-based systems engineering Systems, 7 (7) (2019)
    Google Scholar Madubuike et al., 2022 O.C. Madubuike, C.J. Anumba, R. Khalla A
    review of digital twin applications in construction Journal of Information Technology
    in Construction (ITcon), 27 (2022), pp. 145-172, 10.36680/j.itcon.2022.008 View
    in ScopusGoogle Scholar Meng et al., 2022 X. Meng, Z.Y. Wu, J. Cai, J. Pok, A.
    Chew, R. Kalfarisi Improving Near Real-Time Anomaly Event Classification with
    Trend Change Detection for Smart Water Grid Operation Management Urban Water Journal
    (2022), 10.1080/1573062X.2022.2058565 Google Scholar Mounce et al., 2002 S. Mounce,
    A. Day, A. Wood, A. Khan, P. Widdop, J. Machell A neural network approach to burst
    detection Water Science and Technology, 45 (4–5) (2002), pp. 237-246 Vols. CrossRefView
    in ScopusGoogle Scholar Mounce and Boxall, 2011 Ed. S.R. Mounce, J. Boxall Online
    Monitoring and Detection Z.Y. Wu (Ed.), Water loss reduction, Bentley Institute
    Press, Exton, PA, USA., ISBN (2011) 978-1-934493-08-3 Google Scholar Mounce et
    al., 2014 S.R. Mounce, R. Mounce, T. Jackson, J. Austin, J.B. Boxall Pattern matching
    and associative artificial neural networks for water distribution system time
    series data analysis Journal of Hydroinformatics, 16 (2014), pp. 617-632 CrossRefView
    in ScopusGoogle Scholar Pedersen et al., 2021 A. Pedersen, M. Borup, A. Brink-Kjær,
    L. Christiansen, P. Mikkelsen Living and Prototyping Digital Twins for Urban Water
    Systems: Towards Multi-Purpose Value Creation Using Models and Sensors Water,
    13 (5) (2021), p. 592 CrossRefView in ScopusGoogle Scholar Perez et al., 2014
    Perez, et al. Leak Localization in Water Networks: A Model-Based Methodology Using
    Pressure Sensors Applied to a Real Network in Barcelona IEEE Control Systems Magazine,
    34 (4) (2014), pp. 24-36 CrossRefGoogle Scholar Pesantez et al., 2022 J.E. Pesantez,
    F. Alghamdi, S. Sabu, G. Mahinthakumar, E.Z. Berglund Using a digital twin to
    explore water infrastructure impacts during the COVID-19 pandemic Sustainable
    Cities and Society, 77 (Feb) (2022), Article 103520, 10.1016/j.scs.2021.103520
    View PDFView articleView in ScopusGoogle Scholar Phua et al., 2022 A. Phua, C.H.
    Davies, G.W. Delaney A digital twin hierarchy for metal additive manufacturing
    Computers in Industry, 140 (2022) (2022), Article 103667 View PDFView articleView
    in ScopusGoogle Scholar Ponce et al., 2014 M.V.C. Ponce, L.E.G. Castasnon, V.P.
    Cayuela Model-based leak detection and location in water distribution networks
    considering an extended-horizon analysis of pressure sensitivities Journal of
    Hydroinformatics, 16 (3) (2014), pp. 649-670 View in ScopusGoogle Scholar PUB
    Singapore''s National Water Agency 2016 PUB Singapore''s National Water Agency
    Managing the Water Distribution Network with a Smart Water Grid Smart Water, 4
    (2016), p. 1, 10.1186/s40713-016-0004-4 Google Scholar Romano et al., 2014a M.
    Romano, Z. Kapelan, D. Savic Automated Detection of Pipe Bursts and other Events
    in Water Distribution Systems ASCE J. Water Resour. Plann. Manage. (4) (2014),
    p. 140 457–467 View in ScopusGoogle Scholar Romano et al., 2014b M. Romano, Z.
    Kaplena, D. Savic Evolutionary Algorithm and Expectation Maximization Strategies
    for Improved Detection of Pipe Bursts and Other Events in Water Distribution Systems
    ASCE J. Water Resour. Plann. Manage. (2014), pp. 572-584 View in ScopusGoogle
    Scholar Rosen et al., 2015 R. Rosen, G. von Wichert, K.D. Bettenhausen About the
    importance of autonomy and digital twins for the future of manufacturing IFAC
    Papers OnLine, 48 (3) (2015), pp. 567-572 View PDFView articleView in ScopusGoogle
    Scholar Sacks et al., 2018 R. Sacks, A. Kedar, A. Borrmann, A. Ma, L. Brilakis,
    P. Hüthwohl, et al. See Bridge as next-generation bridge inspection: Overview,
    information delivery manual, and model view definition Automation in Construction,
    90 (June) (2018), pp. 134-145 View PDFView articleView in ScopusGoogle Scholar
    Semeraro et al., 2021 C. Semeraro, M. Lezooche, H. Panetto, M. Dassisti Digital
    Twin Paradigm: A systematic literature review Computers in Industry, 130 (2021),
    10.1016/j.compind.2021.103469 Sept. 2021 Google Scholar Sophocleous et al., 2019
    S. Sophocleous, D.A. Savic, Z. Kapelan Leak Localization in a Real Water Distribution
    Network based on Search-Space Reduction ASCE J. Water Resour. Plann. Manage.,
    145 (7) (2019), 10.1061/(ASCE)WR.1943-5452.0001079 Google Scholar Tao et al.,
    2014 T. Tao, H.D. Huang, F. Li, K.L. Xin Burst detection using an artificial immune
    network in water-distribution systems ASCE J. Water Resour. Plann. Manage., 140
    (10) (2014), Article 04014027 CrossRefView in ScopusGoogle Scholar Torfs et al.,
    2022 E. Torfs, N. Nicolaï, S. Daneshgar, J.B. Copp, H. Haimi, D. Ikumi, et al.
    The transition of WRRF models to digital twin applications Water Sci Technol,
    85 (10) (2022), pp. 2840-2853, 10.2166/wst.2022.107 View in ScopusGoogle Scholar
    United Nations 2018 United Nations World urbanization prospects (2018) https://population.un.org/wup
    New York Google Scholar van Manen et al., 2021 M. van Manen, L. olde Scholtenhuis,
    H. Voordijk Empirically validating five propositions regarding 3D visualizations
    for subsurface utility projects Engineer., Construc. Architect. Manage., 29 (6)
    (2021), pp. 2535-2553 Google Scholar Vrachimis et al., 2021 S.G. Vrachimis, S.
    Timotheou, D.G. Eliades, M.M. Polycarpou Leakage detection and localization in
    water distribution systems - A model invalidation approach Control Engineer. Prac.,
    110 (May) (2021), Article 104755 View PDFView articleView in ScopusGoogle Scholar
    Wu et al., 2018 Y. Wu, S. Liu, K. Smith, X. Wang Using Correlation between Data
    from Multiple Monitoring Sensors to Detect Bursts in Water Distribution Systems
    ASCE J. Water Resour. Plann. Manage., 144 (2) (2018) 1943-5452.0000870 Google
    Scholar Wu, 2002 Z.Y. Wu Darwin Calibrator Technique Reference Haestad methods,
    Waterbury, CT (2002) Google Scholar Wu, 2009 Z.Y. Wu A Unified Approach for Leakage
    Detection and Extended Period Model Calibration of Water Distribution Systems
    Urban Water Journal, 6 (1) (2009), pp. 53-67 CrossRefView in ScopusGoogle Scholar
    Wu, 2018 Z.Y. Wu, \"Enabling Digital Twins for Resilient Infrastructure,\"2018.
    https://www.linkedin.com/feed/update/urn:li:activity:6772281679156457472/. Google
    Scholar Wu et al., 2022 Z.Y. Wu, A. Chew, X. Meng, J. Cai, J. Pok, R. Kalfarisi,
    et al. Data-Driven and Model-Based Framework for Smart Water Grid Anomaly Detection
    and Localization IWA AQUA – Water Infrastructure, Ecosystems and Society, 71 (1)
    (2022), p. 31, 10.2166/aqua.2021.091 View PDFView articleGoogle Scholar Wu and
    He, 2021 Z.Y. Wu, Y. He Time Series Data Decomposition-based Anomaly Detection
    and Evaluation Framework for Smart Water System Management ASCE J. Water Resour.
    Plann. Manage. (2021), pp. 1943-5452, 10.1061/(ASCE)WR 0001433 Google Scholar
    Wu et al., 2010 Z.Y. Wu, P. Sage, D. Turtle Pressure Dependent Leakage Detection
    Approach and its Application to District Water Systems ASCE J. Water Resour. Plann.
    Manage., 136 (1) (2010), pp. 116-128 View in ScopusGoogle Scholar Wu et al., 2002
    Z.Y. Wu, T. Walski, R. Mankowski, J. Cook, M. Tryby, G. Herrin Calibrating Water
    Distribution Model Via Genetic Algorithms Proceedings of the AWWA IMTech Conference,
    CO, USA, Denver (2002) Google Scholar Zanfei et al., 2022 A. Zanfei, A. Menapace,
    B.M. Brentan, M. Righetti, M. Herrera Novel approach for burst detection in water
    distribution systems based on graph neural networks Sustainable Cities and Society,
    86 (2022), Article 104090 View PDFView articleView in ScopusGoogle Scholar Zhou
    et al., 2019 X. Zhou, Z. Tang, W. Xu, F. Meng, X. Chu, K. Xin, et al. Deep learning
    identifies accurate burst locations in water distribution networks Water Research,
    166 (2019), Article 115058 View PDFView articleView in ScopusGoogle Scholar Cited
    by (9) A continuous leakage real-time localization method based on space phase
    image of elastic wave field with improved CNN 2024, Measurement: Journal of the
    International Measurement Confederation Show abstract Design, development, and
    optimization of a conceptual framework of digital twin electric grid using systems
    engineering approach 2024, Electric Power Systems Research Show abstract Flow
    forecasting for leakage burst prediction in water distribution systems using long
    short-term memory neural networks and Kalman filtering 2023, Sustainable Cities
    and Society Show abstract An Optimized Bio-inspired Localization Routing Technique
    for Sustainable IIoT Networks &amp; Green Cities 2023, Sustainable Cities and
    Society Show abstract Review on environmental aspects in smart city concept: Water,
    waste, air pollution and transportation smart applications using IoT techniques
    2023, Sustainable Cities and Society Show abstract A formal model for reliable
    digital transformation of water distribution networks 2023, Procedia Computer
    Science Show abstract View all citing articles on Scopus View Abstract © 2023
    Elsevier Ltd. All rights reserved. Recommended articles Probabilistic warm solutions-based
    multi-objective optimization algorithm, application in optimal design of water
    distribution networks Sustainable Cities and Society, Volume 91, 2023, Article
    104424 Mohammad Mehdi Riyahi, …, Ali Haghighi View PDF Zero-net energy management
    for the monitoring and control of dynamically-partitioned smart water systems
    Journal of Cleaner Production, Volume 252, 2020, Article 119745 Carlo Giudicianni,
    …, Kemi Adeyeye View PDF A strategy for sustainable urban water management using
    water network partitioning with optimal booster pump configuration: A case study
    Sustainable Cities and Society, Volume 90, 2023, Article 104391 Xuan Khoa Bui,
    Doosun Kang View PDF Show 3 more articles Article Metrics Citations Citation Indexes:
    9 Captures Readers: 44 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply."'
  inline_citation: '>'
  journal: Sustainable Cities and Society
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: High Fidelity Digital Twin-Based Anomaly Detection and Localization for Smart
    Water Grid Operation Management
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Khan O.H.
  - Gurpinar O.
  - Banerjee R.
  - Kano D.P.
  - Tellez C.
  - Suarez G.G.
  - Grijalva R.
  - Ali S.
  citation_count: '0'
  description: The surveillance team in an oilfield has the difficult task of maximizing
    hydrocarbon production while delaying water production to achieve optimum profitability.
    For instance, in a waterflooded asset, it needs to intelligently allocate the
    available injection water to achieve a balanced sweep of oil across the reservoir.
    A sound understanding of the subsurface flow and inter-well communication is essential
    here, but the team rarely has access to high-fidelity tools that can help them
    understand the reservoir behavior. Reservoir simulation models encapsulate all
    the acquired data along with the interpretations of the subsurface teams and are
    thus ideal tools to base such decisions on but are seldom used in operations as
    the associated workflows do not conform to the fast decision-making timeframe.
    This paper presents a system that leverages cloud scalability, automation, and
    data analytics to extract insights from subsurface models and generate timely
    operational advice. The solution connects subsurface models with real-time production
    data through a cloud-based data platform to automate the update of models with
    the latest production data. An optimizer is employed that uses streamline-based
    properties to determine the optimum operating settings for the injection and production
    wells. The optimization objective can be tailored to align with the asset management
    goals, such as reducing water recycling and balancing recovery or voidage across
    the field. The outputs from the subsurface model are translated into actionable
    insights through a dashboard of fit-for-purpose analytics that presents operational
    recommendations along with the forecasted outcomes. The system also performs a
    series of domain-derived confidence checks on the model to quantify the reliability
    of the recommendations generated. A virtual field management framework is used
    that captures all the field operating constraints. The entire workflow is automated
    and can be scheduled to run at a defined frequency so that the surveillance team
    always has access to proposed actions based on the latest production conditions.
    To further accelerate the time to decision, machine learning-based avatars of
    the full subsurface model and reduced-order representations can be integrated
    into the framework. A case study is presented that describes the application of
    this subsurface model-driven operational optimization system to a field in the
    Amazon basin, South America. Using the solution, the subsurface modeling, production
    surveillance, and operations teams were able to work together to identify opportunities
    for reducing water recycling and increasing oil production while considerably
    accelerating the decision-making process due to automation and focused analytics.
    The paper demonstrates how the latest digital technologies have removed the barriers
    to the use of detailed subsurface models in guiding operations. The framework
    described can be used to improve the operational decision-making in any hydrocarbon
    asset regardless of the recovery mechanism.
  doi: 10.2118/215984-MS
  full_citation: '>'
  full_text: '>

    "Advertisement All Content All Proceedings Society of Petroleum Engineers (SPE)
    Abu Dhabi International Petroleum Exhibition and Conference                              Advanced
    Search Cart Register Sign In HOME LATEST CONFERENCE ALL YEARS OTHER PROCEEDINGS
    VISIT SPE CITATION MANAGER ADIPEC October 2–5, 2023 Abu Dhabi, UAE Day 1 Mon,
    October 02, 2023 ISBN: 978-1-959025-07-8 Previous Paper Next Paper Subsurface-Guided
    Production Surveillance for High-Confidence Operational Decisions Osama Hasan
    Khan; Omer Gurpinar; Raj Banerjee; Daniel Pupim Kano; Camillo Tellez; Gabriel
    Gil Suarez; Ricardo Grijalva; Samad Ali Paper presented at the ADIPEC, Abu Dhabi,
    UAE, October 2023. Paper Number: SPE-215984-MS https://doi.org/10.2118/215984-MS
    Published: October 02 2023 Cite Share Get Permissions Abstract The surveillance
    team in an oilfield has the difficult task of maximizing hydrocarbon production
    while delaying water production to achieve optimum profitability. For instance,
    in a waterflooded asset, it needs to intelligently allocate the available injection
    water to achieve a balanced sweep of oil across the reservoir. A sound understanding
    of the subsurface flow and inter-well communication is essential here, but the
    team rarely has access to high-fidelity tools that can help them understand the
    reservoir behavior. Reservoir simulation models encapsulate all the acquired data
    along with the interpretations of the subsurface teams and are thus ideal tools
    to base such decisions on but are seldom used in operations as the associated
    workflows do not conform to the fast decision-making timeframe. This paper presents
    a system that leverages cloud scalability, automation, and data analytics to extract
    insights from subsurface models and generate timely operational advice. The solution
    connects subsurface models with real-time production data through a cloud-based
    data platform to automate the update of models with the latest production data.
    An optimizer is employed that uses streamline-based properties to determine the
    optimum operating settings for the injection and production wells. The optimization
    objective can be tailored to align with the asset management goals, such as reducing
    water recycling and balancing recovery or voidage across the field. The outputs
    from the subsurface model are translated into actionable insights through a dashboard
    of fit-for-purpose analytics that presents operational recommendations along with
    the forecasted outcomes. The system also performs a series of domain-derived confidence
    checks on the model to quantify the reliability of the recommendations generated.
    A virtual field management framework is used that captures all the field operating
    constraints. The entire workflow is automated and can be scheduled to run at a
    defined frequency so that the surveillance team always has access to proposed
    actions based on the latest production conditions. To further accelerate the time
    to decision, machine learning-based avatars of the full subsurface model and reduced-order
    representations can be integrated into the framework. A case study is presented
    that describes the application of this subsurface model-driven operational optimization
    system to a field in the Amazon basin, South America. Using the solution, the
    subsurface modeling, production surveillance, and operations teams were able to
    work together to identify opportunities for reducing water recycling and increasing
    oil production while considerably accelerating the decision-making process due
    to automation and focused analytics. The paper demonstrates how the latest digital
    technologies have removed the barriers to the use of detailed subsurface models
    in guiding operations. The framework described can be used to improve the operational
    decision-making in any hydrocarbon asset regardless of the recovery mechanism.
    Keywords: geology, reservoir simulation, united states government, optimization
    problem, upstream oil & gas, asia government, geologist, waterflooding, workflow,
    artificial intelligence Subjects: Well & Reservoir Surveillance and Monitoring,
    Improved and Enhanced Recovery, Reservoir Simulation, Information Management and
    Systems, Waterflooding, Well Operations and Optimization Copyright 2023, Society
    of Petroleum Engineers DOI 10.2118/215984-MS You can access this article if you
    purchase or spend a download. Sign in Don''t already have an account? Register
    Personal Account Username Password SIGN IN Reset password Register Sign in via
    OpenAthens Pay-Per-View Access $28.00 BUY THIS ARTICLE Annual Article Package
    – 25 $225 BUY DOWNLOADS Annual Article Package – 50 $400 BUY DOWNLOADS View Your
    Downloads Advertisement View Metrics Email Alerts Proceedings Paper Activity Alert
    Alert Latest Conference Proceeding Alert Advertisement Suggested Reading Enhancing
    Waterflooding Performance Using a combined Data Driven and Physical Modeling Approach
    23ADIP An AI-Driven Multiwell Placement and Scheduling Method 23ADIP AI-Assisted
    History Matching Application to a Large Onshore Carbonate Reservoir 23ADIP Drilling
    in the Digital Age: Case Studies of Field Testing a Real-Time ROP Optimization
    System Using Machine Learning 23MEDT Integrating Learnings from Matrix-Acid Stimulation
    of Smart Liner Completions – A Template for the Future 23ATCE Advertisement Explore
    Journals Conferences eBooks Publishers Connect About Us Contact Us Content Alerts
    SPE Member Pricing Resources Terms of Use Privacy Help KBART Engage Subscribe
    Advertise   This site uses cookies. By continuing to use our website, you are
    agreeing to our privacy policy. Accept"'
  inline_citation: '>'
  journal: Society of Petroleum Engineers - ADIPEC, ADIP 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Subsurface-Guided Production Surveillance for High-Confidence Operational
    Decisions
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Araujo S.O.
  - Peres R.S.
  - Filipe L.
  - Manta-Costa A.
  - Lidon F.
  - Ramalho J.C.
  - Barata J.
  citation_count: '1'
  description: The agricultural sector worldwide faces serious problems regarding
    water scarcity, which demands innovative management methods to optimise water
    use. In response, we propose the Intelligent Data-Driven Decision Support for
    Agricultural Systems (ID3SAS) methodology, which offers a scalable, flexible,
    and cloud-based decision support system for real-time supervision and control
    in agricultural environments. Aligned with the prevailing trends of Agriculture
    4.0, ID3SAS integrates data acquisition, cloud-based storage, machine learning,
    predictive analysis, and run-time reasoning to facilitate decision-making processes,
    thereby assisting users in making more informed and sustainable decisions. In
    a case study with tomato plants, ID3SAS-irrigated plants showed 20.9% reduction
    in water consumption and 26.4% increase in crop production compared to traditional
    methods, which despite the controlled laboratory environment setting, highlights
    the methodology's promising potential in addressing water scarcity and enhancing
    agricultural productivity.
  doi: 10.1109/ACCESS.2023.3324813
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 11 Intelligent
    Data-Driven Decision Support for Agricultural Systems-ID3SAS Publisher: IEEE Cite
    This PDF Sara Oleiro Araújo; Ricardo Silva Peres; Leandro Filipe; Alexandre Manta-Costa;
    Fernando Lidon; José Cochicho Ramalho; José Barata All Authors 1 Cites in Paper
    405 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract
    Document Sections I. Introduction II. The Id3sas Methodology III. Id3sas Implementation
    IV. Results and Discussion V. Conclusion, Limitations and Future Work Show Full
    Outline Authors Figures References Citations Keywords Metrics Footnotes Abstract:
    The agricultural sector worldwide faces serious problems regarding water scarcity,
    which demands innovative management methods to optimise water use. In response,
    we propose the Intelligent Data-Driven Decision Support for Agricultural Systems
    (ID3SAS) methodology, which offers a scalable, flexible, and cloud-based decision
    support system for real-time supervision and control in agricultural environments.
    Aligned with the prevailing trends of Agriculture 4.0, ID3SAS integrates data
    acquisition, cloud-based storage, machine learning, predictive analysis, and run-time
    reasoning to facilitate decision-making processes, thereby assisting users in
    making more informed and sustainable decisions. In a case study with tomato plants,
    ID3SAS-irrigated plants showed 20.9% reduction in water consumption and 26.4%
    increase in crop production compared to traditional methods, which despite the
    controlled laboratory environment setting, highlights the methodology’s promising
    potential in addressing water scarcity and enhancing agricultural productivity.
    ID3SAS Methodology, composed of nine core components: External Source, Sensing,
    Control, Gateway, Cloud-based Data Storage, Data Processing, Artificial Intelligence,
    Deci...View more Published in: IEEE Access ( Volume: 11) Page(s): 115798 - 115815
    Date of Publication: 16 October 2023 Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2023.3324813
    Publisher: IEEE Funding Agency: SECTION I. Introduction Water scarcity is a growing
    concern in many regions around the world, due to climate change, population growth,
    urbanisation, industrial activities, and intensive agriculture [1], [2]. Addressing
    this issue requires a comprehensive approach that includes water conservation,
    efficient use of resources and investment in new technologies and infrastructure
    to improve water availability and quality. Information and Communication Technology
    (ICT), particularly regarding sensing technologies, robotics, Internet of Things
    (IoT), cloud computing, Big Data, and Artificial Intelligence (AI), are playing
    an increasingly important role in the digitalisation of agricultural systems.
    Food and Agriculture Organization (FAO) of the United Nations denominates this
    role as “Digital Agricultural Revolution” [3], also known as “Agriculture 4.0”
    [4], [5], [6], [7], [8]. It is expected that the use of such technologies will
    bring significant advances worldwide, improving the productivity and efficiency
    of agricultural sector, and enhancing the quantity, quality and availability of
    agricultural products. Moreover, it will aid in adapting to climate change, curbing
    food loss and waste, optimising the utilization of natural resources, and ultimately
    leading to a reduced environmental impact in the foreseeable future [8]. The research
    work envisioned here is focused on the design of a methodology for the development
    of a Decision Support System (DSS) oriented to the agricultural sector, and from
    this, the Intelligent Data-Driven Decision Support for Agricultural Systems (ID3SAS)
    methodology is born. This proposed methodology is aligned with the current Agriculture
    4.0 trend and combines sensing technologies, IoT, cloud computing, data analysis
    based on AI methods, and decision-making support to address the issues faced by
    farmers/managers in agricultural environments. For this experiment, a Wireless
    Sensor and Actuator Network (WSAN) was deployed to collect diverse parameters
    such as air temperature, humidity, soil moisture, ultraviolet (UV) radiation,
    infrared (IR) radiation, and visible light using sensors, with actuators (relay
    and water pump) enabling on- field actions. Data are transferred from the sensor
    nodes to a gateway via WiFi using Message Queuing Telemetry Transport (MQTT) communication
    protocol, which is posteriorly sent to a cloud server for storage. Machine Learning
    (ML) models were created for soil moisture and time-to-water estimation. Extra
    Trees Regression (ExtraTR) and AdaBoost provided better performance and, for this
    reason, were the models implemented in the system. For the DSS, we used the Fuzzy
    Logic theory to determine the irrigation time according to the sensors’ measurements
    and weather forecasting. At last, an interactive and user-friendly dashboard was
    created for data visualisation, recommendations, and controlling actions, in real-time.
    Our solution was implemented and tested on tomato plants (Lycopersicon esculentum
    L.), which will be referred to as the “prototype” in this article. The case study
    consisted of having two crops, where one was watered according to the manufacturer’s
    recommendations (i.e., the traditional method) and the other was watered according
    to the recommendations of the ID3SAS system. At the end of the study, both methods
    were evaluated considering the number and weight of tomatoes, as well as water
    consumption. It is important to note that this prototype offers essential guidance
    for implementing the ID3SAS methodology. Its successful implementation empowers
    farmers/managers with data-driven insights and smart recommendations. This facilitates
    the optimisation of irrigation schedules, efficient resource allocation and improved
    crop management, leading to increased productivity, reduced water consumption
    and minimised environmental impact. As a result, ID3SAS provides guidance for
    the widespread adoption of sustainable agricultural practices. To summarise, the
    contributions of the present article are as follows: We provide a generic methodology
    for the creation of a Smart Agricultural System (SAS) that can be easily adopted
    and adapted by the research community for additional testing and improvement.
    It is practical, affordable, and straightforward to implement; We cover a proper
    method for managing and preserving wireless sensor information through the utilisation
    of cloud computing technology and open-source software solutions; The experiment
    work collects data and takes actions in the field, which can significantly improve
    agricultural productivity, efficiency, and sustainability; The ID3SAS methodology
    supports decision-making in real-time, which is beneficial for farmers to address
    the dynamic nature of agricultural environments. The remainder of the article
    is structured as follows: subsection I-A presents the background of topic under
    study, regarding some technologies of Agriculture 4.0, followed by an overview
    of related work that can be found in current literature, in subsection I-B. Section
    II presents the overall design of ID3SAS methodology and it is divided into three
    subsections: ID3SAS concept in subsection II-A, its goals and requirements in
    subsection II-B and system architecture in subsection II-C. ID3SAS implementation
    in a prototype can be found in Section III. The results of the proposed system
    are presented and discussed in Section IV. In Section V, we conclude the research
    work, its limitations, and remarks regarding future work. A. Background Agriculture
    is a complex and multi-disciplinary field that involves the collaboration of various
    stakeholders (including farmers, managers, producer organizations, suppliers,
    auditors, and researchers) for effective management, decision-making, and the
    successful implementation of sustainable agricultural practices. Advances in sensor
    technology have provided an invaluable capability to continuously monitor targeted
    agricultural parameters, while simultaneously, robotics has significantly enhanced
    the automation of farming procedures. Moreover, the rise of affordable and accessible
    computing power has fostered the creation of sophisticated decision support tools,
    which can substantially assist in the realm of improved agriculture management,
    leveraging data science, Big Data, and ML-based approaches. In this regard, the
    comprehensive exploration and analysis of Agriculture 4.0’s emerging trends and
    core technologies were meticulously documented in the research conducted by [8].
    Considering the scientific insights presented in this article, it is appropriate
    to briefly introduce the trends that follow. Wireless Sensor and Actuator Networks:
    In recent years, Wireless Sensor Network (WSN) and WSAN have been widely used
    in numerous agricultural applications to improve traditional farming methods.
    Three fundamental tasks are carried out by sensor networks: sensing, communication,
    and computation. The difference between WSN and WSAN is that the latter includes
    an additional element: an actuator. This can be any physical device (such as lamps,
    fans, valves, or water pumps) that interacts with the environment. These networks
    are distributed arrangements of several sensors and actuators “nodes” interconnected
    by wireless links. Internet of Things: Conceptually, IoT refers to the capacity
    to connect physical and digital “things” with standard and interoperable communication
    protocols [9]. Since agricultural activities need to be continuously monitored
    and managed, agriculture is a perfect candidate for the deployment of IoT technologies.
    A comparison of the most used wireless communication protocols is presented in
    [8], featuring the basic characteristics of Bluetooth, Long Range Wide Area Network
    (LoRaWAN), Near Field Communication (NFC), Radio-Frequency IDentification (RFID),
    Sigfox, WiFi, Zigbee, and mobile communications. Within their analysis, the authors
    concluded that Sigfox, ZigBee, and LoRaWAN exhibit the highest suitability for
    IoT-based agricultural applications, due to their energy-efficient nature, cost-effectiveness,
    and superior communication range. Cloud computing: Nowadays, cloud computing has
    attracted significant interest within the agricultural sector as according to
    [9], it provides (a) reasonably priced data storage services that significantly
    lowers storage costs for agricultural enterprises; (b) intelligent large-scale
    computer systems that convert these agricultural data into knowledge; and (c)
    a secure platform for the development of diverse agricultural IoT applications.
    Data Analytics, Big Data, and Machine Learning: As stated in the research conducted
    by [10], data analytics refers to the application of computer systems to analyse
    large datasets to support decision-making. This field is highly interdisciplinary,
    incorporating elements from various scientific disciplines such as statistics,
    ML, pattern recognition, system theory, operations research, and AI. The phases
    of data analysis, as outlined by [10], include (a) data preparation (planning,
    data collection, feature generation, and data selection); (b) preprocessing (cleaning,
    filtering, completion, correction, standardisation, and transformation); (c) analysis
    (visualisation, correlation, regression, forecasting, classification, and clustering);
    (d) postprocessing (interpretation, documentation, and evaluation). Data analytics,
    through Big Data, AI/ ML algorithms or statistics, has been identified as one
    of the main drivers behind the implementation of Agriculture 4.0 [8]. On the one
    hand, Big Data is defined as datasets whose size is beyond the ability of typical
    database software tools to capture, store, manage, and analyse [11]. Generally,
    Big Data is combined with the term “5V”, representing its five dimensions [12]:
    (a) volume, (b) velocity, (c) variety, (d) value, and (e) veracity. On the other
    hand, ML can be described as a computer program or system that possesses the ability
    to learn specific tasks without explicit programming [13]. It is a process that
    involves computers or machines to make decisions or recommendations by leveraging
    multiple data inputs. In a review made by [14] regarding ML applications in agriculture,
    the authors concluded that 61% of the analysed articles used ML methods for crop
    management (22% disease detection, 20% yield prediction, 8% weed detection, 8%
    crop quality, and 3% species recognition), 19% for livestock management (12% livestock
    production and 7% animal welfare), 10% for soil management and 10% from water
    management. Decision Support System: The definition of DSS is not consensual in
    the literature. In the present document, we will use the definition provided by
    [8]: software mechanism which aids an end-user to easily and quickly leverage
    complex data to improve decision-making processes. This involves transforming
    both raw data and the results obtained from analytics tools into actionable knowledge,
    presented through a user interface in a comprehensible manner. There are several
    ways to classify a DSS, depending on the type to be implemented, the design, and
    the application [15]. B. Related Work Significant work has been invested in studying
    the many aspects of Agriculture 4.0 during the past few years. An automatic DSS
    was proposed in [16] for managing irrigation in agriculture by utilising several
    autonomous nodes to measure soil and climatic parameters and estimate weekly irrigation
    needs. ML techniques are used for the reasoning engine of the system. A smart
    platform was proposed in [17], which aims to assist farmers in saving resources
    and enhancing farming productivity. This platform combines a WSN and drone imagery
    to gather data, allowing the tracking of soil irrigation and pest detection. The
    gathered data is transmitted to the cloud, where a rule-based system deduces the
    appropriate action based on it. In [18] the authors proposed a low-cost IoT system
    based on a WSN for agricultural applications. This system consists of sensor nodes
    (Arduino-based with a WiFi module and various sensors), a gateway (a Raspberry
    Pi including Mosquitto and Node-RED), and a user interface. The data are sent
    to the gateway via WiFi, using the MQTT protocol and posteriorly transferred to
    the cloud service (IBM Bluemix) for storage and visualisation in real-time. Reference
    [19] developed an autonomous and solar-powered IoT-based system for monitoring
    nitrate concentration in water bodies (lakes, streams, rivers). The collected
    data from sensor nodes are transferred to a gateway which, in its turn, sends
    data to a cloud server for storage. WiFi and LoRa protocols are used for data
    communication. The LoRa protocol was shown to be more efficient in terms of overall
    energy consumption, in addition to allowing data to travel larger distances compared
    to the standard WiFi protocol. Similarly, [20] developed an IoT-based sensor node
    to monitor a greenhouse. This node is composed of a microcontroller (ESP8266 NodeMCU),
    various sensors (air temperature and humidity, capacitive soil moisture, soil
    temperature, and light intensity), and two power units (lithium-ion batteries
    and a solar panel). The microcontroller is responsible for data collection and
    transmission to the gateway. Both Mosquitto and Node-RED are used in this implementation.
    In [21] an IoT-based system was proposed for smart agricultural applications.
    The authors designed a simulation environment (using Riverbed Modeler) with various
    sensors (e.g., temperature, rain, light, wind, pH, acoustic, light intensity,
    humidity, location, and chemical properties) that collect specific cornfield data
    and send them to a coordinator node. This node is responsible for communicating
    with a drone that, in its turn, sends data to the gateway. Node-RED gathers data
    from the Riverbed Modeler and then stores it in InfluxDB database. Visual interfaces
    and graphs are provided by Grafana. Reference [22] proposed an IoT sensor simulator,
    using Node-RED, IBM Bluemix, and IBM IoT sensors, and was designed specifically
    for lettuce plants grown in greenhouses or indoor agricultural environments. The
    culmination of these research efforts has played an important role in propelling
    the agricultural sector forward through innovative and creative approaches, consistently
    prioritising sustainability. These efforts encompass a diverse range of domains,
    including irrigation management, resource conservation, pest detection, water
    quality monitoring, and greenhouse monitoring. Employing cutting-edge technologies
    such as IoT, ML, cloud computing, and drone imagery, these initiatives seek to
    improve agricultural efficiency, productivity and resource optimisation. However,
    these works also demonstrate general limitations including reliance on rule-based
    reasoning, potential lack of adaptability to dynamic conditions, limited integration
    of advanced data analytics and ML, and a focus on specific aspects of agricultural
    management rather than comprehensive DSS. In light of this, the proposed methodology,
    ID3SAS, bridges these gaps by combining sensing technology, advanced data analytics,
    and fuzzy logic reasoning within a scalable and cloud-based DSS. By addressing
    limitations seen in prior works and providing guidelines for seamless integration,
    ID3SAS presents a promising unified approach for shaping the future of agriculture–
    a vision that harmonises intelligence, sustainability, and global societal demands.
    SECTION II. The Id3sas Methodology In this section, an overview of the design
    and development of the proposed methodology - ID3SAS - is provided. It begins
    with a description of the methodology’s concept, its main goals, and requirements.
    The methodology is then introduced, along with an overview of its individual structural
    components. A. Concept ID3SAS seeks to provide researchers, and developers who
    want to build a SAS with a set of essential requirements, specifications, and
    guidelines, distilled from a comprehensive study of the latest advancements in
    the field [8]. Within the context of this research work, a SAS is a system that
    combines different technologies (IoT, sensors, actuators, AI, and cloud computing,
    among others) in order to give the possibility to farmers and managers to have
    control over the agricultural processes and make better and quicker decisions.
    The following services are accessible through this system: Monitoring: Several
    parameters are measured by sensors that are strategically placed in the agricultural
    field and/or greenhouses (sometimes referred to as the “physical environment”
    in this document) and transferred, using proper communication protocols, to a
    local-based or cloud-based service for storage and further processing and analysis.
    External sources could also provide valuable data, which could include forecasting
    services (e.g., OpenWeatherMap API [23]) or satellite Earth observation services
    (e.g., Copernicus-related services [24]). Data transmission, storage, and processing:
    IoT technology is in charge of sending the collected data from the physical environment
    to a gateway server, which can send to a local-based or cloud-based server for
    storage and further processing. Data analysis and predictions: AI-based methods,
    particularly in the facet of ML, can identify complex patterns, trends, and relationships
    in the multidimensional, heterogeneous data, making accurate predictions and providing
    a strong foundation for improved decision-making and operations management. Decision
    support: A DSS seeks to assist managers and farmers in making quicker and more
    effective decisions to facilitate the planning of their agricultural activities.
    Control: It may be necessary to act on the physical environment (automatically
    or under user control). For instance, activating and controlling actuators to
    change the environment or the condition of the process in a predefined manner.
    A six-level model of automated decision-making based on AI is described in [25]
    and [26], starting from level 0 (no autonomy) until level 5 (full autonomy). The
    successful development and implementation of a SAS in the agricultural sector
    envisions to assist in sustainable development, by providing social, economic,
    and environmental benefits. These benefits could include improving crop productivity
    and farm profitability, optimising the management of farm inputs (e.g., irrigation
    water), and improving both storage and marketing activities thus ensuring food
    security. B. Goals and Requirements Goals have long been recognised as essential
    elements involved in the Requirements Engineering process as they provide the
    rationale for requirements [27], [28]. Considering this, Table 1 presents the
    goals that have been defined for ID3SAS. The description of these goals can be
    found in Table 7 (Appendix). These goals have as a foundation the review made
    by the authors in [8]. TABLE 1 ID3SAS goals These goals can be seen as general
    key aspects to advance the agricultural sector towards the digitalisation and
    empowerment of a SAS with AI, from the integration of multiple sensor nodes to
    the adoption of data-driven and automated processes. In addition, it is important
    to consider a generic approach that can be adopted across diverse agricultural
    scenarios. Furthermore, facilitating the utilisation of technology involves providing
    practical solutions that are user-friendly and accessible for farmers to embrace
    technological advancements in agriculture. A requirement describes the capabilities
    or characteristics that a product or service must provide to deal with a specific
    problem. According to [29], the requirements can be categorised in: (1) Functional
    Requirement (FR): ” 1. statement that identifies what results a product or process
    shall produce. 2. requirement that specifies a function that a system or system
    component shall perform ”, and (2) Non-Functional Requirement (NFR): ” 1. software
    requirement that describes not what the software will do but how the software
    will do it ”. Table 2 lists both FR and NFR defined for the ID3SAS. The description
    of each requirement can be found in Table 8 (presented in Appendix). TABLE 2 List
    of Functional and Non-Functional Requirements for ID3SAS However, it is important
    to remember that these requirements should be seen as a foundation for the design
    and implementation of a SAS within the scope of Agriculture 4.0. Depending on
    the case study at hand, requirements will have to be refined or new requirements
    will have to be adapted, as long as they meet the particular needs and desires
    of the stakeholders. C. Methodology ID3SAS is an integrative methodology that
    formalises the steps that should be taken to design and implement a SAS in the
    context of Agriculture 4.0. It proposes valuable tools for the agricultural sector
    and is designed with generic applicability in mind, in order to be used in different
    types of crops, fields, and environmental conditions, while still offering a wide
    variety of features and high usability. Figure 1 illustrates the ID3SAS methodology,
    its core components, data flow, and phases. This methodology has as a foundation
    the conceptual cloud-based IoT architecture proposed by [8]. This architecture
    consists of four layers (from bottom to top: physical, communication, service,
    and application layers). Adapting this architecture to ID3SAS, we have: Physical
    layer: Responsible for monitoring and actuating functions, where data are collected
    from the IoT devices and actions are made in the field through actuators. It includes
    the Sensing and Control components. Communication layer: Where adequate network
    allows the data communication between layers. It includes the Gateway component.
    Service layer: Responsible for data storage, processing, and analysis. It includes
    the Database, Data Processing, Artificial Intelligence, and Decision Support components.
    Application layer: For the access of agricultural information and control actions.
    It includes the Human-Machine Interface component. Other sources (optional): External
    dataset(s). It concludes the External Source component. FIGURE 1. The ID3SAS Methodology,
    composed of nine core components: External Source, Sensing, Control, Gateway,
    Cloud-based Data Storage, Data Processing, Artificial Intelligence, Decision Support
    and Human-Machine Interface. Show All This methodology is also divided into seven
    stages representing the data flow, starting from: Data Acquisition: The first
    step of ID3SAS methodology and, as the name implies, is where data are collected.
    In this phase we have (a) Sensing component, responsible for acquiring the data
    directly from the sensors or other devices in the Physical Layer; and (b) External
    Source component (optional), an external data source could be any source in the
    Internet that does not belong to the local network (e.g., weather forecasting
    services). The combination of different types of sensing devices can produce a
    more global informative dataset. Data Transmission: After collecting the desired
    data, it is necessary to transfer it to the next phase so that it can be stored,
    processed, and analysed. The physical devices (sensors and/or actuators) can be
    connected to a Gateway component that plays a role as the data forwarder between
    different networks. The choice of the most adequate communication protocol fully
    depends on the requirements of the system to be designed and implemented, as well
    as economic, accessibility, and capacity factors. Data Storage: Cloud computing
    (e.g., Database-as-a-Service (DBaaS) [30] and Platform-as-a-Service (PaaS) [31])
    is very convenient for applications that use a huge amount of data, as it provides
    inexpensive data storage services for text, image, video, and other formats, which
    considerably reduces storage costs for agricultural enterprises. As so, a Cloud-based
    Data Storage component can be found in this phase, where data from the Sensing
    component and external sources are virtually stored in a cloud-based server for
    further processing and analysis. Data Processing and Analysis: Sometimes, data
    collected from sensors and/or external sources are not ready to be directly used
    for decision-making processes. Facing this, the Data Processing component is responsible
    for transforming these “raw” data and preparing it for the next phase. Additionally,
    the Artificial Intelligence component can be used for advanced data analysis and
    generating predictions. Reasoning: In this phase, the Decision Support component
    receives inputs from the previous phases and calculates and deducts watering suggestions
    (e.g., precise time for watering the fields). Data transformation is done by reasoning
    processes, i.e., the component contains a Rule base and Fact base that enables
    the system to infer new data and make decisions. This system uses log data of
    the system, combined with AI-based techniques and agricultural expertise to create
    new appropriate rules and thus enrich the Rule base. User Interaction: Users can
    easily visualise the information from the physical environment by requesting data
    from the Sensing component and/or External Source component. To this end, an Human-Machine
    Interface (HMI) should be designed to support the processes of the entire SAS.
    According to the user’s demands, the output of this phase could be data/information
    for monitoring purposes, and/or physical action realised by an actuator. After
    the data leave the Human-Machine Interface component, there are two possible paths,
    as it is necessary to understand if there is a need to act in the physical layer:
    Does the agro-system “need intervention?”. If NO, the data flow ends with the
    HMI component; If YES, the user sends the final command to the actuators in the
    Control component. Actuation: In this phase, we find the Control component, which
    is responsible for controlling the actuators that are placed in the physical environment.
    Therefore, the level of autonomy of the system needs to be defined. Additionally,
    it is possible to see in Figure 1 two input points - Start - indicating that the
    system can acquire data from both internal (sensor) and external sources. There
    are also two output points - End - indicating whether the system is a Monitoring
    system (for monitoring purposes) or a Control system (applicable when the physical
    environment needs actuator intervention). SECTION III. Id3sas Implementation The
    ID3SAS methodology was deployed and tested in a lab scenario: a prototype consisting
    of tomato plants, located inside the UNINOVA room, at NOVA School of Science and
    Technology (NOVA-SST), Caparica, Portugal. The idea of this case study was to
    have separate tomato plants (of the same batch), where one was watered every three
    days according to the manufacturer’s specification, and the other is watered according
    to the recommendations of the ID3SAS system (Figure 2). It is worth highlighting
    that the goal of this prototype is to provide a reference for implementing the
    ID3SAS methodology. As such, only two plants were used since the focus was the
    functionality testing of the reference implementation. Regardless, it possesses
    the flexibility to be customised and scaled to accommodate larger agricultural
    scenarios. FIGURE 2. ID3SAS case study: example of two tomato pots (from the same
    batch), one of which received irrigation recommendations according to the manufacturer
    (‘control plant’) and the other received irrigation recommendations from the ID3SAS
    system (‘test plant’). Show All The material used for this case study is listed
    below: Plants: Tomato plants (Lycopersicon esculentum L.), inserted in plots with
    a surface area of 0,04 m 2 . Hardware: (a) two microcontrollers (ESP32 NodeMCU
    and ESP8266 NodeMCU); (b) one single-board computer (Raspberry Pi 3 Model B);
    (c) six sensors (two air temperature and humidity sensors DHT11, two sunlight
    sensors SI1145, two capacitive soil moisture sensors); (d) two actuators (one
    2-channel SPDT Relay, one submersible water pump with a flow rate of, approx.,
    120L/hour ); (e) Bresser Weather Station 7-in-1 Sensor; (f) Other relevant components
    (external power supply, breadboards, jumper cables, water tank). Software: (a)
    Arduino IDE; (b) Docker; (c) Eclipse Mosquitto; (d) Node-RED; (e) MongoDB Atlas;
    (f) Jupyter Notebook; (g) Weather API - OpenWeatherMap. A. Sensing Component In
    this prototype, the Sensing component consists of two sensor nodes, namely Sensor
    Node 1 and Sensor Node 2. Both of these nodes are equipped with a set of sensors,
    including the SHT31, SI1145, and capacitive soil moisture sensors. The primary
    distinction lies in the microcontroller employed by each node, as Sensor Node
    1 integrates the ESP32 NodeMCU, whereas Sensor Node 2 utilises the ESP8266 NodeMCU.
    Figure 3 shows the hardware structure for Sensor and Actuator Node 1. In both
    sensor nodes, the microcontroller is responsible for sending the collected data
    from sensors to the Gateway component (subsection III-C) via WiFi using MQTT protocol.
    The SHT31 (air temperature and humidity) and SI1145 (sunlight) sensors are calibrated
    based on the weather station readings. The soil moisture sensor is calibrated
    by correlating the values when the sensor is placed in the air and when it is
    immersed in water. Data are collected with 1 hour sampling time. FIGURE 3. ESP32
    NodeMCU connected to sensors (SHT31, SI1145, capacitive soil moisture), actuators
    (2-channel relay, water pump), and an external power supply. Show All B. External
    Source Component The External Source component was designed to correlate the parameters
    obtained by the physical sensors and by external sources (such as global and local
    weather stations, satellites, and radars). The developed External Source component
    relies upon the OpenWeatherMap API. This Application Programming Interface (API)
    is useful for retrieving both current and forecasted weather data (up to a duration
    of 5 days) for any given location across the globe. Subsequently, this functionality
    will prove valuable for the Decision Support component (subsection III-G), as
    it will require consideration of significant indicators such as precipitation
    patterns, including current and forecasted rainfall within the upcoming hours.
    Based on these indicators, the ID3SAS system will make informed decisions regarding
    the watering or non-watering of plants. C. Gateway Component The Gateway component
    is responsible for distributing data from the physical layer and from external
    sources to other components of the methodology. The communication is carried out
    using MQTT protocol (over WiFi network) through tools like Mosquitto and Node-RED,
    which serve as a communicator and integrator, respectively. MQTT is a suitable
    solution for this prototyping experiment, as it provides a simple and lightweight
    Publisher-Subscriber architecture that fits well within the scope of such IoT
    solutions. For monitoring purposes, the WSAN functions as a Publisher, while Node-RED
    assumes the role of a Subscriber. Conversely, in terms of control, Node-RED acts
    as a Publisher, while the WSAN as a Subscriber. It is important to acknowledge
    that, despite the previous mention of Sigfox, ZigBee, and LoRa as the most suitable
    wireless communication protocols for IoT-based agricultural applications, this
    article employed WiFi for the developed case study. This choice was made due to
    the availability of ESP32 and ESP8266 microcontrollers equipped with built-in
    WiFi modules, which were readily accessible for use in the experiment. In Figure
    4 the flow was configured to get data from the Sensor Node 1 via MQTT and store
    it in the cloud database, using MongoDB Atlas. It also provides functionality
    to trigger sensor data retrieval, send commands to the ESP32, and manually refresh
    the sensors. The same logic was used to configure Sensor Node 2. FIGURE 4. Node-RED
    flow configured to get data from the Sensor Node 1 (publisher) via MQTT to the
    Node-RED (subscriber) and store them in the MongoDB Atlas database. The nodes
    used are: (1a,b,c,d,e,f) MQTT in, (2) Join, (3a,b) Function, (4) Debug, (5) Mongodb
    out, (6) Split, (7) Switch, (8a,b,c,d,e,f) Link out, (9) Inject, (10a,b) MQTT
    out and (11) UI Button node. Show All D. Database Component The selected database
    for this experiment is MongoDB Atlas,1 a cloud-based Not Only-Structured Query
    Language (NoSQL) database solution provided by MongoDB. It was chosen due to its
    reliability, scalability, and security features, making it an ideal choice for
    implementing the ID3SAS system. The deployment of Database component was facilitated
    using Node-RED, by installing the “node-red-node-mongodb” package [32]. This package
    includes three nodes: Mongodb, Mongodb in, and Mongodb out, which enable the seamless
    storage and retrieval of data in/from a MongoDB instance (Figure 4). E. Data Processing
    Component The Data Processing component is crucial to clean, transform, and prepare
    the data for various purposes, such as visualisation or for training AI-based
    models. Figure 5 shows the processes of Artificial Intelligence and data pre-processing.
    The pre-processing stage was made using the Python language within Jupyter Notebook
    and implemented in Node-RED. It is important to note that specific pre-processing
    steps and techniques may vary depending on the characteristics of the data and
    the requirements of the intended ML models. FIGURE 5. ID3SAS Artificial Intelligence
    process and data pre-processing subprocess. Show All 1) Feature Engineering Feature
    Engineering was an important step in this process in order to improve the performance
    and interpretability of ML models. This involved selecting relevant features,
    eliminating redundancy, and creating new informative features derived from existing
    ones. These efforts aimed to provide additional information to the models, thereby
    enhancing their overall effectiveness. Table 3 provides an example of Feature
    Engineering applied in the prototype. In this example, the dataset was transformed
    to enable auto-regression modelling, such that a model can be built using the
    past recent values (lags) of a time series as explanatory variables (input), to
    predict future observations (output). As so, two engineered features were created
    - “Soil Moisture (t-1)” and “Soil Moisture (t+1)”. These new features are derived
    from the original “Soil Moisture” input feature and represent the soil moisture
    values (from sensors) at the previous and subsequent times, respectively. By introducing
    these engineered features, the ML model can capture temporal dependencies and
    patterns in the data that might be useful for predicting future soil moisture
    levels. The same logic was used for the parameters “AirTemp”, “AirHum”, “UVLight”,
    “VisibleLight” and “IRLight”. TABLE 3 Example of Feature Engineering used in the
    data pre-processing process 2) Handle Missing Values and Outliers Missing values
    were handled appropriately using Pandas package.2 To remove the outliers, the
    techniques Z-score and Interquartile Range (IQR) were used. 3) Standardisation
    and Normalisation Standardisation and normalisation [33] are two common techniques
    used in data pre-processing to transform the features of a dataset in preparation
    for creating ML models. Standardisation adjusts features to have zero mean and
    unit variance, while normalisation scales features to a specific range, typically
    between 0 and 1. F. Artificial Intelligence Component The process of creating
    predictive models using ML for regression tasks typically involves several key
    steps: data preparation, data splitting, model selection, training, evaluation,
    and fine-tuning. Figure 5 illustrates the steps of ID3SAS AI process: Data split:
    the dataset is divided into training and testing subsets, typically with a split
    of around 70-80% for training and 20-30% for testing; Model selection: the choice
    of regression models [33] includes linear regression, decision trees, random forests,
    etc.; Model training: the selected model is trained using the training data; Model
    evaluation: the trained model is assessed in terms of performance using the test
    dataset. Evaluation metrics such as Mean Squared Error (MSE), Root Mean Squared
    Error (RMSE), Mean Absolute Error (MAE), or () are commonly used; Fine-tuning:
    if the model’s performance is unsatisfactory, it is necessary to refine or fine-tune
    the model to enhance its performance. Techniques such as Grid Search Cross Validation
    (GridSearchCV) [33] can be used to find the best combination of hyperparameters.
    1) Model Selection, Training and Evaluation Five regression algorithms were selected
    to predict the soil moisture and the time-to-water, namely: Random Forest, ExtraTR,
    Gradient Boosting Regression (GradientBR), and AdaBoost (with Decision Tree) [33].
    The following features were passed to the model: Inputs (from sensors): “AirTemp”,
    “AirHum”, “SoilMoisture”, “UVLight”, “VisibleLight” and “IRLight”. Inputs (from
    Feature Engineering): “AirTemp(t- n )”, “AirHum(t- n )”, “SoilMoisture(t- n )”,
    “UVLight(t- n )”, “VisibleLight(t- n )” and “IRLight(t- n )”, where n is the hour
    of monitoring. Outputs: “SoilMoisture(t+ n )” (estimates soil moisture value after
    n hours) and “TimeToWater” (estimates the number of hours remaining until it is
    necessary to water the plants again). Table 4 compares the selected models according
    to their evaluation metrics - RMSE and (equations 1 and 2, respectively). These
    metrics were used to assess the accuracy and performance of the predictive models:
    RMSE R 2 = 1 n ∑ i=1 n ( y i − y ^ i ) 2 − − − − − − − − − − − − √ =1− ∑ n i=1
    ( y i − y ^ i ) 2 ∑ n i=1 ( y i − y ¯ ) 2 (1) (2) View Source where, n represents
    the number of data points, yi the observed values, y ^ i the predicted values,
    and y ¯ the mean of the observed values. The two best models were selected for
    optimisation using GridSearchCV [33]. TABLE 4 Performance evaluation (RMSE and
    R 2 ) of the predictive models for “SoilMoisture(t+ n )” and “TimeToWater” estimations
    2) Deployment The Artificial Intelligence component was deployed in Node-RED.
    Thus, five Predictor nodes were created, namely: “AdaBoost_SoilMoisture_t+1”,
    “AdaBoost_SoilMoisture_ t +12”, “AdaBoost_SoilMoisture_ t+24”, “ExtraTR_ SoilMoisture_t+6”
    and “ExtraTR_ Timetowater”. These models were chosen according to Table 4. G.
    Decision Support Component The Decision Support component aims to aid managers
    and farmers in expediting and enhancing the decision-making process, thereby facilitating
    the strategic planning of their agricultural endeavors. Figure 6 illustrates its
    process. The first step is to retrieve the current data (air temperature and humidity,
    soil moisture, UV, visible light and infrared light) from sensors (Sensing component,
    subsection III-A). If the soil moisture value is higher than the threshold (in
    this case study the limit value is 60%), then the system does not take actions.
    On the other hand, if the value is lower, then the system checks the weather forecasting
    (External Source component, subsection III-B). If it is expected to rain in the
    next 6 hours, the system does not irrigate the plants. Otherwise, if it is not
    expected to rain, the Fuzzy Logic System (FLS) calculates the irrigation time
    in accordance with data retrieved from the sensors. We used Fuzzy Logic to determinate
    irrigation time, as it is useful to handle uncertain and imprecise inputs rather
    than relying on binary classifications (e.g., soil moisture is “dry” or “not dry”),
    allowing for more accurate and flexible irrigation scheduling. FIGURE 6. ID3SAS
    Decision Support process. Show All 1) Defining Parameters The crop’s water needs
    are influenced by weather parameters. Table 5 shows the general relation between
    tomato water needs and air temperature and humidity, cloudiness, UV index [34],
    and wind speed. It is important to note that this Table provides a general indication
    of the relations between the crop water needs and climatic factors, as the actual
    water needs required may vary based on the crop type, soil type, and other environmental
    factors. TABLE 5 General relation between crop water needs and climatic factors
    (air temperature and humidity, cloudiness, UV index, and wind speed). “+”, “++”,
    “– ” and “– – ” represent strong, very strong, weak, and very weak relations,
    respectively. Information based on [35] and [36] for tomato plants From Table
    5, it is possible to take into consideration the following general principles:
    Air temperature: higher temperatures increase water evaporation, leading to greater
    water requirements for plants; Air humidity: lower humidity levels enhance water
    evaporation, necessitating more water for plants in low humidity conditions; Cloudiness:
    clear sky conditions result in elevated evaporation rates and higher water needs,
    while cloudy conditions reduce evaporation and decrease water requirements; UV
    Index: higher UV radiation levels stimulate increased evaporation and transpiration
    in plants, increasing their water needs; Wind speed: strong winds accelerate evaporation
    and can dry out plants, requiring additional irrigation to compensate for the
    enhanced water loss. In this article, the water crop needs are translated to “Irrigation
    Time”, and so was considered the output of the FLS. It has four subparameters,
    namely: “Short” (2 secs), “Medium-short” (3 secs), “Medium-long” (4 secs), and
    “Long” (5 secs). Remembering that the submersible water pump used has a flow rate
    of 120 L/hour (approx.), it implies that the pump irrigates 33.3 mL/second (approx.)
    of water. 2) Fuzzy Sets and Membership Functions The FLS sets and their associated
    membership functions are represented in Figure 7. All three inputs “Air Temperature”,
    “Air Humidity” and “UV Index” and the output “Irrigation Time” have four fuzzy
    sets. The “Cloudiness” and “Wind speed” parameters were not considered, as the
    experiment was performed inside a room. FIGURE 7. Membership functions of Fuzzy
    Logic System: (a) Air Temperature (fuzzy sets: ‘very_cold’, ‘cold’, ‘normal’ and
    ‘hot’), (b) Air Humidity (fuzzy sets: ‘low’, ‘medium_low’, ‘medium_high’ and ‘high’),
    (c) UV Index (fuzzy sets: ‘low’, ‘moderate’, ‘high’ and ‘very_high’) and (d) Irrigation
    Time (fuzzy sets: ‘short’, ‘medium-short’, ‘medium-long’ and ‘long’). Show All
    3) Fuzzy Rules Given the fuzzy sets, there are 64 possible rules that can be generated
    based on Mamdani Fuzzy Inference System [37]. These rules were described using
    the “IF - THEN” condition. Examples: Rule 1: “IF Air Temperature is Very Cold
    AND Air Humidity is Low AND UV Index is Low THEN Irrigation Time is Short”; Rule
    2: “IF Air Temperature is Normal AND Air Humidity is Medium-high AND UV Index
    is High THEN Irrigation Time is Medium-Long”; Rule 3: “IF Air Temperature is Hot
    AND Air Humidity is Low AND UV Index is Low THEN Irrigation Time is Long”. These
    rules were decided based on Table 5 and the professional knowledge of the authors
    of this article. 4) Deployment The Decision Support component was deployed using
    Node-RED. As illustrated in Figure 6, the first step is to set the soil moisture
    value. In this case study, the value is 60%. The second step is to retrieve information
    from the External Source component (subsection III-B), where it is possible to
    understand if it is predicted to rain in the next few hours. However, as the experiment
    was performed indoors, this functionality was not considered for the recommendations.
    The result of this process is the “Irrigation Time”, which maps it to the corresponding
    irrigation label: “Short” (2 secs), “Medium-short” (3 secs), “Medium-long” (4
    secs) or “Long” (5 secs). These outputs will subsequently serve the purpose of
    controlling the duration of the water pump’s operation (subsection III-H), thereby
    regulating the amount of water utilised for watering the respective plant. H.
    Control Component The Control component of the prototype consists of one Actuator
    Node, composed of a microcontroller (ESP32 NodeMCU), a relay (2-channel SPDT Relay),
    and an actuator (submersible water pump) (Figure 3). The relay is used to control
    the water pump. Given that the ESP32/ESP8266 was not sufficient to power both
    the sensors and the water pump, an external power supply was incorporated into
    the system. Depending on the system requirements, the actuators can be controlled
    in two ways: manually or automatically. Figure 8 illustrates the Control component
    process. The outputs generated by the FLS regulate the duration of the water pump’s
    operation, thereby directly controlling the quantity of water utilised for the
    irrigation processes. FIGURE 8. ID3SAS Control process. Show All I. Human-Machine
    Interface Component The ID3SAS dashboard has six tabs offering various features:
    Home tab: Provides real-time data visualisation from sensors, actuators, and weather.
    It also offers recommendations based on the data. (Figure 9). Weather forecasting
    tab: Displays weather forecasts for up to 5 days, using OpenWeatherMap’s API.
    Plant’s Info tab: Contains a dataset with information on various plants, including
    vegetables (beetroot, broccoli, carrot, cucumber, eggplant, garlic, green pea,
    lettuce, onion, pepper, potato, and sweet potato) and fruits (apple, lemon, melon,
    strawberry, tomato, and watermelon). (Figure 10). Historical Data tab: Stores
    weekly data collected from sensors. Predictions tab: Stores weekly data generated
    by predictive ML models. Files tab: Enables users to download data from the database
    (specifically, MongoDB Atlas) in.csv format. FIGURE 9. ID3SAS Human-Machine Interface
    (HMI) dashboard, composed of six tabs: Home, Weather Forecasting, Plant’s Info,
    Historical Data, Predictions, and Files. Show All FIGURE 10. ID3SAS Human-Machine
    Interface (HMI) dashboard: Plant’s Info tab. Show All The user-friendly dashboard
    provided an intuitive interface that allowed users to access real-time data and
    information effortlessly. Moreover, predictions and recommendations are visualised
    in the dashboard, and were based on the analysis of historical data, current conditions,
    and crop-specific requirements. By leveraging this intelligent guidance, users
    could optimise resource allocation, mitigate risks, and maximise crop yield. Beyond
    data visualisation and recommendations, the dashboard also facilitated control
    actions. Users can remotely monitor and adjust irrigation systems, activate or
    deactivate equipment, and implement automated processes for timely interventions.
    SECTION IV. Results and Discussion A. Goals and Requirements The current article
    highlights the implementation of ID3SAS methodology in a laboratory scenario (i.e.,
    the prototype). The aim is to assess the functionality and efficacy of the methodology
    and if it successfully achieves the initially proposed goals (Table 1) and fulfills
    the established requirements (Table 2). Table 6 provides information on the extent
    to which the ID3SAS prototype meets the intended goals and satisfies both FR and
    NFR. TABLE 6 Goals and (functional and non-functional) requirements validation
    for ID3SAS implementation in the prototype While the authors duly recognise the
    importance of plant physiology, crop production, and water consumption in irrigation
    processes, it asserts that, within the scope of this study, the primary focus
    is placed on evaluating the performance of the ID3SAS methodology itself. According
    to this Table, all goals were successfully accomplished for the prototype, with
    the exception of goal 7 - Achieve robustness to dynamic environmental conditions.
    The outcome can be attributed to the controlled laboratory setting in which the
    experiment was conducted, where dynamic environmental factors such as rainfall
    and wind were absent. Consequently, the corresponding requirement NFR-10, which
    relates to robustness, could not be fulfilled. In order to address this, the acquisition
    of more resilient and outdoor-ready hardware, including sensors and actuators,
    will be necessary. The authors are fully aware of this and have plans to incorporate
    it into a future outdoor case study in the near future. Regarding goal 6 - Achieve
    general applicability to different scenarios - and despite the fact that ID3SAS
    methodology was implemented and tested exclusively in tomato plants, a notable
    feature has been integrated into the HMI dashboard (Figure 10). This feature incorporates
    information pertaining to various vegetables and fruits, encompassing essential
    parameters such as the minimum, maximum, and optimum temperature for vegetative
    growth, relative humidity, and photoperiodism. Consequently, users can conveniently
    navigate the dashboard and select the specific plant of interest. By doing so,
    the system will provide the corresponding requirements tailored to the selected
    plant, enabling effective decision-making and facilitating the implementation
    of relevant strategies. B. Case Study - Prototype ID3SAS methodology was tested
    on a case study that consisted of having tomato plants in separated pots, where
    one was watered according to the manufacturer (i.e., every three days) and the
    other is watered according to the recommendations of the ID3SAS system (Figure
    2). After conducting the experiment (from March to April 2023), measurements were
    taken to assess water consumption and tomato production in both plants. The results
    indicate that the plant watered in accordance with ID3SAS recommendations had
    a water consumption of 2190 mL and a crop production of 148 g. In contrast, the
    plant irrigated according to conventional methods had a water consumption of 2770
    mL and a crop production of 109 g. The findings demonstrate a reduction in water
    consumption of 20.9% and an increase in crop production of 26.4% when using the
    ID3SAS recommended irrigation technique in comparison to traditional methods.
    Nevertheless, the authors are aware of the limited representativeness of the case
    study, as two tomato plants are not representative of the agricultural reality.
    Consequently, it becomes imperative to undertake a comprehensive implementation
    on a medium-large scale scenario, in order to validate the efficacy of the ID3SAS
    system in terms of both production yield and the water consumption used for irrigation
    purposes. The authors hold the expectation that, upon conducting a case study
    of a larger scale, the outcomes pertaining to water consumption and crop production
    will exhibit similarly promising results. C. Hardware and Software The entirety
    of the setup depicted in this case study exemplifies a low-cost approach to implementing
    a SAS, with a total cost of less than 300 euro. This expense consists of ± 200euro
    allocated to sensors, actuators, and weather station (which functioned as the
    reference point for accurate measurements), and ± 70euro to computing equipment.
    From all the material used in the experiment, some conclusions can be drawn: (1)
    we chose the ESP32 and ESP8266 microcontrollers instead of Arduino due to their
    built-in WiFi and Bluetooth modules; (2) we did not notice any difference in performance
    between the ESP32 and the ESP8266, thereby we suggest that the more cost-effective
    option can be pursued; (3) a high disparity exists between a resistive soil moisture
    sensor and a capacitive and corrosion-resistant soil moisture sensor. Initially,
    the resistive sensor was employed, but after a week of operation, the sensor was
    corroded, leading to inaccurate measurements. Consequently, it is recommended
    to employ a capacitive and corrosion-resistant soil moisture sensor; (4) the 7-in-1
    Weather Station was exclusively used to calibrate the sensors, specially in terms
    of air temperature, humidity and UV measurements; (5) the utilisation of a 2-Channel
    SPDT (Single Pole Double Throw) Relay was determined based on the availability
    of resources at hand. However, it should be noted that, for the experiment, only
    one actuator was employed (submersible water pump), connected to a single relay.
    As so, if there is only one actuator connected to the WSAN, it is recommended
    to purchased a non-2-channel relay module instead, as this would allow cost savings
    without compromising the intended functionality; (6) an external power supply
    (12VDC/2.1A/25W) was used to facilitate the seamless operation of the ESP modules,
    sensors and actuators. It was observed that in cases where a node solely consists
    of sensors without any actuators, the requirement for an external power supply
    is rendered unnecessary. However, when designing a SAS based on ID3SAS methodology,
    it is imperative to consider the adaptation of the equipment to the specific scenario
    and budgetary constraints. For instance, the selection of appropriate sensors
    that are outdoor-ready might entail higher costs. Regarding the software, the
    selection of open-source software was motivated by its widespread availability,
    enabling researchers/developers interested in developing a SAS based on the ID3SAS
    methodology to access and utilise such software freely. D. Id3sas Components In
    the present experiment, by implementing the Sensing component (subsection III-A),
    the prototype was able to gather important agricultural data such as air temperature,
    humidity, sunlight, and soil moisture. These data served as inputs for subsequent
    components in the system, enabling informed decision-making and efficient control
    of irrigation actions. The Database component (subsection III-D) was implemented
    involving a cloud-based storage, namely MongoDB Atlas. This approach should be
    the most appropriated choice for storing agricultural information, as it requires
    a good storage capability for huge volumes of data. However, in situations where
    enterprise networks restrict access to cloud services, storing the data locally
    becomes a viable alternative. The Data Processing component (subsection III-E)
    was important to pre-process data. Feature Engineering was used to generate engineered
    features based on existing sensor inputs, allowing the predictive ML models to
    capture temporal dependencies and patterns in data. Missing values and outliers
    were also handled appropriately. With regard to the Artificial Intelligence component
    (subsection III-F), the evaluation results of the predictive ML models presented
    in Table 4 indicate that ExtraTR and AdaBoost exhibited superior performance in
    estimating soil moisture levels and predicting time-to-water, respectively. The
    ExtraTR model achieved a RMSE of 5.57 for “SoilMoisture(t+6)” estimation and a
    of 0.79. For “TimeToWater” estimation, it achieved a RMSE of 7.26 and a of 0.89.
    On the other hand, the AdaBoost model outperformed the ExtraTR model in terms
    of RMSE and for “SoilMoisture(t+1)” (3.81 and 0.91, respectively), “SoilMoisture(t+12)”
    (6.73 and 0.73, respectively), and “SoilMoisture(t+24)” (8.11 and 0.61, respectively)
    estimations. Furthermore, the output generated by the “TimeToWater” model (Figure
    11) was found to be more accurate when compared to the “SoilMoisture(t+ n )” model.
    While it is observed that the “SoilMoisture(t+1)” model has the lowest RMSE and
    highest (Table 4), its practical usefulness is limited for short-term predictions.
    In turn, the “TimeToWater” model offers enhanced planning capabilities over significantly
    longer time horizons. Additionally, although auto-regression models typically
    exhibit strong performance over short time spans, in this specific scenario, a
    decline in performance can be observed after 24 hours, whereas the “TimeToWater”
    model demonstrates success beyond 70 hours and with a smaller dataset. Moreover,
    in terms of interpretability, from an end-user perspective, the scheduling of
    irrigation events is easier to comprehend than the degradation of soil moisture
    levels. FIGURE 11. Comparison of real values and predicted values (ExtraTR and
    AdaBoost models) for “TimeToWater” parameter. Show All The Decision Support component
    (subsection III-G) assists users in making informed decisions and effectively
    planning their agricultural activities. Its process involves retrieving current
    data from sensors, checking weather forecasts, and utilising Fuzzy Logic approach
    for irrigation time calculations. The result is the determination of irrigation
    time, categorised as “Short”, “Medium-short”, “Medium-long”, or “Long”. These
    categories are then used to control the duration of the water pump’s operation,
    regulating the amount of water used for irrigation. By adjusting the “Irrigation
    Time”, the system effectively manages and optimises the irrigation process, ensuring
    appropriate and efficient utilisation of water resources. The Control component
    plays an important role in managing the actuators within the physical environment.
    As a result, it becomes imperative to define the level of autonomy the system
    should possess. In the context of this prototype, the decision to control the
    actuators manually or automatically will affect the overall functionality, performance,
    and application of the system. Lastly, the HMI component (subsection III-I), served
    as a powerful tool, empowering users with real-time information, personalised
    recommendations, and control actions. It improved decision-making capabilities,
    contributing to more sustainable and successful farming practices. SECTION V.
    Conclusion, Limitations and Future Work This article focuses on the implementation
    of the ID3SAS methodology, which represents a major breakthrough for the agricultural
    sector. By integrating wireless sensor data, field actuators, IoT, cloud computing,
    advanced data analytics, predictive models, and decision support tools, it offers
    significant contributions to creating a cutting-edge SAS, providing farmers with
    real-time decision-making capabilities that can lead to increased productivity
    and reduced water consumption. Embracing the transformative potential of Agriculture
    4.0 technologies, the ID3SAS methodology paves the way for more sustainable and
    efficient agricultural practices. ID3SAS was implemented and tested in a laboratory
    scenario, referred to as the prototype. The primary objective is to evaluate the
    functionality and effectiveness of the methodology in achieving the proposed objectives
    and fulfilling the established requirements. While the study acknowledges the
    significance of plant physiology, crop production, and water consumption in irrigation
    processes, it primarily emphasises assessing the performance of the ID3SAS methodology
    itself. However, it is imperative to consider the limitations of the current study.
    The experiment was conducted in a controlled laboratory setting, lacking dynamic
    environmental factors such as rainfall and wind, which limits the generability
    of the findings to real-world agricultural conditions. To address this, future
    research should focus on conducting outdoor case studies to evaluate the robustness
    and performance of the ID3SAS methodology under varying environmental conditions.
    Moreover, further research is needed to expand the applicability of ID3SAS to
    different crops and agricultural contexts. This could involve refining the predictive
    models to accommodate crop-specific requirements and optimising the decision-making
    algorithms for diverse farming practices. Additionally, the acquisition of more
    resilient and outdoor-ready hardware, including sensors and actuators, will be
    crucial for the successful implementation of the system in real-world agricultural
    settings. Continued research and development efforts in these areas will contribute
    to the advancement and widespread adoption of intelligent data-driven DSS in agriculture,
    ultimately promoting sustainable and efficient agricultural practices. While the
    ID3SAS methodology may demonstrate success within the parameters of the study,
    further research, tests, and validations in relation to plant physiology and its
    impact on crop performance could be vital for its real-world applicability and
    practical effectiveness. Appendix See Tables VII and VIII. TABLE 7 ID3SAS goals
    and description TABLE 8 List of Functional and Non-Functional Requirements for
    ID3SAS Methodology Authors Figures References Citations Keywords Metrics Footnotes
    More Like This Internet of Things and Wireless Sensor Networks for Smart Agriculture
    Applications: A Survey IEEE Access Published: 2023 Application of Non-Orthogonal
    Multiple Access in Wireless Sensor Networks for Smart Agriculture IEEE Access
    Published: 2019 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Intelligent Data-Driven Decision Support for Agricultural Systems-ID3SAS
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wei C.
  - Chen Y.
  citation_count: '11'
  description: Improved numerical efficiency in simulating wellbore gas-influx behaviors
    is essential for realizing real-time model-prediction-based gas-influx management
    in wells equipped with managed-pressure-drilling (MPD) systems. Currently, most
    solution algorithms for high-fidelity multiphase-flow models are highly time consuming
    and are not suitable for real-time decision making and control. In the application
    of model-predictive controllers (MPCs), long calculation time can lead to large
    overshoots and low control efficiency. This paper presents a drift-flux-model
    (DFM)-based gas-influx simulator with a novel numerical scheme for improved computational
    efficiency. The solution algorithm to a Robertson problem as differential algebraic
    equations (DAEs) was used as the numerical scheme to solve the control equations
    of the DFM in this study. The numerical stability and computational efficiency
    of this numerical scheme and the widely used flux-splitting methods are compared
    and analyzed. Results show that the Robertson DAE problem approach significantly
    reduces the total number of arithmetic operations and the computational time compared
    with the hybrid advectionupstream- splitting method (AUSMV) while maintaining
    the same prediction accuracy. According to the "Big-O notation"analysis, the Robertson
    DAE approach shows a lower-order growth of computational complexity, proving its
    good potential in enhancing numerical efficiency, especially when handling simulations
    with larger scales. The validation of both the numerical schemes for the solution
    of the DFM was performed using measured data from a test well drilled with water-based
    mud (WBM). This study offers a novel numerical solution to the DFM that can significantly
    reduce the computational time required for gas-kick simulation while maintaining
    high prediction accuracy. This approach enables the application of high-fidelity
    two-phase-flow models in model-prediction-based decision making and automated
    influx management with MPD systems.
  doi: 10.2118/206747-PA
  full_citation: '>'
  full_text: '>

    "Advertisement All Content All Journals SPE Drilling & Completion                              Advanced
    Search Cart Register Sign In HOME LATEST ISSUE ALL ISSUES ARTICLES IN PRESS FOR
    AUTHORS ABOUT VISIT SPE CITATION MANAGER Volume 36, Issue 04 December 2021 Previous
    Article Next Article JOURNAL PAPER| DECEMBER 15 2021 On Improving Algorithm Efficiency
    of Gas-Kick Simulations toward Automated Influx Management: A Robertson Differential-Algebraic-Equation
    Problem Approach Chen Wei; Yuanhang Chen SPE Drill & Compl 36 (04): 943–966. Paper
    Number: SPE-206747-PA https://doi.org/10.2118/206747-PA Article history Cite Share
    Get Permissions Summary Improved numerical efficiency in simulating wellbore gas-influx
    behaviors is essential for realizing real-time model-prediction-based gas-influx
    management in wells equipped with managed-pressure-drilling (MPD) systems. Currently,
    most solution algorithms for high-fidelity multiphase-flow models are highly time
    consuming and are not suitable for real-time decision making and control. In the
    application of model-predictive controllers (MPCs), long calculation time can
    lead to large overshoots and low control efficiency. This paper presents a drift-flux-model
    (DFM)-based gas-influx simulator with a novel numerical scheme for improved computational
    efficiency. The solution algorithm to a Robertson problem as differential algebraic
    equations (DAEs) was used as the numerical scheme to solve the control equations
    of the DFM in this study. The numerical stability and computational efficiency
    of this numerical scheme and the widely used flux-splitting methods are compared
    and analyzed. Results show that the Robertson DAE problem approach significantly
    reduces the total number of arithmetic operations and the computational time compared
    with the hybrid advection-upstream-splitting method (AUSMV) while maintaining
    the same prediction accuracy. According to the “Big-O notation” analysis, the
    Robertson DAE approach shows a lower-order growth of computational complexity,
    proving its good potential in enhancing numerical efficiency, especially when
    handling simulations with larger scales. The validation of both the numerical
    schemes for the solution of the DFM was performed using measured data from a test
    well drilled with water-based mud (WBM). This study offers a novel numerical solution
    to the DFM that can significantly reduce the computational time required for gas-kick
    simulation while maintaining high prediction accuracy. This approach enables the
    application of high-fidelity two-phase-flow models in model-prediction-based decision
    making and automated influx management with MPD systems. Keywords: production
    monitoring, reservoir surveillance, drilling fluids and materials, drilling operation,
    reservoir characterization, production control, well performance, upstream oil
    & gas, surface backpressure, production logging Subjects: Drilling fluid selection
    and formulation (chemistry, properties), Drilling Fluids and Materials, Drilling
    Operations, Drillstem/well testing, Fluid Characterization, Formation Evaluation
    & Management, Information Management and Systems, Managed pressure drilling, Pressure
    Management, Production logging Copyright © 2021 Society of Petroleum Engineers
    You can access this article if you purchase or spend a download. Sign in Don''t
    already have an account? Register Personal Account Username Password SIGN IN Reset
    password Register Sign in via OpenAthens Pay-Per-View Access $35.00 BUY THIS ARTICLE
    Annual Article Package – 25 $225 BUY DOWNLOADS Annual Article Package – 50 $400
    BUY DOWNLOADS View Your Downloads Advertisement 11 View Metrics Cited By Web Of
    Science (2) Google Scholar CrossRef (9) Email Alerts Article Activity Alert Articles
    in press Alert Latest Issue Alert Latest Most Read Most Cited Pipe Viscometer
    for Continuous Viscosity and Density Measurement of Oil Well Barrier Materials
    Applications of Machine Learning Methods to Predict Hole Cleaning in Horizontal
    and Highly Deviated Wells Improvements in Drilling Fluid Rheology Predictions
    Using Rotational Viscometer Combining Magnetic and Gyroscopic Surveys Provides
    the Best Possible Accuracy Advertisement Suggested Reading New Experimental Results
    Show the Application of Fiber Optic to Detect and to Track Gas Position in Marine
    Risers and Shed Light on the Gas Migration Phenomenon Inside a Closed Well SPE
    Drill & Compl (March,2023) A Novel Deepwater Kick Control Strategy for Handling
    Riser Gas Unloading with Data-Driven Parameter Estimation 20MPDU New Experimental
    Results Show the Application of Fiber Optic to Detect and to Track Gas Position
    in Marine Risers and Shed Lights on the Gas Migration Phenomenon Inside a Closed
    Well 22DC A Switching MPD Controller for Mitigating Riser Gas Unloading Events
    in Offshore Drilling SPE Drill & Compl (June,2020) A Mechanistic Gas Kick Model
    to Simulate Gas in A Riser with Water and Synthetic-Based Drilling Fluid 20ADIP
    Advertisement Online ISSN 1930-0204 Print ISSN 1064-6671 Explore Journals Conferences
    eBooks Publishers Connect About Us Contact Us Content Alerts SPE Member Pricing
    Resources Terms of Use Privacy Help KBART Engage Subscribe Advertise   This site
    uses cookies. By continuing to use our website, you are agreeing to our privacy
    policy. Accept"'
  inline_citation: '>'
  journal: SPE Drilling and Completion
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'On Improving Algorithm Efficiency of Gas-Kick Simulations toward Automated
    Influx Management: A Robertson Differential-Algebraic-Equation Problem Approach'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors: []
  citation_count: '0'
  description: 'The proceedings contain 347 papers. The special focus in this conference
    is on Mechatronics, Robotics and Automation. The topics include: A method of multi-antenna
    signal time-delay alignment algorithm for cyclostationary signals; analysis of
    ground-based navigation signal coverage on performance-based navigation; detection
    and analysis of rats'' bioelectromagnetic signal; fault diagnosis of gearbox in
    wind turbine based on wavelet transform and support vector machine; research of
    multi-channel audio data acquisition system based on FPGA and ARM; the signal
    separation for MIMO radar based on particle filter algorithm; simulation of underwater
    target echo based on highlight model; symbol rate estimation method for digital
    signal based on square timing; machinery fault diagnosis based on supervised locally
    linear embedding; a fractional-order Laplacian operator for image edge detection;
    a new color fidelity fast denoising algorithm for high-ISO images; a new video
    denoising algorithm based on adaptive polyview fusion; a parallel stereo matching
    algorithm core for FPGA modeled by DSP builder; a robust algorithm for the inspection
    of fastener head; a video compression coding algorithm for network content transmission;
    an efficient shape recognition method using multiple description fusion; clonal
    selection algorithm based on manifold distance for image compression; fusion of
    polarization image based on curvelet transform; human face expression recognition
    based on feature fusion; image defogging based on improved guided image filtering;
    image recognition based on shape and texture features; point cloud registration
    method based on face-mating after denosing; research on false points removing
    of speech segmentation; research on the detection and tracking method of ship
    intrusion and remaining; study on image processing algorithm for condom sorting;
    study on video transmission system of central heating based on 3G wireless network;
    vehicle association and tracking in image sequences using feature-based similarity
    comparison; corner and edge detection of image based on an annealed chaotic competitive
    network; image haze removal based dark channel prior; real-time information processing
    method and its application in optical target tracking system; target recognition
    application of real-time optical information processing system; the initial retrieval
    based on image segmentation; online pedestrian tracking with kalman filter and
    random ferns; acquisition of point cloud data in 3D reconstruction; application
    of an improved algorithm for denoising of wavelet threshold in palmprint recognition;
    association degree optimization model and algorithm for the reconstruction of
    cross-cut shredded paper; extraction algorithm of lip characteristic parameters
    based on interpolation; multi-fractal spectrum and their applications in metal
    fracture surface images feature extraction; based on the Hamilton improved circle
    of scraps joining together; study on network video monitoring system for industrial
    field; a novel technique of error analysis based on test case combination; apply
    two methods to measure engine noise source identification; design and implementation
    of energy efficiency testing platform; design of on-line detection system for
    paper defects based on line-scan camera; detection resolution analysis of scanning
    acoustic microscopy used in electronic packaging; development of automobile gear
    motion error detection system; spring geometric parameters of non-contact measurement
    based on binocular stereo vision sensor; the research of indoor positioning based
    on double wireless access points; engine fault diagnosis based on improved BP
    neural network with conjugate gradient; high speed small target frequency multiplication
    detection system; weld pool and keyhole detection based on visual sensors in plasma
    arc welding; a practical method of observer velocity optimization with airborne
    ESM sensor; tire pressure monitoring system and wireless passive surface acoustic
    wave sensor; extrinsic calibration of camera and rotating LIDAR using two planes;
    a temperature transmitter with autonomous reconfiguring function; design of frequency
    and amplitude of sine wave measurement circuit based on MSP430; adjustable frequency
    and amplitude wave generator; computer forensics based on data mining; optimization
    of lymphoma classification using dimensional reduction; an improved binary relevance
    algorithm for multi-label classification; application of cluster analysis to classify
    the ports of bohai ring area; a new conflict resolution method in fuzzy reasoning;
    air-combat decision modeling method based on DSM; fire seat intelligent identification
    system; intuitionistic fuzzy multiple attribute decision making method based on
    closeness degree; a method of fast weighted evidence combination exhibited by
    compound conflict; feature extraction for kernel minimum squared error by sparsity
    shrinkage; research of in-car navigation based on improved ant colony algorithm;
    the application of immune genetic algorithm in parallel sorting; forecast of short-term
    wind power based on GA optimized Elman neural network; knowledge-base constrained
    optimization evolutionary algorithm and its applications; a flexible authentication
    scheme with supporting multiple granularity of data integrity; a method of heterogeneous
    data integration based on SOA; a query optimization technology based on data partition;
    a web text de-noising algorithm based on machine learning; information management
    of car oil consumption on mobile with android OS; research on key technology and
    algorithm of open government data; software design for high-speed data capture;
    study on distributed database query optimization; design of an intelligent home
    system based on Linux and Qt; a method of detecting hardware Trojans based on
    side-channel analysis; a research on active storage task allocation strategy based
    on MMC; a review of hierarchical fixed priority scheduling; approaches of ontological
    property mapping based on multi-strategy; application of excel VBA in score analysis
    for specialty accreditation; big data based design of food safety cloud platform;
    design and implementation for the web of origami simulator; design and implementation
    of web-based E-learning platform; design on experience virtual tour system; feasibility
    study on the method of java combined with OSG; how to design the E-government
    2.0 used in Chinese grassroots public service; multi-strategy web service discovery
    for smart government; on the informationization construction of college archives
    management; relational database architecture refine based on the storage space
    estimate; research and design of culture compound based on android platform; research
    on adaptive strategy of web services; software product line measurement process
    capability maturity model; virtual machine migration based on trust measurement
    of computer node; a novel scheme for deleting group members; research on mechanism
    of PKI trust model; temperature-aware scheduling algorithm for multi-core system;
    design of communication module based on GPS/GPRS; research and design on China
    mobile multimedia broadcasting network planning; reconfigurable publish/subscribe
    middleware for wireless sensor networks; low cost AHRS aids GPS attitude navigation
    system; the overlay deployment model under interference based on marginal fitting;
    error correction of coding of wireless transmission channel of digital images;
    AIS development in recent years and message decoding; research on communication
    circuit applied in street lamp control system; a new robust adaptive backstepping
    for ship course-keeping control; a new solution of highway automotive collision
    avoidance; research on evaluation of urban road congestion; research on methods
    for urban rail transit train operation regulation; a portable integrated ship
    monitoring command system; railway freight turnover forecast based on the BP neural
    network; research on special vehicle road navigation algorithm; route optimization
    of DGT based on improved genetic algorithm; research on evaluation of urban road
    congestion; analysis of a eco-epidemiological model with disease in the predator;
    multi-factor model simulation on dynamics of population movements; on the approximately
    denjoy integrals of fuzzy-valued functions; some new impulsive integral inequalities;
    reflection and absorption of the medium with gradient change of impedance; study
    on virtual liver surgery simulation system with real-time haptic feedback; on
    the mean value of Euler function in a special set; constructing von Karman random
    media model with power spectrum method; a distributed multi-robot map fusion algorithm;
    analysis on oscillating tail to rolling stability of water-running robots; cooperative
    obstacle avoidance of multiple robotic fishes based on grids method; design on
    the distributed controller of underwater profile monitoring vehicle; one new kind
    of worming pipe robot; quantitative analysis on workspace influence of robot structural
    parameters; robust adaptive observer for single-linked robotic arm systems; statics
    analysis of 6-DOF parallel robot based on screw theory; target tracking for robot-fishes
    based on unscented kalman filter; the research on visual navigation of AGV in
    outdoor environment; design of compliant mechanism based on the parallel mechanism
    decoupling criterion; the design of industrial robot sorting and pallet system;
    based on eddy current testing of automotive wheel crack detection platform design;
    steer-by-wire force feedback system based on magnetorheological fluid damper;
    equipment servo system signal acquisition module design based on embedded; optimal
    design for stator of a new linear ultrasonic motor; a geometry based algorithm
    for swarm aggregations; a research on anti-slip regulation of in-wheel motor driven
    electric vehicle.'
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: Applied Mechanics and Materials
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 2014 2nd International Conference on Mechatronics, Robotics and Automation,
    ICMRA 2014
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

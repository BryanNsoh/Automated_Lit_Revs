- analysis: '>'
  authors:
  - He Q.
  - Zhao H.
  - Feng Y.
  - Wang Z.
  - Ning Z.
  - Luo T.
  citation_count: '0'
  description: Powered by data-driven technologies, precision agriculture offers immense
    productivity and sustainability benefits. However, fragmentation across farmlands
    necessitates distributed transparent automation. We developed an edge computing
    framework complemented by auction mechanisms and fuzzy optimizers that connect
    various supply chain stages. Specifically, edge computing offers powerful capabilities
    that enable real-time monitoring and data-driven decision-making in smart agriculture.
    We propose an edge computing framework tailored to agricultural needs to ensure
    sustainability through a renewable solar energy supply. Although the edge computing
    framework manages real-time crop monitoring and data collection, market-based
    mechanisms, such as auctions and fuzzy optimization models, support decision-making
    for smooth agricultural supply chain operations. We formulated invisible auction
    mechanisms that hide actual bid values and regulate information flows, combined
    with machine learning techniques for robust predictive analytics. While rule-based
    fuzzy systems encode domain expertise in agricultural decision-making, adaptable
    training algorithms help optimize model parameters from the data. A two-phase
    hybrid learning approach is formulated. Fuzzy optimization models were formulated
    using domain expertise for three key supply chain decision problems. Auction markets
    discover optimal crop demand–supply balancing and pricing signals. Fuzzy systems
    incorporate domain knowledge into interpretable crop-advisory models. An integrated
    evaluation of 50 farms over five crop cycles demonstrated the high performance
    of the proposed edge computing-oriented auction-based fuzzy neural network model
    compared with benchmarks.
  doi: 10.1186/s13677-024-00626-8
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Search Get published
    Explore Journals Books About Login Journal of Cloud Computing Advances, Systems
    and Applications About Articles Submission Guidelines Submit manuscript Research
    Open access Published: 21 March 2024 Edge computing-oriented smart agricultural
    supply chain mechanism with auction and fuzzy neural networks Qing He, Hua Zhao,
    Yu Feng, Zehao Wang, Zhaofeng Ning & Tingwei Luo  Journal of Cloud Computing  13,
    Article number: 66 (2024) Cite this article 87 Accesses Metrics Abstract Powered
    by data-driven technologies, precision agriculture offers immense productivity
    and sustainability benefits. However, fragmentation across farmlands necessitates
    distributed transparent automation. We developed an edge computing framework complemented
    by auction mechanisms and fuzzy optimizers that connect various supply chain stages.
    Specifically, edge computing offers powerful capabilities that enable real-time
    monitoring and data-driven decision-making in smart agriculture. We propose an
    edge computing framework tailored to agricultural needs to ensure sustainability
    through a renewable solar energy supply. Although the edge computing framework
    manages real-time crop monitoring and data collection, market-based mechanisms,
    such as auctions and fuzzy optimization models, support decision-making for smooth
    agricultural supply chain operations. We formulated invisible auction mechanisms
    that hide actual bid values and regulate information flows, combined with machine
    learning techniques for robust predictive analytics. While rule-based fuzzy systems
    encode domain expertise in agricultural decision-making, adaptable training algorithms
    help optimize model parameters from the data. A two-phase hybrid learning approach
    is formulated. Fuzzy optimization models were formulated using domain expertise
    for three key supply chain decision problems. Auction markets discover optimal
    crop demand–supply balancing and pricing signals. Fuzzy systems incorporate domain
    knowledge into interpretable crop-advisory models. An integrated evaluation of
    50 farms over five crop cycles demonstrated the high performance of the proposed
    edge computing-oriented auction-based fuzzy neural network model compared with
    benchmarks. Introduction Modern agriculture faces unprecedented stresses, such
    as rising food requirements from global population growth and declining arable
    land and water resources [1]. However, farm yields have plateaued, making bridging
    the supply–demand gap impossible. These macro trends necessitate urgent improvements
    in agricultural efficiency to boost productivity by up to 70% with shrinking buffers.
    Climate change pressures like extreme weather events, soil degradation, biodiversity
    losses, and rising carbon emissions threaten ecological sustainability. Agriculture
    accounts for over 25% of greenhouse gas emissions, highlighting the sizable decarbonization
    potential. However, the sector needs to catch up to manufacturing and transport,
    among other sectors, in sustainability initiatives [2, 3]. Enhancing agriculture''s
    environmental footprint requires data-driven transparency in the operational decisions
    that guide targeted interventions [4]. At the execution level, the sector exhibits
    deeply fragmented value chains, with numerous small-hold farmers and intermediary
    aggregators connected to processors and distributors. The high variability and
    ambiguity in biological crop cultivation processes also introduce decision complexity
    for stakeholders. Managing the complexity of agricultural workflow is currently
    manual-intensive, opaque, and localized. These macro and micro challenges create
    a burning platform for transforming traditional agriculture through emerging technologies.
    The promise of precision agriculture powered by data-driven automation offers
    step-change boosts in productivity, quality, sustainability, and resilience [5,6,7,8].
    Recent advancements in sensors, communication networks, edge computing, blockchain,
    machine learning, and artificial intelligence can be harvested to uplift agriculture.
    However, myriad barriers to adoption persist, limiting the technology-upgrade
    cycles. Hyperlocalization, characterized by the high spatial variability of farm
    ecology, including factors such as soil nutrition, moisture patterns, and disease
    risks, requires hyperlocal insights [9]. Centralized systems must capture these
    microclimatic nuances. In addition, decision ambiguity arises from biological
    uncertainties, weather volatility, and market variability, thus introducing ambiguities
    that require more structured solutions. Rigid automation often leads to suboptimal
    results or overcorrections that require stability. Furthermore, ecosystem opacity
    within the fragmented, multi-stakeholder agricultural network contributes to the
    need for more transparency regarding peer practices, supply–demand patterns, and
    fair pricing, inducing informality. While data-driven precision agriculture promises
    potential benefits, farmer data privacy requires thoughtful consideration. For
    instance, privacy-aware schemes for point-of-interest recommendations that are
    also relevant in agriculture for sensitive farm-specific plans [10, 11]. Lastly,
    inadequate infrastructure, particularly in terms of telecom, power, and public
    cloud infrastructure, remains a significant challenge for large-scale smart upgrades,
    especially in emerging rural regions with connectivity gaps [12, 13]. Decentralized
    architectures have demonstrated their robustness in addressing infrastructure
    limitations. Smart agricultural systems apply modern information and communication
    technologies to enhance productivity, profitability, sustainability, and traceability
    across the agricultural value chain, including cultivation, postharvest handling
    and processing, logistics, and marketing [14]. Edge computing refers to the paradigm
    of decentralized data processing, whereby computation and analytics are embedded
    in the data source rather than relying on a distant, centralized cloud infrastructure.
    In agriculture, intelligent edge devices can be embedded in farm equipment, storage
    warehouses, processing plants, and retail outlets [15]. Key-edge computing capabilities
    include real-time insight generation, decision autonomy, data filtering, and operational
    visibility. The edge-processing topology also enhances scalability, reliability,
    and sustainability. Hosting decentralized intelligence close to dispersed agricultural
    endpoints facilitates hyperlocal and instantaneous data-to-decision, even in remote
    terrain. Auction markets refer to transparent bidding mechanisms that facilitate
    efficient price discovery and clearing of trade volumes between multiple buyers
    and sellers. Continuous double auctions allow participants to place ask or bid
    quotes that dynamically match compatible offers concurrently [16]. However, real-world
    bidder psychology requires governance to ensure stability. Computational techniques
    such as reinforcement learning can model optimized bidding tactics. Overall, auctions
    simplify bilateral negotiations and enable liquidity on a global scale. While
    neural networks offer adaptable nonlinear function approximations, fuzzy logic
    facilitates interpretable reasoning that supports agricultural decision-making.
    Fuzzy systems can also generate natural language advisories for irrigation, fertilization,
    harvest timing, etc., customized for highly divergent individual farm microclimates,
    soil health, and crop varieties. Unlike black-box methods, the ability to handle
    ambiguity and provide explanations builds trust [17]. Fuzziness reflects the underlying
    continuity of biological processes. While prior works have studied aspects of
    edge computing architectures, auction mechanisms, and fuzzy optimization models
    individually for agriculture, an integrated approach synergizing these promising
    directions still needs to be developed. Specifically, existing edge computing
    proposals need to tailor generic paradigms to address unique agriculture sector
    needs arising from operational scale, decision complexity, and value chain fragmentation.
    Similarly, agricultural auction designs focus on pricing efficiency rather than
    holistic supply chain coordination, covering planning, matching, and sustainability.
    Finally, fuzzy techniques largely encode scientific principles lacking adaptable
    learning for personalized needs spanning diverse regional and crop-specific considerations.
    Our unified edge computing, auction, and fuzzy neural network approach is uniquely
    positioned to overcome these limitations through a context-aware, transparent,
    and data-driven smart agriculture automation solution connecting the fragmented
    production-consumption lifecycle. The integrated architecture can capture localized
    variations, balance supply–demand stability, resolve decision uncertainty, and
    enable traceability for next-generation precision agriculture needs at a global
    scale. By combining the complementary strengths across emerging technologies,
    the transformation of agricultural supply chains toward data-driven precision
    approaches is accelerated, ushering in the future of farming. Accordingly, the
    main contributions of this study are as follows: 1) We propose an edge computing
    framework tailored to agricultural requirements. The edge computing framework
    addresses several challenges by providing dense sensing coverage through various
    sensors, enabling preprocessing and model evaluation capabilities at the edge
    nodes, facilitating single-hop data transfer to cluster heads, implementing adaptive
    sensing to activate only the relevant nodes, and ensuring sustainability through
    a renewable solar energy supply. 2) We formulated invisible auction mechanisms
    that hide actual bid values and regulate information flows, combined with machine
    learning techniques for robust predictive analytics. 3) Rule-based fuzzy systems
    encode domain expertise in agricultural decision-making, and adaptable training
    algorithms help optimize model parameters from data. A two-phase hybrid learning
    approach is formulated. Fuzzy optimization models were formulated using domain
    expertise for three key supply chain decision problems. The remainder of this
    paper is organized as follows. Related work section  reviews related studies.
    Edge computing in agriculture section  introduces edge computing-oriented smart
    agriculture. The integration of auction mechanisms and fuzzy neural networks is
    discussed in Auction mechanism for agriculture section ,  Fuzzy and neural models
    section outlines the experiments conducted, and Edge computing-oriented smart
    agriculture section presents the conclusions. Related work Edge computing in agriculture
    Edge computing has emerged as a promising paradigm for addressing the challenges
    of data processing and decision-making in agriculture. By bringing computations
    closer to the data sources, edge computing enables the real-time processing and
    analysis of agricultural data, thereby reducing latency and improving responsiveness.
    Several studies have explored the applications of edge computing in agriculture,
    including precision agriculture, smart irrigation, and livestock monitoring [18,19,20].
    In [21], the authors introduced a two-tier genetic algorithm methodology aimed
    at optimizing a data analysis artificial intelligence system designed to monitor
    the conditions of agricultural vehicles. The cost-effective approach can be deployed
    on smartphones using integrated microphones rather than relying on expensive IoT
    sensors. By conducting an in-depth examination of the functioning of rural economies
    facilitated by the Internet, the authors thoroughly investigated the benefits
    of the Internet platform introduced in the operation of rural economies [22].
    Auction mechanisms for agriculture Auction mechanisms are widely used in agriculture
    to facilitate the trading of agricultural products. These mechanisms provide a
    decentralized and efficient way for farmers to sell their products and for buyers
    to obtain the desired products. Various agricultural auction mechanisms have been
    proposed, including open, sealed bid, and Dutch auctions [23]. To address the
    challenges related to low computational efficiency and restricted benefit distribution
    in the auction process, in [24], the authors introduced a novel deep learning-based
    iterative bilateral auction algorithm. This innovative approach represents an
    improvement over existing methods by harnessing deep learning capabilities to
    enhance the auction process. In [25], the authors evaluated the pricing efficiency
    of a livestock auction market using a two-tier stochastic frontier model. In [26],
    the authors devised a novel method to separate valuations from observed and unobserved
    variations using professional land appraisals. Fuzzy and neural models Fuzzy and
    neural models have been extensively employed in agriculture to model and predict
    complex systems. Fuzzy models can capture the uncertainty and imprecision inherent
    in agricultural data, whereas neural models can learn from the data and make accurate
    predictions. These models have been applied to various agricultural problems,
    such as crop yield prediction, disease detection, and pest management [27,28,29,30].
    Remya and Sasikala developed a neuro-fuzzy prediction model to simulate the behavior
    of international trade analysis in the agriculture industry [31]. Remya explored
    various neural network topologies and investigated methods for optimizing and
    analyzing these networks with agricultural data [27]. Ramana et al. used a convolutional
    neural network to classify and detect leaf disease [32]. Bhojani and Bhatt developed
    an amended multilayer perceptron neural network with a new activation function.
    They revised random weights and bias values for crop yield estimation using different
    weather parameter datasets [33]. Zhang et al. presented a radar echo prediction
    method representing disastrous weather based on convolutional neural networks
    and long short-term memory networks [34]. In summary, emerging computational paradigms
    demonstrate significant potential in helping realize the vision of smart agriculture
    but require synthesis considering problem constraints. Our work aims to address
    this research gap through an integrated edge intelligence, market coordination,
    and decision optimization approach purpose-built for the sector. Edge computing-oriented
    smart agriculture System model This study presents an edge computing framework
    complemented by auction mechanisms and fuzzy optimizers that connect various supply
    chain stages, as shown in Fig. 1. Fig. 1 Overall framework Full size image Edge
    computing offers powerful capabilities that enable real-time monitoring and data-driven
    decision-making in smart agriculture. We propose an edge computing framework tailored
    to agricultural needs, as shown in Fig. 2. Fig. 2 Proposed edge computing framework
    for smart agriculture Full size image The framework comprises three sections:
    the sensing layer, the edge computing layer, and the growth data model. Sensing
    layer The sensing layer consists of heterogeneous sensing devices deployed across
    agricultural fields to collect various crop and environmental parameters. Sensor
    nodes can be categorized as follows. Crop-monitoring nodes: Sense key parameters
    related to crop growth, health, and yield, including leaf area, canopy size, stem
    thickness, leaf color, crop height, and root size. Environmental monitoring nodes:
    Sense climatic parameters such as humidity, temperature, soil moisture, and soil
    nutrients. Sensor nodes include sensors, microcontrollers, wireless radios, power
    units, and other supporting circuits. Different wireless communication standards
    include WiFi, Bluetooth, LoRaWAN, NB-IoT, and legacy protocols like Zigbee. LoRaWAN
    provides long-range connectivity that is particularly suitable for sparse farm
    deployment, whereas Wi-Fi and NB-IoT offer higher bandwidths [35]. Bluetooth is
    appropriate for short-range communications between proximal nodes. Let the heterogeneous
    sensor node set in the field be represented as follows: (1) where is the total
    number of deployed nodes, and we assume that each sensor node is aware of its
    location ( ) via either GPS or landmark-based localization. Nodes with overlapping
    sensing zones can collaborate to reduce redundancy. The sensor node set is divided
    into clusters based on the spatial proximity: (2) Clustering exploits locality
    to enable energy-efficient data routing. Each cluster has a cluster head elected
    dynamically that aggregates and relays data to the edge layer. Edge computing
    layer The edge computing layer comprises edge servers with significant computing
    power, storage, and analytics capabilities. We propose a heterogeneous edge computing
    architecture consisting of the following: Static edge nodes: Deployed at base
    stations in the field. Mobile edge nodes: Mounted on autonomous ground robots
    or UAVs. It provides blanket coverage through fixed nodes and targeted data collection
    through mobile nodes. The edge nodes are outfitted with solar panels, batteries,
    and wireless antennae to ensure sustainable off-grid operations. Key capabilities
    offered by the edge computing layer include (i) Cluster data aggregation: Combine
    sensor data from nodes within clusters; (ii) Preprocessing and storage: Filter
    noise, detect outliers and temporally store data; (iii) Growth stage identification:
    Classify current growth phase based on crop parameters; (iv) Analytics: Environmental
    and yield predictions via ML models; (v) Control policies: Adaptive sensing frequencies,
    irrigation levels etc. These edge-centric functions distribute computations closer
    to the sensors, avoid cluttering the cloud, and support real-time agriculture.
    Next, we formulated mathematical models for crop and environmental sensing data.  Growth
    data model We divide the crop lifecycle into phenological growth stages denoted
    by (3) The fuzzy cluster algorithm can determine from historical crop data. Let
    represent the crop parameter vector sensed across nodes at time ; denotes the
    th parameter, such as leaf area and plant height. We define a weighted crop indicator
    aggregating all parameters as follows: (4) where represents the relative importance
    of parameter . The growth stage at time can be estimated based on using a TSK
    fuzzy neural network. For example, if representing leaf area and plant height,
    and , then . 0.7 and 0.3 are the weights, while 0.6 and 0.8 are the parameter
    values. The weights scale the parameter values before summing. Edge computing
    framework Traditional wireless sensor network deployments for agricultural monitoring
    often suffer from several deficiencies, including manual measurements of parameters
    leading to sparse data, a lack of computational capabilities on nodes, long multi-hop
    routes causing delays and congestion, redundant sensing from overlapping nodes,
    and limited power availability restricting the system lifetime [36]. Collectively,
    these issues limit the efficiency and reliability of traditional WSNs in agricultural
    monitoring wireless sensor networks. Our proposed edge computing framework addresses
    several of these challenges by providing dense sensing coverage through a variety
    of sensors, enabling preprocessing and model evaluation capabilities at edge nodes,
    facilitating single-hop data transfer to cluster heads, implementing adaptive
    sensing to activate only relevant nodes, and ensuring sustainability through a
    renewable solar energy supply. This comprehensive approach aims to significantly
    enhance the efficiency and effectiveness of agriculture monitoring wireless sensor
    networks. Consequently, the framework can collect high-resolution spatiotemporal
    data to better capture crop dynamics. Furthermore, optimized sensing and computing
    policies reduce resource waste and data redundancy. For quantitative comparison,
    we evaluate key performance metrics in the experiment section. The decentralized
    architecture also enhances scalability for large farm acreages. Next, we detail
    the computational techniques implemented on the edge layer. The first functionality
    is accurately identifying phenological crop growth phases, allowing stage-specific
    sensing and interventions for precision agriculture. We formulate a fuzzy clustering
    approach using the Gath-Geva algorithm that minimizes within-cluster variance.
    Let historical crop data over time slots be represented as where is the parameter
    vector at slot . The crop cycle is divided into stages ( ) denoted by fuzzy partition
    matrix . Element defines the membership of slot in stage . The cluster centers
    are . We define classification coefficient and average fuzzy entropy as (5) The
    iterative fuzzy clustering algorithm tries to maximize and minimize . The steps
    are summarized as follows: Step 1. Initialize: Partition matrix , clusters , iterations
    , weight . Step 2. Compute cluster centers using membership . Step 3. Determine
    cluster covariance and prior probability. Step 4. Calculate fuzzy maximum likelihood
    distance measure. Step 5. Update partition matrix . Step 6. Repeat steps 2–5 until
    . Step 7. Choose optimal based on best and β . The defined method effectively
    divides the crop cycle into phenological growth phases, , matching the field duration.
    Next, we predicted the current stage based on the sensed indicators. To determine
    the growth phase, we designed a Takagi–Sugeno (TS) fuzzy neural network model
    comprising five layers: input, fuzzification, rule, aggregation, and output. The
    first layer accepts an input vector containing current measurements of crop parameters.
    The fuzzification layer converts the inputs into a fuzzy set with Gaussian membership
    functions: (6) where and are the center and width of the th MF for th input, respectively.
    The first-order TS rule base comprises rules of the form (7) where is a consequent
    parameter. The net output is computed as where firing strength . For training,
    we used an extreme learning machine to randomly initialize the input layer weights
    and optimize the output layer weights analytically using the Moore–Penrose inverse.
    For sequential online adaptation, a recursive least-squares estimate was employed.
    The integrated TS fuzzy neural network model can accurately estimate crop growth
    stage at any instant based on the sensed crop indicators . Stage-specific control
    policies are then enacted. Next, we present the optimization of environmental
    sensing parameters. Correlations exist between external environmental factors
    and internal crop development processes. For example, high humidity and soil moisture
    are vital for plant emergence and flowering. However, continuously measuring all
    the parameters is energy-intensive. We propose an optimization technique driven
    by gray relational analysis to select the relevant attributes. Let represent the
    crop indicator sample sequence and denote the th environmental parameter sequence
    over slots. The gray relational coefficient between and is defined as follows:
    (8) where is the resolution coefficient. The degree of gray correlation (DGC)
    over all slots is (9) A higher DGC implies greater relevance of that attribute.
    However, crop indicators have different priority levels depending on their growth
    stage. Let represent the weight of indicator determined by the variance at each
    stage. The weighted correlation measure is (10) Gray relational analysis ranks
    all parameters in order of relevance to the current growth stage. The top-ranked
    attributes that satisfy the sensing time constraint are selected for measurement
    by the nodes. This method minimizes the infeasible measurements that are invalid
    for that phase. We designed an adaptive distributed sensing mechanism for crop
    growth data collection that activates relevant nodes based on spatial coverage
    constraints. Let represent a set of selected sensor nodes. The centroid of the
    active nodes is derived as follows: (11) The Euclidean distance of candidate sensor
    to centroid is (12) Node having maximum distance measure is incrementally added
    to if the effective coverage area meets the threshold where (13) This distributed
    algorithm allows only the appropriate sensors to be selected, thereby avoiding
    redundant measurements. The pseudocode is presented in Algorithm 1. Algorithm
    1. Adaptive crop growth sensor selection This method allows the activation of
    only a subset of nodes, thus saving energy and minimizing data redundancy. Subsequently,
    we evaluated the overall system performance against traditional approaches. Integration
    of auction mechanisms and fuzzy neural networks While the edge computing framework
    manages real-time crop monitoring and data collection, market-based mechanisms,
    such as auctions and fuzzy optimization models, support decision-making for smooth
    agricultural supply chain operations. Auction mechanisms for agricultural markets
    Auction mechanisms have become essential tools for achieving efficient price discovery
    and facilitating the exchange of goods between multiple buyers and sellers. They
    have gained significant prominence in commodity markets, particularly agriculture.
    These include automated matching, where continuous double auctions automatically
    pair compatible ask and bid orders, thereby saving manual effort and ensuring
    suitable trades; price discovery, as the ongoing interaction of agents leads to
    the emergence of market-clearing equilibrium prices that reflect fair valuation;
    allocation efficiency, where auction-clearing algorithms allocate goods to buyers
    willing to pay the highest price, promoting allocative efficiency; and transparency
    provided by centralized order books, offering insight into current prices and
    market depth, unlike in opaque bilateral negotiations. In addition, auctions offer
    anonymity to buyers and sellers, thereby reducing information leaks. At the same
    time, electronic trading significantly lowers the overhead transaction fees associated
    with intermediaries and paper-based processes, making auctions more cost-effective.
    Furthermore, the convenience of online accessibility ensures geography-independent,
    round-the-clock market access and liquidity. Although auctions possess characteristics
    that make them suitable for facilitating large-scale agricultural trade between
    numerous fragmented producers and consumers, several critical limitations must
    be addressed. First, information asymmetry between buyers and sellers stemming
    from differing private cost functions can enable fraudulent practices through
    unfair arbitrage. Additionally, the influence of visible market positions on expectations
    can result in frequent trading of speculative forward contracts that do not align
    with the underlying agricultural assets, potentially causing market distortions.
    Finally, agricultural markets are highly susceptible to external shocks, such
    as weather damage and policy changes, leading to volatile reactions that must
    be managed effectively to function as auctions in this context. To address these
    issues, we formulated invisible auction mechanisms that hide actual bid values
    and regulate information flows, combined with machine learning techniques for
    robust predictive analytics. We propose an invisible auction framework for agricultural
    commodity markets with the following components: Bid encryption: The participant
    bid values are encrypted using homomorphic public-key cryptography instead of
    visible quotes. (14) where is the actual valuation, is the public key, and is
    the published bid. Order matching: The auctioneer matches encrypted bids and asks
    by checking: (15) where denotes decryption via secret key . Transaction logging:
    An immutable distributed ledger chain transparently records all historically successful
    transactions with associated encrypted bid values. Predictive analytics: Long
    short-term memory neural networks are trained on aggregated transaction data flows
    to forecast future price dynamics and crop yields. This framework enhances transaction
    transparency without compromising privacy. Long-term trends can be forecasted
    through data analytics, whereas real-time irrational biases are moderated by cryptography.
    Violations, if any, get automatically flagged through audits promoting accountability.
    Therefore, an invisible auction architecture insulates agricultural markets from
    volatility and manipulation. Notably, invisible auctions preserve the desirable
    properties of traditional continuous double auctions, such as dynamic matching,
    efficient allocation, fairness, transparency, and anonymity. Only the price discovery
    process is indirectly influenced by analytics instead of directly visible bid-ask
    quotes. Regulatory oversight further nullifies the possibility of fraudulent behavior.
    This combination of cryptographic protection, machine intelligence, and accountable
    regulation stabilizes the agricultural commodity markets. Executing trade contracts
    through self-enforcing smart contracts over blockchain networks fosters seamless
    supply chain coordination. Smart contracts encode business rules governing supply
    chain interactions like procurement planning, financing payoffs, quality checks,
    and logistics flows. Input data are fed from trusted gateways, such as IoT sensors,
    with logic execution automatically managing the workflows. Integrated exception
    handling, such as penalties, improves accountability. Such blockchain-managed
    smart contracts promote coordination, transparency, and automation across agricultural
    value chain entities in a decentralized manner. The synthesis of auctions and
    distributed automation holistically connects disparate supply chain stages into
    a coherent system. Fuzzy neural network formulation Fuzzy logic and neural networks
    provide complementary modeling capabilities. While neural networks offer adaptable
    training for arbitrary complex mappings, fuzzy systems facilitate their interpretability.
    We formulate an integrated 5-layer architecture, as shown in Fig. 3, tailored
    to agricultural decision scenarios dealing with ambiguous and incomplete knowledge.
    Fig. 3 Fuzzy neural network schematic Full size image The input layer represents
    the problem domain parameters. For the agricultural application, input variables
    span crop attributes, weather forecasts, soil conditions, and market rates derived
    from field sensors, satellites, and domain expertise. Let vector denote the input
    variables. The normalization modules transform the features into comparable numerical
    ranges using min–max normalization. (16) This preprocessing enhances the training
    stability. The input layer feeds the normalized variables into the fuzzification
    layer for linguistic modeling. Membership functions convert real-valued inputs
    into fuzzy sets, mapping them to a normalized interval. Commonly adopted forms
    include triangular, trapezoidal, Gaussian, and bell curves with tunable parameters.
    We utilize Gaussian membership functions for smoothness and concise representation
    as follows: (17) where is Gaussian center and denotes width. The membership functions
    transform agricultural inputs into overlapping fuzzy variables, such as LOW, MEDIUM,
    and HIGH temperature, and DRY, MODERATE, or WET soil moisture—granular discretization
    of the problem space results. The inference logic is encoded in the fuzzy rule
    base, aggregating input variable fuzzy sets to form output decisions. Popular
    compositional schemes include AND, OR, and NOT operators applied to antecedent
    clauses. We used conjunctive fuzzy rules, with each clause joined by an AND. (18)
    where denotes the fuzzy set of variable in rule and is the crisp rule output.
    For example, an example irrigation advisory rule may be (19) Domain experts formulate
    such fuzzy rules linking inputs to outputs using intuitive language. Automated
    methods also assist rulebase generation from data. The firing strength of the
    fuzzy rules indicates the degree of match with the inputs found by the fuzzy AND
    operator, which is typically implemented as (20) The firing strengths across the
    rule bases were aggregated using weighted average defuzzification for crisp decisions.
    (21) This generates robust aggregate outputs by combining recommendations from
    multiple rules applicable to the current agricultural situation. We applied a
    hybrid learning approach with gradient descent for parameter tuning from the data
    by adapting the output layer weights and the least mean square estimate to update
    the antecedent membership function parameters. Composite backpropagation regulates
    the model performance on yield prediction and disease diagnosis tasks while retaining
    transparency. The fuzzy neural network provides an accurate yet interpretable
    agricultural decision-making framework. Fuzzy model training algorithms While
    rule-based fuzzy systems encode domain expertise in agricultural decision-making,
    adaptable training algorithms help optimize model parameters from the data. A
    two-phase hybrid learning approach is formulated. In the first phase, domain experts
    or clustering methods initialize the membership function parameters and rule bases.
    For example, the fuzzy variable MOISTURE can be defined as. (22) The membership
    functions translate the input moisture percentages into degrees of association
    with the fuzzified sets, LOW, MEDIUM, and HIGH. Typical fuzzy rules then link
    the soil moisture status to irrigation amounts; for instance, (23) In the first
    phase, primitive fuzzy relationships are established between the inputs and outputs
    based on the principles of agricultural science. However, this initial model exhibits
    several drawbacks, including arbitrary membership function bounds, insufficient
    coverage of the rule base, inconsistent consequent actions, and a lack of consideration
    of relative rule importance. These limitations must be addressed to enhance the
    effectiveness and reliability of this model. Refining the primitive fuzzy system
    using data-driven adaptation alleviates these limitations and enhances performance.
    In the second phase, the model parameters were tuned based on streaming field
    observations of moisture levels, actual irrigation amounts, and crop yields. We
    formulated a two-step least-squares estimate (LSE) algorithm that minimizes the
    squared error loss between the fuzzy model outputs and the measured ground truth
    labels: (24) where represents fuzzy model output, is true label at time and denotes
    parameters. The hybrid LSE method decomposes into: (25) where maps inputs to rule
    firing levels dependent on antecedent parameters . The function aggregates rule
    outputs based on consequent weights . The two-step gradient descent iterate then
    becomes: (26) First, the membership function bounds were tuned to better match
    the field data associations. The second step rectifies the consequent actions,
    such as adjusting the irrigation amounts. Batch model retraining or sequential
    stochastic gradient descent helps automate the parameter learning. Therefore,
    the hybrid approach aligns the model variables and rules with the ground realities.
    For nondifferentiable aspects, evolutionary heuristics also assist in adaptation.
    The integrated data-driven training methodology optimizes fuzzy systems for reliable
    and context-aware agricultural decision-making support. Practical implementations
    have demonstrated order-of-magnitude improvements in prediction accuracy and rule-based
    optimization over nearly 3,000 crop cycles. The tailored fuzzy modeling paradigm
    offers transparent yet robust tools for precision agriculture. Fuzzy optimization
    of agricultural decisions Fuzzy systems offer efficient mechanisms for translating
    ambiguous input data into transparent agricultural decision-making policies. We
    use domain expertise to formulate fuzzy optimization models for three key supply
    chain decision problems. Precision agriculture requires the optimal dynamic allocation
    of resources such as water, fertilizers, and pesticides based on crop stages,
    weather patterns, and soil conditions. We encode this as a multi-objective optimization
    problem. (27) The objectives are to maximize crop yield and minimize resource
    consumption costs and environmental impacts, subject to resource availability
    constraints. We designed a Mamdani-type fuzzy inference system with a rulebase:
    (28) where linguistic variables, such as LOW and MEDIUM, model soil moisture and
    resource application levels, respectively. Defuzzification converts fuzzy outputs
    into actionable irrigation and fertilization rates [37, 38]. Common strategies
    include the centroid, mean-max, and maximum criteria. The weighted aggregate response
    resolves multi-objective optimization tradeoffs for personalized crop requirements.
    Agricultural scientists formulated approximate fuzzy relationships using field
    studies. Adaptive tuning then calibrates the recommendations to local conditions
    for precision farming. Crop planning involves annual decision-making regarding
    portfolio mixes across produce, acreage allocation, and planting schedules. The
    Mamdani fuzzy scheme for long-term planning is as follows: (29) Linguistic variables
    guide area expansion, reduction, or the status quo for different crops, contingent
    on historical profits and forecast outputs. Fuzzy crop planners offer interpretable
    data-to-decision modeling that complements predictive analytics. Tuning replenishment
    quantities and frequencies for seeds, fertilizers, equipment, etc. minimizes warehousing
    costs. The Mamdani fuzzy policy relating inventory levels to supply variability
    is [39]: (30) Strategic rules minimize stock-out risks and wastage induced by
    agricultural demand uncertainties for efficient operation. Fuzzy inventory controllers
    allow the embedding of domain insights and adaptive calibration. Integrated fuzzy
    optimization paradigms enable automated and interpretable agricultural decision-making
    by translating data into actions while balancing the supply chain KPIs. Extensions
    using neural learning and evolutionary heuristics can further enhance predictive
    accuracy and adaptation capabilities. Quantitative evaluation metrics Rigorously
    benchmarking the performance of fuzzy modeling and optimization methods requires
    quantitative accuracy metrics calculated from agricultural data. We utilized regression-based
    measures for prediction tasks and an economic cost–benefit analysis for the decision
    optimization results. Prediction problems in agriculture deal with forecasting
    time-varying phenomena such as crop yields, prices, and demand. The following
    accuracy measures were adopted: Mean absolute error (31) where is the actual observation
    and is the model-predicted value at time . Root mean-squared error (32) Mean absolute-percentage
    error (33) Coefficient of determination (34) Lower MAE, RMSE, and MAPE values,
    along with higher values, indicate superior predictive accuracy. Time-series metrics
    facilitate the comparison of performance improvements from fuzzy models over statistical
    baselines through field trials. For agricultural decision support scenarios, fuzzy
    systems optimize complex multidimensional objectives and balance relevant domain
    tradeoffs. Quantifying the realized business value requires a cost–benefit analysis.
    Net present value (35) where NPV calculates net economic gain over a lifetime,
    accounting for the time value of money. Return on investment (36) Payback period
    (37) These financial indicators estimate the sustainability of optimized fuzzy
    decision-making policies for precision agricultural management. Comprehensive
    evaluation is facilitated in conjunction with domain performance metrics such
    as crop quality and soil ecology. Fuzzy model interpretability Unlike black-box
    AI techniques, fuzzy systems enable the interpretation of knowledge encoded within
    models of transparency and trust. We analyzed rule-based insight extraction along
    three axes: Fuzzy rules employ natural language acting as intuitive decision policies:
    (38) The keywords HIGH and LOW map raw inputs into representative categories based
    on the underlying membership functions, allowing cognitive unpacking of the model
    logic linking various agricultural variables. Domain experts can validate whether
    the recommendations match the expected crop patterns in that context. This contrasts
    with the inscrutable weights in deep neural networks. Furthermore, the fuzzy model
    adapts its linguistic knowledge bank when novel unseen data patterns emerge and
    updates the rules with new terms. Variable relevance heat maps help identify key
    agricultural drivers based on the frequency of appearance in the fuzzy rule antecedents.
    (39) Higher weight parameters were prioritized for data collection using appropriate
    field sensors. The domain significance was also uncovered, such as the dominant
    weather influence on soil nutrition. Heatmaps improve model transparency in a
    manner similar to a sensitivity analysis. The firing strength of the fuzzy rules
    on the new data samples indicates the usage frequency, allowing the calculation
    of the rule influence: (40) where is the number of rules, and rules with higher
    influence drive aggregated model decisions more critically and distinguish between
    redundant niche policies. Such analysis enhances user trust and model debugging.
    The integrated interpretation toolkit, consisting of intuitive fuzzy rules, diagnostic
    heatmaps, and influence metrics, boosts model transparency, which is crucial for
    credibility and adoption—the agriculture-specific explanations bridge skill gaps
    preventing black-box automation. Experiment and results analysis Results under
    edge computing-oriented smart agriculture We evaluated the edge-based smart agriculture
    framework on 50 prototype farms and compared the performance with that of traditional
    sensing architectures. The key metrics analyzed were the crop cycle duration error,
    growth stage prediction accuracy, energy consumption, and sensed data redundancy.
    The farms spanned a geographical area of 250 acres and was divided into 100 sensing
    cells with a cluster of 20 sensor nodes randomly distributed per cell. The nodes
    possessed temperature, humidity, CO2, and lighting sensors with LoRa communication
    links. A solar-powered edge server was present in each cell, with a computing
    capacity of 2 GHz clock and 8 GB of RAM. The edge nodes also had a cellular 4G
    hookup for cloud analytics. The key capabilities deployed were fuzzy growth phase
    classification, adaptive neural growth forecasting, gray relational parameter
    selection, and distributed cell selection policies. Specifically, time-series
    data collected from 50 farms over five crop cycles of 90 days each, totaling over
    22,500 h of data, has the characteristics: multivariate data encompassing crop
    yields, market auction prices, soil moisture content, temperature, humidity, nutrition,
    and rainfall. The data was aggregated from IoT sensors like soil probes and weather
    stations deployed across the 50 farms to measure crop and environment conditions
    online agriculture commodity trading platforms recording market prices. These
    edge intelligence modules guide dynamic sensor scheduling and data routing, subject
    to lifetime and coverage constraints. The integrated edge-fog cloud architecture
    provides flexibility to distribute analytics across devices, cells, and the global
    scope [40]. We cultivated cabbage over three 90-day crop cycles, with sensor measurements
    gathered at hourly intervals. Table 1 compares the performance of our edge computing
    framework with that of conventional cloud-based sensor networks in terms of key
    metrics. Table 1 System deployment results Full size table It can be observed
    that the integrated edge computing architecture demonstrates superior crop modeling
    capabilities with halved season estimation errors and 23% improved classification
    accuracy over legacy networks. Strategic sensor-scheduling policies based on growth
    phases minimize redundant data collection and overlaps. Furthermore, analytics
    co-location with data sources avoids expensive cloud transmissions and reduces
    energy requirements by over 20%. Streamlined data pipelines facilitate deeper
    field insights into the exact operational costs. Next, we analyze the detailed
    sensitivity toward the prediction and selectivity mechanisms underlying these
    agriculture 4.0 productivity gains. The results are shown in Table 2. Table 2
    Cabbage growth phase accuracy Full size table Fuzziness captures intermediately
    transitioning states better than rigid discrete models. Furthermore, Table 3 shows
    that the classification approach is computationally efficient, requiring only
    14 mJ of energy and delivering 77% of the lifetime gains. Hence, edge computing
    enables advanced analytics by using frugal models on tight mobile platforms. Table
    3 Energy consumption comparison Full size table The context-aware parameter selection
    scheme dynamically detects relevant attributes over the cabbage crop cycle using
    gray relational analysis, with the Pearson coefficient as a similarity metric.
    Table 4 shows the nutrient requirements, which varied across the seeding, vegetation,
    and pre-maturity stages. Our model automatically activated the corresponding sensors,
    MOISTURE during growth and NPK during flowering. Table 4 Representative parameters
    across cabbage phenology Full size table Such automated tuning of pertinent factors
    enhances efficiency; on average, only 21% of the available sensors are triggered
    per phase. Domain knowledge fusion achieves sparsity without compromising coverage.
    Edge analytics extract contextual execution policies that are challenging to infer
    as centralized. The decentralized sensor coordination protocol dynamically partitions
    cells into active sensing zones and candidate regions iteratively minimizing the
    (41) The distance metric ensures that dispersed sensors are selected, thereby
    capturing wider samples. Furthermore, the effective coverage area is (42) Thresholds
    prevent overlap. Unlike centralized controllers, distributed policies respond
    faster to local moisture fluctuations. Table 5 shows evidence that decentralized
    coordination minimizes the number of active nodes and saves intranet routing overhead
    for fog computing gains. Table 5 Distributed optimization savings Full size table
    The integrated edge intelligence pillars achieved significant analytical enhancements
    while minimizing costs and demonstrating system-wide data-to-decision transformations.
    Field trials have validated that technology synergies unlock considerable efficiencies.
    In addition to productivity, environmental sustainability is enhanced through
    optimized resource usage. Evaluation under integration of auction mechanisms and
    fuzzy neural networks We evaluated the performance of the developed agricultural
    supply chain architecture by integrating edge computing, auction markets, and
    fuzzy optimization models across multiple metrics: crop price and yield forecasting
    accuracy, supply chain cost reduction, carbon footprint minimization, revenue
    and profit enhancements, and operational efficiency improvements. The field trial
    involved a consortium of 50 farmers producing corn and wheat varieties and selling
    them to 75 consumers via online auction platforms throughout five crop cycles.
    Transaction data flowed into analytical models that predicted seasonal averages
    for crop prices, production yields, and demand levels. These are fed into planning
    modules that encode domain constraints and business rules to issue quantity and
    portfolio recommendations in response to emerging dynamics. For prediction accuracy,
    the proposed edge computing-oriented auction-based fuzzy neural network (EC-aFNN)
    should be compared with the four benchmarks: (i) BMAE-Net [41]: data-driven weather
    prediction network, (ii) Bayesian neural network (BNN) [42]: corn yield prediction
    based on remotely sensed variables, (iii) random forest regression (RFR) [43]:
    yield and quality prediction of winter rapeseed (iv) dingo-optimized sand piper
    (DOSP) [44]: automatic crop yield prediction framework designed with two-stage
    classifiers, as shown in Fig. 4. Fig. 4 Forecasting performance comparison Full
    size image Superior accuracy metrics directly and positively affect various aspects
    of smart agricultural supply chain operations. Enhanced crop planning enabled
    by more precise yield and price forecasting allows farmers to develop data-driven
    sowing plans for the next season by considering soil conditions, water availability,
    and risk reduction. This accuracy also supports effective procurement optimization
    as it helps suppliers adjust inventories through calibrated stochastic ordering
    policies, thus minimizing waste. Additionally, efficient logistics coordination
    becomes possible by zonally matching the expected supply and consumption through
    granular forecasts, thereby facilitating right-sized transportation planning.
    Moreover, the stability of market dynamics improved significantly. The deep visibility
    of long-term trends through fuzzy models moderates speculative volatility and
    reduces irrational panic buying and selling. Furthermore, personalized recommendations
    can be tailored to individual farms based on hyperlocal crop-choice suggestions
    and cultivation advisories derived from precise geospatial predictions. Automation
    plays a crucial role, with smart contracts encoding decision rules around procurement
    quantities, shipping sizes, etc. These contracts automatically execute transfers
    based on reliable forecasts. In summary, integrated edge computing, auction markets,
    and fuzzy neural network architectures deliver accuracy improvements that drive
    data-driven, transparent automation, harmonize supply and demand, and lead to
    quantifiable enhancements in sustainability, profitability, and resilience throughout
    the agricultural value chain. Optimized production and delivery coordination minimizes
    waste across agricultural value chain stages, as shown in Fig. 5. Total food loss
    was reduced by 29%, thus lowering operational costs. Fig. 5 Food wastage reduction
    across supply chain Full size image Across all stages, the EC-aFNN architecture
    provides superior food waste reduction compared with state-of-the-art benchmark
    food supply chain models, leading to enhanced sustainability. Supply chain transparency
    and coordination eliminate excess resource usage, as shown in Fig. 6. Fig. 6 Agricultural
    sustainability enhancements Full size image It can be observed that the integrated
    edge computing, auction markets, and fuzzy optimization framework provide 31–55%
    superior sustainability improvements along with energy, water, fertilizer, and
    pesticide reduction over the BNN, which highlights the strengths of our approach.
    Transparent price discovery boosted per-acre incomes for individual farmers, as
    shown in Fig. 7. Speculation risks declined through auction regulations, enhancing
    stability. Fig. 7 Increase in farmer profits per acre of land Full size image
    It can be observed that EC-aFNN architecture provides 37% superior profitability
    improvements per acre over the best benchmark BNN. Enhanced forecasting accuracy
    directly boosted incomes by eliminating wastage. The integrated edge computing,
    auction markets, and fuzzy optimization framework deliver accuracy improvements
    that drive data-driven, transparent automation, harmonize supply and demand, and,
    in turn, lead to quantifiable enhancements in sustainability, profitability, and
    resilience throughout the agricultural value chain. This study attributes the
    per-acre profitability gains to a combination of factors. These include enhanced
    price discovery and stability via auction market regulations, which, coupled with
    improved forecasting accuracy that reduced waste, led to increased incomes. Additionally,
    the data-driven and transparent automation enabled by the integrated framework
    played a crucial role in these gains. Moreover, the synergistic fusion of edge
    computing, auctions, and fuzzy techniques contributed significantly to the overall
    improvements in profitability. Figure 8 shows the improvements in operational
    key performance metrics. Fig. 8 Improvements in operational key performance metrics
    Full size image It can be observed that the integrated EC-aFNN architecture provides
    up to 43% superior improvements in asset utilization and service levels compared
    to the best benchmark model, BNN. Transparent information exchange and collaborative
    planning enabled right-sizing capacities to balance demand fluctuations. Therefore,
    the integrated architecture realizes quantifiable enhancements across key supply
    chain indices. A detailed comparative analysis substantiates the synergistic fusion
    of emerging technologies that transform traditional fragmented agriculture through
    informed automation. Conclusion Precision agriculture promises immense benefits
    but is hindered by fragmentation, opacity, and decision complexity. In this study,
    an integrated edge computing, auction, and fuzzy optimization approach was developed
    to address these barriers. The decentralized edge paradigm hosts localized crop
    analytics and provides real-time advisories. Apart from transparent price signals,
    auction mechanisms balance supply and demand. Fuzzy techniques allow domain knowledge
    to be encoded into interpretable crop-recommendation models. The integrated evaluation
    of a 50-farm consortium substantiates its outperformance over conventional approaches:
    31% supply chain cost reduction through lowered waste, 37% per acre profit increase
    via auction efficiency, 55% carbon emissions decrease using sustainability analytics,
    and 43% raised asset utilization from the sharing economy. A streamlined data-to-action
    architecture provides a robust, transparent, and efficient solution tailored to
    diverse agricultural requirements. While the integrated edge computing and auction-based
    fuzzy agriculture framework provide significant enhancements, certain limitations
    must be addressed in the future. Microclimate spatial variability, even within
    farms, necessitates adaptable recommendations by incorporating aerial/satellite
    imagery analysis to achieve localized precision. Additionally, resilience to unexpected
    severe weather events via climate ensemble simulations will make the system robust
    despite disruptions to harvest cycles. Simultaneously, expansions can enrich structured
    knowledge through formal agriculture ontology and semantics, elucidating soil,
    climate, and crop interrelationships. Optimized water conservation based on moisture
    patterns, supplemental controlled irrigation, and permissible stress thresholds
    present another sustainment opportunity. Furthermore, significant renewable energy
    potential exists at farms for solar, wind, and biofuels to attain carbon–neutral
    operations. Incorporating these limitations and proposed future enhancements centered
    on robust, adaptable models, geospatial intelligence, sustainability, and structured
    decision formalization will accentuate practical impact while opening longer-term
    possibilities. Availability of data and materials No datasets were generated or
    analysed during the current study. References Sawkar RH, Hiregoudar LG, Bharadwaj
    S (2020) Aquaponics: a modern agriculture technology to overcome water scarcity
    and drought. J Geol Soc India 95:108–109 Article   Google Scholar   Utamima A,
    Reiners T, Ansaripoor AH (2022) Evolutionary neighborhood discovery algorithm
    for agricultural routing planning in multiple fields. Ann Oper Res 316:955–977
    Article   Google Scholar   Nyam YS, Kotir JH, Jordaan AJ et al (2021) Developing
    a conceptual model for sustainable water resource management and agricultural
    development: the case of the Breede River Catchment Area, South Africa. Environ
    Manage 67:632–647 Article   CAS   PubMed   Google Scholar   Ding Y, Sun C (2022)
    Does agricultural insurance promote primary industry production? Evidence from
    a quasi-experiment in China, Geneva. Pap Risk Insur Issues Pract 47:434–459 Google
    Scholar   Misara R, Verma D, Mishra N et al (2022) Twenty-two years of precision
    agriculture: a bibliometric review. Precision Agric 23:2135–2158 Article   Google
    Scholar   Nowak B (2021) Precision agriculture: where do we stand? A review of
    the adoption of precision agriculture technologies on field crops farms in developed
    countries. Agric Res 10:515–522 Article   Google Scholar   Duncan E, Glaros A,
    Ross DZ et al (2021) New but for whom? Discourses of innovation in precision agriculture.
    Agric Hum Values 38:1181–1199 Article   Google Scholar   Shaikh TA, Mir WA, Rasool
    T et al (2022) Machine learning for smart agriculture and precision farming: towards
    making the fields talk. Arch Computat Methods Eng 29:4557–4597 Article   Google
    Scholar   Lu HL, Chang YH, Wu BY (2020) The compare organic farm and conventional
    farm to improve sustainable agriculture, ecosystems, and environment. Org Agr
    10:409–418 Article   Google Scholar   Qi LY, Liu YW, Zhang YL et al (2022) Privacy-aware
    point-of-interest category recommendation in internet of things. IEEE Internet
    Things J 9:21398–31408 Article   Google Scholar   Liu YW, Zhou XK, Kou HZ et al.
    Privacy-preserving point-of-interest recommendation based on simplified graph
    convolutional network for geological traveling. ACM Trans Intell Syst Technol.
    2023. Hsu CH, Lin HH, Jhang SW et al (2021) Does environmental engineering help
    rural industry development? Discussion on the impact of Taiwan’s “special act
    for forward-looking infrastructure” on rural industry development. Environ Sci
    Pollut Res 28:40137–40150 Article   Google Scholar   Pearsall H, Gutierrez-Velez
    VH, Gilbert MR et al (2021) Advancing equitable health and well-being across urban–rural
    sustainable infrastructure systems. npj Urban Sustain. 1:26 Article   Google Scholar   Kumar
    CS, Anand RV (2023) A review of energy-efficient secured routing algorithm for
    IoT-Enabled smart agricultural systems. J Biosyst Eng 48:339–354 Article   Google
    Scholar   Shi H, Li Q (2022) Edge computing and the internet of things on agricultural
    green productivity. J Supercomput 78:14448–14470 Article   Google Scholar   Mittelmann
    M, Bouveret S, Perrussel L (2022) Representing and reasoning about auctions. Auton
    Agent Multi-Agent Syst 36:20 Article   Google Scholar   Zhang K, Hao WN, Yu XH
    et al (2023) Research on a kind of multi-objective evolutionary fuzzy system with
    a flowing data pool and a rule pool for interpreting neural networks. Int J Fuzzy
    Syst 25:575–600 Article   Google Scholar   Oteyo IN, Marra M, Kimani S et al (2021)
    A survey on mobile applications for smart agriculture. SN Comput Sci 2:293 Article   Google
    Scholar   Wang X, Ni D (2023) Internet based rural economic entrepreneurship based
    on mobile edge computing and resource allocation. Soft Comput. https://doi.org/10.1007/s00500-023-08620-z
    Article   PubMed   PubMed Central   Google Scholar   Zhang YA, Sun Z, Zhang C
    et al (2021) Body weight estimation of yak based on cloud edge computing. J Wireless
    Com Netw 2021:6 Article   Google Scholar   Gupta N, Khosravy M, Patel N et al
    (2020) Economic data analytic AI technique on IoT edge devices for health monitoring
    of agriculture machines. Appl Intell 50:3990–4016 Article   Google Scholar   Li
    C, Sha Z, Sun T (2023) Rural households’ internet use on common prosperity: evidence
    from the Chinese social survey. Soc Indic Res 170:797–823 Article   Google Scholar   Liu
    P (2021) Balancing cost effectiveness and incentive properties in conservation
    auctions: experimental evidence from three multi-award reverse auction mechanisms.
    Environ Resource Econ 78:417–451 Article   Google Scholar   Feng Y, Mei D, Zhao
    H (2023) Auction-based deep learning-driven smart agricultural supply chain mechanism.
    Appl Soft Comput 149:111009 Article   Google Scholar   Chiu LJV, Taure LW, Groh
    YT (2022) Pricing efficiency in livestock auction markets: a two-tier frontier
    approach. Agric Econ 53:139–151 Article   Google Scholar   Seifert S, Huettel
    S (2023) Is there a risk of a winner’s curse in farmland auctions? Eur Rev Agric
    Econ 50:1140–1177 Article   Google Scholar   Remya S (2022) An adaptive neuro-fuzzy
    inference system to monitor and manage the soil quality to improve sustainable
    farming in agriculture. Soft Comput 26:13119–13132 Article   Google Scholar   Acharjya
    DP, Rathi R (2022) An integrated fuzzy rough set and real coded genetic algorithm
    approach for crop identification in smart agriculture. Multimed Tools Appl 81:35117–35142
    Article   Google Scholar   MohebbiTafreshi G, Nakhaei M, Lak R (2020) A GIS-based
    comparative study of hybrid fuzzy-gene expression programming and hybrid fuzzy-artificial
    neural network for land subsidence susceptibility modeling. Stoch Environ Res
    Risk Assess 34:1059–1087 Article   Google Scholar   Kaya NS, Pacci S, DemiragTuran
    I et al (2023) Comparing geographic information systems-based fuzzy-analytic hierarchical
    process approach and artificial neural network to characterize soil erosion risk
    indexes. Rend Fis Acc Lincei 34:1089–1104 Article   Google Scholar   Remya S,
    Sasikala R (2020) Performance evaluation of optimized and adaptive neuro fuzzy
    inference system for predictive modeling in agriculture. Comput Electr Eng 86:106718
    Article   Google Scholar   Ramana K, Aluvala R, Kumar MR et al (2022) Leaf disease
    classification in smart agriculture using deep neural network architecture and
    IoT. J Circuits Syst Comput 31:2240004 Article   Google Scholar   Bhojani SH,
    Bhatt N (2020) Wheat crop yield prediction using new activation functions in neural
    network. Neural Comput Appl 32:13941–13951 Article   Google Scholar   Zhang L,
    Huang ZY, Liu W et al (2021) Weather radar echo prediction method based on convolution
    neural network and Long Short-Term memory networks for sustainable e-agriculture.
    J Clean Prod 298:126776 Article   Google Scholar   Wang J (2022) Analysis of wireless
    communication networks under edge computing scenarios. Wireless Netw 28:3665–3676
    Article   Google Scholar   Dhillon SK, Madhu C, Kaur D et al (2020) A review on
    precision agriculture using wireless sensor networks incorporating energy forecast
    techniques. Wireless Pers Commun 113:2569–2585 Article   Google Scholar   Shepelev
    GI (2022) Effects of Defuzzification methods on the results of comparing fuzzy
    alternatives. Sci Tech Inf Proc 49:364–370 Article   Google Scholar   Vassiliev
    AE, Vegner AV, Golubeva DE et al (2023) Increasing the quality indicators of the
    functioning of fuzzy solvers at the Defuzzification stage. J Commun Technol Electron
    68:810–818 Article   Google Scholar   Wang G, Wang H, Long Z (2021) Norm approximation
    of mamdani fuzzy system to a class of integrable functions. Int J Fuzzy Syst 23:833–848
    Article   Google Scholar   Oprea SV, Bâra A (2023) An Edge-Fog-Cloud computing
    architecture for IoT and smart metering data. Peer-to-Peer Netw Appl 16:818–845
    Article   Google Scholar   Kong JL, Fan XM, Jin XB et al (2023) BMAE-Net: a data-driven
    weather prediction network for smart agriculture. Agronomy-Basel 13:625 Article   Google
    Scholar   Ma YC, Zhang Z, Kang YH et al (2021) Corn yield prediction and uncertainty
    analysis based on remotely sensed variables using a Bayesian neural network approach.
    Remote Sens Environ 259:112408 Article   Google Scholar   Rajkovic D, Jeromela
    AM, Pezo L et al (2022) Yield and quality prediction of winter rapeseed-artificial
    neural network and random forest models. Agronomy-Basel 12:58 Article   Google
    Scholar   Kolipaka VRR, Namburu A. An automatic crop yield prediction framework
    designed with two-stage classifiers: a meta-heuristic approach. Multimed Tools
    Appl. 2023. Download references Funding This paper was supported by General Projects
    of Zhengzhou Soft Science Research Program in 2023 (Granted No. 8), Annual Program
    of Philosophy and Social Science Planning of Henan Province (Grant No. 2023CJJ113),
    and Chongqing Transportation Science and Technology Project (Granted No.s CQJT-2023CZ28-1
    and CQJT-2023CZ16-1). Author information Authors and Affiliations School of Economics
    and Business Administration, Chongqing University, Chongqing, 400044, China Qing
    He, Hua Zhao & Yu Feng School of Economic and Management, Chongqing Normal University,
    Chongqing, 401331, China Qing He & Zhaofeng Ning School of Social Development,
    East China Normal University, Shanghai, 200241, China Zehao Wang School of Management,
    Lanzhou University, Lanzhou, 73000, China Tingwei Luo Contributions Q.H. contributed
    to conception and writing; H.Z. and Y.F. contributed to methodology; Z.W. contributed
    to data analysis; Z.N. contributed to software; T.L. contributed to polishing.
    Corresponding author Correspondence to Yu Feng. Ethics declarations Ethics approval
    and consent to participate This declaration is “not applicable”. Competing interests
    The authors declare no competing interests. Additional information Publisher’s
    Note Springer Nature remains neutral with regard to jurisdictional claims in published
    maps and institutional affiliations. Rights and permissions Open Access This article
    is licensed under a Creative Commons Attribution 4.0 International License, which
    permits use, sharing, adaptation, distribution and reproduction in any medium
    or format, as long as you give appropriate credit to the original author(s) and
    the source, provide a link to the Creative Commons licence, and indicate if changes
    were made. The images or other third party material in this article are included
    in the article''s Creative Commons licence, unless indicated otherwise in a credit
    line to the material. If material is not included in the article''s Creative Commons
    licence and your intended use is not permitted by statutory regulation or exceeds
    the permitted use, you will need to obtain permission directly from the copyright
    holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
    Reprints and permissions About this article Cite this article He, Q., Zhao, H.,
    Feng, Y. et al. Edge computing-oriented smart agricultural supply chain mechanism
    with auction and fuzzy neural networks. J Cloud Comp 13, 66 (2024). https://doi.org/10.1186/s13677-024-00626-8
    Download citation Received 08 January 2024 Accepted 07 March 2024 Published 21
    March 2024 DOI https://doi.org/10.1186/s13677-024-00626-8 Share this article Anyone
    you share the following link with will be able to read this content: Get shareable
    link Provided by the Springer Nature SharedIt content-sharing initiative Keywords
    Edge computing Smart agricultural supply chain Auction Fuzzy neural networks Download
    PDF Collection Mobile Edge Computing Meets AI Sections Figures References Abstract
    Introduction Related work Edge computing-oriented smart agriculture Integration
    of auction mechanisms and fuzzy neural networks Conclusion Availability of data
    and materials References Funding Author information Ethics declarations Additional
    information Rights and permissions About this article Advertisement Support and
    Contact Jobs Language editing for authors Scientific editing for authors Leave
    feedback Terms and conditions Privacy statement Accessibility Cookies Follow SpringerOpen
    By using this website, you agree to our Terms and Conditions, Your US state privacy
    rights, Privacy statement and Cookies policy. Your privacy choices/Manage cookies
    we use in the preference centre. © 2024 BioMed Central Ltd unless otherwise stated.
    Part of Springer Nature."'
  inline_citation: '>'
  journal: Journal of Cloud Computing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Edge computing-oriented smart agricultural supply chain mechanism with auction
    and fuzzy neural networks
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Tanksale R.S.
  - Mane S.B.
  citation_count: '0'
  description: This study presents a meticulous comparison of plant disease detection
    models on the Raspberry Pi 5 platform, employing Basic CNN, AlexNet, ResNet-50,
    and MobileNet architectures through MiniTensorflow. Our investigation scrutinizes
    response time latency, individual plant image performance, and overall model efficiency
    and accuracy. The assessment includes a diverse dataset, the New Plant Diseases
    Dataset from Kaggle, encompassing various plant species and diseases. Response
    time latency is measured to gauge the processing speed of each model, while individual
    plant image analysis identifies potential efficiency variations across different
    plant types. A userfriendly web application, developed using Python Flask, facilitates
    model accessibility and real-time testing. The study transcends traditional accuracy
    metrics, offering insights into each model's nuanced strengths and limitations.
    This research contributes a valuable perspective on the suitability of these models
    for real-world deployment on the widely used Raspberry Pi 5, essential for practitioners
    and researchers in the field of plant disease detection.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International Journal of Intelligent Systems and Applications in Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Efficient Plant Disease Detection on RISC Devices: A comparison of Basic
    CNN, AlexNet, ResNet-50, and MobileNet Models using MiniTensorFlow'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kumar Kasera R.
  - Gour S.
  - Acharjee T.
  citation_count: '1'
  description: Today farmers around the world are gradually embracing Smart farming
    assisted by different cutting-edge technologies. The Internet of Things (IoT)
    is playing a major role in the development of smart agriculture applications.
    Artificial intelligence, edge computing, cloud computing, big data, etc are other
    forefront technologies used in smart agriculture. Stages of Agriculture activities
    for a certain crop can be broadly classified into three categories, viz, pre-harvest,
    during harvest and post-harvest phases. In each phase, many activities have to
    be performed. Pre-harvesting stage involves seed selection, land preparation,
    crop selection, etc., during harvesting includes irrigation, disease analysis,
    pathogens detection, etc. and Post harvesting involves storage, cooling, reaping,
    etc. In the current work, we have carried out a thorough literature review of
    these activities involving smart farming one by one. We have attempted to find
    the flaws in terms of IoT devices, security, dataset, and methodologies used in
    these existing works. Based on the research gaps a 5G-based smart farming framework
    has been proposed. We have also presented a brief comparative analysis between
    our survey and the existing surveys. Our survey has been found to be more comprehensive
    compared to the existing ones in many regards.
  doi: 10.1016/j.compag.2023.108522
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Pre-harvesting system
    (PHRS) 3. During harvesting system (DHRS) 4. Post harvesting system (POHRS) 5.
    Metaheuristic based algorithm in smart agriculture application 6. Technologies
    based on the IoT for smart agriculture 7. Dataset collection 8. Comprehensive
    shortcomings of PHRS, DHRS, and POHRS 9. Proposed architecture for smart agriculture
    10. Comparative analysis of existing smart agriculture system with proposed 5G
    based architecture 11. Conclusion Declaration of competing interest Data availability
    References Show full outline Cited by (1) Figures (13) Show 7 more figures Tables
    (6) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Computers and Electronics
    in Agriculture Volume 216, January 2024, 108522 Review Article A comprehensive
    survey on IoT and AI based applications in different pre-harvest, during-harvest
    and post-harvest activities of smart agriculture Author links open overlay panel
    Rohit Kumar Kasera, Shivashish Gour, Tapodhir Acharjee Show more Add to Mendeley
    Share Cite https://doi.org/10.1016/j.compag.2023.108522 Get rights and content
    Highlights • A comprehensive literature review is performed for smart agriculture
    techniques. • The survey covers almost all Pre, During and Post harvesting activities
    separately. • A 5G-IoT based smart farming framework is proposed. • In comparison
    with existing surveys our survey was found to be more comprehensive. Abstract
    Today farmers around the world are gradually embracing Smart farming assisted
    by different cutting-edge technologies. The Internet of Things (IoT) is playing
    a major role in the development of smart agriculture applications. Artificial
    intelligence, edge computing, cloud computing, big data, etc are other forefront
    technologies used in smart agriculture. Stages of Agriculture activities for a
    certain crop can be broadly classified into three categories, viz, pre-harvest,
    during harvest and post-harvest phases. In each phase, many activities have to
    be performed. Pre-harvesting stage involves seed selection, land preparation,
    crop selection, etc., during harvesting includes irrigation, disease analysis,
    pathogens detection, etc. and Post harvesting involves storage, cooling, reaping,
    etc. In the current work, we have carried out a thorough literature review of
    these activities involving smart farming one by one. We have attempted to find
    the flaws in terms of IoT devices, security, dataset, and methodologies used in
    these existing works. Based on the research gaps a 5G-based smart farming framework
    has been proposed. We have also presented a brief comparative analysis between
    our survey and the existing surveys. Our survey has been found to be more comprehensive
    compared to the existing ones in many regards. Previous article in issue Next
    article in issue Keywords Smart AgriculturePre-harvestingDuring harvestingPost
    harvestingNB-IoTSDN 1. Introduction One of the most important pillars of human
    society is agriculture. According to the food and agriculture organization (FAO),
    to cater the needs of growing population, food (FAO, 2009) production need to
    be increased by 70–65 % in 2050. Farmers must put in more effort while using the
    traditional agricultural approach, which also uses resources inefficiently. Several
    issues, including population expansion, climatic circumstances, a shortage of
    resources, etc., occur from this ancient farming approach. The term smart agriculture
    refers to digital farming practices that are used to maximize effectiveness instead
    (Javaid et al., 2022) of capability. This system performs structured and optimal
    input and output analytics through smart technologies, objective-focused analysis,
    planning, and monitoring. As a result of collecting and pooling analytical data
    using advanced sensor, a methodology group is built that is optimized for achieving
    this objective-oriented analysis. For monitoring and managing agricultural operations,
    this cutting-edge technology combines Internet of Things (IoT) networks, devices,
    AI, and big data analytics. Through the use of diverse electronic, biochemical,
    and electrical sensors and actuators, various farming field data can be collected,
    and through this data, different sub-operations of farming applications can be
    developed. Using IoT to monitor crops (Sreekantha and Kavya A.M., 2017), detect
    diseases and pests, predict crop yields, robotics-based harvesting of crops, and
    much more. The creation of a wireless sensor network (WSN) can be accomplished
    using various types of wireless connections, each with a range, bandwidth, and
    topology that varies. A novel kind of wireless network can be built using topologies
    like bus, star, and mesh and a variety of communication technologies including
    Bluetooth, ZigBee, LTE-M, thread, Sigfox, etc. to communicate data from one node
    to another about the farming field. The edge gateway layer where all sensor node
    data are stored and processed for further analysis is connected to this sensor
    network. The data can be communicated to a different distributed network over
    the internet to a cloud server for additional analysis and monitoring at the user
    end by using application protocols like “Hypertext transfer protocol” (HTTP),
    “Message queuing telemetry transport protocol” (MQTT), etc. The gateway can be
    utilized as single-board microcontrollers and computers similar the Raspberry
    Pi (Charania and Li, 2020). Digital transformation is the main advancement in
    agricultural development which (Baryshnikova et al., 2022) transforms 1.0 into
    5.0 in the twenty-first century. The key to advancing digital transformation in
    smart agriculture from version 5.0 to version 6.0 is the development of wireless
    communication technology. A number of wireless communication technologies, including
    “Long Range Radio (LoRa)”, Radio frequency module (RFM69)“, ”Narrow Band IoT (NB-IoT)“,
    and ”SigFox“ etc (Hidayat et al., 2020) have been utilised in agriculture. It
    is possible to create a secure smart farm system, also known as a 5G beyond Smart
    agriculture system (Tomaszewski et al., 2022) by fusing several technologies including
    IoT, Edge computing, cloud computing, artificial intelligence (AI), and Blockchain
    (Andreadis et al., 2022, Kasera et al., 2022). The ability to manage and achieves
    a variety of computing workloads and necessities for storage can be encouraged
    by developing a hybrid or dispersed sensor network employing cloud computing and
    edge computing. In this regard, edge computing will be able to regulate jobs that
    demand speed or limitations on connectivity. In addition, cloud computing will
    be able to accommodate operations that demand higher processing capabilities,
    for instance, machine learning (MCLRN), as well as managing enormous volumes of
    data by utilizing load-balancing techniques. From this type of technologies farmers
    will be able to access farming field status remotely and the system will be entirely
    automated through interoperability between machines (Li et al., 2021). Considering
    the research strategy that was used to write this review article is discussed
    in Fig. 1 below. Download : Download high-res image (265KB) Download : Download
    full-size image Fig. 1. The flow of research methodology. The dotted arrow in
    Fig. 1 denotes the simplified structure of how the review article is organized.
    Based on pre-, during-, and post-harvesting operations, the various IoT-enabled
    smart agriculture literature has been identified and categorized. After classifying
    and reading the literature, each pre-harvesting, during-harvesting, and post-harvesting
    operations’ existing subsystems have been thoroughly discussed and its weaknesses
    analyzed. This analysis has been accomplished based on the IoT-enabled technologies,
    data set gathering, and approaches that have been used in the past and it also
    includes an overall thorough assessment of the pre-, during-, and post-harvesting
    subsystem''s research gaps. Based on this research gap a modified 5G IoT-based
    smart agriculture framework has been proposed to reduce the shortcomings of the
    existing work. The Pre-harvest to post-harvest activities have been categorized
    in this article to explain the existing work for the smart farming system. The
    classification of pre- to post-harvest activities is presented in the Fig. 2.
    Download : Download high-res image (485KB) Download : Download full-size image
    Fig. 2. Pre to post harvesting process (S R et al., 2020). The paper is presented
    as per the following structure: The problem with traditional agriculture is introduced
    in section (1), along with how smart agriculture uses cutting-edge technology
    through 5G connection to tackle the problem, and the classification of various
    farming processes from pre-harvesting through post-harvesting. The section (2)
    discusses the IoT-based existing works on various pre-harvesting farming processes.
    The section (3) provides information on the IoT-based existing works in the harvesting
    process. The section (4) provides information on several existing works for the
    post-harvesting process. The modern metaheuristic technique for creating intelligent
    farm systems is covered in section (5). The section (6) analyses the current and
    future communication technologies used for smart agriculture up to this point.
    The section (7) provides information on the existing dataset that can be used
    in solving smart agriculture problems. Section (8) discuss the problem exist in
    the existing IoT based system on various pre to post harvesting subsystem, section
    (9) contributes the recommendation based on existing problem for developing pre
    to post harvesting subsystem, section (10) a comparison of the proposed 5G based
    smart agriculture framework with existing smart agriculture framework is discussed
    and in last section (11) overall summary of the proposed survey has been discussed.
    2. Pre-harvesting system (PHRS) Throughout the pre-harvest process, there are
    a number of land preparation (LPR) sub-activities that considerably increase agricultural
    yield. Researchers, scientists, and engineers have made a number of advancements
    in the past to create a smart PHRS using smart agriculture technology (Gaikwad
    et al., 2021), that can choose the crop in advance depending on climate conditions,
    region, area, etc. and prepare the land for production. The sub-areas of PHRS
    that are used when preparing the land for farming are depicted in Fig. 3. Download
    : Download high-res image (267KB) Download : Download full-size image Fig. 3.
    PHRS subsystem classification. 2.1. Crop yield prediction (CYP) IoT-based method
    for yield prediction in which sensor node data is shared with data centers (Gayatri
    et al., 2015) and made available to the sons of the soil. To anticipate agricultural
    yield, supervised MCLRN is carried out utilizing (Kumar et al., 2020) the “Random
    Forest” (RADF) and “Decision tree” (DT) algorithm. In this situation the RADF''s
    accuracy is superior compared to the DT''s. A two-tier MCLRN model called the
    “adaptive k-Nearest Centroid Neighbour Classifier (aKNCN)” and the “Extreme Learning
    Machine algorithm (ELM)” were proposed to predict crop yield. By applying ELM
    to (Gupta and Nahar, 2023) increase performance accuracy, the suggested system
    optimize the weights using a modified version of the Butterfly Optimisation Algorithm
    (mBOA). The creation of an algorithm for predicting crop yield (Bhojani and Bhatt,
    2020) three new activation functions called “DharaSig,” “DharaSigm,” and “SHBSig”
    are employed to enhance the neural network''s performance on agricultural datasets.
    K Closest neighbor procedure is employed to identify the crop that is most acceptable
    (Gajula et al., 2021). For the purpose of forecasting the yield of the sorghum
    crop, (Jayaram and Marad, 2012) a fuzzy inference approach is implemented. A fuzzy
    model''s input tools are physio-morphological features. Due to estimates and ambiguity,
    the model''s performance depends on quantum data. A method for managing massive
    data and predicting crop productivity three different types of (Fan et al., 2015)
    approaches have been employed that is MapReduce weather data for computing large
    datasets; nearest neighbor weather data for comparing distances across like years;
    and, finally, an “Autoregressive moving average” (ARMA) model for forecasting.
    To determine crop yield, a “Support vector machine” (SVM) and DT approach are
    used. While choosing (Reshma et al., 2020) features for a specific location, factors
    like soil type, temperature, humidity, groundwater level, local population, farmers''
    availability, variety of plantations, and variety of farmed land were taken into
    account. Analysis has been conducted based on these traits to determine the optimal
    crop. A mixed MCLRN approach was put forth to estimate agricultural yield. The
    most precise (Anbananthen et al., 2021) MCLRN prediction from two models is combined
    using the stacking generalization model. Cross-validation is used to evaluate
    a hybrid MCLRN model''s performance to that of other MCLRN models for evaluation.
    For the purpose of predicting agricultural yield (Sajja et al., 2021) an MCLRN
    simulation is designed, where crop segments are built up experimentally for the
    training of models using SVM, random forest, and ID3. In which case SVM outperforms
    other methods. The key advantage of the current CYP is that most systems classify
    soil nutrients and geographic data for crop yield prediction using data mining
    techniques like KNN, ID3 and fuzzy inference systems, which produce superior prediction
    outcomes. The geographic information was gathered using a GPS approach that is
    IoT-enabled. The RGB-D camera is utilized as a mobile platform to enhance the
    CYP. Crop quality, data-driven decision-making, cost reduction, and resource optimization
    are all improved by using IoT-enabled data mining approaches. The shortcomings
    of the existing techniques are as follows: prediction based on time series analysis,
    area-wise analysis, soil quality analysis, country-wise analysis, and geospatial
    analysis remain to be explored. There is no hybrid MCLRN algorithm for handling
    huge datasets. Full IoT based system still need to be worked upon. 2.2. Crop selection
    (CSL) Enhancing Agricultural Sustainability through Crowdsensing (Ginige and Sivagnanasundaram,
    2019) a mobile-based agricultural information-sharing system is developed for
    monitoring real-time farming activities (CSL LPR, “seed selection”, “seed sowing”,
    “irrigation, “crop growth”, “fertilizing”, and “harvesting”) with the help of
    a crop calendar marker. IoT-based system for crop selection and monitoring precision
    farming (Bhojwani et al., 2020) various sensors are employed to measure environmental
    variables and interface with the microprocessor. An IoT gateway using ESP8266
    sends the data acquired to a cloud server. On the basis of data collected earlier
    from the cloud server, the existing working model uses K-Nearest Neighbours (KNN)
    to estimate prospective predictions to be able to make precise decisions about
    what crops to grow in a particular environment. Maximize the crop yield (Kumar
    et al., 2015) for selecting which crops to cultivate over a season the MCLRN method
    predict yield rates based on environmental variables including weather, soil type,
    water density, and crop type. Smart agriculture-based crop selection analysis
    utilising (Tseng et al., 2019) big data a platform is created to track environmental
    elements on a farm and use those environmental factors to evaluate farmers'' agricultural
    practices. The findings suggest that farmers can determine a crop''s suitability
    for their land with greater insight. This is so they can take a look at things
    like soil moisture levels and temperature. The suggested environmental factor
    analysis methodology aids farmers in learning which crops they can produce. In
    order to optimize food production (Udutalapally et al., 2021) an innovative agricultural
    solution is proposed that uses AI and IoT for selecting crops, disease monitoring,
    and automated irrigation systems. The fuzzy MULTIMOORA technology on (Balezentiene
    et al., 2013) language and numerical reasoning is provided as a fuzzy-based system
    for crop selection in Lithuanian climatic conditions. “Johnson''s reduct” classifier
    method is used (Deepa and Ganesan, 2019) to produce classification rules for three
    crops, including rice, “groundnut”, and “sugarcane”, in a decision-based system
    for crop selection. According to present environmental (Bakthavatchalam et al.,
    2022) circumstances a system has been established for precision agriculture that
    uses IoT and classifier-based MCLRN algorithms to recommend the crop for irrigation
    and acquire the highest yield. AI for characterization and forecasting the (Amkor
    and El Barbri, 2023) results of potato samples cultivated with “Nitrogen”, “Phosphorus”,
    “Potassium” (NPK) fertilizers has been suggested in which KNNs are used for classification
    and nonlinear autoregressive models for prediction. Machine learning and artificial
    intelligence advancements for the existing CSL system improve the decision-making
    for planting crops according to climate conditions and location. By using IoT-enabled
    solar power-based crop recommendation systems, energy consumption is reduced.
    Genetic optimization is the most common method for optimizing CSL performance.
    Crop guidance is improved when weather conditions are forecasted through the development
    of a crop calendar-based system. Some of the shortcomings may be as follows: the
    current CSL solution lacks self-sustainability, testing for additional crops,
    security of sensor node data, system optimization, and subsystem integration.
    2.3. Seed selection (SSL) A tillage drip architecture is used for recommending
    seeds for (Indira et al., 2018) planting. Additionally, it discusses how effective
    seed selection based on soil can produce precise results. Seed selection is possible
    in the first phase, automatic watering is covered in the second phase, and plant
    disease diagnosis is covered in the third phase. A computer vision to identify
    (Koklu and Ozkan, 2020) different dry bean seed kinds the user interface was created
    using MATLAB, and 13,611 grains of seven different types of dry beans were photographed.
    The model has undergone 20-fold cross-validation and has been constructed using
    a variety of MCLRN classification methods, including MLP, SVM, KNN, and DT. When
    compared to other classification model results, SVM performance performed better.
    Deep-learning methods for seed classification were proposed in which fourteen
    (Hamid et al., 2022) different types of seeds were gathered and pre-trained using
    “MobileNetV2″ to create a model. The trained model claimed accuracy of 98 % on
    the training set and 95 % on the test set after rigorous experiments, extensive
    pre-processing, and fine-tuning. The advantage of the current SSL system is that
    it chooses the appropriate seeds for individual fields using a computer vision-based
    method based on MCLRN and AI. Water, insecticides, and fertilisers may all be
    used more efficiently by farmers. This has good effects on the environment in
    addition to lowering costs. The existing work lacks a fully automated system and
    limited use of data. Need more research for various types of seed classification
    based on climate condition, geographical region wise, and land wise. 2.4. Seed
    germination (SGM) Proposed and created a smart germination assistance (SGA) system
    for SGM. “Temperature”, “humidity”, “light intensity”, “moisture”, and soil “pH”
    are all factors that (Islam et al., 2019) affect SGM. Using particular sensors,
    the system continuously measures the values of various factors in the surrounding
    environment. Each sensor reading from a different seed is kept and connected to
    an ideal value. Using a low-power embedded system (Shadrin et al., 2019) an AI
    method is proposed that can recognise SGM dynamics without necessitating heavy
    data transfer between nearby nodes. 97 % accuracy is attained with a “convolutional
    neural networks” (CNNs) model for seed recognition. A system based on the IoT
    was proposed to monitor, manage, and (Theparod and Harnsoongnoen, 2022) collect
    data regarding the effects of narrow-band light emitting diodes (LEDs) on sunflower
    nodes. With the help of “narrow-band LEDs” and dynamic germination, it was found
    through research that the germination of sunflower seeds was more successful in
    the red-light zones. IoT-based study is carried out for indoor tomato SGM (Seyar
    and Ahamed, 2023) systems at thresholds. Where transplanted seedlings were grown
    outdoors with a comparison of two irrigation systems using soil water balance
    methods with a long-range LoRa communication system, and the subsurface drip irrigation
    system produced the highest seedling levels of growth based on agronomical parameters
    at a 12 % threshold. A feature of the current SGM system is the usage of a LoRa-based
    data communication system for various modules during the SGM process, such as
    irrigation and seed growing status. For the dynamic seed germination process,
    the usage of IoT-based “narrow-band LEDs” produces better results. The system
    in place uses only one type of seed for testing, and it is not entirely IoT-based.
    As a result, there is a lack of a fully validated testbed system that uses an
    ideal sensor, is self-sustaining, and can be utilised for other crops. The current
    system still has flaws as it does not deal with plant biomass growth, flowering,
    fruits, and other types of crops utilising IoT-based technique and image processing
    algorithm. 2.5. Drought or flood monitoring (DFM) A “WPART” IoT-enabled smart
    farming system is established that uses MCLRN (Rezk et al., 2021) to anticipate
    crop productivity and drought for informed decision-making. The following data
    factors are used to pick features: year, month, rainfall, temperature, air pressure,
    season, crop, “area”, “production”, and productivity. An IoT-based tackle has
    been put up for agricultural drought (Ping, 2014) data transmission and accumulating.
    The outcome shows that the system''s data capture and transmission performance
    is flawless, and it has good application value for gathering and analysing agricultural
    drought data. An MCLRN/IoT-based flood tracking system is portrayed (Rani et al.,
    2020) to gauge the water level in a flood-prone site. The intensity of floods
    is gauged using raindrop and water sensors. An IoT-based dam water monitoring
    alerting system is developed (Ganesh et al., 2022) for calculating how much rain
    fell, one may determine how much water will be released from the dam. The signal
    is analysed and judgements are made using the Arduino UNO. IoT data collection
    in real-time and MCLRN analysis and drought result prediction are two benefits
    of the current DFM. For obtaining and analysing data on agricultural drought,
    the gearbox performance is faultless, and it has strong application value. Absence
    of a long-term analysis based on previously established value and absence of coverage
    based on humidity and rainfall across a vast area were observed. There is lack
    of long-distance data connection methods in remote fields. The absence of dark
    shadow detection in the current technology makes it difficult to detect noisy
    pixels values in unmanned aerial vehicles (UAVs) for flooded regions, which can
    lead to erroneous data. 2.6. Soil testing and measurement (STM) The optical transducer
    is used as a detecting sensor. This sensor (Goswami et al., 2020) comprises of
    three LEDs as a light source and an as “Light detector” (LDR) for assessing the
    results of soil tests performed on four distinct types of soils. Each nutrient''s
    threshold values divide its level into three voltage levels: Low, Mid, and High.
    A technique for monitoring soil health utilising four dynamic parameters was developed.
    In which the (Ramson et al., 2021) effectiveness of a network made up of nine
    soil health monitoring units was tested over the course of several weeks in an
    agricultural field site. Soil sensing, wireless range, power consumption, life
    expectancy, and implementation cost were all evaluated. An IoT-powered soil health
    tracking (Sengupta et al., 2021) approach that can manage agricultural parameters
    has been created. The variations in stimuli, including those related to light,
    heat, sound, motion, magnetic fields, etc., are converted into electrical signals
    by a sensor node and then processed and graphically displayed by the Thingspeak
    cloud server. Using cellphones or personal computers, a methodology is proposed
    for sensing (Saikia and Khatoon, 2022) the percentage of wetness of the soil and
    temperature remotely and continuously. Raspberry Pi-based soil nutrient monitoring
    system for tomato plantations is proposed using various soil sensors (Manickam,
    2020) such as PH and Soil NPK sensors for monitoring the soil continuously. The
    present STM''s strongest point is its use of an IoT-enabled method to assess soil
    health. Thanks to the existing technology that farmers can precisely administer
    fertilisers, insecticides, and water based on the soil''s nutrients, PH, and type,
    crop disease is reduced, and crop yields are increased. There are still lack of
    sensor assessment based on a specified period, in-depth data analysis, additional
    parameters for optimising soil testing in various existing activities etc. There
    is a demand for an affordable, universal solution that can be used to all kinds
    of farms. 2.7. Weather prediction & monitoring (WPM) An agro weather station (AWS)
    that is intended for farmers and researchers is (Faid et al., 2021) develop using
    four layers: perception, transmission, presentation, and administration. For various
    end users, it offers frequently data and AI-based insights. IoT-based intelligent
    energy-efficient approaches have been originated for monitoring and managing greenhouse
    interior temperatures. Many (Subahi and Bouazza, 2020) simulations utilizing a
    greenhouse temperature transfer function are run to show the usefulness of the
    recommended strategy. For temperature and irrigation control a computerized procedure
    is acquired. Using an Android app that connects (Kori et al., 2021) to the controller,
    many agricultural parameters, including as temperature, humidity, soil wetness,
    and rainfall, are tracked and visualised. A strategy to schedule weather forecasts
    was put out in order to foresee (Li et al., 2019) adoption of weather prediction
    information as well as future energy harvesting values based on historical harvesting
    values. A low-cost solar-powered (Devapal, 2020) soil and weather analysis system
    has been offered that looks at different soil properties and weather patterns
    to set up a high-tech smart farm for farmers. IoT, data mining, and android mobile
    applications are all used in the system''s development. Integrating a provincial
    weather station with dual modules to serve as a LoRa-based soil sensor node (Singh
    et al., 2022) for scrutinizing the state of the soil and the weather. During experiment,
    a LoRa portable communication device and an IoT cloud are used to transmit meteorological
    data. Constructed, and tested a flexible (El-magrous et al., 2019) meteorological-soil
    sensor station for acquiring site-specific maps of soil elements, atmospheric
    information, and yield information for the 2018 soybeans season of cultivation.
    Farmers were able to make well-informed decisions on soil selection, irrigation,
    planting, and harvesting thanks to the use of sophisticated tools for weather
    forecasting and data from already-existing systems. The existing weather monitoring
    and forecasting systems have a number of drawbacks, including the absence of AI
    fault detection approaches, a lack of integration with the existing IoT-based
    agriculture system, and a lack of optimize long-range communication technologies.
    There is a need for an intelligent weather system that can identify the soil''s
    nutritional needs and suggest a suitable crop. 2.8. Soil digging (SDG) To enhance
    tillage processes more significant by fusing IoT, “cloud computing”, and “Decision
    support system” (DESS) technologies (Fawzi et al., 2021) the ”Tillage Operations
    Quality Optimization (TOQO)“ model is constructed using two levels: ”Tillage Depth
    1 (TD1)“ and ”Tillage Depth 2 (TD2)“. TD1 = 10–15 cm and TD2 = 25–30 cm. The TOQO
    standard''s tested results improve long-term evolution for the agribusiness by
    maximizing farmer expenditures, accelerating field productivity, and optimizing
    tillage routines. Real-time monitoring of soil-digging machinery, which enables
    farmers to optimise the depth and spacing of rows or holes, is a strength of the
    current system. This accuracy supports resource utilisation that is efficient
    and minimises reductions in waste. Due to the significant differences in soil
    properties, such as moisture content and hardness, the current system needs to
    be improved in terms of performance, affordability, and sensor calibration. Analysis
    to reduce the environmental impact of soil tilling is still lacking in the system.
    More accurate measurements may be possible by the use of the cutting-edge MCLRN
    algorithm. The average growth rate of research publications published between
    2012 and 2023 for PHRS applications that are based on IoT, AI, MCLRN, and other
    techniques is shown in Fig. 4. Download : Download high-res image (193KB) Download
    : Download full-size image Fig. 4. Publication growth rate analysis of PHRS application
    based on IoT and AI, MCLRN and other methodology from 2012 to 2023. The growth
    rate of publication has been assessed based on the quantity of articles published
    in a given year for a specific PHRS application, such as CYP, CSL, SSL, SGM, DFM,
    STM, WPM, and SDG, and the average growth rate analysis has been assessed based
    on the overall quantity of publications for PHRS application year-wise. As observed
    in Fig. 4 graph, a growing number of publications based on IoT, AI, MCLRN, and
    other approaches for PHRS application are made each year, with a high percentage
    of IoT-based PHRS applications. Thus, it can be concluded that the number of PHRS-based
    smart agriculture applications is growing steadily as a result of the convergence
    of IoT, edge, cloud, and AI technologies. 3. During harvesting system (DHRS) After
    preparing the land for the cultivation of crops, there are numerous sub-operations
    engaged during harvesting. The subsystem of the DHRS is shown in Fig. 5. Using
    cutting-edge technologies to automate crop monitoring and irrigation (IoT, MCLRN,
    Data Mining, etc.). It not only emphasises the value of improved production but
    also strongly emphasises data analytics and environmental sustainability. This
    is done to assess the needs and anticipate the compatibility of crops and fertilisers
    in light of the soil and environment. Download : Download high-res image (261KB)
    Download : Download full-size image Fig. 5. DHRS subsystem classification. A wireless
    sensor network is essential for the implementation of smart agriculture (Haseeb
    et al., 2020). There are numerously IoT-enabled prior related work that has been
    done (Ahmed et al., 2018, Anagha et al., 2023, Sah Tyagi et al., 2021) in the
    domain of during the harvesting process. 3.1. Smart irrigation (SIR) Low-cost
    intelligent smart irrigation system using IoT is proposed in three modules. Combined
    (Nawandar and Satpute, 2019) sensor module, irrigation module, and sensor communication
    module. The combined sensor module is used to access crop, plantation, and soil-related
    information. After accessing sensor monitoring data it uses a neural network model
    to make an intelligent decision. These decisions are sent to an irrigation module
    and sensor communication module. The aforementioned data determines whether the
    water machine has to be turned on or off in a certain location. The system keeps
    track of incoming data, and the sensor communication module logs it via the MQTT
    broker. The “AtMega 328” microcontroller and (Saraf and Gawali, 2017) Zigbee communications
    are used to monitor and control sensor data in the existing work. Each field''s
    central node stores sensor data in the cloud database. The report on automatic
    irrigation is delivered to a user via an Android application. An intelligent irrigation
    (Alomar and Alazzam, 2018) system is achieved using IoT and fuzzy logic. As environmental
    variables, air climate and humidity sensors, soil wetness sensors, and light intensity
    sensors are used. By utilizing all the sensor information, a Mamdani fuzzy controller
    controls the flow of water. IoT, a DPLRN, and fuzzy computation are combined to
    form an ecosystem for creating a self-sustaining irrigation system. Soil wetness,
    atmospheric (P. Patel et al., 2022) variables, and the state of crops are all
    input variables in this operational simulation. Leveraging the Raspberry Pi, a
    device called an IoT gateway allows for uploading data to the cloud. To estimate
    if a crop is healthy or slumping, an assortment of DPLRN algorithms are used.
    In order to determine the appropriate time to irrigate the crops, all measured
    input variables are analyzed with a fuzzy logic controller. RFID and sensors to
    establish an efficient farm tracking framework exploiting (Saha et al., 2022)
    “Long range wide area network” (LoRaWAN) protocol with six distinct harvesting
    issues, prohibiting fungal attacks on crops, screening cattle, appropriate watering,
    accurate soil wellness inspection, accurate inspection of crops, and enhancing
    productivity. It maintains appropriate irrigation while conserving water by using
    incredibly effective temperature and humidity sensors. Four distinct categories
    of sensors are used in the soil and crop wellness tracking system to gauge the
    “NDVI” readings of the crops, the “pH” rating of the soil, the percentage of nutrients
    that are contained in the soil, the soil''s compaction, and the amount of water
    in the soil. Cowlar is used by the cattle monitoring system to continuously check
    on the health of the cows. Smart farm decision-making powered by IoT and the cloud
    system that has been designed in order to communicate sensor (Lova Raju and Vijayaraghavan,
    2022) data using “NRF24L01” modules. A suitable irrigation is schedule in which
    the author, without (Sayanthan et al., 2018) the assistance of labour, employed
    an Arduino soil moisture analyzer to measure water requirements at various phases
    of eggplant growth. Using an “Arduino Uno R3” board and an “Arduino DUE”, the
    (Jamroen et al., 2020) intelligent irrigation system is scheduled. For data connectivity,
    the “NRF24L01” module is intended. The current method guards against crop water
    stress situations using a fuzzy inference system. The MCLRN-enabled autonomous
    watering mechanism has been constructed. The raspberry pi and (Vij et al., 2020)
    Arduino mega are two different types of microcontrollers employs in this method.
    The Arduino Mega is equipped with a number of sensors. Arduino Mega sends sensor
    data to Raspberry Pi through the wifi module. Weather data will be retrieved using
    an open-source Application programing interface (API), and a raspberry pi will
    operate to alert a system using weather data and sensor node data. A soil type''s
    propensity for irrigation is predicted using MCLRN. A way to regulating irrigation
    (Mohammed et al., 2023) systems using DPLRN that takes into account the moisture
    and soil structure. In their methodology, soil pictures and moisture sensors are
    used to gather data, which is then processed using real-time videos to determine
    the crop''s need for irrigation and moisture levels. A “VGG-19” model analyses
    the type of image and crop seeded to predict irrigation needs. “TensorFlow” lite
    is used to run experiments on cheap computational hardware and test the proposed
    model on a private dataset. A remote irrigation water pump monitoring, management,
    and (Kirar, 2022) security is developed. The sensors used in this work to detect
    supply voltage and motor current to estimate operating conditions and offer protection.
    The user receives the measured parameters via the SIM900 GSM component regarding
    the intent of remote oversight and management. The Android application was created
    with a better user interface, timer-based functionality, notifications for feedback
    and pump status, among other features. An ATmega 328P microprocessor that is included
    into the Arduino Uno board protects the pump. To track agricultural factors like
    temperature and relative humidity (Hamouda and Elhabil, 2017) a greenhouse smart
    management mechanism is suggested. The watering and cooling of greenhouses are
    managed and controlled automatically by the system. An intelligent system is created
    to track and control several subsystems, including irrigation, (Cecchetti and
    Ruscelli, 2022) lighting, heating, and solar. To enable sensor data to be connected
    to the farm Ethernet network, RS485 bus Ethernet convertor is employed. Automation
    of the heating system, irrigation system, circulation pump, and solenoid valve
    are accomplished using a relay board coupled to a Raspberry Pi 4 microcontroller,
    which is controlled using the HTTP. PHP scripts handle the system''s overall business
    logic. A connected device WSN is created using the “SIXFAB” module (Kiani and
    Seyyedabbasi, 2018) to irrigate crops in agricultural fields, and the Arduino
    component of the module transmits data to a Raspberry Pi-based IoT gateway. One
    of the strengths of the existing SIR system is its use of WSNs and machine learning
    techniques for monitoring and scheduling irrigation of crops for large and small
    farming fields by collecting wet and dry soil data according to the climate and
    soil condition, which ensures crops are irrigated at the right time and irrigation
    systems optimize crop growth. There should be irrigation and crop-specific field
    monitoring, which are weaknesses of the current approaches. The current system
    relies on a single kind of irrigation for a variety of crops. There are lackings
    of self-sustaining system and sensor calibration system. Based on the soil nutrients,
    moisture, temperature, and humidity, more data analysis needs to be done. Heuristic
    techniques for improving irrigation and minimising water use are still lacking.
    To prevent water waste for different crops, the water irrigation system can be
    scheduled or rain harvesting strategies need to be used. Transparency of sensor
    data is lacking. The current process is unable to communicate with another system.
    The system''s performance can be enhanced by using simple cryptographic techniques
    to safeguard data flowing from all the sensors. Communication over long distances
    for data is still unpredictable. 3.2. Soil health monitoring and fertilizer management
    (SHMFM) A methodical approach that accumulates instantaneous data from the farm
    site, such as light strength, wetness of the soil, surface temperature, humidity,
    etc was proposed to provide local access (Bachuwar et al., 2018) to soil temperature,
    humidity, soil wetness, and light intensity, an ESP826612E transmits sensor data
    over a Wi-Fi network using the “IEEE 802.11” protocol. A method to produce data
    sources made up of temperature, humidity, and N, P, and K nutrient content (Rahman
    et al., 2019) that are produced from soil data sensor readings. In order to create
    a soil fertility data warehouse, sensor data is uploaded using IoT technologies.
    By combining Light Dependent Resistor (LDR) and Light Emitting Diodes (LED) in
    a novel NPK sensor (G et al., 2020) an IoT-based system took into account. To
    determine whether N, P, and K deficiencies exist in the soil chosen for testing,
    the Mamdani inference procedure is used. At regular intervals, the farmer is alerted
    to the quantity of fertilizer to be applied. A technique that (Postolache et al.,
    2022) can aid in the evaluation of changes in soil nutrients for more effective
    administration of drainage and fertiliser control. The appliance may gather information
    on the amount of NPK in the soil, further information on soil temperature, conductivity,
    pH, and moisture. A solar fertigation control mechanism for watering using a hybrid
    model and forecasting control (Ahmad et al., 2022) is built on a weather-based
    system accompanied by a crop a repository controlled by real-time sensors that
    keep track of the water condition of the plants as well as the soil moisture and
    water quality. The continuous gauging system for evaluating the water in the soil
    and nutrients for citrus (Zhang et al., 2017) moisture and nutrient status in
    citrus orchards, so that fruit farmers can understand their orchard''s condition
    in time and adjust fertilization and irrigation strategies according to the data.
    To make it simpler for farmers to plant citrus seeds, (Pratama et al., 2021) an
    IoT-enabled gadget that indicates the soil''s nutrients for citrus seedlings using
    a “NPK” indicators and feeds the outcomes to the Thingspeak cloud. A soil wetness
    monitoring system was developed using LoRaWAN detectors with (Hossain et al.,
    2022) blended transmission modules, no in-field root stations or routers, and
    an unmanned aircraft system (UAS)-based mobile router to retrieve the gauges of
    soil wetness taken from buried indicators for a variety of crops. A continuous
    measurement system is proposed for soil nutrition content using an automated fertilizer
    unit for (Visvesvaran et al., 2021) greenhouse systems. The fertilizer system
    automatically provides the plants with the nutrients required once the measurement
    value reduces under the trigger value. The NodeMSU is utilized throughout the
    system for data communication. The performance of the LoRaWAN network beats that
    of the current system for long-distance data transmission, and the “Mamdani inference”
    optimization method based on IoT fuzzy logic yields the best results for measuring
    soil health. From the discussion above, it can be seen that the current system
    has some drawbacks, such as a lack of standardisation due to the fact that different
    soil sensors use different data formats and protocols to collect data. Due to
    the dependence of soil temperature on climate, sensor calibration is still lacking.
    To better manage soil surface and fertilisation, the current system has to be
    optimized. 3.3. Disease detection and analysis (DDAN) For autonomously identifying
    and categorising plant diseases from leaf photos, a DPLRN algorithm is suggested.
    Using the collected images, (Sladojevic et al., 2016) CNNs are trained and validated
    along with fine-tuning. A convolutional neural network model with squeeze net
    architecture is utilised (Hidayatuloh et al., 2018) to distinguish between healthy
    and diseased tomato plant leaves. There are four steps to creating a DPLRN based
    (Andrianto et al., 2020) smartphone application for spotting rice plant diseases.
    These are creating a system architecture for plant disease detection, creating
    a cloud server application and a smartphone application, testing the smartphone
    application, and assessing the system''s performance. The MLP simulation of plant
    diseases, which acquires information as 10 characteristics and 4139 data points,
    was put forward as a real-time (Kumar et al., 2021) detection method. The four
    common forms of disorders are accurately detected by the neural network. An app
    for cellphones that makes use of deep convolutional neural networks to (Pallagani
    et al., 2019) anticipate crop diseases. A total of 38 different diseases have
    been predicted by the app. Farmers everywhere can make use of it even without
    an internet connection. Controlling a pandemic illness with an IoT-based gauge
    is a crucial agricultural (Khattab et al., 2019) application. The system architecture
    can forecast a variety of plant diseases, and the model has been put to the test
    on tomato and potato crops in lab settings. An electronic method designed to communicate
    with mobile phones (Nagasubramanian et al., 2021) to manipulate disease classification,
    environmental objects, and farmer suggestions. MCLRN algorithms, SVMs, and CNNs
    are used to develop the farming suggestion. A leaf detection analysis is put forward
    using (Thorat et al., 2017) an assortment of sensors, such as temperature and
    soil moisture meters, etc. After processing, the leaf image is collected and uploaded
    to the server. The status of the leaf disease is also communicated to the farmer
    via the mobile app. Using “MDFC-ResNet” and DPLRN-based IoT (Hu et al., 2020)
    devices, a crop diagnosis of illnesses IoT system for several crop types is being
    developed. A publicly accessible collection of 54,306 pictures of ailing and healthy
    plant leaves has been assembled (Mohanty et al., 2016) in which a deep CNNs was
    utilised to identify 14 crop types and 26 illnesses from this controlled sample.
    An IoT-based system that uses MCLRN to deliver conveniently (Truong et al., 2017)
    available real-time local environmental data in rural crop fields. With the method,
    it is possible to both identify fungal illnesses and forecast their potential
    spread among crop fields. A “Tiny Machine Learning” (TinyMl)-based technique for
    plant disease identification is designed. Once the model has been trained using
    (Adeola et al., 2022) MCLRN methods, it is transformed into a lightweight model
    with a kilobyte (KB) size that can be placed into devices with external memory.
    Tensorflow lite is used to perform the model conversion with the already installed
    library. The existing method''s strength is its effectiveness in locating the
    illness at the plant''s root system using information on the soil and environment
    of a given region. The performance of the “Tiny Machine Learning” (TinyMl)-based
    technique to identify the kind of sickness was superior to that of existing DPLRN
    systems. For gathering a vast number of statistics on various plants and climatic
    circumstances, the aforementioned existing method still has several shortcomings.
    Lack of ability to detect and control various diseases. To identify plant diseases,
    several existing systems used CNN-based DPLRN algorithms, but the algorithm performance
    still has to be optimized in terms of accuracy, usefulness and real time plant
    disease analysis. 3.4. Pathogens detection (PDT) Biosensors possessed the ability
    to develop into the forefront of diagnostic techniques for various fields of biological
    studies, which comprises immediate assessment of human blood (Sonu and Chaudhary,
    2022) ingredients for both animal and plant infection recognition, environmental
    surveillance, and airborne pathogen identification. As a result variety of techniques
    for detection of (R. Patel et al., 2022) plant pathogens and mechanisms of biosensing
    systems have been examined, whose two main categories of conventional analytical
    methods for the detection of plant diseases are the “Digital droplet polymerase
    chain reaction” and the “Quantum dots-based biosensor”. The exploration of techniques
    for agricultural disease detection is the overall strength of the present work.
    The analysis illustrates the benefits of miniaturized sensors in terms of convenience
    in production; affordability, speed of reaction, and responsiveness, establishing
    those instruments useful for observations in the field. In terms of high levels
    of automation, the work currently being done for pathogen detection still has
    a research gap. It is lacking sensor standardisation. It is necessary to improve
    the methods for detecting various pathogen types, sensor calibration, dataset
    gathering, and technology integration. A cheap sensor needs to be deployed in
    the creation of an affordable, eco-friendly system. Due to the need for further
    optimisation of IoT-enabled systems, there is still a gap in field testing. 3.5.
    Pest controlling (PCN) IoT and CNN-based insect recognition techniques are combined
    in a system. The technology is (Ramalingam et al., 2020) utilized by pest management
    businesses to keep an eye on pests in a variety of settings, including food storage
    areas, hospitals, gardens, etc. Using the IoT for crop monitoring and pest control
    (Tian et al., 2021) an infrastructure for simultaneous and collaborative simulation
    strategy has been provided. Based on the results, the applied simulation with
    IoT assistance system is the most efficient and accurate solution. An artificial
    IoT and DPLRN (Chen et al., 2020) technology can be used to analyze crop growth
    and predict pest occurrences in an environment. A neural network algorithm called
    “You Only Look Once (YOLO)” is used to identify pests in images. A system for
    the detection and control of pests embedded in an embedded environment is proposed
    in which (Vijayalakshmi et al., 2019) if the acceptable limit gets surpassed in
    terms of both temperature and humidity, then the “raspberry pi” captures the image
    of the plant and compares it to the database, and if pests are found, the farmers
    are notified to fertilize. A “Multi-Agent System (MAS)” by deploying a (Debauche
    et al., 2020) Docker environment orchestrated by “Kubernetes” in the Edge AI-IoT
    architecture is constructed. The system utilizes an AI algorithm to identify plant
    diseases and pests and uses an irrigation pivot to treat the crop. The positive
    aspects of MCLRN algorithms like KNN and the (Materne and Inoue, 2018) linear
    regression framework are used to construct a prediction model in a plantation
    to forecast disease and insect outbreaks. The upside of already-existing systems
    is that building a decentralized and accordance simulation structure with the
    IoT for pest control and crop monitoring in combination to increase crop yields,
    lessens the load on one GPU, and contributes to the operation evenly and concurrently
    with all accessible GPUs and perceives data. Based on the usefulness of data,
    the current pest management method still has a gap. For a robotic technique based
    on DPLRN to detect different kinds of insects and rodents, the current solution
    still has to be improved. Due to various data formats and IoT protocols, there
    are still issues when integrating the current system with another system. The
    amount of manual field monitoring by farmers can be decreased, for example, by
    merging deep irrigation systems with current pest management techniques. By including
    preprocessing to normalise the image before the prediction to minimise the effects
    of photo exposure (varying light intensity in outdoor situations), plant disease
    and pest detection can be enhanced. IoT-based security and privacy of sent data
    still require improvement. 3.6. Weed detection (WDT) Robotic weed control that
    uses MCLRN and IoT to detect weeds in onion fields and (Arakeri et al., 2017)
    spray them with the required herbicide. Installing a weed detecting system in
    a chilli (Islam et al., 2021) field using RADF, KNN, and SVM, among other MCLRN
    and image processing algorithms. Systems were built using MATLAB. In order to
    identify weeds in soybean crops (Razfar et al., 2022) a DPLRN based vision-based
    weed identification system is prepared. Three unique CNNs models and MobileNetV2
    are employed in the five-layer DPLRN architecture. In order to increase agricultural
    productivity (Dasgupta et al., 2020) a concept is suggested by utilizing wireless
    sensor networks and AI models for crop forecast and weed identification. In this
    approach, MCLRN is used to create a model after data are collected from sensors
    via WSN. CNN is used in conjunction with this to detect marijuana in drone-taken
    photo. An algorithm is designed based on CNNs to identify and (Jabir and Falih,
    2022) locate weeds in wheat harvests in the region of Beni Mellal-Khenifra, Morocco,
    using an intelligent system. The YOLO model is used to construct a real-time detection
    and identification model on the Raspberry Pi. A network is established for detecting
    weeds (Kulkarni and Angadi, 2019) using a CNN. The CNN is constructed as a pooling
    layer, and the activation function is a “ReLU”. A remote-controlled robot based
    on a Raspberry (Dankhara et al., 2019) Pi is used to detect weed using an image
    processing technique. A model has been formed for precision (Karthikeyan et al.,
    2021) agriculture based on K-means clustering to classify weed plants. A “CNN”
    technique associated with IoT is used for image processing. When compared to another
    neural network technique, the performance of a WSN employing a Raspberry-based
    system with the DPLRN approach is superior. More accurate results were obtained.
    The above-discussed existing work has flaws based on real-time mobile application
    monitoring of weed detection; more parameters can be added to make the DPLRN model
    performance optimised so that real-time weed can be detected accurately; and analysis
    of weed mapping method still has a gap where more research can be carried out.
    Improvements still need to be made to real-time UAV-based technique optimisation.
    The existing system does not incorporate the integration of various environmental
    sensors, actuators, or feedback controllers for monitoring. More research is still
    needed to develop a custom deep learning algorithm that can identify different
    weed types based on plants. 3.7. Crop losses (CLO) To gain an adequate understanding
    of crop health, an apparatus has been (Shafi et al., 2020) put together that combines
    multi-modal data from the IoT nodes and drone photos. The fused data was subjected
    to MCLRN and DPLRN algorithms for crop health classification and creating health
    maps. Data from the sensor nodes is transmitted via a LoRa module. The system
    is intended to design, develop, and test a next generation of automated (Pérez-Ruiz
    et al., 2015) and robotic systems for efficient pest management in agriculture
    and forestry operations using a real-time kinematics (RTK) and “Global positioning
    system” (GPS) controlled autonomous tractor for straight-line tracking. A drone-based
    system is designed in which a “Raspberry Pi” module is integrated (Saha et al.,
    2018) with an array of 64 separate temperature sensors over 12C, an RGB-D camera
    for taking real-time photos, and a GPS navigation module. The cloud server receives
    and stores all sensor data. A system that makes use of multiple sensors to assess
    the temperature, humidity, pH level and scent of the leaves is compared and examined
    (Giri Babu and Anjan Babu, 2020) to check if the gathered leaf values fall within
    the range specified in the actual dataset for tracking crop health. Using IoT
    and remote sensing (Shukla et al., 2021) a method is proposed for agricultural
    health monitoring. To identify healthy crops, IOT-connected UAVs and MCLRN are
    used. Prescription maps are important because they make use of resources like
    pesticides, water, and fertilizers. Farmers are able to decide what resources
    are necessary to ensure that crops are healthy at every stage of growth. An IoT
    platform is constructed that uses image processing and a classifier algorithm
    to detect plant illnesses. If an (Ayalew et al., 2022) automatic medicine system
    identifies ailments, a sprinkler sprays medication. Additionally, disease transmission
    is tracked based on changes in weather using soil humidity and temperature sensors.
    An automated decision-making (Grimblatt et al., 2021) tools and metrics that track
    plant development and health, which have an immediate and measurable effect on
    farmers'' ability to produce crops. Experiments are carried out using two separate
    sensors, soil moisture and temperature, to ascertain the significance of each
    parameter as the foundation for plant growth. An agricultural production system
    simulation is designed (Matsumoto et al., 2017) to carry out intricate business-based
    assessments of the abundance of inventories and crop destruction brought on by
    an absence of knowledge about the quantity of food acquired, the number of unit
    crops, and the enlargement of cultivated fields. IoT-Edge module (Park and Kim,
    2021) collects strawberry hydroponic environment data and strawberry photos, allowing
    for monitoring and determining strawberry harvest time. Utilizing a Wide-area
    inexpensively network (LPWAN) based on the “NB-IoT” (Chang et al., 2018) a smart
    lighting system is developed for greenhouses of expensive crops. Using the temperature,
    humidity, and methane gas sensors MQ4, LDR, and DHT11 (Mahfuz et al., 2020) an
    embedded system is established based on microcontrollers. Its purpose is to keep
    track of the atmosphere all over the greenhouse. In the event that any sensor
    value is outside of its acceptable range, the Arduino will send the user a notification
    SMS using a SIM 900 GSM modem. Through the Android app, a new threshold value
    is also configured. The performance of the smart monitoring of healthy crops is
    outperformed by the IoT that utilises drone and hybrid MCLRN to detect healthy
    crops in the growing environment. The data is transmitted quickly and cheaply
    between the edge and the cloud using an LPWAN based on the “NB-IoT”. It has been
    determined through research of the already-existing system previously described
    that there is still a gap in monitoring and controlling the crop from numerous
    losses. The current system is missing data processing steps and robotic sensors
    with intelligence that can detect different soil parameters, such as soil PH,
    soil water levels, and other characteristics. The ability for mobile-based applications
    to provide the end user with real-time access to farming field information from
    any location still needs refinement. For example, alerts for watering plants,
    temperature control notifications, and disease detection alarms based on the disease
    types and how this disease might be controlled. The examination of extensive data
    based on various crop types is still lacking. Because of climatic circumstances,
    dissimilar data formats, and dissimilar communication protocols, the system is
    not self-sustaining; it is dependent on a certain region and environmental condition.
    It is also unable to integrate with another subsystem. Fig. 6 exhibits the average
    annual growth rate of papers on research produced throughout 2012 and 2023 for
    DHRS implementations based on IoT, AI, MCLRN, and other procedures. Download :
    Download high-res image (191KB) Download : Download full-size image Fig. 6. Publication
    growth rate analysis of DHRS application based on IoT and AI, MCLRN and other
    methodology from 2012 to 2023. According to Fig. 6, the DHRS application research
    publication growth rate analysis has been conducted similarly to that of the PHRS
    application research publication growth rate analysis. The DHRS publishing analysis
    graph shows an increase in the number of research published articles year over
    year. Comparing IoT-based DHRS applications to AI, MCLRN, and other techniques,
    the publishing growth rate was higher between 2019 and 2022. This is because more
    research is being done on SIR, DDAN, and CLO-based applications. In comparison
    to the period from 2012 to 2018, the average annual growth rate of publications
    for SIR-based applications between 2019 and 2022 has been calculated to be 69.23
    %. In contrast, between 2019 and 2022, the average growth rates for CLO and DDAN,
    respectively, were 53.26 % and 63.98 %. It is therefore possible to predict that
    there will be an increase in the number of research publications using IoT and
    AI-based approaches for developing DHRS applications. 4. Post harvesting system
    (POHRS) When preparing the ground for agricultural cultivation, farmers that practice
    traditional farming face a number of challenges. These challenges were brought
    on by the rising demand for agricultural production, and it is not simple to match
    this rising demand for food processing, storage, and supply. The Fig. 7 shows
    the post-harvesting subsystem in which various existing research work has been
    done based on storage, harvesting cycle, supply chain, food processing, etc. (Abouelsaad
    et al., 2022). Download : Download high-res image (213KB) Download : Download
    full-size image Fig. 7. POHRS subsystem classification. The post-harvest physiology
    and management of fruits and vegetables are covered in this area, along with topics
    like harvesting, handling, packaging, storage, hygienic practises, transportation,
    crop waste, etc. In the context of severe weather, it also covered postharvest
    handling. 4.1. Reaping, sorting, cooling, and storage (RSCS) An agricultural robot
    design is incorporated that would use “Autodesk Fusion 360″ (Sazid et al., 2022)
    and ”Webots Simulator“ for reaping, seed sowing, excavating, unmanned ploughing,
    watering, fertilising, and harvesting. “Proteus 8.9” simulates the complete system.
    For data analysis, “MATLAB” is being used. An IoT-based microcontroller farm robot
    automates the system as a whole. An IoT-based low-cost solution is structured
    in which warehouse''s (Banerjee et al., 2020) hazardous gas, CO2, is detected
    using a gas sensor. Tilts or lateral motions of the rack are picked up by shock
    sensors. To safeguard grains from fire, a warning is issued if a fire flame is
    discovered. The Node-Red dashboard allows a user to view the findings of live
    sensor data anywhere, at any time. IoT has been used to monitor and manage food
    grain waste in warehouses. A “DHT11” indicator (Devi et al., 2021) for temperature
    and humidity, a CO2 sensor for air quality, a PIR sensor for moving object detection,
    and other sensors are integrated using “Arduino” to act as a rat and insect repellant.
    A fan is activated to cool the room if the temperature and humidity are above
    and below, respectively, the threshold levels. All sensor node data is accessible
    on the mobile application. Immediate terms surveillance equipment powered by IoT
    that (Siddiqua et al., 2022) can track temperature, humidity, brightness, and
    gas concentration in freezing storage and notify the user of potentially dangerous
    values when the levels surpass the thresholds. The “Arduino UNO” microcontroller
    regulates sensor data and provides it to the ESP32. The MIT App Inventor is used
    on either a computer or an Android phone to monitor the status of the storage
    room. Using a combination of blockchain technology (Sangeetha et al., 2021) a
    system for gauging crop quality and monitoring storage that links farmers with
    distributors directly. Data is gathered in real-time both in the warehouse and
    on the field. All sensor nodes are linked together using Arduino, and information
    is transmitted to the Raspberry Pi-based IoT gateway using Lora communication.
    Farmers and distributors can visualise and analyse data via a web application,
    which is stored in Azure SQL databases. The invention of a stated IoT-enabled
    warehouse management system in which (Anoop et al., 2021) the NodeMSU microcontroller
    is set up to receive temperature and humidity data in this study. A DT method
    is used to examine the temperature swings that took place in Kerala during the
    past five years. To assess and display the warehouse''s climate state, this climate
    data is transmitted to the cloud server Thingspeak. A system based on IoT is established
    for controlling and monitoring food (Hema et al., 2020) instantaneous grain storage
    and procurement. To monitor the overall status under the granary, the system makes
    use of gauges for climate control, moisture, gas, real-time clocks, and burning
    flame gauges. Sensor data is visualized using the thingSpeak cloud platform. An
    MQTT-based application control warehouse system is developed for fruits and vegetables
    storage. Using MQTT and COAP protocol (Deshmukh and Bhalerao, 2017) sensor information
    can be displayed on a web page and accessed via mobile apps. Compared two techniques,
    ”Evaporative Cooling Chambers“ (ECCs) (Verploegen et al., 2018) and ”clay pot
    coolers,“ and proposed employing non-electric cooling and storage devices as a
    potential solution to the post-harvest warehouse issues in rural Mali. An IoT-enabled
    approach is structured that employs sensors to track the condition of agricultural
    fields and warehouses in real-time. The (Nayak et al., 2022) necessary region
    is surrounded by a number of sensors that can identify any impending dangers and
    notify the appropriate people. The infrastructure for safeguarding the harvested
    crops in the warehouse and monitoring the same in real time through an IoT sensor
    network performs better than the performance of the entire existing system for
    developing refrigeration sections through WSN-based clay pots. The system is affordable
    and accessible to all farmers. The aforementioned summary of current research
    has a number of drawbacks based on harvesting, storing, and cooling. There is
    a dearth of smart alert notifications in the storage system. The current storage
    system still lacks real-time monitoring of insects and rodents. There is a need
    for such a sophisticated intelligent-based algorithm that can regulate the warehouse''s
    temperature automatically in accordance with diverse environmental factors and
    locales. For different fruits and vegetables, storage systems should be based
    on weight and long-term storage capability, which is still lacking in the current
    work. On the security and usability of the system at the user end, there is a
    research gap. To boost the performance of the current system, other sensors can
    be added, including RFID, sound sensors, and various gas sensors. 4.2. Crop waste
    management (CWM) A solution to identify (Chihana et al., 2018) warehouse breaches
    and track grains using IoT prototypes is suggested. The usage of cloud storage,
    WSN, and RFID technologies increases accountability and efficiency while reducing
    theft and administrative mistakes. Using an IR sensor, microcontroller, and Wi-Fi
    module a smart garbage management (Jayalakshmi et al., 2017) system built on IOT.
    After garbage levels reach maximum, dustbins are cleaned as soon as possible.
    A framework is formed for smart (Bong Cassendra P. C. et al., 2018) agriculture
    based on a smart waste management perspective. The author discusses the various
    sensor and communication protocols that can be used to track the waste of crops
    in agriculture. The current system''s main strength is its ability to collect
    data instantaneously on the amount and type of agricultural waste. These data
    are examined using cloud computing to determine where crop waste is accumulating
    and to evaluate the risk of fire, illness, and pest infestation. Satellite images
    and ground-based sensors can be used to monitor crop waste degradation. Farmers
    at present have access to information on greenhouse gas emissions and decomposition
    rates. According to a study of previous research, smart agro-waste control research
    is still in its early stages. Low-energy power sensors and sophisticated techniques
    for managing post-harvest waste are not used. Research is still needed for all
    forms of crop loss management. 4.3. Transportation and tracking (TTN) A three-layer
    perishable generate fog computing model is proposed (Musa and Vidyasankar, 2017)
    in which the RFID-embedded sensors that generate sensor readings for the monitoring
    and control layer are among the data producers. A system for the effective distribution
    and transportation of fresh fruit is developed by utilizing the MQ3 sensor. The
    (Elavarasi et al., 2019) system''s result was that it lessened fruit contamination.
    When damaged fruit is discovered, an SMS is delivered to the user''s mobile device,
    and through a remote, the system removes the spoiled fruit using a pick-and-place
    robot. In this article the author go into great (Onwude et al., 2020) detail about
    how cutting food losses during postharvest cold chain activities might enhance
    food security. IoT and blockchain were suggested (Pervez and Haq, 2019) as a means
    of digitally disrupting supply chains and logistics. The supply-chain architecture
    built on a block chain is designed using a direct acyclic graph data structure.
    The IoT-based technologies used in the management of the agricultural supply chain
    in a developing nation like India are discussed. Real-time data sharing (Luthra
    et al., 2018) uses embedded components including actuators, sensors, and network
    connectivity. Digital technologies enable the (Dadi et al., 2021) creation of
    effective agri-food supply networks. “Big data” and IoT are a combination of several
    technologies that the system uses to evaluate enormous amounts of information
    quickly. RFID can sense the food environment. The Blockchain-based supply chain
    management plan (Bhutta and Ahmad, 2021) that places an emphasis on employing
    IoT devices and Blockchain technology to securely identify, trace, and track agricultural
    food during transportation. The methods used to anticipate backorders include
    SVM, KNN, RADF, and AdaBoost. The IoT-based dairy supply chain model is suggested
    and put into practise. In which (Jachimczyk et al., 2021) the related solution
    and the domain-oriented knowledge model are well matched for the integration and
    synergy-enabling processes. RFID is used to capture and share data for production,
    warehousing, sales, supply, and other processes. Advocated in China by integrating
    blockchain and RFID in the (Feng Tian, 2016) supply chain. Information is transferred
    securely and made public via the traceability system by using blockchain. Real-time
    monitoring of the climate, humidity, and geolocation guarantees that harvested
    crops get to their destination in the best feasible conditions, reducing spoiling
    and improving crop quality. Blockchain technology leveraging RFID-based sensor
    nodes optimises supply chains for all crops in real-time. It reduces waste and
    guarantees that crops get there at their intended location in the best feasible
    condition. It has been determined from the discussion of the TTN''s current system
    that the secure supply chain technique has to be updated for all agricultural
    products. Sensor-based technologies, device security and failure, software security,
    and power management all require improvement. The current infrastructure does
    not allow for the dynamic scheduling of transportation based on the agricultural
    products'' shelf lives. There are significant research gaps in the areas of cloud
    platform load balancing, computational cost, and security protocol. Logistical
    processes based on smart contracts can be added to the system to increase its
    efficiency and power. There is still a need for an autonomous system that unifies
    numerous subsystems using IoT with technologies like blockchain and AI. 4.4. Food
    processing (FDP) “Big data” analytics, MCLRN, and the IoT are used to build a
    (Konur et al., 2023) cyber-physical / IoT based food manufacturing system. The
    intelligent production control system offers intelligent decision assistance.
    A tools is structured for tracking and (Jagtap et al., 2021) lowering energy and
    water consumption (FEW), as well as a decision-support system with pertinent hardware
    and software components, utilizing an IoT four-layer architecture. FEW data are
    gathered and used in the food manufacturing sector to examine and improve procedures.
    The food processing system is more effective when IoT, big data analytics, MCLRN,
    and cyber-physical systems are incorporated than when they are automated. Additionally,
    this analysis teaches data professionals new information about how to forecast
    the baking process for achieving product consistency. Productivity may be raised,
    and performance and profitability can be raised by analyzing these data. The current
    research has been examined for individual agricultural goods. For all agricultural
    goods, testing can be done based on the ingredients and food processing. It is
    necessary to integrate seamless IoT devices to improve food processing. The current
    system lacks a strong security system to safeguard system data. Based on IoT,
    AI, MCLRN, and other processes, Fig. 8 presents the average annual growth rate
    estimation of research publication for POHRS application from 2012 to 2023. Download
    : Download high-res image (190KB) Download : Download full-size image Fig. 8.
    Publication growth rate analysis of POHRS application based on IoT and AI, MCLRN
    and other methodology from 2012 to 2023. For the TTN and RSCS system implementations,
    a large number of research articles have been published between 2018 and 2022.
    The average growth rate for the IoT and blockchain-based TTN system has been measured
    as 63.23 % between 2018 and 2021, and the average growth rate has been measured
    for the IoT and AI-based system for storage and cooling at 58.41 % between 2018
    and 2021. However, there has been less growth in research publications on the
    topics of IoT and AI for the other POHRS applications, such as FDP, CWM, sorting,
    and cooling, between 2012 and 2022. Therefore, there is a need for greater study
    in that area. Using IoT, AI, MCLRN, and other methodology categories, the average
    growth rate of research papers for PHRS, DHRS, and POHRS was 41.12 %, 43.23 %,
    and 36.10 %, respectively, till January 2023. 5. Metaheuristic based algorithm
    in smart agriculture application From growing to reaping, an agricultural application
    (Kiani et al., 2022a) uses a meta-heuristic approach. In the first unit, the “Sand
    Cat Swarm Optimization” (SCSO) based algorithm has been created to delegate the
    cultivation work to the appropriate autonomous machines, reducing the labor factor.
    In the second unit, IoT devices keep track of cultivated crops. For crop harvesting
    in the third unit, an improved “ANT colony optimization” (ACO) algorithm has been
    created. A 3D strategy approach has been (Kiani et al., 2022b) employed using
    a couple of Progressive enhancement Grey Wolf Optimisation (I-GWO) and Improved
    Grey Wolf Optimisation (Ex-GWO) for self-sustaining farm operations to search
    for a collision-free feasible route in a sufficient period with minimal expenditure
    in various atmospheric conditions and for multiple barriers. The goal is to tackle
    the NP-hard problem of successful crop harvesting by identifying the finest and
    most suitable paths for UAVs. The results indicate an endeavor to avoid any local
    optima pitfalls and determine the most effective response in an adequate span
    of duration. The fuzzy logic-based “Non-dominated sorting (Fathollahi-Fard et
    al., 2023) genetic algorithm” (NSGEA) model has been developed as a metaheuristic
    optimization strategy where the model incorporates the advantage of multiple factors
    of apprehension such as harvesters'' effectiveness, waves of crops that become
    ripe, parameter weather, as well as adjustments in the value of commodities. The
    framework takes into consideration a wide range of desired results, including
    profitability optimization, preventing waste, and carbon dioxide emissions reduction,
    and it is utilized to calculate the optimum amount of day''s labor for farmers
    and laborers on every block of land. The usefulness of the currently available
    SCSO, ACO, I-GWO, Ex-GWO, and NSGEA metaheuristic algorithms put into effect in
    IoT-based agriculture exceeded other approaches, and the model suggested may be
    used for different applications in a variety of agricultural areas. There are
    still some issues with the optimised performance technique that is currently being
    used to solve NP-hard issues in the field of smart agriculture. Lack of standardisation
    for big croplands utilising IoT and IoT of transportation employing a portable
    robot system to monitor the farming field based on SIR, SCL, CSL, CYP, SGM, SSL,
    STM, SHMFM, DDAN, PDT, WDT, PCN, CLO, TTN, FDP, and RSCS. While supply chain optimizer
    for several harvested crops is currently lacking, the used NSGEA algorithms in
    multiobjective problems can be extended by “Benders decomposition” or “Lagrangian
    relaxation”. 6. Technologies based on the IoT for smart agriculture The development
    of IoT-enabled smart agriculture systems has relied on a variety of technologies
    in the past. It is possible to use this technology wirelessly or wiredly. It is
    conceivable to build an infrastructure for intelligent agriculture at a low cost
    by combining sensors, controllers, and communication technologies. Through the
    synthesis of IoT, artificial intelligence, edge computing, and cloud computing,
    IoT-enabled technologies have made advancements in developing smart agriculture
    systems as well. This section analyses various technologies for developing smart
    agriculture systems in the different major areas of farming operations on the
    basis of discussion in 2 Pre-harvesting system (PHRS), 3 During harvesting system
    (DHRS), 4 Post harvesting system (POHRS), 5 Metaheuristic based algorithm in smart
    agriculture application. The estimation average rate of several technologies utilised
    to create smart PHRS, DHRS, and POHRS system is depicted in Fig. 9 of the graph.
    According to the existing survey (Kalyani and Collier, 2021) and proposed survey
    report, this is the estimated percentage of technologies used in smart agriculture
    methods. Download : Download high-res image (215KB) Download : Download full-size
    image Fig. 9. Growth rate of various technologies used in PHRS, DHRS, POHRS subsystem
    between 2012 and 2022. According to an average percentage analysis of various
    technologies conducted between 2012 and 2022, the use of IoT and other technologies
    for the development of smart agriculture would increase by 2028 (Research and
    Markets, 2023). Table 1 presents cutting-edge technologies, sensor or devices
    that can be applied to build smart agriculture using IoT architecture (Chamara
    et al., 2022) based on PHRS, DHRS, and POHRS. From Table 1 it can be seen that
    the use of IoT has advanced the field of smart agriculture from 2012 to 2023.
    The advancement has been done by deploying various IoT devices / sensors (Pyingkodi
    et al., 2022), wireless communication protocols (Khanh et al., 2022), and UAVs
    using micro-electromechanical system (MEMS) technologies to automate the farming
    field operations (Boursianis et al., 2022). It is possible to communicate from
    machine to machine using a variety of communication standards (Orfanos et al.,
    2023). Table 1. Analysis of Technologies used in the smart agriculture between
    2012 and –2022. References and year Application layer Processing layer Network
    layer Perception layer PHRS DHRS POHRS Technologies Software / programming’s /
    tools Connectivity / Protocols Sensors / Devices (Jayaram and Marad, 2012) ✓ x
    x Fuzzy Inference Systems, MCLRN MATLAB LAN Intel GPU (Balezentiene et al., 2013)
    ✓ x x Multimoora Fuzzy, MCLRN MATLAB LAN, Ethernet Shield, Intel GPU (Ping, 2014)
    ✓ ✓ x Machine Learning, IoT Network testing tool Ethernet, HTTP, TCP, WSN Arduino
    Uno, Infrared detector 512X10, Motor, DHT11/22, Water Level Sensor (Fan et al.,
    2015, Pérez-Ruiz et al., 2015) ✓ ✓ x Machine learning, IoT, Big data Python, C++
    HTTP, TCP, GPRS WIFI Internet, 3G AtMega 32, AVR Microcontroller, GSM module,
    Motor, DHT11/22, Water Level Sensor, GPS, Soil sensor, Light sensor (Feng Tian,
    2016, Sladojevic et al., 2016) ✓ ✓ ✓ MCLRN, IoT, Deep Learning CNN, Blockchain
    TensorFlow, Ethereum WIFI router, HTTP, TCP DHT11, Camera, RFID, GPS (Deshmukh
    and Bhalerao, 2017, Musa and Vidyasankar, 2017, Thorat et al., 2017) ✓ ✓ ✓ MCLRN,
    IoT, Deep Learning CNN, Image processing, Fog computing Android OS, OrCAD, MikroC
    PRO, Visual Basics 6.0, Matlab, Apache server, MySQL, Wireshark WIFI router, USB
    Wifi dongle, HTTP, TCP, SMTP, MQTT, CoAP, IEEE 802.15.1, Bluetooth Communication,
    LoRaWAN Arduino uno, ARM7 LPC2138, Raspberry Pi, DHT11, Camera, RFID, GPS, HC-05
    Bluetooth, Solenoid Valve (Ahmed et al., 2018, Indira et al., 2018, Luthra et
    al., 2018) ✓ ✓ ✓ MCLRN, IoT, Cloud Computing, Data Mining, Fog computing, CNN
    ContikiMAC, Cooja simulator, Python, C++ MQTT, MAC protocol (IEEE 802.11), IEEE
    802.15.4, WIFI Internet, LoRaWAN, 6LoWPAN, SIXFAB module Arduino uno, Raspberry
    Pi,, Radio antenna transmitter, Pressure sensor, RFID (Elavarasi et al., 2019,
    Islam et al., 2019, Khattab et al., 2019) ✓ ✓ ✓ Big Data, IoT, MCLRN ThingSpeak,
    Python, R GSM communication, WIFI, ZigBee, WSN, TCP Arduino uno, Raspberry Pi,
    Arduino Mega, SIM900 GSM Module, Light sensor, PH sensor, Water pump, Camera,
    soil sensor, Solar panel (6v, 9 W), MQ3 sensor (Bhojwani et al., 2020, Chen et
    al., 2020, Hema et al., 2020, Jamroen et al., 2020) ✓ ✓ ✓ Supervised and unsupervised
    MCLRN, Fuzzy logic, YOLOv3 CNN TensorFlow, ThingSpeak, Python, MATLAB TCP, MQTT,
    IEEE 802.15.4, IEEE 802.15.1, Wireless Star Topology, LPWAN, SMTP Arduino Uno,
    Raspberry Pi, ESP8266, NRF24Lo1 Module, SX1276 Lora, NPK sensor, BMP180, MQ135,
    Soil Moisture, Camera, GY-30 (Bhutta and Ahmad, 2021, Ramson et al., 2021) ✓ ✓
    ✓ MCLRN, CNN, IoT, Particle Swarm Optimization, MLP, Blockchain, Edge computing
    ThingsSpeak, iOS and Android based OS, MATLAB, WAFW00F LoRa, WSN, LoRaWAN, NB-IoT
    Arduino Uno, Raspberry Pi, GPS, SHMU unit, DHT11/22, RFID, Co2 sensor (Andreadis
    et al., 2022, Kasera et al., 2022, Kiani et al., 2022b) ✓ ✓ ✓ MCLRN, Metaheuristic
    optimization (Genetic algorithm, ACO, Benders decomposition) Deep learning, Blockchain,
    GIS, Edge computing SSL, Ettercap, IP scanner, ThingsSpeak, Blynk, Adafruit, AWS,
    Ethereum, TensorFlow, Python, MATLAB MQTT, HTTP, TCP, COAP, IEEE 802.15.1, IEEE
    802.15.4, GSM network, WSN, 6LOWPAN, 4G, 5G Arduino Uno, Raspberry Pi, LORA SX1276x,
    NRF24L01, GSM module, ZigBee, Moisture sensor, Pi camera, Pi camera, DHT11, RFID
    The graph in Fig. 10 represent how much data is consumed in GBPS by PHRS, DHRS,
    and POHRS subsystems. This data bandwidth estimate is evaluated and (Annual Internet,
    2023; Virtual Cisco, 2017) measured using prior research. This information is
    obtained through a variety of IoT sensors and actuators, including cameras, DHT
    temperature and humidity sensors, air pressure sensors, rain sensors, distance
    sensors, water flow metres, and others. These sensors and actuators are utilised
    to create smart PHRS, DHRS, and POHRS subsystems. Information for real-time crop
    management is updated often, like every minute or hour. In the upcoming years,
    it is anticipated that the average data bandwidth for IoT-based PHRS, DHRS, and
    POHRS subsystems would keep expanding. The rapid development of sensors and actuators,
    as well as the rising demand for real-time crop management data, are to blame
    for this. As technology has developed, the maximum data bandwidth for IoT-based
    smart agriculture systems has increased year over year. The available data bandwidth
    for various IoT based PHRS, DHRS and POHRS applications from 2012 to 2022 is shown
    in the graph Fig. 10. Download : Download high-res image (152KB) Download : Download
    full-size image Fig. 10. Data consumption analysis (GB) used by IoT devices year
    wise for various IoT based subsystems in smart agriculture. IoT technologies were
    still in their infancy between 2012 and 2014, and data storage capacity for applications
    in the IoT remained quite constrained. Data rates ranging from a few kilobyte
    per second (Kbps) to a few megabyte per second (Mbps) were accessible via wireless
    technologies including 2G and 3G cellular networks, which were widely used. The
    data bandwidth for IoT applications has increased dramatically between 2015 and
    2018 thanks to 4G LTE cellular networks technologies. Higher data speeds were
    offered by 4G networks, which typically oscillated between tens of Mbps to hundreds
    of Mbps. This made it possible to collect and analyse more data thoroughly while
    also enabling the transfer of data more quickly. Improvements to 4G networks and
    the rollout of 5G networks, which promise even more data bandwidth and lower latency,
    started in 2019 to 2021. Data rates of up to several gigabits per second (Gbps)
    are available with 5G technology. Even while 5G was not yet widely available,
    its promise for fast data transfer was becoming more and more clear. The global
    rollout of 5G networks, which are currently in development, will continue in 2022
    and 2023. This will result in enhanced data bandwidth for IoT-based smart agriculture
    applications. Although the actual data rates that can be achieved in real-world
    settings depend on network coverage and infrastructure, the data bandwidth needed
    for IoT-based smart PHRS, DHRS, and POHRS subsystems might vary depending on the
    implementation and the amount of data being communicated. The overall bandwidth
    needs will be influenced by elements including the volume of data gathering, the
    number of sensors placed, and the complexity of the data being conveyed. Communication
    involves a number of factors, such as the data rate, the frequency bands, the
    range, the application, and the cost. A systematic analysis of these factors has
    been conducted in Table 2 to determine which communication standards are to be
    used in PHRS, DHRS, and POHRS subsystem. As from Table 1 and Table 2, some IoT-based
    communication technologies can also be considered in the 5G/5G beyond smart agriculture
    system. Table 2. Comparative analysis of various communication technologies used
    in smart agriculture. Communication Technologies Frequency Bands Data Rate Range
    (m) Application (PHRS/ DHRS / POHRS) Cost Pros Cons ZigBee (short range) 868 MHz
    – 2.4 GHz 250 kbps 75–100 CSL, STM, SIR, SHMFM, DDAN, WDT, CLO, RSCS, TTN, WPM
    Low Trustworthy and self-repairing. Limited coverage range and low transmission
    rate Wi-Fi 2.4 – 5 GHz 600 Mbps 70 – 250 CSL, DFM, SIR, STM, TTN, SSL, SGM, WPM,
    CYP, CWM, SHMFM, SDG, DDAN, PDT, PCN, WDT, CLO, RSCS, CWM, FDP Medium Accessible
    and versatile Electromagnetic (radio) interference can cause installation and
    security issues. BLE 2400 MHz 1 Mbps 100 CSL, SIR, STM, TTN, SSL, SGM, WPM, CYP,
    CWM, SMT Low As far as interoperability is concerned, Bluetooth does not face
    any problems Several security concerns, hackable LoRa I69 MHz, 433 MHz (Asia),
    868 MHz (Europe) and 915 MHz (North America) 0.3 – 50 kbps 20,000 CSL, DFM, SIR,
    STM, TTN, WPM, SHMFM, DDAN, PCN, WDT, CLO, RSCS Low By adjusting output data rates/RF
    output, battery life can be maximized. The data rate is low, and packets are occasionally
    not recognized. SIGFOX 862 – 968 MHz 100––600 bps 15,000 CYP, CSL, SGM, STM, SDG,
    SIR, SHMFM, PDT, WDT, RSCS, CWM, TTN Low A narrowband wireless system can accommodate
    several channels in the same space compared to a wideband wireless system. Strong
    interferences are occurred to surrounding wideband systems by the narrow band
    spectrum that Sigfox end devices emit, hence the presence of more Sigfox devices
    will amplify these interferences. LTE-M Cellular 1–14 Mbps for 3GPP 11,000 CYP,
    CSL, STM, SIR, SHMFM, DFM, WPM, DDAN, PDT, CLO, RSCS, CWM, TTN Low Utilizing TCP/IP
    to connect to any server. High data rate Unsuitable for high-speed data transport.
    NB-IoT 450 – 3500 MHz 250 kbps 5000–––15000 TTN, SMT, SIR, WPM, SHMFM, SGM, CSL
    Low There is an encryption feature as well as SIM-based authentication Neither
    VoLTE nor Voice Over LTE is supported 7. Dataset collection Various datasets is
    collected based on PHRS, DHRS, and POHRS. This dataset can be used to solve a
    problem in CYP, SSL, SIR, DDAN, PCN, WDT, and CWM operations. Existing public
    dataset has been reviewed for several farming operations (Lu and Young, 2020)
    including SSL, DDAN, WDT, CWM, etc., and classified this dataset based on the
    specific problem that can be solved using the IoT based computer vision algorithm
    for PHRS, DHRS, and POHRS subsystems. Including some existing external datasets
    created by various authors can be found in Table 3. This collection includes many
    plant-leaf diseases that affect fruits, vegetables, and seeds. For instance, tomatoes,
    brinjal, potatoes, guava, wheat, cotton, apples, oranges, and so forth. Table
    3. Analysis of dataset that can be used for developing smart agriculture based
    subsystem. References Details (Rauf and Lali, 2021) This dataset of healthy and
    unhealthy guava fruits and leaves can be used to solve plant disease-related issues
    using computer vision techniques. The illness categories in this image dataset
    are Dot, Canker, Mummification, and Rust. Pakistan is the source of the images.
    (Yogesh Suryawanshi et al., 2022) An image collection consists of four vegetables:
    “Bell Pepper”, “Tomato”, “Chili Pepper”, and “New Mexico Chile”. The five distinct
    substructure classes in each vegetable collection are Ripe, Old, Dried, and Wounded.
    (Natnael Tilahun, 2022) This image collection was gathered from a potato farm
    in Holeta, Ethiopia to help in the detection of potato leaf disease. The aforementioned
    collection comprises two distinct varieties of photos. Both “Healthy” and “Late
    Blight” have 363 and 63 images, respectively. The potato disease issue can be
    resolved with this dataset. 8. Comprehensive shortcomings of PHRS, DHRS, and POHRS
    As discussed above in 2 Pre-harvesting system (PHRS), 3 During harvesting system
    (DHRS), 4 Post harvesting system (POHRS), 5 Metaheuristic based algorithm in smart
    agriculture application, some shortcomings have been addressed from the existing
    work on IoT-enabled smart agriculture systems. Individually, these gaps are identified
    according to the various farming activities. The gaps that are noticeable for
    PHRS, DHRS, and POHRS are discussed in the Table 4 from which it can be analysed
    that smart agriculture is a broad research area and the developed existing IoT-enabled
    system still has shortcomings in terms of standard protocols, inconsistencies
    in collected data, and inconsistencies of IoT devices (such as there are multiple
    temperature sensors but their data formats are different and also it is difficult
    to interface that sensor with multiple subsystem microcontroller because of the
    varying platform), difficult to integrate existing system to multiple regions
    because of the environmental factor, cost, lack of technologies enhancement of
    the system and endorsement with real-time information with external source information.
    As from sections, 2, 3, 4 and 5 it can be extrapolated that more examination needs
    to be performed to accomplish IoT-based solutions for the SSL, SGM, SDG, PDT,
    affected crop sorting, CWM, and FDP. Research can be conducted on different crop
    types location-wise. IoT data security is a significant uncertainty, so there
    is a need for scalable WSN or robust mechanisms to protect data. Table 4. In depth
    shortcomings analysis of the existing smart agriculture system based on PHRS,
    DHRS and POHRS. PHRS Problems Focused Description Inconsistency with Standards
    Security protocols, device compatibility, and firmware still need to be standardized
    for IoT-based CSL, YPR, STM, SSL, SGM, DFM, WPM, and SDG systems. Compared to
    other methods and outcomes, the existing systems are difficult to compare. Standardized
    procedures and frameworks are necessary for assessing and comparing different
    methods. Limited Data analysis IoT is dependent on the volume of data. Most of
    the time that information is not easily accessible because of non-availability
    of open source data. More trustworthy sensor data and adequate data-gathering
    techniques are required because still depended on external source data. Data should
    be location-wise, all types of data, and should be validated with real-time and
    existing data. There is need for advanced data analytics techniques to make sense
    of these vast generated data. Inadequate scalability For IoT-based CSL, YPR, STM,
    DFM, and WPM applications, there are many active research projects; nevertheless,
    there is still work to be done to scale this system for commercial applications.
    SGM, SSL and SD-based IoT-based systems require more research. This system are
    not fully automated. Inadequate knowledge Performing experiments on the crop relies
    on understanding of the crop physiology as well as a range of environmental factors,
    which is yet not fully understood. More study is needed on the physiological processes
    of various crops, as well as the effects of environmental conditions on crop growth
    and development. Inability to integrate with current agricultural systems To make
    the fully IoT-based pre-harvesting method more effective, the system can be incorporated
    with the existing agricultural systems such as smart crop recommendation system
    based on weather, location, seed selection and soil nutrients analysis, smart
    soil digging, etc. There is a lack of research in this area of integration. The
    study has to be performed to discover the potential benefits and drawbacks of
    the integration. Limited Accuracy Currently, most IoT devices lead to erroneous
    and inconsistent data, as they have limitations in terms of accuracy, reliability,
    and precision. In addition, sensor calibration is also important despite being
    complex and time-consuming and can result in inconsistent results if not done.
    Also, these devices have to place optimally to ensure correct data collection,
    which can be further used for analysis. The study has to be performed to make
    a system accurate and reliable. Cost Effective IoT-based systems can be expensive
    to install and maintain and thus can be a barrier while adopting the technique,
    especially for small-scale farmers. Although the cost of devices has decreased
    in recent years, the overall integration can still lead to a higher cost. Research
    has to be focused to investigate cost-effective solutions. Use of MCLRN approaches
    The present work has used MCLRN techniques in IoT-based systems, however due to
    the overfitting issue, the trained MCLRN model still cannot make an accurate forecast.
    DHRS Multi-technology incorporating IoT makes it possible for the system to apply
    a variety of technologies during the harvesting process. These technologies can
    be combined to create a system, but research is needed to determine the best way
    to do so. According to the study of the current work, several systems have not
    been fully incorporated. Such as SIR with SHMFM, PCN, PDT, WDT, CLO etc. System
    for Enhancing Irrigation Research must be conducted to point out the efficient
    way to irrigate the plants as compared to the traditional methods of irrigation.
    Such as irrigation system should be managed automatically on behalf of different
    of types crops. Acquiring and adopting users Existing IoT-based DHRS systems are
    still mishandled and challenging to adopt in various environments. Research must
    be performed to make a system that can be easily handled and adopted by end users
    in different environments. Soil health The DHRS process includes IoT enabled system
    for crop monitoring and SHMFM. Research must be performed to examine how SIR affects
    soil systems, microbial residents, and nutrient process for various crops. Environment''s
    impact Still, research is to be investigated based on environmental factors such
    as calibration of temperature, humidity, and rainfall during SHMFM and DDAN. Privacy
    and Security As far as the security of IoT-based DHR systems is concerned, very
    little research has been conducted. Detecting the diseases accurately Although
    IoT-based systems can provide real-time plant health data, there are still limitations
    to how precise the data is. Various factors affect accuracy and research must
    be done to monitor those factors, which can impact accuracy. Efficient Energy
    Continuous data collection is difficult in remote regions. A cost-effective, self-sustaining,
    and optimised technique should be implemented in the current IoT-based systems
    for PDT, DDAN, SHMFM, and WDT so that field monitoring data can be gathered continually.
    Analysing pest behaviour The system to detect pests accurately still needs improvement.
    As various pests respond differently in different environments. Optimization of
    Object Detection algorithms Need more research in the areas of IoT-enabled systems
    for WDT, PDT, CLO, and PCN to provide optimized solutions for accurate results.
    So system performance can be increased. POHRS Security and Privacy While most
    harvesting data must be stored properly and securely. Various IoT-based systems
    can be implemented to monitor and store the data. In this era of cyber threats,
    the system must be made in such a way to make the data properly stored, thus making
    it secure. Innovative solutions with a low cost Developing IoT enables cost-effective
    solutions in post-harvest activities is challenging based on security and privacy.
    As in POHRS, there are still some shortcomings in the existing system, which needed
    to be addressed. Such as in RSCS, SWM, and TTN there is still lacking data security,
    data storage, and low-cost automated system of fruits and vegetables monitoring.
    Research must be done to deeply understand such a situation and make a cost-efficient
    system so that it can be used by small-scale farmers also. Miniature studies In
    POHRS most of the ongoing work is focused on TTN, RSCS, and CWM but missing this
    existing system on a large scale for post-harvest phases. In the current automated
    RSCS system, the sorting technique management can be improved by including scheduling
    and weightage systems for post-harvest storage of crops during the TTN process,
    because Indian farmers have fewer low-cost smart facilities. Research can be done
    to investigate the effectiveness of the IoT system on a large scale as well. Incorporating
    multiple methods IoT system integrates different components which are somehow
    correlated to each other. Research should be carried out to determine how those
    components must be integrated as a distributed system that develops a self-sustainable
    and cost-efficient system. Availability and Reliability The IoT-based system should
    be readily available for the end users. Research should be done regarding the
    improvements in the availability of the data during TTN as well as while RSCS,
    utilizing real-time monitoring. 9. Proposed architecture for smart agriculture
    From PHRS to POHRS, a number of existing smart methodologies have been established
    for all different types of farming tasks, and they are all covered above along
    with their benefits as well as their drawbacks. By using the proposed architecture
    the limitations of the present structures can be reduced in light of the discussion
    above. A compact sensor network is made possible. Thanks to the integration of
    IoT, MCLRN, metaheuristic optimisation algorithm, AI, edge computing, cloud computing,
    SDN, cryptography for data security, UAVs, etc. Using 5G (gNB architecture) and
    5G beyond networks (Abdulghaffar et al., 2021), the recommended IoT-facilitated
    smart farming architecture is designed on the basis of IoT layered architecture
    in the Fig. 11. The sensor layer consists of different types of sensors, and data
    transmitters (“sx1276”, “nrf24l01”, etc.), cameras, high-frequency navigation
    (GPS), etc. It acts to collect and transmit facts it to the central server utilizing
    a 5G network connectivity via an edge gateway for data processing and analytics.
    The central server gives the farmers useful information using miscellaneous algorithms
    and standard procedures. These details may be on the choice of crop, seed germination,
    irrigation, soil analysis, and status, livestock status, crop diseases detection,
    crop sorting and storage, tracking, etc. The collected data are about the PHRS
    subsystem, DHRS subsystem, and POHRS subsystem. These subsystems are interconnected
    to each other to make the overall agriculture system automated. So that farmers
    can optimize their farming procedures and enhance crop yields. Under this system,
    the automated actuators can be used to enable farmers to remotely control some
    of the devices such as irrigation motors, pest control, soil digging, etc. Layer
    by layer, smart agriculture can be developed as follows: Download : Download high-res
    image (896KB) Download : Download full-size image Fig. 11. Proposed 5G based Smart
    Agriculture Framework. 9.1. Perception layer In this layer, multiple sensor networks
    can be created by deploying various sensor nodes for the PHRS subsystem, DHRS
    subsystem, and POHRS subsystem. This subsystem is communicated to each other as
    machine-to-machine communication (Sakthivel and Vidhya, 2021) and connected to
    an each 5GIoT base edge gateway. The PHRS subsystem retrieves the data of various
    environmental factors, including water in the soil, fertiliser, temperature, and
    humidity, sunlight, flood and drought-related, etc, and transmits this data to
    the local IoT edge gateway for further computation and analysis. The DHRS subsystem
    consists of the sensor data of irrigation, NPK, pest controlling, weed detection,
    disease prediction, livestock, insects sound, crop field, etc. This data is also
    transmitted to a local IoT edge gateway and the same as POHRS sensor network data
    will be collected and transmitted to its IoT local edge gateway for further computing
    and analysis. This all subsystems are the backbone of the IoT sensor network.
    9.2. Network layer The entire IoT AGRI subsystem is designed based on the 5G network,
    but it can enable 5G beyond the network as needed. Essentially, a 5G core network
    is a high-level network that is made up of a radio access network and one or more
    edge networks. The 5G base stations are connected to open flow switches which
    are known as gNB switches (edge network). For traffic offloading and “quality
    of service (QoS)” implementation, SDN controllers can interface with base stations
    using the open flow protocol. The “protocol data unit (PDU) session” or “user
    plane function (UPF)” is used in the core network to connect the data network
    (DN). The SDN controller controls all gNB, UPF, and data plane switches. This
    layer is responsible for all transmissions and communications between sensors,
    IoT gateways, and cloud servers. 9.3. Cloud layer The network layer''s via SDN
    controller would transport the sensor data acquired from the perception layer
    to the cloud layer platform, where analytics would be carried out utilising tools
    like AI, MCLRN, Weka, and Hadoop, among others. Cloud platforms include “AWS”,
    “Azure”, “IBM Cloud”, etc. To handle and analyse the data gathered from the sensors,
    this cloud service offers storage and computational capabilities. The designed
    API gateway is used to manage communication between the edge gateway and the cloud
    server while utilising all authentication services. 9.4. Application layer The
    insights produced by the cloud server will be available to the end user through
    mobile applications, web applications, etc., including farmers, stack holders,
    suppliers, ranchers, purchasers, etc. So that farmers may make informed judgements,
    this programme gives them real-time information regarding the PHRS, DHRS, and
    POHRS. 9.5. Data storage and processing layer Depending on the particular applications
    and the volume of data collected, the data storage needs for IoT-based PHRS, DHRS,
    and POHRS subsystems can change. Numerous services, including data source, data
    processing, decision support, transmission system, authorization, storage space,
    and reliability, are offered in the data storage and processing layer. The digital
    footprint of the data collection and storing for the IoT-based PHRS, DHRS, and
    POHRS subsystems in smart agriculture is shown in Fig. 12. Download : Download
    high-res image (611KB) Download : Download full-size image Fig. 12. Data processing
    and storage footprint. Data gathering: Obtaining information from numerous agricultural
    fields (F) using a variety of sensors, including those that measure things like
    temperature, humidity, soil moisture, soil ph, soil NPK, air pressure, RFID, rodents,
    insects, and other animals, as well as things like plant color recognition, rainfall,
    disease detection, and recognization through cameras, storage and cooling control
    of harvested vegetables or fruits, transportation and tracking, water flow measurement,
    level, and pump control. This sensor and actuator data is sent to the server for
    analysis and decision-making for the farm fields, or real-time monitoring. Depending
    on the sensor type and frequency, a single sensor node may generate data on average
    in the range of KB to a megabyte (MB) each day. The expected data storage, for
    instance, can range from GB to terabytes (TB) per year if there is a vast farming
    area with numerous sensors. In addition, image and video data are gathered from
    drones to monitor crop health, pest detection, weed detection, and crop yield.
    This data contains high-definition images of farms in 5 to 100 MB sizes. It is
    possible to estimate total storage capacity by estimating the frequency of capturing
    such imaginary data. The sensor data for CYP, CSL, SGM, STM, SDG, SIR, RSCS, CWM,
    DDAN, PDT, CLO, WDT, SHMFM TTN, and FDP systems as well as scheduling irrigation,
    measuring insect control effectiveness, managing livestock, keeping track of crop
    yields, and managing agribusiness depend on the overall dimension of the farm,
    the variety of crops grown there, and the amount of detail that can be gathered.
    For each crop every year, this data size can be in the KB to MB range. However,
    WPM generates climate-related data that can be recorded for historical research
    and transmitted in KB each hour or day. Data pre-processing: In the pre-processing,
    the gathered data are prepared for further analysis. Which is used to fill in
    the missing data, remove the redundant data, format the data into its size, type,
    and classes, and normalize the data to make data more reliable and knowledgeable.
    Data repository: The local storage server, which may be a NoSql, time-series,
    or relational database, stores all pre-process data. It is quite difficult to
    make the data more trustworthy and long-lasting because the database storage can
    come from a variety of sources of different types and sizes. The data is cleaned
    using a variety of pre-processing techniques throughout the pre-process. There
    are different, specialised cleaning techniques for text and picture data, such
    as stemming and lemmatization, as well as image geometric conversions, image filtering,
    segmentation, Fourier transform, and image restoration, among others. Data from
    both the past and the present is kept in the storage repository. In the edge computing
    layer, data transmission management is carried out between this data processing
    layer. The interval between acquisition and utilisation might vary extensively,
    ranging from a couple of seconds, minutes, or hours to a few weeks, or possibly
    a full year in extreme circumstances. Therefore, several transmission techniques
    can be used for quick and secure long-distance transmission via wired or wireless
    means. High-speed data connection, such as a 5G communication network, is also
    necessary. Various data flow control techniques, including stop and wait, feedback
    control, sliding windows, two-directional communications, etc., will be used to
    manage the data communication traffic between these two communications. Throughout
    all of these steps, data analyses are carried out utilising different MCLRN and
    AI algorithms to send actions and notifications to the user''s cloud server. A
    suggested approach for smart farming system data footprint is developed based
    on smart PHRS, DHRS, and POHRS existing work deficiencies using a 5G data communication
    network. For the storage of this PHRS, DHRS, and POHRS application, the maximum
    average data volume analysis is shown as a graph in Fig. 13. The regular data
    volume analysis is estimated in Fig. 13 as a graph based on the communication
    technologies range, periodicity of the sensor devices, camera resolution, data
    bandwidth, etc. Using different types of agricultural activity properties, this
    average data volume utilisation analysis over the past 30 days has been calculated.
    The analysis of the 30-day total average data volume was calculated at 1.38856
    GB. Depending on the particular PHRS, DHRS, and POHRS application, the data transfer
    frequency changes. Download : Download high-res image (156KB) Download : Download
    full-size image Fig. 13. Estimated digital footprint for one month of proposed
    PHRS,DHRS and POHRS Systems. For instance, a system used to track soil temperature
    and nutrient content might release information once each hour or day. Meanwhile,
    a different system will deliver data every minute for crop growth assessment.
    As more smart sensors are deployed and technology is developed, the amount of
    data conveyed for different crops in soil and crop growth monitoring will expand
    in the future. Aspects that can increase the volume of data include the number
    of sensors used, the type of data (image, text, or numerical), frequency, distance,
    time, cost of data transmission, size of the farmed area, crop type, climate,
    irrigation method, soil type, disease type, etc. 10. Comparative analysis of existing
    smart agriculture system with proposed 5G based architecture For the recommendation
    of a 5G-based smart agriculture framework, some of the existing available research
    surveys have already (Liu et al., 2023) been carried out, in which the major technologies
    and technological barriers preventing the advancement and development of smart
    agriculture applications leveraging 5G technologies are described. The resultant
    effect of 5G on the IoT for smart agriculture is outlined. An exploration of precision
    agricultural (Majumdar et al., 2023) applications has been explored using green
    IoT-based solutions, utilizing UAVs, LPWANs, and 5G networks as well as an assortment
    of technical issues. Utilizing 5G networks and beyond, the long-lasting expansion
    of digital farming through the incorporation of green IoT technology enables the
    IoT greener. The proposed architecture above has been recommended by incorporating
    each multiple-edge gateway grid with the central controller for all small and
    large farming area data based on the existing 5G-based smart agriculture architecture.
    The advantages of using this agriculture system over existing IoT-based agriculture
    systems include the immediately apparent advancement across multiple agriculture
    applications, centralised archives of data, estimation process power, etc. Existing
    smart agriculture exhibits challenging obstacles and demands to handle high volume
    data storing processes, computation power, and managing various agriculture applications
    of small and large farming areas. Therefore, in this instance, data computation,
    interpreting, and other capabilities can be offered close to the network''s edge,
    where initially the data are originated. Edge computing power has benefits such
    as decreased latency, bandwidth savings, reduced downtime, increased trustworthiness,
    improved privacy and security, etc. The proposed IoT-based architecture allows
    for the best provisioning of resources using SDN, network segmentation, route
    optimisation, load balancing, and other practises. A evaluation of current smart
    farm systems with the proposed IoT architecture is shown in Table 5 below based
    on the various parameter. Some of the characteristics are identical in the proposed
    5G-based smart agriculture architecture and the existing smart agriculture architecture.
    The comparison has been verified based on this characteristic. Table 5. Advantages
    of the proposed 5G based smart agriculture system with existing smart agriculture
    system. Comparative parameter (Udutalapally et al., 2021) (Liu et al., 2023) Proposed
    5G based IoT agriculture architecture system Bandwidth Low Bandwidth Fast bandwidth
    with single edge network Fast bandwidth with single and multiple edge network
    with LPWAN communication Latency High latency rate and risk of data loss during
    cloud transmission. Delay time will be increased for large farming area. Delay
    time is reduced as of using multiple edge gateway. Interruption Interruption rate
    are high Interruption rate can be high if switching to 5G beyond network or multiple
    edge network. Interruption are reduced because authenticated edge connection for
    small and large farming field WSN and can be customized based on the network.
    Data storage Limited storage capacity and complicated database management because
    of limited globalization. High storage capacity at the cloud end, as the architecture
    is for small farming area. Capable of managing databases at the edge network and
    storage capacity will be maximum as using distributed system. Energy efficient
    Requires a lot of energy for calculation and processing while transmitting various
    types of data at long distances. More energy required as system is not fully distributed.
    Less energy consumption as system is distributed. Minimises the necessity for
    transmission of data over long distances. Real time decision Real-time decision-making
    can be accomplished although has a larger latency, which restricts its effectiveness
    for circumstances where timeliness is essential. Real time decision possible but
    lack in independency at each edge network. Increase productivity and yield by
    enabling real-time decision-making with exposure to the constantly changing conditions
    on the farm. PHRS Subsystems Integration of PHRS sub systems is possible with
    other farming sub system but need much enhancement, as limited range of network
    connections and no such algorithm for intelligent decision making at the edge
    level. Since PHRS module data differ from farm to farm, there are chances of data
    overload at the edge network level because there are no such discussions on NP-hard
    problem optimization strategies. Using of metaheuristic-based algorithms it is
    possible to increase the efficiency of PHRS, sub-systems in 5G-based or beyond
    networks. DHRS Subsystems Integration of DHRS sub-systems is limited as it provides
    a huge volume of image and video-type data. Integration of the DHRS subsystem
    is achievable as discussed about the UAVs-based system for various image vision
    problems. Integration of DHRS with PHRS subsystem is achievable using NB-IoT M2M
    communication. POHRS Subsystems Integration of POHRS subsystem is limited. POHRS
    subsystem integration for supply chain management. Management of POHRS subsystems
    for TTN, FDP, cooling, harvesting, and farmers'' inventory. Security and privacy
    Device security, data authentication, network slicing, and encryption still need
    to be improved. There is no analogous method discussed for recognising security
    ambiguity while deploying IoT devices for securing inconsistent energy-efficient
    communication devices for considerable distance and durability. The system becomes
    more efficient and capable with the help of 5G, SDN, and distributed edge computing
    structures and is able to oversee massive amounts of network traffic and data
    authentication. As a result of the discussion in Table 5 above, it can be concluded
    that creating the proposed 5G based smart agriculture system using edge computing
    could effortlessly extend to meet the increasing necessities of modern farming.
    The entire structure can be customized by how the agricultural operation grows
    and network changes or whether its operations require more sensors and devices.
    The below Table 6 discusses the proposed literature survey information with existing
    surveys information. Table 6. Comparative analysis of proposed survey from existing
    survey. References Classification of farming operations from pre- to post-harvest
    IoT based hybrid methodology for PHRS DHR, POHRS subsystem Recommendation based
    on existing system shortcomings Use 5G / 5G beyond (Tao et al., 2021) Existing
    survey discussed the plant management, Agri supply management, and challenges
    in IoT technology that can be used year-wise. x Recommendation about devices,
    data and platform not fully expressed in terms of security, self-sustainable,
    and cost x (Da Silveira et al., 2021) A systematic review based on the research
    question and use of agriculture 4.0 development x x Systematic review on the basis
    of research question with 5G technology (Xu et al., 2022) x Discussed about IoT
    technology in agriculture for plant monitoring Details about the problem with
    its Prospection. x (Van Hilten and Wolfert, 2022) x Focused on drone technology
    Recommendation on the basis of aggregation, management cycle, and decision making
    level. 5G Proposed Survey ✓ ✓ ✓ ✓ According to Table 6, the proposed review fills
    the gap in existing reviews for IoT-based smart agriculture by classifying pre-
    and post-harvest activities into PHRS, DHRS, and POHRS subsystems. Based on this
    categorization, various existing work has been discussed in detail with an analysis
    of the IoT communication technologies and metaheuristic approach used in the IoT
    based smart agriculture system. As a result of the discussion of the problem in
    existing work, the 5G and 5G beyond smart agriculture system architecture are
    being prepared. With this recommended framework, the shortcomings of the existing
    work can be reduced, and the system can be optimized. 11. Conclusion IoT-based
    smart agriculture is the advancement of the digital transformation of various
    traditional farming subactivities. In this a comprehensive review by categorizing
    the farming subactivities based on the Pre, During, and Post harvests of the smart
    agriculture-based existing application has been discussed in detail. We have also
    observed the research gaps for each and every activity separately. Based on these
    research gaps it has been analyzed that developing an intelligent farming system
    is still a challenging process. We have tried to address these challenges and
    enhance the performance of the existing systems by proposing a 5G-based hybrid
    framework for smart agriculture. The outcome of the proposed survey is validated
    by comparison with the existing survey papers. It is found that various existing
    surveys have not been represented considering the smart agriculture applications
    according to the Pre, During, and Post harvesting phases. Therefore, our survey
    methodology and outcome seem to outperform the other surveys conducted so far
    for smart agriculture. In future work the technology wise survey for the different
    aspects of smart agriculture may be conducted. For example, we can have a comprehensive
    survey on the use of Machine learning algorithms for each activity of smart agriculture.
    Also crop wise comprehensive survey can be conducted involving all the pre, during
    and post-harvest activities. Declaration of competing interest The authors declare
    that they have no known competing financial interests or personal relationships
    that could have appeared to influence the work reported in this paper. Data availability
    No data was used for the research described in the article. References Abdulghaffar
    et al., 2021 A. Abdulghaffar, A. Mahmoud, M. Abu-Amara, T. Sheltami Modeling and
    evaluation of software defined networking based 5G core network architecture IEEE
    Access, 9 (2021), pp. 10179-10198, 10.1109/ACCESS.2021.3049945 View in ScopusGoogle
    Scholar Abouelsaad et al., 2022 Abouelsaad, I.A., Teiba, I.I., El-Bilawy, E.H.,
    El-Sharkawy, I., 2022. Artificial Intelligence and Reducing Food Waste during
    Harvest and Post-Harvest Processes, in: IoT-Based Smart Waste Management for Environmental
    Sustainability. CRC Press, Boca Raton, pp. 63–82. https://doi.org/10.1201/9781003184096-4.
    Google Scholar Adeola et al., 2022 Adeola, J.O., Degila, J., Zennaro, M., 2022.
    Recent Advances in Plant Diseases Detection With Machine Learning: Solution for
    Developing Countries, in: 2022 IEEE International Conference on Smart Computing
    (SMARTCOMP). Presented at the 2022 IEEE International Conference on Smart Computing
    (SMARTCOMP), IEEE, Helsinki, Finland, pp. 374–380. https://doi.org/10.1109/SMARTCOMP55677.2022.00083.
    Google Scholar Ahmad et al., 2022 U. Ahmad, A. Alvino, S. Marino Solar fertigation:
    A sustainable and smart IoT-based irrigation and fertilization system for efficient
    water and nutrient management Agronomy, 12 (2022), p. 1012, 10.3390/agronomy12051012
    View in ScopusGoogle Scholar Ahmed et al., 2018 N. Ahmed, D. De, I. Hussain Internet
    of Things (IoT) for smart precision agriculture and farming in rural areas IEEE
    Internet Things J., 5 (2018), pp. 4890-4899, 10.1109/JIOT.2018.2879579 View in
    ScopusGoogle Scholar Alomar and Alazzam, 2018 Alomar, B., Alazzam, A., 2018. A
    Smart Irrigation System Using IoT and Fuzzy Logic Controller, in: 2018 Fifth HCT
    Information Technology Trends (ITT). Presented at the 2018 Fifth HCT Information
    Technology Trends (ITT), IEEE, Dubai, United Arab Emirates, pp. 175–179. https://doi.org/10.1109/CTIT.2018.8649531.
    Google Scholar Amkor and El Barbri, 2023 A. Amkor, N. El Barbri Artificial intelligence
    methods for classification and prediction of potatoes harvested from fertilized
    soil based on a sensor array response Sens. Actuators A: Phys., 349 (2023), Article
    114106, 10.1016/j.sna.2022.114106 View PDFView articleView in ScopusGoogle Scholar
    Anagha et al., 2023 C.S. Anagha, P.M. Pawar, P.S. Tamizharasan Cost-effective
    IoT-based intelligent irrigation system Int. J. Syst. Assur. Eng. Manag., 14 (2023),
    pp. 263-274, 10.1007/s13198-023-01854-y View in ScopusGoogle Scholar Anbananthen
    et al., 2021 Anbananthen, K.S.M., Subbiah, S., Chelliah, D., Sivakumar, P., Somasundaram,
    V., Velshankar, K.H., Khan, M.K.A.A., 2021. An intelligent decision support system
    for crop yield prediction using hybrid machine learning algorithms. F1000Res 10,
    1143. https://doi.org/10.12688/f1000research.73009.1. Google Scholar Andreadis
    et al., 2022 Andreadis, A., Giambene, G., Zambon, R., 2022. Low-Power IoT Environmental
    Monitoring and Smart Agriculture for Unconnected Rural Areas, in: 2022 20th Mediterranean
    Communication and Computer Networking Conference (MedComNet). Presented at the
    2022 20th Mediterranean Communication and Computer Networking Conference (MedComNet),
    IEEE, Pafos, Cyprus, pp. 31–38. https://doi.org/10.1109/MedComNet55087.2022.9810376.
    Google Scholar Andrianto et al., 2020 Andrianto, H., Suhardi, Faizal, A., Armandika,
    F., 2020. Smartphone Application for Deep Learning-Based Rice Plant Disease Detection,
    in: 2020 International Conference on Information Technology Systems and Innovation
    (ICITSI). Presented at the 2020 International Conference on Information Technology
    Systems and Innovation (ICITSI), IEEE, Bandung - Padang, Indonesia, pp. 387–392.
    https://doi.org/10.1109/ICITSI50517.2020.9264942. Google Scholar Annual Internet,
    2023 Annual Internet, C., 2023. Cisco Annual Internet Report (2018–2023) White
    Paper. URL https://www.cisco.com/c/en/us/solutions/collateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html.
    Google Scholar Anoop et al., 2021 Anoop, A., Thomas, M., Sachin, K., 2021. IoT
    Based Smart Warehousing using Machine Learning, in: 2021 Asian Conference on Innovation
    in Technology (ASIANCON). Presented at the 2021 Asian Conference on Innovation
    in Technology (ASIANCON), IEEE, PUNE, India, pp. 1–6. https://doi.org/10.1109/ASIANCON51346.2021.9544579.
    Google Scholar Arakeri et al., 2017 Arakeri, Megha.P., Vijaya Kumar, B.P., Barsaiya,
    S., Sairam, H.V., 2017. Computer vision based robotic weed control system for
    precision agriculture, in: 2017 International Conference on Advances in Computing,
    Communications and Informatics (ICACCI). Presented at the 2017 International Conference
    on Advances in Computing, Communications and Informatics (ICACCI), IEEE, Udupi,
    pp. 1201–1205. https://doi.org/10.1109/ICACCI.2017.8126005. Google Scholar Ayalew
    et al., 2022 Ayalew, L.G., Mattihalli, C., Asmare, F.M., 2022. Wirelessly Controlled
    Plant Health Monitoring and Medicate System Based on IoT Technology, in: Woungang,
    I., Dhurandher, S.K., Pattanaik, K.K., Verma, A., Verma, P. (Eds.), Advanced Network
    Technologies and Intelligent Computing, Communications in Computer and Information
    Science. Springer International Publishing, Cham, pp. 3–14. https://doi.org/10.1007/978-3-030-96040-7_1.
    Google Scholar Bachuwar et al., 2018 Bachuwar, V.D., Shligram, A.D., Deshmukh,
    L.P., 2018. Monitoring the soil parameters using IoT and Android based application
    for smart agriculture. Presented at the EMERGING TECHNOLOGIES: MICRO TO NANO (ETMN-2017):
    Proceedings of the 3rd International Conference on Emerging Technologies: Micro
    to Nano, Solapur, India, p. 020003. https://doi.org/10.1063/1.5047679. Google
    Scholar Bakthavatchalam et al., 2022 K. Bakthavatchalam, B. Karthik, V. Thiruvengadam,
    S. Muthal, D. Jose, K. Kotecha, V. Varadarajan IoT framework for measurement and
    precision agriculture: Predicting the crop using machine learning algorithms Technologies,
    10 (2022), p. 13, 10.3390/technologies10010013 View in ScopusGoogle Scholar Balezentiene
    et al., 2013 L. Balezentiene, D. Streimikiene, T. Balezentis Fuzzy decision support
    methodology for sustainable energy crop selection Renew. Sustain. Energy Rev.,
    17 (2013), pp. 83-93, 10.1016/j.rser.2012.09.016 View PDFView articleView in ScopusGoogle
    Scholar Banerjee et al., 2020 Banerjee, S., Saini, A.K., Nigam, H., Vijay, V.,
    2020. IoT Instrumented Food and Grain Warehouse Traceability System for Farmers,
    in: 2020 International Conference on Artificial Intelligence and Signal Processing
    (AISP). Presented at the 2020 International Conference on Artificial Intelligence
    and Signal Processing (AISP), IEEE, Amaravati, India, pp. 1–4. https://doi.org/10.1109/AISP48273.2020.9073248.
    Google Scholar Baryshnikova et al., 2022 N. Baryshnikova, P. Altukhov, N. Naidenova,
    A. Shkryabina Ensuring global food security: Transforming approaches in the context
    of agriculture 5.0 IOP Conf. Ser.: Earth Environ. Sci., 988 (3) (2022), p. 032024,
    10.1088/1755-1315/988/3/032024 View in ScopusGoogle Scholar Bhojani and Bhatt,
    2020 S.H. Bhojani, N. Bhatt Wheat crop yield prediction using new activation functions
    in neural network Neural Comput. & Applic., 32 (2020), pp. 13941-13951, 10.1007/s00521-020-04797-8
    View in ScopusGoogle Scholar Bhojwani et al., 2020 Bhojwani, Y., Singh, R., Reddy,
    R., Perumal, B., 2020. Crop Selection and IoT Based Monitoring System for Precision
    Agriculture, in: 2020 International Conference on Emerging Trends in Information
    Technology and Engineering (Ic-ETITE). Presented at the 2020 International Conference
    on Emerging Trends in Information Technology and Engineering (ic-ETITE), IEEE,
    Vellore, India, pp. 1–11. https://doi.org/10.1109/ic-ETITE47903.2020.123. Google
    Scholar Bhutta and Ahmad, 2021 M.N.M. Bhutta, M. Ahmad Secure identification,
    traceability and real-time tracking of agricultural food supply during transportation
    using Internet of Things IEEE Access, 9 (2021), pp. 65660-65675, 10.1109/ACCESS.2021.3076373
    View in ScopusGoogle Scholar Bong et al., 2018 Bong Cassendra P. C., Lim Li Yee,
    Lee Chew Tin, Fan Yee Van, Klemes Jiri J., 2018. The role of smart waste management
    in smart agriculture. Chemical Engineering Transactions 70, 937–942. https://doi.org/10.3303/CET1870157.
    Google Scholar Boursianis et al., 2022 A.D. Boursianis, M.S. Papadopoulou, P.
    Diamantoulakis, A. Liopa-Tsakalidi, P. Barouchas, G. Salahas, G. Karagiannidis,
    S. Wan, S.K. Goudos Internet of Things (IoT) and Agricultural Unmanned Aerial
    Vehicles (UAVs) in smart farming: A comprehensive review Internet of Things, 18
    (2022), Article 100187, 10.1016/j.iot.2020.100187 View PDFView articleView in
    ScopusGoogle Scholar Cecchetti and Ruscelli, 2022 Cecchetti, G., Ruscelli, A.L.,
    2022. Monitoring and Automation for Sustainable Smart Greenhouses, in: 2022 IEEE
    International Conference on Smart Computing (SMARTCOMP). Presented at the 2022
    IEEE International Conference on Smart Computing (SMARTCOMP), IEEE, Helsinki,
    Finland, pp. 381–386. https://doi.org/10.1109/SMARTCOMP55677.2022.00084. Google
    Scholar Chamara et al., 2022 N. Chamara, M.D. Islam, G.(. Bai, Y. Shi, Y. Ge Ag-IoT
    for crop and environment monitoring: Past, present, and future Agr. Syst., 203
    (2022), p. 103497, 10.1016/j.agsy.2022.103497 View PDFView articleView in ScopusGoogle
    Scholar Chang et al., 2018 Chang, Y.S., Hsiung Chen, Y., Zhou, S.K., 2018. A smart
    lighting system for greenhouses based on Narrowband-IoT communication, in: 2018
    13th International Microsystems, Packaging, Assembly and Circuits Technology Conference
    (IMPACT). Presented at the 2018 13th International Microsystems, Packaging, Assembly
    and Circuits Technology Conference (IMPACT), IEEE, Taipei, Taiwan, pp. 275–278.
    https://doi.org/10.1109/IMPACT.2018.8625804. Google Scholar Charania and Li, 2020
    I. Charania, X. Li Smart farming: Agriculture’s shift from a labor intensive to
    technology native industry Internet of Things, 9 (2020), Article 100142, 10.1016/j.iot.2019.100142
    View PDFView articleView in ScopusGoogle Scholar Chen et al., 2020 C.-J. Chen,
    Y.-Y. Huang, Y.-S. Li, C.-Y. Chang, Y.-M. Huang An AIoT Based Smart Agricultural
    System for Pests Detection IEEE Access, 8 (2020), pp. 180750-180761, 10.1109/ACCESS.2020.3024891
    View in ScopusGoogle Scholar Chihana et al., 2018 Chihana, S., Phiri, J., Kunda,
    D., 2018. An IoT based Warehouse Intrusion Detection(E-Perimeter) and Grain Tracking
    Model for Food Reserve Agency. ijacsa 9. https://doi.org/10.14569/IJACSA.2018.090929.
    Google Scholar Da Silveira et al., 2021 F. Da Silveira, F.H. Lermen, F.G. Amaral
    An overview of agriculture 4.0 development: Systematic review of descriptions,
    technologies, barriers, advantages, and disadvantages Comput. Electron. Agric.,
    189 (2021), Article 106405, 10.1016/j.compag.2021.106405 View PDFView articleView
    in ScopusGoogle Scholar Dadi et al., 2021 V. Dadi, S.R. Nikhil, R.S. Mor, T. Agarwal,
    S. Arora Agri-food 4.0 and innovations: Revamping the supply chain operations
    Prod. Eng. Arch., 27 (2021), pp. 75-89, 10.30657/pea.2021.27.10 View in ScopusGoogle
    Scholar Dankhara et al., 2019 F. Dankhara, K. Patel, N. Doshi Analysis of robust
    weed detection techniques based on the Internet of Things (IoT) Procedia Comput.
    Sci., 160 (2019), pp. 696-701, 10.1016/j.procs.2019.11.025 View PDFView articleView
    in ScopusGoogle Scholar Dasgupta et al., 2020 I. Dasgupta, J. Saha, P. Venkatasubbu,
    P. Ramasubramanian AI crop predictor and weed detector using wireless technologies:
    A smart application for farmers Arab. J. Sci. Eng., 45 (2020), pp. 11115-11127,
    10.1007/s13369-020-04928-2 View in ScopusGoogle Scholar Debauche et al., 2020
    O. Debauche, S. Mahmoudi, M. Elmoulat, S.A. Mahmoudi, P. Manneback, F. Lebeau
    Edge AI-IoT pivot irrigation, plant diseases, and pests identification Procedia
    Comput. Sci., 177 (2020), pp. 40-48, 10.1016/j.procs.2020.10.009 View PDFView
    articleView in ScopusGoogle Scholar Deepa and Ganesan, 2019 N. Deepa, K. Ganesan
    Decision-making tool for crop selection for agriculture development Neural Comput.
    & Applic., 31 (2019), pp. 1215-1225, 10.1007/s00521-017-3154-x View in ScopusGoogle
    Scholar Deshmukh and Bhalerao, 2017 Deshmukh, P.R., Bhalerao, D., 2017. An implementation
    of MQTT through the application of warehouse management system for climacteric
    fruits and vegetables, in: 2017 2nd International Conference on Communication
    and Electronics Systems (ICCES). Presented at the 2017 2nd International Conference
    on Communication and Electronics Systems (ICCES), IEEE, Coimbatore, pp. 844–849.
    https://doi.org/10.1109/CESYS.2017.8321204. Google Scholar Devapal, 2020 D. Devapal
    Smart agro farm solar powered soil and weather monitoring system for farmers Mater.
    Today:. Proc., 24 (2020), pp. 1843-1854, 10.1016/j.matpr.2020.03.609 View PDFView
    articleGoogle Scholar Devi et al., 2021 Devi, A., Julie Therese, M., Dharanyadevi,
    P., Pravinkumar, K., 2021. IoT Based Food Grain Wastage Monitoring and Controlling
    System for Warehouse, in: 2021 International Conference on System, Computation,
    Automation and Networking (ICSCAN). Presented at the 2021 International Conference
    on System, Computation, Automation and Networking (ICSCAN), IEEE, Puducherry,
    India, pp. 1–5. https://doi.org/10.1109/ICSCAN53069.2021.9526400. Google Scholar
    Elavarasi et al., 2019 Elavarasi, G., Murugaboopathi, G., Kathirvel, S., 2019.
    Fresh Fruit Supply Chain Sensing and Transaction Using IoT, in: 2019 IEEE International
    Conference on Intelligent Techniques in Control, Optimization and Signal Processing
    (INCOS). Presented at the 2019 IEEE International Conference on Intelligent Techniques
    in Control, Optimization and Signal Processing (INCOS), IEEE, Tamilnadu, India,
    pp. 1–4. https://doi.org/10.1109/INCOS45849.2019.8951326. Google Scholar El-magrous
    et al., 2019 El-magrous, A.A., Sternhagen, J.D., Hatfield, G., Qiao, Q., 2019.
    Internet of Things Based Weather-Soil Sensor Station for Precision Agriculture,
    in: 2019 IEEE International Conference on Electro Information Technology (EIT).
    Presented at the 2019 IEEE International Conference on Electro Information Technology
    (EIT), IEEE, Brookings, SD, USA, pp. 092–097. https://doi.org/10.1109/EIT.2019.8833811.
    Google Scholar Faid et al., 2021 A. Faid, M. Sadik, E. Sabir An agile AI and IoT-augmented
    smart farming: A cost-effective cognitive weather station Agriculture, 12 (2021),
    p. 35, 10.3390/agriculture12010035 Google Scholar Fan et al., 2015 Fan, W., Chong,
    C., Xiaoling, G., Hua, Y., Juyun, W., 2015. Prediction of Crop Yield Using Big
    Data, in: 2015 8th International Symposium on Computational Intelligence and Design
    (ISCID). Presented at the 2015 8th International Symposium on Computational Intelligence
    and Design (ISCID), IEEE, Hangzhou, China, pp. 255–260. https://doi.org/10.1109/ISCID.2015.191.
    Google Scholar FAO, 2009 FAO, 2009. FAO How to Feed the World in 2050 (High-Level
    Expert Forum). Google Scholar Fathollahi-Fard et al., 2023 A.M. Fathollahi-Fard,
    G. Tian, H. Ke, Y. Fu, K.Y. Wong Efficient multi-objective metaheuristic algorithm
    for sustainable harvest planning problem Comput. Oper. Res., 158 (2023), Article
    106304, 10.1016/j.cor.2023.106304 View PDFView articleView in ScopusGoogle Scholar
    Fawzi et al., 2021 H. Fawzi, S.A. Mostafa, D. Ahmed, N. Alduais, M.A. Mohammed,
    M. Elhoseny TOQO: A new tillage operations quality optimization model based on
    parallel and dynamic decision support system J. Clean. Prod., 316 (2021), Article
    128263, 10.1016/j.jclepro.2021.128263 View PDFView articleView in ScopusGoogle
    Scholar Feng Tian, 2016 Feng Tian, 2016. An agri-food supply chain traceability
    system for China based on RFID & blockchain technology, in: 2016 13th International
    Conference on Service Systems and Service Management (ICSSSM). Presented at the
    2016 13th International Conference on Service Systems and Service Management (ICSSSM),
    IEEE, Kunming, China, pp. 1–6. https://doi.org/10.1109/ICSSSM.2016.7538424. Google
    Scholar G et al., 2020 G, L., C, R., P, G., 2020. An automated low cost IoT based
    Fertilizer Intimation System for smart agriculture. Sustainable Computing: Informatics
    and Systems 28, 100300. https://doi.org/10.1016/j.suscom.2019.01.002. Google Scholar
    Gaikwad et al., 2021 S.V. Gaikwad, A.D. Vibhute, K.V. Kale, S.C. Mehrotra An innovative
    IoT based system for precision farming Comput. Electron. Agric., 187 (2021), Article
    106291, 10.1016/j.compag.2021.106291 View PDFView articleView in ScopusGoogle
    Scholar Gajula et al., 2021 Gajula, A.K., Singamsetty, J., Dodda, V.C., Kuruguntla,
    L., 2021. Prediction of crop and yield in agriculture using machine learning technique,
    in: 2021 12th International Conference on Computing Communication and Networking
    Technologies (ICCCNT). Presented at the 2021 12th International Conference on
    Computing Communication and Networking Technologies (ICCCNT), IEEE, Kharagpur,
    India, pp. 1–5. https://doi.org/10.1109/ICCCNT51525.2021.9579843. Google Scholar
    Ganesh et al., 2022 Ganesh, R.S., S, S., M, G.B., G, A.K., S, G.D., 2022. An IoT-based
    Dam Water Level Monitoring and Alerting System, in: 2022 International Conference
    on Applied Artificial Intelligence and Computing (ICAAIC). Presented at the 2022
    International Conference on Applied Artificial Intelligence and Computing (ICAAIC),
    IEEE, Salem, India, pp. 1551–1554. https://doi.org/10.1109/ICAAIC53929.2022.9792675.
    Google Scholar Gayatri et al., 2015 Gayatri, M.K., Jayasakthi, J., Anandha Mala,
    G.S., 2015. Providing Smart Agricultural solutions to farmers for better yielding
    using IoT, in: 2015 IEEE Technological Innovation in ICT for Agriculture and Rural
    Development (TIAR). Presented at the 2015 IEEE Technological Innovation in ICT
    for Agriculture and Rural Development (TIAR), IEEE, Chennai, pp. 40–43. https://doi.org/10.1109/TIAR.2015.7358528.
    Google Scholar Ginige and Sivagnanasundaram, 2019 A. Ginige, J. Sivagnanasundaram
    Enhancing agricultural sustainability through crowdsensing: A smart computing
    approach JOAAT, 6 (2019), pp. 161-165, 10.18178/joaat.6.3.161-165 Google Scholar
    Giri Babu and Anjan Babu, 2020 Giri Babu, T., Anjan Babu, G., 2020. Identification
    of Crop Health Condition Using IoT Based Automated System, in: Borah, S., Emilia
    Balas, V., Polkowski, Z. (Eds.), Advances in Data Science and Management, Lecture
    Notes on Data Engineering and Communications Technologies. Springer Singapore,
    Singapore, pp. 421–433. https://doi.org/10.1007/978-981-15-0978-0_41. Google Scholar
    Goswami et al., 2020 V. Goswami, P. Singh, P. Dwivedi, S. Chauhan Soil health
    monitoring system Int. J. Res. Appl. Sci. Eng. Technol. (IJRASET), 8 (2020), pp.
    1536-1540 CrossRefGoogle Scholar Grimblatt et al., 2021 V. Grimblatt, C. Jego,
    G. Ferre, F. Rivet How to feed a growing population—An IoT approach to crop health
    and growth IEEE J. Emerg. Sel. Topics Circuits Syst., 11 (2021), pp. 435-448,
    10.1109/JETCAS.2021.3099778 View in ScopusGoogle Scholar Gupta and Nahar, 2023
    A. Gupta, P. Nahar Classification and yield prediction in smart agriculture system
    using IoT J. Ambient Intell. Human Comput., 14 (8) (2023), pp. 10235-10244, 10.1007/s12652-021-03685-w
    View in ScopusGoogle Scholar Hamid et al., 2022 Hamid, Y., Wani, S., Soomro, A.B.,
    Alwan, A.A., Gulzar, Y., 2022. Smart Seed Classification System based on MobileNetV2
    Architecture, in: 2022 2nd International Conference on Computing and Information
    Technology (ICCIT). Presented at the 2022 2nd International Conference on Computing
    and Information Technology (ICCIT), IEEE, Tabuk, Saudi Arabia, pp. 217–222. https://doi.org/10.1109/ICCIT52419.2022.9711662.
    Google Scholar Hamouda and Elhabil, 2017 Hamouda, Y.E.M., Elhabil, B.H.Y., 2017.
    Precision Agriculture for Greenhouses Using a Wireless Sensor Network, in: 2017
    Palestinian International Conference on Information and Communication Technology
    (PICICT). Presented at the 2017 Palestinian International Conference on Information
    and Communication Technology (PICICT), IEEE, Gaza, Palestine, pp. 78–83. https://doi.org/10.1109/PICICT.2017.20.
    Google Scholar Haseeb et al., 2020 K. Haseeb, I. Ud Din, A. Almogren, N. Islam
    An energy efficient and secure IoT-based WSN framework: An application to smart
    agriculture Sensors, 20 (2020), p. 2081, 10.3390/s20072081 View in ScopusGoogle
    Scholar Hema et al., 2020 L.K. Hema, S. Velmurugan, D.N. Sunil, S. Thariq Aziz,
    S. Thirunavkarasu IOT based real-time control and monitoring system for food grain
    procurement and storage IOP Conf. Ser.: Mater. Sci. Eng., 993 (1) (2020), p. 012079,
    10.1088/1757-899X/993/1/012079 View in ScopusGoogle Scholar Hidayat et al., 2020
    Hidayat, T., Mahardiko, R., Sianturi Tigor, F.D., 2020. Method of Systematic Literature
    Review for Internet of Things in ZigBee Smart Agriculture, in: 2020 8th International
    Conference on Information and Communication Technology (ICoICT). Presented at
    the 2020 8th International Conference on Information and Communication Technology
    (ICoICT), IEEE, Yogyakarta, Indonesia, pp. 1–4. https://doi.org/10.1109/ICoICT49345.2020.9166195.
    Google Scholar Hidayatuloh et al., 2018 Hidayatuloh, A., Nursalman, M., Nugraha,
    E., 2018. Identification of Tomato Plant Diseases by Leaf Image Using Squeezenet
    Model, in: 2018 International Conference on Information Technology Systems and
    Innovation (ICITSI). Presented at the 2018 International Conference on Information
    Technology Systems and Innovation (ICITSI), IEEE, Bandung - Padang, Indonesia,
    pp. 199–204. https://doi.org/10.1109/ICITSI.2018.8696087. Google Scholar Hossain
    et al., 2022 F.F. Hossain, R. Messenger, G.L. Captain, S. Ekin, J.D. Jacob, S.
    Taghvaeian, J.F. O’Hara Soil moisture monitoring through UAS-assisted Internet
    of Things LoRaWAN wireless underground sensors IEEE Access, 10 (2022), pp. 102107-102118,
    10.1109/ACCESS.2022.3208109 View in ScopusGoogle Scholar Hu et al., 2020 W.-J.
    Hu, J. Fan, Y.-X. Du, B.-S. Li, N. Xiong, E. Bekkering MDFC–ResNet: An agricultural
    IoT system to accurately recognize crop diseases IEEE Access, 8 (2020), pp. 115287-115298,
    10.1109/ACCESS.2020.3001237 View in ScopusGoogle Scholar Indira et al., 2018 Indira,
    D.N.V.S.L.S., Harshita, M., Pranav, D.S., Sai, J.P.M., 2018. TILLAGE DRIP: An
    Efficient Seed Selection and Conservative Irrigation with Crop Defective Alert
    by IOT, in: Satapathy, S.C., Bhateja, V., Das, S. (Eds.), Smart Computing and
    Informatics, Smart Innovation, Systems and Technologies. Springer Singapore, Singapore,
    pp. 53–62. https://doi.org/10.1007/978-981-10-5547-8_6. Google Scholar Islam et
    al., 2019 Islam, M.N., Jahan, M.R., Ali, A., Rony, S., Anannya, T.T., Aziz, F.I.,
    Bayzed, M., Yeazdani, A., Rabbi, Md.F., 2019. Design and Development of an Intelligent
    Seed Germination System Based on IoT, in: Corrales, J.C., Angelov, P., Iglesias,
    J.A. (Eds.), Advances in Information and Communication Technologies for Adapting
    Agriculture to Climate Change II, Advances in Intelligent Systems and Computing.
    Springer International Publishing, Cham, pp. 146–161. https://doi.org/10.1007/978-3-030-04447-3_10.
    Google Scholar Islam et al., 2021 N. Islam, M.M. Rashid, S. Wibowo, C.-Y. Xu,
    A. Morshed, S.A. Wasimi, S. Moore, S.M. Rahman Early weed detection using image
    processing and machine learning techniques in an Australian chilli farm Agriculture,
    11 (2021), p. 387, 10.3390/agriculture11050387 View in ScopusGoogle Scholar Jabir
    and Falih, 2022 B. Jabir, N. Falih Deep learning-based decision support system
    for weeds detection in wheat fields IJECE, 12 (2022), p. 816, 10.11591/ijece.v12i1
    View in ScopusGoogle Scholar Jachimczyk et al., 2021 B. Jachimczyk, R. Tkaczyk,
    T. Piotrowski, S. Johansson, W. Kulesza IoT-based dairy supply chain - An ontological
    approach Elektron Elektrotech, 27 (2021), pp. 71-83, 10.5755/j02.eie.27612 View
    in ScopusGoogle Scholar Jagtap et al., 2021 S.J. Jagtap, G. Garcia-Garcia, S.
    Rahimifard Optimisation of the resource efficiency of food manufacturing via the
    Internet of Things Comput. Ind., 127 (2021), Article 103397, 10.1016/j.compind.2021.103397
    View PDFView articleView in ScopusGoogle Scholar Jamroen et al., 2020 C. Jamroen,
    P. Komkum, C. Fongkerd, W. Krongpha An intelligent irrigation scheduling system
    using low-cost wireless sensor network toward sustainable and precision agriculture
    IEEE Access, 8 (2020), pp. 172756-172769, 10.1109/ACCESS.2020.3025590 View in
    ScopusGoogle Scholar Javaid et al., 2022 M. Javaid, A. Haleem, R.P. Singh, R.
    Suman Enhancing smart farming through the applications of Agriculture 4.0 technologies
    Int. J. Intell. Netw., 3 (2022), pp. 150-164, 10.1016/j.ijin.2022.09.004 View
    PDFView articleView in ScopusGoogle Scholar Jayalakshmi et al., 2017 Jayalakshmi,
    K., Pavithra, S., Aarthi, C., 2017. Waste to wealth — A novel approach for food
    waste management, in: 2017 IEEE International Conference on Electrical, Instrumentation
    and Communication Engineering (ICEICE). Presented at the 2017 IEEE International
    Conference on Electrical, Instrumentation and Communication Engineering (ICEICE),
    IEEE, Karur, pp. 1–5. https://doi.org/10.1109/ICEICE.2017.8191873. Google Scholar
    Jayaram and Marad, 2012 M.A. Jayaram, N. Marad Fuzzy inference systems for crop
    yield prediction J. Intell. Syst., 21 (2012), 10.1515/jisys-2012-0016 Google Scholar
    Kalyani and Collier, 2021 Y. Kalyani, R. Collier A systematic survey on the role
    of cloud, fog, and edge computing combination in smart agriculture Sensors, 21
    (2021), p. 5922, 10.3390/s21175922 View in ScopusGoogle Scholar Karthikeyan et
    al., 2021 Karthikeyan, P., Manikandakumar, M., Sri Subarnaa, D.K., Priyadharshini,
    P., 2021. Weed Identification in Agriculture Field Through IoT, in: Suresh, P.,
    Saravanakumar, U., Hussein Al Salameh, M.S. (Eds.), Advances in Smart System Technologies,
    Advances in Intelligent Systems and Computing. Springer Singapore, Singapore,
    pp. 495–505. https://doi.org/10.1007/978-981-15-5029-4_41. Google Scholar Kasera
    et al., 2022 Kasera, R.K., Deb, R., Acharjee, T., 2022. A Framework for Blockchain-,
    AI-, and IoT-Driven Smart and Secure New-Generation Agriculture, in: Blockchain
    for IoT. Chapman and Hall/CRC, Boca Raton, pp. 185–215. https://doi.org/10.1201/9781003188247-10.
    Google Scholar Khanh et al., 2022 Q.V. Khanh, N.V. Hoai, L.D. Manh, A.N. Le, G.
    Jeon, M.R. Khosravi Wireless communication technologies for IoT in 5G: Vision,
    applications, and challenges Wirel. Commun. Mob. Comput., 2022 (2022), pp. 1-12,
    10.1155/2022/3229294 Google Scholar Khattab et al., 2019 A. Khattab, S.E.D. Habib,
    H. Ismail, S. Zayan, Y. Fahmy, M.M. Khairy An IoT-based cognitive monitoring system
    for early plant disease forecast Comput. Electron. Agric., 166 (2019), Article
    105028, 10.1016/j.compag.2019.105028 View PDFView articleView in ScopusGoogle
    Scholar Kiani and Seyyedabbasi, 2018 Kiani, F., Seyyedabbasi, A., 2018. Wireless
    Sensor Network and Internet of Things in Precision Agriculture. ijacsa 9. https://doi.org/10.14569/IJACSA.2018.090614.
    Google Scholar Kiani et al., 2022a F. Kiani, G. Randazzo, I. Yelmen, A. Seyyedabbasi,
    S. Nematzadeh, F.A. Anka, F. Erenel, M. Zontul, S. Lanza, A. Muzirafuti A smart
    and mechanized agricultural application: From cultivation to harvest Appl. Sci.,
    12 (2022), p. 6021, 10.3390/app12126021 View in ScopusGoogle Scholar Kiani et
    al., 2022b F. Kiani, A. Seyyedabbasi, S. Nematzadeh, F. Candan, T. Çevik, F.A.
    Anka, G. Randazzo, S. Lanza, A. Muzirafuti Adaptive metaheuristic-based methods
    for autonomous robot path planning: Sustainable agricultural applications Appl.
    Sci., 12 (2022), p. 943, 10.3390/app12030943 View in ScopusGoogle Scholar Kirar,
    2022 M.K. Kirar IoT based remote monitoring control and protection of irrigation
    water pumping system J. Oper. Autom. Power Eng. (2022), 10.22098/joape.2023.9265.1647
    Google Scholar Koklu and Ozkan, 2020 M. Koklu, I.A. Ozkan Multiclass classification
    of dry beans using computer vision and machine learning techniques Comput. Electron.
    Agric., 174 (2020), Article 105507, 10.1016/j.compag.2020.105507 View PDFView
    articleView in ScopusGoogle Scholar Konur et al., 2023 S. Konur, Y. Lan, D. Thakker,
    G. Morkyani, N. Polovina, J. Sharp Towards design and implementation of Industry
    4.0 for food manufacturing Neural Comput. & Applic., 35 (33) (2023), pp. 23753-23765,
    10.1007/s00521-021-05726-z View in ScopusGoogle Scholar Kori et al., 2021 Kori,
    S., Kori, M.A., Kori, A.S., 2021. AGROIoT - IoT Assisted Farming, in: 2021 IEEE
    International Conference on Mobile Networks and Wireless Communications (ICMNWC).
    Presented at the 2021 IEEE International Conference on Mobile Networks and Wireless
    Communications (ICMNWC), IEEE, Tumkur, Karnataka, India, pp. 1–7. https://doi.org/10.1109/ICMNWC52512.2021.9688374.
    Google Scholar Kulkarni and Angadi, 2019 S. Kulkarni, S.A. Angadi IoT based weed
    detection using image processing and CNN Int. J. Eng. Appl. Sci. Technol., 4 (2019),
    pp. 606-609 Google Scholar Kumar et al., 2015 Kumar, R., Singh, M.P., Kumar, P.,
    Singh, J.P., 2015. Crop Selection Method to maximize crop yield rate using machine
    learning technique, in: 2015 International Conference on Smart Technologies and
    Management for Computing, Communication, Controls, Energy and Materials (ICSTM).
    Presented at the 2015 International Conference on Smart Technologies and Management
    for Computing, Communication, Controls, Energy and Materials (ICSTM), IEEE, Avadi,Chennai,
    India, pp. 138–145. https://doi.org/10.1109/ICSTM.2015.7225403. Google Scholar
    Kumar et al., 2020 Kumar, Y.J.N., Spandana, V., Vaishnavi, V.S., Neha, K., Devi,
    V.G.R.R., 2020. Supervised Machine learning Approach for Crop Yield Prediction
    in Agriculture Sector, in: 2020 5th International Conference on Communication
    and Electronics Systems (ICCES). Presented at the 2020 5th International Conference
    on Communication and Electronics Systems (ICCES), IEEE, Coimbatore, India, pp.
    736–741. https://doi.org/10.1109/ICCES48766.2020.9137868. Google Scholar Kumar
    et al., 2021 M. Kumar, A. Kumar, V.S. Palaparthy Soil sensors-based prediction
    system for plant diseases using exploratory data analysis and machine learning
    IEEE Sensors J., 21 (2021), pp. 17455-17468, 10.1109/JSEN.2020.3046295 View in
    ScopusGoogle Scholar Li et al., 2021 X. Li, A. Garcia-Saavedra, X. Costa-Perez,
    C.J. Bernardos, C. Guimaraes, K. Antevski, J. Mangues-Bafalluy, J. Baranda, E.
    Zeydan, D. Corujo, P. Iovanna, G. Landi, J. Alonso, P. Paixao, H. Martins, M.
    Lorenzo, J. Ordonez-Lucena, D.R. Lopez 5Growth: An end-to-end service platform
    for automated deployment and management of vertical services over 5G networks
    IEEE Commun. Mag., 59 (2021), pp. 84-90, 10.1109/MCOM.001.2000730 View in ScopusGoogle
    Scholar Li et al., 2019 Y. Li, J. Si, S. Ma, X. Hu Using energy-aware scheduling
    weather forecast based harvesting for reconfigurable hardware IEEE Trans. Sustain.
    Comput., 4 (2019), pp. 109-117, 10.1109/TSUSC.2018.2800717 Google Scholar Liu
    et al., 2023 Liu, J., Shu, L., Lu, X., Liu, Y., 2023. Survey of Intelligent Agricultural
    IoT Based on 5G. Electronics 12, 2336. https://doi.org/10.3390/electronics12102336.
    Google Scholar Lova Raju and Vijayaraghavan, 2022 K. Lova Raju, V. Vijayaraghavan
    A self-powered, real-time, NRF24L01 IoT-based cloud-enabled service for smart
    agriculture decision-making system Wireless Pers. Commun., 124 (2022), pp. 207-236,
    10.1007/s11277-021-09462-4 View in ScopusGoogle Scholar Lu and Young, 2020 Y.
    Lu, S. Young A survey of public datasets for computer vision tasks in precision
    agriculture Comput. Electron. Agric., 178 (2020), Article 105760, 10.1016/j.compag.2020.105760
    View PDFView articleView in ScopusGoogle Scholar Luthra et al., 2018 Luthra, S.,
    Mangla, S.K., Garg, D., Kumar, A., 2018. Internet of Things (IoT) in Agriculture
    Supply Chain Management: A Developing Country Perspective, in: Dwivedi, Y.K.,
    Rana, N.P., Slade, E.L., Shareef, M.A., Clement, M., Simintiras, A.C., Lal, B.
    (Eds.), Emerging Markets from a Multidisciplinary Perspective, Advances in Theory
    and Practice of Emerging Markets. Springer International Publishing, Cham, pp.
    209–220. https://doi.org/10.1007/978-3-319-75013-2_16. Google Scholar Mahfuz et
    al., 2020 Mahfuz, N., Jahan, R., Islam, Md.M., Nigar, M., Karmokar, S., 2020.
    Microcontroller Based Intelligent Greenhouse Environment Monitoring and Controlling
    System, in: 2020 IEEE International Women in Engineering (WIE) Conference on Electrical
    and Computer Engineering (WIECON-ECE). Presented at the 2020 IEEE International
    Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE),
    IEEE, Bhubaneswar, India, pp. 418–421. https://doi.org/10.1109/WIECON-ECE52138.2020.9397991.
    Google Scholar Majumdar et al., 2023 P. Majumdar, D. Bhattacharya, S. Mitra, B.
    Bhushan Application of green IoT in agriculture 4.0 and beyond: Requirements,
    challenges and research trends in the era of 5G, LPWANs and Internet of UAV Things
    Wireless Pers. Commun., 131 (2023), pp. 1767-1816, 10.1007/s11277-023-10521-1
    View in ScopusGoogle Scholar Manickam, 2020 S. Manickam IoT-based soil condition
    monitoring framework SSRN J. (2020), 10.2139/ssrn.3711616 Google Scholar Materne
    and Inoue, 2018 Materne, N., Inoue, M., 2018. IoT Monitoring System for Early
    Detection of Agricultural Pests and Diseases, in: 2018 12th South East Asian Technical
    University Consortium (SEATUC). Presented at the 2018 12th South East Asian Technical
    University Consortium (SEATUC), IEEE, Yogyakarta, Indonesia, pp. 1–5. https://doi.org/10.1109/SEATUC.2018.8788860.
    Google Scholar Matsumoto et al., 2017 Matsumoto, Y., Hibino, H., Kubo, N., Kimura,
    M., Mizukami, Y., 2017. Modelling and simulation of agricultural production system
    based on IoT cultivated fields information, in: 2017 IEEE International Conference
    on Industrial Engineering and Engineering Management (IEEM). Presented at the
    2017 IEEE International Conference on Industrial Engineering and Engineering Management
    (IEEM), IEEE, Singapore, pp. 354–358. https://doi.org/10.1109/IEEM.2017.8289911.
    Google Scholar Mohammed et al., 2023 Mohammed, S.W., Soora, N.R., Polala, N.,
    Saman, S., 2023. Smart Water Resource Management by Analyzing the Soil Structure
    and Moisture Using Deep Learning, in: Choudrie, J., Mahalle, P., Perumal, T.,
    Joshi, A. (Eds.), IOT with Smart Systems, Smart Innovation, Systems and Technologies.
    Springer Nature Singapore, Singapore, pp. 709–719. https://doi.org/10.1007/978-981-19-3575-6_68.
    Google Scholar Mohanty et al., 2016 S.P. Mohanty, D.P. Hughes, M. Salathé Using
    deep learning for image-based plant disease detection Front. Plant Sci., 7 (2016),
    p. 1419, 10.3389/fpls.2016.01419 View in ScopusGoogle Scholar Musa and Vidyasankar,
    2017 Z. Musa, K. Vidyasankar A fog computing framework for blackberry supply chain
    management Procedia Comput. Sci., 113 (2017), pp. 178-185, 10.1016/j.procs.2017.08.338
    View PDFView articleView in ScopusGoogle Scholar Nagasubramanian et al., 2021
    G. Nagasubramanian, R.K. Sakthivel, R. Patan, M. Sankayya, M. Daneshmand, A.H.
    Gandomi Ensemble classification and IoT-based pattern recognition for crop disease
    monitoring system IEEE Internet Things J., 8 (2021), pp. 12847-12854, 10.1109/JIOT.2021.3072908
    View in ScopusGoogle Scholar Natnael Tilahun, 2022 Natnael Tilahun, 2022. Potato
    Leaf (Healthy and Late Blight). https://doi.org/10.17632/V4W72BSTS5.2. Google
    Scholar Nawandar and Satpute, 2019 N.K. Nawandar, V.R. Satpute IoT based low cost
    and intelligent module for smart irrigation system Comput. Electron. Agric., 162
    (2019), pp. 979-990, 10.1016/j.compag.2019.05.027 View PDFView articleView in
    ScopusGoogle Scholar Nayak et al., 2022 Nayak, S.P., Rai, S.C., Sahoo, B., 2022.
    SAW: A real-time surveillance system at an agricultural warehouse using IoT, in:
    AI, Edge and IoT-Based Smart Agriculture. Elsevier, pp. 315–327. https://doi.org/10.1016/B978-0-12-823694-9.00001-3.
    Google Scholar Onwude et al., 2020 D.I. Onwude, G. Chen, N. Eke-emezie, A. Kabutey,
    A.Y. Khaled, B. Sturm Recent advances in reducing food losses in the supply chain
    of fresh agricultural produce Processes, 8 (2020), p. 1431, 10.3390/pr8111431
    Google Scholar Orfanos et al., 2023 Orfanos, V.A., Kaminaris, S.D., Papageorgas,
    P., Piromalis, D., Kandris, D., 2023. A Comprehensive Review of IoT Networking
    Technologies for Smart Home Automation Applications. JSAN 12, 30. https://doi.org/10.3390/jsan12020030.
    Google Scholar Pallagani et al., 2019 Pallagani, V., Khandelwal, V., Chandra,
    B., Udutalapally, V., Das, D., P. Mohanty, S., 2019. dCrop: A Deep-Learning Based
    Framework for Accurate Prediction of Diseases of Crops in Smart Agriculture, in:
    2019 IEEE International Symposium on Smart Electronic Systems (iSES) (Formerly
    iNiS). Presented at the 2019 IEEE International Symposium on Smart Electronic
    Systems (iSES) (Formerly iNiS), IEEE, Rourkela, India, pp. 29–33. https://doi.org/10.1109/iSES47678.2019.00020.
    Google Scholar Park and Kim, 2021 S. Park, J. Kim Design and implementation of
    a hydroponic strawberry monitoring and harvesting timing information supporting
    system based on nano AI-cloud and IoT-edge Electronics, 10 (2021), p. 1400, 10.3390/electronics10121400
    View in ScopusGoogle Scholar Patel et al., 2022 R. Patel, B. Mitra, M. Vinchurkar,
    A. Adami, R. Patkar, F. Giacomozzi, L. Lorenzelli, M.S. Baghini A review of recent
    advances in plant-pathogen detection systems Heliyon, 8 (12) (2022), p. e11855,
    10.1016/j.heliyon.2022.e11855 View PDFView articleView in ScopusGoogle Scholar
    Patel et al., 2022 P. Patel, Y. Patel, U. Patel, V. Patel, N. Patel, P. Oza, U.
    Patel Towards automating irrigation: a fuzzy logic-based water irrigation system
    using IoT and deep learning Model. Earth Syst. Environ., 8 (2022), pp. 5235-5250,
    10.1007/s40808-022-01452-0 View in ScopusGoogle Scholar Pérez-Ruiz et al., 2015
    M. Pérez-Ruiz, P. Gonzalez-de-Santos, A. Ribeiro, C. Fernandez-Quintanilla, A.
    Peruzzi, M. Vieri, S. Tomic, J. Agüera Highlights and preliminary results for
    autonomous crop protection Comput. Electron. Agric., 110 (2015), pp. 150-161,
    10.1016/j.compag.2014.11.010 View PDFView articleView in ScopusGoogle Scholar
    Pervez and Haq, 2019 Pervez, H., Haq, I.U., 2019. Blockchain and IoT Based Disruption
    in Logistics, in: 2019 2nd International Conference on Communication, Computing
    and Digital Systems (C-CODE). Presented at the 2019 2nd International Conference
    on Communication, Computing and Digital systems (C-CODE), IEEE, Islamabad, Pakistan,
    pp. 276–281. https://doi.org/10.1109/C-CODE.2019.8680971. Google Scholar Ping,
    2014 Ping, L., 2014. Agricultural Drought Data Acquisition and Transmission System
    Based on Internet of Things, in: 2014 Fifth International Conference on Intelligent
    Systems Design and Engineering Applications. Presented at the 2014 Fifth International
    Conference on Intelligent Systems Design and Engineering Applications (ISDEA),
    IEEE, Hunan, China, pp. 128–132. https://doi.org/10.1109/ISDEA.2014.36. Google
    Scholar Postolache et al., 2022 S. Postolache, P. Sebastião, V. Viegas, O. Postolache,
    F. Cercas IoT-based systems for soil nutrients assessment in horticulture Sensors,
    23 (2022), p. 403, 10.3390/s23010403 Google Scholar Pratama et al., 2021 H. Pratama,
    A. Yunan, R. Arif Candra Design and build a soil nutrient measurement tool for
    citrus plants using NPK soil sensors based on the Internet of Things Brilliance,
    1 (2021), pp. 67-74, 10.47709/brilliance.v1i2.1300 View in ScopusGoogle Scholar
    Pyingkodi et al., 2022 Pyingkodi, M., Thenmozhi, K., Nanthini, K., Karthikeyan,
    M., Palarimath, S., Erajavignesh, V., Kumar, G.B.A., 2022. Sensor Based Smart
    Agriculture with IoT Technologies: A Review, in: 2022 International Conference
    on Computer Communication and Informatics (ICCCI). Presented at the 2022 International
    Conference on Computer Communication and Informatics (ICCCI), IEEE, Coimbatore,
    India, pp. 1–7. https://doi.org/10.1109/ICCCI54379.2022.9741001. Google Scholar
    Rahman et al., 2019 Rahman, A., Ermatita, Budianta, D., 2019. Data Warehouse Design
    for Soil Nutrients with IoT Based Data Sources, in: 2019 International Conference
    on Informatics, Multimedia, Cyber and Information System (ICIMCIS). Presented
    at the 2019 International Conference on Informatics, Multimedia, Cyber and Information
    System (ICIMCIS), IEEE, Jakarta, Indonesia, pp. 181–186. https://doi.org/10.1109/ICIMCIS48181.2019.8985209.
    Google Scholar Ramalingam et al., 2020 B. Ramalingam, R.E. Mohan, S. Pookkuttath,
    B.F. Gómez, C.S.C. Sairam Borusu, T. Wee Teng, Y.K. Tamilselvam Remote insects
    trap monitoring system using deep learning framework and IoT Sensors, 20 (2020),
    p. 5280, 10.3390/s20185280 Google Scholar Ramson et al., 2021 S.R.J. Ramson, W.D.
    Leon-Salas, Z. Brecheisen, E.J. Foster, C.T. Johnston, D.G. Schulze, T. Filley,
    R. Rahimi, M.J.C.V. Soto, J.A.L. Bolivar, M.P. Malaga A self-powered, real-time,
    LoRaWAN IoT-based soil health monitoring system IEEE Internet Things J., 8 (2021),
    pp. 9278-9293, 10.1109/JIOT.2021.3056586 View in ScopusGoogle Scholar Rani et
    al., 2020 Rani, D.S., Jayalakshmi, G.N., Baligar, V.P., 2020. Low Cost IoT based
    Flood Monitoring System Using Machine Learning and Neural Networks: Flood Alerting
    and Rainfall Prediction, in: 2020 2nd International Conference on Innovative Mechanisms
    for Industry Applications (ICIMIA). Presented at the 2020 2nd International Conference
    on Innovative Mechanisms for Industry Applications (ICIMIA), IEEE, Bangalore,
    India, pp. 261–267. https://doi.org/10.1109/ICIMIA48430.2020.9074928. Google Scholar
    Rauf and Lali, 2021 Rauf, H.T., Lali, M.I.U., 2021. A Guava Fruits and Leaves
    Dataset for Detection and Classification of Guava Diseases through Machine Learning.
    https://doi.org/10.17632/S8X6JN5CVR.1. Google Scholar Razfar et al., 2022 N. Razfar,
    J. True, R. Bassiouny, V. Venkatesh, R. Kashef Weed detection in soybean crops
    using custom lightweight deep learning models J. Agric. Food Res., 8 (2022), Article
    100308, 10.1016/j.jafr.2022.100308 View PDFView articleView in ScopusGoogle Scholar
    Research and Markets, 2023 Research and Markets, 2023. IoT in Agriculture Market
    by Technology, Automation (Robots, Drones, and Smart Equipment), Sensor Types,
    Hardware, Software and Solutions 2023 - 2028. Google Scholar Reshma et al., 2020
    Reshma, R., Sathiyavathi, V., Sindhu, T., Selvakumar, K., SaiRamesh, L., 2020.
    IoT based Classification Techniques for Soil Content Analysis and Crop Yield Prediction,
    in: 2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics
    and Cloud) (I-SMAC). Presented at the 2020 Fourth International Conference on
    I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), IEEE, Palladam,
    India, pp. 156–160. https://doi.org/10.1109/I-SMAC49090.2020.9243600. Google Scholar
    Rezk et al., 2021 N.G. Rezk, E.-E.-D. Hemdan, A.-F. Attia, A. El-Sayed, M.A. El-Rashidy
    An efficient IoT based smart farming system using machine learning algorithms
    Multimed. Tools Appl., 80 (2021), pp. 773-797, 10.1007/s11042-020-09740-6 View
    in ScopusGoogle Scholar S et al., 2020 S R, P., T, N.K., C, N., Praveen, R., Ahmed,
    M.R., 2020. Technological advances in agriculture from pre-processing of land
    management to post-harvest management: A critical review. International Journal
    of Advanced Science and Technology 29, 3055–3067. Google Scholar Sah Tyagi et
    al., 2021 S.K. Sah Tyagi, A. Mukherjee, S.R. Pokhrel, K.K. Hiran An intelligent
    and optimal resource allocation approach in sensor networks for smart agri-IoT
    IEEE Sensors J., 21 (2021), pp. 17439-17446, 10.1109/JSEN.2020.3020889 View in
    ScopusGoogle Scholar Saha et al., 2018 Saha, A.K., Saha, J., Ray, R., Sircar,
    S., Dutta, S., Chattopadhyay, S.P., Saha, H.N., 2018. IOT-based drone for improvement
    of crop quality in agricultural field, in: 2018 IEEE 8th Annual Computing and
    Communication Workshop and Conference (CCWC). Presented at the 2018 IEEE 8th Annual
    Computing and Communication Workshop and Conference (CCWC), IEEE, Las Vegas, NV,
    pp. 612–615. https://doi.org/10.1109/CCWC.2018.8301662. Google Scholar Saha et
    al., 2022 Saha, H.N., Chakraborty, S., Roy, R., 2022. Integration of RFID and
    sensors in agriculture using IOT, in: AI, Edge and IoT-Based Smart Agriculture.
    Elsevier, pp. 361–372. https://doi.org/10.1016/B978-0-12-823694-9.00004-9. Google
    Scholar Saikia and Khatoon, 2022 D. Saikia, R. Khatoon Smart monitoring of soil
    parameters based on IoT IJATEE, 9 (2022), 10.19101/IJATEE.2021.874650 Google Scholar
    Sajja et al., 2021 Sajja, G.S., Jha, S.S., Mhamdi, H., Naved, M., Ray, S., Phasinam,
    K., 2021. An Investigation on Crop Yield Prediction Using Machine Learning, in:
    2021 Third International Conference on Inventive Research in Computing Applications
    (ICIRCA). Presented at the 2021 Third International Conference on Inventive Research
    in Computing Applications (ICIRCA), IEEE, Coimbatore, India, pp. 916–921. https://doi.org/10.1109/ICIRCA51532.2021.9544815.
    Google Scholar Sakthivel and Vidhya, 2021 S. Sakthivel, G. Vidhya A trust-based
    access control mechanism for intra-sensor network communication in Internet of
    Things Arab J Sci Eng, 46 (2021), pp. 3147-3153, 10.1007/s13369-020-05102-4 View
    in ScopusGoogle Scholar Sangeetha et al., 2021 M. Sangeetha, G. Thejaswini, A.
    Shoba, S. Santoshi Gaikwad, R.T. Amretasre, S. Nivedita Design and development
    of a crop quality monitoring and classification system using IoT and blockchain
    J. Phys.: Conf. Ser., 1964 (6) (2021), p. 062011, 10.1088/1742-6596/1964/6/062011
    View in ScopusGoogle Scholar Saraf and Gawali, 2017 Saraf, S.B., Gawali, D.H.,
    2017. IoT based smart irrigation monitoring and controlling system, in: 2017 2nd
    IEEE International Conference on Recent Trends in Electronics, Information & Communication
    Technology (RTEICT). Presented at the 2017 2nd IEEE International Conference on
    Recent Trends in Electronics, Information & Communication Technology (RTEICT),
    IEEE, Bangalore, pp. 815–819. https://doi.org/10.1109/RTEICT.2017.8256711. Google
    Scholar Sayanthan et al., 2018 Sayanthan, S., Thiruvaran, T., Kannan, N., 2018.
    Arduino based soil moisture analyzer as an effective way for irrigation scheduling,
    in: 2018 IEEE International Conference on Information and Automation for Sustainability
    (ICIAfS). Presented at the 2018 IEEE International Conference on Information and
    Automation for Sustainability (ICIAfS), IEEE, Colombo, Sri Lanka, pp. 1–4. https://doi.org/10.1109/ICIAFS.2018.8913355.
    Google Scholar Sazid et al., 2022 Sazid, M.M., Haider, I., Rahman, M.E., Nuhel,
    A.K., Islam, S., Islam, M.R., 2022. Developing a Solar Powered Agricultural Robot
    for Autonomous Thresher And Crop Cutting, in: 2022 12th International Conference
    on Electrical and Computer Engineering (ICECE). Presented at the 2022 12th International
    Conference on Electrical and Computer Engineering (ICECE), IEEE, Dhaka, Bangladesh,
    pp. 144–147. https://doi.org/10.1109/ICECE57408.2022.10089115. Google Scholar
    Sengupta et al., 2021 A. Sengupta, B. Debnath, A. Das, D. De FarmFox: A quad-sensor-based
    IoT box for precision agriculture IEEE Consumer Electron. Mag., 10 (2021), pp.
    63-68, 10.1109/MCE.2021.3064818 View in ScopusGoogle Scholar Seyar and Ahamed,
    2023 Seyar, M.H., Ahamed, T., 2023. Development of an IoT-Based Precision Irrigation
    System for Tomato Production from Indoor Seedling Germination to Outdoor Field
    Production. Applied Sciences 13, 5556. https://doi.org/10.3390/app13095556. Google
    Scholar Shadrin et al., 2019 D. Shadrin, A. Menshchikov, D. Ermilov, A. Somov
    Designing future precision agriculture: Detection of seeds germination using artificial
    intelligence on a low-power embedded system IEEE Sensors J., 19 (2019), pp. 11573-11582,
    10.1109/JSEN.2019.2935812 View in ScopusGoogle Scholar Shafi et al., 2020 U. Shafi,
    R. Mumtaz, N. Iqbal, S.M.H. Zaidi, S.A.R. Zaidi, I. Hussain, Z. Mahmood A multi-modal
    approach for crop health mapping using low altitude remote sensing, Internet of
    Things (IoT) and machine learning IEEE Access, 8 (2020), pp. 112708-112724, 10.1109/ACCESS.2020.3002948
    View in ScopusGoogle Scholar Shukla et al., 2021 R. Shukla, G. Dubey, P. Malik,
    N. Sindhwani, R. Anand, A. Dahiya, V. Yadav Detecting crop health using machine
    learning techniques in smart agriculture system JSIR, 80 (2021), pp. 699-706,
    10.56042/jsir.v80i08.44034 View in ScopusGoogle Scholar Siddiqua et al., 2022
    Siddiqua, F., M., S.R., Dolon, M.T., Nayna, T.F.A., Rashid, Md.M., Razzak, Md.A.,
    2022. IoT-Based Low-Cost Cold Storage Atmosphere Monitoring and Controlling System,
    in: 2022 International Conference on Wireless Communications Signal Processing
    and Networking (WiSPNET). Presented at the 2022 International Conference on Wireless
    Communications Signal Processing and Networking (WiSPNET), IEEE, Chennai, India,
    pp. 311–315. https://doi.org/10.1109/WiSPNET54241.2022.9767151. Google Scholar
    Singh et al., 2022 D.K. Singh, R. Sobti, A. Jain, P.K. Malik, D. Le LoRa based
    intelligent soil and weather condition monitoring with internet of things for
    precision agriculture in smart cities IET Commun., 16 (2022), pp. 604-618, 10.1049/cmu2.12352
    View in ScopusGoogle Scholar Sladojevic et al., 2016 S. Sladojevic, M. Arsenovic,
    A. Anderla, D. Culibrk, D. Stefanovic Deep neural networks based recognition of
    plant diseases by leaf image classification Comput. Intell. Neurosci., 2016 (2016),
    pp. 1-11, 10.1155/2016/3289801 View in ScopusGoogle Scholar Sonu and Chaudhary,
    2022 Sonu, Chaudhary, V., 2022. A Paradigm of Internet-of-Nano-Things Inspired
    Intelligent Plant Pathogen-Diagnostic Biosensors. ECS Sens. Plus 1, 031401. https://doi.org/10.1149/2754-2726/ac92ed.
    Google Scholar Sreekantha and Kavya, 2017 Sreekantha, D.K., Kavya A.M., 2017.
    Agricultural crop monitoring using IOT - a study, in: 2017 11th International
    Conference on Intelligent Systems and Control (ISCO). Presented at the 2017 11th
    International Conference on Intelligent Systems and Control (ISCO), IEEE, Coimbatore,
    India, pp. 134–139. https://doi.org/10.1109/ISCO.2017.7855968. Google Scholar
    Subahi and Bouazza, 2020 A.F. Subahi, K.E. Bouazza An intelligent IoT-based system
    design for controlling and monitoring greenhouse temperature IEEE Access, 8 (2020),
    pp. 125488-125500, 10.1109/ACCESS.2020.3007955 View in ScopusGoogle Scholar Suryawanshi
    et al., 2022 Yogesh Suryawanshi, Kailas PATIL, Prawit Chumchu, Yogesh Suryawanshi,
    2022. VegNet: Vegetable Dataset with quality (Unripe, Ripe, Old, Dried and Damaged).
    https://doi.org/10.17632/6NXNJBN9W6.1. Google Scholar Tao et al., 2021 W. Tao,
    L. Zhao, G. Wang, R. Liang Review of the internet of things communication technologies
    in smart agriculture and challenges Comput. Electron. Agric., 189 (2021), Article
    106352, 10.1016/j.compag.2021.106352 View PDFView articleView in ScopusGoogle
    Scholar Theparod and Harnsoongnoen, 2022 T. Theparod, S. Harnsoongnoen Narrow-Band
    Light-Emitting Diodes (LEDs) effects on sunflower (Helianthus annuus) sprouts
    with remote monitoring and recording by internet of things device Sensors, 22
    (2022), p. 1503, 10.3390/s22041503 View in ScopusGoogle Scholar Thorat et al.,
    2017 Thorat, A., Kumari, S., Valakunde, N.D., 2017. An IoT based smart solution
    for leaf disease detection, in: 2017 International Conference on Big Data, IoT
    and Data Science (BID). Presented at the 2017 International Conference on Big
    Data, IoT and Data Science (BID), IEEE, Pune, India, pp. 193–198. https://doi.org/10.1109/BID.2017.8336597.
    Google Scholar Tian et al., 2021 E. Tian, Z. Li, W. Huang, H. Ma Distributed and
    Parallel simulation methods for pest control and crop monitoring with IoT assistance
    Acta Agric. Scand. Sect. B — Soil & Plant Sci., 71 (2021), pp. 884-898, 10.1080/09064710.2021.1955959
    View in ScopusGoogle Scholar Tomaszewski et al., 2022 Tomaszewski, L., Kołakowski,
    R., Zagórda, M., 2022. Application of Mobile Networks (5G and Beyond) in Precision
    Agriculture, in: Maglogiannis, I., Iliadis, L., Macintyre, J., Cortez, P. (Eds.),
    Artificial Intelligence Applications and Innovations. AIAI 2022 IFIP WG 12.5 International
    Workshops, IFIP Advances in Information and Communication Technology. Springer
    International Publishing, Cham, pp. 71–86. https://doi.org/10.1007/978-3-031-08341-9_7.
    Google Scholar Truong et al., 2017 Truong, T., Dinh, A., Wahid, K., 2017. An IoT
    environmental data collection system for fungal detection in crop fields, in:
    2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering (CCECE).
    Presented at the 2017 IEEE 30th Canadian Conference on Electrical and Computer
    Engineering (CCECE), IEEE, Windsor, ON, pp. 1–4. https://doi.org/10.1109/CCECE.2017.7946787.
    Google Scholar Tseng et al., 2019 F.-H. Tseng, H.-H. Cho, H.-T. Wu Applying big
    data for intelligent agriculture-based crop selection analysis IEEE Access, 7
    (2019), pp. 116965-116974, 10.1109/ACCESS.2019.2935564 View in ScopusGoogle Scholar
    Udutalapally et al., 2021 V. Udutalapally, S.P. Mohanty, V. Pallagani, V. Khandelwal
    sCrop: A novel device for sustainable automatic disease prediction, crop selection,
    and irrigation in internet-of-agro-things for smart agriculture IEEE Sensors J.,
    21 (2021), pp. 17525-17538, 10.1109/JSEN.2020.3032438 View in ScopusGoogle Scholar
    Van Hilten and Wolfert, 2022 M. Van Hilten, S. Wolfert 5G in agri-food - A review
    on current status, opportunities and challenges Comput. Electron. Agric., 201
    (2022), Article 107291, 10.1016/j.compag.2022.107291 View PDFView articleView
    in ScopusGoogle Scholar Verploegen et al., 2018 Verploegen, E., Sanogo, O., Chagomoka,
    T., 2018. Evaluation of Low-Cost Evaporative Cooling Technologies for Improved
    Vegetable Storage in Mali, in: 2018 IEEE Global Humanitarian Technology Conference
    (GHTC). Presented at the 2018 IEEE Global Humanitarian Technology Conference (GHTC),
    IEEE, San Jose, CA, pp. 1–8. https://doi.org/10.1109/GHTC.2018.8601894. Google
    Scholar Vij et al., 2020 A. Vij, S. Vijendra, A. Jain, S. Bajaj, A. Bassi, A.
    Sharma IoT and machine learning approaches for automation of farm irrigation system
    Procedia Comput. Sci., 167 (2020), pp. 1250-1257, 10.1016/j.procs.2020.03.440
    View PDFView articleView in ScopusGoogle Scholar Vijayalakshmi et al., 2019 Vijayalakshmi,
    B., Ramkumar, C., Niveda, S., Pandian, S.C., 2019. Smart Pest Control System in
    Agriculture, in: 2019 IEEE International Conference on Intelligent Techniques
    in Control, Optimization and Signal Processing (INCOS). Presented at the 2019
    IEEE International Conference on Intelligent Techniques in Control, Optimization
    and Signal Processing (INCOS), IEEE, Tamilnadu, India, pp. 1–4. https://doi.org/10.1109/INCOS45849.2019.8951351.
    Google Scholar Virtual Cisco, 2017 Virtual Cisco, 2017, 2022. Cisco Visual Networking
    Index: Forecast and Trends, 2017–2022. URL https://twiki.cern.ch/twiki/pub/HEPIX/TechwatchNetwork/HtwNetworkDocuments/white-paper-c11-741490.pdf.
    Google Scholar Visvesvaran et al., 2021 Visvesvaran, C., Kamalakannan, S., Kumar,
    K.N., Sundaram, K.M., Vasan, S.M.S.S., Jafrrin, S., 2021. Smart Greenhouse Monitoring
    System using Wireless Sensor Networks, in: 2021 2nd International Conference on
    Smart Electronics and Communication (ICOSEC). Presented at the 2021 2nd International
    Conference on Smart Electronics and Communication (ICOSEC), IEEE, Trichy, India,
    pp. 96–101. https://doi.org/10.1109/ICOSEC51865.2021.9591680. Google Scholar Xu
    et al., 2022 J. Xu, B. Gu, G. Tian Review of agricultural IoT technology Artif.
    Intell. Agric., 6 (2022), pp. 10-22, 10.1016/j.aiia.2022.01.001 View PDFView articleView
    in ScopusGoogle Scholar Zhang et al., 2017 X. Zhang, J. Zhang, L. Li, Y. Zhang,
    G. Yang Monitoring citrus soil moisture and nutrients using an IoT based system
    Sensors, 17 (2017), p. 447, 10.3390/s17030447 Google Scholar Cited by (1) Towards
    Artificial Intelligence Applications in Precision and Sustainable Agriculture
    2024, Agronomy View Abstract © 2023 Elsevier B.V. All rights reserved. Recommended
    articles Intelligent methodologies: An integrated multi-modeling approach to predict
    adaptive mechanisms in farm animals Computers and Electronics in Agriculture,
    Volume 216, 2024, Article 108502 Robson Mateus Freitas Silveira, …, Iran José
    Oliveira da Silva View PDF Onfield estimation of quality parameters in alfalfa
    through hyperspectral spectrometer data Computers and Electronics in Agriculture,
    Volume 216, 2024, Article 108463 Angie L. Gámez, …, Iker Aranjuelo View PDF Dual
    sampling linear regression ensemble to predict wheat yield across growing seasons
    with hyperspectral sensing Computers and Electronics in Agriculture, Volume 216,
    2024, Article 108514 Shuaipeng Fei, …, Yuntao Ma View PDF Show 3 more articles
    Article Metrics Citations Citation Indexes: 1 Captures Readers: 29 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A comprehensive survey on IoT and AI based applications in different pre-harvest,
    during-harvest and post-harvest activities of smart agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - David P.E.
  - Chelliah P.R.
  - Anandhakumar P.
  citation_count: '0'
  description: Edge computing in the era of digital transformation is slowly gaining
    momentum across many industries. It is expected to reach around 75% by 2025. Edge
    computing is adopted by many industries including the agricultural industry. This
    technology is helping to build the future of agriculture with smart farming. Though
    cloud infrastructure has already played an important role in developing the agricultural
    sector, edge computing wins the race in terms of speed and efficiency. The opportunity
    lies within precision agriculture when edge computing is applied to smart farming
    technologies. While using edge computing technology farmers depend on data to
    obtain improved control over the industry and optimize the efficiency of their
    operations which results in reduced operational expenses. Agriculture is one of
    the world's critical industries and has traditionally been slower to advance and
    adopt modern technologies than other industries. But now changes are taking place
    as digitization is becoming more attainable. The agricultural sector is realizing
    the benefits of advanced technologies like AI, process automation, edge computing,
    IoT, etc. Edge computing is one of the evolving technologies that have the potential
    to bring transformation in the agricultural sector. Digitization can help in overcoming
    some of the biggest challenges in agriculture by using sensors, real-time data-driven
    insights, and actuators. There are numerous use case examples for smart farming
    and agriculture starting from keeping track of climate changes and regulating
    the crop or cattle conditions to greenhouse automation and even farm management
    solutions.
  doi: 10.1016/bs.adcom.2023.08.007
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full volume
    Outline Abstract Keywords 1. Introduction 2. Smart agriculture 3. Smart farming
    initiatives is the need of the hour 4. Commonly used sensors for smart farming
    and heavy metal identification 5. High performance computing on edge (HPCE) 6.
    Processing in agriculture 7. The proposed system References Further reading Vitae
    Show full outline Figures (8) Show 2 more figures Tables (4) Table 1 Table 2 Table
    3 Table 4 Advances in Computers Volume 132, 2024, Pages 167-204 Chapter Nine -
    Reshaping agriculture using intelligent edge computing Author links open overlay
    panel Preetha Evangeline David a, Pethuru Raj Chelliah b, P. Anandhakumar c Show
    more Share Cite https://doi.org/10.1016/bs.adcom.2023.08.007 Get rights and content
    Abstract Edge computing in the era of digital transformation is slowly gaining
    momentum across many industries. It is expected to reach around 75% by 2025. Edge
    computing is adopted by many industries including the agricultural industry. This
    technology is helping to build the future of agriculture with smart farming. Though
    cloud infrastructure has already played an important role in developing the agricultural
    sector, edge computing wins the race in terms of speed and efficiency. The opportunity
    lies within precision agriculture when edge computing is applied to smart farming
    technologies. While using edge computing technology farmers depend on data to
    obtain improved control over the industry and optimize the efficiency of their
    operations which results in reduced operational expenses. Agriculture is one of
    the world''s critical industries and has traditionally been slower to advance
    and adopt modern technologies than other industries. But now changes are taking
    place as digitization is becoming more attainable. The agricultural sector is
    realizing the benefits of advanced technologies like AI, process automation, edge
    computing, IoT, etc. Edge computing is one of the evolving technologies that have
    the potential to bring transformation in the agricultural sector. Digitization
    can help in overcoming some of the biggest challenges in agriculture by using
    sensors, real-time data-driven insights, and actuators. There are numerous use
    case examples for smart farming and agriculture starting from keeping track of
    climate changes and regulating the crop or cattle conditions to greenhouse automation
    and even farm management solutions. Previous chapter in volume Next chapter in
    volume Keywords Edge intelligenceSmart agricultureHybrid algorithmsEdge services
    1. Introduction The agricultural sector in developing countries has multiple challenges,
    i.e., if we look at the production side, the first challenge which the farmer
    faces is the productivity challenge, as it becomes evident that developing countries
    are very low in productivity, i.e., for any crop, the particular developing country
    could be the highest producer but at the same time its productivity could be very
    low. Therefore, crop productivity is a significant factor which has to be looked
    at. The second challenge which the farmer faces is with respect to climate change,
    industrial pollution, and pest attacks, as they can damage crops substantially.
    It is deemed necessary for the farmer to mitigate those challenges by adapting
    to the latest technologies and insurance schemes. The third challenge is related
    to market connectivity, whereby the farmer produces crops and thus needs to be
    connected to distant markets as per the crop production analysis and its subsequent
    data insights. It is essential for the farmers to have all the information on
    a digital platform and there should be seamless trade between different markets
    and different places. However, this connection between farmers and the distant
    market is nowhere to be seen in developing countries. On the other hand, the industry
    is looking up for exports, which in turn need to be streamlined substantially.
    From the economic perspective of the developing country, it is a boon if more
    facility in nature and regulatory support has to be given for people who are looking
    to export outside their country or who are looking to have a value-added product
    across the globe. Now, this mismanagement in the agricultural sector can potentially
    lead to food security risk. Precision Agriculture (PA) is intended to help and
    maximize the development of the farming sector and will also help to ensure food
    security [1]. It is to be highlighted that PA is a high-tech farming technology
    that observes, measures, and analyzes farming fields and crops. With the advent
    of PA, on-field sensors can provide detailed levels of data for problems of soil
    and weather conditions pertaining to heavy metal toxics and climate change. Big
    data obtained from sensor networks and farm inputs tracking have a significant
    role to play to increase farm productivity, reduce environmental impacts, and
    improve human welfare [2]. By combining artificial intelligence-based big data
    analytics with sensor and image data, an integrated system could be developed
    for the agricultural domain. Implementing intensive, high-value, personalized
    management of crops would increase both production and economic performance. The
    aim of this paper is to highlight the importance of smart sensors and high-performance
    computing in protecting stakeholders in the agrifood value chain and providing
    them with unlimited access to a large dataset of various categories in order to
    track their farms. The challenges and consideration for the farming sector in
    developing countries are also highlighted. Smart agriculture is always connected
    with high volumes of heterogeneous data sources such as autonomous tractors, harvesters,
    robots and drones, sensors, and actuators. Heterogeneous sensors and other devices
    collect relevant agricultural data such as humidity, temperature, pH, and soil
    conditions. Similarly, it considers the use of various actuators, such as water
    sprinklers, ventilation devices, lighting, automated windows (in glasshouses),
    and soil and water nutrition pumps that react according to the data. The number
    of cloud-based agricultural standalone systems and physical systems is increasing
    on an almost daily basis, helping to achieve a range of monitoring and analyzing
    objectives. Moreover, the last few years of publications have shown that modern
    computing paradigms such as Cloud, Fog, and Edge play a vital role in agriculture.
    The main applications of Cloud, Fog, and Edge Computing in agriculture are crop
    farming, livestock, and greenhouses, which are grouped into different application
    domains. Some of these applications are implemented with the help of IoT-based
    sensors and devices by using wireless sensor networks (WSNs), and some other applications
    are developed with combinations of new computing. For instance, Cloud and Fog,
    Cloud and Edge, Fog and Edge, or Cloud–Fog–Edge and IoT. 2. Smart agriculture
    Smart Agriculture or Smart Farming is an emerging concept that uses modern technologies
    in agriculture and livestock production to increase production, quantity, and
    quality, by making maximum use of resources and minimizing the environmental impact.
    This is demonstrated when farmers and all stakeholders related to agriculture
    use modern technologies and smart devices to monitor their farms, equipment, crops,
    and livestock. Using these devices, they can also obtain statistics on their livestock
    feeding and production of crops [3], [4], [5]. In recent years, smart farming
    has become helpful to all agricultural stakeholders from small to large scale.
    Smart farming provides benefits not only to scientists and agronomists but also
    to farmers to access modern technologies and devices that help in the maximization
    of product quality and quantity while reducing the cost of farming [3]. Smart
    farming mainly focuses on soil fertility, energy, grassland, water, feed, inputs
    and waste, machinery, and time management [6], [7]. The integration of modern
    technologies with agriculture achieves the objectives of smart agriculture such
    as efficiency, sustainability, and availability [8], increased production, water-saving,
    better quality, reduced costs, pest detection, and animal health [9], [10]. The
    other aims are to increase the reliability of spatially explicit data [3], make
    agriculture more profitable for the farmer [3], and offer the farmer the option
    of actively intervening in processes or controlling them [11]. Moreover, big data
    analysis is another goal of smart farming. Big data consist of massive volumes
    and a wide variety of data that are generated and captured by agricultural sensors
    and actuators. In particular, data collected from the field, farm, animals, and
    greenhouses include information on planting, spraying, materials, yields, in-season
    imagery, soil types, and weather. Big data analysis provides efficient techniques
    to do a quality analysis for decision-making [12]. In the coming years, smart
    agriculture is projected to create a significant impact on the world agricultural
    economy by applying all modern technologies. Edge AI will transform the agriculture
    industry. In most cases, farmlands are localized where there is no availability
    of high-speed bandwidth, inappropriate resources to handle data, and it is also
    found that the farmers are not adequately educated about the best practices of
    agriculture. AI practices as follows: 1. Soil quality: Examining the soil moisture
    using a mobile device by checking the farm location and the soil color. 2. Milch
    animals'' health: Tracking the health of livestock by tagging the sensors will
    give the temperature, heart rate etc. and provide insights about the health condition.
    3. Crop Health Analysis: A predictive computation engine, such as drones, can
    be used to check the health of leaves based on color and the pores it has, whether
    attacked by insects, pests, or rodents. 4. Disaster protection: Using edge computing,
    agriculture IoT systems can make informed decisions about potential environmental
    hazards or natural disasters. 5. Examining leaves health: A predictive computation
    engine, such as drones, can be used to check the health of leaves based on color
    and the pores it has, whether attacked by insects, pests, or rodents. 6. Analyzing
    satellite imagery: Deep analysis of satellite images provides an understanding
    of agricultural systems. With the help of Geo-spatial data, farmers can get information
    on crop distribution patterns across the globe along with the impact of weather
    changes on agriculture, among other applications. 7. Assess crop and soil heat:
    Predict the effect of different microbes on the health of plants and identify
    genetic changes that may cause due to harmful pathogens for the plant, among other
    things. 8. Predictive Analytics: Predictive models in AI help to do seasonal analysis,
    represent different market scenarios and optimize business costs. So, here are
    some of the opportunities that can be brought in by edge computing: 2.1. Ag robots
    Autonomous tractors and robotic machinery can run automatically without the intervention
    of humans, and this can be done with the help of edge computing. The tractors
    can communicate with nearby sensors to acquire necessary data about the surrounding
    environment. Ag robots can evaluate the most efficient ways to cover the required
    area taking into consideration the type of task performed, number of vehicles
    existing in the field, size of apparatus, etc. Edge computing will enable the
    ag robots to use computer vision and pre-loaded field data and to interpret the
    insights from that data. Additionally, the automated tractors can reroute automatically
    if there is any obstacle like if there is any animal or human in the way. Such
    smart implements can execute a broad range of tasks, like watering, weeding specific
    field areas when needed, or even autonomously harvesting crops. 2.2. Farm automation
    Similar to ag robots, a greenhouse or even a whole farm can be put on autopilot
    using IoT edge computing. This indicates that the whole ecosystem can perform
    the tasks itself without depending on a remote server to process the accumulated
    data and make decisions about day-to-day processes like feeding the cattle, watering
    the plants, controlling the temperature, humidity, light, etc. Edge computing
    will enable the farm or greenhouse to work without depending on the connection
    to the main server and make decisions based on data from local sensors. This can
    result in improved process reliability and reduced waste, making agriculture a
    more sustainable process. 2.3. Disaster protection Agriculture IoT systems can
    make sophisticated decisions about possible environmental hazards or natural disasters
    with the help of edge computing. Remote sensors can accumulate and examine data
    regarding the changes in the weather or the environment to forecast possible disasters.
    If there are definite indications of danger, they can instantly process the information
    to the general control center. Farmers thus will be able to take real-time appropriate
    measures to shield their crops. It is expected that the dependence on edge computing
    by enterprise-owned IoT devices will reach 6.5 billion in the coming year. Agriculture
    now has all the opportunities to lead the innovation in this field including manufacturing,
    transportation, energy, retail, and healthcare. This indicates that we can predict
    more edge computing use cases in agriculture soon. 3. Smart farming initiatives
    is the need of the hour With the advent of Internet of Things (IoT), smart devices
    have reached into all facets of our day-to-day life, i.e., healthcare and wellness,
    smart homes, automobile and logistics, intelligent cities and industries. In recent
    decades, agriculture has seen a series of technological changes, increasingly
    industrialized and technologically driven. Through different agriculture-based
    smart devices, farmers today now have greater control over animal husbandry and
    cultivation processes, making them more predictable and productive. This, along
    with the rising market demand for agricultural products, has helped to increase
    the worldwide proliferation of intelligent agriculture technologies. Modern agriculture
    can be addressed in several respects. For instance, AgriTech refers to the use
    of technology in the domain of agriculture. In addition, intelligent agriculture
    is primarily used to describe the use of IoT-based agricultural solutions. With
    IoT sensors, farmers can make informed decisions and develop various parameters
    of their work, i.e., cattle to crop production, in order to collect environmental
    and machine metrics. For example, farmers can decide exactly how much pesticide
    and fertilizer is to be utilized to optimize productivity by using smart agriculture
    sensors for monitoring crop status. The same applies to the concept of intelligent
    farming. Fig. 1 shows a broader perspective on a modern-day agricultural model,
    which incorporates various wireless sensor nodes to enable IoT-based farming with
    satellite communication, where different ground sensors are deployed which communicate
    with the cloud computing node for data processing and analysis, so that farmers
    can make correct decisions. Download : Download high-res image (249KB) Download
    : Download full-size image Fig. 1. Edge architecture. Although smart IoT and industrial
    IoT are not as common as consumer-connected devices, the market continues to be
    very competitive. IoT technologies are increasingly being implemented for agriculture.
    COVID-19 has had a positive impact on IoT market share in agriculture. Indeed,
    the smart framing market share is expected to hit $6.2 billion by the end of 2021,
    as reported recently. It is evident that COVID-19 has made a significant impact
    on the farming sector across the world. However, the agricultural sector is showing
    potential to make a strong comeback by leveraging positive government policies
    which indicate adoption of advanced technologies by making substantial investment
    in the agricultural sector. This initiative will make room for IoT-based agricultural
    solutions as a prominent business strategy, thus causing a reasonable increment
    in crop production. However, in the current situation, the market is expected
    to show a decline up to 0.8% for the first two quarters of year 2021 compared
    to 2020 and this trend will show a positive growth from 2022 onwards. In addition
    to this, the smart world agriculture market is projected to triple to 15.3 billion
    dollars by 2025, compared to just over 5 billion dollars back in 2016. If the
    sector continues to expand, there will still be plenty of opportunities for companies.
    In the coming years, creating IoT products for agriculture will distinguish companies
    as early adopters, thus helping to pave the way for success. This model can be
    used for any other application domain with some minor changes based on the domain
    requirements. In the proposed architecture, the Cloud layer is mainly for ample
    scale data storage and data analytics. This layer is also responsible for loading
    algorithms and data analytical tools to Fog nodes. This can also be used to store
    backup data for future analysis. The Fog layer is essential in this model, and
    this will be installed in local farms. Fog layers will be responsible for real-time
    data analytics such as predicting pests and diseases, yield prediction, weather
    prediction, and agricultural monitoring automation. Moreover, this will make decisions
    on real-time data and do reasoning analysis as well. Finally, the processed and
    analyzed data can be uploaded to the Cloud layer for backup purposes or further
    analysis. The third layer is the Edge, consisting of end devices, tractors, sensors,
    and actuators. The main goal of this layer is the collection of data and its transfer
    to the Fog layer. 4. Commonly used sensors for smart farming and heavy metal identification
    Sensors for Soil Moisture (SM) have been used in crop fields for decades to measure
    water content. The use of handheld/manual soil moisture technology is increasingly
    being replaced by automated technologies, since there were difficulties in manual
    soil moisture readings in remote production areas. In the past decade, technology
    has been developed for wireless data collection, providing managers and users
    with real-time access to soil moisture data, resulting in more successful water
    management decisions. Some of the prominent sensing devices to measure soil moisture
    comprise gravimetric sampling, resistive sensors, capacitive sensors, and Ground
    Penetrating Radar (GPR). Gravimetric sampling is a direct and normal SM measurement
    tool. SM is determined by a proportion of dry soil mass to wet soil mass including
    pores. It needs the manual drying of soil samples taken from the field and oven
    sampling. The electrical conductivity of water and the measuring of resistance
    changes based on soil water content are primarily resistive sensors, such as granular
    matrix sensors. This method includes sensor calibration for precise SM reading.
    Intelligent irrigation-based measurement to maintain soil moisture levels is significant
    to improve plant productivity and quality. On the other hand, soil moisture sensors
    these days are expensive, i.e., the ECHO-EC5 soil moisture sensor costs around
    USD 169. In order to overcome the cost constraint factor, Wang et al.proposed
    an RFID-based GreenTag sensor to maintain and improvise plant productivity and
    quality. In addition, RFID sensors can be combined with biosensors comprising
    aptamer and DNA-based properties which can be used to detect heavy metals at nanoscale
    and large scale levels pertaining to food safety monitoring. A heavy metal detection-based
    biosensor is composed of genetically modified bacterial cells and a green fluorescent
    signal amplifier which detects the presence of arsenite in foods. Its arsenic
    detection lasts for an hour with a detection range of 5–140 μg/L. Other methodologies
    pertaining to biosensors, i.e., aptamers and graphene electrodes, have also been
    used to detect arsenic with the possibility of being developed as simple and easy-to-use
    low-cost devices. The EC-5 series sensors were also used by Wu et al. for field-specific
    calibration and evaluation in sandy soils. Nonetheless, EC-5 sensors have turned
    out to be helpful to reveal soil water content dynamics in different soil depths
    post rainfall conditions. The ECHO series has other variants of sensors; i.e.,
    ECHO-EA10 can be used for medium textured soil type with low electrical conductance
    conditions. In addition to this, there is ECHO-10HS soil moisture sensor which
    is a new addition in the soil moisture sensor family and possesses high-frequency
    oscillation, which enables the sensors to accurately measure soil moisture in
    any of the soil or soilless media with minimum salinity and textural effects.
    In order to measure soil water content and salinity, Zemni et al. used 5TE sensors
    at different soil depths to assess dielectric permittivity (Ka) and electrical
    conductivity (ECa). It is to be noted that 5TE sensors are based on frequency
    domain reflectometry (FDR); therefore, they use a fixed frequency wave of broadband
    signal which makes the device cheaper and more compact. Nolz et al. deployed hydro
    probe2 sensors to evaluate near surface soil water and determine in situ water
    retention function. Hydro probe sensors are advantageous due to their linear signal
    response. On the contrary, hydro probe sensors are not suitable for sandy soils.
    Udukumburage et al. used an MP406 soil moisture sensor to verify the saturated
    condition of the expansive soil layer. They also used this sensor to measure volumetric
    water content values in the soil column during the wetting and drying process.
    In order to maintain the indoor ecosystem services, air quality plays an essential
    role. In this regard, MIKROE gas sensors are used to monitor the air quality.
    To evaluate and assess the vegetation change and study physiological and metabolic
    response of corn fields and paddy fields, the Pogo II VWC has been widely used.
    Hu et al. used Portable X-ray Fluorescence Spectroscopy (PXRF) to assess the heavy
    metal content in soil for which they covered 301 farmland soils from Fuyang in
    Zhejiang Province, in the southern Yangtze River Delta, China. Conventional methods
    for heavy metal detection such as Atomic Absorption Spectrometry (AAS), Atomic
    Fluorescence Spectrometry (AFS), and Inductively Coupled Plasma Optical Emission
    Spectroscopy (ICP-OES), are expensive and lengthy procedures which are executed
    in laboratories. Therefore, these methods are not taken into consideration for
    rapid testing and high-density evaluation of soil heavy metals contamination.
    As an alternative method for rapid heavy metal detection, Portable X-ray Fluorescence
    (PXRF) was used to assess cumulative concentrations of soil heavy metals based
    on linear regression models between fluorescence intensity and specific heavy
    metal concentration. Due to its ease of use and rapid testing ability using non-destructive
    quantification, PXRF has been widely used by researchers in numerous domains.
    For the heavy metal assessment in agricultural soil conducted by Hu et al. VNIR
    sensor was used to anticipate soil properties comprising pH, soil nitrogen, and
    carbon. In addition to PXRF, NixPRO color sensor can also be used to identify
    hotspots and total spatial area in excess of environmental thresholds in landfill
    soils. Lately Zhao and Liu have developed a Portable Electrochemical System (PES)
    for on-site heavy metal detection on farmland. Their system was composed of a
    three-electrode configuration which comprised a signal acquisition system integrated
    with a microcontroller-based potentiostat to perform square-wave anodic stripping
    voltammetry. Their system was assessed by testing the detection of pd.(II) and
    cd(II) in acetic acid soil extracts and acetate buffer solution. However, their
    system did not include any wireless sensor module to transmit heavy metal composition
    data. Other than the aforementioned sensors, there are several other wireless
    sensors dedicated to: photosynthesis, i.e., Beta Therm temperature sensor; leaf
    wetness sensor, i.e., SLWA-M003; precision sensor for leaf temperature, i.e.,
    ΔLA-C; light intensity sensor, i.e., BH1750FUI sensor. With the advent of these
    sensors, CO2 sensors also play an essential role, especially in greenhouse systems.
    CO2 sensors have also been widely used to measure the subsequent level in peat
    soil, landfill, and forest control site. In the smart farming ecosystem, the growth
    and quality of the fruit bunch cannot be neglected. In this regard, there are
    dedicated fruit growth monitoring sensors which researchers have used in their
    domain of plantation. Thalheimer designed an optoelectronics sensor for monitoring
    fruit and stem radial growth. Their developed sensor was lightweight and easy
    to install with low maintenance. Nonetheless, the sensor was well tested in open
    field conditions. In addition to this, the effect of gas concentration during
    the fruit growth was studied by Ma et al., for which a smart ethylene electrochemical
    sensor was established to investigate ethylene emission from fruits. Lately, Hanssens
    et al. came up with a heat field deformation sensor to measure sap flow dynamics
    through the tomato peduncle. Heat griddling of the peduncle was performed to differentiate
    flow of xylem and phloem with respect to developing fruits. Capacitive sensors
    calculate SM on the basis of changes in soil capacitance due to differences in
    water content. Commercial UTs use capacitive sensors, which are usually more accurate
    than resistive sensors but cost more. Ground Penetrating Radars (GPR) are based
    upon electromagnetic wave absorption and reflection. SM sensing uses impulses,
    frequency sweeping, and frequency-modulated technologies. This method is used
    for measuring soil moisture near the surface (up to 10 cm). The most reliable
    soil humidity samples used in fields are neutron scattering samples and scattering
    samples use radiation methods for calculating SM by estimating changes to the
    neutron flux density due to water content of the soil. However, in such cases,
    specific licenses are required to carry out its implementation. Numerous research
    studies have been performed to develop electrochemical devices for various applications,
    which are known as potentiostat. Lately, an Arduino-based potentiostat was fabricated
    from cost-efficient components and was able to execute simple electrochemical
    experiments, whereby the results were recorded and analyzed in a Windows operating
    system via USB interface. As an addition to Arduino-based potentiostat, Raspberry
    Pi (RPi) controller was also used to execute the electrochemical experiments,
    whereby the results were displayed on the LCD touch panel connected to the controller.
    Both Arduino- and Raspberry Pi-based potentiostat have the potential to incorporate
    wireless sensors for data transmission; however, these controllers do not contain
    a built-in Analog to Digital Converter (ADC) and Digital to Analog Converter (DAC)
    which make the overall design more sophisticated. In this regard, Hanisah et al.
    came up with a portable Heavy Metal Potentiostat (HMstat) to detect heavy metal
    composition on-site. Their potentiostat comprised a digital Control Signal Component
    (CSC) and the electronic component, which is the analog Potentiostat Read-out
    Circuit Component (PRCC), Nonetheless, it is worth noting that both the Arduino
    and RPi controller board do support the incorporation of various sensor modules.
    Therefore, researchers have room to incorporate soil moisture and temperature
    sensors along with other sensors depending on the slots available in the controller;
    thus, an integrated system for soil moisture and heavy metal analysis can be developed.
    Other soil physical properties can be calculated to populate the map of the soil
    with other soil properties such as soil organic content, pH, sand, silt particles
    percentage, and nutrients such as Mg, P, OM, Ca, base saturation Mg, base saturation
    K, base saturation Ca, CEC, and K/Mg. In situ, calculating these properties in
    real time also faces challenges due to scale, cost, and technology limitations.
    In precision farming, some of the long-lasting decisions can be taken using yield
    monitoring. This method helps in providing spatial distribution of crop yields
    at the end of the growing season. Yield sensors are normally mounted on farm equipment
    and capture yield data automatically in the course of the harvest. In particular,
    mass flow sensors on grain containers are mounted to record grain inflows along
    with the position. The collected data are analyzed with tools such as ArchInfo,
    Mapinfo, and Environment System Analysis International. In order to get an insight
    into the crop yield combined with field topography, Electrical Conductivity (EC)
    sensors are used. Soil''s ability to conduct current is measured by electrical
    conductivity. EC assessment is used to assess the use of phosphorus, cations in
    water, drainage, and rooting depths. EC maps are used for zoning the area. The
    zoning is also used to incorporate precision agricultural practices such as variable
    rate irrigation, variable rate seeding, and drainage management. Electromagnetic
    Induction (EMI) methods can be used for the mapping of the EC by apparent Electrical
    Conductance (ECa) and Visible Near Infrared Reflectance (VNIR). There are a number
    of commercial tools available, i.e., Veris 3100, EC400 sensors in conjunction
    with GPS systems. In the domain of soil sensing, macronutrients such as nitrogen,
    potassium, and phosphorus are essential to the growth of crops. The evaluation
    of these nutrients helps to assess the effects of fertilizer and potential applications.
    The optical detection is based on reflectance spectroscopy to measure the macrosimulation''s
    reflection and absorption. A sensing system using planar electromagnetic sensors
    has been developed in the detection of nitrate and sulphate concentration in natural
    water resources. This approach is used to detect the amounts of nitrate and sulphates
    by correlating the impedance of the sensor array with their concentration. The
    key approaches to soil macronutrients include electrochemical, VIS-NIRS, and ATR
    spectroscopy. These approaches to soil macronutrients are limited to sensing a
    single desired ion because the membrane used in these methods only reacts to one
    ion. To achieve a simultaneous multi-ion sensing, it is necessary to build a detector
    array for the sensing of soil macro nutrients. There are several opportunities
    to advance the state of precision farming through the utilization of the above
    discussed sensors. 5. High performance computing on edge (HPCE) This new High-Performance
    Computing (HPC) solution seeks to move beyond the agricultural services offered
    on edge and provide a comprehensive platform for precision farming and animal
    husbandry and furnish with utility not only for farmers but also for stakeholders.
    The HPCE architecture is adapted from CYBELE conceptual framework. The HPCE model
    uses open and proprietary vast amounts of datasets, including sensor readings,
    as well as satellite data and historic climatic and environmental information
    for ready reference. While this would be the most effective way to use HPC technology,
    it only uses the latest software platforms and projects that are being developed
    by HPCE''s e-controlled services, as well as increased HPC e-infrastructure to
    enable huge heterogeneous data processing to be done and find modern solutions
    to complex problems using dedicated algorithms. Due to the interconnection of
    large-oriented approaches, varying datasets, and available big data techniques,
    it is possible to scale distributed big data research to enormous scales when
    holding many types of datasets together in one place. In doing so, it enables
    the aggregated data and metadata to be aligned semantically to a standard scheme
    and data model and enables advanced data analytics to take secret information
    into account. In addition to this, the HPCE architecture will also help in gaining
    insights from adaptive data visualization services. With reference to CYBELE,
    the architectural approach of the HPC on edge and by organizing a product component
    based on interdependencies, this is intended to highlight the importance of pipelines
    being constructed to promote compatibility and show how to maintain the integrity
    of interdependent services. It is worth noting that CYBELE resonates well with
    the EdgeX platform architecture. EdgeX platform comprises four core services,
    i.e., device services, core services, supporting services, and application services
    to enable smooth workflow optimization. In addition, it will be interesting to
    see a synchronization of EdgeX with a dedicated HPC framework for faster batch
    processing of data over edge. Big, heterogeneous data are made available through
    repositories powered by HPC which is responsible for the processing at the edge
    layer. In this regard, HPC frameworks such as Spark, Hadoop, YARN, Big Deep Learning
    (BigDL), Directed Acyclic Graph (DAG), and Kubernetes are deployed for the batch
    processing of data using distributed framework attached to the edge layer. It
    is worth noting that Spark and BigDL are the widely used frameworks in many organizations
    for their open source and high degree of interoperability features. Spark and
    BigDL are based on MapReduce framework which has high room for tuning for smooth
    workflow optimization. The transmission of the application process interface along
    with data from the cloud layer to the edge layer is conducted using 4G/5G or fiber/DOCSIS/DSL
    communication system. This is seen on the middle section of the architecture.
    At first, the data are processed in the background prior to being passed on to
    the check-in stage for data validator or timestamp validator for resolution of
    data verification and timing problems. Once data are obtained in edge layer, quality
    checks are conducted to identify anomalies and any other data irregularities,
    maintaining their accuracy and validity, which are accompanied by a series of
    measures aligned with processes of data cleansing. Finally, the HPE data provenance
    service provides the mechanisms required for recording all relevant information
    concerning incoming data of interest. With HPE, the data provenance platform is
    inherently connected to the data policy and asset brokerage engine that enables
    the platform to bind data providers and data users with data share and business
    features. In addition to facilitating interoperability and reuse of data, the
    inspected data are annotated and harmonized semantically. Since the data come
    from a variety of physically distributed data sources, a standard data model will
    be created for the semantic definition and annotation of the data. To facilitate
    the pipeline and allow the various heterogeneous components to communicate seamlessly,
    the model will be used as a common language to annotate data and exchange messages
    between the components. Clean and semantically uplifted data are then available,
    i.e., open and proprietary data to be queried, analyzed, and viewed. An exemplification
    of how ground sensors have their data stored and analyzed at cloud data base.
    The on-field data are continuously assessed by a real-time monitoring system to
    ensure triggering effects if any threshold point is crossed. Simultaneously, the
    on-field data are also stored in the cloud database from where the user can download
    the required data and at the same time, data analysis could be applied using the
    machine learning tools stored over the cloud database. To facilitate simulation
    execution, a defined experimental composition setting is designed, as shown in
    the top right part of the architecture (cloud layer). The composition framework
    of experiments aims to support the separate design, development, and execution
    of big data research procedures, the support of embedded scientific computation
    and reproductive tests. In the analysis method, its subsequent template is selected
    to provide each analytical template with its own software and execution endpoint
    and allow the user to modify the appropriate configuration variables (i.e., input
    algorithm, execution parameters, netting parameters, and output parameters). The
    results of each analytical template are presented. The composition system for
    experiments will promote the design and implementation of data analysis workflows
    consisting of a number of data analysis procedures, interconnected in terms of
    data sources and input and output artifacts. The outcome will constitute the input
    to another research template when a template is executed. The output of the research
    model is an object for session that contains all the memory output values. In
    addition to big data, advanced analysis must be implemented when selecting input
    datasets and developing workflows. For HPCE, advanced analytical algorithms are
    available to stakeholders that allow them to explore various forms of data visually
    and to find and solve new trends. In order to achieve improved delivery and monitoring,
    machining and predictive modeling methods should be modified so as to handle the
    predictive life cycle of data planning, detection, and analysis. However, the
    implementation of advanced analytics along with huge, complex data increases the
    need for strong computing power and a higher processing memory, so that information
    can be collected within a realistic timeframe. When the test cases are executed,
    multiple HPC attributes are needed, including storage power, speed of the device,
    memory capacity, and quick turnaround time. The next section discusses the IoT-based
    communication methodologies in edge computing used for precision farming developed
    by several researchers. 6. Processing in agriculture Edge Computing is like a
    specialization of the Internet of Things. Without it, all data collected through
    IoT devices are sent to a cloud centre for processing. With the new technology,
    on the other hand, the collected data is classified locally, so that part of it
    is processed right there, on the “edge” of the network, hence the name edge computing
    through micro data centres. Thus, only certain information is sent to a cloud
    centre, while those that often need to be consulted are analyzed on the device
    itself in the case of agribusiness, in the field reducing data traffic. This ability
    to perform advanced analytics close to the data source meets the market''s need
    to cope with increasing traffic demands. As there is a screening of the information
    that will be sent to the processing centre, transfer rates are optimized. The
    main benefits of Edge Computing are the reduction in bandwidth required for sending
    and processing data and the decrease in latency, which is the response time of
    a request — the period in milliseconds that a data takes to navigate from where
    it was generated to where it will be processed. Both advantages are possible due
    to the proximity between the processing location and the origin of the information;
    only with cloud computing, on the other hand, all data would need to travel long
    distances before returning to consumption. In practice, this reduction in latency
    helps in real-time data access, which is essential for the implementation, with
    maximum effectiveness, of digital and intelligent solutions in agricultural processes.
    Certain functions can be performed on the equipment itself through Edge Computing,
    making it easier to make smarter and more agile decisions. Another example is
    the use of this technology in an agricultural spraying activity, in which sensory
    devices are enabled to determine alone which area should be sprayed, using the
    data collected and analyzed by the devices themselves. As Edge Computing also
    reduces the bandwidth required for processing, the solution becomes even more
    useful for agricultural applications. In the current context, in which IoT solutions
    already allow wide integration between various products, such as sensors, on-board
    computers, edge computing machines, is playing an increasingly important role
    in the application and evolution of technology in the field. It is one of the
    technologies that will have increasing adoption in the coming years, accelerating
    the consolidation of the digital transformation of agribusiness. 7. The proposed
    system The proposed learning model for irrigation is implemented in a prototype
    IoT system that has four components: (i) Edge node layer — This layer consists
    of sensors, actuator, and two microcontrollers. In this layer, edge node acquires
    the sensor data from the surroundings and controls the actuator for actuating
    water pumps to start irrigation. (ii) Edge server layer — This layer consists
    of Raspberry Pi that act as edge server and capable of multitask processing. Here,
    edge server controls the edge nodes for sending signal and receiving data at regular
    interval of time. It is also connected to the cloud server for receiving developed
    and trained machine learning model to be deployed and make irrigation decision
    for controlling edge nodes. (iii) Edge service layer — This layer is deployed
    in the edge server and it is responsible for controlling the whole system through
    a developed web dashboard. The dashboard has live feed data, control of edge nodes,
    and cloud services access. This service layer also has the control access of the
    proposed machine learning model. (iv) Cloud server layer — This layer composed
    of cloud services and cloud storage where its role is to train the machine learning
    model and store the data in database. It sends the trained proposed model to the
    edge server for decision-making regarding irrigation scheduling. The comprehensive
    interconnections in the system are shown in Fig. 2. Download : Download high-res
    image (339KB) Download : Download full-size image Fig. 2. Proposed smart irrigation
    system. The proposed IoT-based smart irrigation system includes five major components:
    field deployed module, Web-based interface, Web API weather input, soil moisture
    prediction mechanism, and edge communication model. 7.1. Web-based interface The
    proposed framework consists of a web-based application to allow farmers visualize
    the growing data and interacting with the garden in real time. In addition, users
    can also be able to examine and analyze the historical growing data, if needed,
    through functionalities such as irrigation control, motor control prediction model
    deployment, and manual data entry implemented in this web application. Here, Node.js
    was chosen for developing the web application [13], [14], while Huang [15] was
    utilized as the database system. Data stored in the database, which is deployed
    in the cloud, will be used for further data analysis in the future. The web application''s
    functions are designed as a software design pattern called model-view-controller
    (MVC). In the frontend, ChartJS is used to represent data through dynamic charts.
    The web application is also used as an interface to manage all the physical devices/actuators
    in the garden. To deploy the web-server to the cloud, a cloud platform as a service
    (PaaS), namely, Heroku, had been utilized. Heroku is a cloud platform that provides
    platform as a service (PaaS), facilitates the creation of applications and deploying
    these online rapidly [16], [17]. It also enhances scalability and functionality
    by integrating several add-on services. The field data are sent to the server
    by Raspberry Pi using this web service. This web service manages the network outage/fluctuation
    during data synchronization from the field device to the server by taking the
    help of flag settings at the database level. The interface facilitates the scheduling
    of irrigation along with visualizing real time sensors and predicted soil moisture
    for upcoming days and precipitation information. By using the denoted threshold
    value of soil moisture suggested by agronomists, the irrigation can be scheduled
    by the user. The system maintains the threshold value depending on the predicted
    pattern of soil moisture and precipitation information. The process of irrigation
    is initiated automatically and stopped after the specified threshold value generated
    from the proposed algorithm of soil moisture when it is reached. 7.2. Edge communication
    model The communication protocols in the proposed framework are flexible and transparent
    in nature for accepting both wired and wireless methodologies. For the maximum
    utilization of potentiality in edge computing components, the communication among
    various components in the edge-IoT system requires intense probing by using the
    versatility among the devices in network edges. For transferring the data gathered
    from pivot sensors, a communication technology such as Zigbee [18] is needed for
    the irrigation systems. Therefore, the communication component in the proposed
    work is classified into three main areas as shown in Fig. 3. Download : Download
    high-res image (451KB) Download : Download full-size image Fig. 3. Edge communication
    model. The Message Query Telemetry Transport (MQTT) protocol is used for the communication
    in the proposed system. The analysis in ref. [19] presented seven IoT messaging
    protocols (MQTT, CoAP, XMPP, AMQP, DDS, REST-HTTP, and WebSocket) as communication
    protocols that play a major role in smart farming. The authors have concluded
    that MQTT proved to be the most secure protocol after probing all the protocols
    with respect to latency, energy and bandwidth requirements, throughput, reliability,
    and security. Moreover, MQTT is secure in both end-to-end architecture and gateway
    server architecture. In an MQTT setup, a MQTT server termed as MQTT broker executes
    on the IoT solution [20]. Under a common identifier, a “publisher” and a “subscriber”
    link among themselves to this broker. In the IoT solution, publishers and subscribers
    are the IoT devices and IoT hubs or control devices, respectively. When the publishers
    have new data for recording, the data are published to the broker. The broker
    then flags that it has new publisher data, and the corresponding data are read
    by the subscriber. Then, the subscriber analyzes the data and reacts accordingly.
    The first level accomplishes with connecting the end users to system with the
    help of mobile or web-based applications through the Internet. The next level
    (cloud computing server) deals with the connection of web server and MQTT broker
    for directing the user requests and other components at the edge landscape or
    from the farms to the right cloud-based services like displaying the real time
    status of the farm for the users, triggering a new deployment of the updated ML
    model to the corresponding edge node. The third level (farming area) is directed
    toward the deployment of sensors and IoT devices (actuators) for communicating
    with other components in the entire system. 7.3. Deployment of soil moisture prediction
    hybrid algorithm The watering mechanism of the plant has different approaches
    in the proposed model. Primarily, the system is trained with manual irrigations
    datasets during the process of learning with respect to suggestions defined by
    agronomists. The model is trained to learn the needs of irrigation in the first
    level of deployment in cloud without the inclusion of pre-processed data. After
    acquiring the required data and training, the proposed system is initiated to
    grasp the plant''s watering needs by undergoing plenty of manual irrigations.
    Thereafter, manual irrigation is not required and the system makes automated decisions
    in watering using the gathered data and the application of ML methods. The proposed
    model then decides the irrigation strategies automatically using ML methods without
    the need including collected datasets in the automatic irrigation process. The
    proposed model can be improved through the learning process when the number of
    precise irrigation inputs is provided to the model at each stage of training.
    The decision-making procedure is developed with two modules for irrigation strategies
    according to the soil moisture prediction for upcoming days. The first module
    deals with training the model in cloud with manual irrigation datasets through
    steps such as data collection, data preprocessing, training, and model development.
    The system acquires values of air temperature (TH), soil temperature (SMT), soil
    moisture (SM), humidity (HU), and ultraviolet rays (UV) periodically from the
    physical environment in the data collection stage, which is essentially required
    for arriving at the watering decisions. Also, the time of performing the manual
    irrigation is recorded in the database. These data are timestamped and stored
    in as datasets to aid in making decisions for knowing the time of irrigation.
    In the next step of pre-processing, inconsistencies are eliminated and outliers
    caused by sensor errors are detected from the irrigation dataset, thereby helping
    in the removal of broken data. The training stage involves the application of
    supervised machine learning (ML) algorithms. Here the regression algorithms such
    as support vector regression (SVR), multiple linear regression (MLR), lasso regression
    (LR), decision tree regressor (DTR), random forest regressor (RF), and XG-boost
    regressor (XB) techniques are used for the deployment. The regression algorithms
    are trained using the collected datasets. Finally, through training, regression
    models are created, namely, SVR model, MLR model, LR model, DTR model, RF model,
    and XB model that are been combined with the second module for decision-making.
    The second module caters to the prediction of irrigation for upcoming days by
    infusing the weather data as an input to the regression trained models. The live
    datasets from the weather API for future prediction of soil moisture variable
    are used. The dependent variables from weather forecast data like temperature
    (TH), humidity (HU), ultraviolet (UV), and precipitation (PC) are tested in the
    aforementioned model for soil moisture prediction. Then, the regression trained
    model is evaluated and deployed using the weather testing data for the prediction
    of soil moisture in accordance with the precipitation. After the prediction of
    data for the upcoming days, these developed regression models are combined with
    unsupervised ML algorithm named k-means clustering for estimating the changes
    incurred in soil moisture prediction due to the impact of weather conditions.
    Further, each regression models with k-means algorithm are evaluated for performances
    in terms of irrigation decision-making process as shown in Table 1. The combined
    algorithms are estimated through MAPE, MSE, R2, execution speed, power consumption,
    and accuracy. The estimation and computation of these parameters are detailed
    by the authors in ref. [21]. Table 1. Comparison of performance metrics obtained
    from various ML algorithms. Algorithms used Accuracy R2 MSE MAPE (%) Execution
    time Power (J) SVR + k-means 0.96 0.96 0.25 1.98 0.06078 1164.85 MLR + k-means
    0.94 0.88 0.31 2.15 0.02075 429.30 LR + k-means 0.95 0.94 0.32 2.23 0.02482 351.35
    DTR + k-means 0.93 0.95 0.29 1.62 0.15687 914.70 RF + k-means 0.95 0.91 0.27 1.57
    0.16745 1475.13 XB + k-means 0.97 0.98 0.20 1.08 0.03547 537.87 XGBoost + k-means
    (XB + k-means) approach provides more accuracy with less MSE comparatively and
    also the R2 with 98% in soil moisture prediction using combined approach is given
    in Table 1. It is evident that the proposed combination performs better when compared
    to other regression + k-means-based approaches. XB + k-means-based hybrid machine
    learning algorithm is applied in irrigation planning module on account of aforementioned
    performance metrices of ML. Although it performs moderately in terms of execution
    time and power usage, it is selected for the deployment in edge computing as it
    has better performed in terms of accuracy, R2, MSE, and MAPE metrices. It is observed
    that the prediction of soil moisture for the upcoming days from the proposed algorithm
    (XB + k-means) is nearer to the actual value as shown in Table 2, and hence, XB
    + k-means is selected for the implementation of SMPHA in edge-based irrigation
    scheduling. Table 2. Comparison of predicted SM value with actual SM value. Date
    Average SM value from sensor Average predicted SM value (XB + k-means) 28-09-2022
    35.23 34.04 29-09-2022 36.41 37.20 30-09-2022 31.57 30.46 01-10-2022 34.66 33.15
    02-10-2022 36.73 37.12 03-10-2022 32.88 33.01 7.4. Edge layer setup The edge node
    acts as a computing center where incoming data are analyzed and fed as the input
    vector to the ML model for processing and to return the control signals for activating
    or deactivating the actuators placed at the farm. Edge node processes the physical
    data (real time) at every end device such as the collected and processed data
    via the Raspberry Pi nodes presented in the proposed scheme. The prediction model
    is designed using TensorFlow API and trained, tested on Google Colab in this work.
    Amazon Web Service (AWS) offers a library named Boto3 having many APIs to upload
    and download objects. After the development of model, it is transferred to Amazon
    S3, a service provided by AWS. The edge node utilizes the trained model from S3
    for analyzing the sensed data acquired from garden''s sensors. The decision is
    delivered based on real time data analysis at the edge node and transmitted to
    Arduino nodes in the fields landscape immediately for controlling the actuators.
    In another flow, the data collected from sensors are filtered so as to keep only
    the modified data at the edge node before being sent back for mitigating the communication
    cost to the database in the cloud. These data are used in the updation of the
    ML model to enhance its efficiency. 7.5. Analytics setup The main goal of this
    experiment lies in gathering the various physical parameters of a farming land
    via sensors and utilizing the fetched data along with weather forecast information
    for developing an algorithm using hybrid machine learning approach to infuse higher
    accuracy in predicting the soil moisture for the upcoming days. As discussed in
    Section 4, for the proper planning and provisioning of optimal irrigation, the
    algorithm provides a predictable estimate of soil moisture with the assistance
    of various statistical measures as shown in Table 1. The measures are adopted
    for estimating the appropriateness and error rate of the proposed algorithm. It
    is inferred from the experiment that, optimal irrigation is feasible using a good
    estimation (close to the actual value) of the soil moisture (Table 2), with the
    support of field data and forecast information, thereby utilizing the natural
    rain efficiently. 7.6. Work flow The flowchart in Fig. 4 depicts the working of
    the proposed system based on the decision support system that is beneficial for
    irrigation needed for the growth of vegetables. The chili plant is grown in a
    growbag attached with sensors and Pi and monitored for 95 days of data collection.
    To bring out optimality in the irrigation system, features relating to climate,
    soil, crop, and field infrastructure are to be considered. To provide several
    recommendations in the production of vegetables, decision support systems (DSSs)
    are designed, which process voluminous information [22]. This proposed work is
    the extension of soil moisture differences (SMD) model [23] developed for soil
    moisture prediction. The threshold values of soil moisture are used in the SMD
    model where the system schedules the irrigation date based on the predicted soil
    moisture and weather forecast (precipitation) information automatically using
    SVR+ k-means modeling. Therefore, in the extension of the aforementioned work,
    further more number of sensors are used to log soil moisture value, which is averaged
    in the proposed model. This model is developed in two divisions of flowchart as
    shown in Fig. 7, where both are interconnected. It is observed that the prediction
    of XB + k-mean approach provides better results as presented in Table 2 and Fig.
    5. Download : Download high-res image (441KB) Download : Download full-size image
    Fig. 4. Flow chart of the proposed edge model. Download : Download high-res image
    (500KB) Download : Download full-size image Fig 7. Average throughput value with
    10 h test scenarios. Download : Download high-res image (393KB) Download : Download
    full-size image Fig. 5. Average response time. The first phase of the flowchart
    describes the hybrid algorithm for the soil moisture prediction (SMPHA) using
    the combination of XB + k-means algorithm. During the data collection step, the
    sensor data for the parameters, namely, TM, HU, ST, UV, and SM, are collected.
    During preprocessing, null values and outliers are removed and the preprocessed
    data are used to train the XG-Boost model. The developed model is then trained
    with variables of live weather features (TM, HU, UV, PC) obtained from Weather
    API for the prediction of SM data. These data are given as input to k-means clustering
    algorithm to predict the soil moisture, which is defined as SMPHA value to be
    infused in the next phase of the flowchart. The second phase of the flowchart
    defines the automatic irrigation planning setup. The setup starts obtaining the
    soil moisture maximum (SMMax) and soil moisture minimum (SMMin) values in the
    dashboard for setting the maximum and minimum level of soil moisture. Then, the
    current soil moisture (CuSM) is sensed and compared against the threshold SMMin.
    If the resulting value is less than SMMin, the process proceeds with SMPHA. On
    the contrary, it stops the irrigation process by sending 0 to the relay. In SMPHA,
    the nearest precipitation date is selected and it is assigned to the predicted
    soil moisture (PSM). The SMMax is decided by finding the minimum of (PSM + SMMin,
    SMMax), and the predicted SMMax is further checked against CuSM with a condition
    if SMMax is greater the CuSM then it sends 1 to the relay as a signal to start
    irrigation. If the condition fails, then it sends 0 to stop irrigation. The process
    of automatic irrigation ends by forecasting the irrigation schedule in accordance
    with the live weather parameters. 7.6.1. Evaluation A hybrid machine learning
    methodology is used in evaluating the first stage of the proposed model. The predicted
    value of the soil moisture is better in terms of their accuracy and error rate.
    From the comparison of the other ML algorithms as shown in Table 2, XB + k-means
    performs better and taken further to be deployed in edge and cloud to check its
    efficiency with each other. Therefore, for analyzing the efficiency of the edge
    server in accordance with the proposed hybrid algorithm SMPHA is evaluated in
    terms of the time taken to train the ML model in edge and cloud. In this experiment
    Raspberry Pi is used to train the SMPHA model with 196,400 rows, that is, input
    data sample size and takes around 1,710,000 ms (approximately 28.5 min). The same
    model when it is trained in Google Colab cloud environment, it takes 204,000 ms
    (approximately 3.4 min) as depicted in Table 3. The main purpose is to run the
    trained model on edge not to train the model at edge. So due to the lack of computing
    capability at the edge, it takes more time to train the model, but it can be ignored
    as it does not affect the purpose of the proposed model. Here, edge is introduced
    to obtain the task of computing from the cloud (i.e., offloading the task) by
    making the system more edge-oriented deployment. It can be accomplished rapidly
    as it requires only 14 s to download a trained SMPHA model from the cloud to the
    edge node with a size of 3101 kb as given in Table 3. The time to download varies
    according to the size of the trained model. So, from this process it can be inferred
    that downloading the trained model saves time when compared to training the model
    at the edge. Through this in real time, deployment of the trained SMPHA model
    in edge is better compared to deployment in cloud services. Furthermore, network
    parameters like latency, throughput, bandwidth, and response time are adopted
    to measure the performance improvements in edge computing. Table 3. Comparison
    of model training time. Empty Cell Edge Cloud Model training time 28.4 min 3.4
    min Downloading time Not applicable 14 s The performance metrices taken into account
    are latency, bandwidth, and response time [24]. The latency of an application
    is the product of two factors: computing latency and transmission latency. The
    time spent on data processing and transmission between end devices to cloud servers
    is termed as computing latency and transmission latency, respectively. The computational
    capacity of the system decides the computing latency as the network servers possess
    a considerable amount of capacity to make the data processing faster, whereas
    the sensors come with limited computing capacity. The latency in transmission
    is increased by the end devices and cloud servers. Bandwidth: As large number
    of sensors are deployed in IoT, data generated would be huge that consumes an
    intense range of bandwidth and leads to several problems such as delay in transmission
    and loss of packets. It becomes unacceptable for the data to be transferred directly
    to cloud servers without applying compression. Therefore, data pre-processing
    and aggregation are needed for IoT gateways before redirecting them to remote
    cloud servers. Then, the issue to be confronted is to control the traffic flow
    by migrating data processing and aggregation tasks optimally to decrease the bandwidth
    needs of the end users while maintaining the data quality. Response time: The
    total response time is calculated by adding up transmission and processing time.
    The local deployment of the proposed model for controlling IoT-based irrigation
    are deployed on two modes: (i) Cloud mode: The developed SMPHA model is implemented
    in the cloud communicating with IoT sensors nodes directly to manage the irrigation
    process. The data are stored and processed at the cloud server itself where it
    uses Heroku platform. (ii) Edge mode – Raspberry Pi is deployed as an edge server
    that involves in processing of the SMPHA model controlling the IoT sensor nodes.
    Here, the data are stored and processed locally within the edge servers. This
    SMPHA model from both the edge and cloud does the job of controlling the actuators
    to initiate and quit the working of water flow motors. Through this deployment
    in both the environments, performance of edge server and cloud server can be checked
    in terms of latency, throughput, bandwidth, and response time is shown in aforementioned
    graphs in Fig. 6, Fig 7, Fig. 8. This performance metrics is not feasible to calculate
    while deploying in real time, so the aforementioned scenarios of two modes are
    virtually created by generating many request and response threads between the
    servers. This sampling, load test, and distributed testing are conducted through
    JMeter application and also verified with Wireshark in cloud servers. The test
    scenario is created here by data of sending and receiving sampling data between
    cloud to IoT sensors and between Edge to IoT sensors. The sampling data considered
    in this work refer to the approximate number of requests generated by Arduino
    to cloud and Arduino to Raspberry Pi that are calculated in real time. The test
    scenario is divided into 10 days of sampling data collected for each day. The
    evaluation results are depicted for latency and response times in 10 days perspective.
    In latency parameter, edge service has decreased by an average of 77.85% time
    compared to the with cloud. In the same manner, the response time of edge service
    is also decreased by 74.09% time compared to cloud service. In throughput calculation,
    sampling data are calculated for an hourly basis for the 10 h data in a day. From
    the hourly comparisons of throughput value, edge outperforms with 67.17% high
    Mbps usage. Through this analysis as shown in Table 4, it is evident that the
    proposed edge computing methodology deployed in Raspberry Pi or in local computers
    outperforms the cloud-oriented approach. Download : Download high-res image (368KB)
    Download : Download full-size image Fig. 6. Average latency with 10 test scenarios.
    Download : Download high-res image (390KB) Download : Download full-size image
    Fig. 8. CPU and memory utilization with and without SMPHA. Table 4. Performance
    metrics for cloud and edge services. Performance metrics Cloud service Edge service
    Throughput (Mbps) 0.04944 0.08265 Latency (ms) 1415.8 313.6 Response time (ms)
    1519.6 393.8 Bandwidth (bps) 86 1365 Finally, to illustrate the efficiency of
    resource management in edge computing, CPU and memory utilization are considered
    for the analysis as both factors rely on the service execution model and the computational
    needs of the services being fired from off-loaders. Fig. 8 depicts the utilization
    of CPU and RAM on the Raspberry Pi acting as an edge node in two cases: with and
    without the deployment of SMPHA model on it. As shown in Fig. 8, the SMPHA model
    affects the CPU of the Raspberry Pi node significantly as it consumed around 41.2%
    of the CPU compared to only 3.5% when it does not host the SMPHA model. However,
    the memory (RAM) utilization in both the cases (with and without deployment of
    an SMPHA model) is nearly the same which is around 31%. Comparatively RAM utilization
    does not have much difference in with and without SMPHA. It is worthwhile to note
    that, the CPU utilization is still much lower than the 50% of total CPU capacity
    in Raspberry Pi. Therefore, it becomes feasible for adopting edge server implementation
    in the proposed irrigation system. 7.7. Conclusion This article proposed a novel
    approach to edge-based irrigation system to facilitate decision-making on watering
    the plants on scheduled time. The proposed approach applying IoT with an edge
    computing framework enables the farming system to adapt to the changes in environmental
    conditions automatically and efficiently. The process of automatic irrigation
    regulates irrigation according to the live weather parameters for forecasting
    the irrigation process. Soil moisture prediction was performed using major regression
    algorithms that are again combined with k-means clustering for estimating the
    changes incurred in soil moisture prediction. These techniques were compared through
    metrics such as MAPE, MSE, speed, and power consumption from which XB + k-means
    was found to perform better. The XB + k-means algorithm was further used for the
    implementation of decision mechanism on the developed edge computing model. The
    proposed edge model saves the data communication cost and reduces the response
    time of IoT services. It can be deployed on existing devices on the network edges
    serving as edge nodes, thereby reducing the overall implementation cost of a large-scale
    IoT system. The edge-based approach was found to perform better than the cloud-based
    approach in terms of response time, latency, throughput, and bandwidth usage.
    Finally, the edge model was analyzed through CPU and memory usage while running
    with and without the algorithm. In both cases, the memory utilization is almost
    lower to total available resource of the edge device. From this, edge device can
    allocate its remaining resource for other computing services, which increases
    the efficiency of edge computing device. The number of end edge nodes can be increased
    according to the field area and then to check the potency of the system. References
    [1] S.K. Routray, A. Javali, L. Sharma, A.D. Ghosh, A. Sahoo Internet of things
    based precision agriculture for developing countries Proceedings of the 2019 International
    Conference on Smart Systems and Inventive Technology (ICSSIT), Tirunelveli, India,
    27–29 November 2019 (2019), pp. 1064-1068 CrossRefView in ScopusGoogle Scholar
    [2] K. Perakis, F. Lampathaki, K. Nikas, Y. Georgiou, O. Marko, J. Maselyne CYBELE–Fostering
    Precision Agriculture & Livestock Farming through Secure Access to large-scale
    HPC enabled virtual industrial experimentation environments fostering scalable
    big data analytics Comput. Netw., 168 (2020), Article 107035 View PDFView articleView
    in ScopusGoogle Scholar [3] J. Poveda Insect frass in the development of sustainable
    agriculture. A review Agron. Sustain. Dev., 41 (2021), pp. 1-10 CrossRefGoogle
    Scholar [4] P.C. Nagajyoti, K.D. Lee, T.V.M. Sreekanth Heavy metals, occurrence
    and toxicity for plants: a review Environ. Chem. Lett., 8 (2010), pp. 199-216
    CrossRefView in ScopusGoogle Scholar [5] P.K. Rai, S.S. Lee, M. Zhang, Y.F. Tsang,
    K.-H. Kim Heavy metals in food crops: health risks, fate, mechanisms, and management
    Environ. Int., 125 (2019), pp. 365-385 View PDFView articleView in ScopusGoogle
    Scholar [6] L.S. Keith, D.W. Wohlers, D.B. Moffett, Z.A. Rosemond ATSDR evaluation
    of potential for human exposure to tungsten Toxicol. Ind. Health, 23 (2007), pp.
    309-345 CrossRefView in ScopusGoogle Scholar [7] P.K. Rai, K.-H. Kim, S.S. Lee,
    J.-H. Lee Molecular mechanisms in phytoremediation of environmental contaminants
    and prospects of engineered transgenic plants/microbes Sci. Total Environ., 705
    (2020), Article 135858 View PDFView articleView in ScopusGoogle Scholar [8] G.
    Sandeep, K.R. Vijayalatha, T. Anitha Heavy metals and its impact in vegetable
    crops Int. J. Chem. Stud., 7 (2019), pp. 1612-1621 View in ScopusGoogle Scholar
    [9] P.-I.K. Chukwuemeka, N.U. Hephzibah Potential health risk from heavy metals
    via consumption of leafy vegetables in the vicinity of Warri refining and petrochemical
    company, Delta state, Nigeria Ann. Biol. Sci., 6 (2018), pp. 30-37 Google Scholar
    [10] Y. Gao, P. Zhou, L. Mao, Y. Zhi, W. Shi Assessment of effects of heavy metals
    combined pollution on soil enzyme activities and microbial community structure:
    modified ecological dose–response model and PCR-RAPD Environ. Earth Sci., 60 (2010),
    pp. 603-612 CrossRefView in ScopusGoogle Scholar [11] S. Tiwari, C. Lata Heavy
    metal stress, signaling, and tolerance due to plant-associated microbes: An overview
    Front. Plant Sci., 9 (2018), p. 452 View in ScopusGoogle Scholar [12] H. Panchasara,
    N.H. Samrat, N. Islam Greenhouse gas emissions trends and mitigation measures
    in Australian agriculture sector—a review Agri, 11 (2021), p. 85 CrossRefGoogle
    Scholar [13] S.R. Wild, K.C. Jones Organic chemicals entering agricultural soils
    in sewage sludges: screening for their potential to transfer to crop plants and
    livestock Sci. Total Environ., 119 (1992), pp. 85-119 View PDFView articleView
    in ScopusGoogle Scholar [14] P.K. Rai Impacts of particulate matter pollution
    on plants: implications for environmental biomonitoring Ecotoxicol. Environ. Saf.,
    129 (2016), pp. 120-136 View PDFView articleView in ScopusGoogle Scholar [15]
    M. Huang, Y. Zhu, Z. Li, B. Huang, N. Luo, C. Liu, G. Zeng Compost as a soil amendment
    to remediate heavy metal-contaminated agricultural soil: mechanisms, efficacy,
    problems, and strategies Water Air Soil Pollut., 227 (2016), pp. 1-18 Google Scholar
    [16] P.K. Rai Biomagnetic Monitoring through Roadside Plants of an Indo-Burma
    Hot Spot Region Elsevier, London, UK (2016) Google Scholar [17] R. Li, H. Wu,
    J. Ding, W. Fu, L. Gan, Y. Li Mercury pollution in vegetables, grains and soils
    from areas surrounding coal-fired power plants Sci. Rep., 7 (2017), pp. 1-9 Google
    Scholar [18] V. Fernández, T. Eichert Uptake of hydrophilic solutes through plant
    leaves: current state of knowledge and perspectives of foliar fertilization CRC
    Crit. Rev. Plant. Sci., 28 (2009), pp. 36-68 CrossRefView in ScopusGoogle Scholar
    [19] R. Cavicchioli, W.J. Ripple, K.N. Timmis, F. Azam, L.R. Bakken, M. Baylis,
    et al. Scientists'' warning to humanity: microorganisms and climate change Nat.
    Rev. Microbiol., 17 (9) (2019), pp. 569-586, 10.1038/s41579-019-0222-5 View in
    ScopusGoogle Scholar [20] N.T.L. Huong, Y.S. Bo, S. Fahad Economic impact of climate
    change on agriculture using Ricardian approach: a case of Northwest Vietnam J.
    Saudi Soc. Agric. Sci., 18 (4) (2019), pp. 449-457, 10.1016/j.jssas.2018.02.006
    View PDFView articleView in ScopusGoogle Scholar [21] R.K. Fagodiya, H. Pathak,
    A. Bhatia, N. Jain, A. Kumar, S.K. Malyan Global warming impacts of nitrogen use
    in agriculture: An assessment for India since 1960 Carbon Manag., 11 (3) (2020),
    pp. 291-301, 10.1080/17583004.2020.1752061 View in ScopusGoogle Scholar [22] S.
    Sarkar, S. Chatterjee, S. Misra Assessment of the suitability of fog computing
    in the context of internet of things IEEE Trans. Cloud Comput., 6 (1) (2018),
    pp. 46-59, 10.1109/TCC.2015.2485206 View in ScopusGoogle Scholar [23] K. Saravanan,
    G. Julie, H. Robinson Handbook of Research on Implementation and Deployment of
    IoT Projects in Smart Cities IGI Global, Hershey (2019), 10.4018/978-1-5225-9199-3
    Google Scholar [24] A. Baylis Advances in precision farming technologies for crop
    protection Outlooks Pest. Manag., 28 (4) (2017), pp. 158-161, 10.1564/v28_aug_04
    View in ScopusGoogle Scholar Further reading [25] C.F. Nicholson, E.C. Stephens,
    B. Kopainsky, P.K. Thornton, A.D. Jones, D. Parsons, J. Garrett Food security
    outcomes in agricultural systems models: case examples and priority information
    needs Agr. Syst., 188 (2021), Article 103030 View PDFView articleView in ScopusGoogle
    Scholar [26] C. Lopes, M. Herva, A. Franco-Uría, E. Roca Inventory of heavy metal
    content in organic waste applied as fertilizer in agriculture: evaluating the
    risk of transfer into the food chain Environ. Sci. Pollut. Res., 18 (2011), pp.
    918-939 CrossRefView in ScopusGoogle Scholar [27] M. Arora, B. Kiran, S. Rani,
    A. Rani, B. Kaur, N. Mittal Heavy metal accumulation in vegetables irrigated with
    water from different sources Food Chem., 111 (2008), pp. 811-815 View PDFView
    articleView in ScopusGoogle Scholar [28] A.K. Meena, G.K. Mishra, P.K. Rai, C.
    Rajagopal, P.N. Nagar Removal of heavy metal ions from aqueous solutions using
    carbon aerogel as an adsorbent J. Hazard. Mater., 122 (2005), pp. 161-170 View
    PDFView articleView in ScopusGoogle Scholar [29] P.K. Rai Heavy metal phytoremediation
    from aquatic ecosystems with special reference to macrophytes Crit. Rev. Environ.
    Sci. Technol., 39 (2009), pp. 697-753 CrossRefView in ScopusGoogle Scholar [30]
    J.E. Gall, R.S. Boyd, N. Rajakaruna Transfer of heavy metals through terrestrial
    food webs: a review Environ. Monit. Assess., 187 (2015), pp. 1-21 Google Scholar
    [31] Z.J. Shen, Y.S. Chen, Z. Zhang Heavy metals translocation and accumulation
    from the rhizosphere soils to the edible parts of the medicinal plant Fengdan
    (Paeonia ostii) grown on a metal mining area, China Ecotoxicol. Environ. Saf.,
    143 (2017), pp. 19-27 View PDFView articleView in ScopusGoogle Scholar [32] O.
    El Hamiani, H. El Khalil, C. Sirguey, A. Ouhammou, G. Bitton, C. Schwartz, A.
    Boularbah Metal concentrations in plants from mining areas in South Morocco: health
    risks assessment of consumption of edible and aromatic plants CLEAN Soil Air Water,
    43 (2015), pp. 399-407 CrossRefView in ScopusGoogle Scholar [33] S. Bolan, A.
    Kunhikrishnan, B. Seshadri, G. Choppala, R. Naidu, N.S. Bolan, Y.S. Ok, M. Zhang,
    C.G. Li, F. Li Sources, distribution, bioavailability, toxicity, and risk assessment
    of heavy metal (loid) s in complementary medicines Environ. Int., 108 (2017),
    pp. 103-118 View PDFView articleView in ScopusGoogle Scholar [34] S.W. Kim, Y.E.
    Chae, J.M. Moon, D.K. Kim, R.X. Cui, G. An, S.W. Jeong, Y.J. An In situ evaluation
    of crop productivity and bioaccumulation of heavy metals in Paddy soils after
    remediation of metal-contaminated soils J. Agric. Food Chem., 65 (2017), pp. 1239-1246
    CrossRefView in ScopusGoogle Scholar [35] S. Kohzadi, B. Shahmoradi, E. Ghaderi,
    H. Loqmani, A. Maleki Concentration, source, and potential human health risk of
    heavy metals in the commonly consumed medicinal plants Biol. Trace Elem. Res.,
    187 (2019), pp. 41-50 CrossRefView in ScopusGoogle Scholar [36] F. Li, W. Shi,
    Z. Jin, H. Wu, G.D. Sheng Excessive uptake of heavy metals by greenhouse vegetables
    J. Geochem. Explor., 173 (2017), pp. 76-84 View PDFView articleGoogle Scholar
    [37] L. Yu, G. Xin, W. Gang, Q. Zhang, S. Qiong, X. Guoju Heavy metal contamination
    and source in arid agricultural soil in Central Gansu Province, China J. Environ.
    Sci., 20 (2008), pp. 607-612 View in ScopusGoogle Scholar [38] A.K. Chopra, C.
    Pathak, G. Prasad Scenario of heavy metal contamination in agricultural soil and
    its management J. Appl. Nat. Sci., 1 (2009), pp. 99-108 CrossRefGoogle Scholar
    [39] W. Feng, Z. Guo, X. Xiao, C. Peng, L. Shi, H. Ran, W. Xu A dynamic model
    to evaluate the critical loads of heavy metals in agricultural soil Ecotoxicol.
    Environ. Saf., 197 (2020), Article 110607 View PDFView articleView in ScopusGoogle
    Scholar [40] J. Wu, J. Li, Y. Teng, H. Chen, Y. Wang A partition computing-based
    positive matrix factorization (PC-PMF) approach for the source apportionment of
    agricultural soil heavy metal contents and associated health risks J. Hazard.
    Mater., 388 (2020), Article 121766 View PDFView articleView in ScopusGoogle Scholar
    [41] M. Shahid, C. Dumat, S. Khalid, E. Schreck, T. Xiong, N.K. Niazi Foliar heavy
    metal uptake, toxicity and detoxification in plants: a comparison of foliar and
    root metal uptake J. Hazard. Mater., 325 (2017), pp. 36-58 View PDFView articleView
    in ScopusGoogle Scholar [42] R. Lal Adaptation and mitigation of climate change
    by improving agriculture in India S. SherazMahdi (Ed.), Climate Change and Agriculture
    in India: Impact and Adaptation, Springer International Publishing, Cham (2019),
    pp. 217-227, 10.1007/978-3-319-90086-5_17 Google Scholar [43] D. Mulla, R. Khosla
    Historical Evolution and Recent Advances in Precision Farming. Soil-Specific Farming
    Precision Agriculture CRC Press, Boca Raton (2015), 10.1201/b18759-2 Google Scholar
    [44] L. Dutta, T.K. Basu Extraction and optimization of leaves images of mango
    tree and classification using ANN IJRAET, 1 (3) (2013), pp. 46-51 Google Scholar
    [45] T. Kawai, H. Mineno Evaluation environment using edge computing for artificial
    intelligence-based irrigation system 2020 16th International Conference on Mobility,
    Sensing and Networking (MSN), IEEE, Tokyo, Japan (2020), pp. 214-219, 10.1109/MSN50589.2020.00046
    View in ScopusGoogle Scholar [46] M.S. Munir, I.S. Bajwa, A. Ashraf, W. Anwar,
    R. Rashid Intelligent and smart irrigation system using edge computing and IoT
    Complexity., 2021 (2021), pp. 1-16, 10.1155/2021/6691571 Google Scholar [47] C.M.
    Angelopoulos, G. Filios, S. Nikoletseas, T.P. Raptis Keeping data at the edge
    of smart irrigation networks: a case study in strawberry greenhouses Comput. Netw.,
    167 (2020), Article 107039, 10.1016/j.comnet.2019.107039 View PDFView articleView
    in ScopusGoogle Scholar [48] M. Satyanarayanan The emergence of edge computing
    Computer., 50 (1) (2017), pp. 30-39, 10.1109/MC.2017.9 View in ScopusGoogle Scholar
    [49] W. Shi, S. Dustdar The promise of edge computing Computer., 49 (5) (2016),
    pp. 78-81, 10.1109/MC.2016.145 View in ScopusGoogle Scholar [50] P.L. Ramirez
    Izolan, F. Diniz Rossi, R. Hohemberger, M.P. Konzen, R.G. da Cunha, L.R. Saquette,
    et al. Low-cost fog computing platform for soil moisture management 2020 International
    Conference on Information Networking (ICOIN), IEEE, Barcelona, Spain (2020), pp.
    499-504, 10.1109/ICOIN48656.2020.9016572 View in ScopusGoogle Scholar [51] F.
    Ferrandez-Pastor, J. Garcia-Chamizo, M. Nieto-Hidalgo, J. Mora-Pascual, J. Mora-Martínez
    Developing ubiquitous sensor network platform using internet of things: application
    in precision agriculture Sensors., 16 (7) (2016), p. 1141, 10.3390/s16071141 View
    in ScopusGoogle Scholar [52] X. Xu, X. Liu, Z. Xu, F. Dai, X. Zhang, L. Qi Trust-oriented
    IoT service placement for smart cities in edge computing IEEE Internet Things
    J., 7 (5) (2020), pp. 4084-4091, 10.1109/JIOT.2019.2959124 View in ScopusGoogle
    Scholar [53] X. Wu, M. Liu In-situ soil moisture sensing: measurement scheduling
    and estimation using compressive sensing 2012 ACM/IEEE 11th International Conference
    on Information Processing in Sensor Networks (IPSN), IEEE, Beijing, China (2012),
    pp. 1-11, 10.1145/2185677.2185679 Google Scholar [54] T. Kameoka, K. Nishioka,
    Y. Motonaga, Y. Kimura, A. Hashimoto Watanabe N. smart sensing in a vineyard for
    advanced viticultural management Proceedings of the 2014 International Workshop
    on Web Intelligence and Smart Sensing, Saint Etienne France (2014), pp. 1-4, 10.1145/2637064.2637091
    Google Scholar [55] K. Cagri Serdaroglu, C. Onel, S. Baydere IoT-based smart plant
    irrigation system with enhanced learning 2020 IEEE Computing, Communications and
    IoT Applications (ComComAp.), IEEE, Beijing, China (2020), pp. 1-6, 10.1109/ComComAp51192.2020.9398892
    Google Scholar [56] J. Kwok, Y. Sun A smart IoT-based irrigation system with automated
    plant recognition using deep learning Proceedings of the 10th International Conference
    on Computer Modeling and Simulation - ICCMS2018, ACM Press, Sydney, Australia
    (2018), pp. 87-91, 10.1145/3177457.3177506 View in ScopusGoogle Scholar [57] A.
    Goldstein, L. Fink, A. Meitin, S. Bohadana, O. Lutenberg, G. Ravid Applying machine
    learning on sensor data for irrigation recommendations: revealing the agronomist''s
    tacit knowledge Precision Agricult., 19 (3) (2018), pp. 421-444, 10.1007/s11119-017-9527-4
    View in ScopusGoogle Scholar [58] A. Vij, S. Vijendra, A. Jain, S. Bajaj, A. Bassi,
    A. Sharma IoT and machine learning approaches for automation of farm irrigation
    system Proc. Comput. Sci., 167 (2020), pp. 1250-1257, 10.1016/j.procs.2020.03.440
    View PDFView articleView in ScopusGoogle Scholar [59] H. Krishnan, R. Scholar
    MongoDB – a comparison with NoSQL databases Int. J. Sci. Eng. Res., 7 (5) (2016),
    pp. 1035-1037 Google Scholar [60] T. Ojha, S. Misra, N.S. Raghuwanshi Wireless
    sensor networks for agriculture: the state-of-the-art in practice and future challenges
    Comput Electr Agricult., 118 (2015), pp. 66-84, 10.1016/j.compag.2015.08.011 View
    PDFView articleView in ScopusGoogle Scholar [61] J. Gutierrez, J.F. Villa-Medina,
    A. Nieto-Garibay, M.A. Porta-Gandara Automated irrigation system using a wireless
    sensor network and GPRS module IEEE Trans. Instrum. Meas., 63 (1) (2014), pp.
    166-176, 10.1109/TIM.2013.2276487 View in ScopusGoogle Scholar [62] S. Chanthakit,
    P. Keeratiwintakorn, C. Rattanapoka An IoT system design with real time stream
    processing and data flow integration In: 2019 Research, Invention, and Innovation
    Congress (RI2C.), IEEE, Bangkok, Thailand (2019), pp. 1-5, 10.1109/RI2C48728.2019.8999968
    Google Scholar [63] H. Lv, S. Wang Design and Application of IoT Microservices
    Based on Seneca DEStech Transactions on Computer Science and Engineering, (icte.),
    USA (2016), 10.12783/dtcse/icte2016/4814 Google Scholar [64] B.-H. Lee, E.K. Dewi,
    M.F. Wajdi Data security in cloud computing using AES under HEROKU cloud 2018
    27th Wireless and Optical Communication Conference (WOCC), IEEE, Hualien (2018),
    pp. 1-5, 10.1109/WOCC.2018.8372705 View PDFView articleGoogle Scholar [65] M.A.
    Lopez Pena, F.I. Munoz SAT-IoT: An architectural model for a high-performance
    fog/edge/cloud IoT platform 2019 IEEE 5th World Forum on Internet of Things (WF-IoT.),
    IEEE, Limerick, Ireland (2019), pp. 633-638, 10.1109/WF-IoT.2019.8767282 View
    in ScopusGoogle Scholar [66] Weather API. Retrieved from https://openweathermap.org/api.
    Google Scholar [67] D. Gislason Zigbee Wireless Networking (1st ed.), Elsevier
    Publisher, Newnes, London (2008) Google Scholar [68] K. Tanabe, Y. Tanabe, M.
    Hagiya Model-based testing for MQTT applications M. Virvou, H. Nakagawa, L.C.
    Jain (Eds.), Knowledge-Based Software Engineering: 2020, Springer International
    Publishing, Cham (2020), pp. 47-59, 10.1007/978-3-030-53949-8_5 View in ScopusGoogle
    Scholar [69] L. Babun, K. Denney, Z.B. Celik, P. McDaniel, A.S. Uluagac A survey
    on IoT platforms: communication, security, and privacy perspectives Comput. Netw.,
    192 (2021), Article 108040, 10.1016/j.comnet.2021.108040 View PDFView articleView
    in ScopusGoogle Scholar [70] K. Rastogi, D. Lohani Edge computing-based internet
    of things framework for indoor occupancy estimation Int. J. Ambient Comput. Intell.,
    11 (4) (2020), pp. 16-37, 10.4018/978-1-6684-5700-9.ch031 Google Scholar [71]
    S. Premkumar, A.N. Sigappi Functional framework for edge-based agricultural system
    AI, Edge and IoT-Based Smart Agriculture (1st ed.), Academic Press, Elsevier,
    USA (2021), pp. 71-100, 10.1016/B978-0-12-823694-9.00029-3 View in ScopusGoogle
    Scholar [72] J. Phani Kumar, P. Paramaguru, T. Arumugam, N. Manikanda Boopathi,
    K. Venkatesan Genetic divergence among Ramnad mundu chilli (Capsicum annuum L.)
    genotypes for yield and quality Electr. J. Plant Breeding., 12 (1) (2021), pp.
    228-234 Google Scholar [73] A. Goap, D. Sharma, A.K. Shukla, K.C. Rama An IoT-based
    smart irrigation management system using machine learning and open source technologies
    Comput Electronic Agricult., 155 (2018), pp. 41-49, 10.1016/j.compag.2018.09.040
    View PDFView articleView in ScopusGoogle Scholar [74] M.S. Aslanpour, S.S. Gill,
    A.N. Toosi Performance evaluation metrics for cloud, fog and edge computing: a
    review, taxonomy, benchmarks and standards for future research Internet Things.,
    12 (2020), Article 100273, 10.1016/j.iot.2020.100273 View PDFView articleView
    in ScopusGoogle Scholar [75] A. Sunardi Suharjito MVC architecture: a comparative
    study between Laravel framework and slim framework in freelancer project monitoring
    system web based Proc. Comput. Sci., 157 (2019), pp. 134-141, 10.1016/j.procs.2019.08.150
    View PDFView articleView in ScopusGoogle Scholar [76] R. Shimonski The Wireshark
    Field Guide (1st ed.), Syngress Press, Elsevier, New York (2013), 10.1016/B978-0-12-410413-6.00001-2
    Google Scholar Cited by (0) Dr. Preetha Evangeline David is currently working
    as an Associate Professor and Head of the Department in the Department of Artificial
    Intelligence and Machine Learning at Chennai Institute of Technology, Chennai,
    India. She holds a PhD from Anna University, Chennai in the area of Cloud Computing.
    She has published many research papers and Patents focusing on Artificial Intelligence,
    Digital Twin Technology, High Performance Computing, Computational Intelligence
    and Data Structures. She is currently working on Multi-disciplinary areas in collaboration
    with other technologies to solve socially relevant challenges and provide solutions
    to human problems. Dr. P. Anandhakumar is a professor in the Department of Information
    Technology at Anna University, Chennai. He has completed his doctorate in the
    year 2006 from Anna University. He has produced 17 PhD''s in the field of Image
    Processing, Cloud Computing, Multimedia technology and Machine Learning. His ongoing
    research lies in the field of Digital Twin Technology, Machine Learning and Artificial
    Intelligence. He has published more than 150 papers indexed in SCI, SCOPUS, WOS
    etc. Pethuru Raj Chelliah (PhD) works as the chief architect at the Site Reliability
    Engineering Center of Excellence, Reliance Jio Infocomm Ltd. (RJIL), Bangalore.
    Previously, he worked as a cloud infrastructure architect at the IBM Global Cloud
    Center of Excellence, IBM India, Bangalore, for four years. He also had an extended
    stint as a TOGAF-certified enterprise architecture consultant in Wipro Consulting
    services division and as a lead architect in the corporate research division of
    Robert Bosch, Bangalore. He has more than 17 years of IT industry experience.
    Shreyash Naithani is currently a site reliability engineer at Microsoft R&D. Prior
    to Microsoft, he worked with both start-ups and mid-level companies. He completed
    his PG Diploma from the Centre for Development of Advanced Computing, Bengaluru,
    India, and is a computer science graduate from Punjab Technical University, India.
    In a short span of time, he has had the opportunity to work as a DevOps engineer
    with Python/C#, and as a tools developer, site/service reliability engineer, and
    Unix system administrator. During his leisure time, he loves to travel and binge
    watch series. Shailender Singh is a principal site reliability engineer and a
    solution architect with around 11 year''s IT experience who holds two master''s
    degrees in IT and computer application. He has worked as a C developer on the
    Linux platform. He had exposure to almost all infrastructure technologies from
    hybrid to cloud-hosted environments. In the past, he has worked with companies
    including Mckinsey, HP, HCL, Revionics and Avalara and these days he tends to
    use AWS, K8s, Terraform, Packer, Jenkins, Ansible, and OpenShift. View Abstract
    Copyright © 2024 Elsevier Inc. All rights reserved. Part of volume Applying Computational
    Intelligence for Social Good Edited by Preetha Evangeline David, P. Anandhakumar
    Download full volume Recommended articles Article Metrics Captures Readers: 8
    View details About ScienceDirect Remote access Shopping cart Advertise Contact
    and support Terms and conditions Privacy policy Cookies are used by this site.
    Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024
    Elsevier B.V., its licensors, and contributors. All rights are reserved, including
    those for text and data mining, AI training, and similar technologies. For all
    open access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Advances in Computers
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Reshaping agriculture using intelligent edge computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Whig P.
  - Velu A.
  - Nadikattu R.R.
  citation_count: '0'
  description: Increased agricultural activity is supposed to be of crucial importance
    as intelligent agriculture or precision agriculture. Increased agricultural activity
    is supposed to be of crucial importance as intelligent agriculture or precision
    agriculture. The bandwidth and the information repository are too much for an
    old cloud-based system that largely employs IoT devices. Reduced latency, better
    battery life for IoT systems, a lot more efficient cash knowledge acquisition,
    accessibility to intellectual capital, and AI, ML IoT-EDGE style platform are
    suggested or may be used. When opposed to using the cloud to process and store
    information, the edge for the IoT provides prospective edges for various IoT installations,
    as well as the elimination of interval in combination with geometrical communication
    potency. Several IoT procedures, for example, will also have a high level of technology
    at the sting, resulting in minimal latency and quick processing. The current cloudbased
    systems, which are built on traditional cloud concepts, cannot handle the large
    quantities and different data produced by linked IoT devices. To facilitate real-time
    decision-making based on the data collected, it is critical to move data processing
    closer to the roots of their production. This will be solved by using fogbased
    models, which will be addressed in this chapter.
  doi: 10.1002/9781119905233.ch8
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register Convergence of Cloud with AI for Big Data Analytics: Foundations and
    Innovation Chapter 8 Fog-IoT Assistance-Based Smart Agriculture Application Pawan
    Whig,  Arun Velu,  Rahul Reddy Nadikattu Book Editor(s):Danda B. Rawat,  Lalit
    K Awasthi,  Valentina Emilia Balas,  Mohit Kumar,  Jitendra Kumar Samriya First
    published: 10 February 2023 https://doi.org/10.1002/9781119905233.ch8 PDF TOOLS
    SHARE Summary Increased agricultural activity is supposed to be of crucial importance
    as intelligent agriculture or precision agriculture. Increased agricultural activity
    is supposed to be of crucial importance as intelligent agriculture or precision
    agriculture. The bandwidth and the information repository are too much for an
    old cloud-based system that largely employs IoT devices. Reduced latency, better
    battery life for IoT systems, a lot more efficient cash knowledge acquisition,
    accessibility to intellectual capital, and AI, ML IoT-EDGE style platform are
    suggested or may be used. When opposed to using the cloud to process and store
    information, the edge for the IoT provides prospective edges for various IoT installations,
    as well as the elimination of interval in combination with geometrical communication
    potency. Several IoT procedures, for example, will also have a high level of technology
    at the sting, resulting in minimal latency and quick processing. The current cloud-based
    systems, which are built on traditional cloud concepts, cannot handle the large
    quantities and different data produced by linked IoT devices. To facilitate real-time
    decision-making based on the data collected, it is critical to move data processing
    closer to the roots of their production. This will be solved by using fog-based
    models, which will be addressed in this chapter. References Convergence of Cloud
    with AI for Big Data Analytics: Foundations and Innovation References Related
    Information Recommended IoT/cloud‐enabled smart services: A review on QoS requirements
    in fog environment and a proposed approach based on priority classification technique
    Amel Ksentini,  Maha Jebalia,  Sami Tabbane International Journal of Communication
    Systems Metropolitan intelligent surveillance systems for urban areas by harnessing
    IoT and edge computing paradigms Rustem Dautov,  Salvatore Distefano,  Dario Bruneo,  Francesco
    Longo,  Giovanni Merlino,  Antonio Puliafito,  Rajkumar Buyya Software: Practice
    and Experience Characterizing application scheduling on edge, fog, and cloud computing
    resources Prateeksha Varshney,  Yogesh Simmhan Software: Practice and Experience
    Smart Agriculture Applications Using Cloud and IoT Keshav Kaushik Convergence
    of Cloud with AI for Big Data Analytics: Foundations and Innovation, [1] SmartHerd
    management: A microservices‐based fog computing–assisted IoT platform towards
    data‐driven smart dairy farming Mohit Taneja,  Nikita Jalodia,  John Byabazaire,  Alan
    Davy,  Cristian Olariu Software: Practice and Experience Additional links ABOUT
    WILEY ONLINE LIBRARY Privacy Policy Terms of Use About Cookies Manage Cookies
    Accessibility Wiley Research DE&I Statement and Publishing Policies Developing
    World Access HELP & SUPPORT Contact Us Training and Support DMCA & Reporting Piracy
    OPPORTUNITIES Subscription Agents Advertisers & Corporate Partners CONNECT WITH
    WILEY The Wiley Network Wiley Press Room Copyright © 1999-2024 John Wiley & Sons,
    Inc or related companies. All rights reserved, including rights for text and data
    mining and training of artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: 'Convergence of Cloud with AI for Big Data Analytics: Foundations and Innovation'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Fog-IoT Assistance-Based Smart Agriculture Application
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chamara N.
  - Bai G.
  - Ge Y.
  citation_count: '1'
  description: 'Precision Agriculture (PA) promises to meet the future demands for
    food, feed, fiber, and fuel while keeping their production sustainable and environmentally
    friendly. PA relies heavily on sensing technologies to inform site-specific decision
    supports for planting, irrigation, fertilization, spraying, and harvesting. Traditional
    point-based sensors enjoy small data sizes but are limited in their capacity to
    measure plant and canopy parameters. On the other hand, imaging sensors can be
    powerful in measuring a wide range of these parameters, especially when coupled
    with Artificial Intelligence. The challenge, however, is the lack of computing,
    electric power, and connectivity infrastructure in agricultural fields, preventing
    the full utilization of imaging sensors. This paper reported AICropCAM, a field-deployable
    imaging framework that integrated edge image processing, Internet of Things (IoT),
    and LoRaWAN for low-power, long-range communication. The core component of AICropCAM
    is a stack of four Deep Convolutional Neural Networks (DCNN) models running sequentially:
    CropClassiNet for crop type classification, CanopySegNet for canopy cover quantification,
    PlantCountNet for plant and weed counting, and InsectNet for insect identification.
    These DCNN models were trained and tested with >43,000 field crop images collected
    offline. AICropCAM was embodied on a distributed wireless sensor network with
    its sensor node consisting of an RGB camera for image acquisition, a Raspberry
    Pi 4B single-board computer for edge image processing, and an Arduino MKR1310
    for LoRa communication and power management. Our testing showed that the time
    to run the DCNN models ranged from 0.20 s for InsectNet to 20.20 s for CanopySegNet,
    and power consumption ranged from 3.68 W for InsectNet to 5.83 W for CanopySegNet.
    The classification model CropClassiNet reported 94.5 % accuracy, and the segmentation
    model CanopySegNet reported 92.83 % accuracy. The two object detection models
    PlantCountNet and InsectNet reported mean average precision of 0.69 and 0.02 for
    the test images. Predictions from the DCNN models were transmitted to the ThingSpeak
    IoT platform for visualization and analytics. We concluded that AICropCAM successfully
    implemented image processing on the edge, drastically reduced the amount of data
    being transmitted, and could satisfy the real-time need for decision-making in
    PA. AICropCAM can be deployed on moving platforms such as center pivots or drones
    to increase its spatial coverage and resolution to support crop monitoring and
    field operations.'
  doi: 10.1016/j.compag.2023.108420
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Graphical abstract Keywords 1. Introduction 2. Materials
    and methods 3. Results and discussion 4. Conclusion and future perspectives Funding
    CRediT authorship contribution statement Declaration of Competing Interest Acknowledgements
    Data availability References Show full outline Cited by (1) Figures (12) Show
    6 more figures Tables (7) Table 1 Table 2 Table 3 Table 4 Table 5 Table 6 Show
    all tables Computers and Electronics in Agriculture Volume 215, December 2023,
    108420 AICropCAM: Deploying classification, segmentation, detection, and counting
    deep-learning models for crop monitoring on the edge Author links open overlay
    panel Nipuna Chamara a, Geng Bai a, Yufeng Ge a b Show more Share Cite https://doi.org/10.1016/j.compag.2023.108420
    Get rights and content Under a Creative Commons license open access Highlights
    • We developed AICropCAM, an edge-computing enabled camera system for crop monitoring.
    • It integrated Raspberry Pi and Arduino for image processing and LoRa communication.
    • It ran a stack of four deep neural networks to characterize multiple plant/canopy
    parameters. • We quantified the power consumption and speed of the system for
    edge image-processing. • AICropCAM is a next-generation enabling technology for
    real-time, low-latency Ag applications. Abstract Precision Agriculture (PA) promises
    to meet the future demands for food, feed, fiber, and fuel while keeping their
    production sustainable and environmentally friendly. PA relies heavily on sensing
    technologies to inform site-specific decision supports for planting, irrigation,
    fertilization, spraying, and harvesting. Traditional point-based sensors enjoy
    small data sizes but are limited in their capacity to measure plant and canopy
    parameters. On the other hand, imaging sensors can be powerful in measuring a
    wide range of these parameters, especially when coupled with Artificial Intelligence.
    The challenge, however, is the lack of computing, electric power, and connectivity
    infrastructure in agricultural fields, preventing the full utilization of imaging
    sensors. This paper reported AICropCAM, a field-deployable imaging framework that
    integrated edge image processing, Internet of Things (IoT), and LoRaWAN for low-power,
    long-range communication. The core component of AICropCAM is a stack of four Deep
    Convolutional Neural Networks (DCNN) models running sequentially: CropClassiNet
    for crop type classification, CanopySegNet for canopy cover quantification, PlantCountNet
    for plant and weed counting, and InsectNet for insect identification. These DCNN
    models were trained and tested with >43,000 field crop images collected offline.
    AICropCAM was embodied on a distributed wireless sensor network with its sensor
    node consisting of an RGB camera for image acquisition, a Raspberry Pi 4B single-board
    computer for edge image processing, and an Arduino MKR1310 for LoRa communication
    and power management. Our testing showed that the time to run the DCNN models
    ranged from 0.20 s for InsectNet to 20.20 s for CanopySegNet, and power consumption
    ranged from 3.68 W for InsectNet to 5.83 W for CanopySegNet. The classification
    model CropClassiNet reported 94.5 % accuracy, and the segmentation model CanopySegNet
    reported 92.83 % accuracy. The two object detection models PlantCountNet and InsectNet
    reported mean average precision of 0.69 and 0.02 for the test images. Predictions
    from the DCNN models were transmitted to the ThingSpeak IoT platform for visualization
    and analytics. We concluded that AICropCAM successfully implemented image processing
    on the edge, drastically reduced the amount of data being transmitted, and could
    satisfy the real-time need for decision-making in PA. AICropCAM can be deployed
    on moving platforms such as center pivots or drones to increase its spatial coverage
    and resolution to support crop monitoring and field operations. Graphical abstract
    Download : Download high-res image (227KB) Download : Download full-size image
    Previous article in issue Next article in issue Keywords Artificial intelligenceComputer
    visionEdge computingInternet of thingsLoRaWANPrecision agriculture 1. Introduction
    The demands for food, feed, fiber, and fuel increase rapidly due to the fast expansion
    of the global population, income growth, technological advancement, and transport
    and logistics improvements (van Dijk et al., 2021). Precision agriculture (PA),
    which seeks to apply the right amount of inputs (fertilizers, irrigation water,
    pesticides, and other chemicals) in the right location at the right time, is essential
    to meet the requirements of future global food production, as well as environmental
    sustainability and climate resilience. PA is predicated on accurate sensor measurements,
    timely and sound decision-making, and automated actuators. The backbone of PA
    is the Internet of Things (IoT) technology that automates data collection, data
    analytics, data presentation, control, and efficient data communication (Chamara
    et al., 2022). Imaging sensors or digital cameras are essential for PA as they
    can capture more information than traditional scalar or vector sensors. Images
    can capture crop phenology for precise decision-making (Taylor and Browning, 2022,
    Tian et al., 2020). Cyclic events such as vegetative growth, flowering, leaf count
    and color change, maturation, and senescence are studied in crop phenology, which
    is essential to PA as it determines the management inputs required by crops. Moreover,
    images have rich information on the scene that allows for pest pressure evaluation.
    At present, a limited number of sensors are available for pest identification
    and pest pressure estimation. Among them, imaging sensors provide the most promising
    solution. Conventional (handcrafted feature extraction) and Artificial Intelligence
    (AI)-based image processing are the two branches of image processing. Traditional
    approaches extract image features defined by shape, texture, and color (Anubha
    et al., 2019, Yuan et al., 2019). The AI-based methods use Convolutional Neural
    Networks (CNN) to extract features from images (Luis et al., 2020). CNN models
    with multiple hidden layers for feature extraction and learning are considered
    Deep Convolutional Neural Networks (DCNN) (LeCun et al., 1998). Conventional imaging
    platforms in PA store images locally using onboard storage memories. Post processing
    refers to the processing of images stored at the central data storage in batches
    at a later time to extract useful information (Aasen et al., 2020). Imaging platforms
    that can access the internet through a stable connection with high bandwidth can
    automatically upload images to Cloud data storage. The vast majority of farmlands
    worldwide are in rural and remote areas with poor access to electric power and
    internet connectivity. This represents a big challenge for camera systems deployed
    in rural farmlands for high-speed image processing, data transmission, and low-latency
    decision-making (Richardson, 2019). Post-processing of crop images has been used
    for the estimation of leaf area index (Aasen et al., 2020), growth rate (Sakamoto
    et al., 2012), leaf chlorophyll and nitrogen content (Wang et al., 2014), fruit
    counts (Wang et al., 2014), and plant height (Sritarapipat et al., 2014). Further
    post-image processing allows for the assessment of biotic stress, such as pest
    density (Barbedo, 2014; Park et al., 2007) and weed pressure (Wang et al., 2019),
    as well as abiotic stress, such as nutrient deficiency (Ghorai et al., 2021).
    Richardson (2019) suggested that deep learning-based methods have the potential
    to facilitate the extraction of more sophisticated phenological data from both
    new and previously archived camera imagery compared to conventional image processing.
    Semantic segmentation-based canopy coverage (CC) estimation (Chamara et al., 2021;
    Liang et al., 2023), image classification-based crop identification (Anubha et
    al., 2019), disease identification (Sharma et al., 2020), growth stage prediction
    (Yasrab et al., 2021) and object detection-based plant feature identification
    (A. Wang et al., 2019) are examples of DCNN applications in agriculture. Conventional
    image processing requires less computational power and less energy, but they are
    limited in adaption to new scenarios, while deep learning requires high computational
    power and consumes more energy. DCNN models require large memory due to the large
    number of parameters these models hold. Therefore, it is not easy to implement
    these models practically in embedded systems that have less memory and computation
    power. These models also require a large amount of data to train to predict with
    high accuracy. Therefore, it is resource intensive. Edge image processing is the
    image processing done on image-capturing devices. The main advantage of edge image
    computing is that it lowers the high throughput data transmission requirement
    over a wireless IoT-enabled imaging network (Cao et al., 2020). Wang et al. (2022a)
    demonstrated the capability of identifying potted flowers with precision above
    89 % in real-time in a Jetson TX 2 computing module based on a DCNN algorithm.
    These authors suggested that a cloud-edge collaborative framework could achieve
    real-time and automatic learning for the DCNN model they have developed. Wang
    et al. (2022b) proposed a real-time weed detection model run on Jetson AGX Xavier
    for field robots. The authors proved it was possible to do real-time weed detection
    with a precision above 90 % yet required expensive hardware. Wang et al. (2022a)
    reviewed Raspberry Pi single-board computer-based real-time image processing applications.
    They concluded that Raspberry Pi (Datasheet Raspberry Pi Model B, 2019) is a cost-effective
    edge computing unit that could potentially be used as an edge image processing
    unit, and the capability of integrating it with IoT was also discussed. Zualkernan
    et al. (2022) demonstrated an edge image processing platform for the classification
    of animals and transmitting the identified animal and time of identification via
    LoRa for a camera trap. Past literature on IoT and image processing applications
    in agriculture has highlighted a research gap in edge image processing with IoT-enabled
    crop monitoring cameras. In-field crop cameras are expected to make real-time
    crop management decisions based on real-time image processing; however, poor internet
    connectivity in agricultural fields severely limits their capability. To address
    this gap, we have developed a novel imaging platform named AICropCAM that extracts
    plant and crop canopy level parameters through DCNN and uploads them to the Cloud
    via low-power, low-throughput communication protocols. We also demonstrated AICropCAM
    on an IoT-enable wireless sensor network in corn and soybean fields. A technology
    that addresses image processing at the lowest level (edge) and transmits only
    useful information can revolutionize real-time decision-making in PA. Therefore,
    the main objective of this paper is to demonstrate AICropCAM to perform edge image
    processing and low-throughput, low-power, and long-range data transmission through
    IoT technology. In this novel AICropCAM platform, multiple DCNN image processing
    algorithms run in series to extract plant-level and canopy-level features in an
    embedded system. Image classification, object detection with classification, and
    image segmentation are the three major applications of DCNN image processing,
    and all three are included in AICropCAM to demonstrate the capabilities of DCNN
    for image processing in PA. AICropCAM has trained models for canopy segmentation,
    crop classification, plant growth stage identification, plant counting, weed counting,
    and plant type identification. All the protocols that transmit data from AICropCAM
    to the Cloud were custom designed. AICropCAM sends the generated data to a cloud
    platform for logging, visualization, and analysis. Furthermore, this paper explains
    the DCNN model training process, model performance, and test results. We reported
    the model training comprehensively because it was essential for AICropCAM development.
    2. Materials and methods Essential activities in this research were data/image
    collection and preprocessing, hardware design for AICropCAM, software design for
    data transmission between the edge and the Cloud, deep learning model design,
    and model training and optimization (Fig. 1). AICropCAM was implemented in a corn
    and soybean field at the field phenotyping facility in Mead, Nebraska, USA (Bai
    et al., 2019). We demonstrated the training of the following DCNNs: CropClassiNet
    for classifying images based on image quality and crop type, CanopySegNet for
    segmenting crop canopy from the background, PlantCountNet for classifying and
    counting soybean and weed plants, and InsectNet for identifying insects and counting
    them. Download : Download high-res image (412KB) Download : Download full-size
    image Fig. 1. Steps of edge image processing program deployment on the embedded
    system (edge devices). 2.1. Image collection, annotation, preprocessing, and augmentation
    Image collection for DCNN model training occurred in four growing seasons using
    three different types of cameras: (i) commercially available Meidas SL122 trail
    cameras in 2019 (Meidas Trail Cameras, 2022), (ii) OV5642 imaging sensors with
    ArduCAM camera shields in 2020, and (iii) Raspberry Pi Camera Module V2 with Raspberry
    Pi Zero in 2021 and 2022 (Chamara, 2021). All the cameras were mounted on the
    bars horizontally extended and fixed on stationary poles erected vertically in
    the fields, as shown in Fig. 2A. The distance between the crop canopy and the
    cameras was maintained between 0.5 and 1.5 m throughout the growing seasons. Images
    used for training the InsectNet were also captured with smartphones as we could
    not collect enough images with insects from the three types of cameras mentioned
    above. Download : Download high-res image (338KB) Download : Download full-size
    image Fig. 2. Left: An Illustration of how AICropCAM was set up in the field for
    image collection. In addition to the camera, other components such as the solar
    panel and data logger were also shown. Right: A close-up view of AICropCAM and
    its hardware components. All three standard image annotation techniques in deep
    learning model training were utilized: (1) folder labeling for the image classification
    models, (2) pixel-level annotation for the semantic segmentation model, and (3)
    bounding boxes for object detection models. Images belonging to the same class
    were grouped into a single folder, and five distinct classes (or folders) were
    created: rejected, corn, soybean, grass, and night. Separating the crop canopy
    from the soil was done with pixel-level annotation and semantic segmentation.
    Bounding boxes, the smallest rectangle around an object, were drawn for corn plants,
    soybean plants, weed plants, and insects. Table 1 explains each type of annotation
    used in the model training. Table 1. Annotation criteria used to generate labels
    from the images to train and test the four deep convolutional neural network models
    in AICropCAM. Labeling Type Class Description Image classification (CropClassiNet)
    Rejected Images were labeled as rejected due to multiple reasons: blurred images
    caused by water droplets on the lens; the cameras turned away from the targeted
    crop; crops growing up to the camera blocking the view or capturing only a few
    leaves; people present in the images; lens covered with different stuff; and the
    camera was not installed in the field. Corn Images entirely covered by corn plants
    at different growth stages. Soybean Images entirely covered by soybean plants
    at different growth stages. Grass/Weed Images only comprise grass/weed plants
    at different growth stages. Night Images captured under low lighting conditions.
    Most of the cameras were not programmed to stop collecting images under low light.
    Crop canopy and background (CanopySegNet) Canopy Pixel labeling was done on the
    crop canopy. We used assisted freehand tool and the superpixel option in the MATLAB
    image labeler. Background Pixel labeling was done on the crop canopy. We used
    assisted freehand tool and the superpixel option in the MATLAB image labeler.
    Plant-type (PlantCountNet) Weed Weed present in the image was labeled using bounding
    boxes. It was challenging to locate the weed after the corn or soybean canopy
    was closed. Soybean Soybean plants present in the image were labeled using bounding
    boxes. Insects (InsectNet) Insects During the labeling process, without distinguishing
    insects based on their type, all the insects present in the images were labeled
    using bounding boxes. Image preprocessing is necessary for DCNN model training
    and real-time edge image processing. Differences in the input layer size in different
    DCNN models demand that images be resized before passing through the model for
    training or prediction purposes. High-resolution images improve accuracy but require
    more computational power. For specific applications, labeled datasets were only
    limitedly available. Therefore, image augmentation techniques were used to increase
    the number of image data sets, including scaling, flipping, cropping, rotation,
    color transformation, PCA color augmentation, and noise rejection (Paymode and
    Malode, 2022). Multiple augmentation techniques were used for each model, as detailed
    in Table 2. Additionally, Table 2 provides the numbers of images in training,
    validation, and testing for the four DCNN models. Table 2. DCNN model image allocation
    and image augmentation. Model Number of images Data Augmentation Techniques Total
    Training Validation Test CropClassiNet 43,611 30,528 9,810 3,273 Random rotation,
    random X  and Y reflection CanopySegNet 51 31 10 10 Transformation (random left/right
    reflection and random X/Y translation of ±10 pixels) PlantCountNet 110 88 11 11
    Transformation (same as CanopySegNet) InsectNet 542 326 108 108 Transformation
    (same as CanopySegNet) Our main objective was not to make the most accurate prediction
    for the DCNN models but to demonstrate the concept of implementing edge image
    processing and transmitting the results to the Cloud for decision-making. Therefore,
    we selected a limited number of images for CanopySegNet, PlantCountNet, and InsectNet,
    which were sufficient to train models with a reasonable degree of accuracy. 2.2.
    DCNN model architecture selection, training, evaluation, and deployment on the
    edge device The steps to select model architecture/model backbone weights and
    image input sizes to train the best model for CropClassiNet, CanopySegNet, PlantCountNet,
    and InsectNet are summarized in Fig. 3. Unlike many DCNN applications that prioritize
    higher accuracy, our application focused on finding the balance between accuracy
    and model deployability on the edge device. Download : Download high-res image
    (771KB) Download : Download full-size image Fig. 3. DCNN model selection process
    during the training and testing by attempting different model architectures, model
    backdone weights, and input image sizes. For example, in the development of CropSegNet
    (Segmentation), we selected DeepLabv3+ (Firdaus-Nawi et al., 2018) with weights
    initialized from pre-trained networks of ResNet18 (He et al., 2016), ResNet50,
    Xception, InceptionresnetV2, and MobileNetV2. The input image sizes tested were
    512 × 512 × 3 and 256 × 256 × 3, and training options were kept constant to find
    the best-performing networks, which should also be deployable to Raspberry Pi
    4B. This process identified DeepLabv3 + with ResNet50 as the most suitable model
    for CropSegNet, with an input image size of 512 × 512 × 3. Table 3 summarizes
    the hyperparameter values and training options for the final DCNN models deployed
    to the edge device. (1) (2) (3) (4) (5) (6) (7) Table 3. Hyperparameter values
    and training options for the best models (SGDM - stochastic gradient descent with
    momentum, RMSProp - Root mean square propagation). Training option and the function/Hyperparameters
    Values for CropClassiNet Values for CanopySegNet Values for InsectNet (320 × 320
    × 3) Values for PlantCountNet (320 × 320 × 3) Optimizer SGDM SGDM SGDM RMSProp
    Momentum 0.9 0.9 0.99 NA Initial learning rate 0.001 0.001 0.001 0.001 Learn rate
    schedule Piecewise Piecewise Piecewise Piecewise Learn rate drop period 10 10
    10 10 Learn rate drop factor 0.3 0.3 0.1 0.3 Minibatch size 16 4 16 32 L2Regularization
    NA 0.005 0.005 0.005 Validation frequency 3 3 3 10 Shuffle Every epoch Every epoch
    Every epoch Every epoch Validation patience 4 10 10 10 Max epochs 100 300 1000
    100 Execution environment Multi GPU Multi GPU GPU GPU The performance of the four
    DCNN models was evaluated using the indices calculated from Eq. (1), (2), (3),
    (4), (5), (6), (7). Accuracy, Precision, Recall, F1 score, and Jaccard index were
    used for the classification models CropClassiNet and CropSegNet, whereas IoU and
    mAP (Mean Average Precision) were used for PlantCountNet and InsectNet. Jaccard
    index gives the proportion of correctly predicted labels to the total number of
    labels. Model training was performed on an NVIDIA GeForce GTX 1650 Ti Mobile processor,
    a dedicated mid-range graphics card with 4 GB GDDR6 memory on a Dell XPS 15 9500
    Laptop. The laptop had an Intel Core i7-10750H 10th Gen processor,16 GB DDR4 RAM,
    and 1 TB SSD hard disk. 2.3. Hardware and software of AICropCAM The IoT data transmission
    and edge image processing hardware comprised the following major components: a
    Raspberry Pi 4B single-board computer, an Arduino MKR1310 development board, an
    Arduino MKR Relay Proto Shield, and a Dragino OLG02 outdoor dual channels LoRa
    Gateway (Fig. 4). The 12 V 8Ah battery powered the Raspberry Pi 4B, controlled
    through the relay shield managed by the Arduino MKR1310. A 3.7 V lithium polymer
    battery powered the Arduino MKR1310 board. There are two advantages of having
    a separate Arduino board. First, the Arduino board consumes less power than the
    Raspberry Pi 4B module. It can be switched on and off according to user requirements.
    Second, it allows uninterrupted communication between the edge node and the Cloud
    with low power. Download : Download high-res image (303KB) Download : Download
    full-size image Fig. 4. Hardware overview of AICropCAM and data flow. AICropCAM
    required programming on two hardware platforms. Arduino was programmed using C++
    in Arduino’s Integrated Development Environment. Raspberry Pi imaging and image
    processing program was developed in MATLAB and deployed onto the Raspberry Pi
    4B using the MATLAB Coder and MATLAB Compiler. A python program was designed to
    read the saved data in the Raspberry Pi 4B and serially communicate to the Arduino
    MKR1310. The primary functions of the MRK1310 program were to (1) turn on the
    Raspberry Pi 4B module based on the user-defined time intervals, (2) get the processed
    data, including the results of DCNN model predictions, through serial communication
    from the Raspberry Pi 4B, and (3) transmit the data to the ThingSpeak Cloud channel
    through the LoRa gateway. All the DCNN models were trained using the MATLAB deep
    learning toolbox. In the edge deployment, a MATLAB program runs multiple models
    logically depending on the prediction result of the previous model estimation,
    as shown in Fig. 5. MATLAB coder generated the C and C++ code derived from the
    program we developed to run on the Raspberry Pi. MATLAB Compiler generated the
    standalone application on the Raspberry Pi (The MathWorks, 2022). Download : Download
    high-res image (477KB) Download : Download full-size image Fig. 5. Overall sequential
    image processing and data generation flow chart. Table 4 lists the parameters
    generated by the models in AICropCAM. The abbreviations in Table 4 are fields
    holding data in the program to reduce the complexity of system development and
    maintain a common standard among different platforms. Fig. 6 shows the data generation
    from images. According to Fig. 6, the size of the images were around 2 MB before
    being fed into the image processing pipeline. The output message contains the
    crop type (CT), plant count (PC), weed count (WC), canopy coverage (CC), and pest
    count (PstC). The resulting message is typically less than 100 bytes. This represents
    a substantial reduction of memory size with the output being 0.00005 times the
    size of the original image. Consequently, this message can be transmitted in a
    single message via LoRa as the maximum LoRa packet size is around 256 bytes. Table
    4. List of parameters used to represent information in the images. Parameter Abbreviation
    Represent information Image location LOC Node ID manually entered/Global positioning
    system location coordinates Image orientation IO Accelerometer/Manually feed/Gravity
    switch Image quality/Crop type CT Image classification based on image quality
    and the crop type Plant count/Weed count PC/WC Multiclass object detection/classification
    Crop canopy coverage CC Semantic segmentation Pest count PstC Multiclass object
    detection/classification Download : Download high-res image (2MB) Download : Download
    full-size image Fig. 6. Examples of message generation and data size reduction
    for LoRa transmission. 2.4. Data transmission, visualization, and storage The
    data generated after image processing were saved on the Raspberry Pi 4B SD card,
    allowing access to the data remotely or through manual retrieval during field
    visits. Two options for transmitting the collected data to the ThingSpeak IoT
    platform are available. Firstly, the data can be uploaded directly from the Raspberry
    Pi 4B if internet connectivity is available for growers with Wi-Fi access. Secondly,
    the Raspberry Pi 4B transmits the recently acquired data to the Arduino MKR1310.
    The Arduino MKR1310 decodes the data received from the Raspberry Pi 4B and forwards
    it to the ThingSpeak. The second method is for low-rate, long-range communication
    beyond the limit of Wi-Fi. A single message receivable to the ThingSpeak server
    includes data for eight fields. In our demonstration, a single message was enough
    to transmit the data generated. Fields 1 and 2 are reserved for geographic coordinates
    (namely, latitude and longitude) to represent the device''s location. The third
    field was for camera orientation. Image quality/crop type, plant count, weed count,
    insect count, and crop canopy coverage were allocated from fields four to eight.
    ThingSpeak supports eight channels per gateway. If additional data is generated
    in the future, we have to create new channels to accommodate them. However, only
    data in a single channel can be passed through a single message. The Arduino-LoRa
    library was used to prepare the LoRa messages forwarded to the gateway (Mistry,
    2016). The message generated from the Arduino MKR1310 includes the device identification
    number and the data with the field number. Once the gateway receives this message,
    it adds the target client ID (generated by ThingSpeak when defining a device),
    host address (mqtt://mqtt3.thingspeak.com), server port number, username and password,
    channel ID, and the data in each field according to the Message Queuing Telemetry
    Transport (MQTT) protocol. Username and password ensure that only authorized devices
    can transmit data to the ThingSpeak platform. ThingSpeak provides two ways to
    interact with its platform, REST (Representative State Transfer) and MQTT protocols.
    The advantages of using MQTT over REST protocol are that it supports ThingSpeak
    data publishing, including immediate and minimum power consumption and data transmission
    over limited bandwidth, which encouraged us to select the MQTT protocol in our
    demonstration. 3. Results and discussion 3.1. DCNN model performance CropClassiNet
    had a test accuracy of 91.26 %, a Jaccard Index of 0.77, and an F1-score of 0.91;
    the confusion matrix is given in Fig. 7. The highest precision is for the “grass”
    class (100 %), and the lowest is for “soybean” (92.0 %). The highest recall is
    for the “corn” class (99.9 %), and the lowest is for “grass” (67.1 %). The primary
    goal of CropClassiNet is to determine the quality of new images and direct them
    for subsequent processing (Fig. 5). This step has never been executed in an image-based
    crop monitoring platform before. Further, CropClassiNet can eliminate erroneous
    images when humans are present in the camera’s field of view or when the camera
    is misaligned due to external factors. AICropCAM can send maintenance requests
    through IoT analytics if rejected images are continuously generated. Download
    : Download high-res image (275KB) Download : Download full-size image Fig. 7.
    Confusion matrix for test images by CropClassiNet. CanopySegNet on the test images
    achieved a global accuracy of 0.93, a weighted IoU of 0.87, and a mean BF score
    of 0.73. Fig. 8 shows an example of an original soybean image and the corresponding
    segmentation result by CanopySegNet, which estimated CC to be 18.72 %. Season-long,
    time-series images can be fed into CanopySegNet to generate diurnal and seasonal
    curves of crop CC, as shown in Fig. 9. Download : Download high-res image (621KB)
    Download : Download full-size image Fig. 8. An image of soybean crop and the segmentation
    result by CropSegNet to calculate canopy coverage. Download : Download high-res
    image (367KB) Download : Download full-size image Fig. 9. Examples of diurnal
    and seasonal variations of canopy coverage as computed by CropSegNet. According
    to Fig. 9, canopy coverage percentage variation is low during the daytime and
    reaches zero at night. This verifies the need to eliminate low-light images before
    segmenting. As shown in Fig. 5, it is possible to eliminate the generation of
    false values when the camera captures images under low light conditions by halting
    the process of running CanopySegNet. There are three diurnal variation series
    on 6/8/2021, 6/26/2021, and 7/12/2021 in Fig. 9. The CC increased from 8 % to
    95 % between 6/8/2021 to 7/12/2021. The seasonal trend showed that the CC reached
    a maximum around 7/8/2021. These results suggest that the proposed stacked models
    can track the daily and seasonal CC variation and eliminate the effect of lighting
    conditions on false value generation. Table 5. Performance of PlantCountNet and
    InsectNet on the test image set (Root mean square error (RMSE)/Final validation
    loss (FVL)). Model Name Architecture Input size Validation RMSE/FVL Mean average
    precision Object class PlantCountNet YOLOv2 320 × 320 × 3 0.888 (RMSE) 0.66 Soybean
    0.86 Weed InsectNet YOLOv4 320 × 320 × 3 26.2 (FVL) 0.02 Insect The overall performance
    of the PlantCountNet and InsectNet is given in Table 5. Fig. 10(A) and 10(B) show
    the result obtained by PlantCountNet for a soybean image at an early vegetative
    stage (V3). Meanwhile Fig. 10(C) and 10(D) shows the result at a reproductive
    stage (R1). It can be seen that, at V3 stage, the model outputs matched the labels
    of soybean and weed plants well, indicating a level of high accuracy. Download
    : Download high-res image (1MB) Download : Download full-size image Fig. 10. The
    result of PlantCountNet for soybean and weed counting: Manually annotated vs.
    model-predicted bounding boxes at V3 growth stage (A and B); manually annotated
    vs. model-predicted bounding boxes at R1 growth stage (C and D). The size of insects
    is very small compared to the size of images (Fig. 11), which is the main reason
    for the low mAP for InsectNet (Table 5). Increasing input image resolution beyond
    480 × 480 × 3 is impractical as it exceeds the memory limitation to load models
    into Raspberry Pi 4B. A potential solution could be to increase the resolution
    of the region of interest by splitting the original image while keeping the resolution
    the same. Also, we suggest using the approach recommended by Tetila et al., 2020a,
    Tetila et al., 2020b in the future on Raspberry Pi model 4B. As technology advances,
    we expect the memory capacities will increase for edge computing units. At the
    same time, the state-of-the-art object detection algorithms will improve the accuracy
    for small object detection. Download : Download high-res image (1MB) Download
    : Download full-size image Fig. 11. The result of InsectNet for insect counting
    in soybean. The top row shows a situation of high false positives and low false
    negatives: (A) and (B) are manually annotated and model-predicted insect labels,
    respectively. The bottom row shows a situation of low false positive and high
    false negative: (C) and (D) are manually annotated and model-predicted insect
    labels. 3.2. Power consumption for Raspberry Pi 4B Since edge cameras in farmlands
    have limited access to electric power, information on their power consumption
    is essential for designing IoT devices and systems. AICropCAM is designed to be
    energized by solar power. It runs on a rechargeable battery when there is no solar
    power. We monitored the maximum energy consumption of each task performed by AICropCAM,
    and the result is presented in Table 6. Four main strategies are available for
    the power management of IoT edge devices: Selecting power-efficient hardware,
    maintaining low power modes, dynamic power management, and cloud-based management.
    Raspberry Pi 4B is an affordable power-efficient single-board computer suitable
    for our application, but it does not naturally support low-power modes. Therefore,
    we introduced the Arduino MKR1310 LoRa module for the Raspberry Pi 4B dynamic
    power management. Furthermore, this Arduino module allows us to perform cloud-based
    central management independently. Table 6. Electrical power consumption of the
    Raspberry Pi 4B and the Arduino MKR1310 during edge image processing. Device Activity
    The maximum current range and the voltage recorded Raspberry Pi 4B Idle run 5.25
    V × (0.45 – 0.53) A Image classification 5.25 V × (0.97 – 1.04) A Image segmentation
    5.25 V × (0.98 – 1.11) A Weed and plant detection 5.25 V × (0.62 – 0.70) A Insect
    detection 5.25 V × (0.62 – 0.70) A Arduino MKR1310 Sleep mode <0.01A Serial communication
    <0.01A LoRa transmission <0.01A For our measurements, we used a Raspberry Pi 4B
    with 8 GB of RAM, connected to an HDMI monitor, a USB keyboard, and a USB mouse,
    and ran a MathWorks® Raspbian image (file used to boot the Raspberry Pi 4B). The
    Raspberry Pi 4B was operated at room temperature and connected to a wireless LAN
    access point and a laptop via an Ethernet cable. The electric current consumption
    for running each DCNN model was recorded during the test. CropClassiNet had the
    highest current consumption, while the PlantCountNet and InsectNet models had
    the lowest. As for LoRa transmission, we could not measure its current consumption
    because the lowest value our instrument could measure was 0.01A. Based on the
    manufacturer''s specifications, the Arduino MKR1310 consumes 104 uA at 5 V. The
    average time to run the DCNN models is essential to estimate the energy consumed
    for each prediction. These parameters listed in Table 7 provide essential guidelines
    for designing IoT sensor nodes with suitable batteries and power sources. We also
    noticed that typically the first prediction of a model took the longest time,
    but the rest take a considerably shorter time to predict. Table 7. Time duration
    needed for the selected DCNN models deployed in the Raspberry Pi 4B. Model/Task
    Input image size Time for predicting results (s) The maximum power demand for
    the activity (W) CropClassiNet/Image quality evaluation and crop classification
    224 × 224 × 3 6.44 5.46 CanopySegNet/Semantic segmentation to separate canopy
    from background 512 × 512 × 3 20.20 5.83 PlantCountNet/Weed and plant detection,
    classification, and counting 320 × 320 × 3 14.38 3.68 InsectNet/Insect detection
    320 × 320 × 3 0.20 3.68 Semantic segmentation was the most power-demanding activity,
    while insect detection was the least. Changing the order of the image processing
    models and adding new models or dropping existing models is possible during regular
    operation. It enables dynamic power management within the Raspberry Pi module.
    The main advantage of AICropCAM is that it implements a stack of four DCNN-based
    image processing models with multiple objectives. To the best of our knowledge,
    this is the first time such a system has been developed for a field crop monitoring
    camera. AICropCAM has applications such as setting up smart in-field or greenhouse
    IoT camera networks with edge computing capability, monitoring crops by attaching
    them to sprinkler irrigation systems (pivots and linear moves), or collecting
    crop information through ground or aerial mobile robots. The relatively short
    time to run each DCNN model makes the system suitable for real-time applications,
    including variable rate irrigation, fertilization, and spraying. For example,
    a pivot irrigated multi-cropping system with AICropCAM can automate irrigation
    or fertigation transition between different crops or crops at different growth
    stages by automatically providing the crop type or growth stage information to
    the irrigation controller. Additionally, existing herbicide or pesticide sprayers
    can get the feedback of the PlantCountNet and InsectNet in the AICropCAM for precision
    spraying. 4. Conclusion and future perspectives This paper outlines the essential
    components of constructing a functional edge image processing framework for real-time
    crop monitoring. From a software standpoint, CropClassiNet can categorize captured
    images according to image quality and detect the presence of specific crop types
    for further processing. CanopySegNet can further quantify the degree of canopy
    coverage; PlantCountNet can count the number of plants and weeds in the image;
    and finally, InsectNet can count the number of insects in the image. These four
    DCNN models, when implemented on edge devices, can extract an array of important
    crop and canopy parameters from field images and enable real-time, low-latency
    decision making and applications. Deep learning-based image processing on the
    edge has excellent potential in PA. Applications of AICropCAM are not limited
    to image classification, segmentation, plant counting, or weed counting. Potential
    future applications include insect classification and crop damage estimation,
    weed classification and pressure estimation, fruit identification and yield estimation,
    decision on replanting (Whigham et al., 2000), and disease identification and
    disease damage estimation in real time using actual field images collected by
    AICropCAM. AICropCAM shows excellent potential in enhancing crop management through
    crop monitoring. However, the current demonstration requires significant improvements
    on both hardware and software fronts. Customized circuitry and modular design
    are required to put AICropCAM in commercial farm applications. The full potential
    of the AICropCAM can be achieved by putting this camera on a moving platform like
    a center pivot with a GPS receiver to generate spatiotemporal data. Crop classification
    must include more crop types, and segmentation models need training data from
    other crop types. The DCNN models for weed and insect identification require the
    capability to identify different weed types, their growth stage, different insect
    types, and their growth stages to generate effective pest control decisions. Additionally,
    improving the models’ accuracy in image classification, segmentation, and object
    detection is crucial. It can be achieved by increasing the number of training
    image data sets. We also planned to expand the research for multiple edge architecture
    evaluation. Architectures such as a high-performance edge computer that accepts
    images from multiple edge devices through short-range, high-speed communication
    (e.g., Wi-Fi) and can run more accurate deep learning models with higher numbers
    of parameters, might be a better solution for the primary objectives addressed
    in this paper. We aim to expand the AICropCAM applications to other crops beyond
    corn and soybean. By making these improvements, AICropCAM will become a more effective
    tool for crop management, potentially revolutionizing how we grow and manage crops.
    Funding This work was supported by the United States Department of Agriculture
    – National Institute of Food and Agriculture grants [Award 2020-68013-32371 to
    YG and GB, Award 2021-67021-34417 to YG]. CRediT authorship contribution statement
    Nipuna Chamara: Methodology, Software, Visualization. Geng Bai: Conceptualization,
    Methodology, Resources. Yufeng Ge: Conceptualization, Resources, Supervision,
    Project administration, Funding acquisition. Declaration of Competing Interest
    The authors declare the following financial interests/personal relationships which
    may be considered as potential competing interests: Nipuna Chamara, Yufeng Ge,
    Geng Bai has patent pending to University of Nebraska-Lincoln. Acknowledgements
    Jianxin Sun assisted in developing the imaging device with Raspberry Pi Zero used
    for image acquisition. David Scoby helped the field management and AICropCAM installation.
    Junxiao Zhang supported the field installation of AICropCAM and smart-phone based
    acquisition of crop images with insects. Data availability Data will be made available
    on request. References Aasen et al., 2020 H. Aasen, N. Kirchgessner, A. Walter,
    F. Liebisch PhenoCams for field phenotyping: using very high temporal resolution
    digital repeated photography to investigate interactions of growth, phenology,
    and harvest traits Front. Plant Sci., 11 (June) (2020), pp. 1-16, 10.3389/fpls.2020.00593
    Google Scholar Anubha et al., 2019 P.S. Anubha, V. Sathiesh Kumar, S. Harini A
    study on plant recognition using conventional image processing and deep learning
    approaches J. Intell. Fuzzy Syst., 36 (3) (2019), pp. 1997-2004, 10.3233/JIFS-169911
    Google Scholar ArduCAM, 2016 ArduCAM ESP8266 UNO board User Guide (pp. 0–9). (2016).
    www.ArduCAM.com. Google Scholar Bai et al., 2019 G. Bai, Y. Ge, D. Scoby, B. Leavitt,
    V. Stoerger, N. Kirchgessner, S. Irmak, G. Graef, J. Schnable, T. Awada NU-Spidercam:
    A large-scale, cable-driven, integrated sensing and robotic system for advanced
    phenotyping, remote sensing, and agronomic research Comput. Electron. Agric.,
    160 (March) (2019), pp. 71-81, 10.1016/j.compag.2019.03.009 View PDFView articleView
    in ScopusGoogle Scholar Barbedo, 2014 J.G.A. Barbedo Using digital image processing
    for counting whiteflies on soybean leaves J. Asia Pac. Entomol., 17 (4) (2014),
    pp. 685-694, 10.1016/j.aspen.2014.06.014 View PDFView articleView in ScopusGoogle
    Scholar Cao et al., 2020 K. Cao, Y. Liu, G. Meng, Q. Sun An Overview on Edge Computing
    Research IEEE Access, 8 (2020), pp. 85714-85728, 10.1109/ACCESS.2020.2991734 View
    in ScopusGoogle Scholar Chamara et al., 2021 N. Chamara, K. Alkhadi, H. Jin, F.
    Bai, A. Samal, Y. Ge A deep convolutional neural network based image processing
    framework for monitoring the growth of soybean crops. 2021 ASABE Annual International
    Meeting, 2100259 (2021), 10.13031/aim.202100259 Google Scholar Chamara et al.,
    2022 N. Chamara, M.D. Islam, G.F. Bai, Y. Shi, Y. Ge Ag-IoT for crop and environment
    monitoring: Past, present, and future Agr. Syst., 203, 103497 (2022), 10.1016/j.agsy.2022.103497
    Google Scholar Chamara, 2021 N. Chamara Development of an Internet of Things (IoT)
    Enabled Novel Wireless Multi-Sensor Network for Infield Crop Monitoring. Master’s
    Thesis, Department of Biological Systems Engineering, University of Nebraska-Lincoln
    (2021) Google Scholar Datasheet Raspberry Pi Model, 2019 Datasheet Raspberry Pi
    Model B, 2019. https://datasheets.raspberrypi.org. Accessed 11 November 2023.
    Google Scholar Firdaus-Nawi et al., 2018 Firdaus-Nawi, M., Noraini, O., Sabri,
    M.Y., Siti-Zahrah, A., Zamri-Saad, M., Latifah, H., 2018. DeepLabv3+_Encoder-Decoder
    with Atrous Separable Convolution for Semantic Image Segmentation. In: Proceedings
    of the European Conference on Computer Vision (ECCV), pp. 801–818. Google Scholar
    Ghorai et al., 2021 A.K. Ghorai, A.R. Barman, B. Chandra, K. Viswavidyalaya, S.
    Jash, B. Chandra, K. Viswavidyalaya, B. Chandra, K. Viswavidyalaya Image processing
    based detection of diseases and nutrient deficiencies in plants SATSA Mukhapatra,
    25 (1) (2021), pp. 1-24 Google Scholar He et al., 2016 He, K., Zhang, X., Ren,
    S., Sun, J., 2016. Deep residual learning for image recognition kaiming. In: Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778.
    doi: 10.1002/chin.200650130. Google Scholar LeCun et al., 1998 LeCun, Y., Bottou,
    L., Bengio, Y., Haffner, P., 1998. Gradient-based learning applied to document
    recognition. Proc. IEEE 86(11), 2278–2323. doi: 10.1109/5.726791. Google Scholar
    Liang et al., 2023 Liang, W. Z., Oboamah, J., Qiao, X., Ge, Y., Harveson, B.,
    Rudnick, D. R., Wang, J., Yang, H., Gradiz, A., 2023. CanopyCAM – an edge-computing
    sensing unit for continuous measurement of canopy cover percentage of dry edible
    beans. Comput. Electron. Agric. 204 (January), 107498. https://doi.org/10.1016/j.compag.2022.107498.
    Google Scholar Luis et al., 2020 Luis, S., Filipe, N.S., Paulo, M.O., Pranjali,
    S., 2020. Deep Learning applications in agriculture: a short review. Deep Learning
    Applications in Agriculture: A Short Review, 1092 AISC(January), C1. doi: 10.1007/978-3-030-35990-4.
    Google Scholar Meidas Trail Cameras, 2022 Meidas Trail Cameras, 2022. https://www.meidase.com/product-category/trail-cameras/.
    Accessed 11 November 2023. Google Scholar Mistry, 2016 Mistry, S., 2016. Arduino
    LoRa. MIT License. https://github.com/sandeepmistry/arduino-LoRa. Accessed 11
    November 2023. Google Scholar Park et al., 2007 Y. Park, R.K. Krell, M. Carroll
    Theory, technology, and practice of site-specific insect pest management J. Asia
    Pac. Entomol., 10 (2) (2007), pp. 89-101 View PDFView articleView in ScopusGoogle
    Scholar Paymode and Malode, 2022 A.S. Paymode, V.B. Malode Transfer learning for
    multi-crop leaf disease image classification using convolutional neural network
    VGG Artif. Intell. Agric., 6 (2022), pp. 23-33, 10.1016/j.aiia.2021.12.002 View
    PDFView articleView in ScopusGoogle Scholar Richardson, 2019 A.D. Richardson Tracking
    seasonal rhythms of plants in diverse ecosystems with digital camera imagery New
    Phytol., 222 (4) (2019), pp. 1742-1750, 10.1111/nph.15591 View in ScopusGoogle
    Scholar Sakamoto et al., 2012 T. Sakamoto, A.A. Gitelson, A.L. Nguy-Robertson,
    T.J. Arkebauer, B.D. Wardlow, A.E. Suyker, S.B. Verma, M. Shibayama An alternative
    method using digital cameras for continuous monitoring of crop status Agric. For.
    Meteorol., 154–155 (2012), p. 113, 10.1016/j.agrformet.2011.10.014 View PDFView
    articleView in ScopusGoogle Scholar Sharma et al., 2020 P. Sharma, Y.P.S. Berwal,
    W. Ghai Performance analysis of deep learning CNN models for disease detection
    in plants using image segmentation Inf. Process. Agric., 7 (4) (2020), pp. 566-574,
    10.1016/j.inpa.2019.11.001 View PDFView articleView in ScopusGoogle Scholar Sritarapipat
    et al., 2014 T. Sritarapipat, P. Rakwatin, T. Kasetkasem Automatic rice crop height
    measurement using a field server and digital image processing Sensors (Switzerland),
    14 (1) (2014), pp. 900-926, 10.3390/s140100900 View in ScopusGoogle Scholar Taylor
    and Browning, 2022 S.D. Taylor, D.M. Browning Classification of daily crop phenology
    in phenocams using deep learning and hidden markov models Remote Sens. (Basel),
    14 (2) (2022), pp. 1-22, 10.3390/rs14020286 Google Scholar Tetila et al., 2020a
    Tetila, E.C., Machado, B.B., Astolfi, G., Belete, N.A.S., Amorim, W.P., Roel,
    A.R., Pistori, H., 2020. Detection and classification of soybean pests using deep
    learning with UAV images. Computers and Electronics in Agriculture, 179(May).
    doi: 10.1016/j.compag.2020.105836. Google Scholar Tetila et al., 2020b E.C. Tetila,
    B.B. MacHado, G.V. Menezes, N.A. De Souza Belete, G. Astolfi, H. Pistori A deep-learning
    approach for automatic counting of soybean insect pests IEEE Geosci. Remote Sens.
    Lett., 17 (10) (2020), pp. 1837-1841, 10.1109/LGRS.2019.2954735 View in ScopusGoogle
    Scholar The MathWorks, 2022 The MathWorks, I., 2022. MATLAB Coder - MATLAB. MathWorks.
    https://www.mathworks.com/products/matlab-coder.html. Google Scholar Tian et al.,
    2020 H. Tian, T. Wang, Y. Liu, X. Qiao, Y. Li Computer vision technology in agricultural
    automation—a review Inf. Process. Agric., 7 (1) (2020), pp. 1-19, 10.1016/j.inpa.2019.09.006
    View PDFView articleView in ScopusGoogle Scholar van Dijk et al., 2021 M. van
    Dijk, T. Morley, M.L. Rau, Y. Saghai A meta-analysis of projected global food
    demand and population at risk of hunger for the period 2010–2050 Nat. Food, 2
    (7) (2021), pp. 494-501, 10.1038/s43016-021-00322-9 View in ScopusGoogle Scholar
    Wang et al., 2022b Q. Wang, M. Cheng, S. Huang, Z. Cai, J. Zhang, H. Yuan A deep
    learning approach incorporating YOLO v5 and attention mechanisms for field real-time
    detection of the invasive weed Solanum rostratum Dunal seedlings Comput. Electron.
    Agric., 199 (July) (2022), Article 107194, 10.1016/j.compag.2022.107194 View PDFView
    articleView in ScopusGoogle Scholar Wang et al., 2022a J. Wang, Z. Gao, Y. Zhang,
    J. Zhou, J. Wu, P. Li Real-time detection and location of potted flowers based
    on a ZED camera and a YOLO V4-tiny deep learning algorithm Horticulturae, 8 (1)
    (2022), 10.3390/horticulturae8010021 Google Scholar Wang et al., 2014 Y. Wang,
    D. Wang, P. Shi, K. Omasa Estimating rice chlorophyll content and leaf nitrogen
    concentration with a digital still color camera under natural light Plant Methods,
    10 (3) (2014), pp. 273-286, 10.1016/S0378-4290(99)00063-5 View in ScopusGoogle
    Scholar Wang et al., 2019 A. Wang, W. Zhang, X. Wei A review on weed detection
    using ground-based machine vision and image processing techniques Comput. Electron.
    Agric., 158 (January) (2019), pp. 226-240, 10.1016/j.compag.2019.02.005 View PDFView
    articleView in ScopusGoogle Scholar Whigham et al., 2000 K. Whigham, D. Farnham,
    J. Lundvall, D. Tranel Soybean replant decision, Department of Agronomy, Iowa
    State University (2000) Google Scholar Yasrab et al., 2021 R. Yasrab, J. Zhang,
    P. Smyth, M.P. Pound Predicting plant growth from time-series data using deep
    learning Remote Sens. (Basel), 13 (3) (2021), pp. 1-17, 10.3390/rs13030331 View
    in ScopusGoogle Scholar Yuan et al., 2019 W. Yuan, N.K. Wijewardane, S. Jenkins,
    G. Bai, Y. Ge, G.L. Graef Early prediction of soybean traits through color and
    texture features of canopy RGB imagery Sci. Rep., 9 (2019), p. 14089, 10.1038/s41598-019-50480-x
    View in ScopusGoogle Scholar Zualkernan et al., 2022 I. Zualkernan, S. Dhou, J.
    Judas, A.R. Sajun, B.R. Gomez, L.A. Hussain An IoT system using deep learning
    to classify camera trap images on the edge Computers, 11 (1) (2022), pp. 1-24,
    10.3390/computers11010013 Google Scholar Cited by (1) YOLO performance analysis
    for real-time detection of soybean pests 2024, Smart Agricultural Technology Show
    abstract © 2023 The Authors. Published by Elsevier B.V. Part of special issue
    Agricultural Cybernetics: A New Methodology of Analysis and Development for Modern
    Agricultural Production Systems Edited by Yanbo Huang, Manoj Karkee, Lie Tang,
    Dong Chen View special issue Recommended articles Joint control method based on
    speed and slip rate switching in plowing operation of wheeled electric tractor
    equipped with sliding battery pack Computers and Electronics in Agriculture, Volume
    215, 2023, Article 108426 Qi Wang, …, Yongjie Cui View PDF LSCA-net: A lightweight
    spectral convolution attention network for hyperspectral image processing Computers
    and Electronics in Agriculture, Volume 215, 2023, Article 108382 Ziru Yu, Wei
    Cui View PDF Automatic detection of crop lodging from multitemporal satellite
    data based on the isolation forest algorithm Computers and Electronics in Agriculture,
    Volume 215, 2023, Article 108415 Rui Guo, …, Tingting Liu View PDF Show 3 more
    articles Article Metrics Citations Citation Indexes: 1 Captures Readers: 19 View
    details About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'AICropCAM: Deploying classification, segmentation, detection, and counting
    deep-learning models for crop monitoring on the edge'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Verma J.
  - Snehi M.
  - Kansal I.
  - Tiwari R.G.
  - Prasad D.
  citation_count: '0'
  description: Precision agriculture is not only crucial for optimizing crop management
    practices but also has a significant impact on social learning. With the increasing
    demand for food, it is essential to ensure the sustainable production of crops.
    One important aspect of precision agriculture is weed detection, which can help
    farmers reduce herbicide use, increase crop yield, and improve sustainability.
    In recent years, deep learning techniques have gained significant interest for
    weed detection in precision agriculture due to their potential to automate and
    optimize crop management practices. This research study compares and analyzes
    various deep learning models, preprocessing and feature extraction techniques,
    and performance metrics used in existing studies on weed detection in precision
    agriculture. The results indicate that deep learning models with convolutional
    neural networks (CNNs), You Only Look Once version 3 (YOLOv3), and faster R-CNN,
    combined with preprocessing techniques such as histogram equalization, segmentation,
    and OTSU binarization, yield the best performance in weed detection. The study
    also identifies the limitations and challenges of existing approaches and suggests
    directions for future research. The review provides valuable insights into the
    current state of the art in weed detection using deep learning techniques and
    serves as a guide for researchers and practitioners interested in developing automated
    weed detection systems for precision agriculture. The performance evaluation of
    the proposed approach involved comparing the results of the weed detection and
    classification using the deep learning model with and without the use of internet
    of things (IoT)-based edge computing. The evaluation metrics used in the study
    included precision, recall, and F1-score. The experimental setup involved training
    the deep learning model on the CropDeep dataset and the UC Merced Land Use dataset.
    The dataset was split into training, validation, and testing sets in a 60:20:20
    ratio. The model was trained using stochastic gradient descent with a learning
    rate of 0.001 and a batch size of 32. The model was trained for 50 epochs, and
    the weights were saved at the end of each epoch. The proposed approach was evaluated
    on a test set of 100 images of crops, and the results were compared with the results
    obtained without the use of IoT-based edge computing. The evaluation showed that
    the proposed approach improved the performance of the deep learning model, with
    an overall F1-score of 0.95, compared to an F1-score of 0.89 without the use of
    IoT-based edge computing. This indicates that the proposed approach can effectively
    detect and classify weeds in crops using IoT-based edge computing. The study also
    includes a table that compares the three methods (CNN, YOLOv3, and faster R-CNN)
    based on accuracy, precision, recall, and F1-score. The experimental results show
    that all three methods achieved high levels of accuracy, with faster R-CNN performing
    the best at 96.3%. YOLOv3 had the highest precision at 96.2%, while faster R-CNN
    had the highest recall at 95.8%. The faster R-CNN method had the highest F1-score
    at 96.3%, indicating the best balance between precision and recall.
  doi: 10.1515/9783110981445-014
  full_citation: '>'
  full_text: '>

    "Skip to content Authenticated with University of Nebraska - Lincoln What does
    this mean? $ USD € EUR - Euro £ GBP - Pound $ USD - Dollar EN 0 University of
    Nebras... SUBJECTS FOR AUTHORS SERVICES PUBLICATIONS ABOUT Unlicensed Published
    by De Gruyter 2024 14 Real-time weed detection and classification using deep learning
    models and IoT-based edge computing for social learning applications From the
    book Augmented and Virtual Reality in Social Learning Devendra Prasad https://doi.org/10.1515/9783110981445-014
    Cite this Share this Your institution currently does not have access to this content.
    If you are connected to another institution, please log in using those credentials.
    Otherwise, please contact your institution to request additional assistance in
    procuring this content. For more information see https://www.degruyter.com/how-access-works
    Showing a limited preview of this publication: Abstract Precision agriculture
    is not only crucial for optimizing crop management practices but also has a significant
    impact on social learning. With the increasing demand for food, it is essential
    to ensure the sustainable production of crops. One important aspect of precision
    agriculture is weed detection, which can help farmers reduce herbicide use, increase
    crop yield, and improve sustainability. In recent years, deep learning techniques
    have gained significant interest for weed detection in precision agriculture due
    to their potential to automate and optimize crop management practices. This research
    study compares and analyzes various deep learning models, preprocessing and feature
    extraction techniques, and performance metrics used in existing studies on weed
    detection in precision agriculture. The results indicate that deep learning models
    with convolutional neural networks (CNNs), You Only Look Once version 3 (YOLOv3),
    and faster R-CNN, combined with preprocessing techniques such as histogram equalization,
    segmentation, and OTSU binarization, yield the best performance in weed detection.
    The study also identifies the limitations and challenges of existing approaches
    and suggests directions for future research. The review provides valuable insights
    into the current state of the art in weed detection using deep learning techniques
    and serves as a guide for researchers and practitioners interested in developing
    automated weed detection systems for precision agriculture. The performance evaluation
    of the proposed approach involved comparing the results of the weed detection
    and classification using the deep learning model with and without the use of internet
    of things (IoT)-based edge computing. The evaluation metrics used in the study
    included precision, recall, and F1-score. The experimental setup involved training
    the deep learning model on the CropDeep dataset and the UC Merced Land Use dataset.
    The dataset was split into training, validation, and testing sets in a 60:20:20
    ratio. The model was trained using stochastic gradient descent with a learning
    rate of 0.001 and a batch size of 32. The model was trained for 50 epochs, and
    the weights were saved at the end of each epoch. The proposed approach was evaluated
    on a test set of 100 images of crops, and the results were compared with the results
    obtained without the use of IoT-based edge computing. The evaluation showed that
    the proposed approach improved the performance of the deep learning model, with
    an overall F1-score of 0.95, compared to an F1-score of 0.89 without the use of
    IoT-based edge computing. This indicates that the proposed approach can effectively
    detect and classify weeds in crops using IoT-based edge computing. The study also
    includes a table that compares the three methods (CNN, YOLOv3, and faster R-CNN)
    based on accuracy, precision, recall, and F1-score. The experimental results show
    that all three methods achieved high levels of accuracy, with faster R-CNN performing
    the best at 96.3%. YOLOv3 had the highest precision at 96.2%, while faster R-CNN
    had the highest recall at 95.8%. The faster R-CNN method had the highest F1-score
    at 96.3%, indicating the best balance between precision and recall. © 2023 Walter
    de Gruyter GmbH, Berlin/Boston — or —   Buy Chapter PDF $42.00 From the book Augmented
    and Virtual Reality in Social Learning Chapters in this book (20) Frontmatter
    Preface Contents List of contributors 1 VR in social learning: applications and
    challenges 2 Integration of blockchain techniques in augmented and virtual reality
    3 A comparative study of Li-Fi over Wi-Fi and the application of Li-Fi in the
    field of augmented reality and virtual reality 4 Augmented reality in cross-domain
    applications 5 Advanced ICT and intelligent systems in sophisticated Healthcare
    5.0 practice in modern social and healthcare transformation: an overview 6 A study
    on enterprise collaboration in metaverse 7 Exploring the synergy between augmented
    and virtual reality in healthcare and social learning 8 Exploratory study of the
    parental perception of social learning among school-aged children based on augmented
    and virtual reality 9 An innovative application using augmented reality to enhance
    the teaching-learning process in school education 10 How do augmented and virtual
    reality influences visitor experiences: a case of heritage tourism sites in Rajasthan
    11 Scope of virtual reality and augmented reality in tourism and its innovative
    applications 12 6G and IoT-supported augmented and virtual reality–enabled simulation
    environment 13 Virtual reality in tourism: assessing the authenticity, advantages,
    and disadvantages of VR tourism 14 Real-time weed detection and classification
    using deep learning models and IoT-based edge computing for social learning applications
    Editors’ biography Index Subjects Architecture and Design Arts Asian and Pacific
    Studies Business and Economics Chemistry Classical and Ancient Near Eastern Studies
    Computer Sciences Cultural Studies Engineering General Interest Geosciences History
    Industrial Chemistry Islamic and Middle Eastern Studies Jewish Studies Law Library
    and Information Science, Book Studies Life Sciences Linguistics and Semiotics
    Literary Studies Materials Sciences Mathematics Medicine Music Pharmacy Philosophy
    Physics Social Sciences Sports and Recreation Theology and Religion Services For
    Journal Authors For Book Authors For Librarians Rights & Permissions Publications
    Publication types Open Access About Contact Career About De Gruyter Partnerships
    Press FAQs Social Facebook Instagram LinkedIn Twitter YouTube Winner of the OpenAthens
    Best Publisher UX Award 2022  Help/FAQ Privacy policy Cookie Policy Accessibility
    Terms & Conditions Legal Notice © Walter de Gruyter GmbH 2024 Consent to website
    analysis We use cookies and other technologies. Some of them are necessary for
    the website to function and are always set. Cookies for website analysis are not
    required and are set only with your consent. Some services for analysis process
    personal data in the USA. With your consent to use these services, you also consent
    to the processing of your data in the USA. Your consent is voluntary and can be
    revoked at any time. For more information, please see our Cookie Policy. Accept
    optional analytics cookies Reject non-essential cookies"'
  inline_citation: '>'
  journal: 'Augmented and Virtual Reality in Social Learning: Technological Impacts
    and Challenges'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-time weed detection and classification using deep learning models and
    IoT-based edge computing for social learning applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Cao Z.
  - Kooistra L.
  - Wang W.
  - Guo L.
  - Valente J.
  citation_count: '1'
  description: Real-time object detection based on UAV remote sensing is widely required
    in different scenarios. In the past 20 years, with the development of unmanned
    aerial vehicles (UAV), remote sensing technology, deep learning technology, and
    edge computing technology, research on UAV real-time object detection in different
    fields has become increasingly important. However, since real-time UAV object
    detection is a comprehensive task involving hardware, algorithms, and other components,
    the complete implementation of real-time object detection is often overlooked.
    Although there is a large amount of literature on real-time object detection based
    on UAV remote sensing, little attention has been given to its workflow. This paper
    aims to systematically review previous studies about UAV real-time object detection
    from application scenarios, hardware selection, real-time detection paradigms,
    detection algorithms and their optimization technologies, and evaluation metrics.
    Through visual and narrative analyses, the conclusions cover all proposed research
    questions. Real-time object detection is more in demand in scenarios such as emergency
    rescue and precision agriculture. Multi-rotor UAVs and RGB images are of more
    interest in applications, and real-time detection mainly uses edge computing with
    documented processing strategies. GPU-based edge computing platforms are widely
    used, and deep learning algorithms is preferred for real-time detection. Meanwhile,
    optimization algorithms need to be focused on resource-limited computing platform
    deployment, such as lightweight convolutional layers, etc. In addition to accuracy,
    speed, latency, and energy are equally important evaluation metrics. Finally,
    this paper thoroughly discusses the challenges of sensor-, edge computing-, and
    algorithm-related lightweight technologies in real-time object detection. It also
    discusses the prospective impact of future developments in autonomous UAVs and
    communications on UAV real-time target detection.
  doi: 10.3390/drones7100620
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                Deny Allow selection
    Allow all   Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Drones All Article Types Advanced   Journals
    Drones Volume 7 Issue 10 10.3390/drones7100620 Submit to this Journal Review for
    this Journal Propose a Special Issue Article Menu Academic Editor Emmanouel T.
    Michailidis Subscribe SciFeed Recommended Articles Related Info Link More by Authors
    Links Article Views 3255 Citations 1 Table of Contents Abstract Introduction Methodology
    Analysis of Selected Publications Results Discussion Conclusions Author Contributions
    Funding Data Availability Statement Conflicts of Interest References share Share
    announcement Help format_quote Cite question_answer Discuss in SciProfiles thumb_up
    Endorse textsms Comment first_page settings Order Article Reprints Open AccessReview
    Real-Time Object Detection Based on UAV Remote Sensing: A Systematic Literature
    Review by Zhen Cao 1,2, Lammert Kooistra 3, Wensheng Wang 4,*, Leifeng Guo 2,*
    and João Valente 1 1 Information Technology Group, Wageningen University & Research,
    6700EW Wageningen, The Netherlands 2 Agricultural Information Institute, Chinese
    Academy of Agriculture Science, Beijing 100081, China 3 Laboratory of Geo-Information
    Science and Remote Sensing, Wageningen University & Research, 6700AA Wageningen,
    The Netherlands 4 Information Center, Ministry of Agriculture and Rural Affairs,
    Beijing 100125, China * Authors to whom correspondence should be addressed. Drones
    2023, 7(10), 620; https://doi.org/10.3390/drones7100620 Submission received: 4
    September 2023 / Revised: 25 September 2023 / Accepted: 29 September 2023 / Published:
    3 October 2023 Download keyboard_arrow_down     Browse Figures Review Reports
    Versions Notes Abstract Real-time object detection based on UAV remote sensing
    is widely required in different scenarios. In the past 20 years, with the development
    of unmanned aerial vehicles (UAV), remote sensing technology, deep learning technology,
    and edge computing technology, research on UAV real-time object detection in different
    fields has become increasingly important. However, since real-time UAV object
    detection is a comprehensive task involving hardware, algorithms, and other components,
    the complete implementation of real-time object detection is often overlooked.
    Although there is a large amount of literature on real-time object detection based
    on UAV remote sensing, little attention has been given to its workflow. This paper
    aims to systematically review previous studies about UAV real-time object detection
    from application scenarios, hardware selection, real-time detection paradigms,
    detection algorithms and their optimization technologies, and evaluation metrics.
    Through visual and narrative analyses, the conclusions cover all proposed research
    questions. Real-time object detection is more in demand in scenarios such as emergency
    rescue and precision agriculture. Multi-rotor UAVs and RGB images are of more
    interest in applications, and real-time detection mainly uses edge computing with
    documented processing strategies. GPU-based edge computing platforms are widely
    used, and deep learning algorithms is preferred for real-time detection. Meanwhile,
    optimization algorithms need to be focused on resource-limited computing platform
    deployment, such as lightweight convolutional layers, etc. In addition to accuracy,
    speed, latency, and energy are equally important evaluation metrics. Finally,
    this paper thoroughly discusses the challenges of sensor-, edge computing-, and
    algorithm-related lightweight technologies in real-time object detection. It also
    discusses the prospective impact of future developments in autonomous UAVs and
    communications on UAV real-time target detection. Keywords: UAV; remote sensing;
    real time; object detection; edge computing; deep learning 1. Introduction Unmanned
    aerial vehicles (UAVs) have been widely used in different scenarios, such as agriculture
    [1], urban traffic [2], and search and rescue [3]. A recent review by Nex et al.
    [4] has revealed that the majority of published papers related to UAVs are focused
    on remote sensing studies [5]. This is largely due to the ease of use, flexibility,
    and relatively moderate costs of UAVs, which have made them a popular instrument
    in the remote sensing domain [4]. The emergence of more advanced algorithms will
    enable the realization of autonomous UAVs [4]. Real-time object detection based
    on UAV remote sensing is an important perception task for achieving fully autonomous
    UAVs. In this paper, the so-called ‘object’ refers to the instances of visual
    objects of a particular class in remote sensing imagery [6]. Any remote sensing
    application consists of two distinct processes: data acquisition and data analysis
    [7]. Although rapidly acquiring UAV remote sensing imagery is an essential first
    step, extracting valuable information from the raw imagery is also critical to
    performing real-time remote sensing. It enables the interpretation and description
    of the targets being measured in a particular scene. Traditional data processing
    has matured with well-established workflow solutions [4]. However, users’ demand
    for autonomous UAVs requires a shift in data processing from offline to real-time.
    The ultimate goal of real-time object detection is to enable real-time sensing
    and reasoning via the automatic, rapid, and precise processing of remotely sensed
    UAV data. Real-time object detection also helps release storage and physical and
    virtual memory in resource-limited hardware. Accordingly, to achieve such a goal,
    real-time object detection based on UAV remote sensing is significant for rapidly
    extracting useful information from remote sensing images [8]. UAV technology is
    at the intersection of many domains, and the research in its neighbouring fields
    influences the processing and utilization of remote sensing data [4]. When leveraging
    the outputs of remote sensing data, all of these tasks strongly rely on the detection
    of one or multiple domain-related objects [9]. Object detection tasks have been
    widely investigated since the beginning of computer vision [9,10], as object detection
    serves as a basis for many other computer vision tasks [6]. As a result, object
    detection is one of the most critical underlying tasks for processing UAV remote
    sensing imagery [9]. Object detection has been defined as the procedure of determining
    the instance of the class to which an object belongs and estimating the object’s
    location by outputting a bounding box or the silhouette around the object [11].
    In UAV remote sensing research, the definition and application of object detection
    could be broader. For example, in a soybean leaf disease recognition study [12],
    the output form of the task was not a bounding box but somewhat different colour
    masks to indicate the healthy and diseased leaves. In computer vision research,
    these masks often have more precise terminology, called segmentation or semantic
    segmentation. Similar situations also occur in tasks such as classification [13,14]
    and monitoring [15,16]. The development of autonomous UAVs for analyzing data
    in real time is an emerging trend in UAV data processing [4]. Compared with manual
    post-processing, users’ needs are evolving, resulting in many UAV remote sensing
    applications having a high demand for real-time image detection. For example,
    in search and rescue scenarios, integrating real-time object detection into a
    UAV-based emergency warning system can help rescue workers better tackle the situation
    [17]. In precision agriculture, generating weed maps in real time onboard is essential
    for weed control tasks and can reduce the time gap between image collection and
    herbicide treatment [18]. Several previous reviews also emphasized the importance
    of real-time object detection. For example, emergency responses can be supported
    by real-time object detection [7], and people also require UAV real-time object
    detection for safety reconnaissance and surveillance [19]. However, most of these
    articles considered and addressed only the algorithm factor of real-time object
    detection while ignoring how the algorithms can be deployed on UAVs [20]. Other
    UAV real-time object detection components that have not been fully considered
    when developing a complete workflow in previous studies, including software and
    hardware technologies based on the embedded system, need further investigation
    [10]. One review [21] investigated hardware, algorithms, and paradigms for real-time
    object detection but was limited to precision agriculture. Another review [22]
    provided a well-summarized and categorized approach to real-time UAV applications,
    as well as relevant datasets. However, there was no further discussion on how
    to implement real-time object detection based on UAVs. From a technological perspective,
    better-performing miniaturized hardware and the surge of deep learning algorithms
    both have a positive impact on UAV remote sensing data processing [4]. It is worth
    reviewing and investigating how these new technologies are applied in UAV real-time
    object detection tasks. As a result, most of the aforementioned studies focused
    on real-time detection algorithm investigations. They should have paid more attention
    to algorithm deployment, which could be critical to successfully implementing
    UAV object detection in practice. Although reviews also discussed solutions for
    UAV real-time object detection algorithms deployed on embedded hardware, they
    were limited to a specific domain. This study aims to fill the gaps in the previous
    work that paid limited attention to onboard UAV real-time object detection implementation.
    Furthermore, the entire UAV real-time object detection process will be summarized
    as a hardware and software framework that can be used for subsequent onboard real-time
    processing. The hardware and software framework can serve as a reference for researchers
    working in the UAV real-time data processing field and drive them towards the
    development of more efficient autonomous UAV systems. Therefore, the first research
    objective of this paper is to summarize the application scenarios and the targets
    of real-time object detection tasks based on UAV remote sensing in order to demonstrate
    the necessity of real-time detection. The second research objective is to investigate
    the current implementation of real-time object detection based on UAV remote sensing
    to observe the impact of sensors, computing platforms, algorithms, and computing
    paradigms on real-time object detection tasks in terms of accuracy, speed, and
    other critical evaluation metrics. The rest of the paper is organized as follows.
    Section 2 presents and describes the steps and methodology of our systematic literature
    review. Then, a general analysis of this systematic review study is provided in
    Section 3. In Section 4, the quantitative results are visualized and discussed
    according to the proposed research questions, and Section 5 discusses the current
    challenges and future opportunities of UAV real-time object detection. Finally,
    Section 6 concludes the paper. 2. Methodology This study adopted the guidelines
    proposed by Kitchenham [23] to undertake a systematic literature review and finally
    reported and visualized the results. Based on the original guidelines [24], a
    review protocol has been developed to specify the reviewing methods used to reduce
    bias at the beginning of the study. The steps in this systematic literature review
    protocol are documented below. 2.1. Research Questions In order to address the
    problems of real-time object detection based on UAV remote sensing, the complete
    workflow of real-time object detection tasks in UAV remote sensing needs to be
    clearly demonstrated. Figure 1 summarizes the process of real-time object detection
    based on UAVs seen in previous studies [25,26,27] by drawing a concept map to
    illustrate each step. Figure 1. The concept map of real-time object detection
    based on UAV remote sensing. The closed loop illustrates the complete autonomous
    workflow, where each node represents one step of real-time object detection. The
    complete workflow shown in Figure 1 includes five steps. The starting point comes
    from the real-time requirements for specific tasks in different application scenarios.
    Therefore, determining the targets and the task scenarios is critical for selecting
    UAVs, sensors, and algorithms. Then, during the data acquisition phase, the chosen
    UAVs are equipped with different sensors to complete data collection according
    to the task’s needs. The remotely sensed data need to be processed in real time,
    so computing platform selection is essential for onboard processing. The chosen
    computing platforms need to establish the computing paradigm for implementing
    real-time object detection. Meanwhile, the core detection algorithms also need
    to be deployed on the platform in the object detection phase. The selection of
    communication methods determines how the data and results are transmitted in the
    workflow. Merely obtaining detection results holds limited significance in practical
    applications, as the essence of real-time detection lies in achieving rapid responsiveness.
    Hence, the outcomes of real-time object detection serve as crucial outputs for
    activities such as decision making, system alerts, or machinery operations. These
    outputs engender value and confer purpose upon this undertaking. The closed loop
    in Figure 1 can be used to describe the completed autonomous workflow of UAV real-time
    object detection. According to the research objectives, this review study will
    focus on advanced real-time object detection based on remote sensing technology,
    including application scenarios, hardware selection, algorithm design, and implementation
    methods. The research questions of this paper are correspondingly proposed as
    follows. RQ1. What are the application scenarios and tasks of real-time object
    detection based on UAV remote sensing? RQ2. What types of UAV platforms and sensors
    are used for different real-time object detection applications? RQ3. Which types
    of paradigms were used in real-time object detection based on UAV remote sensing?
    RQ4. What commonly used computing platforms can support the real-time detection
    of UAV remote sensing based on edge computing? RQ5. What algorithms were used
    for real-time detection based on UAV remote sensing? RQ6. Which improved methods
    were used in real-time detection algorithms for UAV remote sensing? RQ7. How can
    we evaluate real-time detection based on UAV remote sensing regarding accuracy,
    speed, and energy consumption? The formulation of these seven proposed RQs is
    based on the first four phases outlined in the concept map. It is essential to
    acknowledge that rapid response constitutes a pivotal stage within the entirety
    of the workflow. This stage serves as a subsequent action in handling the outputs
    of real-time detection. Consequently, the exploration of the final phase will
    be extended to delve into future prospects for attaining autonomous UAV capabilities,
    as elaborated on in Section 5. 2.2. Search Process The literature search was conducted
    on 7 February 2023, and the relevant journal and conference articles were retrieved
    from two databases (Web of Science and Scopus). This review topic was divided
    into three aspects: platform, task, and processing method. In order to find more
    literature that encompassed the ‘detection’ task, the terms on the ‘Task’ aspect
    were extended to use some other tasks that included ‘detection’, for example,
    identification, monitoring, segmentation, and classification. Based on these terms,
    a list of synonyms, abbreviations, and alternative spellings was drawn up, as
    shown in Table 1. Table 1. The list of search terms based on three aspects. The
    search strings were constructed by the above terms using the Boolean operators
    ‘AND’ and ‘OR’, and wildcards were used to match the search better. The following
    search strings in Table 2 were executed separately in the search engine of two
    databases. Table 2. The search strings for two databases. 2.3. Inclusion and Exclusion
    Criteria The search results were imported into the literature management software
    Endnote. Following automated de-duplication, the remaining documents underwent
    manual filtering to select the definitive literature for review. Therefore, a
    set of inclusion and exclusion criteria based on the research questions was used
    to perform literature screening, mainly by reading titles and abstracts. The full
    text was read when the title and abstract could not be clearly determined. Peer-reviewed
    articles on the following topics that had full texts written in English were included:
    Articles that discussed real-time object detection tasks or algorithms that are
    applied to UAV remote sensing; Articles that specifically mentioned onboard real-time
    processing and used optic sensors. The exclusion criteria are shown as follows
    in Table 3. Table 3. The table of exclusion criteria during literature selection.
    2.4. Data Extraction The corresponding evidence was extracted from the retrieved
    papers to answer the proposed questions properly. For this purpose, we designed
    and created a data extraction table, including general and detailed information.
    The general information contained the publication year and the source of the literature.
    The detailed information included the application categories (scenario, task,
    and target), hardware components (UAV, sensor, computing platform, and communication),
    real-time detection method (implementation paradigm, algorithm, and improvement
    method), and assessment and evaluation metrics (accuracy, speed, latency, and
    energy). The data were extracted by carefully reading and reviewing the selected
    papers. 2.5. Data Synthesis Data synthesis involves collecting and summarizing
    the results of the included primary studies [24]. In this review study, the results
    are discussed in detail through descriptive synthesis, and a quantitative synthesis
    is presented through data visualization to answer the relevant research questions.
    3. Analysis of Selected Publications 3.1. Study Selection The flow-chart diagram
    in Figure 2 shows the process of publication selection. A total of 477 records
    were obtained from searching, of which 222 were from WOS and 255 were from Scopus.
    After removing duplicates, 404 documents remained, but 18 of them did not have
    available full text. The remaining 386 documents were screened by reviewing titles,
    abstracts, and full texts, and 310 documents were excluded based on the exclusion
    criteria. In addition, one citation from the assessed papers that could potentially
    contribute to the understanding of the research question was included in the final
    database after the inclusion and exclusion criteria were evaluated. Finally, 77
    pieces of literature were included in our review study. Figure 2. The process
    of publication selection. 3.2. Overview of Reviewed Publications This subsection
    analyzes the general information contained in the 77 papers and provides an overview
    of the papers reviewed. Figure 3 illustrates that the need for real-time object
    detection was raised by researchers as early as 2002. In that study [28], the
    authors tried to use a UAV to track a target and maintain its position in the
    middle of the image. They ensured real-time performance through the combination
    of a successive-step and multi-block search method. However, it was not until
    2019 that the number of relevant studies began to increase dramatically, reaching
    27 in 2021. Although the number of studies decreased in 2022, the number remained
    above 20, and the overall trend has increased during the past years. We insist
    that real-time object detection thus remains a significant interest in the field
    of UAV remote sensing. Figure 3. The year of publication and the distribution
    of literature type. In terms of literature sources, the majority of the literature
    comes from journals rather than conference proceedings. Figure 4 illustrates the
    names and the number of journals that have at least two papers, and the remaining
    journals with only one document are summarized in the ‘Other’ category. All conferences
    included only one selected paper. Therefore, they are presented as a whole in
    Figure 4, called ‘Conferences proceedings’. Figure 4. Distribution of selected
    publications in specific journals (Remote Sensing, IEEE Access, Journal of Real-Time
    Image Processing, Sensors, Multimedia Tools and Applications, and Electronics)
    or conference proceedings. Only journals with two publications or more are mentioned.
    Additional publications are presented in the ’Other’ category. The result indicates
    that publications on UAV real-time object detection were published in 40 different
    journals and 12 different conference proceedings. Of these, 46 journals or conference
    proceedings included only one piece of literature, with the research being relatively
    scattered across various fields, for example, in electronics [29,30], multimedia
    applications [31,32,33], and transportation engineering [34,35,36]. The most popular
    journal is Remote Sensing, which had 11 papers, followed by IEEE Access with 7
    papers and Sensors and Journal of Real-time Image Processing with 4. From this,
    it can be derived that research on UAV real-time object detection has been focused
    on remote sensing and real-time image processing. 4. Results In this section,
    we analyze the 77 selected publications to address the previously formulated research
    questions using both quantitative analysis and descriptive review. 4.1. Application
    Scenarios and Tasks of Real-Time Object Detection As UAV usability expands across
    diverse applications, the research focus has shifted towards real-time object
    detection using UAV remote sensing. This literature review encompasses the scope
    of real-time object detection scenarios, targets, and task categorizations, as
    depicted in Figure 5. Figure 5. This Sankey diagram of the selected literature
    illustrates the connectivity among real-time detection scenarios, detection targets,
    and tasks. Proceeding from left to right, the diagram categorizes and summarizes
    application scenarios present in the selected literature, the diverse detection
    targets within varying application contexts, and the tasks executed for each specific
    target. The width of the flow between nodes signifies the amount of literature
    pertaining to each node. We have summarized the seven major scenarios of UAV real-time
    detection. Figure 5 visually illustrates the specifics of detection targets and
    tasks. Furthermore, papers focused on algorithmic aspects have been categorized
    under the ‘Other’ category [33,37,38,39,40,41,42,43,44]. Emergency scenarios appear
    20 times within the selection, directly correlated with the imperative for real-time
    responsiveness during critical situations. The traffic diagram depicted in Figure
    5 underscores that in emergency scenarios, the primary detected targets encompass
    humans [45,46,47,48,49,50,51,52], natural disasters [53,54,55,56,57], and abnormal
    crowd events [31,58], all of which necessitate swift responses to avoid casualties.
    An additional subset of detection targets comprises vehicles [28,59] and ships
    [60], both of which are susceptible to dangerous conditions. In this regard, UAV
    real-time object detection emerges as a viable solution for addressing these challenges.
    In particular, providing emergency services during a crisis event is vital for
    rescue missions [45]. The second prominent application scenario revolves around
    agriculture, involving a review of seventeen relevant papers. Precision agriculture
    emphasizes the fast and accurate detection of crop stress, including crop diseases
    [61,62,63], pests [64], and surrounding weeds [18,65,66,67], as a means to reduce
    pesticide dependency and promote sustainable farming practices [65]. Real-time
    information empowers swift responses to disease, pest, and weed propagation, thereby
    minimizing crop stress impact. The scope of ‘real-time’ technology also applies
    to vegetation index [68,69] and crop monitoring [70,71], facilitating monitoring
    systems and informed decision-making. Additionally, this scenario encompasses
    tree detection [72,73,74,75,76], which is often deployed for the real-time identification
    of tree canopies. This capability finds utility in precision spraying [75] and
    fruit yield estimation through counting [73]. The exploration of traffic scenarios
    has also encompassed numerous real-time detection applications, with vehicles
    serving as the primary detection target. A pivotal undertaking involves traffic
    flow analysis, which necessitates real-time detection to derive vehicle speed
    and traffic density [34,77,78]. Furthermore, real-time vehicle detection finds
    application in discerning the diverse vehicle types on roads, encompassing cars,
    trucks, and excavators [36,67,79,80]. Additionally, real-time vehicle detection
    has proven invaluable for tracking objectives [81,82]. In the inspection scenario,
    real-time detection assumes a pivotal role in assessing power facility components
    [29,83,84,85,86,87,88] and detecting surface cracks in bridges and buildings [35,89,90].
    These applications are intricately linked to power transmission, building health,
    and personnel safety. Within less extensive application scenarios, flight planning
    emerges, which is primarily employed to ensure UAV flight safety by surveying
    surrounding targets, such as drones [30,91,92]. Additionally, specific targets
    are addressed for UAV flight testing [93,94,95]. In terms of environmental protection
    scenarios, [96,97] underscore the urgency of real-time detection. Particularly,
    the swift movement of marine plastics mandates instantaneous detection to enable
    prompt interventions. Regarding task distribution, the predominant focus rests
    on detection tasks, comprising 55 studies. While certain tasks diverge from object
    detection, such as monitoring [56] and tracking [81], it is noteworthy that object
    detection stands as the foundational stride within visual recognition endeavours
    [11]. Hence, the remaining studies also necessitate real-time object detection.
    4.2. UAV Platforms and Sensors for Different Real-Time Detection Applications
    UAVs can be categorized based on various criteria, including purpose, size, load,
    and power [21]. The most distinguishing factor often lies in their aerodynamic
    characteristics, leading to classifications into fixed-wing, multi-rotor, and
    hybrid UAVs [98]. By excluding studies that did not specify UAV types, we conducted
    a tally of UAV classifications employed across distinct real-time object detection
    scenarios. The results are presented in Figure 6a. Figure 6. (a) Types of UAVs
    and (b) types of sensors used in different real-time object detection scenarios
    derived from the selected set of 77 publications. Fixed-wing UAVs possess immobile
    wings that rely on forward airspeed for lift generation [98]. Nonetheless, they
    lack backward movement, hovering, or rotation capabilities [99] and necessitate
    demanding take-off and landing conditions [21]. Our review distinctly highlights
    that a mere two studies harnessed fixed-wing UAVs for real-time object detection
    applications: emergencies [28] and agriculture [76]. In contrast, the domain of
    real-time detection applications is notably governed by multi-rotor UAVs [85,93,94],
    which is primarily attributed to their economical manufacturing advantages [99].
    An overwhelming majority of investigations gravitate toward this classification.
    Multi-rotor UAVs ingeniously employ multiple rotors for lift generation [98],
    facilitating attributes such as vertical landing, agile maneuvers, and swift takeoffs.
    Furthermore, due to the inherent hovering capability of multi-rotor UAVs, they
    are especially well-suited for aerial photography [4]. Fixed-wing UAVs require
    sensors equipped with fast shutters to counteract motion blur resulting from the
    absence of forward-motion compensation. The third UAV category encompasses hybrid-wing
    UAVs, merging fixed-wing and multi-rotor technologies. These hybrids utilize multi-rotors
    for vertical take-off and landing, while the fixed-wing component serves extended
    linear coverage. Our review reveals infrequent utilization of hybrid-wing UAVs;
    they are observed solely in one real-time traffic scenario for asset detection
    [80]. The sensors of remote sensing employed in real-time object detection encompass
    RGB [53,64,71,73], multi-spectral [74], hyperspectral [96], thermal infrared [48,84],
    and the fusion of multiple sensors [50,60]. As evidenced in Figure 6b, the RGB
    sensor stands as the predominant sensor type for real-time object detection tasks
    within UAV-based remote sensing. Based on our review, it seems that all studies
    have defaulted the sensor required for real-time object detection to RGB due to
    its advantages of being of a high resolution, light weight, and low cost and being
    easy-to-use. Multi- and hyper-spectral cameras can capture spectral information
    from objects of interest [100,101], each with unique characteristics. Multi-spectral
    sensors offer centimeter-level remote sensing data with several spectral bands,
    typically spanning blue, green, red, red-edge, and near-infrared. In contrast,
    hyper-spectral sensors provide a multitude of narrow bands, extending from ultraviolet
    to longwave [21]. The application of multi-spectral and hyper-spectral sensors
    in non-real-time object detection based on UAV remote sensing has been extensively
    explored in various domains. For instance, spectral sensors have found utility
    in precision agriculture [102,103], landslide monitoring [104], and power line
    inspection [105]. However, in scenarios where real-time object detection is imperative,
    our review has revealed a limited number of studies employing spectral sensors.
    Specifically, only two pieces of literature have been identified that delved into
    the utilization of spectral sensors for real-time object detection. These studies
    encompass the detection of tree canopy detection using multi-spectral cameras
    [74] and the detection of macro plastic in the marine environment using hyper-spectral
    cameras [96]. Of the articles under our scrutiny, two distinct studies leveraged
    the potential of thermal infrared cameras to explore their temperature sensitivity.
    In one instance, the focal point was the detection of photovoltaic panels [84].
    In another significant context, the focus shifted towards identifying individuals
    with elevated body temperatures, which can be potentially indicative of a COVID-19
    infection [48]. Furthermore, two additional research studies have reported applications
    involving the fusion of multiple sensors. In [50], thermal sensors were judiciously
    deployed for identifying individuals in need of rescue, while an RGB sensor was
    simultaneously leveraged for precise localization. In another study [60], an RGB
    camera assumed the role of vessel morphology detection, while thermal infrared
    technology was adeptly employed to pinpoint heat emissions from engines. 4.3.
    Two Paradigms for Real-Time Detection Real-time object detection means that the
    UAVs equipped with sensors and processors have the capacity to quickly process
    the collected data and reliably deliver the needed information. Thus, based on
    our review study, three kinds of paradigms are utilized for real-time object detection:
    embedded systems, cloud computing, and edge computing. The majority of real-time
    object detection studies (n = 72) selected the edge computing paradigm, and 4
    studies reported using the embedded system. At the same time, there was only one
    study that selected the cloud computing solution. Cloud computing is a computing
    paradigm that provides on-demand services to end-users through a pool of computing
    resources that includes storage, computing, data, applications, and so on [106].
    The cloud computing paradigm is shown in Figure 7a. From our review, the advantages
    of the cloud computing paradigm are reflected in [73]. The first advantage is
    that the ground station stores the images collected via UAV and then streams them
    to the cloud. The data are processed on the cloud, which has powerful computing
    and storage resources for massive UAV remote sensing data. The second advantage
    is that the end-users from anywhere at any moment can access the cloud services.
    In addition, the fault-tolerance mechanism of cloud computing ensures the high
    reliability of its processing and analysis services, and the ability of the cloud
    center to dynamically allocate or release resources according to users’ demand
    is also a strength. Figure 7. The paradigm of (a) cloud computing, (b) edge computing
    with remote processing, and (c) edge computing with onboard processing. However,
    cloud computing has some drawbacks when dealing with real-time object detection
    tasks on UAVs. These drawbacks mainly stem from the growing volume of data at
    the edge, which is limited by network bandwidth and makes the data difficult to
    upload to the cloud for processing and analysis [107]. The emergence of edge computing
    can effectively solve the above problem. There are many definitions of edge computing
    [106,107,108]. However, the core of the description is that edge computing is
    the provision of cloud services and IT service environments for users at the edge
    of the network, with the goal of providing computing, storage, and network bandwidth
    services close to the end-devices or end-users, thereby reducing latency, ensuring
    efficient network operation and service delivery, and improving the user experience.
    For real-time UAV object detection, the edge end is usually the UAV that generates
    an enormous volume of data. Based on the above concept of edge computing, we can
    divide edge computing into two forms: One form where the edge end is unable to
    perform large computations; it just processes partial data and then offloades
    to the edge server (ground station) for processing. Figure 7b shows the paradigm
    of edge computing in this form. In this case, the so-called ground station is
    a generic name and usually is a high-performance computing platform, such as a
    laptop [59], mobile phone [48,51] or single-board [57]. Another form where the
    edge end is also the edge server, which has the capability of processing data
    while collecting data. This paradigm can be seen in Figure 7c. There are many
    of these forms of edge computing in our review [31,34,58,84,94], which integrated
    sensors and embedded computing platforms onto the UAV and treated them as a whole,
    which is the edge end. During the flight of the UAV, the images are captured and
    processed simultaneously to obtain the detection results. It is worth mentioning
    that some real-time object detection based on UAV remote sensing is one part of
    a complete system [31], so the results normally will upload to the cloud center,
    but the edge computing for real-time detection ends at the computing platform
    or ground station providing needed information. The subsequent tasks will not
    be discussed here. Edge computing cannot be developed without embedded systems,
    and as we noted, edge end computing platforms are built through embedded systems.
    However, some early studies of real-time target detection [58,82] used embedded
    devices whose performance could not meet the standards required for edge computing,
    so they were put into a separate category. 4.4. Computing Platforms Used for Edge
    Computing Based on the analysis in the previous section, real-time object detection
    primarily utilizes edge computing to implement, so the computing platforms used
    for real-time edge computing are important. They can provide a reference for selecting
    hardware for subsequent studies. In the meantime, GPU-based computing platforms
    can provide more computing power for deep learning algorithms, which are popular
    for image processing. Table 4 lists three typical GPU-based computing platforms
    that are frequently used in edge computing applications in the selected literature.
    Table 4. List of commonly used GPU-based computing platform examples. The number
    of symbols ‘+’ in the table represents the level of performance, with more ‘+’
    indicating stronger performance. The critical parameters of (central processing
    unit (CPU), graphics processing unit (GPU), memory, power, and AI performance
    are compared. The price of these computing platforms is also listed for comparison.
    Some typical studies’ applications in the selected literature are also listed.
    The Nvidia Jetson TX2 is a typical and the most used computing platform. The reason
    for this may come from the fact that it has a relatively balanced processing power,
    power consumption, and price. The widespread use of GPU-based computing platforms
    is also a side note to the development of artificial intelligence, especially
    deep learning, which has become almost preferred in the field of image recognition,
    making GPU platforms more popular due to their parallel computing performance.
    In this review study, field programmable gate arrays (FPGA) are not used much,
    with only one mention in the literature [69], although it is also ideal for these
    edge computing applications due to its reprogramming ability and low-power characteristics.
    Some other GPU-based computing platforms have also been reported, such as the
    tensor processing unit (TPU), which is optimized for tensor computing [74], and
    the Intel Neural Compute Stick, which is based on a visual computing unit (VPU)
    [31,75]. Some CPU-based computing platforms have also been reviewed, such as the
    Raspberry Pi series. Although Raspberry Pi is normally used as a comparison item
    in benchmark studies, it has also been used as the core computing platform in
    some studies. For example, an insulator detection study used a lightweight algorithm
    on a Raspberry Pi 4B to achieve real-time detection [87]. 4.5. Real-Time Object
    Detection Algorithms Based on our review of the selected literature, three categories
    of algorithms have been employed for real-time detection in unmanned aerial vehicle
    (UAV) remote sensing: traditional methods, machine learning, and deep learning.
    Previous surveys [8,12,21] have indicated that deep learning stands as a pivotal
    approach for achieving real-time detection in UAV remote sensing owing to its
    widespread application in image detection. The findings of this study further
    corroborate this assertion. With the exception of one reference that does not
    explicitly outline a specific algorithm, among the remaining literature, 60 works
    utilized deep learning algorithms, 5 employed machine learning methods, and 11
    adopted conventional approaches. Figure 8 illustrates the distribution of specific
    algorithms utilized within each category. Figure 8. Classification of different
    real-time detection algorithms. The tree map shows the specific algorithms in
    each category and the number of uses. The so-called “traditional methods” predominantly
    refer to approaches grounded in digital image processing techniques and analyze
    characteristics such as the morphology and colour of the target object. To elaborate,
    articles utilizing feature-matching methods [28,72,81,93,109] are encompassed
    within this category, including a geometric approach for matching morphological
    features [93]. Additionally, segmentation methods based on colour [57,73,86] have
    also been mentioned. Furthermore, studies targeting non-RGB sensors incorporate
    techniques such as signal processing, as seen in applications such as the water-filling
    method [84]. Some research focuses on computing vegetation indices [68,69], which
    can be calculated by using the required bands to obtain the detection results.
    Regarding machine learning, most research used the support vector machine (SVM)
    algorithm [37,60,79,110]. While deploying SVM alone usually does not achieve the
    requirement of real-time detection, in these studies, commonly modified or added
    methods were adopted to speed up the algorithm, such as the bag of features approach,
    whose origin stems from the bag of words model and which was used to simplify
    the model [79]. Moreover, research using multi-class classification has also been
    documented [96]. In recent years, deep learning has found extensive application
    in image detection tasks. However, it also imposes significant demands on computational
    and storage resources, rendering its deployment in real-time tasks challenging
    [21]. As a result, there is often a need to streamline deep learning models. In
    our investigation, we identified 4 articles [42,54,63,77] utilising custom-designed
    networks, while the remaining 56 references optimized pre-existing models for
    application in real-time detection tasks within UAV remote sensing. Deep learning-based
    object detection has been categorized into two-stage and one-stage algorithms
    [111]. Although two-stage detection was successful in the early stages, its speed
    has been an important challenge. A one-stage object detection algorithm takes
    the entire image and passes it through a fixed grid-based CNN rather than in patches.
    Among the literature optimizing pre-existing models, the majority of the studies
    tended to favour the selection of one-stage models. Notably, the YOLO (You Only
    Look Once) model, in its various versions, represented a substantial portion with
    a total of 35 articles. The versions of YOLO included, for example, YOLOV3-Tiny
    [94], YOLOv4 [43], YOLOV5 [97], etc. Additionally, another single-stage detection
    algorithm, SSD (Single Shot Detection) [40], was featured in 3 articles. Two studies
    were reported to employ two-stage detection algorithms, specifically RCNNs (regions
    with convolutional neural networks) [83]. Furthermore, several other deep learning
    algorithms with light-weight architectures have been used for real-time object
    detection, including MobileNetV2 [36,41,52,95], U-Net [66,67,74,76], ResNet18
    [38,65], AlexNet [18,44], FCN [58], and SegNet [71]. 4.6. Technologies Used for
    Improving UAV Real-Time Object Detection Algorithms In pursuit of enhanced performance,
    deep learning models are often designed to be deeper and more complex, which inevitably
    introduces computing latency. However, in real-time tasks, precision is not the
    only criterion. Therefore, the aforementioned architectures need further refinement
    to suit the resource-constrained environment of unmanned aerial vehicles (UAVs).
    Among the 60 articles employing deep learning models, we conducted an analysis
    and found that 42 articles have optimized the speed of UAV real-time detection.
    Among these, 36 articles proposed algorithmic optimisations. Figure 9 illustrates
    the frequency of the different optimisation methods mentioned across the 33 articles
    discussing algorithmic improvements. Figure 9. Number of uses of improving methods
    for real-time UAV detection algorithms. The remaining 6 articles did not choose
    algorithmic optimisations. Instead, they pursued enhancements to the overall speed
    of the real-time detection system through strategies such as refining output results
    in conjunction with GPU hardware architecture. For instance, they selectively
    output only the portions of the image containing detected objects, thereby reducing
    transmission overhead [61,80]. The essence of lightweight design lies in the substitution
    of compact convolution filters for their bulkier counterparts. Specifically, larger
    convolution filters are replaced by multiple smaller ones, which are subsequently
    concatenated to achieve a comparable outcome. In our investigation, this approach
    is commonly applied to the backbone network of the YOLO algorithm, yielding promising
    results such as model size reduction and improved inference speed. In [75], ShuffleNetV2
    replaced the backbone network of YOLOV3-Tiny. In [90], MobileNetV2 substituted
    for the DarkNet53 backbone of YOLOV3. Moreover, in [43,56,88], MobileNetV3 was
    adopted to replace the CSPDarkNet53 backbone in YOLOV4. There are parameter redundancies
    in deep learning networks, which not only increase the size of the model but also
    slow down the running speed. Thus, pruning the parameters of deep learning models
    to achieve higher processing speeds is also a way to lighten these models [21].
    For instance, studies have reported parameter pruning in the fully connected layers
    [83], as well as pruning applied to each layer of the model [64,82]. Further pruning
    involves reducing the number of channels in convolutional layers [38,55,111,112].
    The purpose of parameter quantisation is to reduce the volume of trained models
    during storage and transmission. Typically, the focus is not on designing smaller
    model architectures but rather on employing lower-bit fixed representations. This
    approach reduces model storage space and significantly decreases the required
    computational resources by diminishing model precision. In [74], model parameters
    were quantized into 8-bit integers, facilitating real-time execution while maintaining
    an acceptable level of accuracy loss. Leveraging TensoRT on GPU hardware also
    enables model quantisation for accelerated performance. This approach has been
    employed in References [35,40,94]. Furthermore, the downsampling of images [49,70]
    by reducing their resolution can also effectively reduce computational load and
    subsequently enhance inference speed. In our review, downsampling is often employed
    in conjunction with other optimization techniques for improved outcomes. For instance,
    in [58], downsampling synergizes with lightweight design for algorithmic refinement.
    Similarly, in [54,55,64], downsampling is combined with parameter pruning for
    optimisation. 4.7. UAV Real-Time Object Detection Evaluation Real-time object
    detection based on UAVs has four evaluation aspects. Accuracy is an important
    metric for evaluating detection algorithms. However, in real-time tasks, detection
    speed is also essential. In addition, the latency performance considers the communication
    delay, computation delay, and so on during the progress from image acquisition
    to output. Last but not least, energy consumption is important, especially for
    practical operations. 4.7.1. Accuracy According to our review, ten evaluation
    metrics were used in the literature. As Figure 10 shows, the accuracy was used
    as the highest number as an evaluation metric. Accuracy is defined as the ratio
    of the number of correctly predicted samples to the total number of predicted
    samples. Although there are 23 studies using accuracy as an evaluation criterion
    for model performance, it is often criticized for failing to reflect the proportion
    of true positives, and it is questionable whether the detection results are comprehensive.
    In addition, precision, recall, F-score, and mAP, which appear more than 10 times,
    can better present the model’s performance by considering true positives, true
    negatives, false positives, and false negatives. These are the most commonly used
    metrics for object detection; we also have some other metrics that can evaluate
    the model to some extent. Figure 10. The number of studies using different metrics
    for accuracy. The average accuracy represents the average recall rate of each
    class in multi-object detection. Compared with accuracy, this metric can better
    reflect the impact of class imbalance. AUC means the area under the curve of an
    ROC. However, since an ROC is not easy to measure, the average precision is equivalent
    to calculating the area under the precision/recall curve. Meanwhile, the IoU is
    a simple measurement standard for object detection, which represents the intersection
    ratio of the ground truth and the prediction, and the mIoU is the average of each
    class. 4.7.2. Speed As a study on real-time target detection, real time is of
    prime importance here, and the computation time of target detection can be considered
    as the most time-consuming item in the whole task. We counted the 63 pieces of
    literature that reported the detection speed while they used different units.
    For easy comparison, the units were standardized to frame rate, noted as FPS (frame
    per second), which is a more common metric in the literature. A higher frame rate
    indicates a faster speed and shorter time consumption. Some studies recorded the
    speed in more than one different experiment situation, and the shortest time consumption
    in the literature was used to represent that study’s result. The detection speed
    was divided into 9 categories, and the distribution is shown in Figure 11. Figure
    11. Detection speed interval distribution. The detection speed was divided into
    9 categories, which are less than 1 FPS, 10 FPS, 20 FPS, 30 FPS, 40 FPS, 50 FPS,
    60 FPS, 70 FPS, and more than 100 FPS. The figures outside the bar indicate the
    number of studies in that speed interval. The blue, red, and green bars represent
    the literature that used traditional methods, machine learning, and deep learning,
    respectively. Although such a comparison does not account for factors such as
    input image size, hardware capabilities, algorithm complexity, network conditions,
    or other potential influences on task detection speed, it does highlight that
    the majority of applications concentrate detection speeds within the range of
    1 to 30 frames per second (FPS). As a result, detection speeds falling within
    this range can generally be considered as fulfilling the real-time processing
    demands for most scenarios. Indeed, faster detection must be better in real practice,
    but the faster speed sacrifices detection accuracy to some extent, for example,
    by using simple algorithms. Two studies that used traditional methods for real-time
    detection reported more than 60 FPS. They both selected RGB cameras to detect
    vegetation indices and obtain the 311 FPS result in the case of low image resolution
    [69]. Another study using FPGA hardware and software co-design optimized implementation
    to achieve 107 FPS [68], which has some specificity and cannot be a general approach
    for every application. 4.7.3. Latency Based on the review results, there are not
    many studies discussing latency in real-time object detection. In the cloud-computing
    paradigm, latency mainly refers to the transmission time from the end device to
    the cloud center. In our database, the edge computing paradigms accounted for
    95.8%. In these studies, based on edge computing, they mainly adopted onboard
    processing, so the latency between edge end and edge server has not been studied
    much. However, one study [88] indicated that offloading the computing to the edge
    server can reduce the computing delay. The author stated that the total delay
    consists of the delay in UAV data transmission to the edge server, the UAV computing
    delay, and the edge server computing delay. The study [80] also considered different
    communication methods. They compared the transfer time over Wi-Fi and 4G. 4.7.4.
    Energy Consumption Energy consumption is an evaluation metric that could be easily
    overlooked, and as is evidenced by our review, just 6 studies (< 10%) reported
    energy consumption. Considering that detection missions are carried out on UAVs,
    the batteries of these UAVs have to provide energy for their own flight, the computing
    platform, and data transmission at the same time. However, the energy seems not
    easy to calculate. In [88], a data transmission energy consumption model, a UAV
    computing energy consumption model, and a UAV flight energy consumption model
    were developed to estimate the total energy consumption over the whole real-time
    object detection task. 5. Discussion In this survey, 77 studies were included
    in a systematic review of real-time object detection based on UAV remote sensing.
    These studies covered different application scenarios and were analyzed in terms
    of hardware selection, algorithm development, and improvement to achieve real-time
    detection over the past 20 years. In summary, real-time object detection is a
    technology that is increasingly in demand in UAV remote sensing because of its
    advantages related to higher detection efficiency and faster response times. In
    this section, the research challenges and the outlook for realizing UAV real-time
    object detection are discussed. 5.1. Current Challenges 5.1.1. Sensor Usage for
    UAV Real-Time Object Detection Promising performance for various real-time object
    detection applications has been shown for four types of sensors and one type of
    sensor combination that can be used on UAVs, namely RBG, multi-spectral, hyper-spectral,
    and thermal sensors, as well as the combination of RGB and thermal sensors. Based
    on the analysis of the sensors deployed, the challenges of sensors in real-time
    applications are further discussed. Although the choice of sensors for UAV real-time
    object detection tasks comes in part from the needs of the measured targets and
    scenarios, more importantly, RGB sensors are used in most studies because of their
    smaller data size, more accessibility to setup, and the more superficial processing
    of RGB images. Meanwhile, the lower price of the RGB camera is also the reason
    to choose it, especially in some large-scale applications [113]. However, it is
    important to note that the spectral information provided by RGB is limited. Multi-spectral
    and hyper-spectral cameras can obtain more band information than RGB cameras,
    especially hyper-spectral imagery containing fine spectral resolution, although
    this also means a larger data volume and increasing computational complexity.
    According to the investigation conducted in this article, there are only two studies
    on real-time object detection using hyper-spectral data with UAVs. One of the
    studies [96] aimed to detect plastics in the ocean by selecting three feature
    bands, including bands sensitive to non-plastics, PE polymers, and PET polymers.
    The authors combined the data from these three bands as training data and used
    a linear classifier for supervised learning to obtain the plastic detection algorithm.
    The advantage of the linear classifier is that it requires very little computing
    resources, making it possible to implement real-time detection on lightweight
    computing platforms mounted on drones. However, the authors also emphasized the
    disadvantage of this approach, which is the inability to automatically extract
    features and the need for a large amount of pre-processing compared to deep learning
    algorithms that require more computing resources. Another study [114] focused
    on ship detection in the maritime environment. The authors proposed a complete
    solution for real-time hyper-spectral detection based on UAVs. The solution includes
    a hyper-spectral system with a camera and control board, a geographic positioning
    system with a Global Positioning System (GPS) and an inertial measurement unit
    (IMU), and a data processing system with a CPU. They used a processing method
    called hyper-spectral derivative anomaly detection (HYDADE) to analyze peak values
    in the spectral response by processing the first and second derivatives of the
    spectrum obtained for each pixel and comparing them with an adaptive threshold
    to detect ships. Based on these two cases, it can be observed that in order to
    achieve real-time detection, researchers have employed relatively simple algorithms
    for processing hyper-spectral data to adapt to the limited computing resources
    on UAVs. Therefore, it is noteworthy that there are only a few algorithms available
    for the real-time processing of hyper-spectral images up to this point. However,
    in other scenarios, especially in agriculture, although hyper-spectral offline
    processing has been widely used in applications such as disease detection [102]
    and crop identification [115], it is still limited in its real-time application.
    Therefore, considering the potential application of deep learning in the field
    of edge computing, its integration is expected to play a significant role in real-time
    detection. Thus, it may be worthwhile to explore the possibility of developing
    a real-time detection algorithm for hyper-spectral images using neural network
    architectures. Furthermore, the enormous volumes of hyper-spectral data not only
    limit them to real-time processing on the low-performance embedded processors
    but also pose challenges for transmitting data in the edge computing environment.
    Compressing hyper-spectral data to achieve their real-time transmission is a solution
    [116]. However, the performance-constricted computing platform onboard also limits
    the compression algorithm due to the high data rate produced by hyper-spectral
    sensors. Therefore, in the above study [116], the authors also mentioned several
    requirements for using a compression algorithm onboard to achieve real-time hyper-spectral
    imagery transmission, including its low computation cost, a high compression ratio,
    an error-resilient nature, and a high level of parallelism that allows for taking
    advantage of low-power graphics processing units (LPGPUs) to speed up the compression
    process. These requirements are very similar to those found in the space environment
    for satellites [117]. In this review, [118] introduced different hyper-spectral
    image compression algorithms for remote sensing. They concluded that exploring
    parallel and hardware implementation is beneficial for reducing computation time
    and computation power and improving performance. From the algorithm optimization
    aspect, in this work [119], they reuse the information extracted from one of the
    compressed hyper-spectral frames to avoid repeat execution in the subsequent hyper-spectral
    frames based on HyperLCA [120], which is a compression algorithm for satellites.
    Moreover, this study demonstrated that the proposed algorithm could be implemented
    in a Jetson Xavier NX on a UAV to compress in real-time hyper-spectral data captured
    by a Specim FX10 camera, which can transmit to ground stations at up to 200 FPS.
    On the other hand, lossless and near-lossless compression showed limited research
    [118], and it is also difficult to attain ratios better than 4:1 just depending
    on lossless compression [121]. Some research proposed a combination of image size
    and encoding algorithms for lossless image compression in the medical field [122].
    Thus, in order to achieve the real-time transmission of hyper-spectral data, it
    is necessary to perform lossy compression to meet the compression ratios imposed
    by the transmission acquisition data rate and transmission bandwidth, but the
    quality of the hyper-spectral data received by the edge server (or ground station)
    must be sufficient to guarantee the minimum standards required by the tasks [116].
    Similarly, other sensors, such as RGB and multi-spectral sensors, should also
    consider the impact of compression algorithms on data quality (resolution) during
    transmission when applying the edge computing paradigm to transmit data to edge
    servers for detection tasks and computation. In terms of multi-spectral sensors,
    although processing multi-spectral data is not as complex as hyper-spectral data,
    some algorithms quickly slow down as the number of bands to be processed increases
    or their parameters change [123]. In one selected study [74], the authors successfully
    trained a deep learning network to detect trees using one-band spectral images.
    This indicates that multi-spectral sensors have a similar challenge as hyper-spectral
    sensors, which need to know the spectral information from targets of interest
    to conduct spectral matching instead of going further to exploit the advantages
    of multi-spectral or hyper-spectral data including more spectrum information to
    detect specific targets. 5.1.2. Edge Computing Paradigm for UAV Real-Time Object
    Detection In this review, edge computing is the most commonly used paradigm for
    real-time detection, rather than cloud computing, as we illustrated in Figure
    8. Cloud computing needs to upload large amounts of raw data to the cloud, which
    is a great challenge for network bandwidth. Although 5G can provide large bandwidth
    and low latency to realize quick transmission between the data generator end and
    the cloud center [124], in our investigation, using 5G technology is not the first
    choice for object detection based on UAV remote sensing applications. A possible
    reason for this is that the capacity of the network is measured by the bandwidth
    per cubic meter, and for UAV remote sensing applications, the number of 5G base
    stations and the number of connected devices in a large space may limit the performance
    of 5G [124]. Thus, despite some success with 5G in object detection that is not
    in the UAV remote sensing scenario, this problem still exists to some extent [125].
    The odds of edge computing is that it allows for more functions to be deployed
    to end devices at the edge to enable them to process the generated data, thus
    solving computationally intensive offloading and latency problems [126]. There
    are two kinds of edge computing paradigms. One is to deploy a local edge server
    (ground station) for UAV information processing (Figure 7b), and the other one
    is to implement a UAV-onboard real-time embedded platform (Figure 7c). Undoubtedly,
    the ideal situation for UAV real-time object detection tasks is to perform onboard
    computation, which avoids the raw data transfer, which usually puts pressure on
    the transmission of the sensor-generated imagery data in object detection using
    computer vision. At the same time, although embedded edge computing platforms
    with GPU acceleration are available in the industry and have been validated in
    different UAV real-time detection scenarios, their computing power is still not
    comparable to that of professional-level computing platforms, which has led to
    a lot of research focusing on how to optimize algorithms [56,65,85], and most
    commonly, compress computer vision models that consist of deep neural networks.
    In [127], the authors pointed out that onboard processing could greatly increase
    the energy consumption of the UAV, making it impossible to take advantage of practical
    applications. In particular, the battery packs of commercial UAVs are for propulsion
    [128], and once this power is allocated to onboard processing and data transmission,
    the flight time will be significantly reduced, which will also lead to a decrease
    in the overall efficiency of the detection tasks [129]. Although an external battery
    can be chosen to power the computing platform exclusively, this in turn will increase
    the payload on the UAV and thus reduce the flight time as well. In this review,
    only 7 studies attempted to consider computing offloading. Computation offloading
    can significantly reduce energy consumption and computing resource requirements
    by a large margin, and this is a current area of research on mobile edge computing
    [130]. Some studies indicated that offloading processing is a feasible solution
    for real-time tasks, which takes into account energy consumption and processing
    speed [125,127,129]. There are four types of offloading types: binary offloading,
    partial offloading, hierarchical architectures, and distributed computing [126].
    The offloading type depends on the UAV’s flying time and the computational capacity
    of both the UAV-aided edge server and the ground edge server, and [131] pointed
    out that energy consumption and task completion time are the most crucial performance
    metrics for designing an offloading algorithm. The included literature in this
    review did not discuss the offloading technology applied in UAVs. One challenge
    mentioned by [132] indicated that the ground edge server may not have sufficient
    energy to execute an offloaded task. Another issue is the offloading delay, which
    was raised in [131] and which has several causes, such as obstacles, low-frequency
    channels, and task size, as well as the constant innovations in neural networks
    that cannot be ignored [126]. Additionally, service latency could affect UAV real-time
    object detection, as mentioned in [131], and a higher latency causes system overhead,
    which severely deteriorates offloading performance. 5.1.3. Lightweight Real-Time
    Object Detection Algorithms Based on UAVs Real-time object detection algorithms
    run on resource-limited edge computing platforms, and those models need to be
    relatively lightweight, thereby reducing the reliance on computational resources
    as well as reducing inference time to meet real-time requirements. In [6], the
    authors highlighted that it has been challenging to improve the detection time
    of detectors, and they provided an overview of the speed-up techniques, including
    feature map shared computation, cascaded detection, network pruning and quantification,
    lightweight network design, and numerical acceleration. In our review study on
    UAV real-time object detection, the most commonly used methods to improve the
    speed of the algorithm are network pruning [54,56,65,112], quantification [67,82,92],
    and the use of a lightweight network design. Network pruning is an essential technique
    for both memory size and bandwidth reduction, and it can remove the redundancy
    of a network and parameters, which can reduce computations without a significant
    impact on accuracy. In [133], the authors demonstrated the possibility of pruning
    90% of all weights in a ResNet-50 network trained on ImageNet, with a loss of
    less than 3% accuracy. However, in [134], the authors noted that although network
    pruning sometimes progressively improves accuracy by escaping the local minimum,
    the accuracy gains are better realized by switching to a better architecture [135].
    In the meantime, the performance could also be bottlenecked by the structure itself,
    and a network architecture search and knowledge distillation can be options for
    further compression [136]. From the practical point of view, due to the limitation
    of embedded device resources, large-capacity optimization networks are not allowed,
    so in [137], the authors pointed out that when pruning a network, it is best to
    consider the deployment environment, target device, and speed/accuracy trade-offs
    to meet the needs of the constrained environment. To perform network quantization
    is to compress a neural network by reducing its value precision, i.e., by converting
    FP32 numbers to lower-bit representations, which can accelerate inference speed
    [136]. However, the literature also mentioned that quantization usually leads
    to accuracy loss due to information loss during the quantization process. In UAV
    real-time object detection tasks, it is a common idea to adopt a compact network
    as the initial model. Unfortunately, the accuracy drop during quantization is
    especially obvious in compact networks. Some advanced quantization techniques
    [136], including asymmetric quantization [40] and calibration-based quantization
    [64], can improve the accuracy. In practice, 8-bit quantization is widely used,
    and in our review studies [67,74], good trade-offs between accuracy and compression
    were achieved in real-time object detection. 5.1.4. Other Challenges for Real-Time
    Object Detection on UAV Remote Sensing Since the implementation of real-time object
    detection for UAVs is a complex task, there are still some neglected issues that
    need to be taken into account. In the detection process of UAVs, remote sensing
    images are often collected by setting up missions in the system. Mature UAVs have
    stable flight control systems and autonomous navigation through active or passive
    sensors [4]. However, in order to achieve the task of real-time target detection,
    with the potential for UAVs to penetrate deeper into the environment rather than
    just detecting at high altitudes, consideration needs to be given to whether there
    is competition for computational resources between increasingly complex autonomous
    navigation and obstacle avoidance strategies and target detection, as well as
    the challenges posed by increased energy consumption. For UAV real-time target
    detection, the collected data need to be read onboard. However, commercial UAV
    manufacturers usually do not open-source their flight control, map transmission,
    or other systems due to copyright considerations, and only a few UAV series are
    open to a limited API interface. These studies [138,139] used the SDKs provided
    by DJI. This certainly makes secondary development more difficult in situations
    where the required information is not directly available. Although the option
    of using open-source flight control, such as PX4 Autopilot (https://px4.io/ (accessed
    on 6 June 2023)), exists, there is also a significant amount of design expertise
    required to ensure its stability, safety, and legality. This may account for the
    lack of implementation of real-time object detection on UAVs from a practical
    operation perspective during this review process. 5.2. Future Outlook 5.2.1. Autonomous
    UAV Real-Time Object Detection As we illustrated in Figure 1,for the concept of
    real-time object detection based on UAV remote sensing, when the computing platform
    executes the detection models, outputting the results and real-time responses
    can make the real-time object detection tasks more automatic and form a closed
    loop. The idea of autonomous UAV tasks is to reduce human operation, where humans
    can just issue commands to deploy, monitor, and terminate the missions of UAVs.
    The UAV can conduct remote sensing according to a specified mission plan and run
    its algorithms automatically to output results. These results can be sent to humans,
    machines, or systems to make quick decisions and respond. In [140], the authors
    used UAVs to identify infected plants and link the results to the system. Then,
    the system decided the chemical and exact amount of spray to use. In this simulation,
    the researchers developed an automatic collaboration between UAVs to detect garbage
    pollution across water surfaces and USVs to pick up garbage [141], thus establishing
    more reliable frameworks to realize a collaborative platform between UAVs and
    systems or robots (air-to-air and air-to-ground) in real-time detection scenarios
    [142]. This will have the opportunity to further bridge the gap between UAVs and
    manned aerial and terrestrial surveys [4]. In fact, the demand for UAV real-time
    object detection comes from the demand for real-time response. It is meaningless
    if only a real-time detection result is obtained. Humans need to use real-time
    detection results to reduce losses and improve efficiency. To achieve this, some
    technologies, including multi-machine collaborative work [143,144], knowledge
    graphs [145], natural language processing [146], and blockchain [147], are needed.
    5.2.2. Communication in Real-Time Object Detection Based on UAV Remote Sensing
    As we discussed in the previous section, edge computing is an ideal technology
    for achieving real-time object detection, except for improving lightweight models
    and offloading technology. In contrast, the development of communication technologies
    cannot be ignored. The limitation of 5G basically arises from the need to reach
    data rates of up to 100 Mbps and 50 Mbps for downlink and uplink, respectively
    [125]. Compared to 5G, 6G needs more significant improvements in performance,
    such as bandwidth, delay, and coverage, which expands 5G’s requirements for scenarios
    such as ultra-low latency, massive connections, and ultra-large bandwidth to achieve
    higher peak transmission rates [148]. Benefiting from the large communication
    bandwidth and high transmission rate of the 6G mobile network, UAVs can achieve
    efficient data collection in a shorter period, which also overcomes the problem
    of insufficient collection time caused by the short battery life of UAVs. In addition,
    the challenge of real-time detection is not only solved by reducing latency and
    increasing network bandwidth but also by considering technologies such as pre-training
    and online learning to solve real-time tasks. The above-mentioned discussion points
    indicate that it is essential to support machine learning or deep learning algorithms
    at the edge. Future generations of wireless communication systems have the opportunity
    to solve this issue. The communication channels in THz and optical frequency regimes,
    while exploiting modulation methods capable of 10 b/symbol, can achieve data rates
    of around 100 Tb/s with such assumptions in mind to provide a communication link
    that can enable massive computations to be conducted remotely from the device
    or machine that is undertaking real-time processing at the edge of the network
    [149]. However, there are also some challenges that need to be considered, such
    as how to enable the interaction between the data generated by UAVs in the airspace
    network and other heterogeneous networks and how to solve the problem of insufficient
    spectrum resources caused by massive UAV access to a 6G network. Additionally,
    even though there is automatic battery replacement technology for UAVs, it still
    cannot solve the root problem of short battery life [150]. 6. Conclusions This
    study reviewed the recent literature on real-time object detection based on UAV
    remote sensing. We investigated the advances in aerial real-time object detection
    and comprehensively considered different aspects, including application scenarios,
    hardware usage, algorithm deployment, and evaluation metrics. Accordingly, the
    current research status and challenges are presented, and a basis and suggestions
    for future research have been proposed. We have adopted a systematic literature
    review approach by first defining a concept map for real-time object detection
    by UAV remote sensing, and according to the concept map analysis, seven research
    questions were analyzed (RQs). The review findings well-illustrated seven research
    questions. More real-time object detection research exists in emergency rescue,
    precision agriculture, traffic, and public facility inspection scenarios (RQ1).
    Multi-rotor UAVs are the most-used platforms due to their ability to hover, thus
    providing easy access to remote sensing images. Although thermal and spectral
    sensors have emerged for studies, they currently need to become mainstream for
    real-time detection but are limited by the form and size of their image data.
    Thus, RGB images are being studied more in UAV remote sensing (RQ2). Most real-time
    detection adopts the edge computing paradigm, and the number of studies using
    the onboard processing strategy is much greater than those using the computation
    offloading strategy (RQ3). GPU-based edge computing platforms are widely used
    to complete real-time object detection in UAV remote sensing images. However,
    some applications also use CPU, VPU, TPU, and FPGA according to their requirements
    (RQ4). With the widespread use of deep learning, it has become the first choice
    for real-time object detection tasks (RQ5), so it is vital to optimize these algorithms
    to better deploy them on resource-constrained computing platforms. Optimization
    can be carried out, e.g., by the use of lightweight convolutional layers, by pruning
    parameters, utilizing low-rank factorization, and incorporating knowledge distillation
    (RQ6). Finally, for evaluation metrics, in addition to accuracy and speed, latency
    and energy deserve equal attention (RQ7). In conclusion, this paper has highlighted
    the challenges and key issues associated with implementing real-time object detection
    for UAV remote sensing. Through a comprehensive analysis of sensor usage, edge
    computing, and model compression, this paper has identified areas that require
    further research and development. Future research needs to explore real-time processing
    solutions for multi-spectral and hyper-spectral images and investigate the possibilities
    of hardware and algorithms under different edge computing paradigms. As mentioned
    in this paper, bridging multiple disciplines, such as robotics and remote sensing,
    is crucial to fostering innovation and progress in real-time UAV remote sensing,
    and collaborative research efforts that connect different fields of study can
    further leverage the latest technologies for the benefit of society. Author Contributions
    Conceptualization, Z.C., L.K. and J.V.; methodology, Z.C.; formal analysis, Z.C.;
    investigation, Z.C.; data curation, Z.C.; writing—original draft preparation,
    Z.C.; writing—review and editing, Z.C., L.K., J.V. and W.W.; visualization, Z.C.;
    supervision, L.K., J.V. and W.W.; project administration, L.K, J.V. and W.W.;
    funding acquisition, L.G. All authors have read and agreed to the published version
    of the manuscript. Funding This research was funded by the National Key R&D Program
    of China (2021ZD0110901) and the Science and Technology Planning Project of the
    Inner Mongolia Autonomous Region (2021GG0341). Data Availability Statement Not
    applicable. Conflicts of Interest The authors declare no conflict of interest.
    References Yang, X.; Smith, A.; Bourchier, R.; Hodge, K.; Ostrander, D.; Houston,
    B. Mapping flowering leafy spurge infestations in a heterogeneous landscape using
    unmanned aerial vehicle Red-Green-Blue images and a hybrid classification method.
    Int. J. Remote Sens. 2021, 42, 8930–8951. [Google Scholar] Feng, J.; Wang, J.;
    Qin, R. Lightweight detection network for arbitrary-oriented vehicles in UAV imagery
    via precise positional information encoding and bidirectional feature fusion.
    Int. J. Remote Sens. 2023, 44, 1–30. [Google Scholar] Alsamhi, S.H.; Shvetsov,
    A.V.; Kumar, S.; Shvetsova, S.V.; Alhartomi, M.A.; Hawbani, A.; Rajput, N.S.;
    Srivastava, S.; Saif, A.; Nyangaresi, V.O. UAV computing-assisted search and rescue
    mission framework for disaster and harsh environment mitigation. Drones 2022,
    6, 154. [Google Scholar] [CrossRef] Nex, F.; Armenakis, C.; Cramer, M.; Cucci,
    D.A.; Gerke, M.; Honkavaara, E.; Kukko, A.; Persello, C.; Skaloud, J. UAV in the
    advent of the twenties: Where we stand and what is next. ISPRS J. Photogramm.
    Remote Sens. 2022, 184, 215–242. [Google Scholar] Chabot, D. Trends in drone research
    and applications as the Journal of Unmanned Vehicle Systems turns five. J. Unmanned
    Veh. Syst. 2018, 6, vi–xv. [Google Scholar] [CrossRef] Zou, Z.; Chen, K.; Shi,
    Z.; Guo, Y.; Ye, J. Object detection in 20 years: A survey. Proc. IEEE 2023, 111,
    257–276. [Google Scholar] Aposporis, P. Object detection methods for improving
    UAV autonomy and remote sensing applications. In Proceedings of the 2020 IEEE/ACM
    International Conference on Advances in Social Networks Analysis and Mining (ASONAM),
    Virtual, 7–10 December 2020; pp. 845–853. [Google Scholar] Ghaffarian, S.; Valente,
    J.; Van Der Voort, M.; Tekinerdogan, B. Effect of attention mechanism in deep
    learning-based remote sensing image processing: A systematic literature review.
    Remote Sens. 2021, 13, 2965. [Google Scholar] Cazzato, D.; Cimarelli, C.; Sanchez-Lopez,
    J.L.; Voos, H.; Leo, M. A survey of computer vision methods for 2d object detection
    from unmanned aerial vehicles. J. Imaging 2020, 6, 78. [Google Scholar] Osco,
    L.P.; Junior, J.M.; Ramos, A.P.M.; de Castro Jorge, L.A.; Fatholahi, S.N.; de
    Andrade Silva, J.; Matsubara, E.T.; Pistori, H.; Gonçalves, W.N.; Li, J. A review
    on deep learning in UAV remote sensing. Int. J. Appl. Earth Obs. Geoinf. 2021,
    102, 102456. [Google Scholar] Pathak, A.R.; Pandey, M.; Rautaray, S. Application
    of deep learning for object detection. Procedia Comput. Sci. 2018, 132, 1706–1717.
    [Google Scholar] Tetila, E.C.; Machado, B.B.; Menezes, G.K.; Oliveira, A.d.S.;
    Alvarez, M.; Amorim, W.P.; Belete, N.A.D.S.; Da Silva, G.G.; Pistori, H. Automatic
    recognition of soybean leaf diseases using UAV images and deep convolutional neural
    networks. IEEE Geosci. Remote Sens. Lett. 2019, 17, 903–907. [Google Scholar]
    Feng, Q.; Liu, J.; Gong, J. UAV remote sensing for urban vegetation mapping using
    random forest and texture analysis. Remote Sens. 2015, 7, 1074–1094. [Google Scholar]
    Nevalainen, O.; Honkavaara, E.; Tuominen, S.; Viljanen, N.; Hakala, T.; Yu, X.;
    Hyyppä, J.; Saari, H.; Pölönen, I.; Imai, N.N.; et al. Individual tree detection
    and classification with UAV-based photogrammetric point clouds and hyperspectral
    imaging. Remote Sens. 2017, 9, 185. [Google Scholar] Byun, S.; Shin, I.K.; Moon,
    J.; Kang, J.; Choi, S.I. Road traffic monitoring from UAV images using deep learning
    networks. Remote Sens. 2021, 13, 4027. [Google Scholar] [CrossRef] Sherstjuk,
    V.; Zharikova, M.; Sokol, I. Forest fire-fighting monitoring system based on UAV
    team and remote sensing. In Proceedings of the 2018 IEEE 38th International Conference
    on Electronics and Nanotechnology (ELNANO), Kyiv, Ukraine, 22–24 April 2018; pp.
    663–668. [Google Scholar] Tijtgat, N.; Ranst, W.V.; Volckaert, B.; Goedemé, T.;
    Turck, F.D. Embedded Real-Time Object Detection for a UAV Warning System. In Proceedings
    of the 2017 IEEE International Conference on Computer Vision Workshops (ICCVW),
    Venice, Italy, 22–29 October 2017; pp. 2110–2118. [Google Scholar] [CrossRef]
    Deng, J.; Zhong, Z.; Huang, H.; Lan, Y.; Han, Y.; Zhang, Y. Lightweight semantic
    segmentation network for real-time weed mapping using unmanned aerial vehicles.
    Appl. Sci. 2020, 10, 7132. [Google Scholar] Ayalew, A.; Pooja. A review on object
    detection from Unmanned Aerial Vehicle using CNN. Int. J. Adv. Res. Ideas Innov.
    Technol. 2019, 5, 241–243. [Google Scholar] Borghi, R.; Gori, F.; Guattari, G.;
    Santarsiero, M. Shape-invariant difference between two Gaussian Schell-model beams.
    JOSA A 2015, 32, 790–796. [Google Scholar] Liu, J.; Xiang, J.; Jin, Y.; Liu, R.;
    Yan, J.; Wang, L. Boost precision agriculture with unmanned aerial vehicle remote
    sensing and edge intelligence: A survey. Remote Sens. 2021, 13, 4387. [Google
    Scholar] Ramachandran, A.; Sangaiah, A.K. A review on object detection in unmanned
    aerial vehicle surveillance. Int. J. Cogn. Comput. Eng. 2021, 2, 215–228. [Google
    Scholar] [CrossRef] Kitchenham, B.; Brereton, O.P.; Budgen, D.; Turner, M.; Bailey,
    J.; Linkman, S. Systematic literature reviews in software engineering–a systematic
    literature review. Inf. Softw. Technol. 2009, 51, 7–15. [Google Scholar] Kitchenham,
    B. Procedures for Performing Systematic Reviews. Keele UK Keele Univ. 2004, 33,
    1–26. [Google Scholar] Krul, S.; Pantos, C.; Frangulea, M.; Valente, J. Visual
    SLAM for indoor livestock and farming using a small drone with a monocular camera:
    A feasibility study. Drones 2021, 5, 41. [Google Scholar] [CrossRef] Li, Z.; Namiki,
    A.; Suzuki, S.; Wang, Q.; Zhang, T.; Wang, W. Application of low-altitude UAV
    remote sensing image object detection based on improved YOLOv5. Appl. Sci. 2022,
    12, 8314. [Google Scholar] [CrossRef] Meng, L.; Peng, Z.; Zhou, J.; Zhang, J.;
    Lu, Z.; Baumann, A.; Du, Y. Real-time detection of ground objects based on unmanned
    aerial vehicle remote sensing with deep learning: Application in excavator detection
    for pipeline safety. Remote Sens. 2020, 12, 182. [Google Scholar] [CrossRef] Canals,
    R.; Roussel, A.; Famechon, J.L.; Treuillet, S. A biprocessor-oriented vision-based
    target tracking system. IEEE Trans. Ind. Electron. 2002, 49, 500–506. [Google
    Scholar] [CrossRef] Ayoub, N.; Schneider-Kamp, P. Real-time on-board deep learning
    fault detection for autonomous UAV inspections. Electronics 2021, 10, 1091. [Google
    Scholar] [CrossRef] Yavariabdi, A.; Kusetogullari, H.; Celik, T.; Cicek, H. FastUAV-net:
    A multi-UAV detection algorithm for embedded platforms. Electronics 2021, 10,
    724. [Google Scholar] [CrossRef] Alam, M.S.; Natesha, B.; Ashwin, T.; Guddeti,
    R.M.R. UAV based cost-effective real-time abnormal event detection using edge
    computing. Multimed. Tools Appl. 2019, 78, 35119–35134. [Google Scholar] [CrossRef]
    Gupta, P.; Pareek, B.; Singal, G.; Rao, D.V. Edge device based military vehicle
    detection and classification from uav. Multimed. Tools Appl. 2022, 81, 19813–19834.
    [Google Scholar] [CrossRef] Yang, Y.; Han, J. Real-Time object detector based
    MobileNetV3 for UAV applications. Multimed. Tools Appl. 2022, 82, 18709–18725.
    [Google Scholar] [CrossRef] Broekman, A.; Gräbe, P.J.; Wynand, J. Real-time traffic
    quantization using a mini edge artificial intelligence platform. Transp. Eng.
    2021, 4, 100068. [Google Scholar] [CrossRef] Ma, D.; Fang, H.; Wang, N.; Zhang,
    C.; Dong, J.; Hu, H. Automatic detection and counting system for pavement cracks
    based on PCGAN and YOLO-MF. IEEE Trans. Intell. Transp. Syst. 2022, 23, 22166–22178.
    [Google Scholar] [CrossRef] Mohan, S.; Shoghli, O.; Burde, A.; Tabkhi, H. Low-power
    drone-mountable real-time artificial intelligence framework for road asset classification.
    Transp. Res. Rec. 2021, 2675, 39–48. [Google Scholar] [CrossRef] Battistone, F.;
    Petrosino, A.; Santopietro, V. Watch out: Embedded video tracking with BST for
    unmanned aerial vehicles. J. Signal Process. Syst. 2018, 90, 891–900. [Google
    Scholar] [CrossRef] Deng, J.; Shi, Z.; Zhuo, C. Energy-efficient real-time UAV
    object detection on embedded platforms. IEEE Trans. Comput.-Aided Des. Integr.
    Circuits Syst. 2019, 39, 3123–3127. [Google Scholar] [CrossRef] Koubâa, A.; Ammar,
    A.; Alahdab, M.; Kanhouch, A.; Azar, A.T. Deepbrain: Experimental evaluation of
    cloud-based computation offloading and edge computing in the internet-of-drones
    for deep learning applications. Sensors 2020, 20, 5240. [Google Scholar] [CrossRef]
    Rabah, M.; Rohan, A.; Haghbayan, M.H.; Plosila, J.; Kim, S.H. Heterogeneous parallelization
    for object detection and tracking in UAVs. IEEE Access 2020, 8, 42784–42793. [Google
    Scholar] [CrossRef] Hua, X.; Wang, X.; Rui, T.; Shao, F.; Wang, D. Light-weight
    UAV object tracking network based on strategy gradient and attention mechanism.
    Knowl.-Based Syst. 2021, 224, 107071. [Google Scholar] [CrossRef] Kyrkou, C. C^3
    Net C 3 Net: End-to-end deep learning for efficient real-time visual active camera
    control. J. Real-Time Image Process. 2021, 18, 1421–1433. [Google Scholar] [CrossRef]
    Liu, J.; Hu, C.; Zhou, J.; Ding, W. Object Detection Algorithm Based on Lightweight
    YOLOv4 for UAV. In Proceedings of the 2022 7th International Conference on Intelligent
    Computing and Signal Processing (ICSP), Xi’an, China, 15–17 April 2022; pp. 425–429.
    [Google Scholar] Shen, H.; Lin, D.; Song, T. A real-time siamese tracker deployed
    on UAVs. J. Real-Time Image Process. 2022, 19, 463–473. [Google Scholar] [CrossRef]
    Lygouras, E.; Santavas, N.; Taitzoglou, A.; Tarchanidis, K.; Mitropoulos, A.;
    Gasteratos, A. Unsupervised human detection with an embedded vision system on
    a fully autonomous UAV for search and rescue operations. Sensors 2019, 19, 3542.
    [Google Scholar] [CrossRef] Rangel, R.K.; Terra, A.C. Development of a Surveillance
    tool using UAV’s. In Proceedings of the 2018 IEEE Aerospace Conference, Big Sky,
    MT, USA, 3–10 March 2018; pp. 1–11. [Google Scholar] Hossain, S.; Lee, D.j. Deep
    learning-based real-time multiple-object detection and tracking from aerial imagery
    via a flying robot with GPU-based embedded devices. Sensors 2019, 19, 3371. [Google
    Scholar] [CrossRef] Barnawi, A.; Chhikara, P.; Tekchandani, R.; Kumar, N.; Alzahrani,
    B. Artificial intelligence-enabled Internet of Things-based system for COVID-19
    screening using aerial thermal imaging. Future Gener. Comput. Syst. 2021, 124,
    119–132. [Google Scholar] [CrossRef] Golcarenarenji, G.; Martinez-Alpiste, I.;
    Wang, Q.; Alcaraz-Calero, J.M. Efficient real-time human detection using unmanned
    aerial vehicles optical imagery. Int. J. Remote Sens. 2021, 42, 2440–2462. [Google
    Scholar] [CrossRef] Li, J.; Peng, Y.; Jiang, T. Embedded real-time infrared and
    visible image fusion for UAV surveillance. J. Real-Time Image Process. 2021, 18,
    2331–2345. [Google Scholar] [CrossRef] Martinez-Alpiste, I.; Golcarenarenji, G.;
    Wang, Q.; Alcaraz-Calero, J.M. Search and rescue operation using UAVs: A case
    study. Expert Syst. Appl. 2021, 178, 114937. [Google Scholar] [CrossRef] Othman,
    N.A.; Aydin, I. A Low-Cost Embedded Security System for UAV-Based Face Mask Detector
    Using IoT and Deep Learning to Reduce COVID-19. In Proceedings of the 2022 International
    Conference on Decision Aid Sciences and Applications (DASA), Chiangrai, Thailand,
    23–25 March 2022; pp. 693–697. [Google Scholar] Hernández, D.; Cecilia, J.M.;
    Cano, J.C.; Calafate, C.T. Flood detection using real-time image segmentation
    from unmanned aerial vehicles on edge-computing platform. Remote Sens. 2022, 14,
    223. [Google Scholar] [CrossRef] Kyrkou, C.; Theocharides, T. Deep-Learning-Based
    Aerial Image Classification for Emergency Response Applications Using Unmanned
    Aerial Vehicles. In Proceedings of the CVPR Workshops, Long Beach, CA, USA, 16–19
    June 2019; pp. 517–525. [Google Scholar] Kyrkou, C.; Theocharides, T. EmergencyNet:
    Efficient aerial image classification for drone-based emergency monitoring using
    atrous convolutional feature fusion. IEEE J. Sel. Top. Appl. Earth Obs. Remote
    Sens. 2020, 13, 1687–1699. [Google Scholar] [CrossRef] Wang, S.; Zhao, J.; Ta,
    N.; Zhao, X.; Xiao, M.; Wei, H. A real-time deep learning forest fire monitoring
    algorithm based on an improved Pruned+ KD model. J. Real-Time Image Process. 2021,
    18, 2319–2329. [Google Scholar] [CrossRef] Yuan, C.; Ghamry, K.A.; Liu, Z.; Zhang,
    Y. Unmanned aerial vehicle based forest fire monitoring and detection using image
    processing technique. In Proceedings of the 2016 IEEE Chinese Guidance, Navigation
    and Control Conference (CGNCC), Nanjing, China, 29–31 July 2016; pp. 1870–1875.
    [Google Scholar] Castellano, G.; Castiello, C.; Mencar, C.; Vessio, G. Crowd detection
    in aerial images using spatial graphs and fully-convolutional neural networks.
    IEEE Access 2020, 8, 64534–64544. [Google Scholar] [CrossRef] Chen, N.; Chen,
    Y. Anomalous vehicle recognition in smart urban traffic monitoring as an edge
    service. Future Internet 2022, 14, 54. [Google Scholar] [CrossRef] Marques, M.M.;
    Lobo, V.; Aguiar, A.P.; Silva, J.E.; de Sousa, J.B.; de Fátima Nunes, M.; Ribeiro,
    R.A.; Bernardino, A.; Cruz, G.; Marques, J.S. An unmanned aircraft system for
    maritime operations: The automatic detection subsystem. Mar. Technol. Soc. J.
    2021, 55, 38–49. [Google Scholar] [CrossRef] Li, F.; Liu, Z.; Shen, W.; Wang,
    Y.; Wang, Y.; Ge, C.; Sun, F.; Lan, P. A remote sensing and airborne edge-computing
    based detection system for pine wilt disease. IEEE Access 2021, 9, 66346–66360.
    [Google Scholar] [CrossRef] Lan, Y.; Lin, S.; Du, H.; Guo, Y.; Deng, X. Real-Time
    UAV Patrol Technology in Orchard Based on the Swin-T YOLOX Lightweight Model.
    Remote Sens. 2022, 14, 5806. [Google Scholar] [CrossRef] Yağ, İ.; Altan, A. Artificial
    Intelligence-Based Robust Hybrid Algorithm Design and Implementation for Real-Time
    Detection of Plant Diseases in Agricultural Environments. Biology 2022, 11, 1732.
    [Google Scholar] [CrossRef] Chen, C.J.; Huang, Y.Y.; Li, Y.S.; Chen, Y.C.; Chang,
    C.Y.; Huang, Y.M. Identification of fruit tree pests with deep learning on embedded
    drone to achieve accurate pesticide spraying. IEEE Access 2021, 9, 21986–21997.
    [Google Scholar] [CrossRef] de Camargo, T.; Schirrmann, M.; Landwehr, N.; Dammer,
    K.H.; Pflanz, M. Optimized deep learning model as a basis for fast UAV mapping
    of weed species in winter wheat crops. Remote Sens. 2021, 13, 1704. [Google Scholar]
    [CrossRef] Lan, Y.; Huang, K.; Yang, C.; Lei, L.; Ye, J.; Zhang, J.; Zeng, W.;
    Zhang, Y.; Deng, J. Real-time identification of rice weeds by uav low-altitude
    remote sensing based on improved semantic segmentation model. Remote Sens. 2021,
    13, 4370. [Google Scholar] [CrossRef] Menshchikov, A.; Shadrin, D.; Prutyanov,
    V.; Lopatkin, D.; Sosnin, S.; Tsykunov, E.; Iakovlev, E.; Somov, A. Real-time
    detection of hogweed: UAV platform empowered by deep learning. IEEE Trans. Comput.
    2021, 70, 1175–1188. [Google Scholar] [CrossRef] Saddik, A.; Latif, R.; El Ouardi,
    A. Low-Power FPGA Architecture Based Monitoring Applications in Precision Agriculture.
    J. Low Power Electron. Appl. 2021, 11, 39. [Google Scholar] [CrossRef] Saddik,
    A.; Latif, R.; El Ouardi, A.; Alghamdi, M.I.; Elhoseny, M. Improving Sustainable
    Vegetation Indices Processing on Low-Cost Architectures. Sustainability 2022,
    14, 2521. [Google Scholar] [CrossRef] Kobayashi, T.; Yokogawa, T.; Igawa, N.;
    Satoh, Y.; Sugino, K.; Miyata, H.; Fujii, S.; Arimoto, K. A Edge Master Computing
    for Pineapple Monitoring System with Drone and Data-management. In Proceedings
    of the 2020 9th International Congress on Advanced Applied Informatics (IIAI-AAI),
    Kitakyushu, Japan, 1–15 September 2020; pp. 404–407. [Google Scholar] Der Yang,
    M.; Tseng, H.H.; Hsu, Y.C.; Tseng, W.C. Real-time crop classification using edge
    computing and deep learning. In Proceedings of the 2020 IEEE 17th Annual Consumer
    Communications & Networking Conference (CCNC), Virtual, 10–13 January 2020; pp.
    1–4. [Google Scholar] Liénard, J.; Vogs, A.; Gatziolis, D.; Strigul, N. Embedded,
    real-time UAV control for improved, image-based 3D scene reconstruction. Measurement
    2016, 81, 264–269. [Google Scholar] [CrossRef] Salamí, E.; Gallardo, A.; Skorobogatov,
    G.; Barrado, C. On-the-fly olive tree counting using a UAS and cloud services.
    Remote Sens. 2019, 11, 316. [Google Scholar] [CrossRef] Blekos, K.; Nousias, S.;
    Lalos, A.S. Efficient automated U-Net based tree crown delineation using UAV multi-spectral
    imagery on embedded devices. In Proceedings of the 2020 IEEE 18th International
    Conference on Industrial Informatics (INDIN), Virtual, 20–23 July 2020; Volume
    1, pp. 541–546. [Google Scholar] Qin, Z.; Wang, W.; Dammer, K.H.; Guo, L.; Cao,
    Z. Ag-YOLO: A real-time low-cost detector for precise spraying with case study
    of palms. Frontiers in Plant Science 2021, 12, 753603. [Google Scholar] [CrossRef]
    [PubMed] Han, P.; Ma, C.; Chen, J.; Chen, L.; Bu, S.; Xu, S.; Zhao, Y.; Zhang,
    C.; Hagino, T. Fast tree detection and counting on UAVs for sequential aerial
    images with generating orthophoto mosaicing. Remote Sens. 2022, 14, 4113. [Google
    Scholar] [CrossRef] Chen, P.Y.; Hsieh, J.W.; Gochoo, M.; Chang, M.C.; Wang, C.Y.;
    Chen, Y.S.; Liao, H.Y.M. Drone-Based Vehicle Flow Estimation and its Application
    to Traffic Conflict Hotspot Detection at Intersections. In Proceedings of the
    2020 IEEE International Conference on Image Processing (ICIP), Virtual, 25–28
    October 2020; pp. 1521–1525. [Google Scholar] Balamuralidhar, N.; Tilon, S.; Nex,
    F. MultEYE: Monitoring system for real-time vehicle detection, tracking and speed
    estimation from UAV imagery on edge-computing platforms. Remote Sens. 2021, 13,
    573. [Google Scholar] [CrossRef] Montanari, R.; Tozadore, D.C.; Fraccaroli, E.S.;
    Romero, R.A. Ground vehicle detection and classification by an unmanned aerial
    vehicle. In Proceedings of the 2015 12th Latin American Robotics Symposium and
    2015 3rd Brazilian Symposium on Robotics (LARS-SBR), Uberlândia, Brazil, 8–11
    October 2015; pp. 253–258. [Google Scholar] Tilon, S.; Nex, F.; Vosselman, G.;
    Sevilla de la Llave, I.; Kerle, N. Towards Improved Unmanned Aerial Vehicle Edge
    Intelligence: A Road Infrastructure Monitoring Case Study. Remote Sens. 2022,
    14, 4008. [Google Scholar] [CrossRef] Rilanto Trilaksono, B.; Triadhitama, R.;
    Adiprawita, W.; Wibowo, A.; Sreenatha, A. Hardware-in-the-loop simulation for
    visual target tracking of octorotor UAV. Aircr. Eng. Aerosp. Technol. 2011, 83,
    407–419. [Google Scholar] [CrossRef] Kyrkou, C.; Plastiras, G.; Theocharides,
    T.; Venieris, S.I.; Bouganis, C.S. DroNet: Efficient convolutional neural network
    detector for real-time UAV applications. In Proceedings of the 2018 Design, Automation
    & Test in Europe Conference & Exhibition (DATE), Dresden, Germany, 9–13 March
    2018; pp. 967–972. [Google Scholar] Bian, J.; Hui, X.; Zhao, X.; Tan, M. A monocular
    vision–based perception approach for unmanned aerial vehicle close proximity transmission
    tower inspection. Int. J. Adv. Robot. Syst. 2019, 16, 1729881418820227. [Google
    Scholar] [CrossRef] Carletti, V.; Greco, A.; Saggese, A.; Vento, M. An intelligent
    flying system for automatic detection of faults in photovoltaic plants. J. Ambient
    Intell. Humaniz. Comput. 2020, 11, 2027–2040. [Google Scholar] [CrossRef] Siddiqui,
    Z.A.; Park, U. A drone based transmission line components inspection system with
    deep learning technique. Energies 2020, 13, 3348. [Google Scholar] [CrossRef]
    Ma, Y.; Li, Q.; Chu, L.; Zhou, Y.; Xu, C. Real-time detection and spatial localization
    of insulators for UAV inspection based on binocular stereo vision. Remote Sens.
    2021, 13, 230. [Google Scholar] [CrossRef] Sarkar, D.; Gunturi, S.K. Online health
    status monitoring of high voltage insulators using deep learning model. The Visual
    Computer 2021, 38, 4457–4468. [Google Scholar] [CrossRef] Deng, F.; Xie, Z.; Mao,
    W.; Li, B.; Shan, Y.; Wei, B.; Zeng, H. Research on edge intelligent recognition
    method oriented to transmission line insulator fault detection. Int. J. Electr.
    Power Energy Syst. 2022, 139, 108054. [Google Scholar] [CrossRef] Kumar, P.; Batchu,
    S.; Kota, S.R. Real-time concrete damage detection using deep learning for high
    rise structures. IEEE Access 2021, 9, 112312–112331. [Google Scholar] [CrossRef]
    Jiang, S.; Cheng, Y.; Zhang, J. Vision-guided unmanned aerial system for rapid
    multiple-type damage detection and localization. Struct. Health Monit. 2023, 22,
    319–337. [Google Scholar] [CrossRef] Yavariabdi, A.; Kusetogullari, H.; Cicek,
    H. UAV detection in airborne optic videos using dilated convolutions. J. Opt.
    2021, 50, 569–582. [Google Scholar] [CrossRef] Kaputa, D.S.; Landy, B.P. YOLBO:
    You Only Look Back Once–A Low Latency Object Tracker Based on YOLO and Optical
    Flow. IEEE Access 2021, 9, 82497–82507. [Google Scholar] [CrossRef] Kyristsis,
    S.; Antonopoulos, A.; Chanialakis, T.; Stefanakis, E.; Linardos, C.; Tripolitsiotis,
    A.; Partsinevelos, P. Towards autonomous modular UAV missions: The detection,
    geo-location and landing paradigm. Sensors 2016, 16, 1844. [Google Scholar] [CrossRef]
    Son, H.S.; Kim, D.K.; Yang, S.H.; Choi, Y.K. Real-time power line detection for
    safe flight of agricultural spraying drones using embedded systems and deep learning.
    IEEE Access 2022, 10, 54947–54956. [Google Scholar] [CrossRef] Zhou, P.; Liu,
    G.; Wang, J.; Weng, Q.; Zhang, K.; Zhou, Z. Lightweight unmanned aerial vehicle
    video object detection based on spatial-temporal correlation. Int. J. Commun.
    Syst. 2022, 35, e5334. [Google Scholar] [CrossRef] Balsi, M.; Moroni, M.; Chiarabini,
    V.; Tanda, G. High-resolution aerial detection of marine plastic litter by hyperspectral
    sensing. Remote Sens. 2021, 13, 1557. [Google Scholar] [CrossRef] Luo, W.; Han,
    W.; Fu, P.; Wang, H.; Zhao, Y.; Liu, K.; Liu, Y.; Zhao, Z.; Zhu, M.; Xu, R.; et
    al. A water surface contaminants monitoring method based on airborne depth reasoning.
    Processes 2022, 10, 131. [Google Scholar] [CrossRef] Radoglou-Grammatikis, P.;
    Sarigiannidis, P.; Lagkas, T.; Moscholios, I. A compilation of UAV applications
    for precision agriculture. Comput. Netw. 2020, 172, 107148. [Google Scholar] [CrossRef]
    Mohsan, S.A.H.; Khan, M.A.; Noor, F.; Ullah, I.; Alsharif, M.H. Towards the unmanned
    aerial vehicles (UAVs): A comprehensive review. Drones 2022, 6, 147. [Google Scholar]
    [CrossRef] Aasen, H.; Burkart, A.; Bolten, A.; Bareth, G. Generating 3D hyperspectral
    information with lightweight UAV snapshot cameras for vegetation monitoring: From
    camera calibration to quality assurance. ISPRS J. Photogramm. Remote Sens. 2015,
    108, 245–259. [Google Scholar] [CrossRef] Adão, T.; Hruška, J.; Pádua, L.; Bessa,
    J.; Peres, E.; Morais, R.; Sousa, J.J. Hyperspectral imaging: A review on UAV-based
    sensors, data processing and applications for agriculture and forestry. Remote
    Sens. 2017, 9, 1110. [Google Scholar] [CrossRef] Zhang, X.; Han, L.; Dong, Y.;
    Shi, Y.; Huang, W.; Han, L.; González-Moreno, P.; Ma, H.; Ye, H.; Sobeih, T. A
    deep learning-based approach for automated yellow rust disease detection from
    high-resolution hyperspectral UAV images. Remote Sens. 2019, 11, 1554. [Google
    Scholar] [CrossRef] Kerkech, M.; Hafiane, A.; Canals, R. Vine disease detection
    in UAV multispectral images using optimized image registration and deep learning
    segmentation approach. Comput. Electron. Agric. 2020, 174, 105446. [Google Scholar]
    [CrossRef] Udin, W.; Norazami, N.; Sulaiman, N.; Zaudin, N.C.; Ma’ail, S.; Nor,
    A.M. UAV based multi-spectral imaging system for mapping landslide risk area along
    Jeli-Gerik highway, Jeli, Kelantan. In Proceedings of the 2019 IEEE 15th International
    Colloquium on Signal Processing & Its Applications (CSPA), Penang, Malaysia, 29–30
    March 2019; pp. 162–167. [Google Scholar] Hota, M.; Kumar, U. Power Lines Detection
    and Segmentation In Multi-Spectral Uav Images Using Convolutional Neural Network.
    In Proceedings of the 2020 IEEE India Geoscience and Remote Sensing Symposium
    (InGARSS), Virtual, 1–4 December 2020; pp. 154–157. [Google Scholar] Khan, W.Z.;
    Ahmed, E.; Hakak, S.; Yaqoob, I.; Ahmed, A. Edge computing: A survey. Future Gener.
    Comput. Syst. 2019, 97, 219–235. [Google Scholar] [CrossRef] Shi, W.; Cao, J.;
    Zhang, Q.; Li, Y.; Xu, L. Edge Computing: Vision and Challenges. IEEE Internet
    Things J. 2016, 3, 637–646. [Google Scholar] [CrossRef] Hu, Y.C.; Patel, M.; Sabella,
    D.; Sprecher, N.; Young, V. Mobile edge computing—A key technology towards 5G.
    ETSI White Pap. 2015, 11, 1–16. [Google Scholar] Upadhyay, J.; Rawat, A.; Deb,
    D. UAV-Based Target Localization in Dense Areas with Computer Vision and GPS Hybrid
    Navigation Model. In Proceedings of the 2021 IEEE International India Geoscience
    and Remote Sensing Symposium (InGARSS), Virtual, 6–10 December 2021; pp. 417–420.
    [Google Scholar] Avola, D.; Cinque, L.; Di Mambro, A.; Diko, A.; Fagioli, A.;
    Foresti, G.L.; Marini, M.R.; Mecca, A.; Pannone, D. Low-altitude aerial video
    surveillance via one-class SVM anomaly detection from textural features in UAV
    images. Information 2021, 13, 2. [Google Scholar] [CrossRef] Mittal, P.; Singh,
    R.; Sharma, A. Deep learning-based object detection in low-altitude UAV datasets:
    A survey. Image Vis. Comput. 2020, 104, 104046. [Google Scholar] [CrossRef] Gao,
    P.; Lee, K.; Kuswidiyanto, L.W.; Yu, S.H.; Hu, K.; Liang, G.; Chen, Y.; Wang,
    W.; Liao, F.; Jeong, Y.S.; et al. Dynamic Beehive Detection and Tracking System
    Based on YOLO V5 and Unmanned Aerial Vehicle. J. Biosyst. Eng. 2022, 47, 510–520.
    [Google Scholar] [CrossRef] Hassler, S.C.; Baysal-Gurel, F. Unmanned aircraft
    system (UAS) technology and applications in agriculture. Agronomy 2019, 9, 618.
    [Google Scholar] [CrossRef] Freitas, S.; Silva, H.; Almeida, J.; Silva, E. Hyperspectral
    imaging for real-time unmanned aerial vehicle maritime target detection. J. Intell.
    Robot. Syst. 2018, 90, 551–570. [Google Scholar] [CrossRef] Zhong, Y.; Hu, X.;
    Luo, C.; Wang, X.; Zhao, J.; Zhang, L. WHU-Hi: UAV-borne hyperspectral with high
    spatial resolution (H2) benchmark datasets and classifier for precise crop identification
    based on deep convolutional neural network with CRF. Remote Sens. Environ. 2020,
    250, 112012. [Google Scholar] [CrossRef] Melián, J.M.; Jiménez, A.; Díaz, M.;
    Morales, A.; Horstrand, P.; Guerra, R.; López, S.; López, J.F. Real-time hyperspectral
    data transmission for UAV-based acquisition platforms. Remote Sens. 2021, 13,
    850. [Google Scholar] [CrossRef] Hsu, C.C.; Lin, C.H.; Kao, C.H.; Lin, Y.C. DCSN:
    Deep compressed sensing network for efficient hyperspectral data transmission
    of miniaturized satellite. IEEE Trans. Geosci. Remote Sens. 2020, 59, 7773–7789.
    [Google Scholar] [CrossRef] Dua, Y.; Kumar, V.; Singh, R.S. Comprehensive review
    of hyperspectral image compression algorithms. Opt. Eng. 2020, 59, 090902. [Google
    Scholar] [CrossRef] Melián, J.; Díaz, M.; Morales, A.; Guerra, R.; López, S.;
    López, J.F. A Novel Data Reutilization Strategy for Real-Time Hyperspectral Image
    Compression. IEEE Geosci. Remote Sens. Lett. 2022, 19, 1–5. [Google Scholar] [CrossRef]
    Raúl, G.; Yubal, B.; María, D.; Lucana, S.; Sebastián, L.; Roberto, S. A New Algorithm
    for the On-Board Compression of Hyperspectral Images. Remote Sens. 2018, 10, 428.
    [Google Scholar] Hussain, A.J.; Al-Fayadh, A.; Radi, N. Image compression techniques:
    A survey in lossless and lossy algorithms. Neurocomputing 2018, 300, 44–69. [Google
    Scholar] [CrossRef] Reid, M.; Millar, R.J.; Black, N.D. Second-generation image
    coding: An overview. ACM Comput. Surv. CSUR 1997, 29, 3–29. [Google Scholar] [CrossRef]
    Hupel, T.; Stütz, P. Adopting Hyperspectral Anomaly Detection for Near Real-Time
    Camouflage Detection in Multispectral Imagery. Remote Sens. 2022, 14, 3755. [Google
    Scholar] [CrossRef] Umar, M.; Ferzund, J.; Sajjad, T.; Owais, S.M. Dealing Issues
    of Mobile Cloud Computing using 5G Technology. Int. J. Comput. Sci. Netw. Secur.
    2017, 17, 246–250. [Google Scholar] Ishtiaq, M.; Saeed, N.; Khan, M.A. Edge computing
    in IOT: A 6g perspective. arXiv 2021, arXiv:2111.08943. [Google Scholar] Chen,
    J.; Ran, X. Deep learning with edge computing: A review. Proc. IEEE 2019, 107,
    1655–1674. [Google Scholar] [CrossRef] Motlagh, N.H.; Bagaa, M.; Taleb, T. UAV-Based
    IoT Platform: A Crowd Surveillance Use Case. IEEE Commun. Mag. 2017, 55, 128–134.
    [Google Scholar] [CrossRef] Yang, J.; Chen, J.; Yang, Z. Energy-efficient UAV
    communication with trajectory optimization. In Proceedings of the 2021 2nd International
    Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)),
    Zhuhai, China, 24–26 September 2021; pp. 508–514. [Google Scholar] Jiang, X.;
    Sheng, M.; Nan, Z.; Chengwen, X.; Weidang, L.; Xianbin, W. Green UAV communications
    for 6G: A survey. Chin. J. Aeronaut. 2022, 35, 19–34. [Google Scholar] [CrossRef]
    Wang, Y.; Zhao, J. Mobile Edge Computing, Metaverse, 6G Wireless Communications,
    Artificial Intelligence, and Blockchain: Survey and Their Convergence. arXiv 2022,
    arXiv:2209.14147. [Google Scholar] Huda, S.A.; Moh, S. Survey on computation offloading
    in UAV-Enabled mobile edge computing. J. Netw. Comput. Appl. 2022, 201, 103341.
    [Google Scholar] [CrossRef] Sacco, A.; Esposito, F.; Marchetto, G. Resource Inference
    for Sustainable and Responsive Task Offloading in Challenged Edge Networks. IEEE
    Trans. Green Commun. Netw. 2021, 5, 1114–1127. [Google Scholar] [CrossRef] Gale,
    T.; Elsen, E.; Hooker, S. The State of Sparsity in Deep Neural Networks. arXiv
    2019, arXiv:1902.09574. [Google Scholar] Augasta, M.; Kathirvalavakumar, T. Pruning
    algorithms of neural networks—A comparative study. Open Comput. Sci. 2013, 3,
    105–115. [Google Scholar] [CrossRef] Blalock, D.; Gonzalez Ortiz, J.J.; Frankle,
    J.; Guttag, J. What is the state of neural network pruning? Proc. Mach. Learn.
    Syst. 2020, 2, 129–146. [Google Scholar] Liang, T.; Glossner, J.; Wang, L.; Shi,
    S.; Zhang, X. Pruning and quantization for deep neural network acceleration: A
    survey. Neurocomputing 2021, 461, 370–403. [Google Scholar] [CrossRef] Cai, H.;
    Gan, C.; Wang, T.; Zhang, Z.; Han, S. Once-for-all: Train one network and specialize
    it for efficient deployment. arXiv 2019, arXiv:1908.09791. [Google Scholar] Xu,
    C.; Li, Q.; Zhou, Q.; Zhang, S.; Yu, D.; Ma, Y. Power Line-Guided Automatic Electric
    Transmission Line Inspection System. IEEE Trans. Instrum. Meas. 2022, 71, 1–18.
    [Google Scholar] [CrossRef] Zhou, Y.; Xu, C.; Dai, Y.; Feng, X.; Ma, Y.; Li, Q.
    Dual-view stereovision-guided automatic inspection system for overhead transmission
    line corridor. Remote Sens. 2022, 14, 4095. [Google Scholar] [CrossRef] Latif,
    G.; Alghazo, J.; Maheswar, R.; Vijayakumar, V.; Butt, M. Deep learning based intelligence
    cognitive vision drone for automatic plant diseases identification and spraying.
    J. Intell. Fuzzy Syst. 2020, 39, 8103–8114. [Google Scholar] [CrossRef] Deng,
    T.; Xu, X.; Ding, Z.; Xiao, X.; Zhu, M.; Peng, K. Automatic collaborative water
    surface coverage and cleaning strategy of UAV and USVs. Digit. Commun. Netw. 2022,
    in press. [Google Scholar] [CrossRef] Mammarella, M.; Comba, L.; Biglia, A.; Dabbene,
    F.; Gay, P. Cooperation of unmanned systems for agricultural applications: A case
    study in a vineyard. Biosyst. Eng. 2022, 223, 81–102. [Google Scholar] [CrossRef]
    Li, L.; Cheng, L.; Li, X.; Yue, L.; Zhang, H. Research on Multi Machine Cooperative
    Autonomous Inspection Strategy for UHV Dense Transmission Channel Based on 5G
    Technology. J. Sensors 2022, 2022, 8524817. [Google Scholar] [CrossRef] Chen,
    X.; Tang, J.; Lao, S. Review of unmanned aerial vehicle swarm communication architectures
    and routing protocols. Appl. Sci. 2020, 10, 3661. [Google Scholar] [CrossRef]
    Chao, K.; Tao, L.; Li, M.; Guoyu, J.; yuchao, W.; Yu, Z. Construction and Application
    Research of Knowledge Graph in Spacecraft Launch. J. Phys. Conf. Ser. 2021, 1754,
    012180. [Google Scholar] [CrossRef] De Curtò, J.; de Zarzà, I.; Calafate, C.T.
    Semantic scene understanding with large language models on unmanned aerial vehicles.
    Drones 2023, 7, 114. [Google Scholar] [CrossRef] Alladi, T.; Chamola, V.; Sahu,
    N.; Guizani, M. Applications of blockchain in unmanned aerial vehicles: A review.
    Veh. Commun. 2020, 23, 100249. [Google Scholar] [CrossRef] Peltonen, E.; Bennis,
    M.; Capobianco, M.; Debbah, M.; Ding, A.; Gil-Castiñeira, F.; Jurmu, M.; Karvonen,
    T.; Kelanti, M.; Kliks, A. 6G white paper on edge intelligence. arXiv 2020, arXiv:2004.14850.
    [Google Scholar] Tomkos, I.; Klonidis, D.; Pikasis, E.; Theodoridis, S. Toward
    the 6G network era: Opportunities and challenges. IT Prof. 2020, 22, 34–38. [Google
    Scholar] [CrossRef] Chen, X.; Sheng, M.; Li, B.; Zhao, N. Survey on unmanned aerial
    vehicle communications for 6G. J. Electron. Inf. Technol. 2022, 44, 781–789. [Google
    Scholar] Disclaimer/Publisher’s Note: The statements, opinions and data contained
    in all publications are solely those of the individual author(s) and contributor(s)
    and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility
    for any injury to people or property resulting from any ideas, methods, instructions
    or products referred to in the content.  © 2023 by the authors. Licensee MDPI,
    Basel, Switzerland. This article is an open access article distributed under the
    terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Cao, Z.; Kooistra, L.; Wang, W.; Guo, L.; Valente,
    J. Real-Time Object Detection Based on UAV Remote Sensing: A Systematic Literature
    Review. Drones 2023, 7, 620. https://doi.org/10.3390/drones7100620 AMA Style Cao
    Z, Kooistra L, Wang W, Guo L, Valente J. Real-Time Object Detection Based on UAV
    Remote Sensing: A Systematic Literature Review. Drones. 2023; 7(10):620. https://doi.org/10.3390/drones7100620
    Chicago/Turabian Style Cao, Zhen, Lammert Kooistra, Wensheng Wang, Leifeng Guo,
    and João Valente. 2023. \"Real-Time Object Detection Based on UAV Remote Sensing:
    A Systematic Literature Review\" Drones 7, no. 10: 620. https://doi.org/10.3390/drones7100620
    Article Metrics Citations Crossref   1 Scopus   1 Google Scholar   [click to view]
    Article Access Statistics Article access statistics Article Views 28. Dec 7. Jan
    17. Jan 27. Jan 6. Feb 16. Feb 26. Feb 7. Mar 17. Mar 0k 1k 2k 3k 4k For more
    information on the journal statistics, click here. Multiple requests from the
    same IP address are counted as one view.   Drones, EISSN 2504-446X, Published
    by MDPI RSS Content Alert Further Information Article Processing Charges Pay an
    Invoice Open Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For
    Reviewers For Editors For Librarians For Publishers For Societies For Conference
    Organizers MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles
    Encyclopedia JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe
    to receive issue release notifications and newsletters from MDPI journals Select
    options Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated
    Disclaimer Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Drones
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Real-Time Object Detection Based on UAV Remote Sensing: A Systematic Literature
    Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Majumdar P.
  - Bhattacharya D.
  - Mitra S.
  - Bhushan B.
  citation_count: '8'
  description: Enabling technologies of Agriculture 4.0 such as IoT-driven Precision
    Agriculture (PA), Unmanned Aerial Vehicles (UAVs), and big data analytics are
    collaborating for the transformation of global agribusiness. In PA applications,
    IoT devices sense, collect, and transmit data to the cloud or edge for processing
    and processed data are stored in data centers. This exchange of a very large amount
    of information amongst billions of interconnected devices demands massive energy
    in PA applications. The growth of IoT devices is exponentially increasing directly
    or indirectly generating Green House Gases and causing energy deficiency in power-hungry
    IoT components like sensors. Thus, adopting green solutions is inevitable to promote
    energy-conserving, environment-friendly, and cost-effective IoT component designs.
    Inspired by achieving a green environment for IoT, we first give an overview of
    different data processing and energy-conserving strategies using machine learning,
    cloud computing, and edge computing. We then discuss and evaluate different Green
    IoT (GIoT) solutions that can be implemented for GIoT-based PA leveraging UAVs,
    Low Power Wide Area Networks (LPWANs), and 5G networks along with several implementation
    concerns. In addition, the sustainable progress towards Agriculture of 5.0 by
    integrating GIoT components is discussed to make the IoT greener using 5G networks
    and beyond. Based on the current survey, we have conceptualized a GIoT framework
    for designing energy-conserving, cost-effective, and environment-friendly PA applications
    while enabling ubiquitous connectivity. Finally, this paper systematically summarizes
    different security threats in GIoT layers and analyzes the measures that can be
    adopted to mitigate those threats in detail.
  doi: 10.1007/s11277-023-10521-1
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Wireless Personal Communications
    Article Application of Green IoT in Agriculture 4.0 and Beyond: Requirements,
    Challenges and Research Trends in the Era of 5G, LPWANs and Internet of UAV Things
    Published: 08 June 2023 Volume 131, pages 1767–1816, (2023) Cite this article
    Download PDF Access provided by University of Nebraska-Lincoln Wireless Personal
    Communications Aims and scope Submit manuscript Parijata Majumdar, Diptendu Bhattacharya,
    Sanjoy Mitra & Bharat Bhushan  567 Accesses 9 Citations Explore all metrics Abstract
    Enabling technologies of Agriculture 4.0 such as IoT-driven Precision Agriculture
    (PA), Unmanned Aerial Vehicles (UAVs), and big data analytics are collaborating
    for the transformation of global agribusiness. In PA applications, IoT devices
    sense, collect, and transmit data to the cloud or edge for processing and processed
    data are stored in data centers. This exchange of a very large amount of information
    amongst billions of interconnected devices demands massive energy in PA applications.
    The growth of IoT devices is exponentially increasing directly or indirectly generating
    Green House Gases and causing energy deficiency in power-hungry IoT components
    like sensors. Thus, adopting green solutions is inevitable to promote energy-conserving,
    environment-friendly, and cost-effective IoT component designs. Inspired by achieving
    a green environment for IoT, we first give an overview of different data processing
    and energy-conserving strategies using machine learning, cloud computing, and
    edge computing. We then discuss and evaluate different Green IoT (GIoT) solutions
    that can be implemented for GIoT-based PA leveraging UAVs, Low Power Wide Area
    Networks (LPWANs), and 5G networks along with several implementation concerns.
    In addition, the sustainable progress towards Agriculture of 5.0 by integrating
    GIoT components is discussed to make the IoT greener using 5G networks and beyond.
    Based on the current survey, we have conceptualized a GIoT framework for designing
    energy-conserving, cost-effective, and environment-friendly PA applications while
    enabling ubiquitous connectivity. Finally, this paper systematically summarizes
    different security threats in GIoT layers and analyzes the measures that can be
    adopted to mitigate those threats in detail. Similar content being viewed by others
    Artificial intelligence-based solutions for climate change: a review Article Open
    access 13 June 2023 IoT-enabled smart cities: a hybrid systematic analysis of
    key research areas, challenges, and recommendations for future direction Article
    Open access 12 March 2024 Recent advances in green technology and Industrial Revolution
    4.0 for a sustainable future Article 09 April 2022 1 Introduction Agriculture
    4.0 focuses on Precision Agriculture (PA) to replace traditional farming with
    smart farming through the introduction of modern, scalable, and automated technological
    solutions. The technological enablers of Agriculture 4.0 includes the Internet
    of Things (IoT), Big Data, Artificial Intelligence (AI), Cloud Computing, Remote
    Sensing, Unmanned Aerial Vehicles (UAVs), and the fifth generation (5G) network
    to deliver automated, predictive and reliable smart farming decisions [1]. The
    5G network supports advanced communication technologies which help in the widespread
    of IoT-based services in future generations [2, 3]. As agricultural practices
    involve the acquisition of large volumes of real-time weather data to be transmitted,
    processed, and stored for farmers to make time-sensitive decisions like irrigation
    scheduling, a lot of energy is consumed from IoT components such as sensors used
    for data acquisition, data transmission through communication protocols and data
    storage in cloud or edge, etc. Most of the IoT components emit greenhouses gases
    (GHGs) either directly or indirectly that are hazardous to the environment due
    to extreme device manufacturing, large shipments of those devices, overloading
    the data centers to serve millions of services, and heavy data traffic generated
    from billions of devices [4]. Promoting biodegradable IoT component designs with
    operational cost management and reduced power consumption can remarkably improve
    the efficiency of agricultural activities with little or no impact on the environment.
    PA applications relying on sensor-generated data for executing diverse applications
    necessitate the use of big data analytics coupled with Artificial Intelligence
    to perform intelligent analysis of these enormous data volumes associated with
    weather, soil, and crop characteristics. Wireless sensors employed for real-time
    weather data sensing facilitate and comprehend the intricate correlation of climate
    change and crop growth in real-time, decreasing the problem of environment parameter
    fluctuation and non-linearity in data acquisition when the agriculture field is
    located in a remote location. Among the widespread applications of PA, smart irrigation
    is gaining increasing attention because crop yield and farmland productivity are
    highly reliant on irrigation scheduling decisions that depend on environmental
    parameters like temperature, rainfall, etc. Traditional weather stations though
    help to determine the impact of climate change on crop yield but issues like the
    agriculture field being located in remote areas can cause weather data to fluctuate
    and data may become inconsistent. Unlike traditional weather stations, IoT-oriented
    agriculture practices are advantageous because real-time data can be acquired
    at any place and at any time through low-cost interconnected sensors transmitted
    to the cloud for storage through suitable communication protocols [5]. Despite
    the numerous advantages IoT offers in PA, the growing interconnection of IoT devices
    in PA is extremely power-consuming and generates GHGs that may lead to loss of
    soil fertility in agricultural land and also generates non-biodegradable solid
    and hazardous wastes from components like active Radio Frequency Identification
    (RFID) tags that could not be recycled easily posing threat to our environment
    [6]. An increasing number of IoT connections are energy intensive as huge data
    are transmitted and processed. Billions of batteries supporting energy-intensive
    IoT operations are also disposed of and replaced throughout the life cycle of
    these IoT devices. Combined global e-waste increased dramatically in 2016 which
    was 44.7 million metric tonnes an average of 6.1 kg/inh (kilograms per inhabitant)
    as compared to 5.8 kg/inh in 2014. However, only 20% (8.9 Mt) of total global
    e-waste is recycled globally. A report presented by Guardian Environment Network
    estimates that in the upcoming 10 years, 3.5% of the global carbon emissions will
    be coming from IoT devices [7]. Thus, the adoption of GreenIoT (GIoT) is inevitable
    to address the GHG emission problem from IoT components which in turn helps in
    better waste management through recycling due to biodegradable waste generation
    from components like passive RFID tags [6]. Design goals of GIoT include operating
    cost reduction and minimizing energy constraint issues of IoT components using
    renewable sources of energy and energy harvesting (EH) techniques and reducing
    the effects of GHGs emissions on the environment. To achieve this design goal,
    a plethora of green designs of hardware and software components are implemented
    that include Green Wireless Sensor Networks (GWSN), Green Radio frequency identification
    (GRFIDs) tags, Green Cloud Computing (GCC), and Green Datacenters (GDC), etc.
    to achieve maximum energy efficiency in all the stages namely, sensing, processing,
    transmitting and storing data [8]. Recently, UAVs emerged as a promising technique
    for intelligent monitoring of the agriculture field with considerable transmission
    power reduction and minimized environmental pollution unlike conventional IoT-based
    agriculture field monitoring techniques [6, 9]. As a result, this article provides
    an overall assessment of approaches for greening IoT leveraging UAVs to allow
    energy-saving, maintaining QoS, low-cost service delivery to vast regions, and
    mitigating the carbon footprint. Low-Power Wide Area Networks (LPWANs) are an
    alternative low-power communication protocol to traditional communication protocols
    that connects low-bandwidth, battery-powered IoT devices across large distances
    [10]. LPWANs support far-off communication using narrow-range communication channels
    for noise reduction [10, 11]. Earlier works based on energy-saving LPWANs are
    therefore also studied in detail in this paper. Algorithms based on Artificial
    Intelligence (AI) use methods to examine large volumes of data generated from
    IoT devices to provide value-added public services [12]. Intelligent processing
    can be done using Machine Learning (ML) algorithms to make time-sensitive, reliable,
    and accurate decisions for different PA tasks like irrigation scheduling to ensure
    crop yield with optimum utilization of water resources [13]. So, ML-based solutions
    for different PA tasks along with different energy management strategies are elaborated.
    The need for adopting 5G networks to meet low cost, low latency, and energy efficiency
    requirements of PA applications is also discussed for the sustainable transition
    from Agriculture 4.0 to Agriculture 5.0. IoT networks need to connect and establish
    communication links across numerous ubiquitous things, which generate a significant
    volume of data that is both vast and heterogeneous. Data processing by IoT devices
    themselves is constrained by their limited computational power and battery, which
    act as the device’s energy sources. Thus, it is necessary to use the cloud computing
    paradigm to process the data that IoT network devices create [14]. Processing
    the sensor-generated data transmitted using a large number of IoT communication
    protocols in the cloud or edge is also very energy intensive. Therefore, augmenting
    energy-saving solutions in the cloud or edge-based processing to process this
    enormous volume of data is also required to address the issue of energy consumption
    of the massive number of interconnected IoT components. Different energy-conserving
    strategies in machine learning, cloud computing, and edge computing-based data
    processing, therefore, need to be discussed in detail. Furthermore, the pros and
    cons of different energy-saving approaches adopted in GIoT and layer-specific
    security threats to GIoT systems are also discussed based on which avenues for
    future research in PA are presented. Based on the current survey, the main goal
    of our paper is to conceptualize a GIoT framework leveraging UAVs, LPWANs, and
    5G networks that meet the requirements of designing energy-aware, cost-effective,
    and environment-friendly PA applications for realizing the true potential of GIoT
    in PA while enabling ubiquitous connectivity. 1.1 Organization of the Paper The
    rest of the article is organized as follows. Section 2 describes the motivation
    and significance of the review. Section 3 describes IoT enablers and associated
    challenges. Section 4 describes green solutions for IoT Enablers and their implementation
    concerns. Data Processing techniques and different energy management strategies
    are described in Sect. 5. Section 6 describes different GIoT strategies leveraging
    Unmanned Aerial Vehicles (UAVs), Low Power Wide Area Networks (LPWANs), and 5G
    Networks. Section 7 explains the proposed GIoT Framework for Energy-Aware PA applications.
    Section 8 describes the different security attacks in different layers of GIoT
    and solutions to mitigate those threats. Section 9 concludes. Table 1 Energy saving
    methods for GIoT based smart PA design components Full size table 2 Motivation
    In PA applications, an enormous number of interconnected IoT devices communicate
    with one another to exchange huge volumes of weather data that directly or indirectly
    generate a lot of GHGs. These GHGs may result in loss of soil fertility in agricultural
    land hindering crop growth and yield. Thus, a significant reduction of environmental
    impacts on agricultural land must be ensured in terms of GHG emission reduction
    [4]. Adopting practices that minimize power usage and emissions without compromising
    system performance necessitates the use of GIoT. Conserving energy and reducing
    \\(\\text{CO}_{2}\\) emissions are the main obstacles in the implementation of
    a green environment. Numerous studies are working on creating green communication
    that minimizes harmful emissions (GHG), maximizes bandwidth usage, and consumes
    as little power as possible while maintaining the optimal performance of emerging
    IoT applications (such as PA). Adoption of green designs for IoT components can
    considerably reduce the environmental impacts of GHGs emissions on crop growth
    and yield by cutting down carbon emissions effectively. Furthermore, problems
    like the increasing number of power-hungry components in IoT interconnections,
    non-biodegradable dumping of non-recyclable waste generated from components like
    active RFID tags, energy-intensive computations of a huge volume of data in cloud
    or edge, operational costs incurred in an increasing number of interconnections
    of IoT components, overloaded data centers with enormous data traffic, etc. needs
    to be tackled successfully for leveraging the true potential of IoT in automation
    of PA tasks. All these factors have roused researchers for finding green solutions
    for IoT-based PA applications for designing low-cost and energy-efficient IoT
    components with minimal GHG emissions. To identify the significance of the paradigm
    shift of IoT to GIoT, we analyze different emerging trends like 5G networks and
    UAVs, etc. leveraging which energy-saving approaches can be designed to meet GIoT
    design goals. The suitability of LPWANs is also ascertained as a low power-consuming
    alternative to traditional communication protocols while providing wider coverage
    of agricultural land. Thus, this survey is envisioned to provide an organized
    assessment of existing GIoT-based PA solutions including 5G networks, UAVs, and
    LPWANs to provide farmers with a cost-effective, low-power consuming, environment-friendly,
    robust, and autonomous alternative to IoT-based PA solutions to replace traditional
    farming with smart green farming for sustainable progress towards Agriculture
    5.0 while ensuring ubiquitous connectivity in PA. Table 1 illustrates a few energy-saving
    methods implemented using GIoT-based smart PA design components. Fig. 1 Frequency
    of occurence of keyword Agriculture 4.0 in reputed journals Full size image Fig.
    2 Frequency of occurence of keyword Agriculture 5.0 in reputed journals Full size
    image Fig. 3 Frequency of occurence of keyword Green Cloud Computing(GCC) in reputed
    journals Full size image Fig. 4 Frequency of occurence of keyword Green Data Centers
    (GDC) in reputed journals Full size image 2.1 Keyword Analysis The keywords that
    have a significant correlation to green designs of IoT components in the PA field
    are analyzed that appeared in the title of the articles in reputed journal databases.
    The articles that appeared in Springer nature journals, Science Direct journals,
    and IEEE Xplore filtering the recently published papers in the last 4 years viz.,
    2019, 2020, 2021 to 2022 are illustrated. The links of reputed journal databases
    from where the significant keywords are searched are https://link.springer.com/,
    https://www.sciencedirect.com/, https://ieeexplore.ieee.org/Xplore/home.jsp. The
    keyword 5G appeared 2271, 2807, 4153, and 1571 times in Springer. The keyword
    5G appeared 1580, 1858, 2272, and 811 times in IEEE. The keyword 5G appeared 1019,
    1355, 1737, and 826 times in Science Direct. The keyword LPWANs appeared 23, 45,
    56, and 36 times in Springer. The keyword LPWANs appeared 32, 48, 58, and 31 times
    in IEEE. The keyword LPWANs appeared 498, 684, 731, and 352 times in Science Direct.
    The keyword Energy Efficiency and IoT appeared 769, 1261, 2239, and 947 times
    in Springer. The keyword Energy Efficiency and IoT appeared 217, 269,376, and
    155 times in IEEE. The keyword Energy Efficiency and IoT appeared 1243, 1633,
    2014, and 1007 times in Science Direct. The keyword UAV appeared 779, 1010, 1534,
    and 618 times in Springer. The keyword UAV appeared 635, 946, 1241, and 715 times
    in IEEE. The keyword UAV appeared 966, 1256, 1471, and 559 times in Science Direct.
    The keyword Agriculture 4.0 appeared 394, 480, 754, and 185 times in Springer.
    The keyword Agriculture 4.0 appeared 15, 7, 18, and 6 times in IEEE. The keyword
    Agriculture 4.0 appeared 498, 684, 731, and 355 times in Science Direct. Fig.
    5 Frequency of occurence of keyword Green Communication and Networking (GCN) in
    reputed journals Full size image Fig. 6 Frequency of occurence of keyword IoT
    and Green House Gases (GHG) in reputed journals Full size image Fig. 7 Frequency
    of occurence of keyword Green wireless Sensor Network(GWSN) in reputed journals
    Full size image Fig. 8 Frequency of occurence of keyword Green IoT in reputed
    journals Full size image The keyword Agriculture 5.0 appeared 119, 130, 412, and
    147 times in Springer. The keyword Agriculture 5.0 appeared 5, 4, 7, and 0 times
    in IEEE. The keyword Agriculture 5.0 appeared 466, 507, 643, and 324 times in
    Science Direct. The keyword Energy Efficiency and IoT appeared 29, 24, 32, and
    11 times in Springer. The keyword Energy Efficiency and IoT appeared 80, 51, 4,
    and 0 times in IEEE. The keyword Energy Efficiency and IoT appeared 57, 80, 52,
    and 24 times in Science Direct. The keyword IoT and GHGs appeared 36, 61, 128,
    and 65 times in Springer. The keyword IoT and GHGs appeared 27, 45, 53, and 39
    times in IEEE. The keyword IoT and GHGs appeared 117, 167, 250, and 164 in Science
    Direct. The keywords GDC appeared 3740, 4386, 5578, and 2472 times in Springer.
    The keyword GDC appeared 83, 91, 147, and 49 times in IEEE. The keyword GDC appeared
    in 7769, 9441, 12,209, and 6146 in Science Direct.The keyword GWSN appeared 435,
    518, 653, and 297 times in Springer. The keyword GWSN appeared 649, 750, 808,
    and 403 times in IEEE. The keyword GWSN appeared 427, 532, 606, and 300 in Science
    Direct.The keyword GCN appeared in 1990, 2310, 2961, and 1386 times in Springer.
    The keyword GCN appeared 2148, 2506, 3140, and 1494 times in IEEE. The keyword
    GCN appeared in 1476, 1720, 2236, and 1081 in Science Direct. The keyword GM2M
    appeared 3026, 3583, 4889, and 2387 times in Springer. The keyword GM2M appeared
    6243, 7610, 9799, and 4929 times in IEEE. The keyword GM2M appeared in 1476, 1720,
    2236, and 1081 in Science Direct.The keyword GRFID appeared 134, 126, 195, and
    83 times in Springer. The keyword GRFID appeared 111, 147, 171, and 81 times in
    IEEE. The keyword GRFID appeared in 207, 268, 314, and 148 in Science Direct.The
    keyword GCC appeared 719, 963, 1292, and 600 times in Springer. The keyword GCC
    appeared 873, 1053, 1224, and 605 times in IEEE. The keyword GCC appeared in 1653,
    1577, 1961, and 970 in Science Direct. Figures 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
    11, 12, 13 and 14 shows appearances of various keywords in reputed journal database.
    Fig. 9 Frequency of occurence of keyword Unmanned Aerial Vehicles (UAV) in reputed
    journals Full size image Fig. 10 Frequency of occurence of keyword Low Power Wide
    Area Networks (LPWANs) in reputed journals Full size image Fig. 11 Frequency of
    occurence of keyword Green Machine to Machine (GM2M) in reputed journals Full
    size image Fig. 12 Frequency of occurence of keyword Energy efficiency and IoT
    in reputed journals Full size image Fig. 13 Frequency of occurence of keyword
    5G in reputed journals Full size image Fig. 14 Frequency of occurence of keyword
    GRFID in reputed journals Full size image Fig. 15 Trends of Data Sent / Received,
    rate of energy consumption, data processing load and predicted number of connections
    Full size image 2.2 Ecological Impacts of IoT and Energy Saving Growing data traffic
    and boundless internet users are making the data centers exhausted. Figure 15
    portrays the approximate growth in data transmitted or received over the internet,
    energy consumption due to sensing, processing, and storing, and overburden on
    data centers due to increasing data traffic and predicted increasing number of
    connections from 2000 to 2021. Data traffic over the internet from 2010 to 2015
    ranges around 100 exabyte in 30 days (Eb/M) and can extend to 519 Eb/M with a
    growth rate of \\(31.58\\%\\) annually [20]. IoT components with exaggerated data
    traffic, data processing, and storage needs generate massive GHGs in the environment
    directly or indirectly. Worldwide internet traffic has risen 3 times from 2015
    to 2019 and can further raise in the current year, according to CISCO. Energy
    consumed from IoT components releases harmful \\(\\text{CO}_{2}\\) flinching from
    35.6 to 43.2 billion metric tons in 2040 [21]. Carbon footprint increased by 5
    times in the year 2020 due to the increasing use of servers in the IP-stimulated
    society [22]. Ample amount of data processing in the IoT network results in inflated
    power consumption and harms health and the environment due to the emission of
    GHGs as per the CISCO 2020 report. Reduction of GHGs emissions, renewable energy
    resources like solar energy usage, and recycling generated waste is the new criterion
    for the organizations. All IoT devices run on batteries, therefore conserving
    energy during data transmission is vital to increase the network’s operational
    time. Energy-hungry IoT devices can be categorized into three components [23]:
    (i) Power consumed by processor components. (ii) Power consumed during data collection
    and switching devices (ON/OFF) etc. (iii) Power consumed by communication protocols
    to enable communication. Sum total of power consumption can be expressed as [24]:
    $$\\begin{aligned} CP = TP + RP + SP + AP+ FP --GP \\end{aligned}$$ (1) where
    CP is consumed power, TP is Transmission Power consumption, RP is Data receiving
    Power consumption, SP is energy spent during data acquisition, AP is Power consumed
    during switching ON/OFF a device, FP is Fixed Power consumed from IoT devices
    and GP is Gain of Power from energy harvesting methods. The power requirement
    can be measured using an external measuring tool to get an overall idea of power
    consumption ignoring power consumption from individual components. Network simulators
    can be used to evaluate the power requirement used in modeling-based methods [25,
    26]. Figure 16 shows different applications of GIoT in PA to minimize cost and
    lessen power consumption while increasing automation and seamless connectivity
    of GIoT-based PA applications. Fig. 16 Applications of GIoT in PA Full size image
    Unlike traditional IoT, GIoT is an environment-friendly alternative that minimizes
    the adverse environmental impacts of computer hardware development and deconstruction
    while ensuring long-term environmental protection from hazardous GHG emissions.
    All the devices, communication networks, sensor systems, clouds, and the web collaborates
    to improve energy efficiency. Better allocation of resources while ensuring high
    performance, recyclable component designs, low latency and cost-effective data
    communication with extended device lifetime, optimal power saving through the
    usage of renewable energy resources and energy harvesting are all the advantages
    of GIoT over traditional IoT. 2.3 Significance of the Review The major significance
    of this review work is enumerated as follows: (i) The ecological impacts of IoT
    components and requirements of energy saving are explained. (ii) Green solutions
    in the form of GIoT enablers for minimizing power consumption of different power-hungry
    IoT components are evaluated in detail. (iii) Implementation concerns of GIoT,
    merits, and demerits of different energy-saving approaches adopted in GIoT are
    discussed in detail for realizing the true potential of GIoT in the implementation
    of PA applications while identifying major roadblocks. (iv) Data processing techniques
    and different energy management strategies are reviewed in detail to understand
    the need for the development of a GIoT framework suitable for energy-aware PA
    applications. (v) A GIoT framework based on GIoT enablers is conceptualized for
    designing cost-effective, energy-aware, and environment-friendly PA applications
    leveraging UAVs, LPWANs, and 5G networks. (vi) Layer-specific security issues
    of GIoT systems and the solutions to mitigate the vulnerability of security attacks
    are described for ensuring the security of GIoT systems. A comparative study of
    the existing work by different authors has been summarized in Table 2 by considering
    the following 12 criteria. 1: Ecological Impacts of IoT and energy saving; 2:
    IoT enablers and associated challenges; 3: Green solutions for IoT Enablers; 4:
    GIoT implementation concerns; 5: ML and Energy Management Strategies; 6: Cloud
    Computing and Energy Management Strategies; 7: Edge Computing and Energy Management
    Strategies; 8: GIoT solutions leveraging UAVs; 9: GIoT solutions leveraging LPWANs;
    10: GIoT solutions leveraging 5G networks; 11: Energy Management in 5G IoT; 12:
    GIoT implementation in Beyond 5G networks; 13: GIoT Framework for Energy-Aware
    PA applications; 14: Security Issues in GIoT and solutions. Here, “Yes” indicates
    that the topic has been covered in detail, “P” indicates that the topic has been
    partially covered, and “No” indicates that the topic has not been covered. From
    Table 2, it can be seen that the current review has addressed all the aspects
    of GIoT-based PA implementation concerns that are not addressed or partially addressed
    in the previous works. Table 2 Related Survey of GIoT based PA Full size table
    3 IoT Enablers and Associated Challenges The enabling technologies for IoT include
    RFID tags, cloud computing, internet, sensing networks, Machine to Machine (M2M),
    data centers and Communication Networks [6]. RFID tags minimize energy usage and
    radio costs during transmission. It uses tags for electronically marking goods
    in response to reader requests. RFID tags can be active and passive [6]. The active
    tags are fitted with a battery that boosts signal transmission. Passive tags use
    the induction principle that does not require batteries which makes the environment
    free from harmful toxic emissions from batteries. Hence, using passive tags is
    a biodegradable alternative as it generates renewable waste. In RFID tags, issues
    like overhearing and tag collisions must also be addressed very carefully [6,
    44]. Green Sensors offers a variety of low-power storage sensor nodes. It also
    aimed to improve energy efficiency, lengthen network life, eliminate relay nodes,
    and make the system cost-effective by efficiently employing resources. Persistent
    fulfillment of energy requirements for energy-constrained battery-operated IoT
    equipment is attainable by applying energy harvesting approaches using renewable
    energy sources. The power-hungry components of Datacenters (DC) are shown in Fig.
    17. Fig. 17 Power hungry components of datacenters [45] Full size image 4 Green
    Solutions for IoT Technology Enablers IoT components produce a significant amount
    of carbon footprint due to the use of scarce raw materials and their energy requirement
    in manufacturing, operating, and recycling processes. To tackle these issues,
    the Green IoT (G-IoT) paradigm comprising of designing green components has emerged
    as a research area of interest to mitigate such carbon footprint generation from
    IoT components. Different green solutions for IoT Technology Enablers are summarized
    here: 4.1 Green Wireless Sensor Networks To save energy from wireless sensors
    used for agriculture monitoring, specific sensing or peer-powering sensors should
    be used. Such techniques of efficient communication route forwarding between sensors
    and cloud systems recorded at the base station should be followed by sleep scheduling
    and compressed sensing. An effective load-balancing algorithm can also be used
    at the gateway nodes. Wireless sensors can also use resource allocator factor’s
    computation as a means of green wireless sensor networks (GWSN) [41]. Usually,
    sleep mode is activated for sensors to save energy, and greater power savings
    can only be attained by activating the WSNs only when data transmission is required
    [6]. 4.2 Green M2M Communication To save energy in M2M communication (GM2M), the
    transmission power can be intelligently adjusted, effective communication protocols
    can be designed, activity scheduling, collaborative energy-saving techniques,
    and energy harvesting (EH) must be used [41]. Energy Harvesting techniques may
    be used to capture energy directly from the environment like solar energy and
    wind energy etc. [46, 47]. 4.3 Green Radio Frequency Identification Tags RFID
    tags can be made greener by lowering the size and applying non-recyclable material
    during production [6]. Passive RFID tags that do not need batteries can be a promising
    green solution [44]. Techniques such as data aggregation, network coding, adaptive
    sampling, compression, routing with energy as a routing metric, and multipath
    routing are all green solutions to maximize energy saving in a GIoT environment
    [48, 41]. 4.4 Green Cloud Computing Green Cloud Computing (GCC) helps in both
    energy and cost reduction in the cloud by efficient allocation of cost-effective
    resources. Energy management strategies of green cloud such as Virtual Machine
    (VM) can be deployed to save energy by consolidation, relocation, placement, and
    allocation [49]. Energy-aware techniques such as renewable energy sources must
    be used to store data that can be easily replenished in nature which are cost-effective
    solutions [45]. Virtual machine (VM) migration and adaptive sampling are the communication
    techniques that can be used in green cloud [41, 44, 50]. 4.5 Green Data Centers
    Dynamic power allocation like dynamic voltage and frequency scaling, vary-on/vary-off
    are all useful for making Green Data Centers (GDC). Greening the IoT entails lowering
    energy while increasing the efficiency of automated connectivity among devices
    [6]. Duty cycling, compressive sensing, and cooperative relaying are all solutions
    that can be utilized to extend the battery life of data storage units [44]. The
    data reduction solution is concerned with lowering communication delays by aggregating
    data to reduce average data transfer rates and improve QoS [15]. Routing approaches
    aim to improve a network’s ability to handle data traffic by carefully selecting
    cluster heads throughout the data transfer process [15, 41]. 4.6 Green Internet
    and Communication Technology For energy saving in internet and communication technology
    (GICT) only the necessary data needs to be transmitted, the wireless data path’s
    overall length must be reduced and renewable green energy sources instead of non-renewable
    energy sources must be encouraged [41]. Figure 18 portrays a distinctive manifestation
    of green designs suggested for a paradigm shift from IoT to GIoT to ensure QoS
    in terms of saving energy, and cost, lowering latency in communication, prolonging
    the lifetime of IoT devices, and reducing GHG emissions to support green transmission
    and communication. Fig. 18 Paradigm shift from IoT to GIoT to adopt green designs
    for PA Full size image Several energy-saving techniques are adopted to implement
    GIoT. Wake-up radio is a scheme to reduce the idle listening period of sensors,
    which incurs extra power consumption for IoT-based data transmission components.
    The radio frequency (RF) energy harvesting mechanism keeps the wake-up radio in
    a deep sleep state which becomes active only after receiving an external RF signal
    to wake up the radio. This reduces the hardware requirement and signal processing
    to execute idle listening resulting in higher energy efficiency [51]. Duty cycling
    is another technique to reduce energy consumption which keeps the node in a sleep
    state most of the time and wakes up only at specific moments to increase the lifespan
    of nodes up to 5–10 years. The duty cycling technique is a trade-off between energy
    consumption and delays in data delivery to the target node. To overcome this delay
    problem, an additional wake-up radio channel can be used [52]. The energy consumption
    due to the sensor-generated data transmission is more than local data processing
    within the sensor node. The data aggregation mechanism conserves energy by eliminating
    redundant data transmission in dense sensors. Data aggregation is a process by
    which multiple similar packets are converted into a single packet. Several techniques
    like probability-based routing, mobility-based routing, cluster head communication,
    etc. can be used to improve latency, transmission power requirement, mobility,
    and network lifetime of sensors and other power-hungry data transmission components
    [53]. Since the number of sensors deployed to monitor an agriculture field is
    increasing, the need for new energy-saving mechanisms to reduce power consumption,
    cost, transmission delay, and network traffic is increasing. Compressed sensing
    is such an energy-saving mechanism to reduce power consumption, cost, transmission
    delay, and network traffic which shows that sparse signals and information in
    sensors can be exactly regenerated from very few random linear measurements. Figure
    19 describes the pros and cons of different energy-saving techniques adopted for
    the implementation of GIoT-based PA. Fig. 19 Pros and cons of different energy
    saving techniques adopted for GIoT based PA Full size image 4.7 Implementation
    Concerns of GIoT Based PA There are six primary implementation concerns to be
    resolved when creating a GIoT-based PA solution viz., hardware, data analytics,
    maintenance, mobility, infrastructure, data security, and privacy [35]. These
    implementation concerns can be explained as follows: (i) Hardware concerns: Different
    types of sensors can be used in IoT-based PA applications. The selection of sensors
    and meters for IoT devices to be used in PA is a hardware concern. (ii) Data analytics
    concerns: It mainly concerns the application of predictive algorithms and machine
    learning or deep learning techniques in IoT-based sensor-generated data to obtain
    a nutritive solution for smart PA. (iii) Maintenance concerns: The primary concern
    is to utilize different regular sensors that monitors all IoT interconnected devices
    as these devices can be easily damaged in the agriculture field. (iv) Mobility
    concerns: The primary concern is the type of wireless communication link like
    4G, 5G, 6LowPan and LoRa used to establish the connection between different sensors
    that are distributed over a large agricultural area. (v) Infrastructure concerns:
    The primary concern is the installation and development of IoT networking architecture
    using technologies like fog computing, cloud computing, network virtualization,
    etc. (vi) Data security and privacy concerns: Adaption of GIoT-based agriculture
    may make the system more susceptible to security attack by an intruder raising
    new security concerns which necessitate more secure communications to be established
    in the smart agriculture filed. 5 Data Processing Techniques and Energy Management
    Because IoT devices lack the computational power to analyze the acquired data,
    ML can be used for extracting meaningful information insights to generate intelligent
    predictive decisions based on acquired sensor data. Cloud computing appears as
    a promising paradigm to deliver high-performance computing and large storage capacity
    to satisfy the pervasive requirement for data processing in IoT networks. Cloud
    computing allows battery-powered IoT devices to offload various functions (such
    as data cleansing, and redundancy elimination) to the cloud. Edge computing allows
    the workload to be offloaded from the cloud to a location closer to the data source
    at the edge of the network to be efficiently handled by the users. Machine Learning,
    Cloud, and Edge computing are summarized in this section responsible for energy-intensive
    data processing along with different energy management techniques. 5.1 Machine
    Learning and Energy Management Following are some pertinent research works in
    the field of PA using ML algorithms such as fertilizer prediction [54], weather
    monitoring [55,56,57], soil moisture monitoring [58, 59], soil moisture monitoring
    with blockchain-based security [60]. To adjust irrigation schedules in response
    to changing weather conditions, ML process a vast amount of weather data [55,
    57]. Fuzzy logic is also used for mathematical modeling of unpredictably varying
    weather parameters. Long periods of data surveillance and monitoring are required
    to assess the accuracy of fuzzy logic. For precision irrigation, constant updating
    of irrigation schedules is accomplished by comparing ideal weather patterns with
    changing weather patterns. Hard coding is avoided with ML, and continual updating
    is achievable by learning from past input data [13]. There has been a substantial
    amount of research on the use of ML to attain energy savings. Artificial intelligence
    (AI) is identified as a possible driver in the optimization of energy resources
    and ML is accelerating the growth of IoT interconnected devices [61]. Localized
    AI in edge computing will filter data so that only relevant data is transmitted
    to the cloud. As a result, there are significant bandwidth and data transmission
    cost savings [62]. ML models help CPUs of edge devices run more quickly and efficiently
    at higher speeds and lower power levels. Video games, smart speakers, drones,
    security cameras, wearable health monitors, etc. are some examples of edge AI-enabled
    technology [7]. A cloud-based data center with real-time power management and
    resource allocation is proposed in [63]. The power requirements of cooling systems
    and data centers are estimated. A community and cloud-based data center powered
    by green energy results in saving 15.09 % on energy costs. On a 4G and 5G network,
    the proposed cloud-based approach creates a communication link with power users.
    Energy-efficient unicast (EEU) and reliable unicast (RU) efficient routing algorithms
    between communicating nodes, as well as an energy model of each node energy consumption,
    were suggested in [64]. The amount of energy used at nodes depends on the software
    operations involved in message transmission, reception, and the number of transmission
    attempts made. The Ad-hoc On-Demand Distance Vector protocol is used to find the
    shortest path between the communication nodes, and the RU protocol is used to
    calculate the likelihood that messages will be delivered successfully over that
    path. The EEU protocol identifies a path between the source and the destination
    that uses the least amount of energy at the nodes along the way. The EEU protocol
    consumes the least amount of energy possible, whereas the RU protocol increases
    the likelihood of delivery. The topic-based data transfer protocol using the mobile
    publish-subscribe Fog computing model is proposed in [65]. An event-driven, context-aware
    distribution system is utilized to decrease the amount of data that is transmitted
    between IoT networks and servers. It can be seen that the protocol’s data traffic
    has been considerably lowered, and its delivery ratio has been considerably decreased.
    ML may be utilized in energy-saving IoT applications like smart energy management
    [66] and smart water management [67], to assist in minimizing energy use. Other
    research consolidates on economizing energy by transferring data more efficiently
    and lessening the number of transmitted packets [68]. In [69], the focus is on
    utilizing ML to achieve energy-efficient mobility. ML techniques are revealed
    to be an intriguing option that can be used in different aspects of energy conservation
    in IoT networks if the data attributes are known. To deal with energy supply variability
    and intermittency, a deep reinforcement learning-based energy scheduling was presented
    in [70]. With the incorporation of ML algorithms to automate complex tasks and
    increase the overall system level of intelligence, UAV-based network performance
    can be significantly improved. Some of the existing works where ML algorithms
    are employed in conjunction with UAVs are summarized here. By reducing UAV’s power
    consumption, authors of [71] determine the best position to deploy airborne base
    stations to offload terrestrial base stations. UAVs are placed momentarily by
    anticipating wireless network congestion based on ML rather than being needed
    to continuously shift their placements. Through a structured radio map in [72]
    the optimal allocation for UAVs operating as airborne base stations are determined.
    The authors suggest a joint clustering and regression problem using a maximum
    likelihood strategy which is created based on the K-segment ray-tracing model
    because of the diverse terrain and difficulties in utilizing such radio maps.
    To recreate the radio map, ML is employed to predict the channel. In [73] the
    best allocation for airborne base stations utilizing UAVs is determined. Traffic
    is downloaded using weighted expectation maximization utilizing ML algorithms.
    Contract theory is also used to verify that the downlink demand is fulfilled through
    the proper selection of UAVs for each hotspot. To enable motion prediction for
    a collection of heterogeneous flying UAVs, an unsupervised method has been developed
    in [74]. The algorithm is intended to categorize the network nodes according to
    their mobility attributes in addition to forecasting the future locations of the
    UAVs. According to [75], by predicting the UAV’s location based on its previous
    locations, the communication efficiency between a UAV and a base station can be
    increased. The problem is that a UAV can experience wind perturbation when offloading
    a terrestrial base station, which might cause some offset and hence a reduction
    in capacity. The authors suggest a Recurrent Neural Network-assisted architecture
    to address this problem, in which the upcoming elevation and horizontal angles
    of the UAV concerning the base station are forecasted based on past angles. So,
    it is possible to forecast the precise location of a UAV which is moving at high
    speed. ML has been successfully integrated with UAV for energy savings [42]. 5.2
    Cloud Computing and Energy Management Although it may be advantageous to use this
    technology, it is widely known that cloud servers, which host cloud applications,
    consume a lot of energy. As a result, it is vital to limit energy exhaustion in
    cloud-based data processing by effective utilization of its resources. The authors
    of [76] presented a method for dividing an application into off-loadable and non-off-loadable
    components to reduce energy usage and execution time. This approach necessitates
    a high level of network dependability to assure the application’s functionality
    and availability. The authors developed an ant system for dynamic virtual machine
    placement in [77], which minimizes the number of active physical machines while
    also lowering the data center’s overall energy usage. Virtual machines can be
    transferred from one physical machine to another using dynamic virtual machine
    placement. As a result, security techniques should be used during relocation to
    secure sensitive data from attacks by intruders. A virtual machine placement method
    in [78] is proposed to reduce the number of active physical machines and their
    energy usage while also balancing the load amongst them. This method, however,
    uses a static virtual machine placement, which implies that once a virtual machine
    is created, it cannot be moved to another real computer. Energy-aware routing
    algorithms help to improve the network lifetime of sensor nodes as well as QoS
    even in the uneven distribution of traffic load. Co-operative relay solves the
    problem of high spectrum needs, reducing response time and allowing devices to
    consume less energy during transmission. Fig. 20 Energy management in cloud, fog
    and edge computing Full size image 5.3 Edge Computing and Energy Management Edge
    computing solutions have emerged as an appealing solution for energy management
    in IoT because it bridges the gap between low-power devices’ limited processing
    capabilities and their computational demands. Edge computing enables the workload
    to be offloaded from the cloud to a location closer to the data source to be efficiently
    handled by the users. It allows users to download data from cloud services and
    upload data to IoT devices. As a result, it can lengthen the battery life of battery-powered
    IoT devices, reducing network traffic, enhancing bandwidth, improving privacy,
    and saving significant amounts of energy and communication time. In [79], focus
    is on compressing data acquired from the edge devices before transmission. The
    proposed approach is based on an error-bounded lossy compressor that is optimized
    for high-data production scenarios where the retrieved data generates the same
    classification accuracy as the compressed data. In [80], a reinforcement-learning-based
    offloading technique is suggested for IoT devices that harvest energy. According
    to their current battery level, the past radio transmission rate of each edge
    device, and the projected amount of collected energy, IoT devices choose an edge
    device and their offloading rate. A deep reinforcement-based offloading method
    is also included in this system to help speed up learning. Fog computing is a
    layer between the cloud and the edge. Where edge computing might send large streams
    of data directly to the cloud, fog computing can receive the data from the edge
    layer before it reaches the cloud and then selectively send relevant data. A fog
    environment places intelligence at the local area network (LAN) and transmits
    data from endpoints to the gateway, where it is then transmitted to sources for
    processing and return transmission. Figure 20 shows different energy management
    techniques in cloud, fog, and edge computing. Some other recent energy management
    techniques adopted using Machine learning, Cloud and Edge Computing are discussed
    in Table 3. Table 3 Other recent energy management techniques adopted using Machine
    learning, Cloud and Edge Computing Full size table 6 GIoT Strategies Leveraging
    Unmanned Aerial Vehicles (UAVs), Low Power Wide Area Networks (LPWANs) and 5G
    Networks The adoption of Unmanned Aerial Vehicles (UAVs) has revolutionized Agriculture
    4.0 by offering farmers major cost savings, reliable connectivity, enhanced efficiency,
    and increased profitability. In [90], UAV is regarded as a sink node in wireless
    communication to collect sensor data. In [91], low-power processing of data is
    performed using UAV. In [92], a Genetic Algorithm (GA) is applied to improve drone-assisted
    networks analyzing energy consumption and sensor density. Sensor nodes suffer
    from limited range, downtime battery constraints, communication range, storing,
    processing, and computing resources [93]. So the integration of UAVs and WSNs
    is required for energy-efficient data acquisition. Recent UAV-based energy-efficient
    approaches for greening IoT are described in Table 4. Figure 21 describes the
    reputed journal distribution of articles using UAVs for green PA. Fig. 21 Reputed
    journal distribution of articles using UAV for green PA Full size image Table
    4 Recent UAV based energy-efficient approaches to GIoT Full size table 6.1 GIoT
    Strategies Using UAVs and RFID for Greening of Things Diminishing tag size followed
    by energy-saving strategies are required to optimize the energy requirement of
    RFID [98]. The RFID and UAV can be combinedly employed as a powerful tools required
    to deliver service in large deployment use cases including PA applications. In
    [99] UAVs with indoor localization are done with RFID to achieve cost efficiency
    using radio-frequency shadowing. Hubbard et al. [100] has shown the enhancement
    of UAV’s battery lifetime. In [101], a feasibility analysis is done to recharge
    the multipurpose tags in UAVs for energy requirement optimization. A few recent
    works are listed in Table 5. Table 5 UAV techniques to green RFID Full size table
    6.1.1 UAV and WSN for Greening of Things In [104] \\(\\text{CO}_{2}\\) concentration
    is monitored during data collection by UAV and WSN combinedly. The authors of
    [105] utilize Particle Swarm Optimization (PSO) for analyzing data. UAV and WSN
    are combinedly and used for data gathering with low power [106]. UAVs are capable
    of managing duty cycling dynamically. Advantages include enhanced communication
    bandwidth, the energy required for data transmission, and an extended coverage
    area. The cooperation of WSN, UAVs, and RFID helps in energy saving, and local
    and cost-effective processing using clustering techniques and has the potential
    of making PA applications greener as shown in Fig. 22. Recent works in the above
    context are discussed in Table 6. Table 6 UAV techniques to green WSN Full size
    table Fig. 22 Energy saving of WSN and RFID using UAV Full size image 6.1.2 Review
    of UAV Applications and Key Innovations in PA Over the last few years, UAVs played
    a very important role in agriculture monitoring. It has widespread applications
    in PA including 3D crop modeling, weed management, crop yield enhancement, vegetation
    index extraction, field-level phenotyping, etc. Some of the contributions in PA
    utilizing green technology of UAV are summarized in Table 7. Table 7 Contributions
    in PA utilizing green technology of UAV Full size table Applications of UAVs in
    PA are seeing an emerging trend. Recently, UAVs in the field of PA are applied
    for soil Mapping, Geographical Information Systems, etc. Different types of UAVs
    based on technical specifications and payload are also discussed [117]. UAVs integrated
    with sensors for crop monitoring and UAV trajectories are also used for data acquisition.
    Consensus and symbolic aggregate approximation algorithms are used at the network
    level for data transmission [118]. UAV in PA is discussed in diverse fields of
    irrigation, fertilization, chemical applications, weed management, and disease
    detection [119] etc. 6.1.3 Energy Constraints in UAV and Solutions Battery constraints
    of UAVs having limited energy, the energy consumption of UAVs during data collection
    is a matter of concern. Placement of UAVs, limited flight time, path planning,
    and interference among communicating UAVs are some of the constraints in using
    UAVs [4]. Energy Harvesting (EH) is a potential direction to augment battery capacity.
    Some of the energy constraint issues and solutions of UAVs are pointed out in
    Table 8. Table 8 Energy constraints in UAV and solutions Full size table Fig.
    23 Paper distribution of LPWAN Full size image 6.2 LPWANs for GIoT Based PA Sensors
    have a limited amount of resources like memory, power, and computing [15]. LPWANs
    are designed to support GIoT applications with low power requirements while retaining
    service quality and providing long-range communications. Figure 23 shows the paper
    distribution of LPWAN technologies. Long-range communication is supported by LPWANs
    having fewer gateways and long battery life [10, 11]. Long-term monitoring is
    possible with LPWANs because it allows sensors to monitor data and then transmit
    those monitored data with minimal power consumption. LPWANs are well-suited for
    deployment in GIoT-based PA applications as these are cost-effective and energy-efficient.
    PA applications where on several occasions, it relies on uplink communication
    for long-range transmission with minimal energy usage, LoRa becomes a feasible
    choice in such a scenario. DASH7 is less preferred in PA applications where the
    communication range exceeds 2 km [10]. Sigfox and LoRa are better than NB (NarrowBand)-IoT,
    when battery life, power, and cost incurred, are considered. NB-IoT is less ideal
    in PA tasks as many farms lack Long-Term Evolution (LTE) cellular coverage which
    is expensive due to weak cellular signal [10]. NB-IoT has a poor level of interference
    immunity [11]. Table 9 shows the specification of different LPWAN techniques.
    Table 9 Specification of LPWANs Full size table It has been found that a LoRaWAN
    communication technology expands the opportunity to install a large and sophisticated
    wireless sensor network in a remote agricultural land of 10 km without being dependent
    on an LTE (4G/5G) or other backhaul networks, by increasing the communication
    range of an IoT network to over 10 km wirelessly [121]. In [122] NB-IoT is evaluated
    in the agricultural environment for field experiments. A Raspberry-based NB-IoT
    node is implemented in terrace, ground, underground and cellar conditions. In
    [123] low-cost sensor nodes are designed for Agro-intelligence IoT using LoRaWAN
    for smart farming applications. In [124] self-powered nodes are used for real-time
    soil health monitoring using LoRaWAN for effective data storage and analysis.
    In [125] a low-cost design is implemented for automated agricultural irrigation
    using both LoRa and Sigfox for the implementation of a cloud-based WSN. In [126]
    a low-cost WSN is implemented for real-time intruder detection and crop data acquisition.
    EnOcean sensors operating in energy harvesting mode and Sigfox-based data transmission
    are used for transmitting real-time agricultural data in the cloud. 6.3 Utility
    of 5G in GIoT and PA Applications To satisfy global goals of designing energy-efficient
    IoT devices, advancing towards 5G cellular systems is a solution for ubiquitous
    connectivity. 5G networks are a highly energy-saving alternative to existing communication
    networks. In [127], a frame structure is proposed for physical layer radio frame
    flexibly to specifically target IoT implementation for \\(5\\text{th}\\) generation
    (5G) networks choosing appropriate Guard Bands for Random Access Channels. It
    supports enormous connections along with bursty and small packet transmissions
    while meeting low-cost, low power, and low complexity operation requirements of
    GIoT. The proposed design is effective for handling transceiver distortions, cell
    implementation, inter-band, and inter-cell interference shown through simulation
    results. 5G can accommodate different transmission speeds, bandwidths, and service
    quality needs. It consists of massive IoT connectivity, improved mobile broadband,
    and vital communications. The 3GPP has improved the design of 5G networks in a
    variety of ways. Reduced transmission delays will result from faster response
    times and improved reliability. Low latency connectivity is essential for communicating
    devices in PA that performs critical tasks based on real-time sensor-generated
    data. For efficient PA applications, a private network can be used that consists
    of independent spectrum options including dedicated, shared, and unlicensed frequency
    bands to support diverse spectrum requirements of IoT applications that allow
    the saving of network resources by allowing network slices assigned for specific
    functions. Network slicing also assures higher security and reliability of data
    transmission. Low latency, high bandwidth connections support of 5G networks results
    in QoS improvement during real-time transmission of a massive volume of data [128,
    129]. Also, the cost per bit of data transmission is reduced to enhance the economic
    feasibility of the 5G network.5G can be used to provide home access to the internet
    using wireless technologies instead of depending on fixed lines as broadband is
    not available through fixed-line operators, especially in remote and rural areas.
    QoS benefits include data communication speeds with reduced cost per bit of data
    transmitted using broadband. 5G networks connect households in rural areas with
    add-on advantages of capacity bandwidth and higher speeds to support massive IoT
    interconnections. Energy harvesting and power management of different power-hungry
    IoT devices in the 5G era need special attention. In [29] UAV-based 5G design
    is implemented using ML algorithms that improve service delivery using multiple
    antennas. In [28] data aggregation in UAV networks is done to reduce the energy
    requirement of power-hungry IoT components. In [130] reliable link selection is
    done to transmit information with reduced co-channel interference, increasing
    Signal to Noise for energy efficiency. In [131] a clustering algorithm is proposed
    where a cluster is formed based on the signal strength received to minimize energy
    consumption. In [132] to overcome the underutilized spectrum and constrained battery
    capacity in GIoT devices, energy harvesting for judicious use of resources is
    utilized. In [18] energy management is done by reducing sensor data transmission
    with increased fault tolerance, reduced energy consumption, and improved device
    failure rate. In [133] adaptive network coding is used to boost transmission efficiency.
    In [38] Three-tier architecture is proposed to reduce energy requirements and
    signaling overhead. The 5G network’s IoT-based solution allows the automated operation
    of various unmanned agricultural devices during plowing, planting, and all the
    growth stages of the crop, resulting in environment-friendly and energy-efficient
    farming operations. Data analytics in PA applications consists of a set of methodologies
    that focuses on gaining actionable insights from a large volume of data [128].
    So, it has a high bandwidth requirement, minimal delay, and maximized throughput.
    Figure 24 shows the benefits of adopting 5G networks in PA for shifting towards
    Agriculture 5.0. In PA, the adoption of 5G networks provides energy efficiency
    and ultralow latency to maximize throughput and reduce downtime of communicating
    devices for gaining higher reliability in data transmission. The data transmission
    speed can be increased during Interactive Augmented and Virtual Reality applications
    with reduced delay from multiple data transmission sources using virtual consultation
    and predictive maintenance services. AI-driven robots can also be utilized to
    achieve data transmission with reduced delay. For real-time monitoring, Machine-type
    communications with long-term evolution and narrowband IoT are paving the way
    for 5G integration in the future. It is used to connect numerous sensors to a
    single cellular tower, allowing farmers to set up more IoT devices to perform
    multiple tasks proficiently. Wearable glasses and smartphones can provide useful
    information about crop, animal, and machinery statistics, weather updates, AI-powered
    disease identification for both plants and cattle, insect exposure, land assessment,
    and so on to implement Augmented Reality and Virtual Reality [134]. In [135] AI-powered
    robots are programmed for using Global Positioning System to plot a route and
    recognize fruits and vegetables that are ripe to harvest. Fig. 24 Adoption of
    5G networks for shifting towards Agriculture 5.0 Full size image 6.3.1 Energy
    Management in 5G IoT Several studies in the literature have emphasized the necessity
    of energy efficiency in 5G networks. In [136] a comprehensive survey is done on
    energy-efficient cellular networks and a spectrum-sharing solution is designed
    for IoT networks with long battery life. In [137] an overview of energy-efficient
    strategies for 5G networks is delivered including resource allocation, network
    planning, network implementation, and hardware solutions. An integrating and energy-efficient
    system model for 5G-IoT is proposed in [138] that utilizes a massive Multiple-Input
    and Multiple-Output (MIMO) scheme to substitute the single remote antenna and
    the Cellular Partition Zooming (CPZ) mechanism for reducing the distance between
    the communicating components and the number of routing devices. 6.4 Implementation
    of GIoT in Beyond 5G Networks Beyond 5G/6G Networks are already seeing an emerging
    trend to make IoT designs greener with low power consumption, and energy harvesting
    strategies. Phase shifting the reflector and using iterative beamforming to lower
    the access point transmission power is a new Intelligent reflector surface and
    Ambient Backscatter communication joint design approach stated in [139]. The NOMA
    strategy is used in conjunction with simultaneous wireless information and power
    transmission technique that allow relays to harvest energy from radio signals
    while also enhancing the sum rate of each IoT device as stated in [140]. For 6G-enabled
    IoT devices, in [36] a cluster-based green communication strategy is proposed.
    A hybrid whale-spotted hyena optimization algorithm is used to guarantee the energy-efficient
    operation of IoT networks which limits the use of a single device as a cluster
    head, decreases the complexity of cluster selection, and prolongs network life.
    Table 10 describes other recent GIoT strategies adopted leveraging UAV, LPWANs
    and 5G networks. Fig. 25 Proposed GIoT layered framework for energy-aware PA Full
    size image Table 10 Other recent GIoT strategies adopted leveraging UAV, LPWANs
    and 5G networks in GIoT Full size table 7 Proposed GIoT Framework for Energy-Aware
    PA Applications To reduce the environmental impacts of hazardous emissions from
    IoT components, a low-cost, low-energy-consuming framework of GIoT for energy-aware
    PA applications is proposed using ML for intelligent decision-making, as shown
    in Fig. 25. To address power consumption, operational cost management, and minimizing
    environmental degradation from millions of interconnected IoT devices, the suggested
    conceptual framework is divided into five layers which are described as follows:
    The green perception layer does self-organized sensing and load balancing where
    parameters are extracted from weather, soil, crops, etc. The sensor operates using
    dynamic sleep/wake-up, energy harvesting to extract power from renewable sources,
    radio optimization, and energy-efficient routing to minimize energy usage [41,
    44]. The green transport layer is used for data processing. Passive RFID Tags
    that are biodegradable must be used in the green transport layer to optimize tag
    estimation adjust dynamic power levels and prevent tag collision as well as overhearing
    problems [6, 44]. Dynamic power adjustment can be attained using green M2M communication
    and energy harvesting is required for dynamic resource allocation [44, 41, 45].
    The green processing layer is responsible for evaluating, processing, and allocating
    resources for data storage [44]. In the green processing layer, processing and
    analysis of data can be done using ML techniques for predictive decisions and
    energy saving can also be achieved using ML solutions. Incorporating ML at the
    network’s edge can be used to achieve declined communication latency, enhanced
    security, and energy efficiency [150]. Edge computing in PA helps to reduce bandwidth
    and optimize latency requirements by sending data to the network’s edge to reduce
    network overloading while retaining flexibility and QoS enhancements [151]. In
    addition, the edge computing nodes provide adequate computational capability and
    low data transmission time. After these data have been processed in the green
    processing layer, these data are communicated to devices at various levels as
    part of a full system model in the green network layer. GCC using virtual machine
    (VM) techniques such as VM consolidation, placement, allocation, and migration
    can be applied in PA to ensure energy efficiency [44, 47]. GDC uses dynamic power
    allocation and energy-aware routing strategies in PA [44]. GICT uses compressive
    sensing, data fusion, cooperative relaying, dynamic topology management as well
    as duty cycling as an energy-efficient metric to extend the battery life of IoT
    components [44, 152]. In the green application layer, data can be obtained after
    being processed in all the layers in the form of readymade applications in PA.
    Table 11 shows the layered architecture of GIoT components to furnish green alternatives
    for power-hungry IoT enablers. While wake-up radio is a non-demand ON/OFF scheduling
    scheme, duty cycling can be on-demand and asynchronous. As a result, wake-up radio
    systems can help to limit the amount of idle hearing and overhearing that duty-cycling
    can cause. But, wake-up radio systems have a restricted communication range and
    incur a high cost as well as there is a possibility for severe interference. Duty-cycling
    can also suffer from high sleep latency and data transmission latency, in addition
    to idle hearing and overhearing. Energy-efficient data collection systems are
    effective methods for lowering IoT energy consumption. Security and latency tribulations
    for data aggregation as well as the barely obtainable data sparsity in data compression
    are still issues that are required to be addressed. Here, MQTT and CoAP stand
    for Message Queuing Telemetry Transport and Constrained Application protocol.
    Table 11 Layered architecture of GIoT components Full size table 8 Security Issues
    in GIoT and Solutions Virtualization of workstations and data abstraction from
    a common physical server is used to build cloud-based IoT services. As a result,
    there is a risk of data theft when a VM communicates with its neighbors. SQL injection,
    malware injection, and man-in-the-middle attacks are all the vulnerable security
    threats to which cloud data are exposed [154]. Furthermore, Blockchain technology
    has recently emerged as a means of connecting billions of devices on IoT networks.
    Blockchain creates a secure mesh network that allows devices to communicate reliably,
    avoiding the risks associated with centralized servers. As the network grows in
    size and the number of devices increases, traditional computing techniques have
    a direct impact on overall energy consumption. In addition to other obstacles
    such as scalability, latency, energy consumption, and flexibility issues, traditional
    computing techniques poses privacy and trust concerns. The sensors used to sense
    environmental parameters in an open agriculture field are very vulnerable to security
    threats as the sensors cannot be monitored regularly. Also, the area where sensors
    are located is not monitored properly compared to the sensors deployed inside
    a metropolitan city and it is simple to add malicious nodes that can overhear
    the information exchanged or impose security threats like [35]. Vulnerabilities
    and weaknesses in applications, interfaces, network parts, and software designs
    pose several security concerns for which user access is limited by allowing authorized
    access only [155]. To combat security risks, effective encryption techniques,
    Intrusion Detection Systems (IDS) [156] and secure authentication schemes are
    required to be implemented. As a result, it might be stated that enhancing security
    strategies are essential such as trust management, communication security, communication
    privacy, and application security. Different security attacks specific to different
    layers of GIoT-based systems are shown in Fig. 26. Fig. 26 Security attacks on
    different layers of GIoT based systems Full size image 8.1 Attacks in Device Layer
    Different security attacks in Device Layer of GIoT based systems are as follows:
    (i) Booting Attacks: The built-in security features of a device are not used during
    the booting process, the intruder tries to invade the communicating device while
    it is rebooting [157]. (ii) Eavesdropping: The intruder gets access over a conversation
    happening between unprotected devices or networks and the information is stolen
    when sent or received for malicious activities. (iii) Sleep Deprivation Attacks:
    The intruder tries to consume all the available power of IoT devices through infinite
    looping or mischievously maximizes the power consumption to reduce IoT device
    lifetime resulting in denial of services due to power exhaustion of these IoT
    devices [158]. (iv) Malicious Code Injection: The intruder injects malicious codes
    into the memory of IoT devices to achieve control over the entire system that
    causes system malfunctioning [159]. 8.2 Attacks in Communication Layer Different
    security attacks in Communication Layer of GIoT based systems are as follows:
    (i) Man-in-the-Middle Attack: The intruder secretly listens to the conversation
    between two parties and gain access over the real-time data traffic [160]. (ii)
    Routing Attack: The intruder attempts to change the transmission path of the data
    transit. A sinkhole attack is a routing attack in which the attacker broadcasts
    a fake transmission path to the nodes to re-route their traffic through it to
    cause various DoS attacks [161]. (iii) Phishing Site Attack: The intruder sends
    deceitful communications to different users, which appears to be valid messages
    and somehow the user id and password are retrieved with minimum effort to attack
    the hacked IoT devices [162]. (iv) Dos Attack: The intruder floods the network
    with unnecessary traffic to make the device fail to respond to genuine user requests.
    Due to the dissimilar configurations of the IoT devices, DoS attack occurs [163].
    8.3 Attacks in Data Analytics Layer Different security attacks in Data Analytics
    Layer of GIoT based systems are as follows: (i) Signature Wrapping attack: Here
    the signature algorithm is altered by the intruder to retrieve the resources and
    alter its information [164]. (ii) Malware Injection and Flooding: Here the attacker
    transfuse malicious code or even a virtual machine onto the cloud to gain right
    to use user’s sensitive information to degrade its quality [165]. (iii) SQL Injection
    Attack: The intruder transfuse malicious codes into the system to retrieve all
    the information about the system to achieve control [166]. 8.4 Application Layer
    Different security attacks in Application Layer of GIoT based systems are as follows:
    (i) Secure onboarding: When a new sensor is used in the network it passes the
    encryption key through the gateways which are vulnerable to various security attacks.
    Then the intruder can crack through the system using the encryption keys [167].
    (ii) Malicious Code Attack: The intruder utilizes cross-site scripting to get
    into the system which results in corrupting and malfunctioning of the entire IoT
    system [168]. (iii) Reprogram Attacks: Here the intruder can change the device
    configurations if it is not protected sufficiently and can induce very harmful
    damages [169]. (iv) Data Thefts: When data is sent over the network there are
    greater likelihoods of data theft. A single fault in the system may cause the
    failure of the entire system [170]. Physical security design, authentication,
    and access control are the security measures to be adopted in the device layer.
    Identity management, secure routing protocols, and encryption can be used in the
    communication layer as security measures. Cloud security, secure identification,
    and anti-virus are the security measures to be adopted in the data analytics layer
    as security measures. Authentication encryption, security protocols, and privacy
    management can be used in the application layer as security measures. Intrusions
    are detected and implemented using several authentication and access control mechanisms
    like encryption mechanisms to protect systems against cyber attacks. Using data
    mining and machine learning approaches, it is possible to differentiate between
    normal and malicious attacks. The intrusion detection for GIoT-based PA as a software
    application will able to reveal different security threats posed to the GIoT systems
    [35]. The resource and energy-constrained IoT devices are not always able to meet
    the computational and power requirement needed in the processing of different
    encryption/decryption techniques and cryptographic solutions at the Device layer.
    Therefore, the design of compatible cryptographic protocols is a significant research
    opportunity for the implementation of GIoT-based PA applications. 9 Conclusion
    Various Agriculture 4.0 strategies such as IoT-driven PA, UAVs, and big data analytics
    are remarkably advantageous given the growing food needs of the rising global
    population and diminishing agricultural land. With the rising number of IoT interconnections
    in PA applications, energy requirement issues of power-hungry IoT components like
    sensors, RFID tags, etc. are also increasing. Furthermore, equipped with the power
    of automation in real-time data acquisition and seamless connectivity in PA tasks,
    IoT components directly or indirectly generate Green House Gases and causes energy
    depletion. So, adopting green designs of GIoT is inevitable to promote energy-conserving,
    environment-friendly, and cost-effective IoT component designs. This work comprehensively
    reviews the most recent utilities of GIoT in PA applications such as energy-efficient
    irrigation monitoring based on commonly observed environment parameters like non-linear
    changes in soil, weather, and crop data. To resolve the energy consumption problem
    of existing IoT technology enablers, the plethora of GIoT enablers like GRFID,
    GWSN, GCN, GDC, and GCC are reviewed in detail for meeting the GIoT design goals
    of energy-efficient, environment-friendly, and cost-effective component designs.
    The overview of different data processing and energy-conserving strategies using
    machine learning, cloud computing, and edge computing is extensively reviewed.
    Further, energy-saving approaches leveraging 5G networks, UAV technologies, and
    LPWANs are presented along with their pros and cons to realize the true potential
    of GIoT. The main goal of this detailed review work is to conceptualize a GIoT
    framework for designing an energy-efficient, cost-effective, and environment-friendly
    PA application utilizing GIoT components for realizing the paradigm shift from
    IoT to GIoT while enabling ubiquitous connectivity in PA. Besides, different security
    threats in each layer of GIoT networks and the measures that can be adopted to
    mitigate those threats are also reviewed. In the future, it is important to identify
    the security loopholes in designing GIoT devices to ensure security amongst heterogeneous
    energy-efficient communicating devices. Also, to leverage the full potential of
    UAV (for UAV flying to long distances and for long duration) in GIoT-based PA
    applications, it is crucial to design an efficient power distributed algorithm
    for real-time data processing, finding suitable techniques for efficient batteries,
    increased battery lifetime and energy harvesting. Besides every other aspect,
    this paper analyzes why GIoT-based techniques need to be adopted to ensure sustainable
    progress towards Agriculture 5.0 leveraging UAVs, LPWANs, and 5G network designs
    in PA with optimized energy-saving and minimized ecological impacts of IoT components
    while ensuring QoS and cost-effectiveness. Data Availibility Data sharing not
    applicable to this manuscript as no datasets were generated or analysed during
    the current study. Code Availability No codes are made available for sharing at
    present. References Zhai, Z., Martinez, J. F., Beltran, V., & Martinez, N. L.
    (2020). Decision support systems for agriculture 4.0: Survey and challenges. Computers
    and Electronics in Agriculture, 170, 105256. Google Scholar   Shafi, M., Molisch,
    A. F., Smith, P. J., Haustein, T., Zhu, P., De Silva, P., Tufvesson, F., Benjebbour,
    A., & Wunder, G. (2017). 5G: A tutorial overview of standards, trials, challenges,
    deployment, and practice. IEEE Journal on Selected Areas in Communications, 35(6),
    1201–1221. Google Scholar   Shafique, K., Khawaja, B. A., Sabir, F., Qazi, S.,
    & Mustaqim, M. (2020). Internet of things (IoT) for next-generation smart systems:
    A review of current challenges, future trends and prospects for emerging 5G-IoT
    scenarios. IEEE Access, 8, 23022–23040. Google Scholar   Popli, S., Jha, R. K.,
    & Jain, S. (2022). Green IoT: A short survey on technical evolution and techniques.
    Wireless Personal Communications, 123(1), 525–553. Google Scholar   Zhang, L.,
    Dabipi, I. K., & BrownJr, W. L. (2018). Internet of things applications for agriculture.
    Internet of Things A to Z: Technologies and Applications, 507–528. https://doi.org/10.1002/9781119456735.ch18
    Alsamhi, S. H., Ma, O., Ansari, M. S., & Almalki, F. A. (2019). Survey on collaborative
    smart drones and internet of things for improving smartness of smart cities. IEEE
    Access, 7, 128125–128152. Google Scholar   Albreem, M. A., Sheikh, A. M., Alsharif,
    M. H., Jusoh, M., & Yasin, M. N. (2021). Green internet of things (GIoT): Applications,
    practices, awareness, and challenges. IEEE Access, 9, 38833–38858. Google Scholar   Arshad,
    R., Zahoor, S., Shah, M. A., Wahid, A., & Yu, H. (2017). Green IoT: An investigation
    on energy saving practices for 2020 and beyond. IEEE Access, 5, 15667–15681. Google
    Scholar   Hernandez-Vega, J.-I., Varela, E. R., Romero, N. H., Hernandez-Santos,
    C., Cuevas, J. L. S., & Gorham, D. G. P. (2018). Internet of things (IoT) for
    monitoring air pollutants with an unmanned aerial vehicle (UAV) in a smart city.
    In Smart Technology (pp. 108–120). Springer Ayoub, W., Samhat, A. E., Nouvel,
    F., Mroue, M., & Prevotet, J. C. (2018). Internet of mobile things: Overview of
    LoRaWAN, DASH7, and NB-IoT in LPWANS standards and supported mobility. IEEE Communications
    Surveys and Tutorials, 21(2), 1561–1581. Google Scholar   Ismail, D., Rahman,
    M., & Saifullah, A. (2018). Low-power wide-area networks: Opportunities, challenges,
    and directions. In Proceedings of the workshop program of the 19th international
    conference on distributed computing and networking (pp. 1–6). Mohamed, E. (2020).
    The relation of artificial intelligence with internet of things: A survey. Journal
    of Cybersecurity and Information Management, 1(1), 24–30. Google Scholar   Mughees,
    A., Tahir, M., Sheikh, M. A., & Ahad, A. (2020). Towards energy efficient 5G networks
    using machine learning: Taxonomy, research challenges, and future research directions.
    IEEE Access, 8, 187498–187522. Google Scholar   Nan, Y., Li, W., Bao, W., Delicato,
    F. C., Pires, P. F., Dou, Y., & Zomaya, A. Y. (2017). Adaptive energy-aware computation
    offloading for cloud of things systems. IEEE Access, 5, 23947–23957. Google Scholar   Popli,
    S., Jha, R. K., & Jain, S. (2016). A survey on energy efficient narrowband internet
    of things (NBIoT): architecture, application and challenges. IEEE Access, 7, 16739–16776.
    Google Scholar   Adam, A. H., Tamilkodi, R., & Valli, M. K. (2019). Low-cost green
    power predictive farming using IoT and cloud computing. In Proceedings of international
    conference on vision towards emerging trends in communication and networking (ViTECoN)
    (pp. 1–5). IEEE. Dhall, R., & Agrawal, H. (2018). An improved energy efficient
    duty cycling algorithm for IoT based precision agriculture. Procedia Computer
    Science, 141, 135–142. Google Scholar   Said, O., Zafer-Al, M., & Tolba, A. (2020).
    Ems: An energy management scheme for green IoT environments. IEEE Access, 8, 44983–44998.
    Google Scholar   Mekala, M. S., & Viswanathan, P. (2020). (t, n): Sensor stipulation
    with THAM index for smart agriculture decision-making IoT system. Wireless Personal
    Communications, 111(3), 1909–1940. Google Scholar   Cao, X., Song, Z., Yang, B.,
    ElMossallamy, M. A., Qian, L., & Han, Z. (2019). A distributed ambient backscatter
    mac protocol for internet-of-things networks. IEEE Internet of Things Journal,
    7(2), 1488–1501. Google Scholar   Sharma, V., You, I., & Kumar, R. (2016). Energy
    efficient data dissemination in multi-UAV coordinated wireless sensor networks.
    Mobile Information Systems, 2016, 1–13. Choi, D. H., Kim, S. H., & Sung, D. K.
    (2014). Energy-efficient maneuvering and communication of a single UAV-based relay.
    IEEE Transactions on Aerospace and Electronic Systems, 50(3), 2320–2327. Google
    Scholar   Bejiga, M. B., Zeggada, A., Nouffidj, A., & Melgani, F. (2017). A convolutional
    neural network approach for assisting avalanche search and rescue operations with
    UAV imagery. Remote Sensing, 9(2), 100. Google Scholar   Tuyishimire, E., Bagula,
    A., Rekhis, S., & Boudriga, N. (2017). Cooperative data muling from ground sensors
    to base stations using UAVs. In IEEE symposium on computers and communications
    (ISCC) (pp. 35–41). Quaritsch, M., Kruggl, K., Wischounig-Strucl, D., Bhattacharya,
    S., Shah, M., & Rinner, B. (2010). Networked UAVs as aerial sensor network for
    disaster management applications. Elektrotechnik Informationstechnik, 127(3),
    56–63. Google Scholar   Ren, Y., Zhang, X., & Lu, G. (2020). The wireless solution
    to realize green IoT: Cellular networks with energy efficient and energy harvesting
    schemes. Energies, 13(22), 5875. Google Scholar   Brewster, C., Roussaki, I.,
    Kalatzis, N., Doolin, K., & Ellis, K. (2017). Iot in agriculture: Designing a
    Europe-wide large-scale pilot. IEEE Communications Magazine, 55(9), 26–33. Google
    Scholar   Wang, S., Garg, H., Lin, G., Kaddoum, J., & Alhamid, M. F. (2021). An
    intelligent UAV based data aggregation algorithm for 5G-enabled internet of things.
    Computer Networks, 185, 107628. Google Scholar   Kouhdaragh, V., Verde, F., Gelli,
    G., & Abouei, J. (2020). On the application of machine learning to the design
    of UAV-based 5G radio access networks. Electronics, 9(4), 689. Google Scholar   Ray,
    P. P. (2017). Internet of things for smart agriculture: Technologies, practices
    and future direction. AIS, 9(4), 395–420. Google Scholar   Tzounis, A., Katsoulas,
    N., Bartzanas, T., & Kittas, C. (2017). Internet of things in agriculture, recent
    advances and future challenges. Biosystems Engineering, 164, 31–48. Google Scholar   Elijah,
    O., Rahman, T. A., Orikumhi, I., Leow, C. Y., & Hindia, M. H. (2018). An overview
    of internet of things (IoT) and data analytics in agriculture: Benefits and challenges.
    IEEE Internet of Things Journal, 5(5), 3758–3773. Google Scholar   Khanna, A.,
    & Kaur, S. (2019). Evolution of internet of things (IoT) and its significant impact
    in the field of precision agriculture. Computers and Electronics in Agriculture,
    157, 218–231. Google Scholar   Ruan, J., Wang, Y., Chan, F. T., Hu, X., Zhao,
    M., Zhu, F., Shi, B., Shi, Y., & Lin, F. (2019). A life cycle framework of green
    IoT-based agriculture and its finance, operation, and management issues. IEEE
    Communications Magazine, 57(3), 90–96. Google Scholar   Ferrag, M. A., Shu, L.,
    Yang, X., Derhab, A., & Maglaras, L. (2020). Security and privacy for green IoT-based
    agriculture: Review, blockchain solutions, and challenges. IEEE Access, 8, 32031–32053.
    Google Scholar   Verma, S., Kaur, S., Khan, M. A., & Sehdev, P. S. (2020). Toward
    green communication in 6G-enabled massive internet of things. IEEE Internet of
    Things Journal, 8(7), 5408–5415. Google Scholar   Alsamhi, S. H., Ma, O., Ansari,
    M. S., & Meng, Q. (2018). Greening internet of things for smart everythings with
    a green-environment life: A survey and future prospects. arXiv. arXiv preprint
    arXiv:1805.00844 Lyu, X., Tian, H., Jiang, L., Vinel, A., Maharjan, S., Gjessing,
    S., & Zhang, Y. (2018). Selective offloading in mobile edge computing for the
    green internet of things. IEEE Network, 32(1), 54–60. Google Scholar   Gupta,
    V., Tripathi, S., & De, S. (2020). Green sensing and communication: A step towards
    sustainable IoT systems. Journal of the Indian Institute of Science, 100(2), 383–398.
    Google Scholar   Foubert, B., & Mitton, N. (2020). Long-range wireless radio technologies:
    A survey. Future Internet Journal, 12(1), 13. Google Scholar   Malik, A., & Kushwah,
    R. (2022). A survey on next generation IoT networks from green IoT perspective.
    International Journal of Wireless Information Networks, 29(1), 36–57. Google Scholar   Lahmeri,
    M. A., Kishk, M. A., Alouini, M. S., Kishk, M. A., & Alouini, M. S. (2021). Artificial
    intelligence for UAV-enabled wireless networks: A survey. IEEE Open Journal of
    the Communications Society, 2, 1015–1040. Google Scholar   Alsamhi, S. H., Afghah,
    F., Sahal, R., Hawbani, A., Al-qaness, M. A., Lee, B., & Guizani, M. (2021). Green
    internet of things using UAVs in B5G networks: A review of applications and strategies.
    AdHoc Networks, 117, 102505. Google Scholar   Zhu, C., Leung, V. C., Shu, L.,
    & Ngai, E. C. (2015). Green internet of things for smart world. IEEE Access, 3,
    2151–2162. Google Scholar   Dayarathna, M., Wen, Y., & Fan, R. (2016). Data center
    energy consumption modeling: A survey. IEEE Communications Surveys and Tutorials,
    18(1), 732–794. Google Scholar   Azevedo, J., & Santos, F. (2012). Energy harvesting
    from wind and water for autonomous wireless sensor nodes. IET Circuits, Devices
    and Systems, 6(6), 413–420. MathSciNet   Google Scholar   Shaikh, F. K., & Zeadally,
    S. (2016). Energy harvesting in wireless sensor networks: A comprehensive review.
    Renewable and Sustainable Energy Reviews, 55, 1041–1054. Google Scholar   Wang,
    J., Hu, C., & Liu, A. (2017). Comprehensive optimization of energy consumption
    and delay performance for green communication in internet of things. Mobile Information
    Systems. https://doi.org/10.1155/2017/3206160 Article   Google Scholar   Liu,
    X. F., Zhan, Z. H., & Zhang, J. (2017). An energy aware unified ant colony system
    for dynamic virtual machine placement in cloud computing. Energies, 10(5), 609.
    Google Scholar   Jayalath, J. M., Chathumali, E. J., Kothalawala, K. R., & Kuruwitaarachchi,
    N. (2019). Green cloud computing: a review on adoption of green-computing attributes
    and vendor specific implementations. In International research conference on smart
    computing and systems engineering (SCSE) (pp. 158–164). Bello, H., Xiaoping, Z.,
    Nordin, R., & Xin, J. (2019). Advances and opportunities in passive wake-up radios
    with wireless energy harvesting for the internet of things applications. Sensors,
    19(14), 3078. Google Scholar   Kozlowski, A., & Sosnowski, J. (2019). Energy efficiency
    trade-off between duty-cycling and wake-up radio techniques in IoT networks. Wireless
    Personal Communications, 107(4), 1951–1971. Google Scholar   Rawat, P., & Chauhan,
    S. (2021). Probability based cluster routing protocol for wireless sensor network.
    Journal of Ambient Intelligence and Humanized Computing, 12, 2065–2077. Google
    Scholar   Goldstein, A., Lior, F., Amit, M., Bohadana, S., Lutenberg, O., & Ravid,
    G. (2018). Applying machine learning on sensor data for irrigation recommendations:
    Revealing the agronomist’s tacit knowledge. Precision Agriculture Journal, 19(3),
    421–444. Google Scholar   Kumar, A., Surendra, A., Mohan, H., Valliappan, K. M.,
    & Kirthika, N. (2017). Internet of things based smart irrigation using regression
    algorithm. In Proceedings of international conference on intelligent computing,
    instrumentation and control technologies (ICICICT) (pp. 1652–1657). IEEE Mohapatra,
    A. G., Lenka, S. K., & Keswani, B. (2019). Neural network and fuzzy logic based
    smart DSS model for irrigation notification and control in precision agriculture.
    Proceedings of the National Academy of Sciences, India Section A: Physical Sciences,
    89(1), 67–76. Google Scholar   Keswani, B., Mohapatra, A., Keswani, P., Khanna,
    A., Gupta, D., & Rodrigues, J. (2020). Improving weather dependent zone specific
    irrigation control scheme in IoT and big data enabled self driven precision agriculture
    mechanism. Enterprise Information Systems Journal, 14(9–10), 1–22. Goap, A., Sharma,
    D., Shukla, A. K., & Rama-Krishna, C. (2018). An IoT based smart irrigation management
    system using machine learning and open source technologies. Computers and Electronics
    in Agriculture, 155, 41–49. Google Scholar   Vij, A., Singh, V., Jain, A., Bajaj,
    S., Bassi, A., & Sharma, A. (2020). Iot and machine learning approaches for automation
    of farm irrigation system. Procedia Computer Science, 167, 1250–1257. Google Scholar   Munir,
    M., Safdar, I., Sarwar, B., & Cheema, S. M. (2019). An intelligent and secure
    smart watering system using fuzzy logic and blockchain. Computers and Electrical
    Engineering Journal, 77, 109–119. Google Scholar   Cioffi, R., Travaglioni, M.,
    Piscitelli, G., Petrillo, A., & DeFelice, F. (2020). Artificial intelligence and
    machine learning applications in smart production: Progress, trends, and directions.
    Sustainability, 12(2), 492. Google Scholar   Remmert, H. (2020). Edge computing,
    artificial intelligence, machine learning and 5G. [https://www.digi.com/blog/post/edge-compute-artificial-intelligence-ml-5g]
    Mehmood, F., Hamza, M. A., Bukhsh, R., Javaid, N., Imran, M. I. U., Choudri, S.,
    & Ahmed, U. (2020). Green fog: Cost efficient real time power management service
    for green community. In Proceedings of the 14th international conference on complex,
    intelligent and software intensive systems (pp. 142–155). Cham: Springer. Sakai,
    R., Saito, T., Nakamura, S., Enokido, T., & Takizawa, M. (2020). Software-oriented
    routing protocol for energy-efficient wireless communications. In Proceedings
    of the 14th international conference on complex, intelligent and software intensive
    systems (pp. 1–11). Cham: Springer. Saito, T., Nakamura, S., Enokido, T., & Takizawa,
    M. (2020). A topic-based publish/subscribe system in a fog computing model for
    the IoT. InProceedings of the 14th international conference on complex, intelligent
    and software intensive systems (pp. 12–21). Cham: Springer. Sheikhi, A., Rayati,
    M., & Ranjbar, A. M. (2015). Energy hub optimal sizing in the smart grid; machine
    learning approach. In IEEE power and energy society innovative smart grid technologies
    conference (ISGT) (pp. 1–5). IEEE. Mounce, S. R., Pedraza, C., Jackson, T., Linford,
    P., & Boxall, J. B. (2015). Cloud based machine learning approaches for leakage
    assessment and management in smart water networks. Procedia Engineering, 119,
    43–52. Google Scholar   Lavassani, M., Forsstrom, S., Jennehag, U., & Zhang, T.
    (2018). Combining fog computing with sensor mote machine learning for industrial
    IoT. Sensors, 18(5), 1532. Google Scholar   Paris, L., & Anisi, M. H. (2019).
    An energy-efficient predictive model for object tracking sensor networks. In IEEE
    5th World Forum on Internet of Things (WF-IoT) (pp. 263–268). IEEE. Liu, Y., Yang,
    C., Jiang, L., Xie, S., & Zhang, Y. (2019). Intelligent edge computing for IoT-based
    energy management in smart cities. IEEE Network, 33(2), 111–117. Google Scholar   Zhang,
    Q., Mozaffari, M., Saad, W., Bennis, M., & Debbah, M. (2018) Machine learning
    for predictive on-demand deployment of UAVs for wireless communications. In IEEE
    global communications conference (GLOBECOM) (pp. 1–9). Chen, J., Yatnalli, U.,
    & Gesbert, D. (2017). Learning radio maps for UAV aided wireless networks: A segmented
    regression approach. In IEEE International Conference on Communications (ICC)
    (pp. 1–6). Zhang, Q., Saad, W., Bennis, M., Lu, X., Debbah, M., & Zuo, W. (2021).
    Predictive deployment of UAV base stations in wireless networks: Machine learning
    meets contract theory. IEEE Transactions on Wireless Communications, 20, 637–652.
    Google Scholar   Peng, H., Razi, A., Afghah, F., & Ashdown, J. (2018). A unified
    framework for joint mobility prediction and object profiling of drones in UAV
    networks. Journal of Communications and Networks, 20, 434–442. Google Scholar   Xiao,
    K., Zhao, J., He, Y., & Yu, S. (2019). Trajectory prediction of UAV in smart city
    using recurrent neural networks. In IEEE international conference on communications
    (ICC) (pp. 1–6). Kumari, R., & Kaushal, S. (2017). Energy efficient approach for
    applicationexecution in mobile cloud IoT environment. In Proceedings of the second
    international conference on internet of things, data and cloud computing (pp.
    1–8). Alharbi, F., Tian, Y. C., Tang, M., Zhang, W. Z., Peng, C., & Fei, M. (2019).
    An ant colony system for energy-efficient dynamic virtual machine placement in
    data centers. Expert Systems with Applications, 120, 228–238. Google Scholar   Gharehpasha,
    S., Masdari, M., & Jafarian, A. (2021). Virtual machine placement in cloud data
    centers using a hybrid multi-verse optimization algorithms. Artificial Intelligence
    Review, 54, 2221–2257. Azar, J., Makhoul, A., Barhamgi, M., & Couturier, R. (2019).
    An energy efficient IoT data compression approach for edge machine learning. Future
    Generation Computer Systems, 96, 168–175. Google Scholar   Min, M., Xiao, L.,
    Chen, Y., Cheng, P., Wu, D., & Zhuang, W. (2019). Learning based computation offloading
    for IoT devices with energy harvesting. IEEE Transactions on Vehicular Technology,
    68(2), 1930–1941. Google Scholar   Ye, Y., Azmat, F., Adenopo, I., Chen, Y., &
    Shi, R. (2021). RF energy modelling using machine learning for energy harvesting
    communications systems. International Journal of Communication Systems, 34, 4688.
    Google Scholar   Khan, Z. A., Hussain, T., & Baik, S. W. (2022). Boosting energy
    harvesting via deep learning-based renewable power generation prediction. Journal
    of King Saud University-Science, 34, 101815. Google Scholar   Chu, M., Liao, X.,
    Li, H., & Cui, S. (2019). Power control in energy harvesting multiple access system
    with reinforcement learning. IEEE Internet of Things Journal, 6, 9175–9186. Google
    Scholar   Zhang, Y., He, J., & Guo, S. (2018). Energy-efficient dynamic task offloading
    for energy harvesting mobile cloud computing. In 2018 IEEE international conference
    on networking, architecture and storage (NAS) (pp. 1–4). Singh, S., Sharma, P.
    K., Moon, S. Y., & Park, J. H. (2017). EH-GC: An efficient and secure architecture
    of energy harvesting green cloud infrastructure. Sustainability, 9, 673. Google
    Scholar   Kakati, S., Mazumdar, N., & Nag, A. (2022). Green cloud computing for
    IoT based smart applications. In Green mobile cloud computing (pp. 201–212). Cham:
    Springer International Publishing. Zhang, G., Zhang, W., Cao, Y., Li, D., & Wang,
    L. (2018). Energy-delay tradeoff for dynamic offloading in mobile-edge computing
    system with energy harvesting devices. IEEE Transactions on Industrial Informatics,
    14, 4642–4655. Google Scholar   Lu, M., Fu, G., Osman, N. B., & Konbr, U. (2021).
    Green energy harvesting strategies on edge-based urban computing in sustainable
    internet of things. Sustainable Cities and Society, 75, 103349. Google Scholar   Tang,
    Q., Xie, R., Yu, F. R., Huang, T., & Liu, Y. (2020). Decentralized computation
    offloading in IoT fog computing system with energy harvesting: A dec-POMDP approach.
    IEEE Internet of Things Journal, 7, 4898–4911. Google Scholar   Kim, Y., & Lee,
    T. J. (2017). Service area scheduling in a drone assisted network. In International
    conference on computational science and its applications (pp. 161–171). Springer.
    Carrio, A., Parez, C. S., Ramos, A. R., & Campoy, P. (2017). A review of deep
    learning methods and applications for unmanned aerial vehicles. Journal of Sensors,
    2, 1–13. Google Scholar   Yoo, S. J., Park, J. H., Kim, S. H., & Shrestha, A.
    (2016). Flying path optimization in UAV-assisted IoT sensor networks. ICT Express,
    2(3), 140–144. Google Scholar   Hawbani, A., Wang, X., Kuhlani, H., Ghannami,
    A., Farooq, M. U., & Al-Sharabi, Y. (2019). Extracting the overlapped sub-regions
    in wireless sensor networks. Wireless Networks, 25(8), 4705–4726. Google Scholar   Moradi,
    M., Bokani, A., & Hassan, J. (2020). Energy-efficient and QoS-aware UAV communication
    using reactive RF band allocation. In 30th International telecommunication networks
    and applications conference (ITNAC) (pp. 1–6). IEEE. Ahmed, S., Chowdhury, M.
    Z., & Jang, Y. M. (2021). Energy-efficient UAV-to-user scheduling to maximize
    throughput in wireless networks. IEEE Access, 8, 21215–21225. Google Scholar   Li,
    M., Cheng, N., Gao, J., Wang, Y., Zhao, L., & Shen, X. (2020). Energy-efficient
    UAV-assisted mobile edge computing: resource allocation and trajectory optimization.
    IEEE Transactions on Vehicular Technology, 69(3), 3424–3438. Google Scholar   Nguyen,
    A. N., Vo, V. N., So-In, C., & Ha, D. B. (2021). System performance analysis for
    an energy harvesting IoT system using a DF/AF UAV-enabled relay with downlink
    NOMA under Nakagami-m fading. Sensors, 21(1), 285. Google Scholar   Namboodiri,
    V., & Gao, L. (2009). Energy-aware tag anticollision protocols for RFID systems.
    IEEE Transactions on Mobile Computing, 9(1), 44–59. Google Scholar   Choi, J.
    S., Son, B. R., Kang, H. K., & Lee, D. H. (2012). Indoor localization of unmanned
    aerial vehicle based on passive UHF RFID systems. In 9th international conference
    on ubiquitous robots and ambient intelligence (URAI) (pp. 188–189). IEEE. Hubbard,
    B., Wang, H., Leasure, M., Ropp, T., Lofton, T., Hubbard, S., & Lin, S. (2015).
    Feasibility study of UAV use for RFID material tracking on construction sites.
    In 51st ASC annual international conference proceedings. Allegretti, M., & Bertoldo,
    S. (2015). Recharging RFID tags for environmental monitoring using UAVs: A feasibility
    analysis. Wireless Sensor Network, 7(2), 13. Google Scholar   Hubbard, B., Wang,
    H., & Leasure, M. (2016). Feasibility study of UAV use for RFID material tracking
    on construction sites. In Presented at the Proc. 51st ASC annual international
    conference proceedings College Station, TX, USA. Greco, G., Lucianaz, C., Bertoldo,
    S., & Allegretti, M. (2015). A solution for monitoring operations in harsh environment:
    A rfid reader for small UAV. In International conference on electromagnetics in
    advanced applications (ICEAA) (pp. 859–862). IEEE. Malaver, A., Motta, N., Corke,
    P., & Gonzalez, F. (2015). Development and integration of a solar powered unmanned
    aerial vehicle and a wireless sensor network to monitor greenhouse gases. Sensors,
    15(2), 4072–4096. Google Scholar   Ho, D. T., Grotli, E. I., Sujit, P., Johansen,
    T. A., & Sousa, J. B. (2015). Optimization of wireless sensor network and UAV
    data acquisition. Journal of Intelligent and Robotic Systems, 78(1), 159. Google
    Scholar   Moreno, C. A., Marin, R. B., Marco, A. M., & Nebra, R. C. (2017). Unmanned
    aerial vehicle based wireless sensor network for marine-coastal environment monitoring.
    Jornada de Jovenes Investigadores del, I3A, 5. Google Scholar   Zanjie, H., Hiroki,
    N., Nei, K., Fumie, O., Ryu, M., & Baohua, Z. (2014). Resource allocation for
    data gathering in UAV-aided wireless sensor networks. In Network infrastructure
    and digital content (ICNIDC), 4th IEEE international conference (pp. 11–16). Zhan,
    C., Zeng, Y., & Zhang, R. (2017). Energy-efficient data collection in UAV enabled
    wireless sensor network. IEEE Wireless Communications Letters, 7(3), 328–331.
    Google Scholar   Jawhar, I. H., Mohamed, N., Trabelsi, Z., & Al-Jaroodi, J. (2016).
    Architectures and strategies for efficient communication in wireless sensor networks
    using unmanned aerial vehicles. Unmanned Systems, 4(04), 289–305. Google Scholar   Horstrand,
    P., Guerra, R., Rodriguez, A., Diaz, M., Lopez, S., & Lopez, J. F. (2019). A UAV
    platform based on a hyperspectral sensor for image capturing and on-board processing.
    IEEE Access, 7, 66919–66938. Google Scholar   Bah, M. D., Dericquebourg, E., Hafiane,
    A., & Canals, R. (2018). Deep learning based classification system for identifying
    weeds using high-resolution UAV imagery (pp. 176–187). Cham: Springer. Google
    Scholar   Hassanein, M., & El-Sheimy, N. (2018). An efficient weed detection procedure
    using low-cost UAV imagery system for precision agriculture applications. In International
    archives of the photogrammetry: remote sensing & spatial information sciences.
    Spachos, P., & Gregori, S. (2019). Integration of wireless sensor networks and
    smart UAVs for precision viticulture. IEEE Internet Computing, 23(3), 8–16. Google
    Scholar   Carl, C., Landgraf, D., van der Maaten-Theunissen, M. T., Biber, M.
    P., & Pretzsch, H. (2017). Robinia pseudoacacia l. flowers analyzed by using an
    unmanned aerial vehicle (UAV). Remote Sensing, 9(11), 1091. Google Scholar   Faical,
    B. S., Costa, F. G., Pessin, G., Ueyama, J., Freitas, H., Colombo, A., Fini, P.
    H., Villas, L., Osorio, F. S., Vargas, P. A., & Braun, T. (2014). The use of unmanned
    aerial vehicles and wireless sensor networks for spraying pesticides. Journal
    of Systems Architecture, 60(4), 393–404. Google Scholar   Hassan, M. A., Yang,
    M., Rasheed, A., Yang, G., Reynolds, M., Xia, X., Xiao, Y., & He, Z. (2019). A
    rapid monitoring of NDVI across the wheat growth cycle for grain yield prediction
    using a multi-spectral UAV platform. Plant Science, 282, 95–103. Google Scholar   Radoglou-Grammatikis,
    P., Sarigiannidis, P., Lagkas, T., & Moscholios, I. (2020). A compilation of UAV
    applications for precision agriculture. Computer Networks, 172, 107148. Google
    Scholar   Popescu, D., Stoican, F., Stamatescu, G., Ichim, L., & Dragana, C. (2020).
    A compilation of UAV applications for precision agriculture. Sensors, 20, 817.
    Google Scholar   Boursianis, A. D., Papadopoulou, M. S., Diamantoulakis, P., LiopaTsakalidi,
    A., Barouchas, P., Salahas, G., Karagiannidis, G., Wan, S., & Goudos, S. K. (2020).
    Internet of things (IoT) and agricultural unmanned aerial vehicles (UAVs) in smartfarming:
    A comprehensive review. Internet of Things, 18, 100187. Google Scholar   Mekki,
    K., Bajic, E., Chaxel, F., & Fernand, M. (2019). A comparative study of LPWAN
    technologies for large-scale IoT deployment. ICT Express, 5(1), 1–7. Google Scholar   Islam,
    N., Ray, B., & Pasandideh, F. (2020). IoT based smart farming: Are the LPWAN technologies
    suitable for remote communication?. In IEEE international conference on smart
    internet of things (SmartIoT) (pp. 270–276). Valecce, G., Petruzzi, P., Strazzella,
    S., & Grieco, L. A. (2020). NB-IoT for smart agriculture: Experiments from the
    field. In International conference on control, decision and information technologies
    (pp. 71–75). Valente, A., Silva, S., Duarte, D., Cabral Pinto, F., & Soares, S.
    (2020). Low-cost LoRaWAN node for agro-intelligence IoT. Electronics, 9(6), 987.
    Google Scholar   Ramson, S. R. (2021). A self-powered, real-time, LoRaWAN IoT-based
    soil health monitoring system. IEEE Internet of Things Journal, 8, 9278–9293.
    Google Scholar   Fernandez-Ahumada, L. M., Ramirez-Faz, J., Torres-Romero, M.,
    & Lopez-Luque, R. (2019). Proposal for the design of monitoring and operating
    irrigation networks based on IoT, cloud computing and free hardware technologies.
    Sensors, 19, 2318. Google Scholar   Dai, J., & Sugano, M. (2019). Low-cost sensor
    network for collecting real-time data for agriculture by combining energy harvesting
    and LPWA technology. In IEEE Global humanitarian technology conference. Ijaz,
    A., Zhang, L., Grau, M., Mohamed, A., Vural, S., Quddus, A. U., Imran, M. A.,
    Foh, C. H., & Tafazolli, R. (2016). Enabling massive IoT in 5G and beyond systems:
    PHY radio frame design considerations. IEEE Access, 24(4), 3322–39. Google Scholar   Duan,
    L., & Xu, L. D. (2021). Data analytics in industry 4.0: A survey. Information
    Systems Frontiers. https://doi.org/10.1007/s10796-021-10190-0 Article   Google
    Scholar   Li, S., Iqbal, M., & Saxena, N. (2022). Future industry internet of
    things with zero-trust security. Information Systems Frontiers. https://doi.org/10.1007/s10796-021-10199-5
    Article   Google Scholar   Deng, D., Xia, J., Fan, L., & Li, X. (2020). Link selection
    in buffer-aided cooperative networks for green IoT. IEEE Access, 8, 30763–30771.
    Google Scholar   Din, S., Ahmad, A., Paul, A., & Rho, S. (2018). MGR: Multi-parameter
    green reliable communication for internet of things in 5G network. Journal of
    Parallel and Distributed Computing, 118, 34–45. Google Scholar   Na, Z., Wang,
    X., Shi, J., Liu, C., Liu, Y., & Gao, Z. (2020). Joint resource allocation for
    cognitive OFDM-NOMA systems with energy harvesting in green IoT. Ad Hoc Networks,
    107, 102221. Google Scholar   Li, J., Liu, Y., Zhang, Z., Ren, J., & Zhao, N.
    (2017). Towards green IoT networking: Performance optimization of network coding
    based communication and reliable storage. IEEE Access, 5, 8780–8791. Google Scholar   Garzon,
    J., Acevedo, J., Pavon, J., & Baldiris, S. (2020). Promoting eco-agritourism using
    an augmented reality-based educational resource: a case study of aquaponics. Interactive
    Learning Environments, 30(7), 1–15. Skvortsov, E. A., Skvortsova, E. G., Sandu,
    I. S., & Iovlev, G. A. (2018). Transition of agriculture to digital, intellectual
    and robotics technologies. EoR, 14(3), 1014–1028. Google Scholar   Gandotra, P.,
    Jha, R. K., & Jain, S. (2017). Green communication in next generation cellular
    networks: A survey. IEEE Access, 5, 11727–11758. Google Scholar   Buzzi, S., Chih-Lin,
    I., Klein, T. E., Poor, H. V., Yang, C., & Zappone, A. (2016). A survey of energy-efficient
    techniques for 5G networks and challenges ahead. IEEE Journal on Selected Areas
    in Communications, 34(4), 697–709. Google Scholar   Zhang, D., Zhou, Z., Mumtaz,
    S., Rodriguez, J., & Sato, T. (2017). One integrated energy efficiency proposal
    for 5G IoT communications. IEEE Internet of Things Journal, 3(6), 1346–1354. Google
    Scholar   Liu, Q., Sun, S., Wang, H., & Zhang, S. (2021). 6G green IoT network:
    Joint design of intelligent reflective surface and ambient backscatter communication.
    Wireless Communications and Mobile Computing, 2021, 1–10. Google Scholar   Amjad,
    M., Chughtai, O., Naeem, M., & Ejaz, W. (2021). SWIPT-assisted energy efficiency
    optimization in 5G/B5G cooperative IoT network. Energies, 14(9), 2515. Google
    Scholar   Pan, C., Ren, H., Deng, Y., Elkashlan, M., & Nallanathan, A. (2019).
    Joint blocklength and location optimization for URLLC-enabled UAV relay systems.
    IEEE Communications Letters, 23, 498–501. Google Scholar   Anand, A., deVeciana,
    G., & Shakkottai, S. (2020). Joint scheduling of URLLC and eMBB traffic in 5G
    wireless networks. IEEE/ACM Transactions on Networking, 28, 477–490. Google Scholar   She,
    C., Liu, C., Quek, T. Q., Yang, C., & Li, Y. (2019). Ultra-reliable and low-latency
    communications in unmanned aerial vehicle communication systems. IEEE Transactions
    on Communications, 67(5), 3768–3781. Google Scholar   Riva, C., & Zaim, A. H.
    (2023). A comparative study on energy harvesting battery-free lorawan sensor networks.
    Electrica, 23(1), 40–47. Google Scholar   Gleonec, P. D., Ardouin, J., Gautier,
    M., & Berder, O. (2021). Energy allocation for lorawan nodes with multi-source
    energy harvesting. Sensors, 21, 2874. Google Scholar   Delgado, C., Sanz, J. M.,
    & Famaey, J. (2019). On the feasibility of battery-less lorawan communications
    using energy harvesting. In Proceedings of IEEE global communications conference
    (GLOBECOM) (vol. 23, pp. 1–6). Waikoloa. Xu, J., Solmaz, G., Rahmatizadeh, R.,
    Turgut, D., & Boloni, L. (2016). Internet of things applications: Animal monitoring
    with unmanned aerial vehicle. arXiv preprint arXiv:1610.05287 Wang, X., Garg,
    S., Lin, H., Kaddoum, G., Hu, J., & Alhamid, M. F. (2021). An intelligent UAV
    based data aggregation algorithm for 5G-enabled internet of things. Computer Networks,
    185, 107628. Google Scholar   Shi, L., Jiang, Z., & Xu, S. (2021). Throughput-aware
    path planning for UAVs in D2D 5G networks. AdHoc Networks, 116, 102427. Google
    Scholar   Dawit, M., & Frisk, F. (2019) Edge machine learning for energy efficiency
    of resource constrained IoT devices. In SPWID: The Fifth international conference
    on smart portable, wearable, implantable and disability oriented devices and systems.
    O’Grady, M. J., Langton, D., & O’Hare, G. M. (2019). Edge computing: A tractable
    model for smart agriculture? Artificial Intelligence in Agriculture Journal, 3,
    42–51. Google Scholar   Baldi, M., & Ofek, Y. (2009). Time for a greener internet.
    In IEEE international conference on communications workshops, ICC Workshops (pp.
    1–6). IEEE. Tahiliani, V., & Mavuri, D. (2018). Green IoT systems: An energy efficient
    perspective. In Eleventh international conference on contemporary computing (IC3).
    IEEE. Phalaagae, P., Zungeru, A. M., Sigweni, B., Chuma, J. M., & Semong, T. (2020).
    Security challenges in IoT sensor networks Green internet of things sensor networks
    (pp. 83–96). Cham: Springer. Google Scholar   Jabbar, W. A., Alsibai, M. H., Amran,
    N. S., & Mahayadin, S. K. (2018). Design and implementation of IoT-based automation
    system for smart home. In Proceedings of International Symposium on Networks,
    Computers and Communications (ISNCC) (pp. 1–6). Bing, K., Fu, L., Zhuo, Y., &
    Yanlei, L. (2011). Design of an internet of things-based smart home system. In
    Proceedings of 2nd international conference on intelligent control and information
    processing (vol. 2, pp. 921–924). Lv, Z. (2020). Security of internet of things
    edge devices. Mahalakshmi, G., & Nadu, T. (2018). Denial of sleep attack detection
    using mobile agent in wireless sensors. International Journal for Research Trends
    and Innovation, 3(5), 139–149. Google Scholar   Gautam, S., Malik, A., Singh,
    N., & Kumar, S. (2019). Recent advances and countermeasures against various attacks
    in IoT environment. In 2019 2nd international conference on signal processing
    and communication (ICSPC (pp. 315–319). Cekerevac, Z., Dvorak, Z., Prigoda, L.,
    & Cekerevac, P. (2017). Internet of things and the man-in-themiddle attacks–security
    and economic risks. MEST, 5(2), 15–25. Google Scholar   Singh, K. J., & Kapoor,
    D. S. (2017). Create your own internet of things: A survey of IoT platforms. IEEE
    Consumer Electronics Magazine, 6(2), 57–68. Google Scholar   Gupta, K. S., & Jayant,
    K. P. (2010). A review study on phishing attack techniques for protecting the
    attacks. Globus-An International Journal of Management and IT, 10(2), 22–25. Google
    Scholar   Kim, H., Kang, E., Broman, D., & Lee, E. A. (2018). Resilient authentication
    and authorization for the internet of things (IoT) using edge computing. ACM Transactions
    on Internet Things, 1, 1–27. Google Scholar   Quasim, M. T. (2021). Challenges
    and applications of internet of things (IoT) in Saudi Arabia. Easy Chair Preprint,
    1–25. [https://easychair.org/publications/preprint_open/r2W4] Ravi, N., & Shalinie,
    S. M. (2020). Learning-driven detection and mitigation of DDoS attack in IoT via
    SDN-cloud architecture. IEEE Internet of Things Journal, 7(4), 3559–3570. Google
    Scholar   Zolanvari, M., Teixeira, M. A., Gupta, L., Khan, K. M., & Jain, R. (2019).
    Machine learning-based network vulnerability analysis of industrial internet of
    things. IEEE Internet of Things Journal, 6(4), 6822–6834. Google Scholar   Gupta,
    H., & Van-Oorschot, P. C. (2019). Onboarding and software update architecture
    for IoT devices. In 17th International conference on privacy, security and trust
    (PST), 8949023. Mahmoud, C., & Aouag, S. (2019). Security for internet of things:
    A state of the art on existing protocols and open research issues. In Proceedings
    of the 9th international conference on information systems and technologies (pp.
    1–6). Hind, M., Noura, O., Amine, K. M., & Sanae, M. (2020). Internet of things:
    Classification of attacks using ctm method. In Proceeding series: In ACM international
    conference. Li, W., Logenthiran, T., Phan, V. T., & Woo, W. L. (2019). A novel
    smart energy theft system (SETS) for IoT-based smart home. IEEE Internet of Things
    Journal, 6(3), 5531–5539. Google Scholar   Download references Acknowledgements
    The authors are grateful to all the staffs and Faculty Members of Computer Science
    and Engineering department of Tripura Institute of Technology, Agartala and National
    Institute of Technology, Agartala, India for providing smooth access to the computing
    resources under their custody. Author information Authors and Affiliations Department
    of Computer Science and Engineering, National Institute of Technology, Agartala,
    Jirania, Barjala, 799046, India Parijata Majumdar & Diptendu Bhattacharya Department
    of Computer Science and Engineering, Techno College of Engineering, Agartala,
    Maheshkhola, 799004, India Parijata Majumdar Department of Computer Science and
    Engineering, Tripura Institute of Technology, Agartala, Narsingarh, 799009, India
    Sanjoy Mitra Department of Computer Science and Engineering, School of Engineering
    and Technology, Sharda University, Greater Noida, Uttar Pradesh, 201310, India
    Bharat Bhushan Contributions Conceptualization of Idea of the Article: PM and
    SM. Literature Search and Data Analysis: SM and PM. Resources: DB and SM. Writing—Original
    Draft Preparation: PM and SM. Writing—Review and Editing: SM and PM and BB. Critical
    Revision of the Work: SM and BB. Visualization: PM and BB. Supervision: DB and
    SM. Overall Administration: DB and SM Corresponding author Correspondence to Sanjoy
    Mitra. Ethics declarations Conflict of interest The authors declare that they
    have no conflict of interest. Human and Animals Rights This review research is
    not having any involvement of Human Participants and/or Animals. Informed Consent
    Not applicable as no any involvement of human participants or any other living
    being. Additional information Publisher''s Note Springer Nature remains neutral
    with regard to jurisdictional claims in published maps and institutional affiliations.
    Rights and permissions Springer Nature or its licensor (e.g. a society or other
    partner) holds exclusive rights to this article under a publishing agreement with
    the author(s) or other rightsholder(s); author self-archiving of the accepted
    manuscript version of this article is solely governed by the terms of such publishing
    agreement and applicable law. Reprints and permissions About this article Cite
    this article Majumdar, P., Bhattacharya, D., Mitra, S. et al. Application of Green
    IoT in Agriculture 4.0 and Beyond: Requirements, Challenges and Research Trends
    in the Era of 5G, LPWANs and Internet of UAV Things. Wireless Pers Commun 131,
    1767–1816 (2023). https://doi.org/10.1007/s11277-023-10521-1 Download citation
    Accepted 18 May 2023 Published 08 June 2023 Issue Date August 2023 DOI https://doi.org/10.1007/s11277-023-10521-1
    Share this article Anyone you share the following link with will be able to read
    this content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Agriculture 4.0 Energy saving GIoT Internet of UAV things
    LPWANs 5G networks Use our pre-submission checklist Avoid common mistakes on your
    manuscript. Sections Figures References Abstract Introduction Motivation IoT Enablers
    and Associated Challenges Green Solutions for IoT Technology Enablers Data Processing
    Techniques and Energy Management GIoT Strategies Leveraging Unmanned Aerial Vehicles
    (UAVs), Low Power Wide Area Networks (LPWANs) and 5G Networks Proposed GIoT Framework
    for Energy-Aware PA Applications Security Issues in GIoT and Solutions Conclusion
    Data Availibility Code Availability References Acknowledgements Author information
    Ethics declarations Additional information Rights and permissions About this article
    Advertisement Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Wireless Personal Communications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Application of Green IoT in Agriculture 4.0 and Beyond: Requirements, Challenges
    and Research Trends in the Era of 5G, LPWANs and Internet of UAV Things'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Trollman H.
  - Jagtap S.
  - Trollman F.
  citation_count: '3'
  description: Global food supply chains are unprepared for the increasing number
    and severity of the expected environmental, social and economic shocks in the
    coming years. The price-setting process of commodities is directly impacted by
    such shocks, influencing consumer behavior regarding food choice and consumption.
    Both the market and advances in precision agriculture drive increased production
    and consumption. However, there has been a lack of consideration of how consumer
    behavior could be harnessed to mitigate such shocks through decreased consumption
    and reduced waste. The SAPPhIRE model of causality was applied to design sustainable
    and ecologically embedded futures derivatives that could have a role in affecting
    commodity markets. Multi-agent systems were combined with artificial intelligence
    and edge computing to provide the necessary functionality. The impact of war in
    Ukraine was used to exemplify the design of consumer “food choice” derivatives.
    This resulted in a mechanism to bring aggregated acts of consumer compassion and
    sustainability to commodities markets to mitigate food security shocks. When implementing
    food choice derivatives, care must be taken to ensure that consumer food choices
    are rational and compatible with individual nutritional needs and financial situations,
    and that the legitimate interests of agri-food businesses are protected.
  doi: 10.1007/s12571-023-01363-7
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Home Food Security Article Crowdsourcing
    food security: introducing food choice derivatives for sustainability Original
    Paper Open access Published: 26 April 2023 Volume 15, pages 953–965, (2023) Cite
    this article Download PDF You have full access to this open access article Food
    Security Aims and scope Submit manuscript Hana Trollman , Sandeep Jagtap & Frank
    Trollman   2365 Accesses 2 Citations Explore all metrics Abstract Global food
    supply chains are unprepared for the increasing number and severity of the expected
    environmental, social and economic shocks in the coming years. The price-setting
    process of commodities is directly impacted by such shocks, influencing consumer
    behavior regarding food choice and consumption. Both the market and advances in
    precision agriculture drive increased production and consumption. However, there
    has been a lack of consideration of how consumer behavior could be harnessed to
    mitigate such shocks through decreased consumption and reduced waste. The SAPPhIRE
    model of causality was applied to design sustainable and ecologically embedded
    futures derivatives that could have a role in affecting commodity markets. Multi-agent
    systems were combined with artificial intelligence and edge computing to provide
    the necessary functionality. The impact of war in Ukraine was used to exemplify
    the design of consumer “food choice” derivatives. This resulted in a mechanism
    to bring aggregated acts of consumer compassion and sustainability to commodities
    markets to mitigate food security shocks. When implementing food choice derivatives,
    care must be taken to ensure that consumer food choices are rational and compatible
    with individual nutritional needs and financial situations, and that the legitimate
    interests of agri-food businesses are protected. Similar content being viewed
    by others Review of the sustainability of food systems and transition using the
    Internet of Food Article Open access 09 October 2018 Sustainable Food Supply Chain
    Management: An Integrated Framework and Practical Perspectives Chapter © 2018
    Enabling artificial intelligence for sustainable food grain supply chains: an
    agri 5.0 and circular economy perspective Article 03 July 2023 1 Introduction
    Global food crises and their associated food price increases worsen food insecurity
    and drive people to reduce their food consumption (Gustafson, 2013; Suppan, 2008).
    Undernourished people are present in both developed and developing countries,
    making Sustainable Development Goal 2, which aims to achieve “zero hunger”, globally
    relevant and a key issue for policymakers. Factors such as increasing food demand
    in some countries, subsidies for biofuels, rising costs of cultivation, crop failure,
    reduced grain stockpiles and inadequate policy support for agriculture do not
    completely explain short-term food price rises (FAO, 2017). The relationship between
    food supply and demand is distorted by financial derivatives markets (Marquina,
    2013; Xuan et al., 2022), affecting the food security of nations. Disagreements
    exist among economists and policymakers about the role of commodity futures (food
    speculations) in the price hikes of 2007/mid-2008 and 2010/2011. Empirical results
    indicate that commodity futures have a negative impact on the food security of
    low-income countries, and financial crises exacerbate the negative effects of
    some commodity futures on food security for low-, middle- and high-income countries
    (Sosoo et al., 2021). The causal relationship between commodity futures and commodity
    prices remains under debate. The expectation has been that commodity speculation
    would be stabilizing, reducing the extent of commodity price variations, and that
    this would help farmers (producers) and processors hedge against short-term unfavorable
    price movements (Suppan, 2008). The market was expected to always be in backwardation
    (with the prices of futures contracts always lower than the prices of spot contracts).
    However, the phenomenon of price rise fluctuations of agricultural products is
    not adequately explained by traditional supply and demand theory (Aït-Youcef,
    2019; Algieri, 2016). Cereal-based supply chains may be described by a generic
    Input-Process-Output (IPO) model with five links: farms, storage areas, mills,
    food processing plants and consumers as the final actors (Carvalho et al., 2021).
    Advances in precision agriculture increase the yield and profitability of crops
    while reducing the resources necessary for cultivation (Van Evert et al., 2017;
    Zhang et al., 2002). Ollenburger et al. (2022) describe the challenges of realistically
    estimating crop yields for agro-economic modelling as they depend on both biophysical
    characteristics (e.g., soil, climate, etc.) and local crop management practices
    (e.g., mechanization, irrigation, crop cultivars). Consequently, even empirically
    based food speculation is unlikely to have a high degree of accuracy, becoming
    even less accurate in the presence of unforeseen food shocks. Assumptions about
    economic growth affect commodity market outlooks. For example, if China remains
    a strong grain importer, there could be a 4 to 25% increase in agricultural commodity
    prices compared to projections in the OECD-FAO Agricultural Outlook 2021–2030
    (Adenauer, 2022; Kavallari et al. 2014). Public buffer stocks are held by many
    countries for price stabilization and food security, but these are rarely effective
    (Beaujeu, 2016). To counter food insecurity, the establishment of an independent
    global buffer stock to create a food reserve has been proposed, but there are
    numerous obstacles to practical implementation, especially in the identification
    of appropriate price triggers (Gilbert, 2011; Tangermann, 2011; Wright, 2009).
    Other proposed solutions include the use of futures contracts or options (as well
    as forward contracting) as tools to manage price risks (e.g., Gilbert (2011),
    Sarris (2010), Sarris et al. (2010); Tangermann (2011)) or an International Grain
    Clearing Arrangement with the objective of guaranteeing grain import contracts
    between private and public agents (Sarris et al., 2010; Tangermann, 2011). Strictly
    financial interventions in commodity futures markets may lack sustainability considerations.
    Integrating environmental, economic, and social attributes has increased in popularity
    when selecting suppliers and sourcing processes (Azadnia et al., 2015; Ghadimi
    et al., 2018, 2019) which become part of price setting. A multi-agent system (MAS)
    has been proposed to support supplier selection based on supplier sustainability
    informed by a deep Q-learning agent for agricultural future market price forecasting
    (Pérez-Pons et al., 2021). Mechanisms for crowdsourcing societal tradeoffs as
    part of computational social choice have been proposed (Conitzer et al., 2015).
    A holistic consideration of solutions in terms of ecological embeddedness (benefits
    for economic actors and the environment) across the value chain would be desirable
    (Trollman & Colwill, 2020). This research employs a modified version of the SAPPhIRE
    model of causality (Chakrabarti et al., 2005) which includes virtual as well as
    physical considerations to design a food choice derivative that could counter
    negative commodity market fluctuations during periods of crisis. Constraints on
    the design include ecological embeddedness and sustainability considerations.
    The application of the design is exemplified on the case of Ukrainian wheat in
    regards to the invasion of Russian forces in February 2022. Proposed approaches
    to implementation are suggested based on crowdsourcing platforms. Few studies
    investigate economic motivations in consumer food choice (Martinho et al., 2022).
    Due to increased supply-side volatility as well as reduced willingness of wealthier
    households to reduce consumption in the face of shortages, commodity markets are
    likely to become more volatile in the future (Baldos & Hertel, 2015). Consumers
    are normally considered to be price-takers with economic motivations significantly
    affecting their behavior regarding food choice and subsequent food consumption
    (Martinho et al., 2022). In fact, nearly every market participant, producer or
    consumer, is a price-taker. The price-maker is the speculative positioning in
    the regulated futures markets - the collective actions of technical traders who
    buy on rising prices and sell on declining prices. Consequently, the question
    this research poses is: How can an alternative consumer-based price-making mechanism
    be introduced to the derivatives market to mitigate food speculation, improving
    food security and the sustainability of agricultural production? The sections
    below initially present the relevant background gathered to support the design
    phase (literature review), a description of the methodology, the results of the
    application of the design phase, and the exemplification of the selected case.
    2 Literature review - Supporting information for the design phase Agri-food systems
    are embedded in complex ecological, economic, and social processes through dynamic
    interactions that are vulnerable to short-term shocks and long-term stresses (Thompson
    & Scoones, 2009). Decreasing food waste would enable the more sustainable feeding
    of the world’s population. Research supports place-based solutions that are locally
    relevant to reducing household food waste in advancing sustainable food systems
    (Ahmed et al., 2021). 2.1 Cereals value chain A typical cereal value chain is
    shown in Fig. 1. However, this value chain does not capture agricultural wastes,
    co-products and by-products (AWCB) that are produced (Ćosić et al., 2016) or the
    amount of food wasted (Jeswani et al., 2021). Post-consumer food waste contributes
    more in terms of both quantity and environmental impact than other life cycle
    stages (primary production, food processing and distribution), however, these
    also have a significant impact. To release cereals for redistribution and minimize
    wastes, the grains need to be at the primary production stage (harvest and storage).
    Cereals that are milled and converted to ingredients have a shorter shelf life
    and added value that is not part of commodity markets. For ecological embeddedness,
    information about consumer food choice consequently needs to be communicated upstream
    to ensure that all the actors in the value chain can benefit. Fig. 1 Schematic
    representation of a “typical” cereal value chain. (adapted from Morell (2012))
    Full size image 2.2 Derivatives in agricultural production The derivatives market
    is for financial instruments such as contracts for futures, options, forwards
    and swaps whose value is derived from their underlying assets. Futures contracts
    involve both a right and obligation to carry out the contract as agreed, and are
    standardized, which means they are traded on exchange markets unlike other derivatives.
    Futures prices are the price of a commodity traded on a futures exchange representing
    a contract to pay a predetermined price at a set delivery date in the future.
    The price information for futures is collected from a range of global marketplaces.
    The extreme volatility in the price level of wheat results from a mix of factors
    including speculation, global demand, and real effective exchange rates with speculation
    being an important determinant of price dynamics (Algieri, 2016). Speculative
    activities often exceed the level required to offset unbalanced hedging, resulting
    in market destabilization (Algieri, 2016). Farmers risk losing money if the price
    of their crop falls before harvest and sale. Futures markets are an important
    source of price information for farmers although only a small percentage of farmers
    directly trade futures (Pérez-Pons et al., 2021). Farmers may minimize risk by
    selling futures contracts which guarantee the receipt of the predetermined price.
    In place of delivery, futures contracts may be liquidated by offsetting (selling
    the commodity locally on the spot market). Physical delivery is relatively rare
    as the contracts of buyers and sellers are counterbalanced. Hedging is beneficial
    to the economy because actors in the value chain such as farmers and millers have
    greater certainty about how much they will earn and pay for commodities. The participants
    in derivatives markets are hedgers, speculators, arbitrageurs, and margin traders.
    Speculators have no interest in actually selling or purchasing the physical commodity.
    Derivatives trading is complex so the general public mostly avoid participation.
    Farmers may use a grain merchant or co-op to access futures, or go directly to
    a futures broker. Relatively few brokers will manage individual accounts like
    those of farmers, and margin payments to cover exposure when the market moves
    unfavorably are required along with possible top-ups. For many small and marginal
    farmers, Farmer Producer Organizations (FPOs) can act to procure and aggregate
    commodities, ensuing that the size and quality standards required for agri-futures
    trade are met. India has set a target of creating 10,000 FPOs by 2024 (Chatterjee
    et al., 2019). Similarly, consumer participation in derivatives markets would
    need to be enabled through aggregation. 2.3 Food insecurity and consumer behavior
    With shocks such as extreme weather events predicted to significantly damage crops,
    corresponding increased commodity price volatility is anticipated (Baldos & Hertel,
    2015; Suppan, 2022). A strong incentive exists to shield urban consumers from
    world price spikes (Anderson et al., 2013) to avoid urban unrest. Food insecurity
    and dietary behaviors, including food choices and preparation methods, are infrequently
    examined in the literature. Food insecurity has been associated with lower nutrient
    intake and higher fat intake with lower frequency of fat-lowering behaviors (Mello
    et al., 2011). When food prices rise, the real incomes of urban, wage labor dependent
    households fall sharply, necessitating a cut to food consumption (Ahmed et al.,
    2009). For wealthier households, there may be diminished willingness to curb food
    consumption (Baldos & Hertel, 2015). The demand-induced scarcity of wheat flour
    and eggs during the Covid-19 pandemic in the United Kingdom (UK) indicated that
    consumers are creatures of habit, unlikely to make sustainable and nutritious
    substitutions or alternative food choices (Trollman et al., 2021) and options
    such as entomophagy remain stigmatized (Adegboye et al., 2021). Concurrently,
    effective evidence-based consumer food waste reduction strategies have been implemented
    in European countries (Parry et al., 2014; Schmidt, 2016). There is also evidence
    that consumers are willing to take additional action to reduce food waste (Ahmed
    et al., 2021). However, the relationship between voluntarily reduced consumption
    accompanied by temporary dietary change in support of food waste reduction for
    humanitarian purposes lacks investigation as there is no direct enabling mechanism.
    The design of such a mechanism is presented in the following sections. 3 Methods
    The overarching method used in this research is that of innovative abduction in
    design (Roozenburg, 1993), extended by Kroll & Koskela (2015, 2017). Abductive
    reasoning examines facts to suggest a theory by generating innovative ideas depending
    on recursive logic based on knowledge and the ability to analogically associate
    different domains (Calabrese & Costa, 2015). In engineering design, generating
    principal solutions is considered to be a crucial phase in the design process
    (the kernel of design). At the most basic level, the solution to a design problem
    comprises of a description of form and its actuation for a given purpose or outcome
    (Roozenburg, 1993). The purpose identified for this research was to design a financial
    instrument to counteract short-term market fluctuations caused by shocks to food
    security. Abduction-based futures research moves from closed, imaginary future
    states to alternative, open explanations (Patokorpi & Ahvenainen, 2009). Design
    research relies on basic research to develop technical norms which can be used
    to improve human activities. Futures studies are an instrument for design which
    tend towards systemic analysis when complexity is encountered. The solution to
    such problems may be seen as the identification of an opportunity, but opportunities
    typically cannot be recognized from inside or outside an existing framework. Futures
    research based on the abductive method breaks free of summary and collective knowledge
    which enables completely new futures designed not only from an existing state,
    but also via anomalies, imaginary explanations, and new theoretical frameworks
    (Patokorpi & Ahvenainen, 2009). The identification of novel or surprising findings
    is a key component of abduction which can then be used to extend, advance, or
    revise existing theories (Halpin & Richard, 2021). According to Tavory and Timmermans
    (2014), an abductive study should answer three questions: (1) Does the data fit
    the theory and/or conclusions? (2) Are the findings plausible, or is there another
    more plausible explanation? (3) If the findings are accurate, why do they matter?
    Answering the first question requires transparency in the collected information/data;
    the second question involves constantly interrogating the analysis, seeking alternative
    explanations, and relating these alternatives to the data; and finally, the third
    question is answered by connecting findings to previous studies and theory, and
    by demonstrating scope or generalizability. Abductive reasoning recognizes the
    role of the researcher as an unavoidable and essential element in the analytical
    dynamic between the researcher and the subject under study (Thomas, 2010) as part
    of a methodological approach that does not undermine, but enhances the research,
    particularly for case studies (Conaty, 2021). Case study research supports depth
    of interaction between the researcher and collected information, hence resonating
    with abduction as a methodological approach. In considering the “how” research
    question as part of the abductive process, the case study may be considered both
    descriptive and explanatory (Conaty, 2021). Studies based on a single case study,
    while facilitating phronesis and depth of understanding, are open to criticism
    for lack of generalizability; however, it has been argued that any weakness of
    case study due to generalizability fails to recognize both the limits of induction
    and to acknowledge the significance of abduction (Thomas, 2010). The researcher
    plays the important role of being an instrument of the method (Wa-Mbaleka, 2020)
    and the primary instrument of sensemaking for the study (Barrett, 2007). Function–behavior–structure
    models such as the SAPPhIRE model are intended to capture rich causal descriptions
    suitable for the purposes of researchers. The SAPPhIRE model is a generic model
    for representing causality of natural and artificial systems to help develop novel
    ideas to solve design problems, as illustrated by using databases of natural systems
    and artificial mechanical systems to describe various behaviors (Chakrabarti et
    al., 2005). The same behavior can be achieved and realized by different solution
    forms (Hubka & Eder, 2012) which rely on information from the databases. In this
    research, no databases exist for selecting mechanisms. Consequently, innovative
    abduction is employed. A modified version of the SAPPhIRE model of causality was
    applied to understand the behavior of financial derivatives and their role in
    affecting commodity markets. SAPPhIRE is a model of causality consisting of seven
    elementary constructs: States, Actions, Parts, Phenomena, Inputs, oRgans and Effects
    (Chakrabarti et al., 2005). The SAPPhIRE constructs were applied as part of a
    Five-step model of abduction (which in some cases may involve fewer steps when
    more constructs are combined) (Bhatt et al., 2021) as illustrated in Fig. 2. Fig.
    2 Five-step model of abduction incorporating the process framework of the abductive
    approach (Patokorpi & Ahvenainen, 2009) Full size image As noted by Bhatt et al.
    (2021), after the generation of the various constructs, the alternatives may be
    evaluated against given criteria (requirements) such as economic criteria. The
    requirements imposed in this research were sustainability and ecological embeddedness
    of the value chain, as described in the Introduction. Therefore, before the SaPPhIRE
    model was applied, the value chain for cereals was first described along with
    sustainability implications and routes to ecological embeddedness (Trollman et
    al., 2020) as found in the Literature Review. This corresponds to a first phase
    of Radical Innovation Design (RID), intended to provide an in-depth understanding
    of the current situation which is then followed by the design phase that generates
    new objects to improve the situation (Lamé et al., 2018). Finally, following the
    development of food choice derivatives in the design phase, a case example of
    the effect of the war in Ukraine on wheat intended for North Africa is presented
    to illustrate how the crowdsourcing of food security could be realized. The case
    approach method adopted follows Zucchella & Urban (2014) in that the abductive
    approach then tests the hypothesis on a case study. 4 Results 4.1 Application
    of the design phase – the SAPPhIRE model The application of SAPPhIRE in this research
    is constrained by sustainability and ecological embeddedness considerations for
    the value chain. For reasons of sustainability, increasing production to counter
    shocks to food security is infeasible over both the short-term (due to the time
    between sowing and harvest) and the longer-term (due to resource limits, biodiversity
    concerns and societal impacts). Consequently, efficiencies need to be found within
    the system e.g., food waste. For ecological embeddedness of the value chain, technology
    may be employed to facilitate the necessary information transfers to create benefits
    to both the economic actors and the environment. Examples of these benefits are
    described in the case study which follows. Step 1: Inference to State change The
    State is comprised of the attributes and values of attributes that define the
    properties of the system at a given moment of time. Input for one system may be
    a state change for another such that the viewpoints are created by system boundaries
    (Chakrabarti et al., 2005). The State in question corresponds to that of the futures
    commodity market (a dynamic state) as influenced by various attributes including
    speculation, global demand, and real effective exchange rates. Step 2: Inference
    to Phenomenon The Phenomenon is a set of potential changes associated with a physical
    effect for a given oRgan and Inputs. The Phenomenon is the countering of a shock
    to the system as may be caused by climate-related crop failure, labor shortages
    due to a pandemic and/or war in a globally important food producing nation. Step
    3: Inference to Effect The Effect reflects laws governing change. These may be
    laws of nature or constraints imposed by regulations. The Effect herein is moderation
    of commodity market fluctuations as governed by transactions on the commodity
    markets. Step 4: Inference to oRgan and Input An oRgan is a structural context
    necessary for an effect to be activated. Input is the information or material
    requirements to activate the Effect. The oRgan is the proposed food choice derivative.
    The Input is the information about the participation of consumers in creating
    the oRgan. Step 5: Inference to Part The Part is the set of physical components
    and interfaces constituting the system and its environment of interaction. Parts
    create or enable oRgans. In this case, Parts are the enablers of consumer food
    choices, e.g., the crowdsourcing platform aggregating decreased consumption and
    food waste reductions. 4.2 Case study: War in Ukraine Russia’s invasion of Ukraine
    is anticipated to cause a “perfect storm” of increased food prices leading to
    civil war across the developing world (Jagtap et al., 2022; Koren & Winecoff,
    2022). Ukraine produces about 6% of all food calories traded on the international
    market (Amis Market Monitor, 2022). Due to the invasion by Russian forces in February
    2022, Ukraine is expected to harvest less than half of the 80 MMT (million metric
    tonnes) of grain (wheat, corn and barley) produced in 2021. The affected July
    harvest of wheat in Ukraine results from planting in March and February with exports
    of about 16.7 MMT intended primarily for North Africa and South Asia (OEC, n.d.).
    Indonesia, Egypt, Pakistan, Bangladesh and Morocco (Reidy 2022) each expected
    over 1 MMT of Ukrainian wheat in 2022. Bread production globally is estimated
    at about 100 MMT per year of which 65% is consumed in Europe (Melikoglu & Webb,
    2013). About 25% of all bread in the Netherlands is wasted (about 800 thousand
    loaves every day) (Rietveld, 2019). In the UK, about half of the bread produced
    is wasted. The amount of bread wasted every day is about 1 million loaves (WRAP,
    2021) or about 500 MT of wheat per day (based on a loaf with 400 g of wheat flour
    made from 500 g of wheat). Therefore, if no bread was wasted in July 2022 (31
    days) in the UK, about 15,500 MT of wheat could be added to global commodity markets.
    This is sufficient to trade on wheat futures exchanges (Chicago Board of Trade
    (CBOT) and NYSE Euronext (Euronext)) as shown in Table 1. Table 1 Contract sizes
    for wheat futures exchanges Full size table Application of the SAPPhIRE model
    to wheat markets is shown in Fig. 3. In Step 1, there are numerous strategies
    that may be employed to counter speculative wheat market fluctuations, not all
    of which are noted in Fig. 3 as indicated by “…”. The conservation of existing
    supplies is selected due to the constraint of sustainability as previously explained.
    The conservation of existing supplies of wheat can thus be accomplished by reducing
    consumption or reducing waste as enabled by consumers not purchasing wheat-based
    products such as bread within a specified limited time, purchasing an alternative
    product that is not wheat-based during that time, and/or purchasing less of the
    wheat-based product. The information about consumer food choices then needs to
    be conveyed upstream the supply chain for ecological embeddedness: so that the
    supply chain actors can prepare and benefit, and so that the grain is physically
    available in pre-processed form. The food choice derivative can consequently be
    created based on the amounts of wheat conserved. Fig. 3 Wheat market case study
    reasoning with SAPPhIRE model Full size image Examples of how consumers could
    purchase less include schemes such as: Buy one, get one later (after the specified
    time) for those who purchase more than one loaf regularly. Buy half a loaf (enabled
    by retailer and/or packaging of manufacturer). Buy none, get one later (the negative
    coupon: a guarantee for the future in case of local shortages). Buy none, get
    a nutritionally equivalent alternative. Buy none, get a functionally equivalent
    alternative. Such schemes would support ecologically embedded benefits to the
    retailer in terms of customer loyalty and stock optimization, to the consumer
    in terms of health benefits which could also inform the seed prebreeder and breeder,
    and to the rest of the value chain with respect to the ability to take proactive
    action. An MAS is a computerized system composed of multiple interacting intelligent
    agents. Each agent has autonomy and flexibility, making multi-agent technology
    suitable for distributed, real-time applications. MASs may be used for cognitive
    modeling and social simulation (Sun & Naveh, 2004). MAS has been combined with
    AI and blockchain for privacy and security of health records (Alruwaili, 2020).
    The privacy and security of consumer food choices could thus be protected and
    supported by edge computing which offers an efficient alternative to storing,
    processing, and analyzing consumer data. Crowdsourcing enables consumer engagement
    and therefore improves the likelihood of success: to decide which type of purchasing
    scheme should be offered, to connect people to buy the other half of the loaf
    of bread, to make decision about the timing and location of purchases, select
    nutritional and functional alternatives, etc. which would prepare the necessary
    aggregated information to ensure the standards for futures trading are met. The
    ultimate goal would be global benefits throughout the value chain with lower and
    more stable food and raw ingredient prices. Crowdsourcing is usually defined as
    the practice of collecting and aggregating needed services, information or other
    resources supplied by the general public (Hosseini et al., 2015). Crowdsourcing
    applications have the following key elements: (1) tasks, which are outsourced
    with various characteristics in reality e.g., the purchasing schemes above; (2)
    requesters, who release the tasks; (3) system platforms, which provide efficient
    measures to manage and organize the entire crowdsourcing process; and (4) workers,
    i.e., the crowd of people (Jiang et al., 2018). The power in food supply chains
    lies with retailers who are in the position of managing various purchase schemes
    for the benefit of their stock. Retailers would be encouraged to participate also
    for reasons of good corporate responsibility. Retailers are consequently a logical
    choice for representing requesters who at the same time would be agents in the
    MAS, capable of making autonomous decisions (Dorri et al., 2018) supported by
    AI analysis of consumer behavior, yet acting collaboratively with other agents
    to aggregate information on reduced consumption to support the food choice derivatives.
    A typical feature of MAS is that the real benefit of agents can only be harnessed
    through collaborative work with other agents through features such as sociability
    (sharing knowledge), autonomy (independent execution of decision-making for appropriate
    action), and proactivity (using history, sensed parameters, and the information
    from other agents to predict possible future actions) (Dorri et al., 2018). MAS
    can be leaderless or leader-follower with mobile leaders or multiple leaders also
    a possibility. Each agent may work within its own edge computing environment and
    send collected data to other agents when pre-defined targets are met with respect
    to the social network (crowd) it interacts with. Information may then be communicated
    to other actors in the value chain to inform and enable planning in aggregate.
    The individual contributions would be captured from interactions of the crowd
    with the crowdsourcing platform via various devices (e.g., smartphones, laptops)
    enabling a flexible level of co-creation with the aggregating mechanism either
    centrally operated by the task issuer or intrinsic to a crowdsourced system (Hosseini
    et al., 2019). Figure 4 illustrates a possible configuration using retailers as
    agents who would employ specifications for stock optimization and rewards/penalties
    supporting consumer health and nutrition based on localized knowledge and behavior.
    Fig. 4 Possible crowdsourcing system illustrating interaction of MASs and aggregated
    virtual resources with physical resources and futures markets. System informed
    by Jiang et al. (2018) and Hosseini et al. (2019) Full size image 5 Discussion
    The globalization of food markets, combined with the production advances of the
    Green Revolution, have created a world where severe regional famine is exceptional
    rather than normal. As it is demonstrably true that total food production remains
    sufficient to meet current global nutritional needs (Rahimifard et al., 2018),
    institutional improvements in markets are key to providing food security to the
    nearly 9% of humans who are currently undernourished. While markets reward innovation,
    they are often slow to adopt institutional change. The London Metal Exchange banned
    day drinking by traders in 2019, some 142 years after sober trading was proposed.
    World cereal production has been over two billion MT every year since 2004, and
    over one billion MT every year since 1968. Price fluctuations create winners and
    losers, but very large and rapid price changes can be devastating to the economy
    and food security. February of 2022 saw the price of wheat rise by over a hundred
    dollars per MT (43%) over a period of just two weeks. If all payments for cereals
    during the year were similarly changed, the result could be the unexpected transfer
    of over three hundred billion US dollars, more than the entire GDP of Chile or
    Finland. Sufficient liquid assets to create that kind of wealth transfer from
    consumers to producers do not exist, and price fluctuations on that scale could
    be ruinous, leaving unsold cereals and empty stomachs. A price change in the opposite
    direction could leave producers financially nonviable, risking the mass abandonment
    of agriculture. Long term contracts mitigate those risks by ensuring that significant
    amounts of grain have prices set at levels that leave producers viable and consumers
    solvent even if the current price rises or falls to beyond those limits. Derivatives
    markets have the potential to further stabilize the actual transfer of cereals
    to hungry people in the face of economic shocks. Waste reduction is an inherently
    limited source because the waste is a finite subset of overall production. 100%
    efficiency is technically impossible and efforts to move closer to perfection
    have diminishing returns. There is currently every reason to believe that food
    waste is high enough that waste-prevention efforts are worth pursuing, but there
    is a limit to how large this segment of the market can grow. Waste reduction derivatives
    logically are restricted to being a smaller economic consideration than the underlying
    primary markets. This stands in contrast to value adding food preparation, which
    at times is valued many times the worth of the inputs. The proposed food choice
    derivatives investigated are feasible both technologically and in terms of aggregating
    sufficient quantities of commodities for trading on futures markets in the case
    of wheat. However, there are many unknowns related to the actual response of consumers
    and futures markets. Although the food choice derivatives have been designed as
    a voluntary measure to address crises, given severe shocks to the food systems
    of nations, governmental bodies could compel the use of such a system for food
    redistribution to minimize malnutrition and starvation. The proposed food choice
    derivatives compare favorably with other proposed solutions in that ecological
    embeddedness of the value chain and sustainability of the food system are intrinsic.
    Futures contracts and options have been proposed as tools to manage price risks
    (e.g., Gilbert (2011), Sarris (2010), Sarris et al. (2010), Tangermann (2011)),
    but these are solely financial in nature. Reducing food waste and consumption
    are a superior solution to increasing agricultural production due to the likelihood
    of insufficient time to harvest and increased social and environmental pressures
    connected to unsustainability. Previous research has concluded that pathways to
    reduce environmental impacts of the global food system should be designed around
    regional differences in food consumption (Ibarrola-Rivas & Nonhebel, 2022). The
    case study for Ukrainian wheat indicates that the aggregated quantities from one
    nation such as the UK over a short period of time (one month to maintain consumer
    engagement) would be insufficient to replace all of the wheat harvest anticipated
    to be lost due to the war in Ukraine (thousands of MT as opposed to MMT), but
    similar efforts across the European Union would be more significant. Achievement
    of near full replacement of the lost harvest would be an added benefit as the
    defined role of the proposed food choice derivatives is not to replace the lost
    harvest, but to counter speculative market fluctuations that the lost harvest
    causes. Consumers in times of crises may not make appropriate food choices. There
    are few studies that investigate the economic motivations in consumer food choice
    (Martinho et al., 2022). The proposed food choice derivative should introduce
    the option to participate in a humanitarian effort prior to any actual changes
    in supply or cost although consumers may perceive a future resource scarcity.
    Ideally, the triggers for initiating crowdsourcing based on market volatility
    would be set early enough to counter significant price spikes, limiting the subsequent
    effects on purchasing power. Financial insecurity would likely have a negative
    effect on charitable giving but could be positive for the proposed food choice
    derivatives in that consumers would already be considering reduced consumption
    and waste. Previous research has shown that consumers facing limited supply may
    not make the best choices to benefit their health and nutrition (Maxwell et al.,
    2008; Trollman et al., 2021). Consumers tend to select similar substitutes with
    dissimilar alternatives reducing the desire for the original product (Arens &
    Hamilton, 2016, 2018). If consumers are asked to select alternatives or substitutes,
    there may be long-term effects on consumer habits, behavior and brand loyalty
    with the exact effects being unknown. The use of strategies to encourage consumers
    to consume less bread may have positive impacts on health. There is evidence that
    the consumption of pulses is an important strategy to reduce the risk of cardiovascular
    disease (Lukus et al., 2020) – pulses (beans, peas, chickpeas, and lentils) can
    be used as a direct replacement for wheat flour in baked goods. Dietary changes
    may have an impact on gut microbiota (Korpela, 2018). Few studies examine the
    impact of substituting refined carbohydrate with wholegrain (Jebb, 2015). Overall,
    research suggests that a temporary dietary change is more likely to be successful
    and that this is unlikely to lead to a long-term dietary modification (Jebb, 2018).
    Similarly, it is unclear if temporary food waste reduction initiatives would translate
    into longer term actions. Advance knowledge of consumer behavior would benefit
    the actors in the value chain. The potential benefits that foreknowledge of consumer
    behavior can have for the value chain include: prebreeders and breeders of grains
    receiving information about dietary choices so that nutritional characteristics
    of grains could be improved, farmers having information to support planting choices,
    grain processors and millers having time to reallocate resources to process other
    products preventing overproduction and other forms of value loss (Trollman & Trollman,
    2019), food manufacturers being able to consider reformulation of their products
    to support both consumer health and nutrition as well as reflecting changes on
    the supply side of raw ingredients, and increased customer loyalty for the food
    retailer. The main driver for selecting crowdsourcing platforms was independence
    from existing methods of tracking consumer behavior. Food retailers have loyalty
    apps and cards, but hesitate to share this information for various reasons including
    consumer trust and privacy, competitive advantage, and legislation. Edge computing
    would localize individual consumer data for greater security and enable faster
    processing by supporting AI. Food retailers do not all serve the same markets
    in terms of characteristics such as wealth, health, and motivations. Consumer
    trust may also be increased if the crowdsourcing is local and coordinated by a
    retailer they know. The effectiveness of the food choice derivatives will depend
    on how they are perceived by the market. Although the design of the food choice
    derivatives ensures that they satisfy market regulations and have underlying physical
    resources, when the time comes for consumers to limit their consumption or make
    alternative choices, they may not comply. The degree of non-compliance may over
    time (through learning) be anticipated by AI. It will likely fall to retailers
    to determine if and what kind of sanctions may be imposed for non-compliance.
    Due to the localized nature of the nodes of the MAS, retailers may be able to
    share information that tracks whether consumers have made additional purchases
    elsewhere to make up for any commitments to reduce consumption. The independence
    and voluntary nature of participation may support data sharing as existing sales
    data are commercially sensitive and unlikely to be shared (Jebb, 2018). This research
    may be applied to the commodity sector in general, including energy and metals.
    An example application is the energy reduction scheme in the UK intended to prevent
    electricity blackouts by allowing smart meter customers to reduce their usage
    during times of peak demand (Octopus Energy, 2022). Future research directions
    should seek to explore and better understand how humanitarian responses in terms
    of reduced food consumption and waste impact on longer-term behavior and the most
    effective strategies for their realization. 6 Conclusions The purpose of this
    research was to design an alternative consumer-based price-making mechanism for
    derivatives markets to mitigate the negative effects of food speculation while
    improving food security and the sustainability of agricultural production. The
    design is presented in Fig. 4 with viability of the design supported by the case
    study of Ukrainian wheat based on the causal approach shown in Fig. 3. Although
    this “food choice” derivative is feasible, consumers should be supported in making
    relevant choices so that their nutrition and health is not compromised. Current
    communication within supply chains is not capable of managing the proposed derivatives
    which should instead make use of crowdsourcing platforms linked to futures markets
    with relevant data available to all actors of the supply chain to enable adequate
    time for planning. Enabling food choice derivatives has the potential to contribute
    to greater food security and decreased food waste when food systems are confronted
    with shocks. Data Availability Not applicable. References Adegboye, A. R. A.,
    Bawa, M., Keith, R., Tewfik, S., & Tewfik, I. (2021). Edible insects: Sustainable
    nutrient-rich foods to tackle food insecurity and malnutrition. World Nutrition,
    12(4), 176–189. https://doi.org/10.26596/wn.2021124176-189 Article   Google Scholar   Adenauer,
    M. (2022, January 13). The role of China’s feed deficit in international grain
    markets. OECD Food Agriculture Fisheries Papers No. 172. Retrieved June 18, 2022,
    from https://www.oecd-ilibrary.org/agriculture-and-food/the-role-of-china-s-feed-deficit-in-international-grain-markets_2138cc7f-en
    Ahmed, S., Stewart, A., Smith, E., Warne, T., & Byker Shanks, C. (2021). Consumer
    perceptions, behaviours, and knowledge of food waste in a rural American State.
    Frontiers in Sustainable Food Systems, 5. https://doi.org/10.3389/fsufs.2021.734785
    Ahmed, S. A., Diffenbaugh, N. S., & Hertel, T. W. (2009). Climate volatility deepens
    poverty vulnerability in developing countries. Environmental Research Letters,
    4(3), 034004. https://doi.org/10.1088/1748-9326/4/3/034004 Article   Google Scholar   Aït-Youcef,
    C. (2019). How index investment impacts commodities: A story about the financialization
    of agricultural commodities. Economic Modelling, 80, 23–33. https://doi.org/10.1016/j.econmod.2018.04.007
    Article   Google Scholar   Algieri, B. (2016). A roller coaster ride: An empirical
    investigation of the main drivers of wheat price. In M. Kalkuhl, J. von Braun,
    & M. Torero (Eds.), Food Price volatility and its implications for Food Security
    and Policy. Springer. https://doi.org/10.1007/978-3-319-28201-5_10 Alruwaili,
    F. F. (2020). Artificial Intelligence and multi agent based distributed ledger
    system for better privacy and security of electronic healthcare records. PeerJ
    Computer Science, 6, e323. https://doi.org/10.7717/peerj-cs.323 Article   PubMed   PubMed
    Central   Google Scholar   Amis Market Monitor. (2022, June). Global food security
    consequences of the war in Ukraine. Retrieved June 19, 2022, from http://www.amis-outlook.org/fileadmin/user_upload/amis/docs/Market_monitor/AMIS_Market_Monitor_current.pdf
    Anderson, K., Rausser, G. C., & Swinnen, J. F. M. (2013). Political economy of
    public policies: Insights from distortions to agricultural and food markets. Journal
    of Economic Literature, 51(2), 423–477. https://doi.org/10.1257/jel.51.2.423 Article   Google
    Scholar   Arens, Z. G., & Hamilton, R. W. (2016). Why focusing on the similarity
    of substitutes leaves a lot to be desired. Journal of Consumer Research, 43(4),
    448–459. https://doi.org/10.1093/jcr/ucw034 Article   Google Scholar   Arens,
    Z. G., & Hamilton, R. W. (2018). The substitution strategy dilemma: Substitute
    selection vs. substitute effectiveness. Journal of the Academy of Marketing Science,
    46, 130–146. https://doi.org/10.1007/s11747-017-0549-2 Article   Google Scholar   Azadnia,
    A. H., Saman, M. Z. M., & Wong, K. Y. (2015). Sustainable supplier selection and
    order lot-sizing: An integrated multi-objective decision-making process. International
    Journal of Production Research, 53(2), 383–408. https://doi.org/10.1080/00207543.2014.935827
    Article   Google Scholar   Baldos, U. L. C., & Hertel, T. W. (2015). The role
    of international trade in managing food security risks from climate change. Food
    Security, 7, 275–290. https://doi.org/10.1007/s12571-015-0435-z Article   Google
    Scholar   Barrett, J. R. (2007). The researcher as instrument: Learning to conduct
    qualitative research through analyzing and interpreting a choral rehearsal. Music
    Education Research, 9(3), 417–433. https://doi.org/10.1080/14613800701587795 Article   Google
    Scholar   Beaujeu, R. (2016). Alternative Policies to Buffer Stocks for Food Security
    OECD Food Agriculture and Fisheries Papers No. 97. OECD Publishing. Retrieved
    June 19, 2022 from https://doi.org/10.1787/5jln0434qkzp-en Bhatt, A. N., Majumder,
    A., & Chakrabarti, A. (2021). Analyzing the modes of reasoning in design using
    the SAPPhIRE model of causality and the Extended Integrated Model of Designing.
    Artificial Intelligence for Engineering Design Analysis and Manufacturing, 35(4),
    384–403. https://doi.org/10.1017/S0890060421000214 Article   Google Scholar   Calabrese,
    A., & Costa, R. (2015). Strategic thinking and business innovation: Abduction
    as cognitive element of leaders’ strategizing. Journal of Engineering and Technology
    Management, 38, 24–36. https://doi.org/10.1016/j.jengtecman.2015.06.001 Article   Google
    Scholar   Carvalho, O., Charalambides, M. N., Djekić, I., Athanassiou, C., Bakalis,
    S., Benedito, J., Briffaz, A., Castañé, C., Valle, D., de Sousa, G., Erdogdu,
    I. M. N., Feyissa, F., Kavallieratos, A. H., Koulouris, N. G., Pojić, A., Raymundo,
    M., Riudavets, A., Sarghini, J., Trematerra, F., & Tonda, A. (2021). Modelling
    processes and products in the cereal chain. Foods, 10(1), 82. https://doi.org/10.3390/foods10010082
    Article   CAS   PubMed   PubMed Central   Google Scholar   Chakrabarti, A., Sarkar,
    P., Leelavathamma, B., & Nataraju, B. S. (2005). A functional representation for
    aiding biomimetic and artificial inspiration of new ideas. Artificial Intelligence
    for Engineering Design Analysis and Manufacturing, 19, 113–132. https://doi.org/10.1017/S0890060405050109
    Article   Google Scholar   Chatterjee, T., Raghunathan, R., & Gulati, A. (2019).
    Linking farmers to futures market in India. Indian Council for Research on International
    Economic Relations. Retrieved June 19, 2022 from https://think-asia.org/handle/11540/10909
    Conaty, F. (2021). Abduction as a methodological approach to case study research
    in management accounting – an illustrative case. Accounting Finance & Governance
    Review, 27. https://doi.org/10.52399/001c.22171 Conitzer, V., Brill, M., & Freeman,
    R. (2015). Crowdsourcing societal tradeoffs. In G. Weiss, P. Yolum, R.H. Bordini,
    & E. Elkind (Eds.), Proceedings of the 2015 International Conference on Autonomous
    Agents and Multiagent Systems. International Foundation for Autonomous Agents
    and Multiagent Systems. https://doi.org/10.5555/2772879.2773305 Ćosić, B., Pukšec,
    T., Krajčić, G., Duić, N., Markovska, N., Mikulčić, H., Vujanović, M., & Bedoić,
    R. (2016). Data-base/Inventory of the CEREALS AWCB value chain. AgroCycle for
    a Circular Economy. Retrieved June 19, 2022 from http://www.agrocycle.eu/files/2018/02/CEREALS-AWCB-value-chain-.pdf
    Dorri, A., Kanhere, S. S., & Jurdak, A. R. (2018). Multi-agent systems: a survey.
    IEEE Access: Practical Innovations, Open Solutions, 6, 28573–28593. https://doi.org/10.1109/ACCESS.2018.2831228
    Article   Google Scholar   FAO (2017). The future of food and agriculture – Trends
    and challenges. FAO. Retrieved June 21, 2022 from https://www.fao.org/3/i6583e/i6583e.pdf
    Ghadimi, P., Toosi, F. G., & Heavey, C. (2018). A multi-agent systems approach
    for sustainable supplier selection and order allocation in a partnership supply
    chain. European Journal of Operational Research, 269, 286–301. https://doi.org/10.1016/j.ejor.2017.07.014
    Article   Google Scholar   Ghadimi, P., Wang, C., Lim, M. K., & Heavey, C. (2019).
    Intelligent sustainable supplier selection using multi-agent technology: Theory
    and application for industry 4.0 supply chains. Computers & Industrial Engineering,
    127, 588–600. https://doi.org/10.1016/j.cie.2018.10.050 Article   Google Scholar   Gilbert,
    C. (2011). International agreements for commodity price stabilization: An assessment.
    OECD Food, Agriculture and Fisheries Papers, No. 53. Retrieved June 19, 2022 from
    https://www.oecd-ilibrary.org/docserver/5kg0ps7ds0jl-en.pdf?expires=1655635942&id=id&accname=guest&checksum=C314B1C9A0D8E9C22E666AF3C85488EB
    Gustafson, D. J. (2013). Rising food costs & global food security: Key issues
    & relevance for India. Indian Journal of Medical Research, 138(3), 398–410. PubMed   PubMed
    Central   Google Scholar   Halpin, M., & Richard, N. (2021). An invitation to
    analytic abduction. Methods in Psychology, 5, 100052. https://doi.org/10.1016/j.metip.2021.100052
    Article   Google Scholar   Hosseini, M., Shahri, A., Phalp, K., Taylor, J., &
    Ali, R. (2015). Crowdsourcing: A taxonomy and systematic mapping study. Computer
    Science Review, 17, 43–69. https://doi.org/10.1016/j.cosrev.2015.05.001 Article   Google
    Scholar   Hosseini, M., Angelopoulos, C. M., Chai, W. E., & Kundig, S. (2019).
    Crowdcloud: A crowdsourced system for cloud infra-structure. Cluster Computing,
    22, 455–470. https://doi.org/10.1007/s10586-018-2843-2 Article   Google Scholar   Hubka,
    V., & Eder, W. E. (2012). Theory of Technical Systems: A total Concept Theory
    for Engineering Design. Springer Science & Business Media. Ibarrola-Rivas, M.
    J., & Nonhebel, S. (2022). Regional food preferences influence environmental impacts
    of diets. Food Security. https://doi.org/10.1007/s12571-022-01270-3 Article   Google
    Scholar   Jagtap, S., Trollman, H., Trollman, F., Garcia-Garcia, G., Parra-López,
    C., Duong, L., Martindale, W., Munekata, P. E. S., Lorenzo, J. M., Hdaifeh, A.,
    Hassoun, A., Salonitis, K., & Afy-Shararah, M. (2022). The Russia-Ukraine Conflict:
    Its Implications for the Global Food Supply Chains. Foods, 11(14), 2098. https://doi.org/10.3390/foods11142098
    Jebb, S. A. (2015). Carbohydrates and obesity: From evidence to policy in the
    UK. Proceedings of the Nutrition Society, 74(3), 215–220. https://doi.org/10.1017/S0029665114001645
    Jebb, S. A. (2018). Interventions to accelerate change towards a healthier diet.
    Proceedings of the Nutrition Society, 77(2), 106–111. https://doi.org/10.1017/S0029665117004086
    Jeswani, H. K., Figueroa-Torres, G., & Azapagic, A. (2021). The extent of food
    waste generation in the UK and its environmental impacts. Sustainable Production
    and Consumption, 26, 532–547. https://doi.org/10.1016/j.spc.2020.12.021 Article   Google
    Scholar   Jiang, J., An, B., Yichuan, J., Lin, D., Bu, Z., Cao, J., & Hao, Z.
    (2018). Understanding Crowdsourcing Systems from a Multiagent Perspective and
    Approach. ACM Transactions on Autonomous and Adaptive Systems, 13(2), 1–32. https://doi.org/10.1145/3226028
    Article   Google Scholar   Kavallari, A., Fellmann, T., & Gay, S. H. (2014). Shocks
    in economic growth shocking effects for food security? Food Security, 6, 567–583.
    https://doi.org/10.1007/s12571-014-0368-y Article   Google Scholar   Koren, O.,
    & Winecoff, W. K. (2022). U.S. Federal Reserve Policies can cause political instability
    by raising bread prices. Food Security. https://doi.org/10.1007/s12571-022-01300-0
    Article   PubMed   PubMed Central   Google Scholar   Korpela, K. (2018). Diet,
    microbiota, and metabolic health: trade-off between saccharolytic and proteolytic
    fermentation. Annual Review of Food Science and Technology, 9, 65–84. https://doi.org/10.1146/annurev-food-030117-012830
    Article   CAS   PubMed   Google Scholar   Kroll, E., & Koskela, L. (2015). On
    abduction in design. In J. Gero & S. Hanna (Eds.), Design Computing and Cognition
    ‘14 (pp. 327–344). Springer. https://doi.org/10.1007/978-3-319-14956-1_19 Kroll,
    E., & Koskela, L. (2017). Studying design abduction in the context of novelty.
    In A. Maier, S. Škec, H. Kim, M. Kokkolaras, J. Oehmen, G. Fadel, F. Salustri,
    & M. Van der Loos (Eds.), DS 87 – 7 Proceedings of the 21st International Conference
    on Engineering Design (ICED 17) Vol 7: Design Theory and Research Methodology
    (pp. 061–070). The Design Society. https://www.designsociety.org/publication/39806/Studying+design+abduction+in+the+context+of+novelty.
    Accessed 28 Dec 2022. The abstract for this paper was presented at the International
    Web Conference on Food Choice & Eating Motivation 19th & 20th May, 2022. http://events.ipv.pt/fcem/
    Lamé, G., Yannou, B., & Cluzel, F. (2018). Analyzing RID methodology through the
    lens of innovative abduction. In D. Marjanović, M. Štorga, S. Škec, N. Bojčetić,
    & N. Pavković (Eds.), DS 92: Proceedings of the DESIGN 2018 15th International
    Design Conference (pp. 1879–1890). The Design Society. https://doi.org/10.21278/idc.2018.0322
    Lukus, P. K., Doma, K. M., & Duncan, A. M. (2020). The role of pulses in cardiovascular
    disease risk for adults with diabetes. American Journal of Lifestyle Medicine,
    14(6), 571–584. https://doi.org/10.1177/1559827620916698 Article   PubMed   PubMed
    Central   Google Scholar   Marquina, A. (2013). Financial derivatives, their impact
    on food security and regulation attempts. UNISCI Discussion Papers, 31, 149–170.
    https://doi.org/10.5209/rev_UNIS.2013.n31.44761 Martinho, V. J. P. D., Bartkiene,
    E., Djekic, I., Tarcea, M., Barić, I. C., Černelič-Bizjak, M., Szűcs, V., Sarcona,
    A., El-Kenawy, A., Ferreira, V., Klava, D., Korzeniowska, M., Vittadini, E., Leal,
    M., Bolhuis, D., Papageorgiou, M., & Guiné, R. P. F. (2022). Determinants of economic
    motivations for food choice: Insights for the understanding of consumer behaviour.
    International Journal of Food Sciences and Nutrition, 73(1), 127–139. https://doi.org/10.1080/09637486.2021.1939659
    Article   PubMed   Google Scholar   Maxwell, D., Caldwell, R., & Langworthy, M.
    (2008). Measuring food insecurity: Can an indicator based on localized coping
    behaviors be used to compare across contexts? Food Policy, 33(6), 533–540. https://doi.org/10.1016/j.foodpol.2008.02.004
    Article   Google Scholar   Melikoglu, M., & Webb, C. (2013). Use and waste of
    bread to produce fermentation products. In M. Kosseva, & C. Webb (Eds.), Food
    Industry Wastes (pp. 63–76). Academic. https://doi.org/10.1016/B978-0-12-391921-2.00004-4
    Mello, J. A., Gans, K. M., Risica, P. M., Kirtania, U., Strolla, L. O., & Fournier,
    L. (2011). How is food insecurity associated with dietary behaviors? An analysis
    with low income, ethnically diverse participants in a nutrition intervention study.
    Journal of the Academy of Nutrition and Dietetics, 110(12), 1906–1911. https://doi.org/10.1016/j.jada.2010.09.011
    Article   Google Scholar   Morell, M. K. (2012). New cereal value chain: From
    seed to sewage. Cereal Foods World, 57(2), 44–49. https://doi.org/10.1094/CFW-57-2-0044
    Article   Google Scholar   Octopus Energy. (2022, October 7). Blackout Busters:
    Octopus Energy customers could make £100 whilst helping end power cuts. Retrieved
    December 28, 2022, from https://octopus.energy/press/blackout-busters-octopus-energy-customers-could-make-100-whilst-helping-end-power-cuts/
    OEC (n.d.). Wheat in Ukraine. Retrieved April 12, from https://oec.world/en/profile/bilateral-product/wheat/reporter/ukr
    Ollenburger, M., Page, K., & Zhang, X. (2022). Uncertainties in estimating global
    potential yields and their impacts for long-term modelling. Food Security. https://doi.org/10.1007/s12571-021-01228-x
    Article   Google Scholar   Parry, A., LeRoux, S., Quested, T., & Parfitt, J. (2014,
    November 1). UK food waste—historical changes and how amounts might be influenced
    in the future. Waste and Resources Action Programme (WRAP). Retrieved June 15,
    2021, from https://wrap.org.uk/resources/guide/uk-food-waste-historical-changes-and-how-amounts-might-be-influenced-future
    Patokorpi, E., & Ahvenainen, M. (2009). Developing an abduction-based method for
    futures research. Futures, 41(3), 126–139. https://doi.org/10.1016/j.futures.2008.09.019
    Article   Google Scholar   Pérez-Pons, M. E., Alonso, R. S., García, O., Marreiros,
    G., & Corchado, J. M. (2021). Deep Q-Learning and preference based Multi-Agent
    System for Sustainable Agricultural Market. Sensors (Basel, Switzerland), 21(16),
    5276. https://doi.org/10.3390/s21165276 Article   PubMed   Google Scholar   Rahimifard,
    S., Stone, J., & Trollman, H. (2018). Global food security: The engineering challenges.
    International Journal of Sustainable Engineering, 11(2), 77–78. https://doi.org/10.1080/19397038.2018.1475091
    Article   Google Scholar   Reidy, J. (2022, April 11). Drought devastating Morocco’s
    grain production. World-Grain.com. Retrieved June 19, 2022, from https://www.world-grain.com/articles/16750-drought-devastating-moroccos-grain-production
    Rietveld, J. (2019, February 5). Netherlands throws away 5 million kilos of food
    every day: report. NL# Times. Retrieved June 19, 2022, from https://nltimes.nl/2019/02/05/netherlands-throws-away-5-million-kilos-food-every-day-report
    Roozenburg, N. F. M. (1993). On the pattern of reasoning in innovative design.
    Design Studies, 14(1), 4–18. https://doi.org/10.1016/S0142-694X(05)80002-X Article   Google
    Scholar   Sarris, A. (2010, May). Hedging cereal import price risks and institutions
    to assure import supplies. FAO Commodity Market Review 2009–2010. Retrieved June
    19, 2022, from https://www.fao.org/3/i1545e/i1545e00.pdf Sarris, A., Conforti,
    P., & Prakash, A. (2010). The use of organized commodity markets to manage food
    import price instability and risk. Agricultural Economics, 42(1), 47–64. https://doi.org/10.1111/j.1574-0862.2010.00463.x
    Article   Google Scholar   Schmidt, K. (2016). Explaining and promoting household
    food waste-prevention by an environmental psychological based intervention study.
    Resources Conservation and Recycling, 111, 53–66. https://doi.org/10.1016/j.resconrec.2016.04.006
    Article   Google Scholar   Sun, R., & Naveh, I. (2004). Simulating organizational
    decision-making using a cognitively realistic agent model. Journal of Artificial
    Societies and Social Simulation, 7(3), 1–5. Google Scholar   Sosoo, V. E., Okorie,
    D. I., & Chen, H. (2021). Roles of commodity futures derivatives and financial
    crises in global food security. Economic and Political Studies, 9, 336–357. https://doi.org/10.1080/20954816.2021.1872854
    Article   Google Scholar   Suppan, S. (2008, November 12). Commodities market
    speculation: the risk to food security and agriculture. Institute for Agriculture
    & Trade Policy (IATP). Retrieved June 19, 2022, from https://www.iatp.org/documents/commodities-market-speculation-the-risk-to-food-security-and-agriculture
    Suppan, S. (2022, March 16). Wheat futures prices and the war on regulation. Institute
    for Agriculture & Trade Policy (IATP). Retrieved June 19, 2022, from https://www.iatp.org/wheat-futures-prices-and-war-regulation
    Tangermann, S. (2011). Policy solutions to agricultural market volatility: a synthesis.
    International Centre for Trade and Sustainable Development (ICTSD), Issue Paper
    No. 33. Retrieved June 19, 2022, from https://www.files.ethz.ch/isn/138403/tangermann-price-volatility-and-policy-options.pdf
    Tavory, I., & Timmermans, S. (2014). Abductive analysis theorizing qualitative
    research. The Chicago University Press. Thomas, G. (2010). Doing case study: abduction
    not induction, phronesis not theory. Qualitative Inquiry, 16(7), 575–582. https://doi.org/10.1177/1077800410372601
    Article   Google Scholar   Thompson, J., & Scoones, I. (2009). Addressing the
    dynamics of agri-food systems: An emerging agenda for social science research.
    Environmental Science & Policy, 12(4), 386–397. https://doi.org/10.1016/j.envsci.2009.03.001
    Article   Google Scholar   Trollman, H., & Colwill, J. A. (2020). A transformational
    change framework for developing ecologically embedded manufacturing. Global Journal
    of Flexible Systems Management, 21, 341–368. https://doi.org/10.1007/s40171-020-00252-8
    Article   Google Scholar   Trollman, H., Colwill, J. A., & Brejnholt, A. (2020).
    Ecologically embedded design in manufacturing: legitimation within circular economy.
    Sustainability, 12(10), 4261. https://doi.org/10.3390/su12104261 Article   Google
    Scholar   Trollman, H., Jagtap, S., Garcia-Garcia, G., Harastani, R., Colwill,
    J., & Trollman, F. (2021). COVID-19 demand-induced scarcity effects on nutrition
    and environment: Investigating mitigation strategies for eggs and wheat flour
    in the United Kingdom. Sustainable Production and Consumption, 27, 1255–1272.
    https://doi.org/10.1016/j.spc.2021.03.001 Article   PubMed   PubMed Central   Google
    Scholar   Trollman, H., & Trollman, F. (2019). A sustainability assessment of
    smart innovations for mass production, mass customization and direct digital manufacturing.
    In A. Akdogan, & A. S. Vanli (Eds.), Mass Production Processes. Intech Open. https://doi.org/10.5772/intechopen.88897
    Van Evert, F. K., Gaitán-Cremaschi, D., Fountas, S., & Kempenaar, C. (2017). Can
    precision agriculture increase the profitability and sustainability of the production
    of potatoes and olives? Sustainability, 9(10), 1863. https://doi.org/10.3390/su9101863
    Article   Google Scholar   Wa-Mbaleka, S. (2020). The researcher as an instrument.
    In A. Costa, L. Reis, & A. Moreira (Eds.), Computer supported qualitative research.
    WCQR 2019. Advances in intelligent systems and computing. (Vol. 1068). Springer.
    https://doi.org/10.1007/978-3-030-31787-4_3 WRAP (2021, October). Food surplus
    and waste in the UK – key facts. Waste and Resources Action Programme (WRAP).
    Retrieved June 19, 2022, from https://wrap.org.uk/resources/report/food-surplus-and-waste-uk-key-facts
    Wright, B. D. (2009, June 25). International grains reserves and other instruments
    to address volatility in grain markets. The World Bank. Retrieved June 19, 2022,
    from https://doi.org/10.1596/1813-9450-5028 Xuan, Y., Hu, Y., & Wang, H. (2022).
    Social and economic analysis on the price spillover effect of agricultural products
    from the perspective of financialization: Evidence from China’s oil and oilseeds
    industrial chain. Applied Nanoscience. https://doi.org/10.1007/s13204-021-02094-x
    Article   Google Scholar   Zhang, N., Wang, M., & Wang, N. (2002). Precision agriculture—A
    worldwide overview. Computers and Electronics in Agriculture, 36(2–3), 113–132.
    https://doi.org/10.1016/S0168-1699(02)00096-0 Article   Google Scholar   Zucchella,
    A., & Urban, S. (2014). Futures of the sustainable firm: An evolutionary perspective.
    Futures, 63, 86–100. https://doi.org/10.1016/j.futures.2014.08.003 Article   Google
    Scholar   Download references Author information Authors and Affiliations Department
    of Work, Employment, Management and Organisations, School of Business, University
    of Leicester, University Road, Leicester, LE1 7RH, UK Hana Trollman Sustainable
    Manufacturing Systems Centre, School of Aerospace, Transport & Manufacturing,
    Cranfield University, Cranfield, MK43 0AL, UK Sandeep Jagtap Glenfield Hospital,
    University Hospitals of Leicester NHS Trust, Leicester, LE3 9QP, UK Frank Trollman
    Corresponding author Correspondence to Hana Trollman. Additional information Publisher’s
    note Springer Nature remains neutral with regard to jurisdictional claims in published
    maps and institutional affiliations. Rights and permissions Open Access This article
    is licensed under a Creative Commons Attribution 4.0 International License, which
    permits use, sharing, adaptation, distribution and reproduction in any medium
    or format, as long as you give appropriate credit to the original author(s) and
    the source, provide a link to the Creative Commons licence, and indicate if changes
    were made. The images or other third party material in this article are included
    in the article''s Creative Commons licence, unless indicated otherwise in a credit
    line to the material. If material is not included in the article''s Creative Commons
    licence and your intended use is not permitted by statutory regulation or exceeds
    the permitted use, you will need to obtain permission directly from the copyright
    holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
    Reprints and permissions About this article Cite this article Trollman, H., Jagtap,
    S. & Trollman, F. Crowdsourcing food security: introducing food choice derivatives
    for sustainability. Food Sec. 15, 953–965 (2023). https://doi.org/10.1007/s12571-023-01363-7
    Download citation Received 23 June 2022 Accepted 15 March 2023 Published 26 April
    2023 Issue Date August 2023 DOI https://doi.org/10.1007/s12571-023-01363-7 Share
    this article Anyone you share the following link with will be able to read this
    content: Get shareable link Provided by the Springer Nature SharedIt content-sharing
    initiative Keywords Crowdsource Derivatives market Food security Food waste Sustainability
    Use our pre-submission checklist Avoid common mistakes on your manuscript. Sections
    Figures References Abstract Introduction Literature review - Supporting information
    for the design phase Methods Results Discussion Conclusions Data Availability
    References Author information Additional information Rights and permissions About
    this article Advertisement Discover content Journals A-Z Books A-Z Publish with
    us Publish your research Open access publishing Products and services Our products
    Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio
    BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state
    privacy rights Accessibility statement Terms and conditions Privacy policy Help
    and support 129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University
    of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Food Security
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Crowdsourcing food security: introducing food choice derivatives for sustainability'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Li D.
  - Jiang Q.
  - Li S.
  - Liu X.
  - Liu J.
  citation_count: '0'
  description: Precision agriculture and aging farming populations have given rise
    of autonomous farm vehicles to help reduce labor cost, save agriculture resources,
    and improve farming productivity. Unlike self driving on city roads or in dedicated
    facilities, autonomous vehicles on farmlands face a very different set of challenges.
    For example, large farms lack network coverage, the dynamics of the farm landscape
    change, soil conditions, and farm vehicles can be affected by weather and working
    conditions. Thus, autonomous farm vehicles require strong on-board sensing, cognition,
    and adaptive real-time decision-making capabilities. In this article, we analyze
    the autonomous capabilities for farm vehicles by determining general requirements,
    then pointed out the specific capabilities. In addition, we explore a multi-dimensional
    network with space-air-ground integrated network (SAGIN) architecture for autonomous
    farm vehicles that incorporates key technologies to address the needs of comprehensive
    network coverage, flexible networking, and large-scale access. Besides, the primary
    challenges faced by edge computing are addressed and we conduct experiments on
    diverse multi-models on various GPU platforms. The results show that our edge
    intelligent based AI inference scheduling framework as a significant overall performance
    gain on different GPU platforms compared with the baseline inference frameworks.
    Furthermore, we analyze the challenges of autonomous farm vehicles.
  doi: 10.1109/MNET.006.2300021
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Network >Volume: 37 Issue:
    4 Networked Edge Intelligence for Autonomous Farm Vehicles Publisher: IEEE Cite
    This PDF Dongbo Li; Qianpeng Jiang; Shulang Li; Xuanyu Liu; Jie Liu All Authors
    153 Full Text Views Abstract Document Sections Introduction Autonomous Capabilities
    for Farm Vehicles Space-Air-Ground Integrated Network for Autonomous Farm Vehicles
    Edge Computing on Autonomous Farm Vehicles Open Research Challenges Show Full
    Outline Authors Figures References Keywords Metrics Abstract: Precision agriculture
    and aging farming populations have given rise of autonomous farm vehicles to help
    reduce labor cost, save agriculture resources, and improve farming productivity.
    Unlike self driving on city roads or in dedicated facilities, autonomous vehicles
    on farmlands face a very different set of challenges. For example, large farms
    lack network coverage, the dynamics of the farm landscape change, soil conditions,
    and farm vehicles can be affected by weather and working conditions. Thus, autonomous
    farm vehicles require strong on-board sensing, cognition, and adaptive real-time
    decision-making capabilities. In this article, we analyze the autonomous capabilities
    for farm vehicles by determining general requirements, then pointed out the specific
    capabilities. In addition, we explore a multi-dimensional network with space-air-ground
    integrated network (SAGIN) architecture for autonomous farm vehicles that incorporates
    key technologies to address the needs of comprehensive network coverage, flexible
    networking, and large-scale access. Besides, the primary challenges faced by edge
    computing are addressed and we conduct experiments on diverse multi-models on
    various GPU platforms. The results show that our edge intelligent based AI inference
    scheduling framework as a significant overall performance gain on different GPU
    platforms compared with the baseline inference frameworks. Furthermore, we analyze
    the challenges of autonomous farm vehicles. Published in: IEEE Network ( Volume:
    37, Issue: 4, July/August 2023) Page(s): 297 - 304 Date of Publication: 24 October
    2023 ISSN Information: DOI: 10.1109/MNET.006.2300021 Publisher: IEEE Introduction
    Farming, an agricultural activity as old as the existence of human civilization,
    is experiencing dramatic disruptions in recent years [1]. On one hand, climate
    change and regional geopolitical challenges put huge pressure on food security
    to feed the ever growing population. On the other hand, the farming labor force
    is declining drastically. Based on a survey by the Food and Agriculture Organization
    of the United Nations, the average age of farmers is almost 60 in US and most
    developed countries. The world is facing daunting challenges on who will grow
    our food and how to grow them. Autonomous farming is a concept where intelligent
    systems perform farm perception, decision making, and actuation without much involvement
    from human. It not only removes farmers from labor intensive and tedious farming
    activities, but also improves production quality and quantities by precisely applying
    seeding varieties, irrigation and fertilizer quantities, and pest and disease
    control [2]. Autonomous farm vehicles is an essential part of autonomous farming.
    They perform precise farming activities based on locations, conditions, and instructions
    without human intervention. The fist autonomous farm vehicle of the modern sense
    was developed in 1997 after differential global positioning system (GPS) became
    available for civilian use [3]. Due to relatively simple farmland environments,
    GPS-assisted driving spread quickly among advanced farm vehicles. However, these
    vehicles primarily follow preset trajectories, and still require human drivers
    to handle complex maneuvers and soil conditions [4]. Technology advances in autonomous
    driving cars in recent years motivate farm equipment companies to invest heavily
    in autonomous driving. Industrial leader Deere & Co. has invested more than $1
    billion in autonomous farm vehicle technology over the past five years. This includes
    investments in Agco Corporation (AGCO), a maker of autonomous tractors and other
    farm vehicles, and in Blue River Technology, a startup developing autonomous crop-spraying
    robots [5]. Technologies required by autonomous farm vehicles share some similarities
    as self-driving cars, yet have their unique challenges [6], [7]. Cars are transportation
    devices. Their primary role is to ship people or goods from point A to point B
    safely and quickly through a complex road network. Farm vehicles are production
    devices. Their primary role is to perform scheduled tasks safely, quickly, and
    precisely over large fields and through growth seasons. This setting brings some
    uniaue challenges. Field Conditions The most significant driving challenge for
    farm vehicles comes from soil conditions and workload, and the conditions could
    change due to crop growth and weather conditions. Operation Precision Many agriculture
    procedures, such as harvesting and precise weed removal require centimeter-level
    positioning and operation accuracy. It could be an order more than that of car
    driving. Lack of Network Modern farms could span over a large area with hardly
    any mobile network coverage. In this case, infrastructure and road-side computing
    assistance becomes infeasible. Vehicle Varieties While most passenger cars are
    alike, there are thousands of farm vehicles and each of them may only be used
    for a short period of time over a growth season. We are facing a great challenge
    to give them autonomy one by one. Figure 1. An edge computing architecture with
    a task scheduling module for agricultural autonomous vehicles. Show All In the
    face of the above challenges, we have researched and explored the autonomous capabilities,
    space-air-ground integrated network (SAGIN), and edge computing for autonomous
    farm vehicles to achieve efficient performance and precise control. An edge computing
    architecture [8] with a task scheduling module for agricultural autonomous vehicles
    is depicted in Fig. 1. The main contributions of this article are as follows:
    In this article, we analyze the autonomous capabilities for autonomous farm vehicles.
    In particular, we determined the general requirements from the unique challenges
    that farm vehicles faces. Then we pointed out the specific capabilities that farm
    vehicles need to satisfy, as well as their potential applications. This part of
    the research shows that autonomous farm vehicles are completely different from
    that of road vehicles in terms of requirements and technologies. We explore SAGIN
    architecture for autonomous farm vehicles. In areas that cannot be covered by
    the terrestrial network, aerial network, and satellite network are used as a supplement.
    The multi-dimensional network incorporates key technologies, including mobile
    edge computing (MEC), multi-beam antenna technology, soft defined networking (SDN),
    and network function virtualization (NFV) to optimize quality of service (QoS)
    and meet the needs of comprehensive network coverage and flexible networking.
    We analyze the primary characteristics of edge computing on autonomous farm vehicles,
    including resource constraints, latency requirements, and multitasking capabilities.
    In addition, we conduct experiments on diverse multi-models. The results show
    that our edge intelligent based AI inference scheduling framework has a significant
    over-all performance gain on different GPU platforms compared with the baseline
    inference frameworks. We analyze the open research challenges of autonomous farm
    vehicles in three areas: dirt condition adaptation, precise actuation under unpredictable
    disturbance, concurrent real-time and multitasking under edge-cloud constraints.
    In addition, we give the possible ways to respond to the challenges. Autonomous
    Capabilities for Farm Vehicles There are various types of farm vehicles and each
    type has a unique demand for autonomy. In this part, capabilities shared by most
    farm vehicles are introduced, as shown in Table 1. High-Quality Navigation Location,
    navigation, and driving in straight lines, turns, and tight corners constitute
    the cornerstone of autonomous farm vehicles. By high-quality, we mean these actions
    need to be precise, adaptive, and robust. The complexity of such capabilities
    comes from the characteristics of agriculture and the uncertainty of farmlands.
    In the fields, the distance between ridges is normally around 20cm, while the
    size of farm vehicles counts by meters. Any tiny error in location and tracking
    could harm entire rolls of crops. Therefore, the accuracy during work must be
    assured. Thus, both precise actuation and environmental perception are required.
    Precise actuation assures the result of command execution, dropping the error
    into an acceptable range. Environmental perception is necessary for correcting
    any error accumulated by GPS-type of positioning, avoiding obstacles, and adapting
    to condition changes. The sensitivity and repeatability of navigation are particularly
    important during cultivation [9], since the same field may be processed repeatedly
    for different purposed during a growth season. Environment Perception The perception
    of environment could be achieved by a combination of sensing modalities and the
    artificial intelligence (AI) algorithms. Generally speaking, the following capabilities
    are necessary for the perception of environments: Ridge following. Plant and weed
    recognition and localization. Pest and disease recognition. Obstacle recognition.
    Ridge following is focused on the relative positioning of vehicles. It could not
    only help the vehicles to rectify the directions but also mark relative locations.
    Recognition and localization of “plant and weed” are useful to determine the growth
    status of weeds and crops and conduct precise weeding without large scale herbicide
    application. The recognition of pests and diseases will be used for the decision-making
    process for precise application of fertilizers, pesticides, and nutrients. Inconspicuous
    displacement deviation could also be detected by perception. The perception is
    primarily used to guide the action of farm vehicles and follow up the growth of
    crops. The data collected by remote sensing satellite and unmanned aerial vehicles
    (UAV) were uploaded and processed in cloud datacenter. The result provides guidance
    for autonomous farm vehicles in the field. The process of this precise management
    is shown in Fig. 2. The perception of the environment is essential not only for
    performing precise farming tasks, but also for making general farming decisions
    such as irrigation, field management, and harvesting. These are excellent application
    scenarios for AI techniques, especially computer vision and sensor fusion. Path
    Planning Path planning designs the vehicle paths and operation tasks according
    to the mission and farmland conditions [10]. With open farmland and unpredictable
    natural conditions, vehicle work environments have much uncertainty, which could
    invalidate the originally planned paths and interfere task execution. Thus, the
    path planning for farm vehicles need to be on-demand, situation-aware, and flexible
    with the overarching target in mind. Like self-driving cars, path planning for
    autonomous farm vehicles are done at two levels. In the navigation level, the
    primary goal is obstacle avoidance and drive safety. Interestingly, there are
    less moving object in farms and farm vehicles typically drive below 40 mph. This
    gives the vehicles more time react and can simply halt and wait for mobile obstacles
    (like human and animals) to move out of way. In other words, obstacle avoidance
    may not be the most difficult task for farm vehicles. However, the challenges
    come from higher level path planning, given the changing land conditions due to
    crop growth and weather conditions. A mushy patch of land may stick the vehicle
    and must be planned around. Table 1. Table of autonomous capabilities for farm
    vehicles. Collaborations While family farms may only require one vehicle to operate
    at a time, for large farms, many vehicles must collaborate for throughput, efficiency,
    and cost reduction. Same types of vehicles may work in parallel, or different
    types of vehicle may coordinate for complex tasks. For example, drones could guide
    ground vehicles to give them crop and field conditions. Vehicles may coordinate
    in real-time for overall system robustness and fault tolerance. The distributed
    work load and the modular farm vehicles provide the opportunity to further improve
    the efficiency, and the pattern could be applied to any similar farms. Both collaboration
    and swarming provide efficient ways for farming, while the application need to
    be supported by a series of technologies, such as cooperative scheduling, action
    priority validation, and distributed communication architecture. Space-Air-Ground
    Integrated Network for Autonomous Farm Vehicles As the number of autonomous farm
    vehicles and the number of interconnected terminals increase, the terrestrial
    network will not be able to meet the large amount of data transmission needs.
    Mean-while, in some remote farm areas, terrestrial network coverage is difficult,
    which brings challenges to the deployment of autonomous farm vehicles and networking
    with surrounding agricultural IoT devices. SAGIN is an infrastructure based on
    terrestrial network, supplemented and extended by satellite network and air network,
    providing ubiquitous, intelligent, collaborative and efficient information guarantee
    for various network applications in the wide space range, which can provide comprehensive
    coverage, high reliability and low latency communication network for autonomous
    farm vehicles of smart agriculture [11]. We explore a MEC-based SAGIN architecture
    for autonomous farm vehicles, as shown in Fig. 3. In the heterogeneous, multi-tier
    integration network, different access networks have different characteristics,
    such as coverage, control mode, spectrum allocation, and access performance. Therefore,
    the choice of network access for autonomous farm vehicles will greatly affect
    QoS, and the development of SAGIN will profoundly affect the performance of aautonomous
    farm vehicles. Figure 2. Generation of the prescription map and its applications
    in agriculture. Show All Terrestrial Network Cellular network is generally used
    for data transmission in farms if the base station can cover and the network is
    stable. However, since cellular networks cannot cover many areas, other network
    means are needed to meet the demand for reliable data transmission of autonomous
    farm vehicles. In addition to cellular networks, terrestrial networks can also
    be divided into short-range wireless network (SRWN) and low power wide area network
    (LPWAN) according to the communication distance. Short-Range Wireless Network
    SRWN mainly include protocols, such as WiFi and ZigBee. They will be physically
    limited by the 2.4G signal in terms of radio frequency performance. ZigBee is
    characterized by close range, simple application, self-organized communication,
    low power consumption. Since it supports automatic networking, it requires at
    least one coordinator as well as a router and can be suitable for networking and
    control of autonomous farm vehicle sensors. WIFI is mainly used in scenarios with
    high transmission rate and can be suitable for short distance video data transmission
    of autonomous farm vehicles. Low-Power Wide-Area Network Compared with SRWN, LPWAN
    has the features of low cost, low power consumption, and wide coverage, which
    matches the application requirements of autonomous farm vehicles in smart agriculture.
    LPWAN mainly includes LoRa, narrow band Internet of Things (NB-IoT). LoRa adopts
    LoRaWAN communication standard and adopts star topology to meet the demand of
    direct information interaction between end nodes and gateways during long distance
    connection, effectively reducing network complexity, and energy loss. loRa uses
    linear frequency modulation spread spectrum modulation technology to increase
    communication distance and improve network efficiency. NB-IoT is a standard specification
    defined through Third Generation Partnership Project (3GPP) that uses licensed
    frequency bands. It mainly focuses on low-power wide area networks and has outstanding
    advantages such as large area coverage, wide connectivity. and small rate. Afriai
    Network Aerial networks have greater coverage compared to terrestrial networks
    and can be used as a complement to terrestrial networks for autonomous farm vehicles.
    Aerial networks can be divided into high altitude platforms (HAPs) and low altitude
    platforms (LAPs), and the main infrastructure includes UAVs, blimps and balloons,
    etc. LAPs have the advantages of short communication latency and easy deployment
    compared to HAPs. UAVs, as the core components of LAPs, have been used in many
    networks of autonomous farm vehicles with the following features and advantages
    [12]. High Quality Communication; UAVs can construct line-of-sight (LOS) channels
    during aerial operations and link through direct links without refraction or scattering.
    Therefore, the communication process has a low signal attenuation loss, which
    can effectively improve the signal-to-noise ratio at the receiving end, thus achieving
    high-quality communication. Relay Network In areas without terrestrial network
    coverage, autonomous tarm vehicles are in isolation from the outside world. UAVs
    can be introduced into the network of autonomous farm vehicles as relays. By deploying
    UAVs as relay nodes, interconnection with the outside world can be achieved. Figure
    3. Space-air-ground integrated network for autonomous farm vehicles. Show All
    Efficient Data Collection In scenarios where data collection cannot be performed
    by the sensing devices of autonomous farm vehicles in farmland, flexible data
    collection can be achieved by deploying UAVs and optimizing the design of their
    flight trajectories. Low-Cost and Flexible Networking UAVs can be flexibly deployed
    and applied to complex and changing scenarios and environments. A swarm composed
    of multiple UAVs can build a stable communication network in different application
    scenarios. Thus, UAVs can be used for low-cost temporary networking to respond
    to different types of needs. Satellitenetwork Satellite networks complement terrestrial
    and aerial networks to achieve global coverage [13]. Satellites can be classified
    as geostationary orbit (GEO), medium earth orbit (MEO), and low earth orbit (LEO)
    satellites by orbit altitude. GEO satellites are relatively geostationary, and
    the network topology between satellite nodes is relatively fixed; LEO orbital
    altitude is about 500-2000km, which has the advantages of flexible networking
    and low time delay. Multi-Dimensional Heterogeneous Network Routing Management
    Technology As a hierarchical multidimensional network, satellite networks have
    a dynamic network topology. For autonomous farm vehicles, it is necessary to establish
    an efficient, reliable, and secure network routing system with satellites. Reasonable
    topology design can ensure seamless network switching between autonomous farm
    vehicles and satellites, improve the effectiveness of resource management, network
    reliability and provide load balancing capability. Multi-Beam Antenna Technology
    Satellite networks achieve efficient reuse of limited spectrum resources by adopting
    multi-beam antenna technology, thus enhancing system capacity. By equipping autonomous
    farm vehicles with multi-beam antenna, limited power, and processing resources
    can be matched with actual needs, and beam hopping (BH) technology can be used
    to achieve cluster management between autonomous farm vehicles and satellite ground
    stations, increasing systom caparity. Soft Defined Network and Network Function
    Virtualization By deploying SDN controllers on autonomous farm vehiclcs, based
    on NFV technology, decoupling of network hardware and software can be achieved
    to a certain extent. It is beneficial for controlling, configuring, updating,
    and optimizing network traffic, routing, protocols, transmission strategies, and
    so on. It can model and map the network topology and real-time traffic between
    satellites and autonomous farm vehicles to achieve comprehensive intelligent control
    of network conditions. Figure 4. EI based AI inference framework for autonomous
    farm vehicles. Show All Mobile Edge Computing Autonomous farm vehicles are facing
    increasing challenges in terms of QoS requirements, such as high data rates, low
    communication latency, and processing energy consumption. By using autonomous
    farm vehicles as the ground edge computing nodes of SAGIN, and achieving joint
    computing scheduling with satellites, MEC can reduce endpoint energy consumption
    and core network traffic and improve network scalability. Edge Computing on Autonomous
    Farm Vehicles Effective network connectivity enables precise control and real-time
    data transmission of autonomous farm vehicles. Edge computing provides real-time
    and efficient local decision-making for autonomous farm vehicles on the edge of
    the network and the device side closer to the data source. Edge intelligent (EI)
    can effectively solve the issue of relatively low bandwidth of networking for
    autonomous farm vehicles by processing data on the edge-side rather than on cloud
    servers. As a direct consequence, transmission latency caused by massive data
    congestion could be avoided. Resource Constraints and Acceleration Compared to
    cloud servers, edge nodes have limited resources due to their size and power sensitivity.
    To use complex AI models, like ResNet50 for object detection on edge devices,
    there must be enough memory and computation capability. Therefore, developing
    efficient edge AI accelerators is crucial, which involves redesigning hardware
    architectures and creating flexible task scheduling mechanisms to improve data
    throughput. There are many proposed and commercialized solutions, like Google
    Edge NPU and Intel Nervana NNP. Additionally, some studies focus on designing
    more resource-friendly AI inference frameworks and compression methods for general
    AI models [14]. However, accuracy may be sacrificed in compression methods. The
    future of edge AI processor architecture will involve a combination of targeted
    AI models, highly optimized hardware, and programmable engines. We are considering
    applying EI based AI inference framework to autonomous farm vehicles, as shown
    in Fig. 4, highly optimized hardware, and programmable engines. Multi-model is
    transformed into a directed acyclic graph (DAG) representation. By doing so, the
    task of reducing the overall delay of multi-model inference can be redefined as
    a finegrained operator scheduling problem based on DAG. In order to determine
    the optimal scheduling, a cost model is used to measure the inference delay of
    the entire computational graph. The parameters of the operator scheduling model
    are initialized and trained using deep reinforcement learning. Once the training
    phase is completed, the model can be deployed on autonomous farm vehicles to improve
    the computational speed of the algorithm. Real-Time Reactivity Latency is an important
    metric for autonomous farm vehicles. Either the processing of tasks or the transfer
    of data between different blocks may cause delay. Therefore, co-design of task
    scheduling algorithm and task processing mechanism is required, with latency-oriented
    optimization used to cater to real-time reactivity. Existing approaches include
    using cloud-edge synergy technology to redesign topology by deftly arranging edge-nodes
    in a distributed manner. For example, offloading low-priority, resource-intensive
    tasks to the cloud, or another auxiliary edge-node. Alternatively, data from edge
    processors in the same geographical area, such as the topography, climate, and
    land conditions, can be gathered and sent to the superior-node to aid the edge-node
    in making decisions at a regional level. Moreover, introducing a deep learning
    algorithm (e.g., reinforcement learning) into the workload scheduling stage will
    allow us to comprehensively evaluate multiple criteria and find the optimal reliability-reactivity
    trade-off. It is crucial to note that, in contrast to road vehicles, farm vehicles
    is more delay-tolerant. The rapid response to unexpected disturbance, and sensing
    to actuation close loop under various driving conditions are more representative
    of the real-time demand for the farm vehicles system. Multitasking With the development
    of automation and mechanization technology, farm vehicles replace livestock and
    are developing toward intelligence and automation. Farm vehicles can complete
    multiple tasks at the same time with edge computing devices equipped. Weeding
    is one of the most important tasks which can increase crop yields significantly.
    At present, some research institutions and well-known companies have developed
    various advanced weeding robots. A weeding robot mainly includes three subsystems:
    navigation system, identification system and weeding system. For navigation system,
    precise guidance of sensors and actuators are necessary for weeding. The general
    technology for precise lateral guidance in agriculture is real-time kinematic
    (RTK) GPS technology. The accuracy of location measurement can be within three
    centimeters. The identification system acquires and processes the information
    of seedlings and grasses. The weeding system completes the weeding operation according
    to the information transmitted by the image identification technology. All the
    subsystems are developed on the edge computing device. Platform Profiling Results
    Edge intelligence applications in agriculture, such as autonomous farm vehicles,
    usually deploy multiple models on edge computing devices to execute multiple tasks
    concurrently. Some tasks, such as navigation, need to produce reliable results
    in real time. However, the deep learning frameworks provided by most manufacturers
    only focus on optimizing a single model at present. In order to speed up the multi-task
    inference of resource-constrained edge devices, a EI based AI inference framework
    is used for autonomous farm vehicles. Figure 5 shows the generality of EI based
    AI inference scheduling framework. Here we utilize various single models (ResNet18/34/50,
    Inception-v1, and MobileNet-v1) to assemble homogeneous (R18+R34+R50) and heterogeneous
    (R18+Iv1+Mv1) concurrent multi-task deep neural network models. In addition, we
    also use a heterogeneous complex model YOLOP [15], which consists of three sub-models
    to evaluate the performance of low-speed automatic driving in the real world.
    Compared with the baseline inference framework, EI based AI inference scheduling
    framework has a significant overall performance gain (acceleration of 1.35 times
    to 2.84 times) on different GPU accelerators. Furthermore, it has great advantages
    in real-time performance. Even on Jetson Nano, which has the lowest computing
    power, it can infer the complex hybrid model YOLOP at a speed of 15.6FPS. In addition,
    it also reveals the scalability advantage, which can accelerate the inference
    of multiple models at the same time on GPU accelerators with different architectures.
    For farm autonomous vehicles that rely on visual servo control, visual algorithms
    are essential for recognizing furrows and providing navigation lines. Faster recognition
    speeds enable shorter control cycles, which is particularly important in tasks
    involving multiple coordinated vehicles. To ensure real-time task assignment and
    adjustment, each vehicle share its current job status through the network. Therefore,
    faster recognition speeds result in reduced information sharing delays among vehicles.
    The inference performance of EI based AI inference scheduling framework is 3.16
    and 3.34 times higher than TensorFlow and PyTorch, respectively. Utilizing EI
    based AI inference scheduling framework leads to improved communication speed
    between farm autonomous vehicles. Open Research Challenges As discussed above,
    autonomous farm vehicles are a unique class of autonomous systems that rise from
    the need to reduce cost and improve precision in agriculture. To achieve them
    at scale, a number of research problems must be addressed. Dirt Condition Adaptation
    In the dirt environment of farms, the fields are scattered unevenly and there
    are various obstacles, which affect the normal operation of autonomous farm vehicles
    and pose safety risks. In addition, the complex structural situation of paddy
    fields and their hard substrates are uneven, which directly affect the accuracy
    and efficiency of autonomous farm vehicle driving and operation. In order to improve
    the adaptability to dirt condition, it is necessary to study the obstacle recognition
    technology of farmland, the shape of the plot, obstacles, and the standard process
    of operation of autonomous farm vehicles. It is necessary to explore the main
    self-planning of field ridge and field corner coverage operation path and the
    autonomous planning method of avoiding obstacle bypass path to achieve full coverage
    and efficient autonomous planning technology of operation path. Meanwhile, it
    is necessary to study the hard bottom unevenness of paddy fields on the driving
    influence law of autonomous farm vehicles, and break through the autonomous driving
    technology of autonomous farm vehicles that adapt to the hard bottom unevenness
    of paddy fields, frequent reversing and detouring, so as to realize high-precision
    and high-efficiency autonomous operations in farmlands of different depths. Figure
    5. The inference performance of EI based AI inference scheduling framework on
    heterogeneous GPU platforms. Show All Precise Actuation Under Unpredictable Disturbance
    Autonomous farm vehicles are subject to many unpredictable factors, such as the
    special terrain of farmland, weather change, natural obstacles, and diverse planting
    structures when operating in the field. Relying only on human observation and
    empirical judgment, it is difficult to ensure reliable and precise driving of
    autonomous farm vehicles. Meanwhile, the network infrastructure of farmland in
    remote areas is weak. Combined with landscape complexity and condition changes,
    the information collection and processing work is large. These problems bring
    great challenges for autonomous farm vehicles to drive accurately under unpredictable
    disturbances in the field. There is an urgent need to build intelligent sensing
    systems, AI stack, and network adaptation capabilities for farm vehicles, which
    can make intelligent decisions based on multi-modality sensing data. These requirements
    and conditions are quite different from road driving and deserve research attentions
    by its own means. Concurrent Real-Time and Multitasking Under Edge-Cloud Constraints
    Large numbers of sensors and edge devices are deployed among farms to unify the
    plot information into the cloud through IoT technology. This process will focus
    on the agricultural management aspects of rice, corn, wheat, and other crops,
    using multi-source heterogeneous agricultural data fusion technology to aggregate,
    classify, analyze, and mine multi-dimensional data of agricultural production,
    and improve the real-time and information utilization rate of extracting, fusing
    and mining agricultural knowledge from agricultural production big data. However,
    the whole process generates a large amount of agricultural data sensing and transmission,
    which requires concurrent and real-time multitasking of large amounts of data
    under edge cloud constraints. There is an urgent need for research on edge computing
    technologies under autonomous farm vehicle networks to enhance concurrent and
    realtime multitasking of massive farm machine data during busy periods of agricultural
    operations. This process will focus on the agricultural management aspects of
    rice, corn, wheat and other Crops, using multi-source heterogeneous agricultural
    data fusion technology to aggregate and classify, analyze and mine multi-dimensional
    data of agricultural production, and improve the real-time and information utilization
    rate of extracting, fusing and mining agricultural knowledge from agricultural
    production big data Conclusion And Future Work In this article, we gave a taxonomy
    of the autonomous building blocks for farm vehicles and technical challenges for
    achieving them. In addition, we present a SAGIN architecture for autonomous farm
    vehicles to meet the needs of comprehensive network coverage, and flexible networking.
    Besides, the primary challenges faced by edge computing are addressed and we conduct
    experiments on diverse multi-models on various GPU platforms. The results show
    that our edge intelligent scheduling framework as a significant overall performance
    gain on various GPU platforms compared with the baseline inference frameworks.
    Future work is in progress to consider autonomous agricultural vehicles oriented
    to achieve concurrent real-time processing and precise control under edge-cloud
    constraints. ACKNOWLEDGMENTS This work is partly supported by the National Key
    R&D Program of China under Grant No.2021Zd0110905, the Programs for Science and
    Technology Development of Heilongjiang Province under Grant No.2021Zxj05a03, the
    China Postdoctoral Science Foundation under Grant No.2022TQ0091 and No.2022M720958,
    the Key R&D Program of Heilongjiang Province under Grant No.2022zx01A23 and No.2022zx01A25,
    the National Natural Science Foundation of China under Grant No.61972114. Authors
    Figures References Keywords Metrics More Like This Hierarchical Domain-Based Multicontroller
    Deployment Strategy in SDN-Enabled Space–Air–Ground Integrated Network IEEE Transactions
    on Aerospace and Electronic Systems Published: 2022 Dynamic SFC Embedding Algorithm
    Assisted by Federated Learning in Space–Air–Ground-Integrated Network Resource
    Allocation Scenario IEEE Internet of Things Journal Published: 2023 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Network
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Networked Edge Intelligence for Autonomous Farm Vehicles
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Morales-García J.
  - Bueno-Crespo A.
  - Martínez-España R.
  - García F.J.
  - Ros S.
  - Fernández-Pedauyé J.
  - Cecilia J.M.
  citation_count: '2'
  description: Precision agriculture generates large datasets from IoT infrastructures
    deployed for continuous crop monitoring. This data requires analysis to usefully
    transform this data deluge into insights that can deliver value-generating services
    to farmers in a timely manner. This paper introduces SEPARATE; a dynamic interoperable
    and decentralized infrastructure for executing both, training and inference stages
    of deep learning (DL) algorithms in smart agriculture scenarios. The presented
    infrastructure allows the execution of the inference stage at the edge, achieving
    a highly efficient and responsive local temperature prediction service to take
    actions based on the predictions generated. Moreover, the training stage is offloaded
    to the cloud along with the generated historical data, allowing the trained model
    to be periodically updated at the edge. On the one hand, our results show that
    the Convolutional Neural Network model together with the Long Short-Term Memory
    technique (CNNLSTM) obtains the best results in both prediction accuracy and computational
    time. On the other hand, an analysis has been carried out to determine how often
    the model must be retrained, obtaining results that indicate that from day 9–10,
    it would be necessary to retrain the model, although, until day 20, the precision
    is not greatly reduced. Moreover, the SEPARATE infrastructure enables the execution
    of real-time inference from sensor-generated data and seamless model retraining
    in an operational greenhouse for temperature forecast with satisfactory performance.
  doi: 10.1016/j.iot.2023.100734
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords 1. Introduction 2. Related works 3. Materials
    and methods 4. Results 5. Discussion 6. Conclusions and future work CRediT authorship
    contribution statement Declaration of Competing Interest Funding Data availability
    References Show full outline Cited by (2) Figures (4) Tables (17) Table 1 Table
    2 Table 3 Table 4 Table 5 Table 6 Show all tables Internet of Things Volume 22,
    July 2023, 100734 Research article SEPARATE: A tightly coupled, seamless IoT infrastructure
    for deploying AI algorithms in smart agriculture environments Author links open
    overlay panel Juan Morales-García a, Andrés Bueno-Crespo a, Raquel Martínez-España
    b, Francisco J. García c, Sergio Ros c, Julio Fernández-Pedauyé d, José M. Cecilia
    d Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.iot.2023.100734
    Get rights and content Highlights • Precision agriculture needs to deploy infrastructures
    to make decisions. • A dynamic decentralized infrastructure to predict greenhouse
    temperature. • Machine Learning and Deep Learning techniques have been used for
    temperature prediction. • Assessment of the accuracy and performance of the infrastructure,
    in Edge and Cloud. • MQTT and Near Real Time are used in the infrastructure presented
    and evaluated. Abstract Precision agriculture generates large datasets from IoT
    infrastructures deployed for continuous crop monitoring. This data requires analysis
    to usefully transform this data deluge into insights that can deliver value-generating
    services to farmers in a timely manner. This paper introduces SEPARATE; a dynamic
    interoperable and decentralized infrastructure for executing both, training and
    inference stages of deep learning (DL) algorithms in smart agriculture scenarios.
    The presented infrastructure allows the execution of the inference stage at the
    edge, achieving a highly efficient and responsive local temperature prediction
    service to take actions based on the predictions generated. Moreover, the training
    stage is offloaded to the cloud along with the generated historical data, allowing
    the trained model to be periodically updated at the edge. On the one hand, our
    results show that the Convolutional Neural Network model together with the Long
    Short-Term Memory technique (CNNLSTM) obtains the best results in both prediction
    accuracy and computational time. On the other hand, an analysis has been carried
    out to determine how often the model must be retrained, obtaining results that
    indicate that from day 9–10, it would be necessary to retrain the model, although,
    until day 20, the precision is not greatly reduced. Moreover, the SEPARATE infrastructure
    enables the execution of real-time inference from sensor-generated data and seamless
    model retraining in an operational greenhouse for temperature forecast with satisfactory
    performance. Previous article in issue Next article in issue Keywords Publish/Subscribe
    infrastructureEdge computingMachine learningDeep learningInternet of ThingsSmart
    agriculture 1. Introduction Precision agriculture is increasingly making use of
    new technologies in order to improve profits and reduce costs [1]. In a globalized
    world where costs are increasing day by day, it is important to have autonomous
    systems that allow farmers to better control their crops [2]. Monitoring and anticipation
    in decision-making can save a lot of production costs and crop losses [3]. Greenhouses,
    due to their structure, allow crop control, both of growth, pests, and climatic
    variables that directly influence crop yields [4]. For this control, the devices
    and sensors provided by the Internet of Things (IoT) provide great versatility
    and convenience for efficient data capture. Current operational IoT solutions
    in the area of smart agriculture in real-world environments are mainly based on
    centralized IoT systems, where data is sent to a centralized cloud-based architecture,
    processed, and further analyzed [5]. However, agricultural environments are often
    located in rural areas where connectivity and power supply are limited [6]. Indeed,
    a dynamic, interoperable, and decentralized architecture is mandatory in these
    environments to achieve highly efficient and responsive data-based services. Some
    solutions have been proposed that bring the execution of machine learning (ML)
    and even deep learning (DL) algorithms close to the data capture, i.e. at the
    edge, in agricultural environments [7], [8], [9]. Edge computing [10] is becoming
    a widely used approach towards decentralization, where preliminary computations
    on data are carried out in (or close to) the data capture devices, providing a
    number of advantages, including energy savings, responsive application and service
    development, highly scalable, reliable and secure system design. However, computational
    devices that are available at the edge typically rely on batteries or energy harvesters,
    leading to ultra-low power designs, but also limiting the workloads to be executed
    on them. Actually, edge Computing is limited to the inference stage of Machine
    Learning/Deep Learning (ML/DL) algorithms in what is recently called TinyML [11].
    This makes sense because at this level of the IoT infrastructure, very little
    computational horsepower is available and thus computationally heavy workloads,
    such as those found at the training stage of ML/DL algorithm cannot be executed
    in a reasonable timeframe and with a manageable energy budget. However, training
    ML/DL algorithm periodically is mandatory to achieve more accurate results in
    these environments of rapidly changing conditions, so influenced by the abrupt
    changes brought about by climate change [12]. In this paper, we present SEPARATE;
    a seamless and tightly coupled IoT infrastructure for developing training and
    inference of ML/DL algorithms in operational smart agriculture environments. SEPARATE
    relies on a publish/subscribe (Pub/Sub) system based on Message Queuing Telemetry
    Transport (MQTT) protocol to perform data analytics at the edge of an IoT infrastructure
    deployed in an operational greenhouse located in Murcia (Spain). Particularly,
    the SEPARATE infrastructure receives information through MQTT from the air temperature
    sensors deployed inside the greenhouse that feed ML/DL models to predict the climatic
    state of the greenhouse in the following hours (i.e., inference stage). It is
    also important to study the need to retrain the prediction model to always have
    the best available precision without affecting response times. Moreover, SEPARATE
    also sends the data to the cloud via MQTT to store the historical data and thus
    to periodically retrain the model to be updated at the inference stage and thus
    provide a more accurate forecast. The main contributions of the paper include
    the following: 1. The SEPARATE infrastructure is introduced to provide an interoperable
    and decentralized dynamic architecture for ML/DL training and inference. 2. SEPARATE
    is designed for a real and operational IoT infrastructure. Our developments and
    tests have been carried out in an operational greenhouse deployed in Murcia (Spain)
    3. Different ML/DL models are considered in terms of execution time and accuracy
    to establish the best combination in the quality and performance tradeoff. 4.
    Study and analysis of the days needed to retrain the best model, without significantly
    losing precision. 5. SEPARATE offers an infrastructure not only for monitoring
    but also for predicting actions in advance, thanks to its prediction models for
    several hours ahead. The rest of the paper is organized as follows. Section 2
    shows related works within the umbrella of ML/DL as applied to Pub/Sub solutions
    in forecasting climatic variables in greenhouses. Section 3 describes in detail
    the different approaches proposed and the artificial intelligence methods used
    to compare an evaluate results. Section 4 shows the performance results for the
    Pub/Sub solution and for the artificial intelligence models before discussing
    them in Section 5. Finally, Section 6 presents the main conclusions and discusses
    future works. 2. Related works The MQTT communications protocol is increasingly
    being used in precision agriculture, replacing the HTTP protocol, [13]. Although
    the HTTP protocol uses a request/response architecture and HTTP can transfer a
    large number of data in small packets that can cause a large overhead. Therefore,
    due to this overhead, communication for IoT services via this protocol can cause
    serious bandwidth problems. Moreover, all HTTP calls are stateless, which leads
    to authentication every time you connect, as you connect to the IP or URL to make
    the REST API calls, the session is not saved and thus, after getting the response,
    the device closes the connection. This is due to possible network overload [14].
    In contrast, MQTT (Message Queue Telemetry Transport) is a lightweight protocol
    that is designed for the IoT ecosystem. It was invented by IBM, is based on the
    OSI TCP/IP model, and has a very lightweight application layer with a header size
    of 2 bytes. MQTT follows an asymmetric architecture and operates under the publish
    and subscribe protocol. It is designed to send a message to one or more devices
    with low latency but is not recommended for sending large amounts of data. Given
    its characteristics, it is very useful for use in IoT systems, since among its
    advantages we find the secure delivery of the message, thus avoiding the loss
    of data [15], [16]. Given the advantages of the MQTT protocol, it is increasingly
    used in IoT environments and in the world of precision agriculture. For instance,
    in [17] the authors propose a precision agriculture system based on wireless sensor
    networks with the MQTT protocol for monitoring and controlling the environmental
    conditions of a greenhouse by collecting information on humidity, temperature,
    light, and nutritional needs of the plants. In [18], the design and implementation
    of an intelligent irrigation system to automate the irrigation system in agricultural
    fields are proposed. The system is a near real-time system using the MQTT protocol
    for communications between the sensor side and the client side. The authors of
    [2] present an open-source platform covering automated precision agriculture scenarios.
    For this purpose, the platform is distributed on three levels, Cyber–Physical
    Systems, Edge computing, and Cloud. To connect the sensors and actuators with
    the end user, they use IoT technologies and protocols such as MQTT, the Constrained
    Application Protocol (CoAP), and FIWARE, among others. The platform is successfully
    tested in a hydroponic greenhouse. In [19], authors proposed the design of a remote
    monitoring and control system for greenhouses. The system uses IoT to collect
    greenhouse parameters such as temperature, relative humidity, and luminosity.
    After collecting the data and sending it to the server, the IoT polls the data
    on the internet through the MQTT protocol and compares it with existing parameters
    in order to send a correction to the greenhouse if necessary. A system for monitoring
    and controlling microclimatic parameters of a greenhouse is proposed in [20].
    In this case, the system collects temperature and humidity values as well as gas
    values. The data is sent through an Arduino to a raspberry via the MQTT protocol.
    Another aspect of agriculture where IoT systems and the MQTT protocol is also
    very useful is for the prevention and care of bees to avoid Colony Collapse Disorder,
    a disorder still under study. To obtain data for this study, in [21] the authors
    propose the design of a near real-time system that collects temperature, humidity,
    and weight data and sends it via MQTT to a ThingsBoard for analysis, the system
    called Beemon works continuously and in open-air hives. As can be seen, the proposed
    systems are used to monitor and control different agricultural systems, from different
    points of view. The difference with our proposal is that in our case, in addition
    to carrying out monitoring tasks, we also carry out advance prediction tasks,
    in order to take measures before any event occurs, thus achieving a better optimization
    of resources. 3. Materials and methods This section provides the materials and
    methods of the SEPARATE infrastructure. As previously mentioned, it provides an
    interoperable and decentralized dynamic architecture for ML/DL training and inference
    in an operational greenhouse. Therefore, we introduce the operational greenhouse
    where SEPARATE is deployed before providing to the reader the main insights of
    SEPARATE infrastructure. The case study here presented aims at forecasting the
    internal temperature of this greenhouse through different ML/DL methods that are
    also presented, showing the main parameters used for the evaluation carried out
    in the next section. 3.1. Operational greenhouse Fig. 1 shows the operational
    greenhouse targeted for this study, namely ETIFA. ETIFA is an operational greenhouse
    hosted by NUTRICONTROL; a Spanish leading company in developing automatic fertigation
    and Climate control technology. ETIFA is located in Murcia (South-eastern Spain),
    a semi-arid region where the average annual temperature is around 25 °C. This
    greenhouse has a surface area of 50 m2 and operates with a system for climate
    control and fertigation. Download : Download high-res image (746KB) Download :
    Download full-size image Fig. 1. Targeted operational greenhouse located at Murcia
    (Spain). ETIFA fertigation and climate control is carried out by NUTRICONTROL’s
    OPTIMUM system; a complete solution for climate management and fertigation of
    these environments. The NUTRICONTROL’s OPTIMUM system is orchestrated by a CPU-based
    node (OPTIMUM Orchestator, from now on) where all sensors (input/output) are plugged
    into in a modular way. Among the sensors available in ETIFA are temperature, humidity,
    radiation, and wind speed, just to name a few. Of particular interest to us is
    the air temperature inside the greenhouse as it is the target for the forecast
    carried out in this paper. This variable is measured every 5 min in the greenhouse,
    providing near-real-time (NRT) continuous measurements to take actions that can
    increase/decrease the greenhouse temperature to reach the ideal temperature of
    the crop being grown. 3.2. SEPARATE infrastructure The SEPARATE infrastructure
    relies on the MQTT standard protocol [22]. MQTT is a lightweight Pub/Sub messaging
    transport system where sensors can publish the generated data (e.g. temperature
    sensor) and several nodes can be subscribed to receive values in NRT. Fig. 2 shows
    the main SEPARATE building blocks that are deployed in the greenhouse. First,
    the MQTT broker or server, deployed in the OPTIMUM orchestrator, is responsible
    for dispatching messages between the sender (or publisher) and the appropriate
    receivers. SEPARATE is based on Java-based open source HIVEMQ Community Edition
    (CE).1 Download : Download high-res image (187KB) Download : Download full-size
    image Fig. 2. SEPARATE main building blocks based on MQTT schema. MQTT clients
    are subscribed to and publish information on a particular topic. In our case,
    the MQTT client is developed using the Eclipse Paho MQTT Python client library
    [23] that enables applications to connect to an MQTT broker to publish messages
    and to subscribe to topics and receive published messages. SEPARATE infrastructure
    is based on three MQTT clients. The first client is hosted in the OPTIMUM orchestrator
    and publishes data to the topic “Temperature” from the greenhouse as soon as it
    is received from the sensors. The second and third clients are subscribed to the
    same topic but are deployed in different computing nodes, depending on the task
    associated with each of them. The second MQTT client is deployed on an Nvidia
    Jetson Nano in the greenhouse; very close to the capture node, i.e. at the edge.
    This client is designed to run the ML/DL inference of the model to forecast the
    indoor temperature of the greenhouse for the next few hours. In this way, the
    MQTT client periodically receives the data temperature that is stored in a CSV
    file in the Jetson Nano. Another background process (i.e. cron job) runs the model
    inference every set time frame (e.g., every 15 min), which collects the information
    gathered by the MQTT client and generates the prediction. It is important to note
    that each time frame, the ML/DL inference is executed taking into account the
    last updated data generated by the greenhouse and thus more accurate predictions
    should be generated using these new records. The last MQTT client is deployed
    in a cloud server hosted in our lab at UPV. This MQTT client is also subscribed
    to “Temperature” topic and once data is received from this topic, this cloud-based
    MQTT client stores it in an InfluxDB database where historical data is increasingly
    generated. On this cloud-based server, data quality controls, sanitization processes,
    etc. are carried out to prepare the data for an efficient training procedure.
    It is important to note that the training procedure does not need to be carried
    out on a sub-daily basis or even a daily basis. This is indeed a configuration
    parameter that is set according to the computational and accuracy tradeoff. In
    preliminary evaluations conducted in the particular context of the ETIFA greenhouse,
    it has been empirically observed that trained models give predictions at the inference
    stage within the same quality range as models trained with data from up to a month
    before. However, important differences in the forecast accuracy start to become
    relevant if ML/DL models are trained with data of more than a month before the
    horizon is predicted. Depending on the application, the user may prefer a more
    conservative scenario and retrain more frequently to obtain the most accurate
    results, or be more computationally efficient and only train when significant
    differences in the results are really noticeable. It is worth noting that training
    the heavier ML/DL ETIFA models can take several computational days, as it will
    be shown in Section 4.2. In any case, the model will be trained on the cloud server,
    and once trained, SEPARATE has to provide a mechanism to update the model trained
    on the edge in a transparent way to the user. The chosen way has been to enable
    a REST endpoint where a process on the edge node can update the model periodically.
    In our case, a month has been set by default although this can be easily changed
    in the configuration schema. 3.3. Datasets For the evaluation of the accuracy
    of the AI models, two different representative points of the year have been taken
    into account; i.e. winter and summer. This dichotomy is due to the fact that these
    are the two points at which the climatological variables (and their behavior)
    differ the most. Moreover, data time granularity has been also considered for
    the evaluation, i.e., the data are grouped into 15 min, 30 min, and 60 min periods.
    In this way, we can verify that (1) the model fits the data correctly, (2) it
    is able to predict at any point of the year and (3) that different time granularity
    can be applied depending on the needs of the problem. Finally, short-term (12
    h) and long-term (24 h) prediction has also been taken into account. Table 1 summarizes
    the description of the datasets that have been used to carry out the temperature
    prediction. It shows the start date of the data, the end date, and the number
    of instances contained in each dataset. Each dataset contains the temperature
    values of a greenhouse between the indicated dates, distinguishing whether the
    dataset ends on a summer or winter day. It is important to clarify that in southeastern
    Spain, June temperatures are already summer temperatures. Table 1. Dataset description.
    Datasets Start date End date # Instances CLEAN-DS-15-SUMMER 18-12-18 06-06-21
    86544 CLEAN-DS-15-WINTER 18-12-18 17-01-21 73104 CLEAN-DS-30-SUMMER 18-12-18 06-06-21
    43273 CLEAN-DS-30-WINTER 18-12-18 17-01-21 36553 CLEAN-DS-60-SUMMER 18-12-18 06-06-21
    21637 CLEAN-DS-60-WINTER 18-12-18 17-01-21 18277 DIRTY-DS-15-SUMMER 18-12-18 06-06-21
    86544 DIRTY-DS-15-WINTER 18-12-18 17-01-21 73104 DIRTY-DS-30-SUMMER 18-12-18 06-06-21
    43273 DIRTY-DS-30-WINTER 18-12-18 17-01-21 36553 DIRTY-DS-60-SUMMER 18-12-18 06-06-21
    21637 DIRTY-DS-60-WINTER 18-12-18 17-01-21 18277 SMOOTH-DS-15-SUMMER 18-12-18
    06-06-21 86544 SMOOTH-DS-15-WINTER 18-12-18 17-01-21 73104 SMOOTH-DS-30-SUMMER
    18-12-18 06-06-21 43273 SMOOTH-DS-30-WINTER 18-12-18 17-01-21 36553 SMOOTH-DS-60-SUMMER
    18-12-18 06-06-21 21637 SMOOTH-DS-60-WINTER 18-12-18 17-01-21 18277 3.4. Artificial
    Intelligence models This section introduces four ML/DL models that have been used
    for the evaluation of SEPARATE. We refer the reader to [24] for insights. • Artificial
    Neural Networks (ANN): A neural network is a model that mimics the way a set of
    biological neurons works. Although its use in classification is more widespread,
    it can also be used in regression models. A single perceptron (or artificial neuron)
    can be imagined as a logistic regression. The artificial neural network, or ANN,
    is a group of multiple perceptrons in each layer forming a multilayer perceptron
    (MLP). The MLP we use in this work is composed of three layers: input, hidden,
    and output. The input layer receives the input features, the hidden layer processes
    the inputs and the output layer produces the output. Essentially, each layer tries
    to learn certain weights. Artificial neural networks have the ability to learn
    any complex relationship between input and output because they use an activation
    function that allows them to learn non-linear properties in the network. [25],
    [26]. • Convolutional Neural Network (CNN): Convolutional neural network models
    are used in different applications and domains, where they are most frequently
    used in imaging for classification. However, they are also used in regression,
    where they can be used using time series by transforming the data to adapt them
    to the inputs of the convolutional network. A CNN is made up of blocks of filters,
    which, through convolution operations, allow the relevant features to be extracted
    from the input. One of the advantages of CNNs over conventional neural networks
    (ANNs) is the automatic learning of the filters so that the necessary and most
    relevant features are obtained from the input data. [27]. • Long Short-Term Memory
    (LSTM): this model of DL is commonly used because in addition to working with
    time series like recurrent models, but with the advantage that this network allows
    for long-term memory. LSTM is a type of recurrent neural architecture with a state
    memory and multilayer cell structure [28]. LSTM unit is composed of a cell, an
    input gate, an output gate, and a forget gate (Fig. 3, only the LSTM layer). The
    cell remembers values over arbitrary time intervals and the three gates regulate
    the flow of information into and out of the cell. The LSTM differs from a classic
    recurrent network in that it does not overwrite its content at each time step
    but is able to decide whether to keep the existing memory through the introduced
    doors. If the LSTM unit detects an important characteristic of an input sequence
    at an early stage, it carries this information over long distances, therefore
    it detects long-distance dependencies. • Convolutional Neural Network + Long Short-Term
    Memory (CNNLSTM): This model is a combination of CNN and LSTM (also known as ConvLSTM).
    It presents a convolutional network where the MLP layer fully connected to the
    final layer has been replaced by an LSTM network. Therefore, the CNN is in charge
    of automatically extracting the input features and the LSTM is in charge of obtaining
    the regression results (see Fig. 3). Table 2 shows all hyperparameters (rows)
    used for each model (columns). A brief description of the meaning of each hyperparameter
    is given below: Download : Download high-res image (264KB) Download : Download
    full-size image Fig. 3. Model CNNLSTM. In the first stage, the convolutional layer
    is in charge of extracting the feature vector so that finally the LSTM layer performs
    the forecast. • Units: Number of neurons used in hidden layers. • Filters: Features
    detector. • Kernel size: Filters matrix used to extract the features from the
    dataset. • Strides: Number of pixels shifts over the input matrix. • Activation
    function: Function that decides if a neuron should be (or not) activated. • Batch
    size: Size of bach used for training/forecasting. • Epochs: Number of epoch used
    in training. • Optimizer: Function that optimizes the learning of an artificial
    intelligence model, updating its neurons’ weights depending on the error evaluation.
    • Loss function: Function used to evaluate the error of the model in each epoch.
    • Learning rate: Percentage change with which weights are updated at each iteration.
    Table 2. Hyperparameters used for each model. A dash in a cell indicates that
    the model does not have that parameter. Hyperparameter MLP CNN LSTM CNNLSTM Units
    70 – 70 – Filters – 64 – 64 Kernel size – 1 – 2 Strides – 1 – 4 Activation function
    Tanh Tanh Tanh Tanh Batch size 2880 2880 2880 2880 Epochs (＋ EarlyStopping) 3000
    3000 3000 3000 Optimizer Adam Adam Adam Adam Loss function MSE MSE MSE MSE Learning
    rate (＋ ReduceLROnPlateau) 0.003 0.003 0.003 0.003 4. Results This section shows
    the results of the different experiments that have been carried out. They can
    be divided into two main sets. On one side, an experiment is proposed to evaluate
    the effectiveness of the NRT system based on SEPARATE (see Section 4.1). While,
    on the other side, an experiment will be proposed to evaluate the accuracy of
    ML/DL models in an NRT environment (see Section 4.2). In addition, a study is
    carried out on the need to retrain the model from time to time so as not to lose
    precision in the predictions. These results are broadly discussed in Section 5.
    4.1. Pub/Sub solution evaluation In the following, the execution time on HPC and
    edge computing platforms for training and inference of ML/DL techniques is shown
    and analyzed individually. This experiment leads us to argue the computational
    differences between the two devices and the need for SEPARATE to coordinate training
    and inference in this context. 4.1.1. HPC evaluation The HPC computing node is
    evaluated by running the training and inference for the different ML/DL models
    described in Section 3.4. This node is composed of an AMD EPYC 7282, 64 CPUs (2
    sockets 16 cores per socket 2 threads per core) at 2.8 MHz for each core. Moreover,
    it also contains two NVIDIA A100-PCIE-40 GB (Tesla architecture) and it is endowed
    with up to 256 GB and 2 TB SSD. Tables 3, 4, 5, 6 show the MLP, CNN, LSTM and
    CNNLSTM execution time on the HPC server targeted for the multicore CPU or a GPU,
    respectively. Each row of the table represents the performance times for each
    of the datasets described in Section 3.3. Each column of the table represents
    the performance times studied and is grouped into training and inference, for
    each of the two platforms studied (CPU and GPU). For inference, a distinction
    is made between 12 h and 24 h inference. In particular, Table 3 shows that the
    MLP training time on CPU range from 263.945 to 729.050 s, while on GPU they range
    from 241.099 to 500.245 s, obtaining up to 1.5X performance in the best scenario.
    Inference times are almost identical on both CPU and GPU, being a few milliseconds
    slower on GPU, and ranging between 0.592 and 5.022 s. Regarding the inference
    between 12 and 24 h, there is practically no difference, since the 24 h time is
    practically twice as long as the 12 h time, which is consistent since twice as
    many values are inferred. Table 3. Execution time in seconds obtained by running
    the MLP model on CPU and GPU included in the HPC server platform. Execution time
    of training and inference (12 h and 24 h) are provided. Platform CPU GPU Times
    Training Inference Training Inference Dataset Empty Cell 12 h 24 h Empty Cell
    12 h 24 h CLEAN-DS-15-SUMMER 713.861 2.276 4.472 500.245 2.470 4.862 CLEAN-DS-15-WINTER
    628.725 2.246 4.737 445.597 2.428 5.022 CLEAN-DS-30-SUMMER 390.665 1.169 2.266
    311.396 1.246 2.419 CLEAN-DS-30-WINTER 358.576 1.165 2.253 293.535 1.252 2.410
    CLEAN-DS-60-SUMMER 275.897 0.604 1.151 248.403 0.629 1.194 CLEAN-DS-60-WINTER
    264.678 0.596 1.113 241.099 0.637 1.193 DIRTY-DS-15-SUMMER 699.936 2.290 4.514
    494.385 2.425 4.900 DIRTY-DS-15-WINTER 645.416 2.374 4.615 440.965 2.472 4.828
    DIRTY-DS-30-SUMMER 388.948 1.164 2.243 311.467 1.248 2.406 DIRTY-DS-30-WINTER
    354.699 1.159 2.250 294.019 1.226 2.388 DIRTY-DS-60-SUMMER 276.120 0.596 1.146
    248.354 0.644 1.197 DIRTY-DS-60-WINTER 264.019 0.591 1.138 242.394 0.648 1.207
    SMOOTH-DS-15-SUMMER 729.050 2.490 4.512 491.324 2.639 4.817 SMOOTH-DS-15-WINTER
    633.765 2.321 4.570 452.423 2.403 4.809 SMOOTH-DS-30-SUMMER 392.934 1.155 2.594
    308.026 1.240 2.685 SMOOTH-DS-30-WINTER 358.637 1.155 2.254 293.757 1.235 2.395
    SMOOTH-DS-60-SUMMER 274.794 0.595 1.124 247.762 0.627 1.205 SMOOTH-DS-60-WINTER
    263.945 0.600 1.152 242.576 0.642 1.222 Table 4 shows that the CNN training time
    on CPU range from 2,089.193 to 33,877.128 s, while on GPU they range from 275.392
    to 755.894 s, obtaining up to 10X performance in the best-case scenario. Inference
    times are almost identical on both CPU and GPU, being a few milliseconds slower
    on GPU, and ranging between 0.571 and 5.166 s. Table 4. Execution time in seconds
    obtained by running the CNN model on CPU and GPU included in the HPC server platform.
    Execution time of training and inference (12 h and 24 h) are provided. Platform
    CPU GPU Times Training Inference Training Inference Dataset Empty Cell 12 h 24
    h Empty Cell 12 h 24 h CLEAN-DS-15-SUMMER 33807.923 2.316 4.507 749.809 2.436
    4.839 CLEAN-DS-15-WINTER 27835.258 2.348 4.509 660.638 2.463 4.822 CLEAN-DS-30-SUMMER
    8460.801 1.192 2.518 404.968 1.236 2.716 CLEAN-DS-30-WINTER 7237.790 1.175 2.223
    384.064 1.249 2.384 CLEAN-DS-60-SUMMER 2454.417 0.616 1.122 298.052 0.684 1.232
    CLEAN-DS-60-WINTER 2119.112 0.580 1.121 286.328 0.658 1.210 DIRTY-DS-15-SUMMER
    33613.773 2.309 4.503 755.894 2.434 4.778 DIRTY-DS-15-WINTER 28009.784 2.405 4.575
    667.642 6.271 4.811 DIRTY-DS-30-SUMMER 8423.981 1.189 2.234 408.309 1.241 2.376
    DIRTY-DS-30-WINTER 7239.152 1.192 2.246 399.793 6.606 2.426 DIRTY-DS-60-SUMMER
    2463.910 0.628 1.145 299.358 0.658 1.221 DIRTY-DS-60-WINTER 2089.193 0.607 1.110
    299.714 6.090 1.211 SMOOTH-DS-15-SUMMER 33877.128 2.323 4.477 741.246 2.475 4.776
    SMOOTH-DS-15-WINTER 27866.877 2.318 4.943 666.987 2.503 5.166 SMOOTH-DS-30-SUMMER
    8456.179 1.165 2.284 400.301 1.265 2.383 SMOOTH-DS-30-WINTER 7228.456 1.454 2.317
    377.420 1.669 2.397 SMOOTH-DS-60-SUMMER 2456.905 0.571 1.140 289.699 0.661 1.203
    Table 5 shows that the LSTM training time on CPU range from 7,821.983 to 148,153.696
    s, while on GPU they range from 446.884 to 3,419.390 s, obtaining a  15X performance.
    Inference times are almost identical on both CPU and GPU, being a few milliseconds
    slower on CPU, and ranging between 1.003 and 6.020 s. Table 5. Execution time
    in seconds obtained by running the LSTM model on CPU and GPU included in the HPC
    server platform. Execution time of training and inference (12 h and 24 h) are
    provided. Platform CPU GPU Times Training Inference Training Inference Dataset
    Empty Cell 12 h 24 h Empty Cell 12 h 24 h CLEAN-DS-15-SUMMER 147642.328 3.290
    5.605 3362.940 2.966 5.262 CLEAN-DS-15-WINTER 125425.139 3.363 5.973 2931.164
    2.974 5.536 CLEAN-DS-30-SUMMER 37469.883 1.751 2.643 1136.169 1.634 2.467 CLEAN-DS-30-WINTER
    31228.075 1.723 2.963 1001.663 1.633 2.887 CLEAN-DS-60-SUMMER 8983.771 1.003 1.159
    481.747 1.013 1.219 CLEAN-DS-60-WINTER 7821.983 1.015 1.194 446.884 1.015 1.216
    DIRTY-DS-15-SUMMER 147086.625 3.582 5.778 3419.389 3.284 5.173 DIRTY-DS-15-WINTER
    125981.805 3.363 5.688 2988.742 3.048 5.275 DIRTY-DS-30-SUMMER 37478.132 1.706
    2.496 1132.158 1.636 2.488 DIRTY-DS-30-WINTER 31363.002 1.721 2.576 998.420 1.639
    2.460 DIRTY-DS-60-SUMMER 8994.831 1.025 1.581 479.596 1.018 1.749 DIRTY-DS-60-WINTER
    7892.433 1.412 1.211 446.892 1.431 1.176 SMOOTH-DS-15-SUMMER 148153.696 3.290
    5.654 3414.785 3.018 5.227 SMOOTH-DS-15-WINTER 126536.579 3.307 6.020 2991.940
    3.291 5.263 SMOOTH-DS-30-SUMMER 37245.633 1.729 2.482 1122.942 1.630 2.467 SMOOTH-DS-30-WINTER
    31630.357 1.705 2.617 1003.449 1.633 2.486 SMOOTH-DS-60-SUMMER 8994.010 1.014
    1.189 482.858 1.007 1.227 SMOOTH-DS-60-WINTER 7841.688 1.020 1.195 448.608 1.029
    1.217 Finally, Table 6 shows that the CNNLSTM training time on CPU range from
    1,831.9153 to 31,471.342, while on GPU they range from 323.845 to 890.787, obtaining
    up to 20X performance. Inference times are almost identical on both CPU and GPU,
    being a few milliseconds slower on GPU, and ranging between 0.969 and 5.049. Table
    6. Execution time in seconds obtained by running the CNNLSTM model on CPU and
    GPU included in the HPC server platform. Execution time of training and inference
    (12 h and 24 h) are provided. Platform CPU GPU Times Training Inference Training
    Inference Dataset Empty Cell 12 h 24 h Empty Cell 12 h 24 h CLEAN-DS-15-SUMMER
    31455.494 2.759 4.599 871.329 2.872 4.850 CLEAN-DS-15-WINTER 26227.227 3.148 4.683
    775.974 3.189 4.841 CLEAN-DS-30-SUMMER 7883.942 1.588 2.300 487.813 1.647 2.420
    CLEAN-DS-30-WINTER 6752.098 1.589 2.707 447.680 1.656 2.877 CLEAN-DS-60-SUMMER
    2222.535 1.000 1.616 350.630 1.048 1.777 CLEAN-DS-60-WINTER 1920.816 1.009 1.125
    334.212 1.039 1.212 DIRTY-DS-15-SUMMER 31329.182 2.778 4.611 868.439 2.871 4.855
    DIRTY-DS-15-WINTER 26049.698 2.797 4.798 890.787 6.681 5.049 DIRTY-DS-30-SUMMER
    7960.443 1.555 2.249 484.462 1.635 2.418 DIRTY-DS-30-WINTER 6788.469 1.606 2.245
    467.469 6.823 2.415 DIRTY-DS-60-SUMMER 2221.137 0.969 1.060 351.492 1.041 1.203
    DIRTY-DS-60-WINTER 1929.761 0.973 1.133 346.623 6.078 1.209 SMOOTH-DS-15-SUMMER
    31471.342 2.731 4.541 852.136 2.853 4.848 SMOOTH-DS-15-WINTER 26336.821 2.713
    4.564 767.090 2.843 4.803 SMOOTH-DS-30-SUMMER 7924.806 1.596 2.251 476.830 1.656
    2.404 SMOOTH-DS-30-WINTER 6765.339 1.584 2.259 441.828 1.651 2.420 SMOOTH-DS-60-SUMMER
    2222.474 1.011 1.147 343.871 1.030 1.199 SMOOTH-DS-60-WINTER 1831.915 0.999 1.142
    323.847 1.042 1.202 In conclusion for the 4 models run on the server, we have
    that the GPU execution for training is much faster between 1.5 and 20x at best.
    The speed difference between CPU and GPU increases when the model is more complex,
    the complexity hierarchy being MLP, CNN, LSTM, and CNNLSTM models. In the case
    of inference, the same situation occurs for all four models, i.e., execution on
    the CPU is slightly faster than on the GPU. This has a logical explanation since
    in the case of inference, no large computational power is needed. 4.1.2. Edge
    evaluation The edge computing platform is evaluated by only running the inference
    for the different ML/DL models described in Section 3.4. In SEPARATE, only ML/DL
    inference is executed at this level of the infrastructure, as training is computationally
    forbidden. It is worth highlighting that the edge computing node is an Nvidia
    Jetson Nano that has a 5-core ARM Cortex-A57 MPCore CPU, 2MB L2, 128-core Maxwell
    GPU, and 4 GB 64-Bit LPDDR4 running at 25.6 GB/sec. Therefore, the CPU and GPU
    runs are analyzed to find out whether the inclusion of GPUs brings better performance
    results to inference in this scenario. Moreover, SEPARATE will send the ML/DL
    model into the edge device to proceed with the inference with the more updated
    model. Therefore, the execution time of loading an ML/DL model in the edge device
    once it is received is also reported below. Tables 7, 8, 9, 10 show the MLP, CNN,
    LSTM and CNNLSTM execution time at the edge of both, the Load and Inference stages
    of the SEPARATE pipeline, respectively. Each row of the table shows the performance
    times for each of the datasets described in Section 3.3. Each column shows the
    execution times for these stages, for each of the two processors studied; i.e.
    CPU and GPU. In particular, Table 7 shows that the MLP load time is almost identical
    on both CPU and GPU, being a few seconds slower on GPU, and ranging between 0.151
    and 5.731 s. Inference time reported is also almost identical on both CPU and
    GPU, being a few seconds slower on GPU, and ranging between 2.351 and 20.356 s.
    Table 7. Execution time in seconds obtained by running the MLP model on CPU and
    GPU included in the edge computing platform. Times for a load of the ML model
    (Load) and execute the inference for the next 12 and 24 h (Inference) are provided.
    Platform CPU GPU Times Load Inference Load Inference Dataset Empty Cell 12 h 24
    h Empty Cell 12 h 24 h CLEAN-DS-15-SUMMER 0.154 9.364 19.212 0.199 9.912 20.136
    CLEAN-DS-15-WINTER 0.155 9.192 18.792 0.275 10.069 20.088 CLEAN-DS-30-SUMMER 0.175
    5.343 8.938 0.204 5.549 9.851 CLEAN-DS-30-WINTER 0.161 4.851 9.566 0.203 5.208
    10.657 CLEAN-DS-60-SUMMER 0.192 2.817 4.787 0.251 3.124 4.839 CLEAN-DS-60-WINTER
    0.167 2.326 4.525 0.270 2.684 4.902 DIRTY-DS-15-SUMMER 0.158 9.546 18.579 0.229
    9.904 20.016 DIRTY-DS-15-WINTER 0.346 9.774 18.604 5.731 12.104 19.646 DIRTY-DS-30-SUMMER
    0.151 4.655 9.667 0.234 4.383 10.310 DIRTY-DS-30-WINTER 0.153 4.469 8.719 0.244
    5.389 9.983 DIRTY-DS-60-SUMMER 0.171 2.351 4.687 0.244 2.570 4.972 DIRTY-DS-60-WINTER
    0.158 2.752 4.458 0.295 3.159 4.573 SMOOTH-DS-15-SUMMER 0.154 8.975 18.901 0.235
    10.259 19.969 SMOOTH-DS-15-WINTER 0.156 8.774 18.566 0.211 9.967 20.356 SMOOTH-DS-30-SUMMER
    0.153 4.478 9.508 0.242 5.056 10.472 SMOOTH-DS-30-WINTER 0.154 4.924 9.586 0.490
    5.513 9.406 SMOOTH-DS-60-SUMMER 0.180 2.388 5.244 0.238 2.604 5.339 SMOOTH-DS-60-WINTER
    0.165 2.357 4.788 0.360 2.757 4.674 Table 8 shows that the CNN load time is almost
    identical on both CPU and GPU, being a few seconds slower on GPU, and ranging
    between 0.273 and 17.968 s. Inference time is almost identical on both CPU and
    GPU, being a few seconds slower on GPU, and ranging between 2.320 and 21.107 s.
    Table 8. Execution time in seconds obtained by running the CNN model on CPU and
    GPU included in the edge computing platform. Times for load of the DL model (Load)
    and execute the inference for the next 12 and 24 h (Inference) are provided. Platform
    CPU GPU Times Load Inference Load Inference Dataset Empty Cell 12 h 24 h Empty
    Cell 12 h 24 h CLEAN-DS-15-SUMMER 0.325 8.800 18.192 0.478 10.054 20.270 CLEAN-DS-15-WINTER
    0.342 9.286 17.946 0.755 11.147 21.107 CLEAN-DS-30-SUMMER 0.273 4.806 9.560 0.405
    5.257 10.004 CLEAN-DS-30-WINTER 0.278 4.509 8.893 0.417 5.002 9.567 CLEAN-DS-60-SUMMER
    0.315 2.490 4.335 0.477 2.765 4.895 CLEAN-DS-60-WINTER 0.360 2.320 4.559 0.605
    2.762 4.682 DIRTY-DS-15-SUMMER 0.403 9.511 18.579 0.569 10.436 20.527 DIRTY-DS-15-WINTER
    0.739 9.745 18.280 9.830 28.747 20.656 DIRTY-DS-30-SUMMER 0.291 4.667 8.889 0.449
    5.021 9.796 DIRTY-DS-30-WINTER 0.298 4.996 8.801 0.403 6.086 10.305 DIRTY-DS-60-SUMMER
    0.269 2.843 4.683 0.574 3.293 4.727 DIRTY-DS-60-WINTER 0.364 2.555 4.509 0.656
    3.234 4.935 SMOOTH-DS-15-SUMMER 0.325 9.843 17.758 17.968 10.806 20.851 SMOOTH-DS-15-WINTER
    0.329 9.231 18.090 0.501 10.118 20.274 SMOOTH-DS-30-SUMMER 0.280 4.710 8.680 0.415
    4.844 9.917 SMOOTH-DS-30-WINTER 0.320 5.105 8.919 0.400 5.556 9.913 SMOOTH-DS-60-SUMMER
    0.367 2.439 4.605 0.424 2.740 4.653 SMOOTH-DS-60-WINTER 0.328 2.397 4.514 0.459
    2.710 4.869 Table 9 shows that the LSTM load time is almost identical on both
    CPU and GPU, being a few seconds slower on GPU, and ranging between 1.457 and
    8.081 s. Inference time is almost identical on both CPU and GPU, being a few seconds
    slower on GPU, and ranging between 3.793 and 25.917 s. Table 9. Execution time
    in seconds obtained by running the LSTM model on CPU and GPU included in the edge
    computing platform. Times for load of the DL model (Load) and execute the inference
    for the next 12 and 24 h (Inference) are provided. Platform CPU GPU Times Load
    time Forecast time Load time Forecast time Dataset Empty Cell 12 h 24 h Empty
    Cell 12 h 24 h CLEAN-DS-15-SUMMER 2.053 13.656 25.046 2.073 12.615 22.895 CLEAN-DS-15-WINTER
    1.480 14.284 25.917 1.633 13.007 22.943 CLEAN-DS-30-SUMMER 2.294 6.581 10.545
    2.283 7.006 11.355 CLEAN-DS-30-WINTER 1.504 6.802 11.056 1.569 7.157 10.739 CLEAN-DS-60-SUMMER
    1.618 4.872 4.599 1.570 4.966 5.222 CLEAN-DS-60-WINTER 2.454 3.793 4.880 1.613
    5.176 5.203 DIRTY-DS-15-SUMMER 1.502 14.437 24.876 1.534 13.426 21.957 DIRTY-DS-15-WINTER
    2.070 14.355 24.823 8.081 25.461 22.661 DIRTY-DS-30-SUMMER 1.506 7.482 10.003
    1.573 8.090 11.177 DIRTY-DS-30-WINTER 2.077 7.024 10.135 1.515 7.820 10.758 DIRTY-DS-60-SUMMER
    1.477 4.200 4.978 1.540 4.272 5.305 DIRTY-DS-60-WINTER 1.457 3.919 4.540 1.566
    4.518 5.583 SMOOTH-DS-15-SUMMER 1.559 13.906 24.823 1.550 13.544 21.932 SMOOTH-DS-15-WINTER
    1.555 14.355 24.377 1.637 13.624 22.311 SMOOTH-DS-30-SUMMER 1.507 6.663 10.268
    1.558 7.152 10.994 SMOOTH-DS-30-WINTER 1.548 7.959 10.392 1.550 7.270 12.191 SMOOTH-DS-60-SUMMER
    1.534 4.005 5.018 1.528 4.376 5.483 SMOOTH-DS-60-WINTER 1.512 3.995 5.954 1.549
    4.337 5.452 Finally, Table 10 shows that the CNNLSTM load time is almost identical
    on both CPU and GPU, being a few seconds slower on GPU, and ranging between 1.648
    and 7.049 s. Inference time is almost identical on both CPU and GPU, being a few
    seconds slower on GPU, and ranging between 3.828 and 22.789 s. Table 10. Execution
    time in seconds obtained by running the CNNLSTM model on CPU and GPU included
    in the edge computing platform. Times for a load of the DL model (Load) and execute
    the inference for the next 12 and 24 h (Inference) are provided. Platform CPU
    GPU Times Load time Forecast time Load time Forecast time Dataset Empty Cell 12
    h 24 h Empty Cell 12 h 24 h CLEAN-DS-15-SUMMER 1.751 11.511 19.149 2.138 13.424
    22.707 CLEAN-DS-15-WINTER 1.914 12.009 19.610 3.977 13.725 22.218 CLEAN-DS-30-SUMMER
    1.669 6.858 9.166 1.964 7.403 11.114 CLEAN-DS-30-WINTER 1.648 6.579 9.989 1.895
    7.105 11.608 CLEAN-DS-60-SUMMER 1.816 4.299 4.529 1.829 4.519 5.147 CLEAN-DS-60-WINTER
    1.648 4.243 4.678 1.839 4.459 5.443 DIRTY-DS-15-SUMMER 1.912 12.158 19.096 2.009
    13.861 22.447 DIRTY-DS-15-WINTER 2.661 11.648 19.100 7.049 29.010 22.319 DIRTY-DS-30-SUMMER
    2.500 6.701 9.464 2.621 7.314 10.942 DIRTY-DS-30-WINTER 1.828 6.606 9.504 1.849
    7.761 10.723 DIRTY-DS-60-SUMMER 1.783 3.828 3.936 1.859 4.566 5.200 DIRTY-DS-60-WINTER
    1.706 4.142 4.628 1.901 5.065 5.188 SMOOTH-DS-15-SUMMER 1.732 11.807 19.284 1.970
    14.001 22.177 SMOOTH-DS-15-WINTER 1.722 12.143 19.633 2.066 13.849 22.789 SMOOTH-DS-30-SUMMER
    1.690 6.553 10.389 1.922 7.433 11.659 SMOOTH-DS-30-WINTER 1.781 7.347 9.390 1.889
    8.221 11.167 SMOOTH-DS-60-SUMMER 1.665 5.113 4.631 1.835 5.823 5.372 SMOOTH-DS-60-WINTER
    1.720 5.250 4.600 1.877 5.509 5.426 In conclusion, execution on the edge is slightly
    faster on the CPU than on the GPU for all 4 models tested. This result is consistent
    with the results shown above for the execution on the server. As inference is
    an inexpensive process, the computational power offered by the GPU is not necessary.
    Evidently, inference on the Edge is somewhat slower than on the server, but with
    completely acceptable times. 4.2. ML/DL models quality assessment This section
    shows the results obtained when all ML/DL techniques are used to forecast the
    internal temperature of the greenhouse. Several metrics are provided to analyze
    the goodness of fit of the models. They are the Root Mean Squared Error (RMSE)
    and the Mean Absolute Error (MAE) which shows the gap between the forecast and
    actual values. MAE and RMSE are calculated by averaging the absolute difference
    between the predicted and actual values. Moreover, we also provide the that shows
    the variance of the forecast variable that is predictable from the actual variable.
    These metrics are shown for all ML/DL models, temporal granularity, and different
    evaluation periods (i.e. SUMMER and WINTER). It is important to note that these
    values were obtained using the Python-based Scikit-Learn library. Table 11 shows
    the main quality figures achieved by the MLP model. This technique obtains the
    best result in MAE and RMSE with the CLEAN-DS-15-WINTER dataset for both 12 h
    and 24 h forecasts. The lowest MAE and RMSE is obtained with 12 h prediction with
    1.276 °C and 1.538 °C respectively. The difference with the 24 h prediction is
    very small for all the datasets evaluated in general. Table 11. Results of the
    MLP technique, values in sub-index indicate the standard deviation obtained after
    the repetition of each experiment. R (coefficient of determination) RMSE (root
    mean square error) MAE (mean absolute error). RMSE and MAE are measured in degrees
    Celsius (°C). Forecasting period 12 h 24 h Datasets R RMSE MAE R RMSE MAE CLEAN-DS-15-SUMMER
    0.5880.120 4.0440.287 3.7100.267 0.8060.053 3.3660.191 2.9320.201 CLEAN-DS-15-WINTER
    0.8380.038 1.5380.081 1.2760.093 0.8860.018 1.6430.088 1.2790.079 CLEAN-DS-30-SUMMER
    0.6260.119 3.7680.222 3.4340.260 0.8210.032 3.2420.232 2.8090.244 CLEAN-DS-30-WINTER
    0.8530.043 1.6340.141 1.4030.135 0.8910.027 1.7060.082 1.3480.062 CLEAN-DS-60-SUMMER
    0.8350.100 3.2420.286 2.9270.289 0.8780.043 3.3270.133 2.9620.151 CLEAN-DS-60-WINTER
    0.8300.024 1.7080.064 1.5060.066 0.8990.008 1.6540.027 1.3270.028 DIRTY-DS-15-SUMMER
    0.5650.147 3.9060.413 3.5280.405 0.7740.093 3.3010.291 2.8320.270 DIRTY-DS-15-WINTER
    0.8160.037 1.5190.117 1.2780.127 0.8760.012 1.5780.104 1.2620.094 DIRTY-DS-30-SUMMER
    0.6130.081 3.8580.255 3.5290.264 0.8210.034 3.1470.132 2.7010.113 DIRTY-DS-30-WINTER
    0.7870.052 1.7280.133 1.4880.117 0.8700.029 1.6770.102 1.3570.081 DIRTY-DS-60-SUMMER
    0.8190.075 3.1360.333 2.8330.354 0.8770.041 3.1540.355 2.8320.343 DIRTY-DS-60-WINTER
    0.8280.018 1.7370.073 1.5330.069 0.9000.008 1.6350.031 1.3220.038 SMOOTH-DS-15-SUMMER
    0.6850.149 3.7810.405 3.4940.374 0.8490.056 3.3870.196 2.9950.217 SMOOTH-DS-15-WINTER
    0.7900.065 1.5990.209 1.2970.232 0.8670.031 1.7410.125 1.3380.137 SMOOTH-DS-30-SUMMER
    0.7050.125 3.7750.358 3.4510.372 0.8550.039 3.3950.165 3.0000.139 SMOOTH-DS-30-WINTER
    0.7840.043 1.7630.182 1.4640.197 0.8750.021 1.8770.100 1.4560.087 SMOOTH-DS-60-SUMMER
    0.7480.077 3.4570.160 3.1710.143 0.8950.027 3.6620.227 3.2610.214 SMOOTH-DS-60-WINTER
    0.7220.040 2.0120.129 1.7330.158 0.8540.020 2.1270.065 1.7180.071 Table 12 reports
    the quality figures for the CNN technique. As with MLP, the results for the 12
    h and 24 h forecasts are quite similar. However, the best result is obtained with
    the DIRTY-DS-30-WINTER dataset with a MAE and RMSE of 1.252 °C and 1.492 °C. Contrary
    to the MLP technique, although with really little difference, the best result
    is obtained with a dataset without preprocessing. This makes sense as deep learning
    techniques are better able to remove possible noise in the data. Table 12. Results
    of the CNN technique, values in sub-index indicate the standard deviation obtained
    after the repetition of each experiment. R (coefficient of determination) RMSE
    (root mean square error) MAE (mean absolute error). RMSE and MAE are measured
    in degrees Celsius (°C). Forecasting period 12 h 24 h Datasets R RMSE MAE R RMSE
    MAE CLEAN-DS-15-SUMMER 0.7390.189 3.6050.286 3.2790.208 0.8670.044 3.0860.137
    2.6820.158 CLEAN-DS-15-WINTER 0.7890.224 1.7820.831 1.5450.855 0.8080.283 1.7870.753
    1.4630.753 CLEAN-DS-30-SUMMER 0.8150.174 3.4990.255 3.2340.194 0.8970.049 3.2670.052
    2.9060.100 CLEAN-DS-30-WINTER 0.7780.022 1.5490.126 1.2590.095 0.8760.010 1.6130.041
    1.2570.038 CLEAN-DS-60-SUMMER 0.8410.022 3.4750.070 3.2000.096 0.8590.008 3.3600.056
    3.0200.059 CLEAN-DS-60-WINTER 0.8290.013 1.7230.022 1.5030.025 0.8990.004 1.6270.012
    1.3110.014 DIRTY-DS-15-SUMMER 0.7990.102 3.3470.106 3.0140.153 0.8620.025 3.0340.174
    2.6420.162 DIRTY-DS-15-WINTER 0.7950.208 1.8340.782 1.5970.805 0.8080.282 1.8590.721
    1.5100.727 DIRTY-DS-30-SUMMER 0.8700.074 3.4310.187 3.1970.165 0.8980.040 3.1600.073
    2.8220.049 DIRTY-DS-30-WINTER 0.8140.025 1.4920.201 1.2520.210 0.8860.008 1.5390.102
    1.2220.098 DIRTY-DS-60-SUMMER 0.7890.029 3.5530.075 3.2990.088 0.8530.008 3.2490.046
    2.8900.056 DIRTY-DS-60-WINTER 0.8310.013 1.6660.027 1.4420.034 0.8980.005 1.6000.020
    1.2810.016 SMOOTH-DS-15-SUMMER 0.7450.160 3.5350.246 3.1610.269 0.8710.036 3.0260.166
    2.5980.214 SMOOTH-DS-15-WINTER 0.6810.310 2.0581.008 1.8181.044 0.7080.373 2.0640.955
    1.7300.958 SMOOTH-DS-30-SUMMER 0.7540.156 3.5300.182 3.2390.161 0.8930.053 3.3380.095
    2.9800.122 SMOOTH-DS-30-WINTER 0.7560.012 1.7450.095 1.4430.104 0.8630.004 1.7930.027
    1.4010.027 SMOOTH-DS-60-SUMMER 0.8460.018 3.4820.120 3.2490.135 0.9330.004 3.6170.080
    3.2490.062 SMOOTH-DS-60-WINTER 0.6960.012 2.0390.046 1.7520.050 0.8400.006 2.1570.019
    1.7450.017 Table 13 shows the results of the LSTM technique. This technique obtains
    a similar behavior to the previous deep learning techniques. In the overall tuning,
    there is no difference in the prediction at 12 or 24 h. Moreover, although the
    results are similar, this technique obtains slightly higher RMSE and MAE values
    than the other deep learning techniques discussed. The best results are obtained
    with the DIRTY-DS-60-WINTER dataset, where its MAE and RMSE are 1.294 °C and 1.554
    °C in 12 h prediction respectively. Table 13. Results of the LSTM technique, values
    in sub-index indicate the standard deviation obtained after the repetition of
    each experiment. R (coefficient of determination) RMSE (root mean square error)
    MAE (mean absolute error). RMSE and MAE are measured in degrees Celsius (°C).
    Prediction hours 12 h 24 h Datasets R RMSE MAE R RMSE MAE CLEAN-DS-15-SUMMER 0.6050.260
    3.6020.550 2.5010.242 0.5210.324 5.8191.225 4.7730.925 CLEAN-DS-15-WINTER 0.2570.057
    2.7850.043 2.0730.056 0.3230.058 3.9850.167 2.9670.064 CLEAN-DS-30-SUMMER 0.8360.052
    2.6580.209 2.2090.231 0.9120.035 2.8130.268 2.4510.229 CLEAN-DS-30-WINTER 0.7790.041
    1.7240.196 1.4000.185 0.8750.029 1.7190.124 1.3670.107 CLEAN-DS-60-SUMMER 0.8270.026
    2.7560.203 2.4010.270 0.9300.012 3.0000.192 2.6460.173 CLEAN-DS-60-WINTER 0.7960.022
    1.6550.154 1.3890.153 0.8930.010 1.6090.088 1.2580.079 DIRTY-DS-15-SUMMER 0.4810.234
    4.3241.610 3.1511.026 0.5300.234 6.6492.812 5.5182.373 DIRTY-DS-15-WINTER 0.2880.109
    3.0880.256 2.6110.353 0.3180.136 3.5160.408 2.9050.191 DIRTY-DS-30-SUMMER 0.8050.051
    2.6880.199 2.2750.214 0.9090.024 2.8030.216 2.4600.189 DIRTY-DS-30-WINTER 0.7510.077
    1.8850.375 1.5400.340 0.8570.054 1.7350.248 1.3660.217 DIRTY-DS-60-SUMMER 0.8020.030
    3.0000.199 2.6910.175 0.9270.009 2.8080.107 2.4660.136 DIRTY-DS-60-WINTER 0.7850.057
    1.5540.209 1.2940.171 0.8810.041 1.6560.102 1.3170.096 SMOOTH-DS-15-SUMMER 0.5500.269
    4.7712.427 3.6141.750 0.5620.171 6.4503.994 5.4263.485 SMOOTH-DS-15-WINTER 0.4010.116
    2.9360.544 2.5550.547 0.3850.026 3.2360.156 2.7880.203 SMOOTH-DS-30-SUMMER 0.7110.062
    3.2150.295 2.6890.219 0.8030.107 3.9680.947 3.3480.744 SMOOTH-DS-30-WINTER 0.6480.166
    2.1240.277 1.7440.198 0.7830.175 2.1150.592 1.6690.417 SMOOTH-DS-60-SUMMER 0.8330.019
    2.9820.084 2.6630.107 0.9340.008 3.4190.246 3.0290.224 SMOOTH-DS-60-WINTER 0.6650.027
    2.1020.115 1.7790.111 0.8230.016 2.1530.032 1.7310.039 Finally, Table 14 shows
    the quality figures of the CNNLSTM technique, which reports very similar results
    to the CNN technique. It follows the trend of obtaining very similar results for
    12 h and 24 h forecasts. Moreover, the best result is obtained with the DIRTY-DS-60-WINTER
    dataset. In this case, although also with little difference, the best result is
    obtained with the data without preprocessing. Specifically, the MAE and RMSE results
    are 1.200 °C and 1.357 °C respectively. Table 14. Results of the CNNLSTM technique,
    values in sub-index indicate the standard deviation obtained after the repetition
    of each experiment. R (coefficient of determination) RMSE (root mean square error)
    MAE (mean absolute error). RMSE and MAE are measured in degrees Celsius (°C).
    Prediction hours 12 h 24 h Datasets R RMSE MAE R RMSE MAE CLEAN-DS-15-SUMMER 0.7860.088
    3.3440.179 3.0140.203 0.8760.023 2.9470.321 2.5530.368 CLEAN-DS-15-WINTER 0.8750.023
    1.5270.185 1.3030.193 0.9230.008 1.4790.150 1.1930.110 CLEAN-DS-30-SUMMER 0.7940.106
    3.4830.251 3.2100.225 0.8600.051 3.2230.067 2.8430.079 CLEAN-DS-30-WINTER 0.8740.017
    1.5990.087 1.4010.091 0.9210.007 1.5950.035 1.2800.032 CLEAN-DS-60-SUMMER 0.9350.005
    3.1020.039 2.8670.058 0.9390.010 3.2910.063 2.9560.051 CLEAN-DS-60-WINTER 0.8760.003
    1.4410.023 1.2810.022 0.9300.001 1.5040.040 1.2200.018 DIRTY-DS-15-SUMMER 0.8270.045
    3.3810.222 3.0920.244 0.8630.024 2.9750.194 2.5950.196 DIRTY-DS-15-WINTER 0.8810.025
    1.5270.111 1.2950.124 0.9270.009 1.5940.120 1.2580.102 DIRTY-DS-30-SUMMER 0.8680.097
    3.3590.172 2.8870.298 0.8570.029 3.5750.364 3.1420.296 DIRTY-DS-30-WINTER 0.8770.009
    1.5750.052 1.3700.051 0.9260.003 1.5930.057 1.2670.040 DIRTY-DS-60-SUMMER 0.9370.004
    3.0930.038 2.8660.061 0.9420.004 3.2780.058 2.9520.053 DIRTY-DS-60-WINTER 0.8820.006
    1.3570.043 1.2000.048 0.9350.003 1.4040.018 1.1420.022 SMOOTH-DS-15-SUMMER 0.7140.079
    3.3580.315 2.9940.366 0.8440.104 2.9040.346 2.4570.335 SMOOTH-DS-15-WINTER 0.8480.038
    1.6300.199 1.4070.195 0.9040.016 1.5960.134 1.2830.107 SMOOTH-DS-30-SUMMER 0.7760.143
    3.5280.271 3.2530.242 0.8930.051 3.2810.062 2.9030.072 SMOOTH-DS-30-WINTER 0.7870.040
    1.7870.093 1.5060.119 0.8880.016 1.8320.062 1.4350.032 SMOOTH-DS-60-SUMMER 0.9060.012
    3.3690.050 3.1330.119 0.9470.008 3.7630.094 3.3750.067 SMOOTH-DS-60-WINTER 0.7150.015
    2.0100.051 1.7320.055 0.8540.008 2.1100.060 1.7240.033 4.3. Model retraining evaluation
    ML models require periodic retraining to improve the quality of predictions as
    new data is generated. However, these retrainings are quite computationally expensive,
    and that is why SEPARATE allows asynchronous communication with an HPC server
    that retrains the model and, once retrained, can be updated at the edge. The question
    here was how often it is necessary to perform these trainings. To analyze this
    point, the following tests have been carried out. First, the model has been trained
    using all the data from each dataset under study, except for the last 30 days.
    Subsequently, the model was tested with day 1, then day 2, then day 3, and so
    on until day 30. Independent tests were performed on each day, in order to visualize
    and analyze the impact of error and model fit as the days passed. The results
    of these tests indicate the maximum time that an ML/DL time series model can predict
    without retraining or loss of prediction quality. Although all techniques have
    similar performance, the one with the lowest error is the CNNLTSM, so this test
    has been performed with this technique. Fig. 4, Fig. 4 show and the mean of RMSE
    and MAE metrics for all targeted datasets. Particularly, Fig. 4(a) reports significant
    sharp differences testing 10, 16, 20, and 21 days respectively using metric. Fig.
    4(b) focuses on RMSE and MAE metrics and it can be seen that from days 9 and 10
    onwards, there is a significant upward trend in the error. The same occurs on
    days 16, 20, and 21, the latter two being the days with the greatest error with
    respect to the rest of the days. After showing the test results evaluating 30
    days separately and analyzing that days 9 and 10, 16, 20, and 21 seem to be days
    with significant key differences, we now apply non-parametric statistical tests
    to statistically contract from which day the CNNLSTM model should be retrained
    due to the significant increase in error and the drop in fit. We perform a non-parametric
    statistical test, in particular, the Kruskal–Wallis test [29], since the data
    do not follow a normal distribution. To make this statement, we proceeded to perform
    a Kolmogorov–Smirnov test [30] for normality of the data, obtaining a -value of
    0.000, which indicates that the RMSE, MAE, and data do not follow a normal distribution.
    Kruskal–Wallis tests have been also performed using all datasets, without distinguishing
    by data pre-processing used, the season of the year, as well as granularity. For
    a greater amount of information, tests have been performed individually for each
    of the metrics evaluated in the accuracy, which have been MSE, RMSE, and R . The
    statistical results, with a 95% confidence level, after performing the Kruskal–Wallis
    test, show the adjusted -values indicated in Table 15, Table 16, Table 17. Download
    : Download high-res image (941KB) Download : Download full-size image Fig. 4.
    Mean of all datasets in Table 1 for all the metrics. Table 15 shows for the first
    10 days, the -values with values higher than 0.05; i.e., confidence level of 95%.
    Thus, it is important to note that the first two days have significant differences
    with a 95% confidence level, with days 9, 10, 12, 16, 17, 18, 19, 20, and 21.
    Days 3 to 10, however, have significant differences from the models for days 20
    and 21. These results lead us to conclude that taking into account the MAE metric,
    from day 9 onwards, the model starts to lose accuracy, however, when the accuracy
    drops drastically is from day 19 onwards. Table 16 shows the -values, with a confidence
    level of 95%, for the first 10 days for the RMSE metric. As can be seen, the results
    are very similar to the MAE metric, with the only exception that day 9 has no
    significant differences with days 20 and 21. Despite this difference, the conclusion
    is the same as that obtained for the MAE metric, from day 9 onwards, accuracy
    decreases but drops drastically from day 19 onwards. Therefore, the two error
    metrics indicate the same conclusion. Table 15. -values of the statistical analysis
    for all datasets, considering the MAE metric of each of the tested days. Only
    -values 0.06 are shown. Days 1 2 3 4 5 6 7 8 9 10 9 0.002 0.054 10 0.002 0.051
    12 0.011 16 0.000 0.000 17 0.000 0.000 18 0.000 0.007 19 0.000 0.011 20 0.000
    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.080 0.007 21 0.000 0.000 0.000 0.000
    0.000 0.000 0.000 0.000 0.012 0.011 The 17 shows the -values, at 95% confidence
    level, for the values of the R2 metric. It shows significant differences in change
    with respect to errors. It should be considered that the R2 metric measures the
    overall model fit, so it is possible that it does not represent the errors as
    much as the overall fit. This table also shows how the days are reduced, and there
    are significant differences in the R2 metric of days 1 and 2 with the models of
    days 10, 12, 16, 20, 21. While for days 4, 5, 7, and 8 there are only significant
    differences with the models for days 20 and 21. These results lead us to the same
    conclusion as indicated by the previous metrics. From day 9 onwards, the accuracy
    and fit of the models drop, on the tenth-day accuracy is lost. However, when the
    accuracy drops drastically from day 20 onwards. Table 16. -values of the statistical
    analysis for all datasets, considering the RMSE metric of each of the tested days.
    Only -values 0.06 are shown. days 1 2 3 4 5 6 7 8 10 9 0.000 0.002 10 0.002 0.043
    12 0.012 16 0.000 0.000 17 0.000 0.000 18 0.000 0.004 19 0.001 0.002 20 0.000
    0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.007 21 0.000 0.000 0.000 0.000 0.000
    0.000 0.000 0.000 0.011 Thus, we can conclude that days 1 and 2 are the most accurate,
    but there is really no significant loss of accuracy until day 9. Days 20 and 21
    have significant differences with the first 10 days. This already indicates that
    from then on, the model decreases in accuracy, so from day 19, if day 9 has not
    been carried out, the model should be retrained. Table 17. -values of the statistical
    analysis for all datasets, considering the R metric of each of the tested days.
    Only -values 0.06 are shown. Days 1 2 4 5 7 8 10 0.000 0.000 0.000 0.000 0.000
    0.000 12 0.001 16 0.005 20 0.000 0.000 0.025 0.000 0.002 21 0.000 0.000 0.024
    0.000 0.002 The problem of retraining can be solved by using incremental learning.
    Although there is no common framework for dealing with this problem in deep learning
    techniques, there are some publications that address it. Incremental learning
    can be classified into three scenarios [31]: Task-incremental learning, Domain-incremental
    learning and Class-incremental learning. Task-incremental learning scenario is
    about learning sequentially to solve a series of tasks in the same context. Domain-incremental
    learning scenario focuses on solving the same problem but in different contexts.
    In contrast, Class-incremental learning focuses on learning to discriminate between
    incrementally observed classes. In the case we are concerned with in this study,
    we will be able to perform incremental learning to change context, for example,
    to change the greenhouse, or to perform incremental tasks, which would be to continue
    predicting the temperature in the same greenhouse. Some publications perform incremental
    learning using Deep Learning techniques. Thus in [32] the authors present an incremental
    learning method using an LSTM network for attitude estimation of an object in
    space using a gyroscope, accelerometer, and magnetometer sensors. It is initially
    trained with sensor data that is dynamically updated at runtime by the LSTM network.
    The incremental learning is done in a rough way, starting from the initial weights
    of the trained network and only training with the new information available. Another
    incremental learning technique based on an LSTM is presented in [33], in this
    case, it is not focused on a specific problem, but the technique is evaluated
    with a synthetic data set and good results are obtained. Another study that also
    uses Deep learning techniques adapted to computational learning is presented in
    [34]. The authors present an incremental learning paradigm called Deep Model Consolidation
    to learn labels when the original training data is not available. The idea of
    the work is to first train a separate model for new labels only, and then combine
    the two individual models trained on data from two different sets of labels (old
    labels and new labels) through a novel double distillation training objective.
    Therefore, in view of the results obtained in the literature, the problem of retraining
    is solved by applying incremental learning, although future work may study in
    depth specific techniques for the problem addressed in this study. 5. Discussion
    This section first analyzes the proposed Pub/Sub solution (see Section 3.2) using
    all the metrics obtained in Sections 4.1.1 HPC evaluation, 4.1.2 Edge evaluation.
    Moreover, the precision of the ML/DL models used (see Section 3.4) is analyzed
    using metrics obtained in Section 4.2. Finally, the necessary retraining time
    is discussed following the metrics shown in Section 4.3. Regarding the Pub/Sub
    solution, two aspects should be considered: (1) the execution time spent on training
    and inference with the different ML/DL models, executed on CPU or GPU in the HPC
    computing platform; and (2) the execution time spent on loading and forecasting
    with the different ML/DL models, executed on CPU and GPU of the edge computing
    platform. HPC platforms are needed for training heavy models, like those ones
    used in this investigation. Analyzing the obtained results can be concluded that
    using GPU is much faster than using only a CPU obtaining, on average, a 1.25X
    performance. However, in terms of inference, both CPU and GPU are very evenly
    matched, with the CPU being slightly faster than the GPU (on average, 0.94X of
    performance). This makes sense in our case because, although the models are heavy
    for training as they use large datasets to do this task, the inference is reduced
    to the univariate prediction of the greenhouse internal temperature. Furthermore,
    a maximum prediction horizon of 24 h is considered, as a larger time horizon is
    not operational in the greenhouse. However, this implies that at the smallest
    temporal granularity; i.e. 15 min, no more than 96 values are predicted, which
    implies a light forecast for this type of deep learning model. Edge computing
    is needed to generate a forecast as soon as data is generated or received. Analyzing
    the obtained results can be concluded that using CPU is much faster than using
    GPU obtaining, on average, a 2.44X performance as far as the model load is concerned.
    However, in terms of prediction, both CPU and GPU are evenly matched, with the
    CPU being slightly faster than the GPU (on average, 0.91X of performance). As
    with HPC platforms, this makes sense in our case because, although the stored
    models are heavy, once loaded into memory it is much faster to perform the inference
    on CPU rather than having to take it to GPU since the inference is still reduced
    to the univariate prediction of the internal greenhouse temperature as in the
    previous case. Although the model file is heavy, the model loading and univariate
    prediction tasks are very light tasks, so performing them on GPU means the appearance
    of bottlenecks, especially in memory access tasks, not taking full advantage of
    the GPU’s potential. Comparing the model training/loading and inference times
    on HPC and edge platforms, it can be concluded that loading the model in an edge
    platform is much faster than training it in an HPC platform (on average, 1,057.71X
    performance). Moreover, due to the low computational capabilities of edge platforms,
    the forecasting time in edge platforms is much slower than in HPC platforms (on
    average, 0.24X performance). Regarding the accuracy of ML/DL models, it can be
    concluded that it depends mainly on the characteristics of the data. For example,
    when there is a lot of data with a low temporality (such as 15 min datasets),
    models such as CNN and CNNLSTM perform very well. However, when the data has a
    higher temporal granularity (such as 60 min datasets), models such as LSTM show
    the best performance. It should also be noted that there are simple (in terms
    of architecture) models such as MLP that have reported good results. In addition,
    it is important to note that smooth pre-processing is not effective for any of
    the techniques, as it always provides lower performance. Moreover, for DL techniques,
    the best results are usually obtained with the raw datasets, as they are able
    to remove possible noise from the data. Although there are no major differences
    with the other techniques, the most stable technique is CNNLSTM because its accuracy
    performance is somewhat better than the other techniques, at both 12 and 24 h,
    regardless of the temporal granularity of the data. However, in terms of computing
    time, it is one of the slowest techniques for inference, although the times are
    still manageable, so given the importance of greenhouse temperature and the fact
    that the time difference is only 1 or 2 s, it can be selected as the best technique
    to implement. Finally, we discuss the analysis of the days needed to perform model
    retraining. Considering the results shown, in the first 9 days, the model remains
    stable in all metrics. From day 9 onwards, the model loses accuracy. However,
    the results have shown that when there is really a significant loss of accuracy
    is from day 20 onwards, as all previous days have significant differences with
    the metrics obtained from day 20. This shows the need for retraining on the ninth
    day of the model run. If there are any problems in the system, there would be
    a margin of 11 days to retrain the model (i.e., until day 20), where the model
    update should be mandatory. Thus, we can conclude that from day 19 the model should
    collect all the data and retrain the new model without delay, although the best
    day not to lose accuracy would be day 9. It is important to consider that from
    day 9 the model must be trained, if we are looking for optimal accuracy, for any
    kind of temporal granularity, the season of the year, as well as data pre-processing.
    6. Conclusions and future work New technologies are helping to improve quality,
    efficiency, and profitability in many areas. Farming in recent years is gaining
    a great deal of performance when new technologies bring their advantages. Proof
    of this is the automation that is taking place in greenhouses. IoT and new communications
    protocols help to connect sensors, with information-gathering and decision-making
    systems quickly and effectively, achieving fast and efficient monitoring and execution
    of actions. Thus, in this research, an infrastructure applied to an operational
    greenhouse has been proposed, consisting of a Pub/Sub-based infrastructure that
    offers an interoperable and decentralized dynamic architecture for ML/DL training
    and inference. The infrastructure is evaluated to forecast the internal temperature
    of an operational greenhouse. This allows the farmer to act in advance to have
    the best climatic conditions for his crops, with a reliable and fast-running model
    on the edge. After this research, it can be concluded that Pub/Sub systems are
    nowadays mandatory for IoT applications that require taking actions in almost
    real-time. When a real-time data publisher is considered to monitoring an ecosystem,
    and decisions need to be taken based on analytics and forecast, it is mandatory
    to have a tightly coupled, seamless IoT infrastructure that covers the whole data
    cycle from the capture to the processing pipeline to analyze them and make reliable
    forecasting in the shortest possible time in order to make decisions in NRT. Finally,
    it should be noted that the best prediction model found for the SEPARATE infrastructure
    was the CNNLTSM model. Moreover, it has been analyzed and from the 9th day of
    prediction at any granularity and/or season of the year, the model should be retrained
    in order not to lose accuracy. The future work of this research consists of optimizing
    the developed architecture, following different strategies that could improve
    the overall performance such as analyzing other possible Pub/Sub architectures
    that improve the response times of the proposal. Moreover, in order to optimize
    the models by which this architecture is developed, the following strategies could
    be studied: incorporating other artificial intelligence models different from
    the existing ones; increasing the number of variables to be predicted using the
    developed architecture; and changing the training strategy (batch training) for
    one that allows optimizing the training time, such as online/incremental training.
    CRediT authorship contribution statement Juan Morales-García: Methodology, Software,
    Formal analysis, Investigation, Writing – original draft, Writing – review & editing,
    Visualization. Andrés Bueno-Crespo: Methodology, Validation, Writing – original
    draft, Writing – review & editing, Funding acquisition. Raquel Martínez-España:
    Methodology, Validation, Writing – original draft, Writing – review & editing,
    Visualization. Francisco J. García: Conceptualization, Formal analysis. Sergio
    Ros: Conceptualization, Formal analysis. Julio Fernández-Pedauyé: Software. José
    M. Cecilia: Conceptualization, Methodology, Validation, Formal analysis, Investigation,
    Writing – original draft, Writing – review & editing, Supervision, Project administration,
    Funding acquisition. Declaration of Competing Interest The authors declare the
    following financial interests/personal relationships which may be considered as
    potential competing interests: Jose M. Cecilia, Andrés Bueno-Crespo, Juan Morales-García,
    Francisco J. García and Sergio Navarro report financial support was provided by
    Spanish Ministry of Science. Funding This work is derived from R&D projects RTC2019-007159-5,
    as well as the Ramon y Cajal Grant RYC2018-025580-I, funded by MCIN/AEI /10.13039/501100011033,
    “FSE invest in your future” and “ERDF A way of making Europe”. All authors approved
    the version of the manuscript to be published. Data availability Data will be
    made available on request. References [1] Lowenberg-DeBoer J. The economics of
    precision agriculture Precision Agriculture for Sustainability, Burleigh Dodds
    Science Publishing (2019), pp. 481-502 Google Scholar [2] Zamora-Izquierdo M.A.,
    Santa J., Martínez J.A., Martínez V., Skarmeta A.F. Smart farming IoT platform
    based on edge and cloud computing Biosyst. Eng., 177 (2019), pp. 4-17 View PDFView
    articleView in ScopusGoogle Scholar [3] Garrido M.C., Cadenas J.M., Bueno-Crespo
    A., Martínez-España R., Giménez J.G., Cecilia J.M. Evaporation forecasting through
    interpretable data analysis techniques Electronics, 11 (4) (2022), p. 536 CrossRefView
    in ScopusGoogle Scholar [4] Howard D.A., Ma Z., Veje C., Clausen A., Aaslyng J.M.,
    Jørgensen B.N. Greenhouse industry 4.0–digital twin technology for commercial
    greenhouses Energy Inform., 4 (2) (2021), pp. 1-13 CrossRefView in ScopusGoogle
    Scholar [5] Yang J., Sharma A., Kumar R. IoT-based framework for smart agriculture
    Int. J. Agric. Environ. Inf. Syst. (IJAEIS), 12 (2) (2021), pp. 1-14 Google Scholar
    [6] Yaacoub E., Alouini M.-S. A key 6G challenge and opportunity—Connecting the
    base of the pyramid: A survey on rural connectivity Proc. IEEE, 108 (4) (2020),
    pp. 533-582 CrossRefView in ScopusGoogle Scholar [7] Liakos K.G., Busato P., Moshou
    D., Pearson S., Bochtis D. Machine learning in agriculture: A review Sensors,
    18 (8) (2018), p. 2674 View in ScopusGoogle Scholar [8] Kamilaris A., Prenafeta-Boldú
    F.X. Deep learning in agriculture: A survey Comput. Electron. Agric., 147 (2018),
    pp. 70-90 View PDFView articleView in ScopusGoogle Scholar [9] Garg D., Alam M.
    Deep learning and IoT for agricultural applications Internet of Things (IoT),
    Springer (2020), pp. 273-284 CrossRefView in ScopusGoogle Scholar [10] Satyanarayanan
    M. The emergence of edge computing Computer, 50 (1) (2017), pp. 30-39 View in
    ScopusGoogle Scholar [11] Warden P., Situnayake D. TinyML O’Reilly Media, Incorporated
    (2019) Google Scholar [12] Wu Y., Dobriban E., Davidson S. Deltagrad: Rapid retraining
    of machine learning models International Conference on Machine Learning, PMLR
    (2020), pp. 10355-10366 Google Scholar [13] Mishra B., Kertesz A. The use of MQTT
    in M2M and IoT systems: A survey IEEE Access, 8 (2020), pp. 201071-201086 CrossRefView
    in ScopusGoogle Scholar [14] Wukkadada B., Wankhede K., Nambiar R., Nair A. Comparison
    with HTTP and MQTT in internet of things (IoT) 2018 International Conference on
    Inventive Research in Computing Applications, ICIRCA, IEEE (2018), pp. 249-253
    CrossRefView in ScopusGoogle Scholar [15] Kim S.-M., Choi H.-S., Rhee W.-S. IoT
    home gateway for auto-configuration and management of MQTT devices 2015 IEEE Conference
    on Wireless Sensors, ICWiSe, IEEE (2015), pp. 12-17 View in ScopusGoogle Scholar
    [16] Tantitharanukul N., Osathanunkul K., Hantrakul K., Pramokchon P., Khoenkaw
    P. MQTT-topics management system for sharing of open data 2017 International Conference
    on Digital Arts, Media and Technology, ICDAMT, IEEE (2017), pp. 62-65 CrossRefView
    in ScopusGoogle Scholar [17] Syafarinda Y., Akhadin F., Fitri Z., Widiawan B.,
    Rosdiana E., et al. The precision agriculture based on wireless sensor network
    with MQTT protocol IOP Conference Series: Earth and Environmental Science, Vol.
    207, No. 1, IOP Publishing (2018) 012059 Google Scholar [18] Ahmed A.A., Al Omari
    S., Awal R., Fares A., Chouikha M. A distributed system for supporting smart irrigation
    using internet of things technology Eng. Rep., 3 (7) (2021) Google Scholar [19]
    Taha F.M., Osman A.A., Awadalkareem S.D., Omer M.S., Saadaldeen R.S. A design
    of a remote greenhouse monitoring and controlling system based on internet of
    things 2018 International Conference on Computer, Control, Electrical, and Electronics
    Engineering, ICCCEEE, IEEE (2018), pp. 1-6 CrossRefGoogle Scholar [20] Singh T.A.,
    Chandra J. IOT based green house monitoring system J. Comput. Sci., 14 (5) (2018),
    pp. 639-644 View in ScopusGoogle Scholar [21] Tashakkori R., Hamza A.S., Crawford
    M.B. Beemon: An IoT-based beehive monitoring system Comput. Electron. Agric.,
    190 (2021), Article 106427 View PDFView articleView in ScopusGoogle Scholar [22]
    Hunkeler U., Truong H.L., Stanford-Clark A. MQTT-S—A publish/subscribe protocol
    for wireless sensor networks 2008 3rd International Conference on Communication
    Systems Software and Middleware and Workshops, COMSWARE’08, IEEE (2008), pp. 791-798
    CrossRefView in ScopusGoogle Scholar [23] Bender M., Kirdan E., Pahl M.-O., Carle
    G. Open-source mqtt evaluation 2021 IEEE 18th Annual Consumer Communications &
    Networking Conference, CCNC, IEEE (2021), pp. 1-4 CrossRefView in ScopusGoogle
    Scholar [24] Brownlee J. Deep Learning for Time Series Forecasting: Predict the
    Future with MLPs, CNNs and LSTMs in Python Machine Learning Mastery (2018) Google
    Scholar [25] Bishop C.M. Pattern Recognition and Machine Learning Springer (2006)
    Google Scholar [26] Haykin S., Lippmann R. Neural Networks: A Comprehensive Foundation
    (second ed.), Prentice Hall PTR (1998) Google Scholar [27] Li Z., Liu F., Yang
    W., Peng S., Zhou J. A survey of convolutional neural networks: analysis, applications,
    and prospects IEEE Trans. Neural Netw. Learn. Syst. (2021) Google Scholar [28]
    Hochreiter S., Schmidhuber J. Long short-term memory Neural Comput., 9 (8) (1997),
    pp. 1735-1780 CrossRefView in ScopusGoogle Scholar [29] Hecke T.V. Power study
    of anova versus Kruskal-Wallis test J. Stat. Manag. Syst., 15 (2–3) (2012), pp.
    241-247 CrossRefGoogle Scholar [30] Marsaglia G., Tsang W.W., Wang J. Evaluating
    Kolmogorov’s distribution J. Stat. Softw., 8 (2003), pp. 1-4 View in ScopusGoogle
    Scholar [31] van de Ven G.M., Tuytelaars T., Tolias A.S. Three types of incremental
    learning Nat. Mach. Intell. (2022), pp. 1-13 CrossRefGoogle Scholar [32] Narkhede
    P., Walambe R., Poddar S., Kotecha K. Incremental learning of LSTM framework for
    sensor fusion in attitude estimation PeerJ Comput. Sci., 7 (2021), Article e662
    CrossRefGoogle Scholar [33] Lemos Neto Á.C., Coelho R.A., Castro C.L.d. An incremental
    learning approach using long short-term memory neural networks J. Control Autom.
    Electr. Syst., 33 (5) (2022), pp. 1457-1465 CrossRefView in ScopusGoogle Scholar
    [34] J. Zhang, J. Zhang, S. Ghosh, D. Li, S. Tasci, L. Heck, H. Zhang, C.-C.J.
    Kuo, Class-incremental learning via deep model consolidation, in: Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2020, pp.
    1131–1140. Google Scholar Cited by (2) Change Management for the Sustainable Development
    of the Agrarian Economy of Artificial Intelligence 2024, Global Journal of Flexible
    Systems Management Design of agricultural irrigation monitoring system based on
    IOT cloud platform 2023, Proceedings of the 18th IEEE Conference on Industrial
    Electronics and Applications, ICIEA 2023 1 https://github.com/hivemq/hivemq-community-edition.
    View Abstract © 2023 Elsevier B.V. All rights reserved. Recommended articles Optimal
    reliable design of energy-efficient Wireless Body Area Networks Internet of Things,
    Volume 22, 2023, Article 100727 Mohammad Ali Raayatpanah, …, Angelo Trotta View
    PDF Development and implementation of a PQ analyser to monitoring public lighting
    installations with a LoRa wireless system Internet of Things, Volume 22, 2023,
    Article 100711 F. Sanchez-Sutil, A. Cano-Ortega View PDF An authentication approach
    in SDN-VANET architecture with Rider-Sea Lion optimized neural network for intrusion
    detection Internet of Things, Volume 22, 2023, Article 100723 Manoj kumar Pulligilla,
    C. Vanmathi View PDF Show 3 more articles Article Metrics Citations Citation Indexes:
    1 Captures Readers: 23 View details About ScienceDirect Remote access Shopping
    cart Advertise Contact and support Terms and conditions Privacy policy Cookies
    are used by this site. Cookie settings | Your Privacy Choices All content on this
    site: Copyright © 2024 Elsevier B.V., its licensors, and contributors. All rights
    are reserved, including those for text and data mining, AI training, and similar
    technologies. For all open access content, the Creative Commons licensing terms
    apply."'
  inline_citation: '>'
  journal: Internet of Things (Netherlands)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'SEPARATE: A tightly coupled, seamless IoT infrastructure for deploying AI
    algorithms in smart agriculture environments'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Emmi L.
  - Fernández R.
  - Gonzalez-de-Santos P.
  - Francia M.
  - Golfarelli M.
  - Vitali G.
  - Sandmann H.
  - Hustedt M.
  - Wollweber M.
  citation_count: '4'
  description: Autonomous robots in the agri-food sector are increasing yearly, promoting
    the application of precision agriculture techniques. The same applies to online
    services and techniques implemented over the Internet, such as the Internet of
    Things (IoT) and cloud computing, which make big data, edge computing, and digital
    twins technologies possible. Developers of autonomous vehicles understand that
    autonomous robots for agriculture must take advantage of these techniques on the
    Internet to strengthen their usability. This integration can be achieved using
    different strategies, but existing tools can facilitate integration by providing
    benefits for developers and users. This study presents an architecture to integrate
    the different components of an autonomous robot that provides access to the cloud,
    taking advantage of the services provided regarding data storage, scalability,
    accessibility, data sharing, and data analytics. In addition, the study reveals
    the advantages of integrating new technologies into autonomous robots that can
    bring significant benefits to farmers. The architecture is based on the Robot
    Operating System (ROS), a collection of software applications for communication
    among subsystems, and FIWARE (Future Internet WARE), a framework of open-source
    components that accelerates the development of intelligent solutions. To validate
    and assess the proposed architecture, this study focuses on a specific example
    of an innovative weeding application with laser technology in agriculture. The
    robot controller is distributed into the robot hardware, which provides real-time
    functions, and the cloud, which provides access to online resources. Analyzing
    the resulting characteristics, such as transfer speed, latency, response and processing
    time, and response status based on requests, enabled positive assessment of the
    use of ROS and FIWARE for integrating autonomous robots and the Internet.
  doi: 10.3390/agriculture13051005
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Agriculture All Article Types Advanced   Journals
    Agriculture Volume 13 Issue 5 10.3390/agriculture13051005 Submit to this Journal
    Review for this Journal Propose a Special Issue Article Menu Academic Editors
    Jin Yuan Wei Ji Qingchun Feng Show more... Subscribe SciFeed Recommended Articles
    Related Info Link More by Authors Links Article Views 1975 Citations 6 Table of
    Contents Abstract Introduction Materials and Methods Experimental Assessment System
    Assessment and Discussion Conclusions Author Contributions Funding Institutional
    Review Board Statement Data Availability Statement Conflicts of Interest References
    share Share announcement Help format_quote Cite question_answer Discuss in SciProfiles
    thumb_up Endorse textsms Comment first_page settings Order Article Reprints Open
    AccessArticle Exploiting the Internet Resources for Autonomous Robots in Agriculture
    by Luis Emmi 1,*, Roemi Fernández 1, Pablo Gonzalez-de-Santos 1, Matteo Francia
    2, Matteo Golfarelli 2, Giuliano Vitali 3, Hendrik Sandmann 4, Michael Hustedt
    4 and Merve Wollweber 4 1 Centre for Automation and Robotics (UPM-CSIC), 28500
    Arganda del Rey, Madrid, Spain 2 Department of Computer Science and Engineering
    (DISI), Alma Mater Studiorum-University of Bologna, 40127 Bologna, Italy 3 Department
    of Agricultural and Food Sciences (DISTAL), Alma Mater Studiorum-University of
    Bologna, 40127 Bologna, Italy 4 Laser Zentrum Hannover e.V., Hollerithallee 8,
    30419 Hannover, Germany * Author to whom correspondence should be addressed. Agriculture
    2023, 13(5), 1005; https://doi.org/10.3390/agriculture13051005 Submission received:
    16 March 2023 / Revised: 17 April 2023 / Accepted: 29 April 2023 / Published:
    2 May 2023 (This article belongs to the Special Issue Robots and Autonomous Machines
    for Agriculture Production) Download keyboard_arrow_down     Browse Figures Review
    Reports Versions Notes Abstract Autonomous robots in the agri-food sector are
    increasing yearly, promoting the application of precision agriculture techniques.
    The same applies to online services and techniques implemented over the Internet,
    such as the Internet of Things (IoT) and cloud computing, which make big data,
    edge computing, and digital twins technologies possible. Developers of autonomous
    vehicles understand that autonomous robots for agriculture must take advantage
    of these techniques on the Internet to strengthen their usability. This integration
    can be achieved using different strategies, but existing tools can facilitate
    integration by providing benefits for developers and users. This study presents
    an architecture to integrate the different components of an autonomous robot that
    provides access to the cloud, taking advantage of the services provided regarding
    data storage, scalability, accessibility, data sharing, and data analytics. In
    addition, the study reveals the advantages of integrating new technologies into
    autonomous robots that can bring significant benefits to farmers. The architecture
    is based on the Robot Operating System (ROS), a collection of software applications
    for communication among subsystems, and FIWARE (Future Internet WARE), a framework
    of open-source components that accelerates the development of intelligent solutions.
    To validate and assess the proposed architecture, this study focuses on a specific
    example of an innovative weeding application with laser technology in agriculture.
    The robot controller is distributed into the robot hardware, which provides real-time
    functions, and the cloud, which provides access to online resources. Analyzing
    the resulting characteristics, such as transfer speed, latency, response and processing
    time, and response status based on requests, enabled positive assessment of the
    use of ROS and FIWARE for integrating autonomous robots and the Internet. Keywords:
    precision agriculture; autonomous robots; artificial intelligence; IoT; cloud
    computing 1. Introduction The year 2022 ended with more than 8 billion inhabitants
    of the world. Most governments understand that feeding this vast and growing population
    is one of the significant challenges they must face in the coming years. Some
    associations have predicted that food production will need to increase by 70%
    to feed the entire population in 2050 [1]. In developed countries, cultivated
    land is close to its maximum output; therefore, the solution is oriented toward
    optimizing the available resources. Many different cultural and technological
    methods for increasing crop yield are being used. Some improve crop yields, but
    at the extra cost of increasing environmental pollution and the carbon footprint.
    These side effects are unacceptable in many industrialized nations, such as those
    in the European Union, which is committed to using sustainable methods. Precision
    agriculture leverages technologies to achieve those objectives and avoids undesired
    effects. PA is a concept for farm management founded on observation, measurement,
    and response to crop variability [2]. It assembles different methods to manage
    variations in a farm to enhance crop yield, improve commercial profit, and guarantee
    eco-environmental sustainability. PA uses current information and communication
    technologies (ICT), automation, and robotics to monitor crop growth, predict the
    weather accurately, perform optimal irrigation, apply fertilizers smartly, manage
    weeds and pests accurately, test soil quality precisely, etc. Since the late 1980s,
    precision agriculture techniques have been introduced step by step in the agricultural
    production sector, integrating the following: Sensors to acquire geolocated biodata
    of crops and soil, e.g., nitrogen sensors, vision cameras, global navigation satellite
    systems (GNSS), etc. Computers for analyzing those data and running simple algorithms
    to help farmers make simple decisions (applying or not applying a given process,
    modifying a process application map, etc.). Actuators in charge of executing the
    decisions (opening/closing valves, altering a trajectory, etc.) for modifying
    crops. As an actuator, we consider the agricultural tool, also called the agricultural
    implement, and the vehicle, manually or automatically driven, to move the tool
    throughout the working field and apply the farming process. The integration of
    subsystems onboard robotic vehicles started in the late 1990s. Some illustrative
    examples, based on retrofitting conventional vehicles, are the autonomous agricultural
    sprayer [3], which focuses on achieving a pesticide spraying system that is cheap,
    safe, and friendly to the environment, and the autonomous orchard vehicles for
    mowing, tree pruning, and training, spraying, blossoming, and fruit thinning,
    fruit harvesting, and sensing [4], both deployed in the USA. In Europe, we can
    find the RHEA fleet (see Figure 1a), consisting of a fleet of three tractors that
    cooperate and collaborate in the application of pesticides [5]. Regarding robotic
    systems based on specific structures designed for agriculture (see Figure 1b),
    we can remark on LadyBird in Australia, intended for the valuation of crops using
    thermal and infrared detecting systems, hyperspectral cameras, stereovision cameras,
    LIDAR, and GPS [6], and Vibro Crop Robotti in Europe, built for accurate seeding
    and mechanical row crop cleaning [7]. These robots were integrated around computing
    systems based on centralized or elementary distributed architectures to handle
    a few sensors and control unsophisticated agricultural tools. Figure 1. (a) Agricultural
    robots based on retrofitted conventional vehicles (RHEA fleet); (b) agricultural
    robots designed on purpose (Courtesy of AgreenCulture SaS). In addition to those
    developments, related technologies have evolved drastically in recent years, and
    now sensors can be spread throughout the field and communicate with each other.
    This is possible because of the Internet of Things (IoT). This computing concept
    describes how to cluster and interconnect objects and devices through the Internet,
    where all are visible and can interact with each other. IoT defines physical objects
    with devices (mainly sensors) and includes processing power, software applications,
    and other technologies to exchange data with other objects through the Internet.
    Moreover, computers can run artificial intelligence (AI) algorithms, considering
    AI as the ability of a machine (computer) to emulate intelligent human actions.
    The application of AI to agriculture has been focused on three primary AI techniques:
    expert systems, artificial neural networks, and fuzzy systems, with significant
    results in the management of crops, pests, diseases, and weeds, as well as the
    monitoring of agricultural production, store control, and yield prediction, for
    example [8]. AI techniques are also applied to provide vehicles with autonomy;
    therefore, autonomous agricultural robots leverage this technology. AI-based vision
    systems can fulfill the following roles: Detecting static or dynamic objects in
    their surroundings. Detecting row crops for steering purposes. Identifying plants
    and locating their positions for weeding are clear examples of the current use
    of AI techniques in agricultural robotics [9]. Another technology that has evolved
    in the last decade is cloud computing, defined as the on-demand delivery of computing
    services, mainly data storage and computing power, including servers, storage,
    databases, networking, software applications, artificial intelligence methods,
    and analytics algorithms over the Internet. The main objective of cloud computing
    systems is to provide flexible resources at adapted prices. A cloud computing
    system allows the integration of data of different types, loaded from many sources
    in batch and real-time. In particular, the integration can be based on georeferenced
    data in the precision farming area. Data can range from trajectory data to images
    and videos related to fields and missions and any sensors installed on the autonomous
    robot. Cloud computing allows the use of services available in the cloud (computing,
    storing, etc.), with increasing advantages provided by big data techniques. Many
    agricultural applications of big data technologies have already been introduced
    in agriculture [10] and should be present in future robotic systems. This article
    presents an architecture to integrate new technologies and Internet trends in
    agricultural autonomous robotic systems and has two main objectives. The first
    objective is to provide an example of designing control architectures to connect
    autonomous robots to the cloud. It is oriented toward robot designers and gives
    significant technical details. The second objective is to disclose to farmers
    the advantages of integrating the new technologies in autonomous robots that can
    provide farmers with significant advantages regarding (i) data storage, which
    is a secure and efficient way to store, but also access and share, data, eliminating
    the need of physical storage and, thus, reducing the risk of data loss; (ii) scalability,
    which allow the farmers to expand or reduce their storage needs, efficiently optimizing
    their resources, and (iii) analytics services, which allow a farmer to analyze
    their own data to make informed decisions taking advantage of the AI tools available
    on the cloud. These are general advantages of using the cloud, but autonomous
    robots have great potential for collecting data and must facilitate communicating
    those data to the cloud. To base the architecture on a specific example, the integration
    of a laser-based system for weed management is considered. Thus, Section 2 presents
    the material, defining the robot’s components, and the methodology, detailing
    the system’s architecture. Section 3 then introduces the experiments to be assessed
    and discussed in Section 4. Finally, Section 5 summarizes the conclusions. 2.
    Materials and Methods This section first describes the components and equipment
    integrated for building the autonomous robot used to validate and assess the proposed
    integration methodology. Second, the methods for the integration of components
    are detailed. 2.1. System Components 2.1.1. Main Process Loop in PA Autonomous
    Robots The autonomous systems used for precision agriculture generally follow
    the structure of an automatic control loop that consists of the following (see
    Figure 2): Selecting the references for the magnitudes to be controlled, i.e.,
    defining the desired plan. Measuring the magnitudes of interest. Making decisions
    based on the measured and desired values of the magnitudes (control strategy).
    Executing the decided actions Figure 2. Components of a precision agriculture
    robotic system and main information flow. In our application, the selecting references
    are made with the smart navigation manager (mission planner), the measures of
    the magnitudes of interest are performed with the perception system and the IoT
    sensor network, the decisions are made with the smart navigation manager (smart
    operation manager), and the actions are executed with the agricultural tool and
    the autonomous robot that move the implement throughout the mission field. In
    addition, our system also takes care of the interaction with the cloud and the
    operator. In our proposed integration method, these components are grouped into
    modules, as illustrated in Figure 2 and Figure 3. These modules are as follows.
    Figure 3. Computing architecture. 2.1.2. Agricultural Robot A manually driven
    or autonomous vehicle is essential in agricultural tasks to perform the necessary
    actions throughout the working field. In this case, we use a compact mobile platform
    based on a commercial vehicle manufactured by AgreenCulture SaS, France. This
    is a tracked platform, and, thus, it operates as a skid-steer mechanism. The track
    distance can be adapted to the crop row space. Equipped with an engine or batteries,
    the platform can follow predefined trajectories at 6 km/h with a position accuracy
    of ±0.015 m using a global positioning system (GPS) based on the real-time kinematic
    (RTK) technique. This mobile platform is illustrated in Figure 4a. Figure 4. (a)
    Mobile platform (AgreenCulture SaS) and (b) autonomous laser weeding system. 2.1.3.
    Perception System A perception system is based on computer vision algorithms that
    obtain, process, analyze, and understand images and data from the environment.
    With these inputs, the system produces numerical and symbolic information for
    making decisions. The perception system for this study consists of the following
    systems: Guiding vision system: This system aims to detect static and dynamic
    obstacles in the robot’s path to prevent the robot tracks from stepping on the
    crops during the robot’s motion. Furthermore, it is also used to detect crop rows
    in their early growth stage to guide the robot in GNSS-denied areas [8]. The selected
    perception system consisted of a red–green–blue (RGB) wavelength vision camera
    and a time-of-flight (ToF) camera attached to the front of the mobile platform
    using a pan-tilt device, which allows control of the camera angle with respect
    to the longitudinal axis of the mobile platform, x. Figure 4 illustrates both
    cameras and their locations onboard the robot. Weed–meristem vision system: The
    system is based on 3D vision cameras to provide the controller with data on crops
    and weeds. These data are used to carry out the main activity of the tool for
    which it has been designed: weed management, in this case. For example, the perception
    system used in this study consists of an AI vision system capable of photographing
    the ground and discriminating crops from weeds in a first step using deep learning
    algorithms. In the second step, the meristems of the detected weeds are identified.
    Figure 3 sketches this procedure. 2.1.4. Agricultural Tools Agricultural tools
    focus on direct action on the crop and soil and rely on physical (mechanical,
    thermal, etc.) or chemical (pesticides, fertilizers, etc.) foundations. This study
    used a thermal weeding tool based on a high-power laser source that provided lethal
    laser doses to be deployed on the weed meristems using scanners. An AI video system
    provided the positions of the weed meristems. Indeed, this specific solution physically
    integrated the AI vision system, the laser scanner, and the high-power laser source
    into the laser-based weeding tool component. The video frames acquired with this
    system were sent to the central controller at a rate of 4 frames/s. After the
    mission, all stored images were sent to the cloud. 2.1.5. The Smart Navigation
    Manager (SNM) This manager is a distributed software application responsible for
    driving the autonomous robot and coordinating all other modules and systems. The
    SNM is split into (i) the smart operation manager and (ii) the central manager,
    which also includes the human–machine interface (HMI). Smart Operation Manager
    (SoM) The smart operation manager is a human–computer interaction module that
    can acquire, process, and deliver information based on computer algorithms and
    is devoted to assisting farmers in making accurate, evidence-based decisions.
    The SoM is specialized for laser weeding technology, the tool selected for this
    study. Data management is performed through the Internet using FIWARE. Data access
    control is provided via a virtual private network (VPN) to secure data transfer
    to/from the cloud. The visual dashboard will also be available on the HMI for
    field operations. Through the dashboard, the operator will also interact with
    the robot. The smart operation manager is allocated in the cloud. It contains
    the global mission planner and supervisor, the map builder, and the module for
    managing the IoT and cloud computing system (see Figure 3 and Figure 5). The hardware
    of the SoM relies on a cluster of 10 servers. Figure 5. Cloud computing modules/containers.
    (a) Global Mission Planner A planner is a software tool responsible for computing
    the trajectories of the vehicle and an a priori known treatment map. The planner
    obtains some types of information from the Internet, including the following:
    Map information according to the data models on the Internet; Other information
    provided by third parties, such as weather forecasts; Data models to create maps
    for accessing already known treatment maps (sets of points in the field) which
    commonly originate from third-party map descriptions (Google Earth; Geographic
    Information System (GIS); GeoJSON.io, an open standard format to represent geographical
    features with nonspatial qualities). Regarding robot location, two types of systems
    are envisaged, as follows: Absolute location based on GNSS: GNSS integrates several
    controllers for line tracking and is based on Dubins paths [11]; ○ Relative location
    based on RGB and ToF cameras, LIDAR, and IoT sensors: These methods are based
    on different techniques for navigation in the field and navigation on the farm,
    such as hybrid topological maps, semantic localization and mapping, and identification/detection
    of natural and artificial elements (crops, trees, people, vehicles, etc.) through
    machine learning techniques. (b) Global Mission Supervisor A supervisor is a computational
    tool responsible for overseeing and monitoring the execution of the mission plan
    while helping the farmer (operator) manage potential failures. Most supervisor
    systems are designed around two actions: fault detection and fault diagnosis.
    The supervisor executes the following actions: Receiving alarms from the system
    components (vehicle, sensors, weeding tool, etc.). Detecting faults in real-time.
    Executing diagnosis protocols. Collecting all available geo-referred data generated
    by every module onboard the robot. The data are stored in both the robot and the
    cloud. (c) Map Builder A map builder is an application used to convert maps based
    on GeoJSON into FIWARE entities. Its main function is to support farmers in using
    the robotic system in a simple, reliable, and robust way by giving the robot enough
    information a priori (e.g., farm schema and boundaries, field locations and shapes,
    crop types, and status). This module takes advantage of the data models created
    by the FIWARE community to represent the farm and other environments digitally,
    where they have been conditioned to be adapted to robotic systems and especially
    oriented to navigation [12]. The design of the Map Builder allows the user to
    accomplish the following: Select the field in GeoJSON.IO, an open-source geographic
    mapping tool that allows maps and geospatial data to be created, visualized, and
    shared in a simple and multiformat way. Assign essential attributes to comply
    with FIWARE. These attributes are those based on the farmer’s knowledge. They
    can include static (i.e., location, type, category) and dynamic (i.e., crop type
    and status, seeding date, etc.) attributes. Export in * GeoJSON format. The map
    obtained will be imported for extracting the information required to fill in the
    FIWARE templates, which include the farms and parcel data models, and other elements
    in a farm, such as buildings and roads. This conversion makes it easier to connect
    the robot to the cloud by standardizing data. These data, after processing, constitute
    a source for the design of processes with the robot, and its storage and subsequent
    analysis can provide forecasts of future events in the field or behavior of the
    robot. (d) IoT System This study integrates an IoT sensor network to collect data
    from the following: The autonomous vehicle: The data and images acquired with
    IoT sensors onboard the vehicle are used to monitor and evaluate performances
    and efficiency and to identify the effects of treatments and traffic on surfaces.
    The environment: Data acquired with IoT sensors deployed on the cropland are used
    to (i) monitor crop development and (ii) collect weather and soil information.
    Two IoT sets of devices are used in our study, as follows: Robot–IoT set: It consists
    of two WiFi high-definition cameras installed onboard the autonomous robot (IoT-R1
    and IoT-R2 in Figure 3). The cameras are triggered from the cloud or the central
    controller to obtain a low frame rate (approximately 1/5 sec). The pictures are
    stored in the cloud and are used to monitor the effects of the passage of the
    autonomous vehicle; therefore, they should include the robot’s tracks. Field–IoT
    set: It consists of the following (see Figure 3): ○ Two multispectral cameras
    (IoT-F1 and IoT-F2) placed at the boundary of cropped areas to obtain hourly pictures
    of crops. ○ A weather station (IoT-F3) to measure precipitation, air temperature
    (Ta), relative humidity (RH), radiation, and wind. ○ Three soil multi-depth probes
    (IoT-F4) for acquiring moisture (Ts) data and three respiration probes (IoT-F5)
    to measure CO2 and H2O. Every one of these components or nodes exchanges messages
    with the Message Queuing Telemetry Transport (MQTT) protocol, carrying JavaScript
    Object Notation (JSON) serialized information from node sensors/cameras interpreted
    as the entity. While metering nodes (weather, soil probe, and respirometer) communicate
    by MQTT messages, camera nodes have to transmit images (maximum of 100 pictures/day
    for periodic snapshots of the area or alarms), and the use of FTP made a wide-band
    networking solution, such as WiFi, mandatory instead of narrowband solutions.
    (e) Cloud Computing System This study sets up a cloud-based data platform, which
    is an ecosystem that incorporates data acquired in the field. The data platform
    supports end-to-end data needs, such as ingestion, processing, and storage, to
    provide the following: A data lake repository for storing mission data to be downloaded
    in batches for post-mission analysis. A web interface for post-mission data analysis
    based on graphical dashboards, georeferenced visualizations, key performance indicators,
    and indices. A container framework for implementing “Decision Support System”
    functionalities that define missions to be sent to the robot. These functionalities
    (e.g., the mission planner) can be implemented and launched from the cloud platform.
    A soft real-time web interface for missions. The interface visualizes real-time
    robot activities and performances or sends high-level commands to the robot (e.g.,
    start, stop, change mission). These functionalities are ordered based on the strictness
    of real-time constraints. The cloud-computing platform is based on the Hadoop
    stack and is powered by FIWARE. We adopted an open-source solution with well-known
    components that can be imported into different cloud service providers if no on-premises
    hardware is available. The core component of the platform is the (FIWARE) Orion
    Context Broker (OCB) from Telefonica [13], a publish/subscribe context broker
    that also provides an interface to query contextual information (e.g., obtain
    all images from the cameras in a specific farm), update context information (e.g.,
    update the images), and be notified when the context is updated (e.g., when a
    new image is added into the platform). The images and raw data are stored in the
    HDFS (Hadoop distributed file system), while the NoSQL (not only structured query
    language) MongoDB database is used to collect the contextual data from FIWARE
    and further metadata necessary to manage the platform [14]. Additionally, we use
    Apache KAFKA, an open-source distributed event bus, to distribute context updates
    from FIWARE to all the modules/containers hosted on the cloud platform. The different
    cloud computing modules/containers used in this study are illustrated in Figure
    5. Central Manager This central manager is an application that is divided into
    the following: Obstacle detection system. This module acquires visual information
    from the front of the robot (robot vision system) to detect obstacles based on
    machine vision techniques. Local mission planner and supervisor. The planner plans
    the motion of the robot near its surroundings. The local mission supervisor oversees
    the execution of the mission and reports malfunctions to the operator (see Section
    2.1.5). Guidance system. This system is responsible for steering the mobile platform
    to follow the trajectory calculated by the planner. It is based on the GNSS if
    its signal is available. Otherwise, the system uses the information from the robot
    vision system to extract the crop row positions and follow them without harming
    the crop. Human–machine interface A human–machine interface (HMI) is a device
    or program enabling a user to communicate with another device, system, or machine.
    In this study, a HMI using portable devices (android tablets) is addressed to
    allow farmers to perform the following: - Supervise the mission. - Monitor and
    control the progress of agricultural tasks. - Identify and solve operational problems.
    - Obtain real-time in-field access in an ergonomic, easy-to-use, and robust way.
    - Maintain the real-time safety of the entire system. To achieve these characteristics,
    a graphic device was integrated with the portable/remote controller of the mobile
    platform. This controller provides manual and remote vehicle control and integrates
    an emergency button. 2.1.6. Sequence of Actions The relationships among these
    components and modules and the information flow are illustrated in Figure 2 and
    Figure 3. The process is a repeated sequence of actions (A0 to A6), defined as
    follows: A0 The system is installed in the field, The operator/farmer defines
    or selects a previously described mission using the HMI and starts the mission.
    A1 The sensors of the perception module (M1) installed onboard the autonomous
    robot (M2) extract features from the crops, soil, and environment in the area
    of interest in front of the robot. A2 The data acquired in action A1 are sent
    to the smart operation manager, determining the consequent instructions for the
    robots and the agricultural tool. A3 The required robot motions and agricultural
    tool actions are sent to the robot controller, which generates the signal to move
    the robot to the desired positions. A4 The robot controller forwards the commands
    sent by the smart navigation manager or generates the pertinent signals for the
    agricultural tool to carry out the treatment. A5 The treatment is applied, and
    the procedure is repeated from action A1 to action A5 until field completion (A6).
    A6 End of mission. 2.2. Integration Methods Integrating all of the components
    defined in the previous section to configure an autonomous robot depends on the
    nature of the applications the robot is devoted to and the connections and communication
    among the different components that must be precisely defined. Thus, this section
    first describes the computing architecture of the controller, which integrates
    the different subsystems and modules. Second, the interfaces between subsystems
    are precisely defined. Finally, the operation procedure is defined. 2.2.1. Computing
    Architecture A distributed architecture based on an open-source Robot Operating
    System (ROS) is proposed to integrate the system’s main components onboard the
    mobile platform in this study. ROS is the operating system most widely accepted
    by software developers to create robotics applications. It consists of a set of
    software libraries and tools that include drivers and advanced algorithms to help
    developers build robot applications [15]. In this study, ROS, installed in the
    central controller, is used as a meta-operating system for the testing prototype.
    The necessary interfaces (bridges) are developed to establish communication with
    the autonomous vehicle, the perception system, and the laser-based weeding tool.
    Because of ROS versatility and its publisher/subscriber communication model, it
    is possible to adapt the messages to protocols commonly used in IoT, such as Message
    Queuing Telemetry Transport (MQTT). ROS supports software developers in creating
    robotics functionalities to monitor and control robot components connected to
    a local network. However, this solution is not extendible to a wider network,
    such as the Internet. Fortunately, there exist some ROS modules that solve the
    problem. One is ROSLink, a protocol for extensions defining an asynchronous communication
    procedure between the users and the robots through the cloud [16]. ROSLink performance
    has been shown to be efficient and reliable, and it is widely accepted by the
    robotics software community [17]. Although ROSLink has been widely used to connect
    robotic systems with the cloud, it is oriented toward transmitting low-level messages.
    There is no convention to define standard data models that allow intelligent robotics
    systems to be scalable. One alternative to a more internet-oriented communication
    framework is FIWARE, which offers interaction with the cloud using cloud services
    that provide well-known benefits, such as (a) cost and flexibility, (b) scalability,
    (c) mobility, and (d) disaster recovery [18]. FIWARE is an open software curated
    platform fostered by the European Commission and the European Information and
    Communication Technology (ICT) industry for the development and worldwide deployment
    of Future Internet applications. It attempts to provide a completely open, public,
    and free architecture and a collection of specifications that allows organizations
    (designers, service providers, businesses, etc.) to develop open and innovative
    applications and services on the Internet that fulfill their needs [19]. In this
    study, a cloud-based communication architecture has been implemented using FIWARE
    as the core, which allows messages between the edge and the cloud to be transferred
    and stored. The selection was made because this is an open-source platform that
    provides free development modules and has many enablers already developing and
    integrating solutions for smart agriculture. In addition to FIWARE, we use KAFKA,
    a robust distributed framework for streaming data (see Section 2.1.5) that allows
    producers to send data and for consumers to subscribe to and process such updates.
    KAFKA enables the processing of streams of events/messages in a scalable and fault-tolerant
    manner, and decouples producers and consumers (i.e., a consumer can process data
    even after a producer has gone offline). For historic data, HDFS allows the download
    of batches of data at any time and replicates each data in three copies to prevent
    data loss. The visual dashboard will also be available on the HMI for the field
    operations. Through the dashboard, the operator will also interact with the robot.
    FIWARE smart data models do not suffice to represent our application domain or
    to integrate the agricultural and robotic domains; therefore, we have extended
    the existing models and updated some existing entities. Since smart data models
    from FIWARE are overlapping and sometimes inconsistent, we had to envision a unified
    model to integrate and reconcile the data. To connect the robotic system with
    the cloud, specific data models were developed to represent the different robotic
    elements, following the guidelines of FIWARE and its intelligent data models [12].
    The IoT devices deployed in the field must be able to establish connections through
    WiFi and LoRa technologies. WiFi is a family of wireless network protocols. These
    protocols are generally used for Internet access and communication in local area
    networks, allowing nearby electronic devices to exchange data using radio waves.
    LoRa technology is a wireless protocol designed for long-range connectivity and
    low-power communications and is primarily targeted for the Internet of Things
    (IoT) and M2M networks. LoRa tolerates noise, multipath signals, and the Doppler
    effect. The cost of achieving this is a very low bandwidth compared to other wireless
    technologies. This study uses a 4G LTE-M modem to connect to the Internet. At
    a lower level of communication, CANbus or ISOBUS is generally used to control
    and monitor the autonomous vehicle. This study uses CANbus and its communication
    protocol CANopen. Autonomous vehicles and agricultural tools typically contain
    their own safety controllers. The first behaves as a master and, in the case of
    a risky situation, it commands the tool to stop. The human–machine interface (HMI)
    will include a synchronous remote procedure call-style communication over the
    services protocol and asynchronous communications to ensure the robot’s safety.
    In addition to these ROS-based protocols, the HMI has a safety control connected
    to the low-level safety system (by radiofrequency) for emergency stops and manual
    control. Figure 6 illustrates the overall architecture, indicating the following:
    The modules (Mi), presented in the previous sections. The interconnection between
    modules, presented in the next section. The communication technologies and protocols
    to configure agricultural robotic systems that integrate IoT and cloud computing
    technologies. The main characteristics of this architecture are summarized in
    Table 1. Figure 6. Experimental fields. Table 1. Architecture components. 2.2.2.
    Interfaces between System Components This architecture considers four main interfaces
    between systems and modules, as follows: Smart Navigation Manager (M4)/Perception
    System (M1) interface To receive the raw information from the perception system
    (sensors, cameras, etc.), the central manager uses direct connections via the
    transmission control protocol/Internet protocol (TCP/IP) for sensors and the universal
    serial bus (USB) for RGB and ToF cameras. All IoT devices use the available wireless
    communication technologies (WiFi and LoRa) to access the Internet and the cloud.
    To guide the robot, the obstacle detection system obtains data from the guiding
    vision system (RGB and ToF cameras) through the Ethernet that communicates the
    central manager with the perception system. This communication is stated using
    the ROS manager and the perception–ROS bridge (see Figure 3). Smart Navigation
    Manager (M4)/Agricultural Tool (M3) interface These systems can communicate through
    ROS messaging protocols, where the publisher/subscriber pattern is preferred.
    This interface exchanges simple test messages to verify the communication interface.
    It is worth mentioning that the perception system and the agricultural tool are
    connected directly in some specific applications. This solution decreases the
    latency of data communication but demands moving a portion of the decision algorithms
    from the smart navigation manager to the tool controller; therefore, the tool
    must exhibit computational features. This scheme is used in the weeding system
    to test the proposed architecture. Smart Navigation Manager (M4)/Autonomous Robot
    (M2) interface Initially, these systems communicate via CANbus with the CANopen
    protocol. The central manager uses this protocol to receive information on the
    status of the autonomous vehicle and basic information from the onboard sensors
    (GNSS, IMU, safety system, etc.). A CANbus–ROS bridge is used to adapt the communication
    protocols. Autonomous Robot (M2)/Agricultural Tool (M3) interface Usually, it
    is not necessary for the vehicle to directly communicate with the tool because
    the smart navigation manager coordinates them. However, as autonomous vehicles
    and agricultural tools usually have safety controllers, there is wired communication
    between the two safety controllers. In such a case, the autonomous vehicle safety
    controller works as a master and commands the tool safety controller to stop the
    tool if a dangerous situation appears. Perception System (M1)/Agricultural Tool
    (M3) This communication is required to inform the agricultural tools about the
    crop status. In weeding applications, the information is related to the positions
    of the weeds. In this specific application, the perception system (weed meristem
    detection module) sends the weed meristem positions to the laser scanner module
    of the agricultural tool. This communication is carried out using a conventional
    Ethernet connection. The metadata generated via the detection system are made
    available in the existing ROS network and sent to the smart navigation manager.
    Smart Navigation Manager internal/cloud communications The smart navigation manager
    is a distributed system that consists of three main modules: The central manager
    running on the central controller. The smart operation manager running on the
    cloud. The HMI running in a portable device. The central manager and the smart
    operation manager communicate via NGSI v2, a FIWARE application programming interface,
    using a FIWARE–ROS bridge to adapt ROS protocols to NGSI v2 messages. In contrast,
    the HMI communicates with the central manager via WiFi and Internet, directly
    accessing the web services hosted in the cloud. The HMI exhibits a panic button
    connected via radiofrequency to the safety systems of the autonomous robot and
    the agricultural tool. IoT system/Cloud There is a direct link from the IoT system
    to the cloud using MQTT. 2.2.3. Operation Procedure To use the proposed architecture
    and method, the user must follow the method below. Creating the map: The user
    creates the field map following the procedure described in the MapBuilder module
    (see Section 2.1.5). Creating the mission: The user creates the mission by selecting
    the mission’s initial point (home garage) and destination field (study site).
    Sending the mission: The user selects the mission to be executed with the HMI
    (all defined missions are stored in the system) and sends it to the robot using
    the cloud services (see Section Smart Operation Manager (SoM)). Executing the
    mission: The mission is executed autonomously following the sequence of actions
    described in Section 2.1.6. The user does not need to act except for when alarms
    or collision situations are detected and warned of by the robot. Applying the
    treatment: When the robot reaches the crop field during the mission, it sends
    a command to activate the weeding tool, which works autonomously. The tool is
    deactivated when the robot performs the turns at the headland of the field and
    is started again when it re-enters. The implement was designed to work with its
    own sensory and control systems, only requiring the mobile platform for mobility
    and information when it must be activated/deactivated. Supervising the mission:
    When the robotic system reaches the crop field, it also sends a command to the
    IoT sensors, warning that the treatment is in progress. Throughout the operation,
    the mission supervisor module analyzes all the information collected by the cloud
    computing system, generated by both the robotic system and the IoT sensors. It
    evaluates if there is a possible deviation from the trajectory or risk of failure.
    Ending the mission: The mission ends when the robot reaches the last point in
    the field map computed by the MapBuilder. Optionally, the robot can stay in the
    field or return to the home garage. During the mission execution, the user can
    stop, resume, and abort the mission through the HMI. 3. Experimental Assessment
    This section states the characteristics of the described autonomous robot with
    IoT and cloud computing connectivity. To achieve this purpose, the experimental
    field for this study is first described. Then, a test mission is defined to acquire
    data from the different subsystems. Finally, the system characteristics are analyzed
    and assessed. The characteristics obtained are not compared with similar robotic
    systems due to the lack of such information in the literature. There are no published
    results in weeding applications; therefore, it is difficult to compare, and the
    indicators have been geared towards general cloud computing and mobile robotics
    characteristics. Therefore, cross-validation has been carried out, comparing the
    features of the autonomous robot with the general performance of the robot and
    cloud communication. Productivity, cost, and other indicators of the presented
    architecture are those of the general use of cloud computing. 3.1. Study Site
    The system developed for this study was tested in an experimental field located
    in Madrid, Spain (40°18′45.166″, −3°28′51.096″). The climate of the study site
    is classified as a hot summer Mediterranean climate with an average annual temperature
    of 14.3 °C and precipitation of 473 mm. The experimental field consisted of two
    areas of 60 × 20 m2 that grew wheat (Triticum aestivum L.), with crop rows at
    a distance of 0.10 m, and maize (Zea mays L.), with crop rows at a distance of
    0.50 m, respectively. Each area was divided into three sections of 20 × 20 m2.
    The sections in one area were seeded in consecutive weeks, allowing us to conduct
    experiments in three-week windows. Figure 6 shows the experimental field and the
    distribution of the areas and sections. 3.2. Description of the Test Mission Tests
    were conducted to assess the performance and quality of integrating new technologies
    in autonomous robots for agriculture. First, the testing prototype was integrated
    with the components introduced in Section 2; then, several IoT devices were disseminated
    throughout the field (RGB and multispectral cameras, weather stations, soil probes,
    etc.); finally, a mission was defined to acquire data in the study site to perform
    quantitative analyses. The mission consisted of covering sections of 20 × 20 m2
    with wheat and maize crops while the following occurred: Acquiring data from the
    IoT sensor network. Taking pictures of the crop. Acquiring data from the guidance
    system. Sending all the acquired information to the cloud. The mission proposed
    by the planner is illustrated in Figure 7. The robot tracked the path autonomously,
    and the following procedures were carried out. Figure 7. Robot’s path from the
    home garage to the study site. The planner provides the mission for covering the
    study site. Perception system procedure Guiding vision system: This experiment
    was conducted in the treatment stage, where the crop was detected to adjust the
    errors derived from planning and the lack of precision of the maps. YOLOv4 [20],
    a real-time object detector based on a one-stage object detection network, was
    the base model for detecting early-stage growth in maize [8], a wide-row crop.
    The model was trained using a dataset acquired in an agricultural season before
    these tests using the same camera system [21]. Moreover, in the case of wheat,
    which is a narrow-row crop, a different methodology was applied through the use
    of segmentation models, such as MobileNet, a convolutional neural network for
    mobile vision applications [22], trained using a dataset acquired in an agricultural
    season before these tests [23], with the same camera system. The detection of
    both crops was evaluated with regard to the GNSS positions collected manually
    for the different crop lines. The maize and wheat datasets were built with 450
    and 125 labeled images, respectively. Data augmentation techniques (rotating,
    blurring, image cropping, and brightness changes) were used to increase the size
    of the datasets. For both crops, 80% of the data was destined for training, 10%
    for validation, and 10% for testing. The AI vision system: This system uses data
    from the installed RGB cameras to enable robust automated plant detection and
    discrimination. For this purpose, the state-of-the-art object detection algorithm
    Yolov7 is used in combination with the Nvidia framework DeepStream. Tracking the
    detected plants is performed in parallel by a pretrained DeepSort algorithm [24].
    The reliability of the object detection algorithm is evaluated using test datasets
    with the commonly used metrics “intersection over union” (IoU) and “mean average
    precision” (mAP). This system works cooperatively with laser scanners as a stand-alone
    system. The information is not stored in the cloud. The dataset used for training
    weed/crop discrimination was generated in fields in several European countries.
    It contains 4000 images, 1000 of which are fully labeled. Distinctions are made
    according to the processing steps to be applied: weeds, grasses, and crops. In
    addition, the dataset was expanded to three times its original size through augmentation
    measures. As well as generating new training data, this enables robustness against
    changing environmental influences, such as changing color representation, motion
    blur, and camera distortion. The YoloV7 network achieved a mean average precision
    (mAP) of 0.891 after 300 epochs of training. The dataset was divided into 80%,
    10%, and 10% for training, validation, and testing subsets, respectively. Autonomous
    robot procedure The navigation controller: Given a set of trajectories based on
    RTK-GNSS, the performance of the guidance controller was evaluated by measuring
    lateral and angular error through the incorporation of colored tapes on the ground
    and using the onboard RGB camera and ToF to extract the tape positions to compute
    the errors concerning the robot’s pace. Smart Navigation Manager procedure: Smart
    operation manager: The processing time, latency, success rate, response time,
    and response status based on requests of the mission planner, IoT sensors, and
    cloud computing services were evaluated using ROS functionalities that provide
    statistics related to the following: ○ The period of messages by all publishers.
    ○ The age of messages. ○ The number of dropped messages. ○ Traffic volume to be
    measured in real-time. Central manager: The evaluation is similar to that used
    for the navigation controller. Obstacle detection system: YOLOv4 and a model already
    developed based on the COCO database were introduced to detect common obstacles
    in agricultural environments and were also used for evaluation. YOLOv4 is a one-stage
    object detection model, and COCO (common objects in context) is a large-scale
    object detection, segmentation, and captioning dataset. 4. System Assessment and
    Discussion The mission described in the previous section produced crop images,
    sensor data, and traffic information with the following characteristics: Crop
    images: During the robot’s motion, images are acquired at a rate of 4 frames/s
    to guide the robot. The RGB images are 2048 × 1536 pixels with a weight of 2.2
    MB (see Figure 8 and Figure 9), and the ToF images feature 352 × 264 points (range
    of 300–5000 mm) (see Figure 10). The images are sent to the guiding and obstacle
    detection system through the Ethernet using ROS (perception–ROS bridge in the
    perception system and ROS manager in the central manager). A subset of these images
    is stored in the cloud for further analysis. Using a FIWARE–ROS bridge with the
    NGSI application programming interface, the system sends up to 4 frames/s. Sensor
    data: IoT devices send the acquired data using 2.4 GHz WiFi with the MQTT protocol
    and JSON format. Traffic information: The ROS functionalities mentioned above
    revealed that during a field experiment (10 min duration), the total number of
    delivered messages was 2,395,692, with a rate of only 0.63% dropped messages (messages
    that were dropped due to not having been processed before their respective timeout),
    with average traffic of 10 MB/s and maximum traffic of 160 MB at any instant of
    time. No critical messages (command messages) were lost, demonstrating robustness
    within the smart navigation manager. Regarding cloud traffic, during a period
    of time of approximately 3 h, the messages sent to the cloud were monitored, where
    the number of messages received by the cloud was measured; the delay time of the
    transmission of the messages between the robot (edge) and the OCB, and between
    the robot and the KAFKA bus (see Figure 3), were also measured. During this interval
    of time, around 4 missions were executed, and a total of 14,368 messages were
    sent to the cloud, mainly the robot status and the perception system data. An
    average delay of about 250 ms was calculated between the moment the message is
    sent from the robot and the moment it is received in the OCB (see Figure 11a).
    Moreover, the KAFKA overhead, i.e., the time it takes for a message received by
    the OCB to be forwarded to the KAFKA bus and eventually processed by a KAFKA consumer,
    was approximately 1.24 ms, demonstrating that the internal communications within
    the server and hosted cloud services are robust (see Figure 11b). Figure 8. Example
    of a wheat image acquired with the guiding vision system and uploaded to the cloud.
    Figure 9. Example of a maize image acquired with the guiding vision system and
    uploaded to the cloud. Figure 10. Example of a ToF intensity image acquired with
    the guidance system and uploaded to the cloud. Figure 11. Example of a ToF intensity
    image acquired with the guidance system and uploaded to the cloud. (a) Message
    delay and (b) Kafka overhead. The system has been tested in a field with two different
    crops. Data related to cloud communication and robot guidance algorithms have
    been collected. The communication performance is similar to that obtained using
    conventional mechanisms, so we benefit from using ROS and FIWARE without compromising
    performance. 5. Conclusions An architecture is presented to configure autonomous
    robots for agriculture with access to cloud technologies. This structure takes
    advantage of new concepts and technologies, such as IoT and cloud computing, allowing
    big data, edge computing, and digital twins to be incorporated into modern agricultural
    robots. The architecture is based on ROS, the most universally accepted collection
    of software libraries and tools for building robotic applications, and FIWARE,
    an open architecture that enables the creation of new applications and services
    on the Internet. ROS and FIWARE provide attractive advantages for developers and
    farmers. ROS and FIWARE offer powerful tools for developers to build control architectures
    for complex robots with cloud computing/IoT features, making development easier
    and leveraging open-source frameworks. ROS and FIWARE, as in the proposed integration,
    provide reusability, scalability, and maintenance using the appropriate hardware
    resources. In addition, integrating the robot controller into the Internet allows
    the exploitation of autonomous robot services for agriculture through the Internet.
    On the other hand, the use of this type of architecture reveals to farmers the
    advantages of communicating autonomous robots with the cloud, providing them with
    leading benefits to storing data safely and efficiently, eliminating physical
    storage, and, thus, reducing the risk of data loss. Data stored in the cloud makes
    it easy to access data from anywhere and share it with other farmers or platforms.
    In addition, the services offered in the cloud are very flexible to contract the
    actual storage needed at all times, optimizing the farmer’s resources. Finally,
    farmers can use the analysis tools available in the cloud to make their own decisions.
    In any case, working in the cloud requires an initial investment, which is usually
    recovered quickly. The different components of the robot, particularized for a
    laser-based weeding robot, are described, and the general architecture is presented,
    indicating the specific interfaces. Based on these components, the article presents
    the action sequence of the robot and the operating procedure to illustrate how
    farmers can use the system and what benefits they can obtain. Several experiments
    with two crops were conducted to evaluate the proposed integration based on the
    data communication characteristics, demonstrating the system’s capabilities. The
    crop row detection system works correctly for both crops, tracking the rows with
    an accuracy of ±0.02 m. The evaluation concluded that the system could send image
    frames to the cloud at 4 frames/s; messages between subsystems and modules can
    be passed with a 0.63% rejection rate. Regarding the traffic of the information
    exchanged, an average delay of 250 ms was detected in the messages between the
    robot and the OCB. In contrast, the OCB and the KAFKA bus measured an average
    message of 1.24 ms. This indicates the robustness of internal communications within
    the server and hosted cloud services. This performance is in the range obtained
    when a system communicates with the cloud using conventional methods, so ROS and
    FIWARE facilitate communication with the cloud without compromising performance.
    Future work will focus on extending cloud computing architecture to integrate
    digital twins, orchestrate big data ensembles, and facilitate the work of robots
    with edge computing performance. Author Contributions Conceptualization, L.E.,
    R.F., P.G.-d.-S., M.F., M.G., G.V., H.S., M.H. and M.W.; methodology, L.E. and
    R.F.; software, L.E., M.F., H.S. and M.W.; validation, L.E., M.F., G.V. and H.S.;
    investigation, L.E., R.F., P.G.-d.-S., M.F., M.G., G.V., H.S., M.H. and M.W.;
    writing—original draft preparation, P.G.-d.-S.; writing—review and editing, L.E.,
    P.G.-d.-S. and R.F.; supervision, L.E. and P.G.-d.-S.; funding acquisition, P.G.-d.-S.,
    G.V., M.G. and M.W. All authors have read and agreed to the published version
    of the manuscript. Funding This article is part of a project that has received
    funding from the European Union’s Horizon 2020 research and innovation program
    under grant agreement No 101000256. Institutional Review Board Statement The study
    was conducted in accordance with the Declaration of Helsinki, and approved by
    the Ethics Committee of CSIC. Data Availability Statement Herrera-Diaz, J.; Emmi,
    L.A.; Gonzalez de Santos, P. Maize Dataset. 2022. Available online: http://doi.org/10.20350/digitalCSIC/14566
    (accessed on 1 April 2023). Herrera-Diaz, J.; Emmi, L.; Gonzalez de Santos, P.
    Wheat Dataset. 2022. Available online: http://doi.org/10.20350/digitalCSIC/14567
    (accessed on 1 April 2023). Conflicts of Interest The authors declare no conflict
    of interest. References Ghose, B. Food security and food self-sufficiency in China:
    From past to 2050. Food Energy Secur. 2014, 3, 86–95. [Google Scholar] [CrossRef]
    Zhang, N.; Wang, M.; Wang, N. Precision agriculture—A worldwide overview. Comput.
    Electron. Agric. 2002, 36, 113–132. [Google Scholar] [CrossRef] Stentz, A.; Dima,
    C.; Wellington, C.; Herman, H.; Stager, D. A System for Semi-Autonomous Tractor
    Operations. Auton. Robot. 2002, 13, 87–104. [Google Scholar] [CrossRef] Bergerman,
    M.; Maeta, S.M.; Zhang, J.; Freitas, G.M.; Hamner, B.; Singh, S.; Kantor, G. Robot
    Farmers: Autonomous Orchard Vehicles Help Tree Fruit Production. IEEE Robot. Autom.
    Mag. 2015, 22, 54–63. [Google Scholar] [CrossRef] Gonzalez-De-Santos, P.; Ribeiro,
    A.; Fernandez-Quintanilla, C.; Lopez-Granados, F.; Brandstoetter, M.; Tomic, S.;
    Pedrazzi, S.; Peruzzi, A.; Pajares, G.; Kaplanis, G.; et al. Fleets of robots
    for environmentally-safe pest control in agriculture. Precis. Agric. 2017, 18,
    574–614. [Google Scholar] [CrossRef] Underwood, J.P.; Calleija, M.; Taylor, Z.;
    Hung, C.; Nieto JFitch, R.; Sukkarieh, S. Real-time target detection and steerable
    spray for vegetable crops. In Proceedings of the International Conference on Robotics
    and Automation: Robotics in Agriculture Workshop, Seattle, WA, USA, 9–11 May 2015.
    [Google Scholar] Kongskilde. New Automated Agricultural Platform—Kongskilde Vibro
    Crop Robotti. 2017. Available online: http://conpleks.com/robotech/new-automated
    (accessed on 14 December 2022). Emmi, L.; Herrera-Diaz, J.; Gonzalez-De-Santos,
    P. Toward Autonomous Mobile Robot Navigation in Early-Stage Crop Growth. In Proceedings
    of the 19th International Conference on Informatics in Control, Automation and
    Robotics (ICINCO 2022), Lisbon, Portugal, 14–16 July 2022; pp. 411–418. [Google
    Scholar] [CrossRef] Bannerjee, G.; Sarkar, U.; Das, S.; Ghosh, I. Artificial Intelligence
    in Agriculture: A Literature Survey. Int. J. Sci. Res. Comput. Sci. Appl. Manag.
    Stud. 2018, 7, 3. [Google Scholar] Osinga, S.A.; Paudel, D.; Mouzakitis, S.A.;
    Athanasiadis, I.N. Big data in agriculture: Between opportunity and solution.
    Agric. Syst. 2021, 195, 103298. [Google Scholar] [CrossRef] Yang, D.; Li, D.;
    Sun, H. 2D Dubins Path in Environments with Obstacle. Math. Probl. Eng. 2013,
    2013, 291372. [Google Scholar] [CrossRef] Emmi, L.; Parra, R.; González-de-Santos,
    P. Digital representation of smart agricultural environments for robot navigation.
    In Proceedings of the 10th International Conference on ICT in Agriculture, Food
    & Environment (HAICTA 2022), Athens, Greece, 22–25 September 2022; pp. 1–6. [Google
    Scholar] Orion Context Broker. Telefonica. Available online: https://github.com/telefonicaid/fiware-orion
    (accessed on 22 February 2023). Francia, M.; Gallinucci, E.; Golfarelli, M.; Leoni,
    A.G.; Rizzi, S.; Santolini, N. Making data platforms smarter with MOSES. Futur.
    Gener. Comput. Syst. 2021, 125, 299–313. [Google Scholar] [CrossRef] ROS—The Robot
    Operating System. 2023. Available online: https://www.ros.org/ (accessed on 24
    April 2020). ROSLink. 2023. Available online: https://github.com/aniskoubaa/roslink
    (accessed on 5 January 2023). Koubaa, A.; Alajlan, M.; Qureshi, B. ROSLink: Bridging
    ROS with the Internet-of-Things for Cloud Robotics. In Robot Operating System
    (ROS); Koubaa, A., Ed.; Studies in Computational Intelligence; Springer: Cham,
    Switzerland, 2017; Volume 707. [Google Scholar] [CrossRef] Fiware Community Fiware:
    The Open Source Platform for Our Smart Digital Future. Available online: https://www.fiware.org/
    (accessed on 5 January 2023). López-Riquelme, J.; Pavón-Pulido, N.; Navarro-Hellín,
    H.; Soto-Valles, F.; Torres-Sánchez, R. A software architecture based on FIWARE
    cloud for Precision Agriculture. Agric. Water Manag. 2017, 183, 123–135. [Google
    Scholar] [CrossRef] Bochkovskiy, A.; Wang, C.Y.; Liao, H.Y.M. YOLOv4: Optimal
    speed and accuracy of object detection. arXiv 2020, arXiv:2004.10934. [Google
    Scholar] Herrera-Diaz, J.; Emmi, L.A.; Gonzalez de Santos, P. Maize Dataset. 2022.
    Available online: https://digital.csic.es/handle/10261/264581 (accessed on 1 April
    2023). Howard, A.G.; Zhu, M.; Chen, B.; Kalenichenko, D.; Wang, W.; Weyand, T.;
    Andreetto, M.; Adam, H. MobileNets: Efficient Convolutional Neural Networks for
    Mobile Vision Applications. arXiv 2017, arXiv:1704.04861. [Google Scholar] Herrera-Diaz,
    J.; Emmi, L.; Gonzalez de Santos, P. Wheat Dataset. 2022. Available online: https://digital.csic.es/handle/10261/264622
    (accessed on 1 April 2023). Wojke, N.; Bewley, A.; Paulus, D. Simple Online and
    Realtime Tracking with a Deep Association Metric. In Proceedings of the IEEE International
    Conference on Image Processing (ICIP), Beijing, China, 17–20 September 2017. [Google
    Scholar]     Disclaimer/Publisher’s Note: The statements, opinions and data contained
    in all publications are solely those of the individual author(s) and contributor(s)
    and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility
    for any injury to people or property resulting from any ideas, methods, instructions
    or products referred to in the content.  © 2023 by the authors. Licensee MDPI,
    Basel, Switzerland. This article is an open access article distributed under the
    terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Emmi, L.; Fernández, R.; Gonzalez-de-Santos,
    P.; Francia, M.; Golfarelli, M.; Vitali, G.; Sandmann, H.; Hustedt, M.; Wollweber,
    M. Exploiting the Internet Resources for Autonomous Robots in Agriculture. Agriculture
    2023, 13, 1005. https://doi.org/10.3390/agriculture13051005 AMA Style Emmi L,
    Fernández R, Gonzalez-de-Santos P, Francia M, Golfarelli M, Vitali G, Sandmann
    H, Hustedt M, Wollweber M. Exploiting the Internet Resources for Autonomous Robots
    in Agriculture. Agriculture. 2023; 13(5):1005. https://doi.org/10.3390/agriculture13051005
    Chicago/Turabian Style Emmi, Luis, Roemi Fernández, Pablo Gonzalez-de-Santos,
    Matteo Francia, Matteo Golfarelli, Giuliano Vitali, Hendrik Sandmann, Michael
    Hustedt, and Merve Wollweber. 2023. \"Exploiting the Internet Resources for Autonomous
    Robots in Agriculture\" Agriculture 13, no. 5: 1005. https://doi.org/10.3390/agriculture13051005
    Note that from the first issue of 2016, this journal uses article numbers instead
    of page numbers. See further details here. Article Metrics Citations Crossref   6
    Web of Science   3 Scopus   3 Google Scholar   [click to view] Article Access
    Statistics Article access statistics Article Views 28. Dec 7. Jan 17. Jan 27.
    Jan 6. Feb 16. Feb 26. Feb 7. Mar 17. Mar 0 500 1000 1500 2000 2500 For more information
    on the journal statistics, click here. Multiple requests from the same IP address
    are counted as one view.   Agriculture, EISSN 2077-0472, Published by MDPI RSS
    Content Alert Further Information Article Processing Charges Pay an Invoice Open
    Access Policy Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For
    Editors For Librarians For Publishers For Societies For Conference Organizers
    MDPI Initiatives Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia
    JAMS Proceedings Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive
    issue release notifications and newsletters from MDPI journals Select options
    Subscribe © 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated Disclaimer
    Terms and Conditions Privacy Policy"'
  inline_citation: '>'
  journal: Agriculture (Switzerland)
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Exploiting the Internet Resources for Autonomous Robots in Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Mukherjee A.
  - Panja A.K.
  - Dey N.
  - Crespo R.G.
  citation_count: '2'
  description: Unmanned aerial vehicle based precision agriculture is a predominant
    research area. The modern flying ad-hoc network leverages the advanced low latency
    vehicular communication and intelligent computing paradigms that help the ecosystem
    to grow up to the next level. In this work, we propose an ecosystem for precision
    agriculture that leverages the use of the opportunistic MQTT protocol in an edge-enabled
    intelligent drone network for sensing and performing crop prediction using an
    intelligent ensemble machine learning model. The proposed approach leverages the
    edge computing system that requires low energy devices and also exploits the ultra-low
    latency opportunistic message transfer methodology. The experimental results show
    the maximum of 0.9 message delivery ratio and a minimum of 600 ms latency is achieved
    by opportunistic MQTT protocol in an ultra-low latency sparse network scenario.
    A weighted ensemble model is deployed onto the edge enabled devices or the drones.
    An accuracy of 96.5% is achieved in predicting the type of crops that can be grown
    in the soil about the selected area of interest.
  doi: 10.1111/exsy.13090
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register Expert Systems ORIGINAL ARTICLE Full Access An intelligent edge enabled
    6G-flying ad-hoc network ecosystem for precision agriculture Amartya Mukherjee,  Ayan
    Kumar Panja,  Nilanjan Dey,  Rubén González Crespo First published: 06 July 2022
    https://doi.org/10.1111/exsy.13090Citations: 1 SECTIONS PDF TOOLS SHARE Abstract
    Unmanned aerial vehicle based precision agriculture is a predominant research
    area. The modern flying ad-hoc network leverages the advanced low latency vehicular
    communication and intelligent computing paradigms that help the ecosystem to grow
    up to the next level. In this work, we propose an ecosystem for precision agriculture
    that leverages the use of the opportunistic MQTT protocol in an edge-enabled intelligent
    drone network for sensing and performing crop prediction using an intelligent
    ensemble machine learning model. The proposed approach leverages the edge computing
    system that requires low energy devices and also exploits the ultra-low latency
    opportunistic message transfer methodology. The experimental results show the
    maximum of 0.9 message delivery ratio and a minimum of 600 ms latency is achieved
    by opportunistic MQTT protocol in an ultra-low latency sparse network scenario.
    A weighted ensemble model is deployed onto the edge enabled devices or the drones.
    An accuracy of 96.5% is achieved in predicting the type of crops that can be grown
    in the soil about the selected area of interest. 1 INTRODUCTION The use of sensor-based
    devices and the extensive use of unmanned aircraft systems (UAS) is highly relevant
    in the field of precision agriculture. Various types of agriculture mechanisms
    have been adopted in different parts of the globe which focus on the cultivation
    of healthy crops which ensure the quality of the food. Due to the huge population
    growth, food production also needs to be increased rapidly. In such cases, conventional
    farming methodologies are not effective as they over-utilize resources like water,
    electricity, fertilizers. On the other hand, the crop production rate in such
    cases is limited. To utilize the resources optimally the farmers need to be trained
    so that they can use sophisticated technology. The purpose of smart farming and
    smart agriculture is to produce a solution that increases the quantity as well
    as the quality of the crops with minimum labour. This involves the implementation
    of modern and advanced sensing, communication, and computing technology that paves
    a way to ensure the revolution of agriculture. A smart agriculture system is also
    necessary for addressing food security, change of climate, soil quality assessment,
    precision irrigation, and many more. The sensing and measurement of the water
    and the pH level of the land is a crucial task. Based on the soil moisture the
    automated water dispenser and the sprinkler have to be deployed so that the moisture
    content can be properly maintained. Secondly, the pH of the land also plays a
    vital role in the growth of the different crops and plants. Also, the quantity
    of the fertilizers that are used to grow the plants is a major part of the development
    of the precise agriculture ecosystem. Secondly, to send the data and receive the
    commands in an automated environment the Internet of Things ecosystem is an utmost
    necessity. In the case of a remote environment to send and receive the crucial
    farming information and control commands, a sophisticated networking methodology
    is needed. In a large farming environment like a big paddy field, or vast crop
    field the lack of network coverage is an obvious issue. Therefore a sophisticated
    network model with low latency communication is highly required. Along with this
    the sensor information must be processed and analysed so that the critical decision
    can be made for precision agriculture. Also, based on the time-series data the
    seasonal irrigation and crop harvesting is highly possible by constantly monitoring
    and analysing the crop, plant, soil, and environmental information. This article
    mainly focuses on the implementation of the low latency network infrastructure
    for the message transfer in a highly sparse network scenario so that critical
    information can be transferred in a minimum delay. Undoubtedly an extensive edge
    enabled network ecosystem is required for intelligent agriculture so that the
    crop prediction service can be provided in a very remote rural region where network
    disruption happens frequently due to the limitation of the network coverage. Therefore
    the key contribution of the work can be stated as follows: The realization of
    the edge enabled flying ad-hoc network (FANET) for precision agriculture application
    under an opportunistic message transfer scenario with realistic mobility of the
    flying vehicular node. The use of the unmanned aerial vehicle (UAV) nodes as a
    mobile edge computing platform that can run the intelligent artificial intelligence
    (AI) models in a resource constraint scenario. Design and development of an extremely
    fault-tolerant majority voting-based machine learning model for crop type prediction
    which can be able to execute in a low resource edge device. The article has been
    organized with the following flow. Section 2 of the article gives an overview
    of the research carried out in the domain of UAV on agricultural application and
    also various approaches in crop-related predictions. Section 3 discusses the FANET
    architecture followed by the mobility models and routing discussed in the subsequent
    subsections. Section 4 discusses the ensemble-based learning approach used in
    determining the crop type. Section 5 presents the various experimental results.
    We have concluded in Section 6 with a vivid discussion and future scope of action.
    2 RELATED RESEARCHES There is plenty of research that has been proposed in different
    UAV based agriculture applications as well as intelligent edge applications. The
    primary target of the research is to provide a service that will give a monetary
    benefit to the farmers by reducing the human effort, reduction of the maintenance
    cost, 24-h monitoring and analysis of the cultivated land, and intelligent forecasting
    by leveraging the modern Internet of Things (IoT) and machine learning (ML) models.
    Farooq et al. (2020) describe the potential domain of research on relevant IoT-based
    agriculture systems (Dejene et al., 2020) and the intelligent aspects. Maddikunta
    et al. (2021) address the potential requirements of UAV in smart agriculture that
    emphasized UAV decision support systems, real-time sensing, monitoring, and data
    aggregation. The use of multispectral and hyperspectral sensors along with smart
    Bluetooth and Wi-Fi technology is the main topic of interest here. Wireless sensor
    network synchronization mechanism has been proposed by Zervopoulos et al. (2020).
    A novel synchronization scheme has been proposed so that the sink node clocks
    the entire WSN. The sink clock in such a case is used as a point of reference.
    Misra et al. (2020) show the potential scope of big data and AI in the food industry.
    Greenhouse monitoring, UAV-based crop imaging is the primary focus in their works.
    In the work Economic data analytic AI technique on IoT edge devices for health
    monitoring of agriculture machines (Gupta et al., 2020; Núñez-Valdez et al., 2020),
    the authors propose. The implementation of green IoT for the agriculture machine
    has been conceptualized. A bi-level genetic algorithm approach has been proposed
    to optimize the health and growth of agriculture plants. Antony et al. (2020)
    describe an IoT-based precision smallholder farming methodology for the countries
    which have low and middle-income people. A security framework for green-IoT for
    agriculture has been proposed by Ferrag et al. (2020). A four-tier green IoT-based
    agriculture system is mainly emphasized in this work. In this case, fog-enabled
    drone base architecture has been addressed also (Kishor et al., 2020). An item
    delivery and geographical information system (GIS) inspired autonomous drone system
    has been proposed by Budiharto et al. (2019). The survey primarily emphasizes
    the use of GIS-based remote sensing and its potential application perspective.
    A novel unmanned ground vehicle (UGV) platform has been proposed by Quaglia et
    al. (2018). The UGV service provided by the authors is responsible for crop monitoring
    and also it offers a platform for the landing of the UAV. Puri, Nayyar, and Raja
    (2017) elaborate on the utilities and the technological breakthrough of drone-based
    agriculture (Lopez et al., 2020). The use of numerous fixed-wing and multi-copter
    drones has been emphasized in their work. The energy-efficient methodology of
    drone networks is also a crucial topic of interest. Jawad et al. (2019) give a
    direction of a wireless power transfer mechanism for the drone that is taking
    part in a precision agriculture scenario. A magnetic resonant coupling (MRC) technique
    has been adopted to perform power transfer with an efficiency of 85.25%. Murugan,
    Garg, and Singh (2017) proposed an adaptive classification mechanism that takes
    both satellite and drone statistical image data. Cloud masking, satellite image
    fusion, and image segmentation have been performed to validate the sparseness
    and density of the vegetation and crops. A LoRa based visual monitoring scheme
    has been proposed by Ji et al. (2019). The mechanism ensures low power data transmission
    for low bandwidth devices like ground-based sensors. The optimization of the number
    of messages and the image quality is the main topic of interest in this work.
    The MSE of the streaming images has been measured for the accuracy of the optimized
    model. Ruan et al. (2019) elaborate on the necessity of an IoT framework in agriculture.
    The work reveals the extensive survey on agriculture IoT by applying cite space
    methodology related to the co-operation networks. The influence study has also
    been made from the statistical and historical data that reflects the ample research
    in the field of IoT-based agriculture. A smart agriculture IoT system has been
    proposed by Bu and Wang (2019). A deep reinforcement learning-based mechanism
    has been engineered which can be able to classify in an edge computing platform.
    Sa et al. (2017) proposed the concept of Weednet. An encoder-decoder cascaded
    convolution neural network has been designed for the optimal accuracy of weed
    prediction. The experiment achieves a 0.8 F1 score in the prediction of weeds.
    Agricultural data gathering remains a greater challenge in the present research
    domain. Brinkhoff et al. (2017) proposed a data logging platform by the name of
    WiField. The proposed approach utilizes the IEEE 802.11 technology to gain on
    farm connectivity for data gathering. The platform collects data from probes,
    data such as soil moisture, soil tension, depth sensor, and so forth. The collected
    data gets uploaded into a cloud platform. Another data gathering approach that
    explores fog computing has been proposed by Chang et al. (2018). The method collects
    data from GreenHouses in realtime manner and reduces the computational loading
    to cloud infrastructure by processing at fog level. Ensemble-based approaches
    are also gaining popularity and are also widely used in the domain of IoT-based
    applications (Ani et al., 2017; Zhang et al., 2020). Ensemble models are built
    on the pretext of considering multiple approaches with different parameters tuned,
    different approaches, and even data sets to give a collective learning paradigm.
    In the domain of crop prediction, numerous researches have been proposed to collect
    and assimilate data pertaining to crops and increase the yield by performing numerous
    predictions. Everingham et al. (2009) an ensemble approach to collect sugarcane
    production information is proposed. The work addresses and employs a continuous
    forecasting approach using multiple statistical models. Balakrishnan and Muthukumarasamy
    (2016) proposed a machine learning-based ensemble approach using ADASVM and ADANaive
    Bayes and have compared their approach with state-of-the-art support vector machine
    (SVM) and Naïve Bayes classifier. Their proposed approach is used to predict the
    yield pertaining across a certain time of the year. Thus in the majority of the
    past literature, we can observe that Ensemble-based approaches have been majorly
    used in predicting crop yield (Battisti et al., 2017; De Wit & Van Diepen, 2007)
    or just to determine the quality (Mukherjee et al., 2019) of the soil. Thus in
    our approach, we have tried to explore the power of ensemble in determining which
    type of crop can be grown on a particular area of interest utilizing the power
    of IoT as a tool for data collection and routing and giving and presenting a framework
    where the whole system can be used as an abstracted service for the end-users.
    3 THE LOW LATENCY FANET ARCHITECTURE To design a low latency ecosystem for farming,
    numerous major aspects have to be taken into account. The proposed architecture
    depicted in Figure 1 performs a unique solution that can integrate various domains
    of agriculture which is not only farming but also harvesting, packaging, greenhouse
    system infrastructure monitoring, farm animals, and cattle monitoring. One of
    the major issues in this scenario is the message transfer amongst various sensor
    nodes and the base station. Often the sensors are deployed in cultivated lands;
    the aggregation of the data involves some processing and the buffer units. As
    most of the firming fields are nearer to the villages and the outskirts the disruption
    of the network is a crucial factor. In such a case the sensor node must buffer
    the information and as it becomes in the transmission range of the mobile base
    station it immediately transmits the data opportunistically. FIGURE 1 Open in
    figure viewer PowerPoint Layered architecture of the proposed system We propose
    a layered architecture that leverages the advantages of the edge computing paradigm.
    The ecosystem consists of five layers. The bottom layer is the sensing layer that
    mainly consists of sensor groups or sensor networks. The nodes in this case are
    deployed in such a way that they collect the maximum information. There are various
    deployment strategies involved to effectively place the sensors and collect the
    optimal amount of data. In general, the sensors are the stationary nodes that
    collect the data from the ground level. There are numerous topologies we can consider
    to deploy the ground-based sensors like the grid, zig-zag, and randomized form
    and sometimes independently log the data or may connect with a base station which
    acts as a centralized data store. The next layer is the device layer that mainly
    comprises the data aggregator. In our proposed work we have implemented a set
    of dynamically connected UAV nodes whose network ecosystem is amalgamated with
    the 5G/6G ultra-low latency backhaul. The advantage of 6G technology in this case
    is the improved forwarding latency and the connectivity at anywhere. Secondly
    the use of network slice also makes a pivotal role in order to improve the connectivity
    and the network resource utilization amongst various services. The UAV here captures
    the image and the data from the sensors that are deployed on the ground. As the
    UAV nodes are part of FANET, they perform tasks collectively. In such a scenario
    the sensor data has to be sent to the UAV node in the form of packets. In a sparse
    network scenario, the routing of the data is a challenge. Also, the UAV nodes
    are the flying objects that maintain a certain altitude and speed. The mobility
    pattern of the UAV must ensure optimum message transfer and the receiving. As
    the UAV is deployed within an ultra-low latency network a network slice mechanism
    has to be applied in such a case the group of UAV in a specific data can be considered
    in a common network slice. The third layer is majorly useful for caching and computation
    purposes. This layer mainly comprises the dew and the edge sub-layer. The main
    phenomena of this layer are to perform the intelligent data processing task that
    can predict the possibilities of the types of harvested crops based on a collected
    atmospheric criterion. In this case, the intelligent AI model has been deployed
    in a low-resource edge device. The model has been optimized in that case so that
    it gives significantly good prediction accuracy. Overall communication and connectivity
    have been controlled by the ultra-low latency network where heterogeneous network
    infrastructure can be applied like 5G mobile base station, satellite network connection,
    stationary radio access points. The satellite network framework is highly useful
    in this case because of its high coverage and network availability. In the beyond
    5G scenario, this is a key part of the network backbone throughout the globe.
    A real-life three-dimensional representation of the ecosystem is depicted in Figure
    2. FIGURE 2 Open in figure viewer PowerPoint Three-dimensional representation
    of the precision agriculture ecosystem 3.1 Mobility model The mobility model that
    has been considered here mainly follows two different mathematical systems (Mukherjee,
    Dey, & De, 2020). In the first case, the nodes follow a randomized Gauss–Markov
    philosophy. The model is perhaps more realistic and easily deployable in a 3D
    space. We have chosen this mobility model for its simplicity. The airborne network
    for sparse network scenarios can be easily deployed using this mobility model.
    This model is memory-based mobility that has a tuning parameter α. The Markov
    process has to be applied in this case for all moving nodes in the 3D space as
    xn, yn and zn with a velocity vector computed as: x n = α . x n − 1 + ( 1 − α
    ) ⁢ x ′ + ( 1 − α 2 ) ⁢ x x n − 1 (1) y n = α . y n − 1 + ( 1 − α ) ⁢ y ′ + (
    1 − α 2 ) ⁢ y y n − 1 (2) z n = α . z n − 1 + ( 1 − α ) ⁢ z ′ + ( 1 − α 2 ) ⁢
    z z n − 1 (3) At the initial condition, the value α = 0 implies the non-predictable
    movement of the node, and the nodes are considered memory less. α = 1 implies
    the movement is predictable. The velocity within x, y, and z-direction can be
    computed as Vx, Vy, and Vz which can be obtained by the following methodology:
    V x = s n coscos ( d n ) ⁢ cos ⁡ ( p n ) (4) V y = s n ⁢ sin ⁡ ( d n ) ⁢ cos ⁡
    ( p n ) (5) V z = s n ⁢ sin ⁡ ( p n ) (6) Here, sn is the distance factor, pn
    is the pitch and dn is the distance which can be computed as below. d n = α .
    d n − 1 + ( 1 − α ) ⁢ d ′ + ( 1 − α 2 ) ⁢ d x n − 1 (7) p n = α . p n − 1 + (
    1 − α ) ⁢ p ′ + ( 1 − α 2 ) ⁢ p x n − 1 (8) s n = α . s n − 1 + ( 1 − α ) ⁢ s
    ′ + ( 1 − α 2 ) ⁢ s x n − 1 (9) In the second case, the shortest path-based mobility
    has been considered for the group of nodes that manly follows Dijkstra based shortest
    path approach. This is a highly realistic model and ensures the optimized performance
    of the routing mechanism. The movement path of the node, in this case, can be
    considered as weighted graph G = {V, N, w} having cost function w: E → N . This
    implies a mapping of the edge ( u , v ) ∈ E as a non-negative integer weight that
    is w ⁡ ( u , v ) ∈ N . The length function {L} can be obtained by { L } = ∑ i
    = 1 n w ⁡ ( x i − 1 , x i ) where x i ∈ V for the graph G = (V, N, w). According
    to the shortest path methodology, the node movements are decided according to
    the vertex point. Dijkstra algorithm is mainly used to predict the shortest path
    from one point to another in this case. The time complexity of the algorithm,
    in this case, is completely related to the number of edges and number of nodes
    which is strictly O(e log n). 3.2 Routing In the case of rural areas, internet
    connectivity is majorly disrupted due to the poor signal strength of the network.
    This will impact the message transfer. In our work, the hybrid FANET has been
    implemented along with the standard 4G/5G network. Here the FANET nodes are the
    group of UAV connected wirelessly. In the majority of the cases, the UAV nodes
    collect data from the sensor deployed on the ground. Often the node covers a vast
    geographical area. Due to that, the network may experience a significant amount
    of disconnection. The message transfer may be disrupted. The message transfer
    scheme that has been proposed in such a scenario must follow the QoS aware opportunistic
    messaging policy (Jat et al., 2018). Since the drone nodes are part of IoT, therefore
    a low latency, the lightweight protocol is highly recommended for the efficient
    transfer of the message in an opportunistic manner. To achieve that, we propose
    a hybrid opportunistic routing mechanism that enhances the effectiveness of the
    MQTT protocol in a sparse network scenario. One of the major advantages of the
    MQTT protocol is the lightweight nature of the protocol. Along with that MQTT
    can able to transfer the message in three levels of QoS. The FANET nodes often
    suffer from network disconnectivity. So the best approach is to implement a Delay
    Tolerant mechanism to transfer the message from source to destination. To achieve
    this amalgamation of an opportunistic network with MQTT protocol is extremely
    necessary. MQTT is a lightweight protocol. The gRPC on the other hand is a high
    performance remote procedure call. The advantage of MQTT over gRPC is the availability
    of the varying QoS levels. Secondly the MQTT also has a lesser data footprint
    in comparison to gRPC. Algorithm 1 shows the message transfer scheme for MQTT
    for FANET nodes. Algorithm 1. Opportunistic message routing for MQTT Input: m,ninit_t,
    n_n ←  {{NODE}, ϕ}, l(m), l(n), sim_t,b ←  READ_MAG, state  ←  ϕ Output: τm (sub
    ), sub_id Start 1. for t ≤ sim_t^n_n ≠  ϕ 2.   tmx ← init_t 3.   Tx(tmx) 4.   xcg(sv(state))
    5.   buffer(state) 6.   Rx (tmy) 7.    ds = ( n ) 2 + l ⁢ ( m ) 2 × cos ⁡ ( cos
    ⁡ ( b ) )                                   8.   tmn = tmx-tmy+ds 9.   state  ←
    wrap[t,tmn] 10. end for 11. τm (sub ) ←  min[tmn(n_n)] 12. sub_id ←  format (τm
    (sub)) 13. mqtt_run(sub_id) defmqtt_run: 14.  call pub (broker, QoS,topic) 15.  if
    sub_id = sv(node(sub_id)) 16.   call sub(broker,topic) Stop The entire operation
    has been done based on the timestamp-based summary vector approach. In this case,
    during an encounter, each node has to exchange their summary vector with each
    other. The summary vector must consist of the timestamp of the encountered node.
    A node encounters another if and only if any of them are in the transmission range
    of the adjacent node while moving. The nodes are moving in the 3D space by following
    a certain mobility model. There is a high chance of contact of the nodes with
    each other in such a case. Each time while the nodes get connected the timestamp
    of the previous summary vector exchange has been compared. If ‘n’ numbers of nodes
    get connected then each time the timestamp has to be compared with all n nodes.
    The node having a lower timestamp value is considered the best forwarder of the
    message. The node collecting the data from the sensor nodes acts as a subscriber.
    Sensor nodes act like publishers in this case. UAV nodes also contain the broker
    deployed on board and depending upon the forwarding probability the nodes also
    act as publisher or publisher and subscriber both. We have considered the entire
    messaging scheme is under the B5G/6G network scenario. The approach is crucial
    and the 6G network philosophy always ensures the mission-critical services in
    a challenging scenario. In our proposed methodology the use of such a technology
    is relevant due to the introduction of various services under a single umbrella.
    The large groups of cultivated fields are often separated by vast geographical
    separation. The B5G framework always guarantees a sustainable network ecosystem
    to ensure seamless connectivity anywhere. 4 AERIAL EDGE COMPUTING The sensor data
    are collected by the drones for processing. Our objective lies in developing drone-enabled
    aerial edge computing, where the collected datasets are transformed and predictions
    are done at the drone level itself. 4.1 Data and pre-processing The data collected
    through various sensors are routed through edge drones towards a sink server.
    In the very area of interest, multiple sensor combinations along with a connected
    microcontroller are deployed. For experimentation, we have used FC28 Hygrometer
    and DHT11 sensors to measure the soil moisture and temperature. HALJIA Rain Sensor
    is used to measure the amount of rainfall estimation and Robocraze 822 soil ph
    sensor for calculating the pH level of the soil. Each of the units is connected
    to a microcontroller that consolidates the raw information. As the drone approaches
    an area of interest a query message is sent to collect the information. The microcontroller
    on receiving the message responds by sending the real-time raw data of pH, rainfall,
    soil moisture, and temperature related to the UAV node. The model building on
    the other hand is done in the Base Station. The collected data comprises various
    information about soil such as rainfall, pH, humidity, and temperature. In order
    to build the prediction model, we have used the popular crop dataset for the training
    process. We have plotted an overall overview of the average requirement of the
    necessary features about the growth of each crop type in Figure 3. It can be observed
    that many of the crops require high temperatures such as mango and adzuki beans,
    while papaya, jute, chickpeas require very low-temperature conditions. Rainfall
    is another one of the major criteria. We can observe that sugarcane, jute, and
    rice require very high rainfall conditions while muskmelon requires the least
    rainfall. Thus the combination of considered feature values plays an important
    role in distinguishing the various crops from data collected from different soil
    types. We have also given a correlation matrix to depict the choice of a selected
    set of features for our learning model in Figure 4. FIGURE 3 Open in figure viewer
    PowerPoint Overview of the average requirement of rainfall, pH, humidity, the
    temperature of the soil of the growth of each crop FIGURE 4 Open in figure viewer
    PowerPoint Correlation matrix between the selected features set on the collected
    data During the testing phase, the collected raw data is pre-processed for missing
    entries and edge level prediction is performed using the deployed model at the
    edge level or on the drones. The drones route the information towards the sink
    node and onto the higher levels of the system to answer the query. 4.2 Classifiers
    The features considered for the classification problem are temperature, humidity,
    pH, and rainfall. The pre-processed model M is depicted as follows: M = Model
    ( T , H , ρ , R , Y ) Here T: temperature, H: humidity, ρ: pH. value of soil,
    R: rainfall, Y: label. The selected set of features are unique and they directly
    affect the type of crops that can be grown in the selected area of interest. Features
    such as temperature, humidity, and rainfall give insight into the weather condition,
    soil moisture. pH is a factor along with the temperature and rainfall gives an
    insight into the nutrient uptake and physio-chemical properties of soil. Knowing
    the exact rate of change of features that draws the boundary of cultivation of
    the different crops is difficult. Thus the classification process is carried out
    to predict the type of crop that can be grown in a particular region. Knowing
    the exact rate of change of features that draws the boundary of cultivation of
    the different crops is difficult. Hence For example the classification process
    is done to predict the type of crop that can be grown in a particular region.
    The data collected is under varying contexts used for training the model. We have
    tested the collected data set using state-of-the-art classifiers [(Khadse et al.,
    2020)(P)] decision tree, Naïve Bayes, kNN, and SVM. We have also utilized the
    classifier to build a light weighted majority voting approach. k-Nearest neighbour
    approach: Nearest neighbour (Kumar et al., 2020; Wu et al., 2009) classifiers
    calculate the nearest neighbour distance and the model is built accordingly. The
    distance metric is evaluated considering various approaches such as Euclidean,
    Manhattan, Mahalanobis, and so forth. The k parameter in the classifier is the
    number of data points that will be considered for building the model. Decision
    tree approach: Decision tree (Lu et al., 2009) is a tree-based classification
    approach that works by creating a tree-like model for prediction. Each node of
    the tree takes into consideration each of the feature vectors. For prediction,
    the data about each feature metric is parsed accordingly from the root of the
    tree through each node. The leaf of the tree contains the predicted crop which
    can be grown in the selected area of choice for cultivation. Naïve Bayes: Naïve
    Bayes (Priya et al., 2018) approach works by probabilistic modelling. The very
    model is built on the pretext of causality where the gathered soil features should
    fall under the label of the respective crop that can be grown. Naïve Bayes inherently
    considers the distribution of data to be Gaussian, so the accuracy drops if the
    classes are imbalanced. SVM (Dietterich, 2000) works by drawing a hyperplane amongst
    the class label, in this case, the class labels are the crops. The respective
    data points closer to the respective hyperplane is the class to which the data
    points belong. The kernel function of SVM plays a major part in transforming the
    data to its required form. 4.3 Ensemble model The ensemble models (Kaur et al.,
    2014) are built to take the collective decision in model building. Ensemble approaches
    can be built using the same classifiers or different classifiers. In the learning
    algorithm, the predicted output is considered for evaluation, and accordingly,
    the model is drawn. Balakrishnan and Muthukumarasamy (2016) proposed a crop production
    prediction model considering an ensemble of decision making between selected classifiers
    such as SVM and Naïve Bayes classifier proposing ensemble approach AdaSVM and
    AdaNaive. Another work on yield prediction can be found in Feng et al. (2020).
    The authors have utilized UAV based hyperspectral imagery for data collection.
    The collected data are fed into three regressors based on nearest neighbour, support
    vector and random forest. An ensemble model is drawn with the selected models.
    For our proposed model we have used majority voting which uses a combination of
    rules of bagging and boosting approach. Xtrain = [ x 1 , 1 ⋯ x 1 , m ⋮ ⋱ ⋮ x n
    , 1 ⋯ x n , m ] (10) Let Xtrain (Equation 10) be the data samples collected for
    training our model. The number of columns or m = 4 in our case as the considered
    features are rainfall, temperature, humidity and pH. The Ytrain is the associated
    class label; where Ytrain = [ y 1 , … , y n ] . (11) The output of the base classifiers
    can be mapped as follows M([ x i , 1 … . . ⁢ x i , m ] ) =  pred i . Let C be
    set of classifier list where C = [ c 1 … . . ⁢ c count _ b ] ; (12) where count_b
    is the number of base classifiers used for training the ensemble model. In traditional
    weight determination, the weights of the ensemble classifier w can be written
    as follows. ∑ i = 1 count _ b w i = 1 (13) Let p 1 , p 2 , p 3 be the prediction
    probability of the base level models; then the overall prediction probability
    p = ∑ i = 1 count _ b w i × p i . (14) Now , p = 1 − ( ∑ i = 1 count _ b w i ×
    p i ) / ( n × count _ b ) (15) In majority voting ensemble all the base classifiers
    are voted in a uniform manner; that is wi = 1/count_b where 1 ≥ i ≤ count_b. For
    our weighted majority voting classifier, we have evaluated the 10-fold cross-validation
    whose accuracy is given as accuracy _ CV ⁡ ( C i ) ; where Ci represents the classifier.
    The weight of the individual base learners are obtained as; W ⁡ ( Bi ) = Accuracy
    _ CV ⁡ ( C i ) ∑ i = 1 count _ b Accuracy _ CV ⁡ ( C i ) (16) here Bi is the base
    learner. Algorithm 2 depicts the majority voting procedure, which is deployed
    onto every edge drone to collect data and predict performance prediction and routing
    (Mukherjee, Panja, & Dey, 2020; Panja & Ghosh, 2020) in a real-time manner. Algorithm
    2. Majority Voting Input: D’ <- Preprocessed Data Output: Start 1. Initialize
    training and test set from the preprocessed dataset D’ 2. Tr=(Xtrain, Ytrain),  Tt
    = (Xtest, Ytest) 3. Initialize classifier list C =[ c1,c2,..ccount b ] , base
    learner count count_b 4. for i=1 to count_b do 5. begin 6.    Initialize base
    learner Bi with classifier ci. 7.    Bi=10-Fold- Cross Validation ( ci, Tr) 8.
    end 9. for i=1 to count_b do  10begin 11. Weight Determination wi using Equation
    (16) 12. predi = Classify(Bi, Tr) 13end 14. R = MajorityVoting(pred1, pred1… predb_count,
    w) Stop A block diagram depicting the model built with train and test set separately
    is shown in Figure 5. The training data is passed through 10-fold cross-validation
    where each of the classifiers is passed through state-of-the-art base classifiers.
    The base classifier''s parameters are tuned through experimentation. FIGURE 5
    Open in figure viewer PowerPoint Block diagram of the ensemble model building
    The objective of our approach is to provide a framework of drone as a service
    to the end-users. The pre-processing of the data is performed at the drone level
    or edge level itself. The gathered pre-processed information is routed opportunistically
    towards a base station and finally to a cloud service provider. The majority voted
    ensemble built is a very lightweight model, which is trained using the different
    classifiers. The model is deployed onto every drone to perform edge-level pre-processing
    (Chakrabarti et al., 2021) and prediction. The requests from the end-user are
    parsed through the system into the Base Stations at the area of interest which
    processes the query accordingly. 5 RESULT ANALYSIS 5.1 Network performance analysis
    The crucial performance metrics that have been chosen in this case are node density,
    message buffer size, and node speed. The reason behind choosing those parameters
    is to understand the message delivery and the latency overhead of the proposed
    methodology. In most cases, the FANET suffers serious latency issues due to the
    varying speed of the nodes themselves. This phenomenon is even more critical during
    intermittently connected nodes. It has been reported that under different mobility
    models the change in the speed of effects affects the message delivery ratio as
    well as the delivery latency. Therefore the performance analysis for the FANET
    communication ecosystem has to be done based on the performance metrics like delivery
    probability (DP), average latency (AL), message overhead ratio (MR). 5.1.1 Effect
    of node density in message delivery In a sparse FANET scenario node density offers
    a great impact on message delivery. Figure 6a,b illustrate the impact of the node
    density in DP for Gauss–Markov and shortest path mobility respectively. FIGURE
    6 Open in figure viewer PowerPoint (a) Delivery probability (DP) performance on
    varying node density for Gauss-Markov model. (b) DP performance on varying node
    density for shortest path map-based model The Gauss–Markov model mainly emphasizes
    the Markov process which primarily depends on tuning parameters. In the case of
    highly sparse network infrastructure (when the number of nodes is below 50) the
    DP for all routing models is moderate. As the number of nodes increases the chance
    of message forwarding increases because of the more number of intermediate relay
    nodes. In the case of the Gauss Markov model, the DP performance of MaxProp and
    the opportunistic MQTT perform almost similarly. As the number of node increases
    beyond 250, the opportunistic MQTT outperforms. This is because the timestamp
    management that has been introduced keeps track of nodes within the transmission
    range. In this case, the time stamp acts as a crucial parameter for the better
    connectivity of the nodes amongst each other. On the other hand, Epidemic routing
    reaches its maximum benchmark in the case of DP. In the case of the shortest path-map-based
    model, the fall of DP is not so drastic due to the choosing of the optimal path
    by the nodes. This is due to the encounter probability of the node are almost
    similar for most of the nodes. 5.1.2 Effect of node speed in message delivery
    The effect of the node speed on DP has been illustrated in Figure 7. The performance
    of epidemic routing under the Gauss Markov model presents the lowest benchmark
    of DP which is 0.35 while the speed is 30 km/h. MaxProp routing in this case outperforms
    opportunistic MQTT as it reaches the height benchmark of 0.88. This is due to
    the increasing delivery likelihood within the randomized movement path. FIGURE
    7 Open in figure viewer PowerPoint (a) Node speed versus delivery probability
    (DP) in Gauss Markov mobility, (b) node speed versus DP in shortest path map-based
    mobility In the case of the shortest path map-based model (shown in Figure 7b)
    the highest DP benchmark has been reached by both MaxProp and Opportunistic MQTT
    at a node speed of 30 km/h. It has also been observed that the DP has started
    increasing as the speed increases up to 20 km/h and after that, it becomes almost
    constant, Except ProPHET whose DP decreases by 30 km/h. The constant nature is
    reported due to the shortest path model in which the nodes are mainly using a
    constant mobility path. As the ProPHET is restricted flooding and it is optimized
    to ensure minimum message overhead so increasing speed in some cases offers a
    negative impact on it. 5.1.3 Performance evaluation based on latency and MR Message
    delivery latency and the overhead ratio is a crucial factor to understand the
    performance of the proposed message transfer strategy. Message overhead is also
    taken into account as a major performance benchmark too. In case of flooding the
    huge number of message copy has been generated within the network. As a result,
    more bandwidth gets consumed. The flooding also results in network congestion
    in some cases. Figure 8 shows the performance comparison of buffer size with the
    message delivery latency. It is a normal phenomenon that the increased buffer
    size leads to latency overhead in the network. As a result, more messages get
    temporarily buffered into the edge node. In the case of MaxProp routing, as the
    buffer size increases the latency increases exponentially, as a result, there
    is a chance of network congestion. Opportunistic MQTT and the ProPHET in this
    case perform almost similarly and they offer a maximum benchmark of 1565.12 and
    1611.31 ms respectively for the buffer size 100 MB. FIGURE 8 Open in figure viewer
    PowerPoint Latency performance comparison of different routing mechanisms 5.1.4
    AL comparison AL performance comparison of proposed message transfer strategy
    under the mentioned mobility model has been illustrated in Figure 9. FIGURE 9
    Open in figure viewer PowerPoint Average latency comparison for proposed message
    transfer framework under different mobility model Figure 9 shows a comparatively
    higher AL achieved by the Gauss Markov model in comparison to shortest path mobility.
    In the case of MaxProp routing, the AL reported being highest for both Gauss Markov
    as well as shortest path map-based mobility. On the other hand, Opportunistic
    MQTT offers a minimum latency benchmark for the shortest path map-based model
    which is 656.7 ms. In the case of the Gauss Markov model, ProPHET outperforms
    the opportunistic MQTT due to its restricted message forwarding nature. 5.1.5
    MR performance comparison The MR is a crucial metric to be considered to understand
    the performance of the proposed message transfer strategy. This ratio can be computed
    as the difference between the relayed and delivered messages upon the delivered
    message. Message overhead is a crucial component because this ensures the number
    of additional and unused messages in the network. The increasing number of message
    overhead causes network congestion for sure. If the time to live (TTL) for the
    message is extremely high then the chance of congestion has been increased exponentially.
    Therefore we have to observe this parameter crucially. Figure 10 shows the MR
    for the different message transfer strategies under two different mobility models.
    A large amount of message overhead is reported for the epidemic routing. This
    is because of the unrestricted flooding nature of the epidemic message transfer
    where most of the generated message has either been dropped or the session expired.
    In the case of MaxProp the Gauss Markov mobility gives a negative impact on the
    delivery likelihood. As the nodes are moving randomly, therefore, the more common
    nodes may be within the transmission range. Thereby increasing the number of message
    copies in the network. The opportunistic MQTT and the ProPHET have performed almost
    similarly in the shortest path Mapbase mobility which is near to 200. FIGURE 10
    Open in figure viewer PowerPoint Message overhead ratio comparison for the different
    routing mechanism 5.2 Classification accuracy The edge level classification is
    performed using the ensemble of classifiers constituting Gaussian Naïve Bayes,
    Decision Tree, KNN, and SVM approaches. The overview of the hyperparameter setting
    is given in Table 1. It has been observed for the k-NN classifier if the k neighbours
    are set to 6 it is giving the maximum accuracy. The Pruning method is employed
    in finding the height of the decision tree approach, and it has been found that
    for the selected dataset the depth of the tree fixed at 80 is giving the best
    result. In the case of SVM classification, extensive experimentation is performed
    by altering the kernels and the accuracy has been recorded. It has been found
    that radial bias function (rbf) is powerful against nonlinear datasets, hence
    the gamma coefficient for rbf is fixed accordingly, in our case it is fixed to
    2. Figure 11 gives an overall comparison between the approaches. It can be observed
    that the Ensemble approach is performing better than the rest of the approach
    with an accuracy of 96%. The F1-Score is also better in the case of the majority
    voting ensemble approach which is presented in Table 2. TABLE 1. Parameter setting
    of the classifiers Classifier Setting Decision tree (max depth) 80 KNN (n-neighbours)
    6 SVM (Kernel, gamma) Rbf, 2 Abbreviations: KNN, k-nearest neighbour approach;
    SVM, support vector machine. FIGURE 11 Open in figure viewer PowerPoint Comparison
    of classification accuracy with state-of-the-art classifier and majority voting
    ensemble TABLE 2. F1-score comparison table Classifier F1-score Decision tree
    0.91 KNN 0.87 SVM 0.90 Naïve Bayes 0.89 Majority voting 0.95 Abbreviations: KNN,
    k-nearest neighbour approach; SVM, support vector machine. The next set of experiments
    presents the comparison of resources required during the time of model building.
    The memory requirement in percentage is presented in Figure 12a,b presents the
    overall memory requirement in percentage. We can observe that the decision tree-based
    approach requires the least CPU resource during the training phase. Figure 13
    gives the overview of the time required during the time of model training. The
    time requirement is given in seconds, the time requirement gives the overall time
    required during the training process which is performed in the sink servers. It
    can be observed that for the selected training dataset the time required during
    training for the Naïve Bayes classifier is the least while the SVM classifier
    takes the maximum time in the training process. FIGURE 12 Open in figure viewer
    PowerPoint (a) Comparison plot of the classifier with respect to memory requirement
    during training. (b) Comparison plot of classifier with CPU requirement during
    training process FIGURE 13 Open in figure viewer PowerPoint Time requirement in
    seconds during training process by the classifiers used in model building 6 CONCLUSION
    AND FUTURE WORK In this work, an ultra-low-latency intelligent edge enabled FANET
    ecosystem has been proposed which sense, gather, and predict the best possible
    crop in cultivated land. The FANET nodes are taking a major role, in this case,
    to gather the data from different sensor deployment zones and opportunistically
    perform the publish-subscribe operation under both Gauss Markov and Shortest path
    mobility models. The standard opportunistic protocol has been compared with an
    opportunistic MQTT message transfer framework and the performance of the opportunist
    MQTT has been measured and compared. The message DP of near about 82% is reported
    in the Gauss Markov model and 89% for the shortest path map-based model has been
    reported in this case. On the other hand, the latency performance of the opportunistic
    MQTT has been measured as near about 1500 millisecond maximum. A reduced trend
    of message overhead has also been observed in the case of shortest path mobility
    as well. Furthermore, the performance of the machine learning model has been measured
    in an edge-enabled device. It has been observed that the weighted majority voting-based
    approach is performing better than the rest of the classifiers used in training
    the base learners. The Edge enables pre-processing and classification and allows
    the system to perform drone-level predictions. Furthermore, the proposed framework
    is built on the pretext of providing drones as an abstracted service to the end-users.
    There are certain limitations we have observed. Firstly the architecture is completely
    dealing with lightweight data. In the case of heavyweight data like images, video
    the proposed methodology has not been tested yet. If we encounter such a class
    of data then definitely the protocol and the prediction model must be changed.
    However, we can consider that as a future work for the proposed methodology. There
    is a lot of research scope involved in an intelligent edge enabled 6G-FANET system.
    The research can further be enhanced to the hybrid FANET and VANET communication
    through the dedicated software-defined network slices. In some cases, the protocols
    must be re-engineered for handling a bulk amount of data at a time like video
    or image streaming. Furthermore, other embedded computing boards onto the drones
    can be explored to add deep learning-based analysis in the domain of precision
    agriculture. Biographies Amartya Mukherjee is an Assistant Professor in the dept
    of CSE(AIML) at the IEM, Salt Lake, Kolkata, India. He is doing PhD from MAKAUT,
    West Bengal, India. He holds a master''s degree in computer science and engineering
    from the NIT, Durgapur, West Bengal, India. His research interest includes Flying
    Ad-Hoc networks, 5G communication, Edge Computing, IoT. He has published various
    papers in the journals of IEEE, Springr, Elsevier as well as he has published
    number of books in the domain of IoT, Intelligent sensing. Ayan Kumar Panja is
    M.Tech (CU), Ph.D.(Pursuing) from Jadavpur University. He is acting as an Assistant
    Professor in CSE(AIML), CSBS. He is an Assistant Professor in the dept. of CSE(AIML).
    He has written several books on WSN, Medical Systems in renowned publication house
    like Elsevier. His research interests includes Localization, Machine and Deep
    Learning, Sensor Networks and Sensor Clouds. Nilanjan Dey is an Associate Professor
    in the Department of Computer Science and Engineering, JIS University, Kolkata,
    India. He is a visiting fellow of the University of Reading, UK. He also holds
    the position of Adjunct Professor at Ton Duc Thang University, Ho Chi Minh City,
    Vietnam. Previously, he held an honorary position of Visiting Scientist at Global
    Biomedical Technologies Inc., CA, USA (2012–2015). He was awarded his Ph.D. from
    Jadavpur University in 2015. He is the Editor-in-Chief of the International Journal
    of Ambient Computing and Intelligence, IGI Global, USA. He is the Series Co-Editor
    of Springer Tracts in Nature-Inspired Computing (Springer Nature), Data-Intensive
    Research (Springer Nature), and Advances in Ubiquitous Sensing Applications for
    Healthcare (Elsevier). He is an associate editor of IET Image Processing and an
    editorial board member of Complex & Intelligent Systems, Springer Nature, Applied
    Soft Computing, Elsevier etc. He is having 110 books and over 300 publications
    in the area of medical imaging, machine learning, computer-aided diagnosis, data
    mining, etc. He is the Indian Ambassador of the International Federation for Information
    Processing–Young ICT Group and Senior member of IEEE. Rubén González Crespo has
    a PhD in Computer Science Engineering from the Pontifical University of Salamanca,
    he is also Industrial Engineering from the same University. Currently he is Vice-president
    of Academic Affairs and Faculty from UNIR and Chief Academy Officer from PROEDUCA
    Group. He is advisory board member for the Ministry of Education at Colombia and
    evaluator from the National Agency for Quality Evaluation and Accreditation of
    Spain (ANECA). Open Research REFERENCES Citing Literature Volume40, Issue4 May
    2023 e13090 Citation Statements beta Supporting 0 Mentioning 2 Contrasting 0 Explore
    this article''s citation statements on scite.ai powered by   Figures References
    Related Information Recommended Intelligent use of fog devices in edge‐cloud paradigm
    to assist in E‐polling Adnan Khalid,  Muhammad Shahbaz,  Imran Ahmed Khan Concurrency
    and Computation: Practice and Experience Metropolitan intelligent surveillance
    systems for urban areas by harnessing IoT and edge computing paradigms Rustem
    Dautov,  Salvatore Distefano,  Dario Bruneo,  Francesco Longo,  Giovanni Merlino,  Antonio
    Puliafito,  Rajkumar Buyya Software: Practice and Experience CloudSimSDN‐NFV:
    Modeling and simulation of network function virtualization and service function
    chaining in edge computing environments Jungmin Son,  TianZhang He,  Rajkumar
    Buyya Software: Practice and Experience Mobility Management UAV‐based Grouping
    routing protocol in flying ad hoc networks for biomedical applications J. Vijitha
    Ananthi,  P. Subha Hency Jose International Journal of Communication Systems Edge‐enabled
    IoT gateway criteria selection and evaluation Peter Papcun,  Erik Kajati,  Dominika
    Cupkova,  Jozef Mocnej,  Martin Miskuf,  Iveta Zolotova Concurrency and Computation:
    Practice and Experience Download PDF Additional links ABOUT WILEY ONLINE LIBRARY
    Privacy Policy Terms of Use About Cookies Manage Cookies Accessibility Wiley Research
    DE&I Statement and Publishing Policies Developing World Access HELP & SUPPORT
    Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES Subscription
    Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley Network Wiley
    Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related companies.
    All rights reserved, including rights for text and data mining and training of
    artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: Expert Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: An intelligent edge enabled 6G-flying ad-hoc network ecosystem for precision
    agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Koubaa A.
  - Ammar A.
  - Abdelkader M.
  - Alhabashi Y.
  - Ghouti L.
  citation_count: '12'
  description: Unmanned aerial vehicles (UAVs) equipped with computer vision capabilities
    have been widely utilized in several remote sensing applications, such as precision
    agriculture, environmental monitoring, and surveillance. However, the commercial
    usage of these UAVs in such applications is mostly performed manually, with humans
    being responsible for data observation or offline processing after data collection
    due to the lack of on board AI on edge. Other technical methods rely on the cloud
    computation offloading of AI applications, where inference is conducted on video
    streams, which can be unscalable and infeasible due to remote cloud servers’ limited
    connectivity and high latency. To overcome these issues, this paper presents a
    new approach to using edge computing in drones to enable the processing of extensive
    AI tasks onboard UAVs for remote sensing. We propose a cloud–edge hybrid system
    architecture where the edge is responsible for processing AI tasks and the cloud
    is responsible for data storage, manipulation, and visualization. We designed
    AERO, a UAV brain system with onboard AI capability using GPU-enabled edge devices.
    AERO is a novel multi-stage deep learning module that combines object detection
    (YOLOv4 and YOLOv7) and tracking (DeepSort) with TensorRT accelerators to capture
    objects of interest with high accuracy and transmit data to the cloud in real
    time without redundancy. AERO processes the detected objects over multiple consecutive
    frames to maximize detection accuracy. The experiments show a reduced false positive
    rate (0.7%), a low percentage of tracking identity switches (1.6%), and an average
    inference speed of 15.5 FPS on a Jetson Xavier AGX edge device.
  doi: 10.3390/rs15071873
  full_citation: '>'
  full_text: '>

    "This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details                Deny Allow selection
    Allow all     Journals Topics Information Author Services Initiatives About Sign
    In / Sign Up Submit   Search for Articles: Remote Sensing All Article Types Advanced   Journals
    Remote Sensing Volume 15 Issue 7 10.3390/rs15071873 Submit to this Journal Review
    for this Journal Propose a Special Issue Article Menu Academic Editors Wenjiang
    Huang Giovanni Laneve Yingying Dong Show more... Subscribe SciFeed Recommended
    Articles Related Info Link More by Authors Links Article Views 3230 Citations
    12 Table of Contents Abstract Introduction Materials and Methods Results Discussion
    Conclusions Author Contributions Funding Acknowledgments Conflicts of Interest
    References Altmetric share Share announcement Help format_quote Cite question_answer
    Discuss in SciProfiles thumb_up Endorse textsms Comment first_page settings Order
    Article Reprints Open AccessArticle AERO: AI-Enabled Remote Sensing Observation
    with Onboard Edge Computing in UAVs by Anis Koubaa *,†, Adel Ammar †, Mohamed
    Abdelkader , Yasser Alhabashi and Lahouari Ghouti College of Computer & Information
    Sciences, Prince Sultan University, Riyadh 11586, Saudi Arabia * Author to whom
    correspondence should be addressed. † These authors contributed equally to this
    work. Remote Sens. 2023, 15(7), 1873; https://doi.org/10.3390/rs15071873 Submission
    received: 3 March 2023 / Revised: 27 March 2023 / Accepted: 29 March 2023 / Published:
    31 March 2023 (This article belongs to the Special Issue Recent Progress in UAV-AI
    Remote Sensing) Download keyboard_arrow_down     Browse Figures Versions Notes
    Abstract Unmanned aerial vehicles (UAVs) equipped with computer vision capabilities
    have been widely utilized in several remote sensing applications, such as precision
    agriculture, environmental monitoring, and surveillance. However, the commercial
    usage of these UAVs in such applications is mostly performed manually, with humans
    being responsible for data observation or offline processing after data collection
    due to the lack of on board AI on edge. Other technical methods rely on the cloud
    computation offloading of AI applications, where inference is conducted on video
    streams, which can be unscalable and infeasible due to remote cloud servers’ limited
    connectivity and high latency. To overcome these issues, this paper presents a
    new approach to using edge computing in drones to enable the processing of extensive
    AI tasks onboard UAVs for remote sensing. We propose a cloud–edge hybrid system
    architecture where the edge is responsible for processing AI tasks and the cloud
    is responsible for data storage, manipulation, and visualization. We designed
    AERO, a UAV brain system with onboard AI capability using GPU-enabled edge devices.
    AERO is a novel multi-stage deep learning module that combines object detection
    (YOLOv4 and YOLOv7) and tracking (DeepSort) with TensorRT accelerators to capture
    objects of interest with high accuracy and transmit data to the cloud in real
    time without redundancy. AERO processes the detected objects over multiple consecutive
    frames to maximize detection accuracy. The experiments show a reduced false positive
    rate (0.7%), a low percentage of tracking identity switches (1.6%), and an average
    inference speed of 15.5 FPS on a Jetson Xavier AGX edge device. Keywords: unmanned
    aerial vehicles; object detection; object tracking; remote sensing; object localization;
    edge computing; inspection; YOLOv4; YOLOv7; DeepSORT 1. Introduction The use of
    unmanned aerial vehicles (UAVs), also known as drones, in remote sensing has been
    increasingly beneficial as they help to speed up the data collection of assets
    of interest using aerial images. Drones make the data collection process cost-effective
    and flexible as drones can fly at low or high altitudes. It also helps missions
    to be more efficient as large regions can be precisely covered in short times
    thanks to the use of high-resolution cameras. Data collection also becomes safe
    as drones replace humans entering dangerous or difficult-to-access environments.
    These benefits are driving the remote sensing business to increasingly rely on
    drones. As a matter of fact, the market of commercial use of UAVs, including remote
    sensing applications, was valued at USD 5.85 billion in 2020 and is expected to
    have a compound annual growth rate of 14.2% [1]. 1.1. Motivating Scenarios AI-powered
    drones with onboard intelligence are becoming a game changer for many applications,
    including search and rescue, rapid infrastructure inspection, and remote sensing,
    to name a few. Integrating AI solutions directly on the drone’s edge (compute)
    devices can dramatically reduce the decision-making time and operational costs.
    In this paper, we will discuss several scenarios in different use cases’ contexts,
    showing the limitation of existing solutions of UAVs for vision-based applications
    and discussing the advantages of real-time onboard AI. 1.1.1. Remote Sensing Tree
    counting is one of the applications in remote sensing, where a drone surveys farm
    regions to count the number of trees. In [2], the authors proposed an offline
    counting and geo-localization of palm trees based on aerial images using deep
    learning. However, the processing was performed offline after collecting palm
    tree images from a UAV. The process of data collection and its offline processing
    takes a long time and needs to be performed in real time. Leveraging GPU-based
    edge devices on board the UAV enables the full automation of palm tree counting
    in real time. Furthermore, it helps to send each palm tree information (e.g.,
    image and coordinates) to the cloud and store it in databases in real time. Naturally,
    the same concept can be applied to other remote sensing applications, such as
    gas leakage localization and mapping [3], flash flood real-time monitoring [4,5],
    and urban environment segmentation [6,7]. 1.1.2. Search and Rescue Consider a
    search-and-rescue mission where a drone is required to explore an extended region
    to search for a missing person in the desert or a forest, for example. It has
    been reported that more than 100 people get lost and die in the desert annually
    in Saudi Arabia alone [8]. The current practice for search-and-rescue using UAVs
    is to manually explore a region with human observers to find the target missing
    people. Using AI on board will help to automate the process as the UAV can execute
    specialized person detection models on board and automatically report their location
    in real time. It is also possible to use a swarm of drones to perform search-and-rescue
    missions in parallel, speeding up the search process and increasing the probability
    of finding and saving people [9]. 1.1.3. Inspection and Surveillance Surveillance
    and inspection using UAVs is one of the fastest businesses in the drone industry
    [10]. Drones are typically used to detect objects of interest in surveillance
    missions, such as vehicles [11], pedestrians [12], and buildings [13]. Traditional
    approaches either inspect real-time video streams by human observers or record
    scenes’ videos and process them offline either manually or using AI techniques
    to extract target objects. The use of onboard AI processing in the UAVs will help
    to automate the inspection process and identify target objects in real time with
    a high accuracy, as will be demonstrated in this paper. The automation of these
    applications on board UAVs is possible thanks to the evolution of edge devices
    and their support of advanced graphics processing units (GPUs), making it possible
    to process complex deep learning models in real time. Before the evolution of
    edge computing, computation offloading has evolved as the prominent approach to
    processing heavy computation in the cloud instead of processing them on robots
    or drones. This concept has been known as cloud robotics. While computation offloading
    offers several advantages by leveraging the capabilities of the cloud resources
    to speed up the processing of deep learning models and computation-intensive applications,
    it suffers from high communication overhead. It also needs a large bandwidth and
    high-quality communication, which cannot always be afforded. In [14], the authors
    proposed a system architecture for computation offloading in Internet-connected
    drones and compared the performance of cloud computation offloading versus edge
    computing for deep learning applications. The study investigated the tradeoff
    between the communication cost and computation and found that computation offloading
    provides higher throughput despite larger communication delays. 1.2. Main Contributions
    In this paper, we aimed to tackle the persisting challenge of deploying onboard
    artificial intelligence on the edge in commercial unmanned aerial vehicles (UAVs)
    that are primarily utilized for remote sensing applications. This predicament
    often necessitates laborious manual data observation or time-consuming offline
    processing, as cloud-based approaches are often impractical. There are a few recent
    works that tested onboard AI on edge in UAVs for detection and tracking, such
    as [15,16,17]. Nevertheless, they did not investigate the hybrid system architecture
    that we implemented in this work, and did not discuss the role of the cloud in
    their solution. To bridge this gap, we propose using edge computation on board
    drones to enable advanced observation and surveillance applications, involving
    object detection, multi-object-tracking, and real-time reporting of detected target
    objects to the cloud. In brief, the contributions of the paper can be summarized
    as follows: We propose a new approach to using edge computing in drones to enable
    the processing of extensive AI tasks on board UAVs for remote sensing. To overcome
    the limited connectivity and high latency of remote cloud servers, we propose
    a cloud–edge hybrid system architecture. In this architecture, the edge is responsible
    for processing AI tasks, and the cloud is responsible for data storage, manipulation,
    and visualization. Our proposed architecture can provide a more scalable and efficient
    solution for remote sensing applications. To implement our proposed architecture,
    we designed and developed AERO, a UAV brain system with onboard AI capability
    using GPU-enabled edge devices. AERO allows us to capture objects of interest
    with high accuracy and transmit data to the cloud in real time without redundancy.
    AERO processes the detected objects over multiple consecutive frames to maximize
    detection accuracy. AERO can be a significant advancement in the field of remote
    sensing as it enables UAVs to perform onboard AI tasks with high accuracy and
    real-time data transmission, providing a more efficient and cost-effective solution
    for remote sensing applications. The remaining sections of the paper are organized
    as follows. Section 1.3 provides a review of the relevant literature and situates
    the contribution of the paper in comparison to previous work. Section 2 presents
    the architecture of the AERO system and describes the AERO AI Module. In Section
    3, we detail the experimental study conducted to evaluate the AERO system’s performance,
    and we discuss their results in Section 4. Finally, Section 5 concludes the paper
    and suggests potential future research directions for further improvements. 1.3.
    Related Works The introduction of UAVs in remote sensing has paved the way for
    several promising applications that span a wide range of domains [18]. Impressive
    progress has been achieved in academic and industrial arenas. Diversity in available
    solutions is mainly attributed to the underlying technologies and modalities used
    in the data sense/acquisition processes [19]. The latter processes are domain-specific
    in nature [20,21]. Other techniques, including data preprocessing, feature extraction,
    and classification, are specifically designed for the application, whether civilian
    or military. UAV applications in remote sensing have been reviewed in [21,22].
    1.3.1. Edge Computing and UAVs Several recent works addressed the edge computing
    paradigm, which involves moving computational processing and storage closer to
    the end-users, devices, or sensors rather than relying solely on cloud-based solutions.
    Specifically, these works focused on leveraging UAVs to offload computation tasks
    to edge computing servers, which enables low-latency computations of specific
    tasks without noticeable delay. In [23], Messous et al. proposed an evaluation
    mechanism of the integration of the computation offloading to edge computing servers
    for the efficient deployment of UAVs. Based on the proposed evaluation, UAV-based
    models are able to decide whether to perform local processing, offload to an edge
    server, or delegate the computational tasks to the ground station. Informed decisions
    are based on low-latency computations of specific tasks without noticeable delay.
    Qian et al. [24] investigated the performance of a UAV-mounted mobile edge computing
    network where the UAV unit offloads and executes specific tasks that originate
    from some mobile terminal users. The trajectory planning problem was formulated
    as a Markov decision process (MDP) where optimal trajectories were obtained using
    a policy based on the double deep Q-network (DDQN) algorithm [25]. Thanks to the
    DDQN efficiency, higher throughput scores were attained. A machine-learning-based
    solution for the planning of UAV trajectories is attributed to Afifi, and Gadallah
    [26]. Unlike many existing solutions, Afifi and Gadallah targeted missions with
    real-time navigation requirements in dense urban environments, where existing
    5G infrastructures are astutely employed to ensure UAV navigation in complex environments
    through continuous interactions between the UAV units and the selected 5G network.
    Like [24], the proposed trajectory planning solution relies on deep reinforcement
    learning strategies, where the planning accuracy attains 99%. In [27], Xia et
    al. proposed a flexible design of a wireless edge network using two UAV units.
    In this design, both units are restricted to operate at fixed altitudes with accelerated
    motions. Over a defined area, while the first UAV unit is in charge of forwarding
    downlink signals to the user terminals (UTs), the second unit is assigned to the
    collection of the uplink data. Using statistical information collected from the
    UT elements and UAVs, lower bounds on conditional average achievable rates are
    derived. The proposed scheme is demonstrated to attain an energy efficiency higher
    than existing ones. Bin et al. [28] tackled the problem of the variability of
    user mobility and MEC environments, where they suggested a novel scheme for intelligent
    task offloading in UAV-enabled MEC systems using a digital twin (DT). At the core
    of the proposed scheme lies the DDQN model, which is specifically designed to
    effectively constrain multi-objective problems. The model was jointly optimized
    using closed-form and iterative procedures. The simulation results clearly indicate
    the convergence of the DDQN-based model while drastically minimizing the total
    energy consumption of the MEC system compared to existing optimization techniques.
    A new aerial edge Internet of Things (EdgeIoT) system was contributed by Li et
    al. [29]. In this new EdgeIoT system, a UAV unit is operated as a mobile edge
    server for processing computational processes related to mission-critical tasks
    emanating from ground IoT devices. To capture the underlying feature correlations,
    a graph-based neural network architecture (GNN) was used for the supervised training
    of the A2C structure. The reported performance analysis highlights the superiority
    of the mixed GNN-A2C framework in terms of the convergence speed and missing task
    rates. In [30], Qian et al. proposed a Monte Carlo tree search (MCTS)-based path
    planning technique assuming that a single UAV is deployed as a mobile service
    to provide computation tasks offloading services for a set of mobile users on
    the ground. The reported results show that the MCTS-based scheme outperforms state-of-the-art
    DQN-based planning algorithms in terms of the average throughput and convergence
    speed. In some instances, UAVs assist edge clouds (ECs) for the large-scale sparely
    distributed user equipment, which allows for wide coverage and reliable wireless
    communication. However, UAVs have limited computation and energy resources, which
    opens the floor for potential optimal resource allocation. In [31], Wang et al.
    introduced a vehicular fog computing (VFC) system where unmanned ground vehicles
    (UGVs) perform the computation tasks offloaded from UAVs that are deployed in
    natural disaster areas. In these areas, UAVs are effectively used to survey disaster
    areas and even perform emergency missions, given their swift deployment and flexibility.
    However, this efficiency is hindered by the limited energy and computational capabilities
    of UAVs. These limitations are properly addressed by the VFC-based UAV system
    proposed by Wang et al., where UGVs may be assigned to perform the computation
    tasks offloaded from UAVs to save energy and computational power. To ensure a
    smooth and steady UAV–UGV collaboration and interaction, the computation task
    offloading problem was cast into a two-sided matching problem, where an iterative
    stable matching algorithm was used. This matching algorithm aims at assigning
    to each UAV the most suitable UGV among the available ones for offloading while
    maximizing the usage of both UAVs and UGVs and reducing the average delay. Yang
    et al. [32] considered a UAV-enabled MEC platform where multiple mobile ground
    users move randomly and tasks arrive in a random fashion. To minimize the average
    weighted energy consumption of all users under constraints expressed in terms
    of data queue stability and average UAV energy consumption, Yang et al. suggested
    a multi-stage stochastic optimization scheme where Lyapunov optimization is converted
    into simpler per-slot deterministic problems vis-a-vis the number of optimizing
    variables. Based on their formulation, Yang et al. solved the resource allocation
    and the UAV movement problems using two reduced-complexity methods, either jointly
    or separately. The two methods not only satisfy the average UAV energy and queue
    stability constraints, but they also reconcile the length of the queue backlog
    and the user energy consumption bounds. The reported results show that the proposed
    joint and two-stage stochastic optimization schemes outperform existing learning-based
    solutions. Finally, it should be noted that the joint optimization scheme attains
    a better performance than its two-stage counterpart at the expense of an increased
    computational complexity. Most of the solutions discussed so far attempt to optimize
    the UAVs’ total (or average) energy consumption and computational power allocation
    among mobile users using some type of learning-based strategy. In their proposal,
    Lyi et al. [33] adopted a different approach to maximize the computation bits
    of the whole MEC system: the joint optimization of task offloading time allocation,
    bandwidth allocation, and the UAV trajectory under specific energy constraints
    of ground devices and maximal UAV battery energy. The proposed solution splits
    the overall optimization procedure into three stages, where successive convex
    optimization schemes are used. Once individual solutions are identified, a block
    coordinate descent (BCD) algorithm integrates the solution of the initial optimization
    problem. Such a formulation aims at obtaining alternating optimal solutions for
    the optimization variables considered (bandwidth allocation of ground devices,
    task offloading time, local computing time allocation, and UAV trajectory) at
    each time slot. Extensive simulation experiments were conducted to demonstrate
    the performance improvement attained by the proposed BCD-based solution. Overall,
    the proposed solutions discussed in this section suggest that UAV-based edge computing
    systems have certain advantages over cloud-based techniques in terms of optimization,
    convergence speed, throughput, and energy efficiency. These advantages make UAV-based
    edge computing systems a promising solution for various applications, including
    precision agriculture, smart cities, and disaster management, where real-time
    data processing and optimization are critical. 1.3.2. Summary of Related Works
    A summary of the current literature is provided in Table 1. Onboard AI edge computing
    is becoming increasingly important for UAV systems, especially those utilizing
    EMC-based solutions. While EMC-based UAV systems offer benefits such as flexibility,
    resilience, and swift deployment, they also present new challenges that can only
    be addressed by advanced AI-based solutions, such as reinforcement and deep learning
    frameworks. Table 1. Comparative analysis of related work. One reason for why
    onboard AI edge computing is necessary for EMC-based UAV systems is the need for
    real-time decision making. In certain applications, such as emergency response,
    decisions need to be made quickly and accurately. Onboard AI edge computing can
    process data in real time, allowing the UAV to make decisions based on the information
    that it collects, without the need for remote servers. This reduces latency and
    ensures that decisions are made in a timely manner. Another reason is the need
    for autonomy. UAVs equipped with onboard AI edge computing can perform tasks autonomously,
    without human intervention. This is important in applications where it may be
    dangerous or impractical for humans to be present, such as in disaster response
    or surveillance missions. The AI algorithms on board the UAV can analyze the data
    collected and make decisions based on pre-defined rules, allowing the UAV to carry
    out its tasks independently. Furthermore, onboard AI edge computing allows for
    a more efficient use of resources. With the computing power on board, data can
    be processed locally without the need for constant data transmission to remote
    servers. This saves time and energy, and allows for a more efficient use of the
    UAV’s limited resources, such as its battery life. Based on the previous review
    of the existing literature, there is a growing trend in adopting EMC-based UAV
    systems, given their flexibility, resilience, and swift deployment. However, new
    challenges emerge with the deployment of such systems that can be handled only
    by advanced AI-based solutions, including reinforcement and deep learning frameworks.
    In fact, the solutions reviewed in the previous section are founded on well-established
    algorithms that have shown promising results in other engineering and science
    fields, including the optimal policy for emergency situations, data fusion, and
    information retrieval [34,35,36]. UAVs are becoming increasingly prevalent across
    multiple industries due to their flexibility and resilience. MEC-enabled UAVs
    are capable of providing computing and communication services at the network edges,
    even for ground-based units in areas with limited network coverage. This is particularly
    important in the field of remote sensing, where data collected from sensors on
    board the UAV need to be processed and analyzed in real time to support timely
    decision making. The ability of MEC-equipped UAVs to handle computing tasks and
    communication services at the network edges can significantly improve the speed
    and accuracy of remote sensing data collection processes. Adopting edge computing
    for the onboard processing on UAVs is a challenging problem, yet beneficial from
    several perspectives. Embedding computation-intensive applications on the UAV
    edge device requires sufficient energy, storage, and computation resources to
    manage the demanding requirements of AI tasks. However, with the evolution of
    edge devices’ capabilities, most of these challenges are overcome to a large extent,
    which makes edge computing in UAVs possible. 2. Materials and Methods 2.1. The
    AERO System 2.1.1. Why AI-Enabled Edge Computing for UAVs? AI-enabled edge computing
    for UAVs can provide several benefits, including a low latency, increased efficiency,
    improved reliability, and enhanced privacy, as described below. Low Latency: with
    advances in graphics processing units (GPUs) for edge devices (e.g., NVIDIA’s
    Jetson boards), edge computing enabled the real-time processing of AI tasks, such
    as object detection, recognition, and tracking. This was not possible a couple
    of years ago. Consequently, edge computing promotes the real-time processing of
    data on board by allowing the drone to make quick local decisions about detected
    objects (e.g., the detection of a person to rescue) before sending the information
    to the cloud, thus saving useless communication with the server. Increased efficiency:
    this approach also improves efficiency by decreasing communication overhead, saving
    bandwidth usage, and reducing the latency and load of the cloud servers. In fact,
    in the case of the cloud computing approach, the drone has to stream images at
    a high frequency and offload AI computation to the cloud. This is greedy in terms
    of the bandwidth and communication overhead, induces more communication latencies,
    and lacks scalability and computation cost, as the cloud cannot tolerate massive
    video traffic with real-time data processing. Edge computing helps to reduce the
    amount of data to be transmitted over a network and sent to the server. Improved
    Reliability: computation on edge also improves the reliability of AI-based UAV
    applications. First, the drone data collection process will be less affected by
    the possible loss of communication due to the increased autonomy of the drone
    by locally processing collected data. In case of total communication loss, the
    data of detected objects are still saved locally and transferred to the cloud
    when the communication is back or offline in the worst scenario. In addition,
    edge computing makes the processing of AI tasks distributed among the UAVs and
    not centralized in the cloud, which can be vulnerable to outages or other disruptions.
    There are two resulting benefits: (1) it avoids the single point of failure, and
    (2) it increases the system’s scalability as computing is fully distributed. Better
    privacy: the local processing of collected images and detected objects helps to
    enhance privacy preserving by reducing the amount of data that are transmitted
    and stored in centralized remote servers. Adopting strong encryption on individual
    detected object frames is more efficient than encrypting the whole video stream.
    In addition, collected object images transmitted to the cloud will remain private
    and secure against unauthorized access, as they no longer require being processed
    as plain data. 2.1.2. AERO System Architecture In this section, we present the
    system architecture of AERO, shown in Figure 1. Figure 1. AERO system architecture.
    The objective of the AERO system is to provide an ecosystem for using an edge-device
    on UAVs to execute complex deep learning algorithms to help automate computer
    vision applications, including object detection and tracking, on board the UAVs.
    The AERO system is composed of four layers: The Drone Layer: this represents the
    one UAV subsystem that is equipped with onboard processing and storage capabilities
    to perform AI tasks such as image and video analysis in real time. Edge computing
    is used to locally process collected raw data rather than sending them to a remote
    server as a video stream. In the UAV AERO, the edge device is a GPU-based embedded
    system (e.g., NVIDIA Jetson Xavier board) directly attached to the drone’s camera
    through a proper channel (USB port, Ethernet (RTSP), or serial). The drone uses
    its network interfaces (e.g., 4G/5G cellular networks or WiFi) to communicate
    with and transmit detected objects’ images to the cloud. The Swarm Layer: this
    layer consists of a cluster of UAVs equipped with camera sensors and AI-edge devices
    that coordinate together to perform a cooperative mission; for instance, distribute
    a search for lost people in a large area. In Figure 1, the UAVs swarm communicates
    with the cloud, which orchestrates their mission, rather than adopting ad hoc
    communication among the drones. The reasons are as follows: – Increased Reliability:
    the communication of UAVs with the cloud through cellular networks provides a
    more robust and stable connectivity compared to ad hoc swarms, which may be subject
    to interference and non-guaranteed message exchange, particularly in large-scale
    deployment. In critical applications such as search and rescue, it is essential
    to maintain reliable communication to ensure better coordination between drones
    through the cloud server. – Interference: in ad hoc swarm communication, the drones
    have to contend for channel access (e.g., CSMA/CA). This will lead to interference
    and collision, which requires message retransmissions. This results in poor communication
    efficiency and increased delays. Other approaches involve the use of time synchronization
    (e.g., time division multiple access (TDMA)), but these techniques are challenging
    as they need to maintain synchronization among the UAVs. Clock drift, latency,
    interference, and the dynamic nature of the UAVs can all impact the accuracy of
    the transmissions, leading to disruptions in the synchrony of the TDMA system.
    – Global Knowledge: with all swarm UAVs communicating with the cloud, the latter
    maintains up-to-date information about all UAVs, including their positions, their
    states, and the list of detected objects. The cloud can make informed decisions
    in real time and an adjustment of the mission plan or resource allocations. For
    example, if a UAV experiences low battery levels, the cloud will be better positioned
    to reassign its tasks to other drones based on optimized criteria. The cloud can
    also optimize the task allocation among all drones and give its global knowledge
    to ensure that mission execution is completed effectively. Overall, these planes
    work together to support the operation and management of a fleet of drones. The
    data plane handles the collection and processing of data, the user plane enables
    human users to interact with the system, and the drone plane manages the operation
    of the drones themselves. The Cloud Layer: as the UAV edge device performs AI
    computation-intensive tasks, the cloud system does not require having sextensive/advanced
    computing resources (GPU-based cloud systems are not required), which reduces
    the deployment cost considerably, as GPU-based cloud systems tend to be more expensive
    than CPU-based cloud systems. The cloud is responsible for data storage, manipulation,
    and visualization. The cloud is organized into three planes. – UAV Plane: the
    UAV plane is primarily responsible for managing the operation of a fleet of drones,
    including overseeing and coordinating the drones’ activities, managing the data
    collected by the drones, and performing mission planning to ensure compliance
    and safety. The fleet management system (FMS) plays a critical role in controlling
    and monitoring drones, scheduling their tasks and missions, and ensuring their
    compliance with airspace regulations. These benefits include improved efficiency,
    data management, and safety. – Data Plane: the data plane is responsible for handling
    the large amounts of data generated by the drones’ sensors and onboard equipment.
    During operation, the drones collect a large amount of data and send them to the
    cloud for storage and processing using advanced data analytics frameworks, and
    visualize dashboards to end-users for quick analysis and decision making based
    on the data collected by the drones. The data plane also ensures the persistence
    and availability of the data when needed by the end users through replication,
    caching, and load balancing. – User Plane: the user plane in the AERO system is
    responsible for interacting with users, including mission planning, monitoring,
    and control. It allows users to access the system through various interfaces and
    applications, such as a web-based dashboard, mobile app, or API. Through the user
    plane, users can create and manage drone missions, view real-time drone data,
    and receive alerts and notifications. Users can monitor the status and performance
    of the operating drones in real time, providing important information such as
    flight paths, battery levels, and sensor data. This feature is essential in situations
    such as emergency response scenarios and surveillance operations. The user plane
    is a critical component of the AERO system, enabling efficient and effective drone
    operations by providing a user-friendly interface for mission management and real-time
    monitoring. The End-User Layer: the end-user layer in the AERO system enables
    end-users to access the system through the Internet using web service APIs. The
    end-users use interactive dashboards to monitor the status of their drones in
    real time, send commands, and receive real-time video streams that have been processed
    by deep learning applications located either at the edge or on the cloud. The
    end-user layer interacts with the cloud layer through its user plane, which provides
    access to authorized cloud resources and allows them to interact, monitor, and
    control drones for operation. The end-users can be of different types depending
    on their role. – Authority: responsible for authorizing drone operations, managing
    the drone fleet, and ensuring compliance with regulations. – Operator: responsible
    for managing and operating drone fleets, executing drone missions, and ensuring
    safety. – User: requests drone operations for various purposes, such as aerial
    photography, surveying, or inspection. 2.1.3. AI-Enabled UAV This section describes
    the UAV platform that we used to test the AERO system in practice. Figure 2 depicts
    our custom-built battery-powered hexacopter platform and highlights its main components.
    The hexacopter specifications are detailed in Table 2. Figure 2. Top view of the
    custom hexacopter. Table 2. Hexacopter specifications. The selected hexacopter
    platform was equipped with custom onboard electronics to enable edge computing
    as well as continuous cloud connectivity. The hardware architecture of the custom
    onboard electronics and communication systems are shown in Figure 3, and are described
    as follows. Figure 3. UAV onboard electronics. Gimbal–camera System: this is a
    camera–gimbal system which consists of the main vision sensor that is stabilized
    by a 3-axis gimbal. This system is called a SIYI ZR10 gimbal–camera system and
    has a 30× hybrid zoom (10× optical and 3× digital) and a 2K camera. The gimbal–camera
    system has its own microprocessor, which has an RTSP (real time streaming protocol)
    server that sends real-time image streams to clients (edge and communication devices)
    using Ethernet connections. In addition, the camera orientation is stabilized
    and controlled by a 3-axis gimbal to control the visual region of interest during
    flight. NVIDIA Jetson Xavier NX: this is the main computation board (edge device)
    and has adequate GPU power to perform real-time object detection and advanced
    autonomous surveillance mission planning. It is connected to the camera–gimbal
    system, via an Ethernet switch, to receive the real-time image stream and send
    camera–gimbal commands to control the camera orientation and zoom level. The Xavier
    NX runs our custom software, which performs real-time object detection and localization,
    which is described in Section 2.2. It also has a connected 4G module to enable
    extended communication with the cloud server to send information about the detected
    objects and receive surveillance mission requests. 4/5G communication: a 4/5G
    communication module is connected to the Xavier NX module to enable communication
    with the cloud server for an extended range. The communicated information includes
    the image frames with metadata (e.g., detected objects and their coordinates)
    sent from the edge device to the cloud server, and mission requests from the cloud
    server to the edge device. Ethernet switch: this hardware module is used to allowfor
    transmitting the camera image stream to the onboard computer (Jetson Xavier NX)
    for image processing, as well as the air unit transceiver, which communicates
    with a ground remote controller for visualization. Pixhawk Orange Cube flight
    controller: this is the autopilot hardware, which runs the well-known open-source
    PX4 autopilot firmware [37]. The autopilot stabilizes the drone’s position and
    executes planned missions that are sent by the onboard computer. Air unit transceiver:
    this module exchanges image streams and UAV telemetry with a ground remote controller
    using a 2.4 GHz link. Remote controller: the ground remote controller is used
    by the UAV backup pilot to control the drone maneuvers, if needed, and have real-time
    visual feedback of the onboard camera stream. 2.2. The AERO AI Module In this
    section, we present the AERO brain system that leverages YOLOv7 [38] for object
    detection, DeepSort [39] for object tracking, and TensorRT (TRT) [40] acceleration
    to ensure the real-time execution of the model on edge devices. The novelty of
    our approach is the design of a multi-stage deep learning model that allows for
    making object inferences over several consecutive frames to optimize the detection
    performance in two main aspects: Accuracy: typical object detection and tracking
    models perform inference on one static image from the video frame, which usually
    leads to high misclassification ratios. We dramatically improved the accuracy
    by considering several consecutive frames and using a voting approach to maximize
    the object recognition accuracy. Real Time: a multi-stage model uses several deep
    learning models in sequence. The deployment of a multi-stage model makes real-time
    inference more challenging, particularly on embedded edge devices, considering
    their lower capabilities. We overcame this issue by using TensorRT acceleration
    on NVIDIA’s Jetson AXG to maintain a high frame rate for the AERO multi-stage
    inference model. 2.2.1. AERO Model Architecture Figure 4 shows the main steps
    of the processing performed by the AERO AI module on edge. The AERO model is composed
    of three modules, namely the Detection Module, the Model Acceleration Module,
    and the Tracking Module, described as follows. Figure 4. The AERO model architecture
    of the AI module. Detection Module The detection module is based on YOLOv7, which
    is the latest version of the widely used YOLO family of single-stage object detectors.
    It established the state of the art both in terms of accuracy and speed, outperforming
    competitor models by a large margin. For comparison, we also tested YOLOv4 [41],
    which is still one of the most popular object detection models. The DeepSORT tracker
    is an extension of the simple online and real-time tracking (SORT) algorithm [42],
    which is an efficient algorithm used for real-time object tracking. The key innovation
    of DeepSORT is the incorporation of a pre-trained deep association metric that
    utilizes object appearance information to improve the tracking performance. The
    deep association metric in DeepSORT uses a pre-trained deep neural network to
    encode the appearance information of objects. By comparing the features extracted
    from the neural network, DeepSORT is able to estimate the likelihood of two objects
    being the same. This allows DeepSORT to handle challenging scenarios such as occlusion,
    appearance changes, and the temporary disappearance of objects. Overall, DeepSORT
    provides a robust and accurate solution for tracking multiple objects in real
    time. Its ability to incorporate appearance information allows it to handle various
    challenging scenarios, making it an ideal solution for applications such as surveillance,
    robotics, and autonomous vehicles. For these reasons, and for its popularity in
    the literature, we opted for this particular tracker, although any other multi-object
    tracker could be used in our system. To integrate DeepSORT with the YOLO object
    detector and the other components of our system, we modified the implementation
    of the track class in a similar way to the one described in [43]. The object detection
    and tracking system processes each new frame by first applying YOLOv7 on the entire
    frame to obtain bounding boxes and confidence scores for all detected objects.
    These bounding boxes are then input to DeepSort, the multi-object tracker, which
    produces pairs of matched tracks and detections as well as lists of unmatched
    tracks and detections. For each track, the system checks whether it should be
    discarded, further processed, or sent to the server. First, the system checks
    if the track has not been matched with a detected bounding box for more than a
    predefined number of consecutive frames (default value of 10). If so, the system
    assumes that the object is no longer in the camera’s field of view. Next, the
    system checks if the track’s age (number of frames in which the same object has
    been detected) is within a predefined interval (default value of [2, 40]). A low
    value indicates that the track is unreliable, whereas a high value means that
    the object information has already been sent to the server. The default values
    of the minimum number of consecutive frames and the track’s age interval were
    fixed empirically after a series of preliminary tests. In all cases, the system
    checks if the current track has been confirmed by being observed in the required
    minimum number of consecutive frames (default value of 3) and has not been deleted
    due to missed detections. If the track is confirmed or has been matched with detected
    bounding boxes in the current or previous frames, the system checks its tracking
    age. If the age is equal to or greater than the maximum allowed age, the system
    sends its information to the server if it has not yet been sent. Finally, the
    system can optionally visualize the object’s bounding box and information using
    the current attributes of the track instance. If the track is not confirmed or
    has not been matched with bounding boxes for at least two consecutive frames,
    the system skips it and moves on to the next track. By following this process,
    the object detection and tracking system can accurately detect and track objects
    in real time while minimizing false detections and conserving computational resources.
    Model Acceleration Module While deep learning models can provide highly accurate
    results, they require significant computational and storage resources to train
    and run, even for YOLOv7, which is the fastest object detector to date. This makes
    deploying deep learning models on edge devices such as Jetson boards a challenging
    task as these devices often have limited resources in terms of memory and processing
    power. To address this challenge, we leveraged the use of the TensorRT acceleration
    framework. TensorRT is a high-performance inference engine developed by NVIDIA
    that allows developers to optimize deep learning models for deployment on a range
    of NVIDIA platforms, including Jetson edge devices. It can optimize models by
    reducing the precision of model parameters and minimizing the memory required
    to store them, allowing the model to run more efficiently on edge devices with
    limited resources. TensorRT can also optimize models by using dynamic tensor memory
    allocation, which allocates memory dynamically during inference, reducing the
    overall memory usage. The TensorRT optimization framework also optimizes models
    by fusing layers, which combines multiple layers in a neural network into a single
    layer to speed up model inference. This is particularly important for applications
    that require real-time processing on edge devices, where latency is critical,
    such as real-time surveillance applications. In a previous study [44], we have
    shown that TensorRT optimization provides the fastest execution on a wide variety
    of cloud and edge devices. This demonstrates the effectiveness of TensorRT in
    optimizing deep learning models for edge devices, achieving faster inference times
    and a lower latency. Target Localization Module In [2], we proposed a methodology
    for object detection and location estimation based on established photogrammetry
    concepts and metadata extracted from drone images, including EXIF and XMP data.
    This approach allows for accurately estimating the GPS location of detected objects
    within each frame. The use of metadata, such as the drone’s altitude and GPS location,
    image size, and calibrated focal length, provides a demonstrably sound basis for
    determining the location of objects in the images. To account for potential errors
    or uncertainty in the distance estimation, the algorithm also incorporates a correction
    factor based on the ratio between the drone’s altitude and the estimated average
    height of the objects using the formula: ⎧ ⎩ ⎨   𝐷 𝑐 𝑥 =(1− ℎ 𝐻 ) 𝐷 𝑥 𝐷 𝑐 𝑦
    =(1− ℎ 𝐻 ) 𝐷 𝑦 (1) where: 𝐷 𝑥 and 𝐷 𝑦 are the coordinates of the object’s bounding
    box center before correction. 𝐷 𝑐 𝑥 and 𝐷 𝑐 𝑦 are the object’s coordinates after
    correction. h is the estimated average object height. H is the drone altitude.
    Additionally, the algorithm considers the yaw degree of the image to refine the
    location estimation of each object further. This approach allows for an accurate
    counting of objects even when there are overlaps between images, further demonstrating
    the scientific rigor of the methodology. This same methodology can be applied
    to the detected objects in the AERO system, although we did not include this target
    localization module in the experimental part of the current study. 3. Results
    3.1. Experimental Setup For the experimental evaluation, we tested two different
    object detection models (YOLOv4 and YOLOv7), two different implementations (PyTorch
    and TensorRT), three different video resolutions (1920 × 1080 for 2 videos, 2688
    × 1512, and 3840 × 2160, see Figure 5 and Figure 6), and three different devices
    (RTX8000, Jetson Xavier AGX, and Jetson Xavier NX). The videos’ length ranges
    from 0.5 mn to 5.9 mn. Videos 1 and 3 were used for the detection of six classes
    of objects (car, person, bicycle, bus, monocycle, and truck), whereas videos 2
    and 4 were used for the detection of a single class (car). On top of each bounding
    box, information is displayed about the detection class, the tracking ID, the
    number of frames in which the same object has been observed, and the object color.
    For videos 1 and 3, the number of objects of each class is also displayed on the
    top left corner. The outputs of videos 2 and 4 are available on this link: shorturl.at/nrzOY
    (accessed on 28 March 2023). As for videos 1 and 3, the original footage was provided
    by a third party that did not agree to disclose them. Figure 5. Sample frames
    from the output of the four videos used for the evaluation of the AI-enabled system,
    with different resolutions. Figure 6. Close view of a sample of the output videos
    showing various classes, and some false negative and false positive detections.
    Table 3 presents the conducted experiments that are analyzed below. Due to software
    environment limitations and compatibility issues, some frameworks did not work
    on some devices. We were able to run all configurations on Jetson Xavier NX (Jetson
    pack 5, TensortRT 8), whereas YOLOv7 did not work on Jetson Xavier AGX (Jetson
    pack 4.5, TensorRT 7) and the TRT versions of YOLOv4 and YOLOv7 did not work on
    the RTX8000 GPU (CUDA version 10.0). Table 3. Conducted experiments on different
    devices, object detection models, frameworks, and input video resolutions. We
    chose the YOLOv7 object detector because it was the state-of-the-art object detector
    in terms of accuracy and speed at the time of this study. As for YOLOv4, we tested
    it for comparison, seeing that it is still one of the most popular object detectors
    (YOLOv5 and YOLOv6 are not as popular in the literature). For our case study,
    we could not use the pre-trained models of YOLOv4 and YOLOv7 because they were
    mainly trained on ground-level images (COCO dataset or OpenImages dataset), and
    we are dealing with aerial images. Consequently, for training YOLOv7, we used
    the VisDrone dataset [45], which we filtered to keep only one class of vehicles
    (cars), and, for YOLOv4, we trained a model on a private dataset containing 940
    UAV images showing six classes (car, person, bicycle, bus, monocycle, and truck)
    with a total of 33,088 instances. These images were captured in the Jeddah region
    in Saudi Arabia, in daylight and sunny conditions, and were manually labeled.
    Table 4 summarizes the main hyperparameters and results of the training of the
    YOLOv4 and YOLOv7 object detectors. Since we built our custom dataset gradually,
    we show the results of the training for several sizes of the dataset. We observe
    that there is a stagnation in terms of the mAP (mean average precision) when moving
    from 545 to 821 training images. YOLOv7 shows notably better results in terms
    of mAP but they are not directly comparable to YOLOv4’s results since the number
    of classes is different. Table 4. Hyperparameters and results of the training
    of the YOLOv4 object detector for several configurations. 3.2. Performance Evaluation
    We first analyzed the inference speed for each device and detection model using
    a series of box plots (Figure 7, Figure 8 and Figure 9). Box plots are a useful
    way to visualize the distribution of data and compare data across multiple variables,
    and can provide insights into the central tendency, variability, and skewness
    of the data. The grey line inside each box represents the median value of the
    data. Half of the data points fall above this line and half fall below. The box
    itself represents the interquartile range (IQR), which contains the middle 50%
    of the data. The bottom of the box represents the first quartile (Q1), or the
    value at which 25% of the data fall below. The top of the box represents the third
    quartile (Q3), or the value at which 75% of the data fall below. The whiskers
    extend from the box to show the range of the data, excluding any outliers, while
    the individual blue points represent a 1D scatter plot of the data. Figure 7.
    Inference speed per device, detection model, and video resolution. Figure 8. Inference
    speed per device, detection model, and connection to the cloud. Figure 9. Inference
    speed per device, detection model, and use of tracker. Figure 7 depicts the box
    plot of the inference speed in frames per second (FPS) for each device, detection
    model, and input video resolution. We observe that the TensorRT optimization of
    the YOLOv4 model provides the fastest inference speed, even on higher-resolution
    input videos, whereas, for YOLOv7, the TRT optimization provides no gain in speed.
    In contrast, the average inference speed deteriorates from 7.2 FPS (for the PyTorch
    implementation) to 2.8 FPS (for TRT). This is likely due to the fact that the
    new features introduced in YOLOv7 are not yet adequately optimized in the latest
    versions of TensorRT. Figure 8 shows the box plot of the inference speed for each
    device and detection model in the case where the detected objects are sent to
    the cloud and in the case where the connection to the cloud is disabled. In all
    cases, the connection to the cloud significantly slows down the inference speed
    of the whole system. The average speeds drops from 12.3 FPS when no data are sent
    to the cloud to 5.0 FPS when sending data to the cloud. This highlights the importance
    of choosing a high-quality network and optimizing the edge–cloud communication.
    Figure 9 shows the box plot of the inference speed for each device and detection
    model in the case where the DeepSORT tracker is included or excluded. On all devices,
    and for all object detection models, the use of the tracker markedly decelerates
    the system. The average inference speed declines from 19.6 FPS (without tracker)
    to 5.0 FPS (with tracker). Nevertheless, the use of the tracker is necessary to
    correctly count the number of objects and send each object’s information to the
    server only once. We should, however, investigate faster multi-object trackers
    to enhance the overall system speed. To analyze the influence of each component
    of the AI system and control for variability due to different devices and video
    resolutions, we generated a set of scatter plots to measure the inference speed
    on the Jetson Xavier NX device with an input video resolution of 1920 × 1080.
    Figure 10 illustrates the scatter plot of the inference speed per number of detected
    objects in each frame using both PyTorch and TRT versions of the YOLOv7 object
    detection model. As previously noted (about Figure 7), the PyTorch implementation
    achieved higher inference speeds compared to the TRT implementation. Figure 10
    appears as a superimposition of three plots, which we will distinguish in subsequent
    figures. Figure 10. Inference speed (in FPS) per number of detected objects, on
    Jetson Xavier NX, with an input video resolution of 1920 × 1080, using the PyTorch
    and TRT version of the YOLOv7 object detection model. Figure 11 presents the scatter
    plot of the inference speed per number of detected objects, on Jetson Xavier NX,
    with an input video resolution of 1920 × 1080, using the TRT version of the YOLOv7
    object detection model, when including or excluding the tracker. As already noted
    in Figure 9, the use of the tracker significantly slows down the system performance.
    The blue dots in Figure 11 represent the measures that included the tracker, and
    correspond to the lower part of the plot in Figure 10. The magenta dots, corresponding
    to the inclusion of the tracker in the AI system, still appear as the superimposition
    of two plots. They will be distinguished in the next figure. Figure 11. Inference
    speed (in FPS) per number of detected objects, on Jetson Xavier NX, with an input
    video resolution of 1920 × 1080, using the TRT version of the YOLOv7 object detection
    model, when including or excluding the tracker. Figure 12 shows a similar scatter
    plot but with no tracker when including or excluding the local saving of the output
    video. It demonstrates that storing the resulting output video on the edge’s disk
    consumes a significant amount of time and markedly slows down the overall inference
    speed. The system speed decreases from 12.9 FPS to 6.8 FPS on average over all
    devices and configurations. For the configuration shown in Figure 12 (Jetson Xavier
    NX, YOLOv7 TRT, no tracker, 1920 × 1080 video resolution), the average inference
    speed drops from 5.8 FPS to 2.7 FPS when saving the output video. Consequently,
    this local storage should not be used unless it is absolutely required for the
    application. Figure 12. Inference speed (in FPS) per number of detected objects,
    on Jetson Xavier NX, with an input video resolution of 1920 × 1080, using the
    TRT version of the YOLOv7 object detection model, with no tracker, when including
    or excluding the saving of the video output. 4. Discussion From Figure 7, Figure
    8, Figure 9, Figure 10, Figure 11 and Figure 12, we conclude that the inference
    speed of an AI system for object detection can be affected by various factors,
    including the device used, the detection model, the input video resolution, the
    use of cloud connectivity, and the inclusion of a tracker or local saving of output
    videos. The TensorRT optimization of the YOLOv4 model provides the fastest inference
    speed even on higher-resolution input videos. However, for YOLOv7, the TRT optimization
    did not provide any gain in speed due to an inadequate optimization of new features
    in the TensorRT version used. Sending data to the cloud significantly slows down
    the inference speed, highlighting the importance of choosing a high-quality network
    and optimizing edge–cloud communication. The use of a multi-object tracker is
    necessary to correctly count the number of objects and send each object’s information
    to the server only once, but it markedly decelerates the system. Finally, avoiding
    the local saving of the output video can also help to improve the system’s inference
    speed. Therefore, the best configuration for an AI system for object detection
    depends on the specific application requirements and hardware constraints. To
    assess the accuracy of the object detector, the influence of the TRT optimization,
    and the multi-object tracker, we selected two test videos (see Figure 5): video
    1: showing six classes (car, person, bicycle, bus, monocycle, and truck), with
    an average of six objects per frame, an input resolution of 3840 × 2160, a length
    of 50 s, and an FPS of 30. video 4: showing a single class of cars (with an average
    of six cars per frame), with an input resolution of 1920 × 1080, a length of 4
    mn and 25 s, and an FPS of 24. We manually counted the following metrics on still
    images extracted from the video every 20 frames (75 frames for video 1 and 319
    frames for video 4): FP: number of false positives (objects incorrectly detected)
    generated by the object detection model. FN: number of false negatives (non-detected
    objects) generated by the object detection model. Precision: 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛= 𝑇𝑃 𝑇𝑃+𝐹𝑃
    , where TP is the number of true positives (correctly detected objects). Recall:
    𝑅𝑒𝑐𝑎𝑙𝑙= 𝑇𝑃 𝑇𝑃+𝐹𝑁 F1 score: 𝐹1𝑠𝑐𝑜𝑟𝑒= 2×𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛×𝑅𝑒𝑐𝑎𝑙𝑙 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+𝑅𝑒𝑐𝑎𝑙𝑙 Identity
    switches: number of switches between the IDs assigned by the tracker. This happens
    when the tracker conflates two objects that are too close. Identity changes: number
    of changes in the IDs assigned by the tracker to the same object. This happens
    when the tracker misinterprets a single moving object for two objects. Table 5
    summarizes the obtained results for these metrics when using the TRT implementations
    of the YOLOv4 object detector on video 1. The number of FNs is relatively low
    compared to the number of FPs due to the fact that most vehicles have a relatively
    large size (compared to video 4). The number of identity switches and changes
    is also reduced compared to video 4 because the distance between objects is markedly
    larger, which makes the tracker’s task easier. Figure 13 shows two close frames
    from the output of video 1 where several detection and tracking errors appear.
    We notice one false positive in frame 240 (‘person’), and two other false positives
    in frame 260 (‘person’ and ‘truck’), as well as a misclassification (truck classified
    as ‘person’). Between the two frames, there are three identity changes (4→34,
    5→4, and 30→19). Identity switches often happen when two objects move close to
    each other, while identity changes may happen when the object’s speed is relatively
    high. Figure 13. Sample frames from the output of video 1, showing frames number
    240 and 260. Table 5. Number of false positive detections (FPs), false negative
    detections (FNs), precision, recall, F1 score, identity switches, and identity
    changes for the TRT implementation of the YOLOv4 object detection model on test
    video 1 (resolution of 3840 × 2160, length of 50 s, FPS of 30) captured by a drone,
    showing 6 classes (car, person, bicycle, bus, monocycle, and truck). On the other
    hand, Table 6 summarizes the obtained results when using the PyTorch or the TRT
    implementations of the YOLOv7 object detector on video 4. The difference between
    the two implementations is relatively minor, except for identity switches, which
    double from 5 to 10 when converting the PyTorch model to TRT. This indicates a
    loss in precision in the converted detection model that impacts the tracker accuracy.
    Nevertheless, this figure remains relatively low (1.6% to 3.1% relative to the
    number of frames) considering the number of cars and the duration of the video.
    By contrast, the number of identity changes is much higher, both for the PyTorch
    and the TRT implementations. The tradeoff between the number of identity switches
    and identity changes can be modified by changing the tracker hyperparameters,
    but we consider the identity switches to be more critical because they entail
    the conflation of the information of different objects, whereas the identity changes
    only result in duplicate information sent to the server. On the other hand, we
    observe that the number of false negatives is much higher than the number of false
    positives. In fact, small or occluded objects are often missed by the object detector,
    as can be seen in Figure 5. Consequently, the precision is high (99.3% for both
    PyTorch and TRT implementations), whereas the recall is much lower (72.5% and
    73.1% for PyTorch and TRT, respectively). This tradeoff can also be modified by
    changing the score threshold for the object detector. Table 6. Number of false
    positive detections (FPs), false negative detections (FNs), precision, recall,
    F1 score, identity switches, and identity changes for the PyTorch and TRT implementation
    of the YOLOv7 object detection model on test video 4 (resolution of 1920 × 1080,
    length of 4 mn and 25 s, FPS of 24) captured by a drone, showing a single class
    of ‘cars’. 5. Conclusions The commercial usage of UAVs is still largely limited
    by the lack of onboard AI on the edge, leading to manual data observation and
    offline processing after data collection. Alternatively, some approaches rely
    on the cloud computation offloading of AI applications, which can be unscalable
    and infeasible due to a limited connectivity and high latency of remote cloud
    servers. To address these issues, in this paper, we proposed a new approach that
    uses edge computing in drones to enable extensive AI task processing on board
    UAVs for remote sensing applications. The proposed system architecture involves
    a cloud–edge hybrid approach where the edge is responsible for processing AI tasks
    and the cloud is responsible for data storage, manipulation, and visualization.
    To implement this architecture, coined AERO, we designed a UAV brain system with
    onboard AI capabilities that uses GPU-enabled edge devices. AERO is a novel multi-stage
    deep learning module that combines object detection (YOLOv4 and YOLOv7) and tracking
    (DeepSort) with TensorRT accelerators to capture objects of interest with a high
    accuracy and transmit data to the cloud in real time without redundancy. AERO
    processes the detected objects over multiple consecutive frames to maximize detection
    accuracy. The experiments show that the proposed approach is effective for utilizing
    UAVs equipped with onboard AI capabilities for remote sensing applications. While
    the proposed system architecture and AERO module were designed to process visual
    data from UAVs, future work could explore the integration of other sensors, such
    as LiDAR or thermal cameras, to enhance the accuracy and efficiency of remote
    sensing applications. In addition, we plan to explore the integration of autonomous
    navigation capabilities to enable UAVs to navigate and collect data independently,
    without the need for manual control or intervention. Another crucial aspect that
    needs to be considered in future works when designing drone systems with onboard
    AI capabilities is security, as highlighted in [46,47,48]. Drone communications
    are susceptible to cyber-attacks, making it crucial to protect the data being
    transmitted between the UAV and the cloud. Implementing security measures such
    as encryption and authentication protocols can protect the system from unauthorized
    access and data breaches. Additionally, implementing physical security measures
    such as tamper-proofing the onboard AI hardware can prevent malicious actors from
    tampering with the system. These security measures must be implemented at every
    stage of the system development and deployment to ensure the safety and privacy
    of data collected by UAVs. Nevertheless, these measures can affect the system’s
    inference speed in a way that still has to be investigated. Author Contributions
    Conceptualization, A.K. and A.A.; methodology, A.K., A.A. and M.A.; software,
    Y.A. and A.A.; validation, A.K., A.A. and M.A.; formal analysis, A.K., A.A. and
    M.A.; investigation, A.K., A.A. and M.A.; resources, A.K.; data curation, A.A.
    and Y.A.; writing—original draft preparation, A.K., A.A., M.A. and L.G.; writing—review
    and editing, A.K., A.A., M.A. and L.G.; visualization, A.A. and M.A.; supervision,
    A.K., A.A. and M.A.; project administration, A.K.; funding acquisition, A.K. All
    authors have read and agreed to the published version of the manuscript. Funding
    The APC for this article was funded by Prince Sultan University. Acknowledgments
    We thank Prince Sultan University for facilitating the experiments on the university
    campus and financially supporting publication expenses. Conflicts of Interest
    The authors declare no conflict of interest. The funders had no role in the design
    of the study; in the collection, analyses, or interpretation of data; in the writing
    of the manuscript, or in the decision to publish the results. References Zanelli,
    E.; Bödecke, H. Global Drone Market Report 2022–2030; Technical report; Drone
    Industry Insights: Hamburg, Germany, 2022. [Google Scholar] Ammar, A.; Koubaa,
    A.; Benjdira, B. Deep-Learning-Based Automated Palm Tree Counting and Geolocation
    in Large Farms from Aerial Geotagged Images. Agronomy 2021, 11, 1458. [Google
    Scholar] [CrossRef] Gallego, V.; Rossi, M.; Brunelli, D. Unmanned aerial gas leakage
    localization and mapping using microdrones. In Proceedings of the 2015 IEEE Sensors
    Applications Symposium (SAS), Zadar, Croatia, 13–15 April 2015; pp. 1–6. [Google
    Scholar] [CrossRef] Abdelkader, M.; Shaqura, M.; Claudel, C.G.; Gueaieb, W. A
    UAV based system for real time flash flood monitoring in desert environments using
    Lagrangian microsensors. In Proceedings of the 2013 International Conference on
    Unmanned Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May 2013; pp. 25–34.
    [Google Scholar] [CrossRef] Abdelkader, M.; Shaqura, M.; Ghommem, M.; Collier,
    N.; Calo, V.; Claudel, C. Optimal multi-agent path planning for fast inverse modeling
    in UAV-based flood sensing applications. In Proceedings of the 2014 International
    Conference on Unmanned Aircraft Systems (ICUAS), Orlando, FL, USA, 27–30 May 2014;
    pp. 64–71. [Google Scholar] [CrossRef] Benjdira, B.; Bazi, Y.; Koubaa, A.; Ouni,
    K. Unsupervised Domain Adaptation Using Generative Adversarial Networks for Semantic
    Segmentation of Aerial Images. Remote Sens. 2019, 11, 1369. [Google Scholar] [CrossRef]
    [Green Version] Benjdira, B.; Ammar, A.; Koubaa, A.; Ouni, K. Data-Efficient Domain
    Adaptation for Semantic Segmentation of Aerial Imagery Using Generative Adversarial
    Networks. Appl. Sci. 2020, 10, 1092. [Google Scholar] [CrossRef] [Green Version]
    Gulf News, Saudi Arabia: 131 People Went Missing in Desert Last Year. 2021. Available
    online: https://gulfnews.com/world/gulf/saudi/saudi-arabia-131-people-went-missing-in-desert-last-year-1.78403752
    (accessed on 1 March 2023). Kobaa, A. System and Method for Service Oriented Cloud
    Based Management of Internet-of-Drones. U.S. Patent US11473913B2, 15 October 2022.
    [Google Scholar] Fortune Buisness Insights, Drone Surveillance Market. 2022. Available
    online: https://www.fortunebusinessinsights.com/industry-reports/drone-surveillance-market-100511
    (accessed on 1 March 2023). Ammar, A.; Koubaa, A.; Ahmed, M.; Saad, A.; Benjdira,
    B. Vehicle detection from aerial images using deep learning: A comparative study.
    Electronics 2021, 10, 820. [Google Scholar] [CrossRef] Yeom, S.; Cho, I.J. Detection
    and tracking of moving pedestrians with a small unmanned aerial vehicle. Appl.
    Sci. 2019, 9, 3359. [Google Scholar] [CrossRef] [Green Version] Ding, J.; Zhang,
    J.; Zhan, Z.; Tang, X.; Wang, X. A Precision Efficient Method for Collapsed Building
    Detection in Post-Earthquake UAV Images Based on the Improved NMS Algorithm and
    Faster R-CNN. Remote Sens. 2022, 14, 663. [Google Scholar] [CrossRef] Koubaa,
    A.; Ammar, A.; Alahdab, M.; Kanhouch, A.; Azar, A.T. DeepBrain: Experimental Evaluation
    of Cloud-Based Computation Offloading and Edge Computing in the Internet-of-Drones
    for Deep Learning Applications. Sensors 2020, 20, 5240. [Google Scholar] [CrossRef]
    [PubMed] Hossain, S.; Lee, D.j. Deep learning-based real-time multiple-object
    detection and tracking from aerial imagery via a flying robot with GPU-based embedded
    devices. Sensors 2019, 19, 3371. [Google Scholar] [CrossRef] [Green Version] Queralta,
    J.P.; Raitoharju, J.; Gia, T.N.; Passalis, N.; Westerlund, T. Autosos: Towards
    multi-uav systems supporting maritime search and rescue with lightweight ai and
    edge computing. arXiv 2020, arXiv:2005.03409. [Google Scholar] Vasilopoulos, E.;
    Vosinakis, G.; Krommyda, M.; Karagiannidis, L.; Ouzounoglou, E.; Amditis, A. A
    Comparative Study of Autonomous Object Detection Algorithms in the Maritime Environment
    Using a UAV Platform. Computation 2022, 10, 42. [Google Scholar] [CrossRef] Pajares,
    G. Overview and Current Status of Remote Sensing Applications Based on Unmanned
    Aerial Vehicles (UAVs). Photogramm. Eng. Remote Sens. 2015, 81, 281–330. [Google
    Scholar] [CrossRef] [Green Version] Nex, F.; Remondino, F. UAV for 3D mapping
    applications: A review. Appl. Geomat. 2014, 6, 1–15. [Google Scholar] [CrossRef]
    Bhardwaj, A.; Sam, L.; Martín-Torres, F.J.; Kumar, R. UAVs as remote sensing platform
    in glaciology: Present applications and future prospects. Remote Sens. Environ.
    2016, 175, 196–204. [Google Scholar] [CrossRef] Torresan, C.; Berton, A.; Carotenuto,
    F.; Di Gennaro, S.F.; Gioli, B.; Matese, A.; Miglietta, F.; Vagnoli, C.; Zaldei,
    A.; Wallace, L. Forestry applications of UAVs in Europe: A review. Int. J. Remote
    Sens. 2017, 38, 2427–2447. [Google Scholar] [CrossRef] Yao, H.; Qin, R.; Chen,
    X. Unmanned Aerial Vehicle for Remote Sensing Applications—A Review. Remote Sens.
    2019, 11, 1443–1464. [Google Scholar] [CrossRef] [Green Version] Messous, M.A.;
    Hellwagner, H.; Senouci, S.M.; Emini, D.; Schnieders, D. Edge computing for visual
    navigation and mapping in a UAV network. In Proceedings of the ICC 2020–2020 IEEE
    International Conference on Communications (ICC), Dublin, Ireland, 7–11 June 2020;
    pp. 1–6. [Google Scholar] Liu, Q.; Shi, L.; Sun, L.; Li, J.; Ding, M.; Shu, F.
    Path Planning for UAV-Mounted Mobile Edge Computing with Deep Reinforcement Learning.
    IEEE Trans. Veh. Technol. 2020, 69, 5723–5728. [Google Scholar] [CrossRef] [Green
    Version] Mnih, V.; Kavukcuoglu, K.; Silver, D.; Graves, A.; Antonoglou, I.; Wierstra,
    D.; Riedmiller, M. Playing Atari with Deep Reinforcement Learning. arXiv 2013,
    arXiv:1312.5602. [Google Scholar] Afifi, G.; Gadallah, Y. Cellular Network-Supported
    Machine Learning Techniques for Autonomous UAV Trajectory Planning. IEEE Access
    2022, 10, 131996–132011. [Google Scholar] [CrossRef] Xia, W.; Zhu, Y.; De Simone,
    L.; Dagiuklas, T.; Wong, K.K.; Zheng, G. Multiagent Collaborative Learning for
    UAV Enabled Wireless Networks. IEEE J. Sel. Areas Commun. 2022, 40, 2630–2642.
    [Google Scholar] [CrossRef] Li, B.; Liu, Y.; Tan, L.; Pan, H.; Zhang, Y. Digital
    twin assisted task offloading for aerial edge computing and networks. IEEE Trans.
    Veh. Technol. 2022, 71, 10863–10877. [Google Scholar] [CrossRef] Li, K.; Ni, W.;
    Yuan, X.; Noor, A.; Jamalipour, A. Deep Graph-based Reinforcement Learning for
    Joint Cruise Control and Task Offloading for Aerial Edge Internet-of-Things (EdgeIoT).
    IEEE Internet Things J. 2022, 9, 21676–21686. [Google Scholar] [CrossRef] Qian,
    Y.; Sheng, K.; Ma, C.; Li, J.; Ding, M.; Hassan, M. Path Planning for the Dynamic
    UAV-Aided Wireless Systems Using Monte Carlo Tree Search. IEEE Trans. Veh. Technol.
    2022, 71, 6716–6721. [Google Scholar] [CrossRef] Wang, Y.; Chen, W.; Luan, T.H.;
    Su, Z.; Xu, Q.; Li, R.; Chen, N. Task Offloading for Post-Disaster Rescue in Unmanned
    Aerial Vehicles Networks. IEEE/ACM Trans. Netw. 2022, 30, 1525–1539. [Google Scholar]
    [CrossRef] Yang, Z.; Bi, S.; Zhang, Y.J.A. Online Trajectory and Resource Optimization
    for Stochastic UAV-Enabled MEC Systems. IEEE Trans. Wirel. Commun. 2022, 21, 5629–5643.
    [Google Scholar] [CrossRef] Lyu, L.; Zeng, F.; Xiao, Z.; Zhang, C.; Jiang, H.;
    Havyarimana, V. Computation Bits Maximization in UAV-Enabled Mobile-Edge Computing
    System. IEEE Internet Things J. 2022, 9, 10640–10651. [Google Scholar] [CrossRef]
    Hamasha, M.; Rumbe, G. Determining optimal policy for emergency department using
    Markov decision process. World J. Eng. 2017, 14, 467–472. [Google Scholar] [CrossRef]
    El-Shafai, W.; El-Hag, N.A.; Sedik, A.; Elbanby, G.; Abd El-Samie, F.E.; Soliman,
    N.F.; AlEisa, H.N.; Abdel Samea, M.E. An Efficient Medical Image Deep Fusion Model
    Based on Convolutional Neural Networks. Comput. Mater. Contin. 2023, 74, 2905–2925.
    [Google Scholar] [CrossRef] Sabry, E.S.; Elagooz, S.; El-Samie, F.E.A.; El-Shafai,
    W.; El-Bahnasawy, N.A.; El-Banby, G.; Soliman, N.F.; Sengan, S.; Ramadan, R.A.
    Sketch-Based Retrieval Approach Using Artificial Intelligence Algorithms for Deep
    Vision Feature Extraction. Axioms 2022, 11, 663–698. [Google Scholar] [CrossRef]
    Meier, L.; Honegger, D.; Pollefeys, M. PX4: A node-based multithreaded open source
    robotics framework for deeply embedded platforms. In Proceedings of the 2015 IEEE
    International Conference on Robotics and Automation (ICRA), Seattle, WA, USA,
    26–30 May 2015; pp. 6235–6240. [Google Scholar] [CrossRef] Wang, C.Y.; Bochkovskiy,
    A.; Liao, H.Y.M. YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for
    real-time object detectors. arXiv 2022, arXiv:2207.02696. [Google Scholar] [CrossRef]
    Wojke, N.; Bewley, A.; Paulus, D. Simple online and realtime tracking with a deep
    association metric. In Proceedings of the 2017 IEEE International Conference on
    Image Processing (ICIP), Beijing, China, 17–20 September 2017; pp. 3645–3649.
    [Google Scholar] Shafi, O.; Rai, C.; Sen, R.; Ananthanarayanan, G. Demystifying
    TensorRT: Characterizing Neural Network Inference Engine on Nvidia Edge Devices.
    In Proceedings of the 2021 IEEE International Symposium on Workload Characterization
    (IISWC), Storrs, CT, USA, 7–9 November 2021; pp. 226–237. [Google Scholar] [CrossRef]
    Bochkovskiy, A.; Wang, C.Y.; Liao, H.Y.M. Yolov4: Optimal speed and accuracy of
    object detection. arXiv 2020, arXiv:2004.10934. [Google Scholar] Bewley, A.; Ge,
    Z.; Ott, L.; Ramos, F.; Upcroft, B. Simple online and realtime tracking. In Proceedings
    of the 2016 IEEE International Conference on Image Processing (ICIP), Phoenix,
    AN, USA, 25–28 September 2016; pp. 3464–3468. [Google Scholar] Ammar, A.; Koubaa,
    A.; Boulila, W.; Benjdira, B.; Alhabashi, Y. A Multi-Stage Deep-Learning-Based
    Vehicle and License Plate Recognition System with Real-Time Edge Inference. Sensors
    2023, 23, 2120. [Google Scholar] [CrossRef] Koubaa, A.; Ammar, A.; Kanhouch, A.;
    AlHabashi, Y. Cloud Versus Edge Deployment Strategies of Real-Time Face Recognition
    Inference. IEEE Trans. Netw. Sci. Eng. 2022, 9, 143–160. [Google Scholar] [CrossRef]
    Zhu, P.; Wen, L.; Du, D.; Bian, X.; Fan, H.; Hu, Q.; Ling, H. Detection and Tracking
    Meet Drones Challenge. IEEE Trans. Pattern Anal. Mach. Intell. 2021, 44, 7380–7399.
    [Google Scholar] [CrossRef] Krichen, M.; Adoni, W.Y.H.; Mihoub, A.; Alzahrani,
    M.Y.; Nahhal, T. Security Challenges for Drone Communications: Possible Threats,
    Attacks and Countermeasures. In Proceedings of the 2022 2nd International Conference
    of Smart Systems and Emerging Technologies (SMARTTECH), Riyadh, Saudi Arabia,
    22–24 May 2022; pp. 184–189. [Google Scholar] Ko, Y.; Kim, J.; Duguma, D.G.; Astillo,
    P.V.; You, I.; Pau, G. Drone secure communication protocol for future sensitive
    applications in military zone. Sensors 2021, 21, 2057. [Google Scholar] [CrossRef]
    Khan, N.A.; Jhanjhi, N.Z.; Brohi, S.N.; Nayyar, A. Emerging use of UAV’s: Secure
    communication protocol issues and challenges. In Drones in Smart-Cities; Elsevier:
    Amsterdam, The Netherlands, 2020; pp. 37–55. [Google Scholar] Disclaimer/Publisher’s
    Note: The statements, opinions and data contained in all publications are solely
    those of the individual author(s) and contributor(s) and not of MDPI and/or the
    editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.  © 2023 by the authors. Licensee MDPI, Basel, Switzerland.
    This article is an open access article distributed under the terms and conditions
    of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
    Share and Cite MDPI and ACS Style Koubaa, A.; Ammar, A.; Abdelkader, M.; Alhabashi,
    Y.; Ghouti, L. AERO: AI-Enabled Remote Sensing Observation with Onboard Edge Computing
    in UAVs. Remote Sens. 2023, 15, 1873. https://doi.org/10.3390/rs15071873 AMA Style
    Koubaa A, Ammar A, Abdelkader M, Alhabashi Y, Ghouti L. AERO: AI-Enabled Remote
    Sensing Observation with Onboard Edge Computing in UAVs. Remote Sensing. 2023;
    15(7):1873. https://doi.org/10.3390/rs15071873 Chicago/Turabian Style Koubaa,
    Anis, Adel Ammar, Mohamed Abdelkader, Yasser Alhabashi, and Lahouari Ghouti. 2023.
    \"AERO: AI-Enabled Remote Sensing Observation with Onboard Edge Computing in UAVs\"
    Remote Sensing 15, no. 7: 1873. https://doi.org/10.3390/rs15071873 Note that from
    the first issue of 2016, this journal uses article numbers instead of page numbers.
    See further details here. Article Metrics Citations Crossref   12 ads   4 Web
    of Science   9 Scopus   12 Google Scholar   [click to view] Article Access Statistics
    Article access statistics Article Views 28. Dec 7. Jan 17. Jan 27. Jan 6. Feb
    16. Feb 26. Feb 7. Mar 17. Mar 0k 1k 2k 3k 4k For more information on the journal
    statistics, click here. Multiple requests from the same IP address are counted
    as one view.   Remote Sens., EISSN 2072-4292, Published by MDPI RSS Content Alert
    Further Information Article Processing Charges Pay an Invoice Open Access Policy
    Contact MDPI Jobs at MDPI Guidelines For Authors For Reviewers For Editors For
    Librarians For Publishers For Societies For Conference Organizers MDPI Initiatives
    Sciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS Proceedings
    Series Follow MDPI LinkedIn Facebook Twitter Subscribe to receive issue release
    notifications and newsletters from MDPI journals Select options Subscribe © 1996-2024
    MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Terms and Conditions
    Privacy Policy"'
  inline_citation: '>'
  journal: Remote Sensing
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'AERO: AI-Enabled Remote Sensing Observation with Onboard Edge Computing
    in UAVs'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Xiao L.
  - Pan Z.
  - Du X.
  - Chen W.
  - Qu W.
  - Bai Y.
  - Xu T.
  citation_count: '1'
  description: Unmanned aerial vehicles (UAVs) have the potential to reduce manual
    interventions in digitizing farmland and improve the accuracy and efficiency of
    data collection. Measuring crop yields with UAVs is a critical step in achieving
    precision agriculture on unmanned farms. The key to estimating rice yield is to
    distinguish the panicle region from the non-panicle region based on semantic segmentation.
    However, the traditional semantic segmentation model, such as the UNet, has an
    inferior segmentation performance on UAV images. In addition, UAVs are unable
    to segment the rice panicle region in real time due to the limited edge computing
    capabilities for some improved UNet models. To address this issue, this study
    proposes a new method for augmenting UAV rice panicle image segmentation called
    weighted skip-connection feature fusion (WSFF). Furthermore, a novel model WSUNet
    is constructed by combining WSFF and UNet model, which aims to enhance the performance
    of rice panicle segmentation without additional computational cost. Two datasets
    of rice panicle images taken with UAV are constructed. These two and cell nuclei
    dataset are used to compare the performance of UNet, WSUNet and UNet++. Mean intersection
    over union (mIOU) and mean pixel accuracy (mPA) are adopted as evaluation metrics.
    In terms of mIOU, the results indicate that WSUNet outperforms the UNet on all
    datasets, with a maximum increase of 2.84 on the rice panicle dataset. And the
    average inferencing speed (AIS) of WSUNet on CPU is 2.1 times that of UNet++.
    Additionally, in order to verify the role of WSFF, 1WSUNet and 2WSUNet are constructed
    based on WSFF with two different skip-connection modes. By observing the training
    scalars of 1WSUNet, 2WSUNet, WSUNet, and UNet, it can be seen that the model set
    with WSFF has a more competitive learning ability than UNet, and the segmentation
    performance of the model could be further improved with the increase of the amount
    of skip-connection.
  doi: 10.1016/j.compag.2023.107754
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Highlights Abstract Keywords Abbreviations 1. Introduction 2. Method 3.
    Datasets 4. Experiments 5. Complement 6. Conclusion CRediT authorship contribution
    statement Declaration of Competing Interest Acknowledgment Appendix A. Implementation
    details Appendix B. Visualization Data availability References Show full outline
    Cited by (3) Figures (8) Show 2 more figures Tables (5) Table 1 Table 2 Table
    3 Table 4 Table 5 Computers and Electronics in Agriculture Volume 207, April 2023,
    107754 Weighted skip-connection feature fusion: A method for augmenting UAV oriented
    rice panicle image segmentation Author links open overlay panel Luolin Xiao a,
    Zhibin Pan a b d, Xiaoyong Du c d e f, Wei Chen a, Wenpeng Qu g, Youda Bai a,
    Tian Xu c Show more Share Cite https://doi.org/10.1016/j.compag.2023.107754 Get
    rights and content Highlights • Novel feature fusion method to reduce information
    loss during pooling process. • Capability of WSUNet to segment UAV-oriented rice
    panicles in complex backgrounds. • Improvement in segmentation performance without
    additional computational cost. Abstract Unmanned aerial vehicles (UAVs) have the
    potential to reduce manual interventions in digitizing farmland and improve the
    accuracy and efficiency of data collection. Measuring crop yields with UAVs is
    a critical step in achieving precision agriculture on unmanned farms. The key
    to estimating rice yield is to distinguish the panicle region from the non-panicle
    region based on semantic segmentation. However, the traditional semantic segmentation
    model, such as the UNet, has an inferior segmentation performance on UAV images.
    In addition, UAVs are unable to segment the rice panicle region in real time due
    to the limited edge computing capabilities for some improved UNet models. To address
    this issue, this study proposes a new method for augmenting UAV rice panicle image
    segmentation called weighted skip-connection feature fusion (WSFF). Furthermore,
    a novel model WSUNet is constructed by combining WSFF and UNet model, which aims
    to enhance the performance of rice panicle segmentation without additional computational
    cost. Two datasets of rice panicle images taken with UAV are constructed. These
    two and cell nuclei dataset are used to compare the performance of UNet, WSUNet
    and UNet++. Mean intersection over union (mIOU) and mean pixel accuracy (mPA)
    are adopted as evaluation metrics. In terms of mIOU, the results indicate that
    WSUNet outperforms the UNet on all datasets, with a maximum increase of 2.84 on
    the rice panicle dataset. And the average inferencing speed (AIS) of WSUNet on
    CPU is 2.1 times that of UNet++. Additionally, in order to verify the role of
    WSFF, 1WSUNet and 2WSUNet are constructed based on WSFF with two different skip-connection
    modes. By observing the training scalars of 1WSUNet, 2WSUNet, WSUNet, and UNet,
    it can be seen that the model set with WSFF has a more competitive learning ability
    than UNet, and the segmentation performance of the model could be further improved
    with the increase of the amount of skip-connection. Previous article in issue
    Next article in issue Keywords UAVRice panicleSemantic segmentationUNETSkip-connection
    Abbreviations UAVsUnmanned Aerial VehiclesWSFFWeighted Skip-Connection Feature
    FusionAISAverage Inferencing SpeedGFLOPsGiga Floating-Point Operations per SecondD2SDepth
    to SpacemIOUMean Intersection over UnionIOUIntersection over UnionmPAMean Pixel
    AccuracyPAPixel Accuracy 1. Introduction Nowadays, more and more farms tend to
    be large-scale and unmanned. With the rapid development of smart agriculture,
    rice panicle segmentation becomes increasingly attractive and has been applied
    in field management such as accurate estimation of rice yield (Reza et al., 2019),
    variable plant protection (Chen et al., 2021), detection of rice diseases and
    pests (Zhou et al., 2014), and detection of the growth period (Ku et al., 2013).
    For a long time, the number of rice panicles is counted manually, which is time-consuming,
    laborious and inefficient. It is also subject to observer bias, making it difficult
    to meet the demands of modern precision agricultural production. In recent years,
    research on automatic counting of rice panicles based on digital images has seen
    rapid development. Du et al. (2018) proposed a parabola segmentation method of
    wheat spikelets based on image processing techniques, enabling simultaneous recognition
    and counting of spikelets and grains. However, this algorithm requires a low-noise
    background, making it unsuitable for more challenging field environments. Liu
    et al. (2014) proposed an iterative growth idea to count the number of grains
    per ear of corn more accurately, combining the morphological concept of watershed
    algorithm and regional growth algorithm. This yielded a segmentation accuracy
    of 94.9% for adhered grains. Nevertheless, due to the great differences in color,
    texture, shape, size, and posture of the rice panicle region in a mature stage,
    the traditional image or machine learning algorithm shows certain limitations.
    In recent two decades, deep learning has been widely used in various fields, and
    the segmentation algorithm based on deep learning has achieved remarkable results
    in the field of image processing. In 2015, a novel model, UNet (Ronneberger et
    al., 2015), was proposed for small training sets. Since then, the model has been
    broadly adopted in the segmentation of biological blood vessel images (Liu et
    al., 2020), liver images (Li et al., 2018), bridge crack images (Zhang et al.,
    2021), and geographic information images (Abdollahi et al., 2022). Xiong et al.
    (2017) proposed a rice panicle segmentation algorithm Panicle-SEG-CNN based on
    super-pixel segmentation and CNN, which is well applied to rice panicle segmentation
    of different varieties and growth stages. Xie et al. (2019) performed an instance
    segmentation algorithm Mask R-CNN including deep residual network (ResNet), region
    proposal networks (RPN), and fully convolutional networks (FCN). The prediction
    results showed that the average accuracy of the grain pixel was 85%. Chen et al.
    (2020) proposed a method for predicting and segmenting grains, branches, and straws
    in hybrid rice grain images. The improved UNet was adopted to increase the depth
    of the network and address the problem of lack of training data and overfitting
    of training. The results showed that the F1 scores of rice grains, branches and
    straws segmentation were 99.42%, 88.56% and 86.84%, respectively. However, when
    these deep learning algorithm models are transferred to the segmentation task
    of the rice panicle in the crop field, the detection accuracy decreases and shows
    some limitations of inefficiency. Therefore, in order to improve the segmentation
    accuracy of rice panicle images taken by UAV without extra computation, this study
    designs a method to feature information fusion between non-adjacent layers called
    WSFF (Weighted Skip-connection Feature Fusion), which runs through the whole process
    of encoding and decoding. 2. Method There are two main points in WSFF, adaptive
    weighted feature fusion and skip-connection of non-adjacent layer''s features.
    In the encoding step, the adaptive weighted multi-pooling fusion method is used
    to reduce information loss caused by the single pooling process. During the decoding
    step, the upsampling feature map of adjacent layers is concatenated with a weighted
    fusion of the skip-connection feature map from the corresponding encoding layer
    and the Depth to Space (D2S) feature map of all non-adjacent decoding layers.
    By combining WSFF and UNet, a novel model WSUNet is constructed. Fig. 1 shows
    the architecture of WSUNet with 5 layers. Download : Download high-res image (277KB)
    Download : Download full-size image Fig. 1. Architecture of WSUNet with 5 layers.
    In the process of downsampling, WSUNet pools each node twice, with the results
    of max-pooling being delivered directly to the next nodes and the results of avg-pooling
    being skip-connected to all non-adjacent nodes. When fusing the feature maps of
    max-pooling with avg-pooling, WSUNet provides different feature maps with different
    weights, which are combined by addition. During the decoding step, two feature
    maps of D2S and bilinear interpolation are produced in each decoding node. The
    weighted sum of the D2S feature map and the skip feature map from the encoding
    layer is then concatenated with the feature map obtained by bilinear interpolation.
    2.1. Encoding As shown in Fig. 2, in the encoding step of in WSUNet, the skip-connections,
    , are added, which are implemented by average pooling. The feature maps are skip-connected
    to all nodes except the adjacent node. Matrix addition is utilized to combine
    multiple feature maps. At the same time, trainable weights are set for each feature
    map so that the weight distribution can be learned among different feature maps
    independently. Download : Download high-res image (113KB) Download : Download
    full-size image Fig. 2. Simple structure of WSUNet. Formally, N denotes for the
    number of nodes, n = N–1. Except for node , every node in encoding can be formulated
    as follows: in which and denote for max-pooling and avg-pooling, respectively.
    is the trainable weight in the encoding step and , Where denotes the weight of
    the feature map when skip-connects to , with average pooling while ewi is the
    weight when operating with max pooling. 2.2. Decoding When decoding, skip-connections,
    , are added in WSUNet. Adaptive weights are used to combine the skip feature map
    of the corresponding encoding layer with the D2S feature maps of all non-adjacent
    layers in the decoding. In the end, the result is concatenated with that of the
    previous nodes by bilinear interpolation. Denote . Each node except for node in
    decoding process can be formulated as follows: in which represents the concatenation
    of the feature maps in channel dimension. denotes bilinear interpolation, is the
    trainable weight in the decoding step and , where denotes the weight of the feature
    map when skip-connects to while represents the weight of the feature map when
    skip-connects to through D2S method. 2.3. Comparison of model parameters Table
    1 shows the model parameters comparison among UNet, UNet++ (Zhou et al., 2018),
    and WSUNet. It can be observed that the parameters and GFLOPs of WSUNet are almost
    the same as those of UNet, with no significant increase in both parameters and
    GFLOPs of WSUNet and UNet. Parameters of these two models are much less than that
    of the UNet++, of which the GFLOPs is about 2.5 times that of WSUNet. However,
    it is worth noting that the memory growth rate of WSUNet has also reached 70%
    compared to UNet, which is just a little less than that of UNet++. Table 1. Model
    parameter comparison among UNet, UNet++, and WSUNet. model params (M) Memory(MB)
    GFlops UNet 7.85 169.00 14.01 UNet++ 9.16( 16.69%) 339.00( 100.59%) 34.60( 146.97%)
    WSUNet 7.93( 1.02%) 285.84( 69.14%) 14.16( 1.07%) Note: The number of layers of
    the three models is set to 5, and the number of channels corresponding to each
    layer is set to [32,64,128,256,512]. The convolution blocks contain two-layer
    3*3 convolution, and the stride and padding are set to 1. 3. Datasets Two sets
    of mature rice panicle datasets, FSF1E and FSF2L, were collected from an unmanned
    farm in South China using a Phantom 4 RTK UAV. The FSF1E dataset represents the
    early rice in Field I, while the FSF2L dataset represents the late rice in Field
    II. The datasets have been published on GRAVITI, and a sample image taken by the
    UAV is shown in Fig. 3. The details of the datasets are displayed in Table 2.
    Download : Download high-res image (524KB) Download : Download full-size image
    Fig. 3. Sample image taken by UAV. Table 2. Raw rice panicle datasets. dataset
    farmland farmland size (acres) type image amount altitude (m) resolution FSF1E
    I 0.46 early rice 6 4.3 5,472 × 3,648 FSF2L II 0.31 late rice 4 2.3 4,846 × 3,648
    Note: FSF1E was taken vertically by UAV at an altitude of 4.3 m for farmland I
    in June 2021 with a resolution of 5472 × 3648. FSF2L was taken vertically at an
    altitude of 2.3 m in late October 2021 for farmland II, with a resolution of 4846
    × 3648. The images were cropped from left to right and top to bottom to a size
    of 256 × 256. Over 2,000 images were manually annotated with semantic segmentation
    using LabelMe (Russell et al., 2008). Meanwhile, the experiments were also conducted
    on the cell nuclei dataset from Broad Bioimage Benchmark Collection (accession
    number BBBC038). As shown in Table 3, the images were split into training and
    validation set randomly according to the ratio of 8:2. Table 3. Experimental datasets.
    dataset images size train valid modality provider FSF1E 1746 256 × 256 1418 328
    RGB The Authors FSF2L 991 256 × 256 774 217 RGB The Authors cell nuclei 670 96
    × 96 522 148 microscopy Data Science Bowl 2018 Note: When cropping large images
    of FSF1E and FSF2L, the crop method was from left to right and from top to bottom,
    excluding the margin images with less than 256 pixels and those without rice panicles.
    4. Experiments The experimental platform was running Ubuntu 20.04, with a NVIDIA
    GeForce RTX 3090 24 GB GPU, an Intel core i7-10700 2.90 GHz CPU and 32G of memory.
    PyTorch 1.9.0 and Python 3.8.5 were utilized. Comparative experiments were conducted
    among UNet, UNet++, and WSUNet on rice panicle and cell nuclei datasets. The results
    are presented in Table 4. Pixel-based accuracy calculation is the most basic and
    simplest indicator in the evaluation indicators. Pixel accuracy (PA) and intersection
    over union (IOU) indicator (also known as the cross-merger ratio) are used as
    standard measures in semantic segmentation. On FSF1E, the mean IOU (mIOU) of WSUNet
    is 82.89%, exceeding UNet by 2.84%. On FSF2L, WSUNet ranks first among the three
    models with a mIOU of 83.48%. And mean PA (mPA) of WSUNet is also comparable to
    both UNet and UNet ++. Table 4. Segmentation performance (mIOU:% / mPA:%) of UNet,
    UNet++, and WSUNet on three datasets. FSF1E FSF2L cell nuclei UNet UNet++ WSUNet
    Fig. 4 illustrates the performance of the models for rice panicle segmentation.
    It can be observed that the UNet model is sensitive to noise, such as shadows
    and leaves. In contrast, WSUNet has a stronger capacity to distinguish noise and
    can learn global information more effectively than UNet. Download : Download high-res
    image (347KB) Download : Download full-size image Fig. 4. Segmentation performance
    comparison between UNet and WSUNet. (a) is a raw cropped image of rice panicle,
    and (b) and (c) are the segmentation results of UNet, WSUNet for image (a), respectively.
    Though the performances of WSUNet and UNet++ are comparable, the GFLOPs of WSUNet
    is far less than that of UNet++. The training and inferencing speed of WSUNet
    are significantly faster than that of UNet++. Table 5 presents the comparison
    of the time-consuming for training and inferencing on FSF1E and cell nuclei. It
    can be seen that UNet++ has the highest time consumption on both CPU and GPU.
    Table 5. Training and inferencing time of UNet, UNet++, and WSUNet. model train
    (s per epoch) inference（ms per batch） FSF1E cell nuclei FSF1E cell nuclei UNet
    UNet++ WSUnet Note: The inferencing speed is represented by the average validation
    time (excluding the metric calculation time) of a single batch (batch_size = 8)
    on the validation set. The FSF1E contains 328 images (41 batches), while the cell
    nuclei contains 148 images (19 batches). This test takes an average training and
    inferencing time of 10 epochs on both CPU and GPU. FSF1E is adopted to show the
    weight fluctuation of WSUNet''s skip-connection feature map in the training process,
    as depicted in Fig. 5. When the training continues, WSUNet adjusts the weights
    of each feature map automatically. It can be observed from Fig. 5(a)(c)(e) that
    in the process of feature extraction, the max-pooling being used for texture extraction
    is more essential in model learning. Nevertheless, the fluctuation of ew0,n in
    Fig. 5(a)(c)(e) reveals that as the model deepens, background extracted through
    avg-pooling becomes increasingly important layer by layer, indicating that the
    deeper the model is, the more remarkable the function of skip-connection feature
    map of avg-pooling will be. From the decoding step of Fig. 5(b)(d)(f), it can
    be observed that the increase of the weight of the skip-connection feature map
    from the encoding layer decreases gradually when the amount of D2S skip-connection
    increases. This demonstrates that the D2S feature map from non-adjacent nodes
    can contribute to information compensation as the number of model layers increases.
    Download : Download high-res image (466KB) Download : Download full-size image
    Fig. 5. Weight Fluctuation of WSUNet on FSF1E. n is the node number and . (a)(c)(e)
    are the weight fluctuation of the feature map in the encoding layer while (b)(d)(f)
    are the weight of the feature map in the decoding layer. It should be noted that
    the model WSUNet performs the best on the validation set when iterating 49 times.
    5. Complement In order to verify the role of WSFF, two additional models, 1WSUNet
    with only one-step feature skip-connection and 2WSUNet with two-step feature skip-connection
    are constructed, as depicted in Fig. 6(a) and (b). It can be seen from Fig. 2
    that WSUNet is three-step skip-connected. But it’s worth noting that WSFF is an
    idea of full-step skip-connection, but not three-step. In fact, when there are
    five layers in the model, the maximum amount of skip-connection is 3. Download
    : Download high-res image (186KB) Download : Download full-size image Fig. 6.
    Simple structure of 1WSUNet, 2WSUNet. Fig. 7 depicts the curves of loss and IOU
    of 1WSUNet, 2WSUNet, WSUNet, and UNet model within 100 iterations. The performance
    of the models with WSFF is significantly better than that of the UNet. Furthermore,
    WSUNet is the best regardless of the average value, the median or extreme value
    of the loss and IOU. This verifies that the idea of WSFF does facilitate the segmentation
    of UNet, and with the increase in the amount of skip-connection, the performance
    of the model is further improved. Download : Download high-res image (240KB) Download
    : Download full-size image Fig. 7. The loss and iou of 1WSUNet, 2WSUNet, WSUNet
    and UNet during training. (a)(c) are the curves of loss and IOU of the four models
    in the iterative process respectively. (b)(d) are the box plot of corresponding
    distribution. 6. Conclusion Rice yield estimation has been a long-standing research
    topic. In this study, semantic segmentation of UAV-captured rice panicles is used
    to provide a basis for yield estimation. To address the problem of insufficient
    feature performance of the UNet in rice panicle segmentation, WSFF is proposed
    and integrated into the UNet to construct the WSUNet. Experiments show that WSUNet
    can improve the performance of image segmentation without extra computational
    costs compared to UNet. The maximum mIOU increase is as high as 2.84% in rice
    panicle segmentation. The improvement of feature representation ability of WSFF
    is also confirmed in this study. CRediT authorship contribution statement Luolin
    Xiao: Methodology, Software, Validation, Formal analysis, Writing – original draft,
    Writing – review & editing. Zhibin Pan: Conceptualization, Supervision, Writing
    – review & editing. Xiaoyong Du: Conceptualization, Funding acquisition, Supervision,
    Writing – review & editing. Wei Chen: Methodology. Wenpeng Qu: Resources, Validation.
    Youda Bai: Resources, Data curation. Tian Xu: Software. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgment This work was supported by The National Key Research
    and Development Program of China, Young Scientist Program (2021YFD1300800), and
    the National Natural Science Foundation of China (Grant No. 31872978), and IAEA
    CRP project (CRP D31030). Appendix A. Implementation details A.1. Data preprocess
    All the data is processed prior to training, and the paths of the training set
    and validation set are recorded in the YAML file. In addition, a random number
    between 0 and 1 is generated for each image when initializing the training and
    validation. If the random number is greater than 0.2, the image will be assigned
    to the training set; otherwise, it will be assigned to the validation set. A.2.
    Traning strategy All models are trained for 100 epochs with an early-stopping
    method. The batch size of 16 and a learning rate of 0.001 are set. The learning
    rate is decayed with a cosine annealing. Adam is employed with a weight decay
    of 0.001 to optimize our models. Appendix B. Visualization Fig. 8 depicts the
    time consumption of WSUNet and UNet++ relative to UNet. As shown, UNet++ has a
    remarkable increase compared to UNet. The increase of WSUNet is far less than
    that of UNet++, which is especially evident on CPU. In practical application scenario,
    the inferencing time is of particular importance. The average increase of inferencing
    time of WSUNet on CPU is only 26.78%, which is much lower than that of UNet++
    with a ratio of 165.95%. Download : Download high-res image (183KB) Download :
    Download full-size image Fig. 8. Time consumption growth of WSUNet and UNet++
    (%) compared to UNet. (a)(b) tests on FSF1E dataset with CPU and GPU respectively,
    (c)(d) tests on cell nuclei dataset with CPU and GPU respectively. Each subfigure
    contains four values, which respectively represent the increase of training and
    inferencing time of WSUNet and UNet++. Data availability Data will be made available
    on request. References Abdollahi et al., 2022 A. Abdollahi, B. Pradhan, A.M. Alamri
    An ensemble architecture of deep convolutional Segnet and Unet networks for building
    semantic segmentation from high-resolution aerial images Geocarto Int., 37 (12)
    (2022), pp. 3355-3370, 10.1080/10106049.2020.1856199 View in ScopusGoogle Scholar
    Chen et al., 2020 J. Chen, M. Han, Y. Lian, S. Zhang Segmentation of impurity
    rice grain images based on U Net model Trans. CSAE, 36 (10) (2020), pp. 174-180,
    10.11975/j.issn.1002-6819.2020.10.021 Google Scholar Chen et al., 2021 H. Chen,
    Y. Lan, B.K. Fritz, W.C. Hoffmann, S. Liu Review of agricultural spraying technologies
    for plant protection using unmanned aerial vehicle (UAV) Int. J. Agric. Biol.
    Eng., 14 (1) (2021), pp. 38-49, 10.25165/j.ijabe.20211401.5714 View in ScopusGoogle
    Scholar Li et al., 2018 X. Li, H. Chen, X. Qi, Q. Dou, C.-W. Fu, P.-A. Heng H-DenseUNet:
    Hybrid Densely Connected UNet for Liver and Tumor Segmentation From CT Volumes,
    in IEEE Transactions on Medical Imaging, 37 (12) (2018), pp. 2663-2674, 10.1109/TMI.2018.2845918
    View in ScopusGoogle Scholar Liu et al., 2020 Liu, Q., Zhong, Z., Sengupta, S.,
    Lakshminarayanan, V., 2020. Can we make a more efficient U-Net for blood vessel
    segmentation? In: Proc. SPIE 11511, Applications of Machine Learning 2020, 115110I
    (20 August 2020). doi:10.1117/12.2567861. Google Scholar Reza et al., 2019 M.N.
    Reza, I.S. Na, S.W. Baek, K.-H. Lee Rice yield estimation based on K-means clustering
    with graph-cut segmentation using low-altitude UAV images Biosyst. Eng., 177 (2019),
    pp. 109-121, 10.1016/j.biosystemseng.2018.09.014 View PDFView articleView in ScopusGoogle
    Scholar Ronneberger et al., 2015 O. Ronneberger, P. Fischer, T. Brox U-Net: Convolutional
    Networks for Biomedical Image Segmentation N. Navab, J. Hornegger, W. Wells, A.
    Frangi (Eds.), Medical Image Computing and Computer-Assisted Intervention – MICCAI
    2015, Lecture Notes in Computer Science, 9351, Springer, Cham (2015), pp. 234-241,
    10.1007/978-3-319-24574-4_28 Google Scholar Du et al., 2018 S. Du, Y. Li, M. Yao,
    L. Li, Q. Ding, R. He Counting method of grain number based on wheatear spikelet
    image segmentation J. Nanjing Agric. Univ., 41 (4) (2018), pp. 742-751, 10.7685/jnau.201709043
    Google Scholar Ku et al., 2013 B. Ku, S.K. Kang, W.G. Sang, M.K. Choi, K.j. Lee,
    H.K. Park, Y.D. Kim, B.K. Kim, J.H. Lee Variation of Panicle Differentiation Stage
    by Leaf Growth According to Rice Cultivars and Transplanting Time Korean J. Crop
    Sci., 58 (4) (2013), pp. 353-361, 10.7740/KJCS.2013.58.4.353 Google Scholar Liu
    et al., 2014 G. Liu, P. Liu, W. Wei, S. Zhang, H. Li Method of image segmentation
    for touching maize kernels Trans. Chinese Soc. Agric. Machinery, 45 (9) (2014),
    pp. 285-290, 10.6041/j.issn.1000-1298.2014.09.046 View in ScopusGoogle Scholar
    Russell et al., 2008 B.C. Russell, A. Torralba, K.P. Murphy, W.T. Freeman LabelMe:
    A Database and Web-Based Tool for Image Annotation Int. J. Comput. Vis., 77 (2008),
    pp. 157-173, 10.1007/s11263-007-0090-8 View in ScopusGoogle Scholar Xie et al.,
    2019 Y. Xie, Z. Yu, H. Jiang, Q. Jin, N. Cai, J. Liang Study on precise segmentation
    method for geometric phenotype measurement of wheat ear J. Nanjing Agric. Univ.,
    42 (5) (2019), pp. 956-966, 10.7685/jnau.201901026 View in ScopusGoogle Scholar
    Xiong et al., 2017 X. Xiong, L. Duan, L. Liu, H. Tu, P. Yang, D. Wu, G. Chen,
    L. Xiong, W. Yang, Q. Liu Panicle-SEG: a robust image segmentation method for
    rice panicles in the field based on deep learning and superpixel optimization
    Plant Methods, 13 (2017), p. 104, 10.1186/s13007-017-0254-7 View in ScopusGoogle
    Scholar Zhang et al., 2021 L. Zhang, J. Shen, B. Zhu A research on an improved
    Unet-based concrete crack detection algorithm Struct. Health Monit., 20 (4) (2021),
    pp. 1864-1879, 10.1177/1475921720940068 Google Scholar Zhou, 2014 X.G. Zhou First
    report of bacterial panicle blight of rice caused by Burkholderia glumae in South
    Africa Plant Dis., 98 (4) (2014), p. 566, 10.1094/PDIS-09-13-0913-PDN View in
    ScopusGoogle Scholar Zhou et al., 2018 Z. Zhou, M.M.R. Siddiquee, N. Tajbakhsh,
    J. Liang UNet++: A Nested U-Net Architecture for Medical Image Segmentation D.
    Stoyanov, et al. (Eds.), Deep Learning in Medical Image Analysis and Multimodal
    Learning for Clinical Decision Support. DLMIA ML-CDS, Lecture Notes in Computer
    Science, 11045, Springer, Cham (2018), pp. 3-11, 10.1007/978-3-030-00889-5_1 Google
    Scholar Cited by (3) Lesa-Net: Semantic Segmentation of Multi-Type Road Point
    Clouds in Complex Agroforestry Environment 2023, SSRN Sugarnet: A Novel Deep Learning
    Approach to Sugarcane Field Segmentation in Satellite Imagery 2023, SSRN Method
    of Peanut Pod Quality Detection Based on Improved ResNet 2023, Agriculture (Switzerland)
    View Abstract © 2023 Elsevier B.V. All rights reserved. Recommended articles VNAI-NDVI-space
    and polar coordinate method for assessing crop leaf chlorophyll content and fractional
    cover Computers and Electronics in Agriculture, Volume 207, 2023, Article 107758
    Jibo Yue, …, Yuanyuan Fu View PDF Green fruit segmentation and orientation estimation
    for robotic green fruit thinning of apples Computers and Electronics in Agriculture,
    Volume 207, 2023, Article 107734 Magni Hussain, …, Paul Heinemann View PDF Leaf
    area index estimation of pergola-trained vineyards in arid regions using classical
    and deep learning methods based on UAV-based RGB images Computers and Electronics
    in Agriculture, Volume 207, 2023, Article 107723 Osman Ilniyaz, …, Xi Chen View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 2 Captures
    Readers: 5 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Weighted skip-connection feature fusion: A method for augmenting UAV oriented
    rice panicle image segmentation'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Feng A.
  - Vong C.N.
  - Zhou J.
  - Conway L.S.
  - Zhou J.
  - Vories E.D.
  - Sudduth K.A.
  - Kitchen N.R.
  citation_count: '1'
  description: Unmanned aerial vehicle (UAV) based remote sensing has been extensively
    used in precision agriculture applications, such as vegetation growth and health
    monitoring, yield estimation, and irrigation management. Conventional procedures
    for UAV data collection and processing require collecting highly overlapped images,
    stitching images to generate an orthomosaic, and using ground control points (GCPs)
    in the field or UAV onboard real-time-kinematic (RTK) global navigation satellite
    system (GNSS) data to improve position accuracy. For improving efficiency, a previous
    study developed a framework to process individual UAV images for mapping cotton
    emergence. The current study aimed to build a near-real time image processing
    pipeline to further improve the positioning accuracy of single UAV images. The
    improved image processing pipeline comprised feature detection and matching, false
    matches removal, geometric transformation matrix calculation, crop row alignment,
    image position assignment, and mapping. The developed pipeline was tested for
    mapping in both cotton and corn fields. Results showed that the position accuracies
    for measuring the distance between GCPs were 0.32 ± 0.21 m and 0.57 ± 0.28 m in
    a cotton and a corn field, respectively, when compared to ground truth data collected
    with an RTK-GNSS. The developed pipeline did not require GCPs in the field or
    image post-processing steps, such as image mosaicking and feature extraction,
    which allowed processing in near-real time and may possibly be implemented in
    real-time using an onboard edge computing system. The pipeline was used to map
    emergence parameters for cotton and corn fields, including stand count, canopy
    area, mean days to imaging after emergence, and plant spacing standard deviation.
    These maps demonstrated the success of the developed methods in providing a low-cost
    near real-time tool (8.6 and 3.6 s/image for the cotton and corn fields, respectively)
    for mapping emergence parameters at field-scale for use in both research and agricultural
    production.
  doi: 10.1016/j.compag.2023.107650
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    View Open Manuscript Outline Highlight Abstract Keywords 1. Introduction 2. Materials
    and methods 3. Results 4. Discussion 5. Conclusion CRediT authorship contribution
    statement Declaration of Competing Interest Acknowledgements Code availability
    Data availability References Show full outline Cited by (1) Figures (13) Show
    7 more figures Tables (3) Table 1 Table 2 Table 3 Computers and Electronics in
    Agriculture Volume 206, March 2023, 107650 Developing an image processing pipeline
    to improve the position accuracy of single UAV images Author links open overlay
    panel Aijing Feng a b 1, Chin Nee Vong a 1, Jing Zhou c, Lance S. Conway d, Jianfeng
    Zhou a, Earl D. Vories d, Kenneth A. Sudduth d, Newell R. Kitchen d Show more
    Add to Mendeley Share Cite https://doi.org/10.1016/j.compag.2023.107650 Get rights
    and content Highlight • An image processing workflow to geo-reference single UAV
    images. • Field mapping of crop early emergence using individual UAV images. •
    Improved position accuracy of 0.17 and 0.57 m for cotton and corn UAV images.
    • Potential real-time processing UAV images for on-site decision making. Abstract
    Unmanned aerial vehicle (UAV) based remote sensing has been extensively used in
    precision agriculture applications, such as vegetation growth and health monitoring,
    yield estimation, and irrigation management. Conventional procedures for UAV data
    collection and processing require collecting highly overlapped images, stitching
    images to generate an orthomosaic, and using ground control points (GCPs) in the
    field or UAV onboard real-time-kinematic (RTK) global navigation satellite system
    (GNSS) data to improve position accuracy. For improving efficiency, a previous
    study developed a framework to process individual UAV images for mapping cotton
    emergence. The current study aimed to build a near-real time image processing
    pipeline to further improve the positioning accuracy of single UAV images. The
    improved image processing pipeline comprised feature detection and matching, false
    matches removal, geometric transformation matrix calculation, crop row alignment,
    image position assignment, and mapping. The developed pipeline was tested for
    mapping in both cotton and corn fields. Results showed that the position accuracies
    for measuring the distance between GCPs were 0.32 ± 0.21 m and 0.57 ± 0.28 m in
    a cotton and a corn field, respectively, when compared to ground truth data collected
    with an RTK-GNSS. The developed pipeline did not require GCPs in the field or
    image post-processing steps, such as image mosaicking and feature extraction,
    which allowed processing in near-real time and may possibly be implemented in
    real-time using an onboard edge computing system. The pipeline was used to map
    emergence parameters for cotton and corn fields, including stand count, canopy
    area, mean days to imaging after emergence, and plant spacing standard deviation.
    These maps demonstrated the success of the developed methods in providing a low-cost
    near real-time tool (8.6 and 3.6 s/image for the cotton and corn fields, respectively)
    for mapping emergence parameters at field-scale for use in both research and agricultural
    production. Previous article in issue Next article in issue Keywords Crop emergenceImage
    processingMappingReal-time processingUAV imagery 1. Introduction Remote sensing
    (RS) based on unmanned aerial vehicle (UAV) platforms has become a regular tool
    in precision agriculture (PA) for efficient data collection from large areas of
    farm fields. Widely used UAV-based sensing systems for agricultural applications
    include cameras with different spectral bands, such as RGB (red, green, and blue),
    multispectral, hyperspectral, and thermal cameras, as well as light detection
    and ranging (LiDAR) sensors. The UAV-based sensing systems have been used in different
    PA applications, such as weed and disease detection, vegetation growth and health
    monitoring, yield estimation, and irrigation management (Tsouros et al., 2019).
    When compared to other RS platforms such as satellites and manned aircrafts, UAV-based
    sensing systems are lower in cost, more friendly in operation, and flexible in
    data acquisition time and altitude. Furthermore, UAV-based sensing systems can
    collect data at high spatial and temporal resolution, have high image quality,
    and provide immediate access (Vega et al., 2015, Xie and Yang, 2020, Yang et al.,
    2017). Meanwhile, as compared to ground-based sensing platforms, UAV-based sensing
    systems are less time-consuming for fine-scale use and do not cause crop damage
    or soil compaction (Xie and Yang, 2020). The key factors for the successful implementation
    of PA technology include accurate site-specific information collection and timely
    decision making (Delavarpour et al., 2021). Site-specific information from UAV-based
    sensing systems usually relies on geo-referencing of UAV images by one of two
    methods: 1) aerial triangulation (AT) using ground control points (GCPs) or 2)
    direct geo-referencing (DG) based on the position and orientation measurements
    of the capturing camera (Rabah et al., 2018). Nowadays, the DG method based on
    the UAV onboard global navigation satellite system (GNSS) receiver is widely used,
    and location accuracy can be improved by using real-time kinematic (RTK) technology.
    For instance, a previous study showed root mean square error (RMSE) for total
    horizontal errors (easting and northing) of 0.843, 0.034 m, and 0.032 m for non-RTK
    UAV data processed via DG, non-RTK UAV data processed with GCPs, and RTK UAV data
    (Hugenholtz et al., 2016). However, RTK-GNSS is usually expensive (Obanawa et
    al., 2019) and installing sufficient GCPs in fields is a time-consuming, non-real
    time operation. Further, the exercise is sometimes difficult or impossible in
    certain field conditions (Štroner et al., 2021). This could occur, for example,
    when crops are very tall or the canopy has completely closed, when soil is very
    wet, or under narrow-row cropping systems. Moreover, the position accuracy when
    using GCPs depends on the configuration and number of GCPs used throughout the
    field (Sanz-Ablanedo et al., 2018). The conventional method of processing UAV
    images usually requires a substantial image overlap (about 75%) to construct orthomosaic
    images of study fields (Tsouros et al., 2019), which results in low efficiency
    in data collection (more flight passes and slower speed). This is especially noticeable
    for UAV data collected with low altitude (≤20 m) to provide sufficient resolution
    for small crop plants at early stages (Feng et al., 2020a, Vong et al., 2021).
    The collected images are then processed using commercial UAV image processing
    software such as Agisoft Metashape (Agisoft LLC, St. Petersburg, Russia) or Pix4D
    mapper (Pix4D S.A., Lausanne, Switzerland), a process that may require from hours
    to days depending on the size of field, number of images, and image resolution
    (Feng et al., 2020a). In addition, the process of image stitching may require
    extensive computational resources and may cause a substantial delay for field
    decision making (Feng et al., 2020a, Xiang and Tian, 2011). Furthermore, orthomosaic
    images may contain image artifacts and distortions caused by image scenes, lighting
    conditions, camera parameters, flight plans (height, speed, and overlaps), and
    processing parameters (Gross and Heumann, 2016, Iglhaut et al., 2019). These issues
    can degrade the image quality and result in inaccurate results from image post-processing,
    such as for vegetation indices (VI) and canopy cover calculations. Post-image
    processing uses additional software such as Matlab, ArcGIS, and QGIS (Tsouros
    et al., 2019, Yang et al., 2017), which further increases complexity and time
    for data processing (Tsouros et al., 2019). Since consumer-grade UAV imaging systems
    are widely used in research and for these, RTK GNSS is generally not available.
    Therefore, a more cost-effective solution for timely image processing and real-time
    decision making is greatly needed. A previous study by Feng at al. (2020a) developed
    an efficient imagery data processing and analysis framework for timely evaluation
    of cotton emergence using a UAV-based imaging system and deep learning (DL) technology.
    The study introduced an approach of directly processing individual image frames
    rather than generating orthomosaic images, which can reduce the processing time
    and prevent image quality degradation. This framework was successfully tested
    for estimating and mapping cotton emergence (stand count and canopy size) with
    a position accuracy of 1.72 m ± 1.37 m (mean ± standard deviation). However, the
    position accuracy was not satisfactory to acquire site-specific information for
    research in PA. Since conventional plant row spacing of row crops such as cotton,
    corn, and soybean ranges from 0.76 to 1.02 m (Clawson et al., 2006, Elmore and
    Abendroth, 2007, Robinson and Conley, 2007), position accuracy should be improved
    to better than 0.38 – 0.51 m (half of the common row spacings) to generate a more
    accurate and reliable field mapping. This study aimed to develop a real-time image
    processing pipeline to process individual UAV images for improved position accuracy.
    The developed pipeline was then used to create emergence maps for cotton and corn
    at field scale to demonstrate its application. Moreover, the position accuracy
    was compared with the method from previous study to evaluate the performance of
    the developed method. 2. Materials and methods 2.1. UAV imaging system A UAV imaging
    system (Phantom 4 Advanced, DJI, Shenzhen, Guangdong, China) was used to collect
    high resolution RGB images in cotton and corn fields. The resolution of the onboard
    RGB camera was set to 4864 × 3648 pixels, resulting in the calculated spatial
    resolution of 3.0 mm pixel−1 at 10 m above ground level (AGL). Images were taken
    sequentially for both fields at 0.5 frames per second (fps) at a flight height
    of 10 m and flight speeds of 7.5 and 7.2 km h−1 for the cotton and corn field,
    respectively. The UAV flight trajectory and flight parameters were set using the
    control apps Autopilot (Hangar Technology, Austin, TX, USA) or Litchi (VC Technology
    ltd, London, U.K.). The image overlaps in both the sideward and forward directions
    were about 60 – 75 %. During aerial image data collection, the onboard GNSS system
    on the UAV continuously recorded the coordinates and altitude of the imaging system
    and provided geo-referencing for each image as part of the image metadata. Geo-referenced
    images were downloaded after the flight for further processing. 2.2. Experimental
    fields and configurations 2.2.1. Cotton field The cotton field was a research
    field located at the Fisher Delta Research, Extension and Education Center of
    the University of Missouri in the upper portion of the Mississippi River Delta
    region near Portageville, MO, USA (36.411° N, 89.696° W). The field has dimensions
    of 315 m (north–south, NS) × 150 m (east–west, E-W). The cotton cultivar PHY 320
    WRF (Dow Agrosciences, Indianapolis, IN) was planted on bedded soil using a John
    Deere 1700 (Deere & Co., Moline, IL, USA) planter on May 15, 2019. The field was
    seeded in a NS direction at a target seeding rate of 136,000 seeds ha−1 with a
    row spacing of 0.97 m. This resulted in a total of 152 crop rows. Most of the
    cotton emerged by May 22, 2019 and the UAV images were collected on May 31, 2019
    [16 days after planting (DAP)]. Ground truth and reference data including GCPs,
    stand count and seedling size, were collected on the day of the UAV flight. In
    this study, 28 GCPs (Fig. 1) were set in the field, including 16 fence posts (∼1.1
    m in height) each with a white-black polytechnic board (30 × 30 cm) on the top
    and 12 quadrats (53 × 53 cm) made with half-inch polyvinyl chloride (PVC) pipes.
    Two different types of GCP were used to mark different sampling methods for assessment
    of cotton stand count. A ground stake that could be recognized during the growing
    season (Fig. 1c) was placed at each GCP to mark its position so that the GCP could
    be placed at the same locations for each data collection. A RTK survey kit (REACH
    RS+, Emlid ltd., Saint Petersburg, Russia) with a ReachView app (Emlid ltd.) was
    used to obtain the coordinates of the 28 GCPs. At each GCP, six flags were used
    to mark six 1-m intervals of crop seedlings in two cotton rows as shown in Fig.
    1a and Fig. 1b. The number of seedlings in each 1-m interval was counted manually
    to serve as ground truth data for the stand count estimation. Meanwhile, a tape
    measure with a precision scale of 1 mm was placed along the cotton rows. A digital
    camera on a cell phone (iPhone 6 s, Apple Inc., Cupertino, CA, USA) was used to
    take videos of the crop rows while being held manually at a height of about 0.5
    m AGL with the camera facing down. Cotton stands were counted by playing back
    the videos and canopy size (top view) was calculated by comparing the scales of
    the tape measure and number of image pixels. Download : Download high-res image
    (133KB) Download : Download full-size image Fig. 1. Illustration of the cotton
    field setup with a and b showing one of the 28 ground control points (GCPs) that
    include two 6-m crop rows, a fence post (GCP), and red flags marking each 1-m
    interval. The ground videos were taken using a cell phone camera. c) UAV image
    showing a PVC pipe quadrat with one ground stake inside. (For interpretation of
    the references to color in this figure legend, the reader is referred to the web
    version of this article.) 2.2.2. Corn field The corn field was located near Columbia,
    MO, USA (38.946° N 92.133° W) with dimensions of 160 m (NS) by 49 m (E-W). The
    field was planted with corn hybrid Pioneer 0589 (Corteva Agriscience, Wilmington,
    DE, USA) on April 20, 2020 using a custom-built four-row planter equipped with
    MaxEmerge XP row units (Deere & Co., Moline, IL, USA) at a 0.76-m row spacing.
    Four planting depth treatments (3.8, 5,1, 6.4, and 7.6 cm) with two replications
    were implemented to create different emergence dates. Each replication of each
    planting depth had eight rows (6.1 m) of corn along the NS direction of the field
    resulting in a total of 64 corn rows. Seeds were planted at the four defined depths
    at a seeding rate of 81,500 seeds ha−1, which was equivalent to an average plant
    intra-row seed spacing of 16 cm. Five monitoring sites were marked with flags
    for ground data collection with each site consisting of two adjacent corn rows
    6.0 m long (Fig. 2). Corn emergence was checked daily, and colored stakes were
    used to mark the newly emerged plants for each day. The first and last emergence
    checks in the monitoring sites were 2 and 12 May of 2020 (12 and 22 DAP). The
    same RTK survey kit with the ReachView app was used to obtain the GPS coordinates
    of the monitoring sites (a flag at one side of the monitoring site was used as
    the GCP). There was a total of five GCPs. The UAV aerial image data was collected
    on 22 May 2020, which was 32 DAP or 20 days after first emergence. This resulted
    in most plants at the site between vegetative growth stage V2 to V4. Then, plant
    spacing (PS) was measured using a tape measure on 15 June 2020 (56 DAP). Download
    : Download high-res image (298KB) Download : Download full-size image Fig. 2.
    Example image of monitoring site with color stakes marking different emergence
    dates at the corn field and one of the flags used as ground control point (GCP).
    The area in the red box in the upper image is enlarged in the lower image. (For
    interpretation of the references to color in this figure legend, the reader is
    referred to the web version of this article.) 2.3. Single image processing pipeline
    development Fig. 3 illustrates the summary workflow of the image pre-processing
    and image processing pipeline to establish location information for single images.
    The collected images were pre-processed using decorrelation stretch to enhance
    the images and standard Hough transform (SHT) to rotate the images for crop row
    detection and ground sample distance (GSD) determination of each image with the
    detailed procedures described in Feng et al. (2020a, Fig. 3 dashed box). Inside
    the dotted box of Fig. 3 are the procedures of the image processing pipelines
    developed in the present study that improved position accuracy of single image
    frames compared to the methods of Feng et al (2020a). The first three procedures
    (symbols highlighted in blue) were modified based on previous customized image
    alignment and stitching algorithms described in Feng, et al. (2020b), focusing
    on image feature identification and matching followed by removal of false matches.
    The remaining three procedures (symbols highlighted in yellow) were added in this
    study to assign position information of each single image based on E-W (crop rows)
    and NS (position in each crop row) translations. The position information of images
    was then used to develop site-specific maps for parameters of interest (e.g.,
    stand count, canopy size, emergence date). Feng et al. (2020b) generated an orthomosaic
    image based on the matched features of the images for the whole field using post-processing
    method after data collection, which was time consuming. On the other hand, the
    image processing pipeline in this study aligned crop rows using single image frames
    (without image mosaicking) for the whole field, which improved the efficiency
    and made near real-time processing possible. The details of the image processing
    pipeline for single image frames (Fig. 3 dotted box) are described in the following
    sections. Download : Download high-res image (463KB) Download : Download full-size
    image Fig. 3. Workflow of image pre-processing (dashed line box) and image processing
    pipeline (dotted line box) in this study. 2.3.1. Feature detection and matching
    Image features were detected using the method of Speeded-Up Robust Features (SURF),
    a 128-dimension (8 orientation bins for each of the 4 × 4 location bins) local
    feature detector, and a descriptor (Bay et al., 2008). As a scale-invariant feature,
    SURF used image pyramids and different sized box filters to find points of interest
    at different scale spaces (Lowe, 2004). The scale space of SURF was divided into
    octaves and each octave was subdivided into a constant number of scale levels.
    The number of pyramid octaves and octave layers were both set to three in this
    study as suggested by Lowe (2004). After feature detection, the k-nearest neighbors
    (KNN) algorithm was used to match the most similar feature pairs in two successive
    images. The KNN calculated all the Euclidean distances of features to find the
    closest K matches. In this study, K was set to 2 (K = 2) so that the algorithm
    would return the two closest key points for each key point to be matched. 2.3.2.
    Removal of false matches False matches, i.e., the pixels that had the shortest
    Euclidean distance but were different objects in the successive images, would
    occur and needed to be removed. Two methods were used sequentially to remove these
    false matches: 1) distance ratio test; 2) matching line slope and length ratio
    test. The distance ratio test was performed using Eq. (1): (1) where, D1 and D2
    are the Euclidean distance of the closest key point and second-closest key point
    identified by KNN; R is the ratio selected by a trial-and-error approach. It was
    assumed that D1 came from the same object as the key point to be matched, while
    D2 came from another object, which could be noise. The distance ratio test then
    tested whether D1 was sufficiently different from D2 to decide it was a false
    match. If the difference was small, D1 could also represent noise. As suggested
    by Lowe (2004), R > 0.80 was initially used to remove all the false matches and
    less correct matches. However, this ratio still kept some false matches in this
    study, and the ratio was adjusted to R > 0.65 to remove all the false matches.
    The images were collected on a relatively calm day (wind speed ≤ 4 m s−1) and
    the UAV was flown parallel to the ground with minimum variations in roll and pitch.
    In our experiments, variations in UAV yaw angle were noticed and therefore the
    images were pre-processed (as described in Feng et al, 2020a) to align the crop
    rows. However, there was no substantial variation in angles to crop rows between
    two successive images since the heading variation was small during the acquisition
    of two images (2 s). Therefore, the correct matches were expected to have similar
    slopes and length. Hence, by calculating the slopes and lengths of matching lines
    using Eq. (2), (3), the ratio of the slope and the length of one matching line
    to the mean value of all matching lines in two successive images would be close
    to 1. (2) (3) where, (x1, y1) and (x2, y2) are the coordinates of a key point
    and its matching point in two successive images. Those matches with a large ratio
    difference from other matches were false matches and were removed by using the
    thresholds of < 0.9 and > 1.1 (determined by trial-and-error methods). Fig. 4
    shows an example of correct matches remaining (yellow lines) after removing false
    matches using the two methods. Before removing false matches, there were 10,978
    matches and after removing false matches using Method 1 (three example lines shown
    in red), there were 113 matches remaining, including false and correct matches.
    Finally, after removing false matches (three example lines shown in blue) using
    Method 2, the remaining 34 matches were all correct matches. The remaining matches
    were distributed on the bottom of left image and top of the right image as these
    are the areas overlapping between them. Fewer matched lines were found at the
    left corner of the two images (bottom left corner of left image and top left corner
    of the right image) as compared to their right corners, where there were fewer
    notable image features being filtered during the SURF feature detection process
    (Bay et al., 2008, Feng et al., 2019). In addition, it can be seen from Fig. 4
    that less matching features were detected from the left portion of images than
    those from the right portion. The possible reason might be that left portion of
    images was brighter or slightly saturated with less distinction between crops
    and soil background than the right portion, where more distinguished features
    were observed (darker soil background and crop row accompanied by shadow). Download
    : Download high-res image (220KB) Download : Download full-size image Fig. 4.
    Feature detection and matching in two successive images (right image is the next
    successive image after the left image flying in the north to south direction)
    of the cotton field. Yellow lines and blue ID number represent valid matches.
    Red lines and red ID number indicate example matches removed after Method 1 while
    blue lines and red ID number indicate example matches removed after Method 2.
    (For interpretation of the references to color in this figure legend, the reader
    is referred to the web version of this article.) 2.3.3. Calculation of the geometric
    transformation matrix Once the correct matches were identified, transformation
    matrices of each matching pair within the two successive images were calculated.
    In this study, a generic transformation matrix M was used as shown in Eq. (4)
    (Szeliski, 2007): (4) where, tx and ty are the distance in pixels of translation
    in the E-W and NS directions; sx and sy are the scale factors in E-W and NS directions,
    respectively; and θ is the rotation angle. Assuming a pixel value of an image
    coordinate I(x, y) was to be transformed into its previous image coordinate I’(x'',y''),
    Eq. (5) shows the transformation of these two images based on the transformation
    matrix M: (5) where, (x, y) and (x’, y’) are image coordinates of image I(x, y)
    and I’(x'',y''). The images had been rotated to obtain crop rows aligned with
    the vertical axis of the images as stated earlier. Therefore, no rotation was
    needed in the image transformation (i.e., θ = 0). In addition, the GSD of each
    image frame was calculated using row spacing (detailed in Section 2.3.5) and the
    UAV did not have much variation between two images (within 2 s). Therefore, the
    scale factor between two successive images was relatively small in this study.
    This study aimed to develop a near real-time pipeline to process individual UAV
    images for improved position accuracy, which required timely data processing (minimize
    processing time). To reduce the computation time of matching two images, only
    translation was considered in the transformation matrix, i.e., without including
    scale factor and rotation (sx and sy = 1; θ = 0). 2.3.4. Crop row alignment based
    on the geometric transformation matrix After applying the SHT to the original
    images, the images were rotated and each crop row position in the rotated images
    was obtained. Then, crop row alignment was conducted, with Fig. 5 showing this
    process for the first two images of the cotton field. Firstly, the crop row numbers
    of the first image were identified manually. The tx in the geometric transformation
    matrix M controlled the distance in pixels of translation in the E-W direction.
    When each crop row in the second image was translated by tx pixels, they would
    match with the positions of each crop row in the first image and would be assigned
    to the row numbers corresponding with the row numbers in the first image. New
    crop rows that appeared on the right side of the second image would be assigned
    a successively higher number from the last crop row in the first image. This process
    would continue in every-two consecutive images until crop row numbers were assigned
    to all images. Download : Download high-res image (331KB) Download : Download
    full-size image Fig. 5. Crop row alignment. There were 10 cotton rows identified
    manually in the first image from the cotton field. The numbers of 9 cotton rows
    identified by the SHT in the second image frame were aligned with the first image
    frame based on the distance in pixels in the E-W direction (tx) from the geometric
    transformation matrix M. The distance in pixels in the NS direction (ty) determined
    the image position within the entire crop row. 2.3.5. Image positions within each
    entire crop row The ty in the geometric transformation matrix M determined the
    distance in pixels of translation in the NS direction as demonstrated in Fig.
    5 and Eq. (4). When the UAV flew in the north to south direction, the images at
    the north and the images at the south were at the beginning and the end of the
    crop rows, respectively as shown in Fig. 6. The ty value was positive when the
    image sequence was from the beginning to the end (north to south). Similarly,
    when the UAV flew from south to north, the image sequence was from the end to
    the beginning of the crop rows and the ty value was negative. Due to the forward
    image overlaps when taking successive images in the fields, each image would move
    ty pixels from its previous image in the NS direction. Since actual UAV flight
    height was inconsistent due to some uncontrolled factors, resulting in different
    GSD for each image, the translation pixels in the NS directions would misrepresent
    the true translation based on the ground distance (translation in meters) for
    the entire crop rows. Hence, to resolve this problem, translation in meters was
    calculated using the GSD of each image as determined based on the fixed row spacing
    (Eq. (6)): (6) Download : Download high-res image (474KB) Download : Download
    full-size image Fig. 6. Illustration of determining image positions within each
    entire crop row. Black cross in each combined image represents the center position
    for each image in their combined image. where ty_meter is the translation in meters
    in the NS direction, ty is the pixels of translation in the NS directions and
    GSD is the ground sampling distance. The GSD was determined automatically by dividing
    the number of pixels for plant rows (obtained after row detections by Hough transformation)
    by actual row spacing (determined by the planter) as described in Feng et al.,
    2020a. The first image of the data collection (the beginning of the first crop
    rows) was given a value of zero and used as the reference for all other images
    collected in each field (Fig. 6). Then, the position in the NS direction of all
    other images was determined by accumulating the ty_meter from each subsequent
    image as illustrated in Fig. 6. 2.3.6. Emergence mapping based on the image alignment
    Crop emergence is an important agronomic factor for plant development assessment
    and field management at early growth stages, and can be evaluated using plant
    population, stand count, uniformity, and seedling size (Sansone et al., 2002,
    Supak, 1990). Crop emergence mapping of these parameters is important for making
    early field management decisions, assessing yield spatial variability, and studying
    effects of soil and environment on crop emergence (Feng et al., 2020a, Vong et
    al., 2022). In this study, emergence maps of a few parameters including stand
    count and canopy area for the cotton field, and stand count, mean days to imaging
    after emergence (DAEmean), and standard deviation of plant spacing (PSstd) for
    the corn field were created. The created maps were based on a local coordinate
    system consisting of a two-dimensional X-Y plane oriented in the NS (Y axis) and
    E-W directions (X axis) with the center position of the first image in the first
    flight path as the origin point (refer to section 2.3.5). Multiple 1-m seedling
    segment images were cropped from each raw image using the method described by
    Feng et al. (2020a) (Fig. 3 dashed line box) and illustrated in Fig. 7. The previously
    stated emergence parameters were estimated using a Resnet18 model described in
    previous studies (Feng et al., 2020a, Vong et al., 2022). Then, the maps were
    created based on the location of each segmented image as determined by the row
    numbers in E-W direction and ty_meter in NS direction. The row numbers were recognized
    based on the crop row assignment steps delineated above. Since the ty_meter described
    the translation in meters in the NS direction for the geometric center of each
    image frame, the translation in meters of each segmented image could be computed
    by adding (segment images below the geometric center) to or subtracting (segment
    images above the geometric center) from the distance in meters of the ty_meter
    (Fig. 7). If some segmented images from different images were geometrically close
    (<1 m), the average of their estimated emergence parameters was used when generating
    the emergence maps. To further demonstrate the usage of the emergence maps created
    from the developed pipeline, the cotton canopy area and stand count maps were
    compared with a yield map generated from an Ag Leader Insight yield monitor installed
    on a cotton harvester (1996 Case IH 2155, Racine, WI). The details of the harvest
    and yield map generation were described in Feng et al. (2019). Then, a Pearson
    correlation was performed to correlate canopy area and stand count with yield.
    Download : Download high-res image (268KB) Download : Download full-size image
    Fig. 7. Illustration of multiple cropped 1-m segment images and computation of
    their position based on the geometric center of an image, ty_meter. 2.4. Position
    accuracy evaluation using GCPs To evaluate the performance of the developed pipeline
    in improving position accuracy, an RTK GNSS system was used to measure the coordinates
    of GCPs in both fields, as shown in Fig. 8 and denoted as ground measurement.
    Furthermore, coordinates of GCPs were also determined from the GNSS of the UAV,
    DJI Phantom 4 Advanced using the method described by Feng et al. (2020a) and denoted
    as Phantom measurement. Then, the distance between GCPs was calculated using the
    coordinates from the ground and Phantom measurement using the haversine formula
    (Feng et al., 2020a, Naik and Nair, 2019). For the pipeline measurement, the distance
    between GCPs was calculated based on ty_meter for the NS direction and the difference
    in crop rows for the E-W direction (Fig. 8c). Then, the position accuracy was
    computed as the difference in their distances for all the GCPs (Ground vs Pipeline
    and Ground vs Phantom) and represented in a boxplot. Download : Download high-res
    image (688KB) Download : Download full-size image Fig. 8. Location of ground control
    points (GCPs) in a) corn field and b) cotton field as well as demonstration of
    distance comparison between two different kinds of systems for the position accuracy
    evaluation: b) ground RTK measurement and c) pipeline measurement. An analysis
    of variance (ANOVA) test followed by Tukey’s Honest Significant Difference (HSD)
    test was conducted to compare position accuracy means at a 0.05 significance level
    (α = 0.05) for the two sets (Ground vs Pipeline and Ground vs Phantom). The cotton
    field had 28 GCPs as shown in Fig. 8b, with all the GCPs south of p1, p2, p3,
    and p4 in the same row. The comparison of coordinates (latitude and longitude)
    was between every-two GCPs in the same row (e.g., p1 and p5, p1 and p9, p1 and
    p13, p1 and p17, p1 and p21, p1 and p25, p5 and p9, etc.). One of the GCPs (p26)
    was not visible in the UAV image and was excluded from the position accuracy comparison.
    Hence, the total pairs for position accuracy comparison in the cotton field was
    78. On the other hand, the locations of GCPs in the corn field (Fig. 8a) were
    more random (at different rows) compared to those of the cotton field. The position
    accuracy comparison was between every-two GCPs (e.g., p1 and p2, p1 and p3, p1
    and p4, etc.), resulting in ten pairs. 2.5. Processing time comparison The processing
    time needed for the entire workflow in Fig. 3 for both fields was recorded and
    compared with the image stitching time needed from two commercial software packages,
    Agisoft Metashape (ver. 1.8.0) and Pix4D Mapper. A desktop configured as an Intel
    Core i9-9900 K 3.60 GHz, an NVIDIA GeForce RTX 2060 GPU with 6 GB memory, an NVIDIA
    GeForce RTX 2060 Super GPU with 8 GB memory, 32 GB RAM and 3 TB solid-state drive
    (SSD) was used to process the images using the new pipeline in this study and
    for image stitching by the two commercial software packages to make a comparison
    of their processing time. The commercial software packages used GPU resources
    of the desktop during processing while the pipelines did not use the desktop’s
    GPU resources. 3. Results 3.1. Position accuracy evaluation Fig. 9 shows the position
    errors of GCPs in both fields measured by the developed pipeline using single
    images, calculated as the distance difference between the ground RTK GPS coordinates
    and coordinates calculated by the pipeline (Ground vs Pipeline). For comparison,
    Fig. 9 (box plots in red color) also shows distance difference for the raw UAV
    images (Feng et al., 2020a, Ground vs Phantom). It can be seen that the distance
    differences (errors) of the developed pipeline were 0.32 ± 0.21 m and 0.57 ± 0.28
    m (mean ± standard deviation) for cotton and corn fields, which were significantly
    lower than those between ground RTK and the Phantom measurement system (1.98 ±
    1.53 m and 2.13 ± 1.89 m respectively). The position error of the previous study
    (Feng et al., 2020a) was 1.72 ± 1.53 m as they only involved 24 pairs of GCPs,
    i.e., every-two successive GCPs in the same row (e.g., p1 and p5, p5 and p9, p9
    and p13, etc.), compared to 78 pairs of every-two GCPs in this study. Download
    : Download high-res image (93KB) Download : Download full-size image Fig. 9. Position
    error (distance difference) between ground RTK (ground), pipeline measurement
    (pipeline), and DJI Phantom 4 system (Phantom) for both cotton and corn fields.
    Different letters in each boxplot of the two fields show significant differences
    in the means at p < 0.05 for the Tukey HSD test. 3.2. Single image processing
    pipeline assessment (problems and solutions) A total of 2,200 and 517 images were
    collected for the cotton and corn fields, respectively. Some of the images were
    not assigned to the correct crop row numbers due to a low degree of overlap between
    two successive images. This was usually caused by an inconsistent actual AGL flight
    height of the UAV, which may have been due to errors in the UAV elevation sensor,
    field slope, signal noise, or low battery level. Moreover, when flying a UAV over
    a relatively larger field such as the cotton field in our study (5.1 ha) with
    a low flight height (10 m), multiple batteries were needed. When the battery level
    was low, we observed that the pre-set flight height changed (lower flight height),
    which resulted in a larger scale factor for the two successive images (between
    the last image before changing the battery and first image after changing the
    battery). Hence, two approaches were considered to solve these problems: 1) using
    side instead of forward overlapping images. The side overlapping images could
    be found based on the nearest position coordinates of images in the UAV flight
    path next to the target path; 2) manually identifying and assigning the crop row
    numbers of the image by referring to the surrounding images (the previous and
    side overlapping images). Fig. 11 illustrates some example situations encountered
    in the cotton field where one of the two solutions was used to solve the problem.
    For example, the successive images in Fig. 10a had<5 % overlap and crop row numbers
    were only able to be manually identified and assigned. Fig. 10b shows a successful
    example of aligning rows by matching features from side overlapping images. On
    the other hand, Fig. 10c illustrates images before and after changing the UAV
    battery, resulting in large scale factor differences and requiring manual row
    number assignment. In our study, < 0.4 % of images taken needed manual assignment
    of row numbers (7/2,200 for cotton and 2/517 for corn fields). This problem can
    be reduced in future studies by using a higher resolution camera, thus enabling
    a higher and more stable flight height for sufficient image overlaps. Download
    : Download high-res image (478KB) Download : Download full-size image Fig. 10.
    Example illustrations of different problems faced in the cotton field requiring
    additional solutions to align the row numbers. a) successive images with < 5 %
    overlap, where row numbers were assigned manually; b) row number successfully
    assigned using side images; c) images before and after changing battery, where
    row numbers were assigned manually. Download : Download high-res image (571KB)
    Download : Download full-size image Fig. 11. Cotton field emergence maps of a)
    stand count and b) canopy size with full dimension of 152 crop rows × 315 m length
    for each crop row and their down-sampled maps with dimension of 38 × 63 in c and
    d, respectively, where each data point equates to a 4 m × 5 m area. A crop yield
    map with the same 4 m × 5 m cell size is shown in e. 3.3. Crop emergence maps
    To demonstrate the usage of the developed pipeline in creating emergence maps,
    a stand count map (seedlings m−1) and a canopy size map (cm2 seedling−1) were
    generated for the cotton field by calculating the number of plants and their average
    canopy size within each meter of each row (Fig. 12a and b). These maps had a resolution
    of 152 × 315 grids (i.e., 152 crop rows by 315 m in NS direction) and were down-sampled
    to a 38 × 63 grid (Fig. 12c and d) by averaging the stand count and canopy size
    of every 5 m in each four adjacent rows (equal to a 4 m × 5 m area) for matching
    with the four-row harvested yield data (Fig. 11e). The figures confirmed the positive
    correlation between yield and stand count/ canopy size (r = 0.3 for stand count
    and r = 0.35 for the canopy size, both with p-value < 0.001) by displaying the
    similar patterns of field variations in the figures. Higher stand count and canopy
    size corresponded to higher yield. For instance, the northeast portion (red circle
    in Fig. 11) of the field had lower stand counts, canopy sizes, and yield while
    the opposite was shown in the southwest part (black circle in Fig. 11) of the
    field. Download : Download high-res image (673KB) Download : Download full-size
    image Fig. 12. Schematic diagram showing the treatment and non-treatment crop
    rows (a) and their emergence maps of stand count (plant m−1, b), mean days to
    imaging after emergence (DAEmean, days, c), and standard deviation of plant spacing
    (PSstd, cm m−1, d) in corn field. For the corn field, emergence maps of three
    parameters: stand count, DAEmean, and PSstd were generated using the developed
    pipeline as shown in Fig. 12b to 12d. These maps had a resolution of 72 × 160
    grids (i.e., 72 crop rows by 160 m in NS direction). Fig. 12a shows the schematic
    diagram of the crop rows, where there were 64 rows with planting depth treatments
    and the remaining eight rows without planting depth treatments. There was no obvious
    pattern in the stand count and PSstd maps related to planting depth, but DAEmean
    showed trends of higher DAEmean with decreasing depths. Collectively, these results
    suggest that the developed pipeline was able to provide position information for
    each single UAV image and further process those images to obtain the emergence
    maps, which would be beneficial in PA applications, especially in understanding
    the effect of spatial variability of the field on crop emergence and production.
    Furthermore, this method could reduce the time needed for putting GCP in the field
    and for image post-processing (image stitching and feature extraction). 3.4. Processing
    time comparison The workflow and parameters set in Agisoft Metashape and Pix4D
    Mapper to stitch the UAV images collected on both fields are detailed in Table
    1, Table 2. The settings for these parameters were to ensure the software used
    the full-size images (not down-sampled images) since the developed pipeline in
    this study used the original full-size images during processing. The common workflow
    to stitch the image to obtain the orthomosaic in Agisoft Metashape includes ‘align
    photos’, ‘build dense point cloud’, ‘build mesh’, and ‘build orthomosaic’. However,
    with the large number of images collected in the cotton field (2,200 images),
    an error occurred during the ‘build mesh’ step stating, ‘Not enough memory’. Therefore,
    another step, ‘build DEM’ was performed to act as the surface for the ‘build orthomosaic’
    step. For Pix4D Mapper, the stitching process failed and did not produce the final
    orthomosaic for either the cotton or corn field, which might be due to the low
    image overlaps. Image overlap for this software is recommended at least 75 % and
    60 % for forward and side overlaps, respectively (https://pix4d.com). Although
    the UAV flights (height, speed, and flight paths) were set to have 60–70 % image
    overlaps for both fields, the actual overlap changed due to inconsistent AGL flight
    height caused by several factors mentioned previously in section 3.2. Other studies
    also indicated that the image reconstruction process using stitching software
    was not fully completed when a side overlap was smaller than 55 % (Seifer et al.,
    2019). Even with the successful process, the resulting orthomosaic would have
    artifacts such as holes, dislocation, and distortion (Cui et al., 2021). Table
    1. Stitching workflow and parameter set in Agisoft Metashape Professional to stitch
    the UAV images collected on cotton and corn fields. Stitching Workflow Parameter
    Cotton Field Corn Field Align Photos Accuracy: Highest; Generic preselection:
    Yes; Reference preselection: Source Build Dense Point Cloud Quality: Ultra high;
    Depth filtering: mild Build Mesh – Source data: Dense cloud; Surface type: Height
    field; Depth maps quality: Ultra high Build DEM Source data: Dense cloud; Quality:
    Ultra high; Depth filtering: mild – Build Orthomosaic Surface: DEM; Blending mode:
    Mosaic Surface: Mesh; Blending mode: Mosaic Table 2. Stitching workflow and parameter
    set in Pix4D Mapper to stitch the UAV images collected on cotton and corn fields.
    Stitching Workflow Parameter (for both cotton and corn) Initial Processing Keypoints
    Image Scale: Full; Matching Image Pairs: Aerial Grid or Corridor Point Cloud and
    Mesh Point Cloud Densification: Image Scale = 1/1, Point Density = High, Minimum
    Number of Matches = 3; DSM, Orthomosaic and Index Resolution: Automatic The total
    image processing time using the algorithms developed in this study was 10.4 and
    5.7 s/image for the cotton and corn fields (as shown in Table 3). The difference
    in the image processing time between the two fields was mostly due to the time
    used in detecting and matching the image features, which were different in the
    images with different crops, soil conditions, residue backgrounds, and lighting
    conditions. These processing times corresponded to 6.4 h for the 5.1 ha cotton
    field and 0.82 h for the 0.8 ha corn field. Meanwhile, the processing times of
    the pipeline were lower than the image stitching time needed by the commercial
    software, which were 88.7 and 97.4 s/image for cotton and corn fields, respectively.
    Table 3. Processing time comparison between the new method of this study and commercial
    software in stitching the UAV images. Field Processing Time (s/image) Pipeline:
    Fig. 3 dashed line Pipeline: Fig. 3 dotted line Pipeline: Total Time Agisoft Metashape
    Cotton 1.8 s 8.6 s 10.4 s 88.7 s Corn 2.1 s 3.6 s 5.7 s 97.4 s 4. Discussion 4.1.
    Pipeline performance The study developed a near real-time UAV image processing
    pipeline that had higher performance than the method used in the previous study
    and achieved a better position accuracy. Without the need for an RTK unit on the
    UAV, the pipeline was able to produce more accurate field maps with an average
    position accuracy of 0.32 and 0.57 m for the cotton and corn fields, respectively.
    The position accuracy of the cotton field is well within half of the common crop
    row spacing, which is 0.38 to 0.51 m (Clawson et al., 2006). The position accuracy
    of the corn field was not within half of the common row spacing (0.19 to 0.49
    m; Elmore and Abendroth. 2007), and lower than that of the cotton field (higher
    distance difference), which might be caused by human errors. As illustrated in
    Fig. 13, a yellow ground stake, which could be clearly seen from the image (Fig.
    13a) was used to mark the GCPs in the cotton field. However, in the corn field,
    two flags were used to mark each monitoring site, with one of the flags used as
    the GCP. However, the point where the flag was inserted into the ground surface
    could not be seen clearly in the image (Fig. 13b). The location for the insertion
    point of the flag was estimated based on the location of the first color stake
    in each plant row (Fig. 13b). Download : Download high-res image (227KB) Download
    : Download full-size image Fig. 13. Images showing a) ground stake used to mark
    the ground control point (GCP) for cotton field and b) flag used to mark the monitoring
    site and used as the GCP for corn field. The developed pipeline was expected to
    be a low-cost near real-time tool for row crop emergence estimation as it reduced
    the time needed for image stitching compared to the commercial software. Image
    stitching comprises several steps: 1) feature detection and matching between images;
    2) non-linear geometric transformation matrix estimation including translation,
    rotation, and scale; 3) warping transformation for mosaic processing (Brown and
    Lowe, 2007). When data are collected for row crops with fixed row spacing and
    under steady UAV flight conditions, the developed method of only calculating translations
    in the geometric transformation matrices required less processing time than the
    stitching process. The dynamic calibration of GSD for individual images using
    row spacing would make it possible for field mapping without the image mosaic
    process. 4.2. Cotton field emergence mapping The mapping of the cotton field in
    this study showed a low correlation value between emergence and yield, which was
    likely caused by environmental factors, irrigation, and other in-season management
    (Feng et al., 2022). Nonetheless, the finding of positive correlation was still
    consistent with previous studies indicating that higher plant density would have
    higher yields as there were more bolls per unit area (Yang et al., 2014, Zhi et
    al., 2016). Meanwhile, canopy size is one of the critical components of canopy
    structure relating to plant photosynthesis, fruiting, and biomass accumulation
    (Jiang et al., 2018, Jung et al., 2018), and is commonly used as a feature in
    cotton yield estimation (Feng et al., 2020c; Jung et al., 2018). More investigations
    are needed to study the effects of environments and crop development on the final
    yield. 4.3. Pipeline limitations Our pipeline has a few limitations. Firstly,
    the method was developed to be used for row crops with fixed row spacing (such
    as cotton and corn shown in this study) as it highly depends on the crop row detection
    for image rotation and GSD calculation for each image. Therefore, there would
    be large errors if crop rows were not detected. Secondly, the method is limited
    to row crops at early emergence, or the crop growth stages before the crop leaves
    of neighboring rows start to overlap and close the canopy. Once leaf overlaps
    occur, crop rows are hardly detected and the initial steps of rotating images
    and calculating GSD are not feasible. In addition, to ensure the best performance
    of the pipeline (without needing manual identification and assignment of crop
    row numbers as detailed in section 3.2), a stable flight height on a flat field
    is desired. Inconsistent flight heights (especially in the situation of UAVs flown
    at low altitude in fields with substantial slopes) and height differences of two
    different flight missions will cause large scale factor differences in images,
    which is not included in our transform matrix calculation. For studies conducted
    on a windy day with limited processing performance using the methods developed
    in this study, automatic detection and correction of scale differences (row spacing
    could still be used as a clue) will be one of the solutions for this issue, which
    we would include in our future studies. 4.4. Potential application and future
    study The pipeline can be applied in a UAV data processing framework with a graphical
    user interface similar to the framework in Feng et al. (2020a) to process the
    data after a UAV flight, which allows a more user-friendly data processing platform
    for different users such as agronomists, breeders, and farmers to obtain crop
    emergence or early growth maps. Furthermore, the pipeline can also be used as
    a processing unit integrated with the onboard UAV sensor to deliver real-time
    data processing and thus reduce the time data transmission and pre-processing,
    before obtaining the final crop emergence maps. Future studies should include
    modification of the pipeline to other row crops such as soybean and vegetable
    for different emergence parameters estimations on the field scale. These estimations
    can be used by researchers to explore the relationships between crop emergence
    and environmental factors such as soil and weather conditions as well as different
    planting treatments. Meanwhile, this can act as a low-cost near real-time tool
    for small-scale farmers to estimate the early emergence in their fields. For large-scale
    farmers, the method can be used to scout areas within fields with emergence issues
    or biotic stresses impacting stand for further management decisions, or field
    areas that cannot be accessed easily by ground vehicles. 5. Conclusion This paper
    reports the development of a near real-time image processing pipeline to process
    single UAV images with an improved position accuracy algorithm to generate emergence
    maps of row crops including cotton and corn. The emergence parameters included
    stand count and canopy size for cotton as well as stand count, mean days to imaging
    after emergence, and plant spacing standard deviation for corn. The developed
    pipeline procedures included feature detection and matching, false matches removal,
    geometric transformation matrix calculation, crop row alignment, assigning position
    of each single image, and mapping. The results showed that the position accuracies
    for the developed pipeline compared to RTK-GNSS ground-truth measurements were
    0.32 ± 0.21 m and 0.57 ± 0.28 m for the cotton and corn fields, respectively.
    Emergence maps of cotton and corn fields were generated to demonstrate the application
    of this new method. The processing time needed to run the algorithm was 8.6 and
    3.6 s/image for cotton and corn fields, respectively. After adding the time needed
    for image pre-processing, the time needed would be 10.4 and 5.7 s image-1, corresponding
    to 1.3 and 1.0 hr ha−1 for the cotton and corn field, respectively. The developed
    pipeline introduced a new approach in using UAV images to quantify crop early
    emergence in a shorter time and lower cost. The current study demonstrated the
    usage of the pipeline for cotton and corn. CRediT authorship contribution statement
    Aijing Feng: Methodology, Data curation, Formal analysis, Writing – original draft.
    Chin Nee Vong: Methodology, Data curation, Formal analysis, Writing – original
    draft. Jing Zhou: Data curation, Formal analysis, Writing – original draft. Lance
    S. Conway: Investigation, Data curation. Jianfeng Zhou: Supervision, Conceptualization,
    Data curation, Writing – review & editing. Earl D. Vories: Resources, Data curation,
    Writing – review & editing. Kenneth A. Sudduth: Conceptualization, Resources,
    Writing – review & editing. Newell R. Kitchen: Conceptualization, Investigation,
    Data curation, Resources, Writing – review & editing. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgements The authors would like to give thanks to colleagues
    Huawei Mou and Shengwei Wang from the Precision and Automated Agriculture Lab
    at the University of Missouri for their help in UAV data collection. We also want
    to thank the staff from the USDA-ARS Cropping Systems & Water Quality Research
    Unit for helping to manage the fields. Code availability The code related to this
    study are available at: https://github.com/AJFeng/Emergence_row_alignment. Data
    availability Data will be made available on request. References Bay et al., 2008
    H. Bay, A. Ess, T. Tuytelaars, L. Van Gool Speeded-up robust features (SURF) Computer
    Vision and Image Understanding, 110 (3) (2008), pp. 346-359, 10.1016/j.cviu.2007.09.014
    View PDFView articleView in ScopusGoogle Scholar Brown and Lowe, 2007 M. Brown,
    D.G. Lowe Automatic panoramic image stitching using invariant features International
    Journal of Computer Vision, 74 (1) (2007), pp. 59-73, 10.1007/s11263-006-0002-3
    View in ScopusGoogle Scholar Clawson et al., 2006 E.L. Clawson, J.T. Cothren,
    D.C. Blouin Nitrogen fertilization and yield of cotton in ultra-narrow and conventional
    row spacings Agronomy Journal, 98 (1) (2006), pp. 72-79, 10.2134/agronj2005.0033
    View in ScopusGoogle Scholar Cui et al., 2020 J. Cui, M. Liu, Z. Zhang, S. Yang,
    J. Ning Robust UAV thermal infrared remote sensing images stitching via overlap-prior-based
    global similarity prior model IEEE Journal of Selected Topics in Applied Earth
    Observations and Remote Sensing, 14 (2020), pp. 270-282, 10.1109/JSTARS.2020.3032011
    Google Scholar Delavarpour et al., 2021 N. Delavarpour, C. Koparan, J. Nowatzki,
    S. Bajwa, X. Sun A technical study on UAV characteristics for precision agriculture
    applications and associated practical challenges Remote Sensing, 13 (6) (2021),
    p. 1204, 10.3390/rs13061204 View in ScopusGoogle Scholar Elmore and Abendroth,
    2007 R.W. Elmore, L.J. Abendroth Row spacing alternatives in corn Paper Presented
    at the Proceedings of the Indiana CCA Conference (2007) Google Scholar Feng et
    al., 2019 Feng, A., Sudduth, K. A., Vories, E. D., & Zhou, J. (2019). Evaluation
    of cotton stand count using UAV-based hyperspectral imagery. Paper presented at
    the 2019 ASABE Annual International Meeting, Boston, MA. Google Scholar Feng et
    al., 2020a A. Feng, J. Zhou, E. Vories, K.A. Sudduth Evaluation of cotton emergence
    using UAV-based imagery and deep learning Computers and Electronics in Agriculture,
    177 (2020), Article 105711, 10.1016/j.compag.2020.105711 View PDFView articleView
    in ScopusGoogle Scholar Feng et al., 2020b A. Feng, J. Zhou, E. Vories, K.A. Sudduth
    Evaluation of cotton emergence using UAV-based narrow-band spectral imagery with
    customized image alignment and stitching algorithms Remote Sensing, 12 (11) (2020),
    p. 1764, 10.3390/rs12111764 View in ScopusGoogle Scholar Feng et al., 2020c A.
    Feng, J. Zhou, E.D. Vories, K.A. Sudduth, M. Zhang Yield estimation in cotton
    using UAV-based multi-sensor imagery Biosystems Engineering, 193 (2020), pp. 101-114,
    10.1016/j.biosystemseng.2020.02.014 View PDFView articleView in ScopusGoogle Scholar
    Feng et al., 2022 A. Feng, J. Zhou, E.D. Vories, et al. Quantifying the effects
    of soil texture and weather on cotton development and yield using UAV imagery
    Precision Agric (2022), 10.1007/s11119-022-09883-6 Google Scholar Gross and Heumann,
    2016 J.W. Gross, B.W. Heumann A statistical examination of image stitching software
    packages for use with unmanned aerial systems Photogrammetric Engineering & Remote
    Sensing, 82 (6) (2016), pp. 419-425, 10.1016/S0099-1112(16)82035-2 View PDFView
    articleView in ScopusGoogle Scholar Hugenholtz et al., 2016 C. Hugenholtz, O.
    Brown, J. Walker, T. Barchyn, P. Nesbit, M. Kucharczyk, S. Myshak Spatial accuracy
    of UAV-derived orthoimagery and topography: Comparing photogrammetric models processed
    with direct geo-referencing and ground control points Geomatica, 70 (1) (2016),
    pp. 21-30, 10.5623/CIG2016-102 View in ScopusGoogle Scholar Iglhaut et al., 2019
    J. Iglhaut, C. Cabo, S. Puliti, L. Piermattei, J. O’Connor, J. Rosette Structure
    from motion photogrammetry in forestry: A review Current Forestry Reports, 5 (3)
    (2019), pp. 155-168, 10.1007/s40725-019-00094-3 View in ScopusGoogle Scholar Jiang
    et al., 2018 Y. Jiang, C. Li, A.H. Paterson, S. Sun, R. Xu, J. Robertson Quantitative
    analysis of cotton canopy size in field conditions using a consumer-grade RGB-D
    camera Frontiers in Plant Science, 8 (2018), p. 2233, 10.3389/fpls.2017.02233
    View in ScopusGoogle Scholar Jung et al., 2018 J. Jung, M. Maeda, A. Chang, J.
    Landivar, J. Yeom, J. McGinty Unmanned aerial system assisted framework for the
    selection of high yielding cotton genotypes Computers and Electronics in Agriculture,
    152 (2018), pp. 74-81, 10.1016/j.compag.2018.06.051 View PDFView articleView in
    ScopusGoogle Scholar Lowe, 2004 D.G. Lowe Distinctive image features from scale-invariant
    keypoints International Journal of Computer Vision, 60 (2) (2004), pp. 91-110,
    10.1023/B:VISI.0000029664.99615.94 View in ScopusGoogle Scholar Naik and Nair,
    2019 R.K. Naik, B.B. Nair Improving GPS based distance measurement accuracy using
    machine learning: an empirical study Paper Presented at the 2019 International
    Conference on Communication and Electronics Systems (ICCES) (2019), 10.1109/ICCES45898.2019.9002218
    Google Scholar Obanawa et al., 2019 H. Obanawa, S. Sakanoue, T. Yagi Evaluating
    the applicability of RTK-UAV for field management Paper Presented at the IGARSS
    2019–2019 IEEE International Geoscience and Remote Sensing Symposium (2019), 10.1109/IGARSS.2019.8897895
    Google Scholar Rabah et al., 2018 M. Rabah, M. Basiouny, E. Ghanem, A. Elhadary
    Using RTK and VRS in direct geo-referencing of the UAV imagery NRIAG Journal of
    Astronomy and Geophysics, 7 (2) (2018), pp. 220-226, 10.1016/j.nrjag.2018.05.003
    View PDFView articleGoogle Scholar Robinson and Conley, 2007 A.P. Robinson, S.P.
    Conley Soybean production systems: plant population and seeding rates for soybean
    Purdue Extension, Purdue University, Indiana, USA (2007) Google Scholar Sansone
    et al., 2002 C. Sansone, T. Isakeit, R. Lemon, B. Warrick Texas cotton production:
    Emphasizing integrated pest management Texas Cooperative Extension Service, Texas
    A & M University System, Texas, USA (2002) Google Scholar Sanz-Ablanedo et al.,
    2018 E. Sanz-Ablanedo, J.H. Chandler, J.R. Rodríguez-Pérez, C. Ordóñez Accuracy
    of unmanned aerial vehicle (UAV) and SfM photogrammetry survey as a function of
    the number and location of ground control points used Remote Sensing, 10 (10)
    (2018), p. 1606, 10.3390/rs10101606 View in ScopusGoogle Scholar Štroner et al.,
    2021 M. Štroner, R. Urban, J. Seidl, T. Reindl, J. Brouček Photogrammetry using
    UAV-mounted GNSS RTK: georeferencing strategies without GCPs Remote Sensing, 13
    (7) (2021), p. 1336, 10.3390/rs13071336 View in ScopusGoogle Scholar Supak, 1990
    Supak, J. (1990). Making replant decisions. Paper presented at the 1990 Beltwide
    cotton production conference. Google Scholar Szeliski, 2007 R. Szeliski Image
    alignment and stitching: A tutorial Foundations and Trends® in Computer Graphics
    and Vision, 2 (1) (2007), pp. 1-104, 10.1561/0600000009 Google Scholar Tsouros
    et al., 2019 D.C. Tsouros, S. Bibi, P.G. Sarigiannidis A review on UAV-based applications
    for precision agriculture Information, 10 (11) (2019), p. 349, 10.3390/info10110349
    View in ScopusGoogle Scholar Vega et al., 2015 F.A. Vega, F.C. Ramirez, M.P. Saiz,
    F.O. Rosua Multi-temporal imaging using an unmanned aerial vehicle for monitoring
    a sunflower crop Biosystems Engineering, 132 (2015), pp. 19-27, 10.1016/j.biosystemseng.2015.01.008
    View PDFView articleView in ScopusGoogle Scholar Vong et al., 2021 C.N. Vong,
    L.S. Conway, J. Zhou, N.R. Kitchen, K.A. Sudduth Early corn stand count of different
    cropping systems using UAV-imagery and deep learning Computers and Electronics
    in Agriculture, 186 (2021), Article 106214, 10.1016/j.compag.2021.106214 View
    PDFView articleView in ScopusGoogle Scholar Vong et al., 2022 C.N. Vong, L.S.
    Conway, J. Zhou, N.R. Kitchen, K.A. Sudduth Corn emergence uniformity estimation
    and mapping using UAV imagery and deep learning Computers and Electronics in Agriculture,
    198 (2022), Article 107008, 10.1016/j.compag.2022.107008 View PDFView articleView
    in ScopusGoogle Scholar Xiang and Tian, 2011 H. Xiang, L. Tian Method for automatic
    georeferencing aerial remote sensing (RS) images from an unmanned aerial vehicle
    (UAV) platform Biosystems Engineering, 108 (2) (2011), pp. 104-113, 10.1016/j.biosystemseng.2010.11.003
    View PDFView articleView in ScopusGoogle Scholar Xie and Yang, 2020 C. Xie, C.
    Yang A review on plant high-throughput phenotyping traits using UAV-based sensors
    Computers and Electronics in Agriculture, 178 (2020), Article 105731, 10.1016/j.compag.2020.105731
    View PDFView articleView in ScopusGoogle Scholar Yang et al., 2014 G. Yang, X.
    Luo, Y. Nie, X. Zhang Effects of plant density on yield and canopy micro environment
    in hybrid cotton Journal of Integrative Agriculture, 13 (10) (2014), pp. 2154-2163,
    10.1016/S2095-3119(13)60727-3 View PDFView articleView in ScopusGoogle Scholar
    Yang et al., 2017 G. Yang, J. Liu, C. Zhao, Z. Li, Y. Huang, H. Yu, X. Zhang Unmanned
    aerial vehicle remote sensing for field-based crop phenotyping: current status
    and perspectives Frontiers in Plant Science, 8 (2017), p. 1111, 10.3389/fpls.2017.01111
    View in ScopusGoogle Scholar Zhi et al., 2016 X.-Y. Zhi, Y.-C. Han, Y.-B. Li,
    G.-P. Wang, W.-L. Du, X.-X. Li, F. Lu Effects of plant density on cotton yield
    components and quality Journal of Integrative Agriculture, 15 (7) (2016), pp.
    1469-1479, 10.1016/S2095-3119(15)61174-1 View PDFView articleView in ScopusGoogle
    Scholar Cited by (1) Optimization Methods for UAVs to Search Light Source in VLC
    2023, Faguang Xuebao/Chinese Journal of Luminescence 1 Aijing Feng and Chin Nee
    Vong are joint first authors. View Abstract © 2023 Elsevier B.V. All rights reserved.
    Recommended articles Aerial multispectral imaging for crop hail damage assessment
    in potato Computers and Electronics in Agriculture, Volume 127, 2016, pp. 406-412
    Jianfeng Zhou, …, Sindhuja Sankaran View PDF Calculation method of wilting index
    based on fractal dimension of multispectral images for the soybean canopy Computers
    and Electronics in Agriculture, Volume 206, 2023, Article 107656 Panpan Shen,
    …, Tao Zhang View PDF Estimating characteristic coefficient of vertical leaf nitrogen
    profile within wheat canopy from spectral reflectance Computers and Electronics
    in Agriculture, Volume 206, 2023, Article 107652 Heli Li, …, Chunjiang Zhao View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 1 Captures
    Readers: 13 View details About ScienceDirect Remote access Shopping cart Advertise
    Contact and support Terms and conditions Privacy policy Cookies are used by this
    site. Cookie settings | Your Privacy Choices All content on this site: Copyright
    © 2024 Elsevier B.V., its licensors, and contributors. All rights are reserved,
    including those for text and data mining, AI training, and similar technologies.
    For all open access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computers and Electronics in Agriculture
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Developing an image processing pipeline to improve the position accuracy
    of single UAV images
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Prajapati J.B.
  - Kumar A.
  - Pramanik J.
  - Prajapati B.G.
  - Saini K.
  citation_count: '1'
  description: Advancements of the last decade in edge computing, edge IoT, and edge
    artificial intelligence now allow for autonomous, efficient, and intelligent systems
    to be proposed for various industrial applications. Intelligence agricultural
    solutions allow farmers to achieve more with less while improving quality and
    providing a rapid go-to-market approachfor produce. Using AI is an effective technique
    to detect any crop health concerns or nutrient inadequacies in the field. Plant
    diseases affect the food system, economy, and environment. This chapter covers
    intelligent agriculture & challenges in front of technology. It focuses AI application
    using machine learning, artificial neural network (ANN), and deep learning. The
    various AI applications in agriculture for land monitoring, crop and varietal
    selection, smart irrigation or automation of irrigation, monitoring of crop health,
    crop disease detection, predictive analytics, weed control, precision agriculture,
    harvesting, yield estimation and phenotyping, supply chain management, and food
    quality.
  doi: 10.4018/978-1-6684-6413-7.ch014
  full_citation: '>'
  full_text: '>

    "Login Register Language: English Welcome to the InfoSci Platform University of
    Nebraska - Lincoln Database Search Research Tools User Resources Reference Hub2
    Edge AI for Real-Time and Intelligent Agriculture Jigna Bhupendra Prajapati, Akash
    Kumar, Jhilam Pramanik, Bhupendra G. Prajapati, Kavita Saini Source Title: Applying
    Drone Technologies and Robotics for Agricultural Sustainability Copyright: © 2023
    |Pages: 30 ISBN13: 9781668464137|ISBN10: 1668464136|EISBN13: 9781668464151 DOI:
    10.4018/978-1-6684-6413-7.ch014 Cite Chapter Favorite View Full Text HTML View
    Full Text PDF Abstract Advancements of the last decade in edge computing, edge
    IoT, and edge artificial intelligence now allow for autonomous, efficient, and
    intelligent systems to be proposed for various industrial applications. Intelligence
    agricultural solutions allow farmers to achieve more with less while improving
    quality and providing a rapid go-to-market approach for produce. Using AI is an
    effective technique to detect any crop health concerns or nutrient inadequacies
    in the field. Plant diseases affect the food system, economy, and environment.
    This chapter covers intelligent agriculture & challenges in front of technology.
    It focuses AI application using machine learning, artificial neural network (ANN),
    and deep learning. The various AI applications in agriculture for land monitoring,
    crop and varietal selection, smart irrigation or automation of irrigation, monitoring
    of crop health, crop disease detection, predictive analytics, weed control, precision
    agriculture, harvesting, yield estimation and phenotyping, supply chain management,
    and food quality. Request access from your librarian to read this chapter''s full
    text. Full Text Preview Introduction Agriculture Agriculture is one of the oldest
    economic sectors for thousands of years ago (Mazoyer & Roudart, 2006). The farming
    began manually with the help of a few animals & with a few manual devices. Agriculture
    is an important sector, of the overall economy anywhere (Alston & Pardey, 2014).
    The various factor dependable on each other for overall growth. Agriculture has
    a wide range of subsections such as farming, food industries, animal centers,
    food trails & errors, services sector, agricultural research, and many more. Agriculture
    can cover different types of farming as Subsistence, Intensive Subsistence, Mediterranean,
    Arable, Shifting Cultivation, etc (Komarek, De Pinto, & Smith, 2020). Today, there
    is an increment in the human population that needs more agricultural production
    with concern to a varied range of food products. There is a large volume of farmers
    associated with middle or low income of agriculture which is accounting for national
    income. To maintain the routine of the Environment cycle agriculture is helpful
    in many nodes as reduces erosion & soil moisture, Soil carbon sequestration (Palm
    et al., 2014). Another side some pesticides used in farming create environmental
    pollution to a certain extent (Tudi et al., 2021). There can be various impacts
    on CO2 by renewable energy consumption (Waheed et al., 2018). Agriculture affects
    directly and indirectly many other industries for prospects. Agriculture methods
    have been changing dynamically. The conventional way of agriculture production
    involved the preparation of soil, sowing of seeds, Adding Fertilizers, Irrigation,
    weed protection, Harvesting, Storage, and distribution as described in Figure
    1. Each phase is modernized as time passes. The new technology assists profoundly
    in enhancing the performance of Agribusiness. Figure 1. Elementary Agriculture
    Intelligent Agriculture Agriculture with AI-aided machinery is becoming popular
    as intelligent Agriculture using IOT support. Intelligent agriculture utilizes
    various types of robots as intelligent machines for different task execution.
    Automation surely benefited in almost all fields but in agriculture, it is a big
    revolution as it is the prime source of income for a large volume of people. The
    smart devices enabled AI support pushes agriculture towards intelligent agriculture
    with human intervention. The traditional agricultural tasks such as harvesting,
    weed identification, and pest examination are also done with autonomous robots
    which are AI aided. The usage of intelligent machines in agriculture will enhance
    the speed of work compared to human laborers (Ahmad & Nabi, 2021). There is a
    higher number of technical integrations with agriculture by various smart devices
    & mechanisms for sensing, identification, transmission, monitoring, analysis,
    and prediction. Such IoT devices will save time & cost & improves crop yields
    (Chen & Yang, 2019). The remote sensors, GIS, GPS, drones, and many others are
    actively playing an important role in Intelligent Agriculture. Agriculture Challenges
    In Front Of Technology Many factors affect traditional farming as rainfall, temperature,
    and humidity. An imbalance in climatic changes may cause deforestation and pollution
    which create a hurdle for farmers to take decisions to prepare the soil, sow seeds,
    and harvest (Harris et al., 2001). The nutrient deficit can result in poor crop
    quality as every crop requires a certain type of soil nourishment (Nair, 2019).
    Weed protection is also crucial to increasing the production of nutrients (Ibáñez
    & Blázquez, 2019). Agriculture is not an isolated sector; it is an integral part
    of a sound ecosystem. There are many challenges in agriculture as horticulture,
    animal centers, dairy, and other allied sectors (McCalla & Economics, 2001). Technology
    is widely integrated into multiple stages of the agriculture process. The internal
    & external resources can be utilized with a better prospect using current trends
    of technologies. The broadly technological challenges can be classified as Continue
    Reading References Follow Reference Abawi G. S. Widmer T. L. (2000). Impact of
    soil health management practices on soilborne pathogens, nematodes and root diseases
    of vegetable crops.Applied Soil Ecology, 15(1), 37–47. 10.1016/S0929-1393(00)00070-6
    Follow Reference Accorsi R. Cholette S. Manzini R. Tufano A. (2018). A hierarchical
    data architecture for sustainable food supply chain management and planning.Journal
    of Cleaner Production, 203, 1039–1054. doi:10.1016/j.jclepro.2018.08.275 Follow
    Reference Agatonovic-Kustrin S. Beresford R. (2000). Basic concepts of artificial
    neural network (ANN) modeling and its application in pharmaceutical research.Journal
    of Pharmaceutical and Biomedical Analysis, 22(5), 717–727. 10.1016/S0731-7085(99)00272-110815714
    Agriinfo. (2018). Soil –Plant – Water – Relationships. Agriinfo.https://agriinfo.in/soil-plant-water-relationships-2206/
    Follow Reference Ahmad I. Shahabuddin S. Sauter T. Harjula E. Kumar T. Meisel
    M. Juntti M. Ylianttila M. (2021). The Challenges of Artificial Intelligence in
    Wireless Networks for the Internet of Things: Exploring Opportunities for Growth.IEEE
    Industrial Electronics Magazine, 15(1), 16–29. 10.1109/MIE.2020.2979272 Follow
    Reference Ahmad L. Nabi F. (2021). Agriculture 5.0: Artificial Intelligence, IoT
    and Machine Learning. CRC Press. Ahn, H.S., Dayoub, F., Popovic, M., MacDonald,
    B.A., Siegwart, R.Y., & Sa, I. (2018). An Overview of Perception Methods for Horticultural
    Robots: From Pollination to Harvest. ArXiv, abs/1807.03124. Follow Reference Aiello
    G. Catania P. Vallone M. Venticinque M. (2022). Worker safety in agriculture 4.0:
    A new approach for mapping operator’s vibration risk through Machine Learning
    activity recognition.Computers and Electronics in Agriculture, 193, 106637. 10.1016/j.compag.2021.106637
    Follow Reference Aitkenhead, M. J., Mcdonald, A. J. S., Dawson, J. J., Couper,
    G., Smart, R. P., Billett, M., Hope, D., & Palmer, S. (2003). A novel method for
    training neural networks for time-series prediction in environmental systems.
    Elsevier, 162, 87–95. 10.1016/S0304-3800(02)00401-5 Follow Reference Alston J.
    M. Pardey P. G. (2014). Agriculture in the Global Economy %J. The Journal of Economic
    Perspectives, 28(1), 121–146. 10.1257/jep.28.1.121 Follow Reference Amatya S.
    Karkee M. Gongal A. Zhang Q. Whiting M. D. (2016). Detection of cherry tree branches
    with full foliage in planar architecture for automated sweet-cherry harvesting.Biosystems
    Engineering, 146, 3–15. 10.1016/j.biosystemseng.2015.10.003 Follow Reference Arif
    C. Indra Setiawan B. Mizoguchi M. Doi R. (2012a). Estimation of soil moisture
    in paddy field using Artificial Neural Networks.International Journal of Advanced
    Research in Artificial Intelligence, 1(1). 10.14569/IJARAI.2012.010104 Follow
    Reference Arif C. Mizoguchi M. Mizoguchi M. Doi R. (2012b). Estimation of soil
    moisture in paddy field using Artificial Neural Networks.International Journal
    of Advanced Research in Artificial Intelligence, 1(1). 10.14569/IJARAI.2012.010104
    Follow Reference Åstrand B. Baerveldt A. J. (2002). An agricultural mobile robot
    with vision-based perception for mechanical weed control.Autonomous Robots, 13(1),
    21–35. 10.1023/A:1015674004201 Follow Reference Babu, S. (2013). A software model
    for precision agriculture for small and marginal farmers. Global Humanitarian
    Technology Conference: South Asia Satellite, 352–355. IEEE. 10.1109/GHTC-SAS.2013.6629944
    Follow Reference Bacco M. Barsocchi P. Ferro E. Gotta A. Ruggeri M. (2019). The
    Digitisation of Agriculture: A Survey of Research Activities on Smart Farming.Array,
    3–4, 100009. 10.1016/j.array.2019.100009 Follow Reference Bak T. Jakobsen H. (2004).
    Agricultural robotic platform with four wheel steering for weed detection.Biosystems
    Engineering, 87(2), 125–136. 10.1016/j.biosystemseng.2003.10.009 Follow Reference
    Bakker T. van Asselt K. Bontsema J. Müller J. van Straten G. (2006). An autonomous
    weeding robot for organic farming.Springer Tracts in Advanced Robotics, 25, 579–590.
    10.1007/978-3-540-33453-8_48 Follow Reference Barlow H. B. (1989). Unsupervised
    Learning.Neural Computation, 1(3), 295–311. 10.1162/neco.1989.1.3.295 Beaman,
    J. A., & Johnson, A. J. (2006). Food distribution channel overview: a guide for
    new manufacturers. OSU. https://ir.library.oregonstate.edu/concern/open_educational_resources/8623hz116
    Follow Reference Bhattacharyya S. S. Maitra D. Deb S. (2021). Study of adoption
    and absorption of emerging technologies for smart supply chain management: A dynamic
    capabilities perspective.[IJAL]. International Journal of Applied Logistics, 11(2),
    14–54. Bhbosale, S., Pujari, V., & Multani, Z. J. A. I. I. R. J. (2020). Advantages
    And Disadvantages Of Artificial Intellegence. 227-230. Follow Reference Bilgili
    M. (2011). The use of artificial neural networks for forecasting the monthly mean
    soil temperatures in Adana, Turkey.Turkish Journal of Agriculture and Forestry,
    35(1), 83–93. https://dergipark.org.tr/en/pub/tbtkagriculture/issue/11593/138197
    Follow Reference Bioucas-Dias, J. M., Plaza, A., Camps-Valls, G., Scheunders,
    P., Nasrabadi, N. M., & Chanussot, J. (2013). Hyperspectral remote sensing data
    analysis and future challenges. Geoscience and Remote Sensing Magazine, 1(2),
    6–36. IEEE . 10.1109/MGRS.2013.2244672 Follow Reference Blasco J. Aleixos N. Roger
    J. M. Rabatel G. Moltó E. (2002). AE—Automation and emerging technologies: Robotic
    weed control using machine vision.Biosystems Engineering, 83(2), 149–157. Follow
    Reference Bonaccorso G. (2017). Machine learning algorithms. Packt Publishing
    Ltd. Follow Reference Bralts V. F. Driscoll M. A. Shayya W. H. Cao L. (1993).
    An expert system for the hydraulic analysis of microirrigation systems.Computers
    and Electronics in Agriculture, 9(4), 275–287. Follow Reference Bu F. Wang X.
    (2019). A smart agriculture IoT system based on deep reinforcement learning.[doi:https://doi.org/10.1016/j.future.2019.04.041].
    Future Generation Computer Systems, 99, 500–507. Follow Reference Bünger L. (2021).
    Robotic waste sorting. Worcester Polytechnic Institute. Follow Reference Busch,
    G. (2012). GIS-based Tools for Regional Assessments and Planning Processes Regarding
    Potential Environmental Effects of Poplar SRC. BioEnergy Research 5(3), 584–605.
    10.1007/S12155-012-9224-0 Follow Reference Cakir, Y., Kirci, M., & Gunes, E. O.
    (2014). Yield prediction of wheat in south-east region of Turkey by using artificial
    neural networks. The 3rd International Conference on Agro-Geoinformatics. Agro-Geoinformatics
    . 10.1109/AGRO-GEOINFORMATICS.2014.6910609 Follow Reference Carbonell J. G. Michalski
    R. S. Mitchell T. M. (1983). 1 - AN OVERVIEW OF MACHINE LEARNING. In MichalskiR.
    S.CarbonellJ. G.MitchellT. M. (Eds.), Machine Learning (pp. 3–23). Morgan Kaufmann.
    Follow Reference Chang D. H. Islam S. (2000). Estimation of soil physical properties
    using remote sensing and artificial neural network.Remote Sensing of Environment,
    74(3), 534–544. Follow Reference Chang, C. & Robotics, K. L. (2018). Smart agricultural
    machine with a computer vision-based weeding and variable-rate irrigation scheme.
    Mdpi.Com.10.3390/robotics7030038 Follow Reference Charoen-Ung, P., & Mittrapiyanuruk,
    P. (2019). Sugarcane Yield Grade Prediction Using Random Forest with Forward Feature
    Selection and Hyper-parameter Tuning. Advances in Intelligent Systems and Computing,
    769, 33–42. 10.1007/978-3-319-93692-5_4 Follow Reference Chattopadhyay P. B. Rangarajan
    R. (2014). Application of ANN in sketching spatial nonlinearity of unconfined
    aquifer in agricultural basin.[doi:https://doi.org/10.1016/j.agwat.2013.11.007].
    Agricultural Water Management, 133, 81–91. Follow Reference Chen J. Chen J. Zhang
    D. Sun Y. Nanehkaran Y. A. (2020). Using deep transfer learning for image-based
    plant disease identification.Computers and Electronics in Agriculture, 173, 105393.
    https://doi.org/10.1016/J.COMPAG.2020.105393 Follow Reference Chen J. Yang A.
    (2019). Intelligent Agriculture and Its Key Technologies Based on Internet of
    Things Architecture.IEEE Access: Practical Innovations, Open Solutions, 7, 77134–77141.
    doi:10.1109/ACCESS.2019.2921391 Follow Reference Cheng X. Zhang Y. Chen Y. Wu
    Y. Yue Y. (2017). Pest identification via deep residual learning in complex background.[doi:https://doi.org/10.1016/j.compag.2017.08.005].
    Computers and Electronics in Agriculture, 141, 351–356. Follow Reference Cui,
    S., Ling, P., Zhu, H., & Keener, H. M. (2018). Plant Pest Detection Using an Artificial
    Nose System: A Review. Sensors 18(2), 378. 10.3390/S18020378 Daheim, C., Poppe,
    K., & Schrijver, R. (2019). Precision agriculture and the future of farming in
    Europe: scientific foresight study. European Parliament. https://data.europa.eu/doi/10.2861/175493
    Follow Reference Daugherty P. R. Wilson H. J. (2018). Human+ machine: Reimagining
    work in the age of AI. Harvard Business Press. Follow Reference Devapriya P. Ferrell
    W. Geismar N. (2017). Integrated production and distribution scheduling with a
    perishable product.European Journal of Operational Research, 259(3), 906–916.
    https://doi.org/10.1016/J.EJOR.2016.09.019 Follow Reference Devaraj, A., Rathan,
    K., Jaahnavi, S., & Indira, K. (2019). Identification of plant disease using image
    processing technique. Proceedings of the 2019 International Conference on Communication
    and Signal Processing, 749–753. IEEE. 10.1109/ICCSP.2019.8698056 Follow Reference
    Dewi T. Risma P. Oktarina Y. (2020). Fruit sorting robot based on color and size
    for an agricultural product packaging system.Bulletin of Electrical Engineering
    and Informatics, 9(4), 1438–1445. Follow Reference dos Santos Ferreira A. Freitas
    D. M. da Silva G. G. Pistori H. Folhes M. T. (2019). Unsupervised deep learning
    and semi-automatic data labeling in weed discrimination.[doi:https://doi.org/10.1016/j.compag.2019.104963].
    Computers and Electronics in Agriculture, 165, 104963. Follow Reference Elshorbagy
    A. Parasuraman K. (2008). On the relevance of using artificial neural networks
    for estimating soil moisture content.Journal of Hydrology (Amsterdam), 362(1-2),
    1–18. Follow Reference Fedorova E. Darbasov V. Okhlopkov M. (2020). The role of
    agricultural economists in study on problems related to regional food safety.
    In E3S Web of Conferences (Vol. 176, p. 05011). EDP Sciences. Follow Reference
    Fennimore, S. A., Slaughter, D. C., Siemens, M. C., Leon, R. G., & Saber, M. N.
    (2016). Technology for automation of weed control in specialty crops. Cambridge.Org,
    30, 823–837. 10.1614/WT-D-16-00070.1 Follow Reference Ferentinos K. P. (2018).
    Deep learning models for plant disease detection and diagnosis.Computers and Electronics
    in Agriculture, 145, 311–318. https://doi.org/10.1016/J.COMPAG.2018.01.009 Follow
    Reference Filimonau V. Todorova E. Mzembe A. Sauer L. Yankholmes A. (2020). A
    comparative study of food waste management in full service restaurants of the
    United Kingdom and the Netherlands.Journal of Cleaner Production, 258, 120775.
    Follow Reference Fuentes, A., Yoon, S., Kim, S. C., & Park, D. S. (2017). A Robust
    Deep-Learning-Based Detector for Real-Time Tomato Plant Diseases and Pests Recognition.
    Sensors, 17(9), 2022. 10.3390/S17092022 Follow Reference Goap A. Sharma D. Shukla
    A. K. Rama Krishna C. (2018). An IoT based smart irrigation management system
    using Machine learning and open source technologies.Computers and Electronics
    in Agriculture, 155, 41–49. https://doi.org/10.1016/J.COMPAG.2018.09.040 Follow
    Reference Gu Z. Qi Z. Ma L. Gui D. Xu J. Fang Q. Yuan S. Feng G. (2017). Development
    of an irrigation scheduling software based on model predicted crop water stress.Computers
    and Electronics in Agriculture, 143, 208–221. https://doi.org/10.1016/J.COMPAG.2017.10.023
    Follow Reference Hady M. F. A. Schwenker F. (2013). Semi-supervised Learning.
    In BianchiniM.MagginiM.JainL. C. (Eds.), Handbook on Neural Information Processing
    (pp. 215–239). Springer Berlin Heidelberg. Follow Reference Haghverdi, A., & Washington-Allen,
    R. (2018). Prediction of cotton lint yield from phenology of crop indices using
    artificial neural networks. Elsevier. 10.1016/j.compag.2018.07.021 Harishankar,
    S., Kumar, R. S., Sudharsan, K. P., Vignesh, U., & Viveknath, T. (2014). Solar
    powered smart irrigation system. Advance in electronic and electric engineering,
    4(4), 341-346. Follow Reference Harris D. Pathan A. K. Gothkar P. Joshi A. Chivasa
    W. Nyamudeza P. (2001). On-farm seed priming: Using participatory methods to revive
    and refine a key technology.[doi:https://doi.org/10.1016/S0308-521X(01)00023-3].
    Agricultural Systems, 69(1), 151–164. Follow Reference Heisel T. Schou J. Christensen
    S. Andreasen C. (2001). Cutting weeds with a CO 2 laser.Weed Research, 41(1),
    19–29. https://doi.org/10.1046/J.1365-3180.2001.00212.X Follow Reference Hinnell,
    A., Lazarovitch, N., & Furman, A. (2010). Neuro-Drip: estimation of subsurface
    wetting patterns for drip irrigation using neural networks. Springer, 28(6), 535–544.
    10.1007/s00271-010-0214-8 Follow Reference Hui, Y. Y., Choy, K. L., Ho, G. T.
    S., Leung, K. H., & Lam, H. Y. (2016). A cloud-based location assignment system
    for packaged food allocation in e-fulfillment warehouse. Sage Journals, 8, 1–15.
    10.1177/1847979016684832 Follow Reference Ibáñez M. D. Blázquez M. A. (2019).
    Ginger and Turmeric Essential Oils for Weed Control and Food Crop Protection.Plants,
    8(3). Advance online publication. 10.3390/plants8030059 Follow Reference Iqbal,
    M. A., & Talukder, K. H. (2020). Detection of Potato Disease Using Image Segmentation
    and Machine Learning. International Conference on Wireless Communications, Signal
    Processing and Networking, 43–47. 10.1109/WISPNET48689.2020.9198563 Follow Reference
    Jagtap, S. T., Phasinam, K., Kassanuk, T., Jha, S. S., Ghosh, T., & Thakar, C.
    M. (2022). Towards application of various machine learning techniques in agriculture.
    Materials Today: Proceedings, 51, 793-797. doi:10.1016/j.matpr.2021.06.236 Follow
    Reference Jha K. Doshi A. Patel P. Shah M. (2019). A comprehensive review on automation
    in agriculture using artificial intelligence.Artificial Intelligence in Agriculture,
    2, 1–12. Follow Reference Kakani V. Nguyen V. H. Kumar B. P. Kim H. Pasupuleti
    V. R. (2020). A critical review on computer vision and artificial intelligence
    in food industry.Journal of Agriculture and Food Research, 2, 100033. https://doi.org/10.1016/J.JAFR.2020.100033
    Follow Reference Kamilaris A. Prenafeta-Boldú F. X. (2018). Deep learning in agriculture:
    A survey.Computers and Electronics in Agriculture, 147, 70–90. https://doi.org/10.1016/J.COMPAG.2018.02.016
    Follow Reference Karar, M. E., Alsunaydi, F., Albusaymi, S., & Alotaibi, S. (2021).
    A new mobile application of agricultural pests recognition using deep learning
    in cloud computing system. Alexandria Engineering Journal, 60(5), 4423-4432. doi:10.1016/j.aej.2021.03.009
    Follow Reference Kasinathan T. Singaraju D. Uyyala S. R. (2021). Insect classification
    and detection in field crops using modern machine learning techniques.[doi:https://doi.org/10.1016/j.inpa.2020.09.006].
    Information Processing in Agriculture, 8(3), 446–457. Follow Reference Kehui X.
    Deqin X. Xiwen L. (2010). Smart water-saving irrigation system in precision agriculture
    based on wireless sensor network.Nongye Gongcheng Xuebao (Beijing), 26(11), 170–175.
    https://doi.org/10.3969/j.issn.1002-6819.2010.11.030 Follow Reference Khedr A.
    E. Kadry M. Walid G. (2015). Proposed Framework for Implementing Data Mining Techniques
    to Enhance Decisions in Agriculture Sector Applied Case on Food Security Information
    Center Ministry of Agriculture, Egypt.Procedia Computer Science, 65, 633–642.
    https://doi.org/10.1016/J.PROCS.2015.09.007 Follow Reference Kim, M. agriculture,
    J. G.-C. and electronics in, & 2008, undefined. (2008). Artificial Neural Network
    estimation of soil erosion and nutrient concentrations in runoff from land application
    areas. Elsevier. 10.1016/j.compag.2008.05.021 Komarek, A. M., De Pinto, A., &
    Smith, V. H. J. A. S. (2020). A review of types of risks in agriculture: What
    we know and what we need to know. Agricultural Systems, 178, 102738. Follow Reference
    Kouadio L. Deo R. C. Byrareddy V. Adamowski J. F. Mushtaq S. (2018). Artificial
    intelligence approach for the prediction of Robusta coffee yield using soil fertility
    properties.Computers and Electronics in Agriculture, 155, 324–338. Follow Reference
    Krisztin T. (2018). Semi-parametric spatial autoregressive models in freight generation
    modeling.Transportation Research Part E, Logistics and Transportation Review,
    114, 121–143. https://doi.org/10.1016/J.TRE.2018.03.003 Kukreja, H., Bharath,
    N., Siddesh, C., & Kuldeep, S. J. I. J. A. R. I. I. E. (2016). An introduction
    to artificial neural network. 1, 27-30. Follow Reference Kumar, I., Rawat, J.,
    Mohd, N., & Husain, S. (2021). Opportunities of Artificial Intelligence and Machine
    Learning in the Food Industry. Journal of Food Quality. 10.1155/2021/4535567 Follow
    Reference Kumar, R., Singh, M. P., Kumar, P., & Singh, J. P. (2015). Crop Selection
    Method to maximize crop yield rate using machine learning technique. International
    Conference on Smart Technologies and Management for Computing, Communication,
    Controls, Energy and Materials, 138–145. 10.1109/ICSTM.2015.7225403 Follow Reference
    Lamm R. D. Slaughter D. C. Giles D. K. (2002). Precision weed control system for
    cotton.Transactions of the ASAE. American Society of Agricultural Engineers, 45(1),
    231. Follow Reference Larsen, R. A., Schaalje, G. B., & Lawson, J. S. (2009).
    Food shelf life: estimation and optimal design. Journal of Statistical Computation
    and Simulation, 80(2), 143–157. 10.1080/00949650802549135 Lauzon, F. Q. (2012,
    2-5 July 2012). An introduction to deep learning. Paper presented at the International
    Conference on Information Science, Signal Processing and their Applications (ISSPA).
    Follow Reference LeCun Y. Bengio Y. Hinton G. (2015). Deep learning.Nature, 521(7553),
    436–444. 10.1038/nature14539 Follow Reference Lezoche M. Hernandez J. E. Díaz
    M. D. M. E. A. Panetto H. Kacprzyk J. (2020). Agri-food 4.0: A survey of the supply
    chains and technologies for the future agriculture.Computers in Industry, 117,
    103187. Follow Reference Li M. Yost R. S. (2000). Management-oriented modeling:
    Optimizing nitrogen management with artificial intelligence.Agricultural Systems,
    65(1), 1–27. Follow Reference Li N. Shepperd M. Guo Y. (2020). A systematic review
    of unsupervised learning techniques for software defect prediction.[doi:https://doi.org/10.1016/j.infsof.2020.106287].
    Information and Software Technology, 122, 106287. Follow Reference Li T. Johansen
    K. McCabe M. F. (2022). A machine learning approach for identifying and delineating
    agricultural fields and their multi-temporal dynamics using three decades of Landsat
    data.[doi:https://doi.org/10.1016/j.isprsjprs.2022.02.002]. ISPRS Journal of Photogrammetry
    and Remote Sensing, 186, 83–101. Follow Reference Li Y. Chao X. (2020). ANN-Based
    Continual Classification in Agriculture.Agriculture, 10(5). doi:10.3390/agriculture10050178
    Follow Reference Liakos K. G. Busato P. Moshou D. Pearson S. Bochtis D. (2018).
    Machine Learning in Agriculture: A Review.Sensors (Basel), 18(8), 2674. https://doi.org/10.3390/s18082674
    Follow Reference Livingstone D. J. (Ed.). (2008). Artificial neural networks:
    methods and applications (pp. 185–202). Humana Press. Follow Reference López E.
    M. García M. Schuhmacher M. Domingo J. L. (2008). A fuzzy expert system for soil
    characterization.Environment International, 34(7), 950–958. Follow Reference Luangkesorn
    K. L. Klein G. Bidanda B. (2016). Analysis of production systems with potential
    for severe disruptions.International Journal of Production Economics, 171, 478–486.
    https://doi.org/10.1016/J.IJPE.2015.09.014 Follow Reference Ma J. Du K. Zheng
    F. Zhang L. Gong Z. Sun Z. (2018). A recognition method for cucumber diseases
    using leaf symptom images based on deep convolutional neural network.Computers
    and Electronics in Agriculture, 154, 18–24. https://doi.org/10.1016/J.COMPAG.2018.08.048
    Follow Reference Mananze, S., Pôças, I., & Cunha, M. (2018). Retrieval of Maize
    Leaf Area Index Using Hyperspectral and Multispectral Data. Remote Sensing, 10(12),
    1942. 10.3390/RS10121942 Follow Reference Mazoyer M. Roudart L. (2006). A history
    of world agriculture: from the neolithic age to the current crisis. NYU Press.
    McCalla, A. F. J. U. A., & Economics, R. (2001). Challenges to world agriculture
    in the 21st century. Agricultural and Resource Economics, 4(3), 1-2. Follow Reference
    Mehra M. Saxena S. Sankaranarayanan S. Tom R. J. Veeramanikandan M. (2018). IoT
    based hydroponics system using Deep Neural Networks.Computers and Electronics
    in Agriculture, 155, 473–486. Mishra, M., & Srivastava, M. (2014). A view of artificial
    neural network. Paper presented at the International Conference on Advances in
    Engineering & Technology Research (ICAETR). Follow Reference Misra N. N. Dixit
    Y. Al-Mallahi A. Bhullar M. S. Upadhyay R. Martynenko A. (2020). IoT, big data
    and artificial intelligence in agriculture and food industry. IEEE Internet of
    Things Journal. Follow Reference Mohanty S. P. Hughes D. P. Salathé M. (2016).
    Using deep learning for image-based plant disease detection.Frontiers in Plant
    Science, 7(September), 1419. https://doi.org/10.3389/FPLS.2016.01419/BIBTEX Moisture,
    S. (2017). Importance of Soil Water. Agriinfo.https://agriinfo.in/soil-moisture-importance-of-soil-water-263/
    Follow Reference Mojjada, R. K., Kiran Kumar, K., Yadav, A., & Satya Vara Prasad,
    B. V. V. (2020). Detection of plant leaf disease using digital image processing.
    Materials Today: Proceedings.10.1016/J.MATPR.2020.11.115 Follow Reference Monga,
    T. (2018). Estimating Vineyard Grape Yield from Images. Lecture Notes in Computer
    Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture
    Notes in Bioinformatics). LNAI, 339–343. 10.1007/978-3-319-89656-4_37 Follow Reference
    Montas H. Madramootoo C. A. (1992). A decision support system for soil conservation
    planning.Computers and Electronics in Agriculture, 7(3), 187–202. Follow Reference
    Monteiro A. L. Freitas Souza M. d. Lins H. A. Teófilo T. M. S. Barros Júnior A.
    P. Silva D. V. Mendonça V. (2021). A new alternative to determine weed control
    in agricultural systems based on artificial neural networks (ANNs).[doi:https://doi.org/10.1016/j.fcr.2021.108075].
    Field Crops Research, 263, 108075. Follow Reference Mucherino, A., & Papajorgji,
    P. Research, P. P.-O., & 2009, undefined. (2009). A survey of data mining techniques
    applied to agriculture. Springer, 9(2), 121–140. 10.1007/s12351-009-0054-6 Follow
    Reference Munz J. M. Gindele N. Doluschitz R. (2020). Exploring the characteristics
    and utilisation of Farm Management Information Systems (FMIS) in Germany.Computers
    and Electronics in Agriculture, 170, 105246. Follow Reference Nair K. P. (2019).
    Soil Fertility and Nutrient Management. In K. P. Nair (Ed.), Intelligent Soil
    Management for Sustainable Agriculture: The Nutrient Buffer Power Concept (pp.
    165–189). Springer International Publishing. Follow Reference Nakai S. Yamada
    Y. (2014). Development of a weed suppression robot for rice cultivation: Weed
    suppression and posture control.Int J Electr Comput Electron Commun Eng, 8, 1736–1740.
    Follow Reference Nasiakou A. Vavalis M. Zimeris D. (2016). Smart energy for smart
    irrigation.Computers and Electronics in Agriculture, 129, 74–83. https://doi.org/10.1016/J.COMPAG.2016.09.008
    Follow Reference Navarro-Hellín H. Martínez-del-Rincon J. Domingo-Miguel R. Soto-Valles
    F. Torres-Sánchez R. (2016). A decision support system for managing irrigation
    in agriculture.Computers and Electronics in Agriculture, 124, 121–131. https://doi.org/10.1016/J.COMPAG.2016.04.003
    Follow Reference Nawandar N. K. Satpute V. R. (2019). IoT based low cost and intelligent
    module for smart irrigation system.Computers and Electronics in Agriculture, 162,
    979–990. https://doi.org/10.1016/J.COMPAG.2019.05.027 Follow Reference Nevavuori
    P. Narra N. Lipping T. (2019). Crop yield prediction with deep convolutional neural
    networks.Computers and Electronics in Agriculture, 163, 104859. https://doi.org/10.1016/J.COMPAG.2019.104859
    Follow Reference Ngo H. C. Hashim U. R. Sek Y. W. Kumar Y. J. Ke W. S. (2019).
    Weeds detection in agricultural fields using convolutional neural network.International
    Journal of Innovative Technology and Exploring Engineering, 8(11), 292–296. https://doi.org/10.35940/IJITEE.K1327.0981119
    Nikolenko, S., Kadurin, A., & Arkhangelskaya, E. J. S. P. (2018). Deep learning.
    Journal of the American Heart Association. Follow Reference Noon S. K. Amjad M.
    Qureshi M. A. Mannan A. (2020). Use of deep learning techniques for identification
    of plant leaf stresses: A review.Sustain. Comput. Informatics Syst., 28, 100443.
    Nørremark, M., & Griepentrog, H. (2004). Analysis and definition of the close-to-crop
    area in relation to robotic weeding. Orgprints.https://orgprints.org/4834/ Follow
    Reference O’Sullivan C. A. Bonnett G. D. McIntyre C. L. Hochman Z. Wasson A. P.
    (2019). Strategies to improve the productivity, product diversity and profitability
    of urban agriculture.[doi:https://doi.org/10.1016/j.agsy.2019.05.007]. Agricultural
    Systems, 174, 133–144. Onishchuk, M. O. (2020). Opto-mechanical sorting of municipal
    solid waste [Doctoral dissertation, BHTY, USA]. Follow Reference Osman, T., Psyche,
    S. S., Kamal, M. R., Tamanna, F., Haque, F., & Rahman, R. M. (2017). Predicting
    Early Crop Production by Analysing Prior Environment Factors. Advances in Intelligent
    Systems and Computing, 470–479. 10.1007/978-3-319-49073-1_51 Follow Reference
    Pallathadka, H., Mustafa, M., Sanchez, D. T., Sekhar Sajja, G., Gour, S., & Naved,
    M. (2021). IMPACT OF MACHINE learning ON Management, healthcare AND AGRICULTURE.
    Materials Today: Proceedings. doi:10.1016/j.matpr.2021.07.042 Follow Reference
    Palm C. Blanco-Canqui H. DeClerck F. Gatere L. Grace P. (2014). Conservation agriculture
    and ecosystem services: An overview.[doi:https://doi.org/10.1016/j.agee.2013.10.010].
    Agriculture, Ecosystems & Environment, 187, 87–105. Follow Reference Pant, J.,
    Pant, R. P., Kumar Singh, M., Pratap Singh, D., & Pant, H. (2021). Analysis of
    agricultural crop yield prediction using statistical techniques of machine learning.
    Materials Today: Proceedings, 46, 10922-10926. doi:10.1016/j.matpr.2021.01.948
    Follow Reference Pantazi X. E. Moshou D. Alexandridis T. Whetton R. L. Mouazen
    A. M. (2016). Wheat yield prediction using machine learning and advanced sensing
    techniques.Computers and Electronics in Agriculture, 121, 57–65. https://doi.org/10.1016/J.COMPAG.2015.11.018
    Follow Reference Partel V. Kakarla S. C. Ampatzidis Y. (2019). Development and
    evaluation of a low-cost and smart technology for precision weed management utilizing
    artificial intelligence.Computers and Electronics in Agriculture, 157, 339–350.
    Follow Reference Qiang L. Jiuping X. (2008). A Study on Vehicle Routing Problem
    in the Delivery of Fresh Agricultural Products under Random Fuzzy Environment.International
    Journal of Information and Management Sciences, 19(4), 673–690. Follow Reference
    Ramcharan A. Baranowski K. McCloskey P. Ahmed B. Legg J. Hughes D. P. (2017).
    Deep learning for image-based cassava disease detection.Frontiers in Plant Science,
    8, 1852. https://doi.org/10.3389/FPLS.2017.01852/BIBTEX Follow Reference Ramos
    P. J. Prieto F. A. Montoya E. C. Oliveros C. E. (2017). Automatic fruit count
    on coffee branches using computer vision.Computers and Electronics in Agriculture,
    137, 9–22. https://doi.org/10.1016/J.COMPAG.2017.03.010 Follow Reference Research,
    R. Z.-P. J. of W. S., & 2010, undefined. (2014). Ethics for weed science. Researchgate.Net.
    10.1017/S0043174500089633 Follow Reference Rico-Fernández M. P. Rios-Cabrera R.
    Castelán M. Guerrero-Reyes H. I. Juarez-Maldonado A. (2019). A contextualized
    approach for segmentation of foliage in different crop species.Computers and Electronics
    in Agriculture, 156, 378–386. Follow Reference Roshanianfard A. Noguchi N. Okamoto
    H. Ishii K. (2020). A review of autonomous agricultural vehicles (The experience
    of Hokkaido University).Journal of Terramechanics, 91, 155–183. Follow Reference
    Rumpf T. Mahlein A. K. Steiner U. Oerke E. C. Dehne H. W. Plümer L. (2010). Early
    detection and classification of plant diseases with Support Vector Machines based
    on hyperspectral reflectance.Computers and Electronics in Agriculture, 74(1),
    91–99. https://doi.org/10.1016/J.COMPAG.2010.06.009 Follow Reference Sadgrove
    E. J. Falzon G. Miron D. Lamb D. W. (2018). Real-time object detection in agricultural/remote
    environments using the multiple-expert colour feature extreme learning machine
    (MEC-ELM).Computers in Industry, 98, 183–191. Follow Reference Saldaña-Robles
    A. L. Bustos-Gaytán A. Diosdado-De la Peña J. A. Saldaña-Robles A. Alcántar-Camarena
    V. Balvantín-García A. Saldaña-Robles N. (2020). Structural design of an agricultural
    backhoe using TA, FEA, RSM and ANN.Computers and Electronics in Agriculture, 172,
    105278. Follow Reference Sawant S. S. Prabukumar M. (2020). A review on graph-based
    semi-supervised learning methods for hyperspectral image classification.[doi:https://doi.org/10.1016/j.ejrs.2018.11.001].
    The Egyptian Journal of Remote Sensing and Space Sciences, 23(2), 243–248. Follow
    Reference Schwenker F. Trentin E. (2014). Pattern classification and clustering:
    A review of partially supervised learning approaches.[doi:https://doi.org/10.1016/j.patrec.2013.10.017].
    Pattern Recognition Letters, 37, 4–14. Follow Reference Sengupta S. Lee W. S.
    (2014). Identification and determination of the number of immature green citrus
    fruit in a canopy under different ambient light conditions.Biosystems Engineering,
    117(C), 51–61. https://doi.org/10.1016/J.BIOSYSTEMSENG.2013.07.007 Shinde, P.
    P., & Shah, S. (2018, 16-18 Aug. 2018). A Review of Machine Learning and Deep
    Learning Applications. Paper presented at the Fourth International Conference
    on Computing Communication Control and Automation (ICCUBEA). Follow Reference
    Shukla M. Jharkharia S. (2014). An inventory model for continuously deteriorating
    agri-fresh produce: An artificial immune system-based solution approach.International
    Journal of Integrated Supply Management, 9(1–2), 110–135. https://doi.org/10.1504/IJISM.2014.064362
    Follow Reference Sicat R. S. Carranza E. J. Nidumolu U. B. (2005). Fuzzy modeling
    of farmers’ knowledge for land suitability classification.Agricultural Systems,
    83, 49–75. Follow Reference Sinwar, D., Dhaka, V. S., Sharma, M. K., & Rani, G.
    (2020). AI-Based Yield Prediction and Smart Irrigation, 155–180. 10.1007/978-981-15-0663-5_8
    Follow Reference Srivastava, A. R., & Venkatesan, M. (2020). Tea leaf disease
    prediction using texture-based image processing. Advances in Intelligent Systems
    and Computing, 1054, 17–25. 10.1007/978-981-15-0135-7_3 Follow Reference Syers
    J. K. (1997). Managing soils for long-term productivity.Philosophical Transactions
    of the Royal Society of London. Series B, Biological Sciences, 352(1356), 1011–1021.
    https://doi.org/10.1098/RSTB.1997.0079 Follow Reference Tajik S. Ayoubi S. Nourbakhsh
    F. (2012). Prediction of soil enzymes activity by digital terrain analysis: Comparing
    artificial neural network and multiple linear regression models.Environmental
    Engineering Science, 29(8), 798–806. https://doi.org/10.1089/EES.2011.0313 Follow
    Reference Tanha Talaviya, Dhara Shah, D. Shah, Nivedita Patel, N. Patel, Hiteshri
    Yagnik, H. Yagnik, & Manan Shah, M. Shah. (2020). Implementation of artificial
    intelligence in agriculture for optimisation of irrigation and application of
    pesticides and herbicides. Artificial intelligence in agriculture, 4, 58-73. doi:
    10.1016/j.aiia.2020.04.002 Tang, L., & Tian, L. ASAE, B. S.-T. of the, & 2000,
    undefined. (2000). Color image segmentation with genetic algorithm for in-field
    weed sensing. Elibrary.Asabe.Org.https://elibrary.asabe.org/abstract.asp?aid=2970
    Follow Reference Tian Y. Yang G. Wang Z. Wang H. Li E. Liang Z. (2019). Apple
    detection during different growth stages in orchards using the improved YOLO-V3
    model.Computers and Electronics in Agriculture, 157, 417–426. https://doi.org/10.1016/J.COMPAG.2019.01.012
    Follow Reference Too E. C. Yujian L. Njuki S. Yingchun L. (2019). A comparative
    study of fine-tuning deep learning models for plant disease identification.Computers
    and Electronics in Agriculture, 161, 272–279. https://doi.org/10.1016/J.COMPAG.2018.03.032
    Follow Reference Tripathi, S., Shukla, S., Attrey, S., Agrawal, A., & Bhadoria,
    V. S. (2020). Smart Industrial Packaging and Sorting System. 245–254. 10.1007/978-981-15-3647-2_18
    Follow Reference Tudi M. Daniel Ruan H. Wang L. Lyu J. Sadler R. Connell D. Phung
    D. T. (2021). Agriculture Development, Pesticide Application and Its Impact on
    the Environment.International Journal of Environmental Research and Public Health,
    18(3). doi:10.3390/ijerph18031112 Follow Reference Valdés-Vela M. Abrisqueta I.
    Conejero W. Vera J. Ruiz-Sánchez M. C. (2015). Soft computing applied to stem
    water potential estimation: A fuzzy rule based approach.Computers and Electronics
    in Agriculture, 115, 150–160. https://doi.org/10.1016/J.COMPAG.2015.05.019 Follow
    Reference van Engelen J. E. Hoos H. H. (2020). A survey on semi-supervised learning.Machine
    Learning, 109(2), 373–440. doi:10.1007/s10994-019-05855-6 Follow Reference van
    Klompenburg T. Kassahun A. Catal C. (2020). Crop yield prediction using machine
    learning: A systematic literature review.Computers and Electronics in Agriculture,
    177, 105709. https://doi.org/10.1016/J.COMPAG.2020.105709 Follow Reference Vellidis
    G. Tucker M. Perry C. Kvien C. Bednarz C. (2008). A real-time wireless smart sensor
    array for scheduling irrigation.Computers and Electronics in Agriculture, 61(1),
    44–50. https://doi.org/10.1016/J.COMPAG.2007.05.009 Follow Reference Waheed R.
    Chang D. Sarwar S. Chen W. (2018). Forest, agriculture, renewable energy, and
    CO2 emission.[doi:https://doi.org/10.1016/j.jclepro.2017.10.287]. Journal of Cleaner
    Production, 172, 4231–4238. Follow Reference Wang, A. X., Tran, C., Desai, N.,
    Lobell, D., & Ermon, S. (2018). Deep transfer learning for crop yield prediction
    with remote sensing data. Proceedings of the 1st ACM SIGCAS Conference on Computing
    and Sustainable Societies, COMPASS. 10.1145/3209811.3212707 Follow Reference Wang,
    Q., Nuske, S., Bergerman, M., & Singh, S. (2013). Automated Crop Yield Estimation
    for Apple Orchards. 745–758. 10.1007/978-3-319-00065-7_50 Follow Reference Wang
    X. P. Wang M. Ruan J. H. Li Y. (2018). Multi-objective optimization for delivering
    perishable products with mixed time windows.Advances in Production Engineering
    & Management, 13(3), 321–332. https://doi.org/10.14743/APEM2018.3.293 Follow Reference
    Whitmire, C. D., Vance, J. M., Rasheed, H. K., Missaoui, A., Rasheed, K. M., &
    Maier, F. W. (2021). Using Machine Learning and Feature Selection for Alfalfa
    Yield Prediction. AI, 2(1), 71–88. 10.3390/AI2010006 Follow Reference Yadav S.
    Sengar N. Singh A. Singh A. Dutta M. K. (2021). Identification of disease using
    deep learning and evaluation of bacteriosis in peach leaf.[doi:https://doi.org/10.1016/j.ecoinf.2021.101247].
    Ecological Informatics, 61, 101247. Follow Reference Yeasin M. Dhandapani A. Ravichandran
    S. (2021). Artificial Intelligence in Agriculture. In SrinivasaraoCh. (Ed.), Agricultural
    Research, Technology and Policy: Innovations and Advances, ICAR-National Academy
    of Agricultural Research Management (NAARM), Hyderabad (pp. 291–306). Follow Reference
    Yost, M. A., Kitchen, N. R., Sudduth, K. A., Sadler, E. J., Drummond, S. T., Volkmann,
    M. R., & Yost MattYost, M. A. (2017). Long-term impact of a precision agriculture
    system on grain crop production. Springer, 18(5), 823–842. 10.1007/s11119-016-9490-5
    Follow Reference You J. Li X. Low M. Lobell D. Ermon S. (2017). Deep Gaussian
    Process for Crop Yield Prediction Based on Remote Sensing Data.Proceedings of
    the AAAI Conference on Artificial Intelligence, 31(1). https://ojs.aaai.org/index.php/AAAI/article/view/11172
    Follow Reference Zhang B. Xie Y. Zhou J. Wang K. Zhang Z. (2020). State-of-the-art
    robotic grippers, grasping and control strategies, as well as their applications
    in agricultural robots: A review.Computers and Electronics in Agriculture, 177,
    105694. https://doi.org/10.1016/J.COMPAG.2020.105694 Follow Reference Zhao Z.
    Chow T. L. Rees H. W. Yang Q. Xing Z. Meng F. R. (2009). Predict soil texture
    distributions using an artificial neural network model.Computers and Electronics
    in Agriculture, 65(1), 36–48. Follow Reference Zhu, H., Chu, B., Zhang, C., Liu,
    F., Jiang, L., & He, Y. (2017). Hyperspectral Imaging for Presymptomatic Detection
    of Tobacco Disease with Successive Projections Algorithm and Machine-learning
    Classifiers. Scientific Reports, 7(1), 1–12. 10.1038/s41598-017-04501-2 Zou, J.,
    Han, Y., & So, S. S. (2008). Overview of artificial neural networks. Artificial
    Neural Networks, 14-22. Request Access You do not own this content. Please login
    to recommend this title to your institution''s librarian or purchase it from the
    IGI Global bookstore. Username or email:   Password:   Log In   Forgot individual
    login password? Create individual account Research Tools Database Search | Help
    | User Guide | Advisory Board User Resources Librarians | Researchers | Authors
    Librarian Tools COUNTER Reports | Persistent URLs | MARC Records | Institution
    Holdings | Institution Settings Librarian Resources Training | Title Lists | Licensing
    and Consortium Information | Promotions Policies Terms and Conditions     Copyright
    © 1988-2024, IGI Global - All Rights Reserved"'
  inline_citation: '>'
  journal: Applying Drone Technologies and Robotics for Agricultural Sustainability
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Edge AI for real-time and intelligent agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Yang Z.Y.
  - Chiu T.C.
  - Sheu J.P.
  citation_count: '0'
  description: Recently, mobile edge computing (MEC) assisted unmanned aerial vehicles
    (UAVs) have brought a revolution to the existing precision agriculture (PA). The
    target UAVs can execute various PA tasks with different heterogeneous resource
    requirements on the farm. However, due to the stringent service deadline of PA
    tasks and the battery limitation of UAVs, one of the promising solutions is to
    offload those computation tasks to MEC servers jointly. This paper explores the
    MEC-assisted task offloading problem with multi-UAVs under different deadline
    constraints in uncertain real-world environments. The diverse requirements of
    PA tasks, the heterogeneous network status, and the dynamic loading of MEC edge
    servers make the offloading decision an NP-hard problem. Therefore, we propose
    a reinforcement learning (RL)-based task offloading approach, BANDIT-SCH, to minimize
    total MEC system costs to achieve online task dispatching and scheduling in uncertain
    environments without further global information. The experiment results show that
    the performance of BANDIT-SCH is approximate to the upper bound strategy, which
    can foresee all edge servers' detailed status.
  doi: 10.1109/GLOBECOM54140.2023.10436856
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >GLOBECOM 2023 - 2023 IEEE Glo... Reinforcement
    Learning-Based Task Offloading of MEC-Assisted UAVs in Precision Agriculture Publisher:
    IEEE Cite This PDF Zih-Yi Yang; Te-Chuan Chiu; Jang-Ping Sheu All Authors 4 Full
    Text Views Abstract Document Sections I. Introduction II. System Model and Problem
    Formulation III. Reinforcement Learning-Based Task Offloading Approach IV. Performance
    Evaluation V. Conclusion Authors Figures References Keywords Metrics Abstract:
    Recently, mobile edge computing (MEC) assisted unmanned aerial vehicles (UAVs)
    have brought a revolution to the existing precision agriculture (PA). The target
    UAVs can execute various PA tasks with different heterogeneous resource requirements
    on the farm. However, due to the stringent service deadline of PA tasks and the
    battery limitation of UAVs, one of the promising solutions is to offload those
    computation tasks to MEC servers jointly. This paper explores the MEC-assisted
    task offloading problem with multi-UAVs under different deadline constraints in
    uncertain real-world environments. The diverse requirements of PA tasks, the heterogeneous
    network status, and the dynamic loading of MEC edge servers make the offloading
    decision an NP-hard problem. Therefore, we propose a reinforcement learning (RL)-based
    task offloading approach, BANDIT-SCH, to minimize total MEC system costs to achieve
    online task dispatching and scheduling in uncertain environments without further
    global information. The experiment results show that the performance of BANDIT-SCH
    is approximate to the upper bound strategy, which can foresee all edge servers''
    detailed status. Published in: GLOBECOM 2023 - 2023 IEEE Global Communications
    Conference Date of Conference: 04-08 December 2023 Date Added to IEEE Xplore:
    26 February 2024 ISBN Information: ISSN Information: DOI: 10.1109/GLOBECOM54140.2023.10436856
    Publisher: IEEE Conference Location: Kuala Lumpur, Malaysia Funding Agency: SECTION
    I. Introduction Recently, severe climate change and global population growth explosively,
    are threatening the production of crops and food dramatically. Precision agriculture
    (PA) is an emerging technology combining the Internet of Things (IoT), remote
    sensing, and automated robotic farming to help farmers improve agricultural production
    intelligently. Unmanned aerial vehicles (UAVs) play a critical role in PA nowadays.
    The sensors on the UAV periodically send information to the 5G back-end for analyzing
    valuable farm output. Similarly, UAVs collect real-time information that provides
    actionable intelligence to farmers. By taking advantage of low deployment cost
    and flexible mobility, UAVs can support different PA applications ranging from
    crop monitoring to spraying [1]. However, most PA tasks are computing-intensive
    and require real-time decision-making [2], which makes UAVs challenging to meet
    all diverse requirements with limited heterogeneous resources and energy budgets.
    Fortunately, mobile edge computing (MEC) is a well-established framework to support
    UAVs and PA clients with instantaneous computational services available at the
    edge network. Since the nearby edge server provides the computation service instead
    of the traditional remote cloud, the offloading latency of the computation task
    and network congestion through the core network can be significantly reduced.
    Many companies have started to deploy MEC systems in the 5G/B5G network to assist
    farmers in achieving PA tasks in the northwestern U.S. and worldwide [3]. There
    exists intensive research that focuses on designing task offloading policy for
    MEC applications [4], [5]. Zhang et al. [6] address offloading tasks with delay
    sensitivities in purely MEC systems. Other related works aim to solve the deadline
    scheduling problem without adopting a UAV plan [7]–[9]. Recently, some literature
    studied the offloading problems with MEC-assisted UAVs [10]–[12], which optimizes
    the flight trajectory or minimizes total energy costs. However, the above researchers
    neglect the diverse deadline requirements of various PA offloading tasks. In our
    work, UAVs need to provide many types of PA services with different resource and
    deadline requirements, especially in uncertain real-world environments. It is
    a novel and challenging task offloading problem compared with existing research.
    Reinforcement Learning (RL) has been regarded as a promising solution for designing
    task-offloading policies [6]. RL-based approaches gain experience through interaction
    with the environment without domain-specific knowledge or require high-complexity
    computation efforts. Also, it is a feasible way to achieve fast adaptation in
    a dynamic and uncertain environment. Previous works [6], [13], [14] advocate deep
    RL (DRL)-based strategies to solve the offloading problem by considering energy,
    migration, security, or in real-world environments. To face the uncertainty caused
    by some stochastic process or unknown information about the environment, it is
    hard to characterize some fragment information to make the offloading decision.
    Besides, the search space and the computing cost for applying the DRL-based technique
    are not practical with resource-limited servers at the edge compared with those
    in the cloud. Therefore, we choose Multi-Armed Bandit (MAB) as one of the RL frameworks
    to provide a feasible solution that embraces the uncertainty over time. Recently,
    [15] formulates the MAB offloading problem in purely edge systems. Furthermore,
    [16] makes the offloading decisions under non-stationary network dynamics. However,
    the above MAB-applied works have not yet considered MEC-assisted UAVs and heterogeneous
    resource allocation, especially in the precision agriculture scenario. In this
    paper, we consider MEC-assisted UAVs to serve various PA tasks with different
    stringent deadlines and resource requirements in uncertain real-world environments.
    We first formulate the optimization problem and show its NP-hard property. The
    objective is to find a task offloading policy to minimize total MEC system costs,
    which means sacrificing less essential data. Then, we proposed a two-stage offloading
    scheme called BANDIT-SCH, including an RL-based Deadline-Aware Bandit Dispatch
    (DABD) algorithm and a Min-Queuing Scheduling (MQ-SCH) algorithm. BANDITSCH enables
    online task dispatching and scheduling even in uncertain real-world environments
    without any predetermined model or domain knowledge. We evaluate our approach
    compared with the state-of-the-art baselines with dynamic loads and stochastic
    task offloading in MEC systems. The experiment results show that the performance
    of the BANDITSCH is approximate to the upper bound baseline, which can foresee
    all edge servers'' detailed status. Fig. 1: Scenario of MEC-assisted multi-UAV
    network in PA. Show All SECTION II. System Model and Problem Formulation A. MEC-Assisted
    UAVs System The system scenario is shown in Fig. 1. We consider a MEC-assisted
    multi-UAV system providing various precision agriculture tasks. Total service
    period T={1,2,…,T} is divided into total T equal time slots. The Base Station
    (BS) set is denoted as M={1,2,…,M} . To provide computing capability closer to
    users, the MEC edge servers (ES), defined as K={1,2,…,K} with computation capacity
    f k , are randomly deployed at the BS. Each ES k maintains a job queue denoted
    as Q k with length | Q k | . The UAVs N={1,2,…,N} are randomly deployed on the
    farm and execute various PA tasks. Specifically, each UAV has a different type
    of PA mission (e.g., crop image analytics and fertilization) with deadlines and
    generates tasks at arbitrary times. The task r t n generated from UAV n at time
    t is characterized by a tuple r t n =( s t n , λ n , ω n ) , where the data size
    represents s t n (bits), λ n is defined as the computation workload (cycles/bit),
    ω n is assigned as the task deadline, respectively. We define a binary variable
    o t n,k ∈{0,1} as an offloading decision indicator. Each UAV n requires the offloading
    task to one of the MEC ESs (i.e., ∑ k∈K o t n,k =1 .) Besides, o t n,k =1 implies
    that the task was generated from UAV n and further processed at ES k . B. Task
    Offloading Model In our scenario, each BS operates on the same frequency band,
    which causes mutual inter-cell interference when multi-UAV sends their data to
    the target BS simultaneously. Therefore, we specify the wireless communication
    parts in Reference Signal Received Power (RSRP) and Signal-to-Interference-plus-Noise
    Ratio (SINR) as follows. Each UAV will select the BS with the most strength-received
    RSRP signal for BS association. We define a binary variable x t n,m ∈{0,1} as
    an association decision indicator of UAV n associated with BS m at time slot t
    . The uplink RSRP of UAV n to BS m at time t is given by: rsr p n,m (t)=P−P L
    n,m (t),∀n∈N, (1) View Source where P denotes the constant transmission power
    of UAVs. P L n,m (t) is obtained by substituting the distance between UAV n and
    BS m and the dedicated band used by the 5G communication spec [17]. According
    to the amount of transmitted data of UAVs serving by the same BS, we assume the
    bandwidth usage of UAV as b n,m (t) . After obtaining the bandwidth usage of UAVs,
    we derive the interference caused by UAVs under adjacent BSs using the same bandwidth
    for transmission. The interference of UAV n is calculated with: I n,m (t)= ∑ m
    ′ ∈M{m} ∑ n ′ ∈N{n} x t n ′ , m ′ rsr p n ′ , m ′ (t)I C n (Φ), ,∀n∈N,∀m∈M,   (2)
    View Source where the function I C n (Φ)=min(Φ,1) indicates the impact on inter-cell
    bandwidth used by UAV n , and the proportion of other UAVs using on the same band
    under neighbor BSs. The Φ= b n ′ m ′ (t) b n,m (t) represents how the bandwidth
    b n ′ , m ′ (t) used by other UAVs in neighboring BSs affects the UAV n bandwidth
    b n,m (t) ratio. Regarding this, we restrict the ratio range to Φ≤1 . According
    to (1) and (2), the SINR of the received signal at the BS m from UAV n is given
    by: sin r n,m (t)= rsr p n,m (t) I n,m (t)+ N 0 B n,m (t) ,∀n∈N. (3) View Source
    where the N 0 refers to the noise spectral density of the normal atmosphere. Therefore,
    the transmission rate of UAV n at time slot t can be obtained as: rat e n,m (t)=
    b n,m (t)lo g 2 (1+sin r n,m (t)),∀n∈N. (4) View Source The uplink data transmission
    delay from UAV n to BS m at time slot t can be calculated as: d trans n,m (t)=
    s t n rat e n,m (t) ,∀n∈N. (5) View Source Note that we assume that the UAV has
    no additional storage equipment. If the amount of uploading data s t n exceeds
    the uplink rate rat e n,m (t) at time t , UAV n will drop these data (i.e., lose
    essential data s t n ). Besides, the computation delay of the task from UAV n
    executed at ES k is given by: d exec n,k (t)= o t n,k ( s t n λ n f k ),∀n∈N.
    (6) View Source C. Task Queuing Model To characterize the processing progress
    of each assigned task in the ES k , we denote the processing time information
    p j n,m,k (t) of the j -th process from UAV n at time t as: p j n,m,k (t)=(τ,
    d trans n,m (τ), d exec n,k (τ), d cpu j,n (t)), ∀n∈N,m∈M, (7) View Source where
    τ represents the initiation time when the UAV n delivers the task, and d cpu j,n
    (t) represents the actual execution time of ES k from initial time τ of request
    to current t . The process will pop out of the Q k when the j -th process has
    been successfully processed. The set of job queue set Q k ={ p 1 n,m,k (t),…,
    p | Q k | n,m,k (t)} , which the execution order of the process in the queue follow
    the ascending power of the index j=1,…,| Q k | . Before the ES executes the process,
    two factors affect the time it starts to be serviced. One is the status of the
    existing queuing tasks in the ES, and the other is the task transfer time from
    the UAV to the ES. We denoted the task arrival time of j -th process which generated
    from UAV n at time τ through BS m transfer to the ES k as: ν τ j =τ+ d trans n,m
    (τ). (8) View Source Before calculating the task waiting time of each process
    j∈ Q k , we need to calculate the remaining processing time R n,k,j (t) of all
    previous processes in ES which are calculated as: R n,k,j (t) = R k,(j−1) (t)+max(
    ν τ j −t,0) +( d exec n,k (τ)− d cpu j,n (t)), (9) View Source where the remaining
    processing time of the 1-th process in the queue is R n,k,1 (t)=max( ν t 1 −t,0)+(
    d exec n,k (τ)− d cpu 1,n (t)) . Therefore, the waiting time of the task is to
    compare the remaining data transfer time ν τ k −t of the current j -process with
    the remaining processing time R n,k,(j−1) (t) of the previous ( j−1 ) -th process.
    We can obtain the waiting time of j -th process from UAV n in the ES k at time
    t as: d wait n,k,j (t)=max(max( ν t j −t, R k,(j−1) (t)),0),∀n∈N. (10) View Source
    The total offloading delay of the task generated from UAV n at time t offloaded
    to ES k is given by: D total n,m,k (t)= d trans n,m (t)+ d wait n,k,j (t)+ d exec
    n,k (t), ∀n∈N,m∈M,k∈K. (11) View Source Note that we assume the response time
    of offloading results back to UAV is relatively short, so we neglect the feedback
    delay in this paper. The lack of data collection will affect the chance of misjudgment
    in PA decision-making. Due to the impact of the random incoming traffic and the
    uncertain status of the heterogeneous servers, the task may be unable to meet
    its deadline requirements. We define missing data of UAV n at time t as the system
    cost, which can be formulated as: Θ t n ( D total n,m,k (t))={ s t n , 0, D total
    n,m,k (t)> w n otherwise . (12) View Source D. Problem Formulation Based on the
    above models, we define the task offloading problem with deadline constraint in
    the heterogeneous MEC system, which is formulated as: min O ∑ t∈T ∑ n∈N ∑ m∈M
    Θ t n ( D total n,m,k (t)) s.t. D total n,m,k (t)≤ w n ,∀n∈N,∀m∈M,∀k∈K, ∑ n∈N
    ∑ j∈ Q k p t k,j,n ≤| Q k |,∀k∈K, ∑ m∈M x t n,m ≤1, x t n,m ∈{0,1},∀n∈N, ∑ k∈K
    o t n,k ≤1, o t n,k ∈{0,1},∀n∈N, S t n ≤rat e n,m (t),∀n∈N,∀m∈M,∀t∈T. (13a) (13b)
    (13c) (13d) (13e) (13f) View Source In (13a), our goal is to finding a task offloading
    policy O={ o t n,k ,∀n∈N,∀m∈M,∀t∈T} to minimize the cumulative offloading cost
    of UAVs subject to (13b)-(13f). The (13b) specifies each PA task should meet the
    service deadline. The (13c) ensures the assigned tasks will not exceed the server''s
    queue length. The (13d) indicates that each UAV can only associate with a single
    BS for task transmission. The (13e) implies that each UAV can be served by only
    one MEC server for task offloading. The (13f) specifies that the task will be
    dropped when the data rate from BS is unsatisfied. Since the optimization variable
    o t n,k ∈O is a binary integer variable, and the other constraints preserve linearity,
    our target problem (13) is formulated as an integer linear programming (ILP) problem.
    SECTION III. Reinforcement Learning-Based Task Offloading Approach To provide
    various PA services in uncertain real-world environments, our focused task offloading
    problem is NP-hard and infeasible to achieve the optimal solution in polynomial
    time. Therefore, we first state the hardness property of our target problem and
    then adopt Reinforcement Learning (RL) strategy to seek a feasible solution. A.
    NP Hardness Theorem 1 Task offloading problem is NP -hard. Proof This problem
    is NP -hard and can be proved by a reduction from generalized assignment problem
    [18]. The proof is omitted due to a lack of space. ■ To deal with challenging
    task offloading problem, we proposed an RL-based approach, BANDIT-SCH, which includes
    a Deadline-Aware Bandit Dispatch (DABD) algorithm and a Min-Queuing Scheduling
    (MQ-SCH) algorithm. At each round, when the agent receives the request from the
    UAV, the DABD algorithm first assigns the task to the target ES k and collects
    the system cost as reward feedback to estimate the future status of the MEC system.
    Then, the target ES k decides the service order of the Q k by MQ-SCH to mitigate
    the waiting period of the queuing tasks. B. Deadline-Aware Bandit Dispatch Policy
    Based on the state-of-the-art bandit algorithm UCB1 [19], we revise it as DABD
    algorithm to solve the stochastic offloading problem and balance the dilemma between
    explore and exploit jointly. The bandit framework comprises two elements, the
    action space A of the arm and the reward function Re(), respectively. We take
    the number of ESs |K| as the available arms of the MAB framework. The action space
    is defined as follows: a∈A={1,2,…,|K|}. (14) View Source Algorithm 1: Deadline-Aware
    Bandit Dispatch (DABD) 1: Initialize: The request dispatch counter c←0, N(a)←0,Q(a)←1,
    ∀a∈A . 2: for t←1 to T do 3: while the MEC system receives r t n at time t do
    4: Calculate the estimated empirical cost of each arms a∈A by (17), and select
    the arm with the highest upper value. 5: Get the reward Re( r t n , a ∗ ) with
    (16). 6: Q( a ∗ )←Q( a ∗ )+ (Re( r t n , a ∗ )−Q( a ∗ )) N(a) 7: N( a ∗ )←N( a
    ∗ )+1 8: c←c+1 9: end while 10: end for Intuitively, DABD leverages the idea of
    concentration in-equality, which provides bounds on how a random variable deviates
    from the expected action-value E[Q(a)] . When the number of decision-making is
    large enough, the empirical mean action-value of the arm, denoted as Q(a) , will
    be close to E[Q(a)] . DABD aims to find a policy to get the maximum empirical
    mean Q(a) . The reward function will guide the decision-making behavior of the
    task dispatch agent. Traditionally, the RL algorithms bound their reward into
    [0, 1] to guarantee convergence in mathematics. Therefore, we need to normalize
    the system cost of the server a given by, Θ ^ N(a) a = Θ t n −( D total n,m,k
    (t)) sup ∀N(a),a Θ ^ N(a) a , (15) View Source where the N(a) is the number of
    time choose server a , and the sup ∀N(a),a Θ ^ N(a) a records the maximum system
    cost value after select server a for N(a) times. We consider reward as the opposite
    of the system cost, given by (15). After selecting server a , the reward can be
    calculated with the following: Re( r t n ,a)= ⎧ ⎩ ⎨ ⎪ ⎪ − Θ ^ N(a) a , −( Θ ^
    N(a) a | Y a | ), | Y a |=0 otherwise . (16) View Source where we define the set
    { r t n ∩ H k | Θ ^ n =0} to record tasks assigned to ES k that meet the deadline
    requirements. The RL agent evaluates the confidence value of each arm and selects
    the highest value as offloading decision a ∗ , given by: a ∗ = argmax a∈A (Q(a)+
    2ln(c) N(a) − − − − − − √ ), (17) View Source where c is dispatch counters and
    N(a) is the number of selection to server a . Once we get the offloading server
    decision a ∗ given by DABD, we can obtain the task offloading indicator as o t
    n, a ∗ . Following the offloading policy o t n, a ∗ ∈O , the learning goal of
    DABD is to minimize the cumulative system cost ∑ c c=0 −(Re( r t n , a ∗ )) ,
    representing data loss. The pseudo codes of DABD are given in Alg 1. The learning
    procedure of DABD starts when receiving the new request r t n . In each decision
    round c , the agent evaluates the confidence value of each arm calculated by (17)
    and chooses the largest one, which has the highest upper confidence value in line
    4. Algorithm 2: Min-Queuing Scheduling (MQ-SCH) Input: The dispatch server a ∗
    , New assigned request r t n , the execution status of target ES Q a ∗ (t) . Output:
    The execution order j ⋆ of request r t n in Q a ∗ 1: Initialize: j ⋆ ←−1, Q a
    ∗ ^ ← Q a ∗ (t), feasible←false,  D wait ←0,  D wait∗ ←0 2: for j in | Q a ∗ ^
    | down to 1 do 3: if j=| Q a ∗ | then 4: Record the total waiting time of the
    queuing tasks at the tail position, D wait∗ ← ∑ j∈ Q a ∗ ^ R n,k,j (t) 5: else
    6: Swap the scheduling position of process from p j n,m,a to p j−1 n,m,a 7: Record
    the total waiting time of the queuing tasks at the new position, D wait ← ∑ j∈
    Q a ∗ R n,k,j (t) 8: end if 9: if All process p j n,m,a ∈ Q a ∗ ^ meet its deadline
    then 10: feasible ← True 11: if D wait∗ ≥ D wait then 12: D wait∗ ← D wait 13:
    j ⋆ ←j 14: end if 15: else 16: break; 17: end if 18: end for 19: if feasible is
    False then 20: Reject the task r t n . ▹ The request not satisfied (13b) 21: else
    22: Q a ∗ ← Q a ∗ ^ ▹ Update to scheduled queue 23: return j ⋆ 24: end if After
    the agent assigns the r t n to ES a ∗ and gets a negative reward, the remaining
    step is to update the average estimate value of the a ∗ and the number of selections
    N( a ∗ ) in lines 6–8. By accumulating task dispatching experience, the agent
    will gradually learn a better offloading policy. C. Min-Queuing Scheduling Mechanism
    After the intelligent agent makes the task offloading assignment, the assigned
    server a ∗ will schedule the execution order in the job queue Q a ∗ to reduce
    the total waiting time without violating the deadline in (13e). The pseudo codes
    of MQ-SCH are given in Alg. 2. The main procedure of MQ-SCH is in three steps.
    First, we push the task in the tail of Q a ∗ ^ and get the initial cumulative
    waiting time D wait of the existing tasks in Q a ∗ ^ in lines 3–5. Second, we
    check whether the order of the new schedule meets the deadline in lines 2–18.
    We repeat the above two steps to check the remaining possible position is feasible
    and make the total D wait less. Last, we confirm whether to reject the task if
    there has no feasible position in Q a ∗ ^ in lines 19–24. The scheduling procedure
    will be interrupted if the swap order of the task does not satisfy the deadline.
    If there is no feasible position for the task in Q a ∗ ^ , the ES a ∗ will reject
    the request r t n accordingly. SECTION IV. Performance Evaluation A. Experiment
    Settings We evaluate the performance of BANDIT-SCH in a MEC-assisted UAVs network
    with various realistic network settings. There are 40 BSs on the farm with an
    area of 1600×700 m 2 . We set the transmission radius of the BS as 350 m and operated
    on the dedicated band with a bandwidth of 100 (MHz). The UAVs perform PA tasks
    by offloading crop images, which requires data size ranging from 1 MB to 3 MB,
    and the workload of processing image recognition is 1900 cycles per bit. The deadline
    ω n for the PA task is [10], [15] slots. The clock speeds f k for each heterogeneous
    server k are set uniformly distributed in [2], [3] (GHz). Besides, we randomly
    deployed total of five servers, in which the number of CPU cores for each server
    is set to be uniformly distributed [6], [10]. Therefore, the computation capacity
    provided by the server is multiplied by the clock speed and number of cores. The
    maximum queue length of each server Q k is uniformly assigned in [3], [8]. Our
    simulations run on Python 3.6.13 with Intel(R) Core(TM) i5-9400 CPU @ 2.90GHz
    processor. We evaluate the uncertain MEC environments in that each server has
    a dynamic load, representing the probability that the server has a random incoming
    task to serve at an arbitrary time. Each simulation results run averaged over
    500 slots and in 20 different episodes. We verify the performance of each offloading
    scheme with two metrics: cumulative system cost and satisfaction rate. The cumulative
    system cost evaluates the service quality of the MEC system. The task offloaded
    from UAVs may be dropped due to insufficient bandwidth allocated by BS. Besides,
    we define the satisfaction rate of the server as the number of tasks that meet
    the deadline divided by the number of tasks successfully received by the server.
    Fig. 2: The impact on the task arrival intensity. Show All Fig. 3: The impact
    on the heterogeneous MEC system. Show All The proposed BANDIT-SCH is compared
    with five candidate algorithms as follows: UPPER, which can foresee all edge servers''
    detailed status and select the ES with the shortest accumulated waiting time for
    queuing tasks. Generally, the queuing status of ES is hard to access, so we take
    the UPPER as the performance upper bound. GREEDY, as a heuristic algorithm, the
    offlading agent assigns the tasks to the ES with the least cumulative system cost.
    UCB1, as a classic MAB algorithm [19], which considers whether the task meets
    the deadline and gives a binary reward. The binary reward in UCB1 will receive
    one if the task meets the deadline constraint, or it will receive 0. BANDIT-EPSILON,
    as one of the MAB algorithms with ϵ probability to explore and ( 1−ϵ ) possibility
    to exploit the arms to get the minimal cumulative system cost. Finally, RANDOM,
    as the performance lower bound, selects one of the ES randomly. B. Impact of the
    Stochastic Offloading and Dynamic Load We evaluate the performance of BANDIT-SCH
    and other baselines in two different PA task request patterns from UAVs and under
    dynamic load in the edge servers. One of the task-generating patterns varies in
    the task arrival intensity of the system and represents the probability that the
    UAV sends a request to the MEC system at each time. The enormous task arrival
    intensity makes the system more stochastic and challenging to support PA services.
    In Fig. 2, we evaluate the impact of task arrival intensity from intensity 10%
    to 80% with a total of five UAVs in the system. Fig. 2(a) presents the cumulative
    system cost, and Fig. 2(b) shows the satisfaction rate, respectively. As expected,
    the proposed BANDIT-SCH scheme can find the proper offloading policy and lose
    less essential data to approximate the UPPER in both performance indexes compared
    to other baselines under different intensities. The custom reward lets BANDIT-SCH
    control well in exploration and exploitation to adapt to the different task arrival
    intensities. In contrast, as shown in Fig. 2(a), the binary reward feedback of
    UCB1 and the exploration-exploitation strategy of BANDIT-EPSILON cannot find a
    good offloading policy in the dynamic network. The lack of exploration of GREEDY
    makes it fall into local optimal, with the worst results eventually. Another task-generating
    pattern is adjusting the number of UAVs in the MEC system. The number of UAVs
    affects the load capacity of the edge server in the long run. Fig. 3(a) and Fig.
    3(b) demonstrate the cumulative system cost and the satisfaction rate under different
    numbers of UAVs, respectively. Here, we set the task intensity of UAVs to 30 %
    at an arbitrary time. Furthermore, compared to the simulation in Fig. 2(a), we
    evaluate the service deadline from 10 to 15 seconds. In fact, we want to evaluate
    the performance under different continuous loads from UAVs with stringent deadlines.
    As the number of UAVs increases, BANDIT-SCH can still outperform other baselines
    and is close to the performance of UPPER. The key point is that the custom reward
    and the one-side confidence let BANDIT-SCH handle the higher continuous loading
    in the system and satisfy requests of UAVs with stringent deadlines. C. The Convergence
    of Learning Offloading Policy To analyze the convergence degree of the MAB-related
    schemes, we combine the two figures of Fig. 2(a) and Fig. 3(a) jointly. Finding
    the policy in the short dispatch rounds is difficult for the bandit-related schemes
    since the agent is still in its initial exploration phase. Unlike other MAB approaches,
    taking (16) as the learning direction, the binary reward of UCB1 cannot adapt
    to insufficient requests and fails in a highly dynamic MEC system. However, the
    BANDIT-SCH scheme can achieve the fast-adaptation and provide feasible solutions
    in these two stochastic offloading patterns. With task intensity increasing, although
    more essential data is inevitably sacrificed in BANDIT-SCH compared with UPPER,
    the cumulative system cost will increase marginally. We''re excited to observe
    that BANDIT-SCH maintains the same satisfaction rate as UPPER in Fig. 2. SECTION
    V. Conclusion This paper investigates the MEC-assisted task offloading problem
    under various deadline constraints with multi-UAVs to minimize total MEC system
    data loss costs. To provide various PA tasks in uncertain real-world environments,
    we proposed an RL-based task offloading mechanism, BANDITSCH, which includes a
    deadline-aware dispatch policy DABD and a minimized scheduling MQ-SCH. The custom
    deadline-aware reward and the one-sided confidence interval let BANDIT-SCH perform
    well in exploration and exploitation to adapt to stochastic offloading and dynamic
    system loading. The experiment results show that the performance of the BANDIT-SCH
    is approximate to the UPPER and can preserve acceptable MEC system cost and satisfaction
    rate in precision agriculture. In future work, we will add UAV-mounted edges to
    assist various task offloading and explore how to design an RL-based strategy
    in such advanced MEC-assisted edge systems for realizing PA services. Authors
    Figures References Keywords Metrics More Like This A Novel Approach to Reduce
    Bandwidth Cost and Balance Network and Server Level Load in Intra Data Center
    Network 2020 IEEE 63rd International Midwest Symposium on Circuits and Systems
    (MWSCAS) Published: 2020 Minimum-Cost Load Balancing Document Distribution in
    Distributed Web Server Systems 2007 IEEE International Symposium on Circuits and
    Systems (ISCAS) Published: 2007 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - IEEE Global Communications Conference, GLOBECOM
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Reinforcement Learning-Based Task Offloading of MEC-Assisted UAVs in Precision
    Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chen P.S.
  - Chang S.C.
  - Chang H.B.
  - Huang W.H.
  - Chueh C.Y.
  - Lee C.C.
  - Chien C.C.
  - Jiang J.A.
  - Wang J.C.
  - Liu A.C.
  - Hsieh M.H.
  - Peng J.C.
  - Guo M.C.
  - Chou C.Y.
  citation_count: '0'
  description: Taiwan, with its small land area, relies heavily on precision agriculture
    to maximize yield per unit area. However, this has led to a high demand for manual
    labor, particularly in harvesting asparagus. In recent years, there has been a
    decrease in the number of available farmers, making the development of automatic
    harvesters increasingly crucial. To address this challenge, this study employs
    deep learning techniques to assist in the identification and harvesting of asparagus
    using a harvester. One of the most challenging aspects for asparagus harvesting
    in Taiwan is distinguishing between the tender, edible spears and the inedible
    asparagus stems. To overcome this, the study uses the object detection model YOLOv5
    (You Only Look Once), which is known for its fast and lightweight nature, to capture
    the two-dimensional coordinates of the asparagus spears on the edge computing
    device. By combining this information with data from an infrared depth camera,
    it is able to obtain the depth information of the asparagus spears, allowing for
    a more accurate identification. The YOLOv5 algorithm boasts an impressive accuracy
    of 91% in identifying asparagus spears and an inference time of 0.3 seconds. Furthermore,
    labeling a single object class for asparagus spears improves recognition by 40%
    in comparison to multiple labels for spears and mother stems. By integrating these
    algorithms, the automatic asparagus harvester is able to quickly and accurately
    determine the coordinates of harvestable asparagus spears, providing farmers with
    a more efficient and effective harvesting method. As a result, labor demands could
    be reduced and yields could be improved.
  doi: 10.13031/aim.202300600
  full_citation: '>'
  full_text: '>

    "Publications Included Search Help About Contact Us Join   If you are not an ASABE
    member or if your employer has not arranged for access to the full-text, Click
    here for options. Deep Learning-Assisted Automatic Asparagus Harvester: Enhancing
    Efficiency and Accuracy in Taiwan''s Precision Agriculture Published by the American
    Society of Agricultural and Biological Engineers, St. Joseph, Michigan www.asabe.org
    Citation:  2023 ASABE Annual International Meeting  2300600.(doi:10.13031/aim.202300600)
    Authors:   Po-Shao Chen, Shan-Cheng Chang, Han-Bin Chang, Wei-Hao Huang, Cheng-Yu
    Chueh, Cheng-Chun Lee, Chia-Chun Chien, Joe-Air Jiang, Jen-Cheng Wang, An-Chi
    Liu, Ming-Hsien Hsieh, Jui-Chu Peng, Ming-Chi Guo, Cheng-Ying Chou Keywords:   asparagus,
    automatic harvester, deep learning, edge computing, object detection Abstract.
    Taiwan, with its small land area, relies heavily on precision agriculture to maximize
    yield per unit area. However, this has led to a high demand for manual labor,
    particularly in harvesting asparagus. In recent years, there has been a decrease
    in the number of available farmers, making the development of automatic harvesters
    increasingly crucial. To address this challenge, this study employs deep learning
    techniques to assist in the identification and harvesting of asparagus using a
    harvester. One of the most challenging aspects for asparagus harvesting in Taiwan
    is distinguishing between the tender, edible spears and the inedible asparagus
    stems. To overcome this, the study uses the object detection model YOLOv5 (You
    Only Look Once), which is known for its fast and lightweight nature, to capture
    the two-dimensional coordinates of the asparagus spears on the edge computing
    device. By combining this information with data from an infrared depth camera,
    it is able to obtain the depth information of the asparagus spears, allowing for
    a more accurate identification. The YOLOv5 algorithm boasts an impressive accuracy
    of 91% in identifying asparagus spears and an inference time of 0.3 seconds. Furthermore,
    labeling a single object class for asparagus spears improves recognition by 40%
    in comparison to multiple labels for spears and mother stems. By integrating these
    algorithms, the automatic asparagus harvester is able to quickly and accurately
    determine the coordinates of harvestable asparagus spears, providing farmers with
    a more efficient and effective harvesting method. As a result, labor demands could
    be reduced and yields could be improved. (Download PDF)    (Export to EndNotes)
    Share Facebook X Email LinkedIn WeChat     Library Home Search Obtaining Full-Text
    E-mail Alert ASABE Home Authors, please use the Guide for Authors when creating
    your articles.  Public Access Information   = Public Access (PA)   = PA Limited
    Time   = Open Access   = Contact Us For Purchase  American Society of Agricultural
    and Biological Engineers 2950 Niles Road, St. Joseph, MI 49085 Phone: +12694290300
    Fax: +12694293852 Copyright © 2024 American Society of Agricultural and Biological
    Engineers"'
  inline_citation: '>'
  journal: 2023 ASABE Annual International Meeting
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Deep Learning-Assisted Automatic Asparagus Harvester: Enhancing Efficiency
    and Accuracy in Taiwan''s Precision Agriculture'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Aguiar S.
  - Barros E.
  citation_count: '0'
  description: Agriculture 4.0, which combines precise sensors, The Internet of Things
    (IoT) and Artificial Intelligence (AI) revolutionize precision agriculture. This
    paper addresses the union of technological solutions from new sensors, AI, IoT,
    and Edge Computing to deliver an innovative solution. The pH is one of the most
    critical parameters of the soil, presenting a diagnosis of the soil. Depending
    on the pH value, plantations can develop or not. In this work, an accurate and
    robust soil pH sensor was developed, as well as a deep learning model for time
    series prediction operating at the edge of the IoT system. The proposed sensor
    showed good performance and a low error percentage compared to commercial sensors
    and pH measurement by traditional laboratory methods. To take advantage of the
    richness of data generated by the pH sensor, a neural network LSTM(long-term memory
    architecture) was implemented for time series prediction. The LSTM model integrated
    into the edge computing system demonstrated accuracy in periodic pH predictions.
    This implementation provides valuable insights for agriculture and smart practices,
    empowering farmers and agronomists to maximize crop productivity.
  doi: 10.1109/SBESC60926.2023.10324263
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 XIII Brazilian Symposium... A Soil
    pH Sensor and a Based on Time-Series Prediction IoT System for Agriculture Publisher:
    IEEE Cite This PDF Saulo Aguiar; Edna Barros All Authors 64 Full Text Views Abstract
    Document Sections I. Introduction II. Related Works III. The Proposed System Architecture
    IV. Development of the pH Sensor V. The Proposed IoT System for Agriculture Show
    Full Outline Authors Figures References Keywords Metrics Abstract: Agriculture
    4.0, which combines precise sensors, The Internet of Things (IoT) and Artificial
    Intelligence (AI) revolutionize precision agriculture. This paper addresses the
    union of technological solutions from new sensors, AI, IoT, and Edge Computing
    to deliver an innovative solution. The pH is one of the most critical parameters
    of the soil, presenting a diagnosis of the soil. Depending on the pH value, plantations
    can develop or not. In this work, an accurate and robust soil pH sensor was developed,
    as well as a deep learning model for time series prediction operating at the edge
    of the IoT system. The proposed sensor showed good performance and a low error
    percentage compared to commercial sensors and pH measurement by traditional laboratory
    methods. To take advantage of the richness of data generated by the pH sensor,
    a neural network LSTM(long-term memory architecture) was implemented for time
    series prediction. The LSTM model integrated into the edge computing system demonstrated
    accuracy in periodic pH predictions. This implementation provides valuable insights
    for agriculture and smart practices, empowering farmers and agronomists to maximize
    crop productivity. Published in: 2023 XIII Brazilian Symposium on Computing Systems
    Engineering (SBESC) Date of Conference: 21-24 November 2023 Date Added to IEEE
    Xplore: 24 November 2023 ISBN Information: ISSN Information: DOI: 10.1109/SBESC60926.2023.10324263
    Publisher: IEEE Conference Location: Porto Alegre, Brazil SECTION I. Introduction
    With the world’s population projected to increase by 2.3 billion people by 2050,
    the demand for food is increasing, requiring more productive agriculture to ensure
    global food security. In this context, the IoT emerges as an essential tool to
    optimize agricultural production, offering more efficient management of agricultural
    elements, processes, and systems, resulting in increased productivity and better
    use of natural resources [1] . Among the critical aspects for the success of agriculture
    is the accurate monitoring of soil conditions, highlighting the importance of
    soil pH sensors. The pH level is a critical indicator that directly influences
    crop development, affecting nutrient availability and the overall health of the
    agricultural ecosystem. The knowledge of soil pH variations over time is vital
    for decision-making on the corrections and adjustments needed to ensure proper
    plant growth [2] . However, accurate environmental data collection has been a
    barrier, especially in remote and hostile areas. The European air quality agency
    highlights the need for highly accurate sensors and computing solutions to ensure
    data accuracy. In this regard, integrating new soil pH sensors with emerging IoT
    technologies and edge computing is promising. Edge computing is promising to overcome
    these limitations by providing real-time data and prediction of soil health over
    time series with greater reliability. [3] . In addition, the application of Artificial
    Intelligence (AI) techniques, particularly Deep Learning methods and Artificial
    Neural Networks (ANN), represents a significant advance in the analysis and prediction
    of time series, including soil pH behavior [4] . These models can capture nonlinear
    complexities and dynamic patterns, enabling more accurate and robust predictions
    crucial for decision-making and strategies in the agricultural sector. The main
    objective of this work was to develop a new pH sensor for soil based on IoT and
    integrate it into an IoT system, taking advantage of the pH data from the developed
    sensor. Furthermore, we sought to implement time series forecasting techniques
    applied to agriculture within this system, aiming to improve agricultural management
    through accurate monitoring and prediction of soil conditions. SECTION II. Related
    Works A. Electronic pH Sensors In the first study performed by [5] , silver solution
    (AgCl) was used as the reference electrode, and antimony oxide (Sb2O3) as the
    measuring electrode. The sensor was used to measure the pH of patients’ saliva.
    Another study in [6] also corroborated the potential of the antimony oxide electrode
    (Sb2O3) in measuring pH, especially in tumor cells. Subsequently, the second step
    focused on comparing soil-specific electronic pH sensors. In the study [7] , the
    authors used antimony of very high purity (99.73%) and tested several combinations
    of electrodes, such as Sb/Sb, Sb/AgCl, and AgCl/Sb, obtaining excellent results.
    B. IoT Systems for Agriculture The work described in [8] developed a system using
    the Long Range (LoRa) communication protocol and the Raspberry Pi hardware for
    data processing and prediction. LoRa technology is especially suitable for agriculture,
    offering range, low power consumption, and penetration capacity in rural areas.
    Other studies, such as [9] and [10] , have adopted similar designs, using LoRa
    or LoRaWAN to communicate between devices and gateways. For implementing the concepts
    of Edge Computing, this work is based on the architecture proposed by [11] , dividing
    the system’s architecture into subsystems, with local and secure processing of
    the collected data. The work described in [12] also is based on a similar architecture
    but with deep learning processing performed at the edge computing layer. C. Deep
    Learning for Time Series Prediction in IoT Systems When choosing the deep learning
    architecture to implement time series prediction in the IoT system, we observed
    the work described in [13] , which compared several deep learning architectures
    for time series prediction and showed that LSTMs and Convolutional Neural Networks
    (CNN) obtained more accurate prediction. The basis for constructing the IoT system
    for predicting time series in edge computing using deep learning was the work
    described in [8] , which adopted recurrent neural networks with LSTM architecture
    to predict temperatures. Other studies, such as [14] and [15] , have also addressed
    the use of LSTMs in edge computing for pollutant prediction and resource use prediction,
    respectively, showing the effectiveness of these architectures in devices of reduced
    computational capacity. SECTION III. The Proposed System Architecture The proposed
    system’s architecture is shown in Figure 1 , divided into distinct subsystems
    called layers or modules. The first is the energy module, composed of a photovoltaic
    panel and rechargeable battery, which powers the next module, the sensor subsystem.
    This layer includes the proposed pH sensor, a soil moisture sensor, a temperature
    sensor, and the ESP32 microcontroller for sensor reading and preprocessing. The
    communication module transmits sensor data via LoRa (Long Range) Communication
    to the next layer, the Edge Node. This layer sends sensor data received via LoRa
    communication to local storage and preprocessing. This module is implemented on
    a Raspberry Pi platform. This module also sends the data to cloud storage, thus
    acting as a local server and gateway. In the Edge Node, training and prediction
    of the pH value time series occur. As mentioned, the data is sent to the Firebase
    platform in the cloud. Finally, the user can view the information in a web interface.
    Fig. 1 Proposed IoT System Architecture Show All SECTION IV. Development of the
    pH Sensor The pH electrode sensor with high purity was developed using unique
    materials, such as Zinc and Antimony. Antimony powder underwent a physicochemical
    transformation to the solid phase, melted in an oven, and cooled naturally. The
    result was the manufacture of two antimony electrodes, robust and resistant, ideal
    for use on the ground. An X-ray Spectroscopy analysis was performed to guarantee
    the purity of the electrodes, resulting in both of them having a concentration
    above 99% During the development of the integrated pH sensor, a circuit was designed
    to acquire and condition electrical signals. A printed circuit board (PCB) was
    developed to reduce noise and facilitate maintenance, improving the robustness
    of the sensor for use on the ground. The sensor module, shown in Figure 2 , also
    includes soil moisture and temperature sensors, as these parameters directly influence
    the measured pH values. The embedded software for reading the sensors and LORA
    communication was implemented in an ESP32 microcontroller. This platform has a
    low power consumption mode (deep sleep) and can be connected via the capacitive
    power button. Fig. 2 Sensor Module Show All After analyzing the signal, it was
    necessary to add a smooth filter to attenuate the noise. In figure 3 it is shown
    in red before applying the filter and in blue after application. The use case
    diagram of the pH sensor can be seen in Figure 4 . After pressing the on/off button,
    the sensors are read, and the display shows temperature, moisture, and pH values
    on the display. If the user turns off the microcontroller through the touch button,
    the system goes into deep sleep mode. The proposed pH sensor has been calibrated
    using the Embrapa method [16] . This method involves using soil samples at different
    representative points of the area of interest, followed by the preparation of
    suspensions and measurement of the pH of the liquid phase. A total of 88 soil
    samples with different pH values were used for calibration, with values ranging
    from 4 to 10.8. The graph in Figure 5 shows the relationship between the pH values
    measured by the Embrapa method in the laboratory and the DDP (Potential Difference)
    values measured by the proposed sensor. Fig. 3 Applying Filter To Smooth Signal
    Show All Fig. 4 Use Case Diagram Show All The regression model results show an
    R2 coefficient of approximately 0.896, indicating that the independent variables
    explain about 89.6% of the variability of the dependent variable. The Mean Quadratic
    Error (MSE) was approximately 0.263, the Mean Absolute Error (MAE) was about 0.422,
    and the Maximum Error was 1.413. In addition, the Mean Absolute Percentage Error
    (MAPE) was 6.70%, indicating that, on average, as predicted by the model, it had
    a discrepancy of about 6.70% concerning the valid values. SECTION V. The Proposed
    IoT System for Agriculture The proposed system ( figure 6 ) consists of several
    interconnected modules. Initially, the sensor module collects pH, temperature,
    and ground temperature data and uses the LoRa protocol to transmit this information
    to a receiving device equipped with LoRa technology. The receiving device is connected
    to the Edge Node, which plays a crucial role in the architecture. The Edge Node,
    implemented in a Raspberry Pi platform, encompasses an on-premises SQLite database
    and a Flask server and also functions as a gateway. This combination allows storing
    and managing the collected data and provides processing and analysis functionalities.
    The Edge Node performs additional tasks, including communicating with an external
    server. It also executes the LSTM model and infers the predictions of the time
    series. Integrating the cloud module, which uses the Firebase database, contributes
    to adequately storing the data collected by the Edge Node. This data includes
    current pH, date, humidity, temperature, day of the week, and daily and weekly
    pH forecast. Fig. 5 pH Sensor Calibration Correlation Plot. Show All Fig. 6 IoT
    System Scheme for Agriculture. Show All SECTION VI. Time Series Prediction The
    pH data collected by the sensors are treated as time series, and to make a prediction
    of future values based on history, we chose to employ Deep Learning models. Specifically,
    the model chosen was Recurrent Neural Networks (RNN) due to its ability to capture
    long-term dependencies in temporal sequences. The Raspberry Pi platform is an
    edge computing device, allowing data processing to be carried out locally, close
    to the collection point. This feature offers extended benefits such as reduced
    latency and less dependence on an ongoing cloud connection. The LSTM model runs
    on Raspberry Pi after preprocessing and normalizing data from IoT sensors. Training
    and predictions are done periodically, while data collection occurs continuously.
    The framework chosen for implementing the Deep Learning model was Keras, a high-level
    library for building and training neural networks. Keras, which uses TensorFlow
    as the backend, makes it possible to create deep neural network architectures
    modularly and offers essential features such as callbacks for training control.
    The system uses an LSTM model to perform complete sequence predictions in a time
    series of pH data collected by IoT sensors. The goal is to learn patterns in the
    data over time and make accurate predictions based on history. The LSTM model
    is chosen for its ability to handle sequential data and capture long-term dependencies
    on sequences. The system loads model configurations from the config.json file
    for periodic predictions, which contains crucial information about the neural
    network architecture and training data. The LSTM model is then trained with the
    prepared training data by adjusting the model weights to minimize the loss function.
    For validation purposes, the model training is performed every 1 hour. After training,
    the system performs periodic predictions every 6 hours, using the LSTM model to
    predict complete sequences of pH values. The forecasts and weekly are stored in
    an SQLite database, along with the current day of the week and the forecast data.
    Forecasting is crucial to this system as it offers significant benefits in continuous
    monitoring, problem prevention, and informed decision-making. It allows monitoring
    pH conditions continuously, avoiding unwanted deviations, such as abrupt drops
    in pH that can cause damage. Additionally, edge prediction has critical advantages
    such as lower latency, greater data privacy and security, the ability to operate
    in environments with intermittent network connectivity, and reduced network load.
    SECTION VII. Results A. pH Sensor Linear Regression Model Validation The DDP measured
    by the proposed sensor and correlated to values measured by the Embrapa Method
    was used in measuring soil pH. A model was generated through linear regression,
    resulting in the fifth equation: Y=17.16798413713084-0.01535258x. Therefore, it
    was necessary to validate and evaluate how well the model fits the observed data,
    verifying that its estimation is close to the actual values. In addition, the
    validation of the linear regression model allows us to verify whether the fundamental
    assumptions of the model are being met, such as the linearity of the relationship
    between the dependent and independent variables. The validation of the linear
    regression model was conducted to evaluate the orientation and accuracy of the
    estimation. The main statistical results indicate: Residue Analysis: The residues
    showed a non-random pattern, suggesting the need for adjustments in the model.
    Residue Normality Test (Shapiro-Wilk): The p-value obtained was 0.308, indicating
    that there is insufficient evidence to reject the null hypothesis of residue normality.
    Analysis of Homoscedasticity (Breusch-Pagan): The p-value of the test was 0.311,
    showing that there is no evidence of heteroscedasticity in the residuals, that
    is, the variance of the errors is constant at all levels of the independents.
    Outliers Identification: Some residues were considered potential outliers based
    on p-values but were insufficient to be considered outliers. Durbin-Watson Autocorrelation
    Test: The test value was approximately 1.94, indicating a low presence of autocorrelation
    in the residuals, which is positive for model validation. The validation results
    suggest that the linear regression model fits the data reasonably well, meeting
    key assumptions and providing expected results for predicting future outcomes.
    The absence of autocorrelation and homoscedasticity in the residuals reinforces
    the reliability of the inferences and estimates of the model. The residuals resulted
    in a non-random pattern, which indicates the need for adjustments to improve the
    accuracy of the projections. TABLE I Statistical Results Values B. pH Sensor Validation
    The validation of the pH sensor proposed in this paper was conducted through statistical
    analysis and comparison with different sensors and measurement methods, a critical
    and essential step to ensure the reliability and accuracy of the measurements
    made by the proposed device. The statistical validation allowed us to evaluate
    the accuracy and consistency of the readings obtained by the sensor in different
    conditions and samples, in addition to determining the uncertainty of the measurements,
    contributing to the confidence in the results received. The study aimed to validate
    the sensor developed for soil pH measurement, using 40 samples from different
    soils with varying pH values. The measurements were performed simultaneously with
    the soil pH sensor developed in this paper, the Embrapa soil pH measurement method,
    and a commercial pH sensor called AK95. The samples were collected representatively,
    covering different soil types and wide pH variations. A statistical analysis was
    conducted to compare the results provided by the soil pH sensor developed with
    the Embrapa methods and the commercial sensor (Akso AK95). The comparative analysis
    between the methods used several statistical metrics: TABLE II Comparison of Metrics
    The low values of MSE, MAE, and MAPE indicated the sensor’s good accuracy values
    compared to the reference methods. The coefficient of determination close to 1
    confirmed that the sensor model explains the variation in pH values. Figures 7
    and 8 show the pH values measured in the developed sensor compared to the Embrapa
    method and a commercial sensor. In summary, statistical validation demonstrated
    that the developed pH sensor presents reliable and close results when compared
    to reference methods. Comparative analysis provided a solid basis for using the
    sensor in future pH measurements measurements under different experimental conditions,
    contributing to practical applications in various areas. Fig. 7 Comparison of
    pH Values (Embrapa Method)x pH Values Commercial Sensor Show All Fig. 8 Comparison
    of pH Values (Embrapa Method)x pH Values Sensor Developed Show All C. Analysis
    of Time Series Forecasts An analysis of the predictions allows us to verify the
    performance of the LSTM model developed and confirm the model’s reliability for
    the application in different scenarios. The LSTM model predicts the pH value for
    the current day and the next six subsequent days. The daily comparison approach
    was adopted to assess the accuracy of their prediction. In this approach, each
    daily prediction performed by the model was detected with the actual value of
    the corresponding pH for the same day. This evaluation strategy allowed us to
    verify how well the model adapts to pH fluctuations and identify hit-and-miss
    patterns over time. For this validation, different pH values were measured to
    test the effectiveness of the predictions with these changes. Figure 9 presents
    a graph that compares the actual pH values measured over time with the model’s
    daily pH forecast (pHpred). The blue and orange lines represent the actual and
    predicted pH values as a function of time on the day. This visualization enables
    a quick and precise analysis of the model’s performance against the actual data,
    identifying patterns and discrepancies between the predictions and the observed
    values. Fig. 9 Comparison of Real and Predicted values of pH Time Series. Show
    All The results of the error metrics demonstrate a positive validation of the
    predictions of the pHpred time series (pH predictions) concerning the actual pH.
    The MSE of 0.0572 shows that the model’s predictions are very close to the actual
    pH values, revealing that the model can accurately capture the fluctuations and
    trends in the pH data over time. The RMSE, with a value of 0.2392, also reflects
    the high accuracy of the predictions, indicating a low distribution between the
    predictions and the actual values, confirming the proximity of the predictions
    to the observed data. In addition, the EAC with a value of 0.1797 confirms the
    model’s ability to make future predictions of actual pH values, with an absolute
    mean difference between the predictions and the actual data. The MAPE of only
    2.7858% is remarkable, indicating that the predictions have an average error of
    only 2.79% relative to the actual pH values. This feature means that the model
    is getting it right in predicting pH accurately in most cases. The R2 is equal
    to 0.98143, which indicates that the model explains approximately 98.14% of the
    output data (pH) variability, demonstrating that the model is capturing the vast
    majority of those present in the data and presenting a perfect fit. A confidence
    interval of 95% provides an additional and essential assessment of pH time series
    prediction. This feature means there is a 95% probability that the actual pH value
    is within the given range. The lower and upper bounds of the range are approximately
    6.28 and 6.41, respectively, suggesting that the model is providing consistent
    provisions with high reliability relative to the actual data. Theil’s Index (Theil’s
    U) is necessary for analyzing time series predictions. The Theil Index is an error
    metric that compares the dispersion of prediction errors with the dispersion of
    the data itself, allowing an evaluation of the model’s overall quality concerning
    the variability of the actual values. The presented result of approximately 0.0180
    indicates that the prediction errors are minor concerning the dispersion of the
    actual pH data itself, which suggests that the model is following the accurate
    prediction and trend of the observed data. TABLE III Result of Statistical Metrics
    of pH Time Series Predictions In summary, statistical statistics show that the
    LSTM model performs well when predicting pH values, with predictions close to
    real values and high reliability. D. Dashboard The figure 10 shows the dashboard
    of the IoT system developed, and it is a web application that shows the real-time
    values of Humidity, Soil temperature, current date, current pH values, and pH
    forecasts for the following days of the week. In addition, there is a line plot
    comparing the pH forecasts for the next few days with the actual pH values. The
    user-friendly and intuitive layout provides a pleasant and accessible user experience.
    Fig. 10 IoT System Dashboard. Show All SECTION VIII. Conclusion This work presents
    the design and development of a soil pH sensor integrated with an IoT system for
    agriculture, focusing on time series prediction in edge computing. The soil pH
    sensor showed excellent performance, with robust results. The IoT system was implemented
    with adaptability for agriculture. The LSTM model applied to edge computing had
    excellent results, presenting high accuracy in predictions. The integration of
    these technologies has resulted in an effective solution for precision agriculture.
    Authors Figures References Keywords Metrics More Like This “Why Should I Trust
    Your IDS?”: An Explainable Deep Learning Framework for Intrusion Detection Systems
    in Internet of Things Networks IEEE Open Journal of the Communications Society
    Published: 2022 A DDoS attack detection based on deep learning in software-defined
    Internet of things 2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)
    Published: 2020 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Brazilian Symposium on Computing System Engineering, SBESC
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Soil pH Sensor and a Based on Time-Series Prediction IoT System for Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rathi M.
  - Gomathy C.
  citation_count: '0'
  description: Agriculture has a significant role in society by providing food and
    acting as the foundation of many developing countries' economies. With an estimated
    9.75 billion people on the planet by 2050, food production must rise to meet the
    growing demand. It is getting harder to increase food production since there is
    a lack of fertile land. To solve this issue, increase output per unit area, and
    achieve the desired outcome, precision agriculture technologies are being used.
    The Internet of Things (IoT), artificial intelligence (AI), and machine learning
    are among the smart technologies that are being adopted by an increasing number
    of industries, including agriculture. Automated irrigation systems can be advantageous
    for farmers who practice precision agriculture, who can also gain valuable knowledge
    about their crops and lessen their environmental impact. With the help of these
    technological advancements, farmers can now more easily manage farming processes.
    This article summarizes the types of sensors needed for agriculture, the communication
    technologies used, and various aspects of smart farming. The roles of Artificial
    intelligence, 5G, and Blockchain in smart farming are discussed.
  doi: 10.1109/ICOSEC58147.2023.10275835
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 4th International Confer... Revolutionizing
    Agriculture with IoT –A Review Publisher: IEEE Cite This PDF Rathi M; C. Gomathy
    All Authors 89 Full Text Views Abstract Document Sections I. Introduction II.
    Applications of Iot in Smart Farming and Related Works III. Architecture of Iot-Based
    Smart Farming IV. Role of Machine Learning and Deep Learning in Agriculture V.
    Role of Blockchain in Smart Agriculture Show Full Outline Authors Figures References
    Keywords Metrics Abstract: Agriculture has a significant role in society by providing
    food and acting as the foundation of many developing countries'' economies. With
    an estimated 9.75 billion people on the planet by 2050, food production must rise
    to meet the growing demand. It is getting harder to increase food production since
    there is a lack of fertile land. To solve this issue, increase output per unit
    area, and achieve the desired outcome, precision agriculture technologies are
    being used. The Internet of Things (IoT), artificial intelligence (AI), and machine
    learning are among the smart technologies that are being adopted by an increasing
    number of industries, including agriculture. Automated irrigation systems can
    be advantageous for farmers who practice precision agriculture, who can also gain
    valuable knowledge about their crops and lessen their environmental impact. With
    the help of these technological advancements, farmers can now more easily manage
    farming processes. This article summarizes the types of sensors needed for agriculture,
    the communication technologies used, and various aspects of smart farming. The
    roles of Artificial intelligence, 5G, and Blockchain in smart farming are discussed.
    Published in: 2023 4th International Conference on Smart Electronics and Communication
    (ICOSEC) Date of Conference: 20-22 September 2023 Date Added to IEEE Xplore: 16
    October 2023 ISBN Information: DOI: 10.1109/ICOSEC58147.2023.10275835 Publisher:
    IEEE Conference Location: Trichy, India SECTION I. Introduction According to a
    recent statement by the UNESCO World Water Assessment Program (WWAP), the world''s
    population will increase by 33% in 2050, increasing the demand for food and water.
    The globe as a whole and the developing nations in particular will suffer greatly
    from this. As a result, nations are attempting to improve agriculture''s sustainability
    by using various technologies. Smart farming is the use of contem-porary information
    and communication technologies (ICT) in agriculture to increase crop yield and
    financial rewards while also aiming to have a smaller environmental impact. Fig.
    1 explains how traditional farming has been transformed into smart farming. Historically,
    humans have been cultivating to obtain the food they require for survival. Agriculture
    is the name of the activity, which evolved over a considerable period of time
    from agriculture 1.0 to 4.0. Farmers used sickles and pitchforks in the seventeenth
    century, a period known as “Agri-culture 1.0,” to cultivate their land. Such farming
    techniques require a lot of manpower to carry out agricultural tasks. The crops,
    however, produced very little. Then, in the 20th century, agriculture 2.0 emerged,
    building on the accomplishments of the previous generation to increase production.
    To cut labor expenses and boost output, this generation introduced a variety of
    agricultural instruments and machines for all agriculturerelated activities. As
    a result, new technologies for agriculture 2.0 are created. The food supply chain
    has also benefited from recent advancements in the transportation industry, enabling
    the long-distance transit of agricultural consignments. Communication technology,
    software engineering, and Robots are examples of third-generation agricultural
    advancements that have improved the operation of modern machinery. The aforementioned
    technologies helped create Agriculture 3.0, a new age of farming. In summary,
    the three agricultural revolutions led to a huge increase in crop productivity.
    Additionally, laborintensive traditional farming methods gave way to the use of
    contemporary practices in agriculture. In terms of efficiency and productivity,
    current developments in agricultural industrialization have begun to rule the
    market globally. However, a number of issues, including digitization, issues in
    the supply chain, ecological issues, and crop yield, need to be addressed in the
    current context of smart farming. In the current environment, integrating modern
    technologies is necessary to increase agricultural activity. In an effort to address
    the shortcomings of the previous generation, agriculture 4.0 has recently been
    presented. Appliances, devices, sensors and actuators called things now connected
    to a network, which is known as the Internet of Things (IoT) [1]–[3]. They can
    be used in conjunction with one another to complete challenging tasks that need
    high intelligence. IoT implementation is thought to be the best option because
    agriculture requires constant monitoring and control. The major components of
    IoT are devices, software, sensor systems, actuators, and connections. They may
    now be deployed in enormous numbers throughout vast indoor and outdoor agricultural
    fields because of the accessibility of affordable, portable, power-efficient technology
    with wireless communication. To evaluate soil conditions, tough hardware modules
    may be buried underground. Other modules may be able to survive adverse weather
    conditions, including sunlight, rain, and high humidity. Graphical Processing
    Units (GPUs), another type of specialized hardware, can process enormous volumes
    of data gathered by these. On the software side, current technologies like big
    data and AI use this data gathered by the sensors as input to the AI-based predictors
    that may provide farmers with new insights. The advantages of this technological
    revolution include increased crop yield, water saving, and reduced use of fertilizers.
    In numerous industries, including healthcare, smart homes, smart cities, logistics,
    agriculture, smart grid, and autonomous vehicles [4]–[10]. Fig. 1. Technological
    changes in Agriculture Industry Show All SECTION II. Applications of Iot in Smart
    Farming and Related Works In smart farming, IoT makes its major contribution at
    each stage of agriculture, from seed selection to supply chain management. Crop
    management, Irrigation scheduling, livestock, and greenhouses are the main ways
    IoT is used in agriculture. Agricultural land and livestock, which are connected
    to the cloud, are monitored with the help of different WSN-based IoT sensors and
    devices, which support farmers in collecting useful data from agriculture fields
    through sensors. Some IoT- based setups use cloud services to analyze and process
    data from far away or at the network edge. This helps researchers and farmers
    make better decisions. A plan is made for IoT management that keeps an eye on
    things like weather, soil, air, and water. The environment is also monitored by
    IoT, which generates detailed analyses of temperature, hazardous radiation levels,
    noise levels, and air and water contamination. Additionally, information obtained
    regarding various environmental characteristics is communicated to the user via
    warnings or messages with recommendations to the authorities. Smart irrigation
    systems include data acquisition (sensor), data processing, fault detection, wireless
    communication, and irrigation control. Smart farming is a way to grow food in
    a clean and sustainable way that requires a lot of money and high-tech tools.
    We are talking about a system that uses sensors to keep an eye on the crop field.
    These sensors keep track of everything that is important for growing crops, such
    as the soil''s moisture, humidity, light, temperature, and so on. They also automate
    the irrigation system. With this system, farmers can check on their fields from
    anywhere. IoT -based farming is a lot more effective than traditional farming.
    So, it''s important to gather, summarize, analyze, and sort the latest research
    in this area. A vast number of IoT applications for agriculture have been released
    in recent years. We categorize these applications into groups based on their functions
    in accordance with survey results, including monitoring, tracking, and traceability;
    controlling; and modern agriculture such as soilless agriculture and greenhouse
    production. The system measures a number of different parameters, including air
    quality, temperature, humidity, soil, water, fertilizer, insect management, light
    control, and location tracking Fig. 2. Applications of IoT in various Industries
    Show All Fig. 3. Different stages of Smart Farming Show All A. Soil Condition
    Management Effective monitoring systems are essential for creating an irrigation
    control system that can boost production in smart agriculture since they have
    an impact on how plants grow and develop. The climate has a considerable impact
    on crop production. Variable crops need different climate conditions to grow;
    hence, any change in climate has a major negative impact on crop yield in terms
    of both quantity and quality. The main factors needed for the growth of the plant
    are considered to be soil moisture and a proper amount of water. To maintain an
    ideal watering schedule, effective soil moisture monitoring may be regarded as
    essential. These factors also enhance the control of crop-growing conditions.
    In [11]–[14], authors proposed various soil monitoring systems for smart farming.
    B. Irrigation Scheduling and Water Management The method by which an irrigator
    chooses the amount and timing of water to be applied to the crop is known as irrigation
    scheduling. Estimating the water needs of crops for various growth stages and
    environmental conditions is difficult. Fig. 4. Application domains of IoT in smart
    agriculture Show All Knowing how much water the plant can consume and how efficiently
    it can use it will help you avoid overwatering or underwatering. This can be measured
    using a variety of techniques, such as plant observation, soil feel and look,
    soil moisture monitoring equipment, and available water from weather information
    [15]–[17]. Field-deployed sensors are used in IoT-powered smart irrigation systems
    to track soil characteristics, weather and climatic conditions, and agricultural
    parameters for irrigation. To track various soil, water body, plant, and microclimate
    parameters, it employs distributed sensors. The values observed by these sensors
    can be communicated to farmers through the cloud, and they can activate the water
    outlets from anywhere at any time. C. Live Stock Management It enables farmers
    to monitor the condition of animals in their herd from their location and receive
    warnings if anything deviates from the required range. This information helps
    the farmers identify the affected livestock without personally examining the This
    also helps to identify which livestock is affected and which is not, saving them
    from having to personally examine the vital signs of each individual animal to
    determine whether a sickness has spread. The whereabouts, health, and well-being
    of the cattle are tracked by owners of huge farms using wireless IoT applications.
    As owners can find their cattle with the use of IoT-based sensors, it is also
    helpful for reducing labor costs. For example, an IoT-based monitoring system
    for large-scale pig farms, measurement of temperature without contact, and surveillance
    of animals to ensure disease detection and animal health were proposed by authors
    in [18]–[22]. They also provided recommendations for farmers in rural areas regarding
    animal health. D. Agricultural Drones Technology has improved significantly and
    more quickly during the past few years. The use of drones in farming is a great
    example of this progression. Drones are being employed in the agriculture sector
    to advance many farming practices. The several types of UAVs used in precision
    agriculture are listed by the authors in [23]–[25] and offer solutions for evaluating
    the health of animals, crop monitoring, pesticide application, irrigation, planting,
    and soil monitoring. With technological revolutions and proper planning based
    on real-time data collection, drone technology has the potential to change the
    agriculture economy. The information gathered by drones can help farmers better
    understand plant health, plant count, yield forecasting, plant height, drainage
    mapping, weed pressure mapping, and other topics Fig. 5. Applications of IoT in
    Smart Agriculture Show All Fig. 6. Applications of UAV in smart Agriculture Show
    All E. Smart Greenhouses Smart green houses will help farmers improve the quality
    and productivity of agriculture. By using a proportional control system or manual
    intervention, greenhouses keep an eye on and regulate the environmental conditions.
    IoT can be used to build a smart greenhouse, which is a better option than a smart
    home controlled manually. These clever greenhouses can monitor and manage the
    climate without any kind of operator assistance [26]. Sensors deployed on agricultural
    land are used to monitor various factors, including humidity, pH, temperature,
    CO2, electrical conductivity, and pesticides needed, which helps with early fault
    detection and diagnosis. A decision support system (DSS) serves as the overall
    controlling and coordinating mechanism for all actions [27]–[28]. Remote access
    is created by connecting the system to the cloud via IoT. This reduces the requirement
    for ongoing manual supervision. The greenhouse''s internal control action is implemented
    by the cloud server, which also manages data processing. F. Smart Agri-Supply
    Chain Management The goal of the food supply system is to create a smart delivery
    model that will allow crops to be delivered from the farm to the table. Scalability,
    a high level of system dependability, and data correctness are not ensured in
    current food traceability solutions. In addition, traceability procedures in modern
    supply chain networks are laborious and complex. Block chain technology promises
    to develop a new ontology for supply chain traceability in order to reduce these
    worries. In [29], authors have proposed a block chain-IoT-based food traceability
    system (BIFTS) to include the unique deployment of block chain, IoT technology,
    and fuzzy logic into a total traceability shelf life management system for controlling
    perishable food. All transactions are recorded on a block chain, which then uploads
    the data to the Interplanetary File Storage Approach according to the trustworthy
    system outlined in [30]. This system ensures traceability, trust, and delivery
    mechanisms in the agri-food supply chain. G. Crop Disease and Pest Detection Crop
    yield is directly affected by pest and plant disease activity. Pests frequently
    cause bacterial infections in crops, which lead to widespread crop illnesses.
    According to the Food and Agriculture Organization (FAO), pests and diseases cause
    a 20-40% annual loss in crop output worldwide. To avoid this loss and reduce agricultural
    damage, a lot of pesticides need to be sprayed. but pesticides are harmful to
    human and animal health. They also have a significant, even irreversible, negative
    impact on the environment, ultimately contaminating entire ecosystems. Recent
    Internet of Things (IoT)-based intelligent gadgets, such as wireless sensors,
    robots, and drones, are enabling producers to drastically reduce pesticide usage
    by accurately recognizing crop enemies [31]–[32], which will reduce the necessity
    for pesticides. H. Computer Imaging Physically counting fruits and flowers and
    estimating agricultural production is a time-consuming and expensive process.
    Crop yield estimation and prediction are made more accurate and reliable by remote
    sensing technologies. Accurate field and yield maps are produced by automating
    image analysis using computer vision and deep learning algorithms. This imaging
    technique primarily employs sensor cameras that are placed throughout the farm
    to provide images that are later processed digitally. Image processing combined
    with machine learning improves the quality by comparing photos from the database
    with photos of crops to assess their size, shape, color, and growth. Computer
    imagery can help with sorting and grading. [33]. SECTION III. Architecture of
    Iot-Based Smart Farming The major elements of IoT-based smart farming architecture
    are Sensors nodes Network and Gateway that allows devices to be part of the IoT
    Data storage spaces and decision support system End-user applications A. Sensors
    Sensors are the devices that detect and react to specific inputs, such as light,
    motion, pressure, heat, or moisture, and convert them into representations or
    signals that can be interpreted by people for further interpretation and processing.
    The requirement for incorporating smart agriculture is made possible by the numerous
    types of sensors used in agriculture. Since they are responsible for gathering
    the data needed for smart agriculture systems from the farm. B. Communication
    Between Iot Devices A collection of guidelines known as a communication protocol
    facilitates safe data transfer between computers, servers, and other storage and
    processing equipment. Communication technology is a crucial connection in IoT
    applications that connect gateways and end sensors. Every IoT communication protocol
    has unique qualities that make it better suited for some projects than others.
    The range, memory requirement, power consumption, installation expenses, etc.
    of protocols vary greatly. Some only allow device connections within a single
    building, while others allow communication over long distances. For instance,
    Bluetooth, a popular IoT communication technology used in smart homes, exercise
    equipment, and healthcare, requires little power and memory to function. From
    device to device device to act as a gateway device to the cloud or a data center
    Things that are currently connected to the Internet can communicate with one another
    in a variety of ways. Some examples of these technologies are blue tooth, RFID,
    NFC, LoRa, cellular,Cellular and NB IOT. Each method of communication has advantages
    and disadvantages. Bluetooth is typically used for close-range wireless communication.
    In comparison to other communication channels, it consumes a lot of power and
    is rarely used for field consolidation. ZigBee is a superior short-range wireless
    communication mode to Bluetooth since it is less expensive, consumes less power,
    and is simple to set up. When a slow data transport rate is required, it works
    well. RFID is increasingly used. Since it uses wireless technology, it doesn''t
    need a wire [34]. Table I Sensors used in smart agriculture and its uses 1) Lora
    and Lorawan LoRaWAn is a transmission protocol introduced by the LoRa Alliance
    to satisfy the demands of IoT services. There is a built-in security layer, quick
    implementation, and maximum coverage over hundreds of square meters. It has low
    power consumption and few maintenance requirements, making it perfect for several
    sensors. Due to the aforementioned factors, LoRaWAn is ideal for Internet of Things
    (IoT) applications across a variety of industries. With the help of the low-power,
    long-range spread spectrum modulation method known as LoRa, IoT sensors may communicate
    across distances of up to 12 km with only 100 kbps data throughput and the highest
    degree of scalability (5-20K nodes). The authors of [35] have suggested a comparison
    of the performance characteristics of LPWAN technologies, including Sigfox, LoRa,
    and NB-IoT, in terms of deployment, deployment costs, battery life, latency, and
    scalability. In [36]–[37], authors have proposed a smart agriculture monitoring
    system using LoRaWAn technologies. 2) Zigbee The Zigbee protocol allows data to
    be transferred over long distances by using a mesh network of middle nodes to
    connect to remote ones. There are already about 300 million Zigbee nodes in use,
    and the 2.4 GHz frequency band of the technology can be used everywhere without
    requiring a license. If any of the nodes is disabled or removed, it autonomously
    configures itself (self-forming) and changes its configuration dynamically to
    fix itself (self-healing). Zigbee''s widespread adoption in automation and industrial
    IoT is a result of its interoperable nature, which enables seamless communication
    between devices made by numerous manufacturers. 3) Bluetooth Bluetooth is another
    low-power wireless connection option for sensor nodes. It supports a minimum range
    of 50 m with up to 7 nodes and a maximum data transfer speed of 1 MB/s. When compared
    to other communication technologies, the Bluetooth transceiver consumes less power.
    Beyond being the industry standard for handsfree phone and music transmission
    over wireless networks, Bluetooth technology is part of the IoT in both consumer
    and business settings. Bluetooth for the Internet of Things (Bluetooth IoT) is
    popular because it can connect devices without an internet connection on the one
    hand and build large device networks via Bluetooth mesh on the other. In [38],
    authors have proposed a localization method for smart farming based on Bluetooth
    technology. 4) Narrow Band Iot (nb-iot) A low-power wide area (LPWA) technology
    known as narrowband (NB-IoT) has provided a lot of new Internet of Things (IoT)
    devices and services. It increases system capacity and spectrum efficiency and
    reduces system power consumption. It can also extend the battery''s life to more
    than ten years. Data rates of up to 150 kbps are supported. 5) Sigfox Another
    LPWAN technology, similar to NBIoT, is Sigfox. To facilitate communication via
    the ISM radio frequencies, The modulation techniques used by Sigfox are differential
    binary phase-shift keying (DBPSK) and Gaussian frequency-shift keying (GFSK).
    In Europe and the US, Sigfox technology operates at 868 MHz and 902 MHz, respectively.
    It uses an energy-efficient signal dubbed “Ultra Narrowband” that has a wider
    range. It uses a one-hop star topology, and a mobile operator is needed to handle
    the traffic. It allows very slow data speeds of 100 bits per second. Fig. 7. Components
    of Sensor node Show All 6) Wireless Fidelity (wi-fi) Wi-Fi is an IEEE 802.11 protocol
    family designed for wireless sensor nodes where faster data transfer speeds are
    required, but power consumption is not an issue, and high data rates are required,
    such as video transmission. It supports the minimum transmission distance of 100
    feet. For IoT applications in smart agriculture, such high data rates are not
    necessary. For the Internet of Things, two Wi-Fi standards have been created:
    Wi-Fi HaLow (802.11ah) and HEW (802.11ax). It supports upstream rates of as much
    as 290 MB/s.. 7) Cellular The Internet of Things (IoT) is connected to the physical
    world through cellular technology, which makes use of the same cellular network
    as smartphones. Using current mobile networks, this technology enables the connection
    of IoT devices[39]. As a result, there is no longer a need to spend money and
    time creating a special network architecture, especially for IoT devices. Due
    to significant investments made in the development of cellular networks in most
    counties, mobile users always have access to reliable cellular connectivity. Connecting
    devices like streetlights, agricultural, and medical equipment with cellular networks
    like 3G, 4G/LTE, or 5G is the idea behind cellular IoT enablement. The benefits
    of cellular IoT technology are extensive coverage, cost-saving, remote management,
    security, and flexibility in connectivity. After networking components of IoT
    solutions, messaging protocols are still needed for data exchange over devices
    and the cloud. Some of the well-known protocols used in IoT ecosystems include
    the ones listed below [40]. 8) Coap CoAP is a popular client-server IoT protocol.
    Customers can use it to request online transfers as needed. But it also made it
    possible for supporting servers to respond to incoming inquiries. The device nodes
    of the IoT ecosystem can only communicate through CoAP. It was created to work
    with IoT systems that use HTTP. CoAP supports low bandwidth and resource-constrained
    devices to participate in IoT ecosystem. It is frequently used in machine-to-machine
    (M2M) applications.CoAP uses a compact binary message format for encoding requests
    and responses. The headers in CoAP messages are designed to be concise, typically
    requiring only a few bytes. This compact format reduces the amount of data transmitted
    over the network, making it ideal for low-bandwidth environments. Fig. 8. Classification
    of communication technologies used in Internet of Things (IoT) Show All 9) Dds
    Data Distribution Service is providing low-latency data connectivity, highly reliable,
    and a scalable architecture that IoT applications demand.” For data-centric communication,
    DDS is a middleware protocol and API standard. Using a publish-subscribe paradigm,
    this M2M standard delivers real-time data transport that is both high-performance
    and extremely scalable. To deliver applications with high-quality QoS, DDS uses
    multicasting and broker less architecture. 10) MQTT MQTT stands for Message Queuing
    Telemetry Transport, a system that was created for the first time in 1999. This
    protocol does not currently employ message queuing. MQTT''s publish-subscribe
    architecture makes M2M communication easier. It utilizes less technology and encourages
    communication between numerous devices because of its straightforward messaging
    architecture. It is intended to operate in low-bandwidth environments. For connecting
    devices and the Internet of Things, MQTT is now the most well-liked open-source
    protocol. 11) AMQP The Advanced Message Queuing Protocol (AMQP) is a published
    open-source standard for asynchronous wired communications. Between businesses
    and apps, AMQP offers interoperable encryption-based messaging. Client-server
    messaging and IoT device management both use this protocol. Middleware that is
    more message-oriented uses the open standard protocol known as Advanced Message
    Queuing Protocol (AMQP). It delivers interoperability, stability, and security
    even over lengthy distances and in subpar networks. It permits communication even
    when all necessary systems are not available at once. C. Choosing the Right Iot
    Protocol There is no one IoT communication protocol that is optimum or appropriate
    for all deployments. Instead, the design engineers must decide the suitable protocol
    for their organizations based on the requirement of their IoT deployments. These
    decisions should take a variety of factors into account, such as the location
    and power requirements of the connected devices, as well as the size and features
    of the area where the deployment will be located. When choosing the communication
    technology for our application, we must take into account communication range,
    Power efficiency, continuous availability, data throughput, latency, and end-user
    experience. It has been demonstrated that the LoRaWAN protocol is now being used
    more frequently. While selecting the communication technology for our application,
    we need to consider a few things. Communication Range Power Efficiency Continuous
    Availability Data Throughput and Efficiency End-user Experience D. How Sensors
    and Actuators Communicate The ESP8266 Node MCU microcontroller, the 18F458 PIC
    microcontroller, and the TMEGA328P are three common hardware platforms used by
    researchers in IoT-based smart agriculture. The majority of these platforms include
    the Wi-Fi module in it that connects to any Wi-Fi network via the TCP/IP protocol.
    These platforms are affordable, need little additional circuitry, and use less
    power. Furthermore, they have a limited amount of storage and on-board processing.
    A microcontroller logic application could be used to implement any smart watering
    technique. These systems allow for the quick integration of a variety of sensors
    across General Purpose IO (GPIO) pins in order to scale up to incorporate multiple
    sensors on a single platform. The maximum number of sensors that can be used with
    each actuator on the ATMEGA328P is 8. SECTION IV. Role of Machine Learning and
    Deep Learning in Agriculture Artificial intelligence (AI), which includes big
    data, the internet of things (IoT), machine learning, and several other digital
    technologies, is used widely in smart agriculture. [41]. Deep learning-based smart
    agriculture has seen significant success recently. The capacity of various intelligent
    systems built on AI to record, interpret, and help farmers make the best decisions
    at the right moment varies. Sensors (IoT nodes) that are installed in agricultural
    areas can record data, which can then be processed using any deep learning or
    machine learning algorithms and imposed on operational regions utilizing actuators.
    Only AI can decide when to use a specific resource appropriately, taking into
    account both the present situation and predictions for the future. By scheduling
    the appropriate amounts of resources, such as water, pesticides, and fertilizer,
    AI-based smart agriculture can reduce pollution and production costs while increasing
    output.. As early identification and prevention of plant diseases can be aided
    by AI, using fewer treatments to stop their spread would greatly lower environmental
    contamination [42]. For plant health, growth, and yield, agronomic inputs, including
    water, nutrients, and fertilizers, must be continuously provided. [43] Deep learning(DL)
    and machine learning (ML) are the two newest trends in the computer industry.
    Agriculture is monitored during the pre-harvest, harvest, and post-harvest stages
    using machine learning and deep learning algorithms. [44]. Crop selection, soil
    preparation, seed sowing, irrigation, and crop maintenance, which includes applying
    pesticides, spotting weeds, and trimming, are considered pre-harvesting stages
    of farming. To automate the process of estimating soil quality, several authors
    have recommended various machine learning and image recognition algorithms. [45]
    [46] seed sorting and computation [47] [48]. Some often examine tree leaves or
    branch growth to spot diseases, or they frequently use preventative measures to
    do so. Both tasks are carried out manually, and there is a possibility of mistakes.
    The type of disease, its severity, and the affected area play a major role in
    choosing the pesticide to use. Pesticides should not be applied to all crops unless
    absolutely necessary. This can be harmful to both the crops and the farmers''
    health. In [49]–[51], various authors have proposed different methodologies and
    solutions for the problems in the pre harvesting stage. Weeds are one of the factors
    that affect plant growth and productivity, just like pests and plant diseases.
    Numerous machine learning techniques have been put forth by researchers to recognize
    weeds in agricultural fields [52] [53] The most crucial stage is harvesting, which
    comes after pre-harvesting considerations for factors like soil, seeds, weeds,
    etc. are made. Fruit /Crop size, Skin color, flavor, maturation stage, quality,
    and categorization for harvesting are the crucial factors that need to be concentrated
    on at this stage. Fruit that has been harvested correctly and with care will yield
    a profit. Farmers are being helped by a variety of machine learning and deep learning
    techniques to cut down on harvesting-stage losses [54]–[58] The post-harvesting
    stage is a crucial one in agriculture and needs for extra care. Avoiding post-harvesting
    may ruin all of our efforts once the processes from seed selection to till harvesting.
    The post harvesting activities are sorting and grading, shelf life prediction.
    A study revealed that improper post-harvest handling techniques can have an impact
    on the fruit''s quality and quantity, increasing overall losses. [59] A. Challenges
    for Implementing Machine Learning in Smart Agriculture In the context of smart
    agriculture, machine learning offers a number of benefits. In contrast to the
    benefits, there are drawbacks. Some of the challenges that have been encountered
    when using machine learning algorithms in the agricultural sector are listed below:
    Pre-processing the data is step one: Before model training’ testing, and validation
    phase a data preprocessing must be require to clean the data. This could be a
    lengthy procedure. Selection machine learning algorithms: There are lots of machine
    learning algorithms are available selecting a suitable algorithm to our application
    is a tedious process. one can choose the best algorithm by comparing the results
    of various algorithms. This method of trial and error could cause the deployment
    of the model to be delayed. Machine learning model training and testing: To create
    an accurate model, a large amount of training data is required. It''s also crucial
    to test and validate models to ensure their accuracy prior its deployment. For
    the best intended and possible results, a model must be built from scratch, which
    requires extensive training and repeated testing. High-end hardware resources,
    programmers with domain expertise, testing equipment, etc. are required. Cost
    and accessibility: Implementing machine learning in agriculture should be financially
    feasible for farmers, especially small-scale farmers with limited resources. The
    cost of acquiring and maintaining the necessary hardware, software, and expertise
    can be a barrier to adoption. Ensuring affordability and accessibility of machine
    learning solutions is crucial for widespread implementation B. Iot, Ai, and Machine
    Learning in Soilless Agriculture Soilless agriculture is a method used to grow
    plants in a controlled environment without soil. In this method of agriculture,
    less amount of water and area are enough for growing crops. It provides the necessary
    nutrients for plant development artificially [60] [61]. The types of soilless
    agriculture are Hydroponics, Aquaponics and Aeroponics. In hydroponics, plants
    are grown in water-based nutritional solutions without the use of soil and with
    the assistance of mechanical support. A technique called Aquaponics allows for
    the simultaneous growth of plants and fish. Warehouses and other unconventional
    spaces can be used for aquaponics. The trash from the compartment used for fish
    farming is applied to the crops as manure. Chemical pesticides, fertilizers, or
    antibiotics are not utilized in this kind of agriculture to develop plants or
    fish. Future trends in agriculture can be enhanced by domesticating the Internet
    of Things (IoT), artificial intelligence (AI), and machine learning (ML) in accordance
    with the needs of agricultural techniques like hydroponics, aquaponics, and aeroponics..
    Traditional soilless farming has many drawbacks, including poor data sharing,
    heavy labor demands, and a lack of data centralization. Implementing the Internet
    of Things (IoT) concept in controlled environment agriculture can address these
    problems. SECTION V. Role of Blockchain in Smart Agriculture Blockchains are networks
    of computers that share a distributed database. Although it is possible to contribute
    to the database, you cannot change the data already there. The network routinely
    verifies the reliability of the database. Blockchain technology enables the creation
    of a secure way for recording transactions and delivering them to signatories
    or any other target group with an Internet connection. Fundamentally, it is a
    highly democratic ledger that cannot be altered at will and is simple to share.
    Smart decision support systems in farming help farmers make the best decisions
    to boost crop output and profits by managing data effectively. Different sensors
    and equipment used in agriculture gather various types of data about the land
    before transmitting it to a server in a cloud environment. Farmers can interact
    with the intelligent decision support system via mobile applications and websites
    to obtain information on the land from subject-matter specialists. These data
    need to be securely maintained and guarded against unwanted access because they
    are very sensitive. The Internet of Things (IoT), blockchain technology, and edge
    computing are all being integrated to help agricultural areas produce more crops
    while using fewer natural resources. A secure environment for storing and exchanging
    agricultural data is provided via a blockchain-enabled agricultural knowledge
    discovery system[62] [63] SECTION VI. Role of 5g in Smart Farming The dominance
    of 5G wireless technologies in smart agriculture is increasing day by day. This
    is due to the benefits of 5G technology, such as greater data rates and larger
    data capacities,. coverage areas, and adaptability to a variety of communication
    situations. These are critical in big farmlands for real-time crop monitoring.
    Over the last ten years, the 3G / 4G / NB-IoT wireless network technology, which
    provides appropriate speed for transmitting information and communication, has
    been utilized to connect smart devices through the IoT to share data for accurate
    evaluation in the agricultural field. However, as the quantity and quality of
    information has increased, the efficiency of the 4G network has dropped, as data
    transmission has become weaker than previously. The 5G network represents the
    evolution of fifth-generation communication networks to deliver extremely fast
    data transformation in a short period of time. Data transfer on the 5G network
    is faster than on other networks, with download and upload rates roughly 100 times
    faster than on the 4G network. The 5G networks support the design of smart applications
    because of their high data rate, low latency, spectral efficiency SECTION VII.
    Cloud Iot Challenges in Agriculture and How Edge Computing Can Solve Them It is
    impossible to overstate the advantages of IoT applications in agriculture, yet
    smart farming technologies can still face certain difficulties, particularly if
    they rely on the cloud. IoT smart farming faces three main cloud computing difficulties.
    Most use cases benefit greatly from cloud-based solutions. Another issue for the
    cloud can be data volume. Terabytes of data can be produced by widespread sensor
    deployments with frequent readings, which makes cloud storage and processing unfeasible
    and expensive. Cloud, however, is obviously not a choice for remote sites, and
    generally speaking, there are a number of circumstances where cloud must be supplemented
    with on-premises processing or storage. Edge computing expands the functionality
    of the cloud by delivering local resilience, processing, and storage to the network''s
    edge along with the infrastructure for sensing. Security There is a very high
    probability of information violation when it is sent back and forth between the
    field device and the cloud. Additionally, every sensor or device in our IoT network
    may be a potential point of weakness. In edge computing, data remains on the device
    where it was first obtained, so it helps reduce the risk of a data breach or theft.
    Speed Cloud based applications take lot of time to gather, transport, and analyse
    data. Because of this, some businesses may find themselves in a difficult situation
    where they must decide between the speed of data processing and the level of insight
    it can provide. This is especially true for remote accessing of agriculture field.
    Edge computing solves this problem by enhancing network efficiency and accelerating
    data processing, The network''s devices can all examine the data they gather and
    give quick feedback, accelerating processing and enhancing the level of understanding.
    Cost The amount of data generated by the “things” and sent across the network
    often determines how much cloud computing costs. When you consider how many devices
    a single smart farm system uses and how much data it generates, you can see how
    quickly cloud computing costs can rise. Using edge computing in agriculture eliminates
    the need to move or overcrowd your storage with irrelevant and pointless data.
    As a result, you can quickly reduce your cloud costs, including bandwidth and
    storage costs. SECTION VIII. Role of Robots in Smart Farming The Internet of Things
    (IoT) has aided in the development of agricultural robots capable of performing
    jobs that humans cannot. In addition, the robots can remove up to 80% of pesticides
    used on fields without harming the environment. With a workforce shortage, agricultural
    robots will be useful instruments for developing innovative smart agriculture
    solutions. A variety of agricultural robots, including harvesting, sowing, weed
    identification, irrigation, and insect infestation, as well as animal applications,
    are being developed. In [64] [65], the author suggests a vision-based navigation
    system for the Industrial Internet of Things (IIoT) and a binocular vision navigation
    algorithm for intelligent agricultural robots that can combine the edge contour
    and height information of crop rows in images to extract navigation parameters.
    To build a productive tomato harvesting robot, [66] combines the ideas of 3D perception,
    manipulation, and an end-effect. This robot uses deep learning to recognize tomatoes,
    then extracts the target crop''s 3D coordinates and uses 3D coordination to control
    the motion of the manipulator. SECTION IX. Open Issues and Challenges in Smart
    Agriculture Open Issues and Challenges in Smart Agriculture: AI-enabled IoT-based
    smart farming has the potential to revolutionize the agriculture industry by increasing
    efficiency, reducing waste, and improving yields. However, there are several challenges
    that need to be addressed for successful implementation. Here are some of the
    major challenges: Security Issues: There are various security issues that IoT-based
    agricultural systems must handle. Due to inadequate security, users experience
    a wide range of problems, including data loss and other on-field traits. Additionally,
    because of the low energy consumption and limited memory, it is difficult to create
    sophisticated and complex algorithms. The location-based services and IoT-enabled
    location information that are used in precision farming are vulnerable to hackers
    who might exploit them to capture devices. Cryptographic implementations are taken
    out by attacks on IoT devices. Other communication layers are similarly susceptible
    to wireless signal blocking and denial-of-service (DoS) assaults. Cost: When adopting
    IoT in agriculture, a number of costrelated issues, such as deployment and maintenance
    costs, arise. The setup costs are made up of hardware costs for gateways, base
    station infrastructure, and IoT devices and sensors. Also included in operational
    costs are continuing subscription fees for IoT device administration, information
    exchange between services, and centralized information/data collection services.
    Lack Knowledge of Technology: To make all these technological revolutions grand
    success farmers need to understand these technologies. In developing nations where
    the majority of farmers are uneducated, this issue is prevalent because extensive
    investment is needed in farmer training prior to building IoT infrastructure;
    implementing IoT in agriculture is difficult. Reliability: Due to the open environment
    in which IoT devices are used in agriculture, extreme environmental conditions
    may result in connectivity breakdowns and the humiliation of placed sensors. As
    a result, it''s critical to secure the physical security of IoT devices and sensors
    deployed so they can be shielded from harsh weather conditions. Scalability The
    agriculture industry has a huge deployment of IoT devices and sensors, so an intelligent
    IoT management system is needed to be scalable. Limitations use of drones in agriculture
    Unmanned aircraft have many advantages, but there are also several obstacles to
    their deployment, particularly in poor nations. These include the following. Because
    the drone''s flight period is limited to an hour or less, it is important to take
    into account the overlap between the flight lines while choosing the flight line
    path. Drones are expensive, especially when equipped with high-quality hardware,
    software, cameras, and thermal imaging equipment. Drone operation laws: In many
    nations, operating a drone requires a permit; also, the pilot''s height cannot
    exceed 400 feet. Climate influence: Weather conditions have an impact on how drones
    operate. The Wind and rain have an impact on the drone''s performance, so it is
    important to consider the weather before beginning any work. Smart farming generates
    a vast amount of data that needs to be collected, analyzed, and managed. This
    includes data from sensors, weather stations, soil moisture sensors, and other
    sources. Managing and processing this data in real time is a challenge that requires
    sophisticated data management techniques. Connectivity: Smart farming relies on
    IoT devices and sensors to collect and transmit data. The connectivity of these
    devices can be a challenge, especially in rural areas where network coverage may
    be limited. Power Consumption: IoT devices require power to operate, and battery
    life can be a limiting factor. The use of renewable energy sources such as solar
    power and wind power can help address this issue. Addressing these challenges
    will require collaboration between industry, government, and research institutions.
    However, the potential benefits of AI-enabled IoT-based smart farming are significant,
    including increased yields, reduced waste, and improved sustainability. SECTION
    X. How To Optimize the Performance of Smart Farming To optimize the performance
    of IoT-based smart agriculture, several strategies can be implemented. These strategies
    focus on enhancing efficiency, reliability, and scalability while reducing resource
    consumption and response time. Edge Computing: Implement edge computing to process
    data closer to the source (sensors and devices) rather than sending all data to
    centralized servers. Edge computing reduces latency, conserves bandwidth, and
    allows for faster decision-making, making it ideal for time-sensitive applications
    in smart agriculture. Data Compression and Aggregation: Use data compression techniques
    to reduce the size of data transmitted over the network. Additionally, aggregate
    data from multiple sensors to minimize redundant information. This approach decreases
    data transmission requirements and conserves bandwidth, thereby reducing the energy
    consumption Energy Efficiency: Optimize power consumption of IoT devices by using
    low-power components, energy-efficient algorithms, and duty-cycling mechanisms.
    Prolonging the battery life of IoT devices reduces maintenance efforts and ensures
    continuous data collection. Optimized Network Topology: Design the IoT network
    topology strategically to minimize communication hops and improve overall network
    performance. This can be achieved through network clustering or using mesh networks
    to ensure robust connectivity. Quality of Service (QoS): Prioritize critical data
    and applications in the IoT network to ensure high QoS for essential services.
    Allocate resources accordingly to guarantee that vital processes, such as irrigation
    control or weather monitoring, receive priority handling. Security and Privacy
    Measures: Implement robust security protocols to safeguard IoT devices and data
    from unauthorized access. Protecting the integrity and privacy of agricultural
    data is crucial, especially when it involves sensitive information about crops,
    livestock, or farmers. Predictive Analytics and AI: Utilize machine learning algorithms
    to analyze historical data and predict future events, such as weather patterns,
    crop yield, and pest outbreaks. Predictive analytics helps optimize resource allocation
    and enhances decision-making for farmers. Fault Tolerance and Redundancy: Design
    the system with redundancy and fault-tolerance mechanisms to handle device failures
    gracefully. Ensuring that critical processes can continue in case of device malfunctions
    or network disruptions enhances system reliability. Sustainable Resource Management:
    Use IoT data to optimize resource usage, such as water, fertilizers, and energy.
    By employing precision agriculture techniques, farmers can reduce waste and promote
    sustainable practices. Continuous Monitoring and Evaluation: Continuously monitor
    the performance of the IoT-based smart agriculture system and gather feedback
    from users. Regular evaluations help identify areas for improvement and enable
    iterative enhancements. SECTION XI. Conclusion In this paper, we discuss the necessity
    of smart farming to satisfy current food demand and availability. A detailed review
    of existing methods and a recent development in smart agriculture systems were
    discussed. The significant contributions of this paper are the applications of
    IoT in agriculture, the hardware requirements of smart agriculture systems, the
    various wireless communication technologies available and their comparison, the
    role of machine learning in smart farming, and their challenges. We then discussed
    the future technologies for smart farming and social development when society
    fully adopts smart farming. An intelligent IoT system for smart farming can begin
    reducing the need for water, soil, and human resources while increasing food production.
    However, there are several challenges that need to be addressed for successful
    implementation. Data management, connectivity, power consumption, data privacy,
    and security, cost, and farmer education and training are some of the major challenges
    that need to be overcome. By addressing these challenges and embracing new technologies,
    the agriculture industry can meet the increasing demand for food in a sustainable
    and efficient manner. Authors Figures References Keywords Metrics More Like This
    Enhancing Machine Learning Training Performance in Smart Agriculture Datasets
    Using a Mobile App 2023 IEEE International Workshop on Metrology for Agriculture
    and Forestry (MetroAgriFor) Published: 2023 An Innovative Approach for Leaf-based
    Disease Detection in Crops and Soil Analyzer using Machine Learning for Smart
    Agriculture 2022 2nd International Conference on Technological Advancements in
    Computational Sciences (ICTACS) Published: 2022 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings of the 4th International Conference on Smart Electronics and
    Communication, ICOSEC 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Revolutionizing Agriculture with IoT -A Review
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Molina-Rotger M.
  - Morán A.
  - Miranda M.A.
  - Alorda-Ladaria B.
  citation_count: '0'
  description: 'Introduction: Intelligent monitoring systems must be put in place
    to practice precision agriculture. In this context, computer vision and artificial
    intelligence techniques can be applied to monitor and prevent pests, such as that
    of the olive fly. These techniques are a tool to discover patterns and abnormalities
    in the data, which helps the early detection of pests and the prompt administration
    of corrective measures. However, there are significant challenges due to the lack
    of data to apply state of the art Deep Learning techniques. Methods: This article
    examines the detection and classification of the olive fly using the Random Forest
    and Support Vector Machine algorithms, as well as their application in an electronic
    trap version based on a Raspberry Pi B+ board. Results: The combination of the
    two methods is suggested to increase the accuracy of the classification results
    while working with a small training data set. Combining both techniques for olive
    fly detection yields an accuracy of 89.1%, which increases to 94.5% for SVM and
    91.9% for RF when comparing all fly species to other insects. Discussion: This
    research results reports a successful implementation of ML in an electronic trap
    system for olive fly detection, providing valuable insights and benefits. The
    opportunities of using small IoT devices for image classification opens new possibilities,
    emphasizing the significance of ML in optimizing resource usage and enhancing
    privacy protection. As the system grows by increasing the number of electronic
    traps, more data will be available. Therefore, it holds the potential to further
    enhance accuracy by learning from multiple trap systems, making it a promising
    tool for effective and sustainable fly population management.'
  doi: 10.3389/fpls.2023.1241576
  full_citation: '>'
  full_text: '>

    "Top bar navigation About us All journals All articles Submit your research Search
    Login Frontiers in Plant Science Sections Articles Research Topics Editorial Board
    About journal Download article 1,061 Total views 230 Downloads View article impact
    View altmetric score Share on Edited by Liangliang YANG Kitami Institute of Technology,
    Japan Reviewed by Yunchao Tang Guangxi University, China Ebenezer Olaniyi Mississippi
    State University, United States Table of contents Abstract 1 Introduction 2 Materials
    and methods 3 Data collection and generation 4 Machine learning classification
    models 5 Image approach: fruit fly detection 6 Results 7 Discussion 8 Conclusions
    Data availability statement Author contributions Funding Conflict of interest
    Publisher’s note References Export citation Check for updates People also looked
    at Salinity stress-induced phosphorylation of INDETERMINATE-DOMAIN 4 (IDD4) by
    MPK6 regulates plant growth adaptation in Arabidopsis Anamika Rawat, Ronny Völz,
    Arsheed Sheikh, Kiruthiga G. Mariappan, Soon-Kap Kim, Naganand Rayapuram, Khairiah
    M. Alwutayd, Louai K. Alidrissi, Moussa Benhamed, Ikram Blilou and Heribert Hirt
    One-time fertilization of controlled-release urea with compound fertilizer and
    rapeseed cake maintains rice grain yield and improves nitrogen use efficiency
    under reduced nitrogen conditions Yajie Hu, Qin Cai, Yi Xu, Jiantao Xue, Enwei
    Yu, Haiyan Wei, Ke Xu, Zhongyang Huo and Hongcheng Zhang StressNet: a spatial-spectral-temporal
    deformable attention-based framework for water stress classification in maize
    Tejasri Nampally, Kshitiz Kumar, Soumyajit Chatterjee, Rajalakshmi Pachamuthu,
    Balaji Naik and Uday B. Desai A fine recognition method of strawberry ripeness
    combining Mask R-CNN and region segmentation Can Tang, Du Chen, Xin Wang, Xindong
    Ni, Yehong Liu, Yihao Liu, Xu Mao and Shumao Wang A lightweight model for efficient
    identification of plant diseases and pests based on deep learning Hongliang Guan,
    Chen Fu, Guangyuan Zhang, Kefeng Li, Peng Wang and Zhenfang Zhu ORIGINAL RESEARCH
    article Front. Plant Sci., 09 October 2023 Sec. Sustainable and Intelligent Phytoprotection
    Volume 14 - 2023 | https://doi.org/10.3389/fpls.2023.1241576 This article is part
    of the Research Topic IoT, UAV, BCI Empowered Deep Learning models in Precision
    Agriculture View all 15 articles Remote fruit fly detection using computer vision
    and machine learning-based electronic trap Miguel Molina-Rotger 1* Alejandro Morán
    1 Miguel Angel Miranda 2,3 Bartomeu Alorda-Ladaria 1,3,4* 1Industrial Engineering
    and Construction Department, University of the Balearic Islands, Palma, Spain
    2Biology Department, University of the Balearic Islands, Palma, Spain 3Institute
    for Environmental Agro-Environmental Research and Water Economics, University
    of the Balearic Islands, Palma, Spain 4Health Science and Technology Cross-cutting
    Department, Balearic Islands Health Research Institute (IdISBa), Palma, Spain
    Introduction: Intelligent monitoring systems must be put in place to practice
    precision agriculture. In this context, computer vision and artificial intelligence
    techniques can be applied to monitor and prevent pests, such as that of the olive
    fly. These techniques are a tool to discover patterns and abnormalities in the
    data, which helps the early detection of pests and the prompt administration of
    corrective measures. However, there are significant challenges due to the lack
    of data to apply state of the art Deep Learning techniques. Methods: This article
    examines the detection and classification of the olive fly using the Random Forest
    and Support Vector Machine algorithms, as well as their application in an electronic
    trap version based on a Raspberry Pi B+ board. Results: The combination of the
    two methods is suggested to increase the accuracy of the classification results
    while working with a small training data set. Combining both techniques for olive
    fly detection yields an accuracy of 89.1%, which increases to 94.5% for SVM and
    91.9% for RF when comparing all fly species to other insects. Discussion: This
    research results reports a successful implementation of ML in an electronic trap
    system for olive fly detection, providing valuable insights and benefits. The
    opportunities of using small IoT devices for image classification opens new possibilities,
    emphasizing the significance of ML in optimizing resource usage and enhancing
    privacy protection. As the system grows by increasing the number of electronic
    traps, more data will be available. Therefore, it holds the potential to further
    enhance accuracy by learning from multiple trap systems, making it a promising
    tool for effective and sustainable fly population management. 1 Introduction Precision
    Agriculture for pest management requires constant monitoring of the target pest
    population as well as continuous evaluation of environmental conditions like temperature
    and humidity. Bactrocera oleae (Gmelin), known as the olive fruit fly, is a serious
    pest in the olive industry. If environmental conditions favour the proliferation
    of this tephritidae, losses from this pest might exceed 100% of productivity in
    a year. As a result, developing a system capable of collecting field data is critical
    for precise pest management. The traditional monitoring system is based on flytraps.
    Those traps kill specific species of fruit flies, which are then manually collected
    and identified. The number of flies trapped are checked manually usually every
    week during the fruit fly season and then fortnightly during the winter months.
    The number of hours spent in this check task is huge and due to the manually data
    collection frequency, the time to detect an infestation is too large for flash
    responses. Therefore, developing a monitoring station to automate this manual
    trap checking will produce many benefits Martins et al. (2019). In addition, several
    environmental and public health problems appear when insecticides and off-target
    sprays are used extensively without adequate management. Weather parameters like
    air temperature and humidity levels in the spraying area are critical to determine
    the moment to spray and the duration of this process. The adult fly population
    is the insecticide target, and the weather conditions are important to decrease
    or increase the spray process effectiveness. In this sense, automatically monitoring
    those parameters in real time using computer-based platforms is important to adjust
    the spray activity. In general, agricultural scenarios seem to be one of the most
    promising application areas for wireless monitoring station deployments due to
    the necessity of improving the agro-food production chain in terms of precision
    and quality. This involves a careful system design, since a rural scenario consists
    of an extensive area devoid of an electrical power supply and available wired
    connections. Automatic monitoring stations technology is introduced in Precision
    Agriculture strategy (PA) to obtain accurate real time field information and make
    accurate and optimum decisions Bjerge et al. (2023); Fasih et al. (2023). Plant
    pest control remains one of the main research objectives of modern agriculture
    Shah and Wu (2019). The widespread use of insecticides at the field level is still
    the most common practice for the control of plant pests in general and for the
    fruit flies in particular Dias et al. (2018). However, its use is being restricted
    by official authorities due to its impact on the environment, human health, and
    the development of resistance in target pests. The use of PA for pest control
    has been applied to improve the control and/or detection of several pests, as
    examples: particularly sensitive maps are used to drive variable insecticide application
    for the control of certain insect pests Reay-Jones et al. (2019); hyperspectral
    imaging is used to detect fruit fly infestation in fruits Ding et al. (2021);
    or GIS technologies are used to implement user support systems to take more precise
    decisions about treatments of insect pests in the Mediterranean areas Goldshtein
    et al. (2021). In all these cases, a continuum of more accurate monitoring data
    produces a more accurate assessment of pest presence which, together with geolocation
    information, improves understanding of the spatial and temporal distribution of
    pest effects. In fact, the fast access to the information about pests is mandatory
    to accurately manage pests and diseases in agriculture Grasswitz (2019). Since
    the monitoring of fruit flies is dependent on fly identification, the first fruit
    fly identification platform was proposed by Pontikakos et al. (2012) as a combination
    of traditional manual inspection process and the computer-based platform for storing
    the trap checking results. The proposed computer-based platform can perform olive
    fruit fly evolution analysis and treatment prediction considering weather conditions.
    Although the manual trap inspection is also required, the automatic analysis of
    data combined with weather conditions allows determining the best period to apply
    the spray treatment and the areas to be considered in the treatment. The second
    one is related to solve the identification process and reduce the time needed
    to check the fly traps. The authors in Bjerge et al. (2023); Fasih et al. (2023)
    describe a procedure to identify the fruit fly using image segmentation techniques
    using a camera as a sensor and some computing process to obtain the identification
    results. Although, the procedure is proposed using a MacPhil trap. In a MacPhil
    trap, the fly can be over or in the liquid introducing some additional difficulty
    for accurate fly identification process in comparison with using sticky traps.
    The sticky trap retains the flies on the surface of the trap plane and increases
    the possibilities to take an adequate photograph for identification purposes.
    This is where computer vision and Artificial Intelligence (AI) come in. It can
    analyze the photo and identify the olive fly, reducing the time it takes to check
    the traps and automating the process. As a result, the farmer’s workload is reduced.
    Advances in image identification techniques have paved the way for the use of
    AI in this field. Although Deep Learning (DL) is the most commonly used technique,
    Krizhevsky et al. (2017), and there are examples of their effectiveness, Victoriano
    et al. (2023); Uzun (2023), this article discusses classical machine learning
    (ML) approaches. This is because DL requires a large dataset to achieve good results,
    and such a dataset is currently unavailable. It is also computationally expensive.
    Therefore, the study will focus on the ML algorithms Random Forests (RF) and Support
    Vector Machines (SVM). This work shows the design and implementation of a real
    time automated low-cost olive fruit fly smart trap, will now be referred to as
    e-trap throughout this article. The main novelty is the use of ML for image identification,
    in addition to the connection through a GPRS link with a cloud-based platform
    described in Miranda et al. (2019). In particular, it is explored how RF and SVM
    can improve efforts to reduce the use of pesticides against the olive fly to prevent
    crop loss and monitor it remotely. 2 Materials and methods The smart trap approach
    consists of a photographic camera for image capture, a linux-based electronic
    system to implement the algorithms to recognize olive fly adults, a solar-based
    power system, and an ambient relative humidity/temperature sensor. The sensor
    and picture data collected by the smart trap is processed and stored allowing
    in-situ access in case of communication lost. The solar panel and the Stevenson
    screen for the humidity and temperature sensors are at the upper part of a metal
    pole see Figure 1A. The battery, transmitter system, and controller are included
    in a box just in the middle part, as Figure 1A shows. The controller system and
    the transmitter module are in the middle box for weather condition protection.
    In addition, Figure 1B shows the sticky trap supported by a metal pole, including
    a junction box with a camera installed in front of the trap. This camera is connected
    to the controller system for image capture and power supply. Finally, the lower
    part of the metal pole will be used to nail the pole on Earth and thus have a
    first fastening point to finish tying the pole to the strongest olive branches.
    In this way, the metal pole will be stable and tied up during the measurement
    period without disturbing the agricultural machines and workers between olive
    trees. figure 1 Figure 1 Electronic components of the e-trap. (A) E-trap with
    solar panel, Stevenson screen to protect the temperature and relative humidity
    sensor, battery and electronics. (B) Camera placed in front of a Rimi® trap. (C)
    Battery and electronics. 2.1 Sensors and camera The designed prototype includes
    a temperature, a relative humidity sensor, and a camera serial interface (CSI).
    The two sensors (model DHT22) installed in the upper part of the pole will be
    connected and powered from the controller box. This sensor has enough resolution
    in both parameters, see Table 1. The DHT22 device provides a new value each 2
    seconds with reduced energy consumption ratio. The controller system is designed
    to measure and save in local storage memory the temperature and humidity values
    each minute. But, only the maximum, minimum and the average values are transmitted
    to the cloud server every hour including the exact timestamp. This methodology
    reduces the amount of data to be sent to the server and filters the unwanted values
    (aberrant values or errors in communication with the sensor), storing the information
    on the station for post-analysis and maintenance purposes. table 1 Table 1 Specifications
    of sensor and camera elements. The camera used is a CMOS sensor Omnivision 5647
    with removed IR filter (see Table 1 for camera specifications). It is connected
    and powered by the controller system using a CSI bus. The cable between camera
    and controller is 1.5 meters long, allowing to determine the most adequate position
    of sticky trap without restrictions of distances, see metal arm where sticky trap
    and camera are fixed in Figure 1B. The camera is the most energy demanding device
    in the proposed e-trap system apart from the 4G modem. Therefore, it is powered
    on during the instant to take the photo, afterwards, it remains turned off. The
    instant when taking the photography can be adjusted considering the sun position
    and the amount of light available. The smart trap has been programmed by default,
    to take three photos when the sun is around the upper level, so the sunlight intensity
    will be the highest producing the highest image contrast. The three photos will
    be taken around midday hour with a delay of 30 minutes between each photo. In
    addition, users can change the timing of the photo at any time to capture the
    best quality photo depending on the locations and shadows on the sticky trap surface.
    Photographies are taken only three times a day because this is not a real-time
    application. Here the goal is to infer and report the insect population without
    being on the field. In addition, since the system is not perfect, it is convenient
    to take several photographies, three in our case, to filter errors and increase
    the amount of training data. 2.2 Controller and communication system The controller
    system is one of the most important parts of the smart trap. It manages sensor,
    camera, data transmission and performs the fly identification task. All these
    tasks require enough computer resources, low energy consumption and system flexibility.
    In this work a Raspberry Pi B+ is selected to supply the required hardware requirements
    in combination with the Raspbian OS lite version. The selected platform is flexible
    enough to manage all the tasks reducing the number of active processes and power
    consumption, while image processing software can be implemented using open-source
    resources like OpenCV, Bradski (2000). The communication module consists of an
    Airlink GL8200 modem connected to the controller system using the serial port
    interface (SPI). The communication uses flux control to obtain maximum transmission
    velocity ratios (115200 bps). The modem module is compatible with standard AT
    commands and can allow server connections using standard internet protocols like
    File Transfer Protocol (SFTP), Hypertext Transfer Protocol (http) and Network
    Time Protocol (NTP) between others. The NTP protocol is used to maintain and update
    the local real time controller (RTC) enabling a time-based schedule of the tasks.
    The http protocol enables the connection with the remote server to store the sensor
    data and the fly count result on the remote database. In case of necessary, the
    SFTP protocol allows uploading images to the server for validation purposes with
    the penalty to increase the energy consumption available at the smart trap. In
    any case, a SD storage disk is used to save all sensor data, fly count and images.
    Therefore, the data will remain in the smart trap in case communication fails
    and can be accessed manually visiting the trap location during sticky trap maintenance.
    2.3 E-trap firmware The e-trap controller is designed using the Raspian Lite operating
    system implementing a time-scheduled management. The different e-trap tasks are
    executed using the Cron task manager embedded in the Unix systems. In this way,
    the e-trap is configured to work alone without expecting interaction from remote
    infrastructures. The e-trap firmware is divided into five main tasks as shown
    in the functional diagram in Figure 2. All tasks are lunched using the Cron manager,
    Kernighan and Pike (1984). The first task, called “system”, maintain the controller
    date and time updated, check the battery level, peripheral power supply management
    and rebooting-based strategy to avoid software issues. The second task, referred
    to as “collect”, is related to sensor access, and collects temperature and humidity
    values from DHT22 sensor storing it timestamped in a local file using CSV format.
    The third task, named “capture”, takes a picture adjusting the exposition time
    and white balance level to optimize the resolution and the quality of the picture.
    The fourth task, termed “identify”, analyzes the obtained images, and try to identify
    the number of flies trapped. This identification process is explained in the next
    section. And finally, the fifth task, called “transfer”, is responsible to establish
    LTE communications, to send the sensor data file to the remote server and to attend
    to the remote requirements (send the picture file or software update). figure
    2 Figure 2 E-trap firmware flowchart showing the five main tasks and their execution
    times. Each task of the e-trap software is launched by Cron daemon at different
    time during the day. Therefore, each task is implemented independently of the
    other tasks avoiding that one task stop the rest of tasks. In fact, meanwhile
    the Cron daemon is running, the tasks are initiated and terminated without interaction
    between them. It is important to note that the “system” task is executed twice
    a day. The first time it reboots the controller to get a fresh system after one
    day of continuous operation. The second execution of the “system” task (@16:00)
    will shut down all peripherals not related to the collection task. With this procedure,
    the power consumption of Raspberry Pi platform is minimized until the next day’s
    reboot. 3 Data collection and generation 3.1 Dataset collection This article uses
    images of the two e-traps identified as N10 and N17. These traps were placed in
    the olive fields of the “Institut de Recerca i Formació Agroalimentària i Pesquera
    de les Illes Balears” (IRFAP) in Mallorca, Spain. The OV5647 camera, which is
    already integrated in the e-trap itself, was used to capture the images. The resulting
    images have a resolution of 1600 pixels wide by 1200 pixels high, 3 RGB channels,
    24-bit depth, and were saved in.jpg format. Note that the physical position of
    the traps in the olive trees was similar but not exactly the same, resulting in
    differences in the final image. The dataset consists of a total of 62 images,
    45 generated by N10 and 15 generated by N17. Figure 3 shows an example of an image
    taken by each of the traps and Table 2 shows all this data summarized. figure
    3 Figure 3 Example targets from N10 and N17 sticky traps. table 2 Table 2 Dataset
    collection parameters. By taking a photo every day until the sticky pad is replaced,
    the observation reveals the emergence of new flies alongside the already trapped
    flies that persist over time. Figure 4 shows how this allows us to know how the
    same olive fly is observed with different lighting, thus performing the data augmentation
    (DA) technique in an organic way and allowing the classifier model to learn which
    features have the highest priority in defining the fly for its correct classification.
    The application of this technique is common in the AI world, since it allows to
    face the problem of lack of data to train, and in the PA world it is no exception
    (Brilhador et al. (2019); Fawakherji et al. (2020)); (Shorten and Khoshgoftaar
    (2019)). figure 4 Figure 4 Example of the same olive fruit fly from 8 to 15 October
    on N17. 3.2 Dataset generation The 45 images from N10 were used to train the classifier
    models. Classifier test was performed on the remaining 15 images from N17. This
    was advantageous because the classifier model never knew the training data and
    could even be given different e-trap positions and luminance conditions with respect
    to N10. In summary, it was possible to test whether a single e-trap could be used
    to generate a first scalable smart trap system capable of localizing and classifying
    the olive fruit fly. After studying all the available images to train the classifier
    model, the dataset consisted of 501 olive flies, 368 flies of other species or
    very similar insects, and 611 different elements such as the bag or tube with
    the olive fly attractant, the brand of the adhesive panel, holes in the panel,
    other insects, shadows due to different lighting, trap identifier, etc., all of
    32 × 32 × 3 pixels. All of these were grouped into two groups, “olive fly”/”others”,
    resulting in a data set with a ratio of 501 “olive fly” and 979 “others” samples.
    All these dataset values are summarized in Table 3. table 3 Table 3 Training,
    validation, and test set sizes for the cropped images. Note that the training
    size refers to the already augmented data and the percentages refer to the sum
    of these augmented samples. A 9:1 ratio was used for training and validation of
    the models, i.e. 90% of the samples are used for training and 10% for validation.
    In addition, in order to have more working data, basic DA techniques that could
    be present in the nature of the project were applied: vertical image flipping,
    horizontal flipping, 90° rotation, and changes in the brightness and contrast
    of the images. These actions allowed us to enlarge each image up to 24 = 16 new
    alternatives. In addition, it is worth highlighting these DA techniques based
    on basic image manipulations are considered “safe” for this application because
    the label is always preserved Shorten and Khoshgoftaar (2019). Two conditions
    were set for this DA process: first, between zero and ten new images could be
    generated, this number being random for each sample. Second, each DA technique
    could occur with a 50% chance. In this way, the augmentation would not be homogeneous,
    thus preventing the model from learning repetitive patterns. This action eventually
    increased the training data set from 1332 to 8069 samples, and all AI models used
    it, so that the result comparisons for different models are not biased by the
    dataset. Finally, the test images from N17 were simply labeled to match the image
    provided by the e-trap to simulate the real system process. 4 Machine learning
    classification models As mentioned earlier, due to the size of the dataset, the
    final algorithms selected for this article were RF and SVM. These ML methods and
    their validation would be the focus of this section. 4.1 Random forest Random
    Forest, introduced by Breiman (2001), is a supervised learning algorithm used
    for both classification and regression tasks. It is an ensemble method that combines
    multiple decision trees to make predictions. Each decision tree in the RF is built
    independently on a different subset of the training data, and the final prediction
    is made by aggregating the predictions of all the trees. Here’s how RF works:
    1. Data Preparation Given a collection of training examples denoted as x i , y
    i ) ] i = 1 n , where xi represents the input features and yi represents the corresponding
    target labels, RF starts by randomly selecting subsets of the training data with
    replacement. These subsets are known as bootstrap samples. 2. Building Decision
    Trees: For each bootstrap sample, a decision tree is constructed independently.
    At each node of the decision tree, a feature subset is randomly selected, and
    the split that optimally separates the data based on some criterion (e.g., Gini
    impurity or entropy for classification, Jost (2006), mean squared error for regression,
    Langs et al. (2011)) is chosen. The tree continues to split the data until a stopping
    criterion is met, such as reaching a maximum depth or minimum number of samples
    required to split further. 3. Ensemble Prediction: Once all the decision trees
    are built, predictions are made by each tree on unseen data. For classification
    tasks, the class with the majority of votes among the trees is selected as the
    final prediction. For regression tasks, the average of the predicted values from
    all the trees is taken. RF offers several advantages over individual decision
    trees: ● Ensemble Effect: By aggregating predictions from multiple decision trees,
    RF reduces the risk of overfitting and provides more robust predictions. ● Feature
    Randomness: Randomly selecting a subset of features at each node helps to decorrelate
    the trees and capture different aspects of the data. ● Out-of-Bag Evaluation:
    As the trees are built on bootstrap samples, the instances left out in each sample
    (out-of-bag instances) can be used for validation without the need for an additional
    holdout set. In summary, RF is a versatile and powerful algorithm that combines
    the predictions of multiple decision trees to achieve high accuracy and robustness
    in both classification and regression tasks. It is particularly effective when
    dealing with complex data and can handle a large number of features. 4.2 Support
    vector machines Support vector machines (SVM), introduced by Vapnik and Chervonenkis
    (2015), are also supervised learning models used for classification and regression
    analysis. The term SVM typically does not refer to a linear SVM, but rather to
    the use of kernel methods, Sánchez A (2003). Given a collection of training examples
    denoted as [ ( x i , y i ) ] i = 1 n , and a kernel function denoted as K, each
    yi belonging to the set [−1, +1] represents its categorization into one of two
    categories. An objective function of the SVM is used to solve the optimization
    problem defined as follows: max α [ ∑ i = 1 n α i + ∑ i , j = 1 n α i α j y i
    y j K ( x i , x j ) ] ( 1 ) subject to the constraints: 0 ≤ α i ≤ C ∑ i = 1 n
    α i y i = 0 Here, the Lagrange coefficients αi are involved, and the constant
    C is used to penalize training errors present in the samples. An SVM training
    algorithm constructs a model that classifies new examples into one of two categories,
    acting as a non-probabilistic binary linear classifier. The SVM model represents
    the examples as points in a space in which they are mapped to ensure a clear gap
    that maximizes its width between the different categories. Then, new examples
    are projected into the same space and their categorization is predicted based
    on which side of the gap they fall. As mentioned in the introduction, the choice
    of the regularization parameters αiand the form of the kernel function K ( x i
    , x j ) have a significant impact on the performance of the SVM. These factors
    are thoroughly considered and extensively discussed in the comparative experiments.
    4.3 Model validation When building a model, there are several parameters to consider,
    and depending on how they are combined, the results may vary. In addition, there
    is a stochastic variable in the selection of data that may or may not favor the
    final result. Therefore, the techniques used in this article can be grouped into
    two. (i) Grid search, to find the combination of hyperparameters that give the
    best results. (ii) Cross validation, to perform the process k times with different
    combinations of data, thus validating that the response of the classifier model
    is general and not specific to a single combination of data. The metrics used
    for validation were: confusion matrix, accuracy, precision, recall, f1-score,
    Receiver Operating Characteristic (ROC) curve and the Area Under the ROC Curve
    (AUC). 4.3.1 Confusion matrix Measures the performance of a classification model
    by summarizing the number of true positive (TP), true negative (TN), false positive
    (FP), and false negative (FN) predictions in tabular form. 4.3.2 Accuracy This
    metric measures the proportion of correctly classified images out of the total
    number of images in the dataset. A c c u r a c y = ( ( T P + T N ) / T o t a l
    I m a g e s ) ∗ 10 4.3.3 Precision It measures the proportion of correctly predicted
    positive instances out of all instances predicted as positive. P r e c i s i o
    n = T P / ( T P + F P ) 4.3.4 Recall The recall metric measures the ability of
    a model to correctly identify positive instances out of all the instances that
    are actually positive. R e c a l l = T P / ( T P + F N ) 4.3.5 F1-Score The F1
    score is a metric that combines precision and recall to provide a single measure
    of a model’s performance in classification tasks, including image classification.
    It takes into account both the false positives and false negatives to assess the
    balance between precision and recall. The F1 score is calculated by F 1 s c o
    r e = 2 ∗ ( P r e c i s i o n ∗ R e c a l l ) / ( P r e c i s i o n + R e c a
    l l ) . 4.3.6 ROC curve The ROC curve is created by plotting the true positive
    rate (TPR) against the false positive rate (FPR) at various threshold settings.
    The TPR represents the recall or sensitivity (correctly predicted positive instances),
    while the FPR represents the proportion of negative instances incorrectly classified
    as positive. 4.3.7 AUC The AUC measures the performance of a model in terms of
    its ability to discriminate between positive and negative instances across different
    classification thresholds. 5 Image approach: fruit fly detection Identifying the
    olive fruit fly in the e-trap images involved a number of challenges. The first
    was the lack of images available to train and validate the AI model. The second
    was the ability to distinguish the olive fruit fly from other fly families or
    dark elements that might appear in the images. Finally, the third was related
    to the processing power and energy consumption allocated for inference, in this
    case the target device was a Raspberry Pi B+. The usual way to perform this process
    of object detection on an image is usually done by applying convolutional neural
    networks (CNNs). An example of this is the recent publication by Jia et al. (2023),
    where they apply the YOLOX-m network for the localization of different green fruits,
    such as green apple and green persimmon, among the leaves of trees, which can
    also be green. Other examples include the recognition and counting of bananas
    by Wu et al. (2021, 2023). The reason for applying this technique is mainly due
    to its ability to extract physical and temporal features from the images. However,
    in this paper, the CNNs path is discarded because the challenges mentioned in
    the previous section become clearly latent. State of the art CNNs require large
    datasets to train the model, which has not been available so far, and the computational
    process is expensive for some devices such as a Raspberry Pi B+ without external
    aids like a hardware accelerator. The working dataset is considered small compared
    to the usual benchmarks for these tasks. For example, MNIST with 60,000 training
    images, CIFAR-10 and CIFAR-100 with 50,000 images each or Imagenet with 1.2 million
    training images (LeCun et al. (1998); Krizhevsky and Hinton (2009); Deng et al.
    (2009)). Due to this challenge, in this article it was decided to finally apply
    classification methods based on traditional ML techniques. Although such models
    are mainly used for tabular data, present less overfitting when working with small
    amounts of data. In addition, since the model complexity is usually lower, in
    general, power consumption is lower too. Table 4 shows the different models tested
    in a first step. It is observed that for the same set of training data and all
    the metrics of the ML models are clearly superior to those of the DL models. Therefore,
    it was decided to investigate the different ML models in more detail. table 4
    Table 4 Olive fly classification performance metrics for different traditional
    ML and DL approaches. The use of ML techniques for image processing is not new,
    Wang et al. (2021) concluded that traditional ML has a better solution effect
    on small sample data sets. Researchers such as Mekha and Teeyasuksaet (2021) have
    already studied the use of different ML algorithms for the detection of diseases
    in rice leaves, concluding that the application of RF was the one that gave them
    the best results. Another example are Liu et al. (2017), which proposes the use
    of the SVM algorithm for image classification in remote locations, as in our case,
    instead of using DL. Performing fly detection with traditional ML methods was
    a new challenge. Some pre-trained DL models for object detection already have
    this built-in function, capable of locating and classifying objects, as well as
    understanding the overlap between different possible locations of the same object
    (Milioto et al. (2018); Prasetyo et al. (2020); Rong et al. (2022)). In our case,
    the solution was to first apply image processing that takes advantage of the contrast
    between the yellow background of the trap and the dark color of the fly to distinguish
    where the different elements to be classified appear. Finally, all that remained
    was the ML classification process for each of the elements found. Since RF and
    SVM gave the top-2 better performance metrics compared to other models, it was
    decided to combine them to improve classification performance. Therefore, it is
    validated that the element is an olive fruit fly if both models assert that the
    element is an olive fruit fly. Figure 5 shows the logical flow. First, the image
    is captured. Second, the image is processed by segmenting the trap to avoid possible
    false positives and locating the elements that appear in the e-trap. Third, each
    element is classified one by one by applying RF and SVM. Finally, if both validate
    the classification, it is marked on the image. figure 5 Figure 5 Inference pipeline.
    6 Results This section presents the results of the study. In the previous points,
    it was mentioned that CNNs are not able to provide accurate results due to the
    small training dataset. Therefore, classical ML solutions are compared with CNNs
    solutions. 6.1 Machine learning and deep leaning results As mentioned above, the
    challenges of the project were: mainly how to deal with the limited training data
    available, and also whether it is possible to develop an accurate classifier model
    taking into account the low computational capacity of the Raspberry Pi B+. Table
    1 shows the metrics of the different models proposed in the first phase of the
    project. As evident from the analysis, there are six evaluated models, comprising
    three classical ML algorithms and three CNN models. The ML algorithms are the
    already mentioned RF and SVM, and also the Decision Tree algorithm, which already
    includes the RF, as mentioned above. On the other hand, the CNNs include the VGG16,
    Mobilenet, and Xception models (Simonyan and Zisserman (2014); Howard et al. (2017);
    Chollet (2017)). Models that are widely used for image classification due to their
    good results. For example, the work of Subramanian and Sankar (2022), where they
    compare this CNN model and others for coconut maturity detection. Or the work
    of Sehree and Khidhir (2022) that classifies olive trees from unmanned aerial
    vehicle images. Looking at Table 4, the superiority of the ML becomes evident,
    maintaining an accuracy of no less than 75%, compared to the DL, which does not
    achieve more than 60% accuracy in any case due to the limited availability of
    data. As mentioned in section 3.2 Dataset Generation, the validation data come
    from N10, so the metrics will always tend to be higher than the test metrics,
    which comes from e-traps unknown to the model. Table 4 also shows the AUC value,
    DL models tend to be around 0.5, which could lead us to think that they are doing
    a random classification. At this point, it was decided to take the two best results
    and test them as if the system was already in production. 6.2 Random forest and
    support vector machines analysis Figure 6 shows the results of the two-week evolution
    of trap N17 from no flies to six flies. The Figure 6A refers to the true positives
    (TP), i.e. the correct classification of the olive fly by the different models.
    And the Figures 6B, C refer to the false classifications of the fly, the false
    positives (FP) refer to the elements that the model classified as flies and they
    are not, and the false negatives (FN) refer to the elements that are flies and
    the model discarded them. The final hyperparameters used in RF were: max depth
    of 20, min samples split equal to 5, and 3 estimators. And the final SVM hyperparameters
    were A polynomial kernel, C equal to 0.1, and gamma equal to 1. figure 6 Figure
    6 Evolution of the number of olive flies detected in the sticky trap as a function
    of time using different ML classifiers for the N17 e-trap. (A) TP evolution of
    RF classifier, SVM classifier and their combination together with the real count.
    (B) FP evolution of the same classifiers. (C) FN evolution of the same classifiers.
    6.2.1 RF classifier This model tends to classify most items that resemble an olive
    fruit fly as “Olive Fly”. After examining the images, one may conclude this is
    because the RF model is not able to differentiate whether a fly belongs to the
    olive fruit fly species or not, so its FP rate tends to rise and conversely the
    FNs are very low. 6.2.2 SVM classifier The graphs show how this model is more
    cautious about RF in determining whether an object is an olive fly or not. Therefore,
    its FP rate is lower, but it increases the FN discriminating flies that were correct.
    6.2.3 RF+SVM classifier Finally, combining the two models allows for more accurate
    classification. The FNs go down even further, in exchange for the fact that if
    an item is claimed to be a olive fly, it is much more likely to be so. 7 Discussion
    In this study, an intelligent system capable of detecting the olive fly using
    non-invasive techniques was developed. Two models were created with an accuracy
    of 62.1% for RF and 86.4% for SVM, Figure 7A, using only the data of two traps,
    one for training and the other to validate the models. figure 7 Figure 7 RF and
    SVM metrics on the N17 image from the 11th of October. (A) Confusion matrix comparison
    of RF, SVM, and “RF+SVM” models for olive fly classification. (B) Confusion matrix
    comparison of RF and SVM models for classification of all fly species. While RF
    would be the first to warn of a possible fly infestation. SVM proved to be more
    conservative in stating whether or not there was a fly in the sticky trap. In
    addition, a third option was also presented too, the combination of both models
    to be able to combine the best of each and achieve a higher accuracy of 89.1%,
    as shown in Figure 7A. It has been shown that it is also possible to control the
    olive fly using classical ML techniques. Allowing deploy this intelligent systems
    faster than if the detection were performed using CNN techniques. And consequently
    understand the status of the crops before and remotely observe the evolution of
    the fly population, Figure 6A. In addition, the robustness achieved using ML is
    reflected in Figure 7B. Here, the performance of both models is shown when trying
    to classify only flies, regardless of the species. As can be seen, the accuracy
    of both algorithms increases to 91.9% for RF and 94.5% for SVM. Therefore, this
    project demonstrates the application of ML on an e-trap system that facilitates
    the control tasks to the experts, being able to reduce the number of times they
    should go to the fields to make the manual count of the flies, as well as providing
    additional information not to go blindly. Thus providing an improvement compared
    to the previous article of this same project of Miranda et al. (2019). This opens
    a horizon for new challenges where, if the size of the data set and the computational
    capabilities of the system are not optimal, as is often the case in specific systems
    such as the trap described, combined ML techniques can be explored for image classification
    on remote devices. In addition to the benefits described above, the application
    of ML strategies opens up new possibilities for the system. Once the model is
    trained, the device performs the prepreocessing and inference on the image data,
    but only the prediction is exchanged with the server. In this regard, it is also
    worth mentioning the advantages in terms of privacy, e.g. there is no risk related
    to identifying people in images sent to the server. Since no images are shared
    with the server, it also represents an improvement in terms of privacy. Moreover,
    these models are relatively small compared to state-of-the-art neural networks
    and might be running on small IoT devices, such as Raspberry Pi B+ used in this
    case, or even smaller very low power microcontroller boards. Overall, it implies
    a reduction in power and energy consumption and an increase in battery life. All
    this is possible by making a more efficient use of bandwidth. Finally, it is important
    to note that the data source used has come from a single e-trap system, so the
    system has the potential to increase the accuracy of the results as the system
    of nodes grows while each e-trap system can learn specific details of the conditions
    that make it unique. 8 Conclusions The main contributions of this study are threefold:
    development of an intelligent system for efficient crop monitoring, demonstrating
    superior performance of ML methods over DL for this particular case study, and
    further improving performance using a simple model ensembling approach. An intelligent
    system capable of detecting the olive fly using non-invasive techniques was successfully
    developed. The system is capable of monitoring the fly and olive fly population
    using image processing and ML techniques. This enabled experts to remotely monitor
    the status and evolution of the fly population, thereby reducing the need for
    manual fly counts in the fields. Since a relatively small dataset was available,
    the application of classical ML techniques worked better compared to a transfer
    learning approach using pre-trained DL models. The study revealed that classical
    ML models (RF and SVM) outperformed CNN solutions in this case. Despite the scarcity
    of images, these models demonstrated good accuracy, making them an attractive
    option for resource-constrained applications. In particular, the RF and SVM models
    reported an accuracy of 62.1% and 86.4% for the olive fly detection task, respectively.
    In addition, the RF and SVM approaches reported an accuracy of 91.9% and 94.5%,
    respectively, when classifying only flies, regardless of the species. Finally,
    the model performance was further improved by combining both RF and SVM models.
    RF was found to be more sensitive in detecting a potential fly infestation, while
    SVM demonstrated a more cautious approach in stating whether a fly was present
    in the sticky trap. As a result, combining both models led to an increased accuracy
    of 89.1% for the olive fly detection task. In conclusion, this research showcases
    the successful implementation of ML in an e-trap system for olive fly detection,
    providing valuable insights and benefits. The combination of RF and SVM models
    demonstrated promising results, offering more efficient crop monitoring and control
    tasks to the experts. The potential for using small IoT devices for image classification
    opens up new possibilities, emphasizing the significance of ML in optimizing resource
    usage and enhancing privacy protection. As the system grows by increasing the
    number of e-traps, more data will be available. Therefore, it holds the potential
    to further enhance accuracy by learning from multiple e-trap systems, making it
    a promising tool for effective and sustainable fly population management. Data
    availability statement The raw data supporting the conclusions of this article
    will be made available by the authors, without undue reservation. Author contributions
    MM-R, MM and BA-L contributed to conception of the study. MM-R and BA-L contributed
    to the design of the study MM-R organized the datasets and performed the experimental
    analysis. MM-R wrote the first draft of the manuscript. MM-R, MM, AM, and BA-L
    wrote sections of the manuscript. All authors contributed to manuscript revision,
    read, and approved the submitted version. Funding This work has been partially
    sponsored and promoted by the Comunitat Autonoma de les Illes Balears through
    the Direcció General de Recerca, Innovació I Transformació Digital and the Conselleria
    de Economia, Hisenda I Innovació and by the European Union- Next Generation UE
    (BIO/016 A.2). Nevertheless, the views and opinions expressed are solely those
    of the author or authors, and do not necessarily reflect those of the European
    Union or the European Commission. Neither the European Union nor the European
    Commission are to be held responsible. Conflict of interest The authors declare
    that the research was conducted in the absence of any commercial or financial
    relationships that could be construed as a potential conflict of interest. Publisher’s
    note All claims expressed in this article are solely those of the authors and
    do not necessarily represent those of their affiliated organizations, or those
    of the publisher, the editors and the reviewers. Any product that may be evaluated
    in this article, or claim that may be made by its manufacturer, is not guaranteed
    or endorsed by the publisher. References Bjerge, K., Alison, J., Dyrmann, M.,
    Frigaard, C. E., Mann, H. M., Høye, T. T. (2023). Accurate detection and identification
    of insects from camera trap images with deep learning. PloS Sustainabil Transform
    2, e0000051. doi: 10.1371/journal.pstr.0000051 CrossRef Full Text | Google Scholar
    Bradski, G. (2000). The openCV library. Dr. Dobb’s Journal: Software Tools for
    the Professional Programmer 25 (11), 120–123. Google Scholar Breiman, L. (2001).
    Random forests. Mach. Learn. 25, (11), p. 120–123. doi: 10.1023/A:1010933404324
    CrossRef Full Text | Google Scholar Brilhador, A., Gutoski, M., Hattori, L. T.,
    de Souza Inacio,´, A., Lazzaretti, A. E., Lopes, H. S. (2019). “Classification
    of weeds and crops at the pixel-level using convolutional neural networks and
    data augmentation,” in 2019 IEEE latin american conference on computational intelligence
    (LA-CCI) (Guayaquil, Ecuador: IEEE), 1–6. Google Scholar Chollet, F. (2017). “Xception:
    Deep learning with depthwise separable convolutions,” in Proceedings of the IEEE
    conference on computer vision and pattern recognition (Honolulu, USA: IEEE Computer
    Society), 1251–1258. Google Scholar Deng, J., Dong, W., Socher, R., Li, L.-J.,
    Li, K., Fei-Fei, L. (2009). “Imagenet: A large-scale hierarchical image database,”
    in 2009 IEEE conference on computer vision and pattern recognition (Miami, Florida:
    Ieee), 248–255. Google Scholar Dias, N. P., Zotti, M. J., Montoya, P., Carvalho,
    I. R., Nava, D. E. (2018). Fruit fly management research: A systematic review
    of monitoring and control tactics in the world. Crop Prot. 112, 187–200. doi:
    10.1016/j.cropro.2018.05.019 CrossRef Full Text | Google Scholar Ding, G., Qiao,
    Y., Yi, W., Fang, W., Du, L. (2021). Fruit fly optimization algorithm based on
    a novel fluctuation model and its application in band selection for hyperspectral
    image. J. Ambient. Intell. Humanized. Computing. 12, 1517–1539. doi: 10.1007/s12652-020-02226-1
    CrossRef Full Text | Google Scholar Fasih, S. M., Ali, A., Mabood, T., Ullah,
    A., Hanif, M., Ahmad, W. (2023). “Fruit fly detection and classification in iot
    setup,” in International conference on computational science and its applications
    (Athens, Greece: Springer), 593–607. Google Scholar Fawakherji, M., Potena, C.,
    Prevedello, I., Pretto, A., Bloisi, D. D., Nardi, D. (2020). “Data augmentation
    using gans for crop/weed segmentation in precision farming,” in 2020 IEEE conference
    on control technology and applications (CCTA) (Sheraton Downtown, Canada: IEEE),
    279–284. Google Scholar Goldshtein, E., Gazit, Y., Hetzroni, A., Timar, D., Rosenfeld,
    L., Grinshpon, Y., et al. (2021). Long-term automatic trap data reveal factors
    affecting diurnal flight patterns of the mediterranean fruit fly. J. Appl. Entomo.
    145, 427–439. doi: 10.1111/jen.12867 CrossRef Full Text | Google Scholar Grasswitz,
    T. (2019). Integrated pest management (ipm) for small-scale farms in developed
    economies: Challenges and opportunities. insects 10, 179. doi: 10.3390/insects10060179
    PubMed Abstract | CrossRef Full Text | Google Scholar Howard, A. G., Zhu, M.,
    Chen, B., Kalenichenko, D., Wang, W., Weyand, T., et al. (2017). Mobilenets: Efficient
    convolutional neural networks for mobile vision applications. arXiv. preprint.
    arXiv:1704.04861. doi: 10.48550/arXiv.1704.04861 CrossRef Full Text | Google Scholar
    Jia, W., Xu, Y., Lu, Y., Yin, X., Pan, N., Jiang, R., et al. (2023). An accurate
    green fruits detection method based on optimized yolox-m. Front. Plant Sci. 14,
    1411. doi: 10.3389/fpls.2023.1187734 CrossRef Full Text | Google Scholar Jost,
    L. (2006). Entropy and diversity. Oikos 113, 363–375. doi: 10.1111/j.2006.0030-1299.14714.x
    CrossRef Full Text | Google Scholar Kernighan, B. W., Pike, R. (1984). The UNIX
    programming environment Vol. 270 (Hoboken, New Jersey, U.S.: Prentice-Hall Englewood
    Cliffs, NJ). Google Scholar Krizhevsky, A., Hinton, G. (2009). Learning Multiple
    Layers of Features from Tiny Images. (Toronto, Ontario: University of Toronto).
    Available at: https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf.
    Google Scholar Krizhevsky, A., Sutskever, I., Hinton, G. E. (2017). Imagenet classification
    with deep convolutional neural networks. Commun. ACM 60, 84–90. doi: 10.1145/3065386
    CrossRef Full Text | Google Scholar Langs, G., Menze, B. H., Lashkari, D., Golland,
    P. (2011). Detecting stable distributed patterns of brain activation using gini
    contrast. NeuroImage 56, 497–507. doi: 10.1016/j.neuroimage.2010.07.074 PubMed
    Abstract | CrossRef Full Text | Google Scholar LeCun, Y., Bottou, L., Bengio,
    Y., Haffner, P. (1998). Gradient-based learning applied to document recognition.
    Proc. IEEE 86, 2278–2324. doi: 10.1109/5.726791 CrossRef Full Text | Google Scholar
    Liu, P., Choo, K.-K. R., Wang, L., Huang, F. (2017). Svm or deep learning? a comparative
    study on remote sensing image classification. Soft. Computing. 21, 7053–7065.
    doi: 10.1007/s00500-016-2247-2 CrossRef Full Text | Google Scholar Martins, V.
    A., Freitas, L. C., de Aguiar, M. S., de Brisolara, L. B., Ferreira, P. R. (2019).
    “Deep learning applied to the identification of fruit fly in intelligent traps,”
    in 2019 IX Brazilian symposium on computing systems engineering (SBESC) (Natal,
    Brazil: IEEE), 1–8. Google Scholar Mekha, P., Teeyasuksaet, N. (2021). “Image
    classification of rice leaf diseases using random forest algorithm,” in 2021 joint
    international conference on digital arts, media and technology with ECTI northern
    section conference on electrical, electronics, computer and telecommunication
    engineering (IEEE), 165–169. Google Scholar Milioto, A., Lottes, P., Stachniss,
    C. (2018). “Real-time semantic segmentation of crop and weed for precision agriculture
    robots leveraging background knowledge in cnns,” in 2018 IEEE international conference
    on robotics and automation (ICRA) (Brisbane, Australia: IEEE), 2229–2235. Google
    Scholar Miranda, M. Á., Barceló, C., Valdés, F., Feliu, J. F., Nestel, D., Papadopoulos,
    N., et al. (2019). Developing and implementation of decision support system (dss)
    for the control of olive fruit fly, bactrocera oleae, in mediterranean olive orchards.
    Agronomy 9, 620. doi: 10.3390/agronomy9100620 CrossRef Full Text | Google Scholar
    Pontikakos, C. M., Tsiligiridis, T. A., Yialouris, C. P., Kontodimas, D. C. (2012).
    Pest management control of olive fruit fly (bactrocera oleae) based on a location-aware
    agro-environmental system. Comput. Electron. Agric. 87, 39–50. doi: 10.1016/j.compag.2012.05.001
    CrossRef Full Text | Google Scholar Prasetyo, E., Suciati, N., Fatichah, C. (2020).
    “A comparison of yolo and mask r-cnn for segmenting head and tail of fish,” in
    2020 4th international conference on informatics and computational sciences (ICICoS)
    (Semarang, Indonesia: IEEE), 1–6. Google Scholar Reay-Jones, F. P., Greene, J.
    K., Bauer, P. J. (2019). Spatial distributions of thrips (thysanoptera: Thripidae)
    in cotton. J. Insect Sci. 19, 3. doi: 10.1093/jisesa/iez103 CrossRef Full Text
    | Google Scholar Rong, M., Wang, Z., Ban, B., Guo, X. (2022). Pest identification
    and counting of yellow plate in field based on improved mask r-cnn. Discrete.
    Dynamics. Nat. Soc. 2022, 1–9. doi: 10.1155/2022/1913577 CrossRef Full Text |
    Google Scholar Sánchez, A. V. D. (2003). Advanced support vector machines and
    kernel methods. Neurocomputing 55, 5–20. doi: 10.1016/S0925-2312(03)00373-4 CrossRef
    Full Text | Google Scholar Sehree, N. A., Khidhir, A. M. (2022). Olive trees cases
    classification based on deep convolutional neural network from unmanned aerial
    vehicle imagery. Indonesian. J. Electrical. Eng. Comput. Sci. 27, 92. doi: 10.11591/ijeecs.v27.i1.pp92-101
    CrossRef Full Text | Google Scholar Shah, F., Wu, W. (2019). Soil and crop management
    strategies to ensure higher crop productivity within sustainable environments.
    Sustainability 11, 1485. doi: 10.3390/su11051485 CrossRef Full Text | Google Scholar
    Shorten, C., Khoshgoftaar, T. M. (2019). A survey on image data augmentation for
    deep learning. J. big. Data 6, 1–48. doi: 10.1186/s40537-019-0197-0 CrossRef Full
    Text | Google Scholar Simonyan, K., Zisserman, A. (2014). Very deep convolutional
    networks for large-scale image recognition. arXiv. preprint. arXiv:1409.1556.
    doi: 10.48550/arXiv.1409.1556 CrossRef Full Text | Google Scholar Subramanian,
    P., Sankar, T. S. (2022). “Coconut maturity recognition using convolutional neural
    network,” in Computer vision and machine learning in agriculture, volume 2 (Singapore,
    Singapore: Springer), 107–120. Google Scholar Uzun, Y. (2023). An intelligent
    system for detecting mediterranean fruit fly [medfly; ceratitis capitata (wiedemann)].
    (Aksaray, Turkey: Aksaray Üniversitesi Fen Bilimleri Enstitüsü). Google Scholar
    Vapnik, V. N., Chervonenkis, A. Y. (2015). “On the uniform convergence of relative
    frequencies of events to their probabilities,” in Measures of complexity: festschrift
    for alexey chervonenkis (New York, USA: Springer Publishing company), 11–30. Google
    Scholar Victoriano, M., Oliveira, L., Oliveira, H. P. (2023). “Automated detection
    and identification of olive fruit fly using yolov7 algorithm,” in Iberian conference
    on pattern recognition and image analysis (Alicante, Spain: Springer), 211–222.
    Google Scholar Wang, P., Fan, E., Wang, P. (2021). Comparative analysis of image
    classification algorithms based on traditional machine learning and deep learning.
    Pattern Recognition. Lett. 141, 61–67. doi: 10.1016/j.patrec.2020.07.042 CrossRef
    Full Text | Google Scholar Wu, F., Duan, J., Chen, S., Ye, Y., Ai, P., Yang, Z.
    (2021). Multi-target recognition of bananas and automatic positioning for the
    inflorescence axis cutting point. Front. Plant Sci. 12, 705021. doi: 10.3389/fpls.2021.705021
    PubMed Abstract | CrossRef Full Text | Google Scholar Wu, F., Yang, Z., Mo, X.,
    Wu, Z., Tang, W., Duan, J., et al. (2023). Detection and counting of banana bunches
    by integrating deep learning and classic image-processing algorithms. Comput.
    Electron. Agric. 209, 107827. doi: 10.1016/j.compag.2023.107827 CrossRef Full
    Text | Google Scholar Keywords: precision agriculture, olive fruit fly pest, machine
    learning, support vector machine, random forest, computer vision, edge computing,
    remote sensing Citation: Molina-Rotger M, Morán A, Miranda MA and Alorda-Ladaria
    B (2023) Remote fruit fly detection using computer vision and machine learning-based
    electronic trap. Front. Plant Sci. 14:1241576. doi: 10.3389/fpls.2023.1241576
    Received: 16 June 2023; Accepted: 18 September 2023; Published: 10 October 2023.
    Edited by: Liangliang Yang, Kitami Institute of Technology, Japan Reviewed by:
    Yunchao Tang, Guangxi University, China Ebenezer Olaniyi, Mississippi State University,
    United States Copyright © 2023 Molina-Rotger, Morán, Miranda and Alorda-Ladaria.
    This is an open-access article distributed under the terms of the Creative Commons
    Attribution License (CC BY). The use, distribution or reproduction in other forums
    is permitted, provided the original author(s) and the copyright owner(s) are credited
    and that the original publication in this journal is cited, in accordance with
    accepted academic practice. No use, distribution or reproduction is permitted
    which does not comply with these terms. *Correspondence: Miguel Molina-Rotger,
    miguel.molina@uib.es; Bartomeu Alorda-Ladaria, tomeu.alorda@uib.es Disclaimer:
    All claims expressed in this article are solely those of the authors and do not
    necessarily represent those of their affiliated organizations, or those of the
    publisher, the editors and the reviewers. Any product that may be evaluated in
    this article or claim that may be made by its manufacturer is not guaranteed or
    endorsed by the publisher. Footer Guidelines Author guidelines Editor guidelines
    Policies and publication ethics Fee policy Explore Articles Research Topics Journals
    Outreach Frontiers Forum Frontiers Policy Labs Frontiers for Young Minds Connect
    Help center Emails and alerts Contact us Submit Career opportunities Follow us
    © 2024 Frontiers Media S.A. All rights reserved Privacy policy | Terms and conditions
    We use cookies Our website uses cookies that are necessary for its operation and
    other cookies to track its performance or to improve and personalize our services.
    To manage or reject non-essential cookies, please click \"Cookies Settings\".
    For more information on how we use cookies, please see ourCookie Policy Cookies
    Settings Accept Cookies"'
  inline_citation: '>'
  journal: Frontiers in Plant Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Remote fruit fly detection using computer vision and machine learning-based
    electronic trap
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Alanazi B.A.
  - Alrashdi I.
  citation_count: '0'
  description: Neutrosophic sets have emerged as a powerful tool for addressing uncertainty
    and imprecision in diverse domains, and their potential in anomaly detection within
    smart farming systems is the central focus of this paper. We present a cutting-edge
    Neutrosophic Approach to Edge-Based Anomaly Detection, specifically designed to
    cater to the intricacies of smart farming data. By harnessing the unique attributes
    of single-valued neutrosophic sets, in conjunction with single-valued neutrosophic
    decision matrices, our methodology adeptly handles the challenges posed by uncertain,
    dynamic, and multi-dimensional farm data. Through a comprehensive analysis of
    sample data, we illustrate the precision and adaptability of our approach, allowing
    for the quantification of intricate attribute relationships and the precise identification
    of anomalies. By employing neutrosophic statistics and a weighted correlation
    coefficient, our approach provides profound insights into the complex interactions
    within smart farming systems. This research stands as a pivotal contribution within
    the scope of neutrosophic-based anomaly detection, promising to advance the state
    of the art in the realm of precision agriculture.
  doi: 10.5281/zenodo.8404455
  full_citation: '>'
  full_text: '>

    "Skip to main Planned intervention: On Thursday March 28th 07:00 UTC Zenodo will
    be unavailable for up to 5 minutes to perform a database upgrade. Communities
    My dashboard Log in Sign up Published October 3, 2023 | Version v1 Journal article
    Open A Neutrosophic Approach to Edge-Based Anomaly Detection in Smart Farming
    Systems Creators Bandar A Alanazi Ibrahim Alrashdi Description Neutrosophic sets
    have emerged as a powerful tool for addressing uncertainty and imprecision in
    diverse domains, and their potential in anomaly detection within smart farming
    systems is the central focus of this paper. We present a cutting-edge Neutrosophic
    Approach to Edge-Based Anomaly Detection, specifically designed to cater to the
    intricacies of smart farming data. By harnessing the unique attributes of single-valued
    neutrosophic sets, in conjunction with single-valued neutrosophic decision matrices,
    our methodology adeptly handles the challenges posed by uncertain, dynamic, and
    multi-dimensional farm data. Through a comprehensive analysis of sample data,
    we illustrate the precision and adaptability of our approach, allowing for the
    quantification of intricate attribute relationships and the precise identification
    of anomalies. By employing neutrosophic statistics and a weighted correlation
    coefficient, our approach provides profound insights into the complex interactions
    within smart farming systems. This research stands as a pivotal contribution within
    the scope of neutrosophic-based anomaly detection, promising to advance the state
    of the art in the realm of precision agriculture. Files NeutrosophicAnomalyDetection13.pdf
    Files (626.0 kB) Name Size Download all NeutrosophicAnomalyDetection13.pdf md5:89d7ba5505a2c46e5044ed87e61c72fe
    626.0 kB Preview Download Citations Show only: Literature (0) Dataset (0) Software
    (0) Unknown (0) Citations To This Version Search No citations found 38 VIEWS 30
    DOWNLOADS Show more details Versions Version v1 10.5281/zenodo.8404455 Oct 3,
    2023 Cite all versions? You can cite all versions by using the DOI 10.5281/zenodo.8404454.
    This DOI represents all versions, and will always resolve to the latest one. Read
    more. External resources Indexed in OpenAIRE Keywords and subjects Neutrosophic
    Logic; Edge Computing; Anomaly Detection; Smart Farming; Sensor Networks; Agricultural
    IoT; MCDM; Neutrosophic Sets. Details DOI Resource type Journal article Publisher
    Zenodo Rights Creative Commons Attribution 4.0 International Citation Bandar A
    Alanazi, & Ibrahim Alrashdi. (2023). A Neutrosophic Approach to Edge-Based Anomaly
    Detection in Smart Farming Systems. https://doi.org/10.5281/zenodo.8404455 Style
    APA Export JSON Export Technical metadata Created October 3, 2023 Modified October
    5, 2023 Jump up About About Policies Infrastructure Principles Projects Roadmap
    Contact Blog Blog Help FAQ Docs Guides Support Developers REST API OAI-PMH Contribute
    GitHub Donate Funded by Powered by CERN Data Centre & InvenioRDM Status Privacy
    policy Cookie policy Terms of Use Support This site uses cookies. Find out more
    on how we use cookies Accept all cookies Accept only essential cookies"'
  inline_citation: '>'
  journal: Neutrosophic Sets and Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Neutrosophic Approach to Edge-Based Anomaly Detection in Smart Farming
    Systems
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Mattia G.P.
  - Beraldi R.
  citation_count: '0'
  description: Green-powered edge computing architectures allow bringing computation
    in areas that are not reached by the power grids. More often, in applications
    for Precision Agriculture and Smart Cities, we could have a set of nodes that
    are coupled with an accumulator which is, during the day, re-charged by the energy
    harvested by small solar panels. With the latest advances in technology, the edge
    node is generally assimilated to be a low-power Single Board Computer (SBC), and
    it is able to carry out even relatively demanding tasks. For example, it can run
    deep learning models to images or video sequences captured in loco by cameras.
    However, due to the differences in terms of power consumption and weather conditions,
    each node experiences a different lifespan, some nodes may even shut down prematurely,
    causing the interruption of the portion of the deployed service. In this paper,
    we propose three decentralized algorithms that solve the problem by making the
    nodes cooperatively balance the traffic in order to level and maximize their lifespan.
    By comparing the approaches in two different experiments by using a cluster of
    Raspberry Pi 4 we show that our solutions allow to increase the lifespan of the
    service of 10% on average wrt the case in which no algorithm is applied.
  doi: 10.1109/CloudSummit57601.2023.00013
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 IEEE Cloud Summit Lifespan and energy-oriented
    load balancing algorithms across sets of nodes in Green Edge Computing Publisher:
    IEEE Cite This PDF Gabriele Proietti Mattia; Roberto Beraldi All Authors 53 Full
    Text Views Abstract Document Sections I. Introduction II. Related Work III. Model
    & Metrics IV. Proposed Algorithms V. Experimental Results Show Full Outline Authors
    Figures References Keywords Metrics Footnotes Abstract: Green-powered edge computing
    architectures allow bringing computation in areas that are not reached by the
    power grids. More often, in applications for Precision Agriculture and Smart Cities,
    we could have a set of nodes that are coupled with an accumulator which is, during
    the day, re-charged by the energy harvested by small solar panels. With the latest
    advances in technology, the edge node is generally assimilated to be a low-power
    Single Board Computer (SBC), and it is able to carry out even relatively demanding
    tasks. For example, it can run deep learning models to images or video sequences
    captured in loco by cameras. However, due to the differences in terms of power
    consumption and weather conditions, each node experiences a different lifespan,
    some nodes may even shut down prematurely, causing the interruption of the portion
    of the deployed service. In this paper, we propose three decentralized algorithms
    that solve the problem by making the nodes cooperatively balance the traffic in
    order to level and maximize their lifespan. By comparing the approaches in two
    different experiments by using a cluster of Raspberry Pi 4 we show that our solutions
    allow to increase the lifespan of the service of 10% on average wrt the case in
    which no algorithm is applied. Published in: 2023 IEEE Cloud Summit Date of Conference:
    06-07 July 2023 Date Added to IEEE Xplore: 10 August 2023 ISBN Information: DOI:
    10.1109/CloudSummit57601.2023.00013 Publisher: IEEE Conference Location: Baltimore,
    MD, USA SECTION I. Introduction Single Board Computers (SBCs) that are generally
    small in size and have non-negligible computational power, are often suitable
    to be put in strategic positions, for example, in a Smart City [1] thus concretizing
    the Edge Computing paradigm. Moving the computation to the Edge enables the possibility
    of drastically reducing processing latency since it avoids the necessity of sending
    the data to process in the cloud. The computational power available in the Edge
    is limited but its peculiar characteristic is that it is efficient in terms of
    the number of operations that (TOPS) can be carried out per Watt [2]). Moreover,
    the energy profile is usually restrained and they require an amount of power that
    can be easily harvested by modern solar panels (Figure 1). In recent years, renewable
    energies have become a prominent research topic, and they particularly fit the
    context of Edge Computing [3], thus enabling Green Edge Computing. In our work,
    we consider sets of Edge nodes in which one or more services can be deployed.
    We assume that the power grid is not accessible, this can be the case of rural
    areas which need to be actively monitored, or even in specific zones of Smart
    Cities in which the cost of bringing the power grid can be relevant. The solution
    that we envision is that by using solar energy, nodes can exploit energy harvesting
    (EH) by themselves. Fig. 1. Scheme of a set of Edge nodes which are coupled with
    a solar panel and an accumulator (Energy Harvesting technique). The core idea
    for balancing the energy is offloading a portion of the tasks which a node has
    to perform to neighbors which have more energy in the batteries, in this case
    nodes F, E and D. Show All As anticipated, Edge nodes are characterized by two
    essential traits: (i) they require low operation power, usually ranging from about
    10W (Raspberry Pi 41) to 60W (nVidia Jetson AGX Orin 64GB2) and (ii) they have
    non-neglibible computing power which can also be used to run deep learning inference
    [4], [5]. We indeed imagine, as a use case, that each node is coupled with a camera
    and then it has to perform some deep learning task on the captured images or videos.
    The node can also be equipped with special processors (like TPUs or NPUs) which
    can carry out ML tasks with very high energy efficiency. We suppose no central
    entity in our environment, so each node can only interact with its neighbors and
    the interaction takes the form of offloading thus enabling cooperation. Indeed,
    each node is requested to perform a certain number of tasks per second (at rate
    λ ) which can for example supposed to be frame processing, and if needed, it can
    offload a portion of this rate to neighbors. Since each node is characterized
    by a specific amount of residual battery energy, which determines its lifespan,
    in order to increase the availability of the service, nodes need to balance their
    energy consumption. It can be easily shown that what dominates the energy consumption
    is the rate λ , therefore the task offloading causes a decrease of energy consumption
    in the node which forwards the tasks and an increase in the one which receives
    them. Figure 1 shows a simplified environment characterized by a set of Edge nodes
    that are inter-connected and, for example, Nodes F, E and D forward their traffic
    to a given neighbor. Then, we also need to consider that Edge nodes are heterogeneous,
    they have different rates of task execution3 (which we call μ ) and different
    energy consumptions, therefore there is the need to design an algorithm which
    finds the correct amount of tasks that each node needs to offload to others to
    maximize the lifespan of the service in the long run and possibly avoiding a node’s
    shutdown due to low battery. The contributions of this paper can be summarized
    as follows: design of three decentralized algorithms which balance the energy
    consumption of the nodes by relying on cooperative tasks offloading; benchmark
    of the algorithms in a cluster of 11 Raspberry Pi 4 SBCs by using the FaaS as
    task model and the P2PFaaS [6] framework for the implementation; definition of
    a set of performance metrics targeting the behavior of the algorithms with respect
    to service availability, lifespan and lifespan variance; comparison of the algorithm
    both in a standalone scenario and in a solar panel assisted scenario [7] which
    solar energy traces from real panels The rest of the paper is organized as follows.
    In Section II we compare our work to other similar works in literature which address
    energy and load balancing in Edge Computing, in Section III we provide the model
    of the system and the performance evaluation metrics, then in Section IV we illustrate
    the proposed algorithms and in Section V we provide the performance comparison
    of the algorithms in the experimental setting. Finally, we draw the conclusions
    in Section VI. Table I shows all the symbols used in the paper. SECTION II. Related
    Work This paper aims to design distributed and decentralized algorithms which
    exploit load balancing for adjusting the energy consumption of nodes in Fog and
    Edge Computing with the final objective of extending the lifespan of the nodes
    and, as a consequence, of the service itself. We present in this section a series
    of similar works that target energy-aware load balancing. We can define a first
    set of works that target low-level packet routing and load balancing by taking
    into consideration the energy aspect. Adil et al., for example, in [8] focus on
    Wireless Sensor Networks (WSNs) which are networks characterized by nodes that
    are usually powered by batteries and therefore they must efficiently communicate
    over the network to maximize the lifespan. The authors indeed propose an energy-efficient
    load balancing scheme that is based on Energy Gauge Nodes (EGNs) which advertise
    the residual energy of the nodes and this information is used for performing a
    uniform load balancing of packets. A similar approach is followed by Sampayo et
    al. [9] which explores the usage of wake-up radio which has ultra-low power consumption,
    and Ali et al. [10] which exploits clusters energy balanced nodes. Differently
    from our work, the authors of these works are not specifically targeting Edge
    and Fog Computing, in which the nodes are not only sensors but can actively execute
    the whole or part of the computation, moreover, we also consider the green energy
    sources. The second set of works instead more specifically regards Green Edge
    Computing [11]. In particular, Lyu et al. in [12] propose an architecture that
    integrates the Cloud, the MEC (Mobile Edge Computing) layer and the IoT for implementing
    a selective offloading algorithm that is designed to minimize the energy consumption
    of devices. However, the approach is tested only in simulation and it is not considering
    the energy contribution that is harvested from the solar panels. In [13] instead,
    the authors focus on the Internet-of-Vehicles (IoV) and propose an efficient scheduling
    framework to minimize the energy consumption of Green Roadside Units (RSUs) under
    latency constraints. Differently from our work, we hypothesize that each computing
    node has attached an accumulator, moreover, the approach that we follow is decentralized.
    Wu et al. in [14] propose an algorithm called “GLOBE’’ which performs a joint
    geographical load balancing in MEC environments where energy-harvesting nodes
    are considered. The authors show, relying on Lyapunov optimization, that the approach
    achieves a close-to-optimal result compared to an offline algorithm that knows
    the full information about the system. A similar approach is studied in [15] which
    proposes a hierarchical task offloading that optimizes latency, energy consumption
    and cloud fees. However, in these works, which only provide models and simulation,
    the decentralized approach is not considered, which is the core of our work. Similar
    approaches are then used in [16]. Other approaches focused on energy-aware task
    scheduling can be seen in [17], [18] and [19]. SECTION III. Model & Metrics We
    suppose to have a set of N edge nodes. Each node i in the set receives a constant
    rate of tasks per second to be executed which is called λ i , these tasks can
    be associated with the processing of the data generated at the node at the same
    rate, in our use case a task is an image frame processing. The same nodes can
    execute tasks at rate μ i which is again supposed to be constant over time. From
    experimental measures, we assessed that SBCs consume an approximately fixed amount
    of power when they are idle, and we call this contribution P IDLE , then there
    is another contribution that is variable since it depends on the load at time
    t which we call p l (t) . We can define the total power consumption of the node
    i at time t as: p T i (t)= P IDLE + P ι WORK (t) (1) View Source TABLE I List
    of Symbols Used In general, nodes’ variable energy consumption derives from many
    micro-operations that beyond the CPU time can regard data transmission over Ethernet
    (or WiFi), data read or written in RAM or even access to persistent storage. Without
    loss of generality, we can assume that all of these operations are proportional
    to the number of tasks that the nodes have to execute because these tasks may
    involve all the above-mentioned operations. With this assumption the contribution
    to the power consumption p l (t) is determined by the effective rate of tasks
    that the node i is executing at time t which can be seen as: x i (t)= λ i − ∑
    j∈N λ i m ij (t)+ ∑ j∈N λ j m ji (t) (2) View Source where we call m ij (t) the
    percentage of tasks generated by node i which are forwarded to j at time t in
    a cooperative manner. Since we consider small sets of edge nodes we suppose these
    nodes to be arranged in a fully connected topology and therefore the net number
    of tasks rate that a node executes is given by the tasks that it generates from
    which we subtract the rate of task offloaded and the rate of tasks received from
    the neighbors. If we call ρ i (t) the node’s load at time t ρ i (t)= x i (t) μ
    i (3) View Source and we define P WORK as the amount of power required by node
    i for a unit of load. Then, we can rewrite Equation 1 as: p T i (t)= P IDLE +
    P WORK ρ i (t) (4) View Source The value P WORK in Watts (W) can be easily extracted
    by running benchmarks on real devices. We also assume that to each node i is attached
    a battery of initial capacity B 0 i which is assumed to match the full capacity
    B i . Moreover, the battery can be recharged with the power harvested by a solar
    panel which is described by the function s i (t) . We define the law which regulates
    the residual battery capacity over time t as: b i (t)= B 0 i − ∫ t 0 p T i (t)+
    ∫ t 0 s i (t) (5) View Source We proceed to find the solution of the problem,
    which are the m ij (t) functions, by proposing three different algorithms in Section
    IV whose purpose is the one of making nodes that have less energy availability
    to forward to nodes which have more. Further development of the model is left
    as future work since in this work we focus on the effective solution applied to
    a cluster of real SBCs. A. Performance Metrics The proposed algorithms have been
    evaluated according to the following metrics: σ : the average variance between
    the battery capacities over the entire experiment. The metric allows us to measure
    how the algorithm is able to keep the batteries’ charge aligned over time. We
    divide the experiment into n equal slots of time and we measure the average battery
    capacity in every segment. In formulas, for a given node i and the j-th segment
    of time which starts from t s j to t e j we define the average battery of a node
    as: b a,i,j = 1 t e j − t s j ∫ t e j t s j b i (t) (6) View Source Then in a
    given slot j we compute the variance of the average batteries capacities as σ
    i,j = 1 j ∑ k=0 j ( b a,i,k − 1 N ∑ z=0 |N| b a,z,j ) 2 (7) View Source and finally,
    we derive the metrics which best describe the behavour of the variance during
    the experiment: σ= 1 N ∑ i=0 n σ i,j (8) View Source d f : the time in which the
    first node fully discharges and dies. Since the service becomes compromised when
    some nodes become unusable, this value indicates how long the service remains
    at full potential. The metric is described as, given T d the set of t ∗ i which
    is the time in which node i dies (for which b i ( t ∗ i )=0 ) d f =min T d (9)
    View Source d g : the time gap between the first node that reaches zero battery
    capacity value which declares its death and the last one which reaches the same
    state. The metric is describes as, given T d the set of t ∗ i which is the time
    in which node i dies (for which b i ( t ∗ i )=0 ): d g =max T d −min T d (10)
    View Source r: the average percentage of tasks that are not served by the nodes.
    Since nodes have finite queues when they saturate or the battery runs out they
    start to drop requests, given r i as the percentage of tasks rejected by a node
    i, the metric in question is the average among all the nodes; e m i (t) : defines
    the difference between the current energy reference value of node i and the minimum
    value among all the nodes, in other words: e m i (t)= e i (t)− min j e j (t) (11)
    View Source The metric is mainly used in the charts for visualizing the behavior
    of the balancing algorithm over time. The energy reference value e i (t) is described
    in the next section. SECTION IV. Proposed Algorithms We now present three distributed
    and decentralized load-balancing algorithms whose purpose is to balance the energy
    consumption of the nodes to extend the lifespan of the service. In each algorithm,
    we assume that a node receives a task to be executed and a scheduling decision
    must be taken. The decision describes whether to execute it locally or to forward
    it to a neighbor node. The purpose of the algorithms follows the general idea
    that envisions a node to forward part of its tasks to nodes which is in a “better
    state”. Regarding the state we both consider the residual battery level (in percentage)
    which, at time t , can be expressed as: b p i (t)= b i (t) B i (12) View Source
    and the lifespan which, at time t , is described as: l i (t)= b i (t) p t i (t)
    (13) View Source Therefore the proposed algorithms can be applied both by considering
    as reference parameter Equation 12 and Equation 13. Given any two nodes i, j ∈
    N s.t. i ≠ j at time t we can encode that, for example, j is in a “better’’ state
    with respect to i both as: (i) j has a higher residual battery percentage and
    therefore b j p (t)> b p i (t) or (ii) j has a greater lifespan than i and therefore
    l j (t)> l i (t). In the algorithms that we are going to present in this section,
    we encode the function GetEnergyState() ’’ which retrieves the battery percentage
    or the residual lifespan, in the text we will refer to it as energy reference
    value e i (t) which can assume the values b p i (t) or l i (t) according to the
    specific experiment. A. Random Choice The first algorithm that we present is based
    on random choice. The random approach in used in balancing algorithms may seem
    a little bit controversial, however, there is a wide literature that shows that
    the approach has a beneficial effect, especially when the number of nodes increases
    [20]. In order to appreciate the effect of randomness we do not have to forward
    tasks blindly to random nodes but when a task arrives at time t we probe d random
    one node asking their state and then if a node is found in a “better’’ state,
    the task is forwarded [21] to it otherwise it is executed locally. Algorithm 1
    shows the proposed algorithm based on the random choice. The flow of the algorithm
    is the following, suppose that the algorithm is executed by node i: first of all,
    we pick d random nodes from the neighbours of the current node i; then for each
    of the picked nodes we explicitly ask them the state; if a node j with a better
    state is found, then the task is forwarded to it; in any other case, the task
    is executed locally. Algorithm 1 Random Choice Balancer Ensure: neighsIPs ← list
    of neighbor nodes’ IP from configuration Require: task ← task to be executed d←
    number of neighbor nodes to probe function SCHEDULE(task, d ) selfState ← GetEnergyState()
    [1. Pick d random neighbor nodes] randomNodes ← pick d RandomNodes(neighsIPs,
    d ) [2. Retrieve the state of the picked nodes] for ip ∈ randomMachines do randomState
    ← GetEnergyState(ip) [3. Check if the probed node has a better state] if randomState
    > selfState then [3a. If yes, forward the task to it] ForwardTask(task, ip) return
    end if end for [4. If no node in a better state is found, then execute the task
    locally] Execute(task) end function The purpose of the algorithm is to avoid the
    probing of all the neighbor nodes which may introduce latency and relies on the
    probability of finding a node that is in a better state. The mathematical model
    and the assumption behind this idea are well-studied in the above-mentioned works.
    We remark that, in this particular approach, we are not interested to find directly
    the migration ratios m ij (t) from any node i,j∈N since we apply a random decision
    to each task that arrives to the node. B. Ratio approach The second approach is
    specifically designed to find the migration ratios m ij (t) which describe, for
    any two nodes i,j∈N the percentage of the arrival task rate to node i, λ i , that
    is forwarded to node j . The proposed approach divides the time into rounds of
    τ seconds. When the round time is hit the migration ratios for a given node i∈N
    are updated. Moreover, to improve the stability of the found ratio, due to the
    distribution of tasks’ arrivals (which we will assume to be Poissonian during
    the experiments), we introduce a tolerance coefficient ϵ which is used in the
    criterium for establishing if a node is in a better state. In particular, given
    any two nodes i,j∈N , we consider a node j to be in a better state of i if e j
    (t)> e i (t)(1+ϵ) (14) View Source The fundamental idea of the algorithm is that,
    at each round, we make each node i equally forward all its incoming tasks at rate
    λ i to all the neighbors which are in a better state, if they exist. Then, if
    performing this action will cause a certain neighbor node to worsen its state,
    the node will reset the migration ratio towards it. Even if the behavior is all
    or nothing we expect the energy reference value (battery or lifespan) to be equalized
    and maximized over time. Algorithm 2 shows the complete pseudocode of the proposed
    approach which is triggered every τ seconds. The flow of operations is the following:
    probe all the neighbor nodes for their state and store into a list the nodes for
    which the condition in Equation 14 is true. For any node j that is found to not
    have a better state, the ratio is reset; update the ratios towards all nodes in
    the list by distributing the traffic totally and equally. C. Ratio approach with
    adaptive step The last algorithm that we present follows from Algorithm 2 and
    it has the same purpose of finding the migration ratios m ij (t) for a given node
    i , a similar approach has been applied in case of leveling of latency [22]. Even
    in this approach, we reason with rounds of duration τ seconds and at the end of
    the round each node updates its migration ratios. The difference with the previous
    algorithm is that, first of all, any given node i∈N computes the average energy
    reference value (which can be the battery percentage or the lifespan) between
    itself and its neighbors, then it increases by a step size α the migration ratio
    m ij to the nodes whose state is above the average and decreases it by a step
    size α to the nodes whose state is lesser than the average, and this is done by
    always keeping m ij (t) positive. Since arrivals are in general not exactly periodic,
    as in the previous approach, we define a node that is balanced when e a i (t)(1−ϵ)≤
    e i (t)≤ e a i (t)(1+ϵ) (15) View Source Algorithm 2 Ratio Balancer with Equidistribution
    Ensure: neighsIPs ← list of current node’s neighbours ratios ← array of floats
    one for each neighbor in neighsIPs τ← round time lastRatioUpdate ← the timestamp
    of last ratios update Require: task ← task to be executed ε← the better state
    tolerance value function UPDATERATIOSEQUIDISTRIBUTION(neighsIPs, ε ) list ←[]
    selfState ← GetEnergyState(self) [1. Loop over every neighbor] for ip ∈ neighsIPs
    do neighbourState ← GetEnergyState(ip) [2. Check if the current neighbor has a
    (1+ϵ) better state] if neighbourState > selfState ⋅(1+ε) then [2a. If yes then
    save its IP to a list] list.append (ip) else [2b. Otherwise, reset the ratio to
    it] ratios[ip] ←0 end if end for if len(list) >0 then [3. Equidistribute the λ
    rate to all neighbors in a better state] value ← 1/len(list) for ip ∈ list do
    ratios[ip] ← value end for end if return ratios end function We call this zone
    of size 2ϵ e a i (t) , a tolerance zone and a node for which Equation 15 holds
    at time t does not need to alter any migration ratio. Therefore the algorithm
    is triggered only if a node is outside the zone. Algorithm 3 shows the pseudocode
    of the proposed approach. The flow of operations is the following: compute the
    average of the energy reference value e i (t) , then the upper and the lower limits
    of the tolerance zone; at this point we check the condition for which the current
    node i’s state is below the tolerance zone and the migration ratios are not zero,
    this means that the node is forwarding an amount of traffic that is excessive
    and causes it to go below the zone4. If the condition is true then we decrease
    all the positive migration ratios by the step size α . after reducing the ratios,
    check if the current state is above the lower limit of the tolerance zone and
    if this is true we do not further step since the node cannot increase the ratios
    and we assume it in balance; if the node reaches this point then it is below the
    tolerance zone and the ratios must be altered, in particular for going in balance
    we reduce by α the ratios towards every node neighbor j∈N that is below the balance
    zone, because for going in balance it needs to increase their energy reference
    value e j (t) ; increase by α the ratios towards the nodes which are above the
    balance zone, in this way, we increase the energy reference value of the current
    node for decreasing the one of the node to which the traffic is offloaded. Algorithm
    3 Ratio Balancer with Adaptive Step Ensure: neighsIPs ← list of current node’s
    neighbours ratios ← array of floats one for each neighbor in neighsIPs τ← round
    time Require: task ← task to be executed ε← the better state tolerance value α←
    the migration ratios’ step size function UPDATERATIOSADPTSTEP(ratios, neighsIPs,
    ε,α ) [1. Compute the average energy value and the tolerance zone limits] states
    ← GetEnergyStates(neighsIPs) avgEnergy ← sum(states) / len(states) avgHigh ← avgEnergy
    ⋅(1+ε) avgLow ← avgEnergy ⋅(1−ε) [2. Check if the current state is above the average
    and ratios must be reduced] selfState ← GetEnergyState(self) if selfState > avgHigh
    then for ip ∈ neighsIPs do [2a. Reduce of step α every positive ratio] if states[ip]
    >0 then ratios[ip] ← ratios[ip] - α end for end if [3. Check current state is
    above the low limit of the tolerance zone, in that case, the node is balanced]
    if selfState > avgLow then return ratios end if for ip ∈ neighsIPs do [4. Reduce
    the ratio to nodes that are below the tolerance zone] if states[ip] ≤ avgLow then
    ratios[ip] ← ratios[ip] - α [5. Increase the ratio to nodes that are above the
    tolerance zone] if states [ip]> avgHigh and sum(ratios)<1.0 then ratios [ip]←ratios[ip]+α
    end if end for return ratios end function SECTION V. Experimental Results The
    algorithms presented in Section IV have been implemented in the P2PFaaS framework
    [6] which we envisioned and implemented for testing distributed scheduling and
    load balancing algorithms. The paradigm used as a task model is the Function-as-a-Service
    (FaaS), therefore we envision that every node i∈N generates a rate λ i of function
    execution requests per second, then the scheduling decision is made per each request
    upon its generation. We suppose each node to run at maximum K=4 requests in parallel
    with no queue, therefore if a node decides to execute a request locally and it
    is executing exactly four requests, the new upcoming request is automatically
    rejected, thus increasing the r metric. The framework has been installed on 11
    Raspberry Pi 4, however, since the devices had a not real solar panel and battery
    attached we simulated them. We introduced a new module in the framework which
    simulates the energy discharge by periodically reading the actual CPU usage of
    the board and reducing the capacity of a virtual battery. The CPU time gives an
    accurate estimation of the device’s current load and therefore it has been used
    as ρ i (t) in the Equation 4. The energy module implements instead Equation 5
    with ticks that update the battery triggered every second. From real measures
    we assumed, in every experiment and without loss of generality, that the idle
    power of a board as P IDLE =2.5W∀i∈N and the power consumption for a unit of load
    as P WORK =0.025W∀i∈N , in this way, the boards in full load have a total power
    absorption of 5W . The capacity of the batteries and the initial energy as been
    instead set to B i =10Wh∀i∈N . Finally, the arrival rates match the node index,
    starting from i=1 to i=11, λ i =i. A. Discharge The first experiment that we carried
    out assumes that the contribution of the solar panels is absent, i.e. s i (t)=0∀i∈N,∀t≥0
    in Equation 5. Table II shows the results of the experiment in the case in which
    no algorithm is applied to the system and then for every proposed algorithm applied
    both to the battery capacity ( e i (t)= b i (t)) and to lifespan ( e i (t)= l
    i (t)) . What we can observe is that the approach that equally distributes the
    traffic among all the neighbors which are in a better state (Algorithm 2) when
    applied to lifespans is the one which makes the e i (t) more stable (since the
    variance σ=0.04 is minimized) and which minimizes the gap between the first and
    the last nodes that run out of battery ( d g =3s) and also maximizes the lifespan
    of the first node which goes offline (with 2 hours, 27 minutes and 22 seconds).
    This is because the random approach generates an excessive variance and since
    it is random it is less precise in selecting the node for which the migration
    ratio must be increased, then the approach with the adaptive step is instead too
    slow in adjusting the migration ratios and therefore forwarding all the traffic
    all at once is the approach which performs better. Then we need to highlight two
    aspects of these results. First of all, the approaches which use the lifespan
    are as expected the ones which maximize the d f metric because they have the advantage
    of exactly working with the metric. The second aspect regards the probability
    of a task being rejected which is r . In general, none of our approaches focused
    directly on that particular metric, because the objective of all the algorithms
    was to extend the minimum lifespan, however, an approach cannot extend the lifespan
    by rejecting the tasks and thus reducing the energy consumption. This kind of
    reasoning opens for a multi-objective study which is left as future work, however,
    the approach which is resulted to be the better still gives a fair r= 16.5% with
    respect to 13.2% which is the case in which no load balancing is applied. This
    happens because it can be seen as a partial side-effect of balancing the load
    for increasing the lifespan, indeed, a node offload parts of its traffic to nodes
    that have a greater energy availability, probably because they have carried out
    less work with respect to nodes that forwards the traffic. This particularly holds
    when the energy consumption per unit of load ( P WORK ) is the same for every
    node, which is our specific case. TABLE II Comparison of the Proposed Energy Balancing
    Algorithms During Discharge Until the Shutdown of All the Nodes with No Recharge
    During the Experiment. Values of σ Are Intended To Be Multiplied By 10 −3 . B.
    Discharge and Solar Recharge The purpose of this second experiment is to measure
    how the proposed algorithms behave when, as it could happen in a real environment,
    the batteries are recharged during the day according to the solar activity. The
    amount of energy harvested by the solar panels used in the experiment has been
    taken from real home-designed solar panels5 over 3 days of activity, the data
    were re-scaled to match 3 hours under the conditions of the experiment in which
    we suppose that each node is attached to its own polycrystalline solar panel with
    a rated maximum power of 14W6. In this process, we suppose that the differences
    in the traces are due to the different geographical positions of the nodes. Figure
    2 shows the energy harvested by three solar panels. The traces have been applied
    to the 11 nodes by using the following fashion: nodes 1, 4, 7 and 10 follow the
    trace no. 1 in Figure 2a; nodes 2, 5, 8 and 11 follow the trace no. 2 in Figure
    2b; nodes 3, 6 and 9 follow the trace no. 3 in Figure 2c. The configuration of
    the node batteries remains the same as the ones in the previous test (initial
    capacity B i =10Wh, P IDLE =2.5W and P WORK =0.025 ). The arrival rate to the
    node is also the same as the previous experiment (Section V-A). Table III shows
    the final results of the experiment which has been conducted on all the algorithms
    as the previous one. The purpose of the experiment is to show how the algorithms
    react when the energy in the battery can also unpredictably increase. In this
    case, the random approach based on lifespan is the one that maximizes the minimum
    lifespan d f (3 hours, 46 minutes and 38 seconds) and the variance σ=1.02 , this
    is because when energy is more dynamic the random guess is able to better capture
    the overall behavior of the system. Instead, the algorithm based on equidistribution
    of traffic (Algorithm 2 based on lifespan) minimizes the time gap d g but shows
    an unacceptable task rejection probability r . This is because the all-or-none
    approach is not able to follow a dynamic energy behavior. TABLE III Comparison
    of the Proposed Energy Balancing Algorithms During Discharge Until the Shutdown
    of All the Nodes with Simulated Recharge During the Experiment Following the Same
    Curves. Values of σ Are Intended To Be Multiplied By 10 −3 . Figure 3 shows the
    trace of e m i (t) regarding the battery capacity over time ( e i (t)= b i (t))
    when no balancing algorithm is used, while Figure 4 shows the same trace when
    the best approach is used, which is Algorithm 2 with energy reference value the
    lifespan of nodes ( e i (t)= l i (t)∀i∈N) . This illustrates how the proposed
    algorithm can reduce over time the variance between the batteries thus extending
    the lifespan of 25 minutes with respect to the case in which no balancing is used.
    SECTION VI. Conclusions In this paper, we presented three decentralized load balancing
    algorithms that level the energy consumption of the nodes thus extending the lifespan
    of the nodes and therefore of the service in Green Edge Computing environments.
    Indeed, we show a brief mathematical model of the system, the pseudocode of the
    approaches and the experimental results carried out in a cluster of 11 Raspberry
    Pis with simulated batteries and solar panels. However, further investigations
    are needed, especially regarding the mathematical model which can be further developed
    with the communication impact on energy for finding if and under which conditions
    a solution exists, even when considering particular topologies that do not match
    a fully connected graph. Fig. 2. Traces of the power harvested by home-sized solar
    panels normalized to match panels compatible with Edge Computing, assuming a 12V,
    30 × 40cm polycrystalline panel with a maximum harvesting power of 40W. The traces
    recorded during three days have been normalized to match the three hours of the
    benchmark. Show All Fig. 3. Trace of e m i (t) for every node during the experiment
    in which no balancing algorithm is used but with energy harvesting from solar
    panels. The chart shows how the batteries’ energy diverges over time. Show All
    Fig. 4. Trace of e m i (t) for every node during the experiment with Algorithm
    1 is used with energy reference value the lifespan of nodes ( e i (t)= l i (t)∀i∈N)
    and with energy harvesting from solar panels. The chart shows how the batteries’
    energy is more aligned with respect to the case in which no balancing is used.
    Show All ACKNOWLEDGEMENTS The authors would also like to thank the former master’s
    student Marco Ciancia for his implementation and report of the proposed algorithms
    in a cluster of Raspberry Pi 4 boards by using the P2PFaaS Framework [6]. Authors
    Figures References Keywords Metrics Footnotes More Like This A Network Topology
    Clustering Algorithm for Service Identification 2012 International Conference
    on Computer Science and Service System Published: 2012 Topology Recognition of
    Power Internet of Things Based on Absolute Correlation Degree and Clustering Algorithm
    2023 12th International Conference of Information and Communication Technology
    (ICTech) Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 2023 IEEE Cloud Summit, Cloud Summit 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Lifespan and energy-oriented load balancing algorithms across sets of nodes
    in Green Edge Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

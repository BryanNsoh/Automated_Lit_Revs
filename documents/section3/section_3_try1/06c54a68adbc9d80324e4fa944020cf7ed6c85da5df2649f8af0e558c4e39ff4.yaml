- analysis: '>'
  authors:
  - Rezaee M.R.
  - Hamid N.A.W.A.
  - Hussin M.
  - Zukarnain Z.A.
  citation_count: '0'
  description: The proliferation of Internet of Things (IoT) devices and other IT
    forms in almost every area of human existence has resulted in an enormous influx
    of data that must be managed and stored. One viable solution to this issue is
    to store and handle massive amounts of data in cloud environments. Real-time data
    analysis has always been critical. However, it becomes even more crucial as technology
    and the IoT develop, and new applications emerge, such as autonomous cars, smart
    cities, and IoT devices for healthcare, agriculture, and other industries. Given
    the massive volume of data, moving to a remote cloud is time-consuming and produces
    severe network congestion, rendering cloud administration and rapid data processing
    difficult. Fog computing provides close-to-device processing at the network&#x2019;s
    periphery, and fog computing can analyze data in near real-time. However, the
    increased amount of IoT gadgets and data they produce is a formidable challenge
    for fog nodes. Task offloading may enhance fog computing by offloading the excess
    data to other nodes for processing due to the restricted resources in the fog.
    Management of tasks and resources must be optimized in fog devices. This review
    article overviews related works on task offloading in IoT-Fog-Cloud Environment.
    In addition, we discuss about fog networks and Software-defined network (SDN)
    applications and challenges in fog offloading.
  doi: 10.1109/ACCESS.2024.3375368
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Access >Volume: 12 Fog Offloading
    and Task Management in IoT-Fog-Cloud Environment: Review of Algorithms, Networks,
    and SDN Application Publisher: IEEE Cite This PDF Mohammad Reza Rezaee; Nor Asilah
    Wati Abdul Hamid; Masnida Hussin; Zuriati Ahmad Zukarnain All Authors Open Access
    Comment(s) Under a Creative Commons License Abstract Document Sections I. Introduction
    II. Overview of Fundamental Concepts III. Related Surveys IV. Fog Offloading Related
    Approaches V. Evaluation and Comparative Analysis Show Full Outline Authors Figures
    References Keywords Abstract: The proliferation of Internet of Things (IoT) devices
    and other IT forms in almost every area of human existence has resulted in an
    enormous influx of data that must be managed and stored. One viable solution to
    this issue is to store and handle massive amounts of data in cloud environments.
    Real-time data analysis has always been critical. However, it becomes even more
    crucial as technology and the IoT develop, and new applications emerge, such as
    autonomous cars, smart cities, and IoT devices for healthcare, agriculture, and
    other industries. Given the massive volume of data, moving to a remote cloud is
    time-consuming and produces severe network congestion, rendering cloud administration
    and rapid data processing difficult. Fog computing provides close-to-device processing
    at the network’s periphery, and fog computing can analyze data in near real-time.
    However, the increased amount of IoT gadgets and data they produce is a formidable
    challenge for fog nodes. Task offloading may enhance fog computing by offloading
    the excess data to other nodes for processing due to the restricted resources
    in the fog. Management of tasks and resources must be optimized in fog devices.
    This review article overviews related works on task offloading in IoT-Fog-Cloud
    Environment. In addition, we discuss about fog networks and Software-defined network
    (SDN) applications and challenges in fog offloading. A Deep Dive into IoT-Fog-Cloud
    Environments, Exploring Strategies for Offloading and Task Management, Including
    Algorithmic Approaches, Network ,and SDN Applications. Published in: IEEE Access
    ( Volume: 12) Page(s): 39058 - 39080 Date of Publication: 13 March 2024 Electronic
    ISSN: 2169-3536 DOI: 10.1109/ACCESS.2024.3375368 Publisher: IEEE Funding Agency:
    CCBY - IEEE is not the copyright holder of this material. Please follow the instructions
    via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles
    and stipulations in the API documentation. SECTION I. Introduction The vast development
    of intelligent devices and the rise of cloud computing have led to exponential
    growth in the quantity of data generated by IoT gadgets. Furthermore, cutting-edge
    IoT applications need ultra-low latency for data transmission and processing.
    These include augmented reality (AR), virtual reality (VR), autonomous driving,
    and intelligent manufacturing. A new computer paradigm, “fog computing,” is designed
    to fulfil these needs. Rather than transmitting large amounts of data to a centralized
    cloud server, delay-sensitive apps like augmented reality (AR), virtual reality
    (VR), and online games may do the necessary processing at fog nodes. It would
    significantly lessen the latency of information processing and reduce the quantity
    of data sent inside the primary networks. In fog computing, fog nodes are located
    close to the IoT devices so that they may act as a bridge between them and the
    public cloud. Depending on the structure, a fog node might be a cloudlet, a micro-data
    center, or an IoT gateway. The benefits of fog computing have yet to be realized
    entirely despite many practical and educational efforts [1], [2]. Since the IoT
    generates copious amounts of data, cloud computing may be used to manage and analyze
    this deluge of information. However, real-time processing is essential for many
    IoT devices. Fog computing provides a great answer to this problem. Offloading
    tasks from one fog to another node is crucial for continuing processing operations
    without interruption due to the limited resources in fogs for heavy-duty processing,
    particularly for procedures that need to be handled in real-time or quickly. Fog
    offloading and SDN have been widely used across several industries, showcasing
    their capacity to improve operational efficiency and decision-making. Fog computing
    is employed in smart cities to decrease latency and power usage, which is essential
    for IoT applications such as traffic management and public safety systems. Additionally,
    wireless fog networks enabled by SDN offer reduced latency and effective load
    balancing [3], [4], [5]. Within the healthcare sector, it facilitates expedited
    processing of data at the periphery, hence enhancing the promptness and dependability
    of patient treatment [6], [7] Fog computing and SDN are advantageous for industrial
    automation since they provide predictive maintenance and process optimization,
    particularly in industrial Internet of Things (IIoT) systems, ensuring real-time
    performance and high reliability [8], [9]. Vehicular ad-hoc networks (VANET) [10]
    and vehicular networks [11] integrate SDN and fog computing, while [12] employs
    a fusion of fog computing, SDN, and blockchain to enhance IoT sensors in agriculture.
    Additionally, within the domain of Intelligent Transportation Systems (ITS), [13]
    highlights further innovative deployments and [14] focus on prediction of forest
    fires via distributed machine learning on a fog network. These examples highlight
    the extensive influence of the technology across several industries. An evaluation
    of existing research shows that several frameworks and methods have been used
    to offload computation from the fog onto other nodes in the computing infrastructure.
    While algorithms provide many options for dealing with this problem, including
    offloading to the cloud, the most practical approach is to upload work to another
    fog due to the high expense of cloud offloading. The challenge now is picking
    the right node from all the available ones on the network—one that has enough
    computing power, a fast enough connection, enough bandwidth, and is not too far
    from the original place. Literature evaluation and research of various methods
    and methodologies show that centralized and distributed architectures have benefits
    and drawbacks. The fogs assemble their data and the rest of the network’s nodes
    and linkages. In addition to placing a heavy computational burden on the fog and
    communication lines, this effort also needs to improve the efficiency of the underlying
    network and computing fog. The Centralized architecture has performance concerns
    since it relies on a single device, making it vulnerable to outages in case of
    a communication breakdown between the nodes. In light of the numerous complexities
    surrounding offloading in fog computing, with particular emphasis on the intricate
    nature of network structures, this review paper delves into a comprehensive analysis
    of the prevailing challenges and their corresponding solutions. Our objective
    is to scrutinize the diverse aspects of network utilization in fog offloading
    and explore the applications, benefits, and obstacles associated with SDN technology
    within this domain. The following are the primary contributions of this survey:
    A thorough analysis of the fog offloading issue classifies the most recent solutions
    and identifies the various aspects impacting the offloading decision. We discuss
    and explore diverse types of offloading networks by focusing on SDN applications
    in this field. We present a classification for the optimization methodologies
    to tackle the service placement issue for IoT applications deployed across fog
    nodes. Finally, we explore future research directions in fog-based systems and
    identify great difficulties. We will go deeply into each issue in the following
    parts of this review article. In the second part, we will review the significant
    components, ideas, and aspects of fog computing. In the third section, the related
    surveys are discussed. We will then perform a detailed assessment and evaluation
    of fog offloading related approaches and analyzing recent studies in the fourth
    part. In the fifth part, we will assess and evaluate the approaches and categorization
    of fog computing architectures and SDN. In the sixth part, we will discuss the
    results, emphasizing both the advantages and problems connected with SDN in fog
    computing. Finally, in the last part, we will make conclusions that will pave
    the way for future research areas in fog computing. SECTION II. Overview of Fundamental
    Concepts A. IoT The term “Internet of Things” (IoT) refers to a network of physical
    things, such as buildings, cars, and other objects, that collect and distribute
    data using software, sensors, electronics, and network connections. IoT devices
    have confronted storage, communication, energy, and computing limits. Due to these
    inefficiencies, IoT and cloud computing technologies are combined [15]. Many IoT
    systems and information science addresses associated with IoT devices are connected
    to the internet to provide end users and businesses with regular services and
    tasks. Applications for the IoT have exploded in recent years, and predictions
    indicate that this trend will continue. More than seven billion IoT devices were
    linked to the internet in 2018; fourteen billion were anticipated to do so in
    2019. Among the IoT applications with the highest number of deployed devices is
    the home sector, with 663 million devices in use in 2017. Some of the purposes
    for intelligent homes include locks, freezers, stoves, refrigerators, and lighting.
    Expanded IoT usage, or the “smart city,” has been proposed for many European nations.
    Automation, pricing potency, and exactness have contributed most to the present
    trend in industrial, agricultural, and health applications. Patient monitoring,
    energy-saving, and imaging-related technologies are a few examples of healthcare
    gadgets (X-ray machines) [16]. B. Cloud Computing “IoT” and “cloud computing”
    are the foundation of a swift and autonomous transformation. IoT technology’s
    processing, storage, and communications constraints may initially be made up for
    by the almost limitless cloud computing resources and capabilities. Additionally,
    cloud computing may be advantageous in many real-world situations by allowing
    new services. IoT technology has extended its reach to solve real-world issues
    in a more distributed and dynamic fashion [17]. Connecting self-aware, intelligent
    nodes, or “things,” in a dynamic, worldwide network architecture is the core concept
    of the IoT. It supports ubiquitous and pervasive computing potential and is one
    of the most problematic technologies. Some define the IoT as a phrase for small,
    universal, global, and responsible items with limited processing and storage power
    and privacy, security, and accountability concerns. On the other hand, cloud computing
    is a highly developed technology that offers almost endless processing and storage
    capacity and has addressed or substantially resolved most IoT issues. As such,
    it is anticipated that a single IT paradigm—in which Cloud and IoT are complementary
    technologies—will disrupt the current and future internet [18]. The necessity
    for an interface between cloud and fog infrastructures was seen from the beginning
    of the fog concept [19]. Additionally, [18] addresses the interaction between
    such entities; the standardization of this interface is highlighted as one of
    the crucial challenges [20]. C. Edge Computing In order to improve reaction times
    and save bandwidth, edge computing and fog computing—two essential elements of
    distributed computing—seek to move processing and data storage closer to the point
    of need. Even if their goals are identical, their distinct qualities may either
    support or contradict one another. Whereas fog computing makes use of an intermediate
    layer, such as routers or gateway devices, edge computing processes data on devices
    at the edge of the network, such as smartphones and IoT sensors. Through a layered
    computing architecture, the synergy of these two enables a more effective allocation
    of computational activities, boosting efficiency, performance, scalability, and
    system dependability. Edge computing requires the construction of tiny, virtualized
    infrastructures between base stations, radio network controllers, and other aggregation
    sites at the network edge. Although edge computing uses an architecture and an
    operating system distinct from fog computing (one operator maintains the infrastructure,
    excluding consumer devices), it targets applications comparable to fog computing.
    Edge computing also leverages telecom infrastructures to provide mobile edge services,
    including location, information measure management, and radio network information
    [21]. To prolong the battery life of edge devices, the applications running on
    edge devices may be efficiently migrated to fog devices that possess sufficient
    resources and battery capacity. This approach has been demonstrated in research
    [22]. Nevertheless there are additional difficulties in combining edge and fog
    computing. It is difficult to manage resources between fog nodes and edge devices,
    and the increasing data processing at the edge raises security and privacy issues.
    Interoperability problems may arise from a lack of standardisation, and in certain
    situations, the interdependency on network connection presents difficulties. Furthermore,
    the deployment and maintenance of these integrated systems are very complicated,
    and the energy consumption and sustainability of such a dispersed network need
    cautious management. All things considered, edge computing enhances fog computing
    by improving processing power, but it also brings new challenges that must be
    resolved in order to maximise dispersed computing systems. D. Fog Computing Fog
    computing has emerged as a feasible supplement to cloud computing with the advent
    of real-time IoT devices, bringing cloud computing to the edge of the network
    to fulfill the stringent latency constraints and intense processing needs of these
    applications [22], [23]. A typical fog compute node comprises several geographically
    distributed fog nodes positioned at the network’s edge with different resource
    provisioning, such as storage, processing power, and communication bandwidth [24].
    Fog computing bridges edge devices and the cloud, offering low-latency connections
    and a dynamic environment. It is similar to the edge in architecture and closer
    to the cloud regarding resources, capable of performing computations and storing
    data fields [25]. A cloud extension known as fog computing occasionally reduces
    latency and supports time-sensitive applications, including online gaming, healthcare,
    and autonomous driving. Local devices execute simple activities, whereas large
    cloud installations handle sophisticated procedures. Fog computing collects virtual
    resources from several devices scattered around the environment, each managed
    by a different entity [21]. The IoT enables connections between objects and networks.
    Fog computing, an innovative concept, provides computer, storage, and networking
    services to IoT devices (such as sensors or embedded devices) at the network’s
    edge. Fog computing benefits mobile computing swiftly analyses massive amounts
    of data and manages billions of internet-connected devices. Fog property, quality
    of service, interface and programming model, machine offloading, scheduling, accounting
    and tracking, resource and repair management, and information privacy are among
    the fundamental problems in fog computing. Fog computing eliminates interruptions
    with an economical cloud architecture. Positioning fog nodes adjacent to the information
    source provides cloud support options. Instead of transferring IoT data to the
    cloud, fog evaluates and stores it locally at IoT devices, enabling fog to offer
    higher-quality services with quicker response times. Fog is the ideal choice for
    allowing the IoT to provide a range of IoT applications in an IoT system with
    practical and dependable services [26]. The closeness of end users, regionally
    targeted allocation, and quality allowance will distinguish fog from the cloud.
    Fog substantially minimizes network information measure utilization when compared
    to the cloud. In cloud based IoT data processing, each unique piece of IoT data
    must be sent to the cloud data center. Transferring data becomes increasingly
    costly if the number of data to be reviewed rises fast as is the situation with
    today’s IoT. Because of the fog, information is kept and processed locally, reducing
    the utility of sending such information. If processed data is required to be retained
    for different analytical and historical reasons, it is uploaded to the cloud.
    Consumers would benefit from cheaper operational expenses as a consequence. Furthermore,
    since the data is handled so close to the source, the end-user application becomes
    very fast, which is crucial for maintaining the quality of service for period
    and Mobile to Mobile operations. As a result, fog management services improve
    customer satisfaction while IoT information services become more reliable, efficient,
    and consistent [26]. Even though fog networking seems to be a realistic solution
    for overcoming the drawbacks of cloud computing and current networks, some concerns
    must be addressed in the future. The most critical need is a distributed intelligent
    platform for managing computing, networking, and storage resources at the edge.
    Given the wide variety of processing power capabilities of nodes, the uncertainty
    surrounding task demands, resources available at fog nodes, and distribution choices,
    it is challenging to make an acceptable distribution decision in fog networks
    [27]. Furthermore, communication delays between nodes should be considered when
    selecting a distribution, since this may lead to more extended processing times
    [28]. Consequently, the Fog computing paradigm confronts several challenges [29].
    A fog node’s response period is used to evaluate whether it should handle the
    whole of a service request that has been received, process just a part of it,
    or offload it to another fog. Each fog’s reaction time will be determined regularly
    utilizing the fog’s available capacity (i.e., waiting line volume) and the service’s
    demand travel time (lower latency is always desirable) [30]. Each fog in the network
    tries to gather data about other fogs and nodes nearby. Whenever a fog has to
    offload its responsibilities to other nodes, it stays connected to the surrounding
    nodes, changes the value of the computational function and the state of its connection
    connections, and decides about which fog to offload based on an algorithm that
    analyses the different fogs. In contrast, the centralized architecture relies
    on a server or other centralized device to gather data from distributed fogs,
    analyze computing resources, and map out connections between distributed fogs
    throughout a network. Send the communication connections from the nodes constantly
    to the device in the center. A node will communicate with this centralized machine
    when it wants to submit its duties. Central devices pick the target fog for offloading
    and introduce the source node based on nodes and network connections following
    the decision process for which the choice is made. A three-layer fog computing
    architecture is shown in Figure 1. FIGURE 1. A three-layer fog computing architecture
    [22]. Show All E. Task Offloading IoT and mobile devices are not suited for running
    programs needing significant resources since they have limited memory, computing
    power, battery life, and measurement of communication data. Mobile cloud computing
    was developed to solve the current problem and eliminate such challenges. It is
    a paradigm for shifting heavy-lifting mobile device tasks to the cloud or compute
    offloading, which frees up mobile devices’ resource constraints. Several constraints,
    including a sizeable average access latency between users and remote clouds, high
    battery consumption, and a deficiency of local user data, make offloading activities
    to the cloud possible only for specific mobile applications. Novel approaches
    are being presented to address these problems, including offloading mobile network
    traffic to complementary networks like Wi-Fi and satellite-terrestrial networks
    and edge cloud computing [31]. Consider the case when a fog node first receives
    and processes a request for data processing from a thing before responding. When
    a fog node is overloaded with other requests, it may only process a portion of
    the payload before sending it to other fog nodes. There are two ways to simulate
    fog node interactions: With the first approach, a central node keeps up the fog
    node offload contact. Every fog node follows a protocol to provide its most current
    status information to its neighbors. Second, every fog node maintains a frequently
    updated list of the best nodes to manage the offloaded workloads [30]. Offloading
    must handle many challenges in fog computing, including: How to construct the
    best offloading scheme, how to partition an application for offloading, and what
    sort of data is needed for offloading decisions are the first three questions
    [24]. Offloading must handle many challenges in fog computing, including: How
    to construct the best offloading scheme, how to partition an application for offloading,
    and what sort of data is needed for offloading decisions are the first three questions
    [13], [32], [33]. According to [23], resource allocation and dynamic offloading
    in fog computing present many vital challenges. These challenges include the following:
    The Power-Latency Tradeoff and System Dynamics: A fog system often consists of
    several layers, intricate dynamic interactions between fog tiers and the cloud,
    and dynamic internal dynamics that are always changing. Effective Decision-Making
    Process: Because of overheads, decision-making processes should be computationally
    effective. The challenges are often brought on by the unpredictable nature of
    the traffic data, the ongoing nature of task delivery, and the intrinsic complexity
    of the issue. Understanding the Benefits of Predictive Offloading: A crucial aspect
    of online decision-making is using predictive offloading to reduce delays and
    improve the quality of service. Although fog computing prediction offloading has
    various applications, its primary constraints remain a mystery. The key topic
    that will be explored is resource management in terms of computing resources and
    data storage amongst different fogs in the network. IoT devices may offload tasks
    to fog nodes fog nodes to other fog nodes, and fog nodes to clouds. The tasks
    are re-offloaded to the surrounding fog nodes or cloud due to the fog node’s low
    processing resources [34], [35], [36], [37], that resulted in more transmission
    and processing costs [37], [38]. Figure 2 depicts the scopes of task offloading
    in fog computing. FIGURE 2. Task offloading scopes related to fog computing. Show
    All Here, we will present and discuss related fog processing and offloading efforts.
    Due to its relevance and significance, the fog processing debate has garnered
    the attention of several scholars. F. Software Defined Network (SDN) SDN is an
    advanced networking concept that divides the control plane from the data plane
    [39]. This leads to increased flexibility and agility as well as more straightforward
    network design and management. SDN’s main idea is to let a logically centralized
    software-based controller, or control plane, take care of network intelligence
    and decision-making, with the data plane handling tasks like traffic forwarding.
    SDN has many advantages, including network programmability, which promotes network
    automation, and network management, which lowers operating costs by streamlining
    administration activities. And virtualization of networks [40]. Most device power
    consumption in IoT applications happens during packet forwarding on the network
    side [13], [41]. Device life and offloading quality will suffer from poor-quality
    offloading brought on by limited bandwidth and excessive latency. SDN has evolved
    as an auxiliary technology on the network side in offloading operations to alleviate
    this issue [13], [42]. Centralized control, programmability, load balancing, and
    management are just some of the problems that plague traditional Fog networks
    [43], [44], [45]. Fog nodes can efficiently operate together using SDN [2], [45],
    [46]. By enhancing the rules in its centralized SDN controller with a network-wide
    perspective [47], SDN allows for more wiggle room in the network’s programming.
    By gathering information from each network device, adjusting the load-balancing
    plan, and keeping an eye on network traffic, an SDN controller dynamically manages
    the network [45], [48], [49]. Gathering network data, such as utilization of resources,
    device positioning and mobility, load metrics, and network information, is the
    primary duty of the SDN controller in order to ensure the field of SDN-enabled
    networks provides a high level of service [13], [50], [51], [52], [53]. The offloading
    service with SDN can detect changes in the network since it uses the SDN controller
    according to the compute demands and network conditions, it may select the best
    offloading node for an overloaded fog node. SECTION III. Related Surveys As pointed
    out earlier, merely transferring and offloading data across Fogs won’t provide
    the perfect setup without considering task management and resource availability.
    Nevertheless, the majority of prior review papers have addressed algorithms from
    a broad perspective, failing to take into account the specifics of the algorithm’s
    capacity for task and resource management. This work makes a substantial addition
    to the area of fog computing by analyzing fog analysis algorithms based on the
    three primary capabilities of task management, resource management, and task offloading.
    This study diverges from recent surveys focused on fog and Edge computing, mobile
    Edge computing, or machine learning applications. Instead, it offers an in-depth
    analysis of network concerns and SDN applications, specifically within the framework
    of fog offloading. This extensive examination of network and SDN issues fills
    a gap in previous research, which either ignored or briefly addressed these aspects.
    As a result, it makes a substantial addition to the subject. This approach fills
    an essential need in existing literature, establishing our study as a crucial
    asset in comprehending and progressing network management tactics in these developing
    computing paradigms. Surveys [39], [40], and [44] mainly examined Edge computing,
    mobile Edge computing, and general SDN usage. However, they either neglected or
    just briefly addressed network concerns. On the other hand, this study provides
    a detailed analysis of these topics, addressing a significant deficiency in the
    existing body of knowledge and offering valuable perspectives for enhancing network
    management tactics in Fog computing. In [54], task offloading in edge computing
    and the IoT is investigated. The study considers the benefits, factors that impact
    the decision of offloading, and different offloading techniques and algorithms.
    The algorithms are classified into two categories, machine learning and non-machine
    learning, and offloading strategies, such as total and partial offloading, are
    discussed. Authors of [55] analyzed the role and challenges of Artificial Intelligence
    and Machine Learning algorithms for resource management in fog/edge computing
    environments. References [56] examined significant journal publications on mobile
    computing and how the research route, challenges, and methodologies have evolved.
    Also, the architecture and essential components of edge computing are described.
    Reference [57] overviews offloading strategies in a fog environment. The contributions
    they cover are articles published on or before November 2020 and do not contain
    the most recent research in fog computing. A general overview of the goals, optimization
    methods, algorithms relevant to task offloading in fog computing, and formulation
    of its mathematical issue is covered in [58]. The article [35] examines the factors
    influencing whether to utilize the cloud or the fog for offloading while discussing
    various offloading techniques in the cloud-IoT ecosystem. The authors also discuss
    other offloading-supporting technologies, such as wireless connection, virtualization,
    and AI. Reference [59] reviews how Reinforcement Learning (RL) and Deep Reinforcement
    Learning (DRL) algorithms deal with offloading problems in fog computing. Value-based,
    policy-based, and hybrid-based algorithms are the three classes into which it
    divides the fog computing offloading methods. In contrast to prior review studies,
    we focused on task management from different perspectives in this study, including
    network problems and SDN technologies. Table 1 compares this study with other
    relevant studies in this field. TABLE 1 Related Works This review article focuses
    on the importance of networks and SDN in fog computing, emphasizing how they improve
    resource management, scalability, and compute efficiency in centralized and distributed
    computing environments. As a cloud computing extension, fog computing moves storage
    and processing closer to the network’s edge, requiring reliable and adaptable
    network management systems. In this context, SDN’s function is essential since
    it offers dynamic network design and optimization, which can adjust to fog computing
    environments’ different and sometimes erratic requirements. The detailed examination
    of these issues by this study not only offers a complete knowledge of the problems
    and solutions in this field today but also opens the door for future advancements
    in SDN application and network management, both essential for developing fog computing
    technologies. SECTION IV. Fog Offloading Related Approaches The paradigm for fog
    computing has extremely low latency. Due to fog computing scalability and improved
    reactivity, it has caught the interest of numerous academics [14], [35], [46],
    [55], [59], [60]. Several publications in the fog computing sector were investigated
    in the literature review. These articles are classified and compared into the
    following areas of fog offloading based on the kind of algorithms and system architectures.
    Resource management Task management Task Offloading The interconnected components
    comprising the fog computing architecture are shown in Figure 3, and relevant
    articles will be discussed in the following sections. FIGURE 3. The system of
    interconnected components that constitutes fog offloading. Show All Before proceeding
    to the articles connected to the debate, we evaluate the available surveys on
    this issue and emphasize the significance of this study in this part. A. Resource
    Management The fog network consists of various heterogeneous devices that may
    perform computations, store data, and exchange messages. Due to the ever-changing
    nature of fog networks and the mobility of their constituent devices, resource
    management is a significant challenge. Considering the importance of effectively
    managing resources, this might enhance fog network performance and make the most
    of fog’s processing capability. Since then, various attempts to improve fog networks’
    resource management have been assessed. In [30], a fog-to-fog cooperation paradigm
    encourages fog nodes to offload incoming requests based on their load and processing
    capacity. The mathematical model of fog-to-fog collaboration that achieves near-optimal
    task distribution across cooperating fog nodes. The Fog Resource Management Scheme
    (FRAMES) encourages load balancing to address the latency issue with service requests
    received from objects. It is built on the fog as a service concept, which implies
    that each fog node is self-contained in processing, networking, and storage. The
    study uses a formal mathematical model that underlies fog node load balancing.
    The DLAEC algorithm, introduced in reference [61] aims to enhance service quality
    through the utilization of deep learning, taking into account the availability
    of human resources and network capacity for each edge system. The DLAEC method
    maximizes resource utilization at the edge while guaranteeing the concurrent execution
    of the maximum number of deep learning tasks via a three-step decision procedure.
    DLAEC independently evaluates edge access and calculates the correct number of
    deep learning layers for identification at both the edge and cloud nodes, in contrast
    to previous models that allocate a set number of deep learning layers to edge
    systems. By assigning the majority of deep learning tasks to edge nodes, this
    method lessens the requirement for cloud transfers in an Edge Computing-based
    intelligent city environment, reducing network congestion and the load on the
    cloud. Nevertheless, instead of minimizing processing time delays, its primary
    objective is to maximize the capacity of the edge nodes. Consequently, the maximization
    may result in delays, and additional tasks may be accumulated on a single node
    before being redistributed to other nodes. Blaster is a federated structure for
    routing packets within a dispersed edge network to improve application performance
    and data-intensive application scalability [62]. It also includes a revolutionary
    path selection algorithm that predicts the best route using Long Short-Term Memory
    (LSTM). This method employs a Federated Learning (FL) model to increase communication
    across SDN controllers while retaining data flow capacity. Choose the optimal
    route during system construction by using the results of an LSTM model, which
    is a kind of recurrent neural network that uses regression as a tunable technique.
    It is common practice to use the LSTM approach to deep learning-based time series
    forecasting problems. It provides a traffic matrix and a network graph to the
    LSTM. In a peak load prediction, the SDN controller or application may modify
    route selection based on the output, which is the estimated future load on the
    input connections. As a consequence, the state of the network influences route
    selection. Reference [63] deal with implementing SDN to fog networks, namely P4/P4Runtime.
    According to the industry, P4 as a data plan programming language and P4Runtime
    as a control-to-data plan interface may assist address the demands of next-generation
    networks. It presents a unique technique for deploying SDN control plans capable
    of handling fog network SDN data plans and SDN data plans integrated near the
    main network. In this manner, SDN controllers may handle cross-layer SDN data
    plans, enabling certain operations to be offloaded to the Edge. Reference [64]
    creates Android applications that serve as intermediaries between IoT devices
    and Edge/Fog/Cloud Computing ecosystems is made more. These modules facilitate
    connectivity with numerous devices functioning as data sources, and they can seamlessly
    integrate with various Fog/Cloud frameworks, making them readily adaptable for
    diverse applications. This concept is confined to one Android application and
    face limitation to be implemented in any system. A mechanism for data allocation
    in IoT systems was proposed in [65] using the Blockchain. A data controller based
    on fuzzy logic aids in data allocation decisions. FogBus used blockchain-based
    cloud and fog technologies to improve a healthcare case study. The latency of
    data transfers, network utilization, energy consumption, and blockchain storage
    have all decreased, but security mechanism delays persist. In [66], a paradigm
    based on Edge Affinity was proposed and developed to manage applications in processioning
    fog infrastructures. This paradigm organizes applications so that its resource-aware
    approach employs a larger number of fog processes to run applications with heavy
    data loads and rigorous resource needs. It addresses difficulties with application
    data flow and bandwidth. The drawback of this strategy is that it is dependent
    on a static fog management server to perform. In [67], a fog computing model be
    utilized to produce mobility assistance advice for visually impaired people. This
    device combines a mobile phone with a low-cost, low-power embedded board and a
    neural computing stick, giving rise to the acronym PEN (Phone + Embedded Board
    + Neural Computing Stick). These three devices work together to provide numerous
    distributed capabilities by combining fog computing with cloud computing. The
    model’s shortcoming is that varied hardware devices impact the system’s mobility
    and adaptability. Reference [68] present SOSW in Mobile Edge Computing (MEC) by
    leveraging the network traffic matrix. To determine the ideal placements for fog
    nodes, the SOSW model combines column-pivoting linear algebra techniques with
    singular-value decomposition (SVD) and QR factoring. With the aid of ant colony
    optimization (ACO), SOSW provides the constraint-based shortest path algorithm
    (CSPA), a heuristic-based traffic engineering solution that optimizes route calculation
    for task offload. The architecture of fog and its grid to its location within
    the network are the main topics of this research. The placement of fog to IoT
    devices in offloading data to fog in less time is also useful in decreasing energy
    consumption. Selects the route by which the IoT device may upload its data to
    the fog by collecting data through SDN and the recommended method for transmission.
    Research [69] measuring connection quality over time as the average failure, downtime,
    or repair time. To evaluate the reliability of connections, use a k-nearest (k-NNR)
    ML approach based on regression trained on a 5-month real-life network data set.
    The k-NNR considers connection parameters such as the rate of link utilization,
    link failure, and the frequency of data set failures. Furthermore, calculate the
    connection delay as the sum of the transfer delay package size. Research [70]
    discusses the internet of vehicular in MEC by utilizing SDN to propose a resource
    allocation and communication enhancement technique. It leverages q-learning to
    enhance the allocation of communication and computation resources by anticipating
    offload choices. This design’s shortcoming is that it ignores a number of environmental
    factors that are necessary for the proper functioning of the Internet of Vehicles
    system. In order to determine the best offloading choice, communication, computing
    resource allocation, and privacy protection design, it applies a deep reinforcement
    learning method in SDN networks with an emphasis on edge computing-based computing
    offloading and resource allocation. Real-time business from terminal vehicles
    is sent straight into MEC’s processing equipment, and MEC and SDN are integrated
    to provide centralized resource management and flexible network control. Study
    [9] has proposed an adaptive computing optimization for resource management in
    industrial IoT using SDN and edge computing. It describes a strategy for effectively
    calculating the resources of neighboring devices and edge nodes for task processing:
    priority-based transmission with the least energy. In [71] a user revocation system
    with an efficient architecture for a multi-user cloud environment that maintains
    data integrity is provided. It is efficient at reducing overhead when compared
    to current models in the cloud environment, but as user numbers rise, it increases
    the duration it takes to create signatures and proofs. Using CCTV cameras for
    surveillance and event monitoring or on-board cameras for traffic monitoring,
    an application may produce enormous volumes of data, especially when video stream
    processing is involved field [72]. The primary contribution of [20] is the development
    of dynamic workload placement methods for latency-constrained stream processing
    requests. The primary concentration is on the arrangement of operators and the
    allocation of resources in a distributed environment that utilizes cloud and fog
    computing. When there is a network capacity shortage, provisioning of computing
    infrastructure uses the interaction between fog and cloud. The algorithms’ goal
    is to optimize the proportion of successfully handled requests while adhering
    to application delay requirements by efficiently using the resources at hand.
    To balance quality of service and energy consumption in large-scale networks,
    [73] introduces the Set-based Differential Evolutionary algorithm for energy-efficient
    resource management in IoT-based smart cities, employing SDN and fog computing.
    In [74], each fog node in the resource allocation approach for fog computing based
    on SDN is defined by its processing capability and bandwidth (communication capacity).
    The method begins with picking an admin node and then mapping the nodes in the
    task graph to the fog node depending on the capacity of the fog node. Following
    this mapping, the allotted resources are taken from the fog node’s capacity, which
    is maintained by a management module. However, this approach begins by virtualizing
    all of the nodes and scheduling them to one fog node. It then optimizes the schedule
    by relocating the nodes to other fog nodes. B. Task Management By leveraging fog
    in processing information related to IoT devices in many sectors, such as health,
    agriculture, transportation, media, and other sections of intelligent cities,
    various tasks are assigned to the fog for analysis and processing. Several tasks
    are available, ranging from little data gathered by sensors to extensive data
    and films taken by cameras, as well as location and navigation for analysis and
    processing. Most of these data and devices need immediate reactions and real-time
    data processing via fog. Consequently, effectively managing diverse tasks is crucial
    for tasks that must be completed before a deadline. Several studies have developed
    approaches and algorithms for task management in fog networks, some of which are
    addressed here. In order to improve quality in hybrid cloud settings for data-intensive
    applications running in a centralized shared file system, Tuli et al. suggested
    making use of dynamic resources and task scheduling. For data-intensive applications,
    it assesses data file type, data transfer time, network speed, and data proximity
    while planning and dynamically supplying public cloud resources. By lowering the
    quantity of shared file transfers across nodes, this technique may improve service
    quality and decrease task placement in a hybrid cloud environment. This approach
    was designed for cloud computing and is currently incompatible with edge and fog
    computing [75]. A lightweight distributed solution to self-organizing surveillance
    and monitoring fog networks is offered by [76]. FogMon analyses the hardware resources
    (CPU, RAM, HDD) of the access nodes, the end-to-end network quality of service
    (latency and bandwidth) and detects available IoT devices. It does not take storage
    or bandwidth into account when selecting leader nodes. Reference [77] propose
    a privacy-aware task scheduling approach for a Blockchain-based fog network. The
    Ant Colony Optimization (ACO) approach optimizes work scheduling. It keeps end-user
    devices anonymous and reduces work processing time on the cloud’s VRs. To reduce
    application latency, consider demands from edge scheduling [78]. Network latency
    and service time for live video streaming services are significantly decreased
    by a score-based edge service scheduling approach that examines the network, computing,
    and reliability aspects of edge nodes. The flaw is that it restricts the centralized
    optimization process. A fuzzy evolutionary organizer is provided for the multi-target
    resource allocation in a fog environment [79]. Since task processing time, information
    about inter-task communication, and task deadlines are all represented as fuzzy
    values; the technique achieves both the agreement index and robustness aims. The
    proposed approach has a significant temporal complexity. Machine learning is employed
    in the mobile edge processing environment by [80] or distributed task scheduling
    algorithms and distributed device coordination. This model uses the Stackelberg
    game theory and the distributed ADMM optimization approach. This approach can
    achieve quick and ideal convergence regarding intelligent edge processing. The
    design has a significant issue in that it only impacts one MEC server, and the
    scheduling strategy may change when there are several MEC servers. In [81], a
    paradigm for safe data storage and processing at the edge and in the cloud was
    presented. For privacy, this approach encrypts data during transit. In this architecture,
    tasks are broken into tiny portions and transmitted between edge nodes for execution;
    if a node does not have adequate processing capacity, the task migrates to its
    side nodes, and so on, until a suitable node is identified and wholly performed.
    In this system, the node is only dispatched for processing based on its proximity,
    independent of its resources or capacity. It may fail and be compelled to move
    to other nodes. This data transfer and undefined movement might cause substantial
    data latency issues when system demands increase. C. Task Offloading Since there
    is a variety of fog in the network, it is vital to identify the destination fog
    for offloading when fog is overloaded, or IoT devices demand an external processor.
    So, the destination selection choice influences the amount of processing time,
    data delay, and deadline. Conversely, the destination fog’s reliability in completing
    the requisite processing with no errors is another priority offloading operation.
    Factors like having adequate processing power in the destination fog, enough memory,
    and a sufficient and acceptable connection to send data may all be utilized to
    establish the fog’s competence. The right strategy for gathering fog information
    in the network and selecting the optimal fog is vital at this stage. Several approaches
    have been developed to acquire fog information in the network, which may be categorized
    into two categories: centralized and distributed. Most centralized algorithms
    have incorporated SDN technology because of the advantages of SDN networks. 1)
    Decentralize Task Offloading As discussed in last section, some fog offloading
    methods are based on distributed architecture or created without SDN technologies.
    The matching theory-based distributed computing offloading framework MATO, utilized
    for heterogeneous fog nodes to minimize task execution latency, was introduced
    in the research field [82]. Reference [14] enhanced the framework for distributed
    processing on a fog network based on Akka. The Akka toolkit is one of the most
    comprehensive and well-liked actor modeling solutions for Java Virtual Machine
    (JVM). In the Fog IoV network, [37] provide a task offloading strategy employing
    the roadside parked cars as a computing offload location. The struggle between
    IoT devices for fog nodes is treated as a game in Field [83]. The Weighted Potential
    Game’s finite improvement characteristic demonstrates the Nash equilibrium. DecChain
    is a secure edge computing solution based on blockchain that removes the requirement
    for a trusted third party on the network [84]. Concerns such as eliminating a
    trusted network failure point when losing access to a third party have been addressed.
    It faces challenges, such as integrating blockchain into the processing environment
    at the edge. Edge servers or service providers manage tasks in the network. As
    can be seen, service providers handle tasks based on a predefined structure, and
    the capacity of edge nodes to split tasks is not considered. Reference [85] concentrate
    on multi-hop vehicular systems to have optimum options for performing activities
    locally or remotely. For compute offloading, efficient route selection and fog
    node assignment may reduce average service latency and energy consumption. Its
    performance is inferior to other frameworks when there are less than 50 automobiles,
    but by increasing the numbers, performance is more outstanding than others. In
    5G network technologies based on edge computing, research [86] combines optimization
    techniques for task offloading and resource allocation by controlling the energy
    consumption of the system. The plan may provide even better latency performance,
    which boosts the functionality of 5G mobile communication networks and enhances
    end-user satisfaction. The suggested approach ignores the order in which computing
    tasks are completed and only considers the overall processing time delay of all
    tasks inside the system. An Optimal Stopping Theory (OST) inspired paradigm for
    data quality-aware task offloading in mobile edge computing is presented in [87].
    The OST-based method is acceptable when mobile nodes make small, independent choices
    inside the MEC environment and do not need many resources. Each offloading mobile
    node will run the models in a single configuration without considering the context
    of other mobile nodes. The structure and task offloading based on neural network
    service are illustrated using a GPU-based embedded edge server [88]. An offloading
    mechanism is presented based on the computing gap between the edge and the central
    cloud. It is particularly costly to build since it depends on GPU resources at
    the network’s edge. In [22], when one node on the network becomes overburdened,
    it may upload all or part of its responsibilities to other fogs through a cooperative
    mechanism. This algorithm improves fog dispersal based on multipliers distributed
    alternating direction approach. This model focuses on optimizing the Quality of
    Experience (QoE) and increasing the power efficiency of fog nodes and the tradeoff
    between these two measures. Reference [23] provides a multi-layered fog computing
    system for dynamic resource allocation and offloading utilizing traffic prediction.
    It defined the problem as a stochastic network optimization problem and offered
    a solution that reduces power consumption while maintaining queue stability. The
    shortcoming of the concept is that power usage and overall queue backlog sizes
    would become inefficient if forecast mistakes happened. For the concurrent task
    data offloading, [36] suggests collaborating horizontally with several fog nodes
    and vertically with a faraway cloud. It took into account the latency in communication
    between end users and the fog, as well as the time it took to send data and provide
    services. It also factored in local computation time and waiting times at the
    fog node linked to queuing. The authors [89] put their attention on offloading
    duties from a device to fog and fog-to-fog. The ideal scheduling approach for
    the two queues, such as low and high priority in a fog node, is examined in this
    model. The stability of both queues is concurrently maintained while more offloaded
    tasks that are aware of deadlines may be finished. Two techniques comprise the
    recommended approach: The Lyapunov drift-plus-penalty method and fog computing
    collaboration are used to construct a priority-aware scheduling approach based
    on the fog nodes’ queue status. According to the simulation findings, with the
    same resource setup, this strategy may ensure that more tasks are finished within
    the allotted time limit. 2) Centralized Task Offloading Centralized task offloading
    is split into two groups: those that use a SDN and those that don’t. a: SDN-Based
    Task Offloading In this part, we investigate and evaluate fog offloading strategies
    based on SDN technology. Most of these techniques are developed for data offloading
    from IoT or mobile devices to fog. For an SDN-based fog computing system, a dynamic
    offloading service between fog nodes is suggested by [2]. Selecting the suitable
    offloading node and enabling the offloading path by providing an end-to-end bandwidth
    guarantee are the goals of using SDN technology. To choose an appropriate offloading
    node, the proposed method makes use of fog node information and real-time network
    status. Furthermore, a few network parameters may be used to ensure bandwidth
    throughout the offloading path and create an optimal end-to-end path selection
    route. Q-learning offloading choice allows the controller to choose appropriate
    actions depending on the reward function [29]. In this strategy, the controller
    may customize their incentive function based on the desired performance. Consequently,
    the suggested Q-learning-based offloading choice can estimate how good the current
    offloading will be in the future, resulting in remarkable overall system performance.
    Furthermore, the suggested solution is compatible with SDN architecture as the
    reinforcement learning-based decision-making process is on-demand, which allows
    the controller to construct a reward function depending on the required performance.
    By using an integer linear programing (ILP), [90] resolves the multi-hop task
    offloading issue. To solve the problem effectively, use a greedy heuristic-based
    approach since the viable set is non-convex. Latency, energy costs, multi-hop
    routes, and fluctuating network factors like link utilization and SDN rule capacity
    are all part of the greedy approach. The contribution 1) the best decision is
    to compute a work locally or remotely; 2) the best fog node selection; 3) the
    best offloading route selection. With fewer fog devices, the recommended technique
    can attain excellent performance. In [31], SDN approaches are used to optimize
    resource management and load balance across a network of Cloudlets. To balance
    the distribution of different tasks offloaded from mobile devices while optimizing
    resource utilization, it is handled as a mixed-integer linear programming (MILP)
    optimization model. Taking into account both communications and computation delay,
    available resources, and a task with a restricted deadline, the issue of a balanced
    distribution of incoming requests throughout the Cloudlet network is outlined.
    To emulate the recommended architecture, experiment with utilizing Mininet-WIFI
    and Floodlight as the SDN controller. The limitations of this method are the available
    resources and the demands of the consumers. Reference [11] created a blend offloading
    structure to improve the offloading choice selection process by selecting the
    optimal offload node and assuring the infeasible request’s needed deadline and
    the average processing cost of the fog node. It employs a mathematical approach
    known as Binary Linear Programming (BLP) to determine to offload destination fog.
    The fog node’s SDN controller will choose the optimal offload target fog by comparing
    the needed deadline of the infeasible request with the response time of each available
    parked and moving car. Reference [91] suggests a four-layer network paradigm based
    on SDN for the Industrial Internet of Things (IIoT). Depending on the requirements
    of different controllers, all possible computation offloading locations indirectly
    manage the production equipment to tasks at the closest power steering device.
    SDN controllers oversee data transmission routing, while lightweight containers
    such as Docker and Micro are utilized to offer computing. Reference [92] provide
    algorithm in fog system resource management to ensure each task’s specific service
    quality and optimize resource consumption by collaborating amongst fog computing
    nodes. Develop a common heterogeneous task download and resource method with Deep
    Recurrent Reinforcement Learning to optimize tasks within time restrictions. Depending
    on their buffer and resource state, the proposed method may offload their tasks
    into nearby nodes. Prevent unfairness in resource allocation slices with varied
    priorities, resulting in a higher average success rate. Which cloudlet should
    be utilized to offload a particular task from mobile devices is determined by
    [93] based on the load assessment of cloudlets in multi-cloudlet networks. Furthermore,
    SDN is used by this system to load balance between cloudlets in wireless mobile
    networks. Additionally, it suggests an admission control mechanism to limit the
    acceptance of task assignment requests made if there are more requests than the
    network can handle. Authors in [94] considered the multi-hop route and the impact
    of vehicle mobility while proposing a software-defined vehicle network offloading
    technique. It provided an ILP-based optimization problem for determining the ideal
    number of fog nodes for a given network in order to lower operating and capital
    costs. The dynamic offloading for soft real-time workloads in an SDN-based fog
    architecture is investigated in research [95]. Preliminary results have emphasized
    the impact of intra- and inter-fog cluster analysis on the expense of missing
    the deadline. Study [50] explores the offloading problem in IoV systems based
    on SDN and fog computing. It proposes an energy-aware dynamic offloading technique
    to extend the battery life of the IoV system and run more apps. The system model
    calculation and application transfer incur cost, and the heuristic searching optimization
    technique sometimes need assistance in order to find the best answer. However,
    testing on a real IoV edge network was not done in the experiment scenario. The
    Programming Protocol-independent Packet Processors(P4) framework allows for the
    direct execution of resource and system functions on the programmable data plane,
    including in the newly introduced P4. This functionality enables the shifting
    of specific tasks from the controller to specialized hardware, such as P4 switches.
    With P4, programmers can specify packet behavior in the data plane [13]. To optimize
    the efficiency of task-offloading solutions and reduce computational overhead
    and latency in IoT networks, [13] propose a P4-assisted task-offloading scheme
    for fog-based IoT networks. However, if the fog server has the necessary resources,
    the offloaded task from IoT device will be executed immediately; otherwise, the
    task will wait in the queue until those resources become available in the fog.
    As a result, the system becomes less effective, and task processing experiences
    slight delays. b: Centralized Task Offloading (Without SDN) Some research provides
    centralized architectures without using SDN. Authors in [96] provide Fogbus, a
    blockchain-based platform that integrates IoT, fog, edge, and cloud communications
    via user identification and data encryption. Duties are controlled by a fog called
    master fog, who distributes tasks to other fog nodes called workers. The mechanism
    chooses master fog and worker fog nodes at random. When confronted with enormous
    volumes of data and activities, system flexibility is reduced, and modifying and
    transmitting data from multiple nodes to identify the final processing node delays
    and system performance. This complex technique employs a rudimentary blockchain
    algorithm that the system administrator may activate or stop. As the blockchain
    is activated, the system latency rises immediately compared to the inactive state.
    Reference [97] provides a cost-effective compute offloading architecture for use
    in industrial networks. It works based on a fog federation in which a master fog
    controller manages the flow of traffic and data from IIoT sensors to the various
    fog nodes. Furthermore, it hired a policy-based reinforcement learning approach
    using a Q-learning algorithm and a controller-based device adaption strategy to
    regulate emergency-based service requests effectively and route them toward the
    fog devices along the shortest path. Reference [98] introduces a hierarchical
    paradigm for the IoT, fog, and the cloud. Distributed task execution may control
    global energy usage and enable highly scalable IoT applications. As a proof of
    concept, analyze the efficacy of a three-tier design by considering the processing
    needs of several IoT applications in medicine, multimedia, geolocation, and text.
    It evaluates three use cases employing real-world datasets: fog-only, cloud-only,
    and fog-cloud cooperative. SECTION V. Evaluation and Comparative Analysis The
    research about the offloading fog given in the offloading section were examined
    and compared in this part. Table 2 provides an overview of the studied algorithms,
    including the technique employed, the usage of SDN and the kind of protocol utilized,
    the metrics employed the type of simulator used, area of algorithm, and their
    notable features and constraints. As shown in the examination of the articles,
    the majority of the papers and algorithms are concerned with IoT to fog offloading,
    and a few methods have been described in the offloading section from one fog to
    another fog. TABLE 2 Summary of Task Offloading Algorithms Several things could
    be improved when looking at fog-to-fog algorithms utilizing SDN. Fog selection
    is a decision-making method with a high real-time processing requirement and is
    one of the main obstacles in the decision-making process and destination. On the
    other hand, reducing system efficiency by increasing the amount of fog and network
    traffic is a significant difficulty that most of these algorithm’s face. In addition,
    the network data plan could be more helpful in choosing the connection for offloading
    to the destination. Additionally, connection traffic and data plans must be appropriately
    considered when choosing a fog, which might increase the latency in data transmission
    to the target fog and cause the offloading process to halt and fail if the link
    fails. The following is a summary of the comparative evaluation and notable shortcomings
    in current approaches: A. Fog Offloading Algorithm Types Based on the reviewed
    research, we can categorize task offloading techniques as indicated in Figure
    4 fog computing employs a variety of task-offloading strategies. Machine learning
    uses data-driven judgements to adapt to changing situations, but it may need much
    training data and computing power. When well-modelled, mathematical optimization
    gives near-optimal solutions but is challenging and less adaptable. Heuristic
    approaches are simple and efficient, but they are not ideal. Blockchain-based
    offloading improves trust and decentralization while potentially adding overhead.
    The technique of choosing is determined by application requirements and resource
    availability while balancing flexibility, complexity, and trust factors. To summarize,
    fog computing task offloading strategies each have their own benefits and drawbacks
    that suit different application needs. To achieve a balance between flexibility
    and cost, the decision should take into account the unique demands of the application
    as well as the available resources. FIGURE 4. Task offloading algorithm types.
    Show All The combination of mathematical algorithms, AI algorithms, and blockchain
    technology with fog computing has resulted in varied and complex solutions for
    data and resource management. Each of these approaches has distinct advantages
    and constraints, making them crucial in the realm of fog computing. Mathematical
    techniques are often used in fog offloading for various purposes, such as task
    offloading, load balancing, energy optimization, and delay reduction. Their focused
    and precise approach offers practical answers for optimization difficulties, such
    as minimizing energy consumption and distributing computing workloads evenly.
    Nevertheless, they only sometimes provide the most favorable outcomes and may
    need significant processing resources since their effectiveness relies greatly
    on the particularities of the situation and the design of the algorithm. Although
    optimization and game theory based solutions are effective in some constrained
    contexts, matching-based techniques provide potential benefits due to their distributed
    nature and low computing cost methodology [82]. However, AI algorithms in fog
    computing are used for predictive analytics [97], dynamic decision-making [29],
    and adaptive resource management [92]. They possess exceptional flexibility and
    aptitude for learning, making them well-suited for dynamic and unexpected circumstances.
    The primary advantage of AI is its capacity to automate intricate decision-making
    procedures and predict forthcoming requirements. However, it also presents problems
    such as the need for extensive datasets, intricacy in training and implementing
    models, and sometimes, the opaqueness of decision-making processes. Blockchain
    technology [30], a recent addition to the field of fog computing, provides a clear
    benefit in terms of security and the preservation of data integrity. Blockchain
    guarantees a high degree of security by facilitating transparent and distributed
    transactions and communications inside fog networks, according to its distributed
    and tamper-evident characteristics. This capability is essential in remote computing
    systems, where maintaining the accuracy and reliability of data is of utmost importance.
    Nevertheless, blockchain faces a lot of constraints. Scalability problems arise,
    especially when dealing with higher transaction volumes, and the maintenance of
    a blockchain network needs significant resources. Furthermore, the process of
    incorporating blockchain into current systems has its own distinct set of difficulties.
    Ultimately, the selection of mathematical algorithms, AI, and blockchain in fog
    computing is determined by specific criteria such as security, flexibility, utilization
    of resources, and intricacy of the environment. Mathematical algorithms give precise
    and efficient solutions in certain situations, while AI brings flexibility and
    predictive capabilities. Additionally, blockchain ensures unmatched security and
    integrity in distributed systems. Frequently, using a hybrid strategy that capitalizes
    on the advantages of these varied technologies provides the most efficient answer
    in the complex realm of fog computing. Fog-to-fog offloading difficulties and
    challenges need a study and enhancement of route selection and decision selection
    algorithms and the successful use of SDN-based network characteristics. Due to
    the advancement of artificial intelligence and machine learning in multiple sectors,
    many of the approaches that have been seen have turned to employ machine learning,
    deep learning, or AI algorithms in fog computing algorithms. Although these algorithms
    have significantly improved predictions for fog offloading, employing them presents
    several difficulties owing to their high computational cost and the limited processing
    power in the network’s fog. Challenges like: Computing resources are plentiful
    for artificial intelligence, machine learning, and deep learning algorithms, while
    computing resources are scarce in fog. On the other hand, the amount of communication
    load and bandwidth required to transmit data between devices for fog calculations
    adds to the difficulty of fog calculations. B. Fog Computing Architecture The
    effects of centralized, distributed, and SDN techniques on fog computing algorithms
    differ. Algorithms can optimize task offloading in a centralized system with a
    global view of resources and network circumstances, resulting in theoretically
    optimum solutions but presenting a single point of failure and scalability difficulties.
    Distributed techniques disperse decision-making across fog nodes, depending on
    local data and cooperation, making them more robust but less globally optimum.
    SDN-based designs provide dynamic network management, improving algorithm flexibility
    and responsiveness to real-time network changes, but their efficacy depends on
    algorithm integration and network programming. Task offloading centralized and
    distributed schemes features comparison are shown in Table 3. As can be seen,
    centralized networks, particularly SDN, provide several benefits despite their
    limitations and low flexibility. Centralized management using controllers in the
    SDN network allows for more simple controlling and managing of the computing resources
    of various fogs in the network with high capabilities and low loads on fog nodes.
    TABLE 3 Task Offloading Networking Schemes Comparision In dynamic fog environments,
    where node availability, network circumstances, and workload vary, many of the
    current techniques may not be able to adapt properly. Inflexible strategies may
    not function as well as they could under changing circumstances, which might affect
    the system’s overall performance. Mitigating the negative impacts of a highly
    dynamic nature, such as the lack of fog device availability and end device mobility
    support, is an essential concern. SDN is a potential network architecture for
    fog computing because of its centralized, intelligent view and control of the
    network [95]. The following is an overview of the benefits and limitations of
    SDN architecture for fog offloading, including SDN protocols discussion: 1) SDN
    Advantages SDN enables the immediate acquisition of network state, allowing for
    real-time centralized network management based on current network status and user-defined
    rules. Furthermore, this results in advantages in optimizing network setups and
    enhancing network performance [99], which is crucial for fog networks to offload
    tasks immediately without delay. Configuration is crucial in network administration,
    particularly when incorporating new equipment into an established network. The
    difficulty stems from the diversity among network device manufacturers and their
    configuration interfaces, resulting in laborious and error-prone manual setup
    procedures. These errors need extensive troubleshooting efforts. SDN solves this
    problem by consolidating the control plane across different network devices, enabling
    centralized and automated setup via software control. This not only streamlines
    network administration but also allows for adaptive optimization depending on
    current network circumstances. The use of SDN in network configuration greatly
    affects fog computing networks by improving their capacity to quickly and easily
    manage and adjust fog devices to enable new applications and services. In light
    of the present network condition and demand, flow rules may be simply adjusted
    dynamically and optimally using SDN [100]. SDN significantly impacts mathematical
    algorithms [2], [11], [13], [20], [31], [50], [68], [90], [91], [95] by streamlining
    network resource management in fog computing, enhancing load balancing, task offloading,
    and latency optimization. The dynamic allocation of resources empowers these algorithms
    to optimize distribution based on real-time data and preset criteria. Additionally,
    SDN’s adaptability allows swift adjustments, bolstering algorithmic agility amidst
    network changes. In the realm of AI algorithms [20], [29], [69], [70], [92], SDN
    facilitates efficient data handling and routing crucial for decision-making processes.
    Its adaptability enables real-time resource optimization, augmenting AI system
    performance and scalability across diverse networks. Moreover, in blockchain integration
    [30], SDN aligns with the secure, distributed nature of transactions, enhancing
    network security and optimizing resource allocation. It also fosters improved
    interoperability among fog computing nodes, facilitating seamless integration
    of blockchain systems. 2) SDN Challenges Previous research has encountered many
    obstacles with conventional SDN-based handover, which leads to increased latency
    and packet losses because of centralized control. The increase in mobility cars
    puts a load on the main SDN controller, making it difficult to fulfill quality
    of service requirements and causing frequent handover problems. Further limiting
    their efficacy in high-mobility circumstances requires comprehensive simulation
    evaluations. In order to close this gap, article [10] presents a Vehicular ad-hoc
    networks (VANET) architecture that places changeover procedures at the edge of
    the network by merging SDN and fog computing technologies. This adaptable solution
    eases the load on core networks by decentralizing changeover management using
    zone SDN controllers and fog computing vehicles while meeting the needs of highly
    mobile and data-intensive services. Incorporating SDN into fog computing poses
    significant obstacles that need resolution. These tasks include guaranteeing the
    capacity to handle many fog devices and adaptability, improving security and privacy
    within a centralized control system, establishing compatibility across different
    technologies, and optimizing resource management to distribute the workload efficiently.
    Additionally, addressing the critical challenges of optimizing traffic flows while
    minimizing latency, enhancing the energy efficiency of SDN controllers and fog
    nodes, ensuring consistent Quality of Service and reliability in dynamic fog environments,
    and seamlessly integrating SDN into current network infrastructures is essential.
    The number of SDN controllers used in reviewed research is limited, so multi-controller
    scenario challenges need to be considered and discussed in massive networks. It
    is crucial to address these shortcomings to ensure the effective adoption of SDN
    in fog computing. This will need ongoing innovation and cooperation in the industry.
    3) SDN Protocols The OpenFlow [29], [50] protocol, which is well recognized in
    the field of Software-Defined Networking (SDN), provides extensive support and
    compatibility. However, it is limited in terms of flexibility because of its rigid
    architecture. Also it also has some security and scalability concerns. P4 [13],
    a more recent and adaptable protocol, enables the customization of packet processing.
    However, it is more complex and lacks widespread compatibility. In addition to
    these, other protocols such as NetConf and YANG provide network configuration
    management by providing structured data models and transactions. However, they
    may not possess the extensive programmability of P4 or the broad acceptance of
    OpenFlow. Each protocol fulfils distinct network needs, with OpenFlow being characterized
    by a higher level of standardization, P4 providing enhanced control capabilities,
    and NetConf or YANG concentrating on configuration management. The selection of
    either OpenFlow or P4 for fog offloading relies on the particular demands of the
    network. OpenFlow’s standardization and compatibility render it well-suited for
    contexts that priorities interoperability and stability. On the other hand, the
    ability of P4 to define packet processing behaviors is beneficial in situations
    that need customized and specialized data handling. Hence, if the task of offloading
    fog requires packet processing and flexibility that are highly specialized, P4
    would be the more suitable choice. However, for broader and standardized implementations,
    OpenFlow may be the preferred option. The particular needs and attributes of the
    fog computing environment will determine which SDN protocol is best for fog offloading.
    While Netconf is well-known for its simplicity and ease of use, making it a suitable
    match for easy network administration, OpenFlow is recognized for its fine-grained
    control and flexibility, making it excellent for dynamic and complicated network
    management. A network’s complexity, scalability, required functionality and accessible
    knowledge are among the variables that determine which SDN protocol is best. Other
    protocols, including BGP-SDN, ONOS, and Faucet each offer advantages and disadvantages.
    Depending on their particular requirements, certain fog computing architectures
    may even combine these protocols to handle different aspects of task offloading
    and network management. 4) SDN With Machine Learning The integration of SDN with
    Machine Learning may provide several advantages for Fog offloading. SDN offers
    a centralized perspective of the network, enabling the optimization of the decision-making
    process for selecting the most suitable Fog node for offloading. Machine learning
    may be used to create compute offloading strategies that enhance the efficiency
    and dependability of Fog computing. The advantages of integrating Software-Defined
    Networking (SDN) with Machine Learning (ML) for Fog offloading include enhanced
    utilization of storage and computing resources, improved performance metrics like
    latency, energy consumption, and Quality of Service, and the ability to dynamically
    allocate services based on objectives such as power consumption, security, and
    QoS constraints. Nevertheless, it is essential to take into account the drawbacks
    as well. The system’s complexity may result in elevated maintenance expenses.
    Acquiring substantial data to train machine learning models may be a significant
    obstacle. The confidentiality and integrity of the data being processed by the
    Fog nodes may be compromised. To address these challenges, employing lightweight
    methodologies such as federated learning might be effective in fog offloading.
    C. Metrics for Validation During fog offloading, route selection, latency, and
    energy metrics are crucial, yet not all research studies encompass these elements
    based on Table 2. Factors like problem complexity, limited resources, or research
    focus contribute to this omission. Some studies prioritize energy efficiency [50],
    [73], [83], [98], overlooking metrics like latency or route selection, while majority
    concentrate solely on delay optimization, disregarding energy concerns or routes.
    Some researchers highlighted path selection like [2], [69], [74], [85], [97].
    Due to experimental constraints or study scope, researchers sometimes explore
    only a subset of these metrics. However, disregarding any of these measures can
    significantly impact system performance. Neglecting energy efficiency may deplete
    IoT and Fog device battery life while overlooking latency can degrade user experience
    and system performance. Ignoring route selection may lead to poor data transfer
    and heightened network congestion. Therefore, considering all criteria remains
    paramount for optimal system performance in constructing an efficient fog offloading
    system. In prior frameworks, time issues are only partially explored, and the
    computing power of resources needs to be better used. The computational strain
    increases the overall delay time, deployment cost, and energy consumption of IoT
    devices or resource-enriched fog nodes, requiring an efficient task management
    strategy to address this issue. Real-time processing is hampered by the high latency
    and system overload caused by the AI techniques utilized in these systems. D.
    Simulation Limitation Most current articles have undergone testing and evaluation
    in simulated contexts, with only methods [13], [14], [50] applied in actual or
    near-real situations. Furthermore, various kinds of simulators have been employed,
    each with its own merits and drawbacks. The wide range of simulators and the intricate
    nature of different network topologies, particularly SDN, will significantly challenge
    the effectiveness of the suggested algorithms in the real world. While simulations
    carried out using simulators such as iFogSim and Mininet and Matlab, provide insightful
    results, real-world validation is essential. From simulation to real-world application,
    there might be unanticipated difficulties or new factors to take into account.
    Although there are many theoretical ideas, there may not be as much opportunity
    for these techniques’ practical application or real-world assessment. Real-world
    implementation and thorough testing under various conditions are essential to
    verify its efficacy and functionality of proposed algorithms. E. Dataset A primary
    obstacle is the need for uniformity in the datasets used for modelling and executing
    fog-offloading studies and publications. This makes it challenging to generalize
    the data and compare the outcomes of various investigations [101]. More real-world
    data is needed to support the simulation conclusions. This may result in exaggerated
    expectations and erroneous forecasts [101]. Additionally, the particular use case
    and the surrounding environment significantly impact fog computing systems’ performance.
    As a result, it’s critical to carefully choose the simulation tools and datasets
    suitable for the particular use case [102]. The majority of studies use randomized
    data or fail to identify the application as data and tasks that are delegated
    to other fog nodes. Nevertheless, a limited number of researches, such as [14],
    have used real datasets. Consequently, the outcomes of most of experiments may
    not be applicable to addressing real-world applications that need low latency
    or real-time execution. The absence of appropriate datasets and a simulation environment
    that accurately reflects the intricate nature of the fog space is a significant
    challenge. F. Scalability and Throughput As the number of nodes in the network
    increases, the system’s efficiency is significantly diminished. The issue of managing
    massive networks of fog will provide a significant obstacle to the system. In
    the technique described in reference [2], the maximum number of fogs is limited
    to 16, and only a single SDN controller is used. Just 5 fogs used in [29], [90]
    and in real testbed fog node limited to 2 fog in [50], 6 fogs in [13]. Other algorithms
    have also been presented with more fogs, but only a limited number of fogs have
    been tried in small spaces and networks. It has been observed that as the number
    of fogs increases, there is a considerable loss in efficiency. The use of more
    fog nodes in the experiments resulted in a reduction in the overall waiting time
    for tasks [13]. Delay or waiting time is one of the main metrics of related researches
    that is in front of the efficiency of systems, so should be considered. Scalability
    is a significant challenge, particularly in systems with many devices and fogs.
    High overhead approaches may need help scaling efficiently, affecting their viability
    in real-world applications. This can be true of communication overhead, compute
    overhead, or resource allocation. It is crucial to thoroughly evaluate the scalability
    of the suggested algorithms, particularly in practical smart city implementations,
    where the quantity of devices and fog resources may be much greater. G. Security
    and Privacy Maintaining data security and privacy throughout offloading procedures
    is an important yet difficult component. Many current techniques may disregard
    strong security safeguards, putting sensitive data at risk. The [12] merges fog
    computing, SDN, and blockchain to create a security framework for IoT in agriculture.
    By combining blockchain technology with SDN controllers, this design emphasizes
    safe IoT communication. This increases security and dependability, particularly
    for devices with limited resources. If the fog nodes in smart healthcare systems
    lack robust security protocols, there is a risk that malevolent users may be able
    to steal users’ private data. In addition, fog computing must address emerging
    issues, like resource limited IoT devices and insider assaults. In order to address
    these difficulties, [7] suggests implementing a secure authentication system for
    fog nodes in intelligent healthcare based on SDN. The system involves the implementation
    of an authentication algorithm in the SDN gateway to verify the credibility of
    the fog node. The IoT devices only need to transmit their privacy and functional
    properties to the SDN gateway to reduce the computational burden on the IoT devices.
    In the context of fog offloading, where the network environment is constantly
    changing, it is crucial to prioritize secure communication, authentication, and
    authorization. Nonetheless, these aspects have been overlooked in the majority
    of previous research and have not been taken into account. Software-Defined Networking
    (SDN) enables more effective management of these issues via its centralized control
    structure. The centralized method enables the application of security rules and
    network settings in a dynamic and flexible manner, capable of adjusting to evolving
    network circumstances and threats. SDN facilitates enhanced network visibility,
    a critical factor in detecting and addressing security breaches and anomalies.
    SDN facilitates the implementation of encryption, firewalls, and intrusion detection
    systems by unifying control. Conversely, in the absence of SDN, maintaining security
    in fog offloading settings necessitates the use of decentralized methods. This
    involves the implementation of distributed firewalls and intrusion detection systems
    at several network nodes. Effective communication in such situations depends significantly
    on effective peer-to-peer authentication techniques and resilient encryption mechanisms.
    Periodic updates and manual adjustments are essential to align security rules
    with the changing network environment. This technique requires more coordination
    among various network components and may exhibit less adaptability in rapidly
    evolving circumstances as compared to SDN-enabled systems. However, it enables
    a decentralized approach to security, which might be advantageous in situations
    where centralized control is impractical. A complete security architecture that
    includes secure communication, dynamic authentication, strong authorization, network
    segmentation, monitoring, blockchain integration, frequent updates, and user education
    is required due to the changing fog offloading scenario. Every aspect plays a
    vital role in strengthening the fog environment while adjusting to its constantly
    changing circumstance. H. Other Chalenges As indicated in Table 2, most current
    studies do not incorporate cloud offloading in their simulations and implementations.
    This omission can lead to delays in many scenarios due to the absence of a comprehensive
    and accurate integration of cloud services. If the cost and delay associated with
    cloud offloading are less than those of using other fog nodes, the efficiency
    of such algorithms in evaluating cloud offloading remains unaddressed. Consequently,
    when tasks are only offloaded to other fog nodes instead of the cloud, this may
    result in increased delays and costs, leading to reduced system efficiency. Due
    to the dynamic nature of the fog environment, it comprises many fogs with distinct
    memory capacities and processing capabilities. Conversely, the ongoing tasks vary
    in size and have varying deadlines. The intelligent organization of these tasks
    is a challenge faced by the majority of systems and algorithms since it aims to
    maximize the efficiency and capacity used by the fog computing infrastructure.
    For instance, in a scenario where there are three distinct fogs with varying available
    capacities and three different sizes of tasks (small, medium, and large), the
    optimal approach would involve transferring larger tasks to a fog with higher
    capacity and medium tasks to a fog with a proper capacity, smaller tasks to a
    fog with a sufficient capacity. Suppose a fog with more computational capacity
    is allocated to a minor task for any reason like it first come. In that case,
    the computational capacity of other fogs may not be sufficient for the enormous
    task, resulting in a potential delay in completing the task owing to the absence
    of a suitable fog with enough capacity. While several algorithms for resource
    and task management merely include these factors, managing resources and tasks
    concurrently to optimize task offloading efficiency and load balancing is still
    a significant and unavoidable difficulty in large-scale systems and real-time
    tasks that are ignored in most researches. One potential option to address this
    difficulty and enhance fog systems load balancing is integrating SDN with machine
    learning techniques. SDN may get the latest information on forthcoming tasks and
    fog resources. Machine learning can then use the knowledge stored in SDN to forecast
    future events and tasks and choose the most appropriate fog resource for offloading.
    Most previous studies assumed that the task size and fog capacity were the same.
    However, instead of using actual tasks, they have used randomly generated data,
    which fails to accurately depict the present state of the fog network in terms
    of task transmission, task processing, and real-time response. Addressing these
    gaps highlights the need for more flexible and comprehensive offloading approaches
    in the fog computing realm. Fog offloading solutions must improve with strategies
    that balance energy efficiency, scalability, security, flexibility, and latency
    in dynamic settings in a way that considers real-world implementation circumstances.
    SECTION VI. Discussion When a fog is overwhelmed, tasks should be transferred
    to another fog since it cannot process them (known as fog-to-fog offloading).
    In real-time computing, the process of determining and choosing the optimal destination
    node with adequate processing capacity in the quickest possible time is critical.
    Furthermore, most models disregard heterogeneity in computer infrastructure. In
    most present algorithms, when a fog gets overloaded, it asks that the central
    server introduce the destination node for offloading. Before determining which
    node to deploy, the central server evaluates and compares the available nodes.
    It takes a long time to request the central server, perform the decision algorithm,
    respond to the initial node, and ultimately upload data to the destination node.
    Also, choosing the optimum method to convey data from the main fog to the target
    fog is difficult since the selected path may be delayed due to traffic congestion.
    Because of traffic congestion on a particular route, another fog node with an
    acceptable and sufficient bandwidth for data transmission may be used. The issues
    in fog-to-fog offloading include making a judgment about picking fog with adequate
    resources in the shortest period and choosing a suitable way to transmit data.
    In older frameworks, time issues are explored from a limited perspective, and
    computing resources could be used more effectively. Implementing an efficient
    task management strategy is required to address this issue since computational
    strain increases the overall delay time, deployment costs, and energy consumption
    of IoT devices or resource-enriched fog nodes. Real-time processing is hampered
    by the AI algorithms utilized in these techniques, which also introduce significant
    delay and overload into the system. When looking into fog-to-fog algorithms utilizing
    SDN, many things could be improved. Fog selection is one of the main obstacles
    in the decision-making process and destination because it requires a decision-making
    algorithm that is time consuming and high cost in real-time processing. On the
    other hand, increasing the amount of network traffic and fog reduces system efficiency,
    which is a significant difficulty faced by the majority of these algorithms. The
    network data plan is not believed to successfully choose the connection for offloading
    to the destination. Additionally, connection traffic and data plans should be
    adequately taken into account when choosing a fog, which might cause data transmission
    to the target fog to be delayed. If the link fails, the offloading process will
    also halt and fail. A summary of the methods used in task offloading schemes is
    provided in TABLE 4. Fog-to-fog offloading concerns and difficulties need a study
    and enhancement of decision selection and route selection algorithms with appropriate
    use of SDN-based networks’ capabilities. To expedite and enhance the fog offloading
    algorithms, it effectively employs the characteristics and capabilities of SDN
    networks, and artificial intelligence is crucial. Due to the advancement of artificial
    intelligence and machine learning in multiple sectors, many of the diverse fog
    offloading techniques that have been seen have turned to employing AI. These algorithms
    present several difficulties owing to their high computational cost and the limited
    computing resources available in the network for fog, even though they have been
    highly successful in improving estimates for fog and clouds. Challenges like:
    While computational resources are scarce in fog, they are ample for computing
    machine learning, deep learning, and artificial intelligence algorithms. Contrastingly,
    the amount of bandwidth and communication burden required to transmit data between
    devices for offloading decisions makes fog offloading more challenging. TABLE
    4 Summary of Methodology Used in Task Offloading Schemes The term “link prediction-based”
    refers to a technique for maximizing traffic offloading that is based on link
    prediction. The link prediction-based strategy prioritizes traffic offloading
    by selecting relevant seed nodes for efficient data transmission while keeping
    quality of service (QoS) in mind. To optimize overall performance, it is vital
    to establish a balance between traffic dumping and minimizing time delay [103].
    Link prediction methods can assist in determining the optimum link and node to
    offload. In prior studies of resource management that can be addressed as future
    research, heterogeneity or homogeneity of fog nodes is an essential factor that
    keeps the same for different fogs. Another issue for future task management studies
    is partial or whole task offloading. The algorithms should divide and distribute
    tasks efficiently based on task size and priority. Depending on the fog processing
    constraints and task size, each task may offload partially or fully. Aside from
    time and delay, energy consumption and algorithm computation cost are essential
    metrics for fog offloading techniques that are often overlooked in many suggested
    algorithms and should be considered in future studies. While SDN has many benefits,
    it also has certain drawbacks. Latency remains an issue since faraway fog nodes
    or data centers introduce inevitable delays. The complexity of SDN deployment,
    possible security issues from centralized management, and increased network overhead
    may impede adoption. Interoperability concerns might develop, especially in heterogeneous
    fog computing environments, and the initial expense of specialized hardware and
    software may dissuade some organizations from using SDN for fog offloading. SDN’s
    applicability must be determined by carefully examining individual use cases and
    needs. Fog computing simulation has a number of drawbacks, such as issues with
    model accuracy, scalability, the lack of real-time elements, overhead, abstraction,
    and dependence on behavioral assumptions. It may be difficult to effectively simulate
    the dynamic nature of fog computing with constantly changing workloads and network
    circumstances. Further impediments include incomplete network models, problems
    with validation and verification, and low predictive power. Large-scale and resource-intensive
    simulations may also be difficult to execute due to resource limitations. Although
    simulations provide insightful information, they should be utilized with caution,
    and the findings should be interpreted considering these limitations. Real-world
    testing and simulation combined may lead to a more comprehensive knowledge of
    fog computing systems. SECTION VII. Conclusion and Future Work Most of the examined
    related fog offloading algorithms do not take a holistic approach to resource
    management, task management, and task offloading in the same system, instead focusing
    on one or two of these three critical components. Lake of this viewpoint will
    encounter several obstacles in implementing these algorithms in real-world complicated
    settings with various types of tasks and diverse fogs hardware and software with
    changing resources simultaneously. As a result, fog offloading systems need further
    development to be highly adaptable to IoT’s diverse and extensive real-time task
    response. SDN provides various advantages for fog offloading in computer systems.
    It enables network flexibility by enabling dynamic and programmable configurations
    to react to changing workloads. Centralized control streamlines decision-making
    for task offloading, optimizing routing, and enhancing service quality. SDN is
    a crucial tool for practical fog computing since it improves traffic optimization
    and scales to handle the rising number of IoT devices and fog nodes. SDN can manage
    the fog network effectively. However, its centralized and unique architecture
    does increase the possibility of initial implementation expenses. Machine learning
    may be helpful for fog processing if it transfers little data across the network
    while using far fewer computing resources. Machine learning may determine the
    decision-making process in choosing the connection link for data transmission
    and the fog destinations for offload. Selecting an efficient machine learning
    algorithm that decreases the computational burden on the network with its few
    connections and computation resource will be a problem solver. Therefore, future
    studies aim to speed up and enhance the fog-to-fog algorithm by efficiently using
    the capabilities and characteristics of SDN networks and artificial intelligence.
    Furthermore, the implementation of additional SDN controllers and Fog networks
    on a wider scale, together with conducting rigorous testing in real-world scenarios
    and networks, is viable. likewise, exploring the integration of SDN networks with
    both centralized and decentralized networks outside the realm of SDN may serve
    as a viable approach to accommodate and merge novel and more expansive networks
    and smart city challenges. ACKNOWLEDGMENT Any options, finding, and conclusion
    or recommendation expressed in this material are those of the author(s) and do
    not necessarily reflect the views of the United States Air Force. Authors Figures
    References Keywords More Like This Software-Defined Networking for Internet of
    Things: A Survey IEEE Internet of Things Journal Published: 2017 A Software-Defined-Networking-Enabled
    Approach for Edge-Cloud Computing in the Internet of Things IEEE Network Published:
    2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Fog Offloading and Task Management in IoT-Fog-Cloud Environment: Review
    of Algorithms, Networks and SDN Application.'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - David P.E.
  - Chelliah P.R.
  - Anandhakumar P.
  citation_count: '0'
  description: Edge computing in the era of digital transformation is slowly gaining
    momentum across many industries. It is expected to reach around 75% by 2025. Edge
    computing is adopted by many industries including the agricultural industry. This
    technology is helping to build the future of agriculture with smart farming. Though
    cloud infrastructure has already played an important role in developing the agricultural
    sector, edge computing wins the race in terms of speed and efficiency. The opportunity
    lies within precision agriculture when edge computing is applied to smart farming
    technologies. While using edge computing technology farmers depend on data to
    obtain improved control over the industry and optimize the efficiency of their
    operations which results in reduced operational expenses. Agriculture is one of
    the world's critical industries and has traditionally been slower to advance and
    adopt modern technologies than other industries. But now changes are taking place
    as digitization is becoming more attainable. The agricultural sector is realizing
    the benefits of advanced technologies like AI, process automation, edge computing,
    IoT, etc. Edge computing is one of the evolving technologies that have the potential
    to bring transformation in the agricultural sector. Digitization can help in overcoming
    some of the biggest challenges in agriculture by using sensors, real-time data-driven
    insights, and actuators. There are numerous use case examples for smart farming
    and agriculture starting from keeping track of climate changes and regulating
    the crop or cattle conditions to greenhouse automation and even farm management
    solutions.
  doi: 10.1016/bs.adcom.2023.08.007
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full volume
    Outline Abstract Keywords 1. Introduction 2. Smart agriculture 3. Smart farming
    initiatives is the need of the hour 4. Commonly used sensors for smart farming
    and heavy metal identification 5. High performance computing on edge (HPCE) 6.
    Processing in agriculture 7. The proposed system References Further reading Vitae
    Show full outline Figures (8) Show 2 more figures Tables (4) Table 1 Table 2 Table
    3 Table 4 Advances in Computers Volume 132, 2024, Pages 167-204 Chapter Nine -
    Reshaping agriculture using intelligent edge computing Author links open overlay
    panel Preetha Evangeline David a, Pethuru Raj Chelliah b, P. Anandhakumar c Show
    more Add to Mendeley Share Cite https://doi.org/10.1016/bs.adcom.2023.08.007 Get
    rights and content Abstract Edge computing in the era of digital transformation
    is slowly gaining momentum across many industries. It is expected to reach around
    75% by 2025. Edge computing is adopted by many industries including the agricultural
    industry. This technology is helping to build the future of agriculture with smart
    farming. Though cloud infrastructure has already played an important role in developing
    the agricultural sector, edge computing wins the race in terms of speed and efficiency.
    The opportunity lies within precision agriculture when edge computing is applied
    to smart farming technologies. While using edge computing technology farmers depend
    on data to obtain improved control over the industry and optimize the efficiency
    of their operations which results in reduced operational expenses. Agriculture
    is one of the world''s critical industries and has traditionally been slower to
    advance and adopt modern technologies than other industries. But now changes are
    taking place as digitization is becoming more attainable. The agricultural sector
    is realizing the benefits of advanced technologies like AI, process automation,
    edge computing, IoT, etc. Edge computing is one of the evolving technologies that
    have the potential to bring transformation in the agricultural sector. Digitization
    can help in overcoming some of the biggest challenges in agriculture by using
    sensors, real-time data-driven insights, and actuators. There are numerous use
    case examples for smart farming and agriculture starting from keeping track of
    climate changes and regulating the crop or cattle conditions to greenhouse automation
    and even farm management solutions. Previous chapter in volume Next chapter in
    volume Keywords Edge intelligenceSmart agricultureHybrid algorithmsEdge services
    1. Introduction The agricultural sector in developing countries has multiple challenges,
    i.e., if we look at the production side, the first challenge which the farmer
    faces is the productivity challenge, as it becomes evident that developing countries
    are very low in productivity, i.e., for any crop, the particular developing country
    could be the highest producer but at the same time its productivity could be very
    low. Therefore, crop productivity is a significant factor which has to be looked
    at. The second challenge which the farmer faces is with respect to climate change,
    industrial pollution, and pest attacks, as they can damage crops substantially.
    It is deemed necessary for the farmer to mitigate those challenges by adapting
    to the latest technologies and insurance schemes. The third challenge is related
    to market connectivity, whereby the farmer produces crops and thus needs to be
    connected to distant markets as per the crop production analysis and its subsequent
    data insights. It is essential for the farmers to have all the information on
    a digital platform and there should be seamless trade between different markets
    and different places. However, this connection between farmers and the distant
    market is nowhere to be seen in developing countries. On the other hand, the industry
    is looking up for exports, which in turn need to be streamlined substantially.
    From the economic perspective of the developing country, it is a boon if more
    facility in nature and regulatory support has to be given for people who are looking
    to export outside their country or who are looking to have a value-added product
    across the globe. Now, this mismanagement in the agricultural sector can potentially
    lead to food security risk. Precision Agriculture (PA) is intended to help and
    maximize the development of the farming sector and will also help to ensure food
    security [1]. It is to be highlighted that PA is a high-tech farming technology
    that observes, measures, and analyzes farming fields and crops. With the advent
    of PA, on-field sensors can provide detailed levels of data for problems of soil
    and weather conditions pertaining to heavy metal toxics and climate change. Big
    data obtained from sensor networks and farm inputs tracking have a significant
    role to play to increase farm productivity, reduce environmental impacts, and
    improve human welfare [2]. By combining artificial intelligence-based big data
    analytics with sensor and image data, an integrated system could be developed
    for the agricultural domain. Implementing intensive, high-value, personalized
    management of crops would increase both production and economic performance. The
    aim of this paper is to highlight the importance of smart sensors and high-performance
    computing in protecting stakeholders in the agrifood value chain and providing
    them with unlimited access to a large dataset of various categories in order to
    track their farms. The challenges and consideration for the farming sector in
    developing countries are also highlighted. Smart agriculture is always connected
    with high volumes of heterogeneous data sources such as autonomous tractors, harvesters,
    robots and drones, sensors, and actuators. Heterogeneous sensors and other devices
    collect relevant agricultural data such as humidity, temperature, pH, and soil
    conditions. Similarly, it considers the use of various actuators, such as water
    sprinklers, ventilation devices, lighting, automated windows (in glasshouses),
    and soil and water nutrition pumps that react according to the data. The number
    of cloud-based agricultural standalone systems and physical systems is increasing
    on an almost daily basis, helping to achieve a range of monitoring and analyzing
    objectives. Moreover, the last few years of publications have shown that modern
    computing paradigms such as Cloud, Fog, and Edge play a vital role in agriculture.
    The main applications of Cloud, Fog, and Edge Computing in agriculture are crop
    farming, livestock, and greenhouses, which are grouped into different application
    domains. Some of these applications are implemented with the help of IoT-based
    sensors and devices by using wireless sensor networks (WSNs), and some other applications
    are developed with combinations of new computing. For instance, Cloud and Fog,
    Cloud and Edge, Fog and Edge, or Cloud–Fog–Edge and IoT. 2. Smart agriculture
    Smart Agriculture or Smart Farming is an emerging concept that uses modern technologies
    in agriculture and livestock production to increase production, quantity, and
    quality, by making maximum use of resources and minimizing the environmental impact.
    This is demonstrated when farmers and all stakeholders related to agriculture
    use modern technologies and smart devices to monitor their farms, equipment, crops,
    and livestock. Using these devices, they can also obtain statistics on their livestock
    feeding and production of crops [3], [4], [5]. In recent years, smart farming
    has become helpful to all agricultural stakeholders from small to large scale.
    Smart farming provides benefits not only to scientists and agronomists but also
    to farmers to access modern technologies and devices that help in the maximization
    of product quality and quantity while reducing the cost of farming [3]. Smart
    farming mainly focuses on soil fertility, energy, grassland, water, feed, inputs
    and waste, machinery, and time management [6], [7]. The integration of modern
    technologies with agriculture achieves the objectives of smart agriculture such
    as efficiency, sustainability, and availability [8], increased production, water-saving,
    better quality, reduced costs, pest detection, and animal health [9], [10]. The
    other aims are to increase the reliability of spatially explicit data [3], make
    agriculture more profitable for the farmer [3], and offer the farmer the option
    of actively intervening in processes or controlling them [11]. Moreover, big data
    analysis is another goal of smart farming. Big data consist of massive volumes
    and a wide variety of data that are generated and captured by agricultural sensors
    and actuators. In particular, data collected from the field, farm, animals, and
    greenhouses include information on planting, spraying, materials, yields, in-season
    imagery, soil types, and weather. Big data analysis provides efficient techniques
    to do a quality analysis for decision-making [12]. In the coming years, smart
    agriculture is projected to create a significant impact on the world agricultural
    economy by applying all modern technologies. Edge AI will transform the agriculture
    industry. In most cases, farmlands are localized where there is no availability
    of high-speed bandwidth, inappropriate resources to handle data, and it is also
    found that the farmers are not adequately educated about the best practices of
    agriculture. AI practices as follows: 1. Soil quality: Examining the soil moisture
    using a mobile device by checking the farm location and the soil color. 2. Milch
    animals'' health: Tracking the health of livestock by tagging the sensors will
    give the temperature, heart rate etc. and provide insights about the health condition.
    3. Crop Health Analysis: A predictive computation engine, such as drones, can
    be used to check the health of leaves based on color and the pores it has, whether
    attacked by insects, pests, or rodents. 4. Disaster protection: Using edge computing,
    agriculture IoT systems can make informed decisions about potential environmental
    hazards or natural disasters. 5. Examining leaves health: A predictive computation
    engine, such as drones, can be used to check the health of leaves based on color
    and the pores it has, whether attacked by insects, pests, or rodents. 6. Analyzing
    satellite imagery: Deep analysis of satellite images provides an understanding
    of agricultural systems. With the help of Geo-spatial data, farmers can get information
    on crop distribution patterns across the globe along with the impact of weather
    changes on agriculture, among other applications. 7. Assess crop and soil heat:
    Predict the effect of different microbes on the health of plants and identify
    genetic changes that may cause due to harmful pathogens for the plant, among other
    things. 8. Predictive Analytics: Predictive models in AI help to do seasonal analysis,
    represent different market scenarios and optimize business costs. So, here are
    some of the opportunities that can be brought in by edge computing: 2.1. Ag robots
    Autonomous tractors and robotic machinery can run automatically without the intervention
    of humans, and this can be done with the help of edge computing. The tractors
    can communicate with nearby sensors to acquire necessary data about the surrounding
    environment. Ag robots can evaluate the most efficient ways to cover the required
    area taking into consideration the type of task performed, number of vehicles
    existing in the field, size of apparatus, etc. Edge computing will enable the
    ag robots to use computer vision and pre-loaded field data and to interpret the
    insights from that data. Additionally, the automated tractors can reroute automatically
    if there is any obstacle like if there is any animal or human in the way. Such
    smart implements can execute a broad range of tasks, like watering, weeding specific
    field areas when needed, or even autonomously harvesting crops. 2.2. Farm automation
    Similar to ag robots, a greenhouse or even a whole farm can be put on autopilot
    using IoT edge computing. This indicates that the whole ecosystem can perform
    the tasks itself without depending on a remote server to process the accumulated
    data and make decisions about day-to-day processes like feeding the cattle, watering
    the plants, controlling the temperature, humidity, light, etc. Edge computing
    will enable the farm or greenhouse to work without depending on the connection
    to the main server and make decisions based on data from local sensors. This can
    result in improved process reliability and reduced waste, making agriculture a
    more sustainable process. 2.3. Disaster protection Agriculture IoT systems can
    make sophisticated decisions about possible environmental hazards or natural disasters
    with the help of edge computing. Remote sensors can accumulate and examine data
    regarding the changes in the weather or the environment to forecast possible disasters.
    If there are definite indications of danger, they can instantly process the information
    to the general control center. Farmers thus will be able to take real-time appropriate
    measures to shield their crops. It is expected that the dependence on edge computing
    by enterprise-owned IoT devices will reach 6.5 billion in the coming year. Agriculture
    now has all the opportunities to lead the innovation in this field including manufacturing,
    transportation, energy, retail, and healthcare. This indicates that we can predict
    more edge computing use cases in agriculture soon. 3. Smart farming initiatives
    is the need of the hour With the advent of Internet of Things (IoT), smart devices
    have reached into all facets of our day-to-day life, i.e., healthcare and wellness,
    smart homes, automobile and logistics, intelligent cities and industries. In recent
    decades, agriculture has seen a series of technological changes, increasingly
    industrialized and technologically driven. Through different agriculture-based
    smart devices, farmers today now have greater control over animal husbandry and
    cultivation processes, making them more predictable and productive. This, along
    with the rising market demand for agricultural products, has helped to increase
    the worldwide proliferation of intelligent agriculture technologies. Modern agriculture
    can be addressed in several respects. For instance, AgriTech refers to the use
    of technology in the domain of agriculture. In addition, intelligent agriculture
    is primarily used to describe the use of IoT-based agricultural solutions. With
    IoT sensors, farmers can make informed decisions and develop various parameters
    of their work, i.e., cattle to crop production, in order to collect environmental
    and machine metrics. For example, farmers can decide exactly how much pesticide
    and fertilizer is to be utilized to optimize productivity by using smart agriculture
    sensors for monitoring crop status. The same applies to the concept of intelligent
    farming. Fig. 1 shows a broader perspective on a modern-day agricultural model,
    which incorporates various wireless sensor nodes to enable IoT-based farming with
    satellite communication, where different ground sensors are deployed which communicate
    with the cloud computing node for data processing and analysis, so that farmers
    can make correct decisions. Download : Download high-res image (249KB) Download
    : Download full-size image Fig. 1. Edge architecture. Although smart IoT and industrial
    IoT are not as common as consumer-connected devices, the market continues to be
    very competitive. IoT technologies are increasingly being implemented for agriculture.
    COVID-19 has had a positive impact on IoT market share in agriculture. Indeed,
    the smart framing market share is expected to hit $6.2 billion by the end of 2021,
    as reported recently. It is evident that COVID-19 has made a significant impact
    on the farming sector across the world. However, the agricultural sector is showing
    potential to make a strong comeback by leveraging positive government policies
    which indicate adoption of advanced technologies by making substantial investment
    in the agricultural sector. This initiative will make room for IoT-based agricultural
    solutions as a prominent business strategy, thus causing a reasonable increment
    in crop production. However, in the current situation, the market is expected
    to show a decline up to 0.8% for the first two quarters of year 2021 compared
    to 2020 and this trend will show a positive growth from 2022 onwards. In addition
    to this, the smart world agriculture market is projected to triple to 15.3 billion
    dollars by 2025, compared to just over 5 billion dollars back in 2016. If the
    sector continues to expand, there will still be plenty of opportunities for companies.
    In the coming years, creating IoT products for agriculture will distinguish companies
    as early adopters, thus helping to pave the way for success. This model can be
    used for any other application domain with some minor changes based on the domain
    requirements. In the proposed architecture, the Cloud layer is mainly for ample
    scale data storage and data analytics. This layer is also responsible for loading
    algorithms and data analytical tools to Fog nodes. This can also be used to store
    backup data for future analysis. The Fog layer is essential in this model, and
    this will be installed in local farms. Fog layers will be responsible for real-time
    data analytics such as predicting pests and diseases, yield prediction, weather
    prediction, and agricultural monitoring automation. Moreover, this will make decisions
    on real-time data and do reasoning analysis as well. Finally, the processed and
    analyzed data can be uploaded to the Cloud layer for backup purposes or further
    analysis. The third layer is the Edge, consisting of end devices, tractors, sensors,
    and actuators. The main goal of this layer is the collection of data and its transfer
    to the Fog layer. 4. Commonly used sensors for smart farming and heavy metal identification
    Sensors for Soil Moisture (SM) have been used in crop fields for decades to measure
    water content. The use of handheld/manual soil moisture technology is increasingly
    being replaced by automated technologies, since there were difficulties in manual
    soil moisture readings in remote production areas. In the past decade, technology
    has been developed for wireless data collection, providing managers and users
    with real-time access to soil moisture data, resulting in more successful water
    management decisions. Some of the prominent sensing devices to measure soil moisture
    comprise gravimetric sampling, resistive sensors, capacitive sensors, and Ground
    Penetrating Radar (GPR). Gravimetric sampling is a direct and normal SM measurement
    tool. SM is determined by a proportion of dry soil mass to wet soil mass including
    pores. It needs the manual drying of soil samples taken from the field and oven
    sampling. The electrical conductivity of water and the measuring of resistance
    changes based on soil water content are primarily resistive sensors, such as granular
    matrix sensors. This method includes sensor calibration for precise SM reading.
    Intelligent irrigation-based measurement to maintain soil moisture levels is significant
    to improve plant productivity and quality. On the other hand, soil moisture sensors
    these days are expensive, i.e., the ECHO-EC5 soil moisture sensor costs around
    USD 169. In order to overcome the cost constraint factor, Wang et al.proposed
    an RFID-based GreenTag sensor to maintain and improvise plant productivity and
    quality. In addition, RFID sensors can be combined with biosensors comprising
    aptamer and DNA-based properties which can be used to detect heavy metals at nanoscale
    and large scale levels pertaining to food safety monitoring. A heavy metal detection-based
    biosensor is composed of genetically modified bacterial cells and a green fluorescent
    signal amplifier which detects the presence of arsenite in foods. Its arsenic
    detection lasts for an hour with a detection range of 5–140 μg/L. Other methodologies
    pertaining to biosensors, i.e., aptamers and graphene electrodes, have also been
    used to detect arsenic with the possibility of being developed as simple and easy-to-use
    low-cost devices. The EC-5 series sensors were also used by Wu et al. for field-specific
    calibration and evaluation in sandy soils. Nonetheless, EC-5 sensors have turned
    out to be helpful to reveal soil water content dynamics in different soil depths
    post rainfall conditions. The ECHO series has other variants of sensors; i.e.,
    ECHO-EA10 can be used for medium textured soil type with low electrical conductance
    conditions. In addition to this, there is ECHO-10HS soil moisture sensor which
    is a new addition in the soil moisture sensor family and possesses high-frequency
    oscillation, which enables the sensors to accurately measure soil moisture in
    any of the soil or soilless media with minimum salinity and textural effects.
    In order to measure soil water content and salinity, Zemni et al. used 5TE sensors
    at different soil depths to assess dielectric permittivity (Ka) and electrical
    conductivity (ECa). It is to be noted that 5TE sensors are based on frequency
    domain reflectometry (FDR); therefore, they use a fixed frequency wave of broadband
    signal which makes the device cheaper and more compact. Nolz et al. deployed hydro
    probe2 sensors to evaluate near surface soil water and determine in situ water
    retention function. Hydro probe sensors are advantageous due to their linear signal
    response. On the contrary, hydro probe sensors are not suitable for sandy soils.
    Udukumburage et al. used an MP406 soil moisture sensor to verify the saturated
    condition of the expansive soil layer. They also used this sensor to measure volumetric
    water content values in the soil column during the wetting and drying process.
    In order to maintain the indoor ecosystem services, air quality plays an essential
    role. In this regard, MIKROE gas sensors are used to monitor the air quality.
    To evaluate and assess the vegetation change and study physiological and metabolic
    response of corn fields and paddy fields, the Pogo II VWC has been widely used.
    Hu et al. used Portable X-ray Fluorescence Spectroscopy (PXRF) to assess the heavy
    metal content in soil for which they covered 301 farmland soils from Fuyang in
    Zhejiang Province, in the southern Yangtze River Delta, China. Conventional methods
    for heavy metal detection such as Atomic Absorption Spectrometry (AAS), Atomic
    Fluorescence Spectrometry (AFS), and Inductively Coupled Plasma Optical Emission
    Spectroscopy (ICP-OES), are expensive and lengthy procedures which are executed
    in laboratories. Therefore, these methods are not taken into consideration for
    rapid testing and high-density evaluation of soil heavy metals contamination.
    As an alternative method for rapid heavy metal detection, Portable X-ray Fluorescence
    (PXRF) was used to assess cumulative concentrations of soil heavy metals based
    on linear regression models between fluorescence intensity and specific heavy
    metal concentration. Due to its ease of use and rapid testing ability using non-destructive
    quantification, PXRF has been widely used by researchers in numerous domains.
    For the heavy metal assessment in agricultural soil conducted by Hu et al. VNIR
    sensor was used to anticipate soil properties comprising pH, soil nitrogen, and
    carbon. In addition to PXRF, NixPRO color sensor can also be used to identify
    hotspots and total spatial area in excess of environmental thresholds in landfill
    soils. Lately Zhao and Liu have developed a Portable Electrochemical System (PES)
    for on-site heavy metal detection on farmland. Their system was composed of a
    three-electrode configuration which comprised a signal acquisition system integrated
    with a microcontroller-based potentiostat to perform square-wave anodic stripping
    voltammetry. Their system was assessed by testing the detection of pd.(II) and
    cd(II) in acetic acid soil extracts and acetate buffer solution. However, their
    system did not include any wireless sensor module to transmit heavy metal composition
    data. Other than the aforementioned sensors, there are several other wireless
    sensors dedicated to: photosynthesis, i.e., Beta Therm temperature sensor; leaf
    wetness sensor, i.e., SLWA-M003; precision sensor for leaf temperature, i.e.,
    ΔLA-C; light intensity sensor, i.e., BH1750FUI sensor. With the advent of these
    sensors, CO2 sensors also play an essential role, especially in greenhouse systems.
    CO2 sensors have also been widely used to measure the subsequent level in peat
    soil, landfill, and forest control site. In the smart farming ecosystem, the growth
    and quality of the fruit bunch cannot be neglected. In this regard, there are
    dedicated fruit growth monitoring sensors which researchers have used in their
    domain of plantation. Thalheimer designed an optoelectronics sensor for monitoring
    fruit and stem radial growth. Their developed sensor was lightweight and easy
    to install with low maintenance. Nonetheless, the sensor was well tested in open
    field conditions. In addition to this, the effect of gas concentration during
    the fruit growth was studied by Ma et al., for which a smart ethylene electrochemical
    sensor was established to investigate ethylene emission from fruits. Lately, Hanssens
    et al. came up with a heat field deformation sensor to measure sap flow dynamics
    through the tomato peduncle. Heat griddling of the peduncle was performed to differentiate
    flow of xylem and phloem with respect to developing fruits. Capacitive sensors
    calculate SM on the basis of changes in soil capacitance due to differences in
    water content. Commercial UTs use capacitive sensors, which are usually more accurate
    than resistive sensors but cost more. Ground Penetrating Radars (GPR) are based
    upon electromagnetic wave absorption and reflection. SM sensing uses impulses,
    frequency sweeping, and frequency-modulated technologies. This method is used
    for measuring soil moisture near the surface (up to 10 cm). The most reliable
    soil humidity samples used in fields are neutron scattering samples and scattering
    samples use radiation methods for calculating SM by estimating changes to the
    neutron flux density due to water content of the soil. However, in such cases,
    specific licenses are required to carry out its implementation. Numerous research
    studies have been performed to develop electrochemical devices for various applications,
    which are known as potentiostat. Lately, an Arduino-based potentiostat was fabricated
    from cost-efficient components and was able to execute simple electrochemical
    experiments, whereby the results were recorded and analyzed in a Windows operating
    system via USB interface. As an addition to Arduino-based potentiostat, Raspberry
    Pi (RPi) controller was also used to execute the electrochemical experiments,
    whereby the results were displayed on the LCD touch panel connected to the controller.
    Both Arduino- and Raspberry Pi-based potentiostat have the potential to incorporate
    wireless sensors for data transmission; however, these controllers do not contain
    a built-in Analog to Digital Converter (ADC) and Digital to Analog Converter (DAC)
    which make the overall design more sophisticated. In this regard, Hanisah et al.
    came up with a portable Heavy Metal Potentiostat (HMstat) to detect heavy metal
    composition on-site. Their potentiostat comprised a digital Control Signal Component
    (CSC) and the electronic component, which is the analog Potentiostat Read-out
    Circuit Component (PRCC), Nonetheless, it is worth noting that both the Arduino
    and RPi controller board do support the incorporation of various sensor modules.
    Therefore, researchers have room to incorporate soil moisture and temperature
    sensors along with other sensors depending on the slots available in the controller;
    thus, an integrated system for soil moisture and heavy metal analysis can be developed.
    Other soil physical properties can be calculated to populate the map of the soil
    with other soil properties such as soil organic content, pH, sand, silt particles
    percentage, and nutrients such as Mg, P, OM, Ca, base saturation Mg, base saturation
    K, base saturation Ca, CEC, and K/Mg. In situ, calculating these properties in
    real time also faces challenges due to scale, cost, and technology limitations.
    In precision farming, some of the long-lasting decisions can be taken using yield
    monitoring. This method helps in providing spatial distribution of crop yields
    at the end of the growing season. Yield sensors are normally mounted on farm equipment
    and capture yield data automatically in the course of the harvest. In particular,
    mass flow sensors on grain containers are mounted to record grain inflows along
    with the position. The collected data are analyzed with tools such as ArchInfo,
    Mapinfo, and Environment System Analysis International. In order to get an insight
    into the crop yield combined with field topography, Electrical Conductivity (EC)
    sensors are used. Soil''s ability to conduct current is measured by electrical
    conductivity. EC assessment is used to assess the use of phosphorus, cations in
    water, drainage, and rooting depths. EC maps are used for zoning the area. The
    zoning is also used to incorporate precision agricultural practices such as variable
    rate irrigation, variable rate seeding, and drainage management. Electromagnetic
    Induction (EMI) methods can be used for the mapping of the EC by apparent Electrical
    Conductance (ECa) and Visible Near Infrared Reflectance (VNIR). There are a number
    of commercial tools available, i.e., Veris 3100, EC400 sensors in conjunction
    with GPS systems. In the domain of soil sensing, macronutrients such as nitrogen,
    potassium, and phosphorus are essential to the growth of crops. The evaluation
    of these nutrients helps to assess the effects of fertilizer and potential applications.
    The optical detection is based on reflectance spectroscopy to measure the macrosimulation''s
    reflection and absorption. A sensing system using planar electromagnetic sensors
    has been developed in the detection of nitrate and sulphate concentration in natural
    water resources. This approach is used to detect the amounts of nitrate and sulphates
    by correlating the impedance of the sensor array with their concentration. The
    key approaches to soil macronutrients include electrochemical, VIS-NIRS, and ATR
    spectroscopy. These approaches to soil macronutrients are limited to sensing a
    single desired ion because the membrane used in these methods only reacts to one
    ion. To achieve a simultaneous multi-ion sensing, it is necessary to build a detector
    array for the sensing of soil macro nutrients. There are several opportunities
    to advance the state of precision farming through the utilization of the above
    discussed sensors. 5. High performance computing on edge (HPCE) This new High-Performance
    Computing (HPC) solution seeks to move beyond the agricultural services offered
    on edge and provide a comprehensive platform for precision farming and animal
    husbandry and furnish with utility not only for farmers but also for stakeholders.
    The HPCE architecture is adapted from CYBELE conceptual framework. The HPCE model
    uses open and proprietary vast amounts of datasets, including sensor readings,
    as well as satellite data and historic climatic and environmental information
    for ready reference. While this would be the most effective way to use HPC technology,
    it only uses the latest software platforms and projects that are being developed
    by HPCE''s e-controlled services, as well as increased HPC e-infrastructure to
    enable huge heterogeneous data processing to be done and find modern solutions
    to complex problems using dedicated algorithms. Due to the interconnection of
    large-oriented approaches, varying datasets, and available big data techniques,
    it is possible to scale distributed big data research to enormous scales when
    holding many types of datasets together in one place. In doing so, it enables
    the aggregated data and metadata to be aligned semantically to a standard scheme
    and data model and enables advanced data analytics to take secret information
    into account. In addition to this, the HPCE architecture will also help in gaining
    insights from adaptive data visualization services. With reference to CYBELE,
    the architectural approach of the HPC on edge and by organizing a product component
    based on interdependencies, this is intended to highlight the importance of pipelines
    being constructed to promote compatibility and show how to maintain the integrity
    of interdependent services. It is worth noting that CYBELE resonates well with
    the EdgeX platform architecture. EdgeX platform comprises four core services,
    i.e., device services, core services, supporting services, and application services
    to enable smooth workflow optimization. In addition, it will be interesting to
    see a synchronization of EdgeX with a dedicated HPC framework for faster batch
    processing of data over edge. Big, heterogeneous data are made available through
    repositories powered by HPC which is responsible for the processing at the edge
    layer. In this regard, HPC frameworks such as Spark, Hadoop, YARN, Big Deep Learning
    (BigDL), Directed Acyclic Graph (DAG), and Kubernetes are deployed for the batch
    processing of data using distributed framework attached to the edge layer. It
    is worth noting that Spark and BigDL are the widely used frameworks in many organizations
    for their open source and high degree of interoperability features. Spark and
    BigDL are based on MapReduce framework which has high room for tuning for smooth
    workflow optimization. The transmission of the application process interface along
    with data from the cloud layer to the edge layer is conducted using 4G/5G or fiber/DOCSIS/DSL
    communication system. This is seen on the middle section of the architecture.
    At first, the data are processed in the background prior to being passed on to
    the check-in stage for data validator or timestamp validator for resolution of
    data verification and timing problems. Once data are obtained in edge layer, quality
    checks are conducted to identify anomalies and any other data irregularities,
    maintaining their accuracy and validity, which are accompanied by a series of
    measures aligned with processes of data cleansing. Finally, the HPE data provenance
    service provides the mechanisms required for recording all relevant information
    concerning incoming data of interest. With HPE, the data provenance platform is
    inherently connected to the data policy and asset brokerage engine that enables
    the platform to bind data providers and data users with data share and business
    features. In addition to facilitating interoperability and reuse of data, the
    inspected data are annotated and harmonized semantically. Since the data come
    from a variety of physically distributed data sources, a standard data model will
    be created for the semantic definition and annotation of the data. To facilitate
    the pipeline and allow the various heterogeneous components to communicate seamlessly,
    the model will be used as a common language to annotate data and exchange messages
    between the components. Clean and semantically uplifted data are then available,
    i.e., open and proprietary data to be queried, analyzed, and viewed. An exemplification
    of how ground sensors have their data stored and analyzed at cloud data base.
    The on-field data are continuously assessed by a real-time monitoring system to
    ensure triggering effects if any threshold point is crossed. Simultaneously, the
    on-field data are also stored in the cloud database from where the user can download
    the required data and at the same time, data analysis could be applied using the
    machine learning tools stored over the cloud database. To facilitate simulation
    execution, a defined experimental composition setting is designed, as shown in
    the top right part of the architecture (cloud layer). The composition framework
    of experiments aims to support the separate design, development, and execution
    of big data research procedures, the support of embedded scientific computation
    and reproductive tests. In the analysis method, its subsequent template is selected
    to provide each analytical template with its own software and execution endpoint
    and allow the user to modify the appropriate configuration variables (i.e., input
    algorithm, execution parameters, netting parameters, and output parameters). The
    results of each analytical template are presented. The composition system for
    experiments will promote the design and implementation of data analysis workflows
    consisting of a number of data analysis procedures, interconnected in terms of
    data sources and input and output artifacts. The outcome will constitute the input
    to another research template when a template is executed. The output of the research
    model is an object for session that contains all the memory output values. In
    addition to big data, advanced analysis must be implemented when selecting input
    datasets and developing workflows. For HPCE, advanced analytical algorithms are
    available to stakeholders that allow them to explore various forms of data visually
    and to find and solve new trends. In order to achieve improved delivery and monitoring,
    machining and predictive modeling methods should be modified so as to handle the
    predictive life cycle of data planning, detection, and analysis. However, the
    implementation of advanced analytics along with huge, complex data increases the
    need for strong computing power and a higher processing memory, so that information
    can be collected within a realistic timeframe. When the test cases are executed,
    multiple HPC attributes are needed, including storage power, speed of the device,
    memory capacity, and quick turnaround time. The next section discusses the IoT-based
    communication methodologies in edge computing used for precision farming developed
    by several researchers. 6. Processing in agriculture Edge Computing is like a
    specialization of the Internet of Things. Without it, all data collected through
    IoT devices are sent to a cloud centre for processing. With the new technology,
    on the other hand, the collected data is classified locally, so that part of it
    is processed right there, on the “edge” of the network, hence the name edge computing
    through micro data centres. Thus, only certain information is sent to a cloud
    centre, while those that often need to be consulted are analyzed on the device
    itself in the case of agribusiness, in the field reducing data traffic. This ability
    to perform advanced analytics close to the data source meets the market''s need
    to cope with increasing traffic demands. As there is a screening of the information
    that will be sent to the processing centre, transfer rates are optimized. The
    main benefits of Edge Computing are the reduction in bandwidth required for sending
    and processing data and the decrease in latency, which is the response time of
    a request — the period in milliseconds that a data takes to navigate from where
    it was generated to where it will be processed. Both advantages are possible due
    to the proximity between the processing location and the origin of the information;
    only with cloud computing, on the other hand, all data would need to travel long
    distances before returning to consumption. In practice, this reduction in latency
    helps in real-time data access, which is essential for the implementation, with
    maximum effectiveness, of digital and intelligent solutions in agricultural processes.
    Certain functions can be performed on the equipment itself through Edge Computing,
    making it easier to make smarter and more agile decisions. Another example is
    the use of this technology in an agricultural spraying activity, in which sensory
    devices are enabled to determine alone which area should be sprayed, using the
    data collected and analyzed by the devices themselves. As Edge Computing also
    reduces the bandwidth required for processing, the solution becomes even more
    useful for agricultural applications. In the current context, in which IoT solutions
    already allow wide integration between various products, such as sensors, on-board
    computers, edge computing machines, is playing an increasingly important role
    in the application and evolution of technology in the field. It is one of the
    technologies that will have increasing adoption in the coming years, accelerating
    the consolidation of the digital transformation of agribusiness. 7. The proposed
    system The proposed learning model for irrigation is implemented in a prototype
    IoT system that has four components: (i) Edge node layer — This layer consists
    of sensors, actuator, and two microcontrollers. In this layer, edge node acquires
    the sensor data from the surroundings and controls the actuator for actuating
    water pumps to start irrigation. (ii) Edge server layer — This layer consists
    of Raspberry Pi that act as edge server and capable of multitask processing. Here,
    edge server controls the edge nodes for sending signal and receiving data at regular
    interval of time. It is also connected to the cloud server for receiving developed
    and trained machine learning model to be deployed and make irrigation decision
    for controlling edge nodes. (iii) Edge service layer — This layer is deployed
    in the edge server and it is responsible for controlling the whole system through
    a developed web dashboard. The dashboard has live feed data, control of edge nodes,
    and cloud services access. This service layer also has the control access of the
    proposed machine learning model. (iv) Cloud server layer — This layer composed
    of cloud services and cloud storage where its role is to train the machine learning
    model and store the data in database. It sends the trained proposed model to the
    edge server for decision-making regarding irrigation scheduling. The comprehensive
    interconnections in the system are shown in Fig. 2. Download : Download high-res
    image (339KB) Download : Download full-size image Fig. 2. Proposed smart irrigation
    system. The proposed IoT-based smart irrigation system includes five major components:
    field deployed module, Web-based interface, Web API weather input, soil moisture
    prediction mechanism, and edge communication model. 7.1. Web-based interface The
    proposed framework consists of a web-based application to allow farmers visualize
    the growing data and interacting with the garden in real time. In addition, users
    can also be able to examine and analyze the historical growing data, if needed,
    through functionalities such as irrigation control, motor control prediction model
    deployment, and manual data entry implemented in this web application. Here, Node.js
    was chosen for developing the web application [13], [14], while Huang [15] was
    utilized as the database system. Data stored in the database, which is deployed
    in the cloud, will be used for further data analysis in the future. The web application''s
    functions are designed as a software design pattern called model-view-controller
    (MVC). In the frontend, ChartJS is used to represent data through dynamic charts.
    The web application is also used as an interface to manage all the physical devices/actuators
    in the garden. To deploy the web-server to the cloud, a cloud platform as a service
    (PaaS), namely, Heroku, had been utilized. Heroku is a cloud platform that provides
    platform as a service (PaaS), facilitates the creation of applications and deploying
    these online rapidly [16], [17]. It also enhances scalability and functionality
    by integrating several add-on services. The field data are sent to the server
    by Raspberry Pi using this web service. This web service manages the network outage/fluctuation
    during data synchronization from the field device to the server by taking the
    help of flag settings at the database level. The interface facilitates the scheduling
    of irrigation along with visualizing real time sensors and predicted soil moisture
    for upcoming days and precipitation information. By using the denoted threshold
    value of soil moisture suggested by agronomists, the irrigation can be scheduled
    by the user. The system maintains the threshold value depending on the predicted
    pattern of soil moisture and precipitation information. The process of irrigation
    is initiated automatically and stopped after the specified threshold value generated
    from the proposed algorithm of soil moisture when it is reached. 7.2. Edge communication
    model The communication protocols in the proposed framework are flexible and transparent
    in nature for accepting both wired and wireless methodologies. For the maximum
    utilization of potentiality in edge computing components, the communication among
    various components in the edge-IoT system requires intense probing by using the
    versatility among the devices in network edges. For transferring the data gathered
    from pivot sensors, a communication technology such as Zigbee [18] is needed for
    the irrigation systems. Therefore, the communication component in the proposed
    work is classified into three main areas as shown in Fig. 3. Download : Download
    high-res image (451KB) Download : Download full-size image Fig. 3. Edge communication
    model. The Message Query Telemetry Transport (MQTT) protocol is used for the communication
    in the proposed system. The analysis in ref. [19] presented seven IoT messaging
    protocols (MQTT, CoAP, XMPP, AMQP, DDS, REST-HTTP, and WebSocket) as communication
    protocols that play a major role in smart farming. The authors have concluded
    that MQTT proved to be the most secure protocol after probing all the protocols
    with respect to latency, energy and bandwidth requirements, throughput, reliability,
    and security. Moreover, MQTT is secure in both end-to-end architecture and gateway
    server architecture. In an MQTT setup, a MQTT server termed as MQTT broker executes
    on the IoT solution [20]. Under a common identifier, a “publisher” and a “subscriber”
    link among themselves to this broker. In the IoT solution, publishers and subscribers
    are the IoT devices and IoT hubs or control devices, respectively. When the publishers
    have new data for recording, the data are published to the broker. The broker
    then flags that it has new publisher data, and the corresponding data are read
    by the subscriber. Then, the subscriber analyzes the data and reacts accordingly.
    The first level accomplishes with connecting the end users to system with the
    help of mobile or web-based applications through the Internet. The next level
    (cloud computing server) deals with the connection of web server and MQTT broker
    for directing the user requests and other components at the edge landscape or
    from the farms to the right cloud-based services like displaying the real time
    status of the farm for the users, triggering a new deployment of the updated ML
    model to the corresponding edge node. The third level (farming area) is directed
    toward the deployment of sensors and IoT devices (actuators) for communicating
    with other components in the entire system. 7.3. Deployment of soil moisture prediction
    hybrid algorithm The watering mechanism of the plant has different approaches
    in the proposed model. Primarily, the system is trained with manual irrigations
    datasets during the process of learning with respect to suggestions defined by
    agronomists. The model is trained to learn the needs of irrigation in the first
    level of deployment in cloud without the inclusion of pre-processed data. After
    acquiring the required data and training, the proposed system is initiated to
    grasp the plant''s watering needs by undergoing plenty of manual irrigations.
    Thereafter, manual irrigation is not required and the system makes automated decisions
    in watering using the gathered data and the application of ML methods. The proposed
    model then decides the irrigation strategies automatically using ML methods without
    the need including collected datasets in the automatic irrigation process. The
    proposed model can be improved through the learning process when the number of
    precise irrigation inputs is provided to the model at each stage of training.
    The decision-making procedure is developed with two modules for irrigation strategies
    according to the soil moisture prediction for upcoming days. The first module
    deals with training the model in cloud with manual irrigation datasets through
    steps such as data collection, data preprocessing, training, and model development.
    The system acquires values of air temperature (TH), soil temperature (SMT), soil
    moisture (SM), humidity (HU), and ultraviolet rays (UV) periodically from the
    physical environment in the data collection stage, which is essentially required
    for arriving at the watering decisions. Also, the time of performing the manual
    irrigation is recorded in the database. These data are timestamped and stored
    in as datasets to aid in making decisions for knowing the time of irrigation.
    In the next step of pre-processing, inconsistencies are eliminated and outliers
    caused by sensor errors are detected from the irrigation dataset, thereby helping
    in the removal of broken data. The training stage involves the application of
    supervised machine learning (ML) algorithms. Here the regression algorithms such
    as support vector regression (SVR), multiple linear regression (MLR), lasso regression
    (LR), decision tree regressor (DTR), random forest regressor (RF), and XG-boost
    regressor (XB) techniques are used for the deployment. The regression algorithms
    are trained using the collected datasets. Finally, through training, regression
    models are created, namely, SVR model, MLR model, LR model, DTR model, RF model,
    and XB model that are been combined with the second module for decision-making.
    The second module caters to the prediction of irrigation for upcoming days by
    infusing the weather data as an input to the regression trained models. The live
    datasets from the weather API for future prediction of soil moisture variable
    are used. The dependent variables from weather forecast data like temperature
    (TH), humidity (HU), ultraviolet (UV), and precipitation (PC) are tested in the
    aforementioned model for soil moisture prediction. Then, the regression trained
    model is evaluated and deployed using the weather testing data for the prediction
    of soil moisture in accordance with the precipitation. After the prediction of
    data for the upcoming days, these developed regression models are combined with
    unsupervised ML algorithm named k-means clustering for estimating the changes
    incurred in soil moisture prediction due to the impact of weather conditions.
    Further, each regression models with k-means algorithm are evaluated for performances
    in terms of irrigation decision-making process as shown in Table 1. The combined
    algorithms are estimated through MAPE, MSE, R2, execution speed, power consumption,
    and accuracy. The estimation and computation of these parameters are detailed
    by the authors in ref. [21]. Table 1. Comparison of performance metrics obtained
    from various ML algorithms. Algorithms used Accuracy R2 MSE MAPE (%) Execution
    time Power (J) SVR + k-means 0.96 0.96 0.25 1.98 0.06078 1164.85 MLR + k-means
    0.94 0.88 0.31 2.15 0.02075 429.30 LR + k-means 0.95 0.94 0.32 2.23 0.02482 351.35
    DTR + k-means 0.93 0.95 0.29 1.62 0.15687 914.70 RF + k-means 0.95 0.91 0.27 1.57
    0.16745 1475.13 XB + k-means 0.97 0.98 0.20 1.08 0.03547 537.87 XGBoost + k-means
    (XB + k-means) approach provides more accuracy with less MSE comparatively and
    also the R2 with 98% in soil moisture prediction using combined approach is given
    in Table 1. It is evident that the proposed combination performs better when compared
    to other regression + k-means-based approaches. XB + k-means-based hybrid machine
    learning algorithm is applied in irrigation planning module on account of aforementioned
    performance metrices of ML. Although it performs moderately in terms of execution
    time and power usage, it is selected for the deployment in edge computing as it
    has better performed in terms of accuracy, R2, MSE, and MAPE metrices. It is observed
    that the prediction of soil moisture for the upcoming days from the proposed algorithm
    (XB + k-means) is nearer to the actual value as shown in Table 2, and hence, XB
    + k-means is selected for the implementation of SMPHA in edge-based irrigation
    scheduling. Table 2. Comparison of predicted SM value with actual SM value. Date
    Average SM value from sensor Average predicted SM value (XB + k-means) 28-09-2022
    35.23 34.04 29-09-2022 36.41 37.20 30-09-2022 31.57 30.46 01-10-2022 34.66 33.15
    02-10-2022 36.73 37.12 03-10-2022 32.88 33.01 7.4. Edge layer setup The edge node
    acts as a computing center where incoming data are analyzed and fed as the input
    vector to the ML model for processing and to return the control signals for activating
    or deactivating the actuators placed at the farm. Edge node processes the physical
    data (real time) at every end device such as the collected and processed data
    via the Raspberry Pi nodes presented in the proposed scheme. The prediction model
    is designed using TensorFlow API and trained, tested on Google Colab in this work.
    Amazon Web Service (AWS) offers a library named Boto3 having many APIs to upload
    and download objects. After the development of model, it is transferred to Amazon
    S3, a service provided by AWS. The edge node utilizes the trained model from S3
    for analyzing the sensed data acquired from garden''s sensors. The decision is
    delivered based on real time data analysis at the edge node and transmitted to
    Arduino nodes in the fields landscape immediately for controlling the actuators.
    In another flow, the data collected from sensors are filtered so as to keep only
    the modified data at the edge node before being sent back for mitigating the communication
    cost to the database in the cloud. These data are used in the updation of the
    ML model to enhance its efficiency. 7.5. Analytics setup The main goal of this
    experiment lies in gathering the various physical parameters of a farming land
    via sensors and utilizing the fetched data along with weather forecast information
    for developing an algorithm using hybrid machine learning approach to infuse higher
    accuracy in predicting the soil moisture for the upcoming days. As discussed in
    Section 4, for the proper planning and provisioning of optimal irrigation, the
    algorithm provides a predictable estimate of soil moisture with the assistance
    of various statistical measures as shown in Table 1. The measures are adopted
    for estimating the appropriateness and error rate of the proposed algorithm. It
    is inferred from the experiment that, optimal irrigation is feasible using a good
    estimation (close to the actual value) of the soil moisture (Table 2), with the
    support of field data and forecast information, thereby utilizing the natural
    rain efficiently. 7.6. Work flow The flowchart in Fig. 4 depicts the working of
    the proposed system based on the decision support system that is beneficial for
    irrigation needed for the growth of vegetables. The chili plant is grown in a
    growbag attached with sensors and Pi and monitored for 95 days of data collection.
    To bring out optimality in the irrigation system, features relating to climate,
    soil, crop, and field infrastructure are to be considered. To provide several
    recommendations in the production of vegetables, decision support systems (DSSs)
    are designed, which process voluminous information [22]. This proposed work is
    the extension of soil moisture differences (SMD) model [23] developed for soil
    moisture prediction. The threshold values of soil moisture are used in the SMD
    model where the system schedules the irrigation date based on the predicted soil
    moisture and weather forecast (precipitation) information automatically using
    SVR+ k-means modeling. Therefore, in the extension of the aforementioned work,
    further more number of sensors are used to log soil moisture value, which is averaged
    in the proposed model. This model is developed in two divisions of flowchart as
    shown in Fig. 7, where both are interconnected. It is observed that the prediction
    of XB + k-mean approach provides better results as presented in Table 2 and Fig.
    5. Download : Download high-res image (441KB) Download : Download full-size image
    Fig. 4. Flow chart of the proposed edge model. Download : Download high-res image
    (500KB) Download : Download full-size image Fig 7. Average throughput value with
    10 h test scenarios. Download : Download high-res image (393KB) Download : Download
    full-size image Fig. 5. Average response time. The first phase of the flowchart
    describes the hybrid algorithm for the soil moisture prediction (SMPHA) using
    the combination of XB + k-means algorithm. During the data collection step, the
    sensor data for the parameters, namely, TM, HU, ST, UV, and SM, are collected.
    During preprocessing, null values and outliers are removed and the preprocessed
    data are used to train the XG-Boost model. The developed model is then trained
    with variables of live weather features (TM, HU, UV, PC) obtained from Weather
    API for the prediction of SM data. These data are given as input to k-means clustering
    algorithm to predict the soil moisture, which is defined as SMPHA value to be
    infused in the next phase of the flowchart. The second phase of the flowchart
    defines the automatic irrigation planning setup. The setup starts obtaining the
    soil moisture maximum (SMMax) and soil moisture minimum (SMMin) values in the
    dashboard for setting the maximum and minimum level of soil moisture. Then, the
    current soil moisture (CuSM) is sensed and compared against the threshold SMMin.
    If the resulting value is less than SMMin, the process proceeds with SMPHA. On
    the contrary, it stops the irrigation process by sending 0 to the relay. In SMPHA,
    the nearest precipitation date is selected and it is assigned to the predicted
    soil moisture (PSM). The SMMax is decided by finding the minimum of (PSM + SMMin,
    SMMax), and the predicted SMMax is further checked against CuSM with a condition
    if SMMax is greater the CuSM then it sends 1 to the relay as a signal to start
    irrigation. If the condition fails, then it sends 0 to stop irrigation. The process
    of automatic irrigation ends by forecasting the irrigation schedule in accordance
    with the live weather parameters. 7.6.1. Evaluation A hybrid machine learning
    methodology is used in evaluating the first stage of the proposed model. The predicted
    value of the soil moisture is better in terms of their accuracy and error rate.
    From the comparison of the other ML algorithms as shown in Table 2, XB + k-means
    performs better and taken further to be deployed in edge and cloud to check its
    efficiency with each other. Therefore, for analyzing the efficiency of the edge
    server in accordance with the proposed hybrid algorithm SMPHA is evaluated in
    terms of the time taken to train the ML model in edge and cloud. In this experiment
    Raspberry Pi is used to train the SMPHA model with 196,400 rows, that is, input
    data sample size and takes around 1,710,000 ms (approximately 28.5 min). The same
    model when it is trained in Google Colab cloud environment, it takes 204,000 ms
    (approximately 3.4 min) as depicted in Table 3. The main purpose is to run the
    trained model on edge not to train the model at edge. So due to the lack of computing
    capability at the edge, it takes more time to train the model, but it can be ignored
    as it does not affect the purpose of the proposed model. Here, edge is introduced
    to obtain the task of computing from the cloud (i.e., offloading the task) by
    making the system more edge-oriented deployment. It can be accomplished rapidly
    as it requires only 14 s to download a trained SMPHA model from the cloud to the
    edge node with a size of 3101 kb as given in Table 3. The time to download varies
    according to the size of the trained model. So, from this process it can be inferred
    that downloading the trained model saves time when compared to training the model
    at the edge. Through this in real time, deployment of the trained SMPHA model
    in edge is better compared to deployment in cloud services. Furthermore, network
    parameters like latency, throughput, bandwidth, and response time are adopted
    to measure the performance improvements in edge computing. Table 3. Comparison
    of model training time. Empty Cell Edge Cloud Model training time 28.4 min 3.4
    min Downloading time Not applicable 14 s The performance metrices taken into account
    are latency, bandwidth, and response time [24]. The latency of an application
    is the product of two factors: computing latency and transmission latency. The
    time spent on data processing and transmission between end devices to cloud servers
    is termed as computing latency and transmission latency, respectively. The computational
    capacity of the system decides the computing latency as the network servers possess
    a considerable amount of capacity to make the data processing faster, whereas
    the sensors come with limited computing capacity. The latency in transmission
    is increased by the end devices and cloud servers. Bandwidth: As large number
    of sensors are deployed in IoT, data generated would be huge that consumes an
    intense range of bandwidth and leads to several problems such as delay in transmission
    and loss of packets. It becomes unacceptable for the data to be transferred directly
    to cloud servers without applying compression. Therefore, data pre-processing
    and aggregation are needed for IoT gateways before redirecting them to remote
    cloud servers. Then, the issue to be confronted is to control the traffic flow
    by migrating data processing and aggregation tasks optimally to decrease the bandwidth
    needs of the end users while maintaining the data quality. Response time: The
    total response time is calculated by adding up transmission and processing time.
    The local deployment of the proposed model for controlling IoT-based irrigation
    are deployed on two modes: (i) Cloud mode: The developed SMPHA model is implemented
    in the cloud communicating with IoT sensors nodes directly to manage the irrigation
    process. The data are stored and processed at the cloud server itself where it
    uses Heroku platform. (ii) Edge mode – Raspberry Pi is deployed as an edge server
    that involves in processing of the SMPHA model controlling the IoT sensor nodes.
    Here, the data are stored and processed locally within the edge servers. This
    SMPHA model from both the edge and cloud does the job of controlling the actuators
    to initiate and quit the working of water flow motors. Through this deployment
    in both the environments, performance of edge server and cloud server can be checked
    in terms of latency, throughput, bandwidth, and response time is shown in aforementioned
    graphs in Fig. 6, Fig 7, Fig. 8. This performance metrics is not feasible to calculate
    while deploying in real time, so the aforementioned scenarios of two modes are
    virtually created by generating many request and response threads between the
    servers. This sampling, load test, and distributed testing are conducted through
    JMeter application and also verified with Wireshark in cloud servers. The test
    scenario is created here by data of sending and receiving sampling data between
    cloud to IoT sensors and between Edge to IoT sensors. The sampling data considered
    in this work refer to the approximate number of requests generated by Arduino
    to cloud and Arduino to Raspberry Pi that are calculated in real time. The test
    scenario is divided into 10 days of sampling data collected for each day. The
    evaluation results are depicted for latency and response times in 10 days perspective.
    In latency parameter, edge service has decreased by an average of 77.85% time
    compared to the with cloud. In the same manner, the response time of edge service
    is also decreased by 74.09% time compared to cloud service. In throughput calculation,
    sampling data are calculated for an hourly basis for the 10 h data in a day. From
    the hourly comparisons of throughput value, edge outperforms with 67.17% high
    Mbps usage. Through this analysis as shown in Table 4, it is evident that the
    proposed edge computing methodology deployed in Raspberry Pi or in local computers
    outperforms the cloud-oriented approach. Download : Download high-res image (368KB)
    Download : Download full-size image Fig. 6. Average latency with 10 test scenarios.
    Download : Download high-res image (390KB) Download : Download full-size image
    Fig. 8. CPU and memory utilization with and without SMPHA. Table 4. Performance
    metrics for cloud and edge services. Performance metrics Cloud service Edge service
    Throughput (Mbps) 0.04944 0.08265 Latency (ms) 1415.8 313.6 Response time (ms)
    1519.6 393.8 Bandwidth (bps) 86 1365 Finally, to illustrate the efficiency of
    resource management in edge computing, CPU and memory utilization are considered
    for the analysis as both factors rely on the service execution model and the computational
    needs of the services being fired from off-loaders. Fig. 8 depicts the utilization
    of CPU and RAM on the Raspberry Pi acting as an edge node in two cases: with and
    without the deployment of SMPHA model on it. As shown in Fig. 8, the SMPHA model
    affects the CPU of the Raspberry Pi node significantly as it consumed around 41.2%
    of the CPU compared to only 3.5% when it does not host the SMPHA model. However,
    the memory (RAM) utilization in both the cases (with and without deployment of
    an SMPHA model) is nearly the same which is around 31%. Comparatively RAM utilization
    does not have much difference in with and without SMPHA. It is worthwhile to note
    that, the CPU utilization is still much lower than the 50% of total CPU capacity
    in Raspberry Pi. Therefore, it becomes feasible for adopting edge server implementation
    in the proposed irrigation system. 7.7. Conclusion This article proposed a novel
    approach to edge-based irrigation system to facilitate decision-making on watering
    the plants on scheduled time. The proposed approach applying IoT with an edge
    computing framework enables the farming system to adapt to the changes in environmental
    conditions automatically and efficiently. The process of automatic irrigation
    regulates irrigation according to the live weather parameters for forecasting
    the irrigation process. Soil moisture prediction was performed using major regression
    algorithms that are again combined with k-means clustering for estimating the
    changes incurred in soil moisture prediction. These techniques were compared through
    metrics such as MAPE, MSE, speed, and power consumption from which XB + k-means
    was found to perform better. The XB + k-means algorithm was further used for the
    implementation of decision mechanism on the developed edge computing model. The
    proposed edge model saves the data communication cost and reduces the response
    time of IoT services. It can be deployed on existing devices on the network edges
    serving as edge nodes, thereby reducing the overall implementation cost of a large-scale
    IoT system. The edge-based approach was found to perform better than the cloud-based
    approach in terms of response time, latency, throughput, and bandwidth usage.
    Finally, the edge model was analyzed through CPU and memory usage while running
    with and without the algorithm. In both cases, the memory utilization is almost
    lower to total available resource of the edge device. From this, edge device can
    allocate its remaining resource for other computing services, which increases
    the efficiency of edge computing device. The number of end edge nodes can be increased
    according to the field area and then to check the potency of the system. References
    [1] S.K. Routray, A. Javali, L. Sharma, A.D. Ghosh, A. Sahoo Internet of things
    based precision agriculture for developing countries Proceedings of the 2019 International
    Conference on Smart Systems and Inventive Technology (ICSSIT), Tirunelveli, India,
    27–29 November 2019 (2019), pp. 1064-1068 CrossRefView in ScopusGoogle Scholar
    [2] K. Perakis, F. Lampathaki, K. Nikas, Y. Georgiou, O. Marko, J. Maselyne CYBELE–Fostering
    Precision Agriculture & Livestock Farming through Secure Access to large-scale
    HPC enabled virtual industrial experimentation environments fostering scalable
    big data analytics Comput. Netw., 168 (2020), Article 107035 View PDFView articleView
    in ScopusGoogle Scholar [3] J. Poveda Insect frass in the development of sustainable
    agriculture. A review Agron. Sustain. Dev., 41 (2021), pp. 1-10 CrossRefGoogle
    Scholar [4] P.C. Nagajyoti, K.D. Lee, T.V.M. Sreekanth Heavy metals, occurrence
    and toxicity for plants: a review Environ. Chem. Lett., 8 (2010), pp. 199-216
    CrossRefView in ScopusGoogle Scholar [5] P.K. Rai, S.S. Lee, M. Zhang, Y.F. Tsang,
    K.-H. Kim Heavy metals in food crops: health risks, fate, mechanisms, and management
    Environ. Int., 125 (2019), pp. 365-385 View PDFView articleView in ScopusGoogle
    Scholar [6] L.S. Keith, D.W. Wohlers, D.B. Moffett, Z.A. Rosemond ATSDR evaluation
    of potential for human exposure to tungsten Toxicol. Ind. Health, 23 (2007), pp.
    309-345 CrossRefView in ScopusGoogle Scholar [7] P.K. Rai, K.-H. Kim, S.S. Lee,
    J.-H. Lee Molecular mechanisms in phytoremediation of environmental contaminants
    and prospects of engineered transgenic plants/microbes Sci. Total Environ., 705
    (2020), Article 135858 View PDFView articleView in ScopusGoogle Scholar [8] G.
    Sandeep, K.R. Vijayalatha, T. Anitha Heavy metals and its impact in vegetable
    crops Int. J. Chem. Stud., 7 (2019), pp. 1612-1621 View in ScopusGoogle Scholar
    [9] P.-I.K. Chukwuemeka, N.U. Hephzibah Potential health risk from heavy metals
    via consumption of leafy vegetables in the vicinity of Warri refining and petrochemical
    company, Delta state, Nigeria Ann. Biol. Sci., 6 (2018), pp. 30-37 Google Scholar
    [10] Y. Gao, P. Zhou, L. Mao, Y. Zhi, W. Shi Assessment of effects of heavy metals
    combined pollution on soil enzyme activities and microbial community structure:
    modified ecological dose–response model and PCR-RAPD Environ. Earth Sci., 60 (2010),
    pp. 603-612 CrossRefView in ScopusGoogle Scholar [11] S. Tiwari, C. Lata Heavy
    metal stress, signaling, and tolerance due to plant-associated microbes: An overview
    Front. Plant Sci., 9 (2018), p. 452 View in ScopusGoogle Scholar [12] H. Panchasara,
    N.H. Samrat, N. Islam Greenhouse gas emissions trends and mitigation measures
    in Australian agriculture sector—a review Agri, 11 (2021), p. 85 CrossRefGoogle
    Scholar [13] S.R. Wild, K.C. Jones Organic chemicals entering agricultural soils
    in sewage sludges: screening for their potential to transfer to crop plants and
    livestock Sci. Total Environ., 119 (1992), pp. 85-119 View PDFView articleView
    in ScopusGoogle Scholar [14] P.K. Rai Impacts of particulate matter pollution
    on plants: implications for environmental biomonitoring Ecotoxicol. Environ. Saf.,
    129 (2016), pp. 120-136 View PDFView articleView in ScopusGoogle Scholar [15]
    M. Huang, Y. Zhu, Z. Li, B. Huang, N. Luo, C. Liu, G. Zeng Compost as a soil amendment
    to remediate heavy metal-contaminated agricultural soil: mechanisms, efficacy,
    problems, and strategies Water Air Soil Pollut., 227 (2016), pp. 1-18 Google Scholar
    [16] P.K. Rai Biomagnetic Monitoring through Roadside Plants of an Indo-Burma
    Hot Spot Region Elsevier, London, UK (2016) Google Scholar [17] R. Li, H. Wu,
    J. Ding, W. Fu, L. Gan, Y. Li Mercury pollution in vegetables, grains and soils
    from areas surrounding coal-fired power plants Sci. Rep., 7 (2017), pp. 1-9 Google
    Scholar [18] V. Fernández, T. Eichert Uptake of hydrophilic solutes through plant
    leaves: current state of knowledge and perspectives of foliar fertilization CRC
    Crit. Rev. Plant. Sci., 28 (2009), pp. 36-68 CrossRefView in ScopusGoogle Scholar
    [19] R. Cavicchioli, W.J. Ripple, K.N. Timmis, F. Azam, L.R. Bakken, M. Baylis,
    et al. Scientists'' warning to humanity: microorganisms and climate change Nat.
    Rev. Microbiol., 17 (9) (2019), pp. 569-586, 10.1038/s41579-019-0222-5 View in
    ScopusGoogle Scholar [20] N.T.L. Huong, Y.S. Bo, S. Fahad Economic impact of climate
    change on agriculture using Ricardian approach: a case of Northwest Vietnam J.
    Saudi Soc. Agric. Sci., 18 (4) (2019), pp. 449-457, 10.1016/j.jssas.2018.02.006
    View PDFView articleView in ScopusGoogle Scholar [21] R.K. Fagodiya, H. Pathak,
    A. Bhatia, N. Jain, A. Kumar, S.K. Malyan Global warming impacts of nitrogen use
    in agriculture: An assessment for India since 1960 Carbon Manag., 11 (3) (2020),
    pp. 291-301, 10.1080/17583004.2020.1752061 View in ScopusGoogle Scholar [22] S.
    Sarkar, S. Chatterjee, S. Misra Assessment of the suitability of fog computing
    in the context of internet of things IEEE Trans. Cloud Comput., 6 (1) (2018),
    pp. 46-59, 10.1109/TCC.2015.2485206 View in ScopusGoogle Scholar [23] K. Saravanan,
    G. Julie, H. Robinson Handbook of Research on Implementation and Deployment of
    IoT Projects in Smart Cities IGI Global, Hershey (2019), 10.4018/978-1-5225-9199-3
    Google Scholar [24] A. Baylis Advances in precision farming technologies for crop
    protection Outlooks Pest. Manag., 28 (4) (2017), pp. 158-161, 10.1564/v28_aug_04
    View in ScopusGoogle Scholar Further reading [25] C.F. Nicholson, E.C. Stephens,
    B. Kopainsky, P.K. Thornton, A.D. Jones, D. Parsons, J. Garrett Food security
    outcomes in agricultural systems models: case examples and priority information
    needs Agr. Syst., 188 (2021), Article 103030 View PDFView articleView in ScopusGoogle
    Scholar [26] C. Lopes, M. Herva, A. Franco-Uría, E. Roca Inventory of heavy metal
    content in organic waste applied as fertilizer in agriculture: evaluating the
    risk of transfer into the food chain Environ. Sci. Pollut. Res., 18 (2011), pp.
    918-939 CrossRefView in ScopusGoogle Scholar [27] M. Arora, B. Kiran, S. Rani,
    A. Rani, B. Kaur, N. Mittal Heavy metal accumulation in vegetables irrigated with
    water from different sources Food Chem., 111 (2008), pp. 811-815 View PDFView
    articleView in ScopusGoogle Scholar [28] A.K. Meena, G.K. Mishra, P.K. Rai, C.
    Rajagopal, P.N. Nagar Removal of heavy metal ions from aqueous solutions using
    carbon aerogel as an adsorbent J. Hazard. Mater., 122 (2005), pp. 161-170 View
    PDFView articleView in ScopusGoogle Scholar [29] P.K. Rai Heavy metal phytoremediation
    from aquatic ecosystems with special reference to macrophytes Crit. Rev. Environ.
    Sci. Technol., 39 (2009), pp. 697-753 CrossRefView in ScopusGoogle Scholar [30]
    J.E. Gall, R.S. Boyd, N. Rajakaruna Transfer of heavy metals through terrestrial
    food webs: a review Environ. Monit. Assess., 187 (2015), pp. 1-21 Google Scholar
    [31] Z.J. Shen, Y.S. Chen, Z. Zhang Heavy metals translocation and accumulation
    from the rhizosphere soils to the edible parts of the medicinal plant Fengdan
    (Paeonia ostii) grown on a metal mining area, China Ecotoxicol. Environ. Saf.,
    143 (2017), pp. 19-27 View PDFView articleView in ScopusGoogle Scholar [32] O.
    El Hamiani, H. El Khalil, C. Sirguey, A. Ouhammou, G. Bitton, C. Schwartz, A.
    Boularbah Metal concentrations in plants from mining areas in South Morocco: health
    risks assessment of consumption of edible and aromatic plants CLEAN Soil Air Water,
    43 (2015), pp. 399-407 CrossRefView in ScopusGoogle Scholar [33] S. Bolan, A.
    Kunhikrishnan, B. Seshadri, G. Choppala, R. Naidu, N.S. Bolan, Y.S. Ok, M. Zhang,
    C.G. Li, F. Li Sources, distribution, bioavailability, toxicity, and risk assessment
    of heavy metal (loid) s in complementary medicines Environ. Int., 108 (2017),
    pp. 103-118 View PDFView articleView in ScopusGoogle Scholar [34] S.W. Kim, Y.E.
    Chae, J.M. Moon, D.K. Kim, R.X. Cui, G. An, S.W. Jeong, Y.J. An In situ evaluation
    of crop productivity and bioaccumulation of heavy metals in Paddy soils after
    remediation of metal-contaminated soils J. Agric. Food Chem., 65 (2017), pp. 1239-1246
    CrossRefView in ScopusGoogle Scholar [35] S. Kohzadi, B. Shahmoradi, E. Ghaderi,
    H. Loqmani, A. Maleki Concentration, source, and potential human health risk of
    heavy metals in the commonly consumed medicinal plants Biol. Trace Elem. Res.,
    187 (2019), pp. 41-50 CrossRefView in ScopusGoogle Scholar [36] F. Li, W. Shi,
    Z. Jin, H. Wu, G.D. Sheng Excessive uptake of heavy metals by greenhouse vegetables
    J. Geochem. Explor., 173 (2017), pp. 76-84 View PDFView articleGoogle Scholar
    [37] L. Yu, G. Xin, W. Gang, Q. Zhang, S. Qiong, X. Guoju Heavy metal contamination
    and source in arid agricultural soil in Central Gansu Province, China J. Environ.
    Sci., 20 (2008), pp. 607-612 View in ScopusGoogle Scholar [38] A.K. Chopra, C.
    Pathak, G. Prasad Scenario of heavy metal contamination in agricultural soil and
    its management J. Appl. Nat. Sci., 1 (2009), pp. 99-108 CrossRefGoogle Scholar
    [39] W. Feng, Z. Guo, X. Xiao, C. Peng, L. Shi, H. Ran, W. Xu A dynamic model
    to evaluate the critical loads of heavy metals in agricultural soil Ecotoxicol.
    Environ. Saf., 197 (2020), Article 110607 View PDFView articleView in ScopusGoogle
    Scholar [40] J. Wu, J. Li, Y. Teng, H. Chen, Y. Wang A partition computing-based
    positive matrix factorization (PC-PMF) approach for the source apportionment of
    agricultural soil heavy metal contents and associated health risks J. Hazard.
    Mater., 388 (2020), Article 121766 View PDFView articleView in ScopusGoogle Scholar
    [41] M. Shahid, C. Dumat, S. Khalid, E. Schreck, T. Xiong, N.K. Niazi Foliar heavy
    metal uptake, toxicity and detoxification in plants: a comparison of foliar and
    root metal uptake J. Hazard. Mater., 325 (2017), pp. 36-58 View PDFView articleView
    in ScopusGoogle Scholar [42] R. Lal Adaptation and mitigation of climate change
    by improving agriculture in India S. SherazMahdi (Ed.), Climate Change and Agriculture
    in India: Impact and Adaptation, Springer International Publishing, Cham (2019),
    pp. 217-227, 10.1007/978-3-319-90086-5_17 Google Scholar [43] D. Mulla, R. Khosla
    Historical Evolution and Recent Advances in Precision Farming. Soil-Specific Farming
    Precision Agriculture CRC Press, Boca Raton (2015), 10.1201/b18759-2 Google Scholar
    [44] L. Dutta, T.K. Basu Extraction and optimization of leaves images of mango
    tree and classification using ANN IJRAET, 1 (3) (2013), pp. 46-51 Google Scholar
    [45] T. Kawai, H. Mineno Evaluation environment using edge computing for artificial
    intelligence-based irrigation system 2020 16th International Conference on Mobility,
    Sensing and Networking (MSN), IEEE, Tokyo, Japan (2020), pp. 214-219, 10.1109/MSN50589.2020.00046
    View in ScopusGoogle Scholar [46] M.S. Munir, I.S. Bajwa, A. Ashraf, W. Anwar,
    R. Rashid Intelligent and smart irrigation system using edge computing and IoT
    Complexity., 2021 (2021), pp. 1-16, 10.1155/2021/6691571 Google Scholar [47] C.M.
    Angelopoulos, G. Filios, S. Nikoletseas, T.P. Raptis Keeping data at the edge
    of smart irrigation networks: a case study in strawberry greenhouses Comput. Netw.,
    167 (2020), Article 107039, 10.1016/j.comnet.2019.107039 View PDFView articleView
    in ScopusGoogle Scholar [48] M. Satyanarayanan The emergence of edge computing
    Computer., 50 (1) (2017), pp. 30-39, 10.1109/MC.2017.9 View in ScopusGoogle Scholar
    [49] W. Shi, S. Dustdar The promise of edge computing Computer., 49 (5) (2016),
    pp. 78-81, 10.1109/MC.2016.145 View in ScopusGoogle Scholar [50] P.L. Ramirez
    Izolan, F. Diniz Rossi, R. Hohemberger, M.P. Konzen, R.G. da Cunha, L.R. Saquette,
    et al. Low-cost fog computing platform for soil moisture management 2020 International
    Conference on Information Networking (ICOIN), IEEE, Barcelona, Spain (2020), pp.
    499-504, 10.1109/ICOIN48656.2020.9016572 View in ScopusGoogle Scholar [51] F.
    Ferrandez-Pastor, J. Garcia-Chamizo, M. Nieto-Hidalgo, J. Mora-Pascual, J. Mora-Martínez
    Developing ubiquitous sensor network platform using internet of things: application
    in precision agriculture Sensors., 16 (7) (2016), p. 1141, 10.3390/s16071141 View
    in ScopusGoogle Scholar [52] X. Xu, X. Liu, Z. Xu, F. Dai, X. Zhang, L. Qi Trust-oriented
    IoT service placement for smart cities in edge computing IEEE Internet Things
    J., 7 (5) (2020), pp. 4084-4091, 10.1109/JIOT.2019.2959124 View in ScopusGoogle
    Scholar [53] X. Wu, M. Liu In-situ soil moisture sensing: measurement scheduling
    and estimation using compressive sensing 2012 ACM/IEEE 11th International Conference
    on Information Processing in Sensor Networks (IPSN), IEEE, Beijing, China (2012),
    pp. 1-11, 10.1145/2185677.2185679 Google Scholar [54] T. Kameoka, K. Nishioka,
    Y. Motonaga, Y. Kimura, A. Hashimoto Watanabe N. smart sensing in a vineyard for
    advanced viticultural management Proceedings of the 2014 International Workshop
    on Web Intelligence and Smart Sensing, Saint Etienne France (2014), pp. 1-4, 10.1145/2637064.2637091
    Google Scholar [55] K. Cagri Serdaroglu, C. Onel, S. Baydere IoT-based smart plant
    irrigation system with enhanced learning 2020 IEEE Computing, Communications and
    IoT Applications (ComComAp.), IEEE, Beijing, China (2020), pp. 1-6, 10.1109/ComComAp51192.2020.9398892
    Google Scholar [56] J. Kwok, Y. Sun A smart IoT-based irrigation system with automated
    plant recognition using deep learning Proceedings of the 10th International Conference
    on Computer Modeling and Simulation - ICCMS2018, ACM Press, Sydney, Australia
    (2018), pp. 87-91, 10.1145/3177457.3177506 View in ScopusGoogle Scholar [57] A.
    Goldstein, L. Fink, A. Meitin, S. Bohadana, O. Lutenberg, G. Ravid Applying machine
    learning on sensor data for irrigation recommendations: revealing the agronomist''s
    tacit knowledge Precision Agricult., 19 (3) (2018), pp. 421-444, 10.1007/s11119-017-9527-4
    View in ScopusGoogle Scholar [58] A. Vij, S. Vijendra, A. Jain, S. Bajaj, A. Bassi,
    A. Sharma IoT and machine learning approaches for automation of farm irrigation
    system Proc. Comput. Sci., 167 (2020), pp. 1250-1257, 10.1016/j.procs.2020.03.440
    View PDFView articleView in ScopusGoogle Scholar [59] H. Krishnan, R. Scholar
    MongoDB – a comparison with NoSQL databases Int. J. Sci. Eng. Res., 7 (5) (2016),
    pp. 1035-1037 Google Scholar [60] T. Ojha, S. Misra, N.S. Raghuwanshi Wireless
    sensor networks for agriculture: the state-of-the-art in practice and future challenges
    Comput Electr Agricult., 118 (2015), pp. 66-84, 10.1016/j.compag.2015.08.011 View
    PDFView articleView in ScopusGoogle Scholar [61] J. Gutierrez, J.F. Villa-Medina,
    A. Nieto-Garibay, M.A. Porta-Gandara Automated irrigation system using a wireless
    sensor network and GPRS module IEEE Trans. Instrum. Meas., 63 (1) (2014), pp.
    166-176, 10.1109/TIM.2013.2276487 View in ScopusGoogle Scholar [62] S. Chanthakit,
    P. Keeratiwintakorn, C. Rattanapoka An IoT system design with real time stream
    processing and data flow integration In: 2019 Research, Invention, and Innovation
    Congress (RI2C.), IEEE, Bangkok, Thailand (2019), pp. 1-5, 10.1109/RI2C48728.2019.8999968
    Google Scholar [63] H. Lv, S. Wang Design and Application of IoT Microservices
    Based on Seneca DEStech Transactions on Computer Science and Engineering, (icte.),
    USA (2016), 10.12783/dtcse/icte2016/4814 Google Scholar [64] B.-H. Lee, E.K. Dewi,
    M.F. Wajdi Data security in cloud computing using AES under HEROKU cloud 2018
    27th Wireless and Optical Communication Conference (WOCC), IEEE, Hualien (2018),
    pp. 1-5, 10.1109/WOCC.2018.8372705 View PDFView articleGoogle Scholar [65] M.A.
    Lopez Pena, F.I. Munoz SAT-IoT: An architectural model for a high-performance
    fog/edge/cloud IoT platform 2019 IEEE 5th World Forum on Internet of Things (WF-IoT.),
    IEEE, Limerick, Ireland (2019), pp. 633-638, 10.1109/WF-IoT.2019.8767282 View
    in ScopusGoogle Scholar [66] Weather API. Retrieved from https://openweathermap.org/api.
    Google Scholar [67] D. Gislason Zigbee Wireless Networking (1st ed.), Elsevier
    Publisher, Newnes, London (2008) Google Scholar [68] K. Tanabe, Y. Tanabe, M.
    Hagiya Model-based testing for MQTT applications M. Virvou, H. Nakagawa, L.C.
    Jain (Eds.), Knowledge-Based Software Engineering: 2020, Springer International
    Publishing, Cham (2020), pp. 47-59, 10.1007/978-3-030-53949-8_5 View in ScopusGoogle
    Scholar [69] L. Babun, K. Denney, Z.B. Celik, P. McDaniel, A.S. Uluagac A survey
    on IoT platforms: communication, security, and privacy perspectives Comput. Netw.,
    192 (2021), Article 108040, 10.1016/j.comnet.2021.108040 View PDFView articleView
    in ScopusGoogle Scholar [70] K. Rastogi, D. Lohani Edge computing-based internet
    of things framework for indoor occupancy estimation Int. J. Ambient Comput. Intell.,
    11 (4) (2020), pp. 16-37, 10.4018/978-1-6684-5700-9.ch031 Google Scholar [71]
    S. Premkumar, A.N. Sigappi Functional framework for edge-based agricultural system
    AI, Edge and IoT-Based Smart Agriculture (1st ed.), Academic Press, Elsevier,
    USA (2021), pp. 71-100, 10.1016/B978-0-12-823694-9.00029-3 View in ScopusGoogle
    Scholar [72] J. Phani Kumar, P. Paramaguru, T. Arumugam, N. Manikanda Boopathi,
    K. Venkatesan Genetic divergence among Ramnad mundu chilli (Capsicum annuum L.)
    genotypes for yield and quality Electr. J. Plant Breeding., 12 (1) (2021), pp.
    228-234 Google Scholar [73] A. Goap, D. Sharma, A.K. Shukla, K.C. Rama An IoT-based
    smart irrigation management system using machine learning and open source technologies
    Comput Electronic Agricult., 155 (2018), pp. 41-49, 10.1016/j.compag.2018.09.040
    View PDFView articleView in ScopusGoogle Scholar [74] M.S. Aslanpour, S.S. Gill,
    A.N. Toosi Performance evaluation metrics for cloud, fog and edge computing: a
    review, taxonomy, benchmarks and standards for future research Internet Things.,
    12 (2020), Article 100273, 10.1016/j.iot.2020.100273 View PDFView articleView
    in ScopusGoogle Scholar [75] A. Sunardi Suharjito MVC architecture: a comparative
    study between Laravel framework and slim framework in freelancer project monitoring
    system web based Proc. Comput. Sci., 157 (2019), pp. 134-141, 10.1016/j.procs.2019.08.150
    View PDFView articleView in ScopusGoogle Scholar [76] R. Shimonski The Wireshark
    Field Guide (1st ed.), Syngress Press, Elsevier, New York (2013), 10.1016/B978-0-12-410413-6.00001-2
    Google Scholar Cited by (0) Dr. Preetha Evangeline David is currently working
    as an Associate Professor and Head of the Department in the Department of Artificial
    Intelligence and Machine Learning at Chennai Institute of Technology, Chennai,
    India. She holds a PhD from Anna University, Chennai in the area of Cloud Computing.
    She has published many research papers and Patents focusing on Artificial Intelligence,
    Digital Twin Technology, High Performance Computing, Computational Intelligence
    and Data Structures. She is currently working on Multi-disciplinary areas in collaboration
    with other technologies to solve socially relevant challenges and provide solutions
    to human problems. Dr. P. Anandhakumar is a professor in the Department of Information
    Technology at Anna University, Chennai. He has completed his doctorate in the
    year 2006 from Anna University. He has produced 17 PhD''s in the field of Image
    Processing, Cloud Computing, Multimedia technology and Machine Learning. His ongoing
    research lies in the field of Digital Twin Technology, Machine Learning and Artificial
    Intelligence. He has published more than 150 papers indexed in SCI, SCOPUS, WOS
    etc. Pethuru Raj Chelliah (PhD) works as the chief architect at the Site Reliability
    Engineering Center of Excellence, Reliance Jio Infocomm Ltd. (RJIL), Bangalore.
    Previously, he worked as a cloud infrastructure architect at the IBM Global Cloud
    Center of Excellence, IBM India, Bangalore, for four years. He also had an extended
    stint as a TOGAF-certified enterprise architecture consultant in Wipro Consulting
    services division and as a lead architect in the corporate research division of
    Robert Bosch, Bangalore. He has more than 17 years of IT industry experience.
    Shreyash Naithani is currently a site reliability engineer at Microsoft R&D. Prior
    to Microsoft, he worked with both start-ups and mid-level companies. He completed
    his PG Diploma from the Centre for Development of Advanced Computing, Bengaluru,
    India, and is a computer science graduate from Punjab Technical University, India.
    In a short span of time, he has had the opportunity to work as a DevOps engineer
    with Python/C#, and as a tools developer, site/service reliability engineer, and
    Unix system administrator. During his leisure time, he loves to travel and binge
    watch series. Shailender Singh is a principal site reliability engineer and a
    solution architect with around 11 year''s IT experience who holds two master''s
    degrees in IT and computer application. He has worked as a C developer on the
    Linux platform. He had exposure to almost all infrastructure technologies from
    hybrid to cloud-hosted environments. In the past, he has worked with companies
    including Mckinsey, HP, HCL, Revionics and Avalara and these days he tends to
    use AWS, K8s, Terraform, Packer, Jenkins, Ansible, and OpenShift. View Abstract
    Copyright © 2024 Elsevier Inc. All rights reserved. Part of volume Applying Computational
    Intelligence for Social Good Edited by Preetha Evangeline David, P. Anandhakumar
    Download full volume Recommended articles Article Metrics Captures Readers: 8
    View details About ScienceDirect Remote access Shopping cart Advertise Contact
    and support Terms and conditions Privacy policy Cookies are used by this site.
    Cookie settings | Your Privacy Choices All content on this site: Copyright © 2024
    Elsevier B.V., its licensors, and contributors. All rights are reserved, including
    those for text and data mining, AI training, and similar technologies. For all
    open access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Advances in Computers
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Reshaping agriculture using intelligent edge computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Aljuhani A.
  - Kumar P.
  - Islam A.K.M.N.
  - Kumar R.
  - Jolfaei A.
  citation_count: '6'
  description: The Internet of Things (IoT) technology is considered the foundation
    for next-generation smart villages due to its ability to use sustainable information
    and communication technologies. The smart villages can enable real-time data analytics
    and can automate decision-making for local villagers in terms of agriculture,
    health care, transportation, environment, and energy. However, most of the wireless
    sensing devices exchange information using public networks and therefore may not
    be able to resist all forms of attacks. In addition, most of the IoT devices are
    resource restricted and use cloud servers to process and store data. However,
    when IoT devices communicate with cloud computing data centers, the volume of
    data causes network congestion. To provide efficient and secure services, a new
    network architecture named distributed fog computing (DFC) can be created and
    integrated with the IoT-based smart villages deployment. Motivated from the aforementioned
    discussions, this article explores the integration of DFC with IoT in improving
    security and privacy solutions for consumer electronic devices used by villages.
    As a case study, we also design and evaluate the performance of an intrusion detection
    system in a DFC-based smart village environment. Finally, we discuss several open
    security issues and challenges regarding Fog-to-Things enabled smart villages.
  doi: 10.1109/MCE.2022.3193268
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Consumer Electronics Mag...
    >Volume: 12 Issue: 5 Fog Intelligence for Secure Smart Villages: Architecture
    and Future Challenges Publisher: IEEE Cite This PDF Ahamed Aljuhani; Prabhat Kumar;
    Randhir Kumar; Alireza Jolfaei; A. K. M. Najmul Islam All Authors 9 Cites in Papers
    334 Full Text Views Abstract Authors Figures References Citations Keywords Metrics
    Footnotes Abstract: The Internet of Things (IoT) technology is considered the
    foundation for next-generation smart villages due to its ability to use sustainable
    information and communication technologies. The smart villages can enable real-time
    data analytics and can automate decision-making for local villagers in terms of
    agriculture, health care, transportation, environment, and energy. However, most
    of the wireless sensing devices exchange information using public networks and
    therefore may not be able to resist all forms of attacks. In addition, most of
    the IoT devices are resource restricted and use cloud servers to process and store
    data. However, when IoT devices communicate with cloud computing data centers,
    the volume of data causes network congestion. To provide efficient and secure
    services, a new network architecture named distributed fog computing (DFC) can
    be created and integrated with the IoT-based smart villages deployment. Motivated
    from the aforementioned discussions, this article explores the integration of
    DFC with IoT in improving security and privacy solutions for consumer electronic
    devices used by villages. As a case study, we also design and evaluate the performance
    of an intrusion detection system in a DFC-based smart village environment. Finally,
    we discuss several open security issues and challenges regarding Fog-to-Things
    enabled smart villages. Published in: IEEE Consumer Electronics Magazine ( Volume:
    12, Issue: 5, 01 September 2023) Page(s): 12 - 21 Date of Publication: 22 July
    2022 ISSN Information: DOI: 10.1109/MCE.2022.3193268 Publisher: IEEE The rapid
    evolution of technologies and communications raises the demand for emerging smart
    paradigms, such as the Internet of Things (IoT). The IoT aims to transform “things”
    from conventional to a smart object, enabling multiple connected devices to send,
    process, and receive data across multiple locations with minimal or no human involvement.
    Such technology provides several great features to end users, including cost reduction,
    automation, real-time analysis, improving productivity, and better business opportunities.
    IoT technology has been integrated into the operations of smart systems in a wide
    range of critical sectors, such as energy, transportation systems, industrial,
    communication, and healthcare. As a result, the number of IoT-connected devices
    has been growing exponentially and might reach 27 billion by 2025.[1] Thus, from
    a consumer perspective, IoT should be centered on providing safe and automated
    infrastructure in living and nonliving environments. IoT technology plays a vital
    role in allowing smart villages to provide cost-effective and efficient solutions
    for villagers. As the majority of people in different countries live in rural
    settlements with minimum technology and resources, this offers several opportunities
    for developing IoT applications in different important domains within rural settlements.[2]
    For example, villagers regularly use traditional crop harvesting methods, making
    farm management extremely difficult. A smart village includes the agricultural
    IoT, which can help farmers deal with all of the issues associated with farming,
    such as weather and water management. The use of IoT applications and services
    in such a village will improve the quality of life by providing a resilient, cost-effective,
    and sustainable smart village.[3] Even though IoT-based smart villages improve
    the quality of villagers’ lives, developing rural areas as smart villages with
    limited technological resources, such as computational and communication infrastructure,
    remains critical. To address these issues, fog computing is a new emerging technology
    that enables storage, communication, and network functions in a distributed fashion.[4]
    The main principle of fog computing is to extend the cloud closer to IoT devices,
    acting as an intermediate layer between the IoT end user and the cloud. Cloud
    technology has several limitations, such as latency, volume, limited bandwidth,
    data protection, and Internet connectivity. To provide secure, robust, and safe
    telecommunication infrastructures, fog computing offers a great opportunity to
    improve the quality of life for villagers and IoT-enabled smart village consumer
    electronics (CE) devices by offloading security features to multiple fog nodes,
    and providing real-time cyberattack detection near to the data source (see Figure
    1). However, fog computing is not a replacement for cloud computing but it functions
    as an extension of the cloud. Fog computing is considered to be an implementation
    or evolution of edge computing, which is another network paradigm that enables
    technologies to allow computation performed at the edge of the network, closer
    to the data generation points, i.e., sensors.[5] Fog computing shifts the data
    process into a fog node or IoT gateway, which is located within the local area
    network. This is physically more distant from sensors. In addition, the flexibility
    of placing fog nodes anywhere between devices and the cloud is the most significant
    feature that distinguishes fog computing from several implementations of edge
    computing.[5] Figure 1. Fog computing improved security and privacy services in
    IoT-based smart villages. Show All Although IoT-based smart villages aim to improve
    human life and ameliorate the quality of service in several domains, their security
    issues remain a big challenge.[6] Since the term “smart” and “things” often refers
    to technology, such as the IoT, the deployment of such platform in villages introduces
    several cyber threats worth investigating. A Sybil attack, for example, is one
    type of security threat in which an attacker may exploit vulnerabilities in smart
    village networks. In a Sybil attack, a malicious node falsifies its identity and
    excessively broadcasts incorrect information to legitimate nodes, causing a node''s
    resources to be completely drained.[7] In addition, a scanning attack could pose
    a major risk, as such an attack scans vulnerabilities in smart village devices
    and performs malicious activities. Another well-known cyber threat is the man-in-the-middle
    attack, in which an adversary intercepting the network communication between connected
    smart village devices acts as a legitimate device to eavesdrop and steal sensitive
    information. Following this introduction, this article discusses the integration
    of distributed fog computing (DFC) with IoT-based smart villages to improve security
    and privacy services. In addition, this article discusses security-by-design (SbD)
    for an intrusion detection system (IDS) based on DFC in IoT-enabled smart villages
    and explores the potential uses of other emerging technologies with such an environment.
    We also design and implement an IDS for a DFC-based smart village as a case study.
    Finally, this article discusses several open security issues and recommendations
    regarding Fog-to-Things enabled smart villages. DFC-ENABLED IDS The integration
    of fog computing and IoT has driven Fog-of-Things to overcome the cloud limitations
    and provide several advantages. Fog computing improves the security and privacy
    of IoT-enabled smart villages from many perspectives. One of the distinctive features
    of fog computing is that it provides a distributed computing environment, unlike
    cloud computing, which follows a centralized architecture.[6] Therefore, DFC can
    be utilized to provide distributed security solutions, such as IDS. Moreover,
    in such an environment, IoT devices generate a large amount of heterogeneous data
    that require rapid, efficient, and real-time response. The DFC has the ability
    to improve the computational resource of IDS as a security function by working
    closer to the network edge. This can help by providing a lightweight, efficient,
    and rapid mitigation response against several cybersecurity threats. In addition,
    fog computing enables the deployment of parallel and distributed security solutions.
    For example, IDS can be implemented as distributed security functions at multiple
    fog nodes in the context of Fog-of-Things architecture. Thus, enabling a collaborative
    detection and mitigation approach that can share and exchange data to provide
    an effective and robust mitigation approach against several cyberattacks. The
    IDS can benefit from DFC in providing a low latency that allows rapid response,
    resulting in a decrease in potential damages caused by such attacks. Several approaches
    can be implemented to achieve a collaborative IDS in fog computing; however, Fog-of-Things
    IDS architecture has several advantages because it fully leverages the benefits
    of distributed fog nodes in terms of data processing, storage, latency, and scalability.
    In addition, the recourse constraints of IoT devices that require lightweight
    detection are closer to applications and in the proximity of IoT nodes. Therefore,
    utilizing fog architecture in detecting various cyber threats, such as man-in-the-middle,
    sniffing, and eavesdropping attacks, is more effective than the cloud.[8] As Figure
    2 shows, the detection model is hosted locally at each node, while the master
    fog node performs the computation and updates the detection model parameters to
    each node. The architecture reveals that the data can be trained and validated
    at a single node, and distributes the model parameters in parallel to each node,
    enabling a collaborative intrusion detection closer to IoT devices while distributed
    detection nodes exchange the learning parameters with their neighbor nodes through
    the master fog node. The Fog-of-Things IDS architecture allows the building of
    a lightweight, scalable, and rapid detection approach that can effectively and
    efficiently mitigate several cyber threats. Figure 2. Fog-to-Things distributed
    IDS architecture in IoT-based smart villages. Show All IDS-BASED EMERGING TECHNOLOGY
    IN FOG COMPUTING The IDS as a security service can be improved with emerging technologies
    as well as benefit from the architecture of the DFC paradigm in order to enable
    a secure IoT-based smart village that can effectively and efficiently combat several
    cyber threats. We discuss SbD for the possible integration of emerging technologies
    with IDS-based DFC to improve security and privacy solution in smart villages.
    5G Networks The new generation of wireless network technology promises a significant
    revolution in wireless connectivity and network communications. As the IoT environment
    contains a large number of connected devices from several smart domains, which
    communicate with different network topology and protocols, the 5G networks provide
    several benefits over current cellular networks, including fast data transmission,
    low latency, improved capacity, and enhanced coverage for machine type communication.
    The 5G networks also can be a complement with fog computing as such an environment
    cooperates with different network layers requiring fast, reliable, and efficient
    machine-to-machine communication. As the nature of fog computing reveals a decentralized
    architecture that requires a high-frequency transmission rate with minimum delay
    among distributed Fog nodes, such a collaborative security function like a distributed
    IDS can leverage the benefits of 5G technology with fog computing in providing
    rapid and effective security attack mitigation. Artificial Intelligence (AI) AI
    plays a vital role in smart technology and has potential uses of its applications
    within critical domains in smart villages. When speaking of AI, machine learning
    and deep learning (ML/DL) have gained much attention in detecting malicious activities
    and reducing damages to the systems when integrated with security functions, such
    as IDS. The IDS can be employed as a collaborative detection model based on ML/DL
    techniques, leveraging the computational resources, and low latency that are provided
    by DFC to analyze, classify, and mitigate attacks effectively on real time.[9]
    Such features of DFC help develop a lightweight, efficient, and rapid mitigation
    mechanism based on ML/DL techniques, reducing the risk caused by cyber threats
    in smart villages. Software-Defined Network Fog computing can employ software-defined
    networking (SDN) and benefit from its significant features. SDN is a network architecture
    paradigm that enables a network topology to be managed and programmed by software
    applications. As the SDN controller is considered the most important function
    of SDN architecture, the fog layer can utilize the SDN controller to provide the
    anomaly detection approach where the network traffic has to go through a fog node
    or a fog server, in which the SDN controller is hosted.[10] The detection and
    mitigation mechanism provides the controller with updated flow rules to segregate
    and disregard malicious traffic from legitimate traffic. Fog computing provides
    sufficient computational resources for such an implemented detection algorithm
    based on an SDN controller. Network Functions Virtualization (NFV) In addition
    to the SDN, NFV is an emerging technology that employs virtualization concepts
    to its network functions, decoupling network components from underline hardware
    to be all virtualized network functions running as software on standard servers.
    As fog computing operates in a virtualized intermediate layer and virtual machines
    can be dynamically instantiated and removed, the NFV paradigm will benefit fog
    computing by virtualizing different network functions, such as switches, IDS,
    load balancers, and firewalls, and operating those instances over fog nodes.[11]
    NFV also provides flexibility to its virtualized security functions, such as intrusion
    detection and prevention systems, by adapting new rules or instantiating new security
    instances on demand. Blockchain Blockchain technology has been employed with several
    emerging technologies, such as the IoT ecosystem. Blockchain technology follows
    the decentralized architecture by its nature, which can help provide decentralized
    security services for an IoT-based smart village ecosystem. A distributed IDS
    gains several advantages over a single IDS in detecting sophisticated attacks.
    Moreover, distributed IDS nodes need to collaborate and exchange data efficiently
    and effectively between IDS nodes to detect and mitigate a diverse range of cyber
    threats. However, two major challenges with distributed IDS have been observed[12],[13]:
    sharing the information among multiple IDS nodes and computation trust between
    participants. To resolve these issues, blockchain technology ensures the integrity
    of data when sharing and exchanging information among multiple IDS nodes through
    building a trust management model for data sharing. With the advent of fog computing,
    fog nodes can communicate with each other by using blockchain technology without
    the involvement of a centralized authority or third party in the cloud, which
    helps avoid the single point of failure problem.[12] Blockchain technology has
    strong potential and can be integrated with other emerging technology, such as
    SDN and fog computing, to provide a secure, resilient, and more efficient mitigation
    system against several cyber threats in IoT-based smart villages. Big Data Analytic
    The massive amount of heterogeneous data produced from IoT devices requires a
    cost-effective and efficient computational resources method to process, analyze,
    and filter Big Data near IoT devices. The architecture of DFC provides fog data
    services, which comprise several functionalities, such as data management, data
    analysis, data security, and data virtualization.[14] With such features of data
    services in fog architecture, the distributed fog nodes help analyze data in real
    time, providing rapid and efficient decision-making near the IoT sensors. Such
    a lightweight analytical tool implemented based on ML techniques will help in
    analyzing data and selecting the most important features in classifying and detecting
    attacks effectively. CASE STUDY OF DFC FOR SECURE SMART VILLAGE As a case study,
    we have designed and implemented an IDS based on XGBoost and Random Forest using
    DFC. Figure 3 shows the general architecture of our proposed distributed and parallelized
    attack detection process in an IoT-based smart village scenario. In this case
    study, we have several IoT sensors and actuators responsible for capturing real-time
    data from their surroundings and transmitting it to nearby fog nodes for further
    processing. Once the data are received by the nearest worker fog nodes, they compute
    the gradient and send the partial gradient to the master fog node. The master
    fog node aggregates the gradients from all worker fog nodes and sends back the
    new weight to worker fog nodes. The gradients are further used to produce attack
    detection models as an output from the worker fog nodes. This sharing reduces
    overall training time in real time and increases the efficiency of the attack
    detection process. The proposed IDS is based on three different steps. Data acquisition
    and preprocessing: In particular, actual IoT datasets obtained from the IoT environment
    are used to simulate the proposed IDS. The initial features are preprocessed to
    make datasets more generalized and compatible for learning algorithms. Distributed
    learning in fog environment: The learning algorithms are implemented and trained
    on multiple fog nodes. This process can be executed on routing and switching devices
    of the smart village. Attack detection: This phase use the knowledge obtained
    from training to detect attacks. Figure 3. Case study of DFC for secure smart
    village. Show All Performance Evaluation The abovementioned steps are used to
    design and simulate the proposed IDS. The overall experiments of this study were
    performed on an Intel(R) Xeon(R) Silver 4114 CPU @ 2.20 GHz (2 processors), 128-GB
    RAM, and a 2-TB hard disk. We have used Kubernetes and H2O.ai platform to train
    and test the proposed IDS. The parallelism and distribution are carried out by
    a varying number of machines used during training. The ToN-IoT dataset is used
    to show the effectiveness of the proposed model.[8] This dataset contains various
    recent attacks, such as backdoor, DoS, DDoS, injection, MITM, password, ransomware,
    scanning, and XSS attacks, which are mostly found in IoT-based smart village environments.
    The algorithms mentioned in Kumar et al.''s[13] work were used to design proposed
    IDS using DFC. Figure 4 shows the training time for XGBoost and Random Forest
    using 15 fog nodes. It is clear that the training time decreases with the increase
    in worker fog nodes. We have used multiple evaluation metrics, such as detection
    rate (DR), precision (PR), F1, and false alarm rate to evaluate the performance
    of the proposed IDS, as mentioned in Kumar et al.''s[13] work. Table 1 shows per-class
    prediction results using the ToN-IoT dataset. It is worth noting that the performance
    of both algorithms on the ToN-IoT dataset is effective and has obtained higher
    values (i.e., 86%–100%) for different evaluation metrics. Moreover, we see that
    the FAR for the attack groups has been reduced close to 0%. This indicates that
    the DFC-enabled IDS has huge potential in detecting attacks in a real-time IoT-based
    smart villages environment. Finally, we have compared our work with some recent
    state-of-the-art techniques using the ToN-IoT dataset. Table 2 shows the comparison
    in terms of overall accuracy. The proposed distributed IDS has achieved 99.89%
    and 98.31% accuracy with XGBoost and Random Forest, respectively. This is higher
    compared with the works presented in Alsaedi et al.[15] and Ribeiro Junior et
    al.''s[8] works. Moreover, the proposed framework works in distributed environment
    compared with Alsaedi et al.[15] and Ribeiro Junior et al.''s[8] works that uses
    centralized attack detection approach. Table 1. Per-class prediction results (%)
    for proposed IDS on ToN-IoT dataset. Table 2. Performance comparison with existing
    state-of-the-art techniques using ToN-IoT dataset. Figure 4. Training time analysis
    by varying fog nodes. Show All SECURITY ISSUES AND CHALLENGES Although the integration
    of fog computing in a smart village provides considerable advantages to end users,
    security and privacy issues remain significant challenges. We briefly discuss
    the major security and privacy challenges in the integration of fog computing
    with IoT-based smart villages. Authentication The nature of IoT technology requires
    devices to prove their identity and ensure that IoT devices can be trusted to
    connect and exchange data among IoT objects and fog nodes. Authentication of devices
    is important to avoid cyberattacks, such as man-in-the-middle attacks. Many proposed
    authentication schemes were presented in the previous work; however, traditional
    authentication approaches are insufficient and lack scalability. Therefore, a
    lightweight authentication protocol is needed to meet the security requirements
    between IoT devices and fog nodes.[15] As fog computing authenticates many end
    users’ devices simultaneously, to become a part of the network, it lacks real-time
    interaction and causes high latency. Another challenge of authentication is regarding
    trust and service level agreement between different members of interconnected
    services while designing a mutual authentication scheme is another obstacle. Access
    Control Access control is one of the major security protection approaches that
    entails protecting, preserving, and restricting access to a user''s data or service
    from unauthorized access, and allowing the credentials for only authorized entities.
    The main objective of access control is to maintain security and privacy for end
    users and protect data from attacks that attempt to gain unauthorized access and
    perform malicious activities. Due to the involvement of different members of interconnected
    services, “IoT-Fog-Cloud,” maintaining access control between a large group of
    different service providers becomes a challenge. As fog computing comprises many
    fog nodes and data are transmitted among those nodes, it may trigger time delay
    and result in a high latency issue, which affects the access decision to be within
    an acceptable time.[15] Preserving the privacy state while transmitting data from
    one domain to another through fog access control is another challenge in terms
    of maintaining the user''s security and privacy requirements. Data Privacy With
    the rapid growth of several emerging technologies that deal with users’ data,
    privacy constantly becomes a major concern. When discussing privacy, the main
    issues center on how the data are collected, shared, and stored. Due to the increasing
    number of interconnected devices and emerging new technologies that may be integrated
    with other technology architectures, users’ privacy becomes a crucial part to
    maintain and control. An example is sharing users’ data across multiple domain
    architectures, such as IoT-Fog-Cloud. As fog computing follows a distributed architecture,
    in other words, multiple fog nodes scattered and distributed over large areas,
    maintaining data privacy across multiple nodes in different locations becomes
    another challenge.[15] Moreover, fog nodes receive and process data at different
    fog storage levels and forward users’ data to the cloud, such an attack on fog
    node storage will reveal sensitive user data. Therefore, designing new solutions
    for ensuring data privacy is another major challenge. Trust Management Trust management
    is an essential part to be maintained and established to identify a trusted node
    and isolate a malicious node before it is connected to the network. Due to the
    nature of the fog environment, which includes scattered and distributed fog nodes
    over large areas, defining and maintaining the trust status of each node to determine
    whether a node is trustworthy or not becomes a challenge. Another trust management
    challenge is the integration of multiple environments, such as Things-Fog-Cloud,
    which reveals a centralized architecture for the cloud and a distributed environment
    for fog computing. Consequently, designing and maintaining trust management among
    distributed fog nodes is a research issue.[13] Virtualization Technologies The
    primary purpose of network function virtualization (such as SDN and NFV) is to
    enhance network performance while enhancing the network infrastructure''s programmability
    and flexibility. In IoT-based smart villages, the inherent constraints in adapting
    such virtualized infrastructure and ensuring low latency, high throughput, and
    minimal computation overheads are challenging and a research issue. Transition
    From 5G to Beyond 5G The introduction of 5G and the shift to beyond 5G may present
    possible issues for carrier access networks in large-scale DFC installations of
    IoT-based smart villages (e.g., interconnections and interfaces, coordination,
    administration and control, and interconnections between mobile, user plane function
    and fixed carriers). Thus, it will be an interesting research direction to design
    a security solution in such an ecosystem. CONCLUSION In this article, we have
    explored the integration of DFC with IoT-based smart villages to improve the quality
    of life for villagers and CE devices from a security and privacy perspective.
    We have discussed SbD for IDS with the integration architecture of DFC in IoT-based
    smart villages. This article also presented the possible integration of several
    emerging technologies with the IDS-based distributed fog computing to improve
    security and privacy solutions in a smart village. We also designed and implemented
    a case study of an IDS for a distributed fog computing-based smart village. In
    the end, we discussed various security and privacy challenges that require attention
    from the research community. Authors Figures References Citations Keywords Metrics
    Footnotes More Like This A Survey on Security and Privacy Issues in Edge-Computing-Assisted
    Internet of Things IEEE Internet of Things Journal Published: 2021 Security Framework
    for Internet-of-Things-Based Software-Defined Networks Using Blockchain IEEE Internet
    of Things Journal Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Consumer Electronics Magazine
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Fog Intelligence for Secure Smart Villages: Architecture and Future Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Leong Y.M.
  - Lim E.H.
  - Subri N.F.B.
  - Jalil N.B.A.
  citation_count: '1'
  description: Agriculture faces significant challenges, including climate change,
    limited resources, and population growth, necessitating innovative solutions to
    ensure sustainable productivity and food security. Artificial Intelligence of
    Things (AIoT), a convergence of Al and IoT technologies, offers transformative
    potential for agriculture by optimizing resource utilization, improving production
    management, and reducing labor dependency. This paper presents an overview of
    AIoT applications in agriculture, highlighting its benefits, opportunities, and
    challenges. AIoT's benefits include increased efficiency and productivity through
    automation, reduced labor dependency with AI-powered robots, improved decisionmaking
    by analyzing real-time data, and enhanced sustainability by optimizing resource
    use. Opportunities for AIoT in agriculture encompass precision farming, predictive
    analytics, autonomous farming, resource optimization, supply chain efficiency,
    and decision support systems. However, implementing AIoT in agriculture faces
    challenges such as data quality, connectivity, cost, privacy, and user adoption.
    Addressing these challenges is essential to harness AIoT's potential fully. Future
    research directions include developing advanced Al algorithms, exploring edge
    computing, promoting interoperability and standards, and investigating AIoT's
    role in climate resilience and resource management. Research should also focus
    on AIoT adoption and usability, social and ethical implications, and AIoT-based
    supply chain integration. AIoT offers the opportunity to revolutionize agriculture,
    address challenges and unlock opportunities for sustainable productivity and food
    security. By adopting AIoT technologies and following relevant research directions,
    the agricultural sector can overcome challenges and achieve a resilient and food-secure
    future.
  doi: 10.1109/AGRETA57740.2023.10262747
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 IEEE International Confe... Transforming
    Agriculture: Navigating the Challenges and Embracing the Opportunities of Artificial
    Intelligence of Things Publisher: IEEE Cite This PDF Ying Mei Leong; Ean Heng
    Lim; Nor Fatiha Binti Subri; Norazira Binti A Jalil All Authors 1 Cites in Paper
    102 Full Text Views Abstract Document Sections I. Introduction II. Literature
    Review III. Future Research Directions IV. Conclusion Authors Figures References
    Citations Keywords Metrics Abstract: Agriculture faces significant challenges,
    including climate change, limited resources, and population growth, necessitating
    innovative solutions to ensure sustainable productivity and food security. Artificial
    Intelligence of Things (AIoT), a convergence of Al and IoT technologies, offers
    transformative potential for agriculture by optimizing resource utilization, improving
    production management, and reducing labor dependency. This paper presents an overview
    of AIoT applications in agriculture, highlighting its benefits, opportunities,
    and challenges. AIoT’s benefits include increased efficiency and productivity
    through automation, reduced labor dependency with AI-powered robots, improved
    decisionmaking by analyzing real-time data, and enhanced sustainability by optimizing
    resource use. Opportunities for AIoT in agriculture encompass precision farming,
    predictive analytics, autonomous farming, resource optimization, supply chain
    efficiency, and decision support systems. However, implementing AIoT in agriculture
    faces challenges such as data quality, connectivity, cost, privacy, and user adoption.
    Addressing these challenges is essential to harness AIoT’s potential fully. Future
    research directions include developing advanced Al algorithms, exploring edge
    computing, promoting interoperability and standards, and investigating AIoT’s
    role in climate resilience and resource management. Research should also focus
    on AIoT adoption and usability, social and ethical implications, and AIoT-based
    supply chain integration. AIoT offers the opportunity to revolutionize agriculture,
    address challenges and unlock opportunities for sustainable productivity and food
    security. By adopting AIoT technologies and following relevant research directions,
    the agricultural sector can overcome challenges and achieve a resilient and food-secure
    future. Published in: 2023 IEEE International Conference on Agrosystem Engineering,
    Technology & Applications (AGRETA) Date of Conference: 09-09 September 2023 Date
    Added to IEEE Xplore: 28 September 2023 ISBN Information: DOI: 10.1109/AGRETA57740.2023.10262747
    Publisher: IEEE Conference Location: Shah Alam, Malaysia SECTION I. Introduction
    Agriculture represents a crucial sector that underpins our population growth and
    well-being. It has been providing nourishment for generations. The agricultural
    sector faces numerous challenges, including climate change, insufficient agricultural
    land, growing population, biodiversity loss, and low investment in agriculture
    [1], Farmers must cope with climate change, soil erosion, and biodiversity loss,
    satisfy consumers’ changing tastes and expectations, and meet rising demand for
    more food of higher quality [2], The Organisation for Economic Co-operation and
    Development (OECD) emphasizes the three key challenges facing agriculture: feeding
    a growing population, providing a livelihood for farmers, and protecting the environment
    [3], Global threats to agriculture include climate change, depleted resources,
    and soil erosion, which negatively impact the industry and overall food security
    [4], The loss of agricultural land through erosion and manmade factors is one
    of the large problems facing agriculture [5], The World Bank addresses key issues
    in agriculture, including the lack of access to adequate food for a significant
    portion of the world’s population, the need to fight climate change, and the importance
    of digital transformation in the agrifood system [6], Table 1 summarizes the challenges
    facing agriculture: Table 1 Agriculture Challenges These challenges require innovative
    solutions to ensure sustainable productivity growth to feed a growing world population
    in a changing climate, while simultaneously reducing the sector’s greenhouse gas
    emissions. The agriculture sector needs to embrace innovative technologies such
    as Artificial Intelligence of Things (AIoT) to navigate these challenges and embrace
    the opportunities of the future [7][8][9][10]. AIoT is a combination of artificial
    intelligence (Al) technologies and the Internet of Things (IoT) infrastructure.
    AIoT can be used in agriculture to optimize resource utilization, improve production
    management and productivity, and reduce labor dependency [11], SECTION II. Literature
    Review A. What is AIoT? AIoT is a rapidly growing technology that combines the
    power of Al with the connectivity of IoT to create a powerful tool for agricultural
    transformation. Al can analyze large amounts of data from IoT sensors to identify
    patterns and trends that can help farmers make better decisions. For instance,
    Al can be used to monitor crop health, identify pests and diseases, and optimize
    irrigation schedules. Recent advancements in AIoT applications for precision agriculture
    have been discussed in several research papers [7] [8] [12], These papers highlight
    the current progress, applications, and advantages of AIoT in agriculture, including
    optimizing resource utilization, improving production management and productivity,
    and reducing labor dependency. The adoption of AIoT technology significantly transforms
    the traditional agriculture scenario by addressing numerous challenges, including
    pest management and post-harvest management issues [8] [11], However, there are
    still some barriers that need to be overcome, such as the cost factors and the
    adaptation to traditional agricultural practices [8], An AIoT-based smart agricultural
    system for pests’ detection has been proposed in a research paper [13], This system
    notifies farmers of the presence of different pests before they start multiplying
    in large numbers. B. Benefits of AIoT in agriculture AIoT in agriculture offers
    various benefits, including increased efficiency and productivity, reduced labor
    dependency, improved decision-making, and increased sustainability as shown in
    Figure 1. Increase efficiency and productivity. AIoT offers significant benefits
    to farmers by automating tasks such as crop monitoring and irrigation. This automation
    frees up farmers’ time, allowing them to focus on other important activities.
    By utilizing AIoT technologies, farmers can access real-time data on crop health,
    soil moisture, and other relevant factors. This information assists them in making
    more informed decisions about planting, irrigation, and harvesting [7] [8][11],
    For example, Precision Hawk employs AIoT in conjunction with drones to monitor
    crops. Drones collect data on crop health and soil moisture, which is then analyzed
    by AIoT algorithms. The analyzed data is transformed into detailed maps of crop
    fields, enabling farmers to identify areas that require additional attention [14],
    According to a recent study conducted by the McKinsey Global Institute, the implementation
    of Al in agriculture could potentially increase productivity by 70{%} by the year
    2050. This increase in productivity would be instrumental in meeting the food
    demands of a growing global population. Reduce labor dependency:AI-powered robots
    are already being used for tasks like weeding and harvesting. As these robots
    become more sophisticated, they could potentially replace human labor on many
    farms. This could result in job losses in the agricultural sector, but also help
    reduce the cost of food production and save farmers time and money. For example,
    FarmBot sells robotic farming systems that can automate tasks like planting, watering,
    and weeding crops. The systems are controlled via a smartphone or tablet and can
    be programmed to follow specific instructions [8][11][15][16][17], Improve decision-making:AIoT
    can help farmers make better decisions about crop planting, irrigation, and pest
    control by analyzing real-time data from sensors and other IoT devices. This information
    can be used to identify potential problems early on, such as pests or diseases,
    and to take corrective action before they cause significant damage. For example,
    CropMetrics uses AIoT to monitor crops for pests and diseases. The company’s sensors
    collect data on crop health, soil moisture, and other factors, which is then analyzed
    by AIoT algorithms. This information is used to create alerts when there is a
    potential problem, such as the presence of a pest or disease [8][11][13][18],
    Enhance sustainability. AIoT in agriculture can help farmers reduce their environmental
    impact by optimizing resource use and minimizing waste. For instance, AIoT can
    be used to monitor water usage and adjust irrigation schedules accordingly, which
    can help to reduce water waste and improve crop yields. WaterBit is a company
    that sells IoT-enabled water monitoring systems that can be used to track water
    usage in agricultural settings [19], Fig. 1. Benefits of AIoT in Agriculture Show
    All C. Opportunities of AIoT in agriculture AIoT presents various opportunities
    to enhance productivity, sustainability, and decision-making in agriculture (Figure
    2). Precision Farming:AIoT enables precise monitoring and management of crops,
    resulting in optimized resource utilization and improved crop yields. For example,
    AIoT systems can analyze real-time data on soil moisture, weather conditions,
    and crop health to provide precise recommendations for irrigation, fertilization,
    and pest control [11]. Predictive analytics:Leveraging Al algorithms, AIoT can
    analyze historical and real-time data to generate predictive insights. This helps
    farmers to predict crop diseases, pest outbreaks or weather conditions. For example,
    AIoT can predict the occurrence of diseases based on environmental conditions,
    enabling farmers to take timely preventive measures [8]. Autonomous Farming:AIoT
    can enable autonomous farming operations through the use of autonomous vehicles,
    robots, and drones. Tasks such as planting, spraying and harvesting can be carried
    out precisely and efficiently with these devices. For example, Al-powered drones
    can monitor crop health and identify areas that need attention or apply targeted
    treatments [20]. Resource optimization:AIoT systems can optimize the use of resources
    such as water, fertilizers and energy. By analyzing data from sensors and environmental
    factors, AIoT can provide insights into resource allocation, reduce waste and
    improve sustainability. For example, AIoT can optimize irrigation schedules based
    on soil moisture levels and weather forecasts, saving water while maintaining
    crop health [11] [21]. Supply chain efficiency:AIoT can improve agricultural supply
    chain efficiency by providing real-time data and insights. This includes monitoring
    and tracking products, optimizing transport routes and managing inventory. For
    example, AIoT can provide real-time monitoring of temperature and humidity during
    storage and transportation, ensuring the quality and freshness of agricultural
    products [20]. Decision support systems:AIoT can provide farmers with decision
    support systems that provide actionable insights and recommendations. By analyzing
    data from multiple sources, including weather forecasts, market trends, and harvest
    data, AIoT systems can help farmers make informed decisions about planting, harvesting,
    and marketing strategies [8]. These possibilities highlight the potential of AIoT
    to revolutionize agriculture by improving productivity, sustainability and decision-making.
    By harnessing the power of Al and IoT technologies, farmers can optimize resource
    use, reduce costs and increase overall efficiency on farms. Fig. 2. Opportunities
    of AIoT in agriculture Show All D. Challenges of AIoT in agriculture While AIoT
    promises substantial benefits and opportunities for agriculture, its implementation
    presents certain challenges (Figure 3). Data Quality and Integration:AIoT in agriculture
    relies on collecting and analyzing large amounts of data from various sources
    such as sensors, drones, and satellite imagery. Ensuring the quality, accuracy,
    and compatibility of diverse data sets can be challenging. For example, integrating
    data from different types of sensors or ensuring the consistency of data collected
    over time can pose difficulties [22]. Connectivity and Infrastructure:AIoT systems
    require robust and reliable connectivity to transmit data in realtime. However,
    many agricultural areas lack adequate network coverage and internet connectivity.
    This can hinder the seamless functioning of AIoT systems and limit their effectiveness.
    Limited infrastructure can also be a challenge, particularly in rural or remote
    regions [23][24]. Cost and Affordability:Implementing AIoT solutions can involve
    significant costs. Acquiring and deploying the necessary hardware, sensors, and
    IoT devices, as well as setting up the required infrastructure, can be expensive.
    For small-scale or resource-constrained farmers, the upfront costs and ongoing
    maintenance expenses may pose financial challenges [25]. Data Privacy and Security:AIoT
    systems collect and process sensitive data related to crop health, soil conditions,
    and other farm-related information. Ensuring data privacy and protecting against
    cyber threats are critical challenges. Unauthorized access, data breaches, or
    misuse of personal and agricultural data could have serious consequences for farmers
    and the entire agriculture industry [26][27]. Adoption and User Training:Introducing
    AIoT technologies requires farmers and agricultural workers to adapt to new tools
    and processes. Some farmers may face challenges in understanding and utilizing
    AIoT solutions effectively. Training and education programs are essential to ensure
    farmers have the necessary skills and knowledge to leverage AIoT technologies
    optimally [28][29][30]. Interoperability and Standards:AIoT systems often involve
    multiple devices, platforms, and software from different manufacturers and providers.
    Ensuring interoperability and standardization among these systems can be complex.
    Lack of compatibility and standard protocols may limit the seamless integration
    and exchange of data between different components of AIoT solutions [31][32].
    Addressing these challenges is crucial to fully harness the potential of AIoT
    in agriculture and maximize its benefits for farmers and the industry as a whole.
    Fig. 3. Key challenges of AIoT in agriculture Show All SECTION III. Future Research
    Directions AIoT in agriculture holds significant potential to advance the industry
    and address emerging challenges. Future research should focus on the following
    key areas: Advanced Al Algorithms:Developing more sophisticated Al algorithms
    is essential to improve the accuracy and efficiency of AIoT systems in agriculture.
    Research should focus on machine learning models that can handle large and diverse
    datasets, adapt to dynamic environmental conditions, and provide more accurate
    predictions for crop health, pest outbreaks, and weather patterns. Edge Computing
    in AIoT:Edge computing, which involves processing data closer to the source (e.g.,
    on IoT devices), can enhance the responsiveness and reduce latency in AIoT systems.
    Future research should explore how edge computing can be effectively integrated
    into AIoT in agriculture to enable real-time decision-making without relying heavily
    on cloud-based processing. Interoperability and Standards:Addressing the interoperability
    challenges in AIoT systems is critical to facilitate seamless data exchange and
    integration between different devices and platforms. Research efforts should focus
    on developing common standards and protocols to enable the interoperability of
    AIoT solutions from different manufacturers. Sustainable Resource Management:AIoT
    can play a significant role in optimizing resource utilization in agriculture.
    Future research should investigate AI-driven approaches to conserve water, improve
    soil health, and minimize energy consumption while maximizing crop productivity.
    Additionally, exploring AIoT applications in precision fertilization and sustainable
    pest management would contribute to sustainable resource management. AIoT Security
    and Privacy:As AIoT systems collect and process sensitive data, ensuring robust
    security and privacy measures is crucial. Future research should focus on developing
    secure and privacy-preserving AIoT architectures and encryption techniques to
    protect farmers’ data from unauthorized access and cyber-attacks. Autonomous Farming
    Systems:Advancing AI-powered autonomous farming systems, such as robotic tractors
    and drones, could revolutionize agricultural operations. Research should explore
    novel Al algorithms and technologies that enable safe, efficient, and cost-effective
    autonomous farming practices. AIoT and Climate Resilience:Investigating how AIoT
    can assist farmers in adapting to and mitigating the impacts of climate change
    is essential. Future research should focus on developing AIoT solutions that provide
    real-time weather predictions, early warning systems for extreme weather events,
    and climate-smart farming practices. AIoT Data Analytics:Research should concentrate
    on developing data analytics techniques that can extract meaningful insights from
    the vast amount of data generated by AIoT systems in agriculture. This includes
    integrating data from various sources, data fusion, anomaly detection, and predictive
    modeling to support informed decisionmaking. AIoT Adoption and Usability:Exploring
    factors that influence the adoption of AIoT technologies among farmers and agricultural
    stakeholders is vital. Research should identify barriers to adoption and devise
    strategies to enhance the usability and user-friendliness of AIoT solutions. Social
    and Ethical Implications: Future research should examine the social and ethical
    implications of AIoT adoption in agriculture. Understanding the potential impacts
    on farmers’ livelihoods, labor displacement, data ownership, and environmental
    sustainability is critical for responsible and equitable AIoT implementation.
    AIoT-Based Market and Supply Chain Integration:Investigating the role of AIoT
    in streamlining agricultural supply chains, reducing food waste, and ensuring
    fair market access for small-scale farmers is essential. Research should explore
    how AIoT can enhance traceability and transparency in the supply chain, contributing
    to food safety and quality assurance. Multi-Scale AIoT Integration:Research should
    focus on the integration of AIoT technologies across different scales of agriculture,
    from small family farms to large-scale agribusinesses. Exploring AIoT solutions
    that can be tailored to diverse agricultural contexts will enable wider adoption
    and impact. By pursuing these research directions, the agricultural industry can
    fully capitalize on the potential of AIoT, revolutionizing farming practices,
    improving productivity, and contributing to a sustainable and food-secure future.
    SECTION IV. Conclusion Agriculture faces numerous challenges in the modem world,
    from climate change to limited resources and the need for sustainable practices.
    AIoT emerges as a promising solution to address these challenges and unlock new
    opportunities for farmers and the agricultural industry. The combination of Al
    and IoT technologies in agriculture presents benefits such as increased efficiency,
    reduced labor dependency, improved decision-making, and enhanced sustainability.
    Opportunities in AIoT include precision farming, predictive analytics, autonomous
    farming, resource optimization, supply chain efficiency, and decision support
    systems. However, implementing AIoT in agriculture is not without its challenges,
    including data quality, connectivity, costs, privacy, and user adoption. By overcoming
    these challenges and embracing innovative AIoT technologies, the agriculture sector
    can pave the way for sustainable productivity growth, ensuring food security for
    a growing global population. ACKNOWLEDGMENT We would like to extend our heartfelt
    gratitude to all individuals who contributed their time, expertise, and support
    to make this research study possible. Without their invaluable contributions,
    this work would not have been accomplished. We express our sincere appreciation
    to those who provided their knowledge and assistance throughout the research process,
    helping shape and refine our ideas. Additionally, we are deeply grateful to the
    anonymous reviewers for their meticulous review of our paper. Their constructive
    feedback and valuable suggestions played a crucial role in elevating the quality
    and rigor of this study. We acknowledge their dedication to maintaining the standard
    of research in the field. Furthermore, we cannot overlook the unwavering support
    of our families and friends. Their encouragement and understanding have been instrumental
    in overcoming challenges and keeping us motivated. Overall, we recognize and thank
    everyone involved for their priceless contributions to this research. Each individual’s
    involvement has made a significant impact, and we are immensely grateful for their
    role in making this study a reality. Authors Figures References Citations Keywords
    Metrics More Like This Artificial Intelligence and Internet of Things for Sustainable
    Farming and Smart Agriculture IEEE Access Published: 2023 Analysis of Decision
    Support System for Crop Health Management in Smart and Precision Agriculture Based
    on Internet of Things (IoT) and Artificial Intelligence (AI) 2023 1st DMIHER International
    Conference on Artificial Intelligence in Education and Industry 4.0 (IDICAIEI)
    Published: 2023 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 IEEE International Conference on Agrosystem Engineering, Technology
    and Applications, AGRETA 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Transforming Agriculture: Navigating the Challenges and Embracing the Opportunities
    of Artificial Intelligence of Things'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Miller M.
  - Ramachandran A.
  - Morel A.E.
  - Gafurov D.
  - Calyam P.
  citation_count: '0'
  description: Large volumes of video feeds are generated by systems of Unmanned Aerial
    Vehicles (UAV) or city intersections with cameras in edge applications such as
    border security, crime mitigation, precision agriculture and smart city traffic
    management. Due to compute/network resource demands in video processing in a reliable
    and scalable manner to enable situational awareness for application consumers
    of video feeds, these systems need to rely on network services, edge computing
    devices and cloud infrastructure resources. Consequently, there is a need for
    effective integration of point-solutions that can transmit information from the
    system edge to the cloud platforms. In this paper, we present a novel framework
    viz., TIGER (Transmitting Information with Global-designation of Emergency Routes)
    that leverages the merits of Software-Defined Networking (SDN) and Programming
    Protocol-Independent Packet Processors (P4) to provide intelligent network services.
    Specifically, TIGER framework comprises two network services 'priority routing'
    and 'congestion control' that distinguish emergency traffic transmission based
    on source-based routing, and select congestion-free links based on multi-hop routing
    inspection as network cross-traffic increases, respectively. Our experiment results
    show that TIGER framework achieves priority routing by reducing packet jitter
    by 52%, corresponding to robust real-time data transmission. In addition, it achieves
    congestion control through traffic reduction by 45% across multiple pathways.
  doi: 10.1109/NOMS56928.2023.10154345
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >NOMS 2023-2023 IEEE/IFIP Netw... Transmitting
    Information with Global-designation of Emergency Routes for Edge Video Processing
    Publisher: IEEE Cite This PDF Michael Miller; Anvitha Ramachandran; Alicia Esquivel
    Morel; Durbek Gafurov; Prasad Calyam All Authors 122 Full Text Views Abstract
    Document Sections I. Introduction II. Related Work III. TIGER Framework Methodology
    IV. Performance Evaluation V. Conclusion Authors Figures References Keywords Metrics
    Abstract: Large volumes of video feeds are generated by systems of Unmanned Aerial
    Vehicles (UAV) or city intersections with cameras in edge applications such as
    border security, crime mitigation, precision agriculture and smart city traffic
    management. Due to compute/network resource demands in video processing in a reliable
    and scalable manner to enable situational awareness for application consumers
    of video feeds, these systems need to rely on network services, edge computing
    devices and cloud infrastructure resources. Consequently, there is a need for
    effective integration of point-solutions that can transmit information from the
    system edge to the cloud platforms. In this paper, we present a novel framework
    viz., TIGER (Transmitting Information with Global-designation of Emergency Routes)
    that leverages the merits of Software-Defined Networking (SDN) and Programming
    Protocol-Independent Packet Processors (P4) to provide intelligent network services.
    Specifically, TIGER framework comprises two network services ‘priority routing’
    and ‘congestion control’ that distinguish emergency traffic transmission based
    on source-based routing, and select congestion-free links based on multi-hop routing
    inspection as network cross-traffic increases, respectively. Our experiment results
    show that TIGER framework achieves priority routing by reducing packet jitter
    by 52%, corresponding to robust real-time data transmission. In addition, it achieves
    congestion control through traffic reduction by 45% across multiple pathways.
    Published in: NOMS 2023-2023 IEEE/IFIP Network Operations and Management Symposium
    Date of Conference: 08-12 May 2023 Date Added to IEEE Xplore: 21 June 2023 ISBN
    Information: ISSN Information: DOI: 10.1109/NOMS56928.2023.10154345 Publisher:
    IEEE Conference Location: Miami, FL, USA Funding Agency: SECTION I. Introduction
    Unmanned Aerial Vehicles (UAV) working in cooperation as a swarm or city intersections
    with video cameras can be deployed as edge systems to facilitate situational awareness
    in remote areas for applications such as e.g., border security, crime mitigation,
    precision agriculture and smart city traffic management [1]. Such systems can
    enable real-time situational awareness to remote application users who need to
    make important human/material resource allocation decisions. However, due to compute/network
    resource limitations for video processing on-board the UAVs and at the network-edge
    devices, it is critical for these systems to be integrated with edge computing
    and cloud platform resources. Figure 1: Applications at the edge and its integration
    with intelligent network and cloud infrastructure resources. Show All The integration
    needs to meet the demands of emergency services in terms of reliable route connectivity
    and modular network traffic management capabilities to improve Quality of Service
    (QoS) that supports agile/scalable video data processing [2] [3]. In addition,
    related networks need to provide agile and modular capabilities that can be customized.
    Further, the integration of the UAV network and application services management
    (i.e., for edge video processing) in the edge computing and cloud platform resources
    needs to adapt monitoring methodologies [4] that are fine-grained, automated,
    and highly scalable to meet the requirements of visibility and control, at both
    the data and control planes. Traditional mobile self-organizing network technologies
    are too complicated to be quickly constructed and dynamically adjusted according
    to application requirements, making them unsuitable for UAV networks management
    [5]. Figure 1 illustrates how applications at the edge (e.g., drone video analytics
    or video surveillance) can integrate with intelligent network resources and a
    set of cloud server resources. The intelligent network resources that include
    a software-defined networking (SDN) controller [3] as well as programmable switches
    allow the separation of the control and data planes to obtain greater flexibility
    in network management. Consequently, SDN capabilities can be extended to handle
    emergency services needs related to maintaining latency or jitter bounds, as well
    as managing traffic with high precision and advanced monitoring [6]. The major
    challenge to be addressed in this context is the need for solutions that are effective
    for transmitting information from the system edge to the cloud platforms using
    global-designation of emergency routes. Thus, any bottlenecks for the large-volume
    edge application video processing pipelines can be overcome in a dynamic manner.
    In this paper, we present a novel framework for Transmitting Information with
    Global-designation of Emergency Routes (TIGER) that leverages the merits of SDN
    and P4 to provide intelligent network services. The TIGER framework aims to provide
    high-throughput and robust data transmission through network service modules to
    optimize real-time visual situational awareness. For the purposes of this work,
    we detail two major network services: (i) ‘priority routing’ to distinguish emergency
    traffic transmission based on source-based routing, and (ii) ‘congestion control’
    to select congestion-free links based on multi-hop routing inspection as network
    cross-traffic increases. The SDN controller logic in TIGER loads rules onto switches,
    and we utilize the P4 language to develop a custom packet header that extends
    the real-time transport protocol (RTP, RFC 3550) to intelligently prioritize and
    steer traffic to meet the visual cloud/edge computing needs of the applications.
    We assume regular switches at the edge gateway (e.g., ground control station in
    a UAV swarm) interface with programmable switches to enable computation at the
    edge devices as well as cloud servers, and thus new network optimization and management
    challenges arise to develop the TIGER framework that are of both theoretical and
    practical significance [7]. The incident data related information transmission
    to a cloud server for visual edge/cloud computing subsequently involves execution
    of various computer vision based data processing pipelines to serve client-specific
    needs such as e.g., face or action recognition/tracking, in a manner analogous
    to that discussed in [3]. Once processed, the data is transferred to a client
    edge location where the refined information is consumed in the form of visual
    situational awareness. Our experiments performed with the TIGER framework deployment
    produced results that highlight the benefits of using custom network protocols
    and port forwarding via P4 to optimize the handling of packets and traffic control
    across multiple network paths. The remainder of this paper is organized as follows:
    Section II discusses the related work in terms of network services for visual
    cloud/edge computing as well as programmable data plane frameworks. Section III
    details the TIGER framework methodology and implementation to use various components.
    Section IV presents the performance evaluation results of the TIGER framework
    deployment. Lastly, Section V concludes the paper. SECTION II. Related Work This
    section outlines the different aspects of our study, including content related
    to network services for visual cloudcomputing and programmable data plane frameworks,
    two critical areas leveraged to develop TIGER. A. Network Services for Visual
    Cloud/Edge Computing To effectively design a framework for visual cloud/edge computing
    related network services, methods for aggregating and processing data need to
    be defined, including network characteristics and implementations. Authors in
    [3] describe the notion of a collection, computation, and consumption architecture
    to support computer vision techniques. They defined fogs and the use of SDN for
    on-demand computing, offloading, and congestion avoidance to improve QoS on a
    regional scale. In understanding how to build network services for such a large
    quantity of network entities, the work in [8] defined cyber foraging, which is
    the augmentation of low-power devices (e.g., cameras and sensors) to obtain access
    to cloud-like services, which uses SDN to integrate multiple sensing devices and
    inspired our TIGER framework. SDN applications can be extended to 5G networks
    through advanced monitoring, high traffic precision, and strict latency and jitter
    standards [9]. Hence, our work considers QoS metrics (bandwidth, throughput and
    jitter) to validate SDN and P4 benefits to the video processing system’s visual
    situational awareness capability. We specialized in UAV swarm network systems,
    considering the impact of UAV networks, as noted in [10]. In contrast to prior
    works, the novelty of our TIGER framework is in the definition of modular network
    services that prioritize emergency routing for first-responders to gain situational
    awareness through real-time and robust data transmission across edge-cloud networks.
    Our approach enables incident-supporting visual cloud computing applications (with
    video coming from heterogeneous UAV sources) to leverage intelligent network resources
    that combine the benefits of both SDN and programmable switches control using
    P4 to provide new capabilities for transmitting information with global-designation
    of emergency routes for edge video processing. B. Programmable Data Plane Frameworks
    The P4 architecture consists of a parser to handle and define packet headers,
    an ingress block to define match-action tables to process incoming traffic, and
    an egress block to manipulate packet headers after processing [11]. A further
    advantage of P4 is the enhancement it provides for QoS demands. Through custom
    application headers, P4 programmable switches improve QoS (e.g., reduced jitter
    and increased throughput) while simultaneously aiding in traffic control in the
    network [12]. In regards to the dynamic control aspect of P4, the work in [13]
    accentuates the superior customization P4 provides to the programmer, but also
    the visibility into the network environment granted by the language through support
    for enhanced monitoring [14]. A work that is most closely related to our work
    is the CHIMA framework [15] that ties network virtualization and P4-based virtual
    network functions with monitoring of data transmission using In-Band Network Telemetry
    (INT). Additional knowledge expansion for our solution takes inspiration from
    [14], to alias Media Access Control (MAC) addresses to refer to host nodes. Thus,
    our work addresses the unique problem of developing intelligent network services
    to use SDN and programmable data planes for creating a system of priority for
    certain routes, as needed in incident-supporting applications at the edge that
    visually need incident situational awareness for video feeds consumers i.e., first-responders,
    and or decision makers. SECTION III. TIGER Framework Methodology In this section
    we describe the TIGER framework methodology, and how the modules can be customized.
    We also describe the various components, and their functionalities. A. TIGER Framework
    Overview The TIGER framework features modular network services that can be customized
    as per application-specific needs. For transmitting information with global designation
    of emergency routes, the TIGER framework supports two main network services. The
    first one is the TIGER Priority Routing, and the second one is the TIGER Congestion
    Control. In both the network service cases, a custom packet header is used for
    ingress traffic processing at the intermediate switches, which then forward the
    packets based on the rules (i.e., for priority routing and congestion control)
    set by the controller which open up routes. Figure 2: TIGER framework components
    and their interactions within the orchestration of the controller and client for
    setting up network topology and traffic management specifications. Show All B.
    TIGER Framework Components The different TIGER components provide the various
    functionalities of the two main network services as it can be observed in Figure
    2. In TIGERclient, the host destinations that the TIGER framework will use to
    forward processed information for visual situational awareness. For TIGERCtlwe
    use the Open Network Operating System (ONOS) [16] controller logic to set up the
    network topology and to apply rules for the TIGER framework. This allows manipulation
    and global network view of the network environment at run-time. Our custom P4
    protocolsand rules are installed on every switch in the network environment to
    provide the forwarding specifications in packet processing for both the priority
    routing and congestion control network services in the TIGER framework. TIGEREyeprovides
    the network monitoring functions for both MRI and ECN capabilities in the TIGER
    framework and helps with congestion detection and notification within the network
    environment. MRI can track the packet forwarding path and the queue length, whereas,
    ECN notifies the client when there are network infrastructure events related to
    congestion in order to invoke adaptations to tune QoS parameters e.g., packet
    loss and delay to reduce impact on the applications at the edge. Lastly, TIGERcyis
    the custom packet header that extends the RTP packet header is used to distinguish
    emergency traffic from normal traffic for the application traffic that are being
    serviced by the TIGER framework. C. TIGER Framework Implementation To implement
    the TIGER framework in different application contexts, the data plane needs to
    be programmed to have the visibility and control that satisfies the application
    QoS requirements of video feeds streaming to first-responders/decision makers.
    In terms of network control, SDN control plane is a candidate approach to sustain
    automatic network configuration by means of an open API (e.g., OpenFlow), isolating
    and abstracting the data plane from the orchestration at the control layer [17].
    However, SDN solutions need to flexibly support heterogeneous softwarized networks,
    such as next-generation edge-to-cloud computing nodes with IoT gateways that operate
    massive sensors, cameras, and other smart devices. In terms of flexible switch
    architectures, and high-level programming protocols, P4 has become the most widely
    used abstraction, programming language, and paved data plane programming strategy
    [18]. P4 is a high-level programming language for protocol-procedure packet processors,
    and it is compatible with SDN control protocols. OpenFlow supports partial programmability,
    whereas P4 improves and extends the flexibility [19]. In the following, we describe
    two main parts of a TIGER framework implementation: Defining and Using Custom
    Headers: In the P4 language, creation of novel packet headers can be executed
    in the parser. This is where the TIGER framework defines the custom packet header
    i.e., Tigercy. Figure 3 describes how an extension in the RTP packet header is
    modified for the purposes of the network services. Tigercy is applied to all labeled
    emergency traffic within the network. Specifically, when a switch encounters the
    Tigercy packet header, it follows explicit rules set by the controller to transmit
    this packet along a priority connection within the network and/or which is congestion-free
    in terms of cross-traffic. Source-based Routing: To implement the priority routing
    and congestion control network services, the source-based routing protocol is
    utilized and applied to the application-specific Tigercy header while handling
    the flow of network traffic at the intermediate programmable switches. Specifically,
    the source routing is done by checking the type of packets that are being sent.
    For instance, if the Tigercy packet header is being applied, it will determine
    two aspects: first, the path length between the emergency host and clients, and
    second, the traffic on intermediary switches to get an estimate on delay. Every
    switch will select an item from the stack and then deliver the packet accordingly,
    based on the selected port number. This requires the controller to designate a
    specific emergency source in the network environment. The Tigercy header is then
    applied to any data transmitted from this source. In controlling network congestion,
    based upon the sources and destinations of information to be transmitted, the
    TIGER framework implementation explicitly forwards packets to limit and avoid
    creating congestion across links in the network paths used by the application
    traffic. Figure 3: Tigercy header extends the RTP packet header. Show All It is
    also important to mention that giving priority to RTP packets can be done by setting
    up Differentiated Services Code Point (DSCP) in IP headers and doing priority
    scheduling in routers. However, DSCP only supports two metering actions, dropping
    and marking DSCP in the packet headers. This has its limitations including header
    formats [20]. Our application requires flexibility on the data plane, and fine-grained
    network resource control, including queue or packet scheduling. Our work proposes
    a combination of SDN and P4 capabilities in the switches. D. Application Use Cases
    The TIGER framework can be customized to meet the visual cloud/edge computing
    needs of the applications. We assume a network environment at the edge that receives
    incident data (e.g., video and images of scenes-of-interest) collected by an UAV
    swarm or a set of mounted cameras. Figure 4: Priority Routing Network Service
    Application. Show All Figure 4 shows our first application use case involving
    a disaster incident response using a coordinated UAV swarm. In particular, this
    use case requires providing emergency data transmission (related to video streams
    or images) to first responders through a priority network connection, while simultaneously
    routing the same incident data to other sources (e.g., news networks, web and
    social media sites) within a common network environment. Here, the TIGER framework
    implementation goal is to define a specific packet header, Tigercy, as an extension
    of the RTP protocol packet header to optimize the packet transmission speed and
    video quality for priority network clients. All other normal traffic with conventional
    packet headers are transmitted along the regular network route. Figure 5 shows
    our second application use case involving a video surveillance data collection
    using a coordinated UAV swarm and fixes cameras. Here, the TIGER framework implementation
    goal is to use P4 and SDN to limit network congestion caused by other cross-traffic.
    The network model assumption is to consider sending packets from one source network
    to only one other host. Subsequently, additional hosts are periodically added
    to the network for the source to relay information. The adaptation strategy is
    to reduce data load on common network pathways by opening up additional routes
    within the network environment as new destination hosts are added. P4 port forwarding
    provides the ability to explicitly direct packet transmission through switch ports.
    Figure 5: Congestion Control Network Service Application. Show All E. Network
    Testbed Integration Herein, we present how we integrated our TIGER framework in
    a network testbed emulator environment. A network emulator [21] facilitated the
    addition of Docker containers to our network. The switches serve as routers and
    components, following a topology for the use case scenario detailed in Figure
    5. The switches are encompassed by Docker containers, which are connected such
    that each container has one link to each of the middle switches. Lastly, those
    switches are connected to one another to incorporate the infrastructure for packet
    rerouting (potential for multiple pathways between hosts and routes converging
    at switches). In order to emulate real-time situational awareness for an incident-supporting
    application scenario with visual cloud/edge computing, we streamed video between
    hosts for a period of 10 minutes. We gathered data from trials of 250 seconds
    of parallel video streaming from one host to many hosts, or two hosts from one
    set of Docker containers. Simultaneously, we sent ICMP packets of 47000 bytes
    in order to artificially increase traffic along congested links. We further rate-limited
    the links we planned on congesting with configuration in the settings of the TCLink
    [22] links within our topology. In addition to the congestion control case (Case
    1), we consider two cases of emulated traffic congestion on paths between switches,
    256 Kbps (Case 2), and 125 Kbps (Case 3), to systematically analyze the effect
    of congestion in our network environment. Details on the testbed setup to reproduce
    our experiments or modify run-time configuration files and P4 programs can be
    found in our open-source GitHub repository [23]. SECTION IV. Performance Evaluation
    In this section, we first present our evaluation metrics to demonstrate the efficacy
    of the TIGER framework. We describe the experiment results, and highlight the
    benefits of our approach. A. Evaluation Metrics and results To evaluate the efficacy
    of the TIGER framework, criteria are defined for routing protocol and congestion
    control metrics to set expected performance and to provide a baseline for comparison
    to normal network performance (without TIGER). Packet loss and jitter must be
    reduced in the priority route service (with TIGER) to improve QoS and video data
    transmission. The priority route must further transmit increased throughput (bytes/s,
    packets per second (PPS)). 1) TIGER MRI: To first assess the capabilities of TIGER,
    a topology comprised of three switches and five hosts is created. The protocol
    limits congestion on network linkages between switches by routing packets via
    lower traffic routes (which may not be the most direct path). Our metrics are
    tabulated below in Table I. Increased throughput (a 28.8% increase in average
    PPS) is illustrated in Table I, demonstrating that using P4 enhances the data
    transmission. Further, the decrease in jitter and packet loss of 88.0% and 99.8%,
    respectively, using TIGER MRI demonstrates how P4 can improve the QoS of data
    transmission as it shown in Figure 6. These reduced metrics conclude that the
    data is being transmitted in a more timely and effective manner. Table I Network
    with and without TIGER MRI Figure 6: Interval plot of the jitter for TIGER-MRI
    along congested and newly opened network routes. Show All 2) TIGER Priority Routing:
    Results for our network configuration were obtained both ‘with’ and ‘without’
    our priority routing framework. Results can be seen in Table II. Table II Network
    with and without TIGER Priority Routing Along the Priority Network Pathway. The
    throughput was increased by 10.4% in terms of PPS. TIGER’s priority routing increased
    the bandwidth by 74.6%, which is clearly seen in Table II. The mean jitter and
    packet loss decreased by a strongly significant 51.8% and 82.3% through the use
    of TIGER’s priority routing. Figure 7 shows the jitter interval for TIGER Priority
    Routing along the priority network route. With these results, TIGER’s priority
    routing significantly improves QoS and provides more robust data transmission.
    The reduction in jitter serves for more effective data transmission, and the reduced
    packet loss ensures desired information is being obtained by emergency clients.
    Further, the increased throughput, demonstrates that the priority connection in
    TIGER is optimized to transmit more data to be used by high priority clients.
    Figure 7: Jitter interval for TIGER Priority Routing along the priority network
    route. Show All 3) TIGER Congestion Control: Results were obtained with and without
    the utilization of the TIGER framework for Congestion Control (CC). We collected
    traffic measurements to compare the benefits of the CC methodology (Case 1), in
    presence of 256 Kbps (Case 2), and 125 Kbps (Case 3) traffic congestion on paths
    between switches. We reduced the bandwidth of the path between switches [s4-s2]
    in order to emulate congestion. Specifically, all the packets are sent to host
    h 3 with the shortest path [s1-s4-s2], and all packets are sent to h 4 through
    the longer path [s1-s4-s5-s2]. Conventional shortest path would route the packets
    through [s1-s4-s2], but our CC solution would route packets through [s1-s4-s5-s2]
    to avoid congestion at [s4-s2]. Experiment results with metrics are tabulated
    in Tables III and Tables IV, where we can observe that the throughput increases
    by 124.99% and 350.97% respectively for Cases 2 and 3. It can be also observed
    from Figure 8 that QoS metrics are improved, showing a reduction of 25% in Case
    2, and 72% in Case 3 in terms of mean jitter(ms), when TIGER’s CC network service
    is applied to the network environment. Table III shows the performance of the
    scheme with throughput measurements in PPS, demonstrating the benefits of the
    CC network service, and the impact of the congestion inter-packet arrival times
    when we have 256 Kbps traffic congestion in Case 2, and 125 Kbps traffic congestion
    in Case 3. Table III Traffic Measurements To Compare the Benefits of the Congestion
    Control Methodology In Presence of Emulated 256 90 Kbps Traffic Congestion On
    Paths Between Switches (Case 2). Table IV Traffic Measurements To Compare the
    Benefits of the Congestion Control Methodology In Presence of Emulated 125 Kbps
    Traffic Congestion On Paths Between Switches (Case 3). B. Results Discussion TIGER
    provides significant benefits in the cases of priority routing and congestion
    control network services. Results show increased throughput by 10.4% while reducing
    mean and maximum jitter by 51.8% and 42.7% respectively, as well as packet loss
    by 82.3% along the emergency pathway for the Priority Routing network service.
    For the Congestion Control network service, the TIGER redistributes traffic to
    lessen data load on common / direct network pathways, increasing the average PPS
    by 51%. In addition, a packet loss of 0% is experienced with Case 2 and Case 3
    when CC network service is applied as shown in Figure 9. Throughput measurements
    in PPS were also collected to compare the benefits of our CC algorithm (Case 1),
    and the impact of increased congestion in interpacket arrival times between Cases
    2 and 3 as it is observed in Figure 10. The solution utilizes all connections
    of the network and provides gateways to distribute information holistically between
    all network nodes and pathways. In this way, TIGER achieves the goal of providing
    data traffic through all possible network linkages which limits the potential
    congestion that most-direct pathways endure, reducing resource utilization and
    potential cost. Figure 8: Jitter measurements to show impact of increased congestion
    in inter-packet arrival times between switches: CC algorithm (Case 1), 256 Kbps
    (Case 2), and 125 Kbps (Case 3). Show All Figure 9: Packet loss % (Case 1) and
    the impact of increased congestion in inter-packet arrival times between switches:
    256 Kbps (Case 2), and 125 Kbps (Case 3). It can be observed a 0% packet loss
    when CC is applied. Show All Figure 10: Throughput measurements in PPS to compare
    benefits of CC algorithm (Case 1) and the impact of increased congestion in inter-packet
    arrival times between switches: 256 Kbps (Case 2), and 125 Kbps (Case 3). Show
    All SECTION V. Conclusion In this paper, we demonstrated a dynamic network services
    framework viz., TIGER that can be used to optimize the behavior of applications
    at the edge (e.g., drone video analytics, video surveillance) and thus increase
    data throughput and meet other traffic QoS demands for network reliability (e.g.,
    improved jitter). The TIGER framework provides substantial improvement in the
    realm of handling emergency traffic through the utilization of priority routing
    and congestion control network services. The network improvements provided by
    TIGER in terms of QoS metrics (e.g., throughput, loss, jitter) allow for more
    robust data transmission within an integrated system comprised of edge applications,
    intelligent network services and computer vision algorithms on agile/scalable
    cloud servers. As part of future work, the TIGER framework can be enhanced with
    additional scalability analysis. This could involve the migration of the Containernet
    testing onto physical testbeds at-scale in e.g., the NSF-funded FABRIC [24] facility.
    Related FABRIC experiments could help better analyze TIGER framework deployment’s
    performance to handle the large volumes of traffic and computation demands of
    visual cloud/edge computing application pipelines. Authors Figures References
    Keywords Metrics More Like This Compromises between energy consumption and quality
    of service metrics in wireless sensor networks with mobile sink and cluster based
    routing protocols 2017 International Conference on Internet of Things, Embedded
    Systems and Communications (IINTEC) Published: 2017 Impact of Sink Mobility on
    Quality of Service Performance and Energy Consumption in Wireless Sensor Network
    with Cluster Based Routing Protocols 2017 IEEE/ACS 14th International Conference
    on Computer Systems and Applications (AICCSA) Published: 2017 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings of IEEE/IFIP Network Operations and Management Symposium 2023,
    NOMS 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Transmitting Information with Global-designation of Emergency Routes for
    Edge Video Processing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Javeed D.
  - Gao T.
  - Saeed M.S.
  - Kumar P.
  citation_count: '8'
  description: The deployment of Internet of Things (IoT) systems in Smart Agriculture
    (SA) operates in extreme environments including wind, snowfall, flooding, landscape,
    and so on for collecting and processing real-time data. The increased connectivity
    and broad adoption of IoT devices with low-power communications on farmland support
    farmers in making data-driven decisions using various Artificial Intelligence
    (AI) techniques. Furthermore, in such an environment, edge computing is also utilized
    to provide computationally intensive, latency-sensitive, and bandwidth-demanding
    services at the edge of the network. However, protecting edge-to-Things in the
    extreme environment of SA is challenging, due to the volume of data, and also
    attackers exploit network gateways to perform Distributed Denial of Service (DDoS)
    attacks. Motivated by the aforementioned challenges, we develop a novel deep learning-based
    Intrusion Detection System (IDS) for edge-envisioned SA in extreme environments.
    Specifically, a hybrid approach is developed by combining bidirectional gated
    recurrent unit, long-short term memory with softmax classifier to detect attacks
    at the edge of the network. To allow faster learning, the proposed IDS employs
    the Truncated Backpropagation through Time (TBPTT) approach to handle lengthy
    sequences of network data. Furthermore, we suggest an attack scenario with deployment
    architecture for the proposed IDS in the extreme environment of SA. Extensive
    experiments using three publicly available datasets namely, CIC-IDS2018, ToN-IoT,
    and Edge-IIoTset prove the effectiveness of the proposed IDS over some traditional
    and contemporary state-of-the-art techniques.
  doi: 10.1109/JIOT.2023.3288544
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Internet of Things Journal
    >Early Access An Intrusion Detection System for Edge-Envisioned Smart Agriculture
    in Extreme Environment Publisher: IEEE Cite This PDF Danish Javeed; Tianhan Gao;
    Muhammad Shahid Saeed; Prabhat Kumar All Authors 10 Cites in Papers 623 Full Text
    Views Open Access Under a Creative Commons License Abstract Authors Citations
    Keywords Metrics Abstract: The deployment of Internet of Things (IoT) systems
    in Smart Agriculture (SA) operates in extreme environments including wind, snowfall,
    flooding, landscape, and so on for collecting and processing real-time data. The
    increased connectivity and broad adoption of IoT devices with low-power communications
    on farmland support farmers in making data-driven decisions using various Artificial
    Intelligence (AI) techniques. Furthermore, in such an environment, edge computing
    is also utilized to provide computationally intensive, latency-sensitive, and
    bandwidth-demanding services at the edge of the network. However, protecting edge-to-Things
    in the extreme environment of SA is challenging, due to the volume of data, and
    also attackers exploit network gateways to perform Distributed Denial of Service
    (DDoS) attacks. Motivated by the aforementioned challenges, we develop a novel
    deep learning-based Intrusion Detection System (IDS) for edge-envisioned SA in
    extreme environments. Specifically, a hybrid approach is developed by combining
    bidirectional gated recurrent unit, long-short term memory with softmax classifier
    to detect attacks at the edge of the network. To allow faster learning, the proposed
    IDS employs the Truncated Backpropagation through Time (TBPTT) approach to handle
    lengthy sequences of network data. Furthermore, we suggest an attack scenario
    with deployment architecture for the proposed IDS in the extreme environment of
    SA. Extensive experiments using three publicly available datasets namely, CIC-IDS2018,
    ToN-IoT, and Edge-IIoTset prove the effectiveness of the proposed IDS over some
    traditional and contemporary state-of-the-art techniques. Published in: IEEE Internet
    of Things Journal ( Early Access ) Page(s): 1 - 1 Date of Publication: 22 June
    2023 ISSN Information: DOI: 10.1109/JIOT.2023.3288544 Publisher: IEEE Funding
    Agency: Authors Citations Keywords Metrics More Like This A Review of RGB Image-Based
    Internet of Things in Smart Agriculture IEEE Sensors Journal Published: 2023 Hybrid
    Metaheuristics With Machine Learning Based Botnet Detection in Cloud Assisted
    Internet of Things Environment IEEE Access Published: 2023 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Internet of Things Journal
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: An Intrusion Detection System for Edge-Envisioned Smart Agriculture in Extreme
    Environment
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kalyani Y.
  - Collier R.
  citation_count: '1'
  description: The integration of computing paradigms such as Cloud, Fog, and Edge
    is rapidly adopted in many domains. One such application is Smart Agriculture,
    which has diverse requirements for applications ranging from Augmented Reality,
    Satellite, and auto harvesters to a large number of agricultural devices and sensors.
    Cloud, Fog, and Edge integration solves several problems such as latency and bandwidth
    issues, security and privacy, and real-time data analytics. However, the combination
    has a few challenges, including resource allocation, resource scheduling, and
    task scheduling. In order to overcome these challenges and bring Smart Agriculture
    to the next levels of productivity and sustainability, based on Cloud, Fog, Edge
    computing, and Multi-Agent Systems with a concept of Digital Twin, a novel architecture
    is introduced in this paper. The proposed architecture is expected to be applied
    in Smart Agricultural farms and fields, opening new aspects of contemporary applications
    within the Agriculture domain.
  doi: 10.1007/978-3-031-29104-3_12
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart International Symposium on Intelligent
    and Distributed Computing IDC 2022: Intelligent Distributed Computing XV pp 111–117Cite
    as Home Intelligent Distributed Computing XV Conference paper Towards a New Architecture:
    Multi-agent Based Cloud-Fog-Edge Computing and Digital Twin for Smart Agriculture
    Yogeswaranathan Kalyani & Rem Collier  Conference paper First Online: 09 April
    2023 173 Accesses 1 Citations Part of the book series: Studies in Computational
    Intelligence ((SCI,volume 1089)) Abstract The integration of computing paradigms
    such as Cloud, Fog, and Edge is rapidly adopted in many domains. One such application
    is Smart Agriculture, which has diverse requirements for applications ranging
    from Augmented Reality, Satellite, and auto harvesters to a large number of agricultural
    devices and sensors. Cloud, Fog, and Edge integration solves several problems
    such as latency and bandwidth issues, security and privacy, and real-time data
    analytics. However, the combination has a few challenges, including resource allocation,
    resource scheduling, and task scheduling. In order to overcome these challenges
    and bring Smart Agriculture to the next levels of productivity and sustainability,
    based on Cloud, Fog, Edge computing, and Multi-Agent Systems with a concept of
    Digital Twin, a novel architecture is introduced in this paper. The proposed architecture
    is expected to be applied in Smart Agricultural farms and fields, opening new
    aspects of contemporary applications within the Agriculture domain. Keywords Cloud-Fog-Edge
    Multi Agent Systems Digital Twin Smart Agriculture This research is funded under
    the SFI Strategic Partnership Programme (16/SPP/3296) and is co-funded by Origin
    Enterprises plc. Access provided by University of Nebraska-Lincoln. Download conference
    paper PDF 1 Introduction The approaches such as Smart Farming, Smart Agriculture,
    and Precision Agriculture are variations on the same theme. They are typically
    linked to collecting data from many disparate data sources, including autonomous
    tractors, harvesters, robots and drones, sensors, and actuators. For example,
    in crop farming, the agricultural data harvested (such as humidity, temperature,
    pH and soil conditions) is typically analysed to maximise crop yield whilst minimising
    costs (e.g. nutrients, pesticides). Cloud computing helps collect, analyse and
    store data from the farms and fields. The number of standalone Cloud-based agricultural
    systems and physical systems is constantly growing. These systems support various
    monitoring, and analysis goals [9] by harvesting data from deployed sensors and
    uploading it to the Cloud for further analysis. A fundamental limitation of this
    approach is the requirement for pervasive Internet connectivity, which can rarely
    be achieved on real-world farms. Even when such connectivity does exist, it is
    often inhibited by high latency and low bandwidth. These real-world concerns limit
    the potential impact of Cloud-based Smart Agriculture systems. To overcome these
    limitations, the last few years have witnessed the extension of Cloud-based approaches
    like Fog and Edge computing. The main goal of these two computing paradigms is
    to bring Cloud services and resources to edge devices. Edge computing mainly focuses
    on the IoT level, whereas Fog computing focuses on an infrastructure level. Handling
    multiple IoT applications is unsupported in Edge computing and is supported at
    the Fog level. The location of data collection, processing, and storage mainly
    happens in network edge and edge devices in Edge computing. In contrast, it occurs
    near the edge, and core networking in the Fog layer [9]. The authors of [3] explore
    how these new models address the limitations of the Cloud by providing techniques
    for moving the computation, data analysis, and storage closer to the network’s
    edge. While the synthesis of Cloud, Fog, and Edge computing are appealing, it
    is also not trivial, and a number of challenges arise, such as: resource management
    (including sharing and allocation), task management, and scheduling (workflow,
    task). Multi-agent systems are the solution for the challenges mentioned above
    in the integration of such computing paradigms. The Multi agents incorporate social
    aspects and human reasoning to solve problems [16]. In this paper, we propose
    an architecture to integrate all three computing such as Cloud, Fog and Edge and
    Multi-Agent systems with the Digital Twin model for Smart Agriculture. The agents,
    which are deployed in the Fog layer, are responsible for: harvesting sensor data;
    monitoring crop growth through the maintenance of digital twins; and creating,
    monitoring and scheduling tasks. 2 Related Work The state of the art in Cloud,
    Fog and/or Edge Smart Agriculture systems is reviewed in [9]. Reviewed systems
    solve various problems related to animal management, crop management, greenhouse
    management, irrigation management, soil management and weather management. The
    systems deliver a range of benefits (low cost, low latency, saving on bandwidth,
    reliable data collection) and challenges (Security and privacy, Mobility, Data
    processing, Power management, hardware cost, internet connectivity). Reviews,
    focusing on the role of Internet of Things (IoT) in Smart Agriculture [4, 6, 12]
    highlight potential application domains, communication protocols, network types,
    and platforms. Common challenges discussed in these reviews include: Ubiquitous
    connectivity, data management, hardware and software challenges, authorisation
    and trust, and scalability. The role of Multi-Agent Systems (MAS) in Cloud-Fog,
    Cloud-Edge, or Cloud only applications is motivated by the need to address various
    challenges, including: task scheduling, resource allocation, resource sharing,
    and service provisioning. Such systems have typically been suggested for domains
    such as Smart Cities, Smart Healthcare and Autonomous driving. From a Smart Agriculture
    perspective, [15] proposes a Cloud-based MAS that implements a round-table consensus-based
    protocol as part of an adaptive resource management mechanism. [7] proposes a
    Cloud-based MAS to support knowledge discovery and decision-making for autonomous
    crop irrigation. [2] is one of a number of systems that present MAS-based agricultural
    monitoring systems that are implemented using fleets of agent-based Drones [11].
    Finally, [5] describes an Agent-based methodology and middleware for constructing
    IoT applications. Despite the works mentioned above, we could not find a standard
    architecture for the combinations in works that have been done in any domain.
    Although there are several MAS-based models and IoT-based systems available, to
    the best of our knowledge, no systems currently combine the concepts of Digital
    Twin, MAS, and Cloud-Fog-Edge. The significant contributions of this research
    paper are, (1) Propose a novel architecture with a combination of Digital Twin
    with Multi-Agent Cloud-Fog-Edge; (2) Introduce agents and Digital Twin in the
    Fog layer; (3) Introduce Mobile Fog zones and Static Fog zones. The objective
    of agents and Digital Twin in the Fog layer and mobile and Fog zones are clearly
    described in the following section. 3 Proposed Architecture As is depicted in
    Fig. 1, the architecture proposed in this paper is organised over three layers:
    Cloud, Fog, and Edge. The Cloud plays a number of roles but is primarily the domain
    of Big Data/Data Analytics. It provides data storage and anonymisation services
    for farm data, machine learning, and data analysis support. Additionally, the
    Cloud layer hosts various services for topics such as: yield prediction, disease
    identification, pest identification, and growth stage estimation. It provides
    analytical tools that support forecasting outcomes such as expected yield, crop
    waste, and revenues. The Fog layer represents the Farm Management System. The
    Multi-Agent System is deployed in this layer and is responsible for overseeing
    various activities specific to the farm. The Fog is further decomposed into two
    sub-strata: static Fog nodes are hosted in the farm itself, while mobile Fog nodes
    are associated with farm equipment, such as Tractors or Combine Harvesters and
    any other available hardware, such as Drones or Agricultural Robots. The key idea
    is that the static Fog nodes host local data storage /compute services for in-situ
    farm data analysis. In contrast, the mobile Fog nodes allow for the extension
    of the Fog to areas of the farm with sporadic or no Internet connectivity. Finally,
    the Edge consists of any agricultural (or other) devices hosting sensors (in-situ
    soil moisture sensor, tractor-mounted NDVI) or actuators deployed on the farm,
    be it in fields or part of farm equipment such as Tractors or Combine Harvesters.
    Edge devices are connected directly to static Fog services where internet connectivity
    permits. If such connectivity is unavailable, then the data provided by these
    devices is harvested on-demand or opportunistically through data collection services
    hosted on mobile Fog nodes. Fig. 1. Proposed Architecture for MAS-Cloud-Fog-Edge
    Full size image In addition to data collection, the Fog is responsible for overseeing
    other support activities such as: soil analysis, crop monitoring, pest/disease
    identification, or irrigation. Example tasks include: growth monitoring, lodging,
    nutrient analysis, information on the condition of the land, disease and pest
    monitoring, and irrigation needs. Where related to areas of the farm that lack
    Internet connectivity, tasks may be allocated to dedicated agents deployed to
    mobile Fog nodes. These agents are responsible for the achievement of their assigned
    tasks. This may require the support of the farmer (for example, directing the
    farmer via Augmented Reality to the key locations for extracting soil samples
    for a field [8]), or the farmer may play little or no role in the task (e.g. opportunistic
    sensing of data [10]), with the agent instead having full responsibility for its
    completion. Managing tasks is not the only role for agents, as it includes three
    additional types of agent: the Farm agent, Field agents, and the Farmer agent.
    The Farm agent’s primary responsibility is managing the farm and overseeing the
    use of farm resources as optimally as possible in the achievement of tasks whilst
    accounting for the needs/preferences of the farmer, who is represented indirectly
    by the Farmer agent. Field agents are created for each field on the farm to maximise
    the profit for the field, typically by maximising yield while minimising cost.
    To achieve this, each Field agent maintains an associated Digital Twin [13] of
    their field. The Digital Twin is underpinned by sensor data gathered by the system
    and is used to model the performance of the field against predicted performance
    based on historical data. The agent uses this model to create and maintain an
    associated Field Management Plan encoded as tasks, including sensing activities
    (for updating/ calibrating the model) or interventions, such as irrigation or
    spraying fertiliser or pesticide. Collectively the plan determines what tasks
    should be completed and when. The divergence between the predicted and actual
    models triggers reassessment of the field management plan by the relevant Field
    agent, potentially resulting in recommended alterations to the plan. Setting and
    revising the plan is a collaborative activity that occurs between the Field agent(s),
    the Farm agent and the farmer (via the Farmer agent). A central component of our
    approach is the Digital Twin of fields. It provides the primary context for activities
    of the Field agents and underpins the recommendations that agents make. Raw sensor
    data is harvested from Edge devices deployed across the farm by a specific type
    of task agent known as a Sensor Harvester. Third-party data sources supplement
    it (e.g., weather, satellite, or even financial data) and are used in conjunction
    with Cloud-based Data Analytics services to provide insights that the agents can
    apply. Some insights help improve the accuracy of the Digital Twin; others facilitate
    decision-making activities, helping to identify when a Field Management Plan may
    need to be altered or how it should be altered. These Cloud-based services are
    also used in the formation of these plans. Using the Digital Twin model in this
    architecture helps farmers get information on the fields and overall farm behavior.
    It also forecasts yield prediction, growth stage, nutrient information, and weather-report.
    To ensure that our architecture is future-proofed, we have designed it to be agnostic
    to implementing the Digital Twin. To cater for this, our architecture is also
    designed to allow the incorporation of new tasks. To achieve this, task descriptions
    are encoded using a flexible format, and new task types can be supported by creating
    new task-specific agents. Our vision aligns with the recently proposed idea of
    the Computing Continuum [1] which is concerned with developing digital infrastructure
    that is used by complex workflows typically combining real-time data generation
    and processing and computation [14]. Additionally, this architecture can increase
    sensors (soil moisture probes, NDVI sensors, weather stations), and facilitate
    upgrading equipment such as guidance in tractors and variable spray booms/map-based
    variable treatment. 4 Conclusions and Future Work This paper presents a novel
    approach to integrating MAS and Cloud-Fog-Edge with Digital Twin in Smart Agriculture.
    In the whole process of this architecture, there is a high possibility of combining
    several technologies and increasing the number of edge and fog devices (scalability)
    to achieve the objective of this model. For example, Blockchain makes it possible
    to monitor crop growth until handover to suppliers, Artificial intelligence and
    Robotics to help in the fields/farms, and Drones to aid in task achievements in
    the farm monitoring process. Smart Agriculture will benefit from these new technologies
    with the proposed architecture such as production increase, water-saving, better
    quality, cost reduction, early pest and disease identification, and better sustainability.
    In future work, we plan to focus on these areas: (1) Implement the use cases for
    Smart Agriculture using the proposed architecture; (2) Investigate the design
    constraints and requirements in integrating MAS and the computing paradigms with
    the Digital Twin model; (3) Further research on identifying challenges in combining
    new computing paradigms and MAS and possible solutions; We believe that other
    domains have enough scope to adopt the proposed MAS-based Cloud-Fog-Edge computing
    with Digital Twin architecture with additional changes based on the domain’s requirements.
    References Antoniu, G., Valduriez, P., Hoppe, H.C., Krüger, J.: Towards integrated
    hardware/software ecosystems for the edge-cloud-HPC continuum (2021) Google Scholar   Cavaliere,
    D., Loia, V., Senatore, S.: Towards a layered agent-modeling of IoT devices to
    precision agriculture. In: 2020 IEEE International Conference on Fuzzy Systems
    (FUZZ-IEEE), pp. 1–8. IEEE (2020) Google Scholar   Escamilla-Ambrosio, P.J., Rodríguez-Mota,
    A., Aguirre-Anaya, E., Acosta-Bermejo, R., Salinas-Rosales, M.: Distributing computing
    in the internet of things: cloud, fog and edge computing overview. In: Maldonado,
    Y., Trujillo, L., Schütze, O., Riccardi, A., Vasile, M. (eds.) NEO 2016. SCI,
    vol. 731, pp. 87–115. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-64063-1_4
    Chapter   Google Scholar   Farooq, M.S., Riaz, S., Abid, A., Umer, T., Zikria,
    Y.B.: Role of IoT technology in agriculture: a systematic literature review. Electronics
    9(2), 319 (2020) Article   Google Scholar   Fortino, G., Russo, W., Savaglio,
    C., Shen, W., Zhou, M.: Agent-oriented cooperative smart objects: from IoT system
    design to implementation. IEEE Trans. Syst. Man Cybern.: Syst. 48(11), 1939–1956
    (2017) Article   Google Scholar   Glaroudis, D., Iossifides, A., Chatzimisios,
    P.: Survey, comparison and research challenges of IoT application protocols for
    smart farming. Comput. Netw. 168, 107037 (2020) Google Scholar   González-Briones,
    A., Castellanos-Garzón, J.A., Mezquita-Martín, Y., Prieto, J., Corchado, J.M.:
    A multi-agent system framework for autonomous crop irrigation. In: 2019 2nd International
    Conference on Computer Applications & Information Security (ICCAIS), pp. 1–6.
    IEEE (2019) Google Scholar   Huuskonen, J., Oksanen, T.: Soil sampling with drones
    and augmented reality in precision agriculture. Comput. Electron. Agric. 154,
    25–35 (2018) Article   Google Scholar   Kalyani, Y., Collier, R.: A systematic
    survey on the role of cloud, fog, and edge computing combination in smart agriculture.
    Sensors 21(17), 5922 (2021) Article   Google Scholar   Liang, Q., Cheng, X., Huang,
    S.C., Chen, D.: Opportunistic sensing in wireless sensor networks: theory and
    application. IEEE Trans. Comput. 63(8), 2002–2010 (2013) Article   MathSciNet   MATH   Google
    Scholar   Mariani, S., Picone, M., Ricci, A.: About digital twins, agents, and
    multiagent systems: a cross-fertilisation journey. arXiv preprint arXiv:2206.03253
    (2022) Navarro, E., Costa, N., Pereira, A.: A systematic review of IoT solutions
    for smart farming. Sensors 20(15), 4231 (2020) Article   Google Scholar   Ricci,
    A., Croatti, A., Mariani, S., Montagna, S., Picone, M.: Web of digital twins.
    ACM Trans. Internet Technol. (TOIT) (2022) Google Scholar   Rosendo, D., Silva,
    P., Simonin, M., Costan, A., Antoniu, G.: E2Clab: exploring the computing continuum
    through repeatable, replicable and reproducible edge-to-cloud experiments. In:
    2020 IEEE International Conference on Cluster Computing (CLUSTER), pp. 176–186.
    IEEE (2020) Google Scholar   Skobelev, P., Larukchin, V., Mayorov, I., Simonova,
    E., Yalovenko, O.: Smart farming – open multi-agent platform and eco-system of
    smart services for precision farming. In: Demazeau, Y., Matson, E., Corchado,
    J.M., De la Prieta, F. (eds.) PAAMS 2019. LNCS (LNAI), vol. 11523, pp. 212–224.
    Springer, Cham (2019). https://doi.org/10.1007/978-3-030-24209-1_18 Chapter   Google
    Scholar   Villarrubia, G., Paz, J.F.D., Iglesia, D.H., Bajo, J.: Combining multi-agent
    systems and wireless sensor networks for monitoring crop irrigation. Sensors 17(8),
    1775 (2017) Article   Google Scholar   Download references Author information
    Authors and Affiliations School of Computer Science, University College Dublin,
    Dublin, Ireland Yogeswaranathan Kalyani & Rem Collier Corresponding author Correspondence
    to Yogeswaranathan Kalyani . Editor information Editors and Affiliations Bremen
    University of Applied Sciences, Bremen, Germany Lars Braubach Brandenburg University
    of Applied Sciences, Brandenburg, Germany Kai Jander University of Craiova, Craiova,
    Romania Costin Bădică Rights and permissions Reprints and permissions Copyright
    information © 2023 The Author(s), under exclusive license to Springer Nature Switzerland
    AG About this paper Cite this paper Kalyani, Y., Collier, R. (2023). Towards a
    New Architecture: Multi-agent Based Cloud-Fog-Edge Computing and Digital Twin
    for Smart Agriculture. In: Braubach, L., Jander, K., Bădică, C. (eds) Intelligent
    Distributed Computing XV. IDC 2022. Studies in Computational Intelligence, vol
    1089. Springer, Cham. https://doi.org/10.1007/978-3-031-29104-3_12 Download citation
    .RIS.ENW.BIB DOI https://doi.org/10.1007/978-3-031-29104-3_12 Published 09 April
    2023 Publisher Name Springer, Cham Print ISBN 978-3-031-29103-6 Online ISBN 978-3-031-29104-3
    eBook Packages Intelligent Technologies and Robotics Intelligent Technologies
    and Robotics (R0) Share this paper Anyone you share the following link with will
    be able to read this content: Get shareable link Provided by the Springer Nature
    SharedIt content-sharing initiative Publish with us Policies and ethics Download
    book PDF Download book EPUB Sections Figures References Abstract Introduction
    Related Work Proposed Architecture Conclusions and Future Work References Author
    information Editor information Rights and permissions Copyright information About
    this paper Publish with us Discover content Journals A-Z Books A-Z Publish with
    us Publish your research Open access publishing Products and services Our products
    Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio
    BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state
    privacy rights Accessibility statement Terms and conditions Privacy policy Help
    and support 129.93.161.222 Big Ten Academic Alliance (BTAA) (3000133814) - University
    of Nebraska-Lincoln (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Studies in Computational Intelligence
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Towards a New Architecture: Multi-agent Based Cloud-Fog-Edge Computing and Digital
    Twin for Smart Agriculture'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Nosouhi M.R.
  - Sood K.
  - Kumar N.
  - Wevill T.
  - Thapa C.
  citation_count: '8'
  description: With rising temperatures and events contributing to climate change,
    the world is facing extreme weather patterns. Recently, Australia was hit hard
    by bushfires, the most devastating fires ever faced by the country. The economic
    damage reported was nearly one billion Australian dollars and an estimated three
    billion native animals were killed or adversely affected. Given the extent and
    intensity of this damage, researchers are seeking effective solutions to enable
    the prediction of fire before it starts to increase the time available for firefighters
    to protect lives and assets and prepare to mitigate the fires. This motivated
    us to investigate an approach to address this critical problem. In this article,
    we propose a machine learning (ML)-based approach that detects anomalies in spatiotemporal
    measurements of environmental parameters (e.g., temperature, relative humidity,
    etc.). In the proposed approach, an ML-based model learns the normal spatiotemporal
    behavior of the environmental data (collected over a period of one year). This
    is carried out during a one-time training phase. Then, during the detection phase,
    any spatiotemporal pattern in the real-time data (received from the field sensors)
    that is different than the normal pattern will be identified by the model as anomaly
    which indicates a possible bushfire situation. Following this, we propose a supplementary
    classification model based on Moran's I index to ensure that the detected anomalies
    are not due to either a sensor failure or a security attack (which are common
    in Internet of Things). We developed three different ML models for performance
    evaluation and comparison and used the Forest Fire data set to train them. The
    results of our experiments confirm the effectiveness of the proposed approach
    in the early detection of fire symptoms.
  doi: 10.1109/JIOT.2021.3110256
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Internet of Things Journal
    >Volume: 9 Issue: 7 Bushfire Risk Detection Using Internet of Things: An Application
    Scenario Publisher: IEEE Cite This PDF Mohammad Reza Nosouhi; Keshav Sood; Neeraj
    Kumar; Tricia Wevill; Chandra Thapa All Authors 8 Cites in Papers 810 Full Text
    Views Abstract Document Sections I. Introduction and Background II. Related Work
    III. Our Proposed Approach IV. Implementation and Architecture Details V. Performance
    Evaluation Show Full Outline Authors Figures References Citations Keywords Metrics
    Abstract: With rising temperatures and events contributing to climate change,
    the world is facing extreme weather patterns. Recently, Australia was hit hard
    by bushfires, the most devastating fires ever faced by the country. The economic
    damage reported was nearly one billion Australian dollars and an estimated three
    billion native animals were killed or adversely affected. Given the extent and
    intensity of this damage, researchers are seeking effective solutions to enable
    the prediction of fire before it starts to increase the time available for firefighters
    to protect lives and assets and prepare to mitigate the fires. This motivated
    us to investigate an approach to address this critical problem. In this article,
    we propose a machine learning (ML)-based approach that detects anomalies in spatiotemporal
    measurements of environmental parameters (e.g., temperature, relative humidity,
    etc.). In the proposed approach, an ML-based model learns the normal spatiotemporal
    behavior of the environmental data (collected over a period of one year). This
    is carried out during a one-time training phase. Then, during the detection phase,
    any spatiotemporal pattern in the real-time data (received from the field sensors)
    that is different than the normal pattern will be identified by the model as anomaly
    which indicates a possible bushfire situation. Following this, we propose a supplementary
    classification model based on Moran’s I index to ensure that the detected anomalies
    are not due to either a sensor failure or a security attack (which are common
    in Internet of Things). We developed three different ML models for performance
    evaluation and comparison and used the Forest Fire data set to train them. The
    results of our experiments confirm the effectiveness of the proposed approach
    in the early detection of fire symptoms. Published in: IEEE Internet of Things
    Journal ( Volume: 9, Issue: 7, 01 April 2022) Page(s): 5266 - 5274 Date of Publication:
    06 September 2021 ISSN Information: DOI: 10.1109/JIOT.2021.3110256 Publisher:
    IEEE SECTION I. Introduction and Background Bushfire is commonly known as an unplanned
    vegetation fire or wildfire (grass fires, forest fires, and scrub fires, etc.),
    at a large scale. This occurs due to both natural and human–intervention related
    factors, such as weather, natural phenomena, topography, carbon emissions, seasonality,
    etc. [1]. On one side, essentially, it is shaping the nature and planet naturally
    in a variety of ways, but, on the other hand, the high frequency of occurrence
    of bushfire adversely impacts flora and fauna, both human and animal life, damage
    to properties, creates health issues due to air pollution, post bushfire psychological
    problems, and high economic impacts. Many areas in Australia are prone to bushfire
    as the climate is generally dry and hot in many states [2] and drought is common.
    For natural hazards and disasters, including bushfires, Geoscience Australia is
    responsible for preparedness and management activities. It has been reported that
    the bushfire season 2019–2020 was the worst season recorded in Australia [3],
    [4]. Some devastating impacts reported in [3] and [5], caused by the 2019–2020
    bushfire season are listed as follows. More than one billion animals died and
    three billion were affected in total, which is the highest rate of species loss
    in any area in the world [6]. The air pollution caused by severe bushfires in
    2020. The Australian Capital Territory (ACT), Canberra measured the worst air
    quality index of any major city in the world in January the same year. This has
    adversely affected territory’s residents with severe health risks, including [7]
    asthma, impaired vision, increased risk of heart attacks, and the development
    of neurological conditions, etc. This has significantly affected the farming and
    tourism industry. Severe economic damage was reported in 2019–2020 due to the
    Australian bushfire, nearly one billion Australian dollars had been reported as
    insurance losses as a result of the bushfires, almost 13 million hectares of land
    was been burned. [8]. Furthermore the total costs associated with extreme weather
    and climate change is difficult to quantify. The damage-related loss in property
    values from climate hazards across Australia in 2030 is estimated at 571 billion
    Australian dollars [3]. Overall, we note that the impact of bushfire is devastating
    in Australia. Towards this problem, it is critical to have effective and accurate
    forecasting systems to be in place to make better decisions for the mitigation
    of fire risks and hazards. Many attempts have been made as briefly mentioned below.
    Satellites-Based Solutions: In [9]–[11] satellite images are analyzed to detect
    areas that are generating a high level of infrared radiation (called hot spots).
    However, this approach suffers from high latency between successive scans, i.e.,
    rescanning of the same area needs a significant amount of time [12]. In addition,
    the detected hot-spot area does not indicate the exact location of a fire. It
    is also possible that clouds or the smoke prevent the system to have an accurate
    estimation of the fire location. Thus, limited resolution and the lack of real-time
    data generation make the satellite imagery approach inefficient for continuous
    monitoring of a forest zone [12]. Moreover, when the heat source is too small
    (at the early stages of a bushfire), the system may not consider that zone as
    a hot spot [11]. Unmanned Aerial Vehicles (UAVs)-Based Solutions: Furthermore,
    UAVs have been used to take real-time images of fire in the areas that are extremely
    dangerous to access [12]–[14]. The images are analyzed to assess the situation
    and make operational decisions to prevent outbreaks of the fire. UAVs can also
    be equipped with thermal imaging cameras to enable firefighters to see through
    the smoke and search for the victims. This approach is effective in post-fire
    situations but has very limited advantage in the early detection of bushfire.
    In addition, UAVs need high-speed communication links for the transmission of
    high-quality images that is a big issue in many regional forest areas. Section
    II covers more detail of the practical solutions being used by Australian fire
    agencies. Motivated from this, we propose to use the Internet of Things (IoT)
    technology and machine learning (ML) models to identify early symptoms of a bushfire.
    Our proposal is based on spatial correlation theory. We first train the ML model
    using the Forest Fire real data set collected from a target area over a period
    of one year [15]. Then, the real-time environmental data (collected from IoT network
    and tagged with spatiotemporal information) is fed to the trained model for the
    identification of possible anomalies. Note that the outliers in sensor data can
    also be generated by nonbushfire events, such as sensor failures or security attacks.
    In other words, bushfire detection using an approach that is solely based on outliers
    may result in high false positive rates. To address this issue, we utilize the
    spatial correlation between sensor measurements and develop a supplementary classification
    model to ensure that any detected anomaly has been created due to the early symptoms
    of a bushfire. The proposed model works based on Moran’s I index [16], [17] which
    is an effective tool for the measurement of spatial correlation in distributed
    architectures. We implemented a Proof of Concept (PoC) of our approach in Python.
    We also performed a prototype implementation of the approach in an edge computing
    setting to ensure its effectiveness to generate fire alerts at the very early
    stage of a bushfire. Our contributions in this article are as follows. We propose
    an ML-based anomaly detection approach for early detection of bushfire. In the
    proposed approach, the measurement and collection of spatiotemporal environmental
    data is performed using an IoT network. The collected real-time data is analyzed
    by the ML model to identify any spatiotemporal pattern that is different than
    the normal pattern. To reduce the number of false positive detections, a supplementary
    classification model is proposed to estimate the origin of the detected anomalies,
    i.e., early symptoms of a bushfire, sensor failures, or a security attack. We
    implemented the proposed approach in an edge computing setting to furthermore
    reduce the detection latency. Our results confirm the accuracy and effectiveness
    of the proposed approach. We present the related work in Section II. The proposed
    architecture and implementation details are given in Sections III and IV, respectively.
    Performance evaluation results and further discussion are given in Sections V
    and VI, respectively. We summarize this article in Section VII. SECTION II. Related
    Work In [13], a comprehensive survey presents the current problems of forest firefighting
    and state-of-the-art robotic technologies and solutions in firefighting missions.
    Akhloufi et al. [12] reviewed previous research and industry works done in bushfire
    management using UAV applications. It considers different onboard sensor instruments,
    fire perception algorithms, and coordination strategies. Below, we highlight the
    key approaches being used by different Australian authorities in the Bushfire
    context. Australian Bureau of Meteorology (BOM) and Geoscience Australia: In Australia,
    weather forecasts are provided by the BOM. Corresponding fire authorities determine
    the appropriate fire danger rating (FDR) by considering the predicted weather,
    including temperature, relative humidity, wind speed, and dryness of vegetation.
    These FDRs or alerts (via radio, TV, and the Internet) help the government and
    communities to take essential appropriate actions to minimize the potential impact
    and loss. Recently, Geoscience Australia has developed the (real-time) Sentinel
    bushfire monitoring system [5], Digital Earth Australia Hotspots, a national bushfire
    monitoring system. This collects areas generating a high level of infrared radiation
    (called Hotspots), via satellites at 10 min intervals, to identify possible fire
    risks [10]. But it is unable to provide real-time information; every hot-spot
    information is about 17 min old. Furthermore, the hot-spot size does not indicate
    the exact fire zone. Also in cases where the heat source is too small to detect,
    the system does not consider that zone as a hot-spot leading to inaccurate hot-spot
    identification [11]. MyFireWatch Project: This solution is based on an existing
    Department of Fire and Emergency Services (DFES) program, redeveloped by Landgate
    and Edith Cowan University (ECU), Australia, for use by the general public [18].
    This system gives a view of satellite observed hot-spots by detecting heat sources
    above a certain temperature level. Furthermore, these hot-spots update at 2–4
    h intervals and do not fully indicate the exact level of severity. It does not
    provide the exact coordinates of potential fire zones, is unable to determine
    accurately beyond 2 km, hot-spots in the presence of smoke and cloud cannot be
    detected. Besides the use of satellites, the Australian firefighters also make
    use of UAVs as a tool for combating fire [14]. The UAVs (particularly drones)
    provide real-time pictures of fire zones that are extremely dangerous to access.
    This approach is effective in post-fire situations to enable firefighters to make
    early assessments of damage while enroute to emergencies. The cost of UAVs and
    the requirement of high speed Internet connectivity are key hurdles in many regional
    areas or underdeveloped countries. Bushfire Attack Level Toolbox: Researchers
    also use modeling to analyze the potential impact of fire before it occurs. For
    example, to measure the impact of fires on buildings, the Bushfire Attack Level
    Toolbox is developed which provides access to ArcGIS geoprocessing scripts to
    calculate Bushfire Attack Level ratings [19]. For a comprehensive understanding
    of why bushfire monitoring systems does not work as intended, we encourage readers
    to follow [20] and references therein. Also, very recent recommendations provided
    by the Nature Conservation Society of South Australia (NCSSA) to the federal government
    to preparedness for, response to, and recovery from bushfire disasters are listed
    in [21]. FireCloud Project: In FireCloud, a recently done bushfire detection project
    [22], the existing satellite-based fire detection systems are supplemented with
    ground-based IoT remote sensing devices to enhance the accuracy and speed of the
    bushfire detection process. However, it is difficult to judge the effectiveness
    of this work since its results have not been published (e.g., experimental results).
    Moreover, it lacks an effective approach to confront the possible incorrect measurements
    sent by either faulty sensors or illegitimate IoT sensors/attacked sensors (in
    case of a cyber attack on the deployed IoT network). Indeed, any IoT-based approach
    for bushfire detection must be equipped with an effective solution to address
    such threats (atleast publicly accessible forest areas should be protected). Synthesis
    of the Existing Solutions: To the best of our understanding, the current existing
    solutions lack the ability to report the exact location/coordinates of a potential
    fire area in real-time before the fire occurs. In addition, the post-fire solutions
    are not cost effective. Furthermore, we emphasize that due to digitization in
    every domain, the risk of cyber-attack is another factor that might compromise
    the existing techniques to generate a false alert and false negative predictions.
    The existing approaches do not integrally consider approaches to distinguish true
    and false bushfire alerts. In our approach, we utilize a module which enables
    the network to distinguish legitimate and compromised alerts. SECTION III. Our
    Proposed Approach In this section, we present a high level view of our proposed
    approach for bushfire detection. Case 1 (No Fire Danger): In the proposed approach,
    we consider a land/zone where IoT devices or units are deployed taking environmental
    readings, i.e., temperature and humidity. The sensor streams continuously generated
    by IoT units are forwarded to a computing device placed at the edge of the network
    using edge computing technology. The sensor streams collected from the IoT units
    (of a small forest land/zone) are analysed to detect an outlier (see Fig. 1).
    In the absence of any outlier detection, the system considers the zone as no fire
    danger, which means no risk of fire is identified. Here, we have used a natural
    physical phenomenon of data, i.e., the readings of two nearby IoT units would
    be the same under normal conditions. For example, humidity and temperature would
    not change dramatically over short distances. Therefore, we assume that the sensor
    readings or data would be correlated with its neighbors data, with very high probability.
    In this case, there is no spatial correlation between the outliers is detected.
    Contrary if the outlier detection module detects any outlier then the data streams
    are forwarded to a spatial correlation-based recognition module which is an integral
    part of the computing module at the edge of the network. Fig. 1. Proposed system
    architecture. Show All Case 2 (Fire Danger Exists): As mentioned before that in
    the presence of an outlier, the data is forwarded to a spatial correlation module
    to accurately identify the potential risk of fire. If the readings are all in
    the same cluster (no outlier detected at this stage), as expected the framework
    would still consider this scenario as no fire danger. In the case of high fire
    probability, the level of temperature or humidity will increase naturally which
    will be measured by sensors and forwarded to the computing module for analyses.
    In this case, an outlier would be generated. Using this approach of outlier detection,
    the field or zone would be considered as “Fire Danger Zone”. However, this case
    is further divided into three parts. Case 2.1 (False Fire Danger Zone): The sensors
    are mostly deployed in harsh environments. It could be possible that there is
    no fire but the sensor is giving faulty readings. The system could produce outliers
    and the system may consider this scenario as Fire Danger Zone, although it is
    false. Counter Argument. Using the spatial correlation between measurements of
    neighboring IoT sensors we note that in case of a sensor failure, the failed sensor
    will generate faulty data, and thus an outlier will be detected but with a very
    low probability its neighbor sensors also generate faulty measurements as well.
    Thus, the measurements received from its neighbor sensors are not classified as
    outliers as no significant spatial correlation between the measurements is detected.
    Case 2.2 (Compromised Fire Danger Zone): It could also be possible that the sensors
    are compromised and giving fake readings. If there are more outliers, then it
    will be very challenging for the system to differentiate the faulty/false and
    compromised behavior. Counter Argument. We note that in case of a cyber attack
    on the IoT network, several neighboring sensors are targeted by the attacker.
    Therefore, neighbor sensors will also generate faulty measurements. In other words,
    with a very high probability, multiple sensors (located in the neighborhood of
    the malicious node) will also be affected. Thus, a significant spatial correlation
    between the measurements can be observed. In this case, the clustering decisions
    are made based on the possible spatial correlation between the measurements. In
    other words, measurements of all the compromised sensors change rapidly and do
    not follow a location-based and smooth pattern while in case of a true fire, there
    is a smooth pattern in the change of readings received from neighbor sensors over
    time, i.e., the outliers are originated from a particular location and gradually
    propagate to other sensor locations. Now, the next step is to exactly find the
    attacked sensors and their location. To effectively exploit the spatial correlation
    between sensor measurements, we utilize a special mechanism that takes the network
    address (e.g., IP address) of sensors and returns their x and y coordinates. To
    do this, we consider a grid that covers the whole geographical area which is under
    protection. Then, every sensor is assigned with an appropriate x and y coordinate
    based on its physical location. We emphasize that in the case of mobile IoT sensors
    this process can be performed using a dynamic method since the location of a sensor
    may change with respect to time. This can be easily implemented since mobile sensors
    usually send their real-time location data too along with the data streams. Case
    2.3 (True Fire Danger Zone): It can be argued that all sensors in this case may
    generate the same readings and thus a high level of spatial correlation will be
    detected. Counter Argument. We first accept that this is true, however, if we
    increase the land/zone size then it is again highly likely that the readings of
    one zone from another will be different and the outlier will definitely be detected.
    We emphasize that the zone size in this case plays an essential role. Therefore,
    the comparison of different zones or clusters of different zones with each other
    will also provide more accurate insights of potential risk. SECTION IV. Implementation
    and Architecture Details In Fig. 2 we have presented the work-flow of our approach
    which is divided into three phases (particularly based on spatial correlation
    between sensor measurements). The first phase is the preprocessing phase in which
    the data streams from IoT sensors are collected and processed. This phase is performed
    once only during the setup of the IoT network. In the second phase (outlier detection),
    the real-time sensor measurements received from the IoT field network are analysed
    by an ML model to detect an outlier. In the absence of any outlier detection,
    the system considers the IoT field network behavior as normal or No Fire Danger.
    Alternatively, if the system detects any outlier, then the data streams are forwarded
    to a spatial correlation-based recognition module. At this third phase (spatial
    correlation-based classification), the spatial-correlation data of these outliers
    are fed to a classifier in order to accurately classify the detected outliers
    into one of the above mentioned clusters, i.e., False Fire Danger Zone, Compromised
    Fire Danger Zone, and True Fire Danger Zone. Fig. 2. Work-flow of the proposed
    approach. Show All Primarily, we have used the spatial correlation between the
    detected outlier and the measurements of its neighbor sensors to decide on whether
    the outlier is due to a sensor failure or a security attack. We assume that IoT
    humidity and temperature wireless sensors have been already installed in the field
    that effectively covers a target area. The sensor measurements are collected by
    an edge system that is connected to the core system. Regarding the learning model,
    we have used three ML classification algorithms, i.e., classification and regression
    trees (CARTs), random forest (RF), and support vector machine (SVM) at the edge
    segment to detect outliers. In our experiments, we have used the Forest Fire real
    data set [15]. The data set has been created from the meteorological data gathered
    in the northeast region of Portugal over a period of four years. In the next section,
    we present the mathematical modeling of our approach. A. Mathematical Modelling
    As said previously, we utilize the spatial correlation between measurements from
    neighboring sensors to distinguish between a false fire danger detection and a
    true bushfire case. To do this, we have utilized the Moran’s I index [16], [17]
    which is an indicator of spatial correlation in distributed architectures. There
    are global and local versions of the Moran’s I index available. The global version
    indicates the level of spatial correlation over an entire region and is calculated
    as follows: MI= S ∑ S i=1 ∑ S j=1 Δ ij ( m i − m ¯ )( m j − m ¯ ) ∑ S i=1 ∑ S
    j=1 Δ ij ∑ S i=1 ( m i − m ¯ ) 2 View Source where S is the number of measuring
    units (sensors), m i is the value of the desired feature measured by sensor s
    i , and m ¯ is the mean value of feature m . We also need to determine what sensors
    are considered as neighbor. This is applied on the Moran’s I expression using
    the Δ ij weights. For example, if s i and s j are neighbor, then Δ ij =1 , otherwise,
    Δ ij =0 . However, we have adopted a more conservative approach in which Δ ij
    weights are obtained using r ij which is the physical distance between s i and
    s j , i.e., Δ ij = 1 r 2 ij . View Source For the values of MI close to 0, it
    is concluded that there is no spatial correlation in the spatial data set. On
    the other hand, if the absolute value of MI is greater than 0, the global correlation
    of the spatial data set is confirmed. The expected value of the MI index is calculated
    as (−1/S−1) [16], [17]. However, the standardized version of MI is generally used
    to determine the thresholds on which the spatial correlation becomes significant
    in a data set. The global Moran’s I index is standardized to G (MI) as follows:
    G(MI)= MI−Exp(MI) Exp(M I 2 )− (Exp(MI)) 2 − − − − − − − − − − − − − − − − − −
    − − √ . View Source For example, a spatial data set is correlated with a confidence
    level of 95%, if |G| is greater than 1.96. The global Moran’s I index reflects
    the level of spatial correlation over the whole data set. Thus, we use the local
    version of the index to determine the degree of correlation between neighbor sensors
    only. For a specific sensor s i , the local version of the index is calculated
    as follows: MI i = p 2 i = ( m i − m ¯ ) p 2 i ∑ j=1,j≠i S Δ ij ( m j − m ¯ ),where
    ∑ S j=1 Δ ij S−1 − m ¯ 2 . View Source Thus, after an outlier is detected by the
    outlier detection module for sensor s i , the local Moran’s I index MIi is calculated
    for s i to obtain the degree of spatial correlation between s i and its neighbors.
    If the index is close to 0, false fire danger will be reported since in this case,
    there is no correlation between the measurements of s i and its neighbors. In
    other words, it indicates s i is malfunctioning while other sensors are working
    well. However, in case of real fire danger, all the neighbor sensors are generally
    affected by the event. This results in having the measurements of s i and its
    neighbors still spatially correlated. SECTION V. Performance Evaluation In this
    section, we discuss the test settings, experiments results, PoC implementation,
    and a comparison of our approach with three related research works. A. Test Settings
    We have developed a PoC using Python 3.7.4. Two types of workstations were used
    for the experiments: 1) Intel Core i5–11600 2.80-GHz CPU with 8 GB of RAM and
    2) Intel Core i7–7700K @4.20-GHz CPU with 64 GB of RAM. We also used an Android
    mobile device LG G4–H818P equipped with a Hexa–Core 1.8-GHz processor, 3 GB of
    RAM, and running Android OS 5.1, acting as an IoT device. Regarding the IoT network,
    we have used the Eclipse Paho MQTT Python library [23]. The Python code enables
    the MQTT clients and brokers to publish a message and subscribe to a topic and
    receive a published message as well. We use the Forest Fire real data set [15]
    for performance evaluation. The data set has different features, including spatial
    data ( x and y coordinates) and meteorological features, such as temperature and
    relative humidity (see Table I presents the features of the data set.). For the
    outlier detection phase, we have used three ML algorithms, i.e., CARTs, RF, and
    SVM. To model the real fire danger scenario we have added Gaussian noise to the
    measurements of several randomly selected neighbor sensors. TABLE I Description
    of the Forest Fire Data Set In addition, we define R as the percentage of sensors
    that send outlier measurements. We change R from 1% to 5% to see how it affects
    the accuracy of the proposed solution. Furthermore, to evaluate the intensity
    of the outliers, we have changed the level of the injected Gaussian noise by considering
    its standard deviation (sigma) as a percentage of the value of each measurement.
    For this reason, we have changed sigma from 0.2T to 0.5T for temperature outliers
    and from 0.2H to 0.5H for humidity outliers, where T and H are the true measurements
    of temperature and humidity, respectively. Naturally, lower levels of noise result
    in more difficult detection of the relevant outliers. B. Results Figs. 3 and 4
    show the detection accuracy of the three employed ML algorithms for temperature
    and humidity parameters, respectively. As we see in the figures, a higher level
    of the added noise results in higher accuracy, as we expected. Thus, during the
    beginning of a bushfire and considering a fixed value of R , the detection accuracy
    increases over time because the new measurements are distancing from the normal
    expected measurements. This behavior is seen for all the three algorithms. Moreover,
    having a larger value of R results in higher accuracy. This is because in this
    case the data set is more skewed, and therefore a new cluster can be created that
    convinces the classifier algorithms to label it as a separate cluster (i.e., anomaly).
    In addition, the figures show that the CART and RF algorithms perform better than
    the SVM algorithm in terms of detection accuracy. They both give similar performance
    and can detect outliers with the accuracy of as high as 99.4% when 5% of sensors
    generate outliers. However, the SVM algorithm gives the worst performance among
    the three algorithms. Specifically, in case of a lower number of sensors that
    generate outliers (i.e., R=1% or R=2% ), SVM performance is poor in terms of detection
    accuracy. This may result in delayed detections if SVM is employed because it
    needs a higher number of sensors that generate outliers in order to detect a bushfire
    case. Fig. 3. Detection accuracy based on temperature measurements and the percentage
    of sensors who generate outlier measurements (a) CART, (b) RF, and (c) SVM algorithms.
    Show All Fig. 4. Detection accuracy based on humidity measurements and the percentage
    of sensors who generate outlier measurements (a) CART, (b) RF, and (c) SVM algorithms.
    Show All We have also performed the PoC implementation of our approach in two
    different scenarios to evaluate its performance in terms of latency. Fig. 5 shows
    the network structure used in our prototype implementation. First, we performed
    the detection process using an edge server that was located close to the IoT device
    (within the Wifi range). In the second scenario, the procedure was performed by
    a cloud server with a physical distance of 280 km to the IoT field network. We
    used ZeroTier [24] to connect the IoT field network to the cloud server. Moreover,
    PRTG Network Monitor [25] was used to monitor the latency between the IoT devices
    and the servers. Fig. 5. Network structure of our PoC design. Show All Regarding
    the latency between the IoT devices and servers, as Fig. 6(a) and (b) show, the
    proposed approach performs significantly faster in the first scenario in which
    the detection process is done by the edge server. For example, considering the
    packet size of 32B, we obtained the average latency of 19 ms in this case while
    the average latency of 73 ms was obtained in the second scenario in which the
    sensor measurements are sent to a cloud server by the IoT devices where the detection
    procedure is performed. Thus, the detection time of a bushfire can be effectively
    increased by employing several edge servers (each one covers a specific zone in
    the target area) that collect IoT sensor measurements and perform the proposed
    detection approach. The detected events, logs, and performance of the edge servers
    can be monitored in the core segment of the network using a centralized server.
    Fig. 6. Latency report between the IoT device and (a) edge computing server and
    (b) cloud server. Show All We also recorded the end–to–end latency in the detection
    of bushfire symptoms. To emulate the behavior of environmental parameters at the
    early stage of a bushfire (e.g., when temperature and relative humidity are increasing
    and decreasing, respectively), we artificially changed the consecutive sensor
    readings by steps of 20%, 30%, and 50% (see Fig. 7). As we expected, the lowest
    detection time was recorded at the change step of 50%. This indicates that the
    detection time adapts to the spreading speed of fire at its early stage. Moreover,
    the detection latency heavily depends on the time gap between two successive sensor
    readings, i.e., refresh time (in our experiments, we used the refresh time of
    10 s). In fact, to detect an anomaly, there should be a minimum distance between
    two consecutive readings. However, this distance may not be created at a single
    sensor reading (specifically, at low change steps, e.g., 15%). In other words,
    the ML-based anomaly detection model may need to receive a few numbers of successive
    sensor readings before it can detect an anomaly. As Fig. 7 shows, the highest
    level of latency was recorded at the change step of 15% due to the small increase/decrease
    in the measured values. Furthermore, having a large number of sensors ( S ) imposes
    additional processing overhead on the system. This is mainly due to the calculation
    of MI i s for a large number of sensors. Fig. 7. Average end–to–end latency (change
    step w.r.t sensor numbers), time interval between sensor readings was 10 s. Show
    All We performed some experiments to evaluate the system performance in terms
    of distinguishing between a bushfire case and a security attack (see Fig. 8).
    In this regard, we used three different values for the number of victim sensors
    (those who have been successfully compromised by the attacker). This is an important
    factor since the Moran’s I index MI of every outlier depends on the number of
    victim sensors. In other words, if a limited number of sensors are affected by
    the attack, the system obtains a small MI for those sensors (close to 0). In this
    case, the outlier is classified as either a sensor failure (if the obtained MI
    is lower than the first threshold θ 1 ) or a security attack (otherwise). However,
    when a significant number of sensors are affected by the attack, the system obtains
    a large MI because in this case, a large number of sensors are reporting outliers.
    In this case, the calculated MI is compared with the second level of threshold
    to classify the outlier as either a security attack (if the calculated MI is lower
    than the second threshold θ 2 ) or a bushfire (otherwise). Fig. 8. Average accuracy
    of attack detection based on the percentage of victim sensors and the Moran’s
    I index threshold θ 1 . In the experiments, θ 2 has been set to 5. Show All C.
    Comparison Table II shows the results of a comparison between our approach and
    three research works in the field of outlier detection [26]–[28]. For the results
    of our work, we present the average of accuracy and F -score metrics regarding
    the four results achieved using the four different values of sigma when R=1% .
    In [26], an IoT outlier detection architecture is proposed to detect the occurrence
    of anomalies in a forest environment using four different learning algorithms,
    i.e., CART, RF, gradient boosting machine (GBM), and linear discriminant analysis
    (LDA). We only present the best accuracy achieved in [26] (they have achieved
    a low accuracy of 78% using the LDA learning model). As seen in Table II, their
    models have never reached accuracies greater than 97.7% for temperature. For humidity,
    they have achieved the highest level of 99.3%. However, there is no information
    and discussion in the paper about the standard deviation (sigma) of the artificial
    noise added to the data set for outlier generation. In fact, the accuracy will
    increase if we use a higher level of sigma as confirmed by Figs. 3 and 4. TABLE
    II Comparison of Our Approach With Three Research Works in the Field of Outlier
    Detection In [27], the ellipsoidal neighborhood outlier factor (ENOF) mechanism
    [29] has been used to distinguish normal and anomaly measurements. ENOF is an
    outlier detection algorithm in which each data point receives an outlier score
    with respect to the densities of its close neighborhood. Those data points that
    are located in a dense group of data points receive a small score and vice versa.
    The ENOF model also needs to calculate a threshold value using the standard deviation
    of the ENOF scores. This threshold is then used to make anomaly decisions. In
    their work, ISSNIP [30] and IBRL [31] data sets have been used for the experiments
    that include both temperature and humidity measurements. Although the ENOF model
    offers a high level of accuracy, it is still outperformed by our approach (the
    values of F -score metric have not been presented in their work). Furthermore,
    in [28], a modular and hybrid anomaly detection system is proposed for IoT applications.
    It uses a cloud server for anomaly detection in both application and network layers
    and train a centralized learning model. The model weights obtained by the cloud
    server are then transferred to the IoT devices for local anomaly detection. Although
    it offers efficient performance in terms of detection latency, their achieved
    accuracies are still lower than our approach. The reason is that there is a deviation
    between the predictions made by the server and the ones made locally at the IoT
    devices. Furthermore, it requires the local IoT devices to be frequently updated
    by the cloud server. This may increase the communication overhead of the system
    and affects the accuracy. SECTION VI. Further Discussion and Limitations The shown
    approach is simple and effective but there are certain aspects that need to be
    rigorously explored such as: 1) Will the proposed approach truly replace the legacy
    bushfire detection systems? 2) Do we need to deploy the sensors everywhere in
    the forests to detect Bushfires? 3) How to deal with two different verticals (tenants)
    partially using the same IoT deployments but with heterogeneous service requirements?
    We observe that the first two concerns are interlinked and therefore we have to
    address them jointly. First, no solution is best fits in all scenarios therefore
    we need a holistic approach to understand the emergency of the bushfire problem
    before we choose the right solution. Nevertheless, we do not argue that our approach
    will replace the existing solutions, rather we emphasize that it would be beneficial
    to use the proposed approach on top of the existing approaches in an integrated
    way. In view of the second concern, we emphasize that further research is required
    to investigate the modification of IoT-based forest monitoring solutions and identify
    cost-effective architectural solutions for the effective collection of real-time
    environmental data from large forest areas. However, a feasible and more cost-effective
    approach could be to divide the forest area into several smaller zones (i.e.,
    cells). Then, every cell is covered by spreading low-cost sensors which form a
    single wireless sensor network (WSN) in that cell. In fact, every WSN represents
    a small-scale cell that can be replicated in a larger scale to cover the entire
    forest. Each WSN is connected to the main network through one or multiple IoT
    nodes that serve as wireless gateways. This would be a more economic architectural
    solution since the deployment of WSNs is much cheaper than deploying a large number
    of IoT nodes. We do agree that the above solution would still not be fully practical
    and cost-effective. Feasibility still remains an open issue. However, we argue
    that it would be good to identify high fire risk areas first, and then encourage
    land owners (such as, big farm land, forest zone under forest ministry, etc.),
    to allow to deploy the given approach, at highly subsidized rates. Residents living
    nearby potential zones, and emergency fire departments will receive an alert via
    a locally deployed system, respectively, to get prepare in advance. Gradually
    deploying the approach from small scale to large scale zone will eventually strengthen
    the overall effectiveness of the complete bushfire prediction system without replacing
    the legacy system. Towards the third concern, it is arguable to say that the deployment
    of 5G technology and the network slicing concepts within that technology can potentially
    help to achieve multitenants heterogeneous service requirements [32], [33]. However,
    we are still far away with a complete roll out of 5G networks. Thus, this is an
    open challenge, and we need to be cautious with the deployment of the approach
    using legacy telecommunication providers until 5G reaches in regional areas. We
    welcome the research community to collaborate with us to address this critical
    and urgent issue. SECTION VII. Summary and Future Work For early detection of
    bushfire dangers in almost real-time, an approach based on ML and spatial correlation
    between sensor measurements is developed and validated at the edge of the network.
    The proposed mechanism also ensures that if an attacker successfully attacks the
    network (e.g., control sensor communications, manipulate their measurements, etc.),
    the created outliers do not fool the system to generate a false fire alarm. This
    means the proposal accurately shows that either the fire alarm is due to a true
    bushfire danger rather than a sensor failure or a cyber attack. The results of
    our experiments confirmed the merit of our approach. In the future, we intend
    to investigate the design of novel and cost-effective architectural solutions
    to ensure the feasibility of IoT-based approaches in the early detection of bushfire,
    as discussed in the further discussion section. Authors Figures References Citations
    Keywords Metrics More Like This Spatiotemporal Correlation-Based Environmental
    Monitoring System in Energy Harvesting Internet of Things (IoT) IEEE Transactions
    on Industrial Informatics Published: 2019 Device Clustering Algorithm Based on
    Multimodal Data Correlation in Cognitive Internet of Things IEEE Internet of Things
    Journal Published: 2018 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Internet of Things Journal
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Bushfire Risk Detection Using Internet of Things: An Application Scenario'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Li H.
  - Li S.
  - Yu J.
  - Han Y.
  - Dong A.
  citation_count: '5'
  description: With the development of informatization, intelligence and precision
    of modern agriculture, i.e. there is a need for the integration of artificial
    intelligence (AI) with Internet of Things (IoT) systems, which is called AIoT
    (AI + IoT) systems. In this paper, we design an AIoT system for the smart agriculture
    based on the concept of front-rear end separation and the framework of MVVM (Model-View-View
    Model), through which it is possible to handle complex business logic and makes
    the integrating the AI algorithms much easier. Specifically, the system consists
    of a remote data service platform, the data collection terminals build on Raspberry
    Pi and the wireless data transmission using narrow-band Internet of Things (NB-IoT)
    modules. The data service platform is designed with the separated front-end and
    rear-end. The front-end is a web page constructed by the Vue.js and Element, while
    the rear-end business logic processing is constructed using the Python Django
    framework. The data interaction between the front and rear ends is realized through
    Axios. In such a way, the data in the front-end and the rear-end are decoupled,
    which makes it possible to improve the capability in dealing with complex data
    and makes it easy to carry out add-on development and extend new functions. Based
    on the data service platform, a series of basic application functions are integrated,
    including real-time data monitoring, historical data query, data visualization
    and abnormal data alerting, etc. Moreover, we integrate a deep-learning-based
    plant disease and pest detection algorithm in the propose system to show its scalability.
    In addition, the system also combines edge computing technology to improve the
    overall response efficiency of the system. The system has a convenient expansion
    interface and can be used as a basic development platform for various agricultural
    IoT applications, such as the soil environmental monitoring system and the intelligent
    disease and pest monitoring system, etc.
  doi: 10.1145/3512353.3512384
  full_citation: '>'
  full_text: '>

    "This website uses cookies We occasionally run membership recruitment campaigns
    on social media channels and use cookies to track post-clicks. We also share information
    about your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Use the check boxes below to
    choose the types of cookies you consent to have stored on your device. Use necessary
    cookies only Allow selected cookies Allow all cookies Necessary Preferences Statistics
    Marketing Show details       skip to main content University of Nebraska Lincoln
    Browse About Sign in Register Journals Magazines Proceedings Books SIGs Conferences
    People Search ACM Digital Library Advanced Search Conference Proceedings Upcoming
    Events Authors Affiliations Award Winners HomeConferencesAPITProceedingsAPIT ''22AIoT
    Platform Design Based on Front and Rear End Separation Architecture for Smart
    Agricultural RESEARCH-ARTICLE SHARE ON AIoT Platform Design Based on Front and
    Rear End Separation Architecture for Smart Agricultural Authors: Hang Li , Sufang
    Li , Jiguo Yu , Yubing Han , + 1 Authors Info & Claims APIT ''22: Proceedings
    of the 2022 4th Asia Pacific Information Technology ConferenceJanuary 2022Pages
    208–214https://doi.org/10.1145/3512353.3512384 Published:14 March 2022Publication
    History 1 citation 160 Downloads View all FormatsPDF APIT ''22: Proceedings of
    the 2022 4th Asia Pacific Information Technology Conference AIoT Platform Design
    Based on Front and Rear End Separation Architecture for Smart Agricultural Pages
    208–214 Previous Next ABSTRACT References Cited By Recommendations Comments ABSTRACT
    With the development of informatization, intelligence and precision of modern
    agriculture, i.e. there is a need for the integration of artificial intelligence
    (AI) with Internet of Things (IoT) systems, which is called AIoT (AI + IoT) systems.
    In this paper, we design an AIoT system for the smart agriculture based on the
    concept of front-rear end separation and the framework of MVVM (Model-View-View
    Model), through which it is possible to handle complex business logic and makes
    the integrating the AI algorithms much easier. Specifically, the system consists
    of a remote data service platform, the data collection terminals build on Raspberry
    Pi and the wireless data transmission using narrow-band Internet of Things (NB-IoT)
    modules. The data service platform is designed with the separated front-end and
    rear-end. The front-end is a web page constructed by the Vue.js and Element, while
    the rear-end business logic processing is constructed using the Python Django
    framework. The data interaction between the front and rear ends is realized through
    Axios. In such a way, the data in the front-end and the rear-end are decoupled,
    which makes it possible to improve the capability in dealing with complex data
    and makes it easy to carry out add-on development and extend new functions. Based
    on the data service platform, a series of basic application functions are integrated,
    including real-time data monitoring, historical data query, data visualization
    and abnormal data alerting, etc. Moreover, we integrate a deep-learning-based
    plant disease and pest detection algorithm in the propose system to show its scalability.
    In addition, the system also combines edge computing technology to improve the
    overall response efficiency of the system. The system has a convenient expansion
    interface and can be used as a basic development platform for various agricultural
    IoT applications, such as the soil environmental monitoring system and the intelligent
    disease and pest monitoring system, etc. References C. Brewster, I. Roussaki,
    N. Kalatzis, K. Doolin, K. Ellis, Iot in agriculture: Designing a europe-wide
    large-scale pilot, IEEE Communications Magazine55 (9) (2017) 26–33. Y. E. Duan,
    Design of Intelligent Agriculture Management Information System Based on IoT,
    IEEE, 2011. M. A. P. Utomo, A. Aziz, Winarno, B. Harjito, Server room temperature&
    humidity monitoring based on internet of thing (iot), Journal of Physics: Conference
    Series 1306 (2019) 012030–. Show All References Cited By View all Doychev E, Terziyski
    A, Tenev S, Stoyanova-Doycheva A, Ivanova V and Atanasova P. (2023). Architecture
    and Data Knowledge of the Regional Data Center for Intelligent Agriculture. Information.
    10.3390/info14040233. 14:4. (233). https://www.mdpi.com/2078-2489/14/4/233 Recommendations
    Home Edge Computing Architecture for Smart and Sustainable Agriculture and Breeding
    NISS ''19: Proceedings of the 2nd International Conference on Networking, Information
    Systems & Security Challenges of today and tomorrow in developing countries to
    ensure sustainable food security for their populations require smart agriculture
    and breeding. This necessarily depends on water control, soil erosion, livestock
    management, and so on. At the ... Read More Blockchain-Enabled Smart Agricultural
    Knowledge Discovery System using Edge Computing Abstract Blockchain empowered
    agricultural knowledge discovery system provides the secured environment for the
    people to store and exchange agricultural data. The integration of the Internet
    of Things (IoT), blockchain technology, and edge computing ... Read More Recent
    trends of smart agricultural systems based on Internet of Things technology: A
    survey Abstract Internet of Things (IoT) technology can be used to enhance traditional
    approaches by combining advanced technologies with sophisticated methodologies
    aiming to boost agricultural production quality and quantity. The global population
    ... Graphical abstract Display Omitted Read More Comments 15 References View Table
    Of Contents Footer Categories Journals Magazines Books Proceedings SIGs Conferences
    Collections People About About ACM Digital Library ACM Digital Library Board Subscription
    Information Author Guidelines Using ACM Digital Library All Holdings within the
    ACM Digital Library ACM Computing Classification System Digital Library Accessibility
    Join Join ACM Join SIGs Subscribe to Publications Institutions and Libraries Connect
    Contact Facebook Twitter Linkedin Feedback Bug Report The ACM Digital Library
    is published by the Association for Computing Machinery. Copyright © 2024 ACM,
    Inc. Terms of Usage Privacy Policy Code of Ethics"'
  inline_citation: '>'
  journal: ACM International Conference Proceeding Series
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: AIoT Platform Design Based on Front and Rear End Separation Architecture
    for Smart Agricultural
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Gadiraju K.K.
  - Chen Z.
  - Ramachandra B.
  - Vatsavai R.R.
  citation_count: '0'
  description: 'Detecting changes in real-time using remote sensing data is of paramount
    importance in areas such as crop health monitoring, weed detection, and disaster
    management. However, real-time change detection using remote sensing imagery faces
    several challenges: a) it requires real-time data extraction which is a challenge
    for traditional satellite imagery sources such as MODIS and LANDSAT due to the
    latency associated with collecting and processing the data. Due to the advances
    made in the past decade in drone technology, Unmanned Aerial Vehicles (UAVs) can
    be used for real-time data collection. However, a large percentage of this data
    will be unlabeled which limits the use of well-known supervised machine learning
    methods; b) from an infrastructure perspective, the cloud-edge solution of processing
    the data collected from UAVs (edge) only on the cloud is also constrained by latency
    and bandwidth-related issues. Due to these limitations, transferring large amounts
    of data between cloud and edge, or storing large amounts of information regarding
    past time periods on an edge device is infeasible. We can limit the amount of
    data transferred between the cloud and edge by performing analyses on-the-fly
    at the edge using low-power devices (edge devices) that can be connected to UAVs.
    However, edge devices have computational and memory bottlenecks, which would limit
    the usage of complex machine learning algorithms. In this paper, we demonstrate
    how an unsupervised GMM-based real-time change detection method at the edge can
    be used to identify weeds in real-time. We evaluate the scalability of our method
    on edge computing and traditional devices such as NVIDIA Jetson TX2, RTX 2080,
    and traditional Intel CPUs. We perform a case study for weed detection on images
    collected from UAVs. Our results demonstrate both the efficacy and computational
    efficiency of our method.'
  doi: 10.1109/ICMLA55696.2022.00130
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 21st IEEE International ... Real-Time
    Change Detection At the Edge Publisher: IEEE Cite This PDF Krishna Karthik Gadiraju;
    Zexi Chen; Bharathkumar Ramachandra; Ranga Raju Vatsavai All Authors 145 Full
    Text Views Abstract Document Sections I. Introduction II. Review of Literature
    III. Gaussian Mixture Models (GMM) IV. Methodology V. Experiments Show Full Outline
    Authors Figures References Keywords Metrics Footnotes Abstract: Detecting changes
    in real-time using remote sensing data is of paramount importance in areas such
    as crop health monitoring, weed detection, and disaster management. However, real-time
    change detection using remote sensing imagery faces several challenges: a) it
    requires real-time data extraction which is a challenge for traditional satellite
    imagery sources such as MODIS and LANDSAT due to the latency associated with collecting
    and processing the data. Due to the advances made in the past decade in drone
    technology, Unmanned Aerial Vehicles (UAVs) can be used for real-time data collection.
    However, a large percentage of this data will be unlabeled which limits the use
    of well-known supervised machine learning methods; b) from an infrastructure perspective,
    the cloud-edge solution of processing the data collected from UAVs (edge) only
    on the cloud is also constrained by latency and bandwidth-related issues. Due
    to these limitations, transferring large amounts of data between cloud and edge,
    or storing large amounts of information regarding past time periods on an edge
    device is infeasible. We can limit the amount of data transferred between the
    cloud and edge by performing analyses on-the-fly at the edge using low-power devices
    (edge devices) that can be connected to UAVs. However, edge devices have computational
    and memory bottlenecks, which would limit the usage of complex machine learning
    algorithms. In this paper, we demonstrate how an unsupervised GMM-based real-time
    change detection method at the edge can be used to identify weeds in real-time.
    We evaluate the scalability of our method on edge computing and traditional devices
    such as NVIDIA Jetson TX2, RTX 2080, and traditional Intel CPUs. We perform a
    case study for weed detection on images collected from UAVs. Our results demonstrate
    both the efficacy and computational efficiency of our method. Published in: 2022
    21st IEEE International Conference on Machine Learning and Applications (ICMLA)
    Date of Conference: 12-14 December 2022 Date Added to IEEE Xplore: 23 March 2023
    ISBN Information: DOI: 10.1109/ICMLA55696.2022.00130 Publisher: IEEE Conference
    Location: Nassau, Bahamas SECTION I. Introduction The past decade has seen a rapid
    rise in the amount of spatiotemporal data being collected due to the improvements
    in the fields of Internet of Things (IOT) and sensor technologies. According to
    the IDC [1], the amount of data collected globally is expected to increase to
    175 Zettabytes by 2025. Nearly 70% of this data is expected to be processed at
    the edge [2]. This rapid rise in data has been complemented by the development
    of Machine Learning (ML) methods for performing a variety of tasks such as Land
    Use Land Cover (LULC) classification and change detection (CD). In this paper,
    we will focus on change detection (CD). CD focuses on identifying relevant changes
    across time from different imagery for the same location. CD methods are used
    to identify changes to help with disaster management [3], biomass monitoring [4]
    and studying urban mobility [5], [6]. CD approaches can be distinguished in terms
    of data, methodology and the necessary infrastructure required for deploying the
    methods. Due to the size of remote sensing data and the computational complexity
    of most CD approaches, they are typically implemented in cloud/HPC architectures.
    However, in domains such as disaster management, agriculture (weed detection,
    crop health monitoring), and security, where delay in collection and analyses
    of data can cause severe losses, real-time analysis becomes crucial. As a result,
    we require real-time CD methods. The traditional cloud computing (or HPC) approach
    is less suitable [7] for real-time CD due to challenges such as latency, bandwidth-dependency
    and availability of a reliable internet connection [2]. As described in [8], the
    task of offloading the data into cloud systems for data analysis increases communication
    costs and exacerbates latency. In contrast, recent developments in embedded GPU-based
    devices such as NVIDIA Jetson (TX1/2), small powerful edge computers such as Lenovo
    Tiny and single board computers (SBCs) such as Raspberry Pi can perform computations
    closer to the edge of the network. This provides real-time insights to the stakeholder.
    This also lowers the amount of data transferred between cloud and edge, thereby
    overcoming the bandwidth and latency related issues. Examples of real-time change
    detection applied at the edge include: disaster management [9], [10], smart agriculture
    [11] and surveillance [12]. In this paper, we focus on modeling detection of weeds
    as a CD problem. According to [13], weeds impede the growth of crops and reduce
    the productivity of crops such as cotton by nearly 30%. As a result, early detection
    of weeds is important for mitigating their impact and improving crop yield. There
    are several approaches to weed detection using machine learning. Classifying images
    as weeds-vs-regular crops is one approach. However, it requires large amounts
    of labeled data. Building large datasets that cover the entire spectrum of different
    types of weeds found in crops is a challenging affair. An alternative approach
    is to treat detection of weeds as a CD problem. In this approach, the assumption
    is that images at an initial time T0 do not have weeds, while images at an arbitrary
    time T1 may have weeds. The changes found by the CD method at time T1 can be treated
    as potential weeds. In the next section, we discuss challenges associated with
    real-time CD at the edge. A. Challenges With Real-Time CD at the Edge While real-time
    CD at the edge has its appeal for obtaining key insights quickly, due to their
    small size and low power requirements, edge devices have limited computational
    and memory resources. Storing vast amounts of data (such as images of a field
    from earlier times for comparison) or using computationally expensive ML methods
    such as deep learning methods may not be feasible. In addition, while vast amounts
    of remote sensing data is collected daily, only a small fraction of this is labeled.
    This is further exacerbated due to geographical and multi-temporal variability
    associated with agricultural imagery. As a result, complex supervised deep learning
    approaches are infeasible to be applied for CD at the edge. We discuss this in
    further detail in Section II. We describe our contributions in the following section.
    B. Our Contributions We propose a computationally efficient GMM-based approach
    for CD. We address the limitations of existing CD approaches and reduce the communication
    and memory overhead between the cloud and edge by caching the initial GMM model
    parameters at time T0 computed on the cloud on the edge device. At time T1, for
    each patch of the field collected by a UAV, we compute GMM parameters and calculate
    the distance the the GMM parameters at time T0 to identify change. We perform
    scalability studies and compare the performance of the edge device with that of
    conventional CPUs and GPUs. Our method is an unsupervised learning method. As
    a result, it does not suffer with the challenges of limited training data when
    compared to the supervised learning methods. While we demonstrate the unsupervised
    learning solution for weed detection, our idea can be extended to other domains
    such as disaster management. We discuss relevant literature in the following section.
    SECTION II. Review of Literature Since edge computing is a more recent development,
    quite clearly, most CD efforts have been never been evaluated on the edge computing
    devices. A comprehensive review of both CD and edge computing methods is beyond
    the scope of this paper. We focus on the key literature from both the areas. We
    divide the relevant literature into two categories: methods that are either computationally
    expensive or require data from previous timestamps (and thereby are not suitable
    for the edge) and methods that are edge computing-based. A. Compute/Storage Intensive
    Approaches Most CD methods typically involve finding the difference between images
    from two (or more) time steps. Traditional CD methods such as image rationing
    [14] and change vector analysis are pixel-based and demonstrated comparable results
    on low resolution imagery. However, they are inefficient in detecting changes
    in high resolution imagery [15], since they do not consider neighborhood relationships.
    They are also computationally expensive to apply to high resolution imagery. Methods
    that consider the autocorrelations (either spatial or temporal) include sliding-window
    based approaches [15]. Some recent deep learning-based developments include: (a)
    Siamese network-based supervised [16], [17], (b) GAN-based unsupervised [18]–[20]
    and semi-supervised [21] methods. However, these methods have two limitations:
    (i) they do not work in near real-time situations (or on the fly such as drones)
    where there is no ground-truth for the current time-step; (ii) they do not work
    well due to high computational and memory requirements. In addition, they also
    require storage of all the data from both the time steps to detect change (such
    as [16]–[20]). As a result these methods can be ineffective on edge devices. Our
    proposed GMM-based solution on the other hand, only requires the GMM parameters
    to be stored at the edge. This ensures that only a small amount of information
    needs to be transferred from the cloud to the edge (and only once). The advantages
    to this are two fold: (a) first, there is limited communication between the cloud
    and the edge (b) second, the entire image of the previous time step or complex
    models need not be stored on the edge device which has limited memory. B. Edge-Relevant
    Methods We discuss methods that are comparatively computationally less expensive,
    or are designed for the edge. The past decade has seen a rapid rise in research
    edge-based ML such as anomaly detection [7], weed detection [22], disaster management
    [23] and surveillance [7]. These methods are either supervised or unsupervised,
    with key differences in the underlying algorithms, how the edge devices are utilized,
    and the application area. Some notable supervised learning based approaches include:
    resource-efficient methods that project data into a lower dimensional space such
    as [24], [25], anomaly detection methods [26] and neural network-based approaches
    [27]. As discussed earlier, the lack of sufficient labeled data makes using supervised
    learning approaches a challenge in the domain of agriculture. [7] developed a
    K-Means and C-Means clustering based anomaly detection solution to identify temporal
    anomalies in underground mining data. In contrast, our work focuses on building
    a GMM-based solution for image data for near real-time change detection. In addition,
    the K-Means algorithm can be considered a special case of GMM. There is clear
    evidence that GMM is an effective method to be applied to edge computing. [28]
    developed an embedded approach for counting people on an edge computing device.
    They use GMM purely for foreground-background separation and don’t make full use
    of the representational ability of GMM like we do. [29] demonstrated a low-power
    novelty detection solution using GMM that involves sharing of GMM parameters between
    cloud, fog and edge layer devices and using these parameters for novelty/anomaly
    detection. [29] uses the computed means and covariances and statistical measures
    to calculate point anomalies in time series data. In contrast, the focus in this
    paper is on image data, where we compare the computed means and covariances of
    the images at time T0 and time T1. In addition, [29] assumes fixed number of components
    in the GMM while our approach automates finding the optimal number of components.
    In the agriculture domain, [30] builds a solution for navigation of agricultural
    robots using deep learning to improve the initial segmentation tasks. Then, they
    build a Hough transform method to develop a path for the robots. However, the
    deep learning tasks are computed on a high-compute Tesla K80 GPU and are not evaluated
    on an edge device. In the area of weed detection, [22] demonstrate a low-power
    FPGA-accelerated binarized supervised deep neural networks-based solution for
    detecting weeds. In contrast to this supervised approach, our approach is an unsupervised
    CD solution. Next, we discuss GMM clustering and relevant literature for finding
    the optimal number of clusters in a GMM. SECTION III. Gaussian Mixture Models
    (GMM) GMM is a probabilistic generative model that assumes that the data is generated
    from a linear combination of a finite number of Gaussian distributions. Given
    a d-dimensional dataset X = x1, x2,…, xn with n observations: GMM= ∑ k i=1 ϕ i
    N( μ i , Σ i ) , where k represents the number of unique components, µi and i
    are the mean and covariance matrix of the ith mixture (multivariate normal distribution)
    and ϕi is its weight. The parameters θi = (ϕi, µi, Σi) are estimated using the
    Expectation-Maximization (EM) algorithm [31]. Several solutions estimate the optimal
    number of mixture components in a GMM. In the model-based clustering approach
    [32], first GMM clustering on the data is performed for different values of k.
    One can then use Akaike and Bayesian Information Criterion (AIC/BIC) for scoring
    the GMM model based on its log-likelihood and complexity. For example, a GMM with
    k components is optimal for which its BIC is maximum. In contrast, X-Means clustering
    [33] begins with a minimum number of clusters and splits each cluster if its BIC
    improves. This action is repeated until a user-defined maximum number of clusters
    is reached. GMeans [34] and GXMeans [35] are limited by their underlying statistical
    tests. GMeans uses the Anderson-Darling test ( good only when the number of samples
    is ≤ 25 [35]), while the GXMeans method uses Shapiro-Wilk Test (good only when
    the number of samples is ≤ 5000). In short, they both tend to split large clusters.
    This could incur high computational and memory overhead with remote sensing imagery
    where one can have several thousands of points in a cluster. While the merge step
    in GX-Means can combine such split clusters, this introduces additional computational
    overhead. As a result, we use the model-based clustering approach for finding
    the optimal k. SECTION IV. Methodology The central idea behind this paper is to
    detect change by comparing representations of two images instead of comparing
    them directly. Comparing representations of the images reduces the amount of information
    stored regarding earlier image patches. While [15] considers each patch as a multivariate
    Gaussian, this approaches can only consider small patches since larger patches
    could contain heterogeneous components and violate the single Gaussian assumption.
    In contrast, in this paper, each image (patch) is treated as a GMM. This ensures
    that even if the image (patch) contains multiple components (such as soil, vegetation,
    built-up area etc.), they are identified as separate components in the GMM. In
    the next section, we describe our framework. A. Framework Figure 1 illustrates
    the idea behind the CD framework proposed in this paper. Consider two images of
    a region R at two different time periods T0 and T1. At T0, we perform GMM clustering
    on the entire image of the field on the cloud, and obtain the GMM model denoted
    as GM M 0 = ∑ M i=1 ϕ 0 i N( μ 0 i , Σ 0 i ) . We assume that there are no weeds
    at T0. At T1, imagine a drone flying over the same region. Since drones cannot
    capture the entire region R in one shot, we define a patch size to simulate the
    smaller region captured. We perform GMM clustering on-the-fly on this patch (denoted
    as Pj to represent the j-th patch in R) on an edge computing device such as Jetson
    TX2 and obtain the GMM model denoted as GM M 1j = ∑ M i=0 ϕ 1j i N( μ 1j i , Σ
    1j i ) . It should be noted here that in order to perform a comparison, we do
    not need to store the entire image at T0 on the edge. We only need to store the
    GMM0 model parameters. This ensures minimum memory usage, as well as minimum communication
    between cloud and edge. Upon computing the GMM parameters for Pj, we compute the
    distance dj between GMM0 and GMM1j using methods described in Section IV-A1. Then,
    CD can be performed using the computed distances using methods described in Section
    IV-A2. It should also be noted that because we perform GMM clustering on smaller
    patches at time T1 on the edge, computational and memory limitations do not arise.
    In Section V, we perform scalability experiments to test the memory limitations
    of our method. 1) Comparing two GMMs Majority of the research in this area is
    focused on developing KL-Divergence (KLD) based approximations for estimating
    the similarity between two GMMs [36]–[39]. Other notable works include optimal
    transport-based [40] methods. KLD [41] is a statistical method used to measure
    the similarity between two probability distributions. While a closed form solution
    exists to estimate the KLD between two Gaussian distributions (KLD between two
    Gaussian distributions was used for CD in [15]), computing the KLD between two
    GMMs is not an analytically tractable solution. [42] provides a GMM-based solution
    for CD in Synthetic Aperture Radar (SAR) images. However, they use the computationally
    intensive Monte Carlo-based sampling to compute the similarity between the two
    GMMs. In the following section, we describe solutions for approximating the KL-Divergence
    between two GMMs. Gaussian Approximation (GA) [37] approximates (reduces) each
    GMM into a Gaussian Distribution with mean and covariance as: q l =N( ∑ M i=1
    ϕ l i μ l i , ∑ M i=1 ϕ l i ( Σ l i +( μ l i − ∑ M i=1 ϕ l i μ l i ) ( μ l i −
    ∑ M i=1 ϕ l i μ l i ) T ))) where l = 0 for GMM0 and l = 1j for GMM1j. Then the
    distance between GMM0 and GMM1j is reduced to the distance between their Gaussian
    approximations q0 and q1j. This is computed using the symmetric KLD (DKL) between
    the q0 and q 1j : d GA j (GM M 0 ,GM M 1j )= D KL ( q 0 , q 1j ) . The symmetric
    KLD between two distributions P and Q is defined as DKL = KLD(P ||Q) + KLD(Q||P
    ) where KLD(P ||Q) represents the KL-Divergence. Fig. 1: GMM-based CD at the Edge
    Show All Matching-Based Approximation (MA) [39]: In this approach, for each Gaussian
    component in a GMM, we find the corresponding nearest Gaussian component (i.e.,
    matching component) in the other GMM (based on KL-Divergence (KLD)). The final
    distance is the weighted combination of all the minimum distances to the nearest
    components. This is mathematically summarized as: d MA j (GM M 0 ,GM M 1j )= ∑
    M i=1 ϕ 0 i min j (KLD(N( μ 1j j , Σ 1j j )||N( μ 0 i , Σ 0 i ))+log ϕ 0 i ϕ 1j
    j )|| 2) Change Detection We identify that change has occurred if dj(GMM0, GMM1j)
    ≥ t where t is an expert-defined threshold. SECTION V. Experiments 3 categories
    of devices are used: a) edge-based GPU: NVIDIA Jetson TX2 is an embedded AI computing
    GPU device (256 CUDA cores, 8 GB memory); b) conventional GPU: NVIDIA RTX 2080
    GPU (2944 CUDA cores, 8 GB GPU memory); c) conventional CPU: Intel i7-7700HQ processor.
    We evaluate our method on two images of the same field taken from the UAV Sugarbeets
    2015-16 Dataset1. The images are overhead imagery taken at different times. The
    images were recorded using a Zenmuse X3 camera with a resolution of 4, 000×2,
    250 pixels. From Figure 2, we can see a different growing pattern around the middle
    of the field. We assume this to be the change we should be detecting. Fig. 2:
    Change Detection Results on the Sugarbeets Dataset Show All A. Experiments and
    Results In this section, we discuss the experiments conducted to evaluate our
    solution. Given the computational and memory requirements of the GMM-EM procedure,
    typically the entire image (patch) is not used for learning the GMM parameters.
    Instead, we divide the image (patch) into a grid and randomly sample a small percentage
    of pixels from each grid. The initial parameters for the GMM are estimated by
    first performing KMeans clustering on the extracted samples. In each experiment,
    the EM algorithm either terminates when the log-likelihood between successive
    iterations is below the threshold of 1e − 3 or until 2000 iterations are completed.
    Fig. 3: Change Detection Results on the Sugarbeets Dataset Show All We use the
    model-based approach for computing the optimal number of GMM components. When
    performing GMM clustering on the cloud for T0, we perform model-based clustering
    for a maximum of 8 components (chosen based on a visual inspection of the image).
    The image at T0 is divided into a 16 × 16 grid and 10% pixels are randomly chosen
    from each grid. The GMM parameters are then cached on the edge device. Scalability
    Evaluation The two major components of the CD framework are the model-based clustering
    and distance computation. Since model-based clustering is the computationally
    expensive operation, we first study its scalability in terms of increasing patch
    size. 10% of the pixels from each 16×16 grid within the patch is sampled for estimating
    the GMM parameters using the EM algorithm. In order to understand the importance
    of using a GPU, we compare the results to both sequential and multi-threaded implementations
    on a CPU. For each patch size, the experiment is performed 200 times and the average
    execution time is noted. Figure 4a plots the patch size (in mb, x-axis) vs represents
    the execution time (seconds, y-axis) . We can first observe linear trend in execution
    time for all the approaches as the patch size increases. Next, we observe that
    the RTX 2080, which is the best in terms of computation and memory capacity performed
    the best, as expected. We can also observe that the edge device performs comparably
    to a single threaded (sequential) CPU implementation in terms of execution times.
    In order to study the scalability of each device, we compare the increase in execution
    times between the smallest patch (64 × 64 pixels) versus the largest patch (2048
    × 2048 pixels) i.e., a 1024x increase in size. The execution time of the Jetson
    TX2 increases by ~ 23.8x and that of the RTX 2080 increases by ~ 25.2x. However,
    single-threaded CPU (~ 114.4x) and multi-threaded CPU (~ 90.4x) both demonstrate
    a significantly higher increase in execution times. We can observe that edge GPU
    scales much better in comparison to the traditional CPU and has comparable scaling
    with the traditional GPU. Despite a 1024x increase in image size, execution time
    did not increase at the same scale indicating the scalability of our solution.
    Since both GA and MA methods for distance computation are computed only using
    the GMM parameters of T0 and T1, there is no noticeable increase in execution
    time with corresponding to patch size. Distance computation using GA is faster
    than MA, since MA requires KLD computation between every pair of components, while
    GA has a single KLD computation. Fig. 4: Scalability results and Synthetic Image
    Show All CD Evaluation between T0 and T1 We evaluate both the GA and MA methods
    by first comparing the CD outcomes between T0 and T1. As described in Section
    IV-A, we first perform model-based GMM-EM at time T0. Then, we perform model-based
    GMM-EM for each 256 × 256 image patch extracted from the image at time T1. As
    described earlier, extraction of these patches emulates a drone flying over the
    field. The maximum number of clusters to be searched using the model-based approach
    for each patch is set to to 6. In addition, as demonstrated in Figure 4a, computing
    the GMM parameters for a 256 × 256 patch takes very little time. As a result,
    the distance computation can occur on the fly while the drone flies over the field.
    Figure 3 (a),(b) show the distance maps. We can immediately see that the middle
    region of the image at T1 where we wish to detect a change has different distance
    values in comparison to the rest of the image. By defining a threshold value tGA
    = 9.5 and tMA = 7.3, the corresponding change masks can be visualized. Figure
    3 (c), (d) demonstrate the change regions identified by our framework. While GA
    and MA both identify the central region as change, MA doesn’t identify differences
    due to shadow as change. CD Evaluation On a Synthetic Dataset Given the lack of
    labeled data, we evaluated our method on a synthetic image. This image was created
    by randomly replacing sections of the image from T0 with patches from T1. The
    synthetic image can be seen in Figure 4b. The regions of change are shown using
    a black bounding box, while the regions of no-change due to natural growth are
    shown using the yellow bounding box. Figures 5 (a)-(d) show the results of CD
    on this image. Firstly, it can be observed from the distance maps that the synthetic
    regions of actual change have a greater distance from the previous GMM parameters
    in comparison to the synthetic regions of no-change. This clearly indicates the
    ability of our solution to clearly distinguish between actual changes and vegetation
    based changes. The change maps after applying the threshold also clearly show
    that our approach is able to identify the relevant regions of change. Fig. 5:
    Change Detection Results on the Synthetic Dataset Show All SECTION VI. Conclusions
    and Future Work In this paper, we demonstrated a computationally efficient change
    detection (CD) solution for the edge. By caching only the GMM parameters of the
    previous time step instead of entire images, our solution reduces the memory requirements
    and ensures minimal communication between the cloud and edge. We evaluated the
    scalability of our approach on an edge GPU, a traditional CPU and a traditional
    GPU. Our experiments show that the edge device has comparable performance to a
    traditional CPU, and scales better than a traditional CPU. Finally, we demonstrated
    visually that our method detects changes in an unsupervised manner ( Figures 3
    and 5). Our unsupervised CD approach can similarly be applied to disaster management
    to get initial estimates in real-time. ACKNOWLEDGMENT We thank the STAC lab members
    at NCSU, and Jaime E. Puente, Cassidy Lammers and Mike Leach at Lenovo. We greatly
    appreciate the research funding provided by the NSF funded IUCRC Center for Accelerated
    Real Time Analytics (CARTA). We thank Dr. Rada Chirkova for critical inputs to
    this research and Dr. Frank Mueller for access to ARC cluster. Authors Figures
    References Keywords Metrics Footnotes More Like This Machine Learning Algorithms
    for Satellite Image Classification Using Google Earth Engine and Landsat Satellite
    Data: Morocco Case Study IEEE Access Published: 2023 Prediction of FBC Boiler
    Efficiency using Machine Learning Algorithm 2022 IEEE International Power and
    Renewable Energy Conference (IPRECON) Published: 2022 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 21st IEEE International Conference on Machine Learning and
    Applications, ICMLA 2022
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-Time Change Detection at the Edge
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kummar S.
  - Bhushan B.
  citation_count: '0'
  description: The unprecedented growth of population in urban areas has been causing
    a challenge for the citizens in their day-to-day lives such as road congestion,
    public security, environmental pollution, electricity shortage and water shortage.
    To control and resolve all these issues, new technologies have been developed
    for smart cities. Intelligent services and better applications are deployed in
    smart cities, by combining the Internet of Things (IoT) with the technologies
    like data mining (DM) and deep learning (DL). Many sectors like healthcare, governance,
    agriculture and public safety can increase their efficiency with the help of these
    new technologies and can convert these into smart applications for smart cities.
    Different kinds of computing like edge computing, fog computing and cloud computing
    support to provide better insights into analytics with the help of big data in
    smart cities. All these technologies are transforming or raising healthcare ecosystems,
    leading them in the direction of smart healthcare. This permits surgeons to get
    real-time data of their patients distantly with the help of wireless communication.
    Smart healthcare is established on new technologies to convey enriched and valued
    healthcare facilities for patients. This chapter explores the current challenges
    that are faced during the indigenous development of the smart cities. Furthermore,
    the chapter discusses the theoretical background of smart cities with the explanation
    of their components. Moreover, the chapter describes the necessity of computational
    infrastructure for smart cities in a framework of big data and DM. The chapter
    highlights some mining methods for extracting important information from huge
    and mixed data. Additionally, the chapter examines the advancement of healthcare
    sector in smart cities in context of big data and DM.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: 'The Internet of Medical Things: Enabling technologies and emerging applications'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Big data analytics and data mining for healthcare and smart city applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Lakshmi P.
  - Rejith G.
  - Toby T.
  - Sai Shibu N.B.
  - Rao S.N.
  citation_count: '5'
  description: An increasing number of natural and artificially induced disasters
    shows the need for rapid disaster management methods backed by a reliable communication
    infrastructure and data source. Disasters bring losses to human life, livestock,
    properties and habitat. Building collapse is one of the disasters that predominantly
    endanger the local population. A proper rapid disaster management mechanism can
    cut down postdisaster damages. During a disaster, natural or otherwise, the Internet
    of Things (IoT) can play a crucial, potentially life-saving role. IoT systems
    support disaster management operations such as prevention, preparation, response
    and recovery phases. This paper summarises the existing IoT systems designed for
    disaster management and rescue operations. This paper proposes a fog computing
    and UAV-based IoT network architecture to combat the problems associated with
    frequent disasters focusing on collapsed buildings. The proposed architecture
    assists rescuers by integrating IoT sensors and UAVs data with the status of infrastructures.
    The architecture supports the rescuers by providing real-time data by analyzing
    disasters and facilitating disaster search and rescue operations. The paper also
    proposes a communication system with Lora mesh to transmit critical information
    to the base station during post-disaster situations. It presents the results from
    a prototype implementation of the proposed architecture in the Google Cloud Platform.
  doi: 10.1109/WiSPNET54241.2022.9767132
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 International Conference... A Resilient
    IoT System Architecture for Disaster Management in Collapsed Buildings Publisher:
    IEEE Cite This PDF Lakshmi P; Gopika Rejith; Tom Toby; Sai Shibu N. B.; Sethuraman
    N. Rao All Authors 2 Cites in Papers 297 Full Text Views Abstract Document Sections
    I. Introduction II. Related Work III. Proposed System Architecture IV. Results
    and Discussions V. Conclusion Authors Figures References Citations Keywords Metrics
    Abstract: An increasing number of natural and artificially induced disasters shows
    the need for rapid disaster management methods backed by a reliable communication
    infrastructure and data source. Disasters bring losses to human life, livestock,
    properties and habitat. Building collapse is one of the disasters that predominantly
    endanger the local population. A proper rapid disaster management mechanism can
    cut down postdisaster damages. During a disaster, natural or otherwise, the Internet
    of Things (IoT) can play a crucial, potentially life-saving role. IoT systems
    support disaster management operations such as prevention, preparation, response
    and recovery phases. This paper summarises the existing IoT systems designed for
    disaster management and rescue operations. This paper proposes a fog computing
    and UAV-based IoT network architecture to combat the problems associated with
    frequent disasters focusing on collapsed buildings. The proposed architecture
    assists rescuers by integrating IoT sensors and UAVs data with the status of infrastructures.
    The architecture supports the rescuers by providing real-time data by analyzing
    disasters and facilitating disaster search and rescue operations. The paper also
    proposes a communication system with Lora mesh to transmit critical information
    to the base station during post-disaster situations. It presents the results from
    a prototype implementation of the proposed architecture in the Google Cloud Platform.
    Published in: 2022 International Conference on Wireless Communications Signal
    Processing and Networking (WiSPNET) Date of Conference: 24-26 March 2022 Date
    Added to IEEE Xplore: 09 May 2022 ISBN Information: DOI: 10.1109/WiSPNET54241.2022.9767132
    Publisher: IEEE Conference Location: Chennai, India SECTION I. Introduction Globally,
    billions of people have been affected by disasters between 2005 and 2018 according
    to a study by the United Nations Office for Disaster Risk Reduction [1]. There
    are some outrageous consequences when Disasters strike, such as loss of life,
    property, and habitat. To minimize the damage and risks associated with disasters,
    it is necessary to employ efficient management techniques. The cost of the system
    on chip is gradually decreasing so availability and cheaper cost of IoT modules
    allows for more growth in this area [2] and [3]. Lately, the development in technology
    paved a new way to mission-critical service MMTC in 5G NR [4]. So IoT technology
    available today is quite mature and has the potential to be very useful to manage
    disaster scenarios. Rescue events may be interlinked through IoT for proper control
    technique and disaster warning systems, rescue methods, follow-up, and regulation
    techniques can be conjugated for this purpose [5]. So an architectural system
    for effective disaster control using IoT strategies should be introduced to reduce
    the fatality of a disaster phenomenon. The disaster search and rescue operations
    in collapsed buildings are limited by the quantity of information available at
    the time [6] and [7]. The inefficiency of the current mechanism for identification,
    assessment and monitoring is the main challenge faced in a disaster rescue operation.
    This paper aims at developing an architecture for an IoT system for a particular
    use case scenario. The IoT system is expected to function in pre-disaster and
    post-disaster scenarios by efficiently utilizing the information from the IoT
    sensors deployed in a smart building for minimal delay in search and rescue and
    to provide network resilience. During a Disaster, severe damage may happen to
    IoT resources deployed in a building. This will affect the Network resilience
    and result in single-point failure of IoT system deployed in Smart Building [8].
    The major contributions of this paper are: A comprehensive survey on the existing
    disaster management methodologies and understand the key components that delay
    the search and rescue operations. To define IoT architecture for disaster management
    in smart building for the particular use case scenario. To propose a communication
    system for IoT in smart building with importance for network resilience. The paper
    is organised as follows: Section II summarises the state of the art and research
    findings. Section III describes the proposed IoT architecture for disaster response.
    Section IV presents the results and discusses the system performance. The paper
    is concluded in V. SECTION II. Related Work This section presents scholarly works
    on fog computing and wireless mesh topology for IoT architecture in building management
    systems along with different communication technologies used in disastrous scenarios.
    Fog computing has ushered in a gradual change from older cloud servers to newer
    fog servers with the advent of this new concept. Not only does this technology
    provide extensibility to existing cloud architecture, but it also allows for a
    decentralised architecture. The emergence of wireless mesh topology allows for
    the tradeoff of long-range with multiple hops, along with the provision of network
    resilience while reducing the number of nodes that can be reached in a given period.
    A. State of the Art Review Sangmin Park et al. review an effective and economical
    building disaster management system appropriate for fire disasters in smart cities
    [1]. They discuss an Augmented Reality-based Disaster Management System to solve
    the problems due to fire disasters in urban areas. The system was implemented
    and set up with a service system board of 10 system machines. They say that the
    system provides intelligence as a service that provides prompt structure and eviction
    simulation and monitoring and gives Safety Guidelines that provide legal assistance
    to residents and rescuers in the event of a real fire. This IoT-based real-time
    outlying system can respond quickly in association with the fire department by
    providing information on real-time fire incidents. Anurag Verma et al. review
    a combination of IoT Architecture and Building Management and Information System
    (BMIS) which forms Building Internet of Things(BIoT) that maintains energy efficiency
    and sustainability to help reduce global warming [2]. The authors discussed the
    high-level implementation of advanced intelligence features, control parameters
    and IoT infrastructure required for smart building. Focused on sensing, managing
    the infrastructure that makes cloud clients work to use the sensing field using
    communication protocols. The authors have given special attention to some of the
    smart features that make buildings smart like privacy and security, network facilities,
    health and safety services as well general management in smart buildings. Chaitanya
    Kapoor et al. presents a research paper on modelling communication protocols for
    Smart Cities using MatLab''S 5G toolbox. They modelled various V2X, V2I and I2X
    communication protocols and proposed a mathematical model to develop a resilient
    smart city network model [9]. Siddarth et al propose UbiQNet, a Ubiquiti network
    architecture consisting of drones to provide an ad-hoc network during disasters
    in a smart city. They propose to create a mesh network with the support of drones
    to provide a reliable communication backbone for first responders to speed up
    the rescue operations [10]. Manohar N et al. demonstrated how machine learning
    algorithms work in conjunction with the internet of things (IoT) technology to
    monitor floods and alert people living nearby [11]. The authors say that if people
    living in the tremor wave inclined zone are prepared to endure the strike, the
    subsequent harm can be mitigated and daily activities can be maintained. Alarming
    individuals can lessen the misfortunes by admonishing the frameworks. It would
    be possible to limit the damage to life and property if floods were predicted
    at the earliest stages. The authors discuss how machine learning technology and
    the Internet of Things (IoT) are used to implement a flood observing and warning
    system. They cover several sections in this framework. First, sensors are used
    to measure the height of water. After the tallness data is received from the Ethernet
    shield, it is sent to the web page. The third part consists of giving information
    to higher-level specialists regarding the possibility of flooding. While not discussing
    any early warning systems and predicting water level rise times, this system predicts
    whether a flood will occur in a given area without discussing real-life deployment
    details, such as battery requirements. Huang-Chen Lee et al. discusses a detailed
    study of a network of wireless mesh architecture using the Lora module to achieve
    wide area coverage [12]. Apart from the availability of several available communication
    technologies that can transmit wireless data is a basic requirement of an IoT
    system, the high cost calculated makes it impossible for real applications. Dealing
    with this, the problem is choosing a network topology that provides a high level
    of Package Delivery Rate (PDR). The authors say that the architecture uses the
    topology of the star network in communication between LoRa Gateways and IoT devices
    and allows only one hop in between the LoRa device and gate. B. Research Findings
    The papers discuss the role of IoT in disaster management as well as its utilization
    in energy conservation in smart buildings. It has been examined how IoT can assist
    those who are involved in relief operations after a disaster concerning technology
    in disaster management. The paper [1] discusses how to detect residents in the
    event of fire hazards in buildings by providing an instant service for Intelligence
    and Safety Guidelines and the paper provides a clear comparison between the Current
    System and the Proposed System but gives less importance to Post-disaster communication
    methods. The authors have delved into the fog computing domain extensively in
    papers [13] and [2]. This paper has identified a number of applications in the
    modern-day that are based on the fog computing domain extensively in papers [13]
    and [2]. Communication, data flow, and other characteristics of these applications
    are outlined according to the fog paradigm. A novel architecture has been developed
    that depicts the data flow, communication, and security across the entities. A
    comprehensive architectural proposal has yet to be put forth. However system failure
    case is not discussed and the system is not deployed in real-time to study the
    energy consumption in the system in paper [13] and in paper [2], sensing and controlling
    mechanism related description remains unmodified and the constraints also remain
    uncertain. In paper [11], Using the latest technological equipment and simultaneously
    transmitting through the web, the proposed system can effectively detect and predict
    flood times, thus saving lives and making the world a better place. The paper
    [12] introduces mesh topology which gives an advantage over single-point failure
    and provides a long-distance switching solution that can reduce the number of
    nodes delivered at a time avoid multiple locations simultaneously uploading their
    data to a wireless network and minimize data collisions. However, this approach
    causes delays between locally generated data and data uploads at Gateway are high.
    A few of the studies reviewed and discussed scholarly works that reviewed and
    explained a few of the applications that follow modern, state-of-the-art architectures
    as well as taking into account the latest IoT boom that helps meet human needs
    seamlessly. SECTION III. Proposed System Architecture This section describes the
    system architecture in pre-disaster and post-disaster scenarios. The pre-disaster
    scenario architecture consists of sensor nodes, fog computation nodes and a cloud
    node. The sensor nodes and the fog nodes communicate using WiFi during pre-disaster.
    In case of any disaster scenario, the sensor nodes communicate using WiFi. If
    the WiFi connectivity is lost, then the sensor nodes can switch to LoRa and transmit
    data to the ground control station or fog nodes for further processing. Thus making
    it a resilient communication network during disaster scenarios and helping responders
    with uninterrupted real-time data. This section also describes how the network
    resilience can be improved by including a UAV to support the communication between
    the sensor nodes and the ground control station. A. Pre-Disaster Scenario Using
    real-time data collected from the building ambiance in real time, this paper seeks
    to develop a layered IoT architecture that provides disaster detection and mitigation
    in building management. In the pre-disaster scenario architecture consists of
    four layers: the end device layer, the network connectivity layer, the fog computing
    layer, and the cloud computing layer. 1) End Devices Layer: This layer has three
    main functions. To enter data into the system, the first step is to collect the
    necessary data about the ambiance of the building and convert it to a digital
    format. Controlling the building environment in response to the actions and decisions
    received from the system. Moreover, the end-device layer transmits the collected
    data wirelessly to the system, while receiving the control commands from the management
    system. Building ambiance sensors and microcontrollers with wireless interfaces
    are the main components of the end device layer. 2) Network Connectivity Layer:
    Data collected by the various sensors throughout the building is reliably routed
    to their destinations by the network connectivity layer. Consequently, this layer
    implements IoT wireless communication protocols (e.g. WiFi, Lora) and application
    messaging protocols (e.g. MQTT, AMQP, etc.). Essentially, the building''s edge
    nodes and sensor nodes implement the network connectivity layer. Fig. 1. Figure
    shows the IoT-based BMS architecture in pre-disaster scenario Show All 3) Fog
    Computing Layer: A fog computing layer is included in the proposed architecture
    that serves two purposes. Firstly, it extends cloud storage to the edge of the
    network from within the building. Next, it selectively relays data to the cloud.
    Second, it eliminates the need for urgent data to be sent to Internet-based back-ends
    and awaiting feedback, especially when it comes to security-related decisions.
    Fog computing is responsible for the majority of control decisions in a building
    and then transmits those decisions over the network to the end devices. 4) Cloud
    Computing Layer: This architecture is made up of four layers, and the cloud computing
    layer stores and analyzes data relayed from the fog computing layer. Data from
    that building was extensively used to develop some actions related to the building
    as a whole in order to visualize the data and make it more accessible to interested
    users. In addition, this layer contains application program interfaces (APIs)
    and other software tools that can be used by Internet-enabled authorized devices
    to access building data. B. Post Disaster Scenario 1) With Fog device: In the
    post-disaster scenario, of all the N end nodes, k nodes are damaged. Only (N-k)
    end nodes and fog devices are active. Once a disaster is detected and the network
    fails, automatically Lora will be activated by the code running in the Fog device
    implemented in python. The Lora will create a mesh with available nodes and through
    the Fog device, the network will connect to the GS via this Lora Gateway situated
    at the Ground station. The Fog system will initiate commands to signal the UAV
    from the GS for rescue, the location details stored in the database previously
    for each building can be used for path planning. As a backup GSM module is also
    connected to the fog device for emergency data transmission to the cloud. Fig.
    2. Figure shows the network architecture for post-disaster scenario considering
    the fog node Show All Fig. 3. Figure shows the network architecture for post disaster
    scenario without considering the fog node Show All 2) Without the Fog device:
    In this post-disaster scenario, of all the N end nodes, if k nodes and the fog
    device is damaged and only (N-k) end nodes are active, a layered architecture
    will be created using the ESP modules an Emergency data handover to the UAV will
    be initiated and the data will be sent to the cloud via the Lora gateway in the
    GS. As the UAV is fitted with the LoRa module and as this is a mesh network formed
    at the site, the UAV can connect to any node at any location of the building directly
    using the LoRa module and hence access data from IoT modules directly. The data
    from the mesh network is accessed by UAV and is shared with GCS. Here the LoRa
    Mesh can use the UAV as a hop to GCS. C. UAV Assisted Resilient Architecture During
    Post Disaster Scenario The main issue the responders face after a disaster is
    knowing the exact location of the disaster. We consider two disaster scenarios,
    earthquake and fire explosion for demonstrating our proposed methodology. The
    IoT sensors monitor vital parts of the building and provide an early warning with
    the location information to the responders. In case of disaster occurrence, the
    data generated from these IoT devices are analysed to determine the condition
    inside the building, estimate the severity of the destruction and help responders
    plan disaster response activities. UAVs are employed to provide an aerial Lora
    gateway that helps to connect the sensor nodes in the building with the groud
    control station as shown in Figure 4. The Lora mesh network initiates communication
    between its nodes and the UAV as soon as an earthquake is detected. The data from
    the sensor nodes are received by the ground control station and analysed. Based
    on the analysis, rescue operations are planned. After the fire is detected by
    the sensing system in the building, the Lora mesh network initiates communication
    between the nodes and the UAV, which then requests pick up from the ground station
    and asks the fire department to assist as shown in Figure 5. The sensor nodes
    detect motion in a specific range, detect acceleration above a threshold, and
    collect information about the indoor environment. There are a total of 96 sensor
    values from all the total 12 IoT modules from the 3 floors of the building. The
    code generate the data with some adjustments so that it looks like real sensor
    value changes and it is saved into MySQL database at the cloud location. Fig.
    4. Figure shows the system architecture during earthquake scenario Show All Fig.
    5. Figure shows the system architecture during fire or explosion scenario Show
    All SECTION IV. Results and Discussions The Raspberry Pi acting as the fog device
    will analyze each scenario. The DHT11 sensor measures the temperature, humidity,
    and moisture values with an accuracy of 1-degree Celsius, the sensor can measure
    temperature from 0 to 50 degrees Celsius and humidity from 20percentage to 90per-centage.
    Considering a fire scenario, the triggering condition is when the sensor detects
    temperature less than 50C and moisture value less than 20 per cent RH. For smoke
    detection, we can use MQ-2 which is a digital gas and smoke detector and can measure
    or detect LPG, Alcohol, Propane, Hydrogen, CO, and even methane. The critical
    condition is when the value is 1, similarly for the digital flame sensor and PIR
    occupancy sensor. According to the system, if all the four conditions i.e the
    temperature value exceeding 50C along with humidity value going down 20 per cent
    RH and the presence of flame and smoke are detected by the fog device, it is assumed
    that there is a fire disaster. Figure 6 shows the flowchart for the sensing parameters
    in the building showing the threshold values for each sensor and the output for
    the triggering condition which determines whether it is a fire disaster or earthquake.
    The exact location is determined by analyzing the sensor values of the particular
    module in the particular floor and warnings are generated and transmitted to GCS.
    From the database, this data is visualized using Grafana. In real-time, the last
    entry at the MySQL will be analyzed and displayed with related thresholds and
    the building status can be monitored visually as shown in Figure 7. Fig. 6. Figure
    shows the flowchart for sensing parameters in buildings with threshold values
    Show All Fig. 7. Visualisation of overall data in grafana Show All Fig. 8. Figure
    shows a screenshot of the warning message received on a smartphone Show All We
    consider that the fog device continuously receives data from all the modules and
    it will take the last received value and check on the threshold and if all the
    four conditions are triggered, it will read out all the modules where these conditions
    are over the threshold and warning is generated and if all conditions are satisfied
    a fire scenario is detected in the particular location. The location will be identified
    and will be shared with the concerned authorities over an SMS as shown in Figure
    8. Fog device also checks whether all the IoT modules are functional or not and
    if more than 10 per cent of the modules are not producing output, it assumes that
    there is a network failure/disaster detected and it initiates to backup communication
    procedure i.e Lora mesh, till then it will work on WiFi. SECTION V. Conclusion
    This paper presents a fog computing and UAV-based IoT network architecture to
    support first responders in rescue management in collapsed buildings. The architecture
    incorporates IoT nodes and UAV systems to monitor, analyze disasters, and assist
    rescue responders with the status of infrastructures, thereby accelerating disaster
    search and rescue efforts. IoT sensor systems are deployed at various locations
    in the building to generate data during pre and post-disaster scenarios. A fog
    computing node analyse the data generated from this system to provide real-time
    insights to the first responders. The fog computing node transmits the data to
    a ground control station for further analysis. In case of loss to the fog computing
    node, a Lora mesh architecture is proposed with the support of UAVs to deliver
    the data to the responders or the ground station. In this paper, we synthetically
    generated the IoT sensor data that mimics pre and post-disaster scenarios. The
    generated data is then analysed to provide insights to first responders. This
    proposed integrated system can effectively improve disaster management monitoring
    and responses. In future, we would like to employ machine learning algorithms
    to analyse the data and improve the efficiency of the overall system. We would
    also like to have a real-world deployment and understand the operation of the
    system. ACKNOWLEDGEMENT We express our deep gratitude to our beloved Chancellor
    and world renowned humanitarian leader Shri. (Dr) Mata Amritanandamayi Devi (AMMA),
    for the inspiration and motivation. We also thank the faculty and staff members
    of our center for their support in carrying out this work. We also like to thank
    Ms. Divyasree Mohan Menon from Tata Elxsi for supporting us in the work. Authors
    Figures References Citations Keywords Metrics More Like This A High-Level Language
    and Computer Architecture for Real-Time Systems 1989 American Control Conference
    Published: 1989 Testing and debugging in real time systems-design decisions to
    use a distributed computer architecture in a real time application [1989] Proceedings.
    EUROMICRO Workshop on Real Time Published: 1989 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2022 International Conference on Wireless Communications, Signal Processing
    and Networking, WiSPNET 2022
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Resilient IoT System Architecture for Disaster Management in Collapsed
    Buildings
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Ting L.
  - Khan M.
  - Sharma A.
  - Ansari M.D.
  citation_count: '48'
  description: An intelligent climate and watering agriculture system is presented
    that is controlled with Android application for smart water consumption considering
    small and medium ruler agricultural fields. Data privacy and security as a big
    challenge in current Internet of Things (IoT) applications, as with the increase
    in number of connecting devices, these devices are now more vulnerable to security
    threats. An intelligent fuzzy logic and blockchain technology is implemented for
    timely analysis and securing the network. The proposed design consists of various
    sensors that collect real-time data from environment and field such as temperature,
    soil moisture, light intensity, and humidity. The sensed field information is
    stored in IoT cloud platform, and after the analysis of entries, watering is scheduled
    by implementing the intelligent fuzzy logic and blockchain. The intelligent fuzzy
    logic based on different set of rules for making smart decisions to meet the watering
    requirements of plant and blockchain technology provides necessary security to
    the IoT-enabled system. The implementation of blockchain technology allows access
    only to the trusted devices and manages the network. From the experimentation,
    it is observed that the proposed system is highly scalable and secure. Multiple
    users at the same time can monitor and interact with the system remotely by using
    the proposed intelligent agricultural system. The decisions are taken by applying
    intelligent fuzzy logic based on input variables, and an alert is transmitted
    about watering requirements of a field to the user. The proposed system is capable
    of notifying users for turning water motor on and off. The experimental outcomes
    of the proposed system also reveal that it is an efficient and highly secure application,
    which is capable of handling the process of watering the plants.
  doi: 10.1515/jisys-2022-0012
  full_citation: '>'
  full_text: '>

    "Skip to content Authenticated with University of Nebraska - Lincoln What does
    this mean? $ USD € EUR - Euro £ GBP - Pound $ USD - Dollar EN 0 University of
    Nebras... SUBJECTS FOR AUTHORS SERVICES PUBLICATIONS ABOUT Open Access Published
    by De Gruyter February 2, 2022 A secure framework for IoT-based smart climate
    agriculture system: Toward blockchain and edge computing Li Ting , Mudassir Khan
    , Ashutosh Sharma and Mohd Dilshad Ansari From the journal Journal of Intelligent
    Systems https://doi.org/10.1515/jisys-2022-0012 Cite this Share this 45 Abstract
    An intelligent climate and watering agriculture system is presented that is controlled
    with Android application for smart water consumption considering small and medium
    ruler agricultural fields. Data privacy and security as a big challenge in current
    Internet of Things (IoT) applications, as with the increase in number of connecting
    devices, these devices are now more vulnerable to security threats. An intelligent
    fuzzy logic and blockchain technology is implemented for timely analysis and securing
    the network. The proposed design consists of various sensors that collect real-time
    data from environment and field such as temperature, soil moisture, light intensity,
    and humidity. The sensed field information is stored in IoT cloud platform, and
    after the analysis of entries, watering is scheduled by implementing the intelligent
    fuzzy logic and blockchain. The intelligent fuzzy logic based on different set
    of rules for making smart decisions to meet the watering requirements of plant
    and blockchain technology provides necessary security to the IoT-enabled system.
    The implementation of blockchain technology allows access only to the trusted
    devices and manages the network. From the experimentation, it is observed that
    the proposed system is highly scalable and secure. Multiple users at the same
    time can monitor and interact with the system remotely by using the proposed intelligent
    agricultural system. The decisions are taken by applying intelligent fuzzy logic
    based on input variables, and an alert is transmitted about watering requirements
    of a field to the user. The proposed system is capable of notifying users for
    turning water motor on and off. The experimental outcomes of the proposed system
    also reveal that it is an efficient and highly secure application, which is capable
    of handling the process of watering the plants. Keywords: Internet of Things;
    sensors; data privacy and security; fuzzy logic; decision support 1 Introduction
    Due to the modernization of farming, the climate monitoring in agriculture is
    essential for the growth of agricultural yields. With the monitoring of climate,
    efficient watering process is also very important because of shortage of sweet
    water resources across major parts of the world [1]. Therefore, there is a requirement
    for an automatic and intelligent agricultural system that can be adopted for providing
    essential amount of water to the plants and climate monitoring during the maximum
    farming time. The automatic process of climate monitoring and watering is essential
    in Asian region due to the limited resources of water and regularly changing environments.
    The major parts of Asian countries are under severe conditions of hot weather
    and drip system of irrigation, which is utilized for supporting small-scale farming.
    However, the system of drip irrigation is not efficient because of least control
    in the amount of walking during day and night times, various seasons of summer
    and winter [2]. For the efficient utilization of limited water resources, intelligent
    agricultural solution is required to be adopted for obtaining better farming yields
    considering severe conditions of weather. Moreover, many of common people do not
    have the idea and key knowledge for growing plants in an efficient manner. The
    irrigation of plants needs proper control on soil moisture level and monitoring
    of weather and watering quantity for its growth. Many such technologies have been
    designed for providing better water utility during irrigation [3,4,5,6]. However,
    each of these technologies has some limitations, and they are not efficient in
    providing better utilization of water resources and continuous monitoring of climate.
    The prime focus of the proposed design is to present an automatic intelligent
    agricultural system that is capable of monitoring climate and providing an efficient
    utilization of water resources to feed plants during the maximum farming time
    [7]. Moreover, this study also contributes for providing a regular support through
    mobile application for regularly monitoring climate and watering process. The
    blockchain technology is adopted for securing the privacy of the proposed intelligent
    agriculture system [8]. The fuzzy rule is implemented for intelligent decision
    making along with the set of rules, which are applied on the collected data through
    deployed sensors along the field, and providing controls of watering amount in
    accordance with the plant’s watering requirement [9]. The adopted blockchain technology
    provides secure information access among connected Internet of Things (IoT) devices
    [10]. The adopted blockchain technology enables the design by providing access
    only to the trusted devices and thereby controlling and managing the proposed
    intelligent climate and watering agriculture system (ICWAS). Multiple users at
    the same time are capable of monitoring and interacting remotely by using the
    proposed prototype of ICWAS. The prototype application is designed using an Android,
    and the fuzzy logic method is implemented for deciding the action depending upon
    the input values. The proposed ICWAS based on input values of climate and soil
    parameters further activates the actuator for making watering decisions such as
    turning on and off the water tunnels periodically. The humidity, temperature,
    and soil moisture level varies across various parts throughout 24 h of the day.
    This is the reason behind the changes in requirements of watering across various
    parts in a day. The proposed ICWAS monitors climate, light intensity, temperature,
    humidity, and water content in soil through deployed sensors. The sensed information
    is then transferred on the server through Wi-Fi for providing the customized guidance
    of watering and continuously monitoring the plant’s health on smart devices using
    a designed application [11]. Moreover, the varying species of plants requires
    different levels of water irrigation, and therefore, it is essential for effectively
    utilizing the water reservoirs for better plant growth [12]. The intelligent climate
    and pottering agriculture system requires quantifying the input variables collected
    from deployed sensors [13]. In this experimentation, limited amount of plants
    are considered for the modeling of the proposed system. The respective data set
    is collected at local field for accurately monitoring the health of plants and
    recommending the requirements such that the system can guide the farmer in an
    efficient way. The included set of plants in this study is mint, onion, cucumber,
    radish, chili, carrot, tomato, and garlic. The Android application of ICWAS is
    also designed for an intelligent monitoring and smart management of water quantity
    through smart devices. The proposed prototype is tested for its effectiveness
    in laboratory and in field as well. The farmer can easily access the application
    for efficiently monitoring the climate and the level of soil moisture and compare
    the present moisture level with the required soil moisture for a specific plant
    [14]. The design also provides the remote interaction with plants, thereby a farmer
    can adjust the watering amount as per the requirement of specific plant. The proposed
    design provides a real-time monitoring of field from a distant place by simply
    accessing the smart devices across any part of the world with the support of IoT
    and blockchain techniques. The blockchain approach is implemented to secure the
    connection between the server and the IoT devices [15]. Because the proposed design
    of an ICWAS incorporates simple and reasonable mechanisms, the implementation
    of the proposed ICWAS at profitable level profile is a cost-effective result with
    a better efficiency, throughput, and accuracy. The proposed system is not only
    cost effective, but at the same time, it efficiently utilizes the sweet water
    resources and regularly tracks the health of plant by monitoring the climate in
    real time. The rest of the article is arranged as the most recent study in the
    implementation of blockchain and edge computing is discussed in Section 2. Section
    3 represents the proposed architecture of the intelligent agriculture system.
    The results and analysis of the proposed architecture is discussed in Section
    4. The concluding remarks and future direction are presented in Section 5. 2 Related
    studies During the exhaustive study of literature review, very few relevant research
    were identified, which intends to enhance the performance of agriculture in relation
    with various aspects such as soil power enhancement [16]. The suitable quantity
    of soil water includes certain obligatory conditions for the efficient growth
    of plant. Water is the most critical ingredient for the nourishment of life to
    efficiently use water resources. It is studied from one study that Indian farmers
    are facing issues such as electricity of low voltage and power cuts for the irrigation
    of agricultural land [17]. If the farmer does not irrigate agricultural land during
    the power cut time, then the probability of electricity and water wastage is very
    high during those hours, whereas the excessive watering also cause serious damages
    to the crops. Considering these issues, an integrated design was proposed of IoT
    and mobile application [18]. The design uses various sensors for measuring the
    temperature and soil moisture and the integration of Raspberry-Pi for automatically
    turning on and off water pumps. The authors have designed and automatic system
    for observing and irrigating the garden [19]. The design consists of watering
    the garden considering weather forecast and timer settings. The forecast API is
    used to access the forecast and integration of Raspberry-Pi for meeting the watering
    requirements. As per their study advanced sensors, user interface, time lapse
    and the form factor will be considered for the future directions. The authors
    proposed a design that considers recent and previous weather forecast for scheduling
    the watering of plants [20]. System also provides an application for their users
    where the weather conditions are forecasted for making plant watering schedule
    as per the weather conditions. The system also provides a facility for its users
    to select various services of weather forecasting such as underground weather,
    accessing private weather stations and dry sky conditions for the collection of
    different weather data. To access the private weather station, the proposed design
    is connected with Netatmo and Davis tools for accurate and highly localized weather
    information [21]. Depending on the outdoor weather conditions, the watering schedule
    is optimized. The design algorithm compensates inaccurate forecast of weather
    and utilizes water resource efficiently by managing the irrigation process considering
    parameters such as soil humidity, temperature, solar radiation, and speed of wind
    [22]. One study presents system for smart irrigation monitoring and controlling
    that uses wireless sensor networks and cloud computing technology [23]. The integration
    of wireless sensor networks and cloud computing helps monitoring and controlling
    the process of plant irrigation. The authors have utilized a set of census along
    with the actuators for measuring and evaluating water requirements of plants [24].
    The design also consists of an Android application for remotely accessing the
    drips. The communication among sensor nodes and base station is carried out through
    ZigBee module. A web-based graphical user interface is utilized for handling the
    collected information on real-time basis. Another design based on an Android application
    is proposed, to facilitates farmers with full access for the ornamental treatment
    of plants remotely [25]. There is a requirement for optimizing and controlling
    the irrigation requirements. The meadowlands would never be overwatered and underwatered.
    The computer-based designs are adopted as these technologies provide efficient
    collection of data such as plant information and environmental factors with high
    accuracy and in fewer efforts. Recently, with the evolution of technology, smartphones
    and web applications play a critical role in creating highly advanced and fully
    automated systems [26]. Such devices provide simple computing supply for all the
    people globally because of mobility factor. In daily life due to the intense incursion
    of smart devices, the development of secure Android applications is gaining more
    attention. A similar system was designed with the integration of IoT devices and
    Android application, where the design can be scaled up and rebuild [27]. Their
    system contains Arduino and a series of different sensing devices, which are connected
    in planter. The collected data from a real-time environment are deposited in cloud
    database, but this data can only be retrieved through the web application. Their
    scheme is capable of providing the learning of water conservation to the users
    through computerization and building a bridge between the computer system and
    the proposed centric system based on soil moisture sensor measurement. The senses
    become operational when the impedance factor changes among the electrodes, which
    are implanted in soil. The Arduino technology was implemented to design a system
    for controlling the irrigation and roofing procedure in greenhouse [28]. The input
    for the system is environmental data, such as humidity, temperature, soil moisture,
    and light intensity, through deployed sensors. The collected information is then
    compared with the weather forecast information for making the optimal decision.
    The Kalman filter was introduced to remove noise from the sensors [29]. In one
    more study, the authors propose the system based on census that measure the water
    level and water flow, which are connected with water pumps and irrigation canals,
    respectively [30]. They proposed a design, which utilizes wireless sensor networks
    for transmitting the sensed information to the server through gateway node periodically.
    In web server, the collected information are analyzed and kept in database for
    making comparison among recent and predefined values [31]. In their system, an
    alert is generated and transmitted to the farmers when the water requirement is
    needed. In one study, authors proposed an IoT design-based digital approach for
    handling the irrigation process [32]. The sensors are deployed in agricultural
    land for measuring the level of moisture and to check the water level in storage
    through smartphone network. To access the sensor information, an intelligent software
    is installed on the server for making effective decisions about irrigation. A
    design is proposed to improve the water management by using a global system for
    mobile communication module [33]. The design provides regular monitoring of water
    level in storage and capable of providing suggestions about the exact level of
    water, which is required for the plants’ growth. This is also capable of measuring
    the humidity and temperature values to sustain the nutrients present in soil,
    which are essential for the plants’ growth. Recently, the introduction of blockchain
    technology became very popular for securing the transmission in IoT-enabled smart
    systems [34]. The traceability of agricultural goods is becoming a critical challenge.
    To overcome this issue, a study was proposed that implemented blockchain technology
    for securing the tracing of agriculture products [35]. This study also incorporates
    various managerial operations such as irrigation and fertilization of plants.
    The blockchain technology is implemented for recording the information of dispersed
    farmers, sellers, growers, and users for providing the security to many such operational
    information through decentralized manner. In smart agriculture, a design was proposed
    by implementing the infrastructure of blockchain technology [36]. There proposed
    design provides the necessary safety for maintaining the data integrity in agricultural
    domain. The blockchain technology in smart agriculture facilitates users and various
    farmers, which ensures the immutability of high quality and worthy information
    [37]. The blockchain technology enhances the traceability along with the accessibility
    of watering control information spatially. In one study, a farmland irrigation
    system is developed, which contributes for the enhancement of agricultural products
    and livelihood of rural people by adopting modern agricultural process [38]. In
    their proposed system, the authors have implemented the blockchain technology
    for securing the information from compiling histories in irrigation canals, where
    the irrigation information is accessed through various farmland associations of
    irrigation. The role of artificial intelligence and IoT based for the application
    of health-care applications [39,40,41]. Furthermore, ant colony optimization is
    discussed for task offloading in fog computing in agriculture [42]. The sensed
    information can be utilized for making a maintenance process of irrigation resources.
    The blockchain technology serves as an integrated bridge between irrigation association
    and farmers for supporting plant irrigation and efficiently using water resources.
    The comparison of various designed approaches that can be used for smart agriculture
    is tabulated in Table 1. The earlier designed system in agricultural domain is
    focused on efficient utilization of water irrigation by measuring the soil moisture
    [43]. However, essential parameters for controlling the water consumption and
    improved growth of plants are soil type, light intensity, humidity, and temperature.
    Because different plants need different watering requirements, and accordingly
    similar plants can have various irrigation needs consisting of suitable environment
    and soil type [44]. The comparison tabulated in Table 1 clearly highlights that
    there is a strong requirement for designing an intelligent system that can accurately
    measure the climate and irrigation needs on a real-time basis, considering all
    of the possible parameters. The ICWAS is an effort for providing a key that considers
    various constraints instead of only measuring soil moisture. The proposed design
    and its working along with the experimental analysis are discussed in the third
    section. Table 1 Parameters comparison of proposed model with existing technologies
    Previous technologies Parameters Precision soil irrigation Decision support watering
    Optimized consumption of energy Decentralized network Secure data communication
    [8] Yes No No No No [13] No No No No Semi implementation [18] Yes No Yes No No
    [22] Yes Yes (not implemented fuzzy logic) No Yes No [27] No No Yes No No [32]
    Yes No No No No Proposed model Yes Yes Yes Yes Yes 3 Architecture design of intelligent
    agriculture system The proposed ICWAS is designed considering security and integrity
    of data implementing the blockchain technology. The blockchain is applied for
    tracking and tracing the transactions through device, which are performed during
    the operation of the proposed ICWAS. The blockchain technology does not only secure
    the transaction but also enables seamless availability and connectivity of various
    features provided by the proposed system. The proposed architecture of integrated
    IoT and blockchain-based ICWAS is depicted in Figure 1. Figure 1 Proposed model
    for IoT-based ICWAS. The central storage concept may be vulnerable from various
    security threats but to tackle these threats we have implemented a decentralized
    storage approach. In decentralized approach, the climate, watering, and plants
    database are stored using the blockchain technology. The communication channels
    among sensors, actuators, smart devices, and IoT cloud platform of the proposed
    system is depicted in Figure 1. Smart devices are represented as nodes where each
    node contains blockchain copy, and their copies are transmitted to each node for
    their further use. At every 15 minutes, each family in block is updated, and this
    is the reason why the proposed system presents a secure communication procedure,
    and it is nearly impossible to track or trace the security of system. Therefore,
    by implementing the blockchain technology, a secure transmission in terms of receiving
    data from devices, delivering data to users and its storage is achieved. In the
    proposed system, the blockchain module is designed using Java, and the blocks
    contents is defined as hash, which acts as a unique identifier. Each of the block
    is capable for computing block hash, and then secure hash algorithm hash is evaluated
    based on it. A block is designed when threshold level meets the requirement, and
    the connectivity is, therefore, achieved by managing the blockchain. The blockchains
    are then looped over to verify the validation of entire blockchain system that
    whether the blocks hash is matching with previous block hash or not. Figure 2
    depicts the four-layer operation of the proposed ICWAS. These four layers are
    perception layer, network layer, transport and management layer, and application
    layer. In perception layer where the sensors, actuators, and other hardwares are
    deployed. The second layer is the network layer, which is responsible for the
    connection establishment by using Bluetooth and Internet technology. The third
    layer is the transport and management layer, which is responsible for processing
    the sensed information, its security, management, and storage. The fourth layer
    is the application layer; the stored data and regular entries are analyzed using
    smart devices and transferred to the user through Android application. All of
    these four layers continuously interact among each other for providing secure
    transmission in smart devices and sensors for their efficient working of the proposed
    ICWAS. By simply logging-in into the application, a farmer can monitor climate
    and control the process of watering and can schedule actuators for specific plants.
    Figure 2 Architecture of ICWAS. Figure 3 depicts the architectural design of the
    proposed ICWAS, which represents the physical components of the design. It consists
    of the architecture of all the hardware utilized in the intelligent agriculture
    system, which is deployed in a real-time environment. As depicted in Figure 3,
    different sensor nodes such as temperature, soil moisture, humidity, light intensity,
    and camera sensors are deployed in the area of interest, which are connected with
    the microcontroller through analog inputs. The actuators, which consist of water
    pumps and lights, are connected with microcontroller in the serial output port.
    The microcontroller acts as a centralized system, which gathers data from deployed
    sensors and transmits sensed information toward the server through access points.
    The server is responsible for transmitting the sensed information such as light
    intensity, temperature, soil moisture, and humidity to the proposed module of
    fuzzy logic. This module analyses the entries and provides the decision whether
    there is a requirement of watering to the plant considering different plant types
    through the database of plants. Once the watering decision is taken to fulfill
    requirements of plant irrigation then alert is transferred to the user via SMS
    for taking necessary action. The user is capable of changing the operation of
    the system and can set the operation automatically and manually for handling the
    actuators of the system. Figure 3 Hardware implementation of proposed system (ICWAS).
    4 Intelligent watering decision support system Intelligent decision support scheme
    based on fuzzy rule is a major constituent of the proposed ICWAS. The proposed
    decision support system helps in making decisions based on the analysis of collected
    data from sensors. The fuzzy logic is implemented in this study because of its
    high two implications. The first significance is that the fuzzy logic provides
    highly accurate decision-making. The other significance of implementing fuzzy
    rule is its simple and easy implementation for IoT applications. The fuzzy logic
    analyzes the climate and makes decisions about watering requirements of plants.
    The decision is transferred to the mobile application, which is developed in Android.
    Figure 4, depicts the major components of the proposed intelligent decision support
    system such as fuzzy inference procedure, fuzzification, and defuzzification module,
    set of fuzzy rules, database, and sensor data. Typically, in any fuzzy logic design,
    the universal discourse D is inferred in any fuzzy set F in pair as ( D , m )
    . The fuzzy set consists of an ordered pair of i variables along with the membership
    function m f ( i ) . The comparison of fuzzy set F is shown in equation (1). (1)
    F = {  i ,  m f ( i ) ,  i ∈ D } Equation (1) is used for computing fuzzy sets
    and below are the steps, which are followed for the implementation of fuzzy logic.
    Figure 4 Proposed fuzzy logic controller for ICWAS. Step (i): Equations (1) and
    (2) are used for defining initial set of variables Step (ii): In second stage,
    the membership function are declared Step (iii): Rules are formulated for each
    defined variable Step (iv): Input a 1 , a 2 , a 3 ,…, a n are given in the fourth
    step Step (v): In fifth step, the membership functions are declared and utilized
    for each of the input value for their mapping with fuzzy value Step (vi): In sixth
    step, the fuzzy rules are achieved for inferencing each rule Step (vii): In this
    step, the aggregation is achieved for inferencing each rule Step (viii): In the
    last step, the final inference value is further converted to output value Y As
    shown in step (i), the designed fuzzy logic-based intelligent decision support
    system is used for handling five different variables such as temperature, humidity,
    light intensity, soil moisture, and plant type. These five different variables
    are declared as the subset of set F ( P , Q , R , S and T ) . As described in
    equations (1) and (2), the temperature change is represented with variable P ,
    humidity change is represented with variable Q , intensity of light is represented
    with variable R , soil moisture is represented with variable S , and variable
    T represents time. In step (ii), membership function set is computed for each
    input value of variables, such as m P ( a ) , m Q ( a ) , m R ( a ) , m S ( a
    ) , m T ( a ) , which represent the membership function of different input variables
    P , Q , R , S and T . These computed membership functions represent the membership
    degree of variable a for set of variables P , Q , R , S and T as represented in
    equations (2) and (3). (2) P ∪ Q ∪ R ∪ S ∪ T = { a , max ( m P ( a ) , m Q ( a
    ) , m R ( a ) , m S ( a ) , m T ( a ) ) } where a is an element of F . (3) P ∪
    Q ∪ R ∪ S ∪ T = { a , min ( m P ( a ) , m Q ( a ) , m R ( a ) , m S ( a ) , m
    T ( a ) ) } Step (ii) is followed by step (iii) where if then rules are applied
    for the implementation of fuzzy set rules. Every component of the proposed fuzzy
    logic-based intelligent decision support system as mentioned in algorithm above
    are implemented for each module where the working of modules are described in
    section 5. In step (iv), the membership functions are defined for each variable
    P , Q , R and S as temperature change, humidity change, moisture change, and light
    intensity as “lower,” “medium,” and “high.” However, the membership function for
    input variable T is computed as time such as “day” and “night.” Equation (4) represents
    the fuzzy set F ( a i ) , which is fuzzification kernel and further implemented
    utilizing mapping of μ i and a i for a fuzzy set F ( a i ) . (4) ∼ P = μ 1 F (
    a 1 ) + μ 2 F ( a 2 ) + μ 3 F ( a 3 ) + … + μ n F ( a n ) As mentioned in step
    (v), the fuzzification process is computed using equation (4). Equation (5) represents
    the triangular membership function of the proposed implementation. (5) μ P ( a
    ) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ 0 ,  a ≤ X   a − X Z − X X < a ≤ Z Y
    − a Y − Z Z < a < Y   0 ,  a ≥ Y The operations of minimum and maximum are utilized
    for evaluating the fuzzy values through crisp input values as represented in equation
    (6). (6) Δ ( a ; X , Y , Z ) = max ( min ( a − X Y − Z , Z − a Z − Y ) ) As represented
    in equation (6), the three corner coordinates of a for the considered triangular
    membership function, which are declared as X , Y , Z where X < Y < Z . As represented
    in equations (5) and (6), the membership functions are declared for each of five
    variables of the utilized fuzzy logic design. The MATLAB toolbox of fuzzy logic
    is utilized for defining these membership functions. As represented in step (vi),
    the main component of the proposed ICWAS is fuzzy inference procedure, which is
    responsible for effective decision making based on set of if-then rules, membership
    function set and “or,” “and” operators of fuzzy logic. In our proposed scheme,
    the fuzzy inference procedure is mapped with input to the respective output by
    utilizing fuzzy logic. The implemented fuzzy inference procedure consist of following
    steps, which are mentioned below. The fuzzification of input variable through
    membership function. In the next step, fuzzified inputs are combined as per fuzzy
    theory. Making of fuzzy rules. Rules outcome evaluation with the combination of
    output membership function and rule strength. The outcomes are combined for obtaining
    the output distribution. In last step, defuzzification of observed membership
    function is followed. The detailed procedure of fuzzy inference through four inputs
    along with two rules is represented in equations (7) and (8) where W 1 , Y 1 ,
    and Z 1 represent fuzzy and not a crisp value. (7) If  ( U 1 = E 1 1 ,  V 1 =
    E 1 2 ,  W 1 = E 1 3 ,  Y 1 = E 1 4 ,  Z 1 = E 1 5 ) Then  ( w = D 1 ) (8) If  (
    U 2 = E 2 1 ,  V 2 = E 2 2 ,  W 2 = E 2 3 ,  Y 2 = E 2 4 ,  Z 2 = E 2 5 )  Then  (
    w = D 2 ) Thereafter, the intersection over crisp input value with the membership
    function of input is applied for the occasion of three input values. The “and”
    operator is used for merging three fuzzified inputs to obtain the rule strength.
    The implementation of fuzzy inference procedure utilizes a membership function
    for every rule and then depending upon the complaint of each rule a conclusion
    is drawn. In the last step of the proposed implementation, the output is evaluated
    through fuzzy set of rules, which is written using if then statements, and then
    stored in knowledge database. In this step the scalar value is fuzzified, then
    rules are applied where is rule provides fuzzy output and then its conversion
    to a scalar measure. In the proposed scheme, defuzzification approach is utilized
    as it provides accurate outcomes as express in equation (9). (9) a ⁎ = ∫ μ i (
    W ) ⋅ x d x ∫ μ i ( W ) ⋅ d x where a ⁎ represents the defuzzified outcome, μ
    i ( W ) represents the membership function aggregation, and x represents the output
    variable. In equation (9), the output variable x is represented by x-axis, the
    aggregated membership function μ i ( W ) is represented by y-axis and defuzzified
    outcome is expressed as a ⁎ . At last the output shape is observed by the implementation
    of fuzzy “and” operator with clipping of observed membership function as per the
    rule strength. 5 Implementation of intelligent agriculture system The hardware
    devices used for implementing the proposed ICWAS are mentioned below. Arduino-Uno
    Wi-Fi module ESP8266 Water motor – 15 V Soil moisture sensor node – EC1258 Temperature
    and humidity sensor – DHT 11 Light intensity sensor – BH1750 Relay node – 6 V
    5.1 Process of intelligent agriculture system at server end The application is
    designed at server end for handling ICWAS. A web-based interface is introduced
    for handling the system. The management interface provides various options for
    controlling the proposed intelligent agriculture system. The web application requires
    an administrator level login for the secure access and also provides the working
    description of system. A dashboard is provided by the system through application
    for the management of plants data at the administrator level. The administrator
    after logging into the application may add new information about plant such as
    planting period details, fertilizers, watering, and other required details of
    the specific plant. This provided information is visible to the farmers and users
    as per the preference. At the same time, the administrator can also delete the
    details from its repository, which are irrelevant and not necessary. The administrator
    can control or manage users for allowing them to access the functionalities of
    the system by creating accounts. 5.2 Analysis of intelligent agriculture system
    through mobile application An Android-based application for intelligent agriculture
    system is also designed. This application allows user for farmers to control the
    system remotely. The basic control of the system are provided to the user, which
    are available in the menu. This application provides the necessary access to farmers
    such that they can access main features of the proposed system. The user can monitor
    the field, control actuators, and access the necessary alerts. In the user application,
    the information is available about each plant, which represents the suitable time
    and season for its planting and watering. At the backend, the fuzzy logic base
    intelligent system makes decisions by matching the previous and current state
    of the plant. This process provides the guidance to farmer about planting such
    as where and when to plant a seed, details about suitable fertilizers, estimated
    harvesting time, and environmental conditions. The user can their self-schedule
    watering process through their mobile application, are synchronized with a system
    calendar. The sensed information are processed in server on a real-time basis,
    and plant list along with their feasibility rating is transmitted to the farmers’
    mobile. An alert is transmitted to the user mobile whenever the watering schedule
    meet specific date and time or the water level of field decreases. As per the
    regular schedule of watering or with the decrease in level of water, farmer can
    control the state of water motor to on and off by just accessing the application
    from anywhere across the world. When the water level of the field increases or
    meets the level of plant water requirement, again alert is transmitted to the
    user mobile to change the state of water motor to turn it off. 6 Experimental
    analysis and discussion The sensed information from the field received to sink
    node on a real-time basis and installed in IoT cloud platform for its analysis
    and decision-making. The web-server is introduced for monitoring and storing the
    real-time sensor information from sink node. A proposed system consists of knowledge
    base at server and along with predefined rules as tabulated in Tables 2–4. This
    database is obtained by the regular training of sensor nodes for or observing
    their threshold values. To match the observed values with knowledgebase data,
    rule base inference procedure is followed. The collected real-time information
    of temperature, humidity, soil moisture, and light is evaluated to give recommendations
    about the health of plants, and to convey which plant can be planted in particular
    season. Table 5 represents the sensed information about temperature, soil moisture,
    intensity of light, and humidity change. This sensed information from the field
    is further transmitted using microcontroller and received by the server. Table
    2 Training of moisture values Moisture level Training 0–500 Higher/dry condition
    501–700 Average 701 and above Lower/wet condition Table 3 Training of humidity
    values Percentage humidity Classification 70% or above Higher 50–69% Average Less
    than 50% Lower Table 4 Soil moisture classification Light intensity Classification
    Higher Dry condition Lower Wet condition Table 5 Collected entries of sensed data
    Time created at (Instances) Entry Hum (%) Moisture (g/m3) Temp (°C) Light (lux)
    2021-02-12 14:25:23 + 0530 211 23.35 18 15.36 143 2021-02-12 14:28:00 + 0530 212
    20.12 19 16.32 165 2021-02-12 14:34:41 + 0530 213 21.33 22 15.36 183.3 2021-02-12
    14:38:10 + 0530 214 27.35 125 19.22 184 2021-02-12 14:45:30 + 0530 215 27.22 628
    18.17 146.3 2021-02-12 14:52:20 + 0530 216 22.45 13 18.35 145.2 2021-02-12 14:58:03
    + 0530 217 21.37 19 12.35 122 2021-02-12 15:05:28 + 0530 219 19.13 389 13.22 132.6
    The statistics presented in Tables 2–4 auditors hold points, which are observed
    through the training of sensors. Table 5 represents the sensor outcomes, which
    are used in this experiment. The fuzzy rule inference procedure compare the sensor
    values from plants, which are stored in IoT, cloud database with the threshold
    values stored in knowledgebase. The fuzzy logic computes percentage of set of
    rules, which matches with input variable as a score of particular plant. This
    observed score value is then transmitted to the Android application and highlighted
    in the menu bar. This information helps farmer to know the suitability of particular
    plant for its growth and health in different environmental conditions. For controlling
    the watering process of a field, sensed information is transmitted toward server
    five to six times in a day. These transmitted values are compared with the computed
    thresholds of temperature, humidity, soil moisture, and light intensity for checking
    whether to schedule watering process or not. The user is regularly notified with
    the current condition of water level in soil. During watering process, when the
    moisture of soil all the content of water is maintained above the threshold value,
    the water motor is turned off. The collected entries of the field data in stored
    in IoT cloud for analysis and decision making where few sample entries are depicted
    in Figure 5. Table 6 represents the experimental outcomes of the proposed system.
    From the experimentation of 5–10, there are few chances where the value is high,
    and for some cases, the valley is observed medium. Accuracy of the proposed ICWAS
    for most of the experiments is above 98%. The accuracy of the proposed system
    signifies that the system accurately working as per defined fuzzy rules for ICWAS.
    The overall accuracy of the proposed ICWAS is calculated using equation (10).
    (10) ICWAS accuracy = ∑ μ ( A j ) N Figure 5 Collected sensor information in IoT
    cloud during experimentation. Table 6 ICWAS outcomes for ten experiments Experiments
    Humidity (%) Temperature (°C) Time (min) Moisture (voltage) Test result Real result
    Accuracy (%) S1 9 2.68 2.9 High Lower Lower 99 S2 11.2 6.3 4.3 High Medium Medium
    98 S3 9.4 4.58 2.8 High Medium Medium 99 S4 13.6 8.6 2.1 High Higher Higher 99
    S5 15.9 2.34 2.6 High Medium Lower 55 S6 17.6 7.5 2.7 High Higher Higher 98 S7
    16.2 6.3 1.9 High Higher Higher 99 S8 15.3 6.9 4.4 High Higher Higher 100 S9 4.2
    10.5 7.6 High Higher Higher 100 S10 6.9 8.9 1.9 High Lower Lower 100 By implementing
    equation (10), we have calculated the overall accuracy of ICWAS where the percentage
    accuracy for each experiment is represented as μ ( A j ) , and total number of
    experiments is represented as N . The overall accuracy of the proposed system
    through the experimentation is observed as 96.7%. Different sensor information
    and actuators effect after the decision is taken using intelligent fuzzy logic
    is tabulated in Table 7. The actuator response for five experiments of the proposed
    system is depicted in Figure 6. Table 7 Controlling actuator response through
    sensed data Entry Soil moisture Temperature Intensity of light Humidity Status
    of water motor E1 387 26.5 38 79.3 On E2 1,028 26.3 45 77.8 Off E3 1,041 23.2
    54 68.7 Off E4 341 19.3 53 67.5 On E5 283 16.7 16 26 On Figure 6 Actuator response
    for different experimentation. Table 7 represents the observed statistics of sensor
    information, which instigates the decision taken by intelligent fuzzy logic module
    for changing the state of motor by turning on and off with respect to temperature,
    humidity, and soil moisture values. The proposed intelligent agricultural system
    is designed for monitoring climate and early detection of soil dryness. From the
    experimentation, it is analyzed that the proposed system is an effective solution
    for detecting the dryness in soil at early stage. The proposed system offers a
    secure transmission of information from field to the server through decentralized
    network. The proposed integrated IoT and blockchain-based intelligent agricultural
    system has the flexibility of future directions as well. The current system is
    only considered for eight type of plants, whereas the proposed study can be extended
    by implementing genetic algorithm for neural networks for obtaining more precise
    recommendations and accurate predictions at its initial stage. 7 Conclusion In
    the modern era, technology is playing a critical role for the growth of a nation
    and an individual. With the modernization in various sectors, the agricultural
    sector also requires huge advancement especially in a country such as India. The
    modern technologies should be utilized for increasing the efficiency and productivity
    of the agricultural products. This project is aimed to design an intelligent agricultural
    system, which is capable for monitoring the climate and other important parameters
    such as temperature, humidity, soil moisture, and light intensity for enhancing
    the health of plant and increasing the productivity. The proposed intelligent
    agricultural system is an integration of IoT and blockchain technology for providing
    efficient and secure decision system. The system collects the field data in real
    time through deployed sensors and recommends usage with necessary precautions
    and decisions. The decisions are taken by applying intelligent fuzzy logic based
    on input variables, and an alert is transmitted about watering requirements of
    a field to the user. The proposed system is capable of notifying users for turning
    water motor on and off. The current system is only considered for eight type of
    plants, whereas the proposed study can be extended considering future directions
    by implementing the genetic algorithm for neural networks for obtaining recommendations
    that are more precise and accurate predictions at its initial stage. Acknowledgments
    1. Fujian Education Department Science and Technology project (JA15603) application
    of cognitive radio in mobile communication based on GNU radio. 2. Research on
    predictive coding algorithm for millimeter wave large scale MIMO system (FTKY005)
    of Fuzhou Institute of Technology. Funding information: 1. Fujian Education Department
    Science and Technology project (JA15603) application of cognitive radio in mobile
    communication based on GNU radio. 2. Research on predictive coding algorithm for
    millimeter wave large scale MIMO system (FTKY005) of Fuzhou Institute of Technology.
    Conflict of interest: The authors have no conflict of interest. Research involving
    human participants and/or animals: This research has not involved any human participants
    and/or animals. Informed consent: Not applicable as all the material is publically
    available. References [1] Prathibha SR, Hongal A, Jyothi MP. IoT based monitoring
    system in smart agriculture. 2017 International Conference on Recent Advances
    in Electronics and Communication Technology (ICRAECT), IEEE; 2017. p. 81–4.10.1109/ICRAECT.2017.52Search
    in Google Scholar [2] Mekala MS, Viswanathan P. A survey: smart agriculture IoT
    with cloud computing. 2017 International Conference on Microelectronic Devices,
    Circuits and Systems (ICMDCS), IEEE; 2017. p. 1–7.10.1109/ICMDCS.2017.8211551Search
    in Google Scholar [3] Yang J, Sharma A, Kumar R. IoT-based framework for smart
    agriculture. Int J Agric Environ Inf Syst (IJAEIS). 2021;12(2):1–14.10.4018/IJAEIS.20210401.oa1Search
    in Google Scholar [4] Ray PP. Internet of things for smart agriculture: technologies,
    practices and future direction. J Ambient Intell Smart Environ. 2017;9(4):395–420.10.3233/AIS-170440Search
    in Google Scholar [5] Yu K, Liu Y, Sharma A. Analyze the effectiveness of the
    algorithm for agricultural product delivery vehicle routing problem based on mathematical
    model. Int J Agric Environ Inf Syst (IJAEIS). 2021;12(3):26–38.10.4018/IJAEIS.2021070103Search
    in Google Scholar [6] Bu F, Wang X. A smart agriculture IoT system based on deep
    reinforcement learning. Future Gener Comput Syst. 2019;99:500–7.10.1016/j.future.2019.04.041Search
    in Google Scholar [7] Mekala MS, Viswanathan P. A novel technology for smart agriculture
    based on IoT with cloud computing. 2017 International Conference on I-SMAC (IoT
    in Social, Mobile, Analytics and Cloud)(I-SMAC), IEEE; 2017. p. 75–82.10.1109/I-SMAC.2017.8058280Search
    in Google Scholar [8] Sharma A. Recent trends in information and communication
    technologies (ICT) using emerging technologies. Recent Adv Electr ElectrEng (Former
    Recent Pat Electr ElectrEng). 2021;14(1):4–5.10.2174/235209651401201209102007Search
    in Google Scholar [9] Ferrag MA, Shu L, Yang X, Derhab A, Maglaras L. Security
    and privacy for green IoT-based agriculture: Review, blockchain solutions, and
    challenges. IEEE Access. 2020;8:32031–53.10.1109/ACCESS.2020.2973178Search in
    Google Scholar [10] Xiong H, Dalhaus T, Wang P, Huang J. Blockchain technology
    for agriculture: applications and rationale. Front Blockchain. 2020;3:7.10.3389/fbloc.2020.00007Search
    in Google Scholar [11] Vangala A, Das AK, Kumar N, Alazab M. Smart secure sensing
    for IoT-based agriculture: Blockchain perspective. IEEE Sens J. 2020.10.1109/JSEN.2020.3012294Search
    in Google Scholar [12] Verma M. Smart contract model for trust based agriculture
    using blockchain technology. Int J Res Anal Rev. 2021;8(2):354–5.Search in Google
    Scholar [13] Mistry I, Tanwar S, Tyagi S, Kumar N. Blockchain for 5G-enabled IoT
    for industrial automation: a systematic review, solutions, and challenges. Mech
    Syst Signal Process. 2020;135:106382.10.1016/j.ymssp.2019.106382Search in Google
    Scholar [14] Tripoli M, Schmidhuber J. Emerging opportunities for the application
    of blockchain in the agri-food industry. FAO and ICTSD: rome and geneva. Licence:
    CC BY-NC-SA; 2018. p. 3.Search in Google Scholar [15] Singh P, Singh N. Blockchain
    with IoT and AI: a review of agriculture and healthcare. Int J Appl Evolut Computation
    (IJAEC). 2020;11(4):13–27.10.4018/978-1-6684-7132-6.ch070Search in Google Scholar
    [16] Davcev D, Kocarev L, Carbone A, Stankovski V, Mitresk K. Blockchain-based
    distributed cloud/fog platform for IoT supply chain management. Eighth international
    conference on advances in computing, electronics and electrical technology (CEET);
    2018. p. 51–8.Search in Google Scholar [17] Leduc G, Kubler S, Georges JP. Innovative
    blockchain-based farming marketplace and smart contract performance evaluation.
    J Clean Prod. 2021;306:127055.10.1016/j.jclepro.2021.127055Search in Google Scholar
    [18] Kale S, Apte A, Raut S, Dorage S, Bhadkumbhe SM. Blockchain based smart agri-food
    supply chain management. Int J Res Engineering, Sci Manag. 2019;2(6):266–9.Search
    in Google Scholar [19] Liu Y, Sun Q, Sharma A, Sharma A, Dhiman G. Line monitoring
    and identification based on roadmap towards edge computing. Wirel personal Commun.
    2021;1–24.10.1007/s11277-021-08272-ySearch in Google Scholar [20] Sharma A, Singh
    PK, Kumar Y. An integrated fire detection system using IoT and image processing
    technique for smart cities. Sustain Cities Soc. 2020;61:102332.10.1016/j.scs.2020.102332Search
    in Google Scholar [21] Khoa TA, Man MM, Nguyen TY, Nguyen V, Nam NH. Smart agriculture
    using IoT multi-sensors: a novel watering management system. J Sens Actuator Netw.
    2019;8(3):45.10.3390/jsan8030045Search in Google Scholar [22] Sharma A, Kumar
    R. Computation of the reliable and quickest data path for healthcare services
    by using service-level agreements and energy constraints. Arabian J Sci Eng. 2019;44(11):9087–104.10.1007/s13369-019-03836-4Search
    in Google Scholar [23] Naresh M, Munaswamy P. Smart agriculture system using IOT
    technology. Int J Recent Technol Eng. 2019;7(5):98–102.Search in Google Scholar
    [24] Akram SV, Malik PK, Singh R, Anita G, Tanwar S. Adoption of blockchain technology
    in various realms: Opportunities and challenges. Security Priv. 2020;3(5):e109.10.1002/spy2.109Search
    in Google Scholar [25] Abdo JB, Zeadally S. Multi-utility framework: blockchain
    exchange platform for sustainable development. Int J Pervasive Comput Commun.
    2020.Search in Google Scholar [26] Oprunenco A, Akmeemana C. Using blockchain
    to make land registry more reliable in India. LSE Bus Rev. 2018.Search in Google
    Scholar [27] Ronaghi MH. A blockchain maturity model in agricultural supply chain.
    Inf Process Agriculture. 2021;8(3)398–408.10.1016/j.inpa.2020.10.004Search in
    Google Scholar [28] Lavanya G, Rani C, GaneshKumar P. An automated low cost IoT
    based fertilizer intimation system for smart agriculture. Sustain Comput: Inform
    Syst. 2020;28:100300.Search in Google Scholar [29] Elijah O, Orikumhi I, Rahman
    TA, Babale SA, Orakwue SI. Enabling smart agriculture in Nigeria: application
    of IoT and data analytics. 2017 IEEE 3rd Int Conf Electro-Technology Natl Dev
    (NIGERCON) IEEE. 2017;762–6.10.1109/NIGERCON.2017.8281944Search in Google Scholar
    [30] Mehta A, Patel S. IoT based smart agriculture research opportunities and
    challenges. Int J Technol Res Eng. 2016;4:541–3.Search in Google Scholar [31]
    Gill SS, Tuli S, Xu M, Singh I, Singh KV, Lindsay D, et al. Transformative effects
    of IoT, Blockchain and artificial intelligence on cloud computing: evolution,
    vision, trends and open challenges. Internet Things. 2019;8:100118.10.1016/j.iot.2019.100118Search
    in Google Scholar [32] Li X, Huang D. Research on value integration mode of agricultural
    e-commerce industry chain based on internet of things and blockchain technology.
    Wirel Commun Mob Comput. 2020;2020:2020.10.1155/2020/8889148Search in Google Scholar
    [33] García L, Parra L, Jimenez JM, Lloret J, Lorenz P. IoT-based smart irrigation
    systems: an overview on the recent trends on sensors and IoT systems for irrigation
    in precision agriculture. Sensors. 2020;20(4):1042.10.3390/s20041042Search in
    Google Scholar PubMed PubMed Central [34] Van Wassenaer L, van Hilten M, van Ingen
    E, van Asseldonk M. Applying blockchain for climate action in agriculture: state
    of play and outlook. Food & Agriculture Org; 2021.10.18174/532926Search in Google
    Scholar [35] Rahman MU, Baiardi F, Ricci L. Blockchain smart contract for scalable
    data sharing in IoT: a case study of smart agriculture. 2020 IEEE Global Conference
    on Artificial Intelligence and Internet of Things (GCAIoT), IEEE; 2020. p. 1–7.10.1109/GCAIoT51063.2020.9345874Search
    in Google Scholar [36] Shakhbulatov D, Arora A, Dong Z, Rojas-Cessa R. Blockchain
    implementation for analysis of carbon footprint across food supply chain. 2019
    IEEE International Conference on Blockchain (Blockchain), IEEE; 2019. p. 546–51.10.1109/Blockchain.2019.00079Search
    in Google Scholar [37] Anand SJ. Iot-based secure and energy efficient scheme
    for precision agriculture using blockchain and improved leach algorithm. Turkish
    J Computer Math Educ (TURCOMAT). 2021;12(10):2466–75.Search in Google Scholar
    [38] Fan M, Sharma A. Design and implementation of construction cost prediction
    model based on SVM and LSSVM in industries 4.0. Int J Intell Comput Cybern. 2021;14:145–57.10.1108/IJICC-10-2020-0142Search
    in Google Scholar [39] Kishor A, Chakraborty C. Artificial intelligence and internet
    of things based healthcare 4.0 monitoring system. Wirel Personal Commun. 2021;1–17.10.1007/s11277-021-08708-5Search
    in Google Scholar [40] Kishor A, Chakraborty C. Early and accurate prediction
    of diabetics based on FCBF feature selection and SMOTE. Int J Syst Assur Eng Manag.
    2021;1–9.10.1007/s13198-021-01174-zSearch in Google Scholar [41] Kishor A, Jeberson
    W. Diagnosis of heart disease using internet of things and machine learning algorithms.
    Proceedings of Second International Conference on Computing, Communications, and
    Cyber-Security. Singapore: Springer; 2021. p. 691–702.10.1007/978-981-16-0733-2_49Search
    in Google Scholar [42] Kishor A, Chakarbarty C. Task offloading in fog computing
    for using smart ant colony optimization. Wirel Personal Commun. 2021;1–22.10.1007/s11277-021-08714-7Search
    in Google Scholar [43] Dwivedi SK, Amin R, Vollala S. Blockchain based secured
    information sharing protocol in supply chain management system with key distribution
    mechanism. J Inf Security Appl. 2020;54:102554.10.1016/j.jisa.2020.102554Search
    in Google Scholar [44] Mukherjee AA, Singh RK, Mishra R, Bag S. Application of
    blockchain technology for sustainability development in agricultural supply chain:
    justification framework. Oper Manag Res. 2021;1–16.10.1007/s12063-021-00180-5Search
    in Google Scholar Received: 2021-11-03 Accepted: 2021-12-15 Published Online:
    2022-02-02 © 2022 Li Ting et al., published by De Gruyter This work is licensed
    under the Creative Commons Attribution 4.0 International License. Download article
    (PDF) From the journal Journal of Intelligent Systems Volume 31 Issue 1 Submit
    manuscript Journal and Issue This issue All issues Articles in the same Issue
    Research Articles Construction of 3D model of knee joint motion based on MRI image
    registration Evaluation of several initialization methods on arithmetic optimization
    algorithm performance Application of visual elements in product paper packaging
    design: An example of the “squirrel” pattern Deep learning approach to text analysis
    for human emotion detection from big data Cognitive prediction of obstacle''s
    movement for reinforcement learning pedestrian interacting model The application
    of neural network algorithm and embedded system in computer distance teach system
    Machine translation of English speech: Comparison of multiple algorithms Automatic
    control of computer application data processing system based on artificial intelligence
    A secure framework for IoT-based smart climate agriculture system: Toward blockchain
    and edge computing Application of mining algorithm in personalized Internet marketing
    strategy in massive data environment On the correction of errors in English grammar
    by deep learning Research on intelligent interactive music information based on
    visualization technology Extractive summarization of Malayalam documents using
    latent Dirichlet allocation: An experience Conception and realization of an IoT-enabled
    deep CNN decision support system for automated arrhythmia classification Masking
    and noise reduction processing of music signals in reverberant music Cat swarm
    optimization algorithm based on the information interaction of subgroup and the
    top-N learning strategy State feedback based on grey wolf optimizer controller
    for two-wheeled self-balancing robot Research on an English translation method
    based on an improved transformer model Short-term prediction of parking availability
    in an open parking lot PUC: parallel mining of high-utility itemsets with load
    balancing on spark Image retrieval based on weighted nearest neighbor tag prediction
    A comparative study of different neural networks in predicting gross domestic
    product A study of an intelligent algorithm combining semantic environments for
    the translation of complex English sentences A study on automatic correction of
    English grammar errors based on deep learning A novel fingerprint recognition
    method based on a Siamese neural network A hidden Markov optimization model for
    processing and recognition of English speech feature signals Crime reporting and
    police controlling: Mobile and web-based approach for information-sharing in Iraq
    CRNet: Context feature and refined network for multi-person pose estimation Improving
    the efficiency of intrusion detection in information systems Research on reform
    and breakthrough of news, film, and television media based on artificial intelligence
    An optimized solution to the course scheduling problem in universities under an
    improved genetic algorithm An adaptive RNN algorithm to detect shilling attacks
    for online products in hybrid recommender system Computing the inverse of cardinal
    direction relations between regions An improved Jaya optimization algorithm with
    ring topology and population size reduction Review Articles A review on voice
    pathology: Taxonomy, diagnosis, medical procedures and detection techniques, open
    challenges, limitations, and recommendations for future directions An extensive
    review of state-of-the-art transfer learning techniques used in medical imaging:
    Open issues and challenges Special Issue: Explainable Artificial Intelligence
    and Intelligent Systems in Analysis For Complex Problems and Systems Tree-based
    machine learning algorithms in the Internet of Things environment for multivariate
    flood status prediction Evaluating OADM network simulation and an overview based
    metropolitan application Radiography image analysis using cat swarm optimized
    deep belief networks Comparative analysis of blockchain technology to support
    digital transformation in ports and shipping IoT network security using autoencoder
    deep neural network and channel access algorithm Large-scale timetabling problems
    with adaptive tabu search Eurasian oystercatcher optimiser: New meta-heuristic
    algorithm Trip generation modeling for a selected sector in Baghdad city using
    the artificial neural network Trainable watershed-based model for cornea endothelial
    cell segmentation Hessenberg factorization and firework algorithms for optimized
    data hiding in digital images The application of an artificial neural network
    for 2D coordinate transformation A novel method to find the best path in SDN using
    firefly algorithm Systematic review for lung cancer detection and lung nodule
    classification: Taxonomy, challenges, and recommendation future works Special
    Issue on International Conference on Computing Communication & Informatics Edge
    detail enhancement algorithm for high-dynamic range images Suitability evaluation
    method of urban and rural spatial planning based on artificial intelligence Writing
    assistant scoring system for English second language learners based on machine
    learning Dynamic evaluation of college English writing ability based on AI technology
    Image denoising algorithm of social network based on multifeature fusion Automatic
    recognition method of installation errors of metallurgical machinery parts based
    on neural network An FCM clustering algorithm based on the identification of accounting
    statement whitewashing behavior in universities Emotional information transmission
    of color in image oil painting College music teaching and ideological and political
    education integration mode based on deep learning Behavior feature extraction
    method of college students’ social network in sports field based on clustering
    algorithm Evaluation model of multimedia-aided teaching effect of physical education
    course based on random forest algorithm Venture financing risk assessment and
    risk control algorithm for small and medium-sized enterprises in the era of big
    data Interactive 3D reconstruction method of fuzzy static images in social media
    The impact of public health emergency governance based on artificial intelligence
    Optimal loading method of multi type railway flatcars based on improved genetic
    algorithm Special Issue: Evolution of Smart Cities and Societies using Emerging
    Technologies Data mining applications in university information management system
    development Implementation of network information security monitoring system based
    on adaptive deep detection Face recognition algorithm based on stack denoising
    and self-encoding LBP Research on data mining method of network security situation
    awareness based on cloud computing Topology optimization of computer communication
    network based on improved genetic algorithm Implementation of the Spark technique
    in a matrix distributed computing algorithm Construction of a financial default
    risk prediction model based on the LightGBM algorithm Application of embedded
    Linux in the design of Internet of Things gateway Research on computer static
    software defect detection system based on big data technology Study on data mining
    method of network security situation perception based on cloud computing Modeling
    and PID control of quadrotor UAV based on machine learning Simulation design of
    automobile automatic clutch based on mechatronics Research on the application
    of search algorithm in computer communication network Special Issue: Artificial
    Intelligence based Techniques and Applications for Intelligent IoT Systems Personalized
    recommendation system based on social tags in the era of Internet of Things Supervision
    method of indoor construction engineering quality acceptance based on cloud computing
    Intelligent terminal security technology of power grid sensing layer based upon
    information entropy data mining Deep learning technology of Internet of Things
    Blockchain in distribution network faults Optimization of shared bike paths considering
    faulty vehicle recovery during dispatch The application of graphic language in
    animation visual guidance system under intelligent environment Iot-based power
    detection equipment management and control system Estimation and application of
    matrix eigenvalues based on deep neural network Brand image innovation design
    based on the era of 5G internet of things Special Issue: Hybrid Fuzzy Systems
    for Mobile Robots and Their Applications IoT-enabled edge computing model for
    smart irrigation system Convex optimization for additive noise reduction in quantitative
    complex object wave retrieval using compressive off-axis digital holographic imaging
    Special Issue: Cognitive Cyber-Physical System with Artificial Intelligence for
    Healthcare 4.0. Auxiliary diagnosis study of integrated electronic medical record
    text and CT images A hybrid particle swarm optimization with multi-objective clustering
    for dermatologic diseases diagnosis An efficient recurrent neural network with
    ensemble classifier-based weighted model for disease prediction Design of metaheuristic
    rough set-based feature selection and rule-based medical data classification model
    on MapReduce framework Special Issue: Human-Centred Artificial Intelligence for
    Web 4.0 Construction of an IoT customer operation analysis system based on big
    data analysis and human-centered artificial intelligence for web 4.0 Human-centered
    artificial intelligence-based ice hockey sports classification system with web
    4.0 Subjects Architecture and Design Arts Asian and Pacific Studies Business and
    Economics Chemistry Classical and Ancient Near Eastern Studies Computer Sciences
    Cultural Studies Engineering General Interest Geosciences History Industrial Chemistry
    Islamic and Middle Eastern Studies Jewish Studies Law Library and Information
    Science, Book Studies Life Sciences Linguistics and Semiotics Literary Studies
    Materials Sciences Mathematics Medicine Music Pharmacy Philosophy Physics Social
    Sciences Sports and Recreation Theology and Religion Services For Journal Authors
    For Book Authors For Librarians Rights & Permissions Publications Publication
    types Open Access About Contact Career About De Gruyter Partnerships Press FAQs
    Social Facebook Instagram LinkedIn Twitter YouTube Winner of the OpenAthens Best
    Publisher UX Award 2022  Help/FAQ Privacy policy Cookie Policy Accessibility Terms
    & Conditions Legal Notice © Walter de Gruyter GmbH 2024 Consent to website analysis
    We use cookies and other technologies. Some of them are necessary for the website
    to function and are always set. Cookies for website analysis are not required
    and are set only with your consent. Some services for analysis process personal
    data in the USA. With your consent to use these services, you also consent to
    the processing of your data in the USA. Your consent is voluntary and can be revoked
    at any time. For more information, please see our Cookie Policy. Accept optional
    analytics cookies Reject non-essential cookies"'
  inline_citation: '>'
  journal: Journal of Intelligent Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'A secure framework for IoT-based smart climate agriculture system: Toward
    blockchain and edge computing'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Yu X.Y.
  - Guo X.H.
  citation_count: '3'
  description: The intelligent agriculture monitoring is based on the perception and
    analysis of environmental data, which enables the monitoring of the production
    environment and the control of environmental regulation equipment. As the scale
    of the application continues to expand, a large amount of data will be generated
    from the perception layer and uploaded to the cloud service, which will bring
    challenges of insufficient bandwidth and processing capacity. A fog-based offline
    and real-time hybrid data analysis architecture was proposed in this paper, which
    combines offline and real-time analysis to enable real-time data processing on
    resource-constrained IoT devices. Furthermore, we propose a data process-ing algorithm
    based on the incremental principal component analysis, which can achieve data
    dimensionality reduction and update of principal components. We also introduce
    the concept of Squared Prediction Error (SPE) value and realize the abnormal detection
    of data through the combination of SPE value and data fusion algorithm. To ensure
    the accuracy and effectiveness of the algorithm, we design a regular-SPE hybrid
    model update strategy, which enables the principal component to be updated on
    demand when data anomalies are found. In addition, this strategy can significantly
    reduce resource consumption growth due to the data analysis architectures. Practical
    datasets-based simulations have confirmed that the proposed algorithm can perform
    data fusion and exception processing in real-time on resource-constrained devices;
    Our model update strategy can reduce the overall system resource consumption while
    ensuring the accuracy of the algorithm.
  doi: 10.3837/tiis.2020.10.004
  full_citation: '>'
  full_text: '>

    "KSII Transactions on Internet and Information Systems Monthly Online Journal
    (eISSN: 1976-7277) ABOUT HOT DOWNLOADED PAPERS EDITORIAL BOARD DIGITAL LIBRARY
    INFORMATION SPECIAL ISSUES SUBMIT MANUSCRIPT Data anomaly detection and Data fusion
    based on Incremental Principal Component Analysis in Fog Computing Xue-Yong Yu,
    Xin-Hui Guo, Vol. 14, No. 10, October 31, 2020 10.3837/tiis.2020.10.004, Download
    Paper (Free): Incremental Principal Component Analysis Offline and real-time learning
    Fog Computing Data anomaly detection  ABSTRACT The intelligent agriculture monitoring
    is based on the perception and analysis of environmental data, which enables the
    monitoring of the production environment and the control of environmental regulation
    equipment. As the scale of the application continues to expand, a large amount
    of data will be generated from the perception layer and uploaded to the cloud
    service, which will bring challenges of insufficient bandwidth and processing
    capacity. A fog-based offline and real-time hybrid data analysis architecture
    was proposed in this paper, which combines offline and real-time analysis to enable
    real-time data processing on resource-constrained IoT devices. Furthermore, we
    propose a data process-ing algorithm based on the incremental principal component
    analysis, which can achieve data dimensionality reduction and update of principal
    components. We also introduce the concept of Squared Prediction Error (SPE) value
    and realize the abnormal detection of data through the combination of SPE value
    and data fusion algorithm. To ensure the accuracy and effectiveness of the algorithm,
    we design a regular-SPE hybrid model update strategy, which enables the principal
    component to be updated on demand when data anomalies are found. In addition,
    this strategy can significantly reduce resource consumption growth due to the
    data analysis architectures. Practical datasets-based simulations have confirmed
    that the proposed algorithm can perform data fusion and exception processing in
    real-time on resource-constrained devices; Our model update strategy can reduce
    the overall system resource consumption while ensuring the accuracy of the algorithm.  STATISTICS
    Show / Hide Statistics      CITE THIS ARTICLE [IEEE STYLE] X. Yu and X. Guo, \"Data
    anomaly detection and Data fusion based on Incremental Principal Component Analysis
    in Fog Computing,\" KSII Transactions on Internet and Information Systems, vol.
    14, no. 10, pp. 3989-4006, 2020. DOI: 10.3837/tiis.2020.10.004.  [ACM STYLE] Xue-Yong
    Yu and Xin-Hui Guo. 2020. Data anomaly detection and Data fusion based on Incremental
    Principal Component Analysis in Fog Computing. KSII Transactions on Internet and
    Information Systems, 14, 10, (2020), 3989-4006. DOI: 10.3837/tiis.2020.10.004.  [BIBTEX
    STYLE] @article{tiis:23916, title=\"Data anomaly detection and Data fusion based
    on Incremental Principal Component Analysis in Fog Computing\", author=\"Xue-Yong
    Yu and Xin-Hui Guo and \", journal=\"KSII Transactions on Internet and Information
    Systems\", DOI={10.3837/tiis.2020.10.004}, volume={14}, number={10}, year=\"2020\",
    month={October}, pages={3989-4006}} UNIFIED SEARCH (in Title, Author, Abstract,
    and Keywords) CATEGORY SEARCH Title  Author  Abstract  Keywords  DOI  Search  KSII
    Transactions on Internet and Information Systems © 2007~Present, KSII. All Rights
    Reserved."'
  inline_citation: '>'
  journal: KSII Transactions on Internet and Information Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Data anomaly detection and Data fusion based on Incremental Principal Component
    Analysis in Fog Computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Mani Sekhar S.R.
  - Tewari S.
  - Rahman H.
  - Siddesh G.M.
  citation_count: '1'
  description: As the amount of real-time data is increasing rapidly, the computation
    of these data is a challenging task. These data are being produced by billions
    of IoT devices in the world and processed in the cloud. Meanwhile, around two
    quintillion bytes of information are collected every hour and are predicted to
    rise exponentially in the following years. The restrictions of efficiency, storage
    capacity and security of the end devices in the cloud lead to a new indispensable
    computing paradigm named as ‘Fog Computing.’ In this chapter we try to assimilate,
    the need to collect and manage data, how data differs in different scenarios and
    the various methods implemented at present to collect data such as node-based
    segregation which reduces the requirement of a large number of fog nodes to be
    set up and overloading of these nodes. Exploring techniques wherein raw and passive
    forms of data can be made to evolve and become meaningful with reduced size, understanding
    how bluetooth low energy technology can be used to process collected data through
    gateways and usage of data collectors with wireless low powered sensing systems.
    Finally, the chapter discusses fifteen case studies related to Moving Vehicles,
    Industrial Automation, Underwater Data Collection Water Conservation in Agriculture,
    Indoor Air Quality Monitoring, Health Monitoring System, Telehealth Big Data and
    Healthcare 4.0 related to data analytics by incorporating Cloud, Fog and IoT.
  doi: 10.1007/978-981-15-6044-6_5
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Fog Data Analytics for IoT Applications
    pp 79–104Cite as Home Fog Data Analytics for IoT Applications Chapter Data Collection
    in Fog Data Analytics S. R. Mani Sekhar, Snehil Tewari, Haaris Rahman & G. M.
    Siddesh  Chapter First Online: 26 August 2020 426 Accesses 2 Citations Part of
    the book series: Studies in Big Data ((SBD,volume 76)) Abstract As the amount
    of real-time data is increasing rapidly, the computation of these data is a challenging
    task. These data are being produced by billions of IoT devices in the world and
    processed in the cloud. Meanwhile, around two quintillion bytes of information
    are collected every hour and are predicted to rise exponentially in the following
    years. The restrictions of efficiency, storage capacity and security of the end
    devices in the cloud lead to a new indispensable computing paradigm named as ‘Fog
    Computing.’ In this chapter we try to assimilate, the need to collect and manage
    data, how data differs in different scenarios and the various methods implemented
    at present to collect data such as node-based segregation which reduces the requirement
    of a large number of fog nodes to be set up and overloading of these nodes. Exploring
    techniques wherein raw and passive forms of data can be made to evolve and become
    meaningful with reduced size, understanding how bluetooth low energy technology
    can be used to process collected data through gateways and usage of data collectors
    with wireless low powered sensing systems. Finally, the chapter discusses fifteen
    case studies related to Moving Vehicles, Industrial Automation, Underwater Data
    Collection Water Conservation in Agriculture, Indoor Air Quality Monitoring, Health
    Monitoring System, Telehealth Big Data and Healthcare 4.0 related to data analytics
    by incorporating Cloud, Fog and IoT. Keywords Data Data collection Fog computing
    Data analytics Methods of data collection Fog data analytics Access provided by
    University of Nebraska-Lincoln. Download chapter PDF 1 Introduction Data is a
    collection of facts, figures, observations, or a description of things. The term
    data and information are often used interchangeably, though there is a subtle
    difference. Data is raw and unorganized, which can seem random and futile until
    it is organized. When data is structured, processed and presented in a given context
    to make it useful, it is called information. Data is information that is transformed
    into a form that can be moved and analyzed. Data can be classified into three
    categories. Firstly, structured data is the data that can be organized into a
    typical database, i.e. and it can be stored in a table with rows and columns.
    This data can be searched efficiently by human queries or machine algorithms.
    Names, addresses, etc. come under structured data. Unstructured data do not conform
    to any data model. They have internal structure but lack an easily identifiable
    structure, resulting in certain difficulties such as searching and indexing the
    data. Computer programs cannot make use of this data easily. Text, audio, and
    video information, logs, and web activity are part of unstructured data. Semi-structured
    data fits in between structure and unstructured data. They maintain internal tags
    and markings but do not conform to a data model. These organizational properties
    make them easier to analyze by humans but not machines. XML, emails and JSON files
    are few such examples. Data collection is a methodical approach to accumulate
    and regulate information to get a definite understanding of an area of interest.
    Data Collection empowers a person or an institution to answer relevant questions,
    reduce risks incurred due to insufficient data, predict and assess outcomes, understand
    and set new trends. Overall, it gives new insights and a cutting edge over the
    competitors, whereas in the absence of data collection, the companies will still
    have to use the outdated methods to make decisions. Data collected can vary from
    personal data such as demographics, contact details and other identifying factors
    to web data, which comprises any information pulled off from the internet for
    research purposes or otherwise. Most of the data collected is in electronic form;
    hence the size of the collected data is humongous. As a result, this crosses into
    the realm of big data. The fast and steady collection of data in the last two
    decades and the growth of IoT devices over the last couple of years has led to
    a surge in data. Due to this, the term ‘Big Data’ was coined in mid-2005. Any
    huge amount of data structured or unstructured, which must be organized, stocked
    and processed, can be referred to as Big Data, and the metric frequently used
    is with regard to petabytes and exabytes. Data Mining is very often used to collect
    big data, and it is used to decipher patterns and correlations for IoT applications.
    It has been observed that mining data for frequent and repeated patterns have
    been more useful than the regular computing methods. Big data gives intuition
    that helps to make better decisions and strategic business moves. It allows the
    B2C companies to broaden their horizon and prosper by changing the marketing strategies
    and implement new changes with concrete analysis of data to support it. The traditional
    databases cannot monitor big data, and therefore, new computing methods have emerged,
    such as cloud computing, fog computing and quantum computing. The term fog is
    used as an analogy to the real-world fog, and it is a layer between the clouds
    and the ground, which here in our case will be the cloud storage and the IoT devices,
    respectively. Fog computing has a decentralized architecture wherein it has edge
    nodes that have the power to compute loads of data without sending it to distant
    servers. Because of this proximity within the devices, fog computing grants control
    and real-time services and analysis. It facilitates computing near the users and
    provides data security and safety over data leakages. In layman terms, fog nodes
    or gateways are used to crunch through the data and send only the required data
    to the cloud. The remainder of the chapter is organized as follows. Section 2
    highlights the general methods of data collection by various sources and how fog
    computing plays a vital role in data collection. Section 3 explains how optimized
    compression of data can reduce the traffic congestion in the network. Section
    4 gives insights that are helpful in effectively collecting and managing big data.
    Section 5 discusses various case studies in crucial fields such as healthcare,
    agriculture, automation, etc. Section 6 summarizes the data collection methods
    in Fog Data Analytics and concludes the chapter. 2 Methods of Collecting Data
    Over the last few years, there has been an explosion of data from different fields
    through various sources. Data is being collected at a massive rate and pace by
    people and organizations to create a user-friendly environment, perform research
    and increase profits. Some of the ways to collect data are Website visits—A company
    needs to understand user behaviour and traffic on their websites. They use various
    web analytics tools that are available in the market, such as Google Analytics,
    IBM Unica NetInsight, Webtrends Analytics, etc. The website owner, with the aid
    of these tools, collects and visualizes the statistics and perceives the user’s
    activity on the site. This is done in order to understand the different patterns
    in which the user tries to search and access specific choices available throughout
    the website, which is very helpful, for example, in creating a recommender system,
    which makes the website easy to access and saves time. Also, heatmaps can be used
    to track the cursor movements, scrolling areas, and time spent on certain sections.
    Mobile Applications—According to some of the research groups, it is found out
    that as of now, there are approximately 3 million apps present in the play store
    created by Google. These apps can share the information available on mobile phones
    with Google and other third parties. This information can range from the location
    of the user and the nearest phone towers to personal information such as date
    of birth, gender, contact numbers, email ID, etc. The business of advertising
    and data sharing has skyrocketed in recent times and needs to be monitored efficiently.
    Loyalty Programs—It is tougher to maintain a customer base than acquiring the
    customers for the first-time. If not handled and serviced correctly, a customer
    might not return back to the brand/company next time, and thus, to keep the customer’s
    relationship with the brand intact, loyalty programs are used. To be loyal to
    the brand, the user is given offers, discounts, first-access, etc. in return for
    personal information. Sensors—Sensor data is generated by the active gadgets in
    our smart environment and is often associated with the term Internet of Things
    (IoT). This covers everything from counting a number of steps travelled using
    motion or activity trackers, measuring heart rate and pulse, to measuring temperature
    and weather using sensors. Sensor data is generally used for the optimization
    of processes, and machines can adapt to its surroundings by making smart changes.
    For example—Air Asia, in collaboration with GE aviation, uses sensors with IoT
    complemented by AI to cut down its operating costs and boost usage and profits.
    Fog layer acts as a link between the IoT devices and the cloud. Huge amounts of
    data are being generated every day and to deal with the drawbacks of cloud computing,
    it is very important to not only focus on data management, storage, processing,
    analyzing and monitoring but also focus on data collection. If devices are able
    to judge which data is useful and which is redundant or useless, then a lot of
    data will get filtered at the initial layers of networking and computing resulting
    in the intake of data for processing to be reduced by a very significant extent.
    Fog Computing plays a very crucial role in achieving efficient management of data.
    It filters out redundant data and prioritizes the processing of time-sensitive
    data. Data is harvested from the physical environment with the help of sensors
    which are placed in gadgets or IoT devices referred to as Fog devices [25]. A
    number of these devices are connected to large servers of higher configurations
    and the fog devices which are connected to the same server can also interact with
    each other. The efficiency and throughput while processing data and rendering
    the services requested in real-time depends on several factors such as the number
    of linked devices to a server, bandwidth, connectivity of the devices, etc. After
    the necessary evaluations, data is either filtered out or sent to higher levels
    for complex and expensive computation or storage purposes. 3 Optimized Collection
    of Compressive Data Traditional methods of information gathering in wireless sensor
    networks faced many challenges. The sensor data used to be collected continuously
    and stored at a local node. This data would then be forwarded to a central base
    station at regular intervals of time. As a result, this used to congest the entire
    network leading to inefficient data transfer and larger energy consumption [1].
    The need for optimized compression and collection of data was required. According
    to the study by [2], there exist three main categories of schemes used for data
    collection. The first method is that of collecting the critical data or compression
    of original data, and then reconstructing the original data by numerical analysis
    and interpolation techniques [3]. Reconstruction of data results in additional
    energy and time consumption. To solve this issue, an algorithm was developed,
    which reduces the redundancy of data by using the strong correlation among sensory
    data in temporal and spatial spaces [4]. The second method tries to solve the
    efficiency problem by creating advanced routing algorithms and balancing the load
    on the entire network [5, 6]. The final method implements a compressed sensing
    theory where data has a property called sparseness in the transformation process,
    which allows the data to be reconstructed with much fewer samples than Nyquist
    theory [7]. Other methods include collecting data at various time instances, storing
    it in a matrix form, and applying a singular value decomposition technique to
    achieve good compression of the data by choosing the number of singular values
    to be retained without losing out on information [8]. 4 Management of Big Data
    The field of Information Technology has seen a colossal amount of inventions and
    innovations, technological changes, the introduction of tech gadgets and much
    more in the last two decades, and there are no qualms in acknowledging the fact
    that data has become one of the most crucial and fundamental elements of this
    astronomical realm. Therefore, it is important to have an outlook for smart management
    of data, especially big data, to save space and time instead of only focusing
    on computing platforms. The smart management of data leads off from an efficient
    collection of data at the very beginning, and Fog Computing can play a major role
    in achieving it. The data collected from the sensors and several other gadgets
    and devices are transformed from their natural and bland form to an ingenious
    form of data cells that is more substantial in terms of valuable information and
    is also a systematic way of minimizing the load of big data [9]. As soon as the
    data generated from the sensors is collected, then and there, it is processed
    in the local fog, and more relevant data with less velocity and volume is forwarded
    to the cloud for global processing and storage. This also helps in reducing latency
    and communication overhead. 5 Case Studies The following section presents case
    studies discussing how data is collected in various industries such as automotive,
    agriculture and healthcare, etc. in different environment settings and how data
    collected from individuals is utilized in different scenarios. 5.1 Data Collection
    in Moving Vehicles In today’s data-centric world, vehicles are being equipped
    with different kind of instruments. These instrument or sensors provide data such
    as GPS location, vehicle speed, video data, the status of various parts of the
    vehicle and chemical emissions. The data is then used for applications like intelligent
    transportation systems, emergency response systems, traffic monitoring and pollution
    analysis. With the development of the vehicle industry and wireless communication
    technology, the vehicular ad-hoc networks (VANETs) were created. The system mainly
    comprises of an onboard unit (OBU), application unit (AU) and roadside unit (RSU)
    [10]. The OBU is generally mounted on a vehicle for exchanging information with
    RSUs or other OBUs. The AU is a device placed within the vehicle that communicates
    the information with the net via the OBU, which is responsible for all mobile
    and networking function, The RSU is fixed along the roadside or at strategic locations
    for short-range communication. The RSUs extend the transmission range of the network
    by forwarding the data to other OBUs and RSUs and provide internet connectivity
    to the OBUs as well. But VANETs also face various challenges such as signal fading
    due to obstacles between two communication vehicles, bandwidth limitations, connectivity
    due to rapid changes of topology and inefficient routing protocols. To overcome
    these challenges, the concept of fog computing is extended to VANETs. This enhances
    the chances for the optimization of the data gathering process. In [11], a data
    gathering framework based on fog computing (DAFOC) was proposed. Figure 1 shows
    a three-layer data collection framework and analytics involved in each layer.
    The framework intuitively varies the threshold to upload suitable amounts of data
    based on congestion in the network and suppresses unnecessary message transmissions.
    The RSUs in the DAFOC frameworks behave as fog nodes that provide computation
    and storage capabilities among the vehicles. The vehicles have sensors that operate
    on two modes: low-cost sensing (LCS) mode and high-cost sensing (HCS) mode. The
    nodes on LCS mode perceive the environment and produce data at a fairly slow rate.
    The RSUs evaluates the confidence of data and initiates an event validating procedure
    when the confidence is high. Based on this event check, the nodes in HCS mode
    sense more detailed data about the environment. This detailed data is sent to
    the RSU for final event verification where the data may well be advanced to a
    neighbouring node, or another RSU or the cloud directly. This information is processed
    in the cloud, and the decision/feedback is sent back to the RSU. This method lowers
    the overall power requirement of the nodes by implementing the two modes of operation
    and using each mode as and when required. Also, it minimizes unnecessary data
    upload and transmission and reduces transmission costs. Fig. 1 Three-layer architecture
    for data gathering system [11] Full size image 5.2 Fog Computing in Industrial
    Automation Following the trend towards industry 4.0 and cyber-physical organizations,
    the industrial Internet of Things (IIoT) has started taking off. The adoption
    of IIoT is changing industrial automation and leading to greater connectivity
    among industrial systems. Data collected from IIoT applications, such as scheduling
    of paths for industrial robots and manufacturing monitoring, requires real-time
    processing of data, including computing architectures that support low latency
    and efficient response. Cloud computing and IoT have a hand in hand relation.
    The cloud acts as a pathway for the massive amounts of data generated from the
    IoT. But the cloud centres are usually remote, which leads to latency in the transmission
    of data. To offer small latency and positional cognizance for the systems, fog
    computing is adopted in IIoT. A generic framework of fog computing in an industrial
    environment [12], consists of three-layers: things layer, fog layer and distributed
    cloud layer. All the machinery and equipment utilized in the industry are part
    of the things layer. They generate data that has to be managed based on the particular
    request by a certain application. The fog layer includes network devices such
    as routers and gateways to process time-sensitive data since they are closer to
    the things layer. Wired or wireless means of communication can be used with the
    former layer. High-end computing servers form the basis of the distributed cloud
    layer and perform data-intensive computations. This layer uses cellular communication
    or broadband networks to communicate with the fog layer. The communication between
    layers can be performed in numerous ways. The first method involves the IIoT machinery
    to generate data and send requests to the fog nodes for either processing at the
    fog nodes or at the cloud. These fog nodes analyze the requests and transmit the
    results to other fog or cloud nodes. If the workload is light or processing of
    data in real-time is required, the data is sent to the fog nodes. Otherwise, it
    is sent to the cloud. If the data has been sent to the cloud, the clouds nodes
    process the requests, and the results are retrieved by the IIoT nodes. The majority
    of the data is global information for the industry, which is stored in the cloud
    for global data sharing. The second method, unlike the first, performs the tasks
    individually but finally collaborate to complete the tasks in a distributed manner.
    This method demands optimal task allocation since the system is distributed over
    nodes but compensates for the limited computational powers of fog nodes. The final
    method is a multi-tier model that contains two fog layers. The fog layers can
    be of the same or different interaction modes that are centralized or distributed.
    Computationally inexpensive tasks are handled in tier-1, whereas computationally
    demanding tasks can be handled in tier-2. The cloud nodes handle the most demanding
    tasks. In the centralized model, a master node and several fog nodes are present
    at each domain in the fog node. The master node receives the estimated request
    time from each fog node and determines the fog nodes which are idle to perform
    the requested task based on the network conditions, whereas the distributed interaction
    mode does not require a master node. Using a distributed communication protocol,
    the fog nodes communicate with each other. The fog nodes maintain certain variables
    such as waiting time, which are updated in a condition table. The fog nodes choose
    suitable neighbouring nodes for the offloading of tasks. The centralized model
    can be simple to deploy but is prone to single-link failure. That is, if the master
    node fails, the entire system will come to a halt. The distributed mode is not
    vulnerable to single-link failure, but the implementation of a distributed protocol
    is complex, and task distribution is complicated. 5.3 Collection of Data Under
    Water Underwater acoustic sensor networks (UASNs) has been widely accepted for
    data collection schemes underwater. UASNs find applications in ocean disaster
    deterrence, military defence, assisted navigation, monitoring of aquatic life,
    coastline surveillance and protection and resource explorations. These applications
    generate enormous amounts of data such as high-definition video, audio and pictures.
    However, these networks face several issues such as low propagation speed, multipath
    effect and Doppler spread due to the acoustic signals. Therefore, these data collection
    schemes cannot be applied to underwater environment directly and the concept of
    fog computing was extended to these networks. In [13], a fog computing-based,
    four-layer network of underwater sensor cloud system was proposed as depicted
    in Fig. 2. The sensors/nodes in the physical layer have limited storage and computation
    capacities. Fig. 2 Underwater sensor cloud system Full size image They are equipped
    with antennas and are either anchored to the bottom of the ocean or made to float
    at certain depth with the help of buoys. They only sense the data and direct the
    collected information to suitable fog nodes. These fog nodes, in the fog layer,
    have large storage capacities and are computationally stronger than the nodes
    in the physical layer. The main purpose of the fog nodes is to perform localised
    computation on the data received from the physical nodes by discarding redundant
    data, extracting key information and dimensionality reduction of the data. Based
    on this information, the fog nodes, which are generally mobile nodes, make it
    to the surface to distribute the data to nodes in the sink layer if data is delay-insensitive
    or by the transmission of data to sink nodes through multi-hop mode with the help
    of several other above-level mobile fog nodes. The sink nodes in sink layer transmit
    the information to the cloud computing centre by radio signals after data fusion
    operation. This novel method helps to reduce communication delay between the nodes
    and minimize overall energy consumption in the network. 5.4 Water Conservation
    in Agriculture Using Fog and IoT Water is the basic necessity for the survival
    of all living things on Earth. It is essential for ensuring food security to the
    world’s inhabitants. Agriculture is the largest consumer of water accounting to
    about 70% of freshwater. The quality of water is important for physical health
    and fitness. Lack of water or usage of contaminated water can lead to serious
    health problems. The major grounds of water wastage are leakages in pipelines
    during distribution and the use of primitive irrigation method, surface irrigation,
    by drenching areas where no crops can profit from which depletes an enormous portion
    of water. Hence, a smart water management platform is required to sense the amount
    of water required by the agricultural crops and regulate the flow of water to
    where it is required the most. The SWAMP project was undertaken to incorporate
    IoT based solutions for smart water management by monitoring the field based on
    crop status and environment, the condition of the crop and to alter the irrigation
    plot accordingly [14]. The SWAMP system is classified into five layers IoT Services/Sensing
    Layer: A variety of sensors and actuators are utilized to acquire data on soil,
    plant (vegetation index, canopy temperature), weather and precipitation levels.
    The SWAMP pilots use commercial sensors such as drones to take images, as well
    as homemade multiparametric sensor probes [15]. Data Acquisition, Security and
    Management: Distributed databases consisting of cloud and fog nodes work in conjunction
    with each other to deal with large amounts of data coming from the sensing layer.
    Protocols and software for data acquisition along with security are the focus
    of this layer, Data analytics: Analysis of big data is performed in the cloud.
    SWAMP utilizes prevailing algorithms and models. A distributed infrastructure
    of cloud servers and fog nodes are utilized to make the data available to upper
    layers. Management of information: Builds upon application middleware protocols
    in addition to the data analytics facilities in layer 3. This layer acts as an
    API for the final layer. Application Layer: The data that is collected is altered
    into information that is useful to the agriculturalists via user interfaces. The
    SWAMP project has ensured that the layers are generic so as to be adjustable to
    other environmental settings. Layers 1, 2 and 3 are sufficiently elementary to
    be replicable in a variety of settings, whereas layer 4 is a fully customisable
    layer which may need customisation for every deployment. Methodologies in Layer
    5 are application-specific. SWAMP is still in its initial stages, though pilots
    have proven to be successful. 5.5 IoT Implementation for Collection of Data Using
    QR Codes Some specific objects are recognized by using videos which store data
    on the internet. This implementation of IoT model is built on algorithms executed
    in the OpenCV library for python to identify or recognize the objects and use
    Raspberry PI to pile-up the data accumulated from the surrounding. The distinct
    and specific hardware and software used can collectively be called a module [16].
    Every time when there is an object detection the module sends a request to the
    web application. The communication which involves these modules take place through
    HTTP communication and thus, there is a need for active connection to the internet.
    This web application is responsible for storing, monitoring and controlling of
    the data of the objects. In the recent few years, camera monitoring systems have
    become very common and it is observed that a substantial amount of information
    is not being used efficiently. Quick Response Codes, better known as the QR Codes,
    holds the potential to become one of the most intriguing ways of acknowledging
    the recognition of labels or marks, considering the fact that 2D type bar codes
    which are most widely used, encodes alphanumeric characters that have lots of
    information and possible applications. Each QR code is structured in a way so
    that it encompasses data, a code to correct the encountered errors and some orientation
    patterns. The system proposed for implementation can be classified into three-layers,
    as Database Model, Web API and Web Application and the camera module. The system
    enables the user to keep track of the location of an entity at some specific point
    in time. Artificial vision is the most prominent part of this IoT implementation,
    the usual impediments faced are the quality of the camera, the number of frames
    per second and the distinctness of the object. Basically, modules are created
    by the users to gather data and transmit the required information about the respective
    objects in order to dispense that information to all the members of the pool.
    This pool behaves as a reference for the data showcased and also for the upcoming
    data from the modules, hence the pools happen to be the most important since all
    of the data is stacked and registered using a referral or labels. Eventually,
    the user will have contemporary information about various objects. For example,
    this technology can be used to identify vehicles going in and out of a facility
    per day. The facility centre will share the data and the outcome will be available
    to the owner of the car. 5.6 Indoor Air Quality Monitoring Using IoT and Fog With
    the rapid growth of industrialisation and urbanization, the level of pollution
    in the environment has been increasing at an exponential rate. This pollution
    affects the day to day life and quality of living of an individual. Environmental
    pollution can be of air, water or land pollution. Air pollution stands out as
    one of the more prominent forms of pollution as it affects the health conditions
    of people at a larger scale. People today are spending more time indoors (homes,
    offices, work related areas) than outdoors. Due to the rising demand for automation,
    at home and offices, consequently, there has been an increase in the usage of
    electronic devices which have been found to emit many harmful gases and radiations.
    Hence indoor air quality monitoring has become of utmost importance. An IoT enabled
    indoor air quality monitoring system was proposed by [17]. The IoT device/sensor
    samples the air at constant intervals of time. The data was transferred to an
    intermediate node via Bluetooth. This intermediate node then communicates with
    the processing node through Wi-Fi. An alarm was raised whenever the pollution
    level was raised beyond a certain limit. This idea was further improved on by
    [18], as they developed an air monitoring device with the underlying architecture
    strongly formed on the concepts of fog computing. A three-layered approach was
    taken in this system designed as the sensing layer, network layer and application
    layer. The layers communicated with each other through Wi-Fi. The sensing layer
    was the backbone of the entire system. It was used to sense the air quality and
    was deployed over the wide area. The sensing model comprised of the sensor chunk,
    processing unit, communication module and power module. The sensor block consisted
    of various sensors to detect the different types of pollutants and the processing
    module was used to process the raw data from the sensors. The fog computing layer
    used to gather the data from all the sensing layers and passed the data to the
    application layer after necessary processing. The application layer receives data
    from the fog device and provides data visualization either through the website
    or mobile application. The entire model was considered with the sole aim to minimize
    the redundant network traffic, reduce overall power consumption and reduce the
    computational burden on the sensing nodes. With the help of this huge volume of
    data collected and processed, useful messages were generated and sent to the people
    within the confined spaces to raise alerts and create awareness. 5.7 Emotional
    Profiles With the passage of time, people have become more aware of health and
    fitness, and thus many new models have been proposed and developed to apprehend
    the affective state of individuals. More detailed 24/7 calibrated monitoring helps
    to delve deeper into the internal and external worlds experienced by human beings
    [19]. Data such as anatomical signals, speech and facial expressions help to behold
    and assimilate the affective states [20]. This category of data can be accumulated
    effortlessly, with the help of the sensors embedded in today’s smart devices such
    as smartwatches, smart glasses, motion or activity trackers, smartphones, etc.
    Because of the widespread popularity of these devices and their use by the common
    people, there arises an opportunity to develop the existing unorthodox techniques
    to recognize and analyze the various states experienced by the subject and for
    what reason they occur. Also, collecting and analyzing data of this class can
    be helpful in identifying the cause of various emotions, and then based on the
    outcome suggest actions to be taken to deal with them. These devices (smartphones,
    laptops, etc.) are recognized as IoT nodes and are interconnected to each other
    with the help of the internet and other technologies such as radio frequency identification
    (RFID) or other wireless sensor networks. Services in healthcare are omnipresent
    and still have a scope of prevalent research work and great developments. Amidst
    these innumerable devices it is important to collect data but, in the meantime,
    be energy-efficient and cost-effective. One such platform providing energy-aware
    services can be based on REST architecture which stands for Representational State
    Transfer. The energy utilization of the devices can be minimized by logically
    reduplicating the available sensors incorporated within the IoT devices and firmly
    regulating the rate of transfer of data grounded on the reckoning of the energy
    left in the IoT devices. The proposed platform was undertaken to reduce energy
    consumption by the IoT devices and can be classified into three components: Smart
    Devices—Data Collection applications must be installed on every IoT node (smart
    devices) for collecting data related to the emotional state of the people and
    then sending them to fog nodes for further analysis. Central Nodes—These nodes
    act as a hub and sanctions link between the RESTful web services and smart devices
    active in a smart environment. One of the smart devices itself, some other personal
    computer or some special device can take up the job of a central node. RESTful
    web services—The biggest advantage of using this web service is that it is sustainable
    and scalable in nature. Some of the services offered in context to the platform
    discussed are listed in the table Figure 3 is a flowchart displaying the three
    essential components of the proposed architecture and the web services rendered
    essential for complete implementation of the model is listed in Table 1. Fig.
    3 Proposed architecture of the data collection model in fog data analytics [20]
    Full size image Table 1 Required web services provided by the RESTful architecture
    Full size table 5.8 Health Monitoring System Using Fog Computing Healthcare is
    crucial to a country’s economic and wealth development. The rise in people falling,
    accidents and emergencies require hospitals to treat, diagnose and manage all
    these various cases. It is becoming increasingly difficult to monitor that a patient
    is complying by treatment plans and safeguarding them during attacks. To remedy
    this situation, wireless sensor networks are being widely adopted in the field
    of health informatics. Patients wear wireless sensors which can monitor several
    health parameters remotely by the hospital while the patients are at the comfort
    of their homes [21, 22] has proposed a context sensitive fog computing environment
    to improve the state of current healthcare systems. The wireless accessories attached
    to a patient generates huge amounts of data. This data may be useful or redundant.
    Also, the data being collected varies among patients. Cloud computing can cause
    a delay in data transfer from sensor to cloud to hospital, hence to reduce this
    time delay a distributed architecture such as fog computing is required. A three-tier
    architecture consisting of cloud, fog and sensor layer has been proposed. The
    sensors consist of wearable or non-wearable devices such as smartwatches, smart
    glasses or smartphones. The data gathered can be both intrinsic such as blood
    pressure and blood glucose levels or extrinsic such as the temperature of the
    physical location of the patient depending on the context. The collected real-time
    data is then sent to the fog computing layer for data analysis and aggregation.
    The data is distributed among various fog nodes for efficient computing where
    duplication of data is detected and filtered out. Then data is fused to be put
    together as a single entity after which it would be sent to the cloud computing
    tier if further analysis is required. The various health monitoring systems perform
    actions based on this data supervise the actions taken by the fog computing layer.
    The introduction of a fog layer into the cloud computing network reduces the security
    risk associated with patients and the prevention of loss due to a data centre
    failure. The implementation of fog in a health monitoring system is still in its
    primary stages of research and development, but studies have proven it to have
    a fruitful future. 5.9 Collecting Data Related to Elderly Behaviour According
    to various census and surveys, it was reckoned that in the next fifteen years
    there will be a huge shift in the proportion of people living above the age of
    60, this shift can likely be from 11% as of now in 2019, to 17% after a little
    more than a decade in 2030. Therefore, it is necessary to develop effective models
    to make the lives of the older people more smooth, relaxed and supportive in the
    upcoming years. Aged people are equally vulnerable to both physical and cognitive
    diseases such as mild cognitive impairments (MCI) and infirmity [23]. MCI gives
    rise to many significant cognitive changes in the person as noticed during a normal
    conversation in social relationships and daily behaviour and if not acted upon
    the healthcare system, to adapt to the upcoming contrasting requirements then
    there is a possibility of social and economic challenges around the globe. One
    method to acknowledge this issue is, by not considering an elderly person as an
    entity with special requirements. It is the person’s way of living and the cordial
    relationship he maintains with all his colleagues, family and friends what should
    be taken under consideration. The gigantic amount of data accessible today can
    aid in the decision-making process and create smart territory at the service of
    its occupants. Information and Communication Technologies (ICTs) plays an important
    part, by sensing data from the physical domains, managing data and employing,
    with the purpose of facilitating compatible modules upon which newly integrated
    values and personalized assistance can be fabricated. This problem is addressed
    by establishing substructures based on ICTs to observe the ageing behaviour and
    to provide rectifying measures after the data has been completely analyzed with
    the aim of promoting their independent living. Numerous technologies are used
    for surveying elderly people’s behaviour varying from wearable devices to wireless
    sensor networks, vision systems, portable interactive devices, bluetooth low energy
    beacons and augmented reality. Data can also be accumulated using high-end sensor
    devices, but these are not affordable and can create hindrance in implementing
    the data collection model at a large-scale. Therefore, it is important to consider
    the cost of the sensing devices for large scale implementation and it should be
    seen that there is an unobtrusive flow of data. The framework designed for this
    IoT implementation can be divided into two layers, the first layer which is used
    for collecting and managing the data for both indoor and outdoor activities, and
    the second layer then uses this data, analyzes it and then sets off the correct
    measures. The first and foremost requirement for the system is to precisely regulate
    the flow of the collected data from the inharmonious data sources and then assess
    in what aspects the behaviour of the elderly is varying or is consistent in different
    state of indoor and outdoor activities. The optimized data obtained as the output
    will be the prime data for the future works. 5.10 Telehealth Big Data Through
    Fog Computing It is very evident by now, that data gathered with the help of several
    sensors, especially the wearable sensors in healthcare and biomedical application
    is tremendous and will only rise exponentially, and hence there is a need of smart
    information gathering, data storage, data reduction and data analytics at the
    fog layer and then at the further levels [24]. The nested computer gathers the
    discerned data as time series, analyzes it and then tries to decipher similar
    patterns which are present in the collected data. The unique patterns are transmitted,
    and the nested computers draw out the relevant information that is forwarded to
    the cloud. Today some wearable medical sensors like ECG and activity monitors
    when positioned on the human body allows unobstructed 24/7 collection of data
    for health monitoring. Nowadays there are lots of self-regulating devices which
    are present around the human body, including at places like home and office that
    collect real-time data and feed telehealth interventions which help in making
    healthcare a little more affordable and raise awareness of one’s self health.
    This can be cited as a standard example of big data application wherein huge amounts
    of data with real-time information has to undergo a speedy processing to provide
    the optimum healthcare. One of the difficulties faced by the healthcare organizations
    is to project information sensing nodes into the body sensor networks (BSNs) which
    is now facilitated by employing wearable technology devices such as activity trackers,
    smartwatches, belt-worn personal computers, etc. The energy efficiency of these
    edge devices used in telehealth is also a matter of concern. To provide with ceaseless
    monitoring of the patients, BSNs are operated on batteries, and thus it is important
    to keep low power consumption as one of the priorities for BSNs. Generally, the
    procedure of data storage and data transmission devours a lot of energy, and thus
    it is better-off to process the data faster and filter out unwanted data which
    consumes space in storage and consumes energy when it is to be transmitted from
    one layer to another. Fog Computing architectures are extremely useful in achieving
    such objectives, their distinctive features can pull off onsite data analytics
    to lessen the unwanted data from being stacked and transmitted to the cloud. Some
    of the efficient telehealth systems are (1) Philips has come up with a device
    for COPD (chronic obstructive pulmonary disease) patients which basically is an
    adhesive patch ceaselessly gathering information about attributes like respiratory
    function, heart rate and physical activity [25]. (2) Philips is also working on
    developing one of its devices which can be controlled by iPhone and iPads and
    shall be used to subdue the very common tenacious pain suffered by many people
    across the globe [26]. (3) EchoWear is a smartwatch-based system that collects
    approximately 100 Mb data per day per person, who undergo profound speech therapies
    to improve their communication effectiveness [27]. 5.11 BLE-Based Data Collection
    The data gathering is one of the most vital aspect in the implementation of IoT.
    Because on the soaring amount of data being generated every day and which is only
    going to multiply in the coming days, it is crucial that efficient ways of collecting
    data should be focused on. There are many systems proposed with their underlying
    architecture based on Bluetooth Low Energy (BLE) technology to send the data onwards
    from the smart devices, phones or gadgets also referred to as data collectors
    to the fog nodes or hubs for analyzing data [28]. Table 2 compares the attributes
    of some of the similar technologies currently in use. The smart objects are acknowledged
    as the most elementary unit of Internet of Things (IoT) vision. The ideate is
    to connect several devices and objects to each other in our surroundings and bring
    together the data collected by them at any time, from any place and through any
    course of action. According to the data provided by the IoT Analytics, the number
    of internet-connected devices currently active in the world is estimated to be
    around 7 billion, that is a little less than the world population and this number
    is only going to increase insanely as internet connection and consumption increases
    and new devices and gadgets are introduced in the market. There are many applications
    of IoT devices and in various domains such as medicine, industry, agriculture,
    etc. The outpouring of information can be generalized in three phases; the collection
    phase where the data is collected through several IoT devices, the transmission
    phase where the information is filtered through the fog nodes in the fog layer
    and then forwarded to the cloud and the last, the managing, processing and the
    utilization phase. The process of collecting data is a set of techniques and technology
    which is used to sense the real environment and gather the existing data. Smartphones
    are now no more used for carrying out conventional jobs such as to send someone
    a text message or make calls alone but nowadays are also used to sense the environment
    around them. Specialized sensors in smartphone, as shown in Fig. 4, has been a
    huge addition in recent times, such as accelerometer, compass, gyroscope, orientation,
    GPS, proximity, gravity, barometer, light, sensor and some commonly and widely
    used sensors such as microphone and camera. Not only sensors, the smartphones
    also have RFID, NFC and BLE in their arsenal. Bluetooth Low Energy (BLE) is also
    referred to as Smart Bluetooth which was first-time set forth in 2010 as a segment
    of Bluetooth Core Specification version 4.0. It is a technology used to facilitate
    short-range wireless communication. The main aim of this technology is to authorize
    transceivers with low intricacy, low consumption of power, higher shell life and
    lower operating costs than the outstanding transceivers. It is an augmentation
    of the existing Bluetooth technology that permits small battery powered devices
    such as sports sensors, digital and smartwatches, wireless keyboard, etc. to communicate
    with each other. Even though BLE has comparatively less transmission power and
    range, the devices that operate on BLE can stay functional for many years because
    of its highly efficient low power-consuming idle mode. Bluetooth Low Energy (BLE)
    has a major setback that it allows data transmission only over a single hop, however,
    there are many mechanisms coming up in order to tackle this problem using the
    fundamental components of the BLE stack. Table 2 Some specifications of existing
    Low power technologies Full size table Fig. 4 Sensors present in the smart devices
    [28] Full size image 5.12 Safety Management System for Miners Mining contributes
    more than 2.4% of the GDP of the country. It is a source of employment for a large
    section of people, especially those, who reside close to the mines. History serves
    as evidence that even the smallest of mistakes or any form of negligence can prove
    to be lethal in the mining industry such as the Dhanbad and Chasnala disasters
    in India. A maximum number of fatalities occur in the coal mines of India. This
    makes it extremely important to ensure the safety of the mineworkers for which
    it is vital to know their live location and the environment they are working in.
    Cloud computing can be useful but the existing state-of-the-art technologies and
    architectures are unable to garner effective results. Hence many new architectures
    or models are being proposed such as a fog layer being integrated to make the
    system more reliable, dynamic and efficient [29]. Miners are constantly exposed
    to a dangerous and robust environment where toxic gases and dust have adverse
    effects on their health. Several propositions include communication with the help
    of sensors which determine different parameters such as methane gas level, oxygen
    level and water level but they have their own limitations. Even companies have
    tried to set up message centres and implement trained robots for inspection and
    other automation activities but since it is not cost-effective, the practice was
    discontinued. Thus, it is important to make the mineworkers conscious of life-threatening
    situations and also guide them to safe evacuations. One of the recently proposed
    architecture supervises the work environment and the movement of the miners in
    the minefields. A GSM layer has also been added for better navigation and monitoring
    of the action of the miners. Some of these sensors used for determining the level
    of carbon dioxide, carbon monoxide and hydrogen sulfide in the coal mines are
    K-30, MQ-7 and NTMOS H2S gas sensors, respectively. The data from these sensors
    are collected and forwarded to the different sensor nodes which creates a path
    till the fog gateways and then the fog nodes manoeuver the data as per the requirement.
    The fog layer gives an edge to the proposed architecture by reducing latency in
    the time of emergency. The fog layer analyzes the data and notifies the worker
    and the control room if the values of various parameters are on par with the threshold
    limits otherwise it sends the data to the cloud for storage purpose. The data
    stored on the cloud can be used for drills, research and visualization purposes.
    Adding more sensors such as pressure sensors and adding routes for fast and safe
    evacuation at the time of a disaster will alleviate the efficiency and the performance
    level of the architecture. 5.13 Healthcare 4.0 Healthcare industry has swiftly
    and rapidly grown after the evolution of the World Wide Web (WWW), in the last
    three decades. Since inception, Health 2.0 (the mid-2000s) and Health 3.0 have
    already been implemented wherein patients and the doctors are able to use basic
    tools for education, spreading awareness, disseminate elementary health-related
    guidelines and eventually go on to create medical records of the patients and
    store them for future references. These models turned out to be very convenient
    and efficient for the health experts, researchers, hospitals and its other users.
    With the escalating number of medical records and the information stored on a
    daily basis, it was crucial to introduce Cloud Computing in the healthcare industry
    to supplement the processing and storing of information more effectively. Sensors
    and wearable medical devices have developed with the advancing technologies and
    thus have become more reliable and safer to use, as a result of which lots and
    lots of data is being generated everyday and processed and stored in the cloud.
    Although cloud computing mitigates the problems faced regarding the storage and
    processing it still has its own limitations such as the bidirectional transfer
    of data between the user and the cloud is not smooth and fast enough, this impediment
    can lead to life-threatening situations and other blunders in the healthcare industry.
    This is where fog computing can be useful, it can facilitate the job of cloud
    computing in cases of medical emergencies. Fog Computing gives us an edge over
    cloud computing in terms of low latency, i.e. since fog nodes or gateways are
    near to the primitive devices, hence the overhead diminishes; and resilient, i.e.
    it helps to retrieve the lost data and also detect the anomalies in the link connections
    [30]. Fog Computing is also often referred to as SCALE, described in Table 3.
    Different architectures are being proposed that give us an intuition of how fog
    computing can immensely contribute to the Healthcare 4.0. One such three-layer
    architecture proposes the transfer of information between the Medical device layer,
    Fog layer and Cloud layer as per requirements. The first layer, i.e. the Medical
    device layer is the fundamental layer which involves collecting huge amounts of
    data through the different sensors, smart devices and wearable medical devices
    such as smartwatches and glasses. The IoT devices can further be divided into
    devices that digitally monitor the patient''s health and wellness such as ECG,
    glucose, haemoglobin and devices that record parameters based on the surroundings
    such as the number of steps walked, calories burnt, etc. The second layer is the
    fog layer which consists of several computational nodes that function on low power
    and are capable of giving high performance. One of the most valuable benefits
    of using fog computing is the quick responses while processing real-time data.
    The fog nodes are placed geographically near the medical devices and sensors,
    and thus the data which needs to be processed instantly are sent to fog nodes
    to get a prompt response and the rest of the data is forwarded to the cloud. The
    third and the final layer in this architecture is the cloud layer that incorporates
    major high computing data centres which perform on data that is collected by the
    sensors and the medical devices, and is filtered out by the fog layer. The cloud
    layer is also responsible for the storage of the medical records and other information
    which can be accessed by both the medical practitioner or doctors and the patients.
    Further optimisations are required to implement the architecture in the near future
    and make it more scalable. Table 3 Explanation of the acronym SCALE Full size
    table 5.14 Comparison on Case Studies Table 4 shows a set of comparisons drawn
    between multiple case studies formerly presented. It is clear that there is a
    general trend that fog computing proves to be advantageous over general cloud
    computing schemes. Fog computing provides better data security and privacy, reduces
    latency, provides quick decisions and reduces transmission costs. It can also
    allow for efficient real-time analysis, quicker transmission speeds and also filter
    or suppress unwanted data. The boxes shaded in grey show the presence of the specific
    layer in the application mentioned. Table 4 Comparison of different case studies
    Full size table 6 Conclusions The drawbacks of cloud computing, such as latency,
    security and privacy, and eruption in the number of IoT devices in the past decade
    led to the rise of fog computing. Fog brought forward a new era in the world of
    technology. In this chapter, state-of-the-art methods of data collection were
    presented along with several case studies that include summarized descriptions
    of data collection methods in various fog computing applications. The optimized
    collection of useful data was essential in all of the fog applications. There
    was a common theme among the methods used in the various applications. As fog
    nodes were deployed over a large area. Data received from the IoT devices was
    analyzed by these fog nodes and processed according to the significance of the
    data. The redundant data was filtered out and depending on the workload, the computation
    of the data is either performed on the fog node itself or otherwise sent to the
    cloud for further evaluation by the fog node itself. The processed data is then
    sent back to the IoT devices based on its requested service. Case studies in a
    wide range of fields show the importance and emergence of fog computing as a supplement
    to cloud computing. The fog has been widely adopted in fields such as autonomous
    vehicles and healthcare while still being in its infancy stages in fields such
    as agriculture, air quality and emotional profile monitoring systems. Subsequently,
    fifteen case studies were discussed in this work such as Moving Vehicles, Industrial
    Automation, Underwater Data Collection Water Conservation in Agriculture, Indoor
    Air Quality Monitoring, Health Monitoring System, Telehealth Big Data and Healthcare
    4.0 related to data analytics by incorporating Cloud, Fog and IoT. In summary,
    the purpose of this chapter was to provide useful insights into the methods of
    data collection in the fog ecosystem, encapsulating recent research trends in
    data collection and to extend the scope of research and implementation in new
    and exciting domains of fog computing as it will be the part and parcel of the
    cloud computing ecosystem. References Wang, F., Liu, J.: Networked wireless sensor
    data collection: issues, challenges, and approaches. IEEE Commun. Surv. Tut. 13(4),
    673–687 (2010) Article   Google Scholar   Chen, S., Du, L., Wang, K., & Lu, W.:
    Fog computing based optimized compressive data collection for big sensory data.
    In: 2018 IEEE International Conference on Communications(ICC), pp. 1–6. IEEE Google
    Scholar   Zhu, T., Wang, X., Cheng, S., Cai, Z., Li, J.: Critical point aware
    data acquisition algorithm in sensor networks. In: International Conference on
    Wireless Algorithms, Systems, and Applications, pp. 798–808. Springer, Cham (August
    2015) Google Scholar   Cheng, S., Cai, Z., Li, J., Gao, H.: Extracting kernel
    dataset from big sensory data in wireless sensor networks. IEEE Trans. Knowl.
    Data Eng. 29(4), 813–827 (2016) Article   Google Scholar   Dong, M., Ota, K.,
    Liu, A.: RMER: Reliable and energy-efficient data collection for large- scale
    wireless sensor networks. IEEE Internet of Things J. 3(4), 511–519 (2016) Article   Google
    Scholar   Liu, F., Wang, Y., Lin, M., Liu, K., Wu, D.: A distributed routing algorithm
    for data collection in low-duty-cycle wireless sensor networks. IEEE Internet
    of Things J. 4(5), 1420–1433 (2017) Article   Google Scholar   Li, S., Da Xu,
    L., Wang, X.: Compressed sensing signal and data acquisition in wireless sensor
    networks and internet of things. IEEE Trans. Industr. Inf. 9(4), 2177–2186 (2012)
    Article   Google Scholar   de Souza, J.C.S., Assis, T.M.L., Pal, B.C.: Data compression
    in smart distribution systems via singular value decomposition. IEEE Trans. Smart
    Grid 8(1), 275–284 (2015) Article   Google Scholar   Hosseinpour, F., Plosila,
    J., & Tenhunen, H.: An approach for smart management of big data in the fog computing
    context. In: 2016 IEEE International Conference on Cloud Computing Technology
    and Science (CloudCom), pp. 468–471. IEEE (Dec 2016). Google Scholar   Al-Sultan,
    S., Al-Doori, M.M., Al-Bayatti, A.H., Zedan, H.: A comprehensive survey on vehicular
    ad hoc network. J. Netw. Comput. Appl. 37, 380-392 (2014) Google Scholar   Lai,
    Y., Zhang, L., Wang, T., Yang, F., Xu, Y.: Data gathering framework based on fog
    computing paradigm in vanets. In: Asia-Pacific Web (APWeb) and Web-Age Information
    Management (WAIM) Joint Conference on Web and Big Data, pp. 227–236. Springer,
    Cham (July 2017) Google Scholar   Ramli, M.R., Bhardwaj, S., Kim, D.S.: Toward
    reliable fog computing architecture for industrial internet of things (2019) Google
    Scholar   Yu, H., Yao, J., Shen, X., Huang, Y., Jia, M.: Data collection scheme
    for underwater sensor cloud system based on fog computing. In: International Conference
    on Security, Privacy and Anonymity in Computation, Communication and Storage,
    pp. 149–159. Springer, Cham (July 2019) Google Scholar   Kamienski, C., Soininen,
    J. P., Taumberger, M., Fernandes, S., Toscano, A., Cinotti, T. S., Neto, A. T.
    (2018, June). SWAMP: an IoT-based smart water management platform for precision
    irrigation in agriculture. In: 2018 Global Internet of Things Summit (GIoTS),
    pp. 1–6. IEEE. Google Scholar   Kamienski, C., Soininen, J. P., Taumberger, M.,
    Dantas, R., Toscano, A., Salmon Cinotti, T., Torre Neto, A.: Smart water management
    platform: Iot-based precision irrigation for agriculture. Sensors 19(2), 276 (2019)
    Google Scholar   Ibañez, J.F., Castañeda, J.E.S., Santos, J.C.M.: An IoT camera
    system for the collection of data using QR code as object recognition algorithm.
    In: 2018 Congreso Internacional de Innovación y Tendencias en Ingeniería (CONIITI),
    pp. 1–6. IEEE (Oct 2018) Google Scholar   Firdhous, M.F.M., Sudantha, B.H., Karunaratne,
    P.M.: IoT enabled proactive indoor air quality monitoring system for sustainable
    health management. In: 2017 2nd International Conference on Computing and Communications
    Technologies (ICCCT), pp. 216–221. IEEE (Feb 2017) Google Scholar   Idrees, Z.,
    Zou, Z., Zheng, L.: Edge computing based IoT architecture for low cost air pollution
    monitoring systems: a comprehensive system analysis. Des. Consid. Dev. Sens. 18(9),
    3021 (2018) Article   Google Scholar   Swan, M.: Sensor mania! the internet of
    things, wearable computing, objective metrics, and the quantified self 2.0. J.
    Sens. Actuator Netw. 1(3), 217–253 (2012) Google Scholar   Ortega, M.G.S., Rodriguez,
    L.F., Gutierrez-Garcia, J.O.: Energy-aware data collection from the Internet of
    Things for building emotional profiles. In: 2018 Third International Conference
    on Fog and Mobile Edge Computing (FMEC), pp. 234–239. IEEE (2018, April) Google
    Scholar   Kraemer, F.A., Braten, A.E., Tamkittikhun, N., Palma, D.: Fog computing
    in healthcare–a review and discussion. IEEE Access 5, 9206–9222 (2017) Article   Google
    Scholar   Paul, A., Pinjari, H., Hong, W.H., Seo, H.C., Rho, S.: Fog computing-based
    IoT for health monitoring system. J. Sens. (2018) Google Scholar   Almeida, A.,
    Fiore, A., Mainetti, L., Mulero, R., Patrono, L., Rametta, P.: An IoT-aware architecture
    for collecting and managing data related to elderly behavior. Wirel. Commun. Mob.
    Comput. (2017) Google Scholar   Dubey, H., Yang, J., Constant, N., Amiri, A.M.,
    Yang, Q., Makodiya, K.: Fog data: Enhancing telehealth big data through fog computing.
    In: Proceedings of the ASE Bigdata & Socialinformatics 2015, p. 14. ACM (Oct 2015)
    Google Scholar   Naha, R.K., Garg, S., Georgakopoulos, D., Jayaraman, P.P., Gao,
    L., Xiang, Y., Ranjan, R.: Fog computing: survey of trends, architectures, requirements,
    and research directions. IEEE Access 6, 47980–48009 (2018) Article   Google Scholar   Philips:
    Aims to relieve persistent pain with smartphone controlled devices. www.engadget.com/2014/09/17/philips-app-controlled-pain-reliever/
    (17 Sept 2014) Dubey, H., Goldberg, J.C., Abtahi, M., Mahler, L., Mankodiya, K.:
    EchoWear: smartwatch technology for voice and speech treatments of patients with
    Parkinson''s disease. In: Proceedings of the Conference on Wireless Health, p.
    15. ACM (Oct 2015) Google Scholar   Boualouache, A.E., Nouali, O., Moussaoui,
    S., Derder, A.: A BLE-based data collection system for IoT. In: 2015 First International
    Conference on New Technologies of Information and Communication (NTIC), pp. 1–5.
    IEEE (Nov 2015) Google Scholar   Tanwar, S., Vora, J., Kaneriya, S., Tyagi, S.:
    Fog-based enhanced safety management system for miners. In: 2017 3rd International
    Conference on Advances in Computing, Communication & Automation (ICACCA) (Fall),
    pp. 1–6. IEEE (Sept 2017) Google Scholar   Kumari, A., Tanwar, S., Tyagi, S.,
    Kumar, N.: Fog computing for healthcare 4.0 environment: opportunities and challenges.
    Comput. Electr. Eng. 72, 1–13 (2018) Article   Google Scholar   Download references
    Author information Authors and Affiliations Department of Information Science
    and Engineering, Ramaiah Institute of Technology, Bangalore, Karnataka, India
    S. R. Mani Sekhar, Snehil Tewari & G. M. Siddesh Department of Electronics and
    Instrumentation, Ramaiah Institute of Technology, Bangalore, India Haaris Rahman
    Corresponding author Correspondence to S. R. Mani Sekhar . Editor information
    Editors and Affiliations Department of Computer Science and Engineering, Institute
    of Technology, Nirma University, Ahmedabad, Gujarat, India Sudeep Tanwar Rights
    and permissions Reprints and permissions Copyright information © 2020 The Editor(s)
    (if applicable) and The Author(s), under exclusive license to Springer Nature
    Singapore Pte Ltd. About this chapter Cite this chapter Mani Sekhar, S.R., Tewari,
    S., Rahman, H., Siddesh, G.M. (2020). Data Collection in Fog Data Analytics. In:
    Tanwar, S. (eds) Fog Data Analytics for IoT Applications. Studies in Big Data,
    vol 76. Springer, Singapore. https://doi.org/10.1007/978-981-15-6044-6_5 Download
    citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-15-6044-6_5 Published
    26 August 2020 Publisher Name Springer, Singapore Print ISBN 978-981-15-6043-9
    Online ISBN 978-981-15-6044-6 eBook Packages Computer Science Computer Science
    (R0) Share this chapter Anyone you share the following link with will be able
    to read this content: Get shareable link Provided by the Springer Nature SharedIt
    content-sharing initiative Publish with us Policies and ethics Download book PDF
    Download book EPUB Sections Figures References Abstract Introduction Methods of
    Collecting Data Optimized Collection of Compressive Data Management of Big Data
    Case Studies Conclusions References Author information Editor information Rights
    and permissions Copyright information About this chapter Publish with us Discover
    content Journals A-Z Books A-Z Publish with us Publish your research Open access
    publishing Products and services Our products Librarians Societies Partners and
    advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress
    Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.222
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Studies in Big Data
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Data Collection in Fog Data Analytics
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Srinivasan R.
  - Kavitha M.
  - Shashank Reddy D.
  - Naga Harshitha C.
  citation_count: '3'
  description: Internet of Things gives a new development in the area of farming and
    agriculture sector”It provides accurate solutions for the advanced problems involved
    in the agriculture by decreasing extra manpower”In this paper we are executing
    IoT based services to the agricultural sector “The main aim of this paper is to
    detect the insect pests in the tomato crop by using the various sensors” Now days
    the quality agriculture is always a strong area, where the technology based on
    sensors plays a vital role “Most commonly; sensors provide real time data in the
    field” By deploying sensors and Mapping fields farmers can start to comprehend
    their products in miniaturized scale “With the use of Fog computing and Wi-Fi
    based distance network in IoT, the pest data can be collected by the farmer in
    the early stages of the crop diseases via message” Fog Computing has a main aim
    in enlarging by bringing the cloud its required power of computation, storage
    and communication capabilities with respect to IoT to the edge of the network”Instead
    of walking down the field, the farmer today can take necessary measures to reduce
    the pest’s population by using the automatic sprinkler mixed with pesticides by
    using soil moisture sensor.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International Journal of Innovative Technology and Exploring Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Precision agriculture using fog-edge computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Terauchi A.
  - Ooto K.
  - Takahashi N.
  - Harada K.
  - Yamasaki I.
  citation_count: '1'
  description: The pervasive spread of the Internet of Things, or IoT, in recent years
    is remarkable, and NTT is working to incorporate IoT in industries showing the
    greatest promise for creating new value-manufacturing, the auto industry, agriculture,
    and other sectors. This article provides an overview of NTT's initiatives in IoT
    data exchange technology and edge computing technology, and reviews standardization
    trends pertaining to these technologies.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: NTT Technical Review
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Data exchange technology providing real-time data processing and scalability
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

- DOI: https://doi.org/10.1109/access.2020.2975142
  analysis: '>'
  authors:
  - Maanak Gupta
  - Mahmoud Abdelsalam
  - Sajad Khorsandroo
  - Sudip Mittal
  citation_count: 273
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathZoom.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Subscribe Donate Cart Create Account Personal Sign In Personal Sign In *
    Required *Email Address *Password Forgot Password? Sign In Don''t have a Personal
    Account? Create an IEEE Account now. Create Account Learn more about personalization
    features. IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8948470/09003290.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: 'Security and Privacy in Smart Farming: Challenges and Opportunities'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/computers11090135
  analysis: '>'
  authors:
  - Riki Ruli A. Siregar
  - Kudang Boro Seminar
  - Sri Wahjuni
  - Edi Santosa
  citation_count: 22
  full_citation: '>'
  full_text: ">\nCitation: Siregar, R.R.A.;\nSeminar, K.B.; Wahjuni, S.; Santosa,\
    \ E.\nVertical Farming Perspectives in\nSupport of Precision Agriculture\nUsing\
    \ Artiﬁcial Intelligence: A\nReview. Computers 2022, 11, 135.\nhttps://doi.org/10.3390/\n\
    computers11090135\nAcademic Editors: Rytis Maskeliunas\nand Robertas Damaševiˇcius\n\
    Received: 6 July 2022\nAccepted: 1 September 2022\nPublished: 8 September 2022\n\
    Publisher’s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\n\
    published maps and institutional afﬁl-\niations.\nCopyright:\n© 2022 by the authors.\n\
    Licensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\ncomputers\nReview\n\
    Vertical Farming Perspectives in Support of Precision\nAgriculture Using Artiﬁcial\
    \ Intelligence: A Review\nRiki Ruli A. Siregar 1\n, Kudang Boro Seminar 2,*, Sri\
    \ Wahjuni 1 and Edi Santosa 3\n1\nDepartment of Computer Science, IPB University\
    \ Indonesia, Bogor 16680, Indonesia\n2\nDepartment of Agricultural Technology,\
    \ IPB University Indonesia, Bogor 16680, Indonesia\n3\nDepartment of Agronomy\
    \ and Horticulture, Faculty of Agriculture, IPB University Indonesia,\nBogor 16680,\
    \ Indonesia\n*\nCorrespondence: kseminar@apps.ipb.ac.id\nAbstract: Vertical farming\
    \ is a new agricultural system which aims to utilize the limited access to\nland,\
    \ especially in big cities. Vertical agriculture is the answer to meet the challenges\
    \ posed by land\nand water shortages, including urban agriculture with limited\
    \ access to land and water. This research\nstudy uses the Preferred Reporting\
    \ for Systematic Review and Meta-analysis (PRISMA) item as\none of the literary\
    \ approaches. PRISMA is one way to check the validity of articles for a literature\n\
    review or a systematic review resulting from this paper. One of the aims of this\
    \ study is to review\na survey of scientiﬁc literature related to vertical farming\
    \ published in the last six years. Artiﬁcial\nintelligence with machine learning,\
    \ deep learning, and the Internet of Things (IoT) in supporting\nprecision agriculture\
    \ has been optimally utilized, especially in its application to vertical farming.\
    \ The\nresults of this study provide information regarding all of the challenges\
    \ and technological trends in\nthe area of vertical agriculture, as well as exploring\
    \ future opportunities.\nKeywords: vertical farming; artificial intelligence;\
    \ machine learning; deep learning; internet of things (IoT)\n1. Introduction\n\
    The world population is increasing at an accelerating rate. According to a UN\
    \ report,\nthe world population is expected to reach around 8.5 billion by 2030\
    \ [1] and is even pre-\ndicted to reach 9.7 billion by 2050 [2,3]. The challenges\
    \ posed by reliable food demands\nwill be inﬂuenced by various factors, including\
    \ climate change, water scarcity, and limited\nland due to increasing urbanization\
    \ [3]. Research on agriculture has become an important\nfocus [4]. The smart farming\
    \ model is an essential step towards sustainable agriculture [5],\nwhich applies\
    \ intelligent technological innovations in agriculture by leveraging modern\n\
    technologies, such as the Internet of Things platforms, fog/edge computing, cloud\
    \ comput-\ning, and storage, all from the most advanced information and communication\
    \ technologies\n(ICT) [6]. Vertical agriculture is the answer to the challenge\
    \ of land and water shortages,\nincluding urban farming, which has limited access\
    \ to land and water [7]. One of the\ngoals of this research is to provide information\
    \ about agricultural land use by applying\nthe development of vertical farming\
    \ models [8–10], and intelligent system technology in\nvertical crop production\
    \ based on IoT [11–13], as well as processing data collected with the\nrole of\
    \ machine learning algorithms from various scenarios, such as intelligent irrigation\
    \ in\nvertical land technology, predicting yields, monitoring growth, monitoring\
    \ diseases, and\nproposing framework models on vertically integrated farmland\
    \ effectively. They are all\nconducted to change the paradigm of the traditional\
    \ agricultural industry into a modern\nagriculture format from the perspective\
    \ of precision and smart agriculture [2,14].\nMachine learning focuses on developing\
    \ computational artiﬁcial intelligence methods\nthat can access various types\
    \ of data (text, numbers, images, video, and audio), and is\nsupported by data\
    \ communication technology capabilities with data streaming speed\n(velocity)\
    \ using the data for self-learning [15].\nComputers 2022, 11, 135. https://doi.org/10.3390/computers11090135\n\
    https://www.mdpi.com/journal/computers\nComputers 2022, 11, 135\n2 of 19\nThe\
    \ study also presents a framework that maps the activities deﬁned in smart farming,\n\
    the data sets or features used in the data modeling, and the machine learning\
    \ algorithms\nused to analyze the features for each activity deﬁned in the described\
    \ stages of the chain\nand the farm sequences. Vertical farming offers many opportunities\
    \ to combine advances\nin genetics with advances in environmental modiﬁcation\
    \ and to produce a guaranteed\nquality and quantity of crops regardless of the\
    \ weather, soil conditions, or impacts of\nclimate change [10]. This enables the\
    \ opportunity of producing functional or specialized\nfood from staple foods through\
    \ environmental control and manipulation [16]. Vertical\nfarming has various advantages\
    \ over horizontal rice ﬁeld farming, observed from the\nperspectives of environmental,\
    \ social, and economic stability. New high-tech cultivation\nmethods, including\
    \ hydroponics, aeroponics, and aquaponics, largely challenge the need\nfor soil-based\
    \ agriculture for a wide variety of crops [17] and also present a viable option\n\
    for growing crops in urban environments where the geographic footprint is limited\
    \ and the\ndemand for on-time product delivery always increases [8]. A research\
    \ approach was taken\nto obtain the technology used to achieve this goal, at a\
    \ low cost, by utilizing the Internet\nof Things (IoT) [18,19] and artiﬁcial intelligence\
    \ [20] on machine learning techniques [15]\nto help transform big data into knowledge\
    \ [21]. The IoT approach requires a set of sensor\ndevices, including temperature,\
    \ light, soil moisture, nutrition, and several other supporting\nsensors, which\
    \ are monitored continuously and obtain data through the data transmission\npath\
    \ where sensor data can be communicated wirelessly using microcontrollers and\
    \ wireless\nmodules to build intelligent and precise agricultural processes using\
    \ IoT [22].\nThe main objective of this research is to introduce a model of vertical\
    \ crop farming\nas an era of precision and intelligent agriculture as an embodiment\
    \ of intelligent agricul-\nture. Artiﬁcial intelligence methods are described\
    \ that combine the processing of big data\ncollected by IoT systems, the use of\
    \ machine/deep learning in different vertical irrigation\nscenarios, as well as\
    \ for yield predictions, monitoring growth and disease, and assessing\nsample\
    \ quality. Vertical farming (VF) opens up a new era of intelligent agricultural\
    \ engi-\nneering that has the potential to meet future food requirements. Looking\
    \ at the current\nagricultural trends, VF can utilize all agricultural IoT devices\
    \ in multiple dimensions.\nApplying agricultural technologies such as AI (artiﬁcial\
    \ intelligence), machine learning,\nproductivity, and quality factors will increase\
    \ the efﬁciency of VF [23].\nIn Figure 1. The design of the proposed VF model\
    \ represents a new era of intelligent\nagricultural engineering. The application\
    \ of the Intelligent Internet of Things concept by\ncombining artiﬁcial intelligence\
    \ and machine learning algorithms, productivity, and quality\nfactors will improve\
    \ VF.\nIntelligent system agriculture refers to data-driven agriculture, which\
    \ can adaptively\nkeep up with future developments by utilizing new technologies\
    \ for the improvement of\nagricultural knowledge systems from the availability\
    \ of larger amounts of data [24]. With\nthe advancement of data management, smart\
    \ agriculture is growing exponentially, and\ngenerating relevant data has become\
    \ a key element in modern agriculture to assist users in\ndecision-making [25].\
    \ The concept of data-centric agriculture has been promoted in several\nformats,\
    \ such as Agriculture 4.0, Digital Farming, and Smart Farming, and was born from\n\
    telematics and data management combined with the concept of precision agriculture\
    \ to\nimprove agricultural operational accuracy [26]. IoT in the context of agriculture\
    \ refers\nto the use of sensors and other devices to transform every element and\
    \ action involved\nin agriculture into data [27]. IoT is a model for developments\
    \ in Agriculture 4.0 [28]\nand becomes one of the reasons why agriculture can\
    \ produce a large amount of valuable\ninformation. The agricultural sector is\
    \ expected to be heavily inﬂuenced by technological\ndevelopments and innovations\
    \ in IoT [6,29]. The big data concept applied to agricultural\napplications at\
    \ the Consortium of International Agricultural Research Centers (CGIAR)\nuses\
    \ big data [30].\nComputers 2022, 11, 135\n3 of 19\nComputers 2022, 11, x FOR\
    \ PEER REVIEW \n3 of 20 \n \n \nFigure 1. A conceptual architecture of smart vertical\
    \ farming. \nIntelligent system agriculture refers to data-driven agriculture,\
    \ which can adaptively \nkeep up with future developments by utilizing new technologies\
    \ for the improvement of \nagricultural knowledge systems from the availability\
    \ of larger amounts of data [24]. With \nthe advancement of data management, smart\
    \ agriculture is growing exponentially, and \ngenerating relevant data has become\
    \ a key element in modern agriculture to assist users \nin decision-making [25].\
    \ The concept of data-centric agriculture has been promoted in sev-\neral formats,\
    \ such as Agriculture 4.0, Digital Farming, and Smart Farming, and was born \n\
    from telematics and data management combined with the concept of precision agriculture\
    \ \nto improve agricultural operational accuracy [26]. IoT in the context of agriculture\
    \ refers \nto the use of sensors and other devices to transform every element\
    \ and action involved in \nagriculture into data [27]. IoT is a model for developments\
    \ in Agriculture 4.0 [28] and \nbecomes one of the reasons why agriculture can\
    \ produce a large amount of valuable in-\nformation. The agricultural sector is\
    \ expected to be heavily influenced by technological \ndevelopments and innovations\
    \ in IoT [6,29]. The big data concept applied to agricultural \napplications at\
    \ the Consortium of International Agricultural Research Centers (CGIAR) \nuses\
    \ big data [30]. \nData-based management in agriculture uses spatial- and time-based\
    \ data measured \nfrom plants’ soil or other parameters, data from sensors, and\
    \ the decision stage involving \npre-processing activities and an artificial intelligence\
    \ algorithm approach to get the ap-\npropriate data and helps in making and creating\
    \ the right decisions [25]. \n2. Research Methodology \nThe approach uses a systematic\
    \ literature review (SLR), i.e., a method of managing \ninformation sources from\
    \ related research according to predetermined topics [31]. In this \nstudy, SLR\
    \ was conducted to determine the feasibility and study of smart farming tech-\n\
    nology in vertical farming. The research searched using the term: “smart agriculture”\
    \ is \nthen inserted with the term: “vertical agriculture” which will appear in\
    \ the title, abstract, \nand keywords of articles with approaches to “artificial\
    \ intelligence”, “machine learning”, \n“deep learning”, “IoT” and intelligent\
    \ algorithms applied to agricultural systems. This \npaper uses selected reporting\
    \ items for systematic review and meta-analysis (PRISMA) as \none of the SLR approaches.\
    \ PRISMA is a way to check the validity of articles for literature \nreview or\
    \ systematic review [31]. PRISMA, in this study, evaluates a systematic review\
    \ or \nmeta-analysis composed of a checklist of items as a systematic review or\
    \ meta-analysis. \nSteps for preparing a checklist item for a systematic review\
    \ and meta-analysis: \nFigure 1. A conceptual architecture of smart vertical farming.\n\
    Data-based management in agriculture uses spatial- and time-based data measured\n\
    from plants’ soil or other parameters, data from sensors, and the decision stage\
    \ involv-\ning pre-processing activities and an artiﬁcial intelligence algorithm\
    \ approach to get the\nappropriate data and helps in making and creating the right\
    \ decisions [25].\n2. Research Methodology\nThe approach uses a systematic literature\
    \ review (SLR), i.e., a method of managing\ninformation sources from related research\
    \ according to predetermined topics [31]. In\nthis study, SLR was conducted to\
    \ determine the feasibility and study of smart farming\ntechnology in vertical\
    \ farming. The research searched using the term: “smart agriculture”\nis then\
    \ inserted with the term: “vertical agriculture” which will appear in the title,\
    \ abstract,\nand keywords of articles with approaches to “artiﬁcial intelligence”,\
    \ “machine learning”,\n“deep learning”, “IoT” and intelligent algorithms applied\
    \ to agricultural systems. This\npaper uses selected reporting items for systematic\
    \ review and meta-analysis (PRISMA) as\none of the SLR approaches. PRISMA is a\
    \ way to check the validity of articles for literature\nreview or systematic review\
    \ [31]. PRISMA, in this study, evaluates a systematic review or\nmeta-analysis\
    \ composed of a checklist of items as a systematic review or meta-analysis.\n\
    Steps for preparing a checklist item for a systematic review and meta-analysis:\n\
    1.\nTitle: conﬁrm and identify as systematic review and meta-analysis.\n2.\nAbstracts\
    \ are structured; namely, there is a background, methods, results, and conclusions.\n\
    3.\nIn the Introduction section, discover the urgency of the systematic review\
    \ or meta-\nanalysis and the purpose of the systematic review or meta-analysis.\n\
    4.\nThe method of conducting a literature search process is searching for sources\
    \ of\nliterature portals, describing inclusion and exclusion criteria from articles\
    \ or research,\nrepresenting the number of articles obtained during the initial\
    \ search, and then the\nreasons for exclusion, so how many manuscripts can be\
    \ accepted.\n5.\nResults describe with a diagram the selection process of the\
    \ article.\n6.\nDiscussion section on the relevance and plausibility of the ﬁndings.\
    \ The limitations\nthey face start from the study selection process to the limitations\
    \ in the process.\n7.\nConclusions from ﬁndings from systematic reviews and/or\
    \ meta-analyses are brief,\nconcise, and clear.\nPRISMA explanation ﬂow can be\
    \ seen in Figure 2.\nComputers 2022, 11, 135\n4 of 19\nreasons for exclusion,\
    \ so how many manuscripts can be accepted. \n5. \nResults describe with a diagram\
    \ the selection process of the article. \n6. \nDiscussion section on the relevance\
    \ and plausibility of the findings. The limitations \nthey face start from the\
    \ study selection process to the limitations in the process. \n7. \nConclusions\
    \ from findings from systematic reviews and/or meta-analyses are brief, \nconcise,\
    \ and clear. \nPRISMA explanation flow can be seen in Figure 2. \nIdentification\n\
    Screening\nEligibility\nInclusion\nRecord identified \nScopus/Science \nDirect/IEE/MDPI\
    \ \n(n = 424)\nRecord identified \netc (n = 2706)\nRecord screened \non the basis\
    \ of \ntittle (n = 271)\nRecord screened \non the basis of \nabstract (n = 172)\n\
    Record excluded \n(n = 103)\nFull text article \nfor eligibility \n(n = 87)\n\
    Full text article \nexclude, with \nreason\nStudies include \nfrom Scopus, \n\
    Science Direct, \netc\nAdditional \nrecords identified \nthrough cross-\nreferencing\n\
    Total studies \nincluded in meta-\nanalysis\n(n = 68)\nFour-step evaluation of\
    \ literature search process (PRISMA)\nRecord identified \n“vertical farm” \n(n\
    \ = 358)\n \nFigure 2. Literature review with four stages of PRISMA evaluation.\
    \ \n2.1. Literature Review \nThe survey was conducted by looking at the global\
    \ scope of innovations related to \nvertical smart agriculture using machine learning\
    \ with the evaluation carried out in four \nstages including identification, screening,\
    \ feasibility, and inclusion [32]. Literature review \nin perspective was completed\
    \ by identifying, evaluating, and interpreting the scope and \nresults of related\
    \ and relevant research, which is shown in Table 1. \nTable 1. Systematic observation\
    \ of the literature review. \nResearch question \n1. \nWhat types of digital technology\
    \ are used for vertical farming and smart farming? \n2. \nHow are technological\
    \ developments and intelligent algorithm models applied in \nthe context of the\
    \ tools, the technologies used, the level of reliability, and the type of \nfarming\
    \ applied? \n3. \nWhat are the key opportunities and barriers to implementing\
    \ vertical farming for \nsmart farming? \nSelection literature \n1. \nJournal\
    \ articles, original papers, review papers, conference papers \n2. \nPeriodic\
    \ publication: 2016–2022. \nFigure 2. Literature review with four stages of PRISMA\
    \ evaluation.\n2.1. Literature Review\nThe survey was conducted by looking at\
    \ the global scope of innovations related to\nvertical smart agriculture using\
    \ machine learning with the evaluation carried out in four\nstages including identiﬁcation,\
    \ screening, feasibility, and inclusion [32]. Literature review\nin perspective\
    \ was completed by identifying, evaluating, and interpreting the scope and\nresults\
    \ of related and relevant research, which is shown in Table 1.\nTable 1. Systematic\
    \ observation of the literature review.\nResearch question\n1.\nWhat types of\
    \ digital technology are used for vertical farming and smart farming?\n2.\nHow\
    \ are technological developments and intelligent algorithm models applied in the\
    \ context of\nthe tools, the technologies used, the level of reliability, and\
    \ the type of farming applied?\n3.\nWhat are the key opportunities and barriers\
    \ to implementing vertical farming for smart farming?\nSelection literature\n\
    1.\nJournal articles, original papers, review papers, conference papers\n2.\n\
    Periodic publication: 2016–2022.\n3.\nPotential answers to research questions.\n\
    4.\nScopus indexed articles by listing title, afﬁliation, year, source, abstract,\
    \ and quartiles (Q1–Q4 and\nNon–Q).\n5.\nThe focus of the literature is on the\
    \ development of vertical land models with intelligent systems\nin the concept\
    \ of smart farming based on artiﬁcial intelligence/machine learning algorithms.\n\
    6.\nPublications are written in English.\nLiterature source\nScopus, IEEE Xplore,\
    \ Multidisciplinary Digital Publishing Institute (MDPI), Science Direct.\nSearch\
    \ keyword\n((“Farming OR Agriculture”) AND (“Vertical agriculture” OR “Vertical\
    \ Farming” OR “Intelligent\nFarming” OR “Smart Agriculture” OR “Precision Agriculture”\
    \ OR “Smart Farming” OR “Greenhouse ”\nOR “Internet of Things” OR “IoT” OR “Cloud\
    \ Computing” OR “Edge Computing” OR “Wireless\nSensor Networks ” OR “Artiﬁcial\
    \ Intelligence ” OR “Big Data ” OR “Data Analytics ” OR “Data Science\n” OR “Cyber-Physical\
    \ System ” OR “Robotics ” OR “Computer Vision ” OR “Machine Learning ” OR\n“Deep\
    \ Learning ” OR “Data Integration ” OR “Supervised learning ” OR “Unsupervised\
    \ Learning ” OR\n“Decision Support System ” OR “fuzzy”))\nFigure 2 explains the\
    \ criteria that have been mentioned and refer to Table 1 on the\nResearch question,\
    \ Selection literature, Literature sources, and Search keywords with four\nsteps\
    \ of PRISMA evaluation:\nComputers 2022, 11, 135\n5 of 19\n1.\nIdentiﬁcation:\
    \ The amount of data from searches in the Scopus index database, MDPI,\nscience\
    \ direct, etc., is 424. The amount of data from other sources (recommendations\n\
    from experts/manual searches/reports/news) is 2706, and the amount of data that\n\
    appears with the keyword “vertical farm” is 358.\n2.\nScreening: The total number\
    \ of data identiﬁed and then the amount of data after\nduplicate data was deleted\
    \ and indexed by Scopus and deemed irrelevant was 271.\nThe number of data released\
    \ after the selection based on the title and abstract was\n172. The exclusions\
    \ of search results based on title and abstract are: “vertical farm\nobjects”,\
    \ “use of artiﬁcial intelligence”, “machine learning and deep learning methods\n\
    for vertical farms”, “IoT base farming”, “literature studies”, and “published\
    \ outside\n2016–2022”.\n3.\nEligibility: The amount of data in the form of a full-text\
    \ article and excluded because\nit does not meet the criteria based in Table 1.\n\
    4.\nInclusion: The amount of data synthesized in the systematic qualitative review\
    \ and\nthe complete study included in the meta-analysis selected 68 datasets.\n\
    2.2. Research Trends in Vertical Agriculture\nBased on the distribution of 68\
    \ articles from 2016 to 2022, it can be seen in Figure 3, that\n32% of the scientiﬁc\
    \ publications occurred in 2021 and 25% in the ﬁrst six months of 2022.\nFigure\
    \ 4 shows the distribution of scientiﬁc articles indexed by reputation at the\
    \ quartile\nlevel (Scopus). This trend seems to always increase in the application\
    \ of digitalization of\nvertical agriculture by utilizing artiﬁcial intelligence\
    \ [33].\nComputers 2022, 11, x FOR PEER REVIEW \n6 of 20 \n \n \nFigure 3. Distribution\
    \ of literature from 2016 to 2022. \n \nFigure 4. Distribution of articles by\
    \ 2016 to 2022 quartiles. \nA literature review focusing on vertical farming with\
    \ AI has been carried out from\n11\n7\n11\n6\n33\nArticle by Quartil\nQ1\nQ2\n\
    Q3\nQ4\n-\nFigure 3. Distribution of literature from 2016 to 2022.\nA literature\
    \ review focusing on vertical farming with AI has been carried out from\nseveral\
    \ existing papers. In relating the novelty of this study to other surveys, a comparison\n\
    of surveys similar to those available is carried out in Table 2. Most public surveys\
    \ present\nurban farming technologies, vertical farming, IoT, automation, and\
    \ AI reviews. However,\nthis study concentrates on quantitative research related\
    \ to vertical farming models with AI.\nComputers 2022, 11, 135\n6 of 19\n \nFigure\
    \ 3. Distribution of literature from 2016 to 2022. \n \nFigure 4. Distribution\
    \ of articles by 2016 to 2022 quartiles. \nA literature review focusing on vertical\
    \ farming with AI has been carried out from \nseveral existing papers. In relating\
    \ the novelty of this study to other surveys, a comparison \nof surveys similar\
    \ to those available is carried out in Table 2. Most public surveys present \n\
    urban farming technologies, vertical farming, IoT, automation, and AI reviews.\
    \ However, \nthis study concentrates on quantitative research related to vertical\
    \ farming models with \nAI. \nTable 2. Comparison with Other Surveys in the Literature.\
    \ \nReference \nResearch Content \nOur Paper \n[34] \nThe study reviews various\
    \ new and disrup-\ntive technologies introduced in urban farm-\ning: the internet\
    \ of things, automation, artifi-\ncial intelligence, robotics, blockchain, digital\
    \ \ntwins, renewable energy, genetic modifica-\ntion, additive manufacturing,\
    \ and nanotech-\nnology. Each technology is discussed in \nterms of its application,\
    \ advantages, and dis-\nadvantages \nIn this paper, various emerg-\ning and disruptive\
    \ technolo-\ngies for urban agriculture are \nreviewed and assessed. Based \n\
    on the literature from 2015 to \n2021, IoT, automation, and AI \ndo not cover\
    \ the survey of ver-\ntical farming models. \n11\n7\n11\n6\n33\nArticle by Quartil\n\
    Q1\nQ2\nQ3\nQ4\n-\nFigure 4. Distribution of articles by 2016 to 2022 quartiles.\n\
    Table 2. Comparison with Other Surveys in the Literature.\nReference\nResearch\
    \ Content\nOur Paper\n[34]\nThe study reviews various new and\ndisruptive technologies\
    \ introduced in\nurban farming: the internet of things,\nautomation, artiﬁcial\
    \ intelligence,\nrobotics, blockchain, digital twins,\nrenewable energy, genetic\
    \ modiﬁcation,\nadditive manufacturing, and\nnanotechnology. Each technology is\n\
    discussed in terms of its application,\nadvantages, and disadvantages\nIn this\
    \ paper, various emerging and\ndisruptive technologies for urban\nagriculture\
    \ are reviewed and assessed.\nBased on the literature from 2015 to\n2021, IoT,\
    \ automation, and AI do not\ncover the survey of vertical farming\nmodels.\n[35]\n\
    This paper presents an overview of the\nvarious practices and aspects that can\n\
    be or are currently being automated,\nusing robotics, IoT, and Artiﬁcial\nIntelligence\
    \ (AI) more productively.\nWhat distinguishes it has not been\nreviewed in more\
    \ detail from the\nsurvey on the vertical farming model\nusing AI and IoT.\n[36]\n\
    This study aims to monitor and control\nvertical farming by scheduling\nagricultural\
    \ activities by solving\nJob-shop scheduling problems. A\ngenetic Algorithm was\
    \ developed to\nmonitor farm locations remotely.\nThe results of this study are\
    \ not a\nreview related to vertical agricultural\nsurvey technology in the development\n\
    of AI and IoT.\n[37]\nThis survey discusses a comprehensive\noverview of the USVF\
    \ concept using\nvarious techniques to increase\nproductivity and the type, topology,\n\
    technology, control system, social\nacceptance, and novelty beneﬁts of\nthe paper.\n\
    Have not focused on the relevant\ntechnology, have not discussed some of\nthe\
    \ AI algorithms that have been used\nComputers 2022, 11, 135\n7 of 19\nTable 2.\
    \ Cont.\nReference\nResearch Content\nOur Paper\n[23]\nUrban smart vertical farming\
    \ (USVF)\nuses various techniques to increase\nproductivity and its types, topologies,\n\
    technologies, control systems, social\nacceptance, and beneﬁts. This study\nfocuses\
    \ on multiple issues, challenges,\nand recommendations in systems\ndevelopment,\
    \ vertical farm\nmanagement, and modern technology\napproaches\nFocus on IoT Architecture\
    \ and LoRa\ncommunication. We have not discussed\nsome of the AI algorithms that\
    \ have\nbeen used in vertical farming.\nIn Table 2, many studies have been conducted\
    \ on using AI, machine learning, deep\nlearning, and IoT in vertical farming.\
    \ However, none of these studies focus on using smart\nvertical farming for food\
    \ crops such as paddy, corn, and wheat. Study research on vertical\nagricultural\
    \ land using artiﬁcial intelligence, machine learning, and deep learning on staple\n\
    crops such as rice, wheat, or corn is one of the new opportunities for food crop\
    \ agriculture\nresearch on vertical land that can be controlled and monitored\
    \ at any time. Potential\nresearch gaps in vertical farming with artiﬁcial intelligence\
    \ are:\n1.\nThe challenges of indoor rice production compared to indoor vegetable\
    \ production.\n2.\nMore complex growth involves vegetative, reproductive, and\
    \ ripening phases.\n3.\nMore precise and complex water, nutrition, and lighting\
    \ management.\n4.\nMore extended production period from planting to harvest.\n\
    The novelty of this study is to address a new opportunity to study the development\
    \ of\nintelligent and precise indoor production for rice crops using vertical\
    \ farming. This is the\nnovelty of this research.\nBased on the distribution of\
    \ 68 articles from 2016 to 2022 shown in Figure 3, 32% of\nscientiﬁc publications\
    \ in the last six years will be published in 2021. Figure 4 shows the\ndistribution\
    \ of scientiﬁc articles indexed by reputation at the quartile level (Scopus),\
    \ with\ndetails Q1 16% (11), Q2 10% (7), Q3 16% (11), Q4 9% (6), and No Q 49%\
    \ (33). The trend of\nthe number of research and publications is constantly increasing\
    \ in the implementation\nof digitalization of vertical agriculture by utilizing\
    \ artiﬁcial intelligence [33]. In detail, the\npublications mentioned in the agricultural\
    \ object types are shown in Figure 5.\nComputers 2022, 11, x FOR PEER REVIEW \n\
    8 of 20 \n \n \nFigure 5. Numbers of articles in the research sample that mention\
    \ specific research terms. \nFigure 5 shows the number of objects in the agricultural\
    \ sector based on a literature \nstudy that applies smart farming. The type of\
    \ agricultural object refers to the approach \ntaken such as using soil or soilless\
    \ media, developing smart farming concepts, precision, \nautomation, and disease\
    \ detection. Based on the occurrence frequencies of specific terms \nis that the\
    \ vertical farm object in the selected article is the most dominant discussion.\
    \ Fur-\nthermore, from the distribution of the 68 selected articles, in Figures\
    \ 6–8, the trend of pub-\n43\n33\n24\n62\n7\n4\n9\n6\n13\n28\n15\n1\n0\n6\n4\n\
    32\n15\n19\n0\n7\n0\n10\n20\n30\n40\n50\n60\n70\nResearch Term\nFigure 5. Numbers\
    \ of articles in the research sample that mention speciﬁc research terms.\nComputers\
    \ 2022, 11, 135\n8 of 19\nFigure 5 shows the number of objects in the agricultural\
    \ sector based on a literature\nstudy that applies smart farming. The type of\
    \ agricultural object refers to the approach\ntaken such as using soil or soilless\
    \ media, developing smart farming concepts, precision,\nautomation, and disease\
    \ detection. Based on the occurrence frequencies of speciﬁc terms\nis that the\
    \ vertical farm object in the selected article is the most dominant discussion.\n\
    Furthermore, from the distribution of the 68 selected articles, in Figures 6–8,\
    \ the trend of\npublications indexed in the reputable database that the vertical\
    \ agriculture theme from\n2016 to 2022 is always increasing.\n \nFigure 5. Numbers\
    \ of articles in the research sample that mention specific research terms. \n\
    Figure 5 shows the number of objects in the agricultural sector based on a literature\
    \ \nstudy that applies smart farming. The type of agricultural object refers to\
    \ the approach \ntaken such as using soil or soilless media, developing smart\
    \ farming concepts, precision, \nautomation, and disease detection. Based on the\
    \ occurrence frequencies of specific terms \nis that the vertical farm object\
    \ in the selected article is the most dominant discussion. Fur-\nthermore, from\
    \ the distribution of the 68 selected articles, in Figures 6–8, the trend of pub-\n\
    lications indexed in the reputable database that the vertical agriculture theme\
    \ from 2016 \nto 2022 is always increasing. \n \nFigure 6. Distribution of objects\
    \ in the vertical farm of 68 selected articles by quartiles (Scopus). \n1\n0\n\
    0\n0\nagric\nultur\ne\nsmar\nt\nfarmi\nng\nintell\nigen\nverti\ncal\nfarm\nsmar\n\
    t\nagric\nultur\ne\nindus\ntry\nclima\nte\npreci\nsion\nagric\nultur\ne\nauto\n\
    mati\non\nprod\nuctio\nn\nartifi\ncial\nintell\nigenc\ne\npadd\ny\nrice\ndisea\n\
    se\ndete\nction\nyield\npredi\nction\ncrop wate\nr\nsoil livest\nock\nfood\nsecur\n\
    ity\n-\n23\n18\n8\n32\n2\n2\n3\n4\n8\n13\n4\n0\n0\n4\n3\n19\n8\n11\n0\n4\nQ4\n\
    2\n3\n4\n5\n0\n2\n1\n1\n2\n1\n1\n0\n0\n0\n0\n1\n1\n1\n0\n0\nQ3\n8\n5\n4\n8\n2\n\
    0\n2\n1\n3\n4\n4\n0\n0\n2\n0\n5\n2\n4\n0\n0\nQ2\n2\n3\n4\n7\n0\n0\n2\n0\n0\n4\n\
    4\n0\n0\n0\n0\n2\n1\n1\n0\n1\nQ1\n8\n4\n4\n10\n3\n0\n1\n0\n0\n6\n2\n1\n0\n0\n\
    1\n5\n3\n2\n0\n2\n0\n10\n20\n30\n40\n50\n60\n70\nArticle by quartil - Scopus\n\
    Q1\nQ2\nQ3\nQ4\n-\nFigure 6. Distribution of objects in the vertical farm of 68\
    \ selected articles by quartiles (Scopus).\nComputers 2022, 11, x FOR PEER REVIEW\
    \ \n9 of 20 \n \n \nFigure 7. Distribution of trends in vertical farming of 68\
    \ articles selected by year. \nagric\nultur\ne\nsmar\nt\nfarm\ning\nintell\nigen\n\
    verti\ncal\nfarm\nsmar\nt\nagric\nultur\ne\nindu\nstry\nclim\nate\npreci\nsion\n\
    agric\nultur\ne\nauto\nmati\non\nprod\nuctio\nn\nartifi\ncial\nintell\nigen\n\
    ce\npadd\ny\nrice\ndisea\nse\ndetec\ntion\nyield\npredi\nction\ncrop wate\nr\n\
    soil lives\ntock\nfood\nsecur\nity\n2022\n8\n6\n7\n17\n0\n1\n4\n0\n4\n9\n5\n1\n\
    0\n1\n1\n9\n3\n4\n0\n3\n2021\n19\n12\n9\n20\n3\n1\n2\n3\n2\n13\n7\n0\n0\n2\n1\n\
    10\n3\n4\n0\n2\n2020\n8\n7\n6\n11\n2\n1\n1\n0\n2\n2\n1\n0\n0\n2\n0\n7\n6\n4\n\
    0\n0\n2019\n6\n6\n1\n9\n2\n1\n1\n2\n3\n3\n1\n0\n0\n0\n2\n4\n3\n5\n0\n2\n2018\n\
    2\n1\n1\n3\n0\n0\n1\n1\n1\n1\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n2017\n0\n0\n0\n1\n\
    0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n2016\n0\n0\n0\n0\n0\n0\n0\n0\n\
    0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n10\n20\n30\n40\n50\n60\n70\nTREND RESEARCH\
    \ OBJECT YEARS\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n5\n10\n15\n20\n25\n\
    30\n35\nTREND RESEARCH ARTIFICIAL INTELLEGENCE YEARS\n2016\n2017\n2018\n2019\n\
    2020\n2021\n2022\nFigure 7. Distribution of trends in vertical farming of 68 articles\
    \ selected by year.\nComputers 2022, 11, 135\n9 of 19\n \nFigure 7. Distribution\
    \ of trends in vertical farming of 68 articles selected by year. \n \nFigure 8.\
    \ Distribution of artificial intelligence trends in vertical farming of 68 articles\
    \ selected by \nyear. \n2.3. AI Research Trends in Vertical Farming \nArtificial\
    \ intelligence (AI) involves the development of theories and computer sys-\ntems\
    \ capable of performing tasks that require human intelligence, such as sensory\
    \ percep-\ntion and decision making [38] which are combined with Cloud Computing,\
    \ IoT, and big \ndata. AI, especially in machine learning (ML) and deep learning\
    \ (DL) aspects, is consid-\nered one of the main drivers behind the digitalization\
    \ of smart agriculture. This technol-\nogy has the potential to increase crop\
    \ production and improve real-time monitoring, har-\nvesting, processing, and\
    \ marketing [39]. Several intelligent farming systems were devel-\noped that use\
    \ ML and DL algorithms to define various parameters such as smart irriga-\ntion,\
    \ lighting, weed detection, yield prediction, or disease identification. The type\
    \ of ver-\ntical farming proposed to be a smart farm has been reviewed in several\
    \ kinds of literature \n2021\n19\n12\n9\n20\n3\n1\n2\n3\n2\n13\n7\n0\n0\n2\n1\n\
    10\n3\n4\n0\n2\n2020\n8\n7\n6\n11\n2\n1\n1\n0\n2\n2\n1\n0\n0\n2\n0\n7\n6\n4\n\
    0\n0\n2019\n6\n6\n1\n9\n2\n1\n1\n2\n3\n3\n1\n0\n0\n0\n2\n4\n3\n5\n0\n2\n2018\n\
    2\n1\n1\n3\n0\n0\n1\n1\n1\n1\n1\n0\n0\n1\n0\n1\n0\n1\n0\n0\n2017\n0\n0\n0\n1\n\
    0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n2016\n0\n0\n0\n0\n0\n0\n0\n0\n\
    0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nmachin\ne\nlearnin\ng\ndeep\nlearnin\ng\n\
    supervi\nsed\nlearnin\ng\nunsuper\nvised\nlearnin\ng\nregressi\non\nclassifi\n\
    cation\npredicti\non\nforecast\ning\nclusteri\nng\ndecisio\nn\nsupport\nsystem\n\
    robotic\ncomput\ner\nvision\n2022\n8\n4\n0\n0\n0\n3\n3\n3\n0\n0\n4\n0\n2021\n\
    12\n3\n1\n0\n3\n1\n3\n0\n0\n0\n6\n0\n2020\n7\n0\n0\n0\n0\n0\n3\n0\n0\n0\n1\n1\n\
    2019\n4\n2\n0\n0\n0\n1\n3\n0\n0\n0\n2\n0\n2018\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\
    1\n0\n2017\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n2016\n0\n0\n0\n0\n0\n0\n0\n0\n\
    0\n0\n0\n0\n0\n5\n10\n15\n20\n25\n30\n35\nTREND RESEARCH ARTIFICIAL INTELLEGENCE\
    \ YEARS\n2016\n2017\n2018\n2019\n2020\n2021\n2022\nFigure 8. Distribution of artiﬁcial\
    \ intelligence trends in vertical farming of 68 articles selected by year.\n2.3.\
    \ AI Research Trends in Vertical Farming\nArtiﬁcial intelligence (AI) involves\
    \ the development of theories and computer systems\ncapable of performing tasks\
    \ that require human intelligence, such as sensory perception\nand decision making\
    \ [38] which are combined with Cloud Computing, IoT, and big data.\nAI, especially\
    \ in machine learning (ML) and deep learning (DL) aspects, is considered one\n\
    of the main drivers behind the digitalization of smart agriculture. This technology\
    \ has\nthe potential to increase crop production and improve real-time monitoring,\
    \ harvesting,\nprocessing, and marketing [39]. Several intelligent farming systems\
    \ were developed that\nuse ML and DL algorithms to deﬁne various parameters such\
    \ as smart irrigation, lighting,\nweed detection, yield prediction, or disease\
    \ identiﬁcation. The type of vertical farming\nproposed to be a smart farm has\
    \ been reviewed in several kinds of literature as well as\nreviews conducted with\
    \ a focus on artiﬁcial intelligence [2,4]. One of the ﬁndings of this\nreview\
    \ is that machine learning and deep learning algorithms are proven to be better\
    \ in\nproviding high-accuracy quality results compared to other algorithms in\
    \ terms of accuracy\nwhen applied to various agricultural problems, such as disease\
    \ detection and identiﬁcation,\nfruit or crop classiﬁcation, and fruit counting\
    \ among other domains [40]. Figure 9 shows\nthe trend of the artiﬁcial intelligence\
    \ approach based on a literature study.\nFigure 9 describes the research trend\
    \ of the vertical farming model structure taken\nfrom 68 related articles, under\
    \ research studies on types and structures of vertical farming\ndevelopment with\
    \ soil use, hydroponics, energy use, and indoor lighting systems. Study\nanalysis\
    \ shows that most of the research focuses on open farming systems and large areas\n\
    of land, compared to research on vertical farming systems. This is due to the\
    \ high costs\nassociated with developing intelligent technologies and systems\
    \ which typically also in-\nvolve hardware installation. The centralized network\
    \ subscriptions and software packages\nare required to facilitate data processing,\
    \ management of IoT devices and equipment, and\nknowledge exchange, which in turn\
    \ increases operational costs.\nBased on the literature study described in Table\
    \ 3, it was found that AI and ML tech-\nniques are still rarely explored in indoor\
    \ vertical farming systems, whether they are using\nsoil media or without, especially\
    \ for hydroponics, aquaponics, and aeroponics [32]. There\nare only a few publications\
    \ listed in the table related to intelligent system models with\nML techniques.\
    \ Unlike the case with artiﬁcial intelligence in agricultural applications that\n\
    are not vertical land models, many explorations with machine learning in agriculture\
    \ are\nclassiﬁed into three categories, i.e., supervised learning, unsupervised\
    \ learning, and rein-\nforcement learning [34]. ML techniques and algorithms that\
    \ have been widely implemented\nin the agricultural sector are for prediction\
    \ of crop yields, disease and weed detections,\nComputers 2022, 11, 135\n10 of\
    \ 19\nweather prediction (rainfall), estimation of soil properties (type, moisture\
    \ content, pH,\ntemperature, etc.), water management, determination of the optimal\
    \ amount of fertilizer, as\nwell as livestock production and management [15].\n\
    Computers 2022, 11, x FOR PEER REVIEW \n10 of 20 \n \nas well as reviews conducted\
    \ with a focus on artificial intelligence [2,4]. One of the find-\nings of this\
    \ review is that machine learning and deep learning algorithms are proven to \n\
    be better in providing high-accuracy quality results compared to other algorithms\
    \ in terms \nof accuracy when applied to various agricultural problems, such as\
    \ disease detection and \nidentification, fruit or crop classification, and fruit\
    \ counting among other domains [40]. \nFigure 9 shows the trend of the artificial\
    \ intelligence approach based on a literature study. \n \nFigure 9. Distribution\
    \ of IoT trends in vertical farms from 68 selected articles by year. \nFigure\
    \ 9 describes the research trend of the vertical farming model structure taken\
    \ \nfrom 68 related articles, under research studies on types and structures of\
    \ vertical farming \ndevelopment with soil use, hydroponics, energy use, and indoor\
    \ lighting systems. Study \nanalysis shows that most of the research focuses on\
    \ open farming systems and large areas \nof land, compared to research on vertical\
    \ farming systems. This is due to the high costs \nassociated with developing\
    \ intelligent technologies and systems which typically also in-\nvolve hardware\
    \ installation. The centralized network subscriptions and software pack-\nages\
    \ are required to facilitate data processing, management of IoT devices and equipment,\
    \ \nand knowledge exchange, which in turn increases operational costs. \nBased\
    \ on the literature study described in Table 3, it was found that AI and ML tech-\n\
    niques are still rarely explored in indoor vertical farming systems, whether they\
    \ are using \nsoil media or without, especially for hydroponics, aquaponics, and\
    \ aeroponics [32]. There \nare only a few publications listed in the table related\
    \ to intelligent system models with ML \ntechniques. Unlike the case with artificial\
    \ intelligence in agricultural applications that are \nnot vertical land models,\
    \ many explorations with machine learning in agriculture are clas-\nsified into\
    \ three categories, i.e., supervised learning, unsupervised learning, and reinforce-\n\
    ment learning [34]. ML techniques and algorithms that have been widely implemented\
    \ in \nthe agricultural sector are for prediction of crop yields, disease and\
    \ weed detections, \nweather prediction (rainfall), estimation of soil properties\
    \ (type, moisture content, pH, \ntemperature, etc.), water management, determination\
    \ of the optimal amount of fertilizer, \nas well as livestock production and management\
    \ [15]. \n \n \nFigure 9. Distribution of IoT trends in vertical farms from 68\
    \ selected articles by year.\nTable 3. Studies in the use of AI for the development\
    \ of intelligent vertical agriculture.\nModel\nML/Algorithms\nApproach\nApplication\n\
    Crops/Area\nObserved Features\nArticle\nGenetic Algorithm\nand Job-Shop\nScheduling\n\
    Presenting an efﬁcient\nmethod based on the\ngenetic algorithm\ndeveloped to solve\
    \ the\nproposed scheduling\nproblem\nIndoor vertical\nfarming\nfruits\nControl\
    \ and increase\nfood production and\npredict harvest time\n[36]\nRNG k-epsilon\n\
    model\nRNG k is implemented\nto consider the impact of\nair pressure and barriers\n\
    in the computing\ndomain\nIndoor vertical\nfarming\nVegetable plant\nA three-dimensional\n\
    numerical model for\noptimizing airﬂow and\nheat transfer in a vertical\nfarm\
    \ space system\ntaking into account\ncarbon dioxide\nconsumption, and\noxygen\
    \ production.\n[41]\nFuzzy Logic\nFuzzy logic handles\ncertainty and fuzzy\nevaluation\
    \ based on the\ndistance from the mean\nsolution (EDAS) method\nassists in the\
    \ system\nevaluation\ndecision-making\nprocess.\nHydroponics\nsystem in vertical\n\
    farming\nPlanting system\nwithout soil\nNumber of crops type,\nproduction volume,\n\
    attractiveness,\nsustainability, ﬂexibility,\nworkforce requirement,\nstock-out\
    \ cost,\ntransportation cost, and\ninvestment cost\n[42]\nComputers 2022, 11,\
    \ 135\n11 of 19\nTable 3. Cont.\nModel\nML/Algorithms\nApproach\nApplication\n\
    Crops/Area\nObserved Features\nArticle\nFuzzy Logic,\nWEDBA (Weighted\nEuclidean\
    \ Distance\nBased\nApproximation)\nand MACBETH\n(Measuring\nAttractiveness by\
    \ a\nCategorical Based\nEvaluation\nTechnique)\nThe WEDA and\nMACBETH methods\n\
    were used to rank three\nsmart farming\nalternatives in urban\nareas\nSmart system\
    \ in\nhydroponic\nvertical farming\nPlanting system\nwithout soil\nVenture capital\n\
    attractiveness, effective\nmanufacturing process,\nworkforce requirement,\nsecurity,\
    \ space\nrequirement, R&D\ncapabilities, expansion\nopportunities,\ninvestment,\
    \ and\nmaintenance cost\n[43]\nInteger Linear\nProgram\n(ILP)-Crop Growth\nPlanning\
    \ Problem\n(CGPP)\nPresent four\nmathematical models for\nplanning the growth\
    \ of\ncrops in a vertical\nfarming system, which\nare\nstrengthened using\nvariable\
    \ ﬁxing and valid\ninequalities.\nVertical\nfarm\nLeaf\nvegetables\nMachine scheduling\
    \ and\nconﬁguration\n[44]\nMixed-Integer\nLinear\nProgramming\n(MIP)\nThree approaches\
    \ using\npolynomial, pseudo, and\nhybrid variables\n(polynomial end\npseudo)\n\
    Vertical farming\nelevator energy\nminimization\nproblem\n(VFEEMP)\nVertical agriculture\n\
    energy source\nDriving energy in\nvertical farms\n[45]\nComputer\nvision—Machine\n\
    learning\nViola-Jones\nalgorithm and Haar-like\nfeature extraction\nmethod for\
    \ the\nmachine learning\nDetect spot disease\nin tomatoes\nTelemetry vertical\n\
    farming\nDetection of spot disease\nin tomatoes is designed\nusing\n377 images\
    \ of infected\ntomatoes\n[46]\nMulti-criteria\ndecision-making\n(MCDM) and\nPythagorean\
    \ fuzzy\nset (PFS)\nPythagorean Fuzzy\nChoquet Integral\n(PFCIµ)\nMulti-criteria\n\
    decision-making\n(MCDM) framework to\nassess the VF systems. A\nnovel Pythagorean\
    \ fuzzy\nset (PFS) with Choquet\nIntegral model\nintegrated is\nrecommended for\
    \ VF\ntechnology evaluation\nVertical farming\nfeasibility\nevaluation\nframework\n\
    Comparative study\nof agricultural\nvertical land\nEvaluate the urban\nfarming\
    \ framework to\nchoose the right strategy\nand change the strategy\n[47]\nFuzzy\
    \ Logic\nThe fuzzy logic control\nwill be based on the\nstate of charge (SoC)\
    \ of\neach node. A wireless\nsensor network (WSN)\nwill provide two-way\ncommunication\
    \ between\nnodes and coordinators.\nDevelopment and\ndesign of power\ngeneration\
    \ and\ndistribution\noptimized for\nvertical farming.\nPower generation\nand distribution\n\
    for vertical\nfarming\nNew renewable energy\nin vertical farming\n[48]\nSupport\
    \ Vector\nMachine (SVM),\nDecision Tree (DT),\nand Neural\nNetwork (NN)\nThree\
    \ categories of AI\nmodels commonly\nused in soil\nmanagement and\nagricultural\
    \ production\nto enable smart farming\nto be introduced\nMultiphonics\nVertical\
    \ Farming\n(MVF) system\nLeaf vegetable\nThe study discusses how\nAI is adopted\
    \ in soil\nmanagement and MVF\nfor tasks including\nclassiﬁcation, detection,\n\
    and forecasting\n[49]\nComputers 2022, 11, 135\n12 of 19\nTable 3. Cont.\nModel\n\
    ML/Algorithms\nApproach\nApplication\nCrops/Area\nObserved Features\nArticle\n\
    Feed Forward\nNeural Network\nRegression type\nfeed-forward deep\nlearning\na\
    \ neural network has\nbeen utilized\nGreenhouse\nTomatoes\nThe growth of the plants\n\
    is checked every 24 h\nand based on the\ngrowth, the necessary\nconditions are\
    \ provided\nfor the target growth\n[50]\nMachine\nlearning-computer\nvision\n\
    Automatic method for\nextracting phenotype\nfeatures, based on CV,\n3D modeling\
    \ and deep\nlearning. From the\nextracted features,\nheight, weight, and leaf\n\
    area were\npredicted and validated\nwith ground truths\nobtained manually\nVertical\
    \ farms with\nartiﬁcial lighting\n(VFAL)\nVegetables\nMethods for\nvision-based\
    \ plant\nphenotyping in\nindoor vertical farm\nunder artiﬁcial lighting.\nThis\
    \ method combines\n3D plant modeling and\ndeep segmentation of\nhigher leaves,\
    \ for 25–30\ndays, associated with\ngrowth\n[51]\n2.4. IoT Research Trends in\
    \ Vertical Farming\nIoT refers to interconnected computing devices, sensors, actuation\
    \ equipment, and\nmachines connected to the internet, each with a unique identity\
    \ and ability to perform\nremote sensing and monitoring [52]. IoT reference model\
    \ architecture has six layers, i.e.,\nphysical devices and controllers, connectivity/network,\
    \ edge/fog computing, data accumu-\nlation, data abstraction, and application\
    \ layer (user interface) [4]. The development of IoT\napplications in vertical\
    \ farms requires the support of hardware and software infrastructure\nas well\
    \ as communication media to ensure the interconnection of various heterogeneous\n\
    components [53]. This support is one of the vertical efforts of agriculture in\
    \ Industrial Tech-\nnology 4.0, namely the cyber-physical system (CPS) which refers\
    \ to a distributed system\nthat combines physical devices with communication networks\
    \ automatically. CPS bene-\nﬁts from various existing technologies, namely intelligent\
    \ agents, IoT, cloud computing,\ncomputer vision, big data, ML, and DL [54].\n\
    A wireless sensor network (WSN) is considered a type of technology used in IoT\n\
    systems. It can be deﬁned as a group of spatially distributed sensors for monitoring\
    \ the\nphysical conditions of the environment, temporarily storing the collected\
    \ data, and trans-\nmitting the collected information at a central location [6,55].\
    \ The results of the study that IoT\nis applied signiﬁcantly in agriculture, due\
    \ to its broad purpose and function in monitoring,\ntracking, tracing, agricultural\
    \ intelligent machines, and precision agriculture [52], which is\none of the main\
    \ research objectives in the smart farming approach. However, there are still\n\
    few studies that conduct some research on vertical agricultural land by considering\
    \ data\nreliability, interoperability, and IoT smart systems in the development\
    \ of the intelligent\nvertical farming system. This can be seen in Figure 10;\
    \ the trend of IoT-based agricultural\nresearch that focuses on the research of\
    \ IoT applications, monitoring (water, temperature,\nhumidity, pH), and lighting\
    \ systems.\nThe results of the studies from previous research on IoT applications\
    \ on vertical farms\nin Table 4 have been developed for the management of various\
    \ services on vertical farms.\nMost systems are still classiﬁed as prototype and\
    \ conceptual. Considerable research has\nbeen reported on greenhouses, but none\
    \ was found that is relevant to vertical farming.\nThe application of IoT in vertical\
    \ farming has attracted signiﬁcant research because its\napplication has potential\
    \ in various ﬁelds, such as the application of the CPS model to\nvertical farming\
    \ applications, and is a challenge because it requires the right hardware and\n\
    software [56].\nComputers 2022, 11, 135\n13 of 19\nComputers 2022, 11, x FOR PEER\
    \ REVIEW \n14 of 20 \n \n \nFigure 10. Trend-type structure distribution in vertical\
    \ farms from 68 articles selected by year. \nTable 4. IoT applications in vertical\
    \ farming. \nArea \nApplication \nApproach Method \nReference \nHydroponics, Tomato\
    \ plant \ngrowth \nDeveloped using Arduino, \nRaspberry Pi3, and Tensor \nFlow.\
    \ \nDeep Neural Networks \n[57] \nUrban farming \nNB-IoT sensor network (de-\n\
    ployed in balconies of two \nmultistory building struc-\ntures) \nFuzzy logic\
    \ \n[58] \nUrban farming decision sup-\nport framework \nDSS to online database\
    \ cap-\ntured by IoT technologies \nand robotic machines, it is \npromising to\
    \ achieve a high \nlevel of automation in the \nfield of urban agriculture \n\
    Decision support systems \n(DSS) based on modeling \nand simulation have \nbeen\
    \ developed to assess \nfarming systems \n[59] \nPlant Factory Artificial Light\
    \ \n(PFAL) management system \nUse of artificial \nintelligence (AI) with a \n\
    database, Internet of Things \n(IoT), light-emitting diodes \n(LEDs), and phenotyping\
    \ \nunit \nAI-based smart PFAL \nmanagement system \n[60] \nPlan Factory \nGreenhouse\
    \ environmental \nmonitoring, develop complex\nmathematical models to min-\nimize\
    \ energy input or use so-\nlar or wind energy \nControlled \nenvironment agriculture\
    \ \n(CEA) \n[61] \nSmart indoor farming—se-\ncure and self-adapting \nThe important\
    \ element for \nsuch solutions is a cloud, IoT, \nand robotics-based smart \n\
    farming framework. \nAgroRobot and Indoor Farm-\ning Support as a Service \n(IFSaaS)\
    \ \n[62] \nReal-Time Greenhouse Envi-\nronmental Conditions \nDetermination of\
    \ nutrients \nneeded for plant growth, \nClustering quantity using the \nK-means\
    \ method and a \n[63] \nhydroponics\naquaponics\nskygreen\nskyfarm\nsoil\nlight\n\
    solar\nwater\n2022\n2\n0\n0\n0\n4\n4\n0\n3\n2021\n2\n0\n0\n0\n4\n5\n0\n3\n2020\n\
    4\n1\n0\n0\n4\n3\n1\n6\n2019\n3\n1\n0\n0\n5\n2\n1\n3\n2018\n0\n0\n0\n0\n1\n0\n\
    0\n0\n2017\n1\n0\n0\n0\n1\n1\n0\n0\n2016\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2\n4\n6\n\
    8\n10\n12\n14\n16\n18\n20\nTREND RESEARCH TYPE STRUCTURE VF\n2016\n2017\n2018\n\
    2019\nFigure 10. Trend-type structure distribution in vertical farms from 68 articles\
    \ selected by year.\nTable 4. IoT applications in vertical farming.\nArea\nApplication\n\
    Approach Method\nReference\nHydroponics, Tomato plant\ngrowth\nDeveloped using\
    \ Arduino, Raspberry\nPi3, and Tensor Flow.\nDeep Neural Networks\n[57]\nUrban\
    \ farming\nNB-IoT sensor network (deployed in\nbalconies of two multistory\nbuilding\
    \ structures)\nFuzzy logic\n[58]\nUrban farming decision support\nframework\n\
    DSS to online database captured by IoT\ntechnologies and robotic machines, it\
    \ is\npromising to achieve a high level of\nautomation in the ﬁeld of\nurban agriculture\n\
    Decision support systems (DSS) based\non modeling and simulation have\nbeen developed\
    \ to assess farming\nsystems\n[59]\nPlant Factory Artiﬁcial Light\n(PFAL) management\
    \ system\nUse of artiﬁcial\nintelligence (AI) with a\ndatabase, Internet of Things\n\
    (IoT), light-emitting diodes\n(LEDs), and phenotyping\nunit\nAI-based smart PFAL\n\
    management system\n[60]\nPlan Factory\nGreenhouse environmental monitoring,\n\
    develop complex mathematical models\nto minimize energy input or use solar\nor\
    \ wind energy\nControlled\nenvironment agriculture (CEA)\n[61]\nSmart indoor farming—secure\n\
    and self-adapting\nThe important element for such\nsolutions is a cloud, IoT,\
    \ and\nrobotics-based smart farming\nframework.\nAgroRobot and Indoor Farming\n\
    Support as a Service (IFSaaS)\n[62]\nReal-Time Greenhouse\nEnvironmental Conditions\n\
    Determination of nutrients needed for\nplant growth, such as nitrogen (N),\nphosphorus\
    \ (P), and potassium (K) in\nsoil or water, is the key to vertical or\nclosed\
    \ crop cultivation with IoT\nClustering quantity using the K-means\nmethod and\
    \ a prediction approach\nusing the Self-Organizing Map (SOM)\nmethod to enhance\
    \ the device capacity\nand real-time analytics\n[63]\nComputers 2022, 11, 135\n\
    14 of 19\nTable 4. Cont.\nArea\nApplication\nApproach Method\nReference\nCPS/IoT\
    \ Ecosystem: Indoor\nVertical Farming System\nA prototype is a service-oriented\n\
    platform distributed over three scopes\nof operation: cloud, fog,\nsensor/actuator\n\
    Smart agricultural systems using\nCPS/IoT infrastructure and\noffering Infrastructure-as-a-Service\n\
    (IaaS) and Experiment-as-a-Service\n(EaaS) for smart farming\n[53]\nDigital Twins\
    \ for Vertical\nFarming\nDesign science research paradigm,\naiming at the joint\
    \ creation of\nphysical and digital layers of\nIoT-enabled structures for vertical\n\
    farming\nA digital twin reference model for\nIoT-enabled\nstructures of vertical\
    \ farming\n[64]\nAutomatic vertical hydroponic\nfarming\nThe design\nand implementation\
    \ of automated\nvertical hydro farming techniques with\nIoT platforms, and their\
    \ analytics will\nbe conducted using big data analytics\nAutomatic robotic system\
    \ design and\ndevelopment\n[65]\nIoT-Enabled in Smart Vertical\nFarming\nApplication\
    \ of IoT-Enabled Smart\nAgriculture in Vertical Farming\nThe web-based\napplication\
    \ can be used to analyze and\nmonitor the light, temperature,\nhumidity, and\n\
    soil moisture of the vertical farming\nstacks\n[22]\nReview adoption of vertical\n\
    gardens (VG) and/or vertical\nfarms (VF)\nAutomating sustainable vertical\ngardening\
    \ systems by using the IoT\nconcept in smart cities toward\nsmart living\nLiterature\
    \ review\n[66]\nIndoor Vertical Farming\nBuild a\nsystem to monitor the soil moisture\
    \ and\ncontrol water content\nAutomatic\na system, which consists of the Internet\n\
    of Things [IoT]\n[67]\n3. Results and Discussion\nBased on the review, the proposed\
    \ framework maps primarily onto three entities\nconsisting of a vertical land\
    \ smart model, AI/machine learning, and IoT. The literature\nsources were obtained\
    \ from 2016 to 2022 and an article processing approach was carried\nout using\
    \ PRISMA based on the search keywords in Table 1, which obtained 68 limited\n\
    articles indexed by Scopus in quartile 1 as many as 11, quartile 2 as many as\
    \ seven, quartile\n3 as many as 11, quartile 4 as many as six and no quartile\
    \ 33 articles. The distribution\nof reputation-indexed scientiﬁc articles at the\
    \ quartile level (Scopus), with details are\nas follows: Q1 16%, Q2 16%, Q3 10%,\
    \ Q4 95 and No Q 49%. The trend of the number\nof research and publications continues\
    \ to increase in the application of digitalization of\nvertical agriculture by\
    \ utilizing artiﬁcial intelligence. A review from the year that the trend\nis\
    \ always increasing, it can be seen in 2021 by 32%, which is described in Figures\
    \ 3 and 4. A\ntotal of 91% of the selected articles discuss vertical agriculture\
    \ as shown in Figures 5 and 6.\nThe distribution of the use of artiﬁcial intelligence\
    \ has been widely conducted and found;\nthis is seen in 47% of usage on machine\
    \ learning, 22% on robotic automation, and 13% with\ndeep learning approaches.\
    \ The IoT approach can be seen from the discussion of the sensor,\nmonitoring,\
    \ and LED applications which is shown in Figure 9, with a 28% soil research\n\
    object model, 18% hydroponics, and 22% lighting and irrigation.\nVertical agriculture\
    \ has great potential to meet the future food demand by strength-\nening the digital\
    \ farming system to support precision in agriculture with technology and\nartiﬁcial\
    \ intelligence. The prospects of vertical farming in smart agriculture involve\
    \ the use\nof explainable artiﬁcial intelligence to monitor crop growth, forecast\
    \ crop nutrition, evaluate\nplant health, and control pests and diseases. The\
    \ described AI removes the traditional\nComputers 2022, 11, 135\n15 of 19\nparadigm\
    \ concept of machine learning and allows for an understanding of the reasons\n\
    behind certain decisions [68].\nIoT integration in vertical farming is focused\
    \ on optimization and automation tech-\nnologies that seamlessly integrate knowledge,\
    \ products, and services to achieve high\nproductivity, quality, and proﬁt. Not\
    \ much research has been conducted and put forward\nregarding the incubation of\
    \ the IoT concept in the vertical agriculture sector. The main\nﬁndings of several\
    \ studies are presented in Table 4.\nVarious technological problems and architectural\
    \ problems have been addressed\nthrough the development of an IoT-based vertical\
    \ farming smart system, but most of these\nsystems are either in the conceptual\
    \ stage or in prototype form at this time. Its main focus\nlies in farm management,\
    \ irrigation control, crop growth, crop health monitoring, and\ndisease detection.\
    \ Some of these studies have also explained the implementation of IoT\nin modern\
    \ agricultural systems such as vertical farming (soilless farming—aquaponics,\n\
    hydroponics, and aeroponics) and greenhouse farming (soil-based). In addition,\
    \ most\nresearch focuses on addressing speciﬁc problems.\nArtiﬁcial intelligence\
    \ approaches and digital technologies in vertical farming make\nagricultural processes\
    \ more environmentally friendly, and climate-resistant, signiﬁcantly\nreducing\
    \ crop failure and ﬁeld growth, and also reducing the usage of nitrogen fertilizers,\n\
    pesticides, and herbicides [35]. Based on the ﬁndings summarized in the previous\
    \ section,\nmachine learning algorithms and IoT smart technologies can be used\
    \ to increase the overall\nefﬁciency of a vertical agricultural production system.\
    \ However, in the review, the types\nof algorithms discussed in Table 3 have not\
    \ been mentioned much in vertical farming; in\nthis case, models on machine learning\
    \ or deep learning. The analysis shows that several\nstudies have focused on vertical\
    \ farming.\nThe research ﬁndings also show that most of the use cases are still\
    \ in the prototype\nstage. This is due to the complex design and management of\
    \ indoor farming, especially\nsoilless agriculture where the parameters and factors\
    \ (pH, air temperature, humidity, etc.)\nto be controlled vary [69] considerably.\
    \ By looking at Tables 3 and 4 in Section 3, it can\nbe seen that some of the\
    \ uses of artiﬁcial intelligence algorithms from machine learning\nand deep learning\
    \ as well as technologies such as big data and analytics, wireless sensor\nnetworks,\
    \ cyber-physical systems, and digital twins in the ﬁeld of vertical farming have\n\
    not been signiﬁcantly explored. In addition, the costs required to develop smart\
    \ models for\nvertical farming are still expensive, which include deployment,\
    \ operation, and maintenance\ncosts [70].\nThe reliability of the sensor devices,\
    \ as well as the appropriate software applications\nare very important. This is\
    \ because IoT devices need to collect and transfer data based\non decisions made\
    \ using multiple software packages. Unreliable sensing, processing, and\ntransmission\
    \ can lead to erroneous monitoring data reports, long delays, and even data\n\
    loss, thus ultimately impacting agricultural system performance [71]. Standardization\
    \ is\nneeded to take full advantage of digital technology for smart vertical farming\
    \ applications,\nparticularly in device standardization. With standardization,\
    \ device, application, and\nsystem interoperability problems can also be solved.\
    \ The results of previous research on\nvertical farming applications have been\
    \ developed to manage various vertical farming\nservices. Most of the study systems\
    \ are still classiﬁed as prototype and conceptual. Then,\na lot of research was\
    \ conducted on greenhouses, and no investigation was found that\nis relevant to\
    \ the farming system that has been applied. There are still new research\nopportunities\
    \ to investigate and study indoor food crop production using smart and\nprecision\
    \ vertical farming.\n4. Conclusions\nThe results of this study contribute to research\
    \ that will be carried out around vertical\nagriculture to support Agriculture\
    \ 4.0. Vertical farming with AI, ML, and DL approaches\nhas been carried out in\
    \ several previous studies. The main limitation of this review is that\nit uses\
    \ only the prioritized online repositories for literature searches (Scopus, IEEE,\
    \ and\nComputers 2022, 11, 135\n16 of 19\nScience Direct). Second, additional\
    \ keywords and synonyms can result in more research.\nSLR implementation with\
    \ PRISMA received 68 articles from 2016 to 2022 discussing the\nproblems and recommendations\
    \ for vertical farming presented in this study. The pattern\nin the vertical agriculture\
    \ sector is continually increasing. The results can be selected in\n2021 by 32%,\
    \ as depicted in Figures 3 and 4. A total of 91% of articles were chosen to\n\
    discuss vertical agriculture, as shown in Figures 5 and 6. The distribution of\
    \ the use of\nartiﬁcial intelligence has been completed and discovered. This is\
    \ seen in 47% of usage\non machine learning, 22% on robotic automation, and 13%\
    \ on deep learning approaches.\nThe IoT approach can be seen from the discussion\
    \ of the sensor, monitoring, and LED\napplications shown in Figure 9, with a 28%\
    \ soil research object model, 18% hydroponics,\nand 22% lighting and irrigation.\
    \ The research questions posed are regarding the types of\ndigital technologies\
    \ used in vertical farming of innovative farming relationships, the level\nof\
    \ development and intelligent models adopted, and the challenges and barriers\
    \ to gaining\nopportunities from implementing intelligent vertical farming systems.\
    \ The added value of\nvertical agriculture has various advantages compared to\
    \ horizontal rice ﬁelds, as seen from\nthe three pillars of sustainability; namely\
    \ environmental, social, and economic, in the effort\nof world food security.\
    \ The results of studies from previous research on IoT applications in\nvertical\
    \ farms have been developed to manage various services on vertical farms. Most\n\
    of the systems are still classiﬁed as prototypes and mainly carried out conceptually\
    \ for\ngreenhouses. No relevant research on basic crop farming systems such as\
    \ rice, soybean, or\nwheat has been implemented. With the results shown from the\
    \ number of articles reviewed,\nthe use of artiﬁcial intelligence algorithms from\
    \ machine learning and deep learning as well\nas technologies such as big data\
    \ and analytics, wireless sensor networks, cyber-physical\nsystems, and digital\
    \ twins have not been signiﬁcant and explored in vertical farming. This\nis because\
    \ the costs required to develop an intelligent vertical farming model are still\n\
    expensive, including implementation, operational, and maintenance costs. This\
    \ research\nreveals that there are new research opportunities to investigate and\
    \ study indoor food crop\nproduction using smart and precision vertical farming.\n\
    Author Contributions: Conceptualization, K.B.S. and R.R.A.S.; methodology, K.B.S.\
    \ and R.R.A.S.;\nsoftware, R.R.A.S.; validation, K.B.S., S.W. and E.S.; formal\
    \ analysis, K.B.S., S.W. and E.S.; investiga-\ntion, E.S. and S.W.; resources,\
    \ R.R.A.S.; data curation, R.R.A.S.; writing—original draft preparation,\nR.R.A.S.\
    \ and K.B.S.; writing—review and editing, R.R.A.S. and K.B.S.; visualization,\
    \ S.W.; supervision,\nK.B.S.; project administration, K.B.S. All authors have\
    \ read and agreed to the published version of\nthe manuscript.\nFunding: This\
    \ research received no external funding.\nInstitutional Review Board Statement:\
    \ Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability\
    \ Statement: The study did not report any data.\nConﬂicts of Interest: The authors\
    \ declare no conﬂict of interest.\nReferences\n1.\nUnited Nations News Service.\
    \ “UN News—UN Projects World Population to Reach 8.5 Billion by 2030, Driven by\
    \ Growth\nin Developing Countries” UN News. 2015. Available online: http://www.un.org/apps/news/story.asp?NewsID=51526#\n\
    .VkcOinYrLIW (accessed on 23 June 2021).\n2.\nAlfred, R.; Obit, J.H.; Chin, C.P.-Y.;\
    \ Haviluddin, H.; Lim, Y. Towards Paddy Rice Smart Farming: A Review on Big Data,\
    \ Machine\nLearning, and Rice Production Tasks. IEEE Access 2021, 9, 50358–50380.\
    \ [CrossRef]\n3.\nBaumont De Oliveira, F.J.; Ferson, S.; Dyer, R. A Collaborative\
    \ Decision Support System Framework for Vertical Farming Business\nDevelopments.\
    \ Int. J. Decis. Support Syst. Technol. 2021, 13, 34–66. [CrossRef]\n4.\nAhmad,\
    \ L.; Nabi, F. Agriculture 5.0: Artiﬁcial Intelligence, IoT, and Machine Learning,\
    \ 1st ed.; CRC Press: Boca Raton, FL, USA;\nTaylor & Francis Group, LLC: Abingdon,\
    \ UK, 2021; ISBN 9780367646080.\n5.\nChen, J.; Yang, A. Intelligent Agriculture\
    \ and Its Key Technologies Based on Internet of Things Architecture. IEEE Access\
    \ 2019, 7,\n77134–77141. [CrossRef]\nComputers 2022, 11, 135\n17 of 19\n6.\nTzounis,\
    \ A.; Katsoulas, N.; Bartzanas, T.; Kittas, C. Internet of Things in agriculture,\
    \ recent advances and future challenges.\nBiosyst. Eng. 2017, 164, 31–48. [CrossRef]\n\
    7.\nKalantari, F.; Tahir, O.M.; Joni, R.A.; Fatemi, E. Opportunities and challenges\
    \ in sustainability of vertical farming: A review. J.\nLandsc. Ecol. Repub. 2018,\
    \ 11, 35–60. [CrossRef]\n8.\nDespommier, D. The rise of vertical farms. Sci. Am.\
    \ 2009, 301, 80–87. [CrossRef] [PubMed]\n9.\nLu, C.; Grundy, S. Urban Agriculture\
    \ and Vertical Farming; Elsevier: Amsterdam, The Netherlands, 2017; Volume 2,\
    \ ISBN\n9780128046777.\n10.\nSharath Kumar, M.; Heuvelink, E.; Marcelis, L.F.M.\
    \ Vertical Farming: Moving from Genetic to Environmental Modiﬁcation. Trends\n\
    Plant Sci. 2020, 25, 724–727. [CrossRef] [PubMed]\n11.\nIsmail, M.A.F.; Isa, M.N.M.;\
    \ Mohyar, S.N.; Ahmad, M.I.; Ismail, M.N.M.; Ismail, R.C.; Harun, A.; Murad, S.A.Z.\
    \ E-PADI: An\nIoT-based paddy productivity monitoring and advisory system. Indones.\
    \ J. Electr. Eng. Comput. Sci. 2019, 14, 852–858. [CrossRef]\n12.\nVilla-Henriksen,\
    \ A.; Edwards, G.T.C.; Pesonen, L.A.; Green, O.; Sørensen, C.A.G. Internet of\
    \ Things in arable farming: Implemen-\ntation, applications, challenges and potential.\
    \ Biosyst. Eng. 2020, 191, 60–84. [CrossRef]\n13.\nJaiswal, H.; Karmali Radha,\
    \ P.; Singuluri, R.; Sampson, S.A. IoT and Machine Learning based approach for\
    \ Fully Automated\nGreenhouse. In Proceedings of the 2019 IEEE Bombay Section\
    \ Signature Conference, Bombay, India, 26–28 July 2019. [CrossRef]\n14.\nGnanasankaran,\
    \ N.; Ramaraj, E. The effective yield of paddy crop in Sivaganga district—An initiative\
    \ for smart farming. Int. J.\nSci. Technol. Res. 2020, 9, 6452–6455.\n15.\nLiakos,\
    \ K.G.; Busato, P.; Moshou, D.; Pearson, S.; Bochtis, D. Machine learning in agriculture:\
    \ A review. Sensors 2018, 18, 2674.\n[CrossRef] [PubMed]\n16.\nTur, J.A.; Bibiloni,\
    \ M.M. Functional Foods, 1st ed.; Elsevier: Amsterdam, The Netherlands, 2015;\
    \ ISBN 9780123849533.\n17.\nAl-Kodmany, K. The vertical farm: A review of developments\
    \ and implications for the vertical city. Buildings 2018, 8, 24.\n[CrossRef]\n\
    18.\nJayaraman, P.P.; Yavari, A.; Georgakopoulos, D.; Morshed, A.; Zaslavsky,\
    \ A. Internet of things platform for smart farming:\nExperiences and lessons learnt.\
    \ Sensors 2016, 16, 1884. [CrossRef] [PubMed]\n19.\nBianchi, V.; Bassoli, M.;\
    \ Lombardo, G.; Fornacciari, P.; Mordonini, M.; de Munari, I. IoT Wearable Sensor\
    \ and Deep Learning: An\nIntegrated Approach for Personalized Human Activity Recognition\
    \ in a Smart Home Environment. IEEE Internet Things J. 2019, 6,\n8553–8562. [CrossRef]\n\
    20.\nBu, F.; Wang, X. A smart agriculture IoT system based on deep reinforcement\
    \ learning. Futur. Gener. Comput. Syst. 2019, 99,\n500–507. [CrossRef]\n21.\n\
    Bi, S.; Wang, C.; Zhang, J.; Huang, W.; Wu, B.; Gong, Y.; Ni, W. A Survey on Artiﬁcial\
    \ Intelligence Aided Internet-of-Things\nTechnologies in Emerging Smart Libraries.\
    \ Sensors 2022, 22, 2991. [CrossRef]\n22.\nBhowmick, S.; Biswas, B.; Biswas, M.;\
    \ Dey, A.; Roy, S.; Sarkar, S.K. Application of IoT-Enabled Smart Agriculture\
    \ in Vertical\nFarming. Lect. Notes Electr. Eng. 2019, 537, 521–528. [CrossRef]\n\
    23.\nSwain, M. Vertical Farming Trends and Challenges: A New Age of Agriculture\
    \ Using IoT and Machine Learning. In Internet of\nThings for Agriculture 4.0:\
    \ Impact and Challenges; Apple Academic Press: Boca Raton, FL, USA, 2022; pp.\
    \ 1–16. ISBN 9781000369274.\n24.\nSchimmelpfennig, D. Farm Proﬁts and Adoption\
    \ of Precision Agriculture. [Economic Research Report: #217]; United States Department\n\
    of Agriculture: Washington, DC, USA, 2016.\n25.\nSaiz-Rubio, V.; Rovira-Más, F.\
    \ From smart farming towards agriculture 5.0: A review on crop data management.\
    \ Agronomy 2020,\n10, 207. [CrossRef]\n26.\nCEMA. “CEMA—European Agricultural\
    \ Machinery—Priorities,” CEMA aisbl—European Agricultural Machinery Industry\n\
    Association. 2021. Available online: https://www.cema-agri.org/index.php?option=com_content&view=priorities&id=8&\n\
    Itemid=102 (accessed on 2 April 2021).\n27.\nAgriculture IoT Solutions. What Is\
    \ IoT in Agriculture? Farmers Aren’t Quite Sure Despite $4bn US Opportunity, Agfunder.\n\
    2018. Available online: https://agfundernews.com/iot-agriculture-farmers-arent-quite-sure-despite-4bn-us-opportunity.html/\n\
    (accessed on 2 April 2021).\n28.\nGralla, P. Precision Agriculture Yields Higher\
    \ Proﬁts, Lower Risks | HPE,” Hewlett Packard Enterprise Development LP. 2018.\n\
    Available online: https://www.hpe.com/us/en/insights/articles/precision-agriculture-yields-higher-proﬁts-lower-risks-18\n\
    06.html (accessed on 2 April 2021).\n29.\nDhivyaa, C.R.; Anbukkarasi, S.; Saravanan,\
    \ K. Machine Learning Approaches for Agro IoT Systems. Stud. Big Data 2021, 99,\n\
    93–111. [CrossRef]\n30.\nOgawa, S.; Selvaraj, M.G.; Ishitani, M. Crop Development\
    \ with Data-driven Approach towards Sustainable Agriculture: Lifting\nthe Achievements\
    \ and Opportunities of Collaborative Research between CIAT and Japan. Japan Agric.\
    \ Res. Q. 2021, 55, 463–472.\n[CrossRef]\n31.\nPage, M.J.; McKenzie, J.E.; Bossuyt,\
    \ P.M.; Boutron, I.; Hoffmann, T.C.; Mulrow, C.D.; Shamseer, L.; Tetzlaff, J.M.;\
    \ Akl, E.A.;\nBrennan, S.E.; et al. The PRISMA 2020 statement: An updated guideline\
    \ for reporting systematic reviews. BMJ 2021, 372, n71.\n[CrossRef] [PubMed]\n\
    32.\nAbbasi, R.; Martinez, P.; Ahmad, R. The digitization of agricultural industry—A\
    \ systematic literature review on agriculture 4.0.\nSmart Agric. Technol. 2022,\
    \ 2, 100042. [CrossRef]\nComputers 2022, 11, 135\n18 of 19\n33.\nPopkova, E.G.\
    \ Vertical Farms Based on Hydroponics, Deep Learning, and AI as Smart Innovation\
    \ in Agriculture. Smart Innov.\nSyst. Technol. 2022, 264, 257–262. [CrossRef]\n\
    34.\nNg, A.K.; Mahkeswaran, R. Emerging and Disruptive Technologies for Urban\
    \ Farming: A Review and Assessment. J. Phys. Conf.\nSer. 2021, 2003, 012008. [CrossRef]\n\
    35.\nKrishnan, A.; Swarna, S.; Balasubramanya, H.S. Robotics, IoT, and AI in the\
    \ Automation of Agricultural Industry: A Review. In\nProceedings of the 2020 IEEE\
    \ Bangalore Humanitarian Technology Conference (B-HTC), Vijiyapur, India, 8–10\
    \ October 2020.\n[CrossRef]\n36.\nAbukhader, R.; Kakoore, S. Artiﬁcial Intelligence\
    \ For Vertical Farming—Controlling The Food; Mälardalen University School of\n\
    Innovation, Design And Engineering: Västerås, Sweden, 2021.\n37.\nSaad, M.H.M.;\
    \ Hamdan, N.M.; Sarker, M.R. State of the art of urban smart vertical farming\
    \ automation system: Advanced\ntopologies, issues and recommendations. Electronics\
    \ 2021, 10, 422. [CrossRef]\n38.\nSharma, R.; Kamble, S.S.; Gunasekaran, A.; Kumar,\
    \ V.; Kumar, A. A systematic literature review on machine learning applications\n\
    for sustainable agriculture supply chain performance. Comput. Oper. Res. 2020,\
    \ 119. [CrossRef]\n39.\nTalaviya, T.; Shah, D.; Patel, N.; Yagnik, H.; Shah, M.\
    \ Implementation of artiﬁcial intelligence in agriculture for optimisation of\n\
    irrigation and application of pesticides and herbicides. Artif. Intell. Agric.\
    \ 2020, 4, 58–73. [CrossRef]\n40.\nRohit, R.V.S.; Chandrawat, D.; Rajeswari, D.\
    \ Smart Farming Techniques for New Farmers Using Machine Learning. Lect. Notes\n\
    Netw. Syst. 2021, 177, 207–220. [CrossRef]\n41.\nNaranjani, B.; Najaﬁanashraﬁ,\
    \ Z.; Pascual, C.; Agulto, I.; Chuang, P.Y.A. Computational analysis of the environment\
    \ in an indoor\nvertical farming system. Int. J. Heat Mass Transf. 2022, 186,\
    \ 122460. [CrossRef]\n42.\nTolga, A.C.; Gamsiz, B.; Basar, M. Evaluation of hydroponic\
    \ system in vertical farming via fuzzy EDAS method. Adv. Intell. Syst.\nComput.\
    \ 2020, 1029, 745–752. [CrossRef]\n43.\nCagri Tolga, A.; Basar, M. The assessment\
    \ of a smart system in hydroponic vertical farming via fuzzy MCDM methods. J.\
    \ Intell.\nFuzzy Syst. 2022, 42, 2–12. [CrossRef]\n44.\nSantini, A.; Bartolini,\
    \ E.; Schneider, M.; Greco de Lemos, V. The crop growth planning problem in vertical\
    \ farming. Eur. J. Oper.\nRes. 2021, 294, 377–390. [CrossRef]\n45.\nDelorme, M.;\
    \ Santini, A. Energy-efﬁcient automated vertical farms. Omega 2022, 109, 102611.\
    \ [CrossRef]\n46.\nSadik Tasrif Anubhove, M.; Ashraﬁ, N.; Saleque, A.M.; Akter,\
    \ M.; Saif, S.U. Machine Learning Algorithm based Disease Detection\nin Tomato\
    \ with Automated Image Telemetry for Vertical Farming. In Proceedings of the 2020\
    \ International Conference on\nComputational Performance Evaluation (ComPE), Shillong,\
    \ India, 2–4 July 2020; pp. 250–254. [CrossRef]\n47.\nBüyüközkan, G.; Göçer, F.;\
    \ Uztürk, D. A Novel Pythagorean Fuzzy Set Integrated Choquet Integral Approach\
    \ for Vertical Farming\nTechnology Assessment; Elsevier: Amsterdam, The Netherlands,\
    \ 2021; Volume 158.\n48.\nLabrador, C.G.; Ong, A.C.L.; Baldovino, R.G.; Valenzuela,\
    \ I.C.; Culaba, A.B.; Dadios, E.P. Optimization of power generation and\ndistribution\
    \ for vertical farming with wireless sensor network. In Proceedings of the 2018\
    \ IEEE 10th International Conference on\nHumanoid, Nanotechnology, Information\
    \ Technology, Communication and Control, Environment and Management (HNICEM),\n\
    Baguio City, Philippines, 29 November–2 December 2018. [CrossRef]\n49.\nChen,\
    \ Q.; Li, L.; Chong, C.; Wang, X. AI-enhanced soil management and smart farming.\
    \ Soil Use Manag. 2022, 38, 7–13. [CrossRef]\n50.\nWickramaarachchi, P.; Balasooriya,\
    \ N.; Welipenne, L.; Gunasekara, S.; Jayakody, A. Real-time greenhouse environmental\n\
    conditions optimization using neural network and image processing. In Proceedings\
    \ of the 2020 20th International Conference on\nAdvances in ICT for Emerging Regions\
    \ (ICTer), Colombo, Sri Lanka, 4–7 November 2020; pp. 232–237. [CrossRef]\n51.\n\
    Franchetti, B.; Ntouskos, V.; Giuliani, P.; Herman, T.; Barnes, L.; Pirri, F.\
    \ Vision based modeling of plants phenotyping in vertical\nfarming under artiﬁcial\
    \ lighting. Sensors 2019, 19, 4378. [CrossRef] [PubMed]\n52.\nPylianidis, C.;\
    \ Osinga, S.; Athanasiadis, I.N. Introducing digital twins to agriculture. Comput.\
    \ Electron. Agric. 2021, 184, 105942.\n[CrossRef]\n53.\nHaris, I.; Fasching, A.;\
    \ Punzenberger, L.; Grosu, R. CPS/IoT Ecosystem: Indoor Vertical Farming System.\
    \ In Proceedings of the\n2019 IEEE 23rd International Symposium on Consumer Technologies\
    \ (ISCT), Ancona, Italy, 19–21 June 2019; pp. 47–52. [CrossRef]\n54.\nJimenez,\
    \ A.F.; Cardenas, P.F.; Jimenez, F.; Canales, A.; López, A. A cyber-physical intelligent\
    \ agent for irrigation scheduling in\nhorticultural crops. Comput. Electron. Agric.\
    \ 2020, 178, 105777. [CrossRef]\n55.\nJawad, H.M.; Nordin, R.; Gharghan, S.K.;\
    \ Jawad, A.M.; Ismail, M. Energy-efﬁcient wireless sensor networks for precision\n\
    agriculture: A review. Sensors 2017, 17, 1781. [CrossRef]\n56.\nNayak, A.; Reyes\
    \ Levalle, R.; Lee, S.; Nof, S.Y. Resource sharing in cyber-physical systems:\
    \ Modelling framework and case studies.\nInt. J. Prod. Res. 2016, 54, 6969–6983.\
    \ [CrossRef]\n57.\nMehra, M.; Saxena, S.; Sankaranarayanan, S.; Tom, R.J.; Veeramanikandan,\
    \ M. IoT based hydroponics system using Deep Neural\nNetworks. Comput. Electron.\
    \ Agric. 2018, 155, 473–486. [CrossRef]\n58.\nPopli, S.; Jha, R.K.; Jain, S. Green\
    \ NOMA assisted NB-IoT based urban farming in multistory buildings. Comput. Netw.\
    \ 2021, 199,\n108410. [CrossRef]\n59.\nLi, L.; Li, X.; Chong, C.; Wang, C.H.;\
    \ Wang, X. A decision support framework for the design and operation of sustainable\
    \ urban\nfarming systems. J. Clean. Prod. 2020, 268, 121928. [CrossRef]\n60.\n\
    Kozai, T. Current Status of Plant Factories with Artiﬁcial Lighting (PFALs) and\
    \ Smart PFALs. Smart Plant Fact. 2018, 3–13.\n[CrossRef]\nComputers 2022, 11,\
    \ 135\n19 of 19\n61.\nShamshiri, R.R.; Kalantari, F.; Ting, K.C.; Thorp, K.R.;\
    \ Hameed, I.A.; Weltzien, C.; Ahmad, D.; Shad, Z. Advances in greenhouse\nautomation\
    \ and controlled environment agriculture: A transition to plant factories and\
    \ urban agriculture. Int. J. Agric. Biol. Eng.\n2018, 11, 1–22. [CrossRef]\n62.\n\
    Gnauer, C.; Pichler, H.; Tauber, M.; Schmittner, C.; Christl, K.; Knapitsch, J.;\
    \ Parapatits, M. Towards a secure and self-adapting\nsmart indoor farming framework.\
    \ Elektrotechnik Inf. 2019, 136, 341–344. [CrossRef]\n63.\nVadivel, R.; Parthasarathi,\
    \ R.; Navaneethraj, A.; Sridhar, P.; Muhammad Naﬁ, K.A.; Karan, S. Hypaponics-Monitoring\
    \ and\nControlling using Internet of Things and Machine Learning. In Proceedings\
    \ of the 2019 1st International Conference on\nInnovations in Information and\
    \ Communication Technology (ICIICT), Chennai, India, 25–26 April 2019. [CrossRef]\n\
    64.\nMonteiro, J.; Barata, J.; Veloso, M.; Veloso, L.; Nunes, J. Towards sustainable\
    \ digital twins for vertical farming. In Proceedings of\nthe 2018 Thirteenth International\
    \ Conference on Digital Information Management (ICDIM), Berlin, Germany, 24–26\
    \ September\n2018; pp. 234–239. [CrossRef]\n65.\nShrivastava, A.; Nayak, C.K.;\
    \ Dilip, R.; Samal, S.R.; Rout, S.; Ashfaque, S.M. Automatic robotic system design\
    \ and development\nfor vertical hydroponic farming using IoT and big data analysis.\
    \ Mater. Today Proc. 2021. [CrossRef]\n66.\nHalgamuge, M.N.; Bojovschi, A.; Fisher,\
    \ P.M.J.; Le, T.C.; Adeloju, S.; Murphy, S. Internet of Things and autonomous\
    \ control for\nvertical cultivation walls towards smart food growing: A review.\
    \ Urban For. Urban Green. 2021, 61, 127094. [CrossRef]\n67.\nBin Ismail, M.I.H.;\
    \ Thamrin, N.M. IoT implementation for indoor vertical farming watering system.\
    \ In Proceedings of the 2017\nInternational Conference on Electrical, Electronics\
    \ and System Engineering (ICEESE), Kanazawa, Japan, 9–10 November 2017; pp.\n\
    89–94. [CrossRef]\n68.\nAraújo, S.O.; Peres, R.S.; Barata, J.; Lidon, F.; Ramalho,\
    \ J.C. Characterising the agriculture 4.0 landscape—emerging trends,\nchallenges\
    \ and opportunities. Agronomy 2021, 11, 667. [CrossRef]\n69.\nAbbasi, R.; Martinez,\
    \ P.; Ahmad, R. An ontology model to represent aquaponics 4.0 system’s knowledge.\
    \ Inf. Process. Agric. 2022;\nin press. [CrossRef]\n70.\nSinha, B.B.; Dhanalakshmi,\
    \ R. Recent advancements and challenges of Internet of Things in smart agriculture:\
    \ A survey. Future\nGener. Comput. Syst. 2022, 126, 169–184. [CrossRef]\n71.\n\
    Kour, V.P.; Arora, S. Recent Developments of the Internet of Things in Agriculture:\
    \ A Survey. IEEE Access 2020, 8, 129924–129957.\n[CrossRef]\n"
  inline_citation: '>'
  journal: Computers
  limitations: '>'
  pdf_link: https://www.mdpi.com/2073-431X/11/9/135/pdf?version=1662648368
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Vertical Farming Perspectives in Support of Precision Agriculture Using
    Artificial Intelligence: A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.12731/2658-6649-2022-14-6-423-454
  analysis: '>'
  authors:
  - Gurjeet Singh
  - Naresh Kalra
  - Neetu Yadav
  - Ashwani Sharma
  - Manoj Saini
  citation_count: 16
  full_citation: '>'
  full_text: ">\n423\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6,\
    \ 2022\nНАУЧНЫЕ ОБЗОРЫ И СООБЩЕНИЯ\n  \nSCIENTIFIC REVIEWS AND REPORTS\nDOI: 10.12731/2658-6649-2022-14-6-423-454\
    \ \nUDC 004:63\nSMART AGRICULTURE: A REVIEW\nGurjeet Singh, Naresh Kalra, Neetu\
    \ Yadav,                                                    \nAshwani Sharma,\
    \ Manoj Saini\nAgriculture is regarded as one of the most crucial sectors in guaranteeing\
    \ food \nsecurity. However, as the world’s population grows, so do agri-food demands,\
    \ \nnecessitating a shift from traditional agricultural practices to smart agriculture\
    \ \npractices, often known as agriculture 4.0. It is critical to recognize and\
    \ handle the \nproblems and challenges related with agriculture 4.0 in order to\
    \ fully profit from \nits promise. As a result, the goal of this research is to\
    \ contribute to the development \nof agriculture 4.0 by looking into the growing\
    \ trends of digital technologies in the \nfield of agriculture. A literature review\
    \ is done to examine the scientific literature \npertaining to crop farming published\
    \ in the previous decade for this goal. This \nthorough examination yielded significant\
    \ information on the existing state of digital \ntechnology in agriculture, as\
    \ well as potential future opportunities.\nKeywords: Smart Agriculture; Artificial\
    \ Intelligence; Machine Learning; IOT; \nEdge Computing; Fog Computing\nFor citation.\
    \ Gurjeet Singh, Naresh Kalra, Neetu Yadav, Ashwani Sharma, Manoj. \nSmart Agriculture:\
    \ A Review. Siberian Journal of Life Sciences and Agriculture, 2022, \nvol. 14,\
    \ no. 6, pp. 423-454. DOI: 10.12731/2658-6649-2022-14-6-423-454 \n1. Introduction\
    \ \n1.1. A worldwide dilemma of food security\nFood security is a multifaceted\
    \ notion that aims to eliminate hunger by \nassuring a steady supply of nutritious\
    \ food. It is defined by a four-pillar para-\ndigm, each of which is necessary\
    \ to provide food security [1]. Food security \nis becoming a severe global concern\
    \ as a result of anthropogenic factors such \nas rapid population expansion, urbanization,\
    \ industrialization, farmland loss, \nfreshwater scarcity, and environmental degradation.\
    \ This is due to the fact that \n424\nSiberian Journal of Life Sciences and Agriculture,\
    \ Vol. 14, №6, 2022\nthese factors have a direct impact on the agricultural industry,\
    \ which is the \nworld’s principal source of agri-food production. By 2050, it\
    \ is expected that \nthe global population will rise from 7.7 billion to 9.2 billion,\
    \ urban population \nwill rise by 66 percent, arable land will decline by approximately\
    \ 50 million \nhectares, global GHG emissions (source of CO 2 – promote crop disease\
    \ and \npest growth) will rise by 50 percent, agri-food production will decline\
    \ by 20%, \nand food demand will rise by 59 to 98 percent, posing an imminent\
    \ threat. To \nmeet rising food demands, agricultural practitioners around the\
    \ world will need \nto increase crop and livestock production to maximize agricultural\
    \ output. The \nemphasis of this review paper is crop farming, which includes\
    \ the production \nof both food and cash crops. \nA typical agri-food value chain\
    \ displaying three key stages in the production \nof agricultural products: pre-field\
    \ (pre-plantation stage), in-field (plantation and \nharvesting stage), and post-field\
    \ (post-harvesting stage). All of the stages are \nimportant in the value chain,\
    \ but in this examination, we will focus on the sec-\nond stage, in-field, which\
    \ includes numerous crop-growing operations such as \nploughing, sowing, spraying,\
    \ and harvesting, among others. Traditional agricul-\ntural approaches are now\
    \ used in these procedures, which are labor-intensive, \nrequire arable land,\
    \ time, and a significant quantity of water (for irrigation), and \nmake it difficult\
    \ to produce enough food [5]. A part of the problem is also due \nto the improper\
    \ application of pesticides and herbicides, as well as the misuse \nof available\
    \ technologies, both of which hurt crops and ultimately result in \nagricultural\
    \ waste [6]. These problems can be solved by combining advanced \ntechnologies\
    \ and computer-based applications that ensure higher crop yields, \nless water\
    \ use, better pesticide/herbicide use, and improved crop quality. This \nis where\
    \ the concept of smart agriculture comes into play.\n1.2. Smart Agriculture\n\
    Every industry is being revolutionized and reshaped by Industry 4.0. It’s a \n\
    strategic initiative that combines emerging disruptive digital technologies like\
    \ \nthe Internet of Things (IoT), big data and analytics (BDA), system integration\
    \ \n(SI), cloud computing (CC), simulation, autonomous robotic systems (ARS),\
    \ \naugmented reality (AR), artificial intelligence (AI), wireless sensor networks\
    \ \n(WSN), cyber-physical systems (CPS), digital twin (DT), and additive manu-\n\
    facturing (AM) to enable the digitization of the industry [7]. \nAgriculture 4.0,\
    \ also known as smart agriculture, smart farming or digital \nfarming [7], is\
    \ the next phase of industrial agriculture, fueled by the integra-\ntion of these\
    \ technologies in agriculture. Farmers can use smart agriculture to \naddress\
    \ a variety of agricultural food production concerns such as farm pro-\n425\n\
    Siberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\nductivity,\
    \ environmental impact, food security, crop losses, and sustainability. \nFarmers,\
    \ for example, can connect to farms remotely, regardless of location \nor time,\
    \ using IoT-enabled equipment based on WSNs to monitor and control \nfarm operations.\
    \ Drones outfitted with hyper spectral cameras can collect data \nfrom a variety\
    \ of sources on farmlands, while autonomous robots can assist \nor complete repetitive\
    \ chores on farms. Data analytics techniques can be used \nto examine the obtained\
    \ data, and computer programs can be utilized to help \nfarmers make decisions.\n\
    Similarly, smart agriculture can monitor and analyze a wide range of pa-\nrameters\
    \ related to environmental factors, weed control, crop production status, \nwater\
    \ management, soil conditions, irrigation scheduling, herbicides and pes-\nticides,\
    \ and controlled environment agriculture to increase crop yields, reduce \ncosts,\
    \ improve product quality, and maintain process inputs through the use of \nmodern\
    \ systems [8].\n1.3. Research Motivation and Contribution \nThe reason for writing\
    \ this assessment is that digital technologies in agri-\ncultural systems provide\
    \ new strategic solutions for increasing farm output ef-\nficiency and effectiveness.\
    \ Furthermore, digital transformation paves the door \nfor modern farming technologies\
    \ like vertical farming (hydroponics, aquapon-\nics, and aeroponics) to be used,\
    \ which has the potential to solve food security \nissues. However, there are\
    \ a number of issues and restrictions connected with \nthis change from a technological,\
    \ socioeconomic, and management perspective \nthat must be overcome in order to\
    \ fully realise the potential of agricultural 4.0 \n[9].A number of publications\
    \ [9–18] have examined developing trends in the \ndevelopment of agriculture 4.0\
    \ by offering concise information on essential \nuses, benefits, and research\
    \ problems of smart farming. These studies’ research \nfocuses on either explaining\
    \ more general technical aspects while focusing on \nonly one or a few digital\
    \ technologies, or improving agricultural supply chain \nperformance, or developing\
    \ an agriculture 4.0 definition, or achieving sustain-\nable agronomy through\
    \ precision agriculture, or proposing a smart farming \nframework. Nonetheless,\
    \ these studies do not include an explicit discussion of \nthe tools and techniques\
    \ utilized to construct various systems, as well as their \nmaturity level. There\
    \ are also few studies that look at the consequences of dig-\nital technology\
    \ in modern soilless farms including hydroponics, aquaponics, \nand aeroponics\
    \ (indoor/outdoor). As a result, in order to promote conversation \nin this field,\
    \ it is necessary to examine the emergence of agriculture 4.0 from \nmany angles.\
    \ This research seeks to provide a comprehensive overview of dig-\nital technologies\
    \ used in the second stage of the agricultural production value \n426\nSiberian\
    \ Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\nchain (in-field)\
    \ for various farm types as described in section 1.1. The study’s \nkey theoretical\
    \ contribution is the analysis and dissemination of the tools and \ntechniques\
    \ used, as well as the farm type, maturity level of produced systems, \nand potential\
    \ obstacles or inhibiting factors in agriculture 4.0 development. Re-\nsearchers\
    \ and agricultural practitioners will benefit from the review’s insights \nin\
    \ future study on agriculture 4.0. \n1.4. Paper organization \nThe following is\
    \ the structure of the paper after the introduction: \nSection 2 discusses the\
    \ methodology used to collect relevant literature; Sec-\ntion 3 then presents\
    \ the statistical results obtained after a general analysis of the \nselected\
    \ research studies; Section 4 then provides a detailed overview of the \ncore\
    \ technologies used in agricultural digitization; Section 5 then highlights the\
    \ \ntechnical and socio-economic roadblocks to digital integration in agriculture;\
    \ \nand finally, Section 6 outlines a discussion of the research questions.\n\
    2. Research Methodology \nA systematic literature review (SLR) is a technique\
    \ for organizing and iden-\ntifying research related to a specific topic [19].\
    \ SLR is used in this study to look \ninto the state of Industry 4.0 technologies\
    \ in the agricultural industry. Cases \nwhere the phrase ‘agricultural’ occurred\
    \ in the title, abstract, or keywords of \nan article with any of the ‘Industry\
    \ 4.0 technologies’ described in section 1.2 \nare specifically sought. A review\
    \ procedure is established prior to conducting \nthe SLR to ensure a transparent\
    \ and high-quality research process, which are \nthe features that distinguish\
    \ a systematic literature review [20]. By conducting \nthorough literature searches,\
    \ the review methodology also helps to reduce bias. \nThe creation of the research\
    \ questions, the defining of the search method, and \nthe specification of inclusion\
    \ and exclusion criteria are all part of this process. \nTo conduct SLR, this\
    \ paper uses a recommended reporting item for system-\natic reviews and meta-analysis\
    \ (PRISMA) approach. PRISMA is a minimum \ncollection of items based on evidence\
    \ that is used to guide the construction of \nsystematic literature reviews and\
    \ other meta-analyses [19].\n2.1. Review Protocol \nBefore doing the bibliographic\
    \ analysis, a review methodology is estab-\nlished to identify, analyze, and interpret\
    \ data that are relevant to the research \nfocus. To begin, research questions\
    \ are developed in order to provide insight \ninto the study of published studies\
    \ in the research area of interest from many \nperspectives. These are the questions\
    \ that must be addressed in the research. The \nsearch strategy is then created,\
    \ which aids in the identification of appropriate \n427\nSiberian Journal of Life\
    \ Sciences and Agriculture, Том 14, №6, 2022\nkeywords later in the search equation,\
    \ as well as the identification of relevant \ninformation sources, such as academic\
    \ databases and search engines that allow \naccess to vast amounts of digital\
    \ documentation. Science Direct, Scopus, and \nIEEE Xplore are three online research\
    \ archives that are utilized to find relevant \nstudies. Finally, boundaries are\
    \ created by predefining inclusion and exclusion \ncriteria for further inquiry\
    \ and content assessments of selected articles in order \nto narrow the search\
    \ results of each database.\n2.2. Evaluation Process \nIdentification, screening,\
    \ eligibility, and inclusion are the four stages of the \nliterature search process\
    \ that are evaluated. Consolidation is done for the re-\nmoval of duplicate items\
    \ in the identification step after initial metadata filtering \nby the use of\
    \ search expressions. After this phase, the number of publications is \nreduced.\
    \ The titles and abstracts of the papers are reviewed during the screening \n\
    stage, and the most relevant publications are chosen for integral reading. In\
    \ the \nthird stage, full-text screening of these papers is done to ensure that\
    \ they are \neligible for this paper’s goal.\n2.3. Threats to Validity \n(i) SLR\
    \ replication: Because the current search is confined to only three on-\nline\
    \ repositories, the provided SLR is vulnerable to risks to validity. \nAdditional\
    \ sources could potentially lead to the discovery of more pub-\nlications. Validity\
    \ can be regarded satisfactorily addressed because the SLR \nprocess is clearly\
    \ defined in sub-sections 2.1 and 2.2. However, it is possible \nthat slightly\
    \ different publications will be found if this SLR is replicated. This \nvariation\
    \ could be due to various personal choices made throughout the PRIS-\nMA screening\
    \ and eligibility phases, but it’s highly improbable that the overall \nresults\
    \ would alter.\n(ii)The search string used to discover the relevant papers covers\
    \ the entire \nspectrum of SLR; however it’s possible that some important studies\
    \ were over-\nlooked. More research may be found if more keywords and synonyms\
    \ in the \nsearch are included.\n3. Digitization Trends in Agriculture \nAlthough\
    \ the agriculture business is making significant progress in terms \nof digital\
    \ technology adoption, it is still lagging behind other industries such \nas healthcare,\
    \ manufacturing, mining, automotive, energy, and others [15]. The \ncrop farming\
    \ method considered while designing an application or framework \nis referred\
    \ to as the farm type. The farming method, for example, can be soil-\nbased or\
    \ soilless. Open-air fields (conventional outdoor agricultural farms) and \n428\n\
    Siberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\ngreenhouse\
    \ farms are included in the soil-based farming category (indoor). The \nsoilless\
    \ farming category, on the other hand, includes modern farming tech-\nniques such\
    \ as aquaponics, aeroponics, and hydroponics (mostly indoor). In \nthe recent\
    \ decade, autonomous robotics systems (including unmanned guided \nvehicles and\
    \ unmanned aerial vehicles (drones)), the internet of things, and \nmachine learning\
    \ appear to be the most commonly used technology in agricul-\nture. Agriculture’s\
    \ growing sectors include big data, wireless sensor networks, \ncyber-physical\
    \ systems, and digital twins. Furthermore, in contrast to indoor \nfarms, open\
    \ air farms are the most usually examined in research investigations. \nFew publications\
    \ exist for soilless farming systems (aquaponics, aeroponics, \nand hydroponics),\
    \ implying that these modern farming practices are still in \ntheir infancy. Similarly,\
    \ each use case’s services are identified and classified \ninto nine service categories:\
    \ I crop management, CM (estimation/harvesting \nperiod and seed plantation/prediction\
    \ of crop yield/ growth rate/harvesting/ \npollination/ spraying (fertilizer/\
    \ pesticide)); ii) crop quality management, CQM \n(fresh weight, green biomass,\
    \ height, length, width, leaf density, piment content \n(chlorophyll), and phytochemical\
    \ composition); iii) water and environmental \nmanagement, WEM (monitoring and\
    \ control of flow rate, water level, water \nquality (nutrients), temperature,\
    \ humidity, CO2, and weather forecasts, among \nother things); iv) irrigation\
    \ management, IM (water stress detection and sched-\nuling); v) farm management,\
    \ FM (monitoring of farm operations, tracking and \ncounting products, determining\
    \ production efficiency, financial analysis, energy \nconsumption analysis, technology\
    \ integration, and decision-making);\nPDM (pest and disease management) is a term\
    \ used to describe the man-\nagement of pests and diseases (pest identification\
    \ and disease detection) SM \n(Soil Management) vii) (moisture content, soil nutrients,\
    \ fertilizer needs and \napplication) WUVM (weed/unknown vegetation mapping, classification,\
    \ and \npesticide application) viii) weed and unwanted vegetation management FDC\
    \ \n(fruit detection and counting), and ix) \nThe role of various digital technologies\
    \ in smart farming is depicted in \nthese categories. Crop management characteristics\
    \ such as crop yield prediction, \ngrowth rate estimation, and harvesting period\
    \ evaluation are the most 4.0 in the \nprevious decade, whereas soil management,\
    \ fruit identification and counting, \nand crop quality management receive very\
    \ less attention. The European Union’s \nTRL scale, which divides system maturity\
    \ into three generic categories [21], is \nused to assess the technology readiness\
    \ level (TRL) of all use cases. The first \nlevel is conceptual, which corresponds\
    \ to European TRL 1–2 (use case is in \nconcept phase), the second level is prototype,\
    \ which corresponds to Europe-\n429\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nan TRL 3–6 (use case is functional even without all planned\
    \ features), and the \nthird level is deployed, which corresponds to European\
    \ TRL 7–9. (Use case \nis mature with all the possible functions). Each use case’s\
    \ TRL was produced \nin a few experiments. It has been noticed that smart agricultural\
    \ systems have \nmade little progress from the concept and prototype stages to\
    \ the commercial \nstage. The majority of use cases, for example, are still in\
    \ the prototype stage.\n4. Agriculture 4.0 enabling technologies \n4.1. Internet\
    \ of Things driven agricultural systems \nThe Internet of Things (IoT) is a network\
    \ of interconnected computing de-\nvices, sensors, appliances, and machines that\
    \ are all connected to the internet \nand have their own unique identities and\
    \ capacities for remote sensing and \nmonitoring [21]. Network layer (communication),\
    \ perception layer (hardware \ndevices), , middleware layer (device management\
    \ and interoperability), service \nlayer (cloud computing), application layer\
    \ (data integration and analytics), and \nend-user layer are the six layers of\
    \ the IoT reference architecture (user-inter-\nface). IoT devices on the physical\
    \ layer in the agricultural domain collect data \non environmental and crop characteristics\
    \ such as temperature, humidity, pH \nvalue, water level, leaf colour, fresh leaf\
    \ weight, and so on. The network layer is \nresponsible for transmitting this\
    \ information, and its architecture is determined \nby the field size, farm location,\
    \ and type of farming method. ZigBee, LoRa, and \nSigfox, for example, are widely\
    \ utilized and employed in outdoor fields because \nthey are less expensive, have\
    \ low energy consumption, and have a long trans-\nmission range [22, 23]. Bluetooth,\
    \ despite being a secure technology, is only \nemployed in indoor farms due to\
    \ its limited transmission range [22]. Due to its \nhigh costs and high energy\
    \ consumption, Wi-Fi is not a promising technology \nfor agricultural applications\
    \ [22]. On the other hand, RFID (radio frequency \nidentification) and NFC (near\
    \ field communication) technologies are increas-\ningly being used in agricultural\
    \ systems for product tracking [24]. For periodic \nmonitoring of environmental\
    \ and soil characteristics, GPRS or mobile commu-\nnication technology (2G, 3G,\
    \ and 4G) is utilized. Furthermore, HTTP, WWW, \nand SMTP are the most commonly\
    \ utilized communication protocols in agri-\ncultural contexts. Similarly, middleware\
    \ HYDRA and SMEPP are commonly \nused in agricultural systems to enable interoperability\
    \ and system security for \ntheir context-aware functionalities [25]. \nCloud\
    \ computing approaches are used in the service layer to store data. \nThis information\
    \ is then used on the application layer to create smart apps that \nfarmers, agriculture\
    \ experts, and supply chain professionals can use to improve \n430\nSiberian Journal\
    \ of Life Sciences and Agriculture, Vol. 14, №6, 2022\nfarm monitoring and productivity.\
    \ The use of IoT in agriculture is intended to \nprovide farmers with decision-making\
    \ tools and automation technologies that \nallow them to seamlessly integrate\
    \ knowledge, products, and services in order to \nincrease production, quality,\
    \ and profit. A slew of research have been conduct-\ned and presented on the incubation\
    \ of IoT concepts in the agricultural industry. \nThe development of IoT-based\
    \ agricultural systems has addressed a variety of \ntechnological and architectural\
    \ concerns. However, most of these technologies \nare now in the conceptual stage\
    \ or in prototype form (not commercial). Farm \nmanagement, irrigation control,\
    \ crop development, health monitoring, and dis-\nease detection are all priorities.\
    \ \nSome of these studies also explained how IoT is being used in current ag-\n\
    ricultural systems like vertical farming (soilless farming - aquaponics, hydro-\n\
    ponics, and aeroponics) and greenhouse farming (soil-based). Furthermore, the\
    \ \nmajority of studies have been focused on a single issue.\n4.2. Wireless sensor\
    \ networks in agriculture \nA wireless sensor network (WSN) is a technology that\
    \ is utilized in an Inter-\nnet of Things (IoT) system. It is defined as a collection\
    \ of spatially distributed \nsensors for monitoring environmental physical conditions,\
    \ temporarily storing \nobtained data, and transferring the information to a central\
    \ point [22]. A wire-\nless sensor network (WSN) for smart farming is made up\
    \ of multiple sensor \nnodes connected by a wireless connection module. These\
    \ nodes have a variety \nof skills that allow them to self-organize, self-configure,\
    \ and self-diagnose (for \nexample, processing, trans- mission, and feeling).\
    \ There are various varieties of \nWSNs, which are classified based on the environment\
    \ in which they are used. \nTWSNs (terrestrial wireless sensor networks), WUSNs\
    \ (wireless underground \nsensor networks), UWSNs (underwater wireless sensor\
    \ networks), WMSNs \n(wireless multimedia sensor networks), and MWSNs (mobile\
    \ wireless sensor \nnetworks) are a few examples [26]. TWSN and UWSN are commonly\
    \ utilized \nin agricultural applications. TWSN nodes are sensors that collect\
    \ data from \nthe environment and are located above ground. The second type of\
    \ WSN is \nWUSNs, which are WSNs with sensor nodes embedded in the soil. Lower\
    \ fre-\nquencies easily enter the soil in this environment, whereas higher frequencies\
    \ \nare severely attenuated [27]. Because of the limited communication radius,\
    \ the \nnetwork requires a larger number of nodes to cover a big area. Many research\
    \ \npublications on the use of WSN for various outdoor and indoor farm applica-\n\
    tions, such as irrigation management, water quality testing, and environmental\
    \ \nmonitoring, are accessible in the literature. The goal of these experiments\
    \ was \nto create WSN architectures that were simple, low-cost, energy-efficient,\
    \ and \n431\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\n\
    scalable. However, several aspects of WSNs, such as minimum maintenance, \nrobust\
    \ and fault-tolerant architecture, and interoperability, require more study. \n\
    4.3. Cloud computing in agriculture \nCloud computing (CC) is defined as a model\
    \ for enabling convenient, ubiq-\nuitous, on-demand network access to a shared\
    \ pool of configurable computing \nresources (e.g., networks, servers, storage,\
    \ applications, and services) that can \nbe rapidly provisioned and released with\
    \ minimal management effort or ser-\nvice provider interaction, according to the\
    \ National Institute of Standards and \nTechnologies (NIST) [28]. The datacenter\
    \ (hardware), infrastructure, platform, \nand application layers make up the primary\
    \ architecture of CC [29]. Each of \nthese layers corresponds to one of three\
    \ cloud service models: SaaS (software \nas a service), PaaS (platform as a service),\
    \ and IaaS (infrastructure as a service) \n(IaaS). In the agriculture sector,\
    \ cloud computing has gotten a lot of attention in \nthe last decade because it\
    \ provides: 1) low-cost storage for data collected from \nvarious domains via\
    \ WSNs and other preconfigured IoT devices, 2) large-scale \ncomputer systems\
    \ to make intelligent decisions by converting raw data into \nusable knowledge,\
    \ and 3) a secure platform for developing agricultural based \nIoT applications\
    \ [30]. \nCC is used to develop various agricultural applications in conjunction\
    \ with \nIoT and WSN. CC technology is also utilized to develop operational farm\
    \ man-\nagement systems (FMSs) that help farmers and farm managers monitor farm\
    \ \nactivities more efficiently. The traceability of agri-product quality is another\
    \ \narea of interest that is being investigated in global research [31]. However,\
    \ only \npreliminary research has been done to see if traceability complies with\
    \ food \nsafety and quality criteria. The usage of cloud-based agricultural systems\
    \ has \nthe potential to address issues such as rising food demand, pollution\
    \ from pes-\nticides and fertilizers, and the safety of agricultural products.\
    \ These FMSs, on \nthe other hand, lack the flexibility to offer run-time customization\
    \ in response \nto specific farmer needs. Furthermore, because most farm data\
    \ is fragmented \nand distributed, recording farm operations accurately in existing\
    \ FMSs systems \nis problematic [32].\n4.4. Edge/fog computing in agriculture\
    \ \nThe rapid expansion of IoT has resulted in an explosion of sensors and smart\
    \ \ndevices, creating massive amounts of data. The processing and analysis of\
    \ such a \nlarge volume of data in real time is difficult since it puts a strain\
    \ on the cloud serv-\ner and slows response times. When dealing with such a massive\
    \ data set, a cloud \nserver alone will not be able to offer real-time responses.\
    \ Furthermore, because \nIoT applications require a constant exchange of information\
    \ between devices and \n432\nSiberian Journal of Life Sciences and Agriculture,\
    \ Vol. 14, №6, 2022\nthe cloud, they are susceptible to network latency, making\
    \ CC unsuitable for these \napplications [23]. The introduction of the edge computing\
    \ idea has the potential \nto overcome the CC issues. This novel computing architecture\
    \ places computa-\ntional and storage resources (such as cloudlets or fog nodes)\
    \ closer to data sources \nlike mobile devices and sensors at the network’s edge.\
    \ This allows for real-time \nanalytics while maintaining data security on the\
    \ device [23]. Although edge com-\nputing has exciting potential for smart agriculture,\
    \ its applications in agricultural \nsystems are still in their infancy. As a\
    \ result, there are limited research studies in \nthis field. The majority of\
    \ the edge computing-based agricultural systems covered \nin these papers are\
    \ prototypes that solve a small number of challenges across a \nvariety of agricultural\
    \ disciplines. Interoperability and scalability issues haven’t \ngotten enough\
    \ attention so yet. Agricultural robots combine emerging technolo-\ngies such\
    \ as computer vision; wireless sensor networks (WSNs), satellite navi-\ngation\
    \ systems (GPS), artificial intelligence (AI), cloud computing (CC), and the \n\
    Internet of Things (IoT) to help farmers improve productivity and quality of ag-\n\
    ricultural products. AARS in smart farming can be mobile or fixed [33]. Mobile\
    \ \nAARS can move around the working field. Unmanned ground vehicles (UGVs) \n\
    and unidentified aerial vehicles (UAVs) are the two types of mobile AARSs, as\
    \ \ndiscussed in the following sections. \n4.5.1. Unmanned ground vehicles in\
    \ agriculture\nUnmanned ground vehicles (UGVs) are agricultural robots that work\
    \ with-\nout the use of a human operator on the ground. A platform for locomotive\
    \ ap-\nparatus and manipulator, navigation sensors, a supervisory control system,\
    \ an \ninterface for the control system, communication links for information exchange\
    \ \nbetween devices, and system architecture for integration between hardware\
    \ and \nsoftware agents are the main components of UGVs [34]. The control architec-\n\
    ture of a UGV can be remote-operated (controlled via an interface by a human \n\
    operator) or totally autonomous (operated without the use of a human control-\n\
    ler using artificial intelligence technology) [34]. Locomotive systems, likewise,\
    \ \ncan be based on wheels, tracks, or legs [34]. Legged robots are uncommon in\
    \ \nagriculture, despite their great terrain flexibility, inherent Omni directionality,\
    \ \nand soil protection. These robots, however, offer a disruptive locomotion\
    \ mech-\nanism for smart farms when paired with wheels (wheel-legged robots).\
    \ UGVs \nshould meet specific requirements, such as small size, maneuverability,\
    \ resil-\nience, efficiency, human-friendly interface, and safety, in addition\
    \ to the nec-\nessary features for infield operations, in order to improve crop\
    \ yields and farm \nproductivity. A 4WD locomotive system is used in the majority\
    \ of agricultural \nrobotic systems due to its ease of manufacture and control.\
    \ \n433\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6, 2022\n\
    The disadvantage of 4WD is that terrains with stone elements and/or voids \nhave\
    \ a significant impact on the wheels [34]. As a result, other mechanisms, \nsuch\
    \ as legged or wheel-legged locomotive systems, should be investigated. \nAlthough\
    \ some robots include computer vision systems, most of these robots \nare designed\
    \ with a low-cost computer vision system, such as traditional RGB \ncameras, due\
    \ to the difficulties of establishing an accurate and dependable sys-\ntem that\
    \ can replace manual labour. Furthermore, the majority of the systems \nmentioned\
    \ above are still in the research phase, with no large-scale commer-\ncial application.\n\
    4.5.2. Unmanned aerial vehicles in agriculture \nUnmanned aerial vehicles (UAVs),\
    \ sometimes known as aerial robots, are \nplanes that do not have a human pilot\
    \ on board. There are many different types \nof UAVs [35] depending on the technology\
    \ used to fly (wing structure) and the \nlevel of autonomy. Fixed-wing (planes),\
    \ single-rotor (helicopter), hybrid system \n(vertical takeoff and landing), and\
    \ multi-rotor UAVs are examples of wing types \n(drone). Drones (multi-rotor technology),\
    \ which are raised and driven by four \n(quad-rotor) or six (hex-rotor) rotors,\
    \ have grown in popularity in the agricul-\nture sector because to their mechanical\
    \ simplicity in comparison to helicopters, \nwhich rely on a much more complex\
    \ plate control mechanism [36]. Similarly, \nUAVs can be tele-operated or tele-commanded,\
    \ depending on their autonomy \nlevel, with the pilot providing references to\
    \ each actuator of the aircraft to con-\ntrol it in the same way that an onboard\
    \ pilot would, or tele-commanded with the \naircraft relying on an automatic controller\
    \ on board to maintain a stable flight \n[35]. Agricultural UAVs with the right\
    \ sensors (vision, infrared, multispectral, \nand hyper spectral cameras, for\
    \ example) can collect data (vegetation, leaf area, \nand reflectance indexes)\
    \ from their fields to monitor dynamic changes in crops \nthat aren’t visible\
    \ from the ground [37]. Farmers can deduce information about \ncrop illnesses,\
    \ nutrient deficits, water level, and other agricultural growth char-\nacteristics\
    \ using this data. Farmers might plan possible cures using this knowl-\nedge (irrigation,\
    \ fertilization, weed control, etc.). \nThe majority of the systems mentioned\
    \ above are still in the research stage, \nwith no large-scale commercial use.\
    \ Other issues with these UAVs include bat-\ntery life and flight time [35]. Lithium-ion\
    \ batteries are currently in use because \ntheir capacity exceeds that of conventional\
    \ batteries. \nHowever, increasing the battery capacity increases the weight of\
    \ the drone, \nand research is currently underway to overcome this issue. \nFurthermore,\
    \ existing UAVs have complicated user interfaces that can only \nbe used by experts\
    \ to accomplish agricultural chores. People who are elderly \n434\nSiberian Journal\
    \ of Life Sciences and Agriculture, Vol. 14, №6, 2022\nor unfamiliar with UAV\
    \ technology will be able to control it more readily if \nthe user interface is\
    \ improved and made more human-centered with multimod-\nal feedback. \n4.6. Big\
    \ data and analytics in agriculture \nRapid advancements in IoT and CC technologies\
    \ have massively expanded \nthe amount of data available. Textual content (structured,\
    \ semi-structured, and un-\nstructured) and multimedia content (e.g., videos,\
    \ photos, and audio) are included \nin this data, also known as Big Data (BD)\
    \ [38]. Big data analytics is the practice \nof analyzing large amounts of data\
    \ to find hidden patterns, unknown relationships, \nmarket trends, client preferences,\
    \ and other important information (BDA). Big \ndata is usually classified into\
    \ five dimensions, each of which is represented by a V. \nThe concept of BD-driven\
    \ smart agriculture is very new, but its trend is \ngood because it has the potential\
    \ to make a dramatic change in the food supply \nchain and boost food security\
    \ through higher productivity. Agricultural big data \nis typically generated\
    \ from a variety of sources in agriculture, including ground \nsensors, aerial\
    \ vehicles, and ground vehicles equipped with special cameras and \nsensors; governmental\
    \ bodies in the form of reports and regulations; private \norganizations through\
    \ online web services; farmers in the form of knowledge \ngained through surveys;\
    \ and social media [39]. Depending on the agricultural \ndomain, the data can\
    \ be environmental (weather, climate, moisture level, etc.), \nbiological (plant\
    \ disease), or geospatial, and it comes in a variety of volumes, \nspeeds, and\
    \ formats [40]. The information is acquired and stored in a computer \ndatabase,\
    \ where it is analyzed using computer algorithms for seed characteris-\ntics,\
    \ weather patterns, soil attributes (such as pH or nutrient content), marketing\
    \ \nand trade management, consumer behaviour, and inventory management. In \n\
    agriculture, a range of strategies and tools are used to examine large data. The\
    \ \nmost often employed techniques include machine learning, cloud-based plat-\n\
    forms, and modelling and simulation. Machine learning technologies are used \n\
    to solve problems like prediction, clustering, and classification, while cloud\
    \ \nplatforms are utilized for large-scale data storage, preprocessing, and visual-\n\
    ization. There are still numerous potential areas where BDA can be used to \n\
    address various agricultural concerns that are not well covered in existing lit-\n\
    erature. For example, data-intensive greenhouses and indoor vertical farming \n\
    systems, quality control and health monitoring of crops in outdoor and indoor\
    \ \nfarms, genetic engineering, decision support platforms to help farmers design\
    \ \nindoor vertical farms, and scientific models for policymakers to help them\
    \ make \ndecisions about the physical ecosystem’s sustainability. Finally, the\
    \ majority of \nsystems are still in the prototype stage.\n435\nSiberian Journal\
    \ of Life Sciences and Agriculture, Том 14, №6, 2022\n4.7. Artificial intelligence\
    \ in agriculture \nArtificial intelligence (AI) is the study of theories and computer\
    \ systems that \ncan perform activities that need human intelligence, such as\
    \ sensory percep-\ntion and decision-making [41]. AI, particularly in the areas\
    \ of machine learning \n(ML) and deep learning (DL), is seen as one of the primary\
    \ forces driving the \ndigitization of agriculture when combined with CC, IoT,\
    \ and big data. These \ntechnologies have the potential to increase crop production,\
    \ harvesting, pro-\ncessing, and marketing in real time [42]. ML and DL algorithms\
    \ are being used \nto determine various parameters such as weed detection, yield\
    \ prediction, and \ndisease identification in a number of intelligent agricultural\
    \ systems. The fol-\nlowing two sub-sections go through these systems.\n4.7.1.\
    \ Machine learning in agriculture \nsupervised learning (linear regression, regression\
    \ trees, non-linear regres-\nsion, Bayesian linear regression, polynomial regression,\
    \ and support vector \nregression), and unsupervised learning (hierarchal clustering,\
    \ k-means cluster-\ning, neural networks (NN) anomaly detection, principal component\
    \ analysis, \nindependent component analysis, a-priori algorithm, and singular\
    \ value decom-\nposition (SVD)). Weed detection, Crop yield prediction, disease\
    \ and weather \nprediction (rainfall), soil properties estimation ( moisture content,\
    \ type, pH, \ntemperature, etc.), water management, fertilizer amount determination,\
    \ and \nlivestock production and management all use machine learning techniques\
    \ and \nalgorithms [2, 43]. According to the study of these publications, “crop\
    \ yield \nprediction” is an extensively researched area, with the most widely\
    \ utilized ML \napproaches to allow smart farming being linear regression [4],\
    \ neural network \n(NN), random forest (RF), and support vector machine (SVM)\
    \ [2]. \nThe presented use cases are still in the research phase, and no commercial\
    \ \nuse has been recorded as of yet. Furthermore, AI and machine learning ap-\n\
    proaches are found to be underutilized in greenhouse and indoor vertical farm-\n\
    ing systems, particularly hydroponics, aquaponics, and aeroponics. There are \n\
    only a handful publications that use machine learning techniques. To enable \n\
    digital farming, new methodologies such as federated learning and privacy \npreserving\
    \ methods are being developed in light of the digital transformation’s \ncyber-security\
    \ and data privacy problems [44]. These methods create machine \nlearning models\
    \ from local parameters rather than sharing private data samples, \nreducing security\
    \ concerns.\n4.7.2. Deep learning in agriculture \nDeep learning (DL) is an extension\
    \ of classical machine learning (ML) \nbecause extra “depth” (complexity) is added\
    \ to the model, it can accomplish \n436\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\ndifficult tasks (predictions and classification)\
    \ extraordinarily well and quick-\nly. DL’s main benefit is feature learning,\
    \ which includes extracting features \n(high-level information) from big datasets\
    \ automatically [45]. Long short term \nmemory (LSTM) networks, convolutional\
    \ neural networks (CNNs), recurrent \nneural (RNN) networks, generative adversarial\
    \ networks (GANs), radial basis \nfunction networks (RBFNs), multilayer perceptron\
    \ (MLPs), feed-forward ar-\ntificial neural network (ANN), self-organizing maps\
    \ (SOMs), deep belief net-\nworks (DBNs), restricted Boltzmann machines (RBMs),\
    \ and autoencoders are \nexamples of deep learning algorithms Various sites [46]\
    \ provide a full overview \nof these methods, popular architectures, and training\
    \ systems. DL algorithms \nare commonly used in agriculture to solve problems\
    \ related to computer vision \napplications that aim to predict key parameters\
    \ such as crop yields, soil mois-\nture content, weather conditions, and crop\
    \ growth conditions; detect diseases, \npests, and weeds; and identify leaf or\
    \ plant species [47]. Computer vision is an \ninterdisciplinary field that has\
    \ exploded in popularity in recent years thanks to \nthe rise of CNNs. It provides\
    \ methods and techniques for accurately process-\ning digital images and allowing\
    \ computers to analyze and comprehend the vi-\nsual world [48]. CNNs, generally\
    \ is known as Convet and its derivatives, are \nthe most widely used deep learning\
    \ algorithms in agricultural applications. \nRegion-based CNNs (RCNN), Fast-RCNN,\
    \ Faster-RCNN, YOLO, and Mask-\nRCNN are some of the CNN variants, with the first\
    \ four being the most typi-\ncally used to address object detection issues. On\
    \ the other side, Mask-RCNN \nis utilized to overcome instance segmentation issues.\
    \ The reader can find a \nthorough explanation of these algorithms and their applications\
    \ in the exist-\ning bibliography [47]. Other DL approaches have been employed\
    \ in a few re-\nsearch. When it comes to datasets, the majority of deep learning\
    \ models are \ntrained on photographs, with only a few trained on sensor data\
    \ collected in the \nfield. This demonstrates that DL can be used on a wide range\
    \ of datasets. It’s \nalso worth noting that the majority of the research is focused\
    \ on outdoor farms, \nwith next-generation farms (environment-controlled) receiving\
    \ less attention. \nThough digital farming has the potential to be enabled by\
    \ DL, most systems \nare still in the prototype stage. Furthermore, the additional\
    \ obstacles created \nby cyber-security and privacy concerns necessitate the improvement\
    \ of current \ndeep learning and computer vision technologies.\n4.8. Agricultural\
    \ decision support systems \nA decision support system (DSS) is a smart system\
    \ that assists stakehold-\ners and potential users in making decisions in response\
    \ to specific needs and \nchallenges by offering operational responses based on\
    \ meaningful informa-\n437\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\ntion retrieved from raw data, documents, personal knowledge,\
    \ and/or models \n[49]. Data-driven, model-driven, communication-driven, document-driven,\
    \ and \nknowledge-driven DSS are all possibilities. The following source [50]\
    \ lists the \nkey features of these DSSs. The volume of farming data has exploded\
    \ as a re-\nsult of the advent of agriculture 4.0. Platforms like agricultural\
    \ decision support \nsystems (ADSS) are necessary to convert this heterogeneous\
    \ data into practical \nknowledge in order to make evidence-based and precise\
    \ judgments about farm \nmanagement and facility layout [51]. ADSSs have gotten\
    \ a lot of interest in the \nagriculture industry over the last few years. A variety\
    \ of agricultural concerns, \nsuch as farm management, water management, and environmental\
    \ management, \nhave been addressed by a number of ADSSs. Most ADSSs have been\
    \ found \nto ignore expert knowledge, which is extremely useful since it enables\
    \ for the \nconstruction of systems that are tailored to the demands of the users.\
    \ Complex \nGUIs, insufficient re-planning components, a lack of prediction and\
    \ forecasting \nabilities, and a lack of ability to adjust to unpredictable and\
    \ dynamic elements \nare some of the other identified faults with some of these\
    \ ADDSs. It’s also worth \nnoting that all of the ADSSs are for outside agriculture\
    \ systems and are still in \ndevelopment. In comparison, the use of ADSS in indoor\
    \ soilless agriculture is \ncurrently underutilized.\n4.9. Agricultural cyber-physical\
    \ systems \nA cyber-physical system (CPS) is an automated distributed system that\
    \ inte-\ngrates physical processes with communication networks and computing infra-\n\
    structures [52], and it is one of the key technologies of Industry 4.0. There\
    \ are \nthree standard CPS reference architecture models: 5C, RAMI 4.0, and IIRA,\
    \ \nwhich may be found in full at the following source [53]. Among these, the\
    \ 5C \nis a well-known and widely used reference model. CPS takes advantage of\
    \ a \nnumber of existing technologies, including agent systems, IoT, CC, augmented\
    \ \nreality, big data, and machine learning (ML) [54]. Scalability, flexibility,\
    \ au-\ntonomy, reliability, resilience, safety, and security are all improved\
    \ as a result \nof its adoption.\nOne of the most difficult domains that can benefit\
    \ from CPS technology is \nagriculture. Agricultural cyber-physical systems (ACPSs)\
    \ combine advanced \nelectronic technology with agricultural infrastructure to\
    \ create integrated farm \nmanagement systems that interact with the physical\
    \ environment to keep crops \ngrowing at their best [55]. ACPSs collect high-accuracy\
    \ data regarding climate, \nsoil, and crops and utilize it to manage watering,\
    \ humidity, and plant health, \namong other things. For the management of various\
    \ services, a range of ACPSs \nhave been created; however, most of these systems\
    \ are still in the prototype and \n438\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\nconceptual stages. Furthermore, the majority\
    \ of studies are for outdoor farms, \nwith only a few publications published on\
    \ soil-based greenhouse systems. There \nhas been no research on indoor soilless\
    \ agricultural methods. Since of its pro-\nspective applications in a variety\
    \ of fields, ACPSs have sparked a lot of academ-\nic interest; nevertheless, deploying\
    \ CPS models in real-world applications is \nstill a difficulty because it requires\
    \ the right hardware and software [56]. When \ndesigning ACPSs, special emphasis\
    \ should be paid to autonomy, robustness, and \nresilience in order to deal with\
    \ the unpredictable nature of the environment and \nthe unknown characteristics\
    \ of agricultural facilities. ACPSs are influenced by \na variety of factors,\
    \ including humans, sensors, robots, crops, and data.. ACPSs \nmust be properly\
    \ and extensively developed to provide a seamless operation \nwhile avoiding conflicts,\
    \ errors, and disturbances.\n4.10. Digital twins in agriculture \nA digital twin\
    \ (DT) is a dynamic virtual replica of a real-life (physical) \nobject that mimics\
    \ its behaviours and states across multiple stages of the ob-\nject’s lifecycle\
    \ by combining real-world data, simulation, and machine learning \nmodels with\
    \ data analytics to enable understanding, learning, and reasoning \n[57]. The\
    \ physical and virtual entities, the physical and virtual environments, \nthe\
    \ metrology, and realization modules that perform the physical to virtual and\
    \ \nvirtual to physical connection or twinning, the twinning and twinning rate,\
    \ and \nthe physical and virtual processes are all required for a complete description\
    \ of \nthe DT concept for any physical system [58]. Because of advancements in\
    \ tech-\nnology such as the Internet of Things, big data, wireless sensor networks,\
    \ and \ncloud computing, the DT concept has gained traction. This is due to the\
    \ fact that \nthese technologies enable real-time monitoring of physical twins\
    \ at high spatial \nresolutions using both small devices and distant sensing,\
    \ which generate ev-\ner-increasing data streams [21]. In comparison to other\
    \ fields, the notion of DT \nin agricultural applications is relatively new, with\
    \ the first references appearing \nin 2017; as a result, its added value has not\
    \ yet been thoroughly studied [21]. \nBecause of its reliance on natural circumstances\
    \ (temperature, soil, humidity), \nas well as the presence of living and non-living\
    \ physical twins (plants and an-\nimals), framing is a very complex and dynamic\
    \ realm (indoor farm buildings, \ngrow beds, outdoor agricultural fields, agricultural\
    \ machinery). \nNon-living physical twins interact directly or indirectly with\
    \ plants and \nanimals (living physical twins), posing more obstacles for DT in\
    \ agriculture, \nwhereas non-living physical twins are the focus of DT in other\
    \ domains such \nas manufacturing. The majority of research has been on open-air\
    \ agricultur-\nal systems. There is just one study that proposes DT for a soil-based\
    \ vertical \n439\nSiberian Journal of Life Sciences and Agriculture, Том 14, №6,\
    \ 2022\nfarming system and one study that implements DT for a soilless vertical\
    \ farm-\ning system (aquaponics). This could be due to the difficulty of designing\
    \ and \nmanaging modern farming systems. Furthermore, the majority of DTs are\
    \ still \nin the research phase, with no commercial deployment planned. Cost savings,\
    \ \ndisaster prevention, clearer decision making, and efficient management oper-\n\
    ations are all reported benefits of DT applications in agriculture, which can\
    \ be \napplied to a variety of agricultural subfields such as plant and animal\
    \ breeding, \naquaponics, vertical farming, cropping systems, and livestock farming.\
    \ While \nDT technology offers a lot of promise, achieving synchronization between\
    \ the \nreal and digital worlds is difficult. Due to the quirks of living physical\
    \ twins, \nthe intricacy of this procedure is magnified in agricultural settings.\
    \ As a result, \nagricultural DT should begin with micro-farms, which can then\
    \ be gradually up-\ngraded to a more intelligent and autonomous form by adding\
    \ more components.\n4.11. Roadblocks in digitization of agriculture industry \n\
    This section outlines a series of interconnected hurdles to a wider adoption of\
    \ \ndigital technologies in agriculture. Following a review of the literature,\
    \ 21 barri-\ners were found, which were divided into technical and socioeconomic\
    \ categories.\n4.12. Technical roadblocks \n•Interoperability: Data is regarded\
    \ as a critical component in the success of \nsmart systems. Agricultural data\
    \ is typically gathered from a variety of sources, \nincluding thousands of individual\
    \ farmlands, animal industries, and business ap-\nplications. Data can be in a\
    \ variety of formats, making data integration difficult. \nAs a result, after\
    \ systematic data collection, storage, processing, and knowledge \nmining, data\
    \ interoperability is critical to increasing the value of this widely \ndistributed\
    \ data [59]. Interconnected and interoperable devices are also required \nfor\
    \ successful communication between heterogeneous devices. The system’s in-\nteroperability\
    \ can be improved through cross-technology communication [60].\n•Standardization:\
    \ Standardization of devices is required to fully use digital \ntechnologies for\
    \ smart farming applications. Differences in output can occur \nas a result of\
    \ misinterpretation and changes over time. Device, application, and \nsystem interoperability\
    \ concerns can also be overcome by standardization [25].\n•Data quality: Data\
    \ quality, as well as data security, storage, and openness, \nare essential for\
    \ producing meaningful outcomes. Another impediment to the \nadoption of smart\
    \ farming technologies is the lack of decentralized data man-\nagement systems\
    \ [9]. Multiple actors’ willingness to exchange farm data is be-\ning harmed as\
    \ a result of this problem.\n•Hardware implementation: It is incredibly difficult\
    \ to establish a smart agri-\ncultural setup in large-scale open areas. This is\
    \ due to the fact that all hardware, \n440\nSiberian Journal of Life Sciences\
    \ and Agriculture, Vol. 14, №6, 2022\nincluding IoT devices, wireless sensor networks,\
    \ sensor nodes, machinery, and \nequipment, is directly exposed to harsh environmental\
    \ conditions such as heavy \nrainfall, extreme temperatures, extreme humidity,\
    \ high wind speeds, and a vari-\nety of other dangers that can destroy electronic\
    \ circuits or disrupt their normal \nfunctionality [61]. A possible answer is\
    \ to construct a sturdy and lasting casing \nfor all of the expensive devices\
    \ that can withstand real-world conditions [62].\n•Adequate power sources: Typically,\
    \ wireless gadgets used on farms func-\ntion for an extended period of time and\
    \ have a limited battery life. \nBecause replacing a battery in the event of a\
    \ failure is difficult, especially in \nopen-air farms where devices are strategically\
    \ located with limited access [61], a \nproper energy-saving system is required.\
    \ Low-power sensors and proper commu-\nnication management are two viable strategies\
    \ for reducing energy consumption \n[24, 63]. Other intriguing technologies to\
    \ eliminate the need for battery renewal by \nrecharging batteries using electromagnetic\
    \ waves include wireless power transfer \nand self-supporting wireless systems.\
    \ In most agricultural applications, however, \nlong-distance wireless charging\
    \ is required [9]. Another potential alternative is to \ncapture ambient energy\
    \ from rivers, fluid flow, vehicle movement, and the ground \nsurface using sensor\
    \ nodes; however the converted electrical energy is current-\nly restricted, necessitating\
    \ the need to enhance power conversion efficiency [64].\n•Reliability: The dependability\
    \ of devices, as well as the software applica-\ntions that run on them, is critical.\
    \ This is due to the fact that IoT devices must \ncollect and transmit data from\
    \ which judgments are made utilizing a variety of \nsoftware packages. Unreliable\
    \ sensing, processing, and transmission can result \nin erroneous monitoring data\
    \ reports, significant delays, and even data loss, all \nof which can have a negative\
    \ impact on agricultural system performance [25].\n •Adaptability: Agriculture\
    \ is a complicated, dynamic, and continuously \nchanging environment. As a result,\
    \ when building a system, it is critical for de-\nvices and applications to react\
    \ proactively with other entities in the face of un-\nknown and dynamic elements\
    \ in order to provide the required performance [65].\n•Robust wireless architectures:\
    \ Low-cost, wide-area coverage, enough net-\nworking flexibility, and high scalability\
    \ are all advantages of wireless networks \nand communication technologies. However,\
    \ in a dynamic agriculture environ-\nment, such as temperature swings, the movement\
    \ of live objects, and the ex-\nistence of impediments, dependable wireless connection\
    \ is a major difficulty. \nFor example, multipath propagation effects cause signal\
    \ strength oscillations, \nresulting in unstable connectivity and insufficient\
    \ data transmission [66]. These \nelements have an impact on the agricultural\
    \ system’s performance. As a result, \nrobust and fault-tolerant wireless architectures\
    \ with proper sensor node place-\n441\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nment, antenna height, network topology, and communication\
    \ protocols are re-\nquired, as well as low-maintenance wireless systems [11].\n\
    •Interference: Because of the extensive deployment of IoT devices and wire-\n\
    less sensor networks, another difficulty is wireless interference and quality\
    \ of \nservice degradation. Effective channel scheduling between heterogeneous\
    \ sens-\ning devices, cognitive radio-assisted WSNs, and upcoming networking prim-\n\
    itives like concurrent transmission [67] can all help to solve these problems.\
    \ \nBecause agriculture equipment are dispersed in indoor greenhouses, outdoor\
    \ \nfarmlands, underground locations, and even aquatic areas, cross-media com-\n\
    munication between underground, underwater, and air is also necessary for full\
    \ \nintegration of smart technologies [68].\n•Security and privacy: Because smart\
    \ agricultural systems are dispersed, \nthey are vulnerable to cyber-attacks such\
    \ as eavesdropping, data integrity, de-\nnial-of-service assaults, and other sorts\
    \ of disruptions that could jeopardize the \nsystem’s privacy, integrity, and\
    \ availability [69]. With various privacy-preserv-\ning techniques and federated\
    \ learning approaches, cyber-security is a funda-\nmental concern that needs to\
    \ be addressed in the context of smart farming [44].\n•Compatibility: in order\
    \ to meet the fragmentation and scalability standards, \nthe models or software\
    \ applications developed must be adaptable and able to \nrun on any equipment\
    \ in the agricultural system [13]. \n•Resource optimization: To boost farm profitability,\
    \ farmers need a resource op-\ntimization procedure to determine the ideal number\
    \ of IoT devices and gateways, \ncloud storage size, and volume of transmitted\
    \ data. Resource optimization is diffi-\ncult since farms vary in size and require\
    \ different types of sensors to assess different \nvariables [70]. Second, most\
    \ farm management systems do not support run-time \nchanges to match the demands\
    \ of individual farmers. To estimate adequate resource \nallocation, complicated\
    \ mathematical models and algorithms are necessary [32].\n•Scalability: Due to\
    \ technological improvements, the number of gadgets, \ngear, and sensors put on\
    \ farms is continually expanding. \nGateways, network applications, and back-end\
    \ databases should all be de-\npendable and scalable in order to serve these entities\
    \ [71].\n•Human-centered user interfaces: Existing agricultural software and gadgets\
    \ \nhave complicated user interfaces, which are limiting smart farming methods.\
    \ \nThe majority of graphical user interfaces are constructed in such a way that\
    \ \nonly specialists can use them to accomplish agricultural activities. By making\
    \ \nthe user interface more human-centered and providing multimodal feedback,\
    \ a \nbigger group of individuals will be able to use it to complete various agricul-\n\
    tural tasks [35].\n442\nSiberian Journal of Life Sciences and Agriculture, Vol.\
    \ 14, №6, 2022\n4.13. Socio-economic roadblocks \n•Gap between farmers and researchers:\
    \ Farmers’ engagement is critical to \nthe success of the agriculture industry’s\
    \ digitization. Agricultural specialists are \nfrequently unaware of the concerns\
    \ that farmers encounter during the agri-food \nproduction process, which smart\
    \ technologies could solve [16]. Furthermore, it \nis critical to completely comprehend\
    \ the nature of problems in order to create \nan appropriate smart solution. \n\
    As a result, bridging the gap between farmers, agricultural professionals, \n\
    and AI researchers is critical.\n•Expenses connected with smart systems: the costs\
    \ associated with adopt-\ning smart technology and systems are a major impediment\
    \ to the agriculture \nsector’s digitization. These expenses typically include\
    \ deployment, operation, \nand maintenance. Smart system deployment costs are\
    \ typically significant since \nthey include: I hardware installation, such as\
    \ autonomous robots and drones, \nWSNs, gateways, and base station infrastructure,\
    \ and ii) paying trained labour \nto do particular agricultural tasks [72]. Similarly,\
    \ subscriptions to centralized \nnetworks and software packages are necessary\
    \ to support data processing, con-\ntrol of IoT devices and equipment, and knowledge\
    \ exchange, which eventually \nraises operating expenses [73]. Even if service\
    \ providers occasionally provide \nfree subscription packages with limited capabilities,\
    \ storage capacity is limited. \nPeriodic maintenance is essential to ensure the\
    \ proper operation of the smart \nsystem, which adds to the total costs.\nEnvironmental,\
    \ ethical, and societal costs may also be connected with the \nadoption of smart\
    \ devices. Initiatives focusing on cooperative farming are need-\ned to overcome\
    \ cost-related roadblocks by providing: I support services for \nbetter cost management\
    \ and needed investments, and ii) hardware solutions to \ntransform conventional\
    \ equipment into smart farm-ready machinery to reduce \nhigh initial costs [73].\n\
    •Digital division: a lack of awareness of digital technology and their appli-\n\
    cations is another problem limiting the digitalization of the agriculture sector.\
    \ \nThe majority of farmers have no understanding what digital technologies are,\
    \ \nhow to install and utilize them, or which technology is appropriate for their\
    \ farm \nand matches their needs [14]. As a result, farmers must be educated on\
    \ current \nfarming technologies and processes. \nFurthermore, various tactics\
    \ are required to develop tools that use natural \nlanguage and are easily understood\
    \ by farmers with low levels of education [74]. \n•Return on investment: In agriculture,\
    \ like in other industries, the profit \nmargin is critical. When it comes to\
    \ implementing modern technologies, farm-\n443\nSiberian Journal of Life Sciences\
    \ and Agriculture, Том 14, №6, 2022\ners are concerned about the time it will\
    \ take to recoup their investment and the \ndifficulty in assessing the benefits\
    \ [12].\n•Building faith in the effectiveness of smart technology in agriculture\
    \ is \ndifficult, unlike in other disciplines, because many decisions influence\
    \ systems \nthat involve both living and non-living elements, and the results\
    \ can be difficult \nto reverse [16]. In addition, the lack of verification of\
    \ the influence of digital \ntools on farm productivity exacerbates the current\
    \ difficulties.\n•Legal frameworks: different regions and nations have distinct\
    \ legal frame-\nworks that influence the deployment of digital technologies in\
    \ agriculture, par-\nticularly in monitoring and agri-food supply [31]. Similarly,\
    \ laws governing \nresource allocation (spectrum for wireless devices), data privacy,\
    \ and security \ndiffer from country to country [31].\n•Connectivity infrastructure:\
    \ In most developing nations, connectivity in-\nfrastructure is poor, limiting\
    \ access to advanced digital technologies that could \nhelp turn data from disparate\
    \ sources into useful and actionable insights [10].\n4.14. Discussion \nThe goal\
    \ of this study was to describe the new digital technologies that are \nbeing\
    \ used in the agricultural industry in order to predict the future trajectories\
    \ \nof agriculture 4.0. Big data and analytics, wireless sensor networks, cyber-phys-\n\
    ical systems, and digital twins are among the technologies that have yet to be\
    \ \nfully explored in agriculture. This disparity could be due to the fact that\
    \ install-\ning advanced technologies with more complex processes can be costly,\
    \ at least \nin the early stages of their acceptance. The agricultural industry’s\
    \ development \nof these technologies is expected to speed up in the next years.\
    \ The findings of \nSLR also reveal that IoT is widely used in farms. This is\
    \ owing to the IoT’s di-\nverse capabilities, which include monitoring, tracking,\
    \ and tracing, agricultural \nmachinery, and precision agriculture [21]. One of\
    \ the key research aims within \nthe farm 4.0 techniques can be regarded to be\
    \ IoT. Nonetheless, when building \nan intelligent agricultural system, only a\
    \ few researches have examined data \nsecurity and dependability, scalability,\
    \ and interoperability. The outcomes of \nthe study also revealed that the majority\
    \ of use cases are still in the prototype \nstage. The reason for this could be\
    \ that most agricultural activities involve live \nsubjects, such as animals and\
    \ plants, or perishable products, and establish-\ning systems for living subjects\
    \ is more difficult than developing systems for \nnon-living human-made systems.\
    \ Another explanation could be that, due to the \ntrans-disciplinary character\
    \ of agriculture, it is a late adopter of technology. As a \nresult, in order\
    \ to construct intelligent systems, the agricultural community must \nbecome conversant\
    \ with all digital technologies. Finally, differences in plant/\n444\nSiberian\
    \ Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\ncrop species and\
    \ growth conditions complicate agricultural system digitaliza-\ntion [55]. In\
    \ contrast to indoor farms, the majority of the technologies created \nby SLR\
    \ are for open-air soil-based farms (soilless and soil-based). This is owing \n\
    to the complicated design and maintenance of indoor farms, particularly soilless\
    \ \nfarms, where the parameters and elements to be maintained are numerous (pH,\
    \ \nair temperature, humidity, etc.) [5]. However, by incorporating digital technol-\n\
    ogy and data-driven computer applications into indoor farms, a more reliable \n\
    control of the process can be attained. Furthermore, SLR reveals that insufficient\
    \ \nresearch is undertaken in three of the nine service areas described in section\
    \ 3 \n(soil management, fruit detection and counting, and crop quality management).\
    \ \nThis supports the notion that significant research and development is required\
    \ \nin some areas to ensure the successful digitization of the agriculture business\
    \ \nin both developed and developing countries. The agriculture ecosystem’s com-\n\
    plexity creates a set of interrelated hurdles that prevent full integration of\
    \ digital \ntechnology for agriculture 4.0 implementation. As a result, identifying\
    \ possible \nbottlenecks is critical in order to devise strategic strategies to\
    \ overcome them. \nThis research aims to figure out what these stumbling barriers\
    \ are. Following \nthe investigation, 21 barriers were found and characterized\
    \ on both a technical \nand socioeconomic level. These impediments are addressed\
    \ in section 5, which \noutlines what needs to be done on a bigger scale to digitize\
    \ the agricultural \neconomy. However, it is still unknown how much removing or\
    \ mitigating these \nhurdles aids in the successful integration of digital technologies.\
    \ \n4.16. Added value of agricultural digitization \nSeveral benefits that can\
    \ inspire framers and other actors to assist agriculture \nindustry digitization\
    \ have been discovered and outlined based on analysis. The \nbenefits described\
    \ here have the potential to increase farm productivity and im-\nprove product\
    \ quality, but they should not be viewed as a cure for the problems \nthat come\
    \ with smart agriculture [73]. \n•Improved agility: Farm operations can now be\
    \ more agile thanks to digital \ntechnologies. Farmers and agricultural professionals\
    \ can quickly respond to \nany anticipated changes in environmental and water\
    \ conditions using real-time \nsurveillance and forecasting technologies to save\
    \ crops [72].\n•Green process: By lowering the use of in-field fuel, nitrogen\
    \ fertilizers, \npesticides, and herbicides, digital technologies make farming\
    \ more ecologically \nfriendly and climate-resilient [75].\n•Resource efficiency:\
    \ By increasing the quantity and quality of agricultural \noutput while reducing\
    \ the use of water, energy, fertilizers, and pesticides, digital \nplatforms can\
    \ improve resource efficiency [3]. \n445\nSiberian Journal of Life Sciences and\
    \ Agriculture, Том 14, №6, 2022\n•Time and cost savings: By automating various\
    \ tasks such as harvesting, sow-\ning, or irrigation, managing the application\
    \ of fertilizers or pesticides, and sched-\nuling irrigation, digital technologies\
    \ provide significant time and cost savings [76].\n•Asset management: digital\
    \ technologies enable real-time observation of \nfarm holdings and equipment,\
    \ allowing for theft prevention, component re-\nplacement, and routine maintenance\
    \ [10].\n•Product safety: By eliminating fraud [17, 18] linked to adulteration,\
    \ coun-\nterfeiting, and artificial enhancement, digital technologies maintain\
    \ appropriate \nfarm output and ensure a safe and nutritious supply of agri-food\
    \ products [69].\n4.17. Considerations and future prospects \nThe agricultural\
    \ industry would see major benefits as a result of the planned \nmeasures. However,\
    \ the impediments identified in section 5 must be solved first \nin order to make\
    \ things sustainable for small and medium-scale growers. Some \nof the above hurdles\
    \ can be mitigated by awareness campaigns emphasizing the \nimportance of smart\
    \ agriculture at every level of the agricultural value chain and \nencouraging\
    \ novel techniques (such as gamification) to encourage stakeholders \nto take\
    \ an active role in the digital transformation [9]. Initiatives at the federal\
    \ \nlevel, grants and endowments, public-private collaborations, data transparency,\
    \ \nand regional research efforts can all help overcome potential hurdles. Finally,\
    \ \nwhen constructing a smart agriculture system, a roadmap can be used, starting\
    \ \nwith a basic architecture with few components and simpler functionality and\
    \ \ngradually adding components and functionality to develop a sophisticated sys-\n\
    tem with full digitization potential [21]. These issues can pave the road for\
    \ ag-\nriculture 4.0’s successful adoption. The use of explainable artificial\
    \ intelligence \nto monitor crop development, estimate crop biomass, evaluate\
    \ crop health, and \ncontrol pests and diseases is one of the future prospects\
    \ of digital technologies \nin smart agriculture. Explainable AI eliminates the\
    \ old black-box approach of \nmachine learning and allows for a better understanding\
    \ of the reasoning behind \nany given decision [15]. The use of common semantics\
    \ and ontologies to de-\nscribe big data, as well as the adoption of open standards,\
    \ has the potential to \naccelerate research and development in the field of smart\
    \ farming. Similarly, \n5G technology must be thoroughly investigated in order\
    \ to enable improved \nconnectivity and live streaming of crop data [6]. By executing\
    \ precise crop in-\nspections remotely, 5G technology will reduce internet costs\
    \ and enhance the \nentire user experience of farm management and food safety\
    \ [77]. It would also \nhelp to close the gap between stakeholders by keeping\
    \ them informed about \ncrop availability. Finally, blockchain can be used in\
    \ conjunction with IoT and \nother technologies to address data privacy and security\
    \ concerns [78]. \n446\nSiberian Journal of Life Sciences and Agriculture, Vol.\
    \ 14, №6, 2022\n4.18. Transition to Agriculture 5.0 \nThe agriculture sector has\
    \ traditionally had a breakthrough during industri-\nal revolutions. Agriculture\
    \ 4.0 offers significant potential to offset rising food \ndemands and prepare\
    \ for the future by reinforcing agricultural systems with \nWSN, IoT, AI, and\
    \ other technologies, as formally mentioned in preceding \nsections. While agricultural\
    \ 4.0 is still being implemented, agriculture 5.0 is \nalready being discussed.\
    \ \nAgriculture 5.0 builds on agriculture 4.0 by incorporating industry 5.0 prin-\n\
    ciples to provide healthy, affordable food while also ensuring that the environ-\n\
    ments on which life depends are not degraded [79]. Industry 4.0 focuses less \n\
    on the original principles of social fairness and sustainability and more on dig-\n\
    italization and AI-driven technologies for increasing efficiency and flexibility,\
    \ \nthe European Commission formally called for the Fifth Industrial Revolution\
    \ \n(industry 5.0) in 2021 [80]. Industry 5.0 adds to and expands on the industry\
    \ 4.0 \nconcepts by emphasizing human-centricity, sustainability, and resiliency\
    \ [81]. \nIt entails improving human-machine collaboration, decreasing environmental\
    \ \neffect through the circular economy, and designing systems with a high degree\
    \ \nof robustness to reach an ideal balance of efficiency and productivity. Among\
    \ \nthe enabling technologies of industry are cobots (collaborative robots), smart\
    \ \nmaterials with embedded bio-inspired sensors, digital twins, AI, energy efficient\
    \ \nand secure data management, renewable energy sources, and others 5.0[80].\n\
    Farm production efficiency and crop quality can be improved in agriculture \n\
    5.0 settings by delegating repetitive and boring activities to machines and those\
    \ \nthat need critical thinking to humans. For this reason, agricultural cyber\
    \ physical \ncognitive systems (CPCS) that observe/study the environment and conduct\
    \ ap-\npropriate actions, comparable to those established for the manufacturing\
    \ sector, \nshould be developed. This might include collaborative farm robots\
    \ that work in \nthe fields to aid crop growers with time-consuming operations\
    \ like seed sowing \nand harvesting. Similarly, digital twins in agriculture 5.0\
    \ can add substantial value \nby recognizing technical difficulties in agricultural\
    \ systems and resolving them \nmore quickly, detecting crop illnesses, and producing\
    \ more accurate crop output \nestimates. This demonstrates that agriculture 5.0\
    \ has the potential to pave the way \nfor climate-smart, sustainable, and resilient\
    \ agriculture, but it is still in its infancy. \n5. Conclusions \nConcerns about\
    \ global food security have heightened the demand for \nnext-generation industrial\
    \ farms and agricultural intensive production systems. \nDigital technologies,\
    \ such as those given by the Industry 4.0 programme, are at \n447\nSiberian Journal\
    \ of Life Sciences and Agriculture, Том 14, №6, 2022\nthe vanguard of this modern\
    \ agricultural period, providing a wide range of in-\nnovative solutions. Disruptive\
    \ technologies are being integrated into traditional \nagriculture systems by\
    \ scientists and researchers in order to boost crop yields, \ncut costs, reduce\
    \ waste, and sustain process inputs. This report includes an SLR \nthat discusses\
    \ the current state of various technologies in the agriculture sector. \nSeveral\
    \ findings are drawn, including the fact that big data and analytics inte-\ngration,\
    \ wireless sensor networks, cyber-physical systems, and digital twins in \nagriculture\
    \ are still in their infancy, with the majority of use cases still in the \nprototype\
    \ stage. Similarly, 21 technological and socioeconomic impediments \nare found\
    \ and categorized. These impediments must be identified and addressed \nif the\
    \ agriculture industry is to be digitalized. The report also identifies and \n\
    presents the additional value of digital technology in the agriculture industry.\
    \ \nOverall, this research contributes to the ongoing research on agricultural\
    \ 4.0. \nThe review’s principal restriction is twofold: first, only three online\
    \ reposito-\nries (Scopus, IEEE, and Science Direct) are considered for literature\
    \ searches, \nand second, new keywords and synonyms may return more papers. The\
    \ main \nconclusions are highly unlikely to alter in either scenario. Additional\
    \ research \ndatabases and areas can be considered for future study in order to\
    \ provide a \ncomplete overview of the agriculture industry in terms of digitization.\
    \ In addi-\ntion, papers focusing on agriculture 5.0 in general will be featured.\n\
    References\n1. F Schierhorn, M. Elferink, Global Demand for Food Is Rising. Can\
    \ We Meet \nIt? Harv Bus Rev, 2016, 7 (2017). https://hbr.org/2016/04/global-demand-for-\n\
    food-is-rising-can-we-meet-it\n2. Singh, G. Machine Learning Models in Stock Market\
    \ Prediction. International \nJournal of Innovative Technology and Exploring Engineering,\
    \ 2022, vol. 11, \nno. 3, pp. 18-28. https://doi.org/10.35940/ijitee.C9733.0111322\n\
    3. WK Mok, YX Tan, WN. Chen, Technology innovations for food security in \nSingapore:\
    \ A case study of future food systems for an increasingly natural re-\nsource-scarce\
    \ world, Trends Food Sci Technol, 2020, vol. 102, pp. 155–168, \nhttps://doi.org/10.1016/j.tifs.2020.06.013\n\
    4. Nagar, P., & Issar, G. S. Detection of outliers in stock market using regression\
    \ \nanalysis. International Journal of Emerging Technologies in Computational\
    \ and \nApplied Science, 2013. https://doi.org/10.5281/zenodo.6047417\n5. R Abbasi,\
    \ P Martinez, R. Ahmad, An ontology model to represent aquapon-\nics 4.0 system’s\
    \ knowledge, Inf Process Agric, 2021. https://doi.org/10.1016/J.\nINPA.2021.12.001\n\
    448\nSiberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\n6.\
    \ R Abbasi, P Martinez, R. Ahmad, An ontology model to support the automat-\n\
    ed design of aquaponic grow beds, Procedia CIRP, 2021, vol. 100, pp. 55–60, \n\
    https://doi.org/10.1016/j.procir.2021.05.009\n7. G Aceto, V Persico, A. Pescapé,\
    \ A Survey on Information and Communication \nTech- nologies for Industry 4.0:\
    \ State-of-the-Art, Taxonomies, Perspectives, \nand Challenges, IEEE Commun Surv\
    \ Tutorials, 2019. https://doi.org/10.1109/\nCOMST.2019.2938259\n8. B. Ozdogan,\
    \ A. Gacar, H. Aktas. Digital agriculture practices in the context of \nagriculture\
    \ 4.0. Journal of Economics, Finance and Accounting (JEFA), 2017, \nvol. 4, iss.\
    \ 2, pp. 184-191. https://doi.org/10.17261/pressacademia.2017.448\n9. Y Liu, X\
    \ Ma, L Shu, GP Hancke, AM. Abu-Mahfouz, From Industry 4.0 to Ag-\nriculture 4.0:\
    \ Current Status, Enabling Technologies, and Research Challenges, \nIEEE Trans\
    \ Ind Informatics, 2021, vol. 17, no. 6, pp. 4322-4334. https://doi.\norg/10.1109/TII.2020.3003910\n\
    10. F da Silveira, FH Lermen, FG. Amaral, An overview of agriculture 4.0 devel-\n\
    opment: Systematic review of descriptions, technologies, barriers, advantag-\n\
    es, and disadvantages, Comput Electron Agric 189 (2021) 106405, https://doi.\n\
    org/10.1016/J.COMPAG.2021.106405\n11. G Idoje, T Dagiuklas, M. Iqbal, Survey for\
    \ smart farming technologies: Chal-\nlenges and issues, Comput Electr Eng, 2021,\
    \ vol. 92, 107104. https://doi.\norg/10.1016/J.COMPELECENG.2021.107104\n12. J\
    \ Miranda, P Ponce, A Molina, P. Wright, Sensing, smart and sustain- able tech-\n\
    nologies for Agri-Food 4.0, Comput Ind, 2019, vol. 108, pp. 21–36. https://doi.\n\
    org/10.1016/J.COMPIND.2019.02.002 \n13. M Lezoche, H Panetto, J Kacprzyk, JE Hernandez,\
    \ Alemany Díaz MME. \nAgri-food 4.0: A survey of the supply chains and technologies\
    \ for the future \nagriculture, Comput Ind, 2020, vol. 117, 103187. https://doi.org/10.1016/J.\n\
    COMPIND.2020.103187\n14. Bhakta I, Phadikar S, Majumder K. State-of-the-art technologies\
    \ in precision \nagriculture: a systematic review. Journal of the Science of Food\
    \ and Agriculture, \n2019, vol. 99, no. 11. pp. 4878-4888. https://doi.org/10.1002/jsfa.9693\n\
    15. SO Araújo, RS Peres, J Barata, F Lidon, JC. Ramalho, Characterising the \n\
    Agriculture 4.0 Landscape — Emerging Trends, Challenges and Opportu-\nnities,\
    \ Agron, 2021, vol. 11, no. 4, 667. https://doi.org/10.3390/AGRONO-\nMY11040667\n\
    16. M Bacco, P Barsocchi, E Ferro, A Gotta, M. Ruggeri, The Digitisation of Agri-\n\
    culture: a Survey of Research Activities on Smart Farming, Array, 2019, 3–4, \n\
    100009. https://doi.org/10.1016/j.array.2019.100009\n449\nSiberian Journal of\
    \ Life Sciences and Agriculture, Том 14, №6, 2022\n17. Singh, G., & Nager, P.\
    \ A case Study on Nutek India Limited Regarding Deep \nFalling in Share Price.\
    \ Researchers World - Journal of Arts, Science & Com-\nmerce, 2012, vol. 3(2),\
    \ 3.\n18. Nager, P., & Singh, G. An Analysis of Outliers For Fraud Detection in\
    \ Indian \nStock Market. Researchers World - Journal of Arts, Science & Commerce,\
    \ 2012, \nvol. 3(4), 4.\n19. MJ Page, JE McKenzie, PM Bossuyt, I Boutron, TC Hoffmann,\
    \ CD Mulrow, et \nal., The PRISMA 2020 statement: An updated guideline for reporting\
    \ systematic \nreviews, BMJ, 2021, 372. https://doi.org/10.1136/BMJ.N71\n20. Ahmed\
    \ MA, Ahsan I, Abbas M. Systematic Literature Review: Ingenious \nSoftware Project\
    \ Management while narrowing the impact aspect. RACS ‘16: \nProceedings of the\
    \ International Conference on Research in Adaptive and Con-\nvergent Systems,\
    \ 2016, pp. 165–168. https://doi.org/10.1145/2987386.2987422\n21. C Pylianidis,\
    \ S Osinga, IN. Athanasiadis, Introducing digital twins to agricul-\nture, Comput\
    \ Electron Agric 184 (2021) 105942, https://doi.org/10.1016/J.\nCOMPAG.2020.105942\
    \ \n22. Shaikh ZA Aqeel-ur-Rehman, NA Shaikh, N Islam, An integrated framework\
    \ \nto de- velop context aware sensor grid for agriculture, Aust J Basic Appl\
    \ Sci, \n2010. \n23. W Shi, J Cao, Q Zhang, Y Li, L. Xu, Edge Computing: Vision\
    \ and Chal-\nlenges, IEEE Internet Things J 3, 2016, 637–646, https://doi.org/10.1109/\n\
    JIOT.2016.2579198\n24. A Tzounis, N Katsoulas, T Bartzanas, C. Kittas, Internet\
    \ of Things in agricul- \nture, recent advances and future challenges, Biosyst\
    \ Eng, 164, 2017, 31–48, \nhttps://doi.org/10.1016/J.BIOSYSTEMSENG.2017.09.007\n\
    25. VP Kour, S. Arora, Recent Developments of the Internet of Things in Agri-\
    \ cul-\nture: A Survey, IEEE Access 8, 2020, 129924–129957, https://doi.org/10.1109/\n\
    AC- CESS.2020.3009298\n26. MU Aftab, O Ashraf, M Irfan, M Majid, A Nisar, MA.\
    \ Habib, A Review Study \nof Wireless Sensor Networks and Its Security, Commun\
    \ Netw, 7, 2015, 172–179, \nhttps://doi.org/10.4236/cn.2015.74016\n27. X Yu, P\
    \ Wu, W Han, Z. Zhang, A survey on wireless sensor network infra-\nstructure for\
    \ agriculture, Comput Stand Interfaces, 1, 2013, 59–64, https://doi.\norg/10.1016/J.CSI.2012.05.001\n\
    28. Mell PM, Grance T. The NIST definition of cloud computing, 2011. https://doi.\n\
    org/10.6028/NIST.SP.800-145\n29. Alwada’n T. Cloud computing and multi-agent system:\
    \ monitoring and services. \n2018. \n450\nSiberian Journal of Life Sciences and\
    \ Agriculture, Vol. 14, №6, 2022\n30. X Shi, X An, Q Zhao, H Liu, L Xia, X Sun,\
    \ et al., State-of-the-art inter- net of \nthings in protected agriculture, Sensors\
    \ (Switzerland), 19, 2019, 1833, https://\ndoi.org/10.3390/s19081833\n31. J Wang,\
    \ H Yue, Z. Zhou, An improved traceability system for food quality assur-\nance\
    \ and evaluation based on fuzzy classification and neural network, Food Con-\n\
    trol, 79, 2017, 363–370, https://doi.org/10.1016/J.FOODCONT.2017.04.013\n32. S\
    \ Fountas, G Carli, CG Sørensen, Z Tsiropoulos, C Cavalaris, A Vatsanidou, et\
    \ \nal., Farm management information systems: Current situation and future per-\n\
    spectives, Comput Electron Agric, 115, 2015, 40–50, https://doi.org/10.1016/J.\n\
    COMPAG.2015.05.011\n33. A Bechar, C. Vigneault, Agricultural robots for field\
    \ operations: Concepts and \ncomponents, Biosyst Eng, 149, 2016, 94–111, https://doi.org/10.1016/J.BIO-\n\
    SYSTEMSENG.2016.06.014\n34. Gonzalez-De-Santos P, Fernández R, Sepúlveda D, Navas\
    \ E, Armada M. Un- \nmanned Ground Vehicles for Smart Farms. Agron - Clim Chang\
    \ Food Secur, \n2020. https://doi.org/10.5772/INTECHOPEN.90683\n35. J del Cerro,\
    \ CC Ulloa, A Barrientos, L. Rivas J de, Unmanned Aerial Vehicles in \nAgri- culture:\
    \ A Survey, Agron, 11, 2021, 203, https://doi.org/10.3390/AGRON-\nOMY11020203\n\
    36. Patel PN, Patel M, Faldu RM, Dave YR. Quadcopter for Agricultural Surveil-\n\
    lance, 2013.\n37. Sylvester G, Food and Agriculture Organization of the United\
    \ Nations., International \nTelecommunication Union. E-agriculture in action:\
    \ drones for agriculture n.d.:112. \n38. U Sivarajah, MM Kamal, Z Irani, V. Weerakkody,\
    \ Critical analysis of Big Data \nchallenges and analytical methods, J Bus Res,\
    \ 70, 2017, 263–286, https://doi.\norg/10.1016/J.JBUSRES.2016.08.001\n39. M Chi,\
    \ A Plaza, JA Benediktsson, Z Sun, J Shen, Y. Zhu, Big Data for Re- \nmote Sensing:\
    \ Challenges and Opportunities, Proc IEEE, 104, 2016, 2207–2219, \nhttps://doi.org/10.1109/JPROC.2016.2598228\
    \ \n40. K Tesfaye, K Sonder, J Caims, C Magorokosho, A Tarekegn, GT Kassie, et\
    \ al. \nTarget- ing drought-tolerant maize varieties in southern Africa: a geospatial\
    \ crop \nmodeling approach using big data, Int Food Agribus Manag Rev, 19, 2016.\
    \ \n41. R Sharma, SS Kamble, A Gunasekaran, V Kumar, A. Kumar, A system- atic\
    \ \nliterature review on machine learning applications for sustainable agri- culture\
    \ \nsupply chain performance, Comput Oper Res, 119, 2020, 104926, https://doi.\n\
    org/10.1016/J.COR.2020.104926\n42. T Talaviya, D Shah, N Patel, H Yagnik, M. Shah,\
    \ Implementation of artifi-\ncial intelli- gence in agriculture for optimisation\
    \ of irrigation and application \n451\nSiberian Journal of Life Sciences and Agriculture,\
    \ Том 14, №6, 2022\nof pesticides and herbicides, Artif Intell Agric, 4, 2020,\
    \ 58–73, https://doi.\norg/10.1016/J.AIIA.2020.04.002\n43. KG Liakos, P Busato,\
    \ D Moshou, S Pearson, D. Bochtis, Machine Learn- ing in \nAgriculture: A Review,\
    \ Sensors, 18, 2018, 2674, https://doi.org/10.3390/S18082674\n44. G Xu, H Li,\
    \ S Liu, K Yang, X. Lin, VerifyNet: Secure and Verifiable Federat-\ned Learning,\
    \ IEEE Trans Inf Forensics Secur, 15, 2020, 911–926, https://doi.\norg/10.1109/TIFS.2019.2929409\n\
    45. J. Schmidhuber, Deep Learning in Neural Networks: An Overview, Neural Net-\n\
    works, 61, 2014, 85–117, https://doi.org/10.1016/j.neunet.2014.09.003 \n46. Canziani\
    \ A, Paszke A, Culurciello E. An Analysis of Deep Neural Network \nModels for\
    \ Practical Applications, 2016. \n47. A Kamilaris, FX. Prenafeta-Boldu, Deep learning\
    \ in agriculture: A survey, \nComput Electron Agric, 147, 2018, 70–90, https://doi.org/10.1016/j.com-\n\
    pag.2018.02.016\n48. V Kakani, VH Nguyen, BP Kumar, H Kim, VR. Pasupuleti, A critical\
    \ review on \ncomputer vision and artificial intelligence in food industry, J\
    \ Agric Food Res, 2, \n2020, https://doi.org/10.1016/J.JAFR.2020.100033\n49. F\
    \ Terribile, A Agrillo, A Bonfante, G Buscemi, M Colandrea, A D’Antonio, et al.,\
    \ A \nWeb-based spatial decision supporting system for land management and soil\
    \ con-\nservation, Solid Earth 6 (2015) 903–928, https://doi.org/10.5194/SE-6-903-2015\n\
    50. A Felsberger, B Oberegger, G. Reiner, A Review of Decision Support Systems\
    \ \nfor Manufacturing Systems, Undefined, 2016. \n51. P Taechatanasat, L. Armstrong,\
    \ Decision Support System Data for Farmer De-\ncision Making, ECU Publ Post (2013)\
    \ 2014 . \n52. L Wang, M Törngren, M. Onori, Current status and advancement of\
    \ cyber- phys-\nical systems in manufacturing, J Manuf Syst, 37, 2015), 517–527,\
    \ https://doi.\norg/10.1016/J.JMSY.2015.04.008\n53. DGS Pivoto, LFF de Almeida,\
    \ R da Rosa Righi, JJPC Rodrigues, AB Lugli, \nAM. Al- berti, Cyber-physical systems\
    \ architectures for industrial internet of \nthings appli- cations in Industry\
    \ 4.0: A literature review, J Manuf Syst, 58, 2021, \n176–192, https://doi.org/10.1016/J.JMSY.2020.11.017\n\
    54. AF Jimenez, PF Cardenas, F Jimenez, A Canales, A. López, A cyber-physical\
    \ in-\ntelli- gent agent for irrigation scheduling in horticultural crops, Comput\
    \ Electron \nAgric, 178, 2020, 105777, https://doi.org/10.1016/J.COMPAG.2020.105777\n\
    55. A Selmani, H Oubehar, M Outanoute, A Ed-Dahhak, M Guerbaoui, A Lach- hab,\
    \ \net al., Agricultural cyber-physical system enabled for remote management of\
    \ \nsolar-powered precision irrigation, Biosyst Eng, 177, 2019, 18–30, https://doi.\n\
    org/10.1016/J.BIOSYSTEMSENG.2018.06.007\n452\nSiberian Journal of Life Sciences\
    \ and Agriculture, Vol. 14, №6, 2022\n56. A Nayak, RR Levalle, S Lee, SY. Nof,\
    \ Resource sharing in cyber-physical sys-\ntems: modelling framework and case\
    \ studies, 54, 2016, 6969–6983, https://doi.\norg/10.1080/00207543.2016.1146419\n\
    57. C Verdouw, B Tekinerdogan, A Beulens, S. Wolfert, Digital twins in smart farming,\
    \ \nAgric Syst, 189, 2021, 103046, https://doi.org/10.1016/J.AGSY.2020.103046\n\
    58. D Jones, C Snider, A Nassehi, J Yon, B Hicks, Characterising the Digital Twin:\
    \ \nA systematic literature review, CIRP J Manuf Sci Technol, 29, 2020, 36–52,\
    \ \nhttps://doi.org/10.1016/J.CIRPJ.2020.02.002\n59. S Aydin, MN. Aydin, Semantic\
    \ and syntactic interoperability for agricultural \nopen- data platforms in the\
    \ context of IoT using crop-specific trait ontologies, \nAppl Sci, 10, 2020, https://doi.org/10.3390/app10134460\n\
    60. Y He, J Guo, X. Zheng, From Surveillance to Digital Twin: Challenges and Re-\n\
    cent Advances of Signal Processing for Industrial Internet of Things, IEEE Signal\
    \ \nProcess Mag, 35, 2018, 120–129, https://doi.org/10.1109/MSP.2018.2842228\n\
    61. MS Farooq, S Riaz, A Abid, K Abid, MA. Naeem, A Survey on the Role of IoT\
    \ \nin Agriculture for the Implementation of Smart Farming, IEEE Access, 7, 2019,\
    \ \n156237–156271, https://doi.org/10.1109/ACCESS.2019.2949703\n62. A Villa-Henriksen,\
    \ GTC Edwards, LA Pesonen, O Green, CAG. Sørensen, In-\nternet of Things in arable\
    \ farming: Implementation, applications, challenges and \npotential, Biosyst Eng,\
    \ 191, 2020, 60–84, https://doi.org/10.1016/J.BIOSYSTE-\nMSENG.2019.12.013\n63.\
    \ HM Jawad, R Nordin, SK Gharghan, AM Jawad, M. Ismail, Energy-efficient \nwire-\
    \ less sensor networks for precision agriculture: A review, Sensors (Swit-\nzerland),\
    \ 17, 2017, 1781, https://doi.org/10.3390/s17081781\n64. L Sigrist, N Stricker,\
    \ D Bernath, J Beutel, L. Thiele, Thermoelectric Energy \nHarvesting from Gradients\
    \ in the Earth Surface, IEEE Trans Ind Electron, 67, \n2020, 9460–9470, https://doi.org/10.1109/TIE.2019.2952796\n\
    65. AR Yanes, P Martinez, R. Ahmad, Towards automated aquaponics: A re-\nview\
    \ on monitoring, IoT, and smart systems, J Clean Prod, 2020, https://doi.\norg/10.1016/j.jclepro.2020.121571\n\
    66. N Brinis, LA. Saidane, Context Aware Wireless Sensor Network Suitable \nfor\
    \ Preci- sion Agriculture, Wirel Sens Netw, 2016, https://doi.org/10.4236/\nwsn.2016.81001\n\
    67. M Zimmerling, L Mottola, S. Santini, Synchronous Transmissions in Low-Pow-\n\
    er Wireless: A Survey of Communication Protocols and Network Services, ACM \n\
    Comput Surv, 53 2021, https://doi.org/10.1145/3410159\n68. F Tonolini, F. Adib,\
    \ Networking across boundaries: Enabling wireless com-\nmunica- tion through the\
    \ water-air interface, SIGCOMM 2018 - Proc 2018 \n453\nSiberian Journal of Life\
    \ Sciences and Agriculture, Том 14, №6, 2022\nConf ACM Spec Interes Gr Data Commun,\
    \ 2018, 117–131, https://doi.\norg/10.1145/3230543.3230580\n69. L Chen, S Thombre,\
    \ K Jarvinen, ES Lohan, A Alen-Savikko, H Leppakoski, et al., Ro- \nbustness,\
    \ Security and Privacy in Location-Based Services for Future IoT: A Survey, \n\
    IEEE Access, 5, 2017, 8956–8977, https://doi.org/10.1109/ACCESS.2017.2695525\n\
    70. Y Njah, M. Cheriet, Parallel Route Optimization and Service Assurance in Ener-\n\
    gy- Efficient Software-Defined Industrial IoT Networks, IEEE Access, 9, 2021,\
    \ \n24682–24696, https://doi.org/10.1109/ACCESS.2021.3056931\n71. A Rajput, VB.\
    \ Kumaravelu, Scalable and sustainable wireless sensor networks \nfor agricultural\
    \ application of Internet of things using fuzzy c-means algorithm, \nSustain Comput\
    \ Informatics Syst, 22, 2019, 62–74, https://doi.org/10.1016/J.\nSUSCOM.2019.02.003\n\
    72. BB Sinha, R. Dhanalakshmi, Recent advancements and challenges of Internet\
    \ \nof Things in smart agriculture: A survey, Futur Gener Comput Syst, 126, 2022,\
    \ \n169–184, https://doi.org/10.1016/J.FUTURE.2021.08.006\n73. F Caffaro, E. Cavallo,\
    \ The effects of individual variables, farming system char-\nacter- istics and\
    \ perceived barriers on actual use of smart farming technologies: \nEvidence from\
    \ the piedmont region, northwestern Italy, Agric, 9, 2019, https://\ndoi.org/10.3390/AGRI-\
    \ CULTURE9050111 \n74. Mohit Jain, Pratyush Kumar, Ishita Bhansali, Q. Vera Liao,\
    \ Khai Truong, \nShwetak Patel. FarmChat: A Conversational Agent to Answer Farmer\
    \ Que-\nries. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiq-\n\
    uitous Technologies, 2018, vol. 2, issue 4, article 170, pp 1–22. https://doi.\n\
    org/10.1145/3287048\n75. Mclaughlan B, Brandli J, Smith F. Toward Sustainable\
    \ High-Yield Agriculture \nvia Intelligent Control Systems, 2015. \n76. RK Kodali,\
    \ S Soratkal, L. Boppana, IOT based control of appliances, in: Pro-\nceeding -\
    \ IEEE Int Conf Comput Commun Autom ICCCA 2016, 2017, pp. \n1293–1297, https://doi.org/10.1109/CCAA.2016.7813918\n\
    77. Abbasi R, Reyes A, Martinez E, Ahmad R. Real-time implementation of digital\
    \ \ntwin for robot based production line n.d.:4–6. \n78. O Bermeo-Almeida, M Cardenas-Rodriguez,\
    \ T Samaniego-Cobo, E Ferruzo-\nla- Gómez, R Cabezas-Cabezas, W. Bazán-Vera, Blockchain\
    \ in Agriculture: A \nSystematic Literature Review, Commun Comput Inf Sci, 883,\
    \ 2018, 44–56, \nhttps://doi.org/10.1007/978-3-030-00940-3_4\n79. V Saiz-Rubio,\
    \ F. Rovira-Más, From Smart Farming towards Agriculture 5.0: \nA Review on Crop\
    \ Data Management, Agron, 10, 2020, 207, https://doi.\norg/10.3390/AGRONOMY10020207\n\
    454\nSiberian Journal of Life Sciences and Agriculture, Vol. 14, №6, 2022\n80.\
    \ X Xu, Y Lu, B Vogel-Heuser, L. Wang, Industry 4.0 and Industry 5.0 – Incep-\n\
    tion, conception and perception, J Manuf Syst, 61, 2021, 530–535, https://doi.\n\
    org/10.1016/J.JMSY.2021.10.006\n81. PKR Maddikunta, Q-V Pham, P B, N Deepa, K\
    \ Dev, TR Gadekallu, et al., In-\ndustry 5.0: A survey on enabling technologies\
    \ and potential applications, J Ind \nInf Integr, 2021, 100257, https://doi.org/10.1016/J.JII.2021.100257\n\
    DATA ABOUT THE AUTHORS\nGurjeet Singh, Associate Professor& Dean, Lords School\
    \ of Computer Ap-\nplications & IT\n \nLords University\n \nAlwar-Bhiwadi Highway,\
    \ Chikani, Alwar, 301028, Rajasthan\n \nresearch.gurjeet@gmail.com\nNaresh Kalra,\
    \ Deputy Registrar (Research), Faculty of Pharmacy\n \nLords University\n \nAlwar-Bhiwadi\
    \ Highway, Chikani, Alwar, 301028, Rajasthan\n \nnaresh.kalra@lordsuni.edu.in\n\
    Neetu Yadav, Associate Professor& Dean, Lords School of Social Sciences \n& Humanities\n\
    \ \nLords University\n \nAlwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan\n\
    \ \nneetu.yadav@lordsuni.edu.in\nAshwani Sharma, Assistant Professor, Lords School\
    \ of Computer Applica-\ntions & IT\n \nLords University\n \nAlwar-Bhiwadi Highway,\
    \ Chikani, Alwar, 301028, Rajasthan\n \nashwani.sharma@lordsuni.edu.in\nAshwani\
    \ Sharma, Assistant Professor, Lords School of Computer Applica-\ntions & IT\n\
    \ \nLords University\n \nAlwar-Bhiwadi Highway, Chikani, Alwar, 301028, Rajasthan\n\
    \ \nmanoj.saini@lordsuni.edu.in \nПоступила 21.05.2022 \nReceived 21.05.2022\n\
    После рецензирования 21.06.2022 \nRevised 21.06.2022\nПринята 03.07.2022 \nAccepted\
    \ 03.07.2022\n"
  inline_citation: '>'
  journal: Siberian journal of life sciences and agriculture
  limitations: '>'
  pdf_link: http://discover-journal.ru/jour/index.php/sjlsa/article/download/657/260
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'SMART AGRICULTURE: A REVIEW'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/su11205849
  analysis: '>'
  authors:
  - Imran
  - Shabir Ahmad
  - Do‐Hyeun Kim
  citation_count: 27
  full_citation: '>'
  full_text: ">\nsustainability\nArticle\nDesign and Implementation of Thermal Comfort\n\
    System based on Tasks Allocation Mechanism in\nSmart Homes\nImran\n, Shabir Ahmad\n\
    and DoHyeun Kim *\nDepartment of Computer Engineering, Jeju National University,\
    \ Jeju 63243, Korea; imranjejunu@gmail.com (I.);\nshabir@jejunu.ac.kr (S.A.)\n\
    * Correspondence: kimdh@jejunu.ac.kr\nReceived: 4 September 2019; Accepted: 14\
    \ October 2019; Published: 21 October 2019\n\x01\x02\x03\x01\x04\x05\x06\a\b\x01\
    \n\x01\x02\x03\x04\x05\x06\a\nAbstract: The recent trend in the Internet of Things\
    \ (IoT) is bringing innovations in almost every ﬁeld\nof science. IoT is mainly\
    \ focused on the connectivity of things via the Internet. IoT’s integration tools\n\
    are developed based on the Do It Yourself (DIY) approach, as the general public\
    \ lacks technical\nskills. This paper presents a thermal comfort system based\
    \ on tasks allocation mechanism in\nsmart homes. This paper designs and implements\
    \ the tasks allocation mechanism based on virtual\nobjects composition for IoT\
    \ applications. We provide user-friendly drag and drops panels for\nthe new IoT\
    \ users to visualize both task composition and device virtualization. This paper\
    \ also\ndesigns tasks generation from microservices, tasks mapping, task scheduling,\
    \ and tasks allocation\nfor thermal comfort applications in smart home. Microservices\
    \ are functional units of services in\nan IoT environment. Physical devices are\
    \ registered, and their corresponding virtual objects are\ninitialized. Tasks\
    \ are generated from the microservices and connected with the relevant virtual\
    \ objects.\nAfterward, they are scheduled and ﬁnally allocated on the physical\
    \ IoT device. The task composition\ntoolbox is deployed on the cloud for users\
    \ to access the application remotely. The performance of\nthe proposed architecture\
    \ is evaluated using both real-time and simulated scenarios. Round trip\ntime\
    \ (RTT), response time, task dropping and latency are used as the performance\
    \ metrics. Results\nindicate that even for worst-case scenarios, values of these\
    \ metrics are negligible, which makes our\narchitecture signiﬁcant, better and\
    \ ideal for task allocation in IoT network.\nKeywords:\nInternet of Things; Do-It-Yourself;\
    \ IoT Applications; Task Level Management;\nMicroservices; Task allocation\n1.\
    \ Introduction\nServices provided through the world wide web (WWW) serve as a\
    \ medium for people to create,\ninnovate and share their work with others. The\
    \ Internet enables the reuse of other’s work as a\ncornerstone for smart and useful\
    \ things creation. The Internet medium plays a vital role in the\nrealization\
    \ of IoT [1]. The recent trend in the IoT is bringing innovations in almost every\
    \ ﬁeld of life [2].\nHardware boards are electronic modules; IoT users can combine\
    \ these modules to develop their custom\nIoT applications based on smarter things.\
    \ Some of the most popular boards are Adafruit Flora [3],\nArduino [4], Intel\
    \ Edison [5], and Raspberry Pi [6]. Most of the manufacturers of these boards\
    \ provide\nAPI and coding documentation for the programming languages supported\
    \ by its environment; many\nof these boards support programming languages such\
    \ as Python and Java. Users with the necessary\nskills of its supported languages\
    \ can start creating IoT applications by customizing the existing code\nfor these\
    \ boards.\nIn the IoT network sensors, actuators are the most used vital nodes;\
    \ other important key nodes\nare smart objects, RFID tags, and servers. These\
    \ nodes can perform a minimal amount of tasks as they\nSustainability 2019, 11,\
    \ 5849; doi:10.3390/su11205849\nwww.mdpi.com/journal/sustainability\nSustainability\
    \ 2019, 11, 5849\n2 of 24\nare different from each other in capabilities such\
    \ as power consumption, residual energy, available\nmemory, and processing capacity\
    \ [7]. In order to perform some given IoT application tasks, these\nnodes must\
    \ have capability of reconﬁguring themselves and interoperate autonomously. Powerful\n\
    IoT applications require different IoT nodes to collaborate for performing a speciﬁc\
    \ task; all of these\ntasks performed by a node or more than one nodes brings\
    \ to the most diverse applications. Examples\ninclude IoT applications in smart\
    \ house, Agriculture and Healthcare. Furthermore, technologies trends\nshowings\
    \ that in future, more complex applications will be developed by integrating IoT\
    \ and Artiﬁcial\nintelligence, and other ﬁelds’ knowledge together. e.g., Machine\
    \ to Machine (M2M) communication,\ni.e., smart cars and smart vehicles sharing\
    \ critical information such as trafﬁc congestion and accident\nlocations to ambulances.\n\
    Human psychology has various drivers toward the DIY approach. Usability and Innovations\n\
    of today’s DIY architectures enable new users to do creative things in a simple,\
    \ easy way. In the IoT\nﬁeld, one of the motivations for applying DIY approaches\
    \ is the advancement in development Kits\nsuch as Arduino, Grove* and Raspberry\
    \ Pi. Today’s IoT research is mainly focused on technologies\nand research methodologies\
    \ for enabling the connectivity of things to the Internet intelligently and\n\
    efﬁciently. These innovations and research in IoT, particularly in DIY architectures\
    \ making the general\npublic involved in the extension of these technologies to\
    \ other ﬁelds of science. Therefore, DIY\narchitecture and toolkits are essential\
    \ for future IoT advancements. New users cannot understand\nmany important contents\
    \ easily if architecture is not following usability and other ease of use matrices.\n\
    Hence, one of the goals of this research is to provide a solution to the task\
    \ allocation problem using a\nDIY approach focused on user usability and reliability\
    \ factors.\nIn this paper, we propose a tasks allocation mechanism for thermal\
    \ comfort in smart homes. The\nprocess is based on task-based managemnt that includes\
    \ from microservice analysis to task allocation\non physical devices. Microservices\
    \ are used for the generation of Tasks in the IoT environment. These\ngenerated\
    \ tasks are directly associated with IoT resources such as sensors or actuators.\
    \ A task is\nassociated with a device commonly known as task mapping [8]. Task\
    \ scheduling is changing the\norder of these pairs such that tasks that need to\
    \ be executed ﬁrst are executed ﬁrst and vice versa.\nTask allocation is the process\
    \ of assigning a task to a physical device and allocating a time slot to the\n\
    task. Task deployment is the execution of tasks on the physical device at the\
    \ allocated time. The IoT\norchestration architecture we propose provides effective\
    \ task allocation on physical IoT devices full\nﬁling basic requirements of the\
    \ user and avoid the excess use of constrained resources.\nThe rest of the paper\
    \ is structured as follows. Section 2 presents the related work, highlighting\n\
    the contribution to IoT integration architectures. In Section 3, the proposed\
    \ methods for Task and\nVirtual Objects Composition are discussed; Section 4 explains\
    \ the design of the proposed architecture;\nImplementation and results are discussed\
    \ in Section 5. Performance analysis and signiﬁcance of the\nproposed architecture\
    \ is discussed in Section 6; Section 7 concludes the research study and discusses\n\
    future work direction.\n2. Related Work\nThe IoT vision is the connectivity of\
    \ smart objects that can be deployed in any space to provide\nservices to people.\
    \ In order for good user experience, users difﬁculties in the use of IoT tools\
    \ must be\naddressed.Some of the research focuses on the DIY approach for the\
    \ development of user-friendly IoT\nplatforms; users learn visual programming-based\
    \ techniques to develop their custom IoT applications.\nPhilips company is a brand\
    \ of electronics, famous in the market for electronics products primarily\nknown\
    \ for manufacturing appliances of daily use in the home. Philips Hue is an IoT\
    \ management\nplatform For the connectivity of user’s home appliances to their\
    \ IoT smart space [9]. The dashboard\nconsiders usability and best user experience\
    \ factors allowing connectivity of home appliances to\nsmart home IoT network\
    \ in a natural way; users can also monitor the appliances remotely from\nthe IoT\
    \ management platform. This platform only focuses on the realization of IoT; scalability,\
    \ and\nmanagement issues are also not considered by this platform [10].\nSustainability\
    \ 2019, 11, 5849\n3 of 24\nThe OPEL software is an IoT platform that supports\
    \ simple and easy programming. The design\nof this platform considers features\
    \ of programming language which can enlarge the IoT ecosystem;\nfeatures examples\
    \ are portability, extendibility, and high productivity. The platform should provide\
    \ a\nmechanism for secure application development by the use of high-level APIs\
    \ provided by the platform.\nSome of the functions provided by these APIs are\
    \ device management and communication between\nthese devices. This platform also\
    \ supports multiple IoT applications which means that users can install\nmultiple\
    \ applications with diverse functions. The platform also supports the concurrent\
    \ execution\nof these applications, enabling a user to take advantage of using\
    \ multiple services on a single device.\nThis software platform also enables the\
    \ communication of IoT devices with host IoT devices; also the\nhost device will\
    \ able to control the companion IoT device [11].\nGlue.things a project developed\
    \ on the core concept of device integration and real-time\ncommunication utilizing\
    \ some of the well-established open source technologies. This real-time\ncommunication\
    \ is made possible by using the web sockets’ most recent technologies, i.e., CoAP\
    \ and\nMQTT. The protocols are utilized on real-time mashups of the network data\
    \ streams, which is ﬁnally\ndeployed in a distributed environment. The proposed\
    \ system is a mechanism for the composition of\ndata streams from web services\
    \ [12]. Glue.things provides a collaboration platform with JSON data\nmodels,\
    \ REST APIs and web sockets. Node-RED inspires the mashup interface.\nNode-RED\
    \ from IBM’s is a DIY approach based ﬂow programming platform recently developed\n\
    and got popularity due to its browser-based powerful editor [13]. The goal of\
    \ the developed was to\nprovide a programming tool for wiring hardware devices\
    \ by reducing the coding effort and technicality\nfor developers. The node-red\
    \ tool enables users to wire together hardware devices visualized in\ngraphical\
    \ nodes form. The graphical nodes represent physical devices, web service, and\
    \ software\nplatforms. The hardware devices wiring approach used by Node-RED is\
    \ ﬂow programming which will\neven enable a new IoT user to participate in the\
    \ awareness of IoT in other ﬁelds. Chris Simpkin et al. [14]\nproposed mechanism\
    \ to run workﬂows like Node-Red on Edge networks, for this purpose they\ninvestigated\
    \ to ﬁnd out means of migration of Node-RED into a distributed execution environment.\n\
    The demonstration in this work shows the feasibility of such approaches, trafﬁc\
    \ congestion detection\nworkﬂow based on Node-RED is migrated into a decentralized\
    \ execution environment.\nAmong the notable contribution in open-source toolkits\
    \ for creating mainboard is Microsoft .NET\nGadgeteer [15], which use the combination\
    \ of small electronic block approach for mainboard creation.\nThis open-source\
    \ toolkit enables users to create electronic devices based on their own customization\n\
    needs; all they need is to combine small electronic blocks on circuitry for the\
    \ creation of the mainboard.\nA processor has embedded into the mainboard of Microsoft\
    \ .NET Gadgeteer. Lucio Tommaso De Paolis\net al. used an open-source platform\
    \ called Thingsboard for sensors data collection and analytics[16].\nThingboard\
    \ provides mechanisms for data collection, processing the data, providing analytics\
    \ based on\nrule engine. The visualization module is embedded with more than 30\
    \ widgets to visualize a complete\nIoT smart space.\nAmong the notable projects\
    \ from Kickstarter [17] is SAM [18]. SAM does not need any expertise\nin the ﬁeld\
    \ and can be exploited equally by new users as well as expert developers. The\
    \ approach\nused is combining electronics modules blocks, all these modules are\
    \ wireless, which is a cornerstone\nfor innovation, creation, and designs. The\
    \ mechanism followed by SAM is using the internet with a\ncombination of hardware\
    \ and software to a project. The programming language used for SAM toolkit\nis\
    \ the python.\nMazzei et al. [19] further investigate how customizability will\
    \ enable general mass involvement in\nthe creation of such products that can contribute\
    \ to the IoT ecosystem. In literature, some other studies\nused the same idea;\
    \ In the case of Feki et al. research study [20], DIY approach is considered among\n\
    the most trending approach in the future for the development in the IoT ﬁeld.\
    \ Low-cost Systems on\nChip (SoC) based IoT development following the DIY approach\
    \ is proposed by the research study of\nScott and Chin [21].\nSustainability 2019,\
    \ 11, 5849\n4 of 24\nKefalakis et al. [22] presented an OpenIoT project based\
    \ on the visual development paradigm.\nThese tools are visual development based\
    \ Integrated Development Environment (IDE) for the\ndevelopment of IoT application\
    \ and manage its life cycle. A minimal programming approach is\nused in the development\
    \ of IoT applications based on semantic IoT architecture. Users model services\n\
    into graphs in a node-based user interface, which are then converted into SPARQL\
    \ queries.\nIoT applications development in the form of real-time data streams\
    \ is provided by an IoT platform\ncalled Super Stream Collider (SSC) [23]. This\
    \ platform will enable everyone from new IoT users to\nan expert to develop custom\
    \ IoT applications. SSC web-based interface enables users to develop\napplications\
    \ for various IoT scenarios by combining linked streams and data sources to IoT\
    \ resources.\nFor SSC support editor based SPARQL/CQELS query languages; the approach\
    \ used is simple drag\nand drop. The platform exploits cloud infrastructure for\
    \ massive data acquisition, processing, and\nspreading of the data.\nIoT is now\
    \ applicable in agriculture, how to bring innovations in agriculture using IoT\
    \ is studied\nin a ﬁeld called digital agriculture. Recently DIY approach based\
    \ IoT application was developed for\ndigital agriculture. Jayaraman et al. [24]\
    \ discuss such digital agriculture applications which will make\nnaive users monitor\
    \ the growth of the crop in a form, suggests and support the user with irrigation\n\
    decisions. They discuss a user interface called Phenonet, which is a zero-programming\
    \ based novel\nDIY architecture. The efﬁciency of this Open IoT platform is evaluated\
    \ through Phenonet and other\nseveral use cases.\nIn the examples of services\
    \ for data feeds collection, Pachube [25] is a notable web-centric service.\n\
    Pachube store information related to various sensors devices and the data feeds\
    \ provided by these\ndevices over some time. Pachube work on the idea of \"triggers,\
    \ it is capable of data integration,\nprocessing, and visualization. The data\
    \ arrival from hardware or software resources can be deﬁned\nas a trigger. The\
    \ response to such trigger is forwarding of the data to particular URL based on\
    \ rules\ndeﬁned by Pachube, triggering some other relevant triggers. Pachube increases\
    \ the creativity and\ndevelopment by provides a medium for sharing the feeds triggered\
    \ or integrated by one user can be\nused by another user.\nM. S. Khan et al. [26]\
    \ presents a novel CoAP protocol based on DIY architecture. This toolkit\ndesign\
    \ services based on CoAP proxy. The CoAP proxy Communication with the server device\
    \ is\ndone through CoAP proxy using socket connection. All the details are handled\
    \ by improved service\ncomposition toolkit. The toolkit visual interface enables\
    \ a beginner user to compose IoT services. User\nregisters and combines virtual\
    \ objects for physical devices through the drag and drops approach.\nShabir et\
    \ al. [27] present a DIY based service designer with a zero-programming experience.\n\
    Node-RED inspires the concept of the research study, the functionalities provided\
    \ by remote and CoAP\ndevices can be easily customized. Internet Engineering Task\
    \ Force (IETF) [28] has standardized CoAP\nis communication protocols for devices\
    \ having scarce resources. The CoAP server is implemented\nusing the Intel Edison\
    \ board. The platform was chosen due to growth in its acceptance day by day\n\
    in the DIY community all over the world. Visual service designers access the CoAP\
    \ resources via\nCoAP proxy shared by the CoAP server. The proxy implementation\
    \ is based on the Californium [29]\nframework in a programming language called\
    \ a Java. For storing the conﬁguration, they use a novel\napproach based on the\
    \ repository at the cloud. This cloud-based platform ensures the availability\
    \ of\nthese conﬁgurations everywhere. The HTTP protocol is used to handle communication\
    \ between real\ndevices and the DIY toolbox, whereas CoAP protocol is used to\
    \ handle communication between the\nDIY toolbox and cloud.\nIn literature, we\
    \ found some AI-based Intelligent solutions for service composition in the IoT\n\
    environment. Some AI algorithms are used for virtual object management and naming\
    \ these objects\nand automatic service composition. An example of this is A framework\
    \ for IoT objects based on IoT-IMS\nplatform where the naming and management of\
    \ objects are done intelligently [30]. An intelligent\nIoT-based project called\
    \ IoT.est is an effort to support the exchange of information among distributed\n\
    and different IoT nodes, by the use of semantic technologies. IoT service is created\
    \ using a testbed,\nSustainability 2019, 11, 5849\n5 of 24\nand several use cases\
    \ are used for validation purposes. IoT.est also not consider management and\n\
    scalability issues and only focus on the realization of IoT [31].\nTools which\
    \ are Platform-As-A-Service (PAAS), and it does not provide ease of use to new\
    \ users\nare also discussed in the literature. Some of the platforms discussed\
    \ by Vestergaard, L.S et al. [32] are\nDweet.IO [33], ThingWorx [34] and Particle.IO\
    \ [35]. Closed source is one of the disadvantages of such\nplatforms. Other well\
    \ known closed source IoT platforms are Google Cloud IoT [36] and AWS IoT\nplatform\
    \ [37]. To the best of our knowledge, the paradigm of these tools is either desktop-based\
    \ or\nweb-based. They say that if we can combine these paradigms and integrate\
    \ it into IoT applications,\nthen more ideal IoT applications can be developed.\
    \ We now present a summary of the well-known\narchitectures in Table 1. IoT platforms\
    \ are summarized based on features, i.e., devices management,\nintegration API’s,\
    \ open-source, support for Edge computing, data analytics and visualization.\n\
    Table 1. Summary of the existing work.\nIoT Software\nPlatforms\nDevice Managements\n\
    Integration\nEdge Computing\nOpen Source\nTypes of Analytics\nSupport for\nVisualization\n\
    AWS IoT\nplatform [37]\nYes\nREST API\nYes\nNo\nReal-time analytics (Rules\nEngine,\
    \ Amazon Kinesis,\nAWS Lambda)\nYes (AWS IoT\nDashboard)\nIBM IoT Foundation\n\
    Device Cloud [13]\nYes\nREST API\nYes\nNo\nReal-time analytics (IBM\nIoT Real-Time\
    \ Insights)\nYes (data\nanalysis and\nedge data\nanalysis)\nThingWorx - MDM\n\
    IoT Platform [34]\nYes\nREST API\nYes\nNo\nPredictive analytics\n(ThingWorx Machine\n\
    Learning), Real-time\nanalytics (ParStream DB)\nYes (ThingWorx\nSQUEAL)\nParticle.IO\
    \ [35]\nYes\nREST API\nYes\nNo\nYes (Rules Engine)\nYes (Particle\nDashboard)\n\
    ThingsBoard [16]\nYes\nMQTT API\nCoAP API\nHTTP API\nNo (planning in future)\n\
    Yes\nYes (Rules Engine)\nYes (30+\nWidgets)\nGoogle Cloud IoT [36]\nYes\nCloud\
    \ IoT API\nYes\nNo\nYes(BigQuery)\nYes (Google\nData Studio)\nMicrosoft .NET Gadgeteer\
    \ [15]\nYes\nGadgeteer SDK\nNo\nYes\nNo\nYes\n3. Methods\nIn this section, we\
    \ discuss the proposed methodology of Task allocation for thermal comfort in\n\
    smart homes. The proposed methodology consists of several steps. Users use the\
    \ DIY application to\nadd the services they need. For instance, we add thermal\
    \ comfort service name and its requirements\nin detail as a case study for this\
    \ work. The description is analyzed by the IoT server through natural\nlanguage\
    \ processing libraries to split it into microservices. Microservices description\
    \ is analyzed by\nthe microservice analyzer component for generating input tasks.\
    \ Physical things are virtualized into\nvirtual objects through virtualization\
    \ mechanism provided by Virtual Device Manager(VDM), VO-Task\nMapping Manager\
    \ (TMM) mappes relevant tasks to relevant virtual objects. TMM loads tasks and\n\
    virtual objects to the mapping window and visualizes it through Graphical shapes.\
    \ User maps a task\non a virtual object based on the suggestions; A line is dropped\
    \ from tasks to virtual objects to establish\na connection. A mapping window generates\
    \ mapping pairs of tasks and virtual objects based on\nthese connections.\nSome\
    \ of these tasks and virtual objects pairs are more important than others and\
    \ should be\nexecuted ﬁrst than the others. The reordering of these pairs is done\
    \ by VO-Task Scheduling Manager\n(TSM). TSM has a scheduler component that receives\
    \ the mapping pairs from TMM and reorders the\nmapping pairs through scheduling\
    \ algorithms of the TSM. Task Allocation Manager( TAM) handles\nscheduling results\
    \ and allocate tasks into physical device based on the virtual object information\
    \ in\nthe scheduling results, i.e., id and URI of the virtual object, which virtualizes\
    \ a physical device. TAM\npasses the allocated time, device address and task message\
    \ to deployer, which ﬁnally deploys the task\non a physical device at the allocated\
    \ time. Figure 1 represents the proposed methodology.\nGood IoT architecture can\
    \ help develop a robust and scalable IoT solution. In this paper, we\npropose\
    \ a ﬁve-layered architecture for the design of IoT applications based on tasks\
    \ composition\nand virtual objects mechanisms. The proposed architecture is given\
    \ in Figure 2. Each Layer has its\nSustainability 2019, 11, 5849\n6 of 24\nfunctionality;\
    \ the functional goal of all layers is to allocate tasks on virtual objects in\
    \ an IoT environment\nefﬁciently. Physical things Layer composed of physical devices,\
    \ these devices can be actuators and\nsensors. Examples of actuators can be categorized\
    \ to pneumatic actuators, hydraulic actuators, electric\nactuators, and thermal\
    \ actuators, fan and LEDs are examples of actuators in IoT smart space. Examples\n\
    of sensors are a pressure sensor, humidity, proximity sensors, smoke sensors,\
    \ gas and smoke sensors,\nIR and temperature sensors.\nAnalyze Thermal \nComfort\
    \ Service \nDescription\nThermal \nComfort\nDevice \nInformation\nInput Task \n\
    Admission\nVirtual Object Generation\nTasks \nDatabase\nVirtual \nobject \nDatabase\n\
    Mapping \nDatabase\nScheduling \nDatabase\nAllocation \nDatabase\nVO-Task Mapping\n\
    VO-Task Scheduling\nTasks Allocation\nDIY \nInterface\nAdd\nUsers\nInteract using\n\
    Figure 1. IoT Platform based on Tasks Allocation for Implementing Thermal Comfort\
    \ System.\nThe Virtual Objects Layer represents the virtualization of physical\
    \ layer things; these physical\ndevices are virtualized into virtual objects.\
    \ VDM manages these virtual objects; virtual objects\nmanagement includes the\
    \ registration of physical devices to IoT server registry, Creation of virtual\n\
    for the physical device and connectivity of physical devices to virtual objects.\
    \ These virtual objects\nare visualized through sensors and actuators icons on\
    \ Google map. Each marker icon represents a\nvirtual object in the interactive\
    \ map environment; the marker is placed on the latitude and longitude\nof physical\
    \ device location on the building or other places where the device is physically\
    \ deployed.\nEach virtual object performs speciﬁc actions and having certain properties\
    \ representing attributes of\nthe physical device.\nThe Micros service layer is\
    \ responsible for analyzing the description of services and splitting\nthese services\
    \ into functional units based on the analysis results. A group of virtual objects\
    \ provides\nsome of these services and hence, this layer performs the role of\
    \ interconnection between Virtual\nobjects. The microservice composition manager(MSCM)\
    \ module is responsible for the management\nof this layer. MSCM is responsible\
    \ for providing the user interface for services composition, services\nanalysis,\
    \ and microservice generations. MSCM uses two approaches for Micro Services composition,\n\
    the ﬁrst approach compose microservices directly from its associated sensors and\
    \ actuators. The other\nSustainability 2019, 11, 5849\n7 of 24\napproach for microservice\
    \ composition uses logical objects such as proxy server and fuzzy system\nbetween\
    \ sensors and actuators virtual objects.\nThe tasks layer is responsible for the\
    \ composition of tasks from the microservices; this layer\nmanages intuitive and\
    \ easy to use interface for task composition based on the microservices description.\n\
    The architecture utilizes the IntelliSense approach to output Intellisense dialogues\
    \ with tasks and\nmicro services suggestions generated from service at the time\
    \ of service orchestration.\nPhysical things\nProcesses\nProcesses\nVirtual objects\n\
    Vo 1\nVo 2\nVo 5\nVo 6\nvo n\nVo 3\nVo 4\nVirtual objects\nVo 1\nVo 2\nVo 5\n\
    Vo 6\nvo n\nVo 3\nVo 4\nTasks\ntask 1\ntask 4\ntask n\ntask 3\ntask 2\nTasks\n\
    task 1\ntask 4\ntask n\ntask 3\ntask 2\nMicro Services\nms 1\nms 2\nms 3\nms 4\n\
    ms n\nms 5\nThing\nThing\nThing\nThing\nThing\nThing n\nProcess 1\nProcess 2\n\
    Process 4\nProcess n\nProcess 3\nFigure 2. Task Composition Architecture based\
    \ on Virtual Objects in IoT Environment.\nOnce tasks are composed in the tasks\
    \ layers, these tasks are utilized by process layers for further\noperation on\
    \ these tasks. The process layer is responsible for the visual environment where\
    \ tasks can\nbe mapped on virtual objects. Task Mapping is done manually through\
    \ a drag and drop approach.\nThese mapped task results are utilized by a process\
    \ created for task scheduling. The scheduling process\nconsiders task attributes\
    \ and scheduling algorithms to generate scheduling results. A process is created\n\
    for task allocation, which handles scheduling results and allocates tasks to the\
    \ physical device in the\navailable time slot; ﬁnally, tasks are deployed on the\
    \ physical devices.\n4. Design\nIn this section, we discuss the design of the\
    \ proposed system developed on the Task Composition\nArchitecture based on Virtual\
    \ Objects in IoT Environment. We discuss the processes of the platform\non top\
    \ of which thermal comfort mechanism is implemented. The ﬁrst process is the analysis\
    \ of\nthermal comfort servic to generate tasks. Task Generation Manager (TGM)\
    \ component of the system is\nresponsible for the initialization of TGM components\
    \ for Services analysis to generate tasks, the design\nof task generation from\
    \ microservices is given in Figure 3. Natural Language Processing techniques,\n\
    i.e., tokenization, stemming, and lemmatization, are used to generate tasks from\
    \ the description of the\nmicroservices.The Part of Speech (POS) tagging technique\
    \ is used to detect the verb, which helps in\ndeciding the type of the task. Once\
    \ tasks are produced from the microservice description, the Task\nmanager is also\
    \ responsible for the interface for displaying the generated tasks proﬁle on the\
    \ form and\nﬁlling out the form’s visual components.\nTask Manager’s other responsibility\
    \ is extracting the conﬁguration proﬁle from both the\ninformation generated autonomously\
    \ through NLP algorithms and from the form information ﬁlled by\nthe user. The\
    \ parsed proﬁle is converted to task data and stored in the task repository. The\
    \ generated\nSustainability 2019, 11, 5849\n8 of 24\ntask data is passed to TMM,\
    \ where it is loaded into a visual interface used for task mapping on\nvirtual\
    \ objects.\nMicro Service 2\nMicro Service n\nMicro Services\n……..\nEnd\nMicro\
    \ Service \nanalyzer\nTask Repository\n7.Passes tasks data to TMM\n6. Persist\
    \ Task data \nFetch Tasks \nData\nTask Generation Manager (TGM) \nService \nanalyzer\n\
    1.Initialize TGM components\n2. split services \nto functional units\n4. generate\
    \  tokens\nExtract  Configuration\nProfile\nParse Profile\nTask working Data\n\
    5. convert data to tasks\n Task mapping \nManager\n3. analyze micro services\n\
    start\nstart\nFigure 3. Task Generation from Services.\nThe second process is\
    \ the virtualization of physical resources.\nVDM is the main module\nresponsible\
    \ for it to form virtual objects (VO). The virtualization process is also visualized\
    \ through\nvisual components by this module. VDM responsibilities include analyzing\
    \ the supported protocols\non the devices, e.g., CoAP and metadata. VDM also analyzes\
    \ supported methods and platforms that\nprovide the interface for adding, deletion\
    \ and updating of the virtual objects. The virtual object is a\nsimulation of\
    \ the physical device at the virtual IoT smart space. These virtual objects contains\
    \ all the\nattributes of the physical device with some extra attributes particular\
    \ for the virtual IoT environment.\nThese virtual objects also simulate the behaviour\
    \ of the physical device. Figure 4 represents the design\nof the Device virtualization\
    \ mechanism.\nThe third process is the association of tasks with virtual objects\
    \ called task mapping in recent\nstudies [8]. Task Mapping Manager(TMM) is the\
    \ design component responsible for the mapping\nmechanism. Task Mapping Conﬁguration\
    \ Flow is shown in the Figure 5. TMM initializes the graphical\nuser interface\
    \ and libraries needed for the mapping mechanism. The mapping mechanism is drag\n\
    and drop achieved through mapping libraries. TMM is connected to both task and\
    \ virtual objects\nrepository. TMM fetches all virtual objects, tasks, and stores\
    \ it in lists in the main memory. Task and\nvirtual object proﬁles are extracted\
    \ and fed into the mapper submodule of TMM. The user uses a drag\nand drop approach\
    \ to select a task and map it on the relevant virtual object by dropping a line\
    \ from\nthe task to a virtual object. TMM visualize the connection between tasks\
    \ and virtual objects using a\ngraphical line from task to a virtual object. TMM\
    \ saves the connections between virtual objects and\ntasks to a database repository.\n\
    Sustainability 2019, 11, 5849\n9 of 24\nVirtual \nDevice \nManager\nDevice \n\
    Metadata\nFetch  meta \ndata\nDelete\nAdd\nUpdate\nVirtual Object\nVirtual Object\n\
    Virtual Object\nVirtual Object\nVirtual Object\nVirtual Object\nVO Repository\n\
    Visualization \non Map\nVDM \nInterface\nadd  \nVO’s\ndelete \nVO’s\nupdate \n\
    VO’s\nvisualize using map \nmarker\nStore device \nprofile\nSupported \nProtocol\n\
    Supported \nPlatform\nMethods\nAnalyze supported \nplatforms\nAnalyze supported\
    \ methods\nAnalyze supported protocols\nFigure 4. Virtualization of Things.\n\
    Task Mapping Manager\nInitialize UI \ncomponents\n1.Initialize UI\nMapping libraries\n\
    2.Initialize libraries\n Virtual objects   \nRepository\n3. Connect to\n VO’s\
    \ repository\nTask Repository\n4.Connect to \nTask repository\nTasks list\n5.\
    \ Extracts tasks \nTasks Profile\n5.1 .Extracts task profile\nVirtual object list\n\
    4.Extracts available VO’s\nMapper\nVo and tasks \nconnections\nSave connections\n\
    Persist into mapping \nrepository\n6. establish connection \n7.save connection\
    \ locally\n8.Sync mapping results\nVirtual object info\n4.1 .Extracts VO info\n\
    Figure 5. Task mapping Conﬁguration Flow.\nSustainability 2019, 11, 5849\n10 of\
    \ 24\nThe fourth process is the scheduling of the mapped pair in time.\nScheduling\
    \ Manager is\nresponsible for scheduling the Mapping Results on the physical devices.\
    \ The Scheduling Manager\nmanages the whole ﬂow of the information in the scheduling\
    \ window. Scheduling Manager is\nconnected to Task Mapping Repository, Virtual\
    \ Object Repository, and Task Repository.\nScheduling Manager ﬁrst initializes\
    \ the Scheduling window graphical user interface.\nTask mapping results are then\
    \ fetched from task Mapping repository. Task mapping results contain the\nID of\
    \ a task, and a virtual object, based on these ID’s tasks and virtual objects\
    \ are fetched from their\nrepositories. The design of the scheduling conﬁguration\
    \ is given in Figure 6. Once tasks and virtual\nobjects are loaded next step is\
    \ the ordering of the tasks, the primary purpose of task scheduling is a\nreordering\
    \ of tasks for task allocation in IoT application.\nScheduler module fetches virtual\
    \ object information and task proﬁle and creates a scheduling\nprocess using the\
    \ scheduling algorithm. The scheduling process outputs the scheduling order, which\
    \ is\nreordering of the mapping pairs. Scheduling Manager saves these results\
    \ into the scheduling repository\nin the pairs format task id, virtual object\
    \ id, scheduled time. Task Allocation Manager utilizes these\nscheduling results\
    \ for the allocation of tasks on the physical devices connected to the virtual\
    \ objects.\nScheduling Manager\nInitialize UI components\n1.Initialize UI components\n\
    Task mapping repository\n2.connect to TMM repository\n Virtual objects   \nRepository\n\
    3.1.load VO’s info\nTask Repository\n3.2.load task profiles\nTasks list\n3.4.\
    \ Extracts tasks list\nTasks Profile\n3.5.Extracts task profile\nVirtual object\
    \ info\n3.3.Extracts information\nScheduler\nCreate process \nrepresentation\n\
    Scheduling \nalgorithm\nScheduling order\nSave ordering\nScheduling \nrepository\n\
    4.initialize process\n5.apply algorithm\n6.results\n7.save scheduling results\
    \ locally\n8.sync scheduling results\nFigure 6. Scheduling conﬁguration Flow.\n\
    5. Implementation and Results\nIn this research, we developed two DIY based applications\
    \ on the proposed architecture. One\napplication is desktop-based developed in\
    \ .NET technology; the other is web-based developed in\npython. Each of the application\
    \ projects has two main components, one is the IoT server and the\nother the DIY\
    \ toolbox, Table 2 explains the IoT server technology stack, whereas Table 3 explains\
    \ the\ntechnology stack of the DIY toolbox. The IoT server is installed on Raspberry\
    \ PI, all physical resources,\ni.e., sensors and actuators, are connected with\
    \ the IoT server. Arduino is used for the support of\nsensors, i.e., MQ-2 sensor.\
    \ A registry is maintained of the devices with its current status, the status\
    \ of\nthe device can be connected, disconnected, available or busy. The implementation\
    \ at the server side is\ndone through the Python programming language.\nSustainability\
    \ 2019, 11, 5849\n11 of 24\nTable 2. IoT server’s Tech stack.\nComponent\nDescription\n\
    Operating System\nFedora\nHardware\nRaspberry PI, Arduino\nMemory\n1 GB\nServer\n\
    Flask Webserver\nResources\nsensors and actuators\nProgramming language\nPython\n\
    Integrated Development Environment\nVim\nFlask, which is a python based framework\
    \ popular due to the fact that it is widely used in the\nindustry and acceptable\
    \ to the developers because it is a Model View Controller (MVC) paradigm.\nFor\
    \ the experimental purpose of this study, different physical resources such as\
    \ actuators and sensors\nare used. Examples of actuators used are LEDs and fans,\
    \ whereas among the sensors used are a hybrid\nsensor called BME 280, at which\
    \ three sensors are embedded, i.e., temperature, pressure, and humidity\nsensors.\
    \ Other sensors used as physical resources are particulate matter (PM2.5 and PM10)\
    \ and Gas\nsensor Co2.\nFlask server-side application is responsible for the registration\
    \ of these physical resources. This\nserver-side application identiﬁes each physical\
    \ resource by a unique identiﬁer called URI for every\nresource. To request these\
    \ remote resources applications such as our DIY toolbox is accessed through\n\
    these URI by sending an HTTP request to the IoT server, the server give an HTTP\
    \ response containing\nJSON object which is then parsed by the DIY Toolbox.\n\
    Table 3. DIY based Task and Virtual Objects Composition toolbox Tech stack.\n\
    Component\nDescription\nOperating System\nWindows 10, 64 bits\nCPU\nIntel i3-2120\
    \ CPU @3.30 GHz(4 CPUs)\nMemory\n16 Gigabyte\nProgramming Language\nC Sharp, Python\n\
    IDE\nVisual Studio 2019, Community Version\nLibraries\nMind Fusion Diagraming,\
    \ GMap, MySQL, Ribbon, Json.NET\nPersistence\nJson ﬁles in synch with cloud SQL\
    \ for MySQL\nThe toolbox provides the graphical user interface to IoT application\
    \ users where they can virtualize\nthe physical resources connected to their IT\
    \ smart space. Based on the services needed by the users,\ntasks are composed\
    \ through DIY application and ﬂask server. These tasks are mapped to virtual\n\
    objects based on the mapping mechanism explained in the design section. The DIY\
    \ toolbox allocates\ntasks on physical resources based on task scheduling results.\
    \ The DIY toolbox provides all these\nfunctionalities through simple dragging\
    \ and dropping approach. In the future, we will focus on\ndeveloping intelligence\
    \ to the toolbox for making the IntelliSense and suggestions to users more\nefﬁciently.\
    \ For the ease of the user, we will use natural language processing algorithms\
    \ such as the one\nused by the Alexa application.\nFigure 7 represents the structure\
    \ of the DIY applications developed for the evaluation of the\narchitecture client\
    \ application in C Sharp which executes over the common language runtime, and\
    \ the\nweb-based DIY application runs on python. The IoT server has handlers for\
    \ HTTP requests from the\nDIY toolbox and provides an HTTP response containing\
    \ JSON objects to the toolbox. The IoT server\nprovides VDM component of the toolbox\
    \ requests for virtualization of a physical device and devices\ninformation. The\
    \ response for virtualization requests contains device metadata and other attributes\
    \ of\na physical device. Requests containing the analysis of services of the IoT\
    \ environment are handled by\nthe service conﬁguration manager(SCM) a module developed\
    \ in python at the IoT server. The requests\nare parsed by the request parser\
    \ and responses are generated by the response manger.\nSustainability 2019, 11,\
    \ 5849\n12 of 24\nOS(Windows)\n.NET Framework\nPython, C sharp\nCloud SQL for\
    \ \nMySQL\nCloud based IoT server\nHttp client\nVDM\nResponse \nmanager\nSCM\n\
    MySQL \nsync\nRequest \nparser\nRequest \nmanager\nApplication Client\nTask \n\
    Mapping\nTask \nDeployment\nTask \nScheduling\nApplication Client\nTask \nMapping\n\
    Task \nDeployment\nTask \nScheduling\nFigure 7. Task and Composition DIY toolbox\
    \ layered architecture Structure.\n5.1. Execution Flow\nFirst, the services added\
    \ for thermal comfort monitoring is analyzed and microservices are\ngenerated.\
    \ IoT resources are available to the users through IoT services. The user adds\
    \ services\nthrough the DIY application; Microservices are generated autonomously\
    \ from services description.\nNatural Language Processing POS technique is used\
    \ to identify conjunction in the description of the\nservice and the Bigram model\
    \ is used for Semantic Analysis. Python’s NLTK library is used for the\ntokenization\
    \ and POS tagging. For the Bigram model python, ngram library is used. Figure\
    \ 8 represent\nthe implementation results of services and microservices. Section\
    \ (a) of Figure 8 visualize the services\ncomposed manually by the user through\
    \ the DIY application Interface. Section (b) of Figure 8 shows\nthe microservices\
    \ results generated based on the description of the service through Natural Language\n\
    Processing techniques.\nEach service and microservices having a context menu which\
    \ can be open by right-clicking\non the service or microservice. The context menu\
    \ contains a command for creating new services.\nDelete command can be used to\
    \ delete a service or microservice, and View command can be used to\ndisplay a\
    \ property window where description and various attributes of services and microservices\
    \ are\nvisualized through graphical user interface. A service named ‘Monitoring\
    \ Thermal comfort’ are used\nto generate two microservices, namely, Monitoring\
    \ Thermal comfort results and analysis of Thermal\ncomfort conditions. For better\
    \ visualization, if the microservice title is long, a short title is generated\n\
    by abbreviating the verb tokens.\nSustainability 2019, 11, 5849\n13 of 24\n(a)\
    \ Services\n(b) Micro Services\nFigure 8. Service and Micro Services Generation.\n\
    Once microservices are generated, they are analyzed to generate tasks. Task generation\
    \ from\nmicroservices is visualized in the Figure 9.\nThe ﬁgure shows task suggestions\
    \ based on the\nmicroservices description analysis by the DIY Application. Users\
    \ can either ignore the task suggestions\nby clicking the cancel command button\
    \ or utilizing the suggestion by pressing the Add Task command\nbutton. The task\
    \ information is then used by the Task Manager module to ﬁll the window form for\n\
    adding a task proﬁle. The user ﬁlls the rest of the information or modiﬁes the\
    \ task title, and then\nsaves the task by clicking the add command button. If\
    \ the user wants to cancel the task proﬁle adding\noperation, the user has to\
    \ click the close command button.\nFigure 9. Task Generation from Services.\n\
    The task proﬁle is then added to the local database table developed in MySQL in\
    \ our case, but any\ndatabase server can be used. The task proﬁle is ﬁnally added\
    \ to the cloud-based MySQL database. Each\ntask is fed to the Task Mapping Manager\
    \ which is responsible for visualization in the mapping window.\nSustainability\
    \ 2019, 11, 5849\n14 of 24\nEach task is having a context menu, from which various\
    \ operations on the task can be performed.\nTasks can be added, deleted and previewed\
    \ in the graphical user interface of the DIY Application.\nThe next process is\
    \ device virtualization. As already discussed in the design section, VDM is the\n\
    main module responsible for the whole virtualization process of physical things\
    \ into Virtual objects.\nThe device virtualization process is also visualized\
    \ through an interactive map environment based\non the GMAP.NET library. A Virtual\
    \ object is represented through a map marker using a visual icon\nof the physical\
    \ thing. For example, Figure 10a represents the Interactive map with three physical\n\
    things virtualized. Two temperature sensors are visualized through a temperature\
    \ icon image. LED\nActuator is visualized through Red LED icon image. Each virtual\
    \ object is having an options window\nfrom where properties of the virtual object\
    \ can be previewed. Figure 10b is showing the options\nmenu which contains commands\
    \ button for opening windows of task mapping, task scheduling, task\nallocation,\
    \ and Task deployment. Each of these windows contains mapping, scheduling, allocation,\n\
    and deployment modules.\nPhysical things which are registered and currently connected\
    \ to IoT server are visualized on the\nmap at a location based on latitude and\
    \ longitude address of the physical device. The virtual objects\nconﬁguration\
    \ is stored in the form of JSON docs temporarily which is then stored to MySQL\
    \ database\nat a local server and ﬁnally synced to the cloud-based MySQL database.\n\
    (a) Map with Virtual objects\n(b) Virtual objects option Menu\nFigure 10. Device\
    \ Virtualization and Visualization on Map.\nAfter the virtualization of physical\
    \ things and Task generation, the next step is the mapping\nmechanism. The Mapping\
    \ mechanism from the implementation perspective is presented in Figure 11.\nThe\
    \ virtualization module extracts all the available virtual objects from the virtual\
    \ objects repository\nand feeds the virtual objects to the mapping module. The\
    \ task manager extracts the candidate tasks\nfrom the task repository and feeds\
    \ them to the mapping module. In the ﬁgure, Virtual objects are\nvisualized at\
    \ the left side of the mapping window as rounded cornered rectangles, whereas\
    \ tasks are\nvisualized at the right side of the mapping window as circle shapes.\
    \ A window interface utilizing\nMind Fusion diagramming library enables the user\
    \ to do a simple drag and drop operation of mapping.\nA line is dragged from the\
    \ task and dropped at the virtual object establishing a connection between\nthe\
    \ virtual object and task. Once the connection is made, the Generated Mapping\
    \ results are saved\ninto it the mapping repository. Mapping repository is a relational\
    \ table of MySQL database at the local\nserver and cloud MySQL. One mapping connection\
    \ is stored as one record of the mapping repository\ntable at the MySQL database.\
    \ The mapper repository stores the id of participating tasks and the id of\nvirtual\
    \ objects and the mapping time as a single row. In the ﬁgure ‘Mapped Task’ relational\
    \ table is the\nrepository where the results of the mapped tasks are stored.\n\
    Sustainability 2019, 11, 5849\n15 of 24\nVirtual \nDevice \nManager\nVirtual \n\
    Object \nRepository\n1\nTasks \nRepository\nTask \nManager\n3\n2\n4\nFigure 11.\
    \ Task mapping from Implementation Perspective.\nAfter task mapping, the next\
    \ step is task scheduling. As discussed earlier, mapping results are\npairs of\
    \ tasks and virtual objects, i.e., { task id, vo id, mapped time }. In the context\
    \ of this research\nstudy, Task scheduling is referred to the ordering of these\
    \ mapping pairs to minimize the network\nlatency. So Task scheduling changes the\
    \ order of mapping pairs such that more important tasks are\nallocated on the\
    \ devices ﬁrst, the importance of tasks is calculated from various task attributes\
    \ through\nscheduling algorithms. We used the concept of traditional scheduling\
    \ algorithms for the ordering of\nthe tasks. The scheduling window is embedded\
    \ with these algorithms and user select algorithms for\nthe ordering of tasks.\
    \ The ordered tasks are visualized through table and grant chart. Table 4 lists\
    \ task\nattributes considered by the scheduler for reordering the tasks.\nTable\
    \ 4. Task attributes important for task Scheduling.\nComponent\nDescription\n\
    ID\nIdentiﬁer of a the task\nPeriod\nThe period for which the task is assigned\
    \ to the physical device\nVO ID\nID of virtual device to which task is mapped\n\
    Deadline\nDeadline of the task\nArrival\nArrival of the task\nPriority\nPriority\
    \ of the tasks in numbers\nExecution\nThe execution period the task\nFigure 12\
    \ represents the task scheduling mechanism from an implementation perspective.\
    \ Task\nscheduling algorithms are used to produce optimal task orders based on\
    \ the attributes of mapped tasks.\nAlgorithms we considered for scheduling are\
    \ First Come, First served (FCFS), Shortest Task Execution\nFirst (STEF), Shortest\
    \ Task deadline Time (STDT), highest Priority Task First(HPTF) and priority-based\n\
    round-robin. The scheduling manager is responsible for fetching the task and virtual\
    \ object proﬁles.\nIt also fetches mapping results of these tasks from the mapping\
    \ module. The interface provided by\nscheduling manger is used to choose an algorithm\
    \ and preview the scheduling results on the table\nand grant chart. Scheduling\
    \ algorithms consider an attribute or group of attributes mentioned in\nTable\
    \ 3. For example, FCFS considers only the arrival attribute, whereas STDT considers\
    \ the deadline\nattribute only. Human inspection on the scheduling results is\
    \ currently necessary. In the future, we are\nconsidering an autonomous intelligent\
    \ approach for task scheduling. Task scheduling manager saves\nthe generated results\
    \ into local and cloud-based MySQL repository. The scheduling results are stored\n\
    in the scheduling repository, which is fed into the task allocation manager for\
    \ allocation of the tasks on\nphysical devices.\nSustainability 2019, 11, 5849\n\
    16 of 24\nScheduling \nManager\nTask \nmapping \nRepository\n1\n3\nScheduling\
    \ \nAglorithms\n2\nFigure 12. Task scheduling from the Implementation Perspective.\n\
    5.2. Execution of Tasks Allocation of Thermal Comfort System\nOnce all the processes\
    \ is done by the platform, the actuall deployment happens which is the\nreal running\
    \ of the service on IoT devices installed in smart homes. The task allocation\
    \ manager is\nresponsible for the allocation of the task to correct physical devices\
    \ based on the scheduling pairs.\nThe physical device is accessed through the\
    \ URI attribute of the virtual object. As discussed earlier,\nthe Raspberry PI\
    \ based IoT server keeps track of all the devices by maintaining the registry\
    \ of the\nconnected devices. URI contains a device model and encoded Message,\
    \ e.g., getTemp. This Message is\nparsed and decoded by the IoT server to allocate\
    \ the task on the physical device. Figure 13 shows the\nimplementation of the\
    \ task allocation mechanism.\nTask \nAllocation \nManager\nScheduling \nRepository\n\
    1\n2\n`\nFigure 13. Task allocation from Implementation Perspective.\nThe allocation\
    \ results are stored into the allocation repository, storing the allocation results\
    \ is\nhelpful for the deployment manager for the deployment of tasks on the physical\
    \ devices. The repository\ncontains information at the format of task, physical\
    \ device, allocated time, a background service is\nSustainability 2019, 11, 5849\n\
    17 of 24\nmanaged by the deployment manager to check the allocation repository\
    \ continuously and deploy the\ntasks on the physical devices at the allocated\
    \ time.\n5.3. Maintaining Thermal Comfort in Smart Homes: From Service Analysis\
    \ to Tasks Allocation\nIn this section, a brief overview of maintaining Thermal\
    \ Comfort in IoT smart space is presented\nwhich summarized the use of the platform\
    \ and the accomplishment of service goal. The IoT smart\nspace in this case study\
    \ is the Mobile Computing lab, at Jeju National University. The example case\n\
    study has been illustrated in the light of the proposed architecture, signifying\
    \ the strengths of the\nproposed architecture. Table 5 describes the case study\
    \ at service, microservice and task levels. Service\n1 in the case study for the\
    \ Thermal Comfort detection and Notiﬁcation. This service is analyzed from\nits\
    \ description to split the service into functional units called microservices.\n\
    For Example, there are two microservices with Id’s 1.1 and 1.2 belonging to Service\
    \ ID 1. There\nare six tasks in Microservice with Id 1.1 and 2 tasks in Microservice\
    \ with Id 1.2. For this case study,\nRaspberry PI is used as an IoT server and\
    \ a PC server for Data Staging between sensors and Cloud\nSQL based MySQL. Sensors\
    \ such as MQ-2 Gas is connected to Arduino ESP 8266 board because\nthese sensors\
    \ belong to analog sensors family and connecting to Raspberry PI would require\
    \ another\nhardware such as digital to analog which will add a further overhead\
    \ and cost on the overall system.\nThe resources we use are shown in the experimental\
    \ setup shown in Figure 14. From the Experimental\nsetup, it can be understood\
    \ that The PC Server is responsible for accumulating all the data from Http\n\
    client and IoT servers. All sensors are either connected to the Http client or\
    \ the IoT server installed\non Raspberry PI. The PC server syncs the data with\
    \ Cloud SQL for MySQL and deploys tasks on the\nphysical devices either through\
    \ the HTTP client or through the IoT server.\nNOVA Dust Sensor SDS011\n(PM 2.5,PM\
    \ 10)\nIoT Server\nPM2.5, PM 10\n<Temperature,Humidity,Pressure>\nHTTP Client\n\
    Gas Sensor CO2\nCO2\nData Staging (PC Server)\nRESTFul API\nArduino\n ESP 8266\
    \ board \nLighter\nCloud SQL for \nMySQL\nupload\nRaspberry PI\nRaspberry PI\n\
    download\nMQ-2 GAS \nSensor\nBME 280\n(Pressure, Temperature, \nHumidity)\nFigure\
    \ 14. Embedded Hardware for Implementation of Maintaining Thermal Comfort Case\
    \ Study.\nSustainability 2019, 11, 5849\n18 of 24\nTable 5. Service, Micro service\
    \ and Tasks Description of Maintaining Thermal Comfort Case Study.\nType\nService\n\
    ID\nService Name\nService Description\nService\n1\nMonitoring Thermal comfort\n\
    Monitoring results and analysis of thermal comfort conditions in experimental\
    \ buildings for different\nheating systems and ventilation regimes during heating\
    \ and cooling seasons different heating systems and\nventilation regimes\nService\n\
    Service\nID\nMicro\nService ID\nMicro Service\nName\nHost\nEdge\nType\nNumber\n\
    of Tasks\nMicro Service\n1\n1.1\nMonitoring\ncomfort results\nPC\nRaspberry\n\
    Urgent\n6\n1\n1.2\nanalysis of\nthermal comfort\nconditions\nPC\nRaspberry\nUrgent\n\
    2\nTasks\nMeta Data\nService\nID\nMicro\nService\nID\nTask ID\nTask Description\n\
    Type\nTask Title\nTargeted\nResource\nTasks\n1\n1.1\n1.1.1\nGet & send temp\n\
    data\nperiodic\nGet Temp data\nBME 280\nSensor\n1.1.2\nReceive temp data\nPeriodic\n\
    Receive Temp\ndata\nBME 280\nSensor\n1.1.3\nGet and send\nhum data\nPeriodic\n\
    Get hum data\nBME 280\nSensor\n1.1.4\nReceive Hum\ndata\nPeriodic\nReceive hum\
    \ data\nBME 280\nSensor\n1.1.5\nGet and Send\nCO2 data\nPeriodic\nGet Wind data\n\
    MQ-2 Gas\nSensor\n1.1.6\nReceive wind\ndata\nPeriodic\nReceive Wind data\nMQ-2\
    \ Gas\nSensor\nTasks\n1.2\n1.2.1\nDetect thermal comfort\nState based on temp,\n\
    & hum\nperiodic\nCompute Thermal\ncomfort intensity (TCI)\nIOT Server\n1.2.2\n\
    turn on fan, or turn\noff fan\nEvent-Driven\nPredict fan state based\non TCI\n\
    Actuator\n(Fan)\n6. Performance Analysis\nIn this section, we present the performance\
    \ analysis of the proposed architecture. The performance\nof the proposed architecture\
    \ is evaluated using a round-trip time (RTT), Response Time, Latency and\nTask\
    \ Dropping rate metrics. The RTT in our scenarios is the total time the system\
    \ takes from task\ngeneration till task execution and physical device response\
    \ back to the DIY application. The DIY\napplication developed based on the proposed\
    \ architecture maintain logs for each task from its\ngeneration until its execution.\
    \ A log contains information such as task id, target device, deployment\nstatus\
    \ and execution time. For Performance analysis, we calculated the RTT metric by\
    \ deploying tasks\nmentioned in Table 5 via the toolbox.\nDeployment is made based\
    \ on different task parameters, i.e., execution time, period, arrival time\nand\
    \ priority. We deployed these twelve tasks eight times and recorded the total\
    \ times each task took\nfrom task generation to task execution and response back\
    \ to the application. From 8 observations of\neach task, we then calculated min,\
    \ max and Average RTT, which is shown in Figure 15. The RTT is\nmeasured in milliseconds,\
    \ results show that the minimum RTT is 5 ms in the case of the event-driven\n\
    tasks, for example, task ‘Notify Via Alarm’ and task ‘Notify Via LED’. The maximum\
    \ RTT is observed\nfor a task is 92 ms which is also minimum and bearable delay\
    \ for the execution of task which needs\ninput data from other tasks for its complete\
    \ execution.\nThe average RTT for all the tasks executed is 27.75 ms which shows\
    \ that architecture strength for\nimplementing the architecture in real-time scenarios\
    \ such as ﬁre safety and road safety. We consider the\nRTT of Tasks load is the\
    \ second performance analysis metric. For the RTT of Task load, we simulated\n\
    60 tasks in the Apache JMeter load testing tool and analyzed the performance irrespective\
    \ of the load,\nRTT of the simulation results are in the order of a few seconds.\
    \ Figure 16 illustrates the simulation\nanalysis visually through the Line chart.\
    \ Various tasks load from 4 tasks to 60 tasks were taken for\nthe load testing\
    \ of the DIY Toolbox. RTT of tasks is directly proportional to the number of tasks,\
    \ i.e.,\nincreasing the number of task loads will increase the RTT, but the average\
    \ RTT increase is negligible.\nFor instance, for 30 tasks, the minimum RTT observed\
    \ is 22 ms, the maximum RTT for 30 tasks observed\nis 29 ms, and the average time\
    \ for 30 tasks is 24.909 ms. A case study of thermal comfort can be utilized\n\
    in 12 tasks. The architecture can be utilized for more complex case studies in\
    \ the IoT environment.\nSustainability 2019, 11, 5849\n19 of 24\nFigure 15. Round\
    \ Trip Time based Performance Analysis of the proposed Architecture.\nFigure 16.\
    \ Round Trip Time Analysis for different Task load.\nThe third metric on which\
    \ we evaluate the proposed architecture is the response time over time.\nFigure\
    \ 17 shows the response time over time analysis of both periodic sensing tasks\
    \ and event driven\ntasks.The response time is calculated in Milliseconds for\
    \ both periodic sensing tasks and event-driven\ntasks. The maximum and minimum\
    \ response time for a periodic sensing task is 28.6 ms and 15 ms.\nCompare to\
    \ periodic sensing tasks maximum and minimum response time for event-driven tasks\
    \ are\n18.8 ms and 5 ms. As discussed in earlier sections that the sensing tasks\
    \ sense ambient scenarios and\nbased on contextual data generated, irregular patterns\
    \ are predicted. Based on these prediction control\ntasks are activated, which\
    \ can be executed with a variety of actuators. Having said that, the control\n\
    tasks, which are event-driven tasks, are of the highest possible priority. The\
    \ experiments carried out in\nSustainability 2019, 11, 5849\n20 of 24\nthis section\
    \ afﬁrms that the proposed architecture always give more priority to event-driven\
    \ tasks, and\nthis can be witnessed by the lower response time in comparison with\
    \ sensing tasks.\n10\n12\n14\n16\n18\n20\n22\n24\n26\n28\n30\n48:37.0\n48:38.0\n\
    48:40.0\n48:41.0\n48:43.0\n48:44.0\n48:46.0\n48:47.0\n48:49.0\n48:51.0\n48:52.0\n\
    48:53.0\n48:55.0\n48:56.0\n48:58.0\n48:00.0\n49:01.0\n49:03.0\n49:04.0\n49:05.0\n\
    49:07.0\n49:09.0\n49:10.0\n49:12.0\n49:13.0\n49:14.0\n49:16.0\n49:17.0\n49:19.0\n\
    49:21.0\n49:22.0\n49:24.0\n49:25.0\n49:26.0\nResponse Time (ms)\nElapsed Time\n\
    Response Time over Time\nPeriodic Sensing Tasks\nEvent Driven Tasks\nFigure 17.\
    \ Response Time over Time.\nThe fourth metric we consider for the performance\
    \ evaluation is the stability of the architecture in\npeak load time. Task dropping\
    \ rate quantitatively accounts for the stability of the system. The lesser\nnumber\
    \ of tasks dropped in peak load time; the more stable will be the system. For\
    \ this, we carried\nout the task dropping analysis of the proposed architecture.\
    \ Figure 18 shows that as the number of\ninput tasks increases, task dropping\
    \ increases. The minimum task dropping rate is 0 for 26 tasks, and\nmaximum task\
    \ dropping rate is 14 for 600 tasks. It is evident from the rate of increase,\
    \ although the\nnumber of tasks increases but the rate of the dropping is very\
    \ steady. Even for 600 tasks, only 27 tasks\nare dropped, which in other words\
    \ implies that the performance of the system is 97.7%.\nFigure 18. Task Dropping\
    \ Rate.\nSustainability 2019, 11, 5849\n21 of 24\nFinally, we consider the latency\
    \ of tasks deployment; for this purpose, we simulated various sets\nof virtual\
    \ users in Locust, an open-source load testing tool, for cross-domain requests\
    \ from our Toolkit.\nFigure 19 shows the latency of tasks deployment in the simulated\
    \ environment. During testing, we\nprovided three sets of virtual users, 50 users,\
    \ 300 users and 1000 users. Minimum latency for 50, 300\nand 1000 users are 49\
    \ ms,71 ms, and 97 ms, respectively. Maximum latency of 50, 300 and 100 users\
    \ are\n358 ms, 455 ms and 830 ms, respectively. Finally, the average for 50, 300\
    \ and 1000 users are 238 ms,\n327 ms and 432 ms.\n50 Users, 238\n300 Users, 327\n\
    1000 Users, 432\n50 Users, 49\n300 Users, 71\n1000 Users, 97\n50 Users, 358\n\
    300 Users, 455\n1000 Users, 830\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n\
    50 Users\n300 Users\n1000 Users\nLatency (ms)\nMax\nMin\nAverage\nFigure 19. Task\
    \ Deployment Latency.\nComparison and Signiﬁcance\nTo the best of the authors’\
    \ knowledge, Task Composition Architecture based on Virtual Objects\nin IoT Environment\
    \ is the ﬁrst-ever attempt towards task allocations in the IoT environment using\
    \ a\nDIY approach. There are only a few user interfaces for IoT integration platforms\
    \ such as Node-RED,\nAWS IoT, NoFlo, ioBroker, CoAP prototype-based DIY interface\
    \ for service customization of Remote\nIoT devices. These user interfaces are\
    \ the only integration platform for the internet of things and\ndo not provide\
    \ any task level management. First and foremost, The DIY toolkit developed on\
    \ the\nproposed architecture is a complete solution addressing various aspects\
    \ of task allocation in the IoT\nenvironment. These aspects include device virtualization,\
    \ microservices generation from services, task\ngeneration from microservices,\
    \ task mapping to virtual objects, task scheduling and task allocation\nand deployment\
    \ on the physical device. Table 6 provides a comparison of the proposed toolkit\
    \ and the\nrelated IoT integration platforms.\nFor the comparative analysis, we\
    \ consider various parameters including, open-source, DIY\nsupport, Remote Access,\
    \ Conﬁguration repository, ofﬂine access, cloud support, application type,\ngeneric\
    \ entity support, and task level management. One of the goodness of the proposed\
    \ architecture\nis the loosely coupled nature of the modules, making it very easy\
    \ to maintain. The architecture is\nwell-suited for IoT applications that involve\
    \ multi-devices and multi-tasks. The proposed architecture\nis ﬂexible, which\
    \ means that different algorithms for mapping, scheduling and allocation could\
    \ be\nSustainability 2019, 11, 5849\n22 of 24\nintroduced without a major revamp\
    \ to the architecture. The freedom from hardware dependence,\ntask-level management\
    \ and DIY nature of the integration platform for the internet of things makes\
    \ our\nsolution a signiﬁcant, better and ideal solution towards the realization\
    \ of IoT network.\nTable 6. Comparative analysis of proposed Architecture with\
    \ state of art IoT platforms architectures.\nS.No\nName\nOpen\nSource\nDIY\nSupport\n\
    Remote\nAccess\nConﬁguration\nRepository\nOfﬂine\nAccess\nCloud\nSupport\nApplication\n\
    Type\nGeneric\nEntity\nSupport\nTask Level\nManagement\nProgramming\nLanguage\n\
    1\nDweet.IO [33]\nYes\nNo\nNo\nJSON\nNo\nNo\nMiddleware\nNo\nNo\nMulti\nlanguage\n\
    Support\n2\nParticle.IO [35]\nNo\nNo\nYes\nXML\nNo\nYes\nMiddleware\nYes\nNo\n\
    Java\n4\nGlue.thing [12]\nNo\nYes\nYes\nJSON\nNo\nNo\nWeb\nNo\nNo\nNode.js\n5\n\
    Node-red [13]\nYes\nPartial\nYes\nJSON\nNo\nNo\nweb\nNo\nNo\nNode.js\n6\nSuper\
    \ Stream\nCollider [23]\nNo\nPartial\nYes\nJSON/\nPLSQL\nNo\nNo\nWeb\nNo\nNo\n\
    JavaScript\n7\nSAM [18]\nNo\nPartial\nNo\nXML\nYes\nYes\nDesktop\nNo\nNo\nJavaScript/\n\
    Python\n8\nProposed\nSystem\nYes\nYes\nYes\nJSON\nYes\nYes\nDesktop/Web\nYes\n\
    Yes\nCsharp.NET/\nPython\n7. Conclusions\nIn this paper, we proposed a novel approach\
    \ towards the design and implementation of a task\ncomposition toolbox based on\
    \ virtual objects in the IoT environment. The proposed system allows\nthe user\
    \ to perform task allocation on both local and remote physical IoT devices. DIY\
    \ based toolbox\nis developed based on usability factors, the intuitive user interface\
    \ and zero coding approaches for\neffective task allocation and visualization\
    \ of all the modules processes make it a novel architecture. We\nhave made cloud\
    \ services available for data storage. The data from the local server is synced\
    \ and hence\nensures the data available to the user remotely. The DIY toolbox\
    \ also provides real-time visualization\nof the virtual objects and whole task\
    \ allocation process at remote IoT devices. In the future, we will add\nmachine\
    \ learning to automate task mapping to improve the capabilities of the composition\
    \ toolbox.\nTask scheduling can be improved by adding complex scheduling algorithms\
    \ for real-time scenarios,\nsuch as a Fair emergency ﬁrst. The proposed work can\
    \ also be improved by considering network\nlatencies and device paring for task\
    \ allocation autonomously. For the ease of the user, we will use\nnatural language\
    \ processing algorithms such as the one used by the Alexa application.\nAuthor\
    \ Contributions: I. conceived the idea for this paper, designed the experiments\
    \ and wrote the paper; S.A.\nassisted in experimental design. D.K. conceived the\
    \ overall idea of Design and Implementation of Thermal\nComfort System based on\
    \ Tasks Allocation Mechanism, and proof-read the manuscript.\nAcknowledgments:\
    \ This research was supported by the MSIT(Ministry of Science and ICT), Korea,\
    \ under the\nITRC(Information Technology Research Center) support program(IITP-2019-2014-1-00743)\
    \ supervised by the\nIITP(Institute for Information & communications Technology\
    \ Planning & Evaluation).), and this research was\nsupported by Institute for\
    \ Information & communications Technology Planning & Evaluation(IITP) grant funded\n\
    by the Korea government(MSIT) (No.2018-0-01456, AutoMaTa: Autonomous Management\
    \ framework based on\nartiﬁcial intelligent Technology for adaptive and disposable\
    \ IoT). Any correspondence related to this paper should\nbe addressed to Dohyeun\
    \ Kim.\nConﬂicts of Interest: The authors declare no conﬂict of interest.\nReferences\n\
    1.\nVermesan, O.; Friess, P.; Guillemin, P.; Gusmeroli, S.; Sundmaeker, H.; Bassi,\
    \ A.; Jubert, I.S.; Mazura, M.;\nHarrison, M.; Eisenhauer, M. Internet of things\
    \ strategic research roadmap. In A Internet of Things-Global390\nTechnological\
    \ and Societal Trends; PW: Delft, The Netherlands, 2011; Volume 1, pp. 9–52.\n\
    2.\nFriess, P. Internet of Things-Global Technological and Societal Trends from\
    \ Smart Environments and Spaces to Green\nICT; River Publishers: Delft, The Netherlands,\
    \ 2011.\nSustainability 2019, 11, 5849\n23 of 24\n3.\nStern, B.; Cooper, T. Getting\
    \ Started with Adafruit FLORA: Making Wearables with an Arduino-Compatible\nElectronics\
    \ Platform; Maker Media, Inc.: Sebastopol, CA, USA, 2015\n4.\nLouis, L. Working\
    \ Principle Of ARDUINO Aand Using It As A Tool For Study And Research . Int. J.\
    \ Control\nAutom. Commun. Syst. 2016, 1. . [CrossRef]\n5.\nTung, D.M.; Toan, N.V.;\
    \ Lee, J.-G. Exploring the current consumption of an Intel Edison module for IoT\n\
    applications. In Proceedings of the IEEE International Instrumentation and Measurement\
    \ Technology\nConference (I2MTC), Turin, Italy, 22–25 May 2017.\n6.\nChaudhar,\
    \ H. Raspberry Pi Technology: A Review. Int. J. Innov. Emerg. Res. Eng. 2015,\
    \ 2, 83–87.\n7.\nAtzori, L.; Iera, A.; Morabito, G. The internet of things: A\
    \ survey. Comput. Netw. 2010, 54, 2787–2805.\n[CrossRef]\n8.\nAhmad, S.; Mehmood,\
    \ F.; Kim, D.H. A DIY Approach for the Design of Mission-Planning Architecture\n\
    Using Autonomous Task—Object Mapping and the Deployment Model in Mission-Critical\
    \ IoT Systems.\nSustainability 2019, 13, 3647. [CrossRef]\n9.\nXia, F.; Yang,\
    \ L.T.; Wang, L.; Vinel, A. Internet of things. Int. J. Commun. Syst. 2012, 25,\
    \ 1101–1102. [CrossRef]\n10.\nO’Flynn, C. A Lightbulb Worm?. Details of the Philips\
    \ Hue Smart Lighting Design; White Paper; Black Hat USA:\nAlexandria, VA, USA,\
    \ 2016.\n11.\nLee, H.; Sin, D.; Park, E.; Hwang, I.; Hong, G.; Shin, D. Open software\
    \ platform for companion IoT devices.\nIn Proceedings of the 2017 IEEE International\
    \ Conference on Consumer Electronics (ICCE), Las Vegas, NV,\nUSA, 8–10 January\
    \ 2017.\n12.\nLee, H.; Sin, D.; Park, E.; Hwang, I.; Hong, G.; Shin, D. Glue.\
    \ things: A Mashup Platform for wiring the\nInternet of Things with the Internet\
    \ of Services. In Proceedings of the 5th International Workshop on Web of\nThings,\
    \ Cambridge, MA, USA, 8 October 2014; ACM: New York, NY, USA, 2014.\n13.\nHeath,\
    \ N. How IBM’s Node-RED Is Hacking Together the Internet of Things. Available\
    \ online: http:\n//www.techrepublic.com/article/node-red/ (accessed on 12 July\
    \ 2019).\n14.\nSimpkin, C.; Taylor, I.; Harborne, D.; Bent, G.; Preece, A.; Ganti,\
    \ R. Dynamic Distributed Orchestration of\nNode-REDIOT Workﬂows Using a Vector\
    \ SymbolicArchitecture. In Proceedings of the IEEE ACM Workﬂows\nin Support of\
    \ Large-Scale Science (WORKS), Dallas, TX, USA, 11 November 2018; pp. 52–56.\n\
    15.\nVillar, N.; Scott, J.; Hodges, S.; Hammil, K.; Miller, C. NET gadgeteer:\
    \ A platform for custom devices.\nIn Proceedings of the International Conference\
    \ on Pervasive Computing, Newcastle, UK, 18–22 June 2012;\nSpringer: Berlin/Heidelberg,\
    \ Germany, 2012; pp. 216–233.\n16.\nDe Paolis, L.T.; De Luca, V.; Paiano, R. Sensor\
    \ data collection and analytics with thingsboard and spark\nstreaming. In Proceedings\
    \ of the 2018 IEEE Workshop on Environmental, Energy, and Structural Monitoring\n\
    Systems (EESMS), Salerno, Italy, 21–22 June 2018.\n17.\nKickstarter Project. Available\
    \ online: https://www.kickstarter.com/ (accessed on 10 July 2019).\n18.\nSAM:\
    \ The Ultimate Internet Connected Electronics Kit. Available online: https://www.kickstarter.com/\n\
    projects/1842650056/sam-the-ultimate-internet-connected-electronics-ki (accessed\
    \ on 12 July 2019).\n19.\nMazzei, D.; Fantoni, G.; Montelisciani, G.; Baldi, G.\
    \ Internet of Things for designing smart objects.\nIn Proceedings of the 2014\
    \ IEEE World Forum on Internet of Things (WF-IoT), Seoul, Korea, 6–8 March 2014;\n\
    IEEE: Piscataway, NJ, USA, 2014.\n20.\nFeki, M.A.; Kawsar, F.; Boussard, M.; Trappeniers,\
    \ L. The internet of things: The next technological\nrevolutions. Computer 2013,\
    \ 46, 24–25. [CrossRef]\n21.\nScott, G.; Chin, J. A DIY approach to pervasive\
    \ computing for the Internet of things: A smart alarm clock.\nIn Proceedings of\
    \ the 2013 5th Computer Science and Electronic Engineering Conference (CEEC),\
    \ Colchester,\nUK, 17–18 September 2013; IEEE: Piscataway, NJ, USA, 2013; pp.\
    \ 57–60.\n22.\nKefalakis, N.; Soldatos, J.; Anagnostopoulos, A.; Dimitropoulos,\
    \ P. A visual paradigm for IoT solutions\ndevelopment. In Interoperability and\
    \ Open-Source Solutions for the Internet of Things; Springer: Berlin, Germany,\n\
    2015; pp. 26–45.\n23.\nQuoc, H.N.M.; Quoc, M.; Serrano, M.; Le-phuoc, D.; Hauswirth,\
    \ M. Super stream collider–linked stream\nmashups for everyone. In Proceedings\
    \ of the Semantic Web Challenge Co-Located with ISWC2012, Boston,\nMA, USA, 11–15\
    \ November 2012; pp. 11–15.\nSustainability 2019, 11, 5849\n24 of 24\n24.\nJayaraman,\
    \ P.P.; Palmer, D.; Zaslavsky, A.; Georgakopoulos, D. Do-it-Yourself Digital Agriculture\
    \ applications\nwith semantically enhanced IoT platform. In Proceedings of the\
    \ 2015 IEEE Tenth International Conference\non Intelligent Sensors, Sensor Networks\
    \ and Information Processing (ISSNIP), Singapore, 7–9 April 2015;\nIEEE: Piscataway,\
    \ NJ, USA, 2015; pp. 1–6.\n25.\nPachube. The Internet of Things Real-Time Web\
    \ Service and Applications. Available online: http://www.\nappropedia.org/Pachube\
    \ (accessed on 12 July 2019).\n26.\nKhan, M.S.; Kim, D. DIY interface for enhanced\
    \ service customization of remote IoT devices: A CoAP based\nprototype. Int. J.\
    \ Distrib. Sens. Netw. 2015, 2015. [CrossRef]\n27.\nAhmad, S.; Hang, L.; Kim D.H.\
    \ Design and Implementation of Cloud-Centric Conﬁguration Repository for\nDIY\
    \ IoT Applications. Sensors 2018, 18, 474. [CrossRef] [PubMed]\n28.\nShelby, Z.;\
    \ Hartke, K.; Bormann, C. The Constrained Application Protocol (CoAP); Internet\
    \ Engineering Task\nForce (IETF): Fremont, CA, USA, 2014.\n29.\nKovatsch, M.;\
    \ Lanter, M.; Shelby, Z. Californium: Scalable cloud services for the internet\
    \ of things with\ncoap. In Proceedings of the International Conference on the\
    \ Internet of Things (IOT), Cambridge, MA, USA,\n6–8 October 2014.\n30.\nChang,\
    \ K.-D.; Chang, C.-Y.; Liao, H.-M.; Chen, J.-L.; Chao, H.-C. A Framework for IoT\
    \ Objects Management\nbased on Future Internet IoT-IMS Communication Platform.\
    \ In Proceedings of the 2013 Seventh International\nConference on Innovative Mobile\
    \ and Internet Services in Ubiquitous Computing (IMIS), Taichung, Taiwan,\n3–5\
    \ July 2013.\n31.\nGyrard, A.; Bonnet, C.; Boudaoud, K.; Serrano, M. Assisting\
    \ IoT Projects and Developers in Designing\nInteroperable Semantic Web of Things\
    \ Applications.\nIn Proceedings of the 2015 IEEE International\nConference on\
    \ Data Science and Data Intensive Systems, Sydney, Australia, 11–13 December 2015.\n\
    32.\nVestergaard, L.S.; Fernandes, J.; Presser, M. Creative coding within the\
    \ Internet of Things. In Proceedings of\nthe Global Internet of Things Summit\
    \ (GIoTS), Geneva, Switzerland, 6–9 June 2017; IEEE: Piscataway, NJ,\nUSA, 2017;\
    \ pp. 1–6.\n33.\ndweet.io. Share Your Thing—Like It Ain’T No Thang. Available\
    \ online: http://dweet.io/ (accessed on\n12 July 2019).\n34.\nEnterprise IoT Solutions\
    \ and Platform Technology.\nAvailable online: https://www.thingworx.com/\n(accessed\
    \ on 12 July 2019).\n35.\nParticle. Connect Your Internet of Things (IoT) Devices.\
    \ Available online: https://www.particle.io/ (accessed\non 12 July 2019).\n36.\n\
    Shin, S.H.; Yoo, W.S. Sensor Gateway Using Arduino via Google Cloud and IEEE 802.15.4e.\
    \ In Proceedings\nof the Thirteenth International Conference on Internet and Web\
    \ Applications and Services (ICIW 2018),\nBarcelona, Spain, 22–26 July 2018.\n\
    37.\nAndore, D.B. AWS IOT Platform based Remote Monitoring by using Raspberry\
    \ Pi. Int. J. Latest Technol. Eng.\nManag. Appl. Sci. 2017, vi, 38–42\nc⃝ 2019\
    \ by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\n\
    article distributed under the terms and conditions of the Creative Commons Attribution\n\
    (CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n"
  inline_citation: '>'
  journal: Sustainability
  limitations: '>'
  pdf_link: https://www.mdpi.com/2071-1050/11/20/5849/pdf?version=1571741362
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Implementation of Thermal Comfort System based on Tasks Allocation
    Mechanism in Smart Homes
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/agriculture12081277
  analysis: '>'
  authors:
  - Sehrish Munawar Cheema
  - Muhammad Ali
  - Ivan Miguel Pires
  - Norberto Jorge Gonçalves
  - Mustahsan Hammad Naqvi
  - Maleeha Hassan
  citation_count: 10
  full_citation: '>'
  full_text: ">\nCitation: Cheema, S.M.; Ali, M.;\nPires, I.M.; Gonçalves, N.J.; Naqvi,\n\
    M.H.; Hassan, M. IoAT Enabled\nSmart Farming: Urdu\nLanguage-Based Solution for\n\
    Low-Literate Farmers. Agriculture\n2022, 12, 1277. https://doi.org/\n10.3390/agriculture12081277\n\
    Academic Editor: Dimitre Dimitrov\nReceived: 19 July 2022\nAccepted: 20 August\
    \ 2022\nPublished: 22 August 2022\nPublisher’s Note: MDPI stays neutral\nwith\
    \ regard to jurisdictional claims in\npublished maps and institutional afﬁl-\n\
    iations.\nCopyright:\n© 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\n\
    This article is an open access article\ndistributed\nunder\nthe\nterms\nand\n\
    conditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nagriculture\nArticle\nIoAT Enabled Smart Farming: Urdu Language-Based\
    \ Solution\nfor Low-Literate Farmers\nSehrish Munawar Cheema 1,*, Muhammad Ali\
    \ 2, Ivan Miguel Pires 3,*\n, Norberto Jorge Gonçalves 4\n,\nMustahsan Hammad\
    \ Naqvi 1 and Maleeha Hassan 5\n1\nDepartment of Computer Science, University\
    \ of Management and Technology, Sialkot 54770, Pakistan\n2\nDepartment of Software\
    \ Engineering, The Superior University, Lahore 54600, Pakistan\n3\nInstituto de\
    \ Telecomunicações, Universidade da Beira Interior, 6200-001 Covilhã, Portugal\n\
    4\nEscola de Ciências e Tecnologia, University of Trás-os-Montes e Alto Douro,\
    \ Quinta de Prados,\n5001-801 Vila Real, Portugal\n5\nDepartment of Nutritional\
    \ Sciences, University of Sialkot, Sialkot 51310, Pakistan\n*\nCorrespondence:\
    \ sehrish.munawar@skt.umt.edu.pk (S.M.C.); impires@it.ubi.pt (I.M.P.)\nAbstract:\
    \ The agriculture sector is the backbone of Pakistan’s economy, reﬂecting 26%\
    \ of its GPD and\n43% of the entire labor force. Smart and precise agriculture\
    \ is the key to producing the best crop yield.\nMoreover, emerging technologies\
    \ are reducing energy consumption and cost-effectiveness for saving\nagricultural\
    \ resources in control and monitoring systems, especially for those areas lacking\
    \ these\nresources. Agricultural productivity is thwarted in many areas of Pakistan\
    \ due to farmers’ illiteracy,\nlack of a smart system for remote access to farmland,\
    \ and an absence of proactive decision-making\nin all phases of the crop cycle\
    \ available in their native language. This study proposes an internet of\nagricultural\
    \ things (IoAT) based smart system armed with a set of economical, accessible\
    \ devices and\nsensors to capture real-time parameters of farms such as soil moisture\
    \ level, temperature, soil pH level,\nlight intensity, and humidity on frequent\
    \ intervals of time. The system analyzes the environmental\nparameters of speciﬁc\
    \ farms and enables the farmers to understand soil and environmental factors,\n\
    facilitating farmers in terms of soil fertility analysis, suitable crop cultivation,\
    \ automated irrigation and\nguidelines, harvest schedule, pest and weed control,\
    \ crop disease awareness, and fertilizer guidance.\nThe system is integrated with\
    \ an android application ‘Kistan Pakistan’ (prototype) designed in\nbilingual,\
    \ i.e., ‘Urdu’ and ‘English’. The mobile application is equipped with visual components,\n\
    audio, voice, and iconic and textual menus to be used by diverse literary levels\
    \ of farmers.\nKeywords: smart farming; precision agriculture; IoT; sensor network;\
    \ semi-literate farmers; interactive\ninterface; User Interface (UI); Android\
    \ apps\n1. Introduction\nAgriculture is considered the base for human living because\
    \ it is the primary food source\nand plays a crucial role in the global economy.\
    \ Pakistan is 79.6 million km2 and is home to a\npopulation of 192 million. The\
    \ contribution of the agricultural sector to gross domestic product\n(GDP) in\
    \ Pakistan gradually decreased to 19.3% in the year 2020–2021 from 22.04% previously\n\
    recorded in 2019 and generating employment opportunities for 38.5% of Pakistan’s\
    \ labor\nforce and valuable foreign exchange for the country [1–3]. It supports\
    \ the manufacturing and\nservices sectors of the economy by providing backward-forward\
    \ linkages in inputs-outputs\nmarkets and the most significant consumer of household\
    \ durables. Therefore, our agriculture\nsector can be considered an economic activity\
    \ in the country [4]. Farmers are facing issues in\nthe agriculture sector, so\
    \ it’s significant to research, develop of latest mechanisms, and adopt\nnew practices\
    \ to enhance production. Pressure on the agricultural system will increase with\n\
    the continuing expansion of the human population.\nMany areas of Pakistan are\
    \ trailing in agricultural productivity due to a lack of farmers’\nawareness,\
    \ timely access to crucial information, and proactive decision-making [5,6]. It\
    \ is\nAgriculture 2022, 12, 1277. https://doi.org/10.3390/agriculture12081277\n\
    https://www.mdpi.com/journal/agriculture\nAgriculture 2022, 12, 1277\n2 of 23\n\
    vital for human development in these underdeveloped areas to utilize information\
    \ and\ncommunication technologies (ICTs), artiﬁcial intelligence techniques, machine\
    \ learning\n(ML), and deep learning (DL) to make such information more readily\
    \ accessible to farmers,\nsigniﬁcantly increasing crop production [7–13]. Climate\
    \ change and shortage of agricultural\nresources are also signiﬁcant concerns\
    \ for the downfall of agricultural performance resulting\nin food insecurity [14–17].\
    \ This lets farmers hamper soil with intensiﬁed pesticides, which\naffect agricultural\
    \ practices in a harmful manner. Finally, ﬁelds remain barren [18–22].\nThese\
    \ are reasons for crop failure, lower production due to diseases, unpredictable\
    \ climate\nchange, and loss of soil fertility [23,24].\nIn this scenario, the\
    \ traditional agriculture trends are insufﬁcient to increase agricul-\ntural growth.\
    \ Agriculture is also out of the reach of less conventional technologies. In\n\
    this context, digital agriculture, automation, and precision farming, now termed\
    \ smart\nfarming, have arisen as new scientiﬁc ﬁelds that use intense techniques\
    \ to drive agricultural\nproductivity while minimizing its environmental impact\
    \ [25–27]. Data generated by smart\nfarming operations is provided by various\
    \ sensors that enable a better understanding of\nthe operational environment (interaction\
    \ of dynamic conditions of the crop, soil, weather,\nand environmental factors)\
    \ and the operation itself, leading to more accurate and timely\ndecision-making\
    \ [28,29]. Variability in climate and labor shortage is increasing continu-\n\
    ously, providing better insights for agricultural machinery automation. Remote\
    \ monitoring\ntechnologies facilitate farmers to access every inch of the farmlands\
    \ by creating virtual\nfences to monitor, detect and protect crops in real-time\
    \ [30–32]. IoT-based technologies\nallow farmers, among other things, to gather\
    \ data on plants’ environmental conditions like\nclimate change, soil fertility\
    \ level, humidity, temperature, and light intensity to monitor\nﬁelds and farms\
    \ remotely. These technologies assist farmers in having know-how and\nstatus of\
    \ crops anywhere and anytime [33–36].\nIn Pakistan, most farmers have android\
    \ phones [37–41] but are regrettably under-\nutilized. Our preliminary literature\
    \ study compelled us to work to facilitate farmers for\nagriculture automation,\
    \ recommendations, and guidelines in their local language, i.e.,\nUrdu, by using\
    \ the internet of agricultural things (IoAT), also known as agricultural\ninternet\
    \ of things (Ag-IoT) and artiﬁcial intelligence technologies with transliteration\
    \ and\nvoice-speech support in the local language. IoAT is the network of complex\
    \ and diverse\nagricultural objects that compute, process, and recommend solutions\
    \ intelligently based on\ndata generated from every connectable thing [42].\n\
    Previous research shows that using graphical cues, audio, speech, and video in\
    \ mobile\ninterfaces helps low-literates better adapt [43,44]. Field study experiences\
    \ reﬂect that low-\nliterates feel more challenged in understanding and interpreting\
    \ textual information than\ntheir literate peers [45]. In our research, we try\
    \ to accommodate such users by introducing\naudio, speech, Urdu language support,\
    \ and an interactive graphical interface. Researchers\nalso talked about the improvements\
    \ in information dissemination systems for less literate\nfarmers via different\
    \ means [46–50]. However, none considered interface design and\nUrdu language-based\
    \ real-time updates about agricultural guidelines using the android\napplication\
    \ and user preferences. Our choice of Urdu in this work was made by observing\n\
    that 87% of farmers preferred Urdu as a medium of information dissemination [51].\
    \ Our\nresearch is an extended form of [52–54] and primarily focuses on developing\
    \ an IoT-based\nand user-friendly system with these utilities.\n1.1. Rationale\n\
    This section reﬂects the ﬁndings and an evaluation report on information found\
    \ in\nthe literature relevant to our research domain. It represents the overview\
    \ of different ap-\nproaches used by other researchers. Integrating the Internet\
    \ of Things into the agricultural\nsystem has led to the internet of Agricultural\
    \ things (IoAT) and advanced computing\ntechniques. The researchers applied this\
    \ to obtain maximum beneﬁts and also to improve\nthe production of agriculture,\
    \ artiﬁcial intelligence, and IoT [55]. The agriculture domain is\nexperiencing\
    \ new evolution and revolution motivated by cloud technology, IoT, Edge and\n\
    Agriculture 2022, 12, 1277\n3 of 23\nfog computing, sensors, IoT, and big data\
    \ [56]. A proposal was presented for agriculture\napplications by investigating\
    \ integrated platforms, including cloud computing, IoT, and\ndata mining techniques\
    \ [57]. An IoT-based smart agricultural system was developed using\ndeep learning\
    \ combined with a cloud environment comprised of four layers: data collection,\n\
    edge computing, data transmission, and cloud computing layer [58]. A scalable\
    \ network-\nbased architecture was proposed to monitor and regulate agricultural\
    \ farms in rural areas\nusing IoT-based wiﬁ, long-distance network, and fog computing\
    \ [59]. Agricultural data\nanalytics employed with IoT has transformed from speciﬁc\
    \ crops to any kind of crop. The\ndeveloped system could support various applications,\
    \ from controlling and monitoring the\ncrops to promoting them to market [60].\n\
    Literacy is the ability to read and write simple statements [61]. Illiteracy,\
    \ low education,\nand computer illiteracy are signiﬁcant concerns in developing\
    \ countries like Pakistan.\nStudies indicate that user interface (UI) would be\
    \ designed differently for literate, low-\nliterate, and illiterate users. A user\
    \ interface should also consider the cultural context, such\nas language and images.\
    \ The non-textual interface is more user-friendly than the textual\none for illiterate\
    \ users [62].\nThe inability to read and write and the illiteracy of small farmers\
    \ make them vulnerable\nto various workers and cause human health risks [63].\
    \ Previous research inferred that\ncomplex hierarchy and multi-screens become\
    \ difﬁcult for low-literates to understand\nhelpful information, so the visuals,\
    \ audio, video, speech, icons, and images are a better\napproach to passing complex\
    \ data and information to mobile users [64]. The research\nﬁndings shed light\
    \ on some user interface (UI) design guidelines for illiterate and semi-\nliterate\
    \ users that can help take advantage of information and communication technologies\n\
    ICT [51]. The most powerful design factors that should be incorporated into a\
    \ user interface\n(UI) for low-literate users are localization and graphics [65].\
    \ An android application with\naudio, textual, and visual components was designed\
    \ for farmers with diverse literacy\nlevels. It could facilitate them regarding\
    \ vital weather information [45]. Pakistani farmers\ntypically rely on traditional\
    \ sources of information, which could be a reason for their\ninformation deﬁciency.\
    \ Data analysis indicated that farmers had diverse demographic\nconditions, but\
    \ primary among them is the ordinary level of education (52.4% illiterate).\n\
    A high level of information deﬁciency was observed among farmers regarding fertilizers\n\
    application, seed rate, disease diagnosis, pests, and insects’ identiﬁcation,\
    \ and a medium\nlevel of lack in information regarding the selection of varieties,\
    \ harvesting, and pets’\nmanagement was observed [66]. Providing information access\
    \ to low-literate, linguistic\nminority, tech-shy, handicapped and marginalized\
    \ users using speech-based services is a\nviable solution. These services were\
    \ made the national weather hotline of Pakistan [50]. A\nsurvey data revealed\
    \ that farmers in the Vehari district of Pakistan have a low literary rate\nand\
    \ less technical knowledge. They are unable to read agricultural instructions,\
    \ unaware\nof pesticides persistence and toxicity (73%), unable to diagnose cotton\
    \ pests and diseases\n(86%), and unable to decide which crop to grow on cotton\
    \ adjacent farms (100%) [67]. The\nresearch was conducted to study knowledge,\
    \ attitude, and practices regarding pesticide\nusage by vegetable growers in three\
    \ districts; Dadu, Larkana, and Shikarpur of Sindh,\nPakistan. Results show that\
    \ most vegetable growers (40.90%) have low primary education\nliteracy, and 27.27%\
    \ possess a middle pass. That’s why most growers are unfamiliar with\npest and\
    \ insect damage indications and the safe handling of pesticides [68]. Pakistani\n\
    farmers’ awareness of the damaging effects of different pesticides can lead to\
    \ integrated\nand smart pest control and management [69]. Research ﬁndings reﬂect\
    \ farmers’ behavior\nand a low tendency towards reading the labels of the pesticides\
    \ due to low education,\nadvanced age, usage of too technical language, illegible\
    \ fonts, and unclear texts [70]. In [71],\nthe authors developed a basic interactive\
    \ voice response (IVR) system for agro-information\ndissemination, such as fertilizer,\
    \ pesticide information, and weather forecast. In terms\nof usability and information\
    \ extraction, their study reﬂected that simple menu-based\nnavigation interfaces\
    \ are relatively easy to use and understand.\nAgriculture 2022, 12, 1277\n4 of\
    \ 23\nA remote agricultural monitoring platform was proposed in [72] after a detailed\n\
    literature study. Cyber security-based precision farming conceptual architecture\
    \ was\npresented in [73] for the frost prediction in peach production by analyzing\
    \ data captured\nby sensors implanted around an orchard. IoT-based precision farming\
    \ comprises multiple\ncontrol and monitoring applications like monitoring water\
    \ needs according to climate\nconditions, analyzing soil patterns, monitoring\
    \ crops disease and pest attacks, and assessing\noptimum time for planting, harvesting,\
    \ and tracking [74,75].\nAquaAgro offers IoT and Artiﬁcial Intelligence (AI) enabled\
    \ solutions for precision\nfarming. Using a software or app embedded hardware,\
    \ the predictions will be made for\nthe Irrigation scheduling, Fertilizer requirement,\
    \ Pest attack prediction, and Plant disease\ndetection. The essential four services\
    \ that AquaAgro provides are irrigation scheduling,\nFertilizer requirement, Pest\
    \ attack prediction, and Plant disease detection. They have\nreceived an overwhelming\
    \ response from the people [76]. An android mobile application\nnamed ‘Mentha\
    \ Mitra’ was developed with an interactive interface with bilingual (Hindi\nand\
    \ English) for menthol mint growers [77]. Android application provides scientiﬁc\
    \ e-\nadvisories on crop-related diseases, high-yield varieties, pests, insects,\
    \ and improved\ndistillation units.\nAn IoT-based wireless sensor network (WSN)\
    \ framework was proposed to monitor\ncrops smartly by analyzing environmental\
    \ factors [78]. In [79], the authors utilized the\nbeneﬁts of IoT for the implementation\
    \ of precision agriculture by sensing required param-\neters from the ﬁeld and\
    \ making suitable decisions such as activation and deactivation of\nirrigation\
    \ valves. Parameters include soil moisture, temperature and light intensity, etc.\n\
    Sensors could also send the gathered data to the cloud, and an Android application\
    \ was\ndeveloped to access these parameters. An expert IoT-based system relies\
    \ on the stored\nknowledge base and real-time data for farmer recommendations\
    \ [80]. This system will help\nin proactive and reactive tasks to a minimum the\
    \ loss of water. Farooq et al. [81] performed\na comprehensive literature study\
    \ on state-of-the-art techniques in smart farming. They\ndiscussed agriculture\
    \ networks, platforms, architecture, and topologies to help farmers\nto enhance\
    \ the corps’ productivity. This survey paper shows that Government and many\n\
    other stakeholders are interested in deploying IoT in Pakistan’s agriculture ﬁeld.\
    \ To in-\ncrease agricultural productivity, the authors suggested that collaboration\
    \ between allied\nand agriculture activities can be built by integrating big data\
    \ into climate-smart agriculture\nwith resource utilization [82].\nIn [83], the\
    \ authors are more concerned about the water supply to the plants. They\nproposed\
    \ a system in which a farmer can water the plants with a push of a button on his\n\
    phone when he is out of the station. Machine learning algorithms and radio frequency\n\
    identiﬁcation (RFID) tags detect and measure moisture and humidity. Internationally,\n\
    many studies [12,84–86] have been conducted to improve agricultural processes\
    \ based on\nsoil fertility level, crops, weather patterns, and fertilizers. These\
    \ studies used IoT, Global\nPosition Systems (GPS), Global information systems\
    \ (GIS), Wireless Sensor Networks\n(WSN), and many machine learning techniques.\
    \ The implementation of studies results in\nincreased proﬁtability and self-sufﬁciency.\
    \ IoT enabled decision support systems based on\nreal-time farm sensors data,\
    \ improving the water consumption by crops [87–89]. Authors\nin [90] provided\
    \ the real-time farm data, weather, and crops data to a Penman-Monteith\nand crop-coefﬁcient\
    \ model to produce recommendations about irrigation schedules. An\nintelligent\
    \ approach for diagnosing crop disease was proposed in [91], capable of working\n\
    with android devices equipped with fuzzy decision-making at the backend. The system\n\
    interacts with farmers in their native language of Urdu for crop disease diagnosing.\
    \ ‘Padi2U’\nis an android application developed for farmers to manage paddy ﬁelds.\
    \ It provides\nguidelines related to paddy varieties, planting schedule, pest,\
    \ disease, weed, weather\nforecast, and yield information in their native language\
    \ ‘Malay’ [92]. In [93], the authors\ndeveloped an application named ‘BLYNK’ to\
    \ control the IoT-based hardware remotely. The\npurpose of ‘BLYNK’ was to automate\
    \ irrigation and fertilizer supply to farms. Their results\nreﬂect approximately\
    \ 50% water saving and a 35% increase in yield. Irrigation monitoring\nAgriculture\
    \ 2022, 12, 1277\n5 of 23\nand automatic control systems were developed using\
    \ fuzzy decision support to generate a\nmoisture content distribution map of soil\
    \ and enhance affectivity [53,94–98].\nSoil having an essential quantity of macro\
    \ and micro-nutrients would be capable of\ncultivating different crops. The soil’s\
    \ lack of signiﬁcant nutrients (Nitrogen, Phosphorus,\nand Potassium) declines\
    \ crops’ cultivation, growth, and yield. To increase crop production,\nthe suitability\
    \ of a speciﬁc crop to be planted can be recommended by exploiting the soil’s\n\
    macronutrients [99–103]. Soil pH level is the major parameter for measuring soil\
    \ macronu-\ntrients (N, P, and K) and some of the micronutrients [104–108]. Smart\
    \ agro farms [109] use\nsolar power and a low-cost smart system, a perfect combination\
    \ of IoT, data mining, and\nAndroid application. The system monitors and extracts\
    \ a farm’s environmental factors\nsuch as soil moisture, humidity, and weather\
    \ and temperature parameters via data mining\nmodules, and provides optimized\
    \ guidance regarding crop cultivation, irrigation, and\nweather forecast in the\
    \ English language.\n1.2. Objectives and Hypotheses\nThe proposed system obtains\
    \ agricultural data through implanted IoT sensors, such\nas pH, soil moisture,\
    \ humidity, and temperature. The Internet plays a mediatory role in\ncommunication\
    \ and data exchange. We integrated agricultural data acquired from im-\nplanted\
    \ IoT devices with the cloud platform. Data is processed in a decision-making\
    \ system\nbased on learning prediction rules in conjunction with a rule-based\
    \ engine. Generally, a\nfarmer requires guidelines, even from the crop selection\
    \ phase to the harvesting stage. As\npresented in Figure 1, to facilitate low\
    \ literate farmers at each of these steps in their native\nlanguage, we performed\
    \ the following research objectives:\n•\nInvestigated traditional techniques and\
    \ systems with different agricultural interfaces\nto ﬁnd a research gap.\n•\n\
    Design and develop an interface in an easy-to-use format and Urdu for low-literate\n\
    farmers to facilitate their awareness and guidelines in their native language.\n\
    •\nDesign and develop a mechanism for measuring soil fertility of speciﬁc land\
    \ to recom-\nmend suitable crops according to soil fertility using fuzzy logic.\n\
    •\nProvide crops cultivation schedule, crop harvest schedule, automated irrigation\
    \ pro-\ncess, and watering guidelines to farmers.\n•\nFacilitate farmers concerning\
    \ guidelines for weeds and their eradication, pest attacks,\nand awareness of\
    \ best pesticides, crop diseases, and suitable fertilizers.\nAgriculture 2022,\
    \ 12, x FOR PEER REVIEW \n6 of 24 \n \n \nFigure 1. Agriculture Cycle. \n2. Materials\
    \ and Methods \nPrevious studies indicate that most farmers are unfamiliar with\
    \ the latest practices of \nagriculture as they are not facilitated with new technologies\
    \ to access agricultural infor-\nFigure 1. Agriculture Cycle.\nAgriculture 2022,\
    \ 12, 1277\n6 of 23\n2. Materials and Methods\nPrevious studies indicate that\
    \ most farmers are unfamiliar with the latest practices of\nagriculture as they\
    \ are not facilitated with new technologies to access agricultural information\n\
    and thus rely on traditional methods to grow their crops. Related studies indicate\
    \ that there is\nno such smart system providing an interactive interface to a\
    \ low literate or illiterate farmer\nand guidelines from the crop selection phase\
    \ to the harvesting stage. Significant barriers to\naccessing modern information\
    \ systems are the low literacy of farmers, the non-availability of\nlocal-language\
    \ information systems, and systems with fewer features. Our research identified\n\
    that it is essential to equip rural and semi-literate or illiterate farmers with\
    \ updated information\nthrough ICT, IoT, Edge Computing, Cloud Computing, and\
    \ Machine learning techniques, and\nprovide them guidance in almost every phase\
    \ of the crop cycle. It is necessary to develop\nUrdu-language-based information\
    \ smart systems to enhance farmers’ comprehension, crop\nproduction, and sustainable\
    \ agriculture.\nProposed System Design and Architecture\nThe overall design and\
    \ architecture of the solution proposed to cover smart agriculture\nare depicted\
    \ in Figure 2. It comprises three layers: crop (edge) layer, fog computing layer,\n\
    data analytics, and smart management at the cloud layer. The edge and cloud layers\
    \ are\ndesigned to be deployed respectively at local crop premises and remote\
    \ data servers. The\nintermediate fog computing layer comprises a set of virtualized\
    \ control modules in the form\nof Network Function Virtualization (NFV) nodes\
    \ that can be initiated along the network path\nfrom the farm facilities to the\
    \ cloud layer. NFV is a way to virtualize network services, for\nexample, firewalls,\
    \ routers, and load balancers that have traditionally been run on proprietary\n\
    hardware. The intermediate fog layer increases the versatility of deployed solutions\
    \ and\nconnectivity performances with the edge layer. At the crop premises, suitable\
    \ sensors like\nhumidity, temperature, soil moisture sensor, light intensity,\
    \ pH sensor, and actuators like\nwater pumps, valves, and activation of devices\
    \ for smart farming automation are deployed\nand connected with wireless nodes\
    \ as shown in Figure 2. Sensors’ data is captured at the edge\nlayer through wireless\
    \ nodes and transmitted to the fog layer. This layered architecture lets\natomic\
    \ operations requiring high reliability and low latency between sensors and actuators\n\
    to be processed at the fog layer, such as executing irrigation mandates for a\
    \ specific time\ninterval. The fog layer subsystem comprises the farm’s operative\
    \ control like irrigation,\nfarm monitoring, energy management, etc. The fog layer\
    \ is responsible for data fusion and\naggregation to offload analytics functions\
    \ that are usually performed. The fog layer control\nmodules are virtualized through\
    \ NFV techniques that communicate with edge nodes via IoT\nprotocols like constrained\
    \ application protocol (CoAP) and MQ telemetry transport (MQTT).\nAs depicted\
    \ in Figure 2 cloud layer serves as an interface between users and the core platform.\n\
    At this layer, crops current status and configuration parameters are maintained.\
    \ Any change\nin configuration parameters triggers the control actions to be managed\
    \ at fog subsystems.\nAgriculture 2022, 12, x FOR PEER REVIEW \n7 of 24 \n \n\
    sensor, and actuators like water pumps, valves, and activation of devices for\
    \ smart farm-\ning automation are deployed and connected with wireless nodes as\
    \ shown in Figure 2. \nSensors’ data is captured at the edge layer through wireless\
    \ nodes and transmitted to the \nfog layer. This layered architecture lets atomic\
    \ operations requiring high reliability and \nlow latency between sensors and\
    \ actuators to be processed at the fog layer, such as exe-\ncuting irrigation\
    \ mandates for a specific time interval. The fog layer subsystem comprises \n\
    the farm’s operative control like irrigation, farm monitoring, energy management,\
    \ etc. The \nfog layer is responsible for data fusion and aggregation to offload\
    \ analytics functions that \nare usually performed. The fog layer control modules\
    \ are virtualized through NFV tech-\nniques that communicate with edge nodes via\
    \ IoT protocols like constrained application \nprotocol (CoAP) and MQ telemetry\
    \ transport (MQTT). As depicted in Figure 2 cloud layer \nserves as an interface\
    \ between users and the core platform. At this layer, crops current \nstatus and\
    \ configuration parameters are maintained. Any change in configuration param-\n\
    eters triggers the control actions to be managed at fog subsystems. \n \nFigure\
    \ 2. System Design and architecture. \n3. Results and Discussion \n3.1. System\
    \ Components and Expected Outcomes \nThe proposed system gets real-time values\
    \ from sensors implanted in farmland. The \ncontroller grabs data from sensors\
    \ and transmits it to a cloud server, where data analysis \nis performed to match\
    \ predefined conditions and the current state of crops After mapping\nFigure 2.\
    \ System Design and architecture.\nAgriculture 2022, 12, 1277\n7 of 23\n3. Results\
    \ and Discussion\n3.1. System Components and Expected Outcomes\nThe proposed system\
    \ gets real-time values from sensors implanted in farmland. The\ncontroller grabs\
    \ data from sensors and transmits it to a cloud server, where data analysis is\n\
    performed to match predeﬁned conditions and the current state of crops. After\
    \ mapping\nthe requirements and data, the analysis system performs suitable actions\
    \ via actuators. Our\nsystem provides access to an Android application for farmer\
    \ facilitation with the following\nmain features.\n3.1.1. Soil Nutrient Analysis\n\
    With increased emphasis on precision agriculture, economics, and the environment,\n\
    soil analysis is a tool to determine areas where adequate and excessive fertilization\
    \ has\noccurred.\nSoil analysis is also used to monitor past fertility practices\
    \ to changes in\na ﬁeld’s nutrient status.\nNutrient availability can be impacted\
    \ by soil chemical and\nphysical properties.\nIn determining soil nutrient contents,\
    \ soil pH analysis is one parameter. Soil pH refers\nto the acidity and alkalinity\
    \ of soil measured on a logarithmic scale; thus decrease in 1 unit\nof pH value\
    \ causes an increase in acidity by a factor of 10. Small changes in pH values\
    \ have\nsigniﬁcant consequences. Table 1 represents the range values deﬁned for\
    \ soil pH.\nTable 1. Soil pH range values.\npH Level\nRange Values\n<3.5\nUltra-Acidic\n\
    3.6–3.9\nExtremely Acidic\n4–5.5\nStrong acidic\n5.6–6\nMedium acidic\n6.1–6.5\n\
    Slightly acidic\n6.6–7\nVery Slightly acidic\n7.1–7.5\nVery Slightly alkaline\n\
    7.6–8\nSlightly alkaline\n8.1–8.5\nMedium alkaline\n8.6–10\nStrongly alkaline\n\
    Measuring the acidity and alkalinity of soil is essential for analyzing the number\
    \ of\nmacro-nutrients present in the soil, particularly nitrogen (N), potassium\
    \ (K), and phospho-\nrus (P). Crops need these macro-nutrients in their growth,\
    \ thrive, and combat diseases.\nRemoval of bases from the soil due to harvested\
    \ crops, leaching, and acidic residual left in\nsoil due to fertilizers causes\
    \ an increase in acidity of the soil. Soil acidity affects crops and\nplants in\
    \ many ways, such as whether the surface pH is very high or too low, when the\n\
    efﬁcacy of herbicides and chemical reactions may be affected. Soil analysis is\
    \ the best way\nto check pH levels, and maintaining at least a pH of 6.0 is a\
    \ realistic goal. When soil pH is\nvery low (acidity is high) following conditions\
    \ occur:\n•\nSoluble metals, especially Manganese and Aluminum, may be toxic.\n\
    •\nThe population of organisms and their activities accountable for transforming\
    \ N, P,\nand S to plant-available forms may be reduced.\n•\nDeﬁciency of Calcium.\
    \ The soil’s cation exchange capacity (CEC) is low.\n•\nSymbiotic N ﬁxation in\
    \ legume crops is signiﬁcantly impaired. The symbiotic asso-\nciation entails\
    \ a narrower range of soil reactions than does the growth of plants not\nrelying\
    \ on ‘N’ ﬁxation.\n•\nAcidic soil with less organic matter is poorly aggregated\
    \ and has poor tilt.\nAgriculture 2022, 12, 1277\n8 of 23\n•\nThe availability\
    \ of mineral elements in soil may be affected. Association between soil\npH and\
    \ nutrient availability to plants can be depicted in Figure 3. The wider the blue\n\
    bar, the greater the nutrient availability. For example, for a pH range of 5.5–7.5,\
    \ the\navailability of P is highest and drops below 5.5. If the soil pH is 6,\
    \ an amount of P\napplied to it will be more available than if the same amount\
    \ is used in soil with a pH\nless than 5.5. Soil with high pH (>7.4) reduces several\
    \ nutrients such as Fe, Mn, Zn,\nand P, which is not economical for growing agronomic\
    \ crops.\nAgriculture 2022, 12, x FOR PEER REVIEW \n9 of 24 \n \n \nFigure 3.\
    \ Chart representing availability of soil nutrients in terms of soil pH [110].\
    \  \nMacronutrients are essential for plant growth and an excellent overall plant\
    \ state. The \nprimary macronutrients are nitrogen (N), phosphorus (P), and potassium\
    \ (K). Nitrogen is \na principal constituent of several essential plant substances\
    \ necessary for plant develop-\nment, energy metabolism, and protein synthesis.\
    \ Phosphorus is involved in vital plant \nprocesses. Unlike other macronutrients,\
    \ potassium is not included in the composition of \nessential metabolism components.\
    \ Still, it substantially occurs in all plant parts for enzyme \nactivities. Soil\
    \ pH sensor and soil moisture sensor measure the soil characteristics fre-\nquently\
    \ so that a farmer can monitor the status of crops in a healthy range in real-time\
    \ and \nremotely. We can predict a specific value for nitrogen (N), phosphorus\
    \ (P), and potassium \n(K), as Table 3. represents some ideas about these relations.\
    \ \nTable 2. Soil pH and corresponding estimation of N, P, and K \npH Range \n\
    Nitrogen \n(N) \nPhosphorus \n(P) \nPotassium \n(K) \n0–3.9 \n0% \n0% \n0% \n\
    4–4.5 \n2% \n5% \n2% \n4.5–5 \n50% \n20% \n35% \n5–5.5 \n100% \n35% \n50% \n5.5–6\
    \ \n100% \n45% \n70% \n6–6.5 \n100% \n55% \n100% \n6.5–7.0 \n100% \n100% \n100%\
    \ \n7 \n100% \n100% \n100% \n7–7.5 \n100% \n100% \n100% \n7.5–8 \n100% \n70% \n\
    2% \n8–8.5 \n75% \n20% \n2% \n8.5–9\n65%\n100%\n100%\nFigure 3. Chart representing\
    \ availability of soil nutrients in terms of soil pH [110].\nIn relatively large\
    \ amounts, soil provides nitrogen, potassium, phosphorus, calcium,\nmagnesium,\
    \ and sulfur. These are known as macronutrients. Soil supplies iron, boron,\n\
    manganese, copper, molybdenum, and zinc in relatively small amounts, often called\n\
    micronutrients. Plant nutrition is difﬁcult to understand entirely because of\
    \ the variation\nbetween different species of plants or individuals of a given\
    \ clone.\nMacronutrients are essential for plant growth and an excellent overall\
    \ plant state. The\nprimary macronutrients are nitrogen (N), phosphorus (P), and\
    \ potassium (K). Nitrogen is a\nprincipal constituent of several essential plant\
    \ substances necessary for plant development,\nenergy metabolism, and protein\
    \ synthesis. Phosphorus is involved in vital plant processes.\nUnlike other macronutrients,\
    \ potassium is not included in the composition of essential\nmetabolism components.\
    \ Still, it substantially occurs in all plant parts for enzyme activities.\nSoil\
    \ pH sensor and soil moisture sensor measure the soil characteristics frequently\
    \ so that a\nfarmer can monitor the status of crops in a healthy range in real-time\
    \ and remotely. We\ncan predict a speciﬁc value for nitrogen (N), phosphorus (P),\
    \ and potassium (K), as Table 2.\nrepresents some ideas about these relations.\n\
    Agriculture 2022, 12, 1277\n9 of 23\nTable 2. Soil pH and corresponding estimation\
    \ of N, P, and K.\npH Range\nNitrogen (N)\nPhosphorus (P)\nPotassium (K)\n0–3.9\n\
    0%\n0%\n0%\n4–4.5\n2%\n5%\n2%\n4.5–5\n50%\n20%\n35%\n5–5.5\n100%\n35%\n50%\n5.5–6\n\
    100%\n45%\n70%\n6–6.5\n100%\n55%\n100%\n6.5–7.0\n100%\n100%\n100%\n7\n100%\n100%\n\
    100%\n7–7.5\n100%\n100%\n100%\n7.5–8\n100%\n70%\n2%\n8–8.5\n75%\n20%\n2%\n8.5–9\n\
    65%\n100%\n100%\n9–9.5\n50%\n100%\n100%\n9.5–10\n2%\n100%\n100%\n3.1.2. Crops\
    \ Recommendation\nThe recommendation system proceeds based on a decree made by\
    \ a fuzzy logic-based\ndecision support system. Fuzzy logic is the key concept\
    \ for decision-making systems and\ncharacterizes each object of a set by a degree\
    \ of member functions from the interval [0,1].\nThe membership function deﬁnes\
    \ the degree of similarity of an object to the fuzzy subset.\nFuzziﬁcation is\
    \ the method of allocating a system’s numerical input to fuzzy sets with some\n\
    degree of membership. The fuzzy system decides by considering predeﬁned conditions\n\
    and real-time data captured by sensors implanted on a speciﬁc farm. A fuzzy decision\n\
    system is integrated with the controller to recommend suitable crops that can\
    \ be cultivated\non farmland based on available soil nutrients in the soil. Finally,\
    \ real-time data is processed\non the server, and a list of suitable crops is\
    \ directed to the farmer’s mobile app, as shown in\nFigure 4, where the farmer\
    \ can select any crop to cultivate.\nA fuzzy set S with parameters (U, i) where\
    \ U is the universe of discourse and ‘i’\ndenotes the interval of U, i.e., i:U\
    \ —> [0,1]. ’e’ elements can signify a fuzzy set S ordered\npairs. This universe\
    \ of discourse is characterized by a membership function mS(e) that\ndepicts the\
    \ probability of belonging of ‘e’ to ‘S’ as shown in Equation (1):\nS = {(e, mS\
    \ (e), e ∈ U)}\n(1)\nThe proposed fuzzy logic system design has four main components:\
    \ fuzziﬁer, rule\nbase, inference engine, and unfuzziﬁed, represented in Figure\
    \ 5. The fuzziﬁer converts\ncrisp inputs to fuzzy sets. Rules are depicted as\
    \ a group of if-then statements provided by\nan expert or acquired from data.\
    \ The inference engine combines the rules and membership\nfunction to produce\
    \ a fuzzy output.\nAgriculture 2022, 12, 1277\n10 of 23\n \nfuzzy subset. Fuzzification\
    \ is the method of allocating a system’s numerical input to fuzzy \nsets with\
    \ some degree of membership. The fuzzy system decides by considering prede-\n\
    fined conditions and real-time data captured by sensors implanted on a specific\
    \ farm. A \nfuzzy decision system is integrated with the controller to recommend\
    \ suitable crops that \ncan be cultivated on farmland based on available soil\
    \ nutrients in the soil. Finally, real-\ntime data is processed on the server,\
    \ and a list of suitable crops is directed to the farmer’s \nmobile app, as shown\
    \ in Figure 4, where the farmer can select any crop to cultivate.  \n \nFigure\
    \ 4. List of Recommended Crops. \nA fuzzy set S with parameters (U, i) where U\
    \ is the universe of discourse and ‘i’ de-\nnotes the interval of U, i.e., i:U\
    \ ―> [0,1]. ’e’ elements can signify a fuzzy set S ordered \npairs. This universe\
    \ of discourse is characterized by a membership function mS(e) that \ndepicts\
    \ the probability of belonging of ‘e’ to ‘S’ as shown in Equation (1): \n \nS\
    \ = {(e, mS (e), e ∈ U)} \n(1)\n \nThe proposed fuzzy logic system design has\
    \ four main components: fuzzifier, rule \nbase, inference engine, and unfuzzified,\
    \ represented in Figure 5. The fuzzifier converts \ncrisp inputs to fuzzy sets.\
    \ Rules are depicted as a group of if-then statements provided by \nan expert\
    \ or acquired from data. The inference engine combines the rules and membership\
    \ \nfunction to produce a fuzzy output. \n \nFigure 4. List of Recommended Crops.\n\
    The fuzzy logic system starts by fuzzing input variables. Later, the inference\
    \ engine\ntakes the decision based on if-then rules, membership functions, and\
    \ fuzzy logic operators,\ni.e., “and”, “or”. The fuzzy inference maps input variables\
    \ that are the pH level of soil,\ntemperature, humidity, and season to fuzzy output\
    \ by considering a fuzzy inference system\nthat infers results based on fuzzy\
    \ logic. Defuzziﬁcation evaluates the outcome from an\ninput rule set provided\
    \ as if-then statements. These rules are then stored in a knowledge\nbase of the\
    \ proposed system. Following is a brief description of the proposed algorithm.\n\
    Agriculture 2022, 12, x FOR PEER REVIEW \n11 of 24 \n \n \nFigure 5. Fuzzy logic\
    \ System for crop recommendation. \nThe fuzzy logic system starts by fuzzing input\
    \ variables. Later, the inference engine \ntakes the decision based on if-then\
    \ rules, membership functions, and fuzzy logic opera-\ntors, i.e., “and”, “or”.\
    \ The fuzzy inference maps input variables that are the pH level of \nsoil, temperature,\
    \ humidity, and season to fuzzy output by considering a fuzzy inference \nsystem\
    \ that infers results based on fuzzy logic. Defuzzification evaluates the outcome\
    \ \nfrom an input rule set provided as if-then statements. These rules are then\
    \ stored in a \nknowledge base of the proposed system. Following is a brief description\
    \ of the proposed \nalgorithm. \n \nAlgorithm 1: A Fuzzy Logic System \n1. \n\
    Input: RealTimePh, phMin, phMax, currentDate \n2.\nOutput: cropDetails [ ]\nFigure\
    \ 5. Fuzzy logic System for crop recommendation.\nAgriculture 2022, 12, 1277\n\
    11 of 23\nAlgorithm 1: A Fuzzy Logic System\n1.\nInput: RealTimePh, phMin, phMax,\
    \ currentDate\n2.\nOutput: cropDetails [ ]\n3.\nfetchSensorPh()\n4.\nreturn RealTimePh\n\
    5.\nFor row in TimeframOfCrop\n6.\nIf (CurrentDate > CultivationStartTime) &&\
    \ (CurrentDate < CultivationEndTime)\n7.\ncropDetails [ ] = fetchCropDetail(CultivationStartTime,\
    \ CultivationEndTime)\n8.\nend\n9.\nFor row in ph Table\n10.\nif (RealTimePh >\
    \ phMin) && (RealTimePh < phMax)\n11.\ncropDetails [ ] = showCropDetail (phMin,\
    \ phMax)\n12.\nend\n13.\nElse\n14.\nPrint error\n15.\n“No crop can be cultivated\
    \ in these environmental conditions”\n16.\nend\n3.1.3. Land Preparation and Cultivation\n\
    A well-prepared land plays a vital role in providing the important nutrients to\
    \ crops\nin weeds control and is suitable for sowing the seeds. A structured soil\
    \ is required for\nventilation and root penetration. The proposed system gets\
    \ real-time data from the sensors\nimplanted in the farms and recommends a list\
    \ of crops most suitable for cultivating speciﬁc\nﬁelds. From the suggested list,\
    \ the farmers can choose any crop to sow. After the crop\nselection phase, systems\
    \ provide guidelines for land preparation along with a list of\nappropriate fertilizers\
    \ to prepare the soil for a speciﬁc crop. It also provides a cultivation\nschedule\
    \ (suitable season) and cultivation method for each particular crop. All guidance\
    \ is\nprovided in text and voice to make the interface rural farmer-friendly,\
    \ as shown in Figure 6.\nAgriculture 2022, 12, x FOR PEER REVIEW \n12 of 24 \n\
    \ \nschedule (suitable season) and cultivation method for each particular crop.\
    \ All guidance \nis provided in text and voice to make the interface rural farmer-friendly,\
    \ as shown in Fig-\nure 6. \n \n \nFigure 6. Land Preparation and Cultivation.\
    \ \n3.1.4. Irrigation \nThe system transmits the input from deployed IoT devices\
    \ in a specific farm to an \nunderlying irrigation calculation algorithm (ICA)\
    \ illustrated in Figure 7, which recom-\nmends the irrigation scheduling for a\
    \ particular farm. An android application interface is \npresented to the farmer\
    \ to monitor the farm parameters and to get feedback on the irriga-\ntion requirement.\
    \ The whole process is controlled by an irrigation control module in the \nfog\
    \ computing layer.  \nFigure 6. Land Preparation and Cultivation.\n3.1.4. Irrigation\n\
    The system transmits the input from deployed IoT devices in a speciﬁc farm to\
    \ an\nunderlying irrigation calculation algorithm (ICA) illustrated in Figure\
    \ 7, which recom-\nAgriculture 2022, 12, 1277\n12 of 23\nmends the irrigation\
    \ scheduling for a particular farm. An android application interface\nis presented\
    \ to the farmer to monitor the farm parameters and to get feedback on the\nirrigation\
    \ requirement. The whole process is controlled by an irrigation control module\
    \ in\nthe fog computing layer.\nAgriculture 2022, 12, x FOR PEER REVIEW \n13 of\
    \ 24 \n \n \nFigure 7. Irrigation Calculation Algorithm. \nThe irrigation calculation\
    \ algorithm (ICA) determines whether irrigation is required \nor not and calculates\
    \ the volume of irrigation needed. ICA operates on two types of data: \nreal-time\
    \ data collected by sensors and predetermined static data such as crop and soil\
    \ \ndata. Ambient temperature, humidity, and soil moisture measured by sensors\
    \ are dy-\nnamic as they change hourly. Real-time data also incorporate average\
    \ wind data (m/s) to \ncalculate ET0 from an online source [111]. Crop data comprises\
    \ crop coefficient, depletion \nfactor, and adequate root depth. Soil data contains\
    \ soil category, water capacity, wilting \npoint, and location. Location data\
    \ further comprises the latitude and longitude of specific \nfarms.  \nFood and\
    \ Agriculture Organization (FAO) [112] recommends an essential condition \nthat\
    \ ICA evaluates daily to calculate irrigation decisions for a particular farm\
    \ and crop. If \nDr, i ≥ RAW, there is a need for irrigation, here Dr, i is the\
    \ root zone depletion or final de-\npletion at the end of an ith day, and RAW\
    \ is readily available water or amount of water in \nthe root zone measured in\
    \ ‘mm’. To ensure proper crop growth and avoid water stress, \nRAW must be maintained\
    \ above final depletion (Dr, i). If the above condition is good, the \nRAW value\
    \ and total farm area are used to compute the necessary irrigation volume. \n\
    RAW is calculated using ETc (depletion value) and predefined crop data. Every\
    \ day de-\npletion value increases due to crop evapotranspiration that cause an\
    \ irrigation need if it \nincreases than RAW. Depletion before evapotranspiration,\
    \ called initial shortage, and lack \nafter evapotranspiration, represented as\
    \ the final deficit, are calculated using average soil \nmoisture, water capacity,\
    \ and adequate root depth daily. For optimistic irrigation, meas-\nuring the water\
    \ amount a crop loses and requires for a specific duration is essential. Every\
    \ \ncrop type and soil has different water requirements; however, water loss occurs\
    \ due to \nevaporation from the soil surface and plant transpiration. Evapotranspiration\
    \ is a combi-\nnation of evaporation and transpiration. Evapotranspiration ‘ET0’\
    \ be determined by real-\ntime and predefined variables such as humidity, wind\
    \ speed, latitude, and altitude. ET0 \nFigure 7. Irrigation Calculation Algorithm.\n\
    The irrigation calculation algorithm (ICA) determines whether irrigation is required\n\
    or not and calculates the volume of irrigation needed. ICA operates on two types\
    \ of data:\nreal-time data collected by sensors and predetermined static data\
    \ such as crop and soil data.\nAmbient temperature, humidity, and soil moisture\
    \ measured by sensors are dynamic as\nthey change hourly. Real-time data also\
    \ incorporate average wind data (m/s) to calculate\nET0 from an online source\
    \ [111]. Crop data comprises crop coefﬁcient, depletion factor, and\nadequate\
    \ root depth. Soil data contains soil category, water capacity, wilting point,\
    \ and\nlocation. Location data further comprises the latitude and longitude of\
    \ speciﬁc farms.\nFood and Agriculture Organization (FAO) [112] recommends an\
    \ essential condition\nthat ICA evaluates daily to calculate irrigation decisions\
    \ for a particular farm and crop.\nIf Dr, i ≥ RAW, there is a need for irrigation,\
    \ here Dr, i is the root zone depletion or ﬁnal\ndepletion at the end of an ith\
    \ day, and RAW is readily available water or amount of water\nin the root zone\
    \ measured in ‘mm’. To ensure proper crop growth and avoid water stress,\nRAW\
    \ must be maintained above ﬁnal depletion (Dr, i). If the above condition is good,\
    \ the\nRAW value and total farm area are used to compute the necessary irrigation\
    \ volume. RAW\nis calculated using ETc (depletion value) and predeﬁned crop data.\
    \ Every day depletion\nvalue increases due to crop evapotranspiration that cause\
    \ an irrigation need if it increases\nthan RAW. Depletion before evapotranspiration,\
    \ called initial shortage, and lack after evap-\notranspiration, represented as\
    \ the ﬁnal deﬁcit, are calculated using average soil moisture,\nwater capacity,\
    \ and adequate root depth daily. For optimistic irrigation, measuring the\nwater\
    \ amount a crop loses and requires for a speciﬁc duration is essential. Every\
    \ crop type\nAgriculture 2022, 12, 1277\n13 of 23\nand soil has different water\
    \ requirements; however, water loss occurs due to evaporation\nfrom the soil surface\
    \ and plant transpiration. Evapotranspiration is a combination of\nevaporation\
    \ and transpiration. Evapotranspiration ‘ET0’ be determined by real-time and\n\
    predeﬁned variables such as humidity, wind speed, latitude, and altitude. ET0\
    \ and ETc can\nbe computed using the Penman-Monteith model and crop coefﬁcient,\
    \ respectively.\nPenman-Monteith Method:\nThe Penman-Monteith Equation (2) is\
    \ an effective way to compute reference evapo-\ntranspiration (ET0)\nET0 =\n0.408∆(Rn\
    \ − G) + Y\n900\nT+273u2(es − ea)\n∆ + Y(1 + 0.34u2)\n(2)\nwhere Rn is net radiation\
    \ at the surface and computed from publicly available libraries that\napply an\
    \ estimation formula named metabolic [113] and FAO [114], the values of maximum\n\
    temperature, minimum temperature, longitude, and latitude are used to calculate\
    \ Rn. ‘G’ is\nthe soil heat ﬂux, the amount of thermal energy that transfers through\
    \ the soil surface per\nunit of time. As the ICA measures ET0 every 24h, the value\
    \ of soil heat ﬂux is so tiny that\nit can be neglected; thus, G ≈ 0. u2 is the\
    \ wind speed (m/s) measured by an anemometer\nplaced at the height of 2 m above\
    \ ground level. u2 can be computed by Equation (3).\nu2 = uz\n4.87\nln(67.8z −\
    \ 5.42)\n(3)\nwhere ‘z’ is the elevation (m) above sea level. Saturation vapor\
    \ pressure (es) required in\nequation (1) is computed from Equation (4).\nes =\
    \ e0(Tmax) + e0(Tmin)\n2\n(4)\nwhere ‘T’ is the temperature (◦C) and e0 (T) is\
    \ the saturation vapor pressure at air tempera-\nture T (kPa), represented in\
    \ Equation (5).\ne0 (T) = 0.6108 exp\n\x14 17.27T\nT + 273.3\n\x15\n(5)\nea is\
    \ the actual vapor pressure in Equation (1) is computed by Equation (6)\nea =\n\
    e0(Tmax) RHmax\n100\n+ e0\n\x10\nTmin RHmin\n100\n\x11\n2\n(6)\nwhere ‘T’ is the\
    \ temperature (◦C). ‘∆’ in Equation (1) is the vapor pressure curve computed\n\
    by Equation (7).\n∆ =\n4098\nh\n0.618 exp\n\x10\n17.27T\nT+237.3\n\x11i\n(T +\
    \ 237.3)2\n(7)\nwhere ‘T’ is the temperature (◦C). ‘Υ’ in Equation (1) is the\
    \ psychometric constant repre-\nsented in Equation (8)\nΥ = 0.665 × 10−3P\n(8)\n\
    where ‘P’ is the atmospheric pressure (mb) computed by Equation (9).\nP = 101.3\n\
    \x12293 − 0.0065z\n293\n\x135.26\n(9)\nwhere ‘z’ is the sea level (m) altitude.\n\
    Agriculture 2022, 12, 1277\n14 of 23\nCrop Coefﬁcient:\nThe evapotranspiration\
    \ (ET0) calculated by the Penman-Monteith Equation (1) is used\nto compute reference\
    \ evapotranspiration (ETC). As every crop has different evapotranspi-\nration,\
    \ thus Penman-Monteith equation assigns ‘ET0′ to every crop type. The ‘ETc’ crop\n\
    coefﬁcient approach can be used as equation (10).\nETc = Kc ET0\n(10)\nwhere ‘Kc’\
    \ is the crop coefﬁcient which varies from crop to crop and their growth stages.\n\
    ICA Outputs:\nThe irrigation calculation algorithm (ICA) provides ﬂexibility for\
    \ the farmer with\nmultiple options regarding irrigation parameters and user application\
    \ interface in their\nnative language. Some farmers need irrigation output in\
    \ terms of volume, such as gallons\nor liters in acre per inch, whereas some need\
    \ output in terms of time. ICA facilitates farmers\nwith various output parameters\
    \ as per their requirements. For example, if a crop in some\nspeciﬁc farm needs\
    \ 1000L of water, then the system transforms 1000L, whether the output\nin time,\
    \ volume, and acre per inch. The system adjusts the output, calculates how much\n\
    time or acre per inch equals 10L of water, and presents the correct output amount\
    \ to the\nfarmer. Therefore, our proposed solution can work on any farm in Pakistan\
    \ with varying\noutput parameter requirements.\n3.1.5. Crops Disease Prevention\
    \ and Cure\nFor ease of the user, the proposed system provides guidelines about\
    \ diseases and\nprevention and cure methods for cultivated crops. This feature\
    \ enables the farmer to take\nprecautionary steps to avoid any illness before\
    \ any disease occurs. Moreover, in case of\nany disease symptom found, the farmer\
    \ can cure that disease with the help of disease cure\nmethods provided by the\
    \ proposed system, as shown on the app screen in Figure 8.\nAgriculture 2022,\
    \ 12, x FOR PEER REVIEW \n15 of 24 \n \nETc = Kc ET0 \n(10)\nwhere ‘Kc’ is the\
    \ crop coefficient which varies from crop to crop and their growth stages. \n\
    \ \nICA Outputs: \n \nThe irrigation calculation algorithm (ICA) provides flexibility\
    \ for the farmer with \nmultiple options regarding irrigation parameters and user\
    \ application interface in their \nnative language. Some farmers need irrigation\
    \ output in terms of volume, such as gallons \nor liters in acre per inch, whereas\
    \ some need output in terms of time. ICA facilitates farm-\ners with various output\
    \ parameters as per their requirements. For example, if a crop in \nsome specific\
    \ farm needs 1000L of water, then the system transforms 1000L, whether the \n\
    output in time, volume, and acre per inch. The system adjusts the output, calculates\
    \ how \nmuch time or acre per inch equals 10L of water, and presents the correct\
    \ output amount \nto the farmer. Therefore, our proposed solution can work on\
    \ any farm in Pakistan with \nvarying output parameter requirements.  \n \n3.1.5.\
    \ Crops Disease Prevention and Cure \nFor ease of the user, the proposed system\
    \ provides guidelines about diseases and \nprevention and cure methods for cultivated\
    \ crops. This feature enables the farmer to take \nprecautionary steps to avoid\
    \ any illness before any disease occurs. Moreover, in case of \nany disease symptom\
    \ found, the farmer can cure that disease with the help of disease cure \nmethods\
    \ provided by the proposed system, as shown on the app screen in Figure 8.   \n\
    \ \n \nFigure 8. Crops’ Disease Prevention and Cure. \n3.1.6. Pest and Weed Control\
    \ \nPests are harmful organisms that threaten crops’ existence, spread diseases\
    \ in crops, \nand cause destruction. On the other hand, weeds are plants that\
    \ grow where and when \nthey are not needed and compete with crops for nutrients,\
    \ space, light, and water. Weeds \nand pests increase production costs, decrease\
    \ the overall yield, and affect crop quality, so \ngetting rid of them is important\
    \ to maintain quality and yield. They become a big chal-\nlenge if not controlled\
    \ correctly at the right time because they cause severe damage to the \nFigure\
    \ 8. Crops’ Disease Prevention and Cure.\n3.1.6. Pest and Weed Control\nPests\
    \ are harmful organisms that threaten crops’ existence, spread diseases in crops,\n\
    and cause destruction. On the other hand, weeds are plants that grow where and\
    \ when they\nare not needed and compete with crops for nutrients, space, light,\
    \ and water. Weeds and\nAgriculture 2022, 12, 1277\n15 of 23\npests increase production\
    \ costs, decrease the overall yield, and affect crop quality, so getting\nrid\
    \ of them is important to maintain quality and yield. They become a big challenge\
    \ if not\ncontrolled correctly at the right time because they cause severe damage\
    \ to the crop. Our\nsystem aims to protect crops from economic damage by insects,\
    \ plant pathogens, weeds,\npests, and other harmful organisms while reducing reliance\
    \ on hazardous pesticides. The\nsystem provides farmers with authoritative and\
    \ up-to-date information about each crop’s\nweeds and pests. It provides guidelines\
    \ for controlling pest attacks and weed eradication\nmethods, as shown in Figures\
    \ 9 and 10, respectively.\nAgriculture 2022, 12, x FOR PEER REVIEW \n16 of 24\
    \ \n \ncrop. Our system aims to protect crops from economic damage by insects,\
    \ plant patho-\ngens, weeds, pests, and other harmful organisms while reducing\
    \ reliance on hazardous \npesticides. The system provides farmers with authoritative\
    \ and up-to-date information \nabout each crop’s weeds and pests. It provides\
    \ guidelines for controlling pest attacks and \nweed eradication methods, as shown\
    \ in Figure 9 and Figure 10, respectively.  \n \n \nFigure 9. Pests attack control\
    \ guidelines. \n \nFigure 10. Weeds eradication methods. \n3.1.7. Fertilizing\
    \ \nFertilizers have become a vital part of farming nowadays. Whether there is\
    \ a need for \nweed eradication or to increase production, both farmers must use\
    \ fertilizer. So, it is es-\nsential to choose a suitable fertilizer to fulfill\
    \ the requirements. The concentration of macro \nand micronutrients varies season\
    \ by season, so we cannot show the same crop every sea-\nson. In the same way,\
    \ we cannot use the same fertilizer every time. The selection of ferti-\nlizer\
    \ depends upon the crops’ requirements that the farmer may fulfill or the purpose\
    \ they \nFigure 9. Pests attack control guidelines.\nAgriculture 2022, 12, x FOR\
    \ PEER REVIEW \n16 of 24 \n \ncrop. Our system aims to protect crops from economic\
    \ damage by insects, plant patho-\ngens, weeds, pests, and other harmful organisms\
    \ while reducing reliance on hazardous \npesticides. The system provides farmers\
    \ with authoritative and up-to-date information \nabout each crop’s weeds and\
    \ pests. It provides guidelines for controlling pest attacks and \nweed eradication\
    \ methods, as shown in Figure 9 and Figure 10, respectively.  \n \n \nFigure 9.\
    \ Pests attack control guidelines. \n \nFigure 10. Weeds eradication methods.\
    \ \n3.1.7. Fertilizing \nFertilizers have become a vital part of farming nowadays.\
    \ Whether there is a need for \nweed eradication or to increase production, both\
    \ farmers must use fertilizer. So, it is es-\nsential to choose a suitable fertilizer\
    \ to fulfill the requirements. The concentration of macro \nand micronutrients\
    \ varies season by season, so we cannot show the same crop every sea-\nson. In\
    \ the same way, we cannot use the same fertilizer every time. The selection of\
    \ ferti-\nlizer depends upon the crops’ requirements that the farmer may fulfill\
    \ or the purpose they \nFigure 10. Weeds eradication methods.\n3.1.7. Fertilizing\n\
    Fertilizers have become a vital part of farming nowadays. Whether there is a need\n\
    for weed eradication or to increase production, both farmers must use fertilizer.\
    \ So, it is\nessential to choose a suitable fertilizer to fulﬁll the requirements.\
    \ The concentration of\nAgriculture 2022, 12, 1277\n16 of 23\nmacro and micronutrients\
    \ varies season by season, so we cannot show the same crop every\nseason. In the\
    \ same way, we cannot use the same fertilizer every time. The selection of\nfertilizer\
    \ depends upon the crops’ requirements that the farmer may fulﬁll or the purpose\n\
    they have to achieve. If the goal is to eradicate the weeds, the farmer should\
    \ use some\nspeciﬁc fertilizers for a particular weed. Suppose the requirement\
    \ is to enhance crop growth\nand production. In that case, the fertilizer selection\
    \ depends upon the nature of the crop\nas the native farmers are low-literate\
    \ and less aware of choosing the right fertilizer. Thus,\nthe proposed system\
    \ “Kisan Pakistan” provides accurate guidance in terms of relevant\nfertilizers\
    \ along with weed eradication support. The system suggests suitable fertilizers\
    \ for\ndifferent types of weeds and the crops’ growth, along with usage guidance\
    \ in the native\nand English languages, as shown in Figure 6. This makes it much\
    \ easy for native and\nlow-literate farmers to solve their issues without acquiring\
    \ help from any external entity.\n3.1.8. Harvesting and Storing\nHarvesting and\
    \ storing are critical phases in the agriculture cycle because if these\nare done\
    \ correctly, they provide high-quality products resulting in high income. So right\n\
    way of harvesting maximizes the yield and reduces crop fatalities. The proposed\
    \ system\nmakes it convenient for the farmer by providing the best harvesting\
    \ schedule for each\nrecommended crop and harvesting methods, as shown in Figure\
    \ 11.\nAgriculture 2022, 12, x FOR PEER REVIEW \n17 of 24 \n \nhave to achieve.\
    \ If the goal is to eradicate the weeds, the farmer should use some specific \n\
    fertilizers for a particular weed. Suppose the requirement is to enhance crop\
    \ growth and \nproduction. In that case, the fertilizer selection depends upon\
    \ the nature of the crop as the \nnative farmers are low-literate and less aware\
    \ of choosing the right fertilizer. Thus, the \nproposed system “Kisan Pakistan”\
    \ provides accurate guidance in terms of relevant ferti-\nlizers along with weed\
    \ eradication support. The system suggests suitable fertilizers for \ndifferent\
    \ types of weeds and the crops’ growth, along with usage guidance in the native\
    \ \nand English languages, as shown in Figure 6. This makes it much easy for native\
    \ and low-\nliterate farmers to solve their issues without acquiring help from\
    \ any external entity. \n \n3.1.8. Harvesting and Storing \nHarvesting and storing\
    \ are critical phases in the agriculture cycle because if these are \ndone correctly,\
    \ they provide high-quality products resulting in high income. So right way \n\
    of harvesting maximizes the yield and reduces crop fatalities. The proposed system\
    \ makes \nit convenient for the farmer by providing the best harvesting schedule\
    \ for each recom-\nmended crop and harvesting methods, as shown in Figure 11.\
    \ \n \n \nFigure 11. Harvesting and storing guidelines. \n3.2. Discussion \nThis\
    \ research was conducted on a small-scale farm of 2 acres in Sialkot, Pakistan.\
    \ Of the \ntwo, one acre was controlled by the farmer (farm A), where they applied\
    \ traditional farm-\ning techniques. The remaining one acre, farm B, was controlled\
    \ by our proposed smart \nsystem integrated with sensors and IoT techniques. The\
    \ system recommends different \nsuitable crops to be cultivated according to the\
    \ soil analysis, i.e., 6 pH level for farm B. \nFarms A and B were cultivated\
    \ with the same crop. Regarding the irrigation module, we \ncompared the water\
    \ usage on both farm A and farm B. Farm A was irrigated by farmers \nwho used\
    \ conventional estimations for irrigation time and volume. Farm B was irrigated\
    \ \nusing decisions made by the Irrigation Calculation Method (ICA) as a function\
    \ of real-\ntime data supplied by IoT devices deployed on the farm. Table 4. highlights\
    \ the total irri-\ngation volume consumed in farms A and B. It can be depicted\
    \ that farm A, using conven-\ntional farming methods, consumed 48569 L of irrigation\
    \ water, and farm B, using the pro-\nposed solution, utilized 22779 L of irrigation\
    \ water, which resulted in 25790 L of water \nFigure 11. Harvesting and storing\
    \ guidelines.\n3.2. Discussion\nThis research was conducted on a small-scale farm\
    \ of 2 acres in Sialkot, Pakistan. Of\nthe two, one acre was controlled by the\
    \ farmer (farm A), where they applied traditional\nfarming techniques. The remaining\
    \ one acre, farm B, was controlled by our proposed smart\nsystem integrated with\
    \ sensors and IoT techniques. The system recommends different\nsuitable crops\
    \ to be cultivated according to the soil analysis, i.e., 6 pH level for farm B.\n\
    Farms A and B were cultivated with the same crop. Regarding the irrigation module,\
    \ we\ncompared the water usage on both farm A and farm B. Farm A was irrigated\
    \ by farmers\nwho used conventional estimations for irrigation time and volume.\
    \ Farm B was irrigated\nusing decisions made by the Irrigation Calculation Method\
    \ (ICA) as a function of real-time\ndata supplied by IoT devices deployed on the\
    \ farm. Table 3. highlights the total irrigation\nvolume consumed in farms A and\
    \ B. It can be depicted that farm A, using conventional\nfarming methods, consumed\
    \ 48,569 L of irrigation water, and farm B, using the proposed\nAgriculture 2022,\
    \ 12, 1277\n17 of 23\nsolution, utilized 22,779 L of irrigation water, which resulted\
    \ in 25,790 L of water saved,\napproximately 53%. The data for the detailed irrigation\
    \ schedule for both farms are also\nplotted in Figure 12 to illustrate the water\
    \ usage efﬁciency in the proposed solution.\nTable 3. Irrigation Statistics.\n\
    Water Consumption (Farm A)\nWater Consumption (Farm B)\nWater Saving (L)\nWater\
    \ Saving (%)\n48,569\n22,779\n25,790\n53\nAgriculture 2022, 12, x FOR PEER REVIEW\
    \ \n18 of 24 \n \n \nsaved, approximately 53%. The data for the detailed irrigation\
    \ schedule for both farms are \nalso plotted in Figure 12 to illustrate the water\
    \ usage efficiency in the proposed solution.      \nTable 3. Irrigation Statistics.\
    \ \nWater Consumption \n(Farm A) \nWater Consumption  \n(Farm B) \nWater Saving\
    \ \n(L) \nWater Saving \n(%) \n48569 \n22779 \n25790 \n53 \n \n \n \nFigure 12.\
    \ Irrigation frequency and water usage efficiency. \nWe implanted the proposed\
    \ smart system on a small-scale farm. Results show that if \nwe add more sensors\
    \ and IoT devices, the proposed model has the flexibility to be imple-\nmented\
    \ on medium to large farms. The system incorporates Edge, fog, and cloud compu-\n\
    ting with IoT devices which offers low latency, high bandwidth, less energy consumption,\
    \ \nand real-time analytics that make it more efficient. Currently, the system\
    \ incorporates data \nof major crops in Pakistan, but by involving more crop data\
    \ from other global regions, the \nsystem could be implemented on farms with more\
    \ crops. \nOur research covered a wide range of previously proposed models, papers,\
    \ and stud-\nies. All these researches and studies were thoroughly read and understood,\
    \ their domain \nof interest, their architecture, the pros and cons, and the features\
    \ added in their proposed \nstudies. After critically evaluating many studies\
    \ on smart agriculture, some crucial infor-\nmation about related studies is provided\
    \ in Table 1. Readers can obtain an overview and \ncomparison of the previous\
    \ work done by researchers, practitioners, authors, and tech-\nnologists related\
    \ to our research contributions. \n \n \nFigure 12. Irrigation frequency and water\
    \ usage efﬁciency.\nWe implanted the proposed smart system on a small-scale farm.\
    \ Results show that if\nwe add more sensors and IoT devices, the proposed model\
    \ has the ﬂexibility to be imple-\nmented on medium to large farms. The system\
    \ incorporates Edge, fog, and cloud comput-\ning with IoT devices which offers\
    \ low latency, high bandwidth, less energy consumption,\nand real-time analytics\
    \ that make it more efﬁcient. Currently, the system incorporates data\nof major\
    \ crops in Pakistan, but by involving more crop data from other global regions,\
    \ the\nsystem could be implemented on farms with more crops.\nOur research covered\
    \ a wide range of previously proposed models, papers, and\nstudies. All these\
    \ researches and studies were thoroughly read and understood, their\ndomain of\
    \ interest, their architecture, the pros and cons, and the features added in their\n\
    proposed studies. After critically evaluating many studies on smart agriculture,\
    \ some\ncrucial information about related studies is provided in Table 4. Readers\
    \ can obtain an\noverview and comparison of the previous work done by researchers,\
    \ practitioners, authors,\nand technologists related to our research contributions.\n\
    A few limitations are incorporated in this study. We could not conduct the yield\
    \ analy-\nsis of crops cultivated on farm B. Concerning soil analysis, we could\
    \ also involve more soil\nsensors, such as NPK sensors, for better fertility measurements.\
    \ System recommendations\naddress only major crops to be grown in Pakistan. In\
    \ the future, we will incorporate more\ncrop data for different global regions.\
    \ This study was carried out when most regions were\non lockdown, with restrictions\
    \ on movements within Pakistan. We are intended to conduct\nthe qualitative usability\
    \ test of the android application ‘Kisan Pakistan’ among farmers\nin the future.\
    \ We will perform experiments proposed system on large-scale farm lands to\nmeasure\
    \ and improve its performance in the future.\nAgriculture 2022, 12, 1277\n18 of\
    \ 23\nTable 4. Comparison summary of related studies vs. proposed solution.\n\
    Study\nSmart\nSolution\nInterface for\nSemi-literate\nMedium\n(Language)\nProposed\
    \ Features and Guidelines\nSoil\nAnalysis\nCrop\nCultivation\nLand\nPreparation\n\
    Irrigation\nCrop\nDisease\nPest and Weed\nControl\nFertilizer\nHarvest\nWeather\n\
    Forecast\n[45]\nYes\nUrdu\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\n[53]\nYes\nNo\n\
    English\nNo\nNo\nNo\nYes\nNo\nNo\nNo\nNo\nNo\n[54]\nYes\nNo\nEnglish\nNo\nYes\n\
    No\nYes\nNo\nNo\nNo\nNo\nNo\n[111]\nYes\nNo\nUrdu\nNo\nNo\nNo\nNo\nYes\nNo\nNo\n\
    No\nNo\n[50]\nNo\nYes\nN/A\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\n[71]\nNo\nYes\n\
    N/A\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nNo\nYes\n[77]\nYes\nNo\nHindi, English\nNo\n\
    No\nNo\nNo\nYes\nYes\nYes\nNo\nNo\n[109]\nYes\nNo\nEnglish\nYes\nYes\nNo\nYes\n\
    No\nNo\nNo\nNo\nYes\n[92]\nYes\nNo\nMalay\nNo\nYes\nNo\nNo\nYes\nYes\nNo\nNo\n\
    Yes\n[93]\nYes\nNo\nEnglish\nYes\nNo\nNo\nYes\nYes\nNo\nYes\nNo\nNo\nProposed\
    \ Solution\nYes\nYes\nUrdu\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nAgriculture\
    \ 2022, 12, 1277\n19 of 23\n4. Conclusion\nAgriculture is the backbone of Pakistan.\
    \ It is necessary to ensure its sustainable growth\nover the years. We studied\
    \ traditional trends followed by farmers and investigated why\nproductivity lags.\
    \ The key barriers are information inadequacies, lack of information\nsystems\
    \ for illiterates or less-literates, and lack of a system that provides guidance\
    \ at\nevery stage of the crop cycle. This study was carried out to provide a smart\
    \ advisory\nsystem for illiterate and semi-literate farmers of Pakistan that could\
    \ provide them guidance\nfrom crop selection to the harvest stage phase. In this\
    \ research work, we built a cost-\neffective smart system equipped with multiple\
    \ sensors and devices related to the internet\nof things (IoT) technologies. We\
    \ also developed an android application named ‘Kistan\nPakistan’ that allows illiterate\
    \ and low-literate farmers to manage their farms remotely. The\ninterface of the\
    \ android application is interactive due to its visual, audio, voice, and iconic\n\
    components. The proposed solution is applicable globally as all information and\
    \ guidelines\nare disseminated in both the ‘Urdu’ and ‘English’ languages. Edge-cloud\
    \ computing\ndelivers more accurate guidelines in less time and in almost every\
    \ phase of the agricultural\ncycle, increasing productivity and making the agricultural\
    \ ecosystem more robust. We\nexperimented on a small-scale farm, but the results\
    \ reﬂect that it will be efﬁcient for medium\nto large-scale ﬁelds.\nAuthor Contributions:\
    \ Conceptualization, S.M.C.; methodology, S.M.C.; software, S.M.C.; validation,\n\
    M.H.N. and M.H.; formal analysis, S.M.C.; investigation, S.M.C.; writing—original\
    \ draft preparation,\nS.M.C., M.A., I.M.P., N.J.G., M.H.N. and M.H.; writing—review\
    \ and editing, S.M.C., M.A., I.M.P.,\nN.J.G., M.H.N. and M.H.; funding acquisition,\
    \ I.M.P. All authors have read and agreed to the\npublished version of the manuscript.\n\
    Funding: This work is funded by FCT/MEC through national funds and, when applicable,\
    \ co-funded\nby the FEDER-PT2020 partnership agreement under the project UIDB/50008/2020.\n\
    Institutional Review Board Statement: Not applicable.\nInformed Consent Statement:\
    \ Not applicable.\nData Availability Statement: Not applicable.\nAcknowledgments:\
    \ This article is based upon work from COST Action IC1303-AAPELE—Architectures,\n\
    Algorithms, and Protocols for Enhanced Living Environments and COST Action CA16226–SHELD-\n\
    ON—Indoor living space improvement: Smart Habitat for the Elderly, supported by\
    \ COST (European\nCooperation in Science and Technology). COST is a funding agency\
    \ for research and innovation\nnetworks. Our actions help connect research initiatives\
    \ across Europe and enable scientists to develop\ntheir ideas by sharing them\
    \ with their peers. It boosts their research, career, and innovation. More\ninformation\
    \ is available at www.cost.eu (accessed on 20 August 2022).\nConﬂicts of Interest:\
    \ The authors declare no conﬂict of interest.\nReferences\n1.\nZaman, S.B.; Ishaq,\
    \ M.; Niazi, M.A. Contribution of Agriculture Sector in Economic Growth of Pakistan:\
    \ An Empirical Analysis. J.\nAppl. Econ. Bus. Stud. 2021, 5, 103–120. [CrossRef]\n\
    2.\nJatoi, F.Z. Agriculture in Pakistan and it’s impact on Economic growth. SSRN\
    \ Electron. J. 2020. [CrossRef]\n3.\n02-Agriculture.pdf.\nAvailable online: https://www.ﬁnance.gov.pk/survey/chapters_21/02-Agriculture.pdf\
    \ (accessed on\n18 July 2022).\n4.\nKhan, Z.A.; Koondhar, M.A.; Khan, I.; Ali,\
    \ U.; Tianjun, L. Dynamic linkage between industrialization, energy consumption,\n\
    carbon emission, and agricultural products export of Pakistan: An ARDL approach.\
    \ Environ. Sci. Pollut. Res. Int. 2021, 28,\n43698–43710. [CrossRef] [PubMed]\n\
    5.\nSaqib, S.E.; Arifullah, A.; Yaseen, M. Managing farm-centric risks in agricultural\
    \ production at the ﬂood-prone locations of Khyber\nPakhtunkhwa, Pakistan. Nat.\
    \ Hazards 2021, 107, 853–871. [CrossRef]\n6.\nYaseen, M.; Shahzad, M.S.; Khan,\
    \ F.U.; Luqman, M.; Saleem, U.; Nasir, S. Public Sector Advisory Services for\
    \ Rice Productivity: A\nCase Study of Farmers’ Awareness in Tehsil Shakargarh\
    \ of Pakistan. Sarhad J. Agric. 2021, 38, 229–237. [CrossRef]\n7.\nSansa-Otim,\
    \ J.; Nsabagwa, M.; Mwesigwa, A.; Faith, B.; Owoseni, M.; Osuolale, O.; Mboma,\
    \ D.; Khemis, B.; Albino, P.; Ansah, S.O.;\net al. An Assessment of the Effectiveness\
    \ of Weather Information Dissemination among Farmers and Policy Makers. Sustainability\n\
    2022, 14, 3870. [CrossRef]\nAgriculture 2022, 12, 1277\n20 of 23\n8.\nSalik, M.H.;\
    \ Tanwir, F.; Saboor, A.; Akram, M.B.; Anjum, F.; Mehdi, M.; Ashraf, I.; Naazer,\
    \ M.A.; Suleman, M.; Latif, M.;\net al. Role of Radio Communication and Adoption\
    \ of Modern Agricultural Technology: A Study of Farmers in District Jhang,\nPunjab-Pakistan.\
    \ Pak. J. Agric. Sci. 2021, 58, 731–738. [CrossRef]\n9.\nAlant, B.P.; Bakare,\
    \ O.O. A case study of the relationship between smallholder farmers’ ICT literacy\
    \ levels and demographic data\nw.r.t. their use and adoption of ICT for weather\
    \ forecasting. Heliyon 2021, 7, e06403. [CrossRef]\n10.\nJavaid, N. Integration\
    \ of context awareness in Internet of Agricultural Things. ICT Express 2021. [CrossRef]\n\
    11.\nAyim, C.; Kassahun, A.; Addison, C.; Tekinerdogan, B. Adoption of ICT innovations\
    \ in the agriculture sector in Africa: A review\nof the literature. Agric. Food\
    \ Secur. 2022, 11, 22. [CrossRef]\n12.\nJha, K.; Doshi, A.; Patel, P.; Shah, M.\
    \ A comprehensive review on automation in agriculture using artiﬁcial intelligence.\
    \ Artif.\nIntell. Agric. 2019, 2, 1–12. [CrossRef]\n13.\nBannerjee, G.; Sarkar,\
    \ U.; Das, S.; Ghosh, I. Artiﬁcial Intelligence in Agriculture: A Literature Survey.\
    \ Int. J. Sci. Res. Comput. Sci.\nAppl. Manag. Stud. 2018, 7, 1–6.\n14.\nAgesa,\
    \ B.; Onyango, C.; Kathumo, V.; Onwonga, R.; Karuku, G. Climate Change Effects\
    \ on Crop Production in Kenya: Farmer\nPerceptions and Adaptation Strategies.\
    \ Afr. J. Food Agric. Nutr. Dev. 2019, 19, 14010–14042. [CrossRef]\n15.\nNgoune\
    \ Liliane, T.; Shelton Charles, M. Factors Affecting Yield of Crops. Agron. Clim.\
    \ Change Food Secur. 2020. [CrossRef]\n16.\nAhmad, D.; Afzal, M. Impact of climate\
    \ change on pastoralists’ resilience and sustainable mitigation in Punjab, Pakistan.\
    \ Environ.\nDev. Sustain. 2021, 23, 11406–11426. [CrossRef]\n17.\nFahad, S.; Wang,\
    \ J. Climate change, vulnerability, and its impacts in rural Pakistan: A review.\
    \ Environ. Sci. Pollut. Res. 2019, 27,\n1334–1338. [CrossRef]\n18.\nSubeesh, A.;\
    \ Mehta, C.R. Automation and digitization of agriculture using artiﬁcial intelligence\
    \ and internet of things. Artif. Intell.\nAgric. 2021, 5, 278–291. [CrossRef]\n\
    19.\nKumar, S.; Singh, R.; Venkatesh, A.S.; Udayabhanu, G.; Singh, T.B.N. Assessment\
    \ of Potentially Toxic Elements Contamination on\nthe Fertile Agricultural Soils\
    \ Within Fluoride-Affected Areas of Jamui District, Indo-Gangetic Alluvial Plains,\
    \ India. Water Air Soil\nPollut. 2022, 233, 39. [CrossRef]\n20.\nZambito Marsala,\
    \ R.; Capri, E.; Russo, E.; Bisagni, M.; Colla, R.; Lucini, L.; Gallo, A.; Suciu,\
    \ N.A. First evaluation of pesticides\noccurrence in groundwater of Tidone Valley,\
    \ an area with intensive viticulture. Sci. Total Environ. 2020, 736, 139730. [CrossRef]\n\
    21.\nGupta, A.; Singh, U.B.; Sahu, P.K.; Paul, S.; Kumar, A.; Malviya, D.; Singh,\
    \ S.; Kuppusamy, P.; Singh, P.; Paul, D.; et al. Linking Soil\nMicrobial Diversity\
    \ to Modern Agriculture Practices: A Review. Int. J. Environ. Res. Public Health\
    \ 2022, 19, 3141. [CrossRef]\n22.\nKopittke, P.M.; Menzies, N.W.; Wang, P.; McKenna,\
    \ B.A.; Lombi, E. Soil and the intensiﬁcation of agriculture for global food\n\
    security. Environ. Int. 2019, 132, 105078. [CrossRef] [PubMed]\n23.\nKhan, N.A.;\
    \ Gao, Q.; Iqbal, M.A.; Abid, M. Modeling food growers’ perceptions and behavior\
    \ towards environmental changes\nand its induced risks: Evidence from Pakistan.\
    \ Environ. Sci. Pollut. Res. 2020, 27, 20292–20308. [CrossRef] [PubMed]\n24.\n\
    Ullah, W.; Nafees, M.; Khurshid, M.; Nihei, T. Assessing farmers’ perspectives\
    \ on climate change for effective farm-level\nadaptation measures in Khyber Pakhtunkhwa,\
    \ Pakistan. Environ. Monit. Assess. 2019, 191, 547. [CrossRef] [PubMed]\n25.\n\
    Zhang, M.; Wang, N.; Chen, L. Sensing Technologies and Automation for Precision\
    \ Agriculture. In Women in Precision Agriculture;\nSpringer: Cham, Germany, 2021;\
    \ pp. 35–54. [CrossRef]\n26.\nBlasch, J.; van der Kroon, B.; van Beukering, P.;\
    \ Munster, R.; Fabiani, S.; Nino, P.; Vanino, S. Farmer preferences for adopting\n\
    precision farming technologies: A case study from Italy. Eur. Rev. Agric. Econ.\
    \ 2020, 49, 33–81. [CrossRef]\n27.\nGonçalves, P.; Pedreiras, P.; Monteiro, A.\
    \ Recent Advances in Smart Farming. Animals 2022, 12, 705. [CrossRef] [PubMed]\n\
    28.\nDe Alwis, S.; Hou, Z.; Zhang, Y.; Na, M.H.; Ofoghi, B.; Sajjanhar, A. A survey\
    \ on smart farming data, applications and techniques.\nComput. Ind. 2022, 138,\
    \ 103624. [CrossRef]\n29.\nBhat, S.A.; Huang, N.-F. Big Data and AI Revolution\
    \ in Precision Agriculture: Survey and Challenges. IEEE Access 2021, 9,\n110209–110222.\
    \ [CrossRef]\n30.\nUllo, S.L.; Sinha, G.R. Advances in IoT and Smart Sensors for\
    \ Remote Sensing and Agriculture Applications. Remote Sens. 2021,\n13, 2585. [CrossRef]\n\
    31.\nGao, F. Remote Sensing for Agriculture. In Springer Remote Sensing/Photogrammetry;\
    \ Springer: Cham, Germany, 2021; pp. 7–24.\n[CrossRef]\n32.\nWaleed, M.; Um, T.-W.;\
    \ Kamal, T.; Usman, S.M. Classiﬁcation of Agriculture Farm Machinery Using Machine\
    \ Learning and\nInternet of Things. Symmetry 2021, 13, 403. [CrossRef]\n33.\n\
    Qazi, S.; Khawaja, B.A.; Farooq, Q.U. IoT-Equipped and AI-Enabled Next Generation\
    \ Smart Agriculture: A Critical Review,\nCurrent Challenges and Future Trends.\
    \ IEEE Access 2022, 10, 21219–21235. [CrossRef]\n34.\nTao, W.; Zhao, L.; Wang,\
    \ G.; Liang, R. Review of the internet of things communication technologies in\
    \ smart agriculture and\nchallenges. Comput. Electron. Agric. 2021, 189, 106352.\
    \ [CrossRef]\n35.\nMehmood, M.Z.; Ahmed, M.; Afzal, O.; Aslam, M.A.; Zoq-ul-Arfeen,\
    \ R.; Qadir, G.; Komal, S.; Shahid, M.A.; Awan, A.A.; Awale,\nM.A.; et al. Internet\
    \ of Things (IoT) and Sensors Technologies in Smart Agriculture: Applications,\
    \ Opportunities, and Current\nTrends. Build. Clim. Resil. Agric. 2021, 339–364.\
    \ [CrossRef]\n36.\nHassan, S.I.; Alam, M.M.; Illahi, U.; Al Ghamdi, M.A.; Almotiri,\
    \ S.H.; Su’ud, M.M. A Systematic Review on Monitoring and\nAdvanced Control Strategies\
    \ in Smart Agriculture. IEEE Access 2021, 9, 32517–32548. [CrossRef]\nAgriculture\
    \ 2022, 12, 1277\n21 of 23\n37.\nKhan, N.A.; Qijie, G.; Ali, S.; Shahbaz, B.;\
    \ Shah, A.A. Farmers’ use of mobile phone for accessing agricultural information\
    \ in\nPakistan: Ciência Rural 2019, 49. Ciência Rural 2019, 49. [CrossRef]\n38.\n\
    Khan, N.; Siddiqui, B.N.; Khan, N.; Khan, F.; Ullah, N.; Ihtisham, M.; Ullah,\
    \ R.; Ismail, S.; Muhammad, S. Analyzing mobile\nphone usage in agricultural modernization\
    \ and rural development. Int. J. Agric. Ext. 2020, 8, 139–147. [CrossRef]\n39.\n\
    Chhachhar, A.R.; Chen, C.; Jin, J. Mobile Phone Impact on Agriculture and Price\
    \ Information among Farmers. Indian J. Sci. Technol.\n2016, 9. [CrossRef]\n40.\n\
    Aldosari, F.; Al Shunaiﬁ, M.S.; Ullah, M.A.; Muddassir, M.; Noor, M.A. Farmers’\
    \ perceptions regarding the use of Information\nand Communication Technology (ICT)\
    \ in Khyber Pakhtunkhwa, Northern Pakistan. J. Saudi Soc. Agric. Sci. 2019, 18,\
    \ 211–217.\n[CrossRef]\n41.\nFarooq, U. Revolutionising Pakistan Agriculture by\
    \ Increasing the Use of Knowledge, Science and Technology and ICT. In Building\n\
    Knowledge-Based Economy in Pakistan: Learning from Best Practices; Islamabad Policy\
    \ Research Institute: Islamabad, Pakistan, 2016;\npp. 112–143. ISBN 978-969-8721-49-7.\n\
    42.\nLee, I.; Lee, K. The Internet of Things (IoT): Applications, investments,\
    \ and challenges for enterprises. Bus. Horiz. 2015, 58,\n431–440. [CrossRef]\n\
    43.\nMedhi, I.; Patnaik, S.; Brunskill, E.; Gautama, S.N.N.; Thies, W.; Toyama,\
    \ K. Designing mobile interfaces for novice and low-literacy\nusers. ACM Trans.\
    \ Comput. Hum. Interact. 2011, 18, 1–28. [CrossRef]\n44.\nUjakpa, M.M.; Kristof,\
    \ A.; Domingos, A.; Hashiyana, V.; Suresh, N.; Osakwe, J.O.; Iyawa, G. Farmers’\
    \ Use of Mobile Devices in\nDeveloping Countries. In Proceedings of the 2021 IST-Africa\
    \ Conference (IST-Africa), South Africa, 10–14 May 2021; pp. 1–7.\n45.\nIdrees,\
    \ F.; Qadir, J.; Mehmood, H.; Hassan, S.U.; Batool, A. Urdu Language based Information\
    \ Dissemination System for Low-Literate\nFarmers; ACM: New York, NY, USA, 2019.\n\
    46.\nSmart Agriculture on Computers and Handheld Devices. Int. J. Adv. Trends\
    \ Comput. Sci. Eng. 2021, 10, 1177–1182. [CrossRef]\n47.\nSharma, U.; Chetri,\
    \ P.; Minocha, S.; Roy, A.; Holker, T.; Patt, A.; Joerin, J. Do phone-based short\
    \ message services improve the\nuptake of agri-met advice by farmers? A case study\
    \ in Haryana, India. Clim. Risk Manag. 2021, 33, 100321. [CrossRef]\n48.\nChengalur-Smith,\
    \ I.; Potnis, D.; Mishra, G. Developing voice-based information sharing services\
    \ to bridge the information divide\nin marginalized communities: A study of farmers\
    \ using IBM’s spoken web in rural India. Int. J. Inf. Manag. 2021, 57, 102283.\n\
    [CrossRef]\n49.\nMubin, O.; Tubb, J.; Novoa, M.; Naseem, M.; Razaq, S. Understanding\
    \ the Needs of Pakistani Farmers and the Prospects of an ICT\nIntervention; ACM:\
    \ New York, NY, USA, 2015.\n50.\nQasim, M.; Zia, H.B.; Athar, A.; Habib, T.; Raza,\
    \ A.A. Personalized weather information for low-literate farmers using multimodal\n\
    dialog systems. Int. J. Speech Technol. 2021, 24, 455–471. [CrossRef]\n51.\nSrivastava,\
    \ A.; Kapania, S.; Tuli, A.; Singh, P. Actionable UI Design Guidelines for Smartphone\
    \ Applications Inclusive of\nLow-Literate Users. Proc. ACM Hum. Comput. Interact.\
    \ 2021, 5, 1–30. [CrossRef]\n52.\nSheikh, J.A.; Cheema, S.M.; Ali, M.; Amjad,\
    \ Z.; Tariq, J.Z.; Naz, A. IoT and AI in Precision Agriculture: Designing Smart\
    \ System\nto Support Illiterate Farmers. Adv. Intell. Syst. Comput. 2020, 1213,\
    \ 490–496. [CrossRef]\n53.\nMunir, M.S.; Bajwa, I.S.; Cheema, S.M. An intelligent\
    \ and secure smart watering system using fuzzy logic and blockchain. Comput.\n\
    Electr. Eng. 2019, 77, 109–119. [CrossRef]\n54.\nCheema, S.M.; Khalid, M.; Rehman,\
    \ A.; Sarwar, N. Plant Irrigation and Recommender System–IoT Based Digital Solution\
    \ for\nHome Garden. Commun. Comput. Inf. Sci. 2019, 932, 513–525. [CrossRef]\n\
    55.\nChatterjee, S.; Dey, N.; Sen, S. Soil moisture quantity prediction using\
    \ optimized neural supported model for sustainable\nagricultural applications.\
    \ Sustain. Comput. Inform. Syst. 2020, 28, 100279. [CrossRef]\n56.\nGhorbani,\
    \ M.A.; Deo, R.C.; Karimi, V.; Kashani, M.H.; Ghorbani, S. Design and implementation\
    \ of a hybrid MLP-GSA model\nwith multi-layer perceptron-gravitational search\
    \ algorithm for monthly lake water level forecasting. Stoch. Environ. Res. Risk\n\
    Assess. 2018, 33, 125–147. [CrossRef]\n57.\nMorais, R.; Silva, N.; Mendes, J.;\
    \ Adão, T.; Pádua, L.; López-Riquelme, J.A.; Pavón-Pulido, N.; Sousa, J.J.; Peres,\
    \ E. mySense: A\ncomprehensive data management environment to improve precision\
    \ agriculture practices. Comput. Electron. Agric. 2019, 162,\n882–894. [CrossRef]\n\
    58.\nDewi, C.; Chen, R.-C. Decision Making Based on IoT Data Collection for Precision\
    \ Agriculture. Intell. Inf. Database Syst. Recent\nDev. 2019, 830, 31–42. [CrossRef]\n\
    59.\nYang, Z.; Ding, Y.; Hao, K.; Cai, X. An adaptive immune algorithm for service-oriented\
    \ agricultural Internet of Things. Neurocom-\nputing 2019, 344, 3–12. [CrossRef]\n\
    60.\nKale, A.P.; Sonavane, S.P. IoT based Smart Farming: Feature subset selection\
    \ for optimized high-dimensional data using improved\nGA based approach for ELM.\
    \ Comput. Electron. Agric. 2019, 161, 225–232. [CrossRef]\n61.\nWhite, S. Evaluation\
    \ of Articles Written about Agriculture and Comprehension of Agriculture Literacy.\
    \ Master’s Thesis, Tarleton\nState University, Stephenville, TX, USA, 2021.\n\
    62.\nJan, S.; Maqsood, I.; Ahmad, I.; Ashraf, M.; Khan, F.; Imran, M. A Systematic\
    \ Feasibility Analysis of User Interfaces for Illiterate\nUsers. Proc. Pak. Acad.\
    \ Sci. 2019, 56, 75–91.\n63.\nHussain, A.; Akhtar, W.; Jabbar, A. Risk management\
    \ for small farmers in Pakistan: A review. Pak. J. Agric. Sci. 2022, 59, 247–259.\n\
    [CrossRef]\nAgriculture 2022, 12, 1277\n22 of 23\n64.\nCuendet, S.; Medhi, I.;\
    \ Bali, K.; Cutrell, E. VideoKheti: Making Video Content Accessible to Low-Literate\
    \ and Novice Users. In\nProceedings of the SIGCHI Conference on Human Factors\
    \ in Computing Systems, Association for Computing Machinery, New\nYork, NY, USA,\
    \ 27 April 2013; pp. 2833–2842.\n65.\nChaudhry, S.; Muhammad, A.; Shah, A.A.;\
    \ Batoo, F. Human-Computer User Interface Design for Semi-literate and Illiterate\
    \ Users.\nLahore Garrison Univ. Res. J. Comput. Sci. Inf. Technol. 2021, 5, 62–77.\
    \ [CrossRef]\n66.\nHassan, G.; Ashraf, I.; Ul Hassan, N.; Ali, M.; Khalid, I.;\
    \ Ashraf, E.; Raza, H.; Husnain, R.T.; Zia, S.-R.; Asghar, S. Information\ndeﬁciency\
    \ among farmers regarding vegetable production practices in peri-urban areas of\
    \ the Punjab-Pakistan. Int. J. Agric. Ext.\n2021, 9, 19–28. [CrossRef]\n67.\n\
    Ahmad, A.; Shahid, M.; Khalid, S.; Zaffar, H.; Naqvi, T.; Pervez, A.; Bilal, M.;\
    \ Ali, M.A.; Abbas, G.; Nasim, W. Residues of\nendosulfan in cotton growing area\
    \ of Vehari, Pakistan: An assessment of knowledge and awareness of pesticide use\
    \ and health\nrisks. Environ. Sci. Pollut. Res. 2018, 26, 20079–20091. [CrossRef]\n\
    68.\nKhuhro, S.N.; Junejo, I.A.; Hullio, M.H.; Hassan, M.F.; Maitlo, S.A.; Shaikh,\
    \ M.A. Knowledge Attitude Practice Regarding\nPesticide Application among Vegetable\
    \ Growers of Dadu Canal Irrigated Areas of Northern Sindh Pakistan. Pak. J. Agric.\
    \ Res.\n2020, 33, 331. [CrossRef]\n69.\nKhan, F.Z.A.; Manzoor, S.A.; Gul, H.T.;\
    \ Ali, M.; Bashir, M.A.; Akmal, M.; Haseeb, M.; Imran, M.U.; Taqi, M.; Manzoor,\
    \ S.A.; et al.\nDrivers of farmers’ intention to adopt integrated pest management:\
    \ A case study of vegetable farmers in Pakistan. Ecosphere 2021,\n12, e03812.\
    \ [CrossRef]\n70.\nBagheri, A.; Emami, N.; Damalas, C.A. Farmers’ behavior in\
    \ reading and using risk information displayed on pesticide labels: A\ntest with\
    \ the theory of planned behavior. Pest Manag. Sci. 2021, 77, 2903–2913. [CrossRef]\
    \ [PubMed]\n71.\nRiaz, W.; Durrani, H.; Shahid, S.; Raza, A.A. Ict intervention\
    \ for agriculture development: Designing an ivr system for farmers\nin pakistan.\
    \ In Proceedings of the Ninth International Conference on Information and Communication\
    \ Technologies and\nDevelopment, New York, NY, USA, 16 November 2017; pp. 1–5.\n\
    72.\nNakutis, Z.; Deksnys, V.; Jaruevicius, I.; Marcinkevicius, E.; Ronkainen,\
    \ A.; Soumi, P.; Nikander, J.; Blaszczyk, T.; Andersen, B.\nRemote Agriculture\
    \ Automation Using Wireless Link and IoT Gateway Infrastructure. In Proceedings\
    \ of the 26th International\nWorkshop on Database and Expert Systems Applications\
    \ (DEXA), IEEE, Valencia, Spain, 1–4 September 2015.\n73.\nBrun-Laguna, K.; Diedrichs,\
    \ A.L.; Chaar, J.E.; Dujovne, D.; Taffernaberry, J.C.; Mercado, G.; Watteyne,\
    \ T. A Demo of the PEACH\nIoT-Based Frost Event Prediction System for Precision\
    \ Agriculture. In Proceedings of the 13th Annual IEEE International\nConference\
    \ on Sensing, Communication, and Networking (SECON), IEEE, London, UK, 27–30 June\
    \ 2016.\n74.\nSwain, M.; Hashmi, M.F.; Singh, R.; Hashmi, A.W. A cost-effective\
    \ LoRa-based customized device for agriculture ﬁeld monitoring\nand precision\
    \ farming on IoT platform. Int. J. Commun. Syst. 2020, 34, e4632. [CrossRef]\n\
    75.\nGaikwad, S.V.; Vibhute, A.D.; Kale, K.V.; Mehrotra, S.C. An innovative IoT\
    \ based system for precision farming. Comput. Electron.\nAgric. 2021, 187, 106291.\
    \ [CrossRef]\n76.\nAvailable online: https://aquaagro.smartcube.pk/ (accessed\
    \ on 18 July 2022).\n77.\nSingh, P.P.; Pandey, P.; Singh, D.; Singh, S.; Khan,\
    \ M.S.; Semwal, M. ‘Mentha Mitra’—An android app based advisory digital tool\n\
    for menthol mint farmers. Ind. Crops Prod. 2020, 144, 112047. [CrossRef]\n78.\n\
    Ayaz, M.; Ammad-Uddin, M.; Sharif, Z.; Mansour, A.; Aggoune, E.-H.M. Internet-of-Things\
    \ (IoT)-Based Smart Agriculture:\nToward Making the Fields Talk. IEEE Access 2019,\
    \ 7, 129551–129583. [CrossRef]\n79.\nDholu, M.; Ghodinde, K.A. Internet of Things\
    \ (IoT) for Precision Agriculture Application. In Proceedings of the 2018 2nd\n\
    International Conference on Trends in Electronics and Informatics (ICOEI), IEEE,\
    \ Tirunelveli, India, 11–12 May 2018.\n80.\nShahzadi, R.; Ferzund, J.; Tausif,\
    \ M.; Asif, M. Internet of Things based Expert System for Smart Agriculture. Int.\
    \ J. Adv. Comput.\nSci. Appl. 2016, 7, 341–350. [CrossRef]\n81.\nFarooq, M.S.;\
    \ Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey on the Role of IoT in Agriculture\
    \ for the Implementation of\nSmart Farming. IEEE Access 2019, 7, 156237–156271.\
    \ [CrossRef]\n82.\nReghunadhan, R. Big Data, Climate Smart Agriculture and India–Africa\
    \ Relations: A Social Science Perspective. In IoT and\nAnalytics for Agriculture;\
    \ Pattnaik, P.K., Kumar, R., Pal, S., Panda, S.N., Eds.; Springer: Singapore,\
    \ 2020; pp. 113–137. ISBN\n978-981-13-9177-4.\n83.\nRoopaei, M.; Rad, P.; Choo,\
    \ K.-K.R. Cloud of Things in Smart Agriculture: Intelligent Irrigation Monitoring\
    \ by Thermal Imaging.\nIEEE Cloud Comput. 2017, 4, 10–15. [CrossRef]\n84.\nThe\
    \ National Artiﬁcial Intelligence Research and Development Strategic Plan: 2019\
    \ Update. Available online: https://www.nitrd.\ngov/pubs/National-AI-RD-Strategy-2019.pdf\
    \ (accessed on 1 August 2022).\n85.\nU.S. LEADERSHIP IN AI: A Plan for Federal\
    \ Engagement in Developing Technical Standards and Related Tools. Available online:\n\
    https://www.nist.gov/system/ﬁles/documents/2019/08/10/ai_standards_fedengagement_plan_9aug2019.pdf\
    \ (accessed on\n15 January 2020).\n86.\nArtiﬁcial Intelligence in Agriculture.\
    \ Available online: https://www.mindtree.com/sites/default/ﬁles/2018-04/Artiﬁcial%20\n\
    Intelligence%20in%20Agriculture.pdf (accessed on 1 August 2022).\n87.\nGarcía,\
    \ L.; Parra, L.; Jimenez, J.M.; Lloret, J.; Lorenz, P. IoT-Based Smart Irrigation\
    \ Systems: An Overview on the Recent Trends on\nSensors and IoT Systems for Irrigation\
    \ in Precision Agriculture. Sensors (Basel) 2020, 20, 1042. [CrossRef]\nAgriculture\
    \ 2022, 12, 1277\n23 of 23\n88.\nTorres-Sanchez, R.; Navarro-Hellin, H.; Guillamon-Frutos,\
    \ A.; San-Segundo, R.; Ruiz-Abellón, M.C.; Domingo-Miguel, R. A\nDecision Support\
    \ System for Irrigation Management: Analysis and Implementation of Different Learning\
    \ Techniques. Water 2020,\n12, 548. [CrossRef]\n89.\nJiménez, A.-F.; Cárdenas,\
    \ P.-F.; Jiménez, F. Intelligent IoT-multiagent precision irrigation approach\
    \ for improving water use\nefﬁciency in irrigation systems at farm and district\
    \ scales. Comput. Electron. Agric. 2022, 192, 106635. [CrossRef]\n90.\nZia, H.;\
    \ Rehman, A.; Harris, N.R.; Fatima, S.; Khurram, M. An Experimental Comparison\
    \ of IoT-Based and Traditional Irrigation\nScheduling on a Flood-Irrigated Subtropical\
    \ Lemon Farm. Sensors (Basel) 2021, 21, 4175. [CrossRef]\n91.\nToseef, M.; Khan,\
    \ M.J. An intelligent mobile application for diagnosis of crop diseases in Pakistan\
    \ using fuzzy inference system.\nComput. Electron. Agric. 2018, 153, 1–11. [CrossRef]\n\
    92.\nAthirah, R.N.; Norasma, C.Y.N.; Ismail, M.R. Development of an android application\
    \ for smart farming in crop management. In\nIOP Conference Series: Earth and Environmental\
    \ Science; IOP Publishing: Bristol, UK, 2020; Volume 540, p. 012074.\n93.\nKumar,\
    \ T.U.; Periasamy, A. IoT Based Smart Farming (E-FARM)’S. Int. J. Recent Adv.\
    \ Multidiscip. Top. 2021, 2, 85–87.\n94.\nNabati, J.; Nezami, A.; Neamatollahi,\
    \ E.; Akbari, M. An integrated approach land suitability for agroecological zoning\
    \ based on\nfuzzy inference system and GIS. Environ. Dev. Sustain. 2022. [CrossRef]\n\
    95.\nOrojloo, M.; Hashemy Shahdany, S.M.; Roozbahani, A. Developing an integrated\
    \ risk management framework for agricultural\nwater conveyance and distribution\
    \ systems within fuzzy decision making approaches. Sci. Total Environ. 2018, 627,\
    \ 1363–1376.\n[CrossRef]\n96.\nLi, M.; Sui, R.; Meng, Y.; Yan, H. A real-time\
    \ fuzzy decision support system for alfalfa irrigation. Comput. Electron. Agric.\
    \ 2019,\n163, 104870. [CrossRef]\n97.\nBenyezza, H.; Bouhedda, M.; Rebouh, S.\
    \ Zoning irrigation smart system based on fuzzy control technology and IoT for\
    \ water and\nenergy saving. J. Clean. Prod. 2021, 302, 127001. [CrossRef]\n98.\n\
    Bhat, S.K.; Kumar, S.S.; Krishnakumar, K.; Shaju, S.; Kumar, G.P. Enhancing Effectivity\
    \ of Automated irrigation SYSTEM Using Fuzzy\nLogic; AIP Publishing: Sausalito,\
    \ CA, USA, 2021.\n99.\nRajeswari, A.M.; Anushiya, A.S.; Fathima, K.S.A.; Priya,\
    \ S.S.; Mathumithaa, N. Fuzzy Decision Support System for Recommenda-\ntion of\
    \ Crop Cultivation based on Soil Type. In Proceedings of the 4th International\
    \ Conference on Trends in Electronics and\nInformatics (ICOEI) (48184), IEEE,\
    \ Tirunelveli, India, 15–17 June2020.\n100. Banerjee, G.; Sarkar, U.; Ghosh, I.\
    \ A Fuzzy Logic-Based Crop Recommendation System. Adv. Intell. Syst. Comput. 2020,\
    \ 1225,\n57–69. [CrossRef]\n101. Joss, B.N.; Hall, R.J.; Sidders, D.M.; Keddy,\
    \ T.J. Fuzzy-logic modeling of land suitability for hybrid poplar across the Prairie\n\
    Provinces of Canada. Environ. Monit. Assess. 2007, 141, 79–96. [CrossRef]\n102.\
    \ Zhang, L.; Cao, B.; Bai, C.; Li, G.; Mao, M. Predicting suitable cultivation\
    \ regions of medicinal plants with Maxent modeling and\nfuzzy logics: A case study\
    \ of Scutellaria baicalensis in China. Environ. Earth Sci. 2016, 75, 361. [CrossRef]\n\
    103. Wickramasinghe, C.P.; Lakshitha, P.L.N.; Hemapriya, H.P.H.S.; Jayakody, A.;\
    \ Ranasinghe, P.G.N.S. Smart Crop and Fertilizer\nPrediction System. In Proceedings\
    \ of the 2019 International Conference on Advancements in Computing (ICAC), IEEE,\
    \ Malabe,\nSri Lanka, 5–7 December 2019.\n104. Martinez-Ojeda, C.O.; Amado, T.M.;\
    \ Dela Cruz, J.C. In Field Proximal Soil Sensing For Real Time Crop Recommendation\
    \ Using\nFuzzy Logic Model. In Proceedings of the 2019 International Symposium\
    \ on Multimedia and Communication Technology\n(ISMAC), IEEE, Quezon City, Philippines,\
    \ 19–21 August 2019.\n105. Fernando, P., Jr.; Lacatan, L. Microcontroller-Based\
    \ Soil Nutrients Analyzer for Plant Applicability using Adaptive Neuro-Fuzzy Inference\n\
    System; Mattingley Publishing Co., Inc.: Oakland, CA, USA, 2020.\n106. Kapse,\
    \ S.; Kale, S.; Bhongade, S.; Sangamnerkar, S.; Gotmare, Y. IOT Enable Soil Testing\
    \ & NPK Nutrient Detection. A J. Compos.\nTheory 2020, 13, 310–318.\n107. Fernández,\
    \ F.G.; Hoeft, R.G. Managing Soil pH and Crop Nutrients. Ill. Agron. Handb. 2009,\
    \ 24, 91–112.\n108. Akande, S.; Chukwuweike, M.E.; Olaoluwa, S.S. Development\
    \ of a Mechatronics System for Measuring Soil pH and approximating\nNPK Value.\
    \ In Proceedings of the International Conference on Industrial Engineering and\
    \ Operations Management, Monterrey,\nMexico, 3–5 November 2021.\n109. Devapal,\
    \ D. Smart agro farm solar powered soil and weather monitoring system for farmers.\
    \ Mater. Today Proc. 2020, 24,\n1843–1854. [CrossRef]\n110. File:Soil pH effect\
    \ on nutrient availability.svg-Wikimedia Commons. Available online: https://commons.wikimedia.org/wiki/\n\
    File:Soil_pH_effect_on_nutrient_availability.svg (accessed on 19 May 2021).\n\
    111. Gadap Weather—7, 10 & 14 Day Weather Forecast—Sindh, PK. Available online:\
    \ https://www.worldweatheronline.com/gadap-\nweather/sindh/pk.aspx (accessed on\
    \ 19 May 2021).\n112. Allen, R.; Pereira, L.; Raes, D.; Smith, M. Chapter 08—ETc\
    \ under soil water stress conditions. In Crop Evapotranspiration-Guidelines\n\
    for Computing Crop Water Requirements-FAO Irrigation and Drainage Paper 56; 1998;\
    \ Volume 56.\n113. Meteorology and Evaporation Function Modules for Python—Meteorology\
    \ and Evaporation Function Modules 1.0.1 Documenta-\ntion. Available online: http://python.hydrology-amsterdam.nl/moduledoc/index.html\
    \ (accessed on 19 July 2022).\n114. Richards, M. PyETo—Pyeto 0.2 Documentation.\
    \ Available online: https://pyeto.readthedocs.io/en/latest/# (accessed on\n19\
    \ July 2022).\n"
  inline_citation: '>'
  journal: Agriculture
  limitations: '>'
  pdf_link: https://www.mdpi.com/2077-0472/12/8/1277/pdf?version=1661158619
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoAT Enabled Smart Farming: Urdu Language-Based Solution for Low-Literate
    Farmers'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s22114110
  analysis: '>'
  authors:
  - Galina Ilieva
  - Tania Yankova
  citation_count: 5
  full_citation: '>'
  full_text: ">\nCitation: Ilieva, G.; Yankova, T. IoT\nSystem Selection as a Fuzzy\n\
    Multi-Criteria Problem. Sensors 2022,\n22, 4110. https://doi.org/10.3390/\ns22114110\n\
    Academic Editor: Ivan Andonovic\nReceived: 15 March 2022\nAccepted: 26 May 2022\n\
    Published: 28 May 2022\nPublisher’s Note: MDPI stays neutral\nwith regard to jurisdictional\
    \ claims in\npublished maps and institutional afﬁl-\niations.\nCopyright:\n© 2022\
    \ by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open\
    \ access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the Creative\
    \ Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nsensors\nArticle\nIoT System Selection as a Fuzzy Multi-Criteria Problem\n\
    Galina Ilieva *\nand Tania Yankova\nDepartment of Management and Quantitative\
    \ Methods in Economics, University of Plovdiv Paisii Hilendarski,\n4000 Plovdiv,\
    \ Bulgaria; tsvl@uni-plovdiv.bg\n* Correspondence: galili@uni-plovdiv.bg\nAbstract:\
    \ This research aims to analyse the applications of IoT in agriculture and to\
    \ compare the\nmost widely used IoT platforms. The problem of determining the\
    \ most appropriate IoT system\ndepends on many factors, often expressed by incomplete\
    \ and uncertain estimates. In order to ﬁnd\na feasible decision, this study develops\
    \ a multi-criteria framework for IoT solution selection in a\nfuzzy environment.\
    \ In the proposed framework, a new modiﬁcation of the Multi-Attribute Border\n\
    approximation Area Comparison (MABAC) method with a speciﬁc distance measure via\
    \ intuitionistic\nfuzzy values has been presented as a decision analysis method.\
    \ The new technique is more precise\nthan existing crisp and fuzzy analogues,\
    \ as it includes the three components of intuitionistic numbers\n(degree of membership,\
    \ degree of non-membership and hesitancy degree) and the relationships\nbetween\
    \ them. The effectiveness of the new decision-making framework has been veriﬁed\
    \ through\nan illustrative example of ranking IoT platforms.\nKeywords: IoT; Agriculture\
    \ 4.0; MCDM; MABAC method; intuitionistic fuzzy sets; distance measure\n1. Introduction\n\
    The rise of information technologies and the expansion of the Internet have trans-\n\
    formed traditional machines and devices in part of a new Internet of Things (IoT)\
    \ economy,\ngaining ground across many industrial sectors. Over the past two years,\
    \ the outbreak of\nCOVID-19 has aggravated food security and exacerbated the problem\
    \ of digital transforma-\ntion in agriculture. Agriculture 4.0, IoT in agriculture\
    \ and smart agriculture are synonyms\nof technological innovation that has fundamentally\
    \ change the business processes in the\nagricultural value chain [1]. The Internet\
    \ connects sensors, robots, agricultural machinery,\nanalytical tools and farmers\
    \ in a new and inventive way. The deployment of digital tech-\nnologies, such\
    \ as IoT, big data and machine learning (ML) boost revenues from the land,\ngreenhouses,\
    \ warehouses and food processing plants [2].\nAugmented reality is an important\
    \ direction for the digital transformation of agricul-\ntural systems. It enriches\
    \ the capabilities of ﬁeld checking and the early detection of risk\nof crop failure\
    \ and thus speeds up operations and increases yields [3]. Through enhanced\nmonitoring\
    \ and control, a “digital twin” of an agricultural system could be created. The\n\
    system’s efﬁciency is optimized by simulating the real-time behaviour of physical\
    \ assets\n(plants, harvest, machinery and personnel). The advantages of virtual\
    \ copies of agricul-\ntural objects and business processes in comparison with\
    \ classical simulation models are\nscenario management and instantaneous veriﬁcation\
    \ in a real-world context. Traversing\nthe whole range of possible changes of\
    \ ﬁelds’ parameters (light, water, nutrients, humidity\nand temperature) of digital\
    \ copies improves harvest quality and extends the post-harvest\ndurability of\
    \ grains, vegetables, fruits and nuts [4].\nThe incorporation of blockchain into\
    \ IoT platforms is also useful for farmers, suppliers\nand consumers, as this\
    \ combination guarantees the quality of production from the ﬁeld to\nthe table.\
    \ Blockchain ensures the security of data and operations in a supply chain through\n\
    cryptographic algorithms [5,6]. The ﬁfth generation of mobile telecommunications\
    \ (5G)\nallows for lower latency, which means a faster exchange of big data and\
    \ a shorter response\nSensors 2022, 22, 4110. https://doi.org/10.3390/s22114110\n\
    https://www.mdpi.com/journal/sensors\nSensors 2022, 22, 4110\n2 of 26\ntime of\
    \ web-based software. Sensors become more responsive, and farmers react to changes\n\
    in the ﬁeld in real time [7]. Predictive maintenance and the remote and centralized\
    \ control\nof operations are some examples of 5G applications in agriculture [8].\n\
    During the COVID-19 pandemic, the preventative measures (blocking, restrictions\n\
    on the movement of goods and people, social distancing, curfew and restrictions\
    \ on\nlarge gatherings) have revealed weaknesses in food supply chains and have\
    \ called into\nquestion the state of food security and farmers’ incomes. The pandemic\
    \ has revealed the\nneed for sustainable and efﬁcient agricultural value chains\
    \ [9]. In the case of unforeseen\ncircumstances, digital farming tools facilitate\
    \ the transformation of the food industry and\nimproves its ﬂexibility and resilience.\
    \ The advantage of IoT in this crisis situation is that it\noptimizes supply chains,\
    \ reduce costs and minimizes response time [10].\nThe beneﬁts of connecting physical\
    \ objects in farms to the Internet are as follows:\n•\nSaving resources (time\
    \ and labour) by remotely monitoring environmental and infras-\ntructural conditions\
    \ instead of on-site inspections;\n•\nIncreasing the efﬁciency and sustainability\
    \ of production with traceability, timeliness\nand the security of the food supply\
    \ and reduced waste;\n•\nImproving decision-making even in the case of abrupt\
    \ changes in market demand\nthrough real-time data analysis of the entire value\
    \ chain.\nThe decision-making process for IoT system selection could be supported\
    \ by methods\ntaking into account many factors in their calculations. According\
    \ to recent studies, three\nmain approaches have been developed: mathematical\
    \ programming (optimization) [11–13],\nML [14] and multi-criteria decision making\
    \ (MCDM) methods [15–26].\nOptimization models often indicate only local optimums\
    \ instead of the global solution.\nA disadvantage of ML methods is that the quality\
    \ of their solutions depends on dataset\nquality. In contrast, MCDM methods work\
    \ well even on small datasets; dozens of methods\nhave been developed for determining\
    \ object rankings and weights of attributes and their\ncombinations; the obtained\
    \ results are easily interpreted.\nEach MCDM model consists of three main elements:\
    \ a ﬁnite set of alternatives, at least\ntwo criteria and at least one decision-making\
    \ method with crisp or fuzzy estimates and\ncriteria weights. As MCDM has been\
    \ an active area of research in recent years, decision\nanalysis methods have\
    \ found applications to solve the IoT system selection problem.\nSome researchers\
    \ have proposed referential models for IoT platform selection, includ-\ning one\
    \ or more existing MCDM methods; for example, Simple Additive Weight (SAW),\n\
    Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) and\
    \ VIseKriteri-\njumska Optimizacija I Kompromisno Resenje (VIKOR) [17], a set\
    \ of MCDM methods [18]\nand the Decision-Making Trial and Evaluation Laboratory\
    \ (DEMATEL) to determine the\ncause–effect relationship of predeﬁned criteria\
    \ [19].\nAnother segment of studies has suggested new hybrid models combining\
    \ a method\nfor determining the importance of criteria weights with a multi-criteria\
    \ method. For\nexample, Mashal et al. have built a meta-model combining Analytical\
    \ Hierarchy Process\n(AHP) and SAW [20], Youssef—Best Worst Method (BWM) and TOPSIS\
    \ [21]. The Silva\nand Jardim–Goncalves model has combined AHP and Elimination\
    \ and Choice Expressing\nReality (ELECTRE) [22].\nAs the estimates of compared\
    \ IoT platforms are often inaccurate and uncertain, a\nmix of multi-criteria decision-making\
    \ and fuzzy set theory could be employed to rank\nthem [23]. Lin et al. have introduced\
    \ the probabilistic linguistic term sets (PLTSs) to express\nthe users’ preferences\
    \ of IoT platforms. Then, the authors introduced a new combination\nbetween BWM\
    \ and PLTSs for the calculation of the criteria’s importance. After that, a new\n\
    modiﬁcation of Interactive and Multi-criteria Decision Making (TODIM—according\
    \ to the\nmethod’s name in Portuguese) in probabilistic linguistic values has\
    \ been proposed to rank\nIoT platforms [15].\nKondratenko et al. have built a\
    \ Mamdani inference model for the comparison of spe-\ncialized IoT systems. The\
    \ most important criteria that determine the priority of compared\nplatforms are\
    \ reliability, dependability, safety and security [24].\nSensors 2022, 22, 4110\n\
    3 of 26\nIlieva et al. have presented a new methodology combining several MCDM\
    \ methods for\ncloud service choice in a fuzzy environment. According to this\
    \ study, service functionalities,\ncustomer support and rating and security are\
    \ the most important factors inﬂuencing cloud\nsystems evaluation. To demonstrate\
    \ the effectiveness of the pro-posed procedure, the\nauthors have solved the problem\
    \ of cloud storage analysis using the Measurement of\nAlternatives and Ranking\
    \ according to the Compromise Solution (MARCOS) method via\ntriangular fuzzy numbers\
    \ [25].\nChakraborty et al. have evaluated nine cloud service providers using\
    \ the Distance-\nBased Approach (DBA) with triangular fuzzy values of fourteen\
    \ evaluation criteria (grouped\nas quality, technological and economic factors)\
    \ [26].\nAlthough there have been many studies recently concerning the IoT system\
    \ selection\nproblem, there is no universal approach or uniﬁed procedure for its\
    \ solution. The studies\ndescribed above provide some insights on the comparison\
    \ of IoT systems, but they do also\ndemonstrate some drawbacks:\n(1)\nOften, criteria\
    \ systems include only few technical characteristics of IoT systems;\nhowever,\
    \ evaluation should also be a function of many other factors; for example,\nsocial\
    \ and organizational parameters;\n(2)\nIf IoT system assessment depends on qualitative\
    \ factors, then their estimates are often\nsubjective and should be made by a\
    \ team of experts and fuzzy numbers;\n(3)\nThe majority of the proposed fuzzy\
    \ multi-criteria solutions implement only one or\ntwo MCDM methods.\nTo overcome\
    \ these shortcomings, in this manuscript we propose a new fuzzy method-\nology\
    \ for IoT solutions’ evaluation. The selection of an appropriate IoT system according\
    \ to\nthe needs of a given agricultural company is a complex procedure, depending\
    \ on many fac-\ntors. The group multi-criteria approach has the potential to solve\
    \ this multi-factor problem.\nAlternatives include a variety of IoT (general purpose\
    \ or specialized) systems available on\nthe market. The solution to the problem\
    \ is the system that best meets the preferences of a\nparticular farm.\nThe aim\
    \ of this study was to create a methodological framework for the multi-criteria\n\
    management of the procedure for the selection of an IoT system in a fuzzy environment\n\
    with a focus on agriculture companies.\nThe tasks of this study are as follows:\n\
    (1)\npresent the most widely used IoT platforms;\n(2)\nexplore the impact of multi\
    \ sensors IoT systems on agricultural companies;\n(3)\ndevelop a conceptual framework\
    \ for the multi-criteria analysis of an IoT system;\n(4)\ncreate a modiﬁcation\
    \ of Multi-Attribute Border approximation Area Comparison\n(MABAC) for an intuitionistic\
    \ fuzzy environment;\n(5)\nverify the proposed framework and the new method through\
    \ a practical example.\nThe limitations of our study are as follows:\n1.\nThe\
    \ problem of ﬁnding the most suitable IoT system can be solved using different\n\
    approaches, but our study is limited to the decision analysis methods.\n2.\nIn\
    \ order to make an informed decision, decision-makers need to have relevant infor-\n\
    mation (expert opinions, literature sources, decision rules, etc.) for the preliminary\n\
    assessment of the need for an IoT system, the formulation of user requirements\
    \ and\nthe calculation of weighting coefﬁcients and comparison index.\n3.\nIn\
    \ the new framework, only IoT systems for which the necessary information (features,\n\
    reviews, comparisons, etc.) to build a decision matrix is provided can be evaluated.\n\
    The rest of this article is organized as follows: In Section 2, the peculiarities\
    \ of the\nmost widely used general-purpose and specialized IoT platforms for Agriculture\
    \ 4.0 are\nanalysed. Next, the previous studies on the topic of multi-criteria\
    \ selection of IoT systems\nare summarized. Section 3 presents the new multi-criteria\
    \ decision making (MCDM)\nframework for IoT system selection and a modiﬁcation\
    \ of the MABAC method with\nuncertainty in estimates of decision makers. In the\
    \ next section, the problem of IoT product\nSensors 2022, 22, 4110\n4 of 26\n\
    selection is solved using the proposed methodology. The last section summarizes\
    \ the\nobtained results and outlines directions for future work in enhancing the\
    \ multi-criteria\nmethods and expanding their applications.\n2. IoT Technology\
    \ and Its Application in Agriculture\nSmart farming represents the applications\
    \ of IoT through a variety of autonomous\ndevices connected to each other via\
    \ the global network. By using intelligent sensors, drones,\nrobots and agricultural\
    \ machinery, farmers inspect and supervise the agricultural processes,\nfrom planting,\
    \ growing and dispatching to the storage and distribution of crops [27,28].\n\
    However, managers and other stakeholders in agribusiness are still not familiar\
    \ with\nthe capabilities of IoT technology in the remote monitoring of a huge\
    \ amount of data and\ncontrolling physical objects in real-time without human\
    \ interference. In the next section,\nthe basic characteristics of IoT technology\
    \ are presented. Then, the most widely used IoT\nsystems are compared and applications\
    \ of IoT in agriculture are analysed.\n2.1. IoT Basics\nAccording to the NIST\
    \ deﬁnition, IoT is a network of devices that contains hardware,\nsoftware, ﬁrmware\
    \ and actuators which allows the devices to connect, interact and freely\nexchange\
    \ data and information [29–31]. This network encompasses computing devices,\n\
    mechanical machines and various other physical objects that have unique identiﬁers\
    \ and\nexchange data, even without human intervention [32–34].\nDuring the fourth\
    \ revolution in agriculture, farms must adopt new digital technologies\nin order\
    \ to be competitive. However, the digital transformation through IoT poses three\n\
    main technological and business challenges.\nThe ﬁrst one is the growing demand\
    \ for connectivity. The proliferation of 5G stimulates\nthe need for communication\
    \ between an increasing number of sensors. A possible solution\nto the server\
    \ overload problem is the deployment of blockchain storage in decentralized\n\
    computer networks.\nThe next challenge is related to device security and data\
    \ privacy. The threat of unau-\nthorized access to data or the replacement of\
    \ a device’s instructions requires manufacturers\nto continuously improve IoT\
    \ protection and reliability [35].\nThe third challenge is the lack of standards\
    \ unifying the requirement speciﬁcations\nin the manufacturing of IoT components.\
    \ The multitude of devices from different manu-\nfacturers using various communication\
    \ protocols hinders the portability, interoperability\nand manageability of IoT\
    \ systems. Several standardizing bodies have already established\nsome important\
    \ standards for seamless communication between different IoT systems and\namong\
    \ entities within an IoT system [36]. Unfortunately, the harmonization has not\
    \ yet\nbeen completed, which complicates the IoT development process and increases\
    \ its cost.\nIoT technology connects a variety of objects to the Internet, uniting\
    \ the virtual and\nphysical worlds. This merging of the two worlds is a prerequisite\
    \ for the more efﬁcient\nusage of available resources. IoT minimizes human efforts\
    \ because devices can connect and\ncommunicate directly with each other and perform\
    \ various tasks autonomously. Existing\nsecurity, data protection and interoperability\
    \ challenges can be resolved through the active\nengagement of stakeholders.\n\
    2.2. The Peculiarities of Major IoT Platforms\nFrom a cloud technology point of\
    \ view, IoTs platforms connect devices and applica-\ntions within a cloud ecosystem.\
    \ They are also known as IoT Platforms as a Service (PaaS),\ni.e., by using these\
    \ platforms, users create their own applications and services employing\nbuilt-in\
    \ IoT features. An IoT application usually includes the connecting of remote devices\n\
    through the cloud, collecting data from devices, remote control, analysis and\
    \ visualization\nand the management of application versions and user access rights.\
    \ This section brieﬂy\ndescribes the main features of the most widely used IoT\
    \ platforms (AWS IoT Core, MS\nAzure IoT, Google Cloud IoT Core, IBM Watson IoT\
    \ and Oracle IoT Service).\nSensors 2022, 22, 4110\n5 of 26\nAWS IoT Core (https://aws.amazon.com/iot/,\
    \ accessed on 1 March 2022) is a man-\naged cloud service that connects IoT devices\
    \ and interacts with cloud applications and other\ndevices. The platform supports\
    \ a large number of devices, processes and messages, and\nroutes those messages\
    \ reliably and securely. AWS IoT users create their own solutions with\na combination\
    \ of over 60 AWS cloud and edge services. Common service elements across\nall\
    \ deployment models are AWS IoT Greengrass, Amazon Monitron and AWS Panorama.\n\
    AWS also offers a portfolio of capabilities for edge-centric computing that includes\
    \ intelli-\ngence and inference closer to monitored events. Unfortunately, edge\
    \ cloud and on-premises\ndeployment models offer fewer capabilities, especially\
    \ relating to data management and\nanalytics [37].\nMS Azure IoT (https://azure.microsoft.com/en-us/overview/iot/,\
    \ accessed on\n1 March 2022) is a collection of Microsoft-managed cloud services\
    \ that connect, moni-\ntor, and control IoT assets. Each IoT solution is made\
    \ up of one or more IoT devices that\ncommunicate with one or more back-end services\
    \ hosted in the cloud. Azure IoT employs\nAzure platform and offers cloud, edge\
    \ and hybrid deployment options. Azure IoT services\ncan run on-premises and Azure\
    \ IoT edge solutions offer architecturally secure isolation\nthrough a hierarchical\
    \ deployment approach. Customers have access to the Microsoft\nproducts and a\
    \ marketplace for third-party software. Azure IoT can be used in many\nvertical\
    \ markets such as healthcare, retail and manufacturing [37].\nGoogle Cloud IoT\
    \ Core (https://cloud.google.com/solutions/iot, accessed on 1 March\n2022) is\
    \ a cloud service consisting of two main components: a device manager and protocol\n\
    bridges. The former registers devices with the service, so the user can monitor\
    \ and conﬁgure\nthem, while the latter can be employed by devices to connect to\
    \ Google Cloud Platform.\nTypical use cases include asset tracking, visual inspection\
    \ and quality control in retail,\nsmart parking, transportation and logistics.\n\
    IBM Watson IoT (https://cloud.ibm.com/docs/IoT?topic=IoT-iot-cloud-index, ac-\n\
    cessed on 1 March 2022) pro-vides application enablement, data and device management,\n\
    analytics, integration and security. This platform is delivered as a collection\
    \ of services\nwith the IBM Cloud or can be deployed on-premises via private cloud\
    \ capabilities. It is\ndeployed in manufacturing, utilities, transportation and\
    \ logistics. Common use cases are\npredictive maintenance and asset monitoring.\
    \ Customers use the Node-RED open-source\nprogramming language to personalize\
    \ and extend the functionality of Watson IoT [38].\nOracle IoT Cloud Service (https://docs.oracle.com/en/cloud/paas/iot-cloud/,\
    \ ac-\ncessed on 1 March 2022) can be integrated with Oracle’s middleware solutions\
    \ and enter-\nprise applications. Oracle’s industrial IoT (IIoT) are suitable\
    \ for production, asset and ﬂeet\nand service monitoring. A typical solution comprises\
    \ data management capabilities, analyt-\nics, user interfaces with custom dashboards\
    \ and built-in integrations with manufacturing,\nmaintenance and asset management\
    \ systems. These solutions can run on Oracle Cloud but\nare available in an on-premises\
    \ version via private cloud [38].\nThe ﬁve above-mentioned IoT systems share some\
    \ common characteristics. They\nare designed to be platforms with general purpose\
    \ and, therefore, they are best suitable\nfor standardized solutions. A disadvantage\
    \ of these platforms is that they are oriented\nentirely to the cloud ecosystem\
    \ of their vendor. As a result, their work processes are\nmore complex, and their\
    \ settings require specialized knowledge about the particular cloud\ninfrastructure\
    \ (especially in the AWS case). These ecosystems include predeﬁned modules\nand\
    \ applications for a variety of IoT use cases. However, their main disadvantage\
    \ is the\nlack of personalization.\nTable 1 summarizes some main features of the\
    \ presented IoT platforms. These at-\ntributes can be built into an evaluation\
    \ system for the selection of an IoT platform and\nits components.\nSensors 2022,\
    \ 22, 4110\n6 of 26\nTable 1. A comparison of the most widely used IoT platforms.\n\
    Platform Feature\nAWS\nMS Azure\nGoogle Cloud\nIBM Watson\nOracle\nIoT Core Functions\n\
    Connectivity,\nauthentication,\nrules engine,\nDeveloper mode,\nEdge SDK\nConnectivity,\n\
    authentication,\ndevice\nmanagement,\ndevice monitoring,\nIoT Edge SDK\nConnectivity,\n\
    authentication,\ndevice\nmanagement\nConnectivity,\nauthentication,\ndevice\n\
    management, Edge\ncomputing\nConnectivity,\nauthentication,\ndevice\nmanagement,\
    \ Edge\ncomputing\nEdge Computing\nSolutions\nFree RTOS 1\nIoT Edge\nEdge TPU\
    \ 2 chip\nIBM Edge app\nmanager\nIoT Edge\nData Protocols\nHTTP, MQTT,\nWebSockets\n\
    HTTP, MQTT,\nAMQP over\nWebSockets\nHTTP, MQTT\nHTTP, MQTT\nHTTP, MQTT\nData Processing\n\
    and Analytics\nS3, Kinesis,\nLambda, Dynamo\nDB, Elastic Search\nStream Analytics,\n\
    Azure Blob,\nNotiﬁcation,\nPower BI\nDataﬂow, Big Data,\nBig Query, Coding\nService\
    \ Engine\nActivity Tracker,\nLog Analysis,\nMonitoring, Pak\nfor Watson AIOps\n\
    Business\nIntelligence Cloud,\nAnalytics Cloud,\nand Mobile Cloud\nservices\n\
    1 RTOS—Real-time Operating Systems. 2 TPU—Tensor Processing Unit.\nIoT Core Functions:\
    \ The compared IoT platforms gather and store data from and\ncommunicate with\
    \ disparate IoT endpoints in a secure way. They also employ analytics\nto find\
    \ hidden patterns in the data and provide applications that enable organizations\
    \ to\nvisualize and take action on the insights extracted from the data. The five\
    \ vendors offer a\ncloud-edge hybrid model, allowing for a consistent experience\
    \ on both the edge and the cloud.\nEdge Computing Solutions: Edge computing minimizes\
    \ the latency of cloud commu-\nnication between the client and server by bringing\
    \ the infrastructure closer to the ends of\nthe network. With edge computing,\
    \ the compared platforms exchange data with less delay\nand lower cloud server\
    \ bandwidth usage. Customers can gather edge data and send it to\nthe IoT Cloud\
    \ via SDK for devices, gateway software or cloud-based IoT connectors that\ncan\
    \ do protocol translation and then send messages to the cloud services.\nCommunication\
    \ Protocols: Google Cloud IoT, IBM Watson IoT and Oracle IoT employ\nonly two\
    \ data protocols: HTTP and Message Queue Telemetry Transport (MQTT). HTTP\nprotocol\
    \ is not preferred for IoT data transfer because of its high cost, low battery\
    \ life, high\npower consumption and weight issues. In contrast, MQTT is a lightweight\
    \ IoT data proto-\ncol, but it does not support a deﬁned data representation and\
    \ device management structure\nmode. As a result, the implementation of data and\
    \ device management capabilities is\nentirely platform speciﬁc. In addition to\
    \ these two protocols, AWS IoT and Azure IoT also\nsupport WebSocket (in Azure\
    \ IoT case via Advanced Message Queuing Protocol—AMQP).\nWebSocket is an appropriate\
    \ choice for IoT networks where data is bidirectional communi-\ncated continuously\
    \ across multiple devices. AMQP, as an open standard application layer\nprotocol,\
    \ is used for transactional messages between servers.\nData Processing and Analytics:\
    \ IoT platforms offer the analytical services of the\nrespective vendor’s ecosystem.\
    \ The advantage of built-in analytics tools is that users train,\ndeploy and manage\
    \ their new AI models, and then prepare data and analyze information\nin a single\
    \ integrated environment. Unfortunately, these modules require payment to all\
    \ of\nthe above-mentioned platforms.\nEach of the presented platforms is the leader\
    \ on vertical markets in several industries.\nFor example, AWS IoT is the most\
    \ suitable for smart home deployment, while Microsoft\nAzure IoT demonstrates\
    \ high efﬁciency on the Internet of Medical Things (IoMT) market.\nGoogle Cloud\
    \ IoT brings the most value to transport companies. IBM Watson IoT and\nOracle\
    \ IoT are leaders in the management of large enterprises with complex infrastructure\n\
    and a large number of sensors, as both companies have experience in the management\
    \ of\nindustrial equipment.\nThe optimal selection of an appropriate IoT system\
    \ should not be limited to the most\nwidely used platforms and the indicators\
    \ for their comparison in Table 1. There are a\nSensors 2022, 22, 4110\n7 of 26\n\
    variety of open-source and specialized IoT alternatives, some of which even outperform\n\
    the aforementioned technological leaders in some industries.\n2.3. IoT for Agricultural\
    \ Activities\nIn traditional agriculture, due to the heterogeneity of risks and\
    \ long production cycle,\nrevenues are uncertain. The concept of intelligent agriculture\
    \ is revolutionizing the sector.\nIoT systems track the dynamic changes in farms\
    \ (meteorological conditions, soil quality,\navailability and cost of labor force),\
    \ forecast the potential risks of crop damage, plan\nactivities in advance and\
    \ take preventive measures for protection in case of emergencies.\nApplications\
    \ of IoT technology increase the yield and decrease the costs of agricultural\n\
    production without unnecessary treatment. Agriculture is no longer seen as a high-risk\
    \ and\nlabor-intensive industry because the harvest is predictable, and labor\
    \ productivity increases\nand the quality of products in the food supply chain\
    \ are guaranteed [39,40]. Although\nIoT is still not a very popular technology\
    \ in agriculture, its market is constantly growing.\nThe size of the global market\
    \ for intelligent agriculture is expected to quadruple by 2026,\nreaching $22.5\
    \ billion (compared to just over $5 billion in 2016) [41].\nIn this section, we\
    \ discuss the main application areas of IoT in the agricultural supply\nchain.\
    \ This supply chain includes of a variety of participants—input suppliers (cooperatives,\n\
    agro-dealers), farmers (growers), processors, shipping companies, wholesalers,\
    \ retailers\nand ﬁnal consumers. The digitization of agricultural supply chain,\
    \ supported by IoT\ntechnology, is depicted in Figure 1. Every business process,\
    \ performed between actors\nalong the crop trajectory, could be empowered by the\
    \ use of IoT technology, including\nploughing, sowing, irrigation, weeding and\
    \ harvesting. Each product follows its own path\nto reach customers, and every\
    \ relationship between participants (supplier-farmer, farmer-\nprocessing company\
    \ and farmer-distributor) is assisted by IoT devices. The following\nsections\
    \ consider the applications of IoT in agriculture through business processes:\
    \ supply\nof materials, crop management and distribution of food products.\nSensors\
    \ 2022, 22, x FOR PEER REVIEW \n8 of 27 \n \n \nFigure 1. IoT in the agricultural\
    \ supply chain. \n• \nSupply of agricultural materials \nIoT technology improves\
    \ the traceability of agricultural materials (seeds, minerals, \nfertilizers,\
    \ pesticides, fuel, and water) throughout the crop life cycle. IoT devices track\
    \ \nquality, location and time during materials’ transfer from suppliers to warehouses\
    \ or \nfields. To this end, IoT platforms are equipped with various data readers:\
    \ intelligent tags \n(barcodes, near field communication, RFID or low-power Bluetooth),\
    \ which are set up by \nFigure 1. IoT in the agricultural supply chain.\nSensors\
    \ 2022, 22, 4110\n8 of 26\n•\nSupply of agricultural materials\nIoT technology\
    \ improves the traceability of agricultural materials (seeds, minerals,\nfertilizers,\
    \ pesticides, fuel, and water) throughout the crop life cycle. IoT devices track\n\
    quality, location and time during materials’ transfer from suppliers to warehouses\
    \ or\nﬁelds. To this end, IoT platforms are equipped with various data readers:\
    \ intelligent tags\n(barcodes, near ﬁeld communication, RFID or low-power Bluetooth),\
    \ which are set up by\nusing a tagging inventory system. For the supply department,\
    \ IoT ensures accountability\nof costs and timely delivery with optimal routes,\
    \ schedules and balanced vehicle loads.\nThe accurate prediction of required quantities\
    \ reduces excess inventory and improves the\nefﬁciency of contract and cost management\
    \ [42,43].\n•\nCrop management\nThrough IoT platforms, farmers observe and manage\
    \ agricultural processes such as\nplanting, growing, harvesting and harvest management\
    \ via connected sensors installed in\nﬁelds or greenhouses. Agricultural companies\
    \ also apply IoT for better management of crop\nirrigation. The connected sensors\
    \ can monitor the level of precipitation and humidity and\nautomatically adjust\
    \ the irrigation schedules (precision irrigation). Data on soil chemical\ncomposition\
    \ and plant growth facilitates the selection of the most appropriate combination\n\
    of fertilizers and their amount. As a result, the crop yield conditions are optimized\
    \ and\nwater, energy and fertilizer consumption are reduced [44].\nSensors warn\
    \ farmers about pests and diseases immediately preventing their spread\nand minimizing\
    \ damages [45]. Robots and machinery in agricultural ﬁelds operate without\ndowntime\
    \ and thus reduce risks farmers face such as excessive rainfalls, ﬂoods, droughts,\n\
    freezing or toxic fertilizers. Drones are also useful in farming because they\
    \ transmit real-\ntime video and even spray various pesticides and fertilizers\
    \ [46]. Greenhouses also deploy\nmulti-sensor systems that monitor facility parameters\
    \ and plant growth and automatically\nadjust equipment to provide the most appropriate\
    \ conditions for each plant.\nThe conventional monitoring of crops in storage\
    \ requires a lot of time and resources.\nEven in the case of storage equipped\
    \ with wired sensors, operators should check the storage\nconditions on-site,\
    \ which is a continuous and laborious process. IoT systems allow more\nthan remote\
    \ sensing and notiﬁcations. The collected historical data reveal trends regarding\n\
    harvest states and offer decisions to change the method of storage or sale [47,48].\n\
    •\nAgricultural distribution\nIoT systems keep track of the movement of crops\
    \ to processing plants, distributors’\nwarehouses and consumers. Sensors in transport\
    \ containers collect and transmit data\nabout the route, location and status of\
    \ the shipment in real time. In this way, agricul-\ntural companies increase their\
    \ efﬁciency, speed up delivery time and improve customer\nservice [49,50].\nIn\
    \ agriculture, IoT redesigns business processes (preparation of soil, sowing,\
    \ adding\nfertilizers, irrigation, harvesting and storage) to protect crops and\
    \ optimize yield. The main\nadvantages of IoT applications in agriculture are\
    \ as follows:\n(1)\nIoT devices and analytics guarantee timely ﬁeld operations\
    \ under cost control;\n(2)\nRisk in terms of quality and quantity of food supply\
    \ and safety is reduced and, thus,\nthe relationships between agricultural producers\
    \ and consumers are strengthened;\n(3)\nThe agricultural supply chain becomes\
    \ efﬁcient and sustainable.\nThe stability of the IoT-based model of an agricultural\
    \ system depends on its com-\npleteness and accuracy. The proposed approach complicates\
    \ agricultural supply chain\nbut increases its stability. Implementing the model\
    \ also helps stakeholders to predict the\nlong-term consequences of their actions\
    \ and thus further bolster food security, increase\nrevenues and enhance environmental\
    \ sustainability.\nUsing IoT technology, agricultural and processing companies\
    \ can build a reliable\ninterorganizational information system integrating data\
    \ collection, business process model-\nSensors 2022, 22, 4110\n9 of 26\ning and\
    \ planning between supply chain participants for better communication and coherent\n\
    decision-making.\n2.4. IoT Solutions in Farming\nIn this section, we present some\
    \ basic features of the most widely used IoT systems\nin agriculture.\nActility\
    \ (Paris, France, 2010, https://www.actility.com/precision-agriculture, accessed\n\
    on 1 March 2022) provides detection, monitoring and control over long distance\
    \ (over\n15 km) of a wide variety of key agricultural data: soil temperature and\
    \ moisture; weather,\nrainfall and water quality; airborne pollution; crop growth;\
    \ smart connected harvesters and\nirrigation equipment; ﬁre, theft and ﬂood detection.\n\
    Arable (San Francisco, CA, USA, 2014, https://www.arable.com, accessed on 1 March\n\
    2022) sets up a new generation of IoT tools that enable farmers to take advantage\
    \ of\nadvanced sensors, wireless networks and machine learning recommendations\
    \ to improve\ncrop growth via agronomic models and intuitive interface.\nCropX\
    \ (Netanya, Israel, 2013, https://cropx.com, accessed on 1 March 2022) employs\n\
    IoT technology to analyse soil data and integrate it with crop models, satellite\
    \ imagery and\nweather forecasts to help farmers cut crop-input costs by driving\
    \ water, fertilizer, energy\nand labour savings.\nCrop Performance (San Francisco,\
    \ CA, USA, 2009, https://crop-performance.com,\naccessed on 1 March 2022) provides\
    \ geospatial analytics enabling growers and food supply\nchain to increase crop\
    \ yields, conserve resources and monitor the ecological impact of\ngrowing safe\
    \ and healthy food. Crop performance analytics create supply decisions based\n\
    upon crop yields prediction in advance of the harvest.\nCropwise Operations (former\
    \ Cropio) (Zurich, Switzerland, 2014, (https://www.\ncropwise.com/operations,\
    \ accessed on 1 March 2022) as a decision-making tool aims to\noptimize fertilization\
    \ and irrigation, and thus reduces the amount of fertilizer and water\nused. Cropwise\
    \ Operations, combining weather information and satellite data, also makes\nit\
    \ possible to monitor crops and yield forecasts.\nFarmapp (Leopold, Australia,\
    \ 2014, https://farmappweb.com, accessed on 1 March\n2022) is an Integrated Pest\
    \ Management (IPM) software-based service for crops. The\nsoftware includes a\
    \ combination of scouting and fumigation applications with sensors and\nbrings\
    \ IoT devices to the agricultural sector. Using soil sensors, spraying applications\
    \ and\nweather stations, growers are able to receive up-to-date data regarding\
    \ growing conditions.\nGrowlink (Denver, CO, USA, 2015, https://www.growlink.com,\
    \ accessed on 1 March\n2022) uses crop scheduling, labour forecasting, compliance\
    \ logging and reporting and task\nmanagement. Controllers and application give\
    \ users remote access to monitor sensor data\nin real time and control any connected\
    \ devices using a mobile phone or computer. Users\ncan add an unlimited number\
    \ of power block outlets to switch on or off any hardware such\nas ventilation\
    \ blowers, pumps, lights, dehumidiﬁers, humidiﬁers, water chillers, heaters,\n\
    fans or any other electrical device.\nKaa (Miami Beach, FL, USA, 2017, https://www.kaaiot.com/use-cases/smart-farming,\n\
    accessed on 1 March 2022) is a versatile IoT platform that can be used to create\
    \ a broad\nvariety of IoT applications, including those used for smart farming.\
    \ There is no need for\ncoding or previous IoT development experience to use this\
    \ platform.\nMothive (London, UK, 2015, http://www.terraprimagroup.co.uk, accessed\
    \ on 1 March\n2022) designs IoT solutions to collect environmental and situational\
    \ awareness data from\nany location and transform it into knowledge to support\
    \ customers using trigger alerts and\nautomatic responses. After crops, soil and\
    \ weather data are processed and correlated with\nweather and satellite data,\
    \ the system enables the prediction of crop yields and diseases\nand improves\
    \ resource usage and site management through a live alert system.\nParticle (San\
    \ Francisco, US, 2012, https://www.particle.io/agriculture, accessed on\n1 March\
    \ 2022) creates edge-to-cloud IoT development tools including development kits,\n\
    production modules and asset tracking teams. Particle offers different IoT solutions\
    \ for\nSensors 2022, 22, 4110\n10 of 26\nconnectivity, hardware, device cloud\
    \ and applications. For better connectivity reasons, it\noffers three main products:\
    \ Wi-Fi, Cellular and Mesh.\nPycno (London, UK, 2014, https://pycno.co/platform,\
    \ accessed on 1 March 2022)\nis bringing continuous data monitoring and system\
    \ control to agricultural farms. The\nwireless sensors establish a simple and\
    \ low-cost way to collect real-time weather or soil\ndata from a ﬁeld or greenhouse,\
    \ visualise it using cloud-driven analytics and drive different\ncontrol systems.\n\
    Rayven (Sydney, Australia, 2016, https://www.rayven.io/industry-solutions/agriculture-\n\
    farming-iot/, accessed on 1 March 2022) provides organizations with fast, affordable\
    \ access\nto IoT, ML and real-time analytics solutions via a drag-and-drop, codeless\
    \ platform. The\nplatform combines industrial data science and deployment services\
    \ to gather real-time\ninsights and achieve business goals.\nSemios (Vancouver,\
    \ BC, Canada, 2010, https://semios.com, accessed on 1 March 2022)\nis a scalable,\
    \ data analytics platform for growers that helps predict, identify and prevent\n\
    pest and disease pressure. Providing updates every 10 min, the platform applies\
    \ big data\nanalytics and ML to reduce and mitigate crop risks for growers.\n\
    SoilScout (Helsinki, Finland, 2013, https://soilscout.com/applications/agriculture,\n\
    accessed on 1 March 2022) optimizes water and energy usage by guaranteeing permanent\n\
    wireless monitoring. SoilScout wirelessly provides critical insight into data\
    \ from deep\nbelow the surface. Farmers and agriculture professionals employ SoilScout\
    \ to understand\ntheir ﬁelds, optimize soil conditions for better growth and improve\
    \ crop production, also\nreducing operational costs and water consumption (https://www.linkedin.com/company/\n\
    soil-scout/about/, accessed on 1 March 2022)\nThingWorx (Boston, MA, USA, 2012,\
    \ https://www.ptc.com/products/iot, accessed\non 1 March 2022), a PTC Technology\
    \ product, is an IoT and augmented reality platform\nfor industrial enterprises.\
    \ The platform connects devices and systems, normalizes and\nanalyses data, implements\
    \ applications and user interfaces, manages and remotely controls\ndevices and\
    \ delivers new types of experiences through technologies like augmented reality.\n\
    Depending on their purpose, the IoT systems described above can be divided into\
    \ two\nmain groups:\n(1)\nIoT platforms for application development—Actility,\
    \ Kaa, Particle, Rayven, Cropwise\nOperations and ThingWorx;\n(2)\nIoT systems\
    \ (intelligent sensors and analytical platform)—Arable, CropX, CropPerfor-\nmance,\
    \ Farmapp, Growlink, Mothve, Pucho, Semios and SoilScout.\nSome IoT products are\
    \ industry independent, while others are speciﬁcally intended for\nagriculture;\
    \ for example, Farmapp and Growlink—greenhouses automation; Arable, CropX,\nCropPerformance,\
    \ Mothive, Semios and SoilScout—crop management. The majority of\nagricultural\
    \ IoT software is proprietary, while some IoT platforms are open source (for\n\
    example, Kaa and Particle).\nIoT technology has various applications in smart\
    \ agriculture. It overcomes the depen-\ndence on human labor and meteorological\
    \ conditions by automating processes such as\nfertilization and pest control.\
    \ Intelligent sensors and devices track the entire lifecycle of\nplants, increasing\
    \ yields through more efﬁcient use of resources (precise irrigation, control\n\
    of soil quality, rapid detection of growth abnormalities and local treatment with\
    \ pesticides).\nImplementing IoT systems, farmers deliver products with better\
    \ quality at a lower price.\nDespite the many beneﬁts of IoT, this technology\
    \ has some disadvantages; for example,\nplanning, building and managing such a\
    \ system is often a complicated project that could\nbe implemented only by experts\
    \ with a variety of IT skill sets and expertise such as IoT,\ndata analysis and\
    \ web development.\n3. Methodological Framework for IoT Platforms Evaluation\n\
    In this section, we introduce the basic components of multi-criteria decision-making\n\
    theory, formulate the selection of IoT system as a MCDM problem, present new theoretical\n\
    Sensors 2022, 22, 4110\n11 of 26\nframework for reliable ranking of alternatives\
    \ and propose a new MABAC modiﬁcation\nfor multi-criteria decision making.\n3.1.\
    \ Main Components of MCDM Theory\nThe goal of MCDM (multi-criteria analysis) is\
    \ to determine the relative signiﬁcances or\npriorities of a set of N alternatives\
    \ according to a given set of M criteria (attributes). Some\nof the criteria can\
    \ be maximizing (beneﬁcial), while others can be minimizing (cost). The\nsolution\
    \ of the problem of multi-criteria analysis consists of two stages: (1) describing\
    \ the\nalternatives and evaluation criteria and developing the criteria weights;\
    \ (2) aggregating\nperformance and ranking of alternatives.\nAfter selecting sets\
    \ of alternatives and determining the most important criteria, the\ninitial decision\
    \ matrix X is developed:\nX =\nA1\nA2\n. . .\nAN\nC1\nC2\n. . .\nCM\n\n\n\
    x11\nx12\n. . .\nx1M\nx21\nx22\n. . .\nx2M\n. . .\n. . .\n. . .\n. . .\nxN1\n\
    xN2\n. . .\nxNM\n\n\n,\nwhere xij (xij ≥ 0) is the value of i-th alternative\
    \ on j-th criterion. Expert evaluations, results\nobtained from laboratory experiments,\
    \ industrial measurements or computer simulations\ncan be used to ﬁll in matrix\
    \ X.\nThe weighting coefficients of the criteria are described by vector W =\n\
    \x02\nw1\nw2\n. . .\nwM\n\x03\n,\nwhere wj (0 < wj < 1) is the relative weight\
    \ of the j-th criterion and ∑M\nj=1 wj = 1.\nDuring the ﬁrst stage, the weights\
    \ of criteria are calculated according to their impor-\ntance for decision makers.\
    \ Methods such as AHP, DEMATEL, Stepwise Weight Assessment\nRatio Analysis (SWARA),\
    \ entropy method, BWM or Full Consistency Method (FUCOM)\ncan be employed. While\
    \ the calculations in AHP and DEMATEL are based on matrix of\npairwise comparisons,\
    \ other methods require less input data. For example, for FUCOM, it\nis sufﬁcient\
    \ to set ranking of weights and ratios between adjacent coefﬁcients.\nDuring the\
    \ second stage, the ranking of compared alternatives is performed by multi-\n\
    attribute decision-making algorithms such as SAW, VIKOR, Complex Proportional\
    \ As-\nsessment (COPRAS), Additive Ratio Assessment (ARAS), TOPSIS, Weighted Aggregated\n\
    Sum Product Assessment (WASPAS), Evaluation based on Distance from Average Solution\n\
    (EDAS), Multi-Attributive Border approximation Area Comparison (MABAC), Combina-\n\
    tive Distance-based Assessment (CODAS), Multi-Objective Optimization on the basis\
    \ of\nRatio Analysis (MOORA), TODIM, MARCOS or Range of Values (ROV).\nThe above-mentioned\
    \ multi-criteria methods belong to two main groups, with additive\nweighted functions\
    \ (SAW, WASPAS, MOORA, ROV) and according to the distance to the\nbest and worst\
    \ or average alternatives (TOPSIS, VIKOR, COPRAS, ARAS, EDAS, MABAC,\nCODAS, TODIM,\
    \ MARCOS). The variety of multi-criteria methods allow for the different\npoints\
    \ of view of decision-makers to be taken into account when evaluating alternatives.\n\
    The ranking of alternatives is obtained after applying the preferred multi-criteria\n\
    method. The alternative with the highest performance is the best choice among\
    \ the alterna-\ntives set.\n3.2. Conceptual Framework for IoT System Selection\n\
    An IoT system connects a multitude of devices in an ecosystem using different\
    \ network\nand data protocols. A typical IoT system includes several main components:\n\
    •\nIoT devices—a set of connected sensors, appliances, vehicles, industrial robots;\n\
    •\ngateways—to link local devices network to Internet;\n•\nnetwork servers—to\
    \ accept and transfer IoT data usually in cloud data centers;\n•\ncloud applications—for\
    \ IoT data processing;\n•\nuser interface—to visualize IoT data, track KPIs and\
    \ send commands back to IoT devices.\nSensors 2022, 22, 4110\n12 of 26\nThe variety\
    \ of IoT platforms and the many possible combinations of their features\ncomplicate\
    \ the procedure of selecting the best alternative and underscore the necessity\
    \ of a\nrigorous theoretical framework for the IoT platform selection problem\
    \ [51].\nLet IoT_Alternatives\n=\n{A1, A2, . . . , AN} be a given set of systems\
    \ and\nIoT_Criteria = {C1, C2, . . . , CM} be a set of criteria. The features\
    \ set can include technical,\neconomic and environmental characteristics; for\
    \ example, scalability, edge intelligence\nand support; key performance indicators\
    \ and price model; energy consumption and the\nability to generate renewable energy.\
    \ Each alternative Ai ∈ IoT_Alternatives, i = 1, N\ncorresponds to a subset of\
    \ IoT_Criteria.\nThe problem is to rank the given systems according to their evaluations\
    \ in a decision\nmatrix, denoted as EvaluationsN×M for the deﬁned set of criteria.\n\
    Given that each IoT system could be characterized by using vague assessments for\n\
    each criterion, the core of our new framework should be the fuzzy MCDM approach.\
    \ The\nproposed conceptual framework consists of seven steps, as depicted in Figure\
    \ 2.\nSensors 2022, 22, x FOR PEER REVIEW \n13 of 27 \n \n \nNext, in the second\
    \ stage, a suitability index τ is calculated as a measure of company’s \nreadiness\
    \ for IoT deployment. If the index value obtained for a particular organization\
    \ is \nlarger than a predefined threshold, the company could be considered as\
    \ suitable for IoT \ntechnology adoption, and the selection process can continue\
    \ to Step 2. Otherwise, it \nshould go to the end of the IoT platform selection\
    \ process. \n \nFigure 2. A flowchart of the proposed framework for IoT system\
    \ selection. \nStep 2. Development of user requirements specification for IoT\
    \ system \nFigure 2. A ﬂowchart of the proposed framework for IoT system selection.\n\
    Sensors 2022, 22, 4110\n13 of 26\nStep 1. Exploring user’s IoT system needs\n\
    In the ﬁrst stage of this step, in order to collect data about a company’s business\
    \ model,\nwe propose to apply the survey method. There are many questions that\
    \ could be listed in the\nsurvey form; for example, needs (yes/no) for high availability,\
    \ streaming data availability,\nextensive data support, ofﬂine functionality,\
    \ real time analytics and visualization tools.\nNext, in the second stage, a suitability\
    \ index τ is calculated as a measure of company’s\nreadiness for IoT deployment.\
    \ If the index value obtained for a particular organization is\nlarger than a\
    \ predeﬁned threshold, the company could be considered as suitable for IoT\ntechnology\
    \ adoption, and the selection process can continue to Step 2. Otherwise, it should\n\
    go to the end of the IoT platform selection process.\nStep 2. Development of user\
    \ requirements speciﬁcation for IoT system\nIn order to collect data about consumer\
    \ requirements, the survey method is used once\nagain. The questionnaire consists\
    \ of several question groups, corresponding to the various\naspects of an autonomous\
    \ company’s equipment (things, gateway, cloud, data analytics\nand user interface).\
    \ At the end of this step, the minimal values of features of a preferred\nIoT\
    \ platform are deﬁned. Additionally, a matrix for the comparison of criteria importance\n\
    is ﬁlled.\nRemark: A team of experts takes part in Step 1 and Step 2 of the theoretical\
    \ framework.\nThese experts may be employees of the company or external specialists\
    \ in the ﬁeld of IoT.\nStep 3. Search for a list of available IoT systems\nIn\
    \ this step, a list of available IoT products (general purpose and/or industry-speciﬁc;\n\
    open-source and/or proprietary) on the market that satisfy user’s requirements\
    \ from Step 2\nis obtained. To ﬁll this list, an online data search and literature\
    \ review could be employed.\nStep 4. Design of multi-criteria system for IoT systems’\
    \ evaluation\nIn this step, a multi-criteria hierarchical evaluation index for\
    \ IoT systems comparison\nis proposed. It encompasses different groups of indicators\
    \ with speciﬁc relative weights\ndepending on their importance for a company’s\
    \ business processes. This composite index\nis ﬂexible and allows for other groups\
    \ and indicators to be considered for incorporation in\nit, depending on users’\
    \ preferences.\nStep 5. Determination of decision matrix and preprocessing with\
    \ calculation of weight-\ning coefﬁcients\nFirst, based on data about the company’s\
    \ industry and user requirements speciﬁcation\n(Step 2), available datasets for\
    \ IoT systems’ comparison (Step 3) and personalized multi-\ncriteria evaluation\
    \ system (Step 4), the corresponding assessments are ﬁlled in the decision\nmatrix.\
    \ In the case of Likert scale assessments, they could be transformed in intuitionistic\n\
    fuzzy numbers (IFNs) using the 3-touple (Agree, Disagree, Neutral). The conversion\
    \ is\nalso possible for other advanced fuzzy sets such as Pythagorean (2013),\
    \ picture (2013),\nFermatean (2020) and other fuzzy sets. If there are categorical\
    \ variables, they are converted\nin advance into linguistic variables. In the\
    \ case that alternatives are evaluated by a group\nof experts, the decision matrix\
    \ is ﬁlled after the arithmetic means aggregation of their\nassessments. In this\
    \ way, the evaluations of each IoT system’s feature are calculated.\nSecond, the\
    \ values of weighting coefﬁcients are determined. The input data for\ncalculations\
    \ is the matrix of comparison of importance of IoT features by pairs (Step 2).\n\
    In the case of a hierarchy of dimensions, the comparison should be provided for\
    \ each\nhierarchical level from the top to the bottom. The weighting coefﬁcients\
    \ are calculated by\nusing weight determination methods in crisp or fuzzy values.\n\
    Remark: In order to avoid a possible incongruity between some criteria, two different\n\
    approaches can be applied. One of them includes some weight determination methods,\n\
    such as AHP or the Analytic Network Process (ANP). These methods check the consistency\n\
    of pairwise comparisons made by participants. The other approach is Inter-criteria\
    \ Decision\nAnalysis, which allows for removing any redundant criteria or objects\
    \ from the original\ninput data. Both approaches minimize discrepancies in participants’\
    \ opinions.\nStep 6. Execution of multi-criteria decision-making methods\nSensors\
    \ 2022, 22, 4110\n14 of 26\nThis step calculates the ranking of IoT systems using\
    \ one or several MCDM methods\nwith crisp or fuzzy values.\nStep 7. Analysis of\
    \ obtained results\nOnly the top-ranked alternatives from Step 6 are taken into\
    \ consideration. Finally,\ndecision-makers select the product that is the most\
    \ appropriate for the company’s purposes.\nAt the end of the procedure, the IoT\
    \ system with the greatest potential to enhance\ncompetitiveness will be deployed.\n\
    The advantages of the new framework are: (1) it implements a variety of (group)\n\
    methods for weight determination and multi-criteria analysis and their combinations;\n\
    (2) alternatives assessments could be expressed not only by real numbers, but\
    \ also by a\nvariety of fuzzy numbers or by fuzzy relations; (3) assessments can\
    \ be made by a group of\nexperts; (4) it is ﬂexible and can be further extended\
    \ to include new multi-criteria methods\nand types of assessments (such as advanced\
    \ fuzzy sets).\n3.3. New MABAC Modiﬁcation for Intuitionistic Fuzzy Environment\n\
    The Multi-Attribute Border Approximation Area Comparison (MABAC) method is\npart\
    \ of the MCDM group, and it determines similarity between each alternative and\
    \ the\nbest and worst value for each attribute using distance metrics. MABAC ranks\
    \ the given\nopportunities according to their distance to the benchmarking values\
    \ [52].\nThe classical MABAC method consists of six steps, described as follows:\n\
    Step 1. Input of the decision matrix and weighting coefﬁcients.\nLet xij refers\
    \ to the decision value related to the assessment of the i-th alternative\nagainst\
    \ the j-th criteria in decision matrix Evaluations and wj, j = 1, M are weighting\n\
    coefﬁcients of criteria.\nStep 2. Normalization.\nThe normalized matrix T =\n\x02\
    \ntij\n\x03\nN×M is calculated as:\ntij =\n\n\n\n\n\nxij−xjmin\nxjmax−xjmin\
    \ , j ∈ B;\nxij−xjmax\nxjmin−xjmax , j ∈ C.\nwhere xjmax = max\nj (x1, x2, . .\
    \ . , xM), xjmin = min\nj (x1, x2, . . . , xM), B denotes the set of\nmaximizing\
    \ criteria and C is the group of minimizing criteria.\nStep 3. Weighted matrix.\n\
    Let V =\n\x02\nvij\n\x03\nN×M be the weighted normalized decision matrix, where\
    \ vij refers to the\nweighted normalized decision value:\nvij = wjtij\nStep 4.\
    \ Matrix of border approximation area.\nThe border approximation area G of each\
    \ criterion is deﬁned as follows:\ngj =\nN\n∏\ni=1\nv1/N\nij\n.\nStep 5. Matrix\
    \ of distance to the border approximation area.\nThe matrix of distance to the\
    \ border approximation area is calculated as follows:\nqij = vij − gj, i = 1,\
    \ N,\nwhere qij is the distance to the border approximation area.\nSensors 2022,\
    \ 22, 4110\n15 of 26\nThe belonging of alternative Ai to the approximation area\
    \ (G, G+ or G−) is determined\non the basis of the following equation:\nAi ∈\n\
    \n\n\nG+, i f qij > 0\n0, i f qij = 0\nG−, i f qij < 0\nStep 6. Alternatives’\
    \ rank. The total distance of each alternative to the border approxi-\nmation\
    \ area is given by the next formula:\nSi =\nM\n∑\nj=1\nqij.\nThe rank the alternatives\
    \ is based on Si values, sorted in descending order [52].\nWe propose an intuitionistic\
    \ version of the MABAC algorithm. Intuitionistic fuzzy\nsets (1986) are an extension\
    \ of Zadeh’s fuzzy sets (1965) and more than thirty-ﬁve years\nof research reveals\
    \ their potential to model the vagueness and ambiguity in real-world\nproblems.\
    \ With their three semantic components (degree of membership, degree of non-\n\
    membership and hesitancy degree), intuitionistic fuzzy numbers are more expressive\
    \ than\nclassic fuzzy numbers. Besides that, the arithmetic operations with IFNs\
    \ are relatively\nsimple, compared to those of their advanced successors.\nIn\
    \ case of intuitionistic fuzzy assessments of alternatives, the above-mentioned\
    \ calcu-\nlations are made according to the rules of intuitionistic fuzzy arithmetic.\n\
    An intuitionistic fuzzy number (IFN) is characterized by θ = (µθ, ηθ), where µθ\
    \ is\ndegree of membership (truth), ηθ is degree of non-membership (falsity),\
    \ πθ = 1 − µθ − ηθ\nis hesitancy degree and it holds µθ, ηθ ∈ [0, 1] and 0 ≤ µθ\
    \ + ηθ ≤ 1. Then,\ns(θ) = µ + µ(1 − µ − η),\n(1)\nis said to be score function\
    \ of an IFN θ [53].\nLet A = (µ1, η1) and B = (µ2, η2) be two intuitionistic fuzzy\
    \ numbers. The arithmetic\noperations with these intuitionistic fuzzy numbers\
    \ are deﬁned as follows:\nAddition : A + B = (µ1 + µ2 − µ1µ2, η1η2)\nSubtraction\
    \ : A − B =\n(\n⟨ µ1−µ2\n1−µ2 , η1\nη2 ⟩, i f 0 ≤\nη1\nη2 ≤ 1−µ1\n1−µ2 ≤ 1,\n\
    ⟨0, 1⟩, otherwise.\nMultiplication: A × B = (µ1µ2, η1 + η2 − η1η2)\nDivision :\
    \ A / B =\n(\n⟨ µ1\nµ2 , η1−η2\n1−η2 ⟩, i f 0 ≤\nµ1\nµ2 ≤ 1−η1\n1−η2 ≤ 1,\n⟨0,\
    \ 1⟩, otherwise.\nThe λ times of A is given by the next rule [54]:\nλA = ⟨1 −\
    \ (1 − µ1)λ, η1λ⟩.\nIn the new MABAC version, in order to calculate the distance\
    \ to the border approxima-\ntion area (Step 5) in intuitionistic fuzzy environment,\
    \ we employ a new similarity measure\nS1\nGC between Ap and Aq alternatives, assessed\
    \ by intuitionistic fuzzy sets according to the\nfollowing formula [55]:\nS1\n\
    GC\n\0Ap, Aq\n\x01 = 1 −\nv\nu\nu\nt\n1\n12M\nM\n∑\nj=1\nh\n(Dµj2 + Dηj2)Dπj2\
    \ + 2\n\x10\nDminj\n2 + Dmaxj2\n\x11i\nSensors 2022, 22, 4110\n16 of 26\nwhere\
    \ Ap\n=\n\b⟨µpj, ηpj, j = 1, M⟩\n\t\n, Aq\n=\n\b⟨µqj, ηqj, j = 1, M⟩\n\t\n, Dµpj\n\
    =\nµpj − µqj,\nDηpj = ηpj − ηqj, πpj = 1 − µpj − ηpj, πqj = 1 − µqj − ηqj, Dπj\
    \ = 2 −\n\f\fπpj − πqj\n\f\f,\nDminj = min\n\x02\nµpj, µqj\n\x03 − min\n\x02\n\
    µqj, ηpj\n\x03\nand Dmaxj = max\n\x02\nµpj, ηqj\n\x03 − max\n\x02\nµqj, ηpj\n\x03\
    \n.\nThis distance formula employs intuitionistic fuzzy numbers, which means that\
    \ the\nchoice is based on more accurate estimation. The assessments’ representation\
    \ in IFNs com-\nprises a pair of semantically opposite values—membership (truth)\
    \ and non-membership\n(falsity) degree. The advantage of utilized formula is that\
    \ the similarity between intuitionis-\ntic fuzzy sets is calculated in three-dimensional\
    \ space, using additionally the third member-\nship degree–hesitancy. The novelty\
    \ of this formula is that here the similarity depends on\nthe difference between\
    \ the maximum and the minimum of the cross-evaluation factor.\nIn order to assess\
    \ the performance of IoT platforms objectively, we propose a new\nmodiﬁcation\
    \ of MABAC for intuitionistic fuzzy environment. Intuitionistic uncertainty and\n\
    hesitancy degrees account for differences in decision makers’ estimates more accurately\n\
    than classical fuzzy numbers. In addition, the existing intuitionistic aggregating\
    \ operators\nand distance metrics successfully combine individual estimates into\
    \ a complex measure of\nthe quality of compared alternatives. The main disadvantage\
    \ of the proposed method lies\nin the higher time complexity of its similarity\
    \ formula compared to the classical MABAC.\nHowever, the increase in computing\
    \ time is compensated by more accurate measurement\nof the distance between the\
    \ given IoT systems.\n4. Veriﬁcation of MCDM Conceptual Framework\nIn this section,\
    \ we apply the new methodological framework to solve a practical\nproblem for\
    \ IoT platform selection. Then, the IoT systems are estimated by using new\nMABAC\
    \ modiﬁcation with intuitionistic fuzzy values. Finally, we discuss the performance\n\
    of the proposed enhanced multi-criteria method.\n4.1. Practical Example\nLet AF\
    \ be a randomly selected company exposed to an IoT platform selection prob-\n\
    lem. The beneﬁts of IoT for remote, distributed and continuous control over traditional\n\
    software are numerous. The problem is how to ﬁnd the best IoT-based system for\
    \ the\nparticular company.\nStep 1. A team of experts from company AF ﬁll in the\
    \ questionnaire about their IoT\nsystem’s requirements [51]. Let the execution\
    \ of Step 1 of the proposed framework show\nthat the company’s AF suitability\
    \ index is greater than the given threshold.\nStep 2. By using a survey method,\
    \ the minimal user requirements for IoT platform are\ndetermined and a comparison\
    \ matrix of weighting coefﬁcients is ﬁlled in. Respondents\nevaluate the IoT platforms’\
    \ features using ﬁve-point Likert scale from “totally agree”\n(corresponding to\
    \ 5) to “totally disagree” (corresponding to 1).\nStep 3. In this illustrative\
    \ example, we utilize an IoT platforms’ dataset, collected\nfrom Ullah et al.\
    \ [51]. By using online search and literature review the list of IoT platforms\n\
    is determined. The list consists of ﬁve IoT-based products (A1, A2, . . . , A5).\
    \ The IoT-\nbased platforms are as follows: A1—AWS IoT, A2—MS Azure IoT, A3—Google\
    \ Cloud IoT,\nA4—IBM Watson IoT, and A5—Oracle IoT.\nStep 4. In this step, an\
    \ evaluation index C is constructed, C =\n\x02\nCj\n\x03\n, j = 1, 21. The\nassessments\
    \ of alternatives by criteria are obtained by survey of the experts’ team. Each\n\
    criterion represents a product feature of IoT platforms: C1—scalability, C2—ﬂexibility,\n\
    C3—data analytics, C4—disaster recovery, C5—stability, C6—security, C7—data ownership,\n\
    C8—protocol support, C9—system performance, C10—time to market, C11—legacy architec-\n\
    ture, C12—attractive interface, C13—pricing model, C14—cloud ownership, C15—interoperability,\n\
    C16—application environment, C17—hybrid cloud, C18—platform migration, C19—previous\n\
    experience, C20—Edge intelligence, and C21—bandwidth [51].\nStep 5. Input of decision\
    \ matrix and criteria weights\nSensors 2022, 22, 4110\n17 of 26\nThe decision\
    \ matrix values are converted into intuitionistic fuzzy numbers. The\nimportance\
    \ assessments are interpreted as intuitionistic fuzzy numbers and after that,\
    \ they\nare converted into crisp values by using the score function.\nStep 6.\
    \ By using preferred MCDM methods, the scores and rankings of given IoT\nplatforms\
    \ are calculated.\nStep 7. Results’ analysis.\nIn the analysis of results, only\
    \ IoT platforms that have been top ranked with preferred\nMCMD methods are left.\
    \ In this step, decision-makers select the most suitable IoT product.\nThe detailed\
    \ calculations from Step 5, Step 6 (IFNs MABAC) and Step 7 are available\nin the\
    \ next section.\n4.2. MCDM Using IFSs MABAC\nStep 1. Input of decision matrix\
    \ and weighting coefﬁcients\nThe experts’ estimates (linguistic variables) and\
    \ the importance of criteria (as agreed,\ndisagreed and neutral percentages) according\
    \ to questionnaire answers are ﬁlled in Table 2.\nThe linguistic variables are\
    \ converted into crisp numbers using a simple correspondence\nrule. The obtained\
    \ values are written in the decision matrix Evaluations =\n\x02\nxij\n\x03\n5×21.\n\
    Table 2. Experts’ estimates and the importance of criteria for IoT platforms assessment\
    \ (linguistic\nvariables).\nCriteria\nA1\nA2\nA3\nA4\nA5\nImportance (%)\nAgree\n\
    Neutral\nDisagree\nC1\nyes\nyes\nyes\nyes\nyes\n93%\n7%\n0%\nC2\nyes\n-\nyes\n\
    -\nyes\n93%\n7%\n0%\nC3\nyes\nyes\nyes\nyes\nyes\n93%\n7%\n0%\nC4\nyes\nyes\n\
    no\nno\nno\n93%\n7%\n0%\nC5\nyes\nyes\nyes\n-\n-\n93%\n7%\n0%\nC6\nhigh\nhigh\n\
    high\nhigh\nhigh\n93%\n7%\n0%\nC7\n-\nyes\n-\n-\n-\n93%\n7%\n0%\nC8\nyes\nyes\n\
    -\nyes\nyes\n93%\n7%\n0%\nC9\nyes\n-\nyes\nyes\n-\n93%\n7%\n0%\nC10\nyes\nyes\n\
    -\n-\nyes\n86%\n7%\n7%\nC11\nyes\n-\n-\n-\nyes\n86%\n14%\n0%\nC12\nyes\nyes\n\
    -\nno\n-\n86%\n14%\n0%\nC13\nbad\nbad\ngood\n-\n-\n79%\n21%\n0%\nC14\nyes\nyes\n\
    yes\n-\nyes\n79%\n21%\n0%\nC15\nyes\n-\n-\n-\nyes\n79%\n14%\n7%\nC16\nyes\nyes\n\
    yes\nyes\nyes\n71%\n29%\n0%\nC17\nyes\nyes\n-\n-\n-\n64%\n36%\n0%\nC18\nyes\n\
    yes\n-\n-\n-\n64%\n29%\n7%\nC19\nyes\nyes\n-\n-\n-\n64%\n29%\n7%\nC20\nyes\nyes\n\
    yes\n-\nyes\n57%\n29%\n14%\nC21\n-\n-\ngood\n-\n-\n57%\n29%\n14%\nRemark: This\
    \ table shows the transposed input matrix. Reprinted with permission from Ref.\
    \ [51]. 2020, IEEE.\nStep 2. Normalization.\nSensors 2022, 22, 4110\n18 of 26\n\
    The normalized matrix T =\n\x02\ntij\n\x03\n5×21 is calculated as:\ntij =\n\n\
    \n\n\n\nxij−xjmin\nxjmax−xjmin , j ∈ B;\nxij−xjmax\nxjmin−xjmax , j ∈ C.\n\
    In our case, the criteria are only maximizing. Missing values are replaced with\
    \ mean\naverage value of the corresponding criteria.\nThe importance of each factor\
    \ is calculated according to the score function formula,\nwhere agreed, disagreed\
    \ and neutral percentages correspond to positive, negative and\nhesitance memberships’\
    \ values, respectively. The ﬁnal weights wj, j = 1, 21 are normalized\nsuch that:\n\
    21\n∑\nj=1\nwj = 1.\nThe obtained weighting coefﬁcients are as follows: w1 = w2\
    \ = . . . = w9 = 0.051,\nw10 = w16 = 0.047, w11 = w12 = 0.05, w13 = w14 = 0.049,\
    \ w15 = 0.046, w17 = 0.045,\nw18 = w19 = 0.042, and w20 = w21 = 0.038.\nThe obtained\
    \ crisp values after normalization are shown in Table 3.\nTable 3. Normalized\
    \ decision matrix T and weighted coefﬁcients wj (crisp values).\nA1\nA2\nA3\n\
    A4\nA5\nwj\nC1\n0.950\n0.950\n0.950\n0.950\n0.950\n0.051\nC2\n0.950\n0.570\n0.950\n\
    0.570\n0.950\n0.051\nC3\n0.950\n0.950\n0.950\n0.950\n0.950\n0.051\nC4\n0.950\n\
    0.950\n0.050\n0.050\n0.050\n0.051\nC5\n0.950\n0.950\n0.950\n0.570\n0.570\n0.051\n\
    C6\n0.950\n0.950\n0.950\n0.950\n0.950\n0.051\nC7\n0.191\n0.950\n0.191\n0.191\n\
    0.191\n0.051\nC8\n0.950\n0.950\n0.760\n0.950\n0.950\n0.051\nC9\n0.950\n0.570\n\
    0.950\n0.950\n0.570\n0.051\nC10\n0.950\n0.950\n0.570\n0.570\n0.950\n0.047\nC11\n\
    0.950\n0.381\n0.381\n0.381\n0.950\n0.050\nC12\n0.950\n0.950\n0.390\n0.050\n0.390\n\
    0.050\nC13\n0.050\n0.050\n0.950\n0.210\n0.210\n0.049\nC14\n0.950\n0.950\n0.950\n\
    0.760\n0.950\n0.049\nC15\n0.950\n0.381\n0.381\n0.381\n0.950\n0.046\nC16\n0.950\n\
    0.950\n0.950\n0.950\n0.950\n0.047\nC17\n0.950\n0.950\n0.381\n0.381\n0.381\n0.045\n\
    C18\n0.950\n0.950\n0.381\n0.381\n0.381\n0.042\nC19\n0.950\n0.950\n0.381\n0.381\n\
    0.381\n0.042\nC20\n0.950\n0.950\n0.950\n0.619\n0.950\n0.038\nC21\n0.191\n0.191\n\
    0.950\n0.191\n0.191\n0.038\nStep 3. Decision matrix (IFNs) and its normalization\n\
    Sensors 2022, 22, 4110\n19 of 26\nThe crisp values of normalized matrix are converted\
    \ into intuitionistic fuzzy numbers\nby Visalakshi et al. formula [56]\nµ = 1\
    \ − (1 − µ)λ\nη = (1 − µ)λ(λ+1),\nwhere µ is the crisp value and λ ∈ [0, 1], here\
    \ λ = 0.5 (Table 4).\nTable 4. The decision matrix T (IFNs).\nA1\nA2\nA3\nA4\n\
    A5\nC1\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\n\
    C2\n0.776\n0.106\n0.001\n0.999\n0.776\n0.106\n0.001\n0.999\n0.776\n0.106\nC3\n\
    0.776\n0.106\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\nC4\n0.776\n\
    0.106\n0.776\n0.106\n0.025\n0.962\n0.025\n0.962\n0.025\n0.962\nC5\n0.776\n0.106\n\
    0.776\n0.106\n0.776\n0.106\n0.001\n0.999\n0.001\n0.999\nC6\n0.776\n0.106\n0.776\n\
    0.106\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\nC7\n0.001\n0.999\n0.776\n0.106\n\
    0.001\n0.999\n0.001\n0.999\n0.001\n0.999\nC8\n0.776\n0.106\n0.776\n0.106\n0.001\n\
    0.999\n0.776\n0.106\n0.776\n0.106\nC9\n0.776\n0.106\n0.001\n0.999\n0.776\n0.106\n\
    0.776\n0.106\n0.001\n0.999\nC10\n0.776\n0.106\n0.776\n0.106\n0.001\n0.999\n0.001\n\
    0.999\n0.776\n0.106\nC11\n0.776\n0.106\n0.001\n0.999\n0.001\n0.999\n0.001\n0.999\n\
    0.776\n0.106\nC12\n0.776\n0.106\n0.776\n0.106\n0.001\n0.999\n0.025\n0.962\n0.001\n\
    0.999\nC13\n0.025\n0.962\n0.025\n0.962\n0.776\n0.106\n0.001\n0.999\n0.001\n0.999\n\
    C14\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\n0.001\n0.999\n0.776\n0.106\nC15\n\
    0.776\n0.106\n0.001\n0.999\n0.001\n0.999\n0.001\n0.999\n0.776\n0.106\nC16\n0.776\n\
    0.106\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\n0.776\n0.106\nC17\n0.776\n0.106\n\
    0.776\n0.106\n0.001\n0.999\n0.001\n0.999\n0.001\n0.999\nC18\n0.776\n0.106\n0.776\n\
    0.106\n0.001\n0.999\n0.001\n0.999\n0.001\n0.999\nC19\n0.776\n0.106\n0.776\n0.106\n\
    0.001\n0.999\n0.001\n0.999\n0.001\n0.999\nC20\n0.776\n0.106\n0.776\n0.106\n0.776\n\
    0.106\n0.001\n0.999\n0.776\n0.106\nC21\n0.001\n0.999\n0.001\n0.999\n0.776\n0.106\n\
    0.001\n0.999\n0.001\n0.999\nThe weighted normalized matrix V =\n\x02\nvij\n\x03\
    \n5×21 is calculated by using formula for λ\ntimes (Table 5):\nvij = wjtij\nTable\
    \ 5. The weighted decision matrix V (IFNs).\nA1\nA2\nA3\nA4\nA5\nC1\n0.073\n0.892\n\
    0.073\n0.892\n0.073\n0.892\n0.073\n0.892\n0.073\n0.892\nC2\n0.073\n0.892\n0.000\n\
    1.000\n0.073\n0.892\n0.000\n1.000\n0.073\n0.892\nC3\n0.073\n0.892\n0.073\n0.892\n\
    0.073\n0.892\n0.073\n0.892\n0.073\n0.892\nC4\n0.073\n0.892\n0.073\n0.892\n0.001\n\
    0.998\n0.001\n0.998\n0.001\n0.998\nC5\n0.073\n0.892\n0.073\n0.892\n0.073\n0.892\n\
    0.000\n1.000\n0.000\n1.000\nSensors 2022, 22, 4110\n20 of 26\nTable 5. Cont.\n\
    A1\nA2\nA3\nA4\nA5\nC6\n0.073\n0.892\n0.073\n0.892\n0.073\n0.892\n0.073\n0.892\n\
    0.073\n0.892\nC7\n0.000\n1.000\n0.073\n0.892\n0.000\n1.000\n0.000\n1.000\n0.000\n\
    1.000\nC8\n0.073\n0.892\n0.073\n0.892\n0.000\n1.000\n0.073\n0.892\n0.073\n0.892\n\
    C9\n0.073\n0.892\n0.000\n1.000\n0.073\n0.892\n0.073\n0.892\n0.000\n1.000\nC10\n\
    0.068\n0.900\n0.068\n0.900\n0.000\n1.000\n0.000\n1.000\n0.068\n0.900\nC11\n0.072\n\
    0.893\n0.000\n1.000\n0.000\n1.000\n0.000\n1.000\n0.072\n0.893\nC12\n0.072\n0.893\n\
    0.072\n0.893\n0.000\n1.000\n0.001\n0.998\n0.000\n1.000\nC13\n0.001\n0.998\n0.001\n\
    0.998\n0.071\n0.896\n0.000\n1.000\n0.000\n1.000\nC14\n0.071\n0.896\n0.071\n0.896\n\
    0.071\n0.896\n0.000\n1.000\n0.071\n0.896\nC15\n0.067\n0.902\n0.000\n1.000\n0.000\n\
    1.000\n0.000\n1.000\n0.067\n0.902\nC16\n0.068\n0.900\n0.068\n0.900\n0.068\n0.900\n\
    0.068\n0.900\n0.068\n0.900\nC17\n0.064\n0.905\n0.064\n0.905\n0.000\n1.000\n0.000\n\
    1.000\n0.000\n1.000\nC18\n0.061\n0.910\n0.061\n0.910\n0.000\n1.000\n0.000\n1.000\n\
    0.000\n1.000\nC19\n0.061\n0.910\n0.061\n0.910\n0.000\n1.000\n0.000\n1.000\n0.000\n\
    1.000\nC20\n0.055\n0.919\n0.055\n0.919\n0.055\n0.919\n0.000\n1.000\n0.055\n0.919\n\
    C21\n0.000\n1.000\n0.000\n1.000\n0.055\n0.919\n0.000\n1.000\n0.000\n1.000\nStep\
    \ 4. Matrix of border approximation area.\nThe border approximation area G of\
    \ each criterion is calculated as follows:\ngj =\n21\n∏\ni=1\nv1/21\nij\n= ⟨\n\
    \"\n21\n∏\ni=1\n\0µij\n\x011/21\n#\n,\n\"\n1 −\n21\n∏\ni=1\n\01 − ηij\n\x011/21\n\
    #\n⟩.\nThe results are shown in Table 6.\nTable 6. Calculations and the obtained\
    \ matrix of border approximation area G.\nA1\nA2\nA3\nA4\nA5\nG\nC1\n0.593\n0.641\n\
    0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n0.073\n0.892\nC2\n0.593\n\
    0.641\n0.121\n0.131\n0.593\n0.641\n0.121\n0.131\n0.593\n0.641\n0.003\n0.996\n\
    C3\n0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n0.073\n\
    0.892\nC4\n0.593\n0.641\n0.593\n0.641\n0.265\n0.287\n0.265\n0.287\n0.265\n0.287\n\
    0.007\n0.990\nC5\n0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n0.121\n0.131\n0.121\n\
    0.131\n0.003\n0.996\nC6\n0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n0.593\n0.641\n\
    0.593\n0.641\n0.073\n0.892\nC7\n0.121\n0.131\n0.593\n0.641\n0.121\n0.131\n0.121\n\
    0.131\n0.121\n0.131\n0.000\n1.000\nC8\n0.593\n0.641\n0.593\n0.641\n0.121\n0.131\n\
    0.593\n0.641\n0.593\n0.641\n0.015\n0.978\nC9\n0.593\n0.641\n0.121\n0.131\n0.593\n\
    0.641\n0.593\n0.641\n0.121\n0.131\n0.003\n0.996\nC10\n0.584\n0.631\n0.584\n0.631\n\
    0.119\n0.129\n0.119\n0.129\n0.584\n0.631\n0.003\n0.996\nC11\n0.591\n0.639\n0.120\n\
    0.130\n0.120\n0.130\n0.120\n0.130\n0.591\n0.639\n0.001\n0.999\nC12\n0.591\n0.639\n\
    0.591\n0.639\n0.120\n0.130\n0.264\n0.286\n0.120\n0.130\n0.001\n0.998\nC13\n0.263\n\
    0.285\n0.263\n0.285\n0.589\n0.636\n0.120\n0.130\n0.120\n0.130\n0.001\n0.999\n\
    C14\n0.589\n0.636\n0.589\n0.636\n0.589\n0.636\n0.120\n0.130\n0.589\n0.636\n0.014\n\
    0.979\nSensors 2022, 22, 4110\n21 of 26\nTable 6. Cont.\nA1\nA2\nA3\nA4\nA5\n\
    G\nC15\n0.582\n0.629\n0.118\n0.128\n0.118\n0.128\n0.118\n0.128\n0.582\n0.629\n\
    0.001\n0.999\nC16\n0.584\n0.631\n0.584\n0.631\n0.584\n0.631\n0.584\n0.631\n0.584\n\
    0.631\n0.068\n0.900\nC17\n0.578\n0.625\n0.578\n0.625\n0.117\n0.127\n0.117\n0.127\n\
    0.117\n0.127\n0.001\n0.999\nC18\n0.572\n0.618\n0.572\n0.618\n0.116\n0.126\n0.116\n\
    0.126\n0.116\n0.126\n0.001\n0.999\nC19\n0.572\n0.618\n0.572\n0.618\n0.116\n0.126\n\
    0.116\n0.126\n0.116\n0.126\n0.001\n0.999\nC20\n0.559\n0.605\n0.559\n0.605\n0.559\n\
    0.605\n0.113\n0.123\n0.559\n0.605\n0.011\n0.984\nC21\n0.113\n0.123\n0.113\n0.123\n\
    0.559\n0.605\n0.113\n0.123\n0.113\n0.123\n0.000\n1.000\nStep 5. Matrix of distance\
    \ to the border approximation area.\nThe values of distance matrix to the border\
    \ approximation area\nqij = vij − gj, i = 1, 21\nare calculated by using S1\n\
    GC formula (Table 7).\nTable 7. The matrix of distances to the border approximation\
    \ area Q.\nA1\nA2\nA3\nA4\nA5\nC1\n1.000\n1.000\n1.000\n1.000\n1.000\nC2\n0.975\n\
    0.999\n0.975\n0.999\n0.975\nC3\n1.000\n1.000\n1.000\n1.000\n1.000\nC4\n0.976\n\
    0.976\n0.998\n0.998\n0.998\nC5\n0.975\n0.975\n0.975\n0.999\n0.999\nC6\n1.000\n\
    1.000\n1.000\n1.000\n1.000\nC7\n1.000\n0.974\n1.000\n1.000\n1.000\nC8\n0.979\n\
    0.979\n0.995\n0.979\n0.979\nC9\n0.975\n0.999\n0.975\n0.975\n0.999\nC10\n0.977\n\
    0.977\n0.999\n0.999\n0.977\nC11\n0.974\n1.000\n1.000\n1.000\n0.974\nC12\n0.974\n\
    0.974\n1.000\n1.000\n1.000\nC13\n1.000\n1.000\n0.975\n1.000\n1.000\nC14\n0.980\n\
    0.980\n0.980\n0.995\n0.980\nC15\n0.976\n1.000\n1.000\n1.000\n0.976\nC16\n1.000\n\
    1.000\n1.000\n1.000\n1.000\nC17\n0.977\n0.977\n1.000\n1.000\n1.000\nC18\n0.978\n\
    0.978\n1.000\n1.000\n1.000\nC19\n0.978\n0.978\n1.000\n1.000\n1.000\nC20\n0.984\n\
    0.984\n0.984\n0.996\n0.984\nC21\n1.000\n1.000\n0.980\n1.000\n1.000\nThe belonging\
    \ of alternative Ai to the approximation area (G, G+ or G−) is determined\non\
    \ the basis of the following equation:\nAi ∈\n\n\n\nG+, i f qij > 0\n0, i f\
    \ qij = 0\nG−, i f qij < 0\nStep 6. Alternatives’ rank.\nThe total distance of\
    \ each alternative to the border approximation area is obtained by\nthe next formula:\n\
    Si =\n5\n∑\nj=1\nqij.\nSensors 2022, 22, 4110\n22 of 26\nThe rank the alternatives\
    \ is based on Si values, sorted in ascending order (Table 8).\nTable 8. The overall\
    \ alternative scores and their corresponding ranking–new MABAC (IFNs).\nS1\nGC\
    \ MABAC\nScore\nRank\nA1\n0.015\n1\nA2\n0.012\n2\nA3\n0.008\n3\nA4\n0.003\n5\n\
    A5\n0.008\n4\nThe obtained ranking by using new intuitionistic fuzzy MABAC is\
    \ as follows:\nS1\nGC MABAC : A1 ≻ A2 ≻ A3 ≈ A5 ≻ A4,\ni.e., A1 platform (AWS\
    \ IoT) is the most suitable for AF company according to the given\nrequirements.\n\
    Step 7. In order to check the reliability of proposed model and the consistency\
    \ of the\nresults produced by intuitionistic fuzzy assessments, the same problem\
    \ is solved by using\ncrisp SAW, crisp MABAC and IFNs MABAC with L2 discrimination\
    \ measure [57] (Table 9).\nTable 9. The overall alternative scores and their corresponding\
    \ rankings—crisp SAW, crisp MABAC\nand IFNs L2 MABAC.\nCrisp SAW\nCrisp MABAC\n\
    L2 MABAC\nScore\nRank\nScore\nRank\nScore\nRank\nA1\n0.839\n1\n0.375\n2\n0.110\n\
    3\nA2\n0.784\n2\n0.379\n1\n0.115\n1\nA3\n0.682\n3\n0.344\n3\n0.113\n2\nA4\n0.549\n\
    5\n0.303\n4\n0.103\n4\nA5\n0.661\n4\n0.295\n5\n0.102\n5\n4.3. Analysis of Obtained\
    \ Results\nThe obtained rankings are almost identical or similar to the S1\nGC\
    \ MABAC result:\nCrisp SAW: A1 ≻ A2 ≻ A3 ≻ A5 ≻ A4;\nCrisp MABAC: A2 ≻ A1 ≻ A3\
    \ ≻ A4 ≻ A5;\nIFNs L2 MABAC: A2 ≻ A3 ≻ A1 ≻ A4 ≻ A5;\nSpearman’s rank correlation\
    \ coefﬁcient is applied as a similarity measure between\nclassical SAW and each\
    \ other MCDM methods’ rankings. Spearman’s coefﬁcients indicates\nhigh degrees\
    \ of closeness of obtained rankings—0.8 (crisp MABAC), 0.6 (L2 MABAC) and\n1.0\
    \ (S1\nGC MABAC). This means that the proposed intuitionistic fuzzy model is reliable\
    \ and\ncould be applied for MCDM.\nThe analysis also shows that two groups of\
    \ IoT platforms can be distinguished in the\nobtained crisp and fuzzy MCDM rankings:\n\
    Group 1. IoT platforms with high assessments—A1, A2 and A3;\nGroup 2. IoT platforms\
    \ with relative low assessments—A4 and A5.\nThe highest experts’ ratings (crisp\
    \ SAW and S1\nGC MABAC) of alternative A1 (AWS IoT)\nassign it to the leading\
    \ group, while alternatives A4 (IBM Watson IoT) and A5 (Oracle IoT)\nfalls into\
    \ the second part of the ranking (crisp SAW, crisp MABAC, L2 MABAC and S1\nGC\n\
    MABAC). One possible reason for the worse ranking of IBM Watson IoT and Oracle\
    \ IoT is\nthat both platforms are more encapsulated in their company’s ecosystems\
    \ than other three\nplatforms. The good performance of A1 and A2 correspond to\
    \ the GMQ’2021 assertion,\nthat AWS IoT and Azure IoT are “challenger” and “leader”\
    \ respectively among the best\nIIoT platforms. Therefore, it can be concluded\
    \ that the proposed algorithm is robust and\nSensors 2022, 22, 4110\n23 of 26\n\
    reliable, because the obtained ranking meets the customers’ preferences in company\
    \ AF.\nAnother advantage of the new multi-criteria method in comparison with optimization\
    \ and\nmachine learning methods is that the results are easily explainable.\n\
    The utilization of S1\nGC MABAC not only led to a better treatment of subjective\
    \ experts’\nopinions, but also to a reduction in time complexity in comparison\
    \ with recently created\nanalog L2 MABAC. By using the new distance formula between\
    \ IFNs in MABAC, a good\nbalance between low computational complexity, simplicity\
    \ of decision-making model and\nits effectiveness was achieved.\nThe comparison\
    \ with results obtained from similar previous studies shows the following:\n•\n\
    Despite the large number of methodologies for IoT system selection, only several\
    \ stud-\nies investigate and analyze more than two MCDM methods [17,18,22,25]\
    \ or employ\nthe fuzzy approach [15,18,24–26].\n•\nSome of the researchers compare\
    \ only specialized IoT platforms or particular elements\nof IoT infrastructure\
    \ [16,20,25].\n•\nIn some studies, a practical example for the ranking of IoT\
    \ alternatives is miss-\ning [18,19,22].\n•\nThe obtained rankings of IoT platforms\
    \ are almost identical to those obtained by\nKondratenko et al. and Chakraborty\
    \ (AWS, Azure, Google, IBM) [24,26], Lin et al.\n(AWS, Azure, IBM) [15] and Youssef\
    \ (AWS, Azure, Google) [21].\nThe proposed framework systematizes common rules\
    \ and procedures for group multi-\ncriteria selection of IoT platforms. The new\
    \ framework ensures feasible solution using\nusers’ needs and avoiding subjectivism\
    \ in experts’ opinions. It facilitates the construction\nof complex indices for\
    \ systems evaluation, including technical speciﬁcations, key perfor-\nmance indicators\
    \ and metrics for the sustainability of IoT ecosystems. Furthermore, it is\nﬂexible\
    \ and timesaving, reducing the possibility of errors while preparing relevant\
    \ input\ndata for each step of the decision-making process. Unlike previous similar\
    \ studies, the\nnew framework could implement multi-criteria analysis in different\
    \ fuzzy environments\n(classical and intuitionistic).\n5. Conclusions\nThe process\
    \ of determining the best suitable IoT platform depends on many factors,\n(peculiarities\
    \ of business processes and legacy systems, users’ preferences, vendor’s proﬁle\n\
    to name a few), i.e., it is in fact a multi-criteria decision-making problem.\
    \ This study\noutlines a multi-criteria framework for IoT platform selection in\
    \ a fuzzy environment. In\nthe proposed framework, a new modiﬁcation of Multi-Attribute\
    \ Border approximation\nArea Comparison (MABAC) method with speciﬁc similarity\
    \ measure via intuitionistic\nfuzzy values has been presented as a decision analysis\
    \ method. The new technique is\nmore precise than existing crisp and fuzzy analogues,\
    \ as its (1) calculations include the\nthree semantic components of intuitionistic\
    \ fuzzy numbers and (2) distance formula takes\ninto account the relationship\
    \ between cross-evaluation of membership (truth) degrees as\naddition to the difference\
    \ between main intuitionistic components. The effectiveness of\nthe new decision-making\
    \ framework has been veriﬁed through an illustrative example of\nranking IoT platforms.\n\
    The new framework automates the process of ranking of IoT systems and has several\n\
    advantages:\n(1)\nThe comparison is based on a complex index that covers technological\
    \ and business\nrequirements of a team of experts and consumer preferences;\n\
    (2)\nMCDM methods have the capability to handle vague and uncertain estimates\
    \ of both\ncost and beneﬁcial criteria via fuzzy values;\n(3)\nThe proposed evaluation\
    \ system is ﬂexible. It can be further extended with additional\ndecision-making\
    \ algorithms and adapted to other organizations or sectors;\n(4)\nThe weighting\
    \ coefﬁcients and decision matrix are determined by a group of experts\nfamiliar\
    \ with the company’s business processes and IoT technology.\nSensors 2022, 22,\
    \ 4110\n24 of 26\nThe advantage of the proposed fuzzy modiﬁcation of MABAC method\
    \ is that the\ndistance between compared alternatives is calculated by an improved\
    \ formula for similarity\nin intuitionistic environment:\n•\nIn addition to membership\
    \ and non-membership parameters, a hesitancy degree\nis included;\n•\nThe difference\
    \ of maximum of the cross-evaluation factor and the difference of mini-\nmum of\
    \ the cross-evaluation factor also participates in the calculation.\nThe validity\
    \ of the new framework is demonstrated using a practical example for\nthe selection\
    \ of IoT platforms. The problem is to ﬁnd the best ranking alternative from\n\
    ﬁve IoT platforms (AWS IoT Core, Microsoft Azure IoT, Google Cloud IoT Core, IBM\n\
    Watson IoT and Oracle IoT) according to twenty-one criteria for comparison. The\
    \ analysis\nof obtained results shows that the proposed methodology is reliable\
    \ and correctly reﬂects\nuser’s requirements.\nIn the future, the theoretical\
    \ framework will be improved by aggregating several\nrankings obtained through\
    \ different multi-criteria methods using meta-methods. Addi-\ntionally, the proposed\
    \ mechanisms for the ranking of IoT alternatives will be expanded\nto address\
    \ uncertainty of estimates with different types of fuzzy sets (for example, type-2\n\
    fuzzy numbers and spherical fuzzy numbers). We also have a plan to develop new\
    \ hybrid\nmethods for IoT systems’ evaluation combining weights determination\
    \ algorithms with\nmulti-criteria decision-making methods.\nAuthor Contributions:\
    \ Conceptualization, G.I. and T.Y.; framework, T.Y. and G.I.; MABAC modi-\nﬁcation,\
    \ G.I.; validation, G.I. and T.Y.; formal analysis, T.Y.; resources, G.I.; writing—original\
    \ draft\npreparation, G.I.; writing—review and editing, G.I. and T.Y.; visualization,\
    \ T.Y.; supervision, G.I.;\nproject administration, T.Y.; funding acquisition,\
    \ G.I. and T.Y. All authors have read and agreed to the\npublished version of\
    \ the manuscript.\nFunding: This research was partially funded by the National\
    \ Research Programme “Smart Crop\nProduction”, approved by decision of the Council\
    \ of Ministers No. 866/26.11.2020, by the Ministry\nof Education and Science and\
    \ by the National Science Fund, co-founded by the European Regional\nDevelopment\
    \ Fund, Grant No. BG05M2OP001-1.002-0002 “Digitization of the Economy in Big\n\
    Data Environment”.\nInstitutional Review Board Statement: Not applicable.\nInformed\
    \ Consent Statement: Not applicable.\nData Availability Statement: Not applicable.\n\
    Conﬂicts of Interest: The authors declare no conﬂict of interest.\nReferences\n\
    1.\nMuangprathub, J.; Boonnam, N.; Kajornkasirat, S.; Lekbangpong, N.; Wanichsombat,\
    \ A.; Nillaor, P. IoT and agriculture data\nanalysis for smart farm. Comput. Electron.\
    \ Agric. 2018, 156, 467–474. [CrossRef]\n2.\nMisra, N.N.; Dixit, Y.; Al-Mallahi,\
    \ A.; Bhullar, M.S.; Upadhyay, R.; Martynenko, A. IoT, Big Data, and Artiﬁcial\
    \ Intelligence in\nAgriculture and Food Industry. IEEE Internet Things J. 2020,\
    \ 9, 6305–6324. [CrossRef]\n3.\nXi, M.; Adcock, M.; McCulloch, J. Future agriculture\
    \ farm management using augmented reality. In Proceedings of the IEEE\nWorkshop\
    \ on Augmented and Virtual Realities for Good (VAR4Good), Reutlingen, Germany,\
    \ 18 March 2018; pp. 1–3.\n4.\nGhandar, A.; Ahmed, A.; Zulﬁqar, S.; Hua, Z.; Hanai,\
    \ M.; Theodoropoulos, G. A Decision Support System for Urban Agriculture\nUsing\
    \ Digital Twin: A Case Study with Aquaponics. IEEE Access 2021, 9, 35691–35708.\
    \ [CrossRef]\n5.\nThakore, R.; Vaghashiya, R.; Patel, C.; Doshi, N. Blockchain—Based\
    \ IoT: A Survey. Procedia Comput. Sci. 2019, 155, 704–709.\n[CrossRef]\n6.\nTorky,\
    \ M.; Hassanein, A.E. Integrating blockchain and the internet of things in precision\
    \ agriculture: Analysis, opportunities, and\nchallenges. Comput. Electron. Agric.\
    \ 2020, 178, 105476. [CrossRef]\n7.\nTang, Y.; Dananjayan, S.; Hou, C.; Guo, Q.;\
    \ Luo, S.; He, Y. A survey on the 5G network and its impact on agriculture: Challenges\n\
    and opportunities. Comput. Electron. Agric. 2020, 180, 105895. [CrossRef]\n8.\n\
    Doukovska, L. Artiﬁcial Intelligence to Support Bulgarian Crop Production. Eng.\
    \ Sci. 2021, 54, 30–48. [CrossRef]\n9.\nTimilsina, B.; Adhikari, N.; Kaﬂe, S.;\
    \ Paudel, S.; Poudel, S.; Gautam, D. Addressing Impact of COVID-19 Post Pandemic\
    \ on\nFarming and Agricultural Deeds. Asian J. Adv. Res. Rep. 2020, 11, 28–35.\
    \ [CrossRef]\nSensors 2022, 22, 4110\n25 of 26\n10.\nKhan, J.Y.; Yuce, M.R. (Eds.)\
    \ Internet of Things (IoT): Systems and Applications; CRC Press: Singapore, 2019.\n\
    11.\nGan, G.-Y.; Lee, H.-S.; Liu, J.-Y. A DEA Approach towards to the Evaluation\
    \ of IoT Applications in Intelligent Ports. J. Mar. Sci.\nTechnol. 2021, 29, 257–267.\
    \ [CrossRef]\n12.\nPark, S.; Lee, K. Improved Mitigation of Cyber Threats in IIoT\
    \ for Smart Cities: A New-Era Approach and Scheme. Sensors 2021,\n21, 1976. [CrossRef]\n\
    13.\nZhang, X.; Geng, J.; Ma, J.; Liu, H.; Niu, S.; Mao, W. A hybrid service selection\
    \ optimization algorithm in internet of things.\nEURASIP J. Wirel. Commun. Netw.\
    \ 2021, 2021, 4. [CrossRef]\n14.\nKale, A.P.; Sonavane, S.P. IoT based Smart Farming:\
    \ Feature subset selection for optimized high-dimensional data using improved\n\
    GA based approach for ELM. Comput. Electron. Agric. 2018, 161, 225–232. [CrossRef]\n\
    15.\nLin, M.; Huang, C.; Xu, Z.; Chen, R. Evaluating IoT Platforms Using Integrated\
    \ Probabilistic Linguistic MCDM Method. IEEE\nInternet Things J. 2020, 7, 11195–11208.\
    \ [CrossRef]\n16.\nSingh, M.; Baranwal, G.; Tripathi, A.K. QoS-aware selection\
    \ of IoT-based service. Arab. J. Sci. Eng. 2020, 45, 10033–10050.\n[CrossRef]\n\
    17.\nNunes, L.H.; Estrella, J.C.; Perera, C.; Delbem, A.C.B.; Reiff-Marganiec,\
    \ S. Multi-criteria IoT resource discovery: A comparative\nanalysis. Softw. Pract.\
    \ Exp. 2016, 47, 1325–1341. [CrossRef]\n18.\nContreras-Massé, R.A.; Ochoa-Zezzatti,\
    \ A.; García, V.; Elizondo-Cortés, M. Selection of IoT Platform with Multi-Criteria\
    \ Analysis:\nDeﬁning Criteria and Experts to Interview. Res. Comput. Sci. 2019,\
    \ 148, 9–19. [CrossRef]\n19.\nNarwane, V.S.; Gunasekaran, A.; Gardas, B.B. Unlocking\
    \ adoption challenges of IoT in Indian Agricultural and Food Supply\nChain. Smart\
    \ Agric. Technol. 2022, 2, 100035. [CrossRef]\n20.\nMashal, I.; Alsaryrah, O.;\
    \ Chung, T.Y.; Yuan, F.C. A multi-criteria analysis for an internet of things\
    \ application recommendation\nsystem. Technol. Soc. 2020, 60, 101216. [CrossRef]\n\
    21.\nYoussef, A.E. An Integrated MCDM Approach for Cloud Service Selection Based\
    \ on TOPSIS and BWM. IEEE Access 2020, 8,\n71851–71865. [CrossRef]\n22.\nSilva,\
    \ E.M.; Jardim-Goncalves, R. Cyber-Physical Systems: A multi-criteria assessment\
    \ for Internet-of-Things (IoT) systems.\nEnterp. Inf. Syst. 2019, 15, 332–351.\
    \ [CrossRef]\n23.\nPeneva, V.; Popchev, I. Fuzzy criteria importance with weighting\
    \ functions. C. R. Acad. Bulg. Sci. 2008, 61, 293–300.\n24.\nKondratenko, Y.;\
    \ Kondratenko, G.; Sidenko, I. Multi-criteria decision making and soft computing\
    \ for the selection of specialized\nIoT platform. In Proceedings of the XVIII\
    \ International Conference on Data Science and Intelligent Analysis of Information,\
    \ Kiev,\nUkraine, 4–7 July 2018; pp. 71–80.\n25.\nIlieva, G.; Yankova, T.; Hadjieva,\
    \ V.; Doneva, R.; Totkov, G. Cloud Service Selection as a Fuzzy Multi-criteria\
    \ Problem. TEM J.\n2020, 9, 484–495. [CrossRef]\n26.\nChakraborty, A.; Jindal,\
    \ M.; Khosravi, M.R.; Singh, P.; Shankar, A.; Diwakar, M. A Secure IoT-Based Cloud\
    \ Platform Selection\nUsing Entropy Distance Approach and Fuzzy Set Theory. Wirel.\
    \ Commun. Mob. Comput. 2021, 2021, 6697467. [CrossRef]\n27.\nMishra, K.N.; Kumar,\
    \ S.; Patel, N.R. Survey on Internet of Things and its Application in Agriculture.\
    \ J. Phys. Conf. Ser. 2021,\n1714, 012025. [CrossRef]\n28.\nYerovi, E.; Delgado-Vera,\
    \ C.; Molina-Oleas, W.; Ortega-Ponce, L. A Brief Systematic Review of the Latest\
    \ Advances in IOT Plat-\nforms in Agriculture. In Proceedings of the International\
    \ Conference on Technologies and Innovation, Guayaquil, Ecuador, 22–25\nNovember\
    \ 2021; Valencia-García, R., Bucaram-Leverone, M., Del Cioppo-Morstadt, J., Vera-Lucio,\
    \ N., Jácome-Murillo, E., Eds.;\nSpringer: Cham, Switzerland, 2021; Volume 1460,\
    \ pp. 201–215.\n29.\nVoas, J. NIST SP 800-183 Networks of ‘Things’. 2016. Available\
    \ online: https://nvlpubs.nist.gov/nistpubs/SpecialPublications/\nNIST.SP.800-183.pdf\
    \ (accessed on 1 March 2022).\n30.\nSethi, P.; Sarangi, S.R. Internet of things:\
    \ Architectures, protocols, and applications. J. Electr. Comput. Eng. 2017, 2017,\
    \ 9324035.\n[CrossRef]\n31.\nSharma, N.; Solanki, V.K.; Davim, J.P. Basics of\
    \ the Internet of Things (IoT) and Its Future. In Handbook of IoT and Big Data;\
    \ CRC\nPress: Boca Raton, FL, USA, 2019; pp. 165–186. [CrossRef]\n32.\nOlusanya,\
    \ G.S.; Okunbor, C.; Avwokuruaye, O. Internet of Things (IOT) as the future of\
    \ networked devices: An overview. Glob. J.\nEng. Technol. Adv. 2021, 9, 031–037.\
    \ [CrossRef]\n33.\nLaghari, A.A.; Wu, K.; Laghari, R.A.; Ali, M.; Khan, A.A. A\
    \ Review and State of Art of Internet of Things (IoT). Arch. Comput.\nMethods\
    \ Eng. 2021, 29, 1395–1413. [CrossRef]\n34.\nKoohang, A.; Sargent, C.S.; Nord,\
    \ J.H.; Paliszkiewicz, J. Internet of Things (IoT): From awareness to continued\
    \ use. Int. J. Inf.\nManag. 2021, 62, 102442. [CrossRef]\n35.\nNasr, M.; Islam,\
    \ M.; Shehata, S.; Karray, F.; Quintana, Y. Smart Healthcare in the Age of AI:\
    \ Recent Advances, Challenges, and\nFuture Prospects. IEEE Access 2021, 9, 145248–145270.\
    \ [CrossRef]\n36.\nLewis, B. Standards Hat Trick for the Internet of Things. 2020.\
    \ Available online: https://www.iso.org/news/ref2529.html\n(accessed on 1 March\
    \ 2022).\n37.\nVelosa, A.; Friedman, T.; Thielemann, K.; Berthelsen, E.; Havart-Simkin,\
    \ P.; Goodness, E.; Flatley, M.; Jones, L.; Quinn, K. Gartner\nMagic Quadrant\
    \ for Industrial IoT Platforms. 2021. Available online: https://www.gartner.com/en/documents/4006918/magic-\n\
    quadrant-for-industrial-iot-platforms (accessed on 1 March 2022).\nSensors 2022,\
    \ 22, 4110\n26 of 26\n38.\nGoodness, E.; Kim, S.; Friedman, T.; Velosa, A.; Berthelsen,\
    \ E.; Shrivastava, A. Gartner Magic Quadrant for IIoT Platforms 2019.\nAvailable\
    \ online: https://b2bsalescafe.ﬁles.wordpress.com/2019/09/gartner-magic-quadrant-for-industrial-iot-platforms-june-\n\
    2019.pdf (accessed on 1 March 2022).\n39.\nFriha, O.; Ferrag, M.A.; Shu, L.; Maglaras,\
    \ L.A.; Wang, X. Internet of Things for the Future of Smart Agriculture: A Comprehensive\n\
    Survey of Emerging Technologies. IEEE/CAA J. Autom. Sin. 2021, 8, 718–752. [CrossRef]\n\
    40.\nSinha, B.B.; Dhanalakshmi, R. Recent advancements and challenges of Internet\
    \ of Things in smart agriculture: A survey. Futur.\nGener. Comput. Syst. 2021,\
    \ 126, 169–184. [CrossRef]\n41.\nFnF Research Smart Agriculture Market Size Globally\
    \ Estimated to Reach USD 22.5 Bn, with 8.9% CAGR by 2026: Facts & Factors.\n2021.\
    \ Available online: https://www.globenewswire.com/news-release/2021/10/18/2315821/0/en/Smart-Agriculture-Market-\n\
    Size-Globally-Estimated-to-Reach-USD-22-5-Bn-with-8-9-CAGR-by-2026-Facts-Factors.html\
    \ (accessed on 1 March 2022).\n42.\nBalaji, G.N.; Nandhini, V.; Mithra, S.; Priya,\
    \ N.; Naveena, R. IoT based smart crop monitoring in farm land. Imp. J. Interdiscip.\
    \ Res.\n2018, 4, 88–92.\n43.\nAkhter, R.; Soﬁ, S.A. Precision agriculture using\
    \ IoT data analytics and machine learning. J. King Saud Univ. Comput. Inf. Sci.\
    \ 2021.\n[CrossRef]\n44.\nRamaprasad, S.S.; Kumar, B.S.S.; Lebaka, S.; Prasad,\
    \ P.R.; Kumar, K.N.S.; Manohar, G.N. Intelligent Crop Monitoring and\nProtection\
    \ System in Agricultural ﬁelds Using IoT. In Proceedings of the 2019 4th International\
    \ Conference on Recent Trends on\nElectronics, Information, Communication & Technology\
    \ (RTEICT), Bangalore, India, 17–18 May 2019; pp. 1527–1531. [CrossRef]\n45.\n\
    Madhav, M.U.; Jyothi, D.N.; Kalyani, P. Prediction of pesticides and identiﬁcation\
    \ of diseases in fruits using Support Vector\nMachine (SVM) and IoT. AIP Conf.\
    \ Proc. 2021, 2407, 020016. [CrossRef]\n46.\nGupta, N.; Gupta, S.; Khosravy, M.;\
    \ Dey, N.; Joshi, N.; Crespo, R.G.; Patel, N. Economic IoT strategy: The future\
    \ technology for\nhealth monitoring and diagnostic of agriculture vehicles. J.\
    \ Intell. Manuf. 2021, 32, 1117–1128. [CrossRef]\n47.\nKhan, N.; Ray, R.; Sargani,\
    \ G.; Ihtisham, M.; Khayyam, M.; Ismail, S. Current Progress and Future Prospects\
    \ of Agriculture\nTechnology: Gateway to Sustainable Agriculture. Sustainability\
    \ 2021, 13, 4883. [CrossRef]\n48.\nOliveira, L.; Moreira, A.; Silva, M. Advances\
    \ in Agriculture Robotics: A State-of-the-Art Review and Challenges Ahead. Robotics\n\
    2021, 10, 52. [CrossRef]\n49.\nLuthra, S.; Mangla, S.K.; Garg, D.; Kumar, A. Internet\
    \ of Things (IoT) in Agriculture Supply Chain Management: A Developing\nCountry\
    \ Perspective. In Emerging Markets from a Multidisciplinary Perspective; Springer:\
    \ Cham, Switzerland, 2018; pp. 209–220.\n[CrossRef]\n50.\nDutta, P.K.; Mitra,\
    \ S. Application of Agricultural Drones and IoT to Understand Food Supply Chain\
    \ during Post COVID-19. Agric.\nInform. Autom. Using IoT Mach. Learn. 2021, 67–87.\
    \ [CrossRef]\n51.\nUllah, M.; Nardelli, P.J.; Wolff, A.; Smolander, K. Twenty-One\
    \ Key Factors to Choose an IoT Platform: Theoretical Framework and\nIts Applications.\
    \ IEEE Internet Things J. 2020, 7, 10111–10119. [CrossRef]\n52.\nPamuˇcar, D.;\
    \ ´Cirovi´c, G. The selection of transport and handling resources in logistics\
    \ centers using Multi-Attributive Border\nApproximation area Comparison (MABAC).\
    \ Expert Syst. Appl. 2015, 42, 3016–3028. [CrossRef]\n53.\nLiu, H.-W.; Wang, G.-J.\
    \ Multi-criteria decision-making methods based on intuitionistic fuzzy sets. Eur.\
    \ J. Oper. Res. 2007, 179,\n220–233. [CrossRef]\n54.\nLei, Q.; Xu, Z. Derivative\
    \ and Differential Operations of Intuitionistic Fuzzy Numbers. Int. J. Intell.\
    \ Syst. 2014, 30, 468–498.\n[CrossRef]\n55.\nGohain, B.; Chutia, R.; Dutta, P.;\
    \ Gogoi, S. Two new similarity measures for intuitionistic fuzzy sets and its\
    \ various applications.\nInt. J. Intell. Syst. 2021, 36, 7805–7838. [CrossRef]\n\
    56.\nVisalakshi, N.K.; Thangavel, K.; Parvathi, R. An Intuitionistic Fuzzy Approach\
    \ to Distributed Fuzzy Clustering. Int. J. Comput.\nTheory Eng. 2010, 2, 295–302.\
    \ [CrossRef]\n57.\nMishra, A.R.; Garg, A.K.; Purwar, H.; Rana, P.; Liao, H.; Mardani,\
    \ A. An Extended Intuitionistic Fuzzy Multi-Attributive Border\nApproximation\
    \ Area Comparison Approach for Smartphone Selection Using Discrimination Measures.\
    \ Informatica 2020, 32,\n119–143. [CrossRef]\n"
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/22/11/4110/pdf?version=1653977514
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: IoT System Selection as a Fuzzy Multi-Criteria Problem
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s23083876
  analysis: '>'
  authors:
  - M D. Torres Pons
  - Estuardo Valenzuela
  - Brandon Rodríguez
  - Juan Arturo Nolazco-Flores
  - Carolina Del-Valle-Soto
  citation_count: 19
  full_citation: '>'
  full_text: ">\nCitation: Pons, M.; Valenzuela, E.;\nRodríguez, B.; Nolazco-Flores,\
    \ J.A.;\nDel-Valle-Soto, C. Utilization of 5G\nTechnologies in IoT Applications:\n\
    Current Limitations by Interference\nand Network Optimization\nDifﬁculties—A Review.\
    \ Sensors 2023,\n23, 3876. https://doi.org/10.3390/\ns23083876\nAcademic Editor:\
    \ Tommaso\nPecorella\nReceived: 15 March 2023\nRevised: 29 March 2023\nAccepted:\
    \ 3 April 2023\nPublished: 11 April 2023\nCopyright:\n© 2023 by the authors.\n\
    Licensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nsensors\nArticle\n\
    Utilization of 5G Technologies in IoT Applications:\nCurrent Limitations by Interference\
    \ and Network\nOptimization Difﬁculties—A Review\nMario Pons 1, Estuardo Valenzuela\
    \ 1, Brandon Rodríguez 1, Juan Arturo Nolazco-Flores 2\nand Carolina Del-Valle-Soto\
    \ 3,*\n1\nFacultad de Ingeniería, Universidad del Istmo, Km 19.2 Carretera a Fraijanes,\
    \ Fraijanes 01062, Guatemala;\npons171118@unis.edu.gt (M.P.); valenzuela181135@unis.edu.gt\
    \ (E.V.); rodriguez181048@unis.edu.gt (B.R.)\n2\nSchool of Engineering and Science,\
    \ Tecnológico de Monterrey, Av. Eugenio Garza Sada 2501,\nMonterrey 64849, NL,\
    \ Mexico; jnolazco@tec.mx\n3\nFacultad de Ingeniería, Universidad Panamericana,\
    \ Álvaro del Portillo 49, Zapopan 45010, JA, Mexico\n*\nCorrespondence: cvalle@up.edu.mx;\
    \ Tel.: +52-33-1368-2200\nAbstract: 5G (ﬁfth-generation technology) technologies\
    \ are becoming more mainstream thanks to\ngreat efforts from telecommunication\
    \ companies, research facilities, and governments. This tech-\nnology is often\
    \ associated with the Internet of Things to improve the quality of life for citizens\
    \ by\nautomating and gathering data recollection processes. This paper presents\
    \ the 5G and IoT technolo-\ngies, explaining common architectures, typical IoT\
    \ implementations, and recurring problems. This\nwork also presents a detailed\
    \ and explained overview of interference in general wireless applica-\ntions,\
    \ interference unique to 5G and IoT, and possible optimization techniques to overcome\
    \ these\nchallenges. This manuscript highlights the importance of addressing interference\
    \ and optimizing\nnetwork performance in 5G networks to ensure reliable and efﬁcient\
    \ connectivity for IoT devices,\nwhich is essential for adequately functioning\
    \ business processes. This insight can be helpful for\nbusinesses that rely on\
    \ these technologies to improve their productivity, reduce downtime, and\nenhance\
    \ customer satisfaction. We also highlight the potential of the convergence of\
    \ networks and\nservices in increasing the availability and speed of access to\
    \ the internet, enabling a range of new and\ninnovative applications and services.\n\
    Keywords: 5G technologies; interference; wireless network optimization; internet\
    \ of things\n1. Introduction\nThe COVID-19 pandemic shifted the general public’s\
    \ attention to digital solutions\nand brought immense demand to the telecommunications\
    \ market. The convergence of 5G\ntechnology and the Internet of Things (IoT) [1]\
    \ is the next natural step for two advanced\ntechnologies developed to make the\
    \ lives of their users more accessible, more comfortable,\nand more productive\
    \ [2]. One of the most standard technologies to be brought into the\nmainstream\
    \ area is 5G, which will allow for new business opportunities by being comple-\n\
    mented with Industry 4.0, IoT devices, and Smart Cities and improve overall connectivity\n\
    around the globe [3]. The Internet of Things is an ecosystem of increasing complexity:\
    \ a\nuniverse of connected things capable of capturing critical data and carrying\
    \ out advanced\nanalysis using cloud-based functionalities to extract valuable\
    \ information. This technology\nposes a great opportunity for a multitude of actors\
    \ in all sectors of activity [4]. Many\ncompanies are organizing to focus on IoT\
    \ and connectivity when developing their products\nand services of the future.\n\
    Deployment costs, range, interference, and capabilities of Internet of Things\
    \ devices\nare all factors in identifying the right primary or complementary connectivity\
    \ option for\nan IoT deployment. Wi-Fi 6 or Zigbee is adequate for some elements\
    \ of smart building\nSensors 2023, 23, 3876. https://doi.org/10.3390/s23083876\n\
    https://www.mdpi.com/journal/sensors\nSensors 2023, 23, 3876\n2 of 41\ncontrols\
    \ but useless for highly mobile wide-area use [5]. Additionally, endpoints such\
    \ as\nBluetooth, Zigbee, RFID, or Wi-Fi can be signiﬁcantly more cost effective\
    \ in scenarios where\n5G may be available but has not yet reached a signiﬁcant\
    \ market scale to do competitive\nendpoints or network services [6]. Technical\
    \ studies [7] show that 5G and other services can\ncoexist in speciﬁc frequency\
    \ bands. The technical conditions must be adequately adapted\nand not excessively\
    \ restrictive; otherwise, there is a risk of affecting the costs, coverage,\n\
    and quality of operation of 5G services.\nThere is great interest in the new applications\
    \ of mobile technology merging 5G and\nthe Internet of Things technologies. In\
    \ the design of new applications or technological\naccessories using 5G and the\
    \ Internet of Things, compliance with the permitted exposure\nlimits are contemplated.\
    \ International exposure guidelines have been developed due to\nextensive research\
    \ carried out over many decades. All the analyses carried out by indepen-\ndent\
    \ public health authorities, expert groups, and the World Health Organization\
    \ (WHO)\nagree that these guidelines guarantee protection for all people against\
    \ any health danger [8].\nAs with all technological generations, 5G dramatically\
    \ improves energy efﬁciency depart-\nment and speed rates. However, this technology\
    \ has recently been in the public eye for its\nimplementation challenges.\nIoT\
    \ technologies are now being widely used in the consumer-grade market, primarily\n\
    targeted toward home automation and security. This rise in consumer adoption has\
    \ led to\nproposals to incorporate IoT devices to bring these types of improvements\
    \ to a metropolitan\nscale [9]. These improvements are speculated to improve security\
    \ and automation tasks\nand tackle long-lasting difﬁculties such as trafﬁc control,\
    \ waste management, and so on.\nHowever, IoT does not depend solely on the electronics\
    \ being deployed and installed;\nthey rely on efﬁcient and resilient transmission\
    \ technology being used. The convergence\nof networks and services is an essential\
    \ aspect of the modern internet. The internet has\nevolved from a simple means\
    \ of communication to a complex and multifaceted ecosystem\nthat is integrated\
    \ into nearly every aspect of our daily lives. The advent of 5G technology\nhas\
    \ further pushed the convergence of networks and services, providing users with\
    \ faster\nand more reliable internet connections, enabling a range of new and\
    \ innovative applications\nand services [10].\nOne of the most signiﬁcant ways\
    \ that the convergence of networks and services\nimpacts internet services is\
    \ by increasing the availability and speed of access to the internet.\n5G technology\
    \ offers faster speeds and greater bandwidth, allowing users to access high-\n\
    quality video, audio, and other media content in real-time [11]. This means that\
    \ internet\nservice providers can offer a range of new services and applications\
    \ that were previously\nimpossible, such as virtual and augmented reality experiences\
    \ and immersive gaming.\nCellular connectivity will enable key IoT goals to be\
    \ achieved, in particular, reduced\ndevice complexity and cost and increased coverage\
    \ to support challenging and remote\napplications, deployment ﬂexibility, high\
    \ capacity, and long battery life. 3GPP wireless\ntechnologies offer compelling\
    \ technology advantages that will continue to increase the\ncapacity of Long Term\
    \ Evolution (LTE) infrastructure to address the vast IoT market in\nthe long term,\
    \ and 5G will add to the IoT landscape soon. In Releases 14, 15, and beyond\n\
    of the 3GPP (Third-Generation Partnership Project), the standards solve all commercial\n\
    bottlenecks to facilitate the vision of 5G and the huge IoT Market [12]. This\
    \ can lead\nto the explosion of billions of devices and sensors that show digital\
    \ representations of\nour real world powered by low-cost devices, long battery\
    \ life, ubiquitous coverage, and\ninnovative business applications. 5G promises\
    \ that it will be possible to achieve critical\nIoT applications, which require\
    \ real-time dynamic process control and automation in\nvarious ﬁelds, such as\
    \ vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), high-speed\nmotion,\
    \ and trafﬁc control. Critical parameters to enable the required performance are\n\
    sub-millisecond network latency and ultra-high reliability. Both are intrinsic\
    \ components of\nthe 3GPP work to deﬁne the new radio interface for 5G [13]. The\
    \ 5G network architecture\nis being designed to address both IoT scenarios.\n\
    Sensors 2023, 23, 3876\n3 of 41\nThe success of the IoT services on 5G networks\
    \ depends on the ability of these networks\nto manage interference effectively.\
    \ Interference can occur when different IoT devices operate\nin the same area,\
    \ and their signals overlap, causing lower throughput, higher latency, and\ndecreased\
    \ reliability [14]. This is a signiﬁcant challenge for 5G networks and IoT services,\
    \ as\nthey are designed to support a vast number of devices and applications,\
    \ each with unique\nconnectivity and latency requirements.\nFigure 1 shows the\
    \ comparison between 5G and IoT, which is a topic of interest\nin the technology\
    \ world. To implement 5G, there are speciﬁc requirements, including\ninfrastructure\
    \ and specialized hardware, while the evolution of wireless networks has led to\n\
    faster and more reliable data transfer rates. The evolution of IoT has enabled\
    \ the creation of\nlow-power, low-cost devices that can be connected to the internet.\
    \ Wireless communication\ntechnologies such as Bluetooth, Wi-Fi, ZigBee, and LoRa\
    \ are suitable for different types of\nIoT applications, and cloud-based solutions\
    \ are used to store and process vast amounts\nof data generated by IoT devices.\
    \ 5G applications include autonomous vehicles, remote\nsurgery, and virtual and\
    \ augmented reality, and these require high bandwidth, low latency,\nand reliable\
    \ connectivity. However, there are challenges associated with 5G networks,\nsuch\
    \ as interference and network optimization difﬁculties. The coexistence of 5G\
    \ networks\nand IoT applications is a concern, and optimization challenges in\
    \ 5G networks need to be\naddressed to enable efﬁcient and effective implementation.\n\
    Figure 1. Summary of conceptual schemes that addresses the present work.\nMotivation\n\
    The motivation of this work is to compile the impact of interference on the leading\
    \ 5G\ntechnologies that will inﬂuence the communications of IoT devices.\nIoT\
    \ services are used in various industries, including healthcare, manufacturing,\n\
    and transportation, where reliable and efﬁcient connectivity is essential for\
    \ the proper\nfunctioning of IoT devices and the smooth operation of business\
    \ processes. If interference\nand network performance issues are not addressed,\
    \ businesses may experience reduced\nproductivity, increased downtime, and decreased\
    \ customer satisfaction. Consequently,\naddressing the interference and optimization\
    \ of 5G networks in IoT services is essential to\nensure reliable and efﬁcient\
    \ connectivity for IoT devices and allow businesses to take full\nadvantage of\
    \ the beneﬁts of 5G networks and IoT services. For this reason, the motivation\n\
    of this work is to review the state of the art of the work to address the interference\
    \ and\noptimization of 5G technologies in IoT services.\nInterference and optimization\
    \ of 5G networks in IoT services is important to ensure\nreliable and efﬁcient\
    \ connectivity for IoT devices, which is essential for the proper func-\nSensors\
    \ 2023, 23, 3876\n4 of 41\ntioning of business processes. By implementing interference\
    \ management techniques and\noptimizing network performance, businesses can take\
    \ full advantage of the beneﬁts of 5G\nnetworks and IoT services.\nThe main contribution\
    \ of this review is to present the idea that the convergence\nof 5G networks and\
    \ IoT services represents a technological revolution that promises to\nchange\
    \ how we interact with the world around us. However, this union has its challenges,\n\
    and only by overcoming them can we unlock the full potential of these groundbreaking\n\
    technologies. By bridging the gap between 5G and IoT, we pave the way for a new\
    \ era\nof innovation: every device is connected, and every experience is seamless.\
    \ This work\ndescribes the main challenges between 5G networks and IoT services\
    \ and highlights the\nneed for seamless integration of these technologies to achieve\
    \ their full potential. This\npaper reinforces the idea that IoT technologies\
    \ power 5G services, and their compatibility\nis crucial for offering high-speed\
    \ and low-latency services to consumers. Furthermore, it\nunderscores that interference\
    \ is one of the biggest problems facing manufacturers, and they\nmust consider\
    \ it to offer compatible and reliable services. Ultimately, this article guides\n\
    the industry to ensure that 5G and IoT technologies work together seamlessly,\
    \ opening up\nendless possibilities for innovation and progress.\nFigure 2 describes\
    \ how the IoT and 5G technology can work together to enable a range\nof applications\
    \ in different ﬁelds. In the ﬁrst application, smart cities, IoT devices can\n\
    be used to collect real-time data on trafﬁc patterns, air quality, and energy\
    \ usage. These\ndata can be used to optimize city operations and improve quality\
    \ of life. 5G networks\ncan support these applications by providing the necessary\
    \ bandwidth and low latency.\nIn industrial automation, IoT devices can be used\
    \ to monitor and control manufacturing\nprocesses and equipment in real time.\
    \ This can help to improve efﬁciency and reduce\ndowntime. 5G networks can provide\
    \ the necessary bandwidth, reliability, and low latency\nto support these applications.\
    \ In healthcare, IoT devices can be used for remote patient\nmonitoring and real-time\
    \ communication between healthcare providers. This can help\nto improve patient\
    \ outcomes and reduce healthcare costs. 5G networks can provide\nthe necessary\
    \ bandwidth, low latency, and reliability to support these applications. In\n\
    transportation, IoT devices can provide real-time data on trafﬁc patterns and\
    \ vehicle\nperformance, which can be used to optimize trafﬁc ﬂow and improve safety.\
    \ 5G networks\ncan support these applications by providing the necessary bandwidth,\
    \ low latency, and\nreliability. In agriculture, IoT devices can be used to monitor\
    \ crops and livestock in real-time,\nwhich can help to optimize production and\
    \ reduce waste. 5G networks can support these\napplications by providing the necessary\
    \ bandwidth, reliability, and low latency. In retail,\nIoT devices can be used\
    \ to collect real-time data on customer behavior and inventory levels,\nwhich\
    \ can be used to optimize store operations and improve the customer experience.\
    \ 5G\nnetworks can provide the necessary bandwidth, reliability, and low latency\
    \ to support\nthese applications. Overall, the text shows how IoT and 5G technology\
    \ can work together\nto enable a range of applications in different ﬁelds. By\
    \ providing the necessary bandwidth,\nlow latency, and reliability, 5G networks\
    \ can support real-time data collection and analysis,\nwhich can help to improve\
    \ efﬁciency, reduce costs, and enhance the quality of life in\nvarious sectors.\n\
    Sensors 2023, 23, 3876\n5 of 41\n5G\nHealthcare\n5G will enable remote patient\
    \ \nmonitoring to happen at scale when \ncompared to other connectivity \nsolutions\
    \ through the promise of:\n-Greater reliability and security of the \nservice.\n\
    -Increased capacity for number of \nconnected           devices per square \n\
    kilometre.\n-Mobility versus in-home connectivity \nsolutions such as Wi-Fi.\n\
    Agriculture\nSmart farming may play a key role in food \ncrop production. Leveraging\
    \ a combination \nof 5G, edge computing and artiﬁcial \nintelligence that allows\
    \ for connectivity at a \nhigher speed with lower latency.\nCompanies are developing\
    \ \nsmart farming systems that \ncan beneﬁt from 5G. 5G will \nalso make farming\
    \ more \nprecise, using customized \ndata for farm management \njust like water,\
    \ pesticide use, \nand waste.\n5G is building transformative \npossibilities for\
    \ business. \nCreating powerful customer \nexperiences and effective \ninventory\
    \ tracking, high speeds \nand large data volumes that 5G \ncan support.\nHow products\
    \ are \nmanufactured \nThe evolution of the technology \nin the world of robotics\
    \ and \nwarehouse transportation \ndepends now on 5G and IoT will \nbe key to\
    \ enhancing and \nenabling advances in \nmanufacturing. \nIndustrial \nautomatation\n\
    5G technology has a number \nof features which will \npositively impact digital\
    \ \nexperiences and smart \ncities.\nBy using sensors, wearables and e-\nhealth\
    \ devices, patient attributes can be \ncollected and analysed without the need\
    \ \nfor patients to travel to primary care \nfacilities and have a face to face\
    \ \nappointment with a medical \nprofessional.\nRetail\n5G will empower \nan omnichannel\
    \ \nretail revolution to \nengage shoppers, \nincrease sales, \nand reduce \n\
    operating costs\n5G brakes on the \ndevelopment of the Internet \nof Things, which\
    \ will be \nable to explote the potential \nnot only in the home \nenvironment\
    \ but also in \nindustrial plants, in public \nbuildings or on the streets.\n\
    Smart cities\nOrganizational \nstructures. Since the \ncity as an entity \nseeks\
    \ innovation, it \nneeds data and \nanalysis tools to \nachieve it.\nhow can this\
    \ beneﬁt you?\nDeliver the best-performing 5G services anywhere.\nAchieve superior\
    \ RAN performance with a \nsuperior transport network.\nEstablish technology leadership\
    \ in new markets \nas you deliver on a whole new set of 5G use \ncases.\nService\
    \ providers will need high-performing 5G \nTransport solutions that are easy to\
    \ build, scale, \nand service. Transport solutions are designed to \nefﬁciently\
    \ meet all needs, getting 5G technology’s \nhelp will give us the best potential\
    \ to evolve with \nthe best performance.\n smart farming \ncould become a \ngame\
    \ changer as \nwe face a \ncrossroads in \nresources and \nproduction.\nIn addition\
    \ to a higher speed \nto upload and download \ndata, it ensures very short \n\
    latency times and the ability \nto connect multiple devices \nat the same time.\n\
    Transportation\nFigure 2. 5G applications impacted by IoT devices.\n2. Related\
    \ Work\nThe radio signal characteristics of new wireless applications are similar\
    \ to those of\nexisting mobile technologies [5]. This is where the interest of\
    \ this work lies in considering in\ndetail the impact and types of interference\
    \ of 5G technologies that coexist with IoT devices.\nThe new applications use\
    \ similar transmit powers and operate in the same frequency ranges.\nTo mitigate\
    \ interference, we can synchronize or coordinate all networks or implement\nlarge\
    \ guard bands that waste valuable spectrum [15]. In practice, close cooperation\
    \ is\nrequired between all operators in each frequency band, and not all usage\
    \ modes and\nall types of 5G deployments can likely be supported simultaneously.\
    \ Regulators need\nto consider these technical issues and their implications when\
    \ deciding how to arrange\nfrequencies in these bands.\nVarious interference management\
    \ techniques, such as power control, channel allo-\ncation, and beamforming, can\
    \ be implemented to ensure that IoT devices on the same\nnetwork do not interfere\
    \ with each other. However, these techniques can be complicated\nand may require\
    \ signiﬁcant changes to the network infrastructure [16]. Additionally, new\ninterference\
    \ management techniques may be required as IoT devices continue to evolve\nand\
    \ become more sophisticated.\nAnother signiﬁcant challenge in managing interference\
    \ in 5G networks is the diversity\nof devices and applications that use these\
    \ networks. IoT services can be used in various\nindustries, including healthcare,\
    \ manufacturing, and transportation, each with unique\nconnectivity and latency\
    \ requirements [17]. For instance, in healthcare, IoT devices, such as\nSensors\
    \ 2023, 23, 3876\n6 of 41\nwearable monitors and remote patient monitoring systems,\
    \ require low latency and reliable\nconnectivity to provide accurate data and\
    \ alerts. In contrast, IoT devices used in industrial\nautomation require high\
    \ bandwidth and low latency to operate effectively [18]. Therefore,\nmanaging\
    \ interference in 5G networks requires a comprehensive approach that considers\n\
    the diverse connectivity and latency requirements of different IoT devices and\
    \ applications.\nAnother important challenge is the potential for external interference;\
    \ while interfer-\nence management techniques can ensure that IoT devices on the\
    \ same network do not\ninterfere with each other, external interference can occur\
    \ when IoT devices operate in areas\nwith other wireless devices, such as Wi-Fi\
    \ routers, Bluetooth devices, and other cellular\nnetworks. This can lead to signal\
    \ degradation, reduced throughput, and decreased reliabil-\nity of the network\
    \ [19]. As a result, it is essential to consider external interference when\n\
    designing and implementing 5G networks for IoT services, and to use techniques\
    \ such as\nfrequency coordination and spectrum sharing to manage external interference\
    \ effectively.\nTo provide better insights for the 5G interference topic, we follow\
    \ the structure detailed\nin Figure 3.\nFigure 3. 5G and IoT technologies’ impact\
    \ scheme.\nThe impact of 5G network interference on IoT services is an active\
    \ research area. Sev-\neral studies have investigated the effects of interference\
    \ on the performance of IoT devices\nand applications. One recent study by Chandra\
    \ et al. analyzed the impact of interference\non the reliability of 5G networks\
    \ for IoT services [20]. The study found that interference\ncan signiﬁcantly reduce\
    \ the reliability of 5G networks for IoT services, especially in dense\ndeployments\
    \ where multiple devices operate in the same area. The study recommended\nusing\
    \ advanced interference management techniques such as dynamic channel allocation\n\
    and power control to mitigate interference effects and improve network reliability.\n\
    Another recent study by Azari et al. [21] investigated the impact of interference\
    \ on\nthe performance of 5G networks for IoT applications. The study found that\
    \ interference\ncan cause signiﬁcant degradation of network performance, especially\
    \ for applications\nthat require low latency and high bandwidth. The study recommended\
    \ using adaptive\nbeamforming and dynamic channel allocation to reduce interference\
    \ and improve the\nperformance of 5G networks for IoT applications. Additionally,\
    \ the study highlighted\nthe need for more research into interference management\
    \ techniques that can effectively\nmitigate the impact of interference on 5G networks\
    \ for IoT services.\nSeveral research studies have also investigated the impact\
    \ of interference on the\nenergy consumption of IoT devices connected to 5G networks.\
    \ One recent study by\nSensors 2023, 23, 3876\n7 of 41\nAl-Turjman et al. [22]\
    \ found that interference can cause IoT devices to consume more energy\nto maintain\
    \ connectivity, leading to reduced battery life and increased maintenance costs.\n\
    The study recommended the use of interference management techniques, such as energy-\n\
    efﬁcient channel allocation and scheduling to reduce interference and improve\
    \ the energy\nefﬁciency of IoT devices on 5G networks. The study concluded that\
    \ effective interference\nmanagement techniques are crucial for ensuring the sustainability\
    \ and economic viability\nof IoT services on 5G networks.\nAnother critical area\
    \ of research related to 5G network interference in IoT services is\nthe security\
    \ and privacy implications of interference management techniques. Interference\n\
    management techniques, such as beamforming and channel allocation, require the\
    \ ex-\nchange of information between IoT devices and the network, which can potentially\
    \ expose\nsensitive information to eavesdroppers and attackers. A recent study\
    \ by Hasan et al. [23]\ninvestigated the security and privacy risks associated\
    \ with beamforming and proposed a\nsecure beamforming scheme that uses encryption\
    \ and authentication to protect sensitive\ninformation. The study concluded that\
    \ the security and privacy implications of interference\nmanagement techniques\
    \ must be carefully considered when designing 5G networks for\nIoT services. Effective\
    \ security and privacy measures can help mitigate the risks associated\nwith interference\
    \ management techniques and ensure the integrity and conﬁdentiality of\nIoT data\
    \ on 5G networks.\nOverall, the current state of the art and related work on the\
    \ impact of 5G network\ninterference on IoT services highlight the importance\
    \ of effective interference management\ntechniques to ensure the reliability and\
    \ performance of 5G networks for IoT applications.\nThe studies recommend the\
    \ use of advanced interference management techniques, such as\ndynamic channel\
    \ allocation, power control, adaptive beamforming, and spectrum sharing,\nto mitigate\
    \ the effects of interference and improve network performance. However, more\n\
    research is needed to develop new and more effective interference management techniques\n\
    that can address the unique challenges of 5G networks and IoT services.\nTable\
    \ 1 presents a comparison of IoT services based on the impact of 5G network\n\
    interference on their performance. It describes six parameters as follows:\n1.\n\
    IoT Service: This parameters lists the various IoT services that are considered\
    \ in the\ncomparison.\n2.\nReliability: This metric represents the reliability\
    \ of 5G networks when used to support\nthe respective IoT service. Reliability\
    \ is a measure of the ability of the network to\nprovide consistent and dependable\
    \ service. The values in this column range from low\nto high.\n3.\nMultiple devices\
    \ operate: This metric indicates whether the IoT service can operate\nwith multiple\
    \ devices. This is an important factor to consider since many IoT services\ninvolve\
    \ the connection of multiple devices, and the network needs to support the\nsimultaneous\
    \ communication of these devices.\n4.\nLatency: This parameter measures the amount\
    \ of delay or lag time in transmitting data\nbetween the IoT devices and the network.\
    \ Latency is an important metric to consider\nfor real-time IoT services, such\
    \ as connected vehicles and healthcare monitoring. The\nvalues in this column\
    \ range from low to ultra-low.\n5.\nInterference management techniques: This parameter\
    \ lists the various techniques that\ncan be used to manage interference in the\
    \ network. Interference management is crucial\nto maintain high performance in\
    \ the presence of other devices and networks that\nmay use the same frequency\
    \ bands. The techniques listed in this column include dy-\nnamic frequency selection,\
    \ channel hopping, beamforming, coordinated multi-point\ntransmission, dynamic\
    \ power control, interference avoidance, MIMO (multiple-input,\nmultiple-output)\
    \ [24], cognitive radio, massive MIMO, and interference alignment.\n6.\nEnergy\
    \ consumption: This metric indicates the amount of energy consumed by the\nIoT\
    \ devices and the network. Energy consumption is an important consideration for\n\
    IoT services, especially for those that operate in remote locations or rely on\
    \ battery-\npowered devices. The values in this column range from low to high.\n\
    Sensors 2023, 23, 3876\n8 of 41\nTable 1 compares ten IoT services, including\
    \ smart home automation, smart agricul-\nture, industrial IoT, connected vehicles,\
    \ healthcare monitoring, smart cities, environmental\nmonitoring, smart grid management,\
    \ augmented reality, and drones. For each IoT service,\nthe table lists the parameters\
    \ in each column relevant to the impact of 5G network interfer-\nence on its performance.\
    \ Note that the values in the table are just examples and should be\nreplaced\
    \ with appropriate data from relevant papers. The table provides a helpful overview\n\
    of how different IoT services may be impacted by 5G network interference and what\
    \ factors\nare essential to consider when evaluating the performance of these\
    \ services in the presence\nof interference.\nTable 1. Impact of 5G network interference\
    \ on IoT services\nIoT Service\nReliability\nMultiple\nDevices\nLatency\nInterference\n\
    Management\nEnergy\nConsumption\nSmart home\nautomation [7]\nHigh\nYes\nLow\n\
    Dynamic frequency\nselection\nLow\nSmart agriculture [25]\nMedium\nYes\nMedium\n\
    Channel hopping\nHigh\nIndustrial IoT [26]\nHigh\nYes\nLow\nBeamforming\nMedium\n\
    Connected vehicles [27]\nHigh\nYes\nUltra-low\nCoordinated\nmulti-point\ntransmission\n\
    High\nHealthcare\nmonitoring [28]\nHigh\nYes\nLow\nDynamic power\ncontrol\nLow\n\
    Smart cities [29]\nHigh\nYes\nLow\nInterference\navoidance\nHigh\nEnvironmental\n\
    monitoring [30]\nMedium\nYes\nLow\nMIMO\nLow\nSmart grid\nmanagement [31]\nHigh\n\
    Yes\nLow\nCognitive radio\nHigh\nAugmented reality [32]\nHigh\nNo\nUltra-low\n\
    Massive MIMO\nHigh\nDrones [33]\nHigh\nYes\nUltra-low\nInterference\nalignment\n\
    Medium\n3. Materials and Methods\n4G networks are based on LTE technology, which\
    \ uses a frequency spectrum of around\n700 MHz to 2600 MHz. These frequencies\
    \ are divided into different bands that are used for\ndifferent purposes, such\
    \ as voice and data communication. 4G networks use a combination\nof Frequency\
    \ Division Duplex (FDD) and Time Division Duplex (TDD) techniques to\ntransmit\
    \ and receive data. FDD uses separate frequencies for transmitting and receiving\n\
    data, while TDD uses the same frequency for both.\nOn the other hand, IoT devices\
    \ use a variety of technologies and protocols to com-\nmunicate with each other\
    \ and with the internet. These devices can operate on different\nfrequency bands,\
    \ such as 2.4 GHz, 5 GHz, and sub-GHz bands. Some IoT devices use the\nunlicensed\
    \ spectrum, which means they can operate on any frequency without needing a\n\
    license, while others use the licensed spectrum, which requires a license from\
    \ the relevant\nregulatory body.\nOne of the main issues with 4G services and\
    \ networks is that they can cause inter-\nference with IoT devices, especially\
    \ those operating on the same frequency bands. This\ninterference can cause communication\
    \ problems and even lead to data loss or corruption.\nTo mitigate this interference,\
    \ different methods can be used, such as frequency hopping,\nspread-spectrum techniques,\
    \ and power control.\nSensors 2023, 23, 3876\n9 of 41\nFigure 4 summarizes this\
    \ section, where the main concepts related to the impact of\n5G networks on IoT\
    \ services are observed. We analyze the implementation, the evolution,\nand the\
    \ types of wireless technologies that inﬂuence current services, the leading 5G\n\
    technologies and problems, and the coexistence of next-generation networks. We\
    \ frame\ninterference as the heart of the study of problems in this type of network.\n\
    Figure 4. Materials and Methods for 5G and IoT services.\n3.1. 5G Implementation\
    \ Requirements\n5G is an emerging technology in the telecommunications area. Enabling\
    \ high-speed\nconnections, offering lower latencies, and ensuring highly scalable\
    \ connectivity between mul-\ntiple devices [34], every industry worldwide eagerly\
    \ waits for mainstream implementation.\n5G allows for several technologies related\
    \ to massive machine-to-machine communi-\ncations, or IoT, to improve and offer\
    \ high-speed connectivity between devices, primarily\nallowing automation in the\
    \ manufacturing and construction industries. However, IoT has\nseen massive consumer\
    \ implementation in homes, malls, and parks, which means this\ntechnology has\
    \ several use cases for ordinary daily consumers.\nOn the technical side of 5G,\
    \ it works on a higher spectrum range when compared to\ntraditional wireless technologies.\
    \ Ranging from 24 to 100 GHz, it provides low-latency\ncommunication and high\
    \ throughput rates but suffers from adverse conditions caused\nby its high-frequency\
    \ nature [35]. 5G also operates on two frequency bands: Sub 6 GHz\nand mmWave\
    \ (millimeter wave). While mmWave offers faster data transfer rates, it has\n\
    limited coverage and is easily obstructed. On the other hand, the Sub 6 GHz band,\
    \ which\nincludes frequencies below 6 GHz, offers wider coverage and can penetrate\
    \ obstacles such\nas buildings and walls [36]. This means that 5G can actually\
    \ work in the Sub 6 GHz band,\nproviding a more reliable and accessible network\
    \ for users. This is particularly important\nfor rural and suburban areas where\
    \ building penetration is critical, and for indoor usage\nwhere higher frequency\
    \ bands may not be able to reach. Therefore, despite the hype around\nmmWave,\
    \ the Sub 6 GHz band remains a vital part of the 5G network, providing a strong\n\
    foundation for the future of wireless technology.\nTo counteract the limitations,\
    \ 5G has been complemented with new technologies. The\nmost common ones are beamforming,\
    \ massive MIMO, small cell, mmWave, and network\nslicing, and new proposals arise\
    \ everyday to try and get the most out of this generation.\nSensors 2023, 23,\
    \ 3876\n10 of 41\nEven though 5G is far from being implemented worldwide, several\
    \ service providers\nhave been publicly working and sharing their advances related\
    \ to this technology. Some\nfamous names from the IT world are Ericsson, Verizon,\
    \ Nokia, AT&T, T-Mobile, Samsung,\nand Qualcomm. However, undoubtedly, most big\
    \ telecommunications companies are\nworking on projects related to the new generation\
    \ of wireless technologies.\nResearch groups have been focused on the 5G mobile\
    \ network ecosystem, with institu-\ntions such as METIS (Mobile and wireless communications\
    \ Enablers for Twenty-twenty\n(2020) Information Society), 5G PPP (5G Infrastructure\
    \ Public Private Partnership), and\nNYU New York University Wireless, conducting\
    \ impactful research related to MIMO\ntransmissions, millimeter waves, and frameworks\
    \ in the 5G ecosystem [37].\n5G networks offer several features that are essential\
    \ for the Internet of Things (IoT)\nservices, as Figure 5 shows. 5G provides increased\
    \ bandwidth and lower latency, allowing\nIoT devices to transmit data quickly\
    \ and efﬁciently for real-time communication and\nresponse. 5G enables massive\
    \ machine-type communication (mMTC), which allows a\nlarge number of IoT devices\
    \ to connect to the network simultaneously. Ultra-reliable and\nlow-latency communication\
    \ (URLLC) is also provided, ensuring quick and reliable data\ntransmission suitable\
    \ for mission-critical IoT services. Network slicing is another feature of\n5G\
    \ networks, which creates dedicated virtual networks for IoT devices to provide\
    \ better\nnetwork performance and security.\nFigure 5. 5G features that are essential\
    \ for the Internet of Things services.\nBefore the implementation of 5G networks,\
    \ organizations such as IEEE needed to\ncope with challenges about the implementation\
    \ of 5G. One of these challenges is about the\ndata rate key dimensions, since\
    \ the demand of technology services are increasing in the\npast years. 5G should\
    \ be a solution in order to satisfy all this demand and provide a great\nQuality\
    \ of Service (QoS) [38].\nAnother factor to consider is the latency, which is\
    \ responsible for the delay in incoming\nand outgoing packages on a link, as streaming\
    \ services such as online games [39], metaverse,\nand more demand a low latency\
    \ in order to provide better services.\nSensors 2023, 23, 3876\n11 of 41\nIn modern\
    \ society, most products use electrical power, including, for example, electric\n\
    cars such as Tesla. In other words, we are surrounded by electronic devices, and\
    \ it is\nessential to focus on developing friendly devices to avoid consuming\
    \ too much electricity.\nSome important points about 5G energy consumption need\
    \ to be mentioned. First, energy\nefﬁciency depends on the trafﬁc in the network.\
    \ According to the article “Energy-efﬁcient\n5G for a greener future” [40], when\
    \ the trafﬁc load is low, a base station can save 98.75% of\npower, but if the\
    \ trafﬁc load is high, the power consumption may increase.\nFigure 6 describes\
    \ the requirements for 5G. This generation is the latest generation\nof cellular\
    \ networks that is designed to offer signiﬁcant improvements in performance,\n\
    capacity, and ﬂexibility compared to previous generations. To achieve these improvements,\n\
    5G networks utilize several key technologies. One of these technologies is millimeter\n\
    wave (mmWave) frequencies, which are higher frequency bands that can provide higher\n\
    bandwidth and faster data rates. However, these frequencies have short wavelengths\n\
    and require line-of-sight communication between the transmitter and receiver.\
    \ Another\ntechnology used in 5G networks is massive MIMO (multiple input, multiple\
    \ output)\ntechnology, which uses a large number of antennas to increase the number\
    \ of spatial\nstreams and improve the efﬁciency of the wireless channel. This\
    \ can help to increase the\ndata transfer rates and overall network capacity.\
    \ Beamforming is also a key technology used\nin 5G networks, as it uses advanced\
    \ techniques to focus the radio signal towards a speciﬁc\ndevice, increasing the\
    \ signal strength and reducing interference. This technology is crucial\nfor providing\
    \ reliable and high-speed connectivity in a dense and dynamic environment.\nNetwork\
    \ slicing is another feature of 5G networks that allows for the creation of dedicated\n\
    virtual networks to meet the speciﬁc requirements of different applications. This\
    \ means that\ndevices can allocated their own network resources and services,\
    \ providing better network\nperformance and security. Edge computing is also used\
    \ in 5G networks, which provides real-\ntime processing and analysis of data at\
    \ the edge of the network. This can help to reduce the\nlatency and improve the\
    \ performance of time-sensitive applications, such as autonomous\nvehicles and\
    \ virtual reality. Low latency is another feature of 5G networks that is important\n\
    for applications that require real-time communication and response, such as autonomous\n\
    vehicles and remote surgery. 5G networks aim to achieve a latency of less than\
    \ 1 millisecond.\nHigh reliability is also a critical feature of 5G networks,\
    \ with features such as network slicing\nand redundant network paths, ensuring\
    \ that devices stay connected. This is essential for\nmission-critical applications\
    \ that require high availability and low downtime. 5G networks\nsupport full duplex\
    \ communication, which allows for simultaneous transmission and\nreception of\
    \ data. This technology can help to improve the efﬁciency and capacity of the\n\
    network, enabling higher data transfer rates and reducing latency.\nBased on the\
    \ requirements above, the following are the 5G network deployment\nrequirements:\n\
    •\nMillimeter wave (mmWave) frequencies for higher bandwidth and faster data rates.\n\
    •\nMassive MIMO (multiple input, multiple output) technology for increasing spatial\n\
    streams and improving the wireless channel’s efﬁciency.\n•\nBeamforming to focus\
    \ the radio signal towards a speciﬁc device, increasing signal\nstrength and reducing\
    \ interference.\n•\nNetwork slicing for creating dedicated virtual networks to\
    \ meet the speciﬁc require-\nments of different applications, improving network\
    \ performance and security.\n•\nEdge computing for real-time processing and analysis\
    \ of data at the edge of the net-\nwork, reducing latency and improving the performance\
    \ of time-sensitive applications.\n•\nLow latency for real-time communication\
    \ and response, aiming to achieve a latency of\nless than 1 millisecond.\n•\n\
    High reliability for mission-critical applications, ensuring high availability\
    \ and low\ndowntime.\n•\nFull duplex communication for simultaneous transmission\
    \ and reception of data,\nimproving efﬁciency, capacity, and reducing latency.\n\
    Sensors 2023, 23, 3876\n12 of 41\nThe combination of these technologies in 5G\
    \ networks can enable a wide range of\napplications, from IoT services to high-bandwidth\
    \ applications, such as virtual reality and\naugmented reality. 5G networks aim\
    \ to provide the necessary performance metrics to\nsupport these applications,\
    \ enabling the growth of the IoT ecosystem and a new era of\nconnectivity.\nFigure\
    \ 6. 5G implementation requirements.\n3.2. Evolution of Wireless Networks\nWireless\
    \ networks [41] have an important role in our society, because they allow us to\n\
    keep connected in a network without cables, being the bridge to create useful\
    \ tools. For\ninstance, 3GPP provides basic data services such as voice and messaging\
    \ capabilities, with\n4G we can make video calls, and use IP services, and with\
    \ 5G we can get more beneﬁts,\nsuch as low latency, more bandwidth, and other\
    \ interesting features [42].\n3.3. Evolution of IoT\nThe evolution of the internet\
    \ allowed remote connections between machines, and\nthe protocol standardization\
    \ used to transmit the information, such as TCP/IP, enabled\nresearchers to take\
    \ advantage of the internet and allowed to creation of new protocols and\nways\
    \ to transmit the data [43]. Since then, new technologies has arrived in our lives,\
    \ which\nis the case of IoT. In the last few years, new technologies and protocols\
    \ arose to connect\nand transmit data between IoT devices and networks, each providing\
    \ speciﬁc features\nto perform the applications. In the following statements,\
    \ we mention some protocols to\ncommunicate data. Each protocol can provide better\
    \ communication depending on the\napplication. For example, LoRaWAN is used in\
    \ long-range communication, allowing to\ntransmit of data through large distances\
    \ even with obstacles between the link and using\nlow power consumption. Zigbee\
    \ is a protocol commonly used in smart homes, avoiding\ninferences by routers,\
    \ electronic devices, and so on.\nSensors 2023, 23, 3876\n13 of 41\nThe evolution\
    \ of IoT technologies is having a signiﬁcant impact on 5G networks. As\nmore and\
    \ more devices are connected to the internet, there is a growing need for faster,\n\
    more reliable connectivity. This is where 5G networks come in, providing higher\
    \ speeds,\nlower latency, and greater capacity than previous wireless technologies.\
    \ The proliferation\nof IoT devices also creates new opportunities for 5G, as\
    \ the technology is able to support the\nmassive amounts of data generated by\
    \ these devices. However, this also poses challenges\nfor 5G networks, such as\
    \ the need to handle large amounts of trafﬁc from a variety of\ndevices with different\
    \ requirements. As a result, the evolution of IoT technologies is\ndriving innovation\
    \ in 5G networks, as providers look for ways to meet the demands of this\ngrowing\
    \ ecosystem.\nThe implementation of 5G networks is expected to have a signiﬁcant\
    \ impact on the\nevolution of IoT services. One of the most signiﬁcant changes\
    \ is the increase in the speed\nof data transfer. 5G networks have much faster\
    \ data transfer speeds, lower latency, and\nhigher capacity than previous generations\
    \ of mobile networks [44]. This means that IoT\ndevices can transmit and receive\
    \ data much more quickly, which enables more real-time\ndata processing and analysis.\
    \ The improved responsiveness of IoT services will open up\nopportunities for\
    \ new applications that require near-instantaneous data processing, such\nas remote\
    \ surgery, autonomous vehicles, and industrial automation.\nAnother important\
    \ change brought about by the implementation of 5G networks is\nthe increased\
    \ scalability of IoT services. 5G networks have a higher device density, which\n\
    means that they can support a greater number of IoT devices per unit area. This\
    \ will help\nto increase the scalability of IoT services and allow for the deployment\
    \ of more complex\nand sophisticated IoT solutions.\nFurthermore, 5G networks\
    \ are expected to improve the reliability of IoT services. 5G\nnetworks have more\
    \ robust error correction capabilities and redundancy features, which\ncan increase\
    \ the reliability of IoT services. This is particularly important for mission-critical\n\
    applications, such as remote monitoring of infrastructure or medical devices [45].\
    \ Improved\nreliability will also be beneﬁcial in industries that require highly\
    \ reliable communication\nnetworks, such as manufacturing and energy.\nThe enhanced\
    \ security features of 5G networks will also impact the evolution of IoT\nservices.\
    \ 5G networks offer improved security features, such as network slicing, which\n\
    allows for the creation of isolated virtual networks for different IoT applications.\
    \ This can\nhelp to prevent unauthorized access and ensure the security and privacy\
    \ of IoT data. With\nthe increasing number of IoT devices, the importance of security\
    \ and privacy is critical and\n5G networks can provide a more secure environment\
    \ for the data transmitted.\n5G networks will help to reduce the power consumption\
    \ of IoT devices. 5G networks\nare designed to be more energy efﬁcient than previous\
    \ generations of mobile networks [46].\nThis can help to reduce the power consumption\
    \ of IoT devices, prolonging their battery life\nand reducing their environmental\
    \ impact. This is particularly important for IoT devices\nthat are difﬁcult or\
    \ expensive to replace or recharge, such as sensors deployed in remote\nor inaccessible\
    \ locations. Figure 7 describes the main features related to 5G networks and\n\
    IoT services. The performance metrics associated with energy consumption are mentioned\n\
    here too.\nSensors 2023, 23, 3876\n14 of 41\nFigure 7. Deﬁning 5G and features\
    \ that are essential for the Internet of Things services.\n3.4. Wireless Communication\
    \ Technologies for IoT and Cloud-Based Solutions\nThis section covers various\
    \ wireless communication protocols used in IoT devices,\nincluding Wi-Fi AdHoc,\
    \ Zigbee, Z-Wave, LoRaWAN, and SigFox. It also touches on the\nuse of cloud computing\
    \ for IoT applications, such as data storage, analytics, and remote\ndevice management.\
    \ This section could provide a comprehensive overview of wireless\ncommunication\
    \ technologies used in IoT devices and their integration with cloud-based\nsolutions.\n\
    1.\nWi-Fi AdHoc: With the standard of IEEE 802.11, Wi-Fi technology turned into\
    \ the\nﬁrst technology to create devices connected to the network. Allowing to\
    \ create news\narchitectures such as Wi-Fi AdHoc is a decentralized type of wireless\
    \ network because\neach node participates in routing by forwarding data to other\
    \ nodes [47]. These nodes\ncan be IoT devices and are very helpful in applications\
    \ where it is needed to have\nmany devices connected.\n2.\nZigbee: The most popular\
    \ industry wireless mesh networking standard for connecting\nsensors, instrumentation,\
    \ and control systems. Zigbee implements communication in\na personal wireless\
    \ area network, providing low power consumption and interoper-\nating multi-vendor,\
    \ commonly used in home automation, low-power consumption\nsensors, HVAC (Heating,\
    \ Ventilation, and Air Conditioning) control, etc. [48].\n3.\nZ-Wave: A wireless\
    \ protocol evolved by Zensys and conﬁrmed by the Z-Wave Alliance\nfor automation\
    \ apparatuses for home and commercial environments. This protocol\nallows transmitting\
    \ short messages with minimum noise and uses a Mesh network\nconﬁguration [49].\n\
    4.\nLoRaWAN: A low-power, wide-area networking protocol designed to connect battery\n\
    wirelessly operated ‘things’ to the internet in regional, national, or global\
    \ networks. It\ntargets IoT requirements, such as bi-directional communication,\
    \ end-to-end security,\nmobility, and localization services. According to work\
    \ cited in [50], LoRa has the most\nfeatures in terms of IoT, such as low power\
    \ consumption, long-range communication,\netc. Furthermore, the paper tested communication\
    \ in urban and forest areas, showing\nthat LoRaWAN can transmit data up to 2.1\
    \ km in urban areas.\nSensors 2023, 23, 3876\n15 of 41\n5.\nSigFox: SigFox is\
    \ a network operator dedicated to the Internet of Things. The SigFox\nnetwork\
    \ uses the ultra-narrow band, allowing devices to communicate with low\npower\
    \ on a wide area [51].\n6.\nCloud Computing: Cloud computing is a term used to\
    \ describe both a platform and a\ntype of application. One of the essential features\
    \ of cloud computing is the capability\nto assign dynamic resources to the network,\
    \ being an important key to providing\nscalable solutions and avoiding high costs.\
    \ The interference plays an important\nrole when connecting devices since the\
    \ signal quality decrease, which means the\nmodulation decreases and the bits\
    \ per error increases. That is a problem if we are\ntrying to offer large bandwidths\
    \ and low latency in each data transmission [52]. We\nmust consider different\
    \ factors to provide a great QoS, like the weather, buildings,\nhardware, software\
    \ resources, etc. In the IoT context, the buildings and distances\ncreate the\
    \ main interferences. For that reason, technologies such as Zigbee, SigFox,\n\
    LoRaWAN, and Z-wave play a vital role in connecting devices.\n7.\nWiGig: WiGig,\
    \ also known as 802.11ay, is a wireless communication technology that\noperates\
    \ on the 60 GHz frequency band [53]. It was developed as an extension of the\n\
    Wi-Fi standard to provide high-speed, short-range wireless communication, primarily\n\
    for applications that require high bandwidth, such as virtual reality, high-deﬁnition\n\
    video streaming, and gaming. WiGig supports multi-gigabit data transfer rates,\
    \ with\ntheoretical speeds of up to 176 Gbps, which is much faster than the previous\
    \ Wi-\nFi standards [54]. It achieves this speed through the use of wider bandwidth\
    \ and\nadvanced modulation techniques, such as Quadrature Amplitude Modulation\
    \ (QAM)\nand Orthogonal Frequency Division Multiplexing (OFDM). Another notable\
    \ feature\nof WiGig is its low latency, making it ideal for applications that\
    \ require real-time\ndata transfer, such as gaming and virtual reality [55]. It\
    \ also supports multiple-input,\nmultiple-output technology, which enables multiple\
    \ antennas to transmit and receive\ndata simultaneously, improving the overall\
    \ performance and efﬁciency of the network.\nIn the context of 5G networks, WiGig\
    \ can be used as a complementary technology\nto provide high-speed local area\
    \ network (LAN) connections for mobile devices and\nIoT devices. The 60 GHz frequency\
    \ band has a limited range, but it can support high\ndata rates over short distances,\
    \ making it suitable for applications, such as augmented\nand virtual reality\
    \ (AR/VR), wireless HD video streaming, and cloud gaming [56]. In\naddition, WiGig\
    \ can be used as a backhaul technology for small cells in 5G networks,\nenabling\
    \ high-speed data transfers between small cells and the core network. This\ncan\
    \ help improve the performance and capacity of 5G networks, especially in densely\n\
    populated urban areas where there is high demand for data services. Regarding\
    \ IoT\nservices, WiGig can enable high-speed local area connections between IoT\
    \ devices,\nallowing them to share data quickly and efﬁciently. This can be especially\
    \ useful for\napplications, such as smart homes, where multiple IoT devices need\
    \ to communicate\nwith each other in real time.\n3.5. 5G Applications\n5G beneﬁts\
    \ are not utilized solely by the most prominent IT corporations world-\nwide.\
    \ In the modern era, we have found several exciting applications where 5G’s high\n\
    speeds, excellent reliability, and energy efﬁciency come into play and provide\
    \ a better\nuser experience.\n•\nEntertainment services: Video-on-demand services\
    \ are currently one of the most\nutilized services on the internet. These services\
    \ demand high-speed connections, and\nwith rising trends to utilize higher resolution\
    \ devices, 5G plays a vital role in providing\noptimal user experience so that\
    \ they can consume their content without interruption.\n•\nGeneral mobile networks:\
    \ Due to the COVID-19 pandemic in recent years, teleworking\nhas seen an immense\
    \ rise in all sectors globally. This means workers must be able\nto respond to\
    \ video or voice calls at any given time, requiring improved downlink\nand uplink\
    \ speeds. These requirements, complemented with the higher reliability\nSensors\
    \ 2023, 23, 3876\n16 of 41\naspects of 5G, mean that this implementation will\
    \ improve communications in any\ngiven context, especially for work-related tasks.\n\
    •\nInternet of Things: IoT is one of the trendiest topics around the electronics\
    \ ecosys-\ntem, due to its nature to provide automation to simple or very complex\
    \ topics. Even\nthough most IoT devices currently utilize 3G or 4G-LTE technologies\
    \ due to their low\nrequirements for data connectivity, a new generation of IoT\
    \ devices requires higher\nthroughput rates. These requirements are on the limits\
    \ of the current generation of\nwireless technologies, which makes 5G an interesting\
    \ contestant to solve these require-\nments. The most popular IoT applications\
    \ today involve Smart Homes, industries,\nor farming, which generally require\
    \ low amounts of wireless capabilities because\nthe devices have low microprocessing\
    \ power due to the nature of the technology\nitself. However, new trends, such\
    \ as Smart Cities or IoV (Internet of Vehicles), require\nmuch greater throughput\
    \ to function correctly and offer an optimal user experience.\nThese types of\
    \ solutions require capabilities that are only offered by 5G. IoT data\nare visioned\
    \ to increase in data provided per area by 1000 times [57] which means\nIoT applications\
    \ will be part of our everyday lives. The current data are provided\nmainly by\
    \ sensors, but more complex devices will mean that data will be gathered\nfrom\
    \ additional sources. This exponential growth in data consumption will also need\n\
    to be stored in scalable data storages, and this is where cloud computing comes\
    \ in.\nSome of the most famous architectural trends of IoT devices follow three\
    \ principles:\nHardware: All sensor nodes that gather data, their communication\
    \ methods, and the\nhardware interface with the user.\nMiddleware: The layer in\
    \ charge of storing and analyzing the data and monitoring\nthe devices.\nPresentation\
    \ layer: Commonly called the front end, this presents visualization tools\nbetter\
    \ to understand our devices’ current state and behavior.\n5G technologies can\
    \ impact the hardware and middleware layer. As the technology is\nmore energy\
    \ efﬁcient, the devices do not need massive antennas, which can lead to\nincreased\
    \ consumption. At the middleware layer, as devices can communicate more\ndata\
    \ in a given period, this layer will beneﬁt from extra data to improve any statistical\n\
    or machine learning model.\n3.6. 5G Technologies\nThe purpose of this section\
    \ is to describe some of the most popular technologies\nimplemented with 5G.\n\
    Figure 8 shows characteristics and technical speciﬁcations of 5G. 5G networks\
    \ offer\nseveral key characteristics and technical speciﬁcations that make them\
    \ ideal for a wide range\nof applications. 5G provides signiﬁcantly increased\
    \ bandwidth, enabling faster data transfer\nrates for high-speed applications,\
    \ such as virtual and augmented reality. It also offers lower\nlatency, making\
    \ it suitable for real-time communication and response applications, such\nas\
    \ autonomous vehicles and remote surgery. 5G is highly reliable, with features\
    \ such\nas network slicing and redundant network paths, ensuring devices stay\
    \ connected. 5G\nenables massive machine-type communication (mMTC) and ultra-reliable\
    \ and low-latency\ncommunication (URLLC), making it suitable for mission-critical\
    \ applications, such as\nindustrial automation. Additionally, 5G offers network\
    \ slicing, beamforming, and uses\nmillimeter wave (mmWave) frequencies for even\
    \ higher bandwidth and faster data rates.\nOverall, 5G networks offer signiﬁcant\
    \ improvements in bandwidth, latency, reliability, and\nﬂexibility, making them\
    \ well-suited for a wide range of applications.\nSensors 2023, 23, 3876\n17 of\
    \ 41\nFigure 8. Characteristics and technical speciﬁcations of 5G networks.\n\
    1.\nMassive MIMO: This technology is responsible for sending and receiving multiple\n\
    signals simultaneously, utilizing the same radio channel. While other technologies,\n\
    such as Wi-Fi or 4G-LTE, have utilized this technology, massive MIMO performs\
    \ best\nwhen paired with 5G technologies. This technology uses extra antennas\
    \ to move\nenergy into smaller regions of space, which means spectral efﬁciency\
    \ and coverage\nare improved [58].\n2.\nNOMA: Non-Orthogonal Multiple Access:\
    \ A radio access technology that plays a vital\nrole in 5G applications [59].\
    \ This technology offers several beneﬁts, such as low latency\nand massive high-speed\
    \ connectivity. Code domain NOMA is commonly paired with\nmMIMO, drastically improving\
    \ spectral efﬁciency [60]. Power domain NOMA is\ncommonly utilized with MIMO,\
    \ beamforming, and even cooperative communications,\nbeing one of the most ﬂexible\
    \ technologies utilized in 5G implementations.\n3.\nMillimeter Wave: This technology\
    \ uses a frequency band between 30 GHz and\n300 GHz and derives its name from\
    \ the 1 to 10 mm waves utilized by the tech-\nnology. Utilized commonly in radar\
    \ applications, this technology is being paired with\n5G to improve spectrum bandwidth\
    \ and increase spectrum utilizations. The main\nbeneﬁt of pairing this technology\
    \ with 5G is the spectrum freedom linked to mmWave.\nStandard technologies, such\
    \ as GPS, 4G, and satellite connections, utilize the 1 GHz\nto 6 GHz spectrum,\
    \ which is becoming very crowded [61]. Because mmWave is new\nand has a massive\
    \ spectral range, 5G provides an improved user experience through\nthis combination.\n\
    4.\nMachine Learning Techniques: Supervised and unsupervised models are being\
    \ im-\nplemented in 5G technologies to improve overall network capacities, predict\
    \ energy\nconsumption, and optimize tracking technologies such as beamforming.\
    \ In the su-\npervised category, some 5G networks utilize Linear Regression Algorithms\
    \ to predict\nthe scheduling of nodes [62]. Other supervised models utilize Deep\
    \ Neural Networks\nto predict beamforming vectors. Then, unsupervised learning\
    \ models are used to\nimprove handover selection and reduce interruption of services,\
    \ as well as they can\nreduce latency by clustering fog nodes.\n5.\nUnmanned Aerial\
    \ Vehicles (UAV): Being the most innovative proposal, current 5G\nresearchers\
    \ are utilizing UAVs to improve network coverage. These UAVs will assist\nthe\
    \ terrestrial network by serving as beacons. The high altitude of these planes\
    \ could\nsolve many interference problems and even replace entirely terrestrial\
    \ cellular net-\nworks [63]. UAVs, commonly known as drones, have become increasingly\
    \ popular for\nboth commercial and personal use. With the advent of 5G networks\
    \ and IoT, UAVs\ncan now be equipped with a wide range of sensors and devices\
    \ that can transmit\nreal-time data to ground stations for analysis and decision\
    \ making [64]. There are\nseveral potential implementations of UAVs in the context\
    \ of 5G and IoT. One such\nimplementation is in the area of precision agriculture.\
    \ UAVs can be used to gather data\non crop growth, soil conditions, and other\
    \ factors that affect agricultural production.\nThese data can be transmitted\
    \ in real time to a ground station for analysis and used\nSensors 2023, 23, 3876\n\
    18 of 41\nto optimize planting, fertilization, and irrigation schedules [65].\
    \ 5G networks and\nIoT sensors can provide the necessary bandwidth and low latency\
    \ for this type of\napplication. Another potential application of UAVs in the\
    \ context of 5G and IoT is\nin industrial inspection and maintenance. UAVs equipped\
    \ with cameras and other\nsensors can be used to inspect and monitor equipment\
    \ and infrastructure such as\npower lines and wind turbines. Real-time data transmission\
    \ via 5G networks can\nenable remote monitoring and control of these systems,\
    \ improving their reliability\nand reducing maintenance costs [66]. UAVs can also\
    \ be used for emergency response\nand disaster management. In the event of a natural\
    \ disaster, such as a hurricane or\nearthquake, UAVs can be deployed to assess\
    \ damage and provide real-time informa-\ntion to ﬁrst responders. The data collected\
    \ can be transmitted via 5G networks to\nemergency management centers for analysis\
    \ and decision making. UAVs can be used\nfor surveillance and security purposes.\
    \ In public safety applications, UAVs can be\nused to monitor crowd movements\
    \ and gather intelligence on potential threats. In\nprivate security applications,\
    \ UAVs can be used to patrol and monitor facilities for\nintruders or other security\
    \ threats. The combination of UAVs with 5G networks and\nIoT sensors can enable\
    \ a wide range of applications in various industries. With the\npotential to improve\
    \ efﬁciency, reduce costs, and enhance safety, it is likely that we\nwill see\
    \ an increase in the adoption of UAVs in the coming years.\n3.7. 5G Problems\n\
    5G offers excellent improvements over last-generation mobile communication tech-\n\
    nologies. However, many problems related to technological complications, security\
    \ and\nprivacy implications, and even social implications have been discovered.\n\
    Technical complications are related primarily to interference. 5G as a technology\
    \ has\ncomplications related to interference, being as sensible as being dramatically\
    \ affected by\nmild rain in urbanized areas [67]. Even though the technologies\
    \ mentioned previously\nhelp mitigate these problems, 5G still needs to be ready\
    \ to be used on a massive scale.\nTests performed in several countries utilizing\
    \ small cells show the need for more extensive\narchitectures to offer full coverage\
    \ and optimal user experience [68]. This means costly\narchitectures will lead\
    \ providers to focus mainly on urban areas, leaving rural areas unat-\ntended.\
    \ This leads to the following obstacles, which are ethical and social implications.\n\
    One of the main advantages of 5G is the ability to offer improved connections\
    \ to people\nin poor conditions. However, right now, it is only used as a marketing\
    \ stunt because 5G\narchitectures are considerably expensive and cannot offer\
    \ coverage in rural areas. As 5G\nequipment and technology become more widely\
    \ adopted in the following years, we expect\nbig strides in this department.\n\
    Another ethical and social implication is IoV technologies enabled by 5G. As we\
    \ see\nmore autonomous driving cars, and 5G will enable more precise driving for\
    \ these cars, as\nwell as broad adoption of them, we are encountering huge moral\
    \ dilemmas in cases where\ncar accidents are caused by autonomous vehicles. Security\
    \ implications arise from the trend\nof connecting vehicles to the internet, which\
    \ means people can be kidnapped remotely by\ntheir car if hackers gain control\
    \ of their vehicle via the web.\nThe main problems mentioned and explained above\
    \ are listed below:\n•\nTechnical complications related to interference, including\
    \ sensitivity to mild rain in\nurban areas.\n•\nNeed for extensive and costly\
    \ architectures to offer full coverage and optimal user\nexperience, which may\
    \ lead providers to focus mainly on urban areas, leaving rural\nareas unattended.\n\
    •\nEthical and social implications related to the inability to offer improved\
    \ connections\nto people in poor conditions due to the high cost of 5G architectures\
    \ and the lack of\ncoverage in rural areas.\n•\nSecurity implications arising\
    \ from the trend of connecting vehicles to the internet,\nwhich could result in\
    \ remote kidnappings by hackers.\nSensors 2023, 23, 3876\n19 of 41\nTable 2 compares\
    \ the problems presented by 5G and IoT services across several key\nareas, namely\
    \ security, latency, interference, cost, and compatibility. In terms of security,\n\
    5G networks are vulnerable to a range of threats, such as DDoS attacks, identity\
    \ theft, and\nman-in-the-middle attacks, while IoT devices can suffer from security\
    \ breaches due to weak\nencryption, passwords, and outdated ﬁrmware. Regarding\
    \ latency, 5G networks have lower\nlatency, which can be a problem for certain\
    \ IoT applications that require real-time response,\nwhile IoT services may suffer\
    \ from latency due to network congestion, distance from the\nserver, and the number\
    \ of devices connected to the network. Interference is another factor\nthat can\
    \ affect both 5G and IoT services, with both being susceptible to interference\
    \ from\nother wireless devices and environmental factors. Cost is also a concern,\
    \ as the high cost of\n5G infrastructure and services may limit its usefulness\
    \ for many IoT applications, while IoT\nservices may also be expensive to deploy\
    \ and maintain, particularly if they require high\nbandwidth or specialized hardware.\
    \ Finally, compatibility is a potential issue for both 5G\nand IoT services, with\
    \ some IoT devices not being compatible with 5G networks, and IoT\nservices limited\
    \ by compatibility issues with proprietary hardware or software.\nTable 2. Comparison\
    \ of problems presented by 5G and IoT services\nProblem\n5G\nIoT Services\nSecurity\n\
    5G networks are vulnerable to various security threats,\nsuch as DDoS attacks,\
    \ identity theft, and\nman-in-the-middle attacks.\nIoT devices are susceptible\
    \ to security breaches\ndue to poor encryption, weak passwords, and\noutdated\
    \ ﬁrmware.\nLatency\n5G networks have lower latency, which can be a\nproblem for\
    \ certain IoT applications that require\nreal-time response.\nIoT services may\
    \ suffer from latency due to\nnetwork congestion, distance from the server, and\n\
    the number of devices connected to the network.\nInterference\n5G networks can\
    \ experience interference from other\nwireless devices, which can disrupt the\
    \ transmission of\ndata.\nIoT services may also suffer from interference due\n\
    to environmental factors, such as obstacles and\ninterference from other wireless\
    \ devices.\nCost\nThe cost of 5G infrastructure and services may be\nprohibitively\
    \ high for many IoT applications,\nparticularly those that require large-scale\
    \ deployment.\nIoT services may also be expensive to deploy and\nmaintain, particularly\
    \ if they require high\nbandwidth or specialized hardware.\nCompatibility\nSome\
    \ IoT devices may not be compatible with 5G\nnetworks, which can limit their usefulness\
    \ in certain\napplications.\nIoT services may also be limited by compatibility\n\
    issues, particularly if they rely on proprietary\nhardware or software.\n3.8.\
    \ Coexistence of 5G Networks and IoT Applications\nThe coexistence of 5G networks\
    \ and IoT applications has the potential to revolu-\ntionize several industries\
    \ by providing ultra-reliable and low-latency communication,\nmassive machine-type\
    \ communications, and network slicing for multiple services and\napplications\
    \ [18]. One novel idea is the use of 5G networks for industrial automation and\n\
    autonomous vehicles, where ultra-reliable and low-latency communication is critical\
    \ for\nensuring the safety and reliability of the system. Another innovative application\
    \ is the use\nof 5G networks for vehicle-to-everything communication, where autonomous\
    \ vehicles can\nexchange information with other vehicles and infrastructure to\
    \ improve trafﬁc management\nand safety [69]. The use of 5G networks for smart\
    \ cities and agriculture can also be highly\nbeneﬁcial, as it can enable massive\
    \ machine-type communication to support a large number\nof IoT devices, such as\
    \ sensors and actuators, and facilitate data collection, analysis, and\ndecision\
    \ making. Additionally, the use of network slicing can enable multiple services\
    \ and\napplications to coexist on the same infrastructure while maintaining their\
    \ unique require-\nments for security, reliability, and latency. However, the\
    \ coexistence of 5G networks and IoT\napplications also presents several challenges,\
    \ such as security, interference, compatibility,\nand cost [35]. For example,\
    \ security is critical for protecting IoT devices and networks from\ncyber attacks,\
    \ while interference from other wireless devices and environmental factors can\n\
    affect both 5G and IoT services. Moreover, compatibility issues can arise when\
    \ IoT devices\nSensors 2023, 23, 3876\n20 of 41\nare not compatible with 5G networks,\
    \ and the high cost of deploying and maintaining 5G\ninfrastructure and IoT services\
    \ can limit their widespread adoption. Overall, the coexis-\ntence of 5G networks\
    \ and IoT applications presents both opportunities and challenges and\nrequires\
    \ careful consideration of their technical requirements, security, and compatibility\
    \ to\nrealize their full potential.\nTable 3 provides a summary of the coexistence\
    \ of various 5G services and networks\nwith IoT applications. It highlights the\
    \ wireless technology, algorithms used, and coex-\nistence of services with 4G\
    \ and Wi-Fi. The table includes several 5G services, such as\n5G NR, 5G-V2X, 5G\
    \ mMTC, 5G-UHD, 5G-IoT, 5G-eMBB, 5G-URLLC, 5G-mIoT, 5G-gNB,\nand 5G-Slicing, and\
    \ describes their potential applications and system description. The 5G\nservices\
    \ offer different beneﬁts and are designed for speciﬁc applications, such as ultra-\n\
    reliable and low-latency communications for industrial automation, vehicle-to-everything\n\
    communications for trafﬁc management and safety, massive machine-type communications\n\
    for smart cities and agriculture, ultra-high-deﬁnition video communications and\
    \ virtual re-\nality, Internet of Things communications for smart homes and wearables,\
    \ enhanced mobile\nbroadband for high-speed data transfer and streaming, ultra-reliable\
    \ and low-latency com-\nmunications for mission-critical applications, massive\
    \ IoT communications for smart cities\nand agriculture, gigabit-class communications\
    \ for high-speed data transfer and streaming,\nand network slicing for multiple\
    \ services and applications. The table provides a useful\noverview of the coexistence\
    \ of 5G and IoT services and can be helpful in understanding the\npotential beneﬁts\
    \ and challenges of deploying these technologies together.\nTable 3. Coexistence\
    \ of 5G services and networks and Internet of things applications\nService\nWireless\n\
    Technology\nAlgorithms\nUsed\nCoexistence of Services\nApplications and System\
    \ Description\n5G NR [70]\nNR-U\nNOMA\nCoexisting with 4G\nand Wi-Fi\nUltra-reliable\
    \ and low-latency\ncommunications for industrial automation and\nautonomous vehicles\n\
    5G-V2X [71]\nPC5\nOFDMA\nCoexisting with 4G\nand Wi-Fi\nVehicle-to-everything\
    \ communications for trafﬁc\nmanagement and safety\n5G mMTC [72]\nNR-MTC\nNOMA\n\
    Coexisting with 4G\nand Wi-Fi\nMassive machine-type communications for\nsmart\
    \ cities and agriculture\n5G-UHD [73]\nNR-U\nOFDMA\nCoexisting with 4G\nand Wi-Fi\n\
    Ultra-high-deﬁnition video communications and\nvirtual reality\n5G-IoT [74]\n\
    NR-MTC\nNOMA\nCoexisting with 4G\nand Wi-Fi\nInternet of things communications\
    \ for smart\nhomes and wearables\n5G-eMBB [75]\nNR-eMBB\nOFDMA\nCoexisting with\
    \ 4G\nand Wi-Fi\nEnhanced mobile broadband for high-speed data\ntransfer and streaming\n\
    5G-URLLC [76]\nNR-URLLC\nNOMA\nCoexisting with 4G\nand Wi-Fi\nUltra-reliable and\
    \ low-latency communications\nfor mission-critical applications\n5G-mIoT [77]\n\
    NR-mIoT\nNOMA\nCoexisting with 4G\nand Wi-Fi\nMassive IoT communications for smart\
    \ cities\nand agriculture\n5G-gNB [78]\nNR-gNB\nOFDMA\nCoexisting with 4G\nand\
    \ Wi-Fi\nGigabit-class communications for high-speed\ndata transfer and streaming\n\
    5G-Slicing [79]\nNR-Slicing\nNOMA\nCoexisting with 4G\nand Wi-Fi\nNetwork slicing\
    \ for multiple services\nand applications\n3.9. Interference and Network Optimization\
    \ Difﬁculties\nNowadays, with the development of new technologies, networks face\
    \ different chal-\nlenges. Issues such as coverage, latency, availability, and\
    \ accessibility, among others, appear.\nMoreover, taking into account a more profound\
    \ or more centralized point to the character-\nistics of the network, issues such\
    \ as latency, interference, spectrum use according to the\ntechnology being used,\
    \ and others appear.\nSensors 2023, 23, 3876\n21 of 41\nInterference in 5G networks\
    \ can occur due to a variety of factors such as environmental\nconditions, radio\
    \ frequency congestion, and the deployment of too many access points\nin a limited\
    \ area. These issues can cause signal loss or degradation, resulting in poor\n\
    network performance and reduced data transfer rates. Interference in 5G networks\
    \ can\nhave a signiﬁcant impact on IoT devices that rely on a stable and reliable\
    \ connection to\noperate effectively.\nIoT devices are designed to transmit small\
    \ amounts of data over long periods, often\nusing low power and low bandwidth\
    \ networks. The interference in 5G networks can cause\ndelays or interruptions\
    \ in the transmission of data between IoT devices and the cloud-based\nsystems\
    \ they rely on. These disruptions can impact critical functions, such as real-time\n\
    monitoring of environmental conditions, trafﬁc management, and energy consumption.\
    \ In\naddition, interference in 5G networks can result in increased latency, which\
    \ can make it\ndifﬁcult for IoT devices to communicate with each other in a timely\
    \ manner.\nAnother critical aspect of interference in 5G networks is the potential\
    \ for security\nbreaches. As the number of connected devices increases, the risk\
    \ of cyber attacks also\ngrows. Interference in 5G networks can make it easier\
    \ for hackers to gain unauthorized\naccess to IoT devices and the data they transmit.\
    \ This can have serious consequences,\nparticularly for devices that are used\
    \ in critical infrastructure, such as healthcare systems,\npower grids, and transportation\
    \ networks.\nTo mitigate the impact of interference in 5G networks on IoT devices,\
    \ it is essential to\nensure that the network is properly conﬁgured and managed.\
    \ This includes deploying ac-\ncess points strategically to minimize congestion,\
    \ using directional antennas to focus signals\nand reduce interference, and implementing\
    \ security measures to prevent unauthorized\naccess. In addition, new technologies\
    \ such as edge computing and network slicing can help\nto reduce latency and improve\
    \ the reliability of IoT device communication.\nTable 4 outlines some of the main\
    \ types of interference that can impact 5G networks\nand the IoT. Interference\
    \ can occur due to a variety of factors, such as noise, multipath,\nco-channel\
    \ interference, interference from other devices or wireless networks, and jamming.\n\
    One of the key aspects of network performance that interference can affect is\
    \ coverage.\nInterference can reduce the coverage of a wireless network by increasing\
    \ the signal-to-\nnoise ratio (SNR) threshold required for reliable communication.\
    \ When there is noise,\nmultipath, or interference from other wireless networks\
    \ present, signals may not reach as\nfar or penetrate as deeply into buildings,\
    \ resulting in reduced overall coverage. Another\naspect that can be affected\
    \ by interference is latency. Interference can increase latency by\nintroducing\
    \ delays in signal transmission or reception. For instance, multipath interference\n\
    can cause signals to arrive at a receiver at slightly different times, leading\
    \ to signal distortion\nand increased latency. This delay can be particularly\
    \ problematic for real-time applications,\nsuch as gaming or video conferencing.\
    \ Interference can also impact the availability of a\nwireless network. When there\
    \ is co-channel interference or interference from other devices,\nit can cause\
    \ collisions or channel saturation, leading to reduced availability. This can\
    \ result\nin packet loss or connection drops, making it difﬁcult for users to\
    \ access the network and\nresulting in a poor user experience. Access to a wireless\
    \ network can also be affected by\ninterference. Interference can make it harder\
    \ for devices to connect to a network, leading\nto connection failures or reduced\
    \ bandwidth. This can be particularly problematic in\nareas with high device density,\
    \ such as urban environments. Interference can also affect\nmodulation and coding.\
    \ When there is interference present, the quality of the signal can\ndegrade,\
    \ making it more difﬁcult for the receiver to demodulate and decode the signal.\n\
    This can result in errors and reduce the overall throughput of the network.\n\
    Sensors 2023, 23, 3876\n22 of 41\nTable 4. Types of interference that impact 5G\
    \ networks and IoT\nInterference Type\nCoverage\nLatency\nAvailability\nAccess\n\
    Modulation\nCoding\nNoise\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\n\
    Multipath\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nInter-cell\
    \ Interference\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nCo-channel\
    \ Interference\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nInterference\
    \ from other devices\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\n\
    Jamming\nReduced\nIncreased\nReduced\nReduced\nReduced\nReduced\nInterference\
    \ from other wireless networks\nReduced\nIncreased\nReduced\nReduced\nReduced\n\
    Reduced\n3.9.1. Interference\nOne of the issues highlighted by the development\
    \ of 5G is interference. It should be\nremembered that interference, by deﬁnition,\
    \ is when two electromagnetic waves overlap.\nThis overlapping causes communication\
    \ failures from where the wave is sent to where it is\nreceived. There are two\
    \ types of interference: constructive and destructive. Constructive\ninterference\
    \ occurs when the waves overlap or collide in phase, and this causes the resulting\n\
    wave to have a greater amplitude. Furthermore, destructive interference is when\
    \ there is\nan out-of-phase overlap, where the resultant of this wave will be\
    \ of lower amplitude [80].\nSome networks may be more susceptible to interference\
    \ depending on the type of wave\nthey handle, i.e., the frequency used in the\
    \ electromagnetic spectrum. RF can give this\ninterference, whereas in 5G networks,\
    \ millimeter bands and below 6 GHz bands are used.\nIn addition, it must be taken\
    \ into account that these interferences will continue to grow\nwith the development\
    \ of technology.\nFigure 9 covers various types of interference in wireless communication\
    \ systems in\n5G. Adjacent channel interference occurs when adjacent frequencies\
    \ or channels overlap\ndue to imperfections in ﬁlters or non-linearity in ampliﬁers.\
    \ Inter-cell interference happens\nwhen two users from neighboring cells try to\
    \ use the same frequency band simultaneously\ndue to resource limitation within\
    \ the network. Intra-channel and inter-channel interference\noccur due to physical\
    \ proximity of devices and low power within the macro-cell network,\nrespectively.\
    \ Inter-symbol interference results from signal distortion due to phase or\namplitude\
    \ dispersion in the channel. Inter-carrier occurs due to frequency offsets between\n\
    sub-carriers. Inter-numerology interference arises due to non-orthogonality in\
    \ the system,\ncausing difﬁculties for symbol alignment. Cross-link interference\
    \ occurs when signals\nare transmitted to neighboring cells in different directions\
    \ simultaneously. Inter-beam\ninterference happens due to the use of multi-beam\
    \ antenna systems, causing interference\nfrom adjacent beams. Multi-user interference\
    \ happens when several users try to transmit\ntheir information requests at the\
    \ same time, and MU-MIMO is used to increase the capacity\nand performance of\
    \ wireless broadcasting systems.\nWe must consider that with the evolution of\
    \ higher data rates, we are looking for\nthe implementation in a frequency spectrum\
    \ that is becoming more saturated daily. The\ndevelopment in these frequencies\
    \ makes the operator reuse the same frequencies for\nneighboring cells to save\
    \ spectrum. This development causes high interference between\ncells [81]. In\
    \ addition to these, other interferences also occur within the networks. The\n\
    classiﬁcation of these interferences is as follows:\n•\nAdjacent channel interference:\
    \ Adjacent channel interference is a problem that occurs\nin many devices and\
    \ many frequency ranges. This occurs when an adjacent frequency\nor the adjacent\
    \ channel of the one used by our device overlaps. This problem occurs\nin 5G,\
    \ as in other mobile technologies. This type of interference is mainly caused,\
    \ as\nstated in [82], by an imperfection in the ﬁlters, where they cannot ﬁlter\
    \ the desired\nsignal correctly. These imperfections result in nearby frequencies\
    \ passing into the\npassband. In turn, this occurs because the ampliﬁers are not\
    \ linear.\n•\nIntra-cell and inter-cell interference: Inter-cell interference\
    \ is one of the most signiﬁ-\ncant causes of network performance degradation.\
    \ This occurs when two users from\nneighboring cells attempt to use the same frequency\
    \ band simultaneously. This occurs,\nSensors 2023, 23, 3876\n23 of 41\nas said\
    \ in [83], because of resource limitation within the network, due to the frequency\n\
    reuse factor. In the same way, inter-cell interference is identiﬁed when a Base\
    \ Station\nconnects directly in the close range of another BS, and that is when\
    \ there is a simulta-\nneous transmission in that reuse. A distortion appears\
    \ by the interference that gives\nthe user and other equipment in the same cell.\n\
    •\nIntra-Channel and Inter-Channel interference: Inter-channel interference usually\
    \ oc-\ncurs when there is a low power within the macro-cell network. Then, when\
    \ communi-\ncating, the information is forwarded to the nearest base station.\
    \ When the transmission\nis made, it is completed through fast switching and restricts\
    \ delays and propagation\nlosses. However, this produces intra-channel interference\
    \ that affects the valuable\nsignal. On the other hand, inter-channel interference\
    \ occurs due to the physical prox-\nimity of the devices when two separate frequency\
    \ bands cause interference with each\nother. As these devices operate in close\
    \ range, the transmitter of a high-power signal\ninterferes with the receiver\
    \ of a weak signal. It is important to emphasize that 5G IoT\nnetworks or devices\
    \ with channels in the MHz range are susceptible to this type of\ninterference\
    \ due to the proximity and number of nearby devices. One way to mitigate\nthis\
    \ type of interference is through spatial modulation via MIMO [84].\n•\nInter-Symbol\
    \ Interference: Inter-symbol interference occurs when one or more symbols\ninterfere\
    \ with other symbols. It is caused by phase or amplitude dispersion in the\nchannel,\
    \ resulting in signal distortion. This can be seen in OFDMA, where multipath\n\
    propagation occurs. One study [85] exposed how this type of interference can be\n\
    an excellent challenge for network systems and should be sought to improve the\n\
    efﬁciency of the bandwidth while seeking alternatives in the modulation. This\
    \ is in\norder to counteract this type of interference.\n•\nInter-numerology interference:\
    \ Multiple numerology is a model to provide ﬂexibility\nfor devices in different\
    \ services. For these numerologies, 15, 30, 60, 120, and 240 kHz\nchannels are\
    \ used. They aim to improve performance and signiﬁcant bandwidth.\nAs stated in\
    \ [86], the authors introduce a non-orthogonality in the system, causing\ndifﬁculties\
    \ for symbol alignment in the time domain. When sampling at the same\nfrequency,\
    \ numerology tends to align differently, making synchronization within the\nframe\
    \ difﬁcult. This is known as interference between numerologies.\n•\nCross-Link\
    \ Interference: This interference occurs when signals are transmitted to\nneighboring\
    \ cells in different directions simultaneously, either in time frequency or\n\
    arbitrarily overlapping resources. As mentioned in [87], there are different types\
    \ of\ninterference and different ways in which it occurs. For example, the Base\
    \ Station\nreceives interference from user equipment devices in adjacent cells,\
    \ or a downlink\nuser equipment receives interference from a second database.\n\
    •\nInter Beam Interference: With the high demand for technological services, the\
    \ aim\nhas been to improve spectral efﬁciency and network performance. In trade-offs\
    \ for\nnetworks such as 5G, where the quality and capacity must be high, the solution\
    \ of\nincorporating a multi-beam antenna system such as mMIMO was sought, as explored\n\
    in detail in [88]. This technique identiﬁes the best route to providing optimal\
    \ perfor-\nmance to a user. This approach helps compensate for transmission attenuation\
    \ losses,\nespecially in millimeter-wave communication. In this case, the base\
    \ station generates\nmultiple narrow beams of mainly RF energy in all directions\
    \ of the coverage area. This\ncauses a spatial division of multiple beams, introducing\
    \ interference. Adjacent beams\ncause this interference from the same cell or\
    \ a neighboring cell.\n•\nMulti-user Interference: Multi-user interference is\
    \ due to the industry’s quest for\nhigher data rates in applications and the dramatic\
    \ increase in subscribers to wireless\ncommunications [89]. The techniques used\
    \ for this type of technology are given by MU-\nMIMO, a 5G generation technique\
    \ that helps increase the capacity and performance of\nwireless broadcasting systems.\
    \ Multi-user interference occurs when several users try\nto transmit their information\
    \ requests at the same time.\nSensors 2023, 23, 3876\n24 of 41\nFigure 9. Main\
    \ concepts of interference in 5G.\n3.9.2. Interference in 5G\nThe different classiﬁcations\
    \ of interference have been explored. Now it is sought\nas part of the state of\
    \ the art to understand interference within 5G. The enrichment of\ninterference\
    \ in technologies such as Hetnets, IoT, D2D, Relay Node, and New Radio 5G\nwill\
    \ be sought.\n•\nInterference in Hetnets: Hetnets are 5G heterogeneous networks.\
    \ They aim to pro-\nvide wireless coverage for mobile subscribers and indoor and\
    \ outdoor applications.\nHetnets are multi-tier network systems that deploy small\
    \ cells in populated areas.\nThese cells are characterized by having a short range\
    \ and low power consumption.\nThis network comprises access points, which allow\
    \ high density, improvements in\nnetwork ﬂexibility, and so on [90]. Due to the\
    \ infrastructure and locations for deploy-\ning this type of network, they are\
    \ prone to different types of interference, such as\nintra-cell, inter-cell, and\
    \ adjacency channels. This type of problem is due to its poor\nsystematization\
    \ and organization in its network design. There are types of interference\nwithin\
    \ heterogeneous networks due to their infrastructure or grouping depending\non\
    \ the need to be met. The ﬁrst interference that appears is Co-tier interference.\
    \ This\ntype of interference appears mostly in femtocells, where there is much\
    \ demand for\nhigher data rates. This environment allows coverage, such as low-power\
    \ radio access\npoints, giving various services at home [91]. This type of interference\
    \ is observed\nwhen multiple users reside in the same network tier, where transmission\
    \ occurs over\nadjacent cells within the femtocell. Similar to co-tier, cross-tier\
    \ interference can appear.\nThe difference is that the co-tier is the inter-cell\
    \ interference, and the cross-tier is the\ninterference between the femtocell\
    \ and macro-cells, considering that the femtocell is\ninside the macro-cell [92].\
    \ Last but not least, in [93], channel control interference says\nthat one of\
    \ the most critical factors for channel control is the physical control format\n\
    indicator channel. This channel carries scheduling and synchronization information\n\
    for the uplink and downlink link data channels. As the transport is by physical\
    \ means,\nthis will induce interference.\n•\nInterference in D2D: With the introduction\
    \ of 5G, the best wireless systems have\nconstantly sought a solution that allows\
    \ the best quality of communication. Device-\nto-device networks are one of the\
    \ candidates to be the future of 5G networks. Direct\ncontact between two mobiles\
    \ increases efﬁciency in the spectrum. However, it always\nbrings some challenges,\
    \ in this case dealing with interference. As discussed in the\ndescription of\
    \ Hetnets above, these use a high connectivity capacity thanks to their\nSensors\
    \ 2023, 23, 3876\n25 of 41\nstructure with macro-cell and femtocell. They allow\
    \ good performance [94]. With\nthe introduction of D2D, a cellular network is\
    \ sought that signiﬁcantly improves\nspectral efﬁciency and performance. However,\
    \ some challenges are the need for more\nsecurity that this type of technology\
    \ presents and interference. On the interference\nside, they appear related to\
    \ inter-cell interference. Furthermore, intra-cell may be\nrelated to adjacent\
    \ frequency. Furthermore, we must remember that there are types\nof interference\
    \ typical of D2D nodes, D2D-to-CU interference, and inter-D2D node\ninterference,\
    \ among others.\n•\nInterference in IoT and Smart Cities: We cannot limit our\
    \ minds to just one application\nwhen discussing the Internet of things. However,\
    \ everything from D2D devices and\nV2X to smart homes or buildings is part of\
    \ it. The conception of IoT with 5G has\nevolved in large and small ecosystems.\
    \ IoT in some applications is used over the\nunlicensed ISM band, which is used\
    \ for various physical devices to properly leverage\nthe spectrum to adhere to\
    \ the conditions and regulations of short radio communication.\nThe Internet of\
    \ Things has been seen as the other great leap in the evolution of the\nInternet.\
    \ With this in mind, developing smart cities will help create a more sustainable\n\
    and cost-efﬁcient ecosystem [95]. The combination of technologies such as 5G,\
    \ IoT,\nand others will enable big data, offering complex services to the community,\
    \ adding\nmembers in smart cities, and ensuring compatibility. However, it should\
    \ be noted\nthat interference must be characterized. When talking about smart\
    \ cities using Wi-Fi\nbecause of the use of the millimeter band, physical obstacles\
    \ such as walls are things\nto keep in mind, in addition to channel overlapping\
    \ and inter-carrier interference [96].\n3.9.3. Optimization Challenges in 5G Networks\n\
    5G is presented as a developed environment with an ecosystem where the boundaries\n\
    are complete cities. 5G technologies promise high-speed and low-latency data transmission\n\
    using the millimeter band. Although this frequency band allows these advantages,\
    \ it only\nallows short distances. By allowing such short distances, problems\
    \ such as interference\nbecome apparent. The optimization of this type of network\
    \ should always be used to\nget the best out of it. In 5G, techniques such as\
    \ MIMO and beamforming are used to\nreduce interference or signal degradation\
    \ [90]. It should be noted that optimizations for\n5G networks include different\
    \ architectures that are part of this type of network. These\narchitectures can\
    \ be divided into non-standalone and standalone.\nOptimizing these architectures,\
    \ depending on their niche, can be proﬁtable, as the\ncommunication varies. Communication\
    \ can be more accessible or restricted depending\non the architecture. At the\
    \ same time, different modulations can be obtained to enhance\ndata transmission,\
    \ transmission speed, and latency. In the same way, with 5G, most of the\narchitectures\
    \ allow the incorporation of MIMO. Thanks to beamforming management, it is\npossible\
    \ to optimize the use of frequencies for transmission so that some technologies\
    \ can\nsend information in the mmWaves range.\nFrom interference in the case of\
    \ NR, other interferences negatively affect the data\ntransmission in this architecture\
    \ due to the nature of this architecture. These are inter-\ncarrier interference\
    \ and phase interference. This is because it uses the mmWave frequency\nrange.\
    \ In turn, another interference that damages NR is numerology interference [97].\n\
    The evolution of mobile networks from 3G to 4G and now to 5G has signiﬁcantly\n\
    impacted the services and Internet of Things devices. Each new generation has\
    \ provided\nfaster data transfer speeds, increased bandwidth, and improved reliability,\
    \ enabling the\nemergence of new services and applications that were previously\
    \ not possible on mobile\ndevices. As 5G networks become more widely adopted,\
    \ they will continue to unlock new\nopportunities for innovation, transforming\
    \ the way we interact with our devices and the\nworld around us.\nTable 5 shows\
    \ the impact of each mobile generation starting with 3G and explains the\nimpact\
    \ in an IoT context.\nSensors 2023, 23, 3876\n26 of 41\nTable 5. Mobile generations\
    \ and IoT.\nYear\nTechnology\nImpact in IoT\n2000\n3G allows devices to\nconnect\
    \ to the internet since\n3G enables mobile and\nwireless internet\nconnections.\n\
    With internet connections, electronic\ndevices start transmitting data through\n\
    the internet, the ﬁrst step to developing\nIoT devices.\n2008\n4G enables cloud\n\
    computing technology and\ntransmits information with\nthe IP protocol. In addition,\n\
    4G increased the bandwidth\nof each transmission.\nThe data transmission through\
    \ IP protocol\nenables an easy communication method with\nelectronic devices.\
    \ The cloud enables a way to\ndevelop more affordable solutions.\nFurthermore,\
    \ the internet connection cost\ndecreases because 4G delivers a cheap way to\n\
    transmit data as IP protocols manage the data\nmore efﬁciently. This generation\
    \ is the most\nimportant in an IoT context because the\nindustry has all the resources\
    \ to connect\ndevices to the cloud.\n2019\nWith 5G, an essential\nfeature is the\
    \ beam width,\nan important key in the IoT\ncontext.\nIf we have more bandwidth,\
    \ we can provide\nbetter solutions, such as real-time monitoring\nsystems. In\
    \ our society, these solutions are\nvital if we want to automate processes. For\n\
    this reason, 5G plays an essential role in the\nIoT context because the industry\
    \ is trying to\nautomate all its processes.\nNew technologies and recent research\
    \ about wireless communication have created\nnew ways to transmit and receive\
    \ data. With the evolution of technology such as 5G, new\nfeatures arrived to\
    \ provide/perform the ways to send and receive data. IoT has shown\nmore beneﬁts,\
    \ helping with other technologies such as machine learning, cloud computing,\n\
    and others. Since the data can be processed, each device forms a swarm intelligence\
    \ that\nallows automatization and avoids wasting resources in the industry.\n\
    Another factor in analyzing is the interference with the channels, since our houses,\n\
    ofﬁces, and even natural places have electronic devices that typically use the\
    \ 2.4 GHz band,\nwhich causes interference in this band. Therefore, 5G incorporates\
    \ new bands to avoid\nthe interference caused by this massive consumption of 2.4\
    \ GHz. We need to compare\nthe features of 3G, 4G, and 5G to understand why 5G\
    \ is an essential key in smart cities.\nThe main technical characteristics of\
    \ these three generations of technologies can be seen in\nTable 6.\nTable 6. Important\
    \ Features in 3G, 4G, and 5G.\n``````````\nFeature\nGeneration\n3G\n4G\n5G\nStandard\n\
    WCDMA, CDMA2000\nOFDMA, MC-CDMA\nCDMA, BDMA\nData rate\n2 Mbps\n2 Mbps–1 Gbps\n\
    1 Gbps and higher\nFrequency\n1.8–2.5 GHz\n2–8 GHz\n3–300 GHz\nCore type network\n\
    Packet network\nAll IP network\nIP network and 5G-NI\nTable 7 presents the expectations\
    \ for the use of 5G technology in the IoT. The ﬁrst\nfeature mentioned is bandwidth.\
    \ Bandwidth refers to the amount of data that can be\ntransmitted over a network\
    \ or a communication channel in a given amount of time. In\nthe context of 5G,\
    \ higher bandwidth means that more data can be transmitted over the\nairwaves\
    \ in a shorter period of time, which can result in faster and more reliable 5G\n\
    Sensors 2023, 23, 3876\n27 of 41\ntransmissions. Another feature highlighted is\
    \ artiﬁcial intelligence, which can analyze\nall the data generated by the IoT\
    \ devices to take accurate decisions. With the use of AI,\nIoT devices can identify\
    \ patterns, make predictions, and take actions based on the data\ngathered. This\
    \ feature is essential to support IoT applications that require real-time decision\n\
    making, such as smart cities and intelligent transportation systems. The third\
    \ feature is\nreal-time monitoring and management, which means the capability\
    \ to monitor and manage\nelectronic devices. This feature allows IoT devices to\
    \ be monitored and managed from a\ncentral location, which can be very useful\
    \ for large-scale applications, such as industrial\nautomation or smart grid management.\
    \ Swarm intelligence is another feature mentioned,\nwhich means that each IoT\
    \ device can be a node and work with other nodes to create a\nswarm intelligence.\
    \ This feature enables IoT devices to work collaboratively and efﬁciently,\nproviding\
    \ better performance and reliability in complex applications. Quality of service\n\
    (QoS) is also listed as a signiﬁcant feature that 5G can provide in IoT connections.\
    \ With\n5G, IoT devices can experience better connectivity, lower latency, and\
    \ higher throughput,\nwhich can improve the overall QoS and performance of IoT\
    \ applications. In the context\nof IoT connections, QoS refers to the ability\
    \ of the network to provide reliable and high-\nperformance connectivity to IoT\
    \ devices. 5G is a promising technology for IoT connections,\nas it can provide\
    \ several features that can improve the overall QoS and performance of IoT\napplications.\
    \ 5G is designed to provide a signiﬁcantly improved QoS compared to previous\n\
    generations of mobile networks. This is achieved through a combination of advanced\n\
    technologies and features that are built into the 5G standard. One of the key\
    \ features of\n5G that can contribute to a better QoS is the use of advanced radio\
    \ access technologies.\nThese technologies, such as massive MIMO and beamforming,\
    \ allow for more efﬁcient\nuse of the radio spectrum and better signal quality.\
    \ This means that 5G can provide better\nconnectivity and signal strength, which\
    \ can improve the reliability and availability of the\nnetwork. Another important\
    \ feature of 5G that can contribute to a better QoS is the use of\nnetwork slicing.\
    \ Network slicing allows the network to be divided into multiple virtual\nnetworks,\
    \ each tailored to speciﬁc use cases and requirements. This means that different\n\
    applications and services can be given different levels of priority, bandwidth,\
    \ and latency\nrequirements, depending on their needs. This can improve the QoS\
    \ for each individual\napplication and user. In addition, 5G can provide lower\
    \ latency, higher throughput, and\nbetter support for massive IoT deployments,\
    \ all of which can contribute to a better QoS.\nLower latency means that there\
    \ is less delay between the transmission of data and its\nreception, which can\
    \ enable real-time communication and faster response times. Higher\nthroughput\
    \ means that more data can be transmitted over the network in a given time,\n\
    which can improve the performance of applications that require high-bandwidth\
    \ data\ntransfer. Finally, better support for massive IoT deployments means that\
    \ the network can\nhandle a large number of connected devices and data trafﬁc,\
    \ without compromising the\nQoS for individual devices or applications.\nLow latency\
    \ is another feature that 5G can offer, reducing the delay between data\ntransmission\
    \ and reception. This feature is particularly important for applications that\n\
    require immediate decision making, such as autonomous vehicles or remote surgery.\
    \ Cloud\ncomputing is mentioned as a feature that 5G can provide in IoT connections.\
    \ With 5G, IoT\ndevices can connect to the cloud more efﬁciently, and each device\
    \ can use all the resources\nof the cloud, such as storage and processing power.\
    \ This feature can signiﬁcantly improve\nthe performance and scalability of IoT\
    \ applications, especially those that require large\namounts of data processing\
    \ and storage.\nLow latency is particularly important for applications that require\
    \ immediate decision\nmaking, such as autonomous vehicles or remote surgery. With\
    \ 5G, the latency can be\nreduced to as low as one millisecond, which can enable\
    \ real-time communication and\nfaster response times. Furthermore, 5G can provide\
    \ higher throughput, which refers to\nthe amount of data that can be transmitted\
    \ over a network in a given time. With higher\nthroughput, IoT devices can transmit\
    \ and receive larger amounts of data, which can\nimprove the performance of IoT\
    \ applications that require high-bandwidth data transfer,\nSensors 2023, 23, 3876\n\
    28 of 41\nsuch as video streaming or real-time sensor data. Cloud computing is\
    \ another feature\nthat 5G can offer for IoT connections. With 5G, IoT devices\
    \ can connect to the cloud more\nefﬁciently, and each device can use all the resources\
    \ of the cloud, such as storage and\nprocessing power. This feature can signiﬁcantly\
    \ improve the performance and scalability of\nIoT applications, especially those\
    \ that require large amounts of data processing and storage.\nTable 7. Expectation\
    \ for 5G in IoT.\nFeature\nDescription\nBandwidth\nMore bandwidth to supply applications\
    \ with\nhigh speed.\nAI\nArtiﬁcial intelligence can analyze all the data\ngenerated\
    \ by the IoT devices to take accurate\ndecisions.\nReal-time monitoring and\n\
    management\nThe capability to monitor and manage electronic\ndevices remotely.\n\
    Swarm intelligence\nEach IoT device can be a node, and working with\nother nodes,\
    \ can work as a swarm intelligence.\nQoS\n5G can provide a better QoS in IoT connections.\n\
    Low Latency\n5G reduces the latency, which means that the IoT\ndevices can take\
    \ immediate decisions.\nCloud computing\n5G can provide better connections to\
    \ the cloud,\nwhich means each IoT device can use all the\nresources of the cloud.\n\
    Since smart cities use IoT devices to provide a solution in our daily routine,\
    \ 5G is\nessential in providing a more stable, scalable, and accurate solution,\
    \ with help from other\ntechnologies, such as cloud computing, machine learning,\
    \ and so on. In other words, 5G is\nkey in smart cities because this generation\
    \ optimizes how to transmit and receive data and\nperforms the way to obtain data.\
    \ Based on these data, electronic devices can make accurate\ndecisions after processing.\n\
    Table 8 was divided into parts, in which the ﬁrst part deals exclusively with\
    \ the\ndescription and impact on 5G, and the second part describes cases and ways\
    \ to prevent\nthis interference.\nTable 8. Technologies for the elderly\nInterference\n\
    Description\n5G Impact\nAdjacent Channel\nInterference\nThis occurs when the frequency\
    \ channel of\nour device is overlapped.\nIf we do not have good bandpass ﬁlters,\
    \ there\nwill be interference from nearby frequencies. In\n5G devices, this can\
    \ have a signiﬁcant impact.\nIntra-cell and\ninter-cell\ninterference\nInter-cell\
    \ interference occurs when two\nusers in neighboring cells attempt to use\nthe\
    \ same frequency simultaneously.\nIntra-cell interference occurs when there is\n\
    a simultaneous short-range transmission\nby two BSs, with distortion from the\
    \ user\nand the other equipment in the same cell.\nThis type of interference can\
    \ severely damage 5G\nnetworks because for bases or architectures\nwhere there\
    \ are micro- or macro-cells, the power\nof neighboring signals in both uplink\
    \ and\ndownlink transmission by multiple users can\ninterfere with each other\
    \ [98].\nSensors 2023, 23, 3876\n29 of 41\nTable 8. Cont.\nInterference\nDescription\n\
    5G Impact\nIntra-Channel and\nInter-Channel\ninterference\nIntra-channel interference\
    \ occurs when\nthere is little power within the macro\nnetwork cell.\nInter-channel\
    \ interference occurs due to the\nproximity of devices when two separate\nfrequencies\
    \ cause interference. As they operate\nat short range, the transmitter of a high-power\n\
    signal causes interference; interference can also\nbe due to the exploration of\
    \ hetnets with OFDM.\nThere are ICI reduction solutions with reverse\nfrequency\
    \ allocation (RFA) employed, which is a\nproactive interference.\nInter-Symbol\n\
    interference\nThis type of interference occurs when one\nor more symbols interfere\
    \ with other\nsymbols.\nIt is caused by phase or amplitude dispersion of\nthe\
    \ channel, which results in signal distortion.\nThis can be clearly seen in OFDMA,\
    \ which\ncauses multipath propagation and impacts\nbandwidth efﬁciency.\nInter-Numerology\n\
    interference\nOccurs when using the numerology system\nfor greater ﬂexibility\
    \ and does not allow\nthe alignment in the time domain to be\nperfect. These misalignments\
    \ or\nimperfections are known as\ninter-numerology interference.\nIn the search\
    \ for higher performance and\nsigniﬁcant bandwidth, using numerology, can\ncause\
    \ interference by having networks with\nmany devices sending signiﬁcant amounts\
    \ of\ninformation, which makes this type of\ninterference more pronounced, affecting\
    \ the\nnetwork’s performance.\nCross-Link\nInterference\nThis type of interference\
    \ occurs when a\ntransmission is made to a neighboring cell\nin different directions\
    \ simultaneously,\neither by arbitrarily overlapping resources\nor by time frequency.\n\
    Cross-link interference can affect 5G networks\ndue to the amount of BS required,\
    \ since incorrect\nhopping can cause performance failures.\nInter-Beam\ninterference\
    \ [99]\nThis occurs when using MIMO technology,\nas this type of array sends RF\
    \ energy in all\ndirections, with the spatial division of the\nmultiple beams\
    \ causing interference.\nAdjacent beams cause this either by the\nsame cell or\
    \ by neighboring cells.\nIt causes interference in applications where\nMIMO antenna\
    \ technology is introduced due to\nthe same usage. When looking for better spectral\n\
    efﬁciency and improvements in network\nperformance, interference from adjacent\
    \ beams\nwithin the same cell or multiple MIMO arrays\nmay negatively inﬂuence\
    \ their neighbors.\nMulti-User\ninterference [100]\nThis occurs when, in MU-MIMO,\
    \ multiple\nusers try to transmit information\nsimultaneously.\nConsidering that\
    \ in 5G, performance and\ninformation forwarding improvements are\nsought, when\
    \ switching to MU-MIMO,\nuncoordinated cells encounter more signiﬁcant\nproblems\
    \ during user management.\nAdjacent Channel\nInterference\nThis occurs when the\
    \ frequency channel of\nthe device is overlapped.\nIf we do not have good bandpass\
    \ ﬁlters, there\nwill be interference from nearby frequencies. In\n5G devices,\
    \ this can have a signiﬁcant impact.\nIt is pertinent to consider how this type\
    \ of interference can affect or impact 5G networks\ntoday, since it must be kept\
    \ in mind with the explosive development of technology. In turn,\nthis can affect\
    \ different 5G architectures, since the main objectives of these networks are\
    \ to\nimprove things such as latency, throughput, transmission speeds, etc.\n\
    Table 9 provides an overview of different types of interference that can occur\
    \ in 5G net-\nworks and their potential impacts on network performance. Adjacent\
    \ Channel Interference\noccurs when the frequency channel of our device is overlapped\
    \ with nearby frequencies,\nleading to interference. Intra-cell and inter-cell\
    \ interference occurs when multiple users\nSensors 2023, 23, 3876\n30 of 41\n\
    in neighboring cells attempt to use the same frequency simultaneously or when\
    \ there is a\nsimultaneous short-range transmission by two base stations in the\
    \ same cell. This type of\ninterference can severely damage 5G networks, particularly\
    \ in architectures where there\nare micro- or macro-cells. Intra-channel and inter-channel\
    \ interference occurs when there\nis little power within the macro network cell,\
    \ though inter-channel interference can also\noccur due to the proximity of devices\
    \ operating at different frequencies. Inter-Symbol inter-\nference occurs when\
    \ one or more symbols interfere with other symbols, resulting in signal\ndistortion\
    \ due to phase or amplitude dispersion of the channel. Inter-Carrier interference\n\
    occurs when the signal is lost due to an offset between the subcarriers, leading\
    \ to large-scale\nor small-scale fading and variations in the received signal.\
    \ Inter-Numerology interference\noccurs when using the numerology system for greater\
    \ ﬂexibility, leading to misalignments\nor imperfections known as inter-numerology\
    \ interference. Cross-Link Interference occurs\nwhen a transmission is made to\
    \ a neighboring cell in different directions simultaneously,\nleading to performance\
    \ failures. Inter-Beam interference occurs when using MIMO tech-\nnology, with\
    \ the spatial division of the multiple beams causing interference from adjacent\n\
    beams either by the same cell or by neighboring cells. Finally, Multi-User interference\n\
    occurs when multiple users try to transmit information simultaneously, leading\
    \ to problems\nduring user management in uncoordinated cells.\nTable 9. Interference\
    \ and its impact on 5G networks.\nInterference Type\nDescription\nImpact on 5G\n\
    Networks (✓yes,\n× is no\nAdjacent Channel\nFrequency channel overlap\n✓\nIntra-cell\
    \ and inter-cell\nSimultaneous transmission in\nneighboring cells\n×\nIntra-Channel\
    \ and\ninter-Channel\nLow power in the macro\nnetwork cell\n✓\nInter-Symbol\n\
    Interference between symbols\n×\nInter-Carrier\nSignal loss due to subcarrier\
    \ offset\n×\nInter-Numerology\nMisalignments in the\nnumerology system\n×\nCross-Link\n\
    Overlapping transmissions to\nneighboring cells\n×\nInter-Beam\nInterference from\
    \ adjacent beams\nin MIMO\n×\nMulti-User\nSimultaneous transmission from\nmultiple\
    \ users\n×\n4. Results and Discussions\nIn recent years, the deployment of 5G\
    \ networks has gained signiﬁcant attention due\nto its potential to revolutionize\
    \ the communication industry. One of the areas where 5G\nnetworks are expected\
    \ to have a substantial impact is the IoT services. This literature\nreview article\
    \ aims to provide an in-depth analysis of the impact of 5G networks on IoT\nservices,\
    \ speciﬁcally examining the issue of interference in this type of network and\
    \ its\nrelated technologies.\nAs a result of new technologies in mobile communications,\
    \ 5G can provide a solution\nin a smart city context. Each IoT device can consume\
    \ a reduced bandwidth, but the problem\narises when the number of IoT devices\
    \ increases. For this reason, it is essential to provide\nhigh beam width for\
    \ better communication between IoT devices.\nSensors 2023, 23, 3876\n31 of 41\n\
    The emergence of 5G networks and Internet of Things services has brought about\n\
    a new era of connectivity and transformation to various industries. With the increasing\n\
    number of connected devices, there is a need for a network that can handle the\
    \ massive\ndata transfer, low latency, and high-speed communication required by\
    \ IoT devices. The\nconvergence of 5G networks and IoT services is expected to\
    \ revolutionize the way devices\ncommunicate with each other and the internet.\
    \ In this section, we will critically discuss the\nrelated impact of network and\
    \ service convergence between 5G networks and IoT services.\nOne of the main beneﬁts\
    \ of the convergence of 5G networks and IoT services is the\nability to support\
    \ massive machine-to-machine communication. The integration of 5G\nnetworks with\
    \ IoT devices creates a seamless connection, allowing devices to communicate\n\
    with each other and the internet at high speeds and low latency. This has signiﬁcant\n\
    implications for industries such as healthcare, transportation, and manufacturing,\
    \ where\nlarge volumes of data need to be transmitted in real time to enable efﬁcient\
    \ operations. For\ninstance, connected cars, trains, and airplanes can communicate\
    \ with each other and other\nconnected devices in real time, leading to improved\
    \ safety and efﬁciency.\nAnother impact of the convergence of 5G networks and\
    \ IoT services is the creation\nof new business models and revenue streams. With\
    \ the increased speed and capacity of\n5G networks, service providers can offer\
    \ new IoT services such as smart homes, smart\ncities, and smart factories. This\
    \ creates an opportunity for service providers to develop new\nbusiness models\
    \ and revenue streams, such as selling data insights, providing managed\nservices,\
    \ and offering customized solutions. For example, telecom operators can offer\n\
    IoT connectivity as a service, which provides businesses with a cost-effective\
    \ and scalable\nmethod to connect and manage their IoT devices.\nHowever, the\
    \ convergence of 5G networks and IoT services also presents some chal-\nlenges\
    \ that need to be addressed. One of the challenges is the issue of security and\
    \ privacy.\nAs the number of connected devices grows, the potential for cyberattacks\
    \ and data breaches\nalso increases. Therefore, service providers and device manufacturers\
    \ need to work to-\ngether to ensure that IoT devices are secure and comply with\
    \ data protection regulations.\nAdditionally, the convergence of 5G networks and\
    \ IoT services requires signiﬁcant invest-\nments in infrastructure and technology.\
    \ Service providers need to deploy a massive number\nof 5G base stations to enable\
    \ reliable and consistent connectivity for IoT devices.\nThe convergence of 5G\
    \ networks and IoT services has the potential to revolutionize the\nway devices\
    \ communicate with each other and the internet. It has signiﬁcant implications\n\
    for industries such as healthcare, transportation, and manufacturing, creating\
    \ new business\nmodels and revenue streams. However, it also presents challenges\
    \ such as security and\nprivacy concerns and the need for signiﬁcant investments\
    \ in infrastructure and technology.\nTherefore, service providers and device manufacturers\
    \ need to work together to address\nthese challenges and ensure that the convergence\
    \ of 5G networks and IoT services leads to\na safer, more efﬁcient, and connected\
    \ world.\nTable 10 discusses the potential positive and negative impacts of integrating\
    \ 5G\ntechnologies with IoT solutions. The table is divided into three columns,\
    \ including Category,\nContext, and Explanation.\nThe ﬁrst category mentioned\
    \ in the table is Positive, which includes three different\ncontexts. The ﬁrst\
    \ context is Cost Optimization, which refers to the potential cost savings\nassociated\
    \ with integrating 5G technologies with IoT solutions. With the help of data\n\
    gathered by devices, businesses and organizations can optimize their processes,\
    \ leading to\nmore cost-effective solutions. Additionally, data-driven decision\
    \ making allows private\nor public entities to make better decisions. For instance,\
    \ a city can use IoT solutions to\noptimize trafﬁc ﬂow, leading to reduced fuel\
    \ consumption and fewer trafﬁc jams.\nThe second context mentioned in the Positive\
    \ category is Improving QoS, which refers\nto the potential improvement in the\
    \ quality of life for citizens. By providing relevant\ninformation and real-time\
    \ control over public infrastructure, cities can positively impact\ncitizens’\
    \ lives. For example, using IoT solutions, a city can improve security by monitoring\n\
    Sensors 2023, 23, 3876\n32 of 41\npublic spaces and providing real-time alerts\
    \ in case of emergencies. Additionally, cities can\ncreate new economic development\
    \ opportunities fueled by the digitalization era.\nThe third context mentioned\
    \ in the Positive category is Reducing climate change. By\nimplementing IoT solutions\
    \ with 5G technologies, businesses can have closer control over\nindustrial processes\
    \ and real-time analytics regarding relevant environmental properties.\nThis can\
    \ be the next step in becoming a more environmentally friendly society.\nMoving\
    \ onto the Negative category, the table mentions two different contexts. The\n\
    ﬁrst context is Digital Non-Inclusion, which refers to the potential negative\
    \ impact of IoT\nsolutions on regions with less access to technological services,\
    \ while 5G and IoT efforts\ncan improve the quality of life of those cities that\
    \ can afford it, they currently do not offer\ncost-effective solutions for regions\
    \ with less access to technological services.\nThe second context mentioned in\
    \ the Negative category is privacy compromises.\nHaving real-time information\
    \ on assets, people, and any living or non-living organism\nin a region can seriously\
    \ threaten privacy violations. Political or social movements can\nnegatively use\
    \ sensible data related to citizens to perform any action.\nTable 10. Explanation\
    \ of the positive or negative impact in 5G and IoT.\nCategory\nContext\nExplanation\n\
    Positive\nCost\nOptimization\nIntegrating 5G technologies with IoT solutions will\n\
    allow for more cost-effective solutions when 5G\ntechnologies reach the mainstream\
    \ market. Optimizing\nprocesses with the data gathered by the devices will\nallow\
    \ for data-driven decision making, allowing\nprivate or public entities to make\
    \ better decisions.\nPositive\nImproving\nQoS\nBy providing relevant information\
    \ and real-time\ncontrol over public infrastructure, citizens will be\npositively\
    \ impacted by reduced trafﬁc, improved\nsecurity, and new economic development\n\
    opportunities fueled by the digitalization era.\nPositive\nReducing\nclimate change\n\
    Having closer control over industrial processes and\nreal-time analytics regarding\
    \ relevant environmental\nproperties, implementing IoT solutions with 5G\ntechnologies\
    \ can be the next step in becoming a more\nenvironmentally friendly society.\n\
    Negative\nDigital\nNon-Inclusion\nWhile 5G and IoT efforts can improve the quality\
    \ of\nlife of those cities that can afford it, they currently do\nnot offer cost-effective\
    \ solutions for regions with less\naccess to technological services.\nNegative\n\
    Privacy\ncompromises\nHaving real-time information on assets, people, and\nany\
    \ living or non-living organism in a region can\nseriously threaten privacy violations.\
    \ Political or social\nmovements can negatively use sensible data related to\n\
    citizens to perform any action.\nFigure 10 discusses the main challenges on 5G\
    \ networks. One of the main challenges\nof 5G networks related to interference,\
    \ IoT devices, and network optimization is the high\ndemand for wireless connectivity\
    \ and data transmission. With the increasing number of\nIoT devices and the exponential\
    \ growth of data usage, 5G networks must be optimized\nto handle the massive amount\
    \ of data transmission while minimizing interference. The\ndeployment of small\
    \ cells and heterogeneous networks is one strategy to increase net-\nwork capacity\
    \ and reduce interference. However, the complexity of network planning,\ndeployment,\
    \ and management increases with the deployment of small cells, which requires\n\
    sophisticated optimization techniques. Additionally, the development of 5G IoT\
    \ devices\nSensors 2023, 23, 3876\n33 of 41\nwith limited power and processing\
    \ capabilities also presents a challenge. The design of\nlow-power wireless communication\
    \ protocols and efﬁcient resource allocation techniques\nis necessary to optimize\
    \ the performance of IoT devices in 5G networks. 5G networks’\nchallenges related\
    \ to interference, IoT devices, and network optimization require advanced\nsolutions\
    \ and innovative technologies to ensure high-quality wireless connectivity and\n\
    meet the demands of the growing digital ecosystem.\nFigure 10. Challenges of 5G\
    \ networks.\nTable 11 is a representation of the future research challenges in\
    \ 5G that are directly\nrelated to IoT services. It is a ﬁve-column table with\
    \ the following labels for each column:\nFeatures, Advantages, Research Challenges,\
    \ Key Requirements, and Interoperability. The\nFeatures column lists the main\
    \ features that are relevant for IoT services in 5G. In this table,\nthe features\
    \ are IoT Services, Edge Computing, 5G Radio Access, and Network Slicing. The\n\
    Advantages column lists the advantages that 5G can provide to IoT services, for\
    \ example,\nenabling new use cases, reducing latency, providing high data rates,\
    \ and providing cus-\ntomizable networks. The Research Challenges column lists\
    \ the key research challenges that\nneed to be addressed in order to fully realize\
    \ the potential of 5G for IoT services, for exam-\nple, network slicing, security,\
    \ scalability, resource allocation, and spectrum management.\nThe Key Requirements\
    \ column lists the key technical requirements that need to be met in\norder to\
    \ address the research challenges, for example, low latency, high reliability,\
    \ energy\nefﬁciency, and service level agreements. The Interoperability column\
    \ lists the key interoper-\nability issues that need to be addressed in order\
    \ to ensure that different 5G networks and\nIoT devices can work together seamlessly,\
    \ for example, standardization, integration with\nexisting systems, compatibility\
    \ with different technologies, and interoperability between\nnetwork slices.\n\
    Interference can have a signiﬁcant impact on 5G networks, particularly in the\
    \ context\nof Internet of Things (IoT) devices. The large number of IoT devices\
    \ that will be connected\nto 5G networks will inevitably lead to increased interference,\
    \ which can result in degraded\nnetwork performance and poor user experience.\n\
    One of the critical responses to interference in 5G networks is to employ advanced\n\
    signal processing techniques to mitigate the effects of interference. For example,\
    \ beam-\nforming and advanced receiver algorithms can help to reduce interference\
    \ on 5G networks.\nAdditionally, the use of multi-antenna systems and smart antennas\
    \ can improve the quality\nof the received signal and reduce interference.\nAnother\
    \ critical response is to implement interference management protocols that\nenable\
    \ the efﬁcient use of available radio resources. These protocols can help to coordinate\n\
    the use of different channels, reduce interference between neighboring cells,\
    \ and optimize\nthe use of spectrum resources.\nFor instance, the use of small\
    \ cell networks can help to reduce interference by reduc-\ning the distance between\
    \ the transmitter and receiver. In addition, the use of frequency\nSensors 2023,\
    \ 23, 3876\n34 of 41\nreuse techniques, such as fractional frequency reuse, can\
    \ help to mitigate the impact of\ninterference in multi-cell networks.\nTable\
    \ 11. Future research challenges in 5G related to IoT services.\nFeatures\nAdvantages\n\
    Research\nChallenges\nKey Requirements\nInteroperability\nIoT\nServices\nEnables\
    \ new\nuse cases\nNetwork slicing\nLow latency\nStandardization\nSecurity\nHigh\
    \ reliability\nIntegration with existing systems\nScalability\nMassive machine-type\n\
    communication\nCompatibility with different\ntechnologies\nEdge\nComputing\nReduced\n\
    latency\nResource allocation\nEnergy efﬁciency\nInteroperability with\ncloud services\n\
    Edge intelligence\nResource management\nSecurity\nEdge analytics\nQoS management\n\
    Integration with network slicing\n5G Radio\nAccess\nHigh data rates\nSpectrum\n\
    management\nLow power consumption\nCompatibility with legacy systems\nMulti-connectivity\n\
    Interference management\nNetwork densiﬁcation\nmmWave\ncommunications\nCoverage\n\
    Integration with edge computing\nNetwork\nSlicing\nCustomizable\nnetworks\nOrchestration\n\
    Service level agreements\nInteroperability between slices\nResource allocation\n\
    Isolation\nScalability\nQoS management\nSecurity\nIntegration with existing networks\n\
    Table 12 summarizes the future research challenges in 5G for IoT services. The\
    \ ﬁrst\nitem, Issues, describes the main challenges faced in the implementation\
    \ of 5G for IoT\nservices. The ﬁve issues identiﬁed in the table are Interference,\
    \ Security, Energy Efﬁciency,\nScalability, and Latency. The item Methodologies\
    \ presents the proposed techniques or\nmethods to address the identiﬁed issues.\
    \ For example, DSA and Cooperative Sensing are\nproposed to address the Interference\
    \ issue. Similarly, Authentication and Encryption are\nproposed to address the\
    \ Security issue. The table provides a list of techniques for each of\nthe identiﬁed\
    \ issues. The item Advantages describes the potential beneﬁts of using the\nproposed\
    \ methodologies. For instance, the use of DSA and Cooperative Sensing can lead\n\
    to better spectrum utilization and increased reliability. Similarly, using authentication\
    \ and\nencryption can provide secure communication and protect against attacks.\
    \ The item Limi-\ntations/Future Work describes the challenges or limitations\
    \ of the proposed methodologies\nand highlights the areas that need further research.\
    \ For example, the table highlights\nthe need for developing efﬁcient and scalable\
    \ DSA and cooperative sensing algorithms\nto address the Interference issue. Similarly,\
    \ developing lightweight and energy-efﬁcient\nsecurity mechanisms is identiﬁed\
    \ as future work to address the Security issue.\nTable 13 includes several types\
    \ of interference that affect 5G networks and IoT ser-\nvices. These include atmospheric\
    \ absorption, free space path loss, reﬂection, refraction,\ndiffraction, scattering,\
    \ rain fade, multipath fading, co-channel interference, adjacent chan-\nnel interference,\
    \ and interference from other radios and IoT devices. The table provides\ntechnical\
    \ details about the frequency range, bandwidth, power level, and impact of each\n\
    interference type.\n•\nInterference: The type of interference that affects 5G\
    \ networks and IoT services.\n•\nFrequency: The frequency range in which the interference\
    \ occurs.\n•\nBandwidth: The bandwidth of the interference.\n•\nPower: The power\
    \ level of the interference.\n•\nImpact: The effect of the interference on 5G\
    \ networks and IoT services.\nSensors 2023, 23, 3876\n35 of 41\nTable 12. Future\
    \ research challenges in 5G for IoT services.\nIssues\nMethodologies\nAdvantages\n\
    Limitations/Future Work\nInterference\nDynamic Spectrum\nAccess, cooperative\n\
    Sensing\nBetter spectrum\nutilization,\nincreased reliability\nDeveloping efﬁcient\
    \ and\nscalable DSA (Dynamic\nSpectrum Access) and\ncooperative sensing\nalgorithms\n\
    Security\nAuthentication,\nencryption\nSecure\ncommunication,\nprotecting against\n\
    attacks\nDeveloping lightweight\nand energy-efﬁcient\nsecurity mechanisms\nEnergy\n\
    Efﬁciency\nPower\nmanagement,\nresource allocation\nLonger battery life,\nimproved\
    \ system\ncapacity\nDeveloping\nenergy-efﬁcient\nalgorithms for resource\nallocation\
    \ and power\nmanagement\nScalability\nNetwork slicing,\nvirtualization\nBetter\
    \ resource\nutilization,\nimproved service\nquality\nDeveloping efﬁcient\nnetwork\
    \ slicing and\nvirtualization techniques\nfor massive IoT\ndeployments\nLatency\n\
    Edge computing,\nnetwork\narchitecture\nReduced\ncommunication\ndelay, improved\n\
    application\nperformance\nDeveloping low-latency\nedge computing and\nnetwork\
    \ architecture for\nIoT services\nTable 13. Interference characteristics in 5G\
    \ networks and IoT services.\nInterference\nFrequency\nBandwidth\nPower\nImpact\n\
    Reference\nAtmospheric Absorption\n24–40 GHz\nNarrowband\nLow\nAttenuation\n[101]\n\
    Free Space Path Loss\nAll\nAll\nLow\nAttenuation\n[102]\nReﬂection\nAll\nAll\n\
    Low\nMultipath Fading\n[103]\nRefraction\nAll\nAll\nLow\nPath Bending\n[104]\n\
    Diffraction\nAll\nAll\nLow\nPath Bending\n[105]\nScattering\nAll\nAll\nLow\nMultipath\
    \ Fading\n[106]\nRain Fade\n10–100 GHz\nWideband\nHigh\nAttenuation\n[107]\nMultipath\
    \ Fading\nAll\nAll\nLow\nIntersymbol Interference\n[108]\nCo-Channel Interference\n\
    All\nAll\nHigh\nReduced Signal Quality\n[109]\nAdjacent Channel\nInterference\n\
    All\nAll\nHigh\nReduced Signal Quality\n[110]\nInterference from\nOther Radios\n\
    All\nAll\nHigh\nReduced Signal Quality\n[111]\nInterference from Other\nIoT Devices\n\
    All\nAll\nLow\nReduced Signal Quality\n[112]\nSensors 2023, 23, 3876\n36 of 41\n\
    5. Conclusions\nThe convergence of 5G technology and the Internet of Things is\
    \ an essential step\ntowards achieving new business opportunities and improving\
    \ connectivity worldwide.\nThe ecosystem of IoT devices is complex, and choosing\
    \ the right primary or complementary\nconnectivity option depends on factors such\
    \ as deployment costs, range, interference,\nand capabilities. Technical studies\
    \ have shown that 5G and other services can coexist in\nspeciﬁc frequency bands,\
    \ provided that the technical conditions are adequately adapted.\nCompliance with\
    \ the permitted exposure limits is also essential when designing new\napplications\
    \ or technological accessories using 5G and IoT.\nThe convergence of networks\
    \ and services, driven by 5G technology, is transforming\nthe internet into a\
    \ complex and multifaceted ecosystem integrated into nearly every aspect\nof our\
    \ daily lives. The availability and speed of access to the internet are increasing,\n\
    allowing users to access high-quality media content in real-time and internet\
    \ service\nproviders to offer a range of new services and applications. Cellular\
    \ connectivity will\nenable the achievement of key IoT goals, such as reducing\
    \ device complexity and cost,\nincreasing coverage to support remote applications,\
    \ and providing deployment ﬂexibility,\nhigh capacity, and long battery life.\n\
    Businesses can beneﬁt greatly from the optimization of network performance in\
    \ 5G\nnetworks, which is essential for adequately functioning business processes,\
    \ improving\nproductivity, reducing downtime, and enhancing customer satisfaction.\
    \ The potential of the\nconvergence of networks and services in increasing the\
    \ availability and speed of access to\nthe internet enables a range of new and\
    \ innovative applications and services, transforming\nthe way we live and work.\n\
    Managing interference in 5G networks is a signiﬁcant challenge in ensuring the\
    \ reli-\nability and performance of IoT services. Effective interference management\
    \ techniques,\ndiverse connectivity and latency requirements of IoT devices and\
    \ applications, and external\ninterference are signiﬁcant issues that must be\
    \ addressed to ensure that 5G networks can\nsupport the massive number of devices\
    \ and applications that rely on them.\n5G has a lot of features necessary for\
    \ smart cities. However, it can be improved by\ncombining it with protocols such\
    \ as LoRaWAN, which provides low-range communication,\nZ-Wave, Zigbee, and SigFox\
    \ for house IoT devices. 5G with IoT technologies combine\nall this to provide\
    \ a more complex solution, taking care of the attenuation of the signal,\nsecurity\
    \ protocols, bandwidth, QoS, and more.\nAuthor Contributions: M.P. reviewed, interpreted\
    \ and drafted the comparison results and some\ntables. E.V. was involved on the\
    \ formal analysis and the manuscript. B.R. made the ﬁgures and their\ncomparison\
    \ and performed the formal analysis. J.A.N.-F. directed some formal concepts and\
    \ review\nthe manuscript. C.D.-V.-S. developed the analysis, supervised the research\
    \ methodology and the\napproach of this work, prepared the scenario and analyzed\
    \ the results. All authors have read and\nagreed to the published version of the\
    \ manuscript.\nFunding: This research received no external funding.\nInstitutional\
    \ Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\n\
    Data Availability Statement: Not applicable.\nConﬂicts of Interest: The authors\
    \ declare no conﬂict of interest.\nReferences\n1.\nLin, Z.; Lin, M.; De Cola,\
    \ T.; Wang, J.B.; Zhu, W.P.; Cheng, J. Supporting IoT with rate-splitting multiple\
    \ access in satellite and\naerial-integrated networks. IEEE Internet Things J.\
    \ 2021, 8, 11123–11134. [CrossRef]\n2.\nShao, D.; Mwangakala, H.; Ishengoma, F.;\
    \ Mongi, H.; Mambile, C.; Chali, F. Sustenance of the digital transformations\
    \ induced\nby the COVID-19 pandemic response: Lessons from Tanzanian public sector.\
    \ Glob. Knowl. Mem. Commun. 2022, ahead-of-print.\n[CrossRef]\nSensors 2023, 23,\
    \ 3876\n37 of 41\n3.\nMinoli, D.; Occhiogrosso, B. Practical aspects for the integration\
    \ of 5G networks and IoT applications in smart cities environments.\nWirel. Commun.\
    \ Mob. Comput. 2019, 2019, 5710834. [CrossRef]\n4.\nVermesan, O.; Friess, P. Internet\
    \ of Things: Converging Technologies for Smart Environments and Integrated Ecosystems;\
    \ River Publishers:\nLjubljana, Slovenia, 2013.\n5.\nGhosh, A.; Maeder, A.; Baker,\
    \ M.; Chandramouli, D. 5G evolution: A view on 5G cellular technology beyond 3GPP\
    \ release 15.\nIEEE Access 2019, 7, 127639–127651. [CrossRef]\n6.\nMontori, F.;\
    \ Bedogni, L.; Di Felice, M.; Bononi, L. Machine-to-machine wireless communication\
    \ technologies for the Internet of\nThings: Taxonomy, comparison and open issues.\
    \ Pervasive Mob. Comput. 2018, 50, 56–81. [CrossRef]\n7.\nMuteba, K.; Djouani,\
    \ K.; Olwal, T. 5G NB-IoT: Design, Considerations, Solutions and Challenges. Procedia\
    \ Comput. Sci. 2022,\n198, 86–93. [CrossRef]\n8.\nHardell, L.; Carlberg, M. [Comment]\
    \ Health risks from radiofrequency radiation, including 5G, should be assessed\
    \ by experts\nwith no conﬂicts of interest. Oncol. Lett. 2020, 20, 15. [CrossRef]\n\
    9.\nMumtaz, S.; Alsohaily, A.; Pang, Z.; Rayes, A.; Tsang, K.F.; Rodriguez, J.\
    \ Massive Internet of Things for industrial applications:\nAddressing wireless\
    \ IIoT connectivity challenges and ecosystem fragmentation.\nIEEE Ind. Electron.\
    \ Mag. 2017, 11, 28–33.\n[CrossRef]\n10.\nMarkakis, E.K.; Karras, K.; Sideris,\
    \ A.; Alexiou, G.; Pallis, E. Computing, caching, and communication at the edge:\
    \ The cornerstone\nfor building a versatile 5G ecosystem. IEEE Commun. Mag. 2017,\
    \ 55, 152–157. [CrossRef]\n11.\nChettri, L.; Bera, R. A comprehensive survey on\
    \ Internet of Things (IoT) toward 5G wireless systems. IEEE Internet Things J.\
    \ 2019,\n7, 16–32. [CrossRef]\n12.\nChaudhari, B.S.; Zennaro, M.; Borkar, S. LPWAN\
    \ technologies: Emerging application characteristics, requirements, and design\n\
    considerations. Future Internet 2020, 12, 46. [CrossRef]\n13.\nHwang, S.H.; Liu,\
    \ S.Z. Survey on 3GPP low power wide area technologies and its application. In\
    \ Proceedings of the 2019 IEEE\nVTS Asia Paciﬁc Wireless Communications Symposium\
    \ (APWCS), Singapore, 28–30 August 2019; IEEE: Piscataway, NJ, USA,\n2019; pp.\
    \ 1–5.\n14.\nSahoo, B.P.; Chou, C.C.; Weng, C.W.; Wei, H.Y. Enabling millimeter-wave\
    \ 5G networks for massive IoT applications: A closer\nlook at the issues impacting\
    \ millimeter-waves in consumer devices under the 5G framework. IEEE Consum. Electron.\
    \ Mag. 2018,\n8, 49–54. [CrossRef]\n15.\nYang, L.; Zhao, B.Y.; Zheng, H. The spaces\
    \ between us: Setting and maintaining boundaries in wireless spectrum access.\
    \ In\nProceedings of the Sixteenth Annual International Conference on Mobile Computing\
    \ and Networking, Chicago, IL, USA, 20–24\nSeptember 2010; pp. 37–48.\n16.\nQamar,\
    \ F.; Hindia, M.N.; Dimyati, K.; Noordin, K.A.; Amiri, I.S. Interference management\
    \ issues for the future 5G network: A\nreview. Telecommun. Syst. 2019, 71, 627–643.\
    \ [CrossRef]\n17.\nAttaran, M. The impact of 5G on the evolution of intelligent\
    \ automation and industry digitization. J. Ambient. Intell. Humaniz.\nComput.\
    \ 2021, 1–17. [CrossRef]\n18.\nSiddiqi, M.A.; Yu, H.; Joung, J. 5G ultra-reliable\
    \ low-latency communication implementation challenges and operational issues\n\
    with IoT devices. Electronics 2019, 8, 981. [CrossRef]\n19.\nFerro, E.; Potorti,\
    \ F. Bluetooth and Wi-Fi wireless protocols: A survey and a comparison. IEEE Wirel.\
    \ Commun. 2005, 12, 12–26.\n[CrossRef]\n20.\nChandra, S.; Arya, R.; Verma, A.K.\
    \ Reliability and age of information analysis of 5G IoT for intelligent communication.\
    \ Comput.\nElectr. Eng. 2022, 101, 108053. [CrossRef]\n21.\nAzari, A.; Masoudi,\
    \ M. Interference management for coexisting Internet of Things networks over unlicensed\
    \ spectrum. Ad Hoc\nNetw. 2021, 120, 102539. [CrossRef]\n22.\nAl-Turjman, F. 5G-enabled\
    \ devices and smart-spaces in social-IoT: An overview. Future Gener. Comput. Syst.\
    \ 2019, 92, 732–744.\n[CrossRef]\n23.\nHasan, M.K.; Ghazal, T.M.; Saeed, R.A.;\
    \ Pandey, B.; Gohel, H.; Eshmawi, A.; Abdel-Khalek, S.; Alkhassawneh, H.M. A review\
    \ on\nsecurity threats, vulnerabilities, and counter measures of 5G enabled Internet-of-Medical-Things.\
    \ IET Commun. 2022, 16, 421–432.\n[CrossRef]\n24.\nLin, Z.; Lin, M.; Champagne,\
    \ B.; Zhu, W.P.; Al-Dhahir, N. Secrecy-energy efﬁcient hybrid beamforming for\
    \ satellite-terrestrial\nintegrated networks. IEEE Trans. Commun. 2021, 69, 6345–6360.\
    \ [CrossRef]\n25.\nTang, Y.; Dananjayan, S.; Hou, C.; Guo, Q.; Luo, S.; He, Y.\
    \ A survey on the 5G network and its impact on agriculture: Challenges\nand opportunities.\
    \ Comput. Electron. Agric. 2021, 180, 105895. [CrossRef]\n26.\nMahmood, A.; Beltramelli,\
    \ L.; Abedin, S.F.; Zeb, S.; Mowla, N.I.; Hassan, S.A.; Sisinni, E.; Gidlund,\
    \ M. Industrial IoT in\n5G-and-beyond networks: Vision, architecture, and design\
    \ trends. IEEE Trans. Ind. Inform. 2021, 18, 4122–4137. [CrossRef]\n27.\nStorck,\
    \ C.R.; Duarte-Figueiredo, F. A survey of 5G technology evolution, standards,\
    \ and infrastructure associated with vehicle-to-\neverything communications by\
    \ internet of vehicles. IEEE Access 2020, 8, 117593–117614. [CrossRef]\n28.\n\
    Liu, E.; Efﬁok, E.; Hitchcock, J. Survey on health care applications in 5G networks.\
    \ IET Commun. 2020, 14, 1073–1080. [CrossRef]\n29.\nOgbodo, E.U.; Abu-Mahfouz,\
    \ A.M.; Kurien, A.M. Enabling LPWANs for Coexistence and Diverse IoT Applications\
    \ in Smart\nCities Using Lightweight Heterogenous Multihomed Network Model. J.\
    \ Sens. Actuator Netw. 2022, 11, 87. [CrossRef]\nSensors 2023, 23, 3876\n38 of\
    \ 41\n30.\nIvanova, D.; Markova, E.; Moltchanov, D.; Pirmagomedov, R.; Koucheryavy,\
    \ Y.; Samouylov, K. Performance of priority-based\ntrafﬁc coexistence strategies\
    \ in 5G mmWave industrial deployments. IEEE Access 2022, 10, 9241–9256. [CrossRef]\n\
    31.\nAhmad, A.; Rehmani, M.H.; Tembine, H.; Mohammed, O.A.; Jamalipour, A. IEEE\
    \ Access Special Section Editorial: Optimization\nfor emerging wireless networks:\
    \ IoT, 5G, and smart grid communication networks. IEEE Access 2017, 5, 2096–2100.\
    \ [CrossRef]\n32.\nBairagi, A.K.; Munir, M.S.; Alsenwi, M.; Tran, N.H.; Alshamrani,\
    \ S.S.; Masud, M.; Han, Z.; Hong, C.S. Coexistence mechanism\nbetween eMBB and\
    \ uRLLC in 5G wireless networks. IEEE Trans. Commun. 2020, 69, 1736–1749. [CrossRef]\n\
    33.\nShen, H.; Ye, Q.; Zhuang, W.; Shi, W.; Bai, G.; Yang, G. Drone-small-cell-assisted\
    \ resource slicing for 5G uplink radio access\nnetworks. IEEE Trans. Veh. Technol.\
    \ 2021, 70, 7071–7086. [CrossRef]\n34.\nPainuly, S.; Sharma, S.; Matta, P. Future\
    \ trends and challenges in next generation smart application of 5G-IoT. In Proceedings\
    \ of\nthe 2021 5th International Conference on Computing Methodologies and Communication\
    \ (ICCMC), Erode, India, 8–10 April\n2021; IEEE: Piscataway, NJ, USA, 2021; pp.\
    \ 354–357.\n35.\nGupta, N.; Sharma, S.; Juneja, P.K.; Garg, U. Sdnfv 5g-iot: A\
    \ framework for the next generation 5g enabled iot. In Proceedings of\nthe 2020\
    \ International Conference on Advances in Computing, Communication & Materials\
    \ (ICACCM), Dehradun, India, 21–22\nAugust 2020; IEEE: Piscataway, NJ, USA, 2020;\
    \ pp. 289–294.\n36.\nIslam, S.; Zada, M.; Yoo, H. Low-pass ﬁlter based integrated\
    \ 5G smartphone antenna for sub-6- GHz and mm-wave bands. IEEE\nTrans. Antennas\
    \ Propag. 2021, 69, 5424–5436. [CrossRef]\n37.\nMitra, R.N.; Agrawal, D.P. 5G\
    \ mobile technology: A survey. ICT Express 2015, 1, 132–137. [CrossRef]\n38.\n\
    Ahad, A.; Tahir, M.; Yau, K.L.A. 5G-based smart healthcare network: Architecture,\
    \ taxonomy, challenges and future research\ndirections. IEEE Access 2019, 7, 100747–100762.\
    \ [CrossRef]\n39.\nAndrewsetal, J. Whatwill5Gbe? IEEE J. Sel. Areas Commun. 2014,\
    \ 32, 1065–1082.\n40.\nHan, S.; Bian, S. Energy-efﬁcient 5G for a greener future.\
    \ Nat. Electron. 2020, 3, 182–184.\n41.\nLin, Z.; Niu, H.; An, K.; Wang, Y.; Zheng,\
    \ G.; Chatzinotas, S.; Hu, Y. Refracting RIS-aided hybrid satellite-terrestrial\
    \ relay\nnetworks: Joint beamforming design and optimization. IEEE Trans. Aerosp.\
    \ Electron. Syst. 2022, 58, 3717–3724. [CrossRef]\n42.\nShim, J.P.; Varshney,\
    \ U.; Dekleva, S.; Knoerzer, G. Mobile and wireless networks: Services, evolution\
    \ and issues. Int. J. Mob.\nCommun. 2006, 4, 405–417. [CrossRef]\n43.\nCano, J.C.;\
    \ Berrios, V.; Garcia, B.; Toh, C.K. Evolution of IoT: An industry perspective.\
    \ IEEE Internet Things Mag. 2018, 1, 12–17.\n[CrossRef]\n44.\nJovovi´c, I.; Forenbacher,\
    \ I.; Periša, M. Massive machine-type communications: An overview and perspectives\
    \ towards 5G. In\nProceedings of the 3rd International Virtual Research Conference\
    \ in Technical Disciplines, Zilina, Slovakia, 19–23 October 2015;\nVolume 3.\n\
    45.\nVaezi, M.; Azari, A.; Khosravirad, S.R.; Shirvanimoghaddam, M.; Azari, M.M.;\
    \ Chasaki, D.; Popovski, P. Cellular, wide-area, and\nnon-terrestrial IoT: A survey\
    \ on 5G advances and the road toward 6G. IEEE Commun. Surv. Tutor. 2022, 24, 1117–1174.\
    \ [CrossRef]\n46.\nTao, J.; Umair, M.; Ali, M.; Zhou, J. The impact of Internet\
    \ of Things supported by emerging 5G in power systems: A review.\nCSEE J. Power\
    \ Energy Syst. 2019, 6, 344–352.\n47.\nStudent, V.; Dhir, R. A study of ad hoc\
    \ network: A review. Int. J. 2013, 3, 135–138.\n48.\nTomar, A. Introduction to\
    \ ZigBee technology. Glob. Technol. Cent. 2011, 1, 1–24.\n49.\nYassein, M.B.;\
    \ Mardini, W.; Khalil, A. Smart homes automation using Z-wave protocol. In Proceedings\
    \ of the 2016 International\nConference on Engineering & MIS (ICEMIS), Agadir,\
    \ Morocco, 22–24 September 2016, IEEE: Piscataway, NJ, USA, 2016; pp. 1–6.\n50.\n\
    Villarim, M.R.; de Luna, J.V.H.; de Farias Medeiros, D.; Pereira, R.I.S.; de Souza,\
    \ C.P.; Baiocchi, O.; da Cunha Martins, F.C. An\nevaluation of LoRa communication\
    \ range in urban and forest areas: A case study in brazil and portugal. In Proceedings\
    \ of the\n2019 IEEE 10th Annual Information Technology, Electronics and Mobile\
    \ Communication Conference (IEMCON), Vancouver, BC,\nCanada, 17–19 October 2019;\
    \ IEEE: Piscataway, NJ, USA, 2019; pp. 0827–0832.\n51.\nAbdulmalek, S.; Nasir,\
    \ A.; Jabbar, W.A.; Almuhaya, M.A.; Bairagi, A.K.; Khan, M.A.M.; Kee, S.H. IoT-Based\
    \ Healthcare-Monitoring\nSystem towards Improving Quality of Life: A Review. Healthcare\
    \ 2022, 10, 1993. [CrossRef] [PubMed]\n52.\nZhang, Q.; Cheng, L.; Boutaba, R.\
    \ Cloud computing: State-of-the-art and research challenges. J. Internet Serv.\
    \ Appl. 2010, 1, 7–18.\n[CrossRef]\n53.\nHansen, C.J. WiGiG: Multi-gigabit wireless\
    \ communications in the 60 GHz band. IEEE Wirel. Commun. 2011, 18, 6–7. [CrossRef]\n\
    54.\nMohamed, E.M. WiGig access point selection using non-contextual and contextual\
    \ multi-armed bandit in indoor environment. J.\nAmbient. Intell. Humaniz. Comput.\
    \ 2022, 1–16. [CrossRef]\n55.\nPham, D.A.; Park, E.; Lee, H.L.; Lim, S. High gain\
    \ and wideband metasurfaced magnetoelectric antenna for WiGig applications.\n\
    IEEE Trans. Antennas Propag. 2020, 69, 1140–1145. [CrossRef]\n56.\nKim, S.; Yun,\
    \ J.H. Motion-aware interplay between wigig and wiﬁ for wireless virtual reality.\
    \ Sensors 2020, 20, 6782. [CrossRef]\n57.\nZhang, W.; Zhang, Z.; Chao, H.C. Cooperative\
    \ fog computing for dealing with big data in the internet of vehicles: Architecture\n\
    and hierarchical resource management. IEEE Commun. Mag. 2017, 55, 60–67. [CrossRef]\n\
    58.\nDahlman, E.; Parkvall, S.; Skold, J. 4G, LTE-Advanced Pro and the Road to\
    \ 5G; Academic Press: Cambridge, MA, USA, 2016.\n59.\nLin, Z.; Lin, M.; Wang,\
    \ J.B.; De Cola, T.; Wang, J. Joint beamforming and power allocation for satellite-terrestrial\
    \ integrated\nnetworks with non-orthogonal multiple access. IEEE J. Sel. Top.\
    \ Signal Process. 2019, 13, 657–670. [CrossRef]\n60.\nMa, Z.; Xiao, M.; Xiao,\
    \ Y.; Pang, Z.; Poor, H.V.; Vucetic, B. High-reliability and low-latency wireless\
    \ communication for internet of\nthings: Challenges, fundamentals, and enabling\
    \ technologies. IEEE Internet Things J. 2019, 6, 7946–7970. [CrossRef]\nSensors\
    \ 2023, 23, 3876\n39 of 41\n61.\nRappaport, T.S.; Sun, S.; Mayzus, R.; Zhao, H.;\
    \ Azar, Y.; Wang, K.; Wong, G.N.; Schulz, J.K.; Samimi, M.; Gutierrez, F. Millimeter\n\
    wave mobile communications for 5G cellular: It will work! IEEE Access 2013, 1,\
    \ 335–349. [CrossRef]\n62.\nDangi, R.; Lalwani, P.; Choudhary, G.; You, I.; Pau,\
    \ G. Study and investigation on 5G technology: A systematic review. Sensors\n\
    2022, 22, 26. [CrossRef]\n63.\nHuang, H.; Savkin, A.V. A method for optimized\
    \ deployment of unmanned aerial vehicles for maximum coverage and minimum\ninterference\
    \ in cellular networks. IEEE Trans. Ind. Inform. 2018, 15, 2638–2647. [CrossRef]\n\
    64.\nLuppicini, R.; So, A. A technoethical review of commercial drone use in the\
    \ context of governance, ethics, and privacy. Technol.\nSoc. 2016, 46, 109–119.\
    \ [CrossRef]\n65.\nVergouw, B.; Nagel, H.; Bondt, G.; Custers, B. Drone technology:\
    \ Types, payloads, applications, frequency spectrum issues and\nfuture developments.\
    \ In The Future of Drone Use: Opportunities and Threats from Ethical and Legal\
    \ Perspectives; T.M.C. Asser Press:\nThe Hague, The Netherlands, 2016; pp. 21–45.\n\
    66.\nKatta, S.S.; Nandyala, S.; Viegas, E.K.; AlMahmoud, A. Benchmarking Audio-based\
    \ Deep Learning Models for Detection and\nIdentiﬁcation of Unmanned Aerial Vehicles.\
    \ In Proceedings of the 2022 Workshop on Benchmarking Cyber-Physical Systems and\n\
    Internet of Things (CPS-IoTBench), Milan, Italy, 3–6 May 2022; IEEE: Piscataway,\
    \ NJ, USA, 2022; pp. 7–11.\n67.\nBorralho, R.; Mohamed, A.; Quddus, A.U.; Vieira,\
    \ P.; Tafazolli, R. A survey on coverage enhancement in cellular networks:\nChallenges\
    \ and solutions for future deployments. IEEE Commun. Surv. Tutor. 2021, 23, 1302–1341.\
    \ [CrossRef]\n68.\nAlsharif, M.H.; Nordin, R. Evolution towards ﬁfth generation\
    \ (5G) wireless networks: Current trends and challenges in the\ndeployment of\
    \ millimetre wave, massive MIMO, and small cells. Telecommun. Syst. 2017, 64,\
    \ 617–637. [CrossRef]\n69.\nBoban, M.; Kousaridas, A.; Manolakis, K.; Eichinger,\
    \ J.; Xu, W. Connected roads of the future: Use cases, requirements, and\ndesign\
    \ considerations for vehicle-to-everything communications. IEEE Veh. Technol.\
    \ Mag. 2018, 13, 110–123. [CrossRef]\n70.\nGarcia, M.H.C.; Molina-Galan, A.; Boban,\
    \ M.; Gozalvez, J.; Coll-Perales, B.; ¸Sahin, T.; Kousaridas, A. A tutorial on\
    \ 5G NR V2X\ncommunications. IEEE Commun. Surv. Tutor 2021, 23, 1972–2026. [CrossRef]\n\
    71.\nAlalewi, A.; Dayoub, I.; Cherkaoui, S. On 5G-V2X use cases and enabling technologies:\
    \ A comprehensive survey. IEEE Access\n2021, 9, 107710–107737. [CrossRef]\n72.\n\
    Bockelmann, C.; Pratas, N.K.; Wunder, G.; Saur, S.; Navarro, M.; Gregoratti, D.;\
    \ Vivier, G.; De Carvalho, E.; Ji, Y.; Stefanovi´c,\nˇC.; et al.\nTowards massive\
    \ connectivity support for scalable mMTC communications in 5G networks.\nIEEE\
    \ Access 2018,\n6, 28969–28992. [CrossRef]\n73.\nSalva-Garcia, P.; Alcaraz-Calero,\
    \ J.M.; Alaez, R.M.; Chirivella-Perez, E.; Nightingale, J.; Wang, Q. 5G-UHD: Design,\
    \ prototyping\nand empirical evaluation of adaptive Ultra-High-Deﬁnition video\
    \ streaming based on scalable H. 265 in virtualised 5G networks.\nComput. Commun.\
    \ 2018, 118, 171–184. [CrossRef]\n74.\nRahimi, H.; Zibaeenejad, A.; Safavi, A.A.\
    \ A novel IoT architecture based on 5G-IoT and next generation technologies.\n\
    In\nProceedings of the 2018 IEEE 9th annual information technology, electronics\
    \ and mobile communication conference (IEMCON),\nVancouver, BC, Canada, 1–3 November\
    \ 2018; IEEE: Piscataway, NJ, USA, 2018; pp. 81–88.\n75.\nHunukumbure, M.; Tsoukaneri,\
    \ G. Cost analysis for drone based 5G eMBB provision to emergency services. In\
    \ Proceedings of\nthe 2019 IEEE Globecom Workshops (GC Wkshps), Waikoloa, HI,\
    \ USA, 9–13 December 2019; IEEE: Piscataway, NJ, USA, 2019;\npp. 1–5.\n76.\nLi,\
    \ Z.; Uusitalo, M.A.; Shariatmadari, H.; Singh, B. 5G URLLC: Design challenges\
    \ and system concepts. In Proceedings of the\n2018 15th international symposium\
    \ on wireless communication systems (ISWCS), Lisbon, Portugal, 28–31 August 2018;\
    \ IEEE:\nPiscataway, NJ, USA, 2018; pp. 1–6.\n77.\nTrivisonno, R.; Condoluci,\
    \ M.; An, X.; Mahmoodi, T. mIoT slice for 5G systems: Design and performance evaluation.\
    \ Sensors\n2018, 18, 635. [CrossRef] [PubMed]\n78.\nMarchese, M.; Moheddine, A.;\
    \ Patrone, F. IoT and UAV integration in 5G hybrid terrestrial-satellite networks.\
    \ Sensors 2019,\n19, 3704. [CrossRef] [PubMed]\n79.\nChekired, D.A.; Togou, M.A.;\
    \ Khoukhi, L.; Ksentini, A. 5G-slicing-enabled scalable SDN core network: Toward\
    \ an ultra-low\nlatency of autonomous driving service. IEEE J. Sel. Areas Commun.\
    \ 2019, 37, 1769–1782. [CrossRef]\n80.\nBodinier, Q.; Bader, F.; Palicot, J. On\
    \ spectral coexistence of CP-OFDM and FB-MC waveforms in 5G networks. IEEE Access\
    \ 2017,\n5, 13883–13900. [CrossRef]\n81.\nBiglieri, E.; Goldsmith, A.J.; Greenstein,\
    \ L.J.; Poor, H.V.; Mandayam, N.B. Principles of Cognitive Radio; Cambridge University\n\
    Press: Cambridge, UK, 2013.\n82.\nZubow, A.; Sombrutzki, R. Adjacent channel interference\
    \ in IEEE 802.11 n. In Proceedings of the 2012 IEEE Wireless Communica-\ntions\
    \ and Networking Conference (WCNC), Paris, France, 1–4 April 2012; IEEE: Piscataway,\
    \ NJ, USA, 2012; pp. 1163–1168.\n83.\nYu, Y.; Dutkiewicz, E.; Huang, X.; Mueck,\
    \ M.; Fang, G. Performance analysis of soft frequency reuse for inter-cell interference\n\
    coordination in LTE networks. In Proceedings of the 2010 10th International Symposium\
    \ on Communications and Information\nTechnologies, Tokyo, Japan, 26–29 October\
    \ 2010; IEEE: Piscataway, NJ, USA, 2010; pp. 504–509.\n84.\nBoukalov, A.O.; Haggman,\
    \ S.G. System aspects of smart-antenna technology in cellular wireless communications-an\
    \ overview.\nIEEE Trans. Microw. Theory Tech. 2000, 48, 919–929. [CrossRef]\n\
    85.\nBahai, A.R.; Saltzberg, B.R.; Ergen, M. Multi-Carrier Digital Communications:\
    \ Theory and Applications of OFDM; Springer Science &\nBusiness Media: Berlin/Heidelberg,\
    \ Germany, 2004.\nSensors 2023, 23, 3876\n40 of 41\n86.\nZambianco, M.; Verticale,\
    \ G. Interference minimization in 5G physical-layer network slicing.\nIEEE Trans.\
    \ Commun. 2020,\n68, 4554–4564. [CrossRef]\n87.\nSeiﬁ, N.; Zhang, J.; Heath, R.W.;\
    \ Svensson, T.; Coldrey, M. Coordinated 3D beamforming for interference management\
    \ in cellular\nnetworks. IEEE Trans. Wirel. Commun. 2014, 13, 5396–5410. [CrossRef]\n\
    88.\nDe Gaudenzi, R.; Angeletti, P.; Petrolati, D.; Re, E. Future technologies\
    \ for very high throughput satellite systems. Int. J. Satell.\nCommun. Netw. 2020,\
    \ 38, 141–161. [CrossRef]\n89.\nHanzo, L.; Yang, L.L.; Kuan, E.; Yen, K. Single-and\
    \ Multi-Carrier DS-CDMA: Multi-User Detection, Space-Time Spreading, Synchroni-\n\
    sation, Standards and Networking; John Wiley & Sons: Hoboken, NJ, USA, 2003.\n\
    90.\nAgiwal, M.; Roy, A.; Saxena, N. Next generation 5G wireless networks: A comprehensive\
    \ survey. IEEE Commun. Surv. Tutor.\n2016, 18, 1617–1655. [CrossRef]\n91.\nOmar,\
    \ T.; Ketseoglou, T.; Naffaa, I. A novel self-healing model using precoding &\
    \ big-data based approach for 5G networks.\nPervasive Mob. Comput. 2021, 73, 101365.\n\
    92.\nShaddad, R.Q.; Al-Barakani, W.G.; Al-Hakimi, A.R.; Ahmed, S.A.; Ahmed, M.Y.\
    \ Mobility Management for Small Cells in 5G\nUltra-Dense Wireless Network. In\
    \ Proceedings of the 2022 2nd International Conference on Emerging Smart Technologies\
    \ and\nApplications (eSmarTA), Ibb, Yemen, 25–26 October 2022; IEEE: Piscataway,\
    \ NJ, USA, 2022; pp. 1–6.\n93.\nStanze, O.; Weber, A. Heterogeneous networks with\
    \ LTE-Advanced technologies. Bell Labs Tech. J. 2013, 18, 41–58. [CrossRef]\n\
    94.\nQiao, J.; Shen, X.S.; Mark, J.W.; Shen, Q.; He, Y.; Lei, L. Enabling device-to-device\
    \ communications in millimeter-wave 5G cellular\nnetworks. IEEE Commun. Mag. 2015,\
    \ 53, 209–215. [CrossRef]\n95.\nLynggaard, P. Using neural networks to reduce\
    \ sensor cluster interferences and power consumption in smart cities. Int. J.\
    \ Sens.\nNetw. 2020, 32, 25–33. [CrossRef]\n96.\nLiu, Y.; Zeng, Q.; Zhao, Y.;\
    \ Wu, K.; Hao, Y. Novel channel-hopping pattern-based wireless IoT networks in\
    \ smart cities for\nreducing multi-access interference and jamming attacks. EURASIP\
    \ J. Wirel. Commun. Netw. 2021, 2021, 152. [CrossRef]\n97.\nPérez-Neira, A.I.;\
    \ Caus, M.; Zakaria, R.; Le Ruyet, D.; Koﬁdis, E.; Haardt, M.; Mestre, X.; Cheng,\
    \ Y. MIMO signal processing in\noffset-QAM based ﬁlter bank multicarrier systems.\
    \ IEEE Trans. Signal Process. 2016, 64, 5733–5762. [CrossRef]\n98.\nZhang, X.;\
    \ Haenggi, M. A stochastic geometry analysis of inter-cell interference coordination\
    \ and intra-cell diversity. IEEE Trans.\nWirel. Commun. 2014, 13, 6655–6669. [CrossRef]\n\
    99.\nElsayed, M.; Shimotakahara, K.; Erol-Kantarci, M. Machine learning-based\
    \ inter-beam inter-cell interference mitigation in\nmmWave. In Proceedings of\
    \ the ICC 2020–2020 IEEE International Conference on Communications (ICC), Dublin,\
    \ Ireland, 7–11\nJune 2020; IEEE: Piscataway, NJ, USA, 2020; pp. 1–6.\n100. Hu,\
    \ B.; Beaulieu, N.C. Accurate performance evaluation of time-hopping and direct-sequence\
    \ UWB systems in multi-user\ninterference. IEEE Trans. Commun. 2005, 53, 1053–1062.\
    \ [CrossRef]\n101. Moongilan, D. 5G wireless communications (60 GHz band) for\
    \ smart grid—An EMC perspective. In Proceedings of the 2016\nIEEE International\
    \ Symposium on Electromagnetic Compatibility (EMC), Ottawa, ON, Canada, 25–29\
    \ July 2016; IEEE: Piscataway,\nNJ, USA, 2016; pp. 689–694.\n102. Sun, S.; MacCartney,\
    \ G.R.; Rappaport, T.S. Millimeter-wave distance-dependent large-scale propagation\
    \ measurements and\npath loss models for outdoor and indoor 5G systems. In Proceedings\
    \ of the 2016 10th European Conference on Antennas and\nPropagation (EuCAP), Davos,\
    \ Switzerland, 10–15 April 2016; IEEE: Piscataway, NJ, USA, 2016; pp. 1–5.\n103.\
    \ Schulpen, R.; Bronckers, L.; Smolders, A.; Johannsen, U. 5G millimeter-wave\
    \ NLOS coverage using specular building reﬂections.\nIn Proceedings of the 2020\
    \ 14th European Conference on Antennas and Propagation (EuCAP), Copenhagen, Denmark,\
    \ 15–20\nMarch 2020; IEEE: Piscataway, NJ, USA, 2020; pp. 1–5.\n104. Morais, D.H.;\
    \ Morais. 5G and beyond Wireless Transport Technologies; Springer: Berlin/Heidelberg,\
    \ Germany, 2021.\n105. Deng, S.; MacCartney, G.R.; Rappaport, T.S. Indoor and\
    \ outdoor 5G diffraction measurements and models at 10, 20, and 26 GHz.\nIn Proceedings\
    \ of the 2016 IEEE Global Communications Conference (GLOBECOM), Washington, DC,\
    \ USA, 4–8 December 2016;\nIEEE: Piscataway, NJ, USA, 2016; pp. 1–7.\n106. Chun,\
    \ Y.J.; Cotton, S.L.; Dhillon, H.S.; Lopez-Martinez, F.J.; Paris, J.F.; Yoo, S.K.\
    \ A Comprehensive Analysis of 5G Heterogeneous\nCellular Systems Operating Over\
    \ κ–µ Shadowed Fading Channels. IEEE Trans. Wirel. Commun. 2017, 16, 6995–7010.\
    \ [CrossRef]\n107. Samad, M.A.; Diba, F.D.; Choi, D.Y. A survey of rain fade models\
    \ for earth–space telecommunication links—Taxonomy, methods,\nand comparative\
    \ study. Remote Sens. 2021, 13, 1965. [CrossRef]\n108. Mahmud, M.H.; Hossain,\
    \ M.M.; Khan, A.A.; Ahmed, S.; Mahmud, M.A.; Islam, M.H. Performance analysis\
    \ of OFDM, W-OFDM\nand F-OFDM under Rayleigh fading channel for 5G wireless communication.\
    \ In Proceedings of the 2020 3rd International\nConference on Intelligent Sustainable\
    \ Systems (ICISS), Thoothukudi, India, 3–5 December 2020; IEEE: Piscataway, NJ,\
    \ USA, 2020;\npp. 1172–1177.\n109. Dey, P.; Masal, A.; Kaimalettu, S.; Milleth,\
    \ J.K.; Ramamurthi, B. Reference signal design to mitigate co-channel interference\
    \ in 5G\nOFDM systems with multiple numerologies. Phys. Commun. 2022, 53, 101653.\
    \ [CrossRef]\n110. Wu, T.Y.; Chang, T. Interference reduction by millimeter wave\
    \ technology for 5G-based green communications. IEEE Access 2016,\n4, 10228–10234.\
    \ [CrossRef]\nSensors 2023, 23, 3876\n41 of 41\n111. Soret, B.; De Domenico, A.;\
    \ Bazzi, S.; Mahmood, N.H.; Pedersen, K.I. Interference coordination for 5G new\
    \ radio. IEEE Wirel.\nCommun. 2017, 25, 131–137. [CrossRef]\n112. Qamar, F.; Hindia,\
    \ M.N.; Dimyati, K.; Noordin, K.A.; Majed, M.B.; Abd Rahman, T.; Amiri, I.S. Investigation\
    \ of future 5G-IoT\nmillimeter-wave network performance at 38 GHz for urban microcell\
    \ outdoor environment. Electronics 2019, 8, 495. [CrossRef]\nDisclaimer/Publisher’s\
    \ Note: The statements, opinions and data contained in all publications are solely\
    \ those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or\
    \ the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury\
    \ to\npeople or property resulting from any ideas, methods, instructions or products\
    \ referred to in the content.\n"
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/23/8/3876/pdf?version=1681180014
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Utilization of 5G Technologies in IoT Applications: Current Limitations
    by Interference and Network Optimization Difficulties—A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2019.2948027
  analysis: '>'
  authors:
  - Abdelmuttlib Ibrahim Abdalla Ahmed
  - Abdullah Gani
  - Siti Hafizah Ab Hamid
  - Abdelzahir Abdelmaboud
  - Hassan Jamil Syed
  - Riyaz Ahamed Ariyaluran Habeeb
  - Ihsan Ali
  citation_count: 14
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathMenu.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Subscribe Donate Cart Create Account Personal Sign In Browse My Settings
    Help Institutional Sign In All Books Conferences Courses Journals & Magazines
    Standards Authors Citations ADVANCED SEARCH Journals & Magazines >IEEE Access
    >Volume: 7 Service Management for IoT: Requirements, Taxonomy, Recent Advances
    and Open Research Challenges Publisher: IEEE Cite This PDF Abdelmuttlib Ibrahim
    Abdalla Ahmed; Abdullah Gani; Siti Hafizah Ab Hamid; Abdelzahir Abdelmaboud; Hassan
    Jamil Syed; Riyaz Ahamed Ariyaluran Habeeb Mohamed All Authors 13 Cites in Papers
    4317 Full Text Views Open Access Comment(s) Under a Creative Commons License Abstract
    Document Sections I. Introduction II. Background III. Service Management Platforms
    for IoT IV. Requirements of Service Management for IoT V. Taxonomy of Service
    Management for IoT Show Full Outline Authors Figures References Citations Keywords
    Metrics Abstract: The exponential growth in the number of smart devices connected
    to the Internet of Things (IoT), and associated with various IoT-based smart applications
    and services, raises interoperability challenges which could affect the sustainability
    of IoT services. IoT software applications are built using different software
    platforms and embedded in diverse types of terminals and sensing devices. Aiming
    to offer smart services over a range of network technologies that use different
    communication protocols. The concept of Web service with service-oriented solutions
    was introduced to cope with the heterogeneity of hardware and software, and to
    tackle issues of interoperability, flexibility and scalability. The main step
    of this solution was the integration of Web of Things technologies into smart
    device networks, with the utilization of IoT gateways. Service management is a
    crucial factor in sustaining service-oriented solutions in dynamic and highly
    scalable IoT systems, and is concerned with several issues associated with service
    provisioning, orchestration, composition and adaption. This work was motivated
    by the need for robust and flexible service management systems that can meet the
    requirements for the rapid scalability and heterogeneity associated with the exponential
    growth of IoT systems. In the literature there is no survey of service management
    issues and associated research efforts in the field of IoT. In this article, we
    identify the key requirements for managing IoT services as well as common service
    management platforms for IoT. We provide a thematic taxonomy based on the important
    factors, and investigate recent advances in service management for IoT systems.
    Finally, the major challenges that remain open are presented as a guide for future
    research directions. Taxonomy of service management for IoT. Published in: IEEE
    Access ( Volume: 7) Page(s): 155472 - 155488 Date of Publication: 17 October 2019
    Electronic ISSN: 2169-3536 DOI: 10.1109/ACCESS.2019.2948027 Publisher: IEEE Funding
    Agency: CCBY - IEEE is not the copyright holder of this material. Please follow
    the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text
    articles and stipulations in the API documentation. SECTION I. Introduction Rapid
    advancements in emerging technologies and the smooth convergence of wireless communication,
    sensors and radio frequency identification (RFID) have resulted in the birth of
    the Internet of Things (IoT). IoT service platforms and corresponding smart features
    have been embedded in electromechanical systems and controllers to establish seamless
    integration between the physical world and cyberspace and to provide smart service
    via daily life applications [5]. Numerous IoT platforms and connectivity protocols
    have been developed, for instance the constrained application protocol (CoAP),
    Bluetooth low energy (BLE) and message queuing telemetry transport (MQTT). However,
    the heterogeneity of the IoT devices, standards and communication protocols raises
    several problems, such as a lack of interoperability, scalability and flexibility
    [7]. A service orientation is utilized in many studies to discuss these problems.
    Service-oriented solutions include service-oriented architecture (SOA) and microservice
    architecture, which are architectural patterns followed in IoT design [7], [10].
    In a service-oriented IoT, the devices/entities provide services to other devices/entities
    via communication protocols. A service is “a discrete unit of business functionality
    that is made available through a service contract” [18]. A service contract comprises
    a service interface, documentation, QoS and service policies. The term ‘service
    management’ indicates a method of enabling seamless service composition, integration
    and interoperability among various IoT applications and platforms, which run on
    various devices over heterogeneous networking technologies [7]. Service management
    aims to ensure and monitor the performance and quality of service of IoT transactions.
    Service-oriented solutions integrate web services into sensor networks via the
    utilization of IoT-optimised gateways that can fill the gap between devices, networks
    and access terminals [14]. The World Wide Web Consortium (W3C) introduced web
    service through Web of Things (WoT) technologies in order to ensure interoperability
    and integration between IoT platforms and domains by extending web technologies
    (e.g. metadata and APIs). WoT provides a Thing description (TD) mechanism that
    is used to describe IoT interfaces, and via which IoT technologies and services
    communicate with each other regardless of the underlying details and heterogeneity,
    across multiple networking protocols [15]. In addition, WoT provides a standardized
    approach for defining and programming IoT behaviors. In service-oriented solutions,
    there are three groups of actors: a set of service providers, a set of service
    requestors and directories of Things. A WoT server represents the service providers
    (by publishing their services at runtime), and a WoT client represents service
    requestors (by discovering the published services). WoT servers, clients and device
    control methods are contained in an entity called a WoT servient. The service
    requester selects a service provider based on the type and quality of the offered
    service [16]. Figure 1 illustrates the processes in a service-oriented solution
    adapted to IoT. FIGURE 1. Service-oriented solution in the IoT. Show All This
    article is the first comprehensive survey of service management for IoT, although
    service composition has previously been reviewed as one the factors of service
    management [17]. This study is conducted with the aim of investigating service
    management for IoT, and is motivated by the need for service-oriented solutions,
    as improved versions will be needed in the future to accommodate a tremendous
    number of services offered by devices through heterogeneous communication networks
    and protocols. The contributions of this article are summarized as follows: We
    identify and describe the core requirements of service management in IoT. We extensively
    investigate service management in the context of IoT, and articulate some prominent
    recent advances. We investigate service management platforms in IoT to identify
    service management paradigms. We present a thematic taxonomy based on the most
    important parameters as an aid to understanding service management and its associated
    issues in IoT. We include a discussion of service management challenges, as a
    guide for future research. Each of these contributions is presented in a separate
    section, from Sections II to VII, and the conclusion is then provided in Section
    VIII. SECTION II. Background This section presents the basic concepts and definitions
    related to service management in IoT. A. The Concept of Service in IoT The services
    are self-contained, loosely-coupled, platform-independent, discoverable, composable
    and invokable [19]. ‘Self-contained’ means that a service maintains its own state
    independently from the application that uses it, while ‘loosely-coupled’ means
    that there are few dependencies between a consumer and a service. ‘Platform-independent’
    means that a requestor can invoke the service regardless of the differences between
    the platforms (hardware or software). The most common way of applying the concepts
    of service is through web service technologies, i.e. computing technologies that
    enable data exchange and interoperability between different applications running
    on various devices over the web [20]. WoT services utilize several standards and
    technologies such as JSON, XML, HTTP, MQTT and CoAP. W3C defined a web service
    as “a software application identified by a Uniform Resource Identifier (URI),
    whose interface and binding are capable of being defined, described and discovered
    by XML artefacts to support direct interactions with other software applications
    using XML based messages via Internet-based protocols” [21]. WoT service management
    can be defined as a management system for WoT services via methods that enforce
    monitoring, control and notifications of service specifications and quality. Service
    quality indicates availability (e.g. the appearance of the service on one or more
    IoT device or cloud of Things), performance (e.g. delay and failure rates) and
    accessibility to the service via the dashboard and WoT browser. B. Web of Things
    WoT was introduced by W3C [22] to leverage web standards and technologies (e.g.
    metadata and APIs) for interconnecting all types of devices, either directly or
    via an M2M gateway. WoT enables the exposure of functionalities through RESTful
    APIs, and this supports easy access and interaction and consequently sustains
    flexible, scalable and interoperable services. Table 1 presents an explanation
    of the terms and definitions used in WoT. TABLE 1 Defintion and Terms of WoT SECTION
    III. Service Management Platforms for IoT These platforms are software that can
    offer integrated services, such as simultaneous connectivity among a tremendous
    number of IoT devices and easily enabling device configuration for device-to-device
    communication and synchronization with the IoT cloud. This section investigates
    the IoT platforms that support service management, and a comparison is provided
    in Table 2. TABLE 2 Comparison of IoT Platforms A. Salesforce Thunder IoT Salesforce
    enriched IoT by introducing the its Thunder platform, an event processing and
    rules engine [23]. This platform was designed to collect, analyze and respond
    to massive and scalable events in real time. An analysis of data streaming in
    IoT environments supports predictive and proactive actions. Thunder supports Salesforce’s
    IoT cloud, which can interconnect the big data generated by IoT devices with the
    consumer’s dashboards, other applications and partners, and can initiate actions
    for real-time responses [24]. Salesforce’s IoT cloud assists the customer in understanding
    the behavior of products and devices by maintaining device profiles based on the
    customer’s context and the data stream received from the IoT device. Streaming
    data helps in inferring the context in which the device is used. Context data
    shape information about the activities by combining the customer’s details with
    device data. B. Amazon Web Service IoT Amazon introduced an integrated solution
    for service management for IoT, involving several platforms components such as
    the Amazon Web Service (AWS) IoT Cloud, AWS IoT device management, AWS IoT Device
    Defender and AWS IoT Analytics [25]. AWS IoT Cloud is a cloud-based platform that
    smoothly connects IoT devices, and securely enables them to interact with each
    other and with cloud applications. This platform supports devices and messages
    by processing and routing those messages to AWS endpoints and other devices in
    a reliable and secure way [26]. AWS IoT device management is a service that offers
    friendly and secure onboard monitoring, organization and remote control of scalable
    IoT devices. The AWS IoT Device Defender is a security service for protecting
    IoT devices through conducting continuous audits on security policies of IoT devices
    to ensure that there is no security violations and misbehaviors. AWS IoT Analytics
    provides accurate and advanced analytics services for massive volumes of IoT data.
    C. Google Cloud IoT Google Cloud IoT platform [27] enriches service management
    for IoT by providing secure connection, data processing and management for millions
    of globally deployed sensing entities. Cloud IoT, in collaboration with other
    services on the Cloud IoT platform, offers integrated solutions. These solutions
    include data aggregation, processing, analysis, and visualization in real time,
    to ensure operational efficiency. Cloud IoT uses sub-underneath/cloud-pub to aggregate
    the data from IoT devices into a unified global system that seamlessly integrates
    the data with data analytics services. Data analytics supports advanced analysis,
    visualizations and artificial intelligence mechanisms to boost operational efficiency
    and business optimization. Furthermore, the Google Cloud IoT platform is highly
    scalable, since it runs on server-less infrastructure and supports standard data
    transmission and security protocols. D. Microsoft Azure IoT Hub Azure IoT Hub
    is a scalable cloud-IoT platform that comprises a device registry, data storage
    management, and security services [28]. The platform maintains individual identities
    and authorizations for each of the connected devices, and preserves the confidentiality
    of device-to-cloud and cloud-to-device communication. The platform provides a
    service interface for supporting the development of IoT applications, device synchronization
    and flexible monitoring. Azure IoT Central and Azure IoT Edge were introduced
    with Azure IoT Hub to support many operational services. Azure IoT Central facilitates
    the connection of IoT devices, provides data analytics, and supports businesses
    integration. Azure IoT Edge realises hybrid cloud and IoT solutions via orchestration
    between code and services, and between cloud and edge. E. Cisco IoT Cisco IoT
    [29] introduced a mobility-cloud-based software suite for IoT to improve IoT-based
    businesses. This platform provides numerous services, such as connectivity services,
    operation management, data management and security. Cisco industrial networking
    solutions offer reliable and secure connectivity for IoT systems. The Cisco IoT
    platform manages and runs IoT operations smoothly and consistently with the help
    of tools such as Cisco IOx for controlling edge applications and Cisco DNA for
    infrastructure integration. Cisco also introduced Kinetic IoT to support data
    extraction and computation. Cisco protects the deployment of devices via a secure
    IoT architecture, which enhances all IoT security services. F. AT&T IoT The AT&T
    IoT Platform [30] enables device manufacturers and developers to build elegant
    solutions for complex problems. The platform categorizes its services for IoT
    environment as device services, data services, containerization services, and
    global connectivity and management. Device services involve management and organization
    of a scalable registry of devices, utilizing a message broker to issue commands
    to IoT applications and maintaining the device state (storage and retrieval of
    state information). Data-related services involve data storage, time-series, data
    analytics and visualization to support decision making. The containerization service
    provided as a cloud application is built and deployed in multi-datacenter environments.
    The AT&T IoT platform provides global connectivity through IoT SIM and hardware.
    G. IBM Watson IoT The IBM Watson IoT platform [31] follows a cloud-based service
    management paradigm, and supports secure connectivity among IoT components, data
    management and analysis. This platform provides an add-on to enable a Blockchain
    service for the validation and authentication of assets and events. The IBM Watson
    IoT platform provides analytics service for enriching, augmenting, interacting
    and smoothly integrating the IoT raw data. This platform makes a significant contribution
    in terms of increasing business revenue, using bidirectional communication with
    the end user to accelerate the access of new services and products. H. Oracle
    IoT Oracle IoT [32] supports several different domains, such as the supply chain
    and enterprise planning. Moreover, the platform extends the application of human
    experience to the cyber-physical, to generate new types of applications such as
    auto-driving using intelligent prediction. The platform provides many services
    such as asset, production and service monitoring. Asset monitoring is performed
    via a dedicated IoT cloud service application that aggregates data regarding the
    location, condition and utilization status of the IoT device. Production monitoring
    is conducted by collecting and integrating data on the manufacturing machines,
    production line and factory setting. Service monitoring increases visibility,
    and supports proactive maintenance through the production prediction paradigm.
    I. Ubidots IoT The Ubidots solution [33] supports the industry by connecting various
    projects such as healthcare, utilities, energy systems, manufacturing and smart
    transportation through providing data captured from IoT devices, data analytics,
    events and alarms and live dashboards. Data capturing is achieved by connecting
    IoT devices to the Ubidots cloud and managing data sensing via device libraries.
    Data analytics services are provided by the Ubidots engine to improve the efficiency
    and effectiveness of the IoT system. The events and alarm engine sends an alert
    in the form of an email, SMS or telegram to the owner of the IoT devices. A live
    dashboard enables the user/administrators to perform live activities such as device
    control and data analysis. SECTION IV. Requirements of Service Management for
    IoT This section presents the essential requirements of service management for
    cloud-based IoT systems. Figure 2. represents these requirements. FIGURE 2. Requirements
    of service management for IoT. Show All A. Scalability In IoT applications, the
    transactions are generally composed of many services from different service providers.
    Scalability and flexibility are required, since the number of IoT devices is rapidly
    increasing and is expected to provide billions of services in the future [34].
    Publishing a tremendous amount of resources in the cloud requires a highly scalable
    directory/registry of Things, in order to ensure the rapid and real-time discovery
    of IoT resources and services. Unlike many conventional distributed systems, resources
    in IoT systems are related to each other both semantically and contextually. The
    traffic monitoring application may invoke a service that involves resources located
    within the same environmental context, e.g. a monitoring service for a road with
    light and smoke sensors. B. Interoperability According to the IEEE [35], interoperability
    is “the ability of two or more systems or components to exchange information and
    to use the information that has been exchanged”. The essential concern is to allow
    two or more heterogeneous resources to interact by making their services compatible
    at the syntactic interface level [36]. A service management platform is required
    in order to provide interoperable services for the heterogeneous devices, apps,
    platforms and communication technologies [37]. Interoperability is improved by
    considering compatibility with communication protocols and standards and all types
    of applications, such as mobile, business and desktop apps. WoT is trying to tackle
    this heterogeneity by including communication metadata in the TD. C. QoS Metrics
    and Measurement Interactive IoT applications have functional and non-functional
    requirements for service composition [38]. Functional requirements present the
    expected functioning service from the IoT service, while the TD defines the functional
    requirements. Non-functional requirements are QoS issues such as interoperability,
    response time, availability, accuracy, price reliability, sustainability, and
    service level agreements (SLAs). Specification of the metrics that determine the
    service consumer’s satisfaction with the provided service is an essential issue
    for measuring and assessing IoT services. Service providers use QoS metrics to
    ensure that the service is running according to a specific set of measures, and
    the service consumer uses specific QoS metrics to select suitable service providers.
    QoS metrics differ according to the context of use, and have different requirements
    and degrees of importance [39], [40]. D. Management of Service Level Agreements
    An SLA is a contract between a service provider and service requestor/consumer.
    In IoT, web services interact with each other to ensure QoS via SLAs. SLAs are
    critical for the deployment of IoT entities and the adoption of cloud services
    [39]. The SLA lifecycle has requirements related to information handling, creation
    of the SLA template, the definition of management issues and SLA enforcement [41].
    Information handling focuses on the processing of the information, which affects
    the usage of the service. The creation of the SLA template is associated with
    capturing relevant information such as service components and service provisioning
    information. Management issues involve several activities such as monitoring,
    negotiation, assessment, trustworthiness and violation. SLA enforcement and termination
    are triggered by the time expiration of the service period or a violating action.
    E. Monitoring and Visualization IoT services span multiple network domains and
    sophisticated technologies. A robust service monitoring solution is necessary
    for critical devices such as alarm systems, IP cameras, smart locks, pet monitors,
    healthcare devices, thermostats and the cloud of Things, while the automated monitoring
    and visualization of service provisioning assist in tuning the QoS and scaling
    network resources to fit the SLA. One of the main challenges facing service management
    in IoT is the monitoring of SLA violations. IoT allows users to compose massive,
    pervasive and complicated applications. Consequently, it is crucial to develop
    an effective method for SLA monitoring and management [39]. Monitoring mechanisms
    mainly focus on the service provider, and create alerts in the case of bottleneck,
    failure or SLA violation. F. Big Data Analytics Recently, big data analytics has
    been widely utilized in service management processes such as making correlations,
    deriving deep insights, and extracting patterns from IoT data [42]. These processes
    help in increasing the operational efficiency and high control in real time. The
    primary emphasis of big data analytics for service management is the analysis
    and evaluation of big data records related to QoS and the behaviors of IoT devices.
    Using real-time big data analytics for IoT performance and activities helps in
    proactive maintenance and other actions such as storing streaming data in an operational
    database. Real-time analytics for operational data also optimizes the way in which
    IoT devices and applications interact, and provides smart services [43]. G. Security
    and Privacy Service management for IoT is associated with several security factors;
    it starts from a consideration of security features in the initial design of the
    IoT devices and includes the runtime of the service and the method of interaction
    between these devices [44]. Various security services are required for the different
    phases of IoT operations, such as device connection and synchronization, preserving
    the privacy of the transaction data and ensuring the integrity of entities. When
    an entity connects to the system, authentication is needed to establish trust
    with other IoT devices and services. After the establishment of trust, IoT devices
    and services can securely communicate and collaborate via information exchange
    and performing transactions. Preserving the privacy and integrity of the exchanged
    data is a crucial issue, as some of the data are sensitive and are used in critical
    decision making [45]. The incorporation of a reliable lightweight cryptographic
    mechanism with each IoT device and the application of security practices are required
    as countermeasures for various security threats. SECTION V. Taxonomy of Service
    Management for IoT This section introduces a thematic taxonomy of service management
    for IoT that includes several components and parameters of the service management
    environment, namely service types, architectural organizations, middleware, runtime
    management, security and applications, as illustrated in Figure 3. FIGURE 3. Taxonomy
    of service management for IoT. Show All A. Types of Service IoT services can be
    categorized based on their technical features into four classes: identity-related,
    data aggregation, collaborative-aware, and pervasive services. 1) Identity-Related
    Services Managing the identity of Things and their owners is a crucial factor
    in successfully leveraging the shifting characteristics of cyberspace. Identity-related
    services provide an identification feature for IoT entities through several technologies
    such as RFIDs and barcodes. An RFID tag is attached to a device, and a tag reader
    then accesses the information in the RFID tag (i.e. the identity information),
    and makes a request to the IoT name resolution server [46]. 2) Data Aggregation
    Services This type of service utilizes identity-related services in conjunction
    with the Internet, sensing devices and gateways. IoT gateways enable data aggregation
    services to access differently to access remote sensors and networking auxiliary
    devices. Data aggregation is then performed by a sensing device that collects
    and processes the data and transmits it via a WoT service using JSON or XML to
    the platform for further processing [47]. The platform implements the management
    strategy, involving the sensing devices, applications, data, services and third
    parties. These types of services are necessary in the monitoring of IoT applications,
    for instance monitoring and control systems in the greenhouse of smart agriculture
    applications [15]. 3) Collaboration-Aware Services In IoT, a collaboration-aware
    service involves device-to-device communication and device-to-human interaction,
    and in many scenarios these types of communication are performed with the help
    of an IoT cloud [47]. Composing collaboration-aware services requires network
    security, sensing devices with processing capabilities and smarter terminals.
    Collaboration-aware services depend on aggregation services to begin assessments
    for decision making and performing actions. 4) Pervasive Services Pervasive services
    are the main goal of IoT, and extend collaborative-aware services to provide smooth
    connectivity anywhere, anytime, for everything, and for every task, whether via
    computer, smartphone or another type of smart terminal. The RESTful protocol supports
    pervasive services by providing a universal API that ensure interoperability in
    IoT systems [42]. To achieve the user’s transaction goals, collaborative-aware
    and pervasive services follow many processes of service management, such as service
    identifications and definition, service discovery and selection, service composition
    and service orchestration. B. Architectural Organizations Architectural organization
    is used to model high-level design that fulfils the requirements of various actors
    when building an IoT application. This architecture further provides direction
    for application design and development, which contains layers and tiers. The most
    common architectural organization for IoT services are service-oriented architecture
    (SOA) and micro-services, which are discussed in the following and compared in
    Table 3. TABLE 3 IoT Service Management Architectures 1) Service-Oriented Architecture
    SOA for IoT (SOA-IoT) is used to couple heavyweight functionalities or containers
    in a corporate information system. Moreover, SoA is suitable for embedding many
    real-world devices to assist in the processing and communication of user tasks
    [48]. SOA-IoT-based load balancing techniques have been used in IoT architectures
    to address the high bandwidth issues raised by a large number of terminals, which
    are accompanied by an increase in the data transmission time [49]. In addition,
    SOA-IoT can help in the decomposition of complex and monolithic systems into loosely
    coupled components. A complex system is managed as a set of strongly defined objects
    or subsystems. When SOA-IoT is applied to IoT, the resulting design can provide
    extensibility, scalability, modularity, and interoperability among different IoT
    devices [50]. 2) Microservices Microservices are a method of splitting large,
    structured applications into small, extremely decoupled tasks. Furthermore, a
    separate process is run for each service, rather than full in-memory function
    calls, and lightweight appliances are used to communicate with each other [51].
    The microservice mechanism permits IoT devices to use various messaging protocols
    inside the service itself. Moreover, separate application features are more capable
    of independent processing, and allow for resilience of the complete application;
    in the case of an application crash, only that specific service will be terminated,
    rather than the entire application. In fact, there is compatibility in several
    respects between the microservices and the IoT, for instance the use of lightweight
    communication and software containers to achieve independent software deployment,
    semi-decentralized management and independent development approaches. Additionally,
    the conception of choreography in microservices can work as an outline for IoT
    applications [52]. C. Middleware Middleware is a software layer that serves as
    a mediator between a different set of applications communicating with a various
    IoT devices [53]. This subsection briefly overviews the main types of middleware
    for IoT, namely service-based, cloud-based and actor-based, and presents a comparison
    in Table 4. TABLE 4 Types of IoT Middlewares 1) Service-Based Service-based IoT
    middleware are deployable in the cloud or on servers. This type of middleware
    is associated with simple tools such as web applications for viewing the raw data
    generated by IoT devices. However, the middleware offers limited functionalities
    to users in the case of composition or integration with other applications or
    the interoperation of data. Security is ensured by setting up restricted access
    to protect private and sensitive data. In service-based middleware, the computational
    units cannot be extended or configured by the end-users. The services are autonomous,
    dynamically adaptive and can deliver a flexible and simple environment for application
    development [54]. Service-based middleware requires simultaneous communication
    between the service consumer and producer [55]. 2) Cloud-Based Although cloud-based
    IoT middleware supports the deployment of only a limited number and type of IoT
    devices, it easily enables data aggregation and interpretation. In this type of
    middleware, the functionalities are exposed as a group of APIs with high computation
    power, massive capacity storage with a service monitoring and analytics tool.
    A cloud-based IoT service is provided to the device via the cloud, and is controlled
    by the cloud provider and accessed by the requesting entities. A cloud-based platform
    is extensively used for several IoT applications, such as smart homes, smart cities
    and smart energy. It contributes several modules for regular device-to-device
    activity, for instance device management, data collection, storage management
    and security. 3) Actor-Based Actor-based middleware has a relatively large response
    time and scalability for connecting IoT devices, and hence this type of middleware
    is deployable in all computation layers, including IoT devices. Furthermore, the
    middleware allows users to extend the computational units through utilizing or
    developing pluggable actors. Actor-based IoT middleware does not utilize a particular
    standard such as RESTful API or BLE to achieve interoperability between IoT devices.
    However, a specific model of programming or device abstraction is exploited by
    the middleware to tackle the heterogeneity of IoT devices [55]. D. Runtime Management
    Runtime management helps to ensure flexible and easy use of the required scripts
    in the IoT devices, with the aim of providing a service [56]. This section discusses
    the different types of common runtime management of service management for IoT.
    1) Composition Service composition enables interaction between IoT entities and
    consumer requirements [17]. Service composition follows several strategies to
    select a suitable service and service provider, based on the services that are
    recognized by the service discovery mechanism. The selection of appropriate services
    is a crucial task that entails achieving the desired quality and functionality
    by combining many services to form an integrated composite service. The service
    composition process involves web suppliers and business processes in IoT. 2) Provisioning
    Provisioning is the method of preparing and delivering the services of the smart
    devices to the web. Service provisioning is achieved through collaboration between
    standard applications, smart and ubiquitous applications. Smart service provisioning
    offers a new opportunity for conventional internet applications to move toward
    new ecosystems. A smart object can also be incorporated into the open web standard
    using web application programming interfaces. The rapid growth of IoT applications
    has transformed service provisioning from the perspective of always-on services
    to always-responsive services, i.e. at-runtime responses for any user [8]. 3)
    Orchestration Service orchestration supports the integration of multiple services
    to perform a user task or data synchronization in real time [57]. In the IoT context,
    orchestration is concerned with the identification of which components or smart
    devices are needed to form the requested service [11]. An orchestrator can be
    any IoT device that is used to control the execution transparently to the user.
    The orchestrator sends a triggering event that checks the condition for carrying
    out an action using actuators [58]. The development of a service orchestrator
    requires a deep understanding of service semantics and decomposition of the service
    request [59]. 4) Adaption The IoT model converts objects from conventional to
    smart objects, to provide the end user with the functions and qualities of the
    system. IoT systems are rapidly changing, heterogeneous, highly dynamic, and subject
    to risk and failure. The corresponding system must therefore have the ability
    to adapt itself at runtime to receive the environment circumstances and transfer
    the existing business model into a new ecosystem [60]. The adaptation architecture
    for IoT systems is used for service diagnosis, application diagnosis and service
    fault recovery [61]. E. Security Security preservation is a crucial issue for
    heavily connected devices and spanned services in IoT environments [62]. Service
    provisioning in IoT orchestrates authentication, authorization, access control
    and data integrity, to provide secure and satisfactory services to users. This
    subsection elaborates the various trust and security levels that have been used
    in service management for IoT. 1) Authentication and Authorization The initial
    step for a smart device mission is bootstrapping, in which a smart device wakes
    up and wants to be connected to the ecosystem. The device must first undergo the
    authentication process before joining the system, to avoid malicious devices joining.
    If the authentication process is successfully completed, an authorization process,
    in which the smart device is granted the authorization level necessary to carry
    out a certain task or service according to predefined policies. Adopting a robust
    and fine-grained authorization mechanism is crucial to the WoT ecosystem, since
    smart devices can be discovered easily on the World Wide Web [63]. Most of the
    existing authentication solutions use a distributed authorization style, in which
    a back-end server performs complex jobs, requiring rich computing resources. There
    is typically a server located between the smart device (service provider) and
    the service requestor, and the service needs the ability to differentiate between
    the various requests sent by different entities, and to enforce the appropriate
    authentication decision [64]. 2) Access Control The concept of access control
    is adopted in IoT to protect front-end and back-end data and IoT services and
    resources by applying data access restrictions. The crucial factor is the method
    used to allow smart devices to grant access to a service requestor in an IoT ecosystem,
    where the source of threat can be a malicious device, unauthorized data exposure,
    or a range of attacks. WoT uses two approaches to enforce access control: the
    distributed approach and the centralized approach [65]. In the distributed approach,
    an access control server authenticates an IoT entity and grants it the appropriate
    access token, which allows access to the IoT resource according to the deployment
    policy, either permanently or for a specific time interval. In the centralized
    approach, all the requests pass via an access control server, which issues an
    authorization status and connects them with the right destination. 3) Data Integrity
    and Confidentiality Secure communication across the WoT is mandatory to preserve
    data integrity and confidentiality and to thwart attackers [66]. However, encryption
    solutions require computational capability and memory resources, which cannot
    be always offered by smart devices. Lightweight end-to-end encryption is established
    at either the transport layer or the applications layer. Data encryption at the
    transport layer enables secure communication in the WoT in the form of human-to-Thing
    and Thing-to-Thing communication. Application-based security concerns with direct
    interaction and datagram payload data, for instance via application proxies, which
    are utilized by several firewalls [67]. F. Applications This section discusses
    examples of IoT applications that rely on service management. Figure 4 shows four
    of these application domains, namely smart healthcare, smart commerce, smart cities,
    and smart agriculture. FIGURE 4. Service management domains for IoT. Show All
    1) Smart Healthcare Smart healthcare aims to meet the increasing demand arising
    from an aging populace with chronic diseases. A smart healthcare system has a
    sensing layer and service layer. The sensing layer is concerned with acquiring
    special kinds of health information via sensors and wearable devices [68], while
    the service layer offers an authentic healthcare service, for instance by processing
    patient data on health status such as glucose level, heart rate and blood type.
    Scalability provides the advantages of collecting, processing and analyzing a
    number of sources of data to obtain feedback, in order to understand the patients’
    fitness status and the effects of their clinical conditions. Moreover, it leads
    to the establishing of trust between medical doctors and patients [69]. 2) Smart
    Agriculture Smart agriculture, also known as precision agriculture, is an IoT
    application that relies on emerging digital farming technologies such as robots,
    drones and satellites. Climate changes play a vital role in agriculture sectors,
    which need to be monitored in terms of weather and the growth of plants and trees.
    Smart agriculture helps farmers to effectively manage their products and to interact
    with various stakeholders [70]. Smart agriculture applications enable farmers
    to monitor irrigation, and to measure the nitrogen, phosphorus, and potassium
    in liquid manure. Moreover, smart agriculture applications offer opportunities
    for interaction with other farmers via social networks services. However, security
    threats to smart agriculture services are increasing due to the impacts of global
    climate change, and farmers interconnected via social networking need to be trusted
    in terms of their product suggestions and decision making. 3) Smart Commerce The
    smart commerce revolution has moved beyond traditional e-commerce models by adding
    customer-centric, brand-centric, data-centric, and experience-driven models. Among
    the many IoT services, smart-commerce applications suits the best case for the
    IoT service. There are two different cases related to smart commerce applications
    [71]. In the first, when the user notices an advertisement for a product, clicking
    the ad and enquiring via their website will give information about the product
    details and provide an option to buy via smart marketing. Furthermore, the selected
    picture can show the nearest store and offer promotion and discount coupons. In
    the second case, a consumer’s smartphone is used to detect the customer’s movements
    in the supermarket via GPS. This real-time location information helps in analyzing
    the behavior pattern of the customer in the supermarket. In both cases, smart
    commerce applications are location-based, personalized and real-time. The main
    challenges are related to the integration of diverse services and seamless connections
    between different technologies. 4) Smart Cities A smart city is defined as “a
    city that engages its citizens and connects its infrastructure electronically”
    [72]. Modern and sophisticated sensors provide new opportunities to collect and
    efficiently use smart city data for urban planning, awareness, policy and decision
    making. Moreover, managing these data and creating smart services for urban areas
    requires trust and adoption by various stakeholders, including citizens [9]. Nevertheless,
    the number of security and privacy challenges from smart city applications are
    increasing tremendously, such as user privacy related to location, threats to
    user devices, the hijacking of smart city signals and ransomware attacks on energy
    management systems. SECTION VI. Recent Advances in Service Management for IoT
    This section critically investigates the existing service management solutions
    (models, frameworks and protocols). These solutions aim to cope with challenges
    associated with service provision, orchestration, composition and adaptation,
    as described in Table 5, and are discussed below. TABLE 5 Comparison of Recent
    Advances in Service Management for IoT A. Service Composition Min et al. [1] implemented
    the artificial bee colony algorithm for resource and QoS-aware service composition.
    The authors improved the solution by introducing an operator for resource checking,
    to ensure that the component services had sufficient resources to execute the
    task successfully. Resource checking depends on an analysis of the mutual relationships
    between resources and services. The researcher defined the features of services
    in different domains, and the implementation showed that the proposed method resulted
    in considerable improvement. However, the resource checking operator needed to
    be redesigned for flexible alignment with highly dynamic resources. The actual
    discovery of domain features and analysis of the impact of each feature on the
    optimization domain are required. Alsaryrah et al. [2] introduced a pulse algorithm
    to solve the shortest path optimization problem for a bi-objective optimal balance
    between energy consumption and QoS in service composition in an IoT environment.
    The authors deployed several smart objects and ran their algorithm to select the
    most suitable objects for service composition. The experimental results revealed
    that the proposed solution required less execution time for various service profiles,
    achieved considerable performance improvement in terms of energy consumption and
    network lifetime, and preserved an acceptable QoS. Huang et al. [3] introduced
    a framework for building smart applications based on intelligent edge computing.
    This solution pushes the computation process from the cloud server to the edge
    node, in order to provide reliable and timely data analytics in IoT applications.
    The proposed framework was implemented with a case study, and a performance comparison
    was then conducted between running it on an edge node vs. the cloud. The experimental
    results demonstrated that edge intelligence for IoT services effectively assists
    in building smart applications and provides situation-awareness and better response
    time. Mohammadi et al. [4] studied time wastage in the indoor environment of smart
    city services. The authors proposed a semi-supervised deep reinforcement learning
    model to satisfy the requirements of indoor localization in smart city applications.
    The accuracy of the learning agent was improved by setting smart applications
    to consume both labeled and unlabeled data. The model employed a vibrational auto-encoder
    as an inference engine to generate optimum policies. The author considered smart
    buildings as a case study, utilizing Bluetooth technology with low energy signal
    strength, and applied their model to the problem of indoor localization. The experimental
    results showed an improvement regarding the distance to the target, and better
    performance than deep reinforcement learning model. Sun et al. [6] introduced
    a two-tier framework to represent the functionalities of smart Things in an IoT
    service. The authors utilized heuristic algorithms to facilitate the coordination
    of Smart Things for service composition in scenarios where the task requirements
    span across multiple Things. The ant colony, genetic, and swarm algorithms were
    adopted as heuristic methods of finding the optimal service compositions. The
    experimental results showed that the adopted algorithms find the approximately
    optimal service composition while reducing the energy consumption and prolonging
    the network lifetime. B. Service Provisioning Han and Crespi [8] proposed an architecture
    to support service provisioning for smart objects, the architecture associated
    with the semantic annotation. The authors aim to enable the seamless integration
    of IoT applications with the web through setting smart objects as IP-based entities
    that can ensure low energy consumption and serve as an integral part of the online
    service. The researchers assessed their solution empirically using several prototypes
    and applications. The results demonstrated that the proposed architecture supports
    the integration of IoT applications on the Web. However, further testing on the
    different scenario of WoT is required to verify the efficiency of the proposed
    architecture. Khan et al. [9] proposed a service provisioning framework to ensure
    security and privacy during service provisioning in a smart city. This solution
    achieved its goal by overcoming the problems of service compromise, malicious
    citizens, and malicious service providers. The system meets several requirements
    of end-to-end service provisioning, such as trust-based data acquisition, secure
    processing, transmission, and preservation of service integrity with legitimate
    provisioning. The authors tested their framework in different scenarios of service
    provisioning for smart cities, and developed a lightweight communication protocol
    for verification purposes. The results proved the usefulness of the framework
    based on the individual components, but the robustness of this protocol not verified
    in a real smart city environment. C. Service Orchestration Viejo and Sánchez [11]
    proposed privacy-by-design protocols for service orchestration and delivery in
    fog-enabled IoT systems. Their solution secures data exchange in the network by
    employing attribute-based encryption in fog-based IoT, and ensures that the data
    necessary to satisfy the service are released only to the only entities involved,
    thus satisfying the data minimization principle. The proposed protocols run in
    any IoT architecture consist of fog nodes, sensing devices and the cloud. The
    experimental results showed that the proposed protocol was secure and feasible,
    although the protocol was not evaluated in a realistic, operational IoT environment.
    Wang et al. [12] introduced a linear programming model together with an optimization
    algorithm for a performance and resource-aware orchestration system. The proposed
    model was aimed at ensuring performance maximization while optimizing resource
    utilization in the IoT environment in the presence of large volumes of traffic.
    The authors built a prototype for implementing their solution on OpenStack, and
    the experimental results revealed that the proposed model obtained better performance
    than the existing solutions. D. Service Adaption Lee et al. [13], proposed a model
    for tackling the problem of unsatisfactory provisioning of smart IoT services.
    The solution introduced the service composition of two layers, namely the user
    control layer and the cloud control layer; the former is concerned with the management
    of service context awareness and end-to-end service connection, and the latter
    with the management of service profiling, resource allocation, service scheduling,
    and adaptation policies. The authors conducted experiments on a lightweight prototype.
    In the experimental results, the proposed model showed performance improvement
    in terms of throughput in comparison with the legacy binding approach. However,
    investigation and consideration of advanced issues such as mobility management
    are needed for the effective utilization of the proposed model. SECTION VII. Open
    Research Challenges Current service management approaches for IoT have the potential
    to provide numerous solutions, but many challenges have not yet been fully addressed
    and require collaboration from standardization committees, hardware manufacturers,
    software developers and IoT stakeholders. This section discusses several challenges
    related to service management in the context of IoT, as shown in Figure 5. FIGURE
    5. Service management challenges in IoT. Show All A. Interoperability-Related
    Challenges Service management in IoT encounters three types of interoperability
    challenges: connectivity, semantic and syntactic. 1) Connectivity Challenges These
    are concerned with enabling seamless integration and information exchange between
    IoT systems with diverse device capabilities, via different networking technologies,
    standards, communication protocols and platforms [73]. A lack of connectivity
    and interoperability leads to a limited ability to integrate diverse devices into
    the different service management platforms of IoT systems. 2) Semantic Challenges
    These are concerned with the ability of various IoT applications and services
    to interpret the exchanged data in a meaningful way [74]. A high level of semantic
    incompatibility between data and information models in IoT systems leads to different
    descriptions of resource and operational procedures, which results in failure
    of the system [75]. 3) Syntactic Challenges These are concerned with the data
    format and structure that is used in a service or information exchange between
    heterogeneous IoT entities and systems. Syntactic interoperability can be achieved
    by defining an interface for each IoT resource and exposing its metadata to the
    relevant entities. The challenge arises when the encoding rule used by the information
    sender is different from the decoding rule used by the receiver, which results
    in message mismatching. Tackling interoperability challenges in IoT requires cross-domain
    interoperability solutions. B. Scalability-Related Challenges Service management
    in IoT is expected to encounter several challenges related to vertical scalability
    and horizontal scalability. 1) Vertical Scalability Challenges These are related
    to the ability to support additions to enhance the capability of an IoT device
    and to updating of firmware and software applications running on sensing nodes
    and IoT gateways. The challenges are associated with the difficulty of keeping
    track of which updates are available, and consistently applying updates across
    a network containing heterogeneous components that communicate via a set of various
    protocols. 2) Horizontal Scalability Challenges These are concerned with the addition
    of new devices, software and services, which need scalable service registry and
    harmonic interaction. The horizontal scalability of service management systems
    in IoT is associated with many challenges related to networking protocols, security,
    privacy, fault tolerance, access control, trust and governance. The problem arises
    when the service management system fails to integrate a wide range of new IoT
    devices [76]. To accommodate rapid scalability in an IoT system, the service management
    system needs to achieve the performance improvement of IoT applications, in order
    to provide high QoS for a scaled-up version of the IoT system. C. Security-Related
    Challenges Conventional security solutions and practices cannot handle the expansion,
    mobility, resource constraints and new security requirements of IoT. The main
    type of trust and security challenges in IoT are identity management, authentication
    and authorization, and vulnerability detection. 1) Identity Management Challenges
    These involve a lack of ability to discover and manage the identities of IoT entities
    across the different integrated IoT-based applications to support authentication
    techniques [77]. 2) Authentication and Authorization These are crucial issues
    for ensuring the security of IoT systems in terms of supporting access control
    and preserving privacy and integrity. Authorization aims to determine which services,
    resources and apps each device can access in the system. The challenge arises
    when IoT devices fail to perform authentication due to weak password authentication
    or poor password management policies [78]. 3) Vulnerability Detection This is
    concerned with monitoring IoT activity logs for anomalies, engaging in penetration
    testing to expose vulnerabilities, and the identification and notification of
    security threats. Challenges arise that are related to high scalability in terms
    of the number and diversity of devices, apps, communication protocols and services,
    which makes it difficult to identify vulnerabilities. 4) Availability These are
    associated with maintaining the durability and accessibility of IoT services.
    Several inherited and emerging availability problems arise in IoT, such as device
    failure and dis-connectivity. The challenges are related to the protection of
    IoT entities against physical tampering and denial of service attacks. In the
    future, reliable and scalable security mechanisms, protocols, polices, practices
    are needed for IoT. Moreover, technologies are needed to provide advanced control
    of data exchanges among IoT entities. D. Big Data-Related Challenges Some IoT
    systems handle massive data at the cloud, device or IoT gateway level. In IoT,
    big data processing encounters several challenges related to accuracy, real-time
    analytics, and visualization [79]. 1) Accuracy Challenges A service management
    system is expected to provide an effective data analytics technique for extracting
    knowledge from the massive data generated by IoT entities. The challenge is to
    extract information from the heterogeneous and complex data generated by different
    IoT entities [80]. 2) Real-Time Analytics Challenges Many IoT applications require
    data extraction and processing in real time. Analyzing data in volumes measured
    in terabytes or petabytes in real time is associated with several challenges such
    as data integration and visualization. 3) Visualization Challenges Visualization
    is an auxiliary for big data analytics that involves dashboard and mobile apps.
    Seamless synchronization between visualization and the data analytics process
    allows the results of the analysis of IoT applications to be meaningful and understandable.
    The challenge is to generate a visual representation of highly heterogeneous big
    data. SECTION VIII. Conclusion IoT is the largest community in cyberspace, comprising
    billions of heterogeneous computation and communication devices, that is intended
    to provide a wide range of services. This environment needs careful device synchronization,
    proper scalability and interoperability management, service monitoring and QoS
    measurement. These tasks cannot be performed without an effective service management
    system, and this article therefore focuses on service management for IoT. First,
    we investigated the recent advances in the literature related to service management
    issues for IoT. We then determined the requirements of service management for
    IoT, and provided a thematic taxonomy. Next, we presented several opportunities
    related to service management in IoT, and identified open research challenges
    that can act as a guide for future research. Finally, we conclude that current
    service management solutions for IoT face challenging issues that must be addressed
    in the future. Authors Figures References Citations Keywords Metrics More Like
    This A Survey on Standards for Interoperability and Security in the Internet of
    Things IEEE Communications Surveys & Tutorials Published: 2021 Security Considerations
    in the Internet of Things Protocol Stack 2021 International Conference on Artificial
    Intelligence, Big Data, Computing and Data Communication Systems (icABCD) Published:
    2021 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/8600701/08874971.pdf
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: 'Service Management for IoT: Requirements, Taxonomy, Recent Advances and
    Open Research Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2022.3144137
  analysis: '>'
  authors:
  - Ishaani Priyadarshini
  - Biswaranjan Bhola
  - Raghvendra Kumar
  - Chakchai So-In
  citation_count: 7
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences Loading
    [MathJax]/extensions/MathMenu.js IEEE.org IEEE Xplore IEEE SA IEEE Spectrum More
    Sites Subscribe Donate Cart Create Account Personal Sign In Personal Sign In *
    Required *Email Address *Password Forgot Password? Sign In Don''t have a Personal
    Account? Create an IEEE Account now. Create Account Learn more about personalization
    features. IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09684387.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: A Novel Cloud Architecture for Internet of Space Things (IoST)
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1145/3356999.3365468
  analysis: '>'
  authors:
  - Ranga Raju Vatsavai
  - Bharathkumar Ramachandra
  - Zexi Chen
  - John A. Jernigan
  citation_count: 2
  full_citation: '>'
  full_text: ">\ngeoEdge: A Real-time Analytics Framework for Geospatial\nApplications\n\
    Ranga Raju Vatsavai∗\nNorth Carolina State University\nRaleigh, North Carolina\n\
    rrvatsav@ncsu.edu\nBharathkumar Ramachandra\nNorth Carolina State University\n\
    Raleigh, North Carolina\nbramach2@ncsu.edu\nZexi Chen\nNorth Carolina State University\n\
    Raleigh, North Carolina\nzchen22@ncsu.edu\nJohn Jernigan\nNorth Carolina State\
    \ University\nRaleigh, North Carolina\njajerni2@ncsu.edu\nABSTRACT\nIn many real-world\
    \ applications, data looses its value if its not\nanalyzed in real-time. Examples\
    \ include natural disasters, crop dis-\nease identification and bioterrorism,\
    \ traffic monitoring, monitoring\nhuman activities and public places, gas pipeline\
    \ monitoring for\nleaks. Edge computing refers to pushing computing power to the\n\
    edge of the network or bringing it closer to the sensors. We en-\nvision that\
    \ an integrated framework (sensors + edge computers\n+ analytics) allows near\
    \ realtime analytics at the edge, which is\ncritical for first responders to national\
    \ security agencies alike. In\naddition to the generation of real-time actionable\
    \ knowledge, edge\ncomputing allows compressing/reducing big geospatial data that\n\
    need to be transmitted to centralized cloud or data centers. In this\nstudy, we\
    \ present the vision behind geoEdge, and show feasibility\nresults using feature\
    \ extraction and unsupervised learning on an\nedge computing device.\nCCS CONCEPTS\n\
    • Computing methodologies → Distributed computing method-\nologies; Machine learning\
    \ algorithms; • Computer systems orga-\nnization → Embedded systems.\nKEYWORDS\n\
    real-time actionable knowledge, edge computing, remote sensing\nACM Reference\
    \ Format:\nRanga Raju Vatsavai, Bharathkumar Ramachandra, Zexi Chen, and John\
    \ \nJernigan. 2019. geoEdge: A Real-time Analytics Framework for Geospatial \n\
    Applications. In Proceedings of BigSpatial ’19. ACM, New York, NY, USA, \n4 pages.\
    \ https://doi.org/10.1145/3356999.3365468\n∗Corresponding Author; Affiliated with\
    \ the Center for Geospatial Analytics.\nPermission to make digital or hard copies\
    \ of all or part of this work for personal or \nclassroom use is granted without\
    \ fee provided that copies are not made or distributed \nfor profit or commercial\
    \ advantage and that copies bear this notice and the full citation \non the first\
    \ page. Copyrights for components of this work owned by others than ACM \nmust\
    \ be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\
    \ \nto post on servers or to redistribute to lists, requires prior specific permission\
    \ and/or a \nfee. Request permissions from permissions@acm.org.\nBigSpatial ’19,\
    \ November 5, 2019, Chicago, IL, USA\n© 2019 Association for Computing Machinery.\n\
    ACM ISBN 978-1-4503-6966-4/19/11. . . $15.00\nhttps://doi.org/10.1145/3356999.3365468\n\
    1\nINTRODUCTION\nA recent Computing Community Consortium (CCC) visioning activ-\n\
    ity defined spatial computing as a unifying field that “encompasses\nthe ideas,\
    \ solutions, tools, technologies, and systems that transform\nour lives by creating\
    \ a new understanding of locations – how we\nknow, communicate, and visualize\
    \ our relationship to locations and\nhow we navigate through them.” [9]. Advances\
    \ in sensor technolo-\ngies have greatly facilitated collection and archival of\
    \ big spatial and\ntemporal data, that lead to the centralized processing. Planet\
    \ Labs is\ncollecting about 9 PB/year and DigitalGlobe (Maxar) is collecting 36\n\
    PB/year of remote sensing data alone. In a recent study, IDC [4] pre-\ndicted\
    \ that the global data will grow from 33 Zettabytes in 2018 to\n175 Zettabytes\
    \ in 2025. Using commodity 8 TB disk drives, we need\nmore than 125 million hard\
    \ disks to hold a Zettabyte of data, making\noffline analytics infeasible without\
    \ employing smart data and edge\ncomputing technologies. In addition, there are\
    \ many real-world ap-\nplications, such as, natural disasters, crop disease identification\
    \ and\nbioterrorism, traffic monitoring, monitoring human activities and\npublic\
    \ places, gas pipeline monitoring for leaks, and autonomous\nvehicles, where real-time\
    \ extraction of knowledge from these data\nstreams becomes critical. We envision\
    \ that the edge computing\nframeworks that bring computing closer to the sensors\
    \ (e.g., UAVs)\nis very relevant for the spatial computing community. Figure 1\n\
    shows an example architecture of spatiotemporal edge computing.\nThis figure also\
    \ shows the distinction between traditional off-line\n(backend) analytics and\
    \ online (near) real-time analytics.\n1.1\nWhy Now?\nWe see two key technology\
    \ innovations that is driving this new vi-\nsion. First, we observe that edge\
    \ computing is not a new technology.\nThough ideas were in development for sometime,\
    \ due to limited\ncomputing capabilities and power requirements, deploying com-\n\
    puting closer to the field sensors was prohibitive. Second, unlike\ntraditional\
    \ sensors, the data generated by modern remote sensing\nsensors (e.g., UAV based)\
    \ and in-situ sensors (e.g., optical soil mois-\nture sensors) poses problems\
    \ in terms of data transmission and\nstorage. However, with recent advances in\
    \ computing, especially\nembedded supercomputing chips (e.g., Nvidia’s Jetson\
    \ TX-1, TX-2,\nNano), tiny yet powerful edge computers (e.g., Lenovo’s P330 Tiny),\n\
    and high-end edge workstations (e.g., Nvidia’s EGX), spatiotem-\nporal edge computing\
    \ at the edge can be feasible and impactful.\nBigSpatial ’19, November 5, 2019,\
    \ Chicago, IL, USA\nVatsavai, Ramachandra, Chen, Jernigan\nAs per Gartner, “91%\
    \ of today’s data is created and processed in\ncentralized data centers. However,\
    \ by 2022 about 75% of all data\nwill need analysis and action at the edge.” We\
    \ now briefly describe\nthe enabling technologies behind this vision and showcase\
    \ few im-\nportant applications, and argue why spatial computing community\nshould\
    \ pay attention to this emerging theme.\nFigure 1: Traditional Offline Analytics\
    \ Vs. Edge Based Near\nReal-time Analytics\n2\nTHE RISE OF THE SENSORS\nGartner\
    \ estimates that there will be 25 billion things connected to\nthe Internet by\
    \ 20201. These sensors (or things) range from sim-\nple temperature sensors to\
    \ complex ultrasound sensors. They are\nplaced at fixed locations, or on moving\
    \ platforms, or on remote\nplatforms like traditional satellites to recent UAVs.\
    \ Most of these\nsensors are connected to the Internet to transmit data to centralized\n\
    facilities, including traditional data centers or modern cloud storage.\nIn particular,\
    \ we are interested in multi-spectral and hyper-spectral\nsensors mounted on UAVs\
    \ which allows us to monitor natural re-\nsources and critical infrastructures\
    \ (e.g., crops, waters, forest, cities,\nnuclear facilities). One major limitation\
    \ with current centralized\nstorage and offline data processing is that this infrastructure\
    \ can\nneither support nor scale well for near realtime applications. A large\n\
    portion of the data generated from these sensors is spatiotemporal\nin nature.\
    \ Spatiotemporal data is often big, therefore it make sense\nto process this data\
    \ close to where it is being generated, which\nmakes case for edge computing.\n\
    3\nTHE RISE OF EDGE COMPUTING\nThe need for edge computing is evident from recent\
    \ report “IDC\nFutureScape: Worldwide Internet of Things 2017 Predictions.” As\n\
    per this report, “By 2019, at Least 40% of IoT-Created Data Will Be\nStored, Processed,\
    \ Analyzed, and Acted Upon Close to, or at the\nEdge of, the Network.” There are\
    \ two key requirements for edge\ncomputing to be successful, (i) computing devices\
    \ with low energy\nrequirements, and (ii) highly scalable streaming analytics\
    \ platforms.\n1http://www.gartner.com/technology/research/internet-of-things/\n\
    4\nTHE RISE OF THE LOW ENERGY HIGH\nPERFORMANCE COMPUTING (AKA\nEMBEDDED SUPERCOMPUTING)\n\
    The power and efficiency of GPUs has increased drastically in\nthe past decade\
    \ [8] along with ever-cheaper and faster storage.\nOnly 20 years ago, the fastest\
    \ computer in the world achieved a\nperformance metric of 1 teraFLOP [10] with\
    \ energy consumption\nof 850,000 watts. The current NVIDIA Jetson TX1 platform\
    \ can\nachieve the same performance metric at under 15 watts, and weighs\n88 grams.\
    \ The progress is absolutely astonishing. We effectively can\nput supercomputers\
    \ in UAVs, but the algorithms and software have\nnot kept pace. Fortunately, we\
    \ are increasingly seeing algorithms\nadapted for streaming GPU-processed workflows.\n\
    5\nTHE RISE REAL TIME SPATIOTEMPORAL\nAPPLICATIONS\nWe now describe two real world\
    \ applications making the case for\nspatiotemporal edge computing. More comprehensive\
    \ with geospa-\ntial big data, applications, and analytics can be found in [1,\
    \ 3, 11, 12]\nTowards UAV-based GPU-accelerated Remote Sensing: In aerial\nremote\
    \ sensing, such as with unmanned aerial vehicles, edge com-\nputing with embedded\
    \ GPUs can leverage immense computational\npower and efficiency [8] to provide\
    \ actionable insight in the food-\nenergy-water (FEW) nexus. NSF and several other\
    \ federal agencies\nare considering FEW 2 to be next big research thrust in the\
    \ USA.\nFood, energy, and water are essential for human wellbeing. Agri-\nculture\
    \ accounts for 70% of total freshwater withdrawals. About\nthe 30% of global energy\
    \ is consumed in food production. Figure 2\nshows simple interaction between these\
    \ three systems, where en-\nergy being is used to pump water for crops. In this\
    \ context, spa-\ntiotemporal edge computing can be used to analyze data from UAVs\n\
    to estimate in near real-time the soil moisture and crop water stress\nat field\
    \ scale which allows farmers to schedule irrigation more\noptimally.\nFigure 2:\
    \ Image shows nexus between food, energy, and wa-\nter systems\n2https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=505241\n\
    geoEdge: A Real-time Analytics Framework for Geospatial Applications\nBigSpatial\
    \ ’19, November 5, 2019, Chicago, IL, USA\nFarmers and agricultural producers\
    \ cannot wait very long for\nremote sensing data to process in the cloud when\
    \ an immediate\ndecision must be reached regarding water application to a crop\
    \ field,\nor how much fertilizer to use (and where to apply it) to address\nnutrient\
    \ deficiency. In search and rescue operations, the immedi-\nacy of data processing\
    \ is obvious. Embedded supercomputers (or\nGPUs) can greatly assist with remote\
    \ sensing algorithms due to the\ninherent multidimensionality of the image data\
    \ and the processors’\nhighly parallel computational architecture [5] [8]. The\
    \ effect would\nbe to expedite the remaining processing, if not obviate some offline\n\
    processing outright. The following are some example cases:\n(1) Batch-to-stream\
    \ workflows: In some cases, what has been\nan offline batch process like orthorectification\
    \ of remote\nsensing images (image stitching) can happen in real time if\nhardware\
    \ can leverage efficient parallel processing [2] [13].\n(2) Anomaly detection:\
    \ traditional streaming adaptations such\nas using a sliding window on real time\
    \ data can allow for\nstreaming anomaly detection with GPU acceleration and\n\
    modified algorithms [13]. Rapidly processed anomaly detec-\ntion could be of great\
    \ benefit when assessing crop damage\ndue to extreme weather events such as floods\
    \ or large hail.\n(3) Image classification: Multispectral or hyperspectral imagery\n\
    can allow detection of crop pestilence or disease using meth-\nods such as support\
    \ vector machines [7].\n(4) Hyperspectral signature classification: Water contamination\n\
    could be detected from hyperspectral data by flying UAVs\nalong waterways. On-board\
    \ processing for certain signatures\nand thresholds could trigger a flight reassignment\
    \ to gather\nhigher resolution imagery in suspected areas for offline pro-\ncessing.\
    \ This approach could lead to more regular monitoring\nof waterways for threats\
    \ to healthcare, agriculture, and the\necosystem.\n(5) Data compression and summarization:\
    \ Data compression\nand summarization (e.g., clustering) are efficient techniques\n\
    to reduce data storage and transmission costs. As these are\nunsupervised techniques,\
    \ it is easy to implement these al-\ngorithm on edge computers and compress images\
    \ on the\nfly.\nFigure 3 shows an use case of near real-time detection of weeds\n\
    using the spatiotemporal edge computing framework. Such real-\ntime detection\
    \ of weeds and crop diseases will allow timely action\nby the farmer before its\
    \ too late.\nAnomaly Detection in Video Streams: Anomaly detection in\nvideo streams\
    \ have several security applications. For example, one\ncould monitor video streams\
    \ at airports and other public places to\nidentify unattended bags or other objects.\
    \ We recently developed a\nprobabilistic anomaly detection framework (KDD-17 under\
    \ review).\nWe ran this algorithm on a video dataset “Peds1” [6] consisting\n\
    of natural images of a pedestrian walkway. Given that we model\nvariation in local\
    \ spatio-temporal neighborhoods, we would expect\nthe method to behave similar\
    \ to a 3D feature (optical flow) detector.\nAnomalous events could be abnormal\
    \ motion patterns or high\namount of variation in pixel values that lasts for\
    \ a short amount of\ntime. Figure 4 shows the result of applying our anomaly detection\n\
    method to a video dataset. (a) represents the frame on which we\nFigure 3: Near\
    \ real-time weed detection while the data still\nbeing collected by UAVs\nqueried\
    \ for anomalies with respect to the rest of the video. Darker\nregions in (b)\
    \ represent low cumulative chi-squared scores and thus\nlow deviation and whiter\
    \ regions represent high deviation from\nnormality (e.g., person on bicycle on\
    \ a pedestrian pathway). Finding\nsuch anomalous patterns in realtime is highly\
    \ useful.\nFigure 4: Anomalous events detected for a frame of a video\nof a pedestrian\
    \ walkway\n6\nFEASIBILITY STUDIES\nTo study the feasibility of running complex\
    \ models on the edge,\nwe started with benchmarking the running times for widely\
    \ used\nunsupervised approaches such as feature extraction (e.g., vegetation\n\
    indices) and data summarization (e.g., clustering) methods. We used\nLenovo ThinkStation\
    \ P320 Tiny edge computer equipped with an\nNvidia Quadro P600 GPU for these experiments.\n\
    BigSpatial ’19, November 5, 2019, Chicago, IL, USA\nVatsavai, Ramachandra, Chen,\
    \ Jernigan\nFigure 5\nExperiment details: For these experiments we considered\
    \ (i)\nNormalized Difference Vegetation Index, (NDVI) (ii) Enhanced Veg-\netation\
    \ Index (EVI), (iii) Standardized Vegetation Index (SVI), (iv)\nK-means clustering\
    \ and (v) Gaussian Mixture Model (GMM) cluster-\ning. For the clustering experiments,\
    \ a 10% sample of input pixels is\nused to build the clustering model (with 10\
    \ clusters) and every pixel\nis classified with this model. K-means clustering\
    \ used the smaller of\n1000 iterations or a difference of 1e-2 on root mean squared\
    \ error\nas the stopping criterion. GMM clustering used the smaller of 1000\n\
    iterations or a difference of 1e-8 on total log likelihood between\nsuccessive\
    \ iterations as the stopping criterion. To implement these\nfunctions we used\
    \ python3 with the pytorch GPU acceleration\nlibrary.\nFor image input, we synthetically\
    \ generate an image by picking\nvalues in [0, 255] from a uniform distribution.\
    \ We ran each of of\nthese functions 1000 times and compute the average runtime\
    \ per\nfunction call to summarize scalability.\nResults: Figure 5 shows how the\
    \ runtime scaling as function\nof image size. Since SVI, NDVI and EVI use 1, 2\
    \ and 3 bands to\nperform their computation and the data transfer to GPU memory\n\
    is the most expensive piece, we see this trend reflected in their\nruntimes. We\
    \ see that with even slightly more complex tasks such\nas K-means clustering or\
    \ GMM clustering, the runtime per call\nquickly approaches 100 ms, and depending\
    \ on the frequency of\ninput images, may not meet a real-time processing requirement\
    \ on\nthe edge for large image sizes (I/O bound) and compute intensive\ntasks.\
    \ Moreover, when the image size is too large (2048 x 2048),\neven a single image\
    \ is too large to fit into GPU memory, throwing\nan OutOfMemory error. We are\
    \ also working on parallelizing these\nalgorithms on the Jetson TX-1/2 cards.\
    \ We are also working with our\nUAS collaborators to integrate Jetson TX-1 for\
    \ onboard processing\nof image streams.\n7\nCONCLUSIONS AND FUTURE RESEARCH\n\
    DIRECTIONS\nNow we have all ingredients required to enable spatiotemporal\ncomputing\
    \ at the edge. If we suppose that a large problem in the\nfood-energy-water nexus\
    \ is inefficient agricultural resource use\nand a solution is advanced decision\
    \ support, then a missing link\nin the chain between the two is a suite of algorithms\
    \ and software\nto take advantage of edge-based supercomputing with efficient\n\
    GPU (and hybrid GPU-CPU) systems such as the NVIDIA Jetson\nseries, or even FPGA-CPU\
    \ hybrids embed on UAVs. To conclude,\nwe should state that for effective computation\
    \ at the edge and\nachieving real-time performance with more complex tasks, the\
    \ data\ntransfer between CPU RAM and GPU DRAM should happen as\nthe computation\
    \ is being performed, asynchronously. Other factors\nsuch as size of GPU memory\
    \ and optimizing computations should\nalso be given a careful thought.\nIn order\
    \ for edge-based spatial computing to have an impact\non real-world problems,\
    \ experts from multiple disciplines must\ncollaborate to identify and develop\
    \ right solutions. We believe that\nthe time is ripe to form a community around\
    \ the topic of geospatial\nedge computing and attack major challenges of spatiotemporal\n\
    edge computing.\n8\nACKNOWLEDGEMENTS\nWe would like to thank our collaborators,\
    \ Rada Chirkova, and STAC\nlab members at NCSU, and Jaime E. Puente, Cassidy Lammers\
    \ and\nMike Leach at Lenovo. We greatly appreciate the research funding\nprovided\
    \ by the NSF funded IUCRC Center for Accelerated Real\nTime Analytics (CARTA)\
    \ and Lenovo for donating ThinkStation\nP320 Tiny edge computer.\nREFERENCES\n\
    [1] Budhendra L. Bhaduri, Dilip R. Patlolla, Ranga Raju Vatsavai, Anil M. Cheriyadat,\n\
    Wei Lu, and Rajasekar Karthik. 2014. Emerging trends in monitoring landscapes\n\
    and energy infrastructures with big spatial data. SIGSPATIAL Special 6, 3 (2014),\n\
    35–45.\n[2] Dai Chenguang and Yang Jingyu. 2011. Research on orthorectification\
    \ of remote\nsensing images using GPU-CPU cooperative processing. In Image and\
    \ Data Fusion\n(ISIDF), 2011 International Symposium on. IEEE, 1–4.\n[3] Arie\
    \ Croitoru, rew Crooks, Jacek Radzikowski, Anthony Stefanidis, Ranga Raju\nVatsavai,\
    \ and N. Wayant. 2014. Geoinformatics and Social Media: New Big Data\nChallenge.\n\
    [4] John Rydning David Reinsel, John Gantz. The Digitization of the World, From\n\
    Edge to Core. https://www.seagate.com/files/www-content/our-story/trends/\nfiles/idc-seagate-dataage-whitepaper.pdf.\
    \ (????). [Online].\n[5] Yan Ma, Lajiao Chen, Peng Liu, and Ke Lu. 2016. Parallel\
    \ programing tem-\nplates for remote sensing image processing on GPU architectures:\
    \ design and\nimplementation. Computing 98, 1-2 (2016), 7–33.\n[6] V. Mahadevan,\
    \ W. Li, V. Bhalodia, and N. Vasconcelos. 2010. Anomaly detection\nin crowded\
    \ scenes. In 2010 IEEE Computer Society Conference on Computer Vision\nand Pattern\
    \ Recognition. 1975–1981. https://doi.org/10.1109/CVPR.2010.5539872\n[7] T Rumpf,\
    \ A-K Mahlein, U Steiner, E-C Oerke, H-W Dehne, and L Plümer. 2010.\nEarly detection\
    \ and classification of plant diseases with support vector machines\nbased on\
    \ hyperspectral reflectance. Computers and Electronics in Agriculture 74,\n1 (2010),\
    \ 91–99.\n[8] Javier Setoain, Manuel Prieto, Christian Tenllado, and Francisco\
    \ Tirado. 2008.\nGPU for parallel on-board hyperspectral image processing. The\
    \ International\nJournal of High Performance Computing Applications 22, 4 (2008),\
    \ 424–437.\n[9] Shashi Shekhar, Steven K. Feiner, and Walid G. Aref. 2015. Spatial\
    \ Computing.\nCommun. ACM 59, 1 (Dec. 2015), 72–81. https://doi.org/10.1145/2756547\n\
    [10] Joel O Stevenson, Robert A Ballance, Karen Haskell, John P Noe, Dennis C\
    \ Dinge,\nThomas A Gardiner, and Michael E Davis. 2008. 7X Performance Results–Final\n\
    Report: ASCI Red vs. Red Storm. Technical Report. Sandia National Laboratories\n\
    (SNL-NM), Albuquerque, NM (United States).\n[11] Ranga Raju Vatsavai and Varun\
    \ Chandola. 2016. Guest editorial: big spatial data.\nGeoInformatica 20, 4 (2016),\
    \ 797–799. https://doi.org/10.1007/s10707-016-0269-7\n[12] Ranga Raju Vatsavai,\
    \ Auroop R. Ganguly, Varun Chandola, Anthony Stefanidis,\nScott Klasky, and Shashi\
    \ Shekhar. 2012. Spatiotemporal data mining in the\nera of big spatial data: algorithms\
    \ and applications. In Proceedings of the 1st\nACM SIGSPATIAL International Workshop\
    \ on Analytics for Big Geospatial Data,\nBigSpatial@SIGSPATIAL 2012, Redondo Beach,\
    \ CA, USA, November 6, 2012. 1–10.\n[13] Yuanfeng Wu, Lianru Gao, Bing Zhang,\
    \ Bin Yang, and Zhengchao Chen. 2015.\nEmbedded GPU implementation of anomaly\
    \ detection for hyperspectral images.\nIn SPIE Remote Sensing. International Society\
    \ for Optics and Photonics, 964608–\n964608.\n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://dl.acm.org/doi/pdf/10.1145/3356999.3365468
  publication_year: 2019
  relevance_score1: 0
  relevance_score2: 0
  title: geoEdge
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3389/friot.2022.1073780
  analysis: '>'
  authors:
  - Khalid Elgazzar
  - Haytham Khalil
  - Taghreed Alghamdi
  - A. Badr
  - Ghadeer Abdelkader
  - Abdelrahman Elewah
  - Rajkumar Buyya
  citation_count: 12
  full_citation: '>'
  full_text: '>

    Revisiting the internet of things:

    New trends, opportunities and

    grand challenges

    Khalid Elgazzar1*, Haytham Khalil1, Taghreed Alghamdi1,

    Ahmed Badr1, Ghadeer Abdelkader 1, Abdelrahman Elewah1 and

    Rajkumar Buyya2

    1IoT Research Lab, ECSE, Ontario Tech University, Oshawa, ON, Canada, 2Cloud Computing
    and

    Distributed Systems (CLOUDS) Laboratory, School of Computing and Information Systems,
    University

    of Melbourne, Parkville, VIC, Australia

    KEYWORDS

    internet of things, IoT challenges, IoT new trends, IoT applications, IoT grand
    vision

    1 Introduction

    The Internet of Things (IoT) is a conceptual paradigm that connects billions of

    Internet-enabled devices to exchange data among themselves and their surroundings
    to

    enable smart interactions and connect the physical infrastructure to digital systems.
    IoT

    represents a revolutionary paradigm that started to affect our lives in many positive
    ways.

    The term Internet of Things was ﬁrst coined in 1999 by Kevien Ashton (Ashton,
    2009)

    and was initially designed to support RFID technology. However, nowadays IoT has

    reached far beyond its designers’ vision and become much popular for the new

    applications

    it

    opens

    up

    in

    many

    vital

    domains

    like

    healthcare,

    intelligent

    transportation,

    public

    safety,

    home

    automation,

    smart

    city,

    asset

    monitoring,

    industrial automation and much more. The evolution of IoT presented the long-

    awaited promise of ubiquitous data access in which people wanted to have access
    to

    real-time data on the go anywhere and anytime.

    Even though there are many other relevant paradigms/model that intersect with
    the

    purpose of IoT (e.g., M2M: Machine to Machine), Web of Things, Internet of Everything

    (IoE), pervasive computing, etc.), there are fundamental differences between them
    and

    IoT. The core values of IoT lies in the promise of helping businesses to increase
    their

    productivity, enhance control over their assets, and make informed business decisions

    based on the inference resulting from the processing of the fusion of big raw
    data acquired

    from the surroundings, including people themselves. Recent research statistics
    reveal over

    10 billion connected IoT devices in 2021. This number is anticipated to reach
    41 billion in

    2027, expecting over 152,000 IoT devices to connect to the Internet per minute
    in 2025.

    Considering the global IoT market size, there was a 22% increase in the market
    size of IoT

    in 2021, hitting $157.9 billion. Smart home devices are the dominant components
    of IoT.

    The penetration rate of IoT varies concerning the application domain. For example,
    IoT

    analytics (Lueth, 2020) argues that industrial applications occupy 22% of the
    global IoT

    projects, with transportation, energy, and healthcare occupying 15%, 14%, and
    9%,

    respectively.

    The main two types of devices that make up the most of IoT are: Sensors and

    Actuators. Sensors are physical devices that can sense/measure a certain phenomena
    and

    OPEN ACCESS

    EDITED AND REVIEWED BY

    Deze Zeng,

    China University of Geosciences

    Wuhan, China

    *CORRESPONDENCE

    Khalid Elgazzar,

    khalid.elgazzar@ontariotechu.ca

    RECEIVED 18 October 2022

    ACCEPTED 07 November 2022

    PUBLISHED 21 November 2022

    CITATION

    Elgazzar K, Khalil H, Alghamdi T, Badr A,

    Abdelkader G, Elewah A and Buyya R

    (2022), Revisiting the internet of things:

    New trends, opportunities and

    grand challenges.

    Front. Internet. Things 1:1073780.

    doi: 10.3389/friot.2022.1073780

    COPYRIGHT

    © 2022 Elgazzar, Khalil, Alghamdi, Badr,

    Abdelkader, Elewah and Buyya. This is

    an open-access article distributed

    under the terms of the Creative

    Commons Attribution License (CC BY).

    The use, distribution or reproduction in

    other forums is permitted, provided the

    original author(s) and the copyright

    owner(s) are credited and that the

    original publication in this journal is

    cited, in accordance with accepted

    academic practice. No use, distribution

    or reproduction is permitted which does

    not comply with these terms.

    Frontiers in The Internet of Things

    frontiersin.org

    01

    TYPE Field Grand Challenge

    PUBLISHED 21 November 2022

    DOI 10.3389/friot.2022.1073780

    can communicate the sensed values to other parties (i.e., collect

    data and report internal states). A GPS and an ECG device are

    examples of IoT sensors. The constituent sensor nodes usually

    utilize small-scale embedded systems to achieve the cost-

    effectiveness

    criteria

    of

    IoT

    solutions,

    increasing

    their

    deployment in various domains. Sensor nodes often use 8-bit

    microcontrollers and inhibit small storage capacity, lowering

    their power sizing and allowing them to run for years on

    batteries. Coupled with the diversiﬁed networking protocols

    available

    to

    match

    the

    existing

    infrastructure

    or

    the

    operational conditions, this highly promotes the deployment

    of IoT solutions in different domains. Actuators are also

    physical devices that can affect a change on the physical

    environments (i.e., take actions) in response to a command or

    a recommendation such as an AC thermostat and a valve. These

    devices need to be connected to the Internet and are able to

    communicate to send or receive data so they can qualify as IoT

    devices.

    The convergence of IoT, advanced data analytics and artiﬁcial

    intelligence opened up the door for the next generation of

    applications that support real-time decision making such as

    improved user experience and predictive maintenance. As such,

    data analytics has become a core component of any IoT

    deployment and will continue to gain popularity and relevance

    to businesses as much as data collection continues to grow and

    support intelligent decision making. In industrial manufacturing,

    for

    example,

    predictive

    maintenance

    can

    predict

    when

    maintenance is required in advance through the measurement

    of vibration levels, heat and other parameters to avoid production

    disruption. IoT data can also reveal rich information about

    customer

    behaviors

    (e.g.,

    driving

    habits

    and

    shopping

    preferences)

    to

    support

    improved

    customer

    experience.

    Machine learning models and artiﬁcial intelligence techniques

    can

    learn

    from

    observations

    (IoT

    data

    collection)

    and

    recommend actions that lead into smart decisions (IoT actuation).

    Although IoT promises to support intelligence decision

    making, enable better quality of life to citizens and make

    transformative changes in their daily lives, there remain grand

    challenges that hinder IoT from reaching its full potential such as

    privacy and security concerns, data heterogeneity and device

    interoperability, unrestricted access control and deployment in

    the open access domain. The heterogeneity and small footprint of

    IoT of sensors for example, comes with two major shortcomings:

    1) The constraints of resources available on the sensor nodes

    render

    it

    infeasible

    to

    apply

    the

    conventional

    security

    mechanisms typically involved in capable computer systems,

    exposing the sensor nodes as a weak security point for the

    whole

    IoT

    system.

    2)

    The

    many

    networking

    protocols

    available to communicate sensed information among IoT

    devices result in interoperability issues between IoT systems

    utilizing different communication protocols.

    The ﬁrst shortcoming of incapable sensor nodes results in the

    notorious “vertical silos,” where an IoT system is, in fact, a set of

    subsystems that lack information sharing among each other.

    That did not represent a signiﬁcant concern at the early ages of

    IoT since the applications were relatively limited, and the IoT had

    not reached its maturity and big vision yet. However, the advent

    of cloud computing in the last decade, coupled with the

    advancements in artiﬁcial intelligence and its subdomains, has

    vowed the prospect of IoT in various domains. This necessitates

    the ability of collaborative IoT systems to build better-informed

    business decisions based on the fusion of inferences coming from

    multiple systems. However, the second shortcoming of IoT

    impedes the scalability of IoT systems, conﬁning the usability

    of sensed information by IoT systems to the managed networks

    of their users without exposing this information to public

    networks. This comes at the cost of increased IoT systems

    outlay, unwanted redundancy of the same information sensed

    by non-interoperable systems, expanded storage footprint, high

    network bandwidth utilization, risen processing cost, and more

    elevated system latency. This paper provides deep analytical

    views on many aspects of IoT technologies including standard

    architecture, stack protocols, value proposition, different IoT

    applications, trending technologies, and challenges.

    The rest of the paper is structured as follows. Section 2

    discusses the IoT standard architecture, enabling technologies

    and stack protocols. Section 3 describes the different domains of

    application for IoT with the most prevailing deployments.

    Section 4 sheds the light on rising trends in IoT and the

    convergence

    between

    IoT

    and

    data

    analytics.

    Section

    5

    discusses the grand challenges for IoT that remain open for

    further research and deemed to decelerate its wide scale adoption.

    Lastly, Section 6 offers concluding remarks.

    2 IoT standard layered architecture

    and protocols

    From the engineering perspective, IoT is witnessing an

    increasing number of enabling technologies. This high diversity

    of IoT enabling technologies stem from the proliferation of IoT

    devices, their heterogeneity and uncertainty of operational

    environments, the advancements in chip manufacturing, and

    variety of communication protocols (Bouguettaya et al., 2021).

    Nonetheless, the advent of artiﬁcial intelligence (AI) and associated

    machine learning (ML) techniques leverage the serendipity of IoT

    by providing insightful information from the fusion of raw data

    collected by heterogeneous sensors to support decision making

    and change how people carry out their everyday business. This

    adds up to the enabling technologies of IoT. Therefore, abstracting

    IoT systems in terms of building blocks helps to contrast the hazy

    boundaries between different enabling technologies and enhance

    the agility and robustness to achieve a successful paradigm for IoT

    systems (Lin et al., 2017). The core elements of a typical layered

    IoT architecture, as depicted on Figure 1, can be summarized as

    follows.

    Frontiers in The Internet of Things

    frontiersin.org

    02

    Elgazzar et al.

    10.3389/friot.2022.1073780

    2.1 Perception layer

    The ﬁrst layer of the IoT architecture is the perception layer,

    also denoted by the hardware, physical, or infrastructure layer.

    This layer encompasses the constituent physical devices of an IoT

    system that are typically responsible for: 1) sensing the

    environment in their vicinity and sending the raw sensed data

    to the next upper layer for processing, such as environmental

    sensors; 2) transforming the logical decisions coming from the

    upper

    inference

    layer

    into

    physical

    actions

    applied

    to

    corresponding devices, such as actuators and servo motors. It

    is worth noting that, and as the name of IoT implies, the

    constituent devices that form an IoT system embed some

    form of communication by which they can be directly or

    indirectly, with the help of a gateway, connected to the

    Internet. Moreover, IoT devices typically include some form

    of identiﬁcation that helps differentiate the data passed to the

    upper layers of the IoT architecture. This identiﬁcation can be

    either burnt into the device ﬁrmware by the manufacturer [such

    as the unique identiﬁer (UUID)], set up by the user through

    conﬁgurable menus or DIP switches, or provided by the

    communication subsystem that the devices utilize (like the

    MAC address or the Bluetooth identiﬁer).

    2.2 Transport layer

    The transport layer, also denoted by the communication and

    network layer, and as its name implies, is responsible for

    connecting IoT devices in the perception layer to the upper

    layers of the IoT architecture, which are typically hosted over the

    Internet using cloud computing technologies. This layer utilizes a

    wide range of communication technologies, like cellular, Wi-Fi,

    Bluetooth, Zigbee, etc. Besides, the transport layer is responsible

    for maintaining the conﬁdentiality of the data exchange between

    the perception layer and the upper layers. Nonetheless, with its

    potential promise and anticipated ubiquity and prevalence, IoT is

    the motivating force behind recent research in enabling

    communication technologies. For example, IPv6 has been

    identiﬁed such that it can provide network addresses to the

    anticipated enormous smart objects connected to the Internet,

    which exceeds the already depleted IPv4 addresses. Similarly, the

    6LoWPAN communication standard has been mainly developed

    to enable IPv6 packet transmission for power-constrained smart

    objects communicating over IEEE 802.15.4.

    The transport layer securities typically used for IP-based

    networking, namely Transport Layer Security (TLS) and

    Datagram TLS (DTLS), provide the essential means for secure

    end-to-end communication. However, these technologies are not

    always

    feasible

    for

    deployment

    in

    resource-constrained

    embedded

    IoT

    devices

    due

    to

    the

    induced

    increased

    processing,

    storage,

    and

    power

    consumption

    overhead

    associated with these security mechanisms. This, in turn,

    usually delegates the authentication and the data integrity

    tasks

    of

    exchanged

    information

    in

    IoT

    systems

    to

    be

    arbitrarily carried out by the application layer based on the

    required security level and device capabilities. Besides, it

    exposes these poorly-secured IoT devices as a weak point for

    FIGURE 1

    IoT layered architecture.

    Frontiers in The Internet of Things

    frontiersin.org

    03

    Elgazzar et al.

    10.3389/friot.2022.1073780

    malicious users to penetrate the underlying critical network

    infrastructure or exploit them for botnet attacks to prevent

    the availability of network resources, aka distributed denial of

    service (DDoS). Derived by the proliferation of IoT devices,

    recent

    statistics

    anticipate

    that

    more

    than

    %25

    of

    all

    cyberattacks against businesses will be IoT-based by 2025.

    This slows down the adoption of IoT and makes businesses

    reluctant to expose the reachability of sensed information by

    their IoT systems beyond their managed networks, adding up to

    the “isolated islands” dilemma of IoT systems.

    2.3 Processing layer

    The processing layer, also denoted as the middleware layer,

    encompasses advanced features that could not be embedded within

    the inherently resource-constrained devices at the perception layer.

    This includes storage, processing, computing, and action-taking

    capabilities. Besides, the middleware layer facilitates IoT systems’

    scalability and interoperability across the computing continuum

    from the edge to a remote cloud data centre. It typically provides

    interfaces, like APIs, for other systems and third-party services to

    leverage the gathered raw data from the IoT devices or the insight

    obtained by the middleware layer after data processing. Based on the

    agreed tradeoff between device loads and bandwidth during the

    system design phase, the middleware layer can be either embedded

    within an on-site capable embedded platform, sometimes denoted as

    an IoT gateway, or hosted over the cloud. The former requires

    utilizing a medium-to-large scale embedded device to act as a

    gateway. Nonetheless, it typically utilizes a Linux kernel-based OS

    to mask the complexity of the underlying hardware interfacing to the

    perception layer devices. The latter, however, depends on relaying

    the raw data from the perception layer to cloud-hosted servers. This

    comes at the cost of higher bandwidth utilization and increased

    latency.

    The emergence of a cloud-hosted middleware layer for IoT

    systems represents a bottleneck considering the security concerns of

    IoT. Cloud computing is the only candidate to digest the enormous

    amount of IoT data coming from perception layer devices. However,

    cloud providers are also principal targets for cyberattacks and single

    points of failure for IoT systems. A successful cyberattack could

    expose an enormous amount of sensitive information to hackers and

    render the IoT system unfunctional. This puts system designers in a

    tradeoff of choosing between the capability, cost-effectiveness, and

    ease of access associated with cloud computing technologies on one

    hand and the panic of potential data leakage in case of a successful

    cloud attack on the other hand.

    2.4 Application layer

    The application layer deﬁnes the domains by which IoT

    systems are deployed. This includes smart homes, smart cities,

    smart agriculture, etc. The application layer manages the logical

    processes to be taken based on the inference coming from the

    middleware layer and the system requirements. This includes

    sending emails, activating alarms, turning a device on or off,

    setting

    parameters,

    etc.

    Therefore,

    the

    application

    layer

    represents the user interface to interact with the other layers

    below it, facilitating human-machine interactions. Since the

    application layer is meant to be used by people, it inhibits a

    wide surface area exposed to good actors and bad actors. The

    common vulnerabilities usually encountered in the application

    layer include distributed denial of service (DDoS), HTTP ﬂoods,

    SQL injections, and cross-site scripting. Although large-scale

    cybersecurity attacks are dangerous, the effect of small-scale

    cybersecurity attacks, usually encountered in IoT systems, can

    be even more dangerous. This is because they do not have unique

    ecosystems, their cyber defense has not yet reached maturity, and

    they can be gone unnoticed for a long time. The security

    mechanisms applied at the application layer are meant to

    fulﬁll the CIA triad, namely conﬁdentiality, integrity, and

    availability. This implies keeping the secrecy of exchanged

    information between communicating parties, ensuring that no

    alterations have been maliciously carried out on the information

    from its source to destination, and making the information

    always available to authorized users requiring it.

    In contrast to the vulnerabilities in the lower layers of the

    IoT architecture mentioned above which can also affect the

    upper layers, security breaches in the application layer do not

    affect the lower layers. In capable computer systems, however,

    security mechanisms are applied in parallel to different layers

    to tighten the system’s safety. Nevertheless, for a market

    usually biased towards the price and the convenience rather

    than the security, this is not usually valid for constrained

    embedded devices often encountered in IoT systems. Security

    practices for IoT systems often delegate the security measures

    to be applied at the application layer based on the system

    requirements or even delegated to the third-party ﬁrewall

    appliances managing the network. Security measures in IoT

    systems usually come at trade-offs regarding the capacity of

    the constituent IoT devices utilized by the system. Moreover,

    with the diverse application domains of IoT, security

    mechanisms can even affect the system’s effectiveness. For

    example, a VoIP-based IoT solution can be adversely affected

    by the induced latency of the security mechanism in action.

    On the other hand, this latency pales for conﬁdentiality- and

    integrity-critical applications, like ﬁnancial and medical

    applications, where the effect of a security breach would be

    catastrophic.

    2.5 Business intelligence layer

    A successful IoT system depends on the utilized enabling

    technologies and how inference is delivered to the user

    Frontiers in The Internet of Things

    frontiersin.org

    04

    Elgazzar et al.

    10.3389/friot.2022.1073780

    abstractly and efﬁciently. The business intelligence layer is

    meant to fulﬁll this task by providing the user with

    visualized

    representations

    of

    the

    information

    coming

    from the middleware layer, masking its complexity and

    making it easier for the user to make informed business

    decisions.

    The business intelligence layer is not affected by the

    constituent embedded IoT devices utilized by the system. It

    does not deal directly with the constituent IoT devices.

    However, it deals with the inference from the middleware

    layer after processing the raw data from the IoT devices

    through

    the

    application

    layer

    protocols.

    Therefore,

    the

    security of the business intelligence layer depends on the

    typical user-level security mechanisms found in capable

    computer systems. The user-level security can be applied to

    different entities constructing the layer. This includes ﬁles,

    databases, or any other resources. The user-level security is

    meant to implement a ﬁne-grained authorization control over

    accessible information to different users based on their

    credibility.

    3 IoT applications

    IoT can be seen in different real-world applications and

    services such as home automation, intelligent transportation,

    smart cities, digital healthcare, remote health monitoring, smart

    agriculture, and industrial automation (Gubbi et al., 2013). In

    each application domain, several sensors are triggered to

    independently gather data, transmit information, and initiate

    and execute services with minimum human intervention (Sarkar

    et al., 2014). The main objective of integrating IoT technology

    into real-world applications is to enhance the quality of life. For

    example, in the domain of smart city services, we ﬁnd IoT

    applications used for increasing city safety, efﬁcient mobility,

    and enhancing smart energy usage (Weber and Podnar Žarko,

    2019). On the other hand, IoT technology has introduced remote

    medical monitoring systems in the healthcare domain which

    empower physicians to provide superior care to patients (Selvaraj

    and Sundaravaradhan, 2020). Numerous research proposes

    different IoT-based solutions and innovations under three

    application domains shown in Figure 2 (Sarkar et al., 2014).

    FIGURE 2

    IoT application domains and related services.

    Frontiers in The Internet of Things

    frontiersin.org

    05

    Elgazzar et al.

    10.3389/friot.2022.1073780

    3.1 Smart city

    IoT technology assists cities to enhance mobility services,

    improve public safety, and control and automate household

    systems. Intelligent transportation, for example, focuses on

    solutions that manage road infrastructure and improve route

    planning for drivers. Furthermore, it provides innovative

    solutions to monitor and manage trafﬁc systems using smart

    trafﬁc signals and sensors, throughout the road network to

    smooth the trafﬁc ﬂow and reduce congestion. The concept of

    smart city services is not restricted to transportation, but also

    involves other aspects of human life, such as public safety, green

    and clean environment, smart grid, efﬁcient delivery of

    municipal services and connecting the physical infrastructure

    to the digital world. In the following we shed the light on some of

    these aspects.

    3.1.1 Trafﬁc management

    IoT-based trafﬁc management systems mainly monitor road

    trafﬁc conditions to solve the problem of increased trafﬁc

    congestion and predict trafﬁc status (Poslad et al., 2015).

    These systems assist drivers by informing them about the

    trafﬁc conditions at a given location and time. For example,

    an adaptive trafﬁc signal control (ATSC) system that captures the

    trafﬁc volume level can signiﬁcantly reduce trafﬁc congestion

    (Saarika et al., 2017). Equipping roads with advanced sensors that

    capture real-time trafﬁc data assists in determining the duration

    of trafﬁc light signals across intersections. The ATSC system not

    only eases the trafﬁc ﬂow at intersections but also reduces travel

    time and fuel consumption, contributing positively to green

    environments. Research on IoT-based real-time ATSC systems

    at an intersection describes the coordinated approach as it is used

    to track the movements of vehicles and pedestrians (Eom and

    Kim, 2020; Jamil et al., 2020). It also uses the deep reinforcement

    learning (DRL) method which is commonly used in ATSC

    systems to teach/educate trafﬁc controllers how to make

    proper decisions. DRL simulates the effect of a trafﬁc signal’s

    action and the resulting changes in trafﬁc status. It would be

    classiﬁed as an appropriate action in that given situation if the

    action improved trafﬁc conditions, and as a negative action

    otherwise (Jamil et al., 2020). Furthermore, IoT-based trafﬁc

    management systems can facilitate smart parking in public

    spaces such as on-street parking, and lot parking. According

    to Libelium company (Dujić Rodić et al., 2020), parking spaces

    play critical roles in reducing trafﬁc volume, and gas emissions.

    In smart parking, drivers can easily locate an empty parking place

    using smart parking maps. These smart maps use IoT sensors

    and cameras to detect and manage the likelihood of parking

    space in a given area. An example of a real-time trafﬁc occupancy

    system for smart parking is called SplitParking which is managed

    by the city of Split in Croatia (Weber and Podnar Žarko, 2019).

    The SplitParking system places sensors integrated with an IoT

    technology within its parking spaces to monitor space occupancy

    andlert the end user of the parking availability through a user-

    friendly mobile application (Weber and Podnar Žarko, 2019).

    3.1.2 Intelligent transportation

    The emergence of IoT has provided a new perspective for

    intelligent trafﬁc systems development. This is because the IoT

    paradigm satisﬁes the public’s demand towards an “always

    connected” model by relying on the interconnection of our

    daily physical objects using the Internet. Hence, allowing it to

    collect, process and transfer data creating smart intelligent

    systems without human intervention.

    In the trafﬁc domain, IoT requires every element such as

    roads, tunnels, bridges, trafﬁc lights, vehicles and roadside

    infrastructures to be Internet-connected for identiﬁcation and

    management purposes. This can be done using sensor-enabled

    devices, for instance, RFID devices, Infrared sensors, GPS and

    many others. Intelligent trafﬁc systems that are IoT-based can

    efﬁciently improve trafﬁc conditions, reduce trafﬁc congestion

    and are unaffected by weather conditions. Moreover, IoT allows

    for dynamic real-time interactions, since it facilitates the

    incorporation of communication, control and data processing

    across the transportation systems. Beyond any doubt, IoT is

    causing a noticeable shift in the transportation sector.

    The

    rapid

    advancements

    within

    information

    and

    communication technologies have also paved the way for

    developing more self-reliable and intelligent transportation

    systems. These include striding advancements in hardware,

    software,

    sensor-enabled

    and

    wireless

    communications

    technologies.

    Therefore,

    moving

    towards

    a

    new

    era

    of

    connected

    intelligent

    transportation

    systems,

    where

    the

    demand

    for

    on-going

    and

    future

    real-time

    trafﬁc

    data

    continues to rise (Abdelkader and Elgazzar, 2020). This

    enforces

    several

    challenging

    requirements

    on

    the

    trafﬁc

    information

    systems.

    Among

    these

    requirements

    is

    broadcasting real-time, user-friendly, and precise trafﬁc data

    for users. These trafﬁc data including color-coded maps

    showing congestion, calculated trafﬁc time intervals between

    arbitrary points on the road network. In addition to trafﬁc

    density estimations that should be easily interpreted by users

    in a very short time. Moreover, demonstrating real-time routes

    for drivers based on the embedded navigation systems such as

    Global

    Positioning

    Systems

    (GPS).

    Another

    challenging

    requirement

    lies

    in

    storing

    huge

    amounts

    of

    trafﬁc

    information generated from progressively complex networks

    of

    sensors,

    where

    Big

    data

    comes

    into

    play.

    However,

    collecting and storing this amount of trafﬁc information is not

    enough. It is crucial to correlate based on game theory

    methodology, validate and make use of data in real-time.

    Hence

    providing

    valuable,

    relevant

    data

    extraction

    and

    insightful predictions of upcoming patterns and trends based

    on historical data. As an example, providing drivers with real-

    time trafﬁc information to assist them in ﬁnding out the best road

    routes. This is why the subsequent role of predictive analytics for

    Frontiers in The Internet of Things

    frontiersin.org

    06

    Elgazzar et al.

    10.3389/friot.2022.1073780

    the whole transportation is needed. Consequently, trafﬁc

    information systems require participation of all of the above

    components to interact and integrate through a common

    infrastructure. It allows immediate transmission of real time

    trafﬁc information to any part of the system (Abdelkader

    et al., 2021).

    Even with the aforementioned beneﬁts and challenges that

    come along with the integration of IoT into the transportation

    sector. IoT provides a paradigm shift that changes the transit

    services

    into

    intelligent

    groundbreaking

    systems,

    where

    numerous cutting edge technologies are incorporated. This

    creates a wide suite of intelligent transportation applications

    that have road users’ experience and safety at its core. A widely

    adopted IoT applications in the automotive industry include: the

    integration of sensors such as weight measurements and real-

    time ﬂeet location sensors-based tracking to help ﬂeet operators

    efﬁciently manage their ﬂeets. Another use case that IoT

    technologies have shown great impact is predictive analytics.

    In this context, drivers are provided with early in advance vehicle

    maintenance alerts in cases of failure of a speciﬁc vehicle

    component. This is because these components are equipped

    with sensors that collect and share real-time information on

    the vehicle’s status with their vendors. It avoids any sudden or

    abrupt failure that can cause a life-hazard situation. Last, but not

    least with a precise focus on the integration of IoT with connected

    mobility. Figure 3 showcases a predictive maintenance scenario,

    where an in-vehicle monitoring system acquires IoT sensing data

    from the faulty in-vehicle sensor. The vehicular data is sent to the

    Diagnostics and Prognostics cloud services for analyzing and

    predicting maintenance issues. Repair recommendations are

    then sent back to the drivers (Kshirsagar and Patil, 2021).

    3.1.3 Emergency response

    Crisis management is one of the critical situations that face

    many governments, ﬁrst responders, emergency dispatchers and

    others who provide necessary ﬁrst aid/assistance at the least

    possible time. In such situations, the design of the required

    infrastructure

    to

    handle

    emergencies

    becomes

    a

    critical

    requirement. With the introduction of IoT technologies to the

    safety systems where a suite of sensors are connected to provide

    real-time data to crisis management ofﬁcials. This includes the

    use of sensors to monitor the water levels in cases of ﬂood

    situations to provide insights that can support real-time data

    analytics to manage ﬂooding crises. Real-time information can

    contribute to improving crisis management response time.

    Hence, reducing or eliminating the costs of crisis-related

    damages. Fireﬁghting is considered a viable use case that ﬁnds

    value in IoT applications. Heat-proof sensors placed in indoor

    buildings can provide real-time information about the initial

    starting point of a ﬁre, spreading patterns and intensity levels

    (Mekni, 2022). It also extends to provide additional safety

    measures for ﬁreﬁghters as they use IoT-based safety alert

    devices that can accurately detect their motions. These devices

    are equipped with acoustic transmitters which act as beacons to

    FIGURE 3

    An IoT-based predictive maintenance use-case scenario.

    Frontiers in The Internet of Things

    frontiersin.org

    07

    Elgazzar et al.

    10.3389/friot.2022.1073780

    allocate ﬁreﬁghters within the building and embedded sensors

    that can monitor their vital health conditions. Besides protecting

    ﬁreﬁghters, IoT-based sensors are employed to sustain indoors

    electrical systems and smartly pre-identify any active heat

    sources through abrupt temperature spikes. Immediate alerts

    are then subsequently sent for rapid and instant inspections. Fire

    systems based on IoT solutions can be actively intelligent to

    detect and promptly put off small ﬁres through the use of smart

    sprinklers. Other emerging solutions that aid ﬁreﬁghters in ﬁre

    crisis situations include computer-aided dispatch data such as

    precise ﬁre locations, environmental conditions and others.

    Augmented reality-IoT based ﬁreﬁghter helmets (Choi et al.,

    2021) are another innovative solution that can effectively guide

    ﬁreﬁghters to navigate in low-visibility conditions.

    Emergency responders and dispatchers are leveraging the

    beneﬁts of IoT-based solutions when dealing with daily trafﬁc

    accidents. Numerous automotive industrial solutions such as GM

    OnStar provide a myriad of applications and services to assist

    ﬁrst aid dispatchers. This could be achieved through utilizing

    cellular networks in conjunction with GPS and IoT technologies.

    Leveraging Vehicle to Infrastructure (V2I) communication-

    based technologies to provide critical information incases of

    trafﬁc accidents. These include avoidance crash response,

    where drivers in crash situations can connect to OnStar call

    center by requesting the appropriate help to be provided to the

    vehicle’s location. The ecall can be activated manually (using a

    push-button) or automatically through data collected from on-

    board

    sensors.

    Other

    applications

    include

    stolen

    vehicle

    assistance which help the authorities in locating the stolen

    vehicle by activating several functionalities. This includes

    halting the restart option upon reactivation of the remote

    ignition block and transmitting a slowdown signal to let the

    vehicle come to a stop eventually (Abboud et al., 2016). Other use

    cases include amber alert notiﬁcations sent to the public by

    integrating IoT and cellular network technologies. Amber alerts

    provide new means of aiding emergency responders and

    authority ofﬁcials in risky situations such as child abduction.

    Ofﬁcials collect crowdsourcing witness information from people

    within close event proximity to assist in their investigations. The

    alerts usually include event description (time and location). In

    addition to the Kidnappers’ detailed information (e.g, vehicle’s

    information, license plate number and their description) as well

    as child description. However, inability to correctly track the

    suspects’ vehicle or missed notiﬁcations by the public may

    contribute and lead to inefﬁcient amber alert-based systems

    (Zhang et al., 2018).

    Traditionally, infrastructure failures and power outages are

    other use cases implying sudden and abrupt crisis situations that

    may be disruptive to emergency ofﬁcials. Based on leveraging IoT

    technologies that aim at providing preventive and predictive

    maintenance. Hence, avoiding sudden breakdowns, anomalies

    and damages of the infrastructure. This could be achieved

    through continuous supervision and monitoring. For instance,

    smart bridges include a modular and IoT-sensor based system for

    monitoring, evaluating and recording any changes of the bridge

    structure in near real-time. Embedded sensors in the core

    structure of the bridge can then relay measurable information

    to management ofﬁcials for further analysis. This includes

    humidity, temperature and corrosion status of the structure.

    Such data is considered valuable to constantly assess and

    evaluate the health structure and provide necessary measures

    such as intervention and predictive measures strategies (Yang,

    2003).

    3.2 Home automation

    Home

    automation

    and

    control

    systems

    are

    essential

    components of smart cities and have played a signiﬁcant part in

    the advancement of our home environments. They have several

    applications for different usage at home, such as entertainment and

    smart living, surveillance, and safety management (Alhaﬁdh and

    Allen, 2016). Home automation is described as a standard home

    environment equipped with IoT technological infrastructure to

    provide a safe and comfortable lifestyle (Khoa et al., 2020). Home

    automation is based on an intelligent, self-adaptive system that

    analyzes and evaluates stakeholder behaviors and has the capability

    to predict the stakeholder’s future actions and interact accordingly.

    Home automation systems use image detection and facial

    recognition models that are embedded in an intelligent control

    system connected to different sensors such as light sensors, motion

    sensors, water leak sensors, smoke sensors, and CCTV cameras

    (Pavithra and Balakrishnan, 2015). These devices communicate

    with each other through a gateway that is distributed throughout a

    home area network. The home control system will connect different

    subsystems that cooperate in modeling the stakeholder’s actions

    and the environment’s information such as temperature, humidity,

    noise, visibility, and light intensity to enhance the learning process.

    For example, lights and AC temperature can be controlled and

    automated to adapt to the stakeholders’ needs and their movements

    in the home environment. This would conserve energy while also

    effectively monitoring energy consumption (Vishwakarma et al.,

    2019). Research on home automation is not restricted to energy

    optimization; it involves health monitoring and security measures.

    By using innovative IoT technologies, we can connect to

    surveillance cameras in the home environment via a mobile

    device. Additionally, stakeholders can have access to doors and

    window sensors to maintain home safety and security remotely

    (Alsuhaym et al., 2021).

    3.3 Industrial sector

    Industrial IoT leverages IoT capabilities in business and

    economic sectors to automate previously complex manual

    operations in order to satisfy consumer needs and reduce

    Frontiers in The Internet of Things

    frontiersin.org

    08

    Elgazzar et al.

    10.3389/friot.2022.1073780

    production costs. Warehouse operations, logistical services,

    supply chain management, and agricultural breeding can have

    machine-to-machine (M2M) intercommunication to ensure

    optimal industrial operations (Pekar et al., 2020). Figure 4

    illustrates a scenario of the IoT communication sensors in a

    smart agricultural system. This smart agriculture system

    monitors and analyzes the environmental parameters using

    soil moisture and harvesting sensors such as ZigBee, EnOcean,

    Z-wave and ANT (Tang et al., 2018). These sensors are

    automated to diagnose the status of a plant and gather this

    data through an IoT platform to take the proper action such as

    when to irrigate in consultation with a weather forecasting

    service available in the Cloud; thus ensuring the efﬁcient use

    of water resources.

    FIGURE 4

    Illustration of a smart agriculture system.

    FIGURE 5

    Supply chain milestones.

    Frontiers in The Internet of Things

    frontiersin.org

    09

    Elgazzar et al.

    10.3389/friot.2022.1073780

    3.4 Logistics and supply chain

    Supply Chain Management (SCM) is a crucial service in our

    world. Since 1900 (Lummus and Vokurka, 1999), humanity has

    evolved SCM to meet the market needs. Figure 5 highlights SCM

    milestones. Before 1900, SCM was restricted to the local areas.

    However, due to the revolution in railways, goods now can reach

    far beyond local borders. Between 1900 and 1950, global SCM

    attracted large players and organizations like UPS began

    providing their services in the SCM ﬁeld. Industry leaders

    started to look for how we could improve the mechanization

    of the SCM process. From 1950 to 1970, the SCM community

    gained a superior experience by analyzing the military logistics of

    the First World War. DHL and FedEx were established as

    logistics enterprises, and IBM built the ﬁrst computerized

    inventory management that was capable of handling complex

    inventory problems and making stock forecasts. In 1975,

    JCPenney

    designed

    the

    ﬁrst

    Real-Time

    Warehouse

    Management System (WMS) that monitors the warehouse

    stock in real-time. Seven years later, Keith Oliver introduced

    the

    Supply

    Chain

    Management

    term.

    In

    the

    90s,

    the

    technological revolution was triggered when many enterprises

    deployed computers to manage their processes and the internet

    to reach their customers through the World Wide Web. In the

    90s, Amazon started running the e-commerce website. The

    4.0 industrial revolution, including the internet of things,

    began growing in the last decade. Although the IoT looks like

    a promising technology to be adopted in the SCM ﬁeld, deploying

    IoT in SCM faces many challenges. The main hindrance

    (Haddud et al., 2017) is the integration of different supply

    chain processes due to The heterogeneity of technologies used

    in various supply chain stages.

    COVID-19 (de Vass et al., 2021) uncovered a new factor that

    magniﬁes the importance of relying on information and

    communications

    technology

    to

    run

    the

    SCM

    systems.

    Businesses had to switch to remote working due to the

    pandemic.

    The

    lockdown

    and

    physical

    distancing

    requirements imposed on suppliers reduced their labors in

    their plants and sometimes obliged to shut down to limit the

    virus spreading. As a result, consumers face product shortages

    due to reduced production volumes during the pandemic. To

    date (Ozdemir et al., 2022), the world is still suffering from the

    devastating effects of COVID-19 on the supply chain. Therefore,

    decision-makers (Baldwin and Di Mauro, 2020; Baldwin and

    Tomiura, 2020) started exploring how we could deploy new

    technologies, such as IoT, for managing remote operations.

    3.5 Healthcare

    IoT sensors and devices shifted the landscape of portable and

    wearable medical devices from ﬁtness and wellness devices to

    medical-grade devices qualiﬁed for usage at hospitals and

    healthcare providers. This shift accelerated the integration of

    remote patient monitoring in hospitals to accommodate patients

    with chronic diseases (Casale et al., 2021). Therefore, numerous

    efforts have

    been conducted

    to advance remote

    patient

    monitoring (RPM) systems with the help of well-established

    IoT infrastructures and standards in the healthcare domain

    (El-Rashidy et al., 2021). The RPM systems are expected to

    match or exceed the performance of the existing monitoring

    and examinations administered at hospitals and healthcare

    facilities (Casale et al., 2021). For example, continuous heart

    rate monitoring and immediate heartbeat detection necessitate

    patients to be hospitalized and/or connected to a Holter monitor

    or similar devices for long-term cardiac diagnosis. However, this

    setup would hinder patient mobility due to the limitations of the

    existing devices in terms of size and the number of attached

    wires. Moreover, hospitals dedicate signiﬁcant resources to

    providing long-term cardiac monitoring that, in some cases, is

    unavailable, especially in low or middle-income countries.

    Therefore, RPM systems effectively reduce death from chronic

    diseases (e.g., heart diseases, diabetes). IoT platforms and devices

    signiﬁcantly accelerated the development and integration of

    RPM systems into existing healthcare infrastructures. To that

    extent, a typical RPM implementation constitutes various

    services but is not limited to data acquisition, tracking,

    communication,

    automated

    analysis,

    diagnoses,

    and

    notiﬁcation systems (Miller et al., 2021).

    4 Rising trends in sensor data

    analytics

    In recent years, the IoT domain has witnessed increasing

    interest by the research community and rising demands from

    the industrial sector to embed real-time data analytics tools into

    the core of IoT standards. While the real value proposition of IoT is

    shifting from providing passive data monitoring and acquisition

    services to autonomous IoT applications with real-time decision-

    making services. Consequently, real-time data analytics is no longer

    an add-on service and has become integral to any IoT application

    rollout. For example, remote patient monitoring (RPM) and real-

    time data analytics have signiﬁcantly contributed to enhancing

    ECG monitoring and enabling healthcare providers to gain 24/

    7 access to their patients remotely, especially for patients with

    coronary diseases (Mohammed et al., 2019). However, sensor data

    acquisition and collections are mapped as the foundation of IoT

    applications yet are considered passive techniques due to the

    absence of intelligence or decision-making. The main goals of

    IoT application at the early stages were to collect and monitor

    signiﬁcant information regarding speciﬁc applications as initially

    proposed in 1999 (Butzin et al., 2016) while developing supply

    chain optimization at Procter & Gamble. Nearly after 2 decades, the

    goals of using IoT applications and their expectations are on the

    rise, demanding proactive and active decisions made on sensor data

    Frontiers in The Internet of Things

    frontiersin.org

    10

    Elgazzar et al.

    10.3389/friot.2022.1073780

    collected in real-time. Accordingly, data analytics permits various

    applications to focus on performing real-time diagnoses, predictive

    maintenance,

    automated

    decision-making,

    and

    theoretically

    improving the productivity and efﬁciency of the intended

    applications. Meanwhile, modern stream processing engines

    (e.g., Apache Kafka and Apache Pulsar) come with built-in APIs

    ready for data analytics integrations (Martín et al., 2022). Moreover,

    most cloud services provide ready-made end-to-end event

    processing and real-time data analytics tools (i.e., Google

    DataFlow).

    4.1 Real-time vs. ofﬂine data analytics:

    Differences, needs, and potential use

    In an IoT-driven society, applications and services integrate

    smart learning approaches for analyzing insightful patterns and

    trends that result in improved decision-making. For more

    effectively optimized analytics, several IoT data-speciﬁcation

    characteristics should be considered. These include dealing

    with huge volumes of data streamed from sensor-based

    devices deployed for IoT applications and services. It requires

    new means of big data analytics that can deal with huge volumes

    of sensor-generated data. In this context, conventional hardware/

    software methods for storage, data analytics and management

    purposes cannot handle such huge volumes of streaming data.

    Moreover, information collected from heterogeneous devices

    result in three signiﬁcant common features among IoT Data.

    These features include data heterogeneity and association of

    time/space stamps based on the sensors’ locations. The third

    feature is the subjectivity of IoT data associated with the high

    noise levels during acquisition and transmission processes.

    Beyond such characteristics that utilize big data analytics

    approaches, a new suite of applications and services arise that

    demand prompt actions in real-time analytics. This is primarily

    due to its time sensitive and fast streaming of IoT data that is

    generated within short time intervals for instant decision

    making and actions. These insightful decisions are time

    stringent, where IoT streaming data analytics need to be

    delivered within a range of hundreds of milliseconds to only

    a few seconds. As such, life-saving applications demand fast and

    continuous streams of incoming data associated in some cases

    with real-time multi-modal data sources for efﬁcient decision

    making. For instance, connected and autonomous vehicles

    require data fusion of real-time sensor data from different

    sources (e.g., Lidars and cameras), V2X communication and

    road entities (e.g., trafﬁc lights) for safe perception decision

    making. Transmitting trafﬁc data to the cloud servers for real-

    time analytics will be liable to network and communication

    latency that are not well-suited for time sensitive applications,

    which may result in fatal trafﬁc accidents. However, analyzing

    real-time streaming

    data

    on powerful cloud computing

    platforms

    that

    adopt

    data

    parallelism

    and

    incremental

    processing

    techniques

    can

    reduce

    the

    end-to-end

    delay

    associated

    with

    two-way

    data

    transmissions.

    A

    more

    optimized approach could reside in solutions such as edge

    computing, where data analytics are closer to the data

    sources (e.g., edge or IoT-based devices) for faster data

    analytics (Goudarzi et al., 2021). However, these solutions

    are still prone to a number of limitations including limited

    computation, power and storage resources on IoT devices. The

    rising trends towards real-time data analytics are also striving in

    non-critical business applications.

    4.2 Decision making

    Leading IoT-based business sectors rely heavily on well-

    analyzed real-time data inferred from their IoT-enabled

    products. For critical and unbiased decision making, real-

    time data analysis by machine learning algorithms can assist

    in eliminating/reducing junk information and estimating

    learning useful patterns. Data-driven analytics will provide

    more in depth insights for optimizing customers’ experiences

    through daily behaviors and patterns analysis. As an

    example, Apple watches can monitor our daily exercises

    and sleeping patterns in real-time and assist in providing

    customized preference notiﬁcations. Uber can also make

    informed decisions based on analyzing real-time demands

    for trafﬁc trips. This determines their pricing rates that

    proportionately increase in rush hours. Other examples

    may include placing sensors within oil tanks for real-time

    monitoring of oil ﬂuid levels, temperature and humidity.

    This initiates automated decision making such as oil

    reordering

    and

    planning

    pre-scheduled

    maintenance

    (Moh’d Ali et al., 2020).

    Decision

    making-based

    systems

    can

    be

    classiﬁed

    according to the different levels of system complexity. This

    includes

    visual

    analytics

    systems

    that

    help

    business

    practitioners to analyze and interpret gathered IoT data.

    Business

    intelligence

    embedded

    dashboards

    aid

    in

    presenting the retrieved IoT information in a meaningful

    manner. Automated and warnings-based systems conduct a

    predeﬁned data analysis that assists in highlighting risky

    situations through alerts and warnings. For example, IoT-

    based real-time environmental monitoring systems can track

    pollutants and chemicals’ levels in the air within an industrial

    city. Warning notiﬁcations are then subsequently sent to

    citizens within the affected geofenced area indicating health

    risk hazards. Reactive-based systems may take a step forward

    towards performing actions described through rule-based

    languages that are carried out when speciﬁc conditions are

    met. For instance, smart lighting IoT-based systems may

    switch off the lights in a speciﬁc building area if no one is

    present, which is indicated by infrared occupancy sensors

    (Wang et al., 2017).

    Frontiers in The Internet of Things

    frontiersin.org

    11

    Elgazzar et al.

    10.3389/friot.2022.1073780

    4.3 Predictive maintenance

    Utilizing

    IoT

    applications

    has

    incredibly

    reduced

    maintenance costs, in particular in the industrial sector. For

    example, industrial equipment manufacturing that embed

    sensors in heavy machinery integrate with analytical tools to

    monitor the operational efﬁcacy, detect faults or failures, and

    provide a full assessment of the operating condition (Mobley,

    2002). This comprehensive performance evaluation occurs on a

    regular basis to maintain the system’s efﬁciency and initiates

    maintenance if needed. This procedure is known as Predictive

    Maintenance (PdM), or condition-based maintenance, and it

    employs diagnostics and prognostics data to spot early signs of

    failure, allowing the system to operate as intended (Zonta et al.,

    2020). Furthermore, PdM can estimate degradation of the

    equipment and predict the remaining useful life (RUL) of

    equipment, which reduces the maintenance costs to the

    minimum and assures service availability. According to Selcuk

    (Selcuk, 2017), IoT-based predictive maintenance increases the

    return on investment by 10 times, where this approach increases

    the total production by 15%–70% and reduces the maintenance

    costs by 25%–30%. Although PdM successfully reduces the cost

    of production and maintenance, it is expensive to implement due

    to the high cost of the hardware and software required to

    effectively incorporate the PdM into the system. Moreover,

    the quality of the training services and the amount of data

    required to ensure the efﬁcacy of the PdM performance can

    be challenging (Compare et al., 2019).

    4.4 Operation optimization and

    automation

    Industry 4.0 is transitioning from a concept-based approach

    into a market reality. Through the integration of intelligent and

    computerized robotic devices into many aspects of industry

    verticals (e.g., 3D printing, E-sports) that can assist in

    automating and optimizing the manufacturing operations.

    This allows accurate, timely and cost effective completed

    manufacturing processes among a set of machines with

    minimal or no human interventions. In addition to decrease

    in

    cost-related

    operations

    through

    effective

    inventory

    management and energy consumption optimization. Effective

    inventory management in logistics and supply chain sectors is

    obtained through the integration of IoT with Radio Frequency

    Identiﬁcation (RFID) (Tan and Sidhu, 2022) and barcode

    scanners.

    Furthermore, IoT technologies within business automation

    can efﬁciently be used for controlling and monitoring machines’

    manufacturing operations, performance and rate of productivity

    through internet connectivity. Moreover, real-time analysis

    generated from onsite IoT-based sensors provides valuable

    insights to initiate more efﬁcient ways for decreasing cost-

    related

    operational

    expenses

    and

    safety-related/unplanned

    maintenance

    issues.

    For

    example,

    incases

    of

    machine

    operational failures, an IoT-based system can promptly send a

    machine repair request to the maintenance department for

    handling the issue. Furthermore, with the introduction of IoT

    technologies, business revenues are subsequently expected to

    increase

    due

    to

    the

    incremental

    rise

    in

    operational

    productivity. This can be achieved through analyzing three

    critical aspects including operational data, timing and the

    reasons for any production issues. This allows business leaders

    to be focused on their high-level core business objectives with a

    well-deﬁned automated workﬂow.

    4.5 Enhanced customer experience

    Connected environments enable businesses to adopt a user-

    centric approach which utilizes IoT technologies for enhanced

    overall customer experience and extend the customers’ loyalty

    towards their services and products. IoT-driven businesses are

    the gateway to futuristic enhanced digital customer experience

    and prolonged loyalty which are considered one of the primary

    laser-focus objectives by many brands. The drive towards more

    personalized services and applications by customers urge many

    enterprises to increase services for customer engagement through

    the use of artiﬁcial intelligence-based customer support systems

    for real-time assistance.

    The aforementioned notion of providing level up services

    that

    incorporate

    personalized

    experiences

    initiated

    many

    innovative applications and services. As such, omnichannel

    customers’ applications and products such as smart-based

    home

    appliances

    and

    devices

    including

    Alexa-supported

    devices,

    Nest

    Thermostat

    and

    intelligent

    Ring

    Doorbell

    cameras

    that

    enable

    customers

    to

    use

    voice

    assisted

    technologies along with IoT to control various aspects of their

    home intelligently. Moreover, ubiquitous smart wearable devices

    such as ﬁtness trackers that collect real-time health data related to

    customer behavior and daily routines to enhance customer

    experience. For instance, providing customers with real-time

    personalized notiﬁcations according to their daily activities.

    Figure 6 demonstrates the users-centric experience among

    various IoT services and applications.

    However, privacy and security data leakage are still

    considered a major challenge that many researchers and

    developers are trying to ﬁnd innovative and tangible solutions

    to secure personal information when shared for improved service

    and application experiences.

    4.6 Asset tracking and monitoring

    Introducing artiﬁcial intelligence (AI) into IoT applications

    has

    created

    signiﬁcant

    opportunities

    for

    innovations

    in

    Frontiers in The Internet of Things

    frontiersin.org

    12

    Elgazzar et al.

    10.3389/friot.2022.1073780

    automation and asset tracking domains. Companies and labour-

    intensive corporations are investing in autonomous working

    environments with less human interaction, and the demand

    for AI and context-aware systems has drastically increased.

    Whereas in times similar to the coronavirus pandemic,

    factories and workplaces have entirely shut down because of

    lockdown measures to prevent human interactions. The fusion

    between AI and IoT transitioned traditional industry models to

    the industry 5.0 revolution. AI and IoT as core technologies to

    industry 5.0 along with wireless sensor networks result in more

    beneﬁts to industries like using analytical techniques to provide

    predictive maintenance notiﬁcations directly affecting downtime,

    improving workforce and increasing production efﬁciency. IoT

    sensors and devices can perceive and sense their environment

    through high-level technologies, such as laser scanners, cameras

    and image processing, movement and proximity. Therefore, real-

    time

    decisions

    are

    made

    autonomously

    regarding

    object

    identiﬁcation

    and

    asset

    tracking

    by

    coupling

    these

    technologies (i.e., image-recognition software). Similarly, IoT

    applications based on AI algorithms can learn and think

    logically about different operations that require problem-

    solving schemes. Autonomous applications operate based on

    the receding-strategy approach, where new and old control

    inputs are carried out simultaneously through computing the

    new control inputs and executing the old ones. The application

    creates these control inputs to provide real-time performance

    based on three hierarchical levels. The higher level is concerned

    with deﬁning complex operations, for example, GPS waypoints

    for an autonomous device (e.g., robot) to follow. The other two

    (mid and lower) levels are precisely related to creating and

    tracking a reference trajectory for this course, respectively.

    The safety of the robot is the responsibility of the mid-level

    controller

    (Vaskov

    et

    al.,

    2019).

    More

    concisely,

    safety

    concerning collision avoidance among a group of automated

    robots performing a speciﬁc task can be avoided by sharing their

    perceived data. Other communications that involve Human-

    Robotic communication are based on the models, such as

    imitative learning and artiﬁcial neural networks.

    5 Open challenges

    5.1 Device and data heterogeneity

    The versatility of IoT devices and sensor nodes in various ﬁelds

    has given rise to many applications. While deep learning, AI, and

    many other enabling technologies assist IoT devices in learning by

    experience and adapting to new environmental inputs to be able to

    conduct complex operations. However, the reliance on receiving

    data representing the context of the environment surroundings

    speciﬁc to the IoT application requires a signiﬁcant number of

    different sensors and devices. Individual sensors or applications

    provide limited cognition and visibility of the surrounding

    environments. Therefore, integrating various sensors is essential

    in context-aware applications. Furthermore, the diversiﬁcation of

    sensor nodes and devices raised numerous challenges in the research

    FIGURE 6

    User-centric IoT application scenarios.

    Frontiers in The Internet of Things

    frontiersin.org

    13

    Elgazzar et al.

    10.3389/friot.2022.1073780

    community and the industry with respect to uniﬁcation and

    standardization. In public sensing, different types of sensors are

    used (e.g., RFID, Ultrasonic, Cameras, Lidars, etc.) to solve

    designated issues like real-time counting of people waiting to be

    served at a speciﬁc service provider. The same extends to IoT

    applications similar to the public sensing domain like trafﬁc

    management

    and

    predictions.

    Therefore,

    the

    demand

    for

    modular

    platforms

    with

    uniﬁed

    application

    programming

    interfaces (APIs), transmission protocols, data transformation

    and

    storage

    is

    growing.

    Moreover,

    data

    conversion

    and

    normalization

    operations

    carried

    out

    in

    applications

    with

    heterogeneous

    devices

    increase

    exponentially

    due

    to

    the

    diversiﬁed number of sensors utilized just for one application

    (e.g., autonomous vehicles).

    Behmann (Behmann and Wu, 2015) described current IoT

    solutions as point solutions where they are isolated and cannot

    interact with each other. Collaborative IoT (C-IoT) (Behmann

    and Wu, 2015) is a recent trend that is still unsaturated and needs

    more effort to be deployed in real-world scenarios. Sharing the

    infrastructure and data becomes inevitable to pave the way for

    C-IoT systems. C-IoT can create an expandable ecosystem, and

    the IoT community will solve complicated problems by relying

    on the collaboration between IoT systems. For instance, an

    ambulance in the emergency state can always have a green

    light on its way if the emergency service can share the

    ambulance’s route with the city’s intelligent trafﬁc system

    using the shared infrastructure of C-IoT. Recently, an active

    movement to have a uniﬁed standard in different IoT layers has

    been raised for a few years to mitigate incompatibility challenges

    faced by the C-IoT trend.

    5.2 Interoperability

    The diversity of IoT devices in the perception layer brings the

    ﬂexibility to build customized IoT solutions and cherrypick the

    appropriate device for a speciﬁc task that matches constraints

    regarding the accuracy, cost, compatibility with the existing

    infrastructure, etc. However, this also comes at the cost of the

    absence of a uniﬁed ecosystem for IoT. This results in

    interoperability issues between different IoT systems and

    increased development time to get diverse IoT devices to act

    as a coherent system. Besides, it leads to the notorious “isolated

    islands” of miniature IoT subsystems based on the brand of

    devices or their enabling technologies, hindering the utilization

    of sensed information by different systems to its maximum and

    impeding the potential promise of IoT.

    5.3 User and data privacy

    The constituent IoT gadgets of an IoT system typically

    consist of consumer electronics (e.g., smart TVs) and wearable

    devices (e.g., smart watches) that gather a lot of information

    about people, which was previously hard to collect. Gathered data

    by IoT devices may include personal information of the users

    (e.g., name, birthdate, etc.), their biometric information (e.g.,

    ﬁngerprint, voice recognition, etc.), and their preferences (e.g.,

    eating habits, preferred movie genres, etc.), which are usually part

    of the device’s initial setup, registration to its cloud platform, or

    for the device to be able to perform its smart designated task

    efﬁciently. Moreover, advanced IoT systems typically involve the

    aggregation

    of

    numerous

    pieces

    of

    information

    from

    heterogeneous smart objects, which is known as “sensor

    fusion” (Abdelmoneem et al., 2018) to provide accurate and

    comprehensive data about the environment, including people

    themselves, to help make better informed decisions. Thanks to

    the

    advancements

    in

    artiﬁcial

    intelligence

    (AI)

    domain

    technologies which can leverage granular data collected by

    smart objects to generate inferences that would not be

    achievable with coarser data from individual smart objects.

    This intelligence imparted to IoT catalyzes its wide adaption

    and makes it quite useful in different application domains.

    However, user privacy concerns are still an open challenge to

    IoT that impedes its widespread adoption and limits its potential

    promise. IoT systems can disclose identiﬁable information about

    people without their consent. Therefore, amidst the potential

    promise of IoT to change the way we deal with our surroundings,

    users are mostly worried about the potential of private

    information leakage (Chanal and Kakkasageri, 2020). They are

    worried about who owns their data and how it is utilized.

    Nonetheless,

    the

    notorious

    correlation

    between

    service

    providers and device vendors on one hand, and data brokers

    on the other hand, raises concerns about the possibility of their

    personal information being disclosed for non-public interest

    objectives. People frequently alter their behavior when they

    suspect

    that

    their

    identiﬁable

    information

    and

    activity

    footprints are being monitored, which reduces their freedom,

    changes their lifestyle, and makes them sceptical of IoT. In the

    following subsections, we review data privacy concerns that are

    associated with IoT.

    5.3.1 De-identiﬁcation of IoT data

    Generally, it is prohibited to make datasets that include

    identiﬁable personal information publicly accessible. One

    common way to prevent exposing personal information in

    datasets is to avoid gathering information that could be used

    to identify people in the ﬁrst place and whenever possible.

    For example, PIR sensors could be used for occupancy

    detection

    rather

    than

    surveillance

    cameras.

    However,

    given the penetration of IoT in a lot of domains with

    differentiated requirements, it is usually hard, or even

    impossible,

    to

    preclude

    the

    inclusion

    of

    identiﬁable

    information in gathered datasets by IoT. In this context,

    de-identiﬁcation (Kim and Park, 2022) is the process used to

    anonymize identiﬁable personal information from datasets,

    Frontiers in The Internet of Things

    frontiersin.org

    14

    Elgazzar et al.

    10.3389/friot.2022.1073780

    which

    is

    quite

    challenging.

    Hashing

    algorithms

    are

    commonly used to pseudonymize identiﬁable information

    in datasets by replacing identiﬁed people in a dataset with

    their unique hash token. However, since different datasets

    often have a lot in common, it is usually easy to ﬁgure out

    who the hashed information belongs to using inference

    techniques.

    5.3.2 Consent

    Consent (O’Connor et al., 2017) is the typical justiﬁcation for

    businesses to collect, use, and disclose personal information.

    However, consent often matters more than just unconsciously

    clicking the “I agree” button by the end user on the “Terms and

    Conditions” statement page of a device. Rather, consent that is

    meaningful and effective requires well-deﬁned and ﬁnely-grained

    structured objectives that the user should be able to choose from.

    Moreover, one can not presume that consent will last forever.

    Therefore, consent methods should represent a single acceptance

    at a single moment in time, which may not be suitable for the

    continual nature of IoT. Also, given the interoperability nature of

    the IoT, where a smart sensor node may be utilised by different

    systems with different privacy policies, an individual can not

    grant meaningful permission for the use of their personal data for

    vague or broad purposes.

    5.4 Vendor lock-in

    IoT vendors and service providers typically maintain the

    security of their active devices or services by regularly providing

    ﬁrmware patches and system updates that address security

    vulnerability issues that continually emerge. However, they

    often

    have

    different

    expectations

    about

    how

    long

    their

    products or services will last than the people who buy them.

    For instance, vendors may terminate technical support or

    ﬁrmware maintainability of a device, or the service provider

    may discontinue the service that the device relies on to operate,

    far before the end user plans to retire the device. This usually

    comes at the cost of possible security holes, privacy issues, and

    vendor lock-in (Fantacci et al., 2014). Therefore, customers

    would have to stick with their active line of products and

    services to keep their systems safe and operational because

    suppliers would no longer care about security and privacy

    issues with their retired devices or have the skills to deal

    with them.

    5.5 Device management

    The “plug and play” feature that usually accompanies IoT

    devices makes them user-friendly since customers can

    seamlessly get them up and running effortlessly without

    the need for complicated setup procedures. However, this

    sometimes comes at the cost of potential user privacy

    exposure since the default setup of devices usually comes

    with

    insufﬁcient

    privacy

    and

    security

    precautions.

    Nonetheless, the fact that a gadget is an IoT device that

    can collect personal information and send it to third parties

    over the cloud may not be even realized by the majority of

    non-technically savvy customers by default. In addition,

    most IoT customers ﬁnd it hard and time-consuming to

    adjust the privacy settings for each device in the system.

    This is because IoT does not have a standard ecosystem and is

    often

    made

    up

    of

    many

    devices

    from

    different

    manufacturers,

    each

    with

    their

    own

    user

    experience

    interface.

    5.6 Accountability

    The extensive and distributed nature of IoT systems, which

    typically include different service providers that handle the collected

    data to achieve the designated task of the system, makes it

    challenging to precisely determine who is responsible for what.

    In order to achieve a robust and highly reliable IoT system

    architecture, system designers usually follow a common system

    architectural model that is known as “microservices” (Butzin

    et al., 2016). They divide the ultimate task of the system into

    small independent tasks, each of which may utilize numerous

    services from different service providers that communicate over

    well-deﬁned APIs. However, this raises privacy concerns because the

    collected

    data,

    which

    may

    contain

    personally

    identiﬁable

    information about users, is now handled and commonly stored

    by various third-party organizations with hazy boundaries that may

    apply different privacy policies.

    5.7 Transparency

    The tiny size of most IoT devices in use today without a

    screen, or at least an adequate screen size to display a lot of textual

    information, makes it difﬁcult for users to review their privacy

    policies before they start using them. In order to review the

    privacy policies of these devices, however, users should login to

    the website of the manufacturer of the device or use a proprietary

    software or a mobile application for the device. However, in

    either case, given the heterogeneous nature of the IoT and the

    anticipated large number of IoT devices people use on a daily

    basis, it looks extremely challenging to follow the privacy policy

    of each encountered device. Also, a lot of privacy policies for IoT

    devices seem vague to the majority of people. Moreover, some

    IoT devices that exist in organizations and public settings are

    usually anonymous without details about the type of information

    they collect or how this information is utilized and for which

    objectives. Also, most of the time, users do not have the option to

    stop the collection.

    Frontiers in The Internet of Things

    frontiersin.org

    15

    Elgazzar et al.

    10.3389/friot.2022.1073780

    5.8 Security (data and device vulnerability)

    IoT devices exchange data with millions of devices through the

    internet

    which

    implicitly

    exposes

    the

    IoT

    devices

    to

    the

    vulnerabilities and security threats of the Internet protocol stack

    (Ilyas et al., 2020). The amount of data collected, stored and shared

    between IoT devices and the service providers are expected to grow

    signiﬁcantly. Besides the extraordinary amount of data produced by

    IoT devices, they induce evidently high-security risks and potential

    cyberattacks destabilizing many applications and industries.

    IoT networks come with their unique security challenges

    (Khanam et al., 2020), where each layer is exposed to certain

    types of attacks (Hassija et al., 2019), like Distributed Denial of

    Service attacks (DDoS) on the network layer. To that extent, a

    multitude of surveys citerefs2 and studies have been conducted to

    expose existing security threats and vulnerabilities in current IoT

    applications. Recent surveys on IoT data and device security

    emphasize that the gap between applying existing security

    techniques to emerging IoT applications is growing signiﬁcantly.

    The security gaps in IoT applications are categorized into vendor-

    related security issues and available resources or capabilities on the

    IoT nodes. IoT vendors for sensors and devices are moving towards

    low-cost manufacturing that lack security features. Similarly, the

    heterogeneity of the IoT applications, protocols, and hardware

    increases the security scope of threats in IoT applications

    (Hassija et al., 2019). On the other hand, IoT applications are

    inherently constrained by the limited processing and storage

    capabilities

    of

    devices

    to

    carry

    out

    sophisticated

    security

    techniques. Therefore, new security measures are introduced for

    IoT resource-constrained devices using robust ML techniques like

    the TinyML framework. The concepts introduced behind the

    integration of ML is to increase the ﬂexibility of IoT nodes in

    defending against emerging security threats (Dutta and Kant, 2021).

    IoT devices can then train the deployed ML models to work against

    new security threats.

    5.9 Open deployments and access control

    Mentioning the access control usually ﬂashed RFID (Radio-

    frequency identiﬁcation) cards. RFID technology sparked the

    existence of the IoT term coined by Kevin Ashton, who

    considered RFID a vital component in The IoT systems. Access

    control as an open challenge is a multifaceted challenge that has been

    raised due to other issues. In this section, we use a wallet holding

    many RFID cards as an example to discuss the access control issues:

    • Heterogeneity: Having many cards to access different

    purposes itself is due to the heterogeneity of the

    systems. There are chances to have a consensus among

    some corporations to unify their access cards to mitigate

    this challenge. For instance, Google Pay is an android

    application that offers contactless purchases on the

    smartphone with a built-in Near Field Communication

    NFC module. Users can register debit or credit cards and

    use them in their daily in-person shopping instead of

    holding many bank cards in wallets. Due to systems

    heterogeneity, we still face a challenge in making all

    services accessible from uniﬁed access.

    • Security: Giving accessibility to banks a counting using

    contactless RFID bank cards looks a very smooth user

    experience in transactions instead of writing sixteen digits

    in card readers. However, card skimming devices can clone

    contactless bank cards.

    To discuss the other issues in access control, we use a smart

    home application as another example facing access control

    challenges:

    • Interoperability: Recently, users can simply control

    their IoT devices in their houses, such as smart TV,

    fridge, coffee machine, and adapted light systems. The

    interoperability between these devices is still very

    challenging due to the lack of standardization. For

    instance, a coffee machine starts pouring coffee on a

    cup if the adapted light senses a motion in the living

    room, and there is a collaborative integration between

    these devices. ThingsDriver (Elewah et al., 2022) is a

    beginning to have A Uniﬁed Interoperable messaging

    protocol that, if adopted by cooperates, can pave the

    way to have a collaborative environment.

    • Privacy: All these smart home devices become remotely

    accessible through user-friendly user interfaces such as a

    smartwatch or phone. On the other side, the ﬂexibility of

    accessibility raises privacy concerns. Residents’ data are

    highly vulnerable to being breached by unauthorized

    access.

    6 Conclusion

    In this paper, we review the Internet of Things technology

    from different architectural, technological, operational and

    value-proposition perspectives. We ﬁrst shed the light on the

    deﬁnition, acclaimed value and potential, and unique features

    and characteristics compared to similar previous technologies

    and standard layered architecture. We then highlight the

    different applications of IoT in various life domains that

    primarily beneﬁt from its realization as a novel computing

    paradigm. We outlined the grand challenges facing IoT which

    may cause slowdown in its widespread adoption at the individual,

    organizational and governmental levels.

    We believe the IoT will continue to grow as a disruptive

    technology that changed the world and it will never be the same

    again. There is a continuously increasing reliance on IoT

    technology in different sectors of our life for its convenience

    Frontiers in The Internet of Things

    frontiersin.org

    16

    Elgazzar et al.

    10.3389/friot.2022.1073780

    and innovative applications stemming out of it. Individuals and

    enterprises started to gain conﬁdence in the technology and

    overlook or ignore the downsides of its security and privacy

    aspects. However, we also believe that the emergence of Edge

    computing in its different forms and shapes has contributed to

    lower the adoption barriers of IoT and increased interest in its

    technology and smart services. We anticipate that in the next few

    years IoT will continue to penetrate deeper in various sectors and

    tape into more industrial and governmental settings.

    Author contributions

    All authors listed have made a substantial, direct, and intellectual

    contribution to the work and approved it for publication.

    Conﬂict of interest

    The authors declare that the research was conducted in the

    absence of any commercial or ﬁnancial relationships that could

    be construed as a potential conﬂict of interest.

    Publisher’s note

    All claims expressed in this article are solely those of the

    authors and do not necessarily represent those of their afﬁliated

    organizations, or those of the publisher, the editors and the

    reviewers. Any product that may be evaluated in this article, or

    claim that may be made by its manufacturer, is not guaranteed or

    endorsed by the publisher.

    References

    Abboud, K., Omar, H. A., and Zhuang, W. (2016). Interworking of dsrc and

    cellular network technologies for V2X communications: A survey. IEEE Trans. Veh.

    Technol. 65, 9457–9470. doi:10.1109/tvt.2016.2591558

    Abdelkader, G., and Elgazzar, K. (2020). “Connected vehicles: Towards accident-

    free intersections,” in 2020 IEEE 6th World Forum on Internet of Things (WF-IoT)

    (IEEE), 1–2.

    Abdelkader, G., Elgazzar, K., and Khamis, A. (2021). Connected vehicles:

    Technology review, state of the art, challenges and opportunities. Sensors 21,

    7712. doi:10.3390/s21227712

    Abdelmoneem, R. M., Shaaban, E., and Benslimane, A. (2018). “A survey on

    multi-sensor fusion techniques in IoT for healthcare,” in 2018 13th International

    Conference on Computer Engineering and Systems (ICCES) (IEEE), 157–162.

    Alhaﬁdh, B., and Allen, W. (2016). Design and simulation of a smart home

    managed by an intelligent self-adaptive system. Int. J. Eng. Res. Appl. 6, 64–90.

    Alsuhaym, F., Al-Hadhrami, T., Saeed, F., and Awuson-David, K. (2021).

    “Toward home automation: An IoT based home automation system control and

    security,” in 2021 International Congress of Advanced Technology and Engineering

    (ICOTEN) (IEEE), 1–11.

    Ashton, K. (2009). That ‘internet of things’ thing. RFID J.

    Baldwin, R., and Di Mauro, B. W. (2020). Economics in the time of COVID-19: A

    new eBook, 2–3. London: VOX CEPR Policy Portal.

    Baldwin, R., and Tomiura, E. (2020). Thinking ahead about the trade impact of

    COVID-19. Econ. Time COVID- 19 59, 59–71.

    Behmann, F., and Wu, K. (2015). Collaborative internet of things (C-IoT): For

    future smart connected life and business. John Wiley & Sons.

    Bouguettaya, A., Sheng, Q. Z., Benatallah, B., Neiat, A. G., Mistry, S., Ghose,
    A.,

    et al. (2021). An internet of things service roadmap. Commun. ACM 64, 86–95.

    doi:10.1145/3464960

    Butzin, B., Golatowski, F., and Timmermann, D. (2016). “Microservices approach

    for the internet of things,” in 2016 IEEE 21st International Conference on Emerging

    Technologies and Factory Automation (ETFA) (IEEE), 1–6.

    Casale, P. N., Vyavahare, M., Coyne, S., Kronish, I., Greenwald, P., Ye, S., et
    al.

    (2021). The promise of remote patient monitoring: Lessons learned during the

    COVID-19 surge in New York city. Am. J. Med. Qual. 36, 139–144. doi:10.1097/01.

    jmq.0000741968.61211.2b

    Chanal, P. M., and Kakkasageri, M. S. (2020). Security and privacy in iot: A

    survey. Wirel. Pers. Commun. 115, 1667–1693. doi:10.1007/s11277-020-07649-9

    Choi, M., Li, G., Todrzak, R., Zhao, Q., Raiti, J., and Albee, P. (2021). “Designing
    a

    LoRa-based smart helmet to aid in emergency detection by monitoring bio-signals,”

    in 2021 IEEE Global Humanitarian Technology Conference (GHTC) (IEEE),

    72–75.

    Compare, M., Baraldi, P., and Zio, E. (2019). Challenges to IoT-enabled predictive

    maintenance for industry 4.0. IEEE Internet Things J. 7, 4585–4597. doi:10.1109/

    jiot.2019.2957029

    de Vass, T., Shee, H., and Miah, S. J. (2021). IoT in supply chain management:

    Opportunities and challenges for businesses in early industry 4.0 context. OSCM.

    Int. J. 14, 148–161. doi:10.31387/oscm0450293

    Dujić Rodić, L., Perković, T., Županović, T., and Šolić, P. (2020). Sensing

    occupancy through software: Smart parking proof of concept. Electronics 9,

    2207. doi:10.3390/electronics9122207

    Dutta, A., and Kant, S. (2021). “Implementation of cyber threat intelligence

    platform on internet of things (IoT) using TinyML approach for deceiving cyber

    invasion,”

    in

    2021

    International

    Conference

    on

    Electrical,

    Computer,

    Communications and Mechatronics Engineering (ICECCME) (IEEE), 1–6.

    El-Rashidy, N., El-Sappagh, S., Islam, S. R., El-Bakry, H., and Abdelrazek, S.

    (2021). Mobile health in remote patient monitoring for chronic diseases: Principles,

    trends, and challenges. Diagnostics 11, 607. doi:10.3390/diagnostics11040607

    Elewah, A., Ibrahim, W. M., Rafıkl, A., and Elgazzar, K. (2022). “ThingsDriver:
    A

    uniﬁed interoperable driver for IoT nodes,” in 2022 International Wireless

    Communications and Mobile Computing (IWCMC) (IEEE), 877–882.

    Eom, M., and Kim, B.-I. (2020). The trafﬁc signal control problem for

    intersections: A review. Eur. Transp. Res. Rev. 12, 50–20. doi:10.1186/s12544-

    020-00440-8

    Fantacci, R., Pecorella, T., Viti, R., and Carlini, C. (2014). A network architecture

    solution for efﬁcient IoT WSN backhauling: Challenges and opportunities. IEEE

    Wirel. Commun. 21, 113–119. doi:10.1109/mwc.2014.6882303

    Goudarzi, M., Wu, H., Palaniswami, M., and Buyya, R. (2021). An application

    placement technique for concurrent IoT applications in edge and fog computing

    environments. IEEE Trans. Mob. Comput. 20, 1298–1311. doi:10.1109/tmc.2020.

    2967041

    Gubbi, J., Buyya, R., Marusic, S., and Palaniswami, M. (2013). Internet of things

    (IoT): A vision, architectural elements, and future directions. Future Gener.

    Comput. Syst. 29, 1645–1660. doi:10.1016/j.future.2013.01.010

    Haddud, A., DeSouza, A., Khare, A., and Lee, H. (2017). Examining potential

    beneﬁts and challenges associated with the internet of things integration in supply

    chains. J. Manuf. Technol. Manag. 28, 1055–1085. doi:10.1108/jmtm-05-2017-0094

    Hassija, V., Chamola, V., Saxena, V., Jain, D., Goyal, P., and Sikdar, B. (2019).
    A

    survey on IoT security: Application areas, security threats, and solution

    architectures. IEEE Access 7, 82721–82743. doi:10.1109/access.2019.2924045

    Ilyas,

    M.

    U.,

    Ahmad,

    M.,

    and

    Saleem,

    S.

    (2020).

    Internet-of-Things-

    Infrastructure-as-a-Service: The democratization of access to public internet-of-

    things infrastructure. Int. J. Commun. Syst. 33, e4562. doi:10.1002/dac.4562

    Jamil, A. R. M., Ganguly, K. K., and Nower, N. (2020). Adaptive trafﬁc signal

    control system using composite reward architecture based deep reinforcement

    learning. IET Intell. Transp. Syst. 14, 2030–2041. doi:10.1049/iet-its.2020.0443

    Khanam, S., Ahmedy, I. B., Idris, M. Y. I., Jaward, M. H., and Sabri, A. Q. B.
    M.

    (2020). A survey of security challenges, attacks taxonomy and advanced

    countermeasures in the internet of things. IEEE Access 8, 219709–219743.

    doi:10.1109/access.2020.3037359

    Frontiers in The Internet of Things

    frontiersin.org

    17

    Elgazzar et al.

    10.3389/friot.2022.1073780

    Khoa, T. A., Nhu, L. M. B., Son, H. H., Trong, N. M., Phuc, C. H., Phuong, N.
    T.

    H., et al. (2020). Designing efﬁcient smart home management with IoT smart

    lighting: A case study. Wireless Communications and mobile computing 2020.

    Kim, J., and Park, N. (2022). De-identiﬁcation mechanism of user data in video

    systems according to risk level for preventing leakage of personal healthcare

    information. Sensors 22, 2589. doi:10.3390/s22072589

    Kshirsagar, A., and Patil, N. (2021). “IoT based smart lock with predictive

    maintenance,”

    in

    2021

    12th

    International

    Conference

    on

    Computing

    Communication and Networking Technologies (ICCCNT) (IEEE), 1–6.

    Lin, J., Yu, W., Zhang, N., Yang, X., Zhang, H., and Zhao, W. (2017). A survey

    on internet of things: Architecture, enabling technologies, security and privacy,

    and applications. IEEE Internet Things J. 4, 1125–1142. doi:10.1109/jiot.2017.

    2683200

    Lueth, K. L. (2020). Top 10 IoT applications in 2020. IoT analytics.

    Lummus, R. R., and Vokurka, R. J. (1999). Deﬁning supply chain management: A

    historical perspective and practical guidelines. Bingley, United Kingdom: Industrial

    Management & Data Systems.

    Martín, C., Langendoerfer, P., Zarrin, P. S., Díaz, M., and Rubio, B. (2022).
    Kafka-

    ML: Connecting the data stream with ML/AI frameworks. Future Gener. Comput.

    Syst. 126, 15–33. doi:10.1016/j.future.2021.07.037

    Mekni, S. K. (2022). “Design and implementation of a smart ﬁre detection and

    monitoring system based on IoT,” in 2022 4th International Conference on Applied

    Automation and Industrial Diagnostics (ICAAID) (IEEE), 1, 1–5.

    Miller, J. C., Skoll, D., and Saxon, L. A. (2021). Home monitoring of cardiac

    devices in the era of COVID-19. Curr. Cardiol. Rep. 23, 1–9. doi:10.1007/s11886-

    020-01431-w

    Mobley, R. K. (2002). An introduction to predictive maintenance. Elsevier.

    Mohammed, K., Zaidan, A., Zaidan, B., Albahri, O. S., Alsalem, M., Albahri, A.

    S., et al. (2019). Real-time remote-health monitoring systems: A review on

    patients

    prioritisation

    for

    multiple-chronic

    diseases,

    taxonomy

    analysis,

    concerns and solution procedure. J. Med. Syst. 43 (7), 1–21. doi:10.1007/

    s10916-019-1362-x

    Moh’d Ali, M. A., Basahr, A., Rabbani, M. R., and Abdulla, Y. (2020).

    “Transforming business decision making with internet of things (IoT) and

    machine learning (ML),” in 2020 International Conference on Decision Aid

    Sciences and Application (DASA) (IEEE), 674–679.

    O’Connor, Y., Rowan, W., Lynch, L., and Heavin, C. (2017). Privacy by design:

    Informed consent and internet of things for smart health. Procedia Comput. Sci.

    113, 653–658. doi:10.1016/j.procs.2017.08.329

    Ozdemir, D., Sharma, M., Dhir, A., and Daim, T. (2022). Supply chain resilience

    during the COVID-19 pandemic. Technol. Soc. 68, 101847. doi:10.1016/j.techsoc.

    2021.101847

    Pavithra, D., and Balakrishnan, R. (2015). “IoT based monitoring and control

    system for home automation,” in 2015 Global Conference on Communication

    Technologies (GCCT) (IEEE), 169–173.

    Pekar, A., Mocnej, J., Seah, W. K., and Zolotova, I. (2020). Application domain-

    based overview of IoT network trafﬁc characteristics. ACM Comput. Surv. 53, 1–33.

    doi:10.1145/3399669

    Poslad, S., Ma, A., Wang, Z., and Mei, H. (2015). Using a smart city IoT to

    incentivise and target shifts in mobility behaviour—is it a piece of pie? Sensors
    15,

    13069–13096. doi:10.3390/s150613069

    Saarika, P., Sandhya, K., and Sudha, T. (2017). “Smart transportation system

    using IoT,” in 2017 International Conference on Smart Technologies for Smart

    Nation (SmartTechCon) (IEEE), 1104–1107.

    Sarkar, C., Nambi, S. A. U., Prasad, R. V., and Rahim, A. (2014). “A scalable

    distributed architecture towards unifying IoT applications,” in 2014 IEEE World

    Forum on Internet of Things (WF-IoT) (IEEE), 508–513.

    Selcuk, S. (2017). “Predictive maintenance, its implementation and latest

    trends,” in Proceedings of the Institution of Mechanical Engineers, Part B:

    Journal

    of

    Engineering

    Manufacture,

    231,

    1670–1679.

    doi:10.1177/

    0954405415601640

    Selvaraj, S., and Sundaravaradhan, S. (2020). Challenges and opportunities in
    IoT

    healthcare systems: A systematic review. SN Appl. Sci. 2, 139–148. doi:10.1007/

    s42452-019-1925-y

    Tan, W. C., and Sidhu, M. S. (2022). Review of RFID and IoT integration in supply

    chain management. Amsterdam, Netherlands: Operations Research Perspectives,

    100229.

    Tang, X., Wang, X., Cattley, R., Gu, F., and Ball, A. D. (2018). Energy harvesting

    technologies for achieving self-powered wireless sensor networks in machine

    condition monitoring: A review. Sensors 18, 4113. doi:10.3390/s18124113

    Vaskov, S., Kousik, S., Larson, H., Bu, F., Ward, J., Worrall, S., et al. (2019).

    Towards provably not-at-fault control of autonomous robots in arbitrary dynamic

    environments. arXiv Preprint arXiv:1902.02851

    Vishwakarma, S. K., Upadhyaya, P., Kumari, B., and Mishra, A. K. (2019). “Smart

    energy efﬁcient home automation system using IoT,” in 2019 4th International

    Conference on Internet of Things: Smart Innovation and Usages (IoT-SIU)

    (IEEE), 1–4.

    Wang, X., Tjalkens, T., and Linnartz, J.-P. (2017). “Smart ofﬁce lighting control

    using occupancy sensors,” in 2017 IEEE 14th International Conference on

    Networking, Sensing and Control (ICNSC) (IEEE), 453–458.

    Weber, M., and Podnar Žarko, I. (2019). A regulatory view on smart city services.

    Sensors 19, 415. doi:10.3390/s19020415

    Yang, S. (2003). A condition-based failure-prediction and processing-scheme for

    preventive maintenance. IEEE Trans. Reliab. 52, 373–383. doi:10.1109/tr.2003.816402

    Zhang, Q., Zhang, Q., Shi, W., and Zhong, H. (2018). Distributed collaborative

    execution on the edges and its application to amber alerts. IEEE Internet Things
    J. 5,

    3580–3593. doi:10.1109/jiot.2018.2845898

    Zonta, T., Da Costa, C. A., da Rosa Righi, R., de Lima, M. J., da Trindade, E.
    S., and

    Li, G. P. (2020). Predictive maintenance in the industry 4.0: A systematic literature

    review. Comput. Industrial Eng. 150, 106889. doi:10.1016/j.cie.2020.106889

    Frontiers in The Internet of Things

    frontiersin.org

    18

    Elgazzar et al.

    10.3389/friot.2022.1073780

    '
  inline_citation: '>'
  journal: Frontiers in the Internet of Things
  limitations: '>'
  pdf_link: https://www.frontiersin.org/articles/10.3389/friot.2022.1073780/pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Revisiting the internet of things: New trends, opportunities and grand challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/electronics12122590
  analysis: '>'
  authors:
  - Abdullah I. A. Alzahrani
  - Sajjad Hussain Chauhdary
  - Abdulrahman A. Alshdadi
  citation_count: 4
  full_citation: '>'
  full_text: '>

    Citation: Alzahrani, A.I.A.;

    Chauhdary, S.H.; Alshdadi, A.A.

    Internet of Things (IoT)-Based

    Wastewater Management in Smart

    Cities. Electronics 2023, 12, 2590.

    https://doi.org/10.3390/

    electronics12122590

    Academic Editor: Domenico Ursino

    Received: 2 April 2023

    Revised: 1 June 2023

    Accepted: 5 June 2023

    Published: 8 June 2023

    Copyright:

    © 2023 by the authors.

    Licensee MDPI, Basel, Switzerland.

    This article is an open access article

    distributed

    under

    the

    terms

    and

    conditions of the Creative Commons

    Attribution (CC BY) license (https://

    creativecommons.org/licenses/by/

    4.0/).

    electronics

    Article

    Internet of Things (IoT)-Based Wastewater Management in

    Smart Cities

    Abdullah I. A. Alzahrani 1

    , Sajjad Hussain Chauhdary 2,*

    and Abdulrahman A. Alshdadi 3

    1

    Department of Computer Science, Collage of Science and Humanities in Al Quwaiiyah,
    Shaqra University,

    Shaqra 11961, Saudi Arabia; a.alzahrani@su.edu.sa

    2

    Department of Computer Science & Artiﬁcial Intelligence, College of Computer Science
    and Engineering,

    University of Jeddah, Jeddah 23890, Saudi Arabia

    3

    Department of Information and System Technology, College of Computer Science and
    Engineering,

    University of Jeddah, Jeddah 23890, Saudi Arabia; alshdadi@uj.edu.sa

    *

    Correspondence: shussain1@uj.edu.sa

    Abstract: Wastewater management is a mechanism that is used to extract and reﬁne
    pollutants

    from wastewater or drainage that can be recycled to the water supply with minimal
    environmental

    effects. New methods and techniques are required to ensure safe and smart wastewater
    management

    systems in smart cities because of the present deteriorating environmental state.
    Wireless sensor

    networks and the Internet of Things (IoT) represent promising wastewater treatment
    technologies.

    The elaborated literature survey formulates a conceptual framework with an Internet
    of Things

    (IoT)-based wastewater management system in smart cities (IoT-WMS) using blockchain
    technology.

    Blockchain technology is now being used to store information to develop an incentive
    model for

    encouraging the reuse of wastewater. Concerning the quality and quantity of recycled
    wastewater,

    tokens are issued to households/industries in smart cities. Nevertheless, this
    often encourages

    tampering with the information from which these tokens are awarded to include
    certain rewards.

    Anomaly detector algorithms are used to identify the possible IoT sensor data
    which has been

    tampered with by intruders. The model employs IoT sensors together with quality
    metrics to measure

    the amount of wastewater produced and reused. The simulation analysis shows that
    the proposed

    method achieves a high wastewater recycling rate of 96.3%, an efﬁciency ratio
    of 88.7%, a low moisture

    content ratio of 32.4%, an increased wastewater reuse of 90.8%, and a prediction
    ratio of 92.5%.

    Keywords: Internet of Things; wireless sensor networks; smart city; wastewater
    management

    1. Introduction

    Water must be safe enough to be used for drinking, washing, and industrial use.

    Wastewater is any water that needs cleaning after use. The purpose of wastewater
    man-

    agement is to preserve wastewater [1]. Untreated wastewater chemicals and pathogens

    can harm animals, plants, and birds that live in or near the water. Healthy wastewater

    management helps to reuse the water volume instead of waste it [2]. Thus, it contaminates

    crops and drinking water which impacts human health. Wastewater is a water supply
    with

    many uses, when correctly processed [3]. Treatment of wastewater is essential
    to protect

    many different habitats [4]. The beneﬁcial use of wastewater often decreases the
    impacts

    of wastewater or industrial efﬂuent contamination on the environment. The end
    usage of

    wastewater deﬁnes the appropriate water quality and safety control procedures
    [5].

    Increased urbanization poses a danger of water shortages. Safe drinking water
    is

    one of the basic human needs. This refers to the notion of wastewater reuse and
    recy-

    cling [6]. The recycled wastewater is contained in an underground sump, and it
    is used

    for planting water. Using recycled water eliminates the dependence on ever costlier
    and

    cheaper groundwater for such applications [7] and will minimize the overﬂow and
    reduce

    wastewater discharge into rivers and oceans. Similar treatment standards occur
    for speciﬁc

    Electronics 2023, 12, 2590. https://doi.org/10.3390/electronics12122590

    https://www.mdpi.com/journal/electronics

    Electronics 2023, 12, 2590

    2 of 14

    applications of water [8]. Treated and recycled wastewater offers an inexpensive
    supply

    that eliminates the demand and burden on freshwater supplies such as groundwater,
    rivers,

    and reservoirs [9]. In the areas impacted by water shortages and drought, this
    is especially

    relevant. Wastewater that is not extracted and recycled is often discharged into
    the wide

    water bodies [10]. The recycling of wastewater is the best way to prevent potential
    water

    depletion and minimize contamination that harms the ecosystem. Untreated wastewater

    does not automatically decompose [11].

    Wastewater treatment is used to extract pollutants from waste or sewage and transform

    them into wastewater that can be reused for other uses (called water recovery)
    or added to

    the water supply with an associated environmental impact [12]. In a basic central
    device

    setup, a wireless sensor network is required, with the base terminal operating
    as the central

    hub [13]. The data are obtained, preserved, and analyzed afterwards. The hardware

    comprises a pump, a ﬂuidic chamber, and various sensor nodes for tracking the
    ﬂuid’s

    color changes [14]. The change of color is tracked independently in the channel
    cabinet and

    the bulk solution. To track atmospheric conditions such as light levels and temperature,

    sensor nodes are often used [15]. An experiment showed the usefulness of wireless
    sensing

    in controlling water puriﬁcation treatments.

    Through detecting and avoiding mixed sewage and chemical overﬂows in wastewater

    using IoT sensors, intelligent wastewater systems can satisfy the demand for freshwater

    within the smart community of the IoT. Freshwater is one of the most valuable
    natural

    commodities that is not available every day. The IoT uses the concept of sensing
    devices

    installed at different points in the water environment for aquatic care [16].
    These sensors

    capture and transmit data to surveillance systems. These data may include the
    water

    quality, temperature changes, pressure changes, water leakage detection, and chemical

    leakage detection. These sensors capture and transmit data to surveillance systems.
    A smart

    water sensor powered by the IoT can monitor the water quality, pressure, and temperature.

    In reality, a sensor solution can control the ﬂuid ﬂow throughout the treatment
    plant and

    can be used by a water utility provider. Using blockchain technologies to monitor
    these

    connections can efﬁciently analyze quantity communications, identify breaches
    in water

    mass balance management, and improve leak detection. If registered data can be
    changed

    retroactively in any particular block without modifying all additional blocks
    that need to

    be agreed by most networks, transaction process transparency and reliable and
    effective

    data management can be instantly enabled. Without the use of blockchain, the system
    will

    require a centralized repository and will be vulnerable to security threats. Moreover,
    it is

    difﬁcult to incentivize the recycling and reuse of wastewater in industries and
    households

    without the concept of tokens/credits in the form of a cryptocurrency. The wastewater

    treatment anomaly detection algorithm is used to diagnose irregular actions (anomalies)

    and water activities not seen regularly. These can result from attacks on control
    components,

    a network, or the physical surroundings; failures; misconﬁgurations; or even standard
    bugs

    in the IoT sensors. Therefore, the ability to detect anomalies acts as a protective
    tool and

    helps to build and sustain.

    The signiﬁcant contributions of this paper include:

    1.

    Designing an IoT-WMS for wastewater re-treatment and management to fulﬁl the

    water needs in a smart city.

    2.

    Suggesting a blockchain technology for the reuse of wastewater in smart cities.

    3.

    The anticipated cost-effectiveness and reliability of outputs compared to the
    current

    model undoubtedly eliminates conventional worldwide wastewater management.

    The rest of the paper is structured as follows: Section 1 introduces the concept
    of

    wastewater management in a smart city. Section 2 presents a discussion on related
    work.

    Section 3 explores the IoT-WMS framework to improve wastewater management and

    encourage recycling wastewater in smart cities. Section 4 elaborates on the results
    and

    discussion based on an analysis in Section 3. Section 5 concludes the research
    with some

    future perspectives.

    Electronics 2023, 12, 2590

    3 of 14

    2. Related Work

    In this section, we present some recent related works and establish their relevance
    to

    our proposed approach. A summary of related work is also presented in Table 1.

    Table 1. Summary of related work.

    Related Work

    Problem Addressed

    Technique Employed

    Vibhas Sukhwani et al. (2020) [17]

    Fresh and eastewater resource management

    in the rural–urban divide

    Knowledge-based conceptual framework

    H. K. Pandey et al. (2020) [18]

    Determining physio-chemical parameters

    from samples of groundwater

    Monitoring the water quality index

    using a geographical information system

    B. Essex et al. (2020) [19]

    Measuring water-related indicators

    to meet clean water and sanitation SDGs

    Proposed a national

    blueprint framework (NBF)

    with 24 water-related indicators

    María C et al. (2020) [20]

    Overview of challenges in

    wastewater management

    Analysis of biomarkers in wastewater

    to assess the health of the population

    Spirandelli et al. (2019) (2020) [21]

    On-site decentralized waste

    water management

    Gap analysis to show deﬁciencies

    in on-site wastewater management

    Congcong et al. (2020) [22]

    Real-time control of

    urban water cycle

    Cyber physical system

    Nie et al. (2019) [5]

    Sustainable smart city

    wastewater treatment

    Big data analytics and IoT

    Sathishkumar et al. (2020) [6]

    Nutrient water supply prediction

    for fruit production

    Artiﬁcial Neural Networks (ANNs)

    Jeong et al. (2020) [23]

    Comparative evaluation of

    urban water management

    Water Metabolism Framework (WMF)

    Landa-Cansigno et al. (2020) [24]

    Efﬁciency evaluation of

    water recycling techniques

    Framework of

    urban water metabolism (UWM)

    and water–energy–pollution

    nexus (WEPN)

    Ojagh et al. (2021) [25]

    Improvement of prediction accuracy

    in an IoT-based monitoring system

    Hybrid edge–cloud preprocessing framework

    Vibhas Sukhwani et al. [17] discussed the development of smart urban–rural linkages

    in a metropolitan area using a water–energy–food nexus-based conceptual approach.
    To an-

    swer this necessity, they presented a conceptual knowledge framework (KCF) that
    provides

    an overview of the water supply ﬂow within the NMA between urban and rural areas.

    The study shows feasible guidance for intelligently linking future developments
    in smart

    cities with the adjacent Rurban Cluster based on the developed framework. The
    study also

    visualized the water, energy, and food linkages between the urban and rural divide.

    H. K. Pandey et al. [18] suggested the GIS and water quality index for groundwater

    quality assessments of a smart city. A water quality index and geographic information

    system was used to determine groundwater samples’ physico-chemical parameters
    for

    drinking purposes. The contamination level in the area was exacerbated by groundwater

    exploitation, urban planning, and anthropogenic practices.

    B. Essex et al. [19] introduced the national blueprint framework (NBA) for the
    Sustain-

    able Development Goals to monitor progress on water-related goals in Europe. The
    17 Sus-

    tainable Development Goals (SDGs), endorsed by 169 countries, face signiﬁcant
    obsta-

    cles in adoption by national governments. A national blueprint framework (NBF)
    with

    24 water-related indicators based on SDG Six, each with a speciﬁc goal, was created.

    María C et al. [20] inferred wastewater management using paradigm shifts and current

    challenges. Wastewater is a major environmental and public health concern, and
    since

    ancient times, its management has been a relentless task. In recent decades, drainage

    analysis has grown exponentially. This paper offered a global review of growing
    wastewater

    science to recognize existing problems and paradigm shifts. Wastewater studies
    can answer

    global issues, such as the public approval of water conservation or access for
    almost

    one-third of the world’s population to basic sanitation.

    The authors of [21] developed decentralized wastewater based on a management

    policy gap analysis. On-site wastewater treatment (OWTS) schemes have been planned

    for the decentralization of wastewater on site. The study indicates a lack of
    coordination

    Electronics 2023, 12, 2590

    4 of 14

    between land use and water baseline preparation, efﬁciency priorities, system
    inventories,

    public outreach, homeowner education, routine inspections, and maintenance processes.

    In [22], the author suggests a cyber-physical systems management framework (CPSMF)

    for real-time control of the urban underwater cycle. Vital infrastructure, or
    urban life

    functioning, needs to be installed in the urban water cycle (UWC), including the
    water

    supply systems and the urban drainage system (UDS). This paper suggests a CPS-based

    management framework that allows control, interoperability, and automated optimization

    of the UWC to maximize the beneﬁts from CPSs.

    The author of [5] introduces Big Data analytics and the IoT into operation safety

    management underwater. An intelligent society such as a smart city is deﬁned by
    a place

    where people live well, plan their lives long term, ensure sustainability, and
    do the least

    harm to the physical environment by ICTs. This paper analyses the Supervisory
    Controller

    and Data Acquirement (SCADA) approach to sustainable smart city water treatment
    based

    on the Internet of Things and Big Data Analytics. Big data analysis is a new technological

    term implying the processing of vast volumes of relevant data from installed IoT
    sensors to

    monitor the device’s physical status, utilization, and efﬁciency.

    Seongpil Jeong et al. [23] used a Water Metabolism Framework (WMF) to evaluate
    ur-

    ban water management in a comparative analysis of three regions. In Korea and
    elsewhere,

    sustainable water conservation focuses on water conservation and reuse, as the
    climate

    and environmental transitions raise the importance of water insecurity. In Ulsan,
    water

    is being abstracted. The river’s water supply is less sustainable and more vulnerable
    to

    weather threats than Seoul, thus making Ulsan’s water infrastructure less sustainable
    and

    more vulnerable.

    Oriana Landa-Cansigno et al. [24] discussed the integrated framework of the urban

    water metabolism (UWM) and the water–energy–pollution nexus (WEPN) for an efﬁciency

    evaluation of water recycling techniques. This paper analyses metabolic efﬁciency
    and its

    effect on a variety of centralized and decentralized water reuse policies and
    the WEPN on

    integral UWSs. The ﬁndings suggest a metabolism measurement of the output in a
    complex

    system such as an UWS will illustrate the degree of the interactions among the
    nexus (e.g.,

    water, energy, and pollution) components.

    IoT-based systems employed in applications similar to wastewater management sys-

    tems, e.g., air quality monitoring systems, exhibit a loss in accuracy compared
    to the

    traditional measurement systems due to missing values and noisy data. The authors
    of [25]

    improved the prediction accuracy of a real-world IoT-based air quality monitoring
    system

    using a hybrid edge–cloud preprocessing framework.

    3. Proposed Model: IoT-Based Wastewater Management System (IoT-WMS)

    The prospect of water shortages is worrying as population growth rises. This has

    sparked the notion of wastewater reuse and recycling. Sensors may therefore be
    used

    for processing and monitoring at various stages of wastewater management. A com-

    prehensive literature survey leads the research for developing an IoT-WMS framework.

    The IoT-WMS concentrates on cloud security using blockchain technology for the
    intelli-

    gent wastewater management schemes followed by smart cities. This IoT-WMS proposes
    a

    trading system based on the use of blockchain rewards for wastewater recycling.
    Every

    household/industry in the smart city enables the IoT-based wastewater management
    strat-

    egy with sensors and actuators. The basic conceptual structure of the IoT in wastewater

    management for smart cities is shown in Figure 1.

    Figure 1 shows the wastewater management cycle with efﬁcient cloud data visualiza-

    tion for decision making. The decision support system performs token (cryptocurrency)

    allocation to households/industries regarding the volume of recycled wastewater.
    Based

    on their requirement to reach a minimum threshold volume, households/industries
    later

    resell these tokens. In a smart contract, the guidelines for the token exchange
    are estab-

    lished. Data stored on a blockchain-enabled cloud give inviolable auditing. The
    smart

    contracts often provide an automatic tracking framework with a secure cloud. Supervised

    Electronics 2023, 12, 2590

    5 of 14

    and unsupervised learning algorithms are used to detect the manipulation of information

    on wastewater recycling in IoT meters by individuals to ensure the robustness
    of this

    model. Effective home automation allows the best usage of water and thereby increases

    the performance of the water delivery system and its services. For anomaly identiﬁcation,

    this study utilizes a polynomial regression analysis algorithm. This anomaly monitoring

    model has been implemented to detect theft in energy consumption power meters.
    The

    time-series data are the meter readings, so a sequential learning model has been
    considered

    in this work. The IoT helps gain access to knowledge and makes signiﬁcant decisions
    by

    obtaining various sensor values such as soil moisture, water levels, etc.

    Figure 1. Domestic wastewater management cycle in smart cities.

    3.1. Wastewater Management Architecture with Blockchain Technology

    The smart wastewater management framework based on blockchain technology con-

    sists of ﬁve layers, as shown in Figure 2.

    The ﬁrst layer, named the sensor layer, establishes the various IoT sensors for
    mon-

    itoring water usage and wastewater recycling. The data captured through these
    sensors

    are considered in the second layer called the data collection layer. In this layer,
    various

    industry/household facilities from layer 1, such as pipelines attached with level
    gauges,

    water meters attached water storage tanks, and smart wastewater treatment units
    ﬁtted

    with IoT-based intelligent objects, are able to sense, track, analyze, acquire,
    and interact

    with data concerning the level of water storage, the quantity of water usage,
    the volume

    of wastewater generation, and its recycling volume. The gathered information is
    further

    transmitted to the third layer, the edge computing layer attached with edge nodes/smart

    gateways, through accessible internet services such as WiFi, 4G, and 5G for computation,

    decision making, collaborative ﬁltering, and transient data storage over a preconﬁgured

    period of time. Using the edge nodes, the aggregated data items are validated
    through

    smart contracts and added to the blockchain. The edge nodes hand over the validated
    data

    units to the cloud server in the fourth layer: the wastewater blockchain located
    on cloud-

    based servers responsible for collecting, storing, processing, monitoring, and
    managing

    blockchain-technology-assisted security operations handling massive data produced
    from

    different IoT-enabled smart cities. In the ﬁfth layers, frameworks for the management
    and

    monitoring of wastewater treatment for recycling and reuse are present. Through
    smart

    contracts, all parties interested in smart city wastewater management and monitoring
    are

    capable of querying the stored information in the blockchain-enabled cloud. For
    example,

    authorized people can access and visualize the data for decision making.

    Electronics 2023, 12, 2590

    6 of 14

    Figure 2. Architectural diagram of wastewater management with blockchain technology.

    Conceptual Workﬂow of IoT-WMS

    The IoT-WMS framework’s main objective is to oversee and manage the volume

    of smart city wastewater recycling remotely using a wastewater treatment unit
    that ex-

    tracts hazardous chemical liquids maintained by each household/industry in a smart
    city.

    The following are a detailed description of various phases involved in the above
    process:

    Phase 1:

    Smart IoT sensors and actuators are mounted on various observation decks and

    administration devices related to water ﬂow and level monitoring, water collection
    units,

    and wastewater treatment units.

    Phase 2:

    The deployed IoT devices will identify, process, and collect the water storage
    level,

    usage volume, and wastewater recycling in wastewater treatment. The gathered infor-

    mation is communicated to edge devices/nodes through smart gateways with acceptable

    technological innovations such as 4G, 5G, and WiFi.

    Phase 3:

    The edge nodes perform the aggregation of the information gathered by various

    database objects. Furthermore, by executing the authentication process, transient
    data will

    be stored on the blockchain. In parallel, for real-time analytics and decision
    making, it

    activates data processing at the edge nodes.

    Blockchain is a data structure that holds a database from distributed communication.

    Blockchain comprises four main elements that make up its entire architecture.
    The ﬁrst

    element, the decentralized network, is a peer-to-peer (P2P) link between sensor
    nodes.

    The interactions which happen in the system are managed by all the nodes. The
    next

    element, the distributed ledger, is an eternal, incorruptible, and publicly transparent

    archive distributed within network nodes with strengthened traceability. According
    to a

    consensus algorithm, the third element, trades, is checked and conﬁrmed through
    peers in

    the respective network. This assists the ledger in remaining consistent, which
    guarantees

    the ledger modiﬁcation when those network members accept it. The fourth element,
    smart

    contracts, deﬁnes the type of transactions that take place within the network.
    It helps

    Electronics 2023, 12, 2590

    7 of 14

    to exchange tokens/rewards between stakeholders, apply strategies, or deﬁne resource

    user privileges.

    As the application framework for implementing approved blockchain networks, Hy-

    perledger Fabric has been used [26–28]. It is an open-source, certiﬁed, distributed
    applica-

    tion framework built on blockchain that enables developers to create and deploy
    distributed

    services. The Composer tool is applicable for constructing the logic of the management

    platform. Smart contracts are distributed on all endorser nodes of the network
    in a Fabric

    network, and the peers check the transfers as shown in Figure 3. If the transaction
    is

    ofﬁcially accepted, it is attached to the ledger and then exchanged with all network
    nodes.

    An authorized blockchain guarantees that when they directly reach the network,
    sectors

    are validated. Except for Bitcoin or Ethereum, Hyperledger Fabric employs a Kafka-based

    consensus rather than Proof-of-Work due to its computation cost. Proof-of-Work
    gives faith

    in a world of trustlessness. The application scenario in this research has a regulatory
    model

    for issuing tokens and rewards, so Proof-of-Work is not needed in this context.

    Figure 3. Flow of Hyperledger transaction.

    Phase 4:

    Each node responsible for validating data units earns a reward for every block
    to be

    authenticated and mined. These rewards (virtual tokens) are traded for different
    bene-

    ﬁts such as obtaining concessions on energy bills, tariffs, taxes, etc. Incentives
    are then

    incorporated into the scheme to encourage clients to support the wastewater management

    program in the smart city and invest in it.

    Phase 5:

    Using smart contracts, the validated data blocks can be submitted to cloud servers

    and logged to the blockchain. The cloud infrastructure can provide big data analysis
    and

    analytics capabilities on the collected data for future monitoring and decision
    making.

    Phase 6:

    Ultimately, to evaluate water consumption, the volume of toxic chemical liquids

    generated, treated, and disposed of by each household/industry in smart cities,
    various

    monitoring and management applications need to be created. In this phase, tokens,
    re-

    ferred to in the Hyperledger Composer as tradable cryptocurrencies, are distributed
    to

    households/industries in the smart city on the basis of their wastewater reuse
    output. The

    Electronics 2023, 12, 2590

    8 of 14

    most productive participant is considered a zero liquid spill strategy and a hundred
    percent

    wastewater is reused in its unit.

    Q f = Vr

    Vp

    , for every member unit in smart city

    (1)

    Q

    ′

    f = q(h, s, o, p),

    (2)

    T = a1 ∗ Q f + a2 ∗ Q

    ′

    f ,

    (3)

    where Q f and Q

    ′

    f denote the quantity and quality factors, respectively. T represents the

    number of tokens to be issued, while a1 and a2 are constant values above the threshold

    values. Tokens are given in compliance with Equations (1)–(3), on the basis of
    the quality

    and quantity of wastewater recycling. For each participant, the threshold criterion
    for

    wastewater recycling differs due to the complexities in treating the various forms
    of toxins.

    When the participant surpasses the threshold, it can trade tokens to other participants
    who

    have not reached the ceiling. Similarly, tokens are often issued to promote greater
    purity of

    ﬁltered water based on efﬁciency.

    3.2. Anomaly Detection

    Anomaly detection is inevitable in IoT-WMS because it detects fraud tampering
    in

    the wastewater management sensor readings. This research extends the study with
    an

    algorithm as follows:

    Polynomial Regression Analysis

    Polynomial regression analysis is an algorithm that forms a relationship between
    two

    variables, such as the input variable (independent), I, and the output variable
    (dependent),

    O. The regression analysis relationship is deﬁned as a polynomial of I in x-th
    degree,

    as shown in (4):

    Om = τ +

    x

    ∑

    i=1

    µiIx

    m + ϵm,

    (4)

    where τ is the threshold reading value, µi denotes the regression factor for i
    ∈ {1, 2, 3, . . . , x},

    and ϵm represents the error rate with m ∈ {1, 2, 3, . . . , n} for n samples.
    If the squared

    difference between the real value and the expected value approaches the threshold
    set

    based on training results, the analysis model predicts the abnormality. The proposed
    IoT-

    WMS improves the quality of recycled water distributed in smart cities and achieves
    a high

    wastewater recycling rate and efﬁciency ratio, a lower moisture content ratio,
    improved

    wastewater reuse, and a higher prediction ratio.

    4. Simulation Results and Discussion

    The proposed IoT-WMS model monitors the recycled wastewater distribution in

    a smart city. Various parameters such as the wastewater recycling rate, the efﬁciency

    ratio, the moisture content ratio, the wastewater reuse ratio, and the prediction
    ratio have

    been considered using the proposed IoT-WMS method. The number of devices used
    for

    numerical simulations ranged from 5 to 30 in increments of 5. Each of these devices
    is

    assumed to have the capability of supporting up to 10 sensors. The simulation
    results

    averaged several random placements of sensors in a two-dimensional space. The
    devices

    are distributed in various stages of the wastewater management system, e.g., storage

    units, drainage units, recycling units, and water consumption units. A blockchain-based

    incentivization method is provided to various stakeholders in a model metropolitan
    area

    and its effect on the above parameters has been analyzed and compared with several

    existing approaches. Periodic monitoring of these parameters is performed using
    a cloud-

    based IoT system.

    Electronics 2023, 12, 2590

    9 of 14

    4.1. Wastewater Recycling Rate

    The wastewater treatment method relies on different factors such as wastewater

    temperature, water velocity, water ﬂow, and pH. The productivity of the treatment
    plant

    improves if these parameters are kept within the necessary limits. These parameters
    must

    be carefully controlled to handle water efﬁciently. The IoT handles the wastewater.
    The IoT

    is a network that can link all devices embedded in electronic systems. Electronic
    IoT systems

    can interact and transfer information with each other. Several physical parameters
    can be

    tracked and communicated to linked equipment such as cell phones and laptops through

    different channels through sensors in wastewater treating plants, such as temperature,

    ﬂow rate, and water level sensors in various tanks. When the sensors sense anomalies

    above the acceptable thresholds of the physical parameters, the IoT can send a
    warning

    to the plant operator via a message or an e-mail and take a control action. Figure
    4 shows

    the wastewater recycling rate for our proposed approach as a function of the number
    of

    IoT devices deployed within a metropolitan area. The recycling rate is also compared

    with several state-of-the-art systems and it has been shown that the performance
    of the

    proposed IoT-WMS system is superior to the existing approaches. Moreover, the
    recycling

    rate improves as the number of deployed devices increases. In other words, the
    availability

    of more measurements and quality feedback helps improve the recycling rate.

    Figure 4. Wastewater recycling rate.

    4.2. Efﬁciency Ratio

    Effective wastewater collection (WC) is a key factor in smart cities’ service.
    Smart cities

    based on an integrated framework of new technologies can use the Internet of Things
    (IoT).

    Monitoring devices could be used as an assistive technology in wastewater collection
    to

    provide a high quality of service (QoS). The following IoT elements are directly
    integrated

    into ITS and waste disposal control systems: (i) RFID, (ii) sensors, (iii) camera,
    and (iv)

    actuators. We suggest IoT-WMS in this paper as an innovative solution to effectively
    store

    wastewater in smart cities. It includes a data management model for real-time
    monitoring

    of pipes to capture wastewater levels and leverage complex pathways.The system
    manages

    inadequate wastewater collection in inaccessible areas in smart cities. Surveillance
    cameras

    are used to capture the trouble areas and to supply the the controllers with evidence.

    The wastewater treatment scheme aims to provide the people of a smart city with
    a high

    standard of operation. Figure 5 shows the efﬁciency ratio for our proposed approach
    as a

    function of the number of IoT devices deployed within a metropolitan area. The
    efﬁciency

    Electronics 2023, 12, 2590

    10 of 14

    ratio is also compared with several state-of-the-art systems and it has been shown
    that

    the performance of the proposed IoT-WMS system is superior to the existing approaches.

    Moreover, the efﬁciency ratio improves as the number of deployed devices increases.

    In other words, the availability of more measurements and quality feedback helps
    improve

    the efﬁciency of the wastewater management system.

    Figure 5. Efﬁciency ratio.

    4.3. Moisture Content Ratio

    The proposed IoT-WMS covers numerous features such as GPS-based remote temper-

    ature and moisture sensing and irrigation equipment. It utilizes wireless sensor
    networks

    to record water characteristics and environmental factors continuously. There
    are multiple

    sensor nodes in a smart city at various points. These parameters are tracked from
    any

    remote computer or internet service, and interface sensors with IoT perform the
    opera-

    tions. This is mainly based on reducing water waste and minimizing manual work
    in the

    irrigation sector to save smart cities’ time, resources, and electricity. The
    system proposes

    to allow farmers to continually track the water levels in water tanks and humidity
    in the

    ﬁeld by remotely monitoring the supply on the internet. When the humidity falls
    below

    a certain level, drip irrigation will be automatically enabled, thereby ensuring
    maximum

    irrigation via the internet. Figure 6 shows the moisture content ratio as a function
    of the

    number of devices. It can be seen that the moisture content ratio is the lowest
    for our

    proposed scheme, with performance of our scheme closest to the UWM-WEPN approach.

    Furthermore, increasing the number of devices yields a lower moisture content
    ratio.

    4.4. Wastewater Reuse Ratio

    Blockchain or distributed ledger is a promising emerging platform that facilitates
    the

    use of a lack of water supplies to store and maintain. The concept of blockchain
    recon-

    ciliation may be a perfect case of inventive reasoning and opportunities for cooperation

    intended to examine the foundational problem of scarcity. The distributed ledger
    should be

    used not only for water use and control of water recovery but can also be used
    to promote

    wastewater sharing and rainwater harvesting for a more prosumer market. Blockchain

    could also be used to develop peer-to-peer water trading networks. Prosumers may
    receive

    wastewater for further treatment, reuse, recycling, and disposal over the water
    processing

    life cycle. Blockchain will radically change the way of handling water supplies,
    from the

    diligent use of renewable and fresh water and water use settlement and payment
    collection

    to water use and frequent reporting. Figure 7 shows the wastewater reuse ratio
    as a function

    Electronics 2023, 12, 2590

    11 of 14

    of the number of devices. The wastewater reuse ratio is the best for our proposed
    system

    relative to other recent approaches. The performance of UWM-WEPN is better than
    the

    rest of the approaches, while CPSMF shows a poor relative performance.

    Figure 6. Moisture content ratio.

    Figure 7. Wastewater reuse ratio.

    Electronics 2023, 12, 2590

    12 of 14

    4.5. Prediction Ratio

    It is necessary to control water in any part of its cycle in smart city water
    management:

    from freshwater abstraction, pretreatment, delivery, use, and collection to post-treatment.

    By removing pollution and changing the way to treat wastewater, the water quality
    will

    be improved. To ensure water safety, IoT-allowed monitoring systems could be deployed.

    Wireless sensors and the anomaly detection algorithm help anticipate leaks, maximizing

    resources, sales, running costs, and pipe repair facilities. Through blockchain
    technologies,

    city companies and city municipalities can monitor water delivery and use in real
    time.

    Through this proposed method, it is possible to track the water quality. Water
    ﬁltration

    devices are used to guarantee the water is of good quality, thus reducing water
    loss.

    Predictive management methods used in water plants ensure that problems contributing

    to the risk of water pipes failing are evaluated rapidly and efﬁciently. Figure
    8 shows the

    prediction ratio. The prediction ratio shows considerable improvement with an
    increasing

    number of IoT devices for all the considered approaches. Furthermore, the predictive

    performance of the proposed IoT-WMS systems is better than the rest of the approaches.
    The

    CPSMF approach shows some promise for lower numbers of devices but its performance

    deteriorates before improving as the IoT devices transition from a moderate value
    to a

    larger number.

    The proposed IoT-WMS improves the quality of recycling water distributed in smart

    cities and achieves a high wastewater recycling rate and efﬁciency ratio, a lower
    mois-

    ture content ratio, improved wastewater reuse, and a better prediction ratio compared
    to

    the cyber-physical systems management framework (CPSMF), the supervisory controller

    and data acquirement (SCADA) approach, the Water Metabolism Framework (WMF),

    the urban water metabolism method (UWM), and the water–energy–pollution nexus

    (WEPN) method.

    Figure 8. Prediction ratio.

    5. Conclusions

    A detailed literature survey helped us to establish a smart wastewater collection

    system for smart cities, namely the IoT-WMS system concentrated on cloud protection
    and

    Electronics 2023, 12, 2590

    13 of 14

    leveraging blockchain technologies. This IoT-WMS uses a trading scheme focused
    on the

    recovery of wastewater using blockchain incentives. Sensors and actuators make
    the IoT-

    based wastewater management strategy available for all households/industries in
    the smart

    city. Compared to existing models, the proposed IoT-WMS for wastewater treatment
    and

    recycling water quality in smart cities achieved a high wastewater recycling rate
    of 96.3%,

    an efﬁciency ratio of 88.7%, a low moisture content ratio of 32.4%, an increased
    wastewater

    reuse of 90.8%, and a prediction ratio of 92.5%. The proposed approach has limitations

    when it comes to the interworking of such systems deployed by several metropolitan

    and/or rural areas. A framework to incentivize wastewater quality improvement
    is more

    useful if it allows for reward tokens to be redeemable across various industrial
    sectors and

    facilities. A future extension of this study is to expand the system with in-depth
    learning

    assistance for wastewater management in smart cities using deep learning technology.

    Author Contributions: All authors substantially contributed towards the methodology,
    validation,

    formal analysis, and preparation of the original draft. All authors have read
    and agreed to the

    published version of the manuscript.

    Funding: The authors extend their appreciation to the deanship of scientiﬁc research
    at Shaqra

    University for funding this research work through the project number (SU-ANN-202205).

    Data Availability Statement: Not applicable.

    Conﬂicts of Interest: The authors declare no conﬂicts of interest.

    References

    1.

    Srivastava, A.; Grotjahn, R.; Ullrich, P.A.; Risser, M. A uniﬁed approach to evaluating
    precipitation frequency estimates with

    uncertainty quantiﬁcation: Application to Florida and California watersheds. J.
    Hydrol. 2019, 578, 124095. [CrossRef]

    2.

    Khan, M.T.R.; Jembre, Y.Z.; Ahmed, S.H.; Seo, J.; Kim, D. Data freshness based
    AUV path planning for UWSN in the internet of

    underwater things. In Proceedings of the 2019 IEEE Global Communications Conference
    (GLOBECOM), Waikoloa, HI, USA,

    9–13 December 2019; pp. 1–6.

    3.

    Yaqub, M.A.; Ahmed, S.H.; Bouk, S.H.; Kim, D. Towards energy efﬁcient duty cycling
    in underwater wireless sensor networks.

    Multimed. Tools Appl. 2019, 78, 30057–30079. [CrossRef]

    4.

    Moon, E.; Khan, M.T.R.; Park, H.; Ahmed, S.H.; Lee, S.; Kim, D. OMRI–MAC: Optimized
    multi-transmission receiver-initiated

    MAC in underwater wireless sensor networks. Wirel. Pers. Commun. 2019, 107, 1491–1505.
    [CrossRef]

    5.

    Nie, X.; Fan, T.; Wang, B.; Li, Z.; Shankar, A.; Manickam, A. Big data analytics
    and IoT in operation safety management in under

    water management. Comput. Commun. 2020, 154, 188–196. [CrossRef]

    6.

    Sathishkumar, V.; Venkatesan, S.; Park, J.; Shin, C.; Kim, Y.; Cho, Y. Nutrient
    water supply prediction for fruit production in

    greenhouse environment using artiﬁcial neural networks. In Basic & Clinical Pharmacology
    & Toxicology; Wiley: Hoboken, NJ,

    USA, 2020; Volume 126, pp. 257–258.

    7.

    Venkatesan, S.; Sathishkumar, V.; Park, J.; Shin, C.; Cho, Y. A Prediction of
    nutrition water for strawberry production using linear

    regression. Int. J. Adv. Smart Converg. 2020, 9, 132–140.

    8.

    Sundarasekar, R.; Shakeel, P.M.; Baskar, S.; Kadry, S.; Mastorakis, G.; Mavromoustakis,
    C.X.; Samuel, R.D.J.; Gn, V. Adaptive

    energy aware quality of service for reliable data transfer in under water acoustic
    sensor networks. IEEE Access 2019, 7, 80093–80103.

    [CrossRef]

    9.

    Gupta, O.; Goyal, N.; Anand, D.; Kadry, S.; Nam, Y.; Singh, A. Underwater networked
    wireless sensor data collection for

    computational intelligence techniques: Issues, challenges, and approaches. IEEE
    Access 2020, 8, 122959–122974. [CrossRef]

    10.

    Khan, W.A.; Khan, M.I.; Kadry, S.; Farooq, S.; Khan, M.I.; Abbas, S.Z. Transportation
    of water-based trapped bolus of SWCNTs

    and MWCNTs with entropy optimization in a non-uniform channel. Neural Comput.
    Appl. 2020, 32, 13565–13576. [CrossRef]

    11.

    Salami, A.F.; Adedokun, E.A.; Al-Turjman, F.; Bello-Salau, H.; Sadiq, B.O.; Dogo,
    E.M. Explorative analysis of AUV-aided

    cluster-based routing protocols for Internet of intelligent underwater sensors.
    In Drones in Smart-Cities; Elsevier: Amsterdam,

    The Netherlands, 2020; pp. 143–187.

    12.

    Deebak, B.D.; Al-Turjman, F. Aerial and underwater drone communication: Potentials
    and vulnerabilities. In Drones in Smart-Cities;

    Elsevier: Amsterdam, The Netherlands, 2020; pp. 1–26.

    13.

    Krishnaraj, N.; Elhoseny, M.; Thenmozhi, M.; Selim, M.M.; Shankar, K. Deep learning
    model for real-time image compression in

    Internet of Underwater Things (IoUT). J. Real-Time Image Process. 2020, 17, 2097–2111.
    [CrossRef]

    14.

    Shankar, K.; Elhoseny, M.; Shankar, K.; Elhoseny, M. An optimal singular value
    decomposition with LWC-rectangle block cipher

    based digital image watermarking in wireless sensor networks. In Secure Image
    Transmission in Wireless Sensor Network (WSN)

    Applications; Springer: Cham, Switerland, 2019; pp. 83–98.

    Electronics 2023, 12, 2590

    14 of 14

    15.

    Saraˇcevi´c, M.; Adamovi´c, S.; Maˇcek, N.; Elhoseny, M.; Sarhan, S. Cryptographic
    keys exchange model for smart city applications.

    IET Intell. Transp. Syst. 2020, 14, 1456–1464. [CrossRef]

    16.

    Amin, F.; Abbasi, R.; Mateen, A.; Ali Abid, M.; Khan, S. A Step toward Next-Generation
    Advancements in the Internet of Things

    Technologies. Sensors 2022, 22, 8072. [CrossRef] [PubMed]

    17.

    Sukhwani, V.; Shaw, R. A Water-Energy-Food Nexus based Conceptual Approach for
    Developing Smart Urban-Rural Linkages in

    Nagpur Metropolitan Area, India. IDRiM J. 2020, 10, 1–22. [CrossRef]

    18.

    Pandey, H.; Tiwari, V.; Kumar, S.; Yadav, A.; Srivastava, S. Groundwater quality
    assessment of Allahabad smart city using GIS

    and water quality index. Sustain. Water Resour. Manag. 2020, 6, 28. [CrossRef]

    19.

    Essex, B.; Koop, S.; Van Leeuwen, C. Proposal for a national blueprint framework
    to monitor progress on water-related sustainable

    development goals in Europe. Environ. Manag. 2020, 65, 1–18. [CrossRef] [PubMed]

    20.

    Villarín, M.C.; Merel, S. Paradigm shifts and current challenges in wastewater
    management. J. Hazard. Mater. 2020, 390, 122139.

    [CrossRef] [PubMed]

    21.

    Spirandelli, D.; Dean, T.; Babcock, R., Jr.; Braich, E. Policy gap analysis of
    decentralized wastewater management on a developed

    paciﬁc island. J. Environ. Plan. Manag. 2019, 62, 2506–2528. [CrossRef]

    22.

    Sun, C.; Puig, V.; Cembrano, G. Real-time control of urban water cycle under cyber-physical
    systems framework. Water 2020,

    12, 406. [CrossRef]

    23.

    Jeong, S.; Park, J. Evaluating urban water management using a water metabolism
    framework: A comparative analysis of three

    regions in Korea. Resour. Conserv. Recycl. 2020, 155, 104597. [CrossRef]

    24.

    Landa-Cansigno, O.; Behzadian, K.; Davila-Cano, D.I.; Campos, L.C. Performance
    assessment of water reuse strategies using

    integrated framework of urban water metabolism and water-energy-pollution nexus.
    Environ. Sci. Pollut. Res. 2020, 27, 4582–4597.

    [CrossRef]

    25.

    Ojagh, S.; Cauteruccio, F.; Terracina, G.; Liang, S.H. Enhanced air quality prediction
    by edge-based spatiotemporal data

    preprocessing. Comput. Electr. Eng. 2021, 96, 107572. . [CrossRef]

    26.

    Attia, O.; Khouﬁ, I.; Laouiti, A.; Adjih, C. An IoT-blockchain architecture based
    on hyperledger framework for health care

    monitoring application. In Proceedings of the NTMS 2019-10th IFIP International
    Conference on New Technologies, Mobility and

    Security, Canary Islands, Spain, 24–26 June 2019; pp. 1–5. [CrossRef]

    27.

    Corradini, E.; Nicolazzo, S.; Nocera, A.; Ursino, D.; Virgili, L. A two-tier Blockchain
    framework to increase protection and

    autonomy of smart objects in the IoT. Comput. Commun. 2022, 181, 338–356. [CrossRef]

    28.

    Capocasale, V.; Gotta, D.; Musso, S.; Perboli, G. A Blockchain, 5G and IoT-based
    transaction management system for Smart

    Logistics: An Hyperledger framework. In Proceedings of the 2021 IEEE 45th Annual
    Computers, Software, and Applications

    Conference (COMPSAC), Madrid, Spain, 12–16 July 2021; pp. 1285–1290. [CrossRef]

    Disclaimer/Publisher’s Note: The statements, opinions and data contained in all
    publications are solely those of the individual

    author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or
    the editor(s) disclaim responsibility for any injury to

    people or property resulting from any ideas, methods, instructions or products
    referred to in the content.

    '
  inline_citation: '>'
  journal: Electronics
  limitations: '>'
  pdf_link: https://www.mdpi.com/2079-9292/12/12/2590/pdf?version=1686208106
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Internet of Things (IoT)-Based Wastewater Management in Smart Cities
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.48175/ijarsct-9463
  analysis: '>'
  authors:
  - Prof. Anand Ingle
  - Priyanka Gupta
  - Nachiket Gaikwad
  - Sanika Bhatye
  citation_count: 0
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International Journal of Advanced Research in Science, Communication and
    Technology
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Precision Agriculture Application using Machine Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.14419/ijet.v12i2.32335
  analysis: '>'
  authors:
  - Saloni Kumari
  citation_count: 0
  full_citation: '>'
  full_text: ">\n \nCopyright © Saloni Kumari. This is an open access article distributed\
    \ under the Creative Commons Attribution License, which permits \nunrestricted\
    \ use, distribution, and reproduction in any medium, provided the original work\
    \ is properly cited. \n \n \nInternational Journal of Engineering & Technology,\
    \ 12 (2) (2023) 26-30 \n \nInternational Journal of Engineering & Technology \n\
    \ \nWebsite: www.sciencepubco.com/index.php/IJET  \n \nResearch paper \n \n \n\
    \ \n \nData integration: “Seamless data harmony: The art  \nand science of effective\
    \ data integration” \n \nSaloni Kumari * \n \nSoftware Engineer II at EY (Ernst\
    \ & Young), Hyderabad, India \n*Corresponding author E-mail: salonisingh899@gmail.com\
    \ \n \n \nAbstract \n \nThe idea of data integration has evolved as a key strategy\
    \ in today's data-driven environment, as data is supplied from various and hetero-\n\
    geneous sources. This article explores the relevance, methodology, difficulties,\
    \ and transformative possibilities of data integration, delving \ninto its multidimensional\
    \ world. Data integration serves as the cornerstone for well-informed decision-making\
    \ by connecting heterogeneous \ndatasets and fostering unified insights. This\
    \ article gives readers a sneak preview of the in-depth investigation into data\
    \ integration, illumi-\nnating its technical complexities and strategic ramifications\
    \ for companies and organizations looking to maximize the value of their data\
    \ \nas-sets. \n \nKeywords: Data Analytics; Data Processing; Data Storage; NoSQL\
    \ Database; Distributed Computing; Scalability; Fault Tolerance; Data Warehousing;\
    \ \nData Ingestion; Workflow Scheduler; Coordination Service; Big Data Architecture;\
    \ Hadoop Ecosystem. \n \n1. Introduction \nIt is obvious that our society is driven\
    \ by data, and as we steadily move toward fully digitalized lives, data is becoming\
    \ a valuable resource \nfor the contemporary economy. We create important data\
    \ whenever we use the internet to make purchases, view content, or share it on\
    \ \nsocial media. Many of the biggest internet companies increasingly rely on\
    \ data-driven business models to run their operations. However, \nwithout data\
    \ integration, none of it is possible. Data integration is the glue that allows\
    \ raw data to be transformed into an asset. Lack of \ndata integration results\
    \ in a host of business issues. \nDue to fragmented data silos between organizations\
    \ or departments within companies, it becomes necessary for users to rekey data\
    \ or \nduplicate their efforts. Making decisions may be difficult in the absence\
    \ of uniform data views. When individuals or departments only have \npartial access\
    \ to data, they frequently make judgments that don't consider the overall process\
    \ and are therefore suboptimal. Businesses \nwaste a lot of money due to inefficiencies\
    \ and bad decisions that result from poor data integration. Techniques for data\
    \ integration aid in \nminimizing these issues. The process of obtaining data\
    \ from many sources and transforming it into a data store or business application\
    \ so \nthat it can be used more efficiently is known as data integration. Three\
    \ different kinds of data integration exist: Business-to-business \nintegration\
    \ entails cross-organizational linkages to improve the efficiency of business\
    \ transactions between trading partners. The goal of \napplication integration\
    \ is to connect different corporate applications to create an integrated process.\
    \ The data store itself is the level at \nwhich database integration takes place.\
    \ Building pipelines to transfer raw data between data stores falls under this\
    \ category. When devel-\noping data warehouses and business intelligence systems,\
    \ this kind of integration is used. In the contemporary workplace, all three forms\
    \ \nof integration are regularly used and are very beneficial to comprehend. In\
    \ the current business environment, businesses that excel at data \nintegration\
    \ will have a significant competitive advantage. \nLet's imagine a producer of\
    \ agricultural equipment wants to use the information gathered by its tractors\
    \ to improve crop yields. Perhaps \nsensors on the tractors can assess the soil\
    \ moisture. The producer may gather this information from all of their tractors\
    \ and integrate it with \ninformation from other sources, such as weather or commodity\
    \ market prices. The ultimate result may be advice for farmers on how to \nimprove\
    \ the efficiency of their irrigation systems to maximize harvests, or the data\
    \ could even be sold to outside parties like hedge funds \nto assist them in making\
    \ smarter investment choices. This may develop into a new revenue stream for the\
    \ corporation that would eventually \ncomplement or even outperform its current\
    \ business strategy. That is an illustration of how digitization may be used to\
    \ transform industries, \nand it all hinges on data fusion. \n2. Research methodology\
    \ \n2.1. Business integration \nBusiness to business, or B2B, integration permits\
    \ the electronic interchange of commercial transactions between two or more trading\
    \ \npartners, such as orders or payments. To accommodate certain scenarios, B2B\
    \ messaging occasionally needs the extra flexibility provided \nInternational\
    \ Journal of Engineering & Technology \n27 \n \nby XML or API standards. As businesses\
    \ rely more and more on alliances or intricate supply chains to hasten entrance\
    \ into new markets \nand boost competitive advantages without B2B messaging, B2B\
    \ integration is becoming more and more crucial. The players in the supply \n\
    chain ultimately communicate manually via email or by sharing Excel attachments.\
    \ \nB2B enables unconnected businesses to link their separate business systems\
    \ into a cohesive workflow. A customer could send a B2B \ncommunication, including\
    \ a purchase order, to the supplier's production system from their ERP system.\
    \ A purchase order acknowledgement \nmay be sent to the customer automatically\
    \ by the supplier system after checking production schedules. Trading partners\
    \ can handle large \nnumbers of transactions with less labor-intensive manual\
    \ labor and less error-prone automation. \nSince it must handle the extra challenges\
    \ of delivering data across corporate boundaries, B2B integration differs from\
    \ application-to-\napplication integration and intra-company database connections.\
    \ \nB2B integrations must check trading partner communications for compliance\
    \ with CDI requirements, acknowledge trade partners, monitor \nthe progress of\
    \ messages, and transmit data securely. \n2.2. Application integration \nAny type\
    \ of software used to carry out tasks is referred to as an application. This includes\
    \ corporate applications like CRM or ERP, iPhone \nor Android mobile apps, and\
    \ cloud services like MailChimp or Google Analytics. Due to how essential software\
    \ has become to our every-\nday lives, it is usually required to use many applications\
    \ to execute activities. These programmes are connected by application integration,\
    \ \nwhich creates an efficient workflow. \n2.3. Database integration \nSimply\
    \ merging data from numerous sources into one unified perspective to produce insights\
    \ might be referred to as database integration. \nIt gathers information from\
    \ many sources and changes it into something more worthwhile and beneficial. \n\
    Most database integration strategies fit into one of these groups. Data from different\
    \ storage locations is combined into one data repository \nthrough data consolidation.\
    \ ETL, or extract, transform, and load, is a typical strategy for data consolidation.\
    \ A specific type of data con-\nsolidation called data warehousing gathers data\
    \ from numerous systems and merges it into a single storage engine that is intended\
    \ to allow \nanalytical queries. \nMoving data from one place to another is known\
    \ as data propagation, and replication is a frequent type of data propagation.\
    \ \nReplication tools that can automatically sync data from an origin source to\
    \ a destination source are available in the majority of relational \ndatabases.\
    \ This is frequently used to help with disaster recovery or boost data access\
    \ performance. In contrast to data consolidation, which \ntransfers data into\
    \ a single data source, data virtualization offers a single view of data across\
    \ multiple data sources. Users can operate with \na façade that is created through\
    \ data virtualization. Behind the scenes, it retrieves data from the many data\
    \ sources. \nIn contrast to data virtualization, data federation enforces a single\
    \ data model across all of the diverse data sources. Database workloads \nare\
    \ frequently divided into one of two categories: LTP or OLAP. \nA database that\
    \ handles common corporate transactions, such as an ERP or CRM system, is referred\
    \ to as old TPE, or online transaction \nprocessing. A mix of database reads and\
    \ writes involving recent business transactions, such as orders or leads, is typical\
    \ of old-style \nworkloads. \nOnline analytical processing, or OLAP, is primarily\
    \ concerned with reporting and analytics. OLAP tasks entail database reads across\
    \ big \ndata sets, such as queries on the daily average of orders over the last\
    \ 12 months. \nData warehouses are made to serve these OLAP workloads. For instance,\
    \ getting data from the billing system would require a very time-\nconsuming query\
    \ if we needed a report that compared the total revenue for this year to the previous\
    \ year. \nIt might be necessary to add up millions of bills from the previous\
    \ two years. Or perhaps there are different billing systems in use in various\
    \ \nlocations, and the revenue figures need to be added together to provide a\
    \ whole picture. All of these data sources would be combined into \na database\
    \ with a data warehouse, allowing for rapid queries on millions of entries. These\
    \ queries can be executed far more quickly than \nsource systems using certain\
    \ technologies. They sometimes combine the outcomes. \nThis implies that the billions\
    \ of billing transaction rows are condensed in a batch process, and the annual\
    \ revenue total is saved in the \ndatabase as a single figure for easy retrieval.\
    \ \nStar schemas, which describe the arrangement of tables and columns in the\
    \ database, are frequently used by data warehouses for their data \nmodels. In\
    \ a star schema, data is kept in two types of tables: facts and dimensions. Fact\
    \ tables keep track of important financial data like \nincome. This design results\
    \ in a large number of rows for the fact table and a relatively smaller number\
    \ of rows for the dimension tables, \nwhich makes for simpler queries, query performance\
    \ gains, and faster aggregations, operations where you sum up rows, like in our\
    \ example, \nwhere we needed the total revenue for a year. This design results\
    \ in many rows for the fact table and a relatively smaller number of rows \nfor\
    \ the dimension tables.  \nData warehouses are frequently replaced by technologies\
    \ like Hadoop or Spark. By splitting data over clusters of servers rather than\
    \ \ntransforming and loading data into a data warehouse, Hadoop enables rapid\
    \ queries on extremely big datasets. \n2.4. ETL extract, transform, load \nETL,\
    \ which stands for Extract, Transform, and Load, is the procedure for loading\
    \ a data warehouse and entails polling data from the source \nsystems and putting\
    \ it into a staging area. \nTo transform data is to prepare it ready for loading\
    \ into the target system. And loading refers to putting data into the intended\
    \ system. \nThe process of extracting involves taking data from multiple source\
    \ systems and putting it into processing staging regions. On-site source \nsystems\
    \ are an example of a source system. ERP programmes such as SAP, cloud applications\
    \ such as Salesforce, CSV files, or SQL \ndatabases. The business's operating\
    \ data is contained in these source systems. For huge data sets, care must be\
    \ taken not to negatively affect \nthe performance of the source system. The extract\
    \ process will read data from these systems using a variety of ways and write\
    \ the data into \na file system or database for the following stage in the processing\
    \ pipeline. Typically, data is retrieved from these extracts in its original \n\
    format and promptly stored in new staging storage in that format before any transformations\
    \ are applied. This lowers the amount of com-\nputer power needed to extract the\
    \ data from the source system. Although the full data set may occasionally be\
    \ recovered in one batch from \nthe source system, it is typically preferable\
    \ to use a change data capture process in the source system. to handle newly added,\
    \ updated, or \nremoved records. Data must be transformed before being put into\
    \ the target system. Data transformations can take a variety of forms. First,\
    \ \n28 \nInternational Journal of Engineering & Technology \n \ndata purification\
    \ is required for this type of transformation to prevent the loading of faulty\
    \ data into the target system. Eliminating faulty \nrecords, getting rid of duplicates,\
    \ or resolving formatting issues are common cleansing chores. \nEnrichment of\
    \ data is frequently essential to enrich the source data before it is loaded.\
    \ This entails adding information to the data that was \nnot included in the source\
    \ system but is required to be loaded into the target system. For instance, the\
    \ customer's address might be provided \nby the source system, but the target\
    \ system might need the GPS coordinates, latitude, and longitude of the address\
    \ to geocode the address \ndata and collect GPS coordinates prior to loading data.\
    \ \nLarge data sets can be put into the target database after the data has been\
    \ extracted and converted. Even while it's common to write data \ninto a relational\
    \ database using SQL statements like insert, update, and delete, loading 300,000\
    \ insert statements to load 300,000 records \nfor an ETL task will be slow and\
    \ use resources on the target system that could have an influence on performance.\
    \ Many databases have \nspecialized bulk load capabilities that assist in the\
    \ effective loading of massive data sets. \nManaging master data and foreign key\
    \ relationships is one frequent problem. In a database, master data refers to\
    \ reference information that \nis used across several tables. \nA foreign key\
    \ is a referential integrity database constraint that makes sure a reference value\
    \ from one table is present in another related \ntable. When loading new orders\
    \ in an e-mail process, for instance, a customer mentioned on an order must be\
    \ present in the customer \nmaster table. It is important to manage the key correctly\
    \ since it links the orders customer field to the customer master table. In data\
    \ \nwarehouses, certain kinds of data links are handled in a specific fashion.\
    \ In fact, tables linked to the dimensions by a foreign key, master \ndata is\
    \ frequently kept in dimension tables. \nMaster data changes over time, as well\
    \ as their connections to business operations, are frequently captured using a\
    \ technique termed \"slowly \nevolving dimensions.\" \nThe most common way to\
    \ enter data into data warehouses is through ETL. However, the procedure is frequently\
    \ referred to as LTE, or \nextract, load, and transform, when working with data\
    \ lakes. \nThis is because the data is directly fed into the data system after\
    \ being extracted from the source system. The lake is transformed at query \n\
    time. The ETL process is normally done during a period of low activity that will\
    \ not affect business users of the business information \ncommonly held in a data\
    \ warehouse. Data warehouse ETL processes are typically batch-focused, possibly\
    \ once a day or once a week. \nGiven that a data warehouse is typically used for\
    \ operational or financial analyses, this makes sense. \nTechnically speaking,\
    \ real-time OLAP is far more difficult to construct than batch based typical OLAP\
    \ systems. Real-time analysis can be \ndone in many ways. \nApache Spark is a\
    \ popular framework for implementing streaming analytics. Real-time streaming\
    \ analytics uses Spark streaming to absorb \nsmall batches of data and transform\
    \ them into a searchable data store. Most event-driven data stores, like Apache\
    \ Kafka, have built-in \nhandlers in tools like Sparke. \nETL procedures can be\
    \ designed and carried out using a wide range of ETL tools, some of which are\
    \ incorporated into database systems. \nAn example of this is SQL Server Integration\
    \ Services, which executes a workflow comprising data sources, data targets, and\
    \ data flow \nactivities. It may be used to connect to a wide variety of databases\
    \ and data sources despite being strongly integrated with SQL Server. An \nopen\
    \ source ETL tool called Taloned supports many different types of databases. Open\
    \ Studio for Windows or Mac can be downloaded \nfor free. It also features a graphic\
    \ designer and allows connectivity with SaaS providers, packaged software apps,\
    \ and data sources like \nDropbox. \nAlthough Apache NiFi is not explicitly an\
    \ ETL tool, given its versatility, it generally automates data transfers across\
    \ systems. It could be \nused for both database and application integration. The\
    \ vast array of data sources that NiFi provides processors for includes on-premises\
    \ \ndatabases, big data platforms, and cloud services. \nThe two most well-known\
    \ cloud providers, Amazon Web Services and Microsoft Azure, both include ETL tools.\
    \ Its name is AWS Glue \nfrom Amazon. The fact that Glue is a cloud-native title\
    \ tool means that it offers a visual designer that can be used in a Web browser.\
    \ Python \nor Scala are two programming languages that can be used to create transformations.\
    \ \nData formatting capabilities are one of AWS Glue's distinctive advantages.\
    \ One of the most widely used methods for storing data such as \nfiles is the\
    \ AWB cloud storage service, known as S03. These files can be crawled by AWS Glue\
    \ and it can create a data catalogue that lists \nthe data that is accessible\
    \ in the data lake. AWS Glue makes it simple to transfer this data into different\
    \ data warehousing services on our \nplatform, such as Amazon Redshift or Amazon.\
    \ Similar cloud ETL software on the Microsoft Azure cloud is called Azure Data\
    \ Factory \n(ADF), which similarly offers a web based visual ETL builder. Building\
    \ EDF ETL processes doesn't require programming, in contrast to \nAWS Glue. More\
    \ than 90 data connectors are available through ADF, including sources from all\
    \ the main cloud service providers, including \nAmazon and Google. ADF's ability\
    \ to host SQL Server Integration Services packages makes it possible to run tasks\
    \ created using SQL \nServer's standard ETL tool on Azure cloud infrastructure.\
    \ \nData propagation, which is the process of moving data from one place to another,\
    \ is frequently used to transfer a database's entirety or a \nspecific subset\
    \ from one location to another. Users at the target site can now access the data\
    \ more quickly, and the source and target sites \nmay benefit from redundancy\
    \ as a result. Data propagation and data warehousing are sometimes used in tandem.\
    \ Even though an organi-\nzation may have an enterprise data warehouse where a\
    \ large global data set is stored, this data is frequently propagated to regional\
    \ data \nmarts where a smaller portion is made available to local business units.\
    \ \nBetter response times for regional users and a more pertinent data set that\
    \ makes business intelligence jobs easier are two benefits of \nemploying data\
    \ marts. Edge computing is another possibility for data dissemination. Although\
    \ moving data and computation to the cloud \nhas been the general trend, businesses\
    \ are discovering an increasing number of use cases that demand computing at local\
    \ sites like retail \nstorefronts or warehouses. Edge computing can improve the\
    \ performance and dependability of services at these outlying locations. An \n\
    application that uses facial recognition to identify workers entering a warehouse\
    \ is a typical example of edge computing. \nData replication is a frequently used\
    \ tool for carrying out data dissemination. Most database engines, including PostgreSQL,\
    \ SQL Server, \nand Oracle, all have replication features built in. \nThis makes\
    \ setting up replication and transferring data from a source database to a target\
    \ database quite simple. Replication's functional \nimplementations differ greatly\
    \ among these databases. The replication solution may, in some situations, be\
    \ centered on replicating a data-\nbase to a backup location for disaster recovery.\
    \ In other situations, the technology aims to transfer a portion of a master database\
    \ to a read-\nonly copy to facilitate reporting and analytics. \nInternational\
    \ Journal of Engineering & Technology \n29 \n \n3. Results and discussion \nThis\
    \ paper provides a thorough review of the many facets of data integration, including\
    \ business integration, application integration, data-\nbase integration, and\
    \ the crucial ETL (Extract, Transform, Load) concept. Data integration is a crucial\
    \ activity in the contemporary digital \nlandscape. Based on the data in the paper,\
    \ the following main findings and discussion points are listed:  \n• \nImportance\
    \ of data integration: \nIn today's data-driven economy, the article emphasizes\
    \ the importance of data integration. Organizations struggle with issues like\
    \ data \nsilos, redundant work, and ineffective decision-making without data integration.\
    \ \n• \nTypes of data integration: \nThe paper discusses three distinct types\
    \ of data integration: business integration, application integration, and database\
    \ integration. These \ntypes are well-defined and essential in a variety of business\
    \ contexts. \n• \nBusiness integration: \nB2B integration makes it easier for\
    \ trading partners to communicate and exchange information about transactions.\
    \ It emphasizes how \ncrucial standards like XML and APIs are for facilitating\
    \ these interactions. \n• \nApplication integration: \nBy connecting several software\
    \ programs, application integration is said to build effective processes. The\
    \ given example shows how this \nintegration can increase productivity and streamline\
    \ procedures. \n• \nDatabase Integration: \nData from several sources are combined\
    \ into one perspective through database integration, increasing its value and\
    \ usability. The article \naddresses several database integration techniques,\
    \ including data consolidation, propagation, virtualization, and federation. \n\
    • \nETL process: \nIt involves removing data from source systems, converting it\
    \ into a format that can be used, and putting it into a target system. Important\
    \ \nsteps in this process include data cleaning, enrichment, and bulk loading.\
    \ \n• \nChallenges in data integration: \nIn data integration procedures, issues\
    \ with managing master data, foreign key relationships, and the dynamic nature\
    \ of data are frequent. \nTo ensure data consistency and correctness, these issues\
    \ must be resolved. \n• \nTechnologies and tools: \nMany ETL tools and cloud-based\
    \ options, such as AWS Glue and Azure Data Factory tools, make data integration\
    \ processes simpler and \nprovide features like data formatting and broad data\
    \ connectors. \n• \nReal-time data integration: \nIt is known that real-time data\
    \ integration is a trickier but more crucial component of data integration. In\
    \ the study, real-time analytics \nsolutions like Apache Spark are alluded to.\
    \ \n• \nData dissemination: \nData replication and propagation are two ways for\
    \ disseminating data that help move data to several sites for greater accessibility\
    \ and \nredundancy. \n \nData integration is a vital procedure that enables businesses\
    \ to fully utilize their data. The concept and its many elements are thoroughly\
    \ \ndiscussed in this study, which also provides insightful information on the\
    \ difficulties, methods, and tools involved in data integration. The \ncapacity\
    \ to convert and analyze data effectively can result in major competitive advantages\
    \ in today's data-driven corporate environment, \nunderscoring the crucial role\
    \ data integration plays in this context. \n4. Conclusion \nThis article concludes\
    \ by delving deeply into the area of data integration and highlighting the crucial\
    \ role it plays in our data-driven society. \nFor organizations to succeed in\
    \ the digital age, data integration acts as the keystone that turns raw data into\
    \ an asset. Business integration, \napplication integration, and database integration\
    \ are the three main types of data integration that are thoroughly examined in\
    \ the article. \nThis information gives readers a thorough grasp of how these\
    \ three types of data integration interact to maximize the value of data. The\
    \ \npaper emphasizes how crucial data integration is in the modern economy, where\
    \ data drives innovation, efficiency, and competitive ad-\nvantage. Without efficient\
    \ data integration, businesses must contend with fragmented data silos, duplication\
    \ of effort, and inadequate \ndecision-making procedures. Ineffective data integration\
    \ can lead to big monetary losses and lost opportunities. In-depth analyses of\
    \ each \nsort of data integration are provided, highlighting the various uses\
    \ and advantages of each. B2B communication, which is the emphasis of \nbusiness\
    \ integration, automates procedures and lowers mistake rates by streamlining transactions\
    \ between businesses. Application integra-\ntion links many software programs\
    \ to ensure efficient operation and smooth operations. Database integration gathers\
    \ data from several \nsources, making it easily accessible for reporting and analysis.\
    \ A crucial step in data integration is the ETL (Extract, Transform, Load) \n\
    process, which is covered in detail in the article. Data warehousing and analytics\
    \ require ETL because it ensures data quality and gets it \nready for analysis.\
    \ The debate over data lakes and warehouses also emphasizes how the field of data\
    \ integration is constantly changing. It \nemphasizes the move toward real-time\
    \ analytics and the effective use of tools like Hadoop and Spark for handling\
    \ large information. The \nessay goes on to detail several ETL tools and cloud-based\
    \ solutions, giving readers insights into how data integration methods are really\
    \ \nput into practice. It emphasizes how crucial it is to pick the appropriate\
    \ tools to make the integration process simpler and more efficient. \nFurther\
    \ demonstrating the adaptability of data integration techniques is the discussion\
    \ on data replication, propagation, and edge computing. \nThese methods enable\
    \ businesses to move data where it is needed, speed up responses, and increase\
    \ service dependability, especially in \ndistant contexts. \nThis article essentially\
    \ emphasizes the critical role that data integration plays in contemporary corporate\
    \ processes. For businesses looking \nto make the most of their data, take wise\
    \ decisions, and gain a competitive edge in a world that is becoming more and\
    \ more data-centric, it \nis a priceless resource. By navigating the complexities\
    \ of data integration and selecting the appropriate tactics and resources, one\
    \ can \nsucceed in the digital age and keep data from being an unmanaged resource\
    \ but rather an asset. \n30 \nInternational Journal of Engineering & Technology\
    \ \n \nAcknowledgement \nI would like to express our sincere gratitude to my organization\
    \ EY (Ernst & Young) for unwavering guidance, invaluable insights, and \nconstant\
    \ encouragement throughout this journey. Their valuable input and feedback significantly\
    \ improved the quality of this research. I \nwould like to acknowledge the contributions\
    \ of my research colleagues and friends who provided valuable feedback, engaging\
    \ discussions, \nand constructive criticism. Their diverse perspectives enriched\
    \ this work significantly. \nReferences \n[1] \"Data Integration Blueprint and\
    \ Modeling: Techniques for a Scalable and Sustainable Architecture\" by Anthony\
    \ David Giordano. \n[2] \"Data Integration in the Life Sciences: 5th International\
    \ Workshop, DILS 2008, Evry, France, June 25-27, 2008, Proceedings\" edited by\
    \ Alfonso \nValencia and Paolo Romano. \n[3] Kimball, R., Ross, M., Thornthwaite,\
    \ W., Mundy, J., & Becker, B. (2008). The Data Warehouse Lifecycle Toolkit. Wiley.\
    \ \n[4] Inmon, W. H., & Linstedt, D. (2015). Data Architecture: A Primer for the\
    \ Data Scientist. Morgan Kaufmann. https://doi.org/10.1016/B978-0-12-\n802044-9.00001-5.\
    \ \n[5] Inmon, W. H., & Hackathorn, R. D. (2007). Using the Data Warehouse. Wiley.\
    \ \n[6] Vassiliadis, P., Simitsis, A., & Georgantas, N. (2002). Conceptual modeling\
    \ for ETL processes. International Journal of Data Warehousing and \nMining, 8(4),\
    \ 1-23. https://doi.org/10.1145/583890.583893. \n[7] Duan, S., & Cercone, N. (2008).\
    \ Data integration: A theoretical perspective. Journal of Computer Science and\
    \ Technology, 23(4), 615-626. \n[8] Piplai, T., & Piplai, S. (2014). Data integration:\
    \ A theoretical perspective. International Journal of Advanced Research in Computer\
    \ Science and \nSoftware Engineering, 4(12). \n"
  inline_citation: '>'
  journal: International journal of engineering & technology
  limitations: '>'
  pdf_link: https://www.sciencepubco.com/index.php/ijet/article/download/32335/17725
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Data integration: “Seamless data harmony: The art and science of effective
    data integration”'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.55041/ijsrem25235
  analysis: '>'
  authors:
  - E Balakrishna
  citation_count: 0
  full_citation: '>'
  full_text: ">\n          International Journal of Scientific Research in Engineering\
    \ and Management (IJSREM) \n                       Volume: 06 Issue: 11 | November\
    \ - 2022                             SJIF Rating: 8.176                      \
    \   ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com             \
    \              DOI: 10.55041/IJSREM17493                                |    \
    \    Page 1 \nSeamless Integration of Edge Computing and Cloud Resources for Enhanced\
    \ \nData Analysis \n \nDr. E. Balakrishna  \n \n \n                          \
    \           Dr.N.Satyavathi \n \n \n \n   \nAssociate Professor \n           \
    \           \n                         Associate Professor                   \
    \               \nDepartment of CSE   \n \n                                  \
    \   Head, Department of CSE   \n            \nVaagdevi College of Engineering\
    \  \n \n                         Vaagdevi College of Engineering             \
    \  \n \n          \n      Abstract-The primary objective of the seamless integration\
    \ of edge computing and cloud resources for \nenhanced data analysis is to create\
    \ a powerful and efficient data processing ecosystem that leverages the \nstrengths\
    \ of both edge devices and cloud infrastructure. This integration aims to provide\
    \ real-time and resource-\nintensive data analysis capabilities, enabling organizations\
    \ to make more informed decisions, respond quickly \nto events, and extract valuable\
    \ insights from their data. It is an enhanced data analysis to create a holistic\
    \ \necosystem that combines real-time responsiveness with robust analysis, enabling\
    \ organizations to harness the \nfull potential of their data for effective decision-making\
    \ and innovation. In this paper we addressed what are the \nfactors that influence\
    \ and how we can improve the data privacy and security in the seamless integration\
    \ of edge \ncomputing and cloud resources for enhanced data analysis \nKey words:\
    \ edge computing, security and cloud resources \n \n1. Introduction: \nThe seamless\
    \ integration of edge computing \nand cloud resources represents a transformative\
    \ \napproach in the realm of data analysis, offering a \ndynamic \nsynergy \n\
    between \nlocalized \nreal-time \nprocessing and expansive cloud-based analytics.\
    \ This \ninnovative integration aims to harness the strengths of \nboth edge computing,\
    \ which enables rapid processing \nat the edge of the network, and cloud resources,\
    \ which \nprovide extensive computational power and storage \ncapabilities. By\
    \ seamlessly combining these two \ncomputing paradigms [1,2], organizations can\
    \ achieve \nenhanced data analysis, informed decision-making, \nand operational\
    \ efficiency across a spectrum of \napplications and industries. \nIn this integration,\
    \ edge devices situated closer \nto data sources perform initial processing and\
    \ filtering, \nminimizing data transmission to the cloud. This \napproach not\
    \ only reduces latency and supports real-\ntime responsiveness but also addresses\
    \ privacy \nconcerns by processing sensitive data closer to its \nsource. Simultaneously,\
    \ cloud resources offer the \ncomputational might require for in-depth historical\
    \ \nanalysis, machine learning, and advanced data \nmodelling. This duality of\
    \ edge and cloud forms the \nfoundation for a comprehensive data analysis \n \
    \         International Journal of Scientific Research in Engineering and Management\
    \ (IJSREM) \n                       Volume: 06 Issue: 11 | November - 2022   \
    \                          SJIF Rating: 8.176                         ISSN: 2582-3930\
    \    \n \n© 2022, IJSREM      | www.ijsrem.com                           DOI:\
    \ 10.55041/IJSREM17493                                |        Page 2 \necosystem,\
    \ capable of addressing the diverse needs of \nmodern applications. \nHowever,\
    \ this integration is not without its \nchallenges. Balancing tasks between edge\
    \ and cloud, \norchestrating dynamic workload distribution, ensuring \ndata privacy\
    \ and security, and maintaining consistency \npose intricate technical and strategic\
    \ considerations. \nAddressing these challenges demands a holistic \napproach\
    \ that spans technology, security measures, \norchestration mechanisms, and compliance\
    \ adherence. \nThis integration holds immense potential \nacross a myriad of domains.\
    \ From optimizing \nindustrial processes and enhancing IoT applications to \n\
    enabling intelligent decision-making[3] in healthcare \nand retail, the seamless\
    \ integration of edge computing \nand cloud resources promises to redefine how\
    \ data is \nanalysed, insights are derived, and strategies are \nformulated. As\
    \ this paradigm continues to evolve, \norganizations are poised to unlock new\
    \ dimensions of \nefficiency, agility, and innovation through the \nconvergence\
    \ of edge computing and cloud resources \nfor the purpose of enhanced data analysis.\
    \ \nIntegration Benefits for Data Analysis: \nLatency Reduction: Integrating edge\
    \ computing and \ncloud resources reduces latency by performing real-\ntime analysis\
    \ at the edge. Critical decisions can be \nmade promptly without waiting for data\
    \ to travel to a \ndistant cloud server and back. Cloud resources can \nthen be\
    \ utilized for more in-depth analysis. \nReal-Time Responsiveness: Edge computing\
    \ allows \nfor immediate data processing and response, making it \nsuitable for\
    \ applications that require instant reactions. \nBy integrating with cloud resources,\
    \ historical data \nand complex analyses can be performed to inform \nlong-term\
    \ strategies. \nScalability and Flexibility: Cloud resources provide \nscalability\
    \ for computationally intensive tasks. During \npeak demands, cloud resources\
    \ can be allocated to \nhandle the load, while edge devices handle routine \n\
    processing. This dynamic allocation ensures efficient \nresource utilization.\
    \ \nBandwidth Efficiency: Integrating edge and cloud \ncomputing optimizes bandwidth\
    \ usage. Only relevant \ninsights or summarized data need to be transmitted to\
    \ \nthe cloud, reducing the amount of data transferred and \nlowering associated\
    \ costs. \nData Privacy and Security: Edge computing \nenhances data privacy and\
    \ security by processing \nsensitive information locally. Only aggregated or \n\
    anonymized data is sent to the cloud, minimizing the \nrisk of exposing critical\
    \ data during transmission. \nDistributed Analysis: The integration enables a\
    \ \ndistributed approach to data analysis. Edge devices \ncan preprocess and filter\
    \ data, while cloud resources \nhandle more extensive analysis. This division\
    \ of \nlabour maximizes resource utilization and speeds up \noverall processing.\
    \ \nResource Allocation: Edge devices perform tasks \nthat require minimal latency,\
    \ leaving cloud resources \navailable for computationally demanding tasks. This\
    \ \nefficient resource allocation enhances the overall \nsystem's performance.\
    \ \nHybrid Architectures: Integrating edge and cloud \ncomputing allows for hybrid\
    \ architectures that \n          International Journal of Scientific Research\
    \ in Engineering and Management (IJSREM) \n                       Volume: 06 Issue:\
    \ 11 | November - 2022                             SJIF Rating: 8.176        \
    \                 ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com\
    \                           DOI: 10.55041/IJSREM17493                        \
    \        |        Page 3 \nleverage the benefits of both paradigms. This \nflexibility\
    \ \naccommodates \ndiverse \nuse \ncases, \nworkloads, and network connectivity\
    \ scenarios. \nRedundancy and Reliability: The integration \nprovides redundancy\
    \ and reliability. If an edge device \nfails, the cloud can seamlessly take over\
    \ the workload, \nensuring uninterrupted data analysis and decision-\nmaking.\
    \ \nThe seamless integration of edge and cloud resources \nhas led to improved\
    \ data analysis and decision-making \nin various real-world scenarios. Here are\
    \ some \nexamples: \nSmart Manufacturing: In manufacturing plants, \nsensors installed\
    \ on machinery collect real-time data \nabout equipment performance. Edge computing\
    \ \nprocesses this data locally to detect anomalies and \npotential failures.\
    \ Critical alerts are sent to cloud \nplatforms for more in-depth analysis. This\
    \ integration \nallows manufacturers to predict maintenance needs, \nreduce downtime,\
    \ and optimize production schedules. \nHealthcare Monitoring: Wearable health\
    \ devices, \nsuch as fitness trackers and medical sensors, collect \ndata about\
    \ individuals' health metrics [4]. Edge \ndevices on these wearables process immediate\
    \ health \ndata, while cloud resources analyse historical trends. \nThis integration\
    \ helps doctors make informed \ndecisions about patient care and identify potential\
    \ \nhealth risks. \nAutonomous Vehicles: Self-driving cars use edge \ncomputing\
    \ to process sensor data in real-time for \nimmediate navigation decisions. Cloud\
    \ resources are \nemployed for high-level route planning, map updates, \nand long-term\
    \ traffic pattern analysis. The integration \nensures \nreal-time \nsafety \n\
    and \ncomprehensive \nnavigation optimization. \nSmart Grids: In the energy sector,\
    \ edge devices \nwithin power distribution networks monitor and \nanalyse energy\
    \ consumption patterns. Immediate \nfeedback is provided for load balancing and\
    \ grid \nstability. Cloud resources are used for long-term \nenergy consumption\
    \ trends and optimizing energy \ndistribution across regions. \nAgricultural Precision:\
    \ IoT sensors in agriculture \ncollect data on soil conditions, weather, and crop\
    \ \nhealth. Edge devices process this data locally to make \nreal-time decisions\
    \ about irrigation and fertilizer \napplication. Cloud resources analyze long-term\
    \ data to \nenhance planting strategies and predict crop yields. \nRetail Analytics:\
    \ In retail environments, edge devices \ntrack foot traffic and customer behaviours\
    \ in real time. \nCloud resources analyse this data to identify trends[6] \nin\
    \ customer preferences and optimize store layouts. \nThis integration helps retailers\
    \ enhance customer \nexperiences and tailor marketing strategies. \nEnvironmental\
    \ Monitoring: Sensors deployed in \nenvironmental monitoring stations gather data\
    \ on air \nquality, pollution levels, and weather conditions. Edge \ndevices process\
    \ immediate data to provide real-time \nalerts and updates. Cloud resources analyse\
    \ long-term \ndata to study environmental trends and support policy \ndecisions.\
    \ \nSupply Chain Management: Edge devices in \nwarehouses monitor inventory levels\
    \ and track \nshipments. Immediate data processing ensures \n          International\
    \ Journal of Scientific Research in Engineering and Management (IJSREM) \n   \
    \                    Volume: 06 Issue: 11 | November - 2022                  \
    \           SJIF Rating: 8.176                         ISSN: 2582-3930    \n \n\
    © 2022, IJSREM      | www.ijsrem.com                           DOI: 10.55041/IJSREM17493\
    \                                |        Page 4 \naccurate stock management and\
    \ quick order \nfulfilment. Cloud resources analyse historical data to \noptimize\
    \ supply chain operations and anticipate \ndemand patterns. \nSmart Cities: Urban\
    \ environments use edge devices \nfor real-time traffic monitoring and pollution\
    \ \ndetection. Cloud resources analyse this data to make \ninformed decisions\
    \ about traffic management and \nurban planning. The integration improves city\
    \ services \nand enhances residents' quality of life. \nDisaster Response: During\
    \ natural disasters, edge \ndevices in disaster-stricken areas provide real-time\
    \ \ninformation on conditions and casualties. Cloud \nresources process this data\
    \ to coordinate emergency \nresponses and allocate resources efficiently, thereby\
    \ \nminimizing human loss and damage. \nThe balance between processing data at\
    \ the edge and \nsending it to the cloud has a significant impact on data \nlatency\
    \ and real-time decision-making[6]. Here's how \nthis balance influences these\
    \ factors: \nProcessing Data at the Edge: \nLow Latency: Edge computing involves\
    \ processing \ndata locally, closer to the data source. This \nsignificantly reduces\
    \ the time taken for data to travel \nto a distant cloud server and back, leading\
    \ to lower \nlatency. \nReal-Time Decision-Making: Edge processing allows \nfor\
    \ immediate data analysis and decision-making. \nTime-sensitive actions can be\
    \ taken in real time based \non locally processed data, enabling quick responses\
    \ to \nevents. \nEfficiency: Edge processing is efficient for tasks that \nrequire\
    \ immediate attention and do not necessitate the \nextensive computational resources\
    \ of cloud servers. \nBandwidth Conservation: By processing data at the \nedge,\
    \ the amount of data that needs to be transmitted \nto the cloud is reduced, conserving\
    \ bandwidth and \nminimizing data transmission costs. \nSending Data to the Cloud:\
    \ \nHigher Latency: Transmitting data to the cloud \nintroduces latency due to\
    \ the time it takes for data to \ntravel over the network to the remote data centre\
    \ and \nback to the edge. This latency can be variable \ndepending on network\
    \ conditions. \nComplex Analysis: Cloud resources offer more \ncomputational power\
    \ and memory, allowing for more \ncomplex data analysis, machine learning, and\
    \ \nadvanced analytics that may not be feasible at the \nedge. \nHistorical Insights:\
    \ Cloud analysis can provide \ninsights based on historical data trends, which\
    \ may \nrequire larger datasets and computational capabilities \nnot available\
    \ at the edge. \nResource-Intensive \nTasks: \nTasks \nthat \ndemand \nsignificant\
    \ computational resources or involve \nanalysing vast amounts of data can be offloaded\
    \ to the \ncloud, where scalability is readily available. \nBalancing Latency\
    \ and Decision-Making: \nUse Case Dependence: The balance between edge and \n\
    cloud processing depends on the specific use case. \nApplications requiring immediate\
    \ actions benefit from \nedge processing to minimize latency, while those \nneeding\
    \ in-depth analysis leverage cloud capabilities. \n          International Journal\
    \ of Scientific Research in Engineering and Management (IJSREM) \n           \
    \            Volume: 06 Issue: 11 | November - 2022                          \
    \   SJIF Rating: 8.176                         ISSN: 2582-3930    \n \n© 2022,\
    \ IJSREM      | www.ijsrem.com                           DOI: 10.55041/IJSREM17493\
    \                                |        Page 5 \nHybrid Approach: A hybrid approach\
    \ can be \nemployed, where time-sensitive data is processed at \nthe edge for\
    \ quick actions, while non-time-sensitive \ndata is sent to the cloud for comprehensive\
    \ analysis. \nEdge Orchestration: Intelligent edge orchestration \nmechanisms\
    \ can dynamically determine whether data \nshould be processed locally or sent\
    \ to the cloud, \nconsidering factors such as data type, urgency, and \navailable\
    \ resources. \nThe integration of edge computing and cloud \nresources has a profound\
    \ impact on the development \nand deployment of Internet of Things (IoT) \napplications\
    \ and devices. It addresses key challenges \nand enhances the capabilities of\
    \ IoT solutions. Here's \nhow this integration influences IoT development and\
    \ \ndeployment: \nReduced Latency and Real-Time Responsiveness: \nIoT devices\
    \ often require real-time responsiveness, \nespecially in applications like industrial\
    \ automation, \nhealthcare monitoring, and autonomous vehicles. \nEdge computing\
    \ enables immediate data processing at \nthe device level, minimizing latency\
    \ and enabling \nreal-time decision-making. \nCloud resources can be used for\
    \ more comprehensive \nanalysis and long-term trends, enhancing the quality \n\
    of insights derived from IoT data. \nImproved Scalability: \nEdge computing and\
    \ cloud resources offer a scalable \napproach to IoT deployment. Edge devices\
    \ can handle \nlocalized data processing, while cloud platforms \nprovide scalability\
    \ for processing data from a large \nnumber of devices. \nBandwidth Optimization:\
    \ \nTransmitting large volumes of raw data from IoT \ndevices to the cloud can\
    \ strain network bandwidth and \nincrease costs. Edge computing reduces the amount\
    \ of \ndata transmitted by processing and filtering data \nlocally before sending\
    \ relevant insights to the cloud. \nEnhanced Privacy and Security: \nEdge computing\
    \ enhances data privacy and security \nby processing sensitive information locally,\
    \ reducing \nthe exposure of critical data during transmission. Only \naggregated\
    \ or summarized data is sent to the cloud, \nreducing risks associated with data\
    \ breaches. \nFlexibility in Application Design: \nIoT applications can leverage\
    \ the integration's \nflexibility. Real-time processing at the edge can cater\
    \ \nto time-critical tasks, while cloud resources can handle \nhistorical \nanalysis,\
    \ \npredictive \nmodelling, \nand \nresource-intensive computations. \nOptimal\
    \ Resource Utilization: \nIoT devices often have limited computational \nresources.\
    \ Edge computing offloads processing tasks \nfrom central servers, optimizing\
    \ the usage of device \nresources while leveraging cloud resources for more \n\
    complex computations. \nResilience and Redundancy: \nThe integration provides\
    \ redundancy in case of device \nfailure. If an edge device malfunctions, cloud\
    \ \nresources can take over processing, ensuring \ncontinuous data analysis and\
    \ decision-making. \nEdge Orchestration: \nEdge orchestration platforms dynamically\
    \ allocate \ntasks between edge devices and cloud resources based \n         \
    \ International Journal of Scientific Research in Engineering and Management (IJSREM)\
    \ \n                       Volume: 06 Issue: 11 | November - 2022            \
    \                 SJIF Rating: 8.176                         ISSN: 2582-3930 \
    \   \n \n© 2022, IJSREM      | www.ijsrem.com                           DOI: 10.55041/IJSREM17493\
    \                                |        Page 6 \non factors such as data type,\
    \ processing requirements, \nand network conditions. This enhances efficiency\
    \ and \nresponse times. \nLocation-Dependent Services: \nCertain IoT applications\
    \ require services that are \nlocation-dependent, such as navigation in autonomous\
    \ \nvehicles. Edge computing enables local processing of \nlocation data, reducing\
    \ dependency on cloud resources \nfor real-time navigation. \nCost Efficiency:\
    \ \nIoT applications often have budget constraints. The \nintegration can lead\
    \ to cost savings by minimizing the \nneed for transmitting data to the cloud\
    \ and optimizing \nresource allocation based on workload. \n2. Literature Survey:\
    \ \nA comprehensive literature survey on the topic \nof \"Seamless Integration\
    \ of Edge Computing and \nCloud Resources for Enhanced Data Analysis\" \ninvolves\
    \ exploring various research [7, 8, 9 and 10] \nthat discuss the challenges, techniques,\
    \ benefits, and \napplications of integrating edge computing and cloud \nresources\
    \ for improved data analysis. \nThe literature survey often delve into the \n\
    technical aspects, algorithms, architectures, and case \nstudies of integrating\
    \ edge and cloud resources. It \nsummarizing the findings and trends in the integration\
    \ \nof edge computing and cloud resources for data \nanalysis. \nSecurity and\
    \ Privacy Studies: \nAs security and privacy are crucial aspects of \nintegration,\
    \ literature discussing the techniques, \nchallenges, and solutions for ensuring\
    \ data security \nand privacy in this context is highly valuable. \nOrchestration\
    \ and Load Balancing Techniques [11]: \nExplore \nliterature \nthat \ndiscusses\
    \ \ndynamic \norchestration and load balancing mechanisms to \nallocate tasks\
    \ effectively between edge devices and \ncloud resources. \nIoT and Industrial\
    \ Applications: \nLook for studies focusing on the integration's \napplications\
    \ in the Internet of Things (IoT) and \nindustrial sectors. These studies often\
    \ showcase how \nthe integration enhances data analysis and decision-\nmaking\
    \ in specific domains. \nCloud Resource Management: \nLiterature on cloud resource\
    \ management explores \nhow to optimize the utilization of cloud resources \n\
    while balancing workloads and ensuring efficient data \nanalysis. \nLatency Reduction\
    \ Techniques: \nStudies on latency reduction techniques discuss \nmethods to minimize\
    \ data transmission delays and \nachieve real-time or near-real-time analytics\
    \ [13]. \nData Aggregation and Compression: \nExplore research on techniques that\
    \ aggregate and \ncompress data at the edge before transmission to the \ncloud,\
    \ optimizing network bandwidth and reducing \ndata transmission costs. \nEnergy\
    \ Efficiency and Resource Constraints: \nLook for literature that addresses how\
    \ to manage \nenergy-efficient processing on resource-constrained \nedge devices\
    \ while maintaining security and privacy. \n \n          International Journal\
    \ of Scientific Research in Engineering and Management (IJSREM) \n           \
    \            Volume: 06 Issue: 11 | November - 2022                          \
    \   SJIF Rating: 8.176                         ISSN: 2582-3930    \n \n© 2022,\
    \ IJSREM      | www.ijsrem.com                           DOI: 10.55041/IJSREM17493\
    \                                |        Page 7 \nFederated Learning and Edge\
    \ AI: \nResearch on federated learning and edge AI discusses \nhow these techniques\
    \ can be applied in the integration \nto enable collaborative machine learning\
    \ models \nwithout sharing raw data. \nThe seamless integration of edge computing\
    \ and cloud \nresources plays a crucial role in addressing issues of \nnetwork\
    \ congestion and bandwidth limitations [12]. \nHere's how this integration contributes\
    \ to alleviating \nthese challenges: \nLocal Data Processing: \nEdge computing\
    \ enables data processing to occur at or \nnear the source of data generation.\
    \ This reduces the \nneed to transmit large volumes of raw data over the \nnetwork\
    \ to centralized cloud servers. \nBy processing data locally at the edge, only\
    \ relevant \ninsights or summarized information are sent to the \ncloud, reducing\
    \ the amount of data that needs to \ntraverse the network. \nMinimized Data Transmission:\
    \ \nTransmitting data over networks, especially in \nscenarios with limited bandwidth,\
    \ can lead to network \ncongestion and increased latency. Edge computing \nreduces\
    \ the need for frequent data transmission, easing \nnetwork traffic. \nBandwidth\
    \ Conservation: \nEdge devices process and filter data, sending only \nnecessary\
    \ information to the cloud. This approach \nconserves bandwidth by avoiding the\
    \ unnecessary \ntransfer of large datasets to the cloud for analysis. \n \n \n\
    Real-Time Insights at the Edge: \nImmediate data processing at the edge enables\
    \ quick \ndecisions and actions without relying on cloud \nresources. This reduces\
    \ the dependency on continuous \ndata transmission to the cloud for real-time\
    \ \nresponsiveness. \nDynamic Data Prioritization: \nThe integration allows for\
    \ dynamic data prioritization. \nCritical or time-sensitive data can be processed\
    \ at the \nedge to ensure immediate responses, while less urgent \ndata can be\
    \ sent to the cloud for more comprehensive \nanalysis. \nEdge Caching: \nEdge\
    \ devices can store frequently accessed or critical \ndata locally using caching\
    \ mechanisms. This reduces \nthe need to retrieve data from the cloud repetitively,\
    \ \nthus alleviating network congestion. \nDistributed Load: \nOffloading computational\
    \ tasks to edge devices \ndistributes the processing load across the network.\
    \ \nThis avoids overburdening a single centralized cloud \nserver and reduces\
    \ the risk of network congestion. \nImproved Scalability: \nAs the number of IoT\
    \ devices and data sources \nincreases, the integration ensures that edge devices\
    \ \nprocess local data, reducing the strain on the network \nand cloud infrastructure.\
    \ \nRedundancy and Failover: \nThe integration provides redundancy by allowing\
    \ for \nfailover mechanisms. If an edge device or network \nsegment becomes congested,\
    \ the system can route data \n          International Journal of Scientific Research\
    \ in Engineering and Management (IJSREM) \n                       Volume: 06 Issue:\
    \ 11 | November - 2022                             SJIF Rating: 8.176        \
    \                 ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com\
    \                           DOI: 10.55041/IJSREM17493                        \
    \        |        Page 8 \nto alternative edge devices or the cloud to maintain\
    \ \nuninterrupted data flow. \nData Aggregation at the Edge: \nEdge devices can\
    \ aggregate data from multiple \nsources before sending aggregated insights to\
    \ the \ncloud. This aggregation reduces the frequency and \nvolume of data transmission,\
    \ easing network \ncongestion. \nSeveral factors influence the seamless integration\
    \ of \nedge computing and cloud resources for enhanced data \nanalysis. These\
    \ factors impact the technical, \noperational, and strategic aspects of the integration.\
    \ \nHere are some key factors to consider: \nUse Case and Application Requirements:\
    \ \nThe specific use case and application requirements \ndetermine the balance\
    \ between edge and cloud \nprocessing. \nConsider \nwhether \nreal-time \nresponsiveness,\
    \ historical analysis, or a combination \nof both is needed. \nLatency Tolerance:\
    \ \nApplications with low-latency requirements, such as \nautonomous vehicles\
    \ or industrial automation, need to \nprioritize edge processing to minimize delays\
    \ in \ndecision-making. \nData Volume and Velocity: \nThe volume and velocity\
    \ of incoming data influence \nwhether processing should occur at the edge or\
    \ in the \ncloud. High data volumes might necessitate initial \nfiltering at the\
    \ edge before sending data to the cloud. \nNetwork Connectivity and Bandwidth:\
    \ \nThe quality of network connectivity, available \nbandwidth, and potential\
    \ network congestion impact \nthe feasibility of transmitting data to the cloud.\
    \ Edge \nprocessing can alleviate these constraints. \nData Privacy and Security:\
    \ \nThe sensitivity of data and privacy concerns influence \nwhether data should\
    \ be processed locally at the edge \nto minimize data exposure during transmission.\
    \ \nComputational Resources of Edge Devices: \nThe computational capabilities\
    \ of edge devices \ndetermine the complexity of analysis they can handle. \nTasks\
    \ requiring significant processing power might be \nmore suitable for cloud resources.\
    \ \nScalability Requirements: \nConsider the scalability requirements of your\
    \ \napplication. Will the number of devices increase? Can \ncloud resources handle\
    \ the workload during peak \ndemands? \nReal-Time Decision-Making: \nApplications\
    \ that require immediate responses, such \nas real-time sensor data analysis,\
    \ benefit from edge \nprocessing to ensure rapid decision-making. \nHistorical\
    \ Analysis and Advanced Analytics: \nCloud resources are advantageous for tasks\
    \ that \ninvolve historical data analysis, machine learning, and \nother advanced\
    \ analytics that require substantial \ncomputational resources. \nResource Constraints\
    \ and Cost Efficiency: \nEdge devices might have resource constraints in terms\
    \ \nof processing power, memory, and energy. Choose the \nprocessing location\
    \ based on optimizing resource \nutilization and cost efficiency. \nEdge Orchestration:\
    \ \n          International Journal of Scientific Research in Engineering and\
    \ Management (IJSREM) \n                       Volume: 06 Issue: 11 | November\
    \ - 2022                             SJIF Rating: 8.176                      \
    \   ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com             \
    \              DOI: 10.55041/IJSREM17493                                |    \
    \    Page 9 \nThe implementation of dynamic edge orchestration \nmechanisms influences\
    \ how tasks are allocated \nbetween edge devices and cloud resources based on\
    \ \nreal-time conditions. \nUser Experience and Data Presentation: \nConsider\
    \ how insights and analysis results will be \npresented to end-users. Ensure a\
    \ seamless user \nexperience regardless of whether data originated from \nedge\
    \ or cloud processing. \nRedundancy and Failover: \nPlan for redundancy and failover\
    \ mechanisms in case \nof edge device failures. Determine how seamlessly the \n\
    system can transition processing tasks to other devices \nor the cloud. \nRegulatory\
    \ and Compliance Considerations: \nRegulatory requirements and compliance standards\
    \ \nmight influence data storage, processing, and \ntransmission decisions. \n\
    Industry and Vertical Specifics: \nDifferent industries and verticals have unique\
    \ \nrequirements. Consider factors like healthcare \nregulations, industrial automation\
    \ standards, and retail \ntrends. \nBy carefully considering these factors, you\
    \ can tailor \nyour approach to seamlessly integrate edge computing \nand cloud\
    \ resources for enhanced data analysis, \nensuring that the integration aligns\
    \ with your \napplication's goals and requirements. \nData privacy and security\
    \ are critical considerations in \nthe seamless integration of edge computing\
    \ and cloud \nresources for enhanced data analysis. Here's how data \nprivacy\
    \ and security are addressed in this integration: \nEdge Data Privacy: \nSensitive\
    \ data can be processed and analysed locally \non edge devices, reducing the need\
    \ to transmit raw \ndata to the cloud. This limits exposure of sensitive \ninformation\
    \ during transmission. \nData Encryption: \nImplement end-to-end encryption to\
    \ protect data \nduring transmission between edge devices and the \ncloud. This\
    \ ensures that data remains secure even if \nintercepted. \nAccess Control: \n\
    Implement access controls at both the edge and cloud \nlevels to restrict data\
    \ access to authorized personnel. \nOnly authorized users should be able to interact\
    \ with \nand analysed the data. \nData Anonymization: \nAnonymize data before\
    \ transmitting it to the cloud. \nThis ensures that individual users' identities\
    \ cannot be \neasily linked to the data. \nSecure Protocols: \nUse secure communication\
    \ protocols such as HTTPS \nand \nMQTT \nwith \nproper \nauthentication \nand\
    \ \nauthorization mechanisms to ensure data integrity and \nprevent unauthorized\
    \ access. \nSecure Edge Devices: \nSecure edge devices with proper authentication,\
    \ \nregular updates, and security patches to prevent \nunauthorized access and\
    \ potential vulnerabilities. \nData Minimization: \nMinimize the data transmitted\
    \ to the cloud by \nprocessing data at the edge and sending only relevant \n \
    \         International Journal of Scientific Research in Engineering and Management\
    \ (IJSREM) \n                       Volume: 06 Issue: 11 | November - 2022   \
    \                          SJIF Rating: 8.176                         ISSN: 2582-3930\
    \    \n \n© 2022, IJSREM      | www.ijsrem.com                           DOI:\
    \ 10.55041/IJSREM17493                                |        Page 10 \ninsights.\
    \ This reduces the risk associated with \ntransmitting large volumes of data.\
    \ \nCloud Security Measures: \nUtilize cloud provider security features such as\
    \ \nencryption at rest, access controls, and intrusion \ndetection to safeguard\
    \ data stored in the cloud. \nCompliance with Regulations: \nEnsure that data\
    \ processing and transmission comply \nwith relevant data protection regulations,\
    \ such as \nGDPR or HIPAA, depending on the industry and \nregion. \nMonitoring\
    \ and Auditing: \nImplement monitoring and auditing mechanisms to \ntrack data\
    \ access and usage. This helps detect \nunauthorized activities and provides an\
    \ audit trail for \ncompliance purposes. \nUser Consent and Transparency: \nEnsure\
    \ that users are informed about data processing \nand obtain their consent, especially\
    \ if sensitive data is \ninvolved. Transparency builds trust and ensures \ncompliance.\
    \ \nData Lifecycle Management: \nDevelop a clear data lifecycle management strategy,\
    \ \nincluding data retention and deletion policies, to \nminimize the risk of\
    \ unauthorized access to outdated \ndata. \nSecurity Testing and Audits: \nRegularly\
    \ conduct security testing and audits of both \nedge devices and cloud resources\
    \ to identify \nvulnerabilities and address potential security gaps. \nEmployee\
    \ Training: \nTrain employees and personnel handling data on best \npractices\
    \ for data privacy and security. Human error is \na common cause of data breaches.\
    \ \nIncident Response Plan: \nHave a well-defined incident response plan in place\
    \ to \nquickly address and mitigate any potential data \nbreaches or security\
    \ incidents. \nBy implementing these measures, organizations can \nensure that\
    \ data remains private and secure throughout \nthe seamless integration of edge\
    \ computing and cloud \nresources for enhanced data analysis. It's essential to\
    \ \nadopt a comprehensive approach that addresses data \nprivacy and security\
    \ at every stage of the data's \njourney, from edge to cloud. \n3.Results and\
    \ Analysis: \nThe following are the overview of the types of \noutcomes that have\
    \ emerged from previous and \nongoing research in this field up to that point:\
    \ \nLatency Reduction and Real-Time Responsiveness: \nResearch has demonstrated\
    \ that processing data at the \nedge reduces latency and enables real-time decision-\n\
    making, leading to improved responsiveness in \napplications such as industrial\
    \ automation and IoT. \nNetwork Bandwidth Optimization: \nStudies have shown that\
    \ by processing data locally at \nthe edge and sending summarized insights to\
    \ the \ncloud, network bandwidth can be conserved, reducing \nthe risk of congestion\
    \ and transmission costs. \nPrivacy Enhancement and Data Security: \nResearch\
    \ \nhas \nemphasized \nthe \nimportance \nof \nprocessing sensitive data locally\
    \ to enhance privacy \n          International Journal of Scientific Research\
    \ in Engineering and Management (IJSREM) \n                       Volume: 06 Issue:\
    \ 11 | November - 2022                             SJIF Rating: 8.176        \
    \                 ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com\
    \                           DOI: 10.55041/IJSREM17493                        \
    \        |        Page 11 \nand minimize data exposure during transmission. This\
    \ \naligns with data protection regulations. \nHybrid Analytics for Better Insights:\
    \ \nPrevious research has highlighted the value of \ncombining real-time edge\
    \ analytics with cloud-based \nhistorical analysis to provide a more comprehensive\
    \ \nview of data and yield deeper insights. \nResource Utilization Optimization:\
    \ \nStudies have explored how balancing processing \nbetween edge and cloud resources\
    \ optimizes the \nutilization of computational resources and improves \noverall\
    \ system efficiency. \nEdge-Cloud Orchestration Techniques: \nResearch has proposed\
    \ and evaluated orchestration \nmechanisms that dynamically allocate tasks between\
    \ \nedge devices and cloud resources based on factors like \ndata type, latency\
    \ requirements, and workload. \nScalability and Workload Management: \nResearch\
    \ has addressed strategies for handling \nscalability challenges, ensuring that\
    \ the integration \ncan scale to accommodate increased data volumes and \ndevice\
    \ connections. \nEdge Device Selection and Optimization: \nPrevious studies have\
    \ analysed the selection of \nappropriate edge devices, considering factors such\
    \ as \nprocessing \npower, \nenergy \nefficiency, \nand \ncompatibility with cloud\
    \ platforms. \nFault Tolerance and Redundancy: \nResearch has investigated failover\
    \ mechanisms and \nredundancy strategies to maintain uninterrupted data \nanalysis\
    \ and decision-making in case of edge device \nfailures. \nIndustry-Specific Applications:\
    \ - Studies have focused \non \nspecific \nindustries, \nsuch \nas \nhealthcare,\
    \ \nmanufacturing, and smart cities, showcasing how the \nintegration benefits\
    \ various sectors through enhanced \ndata analysis. \nPerformance Benchmarking\
    \ and Evaluation: \n- \nPrevious research has evaluated the performance of \n\
    different integration approaches, comparing factors \nlike latency, resource usage,\
    \ and overall system \nefficiency. \nEnergy Efficiency Considerations: - Some\
    \ research \nhas explored how the integration can improve energy \nefficiency\
    \ by offloading tasks from power-hungry \ncloud servers to energy-efficient edge\
    \ devices. \nChallenges and Open Research Questions: - Previous \nstudies have\
    \ identified challenges in terms of load \nbalancing, data consistency, security,\
    \ and seamless \nhandoff between edge and cloud resources, which \nrequire further\
    \ investigation. \nKeep in mind that the field of edge computing and \ncloud integration\
    \ is rapidly evolving, and new \nresearch findings are continuously being published.\
    \ \nImproving data privacy and security in the seamless \nintegration of edge\
    \ computing and cloud resources for \nenhanced data analysis involves a combination\
    \ of \ntechnical techniques, best practices, and tools. Here \nare some advanced\
    \ techniques to enhance data privacy \nand security: \nMulti-Layer Encryption:\
    \ \nImplement end-to-end encryption using strong \ncryptographic algorithms for\
    \ data in transit between \nedge devices and cloud resources. Use encryption \n\
    \          International Journal of Scientific Research in Engineering and Management\
    \ (IJSREM) \n                       Volume: 06 Issue: 11 | November - 2022   \
    \                          SJIF Rating: 8.176                         ISSN: 2582-3930\
    \    \n \n© 2022, IJSREM      | www.ijsrem.com                           DOI:\
    \ 10.55041/IJSREM17493                                |        Page 12 \nlibraries\
    \ and protocols like TLS/SSL to ensure data \nremains confidential. \nHomomorphic\
    \ Encryption: \nExplore homomorphic encryption, which allows \ncomputations to\
    \ be performed on encrypted data \nwithout decrypting it. This technique ensures\
    \ that \nsensitive data remains encrypted even during analysis. \nDifferential\
    \ Privacy: \nIntegrate differential privacy techniques to add noise \nor randomness\
    \ to aggregated data before transmission, \npreserving individual privacy while\
    \ allowing accurate \nanalysis. \nSecure Enclaves: \nUtilize hardware-based security\
    \ features, such as Intel \nSGX or ARM Trust Zone, to create secure enclaves on\
    \ \nedge devices. These enclaves isolate sensitive \ncomputations from the rest\
    \ of the system. \nZero-Trust Architecture: \nAdopt a zero-trust architecture\
    \ that assumes no device \nor user can be trusted by default. Implement strong\
    \ \nauthentication, access controls, and continuous \nmonitoring across both edge\
    \ and cloud components. \nFederated Learning: \nImplement federated learning techniques,\
    \ where \nmodel training occurs on edge devices while only \naggregated model\
    \ updates are sent to the cloud. This \nminimizes the need to transmit raw data.\
    \ \nAttribute-Based Encryption: \nUse attribute-based encryption to define access\
    \ \ncontrols based on attributes (e.g., roles, user \ncharacteristics). This allows\
    \ fine-grained control over \nwho can access specific data. \nBlock chain Technology:\
    \ \nConsider using block chain for secure and tamper-\nresistant data storage\
    \ and auditing. Block chain can \nprovide an immutable ledger for data transactions\
    \ and \naccess history. \nThreat Detection and Intrusion Prevention: \nDeploy\
    \ intrusion detection systems (IDS) and \nintrusion prevention systems (IPS) on\
    \ edge devices \nand in the cloud to monitor for unauthorized access \nand potential\
    \ threats. \nSecure Key Management: - Implement secure key \nmanagement practices\
    \ to protect encryption keys used \nfor data protection. Use Hardware Security\
    \ Modules \n(HSMs) for enhanced key security. \nData Masking and Tokenization:\
    \ - Implement data \nmasking or tokenization techniques to replace \nsensitive\
    \ data with pseudonyms or tokens. This way, \neven if data is compromised, it\
    \ remains unusable. \nPrivacy-Preserving Analytics: - Utilize techniques \nsuch\
    \ as secure multi-party computation (SMPC) or \nsecure function evaluation (SFE)\
    \ to perform analytics \non encrypted data without revealing the data itself.\
    \ \nRegular Security Audits: - Conduct regular security \naudits and vulnerability\
    \ assessments to identify and \naddress potential security weaknesses in both\
    \ edge and \ncloud components. \nPrivacy Impact Assessments: - Conduct privacy\
    \ \nimpact assessments to evaluate potential risks to \nprivacy and identify mitigation\
    \ strategies. This helps \nensure that privacy is considered throughout the \n\
    integration process. \n          International Journal of Scientific Research\
    \ in Engineering and Management (IJSREM) \n                       Volume: 06 Issue:\
    \ 11 | November - 2022                             SJIF Rating: 8.176        \
    \                 ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com\
    \                           DOI: 10.55041/IJSREM17493                        \
    \        |        Page 13 \nContinuous Monitoring and Response: - Implement \n\
    continuous monitoring of edge devices and cloud \nresources to detect anomalies\
    \ and respond to security \nincidents in real-time. \nBy incorporating these advanced\
    \ techniques into the \nintegration of edge computing and cloud resources, \n\
    organizations can significantly enhance data privacy \nand security. It's important\
    \ to approach data privacy \nand security as an ongoing process, continuously\
    \ \nadapting \nto \nemerging \nthreats \nand \nevolving \ntechnologies. \nResearch\
    \ on the seamless integration of edge \ncomputing and cloud resources for enhanced\
    \ data \nanalysis has yielded valuable insights and findings. \nWhile I don't\
    \ have access to the most current research \nbeyond my  \nWhile integrating edge\
    \ computing and cloud resources \nfor enhanced data analysis offers numerous benefits,\
    \ \nthere are also several drawbacks and challenges \nrelated to data privacy\
    \ and security that need to be \nconsidered and addressed. Some of these drawbacks\
    \ \ninclude: \nIncreased Attack Surface: \nThe integration introduces additional\
    \ points of entry \nfor potential cyberattacks, as both edge devices and \ncloud\
    \ resources need to be secured. This broader \nattack surface requires comprehensive\
    \ security \nmeasures. \nData Transmission Risks: \nTransmitting data between\
    \ edge devices and the cloud \ncan expose it to interception and potential breaches\
    \ if \nencryption and secure transmission protocols are not \nproperly implemented.\
    \ \nCloud Vulnerabilities: \nCloud environments are not immune to security \n\
    vulnerabilities. \nMisconfigurations, \nunauthorized \naccess, and data breaches\
    \ can occur if cloud security \nis not managed effectively. \nComplexity of Orchestration:\
    \ \nOrchestrating tasks between edge and cloud resources \ndynamically adds complexity.\
    \ Incorrect orchestration \ndecisions can lead to data exposure or inefficient\
    \ \nresource usage. \n \nData Consistency Challenges: \nMaintaining data consistency\
    \ across edge and cloud \ncomponents can be challenging. Ensuring that \naggregated\
    \ data sent to the cloud is accurate and up-\nto-date requires careful management.\
    \ \nResource Constraints: \nEdge devices often have limited computational \nresources,\
    \ which might constrain the implementation \nof robust security measures. Balancing\
    \ security and \nresource efficiency is a challenge. \nKey Management Complexity:\
    \ \nManaging encryption keys for secure communication \nbetween edge and cloud\
    \ resources can become \ncomplex, requiring careful key distribution and \nrotation\
    \ strategies. \nCompliance Variability: \nEnsuring compliance with data protection\
    \ regulations \nacross edge and cloud environments can be complex \n         \
    \ International Journal of Scientific Research in Engineering and Management (IJSREM)\
    \ \n                       Volume: 06 Issue: 11 | November - 2022            \
    \                 SJIF Rating: 8.176                         ISSN: 2582-3930 \
    \   \n \n© 2022, IJSREM      | www.ijsrem.com                           DOI: 10.55041/IJSREM17493\
    \                                |        Page 14 \ndue to differences in data\
    \ processing and storage \npractices. \nEdge Device Vulnerabilities: \nSome edge\
    \ devices might lack proper security \nfeatures, making them susceptible to attacks.\
    \ Securing \na diverse range of devices can be challenging. \nLimited Processing\
    \ for Security: - Edge devices might \nprioritize data processing over security\
    \ measures due \nto resource constraints, potentially leading to \nvulnerabilities\
    \ if not properly managed. \nInsider Threats: - Insiders with access to edge devices\
    \ \nor cloud resources can pose security risks. Proper \naccess controls and monitoring\
    \ are needed to mitigate \nthis threat. \nLack of Standards: - The lack of standardized\
    \ security \npractices for edge-cloud integration can lead to \ninconsistent security\
    \ implementations and potential \nvulnerabilities. \nData Aggregation Risks: -\
    \ Aggregating data at the \nedge before sending it to the cloud can lead to \n\
    exposure of potentially sensitive insights if not \ncarefully managed and anonymized.\
    \ \nOverhead of Privacy Techniques: - Implementing \nadvanced \nprivacy-preserving\
    \ \ntechniques \nlike \nhomomorphic-encryption or differential privacy can \n\
    introduce processing overhead that affects overall \nsystem performance. \nHuman\
    \ \nFactors: \n- \nHuman \nerror, \nsuch \nas \nmisconfigurations or inadequate\
    \ user training, can \ncompromise security and privacy, underscoring the \nimportance\
    \ of proper training and education. \nTo address these drawbacks, it's crucial\
    \ to \nimplement a comprehensive security strategy that \nencompasses both edge\
    \ and cloud components, \nconsidering the unique challenges and requirements of\
    \ \neach. Regular security assessments, audits, and \nstaying updated with security\
    \ best practices are \nessential to mitigating these challenges and ensuring a\
    \ \nsecure integration of edge computing and cloud \nresources for enhanced data\
    \ analysis. \n4.Conclusion and future scope: \nIn conclusion, the seamless integration\
    \ of edge \ncomputing and cloud resources presents a paradigm-\nshifting approach\
    \ that bridges the gap between \nlocalized real-time processing and expansive\
    \ cloud-\nbased analytics. This integration holds the promise of \nrevolutionizing\
    \ data analysis by leveraging the \nstrengths of both edge and cloud computing\
    \ to drive \nenhanced decision-making, operational efficiency, \nand innovation\
    \ across various industries and \napplications. \nThrough this integration, organizations\
    \ can tap \ninto the power of edge devices positioned closer to \ndata sources,\
    \ enabling rapid initial processing and \nreducing latency for time-sensitive\
    \ applications. This \nlocalized processing not only supports real-time \nresponsiveness\
    \ but also addresses concerns around \ndata privacy and security by minimizing\
    \ data \ntransmission to the cloud. Simultaneously, cloud \nresources provide\
    \ the computational muscle needed \nfor in-depth analysis, complex modelling,\
    \ and long-\nterm trend identification. \n          International Journal of Scientific\
    \ Research in Engineering and Management (IJSREM) \n                       Volume:\
    \ 06 Issue: 11 | November - 2022                             SJIF Rating: 8.176\
    \                         ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com\
    \                           DOI: 10.55041/IJSREM17493                        \
    \        |        Page 15 \nThe future scope of seamless integration of \nedge\
    \ computing and cloud resources is dynamic and \nevolving. As these technologies\
    \ continue to merge and \nmature, they will drive innovation, reshape industries,\
    \ \nand empower organizations to harness data in \nunprecedented ways. To make\
    \ the most of this potential, \ncollaboration \nbetween \nresearchers, \nindustry\
    \ \npractitioners, and policymakers will be vital in shaping \nthe direction of\
    \ this integration. \nReferences \n1. Muralidhara, P. (2017). IoT applications\
    \ in cloud \ncomputing for smart devices. INTERNATIONAL \nJOURNAL OF COMPUTER\
    \ SCIENCE AND \nTECHNOLOGY, 1(1), 1-41.  \n2. Serrano, N., Gallardo, G., & Hernantes,\
    \ J. (2015). \nInfrastructure as a service and cloud technologies. \nIEEE Software,\
    \ 32(2), 30-36.  \n3. Muralidhara, P. (2019). Load balancing in cloud \ncomputing:\
    \ A literature review of different cloud \ncomputing platforms. Page | 8  \n4.\
    \ Elmurzaevich, M. A. (2022, February). Use of \ncloud technologies in education.\
    \ In Conference \nZone (pp. 191-192). 8. Fang, B., Yin, X., Tan, Y., \nLi, C.,\
    \ Gao, Y., Cao, Y., & Li, J. (2016). The \ncontributions of cloud technologies\
    \ to smart grid. \nRenewable and Sustainable Energy Reviews, 59, \n1326- 1331.\
    \  \n5. G‘ayratovich, E. N. (2022). The Theory of the Use \nof Cloud Technologies\
    \ in the Implementation of \nHierarchical Preparation of Engineers. Eurasian \n\
    Research Bulletin, 7, 18-21.  \n6. Ekanayake, J., Gunarathne, T., & Qiu, J. (2010).\
    \ \nCloud \ntechnologies \nfor \nbioinformatics \napplications. IEEE Transactions\
    \ on parallel and \ndistributed systems, 22(6), 998-1011.  \n7. Aziz, M. A., Abawajy,\
    \ J., & Chowdhury, M. \n(2013, December). The challenges of cloud \ntechnology\
    \ adoption in e-government. In 2013 \nInternational Conference on Advanced Computer\
    \ \nScience Applications and Technologies (pp. 470-\n474). IEEE.  \n8. Sharmili,\
    \ N., Yonbawi, S., Alahmari, S., Lydia, E. \nL., Ishak, M. K., Alkahtani, H. K.,\
    \ ... & Mostafa, \nS. M. (2023). Earthworm Optimization with \nImproved SqueezeNet\
    \ Enabled Facial Expression \nRecognition Model. Computer Systems Science & \n\
    Engineering, 46(2).  \n9. Rutskiy, V., Aljarbouh, A., Thommandru, A., \nElkin,\
    \ S., Amrani, Y. E., Semina, E., ... & Tsarev, \nR. (2022). Prospects for the\
    \ Use of Artificial \nIntelligence to Combat Fraud in Bank Payments. \nIn Proceedings\
    \ of the Computational Methods in \nSystems and Software (pp. 959-971). Cham:\
    \ \nSpringer International Publishing.  \n10. Aljarbouh, A., Tsarev, R., Robles,\
    \ A. S., Elkin, S., \nGogoleva, I., Nikolaeva, I., & Varyan, I. (2022). \nApplication\
    \ \nof \nthe \nK-medians \nClustering \nAlgorithm for Test Analysis in Elearning.\
    \ In \nProceedings of the Computational Methods in \nSystems and Software (pp.\
    \ 249- 256). Cham: \nSpringer International Publishing.  \n11. Albarakati, A.\
    \ J., Boujoudar, Y., Azeroual, M., \nEliysaouy, L., Kotb, H., Aljarbouh, A., ...\
    \ & \n          International Journal of Scientific Research in Engineering and\
    \ Management (IJSREM) \n                       Volume: 06 Issue: 11 | November\
    \ - 2022                             SJIF Rating: 8.176                      \
    \   ISSN: 2582-3930    \n \n© 2022, IJSREM      | www.ijsrem.com             \
    \              DOI: 10.55041/IJSREM17493                                |    \
    \    Page 16 \nPupkov, A. (2022). Microgrid energy management \nand monitoring\
    \ systems: A comprehensive review. \nFrontiers in Energy Research, 10, 1097858.\
    \ \n12.  Albarakati, J. A., Azeroual, M., Boujoudar, Y., \nEL Iysaouy, L., Aljarbouh,\
    \ A., Tassaddiq, A., & \nEL Markhi, H. (2022). Multi-Agent-Based Fault \nLocation\
    \ \nand \nCyber-Attack \nDetection \nin \nDistribution System. Energies, 16(1),\
    \ 224. Page | \n9  \n13.  Haq, I., Mazhar, T., Nasir, Q., Razzaq, S., \nMohsan,\
    \ S. A. H., Alsharif, M. H., ... & Mostafa, \nS. M. (2022). Machine Vision Approach\
    \ for \nDiagnosing \nTuberculosis \n(TB) \nBased \non \nComputerized Tomography\
    \ (CT) Scan Images. \nSymmetry, 14(10), 1997 \n"
  inline_citation: '>'
  journal: Indian Scientific Journal Of Research In Engineering And Management
  limitations: '>'
  pdf_link: https://ijsrem.com/download/seamless-integration-of-edge-computing-and-cloud-resources-for-enhanced-data-analysis/?wpdmdl=23372&refresh=651d8b4d4c5111696435021
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Seamless Integration of Edge Computing and Cloud Resources for Enhanced Data
    Analysis
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.55041/ijsrem17493
  analysis: '>'
  authors:
  - E Balakrishna
  citation_count: 0
  full_citation: '>'
  full_text: '>

    Web Store Add shortcut Name URL Customize Chrome'
  inline_citation: '>'
  journal: Indian Scientific Journal Of Research In Engineering And Management
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Seamless Integration of Edge Computing and Cloud Resources for Enhanced Data
    Analysis
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1155/2022/9042382
  analysis: '>'
  authors:
  - Sushabhan Choudhury
  - Rajesh Singh
  - Anita Gehlot
  - Piyush Kuchhal
  - Shaik Vaseem Akram
  - Neeraj Priyadarshi
  - Baseem Khan
  citation_count: 0
  full_citation: '>'
  full_text: ">\nResearch Article\nAgriculture Field Automation and Digitization Using\
    \ Internet of\nThings and Machine Learning\nSushabhan Choudhury,1 Rajesh Singh,2,3\
    \ Anita Gehlot,2,3 Piyush Kuchhal,1\nShaik Vaseem Akram\n,2,4 Neeraj Priyadarshi\n\
    ,5 and Baseem Khan\n3,6\n1University of Petroleum and Energy studies, Dehradun,\
    \ Uttarakhand, India\n2Department of Research and Innovation, Uttaranchal Institute\
    \ of Technology, Uttaranchal University, Dehradun 248007, India\n3Department of\
    \ Project Management, Universidad Internacional Iberoamericana, Campeche C.P.\
    \ 24560, Mexico\n4Law College Dehradun, Uttaranchal University, Dehradun 248007,\
    \ India\n5Department of Electrical Engineering, JIS College of Engineering, Kolkata\
    \ 741235, India\n6Department of Electrical and Computer Engineering, Hawassa University,\
    \ Hawassa, Ethiopia\nCorrespondence should be addressed to Baseem Khan; basseemk@hu.edu.et\n\
    Received 21 May 2022; Revised 18 September 2022; Accepted 27 October 2022; Published\
    \ 12 November 2022\nAcademic Editor: Qiang Wu\nCopyright © 2022 Sushabhan Choudhury\
    \ et al. This is an open access article distributed under the Creative Commons\
    \ Attribution\nLicense, which permits unrestricted use, distribution, and reproduction\
    \ in any medium, provided the original work is\nproperly cited.\nThe real-time\
    \ smart monitoring with intelligence highly gained signiﬁcant attention for enhancing\
    \ the productivity of the crop.\nCurrently, IoT generates a lot of real-time data\
    \ from the sensors, actuators, and identiﬁcation technologies. However,\nextracting\
    \ the meaningful insights from the data is necessary for realizing the intelligent\
    \ ecosystem in agriculture. Based upon\nthe previous studies, it is also identiﬁed\
    \ that the limited studies have merely implemented machine learning (ML) on real-time\n\
    data obtained through customized hardware with dedicated server. In this study,\
    \ we have proposed a customized hand-held\ndevice that enables to deliver recommendations\
    \ to the farmer on the basis of real-time data obtained through IoT hardware\n\
    and ML. A three-layer structure is proposed in the study for realizing custom\
    \ hardware with 2.4 GHz ZigBee and IoT sensors\nfor the data acquisition, communication,\
    \ and recommendation. As a part of real-time implementation, the calibration of\
    \ the\nsensors is processed to form a real-time dataset with precision. The study\
    \ evaluated four ML models and concluded that\nXGBoost has shown a better accuracy\
    \ on the proposed dataset. The XGBoost recommended the crop based on selected\n\
    parameters. The developed hand-held device can be customized with advance features\
    \ with crop recommendations.\n1. Introduction\nAgriculture is the key to human\
    \ survival, as it is the main\nsource of grain and other basic resources. In addition,\
    \ agricul-\nture accounts for about 4% of the world’s gross national prod-\nuct\
    \ (GDP) [1]. Urbanization and population growth in 2050\nconclude that food production\
    \ must be sustainably doubled\nwith minimal water resources [2]. About 97% of\
    \ the water\non the planet is salty, while the remaining 3 is freshwater [3].\n\
    Agriculture uses 70% of freshwater for irrigation in most\ndeveloping countries\
    \ [4]. Therefore, the eﬃcient use of fresh-\nwater during irrigation is the most\
    \ signiﬁcant issue in terms\nof cost reduction and yield improvement. Using the\
    \ traditional\nmethod, farmers manually check and regulate the availability\n\
    of water resulting in a 50% water loss [5]. However, diﬀerent\nirrigation techniques\
    \ like drip irrigation, sprinkle irrigation,\nand furrow irrigation have minimized\
    \ water wastage by 30-\n70% [6]. Yet, the optimal management of water content\
    \ in\nthe soil is not yet achieved with these irrigation techniques\nas overwater\
    \ usage in the agricultural ﬁeld leads to an overﬂow\nof nutrients from the soil\
    \ [7].\nAgriculture also requires adequate levels of fertilizers\nand pesticides,\
    \ as farmers use fertilizers and pesticides while\nneglecting the optimal needs\
    \ of the crop. Apart from that,\nwater availability, nutrient levels, and soil\
    \ moisture are some\nother factors that aﬀect crop productivity as well. With\
    \ the\ntraditional approach, it is a challenging task for the farmer\nto determine\
    \ water availability, nutrient levels, and soil\nHindawi\nJournal of Sensors\n\
    Volume 2022, Article ID 9042382, 17 pages\nhttps://doi.org/10.1155/2022/9042382\n\
    moisture and also to identify which factor is ﬁghting food pro-\nduction [8].\
    \ Here, smart and real-time systems help to moni-\ntor the various parameters\
    \ of the agricultural ﬁeld and\neﬀectively control the water level with other\
    \ resources to\nincrease productivity [9]. Nowadays, real-time monitoring\nand\
    \ intelligent systems are possible with the Internet of Things\n(IoT), as IoT\
    \ monitors agriculture with IoT-enabled sensors\nand communication protocols implemented\
    \ in agriculture\n[10]. The above facts conclude that the IoT has played crucial\n\
    role in multiple areas including agriculture with its sensing,\ncommunication,\
    \ and real-time monitoring features through\nthe IoT hardware. Moreover, it is\
    \ concluded from the previous\nstudies that the ML model delivered signiﬁcant\
    \ results on real-\ntime data [11]. The study framed a research question “How\n\
    and for what purpose may the ML technology be used in agri-\nculture on IoT real-time\
    \ data? On the basis of this research\nquestion, this study has carried out the\
    \ literature review.\n1.1. Literature Review. Large-scale agricultural monitoring\n\
    applications require reliable WSN networks because the maxi-\nmum number of sensors\
    \ is operated over a long period. A wire-\nless sensor network architecture for\
    \ vegetable greenhouses is\npresented to achieve scientiﬁc cultivation and minimize\
    \ man-\nagement eﬀort from an environmental monitoring perspective\n[12]. Smart\
    \ greenhouse management systems and WSNs are\nused to control and monitor agricultural\
    \ parameters and activ-\nities in greenhouses autonomously [13, 14]. A smart green-\n\
    house information monitoring system records environmental\nfactors with ZigBee\
    \ wireless sensors [15].Wi-Fi-based smart\nWSN has been proposed to monitor the\
    \ agricultural environ-\nment, and the system allows intelligent monitoring of\
    \ agricul-\ntural conditions [16, 17]. WSN’s eﬀorts recommend that\nsensor data\
    \ can be collected and sent to the main server [18].\nA WPAN-based water quality\
    \ monitoring system has been\nproposed to clean up and collect real-time sensor\
    \ data on agri-\ncultural land with the LabVIEW data logger [19]. In addition\
    \ to\nWSN, the advent of IoT technology has enabled farmers and\ntechnologists\
    \ to solve the challenges farmers face, such as water\nshortages, cost control,\
    \ and productivity issues [20].\nA scalable IoT and WSN architecture is proposed\
    \ for\nremote monitoring and control of agriculture [21]. For the\nsame, an energy-saving\
    \ ZigBee sensor network with bidirec-\ntional communication and end devices is\
    \ integrated to\ndeliver data from the sensors to the PC at variable times\ndetermined\
    \ by the central node [22]. SiloSense is a unique\narchitecture based on ZigBee\
    \ to monitor the storage condi-\ntions of grain silos to protect them from spoilage\
    \ and disease\n[23]. The most important parameters that are required to\nmonitor\
    \ while growing wheat and other vegetables are soil\nmoisture, ambient temperature,\
    \ air pressure, and sunlight\nintensity [24]. mIoT- and WSN-based agricultural\
    \ system\nare for monitoring air, temperature, soil moisture, and\nhumidity with\
    \ RF modules [25]. The cloud-based and IoT-\nbased smart irrigation system is\
    \ designed to obtain data on\nsoil moisture, soil health, and temperature to reduce\
    \ water\nconsumption [26, 27]. IoT-based greenhouse agriculture is\nimplemented\
    \ to monitor climatic conditions and to obtain\ndata on a cloud server for analysis,\
    \ while the ZigBee protocol\nand the Wi-Fi module are integrated [28, 29]. The\
    \ IoT-based\nframework is designed to perform data analysis using real-\ntime\
    \ data to increase productivity on farms through temper-\nature, soil moisture,\
    \ and humidity sensor [30, 31].\nIoT-enabled plant disease and pest prediction\
    \ system is\nimplemented to reduce the use of insecticides and fungicides,\nand\
    \ additionally, an assessment of meteorological data is also\ncarried out to identify\
    \ the correlation between pest growth\nand climate [32]. ML helps to examine and\
    \ analyze data from\ndiﬀerent ﬁelds of agriculture to improve crop yields and\
    \ oﬀers\ndiﬀerent analytical techniques to predict the yield of crop and\nplant\
    \ disease [33, 34]. The ML-based predictive model helps\nfarmers to get the right\
    \ harvest with unconditional weather\nbehavior [35]. ML algorithms such as neural\
    \ network-based\nmodels are used for predictive analysis purposes [36]. From\n\
    the literature review, it is identiﬁed that smart monitoring in\nthe agricultural\
    \ ﬁeld needs to carry out with advanced technol-\nogies such as IoT. The literature\
    \ also concludes that they are\nlimited studies that analyzed the accuracy of\
    \ the data obtained\nthrough sensors. In addition to this, customization of hard-\n\
    ware on the basis of agricultural ﬁeld requirement is limitedly\nexplored by the\
    \ previous researchers. ML technique is applied\non diﬀerent datasets for disease\
    \ detection, environmental\nparameters monitoring, and automation in irrigation,\
    \ but the\nprevious studies have yet to explore the crop recommendation\non the\
    \ basis of real-time data. However, implementing ML on\nreal-time data primarily\
    \ requires a resource-constrained and\ndedicated server to fulﬁll the task of\
    \ acquiring real-time agri-\ncultural data rather than using it for multiple purposes.\n\
    To overcome this research, the gap of this study imple-\nments customized IoT\
    \ hardware for obtaining the real-time\nﬁeld data through wireless personal area\
    \ network (WPAN)\nand wireless local area network (WLAN). WPAN enables to\nminimize\
    \ the power consumption and also transmits the sen-\nsor data reliably and securely.\
    \ WLAN is used to connect the\ncustomized hardware to the cloud server through\
    \ IP protocol.\nTo maintain accuracy in the data, the calibration methods are\n\
    applied on the sensors. It is also identiﬁed from the previous\nstudy that IoT\
    \ requires analytical techniques to provide intel-\nligent decisions based on\
    \ real-time sensor data obtained from\nIoT sensors [11]. The contributions of\
    \ the study are as follows:\n(i) Customized hardware for sensor node, master node,\n\
    and hand-held device with ZigBee RF modem is\ndesigned for sensing the real-time\
    \ data of agricul-\ntural ﬁeld including temperature, humidity, soil\npH, and\
    \ water level\n(ii) An interference test is implemented to verify that\nthe ZigBee\
    \ signal is not interfering with other\nsignals on the same frequency band\n(iii)\
    \ To enhance the security of data transmission, the\nsymmetric encryption approach\
    \ with a private key\nis applied by leveraging XXTea encryption functions\n(iv)\
    \ A cloud server is developed to log the real-time sen-\nsor data of the agricultural\
    \ ﬁeld\n(v) The pretrained machine learning model is applied\nto real-time data\
    \ such as temperature, humidity,\n2\nJournal of Sensors\nrainfall, and soil pH\
    \ sensor on the cloud server for\nseasonal crop recommendations\nThe organization\
    \ of the study is as follows: Section 1.1\ncovers the proposed system. Section\
    \ 2 covers the circuit dia-\ngram for the development of the system. Section 3\
    \ covers\nsimulation analysis and calibration. Section 4 covers the\nreal-time\
    \ implementation of developed nodes and the cur-\nrent consumption analysis. The\
    \ article is concluded in the\nﬁnal section.\n2. Proposed Architecture\nTo realize\
    \ the main objective of crop recommendation, in\nreal-time, machine learning is\
    \ utilized. This system intends\nto leverage multiple sensors with real-time data\
    \ collection\nsuch as temperature, humidity, rainfall, and soil pH sensor\nto\
    \ improve the eﬃciency and the recommendation of crops,\nwith the support of machine\
    \ learning techniques. As shown\nin Figure 1, the architecture is divided into\
    \ multiple mod-\nules, with both software and hardware parts, each with its\n\
    purpose, from the hardware nodes, for data collection; the\nserver, for data processing;\
    \ and ﬁnally, the hand-held device\nto the user.\nThe system is composed of various\
    \ environmental sen-\nsors that are deployed around the agricultural ﬁeld to collect\n\
    data on a variety of characteristics such as water level, tem-\nperature, soil\
    \ pH, and humidity. This information is then\nsent to the master node, the main\
    \ hub of our system, which\nis in charge of communicating with the developed cloud\n\
    server and transferring the data obtained from the sensors.\nIn the server, the\
    \ information is stored and is also run\nthrough the ML algorithm to be studied.\
    \ From there, based\non the algorithm’s analysis, the information is presented\
    \ to\nthe user on a handheld device, such as crop recommenda-\ntion. The crop\
    \ recommendation feature is activated from\nthe hand-held device, and recommendations\
    \ are received\non the hand-held device based on the user’s request.\n2.1. Data\
    \ Acquisition Layer. The data acquisition layer is the\nprimary layer of the architecture\
    \ for acquiring the environ-\nmental parameters of the agricultural ﬁeld. This\
    \ layer is specif-\nically dedicated to continuously monitor the environmental\n\
    parameters including water level, temperature, humidity, light\nintensity, and\
    \ rain level. For this, IoT sensors are attached to\nthe sensor node as shown\
    \ in Figure 2 and through 2.4GHz\nZigBee communication [37], it transmits data\
    \ to the master\nnode. In addition, the sensor node is enabled with security,\n\
    interference technique, and node mapping feature for secure\nand reliable communication.\n\
    2.2. Data Processing Layer. IoT devices and sensors record\nthe environmental\
    \ parameters of the agricultural ﬁeld in real\ntime. Sensory data processing is\
    \ done with the data process-\ning layer. The master node, which consists of the\
    \ ZigBee RF\nmodule, receives the data from the data acquisition layer and\ntransmits\
    \ it to the cloud server via a Wi-Fi module\n(Figure 3). The master node is powered\
    \ by the battery power\nsupply. The data logger is also available in the data\
    \ process-\ning layer for visualizing the sensor data through Bluetooth.\nThe\
    \ master node with a Wi-Fi module connects to the Inter-\nnet to log the sensory\
    \ data in the cloud server.\n2.3. Analytics and Visualization Layer. Figure 4\
    \ illustrates the\nsystem logic, where it explains the preprocessing and analysis\n\
    of gathered data from the sensor node. The sensor data is\nreceived at the master\
    \ node which is converted into a set of\nscripts and is logged into the cloud\
    \ server. Here, a cloud server\nis also developed to log the sensor node values.\
    \ In the prepro-\ncessing step, the sensor data is converted into a suitable format\n\
    for performing machine learning analyses. The data is fed to a\nmachine learning\
    \ model and based on the data the model, it\nsuggests recommended crop. The outcome\
    \ of the model is\nstored in the cloud server, and the hand-held device that con-\n\
    nects to the cloud server also visualizes the recommended crop\nand real-time\
    \ sensor data. To provide the user with a way to\nsee the data collected from\
    \ the sensors and machine learning\noutcomes, a cloud server is developed.\nA\
    \ cloud server is developed with two diﬀerent API pro-\ntocols for data exchange\
    \ between backend and frontend\nand backend and custom gateway. The interface\
    \ between\nthe backend and the frontend for the exchange of data is\nimplemented\
    \ with the REST API. REST APIs use HTTP\nrequests to perform basic database activities\
    \ within a\nresource, such as creating, reading, updating, and deleting\nrecords.\
    \ REST APIs accept JSON for the request payload\nand send responses to JSON. JSON\
    \ is the standard for data\ntransfer. The interface between the backend and the\
    \ gateway\nis implemented using the MQTT protocol. The cloud server\nassists in\
    \ checking all the sensor values retrieved from the\nagricultural ﬁeld in real\
    \ time. Moreover, a hand-held device\nis connected to the cloud server for providing\
    \ the updates of\nthe crop based on request generated by the user.\n3. Hardware\
    \ Development\nIn this section, we present the schematic diagram of the sen-\n\
    sor node that is primarily implemented for data acquisition.\nMoreover, the customization\
    \ is carried out for the hardware\nof agricultural monitoring including data logger\
    \ and hand-\nheld device. A detailed description of the sensor node and\nthe hand-held\
    \ device is presented below.\n3.1. Sensor Node. Figure 5 illustrates the connection\
    \ of diﬀer-\nent electronic components of the sensor node. The node is\ncomposed\
    \ of a 2.4 GHz RF modem that works in full-\nduplex mode to transmit the data\
    \ from one node to another\nconnected in the network. Principally, two sensors\
    \ (gas\nsensor and humidity sensor) are connected to the node\nwhich are placed\
    \ in the ﬁeld. The function of the gas sensor\nis to measure the concentration\
    \ of the gas (such as LPG and\nbutane) in the present environment. The humidity\
    \ of the\nenvironment is detected with the help of a humidity sensor.\nThe humidity\
    \ sensor gives serial data at the 9600 baud rate\nto the microcontroller. The\
    \ output of these sensors is in\nanalog form. Analog signal from the sensor is\
    \ fed onto the\nanalog to digital pin of the ATMEGA 8 [38].\nThe function of this\
    \ pin is to convert the analog signal\ninto a digital signal. After fetching the\
    \ signal from a sensor\n3\nJournal of Sensors\nattached, the microcontroller performs\
    \ the logical operation\nand controls the overall operation. A display (16∗2 LCD)\
    \ is\nattached to each node. The function of this is to display\nthe measured\
    \ parameters. MAX 232 IC is also used to pro-\nvide communication between the\
    \ node and PC. With the\nhelp of this, the end-user can easily observe the parameters\n\
    and execute the needful action. The whole circuit is working\non the 5 V power\
    \ supply. The RF module is attached to the\nSensor\nnode ‘1’\nMaster\nnode\nData\n\
    logger\nBluetooth\nHandheld device\nData processing layer\nData acquisition layer\n\
    Zigbee\nVisualization & analytics layer\nReal time\nsensor data\nCloud\nserver\n\
    Real\ntime\nsensor\ndata\nReal time\nsensor data\nPre-trained\nmachine\nlearning\n\
    model\nPre-\nprocessing\nReal time\nsensor data\nFinal\noutcome\nFinal\noutcome\n\
    Sensor\nnode ‘2’\nSensor\nnode ‘3’\nSensor\nnode ‘n’\nFigure 1: Proposed architecture.\n\
    ATMEGA 32\ncontroller\npH\nsensor\nDHT\nsensor\nWater level\nsensor\nGas\nsensor\n\
    Zigbee RF\nmodule\nVoltage\nconverter\nBattery\npower supply\nFigure 2: Sensor\
    \ node.\n4\nJournal of Sensors\ntransmitter and receiver pin of the microcontroller.\
    \ A Zig-\nBee module (CC2500) [37] is used in the system to provide\nwireless\
    \ communication in the network. This module works\nin full-duplex mode and also\
    \ can communicate with many\ndevices at the same time. The topology of each node\
    \ in the\npresented network is based on mesh topology. All the\nrequired components\
    \ are integrated and developed hard-\nware of the sensor node as shown in the\
    \ Figure 6. The sensor\nnode is integrated with LCD to visualize the sensor values.\n\
    3.2. Hand-Held Device. Figure 7 shows the circuit diagram of\na hand-held device\
    \ that consists of a Bluetooth modem. The\nmain function of this modem is to receive\
    \ the data trans-\nferred from the data logger node. This node is at the end-\n\
    user and easily provides the collected data to the end-user.\nThis node is connected\
    \ with other nodes in a mesh topology.\nA display is used for showing the measured\
    \ data. Based on\nthis data, end-user can easily take the decision. Figure 8 illus-\n\
    trates the hardware of the hand-held device, and the hand-\nheld device is also\
    \ integrated with display to visualize the\ndata like real-time sensor value and\
    \ crop recommendation.\n3.2.1. Current Consumption Analysis of Hardware. Current\n\
    consumption analysis is performed based on the current\nrequired by each component\
    \ used to develop the system.\nThe power consumption by the ZigBee RF modem is\
    \ maxi-\nmum for each node, followed by consumption by the micro-\ncontroller.\
    \ Even though power was not a design issue for the\nsystem, it is evident that\
    \ the designed system requires less\npower than standard available devices like\
    \ Mica2 and Micaz\nnodes. The current consumption analysis concludes that the\n\
    designed hardware is consuming less amount of power during\nthe data transmission.\
    \ Speciﬁcally, the hand-held device is\nonly consuming a current of 79mA. The\
    \ current consumption\nmay vary when the components in the hardware are increased.\n\
    From Table 1, it is concluded that the power consumption of\nnode 1 is 85mA, node\
    \ 2 is 85mA, node 3 is 264mA, node 4\nis 104mA, and node 5 is 83mA. To meet the\
    \ power require-\nment of the sensor node, an energy harvesting system will be\n\
    integrated into the sensor node in the future. In agriculture,\nsolar panels will\
    \ be used to implement solar energy harvesting\nsystems on sensor nodes. Table\
    \ 2 shows the current consump-\ntion of the hand-held device, and it is 79mA.\
    \ The power to the\nhand-held device is achieved with the battery.\nATMEGA 32\n\
    controller\nWi-Fi\nmodule\nZigbee RF\nmodule\nVoltage\nconverter\nBattery\npower\
    \ supply\nBluetooth\nmodule\nFigure 3: Master node.\nDHT\nsensor\npH\nsensor\n\
    Rainfall\nsensor\nField data is\nobtained\nSent data to\nmaster node\nSent to\n\
    cloud server\nPre-trained\nmachine\nlearning model\nDecision tree,\nKNN, SVM\n\
    Processing\nFinal\noutcome\nCloud\nserver\nHand-held\ndevice\nFigure 4: System\
    \ logic.\n5\nJournal of Sensors\n3.3. Calibration of Sensors. In this section,\
    \ sensor calibration\nis performed to set the sensor to operate accurately and\n\
    without error. This section describes the sensor calibrations\n(temperature/humidity,\
    \ soil moisture, and ultrasonic) used\nto develop the system. Sensor calibration\
    \ is an important\nstep, before the actual implementation of the sensor in the\n\
    system. For the developed system, each sensor is ﬁrst cali-\nbrated with standard\
    \ instruments and after checking its\naccuracy, sensors are used in the system.\
    \ For calibrating soil\nmoisture sensors, the oven method is used. For temperature/\n\
    OSC11\nOSC11\nOSC21\nOSC33\nOSC22\nPA1\nPA0\nPA0\nPA1\n22 p\nD0\nE\nRW\nRS\nVEE\n\
    VDD\nVSS\n7\n6\n5\n4\n3\n2\n1\n8\n9\n10\n11\n12\n13\n14\nD1\nD2\nD3\nD4\nD5\n\
    D6\nD7\nD0\nE\nRW\nRS\nVEE\nVDD\nVSS\n7\n6\n14\nPC0/ADC0\nPC1/ADC1\nPC2/ADC2\n\
    PC3/ADC3\nPC4/ADC4/SDA\nPC5/ADC5/SCL\nPC6/RESET\nPD0/RXD\nPD1/TXD\nPD2/INT0\n\
    PD3/INT1\nPD4/TD/XCK\nPD5/T1\nPD6/AIN0\nPD7/AIN1\nPC0/ADC0\nPC1/ADC1\nPC2/ADC2\n\
    PC3/ADC3\nPC4/ADC4/SDA\nPC5/ADC5/SCL\nPC6/RESET\nPD0/RXD\nPD1/TXD\nPD2/INT0\n\
    PD3/INT1\nPD4/TD/XCK\nPD5/T1\nPD6/AIN0\nPD7/AIN1\nPC0/ADC0\nPC1/ADC1\nPC2/ADC2\n\
    PC3/ADC3\nPC4/ADC4/SDA\nPC5/ADC5/SCL\nPC6/RESET\nPD0/RXD\nPD1/TXD\nPD2/INT0\n\
    PD3/INT1\nPD4/TD/XCK\nPD5/T1\nPD6/AIN0\nPD7/AIN1\nPB0/ICP1\nPB1/OC1A\nPB2/SS/OC1B\n\
    PB3/MOSI/OC2\nPB4/MISO\nPB5/SCK\nPB6/TOSC1/XTAL1\nPB7/TOSC2/XTAL2\nAREF\nAVCC\n\
    ATMEGAB\nATMEGAB\nATMEGAB\nPB0/ICP1\nPB1/OC1A\nPB2/SS/OC1B\nPB3/MOSI/OC2\nPB4/MISO\n\
    PB5/SCK\nPB6/TOSC1/XTAL1\nPB7/TOSC2/XTAL2\nAREF\nAVCC\nPB0/ICP1\nPB1/OC1A\nPB2/SS/OC1B\n\
    PB3/MOSI/OC2\nPB4/MISO\nPB5/SCK\nPB6/TOSC1/XTAL1\nPB7/TOSC2/XTAL2\nAREF\nAVCC\n\
    23\n24\n25\n26\n27\n28\n1\n2\n3\n4\n5\n6\n11\n12\n13\n23\n24\n25\n26\n27\n28\n\
    1\n2\n3\n4\n5\n6\n13\n12\n11\n23\n24\n25\n11\n16\n14\n13\n7\n8\n1\n6\n2\n7\n3\n\
    8\n4\n9\n5\n2\n6\n12\n10\n15\nC1\nC3\nC4\nSerial port\nMAX232\nRF modem\nRF modem\n\
    RF modem\nMicrocontroller Atmega8\nMicrocontroller Atmega8\nMicrocontroller Atmega8\n\
    RXD\nTXD\nTXD\nVcc\nGND\nU2\nC2\n9\n26\n27\n28\n1\n2\n3\n4\n5\n6\n13\n12\n11\n\
    11F\n11F\n12 V\n11F\n1\n3\n4\nC2+\nC2–\nC1+\nC1–\n5\nMAX232\n15\n16\n17\n18\n\
    19\n9\n10\n5\n4\n3\n2\n1\n8\n9\n10\n11\n12\n13\n14\nD1\nD2\nD3\nD4\nD5\nD6\nD7\n\
    14.7456 MHz\n14.7456 MHz\n22 p\nOSC21\nOSC33\nOSC22\nX1\nX1\nC2\nU3\nU2\nC3\n\
    22 p\nC3\n22 p\nC2\nCrystal\nCrystal\nDisplay LCD16±2\nDisplay LCD16±2\nU1\n21\n\
    20\n14\n15\n16\n17\n18\n19\n9\n10\n21\nRXD\nTXD\nTXD\nTXD\nRXD\nVcc\nGND\nRXD\n\
    TXD\nT1IN\nR1OUT\nT2IN\nR2OUT\nT1OUT\nR1IN\nT2OUT\nR2IN\nVS+\nVS–\nVcc\nGND\n\
    20\n14\n15\n16\n17\n18\n19\n9\n10\n21\n20\nGas sensor\nHumidity and temp.\nsensor\n\
    Figure 5: Circuit diagram for the sensor node.\nFigure 6: Hardware of sensor node.\n\
    6\nJournal of Sensors\nCOMPIM\nATMEGA32\nDiode\n+5 V Power supply\n+12 V\nRF modem\n\
    Resistor\nD2\n+5 V\nRXD\nTXD\nTXD\nVcc\nGND\nRx\nTx\nVcc\nGND\nBluetooth modem\n\
    Capacitor\nLED indicator\n3\n32\n21\n20\n19\n18\n17\n16\n15\n14\n29\n28\n27\n\
    26\n25\n24\n23\n22\n2\n3\n1\n5\n6\n4\n8\n9\n7\n11\n12\n13\n14\nD0\nE\nRW\nRS\n\
    VEE\nVSS\nVDD\nD1\nD2\nD3\nD4\nD5\nD6\nD7\n10\n9\n1\n2\n3\n4\n5\n6\nC3\nC2\n14.7456\n\
    XTAL\n7\n8\n22 pf\n22 pf\n13\n12\n40\n39\n38\n37\n36\n35\n34\n33\n30\n330\n1\n\
    2\nVO\nVI\n7805\n1N4007\n1000 u/35 V\nB1\nSwitch\nSW-DPDT\n12 V Battery\nGND\n\
    7805\nP1\nR1\nLCD1\nLMO16L\nReset Ckt\nC1\nDCD\n1\n6\n2\n7\n3\n8\n4\n9\nDSR\n\
    RXD\nRTS\nTXD\nCTS\nDTR\nRI\nERROR\n4.7 k\n10 uf\nRESET\nU1\nXTAL1\nXTAL2\nPD0/RXD\n\
    PD1/TXD\nPD2/INT0\nPD3/INT1\nPD4/OC1B\nPD5/OC1A\nPD6/CP1\nPD7/OC2\nAREF\nAVCC\n\
    PC0/SCL\nPC1/SDA\nPC2/TCK\nPC3/TMS\nPC4/TDO\nPC5/TDI\nPC6/TOSC1\nPC7/TOSC2\nPA0/ADC0\n\
    PA1/ADC1\nPA2/ADC2\nPA3/ADC3\nPA4/ADC4\nPA5/ADC5\nPA6/ADC6\nPA7/ADC7\nPB0/T0/XCK\n\
    PB1/T1\nPB2/AIN0/INT2\nPB3/AIN1/OC0\nPB4/SS\nPB5/MOSI\nPB6/MISO\nPB7/SCK\nFigure\
    \ 7: Circuit diagram of the hand-held device.\nFigure 8: Hardware of hand-held\
    \ device.\n7\nJournal of Sensors\nhumidity sensor calibration, psychrometric is\
    \ used. The\nultrasonic sensor is calibrated with a standard measurement\nruler.\
    \ Tests were carried out for each sensor and compared\nwith standard instruments,\
    \ and it was observed that the sen-\nsors were calibrated appropriately as follows.\n\
    3.3.1. Soil Moisture Sensor. The soil moisture sensor is taken\nfrom the Sunrom\
    \ model (http://sunrom.com/) no. 1282\n[39]. The sensor gives a reading in terms\
    \ of numerical\nvalues, as can be seen in Table 3. This sensor measures mois-\n\
    ture based on the volumetric water content in the soil. On\nthe other hand, the\
    \ standard oven method for ﬁnding soil\nmoisture gives a reading in percentage.\
    \ Initially, the sensor\nreadings are mapped by the oven method [40] to check\
    \ the\nerror between the sensor value and instrument value.\nFigure 9 shows the\
    \ relation between soil moisture content\nshown by the sensor and by standard\
    \ instrument. It provides\ncalibration values of the sensor concerning the percentage\n\
    value of the oven method. To validate the calibration,\nrepeated experiments were\
    \ conducted by taking soil samples\nfrom ﬁve diﬀerent places with valid water\
    \ content and cali-\nbrated them with the standard instruments. Table 4 shows\n\
    the sample readings by soil moisture content (%) with sensor\nvalues. The sensor\
    \ reading from the sensor is received by an\nanalog-to-digital converter (ADC)\
    \ and converted to a %\nvalue using equation (1). If the ADC value of the sensor\
    \ is\n255, then the value is considered 100% accurate concerning\nthe standard\
    \ oven method.\nSoil moisture %\nð Þ = wet soil g\nð Þ‐dry soil g\nð Þ\nð\nÞ ∗\n\
    100\ndry soil g\nð Þ :\nð1Þ\n3.3.2. Ultrasonic Sensor. An ultrasonic sensor [41]\
    \ is calibrated\nwith a standard scale. Table 5 clearly shows the bias value\n\
    between sensor value and scale which is 3cm in each case. So,\nthis biasing is\
    \ managed by programming the microcontroller\naccordingly. It shows a constant\
    \ bias value by the sensor, which\nis eliminated with the help of the microcontroller\
    \ program.\nAfter calibration, the sensor shows accurate readings.\n3.3.3. Temperature/Humidity\
    \ Sensor. Temperature/humidity\nis calibrated with a psychrometer [42]. It is\
    \ achieved by map-\nping the values of the sensor with that of the standard instru-\n\
    ment. The values are adjusted using programming the\ncontroller. The readings\
    \ are taken every half an hour in\nMarch 2020. As shown in Table 6, readings are\
    \ taken, and\nTable 1: Current consumption analysis of sensor nodes.\nComponents\n\
    Node 1 (mA)\nNode 2 (mA)\nNode 3 (mA)\nNode 4 (mA)\nNode 5 (mA)\nMicrocontroller\n\
    17\n17\n17\n17\n17\nRF modem\n58\n58\n58\n58\n58\nSensor 1\n1\n1\n1\n1\n1\nSensor\
    \ 2\n5\n5\n180\n20\n3\nLCD (16 × 2)\n4\n4\n4\n4\n4\nTotal (mA)\n85\n85\n264\n\
    104\n83\nTable 2: Current consumption analysis of hand-held device.\nComponent\n\
    Current (mA)\nMicrocontroller\n17\nRF modem\n58\nLCD (16 × 4)\n4\nTotal (mA)\n\
    79\nTable 3: Calibration of soil moisture sensor with the standard\nmethod.\n\
    Soil moisture reading\nStandard value (%) (oven method)\n100\n39\n120\n46.8\n\
    150\n58.5\n200\n78\n250\n97.5\n255\n100\n0\n50\n100\n150\n200\n250\n300\n0.39\n\
    7.8\n15.6\n23.4\n31.2\n39\n58.5\n97.5\nSoil moisture reading by sensor\nStandard\
    \ instrument value (%)\nSoil moisture by sensor\nFigure 9: Calibration of soil\
    \ moisture sensor w.r.t. standard\ninstrument.\n8\nJournal of Sensors\nthe sensor\
    \ is calibrated accordingly. For calibration of the\nsensor, a psychrometer is\
    \ used as per the calculation given\nin [43].\n3.4. Security and Interference\
    \ Test\n3.4.1. Security. As part of the security feature, during the\nimplementation\
    \ stage, we employ the AVR family of micro-\ncontrollers for applications comparable\
    \ to the one being\nproposed. Complex algorithms are a curse in AVR utilizing\n\
    time complex or memory because they frequently turn the\nexecuting code into a\
    \ blocking one, which means that any\nother routine to be conducted by the controller\
    \ is blocked\nand may create delays in executing the intended function.\nKeeping\
    \ these factors in mind, we should take considerable\nsensitivity while employing\
    \ cryptographic algorithms in\nthese low-bit controllers. Cryptographic functions\
    \ like\nXXTea and AVRCrypto can be used to implement the\nencryption method. In\
    \ our case, we use the XXTea encryp-\ntion functions to implement symmetric encryption\
    \ with pri-\nvate keys that remain exclusive to another layer of network\nnodes\
    \ to increase the security of data communication.\n3.4.2. Interference. The basic\
    \ parameter for detecting and\nhandling interference includes bit error rate (BER),\
    \ packet\nerror rate (PER), received signal strength indicator (RSSI),\nsignal-to-interference-to-noise\
    \ ratio (SINR), throughput,\nand time delay. In this study, we apply an interference\
    \ avoid-\nance algorithm based on frequency agility [39]. This algo-\nrithm allows\
    \ ZigBee to detect interference and ﬂexibly\nmove nodes to a secure channel with\
    \ minimal power con-\nsumption and minimal latency while handling the interfer-\n\
    ence. In this technique, the end devices measure PER with\na transmission time\
    \ of at least 20 packets, and if the PER\ngoes beyond the 25% level, the interference\
    \ information is\ntransferred to the parent router to assess the link quality\n\
    indicator (LQI). When the parent router determines that\nthe LQI value is less\
    \ than 100, it instructs the scanning\nenergy detection to perform interference\
    \ detection on acces-\nsible channels (ED).\nPER =\nNumber of failed messages\n\
    Number of attempted measurements\n\x01\n\x03\n∗ 100%:\nð2Þ\n4. Machine Learning\
    \ Models\nAs previously stated, the machine learning algorithm is used\nto recommend\
    \ the crop based on sensor data. To achieve it,\nthe algorithm must ﬁrst be trained\
    \ to understand the system\nand the environment to provide the outcome of crop\n\
    Table 4: Soil moisture sensor and reading by standard method for diﬀerent samples.\n\
    (a)\nSamples\nSample 1\nSample 2\nWet soil (g)\nDry soil (g)\nSoil moisture\n\
    Wet soil (g)\nDry soil (g)\nSoil moisture\nStandard instrument reading\n114\n\
    98\n16%\n62\n52\n19.23%\nSensor reading\n42\n49\n(b)\nSample 3\nSample 4\nSample\
    \ 5\nWet soil\n(g)\nDry soil\n(g)\nSoil\nmoisture\nWet soil\n(g)\nDry soil\n(g)\n\
    Soil\nmoisture\nWet soil\n(g)\nDry soil\n(g)\nSoil\nmoisture\nStandard instrument\n\
    reading\n68\n50\n36%\n72\n52\n38.46%\n78\n53\n47.16%\nSensor reading\n93\n95\n\
    123\nTable 5: Calibration of ultrasonic sensor with standard instrument.\nDistance\
    \ by standard\nscale (cm)\nDistance by ultrasonic\nsensor (cm)\nBias (cm)\n10\n\
    13\n3\n20\n23\n3\n30\n33\n3\n40\n43\n3\n50\n53\n3\nTable 6: Calibration of temperature/humidity\
    \ sensor with a\nstandard instrument.\nDry\ntemperature\nby standard\ninstrument\n\
    Wet\ntemperature\nby standard\ninstrument\nRelative\nhumidity by\na standard\n\
    instrument\nin %\nTemp.\nsensor\n(Sunrom\n1211)\nHumidity\nby the\nsensor in\n\
    % (Sunrom\n1211)\n18\n10.8\n47.3\n18\n47\n19\n11.5\n46.1\n19\n46\n20\n12.1\n45\n\
    20\n45\n21\n12.7\n44\n21\n44\n22\n13.4\n42\n22\n43\n23\n13.8\n41\n23\n41\n24\n\
    14.1\n42\n24\n42\n9\nJournal of Sensors\nrecommendations. One of the goals of\
    \ this study is that to\nchoose which algorithm is the best algorithm that can\
    \ be\nused not only in the system but in other situations with sim-\nilar data.\
    \ To do this, four diﬀerent classiﬁcation algorithms\nwere tested to see which\
    \ one had the highest accuracy.\n(a) Decision trees (DTs): through hierarchical\
    \ partition-\ning of training data, some functions are used to split\nthe data,\
    \ and this division is done iteratively until the\nleaf node contains the number\
    \ record amount that\ncan be used to classify data [44, 45]. However, as\n(a)\
    \ Customized hardware\n(b) Sensor node with sensors\n(c) Blueterm data logger\n\
    Figure 10: Hardware prototype.\n10\nJournal of Sensors\ndescribed in [46], this\
    \ algorithm faces some limita-\ntions because a small change in the training data\n\
    set can lead to a signiﬁcant change in the tree and\npredicting the next value\
    \ with accuracy becomes\nmore diﬃcult\n(b) Support vector machine (SVM) is used\
    \ mainly for\nclassiﬁcation, classiﬁes data by building dimensions\nn between\
    \ two classes, ﬁnds an optimal hyperplane\nto classify data, uses interval distance\
    \ between neigh-\nboring points, and distinguishes between classes\nwith minimum\
    \ error margin [47]. According to a\nsimpler interpretation, given the training\
    \ data, the\nalgorithm generates the best hyperplanes ranking\nnew examples\n\
    (c) Random forest (RF) is best applied to classiﬁcation\nproblems and integrates\
    \ the DT aggregate packing\nprocess by selecting a subset of features from the\n\
    individual nodes in the tree, avoiding correlation\non the bootstrap set [45]\
    \ and working with a tree\nclassiﬁer, where one tree for each classiﬁer\n(d) XGBoost:\
    \ with the same model as DT, the goal of\nthis algorithm is, as the name suggests,\
    \ to improve\nthe performance of the model. It creates a sequence\nof models,\
    \ and instead of training all the models\nindividually, it models consecutively\
    \ so that the\nnew models try to correct the errors of the previous\nmodels [48].\
    \ The ﬁrst model is built on the original\n(a) Sensor node\n(b) Gateway\n(c) Sensor\
    \ node deployed in agricultural ﬁeld\nFigure 11: Final hardware and deployed sensor\
    \ node in the agricultural ﬁeld.\nTable 7: Data splitting in training and testing.\n\
    Total samples\nRatio\nTraining sample\nTesting sample\n32,000\n70 : 30\n22,400\n\
    7,600\nTable 8: Features of each data set.\nFeature\nDescription\nSensorIDi\n\
    ID of sensor\nValuei\nCollected value\naveragei\nAverage of the sensor values\
    \ for last ﬁve\nobservations\ndiﬀ_seni\nDiﬀerence from other sensor\nhasRecommendationi\n\
    Recommendation of crop\n11\nJournal of Sensors\ndata set, the second model improves\
    \ the ﬁrst model,\nthe third model improves the second model, and so\non. Models\
    \ were added sequentially until no further\nimprovements could be made\n4.1. Data\
    \ Creation. The complete hardware of the proposed\nsystem is shown in Figure 10(a).\
    \ Figure 10(b) illustrates the\nsensor node based on the 2.4 GHz ZigBee module\
    \ that is\nembedded with multiple sensors including water level, tem-\nperature,\
    \ humidity, pH, and light intensity. Moreover, the\nsensor node is interfaced\
    \ with a liquid crystal display for\nvisualizing the sensor data. In this study,\
    \ a custom sensor\nnode with IoT sensors is deployed in the agricultural sector\n\
    of the Maheru, Punjab region as shown in Figure 11. The\nsensor node is deployed\
    \ in an outdoor environment to get\ndata from the sensors in real time. As discussed\
    \ earlier in\nthis section, the sensor node is interfaced with multiple sen-\n\
    sors to detect the environmental parameters of the farm ﬁeld\nand communicate\
    \ with the cloud server through a master\nnode based on 2.4 GHz ZigBee communication\
    \ and wireless\nﬁdelity (Wi-Fi).\nThe input parameters of the sensor data are\
    \ temperature,\nhumidity, water level, and soil pH. The 32,000 samples of\nIoT\
    \ sensor nodes over 6 months are used to build a dataset\nfor training. The manual\
    \ data splitting methods have been\nadopted in which the total number of samples\
    \ is divided into\ntraining and testing samples. The 70: 30 ratio is chosen for\n\
    the proposed dataset, in which 70% for training and 30%\nfor testing as shown\
    \ in Table 7.\nDuring dataset generation, besides collected timestamps\nand sensor\
    \ data, other features were added to each record\nbased on calculations and preprocessed\
    \ data from the values\nof the sensor. Table 8 shows the features of each data\
    \ set.\nThe diﬀerence between datasets is that the standard one only\nhas one\
    \ entry for each of the features while the clustered one\nhas three entries for\
    \ sensorID, average, value, and diﬀ_sen,\neach one regarding the three sensors\
    \ used in the test.\n4.2. Model Analysis. A variety of ML algorithms were used\
    \ to\nanalyze the model to ﬁnd the best one to use in our system.\nFor our case,\
    \ we performed a total of 8 tests for each\nalgorithm, each with a diﬀerent set\
    \ of parameters, to train\nthe algorithms to determine which one has the highest\n\
    accuracy so that it can be applied in our system. Each test\nwas run using Python,\
    \ the scikit-learn library [37], and the\nSpyder platform. Scripts were developed\
    \ for each algo-\nrithm using the appropriate library for scikit-learn classiﬁ-\n\
    cation and used the default conﬁguration. As mentioned\nearlier, 70% of the dataset\
    \ was used for training, and\n30% was used for testing. Table 9 shows the results\
    \ of\neach test, and Figure 12 shows the same results to improve\nthe analysis.\n\
    Table 9: Accuracy of the model.\nAccuracy (%)\nModel\n1\n2\n3\n4\n5\n6\n7\n8\n\
    DT\n79.45\n73.74\n81.81\n73.90\n81.64\n74.99\n80.94\n73.95\nSVM\n29.91\n29.36\n\
    48.97\n49.40\n53.94\n33.82\n60.02\n43.95\nRF\n76.20\n69.85\n80.35\n73.53\n80.35\n\
    73.42\n80.17\n74.49\nXGBoost\n80.45\n75.20\n75.74\n78.82\n85.06\n80.36\n86.71\n\
    83.64\n20\n30\n40\n50\n60\n70\n80\n90\n1\n2\n3\n4\n5\n6\n7\n8\nAccuracy\nNumber\
    \ of tests\nAccuracy (%)\nDT\nSVM\nRF\nXGBoost\nFigure 12: Accuracy of model.\n\
    12\nJournal of Sensors\nTemperature\n45\n80\n70\n60\n50\n40\n30\n40\n35\n30\n\
    25\n20\n2\n1\n0\n3\n6\n5\n4\n3\n8\n7\n20\n40\n60\n80\n0\n20\n40\n60\n80\n0\n20\n\
    40\n60\n80\n0\n20\n40\nRice\nWheat\n60\n80\n0\nNumber of samples\nHumidity\nRain\
    \ level\nSoil pH\nFigure 13: Crop recommendation based on temperature, humidity,\
    \ rain level, and soil pH.\n2\n1\n0\n3\n6\n5\n4\n3\n8\n7\n45\n80\n70\n60\n50\n\
    40\n30\n40\n35\n30\n25\n20\nGreen leaves\nTomato\n20\n40\n60\n80\n100\n0\n20\n\
    40\n60\n80\n100\n0\n20\n40\n60\n80\n100\n0\n20\n40\n60\n80\n100\n0\nNumber of\
    \ samples\nTemperature (in C)\nHumidity\nNutrients level\nLight intensity (candela)\n\
    Figure 14: Crop recommendation based on temperature, humidity, nutrients, and\
    \ light intensity.\n13\nJournal of Sensors\n5. Real-Time Implementation\nThe hardware\
    \ prototype is deployed in real-time to evaluate\nthe developed system for obtaining\
    \ crop recommendations\nbased on sensor values. As shown in ﬁgure 4, the real-time\n\
    sensor values are fed to the pretrained model. Based on\nreceived real-time sensor\
    \ data, the XGBoost model has\nachieved better accuracy among the other pretrained\
    \ ML\nmodels as shown in Table 9. Furthermore, the outcome of\nthe model is illustrated\
    \ in Figures 13(a) and 13(b). In\nFigure 13(a), the crop recommendation is processed\
    \ based\non temperature, humidity, rain level, and soil pH. The x\nTable 10: Comparisons\
    \ with previous studies.\nRef\nCommunication\nData\nprocessing\nAnalytics\nInterference\n\
    Calibration\nHand-held device\nSecurity\n[24]\nWi-Fi\nRaspberry Pi\nis used for\n\
    data\nprocessing\nDecision tree\nalgorithm\nInterference\ntest is not\ncarried\
    \ out\nSensors are not\ncalibrated\nNA, an email has\nbeen used for alerts\nSecurity\
    \ for data\ntransmission is not\nintegrated into the\nhardware\n[49]\nLoRa + Wi-Fi\n\
    Gateway\nNot\nimplemented\nInterference\nbetween the\nsensor node\nand gateway\n\
    is not\nmentioned\nSensors are not\ncalibrated\nYes\nHardware is not\nempowered\
    \ with\nsecurity for data\ntransmission\n[50]\nWi-Fi\nGateway\nNot\nimplemented\n\
    Wi-Fi based\non 2.4 GHz\ninterference\nis not\nimplemented\nSensors are not\n\
    calibrated\nNA\nAsymmetric\nencryption for data\ncommunication is\nnot available\n\
    [51]\nNA\nEdge\ncomputing\nDeep\nreinforcement\nlearning\nNot\nmentioned\nSensors\
    \ are not\ncalibrated\nNA\nSecurity for data\ntransmission is not\nmentioned\n\
    [52]\nNA\nData\naggregator\nDecision\nsupport system\n(DSS)\nNot\nmentioned\n\
    Sensors are not\ncalibrated\nNo\nHardware is not\nempowered with\nsecurity for\
    \ data\ntransmission\n[53]\nLoRa\nLoRa\ngateway\nNo analytics\nare carried out\n\
    Not\ndiscussed\nUtilized PIR,\nDTH11 and soil\nmoisture\nsensor, but\ncalibration\
    \ is\nnot carried out\nNo\nNo\n[54]\nLoRa\nGateway\nSystem is\nimplemented\nin\
    \ real-time for\ntesting, but no\nanalytics are\ncarried out\nInterference\nare\
    \ not\nappeared\nduring\ntransmission\nSensor\ncalibration is\ncarried out but\n\
    no discussion\nabout the\ncalibration is\navailable\nNo visualizing\ndevice or\
    \ hand-held\ndevice\nSecurity to the\nsystem is\nimplemented with\nRFID, but during\n\
    communication, no\nsecurity feature is\nconsidered\n[55]\nLoRa+ NB-IoT\nAggregation\n\
    node\nSVM is\nimplemented\nfor detecting\nthe leaks based\non sensor data\nNA\n\
    Calibration\nAn android\napplication is\ndeveloped to\nvisualize the sensor\n\
    values in real time\nSecurity between the\nnode to node is not\nexplored\nProposed\n\
    study\n2.4 GHz + Wi-Fi Master node\nReal-time\nanalytics on\nsensor data\nwith\
    \ a\npretrained\nmodel\nInterference\navoidance\nalgorithm\nbased on\nfrequency\n\
    agility\nSensor\ncalibration with\na standard\ninstrument to\nconﬁrm the\nerror-free\n\
    sensor value\nHand-held device to\nreceive the real-time\nsensor data and crop\n\
    recommendation\nbased on the user\nrequest\nXXTea encryption\nfunctions are utilized\n\
    to implement\nsymmetric\nencryption\n14\nJournal of Sensors\n-axis denotes the\
    \ number of the data samples, and y-axis\ndenotes the range of temperature, humidity,\
    \ rain level, and\nsoil pH. In the temperature plot, orange denotes the wheat\n\
    crop, and blue color denotes the rice crop.\nBased on the temperature, humidity,\
    \ rain level, and soil\npH, the optimal crops are recommended. For example, in\n\
    the temperature plot, for the temperature range of 39°C-\n45°C, the recommended\
    \ crop is wheat. In case of humidity,\nthe minimum humidity level is recommended\
    \ for the wheat\ncrop. Rice crop is recommended for the rain level of 3 mm\nand\
    \ the pH value of 8, and the wheat crop is recommended.\nThe recommendation of\
    \ the crop is delivered on the basis of\ntrained data, and it may vary with other\
    \ location, as the\ndataset is developed through the real-time data of the study\n\
    location. In case, if the hardware needed to implement in\nother location, then\
    \ the customized hardware with IoT sen-\nsors needs to be developed for a certain\
    \ period of time for\nthe development of dataset.\nIn Figure 14, the crop recommendation\
    \ is processed\nbased on temperature, humidity, nutrients, and light inten-\n\
    sity. The x-axis denotes the number of the data samples,\nand y-axis denotes the\
    \ range of temperature, humidity,\nnutrients, and light intensity. In the temperature\
    \ plot, blue\ndenotes the green leaves, and violent color denotes tomatoes.\n\
    Based on the temperature, humidity, nutrients, and light\nintensity, the optimal\
    \ crops are recommended. In the tem-\nperature plot, for the temperature range\
    \ of 20°C-30°C, the\nrecommended crop is tomato. At the temperature of 35°C,\n\
    the plot concludes that green leaves and tomato crops are\nrecommended.\nIn case\
    \ of humidity, if the range of humidity level is\nbetween 60% and 70%, then both\
    \ crops including green\nleaves and tomato are recommended. The tomato crop is\n\
    recommended for the nutrients level in between 0 and 1%.\nIf the light intensity\
    \ is at 8 candelas, then tomato crop is\nhighly recommended. The hand-held device\
    \ based on the\ncloud server also receives the crop recommendation through\nthe\
    \ Internet based on demand. Table 10 presents the com-\nparison of smart agriculture\
    \ monitoring with previous stud-\nies. To validate the proposed study, the following\
    \ evaluation\nparameters are communication, data processing, analytics,\nsimulation,\
    \ calibration, and hand-held device. The proposed\nstudy oﬀers the advantages\
    \ of a communication protocol\nthat uses both 2.4 GHz ZigBee and Wi-Fi.\nThe integration\
    \ of these two-communication platforms\nenables to obtain the data locally and\
    \ also in the cloud. From\nthe table, it is concluded that the proposed study\
    \ is having\nbeneﬁcial in terms of providing the real-time data to the\nusers\
    \ on the hand-held device through stable and reliable\ncommunication. As seen\
    \ in the previous studies, many\nresearchers have implemented the advanced wireless\
    \ com-\nmunication technology like LoRa. The deployment of the\nLoRa-based sensor\
    \ nodes increases the infrastructure cost\nas compared to ZigBee-based sensor\
    \ nodes. However, LoRa\nand ZigBee can be utilized combinedly in the agricultural\n\
    ﬁeld monitoring in the following manner.\nZigBee-based sensor nodes can be deployed\
    \ in the agri-\ncultural ﬁeld to monitor environmental parameters, and\nthe single\
    \ LoRa-based node can act as supervisor node to\nall the ZigBee-based sensor nodes.\
    \ This LoRa-based node con-\nnects to the gateway, as LoRa can transmit the data\
    \ to a long\nrange. From there, the information of ZigBee-based sensor\nnode can\
    \ be visualized on the cloud server. This approach\ncan be implemented to enhance\
    \ the connectivity and minimize\ninfrastructure cost. This study have enhanced\
    \ the hardware\nwith node mapping feature, frequency agility interference\navoidance,\
    \ and XXTea encryption features. All these features\nare logged in the hardware\
    \ during the programming.\n6. Conclusions\nReal-time smart monitoring with intelligence\
    \ has gained sig-\nniﬁcant attention for increasing crop productivity. At the\n\
    moment, IoT generates a large amount of real-time data\nfrom sensors, actuators,\
    \ and identiﬁcation technologies.\nHowever, extracting meaningful insights from\
    \ data is\nrequired for the intelligent ecosystem and portable device\nfor monitoring\
    \ of agriculture. The current study is focused\non implementing the customized\
    \ hand-held device for\nassisting the farmers with crop recommendation with ML.\n\
    To realize it, ﬁrst, the customized hardware is designed,\nand sensors are calibrated\
    \ to obtain the error free data. In\naddition to this, security is also inbuilt\
    \ in the customized\nhardware for secure transmission of data on the cloud\nserver.\
    \ As the real-time data is available in the cloud server,\nit is utilized for\
    \ forming dataset to conclude to the optimal\nML model for crop recommendation.\
    \ After identifying the\noptimal ML model, it has been applied on the cloud server.\n\
    Based on this, the ML model recommends the crop from\nthe real-time data that\
    \ is generated from the customized\nhardware.\nData Availability\nData will be\
    \ available on request. For the data-related queries,\nkindly contact to Baseem\
    \ Khan, basseemk@hu.edu.et.\nConflicts of Interest\nThe authors declare that they\
    \ have no conﬂicts of interest.\nReferences\n[1] World - Agriculture, “Value added\
    \ (% of GDP) -1995-2018\ndata,” 2021 Forecast Available online: https://tradingeconomics\n\
    .com/world/agriculture-value-added-percent-of-gdp-wb-data\n.html/ (accessed on\
    \ Apr 13, 2021).\n[2] K. Pawlak and M. Kołodziejczak, “The role of agriculture\
    \ in\nensuring food security in developing countries: considerations\nin the context\
    \ of the problem of sustainable food production,”\nSustainability, vol. 12, no.\
    \ 13, p. 5488, 2020.\n[3] “Food production must double by 2050 to meet demand\
    \ from\nworld’s growing population innovative strategies needed to\ncombat hunger,\
    \ experts tell second committee,” Meetings Cov-\nerage and Press Releases Available\
    \ online: https://press.un.org/\nen/2009/gaef3242.doc.htm (accessed on Apr 13,\
    \ 2021).\n[4] M. Ayaz, M. Ammad-Uddin, Z. Sharif, A. Mansour, and\nE.-H. M. Aggoune,\
    \ “Internet-of-Things (IoT)-based smart\n15\nJournal of Sensors\nagriculture:\
    \ toward making the ﬁelds talk,” IEEE Access,\nvol. 7, pp. 129551–129583, 2019.\n\
    [5] M. Carlos-Mancilla, E. López-Mellado, and M. Siller, “Wire-\nless sensor networks\
    \ formation: approaches and techniques,”\nJournal of Sensors, vol. 2016, Article\
    \ ID 2081902, 18 pages,\n2016.\n[6] F. Edwards-Murphy, M. Magno, P. M. Whelan,\
    \ J. O’Halloran,\nand E. M. Popovici, “b+WSN: smart beehive with preliminary\n\
    decision tree analysis for agriculture and honey bee health\nmonitoring,”\nComputers\
    \ and\nElectronics\nin\nAgriculture,\nvol. 124, pp. 211–219, 2016.\n[7] U. Shaﬁ,\
    \ R. Mumtaz, J. García-Nieto, S. A. Hassan, S. A. R.\nZaidi, and N. Iqbal, “Precision\
    \ agriculture techniques and\npractices: from considerations to applications,”\
    \ Sensors (Swit-\nzerland), vol. 19, no. 17, pp. 1–25, 2019.\n[8] A. Pardossi\
    \ and L. Incrocci, “Traditional and new approaches\nto irrigation scheduling in\
    \ vegetable crops,” HortTechnology,\nvol. 21, no. 3, pp. 309–313, 2011.\n[9] V.\
    \ P. Kour and S. Arora, “Recent developments of the Internet\nof Things in agriculture:\
    \ a survey,” IEEE Access, vol. 8,\npp. 129924–129957, 2020.\n[10] P. Majumdar\
    \ and S. Mitra, “IoT and machine learning-based\napproaches for real time environment\
    \ parameters monitoring\nin agriculture: an empirical review,” in Agricultural\
    \ Informat-\nics: Automation Using the IoT and Machine Learning,\npp. 89–115,\
    \ Wiley, 2021.\n[11] M. S. Mahdavinejad, M. Rezvan, M. Barekatain, P. Adibi,\n\
    P. Barnaghi, and A. P. Sheth, “Machine learning for internet\nof things data analysis:\
    \ a survey,” Digital Communications\nand Networks, vol. 4, no. 3, pp. 161–175,\
    \ 2018.\n[12] B. S. Paul and S. Rimer, “Wireless sensor node placement due\nto\
    \ power loss eﬀects from surrounding vegetation,” in Proceed-\nings of the International\
    \ Conference on Heterogeneous Net-\nworking for Quality, Reliability, Security\
    \ and Robustness,\npp. 915–927, Greader Noida, India, 2013.\n[13] D. V. Jose and\
    \ G. Sadashivappa, “Mobile sink assisted energy\neﬃcient routing algorithm for\
    \ wireless sensor networks,”\nWorld of Computer Science & Information Technology\
    \ Journal,\nvol. 5, 2015.\n[14] P. Sanjeevi, S. Prasanna, B. Siva Kumar, G. Gunasekaran,\n\
    I. Alagiri, and R. Vijay Anand, “Precision agriculture and\nfarming using Internet\
    \ of Things based on wireless sensor net-\nwork,” Transactions on Emerging Telecommunications\
    \ Tech-\nnologies, vol. 31, article e3978, 2020.\n[15] L. I. U. Dan, C. Xin, H.\
    \ Chongwei, and J. Liangliang, “Intelli-\ngent agriculture greenhouse environment\
    \ monitoring system\nbased on IOT technology,” in Proceedings of the 2015 Interna-\n\
    tional Conference on Intelligent Transportation, Big Data and\nSmart City, pp.\
    \ 487–490, Halong Bay, Vietnam, 2015.\n[16] R. Singh, A. Gehlot, A. K. Thakur,\
    \ M. Swain, and S. V. Akram,\n“Wireless sensor network with power management system\
    \ for\nwater level regulation in paddy ﬁelds,” International Journal of\nInnovative\
    \ Technology and Exploring Engineering, vol. 9,\npp. 1243–1246, 2020.\n[17] J.\
    \ Gutiérrez, J. F. Villa-Medina, A. Nieto-Garibay, and M. Á.\nPorta-Gándara, “Automated\
    \ irrigation system using a wireless\nsensor network and GPRS module,” IEEE Transactions\
    \ on\nInstrumentation and Measurement, vol. 63, pp. 166–176, 2014.\n[18] X. Zhang,\
    \ J. Zhang, L. Li, Y. Zhang, and G. Yang, “Monitoring\ncitrus soil moisture and\
    \ nutrients using an IoT based system,”\nSensors, vol. 17, no. 3, p. 447, 2017.\n\
    [19] H. Zhang and F. Zhang, “A kind of design of greenhouse\nenvironment monitoring\
    \ system based on LabVIEW,” in\nProceedings of the 2020 Chinese Automation Congress\
    \ (CAC),\npp. 6208–6211, Shanghai, China, 2020.\n[20] K. Foughali, K. Fathallah,\
    \ and A. Frihida, “Using cloud IOT for\ndisease prevention in precision agriculture,”\
    \ Procedia com-\nputer science, vol. 130, pp. 575–582, 2018.\n[21] M. Srbinovska,\
    \ C. Gavrovski, V. Dimcev, A. Krkoleva, and\nV. Borozan, “Environmental parameters\
    \ monitoring in preci-\nsion agriculture using wireless sensor networks,” Journal\
    \ of\nCleaner Production, vol. 88, pp. 297–307, 2015.\n[22] X. Zhang, Q. Wen,\
    \ D. Tian, and J. Hu, “PVIDSS: developing a\nWSN-based irrigation decision support\
    \ system (IDSS) for viti-\nculture in protected area, Northern China,” Applied\
    \ Mathe-\nmatics & Information Sciences, vol. 9, no. 2, pp. 669–679, 2015.\n[23]\
    \ O. Ayurzana and S. Tsagaanchuluun, “Monitoring system of\nagriculture ﬁelds\
    \ using ZigBee modules,” International journal\nof advanced smart convergence,\
    \ vol. 10, pp. 89–96, 2021.\n[24] K. S. P. Reddy, Y. M. Roopa, and N. S. Nandan,\
    \ “IoT based\nsmart agriculture using machine learning,” in Proceedings of\nthe\
    \ 2020 Second International Conference on Inventive\nResearch in Computing Applications\
    \ (ICIRCA), pp. 130–134,\nCoimbatore, India, 2020.\n[25] G. Sushanth and S. Sujatha,\
    \ “IOT based smart agriculture sys-\ntem,” in Proceedings of the 2018 International\
    \ Conference on\nWireless Communications, Signal Processing and Networking\n(WiSPNET),\
    \ pp. 1–4, Chennai, India, 2018.\n[26] N. Sales, O. Remédios, and A. Arsenio,\
    \ “Wireless sensor and\nactuator system for smart irrigation on the cloud,” in\
    \ Proceed-\nings of the 2015 IEEE 2nd World Forum on internet of things\n(WF-IoT),\
    \ pp. 693–698, Milan, Italy, 2015.\n[27] S. Rawal, “IOT based smart irrigation\
    \ system,” International\nJournal of Computers and Applications, vol. 159, no.\
    \ 8, pp. 7–\n11, 2017.\n[28] O. Elijah, T. A. Rahman, I. Orikumhi, C. Y. Leow,\
    \ and M. N.\nHindia, “An overview of Internet of Things (IoT) and data\nanalytics\
    \ in agriculture: beneﬁts and challenges,” IEEE Internet\nof Things Journal, vol.\
    \ 5, no. 5, pp. 3758–3773, 2018.\n[29] A. Khattab, A. Abdelgawad, and K. Yelmarthi,\
    \ “Design and\nimplementation of a cloud-based IoT scheme for precision\nagriculture,”\
    \ in Proceedings of the 2016 28th International Con-\nference on Microelectronics\
    \ (ICM), pp. 201–204, Giza, Egypt,\n2016.\n[30] A. Kamilaris, F. Gao, F. X. Prenafeta-Boldu,\
    \ and M. I. Ali,\n“Agri-IoT: a semantic framework for Internet of Things-\nenabled\
    \ smart farming applications,” in Proceedings of the\n2016 IEEE 3rd World Forum\
    \ on Internet of Things (WF-IoT),\npp. 442–447, Reston, VA, USA, 2016.\n[31] F.\
    \ Kiani and A. Seyyedabbasi, “Wireless sensor network and\nInternet of Things\
    \ in precision agriculture,” International\nJournal of Advanced Computer Science\
    \ and Applications,\nvol. 9, no. 6, 2018.\n[32] H. Lee, A. Moon, K. Moon, and\
    \ Y. Lee, “Disease and pest\nprediction IoT system in orchard: a preliminary study,”\
    \ in Pro-\nceedings of the 2017 Ninth International Conference on Ubiqui-\ntous\
    \ and Future Networks (ICUFN), pp. 525–527, Milan, Italy,\n2017.\n[33] J. Treboux\
    \ and D. Genoud, “Improved machine learning meth-\nodology for high precision\
    \ agriculture,” in Proceedings of the\n2018 Global Internet of Things Summit (GIoTS),\
    \ pp. 1–6, Bilbao,\nSpain, 2018.\n16\nJournal of Sensors\n[34] A. Chlingaryan,\
    \ S. Sukkarieh, and B. Whelan, “Machine learn-\ning approaches for crop yield\
    \ prediction and nitrogen status\nestimation in precision agriculture: a review,”\
    \ Computers and\nElectronics in Agriculture, vol. 151, pp. 61–69, 2018.\n[35]\
    \ K. G. Liakos, P. Busato, D. Moshou, S. Pearson, and D. Bochtis,\n“Machine learning\
    \ in agriculture: a review,” Sensors, vol. 18,\nno. 8, p. 2674, 2018.\n[36] R.\
    \ Sharma, S. S. Kamble, A. Gunasekaran, V. Kumar, and\nA. Kumar, “A systematic\
    \ literature review on machine learning\napplications for sustainable agriculture\
    \ supply chain perfor-\nmance,” Computers and Operations Research, vol. 119, article\n\
    104926, 2020.\n[37] “ZigBee modules - everything RF,” Available online: https://\n\
    www.everythingrf.com/search/rf-modules/ﬁlters?page=\n1&country=global&stechnology=;ZigBee/\
    \ (accessed on Oct\n27, 2021).\n[38] L. A. A. V. R. Microcontroller, I. Programming,\
    \ O. B. Program,\nO. A. Comparator, F. Sleep, and M. Idle, “Reduction, A.D.C.N.\n\
    – up to 16mips throughput at 16mhz – optional boot code\nsection with independent\
    \ lock bits – programming lock for\nsoftware security – three PWM channels – 6-channel\
    \ ADC\nin PDIP package – master / slave SPI serial interface – internal\ncalibrated\
    \ rc oscilla,” 2013.\n[39] S. T. Electronics, “Soil moisture sensor - digital\
    \ + analog out-\nput,” pp. 1–7, 2016, https://www.sunrom.com/.\n[40] “Moisture\
    \ content determination | Mettler Toledo | learn from\nexperts now!,” Available\
    \ online: https://www.mt.com/in/en/\nhome/applications/Laboratory_weighing/moisture-content-\n\
    determination.html/(accessed on Oct 27, 2021).\n[41] S. Voltage, S. Current, and\
    \ O. D. Format, “Ultrasonic distance\nsensor - serial out [1166]: Sunrom electronics/technologies”.\n\
    [42] “Psychrometer calibration |Sling Psychrometer Calibration,”\nAvailable online:\
    \ https://www.alliancecalibration.com/\npsychrometer-calibration(accessed on Oct\
    \ 27, 2021).\n[43] “Relative humidity and dewpoint temperature from tempera-\n\
    ture and wet-bulb temperature formula - weather calculators\nand converters -4WX.COM?\
    \ Weather Information Center!,”\nAvailable online: http://www.4wx.com/wxcalc/formulas/\n\
    rhTdFromWetBulb.php (accessed on Oct 27, 2021).\n[44] R. Saravanan and P. Sujatha,\
    \ “A state of art techniques on\nmachine learning algorithms: a perspective of\
    \ supervised\nlearning approaches in data classiﬁcation,” in Proceedings of\n\
    the 2018 Second International Conference on Intelligent Com-\nputing and Control\
    \ Systems (ICICCS), pp. 945–949, Madurai,\nIndia, 2018.\n[45] M. Mamdouh, M. A.\
    \ I. Elrukhsi, and A. Khattab, “Securing the\ninternet of things and wireless\
    \ sensor networks via machine\nlearning: a survey,” in Proceedings of the 2018\
    \ International\nConference on Computer and Applications (ICCA), pp. 215–\n218,\
    \ Beirut, Lebanon, 2018.\n[46] L. Li, W. Chou, W. Zhou, and M. Luo, “Design patterns\
    \ and\nextensibility of REST API for networking applications,” IEEE\nTransactions\
    \ on Network and Service Management, vol. 13,\nno. 1, pp. 154–167, 2016.\n[47]\
    \ Q. Tang, X. Ge, and Y.-C. Liu, “Performance analysis of two\ndiﬀerent SVM-based\
    \ ﬁeld-oriented control schemes for\neight-switch three-phase inverter-fed induction\
    \ motor drives,”\nin Proceedings of the 2016 IEEE 8th International Power Elec-\n\
    tronics and Motion Control Conference (IPEMC-ECCE Asia),\npp. 3374–3378, Hefei,\
    \ China, 2016.\n[48] “A beginner’s guide to XGBoost. This article will have trees….\n\
    lots of… | by George Seif | towards data science,” Available\nonline: https://towardsdatascience.com/a-beginners-guide-to-\n\
    xgboost-87f5d4c30ed7(accessed on Oct 26, 2021).\n[49] M. Swain, D. Zimon, R. Singh,\
    \ M. F. Hashmi, M. Rashid, and\nS. Hakak, “LoRa-LBO: an experimental analysis\
    \ of LoRa link\nbudget optimization in custom build IoT test bed for agricul-\n\
    ture 4.0,” Agronomy, vol. 11, no. 5, 2021.\n[50] T. Cao-Hoang and C. N. Duy, “Environment\
    \ monitoring sys-\ntem for agricultural application based on wireless sensor net-\n\
    work,” in Proceedings of the 2017 Seventh International\nConference on Information\
    \ Science and Technology (ICIST),\npp. 99–102, Da Nang, Vietnam, 2017.\n[51] F.\
    \ Bu and X. Wang, “A smart agriculture IoT system based on\ndeep reinforcement\
    \ learning,” Future Generation Computer\nSystems, vol. 99, pp. 500–507, 2019.\n\
    [52] P. K. Tripathy, A. K. Tripathy, A. Agarwal, and S. P. Mohanty,\n“MyGreen:\
    \ An IoT-enabled smart greenhouse for sustainable\nagriculture,” IEEE Consumer\
    \ Electronics Magazine, vol. 10,\nno. 4, pp. 57–62, 2021.\n[53] H.\nMuthukrishnan,\n\
    A.\nJeevanantham,\nB.\nSunita,\nS. Najeerabanu, and V. Yasuvanth, “Performance\
    \ analysis of\nWi-Fi and LoRa technology and its implementation in farm\nmonitoring\
    \ system,” IOP Conference Series: Materials Science\nand Engineering, vol. 1055,\
    \ no. 1, article 012051, 2021.\n[54] T. A. Khoa, M. M. Man, and T. Nguyen, “Smart\
    \ agriculture\nusing IoT multi-sensors: a novel watering management sys-\ntem,”\
    \ Journal of Sensor and Actuator Networks, vol. 8, no. 3,\n2019.\n[55] J. Alves\
    \ Coelho, A. Glória, and P. Sebastião, “Precise water leak\ndetection using machine\
    \ learning and real-time sensor data,”\nIoT, vol. 1, no. 2, pp. 474–493, 2020.\n\
    17\nJournal of Sensors\n"
  inline_citation: '>'
  journal: Journal of Sensors
  limitations: '>'
  pdf_link: https://downloads.hindawi.com/journals/js/2022/9042382.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Agriculture Field Automation and Digitization Using Internet of Things and
    Machine Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1007/s11761-022-00356-2
  analysis: '>'
  authors:
  - Sahar Ghrab
  - Imene Lahyani
  - Sami Yangui
  - Mohamed Jmaïel
  citation_count: 0
  full_citation: '>'
  full_text: '>

    Service Oriented Computing and Applications (2023) 17:25–37

    https://doi.org/10.1007/s11761-022-00356-2

    ORIGINAL RESEARCH PAPER

    A core IoT ontology for automation support in edge computing

    Sahar Ghrab1

    · Imene Lahyani2 · Sami Yangui3 · Mohamed Jmaiel2

    Received: 28 July 2022 / Revised: 20 December 2022 / Accepted: 31 December 2022
    / Published online: 10 February 2023

    © The Author(s) 2023

    Abstract

    Service providers provision more and more Internet-of-Things (IoT) services in
    the cloud for dynamicity and cost-effectiveness

    purposes. This is made possible thanks to the introduction of edge computing that
    brings additional computing and resources

    for analytics close to the data sources and thus enables meeting the low latency
    requirement. Edge nodes should support (i) the

    heterogeneity of IoT devices (e.g., sensor, actuator) and (ii) characteristics
    (e.g., mobility, location awareness). IoT is already

    integrated to the hybrid cloud/edge environment. However, the ecosystem lacks
    of automation due to the previously mentioned

    characteristics. Indeed, edge nodes are often manually selected during deployment
    time, and most of the regular Quality Of

    Service (QoS) management procedures remain difﬁcult to implement. This paper introduces
    a comprehensive semantic model

    called EdgeOnto. It encompasses all concepts related to IoT applied in the context
    of edge computing. The ultimate goal

    of EdgeOnto is to automate the several steps that make up the IoT services lifecycle
    in hybrid cloud/edge environment. On

    the one hand, semantics enable an automatic discovery of the relevant edge nodes
    that are suitable to host and execute IoT

    services considering their requirements. On the other hand, it allows supporting
    the speciﬁc QoS procedures that are related

    to such setting (e.g., low latency, mobility, jitter). The core ontology was designed
    with the Protégé open-source tool. A smart

    strawberry farming use case was implemented and evaluated for illustration purposes.
    The results validate the accuracy and

    the precision of the designed semantic matchmaker.

    Keywords Edge computing · Internet of Things (IoT) · Ontology · Quality of Service
    (QoS) · Semantic matchmaking

    1 Introduction

    Internet-of-Things (IoT) service owners are more and more

    leaning on hyperscale cloud providers to provision IoT ser-

    vices, as well as, to store and to process the generated data.

    This trend is motivated by the several advantages that the

    cloud computing paradigm brings such as dynamicity, ﬂexi-

    bilityandcost-effectiveness.However,withtheever-growing

    B Sahar Ghrab

    ghrab.sahar@gmail.com

    Imene Lahyani

    imen.lahyani@enis.tn

    Sami Yangui

    yangui@laas.fr

    Mohamed Jmaiel

    mohamed.jmaiel@redcad.org

    1

    MIRACL Laboratory, University of Sfax, Sfax, Tunisia

    2

    REDCAD Laboratory, University of Sfax, Sfax, Tunisia

    3

    LAAS-CNRS, Université de Toulouse, INSA, 31400

    Toulouse, France

    workloads that is tied to 5G telco network, automation,

    real-time analytics and IoT, service owners started looking

    elsewhere for their computing needs.

    Notably, edge computing enables meeting these comput-

    ing needs. In fact, edge computing is currently reshaping IT

    and business computing. It brings additional resources close

    to the end-users and data sources so that the latency-sensitive

    computing and data analytics could be processed within a

    lownetworklatency[24]. Nevertheless, this brings additional

    challenges that need to be tackled to provision IoT services

    in such setting. Indeed, edge nodes are highly heterogeneous

    in terms of computing capabilities (e.g., supported run-time,

    CPU and RAM workload, storage capacity, autonomy), net-

    work interfaces (e.g., supported communication protocols),

    behavior (e.g., mobile or motionless, online or ofﬂine). These

    characteristics make the operation of edge computing difﬁ-

    cult and costly [24], in particular for IoT where applications

    are latency-sensitive and services are often bound through

    complex gateways and overlay networks.

    IoT is already integrated to the hybrid cloud/edge envi-

    ronments. However, the existing works mainly focus on

    123

    26

    Service Oriented Computing and Applications (2023) 17:25–37

    Fig. 1 Smart strawberry farming

    speciﬁc features (e.g., see [8] for IoT services deployment,

    see [22] for IoT services rescheduling) and fail to fully sup-

    port the whole steps that make up the IoT services life cycle.

    The reader should note that IoT services inherit the same

    Service-Oriented Architecture (SOA) life-cycle phases (i.e.,

    discover, deploy, execute and manage during run-time) [34].

    SOA principles (e.g., service abstraction, discover ability,

    and composability) ensure the viability of network services’

    ecosystem that could be dynamically and ﬂexibly provi-

    sioned, thus coping with changeable IoT needs and dynamic

    Quality Of Service (QoS) requirements along with context

    conditions. In addition to these limitations, the current edge

    frameworks for IoT lack of automation when implementing

    these steps. Edge nodes are often manually selected during

    deployment time, and most of the regular QoS manage-

    ment procedures remain difﬁcult to implement. The QoS

    procedures need to be executed during run-time and aim

    to optimize a set of metrics based on predeﬁned service-

    level objectives. The latter might vary from one use case to

    another depending on the involved data and IoT devices and

    expected outcomes. The objectives could, for instance, range

    from faster response time to less network costs, low latency,

    less service breakdown or better ﬂow control of data, com-

    munication, efﬁciency and accuracy [10].

    1.1 Motivating use case

    The motivating use case is from smart agriculture research

    ﬁeld. It is inspired from the use case introduced in [12]

    where the authors propose an edge framework to handle the

    collection, analysis, prediction, and detection of heteroge-

    neous data in strawberry farming. Strawberries are sensitive

    fruits that are afﬂicted by various pests and diseases. There-

    fore, there is an intense use of agro-chemicals and pesticides

    during production. Due to their sensitivity, temperatures or

    humidity at extreme levels can cause various damages to the

    plantation and to the quality of the fruit.

    The proposed framework is depicted in Fig. 1. This frame-

    work monitors, collects and processes data in real time to (i)

    detect seven of the most common strawberry diseases and (ii)

    determine the required type and amount of chemical fertilizer

    and medication depending on the strawberry size, age and

    disease. To that end, it relies on several sensor nodes, a col-

    lector node and actuators. These devices communicate with

    the computing nodes through the collector module that plays

    the role of IoT gateway. The communication relies on LoRa

    protocol. The computing nodes integrate machine learning

    capabilities for capturing outliers in collected data and exe-

    cute a computer vision model using Yolo v5 architecture to

    identify the prospective disease.

    The provisioning of this framework in large strawberry

    farms requires, in addition to the deployment of the sensors

    and actuators, the deployment of several computing entities

    (e.g., raspberry nodes) that could host the computer vision

    and machine learning algorithms. These nodes must be suf-

    ﬁcient in number to cover the whole farm and to allow close

    and fast interactions between the devices and the algorithms.

    The end-to-end selection should optimize the data trans-

    fer time and the system reaction (e.g., detecting a disease,

    control an irrigation actuator for plant watering with med-

    ication) as fast as possible and with minimal energy cost

    to save devices autonomy and durability. Furthermore, one

    can imagine the deployment of monitoring mobile robots

    over the farm. The robots will be responsible of holding the

    monitoring sensors and the actuators instead of having them

    motionless. In that case, the system should be able to sup-

    port the devices mobility and dynamically select the most

    appropriate gateway and computing nodes to optimize on-

    the-ﬂy the previously mentioned service-level objectives. A

    precise and relevant semantic description of the nodes capa-

    bilities and current workload is the considered alternative in

    this work to automate and enable efﬁcient selection of the

    edge nodes while optimizing the QoS metrics.

    1.2 Contributions and obtained results

    This paper introduces a comprehensive ontology (called

    EdgeOnto). This ontology involves semantic concepts for

    both IoT domain and edge domain. It supports edge com-

    puting features and integrates high-level abstraction of the

    complex information and incremented knowledge at the net-

    work edge (e.g., ad hoc topology, breakdown, mobility). The

    ultimate goal is to support the automation of the QoS man-

    agement procedures in such environment. Speciﬁcally, this

    is achieved by enabling the instantaneous semantic matching

    between the IoT services requirements, from one side, and

    the edge nodes workload/position on the other side.

    The core domain of EdgeOnto was designed with Pro-

    tege,1 a free, open-source ontology editor and framework for

    building intelligent systems. As for the validation, the smart

    strawberry farming use case was implemented and evalu-

    1 https://protege.stanford.edu/.

    123

    Service Oriented Computing and Applications (2023) 17:25–37

    27

    ated. The results validate the accuracy and the precision of

    the designed semantic matchmaker.

    2 The state of the art

    This section ﬁrstly summarizes the different ontologies pro-

    posed in IoT domain. The reviewed ontologies cover sensor,

    security, and applications ontologies. These ontologies focus

    on devices (sensor, actuator), its lifecycle, etc. The detailed

    IoT ontologies do not support the concepts of security, loca-

    tion, place, or time in the exception of some which do not treat

    it deeply. These important concepts are especially useful in

    IoT domain in the context of edge computing (see Sect. 1).

    For thus, some ontologies related to location, context, and

    time are integrated in this section.

    2.1 Ontologies for sensors

    Existing ontologies for sensors in the literature aim to solve

    heterogeneity problems associated with the hardware, soft-

    ware, and the data management aspects of sensors (sensor

    capabilities, extensibility, data access and sharing, sensor

    data description, sensor discovery).

    The SSN (Semantic Sensor Network) ontology [11] des

    cribes sensor resources and the data collected through these

    sensors. The main concepts proposed are sensor, observation,

    and device.

    The SOSA (Sensor, Observation, Sample, and Actuator)

    ontology [19] is a redesigned SSN ontology. The SAREF

    (Smart Appliance REFerence) ontology [33] reuses and

    aligns concepts and relationships in existing appliance-based

    ontologies and is dedicated to the management of energy

    and services in smart homes. Its main proposed concepts are

    Device, Service, Energy, Task, Function and Measurement.

    Semantic actuator network (SAN) ontology [26] is used

    for the description of the actuator concept and its charac-

    teristics (Actuator, Actuating Device and Actuation). The

    OntoSensor ontology [28] extends concepts from other

    ontologies (SensorML, Sumo, ISO-19115) to allow con-

    cepts for the identiﬁcation of sensor categories, behavior,

    relationships, functionalities, and meta-data regarding sensor

    characteristics, performance, and reliability. The MyOn-

    toSens ontology [25] is an extension of OntoSensor. It

    describes sensor observations and capabilities to reason over

    the collected data for the domain of wireless sensor networks

    (WSN).

    2.2 Context-aware ontologies

    Context-aware ontologies aim to identify information about

    context like place, agent, event, latitude, longitude, altitude,

    and location. In the computation context, they express that

    “context is any information that can be used to characterize

    the situation of an entity. An entity is a person, place or object

    that is considered relevant to the interaction between a user

    and an application”.

    Context can be classiﬁed on the one hand as external

    or internal and the other hand as physical or logical [5].

    External or physical contexts are those that can be measured

    using physical sensors, while internal or logical contexts

    are those that are explicitly speciﬁed by users or captured

    by monitoring user interactions. Context awareness bridges

    the gap between real things and the virtual world in the

    IoT through acquiring, analyzing, and interpreting relevant

    context information [23]. [27] deﬁnes an Internet-of-Thing

    context-awareness model that accurately represents context

    in IoT. The context model is a hierarchical structure showing

    contexts related to Resources, Actors, Ambients and Poli-

    cies. This context model includes User context, Location

    context, Activity context, Personal context, Mood context,

    Time context, System context, Environment context and

    Device context. Context-aware ontologies are classiﬁed into

    generic ontologies (information provided by mobile device

    sensors) and speciﬁc domain ontologies (university domain,

    smart information provided by mobile device sensors, both

    physical (e.g., WiFi, Bluetooth, etc.) and virtual (e.g., user

    schedule, web-logs, etc.) to support context-aware services.

    The proposed ontology deﬁnes the relations between differ-

    ent user locations and the contexts identiﬁed. The ontology

    proposed by [3] supports the devices’s discovery and their

    location in smart-home domains using concepts like Person,

    Sensor, Device, Location, etc. The ontology CONON (CON-

    text ONtology) proposed by [32] models context in pervasive

    computing environments and supports logic-based context

    reasoning.

    2.3 Location-aware ontologies

    Location-aware ontologies describe locations of things like

    geographical coordinates (altitude, latitude, and longitude).

    Location is used to describe the context location, its indoor

    and outdoor space, and the property of the environment

    (external context). Location is used to describe the spatial

    context (partly, physical context) of users/devices [4]. Loca-

    tion and context are closely linked and dependent. Different

    models can be used for deﬁning entities locations [15]. The

    considered models are as follows:

    • Geometric models (comprising Cartesian coordinates)

    • Set-theoretic models (for deﬁning location as an element

    of a set, e.g., cellular location, WiFi AP location, etc.)

    • Graph-based models (for deﬁning locations in physically

    grounded networks, social networks, etc.)

    • Semantic models (for deﬁning locations deﬁned using

    human-friendly notations)

    123

    28

    Service Oriented Computing and Applications (2023) 17:25–37

    In IoT domain, location informations are often collected from

    sensor data (like users’ mobile devices to estimate device

    location). WGS84 ontology describes abstract concepts for

    deﬁning spatial things (buildings, people, etc.) and tempo-

    ral things (events, or time duration). It also describes the

    geographical locations of these things by using concepts for

    deﬁning the geo-coordinates using latitude, longitude, and

    altitude.

    2.4 Time-based ontologies

    Time-based ontologies are used to describe the temporal con-

    textwhichincludetime,duration,andsometemporalaspects.

    Time modeling detects the behavior of a system at an interval

    or duration or point of time or the actions to be performed

    in speciﬁc temporal entity. The most popular and commonly

    used time based-ontology is OWL-Time [17]. It is reused to

    propose other time-based ontologies. It is focused on describ-

    ing date-time information speciﬁed in Gregorian calendar

    format.

    DAML-Time ontology [18] is focused on concepts to pro-

    vide a common understanding of time, whereas DAML-S

    ontology [1] provides temporal concepts required to deﬁne

    a web service such as proﬁle, process, and time. The

    KSL-Time (Knowledge System Laboratory) ontology distin-

    guishes between different types of intervals and granularity.

    The Timeline ontology [20] extends Time Ontology by pro-

    viding various concepts representing granularity of time to

    provide more ﬂexibility to the annotations.

    2.5 Security and QoS ontologies

    STAC ontology [16] is an IoT security ontology. It deﬁnes

    the main security concepts (cryptographic concepts, security

    protocols, security tools, security properties) and classiﬁes

    threats and countermeasures by domain and according to the

    OSI model. The main purpose of this ontology is to be reused

    in numerous domains such as security of web applications,

    network management or communication networks (sensor,

    cellular and wireless).

    In IoT domain, cloud computing and edge computing are

    widely used to store, deploy and analyze data coming from

    IoT devices. Due to network overload and changing trans-

    mission delay, the QoS offered can be different. That’s why,

    it is important to measure the QoS, which is dependent on

    many factors like availability, network, robustness, security,

    scalability, performance, etc. In the literature, different QoS

    ontologies are proposed. QoS is the description or measure-

    ment of the overall performance of a service (like telephony,

    computer network) particularly the performance seen by the

    users of the network. Jiang and Aagesen [21] propose a

    QoS ontology based on functional properties representing

    service functionality, which are modeled in terms of oper-

    ations, inputs, outputs, preconditions and effects. However,

    while non-functional properties comprise business policies,

    QoS properties as well as context policies. QoS properties

    include QoS parameters and QoS policies (rule). QoS param-

    eters represent security, availability, scalability, reliability,

    performance, etc.

    [31] proposes an ontology for knowledge representation

    in the Internet of Things composed of different modules like

    IoT services, IoT resources, QoS and QoI. In IoT domain,

    QoS and QoI (Quality of information) are important, which

    exhibit a much higher level of dynamicity. In this work, [31]

    enumerates all the QoS parameters and QoI that are common

    to many applications domains. Reference [31] reuses DUL

    ontology for ontology building. This ontology will be reused

    for EdgeOnto building and precisely for the QoS.

    2.6 Ontologies for IoT applications

    In IoT domain, many ontologies are proposed: IoT ontology

    [13], IoT Lite [7], and IoT-O [29].

    IoT ontology [13] is based on the reuse of other existing

    ontologies like SSN ontology, DUL (DOLCE Ultralite Upper

    ontology) ontology and QUDT (Quantities, Units, Dimen-

    sions and Data Types) Ontology, whereas IoT-Lite ontology

    reuses SSN ontology. The description of IoT concepts is

    based on three classes: objects, system or resource and ser-

    vices. IoT devices are classiﬁed into three classes: sensing

    devices, actuating devices, and tag devices.

    IoT-Lite is focused on sensing, although it has a high-level

    concept on actuation that allows any future extension on this

    area. Services are described with a coverage representing the

    2D-spatial covered by the IoT device.

    IoT-O ontology presents connected device networks and

    semantically describes devices and data in order to make

    systems aware of their environment, its evolution, and the

    changes they can bring to it. Such a description allows smart

    agents to transform their environment thanks to connected

    actuators, according to the perceptions they have of it through

    connected sensors. IoT-O is based on following modules:

    • Sensing module: describes the input data. Its main classes

    come from SSN ontology (ssn:Observation, ssn:Sensor,

    ssn:Device, etc.).

    • Acting module: describes how the system can interact

    with the physical world. Its main classes come from SAN

    (san:Actuator and san:Actuation). It also reuses SSN

    classes that are not speciﬁc to sensing such as ssn:Device

    • Life-cycle module: models state machines to specify sys-

    tem life cycles and device usage. Its main classes are

    lifecycle: State and lifecycle:Transition.

    • Service module: represents web service interfaces. Its

    main classes come from msm:Service and msm: Opera-

    123

    Service Oriented Computing and Applications (2023) 17:25–37

    29

    tion. Services produce and consume msm:Messages, and

    RESTful services can be described with hRest.

    • Energy module: IoT-O’s energy module is deﬁned by

    PowerOnt. It provides the poweront:PowerConsumption

    class, and a set of properties to express power consump-

    tion proﬁles for appliances.

    3 Requirements and related work review

    The previously discussed ontologies summarize the most

    important concepts used in IoT domain (sensor, actuator,

    device, service, etc.). Data generated from the different

    devices are important and should be stored, treated and ana-

    lyzed through the nearest edge nodes in order to increase

    high bandwidth, faster treatment, less transmission delay and

    less packet loss. That’s why different concepts should be

    tacked into consideration in IoT ontologies proposed. These

    concepts are related to edge computing characteristics. In

    fact, edge node should support mobility, data heterogeneity,

    context-awareness (time and location), security and QoS.

    The assessment of existing IoT ontologies regarding the

    presence of key concepts is summarized in Table 1. These

    ontologies are evaluated among a set of conceptual require-

    ments detailed below (see paragraph 3).

    A set of symbols are used to determine whether the con-

    ceptual requirement is supported by the ontology or not:

    • *: The conceptual requirement is not supported by the

    ontology.

    • ** : The conceptual requirement is quite supported by

    the ontology.

    • ***: The conceptual requirement is well supported by

    the ontology.

    Requirements The evaluation of related ontologies is based

    on conceptual requirements identiﬁed as follows:

    • CR1: “Cloud” constitutes the servers accessible on the

    Internet as well as software and databases which run on

    these servers. The servers located in the cloud are hosted

    in data centers distributed around the world.

    • CR2: “Edge” constitutes a computer that acts as an end

    user portal for communication with other nodes. In this

    paper, edge node allows the communication between

    cloud and IoT device.

    • CR3: “Location” constitutes context location of an entity

    in general (e.g., device, actuator, cloud, edge). A distinc-

    tion is made between physical place and virtual place.

    • CR3.1: “Physical place” constitutes an absolute position

    with geographic coordinates.

    • CR3.2: “Virtual place” constitutes a relative position of

    an entity.

    • CR4: “Time” constitutes the information’s given for time

    description (point in time, interval, duration, etc.).

    • CR5: “Security” constitutes a characteristic of using data.

    Data can be accessed only to suitable persons in suitable

    time and location and with some privilege.

    • CR6: “QoS” constitutes the quality of service offered in

    terms of properties and metrics used.

    None of the above-reviewed work meet all the require-

    ments (Table 1). More speciﬁcally, some ontologies meet

    partially the third, fourth, ﬁfth and seventh requirements

    (time and context-awareness). None meets even the ﬁrst, the

    second and the third requirements (edge, cloud, virtual loca-

    tion).

    Nowadays, the use of IoT devices is coupled by the use of

    cloud computing and edge computing for many reasons.

    First, it is an opportunity to analyze data generated by IoT

    devices locally (the nearest edge node used) without sending

    it to cloud. This can facilitate useful data identiﬁcation and

    reduce packet loss and transmission delay. Some applications

    need real-time treatment, which can be guaranteed by edge

    computing.

    Second, edge node support data heterogeneity of IoT

    devices.

    Finally, it is an opportunity to know the localization of an

    object which can be physical or virtual, the quality of service

    offered and information’s about time.

    To put it in a nut shell, an Iot ontology based on the use

    of edge computing should integrate other concepts useful in

    addition to the concepts already presented in the literature in

    relation to device, life cycle, consumption and other.

    The next section gives an overview about these concepts

    and the different requirement which should be respected on

    the one hand. On the other hand, it details reused ontologies

    for the design process of our EdgeOnto ontology.

    4 EdgeOnto principles and design model

    The design process of EdgeOnto is based on the NeOn

    methodology presented in [14]. The NeOn methodology

    is used for building ontology networks and is based on

    the “divide-and-conquer” strategy which decomposes the

    general problem to be solved in different sub-problems rep-

    resented by nine scenarios combined among them [14].

    The ﬁrst step of the NeOn process is to deﬁne conceptual

    and functional requirements (detailed in Sect. 4.1). Con-

    ceptual requirements determine the concepts that should be

    present in the EdgeOnto and are used to analyze existing IoT,

    time-based, location-based, context-awareness and security

    ontologies detailed in Sect. 3.

    123

    30

    Service Oriented Computing and Applications (2023) 17:25–37

    Table 1 Existing ontologies

    review in the light of the

    identiﬁed requirements

    Type

    Ontology

    CR1

    CR2

    CR3

    CR4

    CR5

    CR6

    CR3.1

    CR3.2

    Sensor

    SSN

    *

    *

    *

    *

    *

    *

    *

    SOSA

    *

    *

    *

    *

    *

    *

    *

    SAREF

    *

    *

    *

    *

    *

    *

    *

    SAN

    *

    *

    *

    *

    *

    *

    *

    Onto Sensor

    *

    *

    *

    *

    *

    *

    *

    Time

    DAML-Time

    *

    *

    *

    *

    ***

    *

    *

    DAML-S

    *

    *

    *

    *

    ***

    *

    *

    KSL-Time

    *

    *

    *

    *

    ***

    *

    *

    OWL-Time

    *

    *

    *

    *

    ***

    *

    *

    Timeline ontology

    *

    *

    *

    *

    ***

    *

    Location

    WGS84 ontology

    *

    *

    **

    *

    **

    *

    *

    Context

    CONON

    *

    *

    **

    *

    **

    *

    *

    Ontology of [3]

    *

    *

    *

    *

    **

    *

    *

    Security

    STAC

    *

    *

    *

    *

    *

    ***

    *

    QoS

    Ontology of [31]

    *

    *

    *

    *

    *

    ***

    ***

    QoS ontology [21]

    *

    *

    *

    *

    *

    ***

    ***

    IoT

    IoT ontology

    *

    *

    *

    *

    *

    *

    *

    IoT-Lite

    *

    *

    **

    *

    *

    *

    *

    IoT-O

    *

    *

    *

    **

    **

    *

    *

    As recommended by NeOn, reusable ontologies that are

    compliant with parts of the requirements are integrated in our

    design process and presented in Sect. 4.2.

    4.1 Functional requirements

    Functional requirements regard the ontology structure and

    design principles. Reusability is an important aspect of

    ontology. Many approaches can be used to solve ontology

    reusability.

    • Modularization: designing ontologies in separated mod-

    ules makes them easier to reuse and/or extend [2]. In IoT

    applications, many domains can be integrated and it is

    difﬁcult to capture them in the same ontology. Accord-

    ing to speciﬁc needs and goals, modular ontologies can

    be combined together [29].

    • Reuse of Existing Sources: in order to avoid redeﬁnition

    and prevent redeﬁned concepts from having to align a

    posteriori [29].

    • Alignment to Upper Ontologies: The concepts expressed

    by upper ontologies are intended to be basic and univer-

    sal to ensure generality and expressivity for a wide range

    of domains especially for IoT domain. These concepts

    are meta, generic, abstract and philosophical. The advan-

    tage of top-level ontologies is to gather lots of available

    knowledge and create super structures for information

    that provide interoperability for many applications [9].

    4.2 Reused ontologies for EdgeOnto

    For the design process of EdgeOnto, we reuse some existing

    ontologies: The IoT-O ontology [29], the description ontol-

    ogy for knowledge representation in the IoT domain [31], as

    well as, the DUL ontology.2,3

    4.2.1 DUL ontology

    DUL relies on DOLCE+DnS Ultralite ontology.4 It is a sim-

    pliﬁcation and an improvement of some parts of DOLCE

    Lite-Plus library,5 and Descriptions and Situations ontol-

    ogy.6 The DUL ontology main concepts are presented in

    Fig. 2.

    The main abstract classes of DUL ontology are:

    • DUL:Abstract: Any entity that cannot be located in

    space-time (like mathematical entities: formal semantics

    elements, regions within dimensional spaces, etc.).

    2 http://www.ontologydesignpatterns.org/ont/dul/DUL.owl.

    3 https://www.w3.org/2005/Incubator/ssn/wiki/Alignement_to_

    DUL_Upper_Ontology.

    4 https://ontologydesignpatterns.org/wiki/Ontology:DOLCE+DnS_

    Ultralite.

    5 https://dolce.semanticweb.org.

    6 https://www.ontologydesignpatterns.org/wiki/Ontology:DnS.

    123

    Service Oriented Computing and Applications (2023) 17:25–37

    31

    Fig. 2 DUL ontology tree concepts

    • DUL:Event: Any physical, social, or mental process,

    event, or state. More theoretically, events can be clas-

    siﬁed in different ways, possibly based on ’aspect’ (e.g.,

    stative, continuous, accomplishment, achievement, etc.),

    on ’agentivity’ (e.g., intentional, natural, etc.), or on ’typ-

    ical participants’ (e.g., human, physical, abstract, food,

    etc.).

    • DUL:InformationEntity: A piece of information, be it

    concretely realized or not. It is a catchall class, intended

    to bypass the ambiguities of many data or text that could

    denote either an expression or a concrete realization of

    that expression.

    • DUL:Object: Any physical, social, or mental object, or

    a substance. Following DOLCE Full, objects are always

    participating in some event (at least their own life), and

    are spatially located.

    • DUL:Quality: Any aspect of an Entity (but not a part of

    it), which cannot exist without that Entity. For example,

    the way the surface of a speciﬁc PhysicalObject looks

    like, or the speciﬁc light of a place at a certain time, are

    examples of Quality, while the encoding of a Quality into,

    e.g., a PhysicalAttribute should be modeled as a Region.

    • DUL:Situation: A view, consistent with (’satisfying’) a

    Description, on a set of entities. It can also be seen as a

    ’relational context’ created by an observer on the basis

    of a ’frame’ (i.e., a Description).

    For the rest of the paper, we have identiﬁed some conven-

    tions to follow. The concepts’ names related to each ontology

    used are in bold and have the sans serif font different from

    the normal text. The concepts’ names are proceeded by the

    name of the corresponding ontology.

    4.2.2 IoT-O ontology

    Reference [29] presents a core-domain modular IoT ontol-

    ogy with a vocabulary to describe connected devices and

    their relation with their environment. IoT-O is reused in our

    EdgeOnto because it is based on DUL ontology as well as

    other reference existing related to IoT (like SSN, life cycle,

    msm, PowerOnt, SAN). More informations are given about

    IoT-O in Sect. 2.6. The IoT-O OWL ﬁle is available at the

    following address.7

    4.2.3 Knowledge representation ontology

    Reference [31] presents an ontology for knowledge represen-

    tation in the IoT domain and discusses how it can be used to

    support tasks such as service discovery, testing and dynamic

    composition (see Sect. 2.5). The main concepts reused of the

    description ontology [31] are QualityOfService, IoTService

    and IoTResource. For facilitating concepts’ referencing, we

    give the acronym DO to the Description Ontology of [31].

    The next section details the core domain EdgeOnto ontology

    applied for IoT domain in the context of edge computing.

    5 EdgeOnto architecture and speciﬁcations

    This section ﬁrstly discusses the several modules (i.e., IoT,

    location and time-awareness, and QoS management) that

    make up the EdgeOnto core domain. Our ontology is OWL-

    based (ontology web language). For each module, we detail

    the multiple deﬁned concepts, as well as, the relations

    between them. Then, the second subsection formalizes the

    end user requests to query EdgeOnto. This is followed by the

    description of the associated semantic matching procedure.

    5.1 EdgeOnto core-domain

    EdgeOnto answers to the following questions: What domain

    EdgeOnto will cover (IoT domain applied to Cloud and Edge

    Computing)? For what EdgeOnto will be used (searching the

    nearest edge to the IoT device and choosing the most suitable

    7 https://www.irit.fr/recherches/MELODI/ontologies/IoT-O.html.

    123

    32

    Service Oriented Computing and Applications (2023) 17:25–37

    one)? For what types of queries, EdgeOnto should provide

    answers (proximity, similarity)? A deep analysis is under-

    taken to extract the main concepts related both to cloud,

    edge computing and its use in IoT. Related ﬁelds used in

    this analysis are fog computing, multi-access edge comput-

    ing, time-based, location and IoT ontologies. The concept

    extracted is represented already by the conceptual require-

    ments.

    Secondly, an abstraction exercise is undertaken for iden-

    tifying the main common concepts shared by various IoT

    applications and using cloud and edge computing. Concepts

    are organized as a class hierarchy where abstract concepts

    will be reﬁned with more concrete ones speciﬁc to each

    domain application. They are also described with properties

    and connected to other concepts with semantic relations. We

    tried not to reinvent the wheel, so we further reuse existing

    ontologies (see Sect. 4.2).

    The design process of EdgeOnto is based on:

    • the formal speciﬁcation of the functionalities achieved

    by EdgeOnto. It reuses both DUL, IoT-O and DO [31]

    ontologies and describe the main concepts related to IoT

    domain applied in the context of edge computing (see

    Sect. 4.1).

    • the formal speciﬁcation of what precisely the EdgeOnto

    needs/requires for identifying time, location and QoS,

    edge, cloud. In fact, EdgeOnto covers the conceptual

    requirements CR1, CR2, CR3, CR4, CR5 and CR6.

    . After importing reused ontologies, a matching process is

    undertaken to integrate (i) new concepts to added and (ii)

    align concepts reused.

    EdgeOnto is based on three modules:

    • IoT module: describes the main concepts related to IoT

    (IoT-Thing, device, actuator, sensing device, etc.) and

    edge computing (edge, cloud).

    • Time and location module: describes the main concepts

    related to time and location of each object in EdgeOnto

    (for example, location of an IoT-Thing in point of time,

    location of an edge node in instant t, location of a cloud

    node, etc.)

    • QoS module: describes the quality of service between

    EdgeOnto objects (IoT devices, edge and clouds).

    A set of semantic relations are deﬁned in EdgeOnto rep-

    resented in Table 2.

    5.1.1 IoT module

    This dimension encompasses four main concepts, namely

    EdgeOnto:Cloud,EdgeOnto:Edge,EdgeOnto:Resourceand

    IoT-O:IoT-Thing (Fig. 3).

    Fig. 3 EdgeOnto concepts related to IoT

    • IoT-Thing refers to device (IoT-O:Sensing_device,

    EdgeOnto:Actuator,

    EdgeOnto:Mobile_device

    and

    EdgeOnto:Computing_device)

    • DO:IoT-Resource which can be a server or an Iot -

    Gateway.

    • Aresourcecanbephysical(EdgeOnto:PhysicalResource)

    or virtual(EdgeOnto: VirtualResource) and is used by a

    cloud or an edge.

    • Cloud or edge (represented, respectively, by EdgeOnto

    by EdgeOnto:Cloudand EdgeOnto:Edge)arenodespro-

    grammed enabling recognition, processing or forwarding

    transmission to other nodes.

    – A node cloud (datacenter, database, server, etc.) is

    related to cloud computing which is deﬁned by NIST

    as “a model for enabling convenient, on demand

    network access to a shared pool of conﬁgurable com-

    puting resources (e.g., networks, servers, storage,

    applications, and services) that can be rapidly provi-

    sioned and released with minimal management effort

    or service provider interaction”.

    – An edge node (switcher, router, small/macro base sta-

    tion, etc.) is a node that acts as an end user portal

    for communication with other nodes (cloud node or

    device node).

    – Edge

    nodes

    are

    located

    between

    device

    (EdgeOnto:Device) and cloud (EdgeOnto:Cloud)

    and can facilitate computations nearer to the source

    of data (or where data is generated) and can incorpo-

    rate strategies for remotely enhancing capabilities of

    front-end devices [30].

    123

    Service Oriented Computing and Applications (2023) 17:25–37

    33

    Table 2 EdgeOnto’s semantic

    relations

    Dimension

    Relation

    Range

    Target

    IoT

    EdgeOnto:communicate

    Edge

    Cloud

    EdgeOnto:access

    Device

    Edge

    Dul:is used by

    Resource

    Object

    Location, Time

    DUL: is location of

    Entity

    Entity

    DUL: near to

    Entity

    Entity

    DUL: is region for

    Region

    Entity

    QoS

    DUL: offers

    Object

    Service

    EdgeOnto: hasQoS

    Service

    QualityOfService

    Fig. 4 Concepts related to location and time dimensions

    5.1.2 Location and time-awareness module

    The concepts proposed in this dimension are inherited from

    the DUL ontology (Fig. 4). For time dimension, we reuse

    mainly the concept of DUL:Time Interval deﬁned as “any

    region in a dimensional space that aims at representing time”.

    For representing location, three types of place can be dis-

    tinguished:

    • Dependent location (represented by DUL: Place): is geo-

    graphic entities and non-material locations determined

    by the presence of other entities or of pivot of events and

    signs as well as identiﬁed as complement to other entities.

    For example, the area where the mobile phone is located,

    surrounding of a temperature sensor

    • Non-dependent location (represented by DUL: Physical

    place): can exist independently. It refers to a physical

    place where a physical object is inherently located. For

    example, a room, a building.

    • Abstract or dimensional location (represented by DUL:

    Space Region): is any speciﬁc region in a dimensional

    spacethatisusedtolocalizeanentity(forexample,cloud,

    edge node, device, etc.).

    The semantic relation DUL: is region for is deﬁned

    between DUL:Region and DUL: Entity. In EdgeOnto, this

    relation is available between DUL:Space Region, which is a

    DUL:Region and DUL: Entity.The inverse relation of DUL:Is

    region for is DUL:Has region

    Thesemanticrelation DUL:Haslocationisdeﬁnedbetween

    DUL:Entity and DUL:Entity. In EdgeOnto, this relation

    is available between any entity (like EdgeOnto:Cloud,

    EdgeOnto:Edge, EdgeOnto:Device, etc.) and DUL: Place or

    DU:LPhysical place which are DUL:Entity. The inverse rela-

    tion of DUL:Has location is DUL:Is location of. To ensure

    a consistent instantiation of concepts, Semantic Web Rule

    Language (SWRL) rules (including axioms) help enforce

    restrictions on attribute values and semantic relations, as

    well. Hereafter, we only exemplify SWRL rules referring to

    concepts. For example, Eq. 1 formally reﬂects the following

    statement: “Any EdgeOnto (?x) has location a place (?y) or a

    physicalplace(?z)andhasregionsomespaceregion(?p)dur-

    ing a time interval (?t)”. Informally, each concept related to

    EdgeOnto (like Edge, Cloud or device) should have at least a

    location (which can be a physical place or a dependent place)

    during a time interval or a point of time.

    EdgeOnto(?x) →

    hasLocation(?x, (place(?y, ?x) |

    physicalplace(?z, ?x)))∧

    hasRegion(?t, SpaceRegion(?x, ?p),

    TimeInterval(?t))

    (1)

    5.1.3 QOS management module

    QoS is the description or measurement of the overall perfor-

    mance of a particularly the performance seen by the users of

    the network.

    Different measurements are taken into account to char-

    acterize and evaluate QoS like availability, performance,

    reliability, scalability, and security.

    Theontologyproposedby[31]usestheDULontologyand

    deﬁnetheconceptofQualityofService(DO:QualityOfService)

    as a DUL:Information Object.

    123

    34

    Service Oriented Computing and Applications (2023) 17:25–37

    Fig. 5 Concepts related to QoS dimension

    In IoT-O, reference [29] reuses also the DUL:Information

    Object which ”is a piece of information, be concretely real-

    ized or not. It is intended to bypass the ambiguities of many

    data or text”.

    By

    aligning

    ontology

    of

    [31]

    and

    IoT-O,

    DO:

    QualityOfServiceistreatedinthispaperasan DUL:Information

    Object which is DUL:Information Entity (Fig. 5).

    In IoT-O, a semantic relation IoT-O:hasQoS is deﬁned

    between IoT-O:Service and DO:QualityOfService. In [29],

    IoT-O:Service is “a set of operation and provides a user a way

    to issue requests through an interface. Underlying implemen-

    tation need not to be known by the end user”.

    SWRL rules are deﬁned to infer new semantic relations

    between instances during concept instantiation related to

    QoS dimension. For instance, Eq. 2 formally reﬂects the fol-

    lowing statement: “Any EdgeOnto (?x) that offers a service

    (?y) should has a speciﬁc quality of service (?u)”. Informally,

    each EdgeOnto concept deﬁned as an object (like device,

    cloud, or edge) offers a certain service which has a quality.

    The quality of service offered is already measured by differ-

    ent metrics in the literature.

    EdgeOnto(?x) ∧ of f ers(?x, Service(?y))

    → hasQoS(?x, QualityO f Service(?z, ?u))

    (2)

    - x corresponds to the EdgeOnto instance(s) to be retrieved.

    5.2 User request building

    We deﬁne requirement (REQ) as a set of concepts in

    EdgeOnto requested by the user Ui. We have already detailed

    the set of requirement in Sect. 3. Formally, Eq. 3 represents

    the syntax used for specifying REQ.

    RE Qi = EdgeOnto(?x)[∧Concept j(?x, y)] j=1..n

    (3)

    where

    • Concept j ∈ EdgeOnto (concepts related to this ontol-

    ogy).

    • Note Ui can reﬁne EdgeOnto into concrete concepts

    related to a speciﬁc domain.

    5.3 Semantic matching

    Semantic matching is a technique used to identify informa-

    tion (concepts in the case of ontology) which is semantically

    related. The semantic match maker algorithm takes an OWL-

    S request for the user as input and iterates every OWL-S

    advertisement in its repository in order to determine a match

    [6]. In the OWL-S approach, functionality of a service is

    described in terms of inputs, outputs, preconditions and

    effects. Input and output terms of the service are expressed as

    concepts belonging to a set of ontologies. An advertisement

    (Advt) and a query (Query) match if their outputs and inputs

    match.

    • For every input parameter in Advt, there is one input

    parameter in query. Let Queryin and Advtin represent

    the list of input concepts of query and the advertisement,

    respectively. The service can correctly perform the task

    if all the input concepts deﬁned in the advertisement are

    satisﬁed by the requester (Eq. 4).

    • For every output parameter in Query, there is one output

    parameter in Advt. Let Queryout and Advtout represent

    the list of output concepts of query and the advertisement,

    respectively. The service can be used by the requester if

    all the output concepts deﬁned in the query are satisﬁed

    by the advertisement (Eq. 5).

    ∀c ∈ Advtin, ∃d ∈ Queryin, s.t.match(c, d) ̸= Fail (4)

    ∀c ∈ Queryout, ∃d ∈ Advtout, s.t.match(c, d) ̸= Fail (5)

    6 Use case implementation and

    experimentation

    This section brieﬂy describes the considered test collection

    and presents the EdgeOnto’s population. Then, it discusses

    the performed experiments to evaluate and validate our ﬁnd-

    ings. Finally, it presents the obtained measurements in terms

    of performance and robustness.

    6.1 Test collection

    Table 3 shows an excerpt of EdgeOnto’s population. There

    are three dimensions: IoT, location, time and QoS dimen-

    sions. To conduct experiments on EdgeOnto semantic dis-

    covery, we ﬁrst proceed with the test collection creation.

    123

    Service Oriented Computing and Applications (2023) 17:25–37

    35

    Table 3 Excerpt of EdgeOnto’s population

    Dimension

    Concept

    Instances

    IoT

    Edge

    Collector node, Collector node1

    Server

    VNC server, VNC viewer

    Physical Resource

    Raspberry Pi 4B, InﬂuxDB, Grafana, Creality Ender Pro

    Virtual Resource

    GRAD-CAM algorithm

    Sensing-device

    Humidity and temperature sensor DHT11, Soil humidity

    sensor hygrometer, HD USB camera

    Computing-device

    YOLO 5

    Mobile device

    Smart agriculture drone 1, Smart agriculture drone 2, robot

    1

    Location, Time

    Physical place

    Strawberry farm1,place1, place2

    Space region

    Position (50,40), position (100.120)

    Place

    Middle of the strawberry farm,at the end of strawberry farm

    TimeInterval

    Duration between the informations’ reception coming from

    the node collector and its treatement on the node collector,

    13am

    QoS

    QualityOfService

    Quality of communication between collector node and

    device node, quality of identifying humidity and

    temperature measurements, quality of computing soil

    humidity

    Service

    Computing humidity and temperature, computing soil

    humidity

    Table 4 Excerpt of EdgeOnto’s user request

    Query

    User request

    REQ1

    ∀Device(?x) ∧ nearT o(?x, Edge(?y)

    REQ2

    ∀Device(?x) ∧ access(x?, (collector Node ∨ collector Node1))

    REQ3

    ∀Device(?x) ∧ access(x?, (collector Node ∨ collector Node1)) ∧ hasLocation(?x,
    Place(?z)or Physical Place(?p))

    REQ4

    ∀Device(?x) ∧ access(x?, Edge(?y)) ∧ of f ers(x?, Service(?z))

    REQ5

    ∀Device(?x) ∧ access(x?, Edge(?y)) ∧ of f ers(x?, Service(?z)) ∧ hasQoS(?z, QualityO
    f Service(?q))

    REQ6

    Service(?x)) ∧ hasQoS(?x, QualityO f Service(?y))

    REQ7

    Place ∧ isLocationO f (?x, Entity(?y))

    REQ8

    Place(?x)or Physicalplace(?y)or Spaceregion(?z) ∧ isLocationO f (?x, Entity(?y))

    REQ9

    Resource(?x) ∧ isUsed By(?x, Object(?y))

    REQ10

    Entity(?x) ∧′ hasregion′(?x,′ Spaceregion′(?y)

    For a clarity purpose, Table 4 presents an excerpt of the

    user request identiﬁed in the smart strawberry farming use

    case introduced in the Sect. 1.

    SWRL rules are deﬁned to infer new semantic relations

    between instances during EdgeOnto’s population.

    For instance, Eq. 6 states that “Any Device (?x) that offers

    a Service (?y) at a point of time or Interval Time (?t) located

    onaPhysicalplaceorPlaceorSpaceregion(?l)shouldaccess

    to some Edge (?z) the nearest to this device.

    ∀Device(?x) ∧ of f ers(?x, Service(?y))

    → ∃Edge(?z) ∧ access(?x, Edge(?z))

    ∧nearT o(?x, Edge(?z))

    (6)

    6.2 Performance analysis

    To assess the proposed approach’s performance, we use two

    metrics, namely completeness and efﬁciency. The former

    describes how well our Protégé matchmaker identiﬁes the

    relevant EdgeOnto concepts compared with the total number

    of such EdgeOnto concepts that exist in the test collection.

    The latter describes how well Protégé identiﬁes only those

    relevant EdgeOnto concepts, by comparing the number of

    target EdgeOnto-identiﬁed concepts with the total number

    of EdgeOnto-retrieved concepts. The main preference met-

    rics are True Positive (TP), False Positive (FP), and False

    Negative (FN) where

    123

    36

    Service Oriented Computing and Applications (2023) 17:25–37

    • TP contains the retrieved EdgeOnto concepts that are rel-

    evant

    • FP contains the retrieved EdgeOnto concepts that are not

    relevant

    • FN contains the relevant EdgeOnto concepts that are not

    retrieved (i.e., discarded by the matchmaker).

    Once the sets mentioned above are established, two pop-

    ular performance measurements, in the semantic web and

    machine learning communities, are calculated, namely recall

    and precision. These performance measurements implement

    completeness and efﬁciency metrics and are deﬁned, respec-

    tively, as follows:

    • Recall is the quantity’s measure in the response (how

    close was the result to the actual response). It refers to

    the ratio between the number of true-positive EdgeOnto

    concepts and the number of relevant EdgeOnto concepts,

    including true-positive EdgeOnto concepts and false-

    negative EdgeOnto concepts (Eq. 7).

    Recall =

    TP

    TP + FN

    (7)

    • Precision is the quality’s measure of the response (how

    much the response is correct). It refers to the ratio

    between the number of true-positive EdgeOnto concepts

    and the total number of retrieved EdgeOnto concepts,

    including true-positive and false-positive EdgeOnto con-

    cepts (Eq. 8).

    Precision =

    TP

    TP + FP

    (8)

    6.3 Robustness evaluation

    This section discusses the performed experiments to evaluate

    and validate our ﬁndings. It presents the analyzed obtained

    measurements in terms of performance and robustness by

    applying Eqs. 8 and 7:

    Precision = 0.875 and Recall = 0.954

    These measurements depict that EdgeOnto reach good accu-

    racy for requests’ response (75%) Compared with other IoT

    ontologies, none of the user requests mentioned in Table 4

    can give relevant responses and satisfy user requests. This is

    justiﬁed by many reasons:

    • Lack of concepts in relation with mobility

    • Lack of concepts in relation with context, location and

    time awareness

    • Lack of concepts related to edge, cloud, and device types.

    • Lack of concepts describing quality of service .

    In fact, the proposed ontology EdgeOnto clearly outperforms

    the other IoT ontologies and can provide much better accu-

    racy.

    7 Conclusion and future work

    IoT domain relies, nowadays on hybrid cloud/edge environ-

    ment for faster communication, lower bandwidth and better

    local treatment.

    Compared with existing works, most of them don’t sat-

    isfy the requirements already deﬁned about time, location,

    mobility, and quality of service.

    In this paper, we propose a semantic model (EdgeOnto)

    which highlights all concepts related to IoT applied in the

    context of edge computing. Its main goal is to support the

    automation of the QoS management procedures in hybrid

    cloud/edge environment and the discovery of the relevant

    edge nodes that are suitable to host and execute IoT services

    considering their requirements.

    The illustrative use case is smart strawberry farming [12],

    and the proposed edge platform aims to be an all-in-one

    IoT platform to enable the intelligent farm on strawberries

    cultivation with wireless sensor network (WSN), computer

    vision (CV), machine learning (ML), and long-range (LoRa)

    communication capabilities. The platform makes available

    to the user all the captured metrics for manual analysis and

    data-driven decisions. This platform studies only the com-

    munication between devices and edges where devices and

    edges are static and have the same location during the straw-

    berry farming scenario. In addition to these limitations, the

    current edge framework lacks of automation when imple-

    menting steps that make up the IoT services life cycle in

    hybrid cloud/edge environment. Edge nodes are often manu-

    ally selected during deployment time and most of the regular

    QoS management procedures remain difﬁcult to implement.

    In future works, we study deeply the problem of optimal

    placement where edge and device are simultaneously mobile.

    In fact, when device node is mobile, we should ﬁnd the opti-

    mal edge node the nearest to this device node ensuring a

    sufﬁcient and acceptable quality of service.

    Declarations

    Conﬂict of interest No conﬂicts of interest relevant to content presented

    in this article are associated. The authors have no relevant ﬁnancial or

    non-ﬁnancial interests to disclose, nor competing interests to declare

    that are relevant to the content of this article or could have inﬂuenced

    its outcome.

    123

    Service Oriented Computing and Applications (2023) 17:25–37

    37

    Open Access This article is licensed under a Creative Commons

    Attribution 4.0 International License, which permits use, sharing, adap-

    tation, distribution and reproduction in any medium or format, as

    long as you give appropriate credit to the original author(s) and the

    source, provide a link to the Creative Commons licence, and indi-

    cate if changes were made. The images or other third party material

    in this article are included in the article’s Creative Commons licence,

    unless indicated otherwise in a credit line to the material. If material

    is not included in the article’s Creative Commons licence and your

    intended use is not permitted by statutory regulation or exceeds the

    permitteduse,youwillneedtoobtainpermissiondirectlyfromthecopy-

    right holder. To view a copy of this licence, visit http://creativecomm

    ons.org/licenses/by/4.0/.

    References

    1. Ankolekar A, Burstein M, Hobbs J, Lassila O, Martin D, Mcder-

    mott D, Mcilraith S, Narayanan S, Paolucci M, Payne T, Sycara K

    (2002) 06. Daml-s: Web service description for the semantic web.

    Science 6:97

    2. Aquin M (2012) Modularizing ontologies. In: Suárez-Figueroa

    MC, Gómez-Pérez A, Motta E, Gangemi A (eds) Ontology engi-

    neering in a networked world. Springer, Berlin, pp 213–233

    3. Bae IH (2014) 04. An ontology-based approach to adl recognition

    in smart homes. Futur Gener Comput Syst 33:32–41

    4. Bajaj G, Agarwal R, Singh P, Georgantas N, Issarny V (2017) 07. A

    study of existing ontologies in the iot-domain. arXiv:1707.00112

    5. Baldauf M, Dustdar S, Rosenberg F (2007) A survey on context-

    aware systems. Inf Syst 2(4):263–277

    6. Bellur U, Vadodaria H, Gupta A (2008) 11. Semantic matchmaking

    algorithms. INTECH Open Access Publisher, London, pp 481–502

    7. Bermúdez-Edo M, Elsaleh T, Barnaghi P, Taylor K (2015) 11. Iot-

    lite ontology. W3C Memb Submiss 5:26

    8. Bibani O, Yangui S, Glitho RH, Gaaloul W, Hadj-Alouane NB,

    Morrow MJ, Polakos PA (2016) A demo of a paas for iot appli-

    cations provisioning in hybrid cloud/fog environment. In: IEEE

    international symposium on local and metropolitan area networks,

    LANMAN 2016, Rome, Italy, June 13–15, 2016, pp 1–2. IEEE

    9. Bontas EP, Mochól M, Tolksdorf R (2005) Case studies on ontol-

    ogy reuse. In: IKNOW05 international conference on knowledge

    management, vol 74, pp 345

    10. Canete A, Amor M, Fuentes L (2022) Supporting IoT applications

    deployment on edge-based infrastructures using multi-layer feature

    models. J Syst Softw 183:111086

    11. Compton M, Barnaghi P, Bermudez L, García-Castro R, Corcho

    O, Cox S, Graybeal J, Hauswirth M, Henson C, Herzog A, Huang

    V, Janowicz K, Kelsey WD, Le Phuoc D, Lefort L, Leggieri M,

    Neuhaus H, Nikolov A, Page K, Passant A, Sheth A, Taylor K

    (2012) The SSN ontology of the W3C semantic sensor network

    incubator group. J Web Seman 17:25–32

    12. Cruz M, Mafra S, Teixeira E, Figueiredo F (2022) Smart strawberry

    farming using edge computing and IoT. Sensors 22(15):740

    13. Daniele L, Solanki M, den Hartog F, Roes J (2016) 10. Interoper-

    ability for smart appliances in the iot world, pp 21–29

    14. Del Carmen Suárez de Figueroa Baonza, M (2010) NeOn method-

    ology for building ontology networks: speciﬁcation, scheduling

    and reuse. Ph.D. thesis, Universidad Politécnica de Madrid,

    Madrid, Spain

    15. Flury T, Privat G, Ramparany F (2004) Owl-based location ontol-

    ogy for context-aware services. Proc Artif Intell Mob Syst 7:52–57

    16. Gyrard A, Bonnet C, Boudaoud K (2013) 05. The stac (security

    toolbox: attacks and countermeasures). Ontology 5:165–166

    17. Hobbs J, Pan F (2004) 03. An ontology of time for the semantic

    web. ACM Trans Asian Lang Inf Process 3:66–85

    18. Hobbs JR (2002) A daml ontology of time

    19. Janowicz K, Haller A, Cox S, Phuoc D, Lefrançois M (2018) 07.

    Sosa: a lightweight ontology for sensors, observations, samples,

    and actuators. J Web Seman 56:1–10. https://doi.org/10.1016/j.

    websem.2018.06.003

    20. Jerry R, Hobbs FP (2006) Time ontology in owl

    21. Jiang S, Aagesen F (2006) 01. An approach to integrated semantic

    service discovery, vol 4195, pp 159–171

    22. Li X, Zhou Z, Zhao Z, Yangui S, Zhang W (2021) Data &

    computation-intensive service re-scheduling in edge networks. In:

    Chang CK, Daminai E, Fan J, Ghodous P, Maximilien M, Wang Z,

    Ward R, Zhang J (eds) 2021 IEEE international conference on web

    services, ICWS 2021, Chicago, IL, USA, September 5–10, 2021.

    IEEE, pp 389–396

    23. Martinez-Villase nor L, Gonzalez-Mendoza M (2014) 11. Sharing

    and reusing context information in ubiquitous computing environ-

    ments. pp 227–230

    24. Mouradian C, Naboulsi D, Yangui S, Glitho RH, Morrow MJ,

    Polakos PA (2018) A comprehensive survey on fog computing:

    state-of-the-art and research challenges. IEEE Commun Surv Tutor

    20(1):416–464

    25. Nachabe L, Girod-Genet M, ElHassan B (2015) 01. Uniﬁed data

    model for wireless sensor network myontosens ontology. IEEE

    Sens J 7:3657–3667

    26. Nicolas S, Mahdi BA, KDNHTM (2015) San

    27. Ntalasha D, Renfa L, Wang Y (2016) 02. Internet of thing context

    awareness model. EAI Endors Trans Context Aware Syst Appl

    3(7):151084

    28. Russomanno D, Kothari C, Thomas O (2005) 04. Sensor ontolo-

    gies, from shallow to deep models, pp 107–112

    29. Seydoux N, Drira K, Hernandez N, Monteil T (2016) 11. Iot-o,

    a core-domain IoT ontology to represent connected devices net-

    works, pp 561–576

    30. Varghese B, Wang N, Barbhuiya S, Kilpatrick P, Nikolopoulos DS

    (2016) Challenges and opportunities in edge computing. In: 2016

    IEEE international conference on smart cloud (SmartCloud), pp

    20–26

    31. Wang W, De S, Toenjes R, Reetz E, Moessner K (2012) A compre-

    hensive ontology for knowledge representation in the internet of

    things. In: 2012 IEEE 11th international conference on trust, secu-

    rity and privacy in computing and communications, pp 1793–1798

    32. WangX,ZhangD,GuT,PungH(2004)01.Ontologybasedcontext

    modeling and reasoning using owl, pp 18–22

    33. Xue L, Liu Y, Zeng P, Yu H, Shi Z (2015) 08. An ontology based

    scheme for sensor description in context awareness system. In:

    2015 IEEE international conference on information and automa-

    tion, pp 817–820

    34. Yangui S (2020) A panorama of cloud platforms for IoT applica-

    tions across industries. Sensors 20(9):2701

    Publisher’s Note Springer Nature remains neutral with regard to juris-

    dictional claims in published maps and institutional afﬁliations.

    123

    '
  inline_citation: '>'
  journal: Service Oriented Computing and Applications
  limitations: '>'
  pdf_link: https://link.springer.com/content/pdf/10.1007/s11761-022-00356-2.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: A core IoT ontology for automation support in edge computing
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.20944/preprints202304.0119.v1
  analysis: '>'
  authors:
  - Tagel Aboneh
  - Abebe Rorissa
  citation_count: 0
  full_citation: '>'
  full_text: '>

    This website uses cookies We use cookies to personalise content and ads, to provide
    social media features and to analyse our traffic. We also share information about
    your use of our site with our social media, advertising and analytics partners
    who may combine it with other information that you’ve provided to them or that
    they’ve collected from your use of their services. Consent Selection Necessary
    Preferences Statistics Marketing Show details             Deny Allow selection
    Allow all Instructions for Authors Awards About FAQ Submit Log in/Register preprints.org
    > computer science and mathematics > artificial intelligence and machine learning
    > doi: 10.20944/preprints202304.0119.v1 Preprint Article Version 1 Preserved in
    Portico This version is not peer-reviewed Fusion of Multiple Sensors to Implement
    Precision Agriculture using IoT Infrastructure Tagel Weldu Aboneh *,‡ and Abebe
    Rorissa ‡ ‡ These authors contributed equally to this work. Version 1 : Received:
    31 March 2023 / Approved: 11 April 2023 / Online: 11 April 2023 (10:24:24 CEST)
    How to cite: Aboneh, T.W.; Rorissa, A. Fusion of Multiple Sensors to Implement
    Precision Agriculture using IoT Infrastructure. Preprints 2023, 2023040119. https://doi.org/10.20944/preprints202304.0119.v1
    Copy Abstract Precision Agriculture is the ability to handle variations in productivity
    within a field and maximize financial return, optimize resource utilization and
    minimize impact of the environment. It is also the process of automated data collection,
    cloud storage and utilization to build robust decision support system. In case
    of Ethiopia, due to poor communication infrastructure coverage and absence of
    the state-of-the-art technology in the agriculture sector, implementing precision
    farming system is a challenging tasks in the domain area. In this work, we proposed
    a fusion of multiple sensors using IOT and IIOT infrastructure to collect critical
    data from farming fields to develop precision farming facility for decision makers.
    The main purpose was to monitor weather variability, automate irrigation process,
    extract critical soil properties. In addition, we have used time series data collected
    from sensor devices to build forecasting model. Fusion of multiple IoT device
    provide a mechanism in the agriculture area to deal with real-time monitoring
    of crops. It is cost-effective technology and required low-energy with edge computing
    sensor device. We employed the Message Queuing Telemetry Transport (MQTT) protocol
    to connect the Industrial/Internet of Things (I/IoT) to the cloud server. The
    communication between system user and sensor device has been done via cloud using
    Node-RED platform, web android APIs. The cloud-based Eco-system allows us to aggregate,
    visualize, and analyze live streams output from each sensor in real-time manner.
    Finally, we have built time series forecasting model using records collected by
    each sensor device. Using the multi-variate time series data-set, we have obtained
    about 99 forecasting accuracy on some important variables. Finally, we have developed
    mobile and web-based application for the end-user to monitor the proposed system
    remotely. Keywords Sensor Fusion; IIOT; IOT; Precision Agriculture; Time Series
    data; Predictive model Subject Computer Science and Mathematics, Artificial Intelligence
    and Machine Learning Copyright: This is an open access article distributed under
    the Creative Commons Attribution License which permits unrestricted use, distribution,
    and reproduction in any medium, provided the original work is properly cited.
    Download PDF Comments (0) We encourage comments and feedback from a broad range
    of readers. See criteria for comments and our Diversity statement. Leave a public
    comment Send a private comment to the author(s) * All users must log in before
    leaving a comment Related Articles Peer-review Articles A Testbed to Evaluate
    the FIWARE-Based IoT Platform in the Domain of Precision Agriculture Ramón Martínez
    et al. Sensors, 2016 Latency-Adjustable Cloud/Fog Computing Architecture for Time-Sensitive
    Environmental Monitoring in Olive Groves Athanasios Tsipis et al. AgriEngineering,
    2020 LoRa Based IoT Platform for Remote Monitoring of Large-Scale Agriculture
    Farms in Chile Mohamed Ahmed et al. Sensors, 2022 Wireless Sensor Network Synchronization
    for Precision Agriculture Applications Alexandros Zervopoulos et al. Agriculture,
    2020 High-Density Wi-Fi Based Sensor Network for Efficient Irrigation Management
    in Precision Agriculture Manuel Jiménez-Buendía et al. Applied Sciences, 2021
    Precision Agriculture Design Method Using a Distributed Computing Architecture
    on Internet of Things Context Francisco Ferrández-Pastor et al. Sensors, 2018
    An Approach Based on Fog Computing for Providing Reliability in IoT Data Collection:
    A Case Study in a Colombian Coffee Smart Farm Ana Montoya-Munoz et al. Applied
    Sciences, 2020 Development of a Sensor Node for Precision Horticulture Juan López
    et al. Sensors, 2009 Processing Complex Events in Fog-Based Internet of Things
    Systems for Smart Agriculture Sandy da Costa Bezerra et al. Sensors, 2021 A Study
    on the Design of Fog Computing Architecture Using Sensor Networks Hyun-Jong Cha
    et al. Sensors, 2018 Views 89 Downloads 143 Comments 0 Get PDF Cite Share 0 Bookmark
    BibSonomy Mendeley Reddit Delicious Alerts Notify me about updates to this article
    or when a peer-reviewed version is published. Preprints.org is a free preprint
    server subsidized by MDPI in Basel, Switzerland. Contact us RSS MDPI Initiatives
    SciProfiles Sciforum Encyclopedia MDPI Books Scilit Proceedings JAMS Important
    links How it Works Advisory Board FAQ Friendly Journals Instructions for Authors
    About Statistics Subscribe Choose the area that interest you and we will send
    you notifications of new preprints at your preferred frequency. Subscribe © 2024
    MDPI (Basel, Switzerland) unless otherwise stated Disclaimer Privacy Policy Terms
    of Use  Feedback'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: null
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Fusion of Multiple Sensors to Implement Precision Agriculture using IoT Infrastructure
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s23135993
  analysis: '>'
  authors:
  - John Byabazaire
  - Gregory M. P. O’Hare
  - Rem W. Collier
  - Declan Delaney
  citation_count: 0
  full_citation: '>'
  full_text: ">\nCitation: Byabazaire, J.; O’Hare,\nG.M.P.; Collier, R.; Delaney,\
    \ D. IoT\nData Quality Assessment Framework\nUsing Adaptive Weighted Estimation\n\
    Fusion. Sensors 2023, 23, 5993.\nhttps://doi.org/10.3390/s23135993\nAcademic Editor:\
    \ Hassan Chizari\nReceived: 22 May 2023\nRevised: 20 June 2023\nAccepted: 25 June\
    \ 2023\nPublished: 28 June 2023\nCopyright:\n© 2023 by the authors.\nLicensee\
    \ MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nsensors\nArticle\n\
    IoT Data Quality Assessment Framework Using Adaptive\nWeighted Estimation Fusion\n\
    John Byabazaire 1,*\n, Gregory M. P. O’Hare 1,2\n, Rem Collier 1\nand Declan Delaney\
    \ 3\n1\nSchool of Computer Science, University College Dublin, D04 V1W8 Dublin,\
    \ Ireland;\ngregory.ohare@tcd.ie (G.M.P.O.); rem.collier@ucd.ie (R.C.)\n2\nSchool\
    \ of Computer Science and Statistics, Trinity College Dublin, D02 PN40 Dublin,\
    \ Ireland\n3\nSchool of Electrical and Electronic Engineering, University College\
    \ Dublin, D04 V1W8 Dublin, Ireland;\ndeclan.delaney@ucd.ie\n*\nCorrespondence:\
    \ john.byabazaire@ucdconnect.ie\nAbstract: Timely data quality assessment has\
    \ been shown to be crucial for the development of IoT-\nbased applications. Different\
    \ IoT applications’ varying data quality requirements pose a challenge,\nas each\
    \ application requires a unique data quality process. This creates scalability\
    \ issues as the\nnumber of applications increases, and it also has ﬁnancial implications,\
    \ as it would require a separate\ndata pipeline for each application. To address\
    \ this challenge, this paper proposes a novel approach\nintegrating fusion methods\
    \ into end-to-end data quality assessment to cater to different applications\n\
    within a single data pipeline. By using real-time and historical analytics, the\
    \ study investigates the\neffects of each fusion method on the resulting data\
    \ quality score and how this can be used to support\ndifferent applications. The\
    \ study results, based on two real-world datasets, indicate that Kalman\nfusion\
    \ had a higher overall mean quality score than Adaptive weighted fusion and Naïve\
    \ fusion.\nHowever, Kalman fusion also had a higher computational burden on the\
    \ system. The proposed\nsolution offers a ﬂexible and efﬁcient approach to addressing\
    \ IoT applications’ diverse data quality\nneeds within a single data pipeline.\n\
    Keywords: data quality; internet of things (IoT); trust; big data model; data\
    \ fusion\n1. Introduction\nThe Internet of Things (IoT) has played a pivotal role\
    \ in developing applications in\nmany industries, from smart agriculture to transportation,\
    \ health care, and homes. At its\ncore, IoT is the integration of information\
    \ and communication technologies into everyday\nprocesses [1]. Sensors interact\
    \ with the environment and collect data, and actuators receive\ncontrol signals\
    \ from controllers. It is estimated that over 55.7 billion devices will be\nconnected\
    \ to the Internet, producing over 73.1 zettabytes (ZB) of data by 2025 [2]. From\n\
    these IoT deployments, a vast amount of data are collected and used to advance\
    \ innovations\nand improve decision marking.\nLike many IoT solutions, however,\
    \ deployments are often composed of heterogeneous\nsensor systems to ensure data\
    \ collection [3]. The resulting data can suffer from high\nvariability, inconsistencies,\
    \ and gaps. As data are at the center of inferring new insights,\nit is essential\
    \ to assess the quality of the data from which decisions are made. A poor\nunderstanding\
    \ of the quality of the data can lead to poor decisions. Therefore, data quality\n\
    assessment solutions have been proposed [4–7].\nThe factors (issues) that degrade\
    \ the quality of IoT data exist at various stages through-\nout the big data cycle.\
    \ Karkouch et al. [5] deﬁne several of these factors (sensor faults,\nresource\
    \ limitations, network connectivity, security, and privacy) and illustrate their\
    \ place-\nment into and through the big data cycle. Figure 1 shows how various\
    \ issues exist at\ndifferent stages. Therefore, data quality assessment should\
    \ also be carried out continuously\nSensors 2023, 23, 5993. https://doi.org/10.3390/s23135993\n\
    https://www.mdpi.com/journal/sensors\nSensors 2023, 23, 5993\n2 of 18\nthroughout\
    \ the big data cycle. Quantifying, understanding, and making these data quality\n\
    issues visible throughout the big data model is essential for effective insight.\n\
    Sensor faults\nLimited resource\nData stream processing\nData Generation\nData\
    \ Pre-processing\nData Processing and Analytics\nData Use\nDeployment scale\n\
    Security and Privacy\nNetwork Connectivity\nEnvironment\nFigure 1. Factors that\
    \ degrade IoT data across the big data model.\nThe vast opportunities IoT data\
    \ presents have led to the development of many data\nquality assessment solutions\
    \ to mitigate the effects of poor data quality. Yang et al. [8]\nproposed data\
    \ quality assessment data based on deep learning for effective pest identiﬁca-\n\
    tion in smart agriculture. Fizza et al. [9] proposed a conceptual data quality\
    \ assessment\nframework that is applied to monitor milk conditions for dairy farms.\n\
    More general solutions have also been proposed. Khokhlov et al. [10] proposed\
    \ a\nframework that uses a knowledge graph to connect various DQ metrics for IoT\
    \ applications.\nMante et al. [11] implemented a 5D-IoT framework for heterogeneous\
    \ IoT systems using\nthe semantic descriptions of sensor observations to assess\
    \ the data. Several other solutions\nhave also been reported [12]. A common feature\
    \ of all these solutions is that they all\nassume data quality is an isolated\
    \ problem that affects a single stage of the big data cycle.\nData quality challenges,\
    \ however, exist at various stages throughout the big data cycle [4].\nEvaluating\
    \ at a single stage misrepresents the quality of the processing chain with respect\n\
    to the applied data. This affects the end user applications in two ways: (1) Using\
    \ data with\nincorrectly calculated quality assessment. (2) Lack of knowledge\
    \ of where in the chain the\ndata quality suffers, or indeed, is enhanced.\nEffective\
    \ data quality assessment is based on a consumer’s (application) fitness for\n\
    use requirements, and indeed, this changes from one user to another [13]. Previous\
    \ re-\nsearch [14,15] has used the phrase fitness for use and data quality interchangeably.\
    \ This\ndefinition of data quality suggests that it is strongly influenced by\
    \ the end user applica-\ntion. Each application has its own unique combination\
    \ of data quality dimensions (DQD)\nthroughout the big data cycle. This forms\
    \ its fitness for use requirements. DQDs provide an\nacceptable way to measure\
    \ data quality, for example, timeliness, accuracy, and completeness.\nExisting\
    \ solutions consider data quality assurance to be a necessary step at a single\n\
    stage (data preprocessing) [13], applied like a Quality Gate with a predeﬁned\
    \ end point.\nOnce the objective is satisﬁed, they assume a lasting standard of\
    \ data quality [13]. It is,\nhowever, a common practice in most IoT deployments\
    \ to use the same data for different\napplications and use cases, or enrich the\
    \ data with external data sources, hence different\nﬁtness for use requirements.\
    \ Such processes are essential for domain-speciﬁc applications [4].\nAs the data\
    \ changes through the big data cycle, so should data quality considerations. None\n\
    of the existing solutions account for the changing nature of data, and hence data\
    \ quality\nthroughout the big data cycle in a single data pipeline.\nThis paper\
    \ implements a data quality assessment solution that uses data fusion strate-\n\
    gies to ensure continuous end-to-end data quality assessment throughout the big\
    \ data\ncycle. More speciﬁcally, this paper seeks to deﬁne a tangible link between\
    \ data quality, data\nquality stages, and their effect on the data through the\
    \ stages in the big data model using data fusion.\nSensors 2023, 23, 5993\n3 of\
    \ 18\nThis builds on previous research that uses trust to evaluate data quality\
    \ [4,16]. This paper,\ntherefore, uses data fusion strategies to combine quality\
    \ scores at each stage into a single\nscore, while maintaining the contribution\
    \ of each stage.\nEach stage has unique data quality properties, and how these\
    \ are combined deter-\nmines the ﬁtness for use for different applications. To\
    \ deliver this unique experience for\neach application within a single data pipeline\
    \ requires a custom fusion strategy for each\napplication. Section 2 gives a detailed\
    \ motivation using two example applications: real-\ntime analytics and historical\
    \ analytics. It also highlights the importance of evaluating the\ncomputational\
    \ efﬁciency of the different fusion strategies. To this end, the following are\
    \ the\ncore contributions of this paper:\n1.\nReview data fusion strategies and\
    \ implement a fusion engine that can integrate\ninto big data data quality assessment\
    \ frameworks for IoT applications. This paper\ncompares three fusion strategies,\
    \ Adaptive weighted fusion, Kalman’s fusion, and a\nNaïve fusion strategy. These\
    \ are compared in terms of computational resources.\n2.\nUsing real-time analytics\
    \ and historical analytics as examples, this paper illustrates\nhow different\
    \ fusion strategies can be harnessed to support different IoT applications’\n\
    unique data quality needs. Different applications can have varying data quality\
    \ needs.\n3.\nIntegrate various industry standard data processing tools (e.g.,\
    \ Hadoop, Spark, and\nKafka) to implement a real-time data quality assessment\
    \ solution and also evaluate the\ncomputation resource efﬁciency associated with\
    \ the fusion methods in an end-to-end\ndata pipeline.\nThe rest of this paper\
    \ is structured as follows: Section 2 highlights the need to integrate\ndata fusion\
    \ into big data quality assessment. Section 3 introduces data quality, trust,\
    \ and\ndata fusion. These are the core concepts of this paper. It also highlights\
    \ related work.\nSection 4 outlines the theoretical and mathematical deﬁnition\
    \ of the framework. Section 5\nhighlights the two evaluating strategies used in\
    \ the paper, and ﬁnally, Section 6 gives the\nsummary and conclusive remarks.\n\
    2. Motivation\nThis section presents the motivation for integrating data fusion\
    \ strategies into end-\nto-end big data quality assessment for IoT applications\
    \ and evaluating the computational\nefﬁciency of each fusion strategy. Data quality\
    \ assessment is a complex and multidimen-\nsional process [17]. An organized methodology\
    \ ensures big data quality throughout its\nentire lifecycle. This methodology\
    \ must include a comprehensive view of quality metrics\nfrom the start of data\
    \ acquisition to the implementation [18]. To this end, an end-to-end\ndata quality\
    \ assessment framework has been deﬁned [16].\nThis proposed approach evaluates\
    \ various data quality dimensions at different stages\nof the big data cycle,\
    \ ultimately resulting in a single quality score that applications can\neasily\
    \ apply. This provides visibility of the individual quality factors at each stage.\
    \ IoT\napplications, however, have varying ﬁtness for use requirements. Consider\
    \ two broad\nclasses of applications, real-time analytics and historical analytics,\
    \ and three data quality\ndimensions, timeliness, accuracy, and completeness.\
    \ Real-time applications require instan-\ntaneous input and fast analysis to make\
    \ decisions or take actions within a speciﬁc time\nframe. Processing data quickly\
    \ with minimal latency is essential for the development and\ndeployment of real-time\
    \ applications [19]. Some examples of this include smart intelligent\ntransportation,\
    \ fraud detection, ﬁnancial trading, and many others. Real-time analytics has\n\
    an essential requirement for timely data. Accuracy and completeness are considered\
    \ desir-\nable. Historical big data analytics, on the other hand, do not require\
    \ timely data [19]. Some\nexamples of it include yield prediction is smart agriculture,\
    \ weather predictions, and many\nothers. Such applications have an essential requirement\
    \ for completeness. Each application\nhas a unique ﬁtness for use requirement\
    \ and hence varying data quality requirements.\nTable 1 summarizes the ﬁtness\
    \ for use differences between real-time and historical analytics\napplications\
    \ based on the above requirements.\nSensors 2023, 23, 5993\n4 of 18\nTable 1.\
    \ Fitness for use classiﬁcation for real-time and historical analytics.\nApplication\
    \ Class\nData Quality Dimensions\nTimeliness\nAccuracy\nCompleteness\nReal-time\
    \ Analytics\nEssential\nDesirable\nDesirable\nHistorical Analytics\nDesirable\n\
    Desirable\nEssential\nA challenge therefore exists. Given a single data stream\
    \ within an IoT data shared\nenvironment, how might a single data pipeline be\
    \ developed that combines the various\nDQDs at different stages of the big data\
    \ cycle to achieve a customize data quality score\nthat uniquely satisﬁes each\
    \ application. Currently, a few options exist: (1) A different data\nquality assessment\
    \ process can be developed for each unique application and integrated\nwithin\
    \ a single data pipeline. This is illustrated as option 1 in Figure 2. (2) Each\
    \ unique\napplication can have its data pipeline integrated with data quality\
    \ assessment that meets\nits unique requirements. This is illustrated as option\
    \ 2 in Figure 2. The ﬁrst case requires\nmaintaining two data quality assessment\
    \ processes, and the last requires maintaining two\ndata pipelines, each with\
    \ its data quality assessment process. Therefore, as the number of\nuse cases\
    \ increases, so would the need to scale the pipelines. This, however, introduces\n\
    redundancy, creating difﬁculties in consistency, and it has ﬁnancial implications.\n\
    Data  \nCollection\nData  \nPre-procesing\nData  \nAnalytics\nData  \nUse\nTimeliness\
    \ + Accuracy + Completeness\nTimeliness + Accuracy + Completeness\nReal-time Analytics\n\
    Historical Analytics\nData  \nCollection\nData  \nPre-procesing\nData  \nAnalytics\n\
    Data  \nUse\nTimeliness + Accuracy + Completeness\nReal-time Analytics\nHistorical\
    \ Analytics\nData  \nCollection\nData  \nPre-procesing\nData  \nAnalytics\nData\
    \  \nUse\nTimeliness + Accuracy + Completeness\nOption 2\nOption 1\nFigure 2.\
    \ Illustrations of the different way to cater to each application’s ﬁtness for\
    \ use requirements.\nIt is crucial to deliver high-quality data through a single\
    \ data pipeline, but there are\nadditional requirements that must be taken into\
    \ account. Many IoT applications have the\nability to off-load certain analytical\
    \ processes to the lower layers of the application, for\nexample, fog and edge\
    \ [20]. Such analytical processes might require data quality assessment.\nA challenge\
    \ exists in these kind of applications. Given various fusion strategies, when\
    \ is it\nappropriate to choose a given strategy based on their computational resource\
    \ utilization?\nFor example, Kalman’s fusion has been reported to be computationally\
    \ expensive [21],\nand therefore, it might not be efﬁcient for edge applications\
    \ that are characterized by low\ncomputational resources.\nThis paper proposes\
    \ an approach that uses fusion within a single data pipeline to\ndeliver a unique\
    \ experience for each application. As the use cases increase, so might the\nfusion\
    \ engine scale to support them. Fusion techniques have been widely used to combine\n\
    different parts of the same or sometimes different systems to complement or beneﬁt\
    \ from\nthe advantages of each. Fusion has an advantage that allows for the weighting\
    \ of the combi-\nnation of the DQDs to be tailored to speciﬁc applications. Therefore,\
    \ this paper investigates\nhow various fusion techniques can be integrated into\
    \ big data quality assessment to deliver\na single data pipeline that can uniquely\
    \ cater to each application’s data quality needs. It\nalso assesses the computational\
    \ resource utilization of the fusion techniques.\nSensors 2023, 23, 5993\n5 of\
    \ 18\n3. Background and Related Work\nThis paper builds on previous research on\
    \ data quality assessment using trust and\ncompares the performance of different\
    \ data fusion strategies. This section deﬁnes key\nconcepts that form the basis\
    \ for the remainder of the paper.\n3.1. Data Quality\nIoT data are a crucial part\
    \ of many systems today and are used to aid decision making\nand create innovations.\
    \ Much of the data used, however, are curated by low-cost sensors,\nwhich can\
    \ be unreliable or inaccurate [22]. Assessing the quality of such data before\
    \ use\nis therefore important. Data quality has been deﬁned differently by several\
    \ authors due\nto its subjective nature. Heravizadeh et al. [23] deﬁne data quality\
    \ as the totality of an\nentity’s characteristics (data) that bear on its ability\
    \ to satisfy stated and implied needs.\nSidi et al. [24] deﬁne data quality as\
    \ appropriateness for use or meeting user needs. This\ndeﬁnitions aligns with\
    \ the illustration given in section 2. Not all applications have the same\ndata\
    \ quality requirements.\nLee et al. [25] present a structured method to represent\
    \ and apply a wide range of\nmetrics, possibly subjective to coefﬁcients. This\
    \ uses the concept of data quality dimensions\n(DQDs). DQDs provide a framework\
    \ to associate wide-ranging data quality metrics to data.\nA DQD is a characteristic\
    \ or feature of information for classifying information and data\nrequirements\
    \ [25], for example, accuracy and completeness. DQDs exist at different stages\n\
    of the big data cycle. Each application has a unique weight for each DQD throughout\
    \ the\nbig data cycle. To satisfy such requirements, different fusion strategies\
    \ have to be applied.\nIn IoT and big data, various solutions have been proposed\
    \ to address the challenges\nof inadequate data quality. For instance, Kuemper\
    \ et al. [26] introduced a framework\nthat leverages the capabilities of IoT infrastructure\
    \ and interpolation algorithms to val-\nidate crowdsourced data through sensor\
    \ fusion. The authors employ machine learning\ntechniques to validate the resulting\
    \ data quality, relying on data obtained from neigh-\nboring sensors. However,\
    \ a signiﬁcant challenge faced by this and other data quality\nsolutions [9,27]\
    \ is the requirement for a gold standard for validation.\n3.2. Data Fusion\nThe\
    \ terms data and information fusion have been used interchangeably in many ﬁelds.\n\
    In some, a distinction occurs, with data fusion referring to raw, unprocessed\
    \ data and\ninformation fusion referring to processed data. Several deﬁnitions\
    \ of data fusion exist. In a\nmore concise deﬁnition, data fusion can be deﬁned\
    \ as a combination of multiple sources to\nobtain improved information; in this\
    \ context, improved information means less expensive,\nhigher-quality, or more\
    \ relevant information [28]. Data fusion is a multidisciplinary area\nthat involves\
    \ several ﬁelds, and it is not easy to establish a clear and strict classiﬁcation\
    \ [28].\nIn the context of this work, since the interest is to determine the relationship\
    \ between data\nquality properties across the big data model and how these propagate\
    \ throughout the\ncycle, this paper adopts an approach proposed by Durrant-Whyte\
    \ et al. [29]. Here, fusion\nis deﬁned according to the relations between the\
    \ input data sources. Three approaches\nare deﬁned:\n1.\nComplementary: The information\
    \ provided by the different sources represents differ-\nent parts of the system\
    \ and fusing it results in a complete representation of the system.\n2.\nRedundant:\
    \ The same target is measured by two different processes, and fusing of the\n\
    resulting information can lead to increased conﬁdence.\n3.\nCooperative: The result\
    \ of the fusion process is said to produce new information that\nis typically\
    \ more complex than the original information.\nFigure 3 summaries Whyte’s three\
    \ classiﬁcation strategies based on the relationships\nbetween the data sources\
    \ and shows how different sources can be combined under scenarios.\nA more detailed\
    \ description can be found here [28].\nSensors 2023, 23, 5993\n6 of 18\n(a + b)\n\
    (b)\n(c)\nFused \ninformation\nA\nB\nC\nS1\nS2\nS3\nS4\nS5\nComplementary \nFusion\n\
    Redundant  \nFusion\nCooperative \nFusion\nA\nB\nB\nC\nC'\nInformation\nSources\n\
    Figure 3. Whyte’s fusion classiﬁcation based on the relations between the data\
    \ sources [28].\n3.3. Related Work\nThe ﬁeld of data fusion has grown immensely\
    \ over the past years, with several\ntechniques reported and used in many applications\
    \ [30]. Traditional fusion methods such\nas least square estimation and arithmetic\
    \ mean have been reported to have low accuracies\nin many situations [31,32].\
    \ Commonly used techniques such as fuzzy logic, Kalman ﬁlter,\nand Bayesian inference\
    \ also suffer from their own limitations [33–35].\nKalman ﬁlter is a form of statistical\
    \ interpolation that uses a model of dynamics and\nonboard sensor measurements\
    \ to recursively determine estimates for data fusion [36]. This\ntechnique requires\
    \ the system to provide the accurate state, observation equations, and\nprior\
    \ knowledge of the statistical characteristics of the system and observation noise\
    \ [30,37].\nKalman ﬁlters exist in several forms. There is the basic Kalman ﬁlter,\
    \ which was designed\nfor linear systems [38]. Other ones include the extended\
    \ Kalman ﬁlter and unscented\nKalman ﬁlter. Each of the preceding ﬁlters tries\
    \ to mitigate the weakness of its predecessor.\nHamouda et al. [39] applied the\
    \ extended Kalman ﬁlter to measure and predict agri-\ncultural parameters, including\
    \ soil moisture and temperature, to ﬁlter noisy measurements\nin smart heterogeneous\
    \ precision agriculture from energy sensor nodes deployed on a\nfarm. Lai et al.\
    \ [40] proposed a low-cost air quality monitoring and real-time prediction\nsystem\
    \ based on IoT and edge computing employing a prediction algorithm that is based\n\
    on a Kalman ﬁlter. This helps improve low-cost sensors’ accuracy by 27% on the\
    \ edge\nside. Abioye et al. [41] applied a Kalman ﬁlter to a subsurface ﬁbrous\
    \ capillary irrigation\nsystem. It was used to reduce the sensor noise and help\
    \ improve the accuracy of water\nlevel estimation.\nThe Bayesian inference uses\
    \ Bayes’ formula to combine sensor data [42]. Bayes’ for-\nmula helps deﬁne the\
    \ relationship between the a priori, a conditional, and a posteriori\nprobabilities\
    \ given in a hypothesis [42]. The downside of this method is that it is sensi-\n\
    tive to prior probability distribution [33]. Razaﬁmandimby et al. [43] applied\
    \ Bayesian\ninference to reduce the amount of high spatiotemporal correlated data\
    \ which are sent\nto the cloud for smart agricultural applications. Their results\
    \ show a reduction in the\namount of transmitted data and energy consumption,\
    \ while maintaining an acceptable\nlevel of data prediction accuracy. Gevaert\
    \ et al. [44] proposed a novel spectral–temporal\nresponse surfaces methodology\
    \ which uses Bayesian inference to impute missing spectral\ninformation in the\
    \ multispectral imagery and introduces observation uncertainties into the\ninterpolations.\
    \ This is applied to a ﬁeld of potatoes for experimentation.\nThe fuzzy logic\
    \ theory allows the uncertainty in multisensor fusion to be directly\nrepresented\
    \ in the inference process [45–47]. When observational evidence highly conﬂicts\n\
    with itself, however, the fusion result may be unacceptable [33]. Manjunatha et\
    \ al. [48]\nused fuzzy logic to propose an algorithm for event detection applications\
    \ in wireless sensor\nnetworks. The results show that multiple data fusion improves\
    \ the reliability and accuracy\nof the sensed data.\nSensors 2023, 23, 5993\n\
    7 of 18\nWeighted fusion algorithms have gained much traction from the data fusion\
    \ commu-\nnity [21,49–51]. These work by assigning a weight factor to each sensor\
    \ input [21]. The core\nadvantages include optimality, unbiasedness, and minimum\
    \ mean squared error [52,53].\nMoreover, compared with the Kalman ﬁlter, Bayesian\
    \ estimation, and fuzzy logic theory,\nit can generate results without the requirement\
    \ of any prior knowledge of the system or\nobservation noises [21,49]. In the\
    \ case of the proposed application, the fusion’s weight-\ning strategy would help\
    \ deliver unique ﬁtness for use requirements for each application.\nTable A2 summarises\
    \ the advantage and disadvantage of the various strategies.\n4. Framework Implementation\n\
    The end-to-end implementation of the system comprises two fundamental compo-\n\
    nents. The ﬁrst component is the data quality assessment (DQA), crucial in real-time\
    \ data\nquality evaluation. The DQA component is responsible for assessing the\
    \ data quality in\nreal-time. It operates through three stages, as shown in Figure\
    \ 4. Each has unique data qual-\nity dimensions: accuracy, completeness, consistency,\
    \ and timeliness. Previous research [16]\ndescribes this in more detail.\nData\
    \ collection\nData pre-processing\nData  processing and analytics\nData use\n\
    Broker  1\nKafka Node\nBroker  2\nBroker  N\nBroker  1\nKafka Node\nBroker  2\n\
    Broker  N\nZookeeper\nTrust computation\nInput\nProcesing\nOutput\nApache Spark\n\
    Trust computation\nHadoop Cluster\nProcessed data\nRaw data\nDashboard\nTrust\
    \ computation\nHDFS (Hadoop Distributed File System)\nData Stores\nAPI Sources\n\
    Real-time streaming\nData producers\nTrust Fusion Engine\nFigure 4. End -to-end\
    \ implementation of the data pipeline with a fusion engine.\nThe second core component\
    \ of the implementation is the data fusion engine. This\ncomponent plays a vital\
    \ role in integrating and consolidating the results obtained from the\nthree stages\
    \ of the DQA. It takes the intermediate quality assessment outputs from each\n\
    stage and returns a single quality score. The data fusion engine operates independently\
    \ and\ncan be conﬁgured with different fusion strategies, providing ﬂexibility\
    \ and adaptability to\nmeet the speciﬁc needs of different applications. By combining\
    \ the outputs from the DQA\nstages, the data fusion engine provides a holistic\
    \ view of the data quality, enabling support\nfor different application needs.\
    \ Both components are modular and can apply assessments of\nfusion strategies\
    \ independently. The following sections highlight each component in detail.\n\
    4.1. Data Quality Assessment (DQA)\nThe DQA is responsible for assessing the quality\
    \ of the data from data streams before\nthey are shared in real-time. This is\
    \ based on previous research [16] that uses trust to\nevaluate data quality. The\
    \ previous study has built and tested an end-to-end DQ assessment\nframework that\
    \ integrates DQ assessment into the big data cycle for data-shared IoT\nSensors\
    \ 2023, 23, 5993\n8 of 18\napplications [4,16]. Trust is a well-established metric\
    \ that has been used to determine the\nvalidity of a piece or source of data in\
    \ crowdsourced or other unreliable data collection\ntechniques. In this paper,\
    \ the terms trust score and quality score are used to mean the\nsame thing.\n\
    Figure 4 shows the detailed internal implementation of the DQA and how it inte-\n\
    grates with the data fusion engine to complement its functionality. The DQA is\
    \ based\non industry-standard data pipeline tools. A detailed description and\
    \ implementation of\nthe DQ assessment framework and the use of trust to evaluate\
    \ DQ for data-shared IoT\napplications can be found here [4,16].\nAs the data\
    \ stream through the framework, they are evaluated for at each stage. In\nFigure\
    \ 4, this is represented by the Trust computation blocks. Each block has a set\
    \ of unique\nDQDs used to evaluate data quality. For example, the trust block\
    \ during data preprocessing\n(T1) will evaluate intrinsic data quality, which\
    \ in our example is timeliness. Trust evaluated\nduring processing (T2) evaluates\
    \ investigative trust, accuracy, and completeness in our\nexample. This computation\
    \ results into a single trust score (T1, T2, and T3) for each stage. T3\nis not\
    \ used in this example, as it is still an element for future research. This requires\
    \ deﬁning\na feedback loop from each application back into the data quality assessment\
    \ framework.\nHowever, it can later be integrated into the framework without any\
    \ modiﬁcations. The\nresulting score must be combined into a single score that\
    \ represents the unique ﬁtness for\nuse for each end-user application.\n4.2. Data\
    \ Fusion Engine\nThe data fusion engine takes the output of all three trust stages\
    \ and returns a single\nscore representative of all the stages. Depending on the\
    \ fusion strategy used, the resulting\nscore should be able to satisfy the data\
    \ quality requirements for each application in a\nhomogeneous data pipeline. Fusion\
    \ allows the facility to control how each stage can be\nweighted to achieve this\
    \ objective. This paper uses an Adaptive weighted fusion strategy\nand compares\
    \ it with other fusion strategies.\n4.2.1. Mathematical Formulation for Adaptive\
    \ Weighted Fusion\nAssuming there are n trust stages with a different trust score\
    \ at each stage, the resulting\nweighted data fusion model is shown in Figure\
    \ 5. Moreover, assume that the mean squared\nerrors of each trust score for each\
    \ stage are σ2\n1, σ2\n2, . . . , σ2\nn, and the calculated trust scores\nare\
    \ T1, T2, . . . , Tn. The corresponding weight factors for the trust scores are\
    \ W1, W2, . . . , Wn,\nrespectively. Since each trust score is independent of\
    \ the other, and all belong to the\nunbiased estimation of T∗, the trust score\
    \ factor and weight of T∗ after fusion satisfy the\nfollowing relationship:\n\
    T∗ =\nn\n∑\ni=1\nWiTi ,\nn\n∑\ni=1\nWi = 1\n(1)\nTherefore, the total mean square\
    \ error is\nσ2 = E\nh\n(T − ¯T)2i\n= E\n\n\n \nn\n∑\ni=1\nWiT −\nn\n∑\ni=1\n\
    WiTi\n!2\n\n= E\n\"\nn\n∑\ni=1\nW2\ni (T − Ti)2\n#\n=\nn\n∑\ni=1\nW2\ni σ2\n\
    i\n(2)\nSensors 2023, 23, 5993\n9 of 18\nFollowing Equation (2), the mean square\
    \ error σ2 is a multivariate quadratic func-\ntion. Therefore, σ2 must have a\
    \ minimum value. Using the extreme value theory of the\nmultivariate function,\
    \ the minimum weight factor is\nW∗\ni =\n1\nσ2\ni ∑n\ni=1\n1\nσ2\ni\n(3)\nCorrespondingly,\
    \ the minimum mean square error is\nσ2\nmin =\n1\n∑n\ni=1\n1\nσ2\ni\n(4)\nFor\
    \ of any number of the trust stages j(j = 1, 2, 3, . . . , n), it can be concluded\
    \ that\nσ2\nmin < σ2\nj\n(5)\n   Initial Trust, \nInvestigative Trust, \n   Result\
    \ Trust, \n \n \n \nFigure 5. Adaptive weighted data fusion model.\nTherefore,\
    \ the overall mean square error is smaller than the mean square error of any\n\
    given single stage. Moreover, the overall fused trust score will be improved compared\
    \ with\nthe trust score of a single stage. The data quality properties of each\
    \ stage are reﬂected into\nthe ﬁnal score. Their contribution, however, is weighted\
    \ depending on the ﬁtness for use\nfor each application. Table A1 summarises all\
    \ the notations used.\n4.2.2. Kalman Fusion\nIn 1D Kalman fusion, the system’s\
    \ state and measurements are scalar values. The ﬁlter\nmaintains two estimates\
    \ of the system’s state: the predicted state, based on the previous\nstate and\
    \ the system’s dynamics, and the ﬁltered state, based on the predicted state and\n\
    the most recent measurement [54]. The Kalman fusion process utilizes these two\
    \ estimates,\nthe predicted state and the ﬁltered state, to continuously update\
    \ its understanding of\nthe system’s state over time. As new measurements become\
    \ available, the ﬁlter reﬁnes\nits estimates by iteratively adjusting the weights\
    \ assigned to the predicted state and the\nmeasurement. This iterative update\
    \ mechanism allows the Kalman ﬁlter to adapt and\nprovide increasingly accurate\
    \ state estimates as more data are assimilated. Figure 6 shows\nthe process of\
    \ measurement update and prediction.\nBy iterating through these equations over\
    \ time, the Kalman fusion combines measure-\nments with predictions to estimate\
    \ the true state of a system. A detailed description and\nmathematical illustration\
    \ of Kalman fusion can be found here [54].\nSensors 2023, 23, 5993\n10 of 18\n\
    Measurement \nUpdate\nPrediction\nFigure 6. Steps of the Kalman fusion.\n5. System\
    \ Evaluation\nTwo experiments were carried out to assess the proposed system,\
    \ each serving a\ndifferent purpose. The initial experiment aimed to demonstrate\
    \ each fusion method’s\nimpact on the resulting data quality score and examine\
    \ how this can be used to support a\nspeciﬁc application.\nVarious fusion methods\
    \ employ distinct weighting schemes. For instance, when\npresented with two inputs,\
    \ a fusion method could assign a greater weight to an input\nwith a lower standard\
    \ error and a lesser weight to one with a higher standard error. As\na result,\
    \ diverse fusion methods can produce varying data quality scores. Rather than\n\
    incorporating numerous data quality assessment procedures into a single pipeline\
    \ or\nconstructing multiple pipelines, different fusion methods can be utilized\
    \ to aid different\napplications by simply integrating a new fusion method or\
    \ implementing a novel weighting\nscheme that is custom tailored to the application.\n\
    The objective of the second experiment is to evaluate and compare the computational\n\
    resource consumption of the different fusion methods. While it is crucial to deliver\
    \ person-\nalized data quality scores, it is also vital to assess the impact of\
    \ each fusion method on the\napplication in terms of computational resources.\
    \ Different applications perform analytics\nthat necessitate quality assessment\
    \ at varying layers. Particular layers, such as the edge,\nhave resource constraints.\
    \ This experiment, therefore, aims to facilitate improved service\nplacement within\
    \ IoT application architectures.\nThe experiments were conducted separately because\
    \ each dataset has speciﬁc features\nsupporting only one experiment. In the ﬁrst\
    \ case, a dataset with a gold standard was used\nto assess ﬁtness for use by varying\
    \ DQDs. In the second case, a dataset collected over a\nmore extended period was\
    \ used. Detailed descriptions of each dataset and experimental\nsetup are provided\
    \ in the following sections.\n5.1. Dataset Description\nTwo datasets where used\
    \ to evaluate the proposed system. Both are collected from\nreal-world IoT deployments.\
    \ The ﬁrst is based on data collected in an air quality deploy-\nment. This dataset\
    \ is publicly available [55]. A multisensor device was co-located with a\nconventional\
    \ air pollution analyzer. This was used to provide the true concentration values\n\
    of the target pollutants at the measurement site. These values were hence used\
    \ as a gold\nstandard. This study uses data from the CO sensor. This was collected\
    \ over a one year\nperiod. This dataset is used to evaluate the ﬁtness for use\
    \ as it contains gold-standard data.\nThis ensures that the accuracy metric can\
    \ be determined and held constant, as its only a\ndesirable DQD.\nThe second dataset\
    \ consists of weather data collected from a real-world setup of\nweather stations\
    \ installed across the United Kingdom between 2014 and 2020. The dataset\nencompasses\
    \ over 100 weather stations, each recording air temperature, rainfall, relative\n\
    humidity, and wind values, as well as an average of 30,000 data points yearly.\
    \ This\ndataset serves as a test case for evaluating the system performance of\
    \ the proposed fusion\ntechniques for big sensor data systems, covering real-time\
    \ and batch processing scenarios.\nSensors 2023, 23, 5993\n11 of 18\nIts deployment\
    \ scale and longevity make it ideal for assessing the effectiveness of the\nproposed\
    \ techniques.\n5.2. Experiment 1\nThe goal of this experiment is to show the effects\
    \ each fusion method has on the\nresulting data quality score and how this can\
    \ be used to support various applications. The\ndata undergo processing via the\
    \ system illustrated in Figure 4. A Kafka producer reads\nand preprocesses the\
    \ data, then sends them to Apache Spark for further processing and\nanalytics.\
    \ Preprocessing involves calculating quality score T1, which assesses timeliness\n\
    DQD, while data processing and analytics calculate the quality score, T2, based\
    \ on accuracy\nand completeness DQDs. These scores are sent to the fusion engine,\
    \ which generates a\nsingle, usable score, as depicted in Figure 4.\nTo investigate\
    \ varying data quality requirements, the experiment explores two scenar-\nios\
    \ by modifying essential DQDs. In the ﬁrst scenario, T1 values are varied while\
    \ T2 is held\nconstant. T1 values are varied by regulating the rate at which the\
    \ Kafka producer transmits\ndata to the consumer, thereby introducing delays in\
    \ the data pipeline. This is expected to\nimpact the data quality of the real-time\
    \ analytics application by lowering timeliness.\nThe second scenario entails changing\
    \ T2 values while keeping T1 constant, which\ninvolves introducing missing values\
    \ into the dataset to impact the completeness of DQD.\nThis manipulation can vary\
    \ quality scores for T2 depending on the rate of missing values.\nBy virtue of\
    \ the data requirements on the historical application, this manipulation should\n\
    affect the overall quality score for the application.\nAfter calculating the scores,\
    \ a distinct fusion strategy is employed for each application\nto enable varying\
    \ weighting of the scores and produce unique, usable quality scores. As\na result,\
    \ two quality score curves are generated, one for each application, using a speciﬁc\n\
    fusion strategy. The resulting curves for the two scenarios are shown in Figure\
    \ 7a and\nFigure 7b, respectively.\n2004-03\n2004-05\n2004-07\n2004-09\n2004-11\n\
    2005-01\n2005-03\nDate\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n1.1\nTrust score\n\
    Adaptive weighted fusion\nNaive fusion\nKalman fusion\n(a)\n2004-03\n2004-05\n\
    2004-07\n2004-09\n2004-11\n2005-01\n2005-03\nDate\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n\
    1.0\n1.1\nTrust score\nAdaptive weighted fusion\nNaive fusion\nKalman fusion\n\
    (b)\nFigure 7. Comparing the effect of each fusion method on the resulting quality\
    \ scores based on\nAdaptive weighted fusion, Kalman fusion, and Naïve fusion.\
    \ The highlighted green areas show the\neffect each fusion method has on the resulting\
    \ quality scores\n5.3. Experiment 2\nThis experiment evaluates the resource consumption\
    \ for the various fusion methods.\nThis is carried out for both real-time and\
    \ batch processes. This measures the CPU and\nmemory utilization. In this setup,\
    \ there were no modiﬁcation to the data or the DQDs. The\ndata are processed as\
    \ is. As the data are evaluated for quality, the experiment measures the\nCPU\
    \ and memory utilization of the fusion engine. It is important to note that the\
    \ results\nreported here are only for the fusion engine. The other parts of the\
    \ system have been\npreviously evaluated [16]. This is represented in Figures\
    \ 8 and 9.\nSensors 2023, 23, 5993\n12 of 18\n50\n100\n150\n200\n250\n300\n350\n\
    400\n0\n10\n20\n30\n40\n50\n%CPU usage\nAdaptive weighted fusion\nKalman fusion\n\
    Naive  fusion\n(a) CPU utilization\n50\n100\n150\n200\n250\n300\n350\n400\n10.6\n\
    10.8\n11.0\n11.2\n11.4\n11.6\n11.8\n12.0\nMemory (MB)\nAdaptive weighted fusion\n\
    Kalman fusion\nNaive  fusion\n(b) Memory utilization\nFigure 8. Comparing CPU\
    \ and memory utilization for three fusion strategies in a real-time data\nstreaming\
    \ pipeline.\n5\n10\n15\n20\n25\n30\n35\nData size (months)\n1\n2\n3\n4\n5\n6\n\
    7\nCPU Time (seconds)\nAdaptive weighted fusion\nKalman fusion\nNaive fusion\n\
    (a) CPU utilization\n5\n10\n15\n20\n25\n30\n35\nData size (months)\n7.5\n8.0\n\
    8.5\n9.0\nMemory (MB)\nAdaptive weighted fusion\nNaive fusion\nKalman fusion\n\
    (b) Memory utilization\nFigure 9. Comparing CPU and memory utilization between\
    \ adaptive weighted and Kalman fusion\nfor batch data pipeline.\n5.4. Results\
    \ and Analysis\nFigure 7 shows the resulting quality scores that take into account\
    \ ﬁtness for use\nrequirements for the two categories of applications. Figure\
    \ 7a shows the resulting effect of\ncontinuously reducing timeliness and its effect\
    \ on both application categories. Adaptive\nweighted fusion and Kalman fusion\
    \ were able to maintain a more stable quality experience\neven when timeliness\
    \ was reduced. Kalman fusion presents an overall mean quality score\nof 0.987\
    \ and standard deviation of 0.009. Adaptive weighted fusion presents an overall\n\
    mean quality score of 0.984 and standard deviation of 0.01. Although the difference\
    \ between\nKalman fusion and Adaptive fusion is relatively small, the characteristics\
    \ they show can\nbe used to deliver a different quality experience to different\
    \ application with varying data\nquality needs where timeliness is not a stringent\
    \ requirement. Naïve fusion, however, was\nimpacted by a reduction in timeliness,\
    \ therefore resulting in lower data quality. It had an\noverall mean quality score\
    \ of 0.886 and standard deviation of 0.05. In an application where\ntimeliness\
    \ is a stringent requirement, this can be useful to show the reduced data quality\n\
    while taking timeliness into consideration.\nFigure 7b shows results of varying\
    \ completeness. The highlighted area shows the\neffect each fusion method has\
    \ on the resulting quality scores. A reduction in T2 did not have\na signiﬁcant\
    \ impact on Kalman fusion. Unlike the above case, Adaptive weighted fusion\npresents\
    \ lower quality scores at some point compared with Naïve fusion, thus showing\n\
    the dynamic capacity of the fusion schemes over the Naïve approach. Overall, Kalman\n\
    fusion presents a mean quality score of 0.984 and standard deviation of 0.011\
    \ compared\nSensors 2023, 23, 5993\n13 of 18\nwith Adaptive weighted fusion, with\
    \ a mean of 0.97 and standard deviation of 0.02. As\nin the above case, these\
    \ differences in the resulting quality score for each fusion method\ncan be used\
    \ to deliver different quality experience to IoT applications with varying data\n\
    quality needs within a single data pipeline.\nAs illustrated above, each fusion\
    \ method had a different effect on the resulting quality\nscore. This paper has\
    \ compared only a few fusion methods and how this can help deliver\nunique ﬁtness\
    \ for use to two broad categories of applications. The system can easily be\n\
    extended to include other fusion methods that can have custom weighting strategies\
    \ to\ndeliver data quality scores to very speciﬁc applications in IoT.\n5.5. System\
    \ Performance\nSystem performance was evaluated for the fusion engine’s CPU time\
    \ and memory\nutilization. These metrics have been suggested as the most appropriate\
    \ when evaluating\na fusion strategy [28]. The evaluation was performed for both\
    \ real-time streaming and\nbatch-processing data pipelines. It is important to\
    \ note that the evaluation results reported\nhere are only for the fusion engine.\
    \ The other part of the system has been evaluated in a\nprevious study [16].\n\
    5.5.1. Real-Time Streaming\nThe fusion engine node is completely decoupled from\
    \ the rest of the system; there-\nfore, its resources can be fully customized\
    \ depending on the workload. The fusion node\nwas conﬁgured for the real-time\
    \ streaming pipeline with 5 CPUs, each at 2.40 GHz and\n32 GB of RAM. CPU utilization\
    \ is measured in percentage usage, while memory is in\nmegabytes consumed.\nFigure\
    \ 8a shows the comparison results for CPU utilization for three fusion strategies:\n\
    Adaptive weighted fusion, Kalman fusion, and Naïve fusion for a single real-time\
    \ stream\njob. As shown, Kalman and Adaptive weighted fusion have the highest\
    \ comparable\npercentage of CPU utilization, with means of 22.44% and 22.54% and\
    \ standard deviations\nof 4.39 and 4.14, respectively. Naïve fusion had the lowest\
    \ values, with a mean of 8.75%\nand a standard deviation of 5.04. All three methods\
    \ had high viability, as shown in the\ngraph, and high and comparable standard\
    \ deviation values.\nFigure 8b shows the comparison results for memory utilization\
    \ for the three fusion\nstrategies. Unlike CPU utilization, Kalman fusion had\
    \ the lowest values, with a mean of\n10.93 MB and a standard deviation of 0.04.\
    \ Kalman fusion has been suggested to be more\nresource-effective for smaller\
    \ data sizes [56]. However, overall, all three fusion strategies\nhad values within\
    \ a close range, with means and standard deviations of 11.33 MB and\n0.132 and\
    \ 11.49 MB and 0.03 for Adaptive weighted and Naïve fusion, respectively. This\
    \ is\nbecause, for real-time streaming jobs, a small amount of data are processed\
    \ at a given time.\n5.5.2. Batch Processing\nThe system was also evaluated for\
    \ batch processing workloads. The results in this\nsection compare two fusion\
    \ strategies: Adaptive weighted and Kalman fusion. They were\nevaluated for CPU\
    \ time and memory utilization as data size increased. The data size was\nmeasured\
    \ in the number of months. This was performed on a single node with 5 CPUs,\n\
    each at 2.40 GHz and 32 GB of RAM.\nFigure 9a,b compares CPU time and memory utilization\
    \ between Adaptive weighted\nfusion, Kalman fusion, and Naïve fusion, respectively,\
    \ as data size increases for batch\nprocessing. As shown, as data size (in months)\
    \ increases, so does consumption for both\nCPU and memory. Adaptive weighted fusion\
    \ and Naïve fusion had lower values compared\nwith Kalman fusion. As previously\
    \ reported, Kalman fusion is a highly computational\nfusion strategy [21].\nAs\
    \ compared with real-time streaming, batch processing had lower memory consump-\n\
    tion. This is partly due to the frequent memory reads and writes that streaming\
    \ jobs incur.\nSensors 2023, 23, 5993\n14 of 18\nBatch processing had high CPU\
    \ percentage usage compared with real-time streaming, with\naverages of up to\
    \ 95%.\nThe system was also evaluated for scalability with different compute conﬁgurations.\n\
    These are summarized in Table 2. The results indicate that the fusion engine could\
    \ not be\nscaled. Increasing compute resources yielded the same average delay\
    \ in CPU time and\nmemory utilized. It should be noted, however, that this constraint\
    \ is inherent in the fusion\nalgorithms rather than the overall system. This is\
    \ because, during the fusion stage, all the\ndata have to be processed in a single\
    \ stage. It should also be noted that the scalability of\nthe DQA was reported\
    \ in previous research [16]. The results show that it could scale both\nhorizontally\
    \ and vertically.\nTable 2. System resource conﬁguration for batch data pipelines.\n\
    Conf 1\nConf 2\nConf 3\nConf 4\nCPU (vcpus)\n4\n8\n16\n32\nRAM (GB)\n8\n16\n32\n\
    64\n5.6. Discussion\nThis paper compares three fusion strategies which combine\
    \ quality scores for a given\ndata stream or data inputs. It can be argued that\
    \ each fusion technique is suitable for a\ngiven application; that is, it presents\
    \ a suitable representation of the data quality for the\ngiven application. The\
    \ application of a given fusion strategy will depend on how the\napplication views\
    \ quality. For example, some applications might require consistent data\nquality,\
    \ requiring a dynamic means to represent quality, while others might handle patches\n\
    of ﬂuctuating data quality but require overall quality above a given threshold.\
    \ This can be\nuseful to support data from sensors in difﬁcult communication situations.\n\
    Each fusion method has a different weighting strategy which affects the ﬁnal score.\n\
    In Kalman fusion, higher error rates are penalized highly [52]. This can be useful\
    \ in\napplications where a change in a single data quality dimension (for example,\
    \ timeliness)\nshould not affect the overall quality of needs of the application.\
    \ Using Kalman fusion,\ntherefore, a higher penalty would be applied to that data\
    \ quality dimension to deliver\nthe desired quality experience for that application.\
    \ For example, in real-time analytics,\nsometimes, the data can be late; however,\
    \ this should not affect the overall quality. These\ndata can be used to calculate\
    \ intermediate results, which can be updated later. Using this\nkind of fusion\
    \ strategy, such applications can be supported.\nAdaptive weighted fusion can\
    \ determine the optimal weights for each source. This\nallows the differences\
    \ between each data source’s error rate to be ﬂexibly considered [57].\nThey can\
    \ be useful in dynamic environments where the error rates between several data\n\
    sources must be considered. This would help maintain a quality score that adapts\
    \ to the\nerror rate. This can be useful to support applications (for example,\
    \ smart agriculture) that\nrely on data from network-constrained environments\
    \ by offering a more dynamic data\nquality assessment experience.\nNaïve fusion\
    \ would assign equal weights. This can be useful in cases where we do\nnot know\
    \ the application’s needs. For scalability and resource-constrained environments,\n\
    however, Adaptive weighted fusion is a better choice compared with Kalman fusion.\n\
    The goal of this work is not to imply that a given fusion method is better than\
    \ the\nother in all general cases but rather to show that a given fusion method\
    \ can deliver a better\nquality experience that satisﬁes a given application requirement.\n\
    6. Summary and Conclusions\nThis paper discussed different IoT applications’ varying\
    \ data quality needs, called\nﬁtness for use. The solution integrates different\
    \ fusion methods to cater to different applica-\ntions’ unique data quality needs.\
    \ The study investigates the impact of these fusion methods\nSensors 2023, 23,\
    \ 5993\n15 of 18\non data quality scores and their applicability in supporting\
    \ diverse applications. It also\nevaluates the computational efﬁciency of the\
    \ fusion methods to optimize service placement.\nHowever, it is essential to note\
    \ some limitations of the study. Firstly, the real-time\nand historical analytics\
    \ comparison may not capture all potential scenarios and variations\nin data quality\
    \ requirements. Different applications may exhibit distinct patterns and\ndata\
    \ characteristics, which could inﬂuence the performance of fusion methods differently.\n\
    Additionally, the study focuses on only three fusion methods—Kalman fusion, Adaptive\n\
    weighted fusion, and Naïve fusion—limiting the exploration of other potential\
    \ fusion\ntechniques that could enhance data quality.\nIn conclusion, this paper\
    \ offers an insightful approach to addressing the diverse data\nquality needs\
    \ of IoT applications through the ﬁtness for use solution and fusion methods.\n\
    However, limitations regarding the representativeness of the comparison scenarios,\
    \ the\nlimited exploration of fusion methods, and the lack of detailed resource\
    \ requirements\nand scalability considerations should be considered when interpreting\
    \ the ﬁndings and\napplying them in practical IoT settings. These form the basis\
    \ for future work.\nAuthor Contributions: J.B.: implementation, writing—original\
    \ draft, validation, and editing. G.M.P.O.:\nsupervision and investigation. R.C.:\
    \ supervision and investigation. D.D.: supervision, investigation,\nvalidation,\
    \ and writing and editing. All authors have read and agreed to the published version\
    \ of\nthe manuscript.\nFunding: This research is funded under the SFI Strategic\
    \ Partnership Programme (16/S/3296) and is\nco-funded by Origin Enterprises plc.\n\
    Institutional Review Board Statement: Not applicable.\nInformed Consent Statement:\
    \ Not applicable.\nData Availability Statement: The data presented in this study\
    \ are available on request from the\ncorresponding author. The data are not publicly\
    \ available due to copyright.\nConﬂicts of Interest: The authors declare no conﬂict\
    \ of interest.\nAppendix A\nTable A1 list all the math notations used in the paper.\n\
    Table A1. Math notations and their deﬁnitions.\nSymbol/Notation\nInterpretation\n\
    σ\nMean squared error of each trust score for each stage\nT\nTrust score for each\
    \ stage\nT∗\nResultant trust score after fusion\nW\nWeighting factor for each\
    \ stage\nAppendix B\nTable A2 Summary of the advantages and disadvantages of data\
    \ quality control\nmethods and fusion approaches.\nSensors 2023, 23, 5993\n16\
    \ of 18\nTable A2. Summary of the advantages and disadvantages of data quality\
    \ control methods and\nfusion approaches.\nMethod\nAdvantages\nDisadvantages\n\
    Data Quality\nDimensions (DQDs)\n•\nDQDs provide an\nacceptable, standardised,\
    \ ﬂexible, and\nmeasurable set of quality metrics to measure\ndata quality.\n\
    •\nThey require domain knowledge to deﬁne.\n•\nThey are a nonexhaustive list which\
    \ can be hard to\ndeﬁne for IoT applications because each use case is\nunique.\n\
    Fuzzy logic\n•\nIt is simple and capable of dealing with\nimprecise information\
    \ and possibly including\nheuristic knowledge about the phenomenon\nunder consideration\
    \ [58]\n•\nIt can produce unacceptable results if there is\nconﬂict between the\
    \ input observations [33]\n•\nIt is computationally expensive [21]\nKalman ﬁlter\n\
    •\nKalman ﬁlter provides an unbiased and optimal\nestimate of a state-vectorin\
    \ the sense of\nminimum error variance [58]\n•\nRequires the system to provide\
    \ the accurate state,\nobservation equations, and prior knowledge of the\nstatistical\
    \ characteristics of the system and\nobservation noise [30,37]\n•\nIt is computationally\
    \ expensive [21]\nBayesian inference\n•\nIt is simple and easy to setup\n•\nThis\
    \ method is sensitive to prior probability\ndistribution [33]\nReferences\n1.\n\
    Li, S.; Xu, L.D.; Zhao, S. The internet of things: A survey. Inf. Syst. Front.\
    \ 2015, 17, 243–259. [CrossRef]\n2.\nKishor, A.; Chakarbarty, C. Task Ofﬂoading\
    \ in Fog Computing for Using Smart Ant Colony Optimization. Wirel. Pers. Commun.\n\
    2022, 127, 1683–1704. [CrossRef]\n3.\nKollolu, R. A Review on Wide Variety and\
    \ Heterogeneity of IoT Platforms. SSRN Electron. J. 2020, 12, 3753–3760. [CrossRef]\n\
    4.\nByabazaire, J.; O’Hare, G.; Delaney, D. Using Trust as a Measure to Derive\
    \ Data Quality in Data Shared IoT Deployments. In\nProceedings of the 2020 29th\
    \ International Conference on Computer Communications and Networks (ICCCN), Honolulu,\
    \ HI,\nUSA, 3–6 August 2020; pp. 1–9. [CrossRef]\n5.\nKarkouch, A.; Mousannif,\
    \ H.; Al Moatassime, H.; Noel, T. Data quality in internet of things: A state-of-the-art\
    \ survey. J. Netw.\nComput. Appl. 2016, 73, 57–81. [CrossRef]\n6.\nAlrae, R.;\
    \ Nasir, Q.; Abu Talib, M. Developing House of Information Quality framework for\
    \ IoT systems. Int. J. Syst. Assur. Eng.\nManag. 2020, 11, 1294–1313. [CrossRef]\n\
    7.\nFarooqi, M.M.; Ali Khattak, H.; Imran, M. Data Quality Techniques in the Internet\
    \ of Things: Random Forest Regression. In\nProceedings of the 2018 14th International\
    \ Conference on Emerging Technologies (ICET), Islamabad, Pakistan, 21–22 November\n\
    2018; pp. 1–4. [CrossRef]\n8.\nYang, J.; Lan, G.; Li, Y.; Gong, Y.; Zhang, Z.;\
    \ Ercisli, S. Data quality assessment and analysis for pest identiﬁcation in smart\n\
    agriculture. Comput. Electr. Eng. 2022, 103, 108322. [CrossRef]\n9.\nFizza, K.;\
    \ Jayaraman, P.P.; Banerjee, A.; Georgakopoulos, D.; Ranjan, R. Evaluating Sensor\
    \ Data Quality in Internet of Things\nSmart Agriculture Applications. IEEE Micro\
    \ 2022, 42, 51–60. [CrossRef]\n10.\nKhokhlov, I.; Reznik, L. Knowledge Graph in\
    \ Data Quality Evaluation for IoT applications. In Proceedings of the 2020 IEEE\
    \ 6th\nWorld Forum on Internet of Things (WF-IoT), New Orleans, LA, USA, 2–16\
    \ June 2020; pp. 1–6. [CrossRef]\n11.\nMante, S.; Hernandez, N.; Hussain, A.M.;\
    \ Chaudhari, S.; Gangadharan, D.; Monteil, T. 5D-IoT, a semantic web based framework\n\
    for assessing IoT data quality. In Proceedings of the 37th ACM/SIGAPP Symposium\
    \ on Applied Computing, Virtual, 25–29\nApril 2022; pp. 1921–1924. [CrossRef]\n\
    12.\nZhang, L.; Jeong, D.; Lee, S. Data Quality Management in the Internet of\
    \ Things. Sensors 2021, 21, 5834. [CrossRef]\n13.\nWest, N.; Gries, J.; Brockmeier,\
    \ C.; Gobel, J.C.; Deuse, J. Towards integrated Data Analysis Quality: Criteria\
    \ for the application of\nIndustrial Data Science. In Proceedings of the 2021\
    \ IEEE 22nd International Conference on Information Reuse and Integration for\n\
    Data Science (IRI), Las Vegas, NV, USA, 10–12 August 2021; pp. 131–138. [CrossRef]\n\
    14.\nReynolds, M.W.; Bourke, A.; Dreyer, N.A. Considerations when evaluating real-world\
    \ data quality in the context of ﬁtness for\npurpose. Pharmacoepidemiol. Drug\
    \ Saf. 2020, 29, 1316–1318. [CrossRef]\n15.\nDevillers, R.; Bédard, Y.; Jeansoulin,\
    \ R.; Moulin, B. Towards spatial data quality information analysis tools for experts\
    \ assessing\nthe ﬁtness for use of spatial data. Int. J. Geogr. Inf. Sci. 2007,\
    \ 21, 261–282. [CrossRef]\n16.\nByabazaire, J.; O’Hare, G.M.; Delaney, D.T. End-to-End\
    \ Data Quality Assessment Using Trust for Data Shared IoT Deployments.\nIEEE Sens.\
    \ J. 2022, 22, 19995–20009. [CrossRef]\nSensors 2023, 23, 5993\n17 of 18\n17.\n\
    Abdullah, M.Z.; Arshah, R.A. A Review of Data Quality Assessment: Data Quality\
    \ Dimensions from User’s Perspective. Adv. Sci.\nLett. 2018, 24, 7824–7829. [CrossRef]\n\
    18.\nFaniel, I.M.; Jacobsen, T.E. Reusing Scientiﬁc Data: How Earthquake Engineering\
    \ Researchers Assess the Reusability of Colleagues’\nData. Comput. Support. Coop.\
    \ Work (CSCW) 2010, 19, 355–375. [CrossRef]\n19.\nMohamed, N.; Al-Jaroodi, J.\
    \ Real-time big data analytics: Applications and challenges. In Proceedings of\
    \ the 2014 International\nConference on High Performance Computing and Simulation\
    \ (HPCS), Bologna, Italy, 21–25 July 2014; pp. 305–310. [CrossRef]\n20.\nTaneja,\
    \ M.; Jalodia, N.; Davy, A. Distributed Decomposed Data Analytics in Fog Enabled\
    \ IoT Deployments. IEEE Access 2019,\n7, 40969–40981. [CrossRef]\n21.\nYaohui,\
    \ Z.; Li, W.; Bao, S.; Haibo, H.; Long, L. Application of an adaptive weighted\
    \ estimation fusion algorithm in landslide\ndeformation monitoring data processing.\
    \ IOP Conf. Ser. Earth Environ. Sci. 2020, 570, 062045. [CrossRef]\n22.\nOkafor,\
    \ N.U.; Delaney, D. Considerations for system design in IoT-based autonomous ecological\
    \ sensing. Procedia Comput. Sci.\n2019, 155, 258–267. [CrossRef]\n23.\nHeravizadeh,\
    \ M.; Mendling, J.; Rosemann, M. Dimensions of business processes quality (QoBP).\
    \ In Business Process Management\nWorkshops; Springer: Berlin/Heidelberg, Germany,\
    \ 2009. [CrossRef]\n24.\nSidi, F.; Shariat Panahy, P.H.; Affendey, L.S.; Jabar,\
    \ M.A.; Ibrahim, H.; Mustapha, A. Data quality: A survey of data quality\ndimensions.\
    \ In Proceedings of the 2012 International Conference on Information Retrieval\
    \ and Knowledge Management, Kuala\nLumpur, Malaysia, 13–15 March 2012; pp. 300–304.\
    \ [CrossRef]\n25.\nLee, Y.W.; Strong, D.M.; Kahn, B.K.; Wang, R.Y. AIMQ: A methodology\
    \ for information quality assessment. Inf. Manag. 2002,\n40, 133–146. [CrossRef]\n\
    26.\nKuemper, D.; Iggena, T.; Toenjes, R.; Pulvermueller, E. Valid.IoT. In Proceedings\
    \ of the 9th ACM Multimedia Systems Conference,\nAmsterdam, The Netherlands, 12–15\
    \ June 2018; pp. 294–303. [CrossRef]\n27.\nTsai, F.K.; Chen, C.C.; Chen, T.F.;\
    \ Lin, T.J. Sensor Abnormal Detection and Recovery Using Machine Learning for\
    \ IoT Sensing\nSystems. In Proceedings of the 2019 IEEE 6th International Conference\
    \ on Industrial Engineering and Applications (ICIEA),\nTokyo, Japan, 12–15 April\
    \ 2019; pp. 501–505. [CrossRef]\n28.\nCastanedo, F. A Review of Data Fusion Techniques.\
    \ Sci. World J. 2013, 2013, 704504. [CrossRef]\n29.\nDurrant-Whyte, H.F. Sensor\
    \ Models and Multisensor Integration. Int. J. Robot. Res. 1988, 7, 97–113. [CrossRef]\n\
    30.\nLuo, R.C.; Yih, C.C.; Su, K.L. Multisensor fusion and integration: Approaches,\
    \ applications, and future research directions. IEEE\nSens. J. 2002, 2, 107–119.\
    \ [CrossRef]\n31.\nCrassidis, J.L.; Junkins, J.L. Optimal Estimation of Dynamic\
    \ Systems; Chapman and Hall/CRC: Boca Raton, FL, USA, 2011.\n[CrossRef]\n32.\n\
    Nandi, S.; Kundu, D. Asymptotic properties of the least squares estimators of\
    \ the parameters of the chirp signals. Ann. Inst. Stat.\nMath. 2004, 56, 52–544.\
    \ [CrossRef]\n33.\nGao, S.; Zhong, Y.; Li, W. Random weighting method for multisensor\
    \ data fusion. IEEE Sens. J. 2011, 11, 1955–1961. [CrossRef]\n34.\nHall, D.L.;\
    \ McMullen, S.A.H. Mathematical Techniques in Multisensor Data Fusion; Artech\
    \ House: New York, NY, USA, 2004.\n35.\nLiao, Y.H.; Chou, J.C. Weighted Data Fusion\
    \ Use for Ruthenium Dioxide Thin Film pH Array Electrodes. IEEE Sens. J. 2009,\
    \ 9,\n842–848. [CrossRef]\n36.\nHaupt, S.E.; Jiménez, P.A.; Lee, J.A.; Kosovi´c,\
    \ B. Principles of meteorology and numerical weather prediction. In Renewable\
    \ Energy\nForecasting; Elsevier: Amsterdam, The Netherlands, 2017; pp. 3–28. [CrossRef]\n\
    37.\nDing, W.; Wang, J.; Rizos, C.; Kinlyside, D. Improving Adaptive Kalman Estimation\
    \ in GPS/INS Integration. J. Navig. 2007,\n60, 517–529. [CrossRef]\n38.\nLi, Q.;\
    \ Li, R.; Ji, K.; Dai, W. Kalman Filter and Its Application. In Proceedings of\
    \ the 2015 8th International Conference on\nIntelligent Networks and Intelligent\
    \ Systems (ICINIS), Tianjin, China, 1–3 November 2015; pp. 74–77. [CrossRef]\n\
    39.\nHamouda, Y.E.M.; Msallam, M.M. Smart heterogeneous precision agriculture\
    \ using wireless sensor network based on extended\nKalman ﬁlter. Neural Comput.\
    \ Appl. 2019, 31, 5653–5669. [CrossRef]\n40.\nLai, X.; Yang, T.; Wang, Z.; Chen,\
    \ P. IoT Implementation of Kalman Filter to Improve Accuracy of Air Quality Monitoring\
    \ and\nPrediction. Appl. Sci. 2019, 9, 1831. [CrossRef]\n41.\nAbioye, E.A.; Abidin,\
    \ M.S.Z.; Mahmud, M.S.A.; Buyamin, S.; Ijike, O.D.; Otuoze, A.O.; Aﬁs, A.A.; Olajide,\
    \ O.M. A data-driven\nKalman ﬁlter-PID controller for ﬁbrous capillary irrigation.\
    \ Smart Agric. Technol. 2023, 3, 100085. [CrossRef]\n42.\nFasbender, D.; Obsomer,\
    \ V.; Radoux, J.; Bogaert, P.; Defourny, P. Bayesian data fusion: Spatial and\
    \ temporal applications. In\nProceedings of the MultiTemp 2007-2007 International\
    \ Workshop on the Analysis of Multi-Temporal Remote Sensing Images,\nLeuven, Belgium,\
    \ 18–20 July 2007. [CrossRef]\n43.\nRazaﬁmandimby, C.; Loscri, V.; Vegni, A.M.;\
    \ Neri, A. Efﬁcient Bayesian Communication Approach for Smart Agriculture\nApplications.\
    \ In Proceedings of the 2017 IEEE 86th Vehicular Technology Conference (VTC-Fall),\
    \ Toronto, ON, Canada, 24–27\nSeptember 2017; pp. 1–5. [CrossRef]\n44.\nGevaert,\
    \ C.M.; Suomalainen, J.; Tang, J.; Kooistra, L. Generation of Spectral–Temporal\
    \ Response Surfaces by Combining\nMultispectral Satellite and Hyperspectral UAV\
    \ Imagery for Precision Agriculture Applications. IEEE J. Sel. Top. Appl. Earth\
    \ Obs.\nRemote Sens. 2015, 8, 3140–3146. [CrossRef]\n45.\nGoodridge, S.G.; Kay,\
    \ M.G.; Luo, R.C. Multilayered fuzzy behavior fusion for real-time reactive control\
    \ of systems with multiple\nsensors. IEEE Trans. Ind. Electron. 1996, 43, 387–394.\
    \ [CrossRef]\nSensors 2023, 23, 5993\n18 of 18\n46.\nÇeven, S.; Albayrak, A.;\
    \ Bayır, R. Real-time range estimation in electric vehicles using fuzzy logic\
    \ classiﬁer. Comput. Electr. Eng.\n2020, 83, 106577. [CrossRef]\n47.\nVlamou,\
    \ E.; Papadopoulos, B. Fuzzy logic systems and medical applications. AIMS neuroscience.\
    \ Aims Neurosci. 2019, 6, 266.\n[CrossRef]\n48.\nManjunatha, P.; Verma, A.; Srividya,\
    \ A. Multi-Sensor Data Fusion in Cluster based Wireless Sensor Networks Using\
    \ Fuzzy\nLogic Method. In Proceedings of the 2008 IEEE Region 10 and the Third\
    \ International Conference on Industrial and Information\nSystems, Kharagpur,\
    \ India, 8–10 December 2008; pp. 1–6. [CrossRef]\n49.\nYang, G.; Tian, G.Y.; Que,\
    \ P.W.; Li, Y. Data fusion algorithm for pulsed eddy current detection. Iet. Sci.\
    \ Meas. Technol. 2007, 1,\n312–316. [CrossRef]\n50.\nButakoff, C.; Frangi, A.F.\
    \ A framework for weighted fusion of multiple statistical models of shape and\
    \ appearance. IEEE Trans.\nPattern Anal. Mach. Intell. 2006, 28, 1847–1857. [CrossRef]\n\
    51.\nDaye, Z.J.; Jeng, X.J. Shrinkage and model selection with correlated variables\
    \ via weighted fusion. Comput. Stat. Data Anal. 2009,\n53, 1284–1298. [CrossRef]\n\
    52.\nLi, D.; Shen, C.; Dai, X.; Zhu, X.; Luo, J.; Li, X.; Chen, H.; Liang, Z.\
    \ Research on Data Fusion of Adaptive Weighted Multi-source\nSensor. Comput. Mater.\
    \ Contin. 2019, 61, 1217–1231. [CrossRef]\n53.\nLiu, H.; Fang, S.; Jianhua, J.\
    \ An improved weighted fusion algorithm of multi-sensor. J. Phys. Conf. Ser. 2020,\
    \ 1453, 012009.\n[CrossRef]\n54.\nWelch, G.F. Kalman Filter. In Computer Vision;\
    \ Springer International Publishing: Cham, Switzerland, 2021; pp. 1–3. [CrossRef]\n\
    55.\nDe Vito, S.; Massera, E.; Piga, M.; Martinotto, L.; Di Francia, G. On ﬁeld\
    \ calibration of an electronic nose for benzene estimation in\nan urban pollution\
    \ monitoring scenario. Sens. Actuator Chem. 2008, 129, 750–757. [CrossRef]\n56.\n\
    Akatsuka, H.; Terada, M. Application of Kalman Filter to Large-Scale Geospatial\
    \ Data. Acm Trans. Spat. Algorithms Syst. 2022, 9,\n1–29. [CrossRef]\n57.\nXu,\
    \ Y.; Lu, Y. Adaptive weighted fusion: A novel fusion approach for image classiﬁcation.\
    \ Neurocomputing 2015, 168, 566–574.\n[CrossRef]\n58.\nEscamilla-Ambrosio, P.;\
    \ Mort, N. Multi-sensor data fusion architecture based on adaptive Kalman ﬁlters\
    \ and fuzzy logic\nperformance assessment. In Proceedings of the Fifth International\
    \ Conference on Information Fusion, FUSION 2002 (IEEE\nCat.No.02EX5997), Annapolis,\
    \ MD, USA, 8–11 July 2002; pp. 1542–1549.\nDisclaimer/Publisher’s Note: The statements,\
    \ opinions and data contained in all publications are solely those of the individual\n\
    author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or\
    \ the editor(s) disclaim responsibility for any injury to\npeople or property\
    \ resulting from any ideas, methods, instructions or products referred to in the\
    \ content.\n"
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/23/13/5993/pdf?version=1687935166
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: IoT Data Quality Assessment Framework Using Adaptive Weighted Estimation
    Fusion
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.31428/10317/10416
  analysis: '>'
  authors:
  - Marouane Salhaoui
  citation_count: 0
  full_citation: '>'
  full_text: ">\n \n  \n \nvrbvnjnnbbttbbtbt  \n\"SMART IOT MONITORING AND REAL-TIME\
    \ CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL \nRECOGNITION AND CLOUD/EDGE COMPUTING\
    \ \nSERVICES\" \n \nPrograma de Doctorado: ENERGÍAS RENOVABLES Y \nEFICIENCIA\
    \ ENERGÉTICA \n \n \n \n \nAutor: Marouane Salhaoui \n \nCartagena (2021) \n \n\
    i \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \n \n \n \n \n \n\
    \ \n \n \nABDELMALEK ESSAADI UNIVERSITY \nFACULTY OF SCIENCE AND TECHNIQUES \n\
    TANGER / MOROCCO \n \nPOLYTECHNIC UNIVERSITY OF CARTAGENA \nUPCT / SPAIN \n \n\
    \ \nDOCTORAL THESIS (Year 2021) \n \nPresented By: \n \nMAROUANE SALHAOUI \n \n\
    Directors:  \n \nAntonio Guerrero-González, Mounir Arioua  \n \nCo-Directors:\
    \ \n \nFrancisco J. Ortiz, Ahmed El Oualkadi \n \nThesis Title: \n \n\"SMART IOT\
    \ MONITORING AND REAL-TIME CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL RECOGNITION\
    \ \nAND CLOUD/EDGE COMPUTING SERVICES\" \n \n \nAccredited research institution:\
    \ \n \n• Laboratoire des Technologies de l’Information et de la Communication\
    \ de ENSA de \nTanger (Morocco) \n• Departamento de Automática, Ingeniería Eléctrica\
    \ y Tecnología Electrónica, UPCT \nCartagena (Spain) \n \nii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nAbstract \n \nIn the fourth industrial revolution\
    \ in which we are immersed, new \ntechnologies are being introduced in production\
    \ processes, such as the use of \nUnmanned Vehicles (UVs) data collection in large\
    \ surfaces, and the use of the \nIndustrial Internet of Things (IIoT). The main\
    \ keys to integrate this new \ntechnology in the industry is to face the challenge\
    \ of making the IT network \ncompatible with its machines, including interoperability,\
    \ fog and cloud \ncomputing, security, decreasing latency and improving data accuracy\
    \ and \nquality of service. \nSmart industrial platforms require multiple synchronized\
    \ processes that \nrequire low latency and higher reliability to achieve the necessary\
    \ performance. \nIn addition, Artificial Intelligence (AI) methods applied to\
    \ IIoT must be able to \naddress these issues as well as other parameters such\
    \ as network deployment \nand resource management. \nThe issues of high-latency\
    \ and unreliable links between the cloud and \nIndustrial IoT endpoints are significant\
    \ challenges. Each fog and edge application \nmay have different latency requirements\
    \ and may generate different types of \ndata and network traffic.  Such generated\
    \ data can be photos received from an \nUV system. The latter can be connected\
    \ to other control system, being used both \nto perform enhancements and to make\
    \ decisions based on the captured photos. \nThis type of connection is sensitive\
    \ in terms of accuracy and latency, as the whole \nplatform must decide quickly\
    \ and with certainty. \nOne of the solutions to overcome the latency challenge\
    \ is the fog/edge \narchitecture. This architecture can also be a viable solution\
    \ regarding the \ninteroperability barrier between interconnected systems. Fog\
    \ computing extends \ncomputation and storage to the edge of the network and presents\
    \ an effective tool \nfor integrating new complex interconnected processing systems.\
    \   \nThe constraint of interoperability can be overcome by adopting advanced\
    \ \nsoftware deployed in the edge and fog installed in an IoT gateway. This software\
    \ \ninteracts simultaneously with the different systems involved through different\
    \ \nprotocols. However, the choice of an IoT gateway is crucial in terms of latency\
    \ \nand accuracy, as it is at the heart of processing and transmitting data to\
    \ the \ndifferent systems and platforms and considered the interface of junction\
    \ between \nthe physical level and cloud. The latter also affects performance\
    \ as it must ensure \nthat data is transferred, processed and returned at speeds\
    \ that meet the needs of \nthe application. \n \niii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nWe address all these challenges by considering appropriate\
    \ protocols and \nsoftware for interoperability and connectivity constraints and\
    \ we discuss the \nperformance some appropriate IoT devices capable of providing\
    \ minimal \nresponse time. \nDeep Learning (DL) services can be deployed near\
    \ requesting users and the \ncloud only intervenes when additional processing\
    \ is required, significantly \nreducing the latency and cost of sending data to\
    \ the cloud for processing. In this \nthesis, we propose novel approaches to solve\
    \ the latency issue by deploying \nintelligence at the edge that pushes DL computations\
    \ from the cloud to the edge \nenabling various distributed, low-latency and reliable\
    \ intelligent services. \nThe main benefit of the proposed approaches is the integration\
    \ of cloud \nservices into a control loop to improve a platform’s decision making\
    \ and the \nperformance of an industrial control system. Cloud AI services are\
    \ also \nintegrated into a drone control loop as an input that helps improve the\
    \ \nmonitoring capability to find and track stationary and mobile objects. \n\
    In this work, we evaluate the latency and accuracy of different systems \ninvolved\
    \ and we propose an intelligent algorithm to select the appropriate AI \ntechnology\
    \ for the scenario to be monitored. This proved to be crucial in deciding \nthe\
    \ best source of artificial intelligence to be used to achieve the specified goals\
    \ \nat each stage in real time. The proposed intelligent algorithms offer a compromise\
    \ \nbetween latency and accuracy. \n \n \n \niv \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nResumen \n \nEn la cuarta revolución industrial en\
    \ la que estamos inmersos, se están \nintroduciendo nuevas tecnologías en los\
    \ procesos productivos, como el uso de \nvehículos autónomos (UVs) para recogida\
    \ de datos en grandes superficies y el \nuso del Internet Industrial de las Cosas\
    \ (IIoT). Las principales claves para integrar \nesta nueva tecnología en la industria\
    \ es afrontar el reto de compatibilizar la red \ninformática con sus máquinas,\
    \ incluyendo la interoperabilidad, computación en \nla niebla/nube/borde (fog/cloud/edge\
    \ computing), la seguridad, la disminución \nde la latencia y la mejora de la\
    \ precisión de los datos y la calidad del servicio. \nLas plataformas industriales\
    \ inteligentes requieren múltiples procesos \nsincronizados que exigen una baja\
    \ latencia y una mayor fiabilidad para lograr el \nrendimiento necesario. Además,\
    \ los métodos de Inteligencia Artificial (IA) \naplicados a la IIoT deben ser\
    \ capaces de abordar estas cuestiones, así como otros \nparámetros como el despliegue\
    \ de la red y la gestión de recursos. \nLos problemas de alta latencia y enlaces\
    \ poco fiables entre la nube y los \npuntos finales del IoT industrial son retos\
    \ importantes. Cada aplicación de niebla \ny borde puede tener diferentes requisitos\
    \ de latencia y puede generar diferentes \ntipos de datos y tráfico de red.  Estos\
    \ datos generados pueden ser imágenes \nrecibidas de un sistema UV, por ejemplo.\
    \ Este sistema puede a su vez conectarse \na otro sistema de control, utilizándose\
    \ tanto para realizar mejoras en el proceso \ncomo para tomar decisiones basadas\
    \ en las imágenes capturadas. Este tipo de \nconexión es sensible en términos\
    \ de precisión y latencia, ya que toda la \nplataforma debe decidir con rapidez\
    \ y seguridad. \nUna de las soluciones para superar el reto de la latencia es\
    \ la arquitectura \nbasada en la niebla/borde (fog/edge). Esta arquitectura también\
    \ puede ser una \nsolución viable en cuanto a la barrera de interoperabilidad\
    \ entre los sistemas \ninterconectados. La computación en la niebla extiende la\
    \ computación y el \nalmacenamiento al borde de la red y presenta una herramienta\
    \ eficaz para \nintegrar nuevos sistemas complejos de procesamiento interconectados.\
    \   \nLa limitación de la interoperabilidad puede superarse adoptando un \nsoftware\
    \ avanzado desplegado en el borde y la niebla instalado en una pasarela \nde IoT.\
    \ Este software interactúa simultáneamente con los distintos sistemas \nimplicados\
    \ a través de diferentes protocolos. Sin embargo, la elección de una \npasarela\
    \ IoT es crucial en términos de latencia y precisión, ya que está en el centro\
    \ \ndel procesamiento y la transmisión de datos a los diferentes sistemas y \n\
    plataformas y se considera la interfaz de unión entre el nivel físico y la nube.\
    \ Esta \núltima también afecta al rendimiento, ya que debe garantizar que los\
    \ datos se \n \nv \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ntransfieran,\
    \ procesen y devuelvan a velocidades que satisfagan las necesidades \nde la aplicación.\
    \ \nAbordamos todos estos retos teniendo en cuenta los protocolos y el software\
    \ \napropiados para la interoperabilidad y las restricciones de conectividad,\
    \ y \nanalizamos el rendimiento de algunos dispositivos IoT apropiados capaces\
    \ de \nproporcionar un tiempo de respuesta mínimo. \nLos servicios de Deep Learning\
    \ (DL) pueden desplegarse cerca de los \nusuarios que los solicitan y la nube\
    \ solo interviene cuando se requiere un \nprocesamiento adicional, reduciendo\
    \ significativamente la latencia y el coste de \nenviar los datos a la nube para\
    \ su procesamiento. En esta tesis, proponemos \nenfoques novedosos para resolver\
    \ el problema de la latencia mediante el \ndespliegue de inteligencia en el borde\
    \ que empuja los cálculos de DL desde la \nnube hasta el borde permitiendo varios\
    \ servicios inteligentes distribuidos, de \nbaja latencia y fiables. \nLa principal\
    \ ventaja de los enfoques propuestos es la integración de los \nservicios en la\
    \ nube en un lazo de control para mejorar la toma de decisiones de \nuna plataforma\
    \ y el rendimiento de un sistema de control industrial. Los servicios \nde IA\
    \ en la nube también se integran en un lazo de control donde interviene un \n\
    dron como una entrada que ayuda a mejorar la capacidad de monitorización para\
    \ \nencontrar y rastrear objetos estacionarios y móviles. \nEn este trabajo, evaluamos\
    \ la latencia y la precisión de los diferentes sistemas \nimplicados y proponemos\
    \ un algoritmo inteligente para seleccionar la tecnología \nde IA adecuada para\
    \ el escenario a vigilar. Esto resulta crucial para decidir cuál \nes la mejor\
    \ fuente de inteligencia artificial que debe utilizarse para alcanzar los \nobjetivos\
    \ especificados en cada escenario en tiempo real. Los algoritmos \ninteligentes\
    \ propuestos ofrecen un compromiso entre latencia y precisión. \n \n \n \nvi \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n صخلملا \n \n \n يفعمج\
    \ مادختسا لثم ، جاتنلإا تايلمع يف ةديدج تاينقت لاخدإ متي ، اهيف كراشن يتلا ةعبارلا\
    \ ةيعانصلا ةروثلا \nةيسيئرلا حيتافملا لثمتت .ءايشلأل يعانصلا تنرتنلإا مادختساو\
    \ ، ةعساو قطانم يف ةلوهأملا ريغ تابكرملا تانايب \n ةهجاوم يف ةعانصلا يف ةديدجلا\
    \ ايجولونكتلا هذه جمدلةقفاوتم تامولعملا ايجولونكت ةكبش لعج يف لثمتملا يدحتلا \n\
    ينمزلا ريخأتلا ليلقتو نملأاو ةيباحسلاو ةيبابضلا ةبسوحلاو يليغشتلا قفاوتلا ةيناكمإ\
    \ كلذ يف امب ، اهتزهجأ عم \nةمدخلا ةدوجو تانايبلا ةقد نيسحتو )نومكلا(  \n \nةددعتم\
    \ ةنمازتم تايلمع ةيكذلا ةيعانصلا تاصنملا بلطتتىلعأ ةيقوثومو ضفخنم ينمزريخأت بجوتست\
    \ يتلاو ، \nءايشلأا تنرتنإ ىلع ةقبطملا يعانطصلاا ءاكذلا بيلاسأ نوكت نأ بجي ، كلذ\
    \ ىلإ ةفاضلإاب .مزلالا ءادلأا قيقحتل \nدراوملا ةرادإو ةكبشلا تيبثت لثم ىرخأ تاملعم\
    \ ىلإ ةفاضلإاب تلاكشملا هذه ةجلاعم ىلع ةرداق  \n   \nاورلا تلاكشم دعتءايشلأا تنرتنإو\
    \ ةيباحسلا ةياهنلا طاقن نيب يلاع ينمزريخأت تاذ و اهب قوثوملاريغ طب \nعاونأ هنع\
    \ جتني دقو ةفلتخم نومك تابلطتم ةفاحلاو بابضلا تاقيبطت نم قيبطت لكل نوكي دق .ريبك\
    \ يدحت ةيعانصلا \nيتلا تانايبلا هذه نوكت نأ نكمي .تاكبشلا ربع ةلوادتملا تانايبلا\
    \ نم ةفلتخم نم ةملتسملا روصلا نم اهؤاشنإ مت \nتانيسحت ءارجلإ همادختسا متي ثيح\
    \ ، رخآ مكحت ماظنب ريخلأا اذه ليصوت نكمي .ةلوهأملا ريغ تابكرملا ماظن \nبجي ثيح\
    \ ، نومكلاو ةقدلا ثيح نم ساسح لاصتلاا نم عونلا اذه .ةطقتلملا روصلا ىلع ًءانب تارارقلا\
    \ ذاختلاو \nفنملا يساسلأا ماظنلا ىلعدكؤم لكشبو ةعرسب ررقي نأ هلمكأب ذ  \n \nيف\
    \ ةتبثم ، بابضلاو ةفاحلا يف ةرشتنم ةمدقتم جمارب دامتعا للاخ نم يليغشتلا قفاوتلا\
    \ دويق ىلع بلغتلا نكمي \nتلاوكوتورب للاخ نم ةكراشملا ةفلتخملا ةمظنلأا عم نمازتم\
    \ لكشب جمانربلا اذه لعافتي .ءايشلأا تنرتنإ ةباوب \n كلذ عمو .ةفلتخمإف ،اهنإ ثيح\
    \ ، ةقدلاو ينمزلاريخأتلاب قلعتي اميف ةيمهلأا غلاب رمأ ءايشلأا تنرتنإ ةباوب رايتخا\
    \ ن \nةقبطلا( ةيداملا ةقبطلا نيب عطاقتلا ةهجاو ربتعت يتلاو ، ةفلتخملا ىنبلاو ةمظنلأا\
    \ ىلإ اهلقنو تانايبلا ةجلاعم بلق \nباحسلاو )يرايعملا لاصتلاا جذومن يف ةقبط ىندأ،ىلولأانمضت\
    \ نأ بجي هنلأ ءادلأا ىلع اًضيأ ةريخلأا هذه رثأت .ة \n قيبطتلا تاجايتحا يبلت تاعرسب\
    \ اهتداعإو اهتجلاعمو تانايبلا لقن \n \nلاصتلاا دويقو يليغشتلا قفاوتلل ةبسانملا\
    \ جماربلاو تلاوكوتوربلا يف رظنلا للاخ نم تايدحتلا هذه لك عم لماعتن  \nيشلأا تنرتنإ\
    \ ةزهجأ ضعب ءادأ شقاننوينمزلا ريخأتلا نم ىندلأا دحلا ريفوت ىلع ةرداقلا ةبسانملا\
    \ ءا  \n \nىلإ ةجاحلا دنع لاإ ةباحسلا لخدتت لاو ، ةبولطملا نيمدختسملا ةمظنأ نم\
    \ برقلاب قيمعلا ملعتلا تامدخ رشن نكمي \nملل ةباحسلا ىلإ تانايبلا لاسرإ ةفلكتو\
    \ ينمزلا ريخأتلا نم ريبك لكشب للقي امم ، ةيفاضإ ةجلاعمهذه يف .ةجلاع \nتاباسح عفدت\
    \ يتلا ةفاحلا ىلع ءاكذلا رشن للاخ نم ينمزلا ريخأتلا ةلكشم لحل ةديدج بيلاسأ حرتقن\
    \ ، ةحورطلأا \nضفخنم ينمز ريخأت تاذو ةعزومو ةقوثومو ةعونتم ةيكذ تامدخ حيتي امم\
    \ ةفاحلا ىلإ ةباحسلا نم قيمعلا ملعتلا  \n \n ةحرتقملا قرطلل ةيسيئرلا ةدئافلا لثمتتيف\
    \ رارقلا عنص ةيلمع نيسحتل مكحتلا ةقلح يف ةيباحسلا تامدخلا جمد يف \nكذلا تامدخ\
    \ جمد اًضيأ متي .يعانصلا مكحتلا ماظن ءادأو يساسلأا ماظنلايف مكحتلا ةقلح يف ةيباحسلا\
    \ يعانطصلاا ءا \nةتباثلا ءايشلأا ىلع روثعلل ةبقارملا ةردق نيسحت ىلع دعاسي لخدمك\
    \ ةلوهأملا ريغ تابكرملا اهعبتتو ةكرحتملاو  \n  \nءاكذلا ةينقت ديدحتل ةيكذ ةيمزراوخ\
    \ حرتقنو ةينعملا ةفلتخملا ةمظنلأا ةقدو ينمزلا ريخأتلا مييقتب موقن ، لمعلا اذه\
    \ يف \nيعانطصلاا ءاكذلل ردصم لضفأ ديدحت يف مساح رمأ اذه نأ تبث .هتبقارم دارملا\
    \ ويرانيسلل ةبسانملا يعانطصلاا \nلأا قيقحتل همادختسلااطسو لاح ةحرتقملا ةيكذلا\
    \ تايمزراوخلا مدقت .يلعفلا تقولا يف ةلحرم لك يف ةبولطملا فاده \nةقدلاو نومكلا\
    \ نيب  \n \n \n \nvii \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \nList of Acronyms  \nAI Artificial Intelligence  \nAIS Automatic Identification\
    \ System \nANN Artificial Neural Network  \nAPI Application programming interfaces\
    \ \nASV Autonomous Surface Vehicle \nAUV Autonomous Underwater Vehicle \nCAN Controller\
    \ area network \nCCM Cloud custom model \nCGM Cloud General Model \nCoAP Constrained\
    \ Application Protocol \nCPS cyber-physical systems \nCPU Central processing unit\
    \  \nCSMA/CD with NDBA Carrier Sense Multiple Access / Collision Detection \n\
    with Non-Destructive Bitwise Arbitration \nCV Computer vision \nDAyRA División\
    \ de Automatización y Robótica Autónoma \nDNNs Deep Neural Networks \nDP Deep\
    \ Learning \nDPM Dynamic Position Mode  \nDVL Doppler Velocity Logger \n \nviii\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nECM Edge custom model\
    \ \nEI Edge Intelligence  \nERP enterprise resource planning \nFN False Negative\
    \ \nFP False Positive \nGPS Global Positioning System \nGPU Graphics Processing\
    \ Unit \nHD High-definition \nHVAC Heating, Ventilating, and Air Conditioning\
    \ \nIaaS Infrastructure-as-a-Service  \nIETF The Internet of Engineering Task\
    \ \nILSVRC ImageNet Large Scale Visual Recognition Challenge \nIM Inspection Mode\
    \  \nIMARS IBM multimedia analysis and retrieval system \nIoS Internet of services\
    \ \nIoT Internet of things \nIoU Intersection on union \nIPM Image Processing\
    \ Algorithm \nIUCN International Union for the Conservation of Nature \nIUNO Interface\
    \ for Unmanned Drones \nM2M machine-to-machine \nMASS Maritime Autonomous Surface\
    \ Ships  \nMES manufacturing execution systems \n \nix \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nML Machine Learning  \nMLaaS Machine Learning as a service\
    \  \nMMM Main Mission Mode \nMPA Marine Protected Area \nMQTT The Message Queuing\
    \ Telemetry Transport \nND Not detected \nNFC Near Field Communication  \nNIC\
    \ network interface controller  \nOPC UA Open Platform Communications Unified\
    \ Architecture  \nOWD One-way delay \nPaaS Platform as-a-Service \nPC-G PC Gateway\
    \ \nPID Proportional–Integral–Derivative \nPV Process Variables \nQoS Quality\
    \ of Service  \nRFID Radio frequency identification  \nRPI-G Raspberry PI Gateway\
    \ \nRTD Round-trip delay time \nS-G Siemens Gateway \nSAAO Smart algorithm for\
    \ autonomy optimization \nSaaS Software-as-a-Service \nSAR Synthetic Aperture\
    \ Radar \nSHDL ScatterNet hybrid deep learning \n \nx \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nSISO single-input–single-output \nSOA Service-oriented\
    \ architecture \nSP Set Points \nSVM Support vector machine \nTAS Time-aware scheduler\
    \  \nTM Tracking Mode  \nTP True Positive \nTSN Time sensitive networking \nUAV\
    \ Unmanned Autonomous Vehicle \nUVs Unmanned vehicles \nVPL Visual Programming\
    \ Language  \nWFQ weighted fair queuing \nWSN Wireless Sensor Network  \nWVR Watson\
    \ Visual Recognition \n \n \n \nxi \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nList of Publications  \nThe work presented in this thesis has appeared\
    \ in the articles reported below.  \nJournal papers:  \n(J1) Salhaoui Marouane;\
    \ Guerrero-González Antonio; Arioua Mounir; Ortiz, \nFrancisco J.; El Oualkadi\
    \ Ahmed; Torregrosa Carlos L. 2019. \"Smart Industrial IoT \nMonitoring and Control\
    \ System Based on UAV and Cloud Computing Applied to \na Concrete Plant\" Sensors\
    \ 19, no. 15: 3316. https://doi.org/10.3390/s19153316  \n \n(J2) Salhaoui Marouane;\
    \ Molina-Molina J. C.; Guerrero-González Antonio; Arioua \nMounir; Ortiz Francisco\
    \ J. 2020. \"Autonomous Underwater Monitoring System for \nDetecting Life on the\
    \ Seabed by Means of Computer Vision Cloud Services\" \nRemote Sens. 12, no. 12:\
    \ 1981. https://doi.org/10.3390/rs12121981  \n \n(J3) Molina-Molina J. C.; Salhaoui\
    \ Marouane; Guerrero-González, Antonio; Arioua, \nMounir. 2021. \"Autonomous Marine\
    \ Robot Based on AI Recognition for \nPermanent Surveillance in Marine Protected\
    \ Areas\" Sensors 21, no. 8: 2664. \nhttps://doi.org/10.3390/s21082664  \n \n\
    (J4) Benbarrad, Tajeddine; Salhaoui Marouane; Kenitar Soukaina B.; Arioua \nMounir.\
    \ 2021. \"Intelligent Machine Vision Model for Defective Product Inspection \n\
    Based \non \nMachine \nLearning\" J. \nSens. \nActuator \nNetw. 10, \nno. \n1:\
    \ \n7. \nhttps://doi.org/10.3390/jsan10010007  \n \nInternational conference papers:\
    \  \n(C1) Marouane Salhaoui, Mounir Arioua, Otman Chakkor, and Jihane Elaasri.\
    \ 2017. \nPerformance Evaluation Survey of WSN Physical Layer. In Proceedings\
    \ of the 2nd \nInternational Conference on Computing and Wireless Communication\
    \ Systems \n(ICCWCS'17). Association for Computing Machinery, New York, NY, USA,\
    \ Article \n68, 1–5. DOI: https://doi.org/10.1145/3167486.3167557 \n \n(C2) Marouane\
    \ Salhaoui, Mounir Arioua, Antonio Guerrero-González, María \nSocorro García-Cascales,\
    \ \"An IoT Control System for Wind Power Generators\", \n17th International Conference,\
    \ IPMU, Published in Information Processing and \nManagement of Uncertainty in\
    \ Knowledge-Based Systems. Applications, \nSpringer, Cádiz, Spain, 2018. https://doi.org/10.1007/978-3-319-91479-4_39\
    \ \n \nxii \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n(C3) Soukaina\
    \ Bakhat Kenitar, Salhaoui Marouane, Arioua Mounir, Ali Younes, and \nA. Guerrero\
    \ Gonzalez. 2018. Evaluation of the MQTT Protocol Latency over \nDifferent Gateways.\
    \ In Proceedings of the 3rd International Conference on Smart \nCity Applications\
    \ (SCA '18). Association for Computing Machinery, New York, NY, \nUSA, Article\
    \ 87, 1–5. DOI: https://doi.org/10.1145/3286606.3286864   \n \n(C4) Soukaina B.K.,\
    \ Ali Y., Mounir A., Marouane Salhaoui. (2019) Latency \nAssessment of MQTT Protocol\
    \ in Transferring Data from the Field to the Cloud \nOver Different Gateways.\
    \ In: Ben Ahmed M., Boudhir A., Younes A. (eds) \nInnovations in Smart Cities\
    \ Applications Edition 2. SCA 2018. Lecture Notes in \nIntelligent \nTransportation\
    \ \nand \nInfrastructure. \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-11196-0_71\
    \  \n \n(C5) S. B. Kenitar, M. Arioua, A. Younes, M. Radi and Marouane Salhaoui,\
    \ \n\"Comparative Analysis of Energy Efficiency and Latency of Fog and Cloud \n\
    Architectures,\" 2019 International Conference on Sensing and Instrumentation\
    \ in \nIoT Era (ISSI), 2019, pp. 1-5, doi: 10.1109/ISSI47111.2019.9043738. \n\
    \ \n(C6) Yassine Yazid, Imad Ez-zazi, Marouane Salhaoui, Mounir Arioua, El Oualkadi\
    \ \nAhmed, Antonio Guerrero González. Extensive Analysis of Clustered Routing\
    \ \nProtocols For Heteregeneous Sensor Networks. Third International Conference\
    \ on \nComputing and Wireless Communication Systems, ICCWCS 2019, April 24-25,\
    \ \n2019, \nFaculty \nof \nSciences, \nIbn \nTofaïl \nUniversity \n-Kénitra- \n\
    Morocco. \nhttp://dx.doi.org/10.4108/eai.24-4-2019.2284208 \n \n(C7) Marouane\
    \ Salhaoui, Molina-Molina, J. C, A. Guerrero-González, Antonio; \nArioua, Mounir;\
    \ Ortiz, Francisco J.; El Oualkadi, Ahmed. Edge-Cloud Architectures \nUsing UAVs\
    \ Dedicated To Industrial IoT Monitoring And Control Applications. \nIEEE- International\
    \ Symposium on Advanced Electrical and Communication \nTechnologies ISAECT2020,\
    \ November 25th-27th, 2020 Ibn Tofail University, \nMorocco \n \n(C8) Benbarrad\
    \ Tajeddine; Salhaoui Marouane; Arioua Mounir. Impact of Standard \nImage Compression\
    \ on the Performance of Image Classification with Deep \nLearning. ICDATA21 (International\
    \ Conference on Digital Age & Technological \nAdvances for sustainable development),\
    \ 2021. 29 - 30 June 2021 Marrakech, \nMorocco. \n \n \n \nxiii \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \nContents  \n \n \nAbstract  \n\
    \ \nResumen \n \n صخلملا \n \nList of Acronyms  \n \nList of Publications  \n\
    \ \n1. Introduction   \n \n1.1 \nBackground \n \n1.1.1 Applications  \n1.1.2 IoT\
    \ Monitoring and Control \n1.1.3. Advantages of Using AI in the cloud \n1.1.4.\
    \ Constraints \n \n1.2 \nMotivation \n \n1.3 \nObjectives and contributions  \n\
    \ \n1.4 \nThesis organization  \n \n2. Performance analysis of IoT Monitoring\
    \ and Control System Based on \nUV, machine vision and artificial intelligence\
    \   \n \n2.1 \nIntroduction  \n \n2.2 \nUV IoT architecture  \n2.2.1. Most Common\
    \ IoT Architectures \n2.2.2. IoT Monitoring and Control Architecture Based on\
    \ Unmanned \nVehicles \n2.2.3 IoT Gateway Capabilities \n \nxiv \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n2.3 \nUV & IoT Protocols \n \n2.3.1\
    \ UV Protocols \n2.3.2 IoT Protocols \n2.3.3 Industrial protocols \n2.3.4 OPC\
    \ UA protocol \n \n \n3. Performance and latency assessment using AI for UV  \
    \ \n \n3.1. Introduction  \n \n3.2. Related works \n \n3.3. Artificial Intelligence\
    \ and Machine Vision \n3.3.1 Artificial Intelligence \n \n3.3.1.2 Inference Versus\
    \ Training \n3.3.1.3 Methods of Machine Learning \n3.3.1.4 Convolutional Neural\
    \ Network for Object Recognition \n \n3.4. Cloud-Edge DL \n \n3.4.1 Cloud AI at\
    \ the edge \n3.4.2 Evaluating performance of an object detection model \n \n3.5.\
    \ Latency Assessment  \n \n3.5.1 Latency between Two Terminals \n3.5.2 OPC UA\
    \ Architecture and delay assessment \n3.5.3 UAV System Delay \n \n4. Energy Efficiency\
    \ and Latency of Smart IoT Monitoring and Control \nSystems Based on cloud Computing\
    \ and Intelligent Machine Vision \n \n4.1 Smart Industrial IoT Monitoring and\
    \ Control Systems Based on cloud \nComputing and Intelligent Machine Vision \n\
    \ \n4.2 Autonomous Underwater Monitoring System for Detecting Life on the Seabed\
    \ \nby Means of Computer Vision Cloud Services \n \nxv \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n4.3 Autonomous Marine Robot Based on AI Recognition\
    \ for Permanent \nSurveillance in Marine Protected Areas \n \n4.4 An IoT Control\
    \ System for Wind Power Generators \n \n5. Conclusions and future work  \n \n\
    5.1 Contributions summary  \n5.2 Future Works  \n \nBibliography  \n \n \nxvi\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nList of Tables \
    \ \n \n \nTable 2.1. Main protocols used in the IoT field \nTable 2.2. Comparison\
    \ of Internet of Things (IoT) protocols \nTable 4.1. Confusion matrix. \nTable\
    \ 4.2. Specification of each machine environment. \nTable 4.3. RTD test of 5200\
    \ samples from the OPC UA client to the OPC UA server (PLC) \nover different clients\
    \ through different machines. \nTable 4.4. RTD Test of 200 photos sent from the\
    \ IoT gateway to the AR.Drone 2.0. \nTable 4.5. RTD test of 100 samples from the\
    \ IoT gateway to IBM Watson over different \nmachines.  \nTable 4.6. Speed Test\
    \ over the three gateways (S-G, RPI-G, PC-G). \nTable 4.7. GPS coordinates of\
    \ the area explored. \nTable 4.8. Accuracy measurement in different platforms.\
    \ \nTable 4.9. Latency measurement in different platforms. \nTable 4.10. Definition\
    \ of mission stages. \nTable 4.11. AI source preferences according to mission\
    \ stage. \nTable 4.12. RTD test of 300 samples of the Edge and Cloud model. \n\
    Table 4.13. Experimental SAAO results \nTable 4.14. Summary of SAAO logs during\
    \ the experiment \n \n \n \nxvii \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nList of Figures \n  \n \nFigure 1.1. A three-layer IoT architecture based\
    \ on: Device, Edge and Cloud for \nPredictive Maintenance (PM) [8]. \nFigure 1.2\
    \ Major limitations of current IoT platforms \nFigure 1.3 Mapping of interoperability\
    \ levels to OSI layers \nFigure 1.4.  Automation Pyramid vs Automation Network\
    \ [43] \nFigure 1.5. Capabilities comparison of cloud, on-device and edge intelligence\
    \ [40] \nFigure 2.1. Most common IoT architectures \nFigure 2.2. UV-IoT Architecture\
    \ \nFigure 2.3. Wiring diagrams in vehicles before and after the appearance of\
    \ CAN \nFigure 2.4. Controller area network bus node \nFigure 2.5. Node of the\
    \ CAN bus system \nFigure 2.6. Comparison of protocols for the exchange of messages:\
    \ (a) MQTT; (b) \nMODBUS TCP. \nFigure 2.7. The IEEE model (a); compared to the\
    \ HTTP (b); the CoAP (c); the MODBUS \nTCP (d); and the MQTT (e). \nFigure 2.8.\
    \ OPC UA in the automation pyramid \nFigure 2.9. Architecture of the OPC UA Server\
    \ \nFigure 3.1. Node-Red Platform \nFigure 3-2: Deep learning in the context of\
    \ artificial intelligence \nFigure 3-3. Connections to a neuron in the brain.\
    \ xi, wi, f (·), and b are the activations, \nweights, nonlinear function, and\
    \ bias, respectively \nFigure 3.4 Simple neural network example and terminology.\
    \ (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nFigure\
    \ 3.5. Training and inference comparison \nFigure 3.6. Six-level rating for edge\
    \ intelligence \nFigure 3.7. IoU equation, Red is ground truth bounding box and\
    \ green is predicted \nbounding box \nFigure 3.8. Latency between two terminals\
    \ in a network \nFigure 3.9. OPC UA delay in OPC UA client server in an Ethernet\
    \ network \nFigure 3.10 Video transmission system delay sources. \nFigure 4.1:\
    \ Proposed UAV-IIoT Platform \nFigure 4.2. Development design of autonomous IIoT\
    \ flight \nFigure 4.3. Node-RED flow in the IoT gateway including the path from\
    \ the PLCs to the \nUAV, from the UAV to IBM Watson, and from Watson to the control\
    \ center. \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \nFigure 4.5. AR.Drone 2.0 mission in the concrete plant. \nFigure\
    \ 4.6. Communication process in the fog layer. \nFigure 4.7. Path used by the\
    \ drone to execute the mission in a concrete plant. \nFigure 4.8. Dataset used\
    \ to train the custom model in WVR service: (a) Shows images \nused to train the\
    \ Mixed class; (b) Shows Images used to train the Normal class. \nFigure 4.9.\
    \ Watson visual recognition test of new images not used in the training phase.\
    \ \nFigure 4.10. Node-RED flow and WVR results of an UAV photo. \nFigure 4.11.\
    \ OPC UA delay in OPC UA client server in an Ethernet network. \n \nxviii \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.12. Node-RED flow\
    \ used to calculate round trip latency (OPC UA Client to the \nOPC UA Server).\
    \ \nFigure 4.13. OPC UA client-server RTD to read one bit through different machines.\
    \ \nFigure 4.14. (a) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the S-G; \n(b) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the RPI-G. \nFigure 4.15. Probability density function of the delay of the\
    \ drone connected to the \ngateway when successive pictures from PC-G and RPI-G\
    \ are taken. \nFigure 4.16. Probability density function of the delay of the drone\
    \ connected to the \ngateway when successive pictures from S-G are taken. \nFigure\
    \ 4.17. CPU Load while taking successive photos and writing them in a folder in\
    \ \nthe PC-G. \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a folder in \nthe RPI-G. \nFigure 4.19. CPU Load while taking successive\
    \ photos and writing them in a folder in \nthe S-G. \nFigure 4.20. Probability\
    \ density function estimation of IBM WVR latency to classify an \nimage located\
    \ in the IoT gateway. \nFigure 4.21. Proposed AUV-IoT Platform \nFigure 4.22.\
    \ Proposed hardware architecture. \nFigure 4.23. Node intercommunications and\
    \ concurrent threads in the IoT gateway. \nFigure 4.24. Communication between\
    \ platforms. \nFigure 4.25. Fan mussel recognition training: defining a fan mussel\
    \ bounding box in \ndifferent cloud services. \nFigure 4.26. Pictures used for\
    \ custom CV model training. \nFigure 4.27. New specimen detection using the IBM\
    \ Python API. \nFigure 4.28. Triangular similarity using a single camera [47].\
    \ \nFigure 4.29. Closed control loop for object detection and tracking. \nFigure\
    \ 4.30. Basic closed-loop system with sensor and actuator delays. \nFigure 4.31.\
    \ Mission generated in IUNO and uploaded into AUV. \nFigure 4.32. Deploying the\
    \ platform to initiate the mission. AUV submarine connected \nto a buoy via a\
    \ DSL cable. \nFigure 4.33. Specimen detection and positioning in IUNO. \nFigure\
    \ 4.34. Communication edge cloud. (a) Training and inference in the cloud; (b)\
    \ \ntraining in the cloud, inference in the edge. \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \nFigure 4.36. Edge architecture\
    \ latency in the proposed platform. \nFigure 4.37. Cloud-based custom models for\
    \ detecting new specimens. \nFigure 4.38. BUSCAMOS-VIGIA framework. \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \nFigure 4.40. Platform’s communications in the tracking\
    \ algorithm. \nFigure 4.41. SAAO diagram. \nFigure 4.42. Calculation of acceptable\
    \ latency limits. Main ASV camera point of view. \nFigure 4.43. Comparison of\
    \ three different clouds vision API detection of boat in Los \nNietos port (Murcia,\
    \ Spain). \nFigure 4.44. Types and number of vessels used to train the vision\
    \ custom models. \nFigure 4.45. Performance of the cloud custom model object detection\
    \ in discerning \ndifferent boat types. \n \nxix \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.46. Performance differences between the Edge\
    \ and the cloud custom models. \nFigure 4.47. Cloud and edge custom models for\
    \ detecting new vessels. \nFigure 4.48. Latency of more than 300 samples. \nFigure\
    \ 4.49. Images analysed. Cloud/edge results comparison \nFigure 4.50. Scale experiment.\
    \ Equivalence of area and distance from integral reserve \n(Islas Hormigas) to\
    \ base station (right) and equivalent area in Mar Menor (left). \nFigure 4.51:\
    \ Edge (left) / cloud (right) trained model recognition tests. \nFigure 4.52.\
    \ Start of mission (MMM) of surveillance of area equivalent to integral \nreserve.\
    \ \nFigure 4.53. (a) Stopped vessel detected. Start TM mode. (b) Tracking Mode\
    \ (TM) test \nduring the experiment.  \nFigure 4.54. Wind energy IoT communication\
    \ architecture \nFigure 4.55. Hardware Setup \nFigure 4.56. Data flow between\
    \ different systems and across different protocols. \nFigure 4.57. Checking OPC\
    \ UA connection using UaExpert Software \nFigure 4.58. Communication between the\
    \ PLC 1512 and IBM Cloud through OPC UA \nprotocol using Node-RED installed the\
    \ industrial Gateway IOT2040. \nFigure 4.59. Dashboard Data of wind Sensors in\
    \ the IoT2040 Gateway \nFigure 4.60. Dashboard data wind sensors in the IBM Watson\
    \ Platform. \n \n \n1 \n \n \nCHAPTER 1 \n \n \n \n--------------------------------------------------\
    \ \n \nIntroduction \n \n-------------------------------------------------- \n\
    \ \n \n \n \nThis chapter presents the background, motivation and main contributions\
    \ of \nthis thesis. It presents an overview of using computer vision and AI in\
    \ IoT \nmonitoring and its applications. The limitations are highlighted of using\
    \ AI in \nIoT monitoring and control and its main constraints as motivations for\
    \ the \npresented work. Subsequently, the main contributions of this thesis are\
    \ \npresented. Finally, the organization of this thesis is detailed. \n \n2.3\
    \ \nBackground  \n \nEmerging new market demands and autonomous technologies such\
    \ as IoT \nare moving the environment of manufacturing companies towards smart\
    \ \nfactories.  The fundamental idea of IoT is a system where physical objects\
    \ are \nenhanced with embedded electronics (RFID tags, sensors, etc.) and connected\
    \ to \nthe Internet. Thus, IoT is based on both smart objects and smart networks\
    \ [1]. The \ndevices in the IoT network can be employed for collecting information\
    \ based on \nthe use cases. These include retail, manufacturing industries, autonomous\
    \ \nvehicles, smart grid, etc. These IoT devices can be used for tasks such as\
    \ tracking \nitems and objects, remote monitoring, and fully autonomous robots.\
    \ It is reported \nthat the amount of IoT devices has been growing every year\
    \ with the predicted \nnumber of devices by 2025 reaching 75.44 billion [2]. \n\
    \ \n2 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe use of IoT has\
    \ become ubiquitous and IoT devices are common in many \nfields. The integration\
    \ of IT and Operational Technology (OT) in the Industrial \nInternet of Things\
    \ (IIoT) enables the “smart factory” concept. IIoT uses IoT \ndevices and sensors\
    \ to monitor machines and environments to ensure the highest \nperformance of\
    \ equipment and processes. \nIn practice, IoT has stimulated the factories and\
    \ the governments to launch \nan evolutionary journey toward the fourth industrial\
    \ revolution called Industry \n4.0. The first industrial revolution started with\
    \ the introduction of mechanical \nmanufacturing equipment, followed by a second\
    \ that entailed the mass \nproduction of goods.  Since the beginning of the 1970's\
    \ and until today, the \nincreasing automation and control of manufacturing processes\
    \ through the use \nof electronics and computers is considered the third revolution\
    \ (digital \nrevolution). Leveraging IoT technology in the manufacturing environment\
    \ leads \nto the fourth stage of industrialization [3]. \nAt the heart of IoT\
    \ and smart manufacturing is the basic principle of Industry \n4.0, products being\
    \ manufactured, components and production machines must \ncollect and share data\
    \ in real time. This leads to a shift from centralized factory \ncontrol systems\
    \ to decentralized intelligence.  \n The exchange of real-time data and information\
    \ between different devices \nand parties is the key element of smart factories;\
    \ this data could represent the \nstate of production. Therefore, the next generation\
    \ of smart factories will need to \nbe able to adapt, almost in real time, to\
    \ constantly technological options and \nregulations [4].  \nTo perform effective\
    \ predictive maintenance (PM), massive amounts of data \nare collected, processed\
    \ and ultimately analyzed by machine learning (ML) \nalgorithms. ML can be used\
    \ on collected data to make predictions. Indeed, the \naccuracy of ML models depends\
    \ primarily on the data collected. \nTraditionally, IoT sensors transmit their\
    \ data readings to the cloud for \nprocessing and modeling. Processing and transmitting\
    \ massive amounts of data \nbetween IoT devices and infrastructure comes at a\
    \ cost. Edge computing, in \nwhich sensors and intermediate nodes can process\
    \ data, can reduce data \ntransmission costs and increase processing speed. These\
    \ techniques can reduce \nthe amount of data sent to the cloud for processing,\
    \ however there are potential \naccuracy trade-offs when ML algorithms use reduced\
    \ data sets. Another \napproach is to move ML algorithms closer to the data to\
    \ reduce the amount of \ndata transmitted [5]. \nVisual recognition technologies\
    \ based on artificial intelligence (AI) and the \nInternet of Things (IoT) can\
    \ offer a detection capacity close to human capabilities \n[6]. The AI cloud services\
    \ allows training of customized ML models that are able \nto classify the received\
    \ data or detect individual objects in a given image along \nwith their bounding\
    \ box and label. There are many different cloud APIs for \ncomputer vision, e.g.,\
    \ IBM, Google, Microsoft Azure and Amazon. They all \n \n3 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nprovide fairly similar capabilities, although some emphasize\
    \ object recognition, \nAmazon, or building custom models, like Microsoft Azure\
    \ and IBM.  \nThe strength of these cloud APIs is their ability to develop custom\
    \ models \nrapidly and download trained custom models to deploy them on the edge\
    \ for \nreal-time applications and low-latency requirements [7-8]. \nWhen computing\
    \ is deployed at the edge for real-time data processing, \naccuracy is also of\
    \ paramount importance. Further, it is also clear that for data \nreduction, the\
    \ edge or device is mainly exploited. However, since the initial \ntraining is\
    \ computationally intensive, the cloud is still used in most of the \nproposed\
    \ techniques for model training. In cases where a dedicated edge node is \nnot\
    \ available, network devices can also be exploited.  \n \n1.1.1 APPLICATIONS \
    \ \n \nMany fields and industries are using IoT as part of their architecture\
    \ today. \nIn the following, we will look at some of them and how IoT can be used\
    \ to further \nimprovements. \n \nA. Smart Factory  \n \nThe main concept of Industry\
    \ 4.0 is smart manufacturing and IIoT, where the \ncomponent, product and machine\
    \ will exchange data on the basis of real time [9]. \nSince exchange of data between\
    \ different devices in real time is the main element \nof smart factory, this\
    \ information can be considered as control, production status, \nsupplier and\
    \ customer order feedback information, material movement, \nsimulation. Smart\
    \ factory will provide the customer with service and smart \nproduct, which will\
    \ be connected to a network based on IoT. The smart factory \ngathers and scans\
    \ data from a related smart application and the product. \n \nB. Smart Vehicles\
    \  \n \nA fully autonomous vehicle can be defined as a vehicle that is capable\
    \ of \nperceiving its environment, deciding on a route to its destination and\
    \ driving it. \nIt is a smart car or robocar that uses a variety of sensors, computer\
    \ processors \nand databases such as maps to take over some or all of the driving\
    \ functions of \nhuman operators. In a few words, an autonomous (or driverless)\
    \ car can also be \ndefined as a vehicle that relies on a combination of Internet\
    \ of Things (IoT) \ndevices (e.g., sensors, cameras, and lidars), appropriate\
    \ software, and artificial \nintelligence to move without a human operator [10].\
    \ \n \nC. Smart grid  \n \n \n4 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nToday most of the power supply system is manually operated, and due to \n\
    some human error, there is loss of power. These small losses result in massive\
    \ \noutrage of power supply. This loss can be brought under control, and a 100%\
    \ \nefficient power transfer system can be designed using IoT, and it is known\
    \ as the \nSmart grid. It is a fully automated system based on blockchain technology,\
    \ which \nis entirely robust & encrypted. This power is divided into channels\
    \ for each \nindividual, and this channel is wholly encrypted with its stash key,\
    \ which is to \nbe decrypted. This results in an equalized power supply throughout\
    \ the grid \nwithout any power loss [11]. Given that millions of end users will\
    \ be involved in \nthe processes and information flows of smart grids, the high\
    \ scalability of these \nmethods becomes an important issue. To solve these problems,\
    \ cloud computing \nservices emerge as a viable solution by providing reliable,\
    \ distributed and \nredundant capabilities on a global scale. Moreover, the implementation\
    \ of an \nintelligent network application on top of mixed cloud and edge processing\
    \ \nmiddleware is able to achieve higher performance by leveraging edge node \n\
    processing and data aggregation to reduce communication with the cloud \nenvironment\
    \ [12]. \n \n \nD. Monitoring environmental parameters   \n \nEnvironmental monitoring,\
    \ as an integral part of smart campuses, is an \napplication that describes any\
    \ activity in a surrounding area to monitor the \nquality of an environment [13].\
    \ It is used in the assessment of any risk that may \nbe posed to the environment\
    \ and humans. The applications of IoT in \nenvironmental monitoring are vast:\
    \ Industrial site monitoring, seabed \nmonitoring, sea or ocean monitoring, environmental\
    \ protection, extreme weather \nmonitoring, \nwater \nsafety, \nendangered \n\
    species \nprotection, \ncommercial \nagriculture, etc. In these applications,\
    \ sensors detect and measure every type of \nenvironmental change [14]. \n \n\
    E. Smart Waste Management  \n \nOne of the major issues that modern cities are\
    \ facing is waste management. \nIt consists of multiple processes like managing\
    \ and monitoring waste, transport, \ncollection, disposal, etc. These processes\
    \ are costly and time-consuming. One can \noptimize these processes to reduce\
    \ cost, which can be used for solving other \nissues that smart cities can be\
    \ deal with. For instance, various sensors can be \ninstalled in places like trucks\
    \ or cans of garbage, which can detect type and \namount of garbage [15]. \n \n\
    F. Smart agriculture  \n \n \n5 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThanks to the IoT, it is possible to meet the food needs of a constantly \n\
    growing population. The analysis of smart agriculture data, i.e., land condition,\
    \ \nweather situation, and soil type, collected from the IoT network, can provide\
    \ \npractical information if used in combination with the data captured by sensors,\
    \ \nwhich measure the level of water resources, heat, humidity, chemicals, water\
    \ \nstress, pump condition, etc. This allows farmers to use fertilizers, water\
    \ and \npesticides in the most accurate amounts, at precise positions and with\
    \ efficient \nscheduling to improve crop yields. Smarter water use, such as monitoring\
    \ and \nsupervising the capacity, location, timing and period of water flow based\
    \ on data \nanalysis, increases irrigation efficiency and thus reduces costs [16].\
    \ \n \nG.  Smart Home  \n \nTo reduce user’s interference in controlling and monitoring\
    \ home settings as \nwell as home appliances, smart home is an emerging application\
    \ [17]. A smart \nhome provides many features for the user like measuring home\
    \ conditions (i.e., \nlight intensity, temperature, heating, etc.), operate home’s\
    \ Heating, Ventilating, \nand Air Conditioning (HVAC) appliances and control them\
    \ with reduced human \ninteraction [18]. Paper [19] presents an example of procedure\
    \ to develop a smart \nhome by combining IoT with cloud computing and web services,\
    \ use a platform \nfor implanting intelligence in actuators as well as in sensors\
    \ and facilitates \ninteraction within smart things using cloud services.  \n\
    \ \nH. Weather Forecasting  \n \nTo predict the state of the atmosphere for a\
    \ future time and for a given \nlocation, weather forecasting is very important.\
    \ Weather forecasting and \nmonitoring consist of a collection of data, assimilation\
    \ of data, and forecast \npresentation. Sensors at weather station used to sense\
    \ humidity, temperature \nwind speed, the moisture of soil, the intensity of light,\
    \ radiation, etc. Data coming \nfrom these sensors is huge in size and difficult\
    \ to monitor. The integration of this \nsensor infrastructure with cloud increases\
    \ its storage and computational \ncapabilities. It also provides effective solutions\
    \ for monitoring and presentation \nof data [20].  \n \nI. Health Care  \n \n\
    Sensors of pervasive healthcare applications make use of cloud computing \nand\
    \ IoT to allows a machine-to-machine communication regardless of the \nlocation\
    \ [21]. Nowadays, in modern hospitals, various body sensors are used to \nmeasure\
    \ and monitor physiological data of the patients. This sensitive collected \n\
    data is maintained for future diagnosis of patient. In some hospitals, this data\
    \ is \nmaintained at the local database. Due to this, doctors who are called to\
    \ handle \n \n6 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncritical cases\
    \ unable to analyze disease. After visiting to the patient only they can \ngive\
    \ proper treatment. However, using the cloud service, this issue can be solved\
    \ \ni.e., data of patients can be maintained and shared with doctors who are abroad,\
    \ \nso that they can treat the patient, independent of location [22].  \n \n1.1.2\
    \ IoT monitoring and controlling \n \nThe rising trends of the Internet of Things\
    \ (IoT) paradigm are attracting \nincreasing attention from both academia and\
    \ industry for their highly emerging \napplications of smartly connecting the\
    \ surrounding things or objects without \nhuman intervention [23]. Collecting\
    \ information from the surrounding \nenvironment to analyze, control, and making\
    \ correct action is the main idea for   \nIoT. To interchange data, IoT resources\
    \ using internet makes use of multiple \ninterconnected technologies like wireless\
    \ sensor network (WSN) and radio \nfrequency identification (RFID). IoT consists\
    \ of smart objects, which can be read, \nlocate, address, and control through\
    \ the internet using RFID, wireless LAN, or   \nsome other means [24]. In recent\
    \ time, IoT is getting more attention due to the \nadvancement of wireless technology.\
    \ The basic idea is due to variety of objects \nsuch as Sensors, RFID, actuators,\
    \ Near Field Communication (NFC), mobile \nphones, etc., which can interact with\
    \ each other by having a distinct address. \nArtificial Intelligence (AI) may\
    \ greatly support Internet of things in different \nways for physical (PHY), data\
    \ link (MAC), network, transport, and application \nlayers. AI cloud computing\
    \ is the fusion of machine learning (ML) capabilities of \nAI with cloud-based\
    \ computing environments, enabling connected, and intuitive \nexperiences. AI\
    \ has become more affordable through the use of cloud platforms. \nThe affordable\
    \ cost, coupled with cloud providers promoting AI as having a \nwidespread value,\
    \ leads to concerns that the technology will be misapplied. \nThere are different\
    \ IoT architectures adopted in research and development \nworks. The three-layer\
    \ IoT architecture shown in Figure 1.1, consists of a sensing \nor device layer,\
    \ which is also call as physical object layer whose main purpose is \nsensing\
    \ and data collection [25]. The second layer is the edge layer, its role is to\
    \ \nperform data transmission over the network, including sometimes being \nresponsible\
    \ for preprocessing and data storage before sending the data to the \ncloud. The\
    \ edge layer is also an appropriate place for ML deployment, allowing \nthe frameworks\
    \ to be implemented using hybrid architectures. \nA layer exists for the primary\
    \ processing of data. Data can be stored and \nprocessed by high-performance servers.\
    \ Predictive maintenance (PM) can \nmonitor machine health to determine likely\
    \ component failure. ML optimization \nmodels are deployed to help make intelligent\
    \ decisions about which production \nparameters to monitor. \n \n \n7 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 1.1. A three-layer IoT architecture\
    \ based on: Device, Edge and Cloud for Predictive \nMaintenance (PM) [25]. \n\
    \ \n \n1.1.3. Advantages of Using AI in the cloud \n \nAI technology is being\
    \ applied in most cloud services to drive interest in \napplication development.\
    \ Typical offerings combine the ability to leverage AI \nservices at a lower cost\
    \ with important data management systems that provide \nthe source of the data,\
    \ and thus the source of the models.  \nCloud-based AI solutions are different;\
    \ however, they have some \ncommonalities, as well as benefits and limitations.\
    \ First of all, the great benefit is \nthat these systems are inexpensive to operate.\
    \ To drive an AI application, \npayment can be made per hour used of each service.\
    \ This is perhaps the largest \nbenefit of cloud AI, really bringing AI down to\
    \ the level of a basic enabling \ntechnology. \nPublic clouds also offer cheap\
    \ data storage. Real databases or storage systems \ncan be leveraged as data input\
    \ into AI applications. Finally, they all provide SDKs \nand APIs that allow us\
    \ to integrate AI features directly into applications, and they \nsupport most\
    \ programming languages. \nWhile AI is a technology that allows a machine to simulate\
    \ human behavior, \nML is a subset of AI that allows a machine to automatically\
    \ learn from prior data \nwithout explicit programming. ML as a service (MLaaS)\
    \ is an umbrella concept \n \n8 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nof various cloud-based platforms that cover most infrastructure issues such\
    \ as \ndata pre-processing, model training, and model evaluation, with further\
    \ \nprediction. \nML offers several advantages, including accurate predictions,\
    \ speed, \nautomation, and scalability [26]. The ML method uses algorithms to\
    \ analyze data, \nfind rules and abstract the rules into models to classify and\
    \ predict unknown \ndata. It can significantly enhance the efficiency of data\
    \ processing and the \naccuracy of prediction results by applying machine learning\
    \ methods to \nmonitoring complex IIoT data. Furthermore, it can also detect abnormal\
    \ \nconditions of the IIoT to the greatest extent possible and reduce the loss\
    \ of \nproperties and lives [27]. On the one hand, Deep learning (DL) structures\
    \ the \nalgorithms into multiple layers in order to create an “artificial neural\
    \ network \n(ANN)”. Complex DL models are being developed, and in addition, CE\
    \ research \nis accelerating to provide more computational resources for DL models\
    \ to \nsupport more applications [28]. Prior to the use of ML in IIoT, the cognitive\
    \ ability \n(to learn the environment) of machines was simply a predefined heuristic.\
    \ \nHowever, sophisticated ML algorithms have improved the cognitive capability\
    \ \nby finding patterns in the data and making predictions [29]. \n \n1.1.4. Constraints\
    \ \n \nIoT is a novel paradigm to interconnect massive wireless devices, which\
    \ has \nthe potentials to be applied in diverse applications and fields. However,\
    \ due to a \nhuge number of wireless devices in IoT networks, many technical challenges\
    \ \nneed to be addressed, Figure 1.2 presents some limitations of current IoT\
    \ \nplatforms. \n \nFigure 1.2 Major limitations of current IoT platforms \n \n\
    \ \n9 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nBased on the presented\
    \ limitations, there are imperative directions that have \nto be considered in\
    \ the future for IoT research studies. \n \nA. Scalability  \n \nThe growing idea\
    \ of IoT which generates a tremendous amount of data for \nprocessing and storage\
    \ guide to enormous leap in the forthcoming year, and \nhence it becomes insistent\
    \ on making the scalable system. The vast application of \nIoT has increased the\
    \ number of devices being connected to the internet, which \nmeets the concern\
    \ to consider various complications that are arising in \nconnectivity [25]. Different\
    \ sources like the internet, social media, machine, and \nmany other devices generate\
    \ data. Thus, special attention must be given for \ntransportation, access, storage,\
    \ and processing of these large sets of structured \nand unstructured digital\
    \ data [25].  \n \nB. Interoperability  \n \nAs the data sharing among smart devices\
    \ is increasing day by day, it is \nnecessary to manage these data transfer properly\
    \ among the system [30]. \nInteroperability can be considered as the potentiality\
    \ of two systems to \ncommunicate, exchange information, or program, or transfer\
    \ the data among \neach other and to implement the given data [31]. It is the\
    \ exchange of information \namong different computers through wide area networks\
    \ or local area networks. \nIt is critical for IoT as most of the communication\
    \ takes place as a machine to \nmachine [32]. \n \nC. Real-Time (Delay)  \n \n\
    Meeting real-time latency requirements depends on how data is collected \nand\
    \ processed [33]. This becomes more severe as IoT applications that involve \n\
    rich data types such as images evolve. In addition, developing real-time analytics\
    \ \nin the cloud is nearly impossible to achieve. \nA variety of IoT applications\
    \ require local analytics. For instance, in the \ncontext of IIoT, to quickly\
    \ turn on or off a piece of equipment in a production \nenvironment can prevent\
    \ a catastrophic situation. Analytics depend on ML \nalgorithms that are computationally\
    \ expensive for some tiny sensors. In addition, \nthe power consumption of small\
    \ sensors has been one of the main concerns even \nbefore the emergence of ML\
    \ in IoT. Thus, achieving the goal of real-time with a \nsensor cloud architecture\
    \ seems ambitious. \nThe limited computational capacity of sensor nodes is a major\
    \ challenge. \nTherefore, a hybrid architecture to implement computationally intensive\
    \ tasks \nsuch as training on the cloud and model deployment for prediction on\
    \ the \nsensing node has emerged. However, this approach also presents challenges\
    \ in \n \n10 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nthe case where\
    \ models require retraining based on new data. In this case, all new \ndata must\
    \ be moved to the cloud, which incurs costs in terms of latency, energy \nconsumption,\
    \ and network resource usage [34]. \n \nD. Accuracy  \n \nThere are many possibilities\
    \ for designing a Neural Network (NN) model, \nprovided that different hyperparameters\
    \ in the network provide a different level \nof accuracy. Particularly, a high\
    \ accuracy model requires more memory than a \nlow accuracy model due to the number\
    \ of parameters. The metric used to \nmeasure accuracy depends on the domain in\
    \ which the ML algorithm is applied. \nIn IIoT, a traditional approach to data\
    \ collection is to stream data from \nsensing devices to the cloud where it is\
    \ processed and modeled. Sensing devices \ngenerate huge amounts of data, continuously\
    \ or periodically, often in a very short \nperiod of time. For instance, in one\
    \ second, thousands of records can be generated \nby one machine [35]. According\
    \ to the Cisco cloud index (2013-2018), an \nautomated facility can generate one\
    \ terabyte of data per hour. For this purpose, \napproaches such as sampling,\
    \ compression, filtering are used to reduce the size \nof data. These techniques\
    \ reduce the amount of data transmitted to the cloud. \nHowever, there are potential\
    \ accuracy trade-offs for ML models that use reduced \ndatasets, as the accuracy\
    \ of ML models depends primarily on the data collected. \nThe accuracy of models\
    \ trained on reduced data should also be a concern \nwhen optimizing for energy\
    \ consumption and latency. This is more important in \ndeep learning approaches\
    \ that require more data to be trained. \nIn current IIoT systems based on edge\
    \ computing, edge devices can only \nperform lightweight computing tasks. To enable\
    \ edge devices and servers to \nperform more complex tasks with higher data processing\
    \ performance and lower \nlatency, edge intelligence (EI) is applied to the IIoT\
    \ edge to make the devices and \nservers intelligent. However, an AI model can\
    \ be trained to make predictions and \ndecisions with high accuracy; however significant\
    \ amounts of training and \nverification data are required. For edge devices,\
    \ training and operating the AI \nmodel is challenging due to limited computing\
    \ and storage resources. \n \nE. Security  \n \nAs the IoT trend inflates multiple\
    \ interconnections and device heterogeneity, \nit eventually generates cyber-attacks.\
    \ Thus, data security is one of the most \ncritical issues. As there is an increase\
    \ in the number of connected devices, there \nare possibilities of cyber-physical\
    \ security vulnerabilities that can be exploited by \nvarious attackers [36].\
    \ Security is a key pillar of the internet, which is the main \nchallenge of IoT.\
    \  \nTherefore, it is necessary to learn from these incidents: industries are\
    \ now the \ntarget of attackers and there is an urgent need to address this issue.\
    \ IIoT is \n \n11 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nsometimes thought\
    \ of as the integration of operational technology (OT) and \ninformation technology\
    \ (IT), with OT comprising the factory network where \nmanufacturing is performed\
    \ and IT comprising the enterprise network [37]. \nThese two components have different\
    \ security requirements, which must be \naddressed to prevent compromise of the\
    \ IIoT infrastructure. \n \n1.2 Motivation  \n \nAlthough IoT has been widely\
    \ used in the above applications, a number of \ncritical limitations have hindered\
    \ the use of AI in various implementations. These \nlimitations tend to mainly\
    \ affect the system response time and the efficiency of \nthe proposed solution.\
    \ The various aspects of DL that need to be improved in an \nIoT concept include\
    \ smart algorithms with improved efficiency and support for \nbetter platforms.\
    \ For this reason, the following issues had to be investigated to \novercome these\
    \ limitations of using AI in IoT architecture. \n \nA. Interoperability \n \n\
    Recent advances in manufacturing technology, such as industrial internet, \ncyber–physical\
    \ systems, AI (Artificial Intelligence), and machine learning have \ndriven the\
    \ evolution of manufacturing architectures into integrated networks of \nautomation\
    \ devices, services, and enterprises. One of the resulting challenges of \nthis\
    \ evolution is the increased need for interoperability at different levels of\
    \ the \nmanufacturing ecosystem. Interoperability means the ability of two or\
    \ more \nparties, machine or human, to make a perfect exchange of content.  \n\
    The IoT is a dynamic global network infrastructure with self-configuring \ncapabilities\
    \ based on interoperable, standard communication protocols, enabling \nall objects\
    \ to communicate with each other. The application of IoT to the \nindustrial domain\
    \ has given rise to a new research area called the Industrial \nInternet of Things\
    \ (IIoT). IIoT is a new service-oriented industrial ecosystem that \nuses networked\
    \ interconnection of industrial resources, data interoperability, \nand system\
    \ interoperability to enable flexible resource allocation, rational \nprocess\
    \ optimization, on-demand process execution, and rapid adaptation of \nenvironments\
    \ [38]. In general, interoperability is defined as the ability of \nheterogeneous\
    \ networks, applications, or computer components to exchange and \nuse information,\
    \ i.e., to speak and comprehend each other [39]. Suited to the IoT \ncontext,\
    \ this refers to the ability of heterogeneous components to exchange and \nshare\
    \ data and functions to achieve a desired goal (defined by a use case or \napplication),\
    \ regardless of the communication protocol used or the format of the \nexchanged\
    \ data.  \nUp to only a few years ago the communication systems for industrial\
    \ \nautomation aimed only at real-time performance suitable for industry and \n\
    \ \n12 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmaintainability based\
    \ on international standards [40]. The Industry 4.0 concept \nhas the flexibility\
    \ to achieve interoperability between the different industrial \nengineering systems.\
    \ To connect the different industrial equipment and systems, \nthe same standards\
    \ and safety levels are required. Open Platform \nCommunications Unified Architecture\
    \ (OPC UA) is a machine-to-machine \n(M2M) communications protocol developed to\
    \ create inter-operable and reliable \ncommunications and is now generally accepted\
    \ as standard in industrial plant \ncommunications [41].  \nThe domain extends\
    \ from software, devices, and control systems on the \nfactory floor to Internet-based\
    \ cloud platforms that provide various on-demand \nservices. \nA successful implementation\
    \ of interoperability in smart manufacturing \nwould therefore result in efficient\
    \ communication and error-free data exchange \nbetween machines, sensors, actuators,\
    \ users, systems and platforms. The \narchitecture and platforms used by machines\
    \ and software packages are a major \nchallenge in this regard. A better understanding\
    \ of the subject can be obtained by \nstudying industry-specific communication\
    \ protocols and their respective logical \nsemantics.  \nTo be more precise and\
    \ in accordance with [42], three levels of \ninteroperability can be specified\
    \ to achieve horizontal interoperability between \ndifferent components, each\
    \ level covering a different facet of interoperability and \ncommunication: \n\
    \ \n• Technological interoperability is given if the two components are physically\
    \ \nconnected to each other and can transmit any type of information on the \n\
    transmission layer [42]. This level of interoperability concerns the lower \n\
    transmission layers of the OSI model (i.e., the physical, data link, network and\
    \ \ntransport layers) and the corresponding protocols. \n \n• Syntactic interoperability\
    \ is ensured if the data format, including encodings, \nas well as the communication\
    \ interface format are clearly defined and agreed \nupon between the two components\
    \ [42]. The abstract term \"communication \ninterface format\" refers to the protocol\
    \ used on the application layer and \nprovided as communication interface by the\
    \ respective component. As with \ntechnological interoperability, it is not necessarily\
    \ required that the two \ncomponents agree on the same protocol, as long as there\
    \ is a possibility of \nadapting two different protocols (the same applies to\
    \ the format and encoding \nof the data embedded in the protocol(s)). \n \n• Semantic\
    \ interoperability is ensured if both components agree on the same \ninformation\
    \ model describing the topic of the exchanged information as well \nas the provided\
    \ communication interfaces [42] (i.e., the meaning of the \nexchanged messages\
    \ with respect to the used protocol). \n \n13 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 1.3 depicts the mapping of these three interoperability\
    \ levels defined \nin [42] to the OSI layers. It should be noted that this mapping\
    \ is not strict and that \nthe boundaries between the OSI layers may vary depending\
    \ on the \nimplementation of the application concerned. \n \n \nFigure 1.3 Mapping\
    \ of interoperability levels to OSI layers \n \n \nThe evolution from traditional\
    \ hierarchical models of enterprise control \nsystem integration, or automation\
    \ pyramid, to integrated networks of smart \ndevices, \ncloud \nservices, \nand\
    \ \nextended \nenterprises \nrequires \nseamless \ncommunication and information\
    \ exchange between heterogeneous and \ntraditionally silent systems (Figure 1.4).\
    \  \nDifferent types of interoperability problems may arise, due to the diverse\
    \ \nnature of interactions in the emerging automation networks. Thus, there is\
    \ a need \nfor vertical interoperability between devices and shop floor automation\
    \ services, \nas well as horizontal interoperability between enterprises and cloud\
    \ service \nplatforms. \n \n \n \n \n14 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 1.4. Automation Pyramid vs Automation Network [43] \n\
    \ \n \nB. Low-latency and ultra-Reliability \n \nThe industrial smart facility\
    \ requires multiple synchronized processes that \nrequire low latency and higher\
    \ reliability to achieve the necessary performance \n[44]. Furthermore, AI methods\
    \ applied to IIoT must be able to address these \nissues as well as other parameters\
    \ such as network deployment and resource \nmanagement [45]. Nevertheless, the\
    \ competence and usefulness of DL-based IIoT \nscenarios are still in the evolutionary\
    \ phase, requiring exclusively the strict low-\nlatency and ultra-reliability\
    \ requirements of IIoT. Therefore, further research \nefforts are needed in this\
    \ direction to establish a theoretical and practical \nbackground for DL-IIoT\
    \ to ensure low-latency and ultra-reliable communication. \nFast and efficient\
    \ computing is another key feature that can affect not only \nlatency and reliability\
    \ but also many other performance parameters in smart \nindustries. As mentioned\
    \ earlier, IIoT requires powerful and useful tools to \ncompute big data obtained\
    \ from various processes and analyze them on specific \nplatforms including servers,\
    \ transmission media, and storage. \nIntelligence at the edge should push DL computations\
    \ from the cloud to the \nedge as much as possible, enabling various distributed,\
    \ low-latency and reliable \nintelligent services, as shown in Figure 1.5. \n\
    \ \n15 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nDL services can be\
    \ deployed close to the requesting users and the cloud only \nintervenes when\
    \ additional processing is required [46], which significantly \nreduces the latency\
    \ and cost of sending data to the cloud for processing. \n \n \n \nFigure 1.5.\
    \ Capabilities comparison of cloud, on-device and edge intelligence [47] \n \n\
    Currently, hybrid cloud-edge computing is used to perform fast and efficient \n\
    computation and provides a comprehensible computing infrastructure for IIoT. \n\
    It is considered appropriate to use the edge-based computing infrastructure due\
    \ \nto its ability to reduce latency and improve the learning process in the network.\
    \ \nNonetheless, the integration of distributed and edge computing infrastructure\
    \ \nfor IIoT remains an open research issue [48]. Particularly, the coupled realization\
    \ \nof distributed and parallel learning for edge-based designs requires further\
    \ \noptimization to attain higher productivity, self-organization, and lower runtime.\
    \ \n \n \nC- Energy consumption of mobile IoT devices \n \nRobotic engineering\
    \ systems are deployed in industry today and are \nconsidered vital to the progress\
    \ of humanity from an industrial perspective in \nthe new digital age. \nThe Internet\
    \ of Robotic Things (IoRT) empowers robotic objects in different \nenvironments\
    \ to be active players in various applications and to share and \nexchange information\
    \ with other robotic objects, IIoT devices and humans. IoRT \napplications are\
    \ developing in parallel with IIoT advancements, combining \ninformation technology\
    \ (IT) used for data-centric computing and operational \n \n16 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ntechnology (OT) used in enterprise and\
    \ industrial operations integrating \nsupervisory control and data acquisition\
    \ (SCADA) systems and programmable \nlogic controllers (PLCs), where industrial\
    \ applications are increasingly \nintegrated, and where new smart connectivity\
    \ networks are used.  \nTransferring large datasets to a central cloud is an energy-intensive\
    \ \noperation, and new computing paradigms are being used and implemented for\
    \ \nIoRT applications. Smart connectivity networks can facilitate the transfer\
    \ and \nprocessing of information in an energy-efficient and high-performance\
    \ manner. \nHowever, deployed batteries have a specific charge rate and, therefore,\
    \ the \noperating time of robots is limited. Autonomous mobile robots are powered\
    \ by \nbatteries mounted on their platforms to provide energy to the on-board\
    \ sensors, \nmicrocontrollers, peripheral modules and servos.  \nDevelopments\
    \ in IoT, AI, and connectivity technology [49] enable IoRT \napplications to reduce\
    \ power consumption and improve energy efficiency, \nresulting in lower costs\
    \ and latency. Energy efficiency, real-time processing, \ncomputation, and analysis\
    \ efficiency of IoRT devices, efficient task offloading, \nand intelligent service\
    \ response time of other IoRT devices and agents must be \naddressed by developing\
    \ new collaborative processing techniques at the edge. \nAlong with ensuring dynamic\
    \ network/resource slice management, dynamic \ndevice management, and the necessary\
    \ containment between different IoRT \ndevices and different complex applications.\
    \ \n \n1.3 Objectives and contributions \n \nThe objective of this thesis is to\
    \ develop and evaluate a real-time IoT \nframework capable of connecting AI cloud\
    \ services with different industrial \nsystems and platforms, trying to overcome\
    \ the limitations and challenges \nshowed in previous sections. Therefore, the\
    \ required systems and networks must \nensure the optimal trade-off between response\
    \ time and system accuracy, \nkeeping in mind that cloud computing is introduced\
    \ in the control loop. In this \ncontext, the main objectives of this work are:\
    \ \n \n1. The design of an IoT architecture to enable interoperable systems \n\
    connecting different IoT devices using different protocols and technologies, \n\
    together with the different proposed systems and networks. To this end, some \n\
    considerations were considered: \n \n \n- \nProtocols and software suitable for\
    \ interoperability and connectivity \nconstraints: The interoperability challenge\
    \ can be overcome by using \nadvanced software deployed in the IoT gateway, which\
    \ can be considered \nas the junction interface between the physical and cloud\
    \ worlds. This \n \n17 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    software must interact simultaneously with the different systems \ninvolved through\
    \ different protocols.  \n \n- \nThe appropriate devices capable of providing\
    \ minimal response time: The \nchoice of an IoT gateway is crucial in terms of\
    \ latency and accuracy, as it \nis at the heart of processing and transmitting\
    \ data to the different systems \nand platforms. \n \n \n2. To further improve\
    \ the trade-off between latency and accuracy, the \nfollowing points are considered:\
    \ \n \n- \nThe most efficient cloud computing solutions for each use case: The\
    \ \nimplemented cloud services must ensure that data is transferred, \nprocessed\
    \ and returned at speeds that meet the needs of the application. \n \n- \nFlexibility\
    \ to use AI models in the edge and the cloud for improved \nperformance: The ability\
    \ to deploy the cloud AI models at the edge can \nfacilitate the use of cloud\
    \ technologies in different sectors. In addition, the \nhybrid cloud/edge architecture\
    \ must ensure a real-time control loop for \nrelevant latency and accuracy. \n\
    \ \nContributions:  \n \nThe main innovative contribution of this thesis is to\
    \ include cloud services in \na control loop, to improve the decision making of\
    \ a factory and improve the \nperformance of an industrial control system.  \n\
    Cloud AI services can also be integrated into a drone control loop as an input\
    \ \ncontributing to improve the monitoring capability to find and track stationary\
    \ \nand moving objects. To this end, the work in this thesis has been divided\
    \ into \nseveral parts depending on the scenario used. Thus, several contributions\
    \ could \nbe enumerated: \n \n1. The validation of the IoT architecture proposed\
    \ in this thesis in the industry \nas a way to control and monitor the status\
    \ of devices and systems integrating \nIoT protocols and edge-computing \n \n\
    2. The Introduction of cloud services computer vision (CV) techniques as a part\
    \ \nof the industrial control loop to improve the operation of the production\
    \ \nprocess in a factory. \n \n3. The integration of CV cloud services into the\
    \ control loop of a drone for \nmonitoring and seeking for a new object using\
    \ the drone's cameras. \n \n18 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n4. The demonstration of that a hybrid AI cloud architecture can solve the\
    \ \nproblem of latency and accuracy of the control system. Choosing the correct\
    \ \nAI CV cloud services is crucial in terms of latency and accuracy of the control\
    \ \nsystem, as the systems need to respond in real time with accuracy.  \n \n\
    5. The use of edge computing topology to reduce latency in low-bandwidth \nenvironments.\
    \ Cloud computing topology improves accuracy at the expense \nof increased latency.\
    \ To meet the system’s requirements, in this thesis, a smart \nalgorithm to optimize\
    \ autonomy is propose and developed. This Is done by \nselecting the appropriate\
    \ AI technology for the scenario being monitored. \nThis proved to be crucial\
    \ in deciding the best source of artificial intelligence \nto be used to achieve\
    \ the specified objectives in each stage in real time. The \nproposed smart algorithms\
    \ ensure a trade-off between latency and accuracy. \n \n6. The validation of the\
    \ proposed IoT architecture for an autonomous marine \nrobot for protection and\
    \ permanent surveillance in marine protected areas \nbased on AI cloud recognition\
    \ services. \n \n \n2.5 Thesis organization \n \nThis thesis is organized and\
    \ divided into 5 chapters. This first chapter has \nbeen dedicated to the presentation\
    \ of IoT, especially Industrial IoT, and the \nchallenges faced in using an IoT\
    \ architecture as the one presented in this thesis. \nMoreover, we discuss the\
    \ constraints and benefits of using AI in the cloud and \nfinally the main motivations\
    \ and contributions of this thesis have also been \nrevealed. The core of this\
    \ thesis is detailed in the following chapters:  \n \n \nChapter 2: Outlines the\
    \ IoT Monitoring and Control Architecture Based on \nUnmanned Vehicles and defines\
    \ some of the protocols adopted in Industrial IoT. \nIt describes also the types\
    \ of IoT architectures, and the use of computer vision \nand AI at the edge using\
    \ cloud services. \n \nChapter 3: This chapter provides an overview of the different\
    \ solutions \nproposed to employ artificial intelligence for monitoring systems\
    \ in an IoT \narchitecture. We start with a review of the state of the art for\
    \ the different AI \ntechniques used for an interoperable IoT architecture. Then,\
    \ a comparison \nbetween the different proposed methods is highlighted. We discuss\
    \ the different \nmethods and factors used to appraise the latency and accuracy\
    \ of the proposed \n \n19 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nAI models and finally a latency assessment for an unmanned vehicle IoT \n\
    architecture. \n \nChapter 4: This chapter focuses on monitoring and control applications\
    \ in a \nIoT architecture. This chapter presents different applications using\
    \ advanced \ndevices and robots to control and monitor areas using computer vision\
    \ and AI \ncloud services. The proposed AI approaches are compared in terms of\
    \ latency \nand accuracy to validate their performance.  \nThe first application\
    \ was about a wind power system connected to the IBM \ncloud for monitoring. The\
    \ second application was to feed results from AI services \nin the cloud into\
    \ an industrial control loop. The AI results come from an \nunmanned aerial vehicle\
    \ camera taking images of materials being transported in \na concrete plant. The\
    \ other application, proposes an AUV model system designed \nto track a species\
    \ of Mediterranean fan mussel, using cloud computing services \nwith edge computing\
    \ as alternative processing units. \nThe latter, proposes an autonomous marine\
    \ robot for protection and \npermanent surveillance in marine protected areas\
    \ based on AI cloud recognition \nservices. \n \nChapter 5: Summarizes the contributions\
    \ of the whole thesis and outlines \nsome directions for future work. \n  \n \n\
    \ \n \n20 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 2 \n \n \n \n-------------------------------------------------- \n \nPerformance\
    \ analysis of IoT Monitoring \nand Control System Based on UV, \nMachine Vision\
    \ and Artificial \nIntelligence \n--------------------------------------------------\
    \ \n \n \n \n \n2.1 Introduction  \n \nAutonomous vehicles have played an increasingly\
    \ important role in \nmonitoring different environments, they are now considered\
    \ one of the best \nremote sensing techniques for collecting data over large areas.\
    \ They are now used \nin different sectors as detection tools to proactively solve\
    \ or prevent many \nproblems. In industry, as an example, unmanned aerial vehicles\
    \ (UAVs) can be \nused for inspections [50], to quantify production and monitor\
    \ construction \nprocesses [51] \nand help make decisions.  \nAutonomous underwater\
    \ vehicles (AUVs) are widely used in various marine \napplications: visual inspection\
    \ of infrastructures [52], aquaculture [53], marine \nbiodiversity mapping [54],\
    \ marine geoscience [55], and visual monitoring of \nmarine life [56] and recovery\
    \ of autonomous underwater vehicles [57]. \nUSVs are currently the subject of\
    \ a number of publications related to ocean \nmonitoring applications related\
    \ to weather/storm forecasting and disaster \n \n21 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nmanagement [58]. They can play a critical role in disaster\
    \ research [59] by \nreplacing rescue teams in remote and dangerous areas [60],\
    \ or by monitoring \ncovered environmental areas such as water bodies [61], or\
    \ by performing long-\nterm monitoring [62]. AI has the potential to be a powerful\
    \ tool and be deployed \nfor marine area surveillance by detecting and recognizing\
    \ vessels through \nartificial intelligence (AI)-based image recognition services.\
    \ \nComputer vision (CV) has particularly improved the field of object detection\
    \ \nand image classification. Visual recognition systems can reach impressive\
    \ \nperformances, thanks to the latest developments in neural networks, in particular\
    \ \ndeep learning (DL). Although all the developed DL algorithms can be deployed\
    \ \nin the cloud, the present cloud computing systems are unable to manage and\
    \ \nanalyze the massive amount of computing power and data. Edge intelligence\
    \ is \nenvisioned to replace DL computing in the cloud, providing a variety of\
    \ reliable, \nlow latency, distributed intelligent services. \n The IoT gateway\
    \ is used to connect the autonomous vehicles and control \nsystems to the internet\
    \ and cloud services, it is able to connect the sensor network \nto the cloud\
    \ computing infrastructure and perform edge and fog computing and \nserves as\
    \ a bridge between sensor networks and cloud services.  \nIntegrating autonomous\
    \ robots into the IoT represents an interoperability \nchallenge, as every IoT\
    \ system has its own communications protocol. Moreover, \na small error or delay\
    \ beyond the tolerated limit could result in a disaster for \nvarious applications.\
    \ The IoT gateway must not only address the challenge of \ninteroperability of\
    \ interconnected systems but also process and transmit data in \nreal-time. \n\
    The current cloud computing system is increasingly unable to cope with the \n\
    massive amount of data it receives [63]. Edge computing, which is composed of\
    \ \nsmart nodes and could take the place of cloud processing, is expected to solve\
    \ \nthis problem since it is closer to the users than the cloud [64]. These smart\
    \ nodes \nrange from smart gateways to offsite ruggedized nodes, to on-premises\
    \ heavy \nstorage nodes and data center servers at the edge. \nNew architectures\
    \ have recently been proposed to address the latency issue. \nA hybrid cloud/edge\
    \ architecture can provide a real-time control loop for better \nlatency and accuracy\
    \ and meet several system requirements. \nThis chapter begins with a description\
    \ of the architecture of three IoT layers, \nand its main components, from data\
    \ detection to its processing. It describes \nseparately the technology used in\
    \ each layer for different use cases. We discuss \nthe use of computer vision\
    \ techniques at the edge and in the cloud, and the effect \nof interoperability\
    \ and real-time requirements. Finally, we end the chapter by \npresenting the\
    \ different cloud APIs used. \n \n2.2 UV IoT architecture \n \n \n22 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2.2.1. Most Common IoT Architectures \n\
    \ \n1. Common IoT Architectures \n \nOne of the main challenges in the technology\
    \ domain to support the \ndeployment of IoT systems is to define a reference architecture\
    \ that supports both \ncurrent and future features. Therefore, such an architecture\
    \ must be: -scalable, -\ninteroperable, -distributive, -able to operate with few\
    \ resources (Computational \npower) -secure so as not to allow unauthorized access.\
    \ \nCurrently, a single reference architecture does not exist, and creating one\
    \ is \nvery complicated regardless of many standardization efforts. One of the\
    \ main \nproblems is related to the natural fragmentation of possible applications,\
    \ each of \nwhich depends on many different variables and design specifications.\
    \ Figure 2.1 \ndescribes some of the most common IoT architectures. \n \n \nFigure\
    \ 2.1. Most common IoT architectures [67] \n \n2. Three-Layer architecture  \n\
    \ \n- Perception, represents the physical layer of the objects and includes all\
    \ the \nfeatures. \n- Network, that stands for the communication layer responsible\
    \ for the \ntransmission of data to the application layer through various protocols\
    \ and \ntechnologies. \n- The application, which is the application layer in which\
    \ the software offering a \nspecific service is implemented. \n \n \n23 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n3. Service-oriented architecture\
    \ \n \nIt represents the four-layer IoT architecture based on SoA, in which there\
    \ is \nthe perception layer, the network layer, the service layer and finally\
    \ the \napplication layer. The SoA is designed to coordinate services and enable\
    \ the reuse \nof hardware and software components. Generally, SoA is based on\
    \ a component \nmodel, which can be designed to connect different functional units\
    \ of \napplications through interfaces and protocols [65-66-67]. \nSoA can be\
    \ easily integrated into the IoT architecture, by extending the three-\nlayer\
    \ architecture, by adding a new layer between the network layer and the \napplication\
    \ layer, called the service layer, which provides services to support the \napplication\
    \ layer. \n \n4. Middleware Architecture \n \nAnother important and very common\
    \ architecture in IoT is the middleware-\nbased IoT architecture or five-layer\
    \ architecture [68]. A five-layer is composed of \nfive levels: perception layer,\
    \ network layer, middleware layer, application layer, \nand business layer. \n\
    Middleware is gaining more and more importance in recent years due to its \nmajor\
    \ role in simplifying the development of new services and integrating legacy \n\
    technologies into new ones.  \nA proposed IoT architecture has to consider many\
    \ factors such as reliability, \ninteroperability, scalability, quality of service,\
    \ etc. In this regard, middleware \nbased IoT architectures help create applications\
    \ more efficiently; they act as a \nconnection between users, data and applications.\
    \ \nMiddleware, in general, is a software or programming service that can \nprovide\
    \ an interposed abstraction between IoT technologies and applications. In \nmiddleware,\
    \ the details of the different technologies are hidden, and standard \ninterfaces\
    \ are provided to allow developers to focus on application development \nwithout\
    \ regard to compatibility between applications and infrastructures. \nMiddleware\
    \ architecture has various advantages, as it can support various \napplications,\
    \ standard protocols, provides standard interfaces and can run on \nvarious operating\
    \ systems and platforms. Middleware plays an important role in \nstandardization,\
    \ providing portability and standard protocols to enable \ninteroperability and\
    \ interaction of services between heterogeneous networks, \ndevices and applications.\
    \ \nMiddleware supports distributed computing and provides a stable high-\nlevel\
    \ interface for applications. \nRegardless, the middleware layer has some critical\
    \ functionality, such as \naggregation and filtering of data received from hardware\
    \ devices, information \nretrieval and device access control for applications.\
    \ \n \n24 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn summary,\
    \ depending on the application, it may be necessary to add \nadditional layers\
    \ or adapt the architecture to the specific application to be \nrealized. An architecture\
    \ can be realized by being adapted to the context of \nexisting IoT architectures,\
    \ such as a server-based architecture, or an architecture \nbuilt from scratch\
    \ such as cloud-based architectures, Edge computing-based \narchitectures, or\
    \ Social Internet of Things (SIoT) architectures [67]. \n \n2.2.2. IoT Monitoring\
    \ and Control Based on Unmanned Vehicles \n \nA drone monitoring system is developed\
    \ as a control system to reduce the \ntime and cost of inspection. The integration\
    \ of drones or unmanned vehicles into \nthe IoT architecture can be presented\
    \ in three layers (Figure 2.2), with drones \nbeing part of the first layer as\
    \ the data generation layer. The first layer can also \ncontain a control system\
    \ connected to a central collection point, which is the IoT \ngateway. The second\
    \ layer is edge/fog computing for computation, storage and \ncommunications. The\
    \ last layer is a cloud back-end with image processing \ntechniques. The Edge/fog\
    \ layer connects the control layer to the drone system, \nthe drone system to\
    \ the cloud, and finally the cloud to the control system. \n \nIn general, the\
    \ Three-Layer architecture can be defined as below:  \n \n• Generation and control\
    \ layer: this represents the physical layer of the objects \nand includes all\
    \ the control systems. \n• Network and data communication layer (Edge/Fog): this\
    \ is the \ncommunication layer responsible for transmitting data to the visualization\
    \ \nand processing layer through various technologies and protocols, can also\
    \ be \nused as a processing layer in case of real time applications. \n• The visualization\
    \ and processing layer, which represents the application layer \nin which the\
    \ software offering a specific service is actually implemented or \nmay just be\
    \ an interface to analyze and visualize the data received from the \nconnected\
    \ systems. \n \n \n \n25 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nFigure 2.2. Industrial UV-IoT Architecture \n \n \nThe control system\
    \ (controllers) receives data from remote or connected \nsensors that measure\
    \ the process variables’ (PVs) setpoints (SP). When the system \ndetects a trend\
    \ change between PVs and SP, the change is routed to the \nprogrammable logic\
    \ controllers (PLCs) and the central point (IoT gateway) to \ntrigger the UV system’s\
    \ reaction. \nThe traditional monitoring system illustrated by humans is replaced\
    \ by a \nremote computing algorithm in the cloud and a UV system, in that the\
    \ UV camera \nserves as an additional monitoring sensor that is processed in the\
    \ cloud to imitate \nthe visual inspection of an operator. The UV can navigate\
    \ to a specific point to \noversee the process using the front camera. The UV\
    \ system is triggered \nautomatically by responding to sensor data from the monitoring\
    \ system and data \nanalyzed in the IoT gateway. The IoT gateway receives the\
    \ captured photos and \nsends them to the cloud, which adopts deep learning techniques\
    \ to analyze and \nsend the results to the IoT gateway and the control system\
    \ to confirm the \nanomaly and make the necessary changes. \n \n2.2.3 IoT Gateway\
    \ Capabilities \n \nThe IoT gateway is capable of connecting the sensor network\
    \ to the cloud \ninfrastructure, performing edge computing, and serving as a bridge\
    \ between the \nsensor networks and cloud services [69]. \n \n26 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nIn the IoT gateway, various software and\
    \ APIs can be installed to establish \nthe connection with different parts of\
    \ each IoT layer. It also allows collecting, \nprocessing, and transmitting the\
    \ data and results to other systems for further \nprocessing or decision making.\
    \ \n In the IoT gateway, various IoT software and APIs, drone libraries and AI\
    \ \nmodels can be installed. These packages are required to ensure the transmission\
    \ \nof data between the different systems according to the protocols involved.\
    \ Since \neach IoT system has its own communication protocol, the IoT gateway\
    \ has to \nsupport different communication protocols, which presents an interoperability\
    \ \nchallenge. \nAn IoT gateway can be defined as a physical device with software\
    \ programs \nand protocols that mediate between smart devices, sensors, controllers\
    \ and the \ncloud. The IoT gateway provides the necessary connectivity, security\
    \ and \nmanageability, while some of the existing devices cannot share data with\
    \ the \ncloud [70]. \n \n2.4 \nUV & IoT Protocols \n \n2.3.1 UV Protocols \n \n\
    Unmanned vehicles (UVs) are widely used for civilian and military \napplications.\
    \ They can be used for remote sensing, transportation, scientific \nresearch,\
    \ search and rescue, and armed attacks. They can be used in applications \nwhere\
    \ human presence is dangerous, or in repetitive surveillance and monitoring \n\
    tasks. Unmanned vehicles can be equipped with sensors, cameras, \ncommunication\
    \ equipment and weapons.  \nUVs are primarily equipped with omni-directional antennas,\
    \ although \ndirectional antennas can also be used to increase the gain of the\
    \ \ntransmitter/receiver, at the cost of designing a mechanism to control the\
    \ direction \nof the antenna.  \nUnmanned vehicles (UVs) can operate autonomously\
    \ or be remotely piloted \nby ground teams. UVs can communicate with the base\
    \ station using different \nprotocols, depending on the network structure and\
    \ the design of the UV system. \nCANbus (CANopen, NMEA2000), Ethernet and WiFi\
    \ (TCP/IP, UDP), RS232, are \nthe most commonly used protocols in autonomous vehicles.\
    \ In this section we \nwill mainly address the CANbus protocol. \n \n \n• CAN\
    \ Protocol \n \nBack in the 1980s, progress in automotive electronics had made\
    \ the number \nof devices that were suddenly required in vehicles grow in a worrying\
    \ way. All \nthese devices had to be connected in some way, generally to each\
    \ other, causing \n \n27 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nan alarming increase in the amount of wiring that had to be introduced into\
    \ a \nvehicle (As shown in Figure 2.3). All this led to problems of assembly,\
    \ \nstandardization of equipment, connections and weight. \nIn February 1986,\
    \ Robert Bosch presented CAN (Controller Area Network) \nat the Society of Automotive\
    \ Engineers (SAE) as a solution to the problem of \nwiring in vehicles. Intel,\
    \ as a manufacturer, and Mercedes-Benz, as a collaborator \nin the development\
    \ project, also worked together on developing the bus. \n \n \nFigure 2.3. Wiring\
    \ diagrams in vehicles before and after the appearance of CAN \n \nIn 1987, Intel\
    \ released the first CAN integrated, followed shortly after by \nPhilips Semiconductors.\
    \ After several improvements and disputes with other \nmanufacturers, it became\
    \ a standard (version 2.0) in 1993, the specifications of \nwhich are reflected\
    \ in ISO11898. Although CAN was initially developed for the \nautomotive industry,\
    \ its robustness and the efficiency of its protocol have \nallowed its entry into\
    \ many industrial applications requiring high transfer rates \nand high reliability\
    \ in the face of errors. Manufacturers in fields as diverse as \nelevators (Kone\
    \ in Finland) and textile machinery have used CAN in their \nproducts. \n \n \n\
    28 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nCAN Characteristics\
    \  \n \nCAN is one of the widest known vehicle bus standards for vehicle networks.\
    \ \nIt is very popular in industrial and automotive applications because of an\
    \ \naffordable and flexible design, which reduces the number of wires. For example,\
    \ \nthe number of wires has been reduced by 40% in the Peugeot 307, which \nincorporates\
    \ two CAN buses [71]. CAN is a message-based protocol; the packets \nhave no information\
    \ about the sender and receiver of the messages, and each \nnode can read the\
    \ messages transmitted over the bus. Functions supported by \nthe protocol in\
    \ the automotive domain are automatic start/stop, parking \nassistance, electric\
    \ parking brakes, collision avoidance, automatic lane detection, \netc. Figure\
    \ 2.4 shows a CAN bus node. It includes a central processing unit (CPU), \nthe\
    \ CAN controller and a transceiver. The function of the CPU is to decode the \n\
    received messages and decide which messages to transmit. Each node can send \n\
    or receive messages, but not simultaneously. A message or frame consists of an\
    \ \nID and a data payload of up to eight bytes (64 bits). \n \n \nFigure 2.4.\
    \ Controller area network bus node \n \nThe network uses two cables as a transmission\
    \ medium. The two cables are \nCAN High and CAN Low. All the system nodes connected\
    \ to the CAN bus \nthrough the corresponding hardware interface. All nodes share\
    \ the same data \nchannel. Each node consists of a CAN Transceiver, CAN Controller\
    \ and CPU as \nshown in Figure 2.5. \n \n \n29 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 2.5. Node of the CAN bus system \n \nThe CAN protocol is\
    \ optimized for short messages and uses a CSMA/CD \nwith NDBA (Carrier Sense Multiple\
    \ Access / Collision Detection with Non-\nDestructive Bitwise Arbitration) arbitration\
    \ access method. A node that needs to \ntransmit a message waits until the bus\
    \ is free and then starts to send the identifier \nof its message bit by bit.\
    \  \n \n2.3.2 IoT Protocols \n \nThere are a large number of protocols that can\
    \ be used in the IoT. Table 1 \nshows some of the most commonly used protocols,\
    \ grouped according to the \nISO/OSI model. Each has advantages and disadvantages,\
    \ and their use must be \nevaluated based on the application. The choice of which\
    \ protocol to use is \ndetermined by the size of the network, the energy consumption\
    \ of each node, \nand the transmission speed needed for a given application. For\
    \ instance, the IPv6 \nprotocol was born first to solve the problem of address\
    \ space (which, with the \nold IPv4 protocol, was about to run out) and second\
    \ to ensure scalability of \nsystems. Nevertheless, this protocol is designed\
    \ for wired networks. To address \nwireless sensor networks (WSN), the 6LoWPAN\
    \ protocol [72] was created. \n \nTable 2.1. Main protocols used in the IoT field\
    \ \nApplication Layer \nCoAP, MQTT, AMQP, XMPP, DSS \nService Discovery: mDMS,\
    \ DNS-SD, SSDP \nSecurity: TLS, DTLS \nTransport Layer \nTCP, UDP \nNetwork Layer\
    \ \nAddressing: IPv4/IPv6                Routing: RPL, CORPL, CARP, etc. \n \n\
    30 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nAdaption Layer \n6LoWPAN,\
    \ 6TiSCH, 6Lo, etc. \nData Link Layer \nIEEE 802.15.4       IEEE 802.15.1    \
    \ LPWAN      RFID, NFC  \n(ZigBee, etc.)        (Bluetooth)    (LoRaWAN, etc.)\
    \  \nIEEE 802.11      IEEE 802.3      IEEE 1901  \n(Wi-Fi)      (Ethernet)   \
    \   (PLC)      Z-Wave \nPhysical Layer \n \n \nIoT devices can support various\
    \ interoperable communication protocols, \nwhether Internet-related or service-related,\
    \ and can communicate with other \ndevices of different genre and infrastructure.\
    \  \n \n2-3-3. Industrial Protocols \n \nEtherCat, CANOpen, Modbus/Modbus TCP,\
    \ Ethernet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and Wireless\
    \ HART are the \nmost frequently used industrial protocols [18]. Until a few years\
    \ ago, \ncommunication systems for industrial automation only aimed at industry-\n\
    specific real-time performance and maintainability based on international \nstandards\
    \ [73]. The Industry 4.0 concept has the flexibility to provide \ninteroperability\
    \ between different industrial engineering systems. To connect \ndifferent industrial\
    \ equipment and systems, the same standards and security \nlevels are needed.\
    \ Open Platform Communications Unified Architecture (OPC \nUA) is a machine-to-machine\
    \ (M2M) communication protocol developed to \ncreate interoperable and reliable\
    \ communications and is now widely accepted as \na standard in industrial plant\
    \ communications [74]. \nAnother important industrial protocol that is still largely\
    \ used in most plants \nis MODBUS TCP exclusively for synchronous polling communications;\
    \ this \nsolution is compatible with most industrial control systems and SCADA-type\
    \ \napplications. However, if asynchronous event-based communications are \nrequired,\
    \ MQTT complements MODBUS TCP operations. The Message Queuing \nTelemetry Transport\
    \ (MQTT) is a lightweight, publish-subscribe network \nprotocol that transports\
    \ messages between IoT devices. An Industrial Internet of \nThings (IIoT) environment\
    \ integrates an event-based message-oriented protocol, \ni.e., MQTT, with a polling-based\
    \ request–response protocol, intended for \nindustrial applications, i.e., MODBUS\
    \ TCP.  \nMODBUS meets industrial requirements, primarily for remote control,\
    \ \nmonitoring and automation functions. MQTT works in parallel with MODBUS \n\
    TCP and complements its functions, however, cannot replace MODBUS [75]. \n \n\
    31 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nHTTP can also be used\
    \ in conjunction with MODBUS, as a web-based real-\ntime data monitoring system\
    \ that uses MODBUS TCP communications, in which \nall data is displayed in a real-time\
    \ graph in a web browser, which is refreshed at \nregular intervals using HTTP\
    \ polling communications [76]. \nThese protocols use the client–server communication\
    \ architecture. MQTT \nuses the publish–subscribe model and is message-oriented,\
    \ whereas HTTP uses \nthe request–response model and is a document-oriented protocol.\
    \ Thus, HTTP is \none-to-one (peer-to-peer), and MQTT is one-to-many. \nThe figure\
    \ 2.6 illustrates a comparison between the MODBUS philosophy \nand the MQTT philosophy\
    \ from a message exchange perspective. The MODBUS \nrequest uses a TCP connection\
    \ and employs a frame format based on an \noptimized application layer message\
    \ structure dedicated to telecontrol and \nmonitoring. The case is different with\
    \ MQTT; while the first client (publisher) \ngenerates an event using four messages,\
    \ the second client (subscriber) consumes \nthis event in six messages. \n \n\
    \ \nFigure 2.6. Comparison of protocols for the exchange of messages: (a) MQTT;\
    \ (b) \nMODBUS TCP. \n \n \nThe Internet of Engineering Task (IETF) has developed\
    \ a lighter application \nprotocol (Constrained Application Protocol (CoAP)) for\
    \ constrained IoT devices \noperating in lossy environments.    \nBased on UDP,\
    \ CoAP is an efficient and lightweight protocol compared to \nother IoT protocols\
    \ such as MQTT, HTTP, etc. CoAP also achieves reliable \ncommunication between\
    \ nodes in wireless sensor networks, along with features \nsuch as resource discovery,\
    \ resource observation, congestion control, etc. These \n \n32 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ncapabilities of CoAP have enabled CoAP\
    \ to be implemented in various domains \nranging from home automation to health\
    \ management systems [77]. \nCoAP uses a specific infrastructure—namely, 6LoWPAN\
    \ (IEEE802.15.4)—\nwhich employs IPv6 in the network layer. Both HTTP and MQTT\
    \ use an \ninexpensive and available communication infrastructure, which is Internet\
    \ or \nIntranet in wireless mode (Wi-Fi—IEEE 802.11) or wire mode (Ethernet—\n\
    IEEE802.3) —which may employ either IPv4 or IPv6 in the network layer. In the\
    \ \ntransport layer, HTTP and MQTT protocols use TCP port numbers 80 and 1883,\
    \ \nrespectively. However, CoAP uses UDP port number 5683. Given that MQTT is\
    \ \nevent-based, it is a message-oriented protocol. Thus, CoAP mimics HTTP in\
    \ \nusing polling-based messaging, but in a shorter time and smaller frame-size,\
    \ \ntable 2 depicts more the difference between these protocols. \n \nTable 2.2.\
    \ Comparison of Internet of Things (IoT) protocols \nFeature \n \nHTTP \nCoAP\
    \ \nMQTT \nMODBUS TCP \ninfrastructure \nnetwork layer \ntransport layer \ntransport\
    \ port \nmodel \npattern \nmechanism \nmethodology \nparadigm \nquality level\
    \ \nstandard \nencoding \nsecurity \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n80,\
    \ 443 \nsynchronous \nrequest-response \none-to-one \ndocument-oriented \nlong\
    \ polling-based \none level \nIETF (RFC7230) \nASCII text \nSSL, TLS \n6LoWPAN\
    \ \nIPv6 \nUDP \n5683 \nAsynchronous \nboth \none-to-one \ndocument-oriented \n\
    polling-based \ntwo: CON or NON \nIETF (RFC7252) \nRESTful (Binary) \nDTLS  \n\
    Ethernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n1883, 8883 \nasynchronous \npublish-subscribe\
    \ \none-to-many \nmessage-oriented \nevent-based \nthree: QoS 0, 1, 2 \nISO/IEC,\
    \ OASIS \nUTF-8 (Binary) \nSSL, TLS \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n\
    502, 802 \nSynchronous \nRequest-response \none-to-one \nbyte-oriented \npolling-based\
    \ \none level \nmodbus.org \nBinary \nTLS \n \nIn Figure 2.7, a comparison between\
    \ the different protocols is conducted \nbased on the protocol communication model\
    \ in the original IEEE model. CoAP \nruns over the connection less UDP in the\
    \ transport layer, whereas in the network \nlayer, CoAP uses either IPv6 or 6LoWPAN.\
    \ When CoAP uses IPv6, it is necessary \nfor it to use Ethernet or Wi-Fi for the\
    \ data link and physical layers, respectively. \nWhen CoAP uses 6LoWPAN, it employs\
    \ IEEE 802.15.4e for the data link and \nphysical layers. \nThe MODBUS TCP and\
    \ the MQTT protocols are both in the same level in the \nIEEE model. While the\
    \ MODBUS TCP uses a byte-encoded frame format for the \nuser data, which is intended\
    \ for industrial applications, the MQTT protocol \nencodes the user data in UTF-8.\
    \ \nThe content (payload) of HTTP may vary according to the type of transferred\
    \ \ndata, called content-type, which could be plain text, PDF application, HTML,\
    \ \nXML, GIF image or audio. For the exchange of data using HTTP, XML is used,\
    \ \nwhich handles verbose plain text for solving interoperability issues. However,\
    \ \n \n33 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nfor CoAP, the\
    \ efficient XML interchange (EXI) [78] is used, which encodes \nverbose XML documents\
    \ in binary format, if interoperability is considered [75]. \nThis is normally\
    \ used for constrained devices to increase the performance \nand decrease the\
    \ consumed power. Hence, CoAP is suitable for constrained \ndevices in IoT-based\
    \ wireless sensor networks that employ IPv6-based \ninfrastructure. However, it\
    \ needs a gateway to exchange data over the Internet. \n \n \n \nFigure 2.7. The\
    \ IEEE model (a); compared to the HTTP (b); the CoAP (c); the MODBUS \nTCP (d);\
    \ and the MQTT (e). \n \nIn summary, there are many IoT protocols, and event-based\
    \ protocols are of \nconsiderable interest for data transfer in the form of notifications\
    \ to complement \nthe MODBUS TCP protocol. This MODBUS protocol is polling-based,\
    \ \nsynchronous, request-response, and optimized for control and monitoring in\
    \ \nindustrial applications, it can establish an IIoT environment. MQTT can \n\
    complement MODBUS TCP with its asynchronous model, event-based \nparadigm, and\
    \ publish-subscribe model. On the other hand, CoAP requires a \nspecific infrastructure,\
    \ and a gateway to move data over the Internet, which adds \nadditional costs\
    \ and causes complications for the environment. \n \n2-3-4. OPC UA Protocol \n\
    \ \nThe Internet's ubiquity is unfortunately only one aspect of this new era,\
    \ not \neven the main one. The most studied topic is the utopian \"single protocol\"\
    \ (i.e., \naccepted by any application market, industry and consumer) that could\
    \ \nintelligently and flexibly describe methods and data. There are several examples\
    \ \nof shared and widely used protocols in specific application markets, and \n\
    probably in the industry the most accepted protocol that harmonizes machine-\n\
    to-machine (M2M) interaction is OPC UA (Open Process Communications \n \n34 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nUnified Architecture). The\
    \ OPC Foundation achieved great success with the \n\"OPC Classic\" protocol and\
    \ is now offering the OPC UA protocol as a more \npowerful successor for its platform-independent\
    \ architecture. \nOPC systems, particularly the latest OPC UA version, plays an\
    \ important \npart in current industrial environments, and more specifically to\
    \ sustain the \nupcoming IIoT environments [79-80]. Basically, they provide a\
    \ standard way to \nestablish a reliable and secure data exchange between industrial\
    \ devices from \nmultiple providers and software systems. This provides us with\
    \ an interface or \ngateway that allows us to interact directly with PLC. In fact,\
    \ OPC UA can be \nconsidered the basic protocol for harmonizing different industrial\
    \ automation \nnetworks and systems [73]. \nAs shown in Figure 2.8, OPC UA has\
    \ been designed to facilitate the exchange \nof information across the hierarchy\
    \ of systems that commonly coexist in industry: \ncontrol systems; manufacturing\
    \ execution systems (MES); enterprise resource \nplanning (ERP); and, finally,\
    \ field devices. OPC UA has a message-based \ncommunication and a service-oriented\
    \ architecture (SOA) with clients and \nservers connected to any types of networks.\
    \ \n \n \nFigure 2.8. OPC UA in the automation pyramid \n \n \nFigure 2.9 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called Address Space.  \n \n35 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nNodes are accessible by clients\
    \ using OPC UA services (interfaces and \nmethods) [80]. In other words, the OPC\
    \ UA address space is the information \nmodel for the communication: real hardware\
    \ devices or real software “objects” \n(sensors, actuators, software applications,\
    \ etc.) are available for OPC UA \ncommunication only if they are modelled, added\
    \ to the address space and finally \ndiscovered by the OPC UA clients. In the\
    \ OPC UA API, there is a discovery \nservice that can be used to find available\
    \ OPC UA servers and to explore their \naddress space. Clearly, the OPC UA communication\
    \ stack converts the calls to \nthe OPC UA API to proper messages for the underlying\
    \ network layers. \n \n \nFigure 2.9. Architecture of the OPC UA Server \n \n\
    \ \nA client application may use the OPC UA client API (application program \n\
    interface) in order to send/receive OPC UA service requests/responses to/from\
    \ \nthe OPC UA server. From the programmer point of view, the OPC UA client API\
    \ \nis like an interface that decouples the client application code from the client\
    \ OPC \nUA communication stack. \n  \n \n \n \n36 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nCHAPTER 3 \n \nRelated works and evaluation of the\
    \ \nlatency of the proposed architecture \n--------------------------------------------------\
    \ \n \n \n1- Introduction  \n \nOne of the main concerns of IoT is the interconnectivity\
    \ and integration of \ndifferent systems in the same architecture. Different challenges\
    \ can arise when it \ncomes to achieving this interconnectivity. \n Ensuring reliable\
    \ communications with all the devices and platforms \ninvolved is a major challenge\
    \ due to the diversity of protocols used in each \nconnected part. Interoperability\
    \ is considered as the primary issue to be solved, \nespecially when new technology\
    \ solutions need to be connected to existing \nnetworks. In addition, most IoT\
    \ architectures need to react in real time while \nensuring the highest level\
    \ of accuracy. Delay in connections affects not only the \ndecision-making, but\
    \ also the energy consumption for different energy \nconstrained devices [81].\
    \ \nThe use of new technologies and their connection to existing networks is \n\
    increasing. Different protocols, APIs and software have been introduced to \n\
    facilitate the interaction of connected systems and services. Node-RED, which\
    \ is \nan effective option for applications to prototype some IoT connectivity,\
    \ is a \ngraphical tool created by IBM to wire together hardware devices, APIs\
    \ and online \nservices. \nPython is also considered a programming tool for IoT\
    \ projects, which has \nbuilt-in support for scientific computing. Its use is\
    \ growing fastest in data science \nand machine learning. Versatility, stable\
    \ libraries with great support and ease of \nuse are its main advantages [82].\
    \ These platforms can be good solutions for \ninteroperability, as they have most\
    \ of the libraries that can facilitate connections \nbetween different systems.\
    \ \n \n37 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nThe communication\
    \ protocols of the IoT platform allow different devices to \ncommunicate and share\
    \ their data with controllers or decision centers. IoT \nplatforms offer the ability\
    \ to select the type of communication technologies based \non the needs of the\
    \ application. However, not all protocols can be used in all \nscenarios. \nIndustry\
    \ now faces the challenge of making the IT network compatible with \nits machines,\
    \ including interoperability, fog/cloud computing, security, latency, \nand quality\
    \ of service. One of the proposed solutions is smarter IoT gateways \n[83], which\
    \ are the bridges between the traditional network and sensor networks \n[84].\
    \ The IoT gateway provides the necessary connectivity, security, and \nmanageability,\
    \ while some of the existing devices cannot share data with the \ncloud [85].\
    \ \nMost of IoT gateways can support all the necessary tools and protocols \n\
    needed to provide communication, computation and storage. The IoT gateway \ncan\
    \ affect the performance of an IoT system in terms of latency and accuracy, \n\
    especially when different software and APIs are implemented. It can be \nconnected\
    \ to the physical layers and transmit the received data to be processed \nin the\
    \ cloud. Using the cloud for AI solutions has its advantages and \ndisadvantages.\
    \ The IoT gateway can be used to implement cloud-based AI \nmodels at the edge\
    \ for processing and decision making, which makes the choice \nof IoT gateway\
    \ selection so crucial for a high-performance IoT architecture. \n \n2- Related\
    \ works \n \n \n2-1 Industrial Protocols  \n \n \nEtherCat, CANOpen, Modbus/Modbus\
    \ TCP, EtherNet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and\
    \ Wireless HART are the \nmost frequently used industrial protocols [86]. Due\
    \ to the incompatible \ninformation models for the data and services of the different\
    \ protocols, \ninteroperability between the different systems with different protocols\
    \ is always \ndifficult. The Industry 4.0 concept has the flexibility to achieve\
    \ interoperability \nbetween the different industrial engineering systems. To\
    \ connect the different \nindustrial equipment and systems, the same standards\
    \ and safety levels are \nrequired. Open Platform Communications Unified Architecture\
    \ (OPC UA) is a \nmachine-to-machine (M2M) communications protocol developed to\
    \ create inter-\noperable and reliable communications and is now generally accepted\
    \ as standard \nin industrial plant communications [87]. OPC UA is an independent\
    \ service-\noriented architecture that integrates all the functionality of the\
    \ individual OPC \nClassic specifications into one extensible framework [88].\
    \ OPC UA enable to \n \n38 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nconnect sub-manufacturing systems and ensure real-time communication \nbetween\
    \ devices and can be deployed in a service-oriented architecture for the \noptimization\
    \ of industrial applications [89]. \n \nOPC UA can allocate all manufacturing\
    \ resources, including embedded \nsystems, to specific areas and extensible computing\
    \ nodes through the address \nspace and a pre-defined model. It solves the problem\
    \ of unified access to the \ninformation of different systems [10]. Infrastructure\
    \ protocols have been \nproposed in many studies; for instance, in [90-91] an\
    \ edge IoT gateway was \ndeveloped to extend the connectivity of MODBUS devices\
    \ to IoT by storing the \nscanned data from MODBUS devices locally and then transferring\
    \ the changes \nvia an MQTT publisher to MQTT clients via a broker. \n \n2-2 Visual\
    \ Programming Languages \n \nVisual Programming Languages (VPL) are widely used\
    \ in IoT applications, \nin [92], a survey on Visual Programming Languages (VPL)\
    \ for IoT was proposed. \nThe analysis mainly focused on comparing them on the\
    \ basis of the programming \nenvironment, project repository, licensing, and supported\
    \ platforms. Some of \nthem are Open-Source platforms, while others are proprietary.\
    \ Among the Open-\nSource platforms (Node-RED, Modkit, miniBloq, NooDL, NETLab,\
    \ Ardublock, \nand Scratch), only some can be programmed using a Web interface\
    \ and executed \non some dockers or on-cloud virtual machines. \nIn addition to\
    \ being open source and having the possibility of adding new \nmodules and functionalities,\
    \ Visual Programming Language (VPL) IoT platforms \nshould exhibit a number of\
    \ non-functional requirements \nThey should demonstrate the capabilities of robustness,\
    \ availability (in terms \nof availability and fault tolerance), scalability,\
    \ security, full respect for privacy, \ninteroperability and openness, etc. \n\
    There are tools that make it easier for devices and their functionality to be\
    \ \ncomposed and combined at a higher level with IoT applications. For the device\
    \ \nlevel, an example of a tool is Node-RED that supports IoT application \ndevelopment\
    \ with a visual flow programming approach (Figure 3.1). Node-RED \nprovides an\
    \ integrated view of the application and the network and interacts \nsimultaneously\
    \ with the different systems involved through different protocols. \nIn [73] Node-RED\
    \ is used in both the IIoT gateway and the Cloud application, \nwhere a methodology\
    \ is proposed to measure delay metrics in OPC UA systems \nto study the impact\
    \ that QoS parameters have on the communication delay from \nthe production line\
    \ to the Cloud and vice versa.  \n \n \n39 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.1. Node-Red Platform \n \nIn [93] Node-RED is proposed\
    \ and applied in an IoT application for oil \nleakage detection in wind turbine\
    \ bearings. In [94], a new method introduced to \nmigrate Node-RED workflows into\
    \ a decentralized execution environment, so \nthat such workflow scan run on Edge\
    \ networks, where nodes are extremely \ntransient in nature. \nThe programming\
    \ of IoT applications is carried out in several ways, using \ndifferent tools\
    \ [95]. For example, in the Google IoT platform, various \nprogramming languages,\
    \ such as Java, Node.js, Python, PHP, Go, Ruby, and C#, \ncan be utilized to program\
    \ data flows from devices to dashboards. In these cases, \ndata flows are deployed\
    \ using programming languages. \n \n2.3 IoT architecture for Robots \n \nImplementing\
    \ an Industry 4.0 architecture requires integration of the latest \ntechnologies,\
    \ for example, IIoT, cyber-physical systems, additive manufacturing, \nbig data\
    \ and data analytics, cyber-security, cloud and edge computing, \naugmented and\
    \ virtual reality, as well as autonomous robots and vehicles [96]. \nA typical\
    \ cloud robotics architecture is based on two elements: the cloud \nplatform and\
    \ its associated equipment and the bottom facility. Bottom facilities \nusually\
    \ encompass all kinds of mobile robots, unmanned aerial vehicles, \nmachines,\
    \ and other equipment [97]. The next generation of robots will include \ninterconnected\
    \ industrial robots [98], cobots [99] and autonomous land vehicles \n(AGVs) [100].\
    \ Cobots support human workers in various tasks, while robots can \ncarry out\
    \ specific tasks, such as looking for objects or transporting tools. \nUnmanned\
    \ Vehicles (UVs) are among the emerging robot technologies that \nleverage the\
    \ power of perception science and are now the preferred remote \n \n40 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nsensing system for gathering data over\
    \ long distances in difficult-to-access \nenvironments [101]. Drone cameras can\
    \ collect remotely sensed images from \ndifferent areas safely and efficiently.\
    \ \nUnmanned vehicles can be deployed in air (Unmanned Aerial Vehicles – \nUAV),\
    \ at the sea surface (Autonomous Surface Vehicles – ASV) or in the water \ncolumn\
    \ (Autonomous Underwater Vehicles – AUV). \nUAVs can save time and money in different\
    \ sectors, such as agriculture, \npublic safety, inspection and maintenance, transportation\
    \ and autonomous \ndelivery systems. This technological revolution was conceived\
    \ to make people’s \nlives easier and to provide machine-to-machine communications\
    \ without human \nintervention [102]. They can be used to check a given installation\
    \ or production \nareas, to transmit data, monitor construction processes, and\
    \ detect anomalies. \nFor instance, in [103], drones’ platform was deployed to\
    \ detect trees and \nbuildings close to power lines. They can also be deployed\
    \ to monitor oil, gas and \nwater pipelines. \nUAVs combined with digital image\
    \ processing have been applied to crack \nassessment as a cost-effective and time-effective\
    \ solution, instead of visual \nobservation [104]. In [105], Machine Learning\
    \ Techniques were used to estimate \nNitrogen nutrition levels in corn crops (Zea\
    \ mays). The work described in [106] \nintroduced a real-time drone surveillance\
    \ system to identify violent individuals \nin public areas by a ScatterNet hybrid\
    \ deep learning (SHDL) network. In [107], \nthe images from a drone camera were\
    \ processed by the bag-of-words algorithm \nto detect crops, soils and flooded\
    \ areas, with MATLAB to program the feature \nextraction algorithm. In [108],\
    \ a solution was proposed to detect a final target \nusing the drone’s camera.\
    \ The system implemented image processing algorithms \nusing the open-source computer\
    \ vision library OpenCV. Cloud solutions like \nGoogle AI, Amazon Web Services,\
    \ and IBM Watson offer on-demand access to \ntheir image recognition services\
    \ to connect with other systems on the internet. \nThe authors in [109] propose\
    \ to move computationally demanding object \nrecognition to a remote computing\
    \ cloud, instead of implementing it on the drone \nitself, by means of a cloud-based\
    \ approach that allows real-time performance \nwith hundreds of object categories.\
    \  \n \n2.4. Applications in Marine field \n \nMarine scientists and robotic engineers\
    \ now have at their disposal a \nheterogeneous collection of robotic vehicles,\
    \ including AUVs, deep-sea landing \nvehicles, unmanned/autonomous surface vehicles,\
    \ remotely operated vehicles, \nand gliders/drifters [110]. These robotic vehicles\
    \ are untethered, self-propelled, \nself-navigating vehicles that can operate\
    \ autonomously from a shore or vessel for \na period of hours to a few days and\
    \ carry scientific payloads to perform sampling \nin the marine environment [111].\
    \  \n \n41 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nDirect vision\
    \ or camera vision is the simplest way to acquire a wealth of \ninformation from\
    \ aquatic environments and plays a vital role in underwater \nrobots. AUVs equipped\
    \ with the most recent cameras are now capable of \ncollecting massive amounts\
    \ of data from the seabed [112]. Computer vision \nalgorithms for underwater robotic\
    \ systems are attracting attention due to \nsignificant advances in vision capacities.\
    \  \nThe authors of [113] propose a stereo-imaging technique for recovering \n\
    underwater images by considering the visibility coefficients. This stereo-imaging\
    \ \napproach was realized using real-time algorithms and was implemented in \n\
    AUVs. The authors of [114] propose the new Qu index, which is used to assess \n\
    the similarity of structures and colors in underwater images. The authors of [115]\
    \ \nintroduce a human perception technique, the High-Dynamic Range Visual \nDifference\
    \ Predictor 2, to predict both overall image quality and artefact \nvisibility.\
    \ The authors of [116] propose a real-time system for object recognition \nin\
    \ acoustic images. A 3D acoustic camera is implemented to produce range \nimages\
    \ of the underwater area [117]. The authors of [118] propose a system for \nautomatic\
    \ interpretation of 3D objects based on 2D image data generated by a \nsector\
    \ scanning sonar unit. Their overall interpretation achieves a success rate of\
    \ \n86% for underwater objects seen in various conditions. \n \nArtificial intelligence\
    \ and machine learning have been proposed to enhance \nAUV missions and analyze\
    \ their data. The authors of [119] describe a system for \nautomatically detecting\
    \ pipelines and other objects on the seabed. Artificial \nneural networks are\
    \ applied to classify, in real time, the pixels of the input image \nof the objects\
    \ into various classes. The authors of [120] propose CNN to learn a \nmatching\
    \ function that can be trained from labelled sonar images after pre-\nprocessing\
    \ to produce matching and non-matching pairs. The authors of [121] \ndescribe\
    \ a DL method to assist in identifying fish species on underwater images. \n \n\
    Collaboration between the QUT University of Australia, Google and the \nGreat\
    \ Barrier Reef Foundation developed the world’s first underwater robotics \nsystem\
    \ specifically designed for coral reef environments [122]. Using real-time \n\
    computer vision, processed on board the robot, it can identify harmful starfish\
    \ \nwith 99.4% accuracy [122]. Marine researchers and robotics specialists tested\
    \ the \neffectiveness of a CV system in identifying sea creatures and found it\
    \ be around \n80% accurate. The system can even be 93% accurate if enough data\
    \ is used to train \nthe algorithm [123]. \n \nUnmanned surface vehicles (USVs)\
    \ are the main investigation areas of \nmaritime autonomous surface ships (MASSs),\
    \ being used in surveillance, \nresearch, scientific investigation and security.\
    \ USVs are defined as self-contained \nunmanned, untethered vessels that can transit\
    \ on the surface of the water \nautonomously or be remotely controlled [124].\
    \ \n \n42 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nThrough\
    \ detailed maps and satellite navigation, an ASV can detect and avoid \nstatic\
    \ obstacles. For in instance, in [125] a performed approach was proposed \nusing\
    \ Google Maps to build a map of static obstacles. \n \nTo respond quickly and\
    \ effectively to the challenges of a highly dynamic \nenvironment, the ASV needs\
    \ on-board logic to monitor the scene, identify critical \nsituations, and perform\
    \ appropriate route modifications [126]. An outstanding \nfeature is its capacity\
    \ to recognize an obstacle at a safe distance and avoid a \ncollision by changing\
    \ its course. Kristan et al. [126] proposed a new graphical \nmodel that supplies\
    \ fast and continuous obstacle image-map estimation from a \nsingle video stream\
    \ captured on-board a USV. \nIn order to ensure accurate detection and tracking\
    \ of objects at sea, \nautonomous vessels require a range of sensing capabilities.\
    \ Radar can provide \nsuch an overview, although certain small vessels and floating\
    \ objects are \nchallenging to recognize. Computer vision by onboard cameras can\
    \ be used for \nthis as a reasonable alternative to a human lookout [127]. The\
    \ work proposed in \n[128] examines the technical challenges of marine image processing\
    \ and artificial \nvision problems for video streams generated by cameras. These\
    \ challenges \ninclude the dynamic nature of the background, the lack of static\
    \ cues, the \npresence of small faraway objects, and lighting effects. Authors\
    \ of [129] propose \na method of identifying and tracking vessels using video\
    \ streams of existing port \nand river surveillance systems. The method detects\
    \ all types of moving vessels, \noperates under varying lighting conditions, and\
    \ assigns a unique identifier to \neach vessel detected. \nIn [130], a monocular\
    \ camera mounted on a USV was used, automatic feature \nextraction and tracking\
    \ filter algorithms are applied for real-time vision-based \ndetection and tracking.\
    \ The approach aims to detect and track another surface \nvessel by deploying\
    \ computer vision techniques. \nNovel technology has already been deployed on\
    \ autonomous craft as part of \nthe Marine 4.0 concept, where AI, cloud, and edge\
    \ technologies are of great \nimportance. For instance, the IBM-funded project,\
    \ the Mayflower Autonomous \nShip (MAS), will use the IBM power servers, IBM Watson\
    \ AI, cloud, and edge \ncomputing technologies to navigate autonomously and avoid\
    \ ocean hazards as \nit travels from Plymouth (England, UK) to Plymouth (Massachusetts,\
    \ USA) [131] \n, thus expanding knowledge of the ocean and removing barriers to\
    \ marine \nresearch. In [132], a Google Cloud Machine Learning Engine is used\
    \ to deploy an \nAI-based object classification system: a software suite for detecting,\
    \ identifying, \nand tracking surface objects. It makes ships safer and more efficient\
    \ by \nautomatically analyzing data from a number of new sensors, along with the\
    \ \nship’s own automatic identification system (AIS) and radar. \nVision and image\
    \ processing applications can benefit from cloud computing, \nas many are data-\
    \ and compute-intensive. By remotely locating storage and \n \n43 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprocessing capabilities in the cloud,\
    \ image processing applications can be \ndeployed remotely and paid for by the\
    \ user in pay-as-you-go or pay-per-use \nbusiness models.  \nOverall, cloud, edge\
    \ and hybrid vision processing solutions each provide \nboth strengths and weaknesses;\
    \ assessing the capabilities of each will allow the \nselection of an optimal\
    \ strategy for any specific design situation. \n \n3. Artificial Intelligence\
    \ and Machine Vision \n \nArtificial intelligence (AI) is the intelligence achieved\
    \ by machines. The \nresearch field of AI is defined as the study of \"intelligent\
    \ agents\": any device that \nsenses its environment and performs actions that\
    \ maximize its chances of \nachieving a given goal [133].  In common parlance,\
    \ the term \"artificial \nintelligence\" is applied when a machine mimics the\
    \ \"cognitive\" functions that \nhumans associate with other human minds, such\
    \ as \"learning\" and \"problem \nsolving\". Capabilities currently classified\
    \ as AI include autonomous driving of \ncars, human speech understanding, high-level\
    \ competition in strategic gaming \nsystems, intelligent routing in content delivery\
    \ networks, military simulations, \nand complex data interpretation. \nThe central\
    \ problems of AI research include learning, planning, reasoning, \nknowledge,\
    \ communication, natural language processing, perception, and the \nability to\
    \ move and manipulate objects [134]. \nAs AI applications are recently also designed\
    \ for commercial solutions, it is \nobliged to deal with the wide availability\
    \ of GPUs (graphics processing units), \nwhich make parallel processing ever faster,\
    \ cheaper and more powerful. \nComputer processors are designed to handle just\
    \ about anything. Central \nprocessing units (CPUs), however, they are very limited\
    \ and, as such, can only \nperform certain mathematical calculations. Very complicated\
    \ combinations are \nimpractical because of the very long processing time. GPUs,\
    \ on the other hand, \nhave become so specialized that they outperform traditional\
    \ processors when it \ncomes to rendering large amounts of complex calculations.\
    \ GPUs offer 10 to 100 \ntimes the computational power of traditional CPUs, which\
    \ is one of the main \nreasons graphics cards are currently being used to power\
    \ some of the most \nadvanced neural networks responsible for deep learning [135].\
    \ \nDeep neural networks (DNNs), also known as deep learning (DL), are part \n\
    of the broad field of AI, which is the science and engineering of creating \n\
    intelligent machines with the ability to achieve goals like humans. Machine \n\
    learning is the subfield of computer science that, according to Arthur Samuel\
    \ in \n1959, gives \"computers the ability to learn without being explicitly \n\
    programmed\"[136]. Evolving from the study of pattern recognition and \ncomputational\
    \ learning theory in artificial intelligence, machine learning \nexplores the\
    \ study and construction of algorithms capable of learning from and \n \n44 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nmaking predictions about data\
    \ [137] by building a model from sample inputs. \nThe relationship between deep\
    \ learning and the whole of artificial intelligence is \nillustrated in Figure\
    \ 3.2. In other words, DL is the study of artificial neural \nnetworks and related\
    \ machine learning algorithms that contain more than one \nhidden layer (Figure\
    \ 3.5).  \n \n \n \nFigure 3.2. Deep learning in the context of artificial intelligence\
    \ \n \nThe upside of an efficient Machine Learning Algorithm is clear. Instead\
    \ of \nthe laborious and haphazard approach of creating a separate, customized\
    \ \nprogram to solve each individual problem in a domain, the single machine \n\
    learning algorithm simply has to learn, through a process called training, to\
    \ \nhandle each new problem. The brain is now considered the best \"machine\"\
    \ we \nknow for understanding and solving problems, so it is perfectly natural\
    \ to look \nto it for a machine learning approach. Therefore, a brain-inspired\
    \ computation is \na kind of algorithm or program that has some aspects of its\
    \ basic functionality or \nform inspired by the way the brain works. \nScientists\
    \ believe that the main computational component of the brain is the \nneuron.\
    \ There are about 86 billion neurons in the average human brain. The \nneurons\
    \ themselves are connected by a number of elements that enter them, \ncalled dendrites,\
    \ and one element that exits them, called an axon, as shown in \nFigure 3.3. The\
    \ neuron accepts signals that arrive via the dendrites, computes on \nthese signals\
    \ and outputs a signal to the axon. These input and output signals are \ncalled\
    \ activations. The axon of a neuron branches and is connected to the \ndendrites\
    \ of many other neurons. The connection between a branch of the axon \nand a dendrite\
    \ is called a synapse. It is estimated that there are 1014 to 1015 \nsynapses\
    \ in the average human brain [138]. A key feature of the synapse is that \nit\
    \ can scale the signal (xi) that passes through it, as shown in Figure 3.3.  \n\
    \ \n \n45 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 3.3.\
    \ Connections to a neuron in the brain. xi, wi, f (·), and b are the activations,\
    \ \nweights, nonlinear function, and bias, respectively \n \nThis scaling factor\
    \ can be called a weight (wi), and the brain is thought to \nlearn by changing\
    \ the weights associated with synapses. Thus, having different \nweights results\
    \ in different responses to an input. It is important to note that \nlearning\
    \ is the adjustment of weights in response to a learning stimulus, whereas \n\
    the organization (what we might think of as the program) of the brain remains\
    \ \nunchanged. This characteristic marks the brain as an excellent source of \n\
    inspiration for a machine learning algorithm. \nAs shown in figure 3.2, Within\
    \ the paradigm of brain-inspired computing \nexists a subarea called spiking computation.\
    \ The inspiration in this subarea is \ntaken from the fact that communication\
    \ in dendrites and axons are spike-shaped \npulses and that the information that\
    \ is transmitted is not based only on the \namplitude of the spike. Rather, it\
    \ also depends on the time at which the pulse \narrives and that the computation\
    \ that takes place in the neuron is a function not \nonly of a single value, but\
    \ of the pulse width and the temporal relationship \nbetween the different pulses.\
    \ In contrast to spiking computing, another sub-area \nof brain-inspired computing\
    \ is called neural networks, which is the focus of most \nresearch articles. \n\
    Neural networks are based on the notion that the computation of a neuron \nconsists\
    \ of a weighted sum of input values. These weighted sums reflect the \nscaling\
    \ of values by the synapses and the combination of those values in the \nneuron.\
    \ Moreover, the neuron does not simply produce this weighted sum, as \nthe computation\
    \ associated with a cascade of neurons would otherwise be a \nsimple linear algebra\
    \ operation. There is instead a functional operation within \nthe neuron that\
    \ is being performed on the combined inputs.   \nFigure 3.4 presents a diagrammatic\
    \ picture of a computational neural \nnetwork.  The neurons in the input layer\
    \ receive some values and propagate them \nto the neurons in the middle layer\
    \ of the network, which is also frequently called \n \n46 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \na “hidden layer.” The weighted sums from one or more\
    \ hidden layers are \nultimately propagated to the output layer, which presents\
    \ the final outputs of the \nnetwork to the user. To align brain-inspired terminology\
    \ with neural networks, \nthe outputs of the neurons are often referred to as\
    \ activations, and the synapses \nare often referred to as weights as shown in\
    \ Figure 3(a). \n \n \n \nFigure 3.4 Simple neural network example and terminology.\
    \  (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nAccording\
    \ to Figure 3.3, the computation of each layer can be expressed as \nfollow: \
    \ \n\U0001D44C\U0001D457= f (∑\n\U0001D44A\U0001D456\U0001D457 \n3\n\U0001D456\
    =1\n\U0001D465\U0001D456 + \U0001D44F)                                       \
    \          (3.1) \n \nWhere Wij, xi and yj are the weights, input activations,\
    \ and output activations, \nrespectively, and f (⋅) is a nonlinear function. The\
    \ bias term b is omitted from \nFigure 3.3 for simplicity. \n \n3.1 Inference\
    \ Versus Training \n \nThe IoT data can be used to train the machine learning\
    \ model and inference \nbefore technical professionals can begin to design a system\
    \ that integrates a \nmachine learning inference server with the IoT, the relationship\
    \ between how IoT \ndata can be used for training the machine learning model and\
    \ inference must be \nunderstood. Figure 3.6 compare the training with inference.\
    \ \n \n• Training \n \nTraining is the process of creating a machine learning\
    \ algorithm. Training \nimplies the use of a deep learning framework (e.g., TensorFlow)\
    \ and a training \ndataset (Figure 3.5). IoT data supplies a source of training\
    \ data that data scientists \n \n47 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand engineers can use to train machine learning models for a diversity of\
    \ use \ncases, from fault detection to consumer intelligence. \n \n \nFigure 3.5.\
    \ Training and inference comparison \n \n• Inference \n \nInference relates to\
    \ the process of using a trained machine learning algorithm \nto make a prediction.\
    \ IoT data can be used as input to a trained machine learning \nmodel, which enables\
    \ predictions that can provide guidance to decision-making \nlogic on the device,\
    \ at the edge gateway or elsewhere in the IoT system. \n \n2.4.2 Methods of Machine\
    \ Learning \n \nTwo of the most widely adopted machine learning methods are supervised\
    \ \nlearning and unsupervised learning. machine learning – about 70 percent –\
    \ is \nsupervised learning. Unsupervised learning accounts for 10 to 20 percent.\
    \ Semi-\nsupervised and reinforcement learning are two other technologies that\
    \ are \nsometimes used [139]. \n \n• Supervised learning  \n \nSupervised learning\
    \ algorithms are trained using labeled examples, typically \nan input where the\
    \ desired output is known. For example, a computer might \nhave data points labeled\
    \ \"R\" (works) or \"F\" (failure). The learning algorithm is \n \n48 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprovided with a set of inputs along with\
    \ the corresponding correct outputs, and \nthe algorithm learns by comparing its\
    \ actual output with the correct outputs to \nfind errors. It then modifies the\
    \ model accordingly.  \nBy means of methods such as regression, classification,\
    \ prediction and \ngradient boosting, supervised learning uses patterns to predict\
    \ label values in \nadditional unlabeled data. \n \n• Unsupervised learning  \n\
    \ \nUnsupervised learning is used with data that have no historical labels. The\
    \ \nsystem is not told the \"correct answer\". The algorithm is supposed to find\
    \ out \nwhat it is shown. The goal is to explore the data and find some structure\
    \ in it. \nUnsupervised learning performs well on transactional data. For instance,\
    \ it can \nidentify customer segments with similar attributes that later can be\
    \ treated in \nsimilar ways in marketing campaigns. Alternatively, it can find\
    \ the main \nattributes that separate customer segments from each other. Popular\
    \ techniques \ninclude nearest neighbor mapping, self-organizing maps, k-means\
    \ clustering and \nsingular value decomposition. These algorithms are also used\
    \ to recommend \nitems, segment text topics, and identify data outliers. \n \n\
    • Semi-supervised learning  \n \nSemi-supervised learning is used for the same\
    \ applications as supervised \nlearning. But it uses both labeled and unlabeled\
    \ data for training: usually a small \namount of labeled data with a large amount\
    \ of unlabeled data (unlabeled data is \nless expensive and costs less effort\
    \ to acquire). This type of learning can be used \nwith methods such as regression,\
    \ classification and prediction. Semi-supervised \nlearning is useful when the\
    \ cost associated with labeling is too high to allow a \nfully labeled training\
    \ process. Some of the earliest examples of this type include \nidentifying a\
    \ person's face on a webcam. \n \n• Reinforcement learning  \n \nReinforcement\
    \ learning is often used in the areas of robotics, gaming and \nnavigation with\
    \ reinforcement learning, the algorithm discovers, via trial and \nerror which\
    \ actions produce the greatest rewards. This type of learning has three \nmain\
    \ constituents: the agent (the learner or decision maker), the environment \n\
    (everything the agent interacts with) and the actions (what the agent can do).\
    \ The \ngoal is for the agent to choose the actions that maximize the expected\
    \ reward in \na given time. The agent will reach the goal much faster if it follows\
    \ a good policy. \nThus, the goal of reinforcement learning is to learn the best\
    \ policy. \n \n \n \n49 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n3.2 Convolutional Neural Network for Object Recognition \n \nSeveral deep\
    \ learning architectures, such as deep neural networks, deep \nconvolutional neural\
    \ networks, deep neural networks, and recurrent neural \nnetworks, have been applied\
    \ to fields such as audio recognition, computer vision, \nautomatic speech recognition,\
    \ natural language processing, and bioinformatics, \nwhere they have been shown\
    \ to produce state-of-the-art results on a variety of \ntasks. Deep neural networks\
    \ have demonstrated their ability to outperform other \nmachine learning algorithms\
    \ in tasks such as object recognition in the field of \ncomputer vision. \nApplying\
    \ computer vision to automatically detect objects is an extremely \nchallenging\
    \ task. Noise disturbance, complex background, occlusion, scale and \nattitude\
    \ changes, low resolution, and other factors strongly influence object \ndetection\
    \ capabilities. Conventional object detection methods, based on the \nhand-crafted\
    \ feature, are not robust to lighting changes, occlusions and \nvariations in\
    \ scale or lack of good generalization ability [140]. Unlike handmade \nfeatures,\
    \ which are designed in advance by human experts to extract a particular \nset\
    \ of chosen properties, the features extracted by CNN are learned from the data.\
    \ \nThe core idea behind this is to learn object models from raw pixel data rather\
    \ than \nusing hand-set features, as in traditional recognition approaches. Training\
    \ these \ndeep models usually requires large training datasets, although this\
    \ problem has \nalso been surmounted by new large-scale labelled datasets such\
    \ as ImageNet \n[141]. \nA convolutional neural network (CNN) works by combining\
    \ different layers \nof neurons that extract certain characteristics from the\
    \ image. Each layer learns a \ndifferent level of abstraction, and in the end\
    \ gives a prediction of whether the \nobject was detected or not [142]. Different\
    \ online resources on deep CNN \narchitectures and vision-related datasets have\
    \ been implemented and are \navailable on the internet.  \nCNN-based methods have\
    \ achieved significant advances in computer vision. \nIn the 2012 ImageNet Large\
    \ Scale Visual Recognition Challenge (ILSVRC) [143], \nHinton and his student\
    \ Krizhevsky [141] applied CNN to image classification \nand achieved a winning\
    \ top-5 test error rate of 15.3%, compared to the 26.2% \nachieved by the second-best\
    \ entry. Applying various convolutional filters, CNN \nmodels can capture the\
    \ high-level representation of the input data, making it \nhighly popular for\
    \ CV tasks. The breakthrough and rapid adoption of DL in 2012 \nbrought into existence\
    \ modern and highly accurate object detection algorithms \nand methods, such as\
    \ the regions with CNN features (R-CNN) method [144], fast \nR-CNN [145], faster\
    \ R-CN [146], RetinaNet [147] and fast yet highly accurate \nmethods like SSD\
    \ [148] and YOLO [149]. CNN-based methods can provide more \naccurate target boxes\
    \ and multi-level semantic information for identification and \nlocalization.\
    \ However, handcrafted features are complementary and can be \ncombined with CNN\
    \ for improved performance [150]. \n \n50 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nBy using the cloud infrastructure, it becomes possible to apply CNN\
    \ \ntechniques which are used in most object detection cloud services [151]. There\
    \ \nare two ways that can help leverage these techniques for a particular application.\
    \ \nThe first one consists of employing our own data and a framework in our own\
    \ \nmachine and training our custom model for custom object detection. The second\
    \ \nis to use cloud services through an API, which is a suite of machine learning\
    \ (ML) \nproducts and CV software development services that allows developers\
    \ with \nlimited ML expertise to train high-quality models specific to the needs\
    \ of their \nproject.  \n \n3.3 Deep Learning for Object Detection \n \nIn the\
    \ last decade, prominent applications like robotics, video surveillance, \nscene\
    \ understanding, and self-driving systems have initiated a significant \namount\
    \ of computer vision research. Thanks to the advancement of neural \nnetworks,\
    \ particularly deep learning, visual recognition systems have achieved \nimpressive\
    \ outcomes, especially in object detection. \nObject detection is the process\
    \ of identifying the instance of the class to which \nthe object belongs and estimating\
    \ its location by outputting the bounding box \naround the object [151]. Although\
    \ object detection and image classification both \nshare a common technical challenge,\
    \ they must handle significant numbers of \nhighly variable objects. Object detection\
    \ is more complex than image \nclassification due to the fact that it must identify\
    \ the precise location of the object \nof interest [152]. Being one of the main\
    \ computer vision issues, object detection is \ncapable of providing useful insights\
    \ for the semantic understanding of images \nand videos [153]. Object detection,\
    \ i.e., the detection of the positions and \ncategories of multiple instances\
    \ of objects in a single image, is a major challenge \nin a diverse set of applications\
    \ such as self-driving vehicles and robotics [154, \n155,156].  \nObject recognition\
    \ efficiency is steadily increasing, with advanced computer \nvision techniques\
    \ working successfully on a wide range of objects. Most of these \ntechniques\
    \ are based on deep learning with convolutional neural networks and \nhave achieved\
    \ impressive performance improvements in a variety of recognition \nproblems [157].\
    \ \n \n3.4 Cloud-Edge DL \n \nPublic clouds have emerged as a new opportunity\
    \ to deliver compute-\nintensive applications. A public cloud refers to a networked\
    \ set of computers that \nfurnish a variety of computing and storage resources\
    \ and offer the appearance of \nunlimited computing capacity on demand at a nominal\
    \ price and under a flexible \npricing model [158-159]. Deep Learning (DL) technology\
    \ is popular nowadays \n \n51 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthanks to its good results in the fields of object detection, image classification\
    \ and \nnatural language processing. The easy availability of powerful data sets\
    \ and \ngraphic processing units are the main reasons for DL’s present popularity.\
    \ \nSeveral smart DL-based applications and services have changed all kinds of\
    \ \npeople’s lives because of the significant advantages of deep learning in the\
    \ \ncomputer vision (CV) fields [160-161]. CV seeks to enable computer systems\
    \ to \nautomatically identify and understand the visual world, simulating human\
    \ \nvision [162]. Algorithms for visual perception tasks have been developed,\
    \ \nincluding (i) object recognition to identify specific objects in image data,\
    \ (ii) object \ndetection to locate semantic objects of a given class, and (iii)\
    \ scene understanding, \nto parse an image into meaningful segments for analysis\
    \ [163]. All these \nalgorithm techniques can be deployed in the cloud.  \nEdge\
    \ computing is progressively being merged with artificial intelligence \n(AI)\
    \ and is intended to migrate DL computation from the cloud to the edge, \nthereby\
    \ enabling distributed, reliable and low-latency intelligent services [161]. \n\
    DL services are implemented nearby the service requests and the cloud is only\
    \ \ninvolved when extra processing is needed [164]. Both the cloud and edge \n\
    computing are considered adequate platforms to incorporate artificial \nintelligence\
    \ approaches.  \n \n3.5 Cloud AI at the Edge \n \nCloud computing is also impacting\
    \ many applications that currently rely on \nlocal storage and processing power.\
    \ Cloud computing provides computing \nresources in the form of a service or application\
    \ over a network. Its services are \ngenerally divided into three categories:\
    \ Platform as-a-Service (PaaS), \nInfrastructure-as-a-Service (IaaS) and Software-as-a-Service\
    \ (SaaS). By remotely \nlocating storage and processing capacity, image processing\
    \ applications and \nmachine vision systems can be performed remotely and paid\
    \ for on a pay-per-\ndemand or pay-per-use business model. Cloud-based systems\
    \ optimally aim to \nautomatically balance and distribute processing loads. \n\
    Building a visual recognition model is a difficult and time-consuming task. \n\
    In addition, the training of deep neural networks demand access to massive data\
    \ \nand computing power, however this issue has also been overcome by new large-\n\
    scale tagged datasets such as ImageNet [165]. Fortunately, there are many ready-\n\
    to-run solutions on the market where these neural networks are often trained by\
    \ \nlower-cost and more powerful clusters of cloud GPUs. \nThese solutions were\
    \ developed by several companies such as Google, \nAmazon, Microsoft, IBM, and\
    \ others, and are provided in the form of application \nprogramming interfaces\
    \ (APIs) which can be integrated into various application. \nVision pre-trained\
    \ models are either hosted for private use or offered as public \nservices for\
    \ deep learning in the cloud [165]. To use the pre-trained cloud-based \n \n52\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmodels, application\
    \ developers employ the cloud-exposed APIs to offload deep \nlearning inference\
    \ tasks to the hosting server. \n \nThe advantage of a customized AI model is\
    \ the possibility to train it \naccording to the use case, in addition to detecting\
    \ the location of objects in the \nimage. The AI model can be trained to identify\
    \ different types of objects and their \nposition in an image. The trained custom\
    \ object detection model in the cloud can \nbe further implemented in an IoT gateway,\
    \ as the cloud service supports the edge \ncomputing option. \nEdge computing\
    \ has recently been envisioned to push cloud computing \nservices closer to IoT\
    \ devices and data sources. Edge computing is designed to \ndrive low-latency\
    \ data processing by migrating computing capacity from the \ncloud data centre\
    \ to the edge [166-167]. Influential cloud computing vendors, \nsuch as Google\
    \ [168] and Microsoft Azure [169], have released service platforms \nto drive\
    \ intelligence to the edge, allowing end devices to execute machine \nlearning\
    \ inference locally with pre-formed models. \nFigure 3.6 describes the six different\
    \ ways of using edge intelligence for ML \napplications, in which the edge can\
    \ be combined with the cloud or used alone for \nthe entire application process.\
    \ In this paper, we adopt two main methods: the \ncloud intelligence method, in\
    \ which training and inferencing are both performed \nin the cloud, and the Level\
    \ 3 method, with on-device inference and cloud \ntraining. \n \n \nFigure 3.6.\
    \ Six-level rating for edge intelligence [170] \n \n \n \n \n \n53 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n3.6  Evaluating performance of an object\
    \ detection model \n \nRapid advances in DL and improvements in device capabilities,\
    \ \nincorporating image sensor resolution, and optics, power consumption, memory\
    \ \ncapacity and computing power, have enhanced the cost-effectiveness and \n\
    efficiency of accelerating the spread of vision-based applications. Compared to\
    \ \ntraditional CV techniques, the DL allows CV engineers to achieve greater task\
    \ \naccuracy [171]. The neural networks used in DL are trained rather than \n\
    programmed; therefore, applications using this method often require less expert\
    \ \nanalysis and tuning and leverage the large amount of video data already present\
    \ \nin current systems. \nThe potential of cloud-based platforms is expected to\
    \ be exploited in the \nfuture for the development of computationally intensive\
    \ CNN applications [172]. \nThe obvious advantage is the possibility of creating\
    \ intelligent systems with \nlonger battery life, because the intense calculations\
    \ are performed elsewhere. \nWide and deep CNNs present a major challenge for\
    \ deployment and \nexecution on resource-constrained devices. Cloud computing\
    \ not only enables \nthe handling of massive amounts of data, but also takes advantage\
    \ of the benefit \nof high computing efficiency at a negligible cost. World leaders\
    \ such as Google, \nAmazon, IBM, and Microsoft offer the public highly scalable,\
    \ fast, and flexible \ncloud computing facilities to train CNN’s resource-hungry\
    \ architectures. The \ncloud environment also facilitates setting up libraries\
    \ for both researchers and \nnew practitioners. \nIn computer vision, one of the\
    \ most powerful algorithms is object detection, \nwhich aids in the classification\
    \ and localization of objects. Object detection is \nmore complicated due to the\
    \ fact that it requires drawing a bounding box around \neach object in the image.\
    \ \nMultiple deep learning algorithms exist for object detection like RCNN: Fast\
    \ \nRCNN, Faster RCNN, YOLO, Mask RCNN, etc. Moreover, Azure Custom Vision, \n\
    Google cloud and IBM Watson services allow users to load an image dataset to \n\
    classify or define the bounding box for each desired object in the image for \n\
    training. \nThe objective of an object detection model is to perform object classification\
    \ \nand localization, the former is to identify whether an object is present in\
    \ the \nimage and the class of the object, and the latter is to predict the boundary\
    \ box \ncoordinates around the object when an object is present in the image.\
    \ \nClassification models are evaluated on accuracy, precision, and recall, while\
    \ \nfor object detection, the concept of intersection over union (IoU) is employed\
    \ \n(Figure 3.7).  \nPrecision indicates the fraction of identified classifications\
    \ that are correct, \nwhile recall indicates the fraction of actual classifications\
    \ that are correctly \nidentified. IoU (intersection on union) is a measure of\
    \ how well a model predicts \n \n54 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthe location of objects and is evaluated using the area of overlap of the\
    \ predicted \nbounding box regions and the ground truth, defined as follows: \n\
    \ \n\U0001D43C\U0001D45C\U0001D448 =\n\U0001D434\U0001D45F\U0001D452\U0001D44E\
    \ \U0001D45C\U0001D453 \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\
    \U0001D45D\n\U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\
    \U0001D45B\U0001D456\U0001D45C\U0001D45B                                     \
    \              (3.2) \n \n \n \n \nFigure 3.7. IoU equation, Red is ground truth\
    \ bounding box and green is \npredicted bounding box \n \nPrecision indicates\
    \ the fraction of identified detections that were correct, and \nrecall indicates\
    \ the fraction of actual detections that were correctly \nidentified. FP (False\
    \ Positive) represents the number of negative samples judged \nto be positive,\
    \ TP (True Positive) is the number of positive samples judged to be \npositive,\
    \ and FN (False Negative) is the number of positive samples judged to be \nnegative.\
    \ \n \n\U0001D443\U0001D45F\U0001D452\U0001D450\U0001D456\U0001D460\U0001D456\U0001D45C\
    \U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\U0001D443+\U0001D447\U0001D443\
    \                                                 (3.3) \n \n\U0001D445\U0001D452\
    \U0001D450\U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441\
    +\U0001D447\U0001D443                                                  (3.4) \n\
    \ \n \n4. Latency Assessment  \n \nOne of the important challenges to overcome\
    \ is the high-latency and \nunreliable link issues between the cloud and the IIoT\
    \ terminals. Fog computing \nextends computing and storage to the network edge\
    \ and is not only considered \nfor computation and storage, but also as a way\
    \ of integrating new systems \ncapable of interconnecting urgent and complex processing\
    \ systems. However, \neach fog and edge application may have different latency\
    \ requirements and may \ngenerate different types of data and network traffic\
    \ [173].  \n \n \n \n55 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n4-1 Latency between Two Terminals \n \nLatency is the time network traffic\
    \ delayed by the system processing, or the \ntotal time needed to send a network\
    \ packet from the application on one server to \nthe application on another server\
    \ through the network interface controller (NIC), \nnetwork (cable, Wi-Fi etc.),\
    \ and into an application on another server (or client). \nTo assess the latency\
    \ between two terminals, most approaches use the round-trip \ndelay time (RTD)\
    \ or the one-way delay (OWD). The latency in the context of \nnetworking is the\
    \ time spent by propagation through the network support and \nhardware of the\
    \ adapter, as well as the software execution times (application and \nOS) (Figure\
    \ 3.8). \n \n \n \nFigure 3.8. Latency between two terminals in a network \n \n\
    The hardware latency inside switches and on wires can be easily identified \n\
    from the switch specifications, length of the wires, and the maximal transmission\
    \ \ndata rates, while the software latency imposed by processing a packet in the\
    \ \nsoftware stack is more arduous to evaluate. Several parameters like system\
    \ \nworkload, operating system and executed application influence software latency.\
    \ \nEquation 3.5 defines the RTD between two terminals in a network, where tA\
    \ \nand tB are the software latency of the terminals A and B respectively, and\
    \ tH \nmarks the hardware latency of switches and wires connecting the terminals\
    \ A \nand B.  \n \n\U0001D445\U0001D447\U0001D437 = 2 \U0001D442\U0001D44A\U0001D437\
    \ = 2 \U0001D461\U0001D434 + 2 \U0001D461\U0001D43B + 2 \U0001D461\U0001D435 \
    \                                (3.5) \n \nTo accurately calculate OWD (by dividing\
    \ the round-trip time by two), the \nconfiguration of the test systems must be\
    \ perfectly symmetrical, meaning they \n \n56 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nmust be running the same software, using the same settings, and have\
    \ equal \nnetwork and system performance. \n \n4-2 OPC UA Architecture and delay\
    \ assessment  \n \nA client application may use the OPC UA client API (application\
    \ program \ninterface) in order to send/receive OPC UA service requests or responses\
    \ to or \nfrom the OPC UA server. From the programmer point of view, the OPC UA\
    \ client \nAPI is like an interface that decouples the client application code\
    \ from the client \nOPC UA communication stack. \n \nIn this section, we analyze\
    \ the delays involved in client-server OPC UA \ncommunications in a switched Ethernet\
    \ network. This model serves to define in \ndetail the non-deterministic sources\
    \ of end-to-end delay. The proposed model is \nbased on time delays defined in\
    \ [174-175] in an Ethernet-based network. Figure \n3.9 shows the round-trip data\
    \ path from an OPC UA server in PLC automate to \nan OPC UA client on the IoT\
    \ gateway and the hardware OWD required. \n \n \n \nFigure 3.9. OPC UA delay in\
    \ OPC UA client server in an Ethernet network \n \nWe consider the end-to-end\
    \ network delay in the switches and wires from \nthe client request to the server,\
    \ which can be divided into three categories, the \nframe transmission delay (dt),\
    \ the time required to transmit all of the packet’s \nbits to the link, the propagation\
    \ delay (dl), the time for one bit to propagate from \nsource to destination at\
    \ propagation speed of the link, and the switching delays \n(ds), which depend\
    \ on the route through the network to the server. \nThe transmission delay depends\
    \ on the length of packet L and capacity of \nlink C. The propagation delay is\
    \ related to the distance between two switches \nand the propagation speed of\
    \ the link S.  \n \n57 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n\U0001D451\U0001D459 =\n\U0001D437\n\U0001D446  , \U0001D451\U0001D461\
    \ =\n\U0001D43F\n\U0001D436                                                  \
    \      \n(3.6) \n \nThe switch delay is defined as the time for one bit to traverse\
    \ from switch \ninput port to the switch output port. It is divided into four\
    \ delays: the first is the \nswitch input delay (dSin), the delay of the switch\
    \ ingress port, including the \nreception of the PHY and MAC latency. The second\
    \ is the switch output delay \n(dSout), the delay of the switch egress port, including\
    \ the transmission PHY and \nMAC latency. The third delay is the switch queuing\
    \ delay (dSq), the time a frame \nwaits in the egress port of a switch to start\
    \ the transmission onto the link. The last \nis the switch processing delay (dSp),\
    \ the time required to examine the packet’s \nheader and determine where to direct\
    \ the packet is part of the processing delay.  \n \n\U0001D451\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D446\U0001D456\U0001D45B + \U0001D451\U0001D446\U0001D45D\
    \ + \U0001D451\U0001D446\U0001D45C\U0001D462\U0001D461 + \U0001D451\U0001D446\U0001D45E\
    (\U0001D461)                                     (3.7) \n \nThe hardware end-to-end\
    \ delay dCS presented as a request from an endpoint \nserver S to the destination\
    \ endpoint in a client C can be expressed as the sum of \nthe delays of all the\
    \ switches and links in the path, n being the number of links \nand n − 1 the\
    \ number of switches along the path.  \n \n\U0001D451\U0001D436\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D461 + ∑\n(\U0001D451\U0001D459,\U0001D456) + ∑\n\U0001D45B\
    −1 \U0001D451\U0001D460,\U0001D456(\U0001D461) \n\U0001D456=1\n \n\U0001D45B\n\
    \U0001D456=1\n                                   (3.8) \n \nFigure 2.8 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called AddressSpace. \nNodes are accessible\
    \ by clients using OPC UA services (interfaces and methods) \n[176]. \n \nIn the\
    \ case of m number of requests from clients to the nodes in the OPC UA \nserver,\
    \ the overall hardware end-to-end delay of the OPC UA client-server (dCS) \ncommunication\
    \ over an Ethernet network, when there are m requests from the \nclient to the\
    \ server, is presented as: \n \n\U0001D461\U0001D43B = \U0001D451\U0001D436\U0001D446\
    (\U0001D461) =  ∑\n(\U0001D451\U0001D461,\U0001D457) + ∑\n(\U0001D451\U0001D459\
    ,\U0001D456) + ∑\n\U0001D45B−1(\U0001D451\U0001D460,\U0001D456)\n\U0001D456=1\n\
    \U0001D45B\n\U0001D456=1\n\U0001D45A\n\U0001D457=1\n                         \
    \    (3.9) \n \n \n \n58 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nBy analyzing all the delays mentioned in the hardware, we admit that the \n\
    end-to-end delay on Ethernet network is deterministic, except the delay in the\
    \ \nswitch queue, which depends on the link utilization. The packet queuing delay\
    \ \nincreases in a frequently used link. \nBy investigating the hardware delays\
    \ for an OPC UA client/server \ncommunication in an Ethernet network, we conclude\
    \ that it is hard to define \nexactly the hardware delay on the account of the\
    \ queuing delay. In that case, \nwhen it comes to complex processes with real-time\
    \ requirements, OPC UA \nreaches its limits. Different ways of defining this delay\
    \ exist, for example QoS \ntechniques such as WFQ (weighted fair queuing) or strict\
    \ priority [177]; \nnevertheless, there is always a certain amount of delay and\
    \ jitter that limits real-\ntime performance. Time sensitive networking (TSN)\
    \ provides mechanisms for \nthe transmission of time-sensitive data over Ethernet\
    \ networks. The adoption of \nOPC-UA over TSN will also drive this paradigm in\
    \ the world of deterministic \nand real-time machine to machine communications.\
    \ TSN provides mechanisms \nfor the transmission of time-sensitive data over Ethernet\
    \ networks. With \nEthernet’s limitations in terms of traffic prioritization,\
    \ the TSN working group \nhas developed the time-aware scheduler (TAS), defined\
    \ in 802.1Qbv [178]. TAS \nis based on TDMA, which solves the problem of synchronization\
    \ and traffic \npriority in the Ethernet. By using this technique, queuing delay\
    \ can be completely \neliminated, hence the end-to-end latency becomes deterministic.\
    \ This technique \nwas adopted in [179] to evaluate OPC UA performance on TSN\
    \ with the most \ncommonly used communication technologies. \n \n3-3 UAV System\
    \ Delay \n \nThere are several ways to introduce latency in a drone’s video compression\
    \ \nand transmission system. The end-to end delay in the system can be divided\
    \ into \nseven categories (Figure.3.10): Tcap is the capture time, Tenc the time\
    \ required to \nencode, the resulting transmission delay is Ttx, Tnw is the delay\
    \ network when \nthe drone is connected to the remote ground station via a network,\
    \ Trx is due to \nthe ground station also being wirelessly connected to a network,\
    \ Tdec is the \ndecoding delay at the reception station, and Tdisp is the display\
    \ latency.  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D45B\
    \U0001D464 + \U0001D447\U0001D45F\U0001D465 + \U0001D447\U0001D451\U0001D452\U0001D450\
    \ + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D                       \
    \          (3.10) \n \n \n \n \n \n59 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.10 Video transmission system delay sources. \n \nNote\
    \ that when the drone is communicating directly with the ground station, \nno\
    \ network is involved and there is only a single transmission delay (Tnw = 0 \n\
    and Trx = 0).  \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D    \
    \                                    (3.11) \n \nIn the H.264 system, each video\
    \ frame is organized into slices which are in \nturn divided into non-overlapping\
    \ blocks and macro-blocks (two-dimensional \nunit of a video frame). Every slice\
    \ is independently encoded and can decode itself \nwithout reference to another\
    \ slice. The main advantage of this system is that it is \nnot required to wait\
    \ for the entire frame to be captured before starting to encode. \nAs soon as\
    \ one slice is captured, the encoding process can start, and slice \ntransmission\
    \ can begin. This technique has a consistent effect on the overall \nlatency as\
    \ it influences all the system latencies from encoding to display. \nTheoretically,\
    \ we define the overall latency by the number of slices N, \nalthough in practice\
    \ this may not be the case due to setting up and processing \nindividual slices.\
    \  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D441. (\U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D)   \
    \                               (3.12) \n \nIn order to efficiently transmit and\
    \ minimize the bandwidth, it is important \nto use video compression techniques,\
    \ although the slice technique also has an \neffect on the compression ratio.\
    \ The higher the number of slices, the faster they \ncan be encoded and transmitted,\
    \ although as this number increases, the number \nof bits used for a slice and\
    \ the effective slice transmission time also increase. \nOther types of delay\
    \ also affect the overall delay. Some factors can be \nadjusted when a UAV system\
    \ is used. For example, Tcap depends on the frame \nrate of the UAV camera, the\
    \ higher the frame rate, the shorter the capture time. \nTx relies on the available\
    \ data bandwidth of the transmission channel, while \nTdisp (video capture) is\
    \ based on the refresh rate of the display. \n \n \n \n \n \n \n60 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \n \n \n \nCHAPTER 4 \n \n--------------------------------------------------\
    \ \n \nEnergy Efficiency and Latency of Smart \nIoT Monitoring and Control Systems\
    \ \nBased on cloud Computing and \nIntelligent Machine Vision \n \n \n--------------------------------------------------\
    \ \n \n \n \n \nI. Smart Industrial IoT Monitoring and Control \nSystems Based\
    \ on cloud Computing and Intelligent \nMachine Vision \n \n61 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n1. Introduction   \n \nIndustry 4.0 is the information-intensive\
    \ transformation trend towards \nautomation and data exchange of manufacturing\
    \ technologies and processes \nincluding, robotics, cyber-physical systems (CPS),\
    \ the Internet of things (IoT), the \nInternet of services (IoS), cloud manufacturing,\
    \ big data and augmented reality \n[180]. Industry 4.0, the Fourth Industrial\
    \ Revolution, has already made \nsignificant changes to manufacturing and production\
    \ industries and offers a \nwealth of opportunities. Nevertheless, numerous issues\
    \ are also becoming the \nfocus of active research. These relate to concerns about\
    \ delays, data security, \ndevice communication and service availability. The\
    \ lack of ubiquitous \ninteroperability between heterogeneous devices is also\
    \ a major concern. \nAttempting to achieve seamless interoperability is further\
    \ complicated by the \nlong life of typical industrial equipment, to which costly\
    \ upgrades or \nreplacements are required to operate with the latest technologies\
    \ [181].  \nDue to the interactions between servers and IoT devices, massive amounts\
    \ of \ndata need to be transmitted through the IoT network, raising significant\
    \ data \ntransmission overhead to the network. As a number of IIoT systems are\
    \ time \nsensitive, the large increase in network traffic causes high network\
    \ latency and \nlarge packet loss, significantly affecting the performance of\
    \ IIoT systems. Fog \ncomputing is a potential middleware that can be very useful\
    \ for various \nindustrial scenarios. Since industrial processes require most\
    \ tasks to be carried \nout locally due to time and security limitations. Fog\
    \ computing can reduce and \nrefine large industrial data locally, before it is\
    \ sent to the cloud. Also, it can \nprovide local processing support with acceptable\
    \ latency for robots and actuators \nin a manufacturing industry [182]. However,\
    \ each fog and edge application may \nhave different latency requirements and\
    \ may generate different types of data and \nnetwork traffic [183]. \nRecent advances\
    \ in robotics, geomatics, and computer vision technologies \nhave made it possible\
    \ to capture an enormous amount of visual data using low-\ncost unmanned aerial\
    \ vehicles (UAVs). As a kind of flexible, fast and low-cost \ndata acquisition\
    \ system, UAVs have demonstrated great capabilities in \nperforming numerous mapping,\
    \ surveying and remote sensing tasks with very \nhigh-resolution data [184]. \n\
    UAVs have been widely used in manufacturing companies to monitor \njobsites in\
    \ real time and to provide high-definition (HD) images and video to \nidentify\
    \ changes and solve or prevent many problems [185]. They have also been \nused\
    \ for maintenance, inspection and tasks that are dangerous, inaccessible or \n\
    costly from the ground [186]. The integration of UAVs in the IoT represents an\
    \ \ninteroperability challenge, since each IoT system has its own communication\
    \ \n \n62 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nprotocol. Besides,\
    \ a small delay or error beyond the tolerated limit could result \nin a disaster\
    \ for various applications, such as manufacturing and monitoring of \naircraft\
    \ and UAVs.  \nUAVs technology has undergone a significant transformation and\
    \ has found \napplications in different fields, the off-board base station gives\
    \ them higher \ncomputational capacity and the ability to carry out more complex\
    \ actions using \nhigh-level programming languages, or leveraging services from\
    \ computer vision \ntools by acquiring, processing, analyzing and understanding\
    \ digital images in \nreal-time.  \nCrack assessment systems for concrete structures\
    \ are constantly improving \nthanks to computer vision technologies and UAVs.\
    \ UAVs combined with digital \nimage processing have been applied to crack assessment\
    \ as a cost-effective and \ntime-effective solution, instead of visual observation\
    \ [187]. Image recognition \ntechnology has a great potential in various industries\
    \ and has been improved by \ndeep learning and machine learning image recognition\
    \ systems (TensorFlow, \nand MATLAB) or image processing techniques such as computer\
    \ algorithms for \ndigital image processing. \n \nConcrete batching plant also\
    \ is a critical process, which is susceptible to \nchanges of mixed materials.\
    \ Due to some errors in the discharge and filtering \nprocess, these materials\
    \ are sometimes mixed incorrectly, which affects the \nquality and consistency\
    \ of the concrete. The drone's camera and cloud-based \nservices can identify\
    \ the condition of the aggregates being transported on the \nconveyor belts so\
    \ that adjustments can be made to the production process. \n \nImage processing\
    \ has become a significant asset for UAVs systems and not \nonly in industry.\
    \ Capturing footage and videos generates a huge amount of data, \nfor which cloud\
    \ computing is vital [188]. \nComputing capabilities can be extended to the cloud,\
    \ taking advantage of the \nservices offered, and saving the cost and energy consumption\
    \ of an embedded \nUAV system. While the fog can be responsible for technical\
    \ assistance between \nhumans and machines, information transparency, interoperability,\
    \ decentralized \ndecision-making, information security, and data analysis.  \n\
    The rest of this chapter is organized as follows, we introduce the proposed \n\
    the three-layer IIoT-based UAV architecture, then we define the different \nprotocols\
    \ and applications used to connect the different systems. Following, we \ndiscuss\
    \ three-layer architecture latency using different IoT gateways in the fog \n\
    layer.  \n \n2. System model \n \n \n63 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nA three-layer IIoT-based UAV architecture (Industrial IoT) is considered\
    \ in \nthis work. An IIoT monitoring and control system based on a UAV integrated\
    \ \ninto traditional industrial control system architecture. The first layer consists\
    \ of \ntwo different systems, the first is industrial control system connected\
    \ to \nindustrial sensors, actuators and PLCs, and the second is the UAV monitoring\
    \ \nsystem. The second layer is the fog computing layer for storage, computing\
    \ and \ncommunications. The last layer is a cloud computing layer with image processing\
    \ \nservices. Communication between the layers and systems is provided by the\
    \ IoT \ngateway installed in the fog layer, which links securely in real time\
    \ the industrial \ncontrol layer to the UAV system, the UAV system to the cloud,\
    \ and finally the \ncloud to the industrial control system. We validated our design\
    \ proposal in an \nindustrial concrete manufacturing plant as a case study with\
    \ the aim of \nimproving production and reducing costs. \n \n \nFigure 4.1: Proposed\
    \ UAV-IIoT Platform \n \nThe control system receives data from remote or connected\
    \ sensors that \nmeasure set points (SP) of process variables (PV). When the system\
    \ detects a \nchange in trend between the PVs and SPs, the change is routed to\
    \ PLCs and the \nIoT Gateway that triggers the UAV system's reaction. The UAV\
    \ goes to a specific \npoint to supervise the process using the front camera.\
    \ Once the images are \ncaptured, the IoT Gateway receives them and sends them\
    \ to the cloud, which \nadopts deep learning techniques to analyze and send the\
    \ results to the IoT \nGateway and the control system to confirm the anomaly.\
    \ The fog layer is \nresponsible for communications between all other layers;\
    \ it automatically makes \ndecisions based on the results and data received and\
    \ transmits the results to other \napplications and layers. The fog layer, presented\
    \ as an IoT gateway, can support \nall the necessary tools and protocols to ensure\
    \ storage, communication and \ncomputing. Between the different layers of the\
    \ IIoT-UAV proposed architecture, \nthere are different network protocols (Figure\
    \ 4.2). In the first layer, the industrial \nsensors of the control system are\
    \ connected to a PLC that acts as an OPC UA \n \n64 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nserver, which routes the sensor data to the IoT Gateway\
    \ using the OPC UA \nprotocol. The IoT gateway integrates an OPC UA client installed\
    \ in Node-RED. \nNode-RED can also communicate with cloud services using IBM Visual\
    \ \nRecognition Nodes (WVR), which sends the UAV’s images to the cloud using \n\
    Internet protocols. The Ar.Drone Node.js library installed in the IoT Gateway\
    \ can \ncommunicate with Node-RED using the Exec node, which launches the UAV\
    \ \nmission and establishes the wireless connection between the UAV and the IoT\
    \ \ngateway using the Wi-Fi protocol. \n \n \nFigure 4.2. Development design of\
    \ autonomous IIoT flight \n \nNode-RED can connect all systems in the proposed\
    \ architecture using a wide \nrange of nodes. The OPC UA server installed in the\
    \ control system (PLC), \ncommunicates with the OPC UA Node-RED client node, which\
    \ reads the sensor \nvalues and launches the UAV program using the Exec node if\
    \ certain conditions \nare met. While receiving new images from the UAV, Node-RED\
    \ send them to the \ncloud for recognition or storage, using the Watson Visual\
    \ Recognition and \nCloudant nodes respectively. Ultimately, based on the results\
    \ received from the \nWVR node, a message is sent to the industrial control system\
    \ using the OPC UA \nnodes to adjust the concrete plant's production. Figure 4.3\
    \ shows the Node-RED \nflow and the connections between the nodes. \n \n \n65\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.3. Node-RED\
    \ flow in the IoT gateway including the path from the PLCs to the \nUAV, from\
    \ the UAV to IBM Watson, and from Watson to the control center. \n \n \n2.1. Use\
    \ Case description   \n \nConcrete batching plants form part of the construction\
    \ sector. Their many \nimportant components include cement and bins, aggregate,\
    \ aggregate batchers, \ncement silos, dust collectors, conveyors, mixers, heaters,\
    \ and control panels. \nConcrete plants involve a human–machine interaction between\
    \ the operator and \nthe control system. The operator inputs the concrete formula\
    \ by specifying the \nquantities of material to be mixed and this data is processed\
    \ by a control system \nso that the correct amount of material is conveyed to\
    \ the mixer (Figure 4.4). The \nmaterials used in the concrete plant are cement,\
    \ admixtures, aggregates, and \nwater. The quality and uniformity of the concrete\
    \ depend on the slump value, air \ncontent, water-cement ratio, and homogeneity.\
    \ \n \n \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \n \nTraditionally, microwave sensors have been used in aggregate bins\
    \ to \nmeasure the aggregate water content and then adjust the formula as required\
    \ to \n \n66 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncontrol concrete\
    \ quality. Aggregates of different sizes are stored in bins for \ndifferent formulas.\
    \ Due to some errors during the filtering and unloading \nprocess, these materials\
    \ are sometimes mixed incorrectly, affecting concrete \nconsistency and quality.\
    \ Both the UAV camera and the IBM WVR service in the \ncloud can track the state\
    \ of the aggregate materials being transported on the \nconveyor belts with the\
    \ aim of adjusting the production process. \nThe cloud service is used to classify\
    \ normal and mixed aggregates. The role \nof the UAV in this is to take pictures\
    \ when materials are being transported on the \nbelts before they reach the mixer.\
    \ The cloud classifies each image sent by the \ndrone and returns the results\
    \ to the IoT gateway as a score between 0.0 and 1.0 \nfor each class. This result\
    \ is sent to the PLC after being processed in the IoT \nGateway. Using these results,\
    \ any excess amount of a material can be measured, \nand the necessary adjustments\
    \ can be made to obtain the final formula. This \noperation eliminates wasted\
    \ time and allows the desired formula to be obtained \nbefore the final mixing.\
    \ The proposed approach is considered a cost-effective \nsolution and eliminates\
    \ repeated and unnecessary operator controls, traditional \nmonitoring and control\
    \ systems. \n \n2.2. UAV Mission Planning  \n \nThe novelty of the proposed IoT\
    \ control system is that it provides real-time \ninteraction between an industrial\
    \ control system, UAVs and the cloud. Based on \nthe input information from the\
    \ concrete plant, the UAV can interact and execute \nthe mission automatically\
    \ and provide the necessary photos to the cloud to \ncompute and analyze the data\
    \ by deep learning methods and send the result back \nto the control system for\
    \ decision-making. The drone mission (Figure 4.5) is split \ninto three paths:\
    \ planning the mission, taking photos, and returning to the \nstarting point.\
    \  \nThe drone takes off at position (x, y), climbs to a certain altitude, hovers,\
    \ \nreturns to the start, and lands. The autonomous flight library was based on\
    \ the \nAR.Drone library [189] , which is an implementation of networking protocols\
    \ for \nthe Parrot AR Drone 2.0. This library has four features: a camera projection,\
    \ an \nextended Kalman filter, a PID Controller to control drone position, back-\n\
    projection to estimate distance to an object, and a VSLAM to improve the drone\
    \ \nposition estimates [190-191]. The AR. Drone 2.0 is equipped with sensors with\
    \ \nautomatic stabilization features and precise controls, two cameras, a 60-fps\
    \ \nvertical QVGA camera for measuring ground speed and a 1280 × 720 at 30 fps\
    \ \nresolution front camera with a 92◦ (diagonal) field of view, three-axis \n\
    magnetometer with 6◦ precision, three-axis accelerometer with +/-50 mg \nprecision,\
    \ Ultrasound sensors to measure height, three-axis gyroscope with \n2000◦/s precision,\
    \ and a pressure sensor with +/-10 Pa precision. The drone can \nmonitor its own\
    \ position and mapping (SLAM), robustness and controls. \n \n \n67 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.5. AR.Drone 2.0 mission in\
    \ the concrete plant. \n \nUAVs are easy to deploy, flexible, can quickly change\
    \ position in a time-\ncritical situation and can be quickly configured. Integrating\
    \ them into a control \nsystem accelerates the production chain by responding\
    \ in real time to the various \nchallenges of the control system thanks to the\
    \ cloud services. Figure 4.6 details \nthe communication process between the different\
    \ parts of the proposed \napproach, including the industrial control system, UAVs\
    \ and the cloud, and data \nflows between the different nodes. Two main applications\
    \ are installed in the IoT \ngateway: the Node.js application and the Node-RED\
    \ application. The former \ncontrols the drone, while the latter facilitates communication.\
    \ \nNode-RED controls the flow by reading data from the OPC UA node, which \n\
    is connected to the automation control system. In case a certain issue is confirmed\
    \ \nby the PLC, Node-RED triggers the UAV mission executed by Node.js. The \n\
    UAV's mission (figure 4.5-4.7) is divided into three parts: planning the mission,\
    \ \ntaking pictures and returning to the starting point. The WVR Node and the\
    \ \nCloudant Node receive the images and send them to the IBM cloud for \nprocessing\
    \ and storage. Node-RED collects the classification scores of each new \nimage\
    \ from the cloud and processes them in the IoT gateway before transmitting \n\
    the evaluation to the control system using OPC UA. \n \n \n68 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.6. Communication process in the fog layer. \n\
    \ \n3. Results and Discussion \n \nThe drone in the worksite (concrete batching\
    \ plant) is located in the base \nstation, which is at a distance from the conveyor\
    \ belts the conveyor belts and is \nalways ready to respond to the new demands\
    \ of the industrial control system. \nThe UAV carried out 10 test missions over\
    \ three days in a real concrete plant in \nCartagena, Spain. The first step was\
    \ to fly automatically over a distance of about \n130 m to position the UAV at\
    \ the beginning of the conveyor belts. Then, the UAV \nmoved over the conveyors,\
    \ took pictures and sent them to the IoT gateway. The \nlast step was to bring\
    \ the UAV back to the starting point (Workstation) (Figure \n4.7). \n \nFigure\
    \ 4.7. Path used by the drone to execute the mission in a concrete plant. \n \n\
    \ \n \n \n69 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n3.1. IBM Watson\
    \ Image Recognition Training  \nOff-board image processing techniques were selected\
    \ due to the asset of the \ncloud services. IBM’s Watson visual recognition (WVR)\
    \ service analyzes the \ncontent of images from the drone camera transmitted through\
    \ the IoT gateway \n(Figure 4.1). MATLAB, OpenCV or TensorFlow could also have\
    \ been used as the \ncontrol system; however, the cloud completes the computing\
    \ activities and \nprovides an efficient time and cost optimization. The WVR service\
    \ can classify \nand train visual content using machine learning techniques. \n\
    WVR is based in part on the technology developed for the IBM multimedia \nanalysis\
    \ and retrieval system (IMARS) [192], supplemented by “deep features” \nthat are\
    \ extracted on Caffe software [193]. The WVR service extracts feature \nvectors\
    \ from a particular layer of a Caffe network for all the supplied examples \n\
    and uses them to train a one-versus-all support vector machine (SVM) model for\
    \ \neach class. The feature extraction process is therefore equivalent to “inferencing”\
    \ \nwith the neural network, but the SVM learning process is less CPU intensive\
    \ than \ninferencing [194]. \nThe Watson service generally accepts a maximum of\
    \ 10,000 images or 100 MB \nper .zip file and a minimum of 10 images per .zip\
    \ file, with different angles and \nscenarios to obtain the maximum precision.\
    \ The service recommends that the \nimages be at least 224 × 224 pixels and contain\
    \ at least 30% of the subject matter. \nIn order to train the custom model, we\
    \ used a dataset of the images captured by \nthe UAV camera from the field of\
    \ practice in different positions. In addition, we \nroughly divided the use case\
    \ into two parts: a mixed material set and a normal \nmaterial set (Figure 4.8).\
    \ \n \n \n                                    (a)                            \
    \                                    (b) \nFigure 4.8. Dataset used to train the\
    \ custom model in WVR service: (a) Shows images \nused to train the Mixed class;\
    \ (b) Shows Images used to train the Normal class. \n \nIn the training stage\
    \ we used the dataset images to create two new classes, a \nMixed class, and a\
    \ Normal class. These classes were grouped to define a single \ncustom model.\
    \ In the testing stage, the results of the Watson tests are shown as a \nconfidence\
    \ score for the image in the range of 0 to 1. A higher score indicates that \n\
    \ \n70 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nthe class is more likely\
    \ to be depicted in the image. The scores are considered as \na threshold for\
    \ action, and the confidence score are based on training images, \nevaluation\
    \ images, and the types of criteria of the desired classification. Figure \n4.9\
    \ shows the test of three different new images and the results of each class score.\
    \ \nWVR recognized the difference between the images according to the density\
    \ of \nthe normal material on the conveyors. For instance, the confidence score\
    \ for the \ntest-3 .jpg image is 0.92 for the normal class, indicating the greater\
    \ likelihood of \nthis class being in the image. \n \n \nFigure 4.9. Watson visual\
    \ recognition test of new images not used in the training \nphase. \n \n3.1.1\
    \ WVR Performance Evaluation \n \nTo assess the performance of the WVR, we used\
    \ a formula to calculate the \naccuracy as defined by equation (4.1). In our case,\
    \ we tested a data set of more \nthan 100 photos and obtained a final detection\
    \ accuracy of 87.28%. The \nmisclassified cases are listed in Table 4.1, which\
    \ represents the confusion matrix. \nOn the basis of a large number of tests with\
    \ new images not used in the training \nphase, a threshold for each score class\
    \ was defined, a decision was made, and the \norder was sent to the industrial\
    \ control system to adjust the quantities of material \nbeing transported on the\
    \ conveyor belts. \n \n \n                      \n\U0001D434\U0001D450\U0001D450\
    \U0001D462\U0001D45F\U0001D44E\U0001D450\U0001D466 =\n\U0001D447\U0001D443 + \U0001D447\
    \U0001D441\n\U0001D447\U0001D443 + \U0001D447\U0001D441 + \U0001D439\U0001D443\
    \ + \U0001D439\U0001D441 \n            \n(4.1) \n \n \nWhere TP is the number\
    \ of positive samples judged to be positive, FP \nrepresents the number of negatives\
    \ samples that are judged to be positive, FN is \nthe number of positive samples\
    \ judged to be negative, and TN the number of \nnegative samples judged negative.\
    \ \n \n \n71 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nTable 4.1.\
    \ Confusion matrix \n \nPredictive Positive \nPredictive Negative \nTrue Positive\
    \ \n58 (TP) \n6 (FN) \nTrue Negative \n9 (FP) \n45  (TN) \n \nAfter training the\
    \ WVR model in the cloud, the WVR Node can send the new \nphotos received in the\
    \ IoT gateway to the cloud service (Figure 4.10). The cloud \nservice classifies\
    \ the new photos and returns the results to the WVR node as a \nscores for each\
    \ class, which are then analyzed and sent to the PLC via the OPC \nUA protocol.\
    \ Figure 4.10 shows the results obtained from the WVR node in Node-\nRED. \n \n\
    Figure 4.10. Node-RED flow and WVR results of an UAV photo \n \n3.2. Delay Assessment\
    \ in the Proposed Platform \nThis section presents the RTD time metrics of the\
    \ IoT gateway connections in \nits conditions of use and highlights the crucial\
    \ role of the IoT gateway in terms \nof latency. In this application, the IoT\
    \ gateway is connected to different systems \nwith different transmitted data.\
    \ Below, we evaluate this difference by using three \ngateways with different\
    \ performances. Each IoT gateway has its own software \nand hardware components\
    \ to process the data with different processing times. \nTable 4.2 shows the specification\
    \ of each of the three selected platforms. \n \nTable 4.2. Specification of each\
    \ machine environment. \n \nSiemens Gateway \nIOT2040 \nRaspberry Pi 3 \nModel\
    \ B \nToshiba \nSATELLITE C870 \nEthernet \n2 x 10/100 Ethernet \nRJ45 \n10/100\
    \ BaseT Ethernet \nsocket \n10/100 BaseT \nEthernet RJ-45 \nProcessor \nIntel\
    \ Quark x1020 \n400 MHz \n1.2 GHz Quad-Core ARMv7 \nIntel Core i3 2348-M \nCPU\
    \ 2.3GHz \nOperation \nSystem \nLinux Kernel 4-4-18 \nYocto Standard \nLinux Raspbian\
    \ 4.14.79-v7+ \n \nWindows 7 \nProfessional \nRAM \n1 GB \n1 GB \n8 GB \nDisk\
    \ Memory \n32 GB \n16 GB \n500 GB \n \n \n72 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n3.2.1. OPC Experimental Method and Results \n \nA case study was\
    \ used to define the latency of the OPC UA client-server \narchitecture. The experimental\
    \ set-up was based on an industrial plant and \nsoftware in addition to three\
    \ different IoT-based platforms. The industrial control \nsystem deployed as an\
    \ OPC UA server uses a Siemens S7-1512 with embedded \nOPC UA communication stack.\
    \ The OPC UA client is implemented using Node-\nRED OPC UA client node in the\
    \ three different devices, the IoT gateway IOT2040 \nfrom Siemens (S-G), a PC\
    \ computer Toshiba SATELLITE (PC-G), and a Raspberry \nPi 3 Model B (RPI-G) (Figure\
    \ 4.11). In the first step of the latency study, we \ncompared the RTD with the\
    \ three different devices considered as OPC UA client \nattached to the same Siemens\
    \ S7-1512 OPC UA server network. \n \n \nFigure 4.11. OPC UA delay in OPC UA client\
    \ server in an Ethernet network. \n \nThe given application is deployed in a local\
    \ network and is based on a typical \nuse case which consists in reading a bit\
    \ from the OPC UA server. All the RTD \nmeasurements were performed on the same\
    \ network. Under these conditions, we \nconsider that RTD delay is derived mainly\
    \ from the Tx software latency of the \nsoftware stack of device X (Equation3.4)\
    \ assuming an insignificant hardware \nlatency tH of the wires and the switch.\
    \ \nAn MX machine is defined as well as a pair of software setup SW and a \nhardware\
    \ setup HW : \n           \U0001D440\U0001D465 = (\U0001D43B\U0001D464,\U0001D446\
    \U0001D464)                                              (4.2) \n \nThe hardware\
    \ setup HW is defined as the set of all hardware elements in this \nmachine and\
    \ the software setup SW is defined as the set of all software elements \n[195].\
    \ \n \n \U0001D43B\U0001D464 = {\U0001D440\U0001D452\U0001D45A\U0001D45C\U0001D45F\
    \U0001D466,\U0001D443\U0001D45F\U0001D45C\U0001D450\U0001D452\U0001D460\U0001D460\
    \U0001D45C\U0001D45F, \U0001D441\U0001D43C\U0001D436 … }                     \
    \               (4.3) \n                                     \U0001D446\U0001D464\
    \ = {\U0001D434\U0001D45D\U0001D45D\U0001D459\U0001D456\U0001D450\U0001D44E\U0001D461\
    \U0001D456\U0001D45C\U0001D45B, \U0001D442\U0001D446, \U0001D437\U0001D45F\U0001D456\
    \U0001D463\U0001D452\U0001D45F\U0001D460 … }                                 \
    \    (4.4) \n \n73 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn order to\
    \ measure latency, a timestamp contained in an injection node in Node-\nRED was\
    \ used (Figure 4.12). In every request, the timestamp request is saved by \na\
    \ function node. The latency L is defined as the difference between the timestamp\
    \ \nof the server response and the client timestamp request saved in the first\
    \ function \nnode. Hence, latency L is measured as : \n \n\U0001D43F = \U0001D447\
    \U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461 − \U0001D447\
    \U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\U0001D45B\U0001D460\U0001D452\
    \ = \U0001D445\U0001D447\U0001D437)                                      (4.5)\
    \ \n \n \nFigure 4.12. Node-RED flow used to calculate round trip latency (OPC\
    \ UA Client to the \nOPC UA Server). \n \nThe latency results are summarized in\
    \ Table 4.3, showing the minimal and \nmaximal values, RTD average, and the standard\
    \ deviation calculated for each fog \ncomputing machine. The OPC UA requests were\
    \ repeated each second to read \nthe one-bit value in the OPC UA server (Figure\
    \ 4.12). All the samples were \nthoroughly checked for the same architecture on\
    \ different days in an \nexperimental campaign with more than 5000 valid samples.\
    \ S-G gateway latency \nis higher than in the RPI-G and PC-G gateways, approximately\
    \ three times that \nof the RPI-G and seven times that of the S-G. This difference\
    \ is evident in the \nprobability density function as shown in Figure 4.13. The\
    \ shapes of the RPI-G \nand the PC-G are almost the same with a single peak, while\
    \ the S-G shape is \nnarrower and scattered over a large time area. \n \nTable\
    \ 4.3. RTD test of 5200 samples from the OPC UA client to the OPC UA server (PLC)\
    \ \nover different clients through different machines. \n \nClient Test \nEnvironment\
    \ \nData Type \nAverage \nStandard \nDeviation \nMinimum \nLatency \nMaximum \n\
    Latency \nS-G \nBOOL (1 bit) \n23.160 ms \n23.56 ms \n19 ms \n878 ms \nRPI-G \n\
    BOOL (1 bit) \n8.22 ms \n3.48 ms \n5 ms \n76 ms \nPC-G \nBOOL (1 bit) \n3.288\
    \ ms \n2.65 ms \n0 ms \n32 ms \n \n74 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.13. OPC UA client-server RTD to read one bit through\
    \ different machines. \n \nIn order to analyze this large difference in the recorded\
    \ RTD between RPI-G \nand S-G, we continuously monitored the CPU load for 5 min\
    \ during the OPC UA \nchannel' s RTD. The RPI-G and S-G gateways were tested individually\
    \ in the \nsame network conditions and running only Node-RED, which runs the OPC\
    \ UA \nclient. The computed CPU usage was calculated as the average of all cores\
    \ of the \nRPI-G and S-G gateways (see figure 4.14). \n \n \n \nFigure 4.14. (a)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in \nthe S-G; (b)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in the \nRPI-G. \n\
    \ \nGiven the analogy of a similar situation [196], which assumes that the larger\
    \ \nthe RTD pattern peaks the higher the probability they are due to the higher\
    \ CPU \nload, although the recorded CPU load patterns are not only due to the\
    \ OPC UA \nclient implemented in Node-RED. Nonetheless, we compared the impact\
    \ of CPU \nusage in the RTD as regards the same conditions in the two gateways.\
    \ It should \n \n75 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nbe noted that\
    \ the impact of Node.js can be estimated to be around 10% of the \nprocessing\
    \ power of the gateway used in the demonstration case, and the number \nof devices\
    \ connected to the gateway linearly increases CPU and memory usage \n[73]. \n\
    There is always intense use of CPU in the S-G RTD when high latency is \ndetected.\
    \ The S-G peaks sometimes exceed 400 ms (Figure 4.14, Table 4.3) while \nin the\
    \ RPI-G they do not exceed 80 ms. Furthermore, the average CPU load of the \n\
    RPI-G is much lower than that of the S-G. The average value of the CPU load in\
    \ \nthe S-G is around 8%, while in the RPI-G it is around 1.7% and the number\
    \ of \ndevices connected to the gateway linearly increases the CPU load. \n \n\
    3.2.2. UAV Experimental Results \n \nThe streaming quality of the proposed Node.js\
    \ application was measured \nunder certain conditions of use to compare the response\
    \ time on different IoT \ngateways in the same configurations and conditions.\
    \ The transmission channel, \nframe rates and compression techniques were the\
    \ same in all the tests on the \nrecording of camera images and saving them to\
    \ a folder in the IoT gateway. The \nimage frames were captured and registered\
    \ in a buffer before being sent to the \ngateway. Encoding was performed by FFMPEG\
    \ codec, and the received frames \nwere decoded in the gateway before being saved\
    \ on the gateway disk. \n \n• Codec Latency \n \nThe AR.Drone library [197] uses\
    \ the basic H264 profile (MPEG4.10 AVC) for \nhigh quality streaming and video\
    \ recording. The Baseline profile was targeted at \napplications in which a minimum\
    \ of computational complexity and a maximum \nof error robustness are required.\
    \ H.264/MPEG4-AVC baseline supports two slice-\ncoding types (I and P slice types),\
    \ designed for progressive video such as video \nconferencing, video-over-IP,\
    \ and mobile applications [198]. The simplest is \nthe I slice, in which all macro-blocks\
    \ are coded without referring to any other \npictures in the video sequence. Previously\
    \ coded images are used to form a \nprediction signal for macro-blocks of the\
    \ predictive-coded P [199]. \nTheoretically, based on Equation (3.12), UAV delay\
    \ can be estimated by: \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D\
    \ + 2. (\U0001D447\U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465\
    \ + \U0001D447\U0001D451\U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\
    \U0001D45D)                                  (4.6) \n \n \nThe experiments focus\
    \ on the mission delay generated by taking pictures in \na concrete production\
    \ plant. We measured the time needed for the drone to \nconnect with the IoT gateway,\
    \ take a picture and save it in a file in the IoT \ngateway (WriteFile function\
    \ from Node.js). Table 4.4 shows the results of an \nAR.Drone 2.0 mission with\
    \ around 200 images on the Node.js application, \n \n76 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntriggered from Node-RED. The latencies in both machines\
    \ are expressed in \nmilliseconds and calculated in the Node.js application. \n\
    \ \nTable 4.4. RTD Test of 200 photos sent from the IoT gateway to the AR.drone\
    \ \n2.0. \n \nThe results provided in Table 4.4 shows the large difference in\
    \ terms of \nlatency between RPI-G, S-G and PC-G. The average RPI-G latency is\
    \ almost three \ntimes that of PC-G, and RPI-G standard deviation is much higher\
    \ than in PC-G. \nNote that these tests were made with an image resolution of\
    \ 640 × 360 px, frame \nrate of 5 fps and a codec with H264 baseline. \nOn the\
    \ other hand, the S-G results are consistently different from those of PC-\nG\
    \ and RPI-G; the average S-G latency is very high, while the standard deviation\
    \ \nis lower than RPI-G. \nFigure 4.15 shows the probability density function\
    \ of the delay of the drone \nconnected to the gateway when successive pictures\
    \ from PC-G and RPI-G are \ntaken. While Figure 4.16 shows the probability density\
    \ function of the delay of \nthe drone connected to the gateway when successive\
    \ pictures from S-G are taken. \nHere, the distributions are clearly different,\
    \ the data spreading of the PC-G \ndistribution covers a narrower range, with\
    \ a larger spread in the S-G and RPI-G \ndistributions. \n \n \nFigure 4.15. Probability\
    \ density function of the delay of the drone connected to \nthe gateway when successive\
    \ pictures from PC-G and RPI-G are taken. \n \nClient Test \nEnvironment \nConnection\
    \ \nEstablished \nAverage  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum\
    \ \nLatency \nS-G \n11429 ms \n1229.92 ms \n365.71 ms \n160 ms \n2906 ms \nRPI-G\
    \  \n5348 ms \n317.76 ms \n411.18 ms \n12 ms \n1706 ms \nPC-G  \n4562 ms \n132.72\
    \ ms \n35.90 ms \n4 ms \n230 ms \n \n77 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.16. Probability density function of the delay of the\
    \ drone connected to \nthe gateway when successive pictures from S-G are taken.\
    \ \n \nFigure 4.17, figure 4.18 and figure 4.19 compare the CPU load of the same\
    \ \nprogram implemented in the IoT gateways. The program continuously takes \n\
    images from the drone and stores them in a file in the gateway. The first time\
    \ \nperiod (red interval) in all three graphs shows the first connection between\
    \ the \ndrone and the gateways, while the rest of the time period is the time\
    \ of execution \nof the Node.js program in the gateways. \n \n \nFigure 4.17.\
    \ CPU Load while taking successive photos and writing them in a \nfolder in the\
    \ PC-G. \n \n \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the RPI-G. \n \n78 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.19. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the S-G. \n \nThe three IoT gateways have different environmental\
    \ specifications. Figures \n4.17-4.19 show these differences in terms of CPU usage\
    \ in the three gateways \nwhile executing the mission. In S-G, it increases from\
    \ 3% to 100%, while in RPI-\nG, the CPU load increases from 2% to 60%. In the\
    \ PC-G gateway the average CPU \nload while executing the mission was around 20%.\
    \ This difference is justified \nmainly by the numbers of cores implemented in\
    \ each gateway processor. S-G \nused a 400 MHz Intel Quark ×1020 processor with\
    \ a single core, while RPI-G used \na 1.2 GHz Quad-Core ARMv7 processor with four\
    \ cores. Furthermore, RPI-G and \nPC-G both support the Graphics Processing Unit\
    \ (GPU), while S-G does not. \n \n3.2.3. Watson Experimental Method \n \nThe IBM\
    \ Watson visual recognition service uses deep neural networks to \nanalyze images\
    \ and is currently operated in a data center in Dallas (USA). \nMultiple servers\
    \ are used to ensure high throughput and reliability. Node-RED \nprovides a node\
    \ to connect to the WVR service which takes an image as input \nand produces a\
    \ set of image labels as output. \nThe experiments carried out were based on Equation\
    \ 4.5 and used the Node-\nRED flow. The latency results are summarized in Table\
    \ 4.5, the RTD average, \nstandard deviation, minimal and maximal values calculated\
    \ for each fog \ncomputing machine.  \nThe experiment was repeated for one sample\
    \ field case image less than a data \nblock size of 154,076 bytes. All the samples\
    \ were carefully and thoroughly \nchecked for the same architecture on the same\
    \ day. Each experimental campaign \nhad around 100 valid samples for each machine.\
    \ Between each 100 requests, the \nnext request is triggered at the time of receiving\
    \ the results of the previous \nrequest from the WVR. \n \n \n79 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.5. RTD test of 100 samples from\
    \ the IoT gateway to IBM Watson over different \nmachines.  \n \n \nThe results\
    \ reported in Table 4 display the differences between the different \nfog machines.\
    \ The average RPI-G and PC-G scores are lower than the S-G. \nHowever, RPI-G is\
    \ faster than S-G and has a larger standard deviation, while PC-\nG is faster\
    \ than RSP-G with a low standard deviation. The probability density \nfunction\
    \ estimates of the WVR delay for the three gateway machines are given in \n(Figure\
    \ 4.20). In this case, the probability density of the S-G has almost the same\
    \ \ncurvature as that of RPI-G, while the probability density of PC-G is larger.\
    \ \n \n \nFigure 4.20. Probability density function estimation of IBM WVR latency\
    \ to classify an \nimage located in the IoT gateway. \n \nGiven that the WVR node\
    \ in Node-RED relies on the HTTP protocol to send \nthe images to the cloud, we\
    \ performed another test using SpeedTest to measure \nthe HTTP throughput between\
    \ the web server and the client over the three \ngateways considered as clients\
    \ (on the same day with the same network \nconditions). The results obtained in\
    \ Table 4.6 indicate similar results for the \ndownload, while the S-G upload\
    \ is lower than the other gateways. \n \n \nClient Test \nEnvironment \nAverage\
    \  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum \nLatency \nS-G \n1913.18\
    \ ms \n522.17 ms \n1454 ms \n5594 ms \nRPI-G \n1373.09 ms \n453.64 ms \n1080 ms\
    \ \n5151 ms \nPC-G \n1129.29 ms \n181.97 ms \n980 ms \n2491 ms \n \n80 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.6. Speed Test over the three gateways\
    \ (S-G, RPI-G, PC-G) \nMachine \nPing \nDownload \nUpload \nS-G \n169.4 ms \n\
    16.3 Mbps \n9.5 Mbps \nRPI-G \n96.4 ms \n17.6 Mbps \n13.8 Mbps \nPC-G \n55.7 ms\
    \ \n17.5 Mbps \n12.3 Mbps \n \n \n \nII.  Autonomous Underwater Monitoring System\
    \ for \nDetecting Life on the Seabed by Means of \nComputer Vision Cloud Services\
    \ \n \n \n1. General introduction \n \nThe world's seas, as a valuable asset and\
    \ a vital part of its ecology, must be \nprotected as an essential source of life,\
    \ food and wealth. This implies monitoring \nsystems to ensure their condition\
    \ and sustainable management, which involves \nsurveying chemical and physical\
    \ parameters related to water quality, such as \ndissolved oxygen, nitrates, salinity,\
    \ temperature, density and chlorophyll levels, \namong others. Other purposes\
    \ of seabed monitoring are the detection and \nconservation of archaeological\
    \ artifacts and the monitoring of the state of marine \nflora and fauna, including\
    \ particularly sensitive endangered species [200]. \nStudies have been carried\
    \ out in different regions of the Mediterranean, \nparticularly in the Mar Menor,\
    \ a zone of particular interest due to its exceptional \nenvironment. Studies\
    \ have been carried out in different regions of the \nMediterranean, particularly\
    \ in the Mar Menor, a zone of particular interest due \nto its exceptional environment.\
    \  \nThe Mar Menor in southeast Spain, with unique salinity and temperature \n\
    characteristics, is Europe’s largest Salt Lake, with an area of 180 km2. It is\
    \ a \nvaluable resource with a remarkable ecosystem and a wide range of habitats\
    \ for \nendangered species. It has been the subject of numerous scientific studies\
    \ when \nit was recently contaminated biologically and chemically by torrential\
    \ rains \ncontaining large amounts of fresh water and agricultural runoff from\
    \ the \nsurrounding farmland, which affected its flora and fauna [200]. It also\
    \ shelters \nconsiderable plankton and phytobenthic populations during the warm\
    \ season. \nAll these factors have affected many of its indigenous species. \n\
    27 types of habitats of special interest have been inventoried in the Mar \nMenor\
    \ and its surroundings, eight of which are of priority [201]. Protected \nspecies\
    \ are also abundant and include seagrass meadows (Cymodocea nodosa \nand Ruppia\
    \ cirrhosa), marine fauna of special interest, such as seahorses \n \n81 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n(Hippocampus ramulosus) or\
    \ toothed carp (Aphanius iberus), large quantities of \nfan mussels (Pinna nobilis)\
    \ and a wide range of seabirds [202]. The fan mussel is \nan endemic bivalve mollusc,\
    \ the largest in the Mediterranean and the second \nlargest in the world. The\
    \ International Union for the Conservation of Nature \n(IUCN) has included Pinna\
    \ nobilis in its updated list of critically endangered \nspecies due to parasitic\
    \ diseases [203]. In 2019, the discovery of a series of \nspecimens in the Mar\
    \ Menor confirmed that this natural area was a refuge for \nthis endangered species\
    \ on the verge of extinction along the entire Mediterranean \ncoastline and that\
    \ it was therefore essential for its monitoring. Although such \nmonitoring can\
    \ be carried out from manned vessels, it is time-consuming, \nlaborious and costly\
    \ and can be carried out much more effectively by AUVs [204]. \nAUVs are now widely\
    \ in use for a variety of tasks, including oceanographic \nsurveys, mine clearance,\
    \ demining and bathymetric data collection in marine and \nriver environments\
    \ [205]. They are valuable for mapping underwater \nenvironments and are playing\
    \ an increasing role in marine development [8]. \nThey now have power sources\
    \ and an intelligent control system that can perform \nautonomously programmed\
    \ tasks with appropriate decision-making capabilities \n[200]. Advances in computer\
    \ science, sensor technology, new materials and \nadvanced algorithms have significantly\
    \ increased their performance, although \nmany issues remain to be resolved [206,207].\
    \ \nAlong with the challenges and difficulties of an autonomous robot \nnavigating\
    \ in an unstructured environment, the marine environment has its own \nlimitations,\
    \ not only because of the currents but also because of the difficulty of \ngeolocating\
    \ the submerged AUV. The absence of communication networks and \nthe complexity\
    \ of real-time connection is also a drawback and could be a \ndetermining factor\
    \ not only for transmitting exploration results, but also for \nleveraging increased\
    \ computing capacity and information management when \nnecessary, such as artificial\
    \ intelligence (AI) provided by cloud computing \nservices.  \nSome AUV architectures\
    \ imply the technological challenge of a high \nprocessing, connection and communication\
    \ capacity. This necessitates an \narchitecture that is capable of integrating\
    \ with a nearby base station, the Internet \nand cloud architectures. The information\
    \ gathered during an operation also \nentails interpretation, which can be crucial\
    \ for decision making. This means that \nnot only the local connection is important,\
    \ as well as the connection with web \nservices (cloud computing, data centers,\
    \ etc.). The latter can be used to create \nwizards for specific purposes and\
    \ processes to which complex and specific tasks \ncan be delegated. \nWe propose\
    \ and assess an AUV system designed to collect and interpret \nunderwater images\
    \ in Mar Menor in order to trace the fan mussel population in \nreal time, using\
    \ georeferenced mosaics generated from the images by an \nautomatic processing\
    \ method. \n \n \n82 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n \n2. System model \n \nThe proposed AUV-IoT architecture is structured\
    \ in three layers, with the \nAUV being in the data generation and pre-processing\
    \ layer. The first layer \nconsists of an AUV composed of different sensors and\
    \ blocks for data generation, \nconversion and pre-processing (figure 4.21). The\
    \ pre-processing system is \ndeployed in an IoT gateway installed in the head\
    \ box and connected to the \ncamera by a switch. The IoT Gateway is defined as\
    \ an edge node. Another layer \nis the data communication layer with the cloud\
    \ via Wi-Fi or 4G networks. The \nlast layer is a back-end cloud with image processing\
    \ techniques. \n \nFigure 4.21. Proposed AUV-IoT Platform \n \nAs shown in Figure\
    \ 4.22, the three layers are made up of different electronic \ndevices with access\
    \ to software services, the physical layer is constituted by a \nvariety of electronic\
    \ devices interconnected by three different networks \naccording to their functionality:\
    \ The Internet/cloud network, the Ethernet \nnetwork and the CAN (controller area\
    \ network). The CAN network is composed \nof one master and four slave nodes.\
    \ Each node consists of an electronic card \nspecifically designed for this vehicle\
    \ and its assigned tasks, and has as a core a \nPIC 18F4685 microcontroller, working\
    \ at a frequency of 25 MHz. \n \n \n83 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.22. Proposed hardware architecture. \n \nThe CAN network\
    \ is the fieldbus that interconnects the elements dedicated \nto instrumentation,\
    \ measurement and actuation. It connects equipment devoted \nto specific processes\
    \ (inputs/outputs, sensor reading, engine control). The CAN \nnetwork has a master/slave\
    \ configuration, and the elements of this network \ncommunicate via the CAN field\
    \ bus, using the CANopen protocol at a speed of \n250 kbps, sufficient for real-time\
    \ exchange of process information. This protocol \nis particularly robust and\
    \ immune to electromagnetic interference, a feature that \nmakes it ideal for\
    \ this vehicle. \nThe CAN network consists of four slave nodes and a master. Each\
    \ node \nconsists of an electronic board specially designed for this vehicle and\
    \ the tasks \nassigned to it, and has a PIC 18F4685 microcontroller as its core,\
    \ operating at a \nfrequency of 25 MHz. The main functions of each node are as\
    \ follows: \n \n• \nNode 1 (in the head of the vehicle) manages its movement,\
    \ lighting, \ncamera power, tilt reading (pitch and roll) and the acquisition\
    \ of inertial \nunit variables. \n• \nNode 2 (DVL: Doppler velocity logger) manages\
    \ data acquisition \nand body tilt reading (pitch and roll). \n• \nNode 3 governs\
    \ GPS reading, engine management and control \n(propulsion, rudder and dive).\
    \ \n• \nNode 4 monitors marine instrumentation sensors (side-scan sonar, \nimage\
    \ sonar, microUSBL) and their energy management. \n• \nThe master node consists\
    \ of a National Instrument single-board \nRemote Input/Output (NI sbRIO) 9606\
    \ (the main vehicle controller). Its \nfunction in this network is to collect\
    \ process information from each of the \nnodes and send commands. It is the link\
    \ with the superior Ethernet \nnetwork. \n \n84 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nThe Ethernet network permits higher data transfer\
    \ rates between devices and \nis formed by the AUV sbRIO control system, IP camera,\
    \ IoT gateway, and the 4G \nrouter. All of these are connected to the buoy via\
    \ an umbilical cable. \nEthernet/DSL (Digital Subscriber Line) gateways are used\
    \ owing to the number \nof wires in the umbilical cable connecting the vehicle\
    \ to the surface buoy (only \ntwo wires are available for data).  \nAs at least\
    \ four cables are used with Ethernet, and only two with DSL, the \nEthernet protocol\
    \ is converted to DSL before and after the umbilical cable by the \nDSL to Ethernet\
    \ gateways. The local bandwidth is 100.0 Mbps, with latencies of \nless than 1\
    \ ms. \nThe Internet/cloud network connects the vehicle to the cloud. The 4G router\
    \ \nintegrated in the surface buoy ensures the connection to the cloud. The aim\
    \ of \nthis network is the communication of the IoT gateway with the cloud and\
    \ \ncommunication of sbRIO control system with IUNO (Interface for Unmanned \n\
    Drones) fleet management software. The IUNO software platform was designed \n\
    at the Automation and Autonomous Robotics Division (DAyRA) of the \nPolytechnic\
    \ University of Cartagena. The platform is intended to manage the \nintegrated\
    \ control of multiple unmanned marine vehicles with the aim of \nsimplifying maritime\
    \ operations. The results obtained from each vehicle, \nregardless of its characteristics,\
    \ facilitate the success of the operation with a high \ndegree of automation [200].\
    \ AEGIR is the name of the AUV developed by \nDAyRA, and it is the main vehicle\
    \ used in this paper; its structure is described in \nFigure 4.22. \n \n3.1. IoT\
    \ Gateway: The Edge Node and Connection to the Cloud \n \nThe implemented IoT\
    \ gateway is capable of connecting the sensor network \nto the cloud computing\
    \ infrastructure, performing edge computing and serving \nas a bridge between\
    \ the sensor networks and the cloud services [208]. \nExperiments were carried\
    \ out using Python installed in the IoT gateway. \nThe Python program employed\
    \ serves as an interface to communicate with \nthe submarine sensors and actuators,\
    \ the cloud computer vision APIs and the \nunderwater controller (Figure 4.23).\
    \ \n \n \n85 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.23.\
    \ Node intercommunications and concurrent threads in the IoT \ngateway. \n \n\
    Python has a built-in support for scientific computing. Its use is growing \n\
    fastest in data science and machine learning [209]. Versatility, the stability\
    \ of \nlibraries with great support, and ease of use are its main benefits [210].\
    \ The IoT \ngateway also features Open-source Computer Vision (OpenCV) which is\
    \ a \nlibrary of programming functions mainly for real-time CV. In our application,\
    \ \nOpenCV is used for live video streaming over an Ethernet network connected\
    \ to \nthe prospective IP camera (model Sony SNC-CH110) installed in the head\
    \ box. \nAll the Python cloud libraries required for image recognition are installed\
    \ in the \nIoT gateway. \nWhereas the Python program in the IoT gateway is started\
    \ (Algorithm 1), \nconnection is established with the camera by the Real-Time\
    \ Streaming Protocol \n(RTSP). The Python program in the IoT gateway is executed\
    \ to run four threads \n(tasks) at the same time (Figure 4.24). \nThe first thread\
    \ is tasked with capturing and streaming video images from \nthe IP camera to\
    \ the IoT gateway internal memory. If a specimen is detected using \nthe cloud\
    \ object detection service, the AUV’s movements are adjusted to focus \nthe camera\
    \ on the object. The distance between the detected specimen and the \nvehicle\
    \ is computed in the IoT gateway and employed to steer the AUV to track \nits\
    \ position. The AUV’s heading and mission control commands are routed via \nTCP/IP\
    \ (Transmission Control Protocol/Internet Protocol) to the sbRIO controller \n\
    in the head box, which is connected to several nodes via a CAN bus protocol. \n\
    Each node is connected to a different group of sensors and actuators.  \nThe cloud\
    \ service used in this case is the vision object detection service, \nwhich allows\
    \ training of customized machine learning models that are able to \ndetect individual\
    \ objects in a given image along with their bounding box and \nlabel. There are\
    \ many different cloud APIs for computer vision, e.g., IBM, Google, \nMicrosoft\
    \ Azure and Amazon. They all provide fairly similar capabilities, \nalthough some\
    \ emphasize object recognition, Amazon, or building custom \n \n86 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmodels, like Microsoft Azure and IBM.\
    \ The strength of these cloud APIs is their \nability to develop custom models\
    \ rapidly and download trained custom models \nto deploy them on the edge for\
    \ real-time applications and low-latency \nrequirements [211-212]. \nTo appraise\
    \ the effectiveness of the suggested platform, we assessed its \noverall latency,\
    \ in order to act quickly when an underwater specimen is detected \nand control\
    \ the AUV mission according to the cloud results of each photo. The \nPython program\
    \ is divided into four threads; however, the response time of the \ncloud services\
    \ takes significantly longer, depending on different factors. Figure \n4.23 presents\
    \ clearly the connection between the IoT gateway and the different \nsystems.\
    \ Each thread of the IoT gateway is responsible for synchronously \ntriggering\
    \ a task and ensures maintenance of the connection. \n \n3. The AUV-IoT Architecture\
    \ Development \n \nIn this section, we itemize and outline the development of\
    \ the above-\nmentioned IoT-AUV autonomous system and its network protocols, portraying\
    \ \nfive main blocks, namely, the IoT gateway, the IP camera, the AUV control\
    \ \nsystem, the AUV control station and the cloud.  \nThe overall mission is triggered\
    \ in the AUV control station by setting the \ndesired waypoints and activating\
    \ the AUV engines and IP camera streaming. The \nIoT gateway in the head box connects\
    \ the AUV nodes and the IP camera with \ncloud services. The IoT gateway receives\
    \ image data from the IP camera in the \nsubmarine’s head box and sensor data\
    \ from the body box. Likewise, the IoT \ngateway seizes the image processing results\
    \ from the cloud for each sent photo. \nIf a fan mussel is detected, the results\
    \ contain its delimitation box in the image \nand the percentage of image accuracy.\
    \ When a fan mussel is detected using the \ncloud API (Application Programming\
    \ Interface), the IoT gateway links up with \nthe main controller to modify the\
    \ submarine’s mission and track the specimen \ndetected. \nThe submarine’s new\
    \ mission is based on the results received from the cloud \nAPI and the algorithm\
    \ processed in the IoT gateway. The algorithm implemented \nin the IoT gateway\
    \ is in charge of adjusting AUV movements to keep the targeted \nspecimen in the\
    \ centre of the field of view. The distance to the detected specimen \nis computed\
    \ using the cloud API and a triangular similarity algorithm [213-214].  \nThe\
    \ desired mission modifications are routed to the main controller to handle \n\
    the engines and vehicle heading. In this case, the AUV’s manual tracking control\
    \ \nis replaced by an automatic specimen detection system using the cloud APIs\
    \ and \nthe distance measurement algorithm implemented in the IoT gateway. A specific\
    \ \narea is explored based on a specific mission with settled waypoints. The tracking\
    \ \nalgorithm in the IoT gateway is triggered automatically if the forward camera\
    \ \ndetects a specimen (Figure 4.24). \n \n87 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.24. Communication between platforms. \nThe IoT gateway’s\
    \ main function is to acquire the camera image, timing the \nshot according to\
    \ the AUV’s depth and speed, to obtain photographic mosaics \nwith overlapping\
    \ images. The IoT gateway receives the captured images and \nforwards them to\
    \ the cloud, which uses advanced learning techniques to analyse \nthe results\
    \ and send them to the IoT gateway. The obtained results from the cloud \nare\
    \ exploited to adjust the new underwater mission to pinpoint the specimen’s \n\
    exact location. This is described in Algorithm 1, as well as in the flowchart\
    \ in \nFigure 4.23. \n \nAlgorithm 1. Specimen tracking algorithm \nStart () \n\
    Step 1:  \n     While (mission has not started) {}         \nStep 2: \n     If\
    \ (mission has ended) \n         {End()} \n     Else \n         {Acquire frame\
    \ and send to cloud} \n         {Get the answer} \n         If (accuracy > 20%)\
    \  \n             {Go to step 3} \n         Else \n             {Go to step 2}\
    \ \nStep 3: \n     {Calculate the bounding box centre of detected object} \n \
    \    {Calculate the distance between the centre of the detected nacre bounding\
    \ box (C1) and \n      the center of the captured frame (C2)} \n     {Conversion\
    \ of distance (C = C2–C1) into degrees (new heading and tilt setpoint)} \n   \
    \  {Send command to sbRIO with new heading and tilt setpoint.} \n     If (C==0)\
    \  \n          {Go to step 4} \n \n88 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n     Else \n          {Go to step 3} \nStep 4: \n     {Send the command\
    \ to sbRIO to set the speed (fixed speed setpoint)} \n     {Take images I1 and\
    \ I2 in two different positions, where P1 and P2 are the pixel widths \n     \
    \ of the objects detected in both images} \n     {Calculate the distance using\
    \ the following equations. \n \n \n \n  \n     where F = 2.34 mm is the focal\
    \ distance, W is the width of the real detected object \n     If (the distance\
    \ D calculated > 2m) \n          {Go to step 4} \n     Else \n          {Go to\
    \ step 5} \nStep 5: \n     {Get accuracy of the specimen image} \n     If (accuracy\
    \ ≥ 80%)  \n          {Save point, save picture and resume mission} \n       \
    \   {Send command to sbRIO to save specimen’s position} \n     Else \n       \
    \   {Go back to the main mission without saving. It is not a specimen} \n    \
    \      {Go to Step 2} \nEnd () \n \n3.3. AUV Control \n \nThe most relevant characteristics\
    \ of the AUV used in the experiment are as \nfollows: the vehicle is physically\
    \ divided into two compartments (head and \nbody), consisting of five thrusters\
    \ (two for propulsion, two for depth control and \none for the rudder) and weighs\
    \ 170 kg. This vehicle is capable of submerging to \n200 m and has 7-hour autonomy.\
    \ Its two battery blocks (one supplies power to \nthe electronics and sensors\
    \ and the second to the thrusters) are reconfigurable to \n24V for greater autonomy\
    \ or to 48V for greater power and cruising speed. It can \nmove at 4 knots and\
    \ perform long-term missions while locating and identifying \nsubmerged targets,\
    \ photogrammetry and sonar inspection of the seabed. It is \nequipped with the\
    \ following devices: image sonar, side scan sonar, micro-USBL \n(UltraShort BaseLine)\
    \ for acoustic positioning, an inertial unit, GPS (Global \nPositioning System),\
    \ a DVL (Doppler Velocity Logger) for measuring \nunderwater movements, a camera\
    \ and a depth meter. \nAs shown in Figure 4.23, our underwater vehicle has a number\
    \ of elements \nand devices interconnected through different networks. While the\
    \ IoT gateway \nis in charge of recognition and communications with the camera\
    \ and the cloud, \nthe sbRIO controller is the AUV’s main control backbone. The\
    \ National \nInstrument sbRIO 9606 embedded controller integrates a real-time\
    \ processor \nwith a reconfigurable FPGA through its LabVIEW environment [215-216].\
    \ It \ncomprises Ethernet, CAN and I/O connectivity, as well as a 400-MHz CPU,\
    \ \n \n89 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n256MB DRAM,\
    \ 512MB storage, and other features listed in [215-216]. A consistent \ncode for\
    \ the sbRIO controller was fully developed in the LabVIEW environment \nfor AUV\
    \ management, control and command. \nThe modules in the sbRIO’s vehicle control\
    \ program comprise these operations: \n• CAN bus (reading and writing interface):\
    \ There are a number of nodes \nconnected to the vehicle's CAN bus, whose network\
    \ master is the sbRIO. Each \nof the nodes has a series of sensors and actuators\
    \ connected. The function of \nthese blocks is to receive information and send\
    \ commands to the different \nnodes through the CANopen protocol. The type of\
    \ data received or sent will \ndepend on the function of the node. \n• TCP/IP\
    \ \n(reading \nand \nwriting \ninterface): \nThis \nmanages \nTCP/IP \ncommunications\
    \ for receiving commands from IUNO and the IoT gateway, \nas well as sending navigation\
    \ information from the vehicle to the rest of the \nequipment on the Ethernet\
    \ network. \n• Data manipulation: This is responsible for adapting the data formats\
    \ from the \ndifferent sources (CAN, inertial unit, IUNO) to a common format within\
    \ the \nprogram and vice versa: e.g., conversion of latitude received through\
    \ the \nCAN network interface (UINT8 array type, extracted from a buffer) to I32\
    \ \ndata type. \n• Data saving: This saves the process and navigation information\
    \ in the sbRIO \nin TDMS (Technical Data Management Streaming) format files. TDMS\
    \ is a \nbinary measurement file format, focused on storing information in the\
    \ \nsmallest possible space. It can be exported to several formats (csv, xls,\
    \ txt, \netc.). \n• Heading \ncontrol/depth \ncontrol/velocity \ncontrol/heading\
    \ \ntilt \ncontrol: \nManagement of the different control loops for heading, depth,\
    \ velocity and \nhead tilt. These take on special importance in automatic or semi-automatic\
    \ \nnavigation modes. \n• Thruster control: As a result of the previous timed\
    \ loop, a heading, depth or \nposition setpoint is obtained. In this module, they\
    \ are processed to obtain as \na result a PWM (Pulse-Width Modulation) value to\
    \ be applied to each of the \nvehicle’s engines. \n• Automatic (IUNO)/manual mode\
    \ navigation: AEGIR developed at the \nDivision of Automation and Autonomous Robotics\
    \ (DAyRA) of the \nPolytechnic University of Cartagena, and the Ocean Server AUV\
    \ IVER2. \nIUNO’s capabilities and characteristics. An AEGIR vehicle can be handled\
    \ in \nboth modes: manual and automatic. This timed loop is in charge of selecting\
    \ \nthe appropriate navigation source. Only the automatic mode is considered in\
    \ \nthis paper. \n• Mission management: Once the mission created in IUNO is downloaded,\
    \ this \nmodule manages each of the waypoints to which the vehicle must navigate,\
    \ \ndispatching the different navigation commands for the heading control/depth\
    \ \ncontrol/position control timed loops. This module also handles the main \n\
    \ \n90 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nnavigation mode in\
    \ normal operations and the specimen tracking navigation \nmode, as described\
    \ in Section 7. \n \n4. Artificial Intelligence and Vision-Based Object Recognition\
    \ \n \n4.1 Object Detection Training in the Cloud \n \nThe Mar Menor, as the largest\
    \ saltwater lake in Europe with a wide range of \nflora, requires constant monitoring.\
    \ The 4G network covers the entire zone and \nconnects a large area to the Internet\
    \ to take full advantage of cloud computing \nservices. As described above, AUVs\
    \ are a complete fan mussel monitoring system \nthanks to being interconnected\
    \ to the latest cloud computing services. \nBesides the general object detection\
    \ models provided by cloud services, \ncertain others can be used to create their\
    \ own custom object detection model to \nidentify items and their location in\
    \ an image. Object detection models can be \ntrained to recognize objects that\
    \ are important to the user in specific domains. \nObject detection training data\
    \ is the set of object labels and locations in each \ntrained image. The tag or\
    \ label identifies what the object is. The location identifies \nwhere it is in\
    \ the image. It is also possible to identify more than one object in an \nimage.\
    \ Cloud services offer users a friendly interface to develop and deploy \ncustom\
    \ CV models. We identify the location by drawing a bounding box around \nthe object\
    \ and providing the top and left pixel coordinates of that box, along with \n\
    the width and height in pixels (Figure 4.25). \n \n \nFigure 4.25. Fan mussel\
    \ recognition training: defining a fan mussel bounding \nbox in different cloud\
    \ services. \nIn the case study, we trained about 90 photos on the same data set\
    \ in Azure, \nGoogle and IBM Watson cloud services, all of which offer nearly\
    \ the same service \nfor custom object detection. The training photos are a mix\
    \ of our own photos and \nothers from Creative Commons sources [217] (Figure 4.26).\
    \ The system is very \nsimilar to custom classification, except that this service\
    \ identifies the location of \nthe items in the image. The response also includes\
    \ a classification label for each \nitem detected and an identification confidence\
    \ score. \n \n \n91 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.26.\
    \ Pictures used for custom CV model training. \nAfter creating a custom object\
    \ detection model and completing the training, \nwe tested its fan mussel detection\
    \ capacity in other images using the Python \ncloud API, as shown in Figure 4.27.\
    \ \nThe trained vision model successfully identified a new specimen in the image\
    \ \nand also its location and its probability percentage score. The blue bounding\
    \ box \nis drawn by the Python program using the results received from the cloud.\
    \ \nAccording to the results and the AUV navigation sensor data, the proposed\
    \ \nAlgorithm 1 can estimate the distance between the AUV head box and the \n\
    detected specimen. \n \n \nFigure 4.27. New specimen detection using the IBM Python\
    \ API. \n5. Visual Servo Control and Distance Estimation \nVisual servo control\
    \ consists of computer vision data usage to control the \nAUV’s motion [218].\
    \ Related works on underwater vision tracking and visual \nservo control for autonomous\
    \ underwater vehicles have shown that vision and \nvisual servo control are imperative\
    \ in developing AUV systems, as the vision–\n \n92 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nAUV combination yields substantial benefits. Several\
    \ studies on underwater \ntracking focus on visual servoing, such as autonomous\
    \ alignment and dynamic \npositioning [218-219], pipeline following and planet\
    \ target tracking [220]. With \nthe advent of machine vision and deep learning,\
    \ it is currently viable to specify \nthe object to be tracked. ML object tracking\
    \ has already been tested in different \nunderwater applications, such as fish\
    \ tracking and diver following and tracking \n[221-222].  \nTo perform underwater\
    \ vision tracking in Mar Menor and track the \nunderwater Pinna nobilis species,\
    \ the fan mussel tracking algorithm is solved \nusing the object recognition cloud\
    \ API incorporated in the AUV control loop. \nThrough this algorithm, we verify\
    \ that a specimen has been detected, and from \nthere we calculate the coordinates\
    \ of its center (x, y). In this scenario, the AUV \nreduces speed, and a PID (Proportional–Integral–Derivative)\
    \ controller will keep \nthe object in the centre of the frame by adjusting AUV\
    \ yaw and head tilt to keep \nthe camera centred on the object detected [223-224].\
    \  \nWhen more than one specimen is detected, the system follows the one with\
    \ \nthe highest score. The x and y coordinates are adopted as information in the\
    \ object \ntracking process. To make the system effectual, the port and starboard\
    \ engines \nand AUV head tilt are adjusted to track the object using the object’s\
    \ coordinates \nas feedback. The thrust motors follow the position changes of\
    \ the object’s \ncoordinates by means of PID controllers. When the detected object\
    \ is centred, its \ndistance from the AUV camera is computed using the cloud API\
    \ results and a \ntriangular similarity algorithm [213-214]: \n \n    \U0001D437\
    \ = \U0001D44A \U0001D439\n\U0001D443\n \n(4.7) \n \nwhere P is the width of\
    \ the object in pixels and W is the width of the object itself. \nThe camera focal\
    \ distance F is fixed and the apparent P is obtained from the \ncloud results.\
    \ To obtain W and estimated distance D, a minimum of two pictures \nare required\
    \ at different distances from the object for calibration, as presented in \nFigure\
    \ 4.28 and Algorithm 1. \n \n \n93 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.28. Triangular similarity using a single camera [225]. \n(\U0001D437\
    \ +  ∆\U0001D451) \U0001D443\U0001D4611 = \U0001D437 \U0001D443\U0001D4612 =\
    \ \U0001D44A \U0001D439 \n(4.8) \n \n\U0001D437 =\n(∆\U0001D451 \U0001D443\U0001D461\
    1)\n(\U0001D443\U0001D4612− \U0001D443\U0001D4611)                           \
    \                                                                  (4.9) \n  \n\
    The cloud object detection API and the tracking algorithm are fully \nimplemented\
    \ using Python. The entire Python program is processed in the IoT \ngateway while\
    \ yaw and tilt are processed in the sbRIO main controller. The \noutput data coordinates\
    \ from the cloud are used to keep the AUV automatically \nfocused on the object\
    \ itself in the desired position. \nThe sbRIO main controller drives the robot’s\
    \ movements to keep the target’s \nbounding box in the centre of the camera image.\
    \ The IoT gateway continuously \nsends coordinate errors (distance, X position,\
    \ Y position) to this controller, so that \nthese data become the input for the\
    \ closed loop for tilt, heading and speed \nadjustments (Figure 4.29). \n \nFigure\
    \ 4.29. Closed control loop for object detection and tracking. \nFigure 29 presents\
    \ the modules and process involved in detecting \nand tracking the target. In\
    \ the object detection algorithm block, the \nsystem aims to keep the target in\
    \ the centre of the image. When the \nrelative size of the target has been obtained\
    \ from the object detection \nAPI, these control loops are kept operative while\
    \ the speed is \ngradually increased to calculate the estimated distance by means\
    \ of \nthe similarity triangulation algorithm. From then on, tilt, heading, \n\
    speed and control loops keep the target in the centre until the vehicle \nis at\
    \ the desired distance. The tilt and heading closed control loop \n \n94 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nwere successfully tested in\
    \ calm waters and slow currents, although \ndifficulties were encountered with\
    \ stronger currents. \nServo Control Latency \nThe visual system is required to\
    \ provide real-time results from the control \nloop with very low latencies. The\
    \ principal concern is the ability to detect the \ntarget and aim the camera at\
    \ the centre of the image. To obtain effective real-time \ncontrol, the delays\
    \ involved in initially detecting the target and those of the \nsensor and actuator\
    \ while tracking the object must be minimised (Figure 4.30) \n[226]. Three distinct\
    \ types of delay are involved. The first is actuator delays, \nwhich occur in\
    \ the feedforward loop when the delay is in the robot itself. The \nsecond type\
    \ is sensor delays in the feedback path of a closed-loop system, derived \nfrom\
    \ a sensor delay. This delay is present in any real-time control system with \n\
    visual feedback and depends on the amount of visual processing required. The \n\
    third type is transportation delays, or pure time delays, usually due to long-\n\
    distance communications. \n \nFigure 4.30. Basic closed-loop system with sensor\
    \ and actuator delays. \nTo reliably assess the servo control latencies, we modelled\
    \ the basic closed-\nloop system with sensor and actuator delays, as shown in\
    \ Figure 4.30. Y(s) is the \noutput signal and R(s) is the reference signal. The\
    \ sensor and actuator delays are \nrepresented, respectively, as \nand \nin the\
    \ frequency domain, the \n(undelayed) sensor dynamics by H(s), the (undelayed)\
    \ plant dynamics by G(s), \nand the controller by C(s). \nThe most important delays\
    \ in a control loop with visual feedback are those \ncaused by the sensor, and\
    \ the delay time directly affects the dynamic stability of \nthe control system.\
    \ System stability is determined by the poles of the \ninput/output transfer function,\
    \ i.e., the roots of the denominator. For a single-\ninput–single-output (SISO)\
    \ system, the denominator (characteristic equation of \nthe system) is simply\
    \ 1+ the loop gain, so that any stability analysis would \nincorporate the total\
    \ actuator and sensor delay to determine stability bounds. \n \n\U0001D44C(\U0001D460\
    )\n\U0001D445(\U0001D460) = \n\U0001D436(\U0001D460)\U0001D43A(\U0001D460)\U0001D452\
    −\U0001D460(\U0001D447\U0001D44E)\n1 + \U0001D436(\U0001D460)\U0001D43A(\U0001D460\
    ) \U0001D452−\U0001D460(\U0001D447\U0001D44E)\U0001D43B(\U0001D460) \U0001D452\
    −\U0001D460(\U0001D447\U0001D460)                                            \
    \    (4.10) \n \n95 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n \nand the\
    \ characteristic equation is: \n \n1 + C(s)G(s)H(s)\U0001D452−\U0001D460(\U0001D447\
    \U0001D44E+\U0001D447\U0001D460)  = 0 \n(4.11) \n \nThe effects of stability can\
    \ be analysed by studying the conditions of marginal \nstability. From the above\
    \ equation, the following expressions are deduced: \n \n|\U0001D436(\U0001D457\
    ⍵)\U0001D43A(\U0001D457⍵)\U0001D43B(\U0001D457⍵)||\U0001D452−\U0001D457\U0001D714\
    \U0001D447| = 1 \n(4.12) \n \n \n\U0001D43F(\U0001D436(\U0001D457⍵)\U0001D43A\
    (\U0001D457⍵)\U0001D43B(\U0001D457⍵))\U0001D43F(\U0001D452−\U0001D457\U0001D714\
    \U0001D447) = 180º  \n(4.13) \n \nAs \n = 1 for all \n, the magnitude of the system\
    \ is not affected by the delay. \nHowever, as L \nradians, it is clear that the\
    \ phase margin for a system \nwith a time delay decreases as the time delay increases,\
    \ leading to instability and \nthus constraining the bandwidth achievable in the\
    \ face of delays. \nOne way to deal with the pernicious effect of known or unknown\
    \ delays is \nto detune first-order gains. With a PID controller, this is performed\
    \ by reducing \nthe proportional gain (P) to levels where the system remains stable.\
    \ This \napproach has the disadvantage that the resulting response is slowed down\
    \ and, \ntherefore, the overall performance of the system is worsened. The servo\
    \ control \nmust ensure a compromise between performance and stability. The performance\
    \ \nis proportional to the value of the gain of the corrector; however, above\
    \ a certain \nvalue, the corrector tends to destabilize the system. \n \n5. Exploration\
    \ Case Study \n \nThe experimental exploration mission was carried out with the\
    \ objective of \ndetermining the viability of the previously described approaches\
    \ in detecting fan \nmussel specimens in an area of 250 m x 100 m in the Mar Menor\
    \ (with the \ncoordinates of Table 4.7). A cloud architecture approach (Figure\
    \ 4.34-a) and a \nhybrid approach, a combination of cloud architecture (main mission)\
    \ and edge \narchitecture (tracking mission) were adopted (Figure 4.34-b). The\
    \ aim of the \nhybrid approach was to take advantage of edge architecture’s lower\
    \ latency and \nfavourable cloud precision. The tests achieved in the previous\
    \ section lead us to \nconclude that the results of Azure custom vision are more\
    \ pertinent to our use \ncase application (in terms of latency and accuracy);\
    \ therefore, we decided to \nadopt both the cloud and edge Azure models for the\
    \ mission described below. \nTable 4.7. GPS coordinates of the area explored.\
    \ \n \n96 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nCorner \nLatitude\
    \ \nLongitude \nNorth east \n37.697635º −0.780121º \nNorth west 37.697635º −0.782876º\
    \ \nSouth west 37.696825º −0.782876º \nSouth east \n37.696825º −0.780121º \n \n\
    Our sailing operation started in a vessel equipped with a robotic arm that \n\
    placed the vehicle in the water. After defining the coordinates of the inspection\
    \ \narea, the mission was planned on IUNO software (Figure 4-31) according to\
    \ the \nweather forecast, the time available and the width of the vehicle’s search\
    \ path. \n \nFigure 4.31. Mission generated in IUNO and uploaded into AUV. \n\
    The AUV employed for the experiment was connected to the buoy as shown \nin Figure\
    \ 4-32. The control station on board the vessel was connected to the AUV \nby\
    \ 4G communications. The different systems were checked before the AUV was \n\
    placed in the water: control, lighting, thrusters, 4G communications, vision,\
    \ etc. \nAfter successfully validating the systems, the vehicle was launched,\
    \ and the \nmission was transferred from IUNO to the AUV. \nWe initiated the main\
    \ mission using the first approach (cloud architecture for \ndetection and tracking).\
    \ The AUV started to explore the area for possible \nspecimens. The average depth\
    \ of the inspection area was 5.02 m and the vehicle \nremained at an average height\
    \ of 2.01 m above the seabed. \nThe first of the six sweeps (Figure 4.31) was\
    \ completed without detecting any \npossible specimens. The first fan mussel was\
    \ detected with 63% accuracy in the \nsecond track, when the AUV switched to the\
    \ secondary mission mode to track it \n(object location in the frame and distance\
    \ calculation). However, this turned out \nto be quite impractical due to the\
    \ high latency of the cloud connection. A timeout \nexception occurred during\
    \ the tracking mission and the algorithm chose to ignore \nit and resume the main\
    \ mission. As described in Section 6, the detection fails if a \ndeadline is missed\
    \ due to transmission delays, which affects the dynamic \nstability of the control\
    \ system. The technical team therefore decided to abort the \n \n97 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmission, return to the starting point\
    \ and launch the same mission in the “hybrid” \nmode. \n \n \nFigure 4.32. Deploying\
    \ the platform to initiate the mission. AUV submarine \nconnected to a buoy via\
    \ a DSL cable. \nThe hybrid mission mode was initiated, and the cloud connection\
    \ was used \nto process the photos sent during the main tracking mission. On the\
    \ second \nsweep, the cloud results in the gateway indicated the presence of a\
    \ specimen with \n64% probability. The vehicle switched to the tracking mode.\
    \ At this point, the \nAUV began manoeuvring to place the target in the centre\
    \ of the image, while the \ninference was switched to the edge model in the IoT\
    \ gateway instead of the cloud \nto reduce latency. The AUV was able to follow\
    \ the suspected specimen up to a \ndistance of 2.13 m. The accuracy of the analysed\
    \ image at this distance was 83.8%, \nusing the trained edge model. For greater\
    \ certainty, the inference was switched \nto the cloud for the last picture to\
    \ confirm the find. In this hybrid mode, the edge \nwas used to speed up tracking\
    \ and AUV response. At this point, the AUV ended \nthe secondary mission mode,\
    \ registered the find as positive, saved its coordinates \nand resumed the main\
    \ mission (Figure 4.33). \n \n \nFigure 4.33. Specimen detection and positioning\
    \ in IUNO. \n \n98 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nNo further\
    \ specimens were detected until the fourth sweep, when another \nwas detected\
    \ with 38% probability. Once again, the vehicle switched to tracking \nmode, centred\
    \ the target in the image and performed the approach manoeuvre \nas before. After\
    \ halting at 2.06 m from the target, the recognition algorithm \nindicated that\
    \ the target was a fan mussel with 59% probability. As the minimum \nconfirmation\
    \ requirement in terms of the probable detection threshold at this \nstage is\
    \ 80%, the target was ignored, and the main mission was resumed. Due to \nthe\
    \ real-time communications, the target was in fact found not to be a fan mussel\
    \ \nbut a dark-coloured rock. On the sixth sweep, the mission and inspection were\
    \ \ncompleted after detecting one target specimen and discarding another possible\
    \ \ndetection that turned out to be a rock. \n \n6. Performance \n \nCloud and\
    \ edge computing are considered adequate platforms to \nincorporate artificial\
    \ intelligence approaches. This paper primarily focuses on the \nissues related\
    \ to the real-time constraints of using an AI cloud in both \nenvironments. Our\
    \ AUV system is designed to collect and interpret underwater \nimages to track\
    \ the fan mussel population in real time by an automatic processing \nmethod.\
    \ This automated approach is based on DL image processing techniques, \nsuch as\
    \ CNN, to detect the position of a possible specimen in a captured photo. \nThe\
    \ IoT gateway algorithm establishes the connection between the AUV control \n\
    system and cloud image processing techniques. The results of our proposed \nsystem\
    \ are compared with cloud and edge image processing in terms of latency \nand\
    \ certainty. Therefore, we aim to compare the response time between the cloud\
    \ \nand edge inference. \nMicrosoft Azure cloud was first compared with IBM and\
    \ Google clouds, as \nshown in Figure 4.34 [227-229]. The second comparison evaluated\
    \ the same cloud \nservice with inference in the edge and comparing the same results\
    \ in the cloud. \n \n \n                                                     \
    \         (a)                                                                (b)\
    \ \n \n99 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nFigure 4.34.\
    \ Communication edge cloud. (a) Training and inference in the \ncloud; (b) training\
    \ in the cloud, inference in the edge. \nWe describe the various network connections\
    \ and the performance metrics \nfor the architectures given in Figure 4.34. We\
    \ first assessed the delay between the \ndifferent terminals in the cloud architecture\
    \ and then compared it to that of the \nedge computing architecture. We evaluated\
    \ the performance of each trained \nmodel in the cloud and in the edge. Below,\
    \ we compare the performance of each \narchitecture, using LattePanda as an IoT\
    \ gateway, with a 1.8-GHz Intel quad-core \nprocessor, 4 GB RAM and 64 GB on-board\
    \ flash memory. \n6.1. Delay Assessment in the Proposed Platforms \nFigures 4.35\
    \ and 4.36 exhibit the different data flows via the various \ncommunication networks\
    \ for the cases of cloud and edge computing. From data \nacquisition (sensors)\
    \ to actuators, the information flow goes through different \nnetworks: CAN and\
    \ Ethernet in the case of edge architecture, and the Internet \nand DSL for the\
    \ cloud architecture. This represents the difference in latency \nbetween the\
    \ two modes and highlights the critical points in each case. \nThe highest latency\
    \ expected in the case of edge computing is Tinference, and the Tcloud \nis the\
    \ one expected in the cloud. \n6.1.1. Cloud Architecture \nIn the adopted cloud\
    \ architecture, all the generated images are sent to the \ncloud services and\
    \ the inference is performed entirely in the cloud. This makes \nthe application\
    \ fully dependent on the cloud results in order to make the \nnecessary adjustments,\
    \ which are crucial in the case of intermittent connectivity. \nFigure 4.35 shows\
    \ the different delays in the use case process. \n \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \n \n100 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nThe response time in the system can be divided into delays,\
    \ as modelled in \nEquation (4.14): \n \n\U0001D447 = \U0001D447\U0001D45B\U0001D44E\
    \U0001D463 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    1 + \U0001D447\U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\
    \U0001D462\U0001D451 + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D461\
    2 + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.14) \n \n \nwhere: \n(1) Tnav is the navigation sensor time, \n(2) Tsb1\
    \ is the acquisition time of the sensor data in sbRIO, \n(3) Tgt1 is the processing\
    \ time of the first and second threads in the IoT gateway \npresented, \n(4) Tby1\
    \ is the transmission time from the AUV to the buoy, \n(5) Tcloud is the time\
    \ needed to send photos to the cloud and receive the response \nresults, \n(6)\
    \ Tby2 is the transmission time of cloud results to the AUV, \n(7) Tgt2 is the\
    \ processing time of the first, second, and third threads in the IoT \ngateway\
    \ presented, \n(8) Tsb2 is the IoT gateway data acquisition time in sbRIO, and\
    \ \n(9) Tact is the actuation time. \nWhen the AUV starts up the IP camera stream,\
    \ the Tsens value can be expressed \nin two ways depending on the data stream,\
    \ according to Equations (15) and (16): \n \n\U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 = {\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1  if  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\n\U0001D447\
    \U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E if \U0001D447\U0001D45B\
    \U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F1 < \U0001D447\U0001D450\U0001D44E\
    \U0001D45A\U0001D452\U0001D45F\U0001D44E  \n(4.15) \n \n\U0001D447 = \U0001D447\
    \U0001D460\U0001D452\U0001D45B\U0001D460 + \U0001D447\U0001D454\U0001D4611 + \U0001D447\
    \U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D4612 + \U0001D447\
    \U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461 \n(4.16) \n \n\
    \ \nTcloud is composed of three different delays: Trequest is the transmission\
    \ time of each \nphoto to the cloud, Tinference is the processing time of the\
    \ transmitted photo in the \ncloud service, and Tresponse is the time from the\
    \ cloud to the buoy. \n \n\U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ = \U0001D447\U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461\
    \ + \U0001D447\U0001D43C\U0001D45B\U0001D453\U0001D452\U0001D45F\U0001D452\U0001D45B\
    \U0001D450\U0001D452 + \U0001D447\U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\
    \U0001D45B\U0001D460\U0001D452 \n(4.17) \n \n6.1.2. Edge Architecture \nIn the\
    \ edge architecture, the data remains in the local machine and the images \nare\
    \ not sent to the cloud; however, the application needs a minimal connection \n\
    to the cloud to report usage, which is suitable for intermittent connectivity.\
    \ The \ncloud connection is almost negligible; instead of sending photos to the\
    \ cloud for \nprocessing, the model uploads to the local IoT gateway and performs\
    \ the \ntreatment. We therefore neglect the cloud connection in this architecture\
    \ and only \nconsider the connections in the AUV. \n \n101 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nFigure 4.36. Edge architecture latency in the proposed\
    \ platform. \nIn the edge model deployed in the IoT gateway, the overall response\
    \ time of \nthe edge architecture in the AUV over the Ethernet and CAN networks\
    \ is \nmodelled as: \n \n\U0001D447 = \U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    \ + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.18) \n \nWhere Tsens is expressed as: \n \n\U0001D447\U0001D460\U0001D452\
    \U0001D45B\U0001D460 = {     \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1   if.  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\
    \U0001D44E\n\U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\
    \    if.\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 < \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E  \n\
    (4.19) \n \nTgt in this case depends on Tthreads executing the 4 threads in the\
    \ IoT \ngateway and the custom model Tinference uploaded from the cloud. \n \n\
    \U0001D447\U0001D454\U0001D461 = \U0001D447\U0001D461ℎ\U0001D45F\U0001D452\U0001D44E\
    \U0001D451\U0001D460 + \U0001D447\U0001D456\U0001D45B\U0001D453\U0001D452\U0001D45F\
    \U0001D452\U0001D45B\U0001D450\U0001D452 \n(4.20) \n \n6.2. Metrics \nThe Azure\
    \ Custom Vision, Google cloud and Watson IBM services allow \nusers to load a\
    \ set of image data and define the bounding box of each desired \nobject in the\
    \ image. To train the model effectively, the images must be varied and \nas close\
    \ as possible to the data on which the predictions will be made. Camera \nangle,\
    \ blurring, background, lighting, size, low resolution and type are all \nimportant\
    \ variations of the image that affect the training process. \nOnce the training\
    \ was completed, we calculated the model’s performance \nusing new image datasets\
    \ (i.e., not included in the training dataset), shown in \nTable 8. Precision\
    \ indicates the fraction of identified classifications that are \n \n102 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \ncorrect, while recall indicates\
    \ the fraction of actual classifications that are \ncorrectly identified. IoU\
    \ (intersection over union) is a metric of how successfully \na model predicts\
    \ the objects’ locations and is gauged using the area of \noverlapping regions\
    \ of the predicted and ground truth bounding boxes, defined \nas: \n \n\U0001D43C\
    \U0001D45C\U0001D448 = \U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453\
    \ \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\U0001D45D\n\U0001D434\
    \U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\U0001D45B\U0001D456\
    \U0001D45C\U0001D45B  \n \n  (4.21) \n \nUnlike IBM in Azure Custom Vision and\
    \ Google cloud, the AI model can be \nexported in different formats (TensorFlow,\
    \ Docker) specially adapted to edge \ndevices, as opposed to in the cloud. The\
    \ model trained for cloud use is different \nfrom that trained for the edge as\
    \ regards accuracy and response time. We used \nthe same photos to train and test\
    \ the trained models for both edge and cloud use \nin the trials. Figure 4.37\
    \ shows some differences in terms of the accuracy of new \nphotos not used in\
    \ the training phase. The five tests clearly show the limits of \neach example;\
    \ for instance, in test 3, the picture was blurred, and Google cloud \ncould not\
    \ detect the mussel, while Microsoft detected it with 83% accuracy and \nIBM only\
    \ 15% accuracy. In test 2, all three clouds detected an unknown red object \n\
    stuck in the sub-bottom as a mussel with different percentages, which shows the\
    \ \nlimitation of the models regarding colour changes. \n \n \nFigure 4.37. Cloud-based\
    \ custom models for detecting new specimens. \n \n103 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nIn order to evaluate the performance of the proposed\
    \ object detection \nmodels, in both the cloud and edge, we used the following\
    \ standard performance \nmetrics: \n \n\U0001D45D\U0001D45F\U0001D452\U0001D450\
    \U0001D456\U0001D460\U0001D456\U0001D45C\U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\
    \U0001D443+\U0001D447\U0001D443 \n \n(4.22) \n \n\U0001D45F\U0001D452\U0001D450\
    \U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441+\U0001D447\
    \U0001D443 \n \n(4.23) \nwhere precision indicates the fraction of identified\
    \ detections that were correct, \nand recall indicates the fraction of actual\
    \ detections that were correctly identified. \nFP (False Positive) represents\
    \ the number of negative samples judged to be \npositive, TP (True Positive) is\
    \ the number of positive samples judged to be \npositive, and FN (False Negative)\
    \ is the number of positive samples judged to be \nnegative. \nTable 4.8. Accuracy\
    \ measurement in different platforms. \n \nTP \nFP \nFN \nPrecision \nRecall \n\
    IoU \nIBM \n28 \n2 \n8 \n0.933333 \n0.777778 \n0.82506 \nGoogle \n22 \n3 \n13\
    \ \n0.916666 \n0.611111 \n0.83364 \nAzure cloud \n33 \n4 \n3 \n0.891892 \n0.916667\
    \ \n0.86601 \nAzure edge \n24 \n3 \n11 \n0.888889 \n0.666667 \n0.678634 \n \n\
    The accuracy measurement tests were performed on all three cloud \nplatforms.\
    \ We also adopted the Azure edge model as it shows a better IoU metric \nscore\
    \ than Google. The accuracy test was performed on more than thirty photos \nof\
    \ mussels detected by our AUV camera, using the same photos in the three \ndifferent\
    \ clouds. The results given in Table 8 clearly show the difference between \n\
    the AI cloud services. \n6.3. Latency Evaluation \nSince most of the cloud APIs\
    \ are based on the HTTP protocol, we performed \na total of 100 HTTP throughput\
    \ tests using SpeedTest between the web server \nand the IoT gateway installed\
    \ in the AUV. The tests were performed in the Mar \nMenor experimental area through\
    \ the 4G connection. The average results of the \ntests carried out in this experimental\
    \ area were as follows: round trip delay: 66ms; \ndownload: 16.6 Mbps; upload:\
    \ 19.3 Mbps. The average size of the image sent \nfrom the AUV to the cloud was\
    \ approximately 194 kb. \nThe local network which connects the vehicle, and the\
    \ buoy presents a low \nfixed latency. This was measured by a 100-automated-delay\
    \ measurement \ncampaign. The average latencies between the IoT gateway and the\
    \ different \n \n104 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    devices in the vehicle’s Ethernet network were as follows: sbRIO: 0.9ms; camera:\
    \ \n1.1ms; 4G router (buoy): 1.2 ms. \nThe latency results are summarized in Table\
    \ 4.9, where average, minimum \nand maximum response time values are calculated\
    \ for each endpoint \narchitecture. The experimental set-up was based on Azure\
    \ and IBM cloud \narchitectures, plus another edge architecture using a custom\
    \ model formed by \nAzure and processed by the IoT gateway. Although IBM Watson\
    \ and Azure \ncustom vision are available worldwide, the locations of the deployments\
    \ differ; \nWatson is deployed in the U.S. and South Korea [226], while Google\
    \ cloud and \nAzure are deployed in various locations around the world [227, 228].\
    \ In this case, \nthe Azure and Google cloud services are deployed in Western\
    \ Europe, while IBM \nis in Dallas, USA. All the samples in each architecture\
    \ were thoroughly verified \nin an experimental campaign with over 100 valid samples.\
    \ The experiments \ncarried out were based on Equations (4.14) and (4.16) and\
    \ Python software. The \nlatter was employed to measure the overall latency. \n\
    Table 4.9. Latency measurement in different platforms. \n \nTotal Response \n\
    \ time (ms) \nCloud response  \ntime (ms) \nIoT Computing  \ntime (ms) \nCapturing\
    \ and \nwriting time (ms) \n \nMin \nMax \nMean \nMin \nMax \nMean \nMin \nMax\
    \ \nMean \nMin \nMax \nMean \nIBM \n1407 \n4060 \n2064 \n1280 \n3896 \n1935 \n\
    0 \n0 \n0 \n93 \n192 \n129 \nGoogle \n1291 \n4384 \n1696 \n1160 \n4071 \n1520\
    \ \n0 \n0 \n0 \n92 \n196 \n130 \nAzure \n1298 \n4572 \n1703 \n1171 \n4435 \n1571\
    \ \n0 \n0 \n0 \n92 \n196 \n131 \nAzure \nedge \n623 \n687 \n634 \n0 \n0 \n0 \n\
    523 \n595 \n532 \n93 \n194 \n130 \n \nThe results reported in Table 9 show the\
    \ differences between the proposed \narchitectures in terms of latency. Despite\
    \ the fact that image processing in edge \ncomputing is performed on the IoT gateway,\
    \ the total response time is \nsignificantly lower than the latency obtained with\
    \ cloud computing. The faster \nrunning time of the custom AI detection model\
    \ ensures real-time tracking and \nnavigation adjustment. Edge average response\
    \ time is almost three times less \nthan that of the cloud. However, the edge\
    \ model is less accurate than the cloud \nmodel; in fact, the edge model loaded\
    \ from the cloud is optimized as far as \npossible to meet the requirements of\
    \ tiny device platforms. \n \n \n \n \n \n \n105 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nIII. System 3. Autonomous Marine Robot Based on\
    \ AI \nRecognition for Permanent Surveillance in Marine \nProtected Areas \n \n\
    1. Introduction  \n  \nThere are unique areas in the marine environment that must\
    \ be protected due \nto their singular characteristics and high environmental\
    \ value. These habitats are \nparticularly sensitive to alteration or disturbance\
    \ by humans, changes in the \necosystem or changes in climate. One of the legal\
    \ tools for their protection is the \ndeclaration of the area as a Marine Protected\
    \ Area (MPA), which legally allows \nfor the establishment of a scenario of maximum\
    \ protection [229]. The main \npurpose of MPAs is to regenerate fishing resources,\
    \ preserve natural resources, \nconserve marine species and recover ecosystems.\
    \ \nA marine reserve is defined as a category of marine protected area with legal\
    \ \nprotection mainly against fishing or development. The main limits as a general\
    \ \nrule are professional fishing (with the exception of a few authorized boats)\
    \ and \ndiving (also with authorized exceptions), while recreational fishing,\
    \ underwater \nfishing and anchoring are totally prohibited. These activities\
    \ in marine reserves \nmust be monitored by the authorities to guarantee the care\
    \ of the ecosystem by \nlaw [230]. A marine reserve can be made up of a single\
    \ area or different non-\nadjacent areas and contains at least one integral reserve,\
    \ which is a natural space \nwith high ecological and biological value due to\
    \ a unique and delicate ecosystem \nsensitive to any alterations. \nThe restrictions\
    \ are even stricter in integral reserves: all activities are \nforbidden, with\
    \ the exception of authorized scientific activities and sailing at a \nlimited\
    \ speed. In Spain there are a total of eleven marine reserves [231], four are\
    \ \non islets, islands and reefs far from inhabited areas and ports, and the rest\
    \ are on \nthe coast or near inhabited areas. The surveillance of areas far from\
    \ the coast is a \nreal challenge: inspection vehicles must be autonomous and\
    \ must not be \ncompromised by the risk of going adrift. Long-distance communications\
    \ with the \nland-based station must be fluid and stable, especially if 4G or\
    \ 5G coverage is not \navailable, as in most marine areas far from the coast and\
    \ in the video surveillance \nscenario, image transmission requires a highly stable\
    \ bandwidth. All these \nrestrictions are a major challenge for the surveillance\
    \ of marine reserves on the \nhigh seas. \nSeveral measures have been adopted\
    \ for the monitoring and surveillance of \nmarine reserves. The materials and\
    \ human resources are available to carry out \n \n106 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nroutine inspections or to set up devices to detect illegal\
    \ fishing. In general, all \nmarine reserves are equipped with vessels, georeferenced\
    \ cameras, night vision \nbinoculars, telescopes and ROVs, among others [231].\
    \ However, all these \nmeasures and means have the same disadvantage: the lack\
    \ of a permanent \npresence. Despite the measures adopted, it is not possible\
    \ to permanently \nmonitor the nature reserve with these means, and the identification\
    \ and arrest of \noffenders is practically incidental. This is why it is very\
    \ difficult to obtain records \nof those who have accessed protected areas and\
    \ to obtain real-time alerts to \nidentify those responsible in the event of damage\
    \ or alteration of the ecosystem. \nUnfortunately, even with the above-described\
    \ means and resources illegal \nactivities such as anchoring or poaching still\
    \ take place. \nProtecting remote marine areas with the currently available means\
    \ is not \nenough for their full protection, especially in integral reserves.\
    \ The challenges are \nquite demanding and even more so in permanent surveillance.\
    \ Autonomous \nSurface Vehicles (ASV) are ideal in this scenario for autonomous\
    \ navigation, but \nthere is also another issue. In order to monitor remote marine\
    \ reserves, the \ncapacity to detect and identify specific types of vessels is\
    \ required. Detection and \nidentification by humans is difficult to equal in\
    \ this scenario and only visual \nrecognition technologies based on artificial\
    \ intelligence (AI) and the Internet of \nThings (IoT) can offer a detection capacity\
    \ close to human capabilities. \nThere are also other issues, mainly water quality,\
    \ pollution and the effect on \nthe ecosystem. In a previous work we proposed\
    \ an autonomous system \nconsisting of an autonomous solar-powered marine robot\
    \ with specialized \nsensing systems [232], designed to carry out long-term observation\
    \ missions in \nshallow water, collecting georeferenced oceanic data to monitor\
    \ and analyse \nphysical-chemical water parameters. \nWe therefore consider permanent\
    \ surveillance and inspection of marine \nreserves to be vital. For this, we introduce\
    \ the concept of the \"watchdog\"; a \nwatchdog roams around an area (for example,\
    \ a fenced-in area around a house). \nAs soon as an intruder is detected, the\
    \ watchdog alerts the owner and deters the \nintruder from entering. If he enters\
    \ the premises, the guard dog chases him out. \nThis concept, applied to autonomous\
    \ navigation by means of ASV craft together \nwith the concepts of Industry 4.0\
    \ applied to marine environments, gives us a \npowerful proposal for the permanent\
    \ surveillance of marine reserves. \nThis paper proposes and evaluates an autonomous\
    \ marine vehicle based on \nartificial intelligence, designed to recognize and\
    \ classify vessels considered as \npotential risks according to their type and\
    \ activity. Its main goal is to track and \nfollow them in real time to obtain\
    \ information (identification and position, video \nrecording, etc) using automatic\
    \ image recognition. When a vessel classified by \nthe algorithms as a potential\
    \ risk inside an integral reserve is detected and \nremains in the same position\
    \ for a certain period, it could mean illegal activity. \nIn the experiment, the\
    \ proposed Autonomous Guard based on the ASV was \n \n107 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntested in this scenario in order to recognize, follow\
    \ and identify vessels based on \nan autonomous navigation and AI image recognition.\
    \ \nThe series of requirements for this include the following factors: it cannot\
    \ \nalter the ecosystem, so its energy source must be totally renewable; its capacity\
    \ \nto detect and recognise target vessels must be precise and reliable, the ability\
    \ to \ndistinguish between different types, and most importantly, the detection\
    \ capacity \nshould not compromise the ASV’s autonomy. \nThere are radar-based\
    \ detection AUVs with fast and accurate detection \nsystems, but this is not enough\
    \ for precise recognition and identification [233]. In \n[234] SAR (Synthetic\
    \ Aperture Radar) images are used together with deep \nlearning (DL) algorithms\
    \ to detect and recognize ships by means of a powerful \nCPU and local graphics\
    \ cards and low computational time, but these have a high-\npower consumption,\
    \ which is incompatible with a stand-alone vehicle. Due to \nthe inevitable vibration\
    \ and constant movement of the autonomous vehicle it is \nadvisable to use single\
    \ board devices and CPUs. This type of solution is suitable \nfor fixed surveillance\
    \ stations, but not for autonomous vehicles, whose autonomy \nis compromised.\
    \ On the other hand, fixed stations are not applicable in this case \ndue to several\
    \ factors, such as limited monitoring range, low reaction capacity, \nexposure\
    \ to environmental conditions and marine environments (in case of \nbuoys), ecosystem\
    \ alteration (in case of installations on islets or reefs), among \nothers. In\
    \ [236] a unified energy management framework was used to enable a \nsustainable\
    \ edge computing paradigm powered by distributed renewable energy \nresources.\
    \ Edge computing technologies significantly simplify local computing \ncapacity\
    \ and increase energy efficiency, while maintaining low latency. AI-based \ntechnologies\
    \ such as edge and cloud computing have proven to be accurate in \nterms of recognition\
    \ results and data analysis [236-238]. In [239] hybrid use of \ncloud/edge technologies\
    \ is considered optimal, significantly reducing the \npercentage of local computing\
    \ by deriving most of the calculation to remote \n(cloud) servers and highly optimised\
    \ algorithms through suitable and specific \ntraining processes. \nAs the paper’s\
    \ main contribution and novelty, we propose a hybrid \nCloud/Edge technology,\
    \ optimised for high image recognition accuracy, \nminimum power consumption and\
    \ low latency, in order to increase vehicle \nautonomy and efficiency, increase\
    \ the likelihood of mission success and security \nduring autonomous surveillance\
    \ missions in marine reserves with MASS. High \npower consumption compromises\
    \ vehicle autonomy during image recognition \nand identification, and high latency\
    \ compromises the control and tracking \nalgorithms. To select the most appropriate\
    \ technology according to the scenario \nand circumstances, we propose the SAAO\
    \ (Smart Algorithm for Autonomy \nOptimization by selecting the proper AI technology\
    \ according to the current scenario). \nThis algorithm is optimized to select\
    \ the appropriate technology (cloud or edge \ncomputing) according to the situation\
    \ and circumstances. \n \n \n108 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n2. Proposed Platform for Surveillance in Marine Protected Areas \n \nThe BUSCAMOS-VIGIA\
    \ ASV was developed by DAyRA (División de \nAutomatización y Robótica Autónoma)\
    \ group at the UPCT. One of its achievements \nis described in [232], where we\
    \ gave the ASV the capability to make long-term \nmissions to acquire data from\
    \ multiparameter probes in the Mar Menor (Murcia, \nSpain) on factors to decide\
    \ the urgency in inspecting a specific area based on \nfuzzy logic. \n \n2.1.\
    \ The ASV–IoT Architecture Development \n \nA framework of this description together\
    \ with the hardware and software \narchitecture in the proposed system are shown\
    \ in Figure 4.38: \n \n \nFigure 4.38. BUSCAMOS-VIGIA framework. \nThe framework\
    \ represents the whole system as follows: it is structured into \ntwo main blocks:\
    \ the ASV block, Communication base station AP (Access Point) \nblock and Cloud/Internet\
    \ block. The first represents the logic or physical \nelements included in the\
    \ vehicle, and the second collects the elements in the \n \n109 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nremote station and cloud computing server.\
    \ Each main block is classified into \nlayers. The ASV block is divided into 4\
    \ layers: The Energy layer, \nSensors/Actuators layer, Navigation control layer,\
    \ and Edge layer. The energy \nlayer is formed of the elements that provide energy\
    \ and autonomy to the vehicle. \nAs can be seen, the batteries can be charged\
    \ in two ways: through photovoltaic \ntechnology (during navigation - so as to\
    \ extend the vehicle’s range - or in port) \nor through an AC source, when solar\
    \ power is not enough, or a quick charge is \nneeded when moored. The next layer\
    \ is the Sensors / Actuators layer, with the \ndifferent detection elements, which\
    \ provide information to the upper layers in \nthe framework (such as GPS, inertial\
    \ unit, LiDAR and cameras). Here also are the \nrudder and thrusters. The upper\
    \ layer is for Navigation and Control and consists \nof a NI cRIO controller (National\
    \ Instrument Compact Remote Input Output) \n9022 model and its peripheral elements\
    \ and modules. The elements in this layer \nare responsible for autonomous navigation\
    \ and use information from the sensors \nin the lower layer and the AI image recognition\
    \ response obtained from the IoT \nGateway in the upper layer. The cRIO controller\
    \ is formed of a main body, based \non a processor and FPGA, together with a reconfigurable\
    \ chassis, with a series of \nmodules necessary for several communication protocols\
    \ to command and \nacquire data from the lower layer, such as CAN-NMEA2000, I2C,\
    \ RS232 and \nRS485, according to the current hardware architecture. There are\
    \ also a serial of \ncode block and algorithms, described in Section 3.3. The\
    \ Upper or Edge layer is \nformed by the IoT Gateway where on-board AI takes place\
    \ by running the \nalgorithms in charge of the camera’s image processing and analysing\
    \ system. \nThe second main block, called “Cloud / Internet”, contains just one\
    \ layer in \nthe highest position of the framework, called the Cloud layer, containing\
    \ not only \nthe AI services, but also information and resources provided in real\
    \ time from \nauthorities and services, which are essential for planning or modifying\
    \ the ASV \nmission. Also found here is the IUNO (Interface for Unmanned drones)\
    \ software. \nThe IUNO software platform was also designed by the DAyRA group\
    \ of the \nPolytechnic University of Cartagena. The platform manages the integrated\
    \ \ncontrol of multiple unmanned marine vehicles with the aim of simplifying \n\
    maritime operations. The results obtained from each vehicle, regardless of its\
    \ \ncharacteristics, facilitate the success of the operation with a high degree\
    \ of \nautomation. This software has already been used in previous experiments\
    \ and \noperations, such as [223,239], and is the only point with human intervention.\
    \ \nActivities such as mission planning or remote supervision are commanded and\
    \ \nmanaged from here.  \nBetween the ASV and Cloud/Internet blocks we find the\
    \ Communications \nbase station AP block, containing the Radio link layer. This\
    \ provides high \nwideband, low latency and long-range WiFi communications between\
    \ the \nvehicle and the land. It is formed by two Ubiquiti ROCKET M2 2.4 GHz modules\
    \ \n(one on land and another in the vehicle) and its antennas, with Ubiquiti airMAX\
    \ \nconnection. Due to the characteristics of the communications scenario, the\
    \ land \n \n110 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nantenna is\
    \ the sector type and the on-board is omnidirectional. The land station \nis connected\
    \ to the Internet. This layer is especially crucial in areas where 4G-5G \ncover\
    \ is not available, as in most integral reserves. \nThere is an extra block in\
    \ both the ASV and Cloud/Internet main blocks called \nthe AI (Artificial Intelligence)\
    \ block. As explained in Section 4, it is formed of the \nAzure Cloud general\
    \ model, Azure cloud custom model and Azure Edge custom \nmodel for AI recognition\
    \ according to the smart algorithm criteria described in \nSection 4.4. \nThe\
    \ most relevant characteristics of the ASV used in the experiment \ndescribed\
    \ in this paper are as follows: the vehicle is 5 meters long. It has a robust\
    \ \nstructure that protects the devices from the weather, as well as a sunroof.\
    \ The \ninside of the vessel is subdivided into two sections by means of a bulkhead.\
    \ In \nthe stern are the elements related to power and propulsion: Block of 8\
    \ 100Ah \nbatteries configured in 2 parallel lines, providing 48V nominal power\
    \ and 14h \nautonomy. Two electric outboard motors, Torqeedo C4.0 Cruise model,\
    \ allow it \nto sail at a maximum speed of 6 knots. It has two racks, located\
    \ on the starboard \nand port sides. In the starboard rack are the IoT Gateway\
    \ (LattePanda single \nboard computer, with 1.8-GHz Intel quad-core processor,\
    \ 4 GB RAM and 64 GB \non-board flash memory) and the WiFi communications elements,\
    \ energy \nmanagement of different equipment, photovoltaic regulator and electrical\
    \ panel. \nThe main elements of the port rack are: the NI cRIO 9022 (National\
    \ Instruments \nCompact Remote Input Output) controller, the rudder controller\
    \ and the \nelectronic periphery. It is equipped with side-scan sonar, echo sounder,\
    \ GPS, \ninertial unit and radar. It also has 4 LiDAR-Lite 3 (Garmin) in both\
    \ bands, bow \nand stern, as safety elements for obstacle detection. It has a\
    \ solar roof formed by \n5 Enecom HF 130 panels that extend the autonomy of the\
    \ vessel according to the \nenvironmental conditions, connected to a photovoltaic\
    \ regulator and its battery \npack. The battery pack can also be charged by AC\
    \ chargers. In terms of vision, \nthe ASV is equipped with an AXIS P5534-E PTZ\
    \ camera (in the bow) with 18x \noptical and 12x digital zoom (total 216x), with\
    \ a resolution of 1280x720p, as well \nas three additional Ubiquiti Air Cam cameras\
    \ in the stern on both starboard and \nport. Its renewable energy source does\
    \ not leave a carbon footprint and it thus \nhas no environmental impact, which\
    \ makes it suitable for permanent navigation \nin marine reserves, particularly\
    \ in integral reserves. Figure 4.39 shows a picture \nof the BUSCAMOS-VIGIA vehicle.\
    \   \n \n \n111 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \n2.2 Implemented Vessel recognition and tracking algorithm\
    \ \nIn this section, we outline and itemize the development of the above-\nmentioned\
    \ IoT-ASV autonomous system, specifically the algorithm related with \noverall\
    \ mission management and its stages, vessel recognition system and the \nimplemented\
    \ tracking algorithm. It has five main blocks, namely, the IoT \ngateway, the\
    \ IP cameras, the ASV control system, the remote-control station and \nthe cloud/edge\
    \ AI image recognition source. \nThe overall mission is planned and triggered\
    \ by IUNO software in the cloud \nbase station by setting either the desired area\
    \ of inspection or the desired \nwaypoints. The navigation controller consists\
    \ of four navigation modes: Main \nMission Mode (MMM), where the vehicle navigates\
    \ by following preprogramed \ntracks, Dynamic Position Mode (DPM), where the vehicle\
    \ stays at specific GPS \ncoordinates while maintaining a fixed heading, Tracking\
    \ Mode (TM), where the \nASV follows a target (vessel) until specific conditions\
    \ are met, and finally, \nInspection Mode (IM), where once the target has been\
    \ reached, the vehicle stays \nat a fixed distance and heading from it, in order\
    \ to obtain and classify general \ninformation about it. Depending on the current\
    \ navigation mode, there will be a \nserial of priorities, targets and outputs,\
    \ as seen in Table 4.10: \nTable 4.10. Definition of mission stages. \n \nStage\
    \ 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \nMode (FBM) \nStage\
    \ 3 \nTracking Mode \n(TM) \nStage 4 \nInspection Mode (IM) \nPriority \nAccuracy\
    \ \n(recognition) \nLatency \nLatency \nBoth accuracy \n(recognition) and \nlatency.\
    \ \n \n112 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nTarget \nVessel\
    \ \nrecognition \nand \nclassification \nBounding box \nstudy (size and \npositions)\
    \ for a \ndetermined \nperiod. \nRemain in the \nsame position \nwith fixed \n\
    heading \n \nReach target \nvessel within \ndefined limits \nStay at a fixed distance\
    \ \nfrom target and \nheading it. \nObtain general and \nadditional information\
    \ \nabout target vessel. \nOutput \nIs the target \na risk \nvessel? (YES \n/\
    \ NO) \nIs the target \nvessel in the \nsame position?  \n(YES / NO) \nAlerts.\
    \ \nTarget has been \nreached inside \ndefined limits? \n(YES / NO). \nAlerts.\
    \ Save \ninformation. \nAlerts. Obtain \ninformation of target \nvessel. Video\
    \ \nstreaming. Save \ninformation. \n \nThe navigation mode will change according\
    \ to the scenario and the current \nstage of the general mission, as specified\
    \ in Algorithm 2 and Figure 4.38. The IoT \ngateway connects the navigation controller\
    \ and IP cameras with cloud services. \nDuring the entire mission, the IoT gateway\
    \ receives image data from the IP \ncameras and sensors (through the cRIO controller).\
    \ If a vessel is detected, the \nresults contain its classification (according\
    \ to the trained AI models), a bounding \nbox in the images (centre, relative\
    \ X-Y position, and size) and accuracy \n(percentage). Likewise, the IoT gateway\
    \ receives the image processing results \nfrom the AI recognition source for each\
    \ photo sent. The AI source (edge or cloud \ncomputing) to analyze images is determined\
    \ by the “Smart algorithm for autonomy \noptimization by selecting the proper\
    \ AI technology according to the current scenario” \n(SAAO) described in Section\
    \ 4.4. The AI source uses advanced learning \ntechniques to analyse the results\
    \ and sends them to the IoT gateway. The results \nobtained from the AI source\
    \ are used according to the specific target of each \nmission stage as described\
    \ in Table 10. This process is carried out throughout the \nmission. \nOnce the\
    \ mission starts (MMM), BUSCAMOS-VIGIA ASV follows the \ndefined mission whilst\
    \ analysing images until a vessel is detected. The AI source \nthen classifies\
    \ it according to the trained AI models to determine the risk level. \nThe mission\
    \ mode then moves to the next stage, the Fixed Buoy Mode (FBM).  \nIn FBM, if\
    \ the vessel has been detected with a camera other than the bow \ncamera, the\
    \ vehicle will initially change its heading (stern: +180°, starboard: +90°, \n\
    port: -90°) until the vessel is detected with the bow camera. IoT image processing\
    \ \nis used with the navigation controller to perform heading modifications to\
    \ keep \nthe detected vessel in the centre of the bow camera. Once the heading\
    \ points to \n \n113 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    the target vehicle, BUSCAMOS-VIGIA ASV will remain in that heading, \nregardless\
    \ of the detected vessel’s behaviour. The ASV can act as a fixed buoy or \nstay\
    \ in same position and heading. This mode is used to study the target’s \nbehaviour\
    \ by analysing the bounding box (size and position) of the processed \nimages\
    \ for a specific period to determine whether the target vessel is immobile \n\
    in the same position, which could mean a potential risk as it could be fishing\
    \ or \nanchored in a protected area. \nAt this point, the mission changes to Tracking\
    \ Mode (TM). The ASV starts \nnavigating and tracking the target by using the\
    \ bounding box’s analysed image \ncollection to fix and update the heading. The\
    \ IoT gateway links up with the main \ncontroller to modify the heading according\
    \ to the target’s position in the image, \nkeeping it in the centre of the bow\
    \ camera’s field of vision. It will continue in this \nmode until LiDAR detects\
    \ the target at a specific distance or if it leaves the \nprotected area. If the\
    \ TM is successful and the target is reached, several actions \ncan take place,\
    \ such us saving the vessel’s position or generating remote alerts. \nWhen the\
    \ target is reached, the last stage, Inspection Mode (IM) starts. The \nASV will\
    \ remain at a fixed distance from the target vehicle and heading as long \nas\
    \ possible. The objective of this stage is to obtain information about the target\
    \ \nand generate alerts in the remote base station. \nThis is described in Algorithm\
    \ 2, as well as in the flowchart in Figure 4.40. \n \n \n \nAlgorithm 2. Vessel\
    \ recognition and tracking algorithm. \nStart () \nStep 1:  \n    While (mission\
    \ has not started) {}    \n    {Starts Main Mission Mode (MMM)}      \nStep 2:\
    \ \n    If (mission has ended) \n        {End ()} \n    Else \n        {Navigate\
    \ follow defined mission} \n        {Select the right AI image recognition source\
    \ (AIsource) trough SAAO} \n        {Acquire frames from 4 cameras and send to\
    \ AIsource} \n        {Get the answer of every frame and add label with camera\
    \ position (bow, stern, \nstarboard, port) of detected vessel, called camera position\
    \ (CP)} \n        If ((accuracy of detected vessel > acceptable limits) AND (type\
    \ of vessel == \nclassified as potential \n        risk)) \n            {Go to\
    \ step 3} \n        Else \n            {Go to step 2} \nStep 3: \n{Starts Fixed\
    \ Buoy Mode (FBM)}      \n \n114 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n{Get the answer of every frame and add label with camera position (bow, stern,\
    \ \nstarboard, port) of detected vessel, called camera position (CP)} \n    Switch\
    \ (CP) \n        Case (CP == bow)  \n             If (accuracy < accuracy results\
    \ acceptable)  \n                {Discard detected vessel. No risk.}         \
    \                \n                {Go to step 2} \n            Else \n      \
    \          {Set new heading pointing detected vessel. Keep current position and\
    \ \nheading} \n                {Start study of target behaviour by analysing bounding\
    \ box of images for a \nspecific period} \n                 If (Detected vessel\
    \ is in the same position)  \n                    {Discard detected vessel. No\
    \ risk}                         \n                    {Go to step 2} \n      \
    \          Else \n                    {Target vessel in the same position. Risk\
    \ (anchoring, fishing)}                         \n                    {Go to step\
    \ 4} \n        Case (CP == stern) \n            {Vehicle turns +180º} \n     \
    \       {Go to step 3} \n        Case (CP == starboard) \n            {Vehicle\
    \ turns +90º} \n            {Go to step 3} \n        Case (CP == port) \n    \
    \        {Vehicle turns -90º} \n            {Go to step 3}    \n        Default:\
    \ \n            {Go to step 2}    \nStep 4: \n    {Start Tracking Mode (TM)} \n\
    \    {Navigate to track target vessel}      \n    {Acquire new frame from bow\
    \ camera and send to AIsource}  \n    {Calculate the bounding box center and vessel\
    \ position in order to fix heading \nwhile tracking} \n    If (LiDAR detects vessel\
    \ at 20m) \n        {Stop navigation. Target reached}  \n        {Go to step 5}\
    \ \n    Else If (vessel leaves integral reserve while tracking) \n        {Target\
    \ not reached}  \n        {Go to step 2} \n    Else  \n        {Go to step 4}\
    \ \nStep 5: \n    {Starts Inspection Mode (IM)} \n    {Acquire new frame from\
    \ bow camera and send to AIsource}  \n \n115 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n    {Calculate the bounding box centre and vessel position in order\
    \ to fix heading and \nkeep distance} \n    While (Target vessel is stopped) \n\
    \    {Record videos, save vessel’s position, obtain additional information, send\
    \ \ndata and alerts to cloud station} \n    If (Vessel starts moving) \n     \
    \   {Stage finished. Information collected} \n        {Go to Step 2} \nSecurity\
    \ Step:     \n    If (Energy == 25%) \n        {Return back to port area. Send\
    \ alert to cloud station} \n    If (Energy == 50%)  \n        {Send alert to cloud\
    \ station} \nEnd () \n \n \n \n \nFigure 4.40. Platform’s communications in the\
    \ tracking algorithm. \n2.3. ASV control \nAs shown in Figure 4.38, our marine\
    \ vehicle has a number of elements and \ndevices interconnected through different\
    \ networks. While the IoT gateway is in \ncharge of image recognition and communications\
    \ with the camera and the cloud, \nthe cRIO controller is the ASV’s main control\
    \ backbone. The National Instrument \ncRIO 9022 controller includes a real-time\
    \ processor and reprogrammable FPGA \nthrough its LabVIEW environment [240], as\
    \ well as a chassis that can be \nreconfigured according to the project architecture.\
    \ By default, it comprises two \nEthernet ports, USB port and serial connectivity.\
    \ For this architecture, the chassis \n \n116 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nhas been equipped with several modules that enable CAN-NMEA2000,\
    \ I2C, \nRS232 and RS485 communications. Its specifications are a 533-MHz CPU,\
    \ 256MB \nDRAM, 2GB storage, one Ethernet port and other features listed in [241].\
    \ A \nconsistent code for the cRIO controller was fully developed in the LabVIEW\
    \ \nenvironment for ASV management, control and command. \nThe software modules\
    \ in the cRIO’s vehicle control program comprise these \nmain operations, as shown\
    \ in Figure 4.38: \n \n• Commands management: It allows cRIO dispatch commands\
    \ from cloud \nstation, such as receive and launch main mission after definition\
    \ trough IUNO \nsoftware, stop it, or execute safety manoeuvres \n• Propulsion\
    \ and rudder control: Management of the different control loops for \nboth propulsion\
    \ and rudder, according to the obtained setpoint from Mission \nexecution control\
    \ module. \n• Incidents management: Security module that manages different actions\
    \ \ndepending on the incidents that may occur during the mission, such as loss\
    \ \nof communications or the impossibility of continuing the defined trajectories\
    \ \ndue to external conditions, such as strong winds or rough seas. \n• Mission\
    \ execution control: This module manages navigation to each of the \nprogrammed\
    \ waypoints, according to the running mission, by dispatching \nthe different\
    \ navigation commands for the heading and position control loops \nwith the information\
    \ received from sensors and IoT image analysis algorithm.  \n• Energy efficiency\
    \ manager: The vehicle contains some non-critical navigation \ndevices that can\
    \ be disconnected in the event of energy and autonomy being \ncompromised. This\
    \ module executes the disconnection if required. \n \n3. Smart algorithm for autonomy\
    \ optimization by selecting the \nproper AI technology according to the current\
    \ scenario (SAAO)  \n \nMaritime Autonomous Surface Ships (MASS) have to guarantee\
    \ a series of \nrequirements in order to fulfil their purpose, in particular,\
    \ autonomy and \nsecurity, while accuracy and latency in the image analysis are\
    \ vital in the \nsurveillance of marine reserves through AI-based visual recognition.\
    \  \nAs defined previously, the surveillance mission is divided into four stages\
    \ in \norder to optimize them according to the objectives and a series of priorities\
    \ to \nattend to each stage, as defined in Table 10. Optimizing the mission execution\
    \ \nmeans accomplishing it in the minimum time possible and with the highest \n\
    guarantee of success, or in other words, execute every stage of the mission in\
    \ the \nmost efficient manner possible. An efficient mission means making the\
    \ most of \nthe energy available, a limited and essential resource for autonomous\
    \ vehicles. \nThe restrictive objective is to save energy and guarantee the success\
    \ of the \n \n117 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nmission and\
    \ its security by taking the appropriate decisions in real time, which \nis the\
    \ crucial task of the proposed AI hybrid cloud/edge SAAO algorithm. \nIn stages\
    \ where accuracy is a priority, optimizing mission execution means \nusing AI\
    \ to obtain the best recognition results, detecting vessels that are a \npotential\
    \ risk to the marine reserve with the maximum precision and success. On \nthe\
    \ other hand, once the potential target has been detected and identified, \noptimizing\
    \ the mission in stages in which latency is a priority means obtaining \naccurate\
    \ results as fast as possible as setpoint for the heading controller block.  \n\
    As a single board low-power CPU is used to extend ASV autonomy, SAAO \nis designed\
    \ to be efficient and executed in platforms where energy is a limitation. \nUsing\
    \ both cloud and edge computing technologies to analyze images at the \nsame time\
    \ will entail extra consumption and increased latency in the image \nanalysis,\
    \ especially in edge computing, where CPU resources are limited. Balance \nis\
    \ the key to efficient and successful decision-making. These decisions are related\
    \ \nto selecting the best AI source technology for the success of every stage,\
    \ all of \nwhich have a series of priorities for optimizing the mission execution,\
    \ as shown \nin Table 4.11: \nTable 4.11. AI source preferences according to mission\
    \ stage. \n \nStage 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \n\
    Mode (FBM) \nStage 3 \nTracking \nMode (TM) \nStage 4 \nInspection \nMode (IM)\
    \ \nPriority \nAccuracy \n(recognition) \nLatency \nLatency \nBoth accuracy \n\
    (recognition) \nand latency. \nPreference \nAzure Cloud \nCustom \nModel \nAzure\
    \ Edge \nCustom \nModel \nAzure Edge \nCustom \nModel \nAzure Cloud \nGeneral\
    \ Model \nAlternativ\ne \nAzure Edge \nCustom \nModel \nAzure Cloud \nCustom \n\
    Model \nAzure \nCloud \nCustom \nModel \nAzure Edge \nCustom Model \n \nIn normal\
    \ conditions latency is adequate in edge models and accuracy is \nsuitable in\
    \ cloud models. That is the reason why there is a logic preference in \nevery\
    \ stage according to the defined priority, provided that accuracy is good \nenough.\
    \ Knowing when and what to offload while maintaining real-time \napplication Quality\
    \ of Service (QoS) requirements are the challenges to \novercome. Depending on\
    \ the mission stage, accuracy and latency results, a \ntechnique of offloading\
    \ to edge computing device (IoT gateway) or remote cloud \nservices is performed\
    \ to complete its execution, as shown in Figure 4.41. \n \n118 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nBasically, intelligent offloading can\
    \ be used as an optimization-based \napproach with constraints such as bandwidth,\
    \ network latency, accuracy \nrequirements or monetary cost. In this application,\
    \ latency and accuracy have \nbeen defined as critical throughout the process,\
    \ and that is why the output results \nof the AI source are linked as inputs to\
    \ the SAAO algorithm after analysing the \nimages.  \nThe decision to offload\
    \ or not depends on hardware capabilities, data size, \nthe deep neural network\
    \ (DNN) model to be used and network quality, among \nother factors. These factors\
    \ can be measured indirectly through latency and \naccuracy. Latency and accuracy\
    \ are the main elements to be considered in this \noptimization approach. Figure\
    \ 4.41 shows the SAAO diagram: \n \nFigure 4.41. SAAO diagram. \nThis diagram\
    \ describes how the SAAO works. The latency and accuracy \nobtained from the previous\
    \ analysis are analyzed according to the mission stage \nand the defined AI source\
    \ preference. In the stages where latency is the priority, \nthe accuracy result\
    \ is analyzed to check whether it is within acceptable limits. \nThis means that\
    \ they should at least be able to identify the target and obtain its \nrelative\
    \ coordinates in the analyzed image in order to obtain the bounding box \ncoordinates\
    \ and use them as a setpoint for the heading control loop. There is no \npoint\
    \ in using a fast AI source if the algorithm cannot detect the target in its \n\
    analysis. This is the critical line for accuracy. \nIn stages where accuracy is\
    \ the priority, latency is analyzed in order to select \nthe preferred or alternative\
    \ AI source. The latency results may vary significantly \ndepending on several\
    \ factors, such us the percentage of bandwidth used, \n \n119 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ndistance from ship to base station, or weather conditions,\
    \ among others. With \nlatency not being the priority in these stages, it has\
    \ to be low enough to obtain an \nacceptably fast response, especially in the\
    \ last stage, where the general cloud \nmodel is used to obtain general information\
    \ about the target vessel. Latency is \nalso crucial to keep the target in the\
    \ centre of the vision field. \nLatency average is updated for edge and cloud\
    \ model with each new \nanalysis. This determines acceptable limits for latency\
    \ dynamically, considering \nparameters such as network quality and bandwidth\
    \ indirectly. \n \n \nFigure 4.42. Calculation of acceptable latency limits. Main\
    \ ASV camera point of \nview. \n= \U0001D443\U0001D45B − \U0001D443\U0001D45B\
    −1 \n(4.24) \n\U0001D447 = \U0001D447\U0001D45B − \U0001D447\U0001D45B−1 \n(4.25)\
    \ \n\U0001D445\U0001D446 = \U0001D437\U0001D435\U0001D436\U0001D436\n\U0001D447\
    \  \n(4.26) \n \nFigure 4.42 shows the difference of position between 2 consecutive\
    \ analysed \nimages. From each successfully analysed image, the bounding box of\
    \ the detected \nvessel, its relative coordinates in the image, as well as its\
    \ timestamp are obtained. \nBy knowing the distance between bounding box centres\
    \ (BBC) and the time \ndifference between analyses (T), the relative speed (RS)\
    \ at which the target moves \nin the image can be obtained. During the time lapse\
    \ between the analysis of 2 \nconsecutive images we can approximate the relative\
    \ speed of displacement of the \ntarget vessel and the ASV as a constant value,\
    \ due to the considerable inertia of \nvessels at sea. With this information,\
    \ it is calculated when the target BBC will \nleave the range of vision, and SAAO\
    \ can determine the selection of the preferred \nor alternative source of AI with\
    \ regard to latency. \n \n120 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nSeveral factors affect SAAO decisions, and they can be measured indirectly\
    \ \nthrough latency and accuracy. Low latency and high accuracy are always \n\
    desirable results, but every AI cloud or edge platform has its advantages and\
    \ \nhandicaps, and we cannot always achieve both simultaneously. Balance and \n\
    effective decision making are the keys to make a mission efficient and successful.\
    \ \n \n4. Experiments and Results  \n4.1. AI recognition and proposed algorithm\
    \ for autonomy optimization  \n \nFigure 4.43 shows an example of three different\
    \ cloud vision APIs analyzing \nthe same image, with different types of boats\
    \ in a port. All three cloud services \nmanaged to detect most of the boats in\
    \ the image. The bounding box location is \naccurate, although the cloud response\
    \ cannot exactly specify the type of each \nboat. Our objective is not only to\
    \ detect each boat in the image but also to group \nthem into more specific categories.\
    \ The general model offered by the cloud has \nits limits in this regard. \n \n\
    \ \nFigure 4.43. Comparison of three different clouds vision API detection of\
    \ boat in \nLos Nietos port (Murcia, Spain). \n4.1.1. Custom model training for\
    \ detection specific vessels \nThe advantage of the customized model is the possibility\
    \ of training it \naccording to the use case, in addition to detecting the location\
    \ of objects in the \nimage. Our model has been trained to identify different\
    \ types of vessels and their \nposition in an image. We created our own custom\
    \ object detection model to be \nimplemented in the proposed IoT gateway using\
    \ the Azure cloud service, as it \nsupports the edge computing technologies and\
    \ gives a better performance than \nthe other solutions [242]. More than 600 photos\
    \ of different types of vessels found \naround the inspection area in the experiment\
    \ have been used to train the custom \nmodel. The model has been trained to recognize\
    \ 7 different types of vessels \n(Figure 4.44). The position of each vessel in\
    \ the image was identified by drawing \na bounding box around the object and providing\
    \ the top and left pixel \ncoordinates of the box, along with the width and height\
    \ in pixels. \n \n \n121 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.44. Types and number of vessels used to train the vision custom models.\
    \ \nAzure can retrain our model in different ways, by quick training or advanced\
    \ \ntraining by specifying the training computation time. The more time and pictures\
    \ \nused train the model in the platform, the better the results and performance\
    \ will \nbe.  \nFigure 4.45 shows the detection testing of new photos not used\
    \ in the training \nphase. The cloud trained model was able to differentiate between\
    \ different types \nof boats, as for instance a man fishing in a kayak. The model\
    \ detected the \nsituation perfectly by the training photos. \n \nFigure 4.45.\
    \ Performance of the cloud custom model object detection in discerning \ndifferent\
    \ boats types. \n4.1.2. Cloud and Edge custom models. \nIn the proposed architecture,\
    \ we put forward the LattePanda IoT gateway \nrunning under Windows 10 LTSB OS,\
    \ where the trained edge model has been \ndeployed by using Microsoft Azure. Azure\
    \ offers the possibility of choosing \nbetween different object detection custom\
    \ model domains, namely General, \nLogo, Products on shelves and General Compact.\
    \ The General domain is trained \nto be used only in the cloud (Cloud Custom Model),\
    \ while the General Compact \ndomain is trained to be used in Edge devices (Edge\
    \ Custom Model). The model \nperformance varies by the selected domain; models\
    \ generated by General \nCompact domains can be exported to run locally, so they\
    \ are lightweight models \n \n122 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand optimized for the constraints of real-time object detection on edge devices,\
    \ \nalthough they are less accurate than the General domain. \nFigure 4.46 shows\
    \ the training performance of 600 photos using the 7-hour \ntraining budget. The\
    \ edge and cloud models were trained with the same number \nof photos and training\
    \ budget. The figure 4.46 shows the difference between the \ntwo models after\
    \ the training. \n \nFigure 4.46. Performance differences between the Edge and\
    \ the cloud custom \nmodels. \nAs the models generated by the compact domains\
    \ are optimized for the constraints \nof real-time classification on edge and\
    \ mobile devices, they are slightly less accurate than \na standard domain with\
    \ the same amount of training data. Figure 4.47 clearly shows the \ndifference\
    \ between the custom model for cloud and edge uses, i.e. between the edge-\ntrained\
    \ model and the cloud-trained model. As can be seen, the distance from the object\
    \ \nto the ships' cameras affects the model’s percentage of accuracy. For instance,\
    \ as shown \nin case 3 in the figure 4.47, the cloud model was able to recognize\
    \ the vessel in the \ndistance accurately, while the edge model was not. \n \n\
    123 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.47. Cloud\
    \ and edge custom models for detecting new vessels. \n \n4.2. Latency assessment\
    \ in edge and cloud custom models \nPerforming powerful DNNs (Deep Neural Networks)\
    \ with real-time execution \nrequirements on edge devices is still a challenge,\
    \ regardless of the hardware \nacceleration and compression techniques deployed.\
    \ Considering offloading the \nDNN computation from local devices to more powerful\
    \ entities such as the cloud \nis a common scenario. Today, the cloud offers an\
    \ edge model for deployment on \ntiny devices, however, cloud models are also\
    \ needed to provide satisfactory \nperformance. Another important factor to consider\
    \ is that the cloud is known to \nfacilitate storage, computational complexity\
    \ and the energy load on the edge and \non local devices. Nevertheless, the cloud\
    \ servers are topologically and spatially \ndistant from the local stations, which\
    \ causes significant communication latency. \nReal-time inference is absolutely\
    \ required for many applications. For instance, \nframes from an autonomous vehicle’s\
    \ camera must be processed rapidly to \nidentify and evade obstacles, or a voice-based\
    \ solution must have a rapid analysis \nand understanding of the user's input\
    \ to provide a feedback. However, \ntransferring data to the cloud for inference\
    \ or training may result in more queues \nand delays in transmission from the\
    \ network and cannot meet the stringent \nrequirements of low end-to-end latency\
    \ required for real-time interactive \napplications. For example, experiments\
    \ have revealed that offloading a camera \nframe to Amazon Web Services and performing\
    \ a computer vision task requires \nmore than 200ms of end-to-end data [243].\
    \ \nIn this use case, Azure Custom Vision's used service works in Western \nEurope.\
    \ The experiments were carried out in the IoT gateway mentioned above \nby using\
    \ Python programming language. The results of the latency are \nsummarized in\
    \ Table 4.12, including: average latency, standard deviation, and \nthe minimum\
    \ and maximum values calculated for each model. The time that the \ncloud model\
    \ needs to send the photos to the cloud for processing and get the \n \n124 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nresults back has been measured.\
    \ Given that the trained edge model is migrated \nas a TensorFlow lite program,\
    \ the photos are analyzed at the IoT gateway instead \nof being sent to the cloud.\
    \ The performance of the edge models varies with the \noperating platform; hence\
    \ the inference time may vary. All samples were \ncarefully and thoroughly checked\
    \ for the same data on the same day. The \nexperiment was repeated using the same\
    \ data for both cloud and edge models. \nEach experimental campaign had about\
    \ 300 different valid samples. \n \nTable 4.12. RTD test of 300 samples of the\
    \ Edge and Cloud model. \n \nMin \nlatency (s) \nMax \nlatency (s) \nAverage \
    \ \n(s) \nVariance  \n(s2) \nStandard \ndeviation \n(s) \nCloud \nModel \n0.805\
    \ \n5.298 \n1.412 \n0.872 \n0.934 \nEdge \nModel \n0.213 \n0.896 \n0.336 \n0.012\
    \ \n0.108 \n \nThe results reported in Table 12 show the latency differences between\
    \ edge \nand cloud models on the same machine. The average cloud model score is\
    \ higher \nthan the edge model by more than 1s. However, the variance of the edge\
    \ model \nis almost null compared to the cloud model, which is close to 900ms,\
    \ which \njustifies the edge model’s better stability in time than compared to\
    \ the cloud \nmodel. \nFigure 4.48 compares the experimental latency results of\
    \ both edge and cloud \nmodel. The edge model shows more stability and all values\
    \ do not exceed the 1s \nlatency. Cloud model can sometimes extend beyond 4s.\
    \ According to the cloud \nlatency results, they can be classified into two ranges.\
    \ The first extends for about \n1 and 2 seconds, while the second extends for\
    \ around 4 and 5 seconds. In \naddition, there is a band where no data has been\
    \ registered, between \napproximately 2.5 and 3.5 seconds. \n \n \n \n125 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.48. Latency of more\
    \ than 300 samples. \n \nThe cloud model’s apparent processing time instability\
    \ can be explained by \nthe internet connection volatility as the photos have\
    \ to be sent to the cloud model \non remote servers for processing, unlike the\
    \ edge model in which all photos are \nprocessed on board or at the local station.\
    \  \nThe cloud and edge models are different in terms of accuracy, even though\
    \ \nthey are trained on the same reference images. In contrast to latency, the\
    \ cloud \nmodel is more accurate, which eventually makes it challenging to choose\
    \ \nbetween both models. Real-time and high accuracy are both essential. However,\
    \ \nin an autonomous marine vehicle where computing power is limited and \nenvironmental\
    \ conditions are variable, low latency and high accuracy in every \nanalysis are\
    \ not guaranteed. The aim is to find an acceptable performance \ncompromise, considering\
    \ the evolution of the ongoing mission phases, as \ndescribed in detail in the\
    \ next section. \n4.3. Experimental test and results (SAAO Algorithm) \nIn order\
    \ to test the decision making of the SAAO algorithm, an experiment \nwas carried\
    \ out based on the analysis of a 1.5-hour video filmed in the Bay of \nCartagena.\
    \ The most interesting results were from a 2-minute sequence of a \nfishing boat,\
    \ whose results were analysed as described below. A 10-second \nextract of the\
    \ analysis is shown in this experiment. \nFor the experiment, this video was used\
    \ as the image source for the IoT \nGateway device, replacing the \"Cameras\"\
    \ block shown in Figure 438. The \ncaptures extracted by the IPM (Image processing\
    \ algorithm) were analysed in \nthree different scenarios. First, only an edge\
    \ computing analysis was carried out, \nrecording latency and accuracy results,\
    \ without the intervention of SAAO. The \nexperiment was then repeated with the\
    \ same images analysed using cloud \ncomputing. Finally, the SAAO algorithm was\
    \ tested in making decisions on the \nmost suitable AI source for the analysis\
    \ of the next image, based on the results \nobtained, and for each of the four\
    \ stages, as shown in Table 4.13 and Figure 4.49. \nTable 4.13. Experimental SAAO\
    \ results \nNº \nSampl\ne \nEdge \nCloud \nSAAO answer for next analysis \nLat\
    \ \n(s) \nAcc \n(%) \nLat \n(s) \nAcc \n(%) \nMM\nM \nFBM \nTM \nIM \n1 \n0.447\
    \ \nND \n1.412 \n16.7 \nCCM \nCCM \nCCM \nCGM \n2 \n0.418 \n64.3 \n1.814 \n68.7\
    \ \nCCM \nECM \nECM \nCGM \n3 \n0.324 \n19.5 \n2.816 \n50.5 \nECM \nECM \nECM\
    \ \nCGM \n4 \n0.356 \n47.9 \n1.313 \n65.8 \nCCM \nECM \nECM \nCGM \n5 \n0.403\
    \ \n23.1 \n4.211 \n33.8 \nECM \nECM \nECM \nECM \n6 \n0.392 \n36.8 \n1.284 \n\
    55.7 \nCCM \nECM \nECM \nECM \n \n126 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nND – Not detected \nCCM – Cloud custom model \nECM – Edge custom\
    \ model \nCGM – Cloud General Model \n \n \nFigure 4.49. Images analysed. Cloud/edge\
    \ results comparison \nAs can be seen in Figure 4.49, there is a difference between\
    \ the edge and cloud \nmodels when detecting the same image. Sometimes the difference\
    \ between the \ntwo percentages is not so significant, while in other cases there\
    \ is a notable \ndifference, especially when the boat is at a distance, which\
    \ sometimes \ncomplicates the detection by using the edge model as seen in the\
    \ example of \nPhoto 1, or the latency results were high, in cloud computing mostly.\
    \ These \nvalues condition the SAAO response, with different decision making in\
    \ each \nstage, according to the preferred or alternative AI source. Special attention\
    \ to \nImages 1 and 5, where the low accuracy in the edge model and the high latency\
    \ \nin the cloud model conditioned SAAO's decision for the alternative AI model.\
    \ In \nImage 6, the alternative AI model (according to Table 11) has also been\
    \ selected \nin IM (Stage 4), due to the risk of losing the bounding box’s centre\
    \ of the target \nin the range of vision. \n4.4 Experiment of BUSCAMOS-VIGIA with\
    \ SAAO \nAs mentioned in the Introduction, the complexity of autonomous \nsurveillance\
    \ varies significantly in different scenarios in the Spanish Network of \nMarine\
    \ Reserves. The Cabo de Palos and Islas Hormigas Marine Reserve [244] in \nthe\
    \ Region of Murcia (Figure 4.50) has medium complexity according to the \npreviously\
    \ defined criteria.  \n \n127 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThis reserve covers an area of 18.98 km2 and is a zone with high biodiversity\
    \ \nand prairies of oceanic posidonia and rocky coralligenous beds, as well as\
    \ \nremarkable marine dynamics. This is a natural underwater area that contains\
    \ an \nintegral reserve in the surroundings of Hormiga Island, El Bajo, El Mosquito\
    \ and \nthe islets of El Hormigón and La Losa. \nThis marine reserve is very near\
    \ the Mar Menor, the largest saltwater lagoon \nin Europe, which was selected\
    \ as the scenario for the case study as the water there \nis usually calm, and\
    \ winds are light (Figure 4.50). \n \n \nFigure 4.50. Scale experiment. Equivalence\
    \ of area and distance from integral reserve \n(Islas Hormigas) to base station\
    \ (right) and equivalent area in Mar Menor (left) \n \nThe test exploration mission\
    \ was carried out to survey a marine space with a \nsurface and distance to the\
    \ base station equivalent to the Cabo de Palos and Islas \nHormigas Marine Reserve.\
    \ The objective was to detect, track and identify \nsuspicious vessels within\
    \ the area to validate the proposed architecture and the \nSAAO algorithm. The\
    \ defined inspection area has a radius of 915 m, with a \nsurface area of 2.63\
    \ km2 and a centre at coordinates 37.689634° N and 0.787109° \nW. To avoid detecting\
    \ vessels outside the test area due to the vision field, the area \ncovered by\
    \ the main mission was reduced by a radius of 100m, as shown in \nFigure 4.52.\
    \ The mission was planned on the IUNO platform.  \nThe recognition system was\
    \ tested in port before the mission through the \nmain bow camera to ensure that\
    \ both Azure cloud and edge AI sources worked \nas expected (Figure 4.51). A fishing\
    \ boat, a recreational boat and a sailing boat \nwere detected by the edge model,\
    \ and an extra sailing boat by the cloud model, \nwith better accuracy in all\
    \ detections.  \n \n \n \n128 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nFigure 4.51: Edge (left) / cloud (right) trained model recognition tests.\
    \ \n \nThe ASV was remotely monitored and supervised from the fishing boat used\
    \ \nas the auxiliary vessel for safety reasons during the entire mission. The\
    \ auxiliary \nvessel was also used to verify the detection, recognition and tracking\
    \ capabilities \nimplemented, as explained below. The different systems (control,\
    \ lighting, \nthrusters, \ncommunications, \nvision, \netc \n(control, \nlighting,\
    \ \nthrusters, \ncommunications, vision, etc) were tested before the BUSCASMOS-VIGIA\
    \ \nmission. After successful validation, the mission was transferred from IUNO\
    \ to \nthe ASV and launched and the vehicle headed for the starting point. Surveillance\
    \ \nof the area began following the previously defined route (Figure 4.52). From\
    \ the \nfirst point of the mission to the fifth sweep in the Main Mission Mode\
    \ (MMM) no \nincidents or detections occurred.   \n \n \nFigure 4.52. Start of\
    \ mission (MMM) of surveillance of area equivalent to integral \nreserve. \n \n\
    \ \n129 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe technical team\
    \ on board the fishing boat remained at a specific point in \nthe fifth sweep\
    \ to study the ASV’s behaviour. The fishing boat was detected by \nBUSCAMOS-VIGIA\
    \ (Figure 4.53-a) and classified as a possible risk. According to \nSAAO logs\
    \ during this stage all image analysis was performed by the cloud-\ntrained model\
    \ except for one case in which the edge-trained model was used due \nto high latency.\
    \ The target vessel’s behaviour was studied to determine if it was \nstationary,\
    \ according to the rules defined Stage 2, Fixed Buoy Mode (FBM). The \nregisters\
    \ showed that only the edge model was used. The bounding boxes of all \nthe analyzed\
    \ images were determined as the accuracy was high enough at this \nstage. After\
    \ the FBM stage, when the results determined that the target vessel \nwas stationary,\
    \ the Tracking Mode (TM) stage began. The technical team on \nboard the target\
    \ vessel then started the motors to verify the tracking capabilities \n(Figure\
    \ 4.53-b). \n \n \n \n                         (a)                           \
    \                                                (b) \nFigure 4.53. (a) Stopped\
    \ vessel detected. Start TM mode. (b) Tracking Mode (TM) test \nduring the experiment.\
    \  \n \nThe ASV successfully reached the target. As in FBM, only the edge model\
    \ \nwas used by the SAAO during all the TM. The vehicle stopped over 15m away\
    \ \nand changed to Inspection Mode (IM), the last mission stage. \nThe results\
    \ obtained from the Azure Cloud AI General Model on additional \ninformation about\
    \ the target vessel were as follows: the three people on board \nwere detected.\
    \ The automatically generated sentences “a group of people on a boat” \nand “a\
    \ group of people riding on the back of a boat in the water” by the cloud general\
    \ \nmodel were useful for obtaining details of the target vessel without the need\
    \ to \nview cameras in real time and without human intervention. At this stage,\
    \ the \nrecords show that the SAAO used both the cloud general model and the edge-\n\
    trained model. The cloud results were not fast enough to determine the target\
    \ \nvessel’s bounding box in some cases. Table 4.14 shows a summary of the SAAO\
    \ \nlogs during the experiment: \n \nTable 4.14. Summary of SAAO logs during the\
    \ experiment \n \n130 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    Stage \nEdge (custom model) \nCloud (custom and general \nmodel) \nSAAO answers\
    \  \nAv. \nLat \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetect\n-ions \nAv. \nLat\
    \ \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetections \nUse of the preferred \n\
    AI source (%) \nMMM \n0.22\n0 \n21 \n1 \n1 \n1.52\n1 \n34 \n2414 \n1 \n99.95 \n\
    FBM \n0.20\n5 \n31 \n58 \n58 \n- \n- \n0 \n- \n100.00 \nTM \n0.23\n1 \n39 \n436\
    \ \n436 \n- \n- \n0 \n- \n100.00 \nIM \n0.21\n8 \n57 \n29 \n27 \n1.58\n9 \n68\
    \ \n92 \n88 \n76.03 \n \nWhen the fishing boat left the area, BUSCAMOS-VIGIA ended\
    \ the IM stage \nand continued with the planned mission (in MMM) until the eighth\
    \ sweep was \ncompleted. The vessel was then commanded to return to port and no\
    \ further \nincidents were registered during the rest of the mission. \n \n \n\
    \ \nIV. An IoT Control System for Wind Power Generators \n \n1. Introduction \
    \  \n \nAs an important source of energy in different countries, renewable energy\
    \ is \nwidely used today, renewable electricity generation in 2018 was 6.1% higher\
    \ than \nin 2017, representing about 16% of global power generation, as reported\
    \ in \nIRENA (2017) [245]. This percentage is expected to double in the next 15\
    \ years \nand 65% of energy use could come from renewable resources by 2050. Wind\
    \ and \nsolar energy production in 2018 increased by 11% and 28%, respectively.\
    \ \nAltogether, these two sources of energy remain dominant in the growth of \n\
    renewable generation, accounting for 73% of growth since 2014 [245]. \nPresent\
    \ machines used for manufacturing already support digital or analog \nsensing\
    \ connected to a central control station to be monitored via a wired \nEthernet\
    \ system [246]. These systems, nevertheless, are not usually connected to \nthe\
    \ Internet [247]. This is the era that meets the important evolution of the \n\
    industry and the Internet. In order to be able to follow this important evolution\
    \ \nof wind energy, it is necessary to enforce the capacity of the Internet to\
    \ assess all \n \n131 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    data collected from the different industrial elements, sensors, actuators, motors,\
    \ \netc. \nA \nvariety \nof \nadvanced \ntechnologies \nsuch \nas \nintelligent\
    \ \nrobots, \ncommunication systems (e.g., 5G), and the Internet of Things (IoT)\
    \ are expected \nto enhance the fourth industrial revolution [248]. IoT connects\
    \ a number of \npeople, devices, processes, and data, enabling them to communicate\
    \ with each \nother seamlessly. IoT can therefore help improve different processes\
    \ to make \nthem more measurable and quantifiable by gathering and processing\
    \ large \namounts of data [249]. IoT can potentially improve the quality of life\
    \ in different \nareas. In the energy sector, IoT can be deployed to increase\
    \ energy efficiency, \nexpand the share of renewable energy, limit the environmental\
    \ impacts of energy \nuse [250], and to have a clear vision of the entire system,\
    \ in real-time, without the \nnecessity of physically being in the area of the\
    \ installation. This will consequently \nreduce waiting times and decrease unnecessary\
    \ costs.  \nThe idea of the IoT is to treat each object as a thing, the renewable\
    \ energy \nresource is considered an object and is assigned a unique IP address,\
    \ where all \ndata gathered by sensors and actuators can be measured, analyzed\
    \ and managed, \nthrough the cloud-based platforms. The communication protocols\
    \ of the IoT \nplatform allow the different devices to communicate and share their\
    \ data with \nthe controllers or decision centers. The IoT platforms offer the\
    \ flexibility to select \nthe type of communication technologies according to\
    \ the needs of the \napplication. Each of these communication technologies has\
    \ specific features and \ncan be carried out through wired and wireless networks,\
    \ including, but not \nlimited to, RS485, Wi-Fi, Bluetooth, ZigBee [251] and cellular\
    \ technology such as \nLTE-4G and 5G networks [252]. The IoT is considered one\
    \ of the complex \nsystems, and this complexity is due to the interactions in\
    \ the environment, an \ninterconnection of the IoT components and the number of\
    \ networks and \nprotocols that are involved. The IoT gateway is the component\
    \ that allows these \ndifferent networks to communicate [253]. \nThe data analysis\
    \ is performed for decision making about the functioning of \nthe application.\
    \ As needed, data analysis can be accomplished offline or in real \ntime. When\
    \ analyzing off-line, the stored data is first collected and then \nvisualized\
    \ on site using visualization tools installed in the IoT gateway or in a \nbase\
    \ station). However, In the case of real-time analysis, cloud or edge servers\
    \ \nare used to perform the visualization, e.g. stream analysis [254].  \nThe\
    \ rest of this chapter is organized as follows. We present a study of related\
    \ \nwork in the field of IoT solutions in the renewable energy sector. We then\
    \ \nintroduce the system model and the different protocols and applications used\
    \ to \nconnect the wind energy control system to the cloud. Following, we describe\
    \ the \nproposed hardware and software used to connect the system to the cloud.\
    \   \nFinally, the possibilities that can be done using the data transmitted offline\
    \ at the \nIoT gateway and in real time in the cloud. \n \n \n132 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2. Modelling System Architecture \n \n\
    Within a wind energy system, a wind turbine converts wind energy into \nelectrical\
    \ energy. First it consists of a rotor, that transforms the aerodynamic \nthrust\
    \ into rotation movement, second a Multiplier, that adapts the rotation \nspeed\
    \ to the speed of the generator, then also an Alternator, that transforms the\
    \ \nrotation energy into electrical energy, and finally a Dump to the grid, that\
    \ injects \nenergy into the electrical network. \nThe wind energy system consists\
    \ of sensors, motors and actuators to be \nmonitored and controlled continuously.\
    \ The system must guarantee a safe and \nreliable operation, monitor the components\
    \ and variables, verify that the \nvariables are in an allowable range and must\
    \ perform fault detection and \nprediction. In a wind turbine, a yaw-guiding motor\
    \ turns the nacelle to face the \nwind, and the movement of the motor depends\
    \ on data from wind direction \nsensors. In fact, predictive analysis will alert\
    \ operators in advance if a component \nneeds to be repaired or inspected.  \n\
    New technologies such as IoT, machine learning, cloud, large data can \nfacilitate\
    \ better use of resources and help harness clean energy along with \noptimization.\
    \ IoT has an important impact on the energy sector, especially wind \nenergy,\
    \ given that this technology is applied to inaccessible environments and \nremote\
    \ areas. \nThe general architecture of an IoT system is composed mainly of three\
    \ parts, \nthe first one is the data generation and control system where it is\
    \ connected to \nthe devices and sensors, secondly it is the IoT gateway where\
    \ the main programs \nand protocols are installed to communicate the received\
    \ data, and finally, the \ncloud service, which reports all the data coming from\
    \ the wind energy system \nthrough the IoT gateway.  \n \n \n133 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.54 : Wind energy IoT communication\
    \ architecture \n \nIn this proposal we present two of the most important sensors\
    \ used in a wind \nenergy system, which are the wind energy direction sensor (Anemometer)\
    \ and \nthe wind speed sensor (Vane). Also proposed in this architecture, the\
    \ Siemens \ntechnology, using two types of PLCs: the PLC 1214 and the PLC 1512\
    \ and an \nindustrial gateway IoT2040 which is the first in the Siemens market\
    \ and can \nexecute different tasks, as handling the data received from the PLCs\
    \ before \nsending it to the cloud or to other machines and systems.  \n \n \n\
    Figure 4.55. Hardware Setup \n \n \n134 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe connected sensors are directly connected to the Siemens PLC 1214\
    \ to \nmonitor the wind status and send a command to the engine generator to change\
    \ \nthe direction of the blades in order to maximize the use of the system. \n\
    Furthermore, it permits the operation to be shut down in the event of a strong\
    \ \nwind flow. In parallel, power quality can be monitored and displayed using\
    \ the \nSENTRON PAC (3200), which delivers the important data for evaluating the\
    \ \nquality of an electrical network. All information received in the sensors\
    \ PLC 1214 \nis transmitted to the PLC 1512 using the industrial communication\
    \ standard \nPROFINET via Ethernet. \nThis solution allows to connect a legacy\
    \ network, presented by the old PLC \n1214 by using another powerful PLC 1512\
    \ with more capabilities to connect to \nanother network, which speaks more communication\
    \ protocols. The OPC \nUnified Architecture (UA) is an independent service-oriented\
    \ architecture that \nintegrates all the functionality of the individual OPC Classic\
    \ specifications into \nan extensible framework [255]. OPC UA is also a machine-to-machine\
    \ \ncommunication protocol, developed to create a reliable, secure, and interoperable\
    \ \ncommunication protocol. OPC-UA uses a client-server architecture, the servers\
    \ \nare applications that present information following the OPC-UA information\
    \ \nmodel, and the clients are applications that retrieve information from the\
    \ servers \nby reading and browsing the information model. In each server is defined\
    \ an \naddress space containing nodes of the OPC-UA model, these nodes represent\
    \ \nphysical objects or software [256]. the Siemens PLC 1512 comes with an OPC\
    \ UA \nserver implemented, which permits the communication with OPC UA clients\
    \ \nsuch as HMI panels, SCADA systems, etc. The OPC UA client is implemented in\
    \ \nthis application in the Siemens IOT2040 gateway, through the application Node-\n\
    RED that has a sample set of nodes that can be used for the communication \nbetween\
    \ different protocols and platforms. It is a programming tool for wiring \ntogether\
    \ hardware devices, APIs and online services, it is a solution to control \nflows\
    \ to be designed and managed graphically [257]. Figure 4.56 shows the setup \n\
    application and the different components from the wind sensors to the cloud \n\
    platform. \n \n \nFigure 4.56. Data flow between different systems and across\
    \ different protocols. \n \n \n \n135 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe OPC UA client implemented in the UAExpert software can \ncommunicates\
    \ with the OPC UA server in the Siemens PLC, its role is to check \nand read all\
    \ the information related to the communication with the PLC, so as to \nshow the\
    \ information model of the UA server, such as labels, blocks, etc (Figure \n4.57).\
    \ This application needs to control the two variables of the speed sensor and\
    \ \nthe orientation sensor. UaExpert can read the NodeID of each variable, which\
    \ is \nthe most important ID used in Node-RED in order to be connected to the\
    \ PLC \nOPC UA server. \n \n \nFigure 4.57 . Checking OPC UA connection using\
    \ UaExpert Software \n \nWe implemented mainly four different nodes for each sensor,\
    \ in order to read \nthe data information from the PLC 1512 and then forward it\
    \ to the cloud for \nvisualization (Figure 4.58). In the first blue node (Inject\
    \ Node) we have \nintroduced the topic, used to connect with the variable Orientation\
    \ in the PLC, \nthis topic is also called Node-ID that can be taken from the software\
    \ UaExpert. \nWe then connected the Inject Node to the OPC UA Client Node that\
    \ has the \naddress of the PLC server to which we want to connect, and finally\
    \ we linked the \nIBM Watson IoT Node that has all the information about our variables\
    \ created in \nour IBM Bluemix cloud account. \n \n \n136 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nFigure 4.58. Communication between the PLC 1512 and\
    \ IBM Cloud \nthrough OPC UA protocol using Node-RED installed the industrial\
    \ \nGateway IOT2040. \n \nC. Discussion and Results \n \n \nFigure 4.59. Dashboard\
    \ Data of wind Sensors in the IoT2040 Gateway \n \nAfter having all the information\
    \ about our sensors in the IoT2040 gateway \n(Figure 4.59), we have created an\
    \ account in IBM Bluemix, then we created a \ndevice in this account, which is\
    \ the IoT2040 gateway in order to connect it to the \nIBM Watson node in Node-RED.\
    \ IBM allows to create different boards, and for \neach board it is possible to\
    \ create cards that present your data and each data is a \nrepresentation for\
    \ your devices, sensors, actuators, or other. In the IBM Watson \nIoT Platform,\
    \ we created the board Wind-Energy, in order to present in a real-\ntime the two\
    \ wind sensors (Figure 4.60). \n \n \n137 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.60 : Dashboard data wind sensors in the IBM Watson Platform\
    \ \n \n \n \n \n138 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 5 \n \n-------------------------------------------------- \n \nConclusions and\
    \ Future Work \n \n \n \nThe lack of interoperability between Internet of Things\
    \ (IoT) devices \nsignificantly increases the complexity and cost of implementing\
    \ IoT and \nintegrating it into existing industrial systems and autonomous robots.\
    \ The quest \nfor seamless interoperability is further complicated by the long\
    \ lifespan of typical \nindustrial equipment, which requires costly upgrades or\
    \ replacements to support \nthe latest technologies. Integrating new and old technologies\
    \ into the IoT \npresents an interoperability challenge, as each IoT system has\
    \ its own \ncommunication protocol. In addition, a small error or delay beyond\
    \ the tolerated \nlimit could result in a disaster for various applications. IoT\
    \ gateways provide an \neffective solution for data communication, security and\
    \ manageability, and serve \nas a bridge between sensor networks and cloud services.\
    \ While the \nenvironmental specifications of each IoT gateway are crucial when\
    \ it comes to \napplications that require efficient computing performance. Cloud\
    \ services can \nhandle many cases efficiently, although latency is a major challenge\
    \ due to the \ninteraction between different systems. Unmanned vehicles (UVs)\
    \ now have great \npotential for many applications. At every stage of many surveillance\
    \ and tracking \nmissions using UVs, priority must be given to either accuracy\
    \ or latency. \nHowever, in some scenarios, stability of measurements and results\
    \ is difficult to \nensure, and certainty is far from guaranteed. Edge computing\
    \ topology reduces \nlatency to support IoT performance in low-bandwidth environments\
    \ and \nmitigates overall network congestion. Cloud computing topology improves\
    \ \naccuracy at the expense of increased latency. This proved crucial in deciding\
    \ the \nbest source of artificial intelligence to use to achieve the specified\
    \ goals at each \nstage in real time. \nAzure Custom Vision, Google cloud, and\
    \ IBM Watson services allow users \nto load a set of images and train them into\
    \ a custom AI model. However, to date, \n \n139 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \njust some of the cloud services allow trained AI models\
    \ to be exported in different \nformats (TensorFlow, Docker) specifically tailored\
    \ for devices, as opposed to the \ncloud. The model trained for use in the cloud\
    \ is different from the one trained for \nthe edge in terms of accuracy and response\
    \ time.  \nThe main contributions of this thesis are summarized in this chapter,\
    \ and the \neminent obtained results are discussed. Then, we emphasize the most\
    \ research \nlines that this thesis opens and can be considered as the future\
    \ works of the work \ndescribed in this report.  \n \n1. Contributions’ summary\
    \ \n \nThe main contributions of this thesis and the eminent results obtained\
    \ are \nsummarized. We highlight the most important research directions that this\
    \ thesis \nopens and that can be considered as future work of the work described\
    \ in this \nreport.  \nIn this thesis, different contributions are proposed to\
    \ address the issues of \nsupervision, interoperability, latency and detection\
    \ accuracy for object tracking.  \nThese contributions can be grouped into four\
    \ main axes. The first one, an \ninteroperable architecture and reliable real-time\
    \ communication have been \nproposed to improve the production process of a concrete\
    \ plant. In the second, \nan AUV model system designed to track a Mediterranean\
    \ fan mussel species, \nusing cloud services with edge computing as alternative\
    \ processing units. In the \nthird line, we propose an intelligent algorithm to\
    \ optimize the autonomy of an \nautonomous marine robot by selecting the appropriate\
    \ AI technology for \nprotection and continuous monitoring in marine protected\
    \ areas. Finally, In the \nfourth, the line focuses on proposing an IoT solution\
    \ to supervise in real time a \nwind system in the cloud. \nIn the first part\
    \ of this thesis, we have introduced a model designed to \nmonitor the smart industrial\
    \ Internet of things based on an unmanned aerial \nvehicle, leveraging cloud computing\
    \ services and using fog computing as a \nbridge between the different IIoT layers.\
    \  \n \n• The proposed model can monitor the condition of a concrete plant \n\
    production line and the condition of the materials transported on \nconveyor belts\
    \ to control the process.  \n• The results reveal the effectiveness of integrating\
    \ drones with deep \nlearning cloud services for processing and analyzing photos\
    \ acquired in \nreal-time.  \n• We demonstrate how to overcome the challenge of\
    \ interoperability using \nfog and Node-RED computation on the IoT gateway.  \n\
    • Node-RED interacts simultaneously with the different systems involved \nthrough\
    \ different protocols. \n \n140 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n• The period of time available to the control system to decide and adjust\
    \ the \nformula is assessed and estimated, depending on the quantity ordered by\
    \ \nthe customer and the composition of the formula. Given these points, the \n\
    overall latency of the proposed solution is acceptable for plant control \ndecisions.\
    \ \n• The Siemens IoT gateway S-G is expected to provide better performance \n\
    in an industrial setting, although it has less capacity than Raspberry \ngateway\
    \ RPI-G.  \n• The second work outlines an AUV model system designed to track a\
    \ \nMediterranean fan mussel species, using cloud services with edge \ncomputing\
    \ as alternative processing units. \n• An innovative algorithm was proposed to\
    \ autonomously track the target \nspecies without human intervention by integrating\
    \ the object detection \nsystem into the AUV control loop. \n• The proposed model\
    \ is capable of detecting, tracking and georeferencing \nspecimens with IUNO software.\
    \ \n• The obtained results highlight the system’s effectiveness and feature the\
    \ \nasset of combining an AUV with deep learning cloud services for \nprocessing\
    \ and analyzing photos.  \n• Although cloud-based architecture automatically distributes\
    \ and balances \nprocessing loads, we overcame latency challenges in the tracking\
    \ process \nby using edge computing in the IoT gateway.  \n• The IoT gateway installed\
    \ in the AUV replaces the cloud processing unit \nby virtue of the interaction\
    \ between the different AUV components. We \nintegrated cloud-based ML services\
    \ into the AUV system to achieve a \ncompletely autonomous pre-programmed search\
    \ mission with relevant \naccuracy.  \n• Furthermore, with the aim of ensuring\
    \ that data is transferred, processed \nand returned at speeds that meet the needs\
    \ of the application, the two \nobject detection services were implemented in\
    \ the cloud and compared in \nterms of latency and accuracy.  \n• The obtained\
    \ experimental results clearly justify the proposed hybrid \ncloud/edge architecture\
    \ and highlight the combination of the system \nperformances that ensure a real-time\
    \ control loop for relevant latency and \naccuracy. \n• Addressing system requirements,\
    \ lower latency and improved cloud \naccuracy, our solution on AUV servo control\
    \ ensures a balance between \nperformance and stability. The hybrid cloud/edge\
    \ architecture is therefore \nrecommended to ensure a real-time control loop and\
    \ achieve consistent \nresults.  \n \n \n141 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nIn the third part, we have presented an autonomous marine robot for\
    \ \ncontinuous protection and surveillance of marine protected areas based on\
    \ AI \nrecognition.  \n \n• The robot was designed to survey and inspect marine\
    \ reserves using AI-\nbased image recognition services, looking for vessels conducting\
    \ \nsuspicious activities. \n• Azure cloud computing and Azure edge computing\
    \ services were used \nfor image analysis, each with their own advantages and\
    \ disadvantages, \nmainly related to accuracy and latency.  \n• To meet the system\
    \ requirements, we proposed and developed an \nintelligent algorithm to optimize\
    \ the autonomy by selecting the \nappropriate AI technology for the monitored\
    \ scenario.  \n• The proposed intelligent algorithm (SAAO) provides a trade-off\
    \ between \nlatency and accuracy. \n \nIn the fourth part of this thesis, we have\
    \ performed a control system using a \nsmart IoT gateway to create a connection\
    \ between an industrial case and the \ncloud.  \n \n• We have provided a solution\
    \ for a wind energy system in order to \nvisualize in a real-time and remotely\
    \ the different components and devices \ninside a wind turbine control system.\
    \  \n• We proposed, the IOT2040 gateway from Siemens, and we have installed, \n\
    several tools that helped us connect our device’s information.  \n• It is simple\
    \ to connect each sensor information of the wind turbine to the \ncloud by using\
    \ the tool Node-RED, and through different communication \nprotocols like OPC\
    \ UA. This solution can really ease the control system of \nwind energy, by collecting,\
    \ saving and communicating relevant data in \nreal-time.  \n• With the help of\
    \ an IoT gateway, analyzed data can be transferred from \nthe cloud to the control\
    \ system and to the devices. \n \n2. Future Works  \n \nThe research conducted\
    \ in this thesis can be extended in future work. Below \nwe present most of the\
    \ possible future contributions: \n \n• Introducing new devices into drones, so\
    \ that they can not only track \nobjects but also interact with them. \n• Introducing\
    \ swarm of drones connected as IOT-drone device and \ncoordinated to perform swarm\
    \ operations. \n \n142 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    • New technologies can be implemented in drones to track and catch \ndetected\
    \ objects. \n• More research is needed in terms of accuracy when tracking a moving\
    \ \nobject. \n \n \n \n \n143 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nReferences \n \n \n \n1- \nG. Miragliotta, A. Perego, and A. Tumino, “Internet\
    \ of Things: Smart Present or Smart Future?” \nItaly, 2012.  \n2- \nStatista.\
    \ IoT: Number of Connected Devices Worldwide 2012–2025; Statista: Hamburg, Germany,\
    \ \n2019. \n3- \nH. Kagermann, W. Wahlster, and J. Helbig, “Recommendations for\
    \ implementing the strategic \ninitiative INDUSTRIE 4.0,” 2013. \n4- \n25. A.\
    \ Azevedo and A. Almeida, “Factory Templates for Digital Factories Framework,”\
    \ Robot. \nComput. Integr. Manuf., vol. 27, no. 4, pp. 755–771, Aug. 2011. \n\
    5- \n46. \nT. Hafeez, L. Xu and G. Mcardle, \"Edge Intelligence for Data Handling\
    \ and Predictive \nMaintenance \nin \nIIOT,\" \nin \nIEEE \nAccess, \nvol. \n\
    9, \npp. \n49355-49371, \n2021, \ndoi: \n10.1109/ACCESS.2021.3069137. \n6- \n\
    Molina-Molina, J.C.; Salhaoui, M.; Guerrero-González, A.; Arioua, M. Autonomous\
    \ Marine Robot \nBased on AI Recognition for Permanent Surveillance in Marine\
    \ Protected Areas. Sensors 2021, 21, \n2664. https://doi.org/10.3390/s21082664\
    \ \n7- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence:\
    \ Paving the Last Mile of \nArtificial Intelligence with Edge Computing. Proc.\
    \ IEEE 2019, 107.  \n8- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis,\
    \ M. A Comparative Taxonomy and Survey \nof Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2. \n9- \nY. Zhong, Xun Xu, Eberhard Klotz, Stephen\
    \ T. Newman. Intelligent Manufacturing in the Context \nof Industry 4.0: A Review.\
    \ Elservier, https://doi.org/10.1016/J.ENG.2017.05.015 \n10- \nK. \nKritayakirana\
    \ \nand \nJ. \nC. \nGerdes, “Autonomous \nvehicle \ncontrol \natthe \nlimits \n\
    of \nhandling,”International Journal of Vehicle AutonomousSystems, vol. 10, no.\
    \ 4, pp. 271–296, 2012. \n11- \nS. E.Collier, “The emerging enernet: Convergence\
    \ of the smart grid with the internet of things”, \nIEEE Industry Applications\
    \ Magazine, 23(2), 12-16, 2016. \n12- \nCarvalho O., Garcia M., Roloff E., Carreño\
    \ E.D., Navaux P.O.A. (2018) IoT Workload Distribution \nImpact Between Edge and\
    \ Cloud Computing in a Smart Grid Application. In: Mocskos E., \nNesmachnow S.\
    \ (eds) High Performance Computing. CARLA 2017. Communications in Computer \n\
    and Information Science, vol 796. Springer, Cham. https://doi.org/10.1007/978-3-319-73353-1_14\
    \ \n13- \nS. Marstijepovic and S. Williams, \"Environmental monitoring and field\
    \ surveillance reference \nguide.pdf\". \n14- \nXu, G.; Shi, Y.; Sun, X.; Shen,\
    \ W. Internet of Things in Marine Environment Monitoring: A Review. \nSensors\
    \ 2019, 19, 1711. https://doi.org/10.3390/s19071711 \n15- \nC. Perera, A. Zaslavsky,\
    \ P. Christen, & D. Georgakopoulos, “Sensing as a service model for smart \ncities\
    \ supported by internet of things”, Transactions on Emerging Telecommunications\
    \ \nTechnologies, 25(1), 81-93, 2014. \n16- \nAkhtar, M.N.; Shaikh, A.J.; Khan,\
    \ A.; Awais, H.; Bakar, E.A.; Othman, A.R. Smart Sensing with Edge \nComputing\
    \ in Precision Agriculture for Soil Assessment and Heavy Metal Monitoring: A Review.\
    \ \nAgriculture 2021, 11, 475. https://doi.org/10.3390/agriculture11060475 \n\
    17- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things for\
    \ smart home: Challenges and \nsolutions”, Journal of Cleaner Production, 140,\
    \ 1454-1464, 2017. \n18- \nR. Sfar, E. Natalizio, Y. Challal, &Z. Chtourou, “A\
    \ roadmap for security challenges in the Internet of \nThings”, Digital Communications\
    \ and Networks, 118-137, 2018. \n19- \nM. Soliman, T. Abiodun, T. Hamouda, J.\
    \ Zhou, & C. H. Lung, “Smart home: Integrating internet of \nthings with web services\
    \ and cloud computing”, In Cloud Computing Technology and Science \n(CloudCom),\
    \ 2013 IEEE 5th International Conference on (Vol. 2, pp. 317-320). 2013. \n \n\
    144 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n20- \nD. Miorandi,\
    \ S. Sicari, F. De Pellegrini, & I. Chlamtac, “Internet of things: Vision, applications\
    \ and \nresearch challenges”, Ad Hoc Networks, 10(7), 1497-1516, 2012. \n21- \n\
    F. Firouzi, A. M. Rahmani, K. Mankodiya, M. Badaroglu, G. V. Merrett, P. Wong,\
    \ & B. Farahani, \n“Internet-of-Things and big data for smarter healthcare: from\
    \ device to architecture, applications \nand analytics”, 2018. \n22- \nS. K.Dash,\
    \ J. P. Sahoo, S. Mohapatra, & S. P. Patil,“Sensor-cloud: assimilation of wireless\
    \ sensor \nnetwork and the cloud”, Advances in Computer Science and Information\
    \ Technology. Networks \nand Communications, 455-464, 2012. \n23- \nL. Atzori,\
    \ A. Iera, and G. Morabito, “The Internet of Things: A survey,” Comput. Netw.,\
    \ vol. 54, no. \n15, pp. 2787–2805, Oct. 2010. \n24- \nM. Kavre, A. Gadekar and\
    \ Y. Gadhade, \"Internet of Things (IoT): A Survey,\" 2019 IEEE Pune Section \n\
    International Conference (PuneCon), 2019, pp. 1-6, doi: 10.1109/PuneCon46936.2019.9105831.\
    \ \n25- \nEdge Computing Task Group.Introduction to Edge Computing in IIoT.Accessed:\
    \ Aug. 2, 2021. \n[Online]. \nAvailable: \nhttps://www.iiconsortium.org/pdf/Introduction_to_Edge_Computing_in_IIoT%_2018-06-18.pdf\
    \ \n26- \nLi, L. Lyu, X. Liu, X. Zhang, and X. Lyu, ‘‘FLEAM: A federated learn-ing\
    \ empowered architecture to \nmitigate \nDDoS \nin \nindustrial \nIoT,’’ \n2020,\
    \ \narXiv:2012.06150. \n[Online]. \nAvailable: \nhttp://arxiv.org/abs/2012.06150\
    \ \n27- \nDong, G. Qin, and H. Tian, ‘‘Enhancing data monitoring scheme based\
    \ on reinforcement learning \nin IIoT systems,’’ inProc. 12th Int. Conf.Commun.\
    \ Softw. Netw. (ICCSN), Jun. 2020, pp. 69–72. \n28- \nF. Wang, M. Zhang, X. Wang,\
    \ X. Ma, and J. Liu, ‘‘Deep learning for edgecomputing applications: A \nstate-of-the-art\
    \ survey,’’IEEE Access, vol. 8, pp. 58322–58336, 2020 \n29- \nChen, J. Wan, Y.\
    \ Lan, M. Imran, D. Li, and N. Guizani, ‘‘Improvingcognitive ability of edge intelligent\
    \ \nIIoT through machine learning,’’IEEE Netw., vol. 33, no. 5, pp. 61–67, Sep.\
    \ 2019. \n30- \nI. Yaqoob, E. Ahmed, I. A. T. Hashem, A. I. A. Ahmed, A. Gani,\
    \ M. Imran & M. Guizani, “Internet of \nthings architecture: Recent advances,\
    \ taxonomy, requirements, and open challenges”, IEEE \nwireless communications,\
    \ 24(3), 10-16, 2017. \n31- \nM. Diaz, C. Martín, & B. Rubio, “State-of-the-art,\
    \ challenges, and open issues in the integration of \nInternet of things and cloud\
    \ computing”, Journal of Network and Computer Applications, 67, 99-\n117, 2016.\
    \ \n32- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things\
    \ for smart home: Challenges and \nsolutions”, Journal of Cleaner Production,\
    \ 140, 1454-1464, 2017. \n33- \nLa, Quang Duy. Ngo, Mao V. Dinh, Thinh Quang.\
    \ Quek, Tony Q.S. Shin, Hyundong. Enabling \nintelligence in fog computing to\
    \ achieve energy and latency reduction. Digital Communications \nand Networks.\
    \ https://doi.org/10.1016/j.dcan.2018.10.008 \n34- \nDong, G. Qin, and H. Tian,\
    \ ‘‘Enhancing data monitoring scheme based on reinforcement learning \nin IIoT\
    \ systems,’’ in Proc. 12th Int. Conf.Commun. Softw. Netw. (ICCSN), Jun. 2020,\
    \ pp. 69–72. \n35- \nD. Xu and L. Duan, ‘‘Big data for cyber physical systems\
    \ in indus-try 4.0: A survey,’’Enterprise Inf. \nSyst., vol. 13, no. 2, pp. 148–169,\
    \ Feb. 2019. \n36- \nS. E.Collier, “The emerging enernet: Convergence of the smart\
    \ grid with the internet of things”, \nIEEE Industry Applications Magazine, 23(2),\
    \ 12-16, 2016. \n37- \nA. C. Panchal, V. M. Khadse and P. N. Mahalle, \"Security\
    \ Issues in IIoT: A Comprehensive Survey of \nAttacks on IIoT and Its Countermeasures,\"\
    \ 2018 IEEE Global Conference on Wireless Computing \nand Networking (GCWCN),\
    \ 2018, pp. 124-130, doi: 10.1109/GCWCN.2018.8668630. \n38- \nE. Sisinni, A. Saifullah,\
    \ S. Han, U. Jennehag, and M. Gidlund,“Industrial Internet of Things: \nChallenges,\
    \ opportunities, and direc-tions,”IEEE Trans. Ind. Informat., vol. 14, no. 11,\
    \ pp. 4724–\n4734,Nov. 2018. \n39- \nN. L. Tsilias, “Open Innovation and Interoperability,”\
    \ inOpening standards: The global politics of \ninteroperability,L. DeNardis,\
    \ Ed. Cambridge, MA, USA: MIT Press, 2011,pp. 97–117. \n40- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109. \n41- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of\
    \ combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6. \n42- \nG. Hatzivasilis, I. G.\
    \ Askoxylakis, G. Alexandris, D. Anicic,A. Br ̈oring, V. Kulkarni, K. Fysarakis,\
    \ and G. \nSpanoudakis,“The Interoperability of Things: Interoperable solutions\
    \ as an enabler for IoT and \nWeb 3.0,” in23rd IEEE International Workshop on\
    \ Computer Aided Modeling and Design of \nCommunication Links and Networks, CAMAD\
    \ 2018, Barcelona, Spain, September 2018, pp. 1–7. \n \n145 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n43- \nMonostori, L.; Kádár, B.; Bauernhansl, T.; Kondoh,\
    \ S.; Kumara, S.; Reinhart, G.; Sauer, O.; Schuh, G.; \nSihn, W.; Ueda, K. Cyber-physical\
    \ systems in manufacturing. CIRP Ann. 2016, 65, 621–641. \n44- \nX. Zuo, Y. Cui,\
    \ M. Wang, T. Xiao, and X. Wang, “Low-latencynetworking: Architecture, techniques,\
    \ \nand opportunities,”IEEE InternetComput., vol. 22, no. 5, pp. 56–63, 2018.\
    \ \n45- \nM. Bennis, M. Debbah, and H. V. Poor, “Ultrareliable and Low-latencyWireless\
    \ Communication: \nTail, risk, and scale,”Proceedings of theIEEE, vol. 106, no.\
    \ 10, pp. 1834–1853, 2018 \n46- \nKang, J. Hauswald, C. Gaoet al., “Neurosurgeon:\
    \ CollaborativeIntelligence Between the Cloud and \nMobile Edge,” inProc. 22nd\
    \ Int.Conf. Archit. Support Program. Lang. Oper. Syst. (ASPLOS \n2017),2017, pp.\
    \ 615–629. \n47- \nXiaofei Wang, Senior Member, IEEE, Yiwen Han, Student Member,\
    \ IEEE, Victor C.M. Leung, Fellow, \nIEEE, Dusit Niyato,Fellow, IEEE, Xueqiang\
    \ Yan, Xu Chen, Member, IEEE. Convergence of Edge \nComputing and Deep Learning:\
    \ A Comprehensive Survey. arXiv:1907.08349v3 [cs.NI]  28 Jan 2020 \n48- \nZ. Li,\
    \ J. Kang, R. Yu, D. Ye, Q. Deng, and Y. Zhang, “ConsortiumBlockchain for Secure\
    \ Energy trading \nin Industrial Internet of Things,”IEEE Trans. Ind. Informat.,\
    \ vol. 14, no. 8, pp. 3690–3700, 2017. \n49- \nAlsamhi, S. H., Ma, O., and Ansari,\
    \ M. S. (2019b). Survey on artificial intelligence-based techniques \nfor emerging\
    \ robotic communication. Telecommun. Syst. 72, 483–503. doi: 10.1007/s11235-019-\n\
    00561-z \n50- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for\
    \ overhead power line inspection using \nan unmanned aerial vehicle RELIFO project.\
    \ In Proceedings of the International Conference on \nUnmanned Aircraft Systems\
    \ (ICUAS), Atlanta, GA, USA, 28–31 May 2013; pp. 244–252. \n51- \nKim, H.; Lee,\
    \ J.; Ahn, E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using\
    \ a UAV \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.  \n52-\
    \ \nGeneration and Processing of Simulated Underwater Images for Infrastructure\
    \ Visual Inspection \nwith UUVs. Sensors 2019, 19, 5497.  \n53- \nBao, J.; Li,\
    \ D.; Qiao, X.; Rauschenbach, T. Integrated navigation for autonomous underwater\
    \ \nvehicles in aquaculture: A review. Inf. Process. Agric. 2020, 7, 139–151.\
    \  \n54- \nBarrett, N.; Seiler, J.; Anderson, T.; Williams, S.; Nichol, S.; Hill,\
    \ N. Autonomous Underwater Vehicle \n(AUV) for mapping marine biodiversity in\
    \ coastal and shelf waters: Implications for Marine \nManagement. In Proceedings\
    \ of the OCEANS’10 IEEE Conference, Sydney, Australia, 24−27 May \n2010. \n55-\
    \ \nWynn, R.B.; Huvenne, V.A.I.; le Bas, T.P.; Murton, B.; Connelly, D.P.; Bett,\
    \ B.J.; Ruhl, H.A.; Morris, K.J.; \nPeakall, J.; Parsons, D.R.; et al. Autonomous\
    \ Underwater Vehicles (AUVs): Their past, present and \nfuture contributions to\
    \ the advancement of marine geoscience. Mar. Geol. 2014.  \n56- \nCorgnati, L.;\
    \ Marini, S.; Mazzei, L.; Ottaviani, E.; Aliani, S.; Conversi, A.; Griffa, A.\
    \ Looking inside the \nOcean: Toward an Autonomous Imaging System for Monitoring\
    \ Gelatinous Zooplankton. Sensors \n2016, 16, 2124. \n57- \nLiu, S.; Xu, H.; Lin,\
    \ Y.; Gao, L. Visual Navigation for Recovering an AUV by Another AUV in Shallow\
    \ \nWater. Sensors 2019, 19, 1889.  \n58- \nJorge, V.A.M.; Granada, R.; Maidana,\
    \ R.G.; Jurak, D.A.; Heck, G.; Negreiros, A.P.F.; Dos Santos, D.H.; \nGonçalves,\
    \ L.M.G.; Amory, A.M. A Survey on Unmanned Surface Vehicles for Disaster Robotics:\
    \ \nMain Challenges and Directions. Sensors 2019, 19, 702. \n59- \nNuţă, I.; Orban,\
    \ O.; Grigore, L. Development and Improvement of Technology in Emergency \nResponse.\
    \ Procedia Econ. Financ. 2015, 32, 603–609. \n60- \nBellingham, J.G.; Rajan, K.\
    \ Robotics in Remote and Hostile Environments. Science 2007, 318, 1098–\n1102.\
    \ \n61- \nMarques, F.; Lourenço, A.; Mendonça, R.; Pinto, E.; Rodrigues, P.; Santana,\
    \ P.; Barata, J. A critical \nsurvey on marsupial robotic teams for environmental\
    \ monitoring of water bodies. In Proceedings \nof the OCEANS 2015, Genova, Italy,\
    \ 19–22 October 2015; pp. 1–6. \n62- \nColey, K. Unmanned Surface Vehicles: The\
    \ Future of Data-Collection. Ocean. Chall. 2015, 21, 14–\n15. \n63- \nMoysiadis,\
    \ V.; Sarigiannidis, P.; Moscholios, I. Towards Distributed Data Management in\
    \ Fog \nComputing. Wirel. Commun. Mob. Comput. 2018, 2018. [Google Scholar] [CrossRef]\
    \ \n64- \nG. Plastiras, M. Terzi, C. Kyrkou and T. Theocharidcs, \"Edge Intelligence:\
    \ Challenges and \nOpportunities of Near-Sensor Machine Learning Applications,\"\
    \ 2018 IEEE 29th International \nConference on Application-specific Systems, Architectures\
    \ and Processors (ASAP), 2018, pp. 1-7, \ndoi: 10.1109/ASAP.2018.8445118. \n \n\
    146 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n65- \n Miorandi, D.\
    \ ; Sicari, S.; De Pellegrini, F.; Chlamtac, I. Internet of Things. Ad Hoc Netw.2012,10,\
    \ \n1497–1516.  \n66- \nXu, L.D. Enterprise systems: State-of-the-art and future\
    \ trends. IEEE Trans. Ind. Informat.2011,7, \n630–640. \n67- \nLombardi, M.; Pascale,\
    \ F.; Santaniello, D. Internet of Things: A General Overview between \nArchitectures,\
    \ Protocols and Applications. Information 2021, 12, 87.  \n68- \nNgu, A.H.H.;\
    \ Gutierrez, M.; Metsis, V.; Nepal, S.; Sheng, M.Z. Iot middleware: A survey on\
    \ issues \nand enabling technologies. IEEE Internet Things J.2016,4, 1.  \n69-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316.  \n70- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141. \n71- \nNavet, N.; Simonot-Lion, F.; Delong, C. In-Vehicle Communication\
    \ Networks: A Historical \nPerspective and Review; Apple Academic Press: Palm\
    \ Bay, FL, USA, 2017; pp. 50–51. \n72- \n[33] Colakovi ́c, A.; Hadžiali ́c, M.\
    \ Internet of Things (IoT): A review of enabling technologies, \nchallenges, and\
    \ open research issues.Comput. Netw.2018,144, 17–39.  \n73- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109.  \n74- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation\
    \ of combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6.  \n75- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Future Internet 2019, 11, 66. \n76- \nTrancă, D.-C.; Pălăcean, A.V.; Mihu, A.C.;\
    \ Rosner, D. ZigBee based wireless modbus aggregator for \nintelligent industrial\
    \ facilities. In Proceedings of the IEEE 25th Telecommunication Forum, \nBelgrade,\
    \ Serbia, 21–22 November 2017.  \n77- \nTariq, M.A.; Khan, M.; Raza Khan, M.T.;\
    \ Kim, D. Enhancements and Challenges in CoAP—A Survey. \nSensors 2020, 20, 6391.\
    \  \n78- \nKäbisch, S.; Peintner, D. W3C Recommendation Canonical EXI. 2018. Available\
    \ online: \nhttps://www.w3.org/TR/exi-c14n/ (accessed on 4 February 2019). \n\
    79- \nCavalieri, S.; Stefano, D.D.; Salafia, M.G.; Scroppo, M.S. A web-based platform\
    \ for OPC UA \nintegration in IIoT environment. In Proceedings of the 2017 22nd\
    \ IEEE International Conference \non Emerging Technologies and Factory Automation\
    \ (ETFA), Limassol, Cyprus, 12–15 September \n2017; pp. 1–6. \n80- \nCavalieri,\
    \ S.; Chiacchio, F. Analysis of OPC UA performances. Comput. Stand. Interfaces\
    \ 2013, 36, \n165–177.  \n81- \nGu, Xiaohui et al. “Energy-Optimal Latency-Constrained\
    \ Application Offloading in Mobile-Edge \nComputing.” Sensors (Basel, Switzerland)\
    \ vol. 20,11 3064. 28 May. 2020, doi:10.3390/s20113064 \n82- \nNetguru. Available\
    \ online: https://www.netguru.com/blog/why-is-python-good-for-research-\nbenefits-of-the-programming-language\
    \ (accessed on 3 May 2020). \n83- \nChen, S.; Xu, H.; Liu, D.; Hu, B.; Wang, H.\
    \ A Vision of IoT: Applications, Challenges, and \nOpportunities with China Perspective.\
    \ IEEE Internet Things J. 2014, 1.  \n84- \nSuárez-Albela, M.; Fernández-Caramés,\
    \ T.M.; Fraga-Lamas, P.; Castedo, L. A Practical Evaluation of \na High-Security\
    \ Energy-Efficient Gateway for IoT Fog Computing Applications. Sensors 2017, 17,\
    \ \n1978. [ \n85- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141.  \n86- \nGutiérrez, C.S.V.; Juan, L.U.S.; Ugarte, I.Z.; Vilches,\
    \ V.M. Time-Sensitive networking for \nrobotics. arXiv 2018, arXiv:1804.07643v2.\
    \  \n87- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of combining\
    \ OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things system.\
    \ In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS), Geneva,\
    \ Switzerland, 6–9 June 2017; pp. 1–6. \n88- \nOPC Foundation. Available online:\
    \ https://opcfoundation.org/about/opc-technologies/opc-\nua/ (accessed on 14 September\
    \ 2018). \n \n147 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n89- \nGirbea,\
    \ A.; Suciu, C.; Nechifor, S.; Sisak, F. Design and implementation of a service-oriented\
    \ \narchitecture for the optimization of industrial applications. IEEE Trans.\
    \ Ind. Inform. 2014, 10, 185–\n196. \n90- \nChen, B.; Wan, J.; Shu, L.; Li, P.;\
    \ Mukherjee, M.; Yin, B. Smart Factory of Industry 4.0: Key \nTechnologies, Application\
    \ Case, and Challenges. IEEE Access 2017, 6, 6505–6519 \n91- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Futur. Internet 2019, 11, 66. \n92- \nRay, P.P. A Survey on Visual Programming\
    \ Languages in Internet of Things. Sci. \nProgram. 2017, 2017, 1231430.  \n93-\
    \ \nBröring, A.; Seeger, J.; Papoutsakis, M.; Fysarakis, K.; Caracalli, A. Networking-Aware\
    \ IoT Application \nDevelopment. Sensors 2020, 20, 897. https://doi.org/10.3390/s20030897\
    \ \n94- \nChris Simpkin, Ian Taylor, Daniel Harborne, Graham Bent, Alun Preece,\
    \ Raghu K. Ganti, Efficient \norchestration of Node-RED IoT workflows using a\
    \ Vector Symbolic Architecture, Future \nGeneration Computer Systems, Elsevier,\
    \ Volume 111, 2020, Pages 117-131, ISSN 0167-\n739X,https://doi.org/10.1016/j.future.2020.04.005.\
    \ \n95- \nYasumoto, K.; Yamaguchi, H.; Shigeno, H. Survey of Real-time Processing\
    \ Technologies of IoT \nData Streams. J. Inf. Process. 2016, 24, 195–202.  \n\
    96- \nFernández-Caramés, T.M.; Fraga-Lamas, P. A Review on Human-Centered IoT-Connected\
    \ Smart \nLabels for the Industry 4.0. IEEE Access 2017, 6, 25939–25957.  \n97-\
    \ \nWan, J.; Tang, S.; Yan, H.; Li, D.; Wang, S.; Vasilakos, A.V. Cloud Robotics:\
    \ Current Status and \nOpen Issues. IEEE Access 2016, 4, 2797–2807.  \n98- \n\
    Robla-Gömez, S.; Becerra, V.M.; Llata, J.R.; González-Sarabia, E.; Ferrero, C.T.;\
    \ Pérez-Oria, J. \n‘Working together: A review on safe human-robot collaboration\
    \ in industrial environments. IEEE \nAccess 2017, 5, 26754–26773.  \n99- \nKoch,\
    \ P.J.; van Amstel, M.; Dębska, P.; Thormann, M.A.; Tetzlaff, A.J.; Bøgh, S.;\
    \ Chrysostomou, D. A \nSkill-based Robot Co-worker for Industrial Maintenance\
    \ Tasks. In Proceedings of the 27th \nInternational Conference on Flexible Automation\
    \ and Intelligent Manufacturing (FAIM 2017), \nModena, Italy, 27–30 June 2017.\
    \  \n100- \nAndreasson, H.; Bouguerra, A.; Cirillo, M.; Dimitrov, D.N.; Driankov,\
    \ D.; Karlsson, L.; Lilienthal, A.J.; \nPecora, F.; Saarinen, J.P.; Sherikov,\
    \ A.; et al. Autonomous transport vehicles: Where we are and \nwhat is missing.\
    \ IEEE Robot. Autom. Mag. 2015, 22, 64–75.] \n101- \nAlsamhi, S.H.; Ma, O.; Ansari,\
    \ M.S.; Gupta, S.K. Collaboration of Drone and Internet of Public \nSafety Things\
    \ in Smart Cities: An Overview of QoS and Network Performance \nOptimization.\
    \ Drones 2019, 3, 13.  \n102- \nSoorki, M.N.; Mozaffari, M.; Saad, W.; Manshaei,\
    \ M.H.; Saidi, H. Resource Allocation for Machine-\nto-Machine Communications\
    \ with Unmanned Aerial Vehicles. In Proceedings of the 2016 IEEE \nGlobecom Workshops\
    \ (GC Wkshps), Washington, DC, USA, 4–8 December 2016; pp. 1–6.  \n103- \nLarrauri,\
    \ J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for overhead power line inspection\
    \ using \nan unmanned aerial vehicle RELIFO project. In Proceedings of the International\
    \ Conference on \nUnmanned Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May\
    \ 2013; pp. 244–252.  \n104- \nKim, H.; Lee, J.; Ahn, E.; Cho, S.; Shin, M.; Sim,\
    \ S.-H. Concrete Crack Identification Using a UAV \nIncorporating Hybrid Image\
    \ Processing. Sensors 2017, 17, 2052. \n105- \nArroyo, J.A.; Gomez-Castaneda,\
    \ C.; Ruiz, E.; de Cote, E.M.; Gavi, F.; Sucar, L.E. UAV Technology and \nMachine\
    \ Learning Techniques applied to the Yield Improvement in Precision Agriculture.\
    \ In \nProceedings of the IEEE Mexican Humanitarian Technology Conference (MHTC),\
    \ Puebla, Mexico, \n29–31 March 2017.  \n106- \nSingh, A.; Patil, D.; Omkar, S.N.\
    \ Eye in the Sky: Real-time Drone Surveillance System (DSS) for \nViolent Individuals\
    \ Identification using ScatterNet Hybrid Deep Learning Network. In Proceedings\
    \ \nof the IEEE Computer Vision and Pattern Recognition (CVPR) Workshops, Salt\
    \ Lake City, UT, USA, \n18–22 June 2018.  \n107- \nManohar, A.; Sneha, D.; Sakhuja,\
    \ K.; Dwivedii, T.R.; Gururaj, C. Drone based image processing \nthrough feature\
    \ extraction. In Proceedings of the 2017 2nd IEEE International Conference on\
    \ \nRecent Trends in Electronics Information & Communication Technology (RTEICT),\
    \ Bangalore, \nIndia, 19–20 May 2017.  \n108- \nJunaid, A.B.; Konoiko, A.; Zweiri,\
    \ Y.; Sahinkaya, M.N.; Seneviratne, L. Autonomous Wireless Self-\nCharging forMulti-Rotor\
    \ Unmanned Aerial Vehicles. Energies 2017, 10, 803. \n \n148 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n109- \nLee, J.; Wang, J.; Crandall, D.; Sabanovic, S.;\
    \ Fox, G. Real-Time Object Detection for Unmanned \nAerial Vehicles based on Cloud-based\
    \ Convolutional Neural Networks. In Proceedings of the First \nIEEE International\
    \ Conference on Robotic Computing, Taichung, Taiwan, 10–12 April 2017. \n110-\
    \ \nSilva, E.; Martins, A.; Dias, A.; Matos, A.; Olivier, A.; Pinho, C.; Silva,\
    \ E.; de Sá, F.A.; Ferreira, H.; Silva, \nH.; et al. Strengthening marine and\
    \ maritime research and technology. In Proceedings of the \nOCEANS 2016 MTS/IEEE\
    \ Monterey, Monterey, CA, USA, 19–23 September 2016; pp. 1–9.  \n111- \nNicholson,\
    \ J.; Healey, A. The present state of autonomous underwater vehicle (AUV) applications\
    \ \nand technologies. Mar. Technol. Soc. J. 2008, 42, 44–51.  \n112- \nWeidner,\
    \ N.; Rahman, S.; Li, A.Q.; Rekleitis, I. Underwater cave mapping using stereo\
    \ vision. In \nProceedings of the IEEE International Conference on Robotics and\
    \ Automation, Singapore, 29 \nMay–3 June 2017; pp. 5709–5715.  \n113- \nRoser,\
    \ M.; Dunbabin, M.; Geiger, A. Simultaneous underwater visibility assessment,\
    \ enhancement \nand improved stereo. In Proceedings of the IEEE International\
    \ Conference on Robotics and \nAutomation, Hong Kong, China, 31 May–7 June 2014;\
    \ pp. 1–8.  \n114- \nLu, H.; Li, Y.; Xu, X.; He, L.; Dansereau, D.; Serikawa,\
    \ S. Underwater image descattering and quality \nassessment. In Proceedings of\
    \ the IEEE International Conference on Image Processing, Phoenix, \nAZ, USA, 25–28\
    \ September 2016; pp. 1998–2002.  \n115- \nLu, H.; Serikawa, S. Underwater scene\
    \ enhancement using weighted guided median filter. In \nProceedings of the IEEE\
    \ International Conference on Multimedia and Expo, Chengdu, China, 14–\n18 July\
    \ 2014; pp. 1–6. \n116- \nForesti, G.L.; Murino, V.; Regazzoni, C.S.; Trucco,\
    \ A. A Voting-Based Approach for Fast Object \nRecognition in Underwater Acoustic\
    \ Images. IEEE J. Ocean. Eng. 1997, 22, 57–65.  \n117- \nHansen, R.K.; Andersen,\
    \ P.A. 3D Acoustic Camera for Underwater Imaging. Acoust. \nImaging 1993, 20,\
    \ 723–727.  \n118- \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar\
    \ imagery using qualitative feature \nmatching. IEEE J. Ocean. Eng. 1994, 19,\
    \ 391–405. \n119- \nForesti, G.L.; Gentili, S. A Vison Based System for Object\
    \ Detection In Underwater Images. Int. J. \nPattern Recognit. Artif. Intell. 2000,\
    \ 14, 167–188. \n120- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching\
    \ via Deep Learning. In Proceedings \nof the 2017 European Conference on Mobile\
    \ Robots (ECMR), Paris, France, 6–8 September 2017.  \n121- \nVillon, S.; Mouillot,\
    \ D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger, S. A Deep\
    \ \nLearning method for accurate and fast identification of coral reef fishes\
    \ in underwater \nimages. Ecol. Inform. 2018.  \n122- \nQut University. Available\
    \ online: https://www.qut.edu.au/news?id=135108 (accessed on 3 May \n2020). \n\
    123- \nPiechaud, N.; Hunt, C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated\
    \ identification of \nbenthic epifauna with computer vision. Mar. Ecol. Prog.\
    \ Ser. 2019, 615, 15–30.  \n124- \nGelin, C. Introduction. In A High-Rate Virtual\
    \ Instrument of Marine Vehicle Motions for \nUnderwater Navigation and Ocean Remote\
    \ Sensing. Springer Series on Naval Architecture, Marine \nEngineering, Shipbuilding\
    \ and Shipping; Springer: Berlin/Heidelberg, Germany, 2013; Volume 1. \n125- \n\
    Heidarsson, H.K.; Sukhatme, G.S. Obstacle detection from overhead imagery using\
    \ self-supervised \nlearning for autonomous surface vehicles. In Proceedings of\
    \ the 2011 IEEE/RSJ International \nConference on Intelligent Robots and Systems,\
    \ San Francisco, CA, USA, 25–30 September 2011; \npp. 3160–3165. \n126- \nKristan,\
    \ M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast Image-Based Obstacle Detection from\
    \ Unmanned \nSurface Vehicles. IEEE Trans. Cybern. 2015, 46, 641–654 \n127- \n\
    Blanke, M.; Hansen, S.; Stets, J.D.; Koester, T.; Brøsted, J.E.; Llopart Maurin,\
    \ A.; Nykvist, N.; Bang, J. \nOutlook for navigation—comparing human performance\
    \ with a robotic solution. In Proceedings \nof the 1st International Conference\
    \ on Maritime Autonomous Surface Ships (ICMASS 2018), Busan, \nKorea, 8–9 November\
    \ 2018.  \n128- \nPrasad, D.K.; Prasath, C.K.; Rajan, D.; Rachmawati, L.; Rajabaly,\
    \ E.; Quek, C. Challenges in video-\nbased object detection in maritime scenario\
    \ using computer vision. arXiv 2016, arXiv:1608.0107. \nAvailable online: https://arxiv.org/abs/1608.01079\
    \ (accessed on 17 November 2020). \n129- \nWawrzyniak, N.; Hyla, T.; Popik, A.\
    \ Vessel Detection and Tracking Method Based on Video \nSurveillance. Sensors\
    \ 2019, 19, 5230.  \n130- \nCho, Y.; Park, J.; Kang, M.; Kim, J. Autonomous detection\
    \ and tracking of a surface ship using \nonboard monocular vision. In Proceedings\
    \ of the 2015 12th International Conference on \nUbiquitous Robots and Ambient\
    \ Intelligence (URAI), Goyang, Korea, 28–30 October 2015. \n \n149 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n131- \nIBM \nBoards \nthe \nMayflower\
    \ \nAutonomous \nShip \nProject. \nAvailable \nonline: https://newsroom.ibm.com/2019-10-16-IBM-Boards-the-Mayflower-Autonomous-Ship-\n\
    Project (accessed on 17 November 2020). \n132- \nGoogle and Rolls-Royce Partner\
    \ on Autonomous Ships. Available online: https://maritime-\nexecutive.com/article/google-and-rolls-royce-partner-on-autonomous-ships\
    \ (accessed on 17 \nNovember 2020). \n133- \nHansen, R.K.; Andersen, P.A. 3D Acoustic\
    \ Camera for Underwater Imaging. Acoust. \nImaging 1993, 20, 723–727.  \n134-\
    \ \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar imagery using qualitative\
    \ feature \nmatching. IEEE J. Ocean. Eng. 1994, 19, 391–405. \n135- \nForesti,\
    \ G.L.; Gentili, S. A Vison Based System for Object Detection In Underwater Images.\
    \ Int. J. \nPattern Recognit. Artif. Intell. 2000, 14, 167–188. \n136- \nVillon,\
    \ S.; Mouillot, D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger,\
    \ S. A Deep \nLearning method for accurate and fast identification of coral reef\
    \ fishes in underwater \nimages. Ecol. Inform. 2018.  \n137- \nPiechaud, N.; Hunt,\
    \ C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated identification of\
    \ \nbenthic epifauna with computer vision. Mar. Ecol. Prog. Ser. 2019, 615, 15–30.\
    \  \n138- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching via Deep\
    \ Learning. In Proceedings \nof the 2017 European Conference on Mobile Robots\
    \ (ECMR), Paris, France, 6–8 September 2017.  \n139- \nGelin, C. Introduction.\
    \ In A High-Rate Virtual Instrument of Marine Vehicle Motions for \nUnderwater\
    \ Navigation and Ocean Remote Sensing. Springer Series on Naval Architecture,\
    \ Marine \nEngineering, Shipbuilding and Shipping; Springer: Berlin/Heidelberg,\
    \ Germany, 2013; Volume 1. \n140- \nHeidarsson, H.K.; Sukhatme, G.S. Obstacle\
    \ detection from overhead imagery using self-supervised \nlearning for autonomous\
    \ surface vehicles. In Proceedings of the 2011 IEEE/RSJ International \nConference\
    \ on Intelligent Robots and Systems, San Francisco, CA, USA, 25–30 September 2011;\
    \ \npp. 3160–3165. \n141- \nKristan, M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast\
    \ Image-Based Obstacle Detection from Unmanned \nSurface Vehicles. IEEE Trans.\
    \ Cybern. 2015, 46, 641–654 \n142- \nGu, J.; Wang, Z.; Kuen, J.; Ma, L.; Shahroudy,\
    \ A.; Shuai, B.; Liu, T.; Wang, X.; Wang, G.; Cai, J.; et al. \nRecent advances\
    \ in convolutional neural networks. Pattern Recognit. 2018, 77 \n143- \n48. Krizhevsky,\
    \ A.; Sutskever, I.; Hinton, G.E. ImageNet classification with deep convolutional\
    \ neural \nnetworks. In Proceedings of the International Conference on Neural\
    \ Information Processing \nSystems, Lake Tahoe, NV, USA, 3–8 December 2012; pp.\
    \ 1097–1105. \n144- \n Deng, J.; Dong, W.; Socher, R.; Li, L.J.; Li, K.; Li, F.F.\
    \ ImageNet: A large-scale hierarchical image \ndatabase. In Proceedings of the\
    \ Computer Vision and Pattern Recognition, 2009 (CVPR 2009), \nMiami, FL, USA,\
    \ 20–25 June 2009; pp. 248–255.  \n145- \n50. Girshick, R. Fast R-CNN. In Proceedings\
    \ of the 2015 IEEE International Conference on Computer \nVision (ICCV), Santiago,\
    \ Chile, 7–13 December 2015.  \n146- \n Ren, S.; He, K.; Girshick, R.; Sun, J.\
    \ Faster R-CNN: Towards Real-Time Object Detection with Region \nProposal Networks.\
    \ IEEE Trans. Pattern Anal. Mach. Intell. 2017, 39, 1137–1149.  \n147- \n Lin,\
    \ T.; Goyal, P.; Girshick, R.; He, K.; Dollár, P. Focal Loss for Dense Object\
    \ Detection. In \nProceedings of the 2017 IEEE International Conference on Computer\
    \ Vision (ICCV), Honolulu, HI, \nUSA, 21–26 July 2017. \n148- \n53.  Liu, W.;\
    \ Anguelov, D.; Erhan, D.; Szegedy, C.; Reed, S.; Fu, C.Y.; Berg, A.C. SSD: Single\
    \ shot \nmultibox detector. In Proceedings of the European Conference on Computer\
    \ Vision, Amsterdam, \nThe Netherlands, 11–14 October 2016; pp. 21–37. \n149-\
    \ \n54. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only look once:\
    \ Unified, real-time object \ndetection. In Proceedings of the IEEE Conference\
    \ on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas, NV, USA,\
    \ 27–30 June 2016; pp. 779–788.  \n150- \nGhidoni, P.L.N.S.; Brahnam, S. Handcrafted\
    \ vs. non-handcrafted features for computer vision \nclassification. Pattern Recognit.\
    \ 2017, 71, 158–172. \n151- \nPathak, A.R.; Pandey, M.; Rautaray, S. Application\
    \ of Deep Learning for Object Detection. In \nProceedings of the International\
    \ Conference on Computational Intelligence and Data Science \n(ICCIDS 2018), Gurugram,\
    \ India, 7–8 April 2018. \n152- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li, X.\
    \ Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n153- \n58. Zhao, Z.; Zheng, P.; Xu, S.; Wu, X. Object\
    \ Detection with Deep Learning: A Review. IEEE Trans. \nNeural Netw. Learn. Syst.\
    \ 2019, 30, 3212–3232.  \n \n150 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n154- \nDahlkamp, H.; Kaehler, A.; Stavens, D.; Thrun, S.; Bradski, G.R. Self\
    \ supervised monocular road \ndetection in desert terrain. In Proceedings of the\
    \ Robotics: Science and Systems, Philadelphia, PA, \nUSA, 16–19 August 2006. \n\
    155- \n Chen, C.; Seff, A.; Kornhauser, A.; Xiao, J. Deep Driving: Learning affordance\
    \ for direct perception \nin autonomous driving. In Proceedings of the 2015 IEEE\
    \ International Conference on Computer \nVision (ICCV), Santiago, Chile, 7–13\
    \ December 2015; pp. 2722–2730.  \n156- \nChen, X.; Ma, H.; Wan, J.; Li, B.; Xia,\
    \ T. Multi-view 3D object detection network for autonomous \ndriving. In Proceedings\
    \ of the 2017 IEEE International Conference on Computer Vision (ICCV), \nHonolulu,\
    \ HI, USA, 21–26 July 2017; pp. 6526–6534. \n157- \nCoates, A.; Ng, A.Y. Multi-camera\
    \ object detection for robotics. In Proceedings of the 2010 IEEE \nInternational\
    \ Conference on Robotics and Automation, Anchorage, AK, USA, 3–7 May 2010; pp.\
    \ \n412–419. \n158- \nArmbrust, M.; Fox, A.; Griffith, R.; Joseph, A.D.; Katz,\
    \ R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, \nA.; Stoica, I.; et al.\
    \ A view of cloud computing. Commun. ACM 2010, 53, 50–58.  \n159- \n63. Kenitar,\
    \ S.B.; Arioua, M.; Younes, A.; Radi, M.; Salhaoui, M. Comparative Analysis of\
    \ Energy \nEfficiency and Latency of Fog and Cloud Architectures. In Proceedings\
    \ of the 2019 International \nConference on Sensing and Instrumentation in IoT\
    \ Era (ISSI), Lisbon, Portugal, 29–30 August 2019; \nIEEE: Piscataway, NJ, USA,\
    \ 2020.  \n160- \n64. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only\
    \ look once: Unified, real-time object \ndetection. In Proceedings of the IEEE\
    \ Conference on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas,\
    \ NV, USA, 27–30 June 2016; pp. 779–788.  \n161- \nWang, X.; Victor, C.M.; Niyato,\
    \ D.; Yan, X.; Chen, X. Convergence of Edge Computing and Deep \nLearning: A Comprehensive\
    \ Survey. IEEE Commun. Surv. Tutor. 2020, 22, 869–904.  \n162- \nComputer Vision,\
    \ WikiPedia. Available online: https://en.wikipedia.org/wiki/Computer_vision \n\
    (accessed on 18 June 2020). \n163- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li,\
    \ X. Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n164- \nKang, Y.; Hauswald, J.; Gao, C.; Rovinski, A.;\
    \ Mudge, T.; Mars, J.; Tang, L. Neurosurgeon: \nCollaborative Intelligence Between\
    \ the Cloud and Mobile Edge. In Proceedings of the 22nd \nInternational Conference\
    \ on Architectural Support for Programming Languages and Operating \nSystems (ASPLOS\
    \ 2017), Xi’an, China, 8–12 April 2017; pp. 615–629.  \n165- \nRussakovsky, O.;\
    \ Deng, J.; Su, H.; Krause, J.; Satheesh, S.; Ma, S.; Huang, Z.; Karpathy, A.;\
    \ Khosla, A.; \nBernstein, M.; et al. ImageNet Large Scale Visual Recognition\
    \ Challenge. Int. J. Comput. Vis. 2015, \n115, 211–252. \n166- \nZhou, Z.; Chen,\
    \ X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving the Last\
    \ Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019, 107.\
    \  \n167- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis, M.\
    \ A Comparative  Taxonomy and \nSurvey of Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2.  \n168- \nGoogle Cloud. Available online: https://cloud.google.com/vision/?hl=en\
    \ (accessed on 3 May \n2020). \n169- \nAzure. Available online: https://azure.microsoft.com/en-au/services/cognitive-services/computer-\n\
    vision/ (accessed on 3 May 2020). \n170- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.;\
    \ Luo, K.; Zhang, J. Edge Intelligence: Paving the Last Mile of \nArtificial Intelligence\
    \ with Edge Computing. Proc. IEEE 2019, 107. \n171- \nO’Mahony, N.; Campbell,\
    \ S.; Carvalho, A.; Harapanahalli, S.; Hernandez, G.V.; Krpalkova, L.; Riordan,\
    \ \nD.; Walsh, J. Deep Learning vs. Traditional Computer Vision. In Advances in\
    \ Computer Vision; Arai, \nK., Kapoor, S., Eds.; Springer: Cham, Switzerland,\
    \ 2020; Volume 943.  \n172- \nStefanini, M.; Lancellotti, R.; Baraldi, L.; Calderara,\
    \ S.A. Deep-learning-based approach to VM \nbehavior Identification in Cloud Systems.\
    \ In Proceedings of the 9th International Conference on \nCloud Computing and\
    \ Services Science, Crete, Greece, 2–4 May 2019; pp. 308–315. \n173- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55 \n174- \nKurose, J.F.; Ross, K.W. Computer Networking: A Top-Down\
    \ Approach, 6th ed.; Pearson: London, \nUK, 2012.  \n175- \nThangamuthu, S.; Concer,\
    \ N.; Cuijpers, P.J.L.; Lukkien, J.J. Analysis of ethernet-switch traffic shapers\
    \ \nfor in-vehicle networking applications. In Proceedings of the 2015 Design,\
    \ Automation Test in \nEurope Conference Exhibition (DATE), Grenoble, France,\
    \ 9–13 March 2015; pp. 55–60 \n \n151 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n176- \nCavalieri, S.; Chiacchio, F. Analysis of OPC UA performances.\
    \ Comput. Stand. Interfaces 2013, 36, \n165–177 \n177- \nGutiérrez, C.S.V.; Juan,\
    \ L.U.S.; Ugarte, I.Z.; Vilches, V.M. Time-Sensitive networking for \nrobotics.\
    \ arXiv 2018, arXiv:1804.07643v2.  \n178- \nIEEE standard for local and metropolitan\
    \ area networks—Bridges and bridged networks-\namendment 25: Enhancements for\
    \ scheduled traffic. In IEEE Std 802.1Qbv-2015 (Amendment to \nIEEE Std 802.1Q-2014\
    \ as amended by IEEE Std 802.1Qca-2015, IEEE Std 802.1Qcd-2015, and IEEE \nStd\
    \ 802.1Q-2014/ Cor 1-2015); IEEE: New York, NY, USA, 2016; pp. 1–57. \n179- \n\
    Bruckner, D.; Blair, R. OPC, UA, TSN: A New Solution for Industrial Communication.\
    \ 2018. Available \nonline: https://www.automationworld.com/sites/default/files/opc_ua_tsn_whitepaper_1.pdf\
    \ (acce\nssed on 13 May 2019). \n180- \nTatum, M.C.; Liu, J. Unmanned Aerial Vehicles\
    \ in the Construction Industry. In Proceedings of the \nUnmanned Aircraft System\
    \ Applications in Construction, Creative Construction Conference, \nPrimosten,\
    \ Croatia, 19–22 June 2017. \n181- \nSisinni, E.; Saifullah, A.; Han, S.; Jennehag,\
    \ U.; Gidlund, M. Industrial Internet of Things: Challenges, \nOpportunities,\
    \ and Directions. IEEE Trans. Ind. Inform. 2018, 14, 4724–4734.   \n182- \nAazam,\
    \ M.; Zeadally, S.; Harras, K.A. Deploying Fog Computing in Industrial Internet\
    \ of Things and \nIndustry 4.0. IEEE Trans. Ind. Inform. 2018.   \n183- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55.  . \n184- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic\
    \ system for overhead power line inspection using \nan unmanned aerial vehicle\
    \ RELIFO project. In Proceedings of the International Conference on \nUnmanned\
    \ Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May [32] 2013; pp. 244–252.\
    \   32. \nIndustrial \nSkyworks. \nDrone \nInspections \nServices. \nAvailable\
    \ \nonline: \nhttps://industrialskyworks.com/droneinspections-services (accessed\
    \ on 21 April 2019). \n185- \nSoria, P.R.; Bevec, R.; Arrue, B.C.; Ude, A.; Ollero,\
    \ A. Extracting Objects for Aerial Manipulation on \nUAVs Using Low Cost Stereo\
    \ Sensors. Sensors 2016, 16, 700.      \n186- \nLagkas, T.; Argyriou, V.; Bibi,\
    \ S.; Sarigiannidis, P. UAV IoT Framework Views and Challenges: \nTowards Protecting\
    \ Drones as “Things”. Sensors 2018, 18, 4015.     \n187- \nKim, H.; Lee, J.; Ahn,\
    \ E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using a UAV\
    \ \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.   \n188- \n\
    Sara Mahmoud, Nader Mohamed, Jameela Al-Jaroodi, Integrating UAVs into the Cloud\
    \ Using the \nConcept of the Web of Things. Article in Journal of Robotics, published\
    \ January 2015. DOI\n \n10.1155/2015/631420 \n189- \nGithub. Available online:\
    \ https://github.com/felixge/node-ar-drone (accessed on 14 September \n2018).\
    \ \n190- \nGithub. \nAvailable \nonline: https://github.com/eschnou/ardrone-autonomy\
    \ (accessed \non \n14 \nSeptember 2018). \n191- \nEngel, J.; Sturm, J.; Cremers,\
    \ D. Accurate Figure Flying with a Quadrocopter Using Onboard Visual \nand Inertial\
    \ Sensing. In Proceedings of the International Conference on Intelligent Robot\
    \ Systems \n(IROS), Algarve, Portugal, 7–12 October 2012; p. 240. [Google Scholar]\
    \ \n192- \nSmith, J.R.; Cao, L.; Codella, N.C.F.; Hill, M.L.; Merler, M.; Nguyen,\
    \ Q.-B.; Pring, E.; Uceda-Sosa, R.A. \nMassive-scalelearning of image and video\
    \ semantic concepts. IBM J. Res. Dev. 2015, 59, 7-1–7-13. \n193- \nCaffe. Available\
    \ online: http://caffe.berkeleyvision.org (accessed on 14 September 2018). \n\
    \ \n194- \nBhattacharjee, B.; Hill, M.L.; Wu, H.; Chandakkar, P.S.; Smith, J.R.;\
    \ Wegman, M.N. Distributed \nlearning of deep feature embeddings for visual recognition\
    \ tasks. IBM J. Res. Dev. 2017, 61, 4-1. \n[Google Scholar] [CrossRef] \n195-\
    \ \nPuttnies, H.; Konieczek, B.; Heller, J.; Timmermann, D.; Danielis, P. Algorithmic\
    \ approach to estimate \nvariant software latencies for latency-sensitive networking.\
    \ In Proceedings of the 2016 IEEE 7th \nAnnual Information Technology, Electronics\
    \ and Mobile Communication Conference (IEMCON), \nVancouver, BC, Canada, 13–15\
    \ October 2016; pp. 1–7. [Google Scholar] \n196- \nNakutis, Z.; Deksnys, V.; Jarusevicius,\
    \ I.; Dambrauskas, V.; Cincikas, G.; Kriauceliunas, A. Round-Trip \nDelay \nEstimation\
    \ \nin \nOPC \nUA \nServer-Client \nCommunication \nChannel. Elektron \nElektrotechnika\
    \ 2016, 22, 80–84.  \n197- \nGithub. Available online: https://github.com/felixge/node-ar-drone\
    \ (accessed on 14 September \n2018). \n \n152 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n198- \nKeith Jack,Digital Television (DTV).  in Digital Video and\
    \ DSP, 2008. ScienceDirect. \nhttps://doi.org/10.1016/B978-0-7506-8975-5.00008-X\
    \ \n199- \nMarpe, D.; Wiegand, T.; Heinrich Hertz Institute (HHI); Sullivan, G.J.\
    \ The H.264/MPEG4 Advanced \nVideo Coding Standard and its Applications. IEEE\
    \ Commun. Mag. 2006, 8, 134–143. [Google \nScholar] [CrossRef] \n200- \nGonzález-Reolid,\
    \ I.; Molina-Molina, J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \n\
    Autonomous Solar-Powered Marine Robotic Observatory for Permanent Monitoring of\
    \ Large \nAreas of Shallow Water. Sensors 2018, 18, 3497. [Google Scholar] [CrossRef]\
    \ [PubMed] \n201- \nBoletín Oficial de la Región de Murcia, Numero 298, Viernes,\
    \ 27 de Diciembre de 2019, Página \n36008, 8089 Decreto-Ley N° 2/2019, de 26 de\
    \ Diciembre, de Protección Integral del Mar Menor. \nAvailable \nonline: https://www.borm.es/services/anuncio/ano/2019/numero/8089/pdf?id=782206\
    \ (accesse\nd on 18 June 2020). \n202- \nInforme Integral Sobre el Estado Ecológico\
    \ del Mar Menor; Comité de Asesoramiento Científico \ndel Mar Menor: Murcia, Spain,\
    \ 2017. \n203- \nKersting, D.; Benabdi, M.; Čižmek, H.; Grau, A.; Jimenez, C.;\
    \ Katsanevakis, S.; Öztürk, B.; Tuncer, S.; \nTunesi, L.; Vázquez-Luis, M.; et\
    \ al. Pinna nobilis. IUCN Red List Threat. Species 2019, \ne.T160075998A160081499.\
    \ \nAvailable \nonline: https://www.iucnredlist.org/species/160075998/160081499\
    \ (accessed on 19 June 2020). \n[CrossRef] \n204- \nBelando, M.D.; García-Muñoz,\
    \ M.R.; Ramos-Segura, A.; Franco-Navarro, I.J.; García-Moreno, P.; \nRuiz-Fernández,\
    \ J.M. Distribución y Abundancia de las Praderas de MACRÓFITOS bentónicos y las\
    \ \nPoblaciones de Nacra (Pinna nobilis) en el Mar Menor; Informe del Instituto\
    \ Español de \nOceanografía y la Asociación de Naturalistas del Sureste: Murcia,\
    \ Spain, 2014; 60p. [Google \nScholar] \n205- \nPaull, L.; Seto, M.; Saeedi, S.;\
    \ Leonard, J.J. Navigation for Underwater Vehicles; Springer: \nBerlin/Heidelberg,\
    \ Germany, 2018. [Google Scholar] [CrossRef] \n206- \nLiu, X.; Xu, X.; Liu, Y.;\
    \ Wang, L. Kalman filter for cross-noise in the integration of SINS and \nDVL.\
    \ Math. Probl. Eng. 2014, 2014, 1–8. [Google Scholar] [CrossRef] \n207- \nPaull,\
    \ L.; Saeedi, S.; Seto, M.; Li, H. AUV navigation and localization: A review.\
    \ IEEE J. Ocean. \nEng. 2014, 39, 131–149. [Google Scholar] [CrossRef] \n208-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316. [Google Scholar] [CrossRef] \n209- \nStackoverflow. \nAvailable \nonline:\
    \ https://stackoverflow.blog/2017/09/14/python-growing-\nquickly/ (accessed on\
    \ 3 May 2020). \n210- \nNetguru. Available online: https://www.netguru.com/blog/why-is-python-good-for-research-\n\
    benefits-of-the-programming-language (accessed on 3 May 2020). \n211- \nZhou,\
    \ Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving\
    \ the Last Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019,\
    \ 107. [Google Scholar] [CrossRef] \n212- \nSikeridis, D.; Papapanagiotou, I.;\
    \ Rimal, B.P.; Devetsikiotis, M. A Comparative Taxonomy and Survey \nof Public\
    \ Cloud Infrastructure Vendors. arXiv 2018, arXiv:1710.01476v2. [Google Scholar]\
    \ \n213- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian: We watch for\
    \ potentialobstacles while you \nare walking andconducting smartphone activities.\
    \ PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n214- \nMegalingam,\
    \ R.K.; Shriram, V.; Likhith, B.; Rajesh, G.; Ghanta, S. Monocular distance estimation\
    \ \nusing pinhole camera approximation to avoid vehicle crash and back-over accidents.\
    \ In \nProceedings of the 2016 10th International Conference on Intelligent Systems\
    \ and Control (ISCO), \nCoimbatore, India, 7–8 January 2016; IEEE: Coimbatore,\
    \ India. [Google Scholar] [CrossRef] \n215- \nNational \nInstruments. \nAvailable\
    \ \nonline: https://www.ni.com/es-es/support/model.sbrio-\n9606.html (accessed\
    \ on 3 May 2020). \n216- \nNational Instruments. Available online: https://www.ni.com/en-us/shop/labview.html\
    \ (accessed \non 3 May 2020). \n217- \nMarine Species. Available online: http://www.marinespecies.org/\
    \ (accessed on 2 June 2020). \n218- \nShi, W.; Cao, J.; Zhang, Q.; Li, Y.; Xu,\
    \ L. Edge computing: Vision and challenges. IEEE Internet Things \nJ. 2016, 3,\
    \ 637–646. [Google Scholar] [CrossRef] \n \n153 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n219- \nKrupinski, S.; Desouche, R.; Palomeras, N.; Allibert,\
    \ G.; Hua, M.D. Pool Testing of AUV Visual \nServoing for Autonomous Inspection.\
    \ IFAC-PapersOnLine 2015, 48, 274–280. [Google Scholar] \n[CrossRef] \n220- \n\
    Kumar, G.S.; Unnikrishnan, V.; Painumgal, M.N.V.; Kumar, C.; Rajesh, K.H.V. Autonomous\
    \ \nUnderwater Vehicle for Vision Based Tracking. Procedia Comput. Sci. 2018.\
    \ [Google Scholar] \n[CrossRef] \n221- \nIslam, M.J.; Fulton, M.; Sattar, J. Towards\
    \ a Generic Diver-Following Algorithm: Balancing \nRobustness and Efficiency in\
    \ Deep Visual Detection. IEEE Robot. Autom. Lett. 2019, 4, 113–120. \n[Google\
    \ Scholar] [CrossRef] \n222- \nYosafat, R.; Machbub, C.; Hidayat, E.M.I. Design\
    \ and Implementation of Pan-Tilt for Face Tracking. \nIn Proceedings of the International\
    \ Conference on System Engineering and Technology, Shah \nAlam, Malaysia, 2–3\
    \ October 2017. [Google Scholar] \n223- \nZhang, B.; Huang, J.; Lin, J. A Novel\
    \ Algorithm for Object Tracking by Controlling PAN/TILT \nAutomatically. In Proceedings\
    \ of the ICETC 2nd International Conference on Intelligent System \n2010, Shanghai,\
    \ China, 22–24 June 2010; Volume VI, pp. 596–602. [Google Scholar] \n224- \nGonzález,\
    \ A.G.; Coronado, J. Tratamiento de los retrasos del procesamiento visual en el\
    \ sistema \nde control de un cabezal estereoscópico. In XX Jornadas de Automática:\
    \ Salamanca, 27, 28 y 29 \nde Septiembre; Universidad de Salamanca: Salamanca,\
    \ Spain; pp. 83–87. \n225- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian:\
    \ We watch for potentialobstacles while you \nare walking andconducting smartphone\
    \ activities. PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n226-\
    \ \nIBM. \nAvailable \nonline: https://cloud.ibm.com/docs/services/visual-recognition?topic=visual-\n\
    recognition-object-detection-overview (accessed on 3 May 2020). \n227- \nGoogle\
    \ Cloud. Available online: https://cloud.google.com/vision/?hl=en (accessed on\
    \ 3 May \n2020). \n228- \nAzure. \nAvailable \nonline: https://azure.microsoft.com/en-au/services/cognitive-\n\
    services/computer-vision/ (accessed on 3 May 2020). \n229- \nMarine protected\
    \ areas in Europe’s seas. An overview and perspectives for the future. European\
    \ \nEnvironment \nAgency. \nNo \n3/2015. \nISSN \n1977-8449. \nAvailable \nonline:\
    \ \nhttps://www.eea.europa.eu/publications/marine-protected-areas-in-europes (accessed\
    \ on 17 \nNovember 2020) \n230- \nLey 3/2001, de Pesca Marítima del Estado. Boletín\
    \ Oficial del Estado del Gobierno de España.  \nAvailable online: https://www.boe.es/eli/es/l/2001/03/26/3/con\
    \ (accessed on 17 November 2020) \n231- \nGobierno \nde \nEspaña. \nReservas \n\
    Marinas \nde \nEspaña. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-pesqueros/reservas-marinas-de-\n\
    espana/(accessed on 17 November 2020) \n232- \nGonzález-Reolid, I.; Molina-Molina,\
    \ J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \nAutonomous Solar-Powered\
    \ Marine Robotic Observatory for Permanent Monitoring of Large \nAreas of Shallow\
    \ Water. Sensors 2018, 18, 3497; doi:10.3390/s18103497. \n233- \nA. Manjunath,\
    \ Y. Liu, B. Henriques and A. Engstle, \"Radar Based Object Detection and Tracking\
    \ for \nAutonomous Driving,\" 2018 IEEE MTT-S International Conference on Microwaves\
    \ for Intelligent \nMobility (ICMIM), Munich, 2018, pp. 1-4, doi: 10.1109/ICMIM.2018.8443497\
    \ \n234- \nYang-Lang Chang, Amare Anagaw, Lena Chang, Yi Chun Wang, Chih-Yu Hsiao\
    \ and Wei-Hong Lee. \nShip Detection Based on YOLOv2 for SAR Imagery. Remote Sens.\
    \ 2019, 11, 786; \ndoi:10.3390/rs11070786 \n235- \nWei Li, Ting Yang, Flavia C.\
    \ Delicato, Paulo F. Pires, Zahir Tari, Samee U. Khan, and Albert Y. Zomaya. \n\
    On Enabling Sustainable Edge Computing with Renewable Energy Resources. IEEE \n\
    Communications Magazine. May 2018, 10.1109/MCOM.2018.1700888 \n236- \nJ. Lee,\
    \ J. Wang, D. Crandall, S. Šabanović and G. Fox, \"Real-Time, Cloud-Based Object\
    \ Detection \nfor Unmanned Aerial Vehicles,\" 2017 First IEEE International Conference\
    \ on Robotic Computing \n(IRC), Taichung, 2017, pp. 36-43, doi: 10.1109/IRC.2017.77.\
    \ \n237- \nK. Zhang, S. Leng, Y. He, S. Maharjan and Y. Zhang, \"Mobile Edge Computing\
    \ and Networking for \nGreen and Low-Latency Internet of Things,\" in IEEE Communications\
    \ Magazine, vol. 56, no. 5, pp. \n39-45, May 2018, doi: 10.1109/MCOM.2018.1700882.\
    \ \n \n154 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n238- \nAkar\
    \ E., Marques O., Andrews W.A., Furht B. (2019) Cloud-Based Skin Lesion Diagnosis\
    \ System \nUsing Convolutional Neural Networks. In: Arai K., Bhatia R., Kapoor\
    \ S. (eds) Intelligent \nComputing. CompCom 2019. Advances in Intelligent Systems\
    \ and Computing, vol 997. \nSpringer, Cham. https://doi.org/10.1007/978-3-030-22871-2_70\
    \ \n239- \nMarouane Salhaoui, J. Carlos Molina-Molina, Antonio Guerrero-González,\
    \ Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater Monitoring System\
    \ for Detecting Life on the Seabed \nby Means of Computer Vision Cloud Services.\
    \ Journal, Remote Sensing MDPI, 2020. \n240- \nNational Instruments. Available\
    \ online: https://www.ni.com/en-us/shop/labview.html (accessed \non 17 Nov 2020).\
    \ \n241- \nNational Instruments. Available online: https://www.ni.com/es-es/support/model.crio-9022.html\
    \ \n(accessed on 17 Nov 2020).  \n242- \nMarouane Salhaoui, J. Carlos Molina-Molina,\
    \ Antonio Guerrero-González, Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater\
    \ Monitoring System for Detecting Life on the Seabed \nby Means of Computer Vision\
    \ Cloud Services. Journal, Remote Sensing MDPI, 2020. \n243- \nM. Satyanarayanan,\
    \ “The emergence of edge computing,” Computer, vol. 50, no. 1, pp. 30–39, \n2017.\
    \ \n244- \nGobierno de España - Reservas Marinas de España. Cabo de Palos – Islas\
    \ Hormigas: Características. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-\n\
    pesqueros/reservas-marinas-de-espana/cabo-de-palos-islas-\nhormigas/caracteristicas/default.aspx\
    \ (accessed on 17 Nov 2020). \n245- \nIRENA - International Renewable Energy Agency.\
    \ Available online : https://www.irena.org, 07 \nJanuary 2021. \n246- \nMönks,\
    \ U., Trsek, H., Dürkop, L., Geneiß, V., Lohweg, V.: Towards distributed intelligent\
    \ \nsensor and information fusion. Mechatronics 34, 63–71 (2016). https://doi.org/10.1016/j.\
    \ \nmechatronics.2015.05.005 \n247- \nDhondge, K., Shorey, R., Tew, J.: HOLA:\
    \ heuristic and opportunistic link selection \nalgorithm for energy efficiency\
    \ in Industrial Internet of Things (IIoT) systems. In: \nCOMSNETS 2016 - Workshop\
    \ on Wild and Crazy Ideas on the Interplay Between IoT and \nBig Data. IEEE (2016)\
    \ \n248- \nDatta, S.K.; Bonnet, C. MEC and IoT Based Automatic Agent Reconfiguration\
    \ in Industry 4.0. In \nProceedings of the 2018 IEEE International Conference\
    \ on Advanced Networks and \nTelecommunications Systems (ANTS), Indore, India,\
    \ 16–19 December 2018; pp. 1–5. 7.  \n249- \nShrouf, F.; Ordieres, J.; Miragliotta,\
    \ G. Smart factories in Industry 4.0:  A review of the concept and \nof energy\
    \ management approached in production based on the Internet of Things paradigm.\
    \ In \nProceedings of the 2014 IEEE International Conference on Industrial Engineering\
    \ and Engineering \nManagement (IEEM), Selangor Darul Ehsan, Malaysia, 9–12 December\
    \ 2014; pp. 697–701. \n250- \nHossein Motlagh, N.; Mohammadrezaei, M.; Hunt, J.;\
    \ Zakeri, B. Internet of Things (IoT) and the \nEnergy Sector. Energies 2020,\
    \ 13, 494. \n251- \nAyesha Hafeez, Nourhan H. Kandil, Ban Al-Omar, T. Landolsi,\
    \ and A. R. Al-Ali, \"Smart \nHome Area Networks Protocols within the Smart Grid\
    \ Context\", Journal of Communications Vol. \n9, No. 9, September 2014 \n252-\
    \ \nLi, S.; Da Xu, L.; Zhao, S. 5G Internet of Things: A survey. J. Ind. Inf.\
    \ Integr. 2018, 10, 1–9 \n253- \nAhmed B. Altamimi and Rabie A. Ramadan, \"Towards\
    \ internet of things modeling: a gateway \napproach\", \nSpringer, \nComplex \n\
    Adapt \nSyst \nModel \n(2016) \n4:25, \nDOI \nhttps://doi.org/10.1186/s40294-016-0038-3\
    \ \n254- \nWatson Internet of Things. Securely Connect with Watson IoT Platform.\
    \ 2019. Available online: \nhttps://www.ibm.com/internet-of-things/solutions/iot-platform/watson-iot-platform\
    \  (accessed \non 15 October 2019). \n255- \n “The OPC Unified Architecture (UA)”\
    \ [Online]. Available: https://opcfoundation.org/about/opc-\ntechnologies/opc-ua/\
    \ \n256- \nThomas Bangemann, StamatisKarnouskos, Roberto Camp, Oscar Carlsson,MatthiasRiedl,\
    \ \nStuart McLeod, Robert Harrison, Armando W. ColomboandPetrStluka, “State of\
    \ the Art in \nIndustrial Automation”, Industrial Cloud-Based Cyber-Physical Systems,\
    \ Springer International \nPublishing Switzerland 2014, DOI: 10.1007/978-3-319-05624-1_2\
    \ \n257- \nNode-RED, Low-code programming for event-driven applications. [Online].\
    \ Available:  \nhttps://nodered.org/  \n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://repositorio.upct.es/bitstream/10317/10416/1/msa.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Smart IoT monitoring and real-time control based on autonomous robots, visual
    recognition and cloud/edge computing services
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.20868/upm.thesis.64746
  analysis: '>'
  authors:
  - Zhaoyu Zhai
  citation_count: 0
  full_citation: '>'
  full_text: ">\ni \n \nUniversidad Politécnica de Madrid \nEscuela Técnica Superior\
    \ de Ingeniería y Sistemas de\n \nTelecomunicación \n \nContributions to Case-Based\
    \ Reasoning \nEnabled Decision Support System for \nSmart Agriculture \n \nDoctoral\
    \ Thesis \n \nZhaoyu Zhai \nDoctorate in Systems and Services Engineering  \n\
    for the Information Society \n \nSupervisor: \nProf. Ph.D. José-Fernán Martínez\
    \ Ortega \n \n \n \n2020 \n \nii \n \n                                       \
    \       \n              \nDoctorado en Ingeniería de Sistemas y Servicios \npara\
    \ la Sociedad de la Información \nTesis Doctoral \nTítulo \nContributions to Case-Based\
    \ Reasoning Enabled \nDecision Support System for Smart Agriculture \nAutor \n\
    Zhaoyu Zhai \nTutor \nProf. José-Fernán Martínez Ortega \nVºBº \nPonente \n \n\
    Tribunal \nPresidente \nTomás Robles Valladares \nSecretario \nLourdes López Santidrian\
    \ \nVocal \nJuan Ramón Velasco Pérez \nVocal \nBaran Cürüklü \nVocal \nCarlos\
    \ García Rubio \nSuplente \nLuigi Glielmo \nSuplente \nMaría Victoria Beltrán\
    \ Martínez \n \nFecha de lectura \nE.T.S.I. y Sistemas de Telecomunicación (U.P.M.)\
    \ \nCalificación \n \n     El Presidente              El secretario          \
    \    Los vocales                      \n \nTesis Doctoral para obtención del título\
    \ de Doctor  \npor la Universidad Politécnica de Madrid \n2020 \niii \n \nTo my\
    \ beloved family. \n \n \n \n \n \n \n \ni \n \nAcknowledgements \n \n \n \nAt\
    \ this moment, I would like to express my gratitude to many people. Without the\
    \ help, care, \nand support from them, this thesis would not been accomplished.\
    \ The four-year Ph.D. study is \none of the best journeys in my life. It is a\
    \ great honor for me to work with the lovely people in the \n‘Next Generation\
    \ Networks and Services’ research group at Universidad Politécnica de Madrid.\
    \ \nFirst and foremost, I would like to sincerely thank Prof. José-Fernán Martínez\
    \ Ortega. As \nmy Ph.D. supervisor, Prof. José-Fernán not only provided me with\
    \ useful suggestions on the \nresearch, but also offered me the chance of participating\
    \ in international research projects. Under \nhis support, I was able to complete\
    \ several scientific papers. His professional knowledge, wisdom, \nrigor, and\
    \ extraordinary supervision inspired me a lot during my Ph.D. period. Prof. José-Fernán\
    \ \nis more than a professor and tutor, but a good friend as well. Overall, He\
    \ turned me from a fresh \ngraduate student to a good researcher. \nSecondly,\
    \ I would also like to thank all the professors and colleagues in the research\
    \ group. \nI will remember all the enjoyable moments and discussions with you.\
    \ \nLast but not the least, I would like to thank my family for their selfless\
    \ love and support to \nme, both financially and emotionally. Although we are\
    \ in different countries and have a six-hour \ntime difference, my family always\
    \ comforted me whenever I felt desperate. Without my family, \nI will be unable\
    \ to finish my Ph.D. study in Spain and I will not become who I am today! \n \n\
    \ \n \n \nii \n \nAbstract \n \n    Nowadays, high demands for food from the world-wide\
    \ growing population are impacting \nthe environment and putting many pressures\
    \ on agricultural productivity. As a farming \nmanagement concept, smart agriculture\
    \ tries to integrate advanced technologies like Internet of \nThings, Artificial\
    \ Intelligence, and Remote Sensing into current farming practices for the purpose\
    \ \nof boosting productivity and improving the quality of agricultural products.\
    \ The core of smart \nagriculture emphasizes on the use of information systems\
    \ and communication technologies in the \ncyber-physical farm management cycle.\
    \ However, farmers can hardly take advantage of collected \ninformation to make\
    \ proper decisions because it is difficult to transfer the explosive amount of\
    \ \nraw data from sensors, actuators, and networks into practical knowledge for\
    \ managing farming \noperations. Therefore, delivering an agricultural decision\
    \ support system to farmers to assist them \nin making evidence-based decisions\
    \ is needed. \nThe ultimate objective of this thesis is to design and implement\
    \ a decision support system \nwithin the Aggregate Farming in the Cloud (AFarCloud)\
    \ platform. Meanwhile, the proposed \ndecision support system tries to overcome\
    \ the current challenging problems in this topic. To \nachieve this objective,\
    \ this thesis follows the below three research areas. \nThe first area aims at\
    \ providing a general solution for delivering an agricultural decision \nsupport\
    \ system for the AFarCloud platform. An architectural proposal of the decision\
    \ support \nsystem framework for managing farming operations is presented in this\
    \ thesis. The proposed \nframework defines an algorithm manager and an algorithm\
    \ toolbox. The former component is \nresponsible to configure registered decision\
    \ support algorithms, while the latter component is \ncapable of selecting a certain\
    \ algorithm to generate decision supports. The proposed framework \ndemonstrates\
    \ how smart agriculture can benefit from the support of a decision support system,\
    \ \nand therefore assist farmers in making evidence-based decisions. \nThe second\
    \ area focuses on designing a case-based reasoning (CBR) algorithm to generate\
    \ \ndecision supports for farmers. This CBR algorithm is implemented within the\
    \ framework \nproposed in the first research area, in particular, within the algorithm\
    \ toolbox component. \nAccording to the nature of the CBR algorithm, it can be\
    \ divided into five steps, including \nrepresentation, retrieval, reuse, revision,\
    \ and retention. In this thesis, an improved CBR algorithm \nis proposed to overcome\
    \ the detected shortcomings of the current research work. Firstly, an \nassociated\
    \ case representation formalism is presented for enhancing the typical feature\
    \ vector \nrepresentation. The proposed representation formalism contains the\
    \ similar and dissimilar \niii \n \nassociations between past cases, enabling\
    \ to compare potential similar cases preferentially. \nSecondly, a triangular\
    \ similarity measure is designed by taking advantage of cosine and Euclidean \n\
    distance measures. For providing a precise measurement, the magnitude differences\
    \ between two \ncompared N-dimensional vectors are taken into consideration. Thirdly,\
    \ a fast case retrieval \nalgorithm is developed, enabling to determine a list\
    \ of similar past cases by comparing a fewer \nnumber of cases. As a consequence,\
    \ the retrieval efficiency is improved while the retrieval \naccuracy can be guaranteed\
    \ as well. Fourthly, a learning-based approach for solution reuse and \nrevision\
    \ is studied. This reuse and revision approach tries to identify the difference\
    \ between the \nproblem part of compared cases, and then update the retrieved\
    \ solution based on previous \nexperiences. Lastly, an associated case retention\
    \ approach is put forward. Apart from the typical \naddition and deletion strategies,\
    \ the proposed retention approach also concerns to update the \nexisted associations\
    \ and generate new associations for the learned cases. By enhancing each step\
    \ \nof the CBR loop, the proposed CBR algorithm is able to generate promising\
    \ decision supports \nwith great efficiency and accuracy. \nThe third area considers\
    \ a hybrid decision support mechanism for the AFarCloud platform. \nIt is noted\
    \ that though the improved CBR algorithm can generate a satisfied result for the\
    \ most \nqueries, it may be unable to generate the decision supports when the\
    \ CBR algorithm fails to \nretrieve a list of similar past cases. Under this circumstance,\
    \ the decision support system should \nstart other registered algorithms to carry\
    \ on the task. Therefore, for coordinating the interaction \nbetween various decision\
    \ support algorithms, a mediator design pattern is adopted in this hybrid \ndecision\
    \ support mechanism. Owing to the design of the mediator component, different\
    \ decision \nsupport algorithms do no need to interact with each other directly.\
    \ Instead, the communication \nwork between the algorithm manager and decision\
    \ support algorithms is handled by this mediator \ncomponent. This hybrid decision\
    \ support mechanism is verified through a preliminary proof, \nconsidering the\
    \ CBR algorithm and an artificial neural network algorithm. The result suggests\
    \ \nthat the hybrid decision support mechanism can enhance the robustness of the\
    \ overall decision \nsupport system. \nLastly, the proposed decision support system,\
    \ along with the improved CBR algorithm, are \nall verified by simulation. The\
    \ simulation results demonstrate that the proposal in this thesis is \neffective\
    \ and achieves better performance than previous works. \n \nKeywords: Smart agriculture,\
    \ decision support system, decision-making, artificial \nintelligence, case-based\
    \ reasoning. \niv \n \nResumen \n \n \n    Hoy en día, la alta demanda de alimentos\
    \ a consecuencia del crecimiento de la población \nmundial está afectando al medio\
    \ ambiente y ejerciendo muchas presiones sobre la producción \nagrícola. La agricultura\
    \ inteligente, entendida como un concepto de la gestión agrícola, intenta la \n\
    integración de tecnologías avanzadas, tales como Internet de las cosas, la inteligencia\
    \ artificial y \nla teledetección, en las prácticas agrícolas actuales, con el\
    \ fin de aumentar la productividad y \nmejorar la calidad de los productos agrícolas.\
    \ El núcleo de la agricultura inteligente hace hincapié \nen el uso de los sistemas\
    \ de información y las tecnologías de comunicaciones en el ciclo de gestión \n\
    de la granja ciberfísica. Sin embargo es difícil que los granjeros puedan aprovechar\
    \ la información \nrecopilada para tomar las decisiones adecuadas. La explosiva\
    \ cantidad de datos procedentes de \nlos sensores, actuadores y redes cuesta transformarla\
    \ en un conocimiento práctico que resulte útil \npara la administración de las\
    \ operaciones agrícolas. Por lo tanto, es necesario proporcionar a los \nagricultores\
    \ un sistema de apoyo a las decisiones agrícolas que les ayude a tomar decisiones\
    \ \nbasadas en la evidencia. \n \nEl objetivo final de esta tesis es diseñar e\
    \ implementar un sistema de soporte a decisiones \ndentro de la plataforma Aggregate\
    \ Farming in the Cloud (AFarCloud). En particular, el sistema \nde apoyo a decisiones\
    \ propuesto trata de superar los desafíos actuales en este tema. Para lograr \n\
    este objetivo, esta tesis sigue las siguientes tres áreas de investigación. \n\
    \ \nLa primera área tiene como objetivo proporcionar una solución general para\
    \ entregar un \nsistema de soporte a decisiones agrícolas para la plataforma AFarCloud.\
    \ En esta tesis se presenta \nla propuesta de un marco de referencia para la arquitectura\
    \ de un sistema de soporte a decisiones \npara la administración de las operaciones\
    \ agrícolas. Este marco define dos componentes: un \nadministrador de algoritmos,\
    \ y un grupo de herramientas de algoritmos. El primero es responsable \nde configurar\
    \ los algoritmos de soporte a decisiones que estén registrados, mientras que el\
    \ \nsegundo es capaz de seleccionar un cierto algoritmo de entre los registrados\
    \ para generar soportes \na decisiones. El marco propuesto demuestra cómo la agricultura\
    \ inteligente puede beneficiarse \ndel apoyo de un sistema de soporte a decisiones,\
    \ y por lo tanto, cómo ayuda a los agricultores a \ntomar decisiones basadas en\
    \ la evidencia. \n \nLa segunda área se centra en el diseño de un algoritmo de\
    \ razonamiento basado en casos \n(CBR) para generar soporte a decisiones para\
    \ los agricultores. Este algoritmo CBR se implementa \ndentro del marco propuesto\
    \ en la primera área de investigación, en particular, en el grupo de \nherramientas\
    \ de algoritmos. De acuerdo a su naturaleza el algoritmo CBR se puede dividir\
    \ en \nv \n \ncinco pasos, que incluyen: representación, recuperación, reutilización,\
    \ revisión y retención. En \nesta tesis, se propone un algoritmo CBR mejorado\
    \ para superar las deficiencias detectadas en el \ntrabajo de investigación. En\
    \ primer lugar, se presenta la representación formal de los casos \nasociados\
    \ para mejorar la representación típica del vector de características. La representación\
    \ \nformal propuesta contiene las asociaciones de similitud y diferencias entre\
    \ casos pasados, \npermitiendo comparar preferentemente los casos similares posibles.\
    \ En segundo lugar, se diseña \nuna medida de similitud triangular aprovechando\
    \ las medidas de distancia del coseno y euclidiana. \nPara proporcionar una medición\
    \ precisa se tienen en cuenta las diferencias al comparar la \nmagnitud entre\
    \ dos vectores N-dimensionales. En tercer lugar, se desarrolla un algoritmo de\
    \ \nrecuperación rápida de casos, que permite obtener una lista de casos pasados\
    \ similares \ncomparando un número menor de casos. En consecuencia, la eficiencia\
    \ de la recuperación mejora \na la vez que se garantiza su precisión. En cuarto\
    \ lugar se estudia un enfoque basado en el \naprendizaje para la reutilización\
    \ y revisión de soluciones. Este enfoque de reutilización y revisión \nintenta\
    \ identificar la diferencia entre la parte del problema de los casos comparados,\
    \ para \nposteriormente actualizar la solución recuperada en base a las experiencias\
    \ previas. Por último, \nse presenta un enfoque de retención del caso asociado.\
    \ Además de las estrategias típicas de \nadición y eliminación, el enfoque de\
    \ retención propuesto se refiere también a la actualización de \nlas asociaciones\
    \ existentes y a la generación nuevas asociaciones para los casos aprendidos.\
    \ Al \nmejorar cada uno de los pasos del ciclo CBR, el algoritmo CBR propuesto\
    \ puede generar soportes \nprometedores para la toma de decisiones, y además hacerlo\
    \ con gran eficiencia y precisión. \n \nLa tercera área considera un mecanismo\
    \ híbrido de soporte a decisiones para la \nplataforma AFarCloud. Se observa que,\
    \ aunque el algoritmo CBR mejorado puede \ngenerar resultados satisfactorios durante\
    \ la mayor parte del tiempo, es posible que no \npueda generar soportes a decisión\
    \ cuando el algoritmo CBR no pueda recuperar una lista \nde casos pasados similares.\
    \ Bajo esta circunstancia, el sistema de soporte a decisiones \ndebe iniciar otros\
    \ algoritmos registrados para llevar a cabo la tarea. Por lo tanto, para \ncoordinar\
    \ la interacción entre varios algoritmos de soporte a decisiones, se adopta un\
    \ \npatrón de diseño tipo mediador en este mecanismo híbrido de soporte a decisiones.\
    \ \nGracias al diseño del componente mediador, los diferentes algoritmos de soporte\
    \ a \ndecisiones no necesitan interactuar entre sí directamente. En cambio, este\
    \ componente \nmediador maneja el trabajo de comunicación entre el administrador\
    \ de algoritmos y los \nalgoritmos de soporte a decisiones. Este mecanismo híbrido\
    \ de soporte a decisión se \nverifica a través de una prueba preliminar que utiliza\
    \ el algoritmo CBR y una red neuronal \nvi \n \nartificial. El resultado sugiere\
    \ que el mecanismo híbrido de soporte a decisiones puede \nmejorar la solidez\
    \ del sistema general. \n \nPor último, el sistema de soporte a decisiones propuesto,\
    \ junto con el algoritmo CBR \nmejorado, se verifican por simulación. Los resultados\
    \ de la simulación demuestran que la \npropuesta en esta tesis es efectiva y logra\
    \ un mejor rendimiento que los trabajos \nanteriores. \n \nPalabras clave: Agricultura\
    \ inteligente, sistema de soporte a la toma de decisiones, toma de \ndecisiones,\
    \ inteligencia artificial, razonamiento basado en casos.\nvii \n \nTable of contents\
    \ \nAcknowledgements .......................................................................................\
    \ i \nAbstract ........................................................................................................\
    \ ii \nResumen ......................................................................................................\
    \ iv \nList of Figures ..............................................................................................\
    \ x \nList of Tables .............................................................................................\
    \ xiv \n1 \nIntroduction .............................................................................................\
    \ 1 \n1.1. Decision support and its importance in smart agriculture .................................................................\
    \ 2 \n1.2. Research framework ..........................................................................................................................\
    \ 4 \n1.3. Problem statements and thesis objectives ..........................................................................................\
    \ 6 \n1.4. Research contributions and thesis structure .......................................................................................\
    \ 9 \n2 \nBackground and related work ...............................................................\
    \ 12 \n2.1. Evolution history of agriculture .......................................................................................................\
    \ 13 \n2.1.1. Agriculture 1.0 to 3.0 ................................................................................................\
    \ 13 \n2.1.2. Agriculture 4.0 ..........................................................................................................\
    \ 14 \n2.1.3. Summary of agricultural evolution............................................................................\
    \ 15 \n2.2. Review of existing decision support systems ..................................................................................\
    \ 16 \n2.2.1. Optimization-based DSSs .........................................................................................\
    \ 17 \n2.2.2. Reasoning-based DSSs ..............................................................................................\
    \ 20 \n2.2.3. Distinctions with expert systems ...............................................................................\
    \ 22 \n2.2.4. Summary of DSSs .....................................................................................................\
    \ 23 \n2.3. Review of the case-based reasoning approach ................................................................................\
    \ 25 \n2.3.1. Review of case representation ...................................................................................\
    \ 26 \n2.3.2. Review of case retrieval ............................................................................................\
    \ 34 \n2.3.3. Review of solution reuse and revision ......................................................................\
    \ 41 \n2.3.4. Review of case retention ...........................................................................................\
    \ 43 \n2.3.5. Summary of the case-based reasoning approach .......................................................\
    \ 44 \n3 \nThe framework of decision support systems for smart agriculture ......\
    \ 45 \n3.1. General architecture of the AFarCloud platform .............................................................................\
    \ 46 \n3.1.1. The semantic middleware in the AFarCloud platform ..............................................\
    \ 47 \n3.1.2. The hardware layer in the AFarCloud platform ........................................................\
    \ 48 \n3.1.3. The farm management system in the AFarCloud platform .......................................\
    \ 49 \nviii \n \n3.2. Specific domain DSS in the AFarCloud platform ...........................................................................\
    \ 51 \n3.3. Framework of the AFarCloud DSS .................................................................................................\
    \ 53 \n4 \nAn improved case-based reasoning approach for the decision support\
    \ \nsystem ..........................................................................................................\
    \ 55 \n4.1. An associated case representation method ......................................................................................\
    \ 56 \n4.1.1. Generation of the association table ...........................................................................\
    \ 56 \n4.1.2. Distinction between the association table and other techniques................................\
    \ 59 \n4.1.3. Content of agricultural cases .....................................................................................\
    \ 62 \n4.1.4. Structure of the proposed case representation method ..............................................\
    \ 68 \n4.2. A triangular similarity measure .......................................................................................................\
    \ 69 \n4.2.1. Formula of the triangular similarity measure ............................................................\
    \ 69 \n4.2.2. Coefficient design in the triangular similarity measure ............................................\
    \ 71 \n4.2.3. The triangular similarity measure in N-dimensional space .......................................\
    \ 73 \n4.2.4. Feature weighting in the triangular similarity measure .............................................\
    \ 74 \n4.3. A fast case retrieval algorithm .........................................................................................................\
    \ 77 \n4.3.1. A set of policies for the retrieval algorithm ..............................................................\
    \ 77 \n4.3.2. Design of the case retrieval algorithm .......................................................................\
    \ 79 \n4.4. A learning-based approach for solution reuse and revision .............................................................\
    \ 82 \n4.4.1. Overview of the revision strategy .............................................................................\
    \ 83 \n4.4.2. Design of the learning component.............................................................................\
    \ 84 \n4.4.3. Adaptation actions: A case study ..............................................................................\
    \ 87 \n4.5. An associated case retention approach ............................................................................................\
    \ 93 \n4.5.1. Storing the learned case .............................................................................................\
    \ 93 \n4.5.2. Updating the existing association ..............................................................................\
    \ 95 \n5 \nA hybrid decision support mechanism..................................................\
    \ 97 \n5.1. A mediator approach for the hybrid decision support system .........................................................\
    \ 98 \n5.1.1. Problem statement in the mediator design pattern ....................................................\
    \ 98 \n5.1.2. Solution of the mediator approach ..........................................................................\
    \ 100 \n5.1.3. Design of the hybrid decision support system with the mediator\
    \ approach ............ 105 \n5.2. A preliminary proof of the hybrid concept ....................................................................................\
    \ 111 \n5.2.1. Result of the CBR algorithm ...................................................................................\
    \ 112 \n5.2.2. Result of the ANN algorithm ..................................................................................\
    \ 115 \n5.2.3. Result of the hybrid concept ....................................................................................\
    \ 115 \n6 \nImplementation and validation ...........................................................\
    \ 120 \nix \n \n6.1. Implementation scope and purpose ...............................................................................................\
    \ 121 \n6.2. The implementation details ...........................................................................................................\
    \ 121 \n6.2.1. Implementation of the associated representation formalism ...................................\
    \ 122 \n6.2.2. Implementation of the triangular similarity measure ..............................................\
    \ 126 \n6.2.3. Implementation of the fast case retrieval algorithm ................................................\
    \ 127 \n6.2.4. Implementation of the learning-based reuse and revision .......................................\
    \ 130 \n6.2.5. Implementation of the associated case retention approach .....................................\
    \ 131 \n6.3. The validation results ....................................................................................................................\
    \ 133 \n6.3.1. Result of the associated case representation ............................................................\
    \ 134 \n6.3.2. Result of the triangular similarity measure .............................................................\
    \ 139 \n6.3.3. Result of the fast case retrieval algorithm ...............................................................\
    \ 144 \n6.3.4. Result of the learning-based solution reuse and revision ........................................\
    \ 148 \n6.3.5. Result of the associated case retention ....................................................................\
    \ 155 \n7 \nConclusion and future work ................................................................\
    \ 160 \n7.1. Conclusion .....................................................................................................................................\
    \ 161 \n7.2. Future work ...................................................................................................................................\
    \ 163 \n7.3. Publications and projects ...............................................................................................................\
    \ 165 \n7.3.1. List of publications ..................................................................................................\
    \ 165 \n7.3.2. Research projects .....................................................................................................\
    \ 167 \nAppendix A ..........................................................................................................................................\
    \ 167 \nAppendix B ..........................................................................................................................................\
    \ 170 \nAppendix C ..........................................................................................................................................\
    \ 173 \nAppendix D ..........................................................................................................................................\
    \ 177 \nReferences ............................................................................................................................................\
    \ 179 \n \n \n \n \n \n \nx \n \nList of Figures \nFigure 1. Critical issues for\
    \ employing DSSs in smart agriculture ...............................................\
    \ 4 \nFigure 2. Overall view of the AFarCloud platform .......................................................................\
    \ 6 \nFigure 3. The evolution history of agriculture ............................................................................\
    \ 14 \nFigure 4. A general framework of decision support systems ......................................................\
    \ 16 \nFigure 5. A general framework of expert systems ......................................................................\
    \ 21 \nFigure 6. A generic workflow of case-based reasoning ..............................................................\
    \ 25 \nFigure 7. An example of the feature vector representation .........................................................\
    \ 26 \nFigure 8. An example of the textual representation ....................................................................\
    \ 27 \nFigure 9. An example of the frame-based representation ...........................................................\
    \ 29 \nFigure 10. An example of the object-oriented representation .....................................................\
    \ 30 \nFigure 11. An example of the ontology representation ...............................................................\
    \ 32 \nFigure 12. An extreme circumstance when measuring with the cosine similarity\
    \ ...................... 37 \nFigure 13. An extreme circumstance when measuring\
    \ with the distance-based similarity ......... 38 \nFigure 14. The architecture\
    \ of the AFarCloud platform .............................................................\
    \ 45 \nFigure 15. The internal connection within the farm management system ..................................\
    \ 49 \nFigure 16. The framework of the decision support system .........................................................\
    \ 52 \nFigure 17. The visualization of six cases in the case base ..........................................................\
    \ 56 \nFigure 18. The association connection between past cases .........................................................\
    \ 57 \nFigure 19. Principles of general hashing and locality sensitive hashing\
    \ approaches .................. 59 \nFigure 20. Principles of the rough set theory\
    \ ..............................................................................\
    \ 59 \nFigure 21. Principles of the filtering technique ...........................................................................\
    \ 60 \nFigure 22. An example of querying the disease type by using dissimilar\
    \ associations ............... 61 \nFigure 23. Some latest sensor equipment ....................................................................................\
    \ 63 \nFigure 24. Examples of multispectral equipment ........................................................................\
    \ 65 \nFigure 25. Examples of wearable technology .............................................................................\
    \ 67 \nFigure 26. Structure of the associated case representation method .............................................\
    \ 68 \nFigure 27. Two vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\
    \n⃗⃗⃗⃗⃗  in three-dimensional space ............................................\
    \ 69 \nFigure 28. Two triangles formed by three vectors \U0001D442\U0001D434\n\
    ⃗⃗⃗⃗⃗ ,  \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ , and \U0001D442\U0001D436\n⃗⃗⃗⃗⃗  .......................................\
    \ 70 \nFigure 29. The coefficient triangle for vectors \U0001D442\U0001D434\n\
    ⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  .....................................................\
    \ 70 \nFigure 30. An example for demonstrating the use of coefficient in TSM ...................................\
    \ 72 \nFigure 31. The mathematical prove of the TSM formula ............................................................\
    \ 73 \nFigure 32. The workflow of adjusting the weights for the Iris plant dataset\
    \ ............................... 75 \nFigure 33. The result of adjusted weights\
    \ for the four features................................................... 76\
    \ \nxi \n \nFigure 34. The workflow of the proposed case retrieval algorithm ............................................\
    \ 79 \nFigure 35. The pseudo code of the proposed case retrieval algorithm ........................................\
    \ 79 \nFigure 36. An example of the proposed case retrieval algorithm................................................\
    \ 80 \nFigure 37. The travelling trajectory of the proposed retrieval algorithm\
    \ in the example ............ 81 \nFigure 38. The overview of the proposed revision\
    \ process in CBR ............................................ 82 \nFigure 39.\
    \ Identifying the difference between the new case \U0001D4411 and retrieved past\
    \ case \U0001D434\U0001D4371 .. 83 \nFigure 40. The workflow of the learning component\
    \ .................................................................. 85 \nFigure\
    \ 41. An example of a normal pest management case ........................................................\
    \ 87 \nFigure 42. An example of adaptation case ..................................................................................\
    \ 88 \nFigure 43. Feature weights for pest management cases ..............................................................\
    \ 89 \nFigure 44. Data visualization of features of the new case and adaptation\
    \ case ........................... 89 \nFigure 45. Data visualization of features\
    \ of the adaptation case and retrieved past cases .......... 90 \nFigure 46. An\
    \ example of the case base for demonstrating coverage and reachability ..............\
    \ 93 \nFigure 47. An example of updating the existing association ......................................................\
    \ 95 \nFigure 48. An example of tightly coupled objects ......................................................................\
    \ 98 \nFigure 49. Tightly coupled decision support algorithms .............................................................\
    \ 99 \nFigure 50. The solution of the mediator approach ....................................................................\
    \ 100 \nFigure 51. The Python code of implementing the abstract Mediator interface\
    \ ......................... 101 \nFigure 52. The Python code of implementing the\
    \ concrete Mediator interface ........................ 101 \nFigure 53. The Python\
    \ code of implementing the base component ..........................................\
    \ 102 \nFigure 54. The Python code of implementing the ordinary components ..................................\
    \ 102 \nFigure 55. The Python code of implementing the main function ..............................................\
    \ 103 \nFigure 56. The test result of the mediator implementation .......................................................\
    \ 103 \nFigure 57. The framework of a general hybrid decision support system ..................................\
    \ 104 \nFigure 58. The workflow of the hybrid decision support system for situation\
    \ (i) ..................... 105 \nFigure 59. The workflow of the hybrid decision\
    \ support system for situation (ii).................... 106 \nFigure 60. The workflow\
    \ of the hybrid decision support system for situation (iii) ..................\
    \ 107 \nFigure 61. The structure of the “Request-Response-Fault” message ........................................\
    \ 109 \nFigure 62. The framework of the hybrid decision support system combining\
    \ CBR and ANN 110 \nFigure 63. The new project in the myCBR workbench .............................................................\
    \ 112 \nFigure 64. The attribute defined in the myCBR workbench .....................................................\
    \ 112 \nFigure 65. The case base in the myCBR workbench ................................................................\
    \ 112 \nFigure 66. The configuration of the similarity measure in the myCBR workbench\
    \ ................. 113 \nFigure 67. The retrieval process in the myCBR workbench\
    \ ..................................................... 113 \nFigure 68. The software\
    \ interface of the ANN algorithm .........................................................\
    \ 114 \nFigure 69. The structure of the message implemented by Python ............................................\
    \ 115 \nxii \n \nFigure 70. The structure of the request, response, and fault\
    \ parts implemented by Python ...... 115 \nFigure 71. An example of sending the\
    \ message to the CBR algorithm .................................... 115 \nFigure\
    \ 72. An example of returning the failure message from the CBR algorithm ..................\
    \ 116 \nFigure 73. An example of sending the message to the ANN algorithm ....................................\
    \ 117 \nFigure 74. An example of returning the response from the ANN algorithm\
    \ ............................ 117 \nFigure 75. Implementation scope within the\
    \ decision support system ...................................... 120 \nFigure\
    \ 76. The Spyder development environment ....................................................................\
    \ 121 \nFigure 77. The associated case representation formalism implemented in\
    \ XML ..................... 122 \nFigure 78. The associated case representation\
    \ formalism implemented in CSV ...................... 122 \nFigure 79. The parse\
    \ function in the DOM interface ................................................................\
    \ 123 \nFigure 80. The function of writing XML elements in Python ...................................................\
    \ 123 \nFigure 81. The function of reading and wiring XML-based cases in Python\
    \ ........................... 123 \nFigure 82. The function of reading and writing\
    \ CSV-based cases in Python ........................... 124 \nFigure 83. The code\
    \ of constructing the association implemented in Python ...........................\
    \ 125 \nFigure 84. The code of calculating the Euclidean distance, the cosine\
    \ similarity, and the magnitude \nimplemented in Python .............................................................................................................\
    \ 126 \nFigure 85. The code of constructing the association implemented in Python\
    \ ........................... 126 \nFigure 86. The code of comparing the new case\
    \ and entry-point case implemented in Python 127 \nFigure 87. The code of assigning\
    \ tokens implemented in Python ............................................. 127\
    \ \nFigure 88. The code of selecting the past case for the next iteration implemented\
    \ in Python .. 127 \nFigure 89. The code of retrieving unused past cases implemented\
    \ in Python .......................... 128 \nFigure 90. The code of calculating\
    \ the difference between cases implemented in Python ....... 129 \nFigure 91.\
    \ The code of normalizing the dataset implemented in Python ..................................\
    \ 129 \nFigure 92. The code of revising the solution of the adaptation case implemented\
    \ in Python ... 130 \nFigure 93. The process of updating the existing associations\
    \ in CSV files .............................. 131 \nFigure 94. The code of generating\
    \ a data frame from a CSV file implemented in Python ....... 131 \nFigure 95.\
    \ The code of updating associations implemented in Python .....................................\
    \ 131 \nFigure 96. The code of returning the data frame to a new CSV file implemented\
    \ in Python ... 132 \nFigure 97. Data visualization of past cases 328, 2997, and\
    \ 2998 .............................................. 134 \nFigure 98. Data visualization\
    \ of past cases 19 and 1836 ...........................................................\
    \ 135 \nFigure 99. Data visualization of past cases 19 and 674 .............................................................\
    \ 135 \nFigure 100. Data visualization of past cases 1836 and 674 .......................................................\
    \ 136 \nFigure 101. Data visualization of past cases 984, 748, and 749 ................................................\
    \ 137 \nFigure 102. Data visualization the new case 57 and the past case 1165\
    \ ................................... 140 \nFigure 103. Data visualization of\
    \ past cases 57 and the past case 1239 ................................... 140\
    \ \nFigure 104. Data visualization of the new case 113 and the past case 221 ...............................\
    \ 141 \nxiii \n \nFigure 105. Data visualization of new case 113 and the past\
    \ case 2483 ................................... 141 \nFigure 106. The average\
    \ precision of retrieved top three similar and dissimilar past cases ..... 144\
    \ \nFigure 107. Data visualization of new case 7 and the past case 52 ...........................................\
    \ 145 \nFigure 108. Data visualization of new case 7 and the past case 267 .........................................\
    \ 145 \nFigure 109. Data visualization of new case 7 and the past case 646 .........................................\
    \ 146 \nFigure 110. The best and worst revision result of prescription values\
    \ ...................................... 150 \nFigure 111. The best and worst\
    \ revision result of dilution factors ............................................\
    \ 150 \nFigure 112. Data visualization of the new case 1 and the past case 148\
    \ ................................... 151 \nFigure 113. Data visualization of\
    \ past cases 148 and 115 .........................................................\
    \ 152 \nFigure 114. Data visualization of past cases 148 and 689 .........................................................\
    \ 152 \nFigure 115. Data visualization of past cases 148 and 1570 .......................................................\
    \ 153 \nFigure 116. Times of updates in the association of past cases ..................................................\
    \ 156 \nFigure 117. Data visualization of the new case 1 and the past case 158\
    \ ................................... 157 \nFigure 118. Data visualization of\
    \ the new case 4 and the past case 2210 ................................. 158\
    \ \nFigure 119. Data visualization of the Iris plant dataset .............................................................\
    \ 168 \nFigure 120. An example of accessing the Iris plant dataset ......................................................\
    \ 168 \nFigure 121. The one-way message exchange pattern ................................................................\
    \ 172 \nFigure 122. The topological structure of a BP neural network .................................................\
    \ 173 \nFigure 123. The flow chart of the variable spray system ..........................................................\
    \ 175 \n \n \n \n \nxiv \n \nList of Tables \nTable 1. Comparison for distinguishing\
    \ DSSs with ESs .............................................................\
    \ 22 \nTable 2. Characteristics of three revision methods .....................................................................\
    \ 41 \nTable 3. An example of a case base ............................................................................................\
    \ 55 \nTable 4. The association table for the case base ..........................................................................\
    \ 56 \nTable 5. Key features of environmental variables in agricultural cases\
    \ ...................................... 62 \nTable 6. Key features of crop/planting\
    \ variables in agricultural cases ........................................ 64\
    \ \nTable 7. Key features of livestock variables in agricultural cases ..............................................\
    \ 65 \nTable 8. Correspondences between the similarity level and measurements\
    \ ............................... 77 \nTable 9. An example of problem differences\
    \ between the new case and adaptation case \n(Scenario 1) .................................................................................................................................\
    \ 84 \nTable 10. An example of problem differences between past cases (Scenario\
    \ 1) ........................ 84 \nTable 11. An example of problem differences\
    \ between the new case and adaptation case \n(Scenario 2) .................................................................................................................................\
    \ 84 \nTable 12. An example of problem differences between past cases (Scenario\
    \ 2) ........................ 84 \nTable 13. Similarity measurements and difference\
    \ values of retrieved past cases ...................... 90 \nTable 14. Solutions\
    \ of the adaptation case and retrieved past cases ...........................................\
    \ 90 \nTable 15. Analysis of the pest quantity and spray volume ..........................................................\
    \ 91 \nTable 16. Comparison of the revised solution and original one ..................................................\
    \ 91 \nTable 17. The statistical properties of the sample data .............................................................\
    \ 111 \nTable 18. Part of the similar association ...................................................................................\
    \ 133 \nTable 19. Part of the dissimilar association ...............................................................................\
    \ 133 \nTable 20. Statistical analysis of past cases 19, 1836, and 674 ..................................................\
    \ 136 \nTable 21. Statistical analysis of past cases 984, 748, and 749 ..................................................\
    \ 129 \nTable 22. Different past cases retrieved by TSM and the ED ...................................................\
    \ 138 \nTable 23. Statistical analysis of past cases 1165 and 1239 .......................................................\
    \ 140 \nTable 24. Statistical analysis of past cases 221 and 2483 .........................................................\
    \ 142 \nTable 25. Statistical analysis of 56 tests ....................................................................................\
    \ 142 \nTable 26. The average precision of the TSM and the ED .........................................................\
    \ 143 \nTable 27. Statistical analysis of the new case 7 and retrieved top three\
    \ similar past cases ....... 146 \nTable 28. The number of compared cases for\
    \ 1.5 million tests ................................................. 147 \nTable\
    \ 29. Comparison of revised and original pesticide types ..................................................\
    \ 148 \nTable 30. Comparison of revised and original prescription values ...........................................\
    \ 148 \nTable 31. Comparison of revised and original dilution factors .................................................\
    \ 149 \nxv \n \nTable 32. Statistical analysis of the new case 1 and the past\
    \ case 148 ...................................... 151 \nTable 33. Statistical\
    \ analysis of the past cases 148, 115, 689, and 1570 ..................................\
    \ 152 \nTable 34. The result of captured difference in the problem part of compared\
    \ cases ................. 153 \nTable 35. The values of prescription and dilution\
    \ factor in past cases 148, 115, 689, and 1570\n ...................................................................................................................................................\
    \ 154 \nTable 36. The result of revising the solution for adapting to the new\
    \ case ............................... 154 \nTable 37. List of unretained cases\
    \ .............................................................................................\
    \ 155 \nTable 38. Part of the similar association of newly retained cases .............................................\
    \ 156 \nTable 39. Part of the dissimilar association of newly retained cases ........................................\
    \ 157 \nTable 40. Characteristics of the Iris plant dataset .....................................................................\
    \ 166 \nTable 41. User guide for the Iris plant dataset ..........................................................................\
    \ 166 \nTable 42. Responses when the Oracle Mediator adopts the one-way interaction\
    \ ..................... 171 \nTable 43. The pseudo code of the BP neural network\
    \ ............................................................... 174 \n1 \n \n\
    1 Introduction\n2 \n \n    At first, this chapter presents the importance of decision\
    \ support in the agriculture domain \nby referring to several successful examples\
    \ like the Watson Decision Platform for agriculture. \nThe research framework\
    \ is briefly introduced and the problems of applying decision support \nsystems\
    \ to smart agriculture are claimed. For overcoming the detected challenges, the\
    \ objective \nof this thesis is summarized. Lastly, the structure of this thesis\
    \ is listed. \n1.1. Decision support and its importance in smart agriculture \n\
    According to the latest statistics from the United Nations Population Division\
    \ [1], there are \nmore human lives on Earth right now than ever before, reaching\
    \ 7.7 billion, and the number is \nstill growing rapidly. Based on the prediction\
    \ in 2015, the population is expected to reach up to \n9.7 billion by 2050 [2].\
    \ A population of this magnitude puts forward a lot of challenges like how \n\
    to increase food productivity, to maintain food quality, to ensure food security,\
    \ to avoid food \nwaste, and so on. In spite of progress made over the last two\
    \ decades worldwide, there are still \nmore than 870 million people suffering\
    \ from chronic hunger, 171 million under 5 years old are \nchronically malnourished,\
    \ 104 million are underweight, and 55 million are acutely malnourished \n[3].\
    \ \nMeanwhile, natural resources available for agriculture has been incredibly\
    \ stressed nowadays. \nOn the one hand, unused farmlands for cultivation are rare\
    \ and 25% of farmlands are marked as \nhighly degraded due to deforestation, overcutting\
    \ vegetation, inadequate fallow periods, \novergrazing, improper crop rotation,\
    \ unbalanced fertilization, etc. At the same time, near 44% of \nfarmlands are\
    \ rated as slightly degraded. It is a common sense that fewer farmlands may lead\
    \ to \nlower agricultural productivity [4]. On the other hand, water resources\
    \ are overused in an \nunreasonable way [5]. Some approaches like precise dripping\
    \ and irrigation are not widely \nadopted. Frequent water transfers from rivers\
    \ and lakes have caused critical environmental issues \nlike cutting off the rivers\
    \ and drying up the lakes. \nBoosting the agricultural productivity and allocating\
    \ natural resources under a reasonable \nmanner is not an easy task, but engineers\
    \ and farmers are working together on creating a \ntechnological solution: smart\
    \ agriculture. \nAs a farming management concept, smart agriculture [6-8] integrates\
    \ advanced technologies \ninto existing farming practices for the purpose of improving\
    \ work efficiency and the quality of \nagricultural products. In particular, smart\
    \ agriculture emphasizes the use of information systems \nand communication technologies\
    \ in the cyber-physical farm management cycle. Smart agriculture \nis also beneficial\
    \ for farmers to get rid of heavy labor and resolving repeated tasks. In the 21st\
    \ \ncentury, owing to the deployment of sensors, actuators, and networks, farmers\
    \ have access to a \n3 \n \nvariety of source data, which can be mainly categorized\
    \ into three groups: environmental, crop-\nrelated, and economic data [9]. It\
    \ is worth noting that data from all aspects are collected and \ngathered. Under\
    \ this circumstance, stakeholders may encounter difficulties in transferring this\
    \ \nexplosive amount of data into practical knowledge for managing farming operations.\
    \ As a \nconsequence, platforms like decision support systems (DSSs) are needed\
    \ in order to assist \nstakeholders in making evidence-based and proper decisions.\
    \ \n \nSome successful examples have illustrated how smart agriculture can benefit\
    \ from DSSs and \nwhy decision supports are important for managing farming operations.\
    \ For instance, the Watson \nDecision Platform for Agriculture was released by\
    \ the IBM Watson and Weather Company [10]. \nThis decision platform integrated\
    \ IBM’s advanced capabilities in Artificial Intelligence, Internet \nof Things,\
    \ and Cloud Computing into agriculture. On the one hand, this platform provides\
    \ a suite \nof solutions that spans the farm-to-fork ecosystem and it is able\
    \ to analyze any factors which have \npotential effects on the crops. Farmers\
    \ can obtain crop pictures by deploying unmanned aerial \nvehicles. Then, these\
    \ pictures are uploaded to the IBM Cloud for further analyses based on \ncomputer\
    \ vision algorithms. The analytic results keep farmers updated with health conditions\
    \ of \ncrops. As a consequence, working efficiency and accuracy of detecting crop\
    \ diseases can be \ngreatly improved. On the other hand, owners of large-scale\
    \ farms can use this platform to estimate \nthe price trending in trading markets.\
    \ Under this circumstance, the time for irrigation, pollination, \nphenology,\
    \ fertilization, harvesting, and reselling can be precisely controlled in order\
    \ to obtain \nthe maximum profits. It is worth mentioning that the Watson Decision\
    \ Platform for Agriculture \nconcerns various input sources, such as meteorological\
    \ data (provided by the Weather Company), \nsoil data (moisture at multiple depths,\
    \ nutrient content, fertility, and soil type), equipment data \n(gathered from\
    \ sensors onboard), workflow data (planting and harvesting dates, fertilizer and\
    \ \npesticide application rates, and harvesting outputs), and high definition\
    \ visual images (collected \nby satellites, drones, and fixed-wing aircrafts).\
    \ IBM is not the only company who contributed to \nsmart agriculture, another\
    \ company named Prospera [11] took advantage of techniques like \nComputer Vision,\
    \ Artificial Intelligence, and Cloud Computing for developing a digital farming\
    \ \nsystem that can help farmers to analyze data collected from their fields.\
    \ This digital farming \nsystem is capable of suggesting the most suitable time\
    \ for irrigation, fertilization, pollination, and \nharvesting by monitoring the\
    \ growth rates of crops. Farmers can also be notified when crops are \ninfected\
    \ by any diseases. According to the statistics from Prospera, yield production\
    \ was \nestimated with 95% accuracy and agricultural productivity was increased\
    \ by at least 30%. Though \nthis system only concerned scenarios in the facility\
    \ environment and large-scale rows for now, it \nstill shows its potential in\
    \ smart agriculture and further functionalities of this system are expected \n\
    in the near future for providing farmers with adequate suites of solutions. Furthermore,\
    \ Bazzani \n[12] developed DSIRR, a decision support system for irrigation. DSIRR\
    \ was more than a \n4 \n \nnormative platform to generate the optimal irrigation\
    \ suggestions, but also a DSS for exploring \nthe trade-off among conflict objectives\
    \ and offering farmers compromising solutions. It \nconsidered four categories\
    \ of data sources, including economic (farm income, profit, and gross \ndomestic\
    \ product), social (public support subsidy and farm employment), water (seasonality,\
    \ \nconsumption, marginal value, and irrigation technology), and environmental\
    \ indicators (soil \ncover, nitrogen, pesticide, and energy). On the basis of\
    \ these indicators, a linear model is used to \nassess the trade-off among economic-social-water-environmental\
    \ objectives. With a user-friendly \ngraphical interface, farmers can directly\
    \ control and monitor irrigation processes. \n \nOverall, judging from the above\
    \ successful examples, it is concluded that the decision \nsupport system indeed\
    \ plays a significant role in smart agriculture and it accelerates the \ndevelopment\
    \ paces of smart agriculture from various perspectives. \n1.2. Research framework\
    \ \nIn current literatures, though plenty of attempts have been made for addressing\
    \ how decision \nsupport systems can be employed in smart agriculture, this research\
    \ topic is still pending further \nexploration and discussion. It is acknowledged\
    \ that DSSs are helpful for smart agriculture, but \nthe unwelcome fact is that\
    \ the use of DSSs has been limited due to some critical issues presented \nin\
    \ Figure 1 [13]. \n \nFigure 1. Critical issues of employing DSSs in smart agriculture.\
    \ \n \nIn Figure 1, following issues have been pointed out by the research community.\
    \ \n• \nFarmers seldom have experiences or knowledge of using DSSs. The typical\
    \ graphical \ninterface of DSSs is sometimes not user-friendly and it may be confusing\
    \ for farmers to \nperform desired operations. \n5 \n \n• \nDSS developers may\
    \ ignore the requirement analyses from the end users, leading to the fact \nthat\
    \ inputs and outputs of DSSs may not fit the farmers’ needs and decision-making\
    \ styles. \n• \nThe functionalities of current DSSs are limited and task-specific.\
    \ A DSS may only focus on \na single perspective. As a consequence, farmers have\
    \ to use several DSSs to manage all the \nagricultural activities. \n• \nWhen\
    \ generating the advice, current DSSs may miss some fundamental factors, such\
    \ as \nclimate change, soil spatial variability, crop disease, etc. The lack of\
    \ these considerations \nmay result in imprecise outputs from DSSs. \nUnder these\
    \ circumstances, a new European project, named Aggregate Farming in the Cloud\
    \ \n(AFarCloud) [14], was launched in 2018. This project aims at providing a distributed\
    \ solution for \nautonomous farming that allows the integration and cooperation\
    \ of agricultural cyber physical \nsystems (CPSs) in real-time for increasing\
    \ efficiency, productivity, animal health, food quality, \nand reducing farm labor\
    \ costs. This platform will be integrated with the farm management \nsoftware\
    \ and support monitoring and decision-making solutions based on big data and real-time\
    \ \ndata mining techniques. The overall view of the AFarCloud platform is presented\
    \ in Figure 2. \nThis platform is composed of the services and applications layer,\
    \ semantic middleware layer, \ncommunication layer, hardware layer, and information\
    \ models. In general, the semantic \nmiddleware is designed to abstract the heterogeneity\
    \ and complexity of the underlying hardware \nlayer for offering a collection\
    \ of homogeneous interfaces used by the application layer to access \nthe services.\
    \ Meanwhile, this middleware ensures that all data are stored in the information\
    \ model \nand provides a publish/subscribe architecture based on the data distribution\
    \ services (DDS). \nIn Figure 2, the decision support system is implemented within\
    \ the application layer. After \nbeing fed by the farm modeling utilities, the\
    \ DSS is able to perform reasoning and suggest the \nactions to be executed. Moreover,\
    \ the DSS has the capability of configuring personalized \ndashboards to monitor,\
    \ optimize, and control the farming operations. \n6 \n \n \nFigure 2. Overall\
    \ view of the AFarCloud platform. \nMotivated by one of the goals defined in the\
    \ AFarCloud project, this thesis tries to find a \nsolution for modeling the decision\
    \ support system for smart agriculture. The DSS will be designed \nto provide\
    \ thoughtful decision supports during several interrelated stages of the missions,\
    \ i.e. (i) \npre-mission data analysis and reasoning; (ii) soft real-time data\
    \ analysis during a mission, and (iii) \npost-mission data analysis and reasoning.\
    \ On the basis of historical, current, and predicted data, \nthe end users are\
    \ able to plan and interpret ongoing processes to make appropriate and reasonable\
    \ \ndecisions, as well as analyze the outcome of a mission. Thus, along with adaptive\
    \ autonomy, \nintuitive interaction, and hierarchical planning, the DSS will support\
    \ users on the agricultural \nmanagement in an efficient and sustainable way.\
    \ \n1.3. Problem statements and thesis objectives \nDelivering a decision support\
    \ system for smart agriculture in the AFarCloud project is the \nultimate objective\
    \ of this thesis. However, this is a challenging task because of the problems\
    \ \nidentified as follow. \nProblem 1: Current decision support systems are usually\
    \ task specific, leading to the fact \nthat farmers have to adopt several DSSs\
    \ to manage farm operations. Meanwhile, few DSSs can \ncover the whole life cycle\
    \ of agriculture by providing farmers with adequate advice in short-term, \nmid-term,\
    \ and long-term decision-making activities [15]. Short-term planning should cover\
    \ the \ntactical day-to-day decision-making activities, such as assigning agricultural\
    \ tasks to the most \nappropriate machineries, generating the optimal travel paths\
    \ for each machinery, scheduling daily \n7 \n \nand weekly irrigation activities,\
    \ etc. Mid-term planning is supposed to offer seasonal decision \nsupports for\
    \ farmers. For instance, fertilization is typically performed by farmers according\
    \ to \ntheir own observations and experiences, usually resulting in imprecise\
    \ chemical usages and \ncausing serious damages to fields and crops. However,\
    \ with the help of mid-term planning, DSSs \ncan provide farmers with detailed\
    \ solutions about the perfect time to fertilize and the amount of \nchemical applications.\
    \ In regards to long-term planning, it usually refers to yearly decision \nsupports.\
    \ For example, agricultural machineries surely suffer from wear and gear. After\
    \ serving \nfor months, old and damaged components have to be replaced by new\
    \ ones. By monitoring the \nstatus of machineries, DSSs can notify farmers about\
    \ which machineries are non-operational \nanymore and what components should be\
    \ replaced. Unfortunately, current DSSs mainly focus on \nshort-term planning\
    \ and lack consideration on mid-term and long-term planning. Therefore, it is\
    \ \nurgent to integrate more functionalities of DSSs and enrich decision supports\
    \ throughout the \nwhole life cycle of agriculture. \nProblem 2: Uncertainty and\
    \ dynamic factors do exist in agriculture, but the fact is that few \nDSSs take\
    \ them into account. Generally, uncertainty and dynamic factors come from the\
    \ \nfollowing aspects. Firstly, meteorological conditions have a great influence\
    \ on crop growths. For \ninstance, rising temperature may shorten the growth circle\
    \ of crops. Consequently, fertilization, \nweeding, and harvesting periods should\
    \ change accordingly [16]. DSSs should take uncertainty \nand dynamic factors\
    \ of climate change into account for providing farmers with more accurate \ndecision\
    \ supports. Secondly, conditions of farmlands are dynamically changing as well,\
    \ especially \nsoil moisture and remaining nutrition in the fields [17]. A low\
    \ value of soil moisture requires \nfarmers to perform irrigation activities more\
    \ frequently, while a high volume of nutrition \nremaining in the fields requires\
    \ farmers to fertilize a fewer amount of manures. Monitoring \nenvironmental changes\
    \ is vital because decision supports are generated based on these dynamic \ndata.\
    \ Thirdly, farmers have to handle uncertainty and dynamic factors of economic\
    \ effects from \nthe market [18]. The price of an agricultural product may be\
    \ affected by several factors like total \nproduction, logistics, inventory in\
    \ local warehouses, consumers’ demands, etc. Any changes in a \nsingle factor\
    \ may lead to a chain reaction. In conclusion, it is suggested that DSSs should\
    \ pay \nattention to uncertainty and dynamic factors. \nProblem 3: Re-planning\
    \ in decision support systems is a challenging research topic. On the \none hand,\
    \ unexpected failures and issues may arise from time to time, such as mechanical\
    \ failures \nof an agricultural machinery and sudden changes in weather. These\
    \ failures and issues may lead \nto the impossibility of following the original\
    \ solutions to complete assigned missions [19]. \nTherefore, DSSs should have\
    \ the capability of adjusting current strategies or generating new ones \nfor\
    \ providing further decision supports for farmers to continue missions. On the\
    \ other hand, when \n8 \n \na mission is being executed, a DSS may detect a better\
    \ strategy for carrying on the rest of the \nmission [20]. Under this circumstance,\
    \ the DSS should inform farmers of the latest suggestions. \nBy adopting this\
    \ newly generated solution, farmers can complete the rest of the mission more\
    \ \nefficiently and smoothly. Conclusively, DSSs are supposed to have a re-planning\
    \ mechanism for \nupdating the decision supports. \nProblem 4: Some researchers\
    \ intend to develop DSSs that resolve complex problems \nautonomously without\
    \ any human interventions [21-23]. Unfortunately, current DSSs have not \nreached\
    \ such intelligent level yet. Due to the limitation of computation capability\
    \ and complexity \nof agricultural problems, DSSs may provide farmers with inaccurate\
    \ decision supports, \nsometimes even wrong suggestions. Therefore, agricultural\
    \ knowledge from experienced experts \nis expected for the purpose of validating\
    \ the feasibility of given strategies and correcting the \nmistakes in generated\
    \ solutions [24]. An interactive interface should be provided by DSSs, \nallowing\
    \ experts to express their knowledge and opinions. By checking generated solutions\
    \ before \nexecution, DSSs are able to lower the possibility of making mistakes.\
    \ \nProblem 5: Though predictions and forecasts are especially helpful for farmers\
    \ to get \nprepared in advance, few DSSs take this issue into consideration. Generally,\
    \ the following three \ntypes of predictions and forecasts are recommended. Firstly,\
    \ crop growths depend on multiple \nfactors like weather, soil, irrigation, and\
    \ fertilization. An early estimation on agricultural \nproduction is helpful for\
    \ farmers to detect whether certain operations should be performed to \nimprove\
    \ product quality [25]. Secondly, forecasts of climate change enable farmers to\
    \ adjust crop \nmanagement and avoid unnecessary climatic risks [26]. Lastly,\
    \ by detecting potential symptoms \nand early signs, DSSs are supposed to warn\
    \ farmers about possible occurrences of pests and crop \ndiseases for helping\
    \ them to take certain precautions and avoid further losses [27]. \nProblem 6:\
    \ Strategies of historical missions usually contain valuable information, including\
    \ \nnot only successful experience, but also failure cases. However, current DSSs\
    \ seldom analyze the \nhistorical information. A historical strategy is applicable\
    \ for its corresponding situation. It is \npromising to compare the real-time\
    \ data with historical ones to generate solutions for current \nmissions within\
    \ a shorter computation time by adopting intelligent algorithms like machine \n\
    learning, deep learning, bio-inspired algorithms [28]. Because similar patterns\
    \ between historical \nand new datasets may be recognized and matched. Successful\
    \ experiences in past cases can be \nused as references in performing current\
    \ agricultural activities. Meanwhile, DSSs can abandon \nuseless strategies by\
    \ judging from failures in past cases. Furthermore, by learning from historical\
    \ \ninformation, regular patterns can be drawn and used to predict future circumstances\
    \ [29]. In \n9 \n \nconclusion, the efficiency of decision-making and quality\
    \ of generated decision supports can be \nsignificantly improved by performing\
    \ analysis on the historical information. \nProblem 7: A DSS usually contains\
    \ a huge amount of information, some of which are \nclassified. Since decision-makers\
    \ uses this information as a basis when making decisions, the \ninformation sent\
    \ to the DSS should be reliable. Otherwise, it might have disastrous effects.\
    \ In \ngeneral, three categories of security issues should be considered when\
    \ delivering a DSS. First, the \nbasic threat is in regard to data loss, which\
    \ means that parts of the database can no longer be \nretrieved. This could blame\
    \ on the physical damage to the storage medium, human error, or \nhardware failures.\
    \ Second comes to the unauthorized access. Computer hackers may develop \nsophisticated\
    \ methods to obtain data from the databases and then use them for personal gain\
    \ or \nharm others. Third, security issues in a DSS should concern the attack\
    \ from viruses and other \nharmful programs. For tackling the above three security\
    \ issues, the use of firewall, encryption, \nand passwords are strongly recommended.\
    \ \nFor tackling the seven problems detected above, the following sub-goals are\
    \ defined in order \nto achieve the objective of this thesis step-by-step. \n\
    Sub-goal 1: Investigating and analyzing the requirements of smart agriculture.\
    \  \nSub-goal 2: Surveying the current state of the art of decision support systems\
    \ for smart \nagriculture. In particular, reviewing existing technologies and\
    \ selecting the appropriate ones for \nthis thesis. \nSub-goal 3: Reviewing the\
    \ selected technologies for identifying any shortcomings that this \nthesis can\
    \ supplement and any improvements that this thesis can contribute to. \nSub-goal\
    \ 4: Presenting a general framework of the decision support system for smart \n\
    agriculture and clarifying how the proposed decision support system serves within\
    \ the AFarCloud \nproject. \nSub-goal 5: Proposing a specific solution for designing\
    \ and implementing the decision \nsupport system based on the selected technology\
    \ with improvements. \nSub-goal 6: Implementing and validating the proposed decision\
    \ support system for smart \nagriculture within the AFarCloud project. \n1.4.\
    \ Research contributions and thesis structure \nThe contributions of this thesis\
    \ can be summarized as follows. \n10 \n \n• \nProposal of a decision support system\
    \ framework for smart agriculture. As a general solution, \nthis framework is\
    \ able to provide farmers with a complete set of decision supports for \nmanaging\
    \ farming operations. \n• \nWithin the proposed framework, a decision support\
    \ algorithm is designed by employing an \nimproved case-based reasoning approach.\
    \ \n• \nAn associated case representation formalism is presented for defining\
    \ agricultural cases. \nDiffering from the typical feature vector representation,\
    \ the proposed representation \nformalism pays attention to the interrelations\
    \ between cases. \n• \nA triangular similarity measure is proposed for providing\
    \ a more accurate retrieval result, \novercoming the shortcomings of typical approaches\
    \ like cosine and Euclidean distance \nmeasures. The proposed measure takes the\
    \ angles, magnitudes of compared vectors, their \nmagnitude difference, and feature\
    \ weights in each vector into account. \n• \nA fast case retrieval algorithm is\
    \ implemented by taking advantage of the proposed associated \ncase representation\
    \ formalism. Instead of traversing the whole case base for identifying the \n\
    most similar past case, this fast case retrieval algorithm compares associated\
    \ cases \npreferentially, leading to higher retrieval efficiency. \n• \nA learning-based\
    \ adaptation strategy is designed by taking advantage of hidden adaptation \n\
    knowledge in the case base, instead of relying on pre-set and refined rule sets.\
    \ \n• \nA new case retention approach is proposed. Apart from the typical addition\
    \ and deletion \nstrategies, the proposed retention approach also takes updating\
    \ the association of past cases \ninto account. \n• \nA hybrid decision support\
    \ mechanism is proposed to supplement the weakness of the case-\nbased reasoning\
    \ approach. A mediator component is integrated in this hybrid mechanism for \n\
    coordinating the communication between different decision support algorithms.\
    \ \nThe rest of this thesis is organized as follows. \nChapter 2: The background\
    \ of the study involved in this thesis is introduced, including the \nhistorical\
    \ evolution of agriculture. Meanwhile, the current state of decision support systems\
    \ and \nthe case-based reasoning approach is reviewed for detecting any potential\
    \ improvements. \nChapter 3: The framework of the decision support system for\
    \ smart agriculture is proposed \nin this chapter, providing an architectural\
    \ view of the system. The components involved within \nthe proposed framework\
    \ is described in detail. \nChapter 4: Contributions of this thesis towards the\
    \ case-based reasoning approach are \nexplained in this chapter. Firstly, the\
    \ associated case representation formalism is described. \n11 \n \nSecond comes\
    \ to the triangular similarity measure. Thirdly, the fast case retrieval algorithm\
    \ is \npresented, following by a learning-based adaptation strategy for solution\
    \ reuse and revision. \nLastly, an associated case retention approach is proposed\
    \ for completing the case-based reasoning \nloop. \nChapter 5: The hybrid decision\
    \ support mechanism is introduced in this chapter, as well as \na preliminary\
    \ analysis on this proposal proves its feasibility and effectiveness. \nChapter\
    \ 6: This chapter shows the detailed implementation of the decision support system,\
    \ \nincluding each step (retrieve, reuse, revise, and retain) within case-based\
    \ reasoning loop. The \nhybrid decision support mechanism is also validated through\
    \ experiments. \nChapter 7: The contributions of the thesis are highlighted in\
    \ this chapter. Meanwhile, future \nwork is discussed for further consideration.\
    \ \n12 \n \n2 Background and \nrelated work\n13 \n \nThis chapter presents the\
    \ background of the research. The evolution history of agriculture is \nanalyzed,\
    \ dating from Agriculture 1.0 to 4.0. Meanwhile, the state of the art of decision\
    \ support \nsystems is reviewed. The merits and demerits of both optimization-based\
    \ and reasoning-based \nsystems are compared. Based on the review result, the\
    \ case-based reasoning approach is selected \nfor modeling the decision support\
    \ system in this thesis, therefore, the current state of the case-\nbased reasoning\
    \ approach is surveyed for detecting any space of potential improvements. \n2.1.\
    \ Evolution history of agriculture \nHuman beings began to cultivate lands and\
    \ breed animals to obtain food for survival \nthousands of years ago. This practice,\
    \ known as agriculture, is the key development in the rise of \nsedentary human\
    \ civilization. Generally, agriculture has evolved following a long-term and \n\
    progressive process, going from Agriculture 1.0 to 4.0 [30]. \n2.1.1. Agriculture\
    \ 1.0 to 3.0 \nAgriculture 1.0 refers to the traditional agricultural era, dating\
    \ back to ancient times. It \nmainly relied on manpower and animal forces. In\
    \ this stage, though simple tools like sickles and \nshovels were used in agricultural\
    \ activities, humans still cannot get rid of heavy manual labors, \nso productivity\
    \ remained at a low level [31]. Until the 19th century, steam engines were improved\
    \ \nand widely used to provide new powers in all walks of life [32]. It came to\
    \ the era of Agriculture \n2.0 when various agricultural machineries were operated\
    \ by farmers manually and lots of \nchemicals were used. Obviously, Agriculture\
    \ 2.0 significantly increased efficiency and \nproductivity. Nevertheless, this\
    \ substantial improvement brought harmful consequences as well, \nsuch as field\
    \ chemical contamination, destruction of ecological environment, excessive \n\
    consumption of powers, and waste of natural resources. In the 20th century, Agriculture\
    \ 3.0 \nemerged from the rapid development of computers and electronics. Computer\
    \ programs and \nrobotic solutions allowed agricultural machineries to perform\
    \ farming operations efficiently [33]. \nBefore the problems left in Agriculture\
    \ 2.0 went too far, strategies were adjusted in Agriculture \n3.0. The reasonable\
    \ work distribution to agricultural machineries was able to reduce the use of\
    \ \nchemicals and improve the precision of farming operations. \nThough Agriculture\
    \ 2.0 relieved the burden of human labors and Agriculture 3.0 could assist \n\
    farmers in managing farming operations efficiently, further developments are still\
    \ expected in the \nera of Agriculture 4.0.  \n14 \n \n2.1.2. Agriculture 4.0\
    \ \nThe technological innovation is not new to agriculture. Various advances,\
    \ such as Internet \nof Things, Big Data, Artificial Intelligence, Cloud Computing,\
    \ and so on, have the potential to \nchange agriculture beyond recognition, and\
    \ hence shifting towards Agriculture 4.0 [34]. \nIn 2013, the German government\
    \ firstly proposed Industry 4.0, known as the fourth industrial \nevolution [35].\
    \ Two years later, Agriculture 4.0 was defined and quickly drew attention from\
    \ \nworldwide researchers [36]. Four main requirements were put forward and listed\
    \ as follows. \n• \nIncreasing productivity: The population growth and shortage\
    \ of food will consequently boost \nthe demand for agricultural production. Meanwhile,\
    \ people’s diet is changing as well, mainly \nreflected in demanding for high-value\
    \ animal protein and high-quality vegetables. \nFurthermore, with the development\
    \ of urbanization, various infrastructures and buildings \nwould take place of\
    \ farmlands [37]. \n• \nAllocating resources reasonably: Natural resources are\
    \ incredibly stressed nowadays. \nFirstly, unused farmlands for cultivation are\
    \ rare and 25% of farmlands are marked as highly \ndegraded due to deforestation,\
    \ overcutting vegetation, inadequate fallow periods, and so on \n[38]. Secondly,\
    \ water resources are overused in an unreasonable way [39]. Frequent water \n\
    transfers from rivers and lakes are causing serious environmental problems. Third\
    \ comes to \ninefficiency of the agricultural machinery deployment due to improper\
    \ work distributions. A \nlarge amount of energy resources is consequently wasted\
    \ [40]. \n• \nAdapting to climate change: Climate change has been greatly affecting\
    \ the farming \noperations. One of the main factors which leads to climate change\
    \ is manmade emissions of \ngreenhouse gases (GHGs). The side effects of climate\
    \ change result in frequent occurrences \nof droughts, floods, and extreme weather\
    \ conditions [41]. Additionally, agricultural \nproductions are especially vulnerable\
    \ and sensitive to the impacts of climate change [42]. \nLack of efforts in adapting\
    \ to climate change will cause an increase in uncertainty about food \nquality,\
    \ accessibility, and utilization. \n• \nAvoiding food waste: Food waste comes\
    \ from each stage of the agricultural life cycle, \nincluding producing, delivering,\
    \ marketing, etc. Firstly, due to the overuse of chemicals, lack \nof pest management,\
    \ and ignorance of climate change adaptation, agricultural products may \nbecome\
    \ contaminated and unqualified [43], leading to food waste and damage to farmlands.\
    \ \nSecondly, the world shares a globalized supply and marketing system [44].\
    \ However, food \ndelivery is time-sensitive, meaning that inappropriate decision-making\
    \ about delivery \nstrategies may cause food waste. Thirdly, wasted food is harmful\
    \ to the environment. Re-\n15 \n \ncycling and processing wasted food may even\
    \ consume more resources than producing new \nones [45]. \nFor tackling the above\
    \ requirements, some successful demonstrations haves illustrated how \nAgriculture\
    \ 4.0 can benefit from the technological applications. For instance, Ferrandez-Pastor\
    \ et \nal. [46] developed a low-cost sensor and actuator network platform by taking\
    \ advantage of \nInternet of Things. This platform aimed at optimizing production\
    \ efficiency, increasing food \nquality, minimizing environmental impacts, and\
    \ reducing the use resources like energy and water. \nDas and Jain [47] proposed\
    \ to use an analysis algorithm over the big dataset for identifying the \noptimum\
    \ growing technique for multiple cropping. In their research, they concluded that\
    \ the \ncombination of smart farming and the big data technique can generate the\
    \ most well-analyzed \nresults and the complex patterns which are not perceivable\
    \ to humans. These results and patterns \ncan provide the optimum use of farming\
    \ resources under the given constraints. Liakos et al. [48] \nexplored the current\
    \ state of machine learning techniques in agriculture. They drew a conclusion\
    \ \nthat the real-time artificial intelligence technique could enable computer\
    \ programs to generate \nadequate recommendations and insights for supporting\
    \ farmers to make proper decisions. Lopez-\nRiquelme et al. [49] presented a precision\
    \ agricultural application on the basis of FIWARE cloud. \nThis application was\
    \ able to reduce the amount of water for irrigation tasks. Thus, their work \n\
    demonstrated that using FIWARE cloud services in the agronomic context was highly\
    \ beneficial. \n2.1.3. Summary of agricultural evolution \nIn general, the evolution\
    \ history of agriculture can be summarized in Figure 3. \n \nFigure 3. The evolution\
    \ history of agriculture. \n16 \n \nAgriculture is undergoing a new revolution\
    \ supported by various smart technologies. In \nAgriculture 4.0, the key features\
    \ emphasize on the concept “smart”, in particular, smart systems \nand devices.\
    \ For instance, replacing human labor with smart robotics is a growing trend across\
    \ \nmultiple industries, and agriculture is no exception [50]. Autonomous vehicles\
    \ like unmanned \naerial vehicles (UAVs) and unmanned ground vehicles (UGVs) will\
    \ be deployed in the fields for \nperforming agricultural operations, including\
    \ seeding, planting, weeding, spraying, harvesting, \netc. On the basis of various\
    \ collected data, a swarm of smart robots is able to work together under \na cooperative\
    \ manner. Meanwhile, farmers are in the position of monitoring the working status\
    \ \nthrough portable devices like tablets and mobile phones. \nIt is worth noting\
    \ that smart systems and devices count on collected information for \nperforming\
    \ operations. In Agriculture 4.0, various data sources are gathered [51], such\
    \ as \nenvironmental data (i.e. meteorological condition and soil condition),\
    \ crop-related data (i.e. \ngrowth and disease), economic data (i.e. reselling\
    \ and logistics), and so on. Obviously, \ntransferring this explosive amount of\
    \ raw data into practical knowledge is a challenging task for \nfarmers. Therefore,\
    \ platforms like decision support systems and expert systems (ES) are needed \n\
    for assisting farmers in making evidence-based and precise decisions. \n2.2. Review\
    \ of existing decision support systems \nRegarding the definition of a DSS, many\
    \ researchers have described this term from various \nviewpoints. In 1980, Jones\
    \ [52] described this term “decision support system” as “a computer-\nbased support\
    \ system for decision makers who deal with semi-structured problems to improve\
    \ the \nquality of decisions”. Sheng and Zhang [53] defined it as “a human-computer\
    \ system which is \nable to collect, process, and provide information based on\
    \ computers”. Terribile et al. [54] \nexplained it as a smart system that provides\
    \ operational answers and supports decision-making \nactivities to specific demands\
    \ and problems based on collected data. Yazdani et al. [55] \nconsidered it as\
    \ “a specific class of computerized information system, enabling to manage \n\
    decision-making activities”. Fontana et al. [56] indicated that “a decision support\
    \ system was \nconceptually developed to support the decision makers to classify\
    \ the activities into core and non-\ncore competencies, and to establish their\
    \ outsourcing relationship”. Judging from the above \ndefinitions, it is concluded\
    \ that a decision support system in the context of agriculture is a human-\ncomputer\
    \ system which utilizes data from various sources, aiming at providing farmers\
    \ with a list \nof feasible advice for supporting their decision-making activities\
    \ under different circumstances. \nOne of the most representative characteristics\
    \ of a DSS is that it does not give direct instructions \nnor commands to farmers.\
    \ Because farmers are in the position of taking the final decisions. A \ngeneral\
    \ framework of a DSS is presented in Figure 4.  \n17 \n \n \nFigure 4. A general\
    \ framework of decision support systems. \n \nIn Figure 4, for solving the agricultural\
    \ problems, agricultural data should be collected in the \nfirst place, including\
    \ historical, current, and predicted data. When gathering these data, it is \n\
    necessary to consider the constraints of monitored objects like their availability,\
    \ coverage, \nresolution, accuracy, frequency, etc. Secondly, collected data are\
    \ treated as inputs to specific \nmodels like crop, irrigation, and production\
    \ estimation models. Additionally, the requirement of \ndata types and the necessity\
    \ of human interventions should be concerned. Thirdly, a set of advice \nfor tackling\
    \ agricultural problems is generated based on computational results. During the\
    \ \ncomputing process, external factors like social reactions, economic effects,\
    \ and environmental \nchanges should be taken into account. Finally, the generated\
    \ solutions are displayed to farmers \nfor supporting their final decisions. By\
    \ adopting these solutions, farmers are supposed to carry on \nfarming operations\
    \ with the minimum investment and the highest economic benefit. \nAccording to\
    \ the tools that DSSs adopt in Figure 4, DSSs can be mainly categorized into two\
    \ \ngroups, named optimization-based and reasoning-based DSSs. These two groups\
    \ of DSSs are \nreviewed in the following sub-sections. \n2.2.1. Optimization-based\
    \ DSSs \nAs a mathematical procedure, optimization is a collection of principles\
    \ and methods used to \nsolve quantitative problems [57]. The purpose of optimization\
    \ is to achieve the best design relative \nto a set of prioritized criteria or\
    \ constraints which include maximizing factors like productivity, \nefficiency,\
    \ profitability, etc. \n18 \n \nThis group of DSSs takes advantage of optimization\
    \ methods like gradient descent [58], \nstochastic gradient descent [59], gradient\
    \ ascent [60], Newton’s method [61], quasi-Newton \nmethod [62], conjugate gradient\
    \ [63], and heuristic optimization methods [64]. The research \ncommunity has\
    \ contributed to a lot towards optimization-based DSSs in the context of agriculture.\
    \ \nLenka and Mohapatra [65] proposed an optimization technique to train a neural\
    \ network \npattern classification algorithm by adopting gradient descent. Their\
    \ algorithm was tested for \npredicting soil moisture content one hour in advance.\
    \ Georgiou and Papamichail [66] tried to \nmaximize the total farm income by using\
    \ the simulated annealing global optimization stochastic \nsearch algorithm in\
    \ combination with the stochastic gradient descent algorithm. Their model was\
    \ \nproved to be applicable as a decision support tool for irrigation scheduling.\
    \ Manimuthu et al. [67] \npresented the application of Newton-Raphson algorithm\
    \ in combination with the pulse width \nmodulation bridge to characterize the\
    \ energy cost associated with locomotion gaits, providing \nrobots with the optimal\
    \ area coverage strategy for agriculture harvesting. Pornprakun et al. [68] \n\
    explored the optimal harvesting policies for sugarcane by using an epsilon-constraints\
    \ method \nand a quasi-Newton optimization method. The generated result was able\
    \ to assist farmers in \ndetermining the optimal harvesting time with the maximum\
    \ profits and the minimum harvesting \ncost. Goit et al. [69] optimized the control\
    \ of power extraction in a wind farm by employing a \nconjugate gradient method.\
    \ The experimental result demonstrated that the energy extraction was \nincreased\
    \ 7% by adopting the optimal control strategy. \nSome other DSSs adopted heuristic\
    \ optimization methods as the optimization tool. These \nmethods include simulated\
    \ annealing (SA), genetic algorithm (GA), ant colony optimization \n(ACO), and\
    \ particle swarm optimization (PSO). \nBrown et al. [70] proposed the Canterbury\
    \ irrigation scheduler as an innovative on-farm \nirrigation scheduling decision\
    \ support method under the circumstance of limited water availability. \nSA was\
    \ used to optimize a set of decision variables and generate the optimal irrigation\
    \ strategy \nthat maximized the expected future farm profit. Borge et al. [71]\
    \ also took advantage of SA and \nintegrated it within a decision support system\
    \ for assessing the impact of changes in prices and in \nagricultural policy on\
    \ land use patterns and on forestry. A case study in the region of southern \n\
    Portugal proved the usefulness and relevance of their proposal. Kong et al. [72]\
    \ presented a \nmathematical optimization model to bring real-time data and information\
    \ to precision decision-\nsupport and to optimize short-term farming operation.\
    \ Their result suggested that the tailored GA \nenabled rapid solution searching,\
    \ however, the solution quality cannot be guaranteed. Muleta and \nNicklow [73]\
    \ developed a DSS by associating GA and a watershed simulation model, aiming at\
    \ \nidentifying the optimal or near-optimal land use patterns. In their proposal,\
    \ GA was linked with \n19 \n \nthe US department of agriculture’s soil and water\
    \ assessment tool (SWAT) for single objective \nevaluations. Chaudhuri et al.\
    \ [74] implemented the ACO algorithm for forecasting the amount of \nsummer monsoon\
    \ rainfall for the next day over Kolkata, India. Compared with the forecast \n\
    generated by a Markov chain model, their proposal achieved greater accuracy. Sung\
    \ et al. [75] \nused ACO for aggregating agricultural data from various sensors.\
    \ The computational simulations \nverified that the proposed algorithm was able\
    \ to remarkably extend the life cycle of sensor nodes, \nand hence to provide\
    \ continuous data sources for decision support systems. Fereidoon and Koch \n\
    [76] presented a complex coupled simulation-optimization tool, SWAT-LINGO-MODSIM-PSO,\
    \ \nto detect the future optimum cultivation area of crops for maximizing the\
    \ economic benefits in \nsouthwest Iran. In their proposal, PSO was used to adjust\
    \ the cultivation areas of different crops, \ntaking into account their specific\
    \ prices and the optimal crop yields under water deficiency. Barak \net al. [77]\
    \ applied a multi-objective PSO algorithm to analyze management system of an \n\
    agricultural production. A case study in Kerman province was considered and the\
    \ average \ngreenhouse gas emissions in watermelon production was reduced by about\
    \ 30%, therefore their \nproposal was proved to provide promising modelling and\
    \ optimization results. \nMore research works on optimization-based DSSs can be\
    \ found in [78-95]. In general, the \napplications of current optimization-based\
    \ DSSs support the farming operation in various fields, \nincluding irrigation,\
    \ fertilization, harvesting, cropping, etc. Meanwhile, these DSSs are able to\
    \ \npartially serve Agriculture 4.0 by increasing productivity, allocating resources\
    \ reasonably, \nadapting to climate change, and avoiding food waste. \nThough\
    \ some of the above research works are not strictly DSSs, researchers mentioned\
    \ them \nas “planning tool”, “decision-making tool”, “optimization model”, “optimization\
    \ method”, \n“multi-objective programming”, “multi-objective optimization”, or\
    \ “optimal scheduling tool” \ninstead. However, these proposals indeed have great\
    \ potential to be integrated within DSSs, no \nmatter how researchers named them,\
    \ their nature is to provide farmers with decision supports. For \ninstance, the\
    \ prediction of soil moisture content in [65] can be treated as an input to a\
    \ DSS for \nassisting farmers in scheduling irrigation activities. The optimal\
    \ area coverage strategy generated \nin [67] is able to provide farmers with decision\
    \ supports on distributing harvesting tasks to the \nmost appropriate agricultural\
    \ machinery, and hence to improve harvesting efficiency. The \nselection of the\
    \ optimal cultivation area of crops in [76] also enables decision supports on\
    \ \ncropping for farmers. The output of the optimization model in [81] can provide\
    \ farmers with \nadvice about how to maximize the operating profit and organic\
    \ matter balance, as well as to \nminimize the labor requirement and soil nitrogen\
    \ losses. The method developed in [85] is \napplicable for providing decision\
    \ supports on enhancing food availability and reducing the \n20 \n \nenvironmental\
    \ impact of agriculture. Consequently, the above research works are all considered\
    \ \nbeing developed within the DSS context for smart agriculture. \nThe merits\
    \ and demerits of optimization-based DSSs will be discussed in Section 2.2.4,\
    \ as \nwell as its comparison with reasoning-based DSSs. \n2.2.2. Reasoning-based\
    \ DSSs \nAs a popular technique in Artificial Intelligence and knowledge-based\
    \ systems, reasoning \n[96] is a process of generating conclusions from the available\
    \ information by using logical \ntechniques. It has various applications, including\
    \ scheduling, problem solving, complex event \nprocessing, predictive analytics,\
    \ etc. Some typical reasoning approaches are listed as follows. \n• \nCase-based\
    \ reasoning (CBR) [97]: CBR refers to the process of solving new problems based\
    \ \non the solutions of similar past problems. It is not only a powerful method\
    \ for computer \nreasoning, but also a pervasive behavior everyday human problem\
    \ solving. \n• \nRule-based reasoning (RBR) [98]: RBR uses an inference engine\
    \ or a semantic reasoner to \ninfer information or take actions based on the interaction\
    \ of inputs and a rule base (a specific \ntype of knowledge base). It follows\
    \ the match-resolve-act cycle for solving new problems. \n• \nEvidential reasoning\
    \ (ER) [99]: ER adopts a belief structure to model an assessment with \nuncertainty,\
    \ a belief decision matrix to represent multi-criteria decision analysis problem\
    \ \nunder uncertainty, evidential reasoning algorithms to aggregate criteria for\
    \ generating \ndistributed assessments, and the concepts of the belief and plausibility\
    \ functions to generate \na utility interval for measuring the degree of ignorance.\
    \ \nSome latest contributions to reasoning-based DSSs are summarized as follows.\
    \ Though there \nare not so many reasoning-based DSSs applied in the context of\
    \ smart farming, DSSs proposed \nin other fields can also inspire the design of\
    \ agricultural DSSs. Thus, DSSs from all the fields are \nincluded in the following\
    \ review, as long as they are related to decision support and decision-\nmaking.\
    \ \nCBR DSSs \nRong and Li [100] described a web-based CBR system for fish disease\
    \ diagnosis. Instead of \ndepending on general domain knowledge, their proposal\
    \ utilized knowledge of previous cases and \nsolved new problems by hunting out\
    \ a similar past case and reusing its solution for tackling the \nnew problem.\
    \ Car and Moore [101] improved CBR with a novel interface, allowing users to select\
    \ \ncase parameters that interest them for case comparison. The updated CBR was\
    \ tested within \nAustralian irrigation cases and presented promising results.\
    \ Padma et al. [102] implemented an \n21 \n \nintelligent decision support system\
    \ (IDSS) for detecting pest and disease in an apple orchard. \nTheir proposal\
    \ adopted CBR and a database technology within a web-based client server \narchitecture.\
    \ The accuracy of decision-making processes achieved 90.20% and this IDSS was\
    \ able \nto provide significant supports for apple farmers to manage pest practices.\
    \ Zhu and Yin [103] \npresented a decision support system for managing crop diseases\
    \ and insect pests on the basis of \nCBR. The ontology data within their framework\
    \ can be processed for supporting on pest \nprevention and control. The prediction\
    \ accuracy of their proposal achieved 86.87% in the \nvalidation. Some DSSs that\
    \ adopted CBR in other fields (i.e. finance, healthcare, emergency \nresponse,\
    \ and industry) can be found in [104-111]. \nRBR DSSs \nBalleda et al. [112] presented\
    \ a rule-based agricultural system for rice and wheat crop pest \nmanagement.\
    \ This system facilitated different components, including a decision support module\
    \ \nand an interactive interface for diagnosis on the basis of responses of the\
    \ user made against the \nqueries related to particular disease symptoms. Naseem\
    \ et al. [113] proposed a rule-based DSS \nusing the semantic web technology.\
    \ This DSS can collect, store, and update agricultural \ninformation at a centralized\
    \ location, and then deliver knowledge through the semantic web, \nproviding query\
    \ services from a agricultural knowledge base. Han [114] adopted a mixed \nreasoning\
    \ strategy of RBR (as the main reasoning approach) and CBR (as a supplement) for\
    \ \nconstructing an animal disease diagnosis system. This system was able to reduce\
    \ the rate of \nmisdiagnosis and improve the quality of veterinary services. Katsiri\
    \ and Makropoulos [115] \nimplemented an ontology framework for decentralized\
    \ water management and analytics with the \nobjective of improving system availability.\
    \ RBR was used as an inference tool for obtaining high-\nlevel knowledge (i.e.\
    \ irrigation scheduling plans). Some DSSs that adopt RBR in other fields (i.e.\
    \ \nfinance, healthcare, emergency response, industry) can be found in [116-123].\
    \ \nER DSSs \nSun et al. [124] presented a method to map plant functional types\
    \ (PFTs) from moderate \nresolution imaging spectroradiometer (MODIS) data using\
    \ an ER algorithm. After utilizing \nMODIS data, multiple lines of evidence computed\
    \ from input data were then combined using \nDempster’s rule of combination. Their\
    \ preliminary result suggested that the multisource ER \nalgorithm can promisingly\
    \ improve the mapping of PFTs. Cohen and Shoshany [125] adopted ER \nin a knowledge-based\
    \ system for land-cover mapping derived from remotely sensed images. The \neffectiveness\
    \ of their proposal was verified by the task of crop recognition in a wide \n\
    heterogeneous region in Israel. Jiang et al. [126] developed a fuzzy evidential\
    \ reasoning approach \nfor selecting the optimal submarine power cable routing\
    \ for offshore wind farms. The decision \n22 \n \nsupport was generated by ER,\
    \ taking into account input variables (after fuzzification) and a belief \nrule\
    \ base. Sanz [127] applied a dynamic ER approach to crop classification. This\
    \ proposal allowed \nthe incorporation of new evidence for the classifier in order\
    \ to achieve better accuracy. Two \ndecision stages were concerned by calculating\
    \ the similarity between the maximum support value \nand other supports of the\
    \ rest of the classes. Some DSSs that adopt ER in other fields (i.e. finance,\
    \ \nhealthcare, emergency response, industry) can be found in [128-135]. \nThe\
    \ merits and demerits of reasoning-based DSSs will be discussed in Section 2.2.4,\
    \ as well \nas its comparison with optimization-based DSSs. \n2.2.3. Distinctions\
    \ with expert systems \nDecision support systems are usually compared with expert\
    \ systems. On the one hand, as \nmentioned in the beginning of Section 2.2, a\
    \ DSS is an interactive system that helps decision-\nmakers to utilize data and\
    \ models for solving unstructured or semi-structured problems. However, \non the\
    \ other hand, an ES [136] is a computer-based system that emulates the decision-making\
    \ \nability of human experts. A general framework of an ES is shown in Figure\
    \ 5. \n \nFigure 5. A general framework of expert systems. \n \nIn Figure 5, three\
    \ key components are demonstrated, including a knowledge base, an \ninference\
    \ engine, and a user interface. The process of capturing and transferring information\
    \ for \ngiven problems is conducted by human experts and knowledge engineers.\
    \ The inference engine \nis used to perform reasoning with expert knowledge and\
    \ users’ queries. Users can both raise \nqueries and obtain the inference result\
    \ through a user interface. A typical application of ESs is its \nemployment in\
    \ the medical fields. For example, Song et al. [137] proposed a data-based \n\
    interactive medical expert system for supporting pregnancy consultations. One\
    \ remarkable feature \n23 \n \nof ESs is that the users should have adequate knowledge\
    \ in the field. In the case of ESs for medical \napplications, users are mainly\
    \ medical personnel. \nThough both systems aim at improving the quality of decisions,\
    \ some distinctions between \nthese two have to be clarified [138,139], especially\
    \ in their objectives, users, orientation, etc. A \ncomparison table is provided\
    \ in Table 1. \nTable 1. Comparison for distinguishing DSSs with ESs. \nCharacteristics\
    \ \nExpert system \nDecision support system \nObjective \nReplication of human\
    \ \nexperts \nAssistance in decision-\nmaking \nOrientation \nExpertise transfer\
    \ \nDecision-making \nDecision maker \nSystem \nHuman \nUser \nPeople with expert\
    \ \nknowledge  \nPeople without much expert \nknowledge \nQuery \nMachine queries\
    \ human \nHuman queries machine \n \nIn general, the objective of an ES is to\
    \ replicate how human experts would perform reasoning. \nThe ES is in the position\
    \ of taking final decisions and therefore providing users with a list of \ncommands\
    \ or instructions on solving problems. While, the objective of a DSS focuses on\
    \ \nproviding assistance in decision-making activities for users. Under this circumstance,\
    \ users have \nthe right to make the final call after receiving a list of generated\
    \ advice from DSSs. It is also worth \nnoting that ESs and DSSs target to different\
    \ groups of users. DSSs are more suitable for ordinary \nusers who do not have\
    \ much expert knowledge. \nAs a consequence, DSSs are more suitable than ESs for\
    \ farmers in the context of agriculture. \n2.2.4. Summary of DSSs \nIn previous\
    \ sub-sections (Sections 2.2.1 and 2.2.2), the existing optimization-based and\
    \ \nreasoning-based DSSs have been reviewed. In this section, their features are\
    \ further discussed for \ndetermining which approach is going to be adopted in\
    \ this thesis. \nBy reviewing literatures [65-95], merits and demerits of the\
    \ optimization-based DSSs are \nsummarized as follows. \n \n \n24 \n \nMerits\
    \ of optimization-based DSSs: \n• \nOptimization-based DSSs are usually capable\
    \ of handling low dimensional problems through \nmathematical computations within\
    \ a short time. \n• \nUnder general circumstance, optimization-based DSSs are\
    \ able to find the true optimum of a \nresponse with fewer trials than the non-systematic\
    \ approaches or the one-variable-at-a-time \nmethods. \n• \nIt is acknowledged\
    \ that optimization algorithms are easy to implement. Meanwhile, \noptimization\
    \ algorithms are usually compatible with other components within DSSs. \nDemerits\
    \ of optimization-based DSSs: \n• \nFew optimization-based DSSs take historical\
    \ data into consideration. In general, optimization \nalgorithms tend to treat\
    \ the latest data as inputs to the programming models. However, \nhistorical data\
    \ undoubtedly contain valuable information, including not only the successful\
    \ \nexperiences, but also failure cases. As a consequence, it seems to be a wise\
    \ approach for \nsmart agricultural systems to take advantage of historical information.\
    \ \n• \nFor optimization-based DSSs, a complete programming model and a set of\
    \ objective \nfunctions has to be constructed beforehand. The performance of optimization-based\
    \ DSSs \ncan be hardly improved because the models and functions are usually fixed\
    \ during \noptimization. Though extra rules can be inserted to the systems that\
    \ might be helpful, the \ncomplexity of DSSs will then increase. \n• \nOptimization\
    \ algorithms are usually computationally expensive for dealing with high \ndimensional\
    \ problems. Because it is not easy to achieve a balance between all the objective\
    \ \nfunctions that have conflict with each other. Meanwhile, due to the natural\
    \ defect of \noptimization algorithms, they may be trapped within a local optimal\
    \ solution and give up on \nsearching for the global optimal ones due to inappropriate\
    \ initial settings for the parameters \nof optimization algorithms. \nBy reviewing\
    \ literatures [100-135], the merits and demerits of reasoning-based DSSs are \n\
    identified as follows. \nMerits of reasoning-based DSSs: \n• \nReasoning-based\
    \ DSSs usually take historical data into account, especially for those DSSs \n\
    that adopt the case-based reasoning approach. Consequently, new problems may be\
    \ handled \nby learning from successful historical experiences. It is also worth\
    \ noting that current and \npredicted data are considered as well. \n25 \n \n\
    • \nCompared with optimization-based DSSs, reasoning-based DSSs do not require\
    \ any \ncomplete domain models nor objective functions. Reasoning-based DSSs is\
    \ applicable when \na domain contains complex information that is difficult or\
    \ impossible to elicit, as well as the \nsystem requires constant maintenance.\
    \ \n• \nMost importantly, the generation of knowledge is on the basis of inference,\
    \ not the process \nof mathematical computation. The decision supports provided\
    \ by reasoning-based DSSs may \nhave a chance for improvement with time. Because\
    \ the coverage in domains will become \nmore complete when more source cases are\
    \ retained in the database. \nDemerits of reasoning-based DSSs: \n• \nReasoning-based\
    \ DSSs highly depends on the structure of information. A well-organized \ncollection\
    \ of information can enhance the performance of reasoning, while unstructured\
    \ data \nmay cause problems during the inference process. \n• \nConstructing the\
    \ knowledge base (case base / rule base) might be a challenging task. For \nexample,\
    \ for DSSs that adopt CBR, how many cases should be stored, how to remove \noverlapping\
    \ cases, how to weight features, etc. \n• \nTransferring a large volume of information\
    \ into practical knowledge is a time-consuming \nprocess. The inference time varies\
    \ in different reasoning techniques. \nIn conclusion, though optimization-based\
    \ DSSs have proved to be effective for solving \nspecific agricultural problems\
    \ and can provide farmers with decision supports to some extent, it \nis determined\
    \ that optimization approaches may not be suitable for designing a general platform\
    \ \nfor smart agriculture. Instead, reasoning techniques is employed to build\
    \ decision support systems \nfor the AFarCloud project. In particular, the case-based\
    \ reasoning approach is favored in this \nthesis, as the main technique in the\
    \ decision support system. Consequently, the current state of \ncase-based reasoning\
    \ is reviewed in the following sub-section. \n2.3. Review of the case-based reasoning\
    \ approach \nAs an important technique in artificial intelligence, CBR is defined\
    \ as the process of solving \nnew problems by matching and adapting cases that\
    \ have been successfully managed before. By \nmimicking how humans would perform\
    \ reasoning and learning, CBR seems to be a more \npsychologically plausible model\
    \ of human reasoning [97]. This unique characteristic makes CBR \na promising\
    \ approach for building intelligent systems [140]. Due to its effectiveness and\
    \ powerful \nreasoning capability, CBR has been applied to various fields, including\
    \ the domain of agriculture. \n26 \n \nCBR can be formalized as a 5R circle [141],\
    \ including the steps of represent, retrieve, reuse, \nrevise, and retain. A generic\
    \ workflow of CBR is presented in Figure 6. \n \nFigure 6. A generic workflow\
    \ of case-based reasoning. \nIn Figure 6, the problem statements are transformed\
    \ into a new case by a certain case \nrepresentation formalism. Given a target\
    \ problem, the retrieval process compares the new case \nwith historical ones\
    \ for the purpose of identifying the most similar past case. Generally, a past\
    \ \ncase consists of a problem and its solution, and typically, annotations about\
    \ how the solution can \nbe derived. Afterwards, the solution of this retrieved\
    \ case is reused to solve the new case. In order \nto perfectly fit the new case,\
    \ a revision process is required to update the proposed solution. After \napplying\
    \ the updated solution, the solved case will be stored in the case base for further\
    \ \ncomparisons. \nTherefore, each step (represent, retrieve, reuse, revise, and\
    \ retain) within the CBR loop is \nreviewed in the sub-sections for detecting\
    \ any room for improvements when applying CBR to the \ndecision support systems\
    \ for smart agriculture. \n2.3.1. Review of case representation \nExperiences\
    \ in the CBR systems are stored by the form of cases, thus the representation\
    \ \nformalism plays a significant role in CBR [142]. Case representation is the\
    \ task of enabling CBR \n27 \n \nsystems to recognize, store, and process past\
    \ contextualized experiences [143]. As a fundamental \nelement, a system without\
    \ cases cannot be a CBR system. Case representation in CBR makes use \nof knowledge\
    \ representation formalisms from artificial intelligence to represent the experiences\
    \ \ncontained in the cases for reasoning purposes. Most importantly, the reasoning\
    \ capability of CBR \nsystems depend on the content and structure of cases. Thus,\
    \ the main issues [144] in the context \nof case representations are identified\
    \ as: (i) defining attributes that describe a case, (ii) defining \nthe structure\
    \ that describes the case content, and (iii) defining the organization that manages\
    \ cases \nin the case base. The research community has proposed a variety of case\
    \ representation formalism, \nsuch as the following. \n• \nFeature vector representation\
    \ [145]: This representation formalism is also known as the \npropositional representation\
    \ or attribute-value pair. It is composed of a set of features \ndescribing the\
    \ problem and a corresponding solution. An example of the feature vector \nrepresentation\
    \ is presented in Figure 7 [146]. \n \nFigure 7. An example of the feature vector\
    \ representation. \nA feature is an individual measurable property or characteristic\
    \ of an observable \nphenomenon. It can be defined by numeric attributes, strings,\
    \ graphs, fuzzy variables, etc. In \nFigure 7, apart from the case IDs, a 4-dimensional\
    \ vector is used to reconstruct phylogenetic trees. \nThese features characterize\
    \ the relative difference of biological sequences. In this example, \n“Name”,\
    \ “Species”, “Accession no.”, and “Length” are the key features to determine the\
    \ \ncommonalities between different cases. \nDue to ease of use and simplicity,\
    \ the feature vector representation has been adopted by \nresearchers from all\
    \ fields. Asadi and Lin [147] employed the feature vector representation in \n\
    28 \n \nmulti-stage document ranking. This representation not only helped the\
    \ system to save more \nmemory, but also offered greater flexibility. Bringer\
    \ et al. [148] used the feature vector \nrepresentation for transforming a fingerprint\
    \ minutiae template into a binary format with a fixed \nlength. The experimental\
    \ result demonstrated that their proposal achieved promising \nimprovements for\
    \ utilization into fast identification algorithms. Svanberg [149] adopted the\
    \ \nfeature vector representation for identifying similar projects in App Inventor.\
    \ By measuring the \nsimilarity between projects, original projects can be distinguished\
    \ from unoriginal ones. Yagi et \nal. [150] proposed an edge-based feature vector\
    \ representation for a medical image recognition \nsystem. The robust nature of\
    \ the feature vector representation was verified through the \ncephalometric landmark\
    \ identification and expert dentists’ practice. \nJudging from the above literatures,\
    \ it is well acknowledged that the feature vector \nrepresentation has the merits\
    \ of simplicity, flexibility, and great robustness. However, there are \nno relationships\
    \ or constraints between features in this representation formalism. Meanwhile,\
    \ Due \nto lack of domain knowledge, semantic similarity can be hardly measured.\
    \ Moreover, if a case \ncontains incomplete or ambiguous information, difficulties\
    \ may be encountered during the \nprocess of case retrieval. \n• \nTextual representation\
    \ [151]: The textual representation method is commonly used in textual \ncase-based\
    \ reasoning (TCBR) systems [152]. As a subfield of CBR, TCBR aims at using \n\
    textual knowledge sources in an automated or semi-automated way for solving problems\
    \ \nthrough case comparisons. An example of the textual representation is shown\
    \ in Figure 8 \n[153]. \n \nFigure 8. An example of the textual representation.\
    \ \n29 \n \nIn Figure 8, the relevant information is interested in “Names and\
    \ Roles” and factors like \n“Security Measure”, “Disclosure-In-Negotiations”,\
    \ “Nondisclosure-Agreement”, and “Info-\nKnown-Competitors”. These pieces of information\
    \ are extracted from a plain text for further \nprocessing in TCBR. \nTwo research\
    \ lines were pointed out by Ozturk and Prasath [154]. The first one focused on\
    \ \nextracting contents of a case from a textual report and populating the obtained\
    \ knowledge into a \ncase base under s structure manner. Chan [155] described\
    \ a method for extracting the salient \ntextual patterns, with consideration of\
    \ moving away keywords and their associated limitations in \ntextual information\
    \ retrieval. Cardenosa et al. [156] presented a new approach for describing \n\
    contents through the use of interlinguas for facilitating the extraction of specific\
    \ pieces of \ninformation, highlighting the different dimensions of a document\
    \ and how these dimensions \ndefined the capacities of their respective contents\
    \ in the scalable process of finding information. \nAngelova [157] discussed the\
    \ role of domain knowledge in extracting structured information from \npatient\
    \ related texts. The prototype system was proved to be effective for providing\
    \ an ontological \nframework for information extraction tasks. The second research\
    \ line concentrated on retrieving \nknowledge from free texts without converting\
    \ them into structured cases. Cohen [158] presented \nWHIRL, a world-based information\
    \ representation language for integrating data from \nheterogeneous information\
    \ sources. WHIRL had proved its effectiveness in inductive text \nclassification.\
    \ Chan [159] proposed a novel textual information extraction method which was\
    \ \nbeyond purely keyword-based method. Instead of detecting specific keywords\
    \ or cue-phrases to \nevaluate the relevance of the sentence, the proposed method\
    \ focused on identification of the main \nfactors in the textual continuity. Buranasing\
    \ and Phoomvuthisarn [160] introduced a word vector \nrepresentation method for\
    \ information extracting from cultural heritage data sources by \nidentifying\
    \ named entities and determining the semantic relation triples and position tags.\
    \ \nA major advantage for adopting the textual representation is that it can handle\
    \ both semi-\nstructured and unstructured documents. This representation method\
    \ is sufficient when the amount \nof information is not too extensive. However,\
    \ it is noted that textual cases are usually presented \nby plain text, resulting\
    \ in difficulty for CBR systems to understand the information within cases. \n\
    Meanwhile, the textual representation is domain specific and it requires knowledge\
    \ engineers to \ndetermine which features are relevant in the target domain. As\
    \ a consequence, the retrieval \nprocess is complex. \n• \nFrame-based representation\
    \ [161]: Frames provide a natural way for the structured and \nconcise representation\
    \ of knowledge. In a single entity, a frame combines all necessary \nknowledge\
    \ about a particular object or concept. It organizes knowledge in a slot and describes\
    \ \n30 \n \nvarious attributes and characteristics of the objects. An example\
    \ of the frame-based \nrepresentation is shown in Figure 9 [162]. \n \nFigure\
    \ 9. An example of the frame-based representation. \n \nIn Figure 9, the frame\
    \ slots are used to represent the characteristics of the object. Each slot \n\
    consists of the slot name and a list of values. This list of values can be a pointer\
    \ to another frame, \na descriptive variable or a procedure. \nYao et al. [163]\
    \ utilized the frame-based representation to construct cases for ship repair \n\
    problems. CBR was adopted in their proposal for assessing the ship repair risk.\
    \ Mohamed et al. \n[164] proposed a hybrid rule and frame-based knowledge representation\
    \ approach to eliminate \ncurrent drawbacks on using both methods separately.\
    \ Their proposal had the advantage of well-\nstructured, supporting on a large\
    \ number of conditions and rules, supporting on complex tasks, \nand great flexibility.\
    \ Su et al. [165] employed CBR for safety accident pre-control and decision \n\
    making in the construction industry. Within their proposal, the frame-based knowledge\
    \ \nrepresentation method was adopted to establish the case database from dimensions\
    \ like slot, facet, \nand facet’s value. Sorenson et al. [166] described a frame-based\
    \ knowledge representation method \nto construct an adequately-explicit bedside\
    \ clinical decision support application for ventilator \nweaning. They concluded\
    \ that frames for knowledge representation were advantageous because \nthey can\
    \ be created, visualized, and conceptualized as self-contairied entities that\
    \ corresponded \nto accepted medical constructs. \nConcluding from the above literatures,\
    \ in the CBR terminology, a frame can represent a case \nand each slot is a case\
    \ feature. As a consequence, cases represented as frames can have semantic \n\
    relationships. As inheritance is an essential feature of the frame-based representation,\
    \ a hierarchy \n31 \n \nof cases connected by IS_A and PART_OF relationships can\
    \ be generated. This case hierarchy \ncan enhance the semantic retrieval and adaption\
    \ operations. The frame-based representation \nmethod has been formalized by description\
    \ logics [167,168]. The notion of “cases as terms” \nindicates that viewing structured\
    \ cases as terms in feature logics enables better understanding in \ncase-based\
    \ reasoning. \n• \nObject-oriented representation [169]: This representation is\
    \ a common way of defining \nIS_A, HAS_A, and PART_OF relationships. Cases can\
    \ be represented by classes and objects. \nA class is a general abstract of a\
    \ group of similar objects, gathering the general features of \nthe group. Usually,\
    \ a class is formulized by a 4-tuple expression, including (i) the \nidentification\
    \ of the class, (ii) the data structure description, (iii) the concrete implementation\
    \ \nof operations, and (iv) the unified external interface. An example of the\
    \ object-oriented \nrepresentation is shown in Figure 10 [170]. \nIn Figure 10,\
    \ two objects are defined, named “Maintenance Report” and “Maintenance \nActivity”.\
    \ Apart from the variable features, a pointer “Activity Code” links the two objects.\
    \ \n \nFigure 10. An example of the object-oriented representation. \n \nKhan\
    \ and Chaudhry [171] adopted the object-oriented case representation method and\
    \ CBR \nin structural analysis. The proposed representation scheme was a step\
    \ forward in the development \nof a system to be utilized for the time-consuming\
    \ structural analysis. Marefat and Britanik [172] \nexplored the CBR application\
    \ in process planning. By utilizing the object-oriented representation, \nthis\
    \ application was able to process selection and sequencing to combine the advantages\
    \ of the \nvariant and generative approaches to process planning. Chen and Lee\
    \ [173] proposed an object-\n32 \n \noriented representation of program trees.\
    \ The object serialization technology was used for storing \nand retrieving the\
    \ syntax trees and program models. In addition, the connection between the \n\
    object-oriented program graph and XML representations was established. Chen et\
    \ al. [174] \npresented an object-oriented hierarchical case representation for\
    \ automotive panels in process \nplanning. The representation scheme extended\
    \ the object model in object-oriented modelling \ntechnology, allowing the CBR\
    \ system to effectively represent and organize the abundant \ninformation in the\
    \ cases. \n \nBy reviewing the above literatures and [175-177], following advantages\
    \ of the object-\noriented representation are detected: (i) it provides a clear\
    \ modular structure for programming. In \nother words, the object-oriented representation\
    \ is beneficial for defining abstract datatypes when \nimplementation details\
    \ are hidden; (ii) objects can be reused within an across applications. It also\
    \ \nhelps to reduce the cost for development; (iii) the object-oriented representation\
    \ makes the CBR \nsystem easier for maintenance. Since this representation is\
    \ modular, part of the objects can be \nupdated without massive changes. However,\
    \ limitations of the object-oriented representation \ncannot be ignored. For example,\
    \ since such representation heavily relies on binary relations, it \nmight be\
    \ difficult to represent ternary relations. \n• \nOntology representation [178]:\
    \ Ontology is a formal explicit description of concepts and \ntheir relations.\
    \ It attempts to represent entities, ideas, and events, along with their \ninterdependent\
    \ properties and relations, on the basis of a system of categories. Within an\
    \ \nontology model, the main components include “Individuals” (instances or objects),\
    \ “Classes” \n(sets, collections, and concepts of things), “Attributes” (aspects,\
    \ properties, and features that \nclasses can have), “Relations” (in which way\
    \ classes and individuals are related to one \nanother), “Rules” (descriptions\
    \ of logical inferences), “Axioms” (assertions in a logical \nform), and “Events”\
    \ (changes of attributes or relations) [179]. An example of the ontology \nrepresentation\
    \ is shown in Figure 11 [180]. \nIn Figure 11, the observer indicates who describes\
    \ the case, the description clarifies what and \nhow the case is described, while\
    \ the target explains why the case is described. Therefore, the \nconcepts of\
    \ a case in the ontology representation are related by using the properties, like\
    \ \n“hasObserver”, “hasDescription”, and “hasTarget”. \n33 \n \n \nFigure 11.\
    \ An example of the ontology representation. \nVarious research works have contributed\
    \ to the ontology representation in CBR. Castro et al. \n[181] focused on a homogenous\
    \ conception of the case base with the aid of the ontology \nrepresentation, trying\
    \ to simplify case retrieval in case-based reasoning. Their conclusion pointed\
    \ \nout that cases may be recovered more effectively and efficiently in the initial\
    \ phase. Xiong et al. \n[182] combined CBR and the ontology representation for\
    \ modelling an e-government DSS. The \nontology was used to extract the case knowledge\
    \ and a similarity algorithm was adopted for case \nretrieval. El-Sappagh and\
    \ Elmogy [183] took advantage of ontology and fuzzy logic reasoning \nfor modelling\
    \ the knowledge within a case base in the diabetes mellitus domain. The fuzzy\
    \ \nontology representation was expected to improve the semantic and storage of\
    \ CBR knowledge \nbase. Zhukova et al. [184] proposed a knowledge-based approach\
    \ for supporting decision making \nin human resource management by employing CBR\
    \ and ontology. An algorithm for retrieving \nsimilar past cases was also designed\
    \ in their proposal. \nFrom above literatures, one of the major advantages of\
    \ applying the ontology representation \nis that by having the essential relationships\
    \ between concepts built into the concepts, it is possible \nfor performing automated\
    \ reasoning about data. Meanwhile, the ontology representation ensures \n34 \n\
    \ \na common understanding of information and enables to explicit domain assumptions.\
    \ As a \nconsequence, the interconnectedness and interoperability of ontology\
    \ models make it easier for \naddressing the challenges of accessing and querying\
    \ in large datasets. Though ontology provides \nan adequate tool for modelling\
    \ data, its usability surely comes with some limitations as well. For \ninstance,\
    \ data are usually imported from a new source into the RDF triples. It happens\
    \ that the \ndata are structurally inconsistent with the constraints set in the\
    \ ontology representation. \nConsequently, the new data have to be modified before\
    \ being integrated with what had already \nbeen loaded in the triples. \nSummary\
    \ of review of case representation methods \nAfter reviewing on the main case\
    \ representation methods (the feature vector representation, \nthe textual representation,\
    \ the frame-based representation, the object-oriented representation, and \nthe\
    \ ontology representation), a conclusion can be drawn that each representation\
    \ method has its \nown advantages and disadvantages.  \nThe choice of a particular\
    \ representation formalism is largely determined by the information \nto be stored\
    \ within a case. According to the content and characteristics of agricultural\
    \ cases, the \nfeature vector representation is selected. However, it is noticed\
    \ that this representation method \nfails to address the interconnectedness between\
    \ cases. In a case base, each case is stored \nindividually. Therefore, inspired\
    \ from the frame-based representation (the pointer concept), the \nfeature vector\
    \ representation is going to be further developed in this thesis. \n2.3.2. Review\
    \ of case retrieval \nCase retrieval plays an essential role in CBR systems because\
    \ the rest of steps (reuse, revise, \nand retain) cannot be further proceed without\
    \ successfully retrieving similar past cases at the first \nplace. Current studies\
    \ on the case retrieval tasks mainly concern the following two aspects: (i) \n\
    proposals of new similarity measures, and (ii) proposals of new indexing methods.\
    \ \nReview of similarity measures \nIn general, a similarity measure [185] is\
    \ a function that quantifies the similarity between two \nobjects. Usually, a\
    \ smaller distance means that the compared two objects have more \ncommonalities.\
    \ Similarity measures can be categorized mainly into two groups: (i) angle-based,\
    \ \nand (ii) distance-based measures. On the one hand, as one of the representative\
    \ angle-based \nmeasures, the cosine similarity measure [186] compares two non-zero\
    \ vectors and calculates the \ncosine angle between them. It evaluates the similarity\
    \ through their orientation, not magnitudes. \nA smaller cosine angle indicates\
    \ that compared vectors are more similar. On the other hand, \n35 \n \ntremendous\
    \ contributions towards distance-based similarity measures have been made, especially\
    \ \nthe Euclidean distance [187], the Manhattan distance [188], the Chebyshev\
    \ distance [189], and \nthe Hamming distance [190]. The smaller the distance is,\
    \ the more commonalities the compared \nobjects will have. The details of these\
    \ similarity measures are reviewed in the following. \n• \nCosine similarity measure:\
    \ The cosine similarity calculates the cosine angle between two \nnon-zero vectors.\
    \ It is widely used in case retrieval for CBR due to its simplicity and \neffectiveness.\
    \ The similarity of images, documents, and numeric values can be measured by \n\
    the cosine similarity because all these data can be represented by vectors. Mathematically,\
    \ \nthe cosine similarity can be formularized in Equation (1) [191]. \n\U0001D446\
    \U0001D456\U0001D45A(\U0001D465, \U0001D465′) = cos(\U0001D703) = \n∑\n\U0001D465\
    \U0001D456∗\U0001D465\U0001D456\n′\n\U0001D45B\n\U0001D456=1\n√∑\n\U0001D465\U0001D456\
    \n2\n\U0001D45B\n\U0001D456=1\n∗√∑\n\U0001D465\U0001D456\n′2\n\U0001D45B\n\U0001D456\
    =1\n                  (1) \nWhere \U0001D703 is the angle between vectors \U0001D465\
    \ and \U0001D465′. \U0001D465\U0001D456 and \U0001D465′\U0001D456represents the\
    \ \U0001D456\U0001D461ℎ attribute in the \nvectors \U0001D465 and \U0001D465′\
    \ respectively. The similarity between these two vectors will increase as the\
    \ \nvalue of cos(\U0001D703) increases. \nHassanien et al. [192] presented an\
    \ automatic CBR based system for assessing water quality \naccording to microscopic\
    \ images of fish gills and livers. The cosine similarity measure was used \nto\
    \ identify a small number of cases with the highest similarity from the case base\
    \ to the query. \nCompared with other similarity measures like Euclidean distance,\
    \ Canberra distance, and Squared \nchord distance, the proposed system achieved\
    \ water quality prediction accuracy of 97.9% when \nusing the cosine similarity\
    \ measure. Senanayke et al. [193] combined the fuzzy logic and CBR to \nbuild\
    \ an assistive tool for sports trainers, coaches, and clinicians for maintaining\
    \ athletes’ profiles, \nmonitoring their recoveries, and adjusting recovery protocols.\
    \ The cosine similarity matrix was \nused to retrieve the most similar past cases\
    \ from the identified cluster. The proposed system was \nverified through a group\
    \ of healthy and post-operated athletes. The experiment result showed the \nclassification\
    \ accuracy is more than 94%.  \n• \nEuclidean distance: The Euclidean distance,\
    \ also known as the Euclidean metric, calculates \nthe straight-line distance\
    \ between two points in the Euclidean space. It has been usually \nemployed to\
    \ measure the similarity of numeric, interval, and fuzzy variables. The formula\
    \ of \nthe Euclidean distance is defined in Equation (2). \n\U0001D437\U0001D456\
    \U0001D460\U0001D461(\U0001D465, \U0001D465′) = √∑\n(\U0001D465\U0001D456 − \U0001D465\
    \U0001D456\n′)2\n\U0001D45B\n\U0001D456=1\n                     (2) \n36 \n \n\
    Where \U0001D437\U0001D456\U0001D460\U0001D461() is the distance between compared\
    \ two points, while \U0001D465\U0001D456 and \U0001D465′\U0001D456 represents\
    \ the \n\U0001D456\U0001D461ℎ attribute in the vectors \U0001D465 and \U0001D465\
    ′ respectively. The similarity between these two points will \nincrease as the\
    \ value of \U0001D437\U0001D456\U0001D460\U0001D461() decreases. \nRahman et al.\
    \ [194] presented a retrieval-based decision support system for dermatoscopic\
    \ \nimages. The similarity between feature vectors was calculated by Bhattacharyya\
    \ and Euclidean \ndistance. Both measures were integrated into a single similarity\
    \ matching function for image \nretrieval. The experimental result showed that\
    \ the combined similarity measure was able to \nretrieve correct images, leading\
    \ to an improvement in diagnostic accuracy. Kwon et al. [195] \nevaluated the\
    \ performance of distance measurement methods for construction noise predictions\
    \ \nby using case-based reasoning. Euclidean distance was employed to measure\
    \ the shortest line \nsegment between two points in Euclidean space for case retrieval.\
    \ \n• \nManhattan distance: The Manhattan distance in N-dimensional space is the\
    \ sum of the \nlengths of the line segments between two points onto the coordinate\
    \ axes. The formula of the \nManhattan distance is defined in Equation (3). \n\
    \U0001D437\U0001D456\U0001D460\U0001D461(\U0001D465, \U0001D465′) = ∑\n|\U0001D465\
    \U0001D456 − \U0001D465\U0001D456\n′|\n\U0001D45B\n\U0001D456=1\n            \
    \          (3) \nWhere \U0001D437\U0001D456\U0001D460\U0001D461() is the distance\
    \ between compared two vectors, while \U0001D465\U0001D456 and \U0001D465′\U0001D456\
    \ represents the \n\U0001D456\U0001D461ℎ attribute in the vectors \U0001D465 and\
    \ \U0001D465′\U0001D456 respectively. The similarity between these two vectors\
    \ \nwill increase as the value of \U0001D437\U0001D456\U0001D460\U0001D461() decreases.\
    \ \n \nLi and Sun [196] adopted the CBR approach to predict business failures.\
    \ They used \nManhattan distance for case retrieval. The outputs from the CBR\
    \ system were then treated as \ninputs to a support vector machine (SVM) model\
    \ for combinations. The empirical result showed \nthat the proposed Multi-CBR-SVM\
    \ was feasible and effective. Ferreira and Oliveira [197] \nproposed a content-based\
    \ image retrieval method to provide specialists with decision supports for \n\
    analyzing the margin sharpness. The Manhattan distance was used to calculate the\
    \ similarity \nbetween the reference nodule and the image database. The authors\
    \ detected that the Manhattan \ndistance achieved a greater precision than the\
    \ Euclidean distance in regards to malignant nodules. \n• \nChebyshev distance:\
    \ The Chebyshev distance is defined as the greatest difference between \ntwo compared\
    \ vectors among any coordinate dimensions. The formula of the Chebyshev \ndistance\
    \ is defined in Equation (4). \n\U0001D437\U0001D456\U0001D460\U0001D461(\U0001D465\
    , \U0001D465′) = max (|\U0001D465\U0001D456 − \U0001D465\U0001D456\n′|)      \
    \                (4) \n37 \n \nWhere \U0001D437\U0001D456\U0001D460\U0001D461\
    () is the distance between compared two points, while \U0001D465\U0001D456 and\
    \ \U0001D465′\U0001D456 represents the \n\U0001D456\U0001D461ℎ attribute in the\
    \ vectors \U0001D465 and \U0001D465′ respectively. The similarity between these\
    \ two vectors will \nincrease as the value of \U0001D437\U0001D456\U0001D460\U0001D461\
    () decreases. \nRashid [198] built a CBR-based model for construction cost predictions.\
    \ The Chebyshev \ndistance was considered to measure the similarity between cases.\
    \ It ensured that relative cases \ncan be retrieved rapidly. Mousa and Yusof [199]\
    \ proposed an improved Chebyshev similarity \nmeasure in clustering analysis of\
    \ blood cancer images. The improved measure aimed at \nminimizing the distance\
    \ between any points and the cluster center of classes. The experimental \nresult\
    \ showed that the proposed measure can generate the smallest objective function\
    \ value and \nconverge at the lowest number of iterations. \n• \nHamming distance:\
    \ The Hamming distance is usually used to measure the similarity of \nstrings.\
    \ The length of strings should be equal. The Hamming distance counts the minimum\
    \ \nnumber of dis-matches between two strings. The formula of the Hamming distance\
    \ is defined \nin Equation (5). \n\U0001D437\U0001D456\U0001D460\U0001D461(\U0001D465\
    , \U0001D465′) = ∑\n(\U0001D465\U0001D456 ⊕ \U0001D465\U0001D456\n′)\n\U0001D45B\
    \n\U0001D456=1\n                      (5) \nWhere \U0001D437\U0001D456\U0001D460\
    \U0001D461() is the distance between compared two points, while \U0001D465\U0001D456\
    \ and \U0001D465′\U0001D456 represents the \n\U0001D456\U0001D461ℎ attribute in\
    \ the vectors \U0001D465 and \U0001D465′ respectively. The symbol ⊕ represents\
    \ the XOR operator. \nThe similarity between these two vectors will increase as\
    \ the value of \U0001D437\U0001D456\U0001D460\U0001D461() decreases. \nMustafa\
    \ [200] improved the Hamming distance by employing a probabilistic approach and\
    \ \napplied it to quick binary image matching. Compared with other binary image\
    \ matching methods \nlike correlation, sum of the absolute difference, and mutual\
    \ information, the improved Hamming \ndistance measure showed the superiority\
    \ among others. Zhang et al. [201] detected that the \ntraditional Hamming distance\
    \ measure may be insufficient to evaluate the similarity of binary \ncodes, thus\
    \ they proposed a weighted Hamming distance algorithm to rank the binary codes\
    \ of \nhashing methods. Extensive experiments were conducted and results demonstrated\
    \ the efficiency \nand accuracy of the improved measure. \nAfter reviewing the\
    \ above similarity measures, their shortcomings are detected as well. These \n\
    measures may generate wrong results under certain extreme circumstances [202-204].\
    \ For \nexample, the cosine similarity measure does not take vectors’ magnitudes\
    \ into consideration, thus \nit may have difficulties when meeting the following\
    \ situation shown in Figure 12. \n38 \n \n \nFigure 12. An extreme circumstance\
    \ when measuring with the cosine similarity. \n \nIn Figure 12, the target vector\
    \ is \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and it is compared with vectors \U0001D442\U0001D435\
    \n⃗⃗⃗⃗⃗ , \U0001D442\U0001D436\n⃗⃗⃗⃗⃗ , and \U0001D442\U0001D437\n⃗⃗⃗⃗⃗⃗ . On\
    \ \nthe one hand, though the angle between them is identical, there exists huge\
    \ differences between \ntheir magnitudes. However, due to the same value of the\
    \ cosine similarity measurement, vector \n\U0001D442\U0001D434\n⃗⃗⃗⃗⃗  is considered\
    \ similar to vectors \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D436\n⃗⃗⃗⃗⃗\
    \ , and \U0001D442\U0001D437\n⃗⃗⃗⃗⃗⃗ . On the other hand, the cosine similarity\
    \ \nbetween \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D436\n⃗⃗⃗⃗⃗ , and \U0001D442\
    \U0001D437\n⃗⃗⃗⃗⃗⃗  all equals to one, meaning that these vectors are exactly\
    \ the same. \nBut the fact tells a different story. It is obvious that these three\
    \ vectors are not the same due to \ntheir magnitude differences. Thus, it is concluded\
    \ that the cosine similarity measure may match \nwrong cases in the step of case\
    \ retrieval in the CBR system. \n \nIn terms of the distance-based measures, the\
    \ Euclidean distance also has certain drawbacks \n[205-207]. It may encounter\
    \ problems when the distances between compared vectors are the same. \nThis situation\
    \ is shown in Figure 13. \n39 \n \n \n \nFigure 13. An extreme circumstance when\
    \ measuring with the distance-based similarity. \nIn Figure 13, the target vector\
    \ is \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and it is compared with vectors \U0001D442\U0001D435\
    \n⃗⃗⃗⃗⃗ , \U0001D442\U0001D436\n⃗⃗⃗⃗⃗ , and \U0001D442\U0001D437\n⃗⃗⃗⃗⃗⃗ . \n\
    Though all these vectors have different magnitudes and orientations, the distance\
    \ between them \nis identical, indicating that vectors \U0001D442\U0001D435\n\
    ⃗⃗⃗⃗⃗ , \U0001D442\U0001D436\n⃗⃗⃗⃗⃗ , and \U0001D442\U0001D437\n⃗⃗⃗⃗⃗⃗  are all\
    \ similar to the vector \U0001D442\U0001D434\n⃗⃗⃗⃗⃗ . \nMeanwhile, it is acknowledged\
    \ that each attribute in an individual vector may offer different \ncontributions.\
    \ However, the Euclidean distance treats all involved attributes equally. Thus,\
    \ it is \nconcluded that the Euclidean distance measure can be further improved\
    \ to retrieve more accurate \ncases in the CBR systems. \nIn regards to the Manhattan\
    \ distance, the Chebyshev distance, and the Hamming distance, \nthey all have\
    \ the same drawbacks as the Euclidean distance measure. When the distance between\
    \ \ncompared vectors is the same, these measures can hardly tell which vector\
    \ is more similar to the \ntarget. \nReview of indexing methods \nAs a computational\
    \ data structure, an index enables a case to be stored and searched in \nmemory.\
    \ Case indexing assigns indexes to cases for facilitation their retrieval [208]\
    \ and it plays \na key role in case base maintenance. Many researchers have concerned\
    \ the indexing issues. \n40 \n \nHonigl and Kung [209] proposed a data quality\
    \ index method for maintaining the case base \nand avoiding storing redundant\
    \ cases. Three indices (average solutions per case, count of similar \nretained\
    \ queries, and missing values) were used to build an index for evaluating the\
    \ quality of the \ncase base. Wiltgen et al. [210] presented two indexing methods,\
    \ named functional indexing and \nstructural indexing. Both indexing methods generated\
    \ separate discrimination networks and had \nmechanisms for preventing the network\
    \ from having duplicate nodes. Similar past cases could be \nretrieved by adopting\
    \ the indexing methods and similarity measurements. Ahmad et al. [211] \nadopted\
    \ the locality sensitive hashing (LSH) technique for obtaining short binary codes\
    \ to \nrepresent medical radiographs. These hashing codes enabled indexing and\
    \ efficient retrieval in \nlarge scale image collections. Durmaz and Bilge [212]\
    \ proposed an approach named randomized \ndistributed hashing (RDH), which used\
    \ LSH in a distributed scheme. RDH randomly distributed \ndata to different nodes\
    \ on a cluster and used hash functions for indexing. Then the query sample \n\
    was locally searched in different nodes during the query stage. The experimental\
    \ result showed \nthat the proposed distributed scheme had great potential to\
    \ search images in large datasets with \nmultiple nodes. Ahmed and Sarma [213]\
    \ detected that accuracy of a system degraded with the \nincrease of the size\
    \ of database, therefore an indexing approach was designed to deal with the \n\
    feature deviation under noise. Considering the retrieval task, the proposed indexing\
    \ approach \nprovided a higher hit rate than existing approaches, even at a low\
    \ penetration rate. \nFrom the above review on current literatures, it is concluded\
    \ that indexing methods have \ngreat influence on case retrieval and case base\
    \ maintenance. LSH is especially popular in case \nindexing. LSH refers to use\
    \ a family of functions to map hash data points into buckets [214]. As \na result,\
    \ data points that are near to each other will be located in the same bucket with\
    \ high \nprobability, while data points that are far from each other will be likely\
    \ placed in different buckets. \nThis makes it easier and more efficient to identify\
    \ past cases that are similar to the new one. \nHowever, LSH does not guarantee\
    \ the accuracy of classified cases sometimes. For example, two \nsimilar data\
    \ points may be separated into different buckets due to the design of hashing\
    \ functions. \nThus, improvements on new indexing methods for case retrieval and\
    \ case base maintenance are \nexpected. It is worth noticing that none of above\
    \ literatures mentioned mining the internal \nassociations between past cases.\
    \ In other words, each case is still individually stored and searched. \nSummary\
    \ of review of case retrieval \nIn conclusion, though current similarity measures\
    \ and indexing methods have proved to be \neffective in case retrieval tasks in\
    \ case-based reasoning, they still require further development for \nenhancing\
    \ the accuracy, efficiency, and robustness of case retrieval. As a consequence,\
    \ a novel \ntriangular similarity measure is proposed in this thesis for overcoming\
    \ the drawbacks of current \n41 \n \nmeasures. Meanwhile, a fast retrieval algorithm\
    \ is developed for retrieving similar past cases by \ncomparing a fewer number\
    \ of cases. This retrieval algorithm is expected to achieve greater \nefficiency\
    \ and accuracy. \n2.3.3. Review of solution reuse and revision \nThe process of\
    \ reuse in the CBR 5R cycle concerns to propose a solution for resolving the \n\
    new problem based on solutions of retrieved similar past cases [215]. A CBR system\
    \ will be \ndegraded to a case retrieval system without reusing solutions of previous\
    \ cases. Reusing a \nretrieved case can be as easy as returning the retrieved\
    \ solution to the new problem without any \nchanges. This strategy is appropriate\
    \ for CBR applications in the classification tasks where each \nsolution is likely\
    \ represented frequently in the case base. However, it becomes more difficult\
    \ \nwhen there are significant differences between the new problem and the retrieved\
    \ cases. Under \nthis circumstance, the process of revising the retrieved solution\
    \ is required for adaptation purpose. \nThis is also the reason why researchers\
    \ usually concern the issue of solution reuse and revision in \ntheir research\
    \ works at the same time. For revision, it can be considered as a situation-action\
    \ pair. \nThe situation part contains the difference between the new and retrieved\
    \ problems, while the \naction part captures the update for the retrieved solution.\
    \ In general, three main categories of \nrevision methods are summarized [216]:\
    \ (i) substitution, (ii) transformation, and (iii) generative \nadaptation. \n\
    • \nSubstitution: This revision method simply replaces some parts of the retrieved\
    \ solution with \nnew values if appropriate. Lieber [217] applied the revision\
    \ theory to CBR for solution \nadaptation. This application claimed to keep as\
    \ much as possible from the solution to be \nrevised, while being consistent with\
    \ the domain knowledge. Ji et al. [218] improved the cost \nprediction accuracy\
    \ in multifamily housing projects by employing a CBR revision model. \nTheir revisional\
    \ formula was developed based on directly adjusting the proposed solution. \n\
    The process of revision focused on those data which had great influence on the\
    \ overall \nobjective. Yan et al. [219] presented an attribute difference revision\
    \ method in a CBR system. \nA support vector regression model was used to detect\
    \ the difference between the target case \nand similar past cases, and therefore\
    \ revising the value to generate the new solution. \n• \nTransformation: This\
    \ revision method alters the structure of the solution for adaptation by \nadding,\
    \ deleting, or replacing parts of the retrieved solutions, i.e. altering steps\
    \ in a plan. Yan \nand Wang [220] proposed a retrieval-based revision method for\
    \ the CBR classifiers. After \nthe reuse step, the target cases and suggested\
    \ solutions were divided into a trustworthy set \nand an untrustworthy set in\
    \ accordance with a threshold value of trustworthiness. Cojan and \nLieber [221]\
    \ applied a belief revision approach to CBR by defining an adaptation operator\
    \ \n42 \n \nthat took into account both the domain knowledge and the adaptation\
    \ knowledge. In \nparticular, a rule-based adaptation process was mentioned in\
    \ their proposal. Ontanon et al. \n[222] explained how revision can be performed\
    \ by attacking specific parts of a case and how \nthey can guide and prevent repentances\
    \ in future cases. It is also worth noting that some \nresearchers employed evolutionary\
    \ algorithms for solution revision. These research works \nhave been found in\
    \ [223-225]. \n• \nGenerative adaptation: Differing from substitution and transformation,\
    \ this revision method \nderives the new solution by replaying the method used\
    \ to derive the retrieved solution, instead \nof directly revising the retrieved\
    \ solution. Chen et al. [226] proposed a self-adaptive \nmechanism through an\
    \ incremental generative model, aiming at adapting the system \narchitecture to\
    \ the changing environments and contexts. Hong et al. [227] presented a \nprincipled\
    \ way to perform structured domain adaption for semantic segmentation. The \n\
    proposed conditional generator and the discriminator competed against each other,\
    \ so that \nthe generator learned to produce the result. Stuikys et al. [228]\
    \ introduced a stage-based \ngenerative learning object model with the capability\
    \ of automatic generation and adaptation. \nTheir proposal shared a similar structure\
    \ as the two-level generic models. \nThe characteristics of the above three revision\
    \ methods are summarized in Table 2 according \nto the review. \nTable 2. Characteristics\
    \ of three revision methods. \nCharacteristics \nSubstitution \nTransformation\
    \ \nGenerative adaptation \nComplexity \nLow \nHigh \nHigh \nAdaptability \nHigh\
    \ \nMedium \nHigh \nExtendibility \nLow \nHigh \nHigh \nDependence on \nretrieved\
    \ solutions \nHigh \nHigh \nLow \nApplicable scenario \nSimple \nComplex \nComplex\
    \ \nSolution reuse and revision is a challenging task in CBR. Revision methods\
    \ like substitution \nand transformation usually update the retrieved solution\
    \ by reasoning about how the differences \nbetween the new problem and past cases\
    \ are reflected in the adaptation process. Meanwhile, the \ngenerative adaptation\
    \ method is likely to perform a new reasoning process for providing an update\
    \ \nsolution. As a consequence, the acquisition of adaptation knowledge requires\
    \ substantial \nengineering efforts in the future.  \n43 \n \nIn conclusion, the\
    \ substitution method is adopted in this thesis for reusing and revising \nretrieved\
    \ solutions according to Table 2. \n2.3.4. Review of case retention \nRetention\
    \ is the process of storing the result as experiences in memory (i.e. a case base)\
    \ [216]. \nA CBR system is supposed to incorporate new useful results, as well\
    \ as forgetting worthless ones. \nAs the last step of the CBR cycle and also the\
    \ easiest part being ignored, the process of retention \nis not only closely related\
    \ to maintain the case base, but also has influence on the reasoning \nefficiency\
    \ and accuracy. Three issues have been pointed out as follows [229]. \n• \nIf\
    \ a worthless case is added into the case base instead of forgetting it, it may\
    \ bring harmful \nconsequences because noisy cases can lead to difficulties for\
    \ retrieval tasks. \n• \nIf a useful case is forgotten instead of retaining it,\
    \ it may weaken the ability of revision in the \nCBR systems. \n• \nIf new cases\
    \ are continuously added to the case base without adopting a proper retention\
    \ \nstrategy, it may also reduce retrieval efficiency. \nGenerally, there are\
    \ two main strategies adopted in the process of retention, named \nremembering\
    \ (addition) [230] and forgetting (deletion) [231] strategies. Yan et al. [232]\
    \ proposed \nan improved dynamic maintenance method for the CBR systems. They\
    \ imitated the memory \nfunction of the human brain to selectively save new cases,\
    \ update the forgotten values, and \nintentionally delete the old cases. These\
    \ policies were proved to significantly reduce the time and \nspace complexity,\
    \ as well as to improve the accuracy of the CBR classifiers. Yang and Zhu [233]\
    \ \naddressed the issue of keeping the case base concise and complete by defining\
    \ a case-addition \nmaintenance policy. Their proposal demonstrated that the coverage\
    \ of the case base computed by \nthe case-addition policy is better than the optimal\
    \ case-base coverage by a fixed lower bound. \nYang and Wu [234] presented a case\
    \ base maintenance method that partitioned cases into clusters. \nNew case bases\
    \ can be constructed based on those clusters, resulting in a smaller scale. Therefore,\
    \ \ncase retrieval tasks can be easily performed within the contents of the new\
    \ case base. Perner [235] \nalso took advantage of the clustering theory and introduced\
    \ case base maintenance method based \non the approximate graph subsumption. Two\
    \ strategies were applied, named divide-and-conquer \nand split-and-merge, allowing\
    \ to better fit the hierarchy to the actual structure of the application. \nTsang\
    \ and Wang [236] concerned the issue of removing redundant cases for maintaining\
    \ the CBR \nsystems. Their proposal was on the basis of the generalization capability\
    \ of cases, aiming at \nidentifying representative cases. The experimental result\
    \ showed the effectiveness of removing \nredundant cases, as well as the ability\
    \ of preserving a satisfying degree of the accuracy of solutions. \nSalamo and\
    \ Golobardes [237] introduced different sort-out techniques for case base maintenance.\
    \ \n44 \n \nTheir proposal was built upon a rough set competence model. The ultimate\
    \ objective was to \nmaintain the competence of the case base and to reduce its\
    \ size as much as possible. \nIn conclusion, it is acknowledged that both addition\
    \ and deletion strategies play significant \nroles in case retention and case\
    \ base maintenance. As a consequence, this thesis is going to adopt \nboth strategies\
    \ in the CBR system. Meanwhile, due to the adoption of an associated case \nrepresentation,\
    \ this thesis also considers the update of these associations when retaining new\
    \ cases \nin the case base. \n2.3.5. Summary of the case-based reasoning approach\
    \ \nAfter deeply reviewing the CBR approach, it is found that each step (represent,\
    \ retrieve, reuse, \nrevise, and retain) within the CBR cycle is under researched.\
    \ Though current contributions have \nproved to be effective in CBR applications\
    \ to some extent, their shortcomings cannot be ignored \nand require further improvements.\
    \ Most importantly, these contributions have provided valuable \ninspirations\
    \ for developing new design of CBR systems for smart agriculture. For applying\
    \ the \nCBR approach to model an agricultural DSS, some issues are listed as follows.\
    \ \n• \nCase representation: Interrelations between cases are ignored in most\
    \ case representation \nmethods. However, these interrelations not only enrich\
    \ the content of an individual case, but \nalso enable fast case retrieval. Consequently,\
    \ none of the existing approaches fulfil our \nrequirements and a new case representation\
    \ method is expected. \n• \nCase retrieval: Current case retrieval algorithms\
    \ usually intend to traverse all the past cases \nfor identifying a list of similar\
    \ ones, leading to low retrieval efficiency. Meanwhile, current \nsimilarity measures\
    \ have natural defect and result in wrong retrieval results. When the \nsimilarity\
    \ measurement is the same, it is hard to tell the differences between compared\
    \ cases. \nThus, the improvements on proposing new similarity measures are expected.\
    \ \n• \nSolution reuse and revision: The acquisition of adaptation knowledge requires\
    \ substantial \nengineering efforts. Because the solutions of retrieved past cases\
    \ do not always fit to the new \nproblem. Though three main categories of revision\
    \ methods have been developed, the \nadaptation process varies in the content\
    \ of problem statements and structures of solutions. As \na consequence, reusing\
    \ and revising solutions in the CBR system is a challenging task. \n• \nCase retention:\
    \ Though addition and deletion strategies have been well developed, few \nliteratures\
    \ addressed the issue of retaining the learned cases with an associated case structure.\
    \ \nProposing a new mechanism for updating the association is necessary as well.\
    \ \nLastly, for applying the CBR approach to develop a DSS for agriculture, the\
    \ seven problems \nstated in Section 1.3 should be also taken into account. \n\
    45 \n \n3 \nThe framework of \ndecision support systems \nfor smart agriculture\n\
    46 \n \nThis chapter presents the overview of the AFarCloud platform, as well\
    \ as how a specific \ndomain decision support system serves the AFarCloud platform\
    \ by integrating an algorithm \nmanage component and an algorithm toolbox component.\
    \ \n3.1. General architecture of the AFarCloud platform \nAs the decision support\
    \ system for smart agriculture is developed within the AFarCloud \nproject, it\
    \ is necessary to understand the architecture of the AFarCloud platform, shown\
    \ in Figure \n14. \n \nFigure 14. The architecture of the AFarCloud platform.\
    \ \nThe AFarCloud platform consists of three major functional components: (i)\
    \ the farm \nmanagement system, (ii) the semantic middleware, and (iii) deployed\
    \ hardware. Apart from these \nfunctional components, the AFarCloud platform also\
    \ interconnects with other data sources like \nthird-party data and legacy systems\
    \ databases.  \n47 \n \n3.1.1. The semantic middleware in the AFarCloud platform\
    \ \nIn Figure 14, the semantic middleware is a software layer used to hide the\
    \ underlying \ncomplexity of hardware and services in distributed systems. As\
    \ a consequence, the application \nlayers can access resources in a unified way.\
    \ In the AFarCloud platform, the middleware uses \nsemantic models which are specified\
    \ by an ontology to abstract the heterogeneity of the \nunderlying resources and\
    \ to ensure that all the information is stored according to a common \ninformation\
    \ model that guarantees interoperability. \nThe semantic middleware acts as a\
    \ communication centralizer, disseminating messages \nbetween the farm management\
    \ system and the hardware layer. The semantic middleware is also \nin charge of\
    \ unifying, processing, and analyzing the data coming from, or directed to, different\
    \ \ntypes of cyber-physical systems deployed in the AFarCloud platform. \nMost\
    \ of the AFarCloud middleware components are hosted by the cloud infrastructure\
    \ \ndeployed in the project, to take advantage of the features provided by cloud\
    \ resources. Cloud \ncomputing is based on the use of remote serves hosted on\
    \ the Internet to manage infrastructure \nand data, which provides promising benefits\
    \ like flexibility and scalability in infrastructure design, \ncost reduction,\
    \ and guaranteed reliability. Other components of the middleware need to be \n\
    deployed at the edge in the facilities of the farm. These components are listed\
    \ in the following. \n• \nImage processing platform: Due to the large size of\
    \ the images processed by this component \nand taken by the UAVs, the loading\
    \ of these images is carried out offline (i.e. through a \nmemory stick), to minimize\
    \ errors and communication costs in the transmission of files and \nto speed up\
    \ the loading process. \n• \nDDS manager: This module is responsible for processing\
    \ the real-time communication with \nUAVs. Therefore, this module should be deployed\
    \ as close as possible to the place where \ndata are generated, in order to minimize\
    \ latencies. \n• \nData pre-processor: For complex sensors, pre-processing data\
    \ is helpful to reduce latency as \ndata do not have to traverse over the network\
    \ to the cloud for processing. By only sending \nimportant data over the network,\
    \ the edge computing reduces both the data traversing the \nnetwork, the processing\
    \ time, and the cost of both transmission and storage. For simple \nsensors that\
    \ do not need pre-processing, it will be done in the cloud. \nThe semantic middleware\
    \ also provides the following interfaces to the rest of elements of \nthe AFarCloud\
    \ architecture. \n \n48 \n \n• \nInterface with the farm management system: \n\
    o Apache Thrift interface: For querying AFarCloud repositories, sending missions\
    \ to \nvehicles, sending commands to actuators, and collecting mission results,\
    \ sensor \nmeasurements, and alarms. \no Web Map Service (WMS) interface: For\
    \ retrieving images from the image catalogue. \no Apache Kafka interface: For\
    \ the DSS to consume streaming data in real-time and for \nenabling real-time\
    \ analytics. \n• \nInterface with the hardware layer: \no Data distribution service\
    \ (DDS) interface with UAVs and UGVs: For sending \ncommands and collecting results\
    \ and alarms. The DDS communications are managed in \nreal-time. \no ISOBUS interface\
    \ with ISOBUS systems: For sending agricultural tasks and collection \nresults.\
    \ \no MQTT interface with IoT compatible devices: For collecting measurements\
    \ from \nsensors, sending commands to actuators, collecting telemetry from tractors.\
    \ The MQTT \ncommunications are managed in real-time. \no Representational state\
    \ transfer (REST) interface with IoT compatible devices: For \ncollecting sensors\
    \ measurements. \n3.1.2. The hardware layer in the AfarCloud platform \nIn Figure\
    \ 14, the hardware layer can be divided into the following categories. \n• \n\
    Sensors: Multispectral sensor, thermal camera, soil sensor, environmental sensor\
    \ (i.e. air \ntemperature, air humidity, wind, CO2, light intensity, etc.), vehicle\
    \ data, and so on. \no Standalone sensors. \no Collars: Smart neck collars for\
    \ monitoring cows. \no Wireless sensor network (WSN): A group of spatially dispersed\
    \ and dedicated sensors \nfor monitoring and recoding the physical conditions\
    \ of the environment. \n• \nActuators: Devices that are responsible for moving\
    \ and controlling a mechanism or a system. \nSome examples included in the actuator\
    \ category refer to the air normal temperature and \npressure (NTP) actuator (for\
    \ taking filtering actions and improving the indoor air quality), \nwater NTP\
    \ actuator (for bio-stimulating the crop growth), greenhouse rooftop inflator\
    \ (for \nautomatically inflate the roof and protect the greenhouse from rain/hail\
    \ weather), etc. \n• \nGround vehicles (GVs): three different types of GVs are\
    \ covered by the AfarCloud platform. \n49 \n \no UGVs: These vehicles are able\
    \ to autonomously execute missions defined by the farm \nmanagement system. Missions\
    \ involve the autonomous movement of UGVs around certain \nareas of the demonstrators.\
    \ \no Legacy systems: GVs are able to autonomously execute a list of agricultural\
    \ tasks \ndefined by the farm management system. It is not the goal of those missions\
    \ to implement \nautonomous navigation (due to the lack of auto-steer abilities\
    \ of tractors, i.e. marching to a \nwaypoint). Two different types of legacy GVs\
    \ are considered in the AfarCloud platform. \n▪ \nISOBUS systems: Legacy GVs are\
    \ able to semi-autonomously \nexecute agricultural tasks carried out by the ISOBUS\
    \ compliant \nimplements of ISOBUS tractors. \n▪ \nTractors: Legacy GVs are able\
    \ to execute and configure specific \ncommands and parameters of the CAN bus of\
    \ the tractors. \n• \nUAVs: Drones are able to autonomously execute missions defined\
    \ by the farm management \nsystem, that consists of a list of commands. Missions\
    \ involve the autonomous movement of \nUAVs around certain areas of the demonstrators.\
    \ \n3.1.3. The farm management system in the AfarCloud platform \nIn Figure 14,\
    \ the farm management system (in the green block) is composed of a mission \n\
    management tool (MMT), a decision support system, a system configurator, and applications\
    \ for \nusers to manage and monitor the whole system, plan cooperative missions,\
    \ configure key \nhardware components, and make decisions. The internal connection\
    \ within the farm management \nsystem is shown in Figure 15. The MMT, the DSS,\
    \ and the system configurator are connected \nthrough a graphical user interface\
    \ plugin, while the rest of components communicates with each \nother through\
    \ the REST interface, Apache Thrift interface, and WMS protocol.  \n \n50 \n \n\
    \ \nFigure 15. The internal connection within the farm management system. \n \n\
    In Figure 15, the farm management system consists of the following components.\
    \ \n• \nMMT: The MMT component is used to define the conditions for cooperative\
    \ missions \ninvolving UAVs and UGVs ranging from fully autonomous UGVs to ISOBUS\
    \ systems. The \nvarious MMT solution will allow the user to access both services\
    \ in the MMT as well as \nthose belonging to the decision support system and system\
    \ configuration modules. \nMeanwhile, there is a main MMT for the operators to\
    \ process data, plan a mission, monitor \na mission, evaluate the results and\
    \ work with the decision support system, and two specific \nmobile MMT versions\
    \ for monitoring vehicles’ missions, the UAV-MMT for the pilots of \nthe UAVs\
    \ and the tractor-MMT, dedicated to in-vehicle usage. \n• \nDSS: The DSS component\
    \ is employed to assist users in making decisions during pre-\nmission, ongoing-mission,\
    \ and post-mission. \n• \nSystem configurator: The system configurator is adopted\
    \ to configure the AFarCloud \ninstance of each farm, to provide for the registration\
    \ of the farm inventory, such as UGVs \nand ISOBUS systems, UAVs and devices (sensors\
    \ and actuators), and to perform pre-mission \nstatus control of the vehicles\
    \ that are involved in a mission. \n• \nApplications: The designed applications\
    \ are supposed to provide users with functions of \nmanaging and monitoring the\
    \ whole AFarCloud system. \n \n51 \n \n3.2. Specific domain DSS in the AFarCloud\
    \ platform \nSustainable agriculture production and processing systems have become\
    \ more complex with \ninvolvement of biological, chemical, physical processes,\
    \ such as soil, water, climatic scenarios \nand crop management practices respectively.\
    \ A DSS can offer a framework within the complex \nsystems. By being represented\
    \ in a structured way, the complex systems can be more easily \nunderstood. \n\
    As concluded in Section 2.2, a DSS is an interactive computer-based system that\
    \ helps \ndecision makers who use communication technologies, data, documents,\
    \ knowledge, and models \nto identify and solve problems, as well as complete\
    \ decision process tasks. As a general term for \nany computer application, a\
    \ DSS is supposed to have the ability of improving the decision-making \nprocess.\
    \ Over the past 40 years, numerous researchers have conceptualized and classified\
    \ DSSs \nin three different categories. \n• \nPassive DSS: A system of aids to\
    \ decision-making process, however, it cannot carry out an \nexplicit decision,\
    \ suggestion, or solution. \n• \nActive DSS: A system of aids to carry out an\
    \ explicit decision, suggestion, or solution. \n• \nCooperative DSS: A system\
    \ that allows decision-makers to modify, supplement, and refine \nthe decision\
    \ supports provided by the system, before sending them back to the system for\
    \ \nvalidation. \nIn the AFarCloud platform, the DSS is designed as a cooperative\
    \ one. The main objective of \nthe AFarCloud DSS is to gather and analyze available\
    \ data, which are collected from sensors and \nretrieved from historical datasets.\
    \ By taking advantage of all the data, the DSS is able to plan, and \ninterpret\
    \ ongoing processes, therefore helping users to make correct decisions, analyze\
    \ the \noutcome, and finally converting raw data into practical knowledge. Some\
    \ DSS use cases in the \nAFarCloud platform are concluded as follows, including\
    \ decision support on pre-mission, \nongoing-mission, and post-mission. \n• \n\
    Pre-mission: This refers to the use cases before starting the mission. \n52 \n\
    \ \no Consulting the forecast: In order to keep the integrity of the vehicles\
    \ and structure, the \nDSS shall consult both the forecast and the current local\
    \ weather, and then warn the user if \nthe safety conditions are met or not (i.e.\
    \ heavy wind and rain). \no Listing the programmed missions, the available vehicles,\
    \ and their state: When \nplanning a mission, the user needs to be aware of the\
    \ pre-programmed missions to prevent \noverlaps. Meanwhile, the number of available\
    \ vehicles and their state (i.e. battery level) \nshould be checked as well. \n\
    o Checking the equipment: Before starting the mission, a set of tests on the vehicles\
    \ and \nequipment should be performed, in order to ensure their proper functions.\
    \ Depending on \nthe target of missions, the equipment to be tested may vary.\
    \ The results of these checks \nmust be reported to the user. \n• \nOngoing-mission:\
    \ This refers to the use cases when the mission is being executed. \no Reporting\
    \ the sensor data: The DSS should continuously report to the users the main \n\
    sensor data for detecting potential problems in real-time in case the automatic\
    \ algorithm \nfailed to do so. \no Detecting possible problems after processing\
    \ the gathered data: Whenever some \nproblems are detected (i.e. extremely dry\
    \ area), the user must be warned to take certain \nactions if appropriate. The\
    \ action might be asking for a more detailed survey. \no A non-critical sensor\
    \ stops working: Whenever a non-critical sensor stops working, the \nuser should\
    \ be notified. Then, the user can verify the warning and decide if the mission\
    \ \nmay continue or not without the data from that sensor. \no The level of battery\
    \ is not enough to finish the mission: Due to unexpected situations \n(i.e. an\
    \ abnormal energy consumption), the calculations in pre-mission stage for the\
    \ battery \nlevel might fail. If this event is detected during the mission (but\
    \ the battery is not in a \ncritical level), the user may decide either to continue\
    \ the mission until the vehicle reaches \nthe failsafe battery level and return\
    \ or ask for an immediate return and abort the current \nmission. \no Reporting\
    \ the vehicle and mission state: A DSS must provide the information about \nthe\
    \ vital sensors of the vehicles, as well as the current state of the missions.\
    \ \n• \nPost-mission: This refers to the use cases when the mission has been completed.\
    \ \no Saving the mission parameters: If a mission was successfully completed,\
    \ the DSS \nshould ask to the user if the mission profile is to be saved and used\
    \ in future operations. \no Data processing: Although the outputs of each sensor\
    \ are predefined, the user may ask \nto generate additional outputs (if the corresponding\
    \ sensors were used during the mission). \no Downloading/displaying outputs: The\
    \ user should have the option to download or view \nthe outcomes of the mission.\
    \ \n53 \n \no Generating notifications based on the processed data: The DSS may\
    \ generate a \nmission report, indicating the main outcomes of the mission. Using\
    \ the previously known \ninformation, the new data is compared with it and the\
    \ automatic analysis can be done to \ngenerate suggestions for future operations.\
    \ \n3.3. Framework of the AFarCloud DSS \nThe framework of the DSS within the\
    \ farm management system is presented in Figure 16. \nTwo main components are\
    \ involved in this framework, including an algorithm manager and an \nalgorithm\
    \ toolbox. \n• \nAlgorithm manager: This component is in charge of managing the\
    \ decision support \nalgorithms and interacting with users through the MMT. The\
    \ users can configure available \nalgorithms by sending commands like listing\
    \ registered algorithms, starting an algorithm, \nstopping an algorithm, and checking\
    \ the status of a running algorithm. \n• \nAlgorithm toolbox: This component registers\
    \ the decision support algorithms and provides \nthe access to the cloud databases\
    \ and external databases or services. Data retrieved from these \ndatabases are\
    \ treated as inputs to the selected algorithm for supporting their computation.\
    \ \nUnder the circumstance that the algorithm fails to provide any results, the\
    \ algorithm toolbox \nwill send an exception to the algorithm manager, asking\
    \ for any further requests. In general \ncases, the algorithm forwards the results\
    \ to the algorithm manager. \n \nFigure 16. The framework of the decision support\
    \ system. \n54 \n \nIn Figure 16, the core of the DSS counts on the algorithms,\
    \ since the decision supports are \ngenerated by these algorithms. Based on the\
    \ characteristics, the algorithms can be classified into \ntwo categories. \n\
    • \nCalculation of complex metrics for crop and animal welfare from raw data:\
    \ Note that these \ncomplex metrics are useful only if they are solving the right\
    \ problem and in a way that is \nunderstood by the users. For example, for calculating\
    \ the percentage of water stress in crop, \nthe metrics should include: (i) soil\
    \ humidity in several depths, (ii) solar radiation, (iii) amount \nof watering,\
    \ (iv) amount of rainfall, (v) soil type, etc. \n• \nRecommendation algorithms:\
    \ This stage represents the next step after calculating the output \nmentioned\
    \ above. The goal of the recommendation algorithm is to integrate metrics and\
    \ \nsuggest different alternatives, or solutions to the users, in order to help\
    \ them reach an \nobjective. An example of this recommendation could be when the\
    \ crops are irrigated \nconsidering the following: (i) levels of water stress\
    \ forecasting next days, (ii) low levels of \ndisease risk, (iii) expected amount\
    \ of irrigation, etc. \nIt is worth mentioning that data for both types of algorithms\
    \ are stored in the AFarCloud \nrepository. The DSS itself does not store any\
    \ data, although algorithms could use local \nrepositories for their own calculations.\
    \ \nIn conclusion, the DSS framework provides the architectural supports for integrating\
    \ \ndifferent decision support algorithms with great scalability, interoperability,\
    \ and robustness. This \nthesis focuses on designing and implementing an algorithm\
    \ (embedded in the algorithm toolbox) \nby adopting the CBR approach for providing\
    \ users with decision supports on managing farming \noperations. \n55 \n \n4 \n\
    An improved case-\nbased reasoning approach \nfor the decision support \nsystem\n\
    56 \n \n    As detected in Section 2.3, the typical CBR approach might be insufficient\
    \ to provide \naccurate results due to the improper case representation method,\
    \ the imprecise similarity measure, \nthe low-efficient case retrieval algorithm,\
    \ the poor solution reuse and revision strategy, and the \nrough case retention\
    \ approach. As a consequence, this thesis tries to improve each step within the\
    \ \nCBR circle for better serving decision support systems in smart agriculture.\
    \ In the following \nsubsections, an associated case representation formalism\
    \ is proposed for overcoming the \nshortcomings of the feature vector representation.\
    \ A triangular similarity measure and a fast case \nretrieval algorithm is proposed\
    \ for improving the efficiency and accuracy of case retrieval. A \nlearning-based\
    \ approach is proposed for solution reuse and revision. Lastly, an associated\
    \ case \nretention approach is presented for storing learned cases. \n4.1. An\
    \ associated case representation method \nThe proposed associated case representation\
    \ is on the basis of the feature vector \nrepresentation. Because agricultural\
    \ cases are usually composed of representative features and \ncorresponding values,\
    \ like soil moisture, soil temperature, air humidity, sunlight and radiation.\
    \ \nHowever, differing from the feature vector representation, this proposal extends\
    \ the “problem-\nsolution” structure with an additional association part. Consequently,\
    \ the proposed association \ncase representation is under the structure of “problem-solution-association”.\
    \ \n4.1.1. Generation of the association table \nThe association part enables\
    \ a single case to be interconnected with other relevant cases, \naiming at mining\
    \ the relationships between cases. Within a case base, a past case could be similar\
    \ \nor dissimilar to several other cases. An example of a case base is given in\
    \ Table 3. This case base \ncontains six past cases and each case has four features.\
    \ After normalization [238], all the cases \nare visualized in Figure 17. \nTable\
    \ 3. An example of a case base. \nCase ID \nFeature 1 \nFeature 2 \nFeature 3\
    \ \nFeature 4 \ncase 1 \n10 \n103 \n55 \n21 \ncase 2 \n15 \n99 \n79 \n98 \ncase\
    \ 3 \n11 \n105 \n52 \n22 \ncase 4 \n18 \n60 \n89 \n105 \ncase 5 \n9 \n112 \n60\
    \ \n25 \ncase 6 \n16 \n153 \n95 \n44 \n57 \n \n \nFigure 17. The visualization\
    \ of six cases in the case base. \nAccording to the visualization result in Figure\
    \ 17, it is obvious that case 1 is similar to cases \n3 and 5 because their data\
    \ deviation is small. Meanwhile, case 1 is dissimilar to cases 4 and 6 \nbecause\
    \ their data distribution has major differences. This result supports that a past\
    \ case could \nbe similar or dissimilar to several other cases. Consequently,\
    \ an association table for the case base \ncan be constructed in Table 4 and the\
    \ association connection between each case is presented in \nFigure 18. Each past\
    \ case is associated with similar and dissimilar cases. \nTable 4. The association\
    \ table for the case base. \nCase ID \nSimilar association \nDissimilar association\
    \ \n1st similar \n \n2nd similar \n \n1st dissimilar \n \n2nd dissimilar \n \n\
    case 1 \ncase 3 \n \ncase 5 \n \ncase 4 \n \ncase 6 \n \ncase 2 \ncase 4 \n \n\
    case 6 \n \ncase 3 \n \ncase 5 \n \ncase 3 \ncase 1 \n \ncase 5 \n \ncase 4 \n\
    \ \ncase 2 \n \ncase 4 \ncase 2 \n \nNULL \n \ncase 1 \n \ncase 3 \n \ncase 5\
    \ \ncase 3 \n \ncase 1 \n \ncase 4 \n \ncase 2 \n \ncase 6 \ncase 5 \n \ncase\
    \ 3 \n \ncase 4 \n \ncase 2 \n \n58 \n \n \nFigure 18. The association connection\
    \ between past cases. \nApart from the case 4, each past case is associated with\
    \ two similar cases. Because the \ncompetence of this case base is insufficient.\
    \ In other words, this case base does not cover enough \npast cases. However,\
    \ this situation rarely happens when more cases are retained in the case base.\
    \ \nIn Table 4, two types of associations are defined as follows. \n• \nSimilar\
    \ association: This association indicates that the features of compared two cases\
    \ have \ngreat commonalities. The IDs of these similar cases are stored in the\
    \ similar association, \nbuilding interconnections to the source case. \n• \n\
    Dissimilar association: This association specifies that there are significant\
    \ differences \nbetween the features of compared two cases. The IDs of these dissimilar\
    \ cases are stored in \nthe dissimilar association. \nThis association table is\
    \ constructed for the purpose of enabling fast case retrieval in the \nretrieval\
    \ process. In the typical case retrieval algorithm, the new case is evaluating\
    \ by traversing \nall the past cases in the case base, consequently leading to\
    \ low retrieval efficiency. However, with \nthe help of this association table,\
    \ the new case has the chance of being compared with the \nassociated cases preferentially.\
    \ For instance, once a new case is reported and the past case 1 is \ntreated as\
    \ the entry-point case for comparison. On the one hand, if this new case is considered\
    \ \nsimilar to the past case 1, then cases 3 and 5 are selected for being compared\
    \ with the new case. \nBecause potential similar cases might exist among the similar\
    \ association of the past case 1. In \n59 \n \nother words, the similar association\
    \ offers the possibility of evaluating the similarity between past \ncases within\
    \ a smaller range, instead of traversing the whole case base. As a result, the\
    \ number of \ncompared cases can be reduced and the retrieval efficiency can be\
    \ improved. On the other hand, \nif this new case is considered dissimilar to\
    \ the past case 1, then cases 4 and 6 are selected for \nbeing compared with the\
    \ new case. The reason why ignoring the cases in the similar association \nis\
    \ that there is a very low chance that the desired outputs are cases 3 and 5.\
    \ However, the cases in \nthe dissimilar association might be the target one.\
    \ Thus, the dissimilar association is able to adjust \nthe searching trajectory\
    \ for the retrieval process and therefore assist the new case in matching a \n\
    similar case as soon as possible. \n4.1.2. Distinction between the association\
    \ table and other techniques \nIt is important to clarify two issues for the association\
    \ table: (i) the distinction between the \nsimilar association and LSH, and (ii)\
    \ the distinction between the dissimilar association, the rough \nset theory,\
    \ and filtering techniques. \nFirstly, regarding the former issue, as introduced\
    \ in Section 2.3.2, LSH uses a family of hash \nfunctions to map data points into\
    \ buckets. The objective is to classify data points that are near to \neach other\
    \ into the same bucket, while locate data points that are far from each other\
    \ into different \nbuckets. This is the major difference between the general hashing\
    \ approach and LSH (See Figure \n19). \nIn Figure 19, the general hashing approach\
    \ simply maps data points into different buckets \nwithout any consideration of\
    \ their distances. For example, though blue and yellow points are near \nto each\
    \ other, they are still grouped in different buckets. However, the blue and yellow\
    \ data points \nare mapped into the same bucket by using the LSH approach. Under\
    \ this circumstance, LSH can \nbe used for data clustering and nearest neighbor\
    \ search tasks and it can achieve greater efficiency \nthan typical searching\
    \ techniques. LSH has a wide range of applications, including near-duplicate \n\
    detection (i.e. to deduplicate large quantities of documents and webpages) [239],\
    \ genome-wide \nassociation study (i.e. to identify similar gene expressions in\
    \ genome databases) [240], large-scale \nimage search (i.e. to identify similar\
    \ images for clustering) [241], and audio/video fingerprinting \n(i.e. to extract\
    \ audio fingerprint for detecting similar songs) [242]. \nHowever, it is noted\
    \ that LSH does not guarantee to present the exact answer due to the \ndesign\
    \ of hash functions. If two near data points are grouped into different buckets,\
    \ LSH can only \nretrieve one of them. Meanwhile, LSH does not build any actual\
    \ relationships between data points. \nDiffering from the LSH approach, the similar\
    \ association built in the proposal establishes real \nconnections between past\
    \ cases. The similar association does not rely on any mapping functions \n60 \n\
    \ \nnor indexing techniques. This association is built upon similarity measurements\
    \ between past \ncases. Therefore, it is guaranteed that similar past cases are\
    \ connected to each other. \n \nFigure 19. Principles of the general hashing and\
    \ locality sensitive hashing approaches. \n \nSecondly, regarding the latter issue,\
    \ there is a clear distinction between the dissimilar \nassociation, the rough\
    \ set theory and filtering techniques. In case retrieval tasks, the rough set\
    \ \ntheory and filtering techniques are helpful because they can avoid comparing\
    \ irrelevant cases.  \nOn the one hand, as an approximation technique, the rough\
    \ set theory defines the lower and \nupper approximations in the original dataset\
    \ (See Figure 20). \n \nFigure 20. Principles of the rough set theory. \nIn Figure\
    \ 20, it is shown that a boundary region can be formed by the lower and upper\
    \ \napproximations, and the rough set theory therefore enables users to have access\
    \ to the dataset they \nare interested in. Research work on applying the rough\
    \ set theory to CBR can be found in \n[243,244]. It is worth noting that other\
    \ regions (marked in yellow in Figure 20) are out of \n61 \n \nconsideration even\
    \ though they may contain relevant information. In other words, other regions\
    \ \ncan be regarded as the deletion part from the original dataset. Besides, one\
    \ of the disadvantages \nof the rough set theory is that it is usually applicable\
    \ to the categorical data. Meanwhile, for \nextracting the data that users are\
    \ interested in, the approximations have to be defined manually. \nOn the other\
    \ hand, the dissimilar association differs from existing filtering techniques\
    \ as well. \nSome researchers tried to set a collection of rules to extract desired\
    \ data [245,246]. These rules \nwere defined based on the observation of data\
    \ and researchers’ own interests (See Figure 21).  \n \nFigure 21. Principles\
    \ of the filtering technique. \n \nIn Figure 21, three filters are used to classify\
    \ the data. After each filtering process, irrelevant \ndata are removed from the\
    \ original dataset and the final dataset only contains the desired data. \nHowever,\
    \ the major drawback of the filtering technique is that the collections of rules\
    \ need to be \ndefined manually. In particular, the definition of the rule sets\
    \ varies in users’ requirements. \n \nDiffering from the rough set theory and\
    \ filtering techniques, the dissimilar association \ndefined in this thesis does\
    \ not remove nor delete any irrelevant data. The dissimilar association \naims\
    \ at building connections between past cases according to the similarity measurements.\
    \ Owing \nto this connection, the searching trajectory of case retrieval can be\
    \ adjusted. It is assumed that if \na new case is dissimilar to a past case, then\
    \ this new case might be potentially similar to the cases \nthat are dissimilarly\
    \ associated with this past case. A simple example is presented in Figure 22 \n\
    for demonstrating why the dissimilar association is helpful in the case retrieval\
    \ task. In this \nexample, the user would like to query about the rice disease\
    \ from a case base. There are two rice \ndiseases in this case base, named “brown\
    \ spot” (see ① and ② in Figure 22) and “blast” (see ③ \nand ④ in Figure 22). Each\
    \ image has one similar association and two dissimilar associations. \n \nIn Figure\
    \ 22, if the query sample (brown spot) is firstly compared with the stored image\
    \ ①, \nthe similarity measurement will indicate that the compared images are similar,\
    \ it is a natural sense to \ncompare the query sample with the image ② which is\
    \ similar to the image ①. However, if the query \nsample is firstly compared with\
    \ the image ④, the similarity measurement will indicate that the \ncompared images\
    \ are dissimilar. Therefore, there is a low chance that the associated similar\
    \ image ③ \n62 \n \nand the query sample have much commonalities. As a consequence,\
    \ the query sample is going to be \ncompared with the dissimilar associations\
    \ (images ① and ②) of the image ④. Under this \ncircumstance, the query sample\
    \ avoids being compared with the image ③, and therefore to accelerate \nthe retrieval\
    \ task. After retrieving the most similar image, the user will be notified that\
    \ the result of \nthe query sample is “brown spot”. \n \nFigure 22. An example\
    \ of querying the disease type by using dissimilar associations. \n \nIt is worth\
    \ noting that when applying the rough set theory or the filtering technique to\
    \ the \nabove example, images ③ and ④ are usually removed from the original dataset.\
    \ A boundary region \n(in the rough set theory) or a final dataset (in the filtering\
    \ technique) is generated for comparison. \nHowever, the association in the proposal\
    \ is built between data, no matter they are similar or dissimilar, \nall the data\
    \ are remained in the dataset. \n4.1.3. Content of agricultural cases \nThe content\
    \ of agricultural cases varies in their applications like pest management, fertilizer\
    \ \napplication, and irrigation scheduling. For instance, an agricultural case\
    \ of irrigation scheduling \ncares about variables like soil moisture, crop breed,\
    \ water consumption rate, and required water \nvolume [247]. While, an agricultural\
    \ case of pest management usually takes into account variables \nlike pest breed,\
    \ crop breed, infected area, and previous treatment [248]. \nJudging from the\
    \ above examples, it is concluded that the general content of agricultural \n\
    cases should contain the following. \n63 \n \nFirstly, environmental variables\
    \ usually include soil and meteorological information. \nEnvironmental variables\
    \ play a significant role in agricultural cases because these variables can \n\
    affect the growth of plants and operation performances. For example, the rising\
    \ temperature can \npossibly shorten the growth circle of crops. Agronomists estimate\
    \ that the growth circle of rice \nwill shorten by one more week if the temperature\
    \ increases by one Celsius [249]. Another \nexample may refer to deploying UAVs\
    \ for performing agricultural tasks. When the wind speed \nreaches over 10 m/s.\
    \ it is not applicable for launching UAVs due to safety concerns [250]. Thus,\
    \ \nsome key features of environmental variables in agricultural cases are summarized\
    \ in Table 5. \nTable 5. Key features of environmental variables in agricultural\
    \ cases. \nFeature category \nFeature name \nContent \nSoil variables \nSoil texture\
    \ \nThis variable refers to the determination of the soil \nclasses based on their\
    \ physical texture, including \nclay, silt, very fine sand, fine sand, medium\
    \ sand, \netc. \nSoil fertility \nThis variable refers to the ability of soil\
    \ to sustain \nagricultural plant growth. It concerns features like \nsoil depth,\
    \ internal drainage, and concentrations of \nplant nutrients. \nSoil moisture\
    \ \nThis variable refers to the measurement of the \nvolumetric water content\
    \ in the soil. \nSoil temperature \nThis variable refers to the measurement of\
    \ the \nwarmth in the soil. \nSoil pH \nThis variable refers to the measurement\
    \ of the \nconcentration of hydrogen ions in the soil. \nOrganic matter \nThis\
    \ variable refers to the organic matter component \nof soil, such as plant and\
    \ animal detritus, cells and \ntissues, and substances. \nMeteorological \nvariables\
    \ \nSolar irradiance \nThis variable refers to the power per unit area \nreceived\
    \ from the sun in the form of electromagnetic \nradiation in the wavelength range.\
    \ It can be \nmeasured by luminous intensity and duration time. \nPrecipitation\
    \ \nThis variable refers to any product of the \ncondensation of atmospheric water\
    \ vapor that falls \nunder gravity from clouds. It is usually measured by \n64\
    \ \n \nrainfall (in millimeters) and time (when to start and \nstop raining).\
    \ \nAir temperature \nThis variable refers to the measurement of how cold \nor\
    \ hot the air is. The most common units for this \nvariable include Celsius and\
    \ Fahrenheit. \nAir humidity \nThis variable refers to the measurement of the\
    \ \nconcentration of water vapor present in the air. \nWind \nThis variable refers\
    \ to the bulk movements of air on \nthe surface of the earth. It can be measured\
    \ by wind \nspeed, direction, and duration time. \n Owing to the advanced sensing\
    \ technology and Internet of Things, environmental data can \nbe collected and\
    \ utilized by various sensors deployed in the farms. Some latest sensor equipment\
    \ \nis shown in Figure 23 [251,252]. \n   \n \n(a)                           \
    \            (b) \nFigure 23. Some latest sensor equipment: (a) a perforated cylinder\
    \ coaxial dielectric sensor for \nmeasuring soil water content; (b) a time-domain\
    \ reflectometry sensor for measuring soil moisture. \nSecondly, crop/planting\
    \ variables are considered, including crop growth, crop yield, stress, \ndry weight,\
    \ flowering time, root biomass index, etc. These variables are essential for managing\
    \ \nfarming operations because agricultural decision-making varies in different\
    \ situations. For \ninstance, the planting density of crops may affect the dilution\
    \ factor of insecticides [253]. \nFurthermore, crops are sensitive to the applied\
    \ insecticides due to their growth stage. Toxic \ninsecticides may be lethal to\
    \ those crops at the seed stage. Thus, following key features of \ncrop/planting\
    \ variables are taken into account in Table 6. \n \n \n \n65 \n \nTable 6. Key\
    \ features of crop/planting variables in agricultural cases. \nFeature category\
    \ \nFeature name \nContent \nCrop variables \nCrop breed \nThis variable refers\
    \ to the types of agricultural \nproduction. Some common breeds that farmers are\
    \ \ngrowing now include cereals (i.e. rice, wheat, and \nbarley), pulses food\
    \ (i.e. red gram, black gram, and \ngreen gram), and oils (i.e. olive, peanut,\
    \ and \nsesame). \nGrowth stage \nThis variable refers to a process with different\
    \ \norgans developing, growing, and dying in \noverlapping sequences. (i.e. the\
    \ growth of cereal \ncrops usually includes vegetative, stem elongation, \nbooting,\
    \ heading, anthesis, milking, dough, and ripe \nseed stages.) \nYield \nThis variable\
    \ refers to the amount of crop harvested \nper area of land. The common units\
    \ for this variable \ninclude kilogram/hectare and tons/hectare. \nStress \nThis\
    \ variable refers to any external factors that \ndecrease crop yields from the\
    \ maximum to a lower \nlevel. Some common crop stresses include diseases, \ninsects,\
    \ salinity, and so on. \nMarket price \nThis variable refers to the profitability\
    \ when \nreselling the agricultural production in the market. \nIn particular,\
    \ this variable plays a key role in \ndecision making about harvesting and logistics.\
    \ \nPlanting variables \nPlanting area \nThis variable refers to the segmentation\
    \ of areas \nwhere crops are planted. \nPlanting \ndensity \nThis variable refers\
    \ to the amount of space left \nbetween plants. The more closely spaced plants\
    \ are, \nthe higher the density. \nApplied \nchemicals \nThis variable refers\
    \ to the chemicals previously \napplied during the planting period. These chemicals\
    \ \ncan be fertilizers, pesticides, insecticides, etc. \nFor monitoring crop/planting\
    \ variables, multispectral sensors have been widely adopted. \nUsually, UAVs and\
    \ remotely operated drones (RODs) carry multispectral cameras for collecting \n\
    66 \n \nimages when surveying an area. Then, techniques like feature extraction\
    \ and pattern recognition \nare adopted for further processing collected images\
    \ and obtaining crop variables. Examples of \nmultispectral equipment are shown\
    \ in Figure 24 [254,255]. \n    \n \n(a)                                     \
    \ (b) \nFigure 24. Examples of multispectral equipment: (a) a multispectral sensor\
    \ for crop \ndiscrimination; (b) an airborne multispectral sensor for assessing\
    \ nitrogen nutrition. \nThirdly, farming operations do not only refer to produce\
    \ crops, but also include grazing \nlivestock, since they can produce labors and\
    \ commodities like meat, eggs, milk, fur, leather, etc. \nAs a consequence, livestock\
    \ variables are also considered in the content of agricultural cases. \nThese\
    \ variables include feed, health, and movement control data. For example, by monitoring\
    \ the \nhealth status of animals can help the government to take the right decisions\
    \ on policies and fund \nallocation [256]. Generally, the key features in livestock\
    \ variables are listed in Table 7. \nTable 7. Key features of livestock variables\
    \ in agricultural cases. \nFeature \ncategory \nFeature name \nContent \nFeed\
    \ \nvariables \nFeed cost \nThis variable refers to the money spent on buying\
    \ \nfood for livestock (i.e. feeding a cow costs around \n360 US dollars per year).\
    \ \nFeed amount \nThis variable refers to the amount of food feed to \nlivestock\
    \ (i.e. a single cow consumes around 13 \nkilograms food per day). \nVariety of\
    \ feed \nThis variable refers to the feed type (i.e. grass, corn, \nand potato.).\
    \ \nRumination \nThis variable refers to the process of acquiring \nnutrients\
    \ from plant-based food (i.e. a cow takes two \nhours for rumination.). \n67 \n\
    \ \nWatering \nThis variable refers to an average amount of water \ndrunk by livestock.\
    \ \nHealth \nstatus \nBody temperature \nThis variable refers to the temperature\
    \ measurement \nof the animal. \nWeight \nThis variable refers to the animal’s\
    \ relative mass or \nthe quantity of matter contained by the animal. \nRuminal\
    \ ORP \nThis variable refers to the oxidation-reduction \npotential (ORP) of the\
    \ first stomach of a ruminant \nanimal. The normal value of this variable ranges\
    \ \nfrom -1000 to 0 mV. \nRuminal pH \nThis variable refers to the value, expressing\
    \ the \nacidity or alkalinity in the first stomach of a \nruminant animal. The\
    \ normal value of this variable \nranges from 4 to 9. \nRuminal temperature \n\
    This variable refers to the temperature measurement \ninside the first stomach\
    \ of a ruminant animal. The \nnormal value of this variable ranges from 20 to\
    \ 50 \nCelsius.  \nMovement \ncontrol \nActivity \nThis variable refers to the\
    \ movement of livestock, \nmeasured by steps per animal per day. \nPosition \n\
    This variable refers to locate where the animal is and \nit can be represented\
    \ by global positioning system \n(GPS) data. \nBehavior \nThis variable refers\
    \ to the current state of livestock \n(i.e. a female cow is mating with a male\
    \ one.).  \n \nFor monitoring livestock variables, wearable technologies have\
    \ been widely deployed. For \nexample, E-tags are used to monitor animal’s body\
    \ temperature, since it is one of the first \nsymptoms when body is fighting against\
    \ illnesses. Some latest wearable technologies are shown \nin Figure 25 [257,258].\
    \ \n68 \n \n           \n \n(a)                                   (b) \nFigure\
    \ 25. Examples of wearable technology: (a) a RFID based ear tag for cows; (b)\
    \ wearable \nsensors for monitoring heart rate, surrounding temperature and humidity.\
    \ \nThe above three groups of variables (environmental, crop/planting, and livestock)\
    \ form the \nproblem part of an agricultural case. Depending on the application\
    \ domain, agricultural cases \nshould be composed of selected key features. \n\
    In regards to the solution part of an agricultural case, it can also be formulated\
    \ by feature-\nvalue pairs as well. For instance, key features of a solution for\
    \ pest management include the \npesticide type, applied quantity, dilution factor,\
    \ spraying method, etc. While a solution for \nassigning tasks to agricultural\
    \ machinery should provide the information about the number of \ninvolved vehicles\
    \ and a list of task distribution strategies. \n4.1.4. Structure of the proposed\
    \ case representation method \nDiffering from the typical feature vector representation\
    \ method, the associated case \nrepresentation method extends the “problem-solution”\
    \ structure with an additional association \npart. Thus, the structure of our\
    \ proposal is “problem-solution-association” (See Figure 26). \nIn Figure 26,\
    \ the problem and solution parts have been explained in Section 4.1.3, while the\
    \ \nassociation part is referred to the association table which are generated\
    \ in Section 4.1.1. Each past \ncase retrieves its similar and dissimilar associations\
    \ from the association table and stores them \nwithin this structure, building\
    \ the connection with each other. \n \n69 \n \n \nFigure 26. Structure of the\
    \ associated case representation method. \n4.2. A triangular similarity measure\
    \ \nThe proposed triangular similarity measure (TSM) combines the cosine angle\
    \ between two \nvectors, their Euclidean distance, and their magnitudes. When\
    \ measuring the similarity, a triangle \nis formed by two compared vectors. The\
    \ area of this triangle is considered as a similarity metric. \nMeanwhile, for\
    \ enhancing the robustness of TSM, a coefficient is designed in the formula. It\
    \ \nconsiders the magnitude differences between two compared vectors. The smaller\
    \ the triangular \narea is, the more similar the two vectors will be. The formula\
    \ of TSM is explained in the next \nsub-sections in detail. \n4.2.1. Formula of\
    \ the triangular similarity measure \nFor two vectors in three-dimensional space,\
    \ \U0001D442\U0001D434\n⃗⃗⃗⃗⃗ = (\U0001D44E1, \U0001D44E2, \U0001D44E3) and \U0001D442\
    \U0001D435\n⃗⃗⃗⃗⃗ = (\U0001D44F1, \U0001D44F2, \U0001D44F3), they \ncan form a\
    \ triangle as follows in Figure 27. \n70 \n \n \nFigure 27. Two vectors \U0001D442\
    \U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  in three-dimensional space.\
    \ \nIn Figure 27, a triangle △AOB is formed by two vectors \U0001D442\U0001D434\
    \n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ . The area of this \ntriangle can be\
    \ calculated by two sides and the included angle (SAS formula). Firstly, the \n\
    magnitudes of the two vectors are calculated by Equations (6) and (7). \n|\U0001D442\
    \U0001D434\n⃗⃗⃗⃗⃗ | = √\U0001D44E1\n2 + \U0001D44E2\n2 + \U0001D44E3\n2      \
    \                           (6) \n|\U0001D442\U0001D435\n⃗⃗⃗⃗⃗ | = √\U0001D44F\
    1\n2 + \U0001D44F2\n2 + \U0001D44F3\n2                                 (7) \n\
    The cosine value of these two vectors is calculated by Equation (1) in Section\
    \ 2.3.2. For \nobtaining the value of the angle, the trigonometric inverse function\
    \ can be employed. Then, the \narea of this triangle is calculated by using the\
    \ SAS formula in Equation (8).  \n\U0001D446△AOB =\n|\U0001D442\U0001D434\n⃗⃗⃗⃗⃗⃗\
    \ |∗|\U0001D442\U0001D435\n⃗⃗⃗⃗⃗⃗ |∗sin (\U0001D703)\n2\n                    \
    \            (8) \n \nIn Equation (8), a smaller area of the triangle indicates\
    \ that the two compared vectors will \nhave more commonalities. An example is\
    \ presented in Figure 28. \nIn Figure 28, the target vector is \U0001D442\U0001D434\
    \n⃗⃗⃗⃗⃗  and it is compared with two source vectors \U0001D442\U0001D435\n⃗⃗⃗⃗⃗\
    \  and \n\U0001D442\U0001D436\n⃗⃗⃗⃗⃗ . Though all these three vectors have different\
    \ magnitudes and orientations, the distance \nbetween the source vectors and the\
    \ target vector is identical, demonstrating that source vectors \n\U0001D442\U0001D435\
    \n⃗⃗⃗⃗⃗  and \U0001D442\U0001D436\n⃗⃗⃗⃗⃗  have the same similarity measurement\
    \ with the target vector \U0001D442\U0001D434\n⃗⃗⃗⃗⃗ . However, by \nadopting\
    \ TSM in Figure 28, we can obtain that the area of the triangle △AOB is smaller\
    \ than the \ntriangle △AOC. Under this circumstance, it is concluded that vectors\
    \ \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  have more \ncommonalities\
    \ than vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D436\n⃗⃗⃗⃗⃗ ,\
    \ which is the expected result from common sense. As a \n71 \n \nconsequence,\
    \ compared with distance-based measures, TSM is able to provide an accurate result\
    \ \neven if the distance between the compared vectors is the same. \n \nFigure\
    \ 28. Two triangles formed by three vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗ ,  \U0001D442\
    \U0001D435\n⃗⃗⃗⃗⃗ , and \U0001D442\U0001D436\n⃗⃗⃗⃗⃗ . \n4.2.2. Coefficient design\
    \ in the triangular similarity measure \nThe robustness of TSM can be further\
    \ enhanced for overcoming the drawbacks of angle-\nbased similarity measures.\
    \ A coefficient, \U0001D43E\U0001D45A\U0001D44E\U0001D454, is designed to improve\
    \ the similarity precision, \ntaking into account the magnitude difference between\
    \ compared vectors. This coefficient is also \nformed by a triangle. Its value\
    \ is decided by calculating the area of the formed triangle. The \ncoefficient\
    \ for vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  is\
    \ shown in Figure 29. \n \nFigure 29. The coefficient triangle for vectors \U0001D442\
    \U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ . \n72 \n \nIn Figure 29, the\
    \ triangle △CAD is formed and its area represents the value of the coefficient\
    \ \nfor vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ .\
    \ The angle (∠CAD) between \U0001D434\U0001D436\n⃗⃗⃗⃗⃗  and \U0001D434\U0001D437\
    \n⃗⃗⃗⃗⃗  is same as the angle ∠AOB. \nThe magnitudes of |\U0001D434\U0001D435\n\
    ⃗⃗⃗⃗⃗ | and |\U0001D434\U0001D438\n⃗⃗⃗⃗⃗ | equal to the Euclidean distance between\
    \ vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \n\U0001D442\U0001D435\n⃗⃗⃗⃗⃗ , while\
    \ the magnitudes of |\U0001D435\U0001D436\n⃗⃗⃗⃗⃗ | and |\U0001D438\U0001D437\n\
    ⃗⃗⃗⃗⃗ | equal to the magnitude difference between vectors \n\U0001D442\U0001D434\
    \n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ . The magnitudes of |\U0001D434\U0001D436\
    \n⃗⃗⃗⃗⃗ | and |\U0001D434\U0001D437\n⃗⃗⃗⃗⃗ | are the sum of the Euclidean distance\
    \ and the \nmagnitude difference. The formula of calculating the magnitudes of\
    \ |\U0001D434\U0001D436\n⃗⃗⃗⃗⃗ | and |\U0001D434\U0001D437\n⃗⃗⃗⃗⃗ | can be \n\
    obtained by Equation (9). \n|\U0001D434\U0001D436\n⃗⃗⃗⃗⃗ | = |\U0001D434\U0001D437\
    \n⃗⃗⃗⃗⃗ | = √(\U0001D44E1 − \U0001D44F1)2 + (\U0001D44E2 − \U0001D44F2)2 + (\U0001D44E\
    3 − \U0001D44F3)2 + ||\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ | − |\U0001D442\U0001D435\n\
    ⃗⃗⃗⃗⃗ ||       (9) \nIn Equation (9), the former part is the Euclidean distance\
    \ between the vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n\
    ⃗⃗⃗⃗⃗ , \nwhile the latter part is the magnitude difference of compared vectors.\
    \ It is detected that the \nEuclidean distance and the magnitude difference have\
    \ a close relationship. When the magnitude \ndifference decreases, so does the\
    \ Euclidean distance. Therefore, both factors are taken into \nconsideration when\
    \ designing the coefficient. The area of the triangle △CAD is also calculated\
    \ \nby the SAS formula shown in Equation (10). \n\U0001D43E\U0001D45A\U0001D44E\
    \U0001D454 = \U0001D446△CAD =\n|\U0001D434\U0001D436\n⃗⃗⃗⃗⃗ |∗|\U0001D434\U0001D437\
    \n⃗⃗⃗⃗⃗⃗ |∗sin (\U0001D703)\n2\n                         (10) \nWith obtained\
    \ areas of triangles △AOB and △CAD, the similarity between vectors \U0001D442\U0001D434\
    \n⃗⃗⃗⃗⃗  and \n\U0001D442\U0001D435\n⃗⃗⃗⃗⃗  can be measured by Equation (11).\
    \ \nSim(\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ ) = \U0001D43E\
    \U0001D45A\U0001D44E\U0001D454 ∗ \U0001D446△AOB                          (11)\
    \ \nAn example is presented in Figure 30 for demonstrating how the designed coefficient\
    \ can \nenhance the robustness of TSM. In this figure, the target vector is \U0001D442\
    \U0001D434\n⃗⃗⃗⃗⃗ , while the source vectors \nare \U0001D442\U0001D435\n⃗⃗⃗⃗⃗\
    \  and \U0001D442\U0001D436\n⃗⃗⃗⃗⃗ . It is clear that the cosine similarity of\
    \ \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  is same as that\
    \ of \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \n\U0001D442\U0001D436\n⃗⃗⃗⃗⃗  because they\
    \ share the same angle. As a consequence, by employing the cosine similarity,\
    \ \nvectors \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D436\n⃗⃗⃗⃗⃗  are\
    \ considered to have the same commonalities with the target vector \U0001D442\U0001D434\
    \n⃗⃗⃗⃗⃗ . \nWhen the basic TSM (in Section 4.2.1) is adopted for measuring the\
    \ similarities in Figure 30, it \ncan be concluded that the vector \U0001D442\U0001D435\
    \n⃗⃗⃗⃗⃗  is more similar to the target vector \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  because\
    \ the area of \nthe triangle △AOB is smaller than the triangle △AOC. However,\
    \ this result may be inaccurate \ndue to the reason that vectors \U0001D442\U0001D434\
    \n⃗⃗⃗⃗⃗  and \U0001D442\U0001D436\n⃗⃗⃗⃗⃗  have similar magnitudes, but the magnitudes\
    \ of \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  \nand \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  have a major\
    \ difference. \n73 \n \n \nFigure 30. An example for demonstrating the use of\
    \ coefficient in TSM. \nTSM is able to generate a more accurate result when adopting\
    \ the coefficient because the \nproduct of the areas of two formed triangles is\
    \ more reliable. In Figure 30, though the area of the \ntriangle △AOB is smaller\
    \ than △AOC, its coefficient value (the area of the triangle △EBF) is \nmuch bigger\
    \ than the area of the triangle △ECF, leading to the fact that the similarity\
    \ of the \nvectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗\
    \  is lower than that of \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D436\
    \n⃗⃗⃗⃗⃗ . Conclusively, it is determined that the \nvector \U0001D442\U0001D436\
    \n⃗⃗⃗⃗⃗  is more similar to \U0001D442\U0001D434\n⃗⃗⃗⃗⃗ . \n4.2.3. The triangular\
    \ similarity measure in N-dimensional space \nFor two vectors in N-dimensional\
    \ space, \U0001D442\U0001D434\n⃗⃗⃗⃗⃗ = (\U0001D44E1, \U0001D44E2, … , \U0001D44E\
    \U0001D45B) and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ = (\U0001D44F1, \U0001D44F2, … , \U0001D44F\
    \U0001D45B), \nthe similarity can be measured by the TSM formula defined in Equation\
    \ (12). \n\U0001D446\U0001D456\U0001D45A(\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\
    \U0001D435\n⃗⃗⃗⃗⃗ ) =\n(√∑\n(\U0001D44E\U0001D456−\U0001D44F\U0001D456)2\n\U0001D45B\
    \n\U0001D456=1\n+|√∑\n\U0001D44E\U0001D456\n2\n\U0001D45B\n\U0001D456=1\n−√∑\n\
    \U0001D44F\U0001D456\n2\n\U0001D45B\n\U0001D456=1\n|)\n2\n∗[\U0001D460\U0001D456\
    \U0001D45B2(\U0001D703)+0.001]∗√∑\n\U0001D44E\U0001D456\n2\n\U0001D45B\n\U0001D456\
    =1\n∗√∑\n\U0001D44F\U0001D456\n2\n\U0001D45B\n\U0001D456=1\n4\n  (12) \nIn Equation\
    \ (12), the value of \U0001D460\U0001D456\U0001D45B(\U0001D703) is added by 0.001\
    \ due to the reason that the compared \ntwo vectors may be overlapped with each\
    \ other. Therefore, the value of \U0001D446\U0001D456\U0001D45A(\U0001D442\U0001D434\
    \n⃗⃗⃗⃗⃗ , \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ ) will equal \nto zero. As a consequence,\
    \ the final result will be zero without this adjustment. \n \n74 \n \nThe mathematical\
    \ prove of the TSM formula is given in Figure 31. \n \nFigure 31. The mathematical\
    \ prove of the TSM formula. \nIn Figure 31, the vectors \U0001D442\U0001D434\n\
    ⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗  refer to the vectors presented in Figure\
    \ 29. The \nvariable \U0001D438\U0001D437\U0001D434\U0001D435\n⃗⃗⃗⃗⃗  denotes\
    \ the Euclidean distance between vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\
    \U0001D435\n⃗⃗⃗⃗⃗ . |\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ | and |\U0001D442\U0001D435\n\
    ⃗⃗⃗⃗⃗ | \nrepresent the magnitudes of these two vectors respectively. Since the\
    \ formulas of the Euclidean \ndistance, magnitude of vectors, and the sine function\
    \ have been proved in N-dimensional space, \nthus the TSM formula is appliable\
    \ in N-dimensional space as well. \nIt might be difficult for humans to understand\
    \ the similarity of two vectors by directly reading \nthe value of the triangle\
    \ area. Therefore, it is better to convert the area values by using the inverse\
    \ \nexponential function [259]. Under this circumstance, the similarity measurement\
    \ can be \nrepresented by percentile values, ranging from 0 to 100%, which fit\
    \ human notions better. The \nsimilarity measurement in percentile values can\
    \ be obtained by using Equation (13).  \n\U0001D446\U0001D456\U0001D45A(\U0001D442\
    \U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ )[0,100%] = \U0001D452\U0001D465\
    \U0001D45D (−\U0001D446\U0001D456\U0001D45A(\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\
    \U0001D435\n⃗⃗⃗⃗⃗ ))               (13) \nA large value of \U0001D446\U0001D456\
    \U0001D45A(\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ )[0,100%]\
    \ means that vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\U0001D435\n⃗⃗⃗⃗⃗\
    \  are more similar. \nOnly if vectors \U0001D442\U0001D434\n⃗⃗⃗⃗⃗  and \U0001D442\
    \U0001D435\n⃗⃗⃗⃗⃗  are absolutely identical, the value of \U0001D446\U0001D456\
    \U0001D45A(\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ )[0,100%]\
    \ equals \nto one hundred percent. Because the value of \U0001D446\U0001D456\U0001D45A\
    (\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ ) equals to zero, indicating\
    \ that the \nEuclidean distance between vectors and their magnitude differences\
    \ are both zero. \n4.2.4. Feature weighting in the triangular similarity measure\
    \ \nAs an important aspect in the similarity measure, the objective of weighting\
    \ is to assign \nrelative importance to a set of features, thereby highlighting\
    \ those features that play key roles. \n75 \n \nTypically, each feature in the\
    \ dataset contributes equally to the final result. However, it is noted \nthat\
    \ some data should be adjusted to make a greater contribution than others. \n\
    Feature weighting can be regarded as a generalization of feature selection [260].\
    \ Considering \na dataset \U0001D706 containing n entities \U0001D465\U0001D45B\
    , \U0001D706 = {\U0001D4651, \U0001D4652, \U0001D4653, … , \U0001D465\U0001D45B\
    }. Each entity consists of the same \nset of features \U0001D439 = {\U0001D453\
    1, \U0001D4532, \U0001D4533, … , \U0001D453\U0001D45A} . In this scenario, feature\
    \ weighting tries to assign a weight \n\U0001D464\U0001D45A to each feature \U0001D453\
    \ ∈ \U0001D439. The value of the assigned weight is usually within the interval\
    \ [0,1] \nand it reflects the degree of relevance of the feature to the particular\
    \ problem at hand. \nIn this thesis, an adaptive feature weighting approach is\
    \ designed for determining the \nimportance of each feature. This weighting approach\
    \ is on the basis of the intra-cluster distance \nand the distance between different\
    \ clusters. The detail of the feature weighting approach is \nexplained as follows.\
    \ \nAt first, a matrix X is formed by n vectors and each vector has m features\
    \ in Equation (14). \n\U0001D44B = [\n\U0001D46511\n⋯\n\U0001D4651\U0001D45A\n\
    ⋮\n⋱\n⋮\n\U0001D465\U0001D45B1\n⋯\n\U0001D465\U0001D45B\U0001D45A\n]         \
    \                  (14) \n \nFor eliminating the dimensional differences, vectors\
    \ in the matrix X are normalized and \nmapped into a common scale, ranging from\
    \ 0 to 1. \n \nSecondly, all the vectors are going to be classified into K clusters\
    \ and the number of vectors \nin each cluster is \U0001D45B1, \U0001D45B2, … ,\
    \ \U0001D45B\U0001D458. Let \U0001D45A\U0001D458\U0001D457 denote the average\
    \ value of the cluster k for the \U0001D457\U0001D461ℎ \nfeature. Then, the sum\
    \ of the distance of the \U0001D457\U0001D461ℎ feature for all clusters can be\
    \ obtained by \nEquation (15). This sum result is treated as the intra-cluster\
    \ distance. \n\U0001D451\U0001D45B = ∑\n∑\n\U0001D45B\U0001D458 (\U0001D465\U0001D456\
    \U0001D457 − \U0001D45A\U0001D458\U0001D457)2\n\U0001D456=1\n\U0001D43E\n\U0001D458\
    =1\n                        (15) \nLet \U0001D45A\U0001D457 denote the average\
    \ value of the \U0001D457\U0001D461ℎ feature in the dataset, the distance of the\
    \ \U0001D457\U0001D461ℎ \nfeature between all clusters can be computed by Equation\
    \ (16). This sum result is regarded as the \ndistance between different clusters.\
    \ \n\U0001D451\U0001D464 = ∑\n(\U0001D45A\U0001D458\U0001D457 − \U0001D45A\U0001D457\
    )2\n\U0001D43E\n\U0001D458=1\n                         (16) \nTherefore, the contribution\
    \ of the \U0001D457\U0001D461ℎ feature to the final result can be obtained by\
    \ Equation \n(17). \n\U0001D450\U0001D457 =\n\U0001D451\U0001D464\n\U0001D451\U0001D45B\
    \                                (17) \n76 \n \nIf the intra-cluster distance\
    \ is close and the distance between different clusters is far, it means \nthat\
    \ this feature may potentially contribute more to the final result. However, if\
    \ the intra-cluster \ndistance is far and the distance between different clusters\
    \ is close, it indicates that this feature \nmay have a minor effect on the final\
    \ result. Conclusively, the weight of the \U0001D457\U0001D461ℎ feature is defined\
    \ \nin Equation (18). \n\U0001D464\U0001D457 =\n\U0001D450\U0001D457\n∑\n\U0001D450\
    \U0001D457\n\U0001D45A\n\U0001D457=1\n                              (17) \nWhere\
    \ \U0001D464\U0001D457 ∈ [0,1] and ∑\n\U0001D464\U0001D457\n\U0001D45A\n\U0001D457\
    =1\n= 1. \nConclusively, the formula of triangular similarity measure in Equation\
    \ (12) can be updated \nwith weights by Equation (18). \n\U0001D446\U0001D456\U0001D45A\
    (\U0001D442\U0001D434\n⃗⃗⃗⃗⃗ , \U0001D442\U0001D435\n⃗⃗⃗⃗⃗ ) =\n(√∑\n\U0001D464\
    \U0001D456(\U0001D44E\U0001D456−\U0001D44F\U0001D456)2\n\U0001D45B\n\U0001D456\
    =1\n+\U0001D464\U0001D456|√∑\n\U0001D44E\U0001D456\n2\n\U0001D45B\n\U0001D456\
    =1\n−√∑\n\U0001D44F\U0001D456\n2\n\U0001D45B\n\U0001D456=1\n|)\n2\n∗[\U0001D460\
    \U0001D456\U0001D45B2(\U0001D703)+0.001]∗√∑\n\U0001D464\U0001D456\U0001D44E\U0001D456\
    \n2\n\U0001D45B\n\U0001D456=1\n∗√∑\n\U0001D464\U0001D456\U0001D44F\U0001D456\n\
    2\n\U0001D45B\n\U0001D456=1\n4\n   (18) \nAn example is given for demonstrating\
    \ how this feature weighting approach works. The Iris \nplant dataset is employed\
    \ and the detail of this dataset is explained in Appendix A. The workflow \nof\
    \ adjusting the weights for the features (sepal length, sepal width, petal length,\
    \ and petal width) \nis presented in Figure 32. The result of the adjusted weights\
    \ is shown in Figure 33. \n \n Figure 32. The workflow of adjusting the weights\
    \ for the Iris plant dataset. \n77 \n \n \nFigure 33. The result of adjusted weights\
    \ for the four features. \nIn Figure 33, the initial weight for all four attributes\
    \ was 0.25 in the first iteration. According \nto the ranking of distances between\
    \ each feature and the cluster center, the weights were adjusted. \nFrom the result\
    \ in Figure 33, the features petal length and petal width contributed more than\
    \ other \ntwo. \n4.3. A fast case retrieval algorithm \nTypical case retrieval\
    \ algorithms try to identify the most similar past cases by traversing the \n\
    whole case base, leading to low efficiency in generating the results. In this\
    \ thesis, a fast case \nretrieval algorithm is designed, taking advantage of the\
    \ associations between past cases. At first, \nthe features of a new case are\
    \ compared with an entry-point case. According to the similarity \nmeasurement,\
    \ associated similar or dissimilar cases are then selected for comparison \npreferentially,\
    \ instead of traversing the whole case base. As a consequence, the proposed \n\
    algorithm can enhance the retrieval efficiency significantly. \n4.3.1. A set of\
    \ policies for the retrieval algorithm \nFirst and foremost, it is necessary to\
    \ determine whether the two compared cases are similar \nor dissimilar. Table\
    \ 8 is presented for demonstrating the correspondence between the similarity \n\
    level and measurements. \n \n \n \n78 \n \nTable 8. Correspondence between the\
    \ similarity level and measurements. \nLevel \nCondition \nIdentical \nThe compared\
    \ two cases are exactly the same, \nachieving a similarity measurement at 100.00%.\
    \ \nHighly similar \nThe compared two cases achieve a similarity \nmeasurement,\
    \ ranging from 75.00% to 99.99%. \nSimilar \nThe compared two cases achieve a\
    \ similarity \nmeasurement, ranging from 50.00% to 74.99%. \nDissimilar \nThe\
    \ compared two cases achieve a similarity \nmeasurement, ranging from 25.00% to\
    \ 49.99%. \nHighly dissimilar \nThe compared two cases achieve a similarity \n\
    measurement, ranging from 0.00% to 24.99%. \nIn regards to the association determination\
    \ (for selecting the associated similar or dissimilar \ncases), a set of policies\
    \ is defined in the proposed case retrieval algorithm, shown as follows. \n• \n\
    Policy 1 – Detection of identical cases: If a past case is detected identical\
    \ to the new case, \nthe case retrieval algorithm terminates immediately. The\
    \ output is this identical case. \n• \nPolicy 2 – Token assignments: \no If a\
    \ past case is considered highly similar to the new case, three positive tokens\
    \ will be \nassigned to this past case. \no If a past case is considered similar\
    \ to the new case, one positive token will be assigned \nto this past case. \n\
    o If a past case is considered dissimilar to the new case, one negative token\
    \ will be \nassigned to this past case. \no If a past case is considered highly\
    \ dissimilar to the new case, three negative tokens will \nbe assigned to this\
    \ past case. \n• \nPolicy 3 – Association selection: The association with more\
    \ tokens will be selected for \ncomparison. When the number of positive tokens\
    \ is greater than negative ones, the past case \nwith the highest similarity measurement\
    \ will be selected. The associated similar cases of this \nchosen one will be\
    \ evaluated in the next iteration. While the comparative result of the current\
    \ \niteration suggests that the number of negative tokens is more, then the past\
    \ case with the \nlowest similarity measurement will be selected. Consequently,\
    \ the associated dissimilar cases \nof this selected one are retrieved from the\
    \ case base for comparison in the next iteration. \n• \nPolicy 4 – Selection of\
    \ previous cases: It happens that all associated cases in a single iteration \n\
    have been compared previously due to the reason that a past case can be associated\
    \ with a 1-\n79 \n \nto-N relation. It makes no sense to repeatedly evaluate cases\
    \ that have been already compared \nbefore, resulting in an endless loop for the\
    \ algorithm. Under this circumstance, the cases to \nbe evaluated in the next\
    \ iteration are selected from previous iterations. Based on the number \nof tokens,\
    \ corresponding association is determined and the past case with the second highest\
    \ \n(or lowest) similarity measurement from the previous iteration will be chosen\
    \ for comparison. \nIf the past cases in the previous iteration have all been\
    \ selected, then the algorithm will repeat \nPolicy 4 one more time. \nThe above\
    \ set of policies is applicable under the circumstance that each past case is\
    \ \nassociated with three similar and three dissimilar cases. Because the number\
    \ of associated cases \ndepends on the size of the case base. When the case base\
    \ contains more past cases, more \nassociations should be built. As a consequence,\
    \ the number of tokens (in Policy 4) should be \nincreased for ensuring that the\
    \ highly similar and highly dissimilar associations can be compared \npreferentially.\
    \ \n4.3.2. Design of the case retrieval algorithm \nThe workflow of the proposed\
    \ case retrieval algorithm is presented in Figure 34. As shown \nin the figure,\
    \ the case retrieval algorithm firstly starts with the new case input by users.\
    \ An entry-\npoint case is randomly selected from the case base for comparison\
    \ in the first iteration. Based on \nthe similarity measurement, the algorithm\
    \ decides whether the new case is similar (or dissimilar) \nto the entry-point\
    \ case. Afterwards, the corresponding association is determined and associated\
    \ \nsimilar (or dissimilar) past cases are retrieved from the case base for comparison.\
    \ Then, the \nsimilarity between the new case and association similar (or dissimilar)\
    \ ones are measured in the \nnext iterations, until the termination condition\
    \ is reached. The termination condition of the \nalgorithm is defined as: (i)\
    \ the maximum iteration number is reached, or (ii) a set of satisfactory \nsimilar\
    \ past cases is retrieved successfully.  \nThe pseudo code of the proposed case\
    \ retrieval algorithm is displayed in Figure 35. \n80 \n \n \nFigure 34. The workflow\
    \ of the proposed case retrieval algorithm. \n \nFigure 35. The pseudo code of\
    \ the proposed case retrieval algorithm. \n81 \n \nFor better demonstrating the\
    \ proposed case retrieval algorithm, an example is presented in \nFigure 36. \n\
    \ \nFigure 36. An example of the proposed case retrieval algorithm. \nIn Figure\
    \ 36, Pi represents the ith past case in the case base, while N1 denotes the new\
    \ case. \nInitially, P1 is selected as the entry-point case for comparison with\
    \ N1 in the first iteration. The \nsimilarity measurement of P1 and N1 reaches\
    \ 30.96%, indicating that P1 is dissimilar to N1. \nTherefore, the dissimilar\
    \ association of P1 is chosen for comparison according to Policies 2 and \n3.\
    \ In the second iteration, P336, P157, and P479 are compared with N1. In this\
    \ iteration, the number \nof positive tokens is greater than negative ones, thus\
    \ the associated similar cases of P157, which \nhas the highest similarity measurement,\
    \ are selected for comparison in the next iteration according \nto Policies 2\
    \ and 3. The case retrieval algorithm keeps running until the 6th iteration, all\
    \ past cases \nhave been repeated and used previously. According to Policy 4,\
    \ P339 which has the second highest \nsimilarity measurement from the 5th iteration\
    \ is chosen as a substitution for comparison in the 6th \niteration. The output\
    \ of this retrieval algorithm is a past case which has the greatest commonalities\
    \ \nwith the new case. The travelling trajectory of the proposed case retrieval\
    \ algorithm in the above \nexample is presented in Figure 37. \n82 \n \n \nFigure\
    \ 37. The travelling trajectory of the proposed retrieval algorithm in the example.\
    \ \nIn Figure 37, it is shown that the proposed retrieval algorithm only compares\
    \ the interested \nassociations. For instance, the similarity measurement between\
    \ P1 and N1 indicates that the \ndissimilar association of P1 should be selected\
    \ for comparison next. Thus, the similar association \nof P1 is ignored. Under\
    \ this circumstance, the retrieval algorithm avoids comparing irrelevant \ncases,\
    \ and therefore improves the retrieval efficiency. \n4.4. A learning-based approach\
    \ for solution reuse and revision \nAfter retrieving the similar past cases, their\
    \ solutions are reused to solve the new problem. \nHowever, the retrieved cases\
    \ are not exactly same as the new ones in most scenarios. Therefore, \nthe solution\
    \ of retrieved cases needs to be revised. For a revision task, it should recognize\
    \ when \nan adaptation should be applied because there are major differences between\
    \ the new and \nretrieved cases. Moreover, the revision task should refine the\
    \ retrieved solution to reflect the \ndifference between the new problem and solved\
    \ ones, as appropriate. For instance, in a clinical \nCBR system, a retrieved\
    \ case with light symptoms should increase the treatment dosage to reflect \n\
    the additional symptoms in the new case [261]. \nInspired from the general case\
    \ representation formalism which consists of the problem and \nsolution pairs,\
    \ a revision can also be considered as situation and action pairs. The situation\
    \ part \nindicates the detected differences between the new and retrieved cases,\
    \ while the action part \ncontains the adaptation for the retrieved solution like\
    \ (i) new values for updating the solution, (ii) \nelements to be added, deleted,\
    \ or changed in the solution, and (iii) more specialized knowledge \nfor extending\
    \ the solution. \n83 \n \n4.4.1. Overview of the revision strategy \nThe case\
    \ base is full of useful knowledge about the problem-solving domain because a\
    \ set \nof cases and their solutions are stored in the case base. By this nature,\
    \ the revision strategy can be \nlearned from previous adaptation strategies.\
    \ Therefore, a learning-based approach is adopted for \ncompleting the revision\
    \ task. The overview of the proposed revision process in CBR is presented \nin\
    \ Figure 38. \n \nFigure 38. The overview of the proposed revision process in\
    \ CBR. \n \nIn Figure 38, four steps are followed for completing the adaptation.\
    \ \n• \nStep 1: The new case \U0001D4411 is compared with past cases in the full\
    \ case base. The most similar \npast case is retrieved and marked as an adaptation\
    \ case \U0001D434\U0001D4371. \n• \nStep 2: The adaptation case \U0001D434\U0001D437\
    1 is removed from the full case base, therefore a cut-down \ncase base is formed.\
    \ The same retrieval process is performed and a collection of similar past \n\
    cases \U0001D443\U0001D456 is retrieved from the cut-down case base. \n• \nStep\
    \ 3: The new case, adaptation case and all retrieved past cases are regarded as\
    \ inputs to \nthe learning component for obtaining the adaptation knowledge. \n\
    • \nStep 4: The learned adaptation strategy is applied to the new case \U0001D441\
    1. \nFor steps 1 and 2, the retrieval component employs the triangular similarity\
    \ measure and the \nfast retrieval algorithm explained in Sections 4.2 and 4.3\
    \ respectively. For the third step, the \nlearning component tries to identify\
    \ the differences between the new case and retrieved past cases. \n84 \n \nThe\
    \ detail of the learning component will be explained later in Section 4.4.2. For\
    \ the fourth step, \nthe adaptation strategy learned from the third step is applied\
    \ to the new case. \n4.4.2. Design of the learning component \nAs mentioned before,\
    \ the revision can be considered as a situation and action pair. The \nsolution\
    \ of the retrieved case can be adapted to the new problem by learning from other\
    \ past cases. \nFirstly, it is necessary to identify the difference between the\
    \ new case \U0001D4411 and the adaptation case \n\U0001D434\U0001D4371 (See Figure\
    \ 39). \nIn Figure 39, owing to the advantage of the feature vector representation,\
    \ the difference \nbetween the problem part of the new case \U0001D4411 and the\
    \ adaptation past case \U0001D434\U0001D4371 can be measured \nby Equation (19).\
    \ \n△\U0001D482\U0001D48D\U0001D48D= ∑\n\U0001D464\U0001D456|\U0001D465\U0001D456\
    \U0001D45A − \U0001D465\U0001D457\U0001D45A|\n\U0001D45B\n\U0001D456=1\n     \
    \                     (19) \nWhere △\U0001D482\U0001D48D\U0001D48D denotes the\
    \ overall difference between the cases. While \U0001D465\U0001D456\U0001D45A and\
    \ \U0001D465\U0001D457\U0001D45A represent \nthe values of features for each case\
    \ respectively. \U0001D464\U0001D456 indicates the weight for each feature. \n\
    \ \nFigure 39. Identifying the difference between the new case \U0001D4411 and\
    \ retrieved past case \U0001D434\U0001D4371. \nAfter obtaining the difference,\
    \ the adaptation case \U0001D434\U0001D4371 is treated as a new case for the \n\
    retrieval task within the cut-down case base. The objective of the second case\
    \ retrieval task is to \nidentify a collection of past cases which have similar\
    \ difference to the detected difference between \nthe new case and the adaptation\
    \ case. It is worth noting that each past case consists of a complete \npair of\
    \ problem and solution. Meanwhile, owing to the associated case representation\
    \ method, \neach past case is associated with several similar and dissimilar cases.\
    \ By looking into the \ndifferences of past cases, it is possible to learn the\
    \ adaptation strategy for revising the solution \nand applying the revised solution\
    \ to the new case. An example is given in Tables 9 to 12 for \n85 \n \ndemonstrating\
    \ how the adaptation strategy can be learned from the difference between past\
    \ cases. \nThis example describes an agricultural problem about applying the chemical\
    \ treatment, \nconcerning the relationships between infected areas and the amount\
    \ of the chemical applications. \nTable 9. An example of problem differences between\
    \ the new case and adaptation case (Scenario \n1). \nCase ID \nInfected area (m2)\
    \ \nDifference \nSolution (mg) \nN1 \n100 \nN/A \nN/A \nAD1 \n102 \n-2 \n0.05\
    \ \nTable 10. An example of problem differences between past cases (Scenario 1).\
    \ \nCase ID \nInfected area (m2) \nDifference \nSolution (mg) \nAdaptation action\
    \ \nAD1 \n102 \n-2 (target) \n0.05 \n0 \nP101 \n103 \n-1 \n0.05 \nN/A \nP102 \n\
    104 \n-2 \n0.05 \nN/A \nTable 11. An example of problem differences between the\
    \ new case and adaptation case (Scenario \n2). \nCase ID \nInfected area (m2)\
    \ \nDifference \nSolution (mg) \nN2 \n200 \nN/A \nN/A \nAD2 \n250 \n-50 \n0.10\
    \ \nTable 12. An example of problem differences between past cases (Scenario 2).\
    \ \nCase ID \nInfected area (m2) \nDifference \nSolution (mg) \nAdaptation action\
    \ \nAD2 \n250 \n-50 (target) \n0.10 \n-0.05 \nP201 \n300 \n-50 \n0.15 \nN/A \n\
    P202 \n305 \n-55 \n0.15 \nN/A \nThe following two scenarios are presented in the\
    \ above tables. \nTables 9 and 10 demonstrate the first scenario, the infected\
    \ area in the new case \U0001D4411 has a \nvalue of 100 m2 and the adaptation\
    \ case in the first retrieval task is \U0001D434\U0001D4371 with a value of 102\
    \ m2. \nTherefore, the difference between these two cases is calculated. In the\
    \ second case retrieval task, \n\U0001D434\U0001D4371 is treated as a new case\
    \ and two past cases \U0001D443101 and \U0001D443102 are retrieved from the cut-down\
    \ \ncase base. It is detected that these retrieved two cases have similar difference\
    \ (value of ‘-2’) with \n\U0001D4411 and \U0001D434\U0001D4371. Meanwhile, it\
    \ is noted that the solution part of \U0001D434\U0001D4371, \U0001D443101, and\
    \ \U0001D443102 is the same, \n86 \n \nmeaning that this solution is appliable\
    \ to all cases with such minor difference. Thus, the retrieved \nsolution of \U0001D434\
    \U0001D4371 (applying 0.05 mg of chemicals) will be used to deal with the new\
    \ case \U0001D4411 \nwithout any update. \nThe second scenario is presented in\
    \ Tables 11 and 12. In this scenario, the infected area of \nthe new case \U0001D441\
    2 has a value of 200 m2. It is assumed that the most similar past case that can\
    \ be \nretrieved from the full case base is \U0001D434\U0001D4372 with a value\
    \ of 250 m2. It is obvious that the new case \nand the retrieved past case has\
    \ a major difference in the feature value. Under this circumstance, \nthe solution\
    \ of the retrieved case \U0001D434\U0001D4372  might be not suitable for the new\
    \ case \U0001D4412 . As a \nconsequence, the adaptation case \U0001D434\U0001D437\
    2 is treated as a new case in the second case retrieval task \nand past cases\
    \ (\U0001D443201 and \U0001D443202) are retrieved from the cut-down case base.\
    \ It is noted that \U0001D434\U0001D4372, \n\U0001D443201 and \U0001D443202 achieve\
    \ a similar difference value at around minus 50. Thus, the knowledge of \nadapting\
    \ the solutions of \U0001D443201 and \U0001D443202 to solve \U0001D434\U0001D437\
    2 can be learned. In Table 12, considering \nthe differences between cases, the\
    \ amount of applied chemical treatments is reduced by 0.05 mg. \nConsequently,\
    \ it is possible to reduce 0.05 mg of chemicals in the solution of the adaptation\
    \ case \n\U0001D434\U0001D4372 for generating a new solution to solve the new\
    \ case \U0001D4412. The output result of the revised \nsolution is to apply 0.05\
    \ mg of chemicals to the infected area. \nConclusively, the learning component\
    \ can be summarized in Figure 40. \n \nFigure 40. The workflow of the learning\
    \ component. \nIn the upper part of Figure 40, it shows a typical retrieve process\
    \ in CBR. The retrieved \ncontent consists of both problem and solution parts\
    \ of a past case. In the lower part of Figure 40, \nthe difference between the\
    \ new case and the adaptation case is calculated based on the feature \nvalues\
    \ and their weights. The retrieved solution of the adaptation case is updated\
    \ based on the \n87 \n \ndetected difference between the retrieved past cases\
    \ from the cut-down case base. Lastly, the \nrevised solution is applied to the\
    \ new problem. \n4.4.3. Adaptation actions: A case study \nThe adaptation actions\
    \ capture the update that transforms the retrieved solution of the \nadaptation\
    \ case into a target solution for solving the new problem. For the numeric adaptation,\
    \ \nthe action part is simple because it usually involves a calculation like adding\
    \ the numeric \ndifference between the target and retrieved solutions. However,\
    \ the adaptation of symbolic \nsolutions is more challenging due to the reason\
    \ that the dissimilarity of numeric features can be \ncalculated for updating\
    \ a numeric solution, but this dissimilarity measurement is not appliable to \n\
    symbolic features. Nevertheless, the adaptation of numeric solutions provides\
    \ insight into what is \ndesirable for the adaptation of symbolic solutions. The\
    \ foundation of an adaptation action depends \non the detection of differences\
    \ between compared cases, and most importantly, how the update \nreflects these\
    \ differences. \nA case study on pest management is conducted for demonstrating\
    \ how the symbolic features \nin the solutions can be adapted. Generally, the\
    \ problem part of a pest management case mainly \nconcerns, but are not limited\
    \ to, the following factors. \n• \nPest variables: \no Pest species: This variable\
    \ affects the selection of a specific pesticide. \no Pest quantity: This variable\
    \ determines the amount of applied pesticide. \no Maturity of pests: This variable\
    \ affects the selection of a specific pesticide. \n• \nEnvironmental variables:\
    \ \no Solar irradiance: This variable may promote the breakdown of many chemicals.\
    \ Most \nof the pesticides are subjected to the photodecomposition. \no Temperature:\
    \ This variable is another important factor in the breakdown of pesticides. \n\
    Applying the chemicals near the root of plants or at the top of their leaves has\
    \ a major \ndifference because temperature at the top is higher than that near\
    \ the soil surface. \no Humidity: This variable affects the performance of pesticide\
    \ applications as well. In \nrainy days, the rain can wash away the pesticides\
    \ attached on the plants. Furthermore, the \nrain can dilute the pesticide concentration.\
    \ \no Soil pH: Soil is a mixture of organic and inorganic bases and acids, all\
    \ of which react \nwith each other to form the soil pH value. Since pesticides\
    \ can be categorized by acidic and \nalkaline ones, if a slightly acidic pesticide\
    \ is applied to an alkaline surface, this pesticide \nmay break down more rapidly.\
    \ For instance, Captan (also known as ethanethiol or ethyl \nmercaptan and it\
    \ is often added as a component of pesticide mixtures for controlling \n88 \n\
    \ \ndiseases on a number of fruits and vegetables as well as ornamental plants)\
    \ has a half-life \nof three hours at a pH value of 7.0, but only 10 minutes at\
    \ a pH value of 8.0. \nThe solution part of a pest management case should include\
    \ the following information [262]. \n• \nSelection of nozzle type: This variable\
    \ decides the nozzles for giving pesticides in the fields. \nThe nozzle type includes\
    \ cone, deflector, air induction, etc. \n• \nSpray volume: This variable determines\
    \ the number of pesticide droplets produced and the \ntarget is covered by a pesticide.\
    \ Usually, higher application volumes are required for effective \ncoverage of\
    \ the target. However, high-volume spraying can result in wastage of chemicals\
    \ as \nwell. \n• \nSpray concentration: This variable implies the applied dosage\
    \ which is the amount of \nformulation to be mixed with water. When the spray\
    \ volume rate is low, the spray \nconcentration should be higher, bringing the\
    \ advantage of wetting foliage more effectively. \n• \nOperating pressure: This\
    \ variable has influence on the flow rate and spraying quality. A \nproper operating\
    \ pressure can avoid potential spray drift. \n• \nSpray angle: This variable indicates\
    \ the angle of nozzles. Wide and narrow angles are both \nadopted. However, they\
    \ have different application scenarios. For instance, narrow angled \nnozzles\
    \ (i.e. 80 degree) are efficient for row crops. \nTaking into account both the\
    \ problem and solution parts, an example of the pest management \ncase is presented\
    \ in Figure 41. \n \nFigure 41. An example of a normal pest management case. \n\
    89 \n \nFor the content of a new case, it only contains the problem part, leaving\
    \ the solution and \nassociation parts empty temporarily. For all the past cases\
    \ in the case base, their contents should \ninclude all three parts. After the\
    \ first case retrieval task (Step 1 in Figure 38), an adaptation case \nis retrieved\
    \ and then treated as a new input to the second case retrieval task (Step 2 in\
    \ Figure 38). \nThere is a slight change in this new input due to the extension\
    \ of an additional part, named \ndifference part (See Figure 42). This difference\
    \ part is helpful for identifying a list of past cases \nwhich has similar differences\
    \ to the new input case. \n \nFigure 42. An example of an adaptation case. \n\
    In Figure 42, the difference between the new case and the adaptation case is calculated\
    \ by \nEquation (19). This adaptation case is treated as a new input to the second\
    \ case retrieval task. If \nthe similar difference between the adaptation case\
    \ and other past cases is detected, then the \nadaptation strategy can be learned\
    \ from these past cases and the revised solution may be \npotentially applicable\
    \ to the new problem. \nIn this case study, a new case, an adaptation case and\
    \ three past cases will be selected from \na case base where 300 cases are stored\
    \ [263]. The association parts of the adaptation case and \nother past cases are\
    \ not considered because the scale of the case base is small. This case study\
    \ \ntries to manage the pest problems for Chilo suppressalis (a pest of rice).\
    \ Therefore, the pest species \nare not taken into account when measuring the\
    \ similarity of cases. The initial weights for all other \nsix features are 0.1667\
    \ and they are updated by Equation (17) for determining which features have \n\
    90 \n \ngreater influence. The final weights are 0.2051 (pest quantity), 0.0938\
    \ (maturity of pest), 0.1723 \n(solar irradiance), 0.1724 (temperature), 0.1499\
    \ (humidity), and 0.2065 (soil pH) respectively, \nshown in Figure 43.  \n \n\
    Figure 43. Feature weights for pest management cases. \n \n After executing the\
    \ first case retrieval task, the adaptation case is retrieved from the case \n\
    base. The data visualization of features of these two cases is displayed in Figure\
    \ 44. The similarity \nmeasurement reaches 97.98%, while the difference between\
    \ these two cases has a value of 0.1120 \naccording to Equation (19). \n \nFigure\
    \ 44. Data visualization of features of the new case and adaptation case. \n \n\
    In Figure 44, it is observed that the main difference between these two cases\
    \ lies on the \nfeatures of maturity of pest and temperature. \n91 \n \n \nIn\
    \ the second case retrieval task, the adaptation case is treated as an input to\
    \ the retrieval \ncomponent. The retrieval result is a collection of three past\
    \ cases and the data visualization is \npresented in Figure 45. The similarity\
    \ measurement and difference values are listed in Table 13. \n  \nFigure 45. Data\
    \ visualization of features of the adaptation case and retrieved past cases. \n\
    Table 13. Similarity measurements and difference values of retrieved past cases.\
    \ \nCase ID Similarity measurement Difference values \n1 \n97.89% \n0.0812 \n\
    2 \n97.86% \n0.0862 \n3 \n96.32% \n0.9183 \n \nAfter identifying the difference\
    \ between the features of past cases, it is important to look into \nhow the solution\
    \ of the adaptation case can be revised to match the solutions of retrieved past\
    \ \ncases. The solutions are listed in Table 14. \nTable 14. Solutions of the\
    \ adaptation case and retrieved past cases. \nCase ID \nNozzle type \nSpray \n\
    volume \nSpray \nconcentration \nOperating \npressure \nSpray \nangle \nAdaptation\
    \ \ncase \nCone \n4600 \nHigh \n3 \n60 \nPast case 1 \nCone \n4411 \nHigh \n3\
    \ \n60 \nPast case 2 \nAir induction \n4930 \nLow \n5 \n90 \nPast case 3 \nCone\
    \ \n4858 \nHigh \n3 \n60 \n92 \n \n \nIn Table 14, apart from the past case 2,\
    \ other past cases and the adaptation case adopts similar \nsolutions (using a\
    \ cone nozzle, under high spray concentration, at 3 bar operating pressure, and\
    \ \nwith a narrow angle of 60 degree). The main difference is the spray volume,\
    \ depending on the \npest quantity and maturity of pest. Based on the difference\
    \ of the spray volume, it is learned that \na larger quantity of pests requires\
    \ a higher volume of pesticides. Therefore, the difference of the \nspray volume\
    \ is analyzed in Table 15. \nTable 15. Analysis of the pest quantity and spray\
    \ volume. \nCase ID \nPest \nquantity \nQuantity \ndifference \nSpray \nvolume\
    \ \nVolume \ndifference \n \nAdaptation \ncase \n857 \n+18 (with new \ncase) \n\
    4600 \nTBD \n \nPast case 1 \n841 \n-16 \n4411 \n-189 \n \nPast case 2 \n892 \n\
    +35 \n4930 \n+330 \n \nPast case 3 \n870 \n+13 \n4858 \n+258 \n \n \nAccording\
    \ to Table 15, it is determined that the difference value between the adaptation\
    \ case \nand past case 1 is minus 16, the volume difference between the adaptation\
    \ case and past case 3 is \n258. The difference value between the new case and\
    \ adaptation case is 18. For revising the \nsolution of the adaptation case, it\
    \ is possible to reduce the spray volume by a certain amount. \nTherefore, the\
    \ revised solution for the new case is to use a cone nozzle to spray 4377 units\
    \ \n(4600 − (189 + 258)/2) of pesticides under high spray concentration, at 3\
    \ bar operating \npressure, and with a narrow angle of 60 degree. Compared this\
    \ revised solution of the original \none stored in the case base, the result shows\
    \ a successful revision. The revised solution and the \noriginal one is shown\
    \ in Table 16. \nTable 16. Comparison of the revised solution and original one.\
    \ \nSolution \nNozzle type \nSpray \nvolume \nSpray \nconcentration \nOperating\
    \ \npressure \nSpray \nangle \nRevised \nsolution \nCone \n4377 \nHigh \n3 \n\
    60 \nOriginal \nsolution \nCone \n4420 \nHigh \n3 \n60 \n93 \n \n \nIn Table 16,\
    \ the revised solution only has a minor difference in the feature of the spray\
    \ \nvolume from the original solution. The rest of features is the same. In conclusion,\
    \ the learning-\nbased approach for solution reuse and revision is effective.\
    \ \n4.5. An associated case retention approach \nAfter successfully solving the\
    \ new problem with the revised solution, the learned case should \nbe retained\
    \ to the case base. The typical approach is to directly add the newly-solved case\
    \ into the \ncase base, along with its solutions. Under the circumstance when\
    \ the new case is extremely similar \nto a past case that has been already stored\
    \ in the case base, a deletion strategy could be applied \nafter evaluating the\
    \ quality of both cases. In this thesis, apart from the normal process of case\
    \ \nretention, the update of the association is also considered because the performance\
    \ of the case \nretrieval algorithm depends on the similar and dissimilar association\
    \ of cases. \nIn this thesis, the proposed case retention approach takes care\
    \ of case base maintenance in \nthe following two aspects: (i) storing the learned\
    \ case, and (ii) updating the existing association \nof past cases. \n4.5.1. Storing\
    \ the learned case \nIn CBR, the efficiency of the system is largely affected\
    \ by the presence of the number of \ncases that are stored in the case base. It\
    \ is desirable to only retain the useful cases, and therefore \nto improve the\
    \ efficiency of the CBR systems. \nIn this sub-section, a case competence model\
    \ is used to evaluate the goodness of a learned \ncase for determine whether this\
    \ case should be retained or not [264]. Generally, the competence \nof a CBR system\
    \ is decided by the range of a target problem that can be solved by the given\
    \ \nsystem. The competence of a case base relies on the local competence properties\
    \ of each case and \nthe relationship between these cases. The local competence\
    \ of an individual case can be \ncharacterized by its coverage and reachability.\
    \ Consider a set of cases (\U0001D436) and a space of target \nproblems (\U0001D447\
    ). For describing these properties, a relation ‘solves’ between a case \U0001D450\
    \ (\U0001D450 ∈ \U0001D436) and a \ntarget problem \U0001D461 (\U0001D461 ∈ \U0001D447\
    ) is defined (i.e. \U0001D460\U0001D45C\U0001D459\U0001D463\U0001D452\U0001D460\
    (\U0001D450, \U0001D461)). This relation specifies that a case \U0001D450 can\
    \ \nbe retrieved from the case base and its solution can be adapted to solve the\
    \ target problem \U0001D461. \n• \nCoverage: The coverage set of a case is the\
    \ set of all target problems that can be solved by \nthis case. This set can be\
    \ defined in Equation (20). \n\U0001D46A\U0001D490\U0001D497\U0001D486\U0001D493\
    \U0001D482\U0001D488\U0001D486\U0001D47A\U0001D486\U0001D495(\U0001D484) = {\U0001D450\
    ′ ∈ \U0001D436:\U0001D460\U0001D45C\U0001D459\U0001D463\U0001D452\U0001D460(\U0001D450\
    , \U0001D450′)}                     (20) \n94 \n \n• \nReachability: The reachability\
    \ set is the set of a target problem that all cases can be used to \nsolve it.\
    \ This set can be defined in Equation (21). \n\U0001D479\U0001D486\U0001D482\U0001D484\
    \U0001D489\U0001D482\U0001D483\U0001D48A\U0001D48D\U0001D48A\U0001D495\U0001D49A\
    \U0001D47A\U0001D486\U0001D495(\U0001D484) = {\U0001D450′ ∈ \U0001D436:\U0001D460\
    \U0001D45C\U0001D459\U0001D463\U0001D452\U0001D460(\U0001D450′, \U0001D450)} \
    \                  (20) \nMoreover, a related set can be defined in Equation (21),\
    \ referring to the set produced from \nthe union of a case’s coverage and reachability\
    \ sets. \n\U0001D479\U0001D486\U0001D48D\U0001D482\U0001D495\U0001D486\U0001D485\
    \U0001D47A\U0001D486\U0001D495(\U0001D484) = \U0001D436\U0001D45C\U0001D463\U0001D452\
    \U0001D45F\U0001D44E\U0001D454\U0001D452\U0001D446\U0001D452\U0001D461(\U0001D450\
    ) ⋃ \U0001D445\U0001D452\U0001D44E\U0001D450ℎ\U0001D44E\U0001D44F\U0001D456\U0001D459\
    \U0001D456\U0001D461\U0001D466\U0001D446\U0001D452\U0001D461(\U0001D450)     \
    \        (21) \nFor example, in Figure 46, \U0001D436\U0001D45C\U0001D463\U0001D452\
    \U0001D45F\U0001D44E\U0001D454\U0001D452\U0001D446\U0001D452\U0001D461(\U0001D450\
    1, \U0001D4502) = {\U0001D4503}, while \U0001D445\U0001D452\U0001D44E\U0001D450\
    ℎ\U0001D44E\U0001D44F\U0001D456\U0001D459\U0001D456\U0001D461\U0001D466\U0001D446\
    \U0001D452\U0001D461(\U0001D4504) =\n{{\U0001D4501, \U0001D4502, \U0001D4505},\
    \ {\U0001D4503}}.  \n \nFigure 46. An example of the case base for demonstrating\
    \ coverage and reachability. \nThe size of the coverage set of a case is only\
    \ a measure of its local competence. For instance, \na case coverage set can overlap\
    \ to limit the competence contributions of individual cases, or it \nmight be\
    \ isolated and exaggerate contributions of individual cases. It is possible that\
    \ a case with \na larger coverage set makes little or no contributions to the\
    \ global competence due to the reason \nthat its contribution is subsumed by the\
    \ local competences of other cases. Under certain extreme \ncircumstances, there\
    \ may be cases with relatively small contributions than others, but these \ncontributions\
    \ may nonetheless be crucial if there are no competing cases. Therefore, a measure\
    \ \nof the coverage of a case, relative to other nearby cases can be defined in\
    \ Equation (22), named \nrelative coverage. \n\U0001D479\U0001D486\U0001D48D\U0001D482\
    \U0001D495\U0001D48A\U0001D497\U0001D486\U0001D46A\U0001D490\U0001D497\U0001D486\
    \U0001D493\U0001D482\U0001D488\U0001D486(\U0001D484) = ∑\n1\n\U0001D450′∈\U0001D436\
    \U0001D45C\U0001D463\U0001D452\U0001D45F\U0001D44E\U0001D454\U0001D452\U0001D446\
    \U0001D452\U0001D461(\U0001D450) |\U0001D445\U0001D452\U0001D44E\U0001D450ℎ\U0001D44E\
    \U0001D44F\U0001D459\U0001D456\U0001D461\U0001D466\U0001D446\U0001D452\U0001D461\
    (\U0001D450′)|\n            (22) \n95 \n \n \nIn Equation (22), the relative coverage\
    \ estimates the unique competence contribution of an \nindividual case, as a function\
    \ of the size of the case’s coverage set. Generally, the relative \ncoverage weights\
    \ the contribution of each covered case by the degree to which these cases are\
    \ \ncovered. The essence of this concept is that if a case is covered by \U0001D45B\
    \ other cases, then each of \nthe \U0001D45B cases will receive a contribution\
    \ of 1 \U0001D45B\n⁄  from this case to their relative coverage measures. \n \n\
    Conclusively, if the new problem achieves a value of the relative coverage that\
    \ is greater \nthan the lowest relative coverage in the case base, then the learned\
    \ case will be retained in the \ncase base. Otherwise, the deletion strategy will\
    \ be adopted and the learned case will not be stored. \n4.5.2. Updating the existing\
    \ association \nAfter the CBR system decides to retain the learned case, the existing\
    \ association of cases should be \nupdated accordingly. The following two scenarios\
    \ are considered in this thesis. \n• \nScenario 1 – Updating the association of\
    \ the new case: If a closer similar or dissimilar \nassociation with the new case\
    \ is detected, the old association of the new case should be \nupdated (See Figure\
    \ 47(a)). \n• \nScenario 2 – Updating the association of the past cases: If a\
    \ new case shows a closer \nassociation with the compared past cases, the old\
    \ association of this past case should be \nreplaced by the new case (See Figure\
    \ 47(b)). \n \n(a) \n96 \n \n \n(b) \nFigure 47. An example of updating the existing\
    \ association: (a) scenario 1; (b) scenario 2. \nIn Figure 47(a), when a new case\
    \ N1 is compared with the past cases P133, P148, and P301, it is \ndetected that\
    \ the similarity measurement between N1 and P148 achieves a higher value. As a\
    \ result, \nP148 takes the first position in the similar association of N1. Meanwhile,\
    \ N1’s existing association \nwith P407 and P157 has a minor adjustment by moving\
    \ backward their positions in the association. \nIt works the same for updating\
    \ the association with P301. \nIn Figure 47(b), the similar and dissimilar association\
    \ of P14 is presented. During the iteration, \nP14 is compared with N1. The comparative\
    \ result indicates that N1 has a closer association than \nP256 with P14. Consequently,\
    \ N1 updates the third position in the similar association of P14 and P256 \n\
    is therefore removed from the association. \n \n97 \n \n5 \nA hybrid decision\
    \ \nsupport mechanism\n98 \n \n    As described in Chapters 3 and 4, the CBR approach\
    \ can be used to model the decision \nsupport system, assisting farmers in managing\
    \ farming operations. After retrieving a collection \nof similar past cases, their\
    \ solutions can be adapted to solve the current situations effectively and \n\
    efficiently. Lastly, the learned case can be stored in the case base for further\
    \ retrieval tasks. \nHowever, it is detected that CBR cannot always retrieve a\
    \ collection of similar past cases because \nthe case base is not wide enough\
    \ to cover everything. It happens that the new problem has never \noccurred before.\
    \ In other words, CBR cannot provide farmers with sufficient advice about solving\
    \ \nthe new problem. As a consequence, a mediator approach for developing a hybrid\
    \ decision \nsupport system is proposed in this chapter. \n5.1. A mediator approach\
    \ for the hybrid decision support system \nIn software engineering, the mediator\
    \ pattern is considered as a behavioral pattern due to the \nreason that it can\
    \ alter the program’s running behavior. It promotes loose coupling by keeping\
    \ \nobjects from referring to each other explicitly and interacting independently.\
    \ In terms of coupling, \nit refers to the degree to which objects depend on each\
    \ other. Usually, tightly coupled objects are \nhard to implement, change, test,\
    \ and reuse because they depend on many different objects. While \nloosely coupled\
    \ objects are easier to implement, change, test, and reuse because they are only\
    \ \nminimal dependencies on other objects. The mediator pattern defines an object\
    \ (Mediator) that \nencapsulates how a set of objects interact. The core of this\
    \ pattern is to let objects interact with \neach other indirectly, but though\
    \ the defined Mediator object that controls and coordinates the \ninteraction.\
    \ This makes the objects loosely coupled because they only depend on the simple\
    \ \nMediator interface. \n5.1.1. Problem statement in the mediator design pattern\
    \ \nThe mediator design pattern tries to solve the problems like the following:\
    \ \n• \nHow can tight coupling between a set of interacting objects be avoided?\
    \ \n• \nHow can the interaction between a set of objects be changed independently?\
    \ \nFor instance, an inflexible way is to define a set of interacting objects\
    \ (Objects1, Objects2, \n…) by referring to each other directly, leading to many\
    \ interconnections between them. An \nexample of tightly coupled objects is presented\
    \ in Figure 48. \n \n \n \n99 \n \n \n(a) \n \n(b) \nFigure 48. An example of\
    \ tightly coupled objects: (a) class diagram; (b) sequence diagram. \n \nIn Figure\
    \ 48, the tightly coupled objects make it impossible to change the interaction\
    \ \nindependently without changing other objects. Meanwhile, this design pattern\
    \ has difficulty in \nreusing and testing existing objects because objects are\
    \ interconnecting with each other tightly. \n \nThe same problem occurs in the\
    \ design of the hybrid decision support system. When the \nCBR decision support\
    \ algorithm is unable to generate the suggestions for farmers, the CBR \nalgorithm\
    \ will request other decision support algorithms for providing the advice. Under\
    \ this \ncircumstance, different decision support algorithms have to communicate\
    \ with each other, as \nshown in Figure 49. \n100 \n \n \n(a) \n \n(b) \nFigure\
    \ 49. Tightly coupled decision support algorithms: (a) class diagram; (b) sequence\
    \ diagram. \n \nIn Figure 49, extra functions have to be implemented if new algorithms\
    \ are added into the \nframework of the decision support systems, leading to high\
    \ communication costs. \n5.1.2. Solution of the mediator approach \nThe mediator\
    \ design pattern provides a solution by defining a separate Mediator object that\
    \ \nencapsulates how a set of objects interact. Instead of interacting with each\
    \ other directly, the \ncommunication between objects is controlled by this Mediator\
    \ object. The class and sequence \ndiagrams of the mediator approach are presented\
    \ in Figure 50. \n101 \n \n \n(a) \n \n(b) \nFigure 50. The solution of the mediator\
    \ approach: (a) class diagram; (b) sequence diagram. \n \nIn Figure 50, a separate\
    \ object, Mediator, is defined as an interface for interacting with other \nobjects.\
    \ Meanwhile, a class (Mediator1) is implemented for controlling and coordinating\
    \ the \ninteraction between objects. Owing to the class inheritance, this mediator\
    \ pattern enables great \nflexibility. For instance, new objects can be added\
    \ into this design and the interaction behavior of \nexisting ones can be changed\
    \ independently by defining new mediator classes. \n102 \n \n \nFor demonstrating\
    \ the effectiveness of the mediator pattern and how a mediator works in \ncontrolling\
    \ the interaction between several objects, an example is presented and implemented\
    \ in \nthe Python programming language. \n \nFirstly, the Mediator interface is\
    \ defined by abstract base classes, shown in Figure 51. \n \nFigure 51. The Python\
    \ code of implementing the abstract Mediator interface. \n \nIn Figure 51, the\
    \ Mediator interface declares a method used by components to notify the \nmediator\
    \ about various events. The mediator may react to these events and pass the execution\
    \ to \nother components. \n \nSecondly, the Mediator interface is instanced in\
    \ Figure 52. \n \nFigure 52. The Python code of implementing the concrete Mediator\
    \ interface. \n \nIn Figure 52, two components (conponent1 and component2) are\
    \ initialized and connected \nto the Mediator interface. Meanwhile, two types\
    \ of events are specified. If each one of the events \nis triggered, component1\
    \ and component2 will execute the assigned tasks accordingly. \n \nThirdly, the\
    \ base component is implemented in Figure 53. \n103 \n \n \nFigure 53. The Python\
    \ code of implementing the base component. \n \nIn Figure 53, the base component\
    \ provides the basic functionality of storing a mediator’s \ninstance inside component\
    \ objects. \n \nFourthly, the two ordinary components are instanced in Figure\
    \ 54. \n \nFigure 54. The Python code of implementing the ordinary components.\
    \ \n \nIn Figure 54, component1 and component2 can execute defined actions when\
    \ being triggered. \nIt is worth mentioning that these concrete components can\
    \ be enriched by various functionalities \nand they do not depend on other components.\
    \ These components do not rely on any concrete \nmediator classes as well. \n\
    \ \n \n \n \n104 \n \nLastly, the main function of the example is implemented,\
    \ shown in Figure 55. \n \nFigure 55. The Python code of implementing the main\
    \ function. \n \nIn Figure 55, two ordinary components are instanced as c1 and\
    \ c2 respectively. Two tests are \nperformed for verifying the mediator pattern\
    \ design. The test results are presented in Figure 56. \n \nFigure 56. The test\
    \ result of the mediator implementation. \nIn the first test, component1 is triggered\
    \ for taking the action A. As demonstrated in Figure \n52, if component1 is triggered,\
    \ component2 is requested to execute the action C. In the second \ntest, component2\
    \ is triggered for taking the action D. After this action, component1 reacts to\
    \ the \nmediator for executing the action B and component2 is taking the action\
    \ C. \n105 \n \nIn conclusion, the Mediator interface is able to coordinate the\
    \ ordinary components \neffectively and it enables a loosely coupled network.\
    \ Each ordinary component can execute tasks \nindependently. \n5.1.3. Design of\
    \ the hybrid decision support system with the mediator \napproach \n \nIn the\
    \ framework of the proposed DSS, it is promising to introduce this mediator pattern\
    \ for \nmanaging the decision support algorithms in case that the CBR algorithm\
    \ fails to retrieve a \ncollection of similar past cases. Considering the combination\
    \ of various algorithms, a framework \nof the hybrid DSS is proposed in Figure\
    \ 57. \n \nFigure 57. The framework of a general hybrid decision support system.\
    \ \n \nIn Figure 57, the mediator component is put between the algorithm manager\
    \ and the \nalgorithm toolbox. This mediator component is responsible to perform\
    \ the following tasks. \n• \nReceiving commands from the algorithm manager. \n\
    • \nForwarding the generated decision supports to the algorithm manager. \n• \n\
    Assigning received missions to the algorithm toolbox. \n• \nReceiving the generated\
    \ decision supports from the algorithm toolbox. \n• \nResponding to failures of\
    \ generating decision supports. \n• \nCoordinating the communication between different\
    \ decision support algorithms. \nBy adopting the mediator approach, various decision\
    \ support algorithms do not need to \ninteract with each other directly, instead,\
    \ the communication is controlled and coordinated by the \n106 \n \nmediator component.\
    \ Three situations are considered in the hybrid DSS: (i) the CBR algorithm \n\
    can generate the decision support independently (in Figure 58), (ii) the CBR algorithm\
    \ fails to \ngenerate the decision support and requests help from other algorithms\
    \ (in Figure 59), and (iii) all \nalgorithms fail to provide the decision supports\
    \ (in Figure 60). \n \nFigure 58. The workflow of the hybrid decision support\
    \ system for situation (i). \n \nFigure 58 displays the workflow of the hybrid\
    \ DSS for the situation that the CBR algorithm \ncan generate the decision supports\
    \ independently. The below steps are followed. \n• \nStep 1: Inputs are sent to\
    \ the MMT.  \n• \nStep 2: As a command and control center for planning and supervising\
    \ the missions, the \nMMT transforms the received inputs into a specific mission.\
    \ This mission is then sent to the \nalgorithm manager component. \n• \nStep 3:\
    \ According to the requirements and constraints of the mission, the algorithm\
    \ manager \ncomponent selects a suitable decision support algorithm and sends\
    \ a request to the mediator \ncomponent (i.e. starting the CBR algorithm). \n\
    • \nStep 4: The mediator component sends the command of starting the CBR algorithm\
    \ and \npasses the mission information to this algorithm for reasoning. \n• \n\
    Step 5: The CBR algorithm takes the mission information and collected data from\
    \ cloud and \nexternal databases as inputs for reasoning. After the decision support\
    \ is generated, the result \nis returned to the mediator component. \n• \nStep\
    \ 6: The mediator component sends the received result to the algorithm manager\
    \ \ncomponent. \n• \nStep 7: The algorithm manager component sends the received\
    \ result to the MMT. \n• \nStep 8: The MMT displays the final output to the users.\
    \ \n107 \n \nFor the above situation, the CBR algorithm can solve the new mission\
    \ independently. \nTherefore, the mediator only communicates with the CBR algorithm\
    \ and the algorithm manager \ncomponent. Other algorithms do not get involved.\
    \ \n \nFigure 59. The workflow of the hybrid decision support system for situation\
    \ (ii). \n \nFigure 59 displays the situation that the CBR algorithm cannot complete\
    \ the mission alone. \nUnder this circumstance, other algorithms are supposed\
    \ to take over the responsibility of \ngenerating the decision supports. As such,\
    \ the below steps are followed to achieve the objective. \n• \nStep 1: Inputs\
    \ are sent to the MMT. \n• \nStep 2: The MMT transforms the received inputs into\
    \ a specific mission. This mission is then \nsent to the algorithm manager component.\
    \ \n• \nStep 3: According to the requirements and constraints of the mission,\
    \ the algorithm manager \ncomponent selects a suitable decision support algorithm\
    \ and sends a request to the mediator \ncomponent (i.e. starting the CBR algorithm).\
    \ \n• \nStep 4: The mediator component sends the command of starting the CBR algorithm\
    \ and \npasses the mission information to this algorithm for reasoning. \n• \n\
    Step 5: When the CBR algorithm fails to retrieve a collection of similar past\
    \ cases, the CBR \nalgorithm returns a failure message to the mediator component\
    \ and requests additional help \nfrom other algorithms. \n• \nStep 6: The indicated\
    \ algorithm receives the request from the mediator component and starts \nthe\
    \ process of generating decision supports. \n• \nStep 7: The generated decision\
    \ support is returned to the mediator component. \n• \nStep 8: The mediator component\
    \ sends the received result to the algorithm manager \ncomponent. \n• \nStep 9:\
    \ The algorithm manager component sends the received result to the MMT. \n108\
    \ \n \n• \nStep 10: The MMT displays the final output to the users. \nFor the\
    \ above situation, since the CBR algorithm cannot provide an output, other decision\
    \ \nsupport algorithms are acting as supplementary components for supporting the\
    \ CBR algorithm. \nMeanwhile, owing to the presence of the mediator component,\
    \ the CBR algorithm and other \nsupplementary algorithms do not interact with\
    \ each other directly. All the communication and \ncoordination tasks are controlled\
    \ by the mediator component. \n \nFigure 60. The workflow of the hybrid decision\
    \ support system for situation (iii). \n \nFigure 60 presents the third situation\
    \ that all algorithms fail to generate the decision supports \nfor the given problem.\
    \ The workflow of this situation is listed as follows. \n• \nStep 1: Inputs are\
    \ sent to the MMT. \n• \nStep 2: The MMT transforms the received inputs into a\
    \ specific mission. This mission is then \nsent to the algorithm manager component.\
    \ \n• \nStep 3: According to the requirements and constraints of the mission,\
    \ the algorithm manager \ncomponent selects a suitable decision support algorithm\
    \ and sends a request to the mediator \ncomponent (i.e. starting the CBR algorithm).\
    \ \n• \nStep 4: The mediator component sends the command of starting the CBR algorithm\
    \ and \npasses the mission information to this algorithm for reasoning. \n• \n\
    Step 5: When the CBR algorithm fails to retrieve a collection of similar past\
    \ cases, the CBR \nalgorithm returns a failure message to the mediator component\
    \ and requests additional help \nfrom other algorithms. \n• \nStep 6: The mediator\
    \ component requests the Algorithm 2 for generating the decision support. \n•\
    \ \nStep 7: The Algorithm 2 sends a failure message to the mediator component.\
    \ \n• \nStep 8: The mediator component requests the Algorithm 3 for generating\
    \ the decision support. \n109 \n \n• \nStep 9: The Algorithm 3 sends a failure\
    \ message to the mediator component. \n• \nStep 10: The mediator component checks\
    \ the registered decision support algorithms. If all \nalgorithms fail to generate\
    \ any results, the mediator component sends a failure message to \nthe algorithm\
    \ manager component. \n• \nStep 11: The algorithm manager component returns the\
    \ failure result to the MMT. \n• \nStep 12: The MMT displays the failure result\
    \ as the output. \nFor the above situation, the mediator component confirms with\
    \ all registered algorithms. If \nall algorithms are unable to generate any results,\
    \ the mediator component will send a failure \nmessage to the algorithm manager\
    \ component. \nInspired by the Oracle Mediator [265] (See Appendix B), in particular\
    \ its functionality and \nmessage exchange patterns, the mediator in this thesis\
    \ has the following functionalities. \n• \nMessage routing: The mediator can consume\
    \ a message from one channel and republish it \nto a different channel based on\
    \ specified conditions. For instance, the algorithm manager \ncomponent would\
    \ like to start the CBR algorithm in the algorithm toolbox component for \nexecuting\
    \ a specific mission. A message should be sent from the algorithm manager to the\
    \ \nalgorithm toolbox through the mediator. \n• \nEvent handling: The mediator\
    \ can both subscribe and raise events. For instance, after a new \nalgorithm is\
    \ registered, an algorithm-registered event can be generated. \n• \nError handling:\
    \ The mediator supports error handling based on fault policies. For instance,\
    \ \nif the CBR algorithm fails to generate decision supports, the mediator is\
    \ able to coordinate \nother algorithms for offering supplementary help. \n• \n\
    Echo: The mediator is able to echo source messages back to the initial caller\
    \ after any \ntransformations, validations, assignments, or sequential operations\
    \ are performed.  \nConsidering the above three situations and four functionalities,\
    \ the structure of a message \ntransmitted between the mediator and other components\
    \ is defined as “Request-Response-Fault” \nin Figure 61. \nIn Figure 61, the header\
    \ of the message stores the information of the sender, receiver, and \ntime stamp.\
    \ For instance, the sender could be the algorithm manager component and the receiver\
    \ \ncan be any one of the algorithms.  \nThe request part starts with a request\
    \ ID, then explains the request information and request \nstatus (i.e. on-going\
    \ or complete). The following requests are considered. Registering an \nalgorithm.\
    \ \n110 \n \n• \nUnregistering an algorithm. \n• \nListing all registered algorithms.\
    \ \n• \nStarting an algorithm. \n• \nStopping an algorithm. \n• \nChecking a running\
    \ algorithm. \nThe response part is composed of a response ID and the response\
    \ information. In general, \nthe response information is the generated decision\
    \ support for the assigned mission. Under the \ncircumstance that the specified\
    \ algorithm fails to provide any results, the response will return a \nfailure\
    \ result. \nThe fault part includes a fault ID, a fault type, and a fault reason.\
    \ The following fault types \nare considered in the hybrid decision support system.\
    \ \n• \nFailure of registering an algorithm. \n• \nFailure of unregistering an\
    \ algorithm. \n• \nFailure of listing registered algorithms. \n• \nFailure of\
    \ starting an algorithm. \n• \nFailure of stopping an algorithm. \n• \nFailure\
    \ of checking a running algorithm. \n• \nFailure of generating a decision support.\
    \ \n \nFigure 61. The structure of the “Request-Response-Fault” message. \n \n\
    It is not necessary to fill each block of the message. For instance, when the\
    \ algorithm \nmanager component request to start the CBR algorithm for executing\
    \ a mission, the CBR \n111 \n \nalgorithm successfully generates the result. Under\
    \ this circumstance, there are not any errors \noccurred, therefore the values\
    \ of fault part are left empty (Null values). \n5.2. A preliminary proof of the\
    \ hybrid concept \nIn this section, a preliminary proof of the hybrid concept,\
    \ namely how the hybrid decision \nsupport system is envisaged to be useful in\
    \ the AFarCloud platform, is provided. In particular, \ntwo decision support algorithms\
    \ are taken into consideration in this hybrid concept, namely the \nCBR algorithm\
    \ and an artificial neural network (ANN) algorithm [266]. \nThis preliminary proof\
    \ concerns the situation that UAVs are adopted to execute plant \nprotection missions.\
    \ The objective is to improve the efficiency of agricultural aviation spraying,\
    \ \nto reduce the use of chemical pesticides, and to increase crop yields by employing\
    \ both CBR and \nANN algorithms. The framework of the hybrid decision support\
    \ system is presented in Figure 62. \n \nFigure 62. The framework of the hybrid\
    \ decision support system combining CBR and ANN. \nIn Figure 62, the mediator\
    \ is responsible to coordinate the communication between the \nalgorithm manager\
    \ component and the algorithm toolbox component.  \nWithin the algorithm toolbox\
    \ component, on the one hand, the CBR algorithm has been \nexplained in Section\
    \ 4, on the other hand, the ANN algorithm is briefly explained in Appendix C.\
    \ \nIn both algorithms, the flight speed (\U0001D45A/\U0001D460), flight altitude\
    \ (\U0001D45A), propeller pitch (\U0001D45A), nozzle \npitch (\U0001D45A), temperature\
    \ (Celsius), wind speed (\U0001D45A/\U0001D460), and prescription value (\U0001D43F\
    \ ℎ\U0001D45A2\n⁄\n) are taken as \ninputs, while the droplet deposition (µ \U0001D43F\
    \ ℎ\U0001D45A2\n⁄\n) is considered as the output. The statistical \nproperties\
    \ of the sample data are shown in Table 17. \n112 \n \nTable 17. The statistical\
    \ properties of the sample data. \nFeature name \nMax \nMin \nMean \nStandard\
    \ deviation \nFlight speed \n5.22 \n1.00 \n3.01 \n0.9842 \nFlight altitude \n\
    4.08 \n1.45 \n1.92 \n0.6912 \nTemperature \n32.00 \n25.00 \n28.77 \n1.7501 \n\
    Propeller pitch \n1.40 \n1.20 \n1.31 \n0.0991 \nNozzle pitch \n0.55 \n0.45 \n\
    0.513 \n0.0380 \nWind speed \n3.20 \n0.01 \n1.144 \n0.5853 \nPrescription \n48.00\
    \ \n5.00 \n20.50 \n9.5481 \nDeposition \n8.86 \n0.01 \n5.69 \n15.7242 \nFor testing\
    \ purpose, ten cases are selected from the sample data (100 cases) and their \n\
    recorded deposition values are removed from the solution part of cases. If a similar\
    \ case can be \nretrieved from the case base, then it is acknowledged that the\
    \ CBR algorithm can solve the \nproblem independently, otherwise, the ANN algorithm\
    \ is required to offer additional help for \nsolving the problem. The reuse, revision,\
    \ and retention parts are not considered in this preliminary \nproof because the\
    \ priority task is to retrieve a similar past case. \nApart from the effectiveness\
    \ of the CBR and ANN algorithms, the contribution of the \nmediator component\
    \ is another objective of this preliminary proof. It is important to verify \n\
    whether the mediator component can coordinate the communication between the algorithm\
    \ \nmanager component and the algorithm toolbox component. Therefore, the results\
    \ of the CBR and \nANN algorithms are presented in Sections 5.2.1 and 5.2.2 respectively,\
    \ while the result of the \nmediator component is presented in Section 5.2.3.\
    \ \n5.2.1. Result of the CBR algorithm \nThe CBR algorithm in this preliminary\
    \ proof is implemented by myCBR [266], which is an \nopen-source similarity-based\
    \ retrieval tool and software development kit (SDK). A new project \nis created\
    \ in the myCBR workbench, shown in Figure 63. \nIn Figure 63, a new project, named\
    \ “myTest”, is created and a concept, named \n“sprayMission”, is defined. For\
    \ each attribute, its minimum and maximum boundaries are \nspecified. For instance,\
    \ the attribute “flightAltitude” is defined by the float type and the value \n\
    ranges from 1.45 to 4.08, shown in Figure 64. \n \n113 \n \n \nFigure 63. The\
    \ new project in the myCBR workbench. \n \nFigure 64. The attribute defined in\
    \ the myCBR workbench. \nA case base is constructed by 90 past cases in the myCBR\
    \ workbench, named \n“myTestCaseBase”, shown in Figure 65. In this figure, it\
    \ displays the number of cases and the \nnumber of attributes in a case. The information\
    \ of the variety of each attribute is also included in \nthe statistics window.\
    \ For instance, the nozzle pitch has three values (0.45, 0.5, and 0.55). \n \n\
    Figure 65. The case base in the myCBR workbench. \n114 \n \n \nThe weight of each\
    \ attribute and the similarity measure can be specified by the user, as shown\
    \ \nin Figure 66. \n \nFigure 66. The configuration of the similarity measure\
    \ in the myCBR workbench. \n \nFor executing the retrieval task, the user has\
    \ to input the query data for each attribute and \nthen press the “Start retrieval”\
    \ button. Then, the retrieval result will be displayed. The retrieved \nsimilar\
    \ past cases are listed in descending order. Meanwhile, the attributes of retrieved\
    \ cases are \npresented. \n \nFigure 67. The retrieval process in the myCBR workbench.\
    \ \nConclusively, the CBR algorithm is able to solve the new problem as long as\
    \ a collection of \nsimilar past case is retrieved from the case base. Under this\
    \ circumstance, the response part of the \n115 \n \nmessage returns the successful\
    \ retrieval result and the information of the fault part is filled by null \n\
    values. \n5.2.2. Result of the ANN algorithm \nThe ANN algorithm is able to calculate\
    \ the value of droplet deposition independently as well. \nThe software interface\
    \ is shown in Figure 68. The software is mainly divided into model training \n\
    and deposition prediction parts. Firstly, the model is trained by the collected\
    \ samples and the BP \nneural network program. Secondly, the user inputs the UAV,\
    \ pesticide, and environmental \nparameters manually. Thirdly, the saved training\
    \ model is used for calculating the predicted \ndeposition value. Until the error\
    \ satisfied the preset threshold, the output is generated and returned \nto the\
    \ algorithm manager component through the mediator component. \n \nFigure 68.\
    \ The software interface of the ANN algorithm. \n5.2.3. Result of the hybrid concept\
    \ \nSince the hybrid DSS is implemented in the Python programming language, the\
    \ structure of \nthe message (see Figure 61) is defined in Figure 69. The structures\
    \ of the request, response, and \nfault parts are shown in Figure 70. \n116 \n\
    \ \n \nFigure 69. The structure of the message implemented by Python. \n \nFigure\
    \ 70. The structures of the request, response, and fault parts implemented by\
    \ Python. \n \nFor starting a spraying mission, a message is sent from the algorithm\
    \ manager component to \nthe algorithm toolbox component, containing the necessary\
    \ information of the header and main \nbody (request, response, and fault). An\
    \ example of sending the message is shown in Figure 71. \n \nFigure 71. An example\
    \ of sending the message to the CBR algorithm. \n117 \n \n \nAfter receiving the\
    \ message in Figure 71, the CBR algorithm reads the information from the \nrequest\
    \ part and executing the required actions (i.e. reading the mission information\
    \ from the \ndatabase and starting the CBR algorithm for generating the decision\
    \ support). \n \nIt is assumed that the CBR algorithm fails to retrieve a collection\
    \ of similar past cases, and \ntherefore the CBR algorithm cannot the complete\
    \ the assigned mission independently. At this \ntime, the CBR algorithm returns\
    \ the message to the algorithm manager with a failure result. An \nexample of\
    \ returning the message is shown in Figure 72. In this figure, the value of response\
    \ is \nleft empty due to the reason that the CBR algorithm fails to generate the\
    \ decision support. \n \nFigure 72. An example of returning the failure message\
    \ from the CBR algorithm. \nAfter receiving the message shown in Figure 72, the\
    \ algorithm manager checks the registered \nalgorithms to look for a substitution\
    \ algorithm for completing the mission. If there is an alternative \nalgorithm\
    \ is available, the algorithm manager component sends a new message for executing\
    \ the \nmission. In this preliminary proof, the alternative is the ANN algorithm.\
    \ Thus, the algorithm \nmanager component sends a new message to the ANN algorithm,\
    \ as shown in Figure 73. \n118 \n \n \n Figure 73. An example of sending the message\
    \ to the ANN algorithm. \nAfter receiving the message in Figure 73, the ANN algorithm\
    \ reads the information from the \nrequest part and executing the required actions.\
    \ As soon as the deposition value is calculated \nsuccessfully, the ANN algorithm\
    \ returns the response information back to the algorithm manager \ncomponent through\
    \ the mediator component, shown in Figure 74. \n \nFigure 74. An example of returning\
    \ the response from the ANN algorithm. \n \nIn Figure 74, the ANN algorithm obtains\
    \ the deposition value of 5.71 according to the \ncalculation over the mission\
    \ information. Since there is no error occurred during the calculation, \nthe\
    \ fault part is left empty and returned to the algorithm manager component. \n\
    \ \nJudging from the result of the preliminary proof, the mediator pattern design\
    \ is able to \ncoordinate various components and algorithms within the hybrid\
    \ DSS. In particular, the mediator \n119 \n \ncomponent is useful when the CBR\
    \ algorithm fails to generate the result and requires alternative \nalgorithms\
    \ to offer helps. \n120 \n \n6 \nImplementation and \nvalidation\n121 \n \n  \
    \  This section shows the implementation of the CBR decision support algorithm.\
    \ Additionally, \neach step of the CBR algorithm is validated through extensive\
    \ experiments. The experimental \nresults demonstrate that the proposed CBR decision\
    \ support algorithm is able to achieve great \nimprovements than the typical CBR\
    \ approach. \n6.1. Implementation scope and purpose \n    The scope and purpose\
    \ is to implement each step of the CBR algorithm, including the \nassociated case\
    \ representation formalism (introduced in Section 4.1), the triangular similarity\
    \ \nmeasure (introduced in Section 4.2), the fast case retrieval algorithm (introduced\
    \ in Section 4.3), \nthe learning-based approach for solution reused and revision\
    \ (introduced in Section 4.4), and the \nassociated case retention approach (introduced\
    \ in Section 4.5). The implementation of the CBR \nalgorithm within the DSS is\
    \ shown in Figure 75. \n \nFigure 75. Implementation scope within the decision\
    \ support system. \n \nIt is worth mentioning that the proposed CBR algorithm\
    \ takes advantage of some existing \ntechniques like the feature vector representation\
    \ and the Euclidean distance measure. In this thesis, \nthe newly proposed methods\
    \ largely extend over the foundations of these existing techniques, \ninstead\
    \ of starting from the scratch.  \n6.2. The implementation details \nThe proposed\
    \ CBR algorithm is mainly implemented by the Python programming language. \nSpyder\
    \ (version 3.3.3) [267], a scientific Python development environment, is adopted\
    \ for \n122 \n \nimplementation. The Python version in the Spyder environment\
    \ is 3.7.3, 64-bit for Windows 10. \nA screenshot of this development environment\
    \ is shown in Figure 76. \n \n Figure 76. The Spyder development environment.\
    \ \n6.2.1. Implementation of the associated representation formalism \nThe associated\
    \ case representation formalism is adopted in this thesis for managing the \n\
    content and structure of agricultural cases. This representation formalism follows\
    \ a “problem-\nsolution-association” structure. \nFor implementation, two approaches\
    \ are employed to organize these agricultural cases: (i) \nextensible markup language\
    \ (XML) files, and (ii) comma-separated values (CSV) files. On the \none hand,\
    \ the structure of XML-based cases is flexible and the case storage is relatively\
    \ \nindependent. Meanwhile, the node custom function in XML enables to create\
    \ new cases \nconveniently. An example of the XML implementation is shown in Figure\
    \ 77. On the other hand, \nthe structure of CSV-based cases allows data to be\
    \ stored in a tabular format. Since the CBR \nalgorithm is coded by the Python\
    \ programming language, libraries like “Numpy” and “Pandas” \ncan be used to manipulate\
    \ the stored past case easily. Furthermore, farmers can read and \nunderstand\
    \ data in CSV format without requiring any expertise in knowledge management or\
    \ \ncomputer science. An example of the CSV implementation is shown in Figure\
    \ 78. \n123 \n \n \nFigure 77. The associated case representation formalism implemented\
    \ in XML. \n \nFigure 78. The associated case representation formalism implemented\
    \ in CSV. \nFour functions are defined by the Python programming language for\
    \ reading and writing the \nXML and CSV files. \nFor reading and writing the XML\
    \ files, the document object model (DOM) interface, \n“xml.dom.minidom”, is adopted.\
    \ A DOM application typically starts by parsing XML into DOM. \nThe parse function\
    \ can take either a filename or an open file object. The parsing process is done\
    \ \nin Figure 79. This figure shows both approaches of using the parse function.\
    \ The DOM standard \nis briefly introduced in Appendix D. \n124 \n \n \nFigure\
    \ 79. The parse function in the DOM interface. \nMeanwhile, the Document module\
    \ in “xml.dom.minidom” is used to write new elements and \ntheir values into the\
    \ XML files. Figure 80 shows an example of writing XML elements in Python. \n\
    \ \nFigure 80. The function of writing XML elements in Python. \nIn summary, the\
    \ functions of reading and writing the XML cases are implemented as shown \nin\
    \ Figure 81. It is noted that “xml.dom” and “xml.dom.minidom” should be imported.\
    \ \n \nFigure 81. The function of reading and writing XML-based cases in Python.\
    \ \n125 \n \nSecondly, for reading and writing cases in the CSV format, two functions\
    \ are implemented \nas shown in Figure 82. \n \nFigure 82. The function of reading\
    \ and writing CSV-based cases in Python. \nIn Figure 82, the CSV module is imported\
    \ and this module implements classes to read and \nwrite tabular data in CSV format.\
    \ Mainly, the CSV module defines the following two functions. \n• \ncsv.reader(csvfile,dialect=’excel’,**fmtparams):\
    \ This function returns a reader object which \niterates over lines in the given\
    \ CSV files. The csvfile can be any object which supports the \niterator protocol\
    \ and returns s string each time. The dialect parameter is optional and used to\
    \ \ndefine a set of parameters specific to a particular CSV dialect. The dialect\
    \ parameter may be \nan instance of a subclass of the Dialect class or one of\
    \ the strings returned by the \nlist_dialects() function. The last parameter in\
    \ this function, named fmtparams, is optional as \nwell. This parameter can be\
    \ given to override individual formatting parameters in the current \ndialect.\
    \ \n• \ncsv.writer(csvfile,dialect=’excel’,**fmtparams): This function returns\
    \ a writer object which \nis responsible for converting the data into delimited\
    \ strings on the given file-like object. The \ncsvfile can be any object with\
    \ a write() method. The dialect parameter is optional and has the \nsame configuration\
    \ as it defines in the reader() function. The other optional keyword, \nfmtparams,\
    \ argues that it can be given to override individual formatting parameters in\
    \ the \ncurrent dialect. \nFor constructing the association of past cases, it\
    \ is necessary to measure the similarity \nbetween each of them. After obtaining\
    \ and sorting all the similarity measurements, each case can \nbe associated with\
    \ several similar and dissimilar ones. Though constructing the association is\
    \ a \ntime-consuming process when a large volume of cases is stored, it is still\
    \ essential to explore the \nrelations between past cases. Because this hidden\
    \ information could be useful for case retrieval. \n126 \n \nBesides, this construction\
    \ is a one-time task. The Python code for generating the similar \nassociation\
    \ of past cases is presented in Figure 83. \n \nFigure 83. The code of constructing\
    \ the association implemented in Python. \nIn Figure 83, in the first part, the\
    \ function getTSM(case1,case2) evaluates the proposed \ntriangular similarity\
    \ measurement between two cases. In the second part, all similarity \nmeasurements\
    \ are sorted by taking advantage of the NumPy package, in particular, the min()\
    \ and \nmax() functions. Lastly, the sorted results are saved to the original\
    \ CSV file. For generating the \ndissimilar association, it follows the same procedure.\
    \ \n6.2.2. Implementation of the triangular similarity measure \nThe triangular\
    \ similarity measure combines the Euclidean distance, the cosine similarity \n\
    measure, and the magnitude of compared vectors. Three functions, named getED,\
    \ getCosine, and \ngetMag, are implemented respectively. For manipulating the\
    \ vectors, NumPy, a fundamental \npackage for scientific computing with Python,\
    \ is adopted. The codes of implementing these three \nfunctions are shown in Figure\
    \ 84. The code of the proposed triangular similarity measure is shown \nin Figure\
    \ 85. \n127 \n \n \nFigure 84. The code of calculating the Euclidean distance,\
    \ the cosine similarity, and the magnitude \nimplemented in Python. \n \nFigure\
    \ 85. The code of calculating the triangular similarity measure implemented in\
    \ Python. \n \nIn Figure 85, The module math is imported, providing access to\
    \ the mathematical functions \ndefined by the C standard. Especially, the exp()\
    \ function is used. This function returns e raised to \nthe power x, where \U0001D452\
    \ = 2.718281. The exp() function converts the similarity measurements into \n\
    percentile values, which fit human notions better. After inputting the compared\
    \ two vectors, the \nfunction getTSM will return the similarity value in percentile.\
    \ \n6.2.3. Implementation of the fast case retrieval algorithm \nThe fast case\
    \ retrieval algorithm is implemented by the Python programming language as \n\
    well. As explained in Section 4.3, the fast retrieval algorithm takes advantage\
    \ of the similar and \ndissimilar associations of each past case. \nFirstly, the\
    \ case files should be loaded to the algorithm. Then, the new case is compared\
    \ with \nan entry-point case by the triangular similarity measure, shown in Figure\
    \ 86. \n128 \n \n \nFigure 86. The code of comparing the new case and entry-point\
    \ case implemented in Python. \n \nAfter obtaining the similarity measurement\
    \ between the new case and the entry-point case, \nthe corresponding association\
    \ is determined based on the number of assigned tokens. In order to \nassign the\
    \ tokens for the rest of iterations (apart from the entry-point comparison), the\
    \ following \ncodes are implemented in Figure 87, on the basis of the content\
    \ in Table 8. \n \nFigure 87. The code of assigning tokens implemented in Python.\
    \ \n \nFor determining the association in the next iteration, the number of positive\
    \ and \nnegative tokens are taken for comparison. According to the Policy 3 defined\
    \ in Section \n4.3, the corresponding association is selected, and therefore the\
    \ past case with the highest \n(or the lowest) similarity measurement is chosen\
    \ for being compared with the new case, \nshown in Figure 88. \n \nFigure 88.\
    \ The code of selecting the past case for the next iteration implemented in Python.\
    \ \n129 \n \n \nWhen it happens that all past cases in a single iteration have\
    \ been already compared, under \nsuch circumstance, the cases to be compared will\
    \ be selected from the previous iteration. \nTherefore, for managing those cases\
    \ which have been compared before, the fast retrieval \nalgorithm marks each past\
    \ case by two types of states: (i) used, and (ii) unused. The initial state \n\
    of each case is unused. After a past case is selected for comparison, its state\
    \ will become used. In \nthe fast case retrieval algorithm, the value “1” denotes\
    \ that a past case has been used while the \nvalue “0” denotes that a past case\
    \ has not been used. An array is defined to store the states of all \npast cases.\
    \ Meanwhile, an array for storing similarity measurement between the new case\
    \ and the \npast cases is defined, as well as an array for storing the history\
    \ of compared cases. For checking \nthe availability of unused cases in previous\
    \ iterations, the following code is implemented in Figure \n89.  \n \nFigure 89.\
    \ The code of retrieving unused past cases implemented in Python. \n \nIn Figure\
    \ 89, if all past cases have been used previously (the states of cases are marked\
    \ by \nthe value “1”), then the Python console will print the message “Error:\
    \ All cases are repeated!”. \nAfterwards, the retrieval algorithm will backtrack\
    \ unused past case in previous iterations. The \nvariable \U0001D450\U0001D45C\
    \U0001D462\U0001D45B\U0001D461 denotes the current number of iterations, while\
    \ the variable \U0001D456  denotes the \nbacktracked rounds. The backtracking\
    \ process is terminated until an unused past case is \nsuccessfully retrieved.\
    \ \n \nThe fast case retrieval algorithm terminates when the maximum iteration\
    \ number is reached \nor a past case which is identical to the new case is retrieved.\
    \ \n130 \n \n6.2.4. Implementation of the learning-based reuse and revision \n\
    The core of the learning-based reuse and revision approach is to detect the difference\
    \ between \nthe features of the new case and past cases. As defined in Equation\
    \ (19), the difference can be \nmeasured by the sum of local differences of features.\
    \ Therefore, the following code is \nimplemented in Figure 90. \n \nFigure 90.\
    \ The code of calculating the difference between cases implemented in Python.\
    \ \n \nIn Figure 90, the variables \U0001D463\U0001D452\U0001D4501 and \U0001D463\
    \U0001D452\U0001D4502 represent the compared cases, while the \nvariable \U0001D464\
    \ indicates the weight of each feature within the case. It is worth mentioning\
    \ that the \ncompared cases should be normalized before treating as inputs to\
    \ the function \U0001D450\U0001D44E\U0001D459\U0001D437\U0001D456\U0001D453\U0001D453\
    (). The \nnormalization process in the case retrieval algorithm takes advantage\
    \ of the package \nsklearn.preprocessing [268]. This package provides several\
    \ common utility functions and \ntransformer classes to change raw feature vectors\
    \ into a representation that is more suitable for \nthe downstream estimators.\
    \ The code of normalizing the dataset is implemented in Figure 91. \n \nFigure\
    \ 91. The code of normalizing the dataset implemented in Python. \n \nIn Figure\
    \ 91, the function min_max_scaler scales features to lie between a given minimum\
    \ \nand maximum value, usually between zero and one. \n \nAfter obtaining the\
    \ difference between the new case and the adaptation case, this difference \n\
    value is recorded, along with the adaptation case, are treated as inputs to the\
    \ case retrieval \nalgorithm for the purpose of identifying a collection of past\
    \ cases with similar difference. \n131 \n \n \nThe difference of solution between\
    \ the adaptation case and retrieved past cases is calculated \nas well by adopting\
    \ the same function \U0001D450\U0001D44E\U0001D459\U0001D437\U0001D456\U0001D453\
    \U0001D453(), presented in Figure 90. By learning from the \ndifference in the\
    \ solution part of past cases, the solution of the adaptation case can be revised\
    \ by \nincreasing or decreasing the value of features in the solution. The implementation\
    \ detail is \npresented in Figure 92. \n \nFigure 92. The code of revising the\
    \ solution of the adaptation case implemented in Python. \n \nIn Figure 92, the\
    \ function \U0001D45F\U0001D452\U0001D463\U0001D456\U0001D460\U0001D452\U0001D446\
    \U0001D45C\U0001D459\U0001D462\U0001D461\U0001D456\U0001D45C\U0001D45B() is defined.\
    \ The variable \U0001D44E\U0001D463\U0001D454\U0001D437\U0001D456\U0001D453\U0001D453\
    \ is the \nmean difference of the features within the retrieved past cases. By\
    \ updating each feature in the \nsolution part of the adaptation case, the revised\
    \ solution is generated and ready for being applied \nto the new case. \n6.2.5.\
    \ Implementation of the associated case retention approach \nAfter deciding to\
    \ retain a learned case, the problem, solution, and association parts of this\
    \ \nlearned case should be added into the case base. This retention process is\
    \ completed by adopting \nthe function \U0001D464\U0001D45F\U0001D456\U0001D461\
    \U0001D452\U0001D436\U0001D44E\U0001D460\U0001D452\U0001D436\U0001D446\U0001D449\
    \ shown in Figure 82. \n \nHowever, the update of existing associations cannot\
    \ be directly overwritten in the CSV files. \nMeanwhile, the deletion of a certain\
    \ past case cannot be completed by the writing functions. \nTherefore, the package\
    \ “Pandas” is adopted for managing these updates. The manipulation \nprocess is\
    \ presented in Figure 93. \n132 \n \n \nFigure 93. The process of updating the\
    \ existing associations in CSV files. \n \nIn Figure 93, the DataFrame from the\
    \ package “Pandas” is a two-dimensional size-mutable \ntabular data structure\
    \ with labeled axes (rows and columns). For generating a data frame from a \n\
    CSV file, the following function CSVtoDF is implemented, as shown in Figure 94.\
    \ \n \nFigure 94. The code of generating a data frame from a CSV file implemented\
    \ in Python. \n \nAfter the data frame is generated, the new association can be\
    \ added accordingly by adopting \nthe function updateAssociation, while the old\
    \ association can be deleted by the function \ndeleteAssociation, as shown in\
    \ Figure 95. \n \nFigure 95. The code of updating associations implemented in\
    \ Python. \n \nIn Figure 95, the function \U0001D459\U0001D45C\U0001D450() is\
    \ adopted for locating the position of desired data, while \nthe function \U0001D451\
    \U0001D45F\U0001D45C\U0001D45D() is employed for deleting the old association.\
    \ \n133 \n \n \nOnce all manipulations have been completed, the data frame is\
    \ written back to a new CSV \nfile, as shown in Figure 96. \n \nFigure 96. The\
    \ code of returning the data frame to a new CSV file implemented in Python. \n\
    6.3. The validation results \nAs described in Section 3, the CBR decision support\
    \ algorithm is mainly used by the \nalgorithm toolbox component. Due to the fact\
    \ that the MMT and the algorithm manager are still \nunder development and they\
    \ are also out of the scope of this thesis, the validation of the proposed \n\
    CBR algorithm is carried out by receiving direct commends from users and loading\
    \ data from \nlocal repositories, instead of receiving commands from the MMT and\
    \ loading data from the cloud \ndatabases. \nThe proposed CBR decision support\
    \ algorithm is employed to manage pest problems. The \npest considered in the\
    \ validation is Chilo suppressalis, while the target crop is rice. Totally, 3000\
    \ \npast cases are stored in the case base and 500 new cases are prepared for\
    \ tests. The objective of \nthe validation is to retrieve a collection of similar\
    \ past cases from the case base. The solutions of \nretrieved cases are reused\
    \ and revised to solve the new problems. Lastly, the learned case is \ndetermined\
    \ whether it should be retained in the case base or not. Though this CBR decision\
    \ \nsupport algorithm is developed within the AFarCloud European research project,\
    \ the deployment \nof sensors and vehicles has not been fully completed yet. Therefore,\
    \ simulated data are used \ncurrently and they are generated within a given range.\
    \ For instance, judging from the current \nliterature [269], the planting density\
    \ of rice usually ranges from 180 to 525 seeds/m2. The life \ncycle of rice can\
    \ be categorized by “embryogenesis”, “vegetative”, “ripening”, and “reproductive”\
    \ \nstages [270], encoded by integers “1”, “2”, “3”, and “4”. The simulated data\
    \ can be found in [271], \nincluding the problem part and solution part. The association\
    \ part is left empty for validation \npurpose. It is assumed that all the information\
    \ is complete and there are no missing data in both \nnew and past cases. \nEach\
    \ step of the CBR algorithm (including representation, retrieval, reuse, revision,\
    \ and \nretention) will be validated in the following sub-sections. In order to\
    \ evaluate the proposed CBR \nalgorithm, a typical CBR algorithm is used for comparison.\
    \ \n134 \n \nThe validation is carried out by using an Intel(R) Core (TM) i5-6200U\
    \ CPU @ 2.30GHz \n2.40GHz processor, being equipped with a RAM memory of 8.00\
    \ GB in a laptop, operating under \nthe 64-bit Windows 10 operating system. \n\
    6.3.1. Result of the associated case representation \nThe association part is\
    \ generated by sequentially comparing all past cases with each other. \nEach past\
    \ case is associated with three similar ones and three dissimilar ones, along\
    \ with their \nsimilarity measurements. A part of the similar and dissimilar associations\
    \ is presented in Tables \n18 and 19 respectively. \nTable 18. Part of the similar\
    \ association. \nPast Case \n1st sim \nsimValue  \n2nd sim \nsimValue \n3rd sim\
    \ \nsimValue \n1 \n541 \n94.53% \n588 \n94.18% \n2799 \n93.17% \n2 \n981 \n93.20%\
    \ \n1707 \n92.68% \n1931 \n91.32% \n3 \n2107 \n93.95% \n187 \n89.71% \n1946 \n\
    89.11% \n4 \n2687 \n93.85% \n1193 \n93.81% \n241 \n92.15% \n5 \n2454 \n97.14%\
    \ \n672 \n95.65% \n2438 \n94.97% \n… \n… \n… \n… \n… \n… \n… \n2996 \n2104 \n\
    92.91% \n405 \n91.34% \n2111 \n90.64% \n2997 \n644 \n96.98% \n563 \n95.31% \n\
    634 \n93.70% \n2998 \n2600 \n99.50% \n311 \n95.79% \n1265 \n93.52% \n2999 \n1263\
    \ \n95.41% \n246 \n94.67% \n373 \n94.45% \n3000 \n78 \n87.55% \n2258 \n87.15%\
    \ \n553 \n86.52% \nTable 19. Part of the dissimilar association. \nPast Case \n\
    1st dissim \nsimValue \n2nd dissim \nsimValue \n3rd dissim \nsimValue \n1 \n1356\
    \ \n6.31% \n1465 \n8.07% \n2764 \n8.15% \n2 \n2264 \n7.50% \n1446 \n9.50% \n2027\
    \ \n9.89% \n3 \n2134 \n6.08% \n184 \n6.67% \n1911 \n7.11% \n4 \n272 \n6.89% \n\
    2095 \n7.51% \n2990 \n8.14% \n5 \n964 \n17.58% \n2470 \n18.09% \n204 \n18.11%\
    \ \n… \n… \n… \n… \n… \n… \n… \n2996 \n1668 \n10.39% \n3000 \n11.06% \n2569 \n\
    11.79% \n2997 \n328 \n12.18% \n114 \n12.30% \n1898 \n12.84% \n2998 \n328 \n7.10%\
    \ \n2458 \n7.76% \n1316 \n8.12% \n135 \n \n2999 \n1140 \n13.44% \n1845 \n13.84%\
    \ \n2134 \n14.70% \n3000 \n2863 \n5.28% \n2430 \n5.49% \n548 \n5.67% \nOwing to\
    \ the adequate coverage, each past case is associated for at least one time. It\
    \ is noted \nthat a single past case can be associated with others for several\
    \ times, depending on the similarity \nmeasurements. For instance, in Table 19,\
    \ the past case 328 is dissimilarly associated with both \npast cases 2997 and\
    \ 2998, achieving the similarity measurements of 12.18% and 7.10% \nrespectively.\
    \ However, these dissimilar associations do not guarantee that past cases 2997\
    \ and \n2998 are similar with each other. For better demonstration, Figure 97\
    \ visualizes the normalized \nvalues of features in past cases 328, 2997, and\
    \ 2998. \n \nFigure 97. Data visualization of past cases 328, 2997, and 2998.\
    \ \nFigure 97 demonstrates that though both past cases 2997 and 2998 are dissimilar\
    \ to the past \ncase 328, they still have a major difference among data like pest\
    \ stage, infected area, and planting \ndensity. In fact, the similarity measurement\
    \ between past cases 2997 and 2998 only reaches \n67.08%. \nHowever, it is not\
    \ absolute that the above theory tells the whole story. There exists a \ncircumstance\
    \ that two cases are dissimilar to a single case at the same time, but these two\
    \ cases \nmay be similar with each other. An example is presented in Figures 98-100.\
    \ For evaluating the \ncommonalities among these three cases, the data covariance\
    \ function, root mean square error \n(RMSE), and mean absolute error (MAE) are\
    \ used. A smaller value of RMSE and MAE indicates \nthat the compared cases have\
    \ more commonalities. The analytic result of their data covariance is \npresented\
    \ in Table 20. \n136 \n \n \nFigure 98. Data visualization of past cases 19 and\
    \ 1836. \n \nFigure 99. Data visualization of past cases 19 and 674. \n137 \n\
    \ \n \nFigure 100. Data visualization of past cases 1836 and 674. \nTable 20.\
    \ Statistical analysis of past cases 19, 1836, and 674. \nCases \nSimilarity measurement\
    \ Data covariance RMSE \nMAE \n(P19, P1836) \n19.11% \n-0.0432 \n0.5859 \n0.4917\
    \ \n(P19, P674) \n19.17% \n-0.0355 \n0.5729 \n0.4878 \n(P1836, P674) \n93.85%\
    \ \n0.1447 \n0.1815 \n0.1466 \n \n \nIn Figures 98 and 99, and Table 20, it is\
    \ identified that past cases 1836 and 674 are both \ndissimilar to the past case\
    \ 19, reaching the similarity measurement of 19.11% and 19.17% \nrespectively.\
    \ Their values of data covariance are both negative as well, suggesting that past\
    \ cases \n1836 and 674 are truly dissimilar to the past case 19. This conclusion\
    \ is also verified through the \nvalues of RMSE and MAE. However, in Figure 100\
    \ and Table 20, the similarity measurement \nbetween past cases 1836 and 674 reaches\
    \ 93.85%, and the value of their data covariance is positive. \nIn other words,\
    \ these two cases are highly similar. \nAnother interesting fact is that a single\
    \ past case may appear in the similar association of \nothers for more than one\
    \ time. For example, the past case 984 appeared in the similar association \n\
    of past cases 748 and 749 respectively. The visualization of normalized data of\
    \ past cases 984, \n748, and 749 is displayed in Figure 101. The analytic result\
    \ is presented in Table 21. \n138 \n \n \nFigure 101. Data visualization of past\
    \ cases 984, 748, and 749. \nTable 21. Statistical analysis of past cases 984,\
    \ 748, and 749. \nCases \nSimilarity measurement Data covariance RMSE \nMAE \n\
    (P984, P748) \n95.76% \n0.0890 \n0.1630 \n0.1181 \n(P984, P749) \n95.79% \n0.0919\
    \ \n0.1590 \n0.1060 \n(P748, P749) \n86.78% \n0.0966 \n0.2422 \n0.1876 \n \nIn\
    \ Figure 101 and Table 21, the result shows that past cases 984, 748, and 749\
    \ all have great \ncommonalities, and their data inflections match with each other.\
    \ According to the data covariance \nspecification, if the covariance value is\
    \ positive, it means that the distribution of compared cases \nis within the same\
    \ direction. Meanwhile, a smaller covariance value indicates a closer correlation\
    \ \nbetween compared cases. From the result in Table 21, the covariance values\
    \ are all positive and \nthey have a tiny difference. Meanwhile, the values of\
    \ RMSE and MAE support this conclusion. \nA higher similarity measurement corresponds\
    \ to a smaller value of RMSE and MAE. \n \nAs a consequence, two conclusions can\
    \ be drawn according to the result of above examples. \n• \nIf a past case Px\
    \ is stored in the dissimilar association of past cases Py and Pz at the same\
    \ time, \nit is not guaranteed that past cases Py and Pz are similar or dissimilar.\
    \ \n• \nIf a past case Px is stored in the similar association of past cases Py\
    \ and Pz at the same time, \nthen past cases Py and Pz are potentially similar.\
    \ \n139 \n \nThis is the reason why the proposed fast case retrieval algorithm\
    \ tries to compare the \nassociated past cases preferentially, instead of traversing\
    \ all past cases in the case base. Under \ngeneral circumstances, the potential\
    \ target case usually exists among the association. \n6.3.2. Result of the triangular\
    \ similarity measure \nThe desired output of the evaluation for the triangular\
    \ similarity measure is the ID of the \nmost similar past case and its similarity\
    \ measurement with the new case. The experiment is \nconducted for 500 times since\
    \ there are 500 new cases. The fast case retrieval algorithm is not \nused in\
    \ this sub-section due to the reason that the efficiency of case retrieval is\
    \ not the main \nconcern for evaluating the triangular similarity measure. The\
    \ validation of the triangular similarity \nmeasure mainly focuses on the accuracy\
    \ of the measurement. In this sub-section, the proposed \ntriangular similarity\
    \ measure is compared with the typical Euclidean distance. The simulated data\
    \ \nof 500 new cases can be found in [272]. It is noted that after retrieving\
    \ a past case from the case \nbase, the learned case is not retained. Consequently,\
    \ the size of the case base is 3000 for the whole \ntime in this sub-section.\
    \ \nThe validation result suggests that the cases retrieved by the proposed TSM\
    \ differs from the \nresult retrieved by the ED in 56 tests. The rest of cases\
    \ retrieved by both similarity measures is \nthe same. Table 22 shows the different\
    \ past cases retrieved by the TSM and the ED. \nTable 22. Different past cases\
    \ retrieved by the TSM and the ED. \nNew case ID TSM \nED \nNew case ID TSM \n\
    ED \n2 \n2371  679  \n262 \n2783  2350  \n23 \n682  \n183  \n271 \n1674  1204\
    \  \n26 \n1301  1560  \n277 \n2392  1236  \n28 \n2214  763  \n286 \n2759  745\
    \  \n57 \n1165  1239  \n287 \n749  2989  \n67 \n888  2756 \n290 \n1161  2966 \
    \ \n76 \n461  \n767  \n303 \n1722  2866  \n87 \n1433  2865 \n314 \n1262  311 \
    \ \n107 \n2115  1762 \n317 \n2314  \n85  \n113 \n221  2483  \n323 \n2993  2895\
    \  \n126 \n2297 \n2063  \n344 \n1077  1168  \n134 \n2  \n984  \n353 \n773  \n\
    615  \n145 \n1172  \n68  \n360 \n2592  325  \n151 \n552  2776  \n362 \n903  2644\
    \  \n140 \n \n154 \n1705  1004  \n363 \n730  \n724  \n163 \n56  \n1479  \n371\
    \ \n1744  2525  \n169 \n295  2711  \n372 \n2572  2359  \n170 \n315  1463  \n390\
    \ \n1892  1306  \n191 \n2383  296  \n396 \n1819  2108  \n192 \n1372  1614  \n\
    406 \n583  \n746  \n197 \n43 \n2859 \n415 \n2255  401  \n199 \n1769  1214  \n\
    424 \n988  \n862  \n206 \n2257  \n59  \n428 \n141  \n411  \n214 \n109  2393  \n\
    430 \n2457  1475  \n218 \n798  \n93  \n439 \n2972  814  \n219 \n2304  785  \n\
    452 \n2257  1572  \n231 \n1609  948  \n473 \n682  1025  \n245 \n2487  2969  \n\
    490 \n643  2544  \n \nIn Table 22, under the columns of TSM and ED, it shows that\
    \ these two approaches retrieved \ndifferent past cases. For demonstrating the\
    \ difference between the retrieval results, two examples \nare picked from these\
    \ 56 tests. \n \nThe first example is the new case 57. In this example, the TSM\
    \ retrieves the past case 1165, \nwhile the ED retrieves the past case 1239. The\
    \ features of pest quantity, pest stage, infected area, \ngrowth stage of crops,\
    \ planting density, temperature, humidity, rainfall, sunlight, and wind speed\
    \ \nare displayed by the line charts in Figures 102 and 103. \n \nAccording to\
    \ the observation, it is determined that the past case 1165 (retrieved by the\
    \ TSM) \nis more similar to the new case 57 than the past case 1239 (retrieved\
    \ by the ED). Because the data \ndeviation between the new case 57 and the past\
    \ case 1165 is smaller. Figure 100 shows that though \nmost of features in the\
    \ new case 57 and the past case 1239 are similar, some features like the \ninfected\
    \ area, growth stage of crops, the minimum temperature of the day, and humidity\
    \ have \nsome mismatches. Table 23 displays the result of the statistical analysis\
    \ between these three cases. \nIn Table 23, the data covariance between the new\
    \ case and past cases are both positive, suggesting \nthat the retrieved past\
    \ cases are similar to the new case. However, the covariance value of the new\
    \ \ncase 57 and the past case 1165 is smaller, indicating a closer correlation\
    \ between these two cases. \nIn conclusion, the past case retrieved by the TSM\
    \ is more accurate in this example. \n141 \n \n \nFigure 102. Data visualization\
    \ of the new case 57 and the past case 1165. \n \nFigure 103. Data visualization\
    \ of the new case 57 and the past case 1239. \nTable 23. Statistical analysis\
    \ of past cases 1165 and 1239. \nCases \nSimilarity measurement Data covariance\
    \ RMSE \nMAE \n(P57, P1165) \n94.59% \n0.0583 \n0.4315 \n0.3273 \n(P57, P1239)\
    \ \n93.89% \n0.0676 \n0.6143 \n0.5081 \n142 \n \n \nThe second example is the\
    \ new case 113. In this example, the TSM retrieves the past case \n221, while\
    \ the ED retrieves the past case 2483. All the features in these three cases are\
    \ displayed \nin Figures 104 and 105. \n \nFigure 104. Data visualization of the\
    \ new case 113 and the past case 221. \n \nFigure 105. Data visualization of the\
    \ new case 113 and the past case 2483. \n \nIn Figures 104 and 105, it shows that\
    \ the past cases retrieved by the TSM and the ED are \nboth similar to the new\
    \ case 113. However, the past case retrieved by the TSM fails to match the \n\
    features like the pest quantity and infected area precisely. For analyzing the\
    \ differences between \nthe retrieved cases, the data covariation function is\
    \ applied and the analysis result is presented in \nTable 24. \n143 \n \nTable\
    \ 24. Statistical analysis of past cases 221 and 2483. \nCases \nSimilarity measurement\
    \ Data covariance RMSE \nMAE \n(P113, P221) \n95.87% \n0.0780 \n0.4041 \n0.3340\
    \ \n(P113, P2483) \n94.70% \n0.0687 \n0.3152 \n0.2612 \n \nIn Table 24, though\
    \ the similarity measured by the TSM is higher than the value calculated \nby\
    \ the ED, the covariance value of the new case 113 and the past case 2483 is smaller,\
    \ suggesting \na closer correlation between these two cases. In conclusion, the\
    \ past case retrieved by the ED is \nmore accurate in this example. \n \nJudging\
    \ from the above two examples, it is noted that both the TSM and the ED do not\
    \ \nguarantee that the retrieved past case is the most similar one under certain\
    \ circumstances. \nTherefore, the data covariance function is applied to all these\
    \ 56 tests for verifying which \nsimilarity measure is more accurate. The result\
    \ is presented in Table 25. \nTable 25. Statistical analysis of 56 tests. \nNew\
    \ case ID \nTSM \n  \nED \nNew case ID \nTSM \nED \n2 \n0.0793   0.0848 \n262\
    \ \n0.1177 0.1074 \n23 \n0.0244   0.0609 \n271 \n0.0493 0.0562 \n26 \n0.0578 \
    \  0.0606 \n277 \n0.0432 0.0217 \n28 \n0.0669   0.0680 \n286 \n0.0546 0.0565 \n\
    57 \n0.0583   0.0676 \n287 \n0.0833 0.0527 \n67 \n0.1106   0.0921 \n290 \n0.0912\
    \ 0.0922 \n76 \n0.1152   0.1256 \n303 \n0.1112 0.1492 \n87 \n0.0494   0.0742 \n\
    314 \n0.0773 0.1002 \n107 \n0.1239   0.1102 \n317 \n0.0559 0.0547 \n113 \n0.0780\
    \   0.0687 \n323 \n0.0516 0.0607 \n126 \n0.0703   0.0889 \n344 \n0.0481 0.0528\
    \ \n134 \n0.1305   0.1007 \n353 \n0.0361 0.0455 \n145 \n0.1050   0.1273 \n360\
    \ \n0.0635 0.0469 \n151 \n0.0716   0.0958 \n362 \n0.0890 0.0506 \n154 \n0.0716\
    \   0.0825 \n363 \n0.1329 0.1333 \n163 \n0.0866   0.0875 \n371 \n0.0643 0.0693\
    \ \n169 \n0.1116   0.0743 \n372 \n0.0551 0.0663 \n170 \n0.0792   0.0818 \n390\
    \ \n0.0872 0.0772 \n191 \n0.0533   0.0725 \n396 \n0.0312 0.0328 \n144 \n \n192\
    \ \n0.0577   0.0769 \n406 \n0.0617 0.0711 \n197 \n0.0463   0.0633 \n415 \n0.0710\
    \ 0.0908 \n199 \n0.0268   0.0432 \n424 \n0.0439 0.0381 \n206 \n0.1106   0.1178\
    \ \n428 \n0.0814 0.0858 \n214 \n0.0440   0.0507 \n430 \n0.1146 0.1165 \n218 \n\
    0.1207   0.1188 \n439 \n0.0207 0.0213 \n219 \n0.0715   0.0721 \n452 \n0.1049 0.0891\
    \ \n231 \n0.0848   0.0647 \n473 \n0.0284 0.0629 \n245 \n0.0569   0.0785 \n490\
    \ \n0.0516 0.0634 \n \nIn Table 25, the columns of TSM and ED display the value\
    \ of data covariance. A small \ncovariance value represents that the compared\
    \ two cases are more similar. For comparison, The \nTSM can correctly retrieve\
    \ the most similar past cases for 40 times, however, the past cases \nretrieved\
    \ by the ED are more accurate in 16 tests. The precision of the TSM and the ED\
    \ can be \nmeasured by the confusion matrix in Equation (23). \nAverage precision\
    \ = \n\U0001D447\U0001D443\n\U0001D447\U0001D443+\U0001D439\U0001D443 (%)    \
    \                 (23) \nwhere TP denotes true positive and FP denotes false positive.\
    \ \n \nThe average precision of the TSM and the ED is presented in Table 26. \n\
    Table 26. The average precision of the TSM and the ED. \nSimilarity measure \n\
    TSM \nED \nAverage precision \n96.80% 92.00% \n \nIn Table 26, the average precision\
    \ of the TSM reaches 96.80% (484/500), while the average \nprecision of the ED\
    \ reaches 92.00% (460/500). Thus, the effectiveness and accuracy of the TSM \n\
    is proved through comparative experiments. \n6.3.3. Result of the fast case retrieval\
    \ algorithm \nIn this sub-section, the fast case retrieval algorithm tries to\
    \ obtain the top three similar past \ncases from the case base. Meanwhile, the\
    \ proposed fast case retrieval algorithm is compared with \nthe typical algorithm\
    \ which traverses all the past cases in the case base. For evaluating the retrieval\
    \ \nresult, two aspects, retrieval accuracy and efficiency, are considered in\
    \ the validation. On the one \nhand, retrieval efficiency specifies that the number\
    \ of compared past cases should be as fewer as \npossible. Because visiting fewer\
    \ cases means higher retrieval efficiency. Please note that the new \n145 \n \n\
    cases are not retained in the case base after case retrieval and the association\
    \ part of each past \ncase is not updated during the experiments in this sub-section.\
    \ Thus, the total times of tests are \n1.5 million (3000 × 500). \nFirstly, retrieval\
    \ accuracy concerns the average precision of retrieved top three similar cases.\
    \ \nThe confusion matrix is adopted here as well and the average precision follows\
    \ the same as \nEquation (23) which presented in the previous sub-section. The\
    \ result is shown in Figure 106. \n \nFigure 106. The average precision of retrieved\
    \ top three similar and dissimilar past cases. \nIn Figure 106, the average precision\
    \ of retrieved top three similar cases reaches 90.52% \n(1357804/1500000), 82.11%\
    \ (1231654/1500000), and 75.03% (1125449/1500000). The average \nprecision of\
    \ retrieved top three dissimilar cases reaches 80.39% (1205858/1500000), 79.14%\
    \ \n(1187119/1500000), and 75.91% (1138655/1500000). The result of the average\
    \ precision \ndemonstrates that the proposed case retrieval algorithm achieves\
    \ promising retrieval accuracy. \nUnder certain circumstances, the proposed case\
    \ retrieval algorithm fails to retrieve the \ncorrect top three cases. For instance,\
    \ the proposed algorithm is sometimes unable to identify the \nmost similar past\
    \ case. The most similar one is missed during runtime due to the limitation of\
    \ \nretrieving time (iteration number). The second most similar past case usually\
    \ takes the first \nposition instead and is therefore treated as the output. This\
    \ is also the reason why the second and \nthe third similar past cases are not\
    \ 100% correctly retrieved. However, this is acceptable because \nCBR does not\
    \ necessarily require the successful retrieval of the most similar cases. All\
    \ retrieved \ntop three similar past cases are not exactly the same as the target\
    \ one. It is worth noting that apart \nfrom case retrieval, CBR also adopts the\
    \ processes of solution reuse and revision. These processes \nare responsible\
    \ to update the solutions of retrieved past cases for adapting to the current\
    \ situations. \nTherefore, successfully retrieving the second or the third similar\
    \ past cases is enough for the CBR \nsystems. For supporting this point of view,\
    \ an example is presented in Figures 107-109, displaying \n146 \n \nthe data visualization\
    \ of the new case 7 and retrieved top three similar past cases 52, 267, and 646.\
    \ \nTheir data covariance and similarity measurements are given in Table 27. \n\
    \ \nFigure 107. Data visualization of the new case 7 and the past case 52. \n\
    \ \nFigure 108. Data visualization of the new case 7 and the past case 267. \n\
    147 \n \n \nFigure 109. Data visualization of the new case 7 and the past case\
    \ 646. \nTable 27. Statistical analysis of the new case 7 and retrieved top three\
    \ similar past cases. \nCases \nSimilarity measurement Data covariance RMSE \n\
    MAE \n(P7, P52) \n95.28% \n0.0535 \n0.4849 \n0.3976 \n(P7, P267) \n95.14% \n0.0677\
    \ \n0.4598 \n0.4233 \n(P7, P646) \n95.09% \n0.0682 \n0.4624 \n0.4569 \nIn Figures\
    \ 107-109, it is shown that the retrieved top three past cases are all similar\
    \ to the \nnew case 7. The result from Table 27 also supports that past cases\
    \ 52, 267, and 646 achieve the \nsimilarity measurement with the new case at 95.28%,\
    \ 95.14%, and 95.09% respectively. \nMeanwhile, the value of data covariance is\
    \ positive, indicating a close correlation between the \nnew case and retrieved\
    \ past cases. The values of RMSE between these cases are similar, so do the \n\
    values of MAE. In other words, there are minor differences between the retrieved\
    \ top three similar \npast cases. The solutions of all these three cases can be\
    \ reused and revised. Therefore, retrieval \naccuracy of the proposed fast case\
    \ retrieval algorithm is proved. \nSecondly, the retrieval efficiency of the proposed\
    \ retrieval algorithm is evaluated by \ncomparing with the typical case retrieval\
    \ algorithm. Traditionally, the typical case retrieval \nalgorithm tries to identify\
    \ the most similar past cases by traversing the whole case base. As a \nconsequence,\
    \ the number of compared cases in this experiment reaches 3000 in total for a\
    \ single \nquery. Differing from the typical approaches, the proposed case retrieval\
    \ algorithm takes \nadvantage of the association part of each past case, and therefore\
    \ measures the similarity between \nthe new case and associated cases preferentially.\
    \ From the evaluation perspective, a fewer number \n148 \n \nof compared cases\
    \ means greater efficiency of case retrieval. The result of the number of \ncompared\
    \ cases for 1.5 million tests is summarized in Table 28. \nTable 28. The number\
    \ of compared cases for 1.5 million tests. \nNumber of compared cases [800,899]\
    \ [900,999] [1000,1099] [1100,1199] \nTimes \n320359 \n479221 \n490357 \n207363\
    \ \nProportion \n21.36% \n31.95% \n32.87% \n13.82% \n \nIn Table 28, the result\
    \ demonstrates that the number of compared past cases ranges from 800 \nto 1199\
    \ approximately. The fewest number of compared cases is 834, while the largest\
    \ number is \n1197. The average number of compared cases is around 1047 (1046.95)\
    \ in a single query. As a \nconsequence, compared with the result of typical case\
    \ retrieval algorithms (by traversing all 3000 \ncases), it is proved that the\
    \ proposed algorithm is able to retrieve similar past cases by fewer \ncomparisons.\
    \ In other words, the proposed algorithm achieves greater retrieval efficiency.\
    \ \nAfter successful case retrieval, the solutions of the retrieved past cases\
    \ can be reused and \nrevised to resolve the new problems.  \n6.3.4. Result of\
    \ the learning-based solution reuse and revision \nFor verifying the effectiveness\
    \ of the learning-based reuse and revision approach, 500 past \ncase (Case ID\
    \ 2501-3000) are drawn from the case base, as the test dataset, assigned with\
    \ new \ncase IDs (1-500). For testing purpose, the solution part of the selected\
    \ 500 cases are removed. \nThe rest of the 2500 (Case ID 1-2500) past cases form\
    \ a new case base. Correspondingly, the \nassociation part of the 2500 past cases\
    \ in the new case base differ from those presented in Section \n6.3.1, meaning\
    \ that the association table is newly generated in this sub-section. It is noted\
    \ that \nafter successful retrieval, reuse, and revision, the learned cases are\
    \ not retained in the case base. \nIn this sub-section, the evaluation of reuse\
    \ and revision focuses on comparing the revised and the \noriginal solutions.\
    \ It is noted that some solutions are left empty in the case base due to the reason\
    \ \nthat the given situation is not suitable for pesticide applications. For instance,\
    \ the probability of \nrainfall is higher than 90%, which usually leads to low\
    \ effectiveness of treatment. \nThe reuse and revision involve the processing\
    \ of three features in the solution part of past \ncases, namely (i) pesticide\
    \ type (“Abamectin-Chlorpyrifos” and “Fipronil”), (ii) prescription \nvalue (ranging\
    \ from 0.1632 to 38.7688), and (iii) dilution factor (ranging from 11.80% to 38.81%).\
    \ \nThe first one is a linguistic feature and the latter two are numeric features.\
    \ \n149 \n \nFor the pesticide type, the revision is considered successful when\
    \ the revised feature matches \nwith the original one. For the prescription value\
    \ and dilution factor, their deviations between the \nrevised and original values\
    \ are evaluated. \nRegarding the pesticide type, the experimental result demonstrates\
    \ that the revised solutions \nof 22 cases differ from the original ones, which\
    \ are listed in Table 29. \nTable 29. Comparison of revised and original pesticide\
    \ types. \nNew case ID Original Revised New case ID Original Revised \n2 \nAC\
    \ \nF \n227 \nF \nAC \n11 \nF \nAC \n244 \nAC \nF \n23 \nAC \nF \n267 \nAC \n\
    F \n27 \nAC \nF \n301 \nF \nAC \n51 \nF \nAC \n306 \nAC \nF \n55 \nF \nAC \n348\
    \ \nF \nAC \n75 \nAC \nF \n377 \nF \nAC \n117 \nF \nAC \n407 \nF \nAC \n141 \n\
    AC \nF \n420 \nF \nAC \n184 \nAC \nF \n492 \nAC \nF \n199 \nAC \nF \n496 \nF \n\
    AC \n \nIn Table 29, AC represents the application of “Abamectin-Chlorpyrifos”,\
    \ while F represents \nthe application of “Fipronil”. Concluding from this table,\
    \ among all the 500 tests, the revision \naccuracy is 95.60% (478/500). Since\
    \ these two pesticides are both appliable to handle the pest \nproblems of Chilo\
    \ suppressalis, even though the revision result in Table 29 may recommend to \n\
    use a different pesticide, these recommendations are not definitely wrong. In\
    \ other words, the \nCBR system should display the results and ask farmers to\
    \ make the final decisions. \n \nRegarding the numeric features, prescription\
    \ value and dilution factor, part of the \nexperimental results are presented\
    \ in Tables 30 and 31 respectively.  \nTable 30. Comparison of revised and original\
    \ prescription values. \nNew case \nID \nOriginal Revised Deviation \nNew case\
    \ \nID \nOriginal Revised Deviation \n1 \n3.9225 \n3.2757 \n-16.49% \n… \n… \n\
    … \n… \n2 \n3.7666 \n4.4258 \n17.5% \n492 \n2.4605 \n2.4504 \n-0.41% \n150 \n\
    \ \n3 \n7.7693 \n7.1214 \n-8.34% \n493 \n12.7588 \n12.7894 \n0.24% \n4 \n1.7067\
    \ \n1.9203 \n12.51% \n494 \n16.9055 \n17.4161 \n3.02% \n5 \n3.8409 \n4.3821 \n\
    14.09% \n495 \n16.7889 \n17.7022 \n5.44% \n6 \nNull \nNull \n0.00% \n496 \n3.7713\
    \ \n3.5326 \n-6.33% \n7 \n1.6006 \n1.7008 \n6.26% \n497 \nNull \nNull \n0.00%\
    \ \n8 \n4.8451 \n4.5704 \n-5.67% \n498 \n1.5257 \n1.4326 \n-6.10% \n9 \n2.3232\
    \ \n2.4305 \n4.62% \n499 \n6.4773 \n6.3815 \n-1.48% \n… \n… \n… \n… \n500 \nNull\
    \ \nNull \n0.00% \nTable 31. Comparison of revised and original dilution factors.\
    \ \nNew case \nID \nOriginal Revised Deviation \nNew case \nID \nOriginal Revised\
    \ Deviation \n1 \n16.15% \n17.87% \n10.70% \n… \n… \n… \n… \n2 \n25.58% \n30.42%\
    \ \n18.93% \n492 \n30.39% \n34.01% \n11.89% \n3 \n20.51% \n21.67% \n5.67% \n493\
    \ \n29.87% \n31.85% \n6.61% \n4 \n25.40% \n27.30% \n7.48% \n494 \n17.50% \n14.03%\
    \ \n-19.85% \n5 \n30.57% \n33.48% \n9.44% \n495 \n18.11% \n21.18% \n16.93% \n\
    6 \nNull \nNull \n0.00% \n496 \n19.58% \n16.16% \n-17.47% \n7 \n18.46% \n15.21%\
    \ \n-17.58% \n497 \nNull \nNull \n0.00% \n8 \n23.04% \n24.43% \n6.02% \n498 \n\
    25.81% \n29.98% \n16.15% \n9 \n15.87% \n16.76% \n5.61% \n499 \n19.66% \n16.91%\
    \ \n-14.01% \n… \n… \n… \n… \n500 \nNull \nNull \n0.00% \n \nIn Table 30, the\
    \ result of the revised prescription value is promising, with an average \ndeviation\
    \ reaching 9.54% in all 500 tests. The maximum deviation happens in the new case\
    \ 430, \nreaching 18.91%, while the minimum deviation happens in the new case\
    \ 287, achieving an almost \nperfect revision (the deviation is 0.12%). These\
    \ two situations are presented in Figure 110. \n151 \n \n \nFigure 110. The best\
    \ and worst revision result of prescription values. \n \nIn Table 31, the average\
    \ deviation of revised dilution factors is approximately 12.92%. The \nmaximum\
    \ deviation happens in the new case 50, reaching 19.97%, while the minimum deviation\
    \ \nhappens in the new case 153, reaching 5.01%. These two situations are presented\
    \ in Figure 111. \n \nFigure 111. The best and worst revision result of dilution\
    \ factors. \nAn example is given below for demonstrating how the learning-based\
    \ approach of solution \nreuse and revision works in the CBR system. This example\
    \ shows how past experiences can be \nreused and revised for solving the new case\
    \ 1. \nAfter treating the new case 1 as the input to the CBR system and starting\
    \ the first retrieval \ntask, an adaptation case is retrieved from the case base,\
    \ along with its stored solution. In this \n152 \n \nsituation, the past case\
    \ 148 is considered as the adaptation case. The data visualization of these \n\
    two cases is presented in Figure 112, while the analytics result is presented\
    \ in Table 32. \n \nFigure 112. Data visualization of the new case 1 and the past\
    \ case 148. \nTable 32. Statistical analysis of the new case 1 and the past case\
    \ 148. \nCases \nSimilarity measurement Data covariance RMSE \nMAE \n(P1, P148)\
    \ \n97.56% \n0.0357 \n0.1370 \n0.1142 \n \nFrom the result in Figure 112 and Table\
    \ 32, it is determined that the new case 1 and the past \ncase 148 have great\
    \ commonalities in all variables. Their similarity measurement reaches 97.56%,\
    \ \nwhile the values of data covariance, RMSE, and MAE are all small, supporting\
    \ that these two \ncases are similar. The difference value of the new case 1 and\
    \ the adaptation case reaches  \n \nThen, the adaptation case (the past case 148)\
    \ is input to the second retrieval task. By adopting \nthe triangular similarity\
    \ measure, a collection of similar past cases is retrieved from the case base.\
    \ \nThe IDs of these retrieved cases are 115, 689, and 1570. The data visualization\
    \ of these cases is \nshown in Figures 113-115. The data analytics result of these\
    \ cases is presented in Table 33. \n \n \n \n153 \n \nTable 33. Statistical analysis\
    \ of the past cases 148, 115, 689, and 1570. \nCases \nSimilarity measurement\
    \ Data covariance RMSE \nMAE \n(P148, P115) \n96.03% \n0.1000 \n0.1607 \n0.1001\
    \ \n(P148, P689) \n95.76% \n0.1022 \n0.1611 \n0.1216 \n(P148, P1570) \n95.02%\
    \ \n0.1189 \n0.1699 \n0.1327 \n \nFigure 113. Data visualization of past cases\
    \ 148 and 115. \n \nFigure 114. Data visualization of past cases 148 and 689.\
    \ \n154 \n \n \nFigure 115. Data visualization of past cases 148 and 1570. \n\
    \ \nFrom the result in Figures 113-115 and Table 33, the retrieved three past\
    \ cases are all similar \nto the past case 148. Their similarity measurements\
    \ all reach above 95.00%, while the values of \ndata covariance are all positive.\
    \ The values of RMSE and MAE suggest the same. \n \nAs two retrieval tasks have\
    \ completed, the new case, the adaptation case, and retrieved \nsimilar past cases\
    \ are treated as input to the learning component. This learning component tries\
    \ \nto capture the difference in the problem part of compared cases. The result\
    \ is presented in Table \n34. \nTable 34. The result of captured difference in\
    \ the problem part of compared cases. \nCases \nV1 \nV2 \nV3 \nV4 \nV5 \nV6 \n\
    V7 \nV8 \nV9 \nV10 \nV11 \nVall \n(N1, P148) \n0.08 \n0 \n0.09 \n0 \n-0.12 \n\
    0.14 \n0.14 \n0.27 \n0.20 \n-0.07 \n0 \n0.76 \n(P148, P115) \n0 \n0 \n0.01 \n\
    0 \n-0.13 \n-0.14 \n0 \n0.19 \n0.16 \n0.03 \n0.43 \n0.55 \n(P148, P689) \n-0.12\
    \ \n0 \n-0.20 \n0 \n-0.10 \n-0.14 \n0 \n0.34 \n0.04 \n-0.04 \n-0.14 \n0.70 \n\
    (P148, P1570) \n0.01 \n0.33 \n0.08 \n0 \n-0.19 \n-0.14 \n-0.14 \n0.09 \n0 \n-0.18\
    \ \n-0.29 \n0.68 \n \nJudging from the result in Table 34, it is determined that\
    \ the difference between the new case \n1 and the past case 148 is similar to\
    \ that between past cases 148 and 689. Therefore, the learning \ncomponent tries\
    \ to capture the pattern how the solution of the past case 689 adapts to solve\
    \ the \npast case 148, and then applies this pattern to update the solution of\
    \ the past case 148. \n155 \n \n \nIn past cases 148 and 689, the type of the\
    \ applied pesticide is both Fripronil. Therefore, this \nvariable does not need\
    \ any revisions. In regards to the prescription and dilution factor, these values\
    \ \nare presented in Table 35. \nTable 35. The values of prescription and dilution\
    \ factor in past cases 148, 115, 689, and 1570. \nCases Pesticide type Prescription\
    \ Dilution factor \nP148 \nFripronil \n2.2885 \n18.64% \nP689 \nFripronil \n5.3213\
    \ \n17.93% \n \nIn Table 35, for updating the prescription value, the solution\
    \ of past case 689 decreases by \n3.0328, while the dilution factor increases\
    \ by 0.71%. Referring to the difference comparison \nbetween the new case and\
    \ the adaptation case, it is concluded that for adapting to the new case, \nthe\
    \ prescription value in the adaptation case should increase, while the dilution\
    \ factor should \ndecrease. Therefore, the calculation result is presented in\
    \ Table 36. \nTable 36. The result of revising the solution for adapting to the\
    \ new case. \n \nPesticide type Prescription Dilution factor \nOriginal \nFripronil\
    \ \n3.9224 \n16.15% \nRevised \nFripronil \n3.4671 \n15.50% \n \nIn Table 36,\
    \ the deviation of revised prescription value is approximately 11.61%, while the\
    \ \ndeviation of revised dilution factor reaches around 8.37%. Concluding from\
    \ the revision result of \npesticide type, prescription value, and dilution factor,\
    \ the proposed learning-based reuse and \nrevision approach is proved effective\
    \ and accurate. \n6.3.5. Result of the associated case retention \nIn this sub-section,\
    \ the same 500 new cases and the same 3000 past cases which presented \nin Section\
    \ 6.3.2 are employed. It is noted that the new case is determined to be retained\
    \ in the \ncase base after successful retrieval, reuse, and revision. If the new\
    \ case is going to be retained, \nthen the association of both new and past cases\
    \ will be updated accordingly. Since there are 500 \nnew cases for testing, the\
    \ experiment is performed for 500 times. In each test, the past case 1 is \nselected\
    \ as the entry point for comparison at the initial iteration. \nThe experimental\
    \ result demonstrates that 30 new cases are not retained in the case base \nbecause\
    \ the similarity measurements between these cases and existed ones reach beyond\
    \ threshold. \nThese 30 new cases are listed in Table 37. \n156 \n \nIn Table\
    \ 37, it is worth mentioning that the deletion strategy is applied to new cases\
    \ 138 and \n399 due to the reason that these two cases have great commonalities\
    \ with newly retained cases \n3057 and 3185 respectively. The rest of unretained\
    \ cases is all similar to the past cases which \nhave been already stored in the\
    \ case base. \nTable 37. List of unretained new cases. \nUnretained \ncase ID\
    \ \nCause \nUnretained \ncase ID \nCause \nN1 \nSim (N1, P158) = 98.35% \nN183\
    \ \nSim (N183, P542) = 98.96% \nN4 \nSim (N4, P2210) = 98.65% \nN190 \nSim (N190,\
    \ P2468) = 98.73% \nN27 \nSim (N27, P1380) = 98.14% \nN307 \nSim (N307, P460)\
    \ = 98.25% \nN53 \nSim (N53, P2361) = 98.02% \nN324 \nSim (N324, P547) = 98.27%\
    \ \nN81 \nSim (N81, P2943) = 98.45% \nN365 \nSim (N365, P1440) = 98.18% \nN82\
    \ \nSim (N82, P1944) = 99.56% \nN367 \nSim (N367, P84) = 98.44% \nN84 \nSim (N84,\
    \ P1326) = 98.16% \nN376 \nSim (N376, P1353) = 98.41% \nN88 \nSim (N88, P411)\
    \ = 98.14% \nN399 \nSim (N399, P3185) = 98.58% \nN91 \nSim (N91, P299) = 98.80%\
    \ \nN411 \nSim (N411, P2237) = 98.51% \nN99 \nSim (N99, P196) = 98.29% \nN437\
    \ \nSim (N437, P921) = 99.30% \nN102 \nSim (N102, P2921) = 99.28% \nN447 \nSim\
    \ (N447, P1095) = 99.07% \nN125 \nSim (N125, P1551) = 98.35% \nN459 \nSim (N459,\
    \ P388) = 98.33% \nN138 \nSim (N138, P3057) = 98.06% \nN476 \nSim (N476, P1358)\
    \ = 98.13% \nN150 \nSim (N150, P324) = 98.49% \nN486 \nSim (N486, P2069) = 98.68%\
    \ \nN162 \nSim (N162, P1883) = 98.77% \nN496 \nSim (N496, P372) = 99.07% \n \n\
    For verifying the updated association of cases, the times of updates in both similar\
    \ and \ndissimilar associations are counted, shown in Figure 116. \n157 \n \n\
    \ \nFigure 116. Times of updates in the association of past cases. \n \nIn Figure\
    \ 116, updates in the association of past cases are counted 2594 in total, 43.71%\
    \ \nhappens in updating the similar association, while 56.29% in updating the\
    \ dissimilar association. \nFor retaining a learned case, the average number of\
    \ updates is approximately 6 times (5.52 times). \n \nThe similar and dissimilar\
    \ association of newly retained cases are considered. The result is \npresented\
    \ in Tables 38 and 39 respectively. \nTable 38. Part of the similar association\
    \ of newly retained cases. \nPast Case \n1st sim \nsimValue  \n2nd sim \nsimValue\
    \ \n3rd sim \nsimValue \n3001 \n679 \n94.91% \n555 \n94.19% \n2371 \n94.11% \n\
    3002 \n1398 \n96.78% \n3423 \n96.03% \n1956 \n95.82% \n3003 \n539 \n94.56% \n\
    1266 \n92.82% \n2799 \n91.31% \n3004 \n1119 \n95.17% \n3400 \n94.83% \n365 \n\
    94.40% \n3005 \n1135 \n94.69% \n386 \n94.51% \n53 \n93.29% \n… \n… \n… \n… \n\
    … \n… \n… \n3466 \n33 \n96.31% \n3253 \n93.46% \n3252 \n93.26% \n3467 \n542 \n\
    94.78% \n1846 \n94.76% \n3183 \n94.36% \n3468 \n2199 \n97.38% \n2167 \n94.12%\
    \ \n782 \n93.45% \n3469 \n2523 \n96.24% \n2860 \n95.84% \n2749 \n93.84% \n3470\
    \ \n2995 \n95.91% \n2882 \n94.79% \n2042 \n94.14% \n158 \n \nTable 39. Part of\
    \ the dissimilar association of the newly retained cases. \nPast Case \n1st dissim\
    \ \nsimValue \n2nd dissim \nsimValue \n3rd dissim \nsimValue \n3001 \n1845 \n\
    12.07% \n2095 \n12.75% \n685 \n13.03% \n3002 \n2807 \n18.75% \n2095 \n20.83% \n\
    490 \n21.70% \n3003 \n2396 \n11.95% \n2745 \n13.27% \n1132 \n13.36% \n3004 \n\
    1217 \n14.72% \n1557 \n14.93% \n2863 \n15.11% \n3005 \n38 \n14.48% \n3478 \n14.69%\
    \ \n1663 \n14.82% \n… \n… \n… \n… \n… \n… \n… \n3466 \n1278 \n16.07% \n3308 \n\
    16.48% \n2990 \n18.00% \n3467 \n2774 \n10.81% \n1079 \n13.97% \n2027 \n14.17%\
    \ \n3468 \n3472 \n11.35% \n3309 \n11.44% \n674 \n12.75% \n3469 \n2095 \n7.21%\
    \ \n564 \n9.39% \n396 \n10.57% \n3470 \n3218 \n13.61% \n3434 \n13.77% \n1239 \n\
    13.92% \n \nIn total, 470 newly retained cases have their own similar and dissimilar\
    \ associations, which \nmeans that the update of associations is successful. \n\
    \ \nAt last, for those unretained cases, two examples (new cases 1 and 4) are\
    \ selected and the \ndata visualization of these cases is presented in Figures\
    \ 117 and 118. \n \nFigure 117. Data visualization of the new case 1 and the past\
    \ case 158. \n159 \n \n \nFigure 118. Data visualization of the new case 4 and\
    \ the past case 2210. \nIn Figures 117 and 118, it is shown that the new cases\
    \ and past cases are extremely similar \nin both situations. Therefore, it is\
    \ unnecessary to replace the old past cases with the new cases, \nsince these\
    \ new cases offer similar contributions as the old ones provide. The cost of retaining\
    \ an \nunnecessary case is high due to the reason that the corresponding similar\
    \ and dissimilar \nassociations existed in the case base have to be updated as\
    \ well. However, this update does not \nadd useful knowledge in the case base.\
    \ Meanwhile, retaining unnecessary cases may reduce the \ncompetence of the case\
    \ base, leading to low retrieval performance. \n \n160 \n \n7 \nConclusion and\
    \ \nfuture work\n \n161 \n \n    This chapter summarizes the main achieved contributions.\
    \ This thesis mainly concentrates on the \nresearch of the decision support system\
    \ for smart agriculture. This decision support system is enabled \nby an artificial\
    \ intelligence technique, named case-based reasoning. The purpose of this thesis\
    \ is to \nimprove each step within the case-based reasoning approach as much as\
    \ possible, including \nrepresentation, retrieval, reuse, revision, and retention.\
    \ Meanwhile, for enhancing the robustness of the \ncase-based reasoning enabled\
    \ decision support system, a hybrid decision support mechanism is \nproposed by\
    \ taking advantage of the improved case-based reasoning approach and artificial\
    \ neural \nnetworks. Apart from summarizing the contributions achieved in this\
    \ thesis, the future work in the \nresearch area of decision support is presented,\
    \ including how each step within the case-based reasoning \napproach can be further\
    \ improved. Though the specific problem this thesis tried to address is only a\
    \ \nsmall fraction among the issues that many researchers are studying on, the\
    \ proposals presented in this \nthesis could be considered as novel trials of\
    \ the case-based reasoning approach and decision support \nmethods for the upcoming\
    \ area of smart agriculture. The results presented in this thesis could be helpful\
    \ \nfor those researchers who are interested in similar problems. \n7.1. Conclusion\
    \ \n    The DSS is an important enabler to assist farmers in managing farming\
    \ operations effectively and \nprofitably. Delivering a DSS for smart agriculture\
    \ in the AFarCloud project is the ultimate objective of \nthis thesis. The proposed\
    \ CBR enabled DSS is explained in detail and its performance is evaluated by \n\
    simulation in different scenarios. The main contributions of this thesis are summarized\
    \ as follows. \n• \nConcluding from the review on the agricultural evolution (from\
    \ Agriculture 1.0 to 4.0), it is \ndetermined that smart agriculture needs the\
    \ help of advanced technologies to boost agricultural \nproductivity and allocate\
    \ various resources under a reasonable manner. Therefore, a DSS is \nbeneficial\
    \ for smart agriculture due to the reason that it can utilize the explosive amount\
    \ of \nenvironmental, crop-related, and economic data, and transfer these data\
    \ into practical knowledge \nfor managing farming operations. Meanwhile, in Section\
    \ 2, both optimization-based and reasoning-\nbased DSSs are surveyed, and it is\
    \ concluded that the reasoning-based approach, in particular the \nCBR approach,\
    \ is more suitable for building a DSS for the AFarCloud platform. \n \n162 \n\
    \ \n• \nThe framework of the DSS in the AFarCloud platform is defined, consisting\
    \ of an algorithm \nmanager and an algorithm toolbox. On the one hand, the algorithm\
    \ manager is linked to the MMT \nfor receiving new missions and forwarding the\
    \ generated decision supports. Meanwhile, the \nmanager component is responsible\
    \ to configure available algorithms like starting, checking, and \nstopping an\
    \ algorithm. On the other hand, the algorithm toolbox is used to register the\
    \ decision \nsupport algorithms and provide the access to the databases and services.\
    \ Most importantly, the \ntoolbox component can generate and forward the decision\
    \ supports to the algorithm manager. The \nproposed DSS framework has great scalability,\
    \ interoperability, and robustness. \n• \nFor improving the performance of the\
    \ CBR enabled DSS, the following contributions are achieved \nin this thesis.\
    \ \no Proposal of an associated case representation formalism: This formalism\
    \ contains the similar \nand dissimilar associations between past cases, enabling\
    \ to compare potential similar cases \npreferentially, instead of comparing all\
    \ the cases in the case base. Therefore, the proposed \nrepresentation formalism\
    \ provides a solid foundation for improving the efficiency of case \nretrieval.\
    \ \no Proposal of a triangular similarity measure: This similarity measure achieves\
    \ great retrieval \naccuracy and robustness by taking advantage of the cosine\
    \ similarity and the Euclidean distance \nmeasures when evaluating the similarity\
    \ between two N-dimensional vectors. In particular, the \nmagnitude differences\
    \ between compared vectors are taken into consideration. \no Proposal of a fast\
    \ case retrieval algorithm: This algorithm aims at retrieving a collection of\
    \ \nsimilar past cases for the CBR system. Owing to the adoption of the associated\
    \ case \nrepresentation formalism, the case retrieval algorithm is able to determine\
    \ the similar past cases \nwith promising accuracy and efficiency. \no Proposal\
    \ of a learning-based approach for solution reuse and revision: This approach\
    \ tries to \nidentify the difference between the compared cases. The revision\
    \ can be considered as a situation \nand action pair. The situation part captures\
    \ the difference, while the action part updates the \nretrieved solution of the\
    \ adaptation case into the target solution for solving the new problem. This \n\
    learning-based approach is able to make the most use of the case base by learning\
    \ from past \nexperiences, and therefore provide a satisfied revision result for\
    \ the CBR system. \n \n163 \n \no Proposal of an associated case retention approach:\
    \ The general addition and deletion strategies \nfor retaining learned cases are\
    \ both concerned. Meanwhile, the retention approach considers to \nupdate the\
    \ existing associations and generate new associations for the learned cases. \
    \ \n• \nThe improvements of the whole CBR loop, including representation, retrieval,\
    \ reuse, revision, and \nretention, are verified through experiments. The experimental\
    \ result shows that the improved CBR \nalgorithm is able to provide users with\
    \ accurate and quick decision supports to manager farming \noperations, compared\
    \ with typical CBR approaches. \n• \nA hybrid DSS for the AFarCloud platform is\
    \ designed. In this hybrid mechanism, two decision \nsupport algorithms (CBR and\
    \ ANN) are both considered. The interaction between these two \nalgorithms is\
    \ coordinated by the mediator component. Based on the result of the preliminary\
    \ proof, \nit is concluded that the mediator component is able to coordinate various\
    \ components and \nalgorithms within the hybrid DSS for the AFarCloud platform.\
    \ In particular, the mediator \ncomponent is useful when the CBR algorithm fails\
    \ to generate decision supports and requires \nalternative algorithms to offer\
    \ helps. \n7.2. Future work \n    This section discusses several challenging issues\
    \ that are expected to be addressed in the future \nresearch. Based on the above\
    \ conclusions and considering the limitations of the current work, future \nresearch\
    \ can be carried out in the following areas: (i) the approaches and algorithms\
    \ proposed in this \nthesis can be further improved or can be applied to different\
    \ scenarios, and (ii) the issues which are not \ntaken into consideration in this\
    \ thesis can be investigated in the future. \n• \nFor the proposed approaches\
    \ and algorithms: \no Regarding the associated case representation formalism,\
    \ the problem of storing past cases is \nnot thoughtfully considered. As indicated\
    \ in Section 4.1, a single past case can be associated for \nmultiple times, which\
    \ surely leads to waste of storage memory. Therefore, it is promising to \nintroduce\
    \ the pointer concept from the object-oriented representation formalism for avoiding\
    \ \nstoring redundant information. Meanwhile, applying the proposed formalism\
    \ to a large-scale case \n \n164 \n \nbase is a challenging task due to the reason\
    \ that the number of associations should be increased \nas the size of the case\
    \ base becomes larger. \no In terms of the triangular similarity measure, it is\
    \ proved to work well on numeric features. \nHowever, it is worth exploring its\
    \ applicability to linguistic and fuzzy features. Agricultural cases \nusually\
    \ contain various features, not only numeric ones. Therefore, adapting the proposed\
    \ \nmeasure to evaluate the similarity between hybrid features is the next step.\
    \ Meanwhile, precisely \ndetermining the weight for each feature is very important.\
    \ Each feature does not offer equal \ncontributions when retrieving the similar\
    \ past cases. Thus, the features which contribute the most \nshould be assigned\
    \ with higher weights. \no In terms of the fast case retrieval algorithm, it may\
    \ not guarantee the converge under the \ncircumstance all selected past cases\
    \ for the current iteration had already been compared. As \nindicated in Section\
    \ 4.3, the proposed algorithm will roll back to previous iterations to find an\
    \ \nunused past case for comparisons. However, this process may result in oscillating\
    \ between similar \nand dissimilar cases without converting to a solution. Therefore,\
    \ designing a proper roll-back \nmechanism is crucial for the performance of the\
    \ proposed retrieval algorithm. \no In terms of the learning-based reuse and revision\
    \ approach, on the one hand, it is essential to \nunderstand the features of the\
    \ adaptation space for different domains. Therefore, the adaptation \ntasks can\
    \ adopt the appropriate learning algorithms. On the other hand, a suitable representation\
    \ \nof possible adaptation problems would be helpful, in particular, for those\
    \ problems where minor \ndifferences do not require adaptation. \no In terms of\
    \ the associated case retention approach, it lacks consideration of the updating\
    \ cost. \nAs mentioned in Section 4.5, the retention process considers both the\
    \ updates for existing \nassociations and for newly learned cases. If a learned\
    \ case is going to replace a past case, those \nassociations of other cases which\
    \ contain this past case should be updated as well, leading to a \nhigh updating\
    \ cost. \n• \nFor the issues which are not taken into consideration in this thesis:\
    \ \no Due to the fact that other components in the AFarCloud platform are still\
    \ under development, \nthe validation of the proposed CBR-based DSS adopts simulated\
    \ data. Integrating with other \ncomponent and using data from real fields for\
    \ verification should be carried out in the near future. \n \n165 \n \nMeanwhile,\
    \ it would be also interesting to consider if the developed algorithm does not\
    \ achieve \nexpected performance over the data collected from the field. Under\
    \ this circumstance, it is worth \nlooking into the process of data pre-processing\
    \ and the selection of appropriate features. \no Though the example used in this\
    \ thesis is mainly about the pesticide applications, it is \npromising to apply\
    \ the CBR algorithm to other agricultural activities like irrigation, fertilization,\
    \ \nharvesting, etc. Furthermore, this proposal may also be appliable in other\
    \ research fields like \nsmart city and smart industry. \no The hybrid decision\
    \ support mechanism proposed in this thesis only adopted two algorithms. \nHowever,\
    \ it is possible to integrate with more algorithms for managing various farming\
    \ \noperations. As more algorithms are involved in the hybrid mechanism, the decision\
    \ support \nsystem would be able to solve more complex problems and achieve better\
    \ performance. \no Maintaining the case base is not thoughtfully considered in\
    \ this thesis, i.e. the size of the case \nbase and its relationship between the\
    \ number of associated cases. It is widely acknowledged that \nthe competence\
    \ of the case base is a key factor in the case-based reasoning system and it would\
    \ \naffect the performance of retrieval, reuse, and revision steps. \n7.3. Publications\
    \ and projects \n7.3.1. List of publications \nThe results presented in this thesis\
    \ were published in the following journals indexed in the Journal \nCitation Report\
    \ (JCR). \n[1] Zhaoyu Zhai, José-Fernán Martínez Ortega, Néstor Lucas Martínez,\
    \ Jesús Rodríguez-Molina. A \nMission Planning Approach for Precision Farming\
    \ Systems Based on Multi-Objective Optimization. \nSensors. vol. 18, no. 6, Jun.\
    \ 2018. DOI: https://doi.org/10.3390/s18061795. (JCR Q1, Impact Factor = \n3.275)\
    \ \n[2] Zhaoyu Zhai, José-Fernán Martínez Ortega, Néstor Lucas Martínez, Castillejo\
    \ Pedro. A Rule-\nBased Reasoner for Underwater Robots Using OWL and SWRL. Sensors.\
    \ vol. 18, no. 10, Oct. 2018. \nDOI: https://doi.org/10.3390/s18103481. (JCR Q1,\
    \ Impact Factor = 3.275) \n \n166 \n \n[3] Peisen Yuan, Zhaoyu Zhai, José-Fernán\
    \ Martínez Ortega, Huanliang Xu. An End-to-End Based \nLow Dimensional Binary\
    \ Embedding for Chrysanthemum Phenotypic Petal Similarity Evaluation. \nIEEE \n\
    Access. \nvol. \n7, \npp. \n152214-152223, \nOct. \n2019. \nDOI: \nhttps://doi.org/10.1109/ACCESS.2019.2947687.\
    \ (JCR Q1, Impact Factor = 3.745) \n[4] Zhaoyu Zhai, José-Fernán Martínez Ortega,\
    \ Castillejo Pedro, Beltran Victoria. A Triangular \nSimilarity Measure for Case\
    \ Retrieval in CBR and Its Application to an Agricultural Decision Support \n\
    System. Sensors. vol. 19, no. 21, Nov. 2019. DOI: https://doi.org/10.3390/s19214605.\
    \ (JCR Q1, Impact \nFactor = 3.275) \n[5] Zhaoyu Zhai, José-Fernán Martínez Ortega,\
    \ Beltran Victoria, Néstor Lucas Martínez. An \nAssociated Representation Method\
    \ for Defining Agricultural Cases in a Case-Based Reasoning System \nfor Fast\
    \ Case Retrieval. Sensors. vol. 19, no. 23, Dec. 2019. DOI: https://doi.org/10.3390/s19235118.\
    \ \n(JCR Q1, Impact Factor = 3.275) \n[6] Zhaoyu Zhai, José-Fernán Martínez Ortega,\
    \ Beltran Victoria, Néstor Lucas Martínez. Decision \nSupport Systems for Agriculture\
    \ 4.0: Survey and Challenges. Computers and Electronics in Agriculture. \nvol.\
    \ 170, Mar. 2020. DOI: https://doi.org/10.1016/j.compag.2020.105256. (JCR Q1,\
    \ Impact Factor = \n3.858) \n[7] Néstor Lucas Martínez, José-Fernán Martínez Ortega,\
    \ Jesús Rodríguez-Molina, Zhaoyu Zhai. \nProposal of an Automated Mission Manager\
    \ for Cooperative Autonomous Underwater Vehicles. \nApplied Sciences-Basel. vol.\
    \ 10, no. 3, Jan. 2020. DOI: https://doi.org/10.3390/app10030855. (JCR Q2, \n\
    Impact Factor = 2.474) \n[8] Zhaoyu Zhai, José-Fernán Martínez Ortega, Néstor\
    \ Lucas Martínez, Vicente Hernández Díaz. \nApplying Case-Based Reasoning and\
    \ A Learning-Based Adaptation Strategy to Irrigation Scheduling \nin Grape Farming.\
    \ Computers and Electronics in Agriculture. vol. 178, Nov. 2020. DOI: \nhttps://doi.org/10.1016/j.compag.2020.105741.\
    \ (JCR Q1, Impact Factor = 3.858) \n[9] Zhaoyu Zhai, José-Fernán Martínez Ortega,\
    \ Néstor Lucas Martínez, Huanliang Xu. An Efficient \nCase Retrieval Algorithm\
    \ for Agricultural Case-Based Reasoning Systems, with Consideration of Case \n\
    \ \n167 \n \nBase \nMaintenance. \nAgriculture-Basel. \nvol. \n9(10), \nSept.\
    \ \n2020. \nDOI: \nhttps://doi.org/10.3390/agriculture10090387 (JCR Q2, Impact\
    \ Factor = 2.072) \n7.3.2. Research projects \nThe results presented in this thesis\
    \ were obtained from the following two European projects. \n[1] SWARMs – Smart\
    \ and Networking Underwater Robots in Cooperation Meshes, under Grant \nAgreement\
    \ No. 662107-SWARMs-ECSEL-2014-1, partially supported by the ECSEL JU and the\
    \ \nSpanish Ministry of Economy and Competitiveness (Ref: PCIN-2014-022-C02-02).\
    \ \n[2] AFarCloud – Aggregating Farming in the Cloud, under grant agreement No.\
    \ 783221-AFarCloud-\nH2020-ECSEL-2017-2, and supported in part by the ECSEL JU\
    \ and in part by the Spanish Ministry of \nScience, Innovation and Universities\
    \ under grant PCI2018-092965. \nAppendix A \nThe Iris plant dataset is a classic\
    \ and very easy multi-class classification dataset. The detail of this \ndataset\
    \ is listed in Table 40. \nTable 40. Characteristics of the Iris plant dataset.\
    \ \nCharacteristics \nContent \nNumber of instances \n150 \nNumber of classes\
    \ \n3 (50 instances in each class) \nNumber of attributes \n4 numeric features\
    \ \nName of classes \nIris-Setosa \nIris-Versicolour \nIris-Virginica \nName of\
    \ Attributes \nSepal length (cm) \nSepal width (cm) \nPetal length (cm) \n \n\
    168 \n \nPetal width (cm) \nMissing attributes \nNone \nThe user guide for this\
    \ Iris plant dataset is provided in Table 41. \nTable 41. User guide for the Iris\
    \ plant dataset. \nParameters: \nreturn_X_y: Boolean, default=False. \nIf True,\
    \ returns (data, target) instead of a Bunch \nobject. See below for more information\
    \ about the \ndata and target object. \nReturns: \ndata: Bunch \nDictionary-like\
    \ object, the interesting attributes are: \n‘data’, the data to learn, ‘target’,\
    \ the classification \nlabels, ‘target_names’, the meaning of the labels, \n‘feature_names’,\
    \ the meaning of the features, \n‘DESCR’, the full description of the dataset,\
    \ \n‘filename’, the physical location of iris csv dataset \n(added in version\
    \ 0.20). \n(data, target): tuple if return_X_y is True \nNew in version 0.18.\
    \ \nThe Iris plant dataset can be displayed in Figure 119. \n \n169 \n \n \n(a)\
    \ \n \n(b) \nFigure 119. Data visualization of the Iris plant dataset: (a) visualization\
    \ of the first two features (sepal \nlength and sepal width); (b) visualization\
    \ of the first three features (sepal length, sepal width, and petal \nlength).\
    \ \n \n170 \n \n \nFor accessing the instances in the Iris plant dataset and obtaining\
    \ their names of classes, the \nfollowing example is given in Figure 120. \n \n\
    Figure 120. An example of accessing the Iris plant dataset. \nAppendix B \nThe\
    \ Oracle Mediator is a service component of the Oracle SOA Suite that provides\
    \ mediation \ncapabilities like selective routing, transformation, and validation\
    \ capabilities, along with various \nmessage exchange patterns like synchronous,\
    \ asynchronous, and event publishing or subscriptions. As \na lightweight framework,\
    \ the Oracle Mediator mediates various components within a composite \napplication.\
    \ Meanwhile, it can convert data to facilitate communication between various interfaces\
    \ \nexposed by different components. Generally, the following primary functions\
    \ are considered in the \nOracle Mediator. \n• \nContent-based and header-based\
    \ routing: The Oracle Mediator enables to define rules based on \nthe message\
    \ payload or message headers. Actions (like routing and delivering data to a database)\
    \ \ncan be specified according to the elements or attributes from the message\
    \ payload or the message \nheaders. \n• \nSynchronous and asynchronous interactions:\
    \ The Oracle Mediator supports both synchronous \nand asynchronous request and\
    \ response interactions. In a synchronous interaction, the client can \nrequest\
    \ a service and then wait for a response to this request. In an asynchronous interaction,\
    \ the \nclient can invoke a service without waiting for a response to this request\
    \ and then specify an action \n(like raising an event or starting a process) after\
    \ an indicated timeout period. \n \n171 \n \n• \nSequential and parallel routing\
    \ of messages: The Oracle Mediator provides the configuration of \nexecuting routing\
    \ rules either in parallel or in sequence. \n• \nMessage resequencing: When incoming\
    \ messages arrive in a random order, the Oracle Mediator \nis able to order the\
    \ messages based on the sequential or chronological information and then send\
    \ \nthe message to the target services in the correct order. \n• \nData transformation:\
    \ The Oracle Mediator offers the possibility of interchanging data among \napplications\
    \ that use different schemas. For instance, a comma-delimited file can be converted\
    \ into \na database table structure. \n• \nPayload validation: The Oracle Mediator\
    \ can validate the incoming message payload by using a \nSchematron or an XSD\
    \ file. \n• \nJava callouts: The Oracle Mediator permits to add Java codes with\
    \ regular expressions to the \nrouting rules. \n• \nEvent handling: The Oracle\
    \ Mediator can both subscribe to and raise an event when a situation of \ninterest\
    \ occurs. \n• \nDynamic routing: The Oracle Mediator can separate the control\
    \ logic of a process from the \nexecution of the process. The control logic determines\
    \ the path taken by the process through the \nMediator Editor. \n• \nError handling:\
    \ The Oracle Mediator supports both manual error handling and error handling \n\
    based on fault policies. A fault policy is composed of conditions and actions,\
    \ where the conditions \nindicate the action to be carried out for a particular\
    \ error condition. \n• \nSending messages back to the caller (Echo): The Oracle\
    \ Mediator can echo source messages back \nto the initial caller after any transformations,\
    \ validations, assignments, or sequencing operations \nare performed. \n• \nMultiple\
    \ part messages: The Oracle Mediator can process messages that consist of multiple\
    \ parts. \nFor instance, some remote procedure call (RPC) web services contain\
    \ multiple parts in the SOAP \nmessage. \nFor maintaining the above-mentioned\
    \ functionalities, it is necessary to understand the message \nexchange patterns\
    \ of the Oracle Mediator. Some common message exchange patterns between the \n\
    Oracle Mediator service component and other applications include (i) one-way message\
    \ exchange \n \n172 \n \npatterns, (ii) request-reply message exchange patterns,\
    \ (iii) request-reply-fault message exchange \npatterns, (iv) request-callback\
    \ message exchange patterns, (v) request-reply-callback message exchange \npatterns,\
    \ and (vi) request-reply-fault-callback message exchange patterns. \nAll these\
    \ six exchange patterns have default configurations of handling responses, faults,\
    \ and \ncallbacks by Oracle JDeveloper when a routing rule is created. The following\
    \ points are applicable to \nall exchange patterns. \n• \nWhen a response, fault,\
    \ or callback is sent back to the caller, it is also possible to route the same\
    \ \nmessage to a different target service or event by clicking the button next\
    \ to the target and selecting \na different target. \n• \nWhen the caller of the\
    \ Mediator expects a response, one or more routing rules may route the request\
    \ \nto a target that does not return a response, but there should be at least\
    \ one sequential routing rule \nthat returns a response. \n• \nWhen there are\
    \ multiple routing rules in a request-response pattern with multiple rules sending\
    \ a \nresponse back to the initial caller, the first response that is received\
    \ is the one delivered to the caller. \nThe other responses are ignored. Thus,\
    \ the routing rules that send the response should precede other \nrouting rules\
    \ that forward the response (if any). \nFor demonstrating how the message exchange\
    \ patterns work, the one-way message exchange \npatterns are explained in the\
    \ following. \nIn a one-way interaction, the Oracle Mediator is invoked but it\
    \ does not send a response back to \nthe caller. Depending on the type of routing\
    \ rule target, the responses, faults, and callbacks are handled \nas shown in\
    \ Table 42. The one-way messages exchange pattern is presented in Figure 121.\
    \ \nTable 42. Responses when the Oracle Mediator adopts the one-way interaction.\
    \ \nRouting rule target type \nResponse \nRequest \nNo response. \nRequest-Response\
    \ \nResponse is forwarded to another target or event. \n \n173 \n \nRequest-Response-Fault\
    \ \nResponse and fault are forwarded to another target \nor event. \nRequest-Callback\
    \ \nCallback is forwarded to another target or event. \nRequest-Response-Callback\
    \ \nResponse and callback are forwarded to another \ntarget or event. \nRequest-Response-Fault-Callback\
    \ \nResponse, fault, and callback are forwarded to \nanother target or event.\
    \ \n \nFigure 121. The one-way message exchange pattern. \nAppendix C \nThe artificial\
    \ neural network (ANN) is a computing system inspired by the biological neural\
    \ \nnetworks that constitute animal brains. The ANN tries to perform tasks by\
    \ considering samples without \nbeing programmed with task-specific rules. A typical\
    \ application of the ANN is image recognition and \nclassification. In general,\
    \ an ANN is on the basis of a collection of connected units or nodes called \n\
    artificial neurons, enabling to transmit a signal to other neurons. Depending\
    \ on the complexity of the \nsystem, the neural network is capable of processing\
    \ information by adjusting the interconnection \nbetween several internal nodes.\
    \ \n \n174 \n \nThe structure of the neural network used in the preliminary proof\
    \ is a three-layer error back \npropagation (BP) neural network. The trained BP\
    \ neural network is able to process the input information \nof similar samples\
    \ and transform it nonlinearly with the minimum output error. The topological\
    \ \nstructure of a BP neural network is presented in Figure 122. The neural network\
    \ includes three hidden \nlayers between the input and output layers. \n \nFigure\
    \ 122. The topological structure of a BP neural network. \n \nIn Figure 122, the\
    \ involved parameters are listed as follows. \n• \n\U0001D43C1– \U0001D43C8 denote\
    \ the input layer neurons. \n• \n\U0001D43B1– \U0001D43B\U0001D45B and \U0001D43B\
    ′′1– \U0001D43B′′\U0001D45B denote the hidden layer neurons. \n• \n\U0001D45B\
    \ denotes the number of the hidden layer neurons. \n• \n\U0001D466 denotes the\
    \ output layer neuron. \n• \n\U0001D44A\U0001D458\U0001D45B denotes the weight\
    \ between the \U0001D458-th node of the input layer and the \U0001D45B-th node\
    \ of the hidden \nlayer. \n• \n\U0001D44F\U0001D456\U0001D45B denotes the bias\
    \ between the \U0001D456-th node of the input layer and the \U0001D45B-th node\
    \ of the hidden layer. \n \n175 \n \n• \n\U0001D44F\U0001D458\U0001D45B denotes\
    \ the bias between the \U0001D458-th node of the hidden layer and the \U0001D45B\
    -th node of the hidden \nlayer. \n• \n\U0001D44A\U0001D45B denotes the weight\
    \ between the \U0001D45B-th node of the hidden layer and the output layer. \n\
    • \n\U0001D44F\U0001D45B denotes the bias between the \U0001D45B-th node of the\
    \ hidden layer and the output layer. \nThe BP neural network is a computing model\
    \ with a learning function with the objective of \nobtaining the relation between\
    \ the input and output from the training samples. The training process \nconsists\
    \ of two steps: (i) signal positive spread, and (ii) error BP. The samples are\
    \ transferred from the \ninput layer to the hidden layer and processed to the\
    \ output layer. The error is computed by comparing \nthe actual value. If the\
    \ actual output satisfies the error range, the output will be obtained. Otherwise,\
    \ the \nerror will return to the input layer through the hidden layer. Under this\
    \ circumstance, the weight and \nbias of all input neurons will be adjusted until\
    \ the error is reduced within the given range. As mentioned \nin Section 5.2,\
    \ the flight speed (\U0001D453\U0001D460), flight altitude (\U0001D453\U0001D44E\
    \ ), propeller pitch (\U0001D45D), nozzle pitch (\U0001D45B\U0001D45D), \ntemperature\
    \ (\U0001D461), wind speed (\U0001D464\U0001D460), and prescription value (\U0001D463\
    ) are taken as input, while the droplet \ndeposition is taken as the output. The\
    \ pseudo code of the BP neural network is shown in Table 43. \nTable 43. The pseudo\
    \ code of the BP neural network. \nAlgorithm: The BP neural network \nDefinition:\
    \ \nInput layer neurons (\U0001D465\U0001D456) \nThe number of input layer neurons\
    \ (\U0001D45B) \nThe hidden layer neurons (\U0001D43B\U0001D457, \U0001D43B′\U0001D457\
    , \U0001D43B′′\U0001D457) \nThe number of input layer neurons (\U0001D458) \n\
    The output layer neurons (\U0001D466) \nInitialization: \nInitialize all weights\
    \ and biases in the network. \nMain body: \nfor \U0001D456 in range (1, \U0001D45B\
    ) do \n    \U0001D4658 = (\U0001D453\U0001D460, \U0001D453ℎ, \U0001D45D, \U0001D45B\
    \U0001D460, \U0001D461, \U0001D464\U0001D460, \U0001D463) \n \n176 \n \n    \U0001D466\
    \ = (\U0001D451) \n    \U0001D465\U0001D456 = \U0001D44B(\U0001D465\U0001D456\
    ) \nEnd \nfor \U0001D457 in range (1, \U0001D458) do \n    for \U0001D461 in range\
    \ (1,3) do \n        \U0001D43B\U0001D457 = ∑ \U0001D44A\U0001D456\U0001D457\U0001D465\
    \U0001D456 + \U0001D44F\U0001D457 \n        \U0001D43B′\U0001D457 = ∑ \U0001D44A\
    ′\U0001D456\U0001D457\U0001D43B\U0001D457 + \U0001D44F′\U0001D457 \n        \U0001D43B\
    ′′\U0001D457 = ∑ \U0001D44A′′\U0001D456\U0001D457\U0001D43B′\U0001D457 + \U0001D44F\
    ′′\U0001D457 \n        \U0001D4660 = \U0001D454(\U0001D43B′′\U0001D457) \n   \
    \ end \nend \nfor all j in range (1, \U0001D458) do \n    \U0001D438 =\n∑ \U0001D452\
    \U0001D457\n2\n2  \n    if (\U0001D438 > \U0001D438\U0001D45F\U0001D45F\U0001D45C\
    \U0001D45F) do \n        \U0001D44A\U0001D456\U0001D457 = \U0001D44A\U0001D456\
    \U0001D457 + α\U0001D43B\U0001D457\U0001D452\U0001D457 \n        \U0001D44F\U0001D457\
    \ = \U0001D44F\U0001D457 + β\U0001D452\U0001D457 \n    return \U0001D456 = 1 \n\
    \    else \U0001D466 = \U0001D4660 \nend \nFor the ANN application in the variable\
    \ spray system for crop protection, the flow chart is \npresented in Figure 123.\
    \ \n \n177 \n \n \nFigure 123. The flow chart of the variable spray system. \n\
    \ \nIn this spray system, the flight speed, flight altitude, and positioning information\
    \ of the UAVs are \nobtained by using the global positioning system (GPS). The\
    \ prescription value of the current position \nis determined by matching the position\
    \ of the UAV with that of the prescription map. Environmental \nparameters like\
    \ temperature and wind speed are collected by sensors. After information fusion,\
    \ the \ninformation is taken as inputs to the BP neural network to predict the\
    \ deposition. The flow rate of the \nspraying is acquired by combining the flight\
    \ speed of the UAV with the predicted deposition value. \nLastly, a pulse width\
    \ modulation square wave is generated to complete the process of flow rate \n\
    regulation. \nAppendix D \nThe “xml.dom.minidom” module is essentially a DOM 1.0-compatible\
    \ DOM with some DOM 2 \nfeatures (primarily namespace features). The usage of\
    \ the DOM interface in Python is straight-forward. \nThe following mapping rules\
    \ apply. \n• \nInterfaces are accessed through instance objects. Applications\
    \ should not instantiate the classes \nthemselves; they should use the creator\
    \ functions available on the Document object. Derived \ninterfaces support all\
    \ operations (and attributes) from the base interfaces, plus any new operations.\
    \ \n \n178 \n \n• \nOperations are used as methods. Since the DOM uses only in\
    \ parameters, the arguments are passed \nin normal order (from left to right).\
    \ There are no optional arguments. void operations return None \nvalues. \n• \n\
    Interface definition language (IDL) attributes map to instance attributes. For\
    \ compatibility with the \nobject management group (OMG) IDL language mapping\
    \ for Python, an attribute foo can also be \naccessed through accessor methods\
    \ (“_get_foo()” and “_set_foo()”). The readonly attributes must \nno be changed\
    \ and this is no enforced at runtime. \n• \nThe types short int, unsigned int,\
    \ unsigned long long, and boolean all map to Python integer objects. \n• \nThe\
    \ type DOMString maps to Python strings. “xml.dom.minidom” supports either bytes\
    \ or strings, \nbut will normally produce strings. Values of type DOMString may\
    \ also be None where allowed to \nhave the IDL null value by the DOM specification\
    \ from the W3C. \n• \nconst declarations map to variables in their respective\
    \ scope. \n• \nDOMException is currently not supported in “xml.dom.minidom”. Instead,\
    \ “xml.dom.minidom” \nuses standard Python exceptions such as TypeError and AttributeError.\
    \ \n• \nNodeList objects are implemented using Python’s built-in list type. These\
    \ objects provide the \ninterface defined in the DOM specification, but with earlier\
    \ versions of Python they do not support \nthe official API. They are, however,\
    \ much more “Pythonic” than the interface defined in the W3C \nrecommendations.\
    \ \n \n \n \n179 \n \nReferences \n1. \nCurrent world population. Available: https://www.worldometers.info/world-population/.\
    \ \n2. \nThe \nworld \npopulation \nprospects: \n2015 \nRevision. \nAvailable:\
    \ \nhttps://www.un.org/en/development/desa/publications/world-population-prospects-2015-\n\
    revision.html. \n3. \nCuesta, J. “A world free of poverty ... but of hunger and\
    \ malnutrition?” European Journal of \nDevelopment Research, vol. 25, no. 1, pp.\
    \ 1-4, Feb. 2013. https://doi.org/10.1057/ejdr.2012.43. \n4. \nUdias, A.; Pastori,\
    \ M.; Dondeynaz, C.; Moreno, C.C.; Ali, A.; Cattaneo, L.; Cano, J. “A decision\
    \ \nsupport tool to enhance agricultural growth in the Mekrou river basin (West\
    \ Africa),” Computers \nand \nElectronics \nin \nAgriculture, \nvol. \n154, \n\
    pp. \n467-481, \nNov. \n2018. \nhttps://doi.org/10.1016/j.compag.2018.09.037.\
    \ \n5. \nDong, C.; Huang, G.; Cheng, G.H.; Zhao, S. “Water resources and farmland\
    \ management in the \nSonghua river watershed under interval and fuzzy uncertainties,”\
    \ Water Resources Management, \nvol. 32, no. 13, pp. 4177-4200, Oct. 2018. https://doi.org/10.1007/s11269-018-2035-0.\
    \ \n6. \nFarooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. “A survey on\
    \ the role of IoT in agriculture \nfor the implementation of smart farming,” IEEE\
    \ Access, vol. 7, pp. 156237-156271, Oct. 2019. \nhttps://doi.org/10.1109/ACCESS.2019.2949703.\
    \ \n7. \nMekala, M.S.; Viswanathan, P. “A survey: Smart agriculture IoT with cloud\
    \ computing,” In \nProceedings of International Conference on Microelectronic\
    \ Devices, Circuits and Systems \n(ICMDCS), Vellore, INDIA, Aug. 10-12, 2017.\
    \ \n8. \nWolfert, S.; Ge, L.; Verdouw, C.; Bogaardt, M.J. “Big data in smart farming\
    \ – A review,” \nAgricultural Systems, vol. 153, pp. 69-80, May 2017. https://doi.org/10.1016/j.agsy.2017.01.023.\
    \ \n9. \nTaechatanasat, P.; Armstrong, L. “Decision support system data for farmer\
    \ decision making,” In \nProceedings of Asian Federation for Information Technology\
    \ in Agriculture, pp. 472-486, 2014. \n10. Watson \nDecision \nPlatform \nfor\
    \ \nAgriculture. \nAvailable: \nhttps://www.ibm.com/downloads/cas/ONVXEB2A. \n\
    11. Prospera. Available: https://www.prospera.ag/. \n12. Bazzani, G.M. “An integrated\
    \ decision support system for irrigation and water policy design: \nDSIRR,” Environmental\
    \ Modelling & Software, vol. 20, no. 2, pp. 153-163, Feb. 2005. \nhttps://doi.org/10.1016/j.envsoft.2003.12.017.\
    \ \n13. Tyrychtr, J.; Vostrovsky, V. “The current state of the issue of information\
    \ needs and dispositions \namong small Czech farms,” Agricultural Economics–Zemedelska\
    \ Ekonomika, vol. 63, no. 4, pp. \n164-174, 2017. https://doi.org/10.17221/321/2015-AGRICECON.\
    \ \n14. AFarCloud project. Available: http://www.afarcloud.eu/. \n \n180 \n \n\
    15. Francis, C.A.; Lieblein, G.; Breland, T.A.; Salomonsson, L.; Geber, U.; Sriskandarajah,\
    \ N.; \nLanger, V. “Transdisciplinary research for a sustainable agriculture and\
    \ food sector,” Agronomy \nJournal, vol. 100, no. 3, pp. 771-776, May-Jun. 2008.\
    \ https://doi.org/10.2134/agronj2007.0073. \n16. Asseng, S.; Jamieson, P.D.; Kimball,\
    \ B.; Pinter, P.; Sayre, K.; Bowden, J.W. “Simulated wheat \ngrowth affected by\
    \ rising temperature, increased water deficit and elevated atmospheric CO2,” \n\
    Filed Crops Research, vol. 85, no. 2-3, pp. 85-102, Feb. 2004. https://doi.org/10.1016/S0378-\n\
    4290(03)00154-0. \n17. Banger, K.; Yuan, M.W.; Wang, J.M.; Nafziger, E.D.; Pittelkow,\
    \ C.M. “A vision for incorporating \nenvironmental effects into nitrogen management\
    \ decision support tools for US maize production,” \nFrontiers in Plant Science,\
    \ vol. 8, Jul. 2017. https://doi.org/10.3389/fpls.2017.01270. \n18. Lin, Y.Z.;\
    \ Deng, X.Z.; Jin, Q. “Economic effects of drought on agriculture in north China,”\
    \ \nInternational Journal of Disaster Risk Science, vol. 4, no. 2, pp. 59-67,\
    \ Jun. 2013. \nhttps://doi.org/10.1007/s13753-013-0007-9. \n19. Evers, L.; Barros,\
    \ A.I.; Monsuur, H.; Wagelmans, A. “Online stochastic UAV mission planning \n\
    with time windows and time-sensitive targets,” European Journal of Operational\
    \ Research, vol. \n238, no. 1, pp. 348-362, Oct. 2014. https://doi.org/10.1016/j.ejor.2014.03.014.\
    \ \n20. Zhou, H.X.; Zeng, Z.; Lian, L. “Adaptive re-planning of AUVs for environmental\
    \ sampling \nmissions: A fuzzy decision support system based on multi-objective\
    \ particle swarm optimization,” \nInternational Journal of Fuzzy Systems, vol.\
    \ 20, no. 2, pp. 650-671, Feb. 2018. \nhttps://doi.org/10.1007/s40815-017-0398-7.\
    \ \n21. Lofaro, A. “Decision support and autonomous decision systems using “Big\
    \ Data”,” in Proceedings \nof 11th IEEE International Conference on Application\
    \ of Information and Communication \nTechnologies (AICT), Moscow, RUSSIA, Sep.\
    \ 20-22, 2017. \n22. Zhang, Z.X.; Jiang, Q.; Wang, R.J.; Song, L.T.; Zhang, Z.Y.;\
    \ Wei, Y.Y.; Mei, T.; Yu, B. “Research \non management system of automatic driver\
    \ decision-making knowledge base for unmanned \nvehicle,” International Journal\
    \ of Pattern Recognition and Artificial Intelligence, vol. 33, no. 4, \nApr. 2019.\
    \ https://doi.org/10.1142/S0218001419590134. \n23. Pietrzykowski, Z.; Wolejsza,\
    \ P. “Decision support system in marine navigation,” In Proceedings \nof 16th\
    \ International Conference on Transport Systems Telematics (TST), Katowice Ustron,\
    \ \nPOLAND, Mar. 16-19, 2016. \n24. Kamali, F.P.; Borges, J.A.R.; Meuwissen M.P.M.;\
    \ de Boer, I.J.M.; Lansink, A.G.J.M.O. \n“Sustainability assessment of agricultural\
    \ systems: The validity of expert opinion and robustness \nof a multi-criteria\
    \ analysis,” Agricultural Systems, vol. 157, pp. 118-128, Oct. 2017. \nhttps://doi.org/10.1016/j.agsy.2017.07.013.\
    \ \n \n181 \n \n25. Chlingaryan, A.; Sukkarieh, S.; Whelan, B. “Machine learning\
    \ approaches for crop yield prediction \nand nitrogen status estimation in precision\
    \ agriculture: A review,” Computers and Electronics in \nAgriculture, vol. 151,\
    \ pp. 61-69, Aug. 2018. https://doi.org/10.1016/j.compag.2018.05.012. \n26. Han,\
    \ E.J.; Ines, A.V.M.; Baethgen, W.E. “Climate-agriculture-modeling and decision\
    \ tool \n(CAMDT): A software framework for climate risk management in agriculture,”\
    \ Environmental \nModelling \n& \nSoftware, \nvol. \n95, \npp. \n102-114, \nSep.\
    \ \n2017. \nhttps://doi.org/10.1016/j.envsoft.2017.06.024. \n27. Chougule, A.;\
    \ Jha, V.K.; Mukhopadhyay, D. “AgroKanti: Location-aware decision support system\
    \ \nfor forecasting of pests and diseases in grapes,” in Proceedings of 3rd International\
    \ Conference on \nInformation System Design and Intelligent Applications (INDIA),\
    \ Visakhapatnam, INDIA, Jan. 08-\n09, 2016. \n28. Ali, M.; Deo, R.C.; Downs, N.J.;\
    \ Maraseni, T. “Multi-stage committee based extreme learning \nmachine model incorporating\
    \ the influence of climate parameters and seasonality on drought \nforecasting,”\
    \ Computers and Electronics in Agriculture, vol. 152, pp. 149-165, Sep. 2018.\
    \ \nhttps://doi.org/10.1016/j.compag.2018.07.013. \n29. Ghorbani, M.A.; Deo, R.C.;\
    \ Karimi, V.; Kashani, M.H.; Ghorbani, S. “Design and implementation \nof a hybrid\
    \ MLP-GSA model with multi-layer perceptron-gravitational search algorithm for\
    \ \nmonthly lake water level forecasting,” Stochastic Environmental Research and\
    \ Risk Assessment, \nvol. 33, no. 1, pp. 125-147. Jan. 2019. https://doi.org/10.1007/s00477-018-1630-1.\
    \ \n30. Rose, D.C.; Chilvers, J. “Agriculture 4.0: Broadening responsible innovation\
    \ in an era of smart \nfarming,” \nFrontiers \nin \nSustainable \nFood \nSystems,\
    \ \nvol. \n2, \nDec. \n2018. \nhttps://doi.org/10.3389/fsufs.2018.00087. \n31.\
    \ Lavelle, P. “Rethinking Chinese history through the history of agriculture,”\
    \ Agricultural History, \nvol. 93, no. 4, pp. 717-718, 2019. \n32. Obrien, P.K.\
    \ “Agriculture and industrial revolution,” Economic History Review, vol. 30, no.\
    \ 1, pp. \n166-181, Feb. 1977. \n33. Marchant, J.A.; Moncaster, M.E. “Robotics\
    \ and automation in agriculture,” Outlook on \nAgriculture, vol. 19, no. 4, pp.\
    \ 221-228, Dec. 1990. https://doi.org/10.1177/003072709001900403. \n34. Zambon,\
    \ I.; Cecchini, M.; Egidi, G.; Saporito, M.G.; Colantoni, A. “Revolution 4.0:\
    \ Industry vs. \nAgriculture in a future development for SMEs,” Processes, vol.\
    \ 7, no. 1, Jan. 2019. \nhttps://doi.org/10.3390/pr7010036. \n35. Anderl, R. “Industrie\
    \ 4.0 – Technological approaches, use cases, and implementation,” AT-\nAutomatisierungstechnik,\
    \ vol. 63, no. 10, pp. 753-765, Oct. 2015. https://doi.org/10.1515/auto-\n2015-0025.\
    \ \n \n182 \n \n36. Agriculture \n4.0: \nThe \nfuture \nof \nfarming \ntechnology.\
    \ \nAvailable: \nhttps://www.worldgovernmentsummit.org/api/publications/document?id=95df8ac4-e97c-6578-\n\
    b2f8-ff0000a7ddb6. \n37. Yuan, J.J.; Lu, Y.L.; Ferrier, R.C.; Liu, Z.Y.; Su, H.Q.;\
    \ Meng, J.; Song, S.; Jenkins, A. \n“Urbanization, rural development and environmental\
    \ health in China,” Environmental \nDevelopment, vol. 28, pp. 101-110, Dec. 2018.\
    \ https://doi.org/10.1016/j.envdev.2018.10.002. \n38. Pang, C.; Yu, H.Y.; He,\
    \ J.; Xu, J.C. “Deforestation and changes in landscape patterns from 1979 \nto\
    \ 2006 in Suan Country, DPR Korea,” Forests, vol. 4, no. 4, pp. 968-983, Dec.\
    \ 2013. \nhttps://doi.org/10.3390/f4040968. \n39. Athukorala, W.; Wilson, C. “Groundwater\
    \ overuse and farm-level technical inefficiency: Evidence \nfrom Sri Lanka,” Hydrogeology\
    \ Journal, vol. 20, no. 5, pp. 893-905, Aug. 2012. \nhttps://doi.org/10.1007/s10040-012-0833-7.\
    \ \n40. Fountas, S.; Sorensen, C.G.; Tsiropoulos, Z.; Cavalaris, C.; Liakos, V.;\
    \ Gemtos, T. “Farm \nmachinery management information system,” Computers and Electronics\
    \ in Agriculture, vol. 110, \npp. 131-138, Jan. 2015. https://doi.org/10.1016/j.compag.2014.11.011.\
    \ \n41. Czimber, K.; Galos, B. “A new decision support system to analyse the impacts\
    \ of climate change \non the Hungarian forestry and agricultural sectors,” Scandinavian\
    \ Journal of Forest Research, vol. \n31, no. 7, pp. 664-673, Aug. 2016. https://doi.org/10.1080/02827581.2016.1212088.\
    \ \n42. Kmoch, L.; Pagella, T.; Palm, M.; Sinclair, F. “Using local agroecological\
    \ knowledge in climate \nchange adaptation: A study of tree-based options in northern\
    \ Morocco,” Sustainability, vol. 10, no. \n10, Oct. 2018. https://doi.org/10.3390/su10103719.\
    \ \n43. van Evert, F.K.; Fountas, S.; Jakovetic, D.; Crnojevic, V.; Travlos, I.;\
    \ Kempenaar, C. “Big data for \nweed control and crop protection,” Weed Research,\
    \ vol. 57, no. 4, pp. 218-233, Aug. 2017. \nhttps://doi.org/10.1111/wre.12255.\
    \ \n44. Borodin, V.; Bourtembourg, J.; Hnaien, F.; Labadie, N. “Handling uncertainty\
    \ in agricultural \nsupply chain management: A state of the art,” European Journal\
    \ of Operational Research, vol. \n254, no. 2, pp. 348-359, Oct. 2016. https://doi.org/10.1016/j.ejor.2016.03.057.\
    \ \n45. Pourmoayed, R.; Nielsen, L.R.; Kristensen, A.R. “A hierarchical Markov\
    \ decision process \nmodeling feeding and marketing decisions of growing pigs,”\
    \ European Journal of Operational \nResearch, vol. 250, no. 3, pp. 925-938, May\
    \ 2016. https://doi.org/10.1016/j.ejor.2015.09.038. \n46. Ferrandez-Pastor, F.J.;\
    \ Garcia-Chamizo, J.M.; Nieto-Hidalgo, M.; Mora-Pascual, J.; Mora-\nMartinez,\
    \ J. “Developing ubiquitous sensor network platform using Internet of Things:\
    \ Application \nin precision agriculture,” Sensors, vol. 16, no. 7, Jul. 2016.\
    \ https://doi.org/10.3390/s16071141. \n47. Das, V.; Jain, S. “Genetic algorithm\
    \ to find most optimum growing technique for multiple cropping \nusing Big Data,”\
    \ In Proceedings of International Conference on Innovative and Emerging \n \n\
    183 \n \nTechnologies for Farming – Energy and Environment – Water (ITsFEW), Vellore,\
    \ INDIA, Oct. \n12-14, 2018. \n48. Liakos, K.G.; Busato, P.; Moshou, D.; Pearson,\
    \ S.; Bochtis, D. “Machine learning in agriculture: \nA review,” Sensors, vol.\
    \ 18, no. 8, Aug. 2018. https://doi.org/10.3390/s18082674. \n49. Lopez-Riquelme,\
    \ J.A.; Pavon-Pulido, N.; Navarro-Hellin, H.; Soto-Valles, F.; Torres-Sanchez,\
    \ R. \n“A software architecture based on FIWARE cloud for precision agriculture,”\
    \ Agricultural Water \nManagement, vol. 183, pp. 123-135, Mar. 2017. https://doi.org/10.1016/j.agwat.2016.10.020.\
    \ \n50. Hajjaj, S.S.H.; Sahari, K.S.M. “Review of agriculture robotics: Practicality\
    \ and feasibility,” in \nProceedings of IEEE International Symposium on Robotics\
    \ and Intelligent Sensors (IRIS), Tokyo, \nJAPAN, Dec. 17-20, 2016. \n51. Sowmya,\
    \ B.J.; Chaitanya, S.K.; Seema, S.; Srinivasa, K.G. “Data analytic techniques\
    \ for \ndeveloping decision support system on agrometeorological parameters for\
    \ farmers,” International \nJournal of Cognitive Informatics and Natural Intelligence,\
    \ vol. 14, no. 2, pp. 92-107, Apr. 2020. \nhttps://doi.org/10.4018/IJCINI.2020040106.\
    \ \n52. Jones, J.W. “Decision support systems – An organizational perspective\
    \ – KEEN, PG, MORTON, \nMSS,” Administrative Science Quarterly, vol. 25, no. 2,\
    \ pp. 376-382, Jun. 1980. \nhttps://doi.org/10.2307/2392463. \n53. Sheng, Y.K.;\
    \ Zhang, S. “Analysis of problems and trends of decision support systems \ndevelopment,”\
    \ In Proceedings of 1st International Conference on E-Business and Information\
    \ \nSystem Security, Wuhan, PEOPLES R CHINA, May 23-24, 2009. \n54. Terribile,\
    \ F.; Agrillo, A.; Bonfante, A.; Buscemi, G.; Colandrea, M.; D’Antonio, A.; De\
    \ Mascellis, \nR.; De Michele, C.; Langella, G.; Manna, P.; Marotta, L.; Mileti,\
    \ F.A.; Minieri, L.; Orefice, N.; \nValentini, S.; Vingiani, S.; Basile, A. “A\
    \ web-based spatial decision supporting system for land \nmanagement and soil\
    \ conservation,” Solid Earth, vol. 6, no. 3, pp. 903-928, Jul. 2015. \nhttps://doi.org/10.5194/se-6-903-2015.\
    \ \n55. Yazdani, M.; Zarate, P.; Coulibaly, A.; Zavadskas, E.K. “A group decision\
    \ making support system \nin logistics and supply chain management,” Expert Systems\
    \ with Applications, vol. 88, pp. 376-\n392, Dec. 2017. https://doi.org/10.1016/j.eswa.2017.07.014.\
    \ \n56. Fontana, M.E.; Aragao, J.P.S.; Morais, D.C. “Decision support system for\
    \ outsourcing strategies,” \nProduction Engineering – Research and Development,\
    \ vol. 13, no. 5, pp. 547-555, Oct. 2019. \nhttps://doi.org/10.1007/s11740-019-00907-1.\
    \ \n57. Ekeocha, R.J.O. “Optimization of systems,” International Journal of Sciences,\
    \ vol. 8, no. 3, pp. \n118-125, Mar. 2019. https://doi.org/10.18483/ijSci.1964.\
    \ \n58. Ong, P.; Cortes, J. “Event-triggered interactive gradient descent for\
    \ real-time multi-objective \noptimization,” In Proceedings of 56th Annual IEEE\
    \ Conference on Decision and Control (CDC), \nMelbourne, AUSTRALIA, Dec. 12-15,\
    \ 2017. \n \n184 \n \n59. Hakizimana, A.; Scott, J.K. “Differentiability conditions\
    \ for stochastic hybrid systems with \napplication to the optimal design of microgrids,”\
    \ Journal of Optimization Theory and Applications, \nvol. 173, no. 2, pp. 658-682,\
    \ May 2017. https://doi.org/10.1007/s10957-017-1096-1. \n60. El-Hajj, A.M.; Niyato,\
    \ D.; Dawy, Z. “A DEC-MDP model for joint uplink/downlink resource \nmanagement\
    \ in OFDMA-based networks,” Physical Communication, vol. 17, pp. 107-117, Dec.\
    \ \n2015. https://doi.org/10.1016/j.phycom.2015.08.006. \n61. Wu, L.L.; Wu, Q.H.;\
    \ Jing, Z.X.; Wei, F.; Deng, S.; Zhou, X.X. “Optimal power and gas dispatch \n\
    of the integrated electricity and natural gas networks,” In Proceedings of IEEE\
    \ Innovative Smart \nGrid Technologies – Asia (ISGT-Asia), Melbourne, AUSTRALIA,\
    \ Nov. 28-Dec. 01, 2016. \n62. Tatsumi, K. “Modified perturbation-based chaotic\
    \ system using the quasi-Newton method with the \nsymmetric rank-one formula for\
    \ global optimization,” In Proceedings of IEEE International \nConference on Systems,\
    \ Man, and Cybernetics (SMC), Miyazaki, JAPAN, Oct. 07-10, 2018. \n63. Dhillon,\
    \ J.S.; Parti, S.C.; Kothari, D.P. “Fuzzy decision making in multiobjective long-term\
    \ \nscheduling of hydrothermal system,” International Journal of Electrical Power\
    \ & Energy Systems, \nvol. 23, no. 1, pp. 19-29, Jan. 2001. https://doi.org/10.1016/S0142-0615(00)00031-4.\
    \ \n64. Ozcan, E.; Misir, M.; Kheiri, A. “Group decision making hyper-heuristics\
    \ for function \noptimisation,” In Proceedings of 13th UK Workshop on Computational\
    \ Intelligence (UKCI), \nGuildford, ENGLAND, Sep. 09-11, 2013. \n65. Lenka, S.K.;\
    \ Mohapatra A.G. “Gradient descent with momentum based neural network pattern\
    \ \nclassification for the prediction of soil moisture content in precision agriculture,”\
    \ In Proceedings \nof IEEE International Symposium on Nanoelectronic and Information\
    \ Systems, Indore, INDIA, \nDec. 21-23, 2015. \n66. Georgiou, P.E.; Papamichail,\
    \ D.M. “Optimization model of an irrigation reservoir for water \nallocation and\
    \ crop planning under various weather conditions,” Irrigation Science, vol. 26,\
    \ no. 6, \npp. 487-504, Sept. 2008. https://doi.org/10.1007/s00271-008-0110-7.\
    \ \n67. Manimuthu, A.; Le, A.V.; Mohan, R.E.; Veerajagadeshwar, P.; Nhan, N.H.K.;\
    \ Cheng, K.P. \n“Energy consumption estimation model for complete coverage of\
    \ a Tetromino inspired \nreconfigurable \nsurface \ntiling \nrobot,” \nEnergies,\
    \ \nvol. \n12, \nno. \n12, \nJun. \n2019. \nhttps://doi.org/10.3390/en12122257.\
    \ \n68. Pornprakun, W.; Sungnul, S.; Kiataramkul, C.; Moore, E.J. “Determining\
    \ optimal policies for \nsugarcane harvesting in Thailand using bi-objective and\
    \ quasi-Newton optimization methods,” \nAdvances in Difference Equations, Jun.\
    \ 2019. https://doi.org/10.1186/s13662-019-2192-3. \n69. Goit, J.P.; Munters,\
    \ W.; Meyers, J. “Optimal coordinated control of power extraction in LES of a\
    \ \nwind \nfarm \nwith \nentrance \neffects,” \nEnergies, \nvol. \n9, \nno. \n\
    1, \nJan. \n2016. \nhttps://doi.org/10.3390/en9010029. \n \n185 \n \n70. Brown,\
    \ P.D.; Cochrane, T.A.; Krom, T.D. “Optimal on-farm irrigation scheduling with\
    \ a seasonal \nwater limit using simulated annealing,” Agricultural Water Management,\
    \ vol. 97, no. 6, pp. 892-\n900, Jun. 2010. https://doi.org/10.1016/j.agwat.2010.01.020.\
    \ \n71. Borge, P.J.; Fragoso, R.; Garcia-Gonzalo, J.; Borges, J.G.; Marques, S.;\
    \ Lucas, M.R. “Assessing \nimpacts of common agricultural policy changes on regional\
    \ land use patterns with a decision \nsupport system: An application in southern\
    \ Portugal,” Forest Policy and Economics, vol. 12, no. \n2, pp. 111-120, Feb.\
    \ 2010. https://doi.org/10.1016/j.forpol.2009.09.002. \n72. Kong, Q.Y.; Kuriyan,\
    \ K.; Shah, N.; Guo, M. “Development of a responsive optimisation \nframework\
    \ for decision-making in precision agriculture,” Computers & Chemical Engineering,\
    \ \nvol. 131, Dec. 2019. https://doi.org/10.1016/j.compchemeng.2019.106585. \n\
    73. Muleta, M.K.; Nicklow, J.W. “Decision support for watershed management using\
    \ evolutionary \nalgorithms,” Journal of Water Resources Planning and Management,\
    \ vol. 131, no. 1, pp. 35-44, \nFeb. 2005. https://doi.org/10.1061/(ASCE)0733-9496(2005)131:1(35).\
    \ \n74. Chaudhuri, S.; Goswami, S.; Das, D.; Middey, A. “Meta-heuristic ant colony\
    \ optimization \ntechnique to forecast the amount of summer monsoon rainfall:\
    \ Skill comparison with Markov chain \nmodel,” Theoretical and Applied Climatology,\
    \ vol. 116, no. 3-4, pp. 585-595, May 2014. \nhttps://doi.org/10.1007/s00704-013-0977-y.\
    \ \n75. Sung, W.T.; Chung, H.Y.; Chang, K.Y. “Agricultural monitoring system based\
    \ on ant colony \nalgorithm with centre data aggregation,” IET Communications,\
    \ vol. 8, no. 7, pp. 1132-1140, May \n2014. https://doi.org/10.1049/iet-com.2013.0995.\
    \ \n76. Fereidoon, M.; Koch, M. “SWAT-MODSIM-PSO optimization of multi-crop planning\
    \ in the \nKarkheh River Basin, Iran, under the impacts of climate change,” Science\
    \ of The Total \nEnvironment, vol. 630, pp. 502-516, Jul. 2018. https://doi.org/10.1016/j.scitotenv.2018.02.234.\
    \ \n77. Barak, S.; Yousefi, M.; Maghsoudlou, H.; Jahangiri, S. “Energy and GHG\
    \ emissions management \nof agricultural systems using multi objective particle\
    \ swarm optimization algorithm: A case study,” \nStochastic Environmental Research\
    \ and Risk Assessment, vol. 30, no. 4, pp. 1167-1187, Apr. 2016. \nhttps://doi.org/10.1007/s00477-015-1098-1.\
    \ \n78. Garcia-Vila, M.; Fereres, E. “Combining the simulation crop model AquaCrop\
    \ with an economic \nmodel for the optimization of irrigation management at farm\
    \ level,” European Journal of \nAgronomy, vol. 36, no. 1, pp. 21-31, Jan. 2012.\
    \ https://doi.org/10.1016/j.eja.2011.08.003. \n79. Navarro-Hellin, H.; Martinez-del-Rincon,\
    \ J.; Domingo-Miguel, R.; Soto-Valles, F.; Torres-\nSanchez, R. “A decision support\
    \ system for managing irrigation in agriculture,” Computers and \nElectronics\
    \ \nin \nAgriculture, \nvol. \n124, \npp. \n121-131, \nJun. \n2016. \nhttps://doi.org/10.1016/j.compag.2016.04.003.\
    \ \n \n186 \n \n80. Zhang, F.L.; Johnson, D.; Johnson, M.; Watkins, D.; Froese,\
    \ R.; Wang, J.J.; “Decision support \nsystem integrating GIS with simulation and\
    \ optimisation for a biofuel supply chain,” Renewable \nEnergy, vol. 85, pp. 740-748,\
    \ Jan. 2016. https://doi.org/10.1016/j.renene.2015.07.041. \n81. Groot. J.C.J.;\
    \ Oomen, G.J.M.; Rossing, W.A.H. “Multi-objective optimization and design of \n\
    farming \nsystems,” \nAgricultural \nSystems, \nvol. \n110, \npp. \n63-77, \n\
    Jul. \n2012. \nhttps://doi.org/10.1016/j.agsy.2012.03.012. \n82. Bravo, M.; Gonzalez,\
    \ I. “Applying stochastic goal programming: A case study on water use \nplanning,”\
    \ European Journal of Operational Research, vol. 196, no. 3, pp. 1123-1129, Aug.\
    \ 2009. \nhttps://doi.org/10.1016/j.ejor.2008.04.034. \n83. Memmah, M.M.; Lescourret,\
    \ F.; Yao, X.; Lavigne, C. “Metaheuristics for agricultural land use \noptimization.\
    \ A review,” Agronomy for Sustainable Development, vol. 35, no. 3, pp. 975-998,\
    \ Jul. \n2015. https://doi.org/10.1007/s13593-015-0303-4. \n84. Hu, J.; Mehrotra,\
    \ S. “Robust and stochastically weighted multiobjective optimization models and\
    \ \nreformulations,” Operations Research, vol. 60, no. 4, pp. 936-953, Aug. 2012.\
    \ \nhttps://doi.org/10.1287/opre.1120.1071. \n85. Galan-Martin, A.; Vaskan, P.;\
    \ Anton, A.; Esteller, L.J.; Guillen-Gosalbez, G. “Multi-objective \noptimization\
    \ of rainfed and irrigated agricultural areas considering production and environmental\
    \ \ncriteria: A case study of wheat production in Spain,” Journal of Cleaner Production,\
    \ vol. 140, pp. \n816-830, Jan. 2017. https://doi.org/10.1016/j.jclepro.2016.06.099.\
    \ \n86. Zhang, X.D.; Huang, G.H.; Nie, X.H. “Optimal decision schemes for agricultural\
    \ water quality \nmanagement planning with imprecise objective,” Agricultural\
    \ Water Management, vol. 96, no. 12, \npp. 1723-1731, Dec. 2009. https://doi.org/10.1016/j.agwat.2009.07.011.\
    \ \n87. Das, B.; Singh, A.; Panda, S.N. “Optimal land and water resources allocation\
    \ policies for \nsustainable irrigated agriculture,” Land Use Policy, vol. 42,\
    \ pp. 527-537, Jan. 2015. \nhttps://doi.org/10.1016/j.landusepol.2014.09.012.\
    \ \n88. Schutze, N.; Schmitz, G.H. “OCCASION: New planning tool for optimal climate\
    \ change adaption \nstrategies in irrigation,” Journal of Irrigation and Drainage\
    \ Engineering, vol. 136, no. 12, pp. 836-\n846, Dec. 2010. https://doi.org/10.1061/(ASCE)IR.1943-4774.0000266.\
    \ \n89. Meyer, B.C.; Lescot, J.M.; Laplana, R. “Comparison of two spatial optimization\
    \ techniques: A \nframework to solve multiobjective land use distribution problems,”\
    \ Environmental Management, \nvol. 43, no. 2, pp. 264-281, Feb. 2009. https://doi.org/10.1007/s00267-008-9225-0.\
    \ \n90. Aiello, G.; Giovino, I.; Vallone, M.; Catania, P.; Argento, A. “A decision\
    \ support system based on \nmultisensor data fusion for sustainable greenhouse\
    \ management,” Journal of Cleaner Production, \nvol. 173, pp. 4057-4065, Jan.\
    \ 2018. https://doi.org/10.1016/j.jclepro.2017.02.197. \n \n187 \n \n91. Bazzani,\
    \ G.M. “A decision support for an integrated multi-scale analysis of irrigation:\
    \ DSIRR,” \nJournal of Environmental Management, vol. 77, no. 4, pp. 301-314,\
    \ Dec. 2005. \nhttps://doi.org/10.1016/j.jenvman.2005.09.001. \n92. Nouiri, I.;\
    \ Yitayew, M.; Massmann, J. Tarhouni, J. “Multi-objective optimization tool for\
    \ \nintegrated groundwater management,” Water Resources Management, vol. 29, no.\
    \ 14, pp. 5353-\n5375, Nov. 2015. https://doi.org/10.1007/s11269-015-1122-8. \n\
    93. Garcia, I.F.; Montesinos, P.; Poyato, E.C.; Diaz, J.A.R. “Energy cost optimization\
    \ in pressurized \nirrigation \nnetworks,” \nIrrigation \nScience, \nvol. \n34,\
    \ \nno. \n1, \npp. \n1-13, \nJan. \n2016. \nhttps://doi.org/10.1007/s00271-015-0475-3.\
    \ \n94. Osaki, M.; Baatalha, M.O. “Optimization model of agricultural production\
    \ system in grain farms \nunder risk, in Sorriso, Brazil,” Agricultural Systems,\
    \ vol. 127, pp. 178-188, May 2014. \nhttps://doi.org/10.1016/j.agsy.2014.02.002.\
    \ \n95. Singh, A.; Panda, S.N.; Saxena, C.K.; Verma, C.L.; Uzokwe, V.N.E.; Krause,\
    \ P.; Gupta, S.K. \n“Optimization modeling for conjunctive use planning of surface\
    \ water and groundwater for \nirrigation,” Journal of Irrigation and Drainage\
    \ Engineering, vol. 142, no. 3, Mar. 2016. \nhttps://doi.org/10.1061/(ASCE)IR.1943-4774.0000977.\
    \ \n96. Verity, J.W. “Automated reasoning – Introduction and applications,” Datamation,\
    \ vol. 30, no. 18, \npp. 163, Jan. 1984. \n97. Watson, I.; Marir, F. “Case-based\
    \ reasoning – A review,” Knowledge Engineering Review, vol. 9, \nno. 4, pp. 327-354,\
    \ Dec. 1994. https://doi.org/10.1017/S0269888900007098. \n98. Hadzistevic, M.;\
    \ Matin, I.; Hodolic, J.; Vukelic, D.; Vukmirovic, S.; Godec, D.; Nedic, B. “Rule\
    \ \nbased reasoning in the knowledge-based mould design system,” Tehnicki Vjesnik-Technical\
    \ \nGazette, vol. 21, no. 5, pp. 1143-1148, Oct. 2014. \n99. Ruspini, E.H. “Conceptual\
    \ and methodological issues in evidential reasoning,” In Proceedings of \nConference\
    \ on Signal Processing, Sensor Fusion, and Target Recognition XVI, Orlando, FL,\
    \ USA, \nApr. 09-11, 2007. \n100. Rong, L.B.; Li, D.L. “DCDDS: A dairy cow disease\
    \ diagnosis system for dairy farm in China,” In \nProceedings of 4th International\
    \ Symposium on Intelligent Information Technology in Agriculture, \nBeijing, PEOPLES\
    \ R CHINA, Oct. 26-29, 2007. \n101. Car, N.J.; Moore, G.A. “Bridging the gap between\
    \ modelling advice and irrigator solutions through \nempirical reasoning techniques,”\
    \ In Proceedings of MSSANZ 19th Biennial Congress on Modelling \nand Simulation\
    \ (MODSIM), Perth, AUSTRALIA, Dec. 12-16, 2011. \n102. Padma, T.; Mir, S.A.; Shantharajah,\
    \ S.P. “Intelligent decision support system for an integrated pest \nmanagement\
    \ in apple orchard,” Studies in Computational Intelligence, vol. 705, pp. 225-245,\
    \ 2017. \nhttps://doi.org/10.1007/978-3-319-53153-3_12. \n \n188 \n \n103. Zhu,\
    \ C.L.; Yin, G.F. “A prediction method of crop diseases and insect pests based\
    \ on ontological \ncase reasoning,” Revista de La Facultad de Agronomia de La\
    \ Universidad del Zulia, vol. 36, no. \n6, pp. 1720-1731, Sept. 2019. \n104. Musto,\
    \ C.; Semeraro, G.; Lops, P.; de Gemmis, M.; Lekkas, G. “Personalized finance\
    \ advisory \nthrough case-based recommender systems and diversification strategies,”\
    \ Decision Support \nSystems, vol. 77, pp. 100-111, Sept. 2015. https://doi.org/10.1016/j.dss.2015.06.001.\
    \ \n105. Park, C.S.; Han, I. “A case-based reasoning with the feature weights\
    \ derived by analytic hierarchy \nprocess for bankruptcy prediction,” Expert Systems\
    \ with Applications, vol. 23, no. 3, pp. 255-264, \nOct. 2002. https://doi.org/10.1016/S0957-4174(02)00045-3.\
    \ \n106. Begum, S.; Ahmed, M.U.; Funk, P.; Xiong, N.; Folke, M. “Case-based reasoning\
    \ systems in the \nhealth sciences: A survey of recent trends and developments,”\
    \ IEEE Transactions on Systems Man \nand Cybernetics Part C – Applications and\
    \ Reviews, vol. 41, no. 4, pp. 421-434, Jul. 2011. \nhttps://doi.org/10.1109/TSMCC.2010.2071862.\
    \ \n107. Fan, C.Y.; Chang, P.C.; Lin, J.J.; Hsieh, J.C. “A hybrid model combining\
    \ case-based reasoning \nand fuzzy decision tree for medical data classification,”\
    \ Applied Soft Computing, vol. 11, no. 1, pp. \n632-644, Jan. 2011. https://doi.org/10.1016/j.asoc.2009.12.023.\
    \ \n108. Amailef, K.; Lu, J. “Ontology-supported case-based reasoning approach\
    \ for intelligent m-\nGovernment emergency response services,” Decision Support\
    \ Systems, vol. 55, no. 1, pp. 79-97, \nApr. 2013. https://doi.org/10.1016/j.dss.2012.12.034.\
    \ \n109. Fan, Z.P.; Li, Y.H.; Wang, X.H.; Liu, Y. “Hybrid similarity measure for\
    \ case retrieval in CBR and \nits application to emergency response towards gas\
    \ explosion,” Expert Systems with Applications, \nvol. 41, no. 5, pp. 2526-2534,\
    \ Apr. 2014. https://doi.org/10.1016/j.eswa.2013.09.051. \n110. Shokouhi, S.V.;\
    \ Skalle, P.; Aamodt, A. “An overview of case-based reasoning applications in\
    \ \ndrilling engineering,” Artificial Intelligence Review, vol. 41, no. 3, pp.\
    \ 317-329, Mar. 2014. \nhttps://doi.org/10.1007/s10462-011-9310-2. \n111. Lao,\
    \ S.I.; Choy, K.L.; Ho, G.T.S.; Yam, R.C.M.; Tsim, Y.C.; Poon, T.C. “Achieving\
    \ quality \nassurance functionality in the food industry using a hybrid case-based\
    \ reasoning and fuzzy logic \napproach,” Expert Systems with Applications, vol.\
    \ 39, no. 5, pp. 5251-5261, Arp. 2012. \nhttps://doi.org/10.1016/j.eswa.2011.11.014.\
    \ \n112. Balleda, K.; Satyanvesh, D.; Sampath, N.V.S.S.P.; Varma, K.T.N.; Baruah,\
    \ P.K. “Agpest: An \nefficient rule-based expert system to prevent pest diseases\
    \ of rice & wheat crops,” In Proceedings \nof 8th IEEE International Conference\
    \ on Intelligent Systems and Control, Coimbatore, INDIA, Jan. \n10-11, 2014. \n\
    113. Naseem, J.; Burney, S.M.A.; Mehmood, N. “An efficient rule based decision\
    \ support system using \nsemantic web technology,” International Journal of Advanced\
    \ Computer Science and \nApplications, vol. 9, no. 12, pp. 346-350, Dec. 2018.\
    \ \n \n189 \n \n114. Han, Q. “Development and application of remote intelligent\
    \ diagnosis mobile phone system for \nanimal diseases,” Revista Cientifica-Facultad\
    \ de Ciencias Veterinarias, vol. 29, no. 2, pp. 393-\n401, Apr. 2019. \n115. Katsiri,\
    \ E.; Makropoulos, C. “An ontology framework for decentralized water management\
    \ and \nanalytics using wireless sensor networks,” In Proceedings of 14th International\
    \ Conference on \nEnvironmental Science and Technology (CEST), Rhodes, GREECE,\
    \ Sept. 03-05, 2015. \n116. Lee, G.H. “Rule-based and case-based reasoning approach\
    \ of internal audit of bank,” Knowledge-\nBased \nSystems, \nvol. \n21, \nno.\
    \ \n2, \npp. \n140-147, \nMar. \n2008. \nhttps://doi.org/10.1016/j.knosys.2007.04.001.\
    \ \n117. Zeydan, M.; Kayserili, S. “A rule-based decision support approach for\
    \ site selection of automated \nteller machines (ATMs),” Intelligent decision\
    \ technologies–Netherlands, vol. 13, no. 2, pp. 161-\n175, May 2019. https://doi.org/10.3233/IDT-180084.\
    \ \n118. Yuan, B.C.; Herbert, J. “Context-aware hybrid reasoning framework for\
    \ pervasive healthcare,” \nPersonal and Ubiquitous Computing, vol. 18, no. 4,\
    \ pp. 865-881, Apr. 2014. \nhttps://doi.org/10.1007/s00779-013-0696-5. \n119.\
    \ Yin, Z.M.; Min, L.T.; Lu, X.D.; Duan, H.L. “A clinical decision support system\
    \ for primary \nheadache disorder based on hybrid intelligent reasoning,” in Proceedings\
    \ of 7th International \nConference on Biomedical Engineering and Informatics\
    \ (BMEI), Dalian, PEOPLES R CHINA, \nOct. 14-16, 2014. \n120. Soufi, M.D.; Samad-Soltani,\
    \ T.; Vandati, S.S.; Rezaei-Hachesu, P. “Decision support system for \ntriage\
    \ management: A hybrid approach using rule-based reasoning and fuzzy logic,” International\
    \ \nJournal \nof \nMedical \nInformatics, \nvol. \n114, \npp. \n35-44, \nJun.\
    \ \n2018. \nhttps://doi.org/10.1016/j.ijmedinf.2018.03.008. \n121. Shan, S.Q.;\
    \ Shi, J.H.; Ren, J.; Hu, Z.J. “Rule-based study on the fault diagnosis algorithm\
    \ of \nemergency response process,” In Proceedings of 12th International Conference\
    \ on Industrial \nManagement (ICIM2014), Chengdu, PEOPLES R CHINA, Sept. 03-05,\
    \ 2014. \n122. Azadeh, A.; Ebrahimipour, V. “A fuzzy inference system for pump\
    \ failure diagnosis to improve \nmaintenance process: The case of a petrochemical\
    \ industry,” Expert Systems with Applications, \nvol. 37, no. 1, pp. 627-639,\
    \ Jan. 2010. https://doi.org/10.1016/j.eswa.2009.06.018. \n123. Iqbal, A.; Zhang,\
    \ H.C.; Kong, L.L.; Hussain, G. “A rule-based system for trade-off among energy\
    \ \nconsumption, tool life, and productivity in machining process,” Journal of\
    \ Intelligent \nManufacturing, vol. 26, no. 6, pp. 1217-1232, Dec. 2015. https://doi.org/\
    \ 10.1007/s10845-013-\n0851-x. \n124. Sun, W.X.; Liang, S.L.; Xu, G.; Fang, H.L.;\
    \ Dickinson, R. “Mapping plant functional types from \nMODIS data using multisource\
    \ evidential reasoning,” Remote Sensing of Environment, vol. 112, \nno. 3, pp.\
    \ 1010-1024, Mar. 2008. https://doi.org/10.1016/j.rse.2007.07.022. \n \n190 \n\
    \ \n125. Cohen, Y.; Shoshany, M. “Analysis of convergent evidence in an evidential\
    \ reasoning knowledge-\nbased classification,” Remote Sensing of Environment,\
    \ vol. 96, no. 3-4, pp. 518-528, Jun. 2005. \nhttps://doi.org/10.1016/j.rse.2005.04.009.\
    \ \n126. Jiang, D.; Wu, B.; Yang, X.F.; Van Gelder, P.H.A.J.M. “A fuzzy evidential\
    \ reasoning based \napproach for submarine power cable routing selection for offshore\
    \ wind farms,” Ocean \nEngineering, vol. 193, Dec. 2019. https://doi.org/10.1016/j.oceaneng.2019.106616.\
    \ \n127. Sanz, C. “DER (Dynamic evidential reasoning), applied to the classification\
    \ of hyperspectral \nimages,” In Proceedings of IEEE International Geoscience\
    \ and Remote Sensing Symposium, \nSydney, AUSTRALIA, Jul. 09-13, 2001. \n128.\
    \ Chin, K.S.; Wang, Y.M.; Yang, J.B.; Poon, K.K.G. “An evidential reasoning based\
    \ approach for \nquality function deployment under uncertainty,” Expert Systems\
    \ with Applications, vol. 36, no. 3, \npp. 5684-5694, Apr. 2009. https://doi.org/10.1016/j.eswa.2008.06.104.\
    \ \n129. Eshghi, A.; Kargari, M. “Introducing a new method for the fusion of fraud\
    \ evidence in banking \ntransactions with regards to uncertainty,” Expert Systems\
    \ with Applications, vol. 121, pp. 382-392, \nMay 2019. https://doi.org/10.1016/j.eswa.2018.11.039.\
    \ \n130. Kong, G.L.; Xu, D.L.; Yang, J.B.; Ma, X.M. “Combined medical quality\
    \ assessment using the \nevidential reasoning approach,” Expert Systems with Applications,\
    \ vol. 42, no. 13, pp. 5522-5530, \nAug. 2015. https://doi.org/10.1016/j.eswa.2015.03.009.\
    \ \n131. Kong, G.L.; Jiang, L.L.; Yin, X.F.; Wang, T.B.; Xu, D.L.; Yang, J.B.;\
    \ Hu, Y.H. “Combining \nprincipal component analysis and the evidential reasoning\
    \ approach for healthcare quality \nassessment,” Annals of Operations Research,\
    \ vol. 271, no. 2, pp. 679-699, Dec. 2018. \nhttps://doi.org/10.1007/s10479-018-2789-z.\
    \ \n132. Wang, H.Y.; Ren, J.; Yang, J.Q.; Wang, J. “Evaluating the effectiveness\
    \ of ERS for vessel oil spills \nusing fuzzy evidential reasoning,” Ocean Systems\
    \ Engineering – An International Journal, vol. 5, \nno. 3, pp. 161-179, Sept.\
    \ 2015. https://doi.org/10.12989/ose.2015.5.3.161. \n133. Wu, B.; Zong, L.K.;\
    \ Yan, X.P.; Soares, C.G. “Incorporating evidential reasoning and TOPSIS into\
    \ \ngroup decision-making under certainty for handling ship without command,”\
    \ Ocean Engineering, \nvol. 164, pp. 590-603, Sept. 2018. https://doi.org/10.1016/j.oceaneng.2018.06.054.\
    \ \n134. Liu, H.C.; Lin, Q.L.; Ren, M.L. “Fault diagnosis and cause analysis using\
    \ fuzzy evidential \nreasoning approach and dynamic adaptive fuzzy Petri nets,”\
    \ Computers & Industrial Engineering, \nvol. 66, no. 4, pp. 899-908, Dec. 2013.\
    \ https://doi.org/10.1016/j.cie.2013.09.004. \n135. Zhou, Z.X.; Dou, Y.J.; Sun,\
    \ J.B.; Jiang, J.; Tan, Y.J. “Sustainable production line evaluation based \n\
    on \nevidential \nreasoning,” \nSustainability, \nvol. \n9, \nno. \n10, \nOct.\
    \ \n2017. \nhttps://doi.org/10.3390/su9101811. \n136. Kastner, J.K.; Hong, S.J.\
    \ “A review of expert systems,” European Journal of Operational \nResearch, vol.\
    \ 18, no. 3, pp. 285-292, Dec. 1984. https://doi.org/10.1016/0377-2217(84)90150-4.\
    \ \n \n191 \n \n137. Song, K.H.; De Jonckheere, J.; Zeng, X.Y.; Koehl, L.; Yuan,\
    \ X.J.; Zhao, X. “Development of a \ndata-based interactive medical expert system\
    \ for supporting pregnancy consultations: General \narchitecture and methodology,”\
    \ In Proceedings of 14th International-Federation-of-Automatic-\nControl (IFAC)\
    \ Symposium on Analysis, Design, and Evaluation of Human Machine Systems \n(HMS),\
    \ Tallinn, ESTONIA, Sept. 16-19, 2019. \n138. Ford, F.N. “Decision support systems\
    \ and expert systems – A comparison,” Information & \nManagement, vol. 8, no.\
    \ 1, pp. 21-26, Jan. 1985. \n139. Connell, N.A.D.; Powell, P.L. “A comparison\
    \ of potential applications of expert systems and \ndecision support systems,”\
    \ Journal of The Operational Research Society, vol. 41, no. 5, pp. 431-\n439,\
    \ May 1990. \n140. Marling, C.; Montani, S.; Bichindaritz, I. “Synergistic case-based\
    \ reasoning in medical domains,” \nExpert \nSystems \nwith \nApplications, \n\
    vol. \n41, \nno. \n2, \npp. \n249-259, \nFeb. \n2014. \nhttps://doi.org/10.1016/j.eswa.2013.05.063.\
    \ \n141. Aamodt, A.; Plaza, E. “Case-based reasoning – Foundational issues, methodological\
    \ variations, \nand system approaches,” AI Communications, vol. 7, no. 1, pp.\
    \ 39-59, Mar. 1994. \n142. Cheng, Z.H.; Chen, L.; Jia, X.S.; Zeng, H.Y. “Case\
    \ representation and retrieval in the intelligent \nRCM analysis system,” In Proceedings\
    \ of Conference on Electronic Commerce, Web Application \nand Communication, Wuhan,\
    \ PEOPLE R CHINA, Mar. 17-18, 2012. \n143. Bergmann, R.; Kolodner, J.; Plaza,\
    \ E. “Representation in case-based reasoning,” Knowledge \nEngineering \nReview,\
    \ \nvol. \n20, \nno. \n3, \npp. \n209-213, \nSept. \n2005. \nhttps://doi.org/10.1017/S0269888906000555.\
    \ \n144. Chen, J.G.; Chen, Y.Z. “Research on operation standard expert system\
    \ based on ontology and \nCBR,” In Proceedings of 18th International Conference\
    \ on Industrial Engineering and Engineering \nManagement, ChangChun, PEOPLES R\
    \ CHINA, Sept. 03-05, 2011. \n145. Abidi, S.S.R.; Manickam, S. “Leveraging XML-based\
    \ electronic medical records to extract \nexperiential clinical knowledge – An\
    \ automated approach to generate cases for medical case-based \nreasoning systems,”\
    \ International Journal of Medical Informatics, vol. 68, no. 1-3, pp. 187-203,\
    \ \nDec. 2002. https://doi.org/10.1016/S1386-5056(02)00076-X. \n146. Dufour-Lussier,\
    \ V.; Le Ber, F.; Lieber, J.; Nauer, E. “Automatic case acquisition from texts\
    \ for \nprocess-oriented case-based reasoning,” Information Systems, vol. 40,\
    \ pp. 153-167, Mar. 2014. \nhttps://doi.org/10.1016/j.is.2012.11.014. \n147. Asadi,\
    \ N.; Lin, J. “Document vector representations for feature extraction in multi-stage\
    \ document \nranking,” \nInformation \nRetrieval, \nvol. \n16, \nno. \n6, \npp.\
    \ \n747-768, \nDec. \n2013. \nhttps://doi.org/10.1007/s10791-012-9217-9. \n148.\
    \ Bringer, J.; Despiegel, V.; Favre, M. “Adding localization information in a\
    \ fingerprint binary \nfeature vector representation,” In Proceedings of Conference\
    \ on Sensing Technologies for Global \n \n192 \n \nHealth, Military Medicine,\
    \ Disaster Response, and Environmental Monitoring and Biometric \nTechnology for\
    \ Human Identification VIII, Orlando, FL, USA, Apr. 25-27, 2011. \n149. Svanberg,\
    \ M. “Using feature vector representations to identify similar projects in App\
    \ Inventor,” \nIn Proceedings of IEEE Blocks and Beyond Workshop (B&B), Raleigh,\
    \ NC, USA, Oct. 09-10, \n2017. \n150. Yagi, M.; Shibata, T.; Tanikawa, C.; Takada,\
    \ K. “A robust medical image recognition system \nemploying edge-based feature\
    \ vector representation,” In Proceedings of 13th Scandinavian \nConference on\
    \ Image Analysis (SCIA 2003), Halmstad, SWEDEN, Jun. 29-Jul. 02, 2003. \n151.\
    \ Dileep, K.V.S.; Chakraborti, S. “Eager to be lazy: Towards a complexity-guided\
    \ textual case-based \nreasoning system,” In Proceedings of 24th International\
    \ Conference on Case-Based reasoning \nResearch and Development (ICCBR), Atlanta,\
    \ GA, USA, Oct. 31-Nov. 02, 2016. \n152. Weber, R.O.; Ashley, K.D.; Bruninghaus,\
    \ S. “Textual case-based reasoning,” Knowledge \nEngineering \nReview, \nvol.\
    \ \n20, \nno. \n3, \npp. \n255-260, \nSept. \n2005. \nhttps://doi.org/10.1017/S0269888906000713.\
    \ \n153. Bruninghaus, S.; Ashley, K.D. “The role of information extraction for\
    \ textual CBR,” In \nProceedings of 4th International Conference on Case-Based\
    \ Reasoning (ICCBR 2001), Vancouver, \nCANADA, Jul. 30-Aug. 02, 2001. \n154. Ozturk,\
    \ P. Prasath, R. “Recognition of higher-order relations among features in textual\
    \ cases using \nrandom indexing,” In Proceedings of 18th International Conference\
    \ on Case-Based Reasoning, \nAlessandria, ITALY, Jul. 19-22, 2010. \n155. Chan,\
    \ S.W.K. “Extraction of salient textual patterns: Synergy between lexical cohesion\
    \ and \ncontextual coherence,” IEEE Transactions on Systems Man and Cybernetics\
    \ Part A – Systems and \nHumans, vol. 34, no. 2, pp. 205-218, Mar. 2004. https://doi.org/10.1109/TSMCA.2003.820570.\
    \ \n156. Cardenosa, J.; Gallardo, C.; Iraola, L. “UNL as a text content representation\
    \ language for \ninformation extraction,” In Proceedings of 7th International\
    \ Conference on Flexible Query \nAnswering Systems, Milan, ITALY, Jun. 07-10,\
    \ 2006. \n157. Angelova, G. “Use of domain knowledge in the automatic extraction\
    \ of structured representations \nfrom patient-related texts,” In Proceedings\
    \ of 18th International Conference on Conceptual \nStructures, Kuching, MALAYSIA,\
    \ Jul. 26-30, 2010. \n158. Cohen, W.W. “WHIRL: A word-based information representation\
    \ language,” Artificial \nIntelligence, vol. 119, no. 1-2, pp. 163-196, Apr. 2000.\
    \ https://doi.org/10.1016/S0004-\n3702(99)00102-2. \n159. Chan, S.W.K. “Beyond\
    \ keyword and cue-phrase matching: A sentence-based abstraction technique \nfor\
    \ information extraction,” Decision Support Systems, vol. 42, no. 2, pp. 759-777,\
    \ Nov. 2006. \nhttps://doi.org/10.1016/j.dss.2004.11.017. \n \n193 \n \n160. Buranasing,\
    \ W.; Phoomvuthisarn, S. “Information extraction for cultural heritage knowledge\
    \ \nacquisition using word vector representation,” In Proceedings of 12th International\
    \ Conference on \nComplex, Intelligent, and Software Intensive Systems (CISIS),\
    \ Matsue, JAPAN, Jul. 04-06, 2018. \n161. Ye, Q.; Liu, J.; Yu, T. “The prediction\
    \ model of case-based reasoning about project evaluation of \nXiamen city,” In\
    \ Proceedings of 3rd International Conference on Civil Engineering and \nTransportation\
    \ (ICCET 2013), Kunming, PEOPLES R CHINA, Dec. 14-15, 2013. \n162. Zeltmate, I.;\
    \ Grundspenkis, J. “An extension of frame-based knowledge representation schema,”\
    \ \nIn Proceedings of International Multi-Conference on Complexity, Informatics\
    \ and Cybernetics, \nOrlando, FL, USA, Apr. 06-09, 2010. \n163. Yao, L.; Chen,\
    \ Z.C.; Yang, J.J. “Research on risk assessment of ship repair based on case-based\
    \ \nreasoning,” In Proceedings of 8th International Conference on Intelligent\
    \ Systems and Knowledge \nEngineering (ISKE), Shenzhen, PEOPLES R CHINA, Nov.\
    \ 20-23, 2013. \n164. Mohamed, H.; Sulaiman, S.; Sabudin, M. “A hybrid of rule\
    \ and frame based approach in solving \nHajj complex problems,” In Proceedings\
    \ of International Conference of Soft Computing and \nPattern Recognition, Malacca,\
    \ MALAYSIA, Dec. 04-07, 2009. \n165. Su, Y.K.; Yang, S.J.; Liu, K.N.; Hua, K.C.;\
    \ Yao, Q. “Developing a case-based reasoning model \nfor safety accident pre-control\
    \ and decision making in the construction industry,” International \nJournal of\
    \ Environmental Research and Public Health, vol. 16, no. 9, May 2019. \nhttps://doi.org/10.3390/ijerph16091511.\
    \ \n166. Sorenson, D.; Grissom, C.K.; Carpenter, L.; Austin, A.; Sward, K.; Napoli,\
    \ L.; Warner, H.R.; \nMorris, A.H. “A frame-based representation for a bedside\
    \ ventilator weaning protocol,” Journal \nof \nBiomedical \nInformatics, \nvol.\
    \ \n41, \nno. \n3, \npp. \n461-468, \nJun. \n2008. \nhttps://doi.org/10.1016/j.jbi.2008.02.002.\
    \ \n167. Donini, F.M.; Lenzerini, M.; Nardi, D.; Nutt, W.; Schaerf, A. “An epistemic\
    \ operator for \ndescription logics,” Artificial Intelligence, vol. 100, no. 1-2,\
    \ pp. 225-274, Apr. 1998. \nhttps://doi.org/10.1016/S0004-3702(98)00009-5. \n\
    168. Cornet, R.; Abu-Hanna, A. “Using description logics for managing medical\
    \ terminologies,” In \nProceedings of 9th Conference on Artificial Intelligence\
    \ in Medicine in Europe, Protaras, CYPRUS, \nOct. 18-22, 2003. \n169. Quan, Q.;\
    \ Rui, Z.; Hong-Yi, C. “Object-oriented case representation and its application\
    \ in IDS,” \nIn Proceedings of 8th IEEE/ACIS International Conference on Computer\
    \ and Information Science, \nShanghai, PEOPLES R CHINA, Jun. 01-03, 2009. \n170.\
    \ Object-oriented \nrepresentation. \nAvailable: \nhttps://web.stanford.edu/class/cs227/Lectures/lec02.pdf.\
    \ \n \n194 \n \n171. Khan, A.A.; Chaudhry, I.A. “Object oriented case representation\
    \ for CBR application in structural \nanalysis,” Applied Artificial Intelligence,\
    \ vol. 29, no. 4, pp. 335-352, Apr. 2015. \nhttps://doi.org/10.1080/08839514.2015.1016390.\
    \ \n172. Marefat, M.; Britanik, J. “Case-based process planning using an object-oriented\
    \ model \nrepresentation,” Robotics and Computer-Integrated Manufacturing, vol.\
    \ 13, no. 3, pp. 229-251, \nSept. 1997. https://doi.org/10.1016/S0736-5845(97)00005-7.\
    \ \n173. Chen, C.W.; Lee, J.K. “Case study: An infrastructure for C/ATLAS environments\
    \ with object-\noriented design and XML representation,” Journal of Systems and\
    \ Software, vol. 71, no. 1-2, pp. \n83-95, Apr. 2004. https://doi.org/10.1016/S0164-1212(02)00151-6.\
    \ \n174. Chen, G.; Chen, J.; Zhao, Z.; Ruan, X.Y. “An object-oriented hierarchical\
    \ case representation of \nautomotive panels in a computer-aided process planning\
    \ system,” International Journal of \nAdvanced Manufacturing Technology, vol.\
    \ 26, no. 11-12, pp. 1323-1330, Nov. 2005. \nhttps://doi.org/10.1007/s00170-004-2105-8.\
    \ \n175. Dubitzky, W.; Bell, D.; Hughes, J. “A generic, object-oriented case-knowledge\
    \ representation \nscheme, and its integration into a wider information management\
    \ scenario,” Expert Systems, vol. \n13, no. 3, pp. 219-233, Aug. 1996. https://doi.org/10.1111/j.1468-0394.1996.tb00121.x.\
    \ \n176. Yeresime, S.; Pati, J.; Rath, S.K. “Review of software quality metrics\
    \ for object-oriented \nmethodology,” In Proceedings of 1st International Conference\
    \ on Internet Computing and \nInformation Communications (ICICIC), Chennai, INDIA,\
    \ Feb. 12-14, 2012. \n177. Mackie, R.I. “Object oriented programming for structural\
    \ mechanics: A review,” In Proceedings \nof 8th International Conference on Civil\
    \ and Structural Engineering Computing, Eisenstadt, \nAUSTRIA, Sept. 19-21, 2001.\
    \ \n178.  Avdeenko, T.V.; Makarova, E.S. “Knowledge representation model based\
    \ on case-based \nreasoning and the domain ontology: Application to the IT consultation,”\
    \ In Proceedings of 16th \nIFAC Symposium on Information Control Problems in Manufacturing\
    \ (INCOM), Bergamo, \nITALY, Jun. 11-13, 2018. \n179. Ding, Y.; Foo, S. “Ontology\
    \ research and development. Part I – A review of ontology generation,” \nJournal\
    \ \nof \nInformation \nScience, \nvol. \n28, \nno. \n2, \npp. \n123-136, \nApr.\
    \ \n2002. \nhttps://doi.org/10.1177/0165551024234020. \n180. Juarez, J.M.; Salort,\
    \ J.; Palma, J.; Marin, R. “Case representation ontology for case retrieval \n\
    systems in medical domains,” In Proceedings of IASTED International Conference\
    \ on Artificial \nIntelligence and Applications, Innsbruck, AUSTRIA, Feb. 12-14,\
    \ 2007. \n181. Castro, J.L.; Sanchez, J.M.; Zurita, J.M. “Simplifying case retrieval\
    \ in case-based reasoning using \nontologies,” In Proceedings of 9th IASTED International\
    \ Conference on Artificial Intelligence and \nSoft Computing, Benidorm, SPAIN,\
    \ Sept. 12-14, 2005. \n \n195 \n \n182. Xiong, C.C.; Wang, L.T.; Tao, X.; Deng,\
    \ Y. “E-government decision support system based on \ncase-based reasoning and\
    \ ontology,” In Proceedings of 12th International Conference on Fuzzy \nSystems\
    \ and Knowledge Discovery (FSKD), Zhangjiajie, PEOPLES R CHINA, Aug. 15-17, 2015.\
    \ \n183. El-Sappagh, S.; Elmogy, M. “A fuzzy ontology modeling for case base knowledge\
    \ in diabetes \nmellitus domain,” Engineering Science and Technology – An International\
    \ Journal – JESTECH, \nvol. 20, no. 3, pp. 1025-1040, Jun. 2017. https://doi.org/10.1016/j.jestch.2017.03.009.\
    \ \n184. Zhukova, I.; Kultsova, M.; Navrotsky, M.; Dvoryankin, A. “Intelligent\
    \ support for decision making \nin human resource management in using case-based\
    \ reasoning and ontology,” In Proceedings of \n11th Joint Conference on Knowledge-Based\
    \ Software Engineering (JCKBSE), Volgograd, \nRUSSIA, Sept. 17-20, 2014. \n185.\
    \ Liao, T.W.; Zhang, Z.M.; Mount, C.R. “Similarity measures for retrieval in case-based\
    \ reasoning \nsystems,” Applied Artificial Intelligence, vol. 12, no. 4, pp. 267-288,\
    \ Jun. 1998. \nhttps://doi.org/10.1080/088395198117730. \n186. Rachkovskij, D.A.\
    \ “Binary vectors for fast distance and similarity estimation,” Cybernetics and\
    \ \nSystems Analysis, vol. 53, no. 1, pp. 138-156, Jan. 2017. https://doi.org/10.1007/s10559-017-9914-\n\
    x. \n187. Elmore, K.L.; Richman, M.B. “Euclidean distance as a similarity metric\
    \ for principal component \nanalysis,” Monthly Weather Review, vol. 129, no. 3,\
    \ pp. 540-549, Mar. 2001. \nhttps://doi.org/10.1175/1520-0493(2001)129<0540:EDAASM>2.0.CO;2.\
    \ \n188. Jiang, W.; Wang, M.J.; Deng, X.Y.; Gou, L.F. “Fault diagnosis based on\
    \ TOPSIS method with \nManhattan distance,” Advances in Mechanical Engineering,\
    \ vol. 11, no. 3, Mar. 2019. \nhttps://doi.org/10.1177/1687814019833279. \n189.\
    \ Esmaeili-Najafabadi, H.; Ataei, M.; Sabahi, M.F. “Designing sequence with minimum\
    \ PSL using \nChebyshev distance and its application for chaotic MIMO radar waveform\
    \ design,” IEEE \nTransactions \non \nSignal \nProcessing, \nvol. \n65, \nno.\
    \ \n3, \npp. \n690-704, \nFeb. \n2017. \nhttps://doi.org/10.1109/TSP.2016.2621728.\
    \ \n190. Mustafa, A.A.Y. “A modified Hamming distance measure for quick detection\
    \ of dissimilar binary \nimages,” In Proceedings of International Conference on\
    \ Computer Vision and Image Analysis \nApplications (ICCVIA), Sousse, TUNISIA,\
    \ Jan. 18-20, 2015. \n191. Xia, P.P.; Zhang, L.; Li, F.Z. “Learning similarity\
    \ with cosine similarity ensemble,” Information \nSciences, vol. 307, pp. 39-52,\
    \ Jun. 2015. https://doi.org/10.1016/j.ins.2015.02.024. \n192. Hassanien, A.E.;\
    \ El-Bendary, N.; Sweidan, A.H.; Mohamed, A.; Hegazy, O.M. “Hybrid-biomarker \n\
    case-based reasoning system for water pollution assessment in Abou Hammad Sharkia,\
    \ Egypt,” \nApplied \nSoft \nComputing, \nvol. \n46, \npp. \n1043-1055, \nSept.\
    \ \n2016. \nhttps://doi.org/10.1016/j.asoc.2015.10.065. \n \n196 \n \n193. Senanayke,\
    \ S.M.N.A.; Malik, O.A.; Iskandar, P.M.; Zaheer, D. “A hybrid intelligent system\
    \ for \nrecovery and performance evaluation after anterior cruciate ligament injury,”\
    \ In Proceedings of \n12th International Conference on Intelligent Systems Design\
    \ and Applications (ISDA), Kochi, \nINDIA, Nov. 27-29, 2012. \n194. Rahman, M.M.;\
    \ Desai, B.C.; Bhattacharya, P. “Image retrieval-based decision support system\
    \ for \ndermatoscopic images,” In Proceedings of 19th IEEE Symposium on Computer-Based\
    \ Medical \nSystems, Salt Lake City, UT, USA, Jun. 22-23, 2006. \n195. Kwon, N.;\
    \ Lee, J.; Park, M.; Yoon, I.; Ahn, Y. “Performance evaluation of distance measurement\
    \ \nmethods for construction noise prediction using case-based reasoning,” Sustainability,\
    \ vol. 11, no. \n3, Feb. 2019. https://doi.org/10.3390/su11030871. \n196. Li,\
    \ H.; Sun, J. “Predicting business failure using multiple case-based reasoning\
    \ combined with \nsupport vector machine,” Expert Systems with Applications, vol.\
    \ 36, no. 6, pp. 10085-10096, Aug. \n2009. https://doi.org/10.1016/j.eswa.2009.01.013.\
    \ \n197. Ferreira, J.R.; Oliveira, M.C. “Evaluating margin sharpness analysis\
    \ on similarity pulmonary \nnodule retrieval,” In Proceedings of IEEE 28th International\
    \ Symposium on Computer-Based \nMedical Systems (CBMS), Sao Paulo, BRAZIL, Jun.\
    \ 22-25, 2015. \n198. Rashid, E. “Construction cost prediction on the basis of\
    \ multiple parameters using case-based \nreasoning method,” International Journal\
    \ of Services Technology and Management, vol. 23, no. \n4, pp. 255-261, Nov. 2017.\
    \ https://doi.org/10.1504/IJSTM.2017.10009179. \n199. Mousa, A.; Yusof, Y. “An\
    \ improved Chebyshev distance metric for clustering medical images,” \nIn Proceedings\
    \ of 2nd Innovation and Analytics Conference and Exhibition (IACE), Alor Setar,\
    \ \nMALASIA, Sept. 29-Oct. 01, 2015. \n200. Mustafa, A.A.Y. “Probabilistic binary\
    \ similarity distance for quick binary image matching,” IET \nImage Processing,\
    \ vol. 12, no. 10, pp. 1844-1856, Oct. 2018. https://doi.org/10.1049/iet-\nipr.2017.1333.\
    \ \n201. Zhang, L.; Zhang, Y.D.; Tang, J.H.; Lu, K.; Tian, Q. “Binary code ranking\
    \ with weighted \nHamming distance,” In Proceedings of 26th IEEE Conference on\
    \ Computer Vision and Pattern \nRecognition (CVPR), Portland, OR, USA, Jun. 23-28,\
    \ 2013. \n202. Ye, J. “Improved cosine similarity measures of simplified neutrosophic\
    \ sets for medical \ndiagnoses,” Artificial Intelligence in Medicine, vol. 63,\
    \ no. 3, pp. 171-179, Mar. 2015. \nhttps://doi.org/10.1016/j.artmed.2014.12.007.\
    \ \n203. Liu, H.F.; Hu, Z.; Mian, A.; Tian, H.; Zhu, X.Z. “A new user similarity\
    \ model to improve the \naccuracy of collaborative filtering,” Knowledge-Based\
    \ Systems, vol. 56, pp. 156-166, Jan. 2014. \nhttps://doi.org/10.1016/j.knosys.2013.11.006.\
    \ \n204. Liu, C.J. “Discriminant analysis and similarity measure,” Pattern Recognition,\
    \ vol. 47, no. 1, pp. \n359-367, Jan. 2014. https://doi.org/10.1016/j.patcog.2013.06.023.\
    \ \n \n197 \n \n205. Ling, H.B.; Jacobs, D.W. “Shape classification using the\
    \ inner-distance,” IEEE Transactions on \nPattern Analysis and Machine Intelligence,\
    \ vol. 29, no. 2, pp. 286-299, Feb. 2007. \nhttps://doi.org/10.1109/TPAMI.2007.41.\
    \ \n206. Zheng, Y.H.; Jeon, B.; Xu, D.H.; Wu, Q.M.J.; Zhang, H. “Image segmentation\
    \ by generalized \nhierarchical fuzzy C-means algorithm,” Journal of Intelligent\
    \ & Fuzzy Systems, vol. 28, no. 2, pp. \n961-973, 2015. https://doi.org/10.3233/IFS-141378.\
    \ \n207. Wu, J.X.; Rehg, J.M. “Beyond the Euclidean distance: Creating effective\
    \ visual codebooks using \nthe histogram intersection kernel,” In Proceedings\
    \ of 12th IEEE International Conference on \nComputer Vision, Kyoto, JAPAN, Sept.\
    \ 29-Oct. 02, 2009. \n208. Farhan, U.; Tolouei-Rad, M.; Osseiran, A. “Indexing\
    \ and retrieval using case-based reasoning in \nspecial purpose machine designs,”\
    \ International Journal of Advanced Manufacturing Technology, \nvol. 92, no. 5-8,\
    \ pp. 2689-2703, Sept. 2017. https://doi.org/10.1007/s00170-017-0274-5. \n209.\
    \ Honigl, J.; Kung, J. “A data quality index with respect to case bases within\
    \ case-based reasoning,” \nIn Proceedings of 6th Asian Conference on Intelligent\
    \ Information and Database Systems \n(ACIIIDS), Bangkok, THAILAND, Apr. 07-09,\
    \ 2014. \n210. Wiltgen, B.; Goel, A.K.; Vattam, S. “Representation, indexing,\
    \ and retrieval of biological cases \nfor biologically inspired design,” In Proceedings\
    \ of 19th International Conference on Case-Based \nReasoning, London, ENGLAND,\
    \ Sept. 11-14, 2011. \n211. Ahmad, J.; Sajjad, M.; Mehmood, I.; Baik, S.W. “SiNC:\
    \ Saliency-injected neural codes for \nrepresentation and efficient retrieval\
    \ of medical radiographs,” PLOS One, vol. 12, no. 8, Aug. \n2017. https://doi.org/10.1371/journal.pone.0181707.\
    \ \n212. Durmaz, O.; Bilge, H.S. “Fast image similarity search by distributed\
    \ locality sensitive hashing,” \nPattern \nRecognition \nLetters, \nvol. \n128,\
    \ \npp. \n361-369, \nDec. \n2019. \nhttps://doi.org/10.1016/j.patrec.2019.09.025.\
    \ \n213. Ahmed, T.; Sarma, M.; “Hash-based space partitioning approach to iris\
    \ biometric data indexing,” \nExpert \nSystems \nwith \nApplications, \nvol. \n\
    134, \npp. \n1-13, \nNov. \n2019. \nhttps://doi.org/10.1016/j.eswa.2019.05.026.\
    \ \n214. Aydar, M.; Ayvaz, S. “An improved method of locality-sensitive hashing\
    \ for scalable instance \nmatching,” Knowledge and Information Systems, vol. 58,\
    \ no. 2, pp. 275-294, Feb. 2019. \nhttps://doi.org/10.1007/s10115-018-1199-5.\
    \ \n215. Cunningham, P.; Smyth, B. “Case-based reasoning in scheduling: reusing\
    \ solution components,” \nInternational Journal of Production Research, vol. 35,\
    \ no. 11, pp. 2947-2961, Nov. 1997. \nhttps://doi.org/10.1080/002075497194237.\
    \ \n216. De Mantaras, R.L.; Mcsherry, D.; Bridge, D.; Leake, D.; Smyth, B.; Craw,\
    \ S.; Faltings, B.; Maher, \nM.L.; Cox, M.T.; Forbus, K.; Keane, M.; Aamodt, A.;\
    \ Watson, I. “Retrieval, reuse, revision and \n \n198 \n \nretention in case-based\
    \ reasoning,” Knowledge Engineering Review, vol. 20, no. 3, pp. 215-240, \nSept.\
    \ 2005. https://doi.org/10.1017/S0269888906000646. \n217. Lieber, J. “Application\
    \ of the revision theory to adaptation in case-based reasoning: The \nconservative\
    \ adaptation,” In Proceedings of 7th International Conference on Case-Based \n\
    Reasoning, Belfast, NORTH IRELAND, Aug. 13-16, 2007. \n218. Ji, C.; Hong, T.;\
    \ Hyun, C. “CBR revision model for improving cost prediction accuracy in \nmultifamily\
    \ housing projects,” Journal of Management in Engineering, vol. 26, no. 4, pp.\
    \ 229-\n236, Oct. 2010. https://doi.org/10.1061/(ASCE)ME.1943-5479.0000018. \n\
    219. Yan, A.J.; Zhang, K.H.; Yu, Y.H.; Wang, P. “An attribute difference revision\
    \ method in case-based \nreasoning and its application,” Engineering Applications\
    \ of Artificial Intelligence, vol. 65, pp. 212-\n219, Oct. 2017. https://doi.org/10.1016/j.engappai.2017.07.015.\
    \ \n220. Yan, A.J.; Wang, D.H. “Trustworthiness evaluation and retrieval-based\
    \ revision method for case-\nbased reasoning classifiers,” Expert Systems with\
    \ Applications, vol. 42, no. 21, pp. 8006-8013, \nNov. 2015. https://doi.org/10.1016/j.eswa.2015.06.027.\
    \ \n221. Cojan, J.; Lieber, J. “Applying belief revision to case-based reasoning,”\
    \ In Proceedings of \nInternational Workshop on Similarity and Analogy based Methods\
    \ in AI (SAMAI), Montpellier, \nFRANCE, Aug. 27, 2012. \n222. Ontanon, S.; Plaza,\
    \ E.; Zhu, J.C. “Argument-based case revision in CBR for story generation,” In\
    \ \nProceedings of 23rd International Conference on Case-Based Reasoning (ICCBR),\
    \ Bad Homburg, \nGERMANY, Sept. 28-30, 2015. \n223. Mohammed, M.A.; Ghani, M.K.A.;\
    \ Arunkumar, N.; Obaid, O.I.; Mostafa, S.A.; Jaber, M.M.; \nBurhanuddin, M.A.;\
    \ Matar, B.M.; Abdullatif, S.K.; Ibrahim, D.A. “Genetic case-based reasoning \n\
    for improved mobile phone faults diagnosis,” Computers & Electrical Engineering,\
    \ vol. 71, no. \n212-222, Oct. 2018. https://doi.org/10.1016/j.compeleceng.2018.07.053.\
    \ \n224. Grech, A.; Main, J. “A case-based reasoning approach for formulating\
    \ university timetables using \ngenetic algorithms,” In Proceedings of 9th International\
    \ Conference on Knowledge-Based \nIntelligent Information and Engineering Systems,\
    \ Melbourne, AUSTRALIA, Sept. 14-16, 2005. \n225. Recio-Garcia, J.A.; Wiratunga,\
    \ N. “Taxonomic semantic indexing for textual case-based \nreasoning,” In Proceedings\
    \ of 18th International Conference on Case-Based Reasoning, \nAlessandria, ITALY,\
    \ Jul. 19-22, 2010. \n226. Chen, B.H.; Peng, X.; Yu, Y.J.; Nuseibeh, B.; Zhao,\
    \ W.Y. “Self-adaptation through incremental \ngenerative model transformations\
    \ at runtime,” In Proceedings of 36th International Conference on \nSoftware Engineering\
    \ (ICSE), Hyderabad, INDIA, May 31-Jun. 07, 2014. \n227. Hong, W.X.; Wang, Z.Z.;\
    \ Yang, M.; Yuan, J.S. “Conditional generative adversarial network for \nstructured\
    \ domain adaptation,” In Proceedings of 31st IEEE/CVF Conference on Computer Vision\
    \ \nand Pattern Recognition (CVPR), Salt Lake City, UT, USA, Jun. 18-23, 2018.\
    \ \n \n199 \n \n228. Stuikys, V.; Burbaite, R.; Bespalova, K.; Blazauskas, T.;\
    \ Barisas, D. “Stage-based generative \nlearning object model for automated content\
    \ adaptation,” Baltic Journal of Modern Computing, \nvol. 5, no. 2, pp. 183-205,\
    \ 2017. https://doi.org/10.22364/bjmc.2017.5.2.03. \n229. Zhou, P.; Yin, W.D.;\
    \ Zhao, J.H. “Research on case retention strategy for industrial case-based \n\
    reasoning (CBR) system: A practical case study,” In Proceedings of International\
    \ Conference on \nComputer Science and Information Processing (CSIP), Xi’an, PEOPLES\
    \ R CHINA, Aug. 24-26, \n2012. \n230. Reinartz, T.; Iglezakus, I.; Roth-Berghofer,\
    \ T. “Review and restore for case-base maintenance,” \nComputational Intelligence,\
    \ vol. 17, no. 2, pp. 214-234, May 2001. https://doi.org/10.1111/0824-\n7935.00141.\
    \ \n231. Portinale, L.; Torasso, P. “Case-base maintenance in a multimodal reasoning\
    \ system,” \nComputational Intelligence, vol. 17, no. 2, pp. 263-279, May 2001.\
    \ https://doi.org/ 10.1111/0824-\n7935.00144. \n232. Yan, A.J.; Qian, L.M.; Zhang,\
    \ C.X. “Memory and forgetting: An improved dynamic maintenance \nmethod for case-based\
    \ reasoning,” Information Sciences, vol. 287, pp. 50-60, Dec. 2014. \nhttps://doi.org/10.1016/j.ins.2014.07.040.\
    \ \n233. Yang, Q.; Zhu, J. “A case-addition policy for case-base maintenance,”\
    \ Computational Intelligence, \nvol. 17, no. 2, pp. 250-262. https://doi.org/10.1111/0824-7935.00143.\
    \ \n234. Yang, Q.; Wu, J. “Keep it simple: A case-base maintenance policy based\
    \ on clustering and \ninformation theory,” In Proceedings of 13th Biennial Conference\
    \ of the Canadian-Society-for-\nComputational-Studies-of-Intelligence (AI 2000),\
    \ Montreal, CANADA, May 14-17, 2000. \n235. Perner, P. “Case-base maintenance\
    \ by conceptual clustering of graphs,” Engineering Applications \nof \nArtificial\
    \ \nIntelligence, \nvol. \n19, \nno. \n4, \npp. \n381-393, \nJun. \n2006. \nhttps://doi.org/10.1016/j.engappai.2006.01.014.\
    \ \n236. Tsang, E.C.C.; Wang, X.Z. “An approach to case-based maintenance: Selecting\
    \ representative \ncases,” International Journal of Pattern Recognition and Artificial\
    \ Intelligence, vol. 19, no. 1, pp. \n79-89, Feb. 2005. https://doi.org/10.1142/S0218001405003909.\
    \ \n237. Salamo, M.; Golobardes, E. “Deleting and building sort out techniques\
    \ for case base maintenance,” \nIn Proceedings of 6th European Conference on Case-Based\
    \ Reasoning, Aberdeen, SCOTLAND, \nSept. 04-07, 2002. \n238. Standardize \nor\
    \ \nNormalize? \n– \nExamples \nin \nPython. \nAvailable: \nhttps://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc.\
    \ \n239. Garcia, F.T.; Villalba, L.J.G.; Orozco, A.L.S.; Ruiz, F.D.A.; Juarez,\
    \ A.A.; Kim, T.H. “Locating \nsimilar names through locality sensitive hashing\
    \ and graph theory,” Multimedia Tools and \nApplications, vol. 78, no. 21, pp.\
    \ 29853-29866, Nov. 2019. https://doi.org/10.1007/s11042-018-\n6375-9. \n \n200\
    \ \n \n240. Chen, L.; Wang, S.M.; Chen, R.S. “A method to detect gene co-expression\
    \ clusters from multiple \nmicroarrays,” Progress in Biochemistry and Biophysics,\
    \ vol. 35, no. 8, pp. 914-920, Aug. 2008. \n241. Dehghani, M.; Moeini, A.; Kamandi,\
    \ A. “Experimental evaluation of local sensitive hashing \nfunctions for face\
    \ recognition,” In Proceedings of 5th International Conference on Web Research\
    \ \n(ICWR), Tehran, IRAN, Apr. 24-25, 2019. \n242. Mau, T.N.; Inoguchi, Y. “Robust\
    \ optimization for audio fingerprint hierarchy searching on \nmassively parallel\
    \ with multi-GPGPUs using K-modes LSH,” In Proceedings of International \nConference\
    \ on Advanced Engineering Theory and Applications (AETA), Busan, SOUTH KOREA,\
    \ \nDec. 08-10, 2016. \n243. Li, H.; Song, Y.; Li, X.P.; Liu, Q.X.; Zhu, Y.F.\
    \ “Research of CBR retrieval method based on rough \nset theory,” In Proceedings\
    \ of 6th IEEE International Conference on Software Engineering and \nService Science\
    \ (ICSESS), Beijing, PEOPLES R CHINA, Sept. 23-25, 2015. \n244. Su, W.B.; Lei,\
    \ Z.F. “Rough case-based reasoning system for continues casting,” In Proceedings\
    \ of \n10th International Conference on Machine Vision (ICMV), Vienna, AUSTRIA,\
    \ Nov. 13-15, 2017. \n245. Singh, K.; Kansal, A.; Singh, G. “An improved median\
    \ filtering anti-forensics with better image \nquality and forensic undetectability,”\
    \ Multidimensional Systems and Signal Processing, vol. 30, \nno. 4, pp. 1951-1974,\
    \ Oct. 2019. https://doi.org/10.1007/s11045-019-00637-8. \n246. Rahman, M.M.;\
    \ Antani, S.K.; Thoma, G.R. “A learning-based similarity fusion and filtering\
    \ \napproach for biomedical image retrieval using SVM classification and relevance\
    \ feedback,” IEEE \nTransactions on Information Technology in Biomedicine, vol.\
    \ 15, no. 4, pp. 640-646, Jul. 2011. \nhttps://doi.org/10.1109/TITB.2011.2151258.\
    \ \n247. Zhang, L.; Li, D.X.; An, X.Y. “Study on water resources optimal allocation\
    \ of irrigation district \nand irrigation decision support system,” In Proceedings\
    \ of 4th IFIP TC 12 Conference on Computer \nand Computing Technologies in Agriculture,\
    \ Nanchang, PEOPLES R CHINA, Oct. 22-25, 2010. \n248. Rossi, V.; Sperandio, G.;\
    \ Caffi, T.; Simonetto, A.; Gilioli, G. “Critical success factors for the \nadoption\
    \ of decision tools in IPM,” Agronomy-Basel, vol. 9, no. 11, Nov. 2019. \nhttps://doi.org/10.3390/agronomy9110710.\
    \ \n249. El-Sharkawy, M.A. “Global warming: causes and impacts on agroecosystems\
    \ productivity and \nfood security with emphasis on cassava comparative advantage\
    \ in the tropics/subtropics,” \nPhotosynthetica, vol. 52, no. 2, pp. 161-178,\
    \ Jun. 2014. https://doi.org/10.1007/s11099-014-0028-\n7. \n250. Wang, J.; Lan,\
    \ Y.B.; Zhang, H.H.; Zhang, Y.L.; Wen, S.; Yao, W.X.; Deng, J.J. “Drift and \n\
    deposition of pesticide applied by UAV on pineapple plants under different meteorological\
    \ \nconditions,” International Journal of Agricultural and Biological Engineering,\
    \ vol. 11, no. 6, pp. \n5-12, Nov. 2018. https://doi.org/10.25165/j.ijabe.20181106.4038.\
    \ \n \n201 \n \n251. Chen, C.; Yan, X.F.; Ma, Y.H.; Yu, S.; Xu, Q.; Grantz, D.A.;\
    \ Lammers, P.S.; Wang, Z.Y.; Sun, \nY.R.; Cheng, Q. “Monitoring near-surface soil\
    \ water content using an innovative perforated \ncylinder coaxial dielectric sensor,”\
    \ Journal of Hydrology, vol. 573, pp. 746-754, Jun. 2019. \nhttps://doi.org/10.1016/j.jhydrol.2019.04.020.\
    \ \n252. Pytka, J.; Budzynski, P.; Kaminski, M.; Lyszczyk, T.; Jozwik, J. “Application\
    \ of the TDR moisture \nsensor \nfor \nterramechanical \nresearch,” \nSensors,\
    \ \nvol. \n19, \nno. \n9, \nMay. \n2019. \nhttps://doi.org/10.3390/s19092116.\
    \ \n253. Leistra, M.; Zweers, A.J.; Warinton, J.S.; Crum, S.J.H.; Hand, L.H.;\
    \ Beltman, W.H.J.; Maund, S.J. \n“Fate of the insecticide lambda-cyhalothrin in\
    \ ditch enclosures differing in vegetation density,” \nPest Management Science,\
    \ vol. 60, no. 1, pp. 75-84, Jan. 2004. https://doi.org/10.1002/ps.780. \n254.\
    \ Handique, B.K.; Khan, A.Q.; Goswami, C.; Prashnani, M.; Gupta, C.; Raju, P.L.N.\
    \ “Crop \ndiscrimination using multispectral sensor onboard unmanned aerial vehicle,”\
    \ Proceedings of the \nNational Academy of Sciences India Section A-Physical Sciences,\
    \ vol. 87, no. 4, pp. 713-719, Dec. \n2017. https://doi.org/10.1007/s40010-017-0443-9.\
    \ \n255. Arroyo, J.A.; Gomez-Castaneda, C.; Ruiz, E.; de Cote, E.M.; Gavi, F.;\
    \ Sucar, L.E. “Assessing \nnitrogen nutrition in corn crops with airborne multispectral\
    \ sensors,” In Proceedings of 30th \nInternational Conference on Industrial Engineering\
    \ and Other Applications of Applied Intelligent \nSystems (IEA/AIE), Arras, FRANCE,\
    \ Jun. 27-30, 2017. \n256. Saravanan, K.; Saraniya, S. “Cloud IoT based novel\
    \ livestock monitoring and identification system \nusing UID,” Sensor Review,\
    \ vol. 38, no. 1, pp. 21-23, Jan. 2018. https://doi.org/10.1108/SR-08-\n2017-0152.\
    \ \n257. Ariff, M.H.; Ismarani, I.; Shamsuddin, N. “RFID based systematic livestock\
    \ health management \nsystem,” In Proceedings of IEEE Conference on Systems, Process\
    \ and Control (ICSPC), Kuala \nLumpur, MALAYSIA, Dec. 12-14, 2014. \n258. Kumar,\
    \ A.; Hancke, G.P. “A Zigbee-based animal health monitoring system,” IEEE Sensors\
    \ \nJournal, vol. 15, no. 1, pp. 610-617, Jan. 2015. https://doi.org/10.1109/JSEN.2014.2349073.\
    \ \n259. Billot, A.; Gilboa, I.; Schmeidler, D. “Axiomatization of an exponential\
    \ similarity function,” \nMathematical \nSocial \nSciences, \nvol. \n55, \nno.\
    \ \n2, \npp. \n107-115, \nMar. \n2008. \nhttps://doi.org/10.1016/j.mathsocsci.2007.08.002.\
    \ \n260. Panday, D.; de Amorim, R.C.; Lane, P. “Feature weighting as a tool for\
    \ unsupervised feature \nselection,” \nInformation \nProcessing \nLetters, \n\
    vol. \n129, \nno. \n44-52, \nJan. \n2018. \nhttps://doi.org/10.1016/j.ipl.2017.09.005.\
    \ \n261. Montani, S. “Case-based reasoning for managing noncompliance with clinical\
    \ guidelines,” \nComputational Intelligence, vol. 25, no. 3, pp. 196-213, Aug.\
    \ 2009. https://doi.org/10.1111/j.1467-\n8640.2009.00338.x \n \n202 \n \n262.\
    \ Matthews, G.A. “How was the pesticide applied?” Crop Protection, vol. 23, no.\
    \ 7, pp. 651-653, \nJul. 2004. https://doi.org/10.1016/j.cropro.2003.12.001. \n\
    263. Case \nStudy \n– \nCase \nbase. \nAvailable: \nhttps://github.com/ZhaoyuZHAI/PhD-\n\
    thesis/blob/master/Case-Study. \n264. Lu, N.; Lu, J.; Zhang, G.Q. “Maintaining\
    \ footprint-based retrieval for case deletion,” In \nProceedings of 16th International\
    \ Conference on Neural Information Processing (ICONIP 2009), \nBangkok, Thailand,\
    \ Dec. 01-05, 2009. \n265. Oracle Mediator – Oracle® fusion middleware developer’s\
    \ guide for Oracle SOA suite. Available: \nhttps://docs.oracle.com/html/E10224_15/med_gsmed.htm.\
    \ \n266. myCBR. Available: http://mycbr-project.org/. \n267. Spyder. Available:\
    \ https://www.spyder-ide.org/. \n268. Scikit \nlearn \n– \n6.3. \nPreprocessing\
    \ \ndata. \nAvailable: \nhttps://scikit-\nlearn.org/stable/modules/preprocessing.html.\
    \ \n269. Sonderskov, M.; Fritzsche, R.; de Mol, F.; Gerowitt, B.; Goltermann,\
    \ S.; Kierzek, R.; Krawczyk, \nR.; Bojer, O.M.; Rydahl, P. “DSSherbicide: Weed\
    \ control in winter wheat with a decision support \nsystem in three south Baltic\
    \ regions – Field experimental results,” Crop Protection, vol. 76, pp. \n15-23,\
    \ Oct. 2015. https://doi.org/10.1016/j.cropro.2015.06.009. \n270. Itoh, J.; Nonomura,\
    \ K.; Ikeda, K.; Yamaki, S.; Inukai, Y.; Yamagishi, H.; Kitano, H.; Nagato, Y.\
    \ \n“Rice plant development: From zygote to spikelet,” Plant and Cell Physiology,\
    \ vol. 46, no. 1, pp. \n23-47, Jan. 2005. https://doi.org/10.1093/pcp/pci501.\
    \ \n271. Validation – Case base pastCase (1-3000). Available: https://github.com/ZhaoyuZHAI/PhD-\n\
    thesis/blob/master/caseBase%201-3000%20(Validation). \n272. Validation – Case\
    \ base newCase (1-500). Available: https://github.com/ZhaoyuZHAI/PhD-\nthesis/blob/master/caseBase%20newCase%201-500%20(Validation).\
    \ \n \n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: http://oa.upm.es/64746/1/ZHAOYU_ZHAI.pdf
  publication_year: 2020
  relevance_score1: 0
  relevance_score2: 0
  title: Contributions to Case-Based Reasoning Enabled Decision Support System for
    Smart Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

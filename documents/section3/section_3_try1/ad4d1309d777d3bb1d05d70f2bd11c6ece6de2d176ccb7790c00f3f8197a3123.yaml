- DOI: https://doi.org/10.1109/access.2021.3066457
  analysis: '>'
  authors:
  - Franklin Magalhães Ribeiro
  - Carlos Kamienski
  citation_count: 24
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Personal Sign In * Required *Email Address *Password Forgot Password?
    Sign In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/9312710/09380363.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: A Survey on Trustworthiness for the Internet of Things
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s22207910
  analysis: '>'
  authors:
  - Vincenzo Barrile
  - Silvia Simonetti
  - Rocco Citroni
  - Antonino Fotia
  - Giuliana Bilotta
  citation_count: 18
  full_citation: '>'
  full_text: ">\nCitation: Barrile, V.; Simonetti, S.;\nCitroni, R.; Fotia, A.; Bilotta,\
    \ G.\nExperimenting Agriculture 4.0 with\nSensors: A Data Fusion Approach\nbetween\
    \ Remote Sensing, UAVs and\nSelf-Driving Tractors. Sensors 2022,\n22, 7910. https://doi.org/10.3390/\n\
    s22207910\nAcademic Editors: Abdul\nM. Mouazen and\nViacheslav Adamchuk\nReceived:\
    \ 25 August 2022\nAccepted: 14 October 2022\nPublished: 18 October 2022\nPublisher’s\
    \ Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished\
    \ maps and institutional afﬁl-\niations.\nCopyright:\n© 2022 by the authors.\n\
    Licensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed\n\
    under\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY)\
    \ license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nsensors\nArticle\n\
    Experimenting Agriculture 4.0 with Sensors: A Data Fusion\nApproach between Remote\
    \ Sensing, UAVs and\nSelf-Driving Tractors †\nVincenzo Barrile 1\n, Silvia Simonetti\
    \ 2\n, Rocco Citroni 3\n, Antonino Fotia 1\nand Giuliana Bilotta 1,*\n1\nDICEAM\
    \ Department, University Mediterranea of Reggio Calabria, 89124 Reggio Calabria,\
    \ Italy\n2\nDepartment of Engineering, Università degli Studi di Messina-Piazza\
    \ Pugliatti, 1, 98122 Messina, Italy\n3\nDepartment of Electronic Engineering,\
    \ University of Rome Tor Vergata, 00133 Roma, Italy\n*\nCorrespondence: giuliana.bilotta@unirc.it\n\
    †\nThis paper is an extended version of “UAV for Precision Agriculture in Vineyards:\
    \ A Case Study in Calabria”\npublished in the Proceedings of the Italian Conference\
    \ on Geomatics and Geospatial Technologies, Genoa,\nItaly, 1–23 July 2021.\nAbstract:\
    \ Geomatics is important for agriculture 4.0; in fact, it uses different types\
    \ of data (remote\nsensing from satellites, Unmanned Aerial Vehicles-UAVs, GNSS,\
    \ photogrammetry, laser scanners\nand other types of data) and therefore it uses\
    \ data fusion techniques depending on the different\napplications to be carried\
    \ out. This work aims to present on a study area concerning the integration\n\
    of data acquired (using data fusion techniques) from remote sensing techniques,\
    \ UAVs, autonomous\ndriving machines and data fusion, all reprocessed and visualised\
    \ in terms of results obtained through\nGIS (Geographic Information System). In\
    \ this work we emphasize the importance of the integration\nof different methodologies\
    \ and data fusion techniques, managing data of a different nature acquired\nwith\
    \ different methodologies to optimise vineyard cultivation and production. In\
    \ particular, in\nthis note we applied (focusing on a vineyard) geomatics-type\
    \ methodologies developed in other\nworks and integrated here to be used and optimised\
    \ in order to make a contribution to agriculture\n4.0. More speciﬁcally, we used\
    \ the NDVI (Normalized Difference Vegetation Index) applied to\nmultispectral\
    \ satellite images and drone images (suitably combined) to identify the vigour\
    \ of the\nplants. We then used an autonomous guided vehicle (equipped with sensors\
    \ and monitoring systems)\nwhich, by estimating the optimal path, allows us to\
    \ optimise fertilisation, irrigation, etc., by data\nfusion techniques using various\
    \ types of sensors. Everything is visualised on a GIS to improve the\nmanagement\
    \ of the ﬁeld according to its potential, also using historical data on the environmental,\n\
    climatic and socioeconomic characteristics of the area. For this purpose, experiments\
    \ of different\ntypes of Geomatics carried out individually on other application\
    \ cases have been integrated into\nthis work and are coordinated and integrated\
    \ here in order to provide research/application cues for\nAgriculture 4.0.\nKeywords:\
    \ vineyards; unmanned aerial vehicles; satellite imagery; agriculture 4.0; sensor\
    \ networks\n1. Introduction\nAs the concept of digital transformation is making\
    \ its way into all ﬁelds of daily life,\nrevolutionizing the way we produce and\
    \ interact, the applications of digital technologies\ntend to “specialize” in\
    \ individual application sectors. Agriculture is often considered a\n“traditionalist”\
    \ sector uninclined to changes; however, in recent years, it has beneﬁted\ngreatly\
    \ from the technological evolution underway.\nThe term “industry 4.0” has been\
    \ coined to indicate digital transformation in produc-\ntion environments; in\
    \ the same vein, the entry of the technologies of the fourth industrial\nrevolution\
    \ into the agrifood sector can be called “agriculture 4.0”. Agriculture 4.0 is\
    \ the\nresult of the application of a series of innovative technologies in the\
    \ agrifood ﬁeld and\nSensors 2022, 22, 7910. https://doi.org/10.3390/s22207910\n\
    https://www.mdpi.com/journal/sensors\nSensors 2022, 22, 7910\n2 of 23\nit can\
    \ be considered as an upgrade of precision agriculture. This was possible thanks\
    \ to\nthe automation of the collection and the integration and analysis of data\
    \ collected directly\nfrom the ﬁelds through various types of sensors. In this\
    \ context, digital technologies 4.0\nare useful to support-thanks to data analysis-the\
    \ farmer in his daily activity and in plan-\nning strategies for his business,\
    \ including relationships with all links in the supply chain,\ngenerating a virtuous\
    \ circle able to create value for the individual company and in cascade\nfor its\
    \ partners. Thanks to these new solutions and the application of digital technologies,\n\
    from the IoT to artiﬁcial intelligence, from the analysis of large amounts of\
    \ data to self-\ndriving tractors to the use of drones, farms can increase proﬁtability\
    \ and the economic,\nenvironmental and social sustainability of its business.\
    \ The beginning of the application of\ntechnologies for precision agriculture\
    \ in Italy dates to the 1990s; basically, it involves using\ndigital solutions\
    \ for speciﬁc interventions, which take into account in particular the needs\n\
    of the soil and plants. The aims of these interventions are to improve the production\
    \ yield\nof the plantations as much as possible and contain costs and environmental\
    \ impact. This\ncategory includes, for example, all interventions to make irrigation\
    \ more efﬁcient without\nwasting water resources or causing the plants to suffer,\
    \ planting technologies adapted to\nthe biochemical and physical characteristics\
    \ of the soil on which the intervention is carried\nout, the administration of\
    \ pesticides commensurate to the speciﬁc needs of each area and\nplant, or of\
    \ fertilizers only in the necessary quantity and at the most useful times.\nFor\
    \ this reason, precision agriculture, in addition to being the predecessor of\
    \ agricul-\nture 4.0, is also one of the cornerstones of the latter, because it\
    \ lays the foundations for\nadapting production processes to individual needs\
    \ thanks to targeted and timely interven-\ntions. All these interventions can\
    \ adapt to the needs of the moment (through GIS, different\ntypes of sensor data,\
    \ and the use of data fusion techniques, production peculiarities can\nalso be\
    \ estimated). The basis for making these technologies more effective is the real-time\n\
    use of data coming from the ﬁelds. Thanks to sensors able transmit information,\
    \ installed\non ﬁelds or agricultural machinery, it will be possible to make timely\
    \ and effective deci-\nsions, which can also be entrusted to automated systems.\
    \ In general, the main advantages\nof agriculture 4.0 are those, as we said, of\
    \ a rationalization of resources, with a positive\neconomic impact for the companies\
    \ in the supply chain. A path of products-from ﬁeld to\ntable-aimed at maximizing\
    \ sustainability also has a positive impact on health, since it will\nbe possible\
    \ to bring better controlled and fresher products to ﬁnal consumers than with\n\
    traditional techniques. To quantify these advantages, there is talk of a saving\
    \ of around 30%\nfor production inputs and a 20% increase in productivity, with\
    \ limited use of chemicals.\nThen focusing on the use of data, it must be added\
    \ that being able to count on the real-time\nanalysis of the information coming\
    \ from the ﬁelds is extremely useful to manage any\nactivity related to agriculture\
    \ in a faster and, therefore, more efﬁcient way. In fact, thanks to\nthe data\
    \ analysis, it will be possible to make the use of agricultural machinery as efﬁcient\n\
    as possible, or to use only the amount of water needed, without waste. Thanks\
    \ to the same\nset of information, it will also be possible to prevent plant diseases\
    \ or counteract pests,\nlimiting damage when problems arise thanks to constant\
    \ and simultaneous monitoring of\ncrops. Moreover, it should be emphasized that\
    \ these are advantages that can be obtained\nregardless of the type of crop.\n\
    This study starts from work previously carried out on a speciﬁc agricultural area,\
    \ with\nthe aim of reanalysis with different tools and techniques in order to\
    \ ﬁnd a more efﬁcient\nmonitoring solution.\nIt is possible to use Geomatics techniques,\
    \ and thus to use satellite images, multi-\nspectral drone images (and there are\
    \ already numerous analyses on the integration of\nsatellite images and drone\
    \ images to improve image quality and productivity), other sen-\nsors (humidity,\
    \ pressure, wind, temperature), merge these data with data fusion techniques,\n\
    manage the use of automated vehicles, and collect everything using GIS to optimise\
    \ the\nagricultural production process (fertilisation, irrigation, etc....) according\
    \ to the needs of\nthe population.\nSensors 2022, 22, 7910\n3 of 23\nThe practice\
    \ of Precision Agriculture (PA) and, recently, Agriculture 4.0, has garnered\n\
    a lot of attention in recent years. Through the integration of information technology\
    \ and\nagronomic practices, it has become possible to automate the management\
    \ of parcels of\nland [1].\nThe literature cited below highlights the research\
    \ questions and useful information\nand underlines the shortcomings of previous\
    \ studies.\nPrecision agriculture is a management strategy [2] that utilizes information\
    \ technology\nto collect data from multiple sources in order to use them in decisions\
    \ regarding ﬁeld\nproduction activities [3]. The goal of this strategy is to integrate\
    \ the ideas of business\nmanagement and process automation. Agriculture 4.0 additionally\
    \ brings together var-\nious innovative methodologies applied from time to time\
    \ in other sectors, such as the\nidentiﬁcation of optimal routes for self-driving\
    \ tractors.\nCrop monitoring, which is based on observations carried out directly\
    \ on crops in place\nin order to obtain data on phenological stages, nutritional\
    \ status [4–6], phytosanitary status,\nproduction expectations [7] and production\
    \ maps [8], is of particular interest in order to\naccomplish this. The monitoring\
    \ of crops relies on observations made directly on the crops\nin their natural\
    \ environment. Since massive amounts of data need to be gathered and\nprocessed,\
    \ process automation is necessary [9].\nThe monitoring of crops makes use of remote\
    \ sensing data and is predicated on the link\nthat exists between several parameters\
    \ relating to the leaf curtain [10]. These parameters\ncan express the vegetative–productive\
    \ responses of plants and evaluate the variability as\na function of the different\
    \ behaviours of surfaces and bodies [11] to the phenomenon of\nabsorption or reﬂection\
    \ of light in the visible and infrared regions [12].\nLarge agricultural regions\
    \ have been monitored using satellite remote sensing ever\nsince the 1970s for\
    \ the purpose of stock forecasting [13], which has resulted in the provision\n\
    of useful data for the industry of agriculture itself. The unique optical behaviour\
    \ of plants\nin the infrared radiation band makes remote sensing techniques particularly\
    \ useful for\nevaluating vegetative health [14], as these techniques are useful\
    \ in practice [15]. The time-\nconsuming and ﬁnancially burdensome ﬂights of airplanes\
    \ ﬁtted with specialized cameras\nwere quickly replaced by satellites that, while\
    \ continuously orbiting the Earth, acquire data\non the electromagnetic emission\
    \ of objects on the Earth’s surface, and consequently also of\nthe crops, with\
    \ their multispectral sensors, if passive, or radar, if active. This has resulted\n\
    in a signiﬁcant reduction in the cost of collecting this information. However,\
    \ passive\nsensors have limitations; acquisition is necessarily diurnal and hindered\
    \ by any cloud cover.\nFurthermore, the level of detail that is obtainable precludes\
    \ performing particular kinds of\nanalyses on smaller parcels of land.\nOn the\
    \ other hand, unmanned aerial vehicles (UAVs) have the potential to be very\n\
    helpful because they can collect more speciﬁc georeferenced information using\
    \ a variety of\nsensors [16–19].\nIn viticulture in particular, optimising vineyard\
    \ cultivation and yield procedures\nthrough the use of automatic cultivation machines\
    \ and data fusion, which faces challenges\nduring production cycles by deﬁning\
    \ an adequate crop management, the Agriculture 4.0\napproach has as its ultimate\
    \ goal the improvement of vineyard yield and grape quality while\nsimultaneously\
    \ reducing all wastes, costs, and the negative impact on the environment [20].\n\
    The information collected by optical sensors in multispectral and hyperspectral\
    \ imag-\ning systems is utilized in the calculation of a diverse range of indices\
    \ related to crop\nproduction (such as the Leaf Area Index (LAI) [15,21]). The\
    \ normalized difference vegeta-\ntion index (NDVI) is one of the indices that\
    \ is utilised the most frequently because of its\nrelationship to crop vigour\
    \ and, as a result of this relationship, to the estimated quantity\nand quality\
    \ of ﬁeld production.\nThe MultiSpectral Instrument (MSI) of Sentinel 2 covers\
    \ large areas, and many satellite\nprograms (i.e., Landsat, Sentinel-1 and Sentinel-2)\
    \ now freely supply datasets, which\npromotes the exploitation of satellite imagery\
    \ for many applications, including agricultural\napplications, as multi-sensor\
    \ and multiresolution data fusion [22–26]. The Sentinel-2\nSensors 2022, 22, 7910\n\
    4 of 23\nsatellite, which was developed by the European Space Agency (ESA), has\
    \ a resolution of\none decametre, a revisitation time of six days, and an efﬁcient\
    \ resolution for analysing crop\nvariability and conditions. If, on the other\
    \ hand, we consider crops to be more like orchards\nand vineyards (with breaks\
    \ in their layouts), then remote sensing becomes more challenging.\nActually,\
    \ the occurrence of paths between yields and weedy vegetation within the cultivated\n\
    land can have a noticeable impact on the overall calculation of spectral indices,\
    \ which in\nturn leads to a less precise evaluation of the crop’s status. New\
    \ methods and algorithms\nwere developed that use multispectral information from\
    \ UAVs for circumventing this\ncriticality [27]. These advancements have been\
    \ made in order to resolve this critical issue.\nLow-altitude platforms, as Unmanned\
    \ Aerial Vehicles (UAVs) with airborne sensors,\ncan differentiate pure canopy\
    \ pixels from other objects by acquiring images with a high\nresolution and having\
    \ ﬂexible ﬂight planning [28]. This allows for the classiﬁcation of\ndetails within\
    \ canopies.\nIn particular, it is possible to successfully combine an unmanned\
    \ rotary-wing platform\nwith a multispectral sensor in order to detect and monitor\
    \ water-stressed areas of orchards,\nvineyards, and olive groves. This is possible\
    \ thanks to the fact that the two technologies\ncan be successfully combined.\n\
    In PA, the NDVI index is a parameter that is used because it is directly related\
    \ to the\nhealth of the vegetation. This allows problems such as a lack of nutrients,\
    \ the presence\nof parasitic infections, or conditions of water stress to be discovered.\
    \ The NDVI index is\ncalculated by processing images that were taken in the infrared.\
    \ The early detection of\nsuch situations enables intervention that is both targeted\
    \ and effective, which results in cost\nsavings and increased crop yield. Infrared\
    \ detection is frequently capable of identifying\nissues well in advance of their\
    \ becoming obvious to the human eye [29,30].\nIn this article we present, among\
    \ other things, a comprehensive vineyard survey\nthat also compares MultiSpectral\
    \ Instrument (MSI) data from a satellite with decametre\nresolution and from a\
    \ low-altitude UAV platform. This allowed us to better understand the\ndifferences\
    \ between the two types of instruments. The performance of Sentinel-2′s MSI,\n\
    WorldVew and the aerial UAV sensors, both with very high resolution, when considering\n\
    the relationship between crop vigour and NDVI was determined. In order to investigate\n\
    the role played by the various vineyard components, satellite data were compared\
    \ with\nUAV images using the following three NDVI indices [31,32]: (i) the entire\
    \ agricultural area;\n(ii) only the vine canopies; and (iii) only the inter-row\
    \ soil. These indices were calculated\nby comparing the UAV data with satellite\
    \ images.\nThe multispectral sensors used on UAVs are capable of recording at\
    \ least three chan-\nnels, as a regular camera would, but one of those channels\
    \ is replaced by infrared. Although\nmultispectral sensors can acquire information\
    \ in more than four bands and multispectral\ncameras are capable of recording\
    \ more than the three channels deﬁned here, for the pur-\nposes of this application,\
    \ each image will consist of two visible colours in addition to\ninfrared [33–36].\
    \ Because of this, the NDVI index can be calculated from a single image\nusing\
    \ a modiﬁed version of the conventional formula. The processing is handled in\
    \ an\nautomated practice by the GIS which we used (QGis). The maps that are obtained\
    \ after\nthe processing are false-colour maps known as “Vigour Maps” [37,38].\
    \ On these maps, red\nrepresents regions that have the highest possible vitality\
    \ [39].\nRecent literature also exists on data fusion techniques for agriculture:\
    \ on input devices\nsynchronised with microcontrollers and sending data from sensors\
    \ via IoT (Internet of\nThings) devices to the cloud [40] and the challenges and\
    \ complexity of Agriculture 4.0 [41].\nIt is obvious that the methodology that\
    \ has been proposed can include other kinds of\ncrops that are grown in rows,\
    \ with crop canopies that do not extend over the entire area of\ncultivation,\
    \ or where there is a signiﬁcant presence of bare soil or grass [42–44].\nSensors\
    \ 2022, 22, 7910\n5 of 23\n2. Materials and Methods\n2.1. Remote Sensing\nRemote\
    \ sensing is the acquisition of information about an object or phenomenon\nwithout\
    \ coming into physical contact with the object. In this case we will refer to\
    \ Remote\nSensing from Earth Observation by satellite and, although it is used\
    \ in numerous ﬁelds, in\nour case it is used for monitoring purposes in agriculture,\
    \ particularly vineyard cultivation.\nIt is crucial for winemakers to gain an\
    \ accurate understanding of the spatial variability\nboth between and within crops\
    \ to be able to make accurate predictions regarding yield and\nquality. The Normalized\
    \ Difference Vegetation Index (NDVI) is one of the most widely\nused indices because\
    \ it is related to crop vigour and, as a result, to estimated quantity and\nquality\
    \ of ﬁeld production.\nPlants absorb solar radiation in the spectral region via\
    \ photosynthetically active radia-\ntion (PAR), which they then use as an energy\
    \ source in the photosynthesis process. Strong\nabsorption at these wavelengths\
    \ will only overheat the plant and potentially damage its\ntissue. As a result,\
    \ plants appear relatively dark in the PAR spectrum and relatively bright\nin\
    \ the near infrared spectrum. Clouds and snow, on the other hand, tend to be bright\
    \ in the\nred band (as well as other visible wavelengths) and dark in the near\
    \ infrared. Chlorophyll,\na pigment found in leaves, strongly absorbs visible\
    \ light for use in photosynthesis. In\ncontrast, the cellular structure of leaves\
    \ strongly reﬂects near-infrared light. The more\nleaves a plant has, the more\
    \ wavelengths are affected, and thus the greater the amount\nof light involved.\
    \ Because earth observation instruments collect data in the visible and\nnear-infrared\
    \ ranges, it was natural to use the large differences in reﬂectance of plants\
    \ to\ndetermine their spatial distribution in satellite images.\nThe following\
    \ formula is used to calculate the NDVI:\nNDVI = (NIR − Red)\n(NIR + Red)\n(1)\n\
    Red and NIR are abbreviations for spectral reﬂectance measurements obtained in\
    \ the\nvisible (red) and near-infrared regions, respectively.\n2.2. UAVs/Sensors\n\
    Unmanned aerial vehicles (UAVs) are a type of robotic aircraft that are controlled\n\
    by radio and have their own built-in control systems. They were initially developed\
    \ in\nthe 1920s for use in the military as a replacement for human pilots serving\
    \ on hazardous\nmissions. In the past, the disadvantages of high cost, large sensors,\
    \ poor endurance,\nand primitive ﬂight control systems caused civilian UAV use\
    \ to develop slowly. At the\nbeginning of the twenty-ﬁrst century, only a few\
    \ low-quality products were available for\nuse in scientiﬁc research. These disadvantages\
    \ still exist today. The market for low-cost\nunmanned aerial vehicles (UAVs)\
    \ has expanded at a rapid rate thanks to the development of\nnew technologies\
    \ and the appearance of UAV manufacturers such as DJI (Shenzhen, China).\nThe\
    \ successful transition of UAVs from military to civilian uses has been facilitated\
    \ by\nthe development of several different technologies. There is now an abundance\
    \ of UAVs\navailable to meet the demand in various ﬁelds of use, including scientiﬁc\
    \ research.\nThe development of remote sensing technology has made it possible\
    \ to devise a\nworkable strategy for the collection of speciﬁc data used for mapping\
    \ land-cover changes,\nmonitoring drought conditions, and analysing complex characteristics\
    \ across space and\ntime. This technology uses a variety of sensors onboard satellites,\
    \ airborne or unmanned\naerial vehicles (UAVs), and it offers a variety of classiﬁcation\
    \ methods for vegetation at both\nlarge and small scales. A practical approach\
    \ to designing strategies for the management\nof forest disasters can be found\
    \ by employing the techniques of remote sensing. This can\ninclude evaluating\
    \ landslide-prone areas through airborne, UAV, and ground-based remote\nsensing,\
    \ as well as evaluating changes in vegetation cover after a wildﬁre for post-ﬁre\n\
    management by using satellite-based remote sensing and UAV.\nSensors 2022, 22,\
    \ 7910\n6 of 23\nThere is technology available today that can automatically steer\
    \ agricultural vehicles\nsuch as tractors [45–47] and harvesters along predeﬁned\
    \ paths using precise global navi-\ngation satellite systems (GNSS). Examples\
    \ of these types of vehicles include tractors and\ncombine harvesters. However,\
    \ a human operator is still required in order to monitor the\nsurrounding environment\
    \ and take corrective action if any potential hazards come into\nview in front\
    \ of the vehicle in order to guarantee its safe operation.\nIt is necessary for\
    \ there to be no need for a human operator whatsoever for the\nautonomous farming\
    \ vehicles to be able to operate in a manner that is both productive and\nrisk-free\
    \ without any assistance from a person. A safety system must be able to perform\n\
    accurate obstacle detection and avoidance in real time while maintaining a high\
    \ degree of\nreliability. Furthermore, in order to handle a wide variety of shifts\
    \ in the illumination and\nweather conditions, multiple sensing modalities need\
    \ to complement each other.\nFor a technological development of this magnitude,\
    \ extensive research and experi-\nments are required to investigate various sensor,\
    \ detection algorithm, and fusion\nstrategy combinations.\nToday platforms such\
    \ as drones support the integration of a wide variety of sensors\nemployed for\
    \ agriculture 4.0. However, the utilisation of these sensors in agriculture 4.0\
    \ is\nclosely linked to their capacity to detect the signal over a greater spectral\
    \ range. Fundamen-\ntally, in agricultural sensing technology four parameters\
    \ must be analysed: the spectral,\nspatial, temporal, and radiometric resolutions.\
    \ However, in most cases the sensors provide\ninformation based on their spectral\
    \ resolution (multispectral, super-spectral and hyperspec-\ntral). Multispectral\
    \ sensors typically use from 3 to 10 bands to cover the relevant spectrum.\nEarly\
    \ detection of the disease, improved irrigation, water management, faster and\
    \ more\naccurate plant counts to optimize fertilizer application and pest control\
    \ represent some\nadvantages of this sensor. Super-spectral sensors use from 10\
    \ to 20 bands to cover broad\nportions of the spectrum. Hyperspectral sensors\
    \ compared to multispectral sensors cover\nhundreds or thousands of narrower bands\
    \ (10 to 20 nm), providing greater resolution and a\nhighly detailed electromagnetic\
    \ spectrum of agricultural ﬁelds. In addition, higher spatial\nresolution, ability\
    \ to distinguish smaller elements, higher temporal resolution, higher ra-\ndiometric\
    \ sensitivity and the ability to detect small differences in radiated energy represent\n\
    only some of the advantages.\n2.3. Self-Driving Tractors/GIS/Other Sensors\nTractors\
    \ used in agriculture are typically capable of working in any terrain. Moreover,\n\
    the signals coming from the navigation sensors are subject to a great deal of\
    \ unpredictability\nin terms of disturbances and noise sources. As a consequence\
    \ of this, it is essential for the\nsensor fusion module to contain efﬁcient methods\
    \ for signal conditioning and estimating\nthe state of the system.\nWhen it comes\
    \ to automated tractor guidance in the ﬁeld, an accurate position mea-\nsurement\
    \ is absolutely necessary. Because the GPS antenna was mounted on the roof of\
    \ the\ntractor cab, which was approximately three meters above the ground, any\
    \ inclination of\nthe tractor would result in an inaccurate position reading (roll\
    \ and pitch). An architecture\nthat uses edge devices to carry out a substantial\
    \ amount of computation (edge computing),\nstorage, and communication locally\
    \ and routes it over the Internet backbone is called fog\ncomputing or fog networking,\
    \ also known as fogging. A FOG was used to measure heading\nangle on this research\
    \ platform. Utilizing Euclidean angles, a method of correction that\ncompensates\
    \ for positional errors caused by inclination-related factors was developed.\n\
    Hardware design and software design are the two components that make up the\n\
    entirety of the overall structural design of unmanned agricultural machinery.\
    \ The de-\nsign of the hardware encompasses both the mechanical design and the\
    \ circuit design.\nProgramming for the control system execution process and algorithmic\
    \ formulations for\npath tracking control are components of software design. By\
    \ contrasting the traditional\nProportional–Integral–Derivative (PID) control,\
    \ fuzzy control, and fuzzy PID control, this\narticle concludes that the fuzzy\
    \ PID control algorithm should be used to control the steering\nSensors 2022,\
    \ 22, 7910\n7 of 23\nof agricultural machinery, while the traditional incremental\
    \ PID control algorithm should\nbe used to control the speed of the vehicle body\
    \ while it is in motion [48,49].\nThe quantity of sensors used to collect data\
    \ in various settings, as well as the quality\nof the data collected by those\
    \ sensors, has been steadily increasing. Even complex environ-\nments, such as\
    \ agricultural areas, can now be “sensed” via a wide variety of equipment,\nwhich\
    \ generates vast amounts of data that can be explored to provide helpful information\n\
    about the area that is being observed. Examples of such environments include urban\
    \ and\nwilderness areas. Because of this, an increased number of studies have\
    \ been carried out in\nan effort to research the vast amounts of information that\
    \ are hidden within the sensed data.\nHowever, it can be extremely difﬁcult to\
    \ transfer the advances made in experiments to the\nreal-world conditions that\
    \ are encountered in practice. There are two primary explanations\nfor this phenomenon.\
    \ To begin, the scope of the research projects that are described in\nscientiﬁc\
    \ texts is typically restricted. This is due to the fact that the data that are\
    \ utilized\nin these experiments typically do not cover all of the variables that\
    \ are connected to the\nissue at hand. As a consequence of this, the results that\
    \ are reported in those articles,\ndespite the fact that they might appear to\
    \ be encouraging, typically reveal nothing about\nthe performance of the proposed\
    \ technique under real-world conditions that are unre-\nstricted. Second, even\
    \ if the data adequately cover the variable conditions that are found\nin practice,\
    \ the chosen sensing technology may not be able to acquire enough information\n\
    to unambiguously resolve the data and provide enough information. This is a possibility\n\
    even if the data adequately cover the variable conditions that are found in practice.\
    \ For\ninstance, even powerful artiﬁcial intelligence models that are fed with\
    \ RGB digital images\nfrequently fail to correctly identify plant diseases based\
    \ on their symptoms. This is due to\nthe fact that different disorders can produce\
    \ visual signs that are similar to one another.\nThere are many sensors that can\
    \ be used in Agriculture 4.0, for example, the Soil\nMoisture Sensor used in our\
    \ case study, but also other environmental sensors, capable of\nproviding data\
    \ that can be used for cultivation decisions, also collected in time series that\n\
    can therefore provide trends. Meteorological data [50] can also provide useful\
    \ time series\nin agriculture.\nAs is well known, G.I.S. (Geographical Information\
    \ System)/WebGIS is a tool for\nanalysing, reporting and querying entities or\
    \ events occurring in the territory. Particularly\nin Agriculture 4.0, the use\
    \ of GIS allows researchers to integrate and manage data of\ndifferent natures\
    \ and, if properly implemented (open source), it also allows identiﬁcation\nof\
    \ optimal routes for vehicles and areas of greater interest in different areas\
    \ if integrated\nwith historical data.\nThe GIS makes use of images captured by\
    \ UAVs as well as Very High-Resolution\n(VHR) satellite imagery categorized using\
    \ OBIA. The Geographic Information System\n(GIS) is helpful for agriculture in\
    \ general, and not just for the management of vineyards\nspeciﬁcally. It takes\
    \ into account the geomorphology of the land, as well as the climatic\nconditions\
    \ (wind, rain, etc.), and the moisture conditions of the soil for the crops. This\n\
    system is able to provide alerts in the event that interventions are required\
    \ depending on\nthe water stress experienced by the crop. As a result, we are\
    \ able to highlight the optimal\nroute for the tractor.\n2.4. Data Fusion\nUtilizing\
    \ data fusion techniques is one approach to minimizing the gaps in coverage\n\
    that are the result of insufﬁcient data. The process of combining data from several\
    \ different\nsources in order to produce information that is more precise, consistent,\
    \ and concise than\nthat which is provided by any individual data source is referred\
    \ to as “data fusion.” There\nare also other deﬁnitions that are more stringent,\
    \ which better ﬁt speciﬁc contexts. Since\nthe ﬁrst half of the 1990s, people\
    \ have been applying this method to solve agricultural\nproblems, and recently,\
    \ there has been an increase in the number of cases in which this\nmethod is used.\
    \ Finding the most effective method to completely explore the synergy\nand complementarities\
    \ that may exist between various kinds of data and sources of data\nSensors 2022,\
    \ 22, 7910\n8 of 23\nis arguably the most difﬁcult part of using techniques that\
    \ involve the fusion of data.\nThis is one of the main challenges that is involved\
    \ in the use of data fusion techniques.\nThis is especially the case when the\
    \ data being compared have signiﬁcantly different\ncharacteristics (for example,\
    \ digital images and meteorological data). Given the wide\nvariety of data sources\
    \ and methods utilized in agricultural applications [40,41], it can be\nchallenging\
    \ to ﬁnd a formalization for the data fusion process that is suitable for all\
    \ of these\napplications. A perspective on the data fusion process is given here,\
    \ broken down into\nthree stages and applicable to the vast majority of situations.\
    \ In the ﬁrst, the corresponding\nattributes used for describing information in\
    \ the various sources must be identiﬁed. This\nmust be done before moving on to\
    \ the next step. If the data sources are comparable, then\nﬁnding such a correspondence\
    \ is not difﬁcult; however, if different types of data are used,\nthen ﬁnding\
    \ such a correspondence may be more difﬁcult. This is one of the primary\nreasons\
    \ that led to the development of the three distinct types of data fusion that\
    \ are\ndiscussed in the paragraph that follows this one. In the second step, all\
    \ of the distinct\nobjects that are mentioned in the various data sources have\
    \ to be located and arranged in\nthe correct order. Because misalignments can\
    \ lead to inconsistent representations and, as\na result, unreliable answers,\
    \ this step is particularly important when the data sources are\nimages. Alignment\
    \ errors are a common cause of these problems. The third step, which\nis the application\
    \ of the actual data fusion, can be carried out once the data have been\ncorrectly\
    \ identiﬁed and are consistent. In actual practice, addressing the inconsistent\
    \ data\nthat already exist is frequently ignored. Auxiliary tools, such as data\
    \ proﬁle techniques,\nwhich can reduce inconsistencies by extracting and exploring\
    \ the metadata associated to\nthe data being fused, have the potential to (at\
    \ least partially) rectify this situation and bring\nit closer to an acceptable\
    \ state.\nWe essentially perform data fusion on satellite images and drone images\
    \ and then on\nvarious types of sensors using two different methodologies.\nGeomatics\
    \ uses various types of data (remote sensing from satellites, UAVs, and\nother\
    \ data), so data fusion techniques are natural depending on the various applications\n\
    to be carried out. This work aims to present on a study area the integration of\
    \ remote\nsensing techniques, UAVs, autonomous driving machines, data fusion,\
    \ and GIS in order\nto optimize the vineyard by optimizing cultivation and production\
    \ by managing data\nof various types acquired with different methodologies. Geomatics-type\
    \ methodologies\nused in other works and integrated here are speciﬁcally applied\
    \ in this note for use and\noptimisation to contribute to agriculture 4.0.\n3.\
    \ Case Study\nIn the course of our research on a broader study area, focusing\
    \ in particular on a\nvineyard that was located in Bova Superiore, a small municipality\
    \ in the province of\nReggio Calabria (South Italy), neighbourhood Briga, and\
    \ that encompassed an area of\napproximately 2.2 hectares. The cultivated territory\
    \ includes a series of parcels cultivated\nas vineyards, the most representative\
    \ of which have, respectively, extensions of about 3.2 ha\nand 1.8 ha (Figure\
    \ 1).\nThe vineyard is located on a sloping land with a varied morphology, with\
    \ an alti-tude\nranging from 600 to 800 m above sea level and an orientation mainly\
    \ facing south.\nThe distance between rows is two meters, there is a gap of one\
    \ metre between each\nrow, and the width of the canopy along each row is approximately\
    \ one metre. The planting\ntook place in 2016 at the earliest.\nThere were differences\
    \ in the vine’s vigour both within and between the plots that\nare likely to be\
    \ found in the vineyard due to the irregular land morphology, such as soil\ncharacteristics\
    \ and elevation.\nSensors 2022, 22, 7910\n9 of 23\nSensors 2022, 22, x FOR PEER\
    \ REVIEW \n9 of 23 \n \n \n \n \nFigure 1. Study area: Bova Superiore in Calabria,\
    \ Southern Italy. \nThe vineyard is located on a sloping land with a varied morphology,\
    \ with an alti-\ntude ranging from 600 to 800 m above sea level and an orientation\
    \ mainly facing south. \nThe distance between rows is two meters, there is a gap\
    \ of one metre between each \nrow, and the width of the canopy along each row\
    \ is approximately one metre. The plant-\ning took place in 2016 at the earliest.\
    \ \nThere were differences in the vine’s vigour both within and between the plots\
    \ that \nare likely to be found in the vineyard due to the irregular land morphology,\
    \ such as soil \ncharacteristics and elevation. \n3.1. Remote Sensing and UAV\
    \ \nIn this study area, some experiments were conducted to test what we said above\
    \ for \nagriculture 4.0. with particular reference to vineyards. \nWe conducted\
    \ survey campaigns using satellites and drones between May and Oc-\ntober of 2021\
    \ in order to extend the scope of the study to include different phenological\
    \ \nphases of vines. Since the vigour does change over the course of the phenological\
    \ cycle, \nwe decided to acquire images at four different stages between flowering\
    \ and ripening so \nthat we could examine the plant in its various vegetative\
    \ states. On the other hand, certain \nclimatological patterns (such as below-average\
    \ rainfall), which impeded the growth of \nplants, contributed to the stress that\
    \ was experienced by the crops. \nAs satellite data were used, a Sentinel-2 Level\
    \ 2A image was acquired on 24 May, 28 \nJuly, 27 August, and 21 September 2020\
    \ at 09:40 UTC and the image characteristics are \nreported in Table 1, and a\
    \ WorldView-3 image acquired on 21 October 2021 (you can see \nan example of this\
    \ in Figure 2). \nTable 1. Characteristics of satellite Sentinel 2 imagery. \n\
    Sentinel 2 \nNo. channels \n13 \nSpectral bands used \nB4-Red 650–680 nm \nB8-NIR\
    \ 770–810 nm \nGround Sampling Distance (GSD) per band \n10 m \nGround Dimension\
    \ of the image \n100 km × 100 km \nFigure 1. Study area: Bova Superiore in Calabria,\
    \ Southern Italy.\n3.1. Remote Sensing and UAV\nIn this study area, some experiments\
    \ were conducted to test what we said above for\nagriculture 4.0. with particular\
    \ reference to vineyards.\nWe conducted survey campaigns using satellites and\
    \ drones between May and October\nof 2021 in order to extend the scope of the\
    \ study to include different phenological phases of\nvines. Since the vigour does\
    \ change over the course of the phenological cycle, we decided\nto acquire images\
    \ at four different stages between ﬂowering and ripening so that we could\nexamine\
    \ the plant in its various vegetative states. On the other hand, certain climatological\n\
    patterns (such as below-average rainfall), which impeded the growth of plants,\
    \ contributed\nto the stress that was experienced by the crops.\nAs satellite\
    \ data were used, a Sentinel-2 Level 2A image was acquired on 24 May, 28\nJuly,\
    \ 27 August, and 21 September 2020 at 09:40 UTC and the image characteristics\
    \ are\nreported in Table 1, and a WorldView-3 image acquired on 21 October 2021\
    \ (you can see an\nexample of this in Figure 2).\nTable 1. Characteristics of\
    \ satellite Sentinel 2 imagery.\nSentinel 2\nNo. channels\n13\nSpectral bands\
    \ used\nB4-Red 650–680 nm\nB8-NIR 770–810 nm\nGround Sampling Distance (GSD) per\
    \ band\n10 m\nGround Dimension of the image\n100 km × 100 km\nRegarding instead\
    \ the multispectral images obtained by drone, it is noted that a DJI\nMatrice\
    \ 600 Pro drone [51] was used, integrating a multispectral sensor, Micasense Altum\n\
    Camera [52] suitable for use in agriculture and with the ability to capture images\
    \ of crops\nin both the visible spectrum and the infrared spectrum simultaneously.\
    \ The following\ncomponents are included in this system:\n•\nA multispectral sensor\
    \ recording crop images of crops in four spectral bands: Green\n(500 nm Bandwidth\
    \ 40 nm), Red (660 nm Bandwidth 40 nm), Red-edge (735 nm\nBandwidth 10 nm) and\
    \ Near Infrared (790 nm Bandwidth 40 nm).\n•\nAn RGB camera (16 MP).\n•\nAn integrated\
    \ 64 GB memory.\nSensors 2022, 22, 7910\n10 of 23\n•\nA built-in brightness sensor\
    \ (‘sunshine’ sensor) that records light situation and cali-\nbrates automatically\
    \ the four multispectral sensors. The ‘sunshine’ sensor inte-grates\nan SD card\
    \ slot to expand storage capacity.\n•\nGPS and IMU (Inertial Measurement Unit).\n\
    •\nTable 2 shows UAV, sensor’s image and characteristics.\nSensors 2022, 22, x\
    \ FOR PEER REVIEW \n10 of 23 \n \n \nFigure 2. WorldView-3 acquired on 21 October\
    \ 2021, resolution 30 cm, subset of the province of \nReggio Calabria including\
    \ the study area. \nRegarding instead the multispectral images obtained by drone,\
    \ it is noted that a DJI \nMatrice 600 Pro drone [51] was used, integrating a\
    \ multispectral sensor, Micasense Altum \nCamera [52] suitable for use in agriculture\
    \ and with the ability to capture images of crops \nin both the visible spectrum\
    \ and the infrared spectrum simultaneously. The following \ncomponents are included\
    \ in this system: \n• \nA multispectral sensor recording crop images of crops\
    \ in four spectral bands: Green \n(500 nm Bandwidth 40 nm), Red (660 nm Bandwidth\
    \ 40 nm), Red-edge (735 nm Band-\nwidth 10 nm) and Near Infrared (790 nm Bandwidth\
    \ 40 nm). \n• \nAn RGB camera (16 MP). \n• \nAn integrated 64 GB memory. \n• \n\
    A built-in brightness sensor (‘sunshine’ sensor) that records light situation\
    \ and cali-\nbrates automatically the four multispectral sensors. The ‘sunshine’\
    \ sensor inte-grates \nan SD card slot to expand storage capacity. \n• \nGPS and\
    \ IMU (Inertial Measurement Unit). \n• \nTable 2 shows UAV, sensor’s image and\
    \ characteristics. \nTable 2. Platforms and sensor used: DJI Matrice 600 Pro and\
    \ Micasense Altum Camera. \n \n \nNo. channels \n4 \nSpectral bands \nB2–Red 640–680\
    \ mm \nB4–NIR 770–810 nm \nGSD per band \n5.2 cm \nFlight speed \n30 km/h \nFlight\
    \ altitude \n30 m \nFOV–Field-of-view \n48° × 36.8° \nGround Dimension of \nthe\
    \ Image \n160 m × 30 m \n100 m × 35 m \nBy carefully defining the sets of waypoints\
    \ along the UAV route, it was possible to \nensure that the aircraft would fly\
    \ at a height of approximately 30 m above the ground. \nWith these parameters,\
    \ the aerial GSD images measure 5 cm (Table 2). \nFigure 2. WorldView-3 acquired\
    \ on 21 October 2021, resolution 30 cm, subset of the province of\nReggio Calabria\
    \ including the study area.\nTable 2. Platforms and sensor used: DJI Matrice 600\
    \ Pro and Micasense Altum Camera.\n \n \nFigure 2. WorldView-3 acquired on 21\
    \ October 2021, resolution 30 cm, subset of the province of \nReggio Calabria\
    \ including the study area. \nRegarding instead the multispectral images obtained\
    \ by drone, it is noted that a DJI \nMatrice 600 Pro drone [51] was used, integrating\
    \ a multispectral sensor, Micasense Altum \nCamera [52] suitable for use in agriculture\
    \ and with the ability to capture images of crops \nin both the visible spectrum\
    \ and the infrared spectrum simultaneously. The following \ncomponents are included\
    \ in this system: \n• \nA multispectral sensor recording crop images of crops\
    \ in four spectral bands: Green \n(500 nm Bandwidth 40 nm), Red (660 nm Bandwidth\
    \ 40 nm), Red-edge (735 nm Band-\nwidth 10 nm) and Near Infrared (790 nm Bandwidth\
    \ 40 nm). \n• \nAn RGB camera (16 MP). \n• \nAn integrated 64 GB memory. \n• \n\
    A built-in brightness sensor (‘sunshine’ sensor) that records light situation\
    \ and cali-\nbrates automatically the four multispectral sensors. The ‘sunshine’\
    \ sensor inte-grates \nan SD card slot to expand storage capacity. \n• \nGPS and\
    \ IMU (Inertial Measurement Unit). \n• \nTable 2 shows UAV, sensor’s image and\
    \ characteristics. \nTable 2. Platforms and sensor used: DJI Matrice 600 Pro and\
    \ Micasense Altum Camera. \n \n \nNo. channels \n4 \nSpectral bands \nB2–Red 640–680\
    \ mm \nB4–NIR 770–810 nm \nGSD per band \n5.2 cm \nFlight speed \n30 km/h \nFlight\
    \ altitude \n30 m \nFOV–Field-of-view \n48° × 36.8° \nGround Dimension of \nthe\
    \ Image \n160 m × 30 m \n100 m × 35 m \nBy carefully defining the sets of waypoints\
    \ along the UAV route, it was possible to \nensure that the aircraft would fly\
    \ at a height of approximately 30 m above the ground. \nWith these parameters,\
    \ the aerial GSD images measure 5 cm (Table 2). \n \n \nNo. channels\n4\nSpectral\
    \ bands\nB2–Red 640–680 mm\nB4–NIR 770–810 nm\nGSD per band\n5.2 cm\nFlight speed\n\
    30 km/h\nFlight altitude\n30 m\nFOV–Field-of-view\n48◦ × 36.8◦\nGround Dimension\
    \ of\nthe Image\n160 m × 30 m\n100 m × 35 m\nBy carefully deﬁning the sets of\
    \ waypoints along the UAV route, it was possible to\nensure that the aircraft\
    \ would ﬂy at a height of approximately 30 m above the ground. With\nthese parameters,\
    \ the aerial GSD images measure 5 cm (Table 2).\n3.2. Self-Driving Vehicles/GIS\n\
    Regarding self-driving vehicles, an old experiment was adapted to simulate the\
    \ be-\nhaviour of one or more tractors. The experiments we have conducted in the\
    \ past concern\nself-driving vehicles intended for road monitoring, in Figure\
    \ 3.\nIn this case, they are applied to agriculture monitoring.\nThe following\
    \ items make up the standard instrumental equipment for such surveys:\n•\ncameras\
    \ that can capture images and movies and enable the acquisition and possibly\n\
    later categorisation of objects, as well as integration with the mapping of the\
    \ network\ntechnology in the area (water, electric, telephone, gas, etc.);\n•\n\
    Odometers and GPS.\nSensors 2022, 22, 7910\n11 of 23\n \n \n3.2. Self-Driving\
    \ Vehicles/GIS \nRegarding self-driving vehicles, an old experiment was adapted\
    \ to simulate the be-\nhaviour of one or more tractors. The experiments we have\
    \ conducted in the past concern \nself-driving vehicles intended for road monitoring,\
    \ in Figure 3. \n \nFigure 3. Equipped self-driving vehicle. \nIn this case, they\
    \ are applied to agriculture monitoring. \nThe following items make up the standard\
    \ instrumental equipment for such surveys: \n• \ncameras that can capture images\
    \ and movies and enable the acquisition and possibly \nlater categorisation of\
    \ objects, as well as integration with the mapping of the network \ntechnology\
    \ in the area (water, electric, telephone, gas, etc.); \n• \nOdometers and GPS.\
    \ \nThe combination of uses will be determined by the kind of survey being conducted\
    \ \nor the result that is to be obtained. \nThe use of Global Navigation Satellite\
    \ System (GNSS) data and the transfer of infor-\nmation between the vehicle and\
    \ the processing centre are essential components of any \ntracking system. In\
    \ order to determine the position of the vehicle automatically, an exper-\niment\
    \ was carried out in advance to assess the efficacy of the various configurations;\
    \ we \nselected the European Geostationary Navigation Overlay System (EGNOS) and\
    \ the Real-\nTime Kinematic (RTK) method to check their respective performances.\
    \ \nThe technological components of the system consist of a device for detecting\
    \ the po-\nsition (GPS), a transmission device (mobile phone), and a data processing\
    \ centre equipped \nwith a GIS platform. In addition to other information that\
    \ is gleaned from active sensors \non the vehicle, the data pertaining to the\
    \ vehicle’s position and its instantaneous speed \nare transmitted from the vehicle\
    \ to a processing point that is in charge of maintaining a \ndatabase of field\
    \ data. \nUsing a digital map of the area, special algorithms were applied to\
    \ reduce errors, as \npositioning errors were present. These algorithms combine\
    \ the position and trajectory of \nthe vehicle as determined by the sensors with\
    \ the routes that are available on the digital \nmap. In the meantime, the information\
    \ that is sent from the vehicle using the various sen-\nsors used enables an update\
    \ to be made to the maps in terms of the routes to optimise the \ntractor’s path.\
    \ \nIn order to determine the location of the vehicle, we analysed the results\
    \ of both the \nEGNOS and RTK positioning systems and compared them. However,\
    \ in order to calculate \nthe position object, the RTK method requires real-time\
    \ data processing, whereas the \nEGNOS system immediately provides location data.\
    \ Although it requires more computa-\ntional work, RTK provides more precise results\
    \ than EGNOS does. When it comes to hard-\nware instrumentation and software,\
    \ the use of EGNOS is reliant on commercially availa-\nble devices, whereas the\
    \ RTK method necessitates the creation of customized software \narchitecture.\
    \ \nIn terms of communication systems, the possibility of using a Wi-Fi network\
    \ offers \nbenefits in terms of costs and speed as a result of the extremely low\
    \ latency, but it also \nFigure 3. Equipped self-driving vehicle.\nThe combination\
    \ of uses will be determined by the kind of survey being conducted or\nthe result\
    \ that is to be obtained.\nThe use of Global Navigation Satellite System (GNSS)\
    \ data and the transfer of infor-\nmation between the vehicle and the processing\
    \ centre are essential components of any\ntracking system. In order to determine\
    \ the position of the vehicle automatically, an ex-\nperiment was carried out\
    \ in advance to assess the efﬁcacy of the various conﬁgurations;\nwe selected\
    \ the European Geostationary Navigation Overlay System (EGNOS) and the\nReal-Time\
    \ Kinematic (RTK) method to check their respective performances.\nThe technological\
    \ components of the system consist of a device for detecting the posi-\ntion (GPS),\
    \ a transmission device (mobile phone), and a data processing centre equipped\n\
    with a GIS platform. In addition to other information that is gleaned from active\
    \ sensors\non the vehicle, the data pertaining to the vehicle’s position and its\
    \ instantaneous speed\nare transmitted from the vehicle to a processing point\
    \ that is in charge of maintaining a\ndatabase of ﬁeld data.\nUsing a digital\
    \ map of the area, special algorithms were applied to reduce errors, as\npositioning\
    \ errors were present. These algorithms combine the position and trajectory of\n\
    the vehicle as determined by the sensors with the routes that are available on\
    \ the digital\nmap. In the meantime, the information that is sent from the vehicle\
    \ using the various\nsensors used enables an update to be made to the maps in\
    \ terms of the routes to optimise\nthe tractor’s path.\nIn order to determine\
    \ the location of the vehicle, we analysed the results of both the\nEGNOS and\
    \ RTK positioning systems and compared them. However, in order to calculate\n\
    the position object, the RTK method requires real-time data processing, whereas\
    \ the EGNOS\nsystem immediately provides location data. Although it requires more\
    \ computational work,\nRTK provides more precise results than EGNOS does. When\
    \ it comes to hardware instru-\nmentation and software, the use of EGNOS is reliant\
    \ on commercially available devices,\nwhereas the RTK method necessitates the\
    \ creation of customized software architecture.\nIn terms of communication systems,\
    \ the possibility of using a Wi-Fi network offers\nbeneﬁts in terms of costs and\
    \ speed as a result of the extremely low latency, but it also offers\ndrawbacks\
    \ in terms of the distance limits that can exist between antennas and the signal\n\
    quality that can be achieved. In most cases, the maximum permissible distance\
    \ between\nantennas is one hundred meters when the weather is clear, there is\
    \ a direct line of sight\nbetween them, and there are no obstructions in the way.\
    \ The signal quality can be affected\nby a variety of parameters, including the\
    \ kind of antenna that is used and the possibility\nof interference.\nThe use\
    \ of the mobile phone network, on the other hand, has a number of beneﬁts,\nincluding\
    \ complete independence among stations and vehicles, increased reliability due\n\
    to the fact that it does not require compliance with minimum distances, and the\
    \ capacity\nto process remote data remotely. The disadvantages include signiﬁcantly\
    \ higher latencies\nand increased costs. This is due to the fact that every device\
    \ needs to be outﬁtted with a\nmobile network modulus and a SIM card that is associated\
    \ with a particular data plan or a\nphone contract.\nSensors 2022, 22, 7910\n\
    12 of 23\nAn open-source GIS/WebGIS was used for the processing and visualisation\
    \ of the\nvarious data acquired. The GIS/WebGIS displays the results of the processing\
    \ and the\noptimal routing of the routes, as well as highlighting the needs and\
    \ requirements of the\narea, such as the need for irrigation timing, fertilisation\
    \ timing, and anything else that may\nbe useful for Agriculture 4.0, with appropriate\
    \ alerts based on data fusion with other data.\nIn order to verify the effectiveness\
    \ of the development, a platform for transmission to\nthe GIS and user interface\
    \ is created; it runs a procedure called Data Transfer GIS (DTGIS)\nfor the subsequent\
    \ export of the data acquired within the GIS, where the “historical” update\n\
    is managed in the existing database.\nIn more detail, the DTGIS was designed to\
    \ automatically transfer data acquired in\nthree software modules, each with its\
    \ own set of functions, to the GIS:\nThe Plug-in Module, which increases the number\
    \ of recognizable and classiﬁable\nobjects that can be represented;\nThe kernel,\
    \ which interacts with users and coordinates the different modules, pre-\nprocessing\
    \ and post-processing the Input/Output data of the modules themselves;\nThe GIS\
    \ I/O (Input/Output) Module, which manages the interface with the GIS software.\n\
    In particular, the ﬁles (space database where the various attributes have been\
    \ assigned\nto the objects) are given in Input in the GIS I/O module, returning\
    \ Output polylines and\npolygons in shp-dbf format.\nTo implement the proposed\
    \ system, a variety of algorithms and methodologies were\nused. Speciﬁcally, a\
    \ multi-objective function based on Genetic Algorithms was used to\ndetermine\
    \ the tractor’s route.\nFurthermore, using Machine Learning algorithms, real-time\
    \ hourly and continuous\ncycle trend information was obtained based on a comparison\
    \ with recent and historical\ndata (including the Backpropagation algorithm for\
    \ the historical series).\nIFTTT (If This Then That) is a programming language\
    \ that allows for the real-time\ncreation of condition chains called applets that\
    \ are triggered by other services (e.g., Gmail,\nFacebook, Instagram, etc.) and\
    \ can send a message when the user, for example, uses a\nhashtag in a tweet, or\
    \ can send a copy of a Facebook photo to an archive when the user is\ntagged in\
    \ it. IFTTT can automate processes related to home automation or web applications,\n\
    such as receiving personalized weather forecasts or alerts in the event of an\
    \ emergency,\nsuch as a ﬂood. In our case, we used this service to send alerts\
    \ and to automate tractor’s\nroute when an alert is received.\nApplet programming\
    \ logic is of the following type: if a predetermined event occurs\n(trigger),\
    \ then perform a predetermined action.\n3.3. Other Types of Sensors\nA wide range\
    \ of available sensors can contribute signiﬁcantly to agricultural practices.\n\
    With the availability of low-cost data processing, solar panels, improved batteries\
    \ and\ncommunications technology, the trend is now for these to operate wirelessly\
    \ and transmit\ndata to the user rather than relying on manual data collection.\
    \ A variety of sensors are\navailable for this purpose, including soil temperature,\
    \ soil moisture content, air temperature\nand relative humidity, rainfall, solar\
    \ radiation, barometric pressure, leaf wetness and wind\nspeed and direction.\n\
    3.3.1. Soil Moisture Sensor\nAs mentioned above, the ability to integrate several\
    \ sensors is of crucial importance.\nFor example, the Soil Moisture Sensor is\
    \ used to measure volumetric moisture content of\nsoils and other material for\
    \ scientiﬁc research and agricultural applications. The sensor\nmeasures volumetric\
    \ water content via the dielectric constant of the soil using capacitance\ntechnology.\
    \ It uses a 70 MHz frequency, which minimizes salinity and textural effects,\n\
    making it an ideal sensor in agricultural and standard scientiﬁc projects. Speciﬁcations\
    \ on\ncharacteristics of the Soil Moisture Sensor are given in Table 3.\nSensors\
    \ 2022, 22, 7910\n13 of 23\nTable 3. Characteristics of the Soil Moisture Sensor.\n\
    Property\nCharacteristics\nAccuracy\nApparent Dielectric Permittivity (εa): ±0.5\
    \ from εa of 2 to 10, ±2.5\nfrom εa of 10 to 50\nSoil Volumetric Water Content\
    \ (VWC): Using standard calibration\nequation: ±0.03 m3/m3 (±3% VWC) typical in\
    \ mineral soils that have\nsolution electrical conductivity < 10 dS/m; using soil\
    \ speciﬁc\ncalibration, ±0.02 m3/m3 (±2% VWC) in any soil\nResolution\nεa: 0.1\
    \ from εa of 1 to 30, 0.2 from εa of 30 to 50\nVWC: 0.0008 m3/m3 (0.08% VWC) in\
    \ mineral soils from 0 to 0.50\nm3/m3 (0–50% VWC).\nRange\nεa: 1 (air) to 50\n\
    VWC: Calibration dependent; up to 0–57% VWC with\npolynomial equation\nSensor\
    \ Type\nCapacitance (frequency domain)\nDimensions\n14.5 cm × 3.3 cm × 0.7 cm\n\
    5.5\nReduced soil microbial activity\nCable length\nSensors come standard with\
    \ 5 m cable. Custom cable lengths available.\nMaximum cable length of 40 m. Please\
    \ contact Decagon if you need\nlonger cable lengths.\nMeasurement Time\n10 ms\n\
    Power\n3 VDC @ 12 mA–15 VDC @ 15 mA\nOutput\n300–1250 mV, independent of excitation\
    \ voltage\nOperative\nEnvironment\nSurvival Temperature: −40–50 ◦C\nOperating\
    \ Temperature: 0–50 ◦C\nConnector Types\n3.5 mm “stereo” plug or stripped and\
    \ tinned lead wires\n3.3.2. Leaf Wetness Sensor\nMost of these are based on well-known\
    \ techniques and are used in other applications,\nbut the leaf wetness sensor\
    \ is aimed speciﬁcally at agricultural use and comprises a surface\nof conductive\
    \ combs with a resistance of 2 MΩ when dry. This falls when condensation\noccurs\
    \ on the surface, reaching approximately 5 kΩ when completely wet. The sensor\n\
    generates a voltage that is inversely proportional to the degree of condensation.\n\
    3.3.3. PH Sensor\nThe PH (Potential Hydrogen) meter is a device used to measure\
    \ acidity and alkalinity\nlevels in water, soil and photo chemicals. The PH meter\
    \ consists of a voltmeter attached to\na pH-responsive electrode varying in the\
    \ range of 0 to 14.\nThe solutions with a pH value between 0 and 7 are acidic\
    \ solutions with a large\nconcentration of hydrogen ions, whereas solutions with\
    \ a pH value between 8 and 14 have\nbasic solutions with small concentrations\
    \ of hydrogen. Solutions with a pH value of 7 are\nneutral solutions. In this\
    \ process, we can detect the pH levels in the soil, in Table 4.\n3.3.4. Temperature\
    \ and Humidity Sensor\nThe sensor has a humidity measuring module, a thermistor\
    \ and an integrated circuit on\nthe back of the sensor unit. The humidity measurement\
    \ module consists of two electrodes.\nSandwiched between the two electrodes is\
    \ a substrate that is capable of holding moisture.\nChange in humidity alters\
    \ the conductivity of the moisture-holding substrate, which at the\nsame time\
    \ changes the resistance. The integrated circuit then processes the change in\
    \ the\nresistance and the humidity value is measured. On the other hand, a change\
    \ in temperature\nchanges the resistance of the thermistor, which is processed\
    \ by the integrated circuit and\nthe calibration results in a temperature value.\n\
    Sensors 2022, 22, 7910\n14 of 23\nTable 4. PH (potential of Hydrogen) values and\
    \ plants growth.\nSoil pH\nPlant Growth\n>8.3\nToo alkaline for most plants\n\
    7.5\nIron availability becomes a problem on alkaline soils.\n7.2\n6.8 to 7.2–near\
    \ neutral\n6.0 to 7.5–acceptable for most plants\n7.0\n6.8\n5.5\nReduced soil\
    \ microbial activity\n<4.6\nToo acidic for most plants\n3.3.5. Barometric Pressure\
    \ Sensor\nBarometric pressure sensors measure the absolute pressure of the air\
    \ around them.\nThis pressure varies with both the weather and altitude. Depending\
    \ on how you interpret\nthe data, you can monitor changes in the weather, measure\
    \ altitude, or any other tasks that\nrequire an accurate pressure reading. The\
    \ sensor consists of a piezoelectric transducer based\non the characteristic of\
    \ silicon to generate an electrical potential difference proportional to\nthe\
    \ mechanical stress applied on its surface. This type of transducer is characterized\
    \ by\nextremely accurate performance and stable measurements of atmospheric pressure,\
    \ with\nexcellent repeatability and low hysteresis. An electronic ampliﬁer circuit\
    \ normalizes the\noutput signal in the most common formats used by acquisition\
    \ circuits (0–1 V, 4–20 mA).\nAn electrical circuit for compensating the temperature\
    \ allows more accurate measurements.\n3.4. Data Fusion\nAs mentioned in Section\
    \ 2.4, we use two different methodologies to perform data\nfusion on satellite\
    \ and drone images, as well as data fusion on various types of sensors.\nSensors\
    \ are used in agriculture for everything from weather monitoring to self-\nwatering.\
    \ Designers can create a prototype for a hardware environment to implement\nthe\
    \ data acquisition and mining process by using low-cost sensors. Thus, the relationship\n\
    between sensors can be understood, and a sensor fusion test environment can be\
    \ created.\nVarious input devices are synchronized using a microcontroller system,\
    \ and all data ob-\ntained from the sensors is wirelessly sent to the cloud by\
    \ an IoT (Internet of Things) device,\nby recording and monitoring from the graphical\
    \ user interface on the web as a real-time\nenvironment to apply data mining algorithms\
    \ later. So, we obtain sensor data relations\nfrom various different data sources,\
    \ such as soil moisture, but it is also possible to obtain\ndata on light, temperature,\
    \ humidity, rain, atmospheric pressure, air quality, and dew point.\nIn the ﬁrst\
    \ experiment illustrated here, we use the soil moisture sensor. Each sensor data\n\
    reading has a different effect on agricultural monitoring; however, reducing the\
    \ number of\nsensors can reduce the cost of a system while still providing accurate\
    \ observations via the\nproposed sensor substitution. A hardware test prototype,\
    \ as well as a software design, are\ncreated for data monitoring and sensor fusion\
    \ in various combinations.\nAcquiring useful data from agricultural areas has\
    \ always been difﬁcult because they\nare often vast, remote, and vulnerable to\
    \ weather events. Despite these obstacles, as\ntechnology advances and prices\
    \ fall, a ﬂood of new data is being collected. Although\na wealth of data is being\
    \ collected at various scales (e.g., proximal, aerial, satellite, and\nancillary\
    \ data), this has been geographically unequal, leaving some areas virtually devoid\n\
    of useful data to help them face their speciﬁc challenges. However, even in areas\
    \ with\nabundant resources and well-developed infrastructure, data and knowledge\
    \ gaps persist,\nowing to the fact that agricultural environments are mostly uncontrolled\
    \ and there are\na plethora of factors that must be considered and properly measured\
    \ in order to fully\ncharacterize a given area. As a result, even with very effective\
    \ algorithms and a well-\ndeﬁned and limited-scope problem, data from a single\
    \ sensor type are frequently unable to\nprovide unambiguous answers. One possible\
    \ solution that has been researched for decades\nis fusing the information contained\
    \ in different sensors and data types. The concept behind\ndata fusion is to investigate\
    \ the complementarities and synergies of various types of data in\nSensors 2022,\
    \ 22, 7910\n15 of 23\norder to extract more reliable and useful information about\
    \ the areas being studied. While\nsome success has been achieved, there are still\
    \ many obstacles that prevent this type of\napproach from becoming more widely\
    \ adopted. This is especially true in agricultural areas,\nwhich have highly complex\
    \ environments.\nAmong the various data fusion methods, kriging was used, the\
    \ weights of which were\nthought of as space variants and determined from calculations\
    \ applied to plant growth\nphenomenology. In other words, rainfall and weather\
    \ values in general, NDVI at varying\nseasons, and soil type were sampled at certain\
    \ target points, from which a certain value of\nsoil moisture was estimated. From\
    \ these values, kriging was carried out at the location of\nthe moisture sensor\
    \ and compared with this truth value. The typical abatement parameters\nof the\
    \ method are varied until a conﬁguration of minima is found for which the value\n\
    calculated by kriging and the value measured by the sensor are small. At this\
    \ point, these\nabatement parameters can be used for kriging applicators to neighbouring\
    \ areas, either\nfrom points observed by humidity sensors or derived from other\
    \ devices.\nSo far, we have talked about data fusion between different sensors,\
    \ but data fusion\nbetween images and sensors is also possible, as is the use\
    \ of neural networks to improve\nimage resolution.\nThe technology associated\
    \ with the use of drones has undergone strong development\nin the last decade\
    \ by improving the stability of the craft, lightening the structure, perfect-\n\
    ing the precision and accuracy of acquisition and optimising the software for\
    \ processing\ndata. Among other things, this technology ﬁnds application in environmental\
    \ monitoring,\ncombining data acquisition over a wide area with high resolution\
    \ and multispectral infor-\nmation. However, surveying with UAVs (Unmanned Aerial\
    \ Vehicles) is not always cheaper\nthan using satellite data. This is where the\
    \ use of machine learning, and in particular,\nSuperResolution, comes in.\nThe\
    \ freely available satellite data, as far as the Sentinel missions of the Copernicus\n\
    programme are concerned, give a considerable advantage, but the resolution of\
    \ these data\nmay be too low for the studies to be carried out. It is therefore\
    \ necessary to intervene\nwith processing methods to improve the quality of the\
    \ data. Furthermore, the timing of\nacquisition favours the use of satellite data\
    \ over the drone survey and the processing of the\nrelated data because it is\
    \ time-consuming. The satellite data, on the other hand, supplied\nalready corrected\
    \ in terms of reﬂectance, are directly usable after downloading.\nWith the use\
    \ of a convolutional neural network, a procedure is applied that uses the\nsatellite\
    \ images as the basic data and allows a higher resolution product to be obtained.\
    \ To\nachieve this, the VDSR (Very Deep Super Resolution) neural network is iplemented,\
    \ using\nimages acquired by drone for training the network. The aim of this work\
    \ is to study the\napplicability of the VDSR (Very Deep Super Resolution) neural\
    \ network in the context of\nremote sensing, using drone images as data.\nSuper-resolution,\
    \ a process for obtaining high-resolution images from low-resolution\nimages,\
    \ compensates in Remote Sensing for limitations due to a spatial resolution that\
    \ is\nnot always adequately detailed. Single Image Super-Resolution (SIRS), in\
    \ particular, aims\nto construct a high-resolution image from a single low-resolution\
    \ image. A basic approach\nto achieve the improvement of an image’s resolution\
    \ is interpolation, but there are other,\nmore elaborate strategies that have\
    \ the same goal.\nThe deep learning algorithm VDSR (Very-Deep Super-Resolution)\
    \ is one of the possible\ntechniques that can be used to perform the SISR process.\
    \ Initially, the training of the\nneural network is necessary in order to then\
    \ use the VDSR network to obtain a high-\nresolution image from a single low-resolution\
    \ image. VDSR is a convolutional neural\nnetwork CNN (Convolutional Neural Network)\
    \ with the aim of relating high- and low-\nresolution images that differ mainly\
    \ in high-frequency detail. The procedure is based on\ndetermining the residuals\
    \ between the two images, i.e., a high-resolution reference image\nand a low-resolution\
    \ image scaled to the same size as the reference image by means of\nbicubic interpolation.\n\
    Sensors 2022, 22, 7910\n16 of 23\nThe objective of the multispectral analysis\
    \ was the calculation of the NDVI index,\nwhich can be obtained from the Red and\
    \ NIR band.\nThe tests carried out on areas of different extension highlight the\
    \ different possibility of\nusing the image processed with the VDSR network as\
    \ the survey area varies. For a portion\nof territory of the order of magnitude\
    \ of one hundred metres, the data acquired with a\ndrone possess resolution and\
    \ detail that the other images cannot represent. For an area of\napproximately\
    \ 25 hectares, the improvement obtained by processing with the VDSR neural\nnetwork\
    \ is enhanced; the extension is high enough to evaluate the use of the drone carefully,\n\
    but not so large as to accept the detail of the satellite image. Here, the use\
    \ of the neural\nnetwork emphasises the edges of the framed elements more strongly,\
    \ making them more\neasily recognisable. For an analysis area of the order of\
    \ magnitude of several kilometres\nsideways or larger, processing with a VDSR\
    \ neural network offers an improvement, but\nthe detail required by the study\
    \ can also be satisﬁed by using the original satellite image.\nA crucial aspect\
    \ in the application of deep learning, which must be carefully evaluated in\n\
    combination with the desired image enhancement, is the computing power required\
    \ to\nperform the processing. The processing time for both the training of the\
    \ neural network\nand its activation is non-negligible if adequate equipment is\
    \ not available. To give an\nexample, the training of the VDSR network used for\
    \ the analyses in this study would have\ntaken about ten days on an average commercial\
    \ laptop with an Intel Core i5 5th Generation\nprocessor and 8-Gigabyte RAM. Furthermore,\
    \ obtaining an image with a larger pixel size\nthan the satellite image also increases\
    \ the calculation time for subsequent processing, such\nas classiﬁcation. The\
    \ time factor negatively affects the evaluation of the practical use of the\n\
    neural network, particularly when compared to other methods of improving the resolution\n\
    of an image, such as interpolation.\n4. Results\nAfter selecting from the Sentinel\
    \ and WorldView images and UAVs multispectral im-\nages, and other sensor (Soil\
    \ Moisture Sensor) data, a data fusion procedure was performed\nwith particular\
    \ reference to areas A and B (Figure 4). So, a procedure has been put into place\n\
    so that the value of the NDVI can be automatically determined from satellite images.\
    \ In\norder to achieve homogenization of Sentinel and UAV data, it is necessary\
    \ to automatically\ndetermine the value of NDVI derived from satellites (NDVIsat),\
    \ through a downsampling\nof correlation between pixels s(i,j) from satellite\
    \ and P(i,j) from UAV), to calculate the NDVI\nfrom UAV (NDVIuav) and to calculate\
    \ both the NDVI for the leaf canopies of the vines\n(NDVIvin) and NDVI of inter-row\
    \ area (NDVIint). In fact, an important tool for evaluating\nthe variability in\
    \ the vineyard and therefore the vines’ vigour is the NDVI index, thus\ncalculated\
    \ for the pixels of the Sentinel and WorldView image s(i,j) thanks to the spectral\n\
    data) in RED and NIR bands:\nNDVIsat(i, j) = nN(i, j) − nR(i, j)\nnN(i, j) + nR(i,\
    \ j)\n(2)\nA preliminary downsampling method of the high-resolution UAV images\
    \ was used to\nallow the comparison of the UAV-based MSI and the satellite imaging.\
    \ So, we proceeded to\nsampling the UAVs, data (at higher resolution) for comparing\
    \ them with the corresponding\nsatellite data, i.e., the set of UAV data D corresponding\
    \ to P(i,j):\nG(i, j) = {d(u, v) ∈ D|αs(i, j + 1) ≤ αd(u, v) < αs(i, j), βs(i,\
    \ j) ≤ βd(u, v) < βs(i + 1, j), ∀u, v}\n(3)\nThus the satellite data s(i,j) and\
    \ UAV data P(i,j) show the same subset of the vineyard.\nThree NDVIs were analysed\
    \ from the VHR 2 data from the multispectral sensor mounted\non the UAV, then\
    \ compared with the satellite data on:\n•\n(i) the entire cultivated area P(i,j):\n\
    Sensors 2022, 22, 7910\n17 of 23\nNDVIuav(i, j) =\n∑u ∑v\nmN(u,v)−mR(u,v)\nmN(u,v)+mR(u,v)\n\
    card P(i, j)\n∀d(u, v) ∈ P(i, j)\n(4)\n•\n(ii) the pixels of the canopies:\nNDVIvin(i,\
    \ j) =\n∑u ∑v\nmN(u,v)−mR(u,v)\nmN(u,v)+mR(u,v)\ncard P(i, j)\n∀d(u, v) ∈ Pvin(i,\
    \ j)\n(5)\n•\n(iii) the pixels of the inter-rows:\nNDVIint(i, j) =\n∑u ∑v\nmN(u,v)−mR(u,v)\n\
    mN(u,v)+mR(u,v)\ncard P(i, j)\n∀d(u, v) ∈ Pint(i, j)\n(6)\nSensors 2022, 22, x\
    \ FOR PEER REVIEW \n18 of 23 \n \nαd(u,v) \nLatitude coordinate (in WGS84) of\
    \ pixel d(u,v) centre \nαs(i,j) \nLatitude coordinate (in WGS84) of the upper\
    \ left corner of pixel s(i,j) \nβd(u,v) \nLongitude coordinate (in WGS84) of pixel\
    \ d(u,v) centre \nβs(i,j) \nLongitude coordinate (in WGS84) of the upper left\
    \ corner of pixel s(i,j) \nIn Figure 4 the results are shown. \nFigure 4a shows\
    \ the full set of pixels obtained from the NDVIsat map, selected from \nSatellite\
    \ imagery. \nIn Figure 4b an NDVIuav map congruent (correctly aligned, at the\
    \ same spatial reso-\nlution) to those derived from satellite imagery (NDVIsat)\
    \ is shown. \nIn Figure 4c a complete NDVIvin map is shown. \nIn Figure 4d the\
    \ NDVIint map of the inter-row ground, derived by processing the \nUAV images\
    \ is shown. \n \nFigure 4. Complete NDVI (Normalized Difference Vegetation Index)\
    \ maps: (a) NDVIsat map, with \npixels fully included in “Area A” and “Area B”,\
    \ derived from satellite images S2, and (b) NDVIuav \nobtained from UAV images\
    \ D2. (c) Vineyard NDVIvin map from UAV images D2 obtained only on \ncanopy pixels\
    \ Pvin, (d) NDVIint map that considers inter-row ground Pint. \nThe use of an\
    \ image with a resolution of approximately 30 centimetres, such as a \nWorldView-3,\
    \ would still enable a better definition of the vigour of the vines and, more\
    \ \ngenerally, of the row crops. This is despite the fact that the resolution\
    \ of the drone data is \nnot comparable to that of the image. \nThe ground sampling\
    \ distance (GSD) for the panchromatic band on WorldView-3 is \n31 centimetres,\
    \ while the GSD for the eight multispectral bands is 124 centimetres. Pro-\nceeding\
    \ in the same manner as here with the UAV and using imagery obtained from the\
    \ \nWorldView-3 satellite would result in an analysis of the vigour that is significantly\
    \ more \naccurate. We could also provide a verification with Object-Based Image\
    \ Analysis (OBIA), \nfirst using segmentation of the canopies and inter-row areas,\
    \ then proceeding separately \nto the classification of the vigour through the\
    \ various NDVIs found in the extraction of \nthe objects formed with OBIA. Because\
    \ the spaces between the rows are distinguishable \n(the data obtained from the\
    \ decametric satellite sensor contribute to an inaccurate under-\nstanding of\
    \ the actual vigour of the vines), we could also provide verifying (extracting\
    \ \nobjects directly from satellite imagery is one of the strengths of OBIA, which\
    \ is used in a \nwide range of applications [22,24]). \nData fusion techniques\
    \ make it possible to obtain complete information on an area \nand on the needs\
    \ connected to cultivation from the fusion of different data [40,41] such as \n\
    Figure 4. Complete NDVI (Normalized Difference Vegetation Index) maps: (a) NDVIsat\
    \ map, with\npixels fully included in “Area A” and “Area B”, derived from satellite\
    \ images S2, and (b) NDVIuav\nobtained from UAV images D2. (c) Vineyard NDVIvin\
    \ map from UAV images D2 obtained only on\ncanopy pixels Pvin, (d) NDVIint map\
    \ that considers inter-row ground Pint.\nIn Figure 4 the results are shown.\n\
    Figure 4a shows the full set of pixels obtained from the NDVIsat map, selected\
    \ from\nSatellite imagery.\nIn Figure 4b an NDVIuav map congruent (correctly aligned,\
    \ at the same spatial resolu-\ntion) to those derived from satellite imagery (NDVIsat)\
    \ is shown.\nIn Figure 4c a complete NDVIvin map is shown.\nIn Figure 4d the NDVIint\
    \ map of the inter-row ground, derived by processing the UAV\nimages is shown.\n\
    Table 5 shows the nomenclature of the symbols used.\nThe use of an image with\
    \ a resolution of approximately 30 centimetres, such as a\nWorldView-3, would\
    \ still enable a better deﬁnition of the vigour of the vines and, more\ngenerally,\
    \ of the row crops. This is despite the fact that the resolution of the drone\
    \ data is\nnot comparable to that of the image.\nSensors 2022, 22, 7910\n18 of\
    \ 23\nTable 5. Nomenclature.\nTerm\nNomenclature\nd(u,v)\nPixel in row u and column\
    \ v of D, raster matrix\nD\nHigh-resolution UAV multispectral image\nP(i,j)\n\
    UAV pixels d(u,v) depicting the area of satellite pixels s(i,j)\nPvin(i,j)\nUAV\
    \ pixels d(u,v) showing only vines canopy\nPint(i,j)\nUAV pixels d(u,v) depicting\
    \ only inter-row ground\nNDVIsat(i,j)\nNDVI estimated using satellite images S\n\
    NDVIuav(i,j)\nEntire NDVI calculated on UAV pixels in P(i,j)\nNDVIvin(i,j)\nNDVI\
    \ calculated only on UAV pixels Pvin(i,j) that represent the vine canopy\nNDVIint(i,j)\n\
    NDVI calculated only on UAV pixels Pint(i,j) showing inter-row ground\nmN(i,j)\n\
    Reﬂectance values in the NIR band of pixels d(u,v)\nmR(i,j)\nDNs in the red band\
    \ of pixels d(u,v)\nnN(i,j)\nDNs in the NIR band of pixels s(i,j)\nnR(i,j)\nDNs\
    \ in the red band of pixels s(i,j)\ns(i,j)\nPixels of row i and column j in the\
    \ raster matrix S\nS\nMultispectral image 10 m resolution from Sentinel satellite\n\
    αd(u,v)\nLatitude coordinate (in WGS84) of pixel d(u,v) centre\nαs(i,j)\nLatitude\
    \ coordinate (in WGS84) of the upper left corner of pixel s(i,j)\nβd(u,v)\nLongitude\
    \ coordinate (in WGS84) of pixel d(u,v) centre\nβs(i,j)\nLongitude coordinate\
    \ (in WGS84) of the upper left corner of pixel s(i,j)\nThe ground sampling distance\
    \ (GSD) for the panchromatic band on WorldView-3\nis 31 centimetres, while the\
    \ GSD for the eight multispectral bands is 124 centimetres.\nProceeding in the\
    \ same manner as here with the UAV and using imagery obtained from\nthe WorldView-3\
    \ satellite would result in an analysis of the vigour that is signiﬁcantly\nmore\
    \ accurate. We could also provide a veriﬁcation with Object-Based Image Analysis\n\
    (OBIA), ﬁrst using segmentation of the canopies and inter-row areas, then proceeding\n\
    separately to the classiﬁcation of the vigour through the various NDVIs found\
    \ in the\nextraction of the objects formed with OBIA. Because the spaces between\
    \ the rows are\ndistinguishable (the data obtained from the decametric satellite\
    \ sensor contribute to an\ninaccurate understanding of the actual vigour of the\
    \ vines), we could also provide verifying\n(extracting objects directly from satellite\
    \ imagery is one of the strengths of OBIA, which is\nused in a wide range of applications\
    \ [22,24]).\nData fusion techniques make it possible to obtain complete information\
    \ on an area\nand on the needs connected to cultivation from the fusion of different\
    \ data [40,41] such as\nsatellite data and UAV images, but also from different\
    \ sensors such as soil moisture sensors\n(as Big Data [53]).\nThe automatic vehicle\
    \ is useful as it is capable of working in any terrain including\ndifﬁcult terrain\
    \ conditions, reducing human intervention.\nFigure 5 depicts the optimized tractor\
    \ path derived from data analysis, with the\nattention points for fertilization/irrigation\
    \ derived from data fusion in green.\nFinally, the GIS displays the results of\
    \ the processing (Figure 6) and the optimal\nrouting of the routes (Figure 5),\
    \ and also highlights with appropriate alerts, depending\non the data fusion with\
    \ other data, the needs and requirements of the area, such as the\nneed for irrigation\
    \ timing, fertilisation timing and anything else that may be useful for\nAgriculture\
    \ 4.0.\nFurthermore, the use of historical data implemented in the GIS makes it\
    \ possible to\nhighlight areas where the analysis of historical and socio-economic\
    \ data makes a different\nkind of cultivation appropriate (Figure 7).\nSensors\
    \ 2022, 22, 7910\n19 of 23\n \nsatellite data and UAV images, but also from different\
    \ sensors such as soil moisture sen-\nsors (as Big Data [53]). \nThe automatic\
    \ vehicle is useful as it is capable of working in any terrain including \ndifficult\
    \ terrain conditions, reducing human intervention. \nFigure 5 depicts the optimized\
    \ tractor path derived from data analysis, with the at-\ntention points for fertilization/irrigation\
    \ derived from data fusion in green. \n \nFigure 5. The optimised tractor path\
    \ obtained from data analysis, with the attention points for fer-\ntilisation/irrigation\
    \ obtained from data fusion shown in green. \nFinally, the GIS displays the results\
    \ of the processing (Figure 6) and the optimal rout-\ning of the routes (Figure\
    \ 5), and also highlights with appropriate alerts, depending on the \ndata fusion\
    \ with other data, the needs and requirements of the area, such as the need for\
    \ \nirrigation timing, fertilisation timing and anything else that may be useful\
    \ for Agriculture \n4.0. \n \n \nFigure 6. GIS (Geographic Information System),\
    \ VHR (Very High Resolution) image: green = NDVI \n(Normalized Difference Vegetation\
    \ Index) high; yellow = NDVI medium; red = NDVI low. \nFurthermore, the use of\
    \ historical data implemented in the GIS makes it possible to \nhighlight areas\
    \ where the analysis of historical and socio-economic data makes a different \n\
    kind of cultivation appropriate (Figure 7). \nFigure 5. The optimised tractor\
    \ path obtained from data analysis, with the attention points for\nfertilisation/irrigation\
    \ obtained from data fusion shown in green.\n \ntention points for fertilization/irrigation\
    \ derived from data fusion in green. \n \nFigure 5. The optimised tractor path\
    \ obtained from data analysis, with the attention points for fer-\ntilisation/irrigation\
    \ obtained from data fusion shown in green. \nFinally, the GIS displays the results\
    \ of the processing (Figure 6) and the optimal rout-\ning of the routes (Figure\
    \ 5), and also highlights with appropriate alerts, depending on the \ndata fusion\
    \ with other data, the needs and requirements of the area, such as the need for\
    \ \nirrigation timing, fertilisation timing and anything else that may be useful\
    \ for Agriculture \n4.0. \n \n \nFigure 6. GIS (Geographic Information System),\
    \ VHR (Very High Resolution) image: green = NDVI \n(Normalized Difference Vegetation\
    \ Index) high; yellow = NDVI medium; red = NDVI low. \nFurthermore, the use of\
    \ historical data implemented in the GIS makes it possible to \nhighlight areas\
    \ where the analysis of historical and socio-economic data makes a different \n\
    kind of cultivation appropriate (Figure 7). \nFigure 6. GIS (Geographic Information\
    \ System), VHR (Very High Resolution) image: green = NDVI\n(Normalized Difference\
    \ Vegetation Index) high; yellow = NDVI medium; red = NDVI low.\nEven though the\
    \ method is still experimental, exploiting applications that have already\nbeen\
    \ individually tested in other areas, these analyses nevertheless make it possible\
    \ to\nclearly highlight what the contribution to Agriculture 4.0 can be from the\
    \ integration of\nthe various technologies of Geomatics. In particular, with the\
    \ experiments carried out, it\nis possible to identify on a study area the optimal\
    \ routes for tractors, the points where\nirrigation and top dressing are required,\
    \ the areas that need intervention and the areas of\nvineyard vigour estimated\
    \ through the use of the NDVI index with the pros and cons of\nthe methodology.\n\
    Sensors 2022, 22, 7910\n20 of 23\nSensors 2022, 22, x FOR PEER REVIEW \n20 of\
    \ 23 \n \n \n \nFigure 7. GIS (Geographic Information System): areas where the\
    \ analysis of historical and socio-\neconomic data makes a different kind of cultivation\
    \ appropriate. \nEven though the method is still experimental, exploiting applications\
    \ that have al-\nready been individually tested in other areas, these analyses\
    \ nevertheless make it possible \nto clearly highlight what the contribution to\
    \ Agriculture 4.0 can be from the integration of \nthe various technologies of\
    \ Geomatics. In particular, with the experiments carried out, it \nis possible\
    \ to identify on a study area the optimal routes for tractors, the points where\
    \ \nirrigation and top dressing are required, the areas that need intervention\
    \ and the areas of \nvineyard vigour estimated through the use of the NDVI index\
    \ with the pros and cons of \nthe methodology. \n5. Conclusions \nOur article\
    \ presents an introduction to a more in-depth analysis by comparing mul-\ntispectral\
    \ vineyard imagery obtained from satellite platforms such as Sentinel-2, at a\
    \ res-\nolution of ten meters, and ultra-high-resolution imagery acquired from\
    \ WorldView satel-\nlite and low-altitude UAV platforms. Using NDVI as a measure\
    \ of vineyard vitality, we \ncompared the usefulness of the images obtained from\
    \ the specified satellites and those \nobtained from UAVs. The chosen experimental\
    \ site for the realization of four imaging \ncampaigns that were scheduled according\
    \ to the main phenological stages of the grape-\nvine was a farm located in Bova\
    \ Superiore, which is in the region of Calabria in Southern \nItaly. \nAs the\
    \ aim of this work is to test methodologies for Agriculture 4.0, the activities\
    \ \nconducted concerning data fusion methodologies on satellite images, UAV images,\
    \ and \nadditional sensors data as well as the use of a self-driving vehicle allow\
    \ for experimenta-\ntion in the area of Agriculture 4.0, leaving open broad research\
    \ topics that can be worked \non in the future. \nIn relation to the specific\
    \ situation of the rows of vines, it is noted that new results \ncan be obtained\
    \ by changing sensors and with new, higher-resolution multispectral satel-\nlite\
    \ images. \nPast results have already shown that data acquired from decametre-resolution\
    \ satel-\nlite systems (Sentinel-2) are insufficient to accurately assess vineyard\
    \ conditions and crop \nvariability. In fact, vineyard vigour may not agree with\
    \ that of the inter-row zones, deter-\nmining three distinct NDVI indices from\
    \ the high-resolution UAV images, considering: (i) \nthe entire cultivated area;\
    \ (ii) only the vine canopy; and (iii) only the soil pixels between \nthe rows.\
    \ Indeed, the NDVI calculated from UAV images of only the pixels representing\
    \ \nFigure 7. GIS (Geographic Information System): areas where the analysis of\
    \ historical and socio-\neconomic data makes a different kind of cultivation appropriate.\n\
    5. Conclusions\nOur article presents an introduction to a more in-depth analysis\
    \ by comparing mul-\ntispectral vineyard imagery obtained from satellite platforms\
    \ such as Sentinel-2, at a\nresolution of ten meters, and ultra-high-resolution\
    \ imagery acquired from WorldView\nsatellite and low-altitude UAV platforms. Using\
    \ NDVI as a measure of vineyard vitality,\nwe compared the usefulness of the images\
    \ obtained from the speciﬁed satellites and those\nobtained from UAVs. The chosen\
    \ experimental site for the realization of four imaging\ncampaigns that were scheduled\
    \ according to the main phenological stages of the grapevine\nwas a farm located\
    \ in Bova Superiore, which is in the region of Calabria in Southern Italy.\nAs\
    \ the aim of this work is to test methodologies for Agriculture 4.0, the activities\n\
    conducted concerning data fusion methodologies on satellite images, UAV images,\
    \ and\nadditional sensors data as well as the use of a self-driving vehicle allow\
    \ for experimentation\nin the area of Agriculture 4.0, leaving open broad research\
    \ topics that can be worked on in\nthe future.\nIn relation to the speciﬁc situation\
    \ of the rows of vines, it is noted that new re-\nsults can be obtained by changing\
    \ sensors and with new, higher-resolution multispectral\nsatellite images.\nPast\
    \ results have already shown that data acquired from decametre-resolution satellite\n\
    systems (Sentinel-2) are insufﬁcient to accurately assess vineyard conditions\
    \ and crop vari-\nability. In fact, vineyard vigour may not agree with that of\
    \ the inter-row zones, determining\nthree distinct NDVI indices from the high-resolution\
    \ UAV images, considering: (i) the\nentire cultivated area; (ii) only the vine\
    \ canopy; and (iii) only the soil pixels between the\nrows. Indeed, the NDVI calculated\
    \ from UAV images of only the pixels representing the\nvine canopy more accurately\
    \ described the vigour of the vineyard. The proposed strategy\ncan be applied\
    \ to other types of crops that are cultivated with signiﬁcant spaces between\n\
    the rows.\nThe GIS that was developed for the purpose of monitoring and managing\
    \ agricultural\nland with remote sensing using UAV images and VHR satellite imagery\
    \ classiﬁed with\nOBIA is very helpful for agricultural management and produces\
    \ alerts in the event that\ncrop stress occurs.\nThis research is still open.\
    \ Further experimentation will have to be carried out to\noptimise the system\
    \ by making it usable and extracting more data to obtain ﬁnal information\nto\
    \ be further tested in the ﬁeld or other areas to estimate the beneﬁts of the\
    \ method.\nSensors 2022, 22, 7910\n21 of 23\nAuthor Contributions: Conceptualization,\
    \ V.B. and G.B.; methodology, V.B. and G.B.; software, V.B.\nand R.C.; validation,\
    \ V.B., S.S. and G.B.; formal analysis, G.B.; investigation, V.B. and R.C.; resources,\n\
    V.B., R.C. and G.B.; data curation, S.S. and R.C.; writing—original draft preparation,\
    \ V.B. and G.B.;\nwriting—review and editing, A.F. and G.B.; visualization, S.S.\
    \ and R.C.; supervision, V.B. and G.B.;\nproject administration, V.B. and S.S.;\
    \ funding acquisition, S.S., A.F., R.C. and G.B. All authors have\nread and agreed\
    \ to the published version of the manuscript.\nFunding: This research received\
    \ no external funding.\nInstitutional Review Board Statement: Not applicable.\n\
    Informed Consent Statement: Not applicable\nData Availability Statement: Not applicable.\n\
    Conﬂicts of Interest: The authors declare no conﬂict of interest.\nReferences\n\
    1.\nArnó, J.; Martínez Casasnovas, J.A.; Ribes-Dasi, M.; Rosell, J.R. Review.\
    \ Precision viticulture. Research topics, challenges and\nopportunities in site-speciﬁc\
    \ vineyard management. Span. J. Agric. Res. 2009, 7, 779–790. [CrossRef]\n2.\n\
    Silvestroni, O.; Lanari, V.; Lattanzi, T. Canopy management strategies to control\
    \ yield and grape composition of Montepulciano\ngrapevines. Aust. J. Grape Wine\
    \ Res. 2018, 25, 30–42. [CrossRef]\n3.\nBramley, R.; Hamilton, R. Understanding\
    \ variability in winegrape production systems. Aust. J. Grape Wine Res. 2004,\
    \ 10, 32–45.\n[CrossRef]\n4.\nSong, J.; Smart, R.E.; Dambergs, R.G.; Sparrow,\
    \ A.M.; Wells, R.B.; Wang, H.; Qian, M.C. Pinot Noir wine composition from\ndifferent\
    \ vine vigour zones classiﬁed by remote imaging technology. Food Chem. 2014, 153,\
    \ 52–59. [CrossRef]\n5.\nKhaliq, A.; Comba, L.; Biglia, A.; Ricauda Aimonino,\
    \ D.; Chiaberge, M.; Gay, P. Comparison of Satellite and UAV-Based\nMultispectral\
    \ Imagery for Vineyard Variability Assessment. Remote Sens. 2019, 11, 436. [CrossRef]\n\
    6.\nPrimicerio, J.; Gay, P.; Ricauda Aimonino, D.; Comba, L.; Matese, A.; Di Gennaro,\
    \ S.F. NDVI-based vigour maps production using\nautomatic detection of vine rows\
    \ in ultra-high resolution aerial images. In Proceedings of the 10th European\
    \ Conference on\nPrecision Agriculture, Volcani Center, Israel, 12–16 July 2015;\
    \ pp. 465–470. [CrossRef]\n7.\nHall, A.; Lamb, D.; Holzapfel, B.; Louis, J. Optical\
    \ remote sensing applications in viticulture—A review. Aust. J. Grape Wine Res.\n\
    2002, 8, 36–47. [CrossRef]\n8.\nLanjeri, S.; Melia, J.; Segarra, D. A multi-temporal\
    \ masking classiﬁcation method for vineyard monitoring in central Spain.\nInt.\
    \ J. Remote Sens. 2001, 22, 3167–3186. [CrossRef]\n9.\nBramley, R.; Profﬁtt, A.P.B.\
    \ Managing variability in viticultural production. Grapegrow Winemak. 1999, 427,\
    \ 11–16.\n10.\nEnenkel, M.; Farah, C.; Hain, C.; White, A.; Anderson, M.; You,\
    \ L.; Wagner, W.; Osgood, D. What Rainfall Does Not Tell\nUs—Enhancing Financial\
    \ Instruments with Satellite-Derived Soil Moisture and Evaporative Stress. Remote\
    \ Sens. 2018, 10, 1819.\n[CrossRef]\n11.\nRomero, M.; Luo, Y.; Su, B.; Fuentes,\
    \ S. Vineyard water status estimation using multispectral imagery from an UAV\
    \ platform and\nmachine learning algorithms for irrigation scheduling management.\
    \ Comput. Electron. Agric. 2018, 147, 109–117. [CrossRef]\n12.\nComba, L.; Biglia,\
    \ A.; Aimonino, D.R.; Gay, P. Unsupervised detection of vineyards by 3D point-cloud\
    \ UAV photogrammetry for\nprecision agriculture. Comput. Electron. Agric. 2018,\
    \ 155, 84–95. [CrossRef]\n13.\nDobrowski, S.; Ustin, S.; Wolpert, J. Remote estimation\
    \ of vine canopy density in vertically shoot-positioned vineyards: Determin-\n\
    ing optimal vegetation indices. Aust. J. Grape Wine Res. 2002, 8, 117–125. [CrossRef]\n\
    14.\nSun, L.; Gao, F.; Anderson, M.C.; Kustas, W.P.; Alsina, M.M.; Sanchez, L.;\
    \ Sams, B.; McKee, L.; Dulaney, W.; White, W.A.; et al.\nDaily Mapping of 30 m\
    \ LAI and NDVI for Grape Yield Prediction in California Vineyards. Remote Sens.\
    \ 2017, 9, 317. [CrossRef]\n15.\nJohnson, L.F. Temporal stability of an NDVI-LAI\
    \ relationship in a Napa Valley vineyard. Aust. J. Grape Wine Res. 2003, 9, 96–101.\n\
    [CrossRef]\n16.\nSenthilnath, J.; Kandukuri, M.; Dokania, A.; Ramesh, K.N. Application\
    \ of UAV imaging platform for vegetation analysis based on\nspectral-spatial methods.\
    \ Comput. Electron. Agric. 2017, 140, 8–24. [CrossRef]\n17.\nPeña, J.M.; Torres-Sánchez,\
    \ J.; De Castro, A.I.; Kelly, M.; Lopez-Granados, F. Weed Mapping in Early-Season\
    \ Maize Fields Using\nObject-Based Analysis of Unmanned Aerial Vehicle (UAV) Images.\
    \ PLoS ONE 2013, 8, e77151. [CrossRef] [PubMed]\n18.\nComba, L.; Gay, P.; Primicerio,\
    \ J.; Aimonino, D.R. Vineyard detection from unmanned aerial systems images. Comput.\
    \ Electron. Agric.\n2015, 114, 78–87. [CrossRef]\n19.\nAlbetis, J.; Duthoit, S.;\
    \ Guttler, F.; Jacquin, A.; Goulard, M.; Poilvé, H.; Féret, J.-B.; Dedieu, G.\
    \ Detection of Flavescence dorée\nGrapevine Disease Using Unmanned Aerial Vehicle\
    \ (UAV) Multispectral Imagery. Remote Sens. 2017, 9, 308. [CrossRef]\n20.\nJohnson,\
    \ L.F.; Bosch, D.F.; Williams, D.C.; Lobitz, B.M. Remote Sensing of Vineyard Management\
    \ Zones: Implications for Wine\nQuality. Appl. Eng. Agric. 2001, 17, 557–560.\
    \ [CrossRef]\nSensors 2022, 22, 7910\n22 of 23\n21.\nRobinson, N.P.; Allred, B.W.;\
    \ Jones, M.O.; Moreno, A.; Kimball, J.S.; Naugle, D.E.; Erickson, T.A.; Richardson,\
    \ A.A. A Dynamic\nLandsat Derived Normalized Difference Vegetation Index (NDVI)\
    \ Product for the Conterminous United States. Remote Sens.\n2017, 9, 863. [CrossRef]\n\
    22.\nBarrile,\nV.;\nBilotta,\nG.\nAn\napplication\nof\nRemote\nSensing:\nObject\n\
    oriented\nanalysis\nof\nsatellite\ndata.\nInt. Arch. Photogramm. Remote. Sens.\
    \ Spat. Inf. Sci. 2008, 37, 107–114.\n23.\nBarrile, V.; Bilotta, G.; Fotia, A.;\
    \ Bernardo, E. Road Extraction for Emergencies from Satellite Imagery. In Computational\
    \ Science and\nIts Applications—ICCSA 2020; LNCS, 12252; Springer: Cham, Switzerland,\
    \ 2020; pp. 767–781. [CrossRef]\n24.\nBarrile, V.; Bilotta, G.; Fotia, A.; Bernardo,\
    \ E. Integrated Gis System for Post-Fire Hazard Assessments with Remote Sensing.\
    \ Int.\nArch. Photogramm. Remote Sens. Spat. Inf. Sci. 2020, XLIV-3/W1-2020, 13–20.\
    \ [CrossRef]\n25.\nAngiulli, G.; Barrile, V.; Cacciola, M. SAR Imagery Classification\
    \ Using Multi-Class Support Vector Machines. J. Electromagn. Waves Appl.\n2005,\
    \ 19, 1865–1872. [CrossRef]\n26.\nBarrile, V.; Bernardo, E.; Candela, G.; Bilotta,\
    \ G.; Modafferi, A.; Fotia, A. Road Infrastructure Heritage: From Scan to InfraBIM.\n\
    WSEAS Trans. Environ. Dev. 2020, 16, 633–642. [CrossRef]\n27.\nDeng, L.; Mao,\
    \ Z.; Li, X.; Hu, Z.; Duan, F.; Yan, Y. UAV-based multispectral remote sensing\
    \ for precision agriculture: A comparison\nbetween different cameras. ISPRS J.\
    \ Photogramm. Remote Sens. 2018, 146, 124–136. [CrossRef]\n28.\nReza, N.; Na,\
    \ I.S.; Baek, S.W.; Lee, K.-H. Rice yield estimation based on K-means clustering\
    \ with graph-cut segmentation using\nlow-altitude UAV images. Biosyst. Eng. 2018,\
    \ 177, 109–121. [CrossRef]\n29.\nJohnson, L.; Roczen, D.; Youkhana, S.; Nemani,\
    \ R.; Bosch, D. Mapping vineyard leaf area with multispectral satellite imagery.\n\
    Comput. Electron. Agric. 2003, 38, 33–44. [CrossRef]\n30.\nBorgogno-Mondino, E.;\
    \ Lessio, A.; Tarricone, L.; Novello, V.; de Palma, L. A comparison between multispectral\
    \ aerial and satellite\nimagery in precision viticulture. Precis. Agric. 2017,\
    \ 19, 195. [CrossRef]\n31.\nNavia, J.; Mondragon, I.; Patino, D.; Colorado, J.\
    \ Multispectral mapping in agriculture: Terrain mosaic using an autonomous\nquadcopter\
    \ UAV. In Proceedings of the 2016 International Conference on Unmanned Aircraft\
    \ Systems (ICUAS), Arlington, VA,\nUSA, 7–10 June 2016; pp. 1351–1358.\n32.\n\
    Hall, A.; Louis, J.; Lamb, D.W. A method for extracting detailed information from\
    \ high resolution multispectral images of vine-\nyards. In Proceedings of the\
    \ 6th International Conference on Geocomputation, Brisbane, QLD, Australia, 24–26\
    \ September 2001.\n33.\nSentinel-2A Handbook Overview. Available online: https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview\n\
    (accessed on 24 September 2022).\n34.\nESA Sentinel Online. Available online:\
    \ https://sentinels.copernicus.eu/web/sentinel/home (accessed on 24 September\
    \ 2022).\n35.\nCopernicus Open Access Hub. Available online: https://scihub.copernicus.eu/dhus/#/home\
    \ (accessed on 10 March 2021).\n36.\nLouis, J.; Charantonis, A.; Berthelot, B.\
    \ Cloud Detection for Sentinel-2. In Proceedings of the ESA Living Planet Symposium,\n\
    Bergen, Norway, 27 June–2 July 2010.\n37.\nDucati, J.R.; Bombassaro, M.G.; Fachel,\
    \ J.M.G. Classifying vineyards from satellite images: A case study on Burgundy’s\
    \ Côte d’Or.\nOENO One 2014, 48, 247–260. [CrossRef]\n38.\nJiang, R.; Wang, P.;\
    \ Xu, Y.; Zhou, Z.; Luo, X.; Lan, Y.; Zhao, G.; Sanchez-Azofeifa, A.; Laakso,\
    \ K. Assessing the Operation\nParameters of a Low-altitude UAV for the Collection\
    \ of NDVI Values Over a Paddy Rice Field. Remote Sens. 2020, 12, 1850.\n[CrossRef]\n\
    39.\nBilotta, G.; Bernardo, E. UAV for Precision Agriculture in Vineyards: A Case\
    \ Study in Calabria. In Geomatics and Geospatial\nTechnologies. ASITA 2021. In\
    \ Communications in Computer and Information Science; Borgogno-Mondino, E., Zamperlin,\
    \ P., Eds.;\nSpringer: Cham, Switzerland, 2022; Volume 1507. [CrossRef]\n40.\n\
    Aygün, S.; Güne¸s, E.O.; Suba¸sı, M.A.; Alkan, S. Sensor Fusion for IoT-based\
    \ Intelligent Agriculture System. In Proceedings of\nthe 8th International Conference\
    \ on Agro-Geoinformatics (Agro-Geoinformatics), Istanbul, Turkey, 16–19 July 2019;\
    \ pp. 1–5.\n[CrossRef]\n41.\nBarbedo, J.G.A. Data Fusion in Agriculture: Resolving\
    \ Ambiguities and Closing Data Gaps. Sensors 2022, 22, 2285. [CrossRef]\n[PubMed]\n\
    42.\nCitroni, R.; Di Paolo, F.; Livreri, P. A Novel Energy Harvester for Powering\
    \ Small UAVs: Performance Analysis, Model Validation\nand Flight Results. Sensors\
    \ 2019, 19, 1771. [CrossRef] [PubMed]\n43.\nRen, H.; Zhao, Y.; Xiao, W.; Hu, Z.\
    \ A review of UAV monitoring in mining areas: Current status and future perspectives.\n\
    Int. J. Coal Sci. Technol. 2019, 6, 320–333. [CrossRef]\n44.\nFurukawa, F.; Laneng,\
    \ L.A.; Ando, H.; Yoshimura, N.; Kaneko, M.; Morimoto, J. Comparison of RGB and\
    \ Multispectral Unmanned\nAerial Vehicle for Monitoring Vegetation Coverage Changes\
    \ on a Landslide Area. Drones 2021, 5, 97. [CrossRef]\n45.\nBarrile, V.; Meduri,\
    \ G.M.; Critelli, M.; Bilotta, G. MMS and GIS for Self-driving Car and Road Management.\
    \ In Computational\nScience and Its Applications—ICCSA 2017; Lecture Notes in\
    \ Computer Science; Springer: Cham, Switzerland, 2017; Volume 10407.\n[CrossRef]\n\
    46.\nNoguchi, N.; Zhang, Q.; Han, S.; Reid, J.F. Autonomous Agricultural Tractor\
    \ with an Intelligent Navigation System. IFAC Proc. Vol.\n2001, 34, 197–202. [CrossRef]\n\
    47.\nLi, Y.; Cao, Q.; Liu, F. Design of control system for driverless tractor.\
    \ MATEC Web Conf. 2020, 309, 04001. [CrossRef]\nSensors 2022, 22, 7910\n23 of\
    \ 23\n48.\nSott, M.K.; Nascimento, L.D.S.; Foguesatto, C.R.; Furstenau, L.B.;\
    \ Faccin, K.; Zawislak, P.A.; Mellado, B.; Kong, J.D.; Bragazzi,\nN.L. A Bibliometric\
    \ Network Analysis of Recent Publications on Digital Agriculture to Depict Strategic\
    \ Themes and Evolution\nStructure. Sensors 2021, 21, 7889. [CrossRef]\n49.\nKragh,\
    \ M.F.; Christiansen, P.; Laursen, M.; Steen, K.A.; Green, O.; Karstoft, H.; Jørgensen,\
    \ R.N. FieldSAFE: Dataset for Obstacle\nDetection in Agriculture. Sensors 2017,\
    \ 17, 2579. [CrossRef]\n50.\nDatiMeteo. Available online: https://datimeteo.it\
    \ (accessed on 24 September 2022).\n51.\nDJI Drones©. Available online: https://www.dji.com/it/matrice600-pro\
    \ (accessed on 24 September 2022).\n52.\nMicaSense (Now Ageagle). Available online:\
    \ https://ageagle.com/store/Calibrated-Reﬂectance-Panel-2-p467113700 (accessed\n\
    on 24 September 2022).\n53.\nTonnang, H.; Balemi, T.; Masuki, K.; Mohammed, I.;\
    \ Adewopo, J.; Adnan, A.; Mudereri, B.; Vanlauwe, B.; Craufurd, P. Rapid\nAcquisition,\
    \ Management, and Analysis of Spatial Maize (Zea mays L.) Phenological Data—Towards\
    \ ‘Big Data’ for Agronomy\nTransformation in Africa. Agronomy 2020, 10, 1363.\
    \ [CrossRef]\n"
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/22/20/7910/pdf?version=1666074846
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Experimenting Agriculture 4.0 with Sensors: A Data Fusion Approach between
    Remote Sensing, UAVs and Self-Driving Tractors'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.2507/daaam.scibook.2017.06
  analysis: '>'
  authors:
  - Imre Petkovics
  - Djerdji Petkovic
  - Ármin Petkovics
  citation_count: 9
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: DAAAM international scientific book ..
  limitations: '>'
  pdf_link: null
  publication_year: 2017
  relevance_score1: 0
  relevance_score2: 0
  title: IoT Devices vs. Drones for Data Collection in Agriculture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/s22176436
  analysis: '>'
  authors:
  - Yohanes Yohanie Fridelin Panduman
  - Nobuo Funabiki
  - Pradini Puspitaningayu
  - Minoru Kuribayashi
  - Sritrusta Sukaridhoto
  - Wen-Chung Kao
  citation_count: 14
  full_citation: '>'
  full_text: ">\nCitation: Panduman, Y.Y.F.;\nFunabiki, N.; Puspitaningayu, P.;\n\
    Kuribayashi, M.; Sukaridhoto, S.;\nKao, W.-C. Design and\nImplementation of SEMAR\
    \ IoT\nServer Platform with Applications.\nSensors 2022, 22, 6436. https://\n\
    doi.org/10.3390/s22176436\nAcademic Editors: Gianluigi Ferrari,\nLuca Davoli,\
    \ Laura Belli and Marco\nMartalò\nReceived: 9 July 2022\nAccepted: 23 August 2022\n\
    Published: 26 August 2022\nPublisher’s Note: MDPI stays neutral\nwith regard to\
    \ jurisdictional claims in\npublished maps and institutional afﬁl-\niations.\n\
    Copyright:\n© 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article\
    \ is an open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of\
    \ the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nsensors\nArticle\nDesign and Implementation of SEMAR IoT Server Platform\n\
    with Applications\nYohanes Yohanie Fridelin Panduman 1, Nobuo Funabiki 1,*, Pradini\
    \ Puspitaningayu 1, Minoru Kuribayashi 1,\nSritrusta Sukaridhoto 2 and Wen-Chung\
    \ Kao 3\n1\nGraduate School of Natural Science and Technology, Okayama University,\
    \ Okayama 700-8530, Japan\n2\nDepartment of Informatic and Computer, Politeknik\
    \ Elektronika Negeri Surabaya, Surabaya 60111, Indonesia\n3\nDepartment of Electrical\
    \ Engineering, National Taiwan Normal University, Taipei 106, Taiwan\n*\nCorrespondence:\
    \ funabiki@okayama-u.ac.jp\nAbstract: Nowadays, rapid developments of Internet\
    \ of Things (IoT) technologies have increased\npossibilities of realizing smart\
    \ cities where collaborations and integrations of various IoT application\nsystems\
    \ are essential. However, IoT application systems have often been designed and\
    \ deployed\nindependently without considering the standards of devices, logics,\
    \ and data communications.\nIn this paper, we present the design and implementation\
    \ of the IoT server platform called Smart\nEnvironmental Monitoring and Analytical\
    \ in Real-Time (SEMAR) for integrating IoT application systems\nusing standards.\
    \ SEMAR offers Big Data environments with built-in functions for data aggregations,\n\
    synchronizations, and classiﬁcations with machine learning. Moreover, plug-in\
    \ functions can be easily\nimplemented. Data from devices for different sensors\
    \ can be accepted directly and through network\nconnections, which will be used\
    \ in real-time for user interfaces, text ﬁles, and access to other systems\nthrough\
    \ Representational State Transfer Application Programming Interface (REST API)\
    \ services. For\nevaluations of SEMAR, we implemented the platform and integrated\
    \ ﬁve IoT application systems,\nnamely, the air-conditioning guidance system,\
    \ the ﬁngerprint-based indoor localization system, the water\nquality monitoring\
    \ system, the environment monitoring system, and the air quality monitoring system.\n\
    When compared with existing research on IoT platforms, the proposed SEMAR IoT\
    \ application server\nplatform offers higher ﬂexibility and interoperability with\
    \ the functions for IoT device managements,\ndata communications, decision making,\
    \ synchronizations, and ﬁlters that can be easily integrated\nwith external programs\
    \ or IoT applications without changing the codes. The results conﬁrm the\neffectiveness\
    \ and efﬁciency of the proposal.\nKeywords: Internet of Things; server platform;\
    \ SEMAR; IoT application system; sensor; MQTT;\nREST API\n1. Introduction\nThe\
    \ rapid growth of urban populations has increased the risk toward quality of life\n\
    (QoL) around the world [1]. Smart cities have been studied for identifying, preventing,\
    \ and\nacting in certain situations. In smart cities, QoL is commonly handled\
    \ with indicators that\nmeasure the effectiveness of the services and sustainability\
    \ of a city in domains/verticals,\nsuch as environments, health cares, securities,\
    \ transportation, economies, educations, and\ngovernments [2]. Particularly, the\
    \ environment vertical has drawn special attention in\nrecent years. Indicators\
    \ of environmental pollutants, such as air and water quality, road\nconditions,\
    \ and house conditions, must be monitored to detect adverse situations associated\n\
    with overpopulated regions. In this sense, Internet of Things (IoT) applications\
    \ must provide\ninteroperability tools that collect, store, and disseminate data\
    \ from several sensors, and\nprovide them to other systems [3,4]. Thus, smart\
    \ cities require collaboration and integration\nof various IoT application systems.\
    \ Studies of IoT server platforms have emerged for\nsuch purposes, where several\
    \ challenges hinder better management and analysis of IoT\napplication data using\
    \ platforms.\nSensors 2022, 22, 6436. https://doi.org/10.3390/s22176436\nhttps://www.mdpi.com/journal/sensors\n\
    Sensors 2022, 22, 6436\n2 of 28\nThe ﬁrst challenge involves the lack of a common\
    \ data format between data sensors\nand data communication protocols. For instance,\
    \ to measure the air and water quality,\ndifferent sensors with different geo-location\
    \ concepts such as addresses, buildings, re-\ngions, or cities can be handled\
    \ in different ways. Thus, an IoT server platform should be\nable to handle various\
    \ data types from different sensors, which makes it necessary to be\nable to work\
    \ with each other despite the diversity in communication protocols or sensor\n\
    technologies.\nThe second challenge is the standard parameters for data processing.\
    \ As an example,\nthe majority of air quality monitoring systems use Air Pollution\
    \ Index (API) to deﬁne the\nindicators of the carbon monoxide (CO), the nitrogen\
    \ dioxide (NO2), the sulfur dioxide\n(SO2), the ozone (O3), and the particulate\
    \ matter (PM10) [5]. However, other researchers\nmentioned that it might be necessary\
    \ to consider other indicators such as the temperature\nand the humidity for their\
    \ measurements [6].\nThe third challenge concerns the data interoperability between\
    \ various IoT application\nsystems within the same domain. It can be described\
    \ as the integration of plural systems\nby sharing output data through information\
    \ networks [3]. For example, a smart building\nsystem should integrate the human\
    \ Indoor Positioning System (IPS) with the environment\nmonitoring system to improve\
    \ QoL while reducing energy usage.\nHowever, in general, IoT application systems\
    \ for smart cities have been designed\nwithout considering these challenges. They\
    \ have been deployed independently and cannot\nbe integrated with other systems.\n\
    In this paper, we propose an IoT server platform called Smart Environmental Monitoring\n\
    and Analytical in Real-Time (SEMAR) for integrating various IoT application systems.\
    \ SE-\nMAR is able to offer Big Data environments with rich built-in functions\
    \ for data aggregations,\nsynchronizations, and classiﬁcations with machine learning.\
    \ Moreover, plug-in functions can\nbe easily implemented and added there. Data\
    \ from devices for different sensors can be\naccepted directly and through network\
    \ connections, which will be used in real-time for\nuser interfaces, text ﬁles,\
    \ and access to other systems through Representational State Transfer\nApplication\
    \ Programming Interface (REST API) services.\nFor evaluations of SEMAR, we implemented\
    \ the platform and integrated ﬁve IoT\napplications, namely, the air-conditioning\
    \ guidance system, the ﬁngerprint-based indoor local-\nization system, the water\
    \ quality monitoring system, the environment monitoring system, and\nthe air quality\
    \ monitoring system. The results conﬁrm the effectiveness and efﬁciency of the\n\
    proposal, including the reduction in the data transmission delay with the implemented\n\
    Message Queue Telemetry Transport (MQTT) service [7].\nThe rest of this paper\
    \ is organized as follows: Section 2 presents related works.\nSection 3 presents\
    \ the design of SEMAR. Section 4 presents the implementation of SE-\nMAR. Sections\
    \ 5–9 brieﬂy describe the IoT application systems implemented in the SEMAR.\n\
    Section 10 describes comprehensive performance evaluations and comparative analysis\n\
    with similar related work. Section 11 presents the threats to validity. Finally,\
    \ Section 12\nconcludes this paper with future works.\n2. Related Works\nIn [8],\
    \ Kamienski et al. proposed a three-layered Open IoT ecosystem approach for\n\
    smart application architectures. It includes input, process, and output in IoT\
    \ application\nsystems. The input gathers information from multiple sources, such\
    \ as sensors and other\nservices. The standard communication protocols cover the\
    \ device connections. The process\nis given by a collection of methodologies,\
    \ procedures, and algorithms for effective and\nefﬁcient data processing. The\
    \ output provides capabilities for data visualizations and\naccessibility.\nIn\
    \ [9], Bansal et al. proposed ﬁve layers for the IoT application system architecture,\n\
    consisting of perception, transport, processing, middleware, and application.\
    \ They divided\ndata processing into two layers, where the processing layer concentrates\
    \ on ﬁltering and\nSensors 2022, 22, 6436\n3 of 28\nformatting the data, and the\
    \ middleware layer intends to execute various logical and\nanalytic operations.\n\
    The connectivity in IoT systems was discussed in [10], where Li et al. examined\
    \ the\nnetworking technologies, and described that IEEE 802.11 (WLAN), IEEE 802.15.1\
    \ (Bluetooth,\nLow-energy Bluetooth), IEEE 802.15.6 (wireless body area networks),\
    \ and 3G/4G were the\nmost widely adopted in IoT application systems and smart\
    \ city environment systems.\nSince IoT systems might consist of various physical\
    \ things and sensors, it is essential\nto provide a device-to-device communication\
    \ protocol. Malche et al. in [11] proposed\nthe MQTT communication protocol for\
    \ environmental monitoring systems with multiple\ndevice sensors. Sharma et al.\
    \ in [12] deﬁned the Representational State Transfer (REST) web\nservice as the\
    \ gateway to collect device data through the HTTP POST protocol. Zhang et al.\n\
    in [13] studied NATS open source messaging to communicate between IoT devices\
    \ [14].\nThe numerous options of communication protocols were surveyed by Dizdarevic\
    \ et al.\nin [15]. They concluded that MQTT and HTTP POST are the most suitable\
    \ for IoT applica-\ntion systems since they are well matured and stable.\nIn [16],\
    \ Marques et al. proposed the IoT system architecture for the indoor air quality\n\
    (IAQ) system in a laboratory environment named iAQ Plus (iAQ+). It collects data\
    \ from\ndevices through Wi-Fi connections and stores data in the SQL server. The\
    \ authors proposed\na web portal and mobile application to manage and visualize\
    \ the obtained data; however,\nthe system does not offer data analysis functions\
    \ to process sensor data.\nIn [17], Benammar et al. proposed the IAQ system that\
    \ is integrated with the Emoncms\nIoT platform for storing and visualizing air\
    \ quality data, temperature, and humidity. The\nauthors used a Waspmote microcontroller\
    \ connected to Raspberry PI as sensor nodes and\nthe MQTT service to send data.\n\
    In [18], Mandava et al. proposed to integrate machine learning algorithms and\
    \ the\nIoT platform infrastructure for monitoring air pollution in smart cities.\
    \ The system collects\nenvironmental and location data to determine air pollution\
    \ conditions in speciﬁc areas, and\nuses the collected data to build a data model\
    \ for air pollution detections using supervised\nmachine learning algorithms.\
    \ The experiment results conﬁrmed the effectiveness of the\nproposed data model\
    \ for air pollution detections.\nIn [19], Senožetnik et al. proposed a management\
    \ framework for groundwater data in\nsmart cities. The system uses a web-based\
    \ IoT service to receive data through HTTP POST,\nconvert it into the JavaScript\
    \ Object Notation (JSON) format, and store it in the MongoDB\nNoSQL database.\
    \ It also allows sharing collected data through REST API. This system is\nsimilar\
    \ to our proposed one; however, the system only provided data communications\n\
    through HTTP POST. Moreover, it did not implement data processing functions to\
    \ analyze\nthe obtained data.\nIn [20], Kazmi et al. proposed a platform that\
    \ provides interoperability of diverse IoT\napplications in smart cities named\
    \ VITAL-OS. It can be integrated with other IoT application\nsystems through REST\
    \ API.\nIn [21], Toma et al. proposed an IoT platform for monitoring air pollution\
    \ in smart\ncities. The system contains wireless and wired connections with sensors\
    \ to send data\nthrough MQTT communications to the server using cellular networks.\
    \ It allows sharing\ndata through REST API; however, this platform was built and\
    \ implemented only for this\nIoT application of monitoring air pollution.\nIn\
    \ [22], Javed et al. proposed an IoT platform for smart buildings. It consists\
    \ of the\ndiscovery, storage, and service planes. The discovery plane performs\
    \ connectivity control\nwith devices through HTTP communications. The storage\
    \ plane manages data storage\nusing Apache Cassandra [23]. The service plane provides\
    \ data processing composed of data\nindexing, visualizing, and analysis.\nIn [24],\
    \ Badii et al. proposed an open source IoT framework architecture for smart cities\n\
    called Snap4City. The system offers modules for device managements, data processing,\n\
    data analysis, and data visualizations.\nSensors 2022, 22, 6436\n4 of 28\nIn [25],\
    \ Putra et al. proposed an implementation of wireless sensor networks in smart\n\
    cities to monitor air pollution. A device will transmit data regarding the air\
    \ pollution to a\nserver through a Wi-Fi network.\nIn [26], Gautam et al. proposed\
    \ an IoT application for the water supply management\nsystem in smart cities.\
    \ The proposed architecture uses General Purpose Input Output (GPIO)\ncommunications\
    \ for connecting ultrasonic sensors and water pumps with Raspberry PI.\nMoreover,\
    \ it uses Ethernet cables as network interfaces to Raspberry PI and the router.\
    \ It\noffers data analysis services and real-time predictions using machine learning\
    \ algorithms\nfor processing data; however, this framework is only built for this\
    \ single IoT application.\nIn [27], Oliveira et al. proposed an IoT application\
    \ for road environment monitoring\nusing mobile-based sensors. The system receives\
    \ sensor data through HTTP POST commu-\nnications in the JSON format, and allows\
    \ processing and visualizing it. It also provides a\nfunction to export data in\
    \ CSV ﬁles.\nIn [28], Metia et al. proposed a digital ﬁlter for the IoT-based\
    \ air pollution monitoring\nsystem. The experiment results in this study show\
    \ that the data processing using Kalman\nﬁlter has enhanced the reliability and\
    \ accuracy of the system; however, they did not\nimplement the real-time data\
    \ processing.\nIn [29], Twahirwa et al. proposed the system for monitoring roads,\
    \ weathers, and\nenvironments by attaching multiple sensors to a vehicle and sending\
    \ sensor data to the\nIoT server. The IoT server can process, store, and visualize\
    \ data with the web application\nsystem.\nIn [30], D’Ortona et al. showed the\
    \ beneﬁts of implementing MQTT communications in\nIoT application systems for\
    \ smart cities. The MQTT communications allow the construction\nof highly scalable\
    \ and ﬂexible IoT systems.\nIn [31], Kumar et al. proposed an anomaly-based intrusion\
    \ detection system (IDS) to secure\nIoT networks from threats such as spying and\
    \ malicious controls. It was implemented at\nthe fog node level. The proposed\
    \ approach might be adopted as an additional system that\ncan avoid threats before\
    \ the IoT platform receives them. Moreover, in [32,33], a method was\nproposed\
    \ to protect IoT networks by data pre-processing functions. It comprises feature\n\
    mapping, missing value inputting, normalization, and feature selection techniques.\
    \ The\nproposed method is similar to our approach in the data aggregation function.\
    \ SEMAR only\nprocesses and stores sensor data registered in the sensor format\
    \ data storage.\nIn [34], Kumar et al. designed PEFL for secure open communication\
    \ channels in\nIoT application systems. The proposed method utilized Long Short-Term\
    \ Memory (LSTM)\nand privacy encoding techniques in order to reduce security risk\
    \ and maintain privacy.\nMoreover, in [35], authors proposed an framework for\
    \ preventing cyber attacks on IoT-fog\ncomputing. It offered virtualized northbound\
    \ interfaces such as load balancer and resource\nmanagement to manage networks\
    \ in IoT systems. The proposed architecture can be utilized\nto enhance network\
    \ performances for the SEMAR IoT application server platform in future\nworks.\n\
    3. Design of SEMAR IoT Server Platform\nIn this section, we present the design\
    \ of the SEMAR IoT server platform for integrating\nvarious IoT application systems.\n\
    3.1. System Overview\nFigure 1 shows the proposed design of the SEMAR IoT server\
    \ platform. The main\ncomponents are data input, data process, and data output.\
    \ The data input is responsible\nfor accepting data from various sources. It consists\
    \ of network interface devices and\ncommunication protocols. The data process\
    \ provides the modules for data processing,\ncontrol, and collection. The data\
    \ output enables visualizations and sharing of collected\ndata. In Table 1 we\
    \ summarize the nomenclature of all the symbols and variables used in\nthis paper.\n\
    Sensors 2022, 22, 6436\n5 of 28\nFigure 1. Design overview of SEMAR IoT server\
    \ platform.\nTable 1. Nomenclature used in the paper.\nParameters\nDescription\n\
    Decision Tree algorithm:\nt\nthe node of decision tree\nn\nnumber of targets classes\n\
    P(i|t)\nthe probability of the speciﬁc data class i in node t\nSupport Vector\
    \ Machine algorithm:\nyi\nthe class label of dataset\nαi\nthe learned weight\n\
    xi\nthe support vector\nx\nthe labeled training sample data.\nK()\nthe kernel\
    \ function\nRadial Basis Function kernel:\nl\nthe length scale of the kernel RBF\n\
    d(xi, xj)\nthe Euclidean distance between xi and xj\n3.2. Data Input\nSEMAR needs\
    \ to collect data from a number of different devices using various network\nconnectivity\
    \ and communication methods; therefore, the following network interfaces\nfor\
    \ constructing physical network connections are implemented in the platform, where\n\
    standard IoT communication protocols for data transmission, namely HTTP and MQTT,\n\
    are included. In the context of IoT, physical devices as a perception layer consist\
    \ of a\nnumber of sensors connected to a controller. With the growth of IoT technology,\
    \ controllers\nsuch as Arduino and Raspberry PI have provided diverse network\
    \ connectivity to accept\ndata from various sensors. General Purpose Input Output\
    \ (GPIO) is the programmable\ninterface in the device controller to receive or\
    \ send command signals from/to IoT sensor\ndevices [36]. In IoT application systems,\
    \ GPIO is the standard interface for connecting\nsensor devices with the controller.\
    \ In addition, it is used for connecting controllers with\nexternal modules such\
    \ as Wi-Fi ones for data communications. Universal Serial Bus (USB) is\nthe serial\
    \ communication media to link devices with computers via USB ports. Currently,\n\
    Sensors 2022, 22, 6436\n6 of 28\nnumerous sensor instruments and devices can transmit\
    \ data using USB connections. The\nUSB connection offers a high data transfer\
    \ capacity. In addition, external communication\nmodules such as Wi-Fi for data\
    \ communication can also be added using USB connection.\nRegarding the IoT data\
    \ transmission concept, diverse hardware and software con-\nnectivity should be\
    \ considered. Diverse network interfaces utilize hardware-based trans-\nmissions,\
    \ such as Wi-Fi, Ethernet, and Cellular—this enables machine-to-machine and\n\
    device-to-server communication.\nIEEE 802.11 wireless LAN (Wi-Fi) is the most\
    \ prevalent network interface in IoT systems.\nIt connects devices with each other\
    \ and to servers. Wi-Fi is useful to connect a lot of devices\nregardless of their\
    \ locations with computers, which improves IoT application developments.\nEthernet\
    \ offers secure and dependable wired connectivity. It is one of the most used\
    \ network\ninterfaces in IoT systems; however, the implementation can be difﬁcult\
    \ over long distances.\nAlthough Wi-Fi and Ethernet offer excellent network performance,\
    \ we should consider\ntheir security and coverage area. The alternative network\
    \ interface that can be utilized is\ncellular networks. Cellular is the network\
    \ interface allowing the mobility of devices with\nthe existing widespread availability\
    \ of cells to connect with the internet. Currently, 5G\ncellular connections offer\
    \ solutions with wider bandwidths than Wi-Fi or Ethernet. The IoT\nplatform can\
    \ use it through Wi-Fi interfaces with mobile routers.\nThe last part of Data\
    \ Input is the communication protocol between IoT devices and\nservers. An IoT\
    \ server should support publish–subscribe and push-and-pull messaging\nsystems\
    \ for sending and receiving data. Thus, our proposed system utilizes MQTT and\n\
    REST API for the communication protocol service.\nMQTT is one of the protocols\
    \ that have been designed for data communications in IoT\napplication systems.\n\
    It can work with minimal memory and the processing\npower [37]. The MQTT broker\
    \ works for receiving messages from clients, ﬁltering the\nmessages according\
    \ to a topic, and distributing the messages to subscribers [38]. The\nMQTT broker\
    \ is implemented in the IoT gateway function of the platform to provide data\n\
    communication services in SEMAR. The IoT gateway function offers communication\
    \ ser-\nvices to connect sensor devices to the server. Using this protocol, sensor\
    \ devices can\ntransmit messages containing sensor data in the JSON format with\
    \ MQTT topics. By\nsubscribing data at the same MQTT topic, the data aggregation\
    \ program in the platform\nobtains each sensor data. In addition, the study by\
    \ Al-Joboury in [39] shows that the load\nbalancer can increase the performance\
    \ and the capacity of MQTT data communications.\nThe IoT gateway function also\
    \ implemented the REST API for receiving sensor data\nthrough the HTTP POST communication\
    \ protocol. It can only receive data in the JSON for-\nmat. The REST API provides\
    \ URLs for sensor data transmission. The management function\nin the platform\
    \ creates the unique URL for each device. The HTTP POST communication\nprotocol\
    \ is compatible with standard network interfaces. Using REST API, sensor devices\n\
    can transmit data in the JSON format.\n3.3. Data Process\nThe data process in\
    \ the SEMAR server platform offers various functions. The large\namount of data\
    \ from data input will be processed to obtain meaningful information using\nsome\
    \ functions. The functions are implemented as independent modules to reduce system\n\
    crashes at system failures. They can be extended to microservices [40,41]. The\
    \ concept of\nmicroservices is the method of developing a large-scale system with\
    \ a set of small indepen-\ndent services. For their implementations, thread-based\
    \ programs are adopted to improve\ntheir performances for real-time data processing.\
    \ Each service will initiate a new thread to\nprocess the newly coming data.\n\
    3.3.1. Data Management (Storage, Aggregator, and Plug-in Functions)\nThe data\
    \ management system is the main function of the IoT platform. In the context\n\
    of IoT, systems must provide data storage, transaction management, query processing,\
    \ and\ndata access for application systems. Thus, the IoT platform must offer\
    \ services to process\nSensors 2022, 22, 6436\n7 of 28\nthe data ﬂow from input\
    \ to output. Moreover, towards developing diverse IoT applications,\ndevices involved\
    \ in IoT should be able to generate different kinds of data types according\n\
    to the application.\nIn order to provide various IoT application systems, SEMAR\
    \ should be a useful\nplatform for a variety of IoT application systems. Thus,\
    \ it needs to support massive\namounts of data in different formats. Moreover,\
    \ it needs to store all the necessary data by\noffering data storage for every\
    \ application. The management data storage is the database that\nstores the operating\
    \ parameters in the SEMAR server platform including the implemented\nIoT application\
    \ systems. The data include the information regarding connected devices,\ncommunications,\
    \ and parameters for the process modules running on the platform. On\nthis platform,\
    \ each device has its own unique sensor format. The management data storage\n\
    database keeps the sensor format as the template to help the development of an\
    \ IoT\napplication system on this platform.\nMeanwhile, the sensor data storage\
    \ is the database that stores all the sensor data in\nthe platform. In IoT application\
    \ systems, sensor devices may offer various data and it\nmay change it over time\
    \ with unstructured formats; therefore, the platform uses the big\ndata technology\
    \ to store unstructured JSON objects generates the unique data storage for\neach\
    \ device. This data storage utilized only accepts registered device data; therefore,\
    \ we\nimplement additional data stored in the form of Log ﬁles. Log Files are\
    \ used to keep the\nvalues of any deﬁned or undeﬁned data using the CSV format.\
    \ The deﬁned data represents\na sensor data that ﬁts the format registered in\
    \ the management data storage. The undeﬁned\ndata represents data whose format\
    \ is not registered.\nThe schema data storage is the database that can be used\
    \ to help the users of IoT\napplication systems by dynamically specify the names,\
    \ ﬁelds, and data types in accessing\nthis storage. It supports multiple data\
    \ types, including integer, ﬂoat, date, time, date-time,\nand string.\nFigure\
    \ 1 illustrates that this database is used to store data synchronization results.\n\
    Through REST API, other systems can access to the sensor data storage. As the\
    \ advantage\nof this database, it can be dynamically deﬁned and modiﬁed by the\
    \ user. It can assist\nintegration of various complex IoT application systems.\n\
    In an IoT system, the data lifecycle begins with the communication gateway re-\n\
    ceiving sensor data, continues with data aggregation and preprocessing, and concludes\n\
    with data storage. For this purpose, SEMAR provides a data aggregator function.\
    \ The\ndata aggregator is the module of collecting data from various data sources,\
    \ applying\nthe value-added processing, and repackaging the information in a consumable\
    \ format.\nAlgorithm 1 illustrates the data processing procedure in this module.\
    \ It forwards the result\nto the following data ﬁlter or stores it in the data\
    \ storage through the database access.\nThe data management system plays a role\
    \ in the sensor data storage process and\nprovides access to additional data processing\
    \ functions. Those services are not only for\nsystems integrated in the IoT platform\
    \ (built-in) but also for plug-in functions that may be\ndeployed as an extension.\
    \ Because an IoT application system may require unique data\nprocessing that has\
    \ not been implemented in the platform. Thus, the platform is designed\nand implemented\
    \ so that users can easily implement plug-in functions without modifying\nexisting\
    \ codes, to fulﬁll the demands of IoT application systems. The plug-in functions\
    \ can\nuse REST API to access the data in the platform.\nSensors 2022, 22, 6436\n\
    8 of 28\nAlgorithm 1 Data aggregator\nInput\n:Raw sensor data received through\
    \ a communication protocol (RSensor)\nDevice code (Dcode)\nOutput:Sensor data\
    \ in a consumable format (MSensor)\nbegin\nSave RSensor in a log ﬁle\nConvert\
    \ RSensor to JSON object\nFind the sensor format from the database using Dcode\
    \ as S f ormat\nif S f ormat not empty then\nInitialize MSensor ← empty JSON object\n\
    for each item in S f ormat do\nif item in RSensor then\nSet MSensor[item] ← RSensor[item]\n\
    end\nend\nSet MSensor[”time”] ← currenttimestamp\nreturn MSensor\nend\nend\n3.3.2.\
    \ Data Filter and Synchronization\nIn this research, we additionally explore the\
    \ data processing capabilities required\nby IoT applications that are not included\
    \ in the standard data management services. For\nexample, sensors of IoT devices\
    \ may generate measurement errors and noise during the\nmeasuring process. It\
    \ can impact the risk of data analysis problems. In addition, IoT\napplications\
    \ such as indoor localization systems require real-time sensor data from several\n\
    devices simultaneously; therefore, our platform deploys the data ﬁlter and synchronization\n\
    functionalities for processing sensor data.\nThe functions of ﬁltering sensor\
    \ data before being saved in a data storage are imple-\nmented. Digital ﬁlters\
    \ are adopted to reduce noise and inaccuracies in data. The following\nprocedure\
    \ is applied for ﬁltering data:\n•\nIt receives sensor data in a JSON format.\n\
    •\nIt selects the sensor ﬁeld’s value to be ﬁltered.\n•\nIt add the ﬁeld value\
    \ in the JSON object with the ﬁlter result.\n•\nIt stores the JSON object in the\
    \ database.\nThe data synchronization function can synchronize the data from different\
    \ devices\nby referring to the timestamp in the data store schema. The timestamp\
    \ was given when the\nplatform receives the data from the sensor device. Thus,\
    \ the platform requests the data\nfrom each sensor’s storage at a speciﬁed detection\
    \ time. For each sensor data, the ﬁeld for\nthe identiﬁer (Fi) to group sample\
    \ data in a speciﬁc value, the ﬁeld for the value (Fv) to be\nsynchronized, the\
    \ default value (de f ault), and the four functions to process the data are\n\
    prepared. The following functions are implemented to process the data:\n•\nAverage:\
    \ it returns the average value of the data collected during the detection time.\n\
    •\nCurrent: it returns the last value among the data collected during the detection\
    \ time.\n•\nMax: it returns the highest value among the data collected during\
    \ the detection time.\n•\nMin: it returns the lowest value among the data collected\
    \ during the detection time.\nAlgorithm 2 illustrates the data processing procedure\
    \ in this module.\nSensors 2022, 22, 6436\n9 of 28\nAlgorithm 2 Data Synchronization\n\
    Input\n: Detection time (Dtime), List of sensor data will be synchronized (LSensor)\n\
    Output:List of synchronized data (SyncData)\nbegin\nSet TimeStart ← currenttime\n\
    Set TimeEnd ← TimeStart + Dtime\nwhile True do\nif TimeEnd = currenttime then\n\
    Set DataSource, Identi f ierList, SyncData ← empty vector\nfor each sensor ∈ LSensor\
    \ do\nSet DSensor ← captured sensor data between TimeStart and TimeEnd\nSet GroupData\
    \ as empty vector\nfor each row in DSensor do\nif row[Fi] not in Identi f ierList\
    \ then\nAppend row[Fi] to Identi f ierList\nend\nAppend row[Fv] to GroupData[row[Fi]]\n\
    end\nfor each i ∈ GroupData do\nSet DataSource[sensor][i] ← processed GroupData[i]\
    \ use the selected\nfunction\nend\nend\nfor each ID ∈ Identi f ierList do\nSet\
    \ SyncItem ← empty vector\nAppend ID to SyncItem[”identi f ier”]\nfor each sensor\
    \ ∈ LSensor do\nif DataSource[sensor][ID] is not empty then\nAppend DataSource[sensor][ID]\
    \ to SyncItem\nend\nAppend sensor[de f ault] to SyncItem\nend\nAppend SyncItem\
    \ to SyncData\nend\nStores SyncData to the schema data storage\nSet TimeStart\
    \ ← currenttime\nSet TimeEnd ← Tstart + Dtime\nend\nend\nend\n3.3.3. Machine Learning\
    \ and Real-time Classiﬁcation\nOne of the exploitation scenarios for the massive\
    \ quantity of IoT data is its predictive\ncapability by utilizing machine learning\
    \ approaches. Several researchers approved the\neffectiveness of machine learning\
    \ implementation in IoT applications [42–44]. Moreover,\nKumar et al. in [45]\
    \ proposed the ensemble design combining machine learning algorithms\nto protect\
    \ networks on the Internet of Medical Things in real-time; therefore, we implement\n\
    machine learning and real-time classiﬁcation function in SEMAR.\nThe machine learning\
    \ algorithms are implemented to help data classiﬁcations. The\nSupport Vector\
    \ Machine [46,47] and Decision Tree [48–50] are implemented in this platform as\n\
    standard machine learning algorithms in IoT application systems.\nDecision Tree\
    \ employs tree decisions including event outcomes, resource costs, and\nutility\
    \ costs. It can create a data model for predicting outcomes by learning simple\
    \ decision\nrules according to the data features. The data model structure consists\
    \ of internal nodes\nrepresenting an attribute, branches representing a decision\
    \ rule, and leaf nodes indicating\nan outcome. Here, C4.5, CART (Classiﬁcation\
    \ and Regression Trees), and Naive Bayes Tree\nSensors 2022, 22, 6436\n10 of 28\n\
    are selected and incorporated into the platform as the most well-known machine\
    \ learning\nalgorithms [48]. CART is the binary recursive partitioning method\
    \ that can handle both\nnumerical and category data [48–50]. It can determine\
    \ the impurity degree of acceptable\ndata and build a binary tree in which each\
    \ internal node provides two classes for the\naccepted attribute. The tree is\
    \ formed by iteratively picking the attribute with the lowest\nGini index. The\
    \ Gini index for each node is calculated by the following equation [48]:\nGini(t)\
    \ = 1 −\nn\n∑\ni=1\nP(i|t)2\n(1)\nSupport Vector Machine (SVM) is utilized as\
    \ the regression and classiﬁcation\ntechnique [51]. This approach has been used\
    \ for the big data classiﬁcation [47]. The\nSVM computes linear decision boundary\
    \ lines that can separate the data for the labeled\ngroups. The SVM decision boundary\
    \ line is calculated by the following equation:\nf (x) = ∑\n∀i\nyiαiK(xi, x)\n\
    (2)\nwhere yi represents the class label, αi represents the learned weight, K()\
    \ represents the\nkernel function, xi denotes the support vector, and x denotes\
    \ the labeled training sample\ndata. The kernel function is given by a collection\
    \ of mathematical operations used to\nprocess the input data and convert it into\
    \ the required format. The radial basis function (RBF)\nkernel is one of the common\
    \ kernel functions in SVM. The following equation illustrates\nthe formula of\
    \ the (RBF) kernel:\nK(xi, xj) = exp(−d(xi, xj)2\n2l2\n)\n(3)\nwhere l represents\
    \ the length scale of the kernel and d(xi, xj) denotes the Euclidean distance\n\
    between xi and xj.\nDecision Tree and SVM have several hyper parameters. For them,\
    \ the Randomized Search\nMethod is implemented in SEMAR to ﬁnd the optimal combination\
    \ of hyper parameters,\ndue to its superior performances with the low cost and\
    \ short computing time compared to\nother methods.\nFor reference, the Decision\
    \ Tree algorithm has the following hyper parameters:\n•\nMaximum depth (max_depth):\
    \ represents the maximum depth of the tree model result.\nIt is used to select\
    \ the optimal model to prevent over-ﬁtting.\n•\nMinimum samples split (min_samples_split):\
    \ represents the minimal amount of data\nrequired to separate an internal node.\
    \ If it is large, it can prevent over-ﬁtting; however,\nif it is very large, it\
    \ can cause under-ﬁtting.\n•\nMinimum samples leaf (min_samples_lea f): represents\
    \ the minimal amount of data\nrequired to be left at the leaf node. It is similar\
    \ to the minimum samples split parameter.\n•\nMinimum weighted fraction leaf (min_weight_fraction_lea\
    \ f): represents the total weight\nrequired at a leaf node.\nThe Support Vector\
    \ Machine algorithm has the following main hyper parameters:\n•\nKernel: represents\
    \ the function of transforming the training dataset into the higher\ndimension\
    \ space. The standard kernel consists of Radial Basis Function (RBF), linear,\n\
    polynomials, and sigmoid.\n•\nC: represents the penalty parameter that controls\
    \ the trade-off between the decision\nboundary and the misclassiﬁcation. C value\
    \ controls the margin of the decision\nboundary line to avoid misclassiﬁcations.\
    \ The large value can prevent the model\nfrom allowing any misclassiﬁcation. If\
    \ the dataset is linearly separable, it will work;\nhowever, if the dataset is\
    \ non-separable/nonlinear, it is better to use a small C value\nto avoid overﬁtting,\
    \ although it allows misclassiﬁcations to occur.\nSensors 2022, 22, 6436\n11 of\
    \ 28\n•\nGamma: represents the coefﬁcient of the kernel used to decide the curvature\
    \ of the\ndecision boundary line. The value of Gamma determines the shape of the\
    \ decision\nboundary line according to the number of dataset points. The large\
    \ value causes the\ndecision boundary to be easily affected by fewer data points,\
    \ and the shape becomes\ncomplex. It can be helpful for nonlinear datasets; however,\
    \ if it is too large, it tends to\nbe over-ﬁtting. On the other hand, for the\
    \ linear dataset, the small values make the\ndecision boundary line more general\
    \ and useful.\nThe machine learning algorithms allow the user to use the data\
    \ stored in the data\nstorage as the sample data. This module can generate a data\
    \ model for the real-time data\nclassiﬁcation module.\nThe real-time data classiﬁcation\
    \ function is implemented to analyze a huge amount of\ndata from various sensor\
    \ devices by periodically running the following procedure:\n1.\nIt loads the data\
    \ classiﬁcation model made by the machine learning algorithm.\n2.\nIt receives\
    \ sensor data from the database.\n3.\nIt classiﬁes data into classes by running\
    \ the data model.\n4.\nIt stores results in the database.\nThe classiﬁcation model\
    \ can be created by each user separately. Moreover, the user\ncan start or stop\
    \ the real-time data classiﬁcation at the user interface.\n3.4. Data Output\n\
    Several output components, such as the monitor display, the user interface, the\
    \ data\nexport, REST API, and the notiﬁcation function, are considered to use\
    \ the data in the\nplatform. The monitor display is attached to the sensor node,\
    \ and accesses the user\ninterface in the platform through a network connection.\
    \ It can easily show sensor data for\neach device.\nThe user interface is provided\
    \ at the web browser to allow users to see the sensor\nand synchronized data by\
    \ tables, graphs, or maps. The platform allows users to access the\nsensor data\
    \ using the time of data receipt. It receives the sensor data in the JSON format\
    \ by\naccessing REST API. The column in the table is formed automatically based\
    \ on the sensor\nformat of each device. The platform can generate the graph for\
    \ each registered format\nsensor. Visualization maps will display the data in\
    \ digital maps based on the GPS data. The\ndata export feature is designed and\
    \ implemented to allow users to download data in Excel,\nJSON, text, or CSV format\
    \ at the speciﬁed time. Users can use this feature by accessing to\nthe user interfaces.\n\
    REST API is employed as a back-end system to access the sensor data. The sensor\
    \ data\nare retrieved from the database and is converted to the JSON format. It\
    \ will be sent to the\nuser interface and plug-in functions using HTTP POST communications.\
    \ The platform can\nexchange and integrate data with other IoT application systems\
    \ via REST API.\nThe notiﬁcation function allows the user to deﬁne the threshold\
    \ for each sensor data\nas the trigger of the message notiﬁcation. If the value\
    \ is over the threshold, the platform\nwill send a notiﬁcation. The platform offers\
    \ two different communication services. First, it\npublishes a message to a speciﬁc\
    \ topic using the MQTT communication protocol. Thus, the\nIoT application system\
    \ can subscribe to topic to receive the messages. Second, it delivers\nemail notiﬁcations\
    \ through the mail server service installed on the server platform. The\nuser\
    \ can dynamically deﬁne email recipients.\n3.5. Management Service\nThe management\
    \ service is used to manage all functions in the SEMAR platform. It\nincludes\
    \ the managements of users, devices, communications, schema data, synchroniza-\n\
    tion functions, analytics, data ﬁlters, and notiﬁcation functions. The management\
    \ of users\nallows us to add users, set permissions, and restrict access to the\
    \ devices.\nThe device management service provides the functions to register the\
    \ devices and the\nsensors of the IoT application system. It allows managing the\
    \ sensor format for each device\ndynamically. The platform can process, save,\
    \ and display the data registered in the sensor\nSensors 2022, 22, 6436\n12 of\
    \ 28\nformat. For convenience, the SEMAR platform provides a template to add the\
    \ device with\nthe same sensor format easily. The schema data management allows\
    \ to create the schema\ndatabase, deﬁne the ﬁeld format, and manage the data.\n\
    The management service provides the functions to add, update, and delete settings\n\
    for data synchronizations, data analytics, data ﬁltering, and notiﬁcations. It\
    \ allows the user\nto run and terminate the module service in the data process.\
    \ All the conﬁguration settings\nare saved as JSON objects.\n4. Implementation\
    \ of SEMAR IoT Server Platform\nIn this section, we present the implementation\
    \ of the SEMAR IoT server platform.\nTable 2 shows the summary of the implementation.\n\
    Table 2. Technology speciﬁcations for implementation of SEMAR IoT server platform.\n\
    IoT Model\nFunction\nComponent\nDescription\nInput\nMQTT\nMQTT Broker\nMosquitto\
    \ v2.0.10\nMQTT Supports\nMQTT v5.0, v3.1.1, and v3.1\nREST API\nLibraries and\
    \ Framework\nTornado Web Server, PyMongo,\nJSON\nCommunication Supports\nHTTP-POST\n\
    Network Interfaces\nNetwork Interfaces Supports\nWi-Fi, Ethernet, Cellular\nProcess\n\
    Server\nOperating System\nUbuntu 18.04.5 LTS\nMemory\n6Gb\nData Storage\nServices\n\
    MongoDB v3.6.3\nData Aggregator\nLibraries and Framework\nTornado Web Server,\
    \ PyMongo,\nJSON, Paho\nCommunication Supports\nHTTP-POST and MQTT\nData Filter\n\
    Libraries and Framework\nPyMongo, JSON, Numpy, Scipy\nand KalmanFilter\nData Synchronization\n\
    Libraries and Framework\nPyMongo, JSON , Pandas, Statistics\nand Threading\nMachine\
    \ Learning and Real-time\nData Classiﬁcation\nLibraries and Framework\nsklearn,\
    \ Pandas, PyMongo, JSON,\nand Threading\nOutput\nUser Interfaces and Data Export\n\
    Programming Language\nPHP, CSS, HTML and Javascript\nLibraries and Framework\n\
    CodeIgniter, Bootstrap, JQuery,\nHighChart JS, DataTables,\nOpenStreetMap\nWeb\
    \ services\nApache v2.4.29, PHP 7.2.24\nDevelopment Pattern\nMVC\nSupported browsers\n\
    Google Chrome, Firefox, Opera\nREST API\nLibraries and Framework\nTornado Web\
    \ Server, PyMongo,\nand JSON\nCommunication Supports\nHTTP-POST\nNotiﬁcation Functions\n\
    Libraries and Framework\nPyMongo, JSON, Paho, smtplib\nNotiﬁcation supports\n\
    Email and MQTT\nEmail Service\nPostﬁx\nManagement\nManagement Services\nLibraries\
    \ and Framework\nTornado Web Server, PyMongo and\nJSON\nCommunication Supports\n\
    HTTP-POST\nIn this implementation, the following two types of communication protocol\
    \ services\nare implemented for data input. Mosquitto [52] is installed for the\
    \ MQTT broker. It allows\nthe platform to receive messages through various MQTT\
    \ versions, and supports connections\nfrom Wi-Fi, Ethernet, and Cellular network\
    \ interfaces. Then, REST API is implemented\nSensors 2022, 22, 6436\n13 of 28\n\
    based on Python programming and Tornado web server [53]. It allows the platform\
    \ to\nreceive messages through HTTP POST and supports connections from Wi-Fi,\
    \ Ethernet, and\nCellular network interfaces.\nThe data process is deployed and\
    \ implemented in the platform. They are developed in\nPython using a variety of\
    \ modules and dependencies. For IoT data management systems,\nwe used two different\
    \ databases service implemented in the platform according to the\ndesign in Section\
    \ 3. The Big Data repository MongoDB [54] is utilized for the data storage\nfor\
    \ managements, sensors, and schema. MongoDB saves data in the JSON format as the\n\
    ﬂexible approach—there is no need to deﬁne data structures, unlike SQL. In addition,\
    \ the\nlog ﬁle is implemented in the CSV format. It can be accessed using a ﬁle\
    \ controller library\nin Python.\nTwo different data aggregators are implemented.\
    \ The ﬁrst one enables message\nreceptions using the MQTT communication protocol.\
    \ It allows a different MQTT communi-\ncation settings for each sensor device.\
    \ The second one does it with REST API. Both data\naggregators access the data\
    \ storage via PyMongo.\nIn this study, the data ﬁlter and synchronization capabilities\
    \ are utilized to process\nsensor data. Scipy and KalmanFilter Python libraries\
    \ are used to apply the data ﬁlters. After\nﬁltering the data, PyMongo is used\
    \ to save it in the data storage. The data synchronization\nused PyMongo for sensor\
    \ data in the data storage. Pandas is used for grouping data sensors.\nThreading\
    \ library is used to enhance the performance of the platform. This function runs\n\
    periodically on the server based on the detection time. The user can stop and\
    \ start this\nservice at the administration page in the user interface. Figure\
    \ 2 illustrates the user interface\nof the data synchronization function for the\
    \ sensor data during 30 s.\nFigure 2. Interface of data synchronization function.\n\
    According to the design systems in Section 3, the data analysis systems consist\
    \ learn-\ning process and real-time analysis service. We implemented both services\
    \ in Python.\nScikit-learn [55] is used to facilitate the learning process. The\
    \ Sklearn library is utilized for\nreal-time analysis to make the classiﬁcation\
    \ model during the learning process.\nData output includes the data visualization\
    \ and the data sharing with other systems\nincluding the plug-in systems. The\
    \ CodeIgniter PHP Framework is adopted to create user\ninterfaces based on the\
    \ Model-View-Control (MVC) design paradigm [56]. A user interface\nwill offer\
    \ data visualizations using HighchartJS, DataTalbes, and OpenStreetMap. Here,\
    \ Apache\nand PHP are required. Figure 3 shows the table of sensor data. Figure\
    \ 4 show graphs of\nsensor data.\nSensors 2022, 22, 6436\n14 of 28\nFigure 3.\
    \ Table of sensor data.\nFigure 4. Graphs of sensor data.\nDataTables library\
    \ is used to allow the user to download sensor data in Excel, JSON,\ntext, and\
    \ CSV formats at the speciﬁed times. Figure 5 show the data export interface.\n\
    REST API is built with Python and Tornado. It allows other application systems\
    \ and plug-in\nfunctions to access to sensor data in JSON formats.\nFigure 5.\
    \ Data export interface.\nFinally, The management service is built in Python and\
    \ Tornado web server. It allows\nus to receive messages through HTTP POST, and\
    \ to access data storage by PyMongo.\n5. Integration of Air Quality Monitoring\
    \ System\nAs the ﬁrst IoT application system, the air quality monitoring system\
    \ is integrated in the\nproposed platform. It can monitor the air quality in smart\
    \ cities.\n5.1. System Architecture\nFigure 6 shows the system overview. This\
    \ system uses a single-board computer (SBC)\nthat is connected to the GPS sensor\
    \ device and the air quality sensor device through Wi-Fi.\nThe air quality sensor\
    \ device covers the carbon monoxide sensor (MQ7), the particulate mat-\nter sensor\
    \ (Shinyei PPD42), the sulfur dioxide sensor (MQ135), the ozone sensor (MQ131),\n\
    Sensors 2022, 22, 6436\n15 of 28\nand the nitrogen dioxide sensor (MiCS 2714.\
    \ The sensor sends the voltage measurement\ndata to the Arduino UNO via GPIO.\
    \ Arduino UNO converts the data into the value of the\npollutant concentration\
    \ level and sends it to the SBC via the MQTT protocol. When the\nair sensor data\
    \ are received, the SBC adds the current time and the location information\n(latitude\
    \ and longitude) from the GPS sensor to the air sensor data, and sends it in the\n\
    JSON format every ﬁve seconds through the MQTT connection.\nFigure 6. System overview\
    \ of air quality monitoring system.\n5.2. Implementation in Platform\nFigure 7\
    \ shows the ﬂow of the functions in the SEMAR server platform for integrating\n\
    this IoT application system. Through the MQTT connection, the data aggregator\
    \ receives\nthe sensor data and stores it in the data storage. The real-time classiﬁcation\
    \ estimates the air\nquality index from the data between 0 and 4 that corresponds\
    \ to the air quality categories\nof good, moderate, poor, very poor, and hazardous.\
    \ The output data are shown at the user\ninterface.\nFigure 7. Function ﬂow for\
    \ air quality monitoring system in platform.\nTo evaluate the system integration,\
    \ we run the system to monitor actual air quality\nconditions. The sensor device\
    \ is mounted on the vehicle, and the single-board computer\nsystem is placed inside\
    \ the vehicle during the experiment. The device system sends air\nquality and\
    \ GPS data every ﬁve seconds. The evaluation results show that SEMAR has\nsuccessfully\
    \ received the sensor data, processed it, and classiﬁed the air quality index\
    \ based\non it. The results can be displayed on the user interface in real-time.\
    \ Table 3 shows the\nevaluation results of the classiﬁcation model used in this\
    \ experiment. We compare two\nalgorithms consisting of Support Vector Machine\
    \ (SVM) and Decision Tree (DT).\nTable 3. Evaluation of air quality monitoring\
    \ classiﬁcation model.\nFeatures\nAlgorithm\nMislabel\nAccuracy\nMSE\nAir Quality\n\
    Support Vector Machine\n605/10,053\n0.94239\n0.05761\nDecision Tree\n43/10,053\n\
    0.99591\n0.00409\nSensors 2022, 22, 6436\n16 of 28\nTable 3 illustrates that the\
    \ accuracy of the developed model is higher than 90%; there-\nfore, we can conclude\
    \ that the real-time classiﬁcation function to determine the air quality\nin SEMAR\
    \ provides advantages over similar studies, including the study by Toma et al.\n\
    in [21].\nMoreover, we also conducted experiment for hyper parameters tuning.\
    \ Table 4 shows\nthe experiment setup for optimizing the hyper parameters using\
    \ the randomized search\nmethod in this IoT Application.\nTable 4. Experiment\
    \ setup for hyper parameter optimizations in air quality monitoring.\nComponent\n\
    Speciﬁcation\nOperating System\nWindows 10 Enterprise, 64-bit\nProcessor\nAMD\
    \ Ryzen 5 3550H\nRAM memory\n8.0 GB\nMachine Learning Library\nScikit-learn [55]\n\
    Machine Learning Method\nSupport Vector Machine and Decision Tree\nDatasets\n\
    25,000 rows air quality data (5 labels, 5\nfeatures)\nFigure 8 shows the confusion\
    \ matrices for the Decision Tree algorithm and the Support\nVector Machine algorithm\
    \ in the air quality monitoring application. For Decision Tree,\nmax_depth = 12,\
    \ min_samples_split = 4, min_samples_lea f = 9, and min_weight_fraction\n_lea\
    \ f = 0.0 are obtained, where the accuracy of the model is 99%. For Support Vector\n\
    Machine, kernel = ”linear”, C = 1, and gamma = 0.01 are obtained, where accuracy\
    \ of the\nmodel is 95%.\nFigure 8. Confusion matrices of Decision Tree and Support\
    \ Vector Machine.\n6. Integration of Water Quality Monitoring System\nAs the second\
    \ IoT application system, the water quality monitoring system is integrated.\n\
    It can monitor the water quality in rivers ﬂowing in smart cities.\n6.1. System\
    \ Architecture\nFigure 9 shows the overview of the system architecture. This system\
    \ utilizes the sensor\ndevice equipped with water quality sensors for the hydrogen\
    \ potential (pH), the oxidation\nreduction potential (ORP), the dissolved oxygen\
    \ (DO), the electrical conductivity (EC),\nthe temperature, total dissolved solids\
    \ (TDS), the salinity (Sal), and the speciﬁc gravity\n(SG). The edge computing\
    \ device Raspberry Pi 3 collects the sensor data every ﬁve seconds\nand sends\
    \ it to a server. The system was tested at various points in the river in Surabaya,\n\
    Indonesia. The sensor node detects multiple parameters of water quality.\nSensors\
    \ 2022, 22, 6436\n17 of 28\nFigure 9. The system overview of the water monitoring\
    \ system.\n6.2. Implementation in Platform\nFigure 10 shows the ﬂow of the functions\
    \ in the platform for integrating this IoT\napplication system. Through the MQTT\
    \ connection, the data aggregator receives sensor\ndata from the devices and stores\
    \ it in the data storage. The real-time classiﬁcation function\nestimates the\
    \ water quality index from the collected data with a number between 0 and\n3 corresponding\
    \ to lightly polluted, heavy polluted, and polluted. The output data are\nshown\
    \ in the user interface.\nFigure 10. Function ﬂow for water quality monitoring\
    \ system in platform.\nWe evaluated the efficacy of the integration of SEMAR with\
    \ the water quality monitoring\nsystem. The evaluation was conducted by operating\
    \ the system in a real-world environment\nto monitor the water quality of a river.\
    \ The device transmits the water sensor data to the\nSEMAR server every five seconds\
    \ through MQTT communications. The experiment results\nindicate that the server\
    \ received the sensor data, classified the water quality index based on the\n\
    obtained data, and displayed it on the user interface in real-time. In addition,\
    \ we compared\nthe SVM and DT machine learning algorithms. are presented in Table\
    \ 5 shows the evaluation\nresults of the classification model utilized in the\
    \ real-classification function.\nTable 5. Evaluation of water quality monitoring\
    \ classiﬁcation model.\nFeatures\nAlgorithm\nMislabel\nAccuracy\nMSE\nWater Quality\n\
    Support Vector Machine\n289/45,397\n0.9936\n0.0064\nDecision Tree\n34/45,397\n\
    0.9993\n0.0007\nTable 5 shows that the accuracy of the classiﬁcation model for\
    \ the water quality is\nhigher than 90%. Thus, the superiority of SEMAR on the\
    \ integration with water quality\nmeasurement systems was conﬁrmed with abilities\
    \ to receive and classify data in real-time.\n7. Integration of Road Condition\
    \ Monitoring System\nAs the third IoT application system, the road condition monitoring\
    \ system is integrated.\nIt can monitor road surface conditions in smart cities.\n\
    Sensors 2022, 22, 6436\n18 of 28\n7.1. System Architecture\nFigure 11 shows the\
    \ system architecture overview. This system is implemented as a\nmobile-based\
    \ sensor network attached to the vehicle. This concept is called Vehicle as a\n\
    Mobile Sensor Network (VaaMSN). This system consists of the edge computing device,\
    \ the\nportable wireless camera, and the sensor device. The camera records the\
    \ road conditions in\nfront of the vehicle and transmits the image frames through\
    \ Real-Time Streaming Protocol\n(RTSP). The sensor device collects GPS, accelerometer,\
    \ and gyroscopes data, and transmits\nthem to the edge computing device via MQTT\
    \ protocol.\nFigure 11. System overview of road condition monitoring system.\n\
    The edge computing device detects potholes from the camera images using the deep\n\
    learning approach, OpenCV [57], and Tensorﬂow [58]. When detecting a pothole,\
    \ image\ndata are recorded in the directory ﬁle. Figure 12 shows the detected\
    \ pothole example by\nthe system. The edge computing will send the location, the\
    \ accelerometer, the gyroscopes,\nand the pothole state to the server through\
    \ the MQTT connection.\nFigure 12. Detected pothole example.\nSensors 2022, 22,\
    \ 6436\n19 of 28\n7.2. Implementation in Platform\nFigure 13 shows the ﬂow of\
    \ the functions in the platform for integrating this IoT\napplication system.\
    \ The data aggregator receives sensor data from the device through the\nMQTT connection,\
    \ and stores it in the data storage. The output data appear in the user\ninterface.\n\
    Figure 13. Function ﬂow for road condition detection system in platform.\nTo evaluate\
    \ the system integration, we run the road condition monitoring system\nto monitor\
    \ road surfaces in actual conditions. We place the sensor device in the vehicle\n\
    according to the layout shown in the system overview. They send JSON data consisting\n\
    of the GPS location, accelerometer, gyroscope, and pothole status to the server\
    \ through\nMQTT communications when the system detects a pothole, as shown in\
    \ Figure 12. The\nexperiment results show that the system can receive data from\
    \ the device, process it, and\ndisplay it on the map of the user interface in\
    \ real-time.\n8. Integration of Air-conditioning Guidance System\nAs the fourth\
    \ IoT application system, the air-conditioning guidance system (AC-Guide) is\n\
    integrated. It can offer the guidance for the optimal use of air-conditioning\
    \ (AC) in smart\ncities [59].\n8.1. System Architecture\nFigure 14 illustrates\
    \ the system architecture overview. AC-Guide uses a web camera,\na DHT22 sensor,\
    \ and Raspberry Pi 3 model b+ as the sensor device. The Python program\nof the\
    \ system periodically (1) collects the humidity and temperature of the room and\
    \ the\nAC control panel photo, (2) collects the standard outdoor weather data\
    \ by accessing to\nOpenWeatherMap API [60], (3) calculates the indoor discomfort\
    \ index (DI) to determines\nwhether the indoor state is comfort or discomfort,\
    \ (4) calculates the outdoor DI to determines\nwhether the outdoor state is comfort\
    \ or discomfort, (5) detects the on/off state of the AC from\nthe photo, (6) sends\
    \ the message to turn on or turn off the AC considering the indoor DI,\nthe outdoor\
    \ DI, and the on/off state of AC, (7) saves the data in the log ﬁle, and (8) send\n\
    the data to the server using the MQTT connection.\nFigure 14. System overview\
    \ of AC-Guide.\nSensors 2022, 22, 6436\n20 of 28\n8.2. Implementation in Platform\n\
    Figure 15 shows the ﬂow of the functions in the platform for integrating this\
    \ IoT\napplication system.\nFigure 15. Function ﬂow for AC-Guide in platform.\n\
    We evaluated the effectiveness of the integration of SEMAR with the air-conditioning\n\
    guidance system. The experiment was carried out by running the system at the #2\
    \ Engineer-\ning Building in Okayama University. The device sends JSON data containing\
    \ the indoor\nhumidity, indoor temperature, indoor discomfort index (DI), outdoor\
    \ humidity, outdoor\ntemperature, outdoor discomfort index (DI), and state of\
    \ AC using MQTT communications\nevery one minute. The evaluation results show\
    \ that SEMAR can receive sensor data and\ndisplay sensor data in real-time on\
    \ the user interface. Previously, these data were not\naccessible from other systems.\
    \ By integrating SEMAR, they can access the data through\nREST API. In addition,\
    \ SEMAR allows adding new sensors to the system without changing\nthe codes; therefore,\
    \ the advantages of integrating the SEMAR system is conﬁrmed.\n9. Integration\
    \ of Fingerprint-based Indoor Localization System\nAs the last IoT application\
    \ system, the ﬁngerprint-based indoor localization system using\nIEEE802.15.4\
    \ protocol (FILS15.4) is integrated. It detects the user locations in indoor environ-\n\
    ments according to the ﬁngerprints of the target location. The process is divided\
    \ into the\ncalibration phase and the detection phase [61,62].\n9.1. System Architecture\n\
    Figure 16 illustrates the overview of FILS15.4 architecture. This system adopts\
    \ trans-\nmitting and receiving devices by Mono Wireless which employs the IEEE802.15.4\
    \ protocol\nat 2.4 GHz [63]. The transmitter Twelite 2525 is small with 2.5 ×\
    \ 2.5 cm and can be powered\nwith a coin battery for a long time. The receiver\
    \ Mono Stick is connected to Raspberry Pi over\na USB port. To improve the detection\
    \ accuracy, the sufﬁcient number of receivers should be\nlocated at proper locations\
    \ in the target area.\nFigure 16. System overview of FILS15.4.\nRaspberry Pi receives\
    \ data from a transmitter, determines the link quality indication\n(LQI) for each\
    \ transmitter, sends the LQI with the ID to the MQTT broker using the MQTT\nprotocol.\
    \ The server receives them from the MQTT broker, synchronizes the data from all\n\
    the receivers, calculates the average LQI with the same transmitter ID, and keeps\
    \ the results\nSensors 2022, 22, 6436\n21 of 28\nin one record in the SQLite database.\
    \ The previous implementation used a free public\nMQTT service.\n9.2. Calibration\
    \ Phase\nThe calibration phase generates and stores the ﬁngerprint dataset. Each\
    \ ﬁngerprint\nconsists of n LQI values where n represents the number of receivers.\
    \ It represents the\ntypical LQI values when a transmitter is located at the corresponding\
    \ location (room in\nFILS15.4).\n9.3. Detection Phase\nThe detection phase detects\
    \ the current room by calculating the Euclidean distance\nbetween the current\
    \ LQI data and the ﬁngerprint for each room and ﬁnding the ﬁngerprint\nwith the\
    \ smallest distance.\n9.4. Implementation in Platform\nFigure 17 shows the ﬂow\
    \ of the functions in the platform for integrating this IoT\napplication system.\
    \ The data synchronization function synchronizes the measured LQI\nvalues among\
    \ all the receivers using the transmitter’s ID, and saves it in the schema data\n\
    storage. The detection program is implemented as the plug-in function in the platform,\
    \ and\nreceives data through REST API services.\nFigure 17. Function ﬂow for FILS15.4\
    \ in platform.\nWe evaluate the integration of SEMAR with the ﬁngerprint-based\
    \ indoor localization\nsystem by running the system at two ﬂoors in the #2 Engineering\
    \ Building of Okayama\nUniversity. This system used six receivers to measure LQI\
    \ from each transmitter. The\nreceiver sent the LQI data every 500 ms to the server\
    \ through MQTT communications.\nThe evaluation results show that SEMAR can receive,\
    \ process, and visualize the data. We\nalso evaluate the data synchronization\
    \ of the LQI data at the multiple receivers from the\nsame transmitter. Figure\
    \ 18 shows the synchronized LQI data for transmitter 1 during 30 s,\nwhere LQi\
    \ for i = 1, . . . , 6 indicates the LQI data at receiver i. They are saved in\
    \ the schema\ndata storage and can be accessed from other programs through REST\
    \ API. This system can\nrun without interruptions even if it processes empty LQI\
    \ data or if error detection occurs.\nWhen the system detects an error, it sets\
    \ the LQI data to the default value. According to the\nevaluation results, the\
    \ effectiveness of integrating the SEMAR system is conﬁrmed.\nFigure 18. LQI data\
    \ of transmitter 1.\nSensors 2022, 22, 6436\n22 of 28\n10. Evaluations\nIn this\
    \ section, we evaluate the implementation of SEMAR IoT server platform.\n10.1.\
    \ Performance Analysis\nTo evaluate the performance of SEMAR at the parameter\
    \ level, ﬁrst, we investigate the\naverage response time for MQTT data communications\
    \ when the number of IoT devices is\nincreased from 1 to 125. In the experiments,\
    \ a virtual IoT device is created in the system\ninstead of a real device. Then,\
    \ each virtual IoT device sends one message through a\ndifferent topic every second.\
    \ During this experiment, the CPU usage rate of the machine is\nalso measured.\n\
    As the response time, the time difference at a virtual IoT device from the data\
    \ transmis-\nsion to the server to the message reception from the server is measured.\
    \ For HTTP POST, it\ncan easily be obtained. When the IoT device sends data to\
    \ the server, the REST API service\nreturns the response message; however, for\
    \ MQTT, the program is modiﬁed to measure the\nresponse time where it will send\
    \ the MQTT message to the device when it stores data in\nthe storage.\nFigures\
    \ 19 and 20 show the average response time and the average CPU usage rate\nwhen\
    \ the number of virtual IoT devices is increased from 1 to 125, respectively.\
    \ The average\nresponse time is 315ms and the CPU usage rate is 74% for 125 devices.\
    \ Thus, SEMAR our\ncan handle hundreds of devices with acceptable delay and CPU\
    \ rate.\nFigure 19. Average response time for MQTT communications with different\
    \ numbers of devices.\nFigure 20. Average CPU usage rate with different numbers\
    \ of devices.\n10.2. The State-of-the-Art Comparative Analysis\nWe compare the\
    \ SEMAR IoT server platform with 14 recent research works that have\nthe similar\
    \ approach. In the comparison with the recent related works in the literature,\
    \ we\nconsider the following features to characterize each proposal:\nSensors\
    \ 2022, 22, 6436\n23 of 28\n•\nIoT application: represents the IoT application\
    \ that is covered or implemented in each\nwork.\n•\nDevice management: indicates\
    \ the capability of the IoT platform to manage devices (Yes\nor No).\n•\nCommunication\
    \ protocol: describes the communication protocol utilized in each work.\n•\nData\
    \ synchronization: implies the capability to synchronize data across several devices\n\
    (Yes or No).\n•\nData ﬁltering function: indicates the implementation of digital\
    \ ﬁlters to process data\n(Yes or No).\n•\nDecision-making assistance: indicates\
    \ the implementation of tools to evaluate data or\ngenerate alerts based on data\
    \ obtained (Yes or No).\n•\nFlexibility: shows the abilities to allow to join\
    \ new devices, to handle different commu-\nnication settings, to deﬁne data types,\
    \ and to easily interact with external systems (Yes\nor No).\n•\nInteroperability:\
    \ represents the ability to be integrated with plural external systems\nthrough\
    \ deﬁned protocols (Yes or No).\n•\nScalability: demonstrates the capability of\
    \ processing a number of data simultaneously\n(Yes or No).\nTable 6 compares the\
    \ fulﬁllment of the nine features among the 14 related works and\nthe proposed\
    \ SEMAR.\nTable 6. State-of-the-art comparison between the existing related studies\
    \ and the proposed solution.\nWork\nReference\nIoT Appli-\ncation\nDevice\nManagement\n\
    Data\nSynchronization\nData Filter\nDecision-\nmaking\nassistance\nFlexibility\n\
    Interoperability\nScalability\nCommunication\nProtocol\n[17]\nIndoor Air Quality\n\
    ✓\n\x17\n\x17\n\x17\n✓\n\x17\n✓\nHTTP\n[64]\nSmart Agriculture\n✓\n\x17\n\x17\n\
    ✓\n✓\n✓\n✓\nMQTT\n[18]\nAir Pollution\n✓\n\x17\n\x17\n✓\n\x17\n\x17\n✓\nHTTP\n\
    [19]\nWater Management\n✓\n\x17\n\x17\n\x17\n\x17\n\x17\n✓\nHTTP\n[65]\nWater\
    \ Management\n✓\n\x17\n\x17\n✓\n✓\n✓\n✓\nMQTT\n[21]\nAir Pollution\n✓\n\x17\n\x17\
    \n\x17\n✓\n✓\n✓\nMQTT\n[66]\nIndoor Air Quality\n✓\n\x17\n\x17\n✓\n\x17\n✓\n✓\n\
    MQTT\n[67]\nSmart City\n✓\n\x17\n\x17\n\x17\n\x17\n\x17\n✓\nHTTP & AMQP\n[68]\n\
    Smart Industry\n✓\n\x17\n\x17\n✓\n✓\n✓\n✓\nMQTT\n[69]\nSmart Agriculture and Smart\
    \ City\n✓\n\x17\n\x17\n\x17\n✓\n✓\n✓\nMQTT\n[70]\nSmart Farming\n✓\n\x17\n\x17\
    \n✓\n✓\n✓\n✓\nMQTT\n[22]\nSmart Building\n✓\n\x17\n\x17\n✓\n\x17\n✓\n✓\nHTTP &\
    \ Web Socket\n[71]\nSmart Irrigation\n✓\n\x17\n\x17\n✓\n\x17\n\x17\n✓\nMQTT\n\
    [72]\nSmart Green and Smart City\n✓\n\x17\n\x17\n\x17\n✓\n✓\n✓\nHTTP, MQTT, AMQP\n\
    SEMAR\nVarious IoT applications\n✓\n✓\n✓\n✓\n✓\n✓\n✓\nHTTP & MQTT\n10.2.1. IoT\
    \ Application\nAlthough the works by Hernández-Rojas et al. in [64], Marcu et\
    \ al. in [69], and\nAntunes et al. in [72] have potentials of use in various IoT\
    \ applications, they have been\nstudied in speciﬁc IoT applications. On the other\
    \ hand, SEMAR has been integrated and\nimplemented in several types of IoT applications.\n\
    10.2.2. IoT Device Management\nAll the related works provide functions to add\
    \ or remove IoT devices. Some works\nsupport device management services. Some\
    \ works include capabilities to deﬁne the sensor\nSensors 2022, 22, 6436\n24 of\
    \ 28\nformat for each IoT device dynamically. The work by Trilles et al. in [70]\
    \ provides the\neasy-to-use user interface to manage IoT devices. On the other\
    \ hand, SEMAR provides all\nof the functions on IoT devices.\n10.2.3. Communication\
    \ Protocol\nHTTP and MQTT are the most adopted communication protocols in IoT\
    \ application\nplatforms. In addition, Del Esposte in [67] and Antunes in [72]\
    \ introduce AMQP as another\nprotocol utilizing TCP connections. Thus, it is suitable\
    \ for server–client communications\n[73]. None of the related works reported functions\
    \ to synchronize data from several\ndevices and digital ﬁlters to process sensor\
    \ data. Only SEMAR provides both the data\nsynchronization capability and digital\
    \ ﬁlters to process data.\n10.2.4. Decision Making Assistance\nFor decision-making\
    \ assistance, a lot of works have offered functions for perspec-\ntive data analysis\
    \ based on collected data. The works by Mandava et al. in [18], by\nKamienski\
    \ et al. in [65], by Chiesa et al. in [66], and by Boursianis et al. in [71] applied\n\
    machine learning algorithms for real-time classiﬁcations, and show the results\
    \ for user\ninterfaces. The work by Hernández-Rojas et al. in [64] utilized message\
    \ notiﬁcations\naccording to a speciﬁc data threshold. The work by Trilles et\
    \ al. in [70] and our SEMAR\nincluded both of them.\n10.2.5. Interoperability\
    \ and Flexibility\nSeveral works provided interoperability. The works by Hernández-Rojas\
    \ et al. in [64],\nby Trilles et al. in [70], and SEMAR allow outer programs to\
    \ process data without changing\nthe existing program in the systems.\nSome works\
    \ consider the ﬂexibility as the IoT application platform. The works by\nHernández-Rojas\
    \ et al. in [64] and by Trilles et al. in [70] provide the capability to dynami-\n\
    cally deﬁne the sensor format and the data type for each device, similar to SEMAR.\n\
    However, any work cannot be connected with other MQTT servers. Only SEMAR\nﬂexibly\
    \ allows users to use other MQTT servers, which will allow IoT applications to\
    \ be\neasily integrated with SEMAR.\n11. Threats to Validity\nThere are two kinds\
    \ of threats to the validity of this research, which are as follows:\n•\nInternal\
    \ validity threat: validates the potential errors in the SEMAR implementation.\n\
    In this study, SEMAR is integrated with ﬁve different IoT application systems.\
    \ Each\nIoT application utilized various kinds of sensors. Possible threats may\
    \ occur when\nsubmitting invalid or incomplete data. Moreover, the integration\
    \ of SEMAR with the\nﬁngerprint-based indoor localization system requires the\
    \ synchronization of data from\neach receiver to determine the location of the\
    \ transmitter. To eliminate potential\nthreats, SEMAR checks sensor data with\
    \ the format. In addition, the data synchro-\nnization function will provide default\
    \ values for devices with no data within the data\nsynchronization timeframe.\n\
    •\nExternal validity threat: validates the generalization ability of the obtained\
    \ results. We\ncompare the results of SEMAR to those of previous IoT-related studies.\
    \ The primary\npotential external threat revealed by the comparison results is\
    \ that not all of the related\nIoT-related research provided comprehensive and\
    \ clear explanations of the proposals.\n12. Conclusions\nThis paper presented\
    \ the design and implementation of the IoT server platform for\nintegrating various\
    \ IoT application systems, called Smart Environmental Monitoring and\nAnalytical\
    \ in Real-Time (SEMAR). It offers Big Data environments with built-in functions\
    \ for\ndata aggregations, synchronizations, and classiﬁcations with machine learning,\
    \ and plug-in\nfunctions that access to the data through REST API. The platform\
    \ was implemented and\nSensors 2022, 22, 6436\n25 of 28\nintegrated with ﬁve IoT\
    \ application systems. The results conﬁrmed the effectiveness and\nefﬁciency of\
    \ the proposal.\nIn future studies, we will continue improving the platform by\
    \ implementing Rules\nEngine and Complex Event Processing (CEP) [74] for the data\
    \ processing. Rules Engine\nwill support user-deﬁned rules, actions, and notiﬁcations.\
    \ CEP will offer the real-time\ndata analysis based on rule patterns [75]. It\
    \ will control the device action or deliver\nmessages to users when rule patterns\
    \ are matched; however, these functions meet issues in\nparallelism, resource\
    \ allocations, distributed networks, and multi-rules optimizations [76],\nwhich\
    \ will be studied. Then, we will continue integrating the proposal with various\
    \ IoT\napplication systems.\nAuthor Contributions: Conceptualization, Y.Y.F.P.,\
    \ N.F. and S.S.; Methodology, Y.Y.F.P.; Software,\nY.Y.F.P. and P.P.; Writing—Original\
    \ Draft Preparation, Y.Y.F.P.; Writing—Review and Editing, N.F.; Vali-\ndation,\
    \ M.K. and W.-C.K. All authors have read and agreed to the published version of\
    \ the manuscript.\nFunding: This research received no external funding.\nInstitutional\
    \ Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\n\
    Data Availability Statement: Not applicable.\nAcknowledgments: The authors thank\
    \ the reviewers for their thorough reading and helpful comments.\nConﬂicts of\
    \ Interest: The authors declare no conﬂict of interest.\nReferences\n1.\nTheoﬁlou,\
    \ P. Quality of Life: Deﬁnition and Measurement. Eur. J. Psychol. 2013, 9, 150–162.\
    \ [CrossRef]\n2.\nMacke, J.; Casagrande, R.; Sarate, J.; Silva, K. Smart City\
    \ and Quality of Life: Citizens’ perception in a Brazilian case study.\nJ. Clean.\
    \ Prod. 2018, 182, 717–726. [CrossRef]\n3.\nNoura, M.; Atiquzzaman, M.; Gaedke,\
    \ M. Interoperability in Internet of Things: Taxonomies and Open Challenges. Mob.\
    \ Networks\nAppl. 2018, 24, 796–809. [CrossRef]\n4.\nCubo, J.; Nieto, A.; Pimentel,\
    \ E. A Cloud-Based Internet of Things Platform for Ambient Assisted Living. Sensors\
    \ 2014, 14,\n14070–14105. [CrossRef]\n5.\nLeong, W.; Kelani, R.; Ahmad, Z. Prediction\
    \ of Air Pollution Index (API) using Support Vector Machine (SVM). J. Environ.\
    \ Chem.\nEng. 2020, 8, 103208. [CrossRef]\n6.\nPerlmutt, L.; Cromar, K. Comparing\
    \ Associations of Respiratory Risk for The EPA Air Quality Index and Health-Based\
    \ Air\nQuality Indices. Atmos. Environ. 2019, 202, 1–7. [CrossRef]\n7.\nMQTT Org.\
    \ Message Queuing Telemetry Transport Protocol. Available online: http://mqtt.org/\
    \ (accessed on 12 May 2022).\n8.\nKamienski, C.; Prati, R.; Kleinschmidt, J.;\
    \ Soininen, J.P. Designing an Open IoT Ecosystem. In Proceedings of the Workshop\
    \ on\nCloud Networks 2019, Belem, Brazil, 16 July 2019.\n9.\nBansal, S.; Kumar,\
    \ D. IoT Ecosystem: A Survey on Devices, Gateways, Operating Systems, Middleware\
    \ and Communication. Int.\nJ. Wirel. Inf. Netw. 2020, 27, 340–364. [CrossRef]\n\
    10.\nLi, S.; Xu, L.; Zhao, S. The Internet of Things: A Survey. Inf. Syst. Front.\
    \ 2014, 17, 243–259. [CrossRef]\n11.\nMalche, T.; Maheshwary, P.; Kumar, R. Environmental\
    \ Monitoring System for Smart City Based on Secure Internet of Things (IoT)\n\
    Architecture. Wirel. Pers. Commun. 2019, 107, 2143–2172. [CrossRef]\n12.\nVenkanna,\
    \ U.; Sharma, S.; Katiyar, B.; Prashanth, Y. A Wireless Sensor Node Based Efﬁcient\
    \ Parking Slot Availability Detection\nSystem for Smart Cities. In Proceedings\
    \ of the 2018 Recent Advances on Engineering, Technology and Computational Sciences\n\
    (RAETCS), Allahabad, India, 6–8 February 2018; pp. 1–6.\n13.\nZhang, Q.; Zhong,\
    \ H.; Shi, W.; Liu, L. A Trusted and Collaborative Framework for Deep Learning\
    \ in IoT. Comput. Netw. 2021, 193,\n108055. [CrossRef]\n14.\nJain, V.; Ahuja,\
    \ A.; Saini, D. Evaluation and Performance Analysis of Apache Pulsar and NATS.\
    \ In Cyber Security and Digital\nForensics; Lecture Notes on Data Engineering\
    \ and Communications Technologies; Springer: Singapore, 2021; pp. 179–190.\n[CrossRef]\n\
    15.\nDizdarevi´c, J.; Carpio, F.; Jukan, A.; Masip-Bruin, X. A Survey of Communication\
    \ Protocols for Internet of Things and Related\nChallenges of Fog and Cloud Computing\
    \ Integration. ACM Comput. Surv. 2019, 51, 1–29. [CrossRef]\n16.\nMarques, G.;\
    \ Pitarma, R. An Internet of Things-Based Environmental Quality Management System\
    \ to Supervise the Indoor\nLaboratory Conditions. Appl. Sci. 2019, 9, 438. [CrossRef]\n\
    17.\nBenammar, M.; Abdaoui, A.; Ahmad, S.; Touati, F.; Kadri, A. A Modular IoT\
    \ Platform for Real-Time Indoor Air Quality Monitoring.\nSensors 2018, 18, 581.\
    \ [CrossRef] [PubMed]\nSensors 2022, 22, 6436\n26 of 28\n18.\nMandava, T.; Chen,\
    \ S.; Isaﬁade, O.; Bagula, A. An IoT Middleware for Air Pollution Monitoring in\
    \ Smart Cities: A Situation\nRecognition Model. In Proceedings of the IST Africa\
    \ 2018 Conference, Gabarone, Botswana, 9–11 May 2018.\n19.\nSeno`zetnik, M.; Herga,\
    \ Z.; Šubic, T.; Brade`sko, L.; Kenda, K.; Klemen, K.; Pergar, P.; Mladeni´c,\
    \ D. IoT Middleware for Water\nManagement. Proceedings 2018, 2, 696. [CrossRef]\n\
    20.\nKazmi, A.; Serrano, M.; Soldatos, J. VITAL-OS: An Open Source IoT Operating\
    \ System for Smart Cities. IEEE Commun. Stand.\nMag. 2018, 2, 71–77. [CrossRef]\n\
    21.\nToma, C.; Alexandru, A.; Popa, M.; Zamﬁroiu, A. IoT Solution for Smart Cities’\
    \ Pollution Monitoring and the Security Challenges.\nSensors 2019, 19, 3401. [CrossRef]\
    \ [PubMed]\n22.\nJaved, A.; Malhi, A.; Kinnunen, T.; Framling, K. Scalable IoT\
    \ Platform for Heterogeneous Devices in Smart Environments. IEEE\nAccess 2020,\
    \ 8, 211973–211985. [CrossRef]\n23.\nThe Apache Cassandra Software Project Website.\
    \ Available online: https://cassandra.apache.org/ (accessed on 22 August 2022).\n\
    24.\nBadii, C.; Bellini, P.; Diﬁno, A.; Nesi, P. Smart city IoT Platform Respecting\
    \ GDPR Privacy and Security Aspects. IEEE Access 2020,\n8, 23601–23623. [CrossRef]\n\
    25.\nPutra, K.; Chen, H.; Prayitno; Ogiela, M.; Chou, C.; Weng, C.; Shae, Z. Federated\
    \ Compressed Learning Edge Computing\nFramework with Ensuring Data Privacy for\
    \ PM2.5 Prediction in Smart City Sensing Applications. Sensors 2021, 21, 4586.\n\
    [CrossRef]\n26.\nGautam, G.; Sharma, G.; Magar, B.; Shrestha, B.; Cho, S.; Seo,\
    \ C. Usage of IoT Framework in Water Supply Management for Smart\nCity in Nepal.\
    \ Appl. Sci. 2021, 11, 5662. [CrossRef]\n27.\nOliveira, F.; Costa, D.; Lima, L.;\
    \ Silva, I. iBikeSafe: A Multi-Parameter System for Monitoring, Evaluation and\
    \ Visualization of\nCycling Paths in Smart Cities Targeted at Cycling Adverse\
    \ Conditions. Smart Cities 2021, 4, 56. [CrossRef]\n28.\nMetia, S.; Nguyen, H.;\
    \ Ha, Q. IoT-Enabled Wireless Sensor Networks for Air Pollution Monitoring with\
    \ Extended Fractional-Order\nKalman Filtering. Sensors 2021, 21, 5313. [CrossRef]\
    \ [PubMed]\n29.\nTwahirwa, E.; Rwigema, J.; Datta, R. Design and Deployment of\
    \ Vehicular Internet of Things for Smart City Applications.\nSustainability 2021,\
    \ 14, 176. [CrossRef]\n30.\nD’Ortona, C.; Tarchi, D.; Raffaelli, C. Open-Source\
    \ MQTT-Based End-to-End IoT System for Smart City Scenarios. Future Internet\n\
    2022, 14, 57. [CrossRef]\n31.\nKumar, P.; Gupta, G.; Tripathi, R. Design of Anomaly-Based\
    \ Intrusion Detection System Using Fog Computing for IoT Network.\nAutom. Control.\
    \ Comput. Sci. 2021, 55, 137–147. [CrossRef]\n32.\nKumar, P.; Gupta, G.; Tripathi,\
    \ R. A Distributed Ensemble Design Based Intrusion Detection System Using Fog\
    \ Computing to\nProtect The Internet of Things Networks. J. Ambient. Intell. Humaniz.\
    \ Comput. 2020, 12, 9555–9572. [CrossRef]\n33.\nKumar, P.; Gupta, G.; Tripathi,\
    \ R. Toward Design of an Intelligent Cyber Attack Detection System using Hybrid\
    \ Feature Reduced\nApproach for IoT Networks. Arab. J. Sci. Eng. 2021, 46, 3749–3778.\
    \ [CrossRef]\n34.\nKumar, P.; Gupta, G.; Tripathi, R. PEFL: Deep Privacy-Encoding-Based\
    \ Federated Learning Framework for Smart Agriculture.\nIEEE Micro 2022, 42, 33–40.\
    \ [CrossRef]\n35.\nKumar, P.; Tripathi, R.P.; Gupta, G. P2IDF: A Privacy-preserving\
    \ Based Intrusion Detection Framework for Software Deﬁned\nInternet of Things-fog\
    \ (SDIoT-Fog). In Proceedings of the 2021 International Conference on Distributed\
    \ Computing and\nNetworking, Nara, Japan, 5–8 January 2021; pp. 37–42.\n36.\n\
    Wu, H.; Chen, C.; Weng, K. Two Designs of Automatic Embedded System Energy Consumption\
    \ Measuring Platforms Using\nGPIO. Appl. Sci. 2020, 10, 4866. [CrossRef]\n37.\n\
    Munshi, A. Improved MQTT Secure Transmission Flags in Smart Homes. Sensors 2022,\
    \ 22, 2174. [CrossRef]\n38.\nDinculean˘a, D.; Cheng, X. Vulnerabilities and Limitations\
    \ of MQTT Protocol Used between IoT Devices. Appl. Sci. 2019, 9, 848.\n[CrossRef]\n\
    39.\nAl-Joboury, I.; Al-Hemiary, E. IoT-F2CDM-LB: IoT Based Fog-to-Cloud and Data-in-Motion\
    \ Architectures with Load Balancing.\nEAI Endorsed Trans. Internet Things 2018,\
    \ 4, 155332. [CrossRef]\n40.\nWaseem, M.; Liang, P.; Shahin, M. A Systematic Mapping\
    \ Study on Microservices Architecture in DevOps. J. Syst. Softw. 2020,\n170, 110798.\
    \ [CrossRef]\n41.\nFridelin, Y.; Ulil Albaab, M.; Anom Besari, A.; Sukaridhoto,\
    \ S.; Tjahjono, A. Implementation of Microservice Architectures on\nSEMAR Extension\
    \ for Air Quality Monitoring. In Proceedings of the 2018 International Electronics\
    \ Symposium on Knowledge\nCreation and Intelligent Computing (IES-KCIC) 2018,\
    \ Bali, Indonesia, 29–30 October 2018; pp. 218–224.\n42.\nKumar, P.; Gupta, G.;\
    \ Tripathi, R.; Garg, S.; Hassan, M. DLTIF: Deep Learning-Driven Cyber Threat\
    \ Intelligence Modeling and\nIdentiﬁcation Framework in IoT-Enabled Maritime Transportation\
    \ Systems. IEEE Trans. Intell. Transp. Syst. 2021, 1–10.\n43.\nKumar, P.; Kumar,\
    \ R.; Gupta, G.; Tripathi, R. BDEdge: Blockchain and Deep-Learning for Secure\
    \ Edge-Envisioned Green CAVs.\nIEEE Trans. Green Commun. Netw. 2022, 1330–1339.\n\
    44.\nKumar, P.; Gupta, G.; Tripathi, R. TP2SF: A Trustworthy Privacy-Preserving\
    \ Secured Framework for Sustainable Smart Cities by\nLeveraging Blockchain and\
    \ Machine learning. J. Syst. Archit. 2021, 115, 101954. [CrossRef]\n45.\nKumar,\
    \ P.; Gupta, G.; Tripathi, R. An Ensemble Learning and Fog-cloud Architecture-driven\
    \ Cyber-attack Detection Framework\nfor IoMT Networks. Comput. Commun. 2021, 166,\
    \ 110–124. [CrossRef]\n46.\nChang, C.; Lin, C. LIBSVM: A Library for Support Vector\
    \ Machines. ACM Trans. Intell. Syst. Technol. 2011, 2, 1–27. [CrossRef]\nSensors\
    \ 2022, 22, 6436\n27 of 28\n47.\nSuárez Sánchez, A.; García Nieto, P.; Riesgo\
    \ Fernández, P.; del Coz Díaz, J.; Iglesias-Rodríguez, F. Application of an SVM-based\n\
    regression model to the air quality study at local scale in the Avilés urban area\
    \ (Spain). Math. Comput. Model. 2011, 54, 1453–1466.\n[CrossRef]\n48.\nGhiasi,\
    \ M.; Zendehboudi, S. Decision Tree-Based Methodology to Select a Proper Approach\
    \ for Wart Treatment. Comput. Biol.\nMed. 2019, 108, 400–409. [CrossRef]\n49.\n\
    Hagan, D.; Isaacman-VanWertz, G.; Franklin, J.; Wallace, L.; Kocar, B.; Heald,\
    \ C.; Kroll, J. Calibration and Assessment of\nElectrochemical Air Quality Sensors\
    \ by Co-Location with Regulatory-Grade Instruments. Atmos. Meas. Tech. 2018, 11,\
    \ 315–328.\n[CrossRef]\n50.\nWei, W.; Ramalho, O.; Malingre, L.; Sivanantham,\
    \ S.; Little, J.; Mandin, C. Machine Learning and Statistical Models for Predicting\n\
    Indoor Air Quality. Indoor Air 2019, 29, 704–726. [CrossRef] [PubMed]\n51.\nGhosh,\
    \ S.; Dasgupta, A.; Swetapadma, A. A Study on Support Vector Machine Based Linear\
    \ and Non-Linear Pattern Classiﬁcation.\nIn Proceedings of International Conference\
    \ on Intelligent Sustainable Systems (ICISS) 2019, Palladam, India, 21–22 February\
    \ 2019;\npp. 24–28.\n52.\nMQTT Mosquitto Server. Available online: https://mosquitto.org/\
    \ (accessed on 12 May 2022).\n53.\nDory, M.; Parrish, A.; Berg, B. Introduction\
    \ to Tornado; O’Reilly Media: Sebastopol, CA, USA, 2012.\n54.\nMongoDB, Mongodb:\
    \ The Application Data Platform. Available online: https://www.mongodb.com/(accessed\
    \ on 12 May 2022).\n55.\nHao, J.; Ho, T. Machine Learning Made Easy: A Review\
    \ of Scikit-learn Package in Python Programming Language. J. Educ. Behav.\nStat.\
    \ 2019, 44, 348–361. [CrossRef]\n56.\nGamma, E.; Helm, R.; Johnson, R.; Vlissides,\
    \ J.M. Design Patterns: Elements of Reusable Object-Oriented Software; Addison-Wesley\n\
    Professional; Addison-Wesley: Boston, MA, USA, 1994.\n57.\nVillán, A.F. Mastering\
    \ OpenCV 4 with Python: A Practical Guide Covering Topics from Image Processing,\
    \ Augmented Reality to Deep\nLearning with OpenCV 4 and Python 3.7; Packt Publishing\
    \ Ltd.: Birmingham, UK, 2019.\n58.\nPang, B.; Nijkamp, E.; Wu, Y. Deep Learning\
    \ With TensorFlow: A Review. J. Educ. Behav. Stat. 2019, 45, 227–248. [CrossRef]\n\
    59.\nHuda, S.; Funabiki, N.; Kuribayashi, M.; Sudibyo, R.; Ishihara, N.; Kao,\
    \ W. A Proposal of Air-Conditioning Guidance System Using\nDiscomfort Index. In\
    \ Proceedings of the 15th International Conference on Broad-Band and Wireless\
    \ Computing, Communication\nand Applications (BWCCA-2020), Yonago, Japan, 28–30\
    \ October 2020; pp. 154–165.\n60.\nOpenWeatherMap. Current Weather and Forecast—OpenWeatherMap.\
    \ Available online: https://openweathermap.org/\n(accessed on 12 May 2022).\n\
    61.\nHuo, Y.; Puspitaningayu, P.; Funabiki, N.; Hamazaki, K.; Kuribayashi, M.;\
    \ Kojima, K. A. Proposal of the Fingerprint Optimization\nMethod for the Fingerprint-Based\
    \ Indoor Localization System with IEEE 802.15.4 Devices. Information 2022, 13,\
    \ 211. [CrossRef]\n62.\nPuspitaningayu, P.; Huo, Y.; Funabiki, N.; Hamazaki, K.;\
    \ Kuribayashi, M.; Kao, W. Investigations of Detection Accuracy\nImprovements\
    \ for Fingerprint-based Indoor Localization System Using IEEE 802.15.4. In Proceedings\
    \ of the Fourth International\nConference on Vocational Education and Electrical\
    \ Engineering (ICVEE) 2021, Surabaya, Indonesia, 2–3 October 2021; pp. 1–5.\n\
    63.\nMono Wireless. Mono Wireless Product Information. Available online: https://mono-wireless.com/jp/products/index.html\n\
    (accessed on 12 May 2022).\n64.\nHernández-Rojas, D.; Fernández-Caramés, T.; Fraga-Lamas,\
    \ P.; Escudero, C. A Plug-and-Play Human-Centered Virtual TEDS\nArchitecture for\
    \ the Web of Things. Sensors 2018, 18, 2052. [CrossRef]\n65.\nKamienski, C.; Soininen,\
    \ J.; Taumberger, M.; Dantas, R.; Toscano, A.; Salmon Cinotti, T.; Filev Maia,\
    \ R.; Torre Neto, A. Smart\nWater Management Platform: IoT-Based Precision Irrigation\
    \ for Agriculture. Sensors 2019, 19, 276. [CrossRef]\n66.\nChiesa, G.; Cesari,\
    \ S.; Garcia, M.; Issa, M.; Li, S. Multisensor IoT Platform for Optimising IAQ\
    \ Levels in Buildings through a Smart\nVentilation System. Sustainability 2019,\
    \ 11, 5777. [CrossRef]\n67.\nDe M. Del Esposte, A.; Santana, E.; Kanashiro, L.;\
    \ Costa, F.; Braghetto, K.; Lago, N.; Kon, F. Design and Evaluation of a Scalable\n\
    Smart City Software Platform with Large-Scale Simulations. Future Gener. Comput.\
    \ Syst. 2019, 93, 427–441. [CrossRef]\n68.\nChristou, I.; Kefalakis, N.; Zalonis,\
    \ A.; Soldatos, J.; Bröchler, R. End-to-End Industrial IoT Platform for Actionable\
    \ Predictive\nMaintenance. IFAC-PapersOnLine 2020, 53, 173–178. [CrossRef]\n69.\n\
    Marcu, I.; Suciu, G.; B˘al˘aceanu, C.; Vulpe, A.; Dr˘agulinescu, A. Arrowhead\
    \ Technology for Digitalization and Automation\nSolution: Smart Cities and Smart\
    \ Agriculture. Sensors 2020, 20, 1464. [CrossRef] [PubMed]\n70.\nTrilles, S.;\
    \ González-Pérez, A.; Huerta, J. An IoT Platform Based on Microservices and Serverless\
    \ Paradigms for Smart Farming\nPurposes. Sensors 2020, 20, 2418. [CrossRef] [PubMed]\n\
    71.\nBoursianis, A.; Papadopoulou, M.; Gotsis, A.; Wan, S.; Sarigiannidis, P.;\
    \ Nikolaidis, S.; Goudos, S. Smart Irrigation System for\nPrecision Agriculture—The\
    \ AREThOU5A IoT Platform. IEEE Sens. J. 2021, 21, 17539–17547. [CrossRef]\n72.\n\
    Antunes, M.; Santiago, A.; Manso, S.; Regateiro, D.; Barraca, J.; Gomes, D.; Aguiar,\
    \ R. Building an IoT Platform Based on Service\nContainerisation. Sensors 2021,\
    \ 21, 6688. [CrossRef]\n73.\nDepari, A.; Fernandes Carvalho, D.; Bellagente, P.;\
    \ Ferrari, P.; Sisinni, E.; Flammini, A.; Padovani, A. An IoT Based Architecture\n\
    for Enhancing the Effectiveness of Prototype Medical Instruments Applied to Neurodegenerative\
    \ Disease Diagnosis. Sensors\n2019, 19, 1564. [CrossRef] [PubMed]\n74.\nMazon-Olivo,\
    \ B.; Hernández-Rojas, D.; Maza-Salinas, J.; Pan, A. Rules Engine and Complex\
    \ Event Processor in the Context of\nInternet of Things for Precision Agriculture.\
    \ Comput. Electron. Agric. 2018, 154, 347–360. [CrossRef]\nSensors 2022, 22, 6436\n\
    28 of 28\n75.\nDa Costa Bezerra, S.; Filho, A.; Delicato, F.; da Rocha, A. Processing\
    \ Complex Events in Fog-Based Internet of Things Systems for\nSmart Agriculture.\
    \ Sensors 2021, 21, 7226. [CrossRef]\n76.\nFlouris, I.; Giatrakos, N.; Deligiannakis,\
    \ A.; Garofalakis, M.; Kamp, M.; Mock, M. Issues in Complex Event Processing:\
    \ Status and\nProspects in the Big Data Era. J. Syst. Softw. 2017,127, 217–236.\
    \ [CrossRef]\n"
  inline_citation: '>'
  journal: Sensors
  limitations: '>'
  pdf_link: https://www.mdpi.com/1424-8220/22/17/6436/pdf?version=1661833595
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Implementation of SEMAR IoT Server Platform with Applications
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3844/ajeassp.2022.230.238
  analysis: '>'
  authors:
  - Antreas Kantaros
  - Dimitrios Piromalis
  citation_count: 3
  full_citation: '>'
  full_text: ">\n \n \n© 2022 Antreas Kantaros and Dimitrios Piromalis. This open-access\
    \ article is distributed under a Creative Commons \nAttribution (CC-BY) 4.0 license.\
    \ \nAmerican Journal of Engineering and Applied Sciences \n \n \n \nReview \n\
    Setting up a Digital Twin Assisted Greenhouse Architecture \n \n1Antreas Kantaros\
    \ and 2Dimitrios Piromalis \n \n1Department of Industrial Design and Production\
    \ Engineering, University of West Attica, Greece \n2Department of Electrical and\
    \ Electronics Engineering, University of West Attica, Greece \n \nArticle history\
    \ \nReceived: 25-10-2022 \nRevised: 11-11-2022 \nAccepted: 11-11-2022 \n \nCorresponding\
    \ Author:  \nAntreas Kantaros \nDepartment of Industrial \nDesign and Production\
    \ \nEngineering, University of \nWest Attica, Greece \nEmail: akantaros@uniwa.gr\
    \ \nAbstract: The present article contains a study about utilizing the Digital\
    \ \nTwins concept in the field of contemporary agricultural production. Through\
    \ \nthis study, an exemplary architecture has been developed regarding the \n\
    conversion of a conventional greenhouse to a digital greenhouse. A digital \n\
    greenhouse modus operandi features a great number of advantages compared \nwith\
    \ the traditional workflow in a conventional greenhouse. The purpose of \nthe\
    \ work is to propose tools for assisting the possible reduction of the \nconsumption\
    \ of the used resources for the crops. This requires the application \nof automation\
    \ of tools for cultivation such as Controlled Environment \nAgriculture (CEA).\
    \ The article shows that the Digital Twins concept can \nimmensely contribute\
    \ towards controlling the agricultural environment and \nat the same time improve\
    \ performance and quality while reducing the \nconsumption of resources for a\
    \ variety of crops. The proposed workflow \nstarts by identifying the parameters\
    \ that need to be taken into account and \nfinally proposes several cyber and\
    \ physical tools for setting up a Digital Twin \nfor the case of a greenhouse.\
    \ The objective of this study was the development \nof a DT architecture that\
    \ would be able to optimize productivity in the context \nof CEA applications.\
    \ \n \nKeywords: Digital Twin, Cyber-Physical Systems, Simulation, Smart \nAgriculture,\
    \ Greenhouse, 4th Industrial Revolution \n \nIntroduction  \nCurrently, there\
    \ is a need to increase productivity and \nreduce the resources being consumed.\
    \ According to the \ndata and statistics, it is estimated that by 2050 the world\
    \ \npopulation will reach over 9.6 billion people. Today the \npopulation is estimated\
    \ at 7.9 billion according to the \nUN's average estimate. Agricultural production\
    \ must \nincrease food production compared to today to ensure the \nnutrition\
    \ demands of this population are met. However, \nthere are many obstacles to this\
    \ effort. Thus, arises the \nneed for applying new, state-of-the-art innovative\
    \ \ntechnologies in agricultural production systems. In this \ncontext, Digital\
    \ Twin (DT) technology comes to the \nforefront. DTs in agriculture can offer\
    \ productivity \noptimization by balancing production and resource \nconsumption\
    \ by using their prediction/forecasting ability. \nThis will be achieved through\
    \ the construction of a Digital \nTwin \narchitecture \nfor \nControlled \nEnvironment\
    \ \nAgriculture (CEA) which will optimize the following \ncrucial elements depicted\
    \ in Fig. 1. \nAccording to Asseng and Cowan calculations \n(Asseng et al., 2020;\
    \ Cowan et al., 2022), the wheat \nharvest using CEA is about 700±40 and 1940±230\
    \ \ntons/hectare/year \nwhereas \nit \nwas \nonly \n3.2 \ntons/hectare/year with\
    \ traditional open field harvest. In \naddition, according to Nicole's finding\
    \ (Nicole et al., \n2016), lettuce quality is improved by growing it in plant\
    \ \nfactories, and the improvement is observed both in the \ncolor and nutritive\
    \ value offered when consumed. \n \n \n \nFig. 1: Digital Twin architecture for\
    \ Controlled Environment \nAgriculture (CEA) \nAntreas Kantaros and Dimitrios\
    \ Piromalis / American Journal of Engineering and Applied Sciences 2022, 15 (4):\
    \ 230.238 \nDOI: 10.3844/ajeassp.2022.230.238 \n \n231 \nHowever, the aforementioned\
    \ optimization procedure \nhas certain drawbacks. As the applied automation percentage\
    \ \nincreases, energy consumption increases as well, elevating \noperating costs.\
    \ Graamans et al. (2018), found that by \ncomparing the production of 1 kg of\
    \ lettuce in a greenhouse \nor plant, 70, 111, 182, and 211 kWh are required in\
    \ \ngreenhouses and 247 kWh in plants in the Netherlands, while \nin the United\
    \ Arab Emirates and Swe-den energy \nconsumption is twice as high as in the Netherlands\
    \ (in terms \nof building total energy). These data came from the study of \n\
    2 greenhouses in Sweden, one with additional artificial \nlighting and the other\
    \ without. Based on the above data, it is \nobvious that the production benefits\
    \ come into conflict with \nthe energy consumption that creates a need for optimized\
    \ \nchoices in applying CEA systems. This is where Digital \nTwin technology can\
    \ offer a potential solution. According to \nKritzinger et al. (2018); Negri et\
    \ al. (2017), DT \"utilizes \nsensible data, mathematical models and real-time\
    \ data \nprocessing to predict and optimize physical asset behavior in \neach\
    \ phase of the life cycle, in real-time.\" \nDigital Twins \nDigital twins are\
    \ virtual representations of real-time \ndata on an object or system using simulations,\
    \ engineer \nlearning, and logical reasoning to aid in decision-making \n(Piromalis\
    \ and Kantaros, 2022; Kantaros et al., 2021; \nTsaramirsis et al., 2022; Singh\
    \ et al., 2021). The operation \nof the Digital Twin is achieved through the precise\
    \ \nrepresentation of a physical object through the designed \nvirtual model.\
    \ The physical twin, for example, will \ncontain some media (e.g., sensors) for\
    \ data collection. \nThen the data are transferred to a corresponding \nprocessing\
    \ system to be applied to the digital twin. This is \nused for the subsequent\
    \ data in processing so that it is \npossible to study problems and performance\
    \ issues to \nimprove the physical object or system. Mainly the data are \ncollected\
    \ to re-apply the corresponding actions to be done \non the original physical\
    \ object. The application of Digital \nTwins in production enables the user to\
    \ decrease the \ndowntime of the equipment and at the same time increase \nproductivity\
    \ (Tao et al., 2019; Parrott and Warshaw, \n2017; Erol et al., 2020; Barricelli\
    \ et al., 2019; Liu et al., \n2021; He and Bai, 2021). \nAt the highest level,\
    \ a digital twin is an architectural \ncompilation powered by a combination of\
    \ cutting-edge \ntechnologies such as IoT (Internet of Things), Cloud \nComputing,\
    \ Edge Computing, Fog Computing, Artificial \nIntelligence, Robotics, Machine\
    \ Learning, and Big Data \nAnalytics. A Digital Twin is designed by collecting\
    \ data and \ncreating computational models for testing. This may include \nan\
    \ interface between the digital model and a real physical \nobject for sending\
    \ and receiving real-time feedback and data. \nBy combining all the necessary\
    \ digital technologies in a \ncoherent platform, a virtual representation of agricultural\
    \ \nproduction will be created consisting of natural elements, \nprocesses, systems,\
    \ resources, etc., (Lu et al., 2020; \nGrieves, 2016; Batty, 2018; Markets and\
    \ Markets, 2020; \nTao et al., 2019). \nSimulation Applications for Agriculture\
    \ \nIn agricultural production, the fundamental resources \nthat determine crop\
    \ production are water, nitrogen, \nenergy, and crop disease-tackling measures.\
    \ In addition, \ndata such as weather, soil characteristics, field hydrology,\
    \ \ncrop characteristics, sowing, and other factors should also \nbe taken into\
    \ account. For the compilation of a Digital Twin \nin agriculture and specifically\
    \ for a greenhouse, simulation \napplications are needed for the digital display\
    \ of the \ngreenhouse. Simulation applications use tailored models for \nbetter\
    \ management of specific physical object parameters to \nmake the best possible\
    \ production decisions. \nIn this context, applications from the literature were\
    \ \nsought that will offer improvement in the way crops are \nmanaged and in monitoring\
    \ the condition of crops, and for \nthe reduction of crop treatments. A crucial\
    \ factor that \nconcerns all growers is the consumption of resources. The \nconsumption\
    \ of resources used for plant production is high \nwater consumption, heating,\
    \ and ventilation. The goal of \ngrowers is to reduce this consumption as much\
    \ as possible. \nTable 1 depicts some suggested applications/systems \nfor the\
    \ Digital Twin Greenhouse that can help manage \nenergy, water, and crop health.\
    \  \nEnergy Plus \nEnergy Plus is a simulation application for engineers, \narchitects,\
    \ and researchers designed to model energy i.e., \nenergy such as heating, cooling,\
    \ ventilation, lighting, and \npower receivers during loading, and also model\
    \ the use of \nwater. Energy Plus applies detailed building physics to the \n\
    transfer of air, moisture, and heat, including radiation transfer \nand heat (convection\
    \ and conduction) transfer separately to \nsupport the modeling of radiation systems\
    \ and the calculation \nof thermal comfort measurements. It calculates light,\
    \ shading, \nand visual comfort measurements. Flexible configuration \nis supported\
    \ at the level of HVAC system components, \ninstallation cooling, and heating\
    \ as well as including a \nlarge set of HVAC component models and installations.\
    \ It \nsimulates hourly time steps to quickly manipulate system \ndynamics and\
    \ control strategies and has a programmed \nexternal interface for modeling control\
    \ sequences and \ninterfacing with other analyzes (Energy Plus, 2022). \n \nTable\
    \ 1: Greenhouse Digital Twins applications/systems \nGreenhouse digital twins’\
    \ applications/systems \nEnergy Plus \nTRNSYS \nDSSAT (decision support system\
    \ for agrotechnology transfer) \nCropX \n \nClimate Field View \nAPSIM \nCropSyst\
    \ \nAntreas Kantaros and Dimitrios Piromalis / American Journal of Engineering\
    \ and Applied Sciences 2022, 15 (4): 230.238 \nDOI: 10.3844/ajeassp.2022.230.238\
    \ \n \n232 \nTRNSYS \nTRNSYS offers a flexible graphical-based software \nenvironment,\
    \ used to simulate the behavior of transient \nsystems. It offers, like other\
    \ similar systems, evaluation of \nthe efficiency of thermal and electrical systems,\
    \ but also can \nbe used for modeling other dynamic systems, such as the \nflow\
    \ circulation or biological processes. TRNSYS consists \nof two parts. The first\
    \ is a Camera (called a kernel) that reads \nand processes the input file, repeatedly\
    \ solves the system, \ndetermines convergence, and plots the system variables.\
    \ The \nkernel also provides utilities that (among other things) \ndetermine the\
    \ thermophysical properties, invert arrays, \nperform linear regressions and interrupt\
    \ external data files. \nThe second part of TRNSYS is an extensive data library,\
    \ \nwhich models the performance of one part of the system. \nThe application\
    \ library offers approximately 150 models \nranging from pumps to multi-zone buildings,\
    \ wind \nturbines to electrolytes, weather data processors to \neconomical routines,\
    \ and basic HVAC equipment to \nemerging cutting-edge technologies (TRNSYS, 2022).\
    \ \nDSSAT (Decision Support System for \nAgrotechnology Transfer) \nThe Rural\
    \ Technology Transfer Decision Support \nSystem (DSSAT) is an application that\
    \ offers crop \nsimulation models and tools for their more efficient use. The\
    \ \ntools offer database management for soil, weather, crop \nmanagement, experimental\
    \ data, utilities, and application \nprograms. Application models simulate growth\
    \ and yield as \na function of soil-plant-atmosphere dynamics. Includes farm \n\
    management and accuracy, regional assessments of the \nimpact of climate variability\
    \ and climate change, genetic \nmodeling and reproduction selection, water use,\
    \ greenhouse \ngas emissions, and long-term viability through soil organic \n\
    carbon and nitrogen balances. Crop models require daily \nweather data, soil surface,\
    \ and profile information, and \ndetailed crop management as data. At the end\
    \ of each day, \nthe water, nitrogen, phosphorus, and carbon balances of the \n\
    plants and the soil are updated, as well as the stage of \ngermination and reproductive\
    \ development of the crop. For \napplications, DSSAT combines crop, soil, and\
    \ weather \ndatabases with crop models and implementation programs \nto simulate\
    \ multiannual results of crop management \nstrategies (DSSAT, 2022). \nCropX \n\
    CropX application is a system that offers automation and \ncrop management with\
    \ advanced analysis technologies for \nagriculture. The system offers management\
    \ of irrigation, and \nfertilization with accurate forecasts, offering the best\
    \ possible \nresult. It processes data from the soil for an even better \npicture\
    \ of the crop and the atmosphere that surrounds the \ncrop. Thus, the system will\
    \ be able to adapt the strategies of \noptimal cultivation. It then offers an\
    \ adapted variable rate \nirrigation system based on changing soil and weather\
    \ \nconditions. It constantly adapts the specific needs of the crop \nto its development\
    \ stage (CropX, 2022). \nClimate Field View \nThe Climate Field View application\
    \ helps in making \ndecisions from crop data to maximize the yield of each \n\
    cultivated acre. The system collects, stores, and visualizes \ncritical data.\
    \ In this way, it will be possible to monitor and \nmeasure the decisions made\
    \ regarding the cultivation to \nimprove the yield and maximize the profit (Climate\
    \ Field \nView, 2022). \nAPSIM \nThe \nAgricultural \nProduction \nSystems \n\
    Simulator \n(APSIM) is internationally recognized as an extremely \nadvanced platform\
    \ for modeling and simulation of systems \ncontaining a platform that enables\
    \ the simulation of systems \nwith a variety of plant, animal, soil, climate,\
    \ and management \ninteractions. APSIM is constantly evolving, with new features\
    \ \nbeing added to APSIM Next Generation. Its development and \nmaintenance are\
    \ based on strict standards of software science \nand engineering (APSIM, 2022).\
    \ \nCropSyst \nCropSyst is a multi-year multi-crop crop simulation \nmodel developed\
    \ by a team at the Department of Biological \nSystems Engineering at Washington\
    \ State University. The \nmodel is used to study the impact of pruning system\
    \ \nmanagement on productivity (Stöckle et al., 2003). \nDigital Twin Architecture\
    \ Design and Compilation \nfor a Greenhouse \nDigital Twin's architecture development\
    \ work to \noptimize productivity is conducted through the development \nof a\
    \ controlled greenhouse environment. A greenhouse is an \nenclosed space, covered\
    \ with a permeable (transparent or \nopaque) material, which allows sunlight to\
    \ enter to heat the \ngreenhouse during the day. In general, a greenhouse is \n\
    necessary for the modification of climatic conditions internally \nin contrast\
    \ to the external environment, to plant plants, and \nproduction of plant products\
    \ regardless of the external \nclimatic conditions. In case of an unwanted temperature\
    \ rise, \nventilation is necessary, while for cold nights or days, a \nheating\
    \ system is necessary to maintain the desired \ntemperature for plant growth (Howard\
    \ et al., 2021;         \nVerdouw et al., 2021; Pylianidis et al., 2021; Tekinerdogan\
    \ \nand Verdouw, 2020; Monteiro et al., 2018; Howard et al., \n2020a; Mukhtar\
    \ et al., 2022; Borowski, 2021; Howard et al., \n2020b; Yang et al., 2022). The\
    \ necessary prerequisites for the \ncreation of a greenhouse are depicted in Fig.\
    \ 2. \nThe additional equipment required consists of the \nautomation infrastructure\
    \ elements of the greenhouse which \nAntreas Kantaros and Dimitrios Piromalis\
    \ / American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238\
    \ \nDOI: 10.3844/ajeassp.2022.230.238 \n \n233 \ninclude systems of heating, ventilation,\
    \ humidity, automatic \ncontrol of the climatic conditions, and irrigation. \n\
    Construction of DT \nFor the proper compilation of the architecture for \ncreating\
    \ a greenhouse DT, the following elements \ndepicted in Fig. 3 must be included.\
    \ \nIn this context, Chaux's methodology based on virtual \nsimulation technology\
    \ is used for indicative development \nof the DT greenhouse architecture (Chaux\
    \ et al., 2021; \nTraoré, 2021). It proposes a strategy to modernize production\
    \ \nwith DT systems including the following elements depicted \nin Table 2. According\
    \ to Chaux’s methodology, ’The data \nnecessary for the optimization must be available\
    \ in the \ncloud and the user must download them in his/her local \ndevice. The\
    \ optimization occurs in the local device and \nthe optimal crop treatment and\
    \ climate control strategy \nare communicated to the controller for its implementation\
    \ \nthrough a gateway (Chaux et al., 2021). \nFramework. \nThis stage includes\
    \ the design of subsequent stages \nin which the developing architecture will\
    \ operate with \nspecific functions' definitions. This categorization \nincludes\
    \ the following parts with corresponding \nfunctions, i.e.: \n \n1. Greenhouse\
    \ \n \nA natural element that needs the help of DT to \noptimize production and\
    \ where after the training the \nselected strategies will be verified. \n \n2.\
    \ Controller \n \nIt is a set of measuring instrument layers, actuators, \nsensors,\
    \ monitors, and controllers for the greenhouse. \nWhich are important for the\
    \ collection of data to be used \nin DT. Then the controller exchanges data with\
    \ the \nnetwork portal to make the corresponding appropriate \ndecisions for the\
    \ crop. \n \n3. Portal \n \nIt is the software that will be used for the connection\
    \ \nbetween different network environments, i.e., at work, it \nis the connection\
    \ between the physical and digital \ncomponents. Its function is to transfer data\
    \ to storage for \nlater use. \n \n4. Storage \n \nThe data used by the simulation\
    \ (current and \nhistorical) requires space to be stored as well as for \ndecisions\
    \ made. So that the data can be processed at any \ntime and there is a record\
    \ of successful decisions to be used \nin the physical element. It is a very important\
    \ part of DT tests. \n \n5. Intelligence Layer \n \nThe Intelligence Layer organizes\
    \ and provides smart \nservices. It is the main element used to direct the service.\
    \ \nIt is responsible for the evaluation and then the selection \nof the best\
    \ strategy. \n \n6. Digital Twin (1) \n \nOne of the recommended or equivalent\
    \ simulation \napplications to control power consumption resources. \n \n7. Digital\
    \ Twin (2) \n \nOne of the recommended or equivalent simulation \napps for controlling\
    \ atmospheric conditions and selecting \ncase-specific treatments. \n \n \n \n\
    Fig. 2: Necessary prerequisites for the creation of a greenhouse \n \n \n \nFig.\
    \ 3: Elements comprising the architecture set-up of a Digital \nTwin for a greenhouse\n\
    Antreas Kantaros and Dimitrios Piromalis / American Journal of Engineering and\
    \ Applied Sciences 2022, 15 (4): 230.238 \nDOI: 10.3844/ajeassp.2022.230.238 \n\
    \ \n234 \nTable 2: Development stages of a DT greenhouse architecture \n \n \n\
    \ \n \nPhysical-Cyber \nFramework:  \nTechnologies: \nDigital Twin: \nIntelligence\
    \ Layer: \nInterface: \nImplementation: \nIt is the framework on \nThe point where\
    \ \nThe Use of selected \nThis part is the \nHere is the part of \nUpon completing\
    \ all the \nwhich the entire DT \nthe non-structural \nsimulation \nlevel of intelligence\
    \ \nthe interaction and \nstages, the elaboration \nthe architecture will be elements\
    \ of the \nto develop and \nwhose main function data transmission \nand application\
    \ of the \nbased. An initial \nframework- planned \nuse of software and \nto compare\
    \  \nthe physical \narchitecture is applied, \ntheoretical multilevel \nare implemented,\
    \ \nmodels to optimize \napplied strategies \nand digital element, \nwhich is\
    \ applied to the \nstructure with functions applying the technologies \nto the\
    \ physical \n and choose the  \nit as also a responsible physical element for\
    \ \nthe mode of \nnecessary for operation \nelement \nbest one. It interacts \n\
    for determining the  \nverification \nOperation of the  \nof the DT and the way\
    \  \n \nwith the applied  \nway of interaction \ndesigned DT \nin which they will\
    \ interact \n \ntechnologies of  \n \n \n \nthe system \n \nTechnologies \n \n\
    • \nGreenhouse \n \nFor the collection of data from the physical element, \nsensors\
    \ are needed to receive inside and outside \ntemperature, humidity, and automatic\
    \ mechanisms that \nbased on the desired temperature and humidity will \nself-excite\
    \ (regulate). \n \n• \nController \n \nThe Arduino Uno Microcontroller can be\
    \ used as a \ncontroller. \n \n• \nPortal \n \nThe portal is used for communication\
    \ between the \ncontroller and storage. Communication can be either \nwireless\
    \ or serial. \n \n• \nStorage \n \nStorage of all data requires cloud storage\
    \ which can \nhost the data for example a database. i.e., the MySQL \nDatabase,\
    \ specifically the phpMyAdmin. \n \n• \nIntelligence Layer \n \nAn operating system\
    \ to store, and connect with \ninformation such as data and financial aspects\
    \ `to achieve \ncommunication between the level of intelligence and the DT. \n\
    \ \n• \nDigital Twin (1) \n \nOne of the recommended or equivalent simulation\
    \ \napplications to control power consumption resources. \n \n• \nDigital Twin\
    \ (2) \n \nOne of the recommended or equivalent simulation \napps for controlling\
    \ atmospheric conditions and selecting \ncase-specific treatments. \nIntelligence\
    \ Layer \nThe control and automation of agricultural production \nand in particular\
    \ of a green-house consisting of distinct \nworkflows. By properly defining the\
    \ workflow sequence, \nthe categorization of actions and their position in the\
    \ value \nchain from farm to consumer can be achieved, which will \nbe the optimization\
    \ of productivity. \nWorkflow Optimization \n \n1. Climate conditions data flow:\
    \ At the intelligence \nlevel, all data comes from the database, i.e., database\
    \ \ncloud, which must be sent for processing to be used \nto create improvement\
    \ strategies, as follows: \n \n• \nData on the atmospheric conditions of the \n\
    Climate inside the greenhouse which are \ntemperature, relative humidity, solar\
    \ gain/loss, \nand outdoor air speed \n• \nData on the atmospheric conditions\
    \ of the \nClimate outside the greenhouse which are \ntemperature and relative\
    \ humidity \n• \nAll data on the previous cultivation conditions \n(atmospheric\
    \ conditions and treatments) \n \n2. Climate conditions: The level of intelligence\
    \ through \nthe evaluation of the sent data and predicted data \ntransfers to\
    \ the software \n3. Data therapy cultivation data: The level of \nintelligence\
    \ \nreceives \nthe \npredicted \nenergy \nconsumption data and atmospheric data\
    \ to produce \nappropriate suitable conditions for the necessary \napplication\
    \ of therapies \n4. Crop treatments: Where the level of intelligence \nthrough\
    \ the evaluation of the sent data and predicted \ndata transfers them to the software\
    \ for the selection \nof appropriate treatments \n5. \nCompletion of the data\
    \ flow: After all possible \ncultivation conditions have been obtained and tested,\
    \ the \nbest cultivation conditions are selected and applied with \nas little\
    \ resource consumption as possible. It is the final \nstage where the final optimization\
    \ is achieved \n \nFigure 4 depicts a flowchart of the aforementioned \nsteps\
    \ regarding workflow optimization. \nAntreas Kantaros and Dimitrios Piromalis\
    \ / American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238\
    \ \nDOI: 10.3844/ajeassp.2022.230.238 \n \n235 \n \n \nFig. 4: Workflow optimization\
    \ sequence \n \nPhysical-Cyber Interface \nThe interaction of the cyber-physical\
    \ and physical \nsystem is an intelligent system, is a computer system \nthrough\
    \ which the mechanism developed by computer-\nbased algorithms is applied. Physical\
    \ data is collected and \ncomputer components are integrated to operate a process\
    \ \nsafely and efficiently. CPS grasps the majority of \nbeneficial elements that\
    \ the Internet of Things (IoT) can \noffer, in its basic architecture. Thus, CPS\
    \ can achieve a \nhigh combination and coordination between physical and \ncomputational\
    \ components. \nAfter defining the workflow, its operation consists of \nthe following:\
    \ \n \n• \nThe controller-level data received is transmitted \nthrough the network\
    \ gateway continuously to the \nstorage level \n• \nIn case of success of the\
    \ strategic optimization, the \ncorresponding data is sent to the local device,\
    \ i.e., to \nthe controller, so that the stream of optimization tasks \ncan be\
    \ applied at the level of intelligence \n \nImplementation \nIn this stage, all\
    \ the aforementioned steps are \nimplemented, including the actual coding compilation\
    \ and its \napplication i.e., in the Arduino microcontroller and a \nplatform\
    \ such as Node-RED (Node-RED, 2022). Node-RED \nis a programming tool for combining\
    \ hardware devices, APIs \n(Application Programming Interface), and online services\
    \ \nfor such purposes. In this context, it provides a browser-\nbased editor that\
    \ enables the simultaneous wiring of program \nflows using a wide range of nodes\
    \ in the offered palette that \ncan be deployed in a single click. \nConclusion\
    \ \nAgricultural production systems should innovate \ntowards increasing production\
    \ while utilizing fewer \nresources to assure food security. Digital twins and\
    \ \ncontrolled environment agriculture may prove to be \nessential mechanisms\
    \ for maximizing output and ensuring \nthe world's food security.  \nThe present\
    \ work presents a step-by-step approach to the \ndevelopment of architecture regarding\
    \ a Digital Twin-\nassisted controlled greenhouse. The goal was achieved by \n\
    creating an architecture that makes use of simulation \nsoftware (such as DTs)\
    \ and allows for the optimization of \nclimate control techniques connected to\
    \ crop microclimate \ncontrol. The proposed tools and actions show that it is\
    \ \npossible to implement such a practice in an already existing \ngreenhouse.\
    \ Achieving a controlled environment in \nagriculture with the help of Digital\
    \ Twins can be considered \nan essential tool to achieve productivity optimization\
    \ to \nreduce the consumption of resources as well as to immensely \ncontribute\
    \ towards the seamless food supply of the planet \n(Symeonaki et al., 2021a; 2021b;\
    \ 2019a,b; Aversa et al., \n2016a,b; Petrescu and Petrescu, 2019; Petrescu et\
    \ al., 2017). \nSuch practices propose a new innovative approach for \nvertical\
    \ integration and optimization of greenhouse \nprocesses to achieve elevated energy\
    \ efficiency and \nproduction outputs without compromising the quality of \nthe\
    \ offered products or sustainability. In this context, the \ndeveloped Digital\
    \ Twins will be able to forecast how the \nphysical twin will perform under constantly\
    \ changing \noperational conditions.  \nFuture work can be identified as the proposed\
    \ \narchitecture's constant evolution due to the introduction of \nnew software\
    \ and hardware tools that will allow swifter \ndevelopment and integration of\
    \ such practices. In this \ncontext, to confirm the capacity of the suggested\
    \ DT \narchitecture to maximize productivity, a case study must be \nimplemented\
    \ to validate the productivity increase. \nAntreas Kantaros and Dimitrios Piromalis\
    \ / American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238\
    \ \nDOI: 10.3844/ajeassp.2022.230.238 \n \n236 \nFunding Information \nThis study\
    \ did not receive any funding.  \nAuthor’s Contributions \nAntreas Kantaros: Writing,\
    \ edited. \nDimitrios Piromalis: Conceptualization, edited. \nEthics \nThere is\
    \ no ethical concern, to the knowledge of the \nauthors, that arises from the\
    \ present work. \nReferences \nAPSIM. (2022). https://www.apsim.info/ \nAsseng,\
    \ S., Guarin, J. R., Raman, M., Monje, O., Kiss, G., \nDespommier, D. D., ...\
    \ & Gauthier, P. P. (2020). \nWheat yield potential in controlled-environment\
    \ \nvertical farms. Proceedings of the National Academy \nof Sciences, 117(32),\
    \ 19131-19135. \n \nhttps://doi.org/10.1073/pnas.2002655117 \nAversa, R., Petrescu,\
    \ R. V., Petrescu, F. I., & Apicella, A. \n(2016a). Smart-factory: Optimization\
    \ and process \ncontrol of composite centrifuged pipes. American \nJournal of\
    \ Applied Sciences, 13(11), 1330-1341. \nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id\n\
    =3075399 \nAversa, R., Petrescu, R. V., Petrescu, F. I., & Apicella, A. \n(2016b).\
    \ Biomimetic and evolutionary design-driven \ninnovation in sustainable products\
    \ development. \nAmerican Journal of Engineering and Applied \nSciences, 9(4).\
    \ \nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id\n=3074457 \nBarricelli,\
    \ B. R., Casiraghi, E., & Fogli, D. (2019). A \nsurvey on digital twin: Definitions,\
    \ characteristics, \napplications, \nand \ndesign \nimplications. \nIEEE \nAccess,\
    \ 7, 167653-167671. \n \nhttps://doi.org/10.1109/ACCESS.2019.2953499 \nBatty,\
    \ M. (2018). Digital twins. Environment and Planning \nB: Urban Analytics and\
    \ City Science, 45(5), 817-820. \nhttps://doi.org/10.1177/2399808318796416 \n\
    Borowski, P. F. (2021). Digitization, digital twins, \nblockchain, and industry\
    \ 4.0 as elements of \nmanagement process in enterprises in the energy sector.\
    \ \nEnergies, 14(7), 1885. \n \nhttps://doi.org/10.3390/en14071885 \nChaux, J.\
    \ D., Sanchez-Londono, D., & Barbieri, G. \n(2021). A digital twin architecture\
    \ to optimize \nproductivity \nwithin \ncontrolled \nenvironment \nagriculture.\
    \ Applied Sciences, 11(19), 8875. \n \nhttps://doi.org/10.3390/app11198875 \n\
    Climate Field View. (2022). https://climate.com/ \nCowan, N., Ferrier, L., Spears,\
    \ B., Drewer, J., Reay, D., & \nSkiba, U. (2022). CEA systems: The means to achieve\
    \ \nfuture \nfood \nsecurity \nand \nenvironmental \nsustainability? Frontiers\
    \ in Sustainable Food Systems, \n6, 891256. https://doi.org/10.3389/fsufs.2022.891256\
    \ \nCropX. (2022). https://cropx.com/ \nDSSAT. (2022) https://dssat.net/ \nEnergy\
    \ Plus. (2022). https://energyplus.net/ \nErol, T., Mendi, A. F., & Doğan, D.\
    \ (2020, October). Digital \ntransformation revolution with digital twin technology.\
    \ \nIn 2020 \n4th \ninternational \nsymposium \non \nmultidisciplinary studies\
    \ and innovative technologies \n(ISMSIT) (pp. 1-7). IEEE. \n \nhttps://ieeexplore.ieee.org/abstract/document/9254288\
    \ \nGraamans, L., Baeza, E., Van Den Dobbelsteen, A., \nTsafaras, I., & Stanghellini,\
    \ C. (2018). Plant factories \nversus greenhouses: Comparison of resource use\
    \ \nefficiency. Agricultural \nSystems, 160, \n31-43. \nhttps://doi.org/10.1016/j.agsy.2017.11.003\
    \ \nGrieves, M. (2016). Origins of the Digital Twin \nConcept. 2016. \n \nhttps://www.researchgate.net/publication/30750972\n\
    7_Origins_of_the_Digital_Twin_Concept \nHe, B., & Bai, K. J. (2021). Digital twin-based\
    \ sustainable \nintelligent manufacturing: A review. Advances in \nManufacturing,\
    \ 9(1), 1-21. \n \nhttps://doi.org/10.1007/s40436-020-00302-5 \nHoward, D. A.,\
    \ Ma, Z., & Jørgensen, B. N. (2020a, June). \nDigital Twin Framework for Energy\
    \ Efficient \nGreenhouse \nIndustry \n4.0. \nIn International \nSymposium on Ambient\
    \ Intelligence (pp. 293-297). \nSpringer, Cham. https://doi.org/10.1007/978-3-030-\n\
    58356-9_34 \nHoward, D. A., Ma, Z., Aaslyng, J. M., & Jørgensen, B. \nN. (2020b,\
    \ October). Data architecture for digital twin \nof commercial greenhouse production.\
    \ In 2020 RIVF \nInternational \nConference \non \nComputing \nand \nCommunication\
    \ Technologies (RIVF) (pp. 1-7). IEEE. \nhttps://doi.org/10.1109/RIVF48685.2020.9140726\
    \ \nHoward, D. A., Ma, Z., Veje, C., Clausen, A., Aaslyng, J. \nM., & Jørgensen,\
    \ B. N. (2021). Greenhouse industry \n4.0–digital \ntwin \ntechnology \nfor \n\
    commercial \ngreenhouses. Energy Informatics, 4(2), 1-13. \n \nhttps://doi.org/10.1186/s42162-021-00161-9\
    \ \nKantaros, A., Piromalis, D., Tsaramirsis, G., Papageorgas, \nP., & Tamimi,\
    \ H. (2021). 3D printing and \nimplementation of digital twins: Current trends\
    \ and \nlimitations. Applied System Innovation, 5(1), 7. \nhttps://doi.org/10.3390/asi5010007\
    \  \nKritzinger, W., Karner, M., Traar, G., Henjes, J., & Sihn, \nW. (2018). Digital\
    \ Twin in manufacturing: A \ncategorical literature review and classification.\
    \ \nIFAC-PapersOnLine, 51(11), 1016-1022. \n \nhttps://doi.org/10.1016/j.ifacol.2018.08.474\
    \ \nAntreas Kantaros and Dimitrios Piromalis / American Journal of Engineering\
    \ and Applied Sciences 2022, 15 (4): 230.238 \nDOI: 10.3844/ajeassp.2022.230.238\
    \ \n \n237 \nLiu, M., Fang, S., Dong, H., & Xu, C. (2021). Review \nof digital\
    \ twin about concepts, technologies, and \nindustrial applications. Journal of\
    \ Manufacturing \nSystems, 58, 346-361. \n \nhttps://doi.org/10.1016/j.jmsy.2020.06.017\
    \ \nLu, Y., Liu, C., Kevin, I., Wang, K., Huang, H., & Xu, X. \n(2020). Digital\
    \ Twin-driven smart manufacturing: \nConnotation, reference model, applications\
    \ and \nresearch issues. Robotics and Computer-Integrated \nManufacturing, 61,\
    \ 101837. \n \nhttps://doi.org/10.1016/j.rcim.2019.101837 \nMarkets & Markets.\
    \ (2020). Digital Twin Market by \nTechnology, Type (Product, Process, and System),\
    \ \nApplication (Predictive Maintenance and Others), \nIndustry (Aerospace & Defense,\
    \ Automotive & \nTransportation, \nHealthcare, \nand \nothers), \nand \nGeography—Global\
    \ Forecast to 2026; Markets and \nMarkets: Pune, India, 2020; p. 177. \nMonteiro,\
    \ J., Barata, J., Veloso, M., Veloso, L., & Nunes, \nJ. (2018, September). Towards\
    \ sustainable digital \ntwins for vertical farming. In 2018 Thirteenth \nInternational\
    \ Conference on Digital Information \nManagement \n(ICDIM) (pp. \n234-239). \n\
    IEEE. \nhttps://doi.org/10.1109/ICDIM.2018.8847169 \nMukhtar, H., Wunderlich,\
    \ R. F., & Lin, Y. P. (2022). \nDigital Twins of the Soil Microbiome for Climate\
    \ \nMitigation. Environments, 9(3), 34. \n \nhttps://doi.org/10.3390/environments9030034\
    \ \nNegri, E., Fumagalli, L., & Macchi, M. (2017). A review of \nthe roles of\
    \ the digital twin in CPS-based production \nsystems. \nProcedia \nManufacturing,\
    \ 11, \n939-948. \nhttps://doi.org/10.1016/j.promfg.2017.07.198 \nNicole, C. C.\
    \ S., Charalambous, F., Martinakos, S., Van \nDe Voort, S., Li, Z., Verhoog, M.,\
    \ & Krijn, M. (2016, \nMay). Lettuce growth and quality optimization in a \nplant\
    \ factory. In VIII International Symposium on \nLight \nin \nHorticulture \n1134\
    \ (pp. \n231-238). \nhttps://doi.org/10.17660/ActaHortic.2016.1134.31 \nNode-RED.\
    \ (2022). https://nodered.org/ \nParrott, A., & Warshaw, L. (2017). Industry 4.0\
    \ and the \ndigital twin. Deloitte Insights. \nPetrescu, N., & Petrescu, F. I.\
    \ (2019). Energy Sources \nToday. Energy Research Journal. \n \nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id\n\
    =3460767 \nPetrescu, R. V., Aversa, R., & Florian, I. (2017). \nPermanent \ngreen\
    \ \nenergy \nproduction \nttp://www.altenergymag.com/article/2017/04/perma\nnent-green-energy-production/25973\
    \ \nPiromalis, D., & Kantaros, A. (2022). Digital Twins in the \nAutomotive Industry:\
    \ The Road toward Physical-\nDigital Convergence. Applied System Innovation, \n\
    5(4), 65. https://doi.org/10.3390/asi5040065 \nPylianidis, C., Osinga, S., & Athanasiadis,\
    \ I. N. (2021). \nIntroducing digital twins to agriculture. Computers \nand \n\
    Electronics \nin \nAgriculture, 184, 105942. \nhttps://doi.org/10.1016/j.compag.2020.105942\
    \ \nSingh, M., Fuenmayor, E., Hinchy, E. P., Qiao, Y., \nMurray, N., & Devine,\
    \ D. (2021). Digital twin: \nOrigin to future. Applied System Innovation, 4(2),\
    \ 36. \nhttps://doi.org/10.3390/asi4020036 \nStöckle, C. O., Donatelli, M., &\
    \ Nelson, R. (2003). CropSyst, \na cropping systems simulation model European\
    \ J. \nhttps://doi.org/10.1016/S1161-0301(02)00109-0 \nSymeonaki, E. G., Arvanitis,\
    \ K. G., & Piromalis, D. D. \n(2019a). Current trends and challenges in the \n\
    deployment of IoT technologies for climate-smart \nfacility agriculture. International\
    \ Journal of Sustainable \nAgricultural Management and Informatics, 5(2-3), \n\
    181-200. https://doi.org/10.1504/IJSAMI.2019.101673 \nSymeonaki, E., Arvanitis,\
    \ K. G., Loukatos, D., & \nPiromalis, D. (2021a). Enabling IoT wireless \ntechnologies\
    \ in sustainable livestock farming toward \nagriculture 4.0. In IoT-based Intelligent\
    \ Modelling \nfor Environmental and Ecological Engineering (pp. \n213-232). Springer,\
    \ Cham. \n \nhttps://doi.org/10.1007/978-3-030-71172-6_9 \nSymeonaki, E., Arvanitis,\
    \ K., Papageorgas, P., & \nPiromalis, D. (2021b). AI-Based Chatbot System \nIntegration\
    \ to a Social Media Platform for \nControlling IoT Devices in Smart Agriculture\
    \ \nFacilities. \nIn Information \nand \nCommunication \nTechnologies \nfor \n\
    Agriculture—Theme \nIV: \nActions (pp. \n193-209). \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-84156-0_10\
    \ \nSymeonaki, E., Arvanitis, K., Piromalis, D., & \nPapoutsidakis, \nM. \n(2019b,\
    \ \nSeptember). \nConversational \nUser \nInterface \nIntegration \nin \nControlling\
    \ \nIoT \nDevices \nApplied \nto \nSmart \nAgriculture: Analysis of a Chatbot\
    \ System Design. \nIn Proceedings \nof \nSAI \nIntelligent \nSystems \nConference\
    \ (pp. \n1071-1088). \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-29516-5_80\
    \ \nTao, F., Zhang, M., & Nee, A. Y. C. (2019). Digital twin-\ndriven smart manufacturing.\
    \ Academic Press.  \nTekinerdogan, B., & Verdouw, C. (2020). Systems \narchitecture\
    \ design pattern catalog for developing \ndigital twins. Sensors, 20(18), 5103.\
    \ \n \nhttps://doi.org/10.3390/s20185103 \nTraoré, M. K. (2021). Unifying Digital\
    \ Twin framework: \nSimulation-based \nproof-of-concept. IFAC-Papers \nOnline,\
    \ 54(1), 886-893. \n \nhttps://doi.org/10.1016/j.ifacol.2021.08.105 \nTRNSYS.\
    \ (2022). https://www.trnsys.com/ \nAntreas Kantaros and Dimitrios Piromalis /\
    \ American Journal of Engineering and Applied Sciences 2022, 15 (4): 230.238 \n\
    DOI: 10.3844/ajeassp.2022.230.238 \n \n238 \nTsaramirsis, G., Kantaros, A., Al-Darraji,\
    \ I., Piromalis, \nD., Apostolopoulos, C., Pavlopoulou, A., ... & Khan, \nF. Q.\
    \ (2022). A modern approach towards an industry \n4.0 \nmodel: \nFrom \ndriving\
    \ \ntechnologies \nto \nmanagement. Journal of Sensors, 2022. \n \nhttps://doi.org/10.1155/2022/5023011\
    \ \nVerdouw, C., Tekinerdogan, B., Beulens, A., & Wolfert, \nS. (2021). Digital\
    \ twins in smart farming. \nAgricultural Systems, 189, 103046. \n \nhttps://doi.org/10.1016/j.agsy.2020.103046\
    \ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\
    \ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nYang, B., Lv, Z.,\
    \ & Wang, F. (2022). Digital Twins for \nIntelligent Green Buildings. Buildings,\
    \ 12(6), 856. \nhttps://doi.org/10.3390/buildings12060856 \n"
  inline_citation: '>'
  journal: American Journal of Engineering and Applied Sciences
  limitations: '>'
  pdf_link: https://thescipub.com/pdf/ajeassp.2022.230.238.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: Setting up a Digital Twin Assisted Greenhouse Architecture
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3390/electronics12102336
  analysis: '>'
  authors:
  - Jun Liu
  - Lei Shu
  - Xu Lu
  - Lei Shu
  citation_count: 4
  full_citation: '>'
  full_text: ">\nCitation: Liu, J.; Shu, L.; Lu, X.; Liu, Y.\nSurvey of Intelligent\
    \ Agricultural IoT\nBased on 5G. Electronics 2023, 12,\n2336. https://doi.org/10.3390/\n\
    electronics12102336\nAcademic Editor: Djuradj Budimir\nReceived: 1 March 2023\n\
    Revised: 29 April 2023\nAccepted: 6 May 2023\nPublished: 22 May 2023\nCopyright:\n\
    © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an\
    \ open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the\
    \ Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n\
    4.0/).\nelectronics\nReview\nSurvey of Intelligent Agricultural IoT Based on 5G\n\
    Jun Liu 1\n, Lei Shu 2,3,*\n, Xu Lu 4,*\nand Ye Liu 2\n1\nSchool of Automation,\
    \ Guangdong Polytechnic Normal University, Guangzhou 510665, China\n2\nCollege\
    \ of Artiﬁcal Intelligence, Nanjing Agricultural University, Nanjing 210095, China\n\
    3\nSchool of Engineering, University of Lincoln, Lincoln LN6 7TS, UK\n4\nSchool\
    \ of Computer Science, Guangdong Polytechnic Normal University, Guangzhou 510665,\
    \ China\n*\nCorrespondence: lei.shu@njau.edu.cn (L.S.); bruda@126.com (X.L.)\n\
    Abstract: In the future, agriculture will face the need for increasing production,\
    \ sustainability, wisdom,\nand efﬁciency, which will bring signiﬁcant challenges\
    \ to the development of modern agriculture. With\nthe gradual popularization of\
    \ 5G, advanced information technologies such as the Internet of Things\nand artiﬁcial\
    \ intelligence promoted the evolution of modern agriculture to intelligent agriculture.\n\
    The 5G-based Internet of Things will play an essential role in the development\
    \ of smart agriculture.\nThis paper investigates the research progress of 5G Internet\
    \ of Things in smart agriculture. It sorts\nout the development status of 5G smart\
    \ agriculture Internet of Things in recent years. Following that,\nthe concept\
    \ of 5G smart agriculture Internet of Things is put forward. It expounds on the\
    \ connotation,\narchitecture, and enabling key technologies. According to the\
    \ key application scenarios of smart\nagriculture, practical cases are presented,\
    \ the development trend and application value of 5G smart\nagriculture Internet\
    \ of Things are shown, and the future development direction is put forward. Firstly,\n\
    the concept of smart agriculture is distinguished, and the category scenarios\
    \ of smart agriculture\nare summarized. Following that, the current review research\
    \ on 5G-IoT is analyzed. This paper\nfocuses on the analysis and summary of the\
    \ changes brought by 5G to various key scenarios in smart\nagriculture. This paper\
    \ analyzes the related key technologies and challenges, puts forward some\nkey\
    \ scientiﬁc problems, and summarizes the research ideas. Finally, the development\
    \ trend and\napplication value of 5G smart agriculture Internet of Things are\
    \ shown. The future development\ndirection is also proposed.\nKeywords: 5G; smart\
    \ agriculture; IoT; monitoring; deep learning; cloud-edge\n1. Introduction\nThe\
    \ future of agriculture is facing serious challenges as people demand higher quality\n\
    food. As shown in Figure 1, by 2050, the gap is expected to be huge, and this\
    \ will pose a\ngreat challenge to resources and the environment. Academician Zhao\
    \ Chunjiang claimed\nthat the intelligent revolution of agriculture in the form\
    \ of smart agriculture has arrived\nin the ﬁrst issue of “Smart Agriculture”.\
    \ Smart agriculture is an advanced stage of the\ndevelopment of agricultural information\
    \ from digitalization to networking and then to\nintelligence, which is a milestone\
    \ for the development of agriculture, and agriculture is\nentering stage 4.0 [1].\n\
    With the commercialization and popularization of smart 5G technology, its charac-\n\
    teristics of high speed, super-large connection, and ultra-low delay will have\
    \ a profound\nimpact on agricultural IoT. Combined with the rapid development\
    \ of artiﬁcial intelligence,\nedge computing, cloud services, and other ﬁelds\
    \ will achieve an epoch-making revolution\nin agricultural production mode. Smart\
    \ Agriculture and 5G-IoT smart agriculture are\nrespectively introduced below.\n\
    Electronics 2023, 12, 2336. https://doi.org/10.3390/electronics12102336\nhttps://www.mdpi.com/journal/electronics\n\
    Electronics 2023, 12, 2336\n2 of 46\nREVIEW \n2 of\nIncreas\ne 49%\nIncreased\
    \ demand \nfor food\n2020\n2050\n2020\n2050\n10B\n7.6B\nMore water\nMore land\
    \ resources\nCarbon emissions from \nagricultural production\nExcessive resource\
    \ \nconsumption\nreduce carbon emissions\nIncrease in \nPopulation\n \nFigure\
    \ 1. Challenges to sustainable agricultural development in the future. \nWith\
    \ the commercialization and popularization of smart 5G technology, its chara\n\
    teristics of high speed, super-large connection, and ultra-low delay will have\
    \ a profou\nimpact on agricultural IoT. Combined with the rapid development of\
    \ artificial inte\ngence, edge computing, cloud services, and other fields will\
    \ achieve an epoch-maki\nrevolution in agricultural production mode. Smart Agriculture\
    \ and 5G-IoT smart agric\nture are respectively introduced below. \n1.1. Smart\
    \ Agriculture \nThere are many kinds of agriculture, including water-saving agriculture,\
    \ facility a\nriculture, ecological agriculture, three-dimensional agriculture,\
    \ organic agriculture, p\ncision agriculture, and so on. Smart agriculture is\
    \ a new agricultural production mo\nwith the core element of information and knowledge.\
    \ By deeply integrating modern \nformation technology such as the Internet, Internet\
    \ of Things, big data, cloud computin\nand artificial intelligence with agriculture,\
    \ it realizes agricultural information perceptio\nquantitative decision-making,\
    \ intelligent control, precise input, and personalized servi\nSmart agriculture\
    \ is an advanced stage of agricultural informatization development fro\ndigitalization\
    \ to networking and intelligence [2,3]. Smart agriculture is a new agricultu\n\
    Figure 1. Challenges to sustainable agricultural development in the future.\n\
    1.1. Smart Agriculture\nThere are many kinds of agriculture, including water-saving\
    \ agriculture, facility agri-\nculture, ecological agriculture, three-dimensional\
    \ agriculture, organic agriculture, precision\nagriculture, and so on. Smart agriculture\
    \ is a new agricultural production mode with the\ncore element of information\
    \ and knowledge. By deeply integrating modern information\ntechnology such as\
    \ the Internet, Internet of Things, big data, cloud computing, and artiﬁcial\n\
    intelligence with agriculture, it realizes agricultural information perception,\
    \ quantitative\ndecision-making, intelligent control, precise input, and personalized\
    \ service. Smart agricul-\nture is an advanced stage of agricultural informatization\
    \ development from digitalization\nto networking and intelligence [2,3]. Smart\
    \ agriculture is a new agricultural production\nmode and ecosystem based on digital\
    \ and precision agriculture, as well as a production\nform in the era of Agriculture\
    \ 4.0. Figure 2 shows the evolution of agriculture from stage 1.0\nto 4.0 [4].\
    \ This revolution that Agriculture 4.0 will completely change how people produce\n\
    food and effectively help people cope with the future population explosion, ecological\n\
    imbalance, food crisis, and other potential challenges [5].\nSmart agriculture\
    \ covers many categories and scenarios. This paper combines previous\nsummaries\
    \ [6,7] and summarizes them according to the large ﬁelds and categories involved\n\
    in agriculture, as shown in the ﬁgure below. In this paper, smart agriculture\
    \ is mainly\noriented to the ﬁeld of planting and breeding, including crop planting,\
    \ animal husbandry,\nand aquatic products. According to the production mode of\
    \ this agriculture, it can be\ndivided into facility agriculture, ﬁeld agriculture,\
    \ precision agriculture, and so on. This\nincludes most areas of agriculture.\
    \ In addition, various types of agricultural production\nElectronics 2023, 12,\
    \ 2336\n3 of 46\ninclude multiple scenarios, such as moisture monitoring, pest\
    \ management, harvesting,\nand so on. The crop or production facing each scenario\
    \ may differ, but many of the key\ntechnologies involved are broadly similar,\
    \ so they are also grouped together. The following\nis a summary of the key technologies\
    \ involved in the scenario, as shown in Figure 3.\nand artificial intelligence\
    \ with agriculture, it realizes agricultural information perception, \nquantitative\
    \ decision-making, intelligent control, precise input, and personalized service.\
    \ \nSmart agriculture is an advanced stage of agricultural informatization development\
    \ from \ndigitalization to networking and intelligence [2,3]. Smart agriculture\
    \ is a new agricultural \nproduction mode and ecosystem based on digital and precision\
    \ agriculture, as well as a \nproduction form in the era of Agriculture 4.0. Figure\
    \ 2 shows the evolution of agriculture \nfrom stage 1.0 to 4.0 [4]. This revolution\
    \ that Agriculture 4.0 will completely change how \npeople produce food and effectively\
    \ help people cope with the future population explo-\nsion, ecological imbalance,\
    \ food crisis, and other potential challenges [5]. \n \nFigure 2. Smart agriculture\
    \ and agriculture 4.0 evolution. \nFigure 2. Smart agriculture and agriculture\
    \ 4.0 evolution.\nPEER REVIEW \n3 of 46 \nSmart agriculture covers many categories\
    \ and scenarios. This paper combines previ-\nous summaries [6,7] and summarizes\
    \ them according to the large fields and categories \ninvolved in agriculture,\
    \ as shown in the figure below. In this paper, smart agriculture is \nmainly oriented\
    \ to the field of planting and breeding, including crop planting, animal \nhusbandry,\
    \ and aquatic products. According to the production mode of this agriculture,\
    \ \nit can be divided into facility agriculture, field agriculture, precision\
    \ agriculture, and so \non. This includes most areas of agriculture. In addition,\
    \ various types of agricultural pro-\nduction include multiple scenarios, such\
    \ as moisture monitoring, pest management, har-\nvesting, and so on. The crop\
    \ or production facing each scenario may differ, but many of \nthe key technologies\
    \ involved are broadly similar, so they are also grouped together. The \nfollowing\
    \ is a summary of the key technologies involved in the scenario, as shown in Fig-\n\
    ure 3. \nSmart Agriculture\nIntelligent \nmonitoring\nWater/Soil \nManagement\n\
    Planting \ngrowth \nmanagement\nPest \nmanagement\nSupply chain \nmanagement\n\
    Typical Scenarios \nof Smart \nAgriculture\nSmart agricultural machinery: \nplanting,\
    \ weeding, picking and \nharvesting\nFishery and aquatic \nproducts\nAnimal \n\
    husbandry\nCrop planting\nGrowth \nmonitoring\nMonitoring of \naquaculture \n\
    environment\nRemote sensing \nmonitoring\nUAV \nmonitoring\nIntelligent \nirrigation\n\
    Moisture \nmonitoring\nWeather \nforecast\nHumidity/\nrainfall \nmonitoring\n\
    Crop phenotype \nmonitoring\nFertilization and \nfeeding \nmanagement\nGeographic\
    \ fence, \nanimal \nmanagement\nNutritional \npesticide \napplication\nInsect\
    \ \nmonitoring\nDisease \nmonitoring/\nprevention\nPhysical sign \nmonitoring/water\
    \ \nquality management\nLivestock \nmonitoring\nIntelligent \nweeding\nIntelligent\
    \ \npicking\nIntelligent \nspraying\nIntelligent \nharvesting\nTransportation\
    \ of \nagricultural \nproducts\nProcessing of \nagricultural \nproducts\nTraceability\
    \ \nmanagement of \nagricultural products\nAgricultural \nproduct storage\nGreenhouse\n\
    Smart animal \nhusbandry\nPlant factory\nIntelligent \nphenotype\nPrecisionAgriculture\n\
    Organic Agriculture\nSightseeing Agriculture\nFacility Agriculture\nField Agriculture\n\
    \  \n \nFigure 3. Smart agriculture field and classification. \nThe Internet of\
    \ Things and other key technologies in smart agriculture, as well as the \nfinal\
    \ target vision, are shown in Figure 4. The ultimate goal of intelligent agriculture\
    \ is to \nrealize intelligent, unmanned, precise, efficient, high-quality, and\
    \ green. The key technol-\nogies needed to achieve the above goals include 5G,\
    \ Internet of Things, big data, artificial \nintelligence, robotics, blockchain,\
    \ drones, and so on. \nSmart \nagriculture\nSmart\nUnmann\ned\nAccurate\nEfficient\n\
    Superior \nquality\nGreen\nTarget\nFigure 3. Smart agriculture ﬁeld and classiﬁcation.\n\
    The Internet of Things and other key technologies in smart agriculture, as well\
    \ as\nthe ﬁnal target vision, are shown in Figure 4. The ultimate goal of intelligent\
    \ agriculture\nis to realize intelligent, unmanned, precise, efﬁcient, high-quality,\
    \ and green. The key\ntechnologies needed to achieve the above goals include 5G,\
    \ Internet of Things, big data,\nartiﬁcial intelligence, robotics, blockchain,\
    \ drones, and so on.\nThe following introduces the research progress of 5G agricultural\
    \ Internet of Things\nin relevant countries around the world, as shown in Table\
    \ 1. It can be seen that the\nrapid progress of 5G commercial deployment in China\
    \ has driven the development of 5G\nagricultural Internet of Things.\nIt is predicted\
    \ that, by 2025, the proportion of 5G connections in the total number of\nconnections\
    \ will increase from 8% in 2021 to 25% in 2025. 5G is expected to account for\n\
    nearly 60% of global mobile service revenue in 2026. With the commercial popularization\n\
    of 5G worldwide, it will lay the foundation for the application of smart agricultural\
    \ IoTs,\nbringing new opportunities.\nElectronics 2023, 12, 2336\n4 of 46\nFigure\
    \ 3. Smart agriculture field and classification. \nThe Internet of Things and\
    \ other key technologies in smart agriculture, as well as the \nfinal target vision,\
    \ are shown in Figure 4. The ultimate goal of intelligent agriculture is to \n\
    realize intelligent, unmanned, precise, efficient, high-quality, and green. The\
    \ key technol-\nogies needed to achieve the above goals include 5G, Internet of\
    \ Things, big data, artificial \nintelligence, robotics, blockchain, drones, and\
    \ so on. \nSmart \nagriculture\nRobot\nInternet \nof Things\nUAV\nAI\nBlockcha\n\
    in\nBig data\n5G\nSmart\nUnmann\ned\nAccurate\nEfficient\nSuperior \nquality\n\
    Green\nTey \nTechnology\nTarget\n \nFigure 4. Key technologies and objectives\
    \ of smart agriculture. \nThe following introduces the research progress of 5G\
    \ agricultural Internet of Things \nin relevant countries around the world, as\
    \ shown in Table 1. It can be seen that the rapid \nFigure 4. Key technologies\
    \ and objectives of smart agriculture.\nTable 1. Global 5G agricultural Internet\
    \ of Things development [8].\nCountry\nAgricultural Type\n5G Agricultural Internet\n\
    of Things\nDevelopment Representa-\ntive/Development\nCharacteristics\n5G Policy\n\
    America\nLarge farms\n5G + UAV + GPS+ satellite\nremote sensing\nFarmLogs, Cropx\n\
    FCC—$9 billion 5G\nsubsidy program\nEurope\nPrecision agriculture\n5G + big data\
    \ + smart\nagricultural machinery\nmonitoring and control, smart\nagricultural\
    \ machinery\nHolland, Switzerland,\nHuawei, Sunrise\n5G commercial\npromotion\n\
    Japan\nGreen agriculture and\necological agriculture\n5G + agricultural Internet\
    \ of\nThings + smart monitoring\nA new farming model with\nautomation and\nintelligence\n\
    5G falls behind, 6G\nworks\nIsrael\nFacility agriculture\nIntelligent depth sense\
    \ +\nintelligent control\nInnovative agriculture\n5G networking\nChina\nMixed\
    \ existence of\nvarious types of\nagriculture\nAgricultural production is\ndeveloping\
    \ towards automation\nand smart agriculture by leaps\nand bounds\n5G, smart agriculture,\n\
    smart agricultural\nmachinery\n5G is being\ncomprehensively\npromoted and\ndemonstrated\
    \ in\nagricultural application\n1.2. 5G-IoT Smart Agriculture\nThe wireless communication\
    \ capability of 5G with low delay, high density, and large\nbandwidth provides\
    \ a communication guarantee for the application of other information\ntechnologies\
    \ in the smart agricultural Internet of Things. Smart agriculture has relied on\
    \ the\nﬁfth generation of information technology 5G, the Internet of Things, robotics,\
    \ drones, big\ndata, AI, machine learning, blockchain, and other key technologies\
    \ to transform modern\nagriculture. It realizes the deep integration of the physical\
    \ world and the information\nworld, changing the current mode of agricultural\
    \ production. Industry-oriented universal\nwide-area Internet of Things is becoming\
    \ the main force [9]. It can promote the expansion\nand upgrading of IoTs in smart\
    \ agriculture and expedite the landing application of big data\nin smart agriculture.\
    \ It is the key to the in-depth application of UAV in agriculture and is\nan important\
    \ booster for integrating artiﬁcial intelligence and robot blockchain in smart\n\
    agriculture [10].\nThe Internet of Things continues to evolve with the evolution\
    \ of information technol-\nogy and sensors. It should not only perceive and transmit\
    \ data but also have functions such\nas recognition, computation, service, semantics,\
    \ and even cognitive decision-making [11].\nThe detection, management, and maintenance\
    \ functions of the Internet of Things will\nalso gradually become intelligent\
    \ and unmanned. The in-depth integration of the Inter-\nnet of Things, big data,\
    \ and artiﬁcial intelligence will revolutionize the current form of\nElectronics\
    \ 2023, 12, 2336\n5 of 46\nthe Internet of Things and generate huge social value\
    \ [12]. As an important part of new\ndigital infrastructure, the Internet of Things\
    \ (IoT) is deeply integrated with 5G, big data,\ncloud computing, artiﬁcial intelligence,\
    \ blockchain, digital twin, and other technologies,\nand is evolving into a smart\
    \ IoT system (IoTs 2.0) [13], which is profoundly changing\nthe process of the\
    \ modern agricultural industry and promoting the rapid development of\nsmart agriculture.\n\
    In the ﬁeld of smart agriculture, the Agricultural Internet of Things (AIoT) is\
    \ devel-\noping rapidly, but still faces many challenges. This includes the new\
    \ application of the\nagricultural scene, the transformation of the new agricultural\
    \ production mode, and the\ndeep integration with other technologies. As a basic\
    \ condition for the in-depth application\nof the agricultural Internet of Things,\
    \ 5G communication technology will promote the\nin-depth application of the agricultural\
    \ Internet of Things in smart agriculture. 5G can\nprovide MTC communication with\
    \ high reliability, low delay, and wide coverage, and its\nthree typical application\
    \ scenarios have broad prospects in smart agriculture [14]. 5G IoT\ntechnology\
    \ can be extended to the scope of current, which cannot be achieved with the\n\
    ﬁeld, making IoT depth perception of the intelligent environment perception, enlarging\n\
    the coverage of the Internet of Things of agriculture and the ascending scale,\
    \ expanding\nthe communication capacity, and realizing large-scale equipment interact\
    \ with each other\nand data sharing so as to realize the agricultural decision-making\
    \ process depth [15]. 5G-\nIoT is expected to provide real-time, on-demand, online,\
    \ reconﬁgurable, and end-to-end\ncoordinated capabilities for a variety of agricultural\
    \ applications. It can provide logically\nindependent network applications and\
    \ conﬁgure networks on demand. According to the\nfuture agricultural needs, the\
    \ integration of 5G with smart agriculture and the Internet of\nThings will be\
    \ able to achieve network characteristics, as shown in Figure 5.\nof the modern\
    \ agricultural industry and promoting the rapid dev\nculture. \nIn the field of\
    \ smart agriculture, the Agricultural Internet of \noping rapidly, but still faces\
    \ many challenges. This includes the\nagricultural scene, the transformation of\
    \ the new agricultural pro\ndeep integration with other technologies. As a basic\
    \ condition for t\nof the agricultural Internet of Things, 5G communication technolo\n\
    depth application of the agricultural Internet of Things in smart a\nvide MTC\
    \ communication with high reliability, low delay, and \nthree typical application\
    \ scenarios have broad prospects in smart \ntechnology can be extended to the\
    \ scope of current, which cann\nfield, making IoT depth perception of the intelligent\
    \ environmen\nthe coverage of the Internet of Things of agriculture and the asce\n\
    the communication capacity, and realizing large-scale equipment \nand data sharing\
    \ so as to realize the agricultural decision-making\nIoT is expected to provide\
    \ real-time, on-demand, online, reconfig\ncoordinated capabilities for a variety\
    \ of agricultural applications.\nindependent network applications and configure\
    \ networks on de\nfuture agricultural needs, the integration of 5G with smart\
    \ agricu\nThings will be able to achieve network characteristics, as shown in\n\
    Fine grained network\nSmart Agriculture \n5G Internet of \nThings Characteristic\
    \ \nDemand\nHigh data rate\nScalability\nReliable elasticity\nHigh density connection\n\
    Mobility\nSecurity\nHigh endurance\nlow power consumption\n \nFigure 5. Characteristics\
    \ of smart agriculture 5G Internet of Things dema\nThe above content will be able\
    \ to promote the landing of sm\nsent, many scholars are paying attention to the\
    \ opportunities and\nthe commercialization of 5G to the Internet of Things and\
    \ have ca\nview studies [16–23]. The relevant summaries are shown in Table \n\
    Table 2. 5G-IoT review papers overview. \nTime \nOverview Journals  \nMain Focus\
    \ \n2016\nM. R. Palattella et al. From technology, standardization\nFigure 5.\
    \ Characteristics of smart agriculture 5G Internet of Things demand.\nThe above\
    \ content will be able to promote the landing of smart agriculture. At present,\n\
    many scholars are paying attention to the opportunities and challenges brought\
    \ by the\ncommercialization of 5G to the Internet of Things and have carried out\
    \ a series of review\nstudies [16–23]. The relevant summaries are shown in Table\
    \ 2.\nElectronics 2023, 12, 2336\n6 of 46\nTable 2. 5G-IoT review papers overview.\n\
    Time\nOverview Journals\nMain Focus\nScene\n2016\nM. R. Palattella et al. [16]\n\
    From technology, standardization and\nmarket prospect\nMarket Paradigm\n2018\n\
    Shancang Li et al. [17]\nKey implementation technologies, main research\ntrends\
    \ and challenges\nKey technologies and trends\n2018\nD. Wang et al. [18]\nNew\
    \ paradigm of 5G intelligent Internet of\nThings (5G l-loT): big data mining,\
    \ deep\nlearning, and reinforcement learning\nNew paradigm\n2018\nG. A. Akpakwu\
    \ et al. [19]\nApplication requirements of the Internet of\nThings and the development\
    \ status of related\ncommunication technologies\nCommunications technology\n2019\n\
    N. Wang et al. [20]\nPhysical layer security\nSecurity\n2020\nK. Shaﬁque et al.\
    \ [21]\nProspects of 5G key technologies for the Internet\nof Things\n5G Key Technology\n\
    2021\nYu Tang et al. [22]\nOpportunities, challenges, and key technologies\nSmart\
    \ agriculture\n2022\nOgbodo E U et al. [23]\n5G and LPWAN-IoT for Improved Smart\
    \ Cities\nand Remote Area Applications\n5G LPWAN-IoT\n2022\nKhanh Q V et al. [24]\n\
    Wireless communication technologies for IoT in\n5G: vision, applications, and\
    \ challenges\nWireless communication\ntechnologies\nDespite a great deal of research\
    \ on 5G-IoT, there are few reviews on 5G IoT in agri-\nculture. Secondly, there\
    \ is a notable amount of research on smart agriculture, as shown in\nTable 3.\n\
    It can be seen that smart agriculture and the Internet of Things are both hot-tracking\n\
    directions, and there are many review articles and rapid technological development.\
    \ Many\nscholars have conducted research from various perspectives. Based on 5G,\
    \ there is not\nmuch in-depth research, and the following method is to carry out\
    \ in-depth research and\ndiscussion from this aspect.\nDomestic literature research\
    \ on 5G intelligent agricultural Internet of Things is also\nbecoming a new hotspot.\
    \ There is a rapid growth trend in related papers, and the main\nresearch ﬁelds\
    \ include smart agriculture, the Internet of Things, 5G, and so on. The above\n\
    distribution obtained from 5G, smart agriculture, and the Internet of Things retrieved\
    \ from\nCNKI shows that research is increasing rapidly as show in Figure 6.\n\
    PEER REVIEW \n7 of 46 \n2021 \nGodwin Idoje et al. \n[41] \nTechnological progress\
    \ and chal-\nlenges of smart farms \nSmart Farm \n2022 N. N. Misra et al. [42]\
    \ \nInternet of Things, Artificial Intelli-\ngence and Big Data in Agriculture\
    \ \nand Food Industry \nFood industry \nIt can be seen that smart agriculture\
    \ and the Internet of Things are both hot-tracking \ndirections, and there are\
    \ many review articles and rapid technological development. \nMany scholars have\
    \ conducted research from various perspectives. Based on 5G, there is \nnot much\
    \ in-depth research, and the following method is to carry out in-depth research\
    \ \nand discussion from this aspect. \nDomestic literature research on 5G intelligent\
    \ agricultural Internet of Things is also \nbecoming a new hotspot. There is a\
    \ rapid growth trend in related papers, and the main \nresearch fields include\
    \ smart agriculture, the Internet of Things, 5G, and so on. The above \ndistribution\
    \ obtained from 5G, smart agriculture, and the Internet of Things retrieved \n\
    from CNKI shows that research is increasing rapidly as show in Figure 6. \n \n\
    Figure 6. Shows the overall trend analysis of related papers. \n1.3. Summary \n\
    1.3.1. Contribution \nIn this paper, the research and prospects of 5G joint IoT\
    \ in smart agriculture are sum-\nmarized. Firstly, it reviews the differences\
    \ between 5G compared with current and previ-\nous communication technologies.\
    \ Following that, combined with the characteristics of the \nagricultural Internet\
    \ of Things, the reform and impact of 5G on it are summarized and \nFigure 6.\
    \ Shows the overall trend analysis of related papers.\nElectronics 2023, 12, 2336\n\
    7 of 46\nTable 3. Summary of smart agriculture.\nTime\nOverview Journals\nTheme\n\
    Key Words\n2017\nMekala M S et al. [25]\nSmart agriculture cloud computing\nSmart\
    \ agriculture, cloud\ncomputing\n2018\nRahul Dagar et al. [26]\nIntelligent Farm\
    \ IoT\nSmart Farm, IoT\n2019\nFarooq M S et al. [27]\nInvestigation on the Role\
    \ of the Internet of\nThings in Smart Farms\nSmart Farm, IoT\n2019\nDevare J et\
    \ al. [28]\nCrop generation detection and control\nDetection, crops\n2019\nFiona\
    \ J R et al. [29]\nImage processing and disease detection\nbased on image detection\
    \ in agriculture\nImage processing, disease\ndetection\n2019\nBh Ag At M et al.\
    \ [30]\nInternet of Things in Smart Farm\nSmart Farm, IoT\n2019\nSarker V et al.\
    \ [31]\nEdge computing Lora in the Internet\nof Things\nEdge computing, Lora\n\
    2019\nSmart et al. [32]\nSmart Farm\nSmart Farm\n2020\nVIPPON et al. [33]\nProgress\
    \ of Internet of Things\nin Agriculture\nIoT, Agriculture\n2020\nFriha O et al.\
    \ [34]\nNew technologies of the Internet of Things\nfor smart agriculture in the\
    \ future\nFuture smart agriculture IoT\n2021\nRayhana R et al. [35]\nRFID sensing\
    \ technology in\nsmart agriculture\nSmart agriculture, RFID,\nperception\n2021\n\
    Xing Yang et al. [36]\nInternet of Things for Smart Agriculture in\nthe Future\n\
    Smart agriculture, IoT\n2021\nYe Liu et al. [37]\nIndustry 4.0 to Agriculture\
    \ 4.0\nAgriculture 4.0\n2021\nBhat S A et al. [38]\nBig data and AI revolution\
    \ for\nprecision agriculture\nBig data, AI, precision\nagriculture\n2021\nGodwin\
    \ Idoje. et al. [39]\nProgress and challenges of intelligent\nagriculture Internet\
    \ of Things\nSmart agriculture, IoT\n2021\nWen Tao et al. [40]\nProgress and challenge\
    \ of intelligent\nagriculture Internet of Things\ncommunication technology\nSmart\
    \ agriculture, IoT,\ncommunication technology\n2021\nGodwin Idoje et al. [41]\n\
    Technological progress and challenges of\nsmart farms\nSmart Farm\n2022\nN. N.\
    \ Misra et al. [42]\nInternet of Things, Artiﬁcial Intelligence\nand Big Data\
    \ in Agriculture and\nFood Industry\nFood industry\n1.3. Summary\n1.3.1. Contribution\n\
    In this paper, the research and prospects of 5G joint IoT in smart agriculture\
    \ are\nsummarized. Firstly, it reviews the differences between 5G compared with\
    \ current and\nprevious communication technologies. Following that, combined with\
    \ the characteristics\nof the agricultural Internet of Things, the reform and\
    \ impact of 5G on it are summarized\nand prospected. Finally, combined with the\
    \ application paradigm of 5G and smart agricul-\ntural IoT, the possible challenges\
    \ are put forward, and some potential research issues are\npointed out.\n1.3.2.\
    \ Organization\n5G-oriented intelligent agricultural Internet of Things is an\
    \ essential direction of smart\nagriculture in the future. This paper intends\
    \ to summarize the relevant research status\nand possible research directions\
    \ from the following perspectives. The rest of this article is\nElectronics 2023,\
    \ 12, 2336\n8 of 46\nstructured as show in Figure 7. In this paper, the impact\
    \ of 5G on the Internet of Things\nfor smart agriculture is sorted out, and the\
    \ potential application scenarios and existing\nchallenges are summarized.\nPEER\
    \ REVIEW \n8 of 46\nThesises Overview\n• \nSmart agriculture\n• \n5G-IoT in Smart\
    \ agriculture\n• \nSummary\nPart I: Introduction\n• \n5G Characteristics\n• \n\
    Typical Applications of Smart Agricultural \nIoT based on 5G\n• \nFuture Trends\
    \ and Key Technologies of 5G \nIoT Application in Smart Agriculture\nPart II:\
    \ Integration and Application of 5G and \nSmart Agricultural Internet of Things\n\
    • \n5G Smart Agricultural IoT 2.0 Architecture\n• \n5G Smart agricultural IoT\
    \ Depth \nComprehensive Sense\n• \nReliable Data-driven detection of 5G Smart\
    \ \nAgricultural IoT\n• \nCloud Edge Fog Computing Fusion in 5G \nSmart Agricultural\
    \ IoT\n• \n5G Smart Agricultural IoT in-depth Service\n• \n5G Smart Agricultural\
    \ IoT Production \nintelligent control\nPart III: Evolution of Smart Agricultural\
    \  2.0 for \n5G\n• \nMain Application Scenarios of 5G Smart \nAgricultural IoT\n\
    • \nDepth Sense of 5G Smart Agriculture\n• \n5G Smart Agricultural Machinery\n\
    • \n5G Agricultural UAV\n• \nSmart agricultural Supply Chain \nManagement under\
    \ 5G\nPart IV: Revolution of smart agricultural iot \napplication paradigm under\
    \ 5G\n• \nFusion and Optimization of Sparse 5G base \nStation and Heterogeneous\
    \ Sensing \nnetwork in Smart agriculture\n• \nOptimization Control for Edge Computing\
    \ \nin 5G Smart Agricultural Production\n• \nScheduling Optimization of Heterogeneous\
    \ \nNodes under 5G Smart Agriculture\n• \nFault Detection and Self-healing for\
    \ 5G \nSmart Agricultural Platform\n• \nAI Application Optimization for 5G Smart\
    \ \nAgricultural IoT\n• \n5G-IoT System Service Model for Smart \nAgriculture\n\
    • \nSecurity Issues of 5G IoTs for Smart \nAgriculture\nPart V: Key Issues and\
    \ Challenges of 5G Smart \nAgricultural IoT\nPart VI: Summary\n \nFigure 7. Structure\
    \ of this article. \n2. Integration and Application of 5G and Smart Agricultural\
    \ Internet of Things \n2.1. 5G Characteristics \nThe existing agricultural IoT\
    \ uses various communication technologies in its appli-\ncation, including Zigbee,\
    \ Wifi, Sigfox, and so on. As a new generation of communication\nmode, 5G is compared\
    \ with the characteristics of other communication modes in agricul-\ntural scenes.\
    \ Table 4 summarizes how 5G compares to other communication technologies\ncommonly\
    \ used in the Internet of Things. 5G has its own characteristics. \nFigure 7.\
    \ Structure of this article.\n2. Integration and Application of 5G and Smart Agricultural\
    \ Internet of Things\n2.1. 5G Characteristics\nThe existing agricultural IoT uses\
    \ various communication technologies in its appli-\ncation, including Zigbee,\
    \ Wiﬁ, Sigfox, and so on. As a new generation of communication\nmode, 5G is compared\
    \ with the characteristics of other communication modes in agricul-\ntural scenes.\
    \ Table 4 summarizes how 5G compares to other communication technologies\ncommonly\
    \ used in the Internet of Things. 5G has its own characteristics.\nElectronics\
    \ 2023, 12, 2336\n9 of 46\nTable 4. 5G compared with other related communication\
    \ technologies.\nParameter\nStandard\nFrequency\nBand\nTime\nDelay\nData Rate\n\
    Transmission\nDistance\nEnergy Con-\nsumption\nCost\nNetwork\nSize\n5G\n3GPP\n\
    Release-16\n3–6 GHz\nLow\n100 Mb/s–\n10 Gb/s\nBase station\nsignal\ncoverage area\n\
    Medium\nMedium\nInﬁnite\n4G\nLTE\n2.4 G/865\nMHz\nMedium\n10 Mb/s–\n1 Gb/s\nBase\
    \ station\nsignal\ncoverage area\nMedium\nMedium\nInﬁnite\nZigbee\nIEEE\n802.15.4\n\
    2.4 G\nHigh\n20–250\nKb/s\nWithin 100 m\nLow\nLow\nBelow 500\nWiﬁ\nIEEE 802.11\n\
    5 GHz-60\nGHz\nMedium\n1 Mb/s–\n7 Gb/s\nLess than\n100 m\nMedium\nMedium\nBelow\
    \ 100\nNB-IoT\n3GPP\nRelease 13\n850–900\nMHz\nHigh\n160–250\nkbps\nBase station\n\
    signal\ncoverage area\nExtremely\nlow\nLow\n<50,000\nSigFox\nSigFox\n200 KHz\n\
    High\n100–600\nbit/s\nBase station\nsignal\ncoverage area\nLow\nLow\n<50,000\n\
    RFID\nISO18000-\n6C\n860–960\nMhz\nLow\n40–160\nkbit/s\n1–5 m\nLow\nLow\n<1000\n\
    It can be seen that 5G has its own characteristics compared with other communication\n\
    technologies, with incomparable advantages in terms of large bandwidth, large\
    \ connection,\nand low delay. Therefore, the emergence of 5G may bring new changes\
    \ and opportunities\nto the existing agricultural production mode in many agricultural\
    \ application scenarios.\nCompared with the 1G voice era, 2G text era, 3G picture\
    \ era, and the recent 4G video\nera, the application scenarios of 5G will get\
    \ a leapfrog development. Compared with 2G\nto 4G, which are born to connect “people”,\
    \ with the advent of the Internet of everything\nera, mobile communication networks\
    \ need to evolve to connect “things”. 5G is facing the\ncommon demand of large\
    \ trafﬁc and small data, mobile broadband on the one hand, and\nthe Internet of\
    \ Things on the other. Its main features are as follows in Figure 8.\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n9 of 46 \n \nNB-IoT \n3GPP Re-\nlease 13 \n850–900\
    \ MHz \nHigh \n160–250 \nkbps \nBase station \nsignal coverage \narea \nExtremely\
    \ low \nLow \n<50,000 \nSigFox \nSigFox \n200 KHz \nHigh \n100–600 \nbit/s \n\
    Base station \nsignal coverage \narea \nLow \nLow \n<50,000 \nRFID \nISO18000-\n\
    6C \n860–960 Mhz \nLow \n40–160 \nkbit/s \n1–5 m \nLow \nLow \n<1000 \nIt can\
    \ be seen that 5G has its own characteristics compared with other communication\
    \ \ntechnologies, with incomparable advantages in terms of large bandwidth, large\
    \ connec-\ntion, and low delay. Therefore, the emergence of 5G may bring new changes\
    \ and oppor-\ntunities to the existing agricultural production mode in many agricultural\
    \ application sce-\nnarios. \nCompared with the 1G voice era, 2G text era, 3G\
    \ picture era, and the recent 4G video \nera, the application scenarios of 5G\
    \ will get a leapfrog development. Compared with 2G \nto 4G, which are born to\
    \ connect “people”, with the advent of the Internet of everything \nera, mobile\
    \ communication networks need to evolve to connect “things”. 5G is facing the\
    \ \ncommon demand of large traffic and small data, mobile broadband on the one\
    \ hand, and \nthe Internet of Things on the other. Its main features are as follows\
    \ in Figure 8. \nq eMBB Enhanced Mobile \nBroadband\nq URLLC ultra reliable low\
    \ delay \ncommunication\nq mMTC Massive Machine Class \nCommunication\nFour characteristics\
    \ of 5G\n• \nUbiquitous\n• \nlow power \nconsumption\n• \nNetwork \nvirtualization\n\
    • \nNetwork intelligence\nq Wireless access technology\nq Network reconfiguration\
    \ \ntechnology\nq Distributed Business Services\nThree application scenarios of\
    \ \n5G\n 5G key technologies\n \nFigure 8. 5G technical introduction. \nThe development\
    \ and deployment of 5G have provided the communication layer \nfoundation for\
    \ access and transmission to realize the “Internet of everything” in a real \n\
    sense. Gb/S span will be realized not only in the field of mobile communication.\
    \ It can also \nprovide 3D, UHD video, AR/VR, cloud office, and other immersive\
    \ interactive methods \nto upgrade. It will also give birth to more new agricultural\
    \ application scenarios. The three \nmajor application scenarios of 5G application\
    \ services include Enhanced Mobile Broad-\nband (eMBB), Massive Machine Type Communications\
    \ (mMTC), and ultra-reliable and \nLow Latency Communications (uRLLC). The latter\
    \ two belong to the application scenarios \nof the Internet of Things [43,44],\
    \ as shown in Figure 9. \n100Gbps \neMBB\nSmart \nagriculture\nSmart \nhome\n\
    3D Video\nvirtual \nreality\nIndustrial \nInternet of\nLow\nMiddle High\nConnection\
    \ \ndensity：\n100m/km2\nPeak data \nrate: \n10Gpbs\nSpace \ncapacity: \n10Mbit/s/\n\
    m2\nEnergy \nefficiency\nFigure 8. 5G technical introduction.\nThe development\
    \ and deployment of 5G have provided the communication layer\nfoundation for access\
    \ and transmission to realize the “Internet of everything” in a real\nsense. Gb/S\
    \ span will be realized not only in the ﬁeld of mobile communication. It can also\n\
    provide 3D, UHD video, AR/VR, cloud ofﬁce, and other immersive interactive methods\
    \ to\nupgrade. It will also give birth to more new agricultural application scenarios.\
    \ The three\nmajor application scenarios of 5G application services include Enhanced\
    \ Mobile Broadband\n(eMBB), Massive Machine Type Communications (mMTC), and ultra-reliable\
    \ and Low\nLatency Communications (uRLLC). The latter two belong to the application\
    \ scenarios of\nthe Internet of Things [43,44], as shown in Figure 9.\nElectronics\
    \ 2023, 12, 2336\n10 of 46\nFigure 9. 5G: The three major application scenarios.\n\
    2.2. Typical Applications of Intelligent Agricultural Iot Based on 5G\nBased on\
    \ the above analysis, the three application scenarios of 5G, eMBB, mMTC,\nand\
    \ uRLLC will be widely applied in smart agriculture. It will signiﬁcantly improve\n\
    the connectivity between smart agriculture stakeholders, user products, and data.\
    \ The\nfollowing Figure 10 shows the typical application scenarios.\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n10 of 46 \n \n2.2. Typical Applications of Intelligent\
    \ Agricultural Iot Based on 5G \nBased on the above analysis, the three application\
    \ scenarios of 5G, eMBB, mMTC, \nand uRLLC will be widely applied in smart agriculture.\
    \ It will significantly improve the \nconnectivity between smart agriculture stakeholders,\
    \ user products, and data. The follow-\ning Figure 10 shows the typical application\
    \ scenarios. \nSmart Agriculture Scenarios \nunder 5G\nEnhanced Mobile \nBroadband\
    \ (eMBB)\nLarge scale machine \ncommunication (mMTC)\nUltra high reliability and\
    \ low delay \ncommunication (uRLLC)\nVideo monitoring of \nplant protection\n\
    UAV mapping/spectral \nimaging\nComplex Image/Video \nProcessing Based on Deep\
    \ \nLearning/AI\nFacility agriculture/stereoscopic \nagriculture: massive sensor\
    \ data \ntransmission\nIntelligent agricultural \nmachinery operation\nPerceptual\
    \ Monitoring \nof Field Agriculture\nData perception in \nfacility agriculture\n\
    Massive perceptual \nmonitoring in fishery and \naquaculture scenes\nAgricultural\
    \ UAV \noperation\nAutomatic driving of \nagricultural machinery\nHigh intelligence\
    \ and \nprecision agriculture scene: \nmassive sensing equipment\nKey point monitoring\
    \ \nand early warning\n \nFigure 10. 5G application scenarios in smart agriculture.\
    \ \n2.2.1. Enhance Mobile Broadband Applications (eMBB) in Smart Agricultural\
    \ IoT \nWith the improvement of intelligence in smart agriculture, there is increasing\
    \ data \ninformation, which needs the support of large data transmission rate.\
    \ The high bandwidth \nof 5G will be able to support high-definition video transmission\
    \ and massive data trans-\nmission. Successful real-time transmission of HD data\
    \ will enable remote real-time detec-\ntion, as well as the combination of machine\
    \ learning algorithms to transmit HD video back \nfor rapid analysis and computation.\
    \ Secondly, massive data transmission can be combined \nwith deep learning algorithms\
    \ to analyze and calculate plant diseases and insect pests \n[45,46] and quick\
    \ weed control. \nThe integrated application of 5G will promote the planting industry\
    \ to realize intel-\nligent planting technology, intelligent agricultural management,\
    \ open planting process, \nand intelligent labor management. 5G network, artificial\
    \ intelligence image recognition, \nsatellite remote sensing [47], big data, and\
    \ other technologies are used to drive all kinds \nof unmanned agricultural machinery\
    \ equipment to realize automatic operation. Including \naerial plant protection\
    \ UAV, unmanned highland gap plant protection machines, rototil-\nler, corn planters,\
    \ unmanned sprinkler irrigation systems, etc., to achieve safe, reliable, \nenvironmental\
    \ protection and energy-saving farm operations. It can also monitor agricul-\n\
    tural production in real-time, realize rapid detection of crop diseases, pests,\
    \ weeds, farm-i\nFigure 10. 5G application scenarios in smart agriculture.\n2.2.1.\
    \ Enhance Mobile Broadband Applications (eMBB) in Smart Agricultural IoT\nWith\
    \ the improvement of intelligence in smart agriculture, there is increasing data\n\
    information, which needs the support of large data transmission rate. The high\
    \ band-\nwidth of 5G will be able to support high-deﬁnition video transmission\
    \ and massive data\ntransmission. Successful real-time transmission of HD data\
    \ will enable remote real-time\ndetection, as well as the combination of machine\
    \ learning algorithms to transmit HD video\nback for rapid analysis and computation.\
    \ Secondly, massive data transmission can be\ncombined with deep learning algorithms\
    \ to analyze and calculate plant diseases and insect\npests [45,46] and quick\
    \ weed control.\nThe integrated application of 5G will promote the planting industry\
    \ to realize intel-\nligent planting technology, intelligent agricultural management,\
    \ open planting process,\nand intelligent labor management. 5G network, artiﬁcial\
    \ intelligence image recognition,\nsatellite remote sensing [47], big data, and\
    \ other technologies are used to drive all kinds of\nunmanned agricultural machinery\
    \ equipment to realize automatic operation. Including\naerial plant protection\
    \ UAV, unmanned highland gap plant protection machines, rototiller,\ncorn planters,\
    \ unmanned sprinkler irrigation systems, etc., to achieve safe, reliable, envi-\n\
    Electronics 2023, 12, 2336\n11 of 46\nronmental protection and energy-saving farm\
    \ operations. It can also monitor agricultural\nproduction in real-time, realize\
    \ rapid detection of crop diseases, pests, weeds, farmland\nwater quality, and\
    \ soil, provide ﬁne-grained nutrition, ventilation, and water supply for\ncrops,\
    \ and improve productivity [48,49].\nIn the 5G smart farm [50], the shading system,\
    \ fresh air system, cooling system,\nfertilization and watering system, data acquisition\
    \ system, and light supplement system\nachieved 5G control. For example, intelligent\
    \ glass greenhouse food production can also\nachieve substantial growth. Mobile\
    \ robots based on 5G can complete panoramic collection.\nAlong with the cultivation\
    \ tank of the greenhouse, it automatically completes inspection,\nﬁxed-point collection,\
    \ automatic return, automatic charging, and other actions. If there\nare obstacles\
    \ along the way, it can automatically go around. Real-time acquisition of\nhigh-deﬁnition\
    \ video data by video sensing nodes can solve the delay problem of massive\ndata\
    \ transmission based on edge computing devices and artiﬁcial intelligence, improve\n\
    quick response ability, and realize front-end intelligent decision-making [51].\
    \ All kinds of\nintelligent agriculture applications based on video processing\
    \ are shown in Table 5.\nTable 5. Video image processing in smart agriculture.\n\
    Literature\nApplication Scenario\nData Type\nGarcia [52]\nDistributed precision\
    \ agriculture\nVideo and Data\nHe Liu [53]\nVideo segmentation\nVideo\nSabzi S\
    \ [54]\nMonitoring of potato weeds in video\nVideo\nHe Jiang [55]\nFruit disease\
    \ surveillance based on deep learning\nImage\nIt can be seen that there are many\
    \ intelligent agricultural applications based on video\nimage detection at present.\
    \ With the continuous development of video acquisition equip-\nment, HD images\
    \ and videos are becoming increasingly popular. Optimizing data trans-\nmission\
    \ has always been a challenge. The integrated application of smart agriculture\
    \ based\non 5G is a big direction.\n2.2.2. Large-Scale Machine Type Communication\
    \ (mMTC) in Smart Agricultural IoT\nSmart agricultural IoT is the next generation\
    \ of agricultural IoT for smart agriculture.\nIt needs a depth perception of the\
    \ agricultural production process. Large-scale agricultural\nproduction scenarios\
    \ require large-scale sensing nodes to transmit data [56]. Traditional\nsensor\
    \ networks have some difﬁculties in networking reliability, energy efﬁciency,\
    \ and\ndeployment cost. However, large-scale machine-type communication based\
    \ on 5G can\nachieve a smart agricultural IoT with low cost, high reliability,\
    \ low power consumption,\nand convenient networking and deployment. For example,\
    \ NB-IoT can be deployed to\nquickly monitor soil, fertilizer, and plants in farmland.\
    \ In this way, the comprehensive\nperception and depth perception of agricultural\
    \ production can be realized, providing\nsupport for the deepening application\
    \ of smart agriculture [57].\n5G-oriented NB-IoT enables dense sensing network\
    \ deployment. Combining com-\nputer vision and other technologies can effectively\
    \ extract plant phenotypic variation\nand its related information. Moreover, machine\
    \ learning, artiﬁcial intelligence, and other\ncutting-edge technologies are used\
    \ for processing [58]. Deep learning convolutional neural\nnetworks were used\
    \ to evaluate crop phenotypic characteristics and soil conditions. Multi-\nspectral\
    \ imaging in agricultural areas is based on IoT sensors and small unmanned aerial\n\
    vehicles (UAVs). It identiﬁes plant quality and leaf diseases.\n2.2.3. Ultra-Reliable\
    \ Low Latency Communication (uRLLC) in Smart Agricultural IoT\nSuch ultra-reliable\
    \ low-latency communication applications are generally oriented to\nmission-critical,\
    \ real-time transmission of critical data and control of major agricultural\n\
    equipment [59]. Drones based on 5G networks can achieve precision operations.\
    \ The\nElectronics 2023, 12, 2336\n12 of 46\nﬂight trajectory and situation data\
    \ of the UAV can be returned to the 5G network UAV\nmanagement and operation platform\
    \ in real-time through the 5G network. Flight status can\nbe monitored in real-time\
    \ [60]. Through the agricultural information collected by UAV and\nsatellite remote\
    \ sensing technology, the platform can intelligently and dynamically analyze\n\
    the crop situation in the monitoring region, make a macroscopic estimation of\
    \ the real-time\nseedling situation, environmental dynamics and distribution of\
    \ crops, and output scientiﬁc\nreports [61]. According to the report, farmers\
    \ can clearly grasp the growth situation of\ncrops and soil moisture and manage\
    \ production in response to problems so as to ensure\nmore scientiﬁc and efﬁcient\
    \ farming activities.\nThe universal application of 5G will provide the communication\
    \ basis for unmanned,\nintelligent, and intelligent agricultural machinery and\
    \ equipment because 5G technology\nhas the characteristics of high speed, short\
    \ delay, low power consumption, ubiquitous\nnetwork, and scalability. It will\
    \ shine in the ﬁelds of agricultural Internet of Things,\nprecision planting,\
    \ agricultural products circulation traceability, agricultural drones, smart\n\
    farming, agricultural industry services, and so on, and promote agriculture to\
    \ be more\ninformationalized and intelligent [62,63].\n2.3. Future Trends and\
    \ Key Technologies of 5G-IoT Application in Smart Agriculture\nIt can be seen\
    \ from the above analysis that the integration of 5G and IoT has a wide\napplication\
    \ prospect in the scenario of smart agriculture. Agricultural IoT can be used\
    \ to\ncollect environmental monitoring information on crop growth and process\
    \ this information\nto develop the production plan of precision agriculture. Precision\
    \ agriculture requires\nthe network to support the connection of massive devices\
    \ and a large number of small\ndata packets. Since agricultural IoT devices are\
    \ often deployed in areas where signals are\nchallenging to reach, such as mountains,\
    \ forests, and waters, 5G can meet the requirements\nwith stronger coverage capability,\
    \ ﬂexibility, scalability, and lower power consumption,\ndelay, and cost. The\
    \ future trends of intelligent agricultural IoT facing 5G mainly reﬂect\nthe following:\n\
    1.\nCloud edge collaboration: agricultural monitoring terminal and cloud collaboration.\n\
    2.\nCloud computing/AI/big data/Internet of Things/digital twin and other agricul-\n\
    tural integration.\n3.\nVirtualization and servitization of perception/access/communication\
    \ layer, software\ndeﬁned network.\n4.\nModel-driven, cloud-native new application\
    \ (APP) development environment for\nsmart Internet of Things.\n5.\nThe deep integration\
    \ of people, information space, and physical space will form\na deep intelligent\
    \ smart agriculture and achieve a harmonious ecology of human–\nmachine symbiosis.\n\
    The key technologies of IoT applications in smart agriculture include vital informa-\n\
    tion sensor technology, phenotype information acquisition technology, phenotype\
    \ group\ndata analysis technology, phenotype group big data management and database\
    \ building\ntechnology, etc. [64,65]. All these technologies need the support\
    \ of 5G. Among them,\nthe life information sensor technology collects information\
    \ about seeds and their propa-\ngation/seed production environment and obtains\
    \ the corresponding physiological and\necological information through signal transformation\
    \ and AI data processing. Phenotypic\ninformation acquisition technology automatically\
    \ extracts important phenotypic features\nand logical relationships from massive\
    \ amounts of information to realize automatic and\naccurate identiﬁcation of phenotypic\
    \ traits. Phenotypic data analysis technology covers the\ncomplete process from\
    \ the initial data collection to the ﬁnal reﬁnement analysis. Phenotype\ngroup\
    \ big data management and database building technology are used to manage, store,\n\
    and share tabular data.\nElectronics 2023, 12, 2336\n13 of 46\n3. Evolution of\
    \ Intelligent Agricultural IoT 2.0 for 5G\nIntelligent Internet of Things (IoT\
    \ 2.0) refers to a complex system that integrates “hu-\nman, information space\
    \ and physical space” [66] under the guidance of 5G and other\ncommunication technologies\
    \ and AI technologies and intelligently interconnects and serves\ncooperatively.\
    \ Among them, the new generation of AI technologies includes data-driven\ndeep\
    \ reinforcement learning intelligence, network-based swarm intelligence, hybrid\
    \ in-\ntelligence oriented by human–machine and brain–computer interaction technology,\
    \ cross-\nmedia inference intelligence, autonomous intelligent system, etc. The\
    \ “wisdom” of the\nsmart IoT system refers to the interconnection of people, information\
    \ space and physi-\ncal space, and the digitalization, IoT, servitization (cloud),\
    \ collaboration, customization,\nﬂexibility, greenness, and intelligence of the\
    \ layered and progressive system [67].\nThe Internet of Things is evolving into\
    \ the next generation. Under the role of 5G, the\nInternet of Things combined\
    \ with big data, machine learning, cloud services, and so on, will\nhave intelligent\
    \ characteristics. It can make the physical process and the information world\n\
    deep integration. The network level of the Internet of Things mainly includes\
    \ monitoring,\ndetection, computing, service, and control from bottom to top,\
    \ and these connotations will\nalso undergo profound changes.\n3.1. 5G Smart Agricultural\
    \ IoT 2.0 Architecture\nWith the rapid development of video business and various\
    \ vertical business applica-\ntions in smart agriculture, centralized data storage\
    \ and processing modes will face difﬁcult\nbottlenecks and pressures. The existing\
    \ Internet of Things architecture is difﬁcult to meet\nthe data return of big\
    \ data, which easily deteriorates network indicators and affects user\nexperience.\
    \ In this case, data processing capabilities and services need to be provided\n\
    near the edge of the network where the data are generated. With the development\
    \ of\n5G and the availability of relevant business requirements and network conditions,\
    \ edge\ncomputing has gradually achieved great development. Agricultural IoT is\
    \ evolving to\nSmart Agricultural IoT 2.0, where edge computing can alleviate\
    \ these defects of centralized\nIoT, and transfer computing tasks to the edge\
    \ service side to signiﬁcantly improve delay\nand energy consumption, especially\
    \ for delay and energy-sensitive IoT applications.\n5G IoT for smart agriculture\
    \ achieves optimal resource allocation through network\nslicing, SDN/VFN, and\
    \ other technologies. However, due to a large amount of sensing\ndata in the smart\
    \ agriculture scene, the real-time requirement is high. With the increase in\n\
    terminal computing power, the network architecture for smart agriculture will\
    \ also change.\nThe architecture of a smart IoT system is shown in Figure 11.\n\
    5G-based agricultural IoT can be implemented by deploying edge computing based\
    \ on\napplication needs. Edge computing migrates IT resources, such as computing\
    \ and storage,\nfrom traditional cloud data centers to users. IT shortens the\
    \ physical distance between\nusers and IT resources, achieves lower data interaction\
    \ delay, and saves network trafﬁc.\nThis provides users with low latency and high\
    \ stability of IT solutions. Edge computation\ndepends on edge nodes. The requirements\
    \ of edge nodes for smart agricultural IoT are\nnot strictly regulated. Compared\
    \ with the general sensor node thought and its computing\npower, the communication\
    \ ability is stronger. The deployment position is usually at the\nend of the network,\
    \ that is, the application site. After IoT edge applications are deployed,\nedge\
    \ nodes serve as extensions of remote IoT platforms on devices. Devices are managed\n\
    through cloud-edge collaboration. Edge nodes can provide computing and management\n\
    services for nearby devices, such as local management of low-latency services,\
    \ local control,\nand rule execution when disconnected from the cloud. The device\
    \ accesses the edge node\nand ﬁnally uploads data to the remote IoT platform through\
    \ the edge node, as shown in\nFigure 12.\nElectronics 2023, 12, 2336\n14 of 46\n\
    energy consumption, especially for delay and energy-sensitive IoT applications.\
    \ \n5G IoT for smart agriculture achieves optimal resource allocation through\
    \ netwo\nslicing, SDN/VFN, and other technologies. However, due to a large amount\
    \ of sensi\ndata in the smart agriculture scene, the real-time requirement is\
    \ high. With the increase\nterminal computing power, the network architecture\
    \ for smart agriculture will al\nchange. The architecture of a smart IoT system\
    \ is shown in Figure 11. \nPrivate \nnetwork \ntechnology\nInternet \nof Things\n\
    Smart sensor \nnetwork\nEthernet\nNew sensing unit\nRFID/Smart sensor/Camera coil,\
    \ GPS, Remote sensing, Radar, QR code\nEdge \ncomputing\nPerception and \nimplementation\
    \ \nof smart \nagriculture\nFog computing\nCloud \ncomputing\nSmart \nagriculture\
    \ \napplication\nEdge computing node \ndomain gateway\nPerception&M\nonitoring\n\
    Detection and \ncalculation\nComputing\nCloud \nservice\nControl\nSmart information\
    \ fusion \nand processing\n \nFigure 11. Architecture of the smart Internet of\
    \ Things system based on 5G. \n5G-based agricultural IoT can be implemented by\
    \ deploying edge computing bas\non application needs. Edge computing migrates\
    \ IT resources, such as computing and sto\nage, from traditional cloud data centers\
    \ to users. IT shortens the physical distance betwe\nusers and IT resources, achieves\
    \ lower data interaction delay, and saves network traf\nThis provides users with\
    \ low latency and high stability of IT solutions. Edge computati\ndepends on edge\
    \ nodes. The requirements of edge nodes for smart agricultural IoT a\nnot strictly\
    \ regulated. Compared with the general sensor node thought and its computi\npower,\
    \ the communication ability is stronger. The deployment position is usually at\
    \ t\nend of the network, that is, the application site. After IoT edge applications\
    \ are deploye\nedge nodes serve as extensions of remote IoT platforms on devices.\
    \ Devices are manag\nthrough cloud-edge collaboration. Edge nodes can provide\
    \ computing and manageme\nservices for nearby devices, such as local management\
    \ of low-latency services, lo\nFigure 11. Architecture of the smart Internet of\
    \ Things system based on 5G.\nElectronics 2023, 12, x FOR PEER REVIEW \ncontrol,\
    \ and rule execution when disconnected from the cloud. The de\nedge node and finally\
    \ uploads data to the remote IoT platform through \nshown in Figure 12. \n***\n\
    ***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n***\n\
    ***\n***\n***\n***\n***\nField agriculture\nPlant factory\nSmart breeding\nEdge\
    \ Server\nEdge Server\nEdge Server\n5G gateway\n5G gateway\n5G gateway\nRemote\
    \ cloud \nservice\n \nFigure 12. Application scenario diagram of the edge computing\
    \ system of the a\nof Things. \n3.1.1. Personalized Service Network Slice in 5G\
    \ Intelligent Agricultural \nThings \nRequirements on network characteristics\
    \ (network speed, delay, n\nFigure 12. Application scenario diagram of the edge\
    \ computing system of the agricultural Internet\nof Things.\nElectronics 2023,\
    \ 12, 2336\n15 of 46\n3.1.1. Personalized Service Network Slice in 5G Intelligent\
    \ Agricultural Internet of Things\nRequirements on network characteristics (network\
    \ speed, delay, number of connec-\ntions, energy consumption, etc.) in different\
    \ agricultural application scenarios are different,\nand some are even contradictory.\
    \ For example, agricultural high-deﬁnition video surveil-\nlance cares about the\
    \ picture quality, and the overall delay of a few seconds or even more\nthan ten\
    \ seconds is not felt. In remote agricultural machinery driving, a delay of more\n\
    than 10 ms will seriously affect safety. Therefore, the purpose of splitting and\
    \ reﬁning the\nnetwork is to respond more ﬂexibly to the needs of smart agriculture\
    \ scenarios. Based on 5G\ntechnology, Network Slicing can be implemented, and\
    \ the Network can be divided into N\nlogical networks according to application\
    \ scenarios as shown in Figure 13. Different logical\nnetworks serve different\
    \ scenarios. Because of the diversiﬁcation of demand, networks\nneed diversiﬁcation.\
    \ The network must be ﬂexible because it needs to be sliced. Because\nthey move\
    \ ﬂexibly, the connections between networks also change ﬂexibly [68].\n \nThings\
    \ \nRequirements on network characteristics (network speed, delay, number of \n\
    tions, energy consumption, etc.) in different agricultural application scenarios\
    \ ar\nent, and some are even contradictory. For example, agricultural high-definition\
    \ vi\nveillance cares about the picture quality, and the overall delay of a few\
    \ seconds \nmore than ten seconds is not felt. In remote agricultural machinery\
    \ driving, a d\nmore than 10 ms will seriously affect safety. Therefore, the purpose\
    \ of splitting an\ning the network is to respond more flexibly to the needs of\
    \ smart agriculture sc\nBased on 5G technology, Network Slicing can be implemented,\
    \ and the Network\ndivided into N logical networks according to application scenarios\
    \ as shown in Fi\nDifferent logical networks serve different scenarios. Because\
    \ of the diversificatio\nmand, networks need diversification. The network must\
    \ be flexible because it nee\nsliced. Because they move flexibly, the connections\
    \ between networks also change\n[68]. \nNetwork slicing is a logical network partitioning\
    \ scheme implemented to m\ndifferent requirements of various applications, which\
    \ can ensure resource isolat\nservice guarantee between slices where different\
    \ services are located [69]. \nCrop growth \nmonitoring VWSN\nMoisture detection\
    \ \nNB IoT\nAgricultural UAV \nspraying formation\nRobot pest inspection \nformation\n\
    Slice 1 Video \nPerception\nSlice 2 narrowband \nsmall data\nOther slices\n5G\n\
    Intelligent agriculture IoT\nSlice 3 High real-time data \ntransmission service\n\
    \  \n \nFigure 13. Smart agriculture 5G-IoT network slice.\nNetwork slicing is\
    \ a logical network partitioning scheme implemented to meet the\ndifferent requirements\
    \ of various applications, which can ensure resource isolation and\nservice guarantee\
    \ between slices where different services are located [69].\n3.1.2. The 5G Intelligent\
    \ Agricultural Internet of Things (IoT) System Is Integrated with\n“Cloud, Network,\
    \ Edge, and End”\nThe impact of 5G on the Internet of Things for smart agriculture,\
    \ including the system\nnetwork architecture, will bring new changes. 5G intelligent\
    \ agricultural Internet of Things\nwill realize the integration of “cloud–network–edge–end”\
    \ and profoundly change the\nagricultural production form [70].\nUnder the role\
    \ of 5G, the future intelligent agricultural Internet of Things must be a\nsystem\
    \ of cloud-net-edge-end deep integration as shown in Figure 14. Realize the deep\
    \ in-\ntegration and control of agricultural production and information world.\
    \ The cloud realizes\nthe cloud of services and data, and the network includes\
    \ all kinds of networks represented\nby 5G. The self-consistency of intelligent\
    \ agricultural IoT is realized by combining edge\ncomputing and terminal nodes\
    \ [71].\nElectronics 2023, 12, 2336\n16 of 46\nUnder the role of 5G, the future\
    \ intelligent agricultural Internet of Things must be a \nsystem of cloud-net-edge-end\
    \ deep integration as shown in Figure 14. Realize the deep \nintegration and control\
    \ of agricultural production and information world. The cloud real-\nizes the\
    \ cloud of services and data, and the network includes all kinds of networks repre-\n\
    sented by 5G. The self-consistency of intelligent agricultural IoT is realized\
    \ by combining \nedge computing and terminal nodes [71]. \nCloud\nEdge \ncomputing\n\
    Sense \ndevice\nInterface\nComputing \nresource\nStorage \nresources\nNetwork\
    \ \nresource\nComputing/Network/Storage API\nControl area\nFunctional \nmodule\n\
    Analysis field\nFunctional \nmodule\nOptimization field\nFunctional module\nEdge\
    \ node:\nEdge gateway\nEdge controller\nEdge server\nEdge sensor\n  \nModel based\
    \ business \norchestration\nDirect resource call\nManagement Service\nSmart agriculture\
    \ Internet of Things application\nCloud service\n5G \n \nFigure 14. 5G-IoT service\
    \ architecture of cloud-edge collaborative smart agriculture. \n3.2. Perception\
    \ of Deep Fusion of 5G-Intelligent Agricultural Internet of Things \nSmart agriculture\
    \ is a form of deep intelligence of agricultural production and a form \nof deep\
    \ integration of the physical production process and information world. First,\
    \ the \nsmart agricultural IoT requires comprehensive and in-depth monitoring\
    \ of agricultural \nproduction processes and objects. This requires the support\
    \ of 5G, the intensive access of \nmassive sensing devices, the transmission of\
    \ large amounts of data, and the support of the \noperating system basic software\
    \ platform suitable for the new generation of IoT systems. \nThe end devices will\
    \ evolve. Meanwhile, the communication modules and architectures \nwill change.\
    \ \n3.2.1. Intelligent Agricultural IoT Sensing Device Based on 5G \nIn order\
    \ to adapt to the performance of the smart agricultural Internet of Things and\
    \ \nthe advantages of 5G, such as high speed, high density, low delay, low power\
    \ consump-\ntion, and wide coverage, the software and hardware of traditional\
    \ sensing devices need \nto be changed. \nThe carrier bandwidth of 5G communication\
    \ varies from 180 K to 200 M [72]. Com-\nmunication rates also range from a multi-point\
    \ uplink rate of 56 kbps for narrowband IoT \nto a maximum peak rate of 10 Gbps.\
    \ The 180 K carrier bandwidth is specifically targeted \nat low-rate NB-IoT applications,\
    \ featuring strong signal strength, strong penetration, and \ngood coverage radius\
    \ and depth coverage. It is mainly suitable for some IoT terminal \nFigure 14.\
    \ 5G-IoT service architecture of cloud-edge collaborative smart agriculture.\n\
    3.2. Perception of Deep Fusion of 5G-Intelligent Agricultural Internet of Things\n\
    Smart agriculture is a form of deep intelligence of agricultural production and\
    \ a form\nof deep integration of the physical production process and information\
    \ world. First, the\nsmart agricultural IoT requires comprehensive and in-depth\
    \ monitoring of agricultural\nproduction processes and objects. This requires\
    \ the support of 5G, the intensive access of\nmassive sensing devices, the transmission\
    \ of large amounts of data, and the support of the\noperating system basic software\
    \ platform suitable for the new generation of IoT systems.\nThe end devices will\
    \ evolve. Meanwhile, the communication modules and architectures\nwill change.\n\
    3.2.1. Intelligent Agricultural IoT Sensing Device Based on 5G\nIn order to adapt\
    \ to the performance of the smart agricultural Internet of Things and\nthe advantages\
    \ of 5G, such as high speed, high density, low delay, low power consumption,\n\
    and wide coverage, the software and hardware of traditional sensing devices need\
    \ to\nbe changed.\nThe carrier bandwidth of 5G communication varies from 180 K\
    \ to 200 M [72]. Com-\nmunication rates also range from a multi-point uplink rate\
    \ of 56 kbps for narrowband IoT\nto a maximum peak rate of 10 Gbps. The 180 K\
    \ carrier bandwidth is speciﬁcally targeted\nat low-rate NB-IoT applications,\
    \ featuring strong signal strength, strong penetration, and\ngood coverage radius\
    \ and depth coverage. It is mainly suitable for some IoT terminal\napplications\
    \ with low data rates and most of the time in hibernation state. Such applica-\n\
    tions are widely used in smart agriculture and many other applications, such as\
    \ ecological\nenvironment monitoring, because many plants and animals have long\
    \ growth cycles and\nslow changes. There are four typical applications of NB-IoT,\
    \ as shown in Table 6.\nSecondly, such applications mainly change the hardware\
    \ of sensor nodes in terms of\nantenna communication module and low-power design\
    \ [73,74]. The module of the terminal\nnode device based on NB-IoT will also change\
    \ correspondingly, as shown in Figure 15.\nElectronics 2023, 12, 2336\n17 of 46\n\
    Table 6. Four typical business types of NB-IoT.\nType\nDescribe\nScene\nAutonomous\
    \ exception\nreporting service type\nFor example, the notiﬁcation of smoke and\
    \ fog alarm\ndetector and smart electricity meter power failure, the\nminimum\
    \ data demand for uplink data (in the order of\ncross knots), and the cycle is\
    \ usually in years and months.\nFishery breeding, precision\nagriculture\nBusiness\
    \ type of independent\nperiodic report\nFor example, the measurement report of\
    \ intelligent utilities\n(gas/water/electricity), intelligent agriculture, intelligent\n\
    environment, etc., the uplink demand for small data volume\n(hundreds of bytes),\
    \ and the cycle is mostly in days\nand hours.\nPlant moisture, environmental\n\
    monitoring, climate monitoring\nNetwork instruction service\ntype\nFor example,\
    \ when the device is turned on/off, it triggers\nsending an uplink report, requests\
    \ meter reading and\nrequires minimal downlink data (in the order of cross knots).\n\
    The cycle is usually in days and hours.\nAutomatic irrigation, automatic\noxygenation,\
    \ etc.\nSoftware update business type\nFor example, software patches/updates require\
    \ a large\namount of data (kilobyte level) for uplink and downlink,\nand the cycle\
    \ is usually in days and hours.\nRemote System Update\nporting service \ntype\
    \ \nof cross knots), and the cycle is usually in years and \nmonths. \nture \n\
    Business type \nof independ-\nent periodic \nreport \nFor example, the measurement\
    \ report of intelligent \nutilities (gas/water/electricity), intelligent agriculture,\
    \ \nintelligent environment, etc., the uplink demand for \nsmall data volume (hundreds\
    \ of bytes), and the cycle \nis mostly in days and hours. \nPlant moisture, en-\n\
    vironmental moni-\ntoring, climate \nmonitoring \nNetwork in-\nstruction ser-\n\
    vice type \nFor example, when the device is turned on/off, it trig-\ngers sending\
    \ an uplink report, requests meter reading \nand requires minimal downlink data\
    \ (in the order of \ncross knots). The cycle is usually in days and hours. \n\
    Automatic irriga-\ntion, automatic ox-\nygenation, etc. \nSoftware up-\ndate business\
    \ \ntype \nFor example, software patches/updates require a large \namount of data\
    \ (kilobyte level) for uplink and down-\nlink, and the cycle is usually in days\
    \ and hours. \nRemote System \nUpdate \nSecondly, such applications mainly change\
    \ the hardware of sensor nodes in terms of \nantenna communication module and\
    \ low-power design [73,74]. The module of the termi-\nnal node device based on\
    \ NB-IoT will also change correspondingly, as shown in Figure \n15. \nPower supply\
    \ module\nSensor node\nData \nacquisition \nmodule\nMicrocontroller/\nMCU\nWireless\
    \ \nprocessing \nmodule\nWireless \ncommunication \nmodule\nStorage\nPower supply\
    \ module\nSensor node\nData \nacquisition \nmodule\nMicrocontroller/\nMCU\nWireless\
    \ \nprocessing \nmodule\nNB IoT \ncommunication \nmodule\nStorage\nNB-SIM \ncard\n\
    \ \nFigure 15. Sensing device communication module changes. \nThe communication\
    \ module is usually made of off-the-shelf modules or selected \nchips for design.\
    \ NB-IoT chips can be used by carriers of China Telecom, China Mobile, \nand China\
    \ Unicom. At the same time, Sim cards are required to order corresponding data\
    \ \nplans. \nMany application scenarios facing smart agriculture also require\
    \ large bandwidth \ndata transmissions, such as video and VR. 5G-oriented sensor\
    \ nodes can select 5G-ori-\nented high-bandwidth communication modules. Its communication\
    \ module baseband \nchips require specialized chips, such as Qualcomm, Huawei,\
    \ etc. Due to the high data rate, \nthe number and type of corresponding sensors\
    \ can also be diverse. In the meantime, the \ncorresponding processor, memory,\
    \ and power supply modules are completely different, \nas shown in Figure 16.\
    \ \nFigure 15. Sensing device communication module changes.\nThe communication\
    \ module is usually made of off-the-shelf modules or selected chips\nfor design.\
    \ NB-IoT chips can be used by carriers of China Telecom, China Mobile, and\nChina\
    \ Unicom. At the same time, Sim cards are required to order corresponding data\
    \ plans.\nMany application scenarios facing smart agriculture also require large\
    \ bandwidth\ndata transmissions, such as video and VR. 5G-oriented sensor nodes\
    \ can select 5G-oriented\nhigh-bandwidth communication modules. Its communication\
    \ module baseband chips\nrequire specialized chips, such as Qualcomm, Huawei,\
    \ etc. Due to the high data rate,\nthe number and type of corresponding sensors\
    \ can also be diverse. In the meantime, the\ncorresponding processor, memory,\
    \ and power supply modules are completely different, as\nshown in Figure 16.\n\
    Sensor nodes are equipped with 5G high-rate baseband chips for high-rate data\
    \ com-\nmunication. Multiple sensors can be integrated into appropriate scenarios\
    \ to improve\nthe integration degree, reduce the number of nodes and optimize\
    \ the network architec-\nture [75,76]. For example, the smart insecticidal lamp\
    \ can integrate a variety of sensors,\nas shown in Figure 17. When multiple sensors\
    \ are integrated, the bandwidth of the data\nstream changes. In the 5G scenario,\
    \ the architecture of the Internet of Things changes ac-\ncordingly, replacing\
    \ the traditional Zigbee network, etc. [77]. The change of communication\nmodule\
    \ will lead to an overall change of hardware. For example, low-power design, the\n\
    architecture of the main control chip, software change, power supply system design,\
    \ sensor\nintegration, etc. [78].\nElectronics 2023, 12, 2336\n18 of 46\nElectronics\
    \ 2023, 12, x FOR PEER REVIEW \n \nPower supply module\nSense Module \n1\nMicrocontroller/\n\
    MCU\nWireless \nprocessing \nmodule\n5G baseband \nchip\nMass storage\nSIM \n\
    card\nSense Module \n2\nSense Module \n3\nSense \nModule  \n4K Video Module\n\
    \ \n \nFigure 16. Sensor node composition model facing high rate facing 5G. \n\
    Sensor nodes are equipped with 5G high-rate baseband chips for high-rate da\n\
    munication. Multiple sensors can be integrated into appropriate scenarios to imp\n\
    integration degree, reduce the number of nodes and optimize the network arch\n\
    [75,76]. For example, the smart insecticidal lamp can integrate a variety of sen\n\
    shown in Figure 17. When multiple sensors are integrated, the bandwidth of t\n\
    stream changes. In the 5G scenario, the architecture of the Internet of Things\
    \ cha\ncordingly, replacing the traditional Zigbee network, etc. [77]. The change\
    \ of com\ntion module will lead to an overall change of hardware. For example,\
    \ low-power\nthe architecture of the main control chip, software change, power\
    \ supply system\nsensor integration, etc. [78]. \nScreen\nSoil moisture\nSoil\
    \ temperature and humidity\nEvaporation\nSoil PH\nRainfall\nPhotosynthetically\
    \ active radiation\nWind speed/direction\nSoil electrical conductivity\n \nFigure\
    \ 17. Multi-sensor system. \n3.2.2. 5G Intelligent Agricultural IoT Operating\
    \ System \nWith 5G, the hardware of IoT sensor nodes for smart agriculture has\
    \ change\nder to adapt to the application scenario, the corresponding software\
    \ system wi\nfected and changed. The vision goal of the Internet of Things with\
    \ 5G is the inter\ntion and interconnectivity of everything However the current\
    \ operating system\nFigure 16. Sensor node composition model facing high rate\
    \ facing 5G.\n4K Video Module\n \nFigure 16. Sensor node composition model facing\
    \ high rate f\nSensor nodes are equipped with 5G high-rate base\nmunication. Multiple\
    \ sensors can be integrated into ap\nintegration degree, reduce the number of\
    \ nodes and \n[75,76]. For example, the smart insecticidal lamp can\nshown in\
    \ Figure 17. When multiple sensors are integ\nstream changes. In the 5G scenario,\
    \ the architecture of\ncordingly, replacing the traditional Zigbee network, et\n\
    tion module will lead to an overall change of hardwar\nthe architecture of the\
    \ main control chip, software cha\nsensor integration, etc. [78]. \nScreen\nSoil\
    \ moisture\nSoil temperature and humidity\nEvaporation\nSoil PH\nRainfall\nPhotosynthetically\
    \ active radiation\nWind speed/direction\nSoil electrical conductivity\n \nFigure\
    \ 17. Multi-sensor system. \n3.2.2. 5G Intelligent Agricultural IoT Operating\
    \ System\nWith 5G, the hardware of IoT sensor nodes for sm\nder to adapt to the\
    \ application scenario, the correspo\nfected and changed. The vision goal of the\
    \ Internet of \ntion and interconnectivity of everything. However, the\nlt t\n\
    t thi\nl\nh\nth\nl\nk\nf i t\nFigure 17. Multi-sensor system.\n3.2.2. 5G Intelligent\
    \ Agricultural IoT Operating System\nWith 5G, the hardware of IoT sensor nodes\
    \ for smart agriculture has changed. In order\nto adapt to the application scenario,\
    \ the corresponding software system will be affected\nand changed. The vision\
    \ goal of the Internet of Things with 5G is the interconnection\nand interconnectivity\
    \ of everything. However, the current operating system is difﬁcult to\nsupport\
    \ this goal, such as the lack of interoperability of a lightweight operating system\
    \ [79].\nThe status quo of the Internet of Things operating system is shown in\
    \ Figure 18.\nElectronics 2023, 12, 2336\n19 of 46\nElectronics 2023, 12, x FOR\
    \ PEER REVIEW \n18 of 46 \n \n \nThe connection volume \nof IoT equipment has\
    \ \nreached 10 billion\nSoftware and hardware \ncoupling is seriously lagging\
    \ \nbehind the industry \nstandard\nThe R&D cycle of the \noperating system is\
    \ 4-\n5 years\nThe cost of software development \nand system integration R&D of\
    \ a \nsingle SKU is more than 300000 \ndollars\nMany terminals\nSystem mismatch\n\
    Long R&D cycle\nHigh R&D cost\nMany brands\nIncompatible\nThe products cannot\
    \ be linked \nwith each other, and the sense of \nuse of intelligent operation\
    \ is poor\nThe Internet of Things giant has \nformed a monopoly and the \nmarket\
    \ competition is insufficient\n \nFigure 18. The status quo of the Internet of\
    \ Things operating system. \nThe current Internet of Things operating system has\
    \ made great progress [80]. Inter-\nnet of Things operating system brands, and\
    \ complementary compatibility, restrict the \ngreat development of the Internet\
    \ of Things. In order to achieve the goal of the Internet of \neverything in the\
    \ 5G scenario, its operating system will need to change in the future. \nA typical\
    \ IoT system is shown in the following Figure 19. Among them, the operating \n\
    system is an important middle part applied to the bottom layer, which is related\
    \ to the \nkey to cloud interconnection and is the key to realizing the seamless\
    \ interaction between \npeople and things. Future IoT operating system requirements\
    \ are shown in Figure 20. \nAgentTiny\nLiteOS\nMCU\nCloud\nDevice\nOceanConnet\
    \ \nIoT Platform\nOther IoT \nPlatform\n \nFigure 19. Huawei 5G IoT system. \n\
    Cross \nplatform\nInteroperabi\nlity\nlow cost\nStrong \nsecurity\nCloud\nHeterogeneous\
    \ \nterminal\n \nFigure 20. Future IoT operating system requirements. \nMany scholars\
    \ have conducted many beneficial studies on the operating system of \nthe Internet\
    \ of Things [81,82], mostly for applications, real-time scheduling, kernel design,\
    \ \nand so on. Less attention is paid to the architecture of future sensor operating\
    \ systems. It \nsummarized the current major IoT operating systems in Table 7.\
    \ In the future, under the \ncondition that the data bandwidth is satisfied, highly\
    \ intelligent is the due connotation of \nsmart agriculture. The concept of a\
    \ sensor node is more general, as there is not only a \nFigure 18. The status\
    \ quo of the Internet of Things operating system.\nThe current Internet of Things\
    \ operating system has made great progress [80]. Internet\nof Things operating\
    \ system brands, and complementary compatibility, restrict the great\ndevelopment\
    \ of the Internet of Things. In order to achieve the goal of the Internet of\n\
    everything in the 5G scenario, its operating system will need to change in the\
    \ future.\nA typical IoT system is shown in the following Figure 19. Among them,\
    \ the operating\nsystem is an important middle part applied to the bottom layer,\
    \ which is related to the key\nto cloud interconnection and is the key to realizing\
    \ the seamless interaction between people\nand things. Future IoT operating system\
    \ requirements are shown in Figure 20.\nThe connection volume \nof IoT equipment\
    \ has \nreached 10 billion\nSoftware and hardware \ncoupling is seriously lagging\
    \ \nbehind the industry \nstandard\nThe R&D cycle of the \noperating system is\
    \ 4-\n5 years\nThe cost of software development \nand system integration R&D of\
    \ a \nsingle SKU is more than 300000 \ndollars\nMany terminals\nSystem mismatch\n\
    Long R&D cycle\nHigh R&D cost\nMany brands\nIncompatible\nThe products cannot\
    \ be linked \nwith each other, and the sense of \nuse of intelligent operation\
    \ is poor\nThe Internet of Things giant has \nformed a monopoly and the \nmarket\
    \ competition is insufficient\n \nFigure 18. The status quo of the Internet of\
    \ Things operating system. \nThe current Internet of Things operating system has\
    \ made great progress [80]\nnet of Things operating system brands, and complementary\
    \ compatibility, restr\ngreat development of the Internet of Things. In order\
    \ to achieve the goal of the Inte\neverything in the 5G scenario, its operating\
    \ system will need to change in the futur\nA typical IoT system is shown in the\
    \ following Figure 19. Among them, the ope\nsystem is an important middle part\
    \ applied to the bottom layer, which is related\nkey to cloud interconnection\
    \ and is the key to realizing the seamless interaction be\npeople and things.\
    \ Future IoT operating system requirements are shown in Figure\nAgentTiny\nLiteOS\n\
    MCU\nCloud\nDevice\nOceanConnet \nIoT Platform\nOther IoT \nPlatform\n \nFigure\
    \ 19. Huawei 5G IoT system. \nCross \nplatform\nInteroperabi\nlity\nlow cost\n\
    Strong \nsecurity\nCloud\nHeterogeneous \nterminal\n \nFigure 20. Future IoT operating\
    \ system requirements. \nMany scholars have conducted many beneficial studies\
    \ on the operating sys\nthe Internet of Things [81,82], mostly for applications,\
    \ real-time scheduling, kernel d\nand so on. Less attention is paid to the architecture\
    \ of future sensor operating syst\nsummarized the current major IoT operating\
    \ systems in Table 7. In the future, und\ncondition that the data bandwidth is\
    \ satisfied, highly intelligent is the due connota\nsmart agriculture. The concept\
    \ of a sensor node is more general, as there is not \nFigure 19. Huawei 5G IoT\
    \ system.\nThe connection volume \nof IoT equipment has \nreached 10 billion\n\
    Software and hardware \ncoupling is seriously lagging \nbehind the industry \n\
    standard\nThe R&D cycle of the \noperating system is 4-\n5 years\nThe cost of\
    \ software development \nand system integration R&D of a \nsingle SKU is more\
    \ than 300000 \ndollars\nMany terminals\nSystem mismatch\nLong R&D cycle\nHigh\
    \ R&D cost\nMany brands\nIncompatible\nThe products cannot be linked \nwith each\
    \ other, and the sense of \nuse of intelligent operation is poor\nThe Internet\
    \ of Things giant has \nformed a monopoly and the \nmarket competition is insufficient\n\
    \ \nFigure 18. The status quo of the Internet of Things operating system. \nThe\
    \ current Internet of Things operating system has made great progress [80]\nnet\
    \ of Things operating system brands, and complementary compatibility, restr\n\
    great development of the Internet of Things. In order to achieve the goal of the\
    \ Inte\neverything in the 5G scenario, its operating system will need to change\
    \ in the futur\nA typical IoT system is shown in the following Figure 19. Among\
    \ them, the ope\nsystem is an important middle part applied to the bottom layer,\
    \ which is related\nkey to cloud interconnection and is the key to realizing the\
    \ seamless interaction be\npeople and things. Future IoT operating system requirements\
    \ are shown in Figure\nAgentTiny\nLiteOS\nMCU\nCloud\nDevice\nOceanConnet \nIoT\
    \ Platform\nOther IoT \nPlatform\n \nFigure 19. Huawei 5G IoT system. \nCross\
    \ \nplatform\nInteroperabi\nlity\nlow cost\nStrong \nsecurity\nCloud\nHeterogeneous\
    \ \nterminal\n \nFigure 20. Future IoT operating system requirements. \nMany scholars\
    \ have conducted many beneficial studies on the operating sys\nthe Internet of\
    \ Things [81,82], mostly for applications, real-time scheduling, kernel d\nand\
    \ so on. Less attention is paid to the architecture of future sensor operating\
    \ syst\nsummarized the current major IoT operating systems in Table 7. In the\
    \ future, und\ncondition that the data bandwidth is satisfied, highly intelligent\
    \ is the due connota\nsmart agriculture. The concept of a sensor node is more\
    \ general, as there is not \nFigure 20. Future IoT operating system requirements.\n\
    Many scholars have conducted many beneﬁcial studies on the operating system of\n\
    the Internet of Things [81,82], mostly for applications, real-time scheduling,\
    \ kernel design,\nand so on. Less attention is paid to the architecture of future\
    \ sensor operating systems. It\nsummarized the current major IoT operating systems\
    \ in Table 7. In the future, under the\nElectronics 2023, 12, 2336\n20 of 46\n\
    condition that the data bandwidth is satisﬁed, highly intelligent is the due connotation\n\
    of smart agriculture. The concept of a sensor node is more general, as there is\
    \ not only a\nsingle perception function but it may also have an executive function,\
    \ etc., based on edge\ncomputing, etc., to achieve node interoperability.\nTable\
    \ 7. List of IoT operating systems.\nIoT OS\nDescription/Provider\nNetworked Operating\
    \ System\nDescription/Provider\nBrillo [80]\nGoogle’s solution for building\n\
    connected devices\nLiteOS\nHuawei\nmbedOS\nARM Internet of Things device platform\n\
    TinyOS\nTencent\nRIoT [83]\nInternet of Things friendly operating system\nAliOS\
    \ Things\nAlibaba\nContiki [84]\nOpen source IoT operating system\nRT-Thread\n\
    Real time operating\nsystem (open source)\nZephyr\nScalable real-time operating\
    \ system for\nresource constrained systems\nWindows 10 IoT Core\nWindows\nNuttx\n\
    Standard compliant and small footprint\nreal-time operating system\nWatchOS\n\
    Apple\nWith an IoT operating system, from service connection to service application,\
    \ the\nultimate goal is service intelligence. In smart agriculture, with a 5G\
    \ scenario, the operating\nsystem of the Internet of Things also needs to serve\
    \ smart agriculture. Fuchsia OS and\nHarmony OS were developed by Google and Huawei.\
    \ The goal is to be able to run on a\nvariety of different hardware platforms,\
    \ with distributed operating systems based on the\nmicrokernel structure and running\
    \ more efﬁciently.\n3.2.3. Large-Scale Terminal Access of 5G Smart Agricultural\
    \ Monitoring Terminals\nA large number of sensing devices will be deployed in\
    \ the smart agricultural IoT for\nbreeding moisture monitoring, ﬁne agriculture,\
    \ and other scenarios. How to access massive\nterminals in LPWA for 5G low-power\
    \ wide area networks [85] is a challenging problem.\nWith the continuous improvement\
    \ of the capabilities of the air interface at the access end,\nthe performance\
    \ bottleneck of the whole system is gradually reﬂected in the core end, edge\n\
    end, and other areas. Therefore, there must also be corresponding innovative technologies\n\
    at the core or edge end to meet the nearly demanding requirements of 5G IoT applications\n\
    in the future [86]. However, the existing cellular network core architecture is\
    \ not suitable\nfor the development of the Internet of Things.\nThe deployment\
    \ of 5G has created the possibility for large-scale and intensive IoT\ndeployment,\
    \ but there are also challenges concerning reliable access and data transmission\n\
    and processing, as shown in Figure 21.\n3.3. Reliable Data-Driven Detection of\
    \ 5G Smart Agricultural IoT\nBased on the various kinds of data acquired by the\
    \ massive sensing devices, they can\nbe detected and processed to serve the upper-layer\
    \ applications. These acquired termi-\nnal underlying data can be used to detect\
    \ complex events in the process of agricultural\nproduction, provide intelligent\
    \ decision-making for smart agricultural production, im-\nproving the degree of\
    \ intelligence. Secondly, based on the breakthrough of current data\nvolume acquisition,\
    \ the breakthrough of machine learning algorithms, and the innovation\nof communication\
    \ technology, all kinds of image processing based on machine learning\nare gradually\
    \ popularized in smart agriculture. These lay the foundation for intelligent\n\
    agricultural production.\nElectronics 2023, 12, 2336\n21 of 46\n3.3.1. Complex\
    \ Event Detection in Agricultural Production\nComplex event detection for agricultural\
    \ production process [87]. Complex event\ndetection abstracts business data into\
    \ a sequence of events. Through the complex event\ndescription method, the potentially\
    \ valuable composite data are described as a speciﬁc\nevent-matching structure.\
    \ The complex event detection engine then detects the event\nsequence satisfying\
    \ the matching structure from a large number of event streams and\nﬁnally outputs\
    \ the data fusion results. The basic strategy of the event detection engine is\n\
    that all Events in the time window are called candidate Events, and the candidate\
    \ Events\ngenerate Matching sets according to the rules.\nectronics 2023, 12,\
    \ x FOR PEER REVIEW \nSupplier\nWarehouse\nCLOUD\n \nFigure 21. 5G large-scale\
    \ access of smart agricultural Internet of Things perce\n3.3. Reliable Data-Driven\
    \ Detection of 5G Smart Agricultural IoT \nBased on the various kinds of data\
    \ acquired by the massive sensin\nbe detected and processed to serve the upper-layer\
    \ applications. Thes\nunderlying data can be used to detect complex events in\
    \ the process \nduction, provide intelligent decision-making for smart agricultural\
    \ p\ning the degree of intelligence. Secondly, based on the breakthrough \nume\
    \ acquisition, the breakthrough of machine learning algorithms, an\ncommunication\
    \ technology, all kinds of image processing based on m\ngradually popularized\
    \ in smart agriculture. These lay the foundation\ncultural production. \n3.3.1.\
    \ Complex Event Detection in Agricultural Production \nComplex event detection\
    \ for agricultural production process [87]\ntection abstracts business data into\
    \ a sequence of events. Through the\nscription method, the potentially valuable\
    \ composite data are des\nFigure 21. 5G large-scale access of smart agricultural\
    \ Internet of Things perception terminal.\nThese data can be multimodal structural\
    \ and unstructured types of data. They are\nwidely used in smart agriculture scenarios.\
    \ When the sensing data are rich enough, the\ncomplex event rules can be established\
    \ through various moisture data and crop growth\nmodels to determine whether drip\
    \ irrigation and fertilization are needed [88,89]. In ﬁsh\nfarming, data collected\
    \ by various sensor devices deployed in ponds are used to determine\nwhether there\
    \ is a lack of oxygen or other complex events, and so on.\nThe detection conditions\
    \ of complex events ﬁrstly need rich physical world data, and\nenough sensing\
    \ devices need to be deployed so that various relationships can be discovered.\n\
    Second, complex computational processing power is required. For pattern matching\
    \ and\nso on, we need quick calculation and judgment. In addition, some complex\
    \ event detection\nis real-time, and these requirements become feasible with 5G.\n\
    3.3.2. Depth Detection of Pests and Diseases Based on Machine Learning\nWith the\
    \ development of information technology, methods based on machine learning\nhave\
    \ been widely used in agricultural production in recent years. Many scholars combine\n\
    image processing with pattern recognition, and widely use it in crop disease and\
    \ pest\nrecognition. The color, shape, texture, and other parameters extracted\
    \ were screened and\noptimized. The linear classiﬁer, Bayesian decision theory,\
    \ fuzzy recognition, and other\npattern recognition techniques were used to identify\
    \ and classify various crop pests and\nElectronics 2023, 12, 2336\n22 of 46\n\
    diseases, which improved the recognition accuracy. Thus, the development of agricultural\n\
    informatization and precision was further promoted [90].\nAs an important branch\
    \ of machine learning, deep learning network is becoming\na hot technology with\
    \ its powerful data analysis ability. Deep learning networks can\ncontain hundreds\
    \ of hidden layers, and the features will be transformed a lot of times.\nDeep\
    \ learning can be applied to identify crop pests and disease targets. For achieving\n\
    the relationship ﬁtting of complex sample data, the core idea is not only to automatically\n\
    extract multi-layer feature representations from a large amount of data through\
    \ a variety of\nlinear and nonlinear transformations but also to complete the\
    \ task of feature extraction and\ntransformation using supervised and unsupervised\
    \ combined training methods [91]. Due\nto the structure of a deep neural network,\
    \ the error features extracted by the previous layer\nnetwork can be weakened\
    \ to a certain extent, and the complex function can be expressed\nwith fewer parameters.\
    \ The structure of the deep neural network will be more compact,\nwhich improves\
    \ the efﬁciency and performance of the network.\nIt is obvious that the current\
    \ methods with strong pattern recognition ability are\nparticularly dependent\
    \ on a large amount of data, which requires enough data to draw\nuseful conclusions.\
    \ The traditional agricultural IoT data are limited, which is challenging to\n\
    support the data collection needs of future smart agriculture development. The\
    \ introduction\nof 5G and smart agricultural IoT provides conditions for the collection\
    \ of massive data.\n3.4. Cloud Edge Fog Computing Fusion in 5G Intelligent Agricultural\
    \ Internet of Things\nIn future smart agricultural IoT, data will be extremely\
    \ abundant, and how to conduct\nanalysis and calculation from these data to guide\
    \ modern agricultural production is an\nimportant challenge.\nDue to the limitations\
    \ of volume and battery life, many mobile devices deployed in\nagricultural production\
    \ cannot meet the requirements of these applications in terms of\ncomputing, storage,\
    \ energy, and other resources. Therefore, Mobile Cloud Computing\n(MCC) technology\
    \ has been proposed. It provides reorganized computing resources for\nmobile devices\
    \ in the cloud platform, migrates data processing and storage to the cloud,\n\
    and reduces constraints on its own resources. With the development of smart agriculture,\n\
    massive data will be generated in the future to be analyzed, processed, and stored\
    \ in the\ncentral cloud [92]. At the same time, there may be a large number of\
    \ connections between\nsensing devices, and these MCCS cannot meet the demand.\
    \ New computing methods, such\nas edge computing and fog computing, will be integrated\
    \ into the intelligent agricultural\nIoT system [93]. Edge sensors no longer need\
    \ to continuously transmit various sensing\ndata to the data center. It can judge\
    \ the sensing data on its own, contacting the data center\nonly when there is\
    \ a signiﬁcant change in the reading to decide what action to take. Cloud\ncomputing\
    \ is suitable for non-real-time, long-period data, and business decision scenarios,\n\
    while edge computing plays an irreplaceable role in real-time, short-period data,\
    \ and local\ndecision-making. Edge computing and cloud computing are two important\
    \ supports for\nthe digital transformation of the industry. Their collaboration\
    \ in the network, business,\napplication, intelligence, and other aspects will\
    \ help support the agricultural IoT to create\ngreater value. Intelligent edge\
    \ computing based on 5G power can use the cloud for large-\nscale security conﬁguration,\
    \ deployment, the management of edge devices, and the ability\nto assign intelligence\
    \ based on device type and scenario, allowing intelligence to ﬂow\nbetween the\
    \ cloud and the edge. The edge computing model in smart agriculture is shown\n\
    in Figure 22.\nSecondly, with the continuous enrichment of data in smart agricultural\
    \ IoT, the tra-\nditional forms of computing will become richer and richer. Distributed\
    \ computing based\non cloud computing, fog computing, and other forms will be\
    \ deeply integrated with 5G\ncommunication capabilities and applied to smart agriculture.\
    \ Agriculture, for wisdom in\ngreenhouse cultivation, oriented precision fertilization,\
    \ aquaculture, animal husbandry,\nand aquaculture, the scene such as plant monitoring,\
    \ needs the edge of the Internet of\nThings system IoT terminal according to the\
    \ scientiﬁc planting and breeding, fertilizers\nElectronics 2023, 12, 2336\n23\
    \ of 46\nand other professional industry model, implement local sampling, local\
    \ operations, and\nlocal decisions at the same time, according to the requirement\
    \ of the center’s continuously\nupdated mathematical model and iteration. Therefore,\
    \ the intelligent Internet of Things\nterminal should be based on the requirements\
    \ of fog computing and edge computing\narchitecture, rely on the machine learning\
    \ and algorithm training of cloud computing\ncenter, complete, reliable real-time\
    \ deep computing, accurately control on-site facilities and\nequipment, and achieve\
    \ the purpose of scientiﬁc planting and breeding.\nFigure 22. Smart agriculture\
    \ edge computing model.\n3.5. 5G Intelligent Agricultural IoT In-Depth Service\n\
    The intelligent Internet of Things platform under the 5G will provide personalized,\n\
    customized, and in-depth services for agriculture. The smart agriculture IoT big\
    \ data\nservice platform is shown in Figure 23.\nFigure 23. Smart agriculture\
    \ Internet of Things service platform.\nBased on the power of 5G and the improvement\
    \ of computing power and storage\ncapacity, combined with the latest service platform\
    \ architecture SaaS, PaaS, IaaS, etc., the\nservices of smart agriculture will\
    \ be extremely friendly and convenient. By shielding the\nunderlying details,\
    \ users will be provided with QoS humanized services, as shown in\nFigure 24.\n\
    Electronics 2023, 12, 2336\n24 of 46\nnics 2023, 12, x FOR PEER REVIEW \n23 of\
    \ 46 \nApplication \nlayer SaaS\nIrrigat\nion \nAPP\nInsect \nmonitoring \nAPP\n\
    Moisture \nanalysis\nWeather \nanalysis\nIntelligent operation and \nmaintenance\
    \ of \nagricultural machinery\nPlatform layer \nPaaS\nFacility layer \nIaaS\n\
    Marginal \nlayer\nEquipmen\nt access\nProtocol \nresolution\nEdge data \nprocessing\n\
    Cloud infrastructure (server, storage, network, virtualization)\nAgricultural\
    \ data modeling, calculation and analysis (mechanism modeling, machine \nlearning,\
    \ visualization)\nAgricultural big data system (Data cleaning, Filling, Matching,\
    \ Management, Analysis, \nVisualization, etc.)\nEquipment Management Resource\
    \ Management Operation and Maintenance \nManagement Fault Diagnosis\nEdge data\
    \ \nprocessing\nEdge data \nprocessing\nBusiness \noperation\n \nFigure 24. 5G\
    \ smart agriculture Internet of Things service. \nConcerning 5G, the Internet,\
    \ the Internet of Things, big data and cloud computing, \nartificial intelligence,\
    \ and other modern information technology and agricultural depth \nfusion, the\
    \ implementation of agricultural information perception and quantitative deci-\n\
    sion-making, intelligent control, accurate, and personalized service, the new\
    \ way of agri-\ncultural production is the agricultural informationization development\
    \ from the ad-\nvanced stage of digital to network and intelligent. \n3.6. 5G\
    \ Intelligent Agricultural IoT Production Intelligent Control \nThe application\
    \ of intelligent agricultural IoT based on 5G is bound to involve pro-\nduction\
    \ control, and control of various agricultural machinery such as irrigation and\
    \ \nspraying [94]. The innate advantages of 5G have innate advantages for the\
    \ control of smart \nagriculture—mainly low delay, high bandwidth, and other technical\
    \ characteristics, as \nshown in Figure 25. \nBreeding\nGrow \nseedlings\nPick\n\
    Grafting\nSpray\nWeed\nFarming\nSpray\nOxygenati\non\nSunshade\nSunshade\nReliability\n\
    High \nbandwidth\nLow delay\n5G\n5G\nScene\n \nFigure 25. 5G of intelligent control\
    \ of intelligent agriculture production. \nFor example, a project uses drones\
    \ to take photos of farmland, and the raw data will \nbe transmitted to the cloud\
    \ via 5G network for real-time data analysis and identification. \nThe results\
    \ can then be re-matched to the field, and a tractor or farm robot, guided by\
    \ GPS, \ncan then navigate to the area where the weeds are growing and carry out\
    \ precise removal. \nThis could reduce pesticide use by up to 90 percent, with\
    \ the possibility of replacing pes-\nticides with hot water to remove weeds later.\
    \ Neural networks and self-learning algo-\nrithms make plant identification more\
    \ and more accurate, but they also generate a lot of \nFigure 24. 5G smart agriculture\
    \ Internet of Things service.\nConcerning 5G, the Internet, the Internet of Things,\
    \ big data and cloud computing,\nartiﬁcial intelligence, and other modern information\
    \ technology and agricultural depth\nfusion, the implementation of agricultural\
    \ information perception and quantitative decision-\nmaking, intelligent control,\
    \ accurate, and personalized service, the new way of agricultural\nproduction\
    \ is the agricultural informationization development from the advanced stage of\n\
    digital to network and intelligent.\n3.6. 5G Intelligent Agricultural IoT Production\
    \ Intelligent Control\nThe application of intelligent agricultural IoT based on\
    \ 5G is bound to involve pro-\nduction control, and control of various agricultural\
    \ machinery such as irrigation and\nspraying [94]. The innate advantages of 5G\
    \ have innate advantages for the control of smart\nagriculture—mainly low delay,\
    \ high bandwidth, and other technical characteristics, as\nshown in Figure 25.\n\
    Electronics 2023, 12, x FOR PEER REVIEW \n23 of 46\n \nApplication \nlayer SaaS\n\
    Irrigat\nion \nAPP\nInsect \nmonitoring \nAPP\nMoisture \nanalysis\nWeather \n\
    analysis\nIntelligent operation and \nmaintenance of \nagricultural machinery\n\
    Platform layer \nPaaS\nFacility layer \nIaaS\nMarginal \nlayer\nEquipmen\nt access\n\
    Protocol \nresolution\nEdge data \nprocessing\nCloud infrastructure (server, storage,\
    \ network, virtualization)\nAgricultural data modeling, calculation and analysis\
    \ (mechanism modeling, machine \nlearning, visualization)\nAgricultural big data\
    \ system (Data cleaning, Filling, Matching, Management, Analysis, \nVisualization,\
    \ etc.)\nEquipment Management Resource Management Operation and Maintenance \n\
    Management Fault Diagnosis\nEdge data \nprocessing\nEdge data \nprocessing\nBusiness\
    \ \noperation\n \nFigure 24. 5G smart agriculture Internet of Things service.\
    \ \nConcerning 5G, the Internet, the Internet of Things, big data and cloud computing\n\
    artificial intelligence, and other modern information technology and agricultural\
    \ depth\nfusion, the implementation of agricultural information perception and\
    \ quantitative deci-\nsion-making, intelligent control, accurate, and personalized\
    \ service, the new way of agri-\ncultural production is the agricultural informationization\
    \ development from the ad-\nvanced stage of digital to network and intelligent.\
    \ \n3.6. 5G Intelligent Agricultural IoT Production Intelligent Control \nThe\
    \ application of intelligent agricultural IoT based on 5G is bound to involve\
    \ pro-\nduction control, and control of various agricultural machinery such as\
    \ irrigation and\nspraying [94]. The innate advantages of 5G have innate advantages\
    \ for the control of smart\nagriculture—mainly low delay, high bandwidth, and\
    \ other technical characteristics, as\nshown in Figure 25. \nBreeding\nGrow \n\
    seedlings\nPick\nGrafting\nSpray\nWeed\nFarming\nSpray\nOxygenati\non\nSunshade\n\
    Sunshade\nReliability\nHigh \nbandwidth\nLow delay\n5G\n5G\nScene\n \nFigure 25.\
    \ 5G of intelligent control of intelligent agriculture production. \nFor example,\
    \ a project uses drones to take photos of farmland, and the raw data will\nbe\
    \ transmitted to the cloud via 5G network for real-time data analysis and identification\n\
    The results can then be re-matched to the field, and a tractor or farm robot,\
    \ guided by GPS\ncan then navigate to the area where the weeds are growing and\
    \ carry out precise removal\nThis could reduce pesticide use by up to 90 percent,\
    \ with the possibility of replacing pes-\nticides with hot water to remove weeds\
    \ later. Neural networks and self-learning algo-\nrithms make plant identification\
    \ more and more accurate, but they also generate a lot of\nFigure 25. 5G of intelligent\
    \ control of intelligent agriculture production.\nFor example, a project uses\
    \ drones to take photos of farmland, and the raw data will be\ntransmitted to\
    \ the cloud via 5G network for real-time data analysis and identiﬁcation. The\n\
    results can then be re-matched to the ﬁeld, and a tractor or farm robot, guided\
    \ by GPS, can\nthen navigate to the area where the weeds are growing and carry\
    \ out precise removal. This\ncould reduce pesticide use by up to 90 percent, with\
    \ the possibility of replacing pesticides\nwith hot water to remove weeds later.\
    \ Neural networks and self-learning algorithms make\nElectronics 2023, 12, 2336\n\
    25 of 46\nplant identiﬁcation more and more accurate, but they also generate a\
    \ lot of data. Therefore,\nthe combination of 5G and other technologies is crucial\
    \ to the success of this innovation\nproject [95,96].\n4. Revolution of Smart\
    \ Agricultural IoT Application Paradigm under 5G\n4.1. Typical Application Scenarios\
    \ of 5G Smart Agricultural IoT\nThe development of 5G network will provide the\
    \ infrastructure needed for smart\nagriculture for agricultural production. The\
    \ main application scenarios include the follow-\ning aspects.\n4.1.1. Smart Farm\n\
    The two characteristics of 5G network, high speed and large connection, will help\n\
    the agricultural industry implement large-scale machine services. Centralized\
    \ control\nof environmental sensors, planters, UAVs, and other monitoring equipment\
    \ and real-\ntime data transmission. Finally, the purpose of intensive farming,\
    \ accurate fertilization,\nand reasonable irrigation is achieved [97]. Agricultural\
    \ machinery automatic agricultural\nmachinery equipment based on 5G was integrated\
    \ to achieve rapid, large-area, efﬁcient,\nand precise spraying operation [98].\n\
    4.1.2. Smart Forestry\nSmart forestry utilizes 5G network video, UAV, and other\
    \ monitoring equipment to\ncarry out forest inspection, realize the monitoring\
    \ of forest resources, forest pests and\ndiseases, wild animals and plants, forest\
    \ ﬁre prevention, and provide guide and rescue\nservices for staff and tourists\
    \ [99].\n4.1.3. Intelligent Animal Husbandry\n5G intelligent animal husbandry\
    \ can improve the production efﬁciency of animal\nhusbandry, reduce the cost of\
    \ breeding, prevent livestock epidemic and livestock loss, and\nprotect animal\
    \ husbandry ecology [100,101]. For example, the use of 5G drone technology,\n\
    wearing 5G terminals on the necks of cows, and the use of Internet of Things technology\
    \ to\nmanage yaks have brought great changes to the traditional herding work of\
    \ plateau herders.\n4.1.4. Smart Fishing Ground\n5G smart ﬁshing grounds use monitoring\
    \ equipment such as high-deﬁnition net-\nwork cameras and underwater camera systems\
    \ to carry out real-scene monitoring, aquatic\nproduct growth monitoring, and\
    \ precise bait casting to improve the safety of underwater\noperations and save\
    \ labor costs [102]. In the Marine ranch, 5G panoramic monitoring appli-\ncation\
    \ is realized through 5G coverage. The panoramic high-deﬁnition camera equipment\n\
    and 5G underwater camera system were set up to realize the 24-h panoramic monitoring\
    \ of\nthe ranch. Managers can observe the growth of aquatic products, including\
    \ underwater\nobservation, from their ofﬁces or homes through mobile phones [103].\
    \ Based on 5G technol-\nogy, the intelligent control of the production process\
    \ of Marine cash crops, including kelp\nand other seedlings, can also be realized,\
    \ making it possible to have unmanned Marine\nranching.\n4.2. Deep Sense of 5G\
    \ Smart Agriculture\n4.2.1. Agricultural 5G Image Processing\nIn smart agriculture,\
    \ a large number of scenes need to realize monitoring or identiﬁ-\ncation and\
    \ detection of various targets. With the rapid development of machine learning\n\
    technology in image processing, many problems in agriculture can be solved by\
    \ video\nmonitoring and image detection. This paper summarizes the typical application\
    \ scenarios\nof agricultural image processing, as shown in Figure 26. It mainly\
    \ includes three categories:\nplant pest and disease identiﬁcation [104,105],\
    \ crop growth analysis and detection [106],\nand livestock and aquaculture monitoring\
    \ [107,108]. Each category is divided into many\nElectronics 2023, 12, 2336\n\
    26 of 46\nspeciﬁc problems. The core mode is to collect image data and then combine\
    \ data with\nan artiﬁcial intelligence machine learning algorithm to train the\
    \ model and then detect\nthe model.\ntechnology in image processing, many problems\
    \ in agriculture can be sol\nmonitoring and image detection. This paper summarizes\
    \ the typical applica\nof agricultural image processing, as shown in Figure 26.\
    \ It mainly includes\nries: plant pest and disease identification [104,105], crop\
    \ growth analysis \n[106], and livestock and aquaculture monitoring [107,108].\
    \ Each category i\nmany specific problems. The core mode is to collect image data\
    \ and then \nwith an artificial intelligence machine learning algorithm to train\
    \ the mode\ntect the model. \nAgricultural image \nprocessing\nIdentification\
    \ of plant \ndiseases and pests\nCrop analysis and \ndetection\nLivestock and\
    \ aquatic \nproducts monitoring\n▪ 1.Fungal diseases\n▪ 2.Citrus diseases\n▪ 3.Grapevine\
    \ diseases\n▪ 4.Detection of citrus spider \nand aphid\n▪ 5.Corn crop diseases\n\
    ▪ 6.Pumpkin disease\n▪ 7.Rice disease\n▪ 8.Identification of \nSpodoptera gracilis\
    \ \n▪ 9.Apple leaf disease\n▪ 1.Crop detection\n▪ 2.Crop row detection\n▪ 3.Smart\
    \ Farm\n▪ 4.Yield detection\n▪ 5.Tomato maturity \ndetection\n▪ 6.Weed detection\n\
    ▪ 7.Ear detection\n▪ 8.Grapefruit shape \ndetection\n▪ 9.Phenotype detection of\
    \ \nbroccoli\n▪ 1.Pig behavior monitoring\n▪ 2.Behavior monitoring of \nwhite\
    \ feather chickens\n▪ 3.Oestrus monitoring of \ndairy cows\n▪ 4.Fish growth monitoring\n\
    ▪ 5.Monitoring of bovine \nprotein content\n▪ 6.Floating feed monitoring\n▪ 7.Feeding\
    \ behavior \nmonitoring\n▪ 8.Bullfrog behavior \nmonitoring\n▪ 9.Monitoring of\
    \ water fly \nbreeding\n▪ 10.Underwater monitoring \nof cage culture\n \nFigure\
    \ 26. Image processing in agriculture. \nWith the popularity of high-definition\
    \ cameras, more images need to b\nin agricultural IoT. The transmission of these\
    \ high-definition images poses a\nthe network. Second, many scenarios require\
    \ real-time detection and proces\npopularity of 5G technology, the effective transmission\
    \ and real-time proce\nand image big data can be realized by building a 5G-oriented\
    \ heterogeneo\nThings. \n4.2.2. Agricultural Intelligence Detection Based Machine\
    \ Learning \nThe development of artificial intelligence machine learning has brough\n\
    tunities for smart agriculture. Many researchers have conducted a great de\nby\
    \ combining machine learning algorithms. The main goal of machine learn\ncation\
    \ and detection [109,110]. In agricultural application scenarios, mac\nmainly\
    \ realizes agricultural sensing data, including video, image, text, and\nmodal\
    \ data, and trains models for data detection. The following figure show\nmodel\
    \ processed by machine learning, as shown in Figure 27. \nFigure 26. Image processing\
    \ in agriculture.\nWith the popularity of high-deﬁnition cameras, more images\
    \ need to be transmitted\nin agricultural IoT. The transmission of these high-deﬁnition\
    \ images poses a challenge for\nthe network. Second, many scenarios require real-time\
    \ detection and processing. With\nthe popularity of 5G technology, the effective\
    \ transmission and real-time processing of\nvideo and image big data can be realized\
    \ by building a 5G-oriented heterogeneous Internet\nof Things.\n4.2.2. Agricultural\
    \ Intelligence Detection Based Machine Learning\nThe development of artiﬁcial\
    \ intelligence machine learning has brought new opportu-\nnities for smart agriculture.\
    \ Many researchers have conducted a great deal of research by\ncombining machine\
    \ learning algorithms. The main goal of machine learning is classiﬁcation\nand\
    \ detection [109,110]. In agricultural application scenarios, machine learning\
    \ mainly\nrealizes agricultural sensing data, including video, image, text, and\
    \ other multi-modal\ndata, and trains models for data detection. The following\
    \ ﬁgure shows the general model\nprocessed by machine learning, as shown in Figure\
    \ 27.\nHowever, the autonomous training model is limited by the resources and\
    \ computing\npower of the sensing device, and the effect is not always ideal.\
    \ At present, there are many\nopen-source deep learning platforms for artiﬁcial\
    \ intelligence, which can optimize model\ntraining and provide detection accuracy\
    \ with the help of platform capabilities. The open\nAI deep learning platform\
    \ is shown in Figure 28.\nElectronics 2023, 12, 2336\n27 of 46\ntronics 2023,\
    \ 12, x FOR PEER REVIEW \n26 of \nData \nset\nData \nprep\nroce\nssin\ng\nData\
    \ \ncleaning\nData \nconversion\nData filling\nTraini\nng \ndata\nTest \ndata\n\
    Training \nmodel\nTest \nmodel\nModel\nEvaluation \noptimization\nDeploy\nAgricultural\
    \ \nsense data\n \nFigure 27. An agricultural intelligence detection framework\
    \ for machine learning. \nHowever, the autonomous training model is limited by\
    \ the resources and computi\npower of the sensing device, and the effect is not\
    \ always ideal. At present, there are ma\nopen-source deep learning platforms\
    \ for artificial intelligence, which can optimize mod\ntraining and provide detection\
    \ accuracy with the help of platform capabilities. The op\nAI deep learning platform\
    \ is shown in Figure 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba\
    \ DTPAI\nBaidu BML\nAmazon ML\nGoogle Cloud \nPlatform\nMahout\nHadoop\nSpark\n\
    GraphLab\nMPICH 2\nDMLC\nPetuum\n \nFigure 28. Open artificial intelligence deep\
    \ learning platform. \nDeep learning is an important branch of machine learning.\
    \ It can automatically an\nefficiently extract target features and recognize targets\
    \ through model training. The app\ncation of deep learning technology combined\
    \ with image processing to the recognition\ncrop diseases and insect pests is\
    \ an inevitable trend in the future development of precisi\nagriculture. The performance\
    \ of deep learning networks is very dependent on data se\nHigh quality, high correlation,\
    \ complete annotation, and large-scale agricultural data se\nare of great significance\
    \ for model training. In the application of crop disease and pe\nrecognition,\
    \ in addition to color images taken by cameras and mobile phones of sensi\ndevices,\
    \ multimodal agricultural data such as hyperspectral, near-infrared, and infrar\n\
    images are becoming a trend, and their acquisition provides support for model\
    \ trainin\nas shown in Figure 29. In addition to publicly available data sets,\
    \ an important source f\ndata set sources is self-collection. However, it is very\
    \ difficult to collect graphs of cr\ndiseases and insect pests, and there are\
    \ some problems, such as page occlusion and victi\narea concealment, which require\
    \ multi-angle sensing equipment to collect at the who\ntime, which requires a\
    \ large amount of data collection and transmission. Based on 5\nhigh-speed transmission\
    \ of data from terminal sensing nodes to the platform can be re\nized, real-time\
    \ detection of data can be realized, and the degree of intelligence can be e\n\
    panded [111]. \nCamera\nVideo\nIR/NIR\n5G\nAgricultural \nimage data set \nplatform\n\
    Training \nmodel\nApplication \nplatform\nFigure 27. An agricultural intelligence\
    \ detection framework for machine learning.\nData \nset\nData \nprep\nroce\nssin\n\
    g\nData \ncleaning\nData \nconversion\nData filling\nTraini\nng \ndata\nTest \n\
    data\ng\nmodel\nTest \nmodel\nModel\nEvaluation \noptimization\nDeploy\nral \n\
    ta\n \nFigure 27. An agricultural intelligence detection framework for machine\
    \ learning. \nHowever, the autonomous training model is limited by the resources\
    \ and computing \npower of the sensing device, and the effect is not always ideal.\
    \ At present, there are many \nopen-source deep learning platforms for artificial\
    \ intelligence, which can optimize model \ntraining and provide detection accuracy\
    \ with the help of platform capabilities. The open \nAI deep learning platform\
    \ is shown in Figure 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba\
    \ DTPAI\nBaidu BML\nAmazon ML\nGoogle Cloud \nPlatform\nMahout\nHadoop\nSpark\n\
    GraphLab\nMPICH 2\nDMLC\nPetuum\n \nFigure 28. Open artificial intelligence deep\
    \ learning platform. \nDeep learning is an important branch of machine learning.\
    \ It can automatically and \nefficiently extract target features and recognize\
    \ targets through model training. The appli-\ncation of deep learning technology\
    \ combined with image processing to the recognition of \ncrop diseases and insect\
    \ pests is an inevitable trend in the future development of precision \nagriculture.\
    \ The performance of deep learning networks is very dependent on data sets. \n\
    High quality, high correlation, complete annotation, and large-scale agricultural\
    \ data sets \nare of great significance for model training. In the application\
    \ of crop disease and pest \nrecognition, in addition to color images taken by\
    \ cameras and mobile phones of sensing \ndevices, multimodal agricultural data\
    \ such as hyperspectral, near-infrared, and infrared \nimages are becoming a trend,\
    \ and their acquisition provides support for model training, \nas shown in Figure\
    \ 29. In addition to publicly available data sets, an important source for \n\
    data set sources is self-collection. However, it is very difficult to collect\
    \ graphs of crop \ndiseases and insect pests, and there are some problems, such\
    \ as page occlusion and victim \narea concealment, which require multi-angle sensing\
    \ equipment to collect at the whole \ntime, which requires a large amount of data\
    \ collection and transmission. Based on 5G, \nhigh-speed transmission of data\
    \ from terminal sensing nodes to the platform can be real-\nized, real-time detection\
    \ of data can be realized, and the degree of intelligence can be ex-\npanded [111].\
    \ \nCamera\nVideo\nIR/NIR\nSpectral camera\n5G\nAgricultural \nimage data set\
    \ \nplatform\nTraining \nmodel\nApplication \nplatform\n \nFigure 28. Open artiﬁcial\
    \ intelligence deep learning platform.\nDeep learning is an important branch of\
    \ machine learning. It can automatically\nand efﬁciently extract target features\
    \ and recognize targets through model training. The\napplication of deep learning\
    \ technology combined with image processing to the recognition\nof crop diseases\
    \ and insect pests is an inevitable trend in the future development of precision\n\
    agriculture. The performance of deep learning networks is very dependent on data\
    \ sets.\nHigh quality, high correlation, complete annotation, and large-scale\
    \ agricultural data sets\nare of great signiﬁcance for model training. In the\
    \ application of crop disease and pest\nrecognition, in addition to color images\
    \ taken by cameras and mobile phones of sensing\ndevices, multimodal agricultural\
    \ data such as hyperspectral, near-infrared, and infrared\nimages are becoming\
    \ a trend, and their acquisition provides support for model training, as\nshown\
    \ in Figure 29. In addition to publicly available data sets, an important source\
    \ for data\nset sources is self-collection. However, it is very difﬁcult to collect\
    \ graphs of crop diseases\nand insect pests, and there are some problems, such\
    \ as page occlusion and victim area\nconcealment, which require multi-angle sensing\
    \ equipment to collect at the whole time,\nwhich requires a large amount of data\
    \ collection and transmission. Based on 5G, high-speed\ntransmission of data from\
    \ terminal sensing nodes to the platform can be realized, real-time\ndetection\
    \ of data can be realized, and the degree of intelligence can be expanded [111].\n\
    Test \ndata\nTest \nmodel\noptimization\nFigure 27. An agricultural intelligence\
    \ detection framework for machine learning. \nHowever, the autonomous training\
    \ model is limited by the resources an\npower of the sensing device, and the effect\
    \ is not always ideal. At present, th\nopen-source deep learning platforms for\
    \ artificial intelligence, which can op\ntraining and provide detection accuracy\
    \ with the help of platform capabili\nAI deep learning platform is shown in Figure\
    \ 28. \nMicrosoft Azure\nIBM System ML\nTencent TML\nAlibaba DTPAI\nBaidu BML\n\
    Amazon ML\nMahout\nHadoop\nSpark\nGraphLab\nMPICH 2\nDMLC\nFigure 28. Open artificial\
    \ intelligence deep learning platform. \nDeep learning is an important branch\
    \ of machine learning. It can auto\nefficiently extract target features and recognize\
    \ targets through model traini\ncation of deep learning technology combined with\
    \ image processing to the \ncrop diseases and insect pests is an inevitable trend\
    \ in the future developmen\nagriculture. The performance of deep learning networks\
    \ is very dependen\nHigh quality, high correlation, complete annotation, and large-scale\
    \ agricul\nare of great significance for model training. In the application of\
    \ crop dis\nrecognition, in addition to color images taken by cameras and mobile\
    \ phon\ndevices, multimodal agricultural data such as hyperspectral, near-infrared\n\
    images are becoming a trend, and their acquisition provides support for m\nas\
    \ shown in Figure 29. In addition to publicly available data sets, an import\n\
    data set sources is self-collection. However, it is very difficult to collect\
    \ g\ndiseases and insect pests, and there are some problems, such as page occlusi\n\
    area concealment, which require multi-angle sensing equipment to collect\ntime,\
    \ which requires a large amount of data collection and transmission. \nhigh-speed\
    \ transmission of data from terminal sensing nodes to the platfor\nized, real-time\
    \ detection of data can be realized, and the degree of intellige\npanded [111].\
    \ \nCamera\nVideo\nIR/NIR\nSpectral camera\n5G\nAgricultural \nimage data set\
    \ \nplatform\nTraining \nmodel\nApplication \nplatform\n \nFigure 29. Machine\
    \ learning detection platform based on 5G. \nFigure 29. Machine learning detection\
    \ platform based on 5G.\nElectronics 2023, 12, 2336\n28 of 46\n4.3. 5G Intelligent\
    \ Agricultural Machinery\nUnder the conditions of high speed and low delay of\
    \ 5G, intelligent agricultural\nmachinery can realize deep real-time perception,\
    \ such as the state information collection,\nfault location, and operation monitoring\
    \ of agricultural machinery can be displayed online\nin real time. The system\
    \ can diagnose the failure of agricultural machinery in real-time and\nschedule\
    \ the cooperative operation of multiple agricultural machineries. The advantage\n\
    of low latency is that route decisions can be made in time, increasing the speed\
    \ of sowing\nor harvesting and making the operation more accurate. Secondly, agricultural\
    \ robots are\nmainly divided into two categories. First, walking robots. The second\
    \ is the robotic hand\nrobot. The robot is mainly based on visual recognition\
    \ technology to identify and locate\nplants and then plant and pick them. 5G technology\
    \ enables robots to receive commands\nfaster, transmit high-deﬁnition pictures\
    \ and videos, and promote the development of\nrobot visual recognition technology.\
    \ 5G has increased the number of robots that can\nbe accessed, allowing multiple\
    \ robots to be remotely controlled to work and improving\noperational efﬁciency.\n\
    4.3.1. Intelligent Agricultural Machinery\nAgricultural machinery plays an important\
    \ role in agricultural production practice.\nIt can effectively improve the efﬁciency\
    \ of agricultural production to promote large-scale\nand industrial planting.\
    \ All kinds of machinery used in the process of agriculture, forestry,\nanimal\
    \ husbandry, deputy, and ﬁshery production are collectively referred to as agricultural\n\
    machinery. Agricultural machinery can be broadly divided into two categories:\
    \ power\nmachinery and working machinery. The following diagram summarizes the\
    \ classiﬁcation\ndiagram of agricultural machinery and equipment according to\
    \ different functions [112,113],\nas shown in Figure 30.\ng\ng\ny\nUnder the conditions\
    \ of high speed and low delay of 5G, intelligent agricultu\nchinery can realize\
    \ deep real-time perception, such as the state information col\nfault location,\
    \ and operation monitoring of agricultural machinery can be dis\nonline in real\
    \ time. The system can diagnose the failure of agricultural machinery \ntime and\
    \ schedule the cooperative operation of multiple agricultural machineries. T\n\
    vantage of low latency is that route decisions can be made in time, increasing\
    \ the sp\nsowing or harvesting and making the operation more accurate. Secondly,\
    \ agricultu\nbots are mainly divided into two categories. First, walking robots.\
    \ The second is \nbotic hand robot. The robot is mainly based on visual recognition\
    \ technology to i\nand locate plants and then plant and pick them. 5G technology\
    \ enables robots to \ncommands faster, transmit high-definition pictures and videos,\
    \ and promote the d\nment of robot visual recognition technology. 5G has increased\
    \ the number of robo\ncan be accessed, allowing multiple robots to be remotely\
    \ controlled to work and im\ning operational efficiency. \n4.3.1. Intelligent\
    \ Agricultural Machinery \nAgricultural machinery plays an important role in agricultural\
    \ production p\nIt can effectively improve the efficiency of agricultural production\
    \ to promote larg\nand industrial planting. All kinds of machinery used in the\
    \ process of agriculture, fo\nanimal husbandry, deputy, and fishery production\
    \ are collectively referred to as a\ntural machinery. Agricultural machinery can\
    \ be broadly divided into two cate\npower machinery and working machinery. The\
    \ following diagram summarizes th\nsification diagram of agricultural machinery\
    \ and equipment according to differen\ntions [112,113], as shown in Figure 30.\
    \ \nIntelligent agricultural \nmachinery and equipment\nTillage \nmachinery\n\
    Plant protection \nmachinery\nIrrigation and \ndrainage \nmachinery\nPower transmission\
    \ \nmachinery\nHarvesting \nmachinery\nAnimal husbandry \nmachinery\nPlanting\
    \ and fertilizing \nmachinery\nFishery and \naquatic products\nAnimal husbandry\n\
    Crop planting\nAuxiliary \nmachinery\n▪ \nCultivator\n▪ \nRotary cultivator\n\
    ▪ \nMicro cultivator\n▪ \nDisc plough\n▪ \nRotary cultivator\n▪ \nScarifier\n\
    ▪ \nStubble cleaner\n▪ \nGrader\n▪ \nDigger\n▪ \nFurrowing and \nridging machine\n\
    ▪ \nCombined grader\n▪ \nDisc harrow\n▪ \nBallast\n▪ \nPruning \nMachineCultivat\n\
    or\n▪ \nEradicator\n▪ \nFogger\n▪ \nSpray\n▪ \nLawnmower\n▪ \nDuster\n▪ \nLawn\
    \ mower\n▪ \nInsecticidal lamp\n▪ \nBooby trap\n▪ \nPlant protection \nUAV\n▪\
    \ \nWater lifting, \ndrainage and \nirrigation\n▪ \nSprinkler \nirrigation \n\
    equipment\n▪ \nDrip irrigation \nequipment\n▪ \nMicro spray \nequipment\n▪ \n\
    Outlet valve\n▪ \nAirbrush\n▪ \nWater and \nfertilizer \nEquipment\n▪ \nWater\
    \ pump\n▪ \nHydraulic turbine\n▪ \nGasoline engine\n▪ \nDiesel engine\n▪ \nEngine\n\
    ▪ \nTractor\n▪ \nLoading and \nunloading \nvehicle\n▪ \nLifting platform\n▪ \n\
    Conveyor\n▪ \nHoist\n▪ \nFeeder\n▪ \nLoader\n▪ \nForklift\n▪ \nSeeder\n▪ \nDrill\n\
    ▪ \nAcupoint planter\n▪ \nPlanter\n▪ \nRice transplanter\n▪ \nTransplanter\n▪\
    \ \nFertilizer \nApplicator\n▪ \nTopdressing \nmachine\n▪ \nMulching \nmachine\n\
    ▪ \nSpray machine\n▪ \nUAV\n▪ \nHarvester\n▪ \nHarvester\n▪ \nThreshing \nmachine\n\
    ▪ \nFruit picking \nmachine\n▪ \nBaler\n▪ \nSheller\n▪ \nCleaner\n▪ \nDrying machine\n\
    ▪ \nWarehousing \nequipment\n▪ \nSeed processor\n▪ \n▪ \nChicken breeding \nequipment\n\
    ▪ \nPig breeding \nequipment\n▪ \nIncubation \nequipment\n▪ \nFan equipment\n\
    ▪ \nHeating \nequipment\n▪ \nAquaculture \nEquipment \n▪ \nCapture \nequipment\n\
    ▪ \nSlaughtering \nequipment\n▪ \nCrushing equipment\n▪ \nStacking equipment\n\
    ▪ \nDrying equipment\n▪ \nCooling equipment\n▪ \nGranulation \nequipment\n▪ \n\
    Screening \nequipment\n▪ \nMixing and stirring\n▪ \nQuantitative \npackaging\n\
    ▪ \nFertilizer production \nmachine\n \nFigure 30. Classification of agricultural\
    \ machinery and equipment. \nThe trend of intelligent agriculture development\
    \ is necessarily intelligent. W\ndevelopment of technology based on automated\
    \ equipment, the intelligent opera\nagriculture will be realized by means of sensors,\
    \ information transmission, and\nmation integration processing, which are based\
    \ on the Internet of Things, big da\nartificial intelligence [114]. \nFor example,\
    \ the intelligent agricultural machine can form a highly intelligen\nating system\
    \ by configuring various sensing devices and computing chips on the a\ntural machine,\
    \ combined with satellite positioning detection terminal equipment,\nintegration\
    \ module, and IoT system. Intelligent agricultural machinery can also \ninformation\
    \ on agricultural machinery operation through the management cente\nFigure 30.\
    \ Classiﬁcation of agricultural machinery and equipment.\nThe trend of intelligent\
    \ agriculture development is necessarily intelligent. With the\ndevelopment of\
    \ technology based on automated equipment, the intelligent operation of\nagriculture\
    \ will be realized by means of sensors, information transmission, and information\n\
    integration processing, which are based on the Internet of Things, big data, and\
    \ artiﬁcial\nintelligence [114].\nFor example, the intelligent agricultural machine\
    \ can form a highly intelligent operat-\ning system by conﬁguring various sensing\
    \ devices and computing chips on the agricultural\nmachine, combined with satellite\
    \ positioning detection terminal equipment, digital in-\ntegration module, and\
    \ IoT system. Intelligent agricultural machinery can also display\nElectronics\
    \ 2023, 12, 2336\n29 of 46\ninformation on agricultural machinery operation through\
    \ the management center informa-\ntion platform. The perception information will\
    \ be monitored for statistics and management,\nagricultural machinery macro management,\
    \ command scheduling, and operation statis-\ntics. Information technology and\
    \ agricultural machinery chain integration, through data\nanalysis, get a scientiﬁc\
    \ decision.\nHigher intelligent agricultural machines require more sensory data\
    \ intake for com-\nputational processing decisions. This requires a smart agricultural\
    \ Internet of Things.\nFor example, the irrigation system of farmland can be completed\
    \ by simple operation of\nfarmers. However, the question of when and how much\
    \ to irrigate depends on people’s\nexperience. The intelligent irrigation system\
    \ can be judged comprehensively through the\nmonitoring data of crop production\
    \ status, temperature, and humidity, meteorological\nconditions, etc., which saves\
    \ manpower and ensures the health of crop growth.\nThe problem is that the traditional\
    \ Internet of Things cannot meet the requirements\nof real-time transmission of\
    \ large amounts of data. With the integration of 5G, smart\nagricultural machines\
    \ can achieve a data communication rate, which is expected to change\nthe production\
    \ mode of smart agricultural machines and the degree of wisdom, as shown\nin Figure\
    \ 31 and Table 8.\nElectronics 2023, 12, x FOR PEER REVIEW \n \nstatistics. Information\
    \ technology and agricultural machinery chain integration, t\ndata analysis, get\
    \ a scientific decision. \nHigher intelligent agricultural machines require more\
    \ sensory data intake f\nputational processing decisions. This requires a smart\
    \ agricultural Internet of Thi\nexample, the irrigation system of farmland can\
    \ be completed by simple operation \ners. However, the question of when and how\
    \ much to irrigate depends on people\nrience. The intelligent irrigation system\
    \ can be judged comprehensively through th\nitoring data of crop production status,\
    \ temperature, and humidity, meteorologica\ntions, etc., which saves manpower\
    \ and ensures the health of crop growth. \nThe problem is that the traditional\
    \ Internet of Things cannot meet the requi\nof real-time transmission of large\
    \ amounts of data. With the integration of 5G, sm\ncultural machines can achieve\
    \ a data communication rate, which is expected to cha\nproduction mode of smart\
    \ agricultural machines and the degree of wisdom, as sh\nFigure 31 and Table 8.\
    \ \nMechanical \narm\nVideo sensing \ndevice\nInfrared \nspectrum\nCamera\n5G+Mechanical\
    \ arm+AGV Independent patrol inspection\nAGV\n \nFigure 31. 5G + robotic arm +\
    \ AGV independent inspection. \nTable 8. Image recognition and detection of intelligent\
    \ agriculture. \nLiterature \nContent \nField \nType \nB. Bose et al. [115] \n\
    Diagnosis, detection, and classifica-\ntion of cannabis diseases \nPlant protection\
    \ \nClassification algo\nD. Brunelli et al. [116] \nIdentify and kill apple pests\
    \ \nPlant protection \nNeural netwo\nR. Medar et al. [117] \nCrop yield prediction\
    \ \nPlant protection \nMachine learn\nN. Gobalakrishnan [118] \nPlant disease\
    \ detection \nCrop diseases and in-\nsect pests \nImage process\nM. Merchant [119]\
    \ \nVarious nutritional deficiencies of \nmango leaves \nCrop protection \nImage\
    \ process\nQ. Feng [120] \nTomato harvesting machine \nHarvest \nImage segmentati\n\
    cessing \nUnder the background of 5G, the smart agricultural IoT will transform\
    \ the \nagricultural machinery equipment and make it more intelligent. Intelligent\
    \ agri\nFigure 31. 5G + robotic arm + AGV independent inspection.\nTable 8. Image\
    \ recognition and detection of intelligent agriculture.\nLiterature\nContent\n\
    Field\nType\nB. Bose et al. [115]\nDiagnosis, detection, and\nclassiﬁcation of\
    \ cannabis diseases\nPlant protection\nClassiﬁcation algorithm\nD. Brunelli et\
    \ al. [116]\nIdentify and kill apple pests\nPlant protection\nNeural network\n\
    R. Medar et al. [117]\nCrop yield prediction\nPlant protection\nMachine learning\n\
    N. Gobalakrishnan [118]\nPlant disease detection\nCrop diseases and insect pests\n\
    Image processing\nM. Merchant [119]\nVarious nutritional deﬁciencies of\nmango\
    \ leaves\nCrop protection\nImage processing\nQ. Feng [120]\nTomato harvesting\
    \ machine\nHarvest\nImage segmentation\nprocessing\nElectronics 2023, 12, 2336\n\
    30 of 46\nUnder the background of 5G, the smart agricultural IoT will transform\
    \ the existing\nagricultural machinery equipment and make it more intelligent.\
    \ Intelligent agricultural\nmachinery can perceive its position, surrounding environment\
    \ relationship, and the inter-\nnal working state of machinery by building machine\
    \ vision, multi-dimensional perception,\nand satellite positioning based on 5G\
    \ agricultural Internet of Things. It can achieve good\ncooperation and scientiﬁc\
    \ implementation, effectively improving the effect of agricultural\nmechanization\
    \ by controlling and operating each process. Intelligent agricultural machin-\n\
    ery 5G-based agricultural Internet of Things can realize real-time monitoring\
    \ of agricultural\nmachinery’s own condition, operating state of machinery and\
    \ tools, meteorological condi-\ntions, and operating environment. It can also\
    \ guide agricultural machinery to adjust the\noperation plan in time according\
    \ to the obtained information and effectively reduce the\nindustrial machinery\
    \ in the process of operation failure, such as machine damage, poor\nquality,\
    \ and other problems. In addition to the above, intelligent agricultural machinery\n\
    will reduce the amount of ineffective operation of industrial machinery. Energy\
    \ efﬁciency\nhas been signiﬁcantly improved. The precise operation also realizes\
    \ the precise applica-\ntion of pesticides and fertilizers and truly realizes\
    \ the requirements of energy-saving and\nenvironmental protection.\nIt is clear\
    \ that smart agriculture combined with the Internet of Things and machine\nlearning\
    \ algorithm big data can transform traditional agricultural machinery and equip-\n\
    ment, making them more intelligent. In addition, the operation of intelligent\
    \ detection\nand sensing equipment can realize the functions of agricultural machinery\
    \ positioning,\nreal-time statistics of agricultural machinery working area, and\
    \ real-time calculation of\noperation quality. The system supports a variety of\
    \ agricultural machinery operations such\nas sowing, transplanting, plant protection,\
    \ harvesting, deep loosening, and land prepara-\ntion, straw returning, and so\
    \ on. It can measure fuel consumption and obtain the working\ncondition information\
    \ of agricultural machinery in real-time. This facilitates the control\nof agricultural\
    \ production progress and facilitates the real-time control of the working\narea,\
    \ working quality, and working power consumption. Being based on geospatial remote\n\
    sensing technology, multi-sensor fusion technology, 5G technology, and big data\
    \ technology,\nthe system realizes the comprehensive upgrading of smart agricultural\
    \ machinery.\n4.3.2. Automatic Driving of Agricultural Machinery\nThe automatic\
    \ driving technology of agricultural machinery is to use high-precision\nsatellite\
    \ positioning and navigation information and controls the hydraulic system of\n\
    agricultural machinery by the controller so that the agricultural machinery can\
    \ drive\nautomatically according to the set route (straight line or curve). It\
    \ can effectively improve\nthe working accuracy, improve the land utilization\
    \ rate, reduce the labor intensity of\nmachine hands, and extend the working time\
    \ (ﬁeld work can also be carried out at night).\nMoreover, it is easy to operate\
    \ and reduces the requirement for the driving ability of the\nmanipulator [121,122].\
    \ Based on the Beidou Navigation Satellite System (BDS) [123,124], a\nglobal Positioning\
    \ system (GPS) can achieve intelligent driving of all kinds of agricultural\n\
    machinery, including rice transplanters, seed drills, combine harvesters, etc.\
    \ The high-\nprecision positioning and navigation technology, image recognition,\
    \ and transmission\ntechnology are applied to the intelligent driving of these\
    \ machines to realize the precise\nnavigation of agricultural machinery driving\
    \ and automatically complete the land tillage,\nsowing, ﬁeld management, and harvest,\
    \ as shown in Figure 32.\nIntelligent agricultural machinery automatic driving\
    \ system uses satellite positioning,\nmechanical control, inertial navigation,\
    \ and other technologies so that agricultural machin-\nery, according to the planned\
    \ route, automatically adjusts the direction of travel. Operation\nprecision can\
    \ reach the centimeter level, and can be used for ditching, raking, sowing, ridge,\n\
    fertilization, spraying, harvesting, transplanting, and other agricultural operations.\n\
    Unmanned agricultural machinery has many problems to be solved, such as real-time\n\
    control, low speed, and complex scenes. Sensing data do not easily meet the needs\
    \ of\nElectronics 2023, 12, 2336\n31 of 46\nintelligent control. The high bandwidth\
    \ and real-time performance of 5G will be able to\nmeet the above requirements\
    \ of unmanned agricultural control operations.\nElectronics 2023, 12, x FOR PEER\
    \ REVIEW \n \nGPS/Beidou \nNavigation \nTerminal\nSatellite \nreceiving \nantenna\n\
    Traveling \ncontroller\nHydraulic \ncontrol \nsystem\nAngle/video \nsensor\n \n\
    Figure 32. 5G unmanned agricultural machinery model. \nIntelligent agricultural\
    \ machinery automatic driving system uses satellite p\ning, mechanical control,\
    \ inertial navigation, and other technologies so that agri\nmachinery, according\
    \ to the planned route, automatically adjusts the direction o\nOperation precision\
    \ can reach the centimeter level, and can be used for ditching\nsowing, ridge,\
    \ fertilization, spraying, harvesting, transplanting, and other agricult\nerations.\
    \ \nUnmanned agricultural machinery has many problems to be solved, such\ntime\
    \ control, low speed, and complex scenes. Sensing data do not easily meet th\n\
    of intelligent control. The high bandwidth and real-time performance of 5G will\n\
    to meet the above requirements of unmanned agricultural control operations. \n\
    4.3.3. 5G Automatic Coordination of Multiple Agricultural Machines \nThe 5G agricultural\
    \ machinery unmanned operating system is deployed on\ncloud network fusion platform.\
    \ With the intelligent agricultural machinery equ\ndocking, we realized the agricultural\
    \ machinery from the hangar, and machine\nway to the operation plot of the whole\
    \ process of unmanned operation. It cover\nproduction links of rice cultivation,\
    \ seed, pipe, and harvest. In the hangar and on t\nthe location map modeling is\
    \ first carried out, and the application equipment dep\nbased on RTK differential\
    \ GNSS positioning technology, IMU data, and UWB pre\nsitioning technology were\
    \ used to achieve the indoor and outdoor centimeter-lev\ntioning accuracy. Secondly,\
    \ the core control system deployed in the edge cloud \nvisual and radar terminals\
    \ installed in the agricultural machinery were combined\nthe surrounding environment\
    \ intelligently. Finally, the AI deep learning algorit\nused to complete the mark\
    \ line recognition and obstacle detection when agricultu\nchinery is moving forward\
    \ and backing up. In this way, unmanned driving, park\nstacle recognition, and\
    \ automatic obstacle avoidance can be realized, as shown in\n33. \nFigure 32.\
    \ 5G unmanned agricultural machinery model.\n4.3.3. 5G Automatic Coordination\
    \ of Multiple Agricultural Machines\nThe 5G agricultural machinery unmanned operating\
    \ system is deployed on the 5G\ncloud network fusion platform. With the intelligent\
    \ agricultural machinery equipment\ndocking, we realized the agricultural machinery\
    \ from the hangar, and machine plough\nway to the operation plot of the whole\
    \ process of unmanned operation. It covers all the\nproduction links of rice cultivation,\
    \ seed, pipe, and harvest. In the hangar and on the road,\nthe location map modeling\
    \ is ﬁrst carried out, and the application equipment deployment\nbased on RTK\
    \ differential GNSS positioning technology, IMU data, and UWB precise\npositioning\
    \ technology were used to achieve the indoor and outdoor centimeter-level\npositioning\
    \ accuracy. Secondly, the core control system deployed in the edge cloud and the\n\
    visual and radar terminals installed in the agricultural machinery were combined\
    \ to sense\nthe surrounding environment intelligently. Finally, the AI deep learning\
    \ algorithm was used\nto complete the mark line recognition and obstacle detection\
    \ when agricultural machinery\nis moving forward and backing up. In this way,\
    \ unmanned driving, parking, obstacle\nrecognition, and automatic obstacle avoidance\
    \ can be realized, as shown in Figure 33.\n4.4. 5G Agricultural UAV\nUAVs require\
    \ a high time delay of network signals. 5G networks give UAVs important\ncapabilities\
    \ such as ultra-high-deﬁnition video transmission, remote networking, and\nautonomous\
    \ ﬂight. 5G technology makes it possible for ﬂeets of drones to work together\n\
    and around the clock. It has huge development space in agriculture, security,\
    \ electricity,\nand other industries [125]. The plant protection UAV is small\
    \ in size, light in weight,\nﬂexible for ﬂight control, and has good applicability\
    \ to different plots and crops. At the\nplatform end, the networked UAV can be\
    \ remotely controlled to set functions such as\nassigning tasks, designing routes\
    \ independently, sending back spraying data in real time,\nand automatically returning\
    \ after an operation. Plant protection UAVs reduce pesticides,\nsave water consumption\
    \ and improve pesticides [126]. The steady wind ﬁeld generated\nby the rotor of\
    \ the UAV can penetrate the bottom of the crop, and the atomization effect is\n\
    good, reaching the back of the blade.\nLive broadcasts of rice by unmanned aerial\
    \ vehicles are relatively popular in south\nChina, which can sow 300~600 mu per\
    \ day, 3~5 times that of ground machinery. At the\nElectronics 2023, 12, 2336\n\
    32 of 46\nsame time, it eliminates the process of seedling, raising, transporting,\
    \ and transplanting.\nThe drone can adjust the nozzle size according to the size\
    \ of the seed. Spray the seeds in\nrows and columns as needed. The UAV can also\
    \ spray granular fertilizer and pesticides.\nAccording to the difference in particle\
    \ density and quality, it can automatically adjust\nthe parameters of the medicine\
    \ box to provide efﬁcient and intelligent fertilization and\napplication schemes.\n\
    Electronics 2023, 12, x FOR PEER REVIEW \n31 of 46 \n \nUAV/satellite high-\n\
    definition field \nmap construction\nGPS, BeiDong, \nGNSS navigation \nand positioning\n\
    Automatic turning \ncontrol of \nagricultural \nmachinery\nField path planning\
    \ \nof agricultural \nmachinery\nMulti machine \ncooperative task \nallocation\
    \ of \nagricultural machinery\nUnmanned \nagricultural \nmachinery\n \nFigure\
    \ 33. Schematic diagram of unmanned agricultural machinery collaboration based\
    \ on 5G. \n4.4. 5G Agricultural UAV \nUAVs require a high time delay of network\
    \ signals. 5G networks give UAVs im-\nportant capabilities such as ultra-high-definition\
    \ video transmission, remote networking, \nand autonomous flight. 5G technology\
    \ makes it possible for fleets of drones to work to-\ngether and around the clock.\
    \ It has huge development space in agriculture, security, elec-\ntricity, and\
    \ other industries [125]. The plant protection UAV is small in size, light in\
    \ \nweight, flexible for flight control, and has good applicability to different\
    \ plots and crops. \nAt the platform end, the networked UAV can be remotely controlled\
    \ to set functions such \nas assigning tasks, designing routes independently,\
    \ sending back spraying data in real \ntime, and automatically returning after\
    \ an operation. Plant protection UAVs reduce pesti-\ncides, save water consumption\
    \ and improve pesticides [126]. The steady wind field gen-\nerated by the rotor\
    \ of the UAV can penetrate the bottom of the crop, and the atomization \neffect\
    \ is good, reaching the back of the blade. \nLive broadcasts of rice by unmanned\
    \ aerial vehicles are relatively popular in south \nChina, which can sow 300~600\
    \ mu per day, 3~5 times that of ground machinery. At the \nsame time, it eliminates\
    \ the process of seedling, raising, transporting, and transplanting. \nThe drone\
    \ can adjust the nozzle size according to the size of the seed. Spray the seeds\
    \ in \nrows and columns as needed. The UAV can also spray granular fertilizer\
    \ and pesticides. \nAccording to the difference in particle density and quality,\
    \ it can automatically adjust the \nparameters of the medicine box to provide\
    \ efficient and intelligent fertilization and appli-\ncation schemes. \nThe drones\
    \ carry a range of remote sensing equipment that can photograph the \ngrowth of\
    \ crops. Remote sensing images combined with extensive data analysis can real-\n\
    ize the functions of crop monitoring, fertilization advice, and pest and disease\
    \ prediction. \nDifferent yields reflect different infrared spectra, which can\
    \ be used to measure the area \nof crops. Pests and diseases can be analyzed by\
    \ infrared spectroscopy and high-definition \nphotographs. \nFor forest management,\
    \ 5G drone ground stations will be deployed around the forest \nfarm, covering\
    \ an area of about 100 km. The drones are equipped with equipment, such \nas optical\
    \ cameras and high-definition cameras, to monitor vegetation growth and forest\
    \ \ncover. Through big data analysis of tree varieties and survival rate, replanting\
    \ suggestions \ncan also predict the occurrence of forest pests and diseases and\
    \ put forward prevention \nFigure 33. Schematic diagram of unmanned agricultural\
    \ machinery collaboration based on 5G.\nThe drones carry a range of remote sensing\
    \ equipment that can photograph the growth\nof crops. Remote sensing images combined\
    \ with extensive data analysis can realize the\nfunctions of crop monitoring,\
    \ fertilization advice, and pest and disease prediction. Different\nyields reﬂect\
    \ different infrared spectra, which can be used to measure the area of crops.\
    \ Pests\nand diseases can be analyzed by infrared spectroscopy and high-deﬁnition\
    \ photographs.\nFor forest management, 5G drone ground stations will be deployed\
    \ around the forest\nfarm, covering an area of about 100 km. The drones are equipped\
    \ with equipment, such as\noptical cameras and high-deﬁnition cameras, to monitor\
    \ vegetation growth and forest cover.\nThrough big data analysis of tree varieties\
    \ and survival rate, replanting suggestions can also\npredict the occurrence of\
    \ forest pests and diseases and put forward prevention and control\nsuggestions.\
    \ In terms of forest ﬁre control, inspection routes can be planned according to\n\
    daily needs, and the UAV will automatically alarm if there is any abnormality\
    \ [127]. If the\nforest is on ﬁre, drones can be sent to check the ﬁre, and the\
    \ ﬁre can be used to identify the\npoint of ﬁre.\nAccording to the different functions\
    \ of agricultural UAVs, as shown in Figure 34,\nthey can be divided into two categories:\
    \ agricultural operation and farmland information\ncollection. Agricultural operation\
    \ refers to the use of unmanned aerial vehicles (UAVs) to\nreplace some human\
    \ agricultural operations and to solve the shortage of human operations\nin quality,\
    \ efﬁciency, and labor, as well as the safety problems of operations. The collection\n\
    of farmland information refers to the timely and accurate collection of ﬁeld information\n\
    using remote sensing detection technology, including photosynthetic quality, soil\
    \ moisture,\nand crop population growth [128,129].\nElectronics 2023, 12, 2336\n\
    33 of 46\n \ncan be divided into two categories: agricultural operation and farmland\
    \ information col-\nlection. Agricultural operation refers to the use of unmanned\
    \ aerial vehicles (UAVs) to \nreplace some human agricultural operations and to\
    \ solve the shortage of human opera-\ntions in quality, efficiency, and labor,\
    \ as well as the safety problems of operations. The \ncollection of farmland information\
    \ refers to the timely and accurate collection of field in-\nformation using remote\
    \ sensing detection technology, including photosynthetic quality, \nsoil moisture,\
    \ and crop population growth [128,129]. \nAgricultural UAV\nPlant protection \n\
    operation\nForestry \nmonitoring\nCrop \npollination\nHerd \npositioning\nSingle\
    \ rotor UAV\nMulti rotor UAV\n \nFigure 34. Type of agricultural UAV. \nSeveral\
    \ challenges remain in the current application of agricultural drones: \nFirst,\
    \ the endurance time of agricultural UAVs is short, which cannot adapt to multi-\n\
    ple types of complex operations in the field. \nSecond, it is difficult to control.\
    \ Most of the intelligence degree is low, and anti-colli-\nsion and other functions\
    \ are lacking. \nThird, the precision application control technology based on\
    \ agricultural information \nis not mature enough. During aerial spraying operations,\
    \ agricultural information such as \ncrop growth, pests, and diseases in different\
    \ operating areas were obtained by aerial re-\nmote sensing technology, and prescription\
    \ maps were generated to determine the pesti-\ncide preparations and dosage required\
    \ for aerial spraying in different areas. The precision \napplication of plant\
    \ protection UAVs was realized by variable control technology. \nAll the above\
    \ have put forward new requirements for the intelligence degree of \nUAVs, mainly\
    \ including intelligent control, precise operation, better function, and optimi-\n\
    zation of spraying equipment. For the precise control of UAVs, it is necessary\
    \ to consume \nmore abundant information to meet its control needs. Secondly,\
    \ the real-time control \nneeds to be strengthened and satisfied, and the large\
    \ bandwidth and low delay of 5G can \nmeet the above requirements. It can be expected\
    \ that the popularity of 5G will be expected \nto promote the further development\
    \ of agricultural drones. \n4.5. 5G Intelligent Agricultural Supply Chain Management\
    \ \nAgricultural products have various production processes, long cycles, and\
    \ numerous \nfactors, so it is challenging to realize standardized production\
    \ and management [130]. The \nsupply chain of agricultural products is in all\
    \ stages of agriculture before, during, and \nafter production. Participants participate\
    \ in different roles of producers and consumers to \nrealize the supply and circulation\
    \ of agricultural products among agricultural producers, \nagricultural materials/agricultural\
    \ service enterprises, wholesale and retail markets, reg-\nulatory agencies, and\
    \ end consumers. It connects the production, processing, transporta-\ntion, sales,\
    \ and other links of agricultural products and integrates logistics, capital flow,\
    \ \nand information flow. It is important to establish a chain structure network\
    \ composed of \nagricultural product suppliers, manufacturers, distributors, retailers,\
    \ and end consumers \n[131]. Traditional agricultural supply chain participants\
    \ mainly use the Internet of Things \ntechnology to achieve information collection,\
    \ transmission, processing, processing, and \nother businesses. However, as IoT\
    \ systems are built in different participant systems, they \nbelong to different\
    \ platforms. For the seemingly interconnected network, the business is \nFigure\
    \ 34. Type of agricultural UAV.\nSeveral challenges remain in the current application\
    \ of agricultural drones:\nFirst, the endurance time of agricultural UAVs is short,\
    \ which cannot adapt to multiple\ntypes of complex operations in the ﬁeld.\nSecond,\
    \ it is difﬁcult to control. Most of the intelligence degree is low, and anti-collision\n\
    and other functions are lacking.\nThird, the precision application control technology\
    \ based on agricultural information\nis not mature enough. During aerial spraying\
    \ operations, agricultural information such as\ncrop growth, pests, and diseases\
    \ in different operating areas were obtained by aerial remote\nsensing technology,\
    \ and prescription maps were generated to determine the pesticide\npreparations\
    \ and dosage required for aerial spraying in different areas. The precision\n\
    application of plant protection UAVs was realized by variable control technology.\n\
    All the above have put forward new requirements for the intelligence degree of\
    \ UAVs,\nmainly including intelligent control, precise operation, better function,\
    \ and optimization\nof spraying equipment. For the precise control of UAVs, it\
    \ is necessary to consume more\nabundant information to meet its control needs.\
    \ Secondly, the real-time control needs to\nbe strengthened and satisﬁed, and\
    \ the large bandwidth and low delay of 5G can meet\nthe above requirements. It\
    \ can be expected that the popularity of 5G will be expected to\npromote the further\
    \ development of agricultural drones.\n4.5. 5G Intelligent Agricultural Supply\
    \ Chain Management\nAgricultural products have various production processes, long\
    \ cycles, and numerous\nfactors, so it is challenging to realize standardized\
    \ production and management [130]. The\nsupply chain of agricultural products\
    \ is in all stages of agriculture before, during, and\nafter production. Participants\
    \ participate in different roles of producers and consumers to\nrealize the supply\
    \ and circulation of agricultural products among agricultural producers,\nagricultural\
    \ materials/agricultural service enterprises, wholesale and retail markets, regu-\n\
    latory agencies, and end consumers. It connects the production, processing, transportation,\n\
    sales, and other links of agricultural products and integrates logistics, capital\
    \ ﬂow, and\ninformation ﬂow. It is important to establish a chain structure network\
    \ composed of agri-\ncultural product suppliers, manufacturers, distributors,\
    \ retailers, and end consumers [131].\nTraditional agricultural supply chain participants\
    \ mainly use the Internet of Things tech-\nnology to achieve information collection,\
    \ transmission, processing, processing, and other\nbusinesses. However, as IoT\
    \ systems are built in different participant systems, they belong\nto different\
    \ platforms. For the seemingly interconnected network, the business is relatively\n\
    independent, unable to quickly and effectively complete the exchange of information,\
    \ the\nreal realization of the whole process of sharing, presentation, and other\
    \ difﬁculties.\nThe traditional Internet is to reduce intermediate links, reduce\
    \ transaction costs,\nexpand the scope of service, improve service quality, and\
    \ so on. Embedding blockchain\ntechnology may deepen the meaning of the Internet.\
    \ It can form credit by recording, storing,\ntransferring, verifying, and analyzing\
    \ information data programmatically. Blockchain can\nsave a great deal of labor\
    \ costs and intermediary costs, and the recorded credit information\nis completer\
    \ and more difﬁcult to fake. The internal structure of the network architecture\
    \ of\neach subsystem is different. The network slice network virtualization of\
    \ 5G can realize the\nisolation and organic combination of each sub-platform.\
    \ An agricultural products supply\nchain management schematic diagram of 5G block\
    \ chain is shown in Figure 35.\nElectronics 2023, 12, 2336\n34 of 46\nsave a great\
    \ deal of labor costs and intermediary costs, and the recorded credit infor-\n\
    mation is completer and more difficult to fake. The internal structure of the\
    \ network ar-\nchitecture of each subsystem is different. The network slice network\
    \ virtualization of 5G\ncan realize the isolation and organic combination of each\
    \ sub-platform. An agricultural\nproducts supply chain management schematic diagram\
    \ of 5G block chain is shown in Fig-\nure 35. \nAgricultural \nproducer\nAgricultural\
    \ materials/\nagricultural clothing \nsupplier\nWholesale \nsales market\nShop/\n\
    Supermarket\n \nRegulators\nConsumer\nBlock 1\nParent chunk \nhash value\npro\n\
    duct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\n\
    tion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant A Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 2\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant B Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 3\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant C Internet\
    \ \nof Things Platform\nBlockchain entry\nBlock 4\nParent chunk \nhash value\n\
    pro\nduct\nion \ninfo\nrma\ntion\nLogi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\n\
    rma\ntion\nInve\nntor\ny \ninfo\nrma\ntion\nBlock \nhead\n \nParticipant D Internet\
    \ \nof Things Platform\nBlockchain entry\n5G agricultural product supply chain\
    \ cloud platform\nNetwork \nSlice 1\nNetwork \nSlice 2\nNetwork \nSlice 3\nNetwork\
    \ \nSlice 4\n5G\n5G\n5G\n5G\n \nFigure 35. 5G block chain agricultural products\
    \ supply chain management schematic diagram. \n5. Challenges of 5G Smart Agricultural\
    \ IoT \n5G will bring new development opportunities to agriculture, making the\
    \ smart agri-\ncultural IoT evolve in a smarter direction. At the same time, it\
    \ also brings many new prob-\nlems, and smart agriculture faces new challenges,\
    \ as shown in Figure 36. \nIntelligent \nmonitoring\nWater/Soil \nManagement\n\
    Management of \nplanting, breeding \nand growth\nPest \nmanagement\nSupply chain\
    \ \nmanagemen\nt\nIntelligent \nAgriculture \nPractice\nSmart agricultural machinery:\
    \ \nplanting, weeding, picking and \nharvesting\nLarge data of video and \nimage\
    \ types\nLarge amount of data\nTransmission \ndifficulties\nMultiple node \ndeployments\n\
    Numerous sensing \nnodes\nDifficulty in \nnetworking\nLarge amount of \nremote\
    \ sensing \ndata\nAI intelligence combined \nwith large amount of \ndata\nNode\
    \ intensive \ndeployment\nWide area deployment\nLarge amount of remote \nsensing\
    \ data\nLarge quantity \nof high-\nprecision \nmonitoring\nHigh real-time \nperformance\n\
    AI intelligence \ncombines large \namount of data\nHigh real-time\nRequire immediate\
    \ \nresponse\nMultiple \nterminal \ntypes\nPlatform \nhybrid\nAI intelligence\
    \ \ncombined with \nlarge amount of \nremote sensing \ndata\nNode wide area \n\
    deployment\n \nFigure 36. The new problems in the smart agriculture Internet of\
    \ Things. \nThese new problems bring new challenges to the application of smart\
    \ agriculture\nMany of these key issues may be partially solved with the introduction\
    \ of 5G technology\nFigure 35. 5G block chain agricultural products supply chain\
    \ management schematic diagram.\n5. Challenges of 5G Smart Agricultural IoT\n\
    5G will bring new development opportunities to agriculture, making the smart agricul-\n\
    tural IoT evolve in a smarter direction. At the same time, it also brings many\
    \ new problems,\nand smart agriculture faces new challenges, as shown in Figure\
    \ 36.\nproducts supply chain management schematic diagram of 5G block chain is\
    \ shown in\nure 35. \nAgricultural \nproducer\nAgricultural materials/\nagricultural\
    \ clothing \nsupplier\nWholesale \nsales market\nShop/\nSupermarket\n \nRegulators\n\
    Consumer\nBlock 1\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant A Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 2\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant B Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 3\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant C Internet \nof Things Platform\nBlockchain\
    \ entry\nBlock 4\nParent chunk \nhash value\npro\nduct\nion \ninfo\nrma\ntion\n\
    Logi\nstics \ninfo\nrma\ntion\nOrd\ner \ninfo\nrma\ntion\nInve\nntor\ny \ninfo\n\
    rma\ntion\nBlock \nhead\n \nParticipant D Internet \nof Things Platform\nBlockchain\
    \ entry\n5G agricultural product supply chain cloud platform\nNetwork \nSlice\
    \ 1\nNetwork \nSlice 2\nNetwork \nSlice 3\nNetwork \nSlice 4\n5G\n5G\n5G\n5G\n\
    \ \nFigure 35. 5G block chain agricultural products supply chain management schematic\
    \ diagram\n5. Challenges of 5G Smart Agricultural IoT \n5G will bring new development\
    \ opportunities to agriculture, making the smart \ncultural IoT evolve in a smarter\
    \ direction. At the same time, it also brings many new p\nlems, and smart agriculture\
    \ faces new challenges, as shown in Figure 36. \nIntelligent \nmonitoring\nWater/Soil\
    \ \nManagement\nManagement of \nplanting, breeding \nand growth\nPest \nmanagement\n\
    Supply chain \nmanagemen\nt\nIntelligent \nAgriculture \nPractice\nSmart agricultural\
    \ machinery: \nplanting, weeding, picking and \nharvesting\nLarge data of video\
    \ and \nimage types\nLarge amount of data\nTransmission \ndifficulties\nMultiple\
    \ node \ndeployments\nNumerous sensing \nnodes\nDifficulty in \nnetworking\nLarge\
    \ amount of \nremote sensing \ndata\nAI intelligence combined \nwith large amount\
    \ of \ndata\nNode intensive \ndeployment\nWide area deployment\nLarge amount of\
    \ remote \nsensing data\nLarge quantity \nof high-\nprecision \nmonitoring\nHigh\
    \ real-time \nperformance\nAI intelligence \ncombines large \namount of data\n\
    High real-time\nRequire immediate \nresponse\nMultiple \nterminal \ntypes\nPlatform\
    \ \nhybrid\nAI intelligence \ncombined with \nlarge amount of \nremote sensing\
    \ \ndata\nNode wide area \ndeployment\n \nFigure 36. The new problems in the smart\
    \ agriculture Internet of Things. \nThese new problems bring new challenges to\
    \ the application of smart agricul\nMany of these key issues may be partially\
    \ solved with the introduction of 5G techno\nFigure 36. The new problems in the\
    \ smart agriculture Internet of Things.\nThese new problems bring new challenges\
    \ to the application of smart agriculture.\nMany of these key issues may be partially\
    \ solved with the introduction of 5G technology.\n5G is the infrastructure of\
    \ the intelligent era. Its characteristics of “extremely high\nspeed, enormous\
    \ capacity and extremely low delay” can provide basic support for meeting\nthe\
    \ development needs of smart agriculture in the future. Compared with the 2–4G\
    \ era,\nthe demand for base stations and network control equipment has increased\
    \ signiﬁcantly\nin 5G. The large-scale application of 5G technology not only increases\
    \ the cost of network\ninfrastructure, but also the cost of power and operation,\
    \ and maintenance is much higher\nthan that of 4G, which brings challenges to\
    \ the ﬁeld agricultural production with low added\nvalue. However, 5G technology\
    \ still has limits when it comes to applications such as virtual\nreality, intelligent\
    \ production, and driverless driving. First, the deployment of 5G base\nstations\
    \ is not balanced. As many 5G base stations are distributed in sparsely populated\n\
    areas, such as ﬁelds, agriculture, and farming, there may be only a few 5G base\
    \ stations\nElectronics 2023, 12, 2336\n35 of 46\nin these areas, which cannot\
    \ effectively cover all of them, which brings challenges to the\npopularization\
    \ and application. Secondly, the introduction of 5G will bring a change of the\n\
    whole smart agriculture application paradigm. The architecture, perception, transmission,\n\
    computing, service, processing, and application mode of 5G Internet of Things\
    \ for smart\nagriculture will bring changes, and there will be challenges.\n5.1.\
    \ Fusion and Optimization of Sparse 5G Base Station and Heterogeneous Sensing\
    \ Network in\nSmart Agriculture\n5.1.1. Optimization of Hybrid Deployment of 5G\
    \ and Sensing Network\nAccording to the analysis, the characteristics of 5G network\
    \ in agriculture are sparse,\nuneven, and they have low coverage of network base\
    \ stations and slow deployment of\nfarm base stations in remote areas. This brings\
    \ challenges for the application of 5G in ﬁeld\nagriculture and plantation agriculture.\n\
    For this imbalance and sparsity feature, it can be conﬁgured from two aspects.\
    \ One is\nto optimize the deployment of sensing nodes, and the other is to deploy\
    \ in combination\nwith heterogeneous networks. The hybrid deployment strategy\
    \ for ﬁeld agriculture, for ex-\nample, 5G sensing nodes are deployed in key areas,\
    \ and other sensing nodes are deployed\nin other areas, and sensing deployment\
    \ optimization is realized through network resource\nvirtualization and other\
    \ technologies. When the communication nodes of large-scale in-\ntelligent agricultural\
    \ sensor networks are deployed in three-dimensional space under the\nbackground\
    \ of 5G, the traditional random node deployment mode has the problems of high\n\
    energy consumption, high cost, and node disconnection. Firstly, by taking advantage\
    \ of the\ncharacteristics of the high bandwidth of 5G communication, a hierarchical\
    \ communication\nscheme can be designed, and a hierarchical node optimal deployment\
    \ model, a communi-\ncation energy consumption model, and a fully connected sensor\
    \ information transmission\nnetwork model are established. On the premise of ensuring\
    \ the full connectivity of sensor\ncommunication network nodes in farmland, the\
    \ life cycle of communication network nodes\nis improved.\n(a) 5G sparse deployment\
    \ based on ﬁeld agricultural planting scenarios.\nCombined with the actual ﬁeld\
    \ agricultural planting scene, the 5G base station has a\nhigh working frequency\
    \ band and a large signal attenuation, and its coverage radius is only\n0.3–0.5\
    \ times that of the 4G base station. It is difﬁcult to meet the goal of low cost\
    \ and high\nbeneﬁt of network construction only by deploying a macro base station.\
    \ The micro-base\nstation has a small coverage radius and low construction cost.\
    \ In order to optimize the\ndeployment cost of 5G base stations, the heterogeneous\
    \ network architecture of “macro\nand micro collaboration” can be adopted. How\
    \ to combine smart agricultural business for\noptimal deployment is an important\
    \ issue. Heterogeneous networks can optimize the cost\nof 5G signal deployment\
    \ while realizing the coverage of agricultural operation areas and\noptimizing\
    \ the perceived cost.\n(b) Intensive deployment optimization of 5G and sensing\
    \ nodes in ﬁne agriculture.\nIn ﬁne agriculture, there are many parameters to\
    \ monitor, many types of business, and\nthe need for intensive sensing equipment,\
    \ which generates an explosion of mobile data.\nHow to realize intelligent and\
    \ efﬁcient green deployment planning of intelligent nodes such\nas base stations\
    \ and gateways with large area coverage for various intelligent agricultural\n\
    applications is one of the key issues. By deploying small base stations with lower\
    \ cost\nand closer to users, it becomes a feasible solution to construct ultra-dense\
    \ heterogeneous\nnetworks centered on monitoring objects.\n5.1.2. Optimization\
    \ of 5G and Sensing Network Gateway Deployment\nPreviously, the deployment optimization\
    \ of sensing nodes and 5G base stations were\nproposed in ﬁne agriculture. In\
    \ the integration of 5G and sensing devices in deployment, it\nis necessary to\
    \ combine the collaboration of the Internet of Things gateway to realize the\n\
    high-low speed switching and transmission of sensing data.\nElectronics 2023,\
    \ 12, 2336\n36 of 46\n(a) The deployment of edge gateway in the Internet of Things.\
    \ The conditions of edge\ngateway coverage and service terminal trafﬁc generator,\
    \ the factors affecting the ofﬂoad-\ning delay of computing tasks, and the constraints\
    \ of edge gateway capacity allocation.\nFollowing that, the edge gateway deployment\
    \ optimization model was established and\noptimized.\n(b) To solve the problem\
    \ of base station deployment in the Low Power Wide Area\nNetwork (LPWAN), the\
    \ received signal values of all terminal test points can be predicted\nby combining\
    \ the terminal receiving signal prediction module. Then, the prediction results\n\
    are transformed into the weight values of all terminal test points during clustering,\
    \ and\nthe terminal test points are clustered. In addition, the location of the\
    \ base station was\nadjusted to achieve the optimal coverage effect and realize\
    \ the deployment optimization in\nthe whole application scenario.\n5.2. Optimization\
    \ Control under Edge Computing in 5G Intelligent Agricultural Production\nThe\
    \ popularization and application of 5G intelligent agricultural Internet of Things\
    \ will\nbring major challenges to the traditional cloud computing model, such\
    \ as high latency and\njitter, no support for location awareness and mobility,\
    \ and non-adaptive communication\ntypes. The production of smart agriculture often\
    \ needs to deploy edge computing to\nachieve real-time computing and reasonable\
    \ allocation of resources.\n5.2.1. Automatic Phenotype Monitoring Based on 5G\
    \ Internet of Things\nBy monitoring and sensing plant growth phenotype, the analysis\
    \ of crop traits is\nof great reference signiﬁcance for cultivating crop varieties\
    \ with excellent traits such as\ndrought resistance, poison resistance, lodging\
    \ resistance, high nutrient rate, and salt and\nalkali resistance. It helps researchers\
    \ select seeds of good quality for the next generation of\nbreeding objects. There\
    \ are many common image-based phenotyping methods in the ﬁeld\nof plant phenotype.\
    \ Among them, the image recognition method based on visible light has\nlower requirements\
    \ on experimental equipment, higher practicability, and can collect large-\nscale\
    \ plant image data. Therefore, the current deep learning can be better applied\
    \ to those\nalgorithms that use visible light images. All these require high-speed\
    \ data transmission,\nand how to collect and control real-time data in multi-source\
    \ sensing devices is a problem\nworth studying. At present, the main concern of\
    \ plant leaf recognition methods based on\nvisible light images is that there\
    \ are not many kinds of recognition methods. There are many\nresearchers working\
    \ on automatic phenotypic sensing platforms, which require automatic\nsensing\
    \ data pickup. Combining the advantages of high bandwidth and dense deployment\n\
    of 5G to realize automatic measurement and real-time computation of phenotype\
    \ is a\nproblem worth studying.\n5.2.2. Intelligent Sensing Real-Time Control\
    \ for Intelligent Agricultural Machinery\nMore intelligent agricultural machinery\
    \ will participate in the future smart agriculture.\nThey can combine 5G Internet\
    \ of Things and edge computing to realize smart agricultural\nproduction. Among\
    \ them they face the real-time control of equipment, which requires\nrapid data\
    \ collection and processing.\nIn the operation of smart agricultural machinery,\
    \ sensors deployed on the roadside of\nfarmland can sense all kinds of environments\
    \ and obtain important trafﬁc information. For\nexample, ﬁxed sensors such as\
    \ vision sensors and millimeter wave sensors are installed\non the side of the\
    \ road, and the information collected by the sensors is sent to the edge\nserver\
    \ for processing to extract information such as vehicle location and vehicle trajectory.\n\
    According to the multi-source information obtained by roadside sensors, crop sensors,\n\
    and smart agricultural sensing equipment, real-time data processing is carried\
    \ out to\nanalyze the operation status and calculate the results. Mobile edge\
    \ computing provides\npowerful computing and storage capabilities. The side camera\
    \ and millimeter wave radar\nare fused based on the edge server. Through data\
    \ preprocessing, space synchronization,\ntime synchronization, and tracking algorithm,\
    \ they can cooperate with each other, jointly\nElectronics 2023, 12, 2336\n37\
    \ of 46\nbuilding an intelligent agricultural machinery environment sensing system\
    \ to make it more\nstable and reliable.\nDuring the operation of intelligent agricultural\
    \ machinery, target tracking should focus\non the following points: (1) Object\
    \ association: radar detection should be associated with\ncamera detection, while\
    \ the current fusion detection must be associated with the existing\ntrajectory;\
    \ (2) Tracking link: appropriate ﬁlter should be selected for tracking; (3) Tracking\n\
    management: tracking object database needs to be maintained.\n5.3. Scheduling\
    \ Optimization of Heterogeneous Nodes under 5G Smart Agriculture\nHow to optimize\
    \ the scheduling of sensing nodes in different rates, resources, and\nnetworks\
    \ is a problem to be studied in the intelligent agricultural IoT under 5G.\n5.3.1.\
    \ Sense Scheduling for 5G Smart Agriculture\nUnder such circumstances, how to\
    \ optimize the deployment of network resources and\nnodes to achieve better overall\
    \ network performance is a problem worth studying.\n(a). Sensing task collaboration\
    \ based on 5G: Sensing task collaboration is a hot issue in\nsensor networks.\
    \ Based on the connectivity, coverage, survivability, and task completion\nrequirements\
    \ of the network, this paper proposes a collaboration mechanism based on\nthe\
    \ limited energy, computing, and storage capacity of the sensing nodes and the\
    \ task\ncompletion requirements. The network topology is reconstructed by adjusting\
    \ the transmit\npower of nodes, neighbor selection, sleep scheduling, or mobile\
    \ node location. The decom-\nposition, assignment, scheduling, and execution of\
    \ tasks are accomplished cooperatively by\ncoordinating the behavior of mobile\
    \ sensor nodes. Topology reconstruction optimization is\nmainly carried out in\
    \ edge nodes and load balancing. In smart agriculture, the perception\nequipment\
    \ is more diverse, and the perception task is more complex.\n(b). Cooperative\
    \ scheduling of large agricultural machinery equipment: agriculture-\noriented\
    \ large agricultural machinery includes unmanned aerial vehicles (UAVs), mutual\n\
    sensing, and task coordination of multi-aerial robots. For example, building the\
    \ social\nInternet of Things creates a dynamic social network for each object\
    \ connected to the Internet\nof Things. Social networks are extended through node\
    \ proﬁles and trust levels to ﬁnd\nobjects that contribute to IoT applications\
    \ and solve resource management problems. Assign\nsensitive tasks fairly to objects\
    \ in the social network. How to optimize the sensing task\nof massive heterogeneous\
    \ sensing devices in the Internet of Things for smart agriculture.\nIt is still\
    \ a challenge to realize the efﬁcient collection of sensing data and the maximum\n\
    efﬁciency of network resources by abstracting network resources.\n5.3.2. Optimization\
    \ of 5G Network Signal Coverage Scheduling for Agricultural UAV\nIn addition to\
    \ the upstream and downstream rate, end-to-end delay of services, end-\nto-end\
    \ delay of control, and positioning accuracy, the coverage height of wireless\
    \ signals is\none of the most important requirements for 5G networks in agriculture.\n\
    According to the requirements of UAV network indicators in each scenario in IMT-\n\
    2020 (5G), Advance Group—White Paper on 5G UAV Application, the coverage height\n\
    requirements of wireless signals of networked UAV in the application ﬁeld are\
    \ shown in\nTable 9.\nOn the basis of the existing network, it is technically\
    \ feasible to deploy a small number\nof base stations for the 5G communication\
    \ requirements of agricultural UAVs. However,\nthe actual network planning still\
    \ needs to focus on several issues.\n(a) Adjacent area planning.\nIn order to\
    \ make connected UAVs ﬂy continuously in the air, in addition to seamless\n5G\
    \ wireless network signals, civil UAVs also need to be able to switch smoothly\
    \ between\ndifferent cells and different base stations. In this way, it is necessary\
    \ to cover the high\nlevel of the community to have a reasonable neighborhood\
    \ relationship. In addition, the\nUAV communication terminal needs to switch from\
    \ the low-level 5G wireless network\nto the high-level 5G wireless network when\
    \ taking off. This also requires reasonable\nElectronics 2023, 12, 2336\n38 of\
    \ 46\nneighborhood planning between the 5G cell covering the high-rise and its\
    \ neighboring 5G\ncell. Similarly, the UAV communication terminal needs to switch\
    \ from the high-level 5G\nwireless network to the low-level 5G wireless network\
    \ when landing. It is also necessary to\nmake reasonable neighborhood planning\
    \ between the 5G cell covering the low layer and\nits adjacent high-rise 5G cell.\
    \ Its switching band is controlled at about 100 m in the air.\n(b) Interference\
    \ problem.\n5G wireless networks are also self-interfering systems. All base stations\
    \ share a band-\nwidth of 100 MHz. Therefore, it is necessary to control the coverage\
    \ of the signal through\nreasonable planning and optimization. In this way, it\
    \ is necessary to avoid discontinuous\ncoverage or blind coverage caused by insufﬁcient\
    \ signal, and to avoid interference in other\ncommunities due to over coverage.\
    \ At the same time, the mutual interference between\nthe 5G cell covering the\
    \ lower layer and the 5G cell covering the upper layer should be\navoided. Of\
    \ course, this will require a long period of experimentation and exploration.\n\
    Table 9. Requirements for coverage height of wireless signals of networked UAVs\
    \ in application ﬁelds.\nNo.\nApplication Area\nBusiness Attribute\nCover Height/m\n\
    Coverage\n1\nAgricultural and forestry plant\nprotection\nSpraying pesticide\n\
    10\ncountryside\n2\nAgricultural and forestry\nsurveying and mapping\nAgricultural\
    \ land survey\n200\ncountryside\n3\nAgricultural inspection\n1080p Video return\n\
    100\nPatrol inspection\ncovers ﬁeld agriculture\n4\nAgricultural formation ﬂight\n\
    UAV formation ﬂight\n200\ncountryside\n5\nFuture cloud AI\nUAV cloud-based autonomous\n\
    ﬂight\n300\ncountryside\n6\nAgricultural and forestry\nmonitoring\nCrop growth\
    \ monitoring\n100\ncountryside\n5.4. Fault Detection and Self-Healing for 5G Intelligent\
    \ Agricultural Platform\nSmart agriculture 5G-IoT faces increasing network scale\
    \ and density, dense terminal\nconnections, and higher intelligence, and the failure\
    \ rate will increase. The production\nefﬁciency of large-scale smart agriculture\
    \ is an important issue. With the integration of\n5G, many intelligent applications\
    \ will be gradually popularized. These apps are built\naround the 5G Internet\
    \ of Things. How to quickly identify the faulty node or device and\nthe self-healing\
    \ ability of the platform are important research issues.\n5.4.1. Node Fault Identiﬁcation\
    \ and Early Warning Based on Heterogeneous Sensing\nData Fusion\nCombining the\
    \ collected sensing data for computational analysis and network topol-\nogy to\
    \ identify node faults is a problem worth studying. Due to the mixed deployment\n\
    of 5G and various sensing devices, mixed data sources, multi-hop communication,\
    \ and\ntransmission route changes, how to realize the fault identiﬁcation of sensing\
    \ nodes and\npossible fault detection is an important research issue.\n5.4.2.\
    \ Research on Fault Tolerance Based on 5G Heterogeneous Fusion Sensing Network\n\
    Traditional perceptual networks generally assume unreliable perception. The actual\n\
    agricultural production will appear to be all kinds of failures. Because of the\
    \ intensive\ndeployment, the cost of ensuring all reliable operations is high.\
    \ Therefore, it is worth\nstudying that fault tolerance can guarantee the normal\
    \ operation of the whole agricultural\nproduction in a certain period of time\
    \ under limited fault.\nElectronics 2023, 12, 2336\n39 of 46\n5.4.3. Self-Healing\
    \ Mechanism Based on 5G Heterogeneous Fusion Sensing Network\nIn smart agriculture,\
    \ production is blocked due to the failure of the sensing equipment\nnetwork,\
    \ which affects efﬁciency. Therefore, it is necessary to study how to self-heal\
    \ after\nfaults occur, such as network topology self-healing, to guarantee node\
    \ pathways. For\nexample, perceptual repair under dense nodes. An additional example\
    \ is 5G gateway\ncoverage self-healing.\n5.5. AI Application Optimization for\
    \ 5G Intelligent Agricultural Internet of Things\nThe application of 5G brings\
    \ new opportunities for smart agriculture, which is ex-\npected to solve the problem\
    \ of data transmission and storage. With the development of\nartiﬁcial intelligence,\
    \ it is an important issue to study lightweight deep artiﬁcial intelligence\n\
    algorithms or platforms combined with various scenarios of smart agriculture.\n\
    Artiﬁcial intelligence algorithms represented by deep learning have laid the foundation\n\
    for many scenarios of smart agriculture applications. With the popularization\
    \ of 5G, the\nrange of application scenarios of smart agriculture will be greatly\
    \ expanded. However, the\ncurrent existence represented by deep learning will\
    \ face the important challenge of how to\nachieve reliable and effective operation\
    \ under the condition of small cost in the scenario of\nsmart agriculture, relying\
    \ on massive data and powerful computing power.\n5.5.1. Lightweight Deep Learning\
    \ Algorithm Based on 5G-IoT Edge Computing\nEdge computing equipment has some\
    \ computing ability, but its computing ability is\nnot enough for massive data\
    \ model training. The challenge is how to design deep learning\nor machine learning\
    \ algorithms suitable for agricultural production. Better results can\nbe obtained\
    \ by training on small sample data, reducing the amount of data transmission,\n\
    reducing the cost of communication resources, and improving the real-time accuracy,\
    \ which\nis a problem worth studying.\n5.5.2. Multi-Source Data-Sensing Machine\
    \ Learning Algorithm for Smart Agriculture\nIn the 5G scenario, sensing nodes\
    \ are densely deployed, and heterogeneous sensing\ndata need to be calculated\
    \ and analyzed to serve the upper layer. However, there are\noften low data quality,\
    \ multi-source, heterogeneous, and multi-modal sensing data, and\nchanges in network\
    \ topology. How to calculate these mixed and redundant low-quality\ndata by clustering,\
    \ statistics, Bayesian, and other machine learning methods is an important\nresearch\
    \ problem.\n5.6. 5G-IoT System Service Model for Smart Agriculture\nAn important\
    \ means to promote the implementation of smart agriculture is the in-\nformation\
    \ physical fusion system based on 5G. The typical application mode of smart\n\
    agriculture is to comprehensively perceive agricultural information through the\
    \ agricul-\ntural Internet of Things. Massive sensing devices for agricultural\
    \ IoT are deployed in the\nwhole process of agricultural production and processing.\
    \ Various information (environ-\nmental temperature and humidity, soil moisture,\
    \ carbon dioxide, images, etc.) is collected\nthrough various networks, including\
    \ 5G. Traditional agricultural models will be changed\nby means of cloud computing,\
    \ big data, edge computing, and artiﬁcial intelligence. It can\nrealize intelligent\
    \ perception, intelligent warning, intelligent decision-making, intelligent\n\
    analysis, and expert online guidance of agricultural production environment to\
    \ provide\nprecise planting, visual management, and intelligent decision-making\
    \ for agricultural\nproduction. This is to realize the intelligent management\
    \ of agricultural visual remote\ndiagnosis, remote control, disaster warning,\
    \ and so on, and gradually establish the visual\ncommunication and application\
    \ mode of agricultural information services. Relying on\nthe knowledge of agricultural\
    \ experts stored in the knowledge base, reasoning, analysis,\nand other mechanisms\
    \ were used to guide the production and circulation of agriculture\nand animal\
    \ husbandry. It promotes the transformation of traditional agriculture, which\
    \ is\nhuman-centered and relies on isolated machinery production mode, to modern\
    \ smart agri-\nElectronics 2023, 12, 2336\n40 of 46\nculture, which is based on\
    \ information and software production mode. How to construct\nan appropriate application\
    \ service paradigm and model for intelligent agriculture 5G-IoT\nis an important\
    \ issue to be studied.\n5.7. Security Issues of 5G Internet of Things for Smart\
    \ Agriculture\nThe future of intelligent agriculture is highly intelligent, informationized,\
    \ and un-\nmanned, and security issues should be a concern. Due to the application\
    \ of 5G technology,\nthere are many data ﬂows and information ﬂows which are prone\
    \ to data deception, etc.,\nwhich will lead to serious consequences, such as the\
    \ death of crops or the poor quality of\nanimal husbandry objects caused by incorrect\
    \ pesticide spraying.\nAt present, there are many research results on the security\
    \ of the Internet of Things.\nIn general, attacks in IoT applications are classiﬁed\
    \ using the following two criteria: (1)\ninternal or external attacks and (2)\
    \ passive or active attacks. Therefore, the threat model can\nbe classiﬁed into\
    \ attacks targeting privacy, authentication, conﬁdentiality, availability, and\n\
    integrity attributes based on the characteristics of attacks that attempt to compromise\
    \ IoT\nagricultural nodes, namely IoT devices, fog nodes, and cloud nodes. 5G\
    \ itself is relatively\nsecure. However, due to the speciﬁc application scenarios,\
    \ the security problems of smart\nagriculture have their speciﬁc characteristics,\
    \ which require joint analysis and research.\n5.7.1. Information Traceability\
    \ of the Whole Process of Intelligent Agricultural Production\nBased on 5G Blockchain\n\
    Food safety has always been a matter of great concern to the public. The traditional\n\
    tracing system has some shortcomings, such as information opacity, data easy to\
    \ be tam-\npered with, poor security, and relative closure. In the future, the\
    \ development of 5G,\ncombined with blockchain technology and its unique advantages,\
    \ will provide a new\nsolution for the reliable traceability of the agricultural\
    \ supply chain. In combination with\nthe communication capability of 5G, blockchain\
    \ technology can be combined with the\nsensing equipment of the agricultural Internet\
    \ of Things for semantic segmentation and\ntracking to achieve high security.\n\
    5.7.2. Intrusion Detection for Intelligent Agricultural Production Based on 5G\n\
    With the popularization of 5G Internet of Things in smart agriculture, the degree\n\
    of intelligent and networked agricultural production is getting higher and higher,\
    \ and\nmore and more security issues need to be paid attention to. Unique security\
    \ issues and\nvulnerabilities may arise, including network, control, communications,\
    \ services, etc. How\nto combine the agricultural production process and the structural\
    \ characteristics of 5G IoT\nto establish a security mechanism, rapid detection,\
    \ and early warning of the intrusion of\nkey steps in the production process is\
    \ an important challenge in the future.\n6. Summary\nIn the future, smart agriculture,\
    \ after 5G technology transformation and upgrading,\nwill show the following characteristics:\
    \ unmanned operation, precise production, reﬁned\ncultivation, standardized production,\
    \ and intelligent supervision. Due to its low latency,\nmassive data transmission,\
    \ and massive connectivity, 5G is contributing to the development\nof IoT in agriculture.\
    \ The combination of 5G with other technologies has spawned a number\nof agricultural\
    \ applications to reduce the environmental impact of pesticides, protect natural\n\
    resources, improve animal welfare and help farmers increase yields and save costs.\
    \ This\npaper summarizes the impact of 5G on the Internet of Things, smart agriculture,\
    \ and related\ntechnologies. The key technologies and scientiﬁc issues affecting\
    \ the development of 5G-IoT\nwere analyzed to provide some ideas for the development\
    \ of 5G in smart agriculture. The\nscope of smart agriculture is relatively large,\
    \ and many details have not been discussed\nin-depth. Further efforts will be\
    \ made in the future.\nAuthor Contributions: Conceptualization, J.L., L.S. and\
    \ X.L.; methodology, X.L.; investigation, J.L.;\nresources, X.L.; data curation,\
    \ L.S.; writing—original draft preparation, J.L. and Y.L.; writing—review\nElectronics\
    \ 2023, 12, 2336\n41 of 46\nand editing, J.L. and Y.L.; visualization, J.L.; supervision,\
    \ X.L. All authors have read and agreed to\nthe published version of the manuscript.\n\
    Funding: This research was fundedby the National Natural Science Foundation of\
    \ China (62176067);\nJoint Fund for Basic and Applied Basic Research in Guangdong\
    \ Province (20A1515111162); Scientiﬁc\nand Technological Planning Project of Guangzhou\
    \ (201903010041, 202103000040); Key Project of\nGuangdong Province Basic Research\
    \ Foundation (2020B1515120095); Project Supported by Guang-\ndong Province Universities\
    \ and Colleges Pearl River Scholar Funded Scheme (2019).\nConﬂicts of Interest:\
    \ The authors declare no conﬂict of interest.\nReferences\n1.\nZhao, C. Research\
    \ on the development status and strategic objectives of smart agriculture. Smart\
    \ Agric. 2019, 1, 1–7. (In Chinese)\n2.\nAyaz, M.; Ammad-Uddin, M.; Sharif, Z.;\
    \ Mansour, A.; Aggoune, E.-H.M. Internet-of-Things (IoT)-based smart agriculture:\n\
    Toward making the ﬁelds talk. IEEE Access 2019, 7, 129551–129583. [CrossRef]\n\
    3.\nQazi, S.; Khawaja, B.A.; Farooq, Q.U. IoT-Equipped and AI-Enabled Next Generation\
    \ Smart Agriculture: A Critical Review,\nCurrent Challenges and Future Trends.\
    \ IEEE Access. 2022, 10, 21219–21235. [CrossRef]\n4.\nJawhar, I.; Mohamed, N.;\
    \ Kesserwan, N.; Al-Jaroodi, J. Networking Architectures and Protocols for Multi-Robot\
    \ Systems in\nAgriculture 4.0. In Proceedings of the 2022 IEEE International Systems\
    \ Conference (SysCon), Montreal, QC, Canada, 25–28 April\n2022; pp. 1–6. [CrossRef]\n\
    5.\nOruma, S.O.; Misra, S.; Fernandez-Sanz, L. Agriculture 4.0: An Implementation\
    \ Framework for Food Security Attainment in\nNigeria’s Post-COVID-19 Era. IEEE\
    \ Access 2021, 9, 83592–83627. [CrossRef]\n6.\nMishra, S.; Nayak, S.; Yadav, R.\
    \ An Energy Efﬁcient LoRa-based Multi-Sensor IoT Network for Smart Sensor Agriculture\
    \ System.\nIn Proceedings of the 2023 IEEE Topical Conference on Wireless Sensors\
    \ and Sensor Networks, Las Vegas, NV, USA, 22–25 January\n2023; pp. 28–31. [CrossRef]\n\
    7.\nQuy, V.K.; Hau, N.V.; Anh, D.V.; Quy, N.M.; Ban, N.T.; Lanza, S.; Randazzo,\
    \ G.; Muzirafuti, A. IoT-Enabled Smart Agriculture:\nArchitecture, Applications,\
    \ and Challenges. Appl. Sci. 2022, 12, 3396. [CrossRef]\n8.\nValecce, G.; Strazzella,\
    \ S.; Grieco, L.A. On the interplay between 5g, mobile edge computing and robotics\
    \ in smart agriculture\nscenarios. In Proceedings of the Ad-Hoc, Mobile, and Wireless\
    \ Networks: 18th International Conference on Ad-Hoc Networks\nand Wireless, ADHOC-NOW\
    \ 2019, Luxembourg, 1–3 October 2019; Springer International Publishing: Berlin/Heidelberg,\n\
    Germany, 2019; pp. 549–559.\n9.\nLiya, M.L.; Arjun, D. A survey of LPWAN technology\
    \ in agricultural ﬁeld. In Proceedings of the 2020 Fourth International\nConference\
    \ on I-SMAC (IoT in Social, Mobile, Analytics and Cloud)(I-SMAC), Palladam, India,\
    \ 7–9 October 2020; pp. 313–317.\n10.\nRadoglou-Grammatikis, P.; Sarigiannidis,\
    \ P.; Lagkas, T.; Moscholios, I. A compilation of UAV applications for precision\
    \ agriculture.\nComput. Netw. 2020, 172, 107148. [CrossRef]\n11.\nKaur, H.; Kushwaha,\
    \ A.S. A Review on Integration of Big Data and IoT. In Proceedings of the 2018\
    \ 4th International Conference\non Computing Sciences (ICCS), Jalandhar, India,\
    \ 30–31 August 2018; pp. 200–203. [CrossRef]\n12.\nShobanadevi, A.; Maragatham,\
    \ G. Data mining techniques for IoT and big data—A survey. In Proceedings of the\
    \ 2017 International\nConference on Intelligent Sustainable Systems (ICISS), Palladam,\
    \ India, 7–8 December 2017; pp. 607–610. [CrossRef]\n13.\nLi, B.-H.; Chai, X.-D.;\
    \ Liu, Y.; Chen, L.; Wei, D.-Y. Wisdom Iot System Development Strategy Study.\
    \ China Engineering Science:\n1–11. Available online: http://kns.cnki.net/kcms/detail/11.4421.G3.20220720.1149.002.html\
    \ (accessed on 28 September 2022).\n(In Chinese).\n14.\nShaﬁ, M.; Molisch, A.F.;\
    \ Smith, P.J.; Haustein, T.; Zhu, P.; De Silva, P.; Tufvesson, F.; Benjebbour,\
    \ A.; Wunder, G. 5G: A Tutorial\nOverview of Standards, Trials, Challenges, Deployment,\
    \ and Practice. IEEE J. Sel. Areas Commun. 2017, 35, 1201–1221. [CrossRef]\n15.\n\
    Chih-Lin, I.; Han, S.; Xu, Z.; Wang, S.; Sun, Q.; Chen, Y. New Paradigm of 5G\
    \ Wireless Internet. IEEE J. Sel. Areas Commun. 2016,\n34, 474–482. [CrossRef]\n\
    16.\nPalattella, M.R.; Dohler, M.; Grieco, A.; Rizzo, G.; Torsner, J.; Engel,\
    \ T.; Ladid, L. Internet of Things in the 5G Era: Enablers,\nArchitecture, and\
    \ Business Models. IEEE J. Sel. Areas Commun. 2016, 34, 510–527. [CrossRef]\n\
    17.\nLi, S.; Da Xu, L.; Zhao, S. 5G Internet of Things: A survey. J. Ind. Inf.\
    \ Integr. 2018, 10, 1–9. [CrossRef]\n18.\nWang, D.; Chen, D.; Song, B.; Guizani,\
    \ N.; Yu, X.; Du, X. From IoT to 5G I-IoT: The Next Generation IoT-Based Intelligent\n\
    Algorithms and 5G Technologies. IEEE Commun. Mag. 2018, 56, 114–120. [CrossRef]\n\
    19.\nKalyani, Y.; Collier, R. A Systematic Survey on the Role of Cloud, Fog, and\
    \ Edge Computing Combination in Smart Agriculture.\nSensors 2021, 21, 5922. [CrossRef]\n\
    20.\nWang, N.; Wang, P.; Alipour-Fanid, A.; Jiao, L.; Zeng, K. Physical-Layer\
    \ Security of 5G Wireless Networks for IoT: Challenges and\nOpportunities. IEEE\
    \ Internet Things J. 2019, 6, 8169–8181. [CrossRef]\n21.\nShaﬁque, K.; Khawaja,\
    \ B.A.; Sabir, F.; Qazi, S.; Mustaqim, M. Internet of Things (IoT) for Next-Generation\
    \ Smart Systems: A\nReview of Current Challenges, Future Trends and Prospects\
    \ for Emerging 5G-IoT Scenarios. IEEE Access 2020, 8, 23022–23040.\n[CrossRef]\n\
    22.\nTang, Y.; Dananjayan, S.; Hou, C.; Guo, Q.; Luo, S.; He, Y. A survey on the\
    \ 5G network and its impact on agriculture: Challenges\nand opportunities. Comput.\
    \ Electron. Agric. 2021, 180, 105895. [CrossRef]\nElectronics 2023, 12, 2336\n\
    42 of 46\n23.\nOgbodo, E.U.; Abu-Mahfouz, A.M.; Kurien, A.M. A Survey on 5G and\
    \ LPWAN-IoT for Improved Smart Cities and Remote Area\nApplications: From the\
    \ Aspect of Architecture and Security. Sensors 2022, 22, 6313. [CrossRef]\n24.\n\
    Khanh, Q.V.; Hoai, N.V.; Manh, L.D.; Le, A.N.; Jeon, G. Wireless communication\
    \ technologies for IoT in 5G: Vision, applications,\nand challenges. Wirel. Commun.\
    \ Mob. Comput. 2022, 2022, 3229294. [CrossRef]\n25.\nMekala, M.S.; Viswanathan,\
    \ P. A Survey: Smart agriculture IoT with cloud computing. In Proceedings of the\
    \ 2017 International\nConference on Microelectronic Devices, Circuits and Systems\
    \ (ICMDCS), Vellore, India, 10–12 August 2017.\n26.\nDagar, R. Smart Farming—IoT\
    \ in Agriculture. In Proceedings of the ICIRCA 2018, Coimbatore, India, 11–12\
    \ July 2018.\n27.\nFarooq, M.S.; Riaz, S.; Abid, A.; Abid, K.; Naeem, M.A. A Survey\
    \ on the Role of IoT in Agriculture for the Implementation of\nSmart Farming.\
    \ IEEE Access 2019, 7, 156237–156271. [CrossRef]\n28.\nDevare, J.; Hajare, N.\
    \ A Survey on IoT Based Agricultural Crop Growth Monitoring and Quality Control.\
    \ In Proceedings of the\n2019 International Conference on Communication and Electronics\
    \ Systems (ICCES), Coimbatore, India, 17–19 July 2019.\n29.\nFiona, J.R.; Anitha,\
    \ J. Automated Detection of Plant diseases and Crop Analysis in Agriculture using\
    \ Image Processing Techniques:\nA Survey. In Proceedings of the 2019 IEEE International\
    \ Conference on Electrical, Computer and Communication Technologies\n(ICECCT),\
    \ Coimbatore, India, 20–22 February 2019.\n30.\nBh Ag At, M.; Kumar, D.; Kumar,\
    \ D. Role of Internet of Things (IoT) in Smart Farming: A Brief Survey. In Proceedings\
    \ of the\nDevices for Integrated Circuit Conference, CSE Department, NIT Jamshedpur,\
    \ Jamshedpur, India, 23–24 March 2019.\n31.\nSarker, V.K.; Queralta, J.P.; Gia,\
    \ T.N.; Tenhunen, H.; Westerlund, T. A Survey on LoRa for IoT: Integrating Edge\
    \ Computing. In\nProceedings of the International Workshop on Smart Living with\
    \ IoT, Cloud and Edge Computing (SLICE 2019), Rome, Italy,\n10–13 June 2019.\n\
    32.\nBacco, M.; Berton, A.; Ferro, E.; Gennaro, C.; Gotta, A.; Matteoli, S.; Paonessa,\
    \ F.; Ruggeri, M.; Virone, G.; Zanella, A. Smart\nfarming: Opportunities, challenges\
    \ and technology enablers. In Proceedings of the 2018 IoT Vertical and Topical\
    \ Summit on\nAgriculture-Tuscany (IOT Tuscany), Tuscany, Italy, 8–9 May 2018;\
    \ pp. 1–6.\n33.\nKour, V.P.; Arora, S. Recent Developments of the Internet of\
    \ Things in Agriculture: A Survey. IEEE Access 2020, 8, 129924–129957.\n[CrossRef]\n\
    34.\nFriha, O.; Ferrag, M.A.; Shu, L.; Maglaras, L.; Wang, X. Internet of Things\
    \ for the Future of Smart Agriculture: A Comprehensive\nSurvey of Emerging Technologies.\
    \ IEEE/CAA J. Autom. Sin. 2020, 8, 718–752. [CrossRef]\n35.\nRayhana, R.; Xiao,\
    \ G.; Liu, Z. RFID Sensing Technologies for Smart Agriculture. IEEE Instrum. Meas.\
    \ Mag. 2021, 24, 50–60.\n[CrossRef]\n36.\nYang, X.; Shu, L.; Chen, J.; Ferrag,\
    \ M.A.; Wu, J.; Nurellari, E.; Huang, K. A Survey on Smart Agriculture: Development\
    \ Modes,\nTechnologies, and Security and Privacy Challenges. IEEE/CAA J. Autom.\
    \ Sin. 2021, 8, 273–302. [CrossRef]\n37.\nLiu, Y. From Industry 4.0 to Agriculture\
    \ 4.0 Current Status Enabling Technologies and Research Challenges. IEEE Trans.\
    \ Ind.\nInform. 2021, 17, 4322–4334. [CrossRef]\n38.\nBhat, S.A.; Huang, N.F.\
    \ Big Data and AI Revolution in Precision Agriculture: Survey and Challenges.\
    \ IEEE Access 2021, 9,\n110209–110222. [CrossRef]\n39.\nSinha, B.B.; Dhanalakshmi,\
    \ R. Recent advancements and challenges of Internet of Things in smart agriculture:\
    \ A survey. Future\nGener. Comput. Syst. 2021, 126, 169–184. [CrossRef]\n40.\n\
    Tao, W. Review of the internet of things communication technologies in smart agriculture\
    \ and challenges. Comput. Electr. Eng.\n2021, 189, 106352. [CrossRef]\n41.\nIdoje,\
    \ G. Survey for smart farming technologies: Challenges and issues. Comput. Electr.\
    \ Eng. 2021, 92, 107104. [CrossRef]\n42.\nMisra, N.N.; Dixit, Y.; Al-Mallahi,\
    \ A.; Bhullar, M.S.; Upadhyay, R.; Martynenko, A. IoT, Big Data, and Artiﬁcial\
    \ Intelligence in\nAgriculture and Food Industry. IEEE Internet Things J. 2022,\
    \ 9, 6305–6324. [CrossRef]\n43.\nYarali, A. AI, 5G, and IoT. In Intelligent Connectivity:\
    \ AI, IoT, and 5G; IEEE: Piscataway, NJ, USA, 2022; pp. 117–131.\n44.\nKar, S.;\
    \ Mishra, P.; Wang, K.-C. 5G-IoT Architecture for Next Generation Smart Systems.\
    \ In Proceedings of the 2021 IEEE 4th 5G\nWorld Forum (5GWF), Montreal, QC, Canada,\
    \ 13–15 October 2021; pp. 241–246. [CrossRef]\n45.\nKhakimov, A.; Salakhutdinov,\
    \ I.; Omolikov, A.; Utaganov, S. Traditional and current-prospective methods of\
    \ agricultural plant\ndiseases detection: A review. In Proceedings of the IOP\
    \ Conference Series: Earth and Environmental Science, 3rd International\nConference\
    \ on Agriculture and Bio-industry (ICAGRI 2021), Banda Aceh, Indonesia, 13–14\
    \ October 2021; Volume 951.\n46.\nDeb, S.D.; Jha, R.K.; Kumar, S. ConvPlant-Net:\
    \ A Convolutional Neural Network based Architecture for Leaf Disease Detection\
    \ in\nSmart Agriculture. In Proceedings of the 2023 National Conference on Communications\
    \ (NCC), Guwahati, India, 23–26 February\n2023; pp. 1–6. [CrossRef]\n47.\nTreboux,\
    \ J.; Genoud, D. High Precision Agriculture: An Application Of Improved Machine-Learning\
    \ Algorithms. In Proceedings\nof the 2019 6th Swiss Conference on Data Science\
    \ (SDS), Bern, Switzerland, 14 June 2019; pp. 103–108. [CrossRef]\n48.\nAsokan,\
    \ A.; Anitha, J. Machine Learning based Image Processing Techniques for Satellite\
    \ Image Analysis—A Survey. In\nProceedings of the 2019 International Conference\
    \ on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon),\nFaridabad,\
    \ India, 14–16 February 2019; pp. 119–124. [CrossRef]\n49.\nGarcia, M.B.; Ambat,\
    \ S.; Adao, R.T. Tomayto, Tomahto: A Machine Learning Approach for Tomato Ripening\
    \ Stage Identiﬁcation\nUsing Pixel-Based Color Image Classiﬁcation. In Proceedings\
    \ of the 2019 IEEE 11th International Conference on Humanoid,\nNanotechnology,\
    \ Information Technology, Communication and Control, Environment, and Management\
    \ (HNICEM), Laoag,\nPhilippines, 29 November–1 December 2019; pp. 1–6. [CrossRef]\n\
    Electronics 2023, 12, 2336\n43 of 46\n50.\nThakor, H.P.; Iyer, S. Development\
    \ and Analysis of Smart Digi-farming Robust Model for Production Optimization\
    \ in Agriculture.\nIn Proceedings of the 2019 6th International Conference on\
    \ Computing for Sustainable Global Development (INDIACom), New\nDelhi, India,\
    \ 13–15 March 2019; pp. 461–465.\n51.\nBandara, T.M.; Mudiyanselage, W.; Raza,\
    \ M. Smart farm and monitoring system for measuring the Environmental condition\
    \ using\nwireless sensor network—IOT Technology in farming. In Proceedings of\
    \ the 2020 5th International Conference on Innovative\nTechnologies in Intelligent\
    \ Systems and Industrial Applications (CITISIA), Sydney, Australia, 25–27 November\
    \ 2020; pp. 1–7.\n[CrossRef]\n52.\nGarcia-Sanchez, A.J.; Garcia-Sanchez, F.; Garcia-Haro,\
    \ J. Wireless sensor network deployment for integrating video-surveillance\nand\
    \ data-monitoring in precision agriculture over distributed crops. Comput. Electron.\
    \ Agric. 2011, 75, 288–303. [CrossRef]\n53.\nLiu, H.; Reibman, A.R.; Ault, A.C.;\
    \ Krogmeier, J.V. Spatial segmentation for processing videos for farming automation.\
    \ Comput.\nElectron. Agric. 2021, 184, 106095. [CrossRef]\n54.\nSabzi, S.; Abbaspour-Gilandeh,\
    \ Y.; Arribas, J.I. An automatic visible-range video weed detection, segmentation\
    \ and classiﬁcation\nprototype in potato ﬁeld. Heliyon 2020, 6, e03685. [CrossRef]\n\
    55.\nJiang, H.; Li, X.; Safara, F. IoT-based agriculture: Deep learning in detecting\
    \ apple fruit diseases. Microprocess. Microsyst. 2021,\n104321. [CrossRef]\n56.\n\
    Hejazi, H.; Rajab, H.; Cinkler, T.; Lengyel, L. Survey of platforms for massive\
    \ IoT. In Proceedings of the 2018 IEEE International\nConference on Future IoT\
    \ Technologies (Future IoT), Eger, Hungary, 18–19 January 2018; pp. 1–8. [CrossRef]\n\
    57.\nZhang, F.; Wan, X.; Zheng, T.; Cui, J.; Li, X.; Yang, Y. Smart Greenhouse\
    \ Management System based on NB-IoT and Smartphone.\nIn Proceedings of the 2020\
    \ 17th International Joint Conference on Computer Science and Software Engineering\
    \ (JCSSE), Bangkok,\nThailand, 4–6 November 2020; pp. 36–41. [CrossRef]\n58.\n\
    Valecce, G.; Petruzzi, P.; Strazzella, S.; Grieco, L.A. NB-IoT for Smart Agriculture:\
    \ Experiments from the Field. In Proceedings of\nthe 2020 7th International Conference\
    \ on Control, Decision and Information Technologies (CoDIT), Prague, Czech Republic,\
    \ 29\nJune 2020–2 July 2020; pp. 71–75. [CrossRef]\n59.\nFei, Y.; Zhuang, Y.;\
    \ Liu, X.; Zhao, Q.; Liao, G.; Fu, Q. Development of an Intelligent Monitoring\
    \ System for Agricultural Machinery.\nIn Proceedings of the 2019 3rd International\
    \ Conference on Robotics and Automation Sciences (ICRAS), Wuhan, China, 1–3 June\n\
    2019; pp. 161–165. [CrossRef]\n60.\nDong, Z.; Duan, J.; Wang, M.; Zhao, J.; Wang,\
    \ H. On Agricultural Machinery Operation System of Beidou Navigation System. In\n\
    Proceedings of the 2018 IEEE 3rd Advanced Information Technology, Electronic and\
    \ Automation Control Conference (IAEAC),\nChongqing, China, 12–14 October 2018;\
    \ pp. 1748–1751. [CrossRef]\n61.\nZhang, J.; Zhou, F.; Jing, C.; Wei, S.; Wu,\
    \ Y.; Jing, C. Research and Design of Automatic Navigation System for Agricultural\n\
    Machinery Based on GPS. In Proceedings of the 2020 IEEE International Conference\
    \ on Power, Intelligent Computing and Systems\n(ICPICS), Shenyang, China, 28–30\
    \ July 2020; pp. 984–986. [CrossRef]\n62.\nLi, C.; Tang, Y.; Wang, M.; Zhao, X.\
    \ Agricultural Machinery Information Collection and Operation Based on Data Platform.\
    \ In\nProceedings of the 2018 IEEE International Conference of Safety Produce\
    \ Informatization (IICSPI), Chongqing, China, 10–12\nDecember 2018; pp. 472–475.\
    \ [CrossRef]\n63.\nDong, Z.; Zhao, J.; Duan, J.; Wang, M.; Wang, H. Research on\
    \ Agricultural Machinery Fault Diagnosis System Based on Expert\nSystem. In Proceedings\
    \ of the 2018 2nd IEEE Advanced Information Management, Communicates, Electronic\
    \ and Automation\nControl Conference (IMCEC), Xi’an, China, 25–27 May 2018; pp.\
    \ 2057–2060. [CrossRef]\n64.\nFan, J.; Zhang, Y.; Wen, W.; Gu, S.; Lu, X.; Guo,\
    \ X. The future of Internet of Things in agriculture: Plant high-throughput\n\
    phenotypic platform. J. Clean. Prod. 2021, 280, 123651. [CrossRef]\n65.\nZhang,\
    \ Y.; Wang, J.; Du, J.; Zhao, Y.; Lu, X.; Wen, W.; Gu, S.; Fan, J.; Wang, C.;\
    \ Wu, S.; et al. Dissecting the phenotypic components\nand genetic architecture\
    \ of maize stem vascular bundles using high-throughput phenotypic analysis. Plant\
    \ Biotechnol. J. 2021, 19,\n35–50. [CrossRef]\n66.\nLi, B.H.; Chai, X.D.; Liu,\
    \ Y.; Chen, L.; Wei, D.Y. Research on Development Strategy of Intelligent Internet\
    \ of Things System.\nEngineering Science of China in Chinese. Available online:\
    \ https://kns.cnki.net/kcms/detail/11.4421.G3.20220720.1149.002.html\n(accessed\
    \ on 28 September 2022).\n67.\nLi, B.H.; Chai, X.D.; Hou, B.C.; Lin, T.Y.; Zhang,\
    \ L.; Li, T.; Liu, Y.; Xiao, Y.Y. Cloud manufacturing system 3.0: A new intelligent\n\
    manufacturing system in the era of “Intelli-gence+”. Comput. Integr. Manuf. Syst.\
    \ 2019, 25, 2997–3012.\n68.\nWu, D.; Zhang, Z.; Wu, S.; Yang, J.; Wang, R. Biologically\
    \ inspired resource allocation for network slices in 5G-enabled Internet of\n\
    Things. IEEE Internet Things J. 2018, 6, 9266–9279. [CrossRef]\n69.\nEscolar,\
    \ A.M.; Alcaraz-Calero, J.M.; Salva-Garcia, P.; Bernabe, J.B.; Wang, Q. Adaptive\
    \ Network Slicing in Multi-tenant 5G IoT\nNetworks. IEEE Access 2021, 9, 14048–14069.\
    \ [CrossRef]\n70.\nLiyanage, M.; Porambage, P.; Ding, A.Y.; Kalla, A. Driving\
    \ forces for multi-access edge computing (MEC) IoT integration in 5G.\nICT Express\
    \ 2021, 7, 127–137. [CrossRef]\n71.\nGupta, N.; Sharma, S.; Juneja, P.K.; Garg,\
    \ U. Sdnfv 5G-iot: A framework for the next generation 5G enabled iot. In Proceedings\
    \ of\nthe 2020 International Conference on Advances in Computing, Communication\
    \ & Materials (ICACCM), Dehradun, India, 21–22\nAugust 2020; pp. 289–294.\n72.\n\
    Ghosh, A.; Maeder, A.; Baker, M.; Chandramouli, D. 5G Evolution: A View on 5G\
    \ Cellular Technology beyond 3GPP Release 15.\nIEEE Access 2019, 7, 127639–127651.\
    \ [CrossRef]\nElectronics 2023, 12, 2336\n44 of 46\n73.\nRasyad, R.M.; Murti,\
    \ M.A.; Rizki, A.P. Design and Realization of Node MCU Module Based on NB-IoT\
    \ for General IoT Purpose.\nIn Proceedings of the 2019 IEEE International Conference\
    \ on Internet of Things and Intelligence System (IoTaIS), Bali, Indonesia,\n5–7\
    \ November 2019; pp. 189–194. [CrossRef]\n74.\nPaiva, S.; Branco, S.; Cabral,\
    \ J. Design and Power Consumption Analysis of a NB-IoT End Device for Monitoring\
    \ Applications. In\nProceedings of the IECON 2020 The 46th Annual Conference of\
    \ the IEEE Industrial Electronics Society, Singapore, 18–21 October\n2020; pp.\
    \ 2175–2182. [CrossRef]\n75.\nYang, F.; Shu, L.; Yang, Y.; Han, G.; Pearson, S.;\
    \ Li, K. Optimal Deployment of Solar Insecticidal Lamps over Constrained Locations\n\
    in Mixed-Crop Farmlands. IEEE Internet Things J. 2021, 8, 13095–13114. [CrossRef]\n\
    76.\nYang, F.; Shu, L.; Huang, K.; Li, K.; Han, G.; Liu, Y. A Partition-Based\
    \ Node Deployment Strategy in Solar Insecticidal Lamps\nInternet of Things. IEEE\
    \ Internet Things J. 2020, 7, 11223–11237. [CrossRef]\n77.\nFitzgerald, P.; Berney,\
    \ H.; Lakshmanan, R.; Coburn, N.; Geary, S.; Mulvey, B. Devices and Sensors Applicable\
    \ to 5G System\nImplementations. In Proceedings of the 2018 IEEE MTT-S International\
    \ Microwave Workshop Series on 5G Hardware and System\nTechnologies (IMWS-5G),\
    \ Dublin, Ireland, 30–31 August 2018; pp. 1–3. [CrossRef]\n78.\nAmato, F.; Amendola,\
    \ S.; Marrocco, G. Upper-bound Performances of RFID Epidermal Sensor Networks\
    \ at 5G Frequencies. In\nProceedings of the 2019 IEEE 16th International Conference\
    \ on Wearable and Implantable Body Sensor Networks (BSN), Chicago,\nIL, USA, 19–22\
    \ May 2019; pp. 1–4. [CrossRef]\n79.\nYaqoob, A.; Ashraf, M.A.; Ferooz, F.; Butt,\
    \ A.H.; Khan, Y.D. WSN Operating Systems for Internet of Things (IoT): A Survey.\
    \ In\nProceedings of the 2019 International Conference on Innovative Computing\
    \ (ICIC), Semarang, Indonesia, 16–17 October 2019;\npp. 1–7. [CrossRef]\n80.\n\
    Steiner, R.; Gracioli, G.; de Cássia Cazu Soldi, R.; Fröhlich, A.A. An Operating\
    \ System Runtime Reprogramming Infrastructure\nfor WSN. In Proceedings of the\
    \ 2012 IEEE Symposium on Computers and Communications (ISCC), Cappadocia, Turkey,\
    \ 1–4 July\n2012; pp. 000621–000624. [CrossRef]\n81.\nRamachandran, G.S.; Michiels,\
    \ S.; Joosen, W.; Hughes, D.; Porter, B. Analysis of Sensor Network Operating\
    \ System Performance\nThroughout the Software Life Cycle. In Proceedings of the\
    \ 2013 IEEE 12th International Symposium on Network Computing and\nApplications,\
    \ Boston, MA, USA, 22–24 August 2013; pp. 211–218. [CrossRef]\n82.\nChovanec,\
    \ M.; Šarafín, P. Real-time schedule for mobile robotics and WSN applications.\
    \ In Proceedings of the 2015 Federated\nConference on Computer Science and Information\
    \ Systems (FedCSIS), Lodz, Poland, 13–16 September 2015; pp. 1199–1202.\n[CrossRef]\n\
    83.\nMathane, V.; Lakshmi, P.V. Deterministic Real Time Kernel for Dependable\
    \ WSN. In Proceedings of the 2018 4th International\nConference for Convergence\
    \ in Technology (I2CT), Mangalore, India, 27–28 October 2018; pp. 1–4. [CrossRef]\n\
    84.\nSava, A.; Zoican, S. Wireless Sensors Network Framework for Developing Boards\
    \ using Contiki Operating System. In Proceedings\nof the 2020 13th International\
    \ Conference on Communications (COMM), Bucharest, Romania, 16–18 June 2020; pp.\
    \ 423–426.\n[CrossRef]\n85.\nAkpakwu, G.A.; Silva, B.J.; Hancke, G.P.; Abu-Mahfouz,\
    \ A.M. A survey on 5G networks for the Internet of Things: Communication\ntechnologies\
    \ and challenges. IEEE Access 2017, 6, 3619–3647. [CrossRef]\n86.\nTendolkar,\
    \ A.; Ramya, S. CareBro (personal farm assistant): An IoT based smart agriculture\
    \ with edge computing. In Proceedings\nof the 2020 Third International Conference\
    \ on Multimedia Processing, Communication & Information Technology (MPCIT),\n\
    Shivamogga, India, 11–12 December 2020; pp. 97–102.\n87.\nHuaji, Z.; Huarui, W.;\
    \ Xiang, S. Research on the ontology-based complex event processing engine of\
    \ RFID technology for agricul-\ntural products. In Proceedings of the 2009 International\
    \ Conference on Artiﬁcial Intelligence and Computational Intelligence,\nShanghai,\
    \ China, 7–8 November 2009; Volume 1, pp. 328–333.\n88.\nKamilaris, A.; Gao, F.;\
    \ Prenafeta-Boldu, F.X.; Ali, M.I. Agri-IoT: A semantic framework for Internet\
    \ of Things-enabled smart\nfarming applications. In Proceedings of the 2016 IEEE\
    \ 3rd world forum on internet of things (WF-IoT), New Orleans, LA, USA,\n12–14\
    \ December 2016; pp. 442–447.\n89.\nBayrakdar, M.E. Employing sensor network based\
    \ opportunistic spectrum utilization for agricultural monitoring. Sustain. Comput.\n\
    Inform. Syst. 2020, 27, 100404. [CrossRef]\n90.\nLiu, J.; Wang, X. Plant diseases\
    \ and pests detection based on deep learning: A review. Plant Methods 2021, 17,\
    \ 22. [CrossRef]\n[PubMed]\n91.\nFuentes, A.; Yoon, S.; Kim, S.C.; Park, D.S.\
    \ A robust deep-learning-based detector for real-time tomato plant diseases and\
    \ pests\nrecognition. Sensors 2017, 17, 2022. [CrossRef] [PubMed]\n92.\nBu, F.;\
    \ Wang, X. A smart agriculture IoT system based on deep reinforcement learning.\
    \ Future Gener. Comput. Syst. 2019, 99,\n500–507. [CrossRef]\n93.\nZhang, R.;\
    \ Li, X. Edge Computing Driven Data Sensing Strategy in the Entire Crop Lifecycle\
    \ for Smart Agriculture. Sensors 2021,\n21, 7502. [CrossRef]\n94.\nSekaran, K.;\
    \ Meqdad, M.N.; Kumar, P.; Rajan, S.; Kadry, S. Smart agriculture management system\
    \ using internet of things.\nTelkomnika 2020, 18, 1275–1284. [CrossRef]\n95.\n\
    Khujamatov, K.E.; Toshtemirov, T.K.; Lazarev, A.P.; Raximjonov, Q.T. IoT and 5G\
    \ technology in agriculture. In Proceedings of the\n2021 International Conference\
    \ on Information Science and Communications Technologies (ICISCT), Tashkent, Uzbekistan,\
    \ 3–5\nNovember 2021; pp. 1–6.\nElectronics 2023, 12, 2336\n45 of 46\n96.\nVan\
    \ Hilten, M.; Wolfert, S. 5G in agri-food—A review on current status, opportunities\
    \ and challenges. Comput. Electron. Agric.\n2022, 201, 107291. [CrossRef]\n97.\n\
    Hsu, C.K.; Chiu, Y.H.; Wu, K.R.; Liang, J.M.; Chen, J.J.; Tseng, Y.C. Design and\
    \ implementation of image electronic fence with 5G\ntechnology for smart farms.\
    \ In Proceedings of the 2019 IEEE VTS Asia Paciﬁc Wireless Communications Symposium\
    \ (APWCS),\nSingapore, 28–30 August 2019; pp. 1–3.\n98.\nArrubla-Hoyos, W.; Ojeda-Beltrán,\
    \ A.; Solano-Barliza, A.; Rambauth-Ibarra, G.; Barrios-Ulloa, A.; Cama-Pinto,\
    \ D.; Arrabal-\nCampos, F.M.; Martínez-Lao, J.A.; Cama-Pinto, A.; Manzano-Agugliaro,\
    \ F. Precision Agriculture and Sensor Systems Applications\nin Colombia through\
    \ 5G Networks. Sensors 2022, 22, 7295. [CrossRef]\n99.\nKai-zheng ZH, F.; Feng,\
    \ X. Intelligent Forestry System Design Based on Big Data. Comput. Telecommun.\
    \ 2020, 1, 56–59.\n100. Farooq, M.S.; Sohail, O.O.; Abid, A.; Rasheed, S. A survey\
    \ on the role of iot in agriculture for the implementation of smart\nlivestock\
    \ environment. IEEE Access 2022, 10, 9483–9505. [CrossRef]\n101. Zhang, M.; Wang,\
    \ X.; Feng, H.; Huang, Q.; Xiao, X.; Zhang, X. Wearable Internet of Things enabled\
    \ precision livestock farming in\nsmart farms: A review of technical solutions\
    \ for precise perception, biocompatibility, and sustainability monitoring. J.\
    \ Clean. Prod.\n2021, 312, 127712. [CrossRef]\n102. Liu, T.; Liu, J.; Wang, J.;\
    \ Xu, J. Optimization of the Intelligent Sensing Model for Environmental Information\
    \ in Aquaculture\nWaters Based on the 5G Smart Sensor Network. J. Sens. 2022,\
    \ 2022, 6409046. [CrossRef]\n103. Kim, K. Development of Buoy Information Monitoring\
    \ System Based on 5G Against the Abandoned, Lost and Discarded Fishing\nGears.\
    \ In Proceedings of the International Conference on Computational Intelligence,\
    \ Cyber Security, and Computational Models,\nCoimbatore, India, 14–16 December\
    \ 2017; Springer: Singapore, 2017; pp. 135–143.\n104. Yuan, L.; Bao, Z.; Zhang,\
    \ H.; Zhang, Y.; Liang, X. Habitat monitoring to evaluate crop disease and pest\
    \ distributions based on\nmulti-source satellite remote sensing imagery. Optik\
    \ 2017, 145, 66–73. [CrossRef]\n105. Fang, L. Research on Plant Diseases and Insect\
    \ Pests Monitoring Technology under the Background of Internet of Things\nTechnology.\
    \ In Proceedings of the 2020 International Wireless Communications and Mobile\
    \ Computing (IWCMC), Limassol,\nCyprus, 15–19 June 2020; pp. 1999–2001.\n106.\
    \ Varshney, R.K.; Sinha, P.; Singh, V.K.; Kumar, A.; Zhang, Q.; Bennetzen, J.L.\
    \ 5Gs for crop genetic improvement. Curr. Opin. Plant\nBiol. 2020, 56, 190–196.\
    \ [CrossRef]\n107. Lafont, M.; Dupont, S.; Cousin, P.; Vallauri, A. Back to the\
    \ future: IoT to improve aquaculture: Real-time monitoring and\nalgorithmic prediction\
    \ of water parameters for aquaculture needs. In Proceedings of the 2019 Global\
    \ IoT Summit (GIoTS), Aarhus,\nDenmark, 17–21 June 2019; pp. 1–6.\n108. Zhang,\
    \ J.; Zhang, R.; Yang, Q.; Hu, T.; Guo, K.; Hong, T. Research on application technology\
    \ of 5G Internet of Things and big data\nin dairy farm. In Proceedings of the\
    \ 2021 International Wireless Communications and Mobile Computing (IWCMC), Harbin\
    \ City,\nChina, 28 June–2 July 2021; pp. 138–140.\n109. Murugamani, C.; Shitharth,\
    \ S.; Hemalatha, S.; Kshirsagar, P.R.; Riyazuddin, K.; Naveed, Q.N.; Islam, S.;\
    \ Mazher Ali, S.P.; Batu,\nA. Machine Learning Technique for Precision Agriculture\
    \ Applications in 5G-Based Internet of Things. Wirel. Commun. Mob.\nComput. 2022,\
    \ 2022, 6534238. [CrossRef]\n110. Lin, B.S.P. Toward an AI-enabled SDN-based 5G\
    \ & IoT network. Netw. Commun. Technol. 2021, 5, 1–7.\n111. Restuccia, F.; Melodia,\
    \ T. Deep learning at the physical layer: System challenges and applications to\
    \ 5G and beyond. IEEE\nCommun. Mag. 2020, 58, 58–64. [CrossRef]\n112. Meng, H.\
    \ Research on key technologies of intelligent agriculture under 5G environment.\
    \ J. Phys. Conf. Ser. 2019, 1345, 042057.\n[CrossRef]\n113. Zhu, L.; Fan, R. Convenience\
    \ of Voice Interaction Design in the 5G Era to Adapt to Agricultural Machinery.\
    \ In Proceedings of the\n2020 Asia-Paciﬁc Conference on Image Processing, Electronics\
    \ and Computers (IPEC), Hong Kong, China, 14–18 December 2020;\npp. 208–212.\n\
    114. Kim, W.S.; Lee, W.S.; Kim, Y.J. A review of the applications of the internet\
    \ of things (IoT) for agricultural automation. J. Biosyst.\nEng. 2020, 45, 385–400.\
    \ [CrossRef]\n115. Bose, B.; Priya, J.; Welekar, S.; Gao, Z. Hemp Disease Detection\
    \ and Classiﬁcation Using Machine Learning and Deep Learning. In\nProceedings\
    \ of the 2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications,\
    \ Big Data & Cloud Computing,\nSustainable Computing & Communications, Social\
    \ Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom), Exeter,\nUK, 17–19\
    \ December 2020; pp. 762–769. [CrossRef]\n116. Brunelli, D.; Albanese, A.; d’Acunto,\
    \ D.; Nardello, M. Energy Neutral Machine Learning Based IoT Device for Pest Detection\
    \ in\nPrecision Agriculture. IEEE Internet Things Mag. 2019, 2, 10–13. [CrossRef]\n\
    117. Medar, R.; Rajpurohit, V.S.; Shweta, S. Crop Yield Prediction using Machine\
    \ Learning Techniques. In Proceedings of the 2019\nIEEE 5th International Conference\
    \ for Convergence in Technology (I2CT), Bombay, India, 29–31 March 2019; pp. 1–5.\
    \ [CrossRef]\n118. Gobalakrishnan, N.; Pradeep, K.; Raman, C.J.; Ali, L.J.; Gopinath,\
    \ M.P. A Systematic Review on Image Processing and Machine\nLearning Techniques\
    \ for Detecting Plant Diseases. In Proceedings of the 2020 International Conference\
    \ on Communication and\nSignal Processing (ICCSP), Chennai, India, 28–30 July\
    \ 2020; pp. 0465–0468. [CrossRef]\n119. Merchant, M.; Paradkar, V.; Khanna, M.;\
    \ Gokhale, S. Mango Leaf Deﬁciency Detection Using Digital Image Processing and\n\
    Machine Learning. In Proceedings of the 2018 3rd International Conference for\
    \ Convergence in Technology (I2CT), Mangalore,\nIndia, 6–8 April 2018; pp. 1–3.\
    \ [CrossRef]\nElectronics 2023, 12, 2336\n46 of 46\n120. Feng, Q.; Wang, X.; Wang,\
    \ G.; Li, Z. Design and test of tomatoes harvesting robot. In Proceedings of the\
    \ 2015 IEEE International\nConference on Information and Automation, Lijiang,\
    \ China, 8–10 August 2015; pp. 949–952. [CrossRef]\n121. Liu, C.; Wang, M.; Zhou,\
    \ J. Coordinating control for an agricultural vehicle with individual wheel speeds\
    \ and steering angles\n[Applications of Control]. IEEE Control Syst. 2008, 28,\
    \ 21–24. [CrossRef]\n122. Ma, J.; Wang, D.; Tang, Y.; Zhao, J. Automatic control\
    \ system of agricultural machinery based on Beidou navigation. In Proceedings\n\
    of the 2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference\
    \ (ITOEC), Chongqing, China, 3–5 October\n2017; pp. 318–323. [CrossRef]\n123.\
    \ Liu, K.; Cheng, G.; Kong, Z. Beidou agricultural machinery automatic driving\
    \ software design. In Proceedings of the 2019\nIEEE 4th Advanced Information Technology,\
    \ Electronic and Automation Control Conference (IAEAC), Chengdu, China, 20–22\n\
    December 2019; pp. 1770–1775. [CrossRef]\n124. Liu, K.; Cheng, G.; Kong, Z. Agricultural\
    \ Machinery Automatic Driving Algorithm Based on Beidou System. In Proceedings\
    \ of\nthe 2019 IEEE 4th Advanced Information Technology, Electronic and Automation\
    \ Control Conference (IAEAC), Chengdu, China,\n20–22 December 2019; pp. 2041–2045.\
    \ [CrossRef]\n125. Chien, W.C.; Hassan, M.M.; Alsanad, A.; Fortino, G. UAV–Assisted\
    \ Joint Wireless Power Transfer and Data Collection Mechanism\nfor Sustainable\
    \ Precision Agriculture in 5G. IEEE Micro 2021, 42, 25–32. [CrossRef]\n126. Alabi,\
    \ C.A.; Tooki, O.O.; Imoize, A.L.; Faruk, N. Application of UAV-Assisted 5G Communication:\
    \ A Case Study of the Nigerian\nEnvironment. In Proceedings of the 2022 IEEE Nigeria\
    \ 4th International Conference on Disruptive Technologies for Sustainable\nDevelopment\
    \ (NIGERCON), Abuja, Nigeria, 17–19 May 2022; pp. 1–5.\n127. Sharma, A.; Singh,\
    \ P.K. UAV-based framework for effective data analysis of forest ﬁre detection\
    \ using 5G networks: An effective\napproach towards smart cities solutions. Int.\
    \ J. Commun. Syst. 2021, e4826. [CrossRef]\n128. Shahzadi, R.; Ali, M.; Khan,\
    \ H.Z.; Naeem, M. UAV assisted 5G and beyond wireless networks: A survey. J. Netw.\
    \ Comput. Appl.\n2021, 189, 103114. [CrossRef]\n129. Mishra, D.; Natalizio, E.\
    \ A survey on cellular-connected UAVs: Design challenges, enabling 5G/B5G innovations,\
    \ and experimen-\ntal advancements. Comput. Netw. 2020, 182, 107451. [CrossRef]\n\
    130. Khandelwal, C. Agriculture Supply Chain Management: A Review (2010–2020).\
    \ Mater. Today Proc. 2021, 47, 3144–3153. [CrossRef]\n131. Taboada, I.; Shee,\
    \ H. Understanding 5G technology for future supply chain management. Int. J. Logist.\
    \ Res. Appl. 2021, 24,\n392–406. [CrossRef]\nDisclaimer/Publisher’s Note: The\
    \ statements, opinions and data contained in all publications are solely those\
    \ of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s).\
    \ MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople\
    \ or property resulting from any ideas, methods, instructions or products referred\
    \ to in the content.\n"
  inline_citation: '>'
  journal: Electronics
  limitations: '>'
  pdf_link: https://www.mdpi.com/2079-9292/12/10/2336/pdf?version=1684748770
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Survey of Intelligent Agricultural IoT Based on 5G
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.3233/ais-220101
  analysis: '>'
  authors:
  - M. Ashok Kumar
  - Amritpal Singh
  citation_count: 6
  full_citation: '>'
  full_text: ">\nJournal of Ambient Intelligence and Smart Environments 14 (2022)\
    \ 229–284\n229\nDOI 10.3233/AIS-220101\nIOS Press\nProbabilistic data structures\
    \ in smart city:\nSurvey, applications, challenges, and research\ndirections\n\
    Mandeep Kumar * and Amritpal Singh\nDepartment of Computer Science and Engineering,\
    \ Dr B R Ambedkar National Institute of Technology, Jalandhar\nPunjab, India\n\
    E-mails: mkkrs88@gmail.com, mandeepkumar.cs.19@nitj.ac.in, amritpal.singh203@gmail.com,\n\
    apsingh@nitj.ac.in\nReceived 24 February 2022\nAccepted 29 June 2022\nAbstract.\
    \ With the commencement of new technologies like IoT and the Cloud, the sources\
    \ of data generation have increased\nexponentially. The use and processing of\
    \ this generated data have motivated and given birth to many other domains. The\
    \ concept\nof a smart city has also evolved from making use of this data in decision-making\
    \ in the various aspects of daily life and also\nimprovement in the traditional\
    \ systems. In smart cities, various technologies work collaboratively; they include\
    \ devices used for\ndata collection, processing, storing, retrieval, analysis,\
    \ and decision making. Big data storage, retrieval, and analysis play a vital\n\
    role in smart city applications. Traditional data processing approaches face many\
    \ challenges when dealing with such voluminous\nand high-speed generated data,\
    \ such as semi-structured or unstructured data, data privacy, security, real-time\
    \ responses, and so on.\nProbabilistic Data Structures (PDS) has been evolved\
    \ as a potential solution for many applications in smart cities to complete this\n\
    tedious task of handling big data with real-time response. PDS has been used in\
    \ many smart city domains, including healthcare,\ntransportation, the environment,\
    \ energy, and industry. The goal of this paper is to provide a comprehensive review\
    \ of PDS and its\napplications in the domains of smart cities. The prominent domain\
    \ of the smart city has been explored in detail; origin, current\nresearch status,\
    \ challenges, and existing application of PDS along with research gaps and future\
    \ directions. The foremost aim of\nthis paper is to provide a detailed survey\
    \ of PDS in smart cities; for readers and researchers who want to explore this\
    \ ﬁeld; along\nwith the research opportunities in the domains.\nKeywords: Smart\
    \ city, Probabilistic Data Structure (PDS), Bloom Filter (BF), big data, Internet\
    \ of Things (IoT)\n1. Introduction\nIn the early 1970s, it was a period of acceleration\
    \ in the ﬁeld of computing and data was the new term. There was\nan evolution\
    \ of relational databases between the 1980s and 1990s. The internet and IoT are\
    \ clusters of unstructured,\nsemi-structured, and structured data. In the 1990s,\
    \ there was slow or no internet in most cities. These were ordinary\ncities. Generally,\
    \ ordinary cities are deﬁned as human settlements without the use of the latest\
    \ technology at all.\nThe need for processing, storage, and analysis is required\
    \ beyond the human and technical infrastructure. This huge\nvolume and variety\
    \ of unstructured data and untapped information is spread across the networks.\
    \ The core part of\nApache Hadoop is the Hadoop Distributed File System (HDFS),\
    \ consisting of the storage part, and the MapReduce\n*Corresponding author. E-mails:\
    \ mkkrs88@gmail.com, mandeepkumar.cs.19@nitj.ac.in.\n1876-1364/$35.00 © 2022 –\
    \ IOS Press. All rights reserved.\n230\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\nFig. 1. Smart city.\nprogramming model for processing\
    \ [4]. As the data is increasing day by day, to access this data in an efﬁcient\
    \ and\nwell-structured manner, the government and public sector require technologies\
    \ and expertise to convert urban cities\nto smart cities. The research interest\
    \ in smart cities has continuously increased in the current and coming years and\n\
    it is economically justiﬁed by the progress of state-of-the-art technologies [21].\
    \ New inventions like the internet, the\ncloud, and IoT have increased data generation\
    \ speed as well as introduced a variation in data. The smart city impacts\ntowns\
    \ and cities around the world with the evolution of the internet and the use of\
    \ new technologies. But in the\ncurrent context, rapid population growth is creating\
    \ challenges for the government and its services. So, smart cities\nare the most\
    \ acceptable solution to such situations of better metropolitan living conditions\
    \ [146]. The emergence of\na smart city has the potential to manage all these\
    \ issues (Fig. 1). But, expeditious urbanization also quickly presents\na major\
    \ challenge worldwide. Though movement from rural to metropolitan areas is unavoidable,\
    \ that’s why cities\npersist in facing many challenges like transport, healthiness,\
    \ air quality, agriculture, and many more [87]. Smart\ncities face many issues\
    \ like pollution, health assistance, overburden on both public and private sectors,\
    \ trafﬁc, etc.\ndue to the rapid growth in population in metropolitan cities [126].\
    \ In this connection, the problems associated with\nthese issues in cities require\
    \ ingenious solutions. They include human strength, ingenuity, and collaboration\
    \ with\ndifferent stakeholders [117].\nIn a recent survey, the United Nations\
    \ estimated that the world’s population will grow by 32% from 2015 to\n2050 and\
    \ that the population will grow by 63% in the metropolitan area. Several researchers\
    \ also stated that by\n2030, more than 60% of the population will be living in\
    \ cities, with the southeast United States experiencing the\ngreatest growth [74,275].\
    \ The extensive and rapid growth of information and Communication Technology (ICT)\n\
    has provided possible solutions and mechanisms to various problems in metropolitan\
    \ areas [13] this approach can\nbe used as a tool [267] to increase the effectiveness\
    \ of the city system. In this regard, the thinking or mentality of\nhumans is\
    \ required to be changed, like a smart mind, to raise the standard of living for\
    \ sustainability in the smart\ncity. Furthermore, remote monitoring and management\
    \ systems are being used to improve energy efﬁciency in smart\ncities [316].\n\
    Since the advent of the coronavirus and its declaration as a worldwide epidemic,\
    \ all public and private sectors have\nbeen affected. This virus has affected\
    \ daily routines and activities like education, communication, daily movement,\n\
    labor, and many more. Some public and private sectors have worked with 50% manpower\
    \ on alternative days. Many\nsectors, like IT companies, schools, etc. have run\
    \ Work From Home (WFH). Even doctors have their OPD or patients\nM. Kumar and\
    \ A. Singh / Probabilistic data structures in smart city\n231\ndiagnosed online.\
    \ The key solution to this epidemic’s key problems for daily life can be solved\
    \ through the smart\ncity. Jasim et al. [129]made a wise decision to help society\
    \ and expand the resources available to individuals in areas\nsuch as healthcare,\
    \ communication, transportation, education, and many others.\nThe Government of\
    \ India (GoI) has a long-term vision for smart cities. GoI deﬁnes smart cities\
    \ as a mission\nto conduct monetary growth and improve the quality of life by\
    \ allowing the development of regional zones and\nutilizing technology that directs\
    \ to smart results. They also designed a workbook “Making a City Smart: Learnings\n\
    from the Smart Cities Mission” with activities in each section to help cities\
    \ plan their smart city journeys. Creating\na smart city incorporates lessons\
    \ from the smart city mission to clarify what, why, and how a smart city works.\n\
    Consolidated at the national level, 100 smart cities have proposed to undertake\
    \ 5,151 projects worth Rs. 2,05,018\ncrores in 5 years from their selected dates.\
    \ New ﬁnancial innovations are built on investment plans. The distribution\nis\
    \ estimated to be from a variety of sources as follows: 6480 projects worth Rs.\
    \ 185,905 Cr are tendered, 5845\nprojects worth Rs. 157,369 are in work order\
    \ stages and 3145 projects worth Rs. 53,256 Cr are completed. The\ncities like\
    \ Gwalior, Thiruvananthapuram, Satna, Udaipur, New Town Kolkata, Bhubaneshwar,\
    \ and Ahmedabad are\ncovered under various smart city projects [183].\n1.1. Role\
    \ of big data in smart city\nBig Data basically stands for velocity, volume, and\
    \ variety of information, which includes complexity in terms\nof speed of data\
    \ generation, the structure of data (variety), and the amount of data to be generated.\
    \ Big data has\na number of deﬁnitions and’V’ principles to make big data processing\
    \ clear and accurate [118]. Anything beyond\nthe human and traditional infrastructure\
    \ and techniques required to store, process, and analyze big data provides\nthe\
    \ solutions for it. With the advent of new technologies such as IoT, ICT, sensors,\
    \ and so on, big data systems are\nbecoming more efﬁcient in sophisticated data\
    \ infrastructures [170].\nThe role of big data in smart cities is heavily inﬂuenced,\
    \ particularly in recognizing patterns, analyzing, and\nprocessing data collected\
    \ from various IoT devices (Fig. 2). Every city is evolving towards being a smart\
    \ city. These\ncities combine basic needs with high technology for a carefree\
    \ and basic lifestyle. To extract important information\nfrom such huge data sets,\
    \ big data analysis is the key [7]. The data collected from different sensors\
    \ and devices in\na smart city’s various gates installed in the city is used for\
    \ better decisions. This growth in data requires efﬁcient\nstorage and handling,\
    \ which is a big challenge for both academia and industry [96]. Big data has different\
    \ effects in\ndifferent parts of the city.\nThe protection of the general public:\
    \ The security and privacy of citizens is the main concern in smart cities.\n\
    To protect their citizens from anything mishappening within the city, various\
    \ analyses of geographical data can be\ndone. This can all be recorded through\
    \ Close Circuit Televisions (CCTVs) and sensors installed on street lights or\n\
    trafﬁc lights. An enormous amount of data is developed and signiﬁcant expansion\
    \ is required when the desired data\ntransforms the city into a considerably safer\
    \ location.\nUrbanism: Cities are investing heavily in transforming to become\
    \ smart cities. The current needs of the city\ncan be identiﬁed through the effective\
    \ use of data, which can aid in identifying areas that require development and\n\
    improvement. As a result, cities can invest by volunteering in areas where they\
    \ are needed.\nFig. 2. Inﬂuence of big data in smart cities.\n232\nM. Kumar and\
    \ A. Singh / Probabilistic data structures in smart city\nTransportation: After\
    \ Covid-19 both public and private transportation are affected after COVID-19.\
    \ Most people\nrely on their own reasoning to get to work and so on. The congestion\
    \ on the roads is increasing, so the risk of\naccidents or anything else going\
    \ wrong has also increased. To handle or manage trafﬁc on roads, the system requires\n\
    big data and well-structured data. Large data sets will also help reduce risks.\n\
    Sustainable Growth: This is also the main part of a smart city. For sustainable\
    \ growth, a huge amount of past and\npresent data is required. Likewise, storing\
    \ this data is one of the challenges for the smart city. This data is updated\n\
    on a daily basis. Data is a special factor in determining the impact of improvement\
    \ in the city.\nInfrastructure: To maintain sustainability, smart city infrastructure\
    \ needs to improve consistently. Obviously, for\nthis data, a smart city is required\
    \ and used in a good manner to improve or maintain the infrastructure.\nSo, the\
    \ role of big data in smart cities is signiﬁcant for efﬁcient and quick results.\
    \ Big data is the brain of the\nsmart city. The main challenge is the lack of\
    \ awareness of using this data to create smart solutions to fulﬁll the\nrequirements\
    \ of citizens. Citizens are the main stakeholders of smart cities. So, to improve\
    \ the standard of living,\nthe developer needs new data processing tools and techniques.\
    \ There is computational, time, and space complexity\nby using the deterministic\
    \ data structure. Probabilistic Data Structures are one of the key solutions for\
    \ smart storage\nand searching of data in real-time scenarios.\nThe traditional\
    \ methods may also produce accurate results in real-time, but there is a trade-off\
    \ in space and time,\nwhich is not acceptable due to the massive amount of data.\
    \ Due to the huge and limitless evolution, the traditional\ndata structure is\
    \ shifted to PDS for retrieval and storage. PDS has given an approximation solution,\
    \ which may be\nor may not be the exact answer, but it moves in the right direction.\
    \ Since PDSs have some probabilistic compo-\nnents, they are efﬁcient in reducing\
    \ the time or space trade-offs. PDS also plays a key role in big data processing,\n\
    storing nonstructural data, helping with fast retrieval, and making approximate\
    \ predictions. Hash functions are used\nto represent these data structures [246].\
    \ The PDS is used for membership checking, frequency testing, similarity\ntesting,\
    \ and cardinal counting. Low memory requirements and good processing speed are\
    \ two distinct features of\nPDS [136].\nThe extensive review of this paper has\
    \ found the key challenges faced during the handling of big data in smart\ncities.\
    \ In this regard, the PDS and its variants have provided the key solutions to\
    \ these challenges and also found new\npossibilities. In this paper, the importance\
    \ of big data in smart cities, generation (Section 2), architecture (Section 4),\n\
    and the detailed application (Section 7) of smart cities, worldwide running smart\
    \ city projects (Section 5) and\ncommonly used PDS (Section 6) have been discussed.\
    \ During the survey, it was found that big data has a high\ninﬂuence on smart\
    \ cities. PDS has evolved as a potential solution for many applications in smart\
    \ cities to complete\nthis tedious task of handling big data with real-time response.\
    \ PDS has been used in many smart city domains,\nincluding healthcare, transportation,\
    \ the environment, energy, and industry. This paper has thoroughly investigated\n\
    the prominent domain of smart cities, including the origin, current research status,\
    \ and existing applications of PDS,\nas well as research gaps and challenges (Section\
    \ 10).\n2. Generations of smart cities\nTo improve the standard of living there\
    \ is a need to change from rural to urban. Governments and citizens are\nincreasing\
    \ their attention in terms of technologies and new startups in smart cities. The\
    \ concept of a smart city for\nurban transformation has radically changed over\
    \ the years. The generation of smart cities has been concise (Table 1).\nBased\
    \ on analysis and study, several researchers have divided the technical advancement\
    \ in smart cities into different\ngenerations (generations 1.0–5.0) (Fig. 3) [140,265]:\n\
    Generations 1.0: – When the technology vendors started implementing their own\
    \ solutions in cities, it was deﬁned\nas the ﬁrst technology-driven smart city.\
    \ Due to the inﬂuential role of big corporations like IBM and Cisco, they\nare\
    \ criticized for their technology concerns. To improve the efﬁciency of public\
    \ and private services, the creators of\ntechnology development are encouraged\
    \ to use their own solutions in cities.\nGenerations 2.0: – Indirectly concerned\
    \ with citizens, issues like healthcare, transport, air quality, and water qual-\n\
    ity are arising. The technology and tools were developed to address such issues\
    \ in generation 2.0. The participation\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\n233\nFig. 3. Generation of smart city [140].\n\
    Table 1\nGeneration of smart city\nParameters\nGeneration 1.0\nGeneration 2.0\n\
    Generation 3.0\nGeneration 4.0\nGeneration 5.0\nYear\n1974–2000\n2000–2010\n2011–2018\n\
    2018–2020\n2021-future\nMain Objective\nImproving efﬁciency\nof city administration\n\
    To address certain\nissues like as\npollution growth,\nhealthcare, and\ntransportation\n\
    Public health and\nsafety, practical\nintelligence, and data\nanalysis\nAggregate\
    \ procedure\nand the challenge of\nincorporating\nresolutions\nHuman interaction\n\
    with the AI system\nFocus on\nTechnological\npressures and the\ninﬂuential role\
    \ of big\ncorporations, like\nCISCO and IBM\nNew technologies,\nexploring various\n\
    options for enriching\nthe grade of life in\ncities\nUrban development,\nparticipate\
    \ in the\nmodern city building\nprogram\nUnderstand the\nopportunities and\nboundaries\
    \ of latest\ntechnologies and\nvalue the inﬂuence\nthat smart city\ntechnologies\n\
    Evaluate all factors of\nlife and the\ninconsistent claims of\nfurther metropolis\n\
    stakeholders\nData/ Information\nSharing\nWithin in an area\nbetween two\nmachines\
    \ and limited\nMachine to Machines\nwith high range\nData Sharing on\nCloud\n\
    Human Interaction\nwith AI\nKey Technologies\nTechnology Driven,\nUrban Big Data\n\
    Technology Enabled,\nSensors, Networks\nCitizen Co-creation,\nDigital Technology,\n\
    IoT, 5G\nCloud Computing\n(CC), Sidewalk Labs\n(Toronto and Google)\nAI, Robotics,\
    \ IoT, 6G\nLimitations\nData Exchange\nlack of technologies\nusages\nPrivacy and\
    \ Security\nData management\nNew and untested\ntechnologies\nof citizens was negligible\
    \ in decision-making in cities [276]. The quality of life and local administration\
    \ was mea-\nsured by modern technology. For this, cities presented agendas and\
    \ schemes that support the execution of trendy\ntechnology.\nGenerations 3.0:\
    \ – Thus, the modern city represents the whole connected ecosystem that integrates\
    \ ICT into a\nsmart city. The modern city building programs were organized and\
    \ the local public participated. It was the time\nwhen the government acted as\
    \ a facility providing services to citizens. Here also, citizens are competent\
    \ to represent\ntheir thoughts and innovative ideas [251]. Here also, the urban\
    \ space is designed for users and their engagement.\nGenerations 4.0: – By adopting\
    \ 4.0 industrial transformation, the beneﬁts of smart cities are valued to outweigh\n\
    city costs through city establishment [298]. This generation of smart cities illustrates\
    \ the most useful parts of the\npast; for example, technology generation 1.0,\
    \ individual performance 2.0, and 3.0 engagement. Smart City Genera-\n234\nM.\
    \ Kumar and A. Singh / Probabilistic data structures in smart city\nTable 2\n\
    Top ﬁve smart cities in last three years\nYears\nSmart Cities\n2021\nSingapore,\
    \ Zurich, Oslo, Taipei City, Lausanne.\n2020\nSingapore, Helsinki, Zurich, Auckland,\
    \ Oslo.\n2019\nSingapore, Zurich, Oslo, Geneva, Copenhagen.\ntions 4.0 is inspired\
    \ by Industry Revolution 4.0, and they develop new technologies. In this, control\
    \ is over the use\nof existing resources and infrastructure.\nGenerations 5.0:\
    \ – In this generation 5.0, the concept of cognitive computing is introduced for\
    \ developing cities.\nIt is purely based on Artiﬁcial Intelligence (AI). Systems\
    \ are self-learned from past and present knowledge that\nreﬂects changes in real-time\
    \ like interest, barriers, etc [228]. Each public and private service can be handled\
    \ by an\nindependent agent, which gives fast and efﬁcient results. Generations\
    \ 5.0 is the main focus on decision-making for\nurban development by using behavioral\
    \ analysis and AI [264].\n3. Ranking of smart city\nWorldwide, there are different\
    \ ranking systems based on distinct parameters. Out of these, the most popular\
    \ are,\n“Liveable City Index (LCI)” [204],“intelligent cities” [292], “sustainable\
    \ cities” [28], “global cities” and “competi-\ntiveness cities” [266].\nThe center\
    \ smart city index is used for ranking by researchers’ organizations such as Smart\
    \ City Observatory, in\ncollaboration with IMD competitiveness [44]. To manage\
    \ the infrastructure of smart cities like transportation, trafﬁc,\nstreet light\
    \ etc. the technologies like AI and IoT may be used. Muhammad A.R. Tariq et al.\
    \ [266] tries to identify\nthe preferences of people living with different city\
    \ ranking systems, and the top ﬁve cities in the last three years are\ngiven in\
    \ Table 2. Another ranking criteria is that Juniper Research, an analyst ﬁrm based\
    \ in the UK, has ranked the\ncities as smart cities on various factors like transportation,\
    \ energy, healthcare, connectivity between urban areas, etc.\nShanghai, Seoul,\
    \ Barcelona, Beijing, and New York are among the top ﬁve global cities considered.\
    \ These cities\nmainly work on real-time data, which helps in managing the assets\
    \ and future-prooﬁng them. They also cover the\ndowntown to provide 5G and 99%\
    \ of ﬁber coverage across the city. To fully ﬁll, the needs of residents, these\
    \ smart\ncities are using the “Citizen Cloud App”, which uses ambient technologies\
    \ like AI, Cloud Computing, and Big Data,\nwhich come under Smart City Generation\
    \ 5.0 [20].\n4. Architecture of smart city\nSmart city development includes the\
    \ integration and implementation of digital and IoT. IoT provides essential\n\
    elements of smart cities like data production, data management, and application\
    \ management. The number of smart\ncity architectures proposed over time [226].\
    \ In Fig. 4 the most generic architecture has been represented with four\nlayers.\
    \ All these four layers are integrated with security modules because of sensitive\
    \ data.\nSensing layer: – The bottom-most layer of the architecture represents\
    \ the sensing layer or data collection layer.\nIoT devices are used to build this\
    \ layer. This layer uses various IoT devices like actuator, Zigbee, Radio Frequency\n\
    Identiﬁcation (RFID) sensors etc. to sens these various parameters like humidity,\
    \ temperature, pressure, etc. Data\ncollection on mobile devices is a huge burden\
    \ on the sensor layer, which resides under the structure. This layer\ncaptures\
    \ real-time data from sensors [26,192].\nTransmission layer: – With a variety\
    \ of communication technologies, the transfer layer carries data to higher\nlevels.\
    \ This layer acts as the spine of any smart city architecture. In this layer,\
    \ the various communication networks\nlike 3G, 4G, LTE, the internet, and satellite\
    \ also help in mobile networks. Fifth-generation (5G) telecommunication\nis embedded\
    \ in the base station for transferring huge wireless trafﬁc [100].\nData management\
    \ layer: – This layer resides between the transmission and application layers\
    \ and is the brain of\na smart city. The functions of this layer are deception,\
    \ editing, analysis, storage, and decision-making [195]. The\nM. Kumar and A.\
    \ Singh / Probabilistic data structures in smart city\n235\nFig. 4. Layered architecture\
    \ of a generic smart city [243].\nstored information in this layer is used to\
    \ provide services to various applications in the top layer. The primary role\n\
    of this layer is to preserve data integrity, data puriﬁcation, expansion, and\
    \ optimization [285]. As the ﬁnal function\nof the data management layer, the\
    \ conclusions obtained are transferred to the application layer for proper use.\n\
    Application layer: – An application layer is required to connect the data management\
    \ layer with urban residents.\nThis is the topmost layer of this architecture.\
    \ This layer provides assistance to the users. It operates applications\nthat\
    \ use IoT, for example, smart homes, grid distribution, smart transport, weather\
    \ forecasting, etc., and intelligent\nhealth [317]. As this layer is directly\
    \ connected to the end-users, the satisfaction of users may increase with the\n\
    improvement of services provided.\n5. Projects contributions related to smart\
    \ city\nThe research on smart city buildings has been accomplished worldwide.\
    \ Hence, the concept of smart cities was\nintroduced. The research was conducted\
    \ by various international organizations, universities, and businesses. Various\n\
    countries, like the US and China, have also accomplished research in intelligent\
    \ urban design [156]. The smart city\nencourages the planning of metropolitan,\
    \ oversight through ICT, IoT, CC etc [157]. The evaluation method proposed\nby\
    \ IBM is very focused on building standards and relevant standards. So far, the\
    \ various initiatives, contributions,\nachievements, and projects in smart cities\
    \ are listed in Table 3 [106].\n6. Probabilistic data structure\nThe exponential\
    \ increase in data production services is most evident in the last decade, due\
    \ to the emergence\nof ICT, IoT, etc. The traditional methods may also produce\
    \ accurate results in real-time, but there is a trade-off in\nspace and time,\
    \ which is not acceptable for a massive amount of data. Due to the huge and limitless\
    \ evolution, the\ntraditional data structure is shifted to PDS for retrieval and\
    \ storage. PDS has given an approximation solution, which\nmay be or may not be\
    \ the exact answer, but it moves in the right direction. Since PDSs have some\
    \ probabilistic\ncomponents, they are efﬁcient in reducing the time or space trade-offs.\
    \ PDS also plays a key role in big data\nprocessing, storing nonstructural data,\
    \ helping in fast retrieval, and making approximate predictions. In general,\n\
    236\nM. Kumar and A. Singh / Probabilistic data structures in smart city\nTable\
    \ 3\nProjects contributions related to smart city\nYear\nProject/Achievement\n\
    Technology/Contribution\nLocation\n1974\nA Cluster Analysis of Los Angeles\n[139]\n\
    Urban Big data\nLos Angeles\n1994\nA Virtual digital City – De Digitale\nStad\
    \ (DDS) [227]\nInternet Use\nAmsterdam\n2005\nResearch on smart cities [2]\nSpent\
    \ $25 m\nCisco\n2008\nSmarter Planet Project [206]\nSensors, networks and analysis\
    \ of\nurban issues\nIBM\n2009\nSmarter Cities Campaign [189]\nSpent $50 m\nIBM\n\
    2009\nSmart Grid [110]\nProvide funds\nAmerican Recovery and\nReinvestment Act\
    \ (ARRA)\n2009\nSmart Meters [32]\n80% of consumers by 2020\nEU Electricity Directive\
    \ required\n2010\nYokohama Smart City Project\n(YSCP) [70]\nInfrastructure, Next\
    \ Generation\nEnergy, and Social Systems\nTrade, Ministry of Economy, and\nIndustry,\
    \ a Japanese government\norganization\n2011\nCompetition of 200 applicants for\n\
    smart city [47]\n24 cities are winners\nIBM\n2011\nExpo World Congress [45]\n\
    50 countries attended\nin Barcelona\n2012\nPublic transit, parking and street\n\
    lighting [27]\nData-drive urban systems\nBarcelona\n2013\nSmart London Board [268]\n\
    Digital Technology\nMayor of London\n2014\n103 pilot smart cities [304]\nSecond\
    \ batch\nChina\n2014\nWien Framework Strategy [209]\nLaunch smart city until 2025\n\
    Vienna City Council\n2015\n100 Smart Cities Mission [9]\nIndian Cities\nGoI\n\
    2016\nSmart Cities Challenge [116]\nColumbus Won $50 m\nUS Dept of Transportation\n\
    2017\n5G testbeds [133]\nTrials programme\nUK government\n2017\nLaunched smart\
    \ city blueprint [53]\nBlueprint\nHong Kong\n2018\nSmart Waterfront ares [289]\n\
    Sidewalk Labs\nToronto and Google\n2018\nSmarter London [166]\nUpgrade 2013 plans\n\
    London\n2018\nMotion Index ranked [63]\nTop 3 cities (New York, London and\nParis)\n\
    IESE Business School Cities\n2018\nAward as Smart city [290]\nSmart City Expo\
    \ World Congress\nSingapore\n2019\nCellular Vehicle to Everything [250]\nC-V2X\
    \ standard\nFord Commitment\n2019\nData Privacy implications [167]\nSidewalk Labs\n\
    Toronto\n2019\nGlobal Smart Cities Alliance [92]\nWorld Economic Forum as\nsecretariat\n\
    G20\n2019\n5G testbeds [315]\nNew York and Salt Lake City\nUS Federal Communications\n\
    Commission\n2020\n$4.2bn smart city in northern Hanoi\n[174]\nExpected to be complete\
    \ in 2028\nVietnamese\n2030\nBy 2030 number of cities are\nincreases [194]\n43\
    \ cities with population more then\n10 million\nWorld survey\n2050\nBy 2050 Live\
    \ in cities [194]\n70% population expected\nWorld survey\nthere are thirteen types\
    \ of PDS (Fig. 5). But in this paper, we are discussing four types, because these\
    \ are widely\nused by various researchers in their design and development. These\
    \ are very useful for handling and storing large\namounts of data in an appropriate\
    \ and efﬁcient manner. Hash functions are used to represent these data structures\n\
    [246]. The PDS is used for membership checking, frequency testing, similarity\
    \ testing, and cardinal counting. Low\nmemory requirements and good processing\
    \ speed are two distinct features of PDS [136].\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\n237\nFig. 5. Overview of PDS [246].\n6.1. Bloom\
    \ ﬁlter\nIn 1970, the concept of Bloom Filter (BF) was introduced by Burton H.\
    \ Bloom [36]. The BF is a probabilistic\nmodel, a highly efﬁcient random data\
    \ structure. It is used to reduce space problems and is an effective way to query\n\
    the membership of any item in an extensive set. The BF consists of an array with\
    \ m-bits which is initialized to 0 and\nk hash functions. The hash function k\
    \ is used to query an element. To ﬁnd the position of elements in the array, put\n\
    them into the k hash functions.\nFor insertion into BF, the ﬁrst element has been\
    \ added using a hash function (Fig. 6). For elements to be inserted,\nhash functions\
    \ are computed and the corresponding bit is set with that index. In the query\
    \ process, an element is\nchecked to see whether it is a member of the set or\
    \ not. For querying, check all bits correspond to indexes. If all the\nbits are\
    \ set high, then the answer is “maybe” and if at least 1 bit is not set, then\
    \ the answer is “deﬁnitely not”.\nProperties of BF:\n– It is impossible to false\
    \ negative, but if the queried locations are set to 1, then a false positive is\
    \ possible (in\nstandard BF).\n– To process an element, the query time is O (k),\
    \ where k is the hash function.\n– The size of the union and intersection of BF\
    \ is the same and to implement hash functions, the operations bitwise\nOR and\
    \ AND are used.\nFig. 6. Insertion in bloom ﬁlter [246].\n6.2. Count min sketch\n\
    Count-min sketch (CMS) was introduced by G.Cormode and S.Muthukrishna in 2003\
    \ [64]. It is a streaming algo-\nrithm for probabilistic sub-linear space [244].\
    \ Its functionality is also hashing-dependent like BF. CMS is different\nfrom\
    \ BF in only that it uses a 2-dimensional array to handle a given data set, while\
    \ BF uses a 1-dimensional array\nfor representing hashed data.\n238\nM. Kumar\
    \ and A. Singh / Probabilistic data structures in smart city\nFig. 7. Count min\
    \ sketch [246].\nThe basic data structure of CMS consists of a 2-D array (d *\
    \ w) where w is used for storing the counts and it\ndepends on the maximum outputs\
    \ given by hash functions, and d is the hash function h(1 . . . d) and it is pairwise\n\
    independent. To update the counts, calculate the hash positions with the d-hash\
    \ functions. The values determined\nby the hash function are used to get the actual\
    \ occurrence of an item in an array. The minimum of the determined\nvalues by\
    \ the hash function is the actual occurrence of an item (Fig. 7). The space used\
    \ by CMS is equal to the count\nof (d * w). With the use of CMS and appropriate\
    \ values of d and w, we get efﬁcient results with very few errors.\nUse more hash\
    \ functions for more accurate results.\nProperties of Count-Min sketch:\n– It\
    \ supports union operations on cells.\n– The query time to process is O (k), where\
    \ k is a hash function.\n– The accuracy improves when an item appears multiple\
    \ times, with a higher frequency, or with heavy hitters.\n– CMS also has various\
    \ applications like compressed sensing, stream processing, frequency tracking,\
    \ etc.\n6.3. Locality sensitive hashing\nIn 1998, Indyk and Motwani introduced\
    \ the Locality Sensitive Hashing (LSH) [123]. LSH works on the principle\nof using\
    \ low-dimensional space for high-dimensional data. The hash functions are selected\
    \ very carefully, which\nhas more chances of collusion in the hash bucket. The\
    \ LSH has three phases. These are: the ﬁrst phase is the\npreprocessing phase\
    \ where different measures are used for mapping data, in the second phase, hash\
    \ tables are\ncreated, and in the ﬁnal phase, these hash tables are used for recognizing\
    \ identical items (Fig. 8). The similar items\nare located in the same bucket,\
    \ so the whole data is located in buckets [104].\nFig. 8. Locality-sensitive hashing\
    \ framework [246].\nM. Kumar and A. Singh / Probabilistic data structures in smart\
    \ city\n239\nA LSH family lshF() is deﬁned with probabilities P1 and P2, an approximation\
    \ factor c ⩾ 1, a threshold R ⩾ 0,\nand for a metric space M = (M, d). This function\
    \ lshF() maps the metric space to buckets sϵS with a set of functions\nh: M →\
    \ S [287]. The following conditions must be satisﬁed for p, qϵM and hash function\
    \ h chosen uniformly at\nrandom from F :\n– if d(p, q) ⩽ R, then h(p) = h(q) (i.e.,\
    \ p and q collide) with probability at least P1,\n– if d(p, q) ⩾ cR, then h(p)\
    \ = h(q) with probability at most P2.\nA family is interesting when P1 ⩾ P2. Such\
    \ a family lshF() is called (R, cR, P1, P2)-sensitive.\nProperties of Locality\
    \ Sensitive Hashing:\n– The same items are hashed to the same buckets as different\
    \ items, so LSH hashes the items a number of times.\n– Cosine, similarity, and\
    \ hammering distances are examples of item LSH functions.\n– The functions of\
    \ LSH are not limited to the same standard measures commonly used for data retrieval,\
    \ overlap,\nand dice coefﬁcient [54].\n6.4. Quotient ﬁlter\nMichael Bender et\
    \ al. proposed a quotient ﬁlter (QF) in 2011 [30]. It uses less memory to sample\
    \ an element that\nis a member or not of the set. Basically, it has performed\
    \ four operations add, delete, is a member, is not a member\non the set. QF uses\
    \ the single hash function for ﬁngerprint generation with a size of p (in bits).\
    \ For insertion of\nelement in QF, remainder fr ← (fp(x) mod 2r) and quotient\
    \ fp ← (⌊fp(x)2r⌋) are calculated, where fp is the\nindex of bucket and fr is\
    \ value inserted in fp bucket. QF gives the speciﬁc result to the query that is\
    \ either probably\nyes or deﬁnitely not the element of the set. There is some\
    \ probability after querying that the element is in the set, but\nactually, it\
    \ is not present (Fig. 9). The storage size is decreased with the increase of\
    \ ﬁlter size, so there is a trade-off\nbetween storage and false-positive [82].\n\
    Properties of Quotient Filter:\n– An Approximate Member Query (AMQ) ﬁlter is used\
    \ to speed up the answers in the storage system.\n– Insertion, deletion, and updating\
    \ are allowed in QF, resulting in the large usage of proxy databases.\n– There\
    \ is no need to re-hash the original key for merging and re-sizing of QF.\nPDSs\
    \ are used in many real-time applications like preserving patient data in healthcare,\
    \ trafﬁc control, energy-\nsaving, and also for SEM and SAM, and many more. In\
    \ the next section, the PDS and their applications in smart\ncities and big data\
    \ will be explored in a more detailed manner.\nFig. 9. Quotient ﬁlter [89].\n\
    240\nM. Kumar and A. Singh / Probabilistic data structures in smart city\n7. Smart\
    \ city application\nThe smart city needs to majorly focus on activities like healthcare,\
    \ trafﬁc, street lights. Intelligent technologies\nlike ICT, IoT, sensors etc.\
    \ and analysis of data are the key requirements to improving the citizen’s standard\
    \ of life.\nThe important application of smart city (Fig. 10) are smart healthcare,\
    \ smart trafﬁc management system, smart\nemergency system, smart street light,\
    \ a virtual power plant in smart grid etc.\nPeoples have a number of reasons like\
    \ job opportunities, education, and many more to move from one city to\nanother\
    \ even in an epidemic like Covid-19. In smart cities data is fetched and analyzed\
    \ through IoT devices like\nsensors, actuators etc. [102]. Further, this data\
    \ is used to improve social services, infrastructure, and decision-\nmaking. This\
    \ information plays an essential role in real-time application and services in\
    \ urban areas [202].\nFig. 10. Applications of smart city.\n7.1. Smart healthcare\n\
    Healthcare is an important service to the growth and development of any smart\
    \ city. In recent years, smart health-\ncare has emerged with the growth of ICT.\
    \ It is a process of managing one’s health by a couple of doctors themselves\n\
    or virtually [112]. The traditional medical system needs to be transformed into\
    \ smart healthcare in order to become\nmore efﬁcient and convenient for patients.\
    \ With the emergence in technologies like ICT, IoT, AI etc. the healthcare\nindustry\
    \ have transformed from old-fashioned like interaction between doctor-patient\
    \ to new i.e. remote health mon-\nitoring [113]. IBM (Armonky, NY, USA) came up\
    \ with the idea of smart healthcare in 2009 [269]. There are some\nchallenges\
    \ while transformation into smart healthcare, these are: healthcare systems, equipment\
    \ are under enormous\nM. Kumar and A. Singh / Probabilistic data structures in\
    \ smart city\n241\npressure, healthcare data is growing exponentially, inform\
    \ decision-making process with detailed information, ad-\nditional wisdom for\
    \ nurses, challenges in consolidating and resolving legal issues, making the patients\
    \ run from\none department to another for collecting reports, accurate precision\
    \ diagnostics, and right measurements. With the\nincrease of population, these\
    \ challenges are also heightened with demanding health services. The preponderance\
    \ of\nindustrialized nations is facing vital difﬁculties regarding the quality\
    \ and cost of numerous healthcare and wellbeing\nservices [3]. Due to limited\
    \ resources, some cities are deprived of proper healthcare services. In view of\
    \ this, there is\na need for new systems, smart healthcare. In the ﬁeld of smart\
    \ healthcare, devices, the internet, and IoT can connect\npeople with each other,\
    \ as well as manage healthcare activities and resources. Smart healthcare is one\
    \ of the highest\nlevels of knowledge building in the medical ﬁeld [108]. To collect\
    \ information dynamically, liking between insti-\ntutions and healthcare, smart\
    \ healthcare is used to take advantage of advanced technologies, devices like\
    \ wearable,\nmobile internet, and the IoT. Smart healthcare can reduce workload\
    \ at the information desk, and also Help patients\nand their wards.\n7.1.1. Evolution\
    \ of healthcare\nVarious authors and researchers in their studies are categories\
    \ the healthcare system in different generations\n(Fig. 11) (Healthcare 1.0–Healthcare\
    \ 5.0). The different functionality evolution of healthcare system are discussed\n\
    as:\nHealthcare 1.0: – In the year between 1970–1990 the ﬁrst evolution ‘Healthcare\
    \ 1.0’ was introduced. Due to\nlimited digital resources, it was restricted to\
    \ paper documentation. It was mainly focused on improving the efﬁciency\nof health\
    \ services and a reduction in paperwork. The revolution transformed the home remedy\
    \ system and the\nuntrained physicians who provide paternal care into a more sophisticated,\
    \ intelligent, and data-driven system that\ncan be called the “medical complex”.\
    \ In the 1830s the British government start piping the water to homes, when\n\
    the plague was caused due to drinking of polluted water [114,171]. Shortly thereafter,\
    \ the scientiﬁc vaccine theory\nwas established [48]. In the 19th century, a better\
    \ environment for healthy living integrated measures for sanitation,\ninfection\
    \ control, vaccination, and epidemiology surveys have been created.\nHealthcare\
    \ 2.0: – The era of Healthcare 2.0 was between 1991–2005, the main focus was to\
    \ combine with digital\ntechnology. Industrial machinery kept working and changing.\
    \ In the 20th century to increase the productivity of\ncheap products, the automobile\
    \ industry introduces the concept of mass production [120]. The healthcare system\n\
    also follows the same. At the end of the 19th century, few large pharmaceutical\
    \ companies were formed [214]. A few\nyears later various antibiotics were introduced,\
    \ with the advent of mass-industrial manufacturing technology [299].\nAlso at\
    \ that time in medical education importance was given to both clinical training\
    \ and basic science education\n[93]. Hospitals are expanding, being provided by\
    \ more specialists, and doctors are being trained to deal with more\npatients\
    \ with complex conditions. The main focus is on building a part of healthcare\
    \ 2.0 [58]. The second version of\nhealthcare is aimed at improving productivity\
    \ and data sharing. The focus on information sharing is not limited to\nwithin\
    \ the organization but among a group of other healthcare providers. The new version\
    \ is entrenched in response\nto the symptoms, illness, and needs of the individual.\
    \ Information was shared with other organizations with privacy\nand security.\
    \ It was electrical energy-oriented.\nHealthcare 3.0: – The era of healthcare\
    \ 3.0 was between 2006–2015. In this evolution, Electronic Health Records\n(EHRs)\
    \ were introduced. It helps the doctors in accessing patient records through cloud\
    \ gateway. It was a step\ntowards creating a value-based model based on Telecommunication\
    \ and information communication technology\n(TICT), which provides database enhancement\
    \ and additional data efﬁciency to prevent medical-related problems\n[1]. The\
    \ advent of microcontrollers in the 1980s allowed for the production of small\
    \ computers and fast-tracking\nenvironments, as well as large data storage [127,255].\
    \ With advanced computer technology, tomography jumped\nfrom single images to\
    \ redesigned images, and doctors could diagnose ulcers with more information and\
    \ diagnose\ndiseases earlier. Doctors are provide evidence-based medicine after\
    \ diagnosis disease [85]. They have additional\ninformation gathered from e-libraries\
    \ using fast computer technologies. Healthcare 3.0 focused on providing emer-\n\
    gency care and was able to ensure preventive care before the onset of illness\
    \ or symptoms of the disease. Internet\nchanges learning because much medical\
    \ literature is available at e-libraries. In Healthcare 3.0 major concern is to\n\
    use technologies like BDA and IoT-based wearable devices along with advanced E-Medical\
    \ record databases.\nHealthcare 4.0: – From 2016 to 2020, the era of Healthcare\
    \ 4.0 was introduced with patient-centric healthcare\nservices with the advent\
    \ of new technologies and IoT devices [261]. This healthcare evolution is inspired\
    \ by ‘In-\n242\nM. Kumar and A. Singh / Probabilistic data structures in smart\
    \ city\nFig. 11. Health generation.\ndustry 4.0’ by establishing personalized\
    \ healthcare platforms and augmented virtualization [271]. It was focused on\n\
    smart devices, involving capabilities of empowering data analytics with ML, DL,\
    \ AI, and IoT for the detection of\ndiseases, [151]. It is the successive approach\
    \ of 1.0, 2.0, and 3.0. Patients get medicine from suppliers by using their\n\
    websites and also get medical assistance through blogs [240]. In this case, patient\
    \ records are shared with healthcare\nprofessionals via an e-Health record over\
    \ the cloud or on the LAN, where many patients and healthcare workers\ncan be\
    \ connected. It helps the physician to access patient records anywhere and also\
    \ communicate with fellow doc-\ntors for better treatment. However, data sharing\
    \ has introduced new challenges such as authentication, security, and\nauthority,\
    \ and so on, [280]. New hands & a new brain, which includes robots, mini-laboratories,\
    \ wearable devices,\nand 3D printers. Every device works faster and more efﬁciently;\
    \ illnesses can be quickly diagnosed using a drop of\nblood; custom-designed surgery\
    \ of body joints can be performed, and bone framework can be prepared using 3D\n\
    printing [280]. Healthcare 4.0 also involves technologies like robotic surgery,\
    \ CC, CPS, information security, and\nmany more.\nHealthcare 5.0: – The era of\
    \ healthcare 5.0 began in 2020 and is going on. This machine includes AI features\n\
    such as a robot nurse, a smart IoT device, and a 6G network speed. [186]. With\
    \ latency (10–100 ms) and reliability\n(99.9999%) [150], and based on ultra-high\
    \ accuracy for remote connections [314], 6G communication addresses\nreliability\
    \ and latency issues in smart cities. Why not 5G? According to [141] 5G will fall\
    \ short of meeting future\ndemands for big data connections such as holographic\
    \ communications (e.g., 3D video conferencing), games, and\ntelesurgery. This\
    \ evolution comes up with device-to-device, machine-to-machine, and human-to-machine\
    \ commu-\nnication. The human-machine cooperation and participation improve the\
    \ diagnosis system and fast results. This\nsystem is more secure than its predecessors.\
    \ A blockchain-based architecture for healthcare applications that auto-\nmatically\
    \ collects data and removes unreliable systems from external companies. The system\
    \ is not dependent on a\nsingle-point failure due to a decentralized network [150].\n\
    The evolution of the healthcare system has also been succinct in Table 4.\nM.\
    \ Kumar and A. Singh / Probabilistic data structures in smart city\n243\nTable\
    \ 4\nEvolution of healthcare\nParameters\nHealthcare 1.0\nHealthcare 2.0\nHealthcare\
    \ 3.0\nHealthcare 4.0\nHealthcare 5.0\nEra Duration 1970–1990\n1991–2005\n2006–2015\n\
    2016–2020\n2020-till date\nObjective\nReduce paper work\nProductive and Sharing\n\
    data\nCome Up with patient\ncentric solutions\nProvide real time\ntracking and\
    \ response\nsolutions\nHigh accuracy in\ndiagnose the diseases\nand analyze the\
    \ huge\namount of data\nFeature\nModular computing\nsystems have emerged\nfrom\
    \ the health sector\nDevelop EHR to provide\nbetter view for\nphysicians\nCombine\
    \ data with\nNetworked EHR, Use\nmicrocontrollers (small\ncomputers) which\nfacilities\
    \ speedy\ncomputation\nCombine with real-time\ninformation collection,\nImprove\
    \ and Increase AI\nuse\nHighly integrated\nefﬁcient sensors which\nhelp to monitor,\
    \ collect\nand diagnose diseases\nFocus\nSimple automation\nConnectivity with\
    \ other\norganizations\nInteractivity with\npatients\nIntegrated real time\nmonitoring,\
    \ diagnostics\nwith AI support\nNo data loss machine to\nmachine and device to\n\
    device communication\nTool\nMachine Tool\nDigital Technology\nComputer, digitization\n\
    and the internet\nIoT, CC, Big Data,\nRobotics, AI\nHuman-Robot\ncollaboration,\n\
    sustainability,\nglobalization\nLimitation\nLimited functionality\nShared limited\n\
    information\nDifferent levels are used\nwithin the community\nfor limited interaction\n\
    Does not achieve full\ncustomer satisfaction,\nNew and untested\ntechnology\n\
    Run in only smart city,\nby integrating modern\nsoftware and\ntechnologies decision\n\
    making is complex\nprocess\nFacilities in Smart Healthcare: – The main participants\
    \ in smart healthcare are research institutes and hospitals,\npatients, and doctors.\
    \ Smart healthcare has many beneﬁts, like disease prevention and monitoring, diagnosis\
    \ and\ntreatment, hospital management, health decision-making, and medical research.\
    \ ICT, IoT, AI, 5G internet, big data,\nand modern biotechnology are the foundations\
    \ of the intelligent healthcare room, according to [108]. Doctors use\nLaboratory\
    \ Information Management system, Electronic medical record etc. for managing health\
    \ data [207].\n7.1.2. Challenges in smart healthcare\nTrusted Communication: –\
    \ Many medical devices experience network failure, which is unacceptable when\
    \ real-\ntime data access is required. It is challenging to maintain connections\
    \ on mobile devices such as wearable devices\nwhile moving anywhere a patient\
    \ walks, crossing boundaries, and covering areas. In mobile devices, switching\n\
    the network to the most powerful available signal also affects data generation.\
    \ The different amounts of data are\ngenerated while switching to the network,\
    \ which is dependent on the roaming relationship between the SIM provider\nand\
    \ the location of the feed. As there are many subcategories for mobile connectivity,\
    \ we should also adjust the\nnetwork type and location to the value, speed, audio,\
    \ and video required by our device.\nCyber security: – Cyber security is one of\
    \ the challenges when we talk about smart healthcare. As it requires\ninternet\
    \ access and IoT devices, the data may be stolen or attackers may attack data\
    \ or modify the data. So the ﬁrst\npriority of the healthcare system is to ensure\
    \ the privacy of patients and their data. There are some private IoT-based\nnetworks\
    \ (e.g. APNs, VPNs, and IPsec protocol) that are available, which create private\
    \ areas only accessible by\nauthorized users or devices.\nScalable Platforms:\
    \ – The smooth functioning of a smart healthcare system, a scalable platform is\
    \ required. For\nthe effectiveness of a smart healthcare system to be enhanced,\
    \ it must be integrated and supported seamlessly with\npatients and their big\
    \ data. So, the authorized professionals, physicians, and patients use the devices\
    \ and system\neasily for monitoring remotely.\nCost: – Meet, the requirements\
    \ of the healthcare system are also cost-effective. The healthcare system may\
    \ take\nless time for decision-making and information gathering. So, it must require\
    \ new tools and techniques for efﬁcient\nstorage and retrieval.\n244\nM. Kumar\
    \ and A. Singh / Probabilistic data structures in smart city\nData Availability:\
    \ – The availability of data is facing some issues like resource management and\
    \ device identiﬁ-\ncation. Systems don’t need any redundancy; they only need consistent\
    \ data. So it requires identifying the resources\nand storage management with\
    \ new technologies in healthcare systems.\nData Security: – While accessing the\
    \ data, it is mandatory that only the authorized user can access the concerned\n\
    data. It still needs to be improved.\nUnique Identiﬁcation: – In the healthcare\
    \ system, it is required to uniquely identify patients by their doctor and\nvice\
    \ versa. This is required for providing or getting the best and correct treatment.\n\
    Privacy Issue: – This is one of the major issues while we are talking about big\
    \ data and IoT devices in a smart\ncity. Many kinds of research provide many tools\
    \ and techniques. But still, it needs to be improved.\nDevice Communication: –\
    \ Machine to machine, a device to machine, and human to machine communication\
    \ is\nchallenging. Patients need a quick response to their records, medical tests,\
    \ and medical reports. A 5G/6G network\nis required for the smooth transformation\
    \ of data communication. It is cost-effective, and also required some tools\n\
    and algorithms for privacy and data exchanges.\nData Integrity: – Ensuring the\
    \ integrity of healthcare data is also challenging because it is important for\
    \ providers\nto use it in making decisions about patient care. It is also required\
    \ for information exchange between doctors and\npatients.\n7.1.3. Application\
    \ of PDS in smart healthcare\nDue to the rapid growth in the population and an\
    \ epidemic, hospitals are overburdened and overcrowded. Patients\nare struggling\
    \ to ﬁnd the doctor’s ofﬁce and pre-body check-up center. Patients and their guardians\
    \ also face the\nissue of understanding medical terms, and they need someone’s\
    \ help to get the proper information. For that, a\nproper healthcare system is\
    \ required with the use of new technologies like sensors, IoT, ICT, etc. On one\
    \ hand, the\nIoT has beneﬁted patients, physicians, hospitals, and health insurance\
    \ companies. On the other hand, challenges\nhave increased. Because sensors and\
    \ IoT have produced massive amounts of data, To handle this data, the following\n\
    is the application of PDS which may be used in smart healthcare systems:\nData\
    \ Processing: – The data generated by devices is homogeneous or heterogeneous,\
    \ semi-structured or unstruc-\ntured, which will result in the trafﬁc load on\
    \ switches. The storage capacity of switches is limited, so the perfor-\nmance\
    \ of routing may be compromised. A scheme ‘BloomStore: Dynamic Bloom Filter-based\
    \ Secure rule-space\nmanagement’ is proposed for Software Deﬁned Networking (SDN)\
    \ [245]. The scheme uses two self-dependent hash\nfunctions for security checks\
    \ and also manages the network resources to handle the trafﬁc in data. Smart healthcare\n\
    systems provide system-assistance analysis for dedicated medical care to patients.\
    \ The security of this data is in dan-\nger. The data security features are improved\
    \ to prevent unauthorized access to information in healthcare systems.\nBF is\
    \ also useful in data transmission elimination [300].\nData Sharing: – The Garbled\
    \ Bloom ﬁlter is used to support authentic search results and secure data sharing\
    \ for\nmultiple users [260] in the Veriﬁable Multi-Key Searchable Encryption (VMKSE).\
    \ This scheme supports single-\nkeyword search. The author also compares his programme\
    \ with a modern solution to evaluate its effectiveness. This\nscheme helps in\
    \ doctor-patient data sharing. The multi-keyword search veriﬁcation mechanism\
    \ is introduced based\non pseudo-random and it is IoT-cloud-enabled for healthcare\
    \ data systems [283]. The mechanism also takes care\nof authentication and advanced\
    \ encryption with advanced privacy of data. BF is used in a secure two-dimensional\n\
    calculation protocol, to compare a unit of characters and record [277].\nData\
    \ Security and Privacy-Preserving System: – The use of IoT in smart cities plays\
    \ a big role in smart healthcare.\nA huge amount of data is exchanged between\
    \ machines, humans, and devices. This big data can be encrypted and\nthen stored\
    \ on a cloud so that only authenticated users can access it. There are also privacy\
    \ issues. A scheme for\nefﬁciently sharing data is proposed to address this issue.\
    \ The author uses attribute-based encryption with attribute BF\nto control access.\
    \ While transforming data or sharing sensitive information, a lot of privacy concerns\
    \ may arise. Xu\net al. propose a scheme using BF, which is privacy-preserving\
    \ for patient health information for sharing information\n[293]. The author uses\
    \ an encrypted search method that allows numerical search for encrypted data.\
    \ The BF and\nmessage veriﬁcation code are used to ﬁlter patient data and check\
    \ the accuracy of search results. Liu et al. design\ncooperative privacy preservation\
    \ for wearable devices that ensure authenticity and consideration for controlling\
    \ data\naccess in the context of space and time information [162]. In space-aware,\
    \ they use MinHash-based authentication,\nand in time-aware, attribute-based encryption\
    \ is applied. They adopted BF to determine the existence of sensitive\nM. Kumar\
    \ and A. Singh / Probabilistic data structures in smart city\n245\nFig. 12. Status\
    \ ledger’s block size with and without using BF. [11].\ndata in storage without\
    \ exposing secret information, and for secure data interaction, positive and negative\
    \ ﬁlters\nare used. Seham A., et al. [11] introduce a system for infection control\
    \ with the use of Blockchain for privacy-\npreserving. In this system, one leader\
    \ elected by authority updates the two BFs, one for infected users and the other\n\
    for close contact users. Two BF are used for infected and suspected users, which\
    \ reduces the storage space. The\nblock size of the COVID-19 status ledger with\
    \ and without using BF is also compared (Fig. 12).\nFast Response and Congestion\
    \ control: – The number of connected devices in the network (like trafﬁc lights,\n\
    vehicles, laptops, smartphones, etc.) is increasing exponentially. For resource\
    \ sharing and effective communication,\nall devices with different conﬁgurations\
    \ have to be integrated into the same network. Due to the rapid growth of\nthese\
    \ devices, the trafﬁc in the network also increases, causing difﬁculty in predicting\
    \ trafﬁc patterns. G. S. Aujla\net al. propose an approach to handle these issues.\
    \ “Blockchain-as-a-Service for Software Deﬁned Network (SDN)\nin Smart City Applications”\
    \ is mentioned [23]. Multiple etiquette ﬁrmware can be integrated into a single\
    \ network\nusing the SDN controller [22].\nIn “Software-deﬁned Content Dissemination\
    \ Scheme for Internet of Healthcare Vehicles in COVID-19 like Sce-\nnarios”, [111]\
    \ introduces a new way to ﬁnd the right online distribution channel described\
    \ in the healthcare ecosys-\ntem software. Internet of Healthcare Vehicle (IoHV)\
    \ is an emerging concept that depends on smart transport, includ-\ning ambulances\
    \ and additional healthcare vehicles (testing Covid-19 immediately). To connect\
    \ to the internet, espe-\ncially when possible, for testing COVID-19 immediately\
    \ and contact tracing, this IoHV is helpful and is deployed\nacross a smart city\
    \ setup. All healthcare vehicles are connected to each other through different\
    \ types of links: vehicle-\nto-pedestrian (V2P), vehicle-to-vehicle (V2V), infrastructure-to-infrastructure\
    \ (I2I), vehicle-to-infrastructure (V2I),\nand cellular links [147]. To overcome\
    \ congestion and improve response, the global information of devices is stored\n\
    in the deletable BF in the proposed framework. While implementing in the real\
    \ world, there are many ambient\nintelligence challenges. Some of them related\
    \ to healthcare are listed below:\nAdopting Advance healthcare technology: Almost\
    \ all medical devices are connected to IoT devices. The man-\nagement systems\
    \ like appointments, patient administration, laboratory information, etc. are\
    \ now handled by ML and\nAI. So it is necessary to develop a connected network\
    \ of healthcare leaders, clinics, manufacturers, and software\ndevelopment companies.\
    \ which enhances the new business models and also helps adopt the new technologies.\n\
    Integration between healthcare services: The massive amount of data is generated\
    \ while using medical devices\nand AI-integrated applications. Many top healthcare\
    \ companies lack data management systems and new architec-\nture.\nRising Healthcare\
    \ cost: The rising costs of healthcare are always a serious issue, which includes\
    \ the manufac-\nturing cost of healthcare vehicles and disease detection and testing\
    \ processes. Due to this, many patients skip lab\ntests and do regular follow-ups.\n\
    246\nM. Kumar and A. Singh / Probabilistic data structures in smart city\nPayment\
    \ Veriﬁcation: – In this digital world and epidemic, the maximum number of transactions\
    \ is done digitally\nand payment veriﬁcation is required. In this lieu, Pratim\
    \ et al. a lightweight payment veriﬁcation based on the\nblockchain using BF is\
    \ proposed as IoT-Assisted e-Healthcare [223]. If BLWN simply asks for the full\
    \ location of\na small set of blocks/topics, there may be a chance for privacy\
    \ leaks as the full area can peer into BLWNs’ assets. It\nmay allow the full site\
    \ to call for Denial of Services (DoS) and the insigniﬁcant liaison service for\
    \ funds available\nfrom BLWN. Therefore, it may be completely overwhelmed by the\
    \ great difﬁculty in its ability to make a computer\nwhile crashing its system.\n\
    Real Time Analysis/Support: – Wearable devices are mainly used in real-time Electronic\
    \ Health Records (EHR)\ncollection. Obviously, encryption is required for searching\
    \ targeted EHRs by medical institutions. In this reference,\nYuan et al. [259]\
    \ propose a scheme in which medical institutions can search and access EHRs in\
    \ the cloud. They\nimprove the search accuracy and privacy of users in EHRs. To\
    \ improve search efﬁciency, the Cuckoo ﬁlter is used\nand gives a facility to\
    \ data owners for modiﬁcation (insert and delete) in their EHRs in the cloud.\n\
    7.2. Smart transportation\nFor moving from one place to another, horses and camels\
    \ were used for a long time in society. The world has\nentered the next phase\
    \ of the movement, namely smart transport, with the advent of new technologies\
    \ and smart\ntransportation systems [180]. “Moving smarter is not our future –\
    \ it is already our present”, says Lisa Jerram, senior\nanalyst at Pike Research,\
    \ simply to make sure the easy journey is acceptable as cities become more populous\
    \ and\nface potential budget crises by building new infrastructure, as is the\
    \ case in Europe, North America and Japan, [38].\nAccording to [274], the population\
    \ of the world’s urban areas increased from 29% to 50% between 1950 and 2008,\n\
    and it is expected to increase to 70% by 2050.\n7.2.1. Application of smart transportation\n\
    To meet the increased demand of citizens, the easy option is to provide then better\
    \ transport services. With this\nthe growth in supply of automobile is increases,\
    \ due to that the trafﬁc congestion is also increases. The attraction to\nthe\
    \ development of smart transport system took a lot of attention to addressing\
    \ trafﬁc congestion and rapid urban\ngrowth [71]. It is identiﬁed that the implementation\
    \ of smart technologies is the key factor in gaining intelligence\nand stability\
    \ [107,233]. Also several researchers shown that how this sustainability achieving\
    \ the environmental and\neconomic efﬁciency [71,115]. Therefore, sustainable transportation\
    \ is very important in today’s society. There are\nvarious application under smart\
    \ transportation are discussed as follows:\nSmart Street Light: – Smart city should\
    \ also needs to upgrade Road street light to smart street light. It helps in\n\
    reducing the energy consumption by dimming the lights. This saved energy are then\
    \ used for other services like\npollution monitoring, update about whether, GPS\
    \ etc. and also help in signing available parking in nearby area.\nBut smart street\
    \ lights are depending on its feature and requirements, and involve a combination\
    \ of cameras and\nsensors. Sensors and Cameras are collecting the data can either\
    \ process locally if street light have computing device\nor propagate through\
    \ network. These devices can detect the movement which enable dynamic lighting\
    \ and dimming\n[102]. Chen et al. present a system which used for controlling\
    \ the street lights using TX2 device and also help in\nupdating the parking status\
    \ to users (Fig. 13).\nIntelligent Transportation System (ITS): – Today, the state-of-the-art\
    \ transport system is heavily inﬂuenced by\nMachine Learning (ML) and Dynamic\
    \ Range Learning (DRL) based strategies to detect autonomous vehicles,\ndispatch\
    \ passengers in a safe manner and ensure the safety of vehicles. ITS uses the\
    \ various advance technologies\nlike senros, IoT devices, ICT and many more [302].\
    \ The huge amount of data is being generated by these IoT devices\nand sensors\
    \ which contributes to the concept of intelligent cities and the future of ITS\
    \ [312]. The techniques like\nAI, ML, and especially DRL play an important role\
    \ as an integral part of sustainable in precisely monitoring and\nmeasuring real-time\
    \ data trafﬁc ﬂow in an urban area [301,305].\nThe various applications of ITS\
    \ are discussed by [302] like: The intelligent highway in Britain, which reduces\n\
    the trafﬁc and accident rate, The CRITER system in Lyon, France, offers transportation\
    \ workers a schematic plan\nlike a map and also predicts the bottleneck points.\
    \ In Japan, electronic toll collections (ETC) measure the physical\ncharacteristics\
    \ of vehicles and check and deduct charges automatically if they are in ETC. It\
    \ is useful to avoid\nillegal entry into the city. Include IoT in ITS to build\
    \ a system where communication between road facilities,\nM. Kumar and A. Singh\
    \ / Probabilistic data structures in smart city\n247\nFig. 13. Smart street light\
    \ scenario [59].\nvehicles, and management equipment is done without barriers.\
    \ The Global Positioning System (GPS) is replaced by\nRadio Frequency Identiﬁcation\
    \ (RFID) in the IoT to become the Smart Transportation System (STS). The author\n\
    also discusses the services for passengers on public transport, like service range,\
    \ charging, security control, and\nadministration.\nAvailability of Parking: –\
    \ With the rapid growth of vehicles in the city, it is a trick for drivers to\
    \ ﬁnd available\nparking. This dilemma is seen as an opportunity to increase the\
    \ efﬁciency of parking facilities, thereby decreasing\nroad accidents and taking\
    \ less time to ﬁnd free space in a smart city. The troubles related to parking\
    \ and trafﬁc\ncongestion could be solved if drivers were aware in advance of the\
    \ availability of parking in the area and surround-\ning areas [39]. A smart and\
    \ automated system that can detect empty parking spaces can reduce search time,\
    \ by\nﬁnding out where parking is available and bypassing lawful information to\
    \ drivers. Maria et al. proposed an image\nprocessing system that takes video\
    \ as input from a drone and feeds it into a frame extraction block [176]. These\n\
    frames are then preprocessed to reduce complexity. These systems may be improved\
    \ if the availability of data and\nthe techniques to manage this data were improved\
    \ or changed with new technologies.\nStreet lights can also play an important\
    \ role in detecting empty parking spaces in open environments. Traditional\nparking\
    \ (sensor-based) occupancy systems are more expensive, as demonstrated by [59].\
    \ They use Jetson TX2, an\nNVIDIA’s Computer Uniﬁed Device Architecture embedded\
    \ artiﬁcial intelligence supercomputer, which has high\npower efﬁciency. This\
    \ system works both day and night with an on-off street parking smart control\
    \ system. Parking\nspace is detected by marker-based image processing using the\
    \ onboard camera of an Unmanned Aerial Vehicle\n(UAV) [67].\nTrafﬁc Control: –\
    \ The authorities are facing chaos trying to manage the trafﬁc with an increase\
    \ of vehicles on the\nroads. Because of a lack of human resources, authorities\
    \ are moving toward smart trafﬁc control to manage the city’s\ntrafﬁc. To reduce\
    \ congestion in the context of VANETs, robots can play a key role. The aim of\
    \ smart robots is to give\ninformation to avoid ideal roads and manage trafﬁc\
    \ congestion in urban areas. To detect illegal trafﬁc behaviour or\ntrafﬁc violations,\
    \ the system uses street cameras [66]. But it is not possible to install street\
    \ cameras everywhere in\nthe city. Modern cars with video storage cameras have\
    \ been introduced to control trafﬁc violations in the city. These\ncars capture\
    \ the videos in the city and report any violations that happen to the authorities.\
    \ Rathore et al. propose a\nsystem to detect the front car and road line using\
    \ the Single Shot MultiBox Detector (SSD) and Hough transform\nfor self-driving.\
    \ A violation detection algorithm is designed for the fog device smart to identify\
    \ driving violations,\nU-turns, and driving central dividers [222]. Steve Mazur\
    \ has also presented a trafﬁc control system (Fig. 14) in\n[180].\nAutomated Toll\
    \ Collection: – To decrease the fuel consumption used in automobiles, the use\
    \ of the cream road\nis required. The government and road contractors are working\
    \ on making the new highways and ﬂyovers in the\ncities, and contractors are installing\
    \ their toll on those roads to complete their expenses. Motorists and commuters\n\
    are spending their valuable time at the toll plazas paying the amount of tax.\
    \ Due to this, the parking problem, trafﬁc\n248\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\nFig. 14. Smart trafﬁc control [180].\ncongestion,\
    \ and pollution are increasing near the toll plaza. Commuters are also facing\
    \ delays, which increases\nthe travel time for their journey [34]. Automatic toll\
    \ collection is on the rise nowadays, both by governments and\nresearchers. The\
    \ main concern with this automated toll collection system, the RIFD tag, is that\
    \ it is installed on\nthe windshield of vehicles. To collect the required amount,\
    \ the vehicles pass through the sensor system before the\ntollgate [134]. Regular\
    \ user may also have facility of prepaid smart cards. So that the trafﬁc at tollgates\
    \ can be\navoided. M.A. Berlin et al. propose an alert message based toll collection\
    \ system using smart Road Side Unit (RSU)\n[34]. This system also helps in stopping\
    \ the payment violation by send the alert message if the any vehicle violate\n\
    the toll payment. This system is totally man free and barricade free, which also\
    \ help in rush hours to handle the\ntrafﬁc [34]. As the use RIFD tags not only\
    \ the time is saved but also eliminate the corruption in toll plazas [8].\nSmart\
    \ Mobility: – Smart mobility is also the main concern in smart transportation\
    \ as it is consistent with the\ndevelopment of a sustainable world [101]. In particular,\
    \ either ICT is the initiative to smart mobility or a complete\nfailure [31].\
    \ Smart Mobility is providing solutions to users by using new technologies like\
    \ IoT, ICT etc. Some\ntourists use apps to plan their journey, but they get limited\
    \ information and priorities for travel recommendations\n[205]. Smart mobility\
    \ is also helpful for citizens to roam and move freely in the vicinity of a smart\
    \ city. Smart\nmobility also helps in improving the trafﬁc control system by giving\
    \ access to other routes in emergencies or trafﬁc\njams. Intelligent navigators\
    \ facilitate providing routes and navigating to essential services like ambulances\
    \ and\ngovernment. can be facilitated by intelligent navigation. In the coming\
    \ year, smart mobility transform into mobility\nas a service paradigm, like car-sharing\
    \ [205].\n7.2.2. Beneﬁts of smart transportation\nFigure 15 explores a picture\
    \ of smart transportation in the city. Smart transportation has many beneﬁts,\
    \ some of\nthem are discussed as.\nSmart Transportation is safer: – In smart transport\
    \ the integration of ML with IoT, 5G help in reducing trafﬁc\nand road accidents.\
    \ In these IoT devices, cameras and other safety devices help in monitoring the\
    \ trafﬁc situation\nand intimate the same to users for improving road safety.\n\
    Smart Transportation is better managed: – Smart transportation facilitates the\
    \ public administration by allowing\nto monitor the performance of road safety\
    \ and trafﬁc. It also gives information on critical sources of problems and\n\
    tracks where maintenance is required.\nSmart Transport is very effective: – With\
    \ better management of resources in smart transport gives more efﬁcient\nresults.\
    \ If we are having quality data, then easily identify the areas where improvement\
    \ is required. It also provides\nbetter-quality ﬁlling rates.\nM. Kumar and A.\
    \ Singh / Probabilistic data structures in smart city\n249\nFig. 15. Smart transportation\
    \ [180].\nSmart Transportation is more cost-effective: – Smart transportation\
    \ also helps in reducing the cost by providing\nthe best shortest routes, giving\
    \ information regarding facilities available with approx distance and price, and\
    \ many\nmore. Commuters also take beneﬁt if they get affordable public transport\
    \ as compared to hiring a private CAB.\nSmart Parking Management: – In smart parking\
    \ the driver or car owner can’t face the problem of ﬁnding the avail-\nable space\
    \ for parking. The system provides the information by collecting real-time data\
    \ from connected devices\nand sensors.\nSmart Trafﬁc Management: – With the smart\
    \ trafﬁc management system users can get information about conges-\ntion on road.\
    \ So that they can plan their journey accordingly.\nSmart Transportation provides\
    \ instant information: – Smart transport system can also provide information in-\n\
    stantly regarding the issue in the city, trafﬁc congestion, and problem areas\
    \ using trafﬁc management centers. They\nalso ensure public safety and provide\
    \ information on affordable insurance plans.\nIntegrated Ticket Systems: – It\
    \ will also provide diverse services to citizens by providing the intelligent\
    \ ticket\nsystem in some local services.\n7.2.3. Challenges in smart transportation\n\
    A large number of vehicles in major cities around the world has posed major transportation\
    \ and stability chal-\nlenges, like air pollution, trafﬁc congestion and energy\
    \ problems [284]. Following are some challenges to smart\ntransportation.\nSecurity:\
    \ – Vulnerable to cyberattacks is one of the biggest fears among smart city dwellers.\
    \ Cyber attacks are\nmore common to criminals as the world’s connectivity to the\
    \ internet increases. The data ﬂow during the smart\ntransport management system\
    \ are may be hacked or used to thief the vehicle if there is no secure communication.\n\
    The security of data used in toll collection systems is also in danger. During\
    \ ﬁnding the available parking space user\nshare their location, this also may\
    \ create problems in user security.\nData Privacy: – User data cannot be retrieved\
    \ without their knowledge. The user’s personal identity must not be\nidentiﬁed\
    \ or traced. Data privacy in smart transport is the main concern. Under the new\
    \ law, data processing must\nhave legitimate.\nSupply Chain: – Due to epidemics\
    \ like Covid-19 the global supply chain is affected. While transportation may\n\
    face various problems during this epidemic. Due to that many businesses are affected.\
    \ When the drivers may ill and\nmove from one region to another it may cause public\
    \ health.\nEnvironmental Problem: – With the rapid growth in the automobile industry\
    \ the trafﬁc on roads also increases.\nThis may affect the air quality and water\
    \ pollution in nearby residential areas. The environmental problems caused\nby\
    \ the IoT devices are currently serious and need to be addressed urgently [180].\n\
    Health Concern: – Health concern is also one of the challenges to smart transportation.\
    \ If the transport system is\nnot connected to hospitals, then it may cause major\
    \ problems or may loss their lives in road accidents. The system\nneeds to improve\
    \ its service on road, and proper intimation of the concerns (hospitals and police\
    \ stations).\n250\nM. Kumar and A. Singh / Probabilistic data structures in smart\
    \ city\n7.2.4. Applications of PDS in smart transport\nThe trafﬁc on roads in\
    \ both rural and urban areas is increasing day by day. It needs to smartly manage\
    \ the trafﬁc\nand distribute the trafﬁc load by making the transport system to\
    \ be smart. It includes smart parking, smart street\nlights, violation check on\
    \ the roads, trafﬁc control system etc.\nData Dissemination: – It means the statistical\
    \ data is transmitted or distributed to end-users. In Pursuing a\nPub/Sub Internet(PURSUIT)\
    \ project use BF to store the path information in source routing. The main scenario\n\
    of this project is general data dissemination [16].\nPrivacy Preserving: – The\
    \ IoT devices and sensors are used to collect and exchange a huge amount of data,\
    \ to\nimprove the transport system. As Cloud Computing progressed, more sensitive\
    \ information (like vehicle registration\nnumber, chassis number, insurance detail,etc.)\
    \ was released to the cloud. The most accurate way to protect data\nprivacy is\
    \ to encrypt data before extracting it [253]. Enabling keyword searches directly\
    \ over encrypted data is a\ndesirable way to make the best use of encrypted data.\
    \ Wang et al. has proposed a brand new idea for acquiring\nmultiple keywords (compound\
    \ keywords) in random search [282]. Unlike most existing keyword search programs,\n\
    the program eliminates the requirement of a predeﬁned keyword dictionary.\n7.3.\
    \ Smart environment\nMany developed cities suffer from poor air quality as population\
    \ and industry growth rapidly. Increasing accep-\ntance of smart transport data\
    \ in smart cities around the world has provided unprecedented opportunities to\
    \ improve\nair quality management in transportation [284]. Government agencies\
    \ and residents are increasingly concerned with\nair grade, which contributes\
    \ to a wide range of human environments and human development. The most common\n\
    methods of predicting air pollution especially utilize low-level simulations.\
    \ These standards produce disappointing\neffects that have led to aspects inﬂuencing\
    \ the measurement of air corrosion based on the overall structure of the\nbuilding.\
    \ Estimating air quality using atmospheric scattering standards is time-consuming.\
    \ Modeling incorporated\ntesting is a new expansion to measure air pollution and\
    \ conservatory gases in an intelligent environment. Normally,\nmaximum houses\
    \ in a smart city are used solar and wind turbines for green energy [140]. Liu\
    \ et al. suggested a\nLong Short-Term Memory (LSTM) model in planning smart environment\
    \ in smart cities, which predict air quality\nthat assists Staked Auto-Encoder\
    \ (SAE) [165]. LSTM is used to evaluate air quality forecasts in smart cities.\
    \ The\ninternal components that occur due to air pollution are removed by optimizing\
    \ SAE. The total error rate is 0.46 and\nthe class accuracy of 91.22% is shown\
    \ by this model, it still needs to be improved.\nJovanovska et al. proposed and\
    \ air quality system based on IoT and Cloud computing [130]. They visualize and\n\
    control air pollution using mobile applications. Sulfur oxide (SO2), Ozone(O3),\
    \ Nitrogen dioxide (NO2), and most\nimportant PM10 and PM2.5 are common indicators\
    \ of contamination that cause health risks like heart and lung\ndiseases. So,\
    \ improving the quality of air is a good effort by everyone for the weather and\
    \ health of every citizen.\n7.3.1. Challenges in smart environment\nThe major\
    \ challenges for the environment are water pollution, air quality, and radiation.\
    \ To achieve sustainable\ngrowth by maintaining a healthy society proper vigilance\
    \ is needed in the world. With the development of IoT and\nsmart sensors, Smart\
    \ Environmental Monitoring (SEM) is the system for environmental monitoring, in\
    \ the latest\nyears [273]. Figure 16 shows various issues of environment like\
    \ temperature, radiation, dust, humidity, ultraviolet\nsignal etc. For establishing\
    \ the system Silvia et al. used the WSN which provides an interface between smart\
    \ sensors\nand IoT Devices [273].\nAir quality Monitoring: – Due to the rapid\
    \ increase in trafﬁc and industries, air pollution is one of the primary\nconcerns\
    \ of our epoch. The earth is becoming increasingly polluted due to the emissions\
    \ of harmful gases like CO,\nNO2, SO2, and CO2. These toxic gases can’t be predicted\
    \ because there are dissolve in the air. So, the air quality\nneeds to be checked,\
    \ and for that, an IoT-based tool is required. An IoT device can collect and analyze\
    \ the data\nto predict the air quality either good or bad. Sensors using Raspberry\
    \ Pi/ Arduino and IoT devices can monitor\nthe local air quality [175]. Dhingra\
    \ et al. develop an application i.e. “IoT-Mobair”, which is mobile-based use to\n\
    monitor and detect the air pollution of the concerned area [76]. This mobile-based\
    \ application has various features\nlike air quality, daily forecasts, health-related\
    \ tips, and risks, air quality map generations etc. But, when dealing with\nbig\
    \ data generated from sensors, then this application has faced some computational\
    \ complexity problems. For that\nM. Kumar and A. Singh / Probabilistic data structures\
    \ in smart city\n251\nFig. 16. Challenges in smart environment.\nDhingra et al.\
    \ have suggested using fog computing instead of cloud computing. The IoT is a\
    \ global system of “smart\ndevices” which can detect and communicate with the\
    \ environment and interact with users and other applications.\nQian et al. found\
    \ that due to low sensitivity and low accuracy the exiting monitoring system does\
    \ not work well and\nit also requires laboratory analysis [218]. The data is highly\
    \ correlated in the case of air pollution monitoring, where\nthese systems are\
    \ leads to a lot of obsolete information. To the data delivery cost and to alleviate\
    \ data neglect Qian\net al. the system i.e. ‘Content-centric IoT-based Air pollution\
    \ Monitoring (CIAM)’. In CIAM, the content method\nis used to compile and integrate\
    \ air pollution data.\nWater quality Monitoring: – Monitoring of water quality\
    \ is important in determining water safety and related pub-\nlic health [256].\
    \ Water quality parameters are determined by the same factors as physical, chemical,\
    \ and biological.\nBacterial contamination, turbidity, dissolved oxygen, dispersion,\
    \ free chlorine, and pH are the typical parameters\nof water quality [215,219].\
    \ The various research papers have been studied in terms of intelligent water\
    \ pollution\ncontrol systems using ML, IoT, and smart sensors. The pollution of\
    \ water in the lake can be predicted using an\nML-based neural network for machine-reading\
    \ which analyzes the sensed image [160]. The water is classiﬁed as\npure or polluted,\
    \ and we studied the separation of water pollution with the use of ML methods\
    \ and IoT devices [61].\nThe prediction of water quality parameters using AI and\
    \ neural networks and the amounts of sulfate or chloride\npresent in water were\
    \ studied [220]. In order to separate the pollutants in water using SVM, the analysis\
    \ of big data\nand problems faced during the separation of water pollution were\
    \ discussed [46]. AI-SVM is a classiﬁcation system\nused for real-time monitoring\
    \ and technology used for testing and its separation from non-drinking water [41,128].\n\
    Video-based monitoring of water quality and pollution was investigated, which\
    \ used IoT video surveillance and\nML tools to separate dirty and clean water\
    \ [208]. To predict the future and quality of water before use, another\nfunction\
    \ which is a feature-based model, also helped in analyzing the water suggested\
    \ [311]. Different ML models\nwere used to test the concentration of chlorophyll-A\
    \ in pond water and were also recommended for real-time water\nmanagement system\
    \ [163].\nAgriculture Monitoring System: – The growth of industrial and robust\
    \ agricultural production methods has ac-\ncelerated to ensure the quality and\
    \ quantity of the growing demand for food [249]. In “smart or green agriculture”,\n\
    Smart Environment Monitoring (SEM) plays an important role as agriculture is the\
    \ relevant growth factor for any\nnation [210]. It also helps in product development\
    \ and sustainable growth to handle major challenges in the agricul-\nture sector\
    \ [196,239]. Ullo et al. refer to the smart agriculture scenarios (Fig. 17), where\
    \ the SEM system is a smart\nagricultural monitoring system in real. In the agriculture\
    \ sector, various factors are very important for achieving\nsustainable production,\
    \ like water level, water pollution level, moisture analysis, soil health etc.\
    \ These features are\nincluded in the smart agricultural monitoring system, which\
    \ is monitored and controlled using IoT devices, smart\nsensors for agriculture\
    \ data capturing, and WSN to transmit data into the cloud [273].\n252\nM. Kumar\
    \ and A. Singh / Probabilistic data structures in smart city\nFig. 17. Smart agriculture\
    \ monitoring system using IoT devices and sensors.\nIn the new agricultural era,\
    \ there is a growing market for IoT that offers a few creative solutions. The\
    \ various\nstudies and research on Smart Agricultural Monitoring systems (SAM)\
    \ are discussed, which include fertilizer con-\ntrol, crop monitoring measures,\
    \ pest control, etc. Kumar et al. propose a system for plant growth monitoring\
    \ i.e.\n‘gCrop’ using IoT, ML and WSN [148]. They use a 3rd-degree regression\
    \ model and provide a prediction with a\nhigh computational complexity of 98%\
    \ accuracy. Shinde and Pathak et al. performed a crop quality test to monitor\n\
    the quality of paddy rice using Synthetic Aperture Radar(SAR) data [242]. In the\
    \ rice quality test, SVMs were used\nwith limited sample size and back distribution\
    \ features. The land and its size play an important role in checking the\ngrowth\
    \ level of different crop species that are either satisfactory or not. To measure\
    \ the leaf index Hosseini et al.\npropose a system with a Gaussian process model\
    \ [91] and using SVM as ML method and reported 89% with a lim-\nited sample size\
    \ [119]. To determine the level of fertilizer, pesticides, and water quantity\
    \ used for plant irrigation, an\nexpert system using AI was developed [78] using\
    \ the Naive Bayes [17] method and studying ML using sensory data\ntaken from agriculture.\
    \ UAV is used [77] to investigated the crop quality tests [230] and soil health\
    \ for phenological\ndata of soybean crop [49]. Smart farming [42], pest monitoring\
    \ [164], and crop monitoring [311] are important in\nthe various uses of SEM systems.\
    \ Weather and the environment also affect the health and growth of plants. Ullu\
    \ et\nal. propose a technique that checks the condition of the soil, moisture,\
    \ air, and water quality, temperature etc. in the\ncontext of SEM using IoT devices,\
    \ AI, and smart sensors [273]. The data analysis is performed while smart agricul-\n\
    ture provides estimation, assisting protection, decision making, and storage management\
    \ [249]. The data is moving\nwhile performing the techniques to achieve smart\
    \ agriculture, and various challenges are faced by both farmers and\nresearchers.\
    \ Some of them are addressed below.\n7.3.2. Challenges in smart agriculture\n\
    To increase food production, farmers will face many challenges. The production\
    \ will increase 70% by the year\n2050 [122]. Various challenges in agriculture\
    \ have been discussed (Fig. 18) as.\nIrrigation management: – One of the objectives\
    \ of an irrigation system is to calculate the water requirement for\ncrops based\
    \ on collected data and water ﬂow without interference from humans. Irrigation\
    \ systems use dispersed\nsensors to monitor the different soils, water bodies,\
    \ vegetation, and microscopic elements. Climate is one of the\nmost important\
    \ variables in estimating agricultural water requirements. A farmer can adjust\
    \ his irrigation system in\na variety of ways according to soil and weather conditions\
    \ [216]. The entire farm can track, manage, and forecast\nM. Kumar and A. Singh\
    \ / Probabilistic data structures in smart city\n253\nFig. 18. Challenges in smart\
    \ agriculture.\nweather from almost anywhere. IoT will help in developing the\
    \ new infrastructure for irrigation in a very exciting\nway. Smart IoT-operated\
    \ irrigation systems use embedded sensors in the ﬁeld to monitor soil structures,\
    \ climate,\nand agricultural irrigation conditions.\nSoil management: – Soil monitoring\
    \ is one of the most challenging agricultural activities for both businesses and\n\
    farmers. Various soil parameters like pH, humidity, etc. are involved in soil\
    \ management and IoT sensors can be\nused to calculate these parameters. Soil\
    \ management helps in ﬁnding the right kind of plants and helps to identify\n\
    fertilizer requirements in the soil. Crop production can be affected by soil testing\
    \ due to a number of environmental\nconcerns. The process and patterns of farming\
    \ can easily be understood, if these types of problems are well deﬁned.\nCrop\
    \ production may improve and fertilization practices can be promoted based on\
    \ ﬁndings of a soil survey study for\nfarmers [37]. The moisture and humidity\
    \ sensors can monitor the moisture in the soil, and IoT technology identiﬁes\n\
    the contaminated soil and shields the ﬁeld from over-fertilization and damage\
    \ to crops. Agricultural productivity\nand quality may increase, pollution can\
    \ be avoided, and input costs may be reduced due to soil management.\nClimate\
    \ management: – Climate has a profound effect on crop production. With the use\
    \ of an IoT-enabled weather\nforecast system, farmers can determine the best time\
    \ to plant, irrigate, and harvest. With the help of distant sensors\nattached\
    \ to the ﬁeld, farmers can learn about natural conditions like humidity, soil\
    \ moisture, and air temperature.\nOn the basis of historical results, to maximize\
    \ the yield, farmers should properly prepare and market the harvest and\nirrigation\
    \ season. By editing and updating the collected data, farmers should take immediate\
    \ steps to ensure a safe\ncrop yield. Many of the right things are put together\
    \ to maintain and establish a good plant environment while living\nunder stringent\
    \ limits like airﬂow, temperature, CO2, and O2 levels. With the use of IoT-enabled\
    \ systems, where for\nadvanced decisions data can be exchanged between intelligent\
    \ sensors and devices, this can be achieved [288].\nAccurate farming: – The traditional\
    \ method of farming to increase yields and preserve crops was based on phys-\n\
    ical examination. If any issue was found, then it was resolved by trial and error\
    \ after being involved in a serious\n254\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\nincident on the farm. Farmers will face various\
    \ different types of challenges while farming, like less water, ﬂoods,\nlack of\
    \ suitable planting space, and cost control. Productivity can be improved with\
    \ the use of IoT in agriculture.\nWith the use of gathered information, farmers\
    \ can organize their farming activities, including what seeds they should\nsow,\
    \ what crop yields should be expected, the time to harvest, and how much fertilizer\
    \ to use. Example: The natural\nsoil diversity of a ﬁeld is an accurate agricultural\
    \ practice. The plants can be planted thicker and the irrigation can\nbe used\
    \ sparingly if the soil in a certain area holds more water. Alternatively, if\
    \ the site is used for grazing, we can\ntake more cattle than an equivalent area\
    \ with a lower level of the soil.\nNutritional management: – As the human body\
    \ needs proper nutrition to grow, the same plants may require\naccurate nutrition.\
    \ Nutrients help to produce the best yield when given at the right prices and\
    \ at the right times.\nToo much and too limited nutrients for plants will affect\
    \ the environment. For example, too much phosphorus,\nammonia, or nitrogen may\
    \ reduce water levels. To grow in one place, the selection of the best crop cycle\
    \ allows\nfor balancing soil fertility. While reducing environmental degradation\
    \ and economic costs, achieving sustainable\nagriculture, nutrition, and technology\
    \ are essential [6].\nGarbage Management: – The wastage of water, soil, and seeds\
    \ is common during farming. This needs to be\ncontrolled, but in an intelligent\
    \ manner. For garbage collection, create smart trash cans using IoT sensors, which\n\
    can smartly sense and collect the garbage. The collected data related to network\
    \ disposal is used to read, store and\ntransmit with the help of these smart trash\
    \ cans. Garbage management can be done with the help of some smart and\nsystematic\
    \ algorithms [10].\nLivestock monitoring: – Livestock plays an important role\
    \ in agriculture, so they need intention, proper care,\ntimely feeding, etc. It\
    \ is a growing worldwide issue to provide enough food to the world’s people with\
    \ the grow-\ning agricultural production. As a result, the importance of livestock\
    \ management on farms is crucial to survival.\nTo improve the quality and quantity\
    \ of agricultural products, new technology like IoT advances is important. It\n\
    also improves the quality of livestock by allowing farmers to make decisions based\
    \ on data-driven. To monitor the\nlivestock’s welfare remotely and identify their\
    \ habitats, cloud-based technologies are used with power communica-\ntion sensors\
    \ [50]. The health condition of livestock like respiratory rate, digestion, blood\
    \ pressure, heart rate, and\nother day and night vital signs can be checked by\
    \ farmers using connected sensors. But the data ﬂow between these\nsensors and\
    \ smart devices is interrupted or tempered, so it needs to be secure and well\
    \ managed to get efﬁcient\nresults.\nFarm Management System (FMS): – Smart farming\
    \ promotes productivity while minimizing environmental in-\nﬂuences, but this\
    \ smart agriculture technique is merely possible with the help of FMS [97]. With\
    \ the help of WSN\nand GSM in FMS, farmers can track the entire farm and capture\
    \ the data with a small controller [199]. With the\nuse of sensors and smart devices\
    \ in the ﬁeld, the identiﬁer is used to provide appropriate awareness of soil,\
    \ fertility,\nand weather, to the farmers. The data collection and storage, monitoring,\
    \ and analysis of the farm operations can\nbe automated using an IoT-based farm\
    \ management system. It can also help in managing agricultural budgets and\nbusiness\
    \ operations. The irrigation scheme helps in protecting the farms from animals\
    \ and pests. But also automatic\nirrigation systems can increase the water consumption\
    \ [105,137].\nTracing and tracking: – Satyanarayana et al. [236] develop the structures\
    \ to remotely track soil structure and\nits status in accordance with the needs\
    \ of plant culture. The different agricultural areas and locations are tracked\n\
    using GPS devices and wireless network connections. The real-time data processing\
    \ is tracked and approved by\nconnecting WSN and ZigBee to other devices like\
    \ the Central Monitoring Station (CMoS), GSM, and GPRS. The\nGPS also enables\
    \ the farmer to take actions based on notiﬁcations sent to the farm manager through\
    \ SMS or MMS.\nIt is often used in agriculture to detect precise location and\
    \ control capacity, despite it having high operating and\nmaintenance costs.\n\
    Plant management: – The growth of a farmer’s crop is most important in farming.\
    \ Farmers use good seeds,\norganic fertilizers, proper watering etc. for best\
    \ results. For farmers to protect themselves from them, they use\nchemical medicines\
    \ and fertilizers, which may later affect the human body. So, it required an intelligent\
    \ system that\nprotects the crop from insects and does not affect the human body.\
    \ This can be done by plant management, which\ninvolves monitoring and recording\
    \ the welfare of the crop. The plant and its diseases can be detected using RFID\n\
    chips and IoT sensors. The farmers can process the data remotely and take necessary\
    \ steps like keeping the insects\nfrom plants. The production of rice for a speciﬁc\
    \ country with a Chinese monitoring station using SVM [152].\nM. Kumar and A.\
    \ Singh / Probabilistic data structures in smart city\n255\nFarmers can also prevent\
    \ the risk and plan their farming practices by demonstrating an effective calculation\
    \ strategy\nfor coffee fruit [68].\nWater Management: – The major challenge in\
    \ greenhouses is to determine how much water is required i.e. wa-\nter management\
    \ [281]. Intelligent sensors are installed to control the waste of water and operate\
    \ them by using a\nvariety of IoT techniques. Automated drip irrigation is used\
    \ to control the soil moisture in irrigation and storage of\nwater in greenhouses.\
    \ The farmers are checking the water levels in a water tank with their Android\
    \ phones. With\nthe use of IoT devices and sensors, the whole water management\
    \ is done like the motor is automatically started and\nstopped by checking the\
    \ level water level. Due to over-irrigation in conventional irrigation systems,\
    \ up to 50% of\nwater is lost [241]. A smart Irrigation system(SIS) provides a\
    \ system to overcome this issue. This system helps the\nfarmers to avoid water\
    \ wastage and improve the quality of their crops through timely irrigation. SIS\
    \ also transmits\nthe knowledge of the ﬁeld to the farmer using temperature and\
    \ soil sensors. Farmers may also plan and modify their\nirrigation according to\
    \ the local weather information. For Water Distribution System (WDS) an architecture\
    \ WD-\nSchain’, which is blockchain-based in MATLAB, is proposed [172]. For security,\
    \ various consensus mechanisms\nare used, and results show a trade-off is required\
    \ between data validation and system complexity (Fig. 19).\nFig. 19. Water distribution\
    \ systems chain architecture [172].\nBlockchain with Agricultural IoT: – To improve\
    \ agricultural intelligence, data-driven technologies can be allowed\na secure\
    \ data storage system. The data collection is often very costly where the inventory,\
    \ agricultural contracts, and\ninformation about farm conditions from a reliable\
    \ source can be provided. Developing the trust between providers\nand consumers\
    \ and establishing a reliable food supply chain, the blockchain technology helps\
    \ in tracking the food\nfor timely payments to stakeholders [191].\nTo monitor\
    \ the farm and collect the data remotely, smart sensors and cameras were used.\
    \ To adopt the current\ncondition of agricultural land, farmers can use IoT devices\
    \ as they use smartphones anywhere in the world. New\ntechnologies like IoT have\
    \ the potential to increase global productivity and reduce the cost of crop production.\
    \ To\nface the challenges on the farm, the agricultural sector can be restructured\
    \ by providing different IoT-based tools\nand techniques. A massive amount of\
    \ unstructured data has also been generated and the PDS has the potential to\n\
    solve issues like handling big data with real-time response.\n7.3.3. Applications\
    \ of PDS in smart environment\nEnergy efﬁciency and trafﬁc awareness: – To improve\
    \ energy efﬁciency and trafﬁc awareness. Yousef et al.\npropose a scheme in underwater\
    \ WSN for water pollution monitoring [297]. BF is used in the preprocessing step\
    \ to\nreduce the number of transmissions and eliminate redundancy to save precious\
    \ energy. This type of project is mainly\nused in deep water like the sea and\
    \ ocean. Mahmoud et al. use BF for customer’s identity and privacy-preserving\n\
    of transferred data in WDS [173]. They also suggest the optimal parameters of\
    \ BF i.e. for 200 customers with 2000\n256\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\nnumbers of bits and 7 hash functions. In WDSchain,\
    \ BF is used to match the authentication of network nodes in\nproof-of-authentication(PoAuth).\n\
    High-performance communication networks: – IoT devices contain many sensors, routers,\
    \ actuators, and base sta-\ntions that need communications between them and send\
    \ millions of data that need to deliver with high-performance\ncommunication networks.\
    \ IoT devices that may have limited power resources or limited integration areas\
    \ have an\nimportant research challenge. To increase the performance of IoT communication\
    \ networks alassery et al. propose\nan efﬁcient mechanism based on BF [12]. BF\
    \ is used to store the routing information after aggregating packets to\nsend\
    \ receiving packets to upstream routers.\nQuery Optimization: – Under the big\
    \ data domain has been developed an air monitoring system, which poses\nmajor\
    \ challenges to data analysis. Peng et al. proposed a scheme for query optimization\
    \ of air quality big data using\nBF index [211]. The efﬁciency of data collected\
    \ in the air quality monitoring system is improved. They create a\nHive data repository\
    \ in the Optimized Row Columnar (ORC) ﬁle format and the Row Group Index (RGI).\
    \ For basic\ndata types 64-bits ThomasWang’s hash function is used and Murmur3\
    \ 64-bit hash algorithm for string and binary\ntype by BF in ORC.\nPrivacy-preserving\
    \ Data Aggregation and Analysis: – A data aggregation algorithm is proposed using\
    \ BF for\nprivacy data analysis in mobile crowdsensing system [212].\n7.4. Smart\
    \ industry\nIn world development, industrial growth plays an important role. When\
    \ the word comes to mind ‘Industry’, then\nmost people probably think that it\
    \ is a noisy and big place. The growth of the industry has increased by 18th century.\n\
    Due to the lack of technologies owned by the industry, it faces various challenges\
    \ like production, distribution,\nsupply chain management etc [279]. By the year\
    \ 2050, technology will have progressed to the level of autonomy\n[80]. The industries\
    \ are categorized into three economic sectors: primary, secondary, and tertiary\
    \ [24].\nPrimary industry: – This sector is concerned with the general people,\
    \ means to sell and supply the products.\nThis sector is place dependent because\
    \ the raw material is extracted from the earth. The operation of this sector for\n\
    economic growth revolves around minerals, earth water, vegetation etc. The example\
    \ of these sectors are farming,\nmining, and ﬁshing and they extract the raw material\
    \ like coal, foods, corn etc. There are two types of industries\nunder the primary\
    \ sector: The genetic industry and the Extractive Industry.\nSecondary industry:\
    \ – After the collection of raw material by primary industries the secondary industries\
    \ used this\nmaterial for construction and manufacturing the products. These industries\
    \ are used to make products like steel for\nautomobiles, textiles for cloths,\
    \ wood for furniture, etc. For manufacturing these products heavy machinery is\
    \ used\nin the production plant and also required manpower for packaging and distribution.\
    \ The example of these sectors\nare consumer goods, craft & fashion, construction,\
    \ manufacturing etc. There are two types of industries under this\nsector: Heavy\
    \ industry and Light industry.\nTertiary industry: – The product is manufactured\
    \ from raw material in the above sector and is now ready for use\nby consumers.\
    \ Tertiary industries generally they are not making any products but only provide\
    \ services to consumers\nand local industries & markets. The main feature of this\
    \ sector is discussion, experiences, access, etc. The ﬁnancial\nand education\
    \ sectors are two groups of tertiary sectors one for making money (ﬁnancial) and\
    \ the other (education)\nis non-proﬁtable. Examples of these sectors are banking,\
    \ educators, administrative, medical, ﬁnancial, insurance,\ntransportation retail,\
    \ wholesale, real estate, hotels, police, defense services, media and information\
    \ technology and\nso on. There are three types of industries under the tertiary\
    \ sector: Telecommunication, Professional, and Franchises.\nThese industries help\
    \ in growing the Gross Domestic Product (GDP) rate of the country.\n7.4.1. Industry\
    \ evolution\nThe farming and handicraft economizing processes changed to be monopolized\
    \ by industry and manufacturing\nmachines in the Industry Revolution. These changes\
    \ transformed society fundamentally in terms of living and\nworking styles. In\
    \ the 18th century Britain began this process and spread all over the world. The\
    \ production of\nmanufactured goods and the use of natural resources have increased\
    \ after these technological changes [294]. The\nindustrial evolution has been\
    \ categorized in Fig. 20 and succinct as given in Table 5.\nIndustry 1.0: – In\
    \ the years 1760–1850, the ﬁrst revolution was introduced with the mechanical\
    \ theme [225].\nIt used steam, coal, and water mechanization for the manufacturing\
    \ process. Production through machines had\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\n257\nFig. 20. Industry 1.0–5.0.\nincreased, so\
    \ the rate of production had increased by eight times for conventional methods\
    \ [270]. It also increased the\nstandard of life by creating various goods in\
    \ massive amounts. Human productivity was increased by the use of steam\npower\
    \ [83]. Machines, stream power, and water power played an important role in the\
    \ ﬁrst industrial revolution’s\ngrowth. If we talk about the developing sectors\
    \ in this revolution, textile manufacture, chemicals, paper machines,\ncement,\
    \ iron industry, gaslighting, transportation, agriculture, railways, and many\
    \ more are existing there [291].\nIndustry 2.0: – In the year 1880–1973 this revolution\
    \ was introduced with industrialization [131]. With the adop-\ntion of new technologies\
    \ like telephone, electric power, sewage, internal combustion engine, etc. this\
    \ revolution\nmanufactured mass production. The sectors that are developed in\
    \ Industry 2.0 through technology are steel, paper\nmaking, petroleum, automobile,\
    \ fertilizer, Iron, chemical, rubber, electriﬁcation, machine tools, telecommunica-\n\
    tions, and many more. Mainly this revolution occurs in America, Britain, and Germany\
    \ [193].\nIndustry 3.0: – In the year 1989–2013, the industrial revolution ‘Industry\
    \ 3.0’ was started. In this industry the\nproduction was automatically done without\
    \ human interference so, the production sector grew in the engineering\nﬁeld.\
    \ The automation was fully computerized, which increases the efﬁciency and reliability\
    \ of the industrial system.\nBut automation also affects employment. With the\
    \ growth in technology, many industries start using robots and\nreducing manpower.\
    \ Industry robots are designed with programmable integrated circuits and give\
    \ accurate and efﬁ-\ncient results. Robots can do painting, welding, testing,\
    \ labeling, etc. It is estimated by the International Federation of\nRobotics\
    \ there are 1.64 million robots used in industry worldwide [51].\nIndustry 4.0:\
    \ – In 2011 the industrial revolution ‘Industry 4.0’ was ﬁrst proposed by the\
    \ German government. In\nthis revolutionary trend, computerization is used in\
    \ manufacturing [149]. The cyber-physical system was developed\nand all systems\
    \ are communicated using IoT devices, cloud computing, and machine learning [272,278].\
    \ These IoT\ndevices help ‘Industry 4.0’ for providing services and also in manufacturing.\
    \ This industry transform information\nthrough Industrial IoT (IIoT) [190]. The\
    \ key components of this revolution include IoT, Cloud Computing, Big\nData, Cyber\
    \ Security, Cognitive computing, etc. [286]. German was initiative the Industry\
    \ 4.0 as “smart manufac-\nturing for the future” [155]. This revolution has emerged\
    \ with the aim of achieving mass production and increasing\nproductivity using\
    \ innovative technologies i.e. similar to previous revolutions [25,213].\nIndustry\
    \ 5.0: – This revolution in the industry is declared by the European Commission,\
    \ after discussions with\nvarious funding agencies, and organizations in Research\
    \ and Innovation workshops in January 2021. To provide\nservices to humanity this\
    \ industry focuses on and highlights innovation and research. It uses the blockchain\
    \ concept\nto integrate the generated data from different industries. To achieve\
    \ social goals like employment, the standard of\nliving and development this industry\
    \ plays a key role [43].\nIndustry 5.0 is not entirely new it is the upgrade version\
    \ of industry 4.0. With growing technology, artiﬁcial\nintelligence uses in industries\
    \ also improved. The capability of humans, interaction with computers, and robot\n\
    workers gives efﬁcient and effective results [279]. This industry proposed the\
    \ 3D techniques (like 3D printing or\nadditive manufacturing is used for creating\
    \ 3D objects) with the use of IoT [80].\n258\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\nTable 5\nEvolution of smart industry\nParameters\n\
    Industry 1.0\nIndustry 2.0\nIndustry 3.0\nIndustry 4.0\nIndustry 5.0\nYear\n1760–1850\n\
    1880–1973\n1989–2013\n2011–2020\n2021-future\nMain Objective\nReplacing manual\n\
    labor, Mechanization,\nWater Power, Steam\nPower\nUpgradation of\nresources, Mass\n\
    Production,\nAssembly Line,\nMechanization\nComputer Aided\nAutomation,\nCAD/CAM,\n\
    Inter-connecting the\nworld\nComputerized\nautomation, Sensor\nRobotic\nManufacturing\
    \ With\nA.I.\nA.I. Anticipates\nHuman Needs and\nPlans Resources,\nSynergetic\n\
    co-production and\nBio-upgradation\nFocus on\nTextile manufacture,\nIron industry,\
    \ steam\npower, machine tools,\nchemicals, cement,\ngas lighting, glass\nmaking,\
    \ agriculture,\ntransportation and\nmany more.\nIron, steel, rail,\nelectriﬁcation,\n\
    machine tools, paper\nmaking, petroleum,\nchemical, maritime\ntechnology, rubber,\n\
    bicycles, automobile,\nengines and turbines,\ntelecommunications\nand trendy business\n\
    management.\nSemiconductor\nindustry, Digital\ncircuits,\nProgrammable\nIntegrated\
    \ circuit,\nTelecommunication,\nwireless\ncommunication,\nRenewable energy\nsector,\
    \ Automate the\nall production\nindustries.\nAll type of Industries,\nsuch as\
    \ Primary,\nsecondary and\nterritory sectors with\nintelligent system.\nWith the\
    \ use of Iot\ndevice the 3D objects\nare manufactured\nwith 3D techniques\n(like\
    \ 3D printing or\nadditive\nmanufacturing).\nKey Technologies\nMachine tools,\
    \ Water\npower and Steam\npower\nElectrical power,\ntelephones, Internal\nCombustion\
    \ engine,\nrailroad networks,\ngas, telegraph,\nsewage and water\nsupply\nRobot,\n\
    Programmable\nIntegrated circuit,\nInternet, Industry\nAutomation.\nIoT, Big data\n\
    Augment reality\nSimulation Cloud\ncomputing, Cyber\nsecurity Autonomous\nrobots.\n\
    Co-bots, Skill\ntransfer systems,\nBionic\nenhancements,\npersonalized\nbio-engineering\n\
    Mathematics tool\nLinear programming,\nGeometry.\nDifferential equation,\nLinear\
    \ equation,\nGeometry\nIntegral equation,\nLinear programming,\nLogical controller.\n\
    Optimization\ntechniques, Network\ntheory\nMulti-layer neural\nnetwork, deep neural\n\
    network\nEnergy source\nCoal, steam\nFossil fuels\nHybrid fuels\n(renewable, fossil,\n\
    nuclear)\nRenewable\nElectricity\nRenewable\nElectricity\nAchievements\nTransportation,\n\
    employment,\nsustained growth,\nAgriculture\ndevelopment.\nElectrical power grid,\n\
    telephones, telegraph,\nInternal Combustion\nengines\nTelecommunication,\nRenewable\
    \ energy,\nAutomated\nindustries, Robots.\nFully Automated\nSystem, Artiﬁcial\n\
    intelligent system in\nindustry application\nto work in uncertain\nsituations.\n\
    Make 3D view of\nobjects with additive\nmanufacturing\nLimitations\nPollution,\
    \ Takes\nmaximum time\nMaximum cost to\nconsume electrical\npower.\nAutomated\
    \ system\nwould not work in\nuncertain situations.\nData in the cloud\nneed to\
    \ improve\nsecurity and privacy.\nExpert systems are\nnot yet developed for\n\
    industries.\nNew and untested\ntechnologies\n7.4.2. Challenges in smart industry\n\
    Data Security: – As the rapid growth of technologies in the smart industry a huge\
    \ amount of data is moving\nbetween IoT devices. The security of data is also\
    \ a major challenge in the smart industry. The data protected and\nsafe from unauthorized\
    \ access is also a challenge to the industry.\nData Management: – This is also\
    \ the major challenge when a huge amount of data is following over the network\n\
    and between devices. Data need to be well structured and in a good manner to access\
    \ and get efﬁcient results.\nStorage: – Storage of industrial big data is very\
    \ tough both for users and developers. Data generated from various\nresources\
    \ IoT devices are scattered and not ﬁltered. The storage of that type of data\
    \ is not easy.\nM. Kumar and A. Singh / Probabilistic data structures in smart\
    \ city\n259\n7.4.3. Applications of PDS in smart industry\nRemove ambiguity: –\
    \ The data generated in the smart industry is ambiguous. Wang et al. proposed\
    \ a technique\n“Fingerprint Summary” for cluster data de-duplication which is\
    \ time and space-efﬁcient. They use BF in this tech-\nnique in each node, for\
    \ reducing data duplication. For efﬁcient detect and remove duplicate data [57]\
    \ proposed a\nnew data structure i.e. ‘Improved Streaming Quotient Filter (ISQF)’.\n\
    Validation: – BF is used for data validation. BF is used to reduce memory consumption\
    \ and bypass the unneces-\nsary comparisons in the validation process [109]. This\
    \ process is space-efﬁcient.\n7.5. Smart energy\nSmart energy plays an important\
    \ role in solving the various issues of past, present, and future like healthcare,\n\
    agriculture, the environment, sustainable development, and many more [79]. The\
    \ energy-saving systems have al-\nready been developed in various cities and buildings,\
    \ in the last few years. A lot of studies for efﬁcient energy have\nalready been\
    \ done [142]. Instead of using the word “smart grid”, a broader approach is to\
    \ use the terms “Smart\nEnergy” or “Smart Energy Systems” (Fig. 21).\nFig. 21.\
    \ Smart energy.\nThe energy system is also facing various challenges like stability,\
    \ energy efﬁciency, cost control, operational\nefﬁciency, environmental issue,\
    \ service management etc. [90]. By achieving smart energy management big data\
    \ an-\nalytics provide new opportunities to deal with these challenges [18]. The\
    \ innovative storage solution and distributed\nresources for efﬁcient power transmission,\
    \ clean power generation, dynamic power distribution, and rational elec-\ntricity\
    \ consumption have been proposed [188]. Smart grid achieves the energy transmission\
    \ and data collection at\nthe same time by integrating energy and information\
    \ ﬂow [187]. The primary focus of smart grids is on electricity\n260\nM. Kumar\
    \ and A. Singh / Probabilistic data structures in smart city\nsectors like cooling,\
    \ heating, electricity, transportation, industry, building etc. It also provides\
    \ affordable, achievable\nsolutions for sustainable and renewable energy [168].\
    \ In the last few years, due to the huge growth in industry,\nenergy consumption\
    \ has also increased. It also increases data generation. With the emergence of\
    \ ICT, the energy\nsystems are being digitized [309]. The massive amount of generated\
    \ data from energy-related sources needs to be\nwell structured for efﬁcient and\
    \ fast results [177]. Due to the rapid increase in the population, energy consumption\n\
    has also increased. Renewable energy like wind and solar power is also in its\
    \ developing stage and has brought\nchallenges like energy security and the adoption\
    \ of new technologies [262]. Industries are using more than one-third\nof the\
    \ total electrical energy used by the country, for production, construction, and\
    \ mining. So in order to gather\nvaluable information, they have collected a big\
    \ database. This data is being used to raise the standard of living [231].\nThe\
    \ variety of big data, like the status of the device, consumption of electricity,\
    \ and interaction with the user, is\nbeing collected by the smart grid. To process\
    \ this big dataset, various techniques like analysis, optimization [310],\nclustering\
    \ [232], classiﬁcation [307] and forecasting [88] have been applied. So, the accurate\
    \ prediction of electricity\ndemand and consumption, the operation and generation\
    \ of power in real-time can be optimized, and also effectively\ndevelop the pricing\
    \ mechanism. With the use of big data analytics, the smart grid gives more control\
    \ over the use\nof energy to the customer, supplies economic and reliable energy,\
    \ responds quickly to the demand for electricity,\nand also quickly restores and\
    \ detect the failure and many more facilities [124]. This also helps in taking\
    \ decision\nfor customers, producers, operators, and regulators in the smart grid\
    \ [308]. Energy management uses emerging\ntechnologies like ICT (Fig. 22).\nFig.\
    \ 22. Energy management (energy cloud) [197].\nThe pattern of consumption and\
    \ production of energy is changed due to involving of big data. The energy big\n\
    data has involved 3Es and 4Vs energy, empathy, exchange, value, velocity, volume,\
    \ and variety [308].\n7.5.1. Challenges in smart energy\nThere are various opportunities\
    \ and some challenges brought by energy big data. Some challenges are listed here:\n\
    Effectively collection of energy big data: It is very difﬁcult to collect data\
    \ from energy resources for giving\nefﬁcient and effective decision-making and\
    \ quick responses.\nManagement storage of energy big data: This is also one of\
    \ the major challenges for energy big data to provide\nbetter services to customers.\n\
    M. Kumar and A. Singh / Probabilistic data structures in smart city\n261\nMining\
    \ and analyzing of energy big data: The mining of data for cleaning big raw data\
    \ and analysis is a very\ntough job.\nLack of effective and efﬁcient decision\
    \ making: The decision making is one of the impotent key points of a smart\nenergy\
    \ system, it also needs to be improved by joining efﬁcient techniques like PDS.\n\
    Privacy preserving of energy big data: This is one of the major concerns to giving\
    \ security to energy big data.\nWith the use of IoT devices, a huge amount of\
    \ data is ﬂowing without any security measures.\nTo achieve the above-discussed\
    \ challenges efﬁcient and effective tools and techniques like PDS are required.\n\
    7.5.2. Applications of PDS in smart energy\nPrivacy Preserving: Zhang et al. proposed\
    \ a mechanism Cuckoo-RPL (Routing Protocol for Low-Power and\nLossy Networks)\
    \ to defend from Advanced metering infrastructure (AMI) network from blackhole\
    \ attack. Cuckoo-\nRPL is also useful to defend from other attacks like version\
    \ number and gray hole attack [303].\nNetwork trafﬁc management: Chaudhary et\
    \ al. designed a “SDN-enabled multi-attribute-based secure communi-\ncation protocol”\
    \ in the Smart Grid environment for their entity communication. They use a cuckoo\
    \ ﬁlter for fast\nforwarding of data [56].\nLoad Balancing: Debnath et al. present\
    \ a scheme i.e. ‘BloomFlash for ﬂash storage device. This scheme also\nachieved\
    \ the load balancing of elements across the BF component. This scheme proves that\
    \ the BF is useful in load\nbalancing techniques [72].\n7.6. Smart governance\n\
    Smart governance means accessing the government services free and in a better\
    \ manner using various free data\nprojects. With the emergence of ICT in smart\
    \ cities, smart governance can improve the services provided by the\ncities [159].\
    \ Developing the businesses of the individual smart economies can play an important\
    \ role in providing a\ncollaborative platform. A smart economy also emphasizes\
    \ economic competitiveness in the development of the city,\non the competitive\
    \ edge economic and human activity [143].\nSmart Economy: – Smart economy that\
    \ is for success with high social welfare, sustainability, and resource-\nefﬁcient,\
    \ is based on innovative technologies. It also helps in improving the quality\
    \ of life by adopting new inno-\nvative ideas and building new entrepreneurs,\
    \ and start-ups, which increase competitiveness and productivity [263].\nThis\
    \ whole system is based on technologies and ICT for urban planning and economic\
    \ advancement. For social\nbeneﬁts smart economy is also expected to deliver more\
    \ products and services without compromising energy and\npollution [144].\nSmart\
    \ Government: – Smart government is the timely demand of the 21st century and\
    \ smart governance is its\nkey tool. The key pillar of smart governance is to\
    \ use technology. The public administration is required to update\nitself with\
    \ the emergence of technology. No one can oppose adopting smart governance as\
    \ it is the new face of\npublic administration, governance, and political process\
    \ [237]. The e-government adopts the electronic process in\nthe administration\
    \ system and political system and it is the starting face of smart government.\
    \ There is a trend of\nusing modern technologies in public administration for\
    \ smart governance systems by developed countries and their\nresearchers, academicians,\
    \ politicians, and practitioners [182]. The role of smart government is presented\
    \ in Fig. 23.\nAn intelligent network is created in the sector of governance and\
    \ it is directly related to the internet where people\ncan connect with each other\
    \ for communication even in remote areas. Better communication with real-time\
    \ objects in\nthe intelligent network is done through the distributed network\
    \ [234]. As it is not an automated decision-maker so\nit is not artiﬁcial intelligence.\
    \ It only connects to the people for gathering information and making the decision\
    \ and\nuse it in the future. Due to the rapid growth of IoT devices and digital\
    \ applications, a lot of data is produced. The\nsource of big data is social networking\
    \ websites, mobile phones, daily household appliances, various private and\ngovernment\
    \ websites, and smart devices being used by various researchers.\nBig data plays\
    \ an important role in transforming traditional governance into smart governance.\
    \ Researchers,\nacademicians, and policymakers argued about the transformation\
    \ of traditional public administration to modern and\nsmart administration in\
    \ point of big data. For developing the public administration and government sector\
    \ a large\namount of data is required. It also helps in developing new models\
    \ [238]. Big data also help in effective decisions,\nfast and efﬁcient results,\
    \ and expert users, increasing their accountability and transparency. It also\
    \ helps in solving\n262\nM. Kumar and A. Singh / Probabilistic data structures\
    \ in smart city\nFig. 23. Role of smart government.\ncomplex tools for reforming\
    \ the government but some researchers have doubts about future technologies. Many\n\
    countries have adopted big data for smart governance, but some public administrations\
    \ are still not ready to adopt\nbig data as full ﬂedge. It happens because, for\
    \ implementation of these technologies, data collection, production and\nprocessing\
    \ require a big investment. And those public administrations who implement impulsive\
    \ faces threats and\nchallenges like reducing the productivity, efﬁciency, and\
    \ capacity in governing system [248].\nThe solutions to these challenges, problems,\
    \ and threats are big data-driven technologies [75] like PDS. The\ngovernment\
    \ agencies taking future and proper decisions, and identify criminals and corruption,\
    \ with the help of\nproper use of big data. The government is generating and managing\
    \ the knowledge with their major responsibility\n[5].\n7.6.1. Challenges in smart\
    \ governance\nAdopting Big data technologies: Some developing countries are already\
    \ adopting big data technologies in smart\ngovernance. But many are facing problems,\
    \ due to their bad handling and management, lack of knowledge, cost-\neffectiveness,\
    \ and data available being either unstructured or semi-structured.\nData Privacy:\
    \ Much conﬁdential data is uploaded by people and used by public administration.\
    \ So, it needs to be\nprotected from malicious users.\nApplications of PDS in\
    \ Smart Governance: As such, we have not found any existing use of PDS in smart\
    \ gover-\nnance. So here the scope of use of PDS is highly recommendable. PDS\
    \ is an efﬁcient data structure for managing\ndata storage and is also compatible\
    \ with new technologies. PDS also helps in protecting data.\n7.7. Smart society\n\
    A smart society means to promote the satisfaction of citizens satisfaction and\
    \ the well-being of metropolitan\nresidents. In this reference, a smart society\
    \ includes a large number of smart: people, infrastructure, education,\nliving;\
    \ water and waste management systems and many more [243]. Society 4.0 faces the\
    \ challenge with information\nsharing and related knowledge, while in society\
    \ 5.0 the increased process complexity and assured sustainability due\nto the\
    \ massive amount of data combined with environment and human physical investigation.\
    \ The major challenge\nwith big data is to take real-time decisions [94].\nM.\
    \ Kumar and A. Singh / Probabilistic data structures in smart city\n263\nFig.\
    \ 24. Society evolution 1.0–5.0 [95].\n7.7.1. Society evolution\nSociety is coexistence\
    \ with nature, and according to ethnographers, society 1.0 had begun with the\
    \ birth of humans\nknown as the hunting society (Society 1.0). In 13,000 BC the\
    \ settlements had been ﬁrmly established and irrigation\ntechniques had been developed\
    \ known as an agrarian society (Society 2.0). At the end of the 18th century,\
    \ the steam\nlocomotives were invented and mass production had started, it was\
    \ the industrial society (Society 3.0). In the latter\n20th century computers\
    \ were invented and the distribution of information was started, this is the information\
    \ society\n(Society 4.0). At the beginning of the 21st century, “super-smart society”\
    \ has introduced and known as (Society\n5.0). The social evolution has categorized\
    \ and concise as given below (Fig. 24).\nSociety 1.0: – This society’s evolution\
    \ begins with the birth of humans. This society is also called a hunting\nsociety.\
    \ People used simple tools for full ﬁll their daily needs including food. People\
    \ have changed their habits on\nthe availability of resources [138].\nSociety\
    \ 2.0: – In 13000 BC this social evolution was introduced with new developing\
    \ agriculture techniques\nand it is also known as an agrarian society. With the\
    \ advancement of technology and demographical changes, this\nrevolution is transformed\
    \ from the earlier society revolution [29]. In Mesopotamia, the hand-made pottery\
    \ and the\ncultivation of barley and wheat were found at early stages [14].\n\
    Society 3.0: – This societal revolution begin at the end of the 18th century,\
    \ when modern physics, gravity law, and\nthe invention of the steam engine had\
    \ discovered and also called Industrial Society. This society changes the face\n\
    of the earth forever. As already discussed industry revolutions are one of the\
    \ growing ﬁelds in terms of economy\nas well as academia [254]. This also builds\
    \ the relationship through transportation, environment, society, and many\nmore.\n\
    Society 4.0: – This is the Information Society, initially planned in 1972 in Japan.\
    \ This society aims for a new\nera after the post-industrial revolution in the\
    \ year 1985 [179]. Here the production of information promotes human\ncreativity,\
    \ and the transition, and development of society.\nSociety 5.0: – At the beginning\
    \ of the 21st century this revolution was introduced with a vision of a “super-\n\
    smart society”. This society provides solutions to many social problems through\
    \ technologies because it is human-\ncentered. This also improves the quality\
    \ of life, the use of robots also increases, and also environment-friendly\n[14].\n\
    7.7.2. Applications of smart society\nThe smart society is directly concerned\
    \ with citizens and daily lives. The main applications are discussed below\n(Fig.\
    \ 25).\nSmart Home/Houses: – To increase the quality of life and independence,\
    \ the homes are equipped with technolo-\ngies called “smart home” [73]. Smart\
    \ homes include home appliances like television, air conditioners, smart fans\n\
    264\nM. Kumar and A. Singh / Probabilistic data structures in smart city\nFig.\
    \ 25. Applications of smart society.\nand lights, etc. are connected with IoT\
    \ devices to effectively deliver the services. To achieve the goals of providing\n\
    the services efﬁciently, the Smart Home Reasoning System (SHRS) plays an impotent\
    \ role to make decisions [181].\nReducing environmental emissions, energy management,\
    \ and increasing home automation is the primary objective\nof smart home [229].\n\
    Smart Living/People: – Smart living gives new opportunities to citizens to increase\
    \ their standard of living. It\nneeds to follow an inclusive strategic approach\
    \ across all age groups and demographics [203]. It provides solutions\nthat are\
    \ controllable, productive, sustainable, economical, and efﬁcient. Smart living\
    \ is changing people’s lives\nwith the emergence of new technologies. Yan et al.\
    \ propose an architecture that controls home lighting using a\nBluetooth-based\
    \ Android smartphone [295]. Peoples are safer in their homes, if they have to\
    \ face any problem, they\ncall independently also the objective of smart living\
    \ [153].\nSmart Buildings: – Smart building is deﬁned as it is efﬁcient energy\
    \ management, a convenient and comfort-\nable environment with reasonable investment,\
    \ and is designed to provide service and management [169]. A smart\nbuilding also\
    \ includes automated processes like security, heating, lighting, air conditioning,\
    \ ventilation, and many\nmore [221]. To develop the smart building the things\
    \ required are future-proof devices, IT skilled team, and robust\nwireless infrastructure.\
    \ The basic components of smart building for security includes CCTV system, access\
    \ control,\nintrusion system, gate automation etc [184].\nSmart Education: – With\
    \ the advancement of technologies everything may be interconnected, instrumented\
    \ with\nAI [313]. Smart education is also an emerging area nowadays and also needs\
    \ attention from both researchers and\nacademics [135]. Various smart education\
    \ projects [121] have already been performed in recent years, in which the\nﬁrst\
    \ smart education project is carried out by Malaysia in 1997 [52]. Smart education\
    \ [62] faces certain issues like\naccessing student knowledge, comparing behavioral\
    \ patterns of a student, data integration, data mining, detecting\neffective and\
    \ emotional state of the student, and many more [60].\nM. Kumar and A. Singh /\
    \ Probabilistic data structures in smart city\n265\n7.7.3. Challenges in smart\
    \ society\nEfﬁciency: – All resource uses in a smart society have their limits\
    \ like battery power, memory storage, and\nbandwidth required for communication.\
    \ They directly affect efﬁciency, which also increases with the rapid growth\n\
    in data.\nHeterogeneous data: – The data generated in the super-smart city is\
    \ heterogeneous, which leads to challenges in\nprocessing, analyzing, and mining\
    \ data. Getting adequate information from big data in heterogeneous information\n\
    networks is also a big challenge.\nPrivacy preserving: – On increasing of smart\
    \ technologies in a smart society the issue of security, and privacy is\nthe main\
    \ concern. Challenges in all aspects like access control, authentication, policy\
    \ enforcement etc.\nApplications of PDS in Smart Society: As such we have not\
    \ found any existing use of PDS in the smart society.\nSo here the scope of use\
    \ of PDS is highly recommendable. In lieu of the above challenges, there are many\
    \ studies\nand researches available that PDS and its variants give an efﬁcient\
    \ result with memory management, and storage,\nalso to handle heterogeneous data.\
    \ PDSs also provide security to the data.\n7.8. Smart sustainability\nThe idea\
    \ of sustainability was introduced in 1987. Sustainability deﬁne that the to meet\
    \ today’s needs without\nsacriﬁcing the future ability to fulﬁll their requirements\
    \ like social, economic, and environmental [19]. Emerging\ntechnologies and digital\
    \ governance are also part of smart sustainability [178]. It also requires a balance\
    \ between\nthe technology, policy, and management by local government [235]. The\
    \ main pillars of sustainability are environ-\nmental, economic, and social. Smart\
    \ sustainability has the potential for solving the problems of urban areas [296].\n\
    In sustainable development, governance plays an impotent role [84]. In sustainable\
    \ development’s planning and\nimplementation, the stakeholder and policymakers\
    \ lack practical research knowledge. To achieve this new technolo-\ngies like\
    \ ICT, IoT and cloud are being used in a smart city. Modern technology and creativity\
    \ are being focused\non the framework of smart cities as compared to sustainability\
    \ cities depending on the data-driven identiﬁcation\nof the dynamic changes in\
    \ the broadcast relationship [258]. To achieve the required level of sustainability\
    \ the data\ncame from various sources in smart cities are need to be well structured.\
    \ The IoT technologies measures in smart\nsustainable cities are air and water\
    \ quality, green urban areas, tourism and culture, energy, digital transformation,\
    \ le-\ngality, and security (Fig. 26). Sustainable economic advancement includes\
    \ all the factors that are included in a smart\ncity. These factors are green\
    \ building, smart education, social responsibility, water management, sustainable\
    \ energy,\nsmart health, smart governance, natural resource management, sustainable\
    \ transportation, and waste management\n(Fig. 27).\nFig. 26. Smart sustainable.\n\
    7.8.1. Challenges in smart sustainability\nCollection of data: – For developing\
    \ sustainability a huge amount of big data is required at a place.\nStorage management:\
    \ – The management of this data in a proper manner is a big challenge.\nPrivacy\
    \ and Security: – Security and privacy of this data is also the main concern.\n\
    266\nM. Kumar and A. Singh / Probabilistic data structures in smart city\nFig.\
    \ 27. Smart sustainable city.\nApplications of PDS in Smart Sustainability: As\
    \ such we have not found any existing use of PDS in smart city\nsustainability.\
    \ So here the scope of use of PDS is highly recommendable. The PDS and its variant\
    \ are very much\neffective in data collection with less time and efﬁcient storage\
    \ management. It also provides security to the data\nmovement in smart sustainability.\n\
    8. Comprehensive analysis of PDS in smart city\nIn the smart city, the data, and\
    \ information are the entrance to instantly bounded competitive beneﬁts. Today,\n\
    billions of people are accessing and releasing huge amounts of data via the internet,\
    \ and social networks. This\ngrowth in data required efﬁcient storage and handling\
    \ of data is a big challenge for both academia and industry [96].\nTo improve\
    \ the efﬁciency of data access and testing, the storage of monthly or annual data\
    \ production from various\ncompanies, hospitals, institutions, and forests is\
    \ at data centers [118]. The variants of data structures in PDSs are\nimportant\
    \ for big data and live streaming systems. A BF is a probabilistic randomized\
    \ data structure given by Burton\nBloom, for efﬁciently storing information of\
    \ static sets to support membership queries [36]. Presently BF is widely\nused\
    \ in many networking and security algorithms [201]. After studying the existing\
    \ uses of PDS in smart cities, it is\nfound that many researchers have used BF\
    \ in healthcare for efﬁcient storage of patient data, privacy-preserving etc.\n\
    in various applications Some of the existing applications of PDS in a smart city\
    \ are recapitulated in below (Table 6).\n9. Generational data management\nA massive\
    \ amount of data is ﬂowing in a smart city. Obviously, this data needs to be managed\
    \ for their well-being\nto be used for both personal and civic data services.\
    \ The use of WEB 3.0 for data management is also important.\nM. Kumar and A. Singh\
    \ / Probabilistic data structures in smart city\n267\nTable 6\nExisting use of\
    \ PDS in smart city\nAuthor/ Year\nArea\nPDS\nDescription\nContribution of PDS\n\
    Limitation\nD Liu et al.\n[161]/2022\nSmart Cities\nCounting\nBloom Filter\n(CBF)\n\
    The data storage scheme has\nproposed which is distributed\nand secure, it is\
    \ used in edge\ncomputing where blockchain is\nenabled\nCBF is used where the\
    \ storage\nchecking is failed. Then CBF\nrecognize the data dynamically\nand locating\
    \ error data\nIt is tough to calculate the\nvalue of counter and it also\nincreases\
    \ the memory\noverhead.\nCongPu et al.\n[217]/2022\nGeneral*\nBloom Filter\n(BF)\n\
    The two mechanisms liteSAD\nand proDIO has been proposed\nto investigating the\
    \ sybil\nattack.\nBF is used to reduce the\nprocessing time and memory\ncost.\n\
    BF is not removed from this\nproposed scheme.\nG. S. Aujla et\nal. [111]/2021\n\
    Healthcare\nVehicles in\nCOVID\nDeletable\nBloom Filter\n(DBF)\nDBF is use to\
    \ overcome\ncongestion and improve\nresponsiveness. DBF maintain\nthe global information\
    \ of the\nﬂow tables and edge devices.\nDBF facilitates the\ninteroperability\
    \ of network\ndevices\nIf more then one item has same\nbut index in DBF then\n\
    collision is occurred, Issue of\nFault tolerance, Flow table\nmanagement.\nSeham\
    \ A., et\nal. [11]/2021\nHealthcare\nBloom Filter\n(BF)\nAn infection control\
    \ system is\nintroduced with the used of\nBlockchain for\nprivacy-preserving.\
    \ In this\nsystem one leader elected by\nauthority update the two BF\none for\
    \ infected user and other\nfor close contact user\nTwo BF are used for infected\n\
    and suspected users, which\nreduce the storage space\nA major drawback of using\n\
    BFs is that their is no function\nfor deleting data.\nHeiko et al.\n[40]/2021\n\
    Smart City\nBloom Filter\n(BF)\nAn overlay network is\nproposed for related trust\
    \ and\nreliable issues, which is fully\ndecentralized.\nBF used to increase privacy\
    \ of\nclient’s\nData security and Privacy issue\nto overlay users.\nAlshdadi et\
    \ al.\n[15]/2021\nSmart Vehicle\n(Transport)\nBloom Filter\n(BF)\nA system is\
    \ proposed to\nminimize the cyber attacks, it\nalso increase the security of\n\
    smart vehicle. This system is\nIoT-based Cyber-Physical\nSystem.\nBF is used for\
    \ authenticating\nthe vehicle ids\nNo proper data management.\nS Bhatia et al.\n\
    [35]/2021\nHealthcare\nMortan Filter\n(MF)\n(advanced\nCuckoo ﬁlter)\nA technique\
    \ is proposed to\nprovide security to the patient\npersonal data which use cloud\n\
    for electronic transformation\nof patient records.\nMorton ﬁlter improves security\n\
    and throughput as compare to\nexiting mechanisms\nIt use underloaded buckets and\n\
    many sparse buckets that are\ncombined into a block so that\ndata stored is more\
    \ densely.\nV Leithardt et\nal. [154]/2021\nSmart\nTransportation\nBloom Filter\n\
    (BF)\nA system is design to provide\nthe security and privacy to the\ndata used\
    \ for License Plate\nRecognition (LPR) in smart\ncity. Also improve the\nperformance\
    \ of blockchain\nbased storage.\nBF is used to maintain the\nuser’s privacy and\
    \ also oppose\nattacks from third-party\nBlockchain may be fail due to\nthe shortcoming\
    \ in engineering\nrequirement and no standard.\nK Wang et al.\n[283]/2021\nHealthcare\n\
    Bloom Filter\n(BF)\nA system is proposed which\nprovide privacy to searchable\n\
    encryption method to patient\ndata.\nBF is used for searching the\nvalues and\
    \ store in veriﬁcation\ntable\nuse of Multiset hash.\nF. Alassery et\nal. [12]/2021\n\
    Smart\nEnvironment\nBloom Filter\n(BF)\nPropose a mechanism for fast\npacket delivery\
    \ in IoT using\nBF. They reduce the size of\nrouting information by using\naggregation.\n\
    BF is used in all sensor nodes\nfor collecting routing data.\nAffect life of battery\
    \ on\nincreasing the size of BF.\n268\nM. Kumar and A. Singh / Probabilistic data\
    \ structures in smart city\nTable 6\n(Continued)\nAuthor/ Year\nArea\nPDS\nDescription\n\
    Contribution of PDS\nLimitation\nSoleymani et\nal. [252]/2021\nSmart City,\nSmart\n\
    Transportation\nQuotient Filter\n(QF)\nA scheme is proposed which\nused for privacy\
    \ preserving\nand message authentication of\nvehicle node.\nQF maintain the authorization\n\
    of vehicles in VANET.\nSecurity needs to be more\nfocused.\nD.S. Jean\nMichel\
    \ et al.\n[69]/2021\nSmart Grid,\nSmart Energy\nCuckoo Filter\n(CF)\nThis project\
    \ represent the\nanalysis and storage\nmanagement of smart grid’s\nbig data.\n\
    CF is used to store and access\nsmart grid’s data.\nSecurity needs to be improve.\n\
    C Kalalas et al.\n[132]/2020\nSmart\nTransportation\nCuckoo Filter\n(CF)\nA scheme\
    \ for vehicle\nauthentication which extend\nthe 5G-AKA (authentication\nand key\
    \ agreement) is\nproposed. CF is used to\nimprove the space efﬁciency.\nCF is\
    \ used to achieve\nauthentication of multiple\nvehicles at a time in space\nrequirement\n\
    No road side unit for broadcast\nto adjacent vehicles for\nmessage veriﬁcation.\n\
    PP Ray et al.\n[223]/2020\nE-Healthcare\nBloom Filter\n(BF)\nA Blockchain and\
    \ IoT based\nscheme is proposed for\nsimplify the payment\nveriﬁcation process\
    \ in real life\nhealthcare applications.\nBF use in privacy preserving\nBitcoin\
    \ transactions raised the\nproblem of\nresource-constrained tool,\nlimited due\
    \ to new technology.\nSu, Yuan, et al.\n[259]/2020\nElectronic\nHealth Records\n\
    (EHRs),\nCuckoo Filter\n(CF)\nAn authorized certiﬁcate less\nconjunctive keyword\
    \ search on\nencrypted EHRs, is proposed\nImprove search efﬁciency and\nallow\
    \ data owners to ﬂexibly\nmanage (insert and delete)\ntheir EHRs in the cloud.\n\
    space of hash tables in cuckoo\nﬁlter become smaller due to\ncan’t avoid false\
    \ positive.\nSingh A et al.\n[245]/2020\nSmart Devices,\nSmart Grid\nBloom Filter\n\
    (BF)\nA scheme is proposed to\nhandle the data trafﬁc by\nmanaging network resources.\n\
    They also perform security\nchecks for the secure\ntransformation of data using\n\
    double hashing.\nBF is used for storage\nmanagement\nNot consider the impact on\n\
    quality-of-service (QoS).\nB Peng et al.\n[211]/2020\nAir Quality,\nSmart\nEnvironment\n\
    Bloom Filter\n(BF)\nA query optimized method is\nproposed for storing\nOptimized\
    \ Row Columnar\n(ORC) format data for air\nquality based on row group\nindex and\
    \ BF index.\nBF is used for indexing\nadjusting the number of hash\nfunctions\
    \ and bit set length is\nrequired for best efﬁciency.\nChe et al.\n[57]/2020\n\
    Industry,\nGeneral*\nBloom Filter\n(BF), Quotient\nFilter (QF)\nPropose a new\
    \ data structure\ni.e.’Improved Streaming\nQuotient Filter (ISQF) which\nis used\
    \ to detect and delete the\nduplicate data\nISQF is used to store the\nsignatures\
    \ of elements in a\ndata stream and provide nearly\nzero error rate.\nneed to\
    \ handle conceptual data\ndrift.\nS. Garg et al.\n[98]/2020\nInternet of\nVehicle\n\
    Count-min\nSketch (CMS),\nBloom Filter\n(BF), Quotient\nFilter (QF),\nHyperLogLog\n\
    (HLL)\nA scheme is proposed for\nSoftware-Deﬁned Internet of\nVehicle (SD-IoV)\
    \ to manage\nthe trafﬁc of data, detect the\nanomaly in suspicious node,\ncheck\
    \ cardinality using PDS\nCMS is used for trafﬁc\nmanagement, BF is used for\n\
    anomaly detection, QF is used\nfor fast and efﬁcient storage of\nnodes, HLL is\
    \ to measure the\ncardinality of each ﬂow\npassing through switch\nCompromising\
    \ the sensitive\ninformation using attacks.\nB. Charyyev et\nal. [55]/2020\nSmart\
    \ Home\nLocality\nSensitive\nHashing (LSH)\nPropose a method to analyze\nthe voice\
    \ and utilize the\nnetwork trafﬁc of a smart\nspeaker to ﬁngerprint the voice\n\
    command.\nLSH is used to analyze the\nvoice command for smart\nhome speaker assistance.\n\
    Trafﬁc ﬂow classiﬁcation.\nM. Kumar and A. Singh / Probabilistic data structures\
    \ in smart city\n269\nTable 6\n(Continued)\nAuthor/ Year\nArea\nPDS\nDescription\n\
    Contribution of PDS\nLimitation\nN. Giatrakos et\nal. [103]/2020\nSmart City\n\
    Locality\nSensitive\nHashing (LSH)\nA technique is proposed to\nprovide a direct\
    \ way for the\naccuracy of bandwidth during\ndetection of outlier procedure.\n\
    They also elaborate on the\napplicability of their technique\nin smart city applications.\n\
    LSH is used during outlier\ndetection for examining\noperational mode.\nNot able\
    \ to detect\nnetwork-level attacks.\nS. Kulkarni\n[145]/2020\nGeneral*\nCount-min\n\
    Sketch (CMS)\nAnalysis the various methods\nof data streaming of\nCMS is one of\
    \ the useful\nsketch for cheeking number of\noccasions of standard things\nno\
    \ implementation proof.\nF. Peng et al.\n[212]/2019\nSmart City,\nSmart\nEnvironment\n\
    Bloom Filter\n(BF)\nPropose a scheme to achieve\ndata privacy which optimizes\n\
    the local differential privacy\nalgorithm in mobile\ncrowdsensing systems and\
    \ for\ndata analysis a data\naggregation algorithm is\nproposed\nBF is used to\
    \ remove noise\ndata and reduce the number of\na participant in task\nProblem\
    \ in getting meaningful\nstatistic because of large size\nBF.\nA. Islam et al.\n\
    [125]/2019\nHealthcare\nBloom Filter\n(BF)\nA blockchain-based scheme is\nproposed\
    \ to provide protection\nfrom cyber threats in the\nhealthcare system\nBF is used\
    \ to reduce the\ntransmission of data for\nauthenticating the users.\nWith the\
    \ increase of users and\ncases, processing and\nvalidation time also increases.\n\
    Xu et al.\n[293]/2019\nE-Healthcare\nVariant Bloom\nFilter (VBF)\nIn this study\
    \ the e-healthcare\nsystem data sharing to assist\nthe cloud to achieve privacy\n\
    protection. BF and message\nveriﬁcation code is used to\nprotect healthcare data\n\
    VBF use for message\nauthentication code to classify\nPersonal Health Information\n\
    (PHI) ﬁles\nDifﬁculty in deletion of data\nand false positive rate may\nexist.\n\
    Mahmoud et\nal. [173]/2019\nSmart\nEnvironment\n(Water\nDistribution)\nBloom Filter\n\
    (BF)\nA blockchain based technique\nfor smart meter data\naggression in water\
    \ distributed\nsystem is proposed.\nBF is used to identify the\ncustomer.\nData\
    \ loss due to data\ntampering, require high\nintegrity of data.\nT Zhang et al.\n\
    [303]/2019\nSmart Meter,\nSmart Grid\nCuckoo Filter\n(CF)\nStudy and propose new\n\
    blackhole attack which is\nbypass the existing defense\nmechanism and to protect\n\
    Advanced metering\ninfrastructure (AMI) from this\nattack a new technique i.e.\n\
    ‘Cuckoo-RPL’ (Routing\nProtocol for Low-Power and\nLossy Networks) based on\n\
    cuckoo ﬁlter.\nCF is used to create a hash\ntable to store all the legal\nmembers\
    \ of the AMI network.\nconsider external attacks only\nnot internal attacks.\n\
    S. Garg et al.\n[99]/2019\nSmart\nTransport\nQuotient Filter\n(QF)\nPropose a\
    \ technique secure the\nVehicular Ad hoc Networks\n(VANETs) communication\nusing\
    \ QF.\nQF is used to check whether a\nnode has entered in the\nnetwork and also\
    \ check any\nattack initiation in network.\nSecurity need to be more\nfocused.\n\
    Ni et al.\n[198]/2019\nSmart Parking Cuckoo Filter\n(CF)\nPropose a parking protocol\n\
    which is secure and privacy\npreserving using two factor\nauthentication for self\
    \ driving\nvehicles.\nCF is used to protect the user’s\nlocation privacy.\nno\
    \ security from cyber attacks.\n270\nM. Kumar and A. Singh / Probabilistic data\
    \ structures in smart city\nTable 6\n(Continued)\nAuthor/ Year\nArea\nPDS\nDescription\n\
    Contribution of PDS\nLimitation\nLiu, Hong, et\nal. [162]/2018\nHealthcare\nBloom\
    \ Filter\n(BF), MinHash\nA scheme for privacy\npreserving of wearable devices\n\
    and control data access, unique\nauthentication in smart\nhealthcare system is\
    \ proposed.\nBF is used for data efﬁciency\nwithout disclose the privacy,\nMinHash\
    \ is used for\nauthentication privacy\npreserving to ﬁnd the similar\ndata ﬁelds\
    \ without using\npersonal information of\ndifferent patient\nSome issue in big\
    \ data\nanalysis, prediction, intelligent\ninference.\nDong Zheng et\nal. [306]/2018\n\
    Smart\nHealthcare\nBloom Filter\n(BF)\nA scheme for sharing medical\ndata efﬁciently\
    \ is proposed.\nThe attribute based encryption\nfor user privacy is used.\nBF\
    \ is use to control the access\nby hiding all attributes.\nFail in cipher text\
    \ veriﬁcation\non cloud.\nMahmood A et\nal. [65]/2017\nsmart\ntransportation\n\
    Cuckoo Filter\n(CF)\nA privacy preserving scheme is\nproposed for Vehicular Ad-hoc\n\
    Networks (VANETs) which is\nindependent of hardware\nCF to improve authentication\n\
    efﬁciency in the batch message\nveriﬁcation phase\nNo signature authentication.\n\
    W Song et al.\n[253]/2017\nGeneral*\nBloom Filter\n(BF)\nPropose a scheme which\
    \ is\nsecure and efﬁcient, which\nprovide privacy on retrieval of\nencrypted large\
    \ amount of\ncloud data.\nBF is used in retrieval\nalgorithm for tree indexing\n\
    no risk evaluation and security\nrisk on collusion attacks.\nZhang et al.\n[300]/2016\n\
    Smart\nTransportation\n(RFID)\nBloom Filter\n(BF)\nA mechanism for reducing the\n\
    data transmission rate while\nidentiﬁcation of process to\nimprove the efﬁciency\
    \ and\naccuracy is proposed.\nBF is used to increase the\nefﬁciency data with\
    \ reducing\ntransmission rate during\nprocess identiﬁcation.\nMore hash functions\
    \ are\nrequired to reduce false\npositive rate.\nE Yousef et al.\n[297]/2016\n\
    Smart\nEnvironment\n(Water\nPollution)\nBloom Filter\n(BF), Counting\nBloom Filter\n\
    (CBF)\nIn this study a scheme for\nmonitoring the water pollution\nwhich is energy\
    \ efﬁcient is\nproposed.\nBF is used to Save the energy\nthrough reducing the\n\
    transmissions rate.\nPrivacy need to improve, data\nmanagement.\nAmadeo M et\n\
    al. [16]/2016\nSmart City\nBloom Filter\n(BF)\nPropose a Information Centric\n\
    Networking (ICN) Model\nwhich approve the data\ndissemination\nBF is use for storing\
    \ the path\ninformation in source-routing\nPractical deployment of ICN.\nA Goyal\
    \ et al.\n[109]/2016\nIndustry,\nGeneral*\nBloom Filter\n(BF)\nPropose and space\
    \ efﬁcient\nalgorithm using BF and\nde-normalized schema to\nvalidate the data\
    \ of two cross\ndatabases (RDBMS and\nNoSQL) for making decision\nand providing\
    \ accurate\ninformation.\nBF is to check the element of\nset using is_member function.\n\
    small probability of false\npositives.\nB Wang et al.\n[282]/2014\nGeneral*\n\
    Bloom\nFilter(BF),\nLocality\nSensitive\nHashing (LSH)\nPropose a scheme overcome\n\
    the problem of multi keyword\nfuzzy search over encrypted\ndata\nLSH function\
    \ is used in BF to\nconstruct ﬁle index to provide\nefﬁcient solution\nnot able\
    \ to represent the\nidentical bi-gram (used for\nkeyword construction).\nG. Li\
    \ et al.\n[158]/2014\nGeneral*\nCount-min\nSketch (CMS)\nA scheme is proposed\
    \ for\nanomaly detection in Wireless\nSensor Network (WSN) using\nCMS.\nCMS is\
    \ used for summarize\nthe data\nYet to implement.\nVatsalan D et\nal. [277]/2013\n\
    Healthcare,\nGovernment\nBloom Filter\n(BF)\nPropose a record linkage\ntechnique\
    \ between database\nand organization. It would also\nprovide privacy to records.\n\
    BF is used for record matching Not able to deal with\nre-identiﬁcation attacks.\n\
    M. Kumar and A. Singh / Probabilistic data structures in smart city\n271\nTable\
    \ 6\n(Continued)\nAuthor/ Year\nArea\nPDS\nDescription\nContribution of PDS\n\
    Limitation\nBeretka et al.\n[33]/2013\nSmart Energy\nLocality\nSensitive\nHashing\
    \ (LSH)\nPropose an algorithm to rising\nthe power quality by\ndistributed local\
    \ generation.\nLSH is used as a feature sets\nwhich are extracted from load\n\
    data using auto-encoders\nUser require prior training of\nauto-encoder.\nDurham\
    \ et al.\n[81]/2010\nHealthcare\nBloom Filter\n(BF)\nA mechanism for matching\
    \ the\npatient record using string\ncomparison method to\nintegrate the record\
    \ with\ncorresponding patient is\nproposed.\nBF is used for approximate\nmatching\
    \ with a patient\nmedical record.\nToo Many hash functions for\neach ﬁeld\n*:\
    \ – May be applicable in smart city applications.\nIslam et al. proposed a blockchain-based\
    \ mechanism using bloom ﬁlter which provides protection from cyber threats\nin\
    \ the healthcare system [125]. In this concern, Liu et al. proposed a blockchain-based\
    \ distributed data storage\nscheme with enabled edge computing. The counting bloom\
    \ ﬁlter is used when the storage checking fails to locate\nthe error data and\
    \ to realize data dynamics [161]. Similarly, Nie et al. propose a secure and privacy-preserving\n\
    blockchain-based data-sharing scheme. For secure proﬁle matching, the ‘Key-policy\
    \ attribute-based encryption’\nalgorithm is used, and to verify the authenticity\
    \ of ciphertext, a bloom ﬁlter with hash functions is designed [200].\nA secure\
    \ framework in a sustainable city environment is proposed by Singh et al. for\
    \ smart parking that is energy\nefﬁcient and blockchain-enabled. For secure communication\
    \ of parking zone data, the Elliptic Curve Cryptography\n(ECC) algorithm is used\
    \ at the transport layer to encrypt and decrypt the data [247].\n10. Research\
    \ opportunities and challenges in smart city\nAs discussed in Section 1.1, big\
    \ data analysis, retrieval, and processing have very high importance from the\n\
    perspective of smart cities. As storage and retrieval of large volumes of unstructured\
    \ data, especially when responses\nare required in real-time, remains a signiﬁcant\
    \ challenge for researchers. From the extensive LR done, some of the\nidentiﬁed\
    \ research areas are:\nFiltering and processing of sensor data: – The data generated\
    \ by various sensors and wearable devices have\nsome limitations like security,\
    \ privacy, ethics, data format, user acceptance, and big data concerns. Also,\
    \ have\nincompatibility issues between data and information. The information collected\
    \ by these devices may contain some\nnoise. This sensor data may be also corrupted\
    \ by the signals antiques like missing value and noise issues, which\nsigniﬁcantly\
    \ reduce phase performance. Before using data for any future analysis, this issue\
    \ needs to be addressed.\nDifﬁcult to monitoring user’s social networking data:\
    \ – It is difﬁcult to monitor users’ data on social network-\ning sites. In smart\
    \ healthcare, doctors can’t rely on data from social media. But still, a system\
    \ for detecting the\npsychological disturbance in patients is presented named\
    \ emotional healthcare. Some techniques used to detect de-\npressive and stressful\
    \ content are Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN),\
    \ and\nBi-directional Long Short-Term Memory (Bi-LSTM). Also proposed recommendation\
    \ systems for patients to get a\ntext-based on the results while they had been\
    \ monitored.\nLack of efﬁcient computational models and data structures: – The\
    \ expansion of massive data has generated\nlarge and complicated data sets. Traditional\
    \ methods used for storage and retrieval of data, increase the computation\noverhead\
    \ in big processing and hence are unable to meet the requirements of the users.\
    \ For big data handling some\nadvanced data, models are required which produce\
    \ results in minimum time with minimum computation overhead.\nOne of the basic\
    \ problems of massive data is to style efﬁcient computational models and data\
    \ structures for solving\nthese problems in big data.\nThe need for energy-efﬁcient\
    \ data processing: – The rise of uses of IoT devices concept paved the way for\
    \ a\nsmart city. Energy management has become a major issue resource as IoT devices\
    \ are constantly consuming huge\namounts of energy. These concerns must be considered\
    \ in order to establish an effective mechanism. The efﬁcient use\n272\nM. Kumar\
    \ and A. Singh / Probabilistic data structures in smart city\nof power aims to\
    \ promise a sustainable city. In addition, IoT devices produce a larger amount\
    \ of data which is needed\nfor optimal processing. Enforcing another challenge\
    \ in securing smart cities is the sharing of data and access control.\nData storage\
    \ and processing: – Smart Cities take hold of the relative advantage of being\
    \ robust for storing\ndata and processing it in the information world. The applications\
    \ of smart cities have generated a continuous huge\namount of data from different\
    \ sources. The existing traditional methods are insufﬁcient to manage this volume\n\
    of data and they have restricted processing speed and effective storage expansion\
    \ costs. To overcome this issue,\nefﬁcient computational models and data structures\
    \ are required.\nVolume data: – Although it is difﬁcult to quantify this challenge\
    \ because data sets are typically very big like hun-\ndreds of terabytes or more.\
    \ The traditional storage system like Relational Database Management Systems (RDBMS)\n\
    and new big data technologies like Hadoop are developed to efﬁciently count the\
    \ data that must be kept and pro-\ncessed. The new data structures are also required\
    \ to handle and produce results at run time.\nReal time response: – The Response\
    \ Time (RT) in the smart city is very important in term of service, results, data\n\
    transmission etc. The RT directs to the fact that the data transmission and business\
    \ data infrastructure at elevated cost\nand should be considered with fewer delays.\
    \ In this case, various techniques have been used which are depending\non the\
    \ situation and difﬁculty of analysis. In smart cities where responses need to\
    \ be given after processing huge\ndata or by handling streaming data, then traditional\
    \ techniques and approaches are not efﬁcient. So some new data\nhandling techniques/data\
    \ structures are required to provide results in real-time.\nVariety of Data: –\
    \ In the smart city the source of a variety of data is also a major issue. The\
    \ smart city data\nis available in different data sets for different applications\
    \ of smart city and with different format styles like audio,\nvideo, images, text\
    \ etc. The data collected from a variety of sources are ambiguous, unstructured,\
    \ or semi-structured.\nThis data needs to be in a well-structured manner for effective\
    \ and efﬁcient results. The traditional methods are not\nsufﬁcient or even do\
    \ not provide accurate results in the real-time scenarios. For this data management,\
    \ a new data\nstructure like PDS is required.\nSearching and Retrieving for a\
    \ data item from the big data: – In huge data, the task of efﬁciently searching\n\
    and retrieving appropriate data for review in the petabyte and exabyte ranges,\
    \ in a variety of formats, is a major\nchallenge. In some applications when deadlines\
    \ are associated, this challenge becomes more tedious.\nStream Processing(Data\
    \ Collection and Distribution Analysis): – The streaming of big data in smart\
    \ cities is a\nbig challenge. There is a huge amount of data is ﬂow in the smart\
    \ city. The processing and analysis of this set of\ndata are required. When raw\
    \ data is combined like vehicle and road, geolocation sensor and social media,\
    \ weather\ndata, then the streaming of data may cause some issues like a too long\
    \ time in result, access problem etc. Also\nsome problems in development like\
    \ it is still dependent. Various decisions and predictions are based on this type\
    \ of\ndata like trafﬁc, future power consumption, etc. Some traditional systems\
    \ are proposed but with various limitations.\nA new mechanism is required to design\
    \ for efﬁcient and effective results.\nIntegration of Heterogeneous Data Sources\
    \ (Diversity Consolidation): – The data coming from different sources\nis not\
    \ in proper sequence, maybe in a different format, or ambiguous. The operation\
    \ on these data sets is difﬁcult to\napply like validation, authentication, updating,\
    \ alteration etc. This data is need to be well structured and organized.\nNatural\
    \ Text Analysis and Communication(social media analysis): – The analysis of natural\
    \ text from social\nnetworks is available through mobile devices like smartphones\
    \ is also challenging. This data is used for monitoring\nthe behavior and emotions\
    \ of citizens in real life. The information on location from various social networking\
    \ sites is\nnot in a proper format. The data include the comments and statements\
    \ about the user’s feelings, thoughts, interests,\nrelations etc. are integrated\
    \ with sensor data. The reliability of this data is also a big challenge.\nAmbient\
    \ Intelligence issues/challenges (speciﬁc to the current generation of smart city\
    \ domains): – The ex-\npeditious growth of conversion from rural to urban areas\
    \ and urban to smart cities is increasing rapidly. It also\nincreases the usage\
    \ and deployment of smart technologies in everything and everywhere in the city.\
    \ So, smart cities\nmay also face some ambient intelligence issues. The main concern\
    \ in smart cities is AI, and privacy when combine\nwith automation and autonomous\
    \ system [257]. This may also create some design trade-offs like:\nHuman control\
    \ vs. automation: Fail to recognize the speed limit sign or fooled by scam stickers\
    \ on road by\nautonomous driving [86]. Autonomous car driving (Uber) had met a\
    \ deadly accident with a woman walking at night\n[185]. Hard Behavior is also\
    \ one of the problems in autonomous systems. An example of this is conversations\
    \ of\ncustomers with fully automated call centers, and online shopping without\
    \ the involvement of humans. In AI-based\nbehavior, there are missing traceability,\
    \ transparency, and incomprehensible decisions.\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\n273\nPrivacy vs. smartness: There is also a trade-off\
    \ between privacy and intelligence. To provide smartness, the data\nshould be\
    \ provided to smart services. For this, blockchain is used, which is also cost-effective.\n\
    Infrastructure: To improve the standard of citizens, sensor technology is used\
    \ for analyzing and gathering in-\nformation. These sensors generally collect\
    \ the data like air quality, crime rates, rush hour stats, etc. To install these\n\
    types of sensors a complicated and costly infrastructure is involved [224].\n\
    Hackers vs Security: The threat level to security has also increased, as the uses\
    \ of sensors and IoT technology\nhave expanded.\nBeing Socially Inclusive: The\
    \ programs like ‘smart transit’ which is a great idea for the bustling city for\
    \ real-time\nupdates. This may also raise some issues like: some people in smart\
    \ cities can’t afford to take transit, all elderly\ngrowing people do use smart\
    \ mobile devices or apps, and how it is possible to use and reach technology to\
    \ these\ngroups of people?\n11. Discussion and conclusion\nIn this paper, we have\
    \ discussed the role of big data in Section 1.1, where we emphasize the importance\
    \ of big\ndata in smart cities. In Section 2 the generations of smart cities have\
    \ been discussed. There are various architectures\nthat have been discussed by\
    \ many researchers, but the most appropriate architecture for the smart city is\
    \ elaborated\nin Section 4. Los Angeles took the ﬁrst action or made the ﬁrst\
    \ contribution to smart city projects in 1974. They\nanalyze the urban big data.\
    \ In Section 5 listed various projects to date and also future plans regarding\
    \ smart cities.\nThe role of big data in smart cities is crucial in a smart city.\
    \ Probabilistic Data Structures (PDS) have been discussed\n(Section 6) as a key\
    \ solution to many applications of smart cities. This paper also emphasizes the\
    \ various applications\nof smart cities, such as smart healthcare, smart transportation,\
    \ smart environment, agriculture, smart governance\nand economy, smart society,\
    \ people, education, and smart sustainability (Section 7). It has been found,\
    \ after going\nthrough various proposed techniques in the area of smart cities;\
    \ that there is an inﬂuence of big data in a smart\ncity. Generated data is inconsistent,\
    \ semi-structured, or unstructured, lack of efﬁciency in retrieval and storage\n\
    management of data, privacy, and security has major concerns. In the smart city,\
    \ the collection of data itself is a big\nchallenge. The data collected using\
    \ IoT devices, records (medical history), social media, and web pages are too\
    \ large.\nObviously, this data is redundant and unstructured. Various monitoring\
    \ systems in smart cities also have issues in the\nanalysis and representation\
    \ of this big data with low dimensions. Many researchers have put their sincere\
    \ endeavors\ninto extracting information from a huge amount of knowledge databases.\
    \ The main challenge in this effort is that\nthere is no standard approach to\
    \ efﬁciently map and keep the big data on consistent data structures. The existing\n\
    tool and techniques cannot work efﬁciently and satisfactorily in data management.\
    \ To store and processing of data\nfor optimal recovery and exploring procedures,\
    \ data structures like PDS is one of the adequate standards to use. In\nthe conclusion\
    \ of this paper after reviewing related work, we have listed the exiting and scope\
    \ of PDS in various\napplications of smart cities in Table 7.\nTable 7\nDomain\
    \ speciﬁc approaches of PDS in smart city\nPDS Smart Healthcare Smart Transport\
    \ Smart Environment Smart Industry Smart Energy Smart Governance Smart Society\
    \ Smart Sustainability\nBF\n✓\n✓\n✓\n✓\n✓\n✓\n✓\n✓\nCMS\n⋆\n✓\n✗\n✗\n✓\n✗\n✓\n\
    ⋆\nLSH\n✓\n⋆\n✓\n✓\n✓\n⋆\n✓\n⋆\nQF\n✓\n✓\n✓\n✗\n✓\n✗\n⋆\n✗\nCF\n✓\n✓\n✓\n⋆\n✓\n\
    ✗\n⋆\n✗\nHLL\n✗\n✓\n✗\n✗\n⋆\n✗\n⋆\n⋆\n⋆: – May be Applicable.\nA few research\
    \ opportunities and challenges have been concluded after analyzing the existing\
    \ research available\nfor the future. We will try to address some of these research\
    \ challenges (Section 10). The goal of this paper is to\nprovide a comprehensive\
    \ review of PDS and its applications in the domains of smart cities. The foremost\
    \ aim of\n274\nM. Kumar and A. Singh / Probabilistic data structures in smart\
    \ city\nthis paper is to provide a detailed survey of PDS in smart cities for\
    \ readers and researchers who want to explore this\nﬁeld, along with the research\
    \ opportunities in the domains.\nConﬂict of interest\nNone to report.\nAppendix.\
    \ Acronyms\nThe acronyms used in this paper are listed in Table 8.\nTable 8\n\
    Acronyms used in the survey and their deﬁnitions\nAcronym\nDeﬁnition\nAcronym\n\
    Deﬁnition\nAI\nArtiﬁcial Intelligence\nORC\nOptimized Row Columnar\nAMI\nAdvanced\
    \ Metering Infrastructure\nPHI\nPersonal Health Information\nAMQ\nApproximate\
    \ Member Query\nPoAuth\nProof-of-Authentication\nAPN\nAccess Point Name\nPURSUIT\n\
    Pursuing a Pub/Sub Internet\nARRA\nAmerican Recovery and Reinvestment Act\nQF\n\
    Quotient Filter\nBF\nBloom Filter\nRDMS\nRelational Database Management Systems\n\
    Bi-LSTM\nBi-directional Long Short-Term Memory\nRFID\nRadio Frequency Identiﬁcation\n\
    CBF\nCounting Bloom Filter\nRGI\nRow Group Index\nCC\nCloud Computing\nRNN\nRecurrent\
    \ Neural Networks\nCCTV\nClosed Circuit Television\nRPL\nRouting Protocol for\
    \ Low-Power and Lossy Networks\nCF\nCuckoo Filter\nRSU\nRoad Side Unit\nCIAM\n\
    Content-centric IoT-based Air pollution Monitoring\nRT\nResponse Time\nCMS\nCount\
    \ Min Sketch\nSAE\nStaked Auto-Encoder\nCMoS\nCentral Monitoring Station\nSAM\n\
    Smart Agricultural Monitoring\nCNN\nConvolutional Neural Network\nSAR\nSynthetic\
    \ Aperture Radar\nCOVID-19\nCoronavirus Disease-19\nSDN\nSoftware Deﬁned Networking\n\
    DDS\nDigitale Stad\nSEM\nSmart Environment Monitoring\nDoS\nDenial of Services\n\
    SHRS\nSmart Home Reasoning System\nDRL\nDynamic Range Learning\nSIS\nSmart Irrigation\
    \ System\nEHRs\nElectronic Health Records\nSQL\nStructured Query Language\nFMS\n\
    Farm Management System\nSSD\nSingle Shot MultiBox Detector\nGDP\nGross Domestic\
    \ Product\nSTS\nSmart Transportation System\nGoI\nGovernment of India\nSVM\nSupport\
    \ Vector Machine\nGPS\nGlobal Positioning System\nUAV\nUnmanned aerial vehicle\n\
    HDFS\nHadoop Distributed File System\nVANETs\nVehicular Ad-hoc Networks\nICT\n\
    Information and Communication Technology\nVBF\nVariant Bloom Filter\nIIoT\nIndustrial\
    \ Internet of Things\nVPN\nVirtual Private Network\nIoHV\nInternet Healthcare\
    \ Vehicle (IoHV)\nVMKSE\nVeriﬁable Multi-Key Searchable Encryption\nIoT\nInternet\
    \ of Things\nWDS\nWater Distribution System\nISQF\nImproved Streaming Quotient\
    \ Filter\nWFH\nWork From Home\nITS\nIntelligent Transportation System\nWSNs\n\
    Wireless Sensor Networks\nLRP\nLicense Plate Recognition\nYSCP\nYokohama Smart\
    \ City Project\nLSH\nLocality Sensitive Hashing\n3G, 4G\nThird, Fourth Generations\n\
    LSTM\nLong Short-Term Memory\n5G\nFifth Generations\nLTE\nLong-Term Evolution\n\
    6G\nSixth Generations\nM. Kumar and A. Singh / Probabilistic data structures in\
    \ smart city\n275\nReferences\n[1] B. Abidi, A. Jilbab and M.E. Haziti, Wireless\
    \ sensor networks in biomedical: Wireless body area networks, in: Europe and MENA\n\
    Cooperation Advances in Information and Communication Technologies, Springer,\
    \ 2017, pp. 321–329.\n[2] M. Abulhakim, Dubai the Smart City, CISCO presentations,\
    \ Retrieved January 31, 2013.\n[3] G. Acampora, D.J. Cook, P. Rashidi and A.V.\
    \ Vasilakos, A survey on ambient intelligence in healthcare, Proceedings of the\
    \ IEEE 101(12)\n(2013), 2470–2494.\n[4] S. Acharya and S. Chellappan, Big data\
    \ and analytics, Book (2015).\n[5] R. Agarwal and V. Dhar, Big data, data science,\
    \ and analytics: The opportunity and challenge for IS research, Vol. 25, INFORMS,\
    \ 2014,\npp. 443–448.\n[6] R.K. Agrahari, Y. Kobayashi, T.S.T. Tanaka, S.K. Panda\
    \ and H. Koyama, Smart fertilizer management: The progress of imaging technolo-\n\
    gies and possible implementation of plant biomarkers in agriculture, Soil Science\
    \ and Plant Nutrition (2021), 1–11.\n[7] B. Aher, Signiﬁcance of Big Data in Smart\
    \ City, 2018.\n[8] S. Ahmed, T.M. Tan, A.M. Mondol, Z. Alam, N. Nawal and J. Uddin,\
    \ Automated toll collection system based on rﬁd sensor, in: 2019\nInternational\
    \ Carnahan Conference on Security Technology (ICCST), IEEE, 2019, pp. 1–3.\n[9]\
    \ R. Aijaz and K. Hoelscher, India’s smart cities mission: An assessment, ORF\
    \ Issue Brief 124(1) (2015), 1–12.\n[10] N. Akbarpour, A. Salehi-Amiri, M. Hajiaghaei-Keshteli\
    \ and D. Oliva, An innovative waste management system in a smart city under\n\
    stochastic optimization using vehicle routing problem, Soft Computing 25(8) (2021),\
    \ 6707–6727.\n[11] S.A. Alansar, M.M. Badr, M. Mahmoud and W. Alasmary, Efﬁcient\
    \ and Privacy-Preserving Infection Control System for Covid-19-Like\nPandemics\
    \ using Blockchain, arXiv preprint arXiv:2104.02263 (2021).\n[12] F. Alassery\
    \ and M.M. Althobaiti, Context information aggregation mechanism based on bloom\
    \ ﬁlters (CIA-BF) for high performance\nmonitoring applications of Internet of\
    \ things, International Journal of Computer Networks & Communications 13(1) (2021),\
    \ 21.\n[13] A.H. Alavi, P. Jiao, W.G. Buttlar and N. Lajnef, Internet of Things-enabled\
    \ smart cities: State-of-the-art and future trends, Measurement\n129 (2018), 589–606.\n\
    [14] M. Aldabbas, X. Xie, B. Teufel and S. Teufel, Future security challenges\
    \ for smart societies: Overview from technical and societal\nperspectives, in:\
    \ 2020 International Conference on Smart Grid and Clean Energy Technologies (ICSGCE),\
    \ IEEE, 2020, pp. 103–111.\n[15] A.A. Alshdadi, Cyber-physical system with IoT-based\
    \ smart vehicles, Soft Computing (2021), 1–13.\n[16] M. Amadeo, C. Campolo, J.\
    \ Quevedo, D. Corujo, A. Molinaro, A. Iera, R.L. Aguiar and A.V. Vasilakos, Information-centric\
    \ networking\nfor the Internet of things: Challenges and opportunities, IEEE Network\
    \ 30(2) (2016), 92–100.\n[17] T.M. Amado and J.C.D. Cruz, Development of machine\
    \ learning-based predictive models for air quality monitoring and characterization,\n\
    in: TENCON 2018–2018 IEEE Region 10 Conference, IEEE, 2018, pp. 0668–0672.\n[18]\
    \ S.M. Amin and B.F. Wollenberg, Toward a smart grid: Power delivery for the 21st\
    \ century, IEEE power and energy magazine 3(5) (2005),\n34–41.\n[19] M. Arena,\
    \ N.D. Ciceri, S. Terzi, I. Bengo, G. Azzone and M. Garetti, A state-of-the-art\
    \ of industrial sustainability: Deﬁnitions, tools and\nmetrics, International\
    \ Journal of Product Lifecycle Management 4(1–3) (2009), 207–251.\n[20] N. Arumugam,\
    \ Cities Forum, 2022.\n[21] J.C. Augusto, Smart cities: State of the art and future\
    \ challenges, Handbook of Smart Cities (2020), 1–12.\n[22] G.S. Aujla, A. Jindal\
    \ and N. Kumar, EVaaS: Electric vehicle-as-a-service for energy trading in SDN-enabled\
    \ smart transportation system,\nComputer Networks 143 (2018), 247–262.\n[23] G.S.\
    \ Aujla, M. Singh, A. Bose, N. Kumar, G. Han and R. Buyya, Blocksdn: Blockchain-as-a-service\
    \ for software deﬁned networking in\nsmart city applications, IEEE Network 34(2)\
    \ (2020), 83–91.\n[24] S.K. Babey, J.E. McFee, C.D. Anger, A. Moise and S.B. Achal,\
    \ Feasibility of optical detection of land mine trip wires, in: Detection and\n\
    Remediation Technologies for Mines and Minelike Targets V, Vol. 4038, International\
    \ Society for Optics and Photonics, 2000, pp. 220–231.\n[25] F. Baena, A. Guarin,\
    \ J. Mora, J. Sauza and S. Retat, Learning factory: The path to industry 4.0,\
    \ Procedia manufacturing 9 (2017), 73–80.\n[26] D. Bandyopadhyay and J. Sen, Internet\
    \ of things: Applications and challenges in technology and standardization, Wireless\
    \ personal\ncommunications 58(1) (2011), 49–69.\n[27] C.T. Barba, M.A. Mateos,\
    \ P.R. Soto, A.M. Mezher and M.A. Igartua, Smart city for VANETs using warning\
    \ messages, trafﬁc statistics\nand intelligent trafﬁc lights, in: 2012 IEEE Intelligent\
    \ Vehicles Symposium, IEEE, 2012, pp. 902–907.\n[28] J. Batten and C. Edwards,\
    \ Sustainable Cities Index 2015 Balancing the economic, social and environmental\
    \ needs of the world’s leading\ncities, Arcadis, 2016.\n[29] B. Bender, Gatherer-hunter\
    \ to farmer: A social perspective, World archaeology 10(2) (1978), 204–222.\n\
    [30] M.A. Bender, M. Farach-Colton, R. Johnson, B.C. Kuszmaul, D. Medjedovic,\
    \ P. Montes, P. Shetty, R.P. Spillane and E. Zadok, Don’t\nthrash: How to cache\
    \ your hash on ﬂash, in: 3rd Workshop on Hot Topics in Storage and File Systems\
    \ (HotStorage 11), 2011.\n[31] C. Benevolo, R.P. Dameri and B. D’auria, Smart\
    \ mobility in smart city, in: Empowering Organizations, Springer, 2016, pp. 13–28.\n\
    [32] F. Benzi, N. Anglani, E. Bassi and L. Frosini, Electricity smart meters interfacing\
    \ the households, IEEE Transactions on Industrial\nElectronics 58(10) (2011),\
    \ 4487–4494.\n[33] S.F. Beretka and E.D. Varga, Locality sensitive hashing of\
    \ customer load proﬁles, in: 2013 International Conference on Renewable Energy\n\
    Research and Applications (ICRERA), IEEE, 2013, pp. 353–356.\n[34] M. Berlin,\
    \ S. Selvakanmani, T. Umamaheswari, K. Jausmin and S. Babu, Alert message based\
    \ automated toll collection and payment\nviolation management system using smart\
    \ road side units, Materials Today: Proceedings (2021).\n276\nM. Kumar and A.\
    \ Singh / Probabilistic data structures in smart city\n[35] S. Bhatia and J. Malhotra,\
    \ Morton ﬁlter-based security mechanism for healthcare system in cloud computing,\
    \ in: Healthcare, Vol. 9,\nMultidisciplinary Digital Publishing Institute, 2021,\
    \ p. 1551.\n[36] B.H. Bloom, Space/time trade-offs in hash coding with allowable\
    \ errors, Communications of the ACM 13(7) (1970), 422–426.\n[37] K. Bodake, R.\
    \ Ghate, H. Doshi, P. Jadhav and B. Tarle, Soil based fertilizer recommendation\
    \ system using Internet of Things, MVP\nJournal of Engineering Sciences 1(1) (2018),\
    \ 13–19.\n[38] A. Bodhani, Smart transport, Engineering & Technology 7(6) (2012),\
    \ 70–73.\n[39] F.F. Borelli, G.O. Biondi and C.A. Kamienski, BIoTA: A buildout\
    \ IoT application language, IEEE Access 8 (2020), 126443–126459.\n[40] H. Bornholdt,\
    \ K. Röbert and P. Kisters, Accessing smart city services in untrustworthy environments\
    \ via decentralized privacy-preserving\noverlay networks, in: 2021 IEEE International\
    \ Conference on Service-Oriented System Engineering (SOSE), IEEE, 2021, pp. 144–149.\n\
    [41] M. Bouamar and M. Ladjal, Evaluation of the performances of ANN and SVM techniques\
    \ used in water quality classiﬁcation, in: 2007\n14th IEEE International Conference\
    \ on Electronics, Circuits and Systems, IEEE, 2007, pp. 1047–1050.\n[42] A.D.\
    \ Boursianis, M.S. Papadopoulou, P. Diamantoulakis, A. Liopa-Tsakalidi, P. Barouchas,\
    \ G. Salahas, G. Karagiannidis, S. Wan and\nS.K. Goudos, Internet of things (IoT)\
    \ and agricultural unmanned aerial vehicles (UAVs) in smart farming: a comprehensive\
    \ review,\nInternet of Things (2020), 100187.\n[43] M. Breque, L. De Nul and A.\
    \ Petridis, Industry 5.0: Towards a sustainable, human-centric and resilient European\
    \ industry, Luxembourg,\nLU: European Commission, Directorate-General for Research\
    \ and Innovation (2021).\n[44] A. Bris and B. Lanvin, Smart City Observatory,\
    \ 2021, https://www.imd.org/smart-city-observatory/home/.\n[45] K. Brookes, Hardmetal\
    \ meet at world congress, Metal Powder Report 66(2) (2011), 10–14.\n[46] R.P.N.\
    \ Budiarti, S. Sukaridhoto, M. Hariadi and M.H. Purnomo, Big data technologies\
    \ using SVM (case study: Surface water classiﬁcation\non regional water utility\
    \ company in Surabaya), in: 2019 International Conference on Computer Science,\
    \ Information Technology, and\nElectrical Engineering (ICOMITEE), IEEE, 2019,\
    \ pp. 94–101.\n[47] M. Bulu, City Competitiveness and Improving Urban Subsystems:\
    \ Technologies and Applications: Technologies and Applications, IGI\nGlobal, 2011.\n\
    [48] H. Burns, Germ theory: Invisible killers revealed, BMJ 334(suppl 1) (2007),\
    \ s11–s11.\n[49] M. Carminati, O. Kanoun, S.L. Ullo and S. Marcuccio, Prospects\
    \ of distributed wireless sensor networks for urban environmental moni-\ntoring,\
    \ IEEE Aerospace and Electronic Systems Magazine 34(6) (2019), 44–52.\n[50] R.\
    \ Casas, A. Hermosa, Á. Marco, T. Blanco and F.J. Zarazaga-Soria, Real-time extensive\
    \ livestock monitoring using LPWAN smart\nwearable and infrastructure, Applied\
    \ Sciences 11(3) (2021), 1240.\n[51] P.G. Cerny, Globalization and the changing\
    \ logic of collective action, International organization 49(4) (1995), 595–625.\n\
    [52] F.-M. Chan, ICT in Malaysian schools: Policy and strategies, in: A Workshop\
    \ on the Promotion of ICT in Education to Narrow the Digital\nDivide, 2002, pp.\
    \ 15–22.\n[53] H.M.Y. Chan, Conduct, Connect, Continue: Foster students’ digital\
    \ literacy at a school library for a smart city (2017).\n[54] M.S. Charikar, Similarity\
    \ estimation techniques from rounding algorithms, in: Proceedings of the Thiry-Fourth\
    \ Annual ACM Symposium\non Theory of Computing, 2002, pp. 380–388.\n[55] B. Charyyev\
    \ and M.H. Gunes, Voice command ﬁngerprinting with locality sensitive hashes,\
    \ in: Proceedings of the 2020 Joint Workshop\non CPS&IoT Security and Privacy,\
    \ 2020, pp. 87–92.\n[56] R. Chaudhary, G.S. Aujla, S. Garg, N. Kumar and J.J.\
    \ Rodrigues, SDN-enabled multi-attribute-based secure communication for smart\n\
    grid in IIoT environment, IEEE Transactions on Industrial Informatics 14(6) (2018),\
    \ 2629–2640.\n[57] S. Che, W. Yang and W. Wang, Improved streaming quotient ﬁlter:\
    \ A duplicate detection approach for data streams, Int. Arab J. Inf.\nTechnol.\
    \ 17(5) (2020), 769–777.\n[58] C. Chen, E.-W. Loh, K.N. Kuo and K.-W. Tam, The\
    \ times they are a-changin’–healthcare 4.0 is coming!, Journal of medical systems\
    \ 44(2)\n(2020), 1–4.\n[59] L.-C. Chen, R.-K. Sheu, W.-Y. Peng, J.-H. Wu and C.-H.\
    \ Tseng, Video-based parking occupancy detection for smart control system,\nApplied\
    \ Sciences 10(3) (2020), 1079.\n[60] N.-S. Chen, C. Yin, P. Isaias and J. Psotka,\
    \ Educational big data: Extracting meaning from data for smart education, Vol.\
    \ 28, Taylor &\nFrancis, 2020, pp. 142–147.\n[61] Q. Chen, G. Cheng, Y. Fang,\
    \ Y. Liu, Z. Zhang, Y. Gao and B.K. Horn, Real-time learning-based monitoring\
    \ system for water contamina-\ntion, in: 2018 4th International Conference on\
    \ Universal Village (UV), IEEE, 2018, pp. 1–5.\n[62] J. Choi and Y. Lee, The status\
    \ of SMART education in Korea, in: EdMedia+ Innovate Learning, Association for\
    \ the Advancement of\nComputing in Education (AACE), 2012, pp. 175–178.\n[63]\
    \ O. Chudiniva and M. Afonina, Formation of “urban planning” indicators for “smart\
    \ city” concept (on the example of SKOLKOVO,\nMoscow), in: MATEC Web of Conferences,\
    \ Vol. 170, EDP Sciences, 2018, p. 02021.\n[64] G. Cormode and S. Muthukrishnan,\
    \ An improved data stream summary: The count-min sketch and its applications,\
    \ Journal of Algorithms\n55(1) (2005), 58–75.\n[65] J. Cui, J. Zhang, H. Zhong\
    \ and Y. Xu, SPACF: A secure privacy-preserving authentication scheme for VANET\
    \ with cuckoo ﬁlter, IEEE\nTransactions on Vehicular Technology 66(11) (2017),\
    \ 10283–10295.\n[66] B. Cunha, C. Brito, G. Araújo, R. Sousa, A. Soares and F.A.\
    \ Silva, Smart Trafﬁc Control in Vehicle Ad-Hoc Networks: A Systematic\nLiterature\
    \ Review, International Journal of Wireless Information Networks (2021), 1–23.\n\
    [67] M. D’Aloia, M. Rizzi, R. Russo, M. Notarnicola and L. Pellicani, A marker-based\
    \ image processing method for detecting available parking\nslots from UAVs, in:\
    \ International Conference on Image Analysis and Processing, Springer, 2015, pp.\
    \ 275–281.\nM. Kumar and A. Singh / Probabilistic data structures in smart city\n\
    277\n[68] J. Daniel, P.-U. Andrés, S. Héctor, B. Miguel, V.D. Patrick and T. Marco,\
    \ A survey of artiﬁcial neural network-based modeling in agroe-\ncology, in: Soft\
    \ Computing Applications in Industry, Springer, 2008, pp. 247–269.\n[69] J.M.\
    \ de Souza Sant’Ana, E. Eldeeb, H. Alves, C. Kalalas and P.J. Nardelli, WP4 Deliverable\
    \ 4.3 a Report on Heterogeneous Big Data\nAggregation I (2021).\n[70] V. de Yokohama,\
    \ Yokohama sumato shiti purojekuto – YSCP, Yokohama Smart City Project (YSCP)]\
    \ [en ligne] http://www.city.\nyokohama.lg, 2010.\n[71] A.K. Debnath, H.C. Chin,\
    \ M.M. Haque and B. Yuen, A methodological framework for benchmarking smart transport\
    \ cities, Cities 37\n(2014), 47–56.\n[72] B. Debnath, S. Sengupta, J. Li, D.J.\
    \ Lilja and D.H. Du, BloomFlash: Bloom ﬁlter on ﬂash-based storage, in: 2011 31st\
    \ International\nConference on Distributed Computing Systems, IEEE, 2011, pp.\
    \ 635–644.\n[73] G. Demiris and B.K. Hensel, Technologies for an aging society:\
    \ A systematic review of “smart home” applications, Yearbook of medical\ninformatics\
    \ 17(01) (2008), 33–40.\n[74] U. Desa, United nations department of economic and\
    \ social affairs, population division. world population prospects: The 2015 revision,\n\
    key ﬁndings and advance tables, Online Edition UN DESA, New York, 2015.\n[75]\
    \ K.C. Desouza and B. Jacob, Big data in the public sector: Lessons for practitioners\
    \ and scholars, Administration & Society 49(7) (2017),\n1043–1064.\n[76] S. Dhingra,\
    \ R.B. Madda, A.H. Gandomi, R. Patan and M. Daneshmand, Internet of Things mobile–air\
    \ pollution monitoring system (IoT-\nMobair), IEEE Internet of Things Journal\
    \ 6(3) (2019), 5577–5584.\n[77] D.R. Di Martini, E.C. Tetila, J.M. Junior, E.T.\
    \ Matsubara, H. Siqueira, A.A. de Castro Junior, M.S. Araujo, C.H. Monteiro, H.\
    \ Pistori and\nV. Liesenberg, Machine learning applied to UAV imagery in precision\
    \ agriculture and forest monitoring in brazililian savanah, in: IGARSS\n2019–2019\
    \ IEEE International Geoscience and Remote Sensing Symposium, IEEE, 2019, pp.\
    \ 9364–9367.\n[78] S. Dimitriadis and C. Goumopoulos, Applying machine learning\
    \ to extract new knowledge in precision agriculture applications, in: 2008\nPanhellenic\
    \ Conference on Informatics, IEEE, 2008, pp. 100–104.\n[79] I. Dincer and C. Acar,\
    \ Smart energy systems for a sustainable future, Applied energy 194 (2017), 225–235.\n\
    [80] A.S. Duggal, P.K. Malik, A. Gehlot, R. Singh, G.S. Gaba, M. Masud and J.F.\
    \ Al-Amri, A sequential roadmap to Industry 6.0: Exploring\nfuture manufacturing\
    \ trends, IET Communications (2021).\n[81] E. Durham, Y. Xue, M. Kantarcioglu\
    \ and B. Malin, Private medical record linkage with approximate matching, in:\
    \ AMIA Annual Sympo-\nsium Proceedings, Vol. 2010, American Medical Informatics\
    \ Association, 2010, p. 182.\n[82] S. Dutta, A. Narang and S.K. Bera, Streaming\
    \ quotient ﬁlter: A near optimal approximate duplicate detection approach for\
    \ data streams,\nProceedings of the VLDB Endowment 6(8) (2013), 589–600.\n[83]\
    \ J.L. Esposito, The Islamic World: Past and Present, Oxford University Press\
    \ on Demand, 2004.\n[84] E. Estevez and T. Janowski, Electronic governance for\
    \ sustainable development – conceptual framework and state of research, Government\n\
    information quarterly 30 (2013), S94–S109.\n[85] Evidence-Based Medicine Working\
    \ Group, Evidence-Based Medicine A New Approach to Teaching the Practice of Medicine\
    \ (1992).\n[86] K. Eykhold, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xi,\
    \ A. Prakash, T. Kohno and D. Song, Robust physical world attacks on\ndeep learning\
    \ models, arXiv preprint arXiv:1707.08945 (2019).\n[87] N. Fajriyah and A. Djunaedi,\
    \ The transformation of smart city concept in urban development (case study: Semarang\
    \ city), in: IOP Con-\nference Series: Earth and Environmental Science, Vol. 764,\
    \ IOP Publishing, 2021, p. 012028.\n[88] S. Fan and R.J. Hyndman, Short-term load\
    \ forecasting based on a semi-parametric additive model, IEEE Transactions on\
    \ Power Systems\n27(1) (2011), 134–141.\n[89] M.A.B.M. Farach-Colton, R. Johnson,\
    \ B.C.K.D. Medjedovic, P. Montes, P. Shetty, R.P. Spillane and E. Zadok, Don’t\
    \ Thrash: How to\nCache Your Hash in Flash, (2012), 1627–1637.\n[90] H. Farhangi,\
    \ The path of the smart grid, IEEE power and energy magazine 8(1) (2009), 18–28.\n\
    [91] R. Fazai, M. Mansouri, K. Abodayeh, V. Puig, M. Selmi, H. Nounou and M. Nounou,\
    \ Multiscale Gaussian process regression-based GLRT\nfor water quality monitoring,\
    \ in: 2019 4th Conference on Control and Fault Tolerant Systems (SysTol), IEEE,\
    \ 2019, pp. 44–49.\n[92] K. Finch and M. Mattmiller, Model Policy: Privacy Impact\
    \ Assessment, G20 Global Smart Cities Alliance (2020).\n[93] A. Flexner, Medical\
    \ Education in Europe: A Report to the Carnegie Foundation for the Advancement\
    \ of Teaching, Vol. 6, Carnegie\nFoundation, 1912.\n[94] R. Foresti, S. Rossi,\
    \ M. Magnani, C.G.L. Bianco and N. Delmonte, Smart society and artiﬁcial intelligence:\
    \ Big data scheduling and the\nglobal standard method applied to smart maintenance,\
    \ Engineering 6(7) (2020), 835–846.\n[95] M. Fukuyama, Society 5.0: Aiming for\
    \ a new human-centered society, Japan Spotlight 27(5) (2018), 47–50.\n[96] S.\
    \ García, S. Ramírez-Gallego, J. Luengo, J.M. Benítez and F. Herrera, Big data\
    \ preprocessing: Methods and prospects, Big Data Analytics\n1(1) (2016), 1–22.\n\
    [97] G. Gardaševi´c, M. Veleti´c, N. Maleti´c, D. Vasiljevi´c, I. Radusinovi´c,\
    \ S. Tomovi´c and M. Radonji´c, The IoT architectural framework,\ndesign issues\
    \ and application domains, Wireless personal communications 92(1) (2017), 127–148.\n\
    [98] S. Garg, A. Singh, G.S. Aujla, S. Kaur, S. Batra and N. Kumar, A probabilistic\
    \ data structures-based anomaly detection scheme for\nsoftware-deﬁned Internet\
    \ of vehicles, IEEE Transactions on Intelligent Transportation Systems 22(6) (2020),\
    \ 3557–3566.\n[99] S. Garg, A. Singh, K. Kaur, G.S. Aujla, S. Batra, N. Kumar\
    \ and M.S. Obaidat, Edge computing-based security framework for big data\nanalytics\
    \ in VANETs, IEEE Network 33(2) (2019), 72–81.\n[100] X. Ge, S. Tu, G. Mao, C.-X.\
    \ Wang and T. Han, 5G ultra-dense cellular networks, IEEE Wireless Communications\
    \ 23(1) (2016), 72–79.\n278\nM. Kumar and A. Singh / Probabilistic data structures\
    \ in smart city\n[101] General Assembly, United Nations: Transforming our world:\
    \ The 2030 agenda for sustainable development, UN: New York, NY, USA,\n2015.\n\
    [102] A. Gharaibeh, M.A. Salahuddin, S.J. Hussini, A. Khreishah, I. Khalil, M.\
    \ Guizani and A. Al-Fuqaha, Smart cities: A survey on data\nmanagement, security,\
    \ and enabling technologies, IEEE Communications Surveys & Tutorials 19(4) (2017),\
    \ 2456–2501.\n[103] N. Giatrakos, A. Deligiannakis, M. Garofalakis and Y. Kotidis,\
    \ Omnibus outlier detection in sensor networks using windowed locality\nsensitive\
    \ hashing, Future Generation Computer Systems 110 (2020), 587–609.\n[104] A. Gionis,\
    \ P. Indyk, R. Motwani et al., Similarity search in high dimensions via hashing,\
    \ in: Vldb, Vol. 99, 1999, pp. 518–529.\n[105] S. Giordano, I. Seitanidis, M.\
    \ Ojo, D. Adami and F. Vignoli, IoT solutions for crop protection against wild\
    \ animal attacks, in: 2018 IEEE\nInternational Conference on Environmental Engineering\
    \ (EE), IEEE, 2018, pp. 1–5.\n[106] GlobalData Thematic Research, History of smart\
    \ cities: Timeline, 2020, https://www.verdict.co.uk/smart-cities-timeline/.\n\
    [107] T. Goldman and R. Gorham, Sustainable urban transport: Four innovative directions,\
    \ Technology in society 28(1–2) (2006), 261–273.\n[108] F. Gong, X. Sun, J. Lin\
    \ and X. Gu, Primary exploration in establishment of China’s intelligent medical\
    \ treatment, Modern Hospital\nManagement 11(2) (2013), 28–29.\n[109] A. Goyal,\
    \ A. Swaminathan, R. Pande and V. Attar, Cross platform (RDBMS to NoSQL) database\
    \ validation tool using bloom ﬁlter, in:\n2016 International Conference on Recent\
    \ Trends in Information Technology (ICRTIT), IEEE, 2016, pp. 1–5.\n[110] S. Grid,\
    \ Smart grid, IEEE Transactions on 1(3) (2009), 253–260.\n[111] A. Gulati, G.S.\
    \ Aujla, N. Kumar, S. Garg and G. Kaddoum, Software-deﬁned content dissemination\
    \ scheme for Internet of healthcare\nvehicles in COVID-like scenarios, IEEE Internet\
    \ of Things Magazine 4(3) (2021), 34–40.\n[112] R. Gupta, A. Kumari, S. Tanwar\
    \ and N. Kumar, Blockchain-envisioned softwarized multi-swarming uavs to tackle\
    \ Covid-19 situations,\nIEEE Network 35(2) (2020), 160–167.\n[113] R. Gupta, S.\
    \ Tanwar, S. Tyagi and N. Kumar, Tactile-Internet-based telesurgery system for\
    \ healthcare 4.0: An architecture, research\nchallenges, and future directions,\
    \ IEEE Network 33(6) (2019), 22–29.\n[114] C. Hamlin and P. Sidley, Revolutions\
    \ in public health: 1848, and 1998?, Bmj 317(7158) (1998), 587–591.\n[115] M.M.\
    \ Haque, H.C. Chin and A.K. Debnath, Sustainable, safe, smart – three key elements\
    \ of Singapore’s evolving transport policies,\nTransport Policy 27 (2013), 20–31.\n\
    [116] M. Harris, Secretive Alphabet division funded by Google aims to ﬁx public\
    \ transit in US, The Guardian 27 (2016).\n[117] I.A.T. Hashem, V. Chang, N.B.\
    \ Anuar, K. Adewole, I. Yaqoob, A. Gani, E. Ahmed and H. Chiroma, The role of\
    \ big data in smart city,\nInternational Journal of information management 36(5)\
    \ (2016), 748–758.\n[118] G. Hegde and N. Hegde, Signiﬁcance of big data frameworks\
    \ and speculative approaches in healthcare systems, International Journal of\n\
    Advanced Networking and Applications 12(6) (2021), 4787–4792.\n[119] M. Hosseini,\
    \ H. McNairn, S. Mitchell, A. Davidson and L.D. Robertson, Comparison of machine\
    \ learning algorithms and water cloud\nmodel for leaf area index estimation over\
    \ corn ﬁelds, in: IGARSS 2019–2019 IEEE International Geoscience and Remote Sensing\
    \ Sympo-\nsium, IEEE, 2019, pp. 6267–6270.\n[120] D.A. Hounshell, The development\
    \ of manufacturing technology in the United States, 1984.\n[121] M.T.A. Hua*,\
    \ Promises and threats: iN2015 Masterplan to pervasive computing in Singapore,\
    \ Science, Technology and Society 17(1)\n(2012), 37–56.\n[122] G. Idoje, T. Dagiuklas\
    \ and M. Iqbal, Survey for smart farming technologies: Challenges and issues,\
    \ Computers & Electrical Engineering\n92 (2021), 107104.\n[123] P. Indyk and R.\
    \ Motwani, Approximate nearest neighbors: Towards removing the curse of dimensionality,\
    \ in: Proceedings of the Thirtieth\nAnnual ACM Symposium on Theory of Computing,\
    \ 1998, pp. 604–613.\n[124] IS Group and Others, Managing big data for smart grids\
    \ and smart meters, IBM Corporation, whitepaper (May 2012), 2012.\n[125] A. Islam\
    \ and S.Y. Shin, BHMUS: Blockchain based secure outdoor health monitoring scheme\
    \ using UAV in smart city, in: 2019 7th\nInternational Conference on Information\
    \ and Communication Technology (ICoICT), IEEE, 2019, pp. 1–6.\n[126] E. Ismagilova,\
    \ L. Hughes, Y.K. Dwivedi and K.R. Raman, Smart cities: Advances in research –\
    \ an information systems perspective,\nInternational Journal of Information Management\
    \ 47 (2019), 88–100.\n[127] A.R. Jadad and M.W. Enkin, Computers: Transcending\
    \ our limits?, BMJ 334(suppl 1) (2007), s8–s8.\n[128] D. Jalal and T. Ezzedine,\
    \ Toward a smart real time monitoring system for drinking water based on machine\
    \ learning, in: 2019 International\nConference on Software, Telecommunications\
    \ and Computer Networks (SoftCOM), IEEE, 2019, pp. 1–5.\n[129] N.A. Jasim, H.\
    \ Th and S.A. Rikabi, Design and Implementation of Smart City Applications Based\
    \ on the Internet of Things, International\nJournal of Interactive Mobile Technologies\
    \ 15(13) (2021).\n[130] E.M. Jovanovska and D. Davcev, No pollution smart city\
    \ sightseeing based on WSN monitoring system, in: 2020 Sixth International\nConference\
    \ on Mobile and Secure Services (MobiSecServ), IEEE, 2020, pp. 1–6.\n[131] J.\
    \ Jull, The second industrial revolution. The history of a concept, Rivista internazionale\
    \ di storia della storiograﬁa (1999), 81–90.\n[132] C. Kalalas and J. Alonso-Zarate,\
    \ Lightweight and space-efﬁcient vehicle authentication based on Cuckoo ﬁlter,\
    \ in: 2020 IEEE 3rd 5G\nWorld Forum (5GWF), IEEE, 2020, pp. 139–144.\n[133] J.\
    \ Kalliovaara, R. Ekman, J. Paavola, T. Jokela, J. Hallio, J. Auranen, P. Talmola\
    \ and H. Kokkinen, Designing a testbed infrastructure\nfor experimental validation\
    \ and trialing of 5G vertical applications, in: International Conference on Cognitive\
    \ Radio Oriented Wireless\nNetworks, Springer, 2017, pp. 247–263.\n[134] P. Kamalakannan,\
    \ M. Balaji, A. Avinash, S. Keerthana and R. Mangayarkarasi, Automated toll collection\
    \ with complex security system,\nin: 2010 2nd International Conference on Education\
    \ Technology and Computer, Vol. 4, IEEE, 2010, pp. V4–356.\nM. Kumar and A. Singh\
    \ / Probabilistic data structures in smart city\n279\n[135] M. Kankaanranta and\
    \ T. Mäkelä, Valuation of emerging learning solutions, in: EdMedia+ Innovate Learning,\
    \ Association for the Ad-\nvancement of Computing in Education (AACE), 2014, pp.\
    \ 168–172.\n[136] I. Katsov, Probabilistic Data Structures For Web Analytics And\
    \ Data Mining, 2012, https://highlyscalable.wordpress.com/2012/05/01/\nprobabilistic-structures-web-analytics-data-mining/\
    \ (cit. on p. 62) (2016).\n[137] S. Katyara, M.A. Shah, S. Zardari, B.S. Chowdhry\
    \ and W. Kumar, WSN based smart control and remote ﬁeld monitoring of Pakistan’s\n\
    irrigation system using SCADA applications, Wireless Personal Communications 95(2)\
    \ (2017), 491–504.\n[138] R.L. Kelly, Hunter-gatherer mobility strategies, Journal\
    \ of anthropological research 39(3) (1983), 277–306.\n[139] H. Kendig, Cluster\
    \ analysis to classify residential areas: A Los Angeles application, Journal of\
    \ the American Institute of Planners 42(3)\n(1976), 286–294.\n[140] A. Khan, S.\
    \ Aslam, K. Aurangzeb, M. Alhussein and N. Javaid, Multiscale modeling in smart\
    \ cities: A survey on applications, current\ntrends, and challenges, Sustainable\
    \ Cities and Society (2021), 103517.\n[141] L.U. Khan, I. Yaqoob, M. Imran, Z.\
    \ Han and C.S. Hong, 6G wireless systems: A vision, architectural elements, and\
    \ future directions,\nIEEE Access 8 (2020), 147029–147044.\n[142] H. Kim, H. Choi,\
    \ H. Kang, J. An, S. Yeom and T. Hong, A systematic review of the smart energy\
    \ conservation system: From smart homes\nto sustainable smart cities, Renewable\
    \ and Sustainable Energy Reviews 140 (2021), 110755.\n[143] N. Komninos, M. Pallot\
    \ and H. Schaffers, Special issue on smart cities and the future Internet in Europe,\
    \ Journal of the knowledge\neconomy 4(2) (2013), 119–134.\n[144] R.B. Kozma, National\
    \ policies that connect ICT-based education reform to economic and social development,\
    \ Human Technology: An\ninterdisciplinary journal on humans in ICT environments\
    \ (2005).\n[145] S. Kulkarni, Streaming Data Analysis: Research and models (2020).\n\
    [146] A. Kumar and J.S. Rattan, A journey from conventional cities to smart cities,\
    \ in: Smart Cities and Construction Technologies, IntechOpen,\n2020.\n[147] N.\
    \ Kumar, S. Misra, J.J. Rodrigues and M.S. Obaidat, Coalition games for spatio-temporal\
    \ big data in Internet of vehicles environment:\nA comparative analysis, IEEE\
    \ Internet of Things Journal 2(4) (2015), 310–320.\n[148] S. Kumar, G. Chowdhary,\
    \ V. Udutalapally, D. Das and S.P. Mohanty, GCrop: Internet-of-Leaf-Things (IoLT)\
    \ for monitoring of the growth\nof crops in smart agriculture, in: 2019 IEEE International\
    \ Symposium on Smart Electronic Systems (iSES)(Formerly iNiS), IEEE, 2019,\npp.\
    \ 53–56.\n[149] S. Kumar, G. Mahesh and C.K. Marigowda, Threats in IoT supply\
    \ chain, in: Internet of Things, Threats, Landscape, and Countermeasures,\nCRC\
    \ Press, 2021, pp. 167–200.\n[150] A. Kumari, R. Gupta and S. Tanwar, Amalgamation\
    \ of blockchain and IoT for smart cities underlying 6G communication: A comprehen-\n\
    sive review, Computer Communications (2021).\n[151] A. Kumari, S. Tanwar, S. Tyagi,\
    \ N. Kumar, M. Maasberg and K.-K.R. Choo, Multimedia big data computing and Internet\
    \ of Things\napplications: A taxonomy and process model, Journal of Network and\
    \ Computer Applications 124 (2018), 169–195.\n[152] H.-Y. Kung, T.-H. Kuo, C.-H.\
    \ Chen and P.-Y. Tsai, Accuracy analysis mechanism for agriculture data using\
    \ the ensemble neural network\nmethod, Sustainability 8(8) (2016), 735.\n[153]\
    \ C.-K. Lee, J. Lee, P.-W. Lo, H.-L. Tang, W.-H. Hsiao, J.-Y. Liu and T.-L. Lin,\
    \ Taiwan perspective: Developing smart living technology,\nInternational Journal\
    \ of Automation and Smart Technology 1(1) (2011), 93–106.\n[154] V. Leithardt,\
    \ Performance and Security Evaluation on a Blockchain Architecture for License\
    \ Plate Recognition Systems, Applied Sciences\n(2021).\n[155] C. Leyh, S. Martin\
    \ and T. Schäffer, Industry 4.0 and lean production – a matching relationship?\
    \ An analysis of selected Industry 4.0\nmodels, in: 2017 Federated Conference\
    \ on Computer Science and Information Systems (FedCSIS), IEEE, 2017, pp. 989–993.\n\
    [156] C. Li, Z. Dai, X. Liu and W. Sun, Evaluation system: Evaluation of smart\
    \ city shareable framework and its applications in China, Sustain-\nability 12(7)\
    \ (2020), 2957.\n[157] C. Li, X. Liu, Z. Dai and Z. Zhao, Smart city: A shareable\
    \ framework and its applications in China, Sustainability 11(16) (2019), 4346.\n\
    [158] G. Li, Y. Liu and Y. Wang, Analysis of the count-min sketch based anomaly\
    \ detection scheme in WSN, in: 2014 IEEE 13th International\nConference on Trust,\
    \ Security and Privacy in Computing and Communications, IEEE, 2014, pp. 961–966.\n\
    [159] S. Li, L. Da Xu and S. Zhao, The Internet of things: A survey, Information\
    \ Systems Frontiers 17(2) (2015), 243–259.\n[160] Y. Li, X. Wang, Z. Zhao, S.\
    \ Han and Z. Liu, Lagoon water quality monitoring based on digital image analysis\
    \ and machine learning\nestimators, Water research 172 (2020), 115471.\n[161]\
    \ D. Liu, Y. Zhang, D. Jia, Q. Zhang, X. Zhao and H. Rong, Toward secure distributed\
    \ data storage with error locating in blockchain enabled\nedge computing, Computer\
    \ Standards & Interfaces 79 (2022), 103560.\n[162] H. Liu, X. Yao, T. Yang and\
    \ H. Ning, Cooperative privacy preservation for wearable devices in hybrid computing-based\
    \ smart health,\nIEEE Internet of Things Journal 6(2) (2018), 1352–1362.\n[163]\
    \ J. Liu, Y. Zhang and X. Qian, Modeling chlorophyll-a in Taihu Lake with machine\
    \ learning models, in: 2009 3rd International Conference\non Bioinformatics and\
    \ Biomedical Engineering, IEEE, 2009, pp. 1–6.\n[164] L. Liu, R. Wang, C. Xie,\
    \ P. Yang, S. Sudirman, F. Wang and R. Li, Deep learning based automatic approach\
    \ using hybrid global and local\nactivated features towards large-scale multi-class\
    \ pest monitoring, in: 2019 IEEE 17th International Conference on Industrial Informatics\n\
    (INDIN), Vol. 1, IEEE, 2019, pp. 1507–1510.\n[165] L. Liu and Y. Zhang, Smart\
    \ environment design planning for smart city based on deep learning, Sustainable\
    \ Energy Technologies and\nAssessments 47 (2021), 101425.\n[166] S. London, A\
    \ Smarter London Together: Listening Exercise for a new Smart London Plan, Retrieved\
    \ June 15, 2018.\n280\nM. Kumar and A. Singh / Probabilistic data structures in\
    \ smart city\n[167] J. Lorinc, A Mess on the Sidewalk, The Bafﬂer (2019), 6–16.\n\
    [168] H. Lund, P.A. Østergaard, D. Connolly and B.V. Mathiesen, Smart energy and\
    \ smart energy systems, Energy 137 (2017), 556–565.\n[169] L. Ma, N. Liu, L. Wang,\
    \ J. Zhang, J. Lei, Z. Zeng, C. Wang and M. Cheng, Multi-party energy management\
    \ for smart building cluster\nwith PV systems using automatic demand response,\
    \ Energy and Buildings 121 (2016), 11–21.\n[170] G.D. Maayan, Signiﬁcance of Big\
    \ Data in Smart City, 2020.\n[171] J.P. Mackenbach, Sanitation: Pragmatism works,\
    \ Bmj 334(suppl 1) (2007), s17–s17.\n[172] H.H. Mahmoud, W. Wu and Y. Wang, WDSchain:\
    \ A toolbox for enhancing the security using blockchain technology in water distribution\n\
    system, Water 13(14) (2021), 1944.\n[173] H.H.M. Mahmoud, W. Wu and Y. Wang, Secure\
    \ data aggregation mechanism for water distribution system using blockchain, in:\
    \ 2019\n25th International Conference on Automation and Computing (ICAC), IEEE,\
    \ 2019, pp. 1–6.\n[174] V. Makrygianni, Privacy on smart cities, Master’s thesis,\
    \ \x04ανεπιστ ´ημιo \x04ειραι ´ως, 2021.\n[175] S. Malleswari and T.K. Mohana,\
    \ Air pollution monitoring system using IoT devices, Materials Today: Proceedings\
    \ (2021).\n[176] G. Maria, E. Baccaglini, D. Brevi, M. Gavelli and R. Scopigno,\
    \ A drone-based image processing system for car detection in a smart\ntransport\
    \ infrastructure, in: 2016 18th Mediterranean Electrotechnical Conference (MELECON),\
    \ IEEE, 2016, pp. 1–5.\n[177] V. Marinakis, H. Doukas, J. Tsapelas, S. Mouzakitis,\
    \ Á. Sicilia, L. Madrazo and S. Sgouridis, From big data to smart energy services:\
    \ An\napplication for intelligent energy management, Future Generation Computer\
    \ Systems 110 (2020), 572–586.\n[178] C. Martin, J. Evans, A. Karvonen, K. Paskaleva,\
    \ D. Yang and T. Linjordet, Smart-sustainability: A new urban ﬁx?, Sustainable\
    \ cities and\nsociety 45 (2019), 640–648.\n[179] Y. Masuda, The Information Society\
    \ as Post-Industrial Society, World Future Society, 1981.\n[180] S. Mazur, An\
    \ introduction to smart transportation: Beneﬁts and examples, Digi International\
    \ 9 (2020), 2020.\n[181] D.N. Mekuria, P. Sernani, N. Falcionelli and A.F. Dragoni,\
    \ Smart home reasoning systems: A systematic literature review, Journal of\nAmbient\
    \ Intelligence and Humanized Computing 12(4) (2021), 4485–4502.\n[182] S. Mellouli,\
    \ L.F. Luna-Reyes and J. Zhang, Smart government, citizen participation and open\
    \ data, Information Polity 19(1, 2) (2014),\n1–4.\n[183] Ministry of Housing and\
    \ Urban Affairs (MoHUA), Smart City, 2021.\n[184] D. Minoli, K. Sohraby and B.\
    \ Occhiogrosso, IoT considerations, requirements, and architectures for smart\
    \ buildings – energy optimization\nand next-generation building management systems,\
    \ IEEE Internet of Things Journal 4(1) (2017), 269–283.\n[185] MIT Technology\
    \ Review, What Uber’s fatal accident could mean for the autonomous-car industry,\
    \ 2018, 2019.\n[186] B. Mohanta, P. Das and S. Patnaik, Healthcare 5.0: A paradigm\
    \ shift in digital healthcare system using artiﬁcial intelligence, IOT and 5G\n\
    communication, in: 2019 International Conference on Applied Machine Learning (ICAML),\
    \ IEEE, 2019, pp. 191–196.\n[187] A. Molderink, V. Bakker, M.G. Bosman, J.L. Hurink\
    \ and G.J. Smit, Management and control of domestic smart grid technology, IEEE\n\
    transactions on Smart Grid 1(2) (2010), 109–119.\n[188] K. Moslehi and R. Kumar,\
    \ A reliability perspective of the smart grid, IEEE transactions on smart grid\
    \ 1(1) (2010), 57–64.\n[189] R. Moss Kanter and S.S. Litow, Informed and interconnected:\
    \ A manifesto for smarter cities, Harvard Business School General Manage-\nment\
    \ Unit Working Paper 09-141, 2009.\n[190] B. Motyl, G. Baronio, S. Uberti, D.\
    \ Speranza and S. Filippi, How will change the future engineers’ skills in the\
    \ Industry 4.0 framework?\nA questionnaire survey, Procedia manufacturing 11 (2017),\
    \ 1501–1509.\n[191] P. Mukherjee, R.K. Barik and C. Pradhan, Agrochain: Ascending\
    \ blockchain technology towards smart agriculture, in: Advances in\nSystems, Control\
    \ and Automations: Select Proceedings of ETAEERE 2020, Springer Singapore, 2021,\
    \ pp. 53–60.\n[192] C.E. Mulligan and M. Olsson, Architectural implications of\
    \ smart city business models: An evolutionary perspective, IEEE Communica-\ntions\
    \ Magazine 51(6) (2013), 80–85.\n[193] S. Muntone, Second industrial revolution,\
    \ Education.com, The McGraw-Hill Companies, Retrieved 14 (2013).\n[194] N. Myers,\
    \ Environmental refugees in a globally warmed world, Bioscience 43(11) (1993),\
    \ 752–761.\n[195] B. Nathali Silva, M. Khan and K. Han, Big data analytics embedded\
    \ smart city architecture for performance enhancement through real-\ntime data\
    \ processing and decision-making, Wireless communications and mobile computing\
    \ 2017 (2017).\n[196] A. Nayyar and V. Puri, Smart farming: IoT based smart sensors\
    \ agriculture stick for live temperature and moisture monitoring using\nArduino,\
    \ cloud computing & solar technology, in: Proc. of the International Conference\
    \ on Communication and Computing Systems\n(ICCCS-2016), 2016, pp. 9781315364094–121.\n\
    [197] NEC Display Solution United Kingdom, NEC’s Smart Energy Vision, 2021.\n\
    [198] J. Ni, X. Lin and X. Shen, Toward privacy-preserving valet parking in autonomous\
    \ driving era, IEEE Transactions on Vehicular Technology\n68(3) (2019), 2893–2905.\n\
    [199] J. Ni, K. Zhang and A.V. Vasilakos, Security and privacy for mobile edge\
    \ caching: Challenges and solutions, IEEE Wireless Communica-\ntions (2020).\n\
    [200] X. Nie, A. Zhang, J. Chen, Y. Qu and S. Yu, Blockchain-Empowered Secure\
    \ and Privacy-Preserving Health Data Sharing in Edge-Based\nIoMT, Security and\
    \ Communication Networks 2022 (2022).\n[201] F. Nikitin, Bloom ﬁlters and their\
    \ applications, in: IEEE, Vol. 11, Citeseer, 2006.\n[202] R. Novotny, R. Kuchta\
    \ and J. Kadlec, Smart city concept, applications and services, Journal of Telecommunications\
    \ System & Management\n3(2) (2014), 1–5.\n[203] S. Nowaczyk, A. Resmini, V. Long,\
    \ V. Fors, M. Cooney, E.K. Duarte, S. Pink, E.E. Aksoy, A. Vinel and M. Dougherty,\
    \ Smaller is smarter:\nA case for small to medium-sized smart cities, Journal\
    \ of Smart Cities and Society (2022), 1–23.\nM. Kumar and A. Singh / Probabilistic\
    \ data structures in smart city\n281\n[204] W. Onnom, N. Tripathi, V. Nitivattananon\
    \ and S. Ninsawat, Development of a liveable city index (LCI) using multi criteria\
    \ geospatial\nmodelling for medium class cities in developing countries, Sustainability\
    \ 10(2) (2018), 520.\n[205] S. Paiva, M.A. Ahad, G. Tripathi, N. Feroz and G.\
    \ Casalino, Enabling technologies for urban smart mobility: Recent trends, opportunities\n\
    and challenges, Sensors 21(6) (2021), 2143.\n[206] S.J. Palmisano, A smarter planet:\
    \ The next leadership agenda, IBM 6 (2008), 1–8.\n[207] F. Pan, Constructing a\
    \ research service system for the diagnosis and treatment of rare diseases in\
    \ China-Interview with Prof Zhang Yuyang,\nVice President of Peking Union Medical\
    \ College Hospital, China Medical Herald 16 (2019), 1–3, Cited By: 2, www.scopus.com.\n\
    [208] Z. Pang, K. Jia and J. Feng, A water environment security monitoring algorithm\
    \ based on intelligent video surveillance, in: 2014 Tenth\nInternational Conference\
    \ on Intelligent Information Hiding and Multimedia Signal Processing, IEEE, 2014,\
    \ pp. 191–194.\n[209] P. Parycek, J. Höchtl and M. Ginner, Open government data\
    \ implementation evaluation, Journal of theoretical and applied electronic\ncommerce\
    \ research 9(2) (2014), 80–99.\n[210] A. Pathak, M. AmazUddin, M.J. Abedin, K.\
    \ Andersson, R. Mustafa and M.S. Hossain, IoT based smart system to support agricultural\n\
    parameters: A case study, Procedia Computer Science 155 (2019), 648–653.\n[211]\
    \ B. Peng and L. Liu, Query optimization for air quality big data based on hive-ORC,\
    \ in: 2020 5th International Conference on Control,\nRobotics and Cybernetics\
    \ (CRC), IEEE, 2020, pp. 19–23.\n[212] F. Peng, S. Tang, B. Zhao and Y. Liu, A\
    \ privacy-preserving data aggregation of mobile crowdsensing based on local differential\
    \ privacy,\nin: Proceedings of the ACM Turing Celebration Conference-China, 2019,\
    \ pp. 1–5.\n[213] M. Peruzzini, F. Grandi and M. Pellicciari, Benchmarking of\
    \ tools for user experience analysis in Industry 4.0, Procedia manufacturing\n\
    11 (2017), 806–813.\n[214] H.C. Peyer, Roche: A Company History, 1896–1996, Editiones\
    \ Roche, 1996.\n[215] A. Piranti, G. Waluyo and D.R. Rahayu, The possibility of\
    \ using Lake Rawa Pening as a source of drinking water, Journal of Water and\n\
    Land Development (2019).\n[216] A.K. Podder, A. Al Bukhari, S. Islam, S. Mia,\
    \ M.A. Mohammed, N.M. Kumar, K. Cengiz and K.H. Abdulkareem, IoT based smart\n\
    agrotech system for veriﬁcation of urban farming parameters, Microprocessors and\
    \ Microsystems 82 (2021), 104025.\n[217] C. Pu and K.-K.R. Choo, Lightweight sybil\
    \ attack detection in IoT based on bloom ﬁlter and physical unclonable function,\
    \ Computers &\nSecurity 113 (2022), 102541.\n[218] X. Qian and X. Wang, Content-Centric\
    \ IoT-Based Air Pollution Monitoring, Wireless Personal Communications (2021),\
    \ 1–10.\n[219] Y. Qin, H.-J. Kwon, M.M. Howlader and M.J. Deen, Microfabricated\
    \ electrochemical pH and free chlorine sensors for water quality\nmonitoring:\
    \ Recent advances and research challenges, RSC advances 5(85) (2015), 69086–69109.\n\
    [220] N.M. Ragi, R. Holla and G. Manju, Predicting water quality parameters using\
    \ machine learning, in: 2019 4th International Conference on\nRecent Trends on\
    \ Electronics, Information, Communication & Technology (RTEICT), IEEE, 2019, pp.\
    \ 1109–1112.\n[221] S.J. Rashid, A. Alkababji and A. Khidhir, Communication and\
    \ network technologies of IoT in smart building: A survey, NTU Journal of\nEngineering\
    \ and Technology 1(1) (2021), 1–18.\n[222] M.M. Rathore, A. Paul, S. Rho, M. Khan,\
    \ S. Vimal and S.A. Shah, Smart trafﬁc control: Identifying driving-violations\
    \ using fog devices\nwith vehicular cameras in smart cities, Sustainable Cities\
    \ and Society 71 (2021), 102986.\n[223] P.P. Ray, N. Kumar and D. Dash, BLWN:\
    \ Blockchain-based lightweight simpliﬁed payment veriﬁcation in IoT-assisted e-healthcare,\
    \ IEEE\nSystems Journal 15(1) (2020), 134–145.\n[224] D. Raynaud and G. Angulo,\
    \ Key Challenges of Smart Cities & How to Overcome Them, 2018.\n[225] G. Reisman,\
    \ Capitalism: A Complete and lntearated Understandino of the Nature and Value\
    \ of Human Economic Life. By George,\nJameson Books Review of Austrian Economics,\
    \ Vol. 10, 1998, pp. 115–132.\n[226] J.A. Rodriguez, F.J. Fernandez and P. Arboleya,\
    \ Study of the architecture of a smart city, in: Multidisciplinary Digital Publishing\
    \ Institute\nProceedings, Vol. 2,23, 2018, p. 1485.\n[227] E. Rommes, E.V. Oost\
    \ and N. Oudshoorn, Gender in the design of the digital city of Amsterdam, Information,\
    \ Communication & Society\n2(4) (1999), 476–495.\n[228] M. Rosemann, J. Becker\
    \ and F. Chasin, City 5.0, Business & Information Systems Engineering 63(1) (2021),\
    \ 71–77.\n[229] A. Saad Al-Sumaiti, M.H. Ahmed and M.M. Salama, Smart home activities:\
    \ A literature review, Electric Power Components and Systems\n42(3–4) (2014),\
    \ 294–305.\n[230] A.K. Saha, J. Saha, R. Ray, S. Sircar, S. Dutta, S.P. Chattopadhyay\
    \ and H.N. Saha, IOT-based drone for improvement of crop qual-\nity in agricultural\
    \ ﬁeld, in: 2018 IEEE 8th Annual Computing and Communication Workshop and Conference\
    \ (CCWC), IEEE, 2018,\npp. 612–615.\n[231] R.A. Salman, L. Myeongbae, L. Jonghyun,\
    \ Y. Cho and S. Changsun, A comparative study of energy big data analysis for\
    \ product man-\nagement in a smart factory, Journal of Organizational and End\
    \ User Computing (JOEUC) 34(2) (2022), 1–17.\n[232] P. Samadi, A.-H. Mohsenian-Rad,\
    \ R. Schober, V.W. Wong and J. Jatskevich, Optimal real-time pricing algorithm\
    \ based on utility maxi-\nmization for smart grid, in: 2010 First IEEE International\
    \ Conference on Smart Grid Communications, IEEE, 2010, pp. 415–420.\n[233] G.\
    \ Santos, H. Behrendt and A. Teytelboym, Part II: Policy instruments for sustainable\
    \ road transport, Research in transportation economics\n28(1) (2010), 46–91.\n\
    [234] M.N.I. Sarker, Y. Bingxin, A. Sultana and A. Prodhan, Problems and challenges\
    \ of public administration in Bangladesh: Pathway to\nsustainable development,\
    \ International Journal of Public Administration and Policy Research 3(1) (2017),\
    \ 16–25.\n[235] L. Sarv and R.-M. Soe, Transition towards smart city: The case\
    \ of tallinn, Sustainability 13(8) (2021), 4143.\n[236] G. Satyanarayana and S.\
    \ Mazaruddin, Wireless sensor based remote monitoring system for agriculture using\
    \ ZigBee and GPS, in: Con-\nference on Advances in Communication and Control Systems,\
    \ Vol. 3, 2013, pp. 237–241.\n282\nM. Kumar and A. Singh / Probabilistic data\
    \ structures in smart city\n[237] K. Schedler, A.A. Guenduez and R. Frischknecht,\
    \ How smart can government be? Discussing the barriers of smart government adoption,\n\
    2017.\n[238] H.J. Scholl and M.C. Scholl, Smart governance: A roadmap for research\
    \ and practice, IConference 2014 Proceedings (2014).\n[239] R. Shahzadi, M. Tausif,\
    \ J. Ferzund and M.A. Suryani, Internet of things based expert system for smart\
    \ agriculture, International Journal\nof Advanced Computer Science and Applications\
    \ 7(9) (2016), 341–350.\n[240] K. Shankar, S. Lakshmanaprabu, A. Khanna, S. Tanwar,\
    \ J.J. Rodrigues and N.R. Roy, Alzheimer detection using group grey wolf opti-\n\
    mization based features with convolutional classiﬁer, Computers & Electrical Engineering\
    \ 77 (2019), 230–243.\n[241] Z. Sheng, S. Yang, Y. Yu, A.V. Vasilakos, J.A. McCann\
    \ and K.K. Leung, A survey on the ietf protocol suite for the Internet of things:\n\
    Standards, challenges, and opportunities, IEEE wireless communications 20(6) (2013),\
    \ 91–98.\n[242] D. Shinde and N. Siddiqui, IOT based environment change monitoring\
    \ & controlling in greenhouse using WSN, in: 2018 International\nConference on\
    \ Information, Communication, Engineering and Technology (ICICET), IEEE, 2018,\
    \ pp. 1–5.\n[243] B.N. Silva, M. Khan and K. Han, Towards sustainable smart cities:\
    \ A review of trends, architectures, components, and open challenges in\nsmart\
    \ cities, Sustainable Cities and Society 38 (2018), 697–713.\n[244] A. Singh and\
    \ S. Batra, A Novel Technique for Efﬁcient Storage and Retrieval of Massive Data\
    \ Sets, PhD thesis, Thapar University Patiala,\n2018.\n[245] A. Singh, S. Batra,\
    \ G.S. Aujla, N. Kumar and L.T. Yang, BloomStore: Dynamic bloom-ﬁlter-based secure\
    \ rule-space management scheme\nin SDN, IEEE Transactions on Industrial Informatics\
    \ 16(10) (2020), 6252–6262.\n[246] A. Singh, S. Garg, R. Kaur, S. Batra, N. Kumar\
    \ and A.Y. Zomaya, Probabilistic data structures for big data analytics: A comprehensive\n\
    review, Knowledge-Based Systems 188 (2020), 104987.\n[247] S.K. Singh, Y. Pan\
    \ and J.H. Park, Blockchain-enabled secure framework for energy-efﬁcient smart\
    \ parking in sustainable city environment,\nSustainable Cities and Society 76\
    \ (2022), 103364.\n[248] V. Singh, I. Srivastava and V. Johri, Big data and the\
    \ opportunities and challenges for government agencies, International Journal\
    \ of\nComputer Science and Information Technologies 5(4) (2014), 5821–5824.\n\
    [249] B.B. Sinha and R. Dhanalakshmi, Recent advancements and challenges of Internet\
    \ of Things in smart agriculture: A survey, Future\nGeneration Computer Systems\
    \ 126 (2022), 169–184.\n[250] N. Sinha, Emerging technology trends in vehicle-to-everything\
    \ connectivity, in: 2019 Wireless Telecommunications Symposium (WTS),\nIEEE, 2019,\
    \ pp. 1–12.\n[251] Smart Cities Team, Smart City 3.0, 2018, https://www.arcweb.com/blog/smart-city-30-building-compelling-smart-city-business-cases.\n\
    [252] S.A. Soleymani, S. Goudarzi, M.H. Anisi, M. Zareei, A.H. Abdullah and N.\
    \ Kama, A security and privacy scheme based on node and\nmessage authentication\
    \ and trust in fog-enabled VANET, Vehicular Communications 29 (2021), 100335.\n\
    [253] W. Song, B. Wang, Q. Wang, Z. Peng, W. Lou and Y. Cui, A privacy-preserved\
    \ full-text retrieval algorithm over encrypted data for cloud\nstorage applications,\
    \ Journal of Parallel and Distributed Computing 99 (2017), 14–27.\n[254] P.N.\
    \ Stearns, The social impact of the industrial revolution, in: The Industrial\
    \ Revolution in World History, Routledge, 2018, pp. 69–88.\n[255] J. Stokes, Inside\
    \ the Machine: An Illustrated Introduction to Microprocessors and Computer Architecture,\
    \ No Starch Press, 2007.\n[256] M.V. Storey, B. Van der Gaag and B.P. Burns, Advances\
    \ in on-line drinking water quality monitoring and early warning systems, Water\n\
    research 45(2) (2011), 741–747.\n[257] N. Streitz, D. Charitos, M. Kaptein and\
    \ M. Böhlen, Grand challenges for ambient intelligence and implications for design\
    \ contexts and\nsmart societies, Journal of Ambient Intelligence and Smart Environments\
    \ 11(1) (2019), 87–107.\n[258] J. Stübinger and L. Schneider, Understanding smart\
    \ city – a data-driven literature review, Sustainability 12(20) (2020), 8460.\n\
    [259] Y. Su, Y. Li, Q. Cao and Z. Wu, Authorized Certiﬁcateless Conjunctive Keyword\
    \ Search on Encrypted EHRs from WSNs, Journal of\nInformation Science & Engineering\
    \ 36(4) (2020).\n[260] Y. Su, J. Wang, Y. Wang and M. Miao, Efﬁcient veriﬁable\
    \ multi-key searchable encryption in cloud computing, IEEE Access 7 (2019),\n\
    141352–141362.\n[261] J. Sun, M. Gao, Q. Wang, M. Jiang, X. Zhang and R. Schmitt,\
    \ Smart services for enhancing personal competence in industrie 4.0 digital\n\
    factory, Logforum 14(1) (2018).\n[262] Q. Sun, H. Li, Z. Ma, C. Wang, J. Campillo,\
    \ Q. Zhang, F. Wallin and J. Guo, A comprehensive review of smart energy meters\
    \ in intelligent\nenergy networks, IEEE Internet of Things Journal 3(4) (2015),\
    \ 464–479.\n[263] B. Surya, F. Menne, H. Sabhan, S. Suriani, H. Abubakar and M.\
    \ Idris, Economic growth, increasing productivity of SMEs, and open\ninnovation,\
    \ Journal of Open Innovation: Technology, Market, and Complexity 7(1) (2021),\
    \ 20.\n[264] M. Svítek, P. Skobelev and S. Kozhevnikov, Smart city 5.0 as an urban\
    \ ecosystem of smart services, in: International Workshop on Service\nOrientation\
    \ in Holonic and Multi-Agent Manufacturing, Springer, 2019, pp. 426–438.\n[265]\
    \ P. Szarek-Iwaniuk and A. Senetra, Access to ICT in Poland and the co-creation\
    \ of urban space in the process of modern social participation\nin a smart city\
    \ – a case study, Sustainability 12(5) (2020), 2136.\n[266] M.A.U.R. Tariq, A.\
    \ Faumatu, M. Hussein, M.L.U.R. Shahid and N. Muttil, Smart city-ranking of major\
    \ Australian cities to achieve a\nsmarter future, Sustainability 12(7) (2020),\
    \ 2797.\n[267] P. Taylor, GIS and geography, Ground truth: The social implications\
    \ of geographic information systems (1995), 51–67.\n[268] C. Thorne and C. Grifﬁths,\
    \ Smart, smarter, smartest: Redeﬁning our cities, in: Smart City, Springer, 2014,\
    \ pp. 89–99.\n[269] S. Tian, W. Yang, J.M. Le Grange, P. Wang, W. Huang and Z.\
    \ Ye, Smart healthcare: Making medical care more intelligent, Global Health\n\
    Journal 3(3) (2019), 62–65.\n[270] J.T. Tong, Finance and Society in 21st Century\
    \ China: Chinese Culture Versus Western Markets, Routledge, 2016.\n[271] H.-L.\
    \ Truong and S. Dustdar, Principles for engineering IoT cloud systems, IEEE Cloud\
    \ Computing 2(2) (2015), 68–76.\nM. Kumar and A. Singh / Probabilistic data structures\
    \ in smart city\n283\n[272] J. Tupa, J. Simota and F. Steiner, Aspects of risk\
    \ management implementation for Industry 4.0, Procedia manufacturing 11 (2017),\n\
    1223–1230.\n[273] S.L. Ullo and G. Sinha, Advances in smart environment monitoring\
    \ systems using IoT and sensors, Sensors 20(11) (2020), 3113.\n[274] United Nations,\
    \ World urbanization prospects: The 2007 revision population database, United\
    \ Nations New York, 2007.\n[275] United Nations, World urbanization prospects:\
    \ The 2014 revision, highlights, Department of Economic and Social Affairs, 2014.\n\
    [276] H. van den Bosch, Smart City Hub, 2017, https://smartcityhub.com/collaborative-city/smart-cities-1-0-2-0-3-0-whats-next/.\n\
    [277] D. Vatsalan, P. Christen and V.S. Verykios, A taxonomy of privacy-preserving\
    \ record linkage techniques, Information Systems 38(6)\n(2013), 946–969.\n[278]\
    \ N.J. Vickers, Animal communication: When I’m calling you, will you answer too?,\
    \ Current biology 27(14) (2017), R713–R715.\n[279] K. Vinitha, R.A. Prabhu, R.\
    \ Bhaskar and R. Hariharan, Review on industrial mathematics and materials at\
    \ Industry 1.0 to Industry 4.0,\nMaterials Today: Proceedings 33 (2020), 3956–3960.\n\
    [280] L. Vogel, Plan needed to capitalize on robots, AI in health care, Can Med\
    \ Assoc, 2017.\n[281] S. Wadekar, V. Vakare, R. Prajapati, S. Yadav and V. Yadav,\
    \ Smart water management using IOT, in: 2016 5th International Conference\non\
    \ Wireless Networks and Embedded Systems (WECON), IEEE, 2016, pp. 1–4.\n[282]\
    \ B. Wang, S. Yu, W. Lou and Y.T. Hou, Privacy-preserving multi-keyword fuzzy\
    \ search over encrypted data in the cloud, in: IEEE INFO-\nCOM 2014-IEEE Conference\
    \ on Computer Communications, IEEE, 2014, pp. 2112–2120.\n[283] K. Wang, C.-M.\
    \ Chen, Z. Tie, M. Shojafar, S. Kumar and S. Kumari, Forward Privacy Preservation\
    \ in IoT enabled Healthcare Systems,\nIEEE Transactions on Industrial Informatics\
    \ (2021).\n[284] Y. Wen, S. Zhang, J. Zhang, S. Bao, X. Wu, D. Yang and Y. Wu,\
    \ Mapping dynamic road emissions for a megacity by using open-access\ntrafﬁc congestion\
    \ index data, Applied Energy 260 (2020), 114357.\n[285] R. Wenge, X. Zhang, C.\
    \ Dave, L. Chao and S. Hao, Smart city architecture: A technology guide for implementation\
    \ and design challenges,\nChina Communications 11(3) (2014), 56–69.\n[286] S.\
    \ Weyer, M. Schmitt, M. Ohmer and D. Gorecky, Towards industry 4.0-standardization\
    \ as the crucial challenge for highly modular,\nmulti-vendor production systems,\
    \ Ifac-Papersonline 48(3) (2015), 579–584.\n[287] Wikipedia, Locality-sensitive\
    \ hashing, 2021.\n[288] B. Windsperger, A. Windsperger, D. Bird, H. Schwaiger,\
    \ G. Jungmeier, C. Nathani and R. Frischknecht, Greenhouse gas emissions due\n\
    to national product consumption: From demand and research gaps to addressing key\
    \ challenges, International Journal of Environmental\nScience and Technology 16(2)\
    \ (2019), 1025–1038.\n[289] J. Won, Smart cities: Toronto’s Google-infused district\
    \ and lessons from Songdo, Korea, Cornell Real Estate Review (2018).\n[290] D.M.\
    \ Wood and D. Mackinnon, Partial platforms and oligoptic surveillance in the smart\
    \ city, Surveillance & Society 17(1/2) (2019),\n176–182.\n[291] E.A. Wrigley,\
    \ Reconsidering the industrial revolution: England and Wales, Journal of Interdisciplinary\
    \ History 49(1) (2018), 9–42.\n[292] Z. Wu, Intelligent City Evaluation System,\
    \ Springer, 2018.\n[293] C. Xu, N. Wang, L. Zhu, K. Sharif and C. Zhang, Achieving\
    \ searchable and privacy-preserving data sharing for cloud-assisted E-healthcare\n\
    system, IEEE Internet of Things Journal 6(5) (2019), 8345–8356.\n[294] M. Xu,\
    \ J.M. David, S.H. Kim et al., The fourth industrial revolution: Opportunities\
    \ and challenges, International journal of ﬁnancial\nresearch 9(2) (2018), 90–95.\n\
    [295] M. Yan and H. Shi, Smart living using bluetooth-based Android smartphone,\
    \ International journal of wireless & mobile networks 5(1)\n(2013), 65.\n[296]\
    \ T. Yigitcanlar, M. Kamruzzaman, M. Foth, J. Sabatini-Marques, E. da Costa and\
    \ G. Ioppolo, Can cities become smart without being\nsustainable? A systematic\
    \ review of the literature, Sustainable cities and society 45 (2019), 348–365.\n\
    [297] E. Yousef, J. Reza and K. Manijeh, An energy efﬁcient and trafﬁc aware data\
    \ fusion scheme for water pollution monitoring, Indian Journal\nof Science and\
    \ Technology 9(15) (2016).\n[298] Y. Yun and M. Lee, Smart city 4.0 from the perspective\
    \ of open innovation, Journal of Open Innovation: Technology, Market, and\nComplexity\
    \ 5(4) (2019), 92.\n[299] L. Zafﬁri, J. Gardner and L.H. Toledo-Pereyra, History\
    \ of antibiotics. From salvarsan to cephalosporins, Journal of Investigative Surgery\n\
    25(2) (2012), 67–77.\n[300] D. Zhang, Z. He, Y. Qian, J. Wan, D. Li and S. Zhao,\
    \ Revisiting unknown RFID tag identiﬁcation in large-scale Internet of things,\
    \ IEEE\nWireless Communications 23(5) (2016), 24–29.\n[301] J. Zhang, Y. Zheng\
    \ and D. Qi, Deep spatio-temporal residual networks for citywide crowd ﬂows prediction,\
    \ in: Thirty-First AAAI Confer-\nence on Artiﬁcial Intelligence, 2017.\n[302]\
    \ M. Zhang, T. Yu and G.F. Zhai, Smart transport system based on “the Internet\
    \ of things”, in: Applied Mechanics and Materials, Vol. 48,\nTrans Tech Publ,\
    \ 2011, pp. 1073–1076.\n[303] T. Zhang, T. Zhang, X. Ji and W. Xu, Cuckoo-RPL:\
    \ Cuckoo ﬁlter based RPL for defending AMI network from blackhole attacks, in:\
    \ 2019\nChinese Control Conference (CCC), IEEE, 2019, pp. 8920–8925.\n[304] J.\
    \ Zhao, Y. Wu, F. Yu and G. Zhan, Risk control and prevention during the smart\
    \ cities’ development, in: 2015 International Conference\non Social Science, Education\
    \ Management and Sports Education, Atlantis Press, 2015, pp. 1535–1538.\n[305]\
    \ Z. Zhao, W. Chen, X. Wu, P.C. Chen and J. Liu, LSTM network: A deep learning\
    \ approach for short-term trafﬁc forecast, IET Intelligent\nTransport Systems\
    \ 11(2) (2017), 68–75.\n[306] D. Zheng, A. Wu, Y. Zhang and Q. Zhao, Efﬁcient\
    \ and privacy-preserving medical data sharing in Internet of Things with limited\
    \ com-\nputing power, IEEE Access 6 (2018), 28019–28027.\n284\nM. Kumar and A.\
    \ Singh / Probabilistic data structures in smart city\n[307] K. Zhou, S. Ding,\
    \ C. Fu and S. Yang, Comparison and weighted summation type of fuzzy cluster validity\
    \ indices, International Journal\nof Computers Communications & Control 9(3) (2014),\
    \ 370–378.\n[308] K. Zhou, C. Fu and S. Yang, Big data driven smart energy management:\
    \ From big data to big insights, Renewable and Sustainable Energy\nReviews 56\
    \ (2016), 215–225.\n[309] K. Zhou and S. Yang, A framework of service-oriented\
    \ operation model of China’s power system, Renewable and Sustainable Energy\n\
    Reviews 50 (2015), 719–725.\n[310] K. Zhou, S. Yang, Z. Chen and S. Ding, Optimal\
    \ load distribution model of microgrid in the smart grid environment, Renewable\
    \ and\nSustainable Energy Reviews 35 (2014), 304–310.\n[311] Z. Zhou and S. Li,\
    \ Peanut planting area change monitoring from remote sensing images based on deep\
    \ learning, in: 2017 4th International\nConference on Systems and Informatics\
    \ (ICSAI), IEEE, 2017, pp. 1358–1362.\n[312] L. Zhu, F.R. Yu, Y. Wang, B. Ning\
    \ and T. Tang, Big data analytics in intelligent transportation systems: A survey,\
    \ IEEE Transactions on\nIntelligent Transportation Systems 20(1) (2018), 383–398.\n\
    [313] Z.-T. Zhu, M.-H. Yu and P. Riezebos, A research framework of smart education,\
    \ Smart learning environments 3(1) (2016), 1–17.\n[314] B. Zong, C. Fan, X. Wang,\
    \ X. Duan, B. Wang and J. Wang, 6G technologies: Key drivers, core requirements,\
    \ system architectures, and\nenabling technologies, IEEE Vehicular Technology\
    \ Magazine 14(3) (2019), 18–27.\n[315] Y. Zou, G. Fettweis, A. Ghosh, G. Ricart,\
    \ M. Latva-Aho and L. Scheuvens, Challenges and Potential for EU–US Collaboration\
    \ in 5G and\nBeyond Networks, ICT Policy, Research, and Innovation: Perspectives\
    \ and Prospects for EU-US Collaboration (2020), 145–164.\n[316] I. Zubizarreta,\
    \ A. Seravalli and S. Arrizabalaga, Smart city concept: What it is and what it\
    \ should be, Journal of Urban Planning and\nDevelopment 142(1) (2016), 04015005.\n\
    [317] Z. Zukarnain, R. Sudin, N. Abdul Rahman and M. Jamaludin, Exploring the\
    \ Potential of Smart City In Kota Bharu, International Journal\nof Engineering\
    \ Trends and Technology (2020), 114–119. doi:10.14445/22315381/CATI1P221.\n"
  inline_citation: '>'
  journal: Journal of Ambient Intelligence and Smart Environments
  limitations: '>'
  pdf_link: https://content.iospress.com:443/download/journal-of-ambient-intelligence-and-smart-environments/ais220101?id=journal-of-ambient-intelligence-and-smart-environments%2Fais220101
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Probabilistic data structures in smart city: Survey, applications, challenges,
    and research directions'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.36227/techrxiv.19642977.v1
  analysis: '>'
  authors:
  - Samir Patel
  - Shubham Vyas
  - Pallabi Saikia
  - Denish kalariya
  - naman parmar
  citation_count: 2
  full_citation: '>'
  full_text: '>

    LOG IN SIGN UP TechRxiv 9,104,714 views 4,234,902 downloads About TechRxiv TechRxiv
    (pronounced "tech archive") is an open, moderated preprint server for unpublished
    research in the areas of engineering, computer science, and related technology.
    https://www.techrxiv.org/ Public Documents 9033 Members by author by title by
    keyword Filter All Sort by Most Recent BIOENGINEERING 865 COMMUNICATION, NETWORKING
    AND BROADCAST TECHNOLOGIES 2267 COMPONENTS, CIRCUITS, DEVICES AND SYSTEMS 1058
    COMPUTING AND PROCESSING 3333 ENGINEERED MATERIALS, DIELECTRICS AND PLASMAS 246
    ENGINEERING PROFESSION 541 FIELDS, WAVES AND ELECTROMAGNETICS 845 GENERAL TOPICS
    FOR ENGINEERS 643 GEOSCIENCE 265 NUCLEAR ENGINEERING 69 PHOTONICS AND ELECTROOPTICS
    342 POWER, ENERGY AND INDUSTRY APPLICATIONS 1192 ROBOTICS AND CONTROL SYSTEMS
    874 TRANSPORTATION 382 AEROSPACE 264 SIGNAL PROCESSING AND ANALYSIS 1935 OOC ADC:
    A Novel Three-Step Technique for Analog-to-Digital Conversion Guo-Liu Zhang March
    22, 2024 This paper explore the Off-on Cycle ADC (OOC ADC), an innovative analog-to-digital
    conversion (ADC) technique that significantly simplifies the analog-to-digital
    conversion process by accomplishing it through just three steps: inputting the
    analog signal, triggering the probe’s dip-and-reset motion (PDR), and outputting
    the binary digital signal. Initially, the paper establishes a theoretical foundation
    for subsequent ADC design by introducing the Off-on Cycle principle (OOC principle)
    in binary encoding rules. Subsequently, it illustrates the design concepts and
    operational principles of the OOC ADC through the illustrative example of a 4-bit
    precision OOC ADC design. Finally, the paper compares the superior performance
    of the OOC ADC over existing ADCs in terms of conversion rate, resolution, process
    complexity, and power consumption. The research findings in this paper have the
    potential to drastically reduce the technical difficulties involved in analog-to-digital
    conversion, facilitate technological advancements in the realm of digital signal
    processing. Smooth Scenario-Based Model Predictive Control for Autonomous Collision
    Avoidance in... Dhanika Mahipala and 1 more March 25, 2024 The Scenario-Based
    Model Predictive Control (SB-MPC) is an autonomous collision avoidance algorithm
    primarily designed for open and coastal waters. One of the challenges in adapting
    SB-MPC for autonomous inland waterway collision avoidance is the inability to
    use a derivative based optimization strategy due to non-smooth components in its
    cost function. Hence, we propose a novel algorithm, Smooth Scenario-Based Model
    Predictive Control (Smooth-SBMPC) specifically designed for highly constrained
    and complex navigational environments inherent to inland waterways. The effectiveness
    of Smooth-SBMPC is validated through a comprehensive simulation study, providing
    insights into its performance in complex navigational environments. Geometrical
    Pruning of the First Order Regular Perturbation Kernels of the Manakov Eq... Astrid
    Barreiro and 2 more March 25, 2024 We propose an approach for constraining the
    set of nonlinear coefficients of the conventional first-order regular perturbation
    (FRP) model of the Manakov Equation. We identify the largest contributions in
    the FRP model and provide geometrical insights into the distribution of their
    magnitudes in a three-dimensional space. As a result, a multi-plane hyperbolic
    constraint is introduced. A closed-form upper bound on the constrained set of
    nonlinear coefficients is given. We also report on the performance characterization
    of the FRP with multiplane hyperbolic constraint and show that it reduces the
    overall complexity with minimal penalties in accuracy. For a 120 km standard single-mode
    fiber transmission, at 60 Gbaud with DP-16QAM, a complexity reduction of 93% is
    achieved with a performance penalty below 0.1 dB. Dynamic Selection of Physical
    Channels for Adaptive Improvement of Link Quality Using... Ryan S. Westafer and
    3 more March 25, 2024 This paper describes integration of a software defined antenna
    (SDA) and a software defined radio (SDR) to enable dynamic and automatic selection
    of physical propagation channels. The SDA, an agile aperture antenna (A3), provides
    monolithic microdiversity, i.e. multiple antenna states within a single structure
    and within a space having maximum dimension of approximately one wavelength. In
    this way physical channel selection occurs outside, and therefore augmenting,
    the front-end electronics. The independent controllable parameters for channel
    access include: frequency, polarization (full Poincaré sphere), and pattern (in
    two dimensions). Several different tests were conducted to maximize a quality
    figure of merit calculated by the radio. Both library-based and evolutionary search
    techniques were used, resulting in short term channel improvements on the order
    of 10 dB, and long term fully optimized improvements on the order of 20 dB. Dataset
    for OPEC Crude Oil Trade Network Saumya Vilas Roy and 1 more March 25, 2024 Quantification
    and analysis of global oil trade networks reveals deep insights into a nation''s
    development and influence at a global scale. Further, it allows us to predict
    future trends and changes to adapt state policy as the crude oil market influences
    the balance of power among the developed and emerging economies alike as it is
    central for energy needs as well for industrial progress. This document is a dataset
    descriptor for the dataset of crude oil exports from OPEC nations to importing
    nations/regions from a period of (2016-2022) structured for easy formation of
    nodes and edges sourced from various sources referenced below also it contains
    the average closing price per barrel and the global demand of crude oil during
    a fiscal year to note and understand complex relations between the global oil
    trade.The data-set is available at https://dx.doi.org/10.21227/m8ds-nd06.The authors
    can be contacted for the access to dataset as well. Passive Actuator-Less Gripper
    for Pick-and-Place of a Piece of Fabric Akira Seino and 3 more March 25, 2024
    In this paper, we propose a Passive Actuator-Less Gripper (PALGRIP) for picking
    a piece of fabric from a stack of fabric parts and placing the picked fabric part.
    The picking of a piece of fabric from a stack is a simple but difficult process
    to automate. The proposed gripper can pick a piece of fabric from the stack by
    simply pressing the fingertips of the gripper against the stack. The fingers are
    closed and opened by the relative motion between the fingers and the housing of
    the gripper. The grasping motion of the gripper is generated by two mechanisms:
    a passive pinching mechanism and a selflocking mechanism. These mechanisms allow
    the fingers to perform open and close movements and to maintain the fingers in
    either open or closed state. The kinematics of the mechanisms are analyzed to
    design the gripper. The relation between the movement of the fingers and the force
    required to operate the gripper is also investigated through static force analysis
    and the experiment. Finally, experiments using PALGRIP are conducted, and the
    experimental results illustrate how the pick-and-place operations are carried
    out using the prototype of PALGRIP. The proposed gripper allows the robot to automate
    fabric pick-andplace operations easily by attaching it to the robot''s endpoint.
    Triaxial 3D-Channeled Soft Optical Sensor for Tactile Robots Matteo Lo Preti and
    3 more March 19, 2024 Soft optical transducers have the potential to fulfill the
    need for advanced tactile sensing in robotics. We present a fingertipshaped soft
    sensor with optically transparent channels that relies on soft materials and sensor
    morphology to measure an applied triaxial force. The proposed 3D-channeled sensor
    has a volume of 2.5 cm3 , and experimental results reveal a fifteen-fold increase
    in voltage compared to its bulk analogous, showcasing a sensitivity of 0.34 N/mV
    and 0.09 N/mV to tangential and normal forces. A prototype with a diameter of
    2 mm (0.4x) indicates the feasibility of scaling down the sensor. Force magnitude
    is estimated with a linear model and then decomposed into its Fxy and Fz with
    an R2 of 0.93 and 0.98 within a sensing range of 4.05 N and 8.50 N, respectively.
    A coordinate transformation from a covariant to a cartesian reference frame is
    used to retrieve the direction of the tangential component of the force. The sensor
    was integrated into a compliant robotic hand as a proof-of-concept to demonstrate
    its real-time operation and suitability for grasping, paving the way for advancements
    in soft tactile sensors that can be embedded in soft robots. Distributed Nonlinear
    Model Predictive Control for a Quadrotor UAV Bilal Mubdir and 1 more March 19,
    2024 A Distributed Nonlinear Model Predictive Control (DNMPC) approach is proposed
    to control the simplified decoupled dynamics of a quadrotor UAV. The performance
    of DNMPC is compared, in terms of tracking and execution time, to that of standard
    control configurations based on centralized MPC and PID control aiming to show
    the suitability of each configuration in terms of performance and the practicality
    of using a particular configuration in real-time applications. The results show
    the advantage of using DN-MPC in terms of ease of tuning and computational cost
    over more centralized feedback control approaches. Indoor Localization based on
    Short-Range Radar and Rotating Landmarks Kolja Thormann and 2 more March 19, 2024
    A novel concept for indoor self-localization based on relative position measurements
    to rotating artificial landmarks (with known positions) using short-range radar
    is proposed. This includes a complete processing pipeline for extracting distance
    and angle measurements from the raw radar data, which consists of a neural network
    for distance estimation, a basic angle-of-arrival estimator, and a particle filter
    for position tracking. Due to the ability of radar to measure range rate, i.e.,
    the velocity in the direction of a detection, it is possible to robustly detect
    the landmarks by detecting and localizing their micro-Doppler pattern. This mean
    localization is possible even under difficult conditions (e.g., light changes).
    Experiments with a wheeled mobile robot and common office fans as landmarks demonstrate
    the effectiveness of the approach for indoor localization. Planning Stories Neurally
    Rachelyn Farrell and 1 more March 19, 2024 Symbolic planning algorithms and large
    language models have different strengths and weaknesses for story generation,
    suggesting hybrid models might leverage advantages from both. Others have proposed
    using a language model in combination with a partial order planning style algorithm
    to avoid the need for a handwritten symbolic domain of actions. This paper offers
    a complementary approach. We use a state space planning algorithm to plan coherent
    multi-agent stories in symbolic domains, with a language model acting as a guide
    to estimate which events are worth exploring first. We evaluate an initial implementation
    of this method on a set of benchmark problems and find that the LLM''s guidance
    is helpful to the planner in most domains. Automated Loop Fusion for Image Processing
    Madushan Abeysinghe and 3 more March 19, 2024 In this paper, we develop a method
    for automatically selecting groups of loops to fuse in an image processing data
    flow graph, here referred to as a "fusing configuration". The method is designed
    for use on Digital Signal Processors (DSP), many of which rely on statically scheduled
    Very Long Instruction Word architecture. Selection is guided by a heuristic instruction
    scheduler that serves as a performance model for a candidate configuration. We
    show that for synthetically generated graphs of size 2 to 10 nodes, this approach
    is capable of selecting the optimal fusing configuration in 80% of graphs and
    selects a configuration that achieves within 10% of the performance of the optimal
    configuration for 90% of graphs. A Lyapunov-based Approach to Nonlinear Programming
    and Its Application to Nonlinear M... Kyunghwan Choi and 1 more March 19, 2024
    A tuning-parameter-free and matrix-inversionfree solution of nonlinear programming
    (NLP) problems is proposed. The key idea is to design an update law based on Lyapunov
    analysis to satisfy the first-order necessary conditions for optimality. To this
    aim, first, the Lyapunov function is defined as the summation of the norms of
    these conditions. Then, the desired optimization variables and Lagrange multipliers,
    which minimize the Lyapunov function the most, are found analytically, thereby
    rapidly approaching the necessary conditions. The proposed method neither requires
    tuning parameters nor matrix inversions; thus, it can be implemented easily with
    less iterations and computational load than conventional methods, such as sequential
    quadratic programming (SQP) and augmented Lagrangian method (ALM). The effectiveness
    of the proposed method is applied to and validated by using it to solve a nonlinear
    model predictive torque control (NMPTC) problem in electrical drives. The results
    are compared with those of SQP and ALM. Vectorized Highly Parallel Density-based
    Clustering for Applications with Noise Joseph Xavier Arnold and 7 more March 19,
    2024 Clustering in data mining involves grouping similar objects into categories
    based on their characteristics. As the volume of data continues to grow and advancements
    in highperformance computing evolve, a critical need has emerged for algorithms
    that can efficiently process these computations and exploit the various levels
    of parallelism offered by modern supercomputing systems. Exploiting Single Instruction
    Multiple Data (SIMD) instructions enhances parallelism at the instruction level
    and minimizes data movement within the memory hierarchy. To fully harness a processor''s
    SIMD capabilities and achieve optimal performance, adapting algorithms for better
    compatibility with vector operations is necessary. In this paper, we introduce
    a vectorized implementation of the Density-based Clustering for Applications with
    Noise (DBSCAN) algorithm suitable for the execution on both shared and distributed
    memory systems. By leveraging SIMD, we enhance the performance of distance computations.
    Our proposed Vectorized HPDBSCAN (VHPDBSCAN) demonstrates a performance improvement
    of up to two times over the state-of-the-art parallel version, Highly Parallel
    DBSCAN (HPDBSCAN), on the ARM-based A64FX processor on two different datasets
    with varying dimensions. Additionally, we evaluate VHPDBSCAN''s energy consumption
    on the A64FX and Intel Xeon processors. The results show that the proposed implementation
    reduces energy consumption by a factor of two on the A64FX Central Processing
    Unit (CPU) and by approximately 19.5% on the Intel Xeon 8368 CPU compared to previous
    methods. UWB Security and Enhancements K. Reaz and 13 more March 19, 2024 Ultra-Wideband
    (UWB) technology re-emerges as a groundbreaking ranging technology with its precise
    microlocation capabilities and robustness. However, the security aspects of UWB
    technology demand thorough scrutiny due to its widespread use in both consumer
    and industrial sectors. This white paper highlights the security dimensions of
    UWB technology, focusing in particular on the intricacies of device fingerprinting
    for authentication, examined through the lens of state-of-the-art machine learning
    techniques. Furthermore, we explore various potential enhancements to the UWB
    standard that could realize a sovereign UWB data network. We argue that UWB data
    communication holds significant potential in healthcare and ultra-secure environments,
    where the use of the common unlicensed 2.4 GHz band-centric wireless technology
    is limited or prohibited. A sovereign UWB network could serve as an alternative,
    providing secure localization and short-range data communication in such environments.
    Data-Driven Insights: Boosting Algorithms to Uncover Electricity Theft Patterns
    in AM... Inam Ullah Khan and 3 more March 19, 2024 This study introduces a sophisticated
    supervised machine learning method for electric theft detection utilizing a customized
    Histogram Gradient Boosting (HGB) algorithm. Comprehensive preprocessing, including
    imputation, normalization, outlier management, and resampling, ensures the timeseries
    data is accurately prepared for analysis. The SMOTE-ENN algorithm corrects class
    imbalances, preparing the data for the feature optimization stage where crucial
    features are selected and extracted. The HGB algorithm, enhanced through Bayesian
    optimization, is central to the training process, resulting in a model that precisely
    classifies electricity consumption patterns as genuine or fraudulent. The robustness
    of the model is assessed against other recognized boosting methods, such as Adaptive
    Boosting (ADB), Gradient Boosting Decision Tree (GBDT), and LightGBM, alongside
    various ensemble and traditional machine learning models. Utilizing key performance
    metrics like accuracy, F1 score, and AUC for validation, the proposed model yields
    very promising results, with a 93% accuracy, 95% F1 score, and 98% AUC, outperforming
    the comparison group under similar dataset and hyperparameter conditions. This
    underscores the model''s potential as a highly accurate tool for combating electricity
    theft within an advanced metering infrastructure (AMI). Software Metrics in Agile
    Software Development: A Review Report Muhammad Faizan Berlas March 19, 2024 Modern
    software systems intensively use the Agile software development processes for
    their development and maintenance. The Agile development methodology encourages
    customer satisfaction, early incremental delivery, and overall development simplicity.
    Agile development methods accept changes in requirements and technology and use
    a more adaptive or iterative approach to planning. With the adaptation of Agile
    process models in the development of modern software systems, there is a need
    for continuous improvement in the Agile processes. Agile development processes
    are modified and upgraded by utilizing software metrics. There are several proposed
    software metrics for measuring performance and quality in Agile software development.
    These include customer satisfaction, story point estimation, velocity, test coverage,
    defects in production, and other metrics. Each software metric has its own merits
    and demerits. This research aims to provide a comprehensive review of published
    research work on software metrics. Specifically, it summarizes the software metrics
    used for measuring the performance of Agile process models. This research paper
    will help understand the usefulness of various software metrics used in Agile
    development, and it will serve as a foundation for future research in software
    metrics for Agile software development. Model-Based Systems Engineering Applied
    to Engineering Learning Analytic Systems (ELA... Pallavi Singh and 2 more March
    19, 2024 Engineering education is a complex that involves multiple stakeholders,
    including students, educators, administrators, and industry partners. It is continuously
    evolving to meet the demands of modern industry and society. The traditional teaching
    and learning methodologies are being replaced by a more integrated skillset that
    focuses on developing students'' cognitive, social, and emotional skills. The
    shift towards this integrated approach is gaining momentum, and it is important
    to have a framework that has been proven to solve complex systems. The usage of
    systems engineering tools to model engineering education systems is not often
    seen. In this paper, a novel application of Model-Based Systems Engineering using
    Systems Modeling Language (SysML) to develop an Engineering Learning Analytic
    System (ELAS) framework that consists of multi-dimensional elements related to
    educational systems. The core of this study involves a rigorous Requirements Verification
    and Validation (V&V) process to ensure stakeholder needs which systematically
    were map with system capabilities. ELAS model simulations provided predictive
    insights into soft skill development, enabling decision-making via targeted interventions
    that could significantly enhance students'' skill sets. ELAS highlights that a
    data-driven approach, enabled by SysML, significantly enhances the ability to
    enact timely by relevant interventions at various levels of the educational management
    process. The proposed ELAS model offers a strategic blueprint for continuous improvement
    within educational institutions, demonstrating a pathway toward a responsive and
    self-improving educational system. The refining of the ELAS model, for broadening
    simulation scopes, and further integrating predictive analytics into administrative
    decision-making processes is an ongoing endeavor. Multi-Discounting Reinforcement
    Learning Based on Reward Decomposition Pengbin Chen and 4 more March 18, 2024
    A document by pengbin chen. Click on the document to view its contents. ← Previous
    1 2 3 4 5 6 7 8 9 … 501 502 Next → TechRxiv | Powered by Authorea.com Home About
    Submission Guidelines FAQs Terms of Use Privacy Policy Contact Us'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://www.techrxiv.org/articles/preprint/A_Futuristic_Survey_on_Learning_Techniques_for_Internet_of_Things_IoT_Security_Developments_Applications_and_Challenges/19642977/1/files/34888401.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'A Futuristic Survey on Learning Techniques for Internet of Things (IoT)
    Security : Developments, Applications, and Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2022.3199408
  analysis: '>'
  authors:
  - Emmanouel T. Michailidis
  - Κωνσταντίνος Μαλιάτσος
  - Dimitrios N. Skoutas
  - Demosthenes Vouyioukas
  - Charalabos Skianis
  citation_count: 15
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE-SA IEEE Spectrum More Sites 404: Page Not Found The
    page you were looking for could not be found. Browse or search IEEE Xplore to
    continue. Email us at onlinesupport@ieee.org for further assistance. © Copyright
    2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09858158.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Secure UAV-Aided Mobile Edge Computing for IoT: A Review'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1201/9781003337454-7
  analysis: '>'
  authors:
  - Payam Barnaghi
  - Martin Bauer
  - Abdur Rahim Biswas
  - Maarten Botterman
  - Bin Cheng
  - Flavio Cirillo
  - Markus Dillinger
  - Hans Graux
  - Seyed Amir Hoseinitabatabaie
  - Ernő Kovács
  - Salvatore Longo
  - Swaroop Nunna
  - Alois Paulin
  - R. R. Venkatesha Prasad
  - John Soldatos
  - Christoph Thüemmler
  - Mojca Volk
  citation_count: 1
  full_citation: '>'
  full_text: '>

    7

    IoT Analytics: Collect, Process, Analyze, and

    Present Massive Amounts of Operational

    Data – Research and Innovation Challenges

    Payam Barnaghi2, Martin Bauer8, Abdur Rahim Biswas3,

    Maarten Botterman9, Bin Cheng8, Flavio Cirillo8, Markus Dillinger7,

    Hans Graux10, Seyed Amir Hoseinitabatabaie2, Ernö Kovacs8,

    Salvatore Longo8, Swaroop Nunna7, Alois Paulin5,

    R. R. Venkatesha Prasad4, John Soldatos1,

    Christoph Thuemmler5 and Mojca Volk6

    1GR, Athens Information Technology, Greece

    2University of Surrey, UK

    3CREATE-NET, Italy

    4TU Delft, Netherlands

    5Edinburgh Napier University, UK

    6University of Ljubljana, Slovenia

    7Huawei, Germany

    8NEC, Germany

    9GNKS Consult BV, Netherlands

    10Timelex, Belgium

    7.1 Introduction

    Internet-of-Things (IoT) Analytics refers to the process of transforming

    vast amounts of information from heterogeneous internet-connected objects,

    data sources and devices (e.g., sensors, appliances, cyber-physical systems,

    Machine-to-Machine systems) to business and application intelligence. Sev-

    eral tools and techniques for IoT analytics have their roots in conventional

    web analytics, which process and combine data streams from web-connected

    computers,cellphonesandwebdatabases.However,IoTanalyticsbroadenthe

    scope of web analytics on the basis of the collection, processing and analysis

    221

    222

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    of information produced by internet-connected devices, thus enhancing the

    scope and functionalities of related applications.

    Nowadays, IoT analytics have a growing momentum, which is highly due

    to the proliferation of IoT devices and the overall momentum of IoT technolo-

    gies and services. IoT analytics hold the promise to enable a wide range of

    novel applications that are not currently possible, which could revolutionize

    applications areas with signiﬁcant socio-economic impact such as healthcare,

    energy management, public safety and more. The IoT analytics vision, while

    fantastic, is associated with several challenges spanning both technical and

    policy issues. For example, at the technical and scientiﬁc forefront, IoT

    devices tend to produce high-velocity streams, which challenge the capabil-

    ities of state-of-the-art BigData systems (such as MapReduce). Furthermore,

    the heterogeneity and diversity of IoT devices is a serious set-back to the

    collection, consolidation and uniﬁed processing of IoT data streams. Other

    challenges relate to the selection, reﬁnement and deployment of effective data

    analytics algorithms that can respond to the stringent QoS (Quality of Service)

    requirements of IoT applications. Likewise, at the policy forefront, there is

    a need for addressing security, privacy and data protection challenges in-line

    with existing regulations, but also in a way that encourages user participation.

    The present chapter of the 2015 IERC Book aims at presenting the

    above-listed challenges of IoT analytics, while at the same time providing

    insights in possible solutions, notably solutions that are being developed

    in the scope of the IERC community. The second section of the chapter

    (following this introductory one), is titled “Deep Internet of Things Data

    Analytics”. It presents challenges and solutions associated with the collection

    and semantic uniﬁcation of diverse data streams, which is one of the ﬁrst

    prerequisite steps for analyzing IoT data sources. Likewise, the third section
    of

    the chapter presents the challenges of IoT/BigData convergence and illustrates

    techniques for integrating IoT with cloud and BigData infrastructures. The

    fourth section of the chapter provides insights associated with the practical

    application of IoTanalytics in healthcare and social care, while the ﬁfth section

    presents an IoT analytics case for public safety. Finally, the sixth section of

    the chapter deals with the ever important policy issues, through presenting

    challenges and providing a perspective for solutions that are in-line with

    existing and emerging EU directives. It also identiﬁes gaps of these directives

    and proposes relevant remedies. Overall, this chapter provides the reader with

    a nice overview of the technical and policy issues associated with the wider

    deployment of advanced IoT analytics, along with some solutions introduced

    and advanced by the IERC community.

    7.2 Deep Internet of Things Data Analytics

    223

    7.2 Deep Internet of Things Data Analytics

    7.2.1 Introduction

    Computers in their early days were not designed for personal use and

    individual applications. They were usually large machines and mainframes

    that specialists worked with. Rapid hardware and software innovations and

    advancements and the emergence of global networks and the Internet made

    computers widely available for everyone to use. Mobile devices and wireless

    technologies made it potentially possible to connect to communication net-

    works and the Internet anytime and anywhere. We now live in an era in which

    physical objects (i.e. “Things”) can be embedded with their own computing

    devices and with networking capabilities. The Internet of Things (IoT) is

    an umbrella term that refers to technologies that enable communication and

    interaction between various devices and real world objects and human users.

    IoT is mainly enabled by advancements in manufacturing low-cost sensors

    and actuators, smart phones, embedded devices, and communication and

    networking technologies. These advancements have resulted in rapid growth

    and the deployment of networked-enabled devices and sensing and actuation

    systems that interconnect the physical word with the cyber-world. The number

    of devices connected to the Internet has already exceeded the number of people

    on earth and is estimated to grow to 50 billion devices by 2020 [39].

    Data collected by different devices are of various types (e.g. temperature,

    light, humidity, video) and are inherently diverse and dynamic (i.e. the quality

    and validity of data can vary with different devices over time; data is also

    mostly location and time dependent). Sensory devices can be ubiquitous

    and are often constrained in power, memory, processing and communication

    capabilities. As the scale of interactions between devices and the load of

    communications rapidly increase, real world data and service trafﬁc become

    voluminous; the current Internet/Web architecture will not be suited to deliv-

    ering reliable, efﬁcient and time-sensitive data and services for large volumes

    of networked devices [1].

    In following paragraphs we discuss that IoT data analytics cannot be

    separated from data collection, device and network conditions and limitations.

    The ability of the resources to effectively publish, discover and access the data

    in large-scale distributed environments will have an impact on the efﬁciency

    of the data analytics methods. Effective data analytics solutions in the IoT

    need to consider the dynamicity and constraints of data collection devices

    and communication networks and should be able to optimise the processes

    for different purposes and requirements, such as latency, accuracy, data and

    224

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    sampling rates, and energy efﬁciency. We discuss data analytics in the IoT

    domain and describe some of the key issues to provide integrated and end-

    to-end solutions for large-scale and efﬁcient data analytics. The integration

    of device and network parameters and their characteristics in the IoT data

    analytics in this work is referred to as Deep IoT data analytics.

    7.2.2 Designing for Real World Problems

    IoT research covers a broad range of technologies and solutions that aim

    to tackle the challenges in networking and communications, interoperability,

    services and stream processing and data analytics. IoT is an integration of

    different systems and technologies. Industry based solutions and services in

    this domain are often under development or do not interoperate on a global

    and large scale, due to a lack of standardisation. Data processing and analytics

    solutions in the IoTare mainly based on conventional data mining and machine

    learning techniques. There are also several solutions and de-facto standards

    for annotation and semantic integration of IoT data.

    However, IoT data is inherently different from other types of data on

    the Web and database systems. Uncertainty, incompleteness, sporadic data

    distributions, scale and energy and resource constraints of the data provider

    devices are among the key issues that make processing IoT data different and

    more challenging than the usual data on the Web and database systems.

    Data analytics solutions in the IoT, in contrast to many existing BigData

    analysis works, cannot be separated from data collection, selection, network

    status and issues such as energy efﬁciency. Efﬁcient and intelligent data

    analysis methods for the IoT domain should consider end-to-end and inte-

    grated solutions and should be adaptable and ﬂexible enough to work with

    incomplete and uncertain data and should also be able to adjust themselves to

    concept drifts (i.e. changes in the data or the objectives of data processing)
    [2]

    and requirement changes. The IoT is an online network of resources and data

    analytics solutions and should be able to process and analyse dynamic data in

    real-time.

    Figure 7.1 (adapted from [3]) shows some of the key dimensions that need

    to be taken into account when designing data analytics methods for the IoT.

    As shown in the ﬁgure, the connectivity and data publication can potentially

    be at any time, from any place and can be related to any-thing. The volume

    of data is a key issue and the networks and communication technologies have

    an impact on various aspects of data access and use, such as latency, quality

    and availability. IoT data can be related to people, personal spaces and living

    7.2 Deep Internet of Things Data Analytics

    225

    Figure 7.1

    Key dimensions in production and deployment of IoT data.

    environments; so reliability, security and privacy are among key issues in

    designing any solutions, including data analytics for the IoT. Having access

    to new types of data and connectivity and interaction with the real world

    provides an opportunity to design new services and applications that rely

    on ambient intelligence. However, data analytics methods for extracting this

    ambient intelligence have to deal with time and location dependency and

    dynamicity of data and the solutions should be able to handle uncertainty

    and quality issues often in a real-time manner. IoT services and applications

    will have an impact on people’s lives and the way that personal and public

    spaces and services are planned and designed (e.g. smart homes and smart

    cities). Industrial IoT applications and services require the processing of large

    volumes of data to make autonomous decisions to control and operate various

    systems and machines.

    Wireless communication is the dominant component in overall energy

    consumption of the remote IoT devices (i.e. in the current systems the

    computationusuallyconsumeslessenergythanthecommunication[4]).Inthis

    regard, careful considerations should be made to minimise the communication

    load in IoT networks. IoT resources are usually programmed to collect and

    forward data based on a given data acquisition frequency and are often

    ignorant of information within the data packets. This could lead to the creation

    226

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    of redundant and unnecessary communication load when data is noisy and

    unreliable or when it does not contain any signiﬁcant or new information.

    The other important issue is the scalability of the data processing and

    computation. Recent efforts in distributing processing tasks among different

    resources (e.g. using software deﬁned solutions [5]), have mitigated the

    problems associated with conventional centralised processing architectures

    to some extent. However, with the scale of the IoT resources, problems such

    as effective use of computational resources on devices and distribution of

    data analytics processes between IoT devices and Cloud based resources are

    challenging issues.

    7.2.3 Real World Data

    To better understand the requirements of data analytics we ﬁrst need to look at

    the data sources and the type of devices and networks that produce and handle

    this data. Access to live real world data and connected worlds of physical

    objects, people and devices are rapidly changing the way we work and interact

    with our surroundings and have had a profound impact on different domains,

    such as healthcare, environmental monitoring, urban systems, industry, and

    control and management applications and decision support systems.

    IoT data is usually collected via sensing devices that are connected to

    wireless or wired networks (e.g. wireless sensor and actuator networks),

    smart phones and other embedded and network-enabled devices. The devices

    can be directly connected to the core network and data analysis compo-

    nents or gateway components can provide data communication between IoT

    devices and higher-level services and applications, including the data analytics

    components in the core networks.

    Figure 7.2 shows a generic framework for IoT data communication where

    some nodes can use Internet and Web based protocols and some are connected

    via gateway components. There are also platforms and solutions that enable

    crowd sourcing of IoT data collection and publication using smart phone

    and network-enabled devices and sensing technologies. Quality, trust and

    reliability, together with the availability and delays in accessing the data are

    key issues in crowd sourced data collection and publication use-cases.

    IoTdata is often published as streaming data with multiple streams that can

    provide similar data (but can have different quality or parameters) or other

    relevant data that need to be integrated and processed together. Extracting

    patterns and ﬁnding correlations between different parts of the data is an

    important task in data analytics for IoT data streams. However, there are two

    7.2 Deep Internet of Things Data Analytics

    227

    Figure 7.2

    A generic framework for IoT data publication and communication.

    key issues: causation vs. co-occurrence requires further analysis and often

    background knowledge is required to interpret and separate the causations;

    time lag between different pattern occurrences and spatial dependencies

    should also be considered when analysing the patterns in the streams. For

    example, an occurrence in a data stream (i.e. an event) can cause a related

    pattern in a different stream (and in a different location) after a period of

    time. So the spatio-temporal interdependencies should also be considered

    in the analysis. The streaming data can sometimes have missing values due

    to communication and device errors or different sampling rates. Different

    interpolation techniques (e.g. Gaussian process or multivariate interpolation

    techniques) or machine learning methods can be employed to compensate for

    the missing values in the data streams.

    7.2.4 Data Interoperability

    Data collection and publication is the initial step for accessing and processing

    IoT data. As discussed, there are several issues regarding the device, network

    and end-user application and service state and requirements that need to be

    taken into consideration when collecting and publishing the IoT data.

    Data is usually published in various forms and via distributed devices

    and sources. There are several existing metadata models and description

    228

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    frameworks that are designed and proposed by academia and industry to

    provide interoperable resource and data descriptions in the IoT domain. For

    example, the W3C Incubator Group on Semantic Sensor Networks developed

    a higher-level model for describing sensors and their capabilities called SSN

    Ontology [6].

    These semantic and metadata models and description frameworks are

    designed to improve the interoperability of the data and resource descriptions.

    Machine-readable and automatically interpretable data descriptions and data

    engineering solutions to enhance the structure and representation of data

    will strongly improve the analytics and integration methods, especially in

    the IoT world, where multi-modality and heterogeneity are among the key

    issues. However, the semantic annotation requirements and the complexity

    of providing structured information with several attributes often hinders

    the effective use of the semantic models that are proposed for real world

    data. Some of the parameters, such as quality of data, are also dynamic

    variables. Most of the current semantic annotation models construct a semantic

    description model and annotate the data according to that model without

    providing an end-to-end set of tools and solutions to add and update more

    attributes and metadata to the annotation after the data is published. However,

    thedynamicityandchangesintheannotatedvalues(e.g.themeaningofquality

    for a data item can change after the time of measurement; provenance of data

    can change as more processing methods are applied to the data) is not captured

    in the models and annotation methods.

    Many of the current semantic annotation frameworks for the IoT are static

    and the provenance and changes to the data and metadata updates are not

    directly supported. Providing “dynamic semantics” in the IoT domain and

    developing tools, APIs and methods that can publish, update and extend the

    semantics as the data is processed and integrated with other sources, or as

    more information is collected and analysed from the environment will help to

    resolve this issue. This will not only address the interoperability issues but
    will

    also create more enhanced and ﬂexible annotations that reﬂect the actual and

    up-to-date attributes of the data. The dynamic semantic methods should also

    use linked-data descriptions to link between different resources and also use

    common vocabularies to describe the concepts and content of the annotations.

    Using common vocabularies and topical ontologies for describing events

    and occurrences and other common attributes of the data, such as units of

    measurement, will signiﬁcantly improve the interoperability and effectiveness

    of data analytics operations.

    7.2 Deep Internet of Things Data Analytics

    229

    7.2.5 Deep Data Analytics Methods

    Edge-level pre-processing, ﬁltering the noise and removing the corrupted data

    and data aggregation mechanisms on the IoT device could help to minimise

    the use of communication resources at source level. Pre-processing and data

    aggregation at device level is a remedy for the congestion problem that often

    occurs in centralised and hierarchical architectures and will lead to a more

    scalable design.

    In the IoT, data analysis algorithms should be able to automatically make

    adjustments and adapt the overall solutions to different information extraction

    and optimisation goals. For example, in an emergency response scenario

    the algorithms need to be optimised for reducing latency; in an elderly

    care scenario increasing the quality of the extracted information would be

    the main priority; in an environmental monitoring framework using a large

    number of wireless sensors and increasing the life-time of the network can

    be one of the main goals of the overall application and consequently the data

    analytics method should also be adjusted and optimised to meet these goals

    and requirements. Obviously IoT devices in large deployments will not run

    for just one application and will not respond to a single demand, so cross-

    application optimisation is also an essential task in developing large-scale and

    multi-purpose IoT frameworks. To perform such optimisation and integrated

    data processing efﬁcient data discovery and selection algorithms for choosing

    the best set of resources at the given time, and adaptable and customisable

    data analytics methods that can push the processing to the edges of the IoT

    networks, are required.

    Most of the conventional machine learning and data analytics methods are

    also designed based on the assumption of having normalised distribution and

    reliable datasets. For example, processing techniques, such as the Symbolic

    Aggregate approXimation (SAX) [7] algorithm for constricting patterns from

    streaming data, assume that the data distribution are normalised. SAX divides

    the normalised probability distributions to equi-probable segments and assigns

    a symbolic representation for each segment. These symbolic representations

    are then used to create representative patterns of the streaming data. While

    SAX or other similar methods have been used effectively in the data analysis

    and stream processing ﬁelds, using them in the IoT has some limitations. SAX

    patterns can still be constructed from the IoT data streams but the distribution

    of the IoTdata in short-time windows, which is often the key focus of the (near)

    real-time data analytics methods, is not normalised and can be a sporadic and

    multivariate distribution. This will require pre-processing and analysis of the

    230

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    data at source level and determining the distribution and other attributes of

    the data before constructing the symbolic representation and constructing the

    patterns.

    Data analytics for dynamic environments such as IoT requires resource-

    aware analysis techniques that focus on both the data and also the resources

    that provide the data. Optimisation for different objectives such as latency,

    accuracy, energy efﬁciency, and network trafﬁc should be supported and the

    algorithms should be able to adjust and adapt to these objectives dynamically.

    The key target of data analytics in the IoT is to create situation-awareness and

    ambient intelligence and to extract actionable information that can be used

    in decision support systems and higher-level applications and services. The

    results of the data analytics can also be used to visualise and demonstrate

    different patterns, occurrences and events in the physical environments. Most

    of these are online applications and services that require (near) real-time

    learning and feedback mechanisms.

    Figure 7.3 shows a multi-level view of data analytics in an IoT framework.

    The device and resources are the edge-level and their parameters at any given

    time will have an impact on real-time data collection and other parameters,

    such as quality and granularity of the data. The analytics methods need to take

    into account these parameters and to also try to control and adjust these using

    Figure 7.3

    A view of data analytics levels in an IoT framework.

    7.2 Deep Internet of Things Data Analytics

    231

    software deﬁned and adjustable solutions to provide more resource-aware

    solutions. The middle layer is the core network and Cloud based services

    that can provide back-end support for discovery, integration, publication and

    storage, and large-scale distributed analytics methods. The functions at this

    level will be adapted according to requirements, concept drifts at the end-user

    and application/service layer and also condition and priorities at the device

    level.

    In the machine learning domain and the Big Data world there are deep

    learning methods that attempt to learn representations and model abstractions

    of data [8]. The deep learning methods often also improve the performance of

    the learning methods by analysing and processing large volumes of data. In the

    IoT domain, the use of deep learning and other conventional and novel data

    analytics and stream processing methods can be very beneﬁcial. However, the

    deep analytics, as described in the paper, mainly describes the adaptability

    and adjustability of the methods towards various optimisation objectives and

    concept drifts and is an attempt to develop analytics and machine learning

    techniques that can take device and network parameters into account and can

    work efﬁciently with multivariate and sporadic data provided by multiple

    sources and by various qualities.

    The data analytics solutions in this IoT domain also rely on semantic anno-

    tations and descriptions of the resources. The more expressive the attributes

    of the data and their provider resource are, the better the interpretation and

    analysis that can be provided. However, expressive semantic annotations

    and metadata will require a higher communication and computation load

    (and consequently will consume more energy in constrained environments).

    The update, query and processing of complex semantics can also their hinder

    efﬁcient utilisation. So a trade-off between semantic descriptions, efﬁcient

    publication, query and discovery methods and adaptable and ﬂexible learning

    and analytics solutions are required in the IoT framework.

    7.2.6 Conclusions

    Increased interest in using the IoT in different domains, such as smart cities,

    healthcare and industry, plays a key role in the production of massive amounts

    of real world data. This data is mainly collected in order to extract actionable

    information, create ambient intelligence and provide situation awareness for

    different higher-level applications and services [9]. IoT is a dynamic environ-

    ment with various devices that are often resource constrained and deployed

    on a large scale. Consequently, IoT data is also dynamic and heterogeneous.

    232

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    In contrast to many Web and database systems, data analytics methods

    depend on the context of the data production source and network and device

    parameters.

    Efﬁcient IoT data analytics methods require end-to-end techniques and

    solutionsforcollectionandpublication,discoveryandselection,andadaptable

    and adjustable data analysis mechanisms and techniques. Drifts and changes,

    both in the end-user targets and operational environments and optimisation

    goals and network and device parameters, should be monitored and captured

    and should be fed back to control mechanisms that can adapt and control

    the data analytics methods. Key challenges for the future generation of IoT

    data analytics, in addition to overcoming the scale, computation and multi-

    modality issues, is to provide software controlled and adaptable solutions that

    can monitor the changes deep in the networks and physical environments and

    optimise their functions and goals based on end-user requirements, network

    and platform context, and changes in the surrounding environment.

    7.3 Cloud-Based IoT Big Data Platform

    7.3.1 Introduction

    The third generation Internet of Things (IoT) comprises millions of appli-

    cations, billions of users and trillions of devices. Over the last years, IoT

    has moved from being a futuristic vision to market reality. It is not any

    more a question that whether IoT will exist surpassing the hype, but it is

    already there and IoT industry race has already begun. Trillions of connected

    devices are the enablers; however the value of IoT is in the data and advanced

    processing of the collected data. IoT data is more dynamic & heterogeneous,

    imperfect & unstructured and, unprocessed & real-time than typical busi-

    ness data. It demands more sophisticated IoT-speciﬁc analytics to make a

    meaningful inference. The exploitation of the real-time big data obtained

    from sensors/actuators in IoT context by processing in sophisticated cloud is

    very much a necessity. This data processing leads to advanced, proactive and

    intelligent applications and services. The colligation of IoT and Big data can

    offer:i)deepunderstandingofthecontextandsituation,ii)real-timeactionable

    insight – detect and reacted to in real-time, iii) performance optimization,

    and iv) proactive and predictive advanced knowledge. Cloud technologies

    offer decentralized and scalable information processing and analytics, and

    data management capabilities.

    Following paragraphs address the cloud based IoT and Big data platform

    concept and their emerging requirements on the convergence of sensors and

    7.3 Cloud-Based IoT Big Data Platform

    233

    devices, big data analytics, cloud data management, edge-heavy computing,

    machine learning and virtualization. Initial results from iKaaS (Intelligent

    Knowledge as a Service) an EU-Japan project on IoT/Cloud/Big data are also

    discussed.

    7.3.2 Big Data in the Context of IoT

    Big data is deﬁned by 4Vs (Figure 7.4), these are Volume-, Velocity, Variety,

    Veracity. Volume means large data size in 100s of terabytes. Velocity means

    the real-time and/or stream of data. Variety means the heterogeneous data

    (e.g., structure and unstructured, diverse data models and query languages,

    and diverse data sources). Veracity means data uncertainty due to data incon-

    sistency, incompleteness, ambiguities, latency, model approximations, etc.

    IoT faces all 4Vs of the Big Data challenges. However the velocity is the

    main IoT Big data challenge because of real-time and stream of data coming

    from diverse IoT devices and sensors. Real-Time Big Data terminology is

    often replaced by the term IoT Big Data. The data coming from the IoT devices

    have to be processed in real-time to arrive at reliable and intelligent decision.

    For example, healthcare wearables (like ECG (Electrocardiogram) devices)

    produce up to 1000 events per second which is a challenge for real-time

    processing considering miniaturized devices and number of such devices.

    Next is the volume, for example, large scale IoT deployments gather and

    process millions pieces of data from millions of sensors per day. Likewise, a

    wearable sensor produces about 55 million data points per day.

    Figure 7.4

    Big Data Properties.

    234

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    7.3.3 Applications of IoT Big Data Analytics

    The applications of IoT Big Data analytics can be classiﬁed into ﬁve main

    categories which are depicted in Figure 7.5 and include:

    • Predictive analytics,

    • Prescriptive analytics,

    • Descriptive analytics,

    • Monitoring and

    • Control and optimization.

    All these require a deep understanding of the domains, situation and the

    requirements of services by users.

    Gaining insights and knowledge in real time and actionable insights

    can lead to performance optimization. All the above ﬁve applications are

    inter-related and requires multiple tools like machine learning, reasoning,

    optimization, etc.

    Predictive analytics is used in many applications where users require

    services that can foresee the situation and act on it. Prescriptive analytics
    can

    provide many possible actionable decisions and also can provide the trade-off

    between them.

    Descriptive analytics offers the insights into the situation and helps in deep

    understanding. Monitoring, control and optimization are legacy applications,

    but with big data analytics they can be improved immensely.

    Figure 7.5

    IoT-Big Data Applications.

    7.3 Cloud-Based IoT Big Data Platform

    235

    Thus, analytics can indeed offer multiple services such as observing

    behaviour of things, gaining important insights and processing in real time

    for immediate actions. For example, in healthcare services IoT analytics can

    be used for understanding the cause of diseases, as well as for identifying

    emergency situations.

    This vision boils down to solving multiple challenges: to store all the

    events (velocity & volume); to run queries over the stored events; (velocity &

    volume) to perform analytics (data mining and machine learning) over the

    data to gain insights. Examples include real-time fall detection and potential

    reactions for aging population. Real-time detection and action represent

    multiple challenges.

    7.3.4 Requirements of IoT Big Data Analytic Platform

    An IoT BigData Analytics Platform is a real-time online platform that

    dynamically manages IoT data/objects but it also provides connectivity to the

    diverse heterogeneous objects, considering the interoperability issues. Next

    is deriving useful information and knowledge from this connection and large

    volume of IoT data. The platform needs to offer ubiquitous accessibility and

    connectivity in facilitation of maximum accessibility as well as connectivity

    of the diverse heterogeneous objects/services and various volumes of users

    including mobility. Dynamic management/orchestration of users, billions of

    devices as well as massive amount of data produced by those connected

    devices, maximum resource utilization, and sharing of IoT resources (objects,

    applications, platforms) are all necessary. Personalized, secure, and privacy

    by design services based on preferences of users and requirements including

    real-world context are the important requirements. Some of the requirements

    are brieﬂy discussed in following paragraphs.

    7.3.4.1 Intelligent and dynamic

    The platform should include intelligent and autonomic features in order to

    dynamically mange the platform functions, components and applications. The

    platform should also be capable of making a proactive decision, dynamic

    deployment, and intelligent decision to understand the context of the envi-

    ronment, users and application requirements, etc. Considering performance

    targets/constraints, ofﬂoading from clients/hosts to cloud is necessary but the

    performance should be guaranteed. Dynamic resource sharing and service

    migration is a must for large scale IoT applications. Dynamic metering may

    be also necessary when IoT devices are shared.

    236

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    7.3.4.2 Distributed

    The platform should include distributed information processing and comput-

    ing capabilities, distributed storage, distributed intelligence, and distributed

    datamanagementcapabilities.Thisneedtobedistributedacrosssmartdevices,

    gateway/server and multiple cloud environments. More distributed processing

    and storage of the massive data as well as cloud functionalities is a must.

    Decentralized (and infrastructure-less) clouds will be the order of the day

    through processing capabilities and positioning data closer to users.

    7.3.4.3 Scalable and elastic

    The platform has to be scalable to address the connectivity from small to large

    number of the devices, manage the different scale of the data and services, as

    well as users. Cloud and edge data management, storage and processing, need

    to be scalable and at the same time elastic.

    7.3.4.4 Real-time

    Real-time data processing and service provisioning of “Big data”, is necessary.

    Un-structured and semi-structured data coming from distributed sources

    should be processed to provide real-time/near real-time services.

    7.3.4.5 Heterogeneous (uniﬁed)

    Interoperability between cloud/IoT services and infrastructure, and federation

    between cloud, Big data and IoT devices has to be in place to realize full

    potential. Standard APIs to deal with heterogeneity need to evolve. Open

    software components, standard data structure and modeling and abstraction

    of heterogeneous IoT devices and the data is necessary. Data always raise

    heterogeneity problems: many data formats, many metadata schema descrip-

    tions, mix of various levels of complexity, etc., are the cases in point.The target

    is to deliver a data model and the speciﬁcation of required mechanisms for

    exploiting both structured and unstructured data, for moving from raw data to

    linked data, enabling the adoption of a common understanding, the recognition

    of similar data, and unambiguous description of relevant information for

    multimodal and cross-domain smart space applications.

    7.3.4.6 Security and privacy

    Security and privacy by design is also needed including different privacy and

    security features like data integrity, localization, conﬁdentiality, SLA(Service

    Level Agreements), security and privacy-preserving data management mod-

    ules. Holistic approaches are required to address privacy & security issues

    7.3 Cloud-Based IoT Big Data Platform

    237

    across value chains including privacy by design aspects, software algorithms

    and new data management models.

    7.3.5 Cloud-Based IoT Analytic Platform

    The cloud-based platform is dynamic in nature and offers ﬂexible resources

    sharing and service provisioning. It also offers a scalable and elastic service/

    resources management platform. The platform also offers reliable and easy

    access to the services using large amount of computing and storage resources.

    The cloud-based platform is also homogeneous (uniﬁed) which reduces the

    technological heterogeneity. On the other hand, IoT depends on massive

    resources available when needed and scaled back when not needed. This

    can only be achieved using cloud paradigm. For IoT, cloud computing

    functionalities enable the realization of the IoTvision. For Cloud, IoTprovides

    huge opportunities for cloud services. There are two basic approaches for

    the convergence of IoT-Big data and Cloud. These are (i) Cloud-centric IoT

    (bringing IoT functionalities into Cloud) and (ii) IoT-Centric Cloud (bringing

    Cloud functionalities into IoT).

    In the following, we provide an overview of the iKaaS platform that

    has been developed as an example and which is illustrated in Figure 7.6.

    It combines ubiquitous and heterogeneous sensing, along with big data and

    cloud computing technologies. iKaaS enables IoT processing consisting of

    continuous iterations on data ingestion, data storage, analytics, knowledge

    Figure 7.6

    iKaaS Platform.

    238

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    generation and knowledge sharing phases, while at the same time providing

    a foundation for service provisioning. The iKaaS platform comprises of the

    cloud ecosystem that consists of Local Clouds and a Global Cloud. More

    speciﬁcally:

    • Alocal cloud is created on-demand; it comprises of sufﬁcient/appropriate

    computing/storage/networking capabilities, and provides requested ser-

    vices to users in a certain geographical area and time period as well as

    offers additional processing and storage capability to services.

    • The global cloud is seen in the “traditional” sense, as a construct with

    on-demand/elastic processing power and storage capability. It is a

    “backbone infrastructure”, which increases the business opportunities

    for service providers, and the ubiquity/reliability/scalability of service

    provisioning. It offers more opportunities for offering services, more

    options on which service features are based in case of context changes,

    more resources for deriving meaningful decisions, and elastic provision

    of resources on demand.

    Local clouds can involve an arbitrarily large number of nodes (sensors, actu-

    ators, smart-phones, etc.). The aggregation of resources comprises sufﬁcient

    processing power and storage space. The goal is to serve users in a certain

    area. In this respect, a local cloud is the virtualised processing, storage and

    networking environment, which comprise IoT devices in the vicinity of the

    users; users will exploit the various services composed of the devices in local

    clouds and their capabilities e.g., a sensor and its gateway equipped with the

    iKaaS platform.

    The global cloud can enable, as a special (yet important) case, the existence

    of IoT service providers capable of providing larger scale services without

    owning actual IoT infrastructure.

    The Cloud ecosystem comprises the following essential functionalities:

    • Consolidated service-logic/resource descriptions/registries as part of the

    Global Cloud enabling the reuse of services. Practically, a set of registr-

    ies will be developed enabling the pooling of service logic and resources.

    • Autonomic service management, ﬁrst the global cloud and then, in the

    local cloud. This functionality will be in charge of (i) dynamically

    understanding the requirements, decomposing the service (ﬁnding the

    components that are needed); (ii) ﬁnding the best service conﬁguration

    and migration (service component deployment) pattern; (iii) during the

    service execution, reconﬁguring the service, i.e., conducting dynamic

    additions, cessations, substitutions of components.

    7.4 IoT Analytics in Health and Social Care

    239

    • Distributed data storage and processing is anticipated for global and

    local clouds. This means capabilities for efﬁciently communicating,

    processing and storing massive amounts of, quickly-emerging, versatile

    data (i.e., “big data”), produced by a huge number of diverse IoT devices.

    • Derivation of information and knowledge (e.g., on device behaviour,

    service provision, user aspects, etc.), while ensuring security and privacy

    as a top concern.

    • Knowledge as a service (KaaS) will be primarily part of the Global Cloud.

    This area covers: (i) device behaviour aspects; (ii) the way services have

    been provided (e.g., through which IoTresources) and the respective

    quality levels; and (iii) user preferences.

    Thus the iKaaS functionality will determine the optimal way to offer a service.

    For instance service components may need to be migrated as close as possible

    to the required (IoT) data sources. IoT services may need generic service

    support functionality that is offered within the cloud, and, at the same time,

    they do rely on local information (e.g., streams of data collected by sensors
    in

    a given geographic area), therefore, the migration of components close to the

    data sources will help in reduction of data trafﬁc.

    7.4 IoT Analytics in Health and Social Care

    7.4.1 Introduction

    Following a protracted start back in the early 2000, IoT is nowadays an

    undeniable force, which will dictate our (virtual) reality in years to come.

    According to ﬁgures by Cisco the global amount of mobile data will grow

    dramatically to an annual run rate up from 30 exabytes in 2014 to 249 exabytes

    by 2019 [10]. While a signiﬁcant share of this data, almost 79% will account

    for IP video streaming by 2018 it is reasonable to assume that by then 5–10%

    of the overall trafﬁc will be generated by smart devices, sensors, attenuators,

    embedded – and cyber-physical systems. Although these developments are

    currently driven in the ﬁrst instance by industrial domains such as automotive,

    retail and logistics there is evidence for massive utilization of IoT strategies

    in the health and social care domains in the near future.

    It has become increasingly clear that the way health and social care

    will be delivered in the future is undergoing substantive changes. These

    changes are driven by the demographic and socio-economic developments

    in our societies and also the technological and bio-medical progress. As a

    general trend the availability of smart IoT capable devices has dramatically

    240

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    improved. Wearables are everywhere, from smart glucometers for blood-

    glucose measurement, insulin-pumps and highly complex brain-pacemakers

    for the treatment of Parkinson’s disease to the “iWatch” or similar products.

    Portability has increased since storage capacity of smart phones has reached

    hundreds of Gigabytes and the battery capacity is signiﬁcantly improved.

    Governments in Europe are now publically debating the utilization of IoT

    technology to control health and social care costs by enabling and empowering

    patients and their informal carers [11]. However, while the focus of IoT

    research has so far been placed on creating reference architectures and conduct

    design- and feasibility studies in order to interlink devices and capture and

    collect information the issues around analytics and the creation of value are

    now taking center stage [12].

    Even though the focus of this section is clearly on analytics and enabling

    architectural designs it is certainly important to underline that in sensitive

    areas (such as healthcare), the discussed technologies and their possibilities

    have to always be set into perspective with the relevant ethical and legal

    considerations [13]. For further information on this topic the interested reader

    may wish to consult the ethics, science and technology section at the European

    Political Strategy Centre [14].

    7.4.2 Architectural Approach to Data Analytics

    Essential to the health – and social care domains is the understanding that

    architecture should be scalable and able to cater for the analysis of big and

    small data whereby the topology is becoming more and more relevant [15,

    16]. Conventional cloud computing has long been regarded as the holy grail

    of big data analysis and is certainly a powerful method. The ability to share

    computing resources and balance the load according to the need of the task

    at hand makes cloud infrastructures clearly a formidable approach. Typical

    examples include the analysis of pre-existing large databases such as censuses

    or genetic information (genomics) databases.

    However, standard cloud approaches seem to struggle with some require-

    ments of the health and care domains, especially with regards to time critical

    processes.Although cloud approaches are powerful strategies, the bottle-neck

    seems to be the network and the relatively high latencies associated with it.

    Furthermore, there are continuous privacy and security concerns associated

    with public clouds for the use in health and care.

    The biggest challenge seems to be the fact that the predicted growth of

    network trafﬁc, especially mobile trafﬁc, will outperform the network capacity

    7.4 IoT Analytics in Health and Social Care

    241

    by 2019 [10].At the same time there is clear evidence for a signiﬁcant increase

    in sensors, attenuators, embedded and cyber-physical systems, which on the

    one hand clearly drives the utilization of IoT technology in e-Health but also

    drives the increase in data, which further widens the gap between trafﬁc

    demand and network capacity. This dilemma has caused a paradigm shift

    towards a distributed analytics approach, which might be the way forward in

    the health and care domains, which are set to generate very large amount of

    data with the potential to jam up existing infrastructures.

    While hybrid-cloud models were early manifestations of the attempt to

    solve the privacy problem in sensitive areas such as health and care, most

    recently this has been developed further into more sophisticated strategies

    involving mobile edge cloud computing and lately the so called “fogging”

    [16–18]. Fog computing in a way merges the beneﬁts of cloud computing and

    grid computing as it on the one hand integrates peripheral smart devices in

    one distributed approach while on the other hand allows for local problems

    to be solved locally. This has implications with regards to latency, privacy,

    precision, autonomy and liability [19, 20].

    While politicians and administrators still push for electronic patient ﬁles or

    electronic health records there is an urgent demand to clarify the terminology.

    As it is unlikely that a homogeneous data base system ideal for the assessment

    through classic cloud strategies can be achieved in most European countries

    in the foreseeable future hyper-distributed models where patients will be

    using their own smart devices to collect and manage their own data will

    become the norm. Fogging, supported through mobile edge clouds might be

    far superior to conventional clouds in such a scenario. New hyper-distributed

    architectures could also protect clinical infrastructures from being over-loaded

    with irrelevant information while it allows for patients and informal carers to

    be in full control of their information. It will also protect health care providers

    from the risk of loss or theft of information and reduce their exposure to

    litigation.

    7.4.3 IoT Data Analytics

    Big data analytics in healthcare is considered a transformational science,

    which has gained much attention in recent years. Doubtlessly, this can be

    attributed to unsustainable costs in healthcare, which calls for IT-assisted

    solutions. Growing adoption of patient-centred mobile digital health appli-

    cations, availability of advanced cloud and connectivity options, and the rise

    of the wearables allowing for continuous observation of health-related events

    242

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    have already massively increased the amount of health-related information.

    Known as mobile or pervasive healthcare, remote collection of personal health

    and environmental data through sensor networks and mobile devices is well

    underway. This creates opportunity to track healthy behaviours, understand

    diseases at a granular level and provide true patient-centred care, and might

    fundamentally alter healthcare services as the industry moves to value-based

    models.

    In order to exploit and fully leverage this long-term potential in the context

    of healthcare, advanced big data analytics are needed to enable extraction

    of valuable and actionable insights and establish sustainable value chains

    [21, 22]. The use of analytics solutions in healthcare is being increasingly

    recognized for its value in delivering quality care and gaining competitive

    edge. Most importantly, tools are needed to cope with the 4Vs [23] of Big

    Data in healthcare (i.e. Volume, Velocity, Variety and Veracity) and to translate

    “noisy masses of data” into unambiguous, quality and meaningful insights

    that can be safely applied with conﬁdence to practice on both patients’ and

    experts’ sides. In turn, the healthcare analytics market is growing at a rapid

    pace, and there are several good practice examples of use resulting for example

    in lower hospital readmissions and shorter hospital stays, and successful mon-

    itoring and prevention of chronic diseases. According to MarketsAndMarkets

    [24], the healthcare analytics market is experiencing substantial growth at a

    Compound Annual Growth Rate (CAGR) of 25.2% and is expected to reach

    $21,346.4 Million in 2020. However, obviously the potential comes with a

    price – expectations are high and requirements are strict around security,

    privacy and protection of sensitive information and establishment of trust

    is necessary throughout the value chains. If not addressed appropriately, these

    might present the biggest barriers for adoption.

    In terms of research and science, Big Data is a well-developed ﬁeld when

    it comes to principles, algorithms, methods and tools for data collection,

    cleaning, description and interpretation. The presently established descrip-

    tive analytics in healthcare are giving way to predictive and prescriptive

    techniques to process volumes of heterogeneous messy data harvested from

    various sources and integrated across distributed infrastructures. Semantic

    science, machine learning and classiﬁcation mechanisms provide for powerful

    interpretation and translation techniques, for example to integrate and quantify

    sources with insights into patients’ personal point of view, such as Twitter or

    self-reportingmobileapps,andtranslatesubjectiveobservationsintoobjective

    medical terms. Other recognized techniques are also statistical analytics, fact

    clustering, and natural language processing. However, regardless of such

    7.4 IoT Analytics in Health and Social Care

    243

    advanced techniques, data analysis is frequently the application’s bottleneck,

    both due to insufﬁcient scalability of the underlying algorithms and due to the

    increasing volume and complexity of the source data, which is continuously

    challenging current approaches. This, in addition to data processing and

    interpretation science, opens also a whole new avenue of research related

    to capabilities, capacities and coping strategies when transmitting masses of

    healthcare data. In this respect, the rise of cloud computing has introduced

    dramatic shifts in how data is processed ﬂexibly, efﬁciently and in a scalable

    way over distributed architectures and shared resources. The cloud computing

    market for healthcare itself is expected to reach $5.4 billion by 2017, according

    toMarketsAndMarkets[25],whereastheconceptsofDataasaService(DaaS),

    Software as a Service (SaaS), Platform as a Service (PaaS) and Infrastructure

    as a Service (IaaS) are examples of already highly adopted cloud services for

    bioinformatics data processing. This drives further research in various areas,

    which is now looking for example into declarative approaches for expressing

    programs to achieve transparency and optimizations of large and heteroge-

    neous cloud clusters on a global scale. Another research direction focuses

    on new communication technologies, such as Software Deﬁned Networking

    (SDN) and Software Design Data Centres (SDDC) intended to support the

    massive increases in Internet bandwidth and complexities introduced by IoT,

    which extend beyond bandwidth requirements and device count, such as

    lower latency, greater determinism and processing closer to the edge of the

    network [26]. The latter, known as fog or edge computing, is a step fur-

    ther towards coping with bandwidth and latency constraints as well as to

    support scalable distributed big data analysis using context-aware localized

    computing.

    In essence, fog computing capitalizes on the proliferation of smart devices

    with increasingly powerful processing capacities and moves some of the

    transactions and resources from the centre of the cloud to its edge and inven-

    tively reuses processing capacities of existing devices rather than establishing

    channels for cloud storage and utilization [27]. This aggregates selected data

    at a certain access point and localizes selected processes, hereby reducing

    the need for large bandwidth capacities on the cloud channels, processing

    delays and enormous data management capacities at central locations, and

    ﬁnally leading to improved efﬁciency and reduced costs. This approach is

    highly promising for IoT in general and including healthcare, and seems to

    be particularly well-suited for applications for which cloud-based approaches

    might be either less suitable or less feasible, for example applications that

    are latency-sensitive, highly distributed in geographic terms or fast-operating

    244

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    in near-real time, especially in Health 4.0 applications [16]. In addition, fog

    computing keeps the data at its source without sending it into global networks,

    which presents another crucial beneﬁts for healthcare, namely facilitating the

    software-to-data paradigm, which is recognized as the approach to be taken

    in healthcare to better cope with the security, privacy and data protection

    requirements as well as to reinsure the users about where their privacy-

    sensitive data is located [17]. Current approaches suggest the use of machine

    learning models to support the training process taking place on a fraction of

    data in the cloud, followed by localized and highly optimized data processing

    on a resource-constrained smart device, for example smartphone or embedded

    device, using techniques such as decision trees, fuzzy logic or deep belief

    network [28]. These new avenues of research, hand in hand with the rising

    5th generation of telecommunications networks (5G), represent promising

    advancements towards transformational patient-centred and quality-driven

    healthcare for the future.

    7.4.4 IoT Data Governance and Privacy Implications

    Along with increasing computerization tendencies towards “informated

    healthcare”, focus shifts on novel issues such as the governance of data

    ownership, data access control, accountability, security, and privacy. In a

    nutshell, challenges arise on questions such as who has access to the collected

    and stored data, how is it anonymised and/or de-personalized, and how non-

    repudiation of data exchange, possession and creation can be assured, which

    is a crucial prerequisite for the integrity and trust in the data at stake.

    Healthcare data is very speciﬁc data – unlike data which is collected for

    traditional purposes of e.g. commerce, transport, logistics, or control over

    manufacturing processes, healthcare data is a special kind of personal data,

    which is subject to detailed legal regulations, policies and jural decisions.

    Data used in the healthcare domain is often so-called personal data, which

    is a legal term denoting (1) any information, which is (2) relating to (3) an

    identiﬁed or identiﬁable (4) natural person. This legal concept is deliberately

    kept rather broad and lacks clear and direct applicability for information

    systems developers. There is a however a need to separately clarify whether

    or not a piece of data has to be considered personal data under the respective

    regulations. A good and substantiated overview on what constitutes personal

    data with regard to the EC Directive 95/46/EC (Data Protection Directive) and

    Directive 2002/58/EC (E-Privacy Directive) is provided by Opinion 4/2007 of

    the Data Protection Working Party [29], nevertheless, legal assistance might

    be advisable in order to determine how to treat data properly.

    7.4 IoT Analytics in Health and Social Care

    245

    Aside from the particularities emerging from legal data, system designers

    and developers must take into consideration that access to the thus collected

    and stored data might be requested by multiple heterogeneous stakeholders.

    The data subject, i.e. the person, who the data is about, is entitled to know

    which data is collected and to receive access to the collected data, to demand
    its

    rectiﬁcation, and in certain cases, its destruction. Aside from the data subject,

    access to the data in the healthcare domain can be requested by third parties

    for reasons of research, disease prevention/control, and for other purposes

    of governance bodies. Access to the collected personal data thus can be

    requested by a set of stakeholders with justiﬁed interest, which cannot be

    fully foreseen at design time of the information system. A further level of

    complexity is introduced, as the data subject is eligible to know with whom

    the data has been shared and who is in possession of its data, in order to

    demand deletion/rectiﬁcation of the data. The resulting constraints imply new

    demands to information system designers and developers, who need to take

    into account complex requirements, which might unforeseeably change in the

    future due to interventions by law [30].

    In order to accommodate for these constraints, new principles of data

    governance have been introduced in the past years, most importantly the

    concept of ﬁne grained access control (FGAC), and fair non-repudiable

    message exchange (FNR). FGAC refers to the ability of databases to govern

    access to core data based on access policies, which take into account the

    contents of the data query, the context of the request, and the identity of

    the requester. Unlike with traditional approaches, which categorize access

    permissions based on the pre-assigned role of the requester, FNR does not

    rely on roles, but rather on the complex context. Technologies for FNR have

    been described e.g., in [31] and [32] which focus on FNR technologies that

    utilize SQL query rewriting for governing access to the data. Standardization

    efforts have been conducted by OASIS, which provides the eXtensible

    Access Control Markup Language (XACML), while IBM introduced the

    Enterprise PrivacyAuthorization Language (EPAL). XACMLplays an impor-

    tant role also in the European Future Internet landscape, where a dedicated

    FIWARE Generic Enabler module aims to provide XACML to the IoT

    domain.

    Fair non-repudiation (FNR) reveals its utility when personal data between

    two entities must be exchanged in such way, that the exchange cannot be

    refuted by any of the participating parties. This way, a non-repudiable trace

    chain is coined, which then can be accessed by parties with a vested interest.

    A state-of-the-art summary on FNR has been provided in [33], where an

    246

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    internet-based approach is described for the direct message exchange between

    two technical systems.

    Combining FGAC and FNR enables the creation of sustainable technology

    for the governance of data in domains of healthcare, public governance, or

    public education, i.e. in domains, where governance of access to personal data

    is subject to public domain policies and inﬂuenced by the legal domain.

    7.5 IoT Analytics for Public Safety

    7.5.1 Introduction

    Today Internet of Things (IoT) technologies are transforming our living space

    into intelligent Smart Environments (Smart City, Smart Home, Smart Building

    etc.). Smart Environments are equipped with a variety of sensors for capturing

    informationandanalysingdataina‘SmartWay’,extractingactionableinsights

    and adapting their behaviour to the needs of the users. With the number of

    connected IoT devices growing into the billions – e.g., Cisco forecasts 50

    billion devices connected by 2020 [39] – IoT analytics start to become more

    and more popular because only raw sensor data are not sufﬁcient to deliver the

    right QoS to the users. Only if we can give a meaning to IoT data and extract

    the relevant information on the right abstraction level, the Internet of Things

    vision can become reality.

    7.5.1.1 IoT analytics

    Under the constraints of IoT system and the requirements from IoT applica-

    tions, analytics are playing an important role in the information lifecycle of

    IoT. Ultimately, IoT analytics enables to ﬁnd the relevant piece of information

    in the ﬂood of IoT data, identifying the anomalies that require attention,

    extracting the unknown patterns and helping to predict what is going to happen

    next.

    IoT analytics need to deal with the IoT system characteristics where the

    data are highly heterogeneous, dimensional, and unstructured, coming from

    various data sources even in different business domains. This creates new

    challenges in the analytics area where problems like data distribution, data

    reliability, real-time data processing and many others need to be addressed.

    In addition to that, IoT applications are also expecting a certain quality in
    the

    provided data, ranging from insightful statistic results and meaningful patterns

    for making planning and optimization to real-time predictions and suggestions

    for making timely or even automated decisions.

    7.5 IoT Analytics for Public Safety

    247

    Smart cities are a good example of large-scale IoT systems where IoT

    analytics is highly demanded with great potential to make beneﬁts. For exam-

    ple, there are about 12,000 sensors deployed in the city of Santander [34] that

    provides information about environmental conditions, parking availability,

    trafﬁc density, weather and irrigation information. Therefore, in today’s Smart

    Cities, there is already a large quantity of information, but by applying more

    advanced IoT analytics, more relevant information can be extracted.

    7.5.1.2 IoT analytics for public safety

    In following paragraphs, we explain the challenges of IoT analytics using

    Public Safety as the application domain, which is one of the most important

    aspects of a Smart City. Based on the results delivered by advanced IoT data

    analytics, we cannot only make city planning and operation smarter, but we can

    also improve and ensure the safety of citizens [35]. As the sensors deployed

    in Smart Cities monitor the city pulse and report various situations all around

    our cities in an 24 × 7 basis, potential safety problems can be identiﬁed early

    and be localized better, therefore effective actions can be taken in time to

    improve the safety and well-being of the citizens. Many studies show that,

    even with cheap but widely deployed sensors, important safety issues can be

    identiﬁed early and swiftly addressed, e.g. the formation of a crowd of people,

    the breakout of a ﬁre [40], a burst pipe [41] or a blocked street.

    One of the challenges for IoT analytics to enable Public Safety is to be able

    to sense and react to critical situations and mine raw sensor data in real-time.

    This is mainly because the raw sensor data are very noisy, heterogeneous,

    and high dimensional, which introduce many complexity and computation

    difﬁcultiestoextracthighqualityresultsinreal-time.Toaddressthischallenge,

    the following technical problems have been taken into account in our IoT

    analytics solutions for Public Safety.

    • Establishing dynamic communication channels: in a typical IoTsystem

    like Smart Cities, IoT data ﬂow from sensors to various analytics

    applications and then actionable results are derived. Automated actions

    are requested from deployed actuators. The ﬁrst problem to be solved

    for IoT analytics is to establish communication channels among sensors,

    analytics applications, and actuators, in a dynamic, ﬂexible, and scalable

    way, so that information ﬂow between different components can be easily

    ensured.

    • Dealing with big data in real time: Real-time is a very important aspect

    regarding Public Safety, because critical situations need to be detected

    248

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    immediately or to be predicted early enough. In this case, authorities

    will have enough time to take actions to avoid potential safety problems.

    For example, an algorithm of Crowd Detection must be fast enough

    to identify an emerging crowd situation and then trigger an alarm to

    inform authorities. To reduce the latency from generating raw data to

    taking actions, the following issues must be considered by IoT analytics:

    1) how to control the frequency of data generation; 2) where to do data

    pre-processing; 3) how to design algorithms for parallelized real-time

    data stream processing; 4) how to orchestrate resources in the cloud and

    at the edge to do scalable data processing.

    • Achieving actionable insights with good accuracy: results derived from

    IoT data must be actionable, meaning that the results are understandable,

    accurate and timely enough to allow authorities to make effective actions.

    If the results of Crowd Detection come one hour after the crowd event

    happens or most of the detected crowds are false positive, this type

    of analytics is not usable for enhancing the Public Safety. Therefore,

    efﬁcient and advanced machine learning or prediction algorithms must

    be used by IoT analytics to provide real-time feedback to the authorities.

    • Preserving user privacy: as data are collected from different sources,

    one obvious issue is the user privacy. Privacy protection and governance

    must be seriously taken into account from the start. This will affect the

    choice of our solutions.

    Of course, data and system security is another technical issue for IoT analytics,

    but it is not regarded as a key focuses of this paper. In the remainder of this

    paper,twospeciﬁcsolutionsareintroducedtoexplainhowweimprovedPublic

    Safety via IoT analytics for outdoor and indoor use cases.

    7.5.2 Crowd Detection Solution for a Safer City

    Efﬁcient emergency systems require a number of different technologies to

    monitor and detect dangerous events in real-time. Several problems arise in

    the design, implementation and development of such systems. One of the main

    problems that affect such systems is human behaviour in critical situations.

    Being able to detect dangerous situations and act in real-time is a need for

    enhancing people’s safety but is not an easy task due to the variety of the

    human behaviours. In this case, IoT analytics can help to fuse and mine sensor

    data from various installations to produce actionable insights. One example of

    IoT analytics’ solution is the privacy preserving Crowd Detection component

    from NEC.

    7.5 IoT Analytics for Public Safety

    249

    Concretely, the Crowd Detection core functionality is on understand-

    ing the dynamics of crowd. This requires in-depth understanding of how

    humans move in an indoor space over time. Most state of the art approaches

    are using video based crowd analysis. They face deployability issues on

    account of privacy regulations and the public’s perception of surveillance.

    Our approach is based on privacy preserving sensors, guaranteeing that no

    collected information can be used to identify an individual.

    In addition to the citizens’safety, our crowd analysis can provide relevant

    information for the design of public spaces, e.g., making shopping malls more

    comfortable for customers, enhancing their safety, or coordinating evacuation

    plans based on the real-time crowd behaviour. The Crowd Detection solution

    can also be used for automated detection of anomalies and alarms and is a

    prerequisite for assisting people during crowd emergencies.

    7.5.2.1 The privacy preserving approach

    The goal of our Crowd Detection solution is to provide real-time estimation

    regarding the crowd density in the target area. We focused on a solution for

    estimating crowd of people in an indoor scenario, taking into account privacy

    related issues and deployment costs. Using the sensor fusion approach, we

    are able to estimate the crowd density by sampling the area with carefully

    positioned sensors in the indoor environment, which will be used to measure

    the human activities and correlate them to the density of the crowd present on

    the scene. In addition, using more traditional sensors such as sound, pressure
    or

    CO2 sensors, inexpensive and privacy preserving infrared proximity sensors

    is a core part of our approach.

    Our solution has the advantage that it estimates the crowd levels with low

    cost sensors and without infringing any individual’s privacy rights. In fact,

    as Chan et al. describe in [36], there are various Crowd Detection solutions

    based on computer vision on the market, however privacy is a well-known

    problem for computer vision technologies for two reasons: ﬁrst, the perception

    of compromised privacy is particularly strong for technologies which record

    the people’s actions; second, current vision-based monitoring is usually based

    on object tracking or image primitives, both of which imply the identiﬁcation

    of the individuals.

    The NEC Crowd Detection solution has been deployed and tested for a

    trial in a Singapore shopping mall, where our system has been running for

    a period of two months and proving the feasibility of such solution. During

    the trial 23 sensors were deployed using a similar sensor installation plan as

    described in Figure 7.7 for estimating the crowd levels.

    250

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    Figure 7.7

    Example of sensor installation in a shopping mall.

    7.5.3 Mobile Operation Centres (MOC)

    The Crowd Detection solution shows how IoT can be used to enhance people

    safety for indoor environments. However, for big public events like the

    Football World Cup or the Olympics, IoT analytics is also required to preserve

    people safety. During such events, many agencies are collaborating to ensure

    the people safety. As more and more sensors are deployed in urban area

    by different city service departments like police, ﬁre department, homeland

    security etc., it is extremely important to share sensor information and derived

    situations across different agencies in order to improve the safety of such big

    events.

    Typically, a Central Control Centre is designed to deal with normal tasks

    but has limited amount of resource to handle big events. To overcome such a

    problem, the capabilities of the control centres can be enhanced by deploying

    mobile operation centres (MOC), which can be easily setup in a ﬁxed location.

    Traditionally, MOCs are equipped with voice communication and video cam-

    eras to capture critical situations. With the help of the IoT systems, we are
    able

    to capture more information about the real world using sensors that have been

    built into wearables devices, attached to the normal tools of a law enforcement

    ofﬁcers, or built into devices like cars, riot control barriers, entrance gates,

    etc. Still, human intelligence is needed to understand the situations and react

    to them even with the assistance of derived information from IoT analytics. In

    this context, ensuring dynamic information ﬂow between the physical world

    and different authorities is important for enhancing the people’s safety.

    NEC developed a Mobile Operational Centre (MOC) solution for inter-

    agency collaboration in a Smart City, which enables the dynamic data

    exchange of real-time sensor data streams between different agencies. The

    7.5 IoT Analytics for Public Safety

    251

    MOC is realized combining a dynamic and federated IoT system with an IoT

    discovery component [38], which is able to handle presence registration of

    resources with their locations, types etc., and an IoT broker [37], which is

    able to fetch data by querying/subscribing to the IoT discovery component

    and requesting data from the underlying data sources. In such system IoT

    analytics play a role of mining and visualizing the sensor data in real-time to

    be used within a dashboard shown in Figure 7.8.

    7.5.4 Conclusions and Outlook

    As sensors and actuators are becoming cheap and being widely deployed in

    modern cities like Santander in Spain and Chicago in US, the Internet of

    Things is now providing us great potential to improve our society in terms

    of safety, security, efﬁciency and equality by leveraging collected data. Our

    research goal in IoT analytics is turn collected data into actionable insights

    to improve and ensure Public Safety in various business domains. For Public

    Safety, the main challenge to be addressed is to sense critical situations and

    act on them in real-time. This paper introduced the major technical issues that

    we are trying to solve in the IoT analytics area, in terms of privacy-preserving,

    sensor data fusion, anomaly detection, and dynamic data exchange.

    Two concrete solutions have been presented in detail to explain how

    we improve Public Safety using IoT analytics techniques at different levels.

    Figure 7.8

    Mobile Operation Center Dashboard.

    252

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    Regarding the Crowd Detection system, additional advantages compared to

    the existing solutions are: the approach is privacy preserving, the amount

    of sensors required scales better with the area to be monitored and the cost

    of the individual sensors and computing nodes is considerably lower than

    the hardware commonly used in the state-of-the art. In addition to that, our

    solution estimate crowd levels in real-time and this is also an advantage for

    trigger quick actions and preserve the people safety without compromise their

    privacy.

    The second is the Mobile Operational Centre solution, enabling dynamic

    data exchange of real-time sensor data streams between different agencies.

    This can be used by city authorities like police ofﬁces to quickly enable

    inter-agency collaboration. Both solutions have been deployed and tested in

    Singapore as part of the Safer City solution.

    As future work, we intend to complement the current approaches by

    addressing additional challenges in the IoT analytics for Public Safety. In the

    case of Crowd Detection, we are exploring how reinforcement learning can

    improve the current solution in real-time without losing in system performance

    or how to distinguish the crowd estimation from other type of emergency

    without a human interaction. In addition to that, we are extending the Crowd

    Detection solution to outdoor areas exploring new techniques like Bluetooth

    and Wi-Fi monitoring.

    7.6 Towards a Positive Approach in Dealing with Privacy

    in IoT Data Analytics

    7.6.1 Introduction

    Businesses are looking for guidance on how to deal with big data in a

    responsible/legal way as they see the opportunities offered by big data, big

    data generation, collection, and analytics. IoT is a major driver in this, as

    “connected things” will generated endless streams of data that will be captured

    and used.According to the European Data Protection Supervisor Peter Hustinx

    (December 2014): “If big data operators want to be successful, they should

    invest in good privacy and data protection, preferably at the design stages of

    their projects”.

    While we want to beneﬁt from the value that IoT and its data have to offer,

    the key outcome should be “trust” by citizens and consumers. This requires

    that privacy and data protection are taken into account in every step of the

    development cycle of IoT technologies and services.

    7.6 Towards a PositiveApproach in Dealing with Privacy in IoTDataAnalytics

    253

    7.6.2 IoT and Privacy

    It is clear: in terms of pervasiveness, IoT has already contributed to the

    emergence of a society in which almost everything is or can be moni-

    tored, well beyond the des criptions as used by George Orwell in his book

    “1984” [42]. The novel is set in Airstrip One (formerly known as Great

    Britain), a province of the super state Oceania in a world of perpetual war,

    omnipresent government surveillance, and public manipulation, dictated by a

    political system euphemistically named English Socialism (or Ingsoc in the

    government’s invented language, Newspeak) under the control of a privileged

    Inner Party elite that persecutes all individualism and independent thinking

    as “thought crime”. “Big Brother is watching you”, and trust in society and

    freedom is sketched as very low (Figure 7.9). This book had a great inﬂuence

    of the thinking of a generation that grew up after World War 2 and reﬂects

    some of the thinking that is fundamental in the discussions about privacy.

    Now: whereas the levels of monitoring are very high and well beyond the

    imagination of Orwell in terms of what technically is possible, in Europe

    trust in government and society has remained at a relatively high level.

    When Snowden revealed, starting in June 2013, some evidence reﬂecting the

    pervasiveness of monitoring through numerous global surveillance programs,

    many of them run by the NSA and the Five Eyes1 with the cooperation of

    Figure 7.9

    1984, a society in which you can trust nobody – and “Big brother” sees it all,
    and

    a reality of pervasive monitoring by security forces in 2013 [43].

    1“Five Eyes”, often abbreviated as “FVEY”, refer to an intelligence alliance comprising

    Australia, Canada, New Zealand, the United Kingdom, and the United States that
    was formed.

    These countries are bound by the multilateral Agreement, a treaty for joint cooperation
    in

    signals intelligence.

    254

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    telecommunication companies and European governments, this resulted in

    widely expressed concern and even outrage by the general public, civil society

    and politicians.

    This led to a global discussion making clear that monitoring is a necessity,

    yet should not take place at all costs, and a balance is yet to be found. This

    results in a discussion that will continue to stretch over the decades to come.

    7.6.3 European Way Forward

    Within this setting, the discussion in Europe about privacy and data protection

    is ﬁnding its way, moving from a Directive on Data protection and privacy

    towards an anticipated General Data Protection Regulation. The reform aims

    to strengthen individual rights and tackle the challenges of globalisation and

    new technologies. It furthermore attempts to “simplify” compliance as the

    Regulation would become directly applicable law in all EU member states,

    whereas the Directive was implemented through national Privacy Acts in

    similar but not always identical ways.

    When the original Data Protection Directive was developed and agreed in

    1995, the Internet was by far not as important as today, and nobody had even

    mentioned the term “Internet of Things” yet. The current reform has been

    under way since 2011 and culminated in a Proposal to Council and Parliament

    by the European Commission on 25 January 2012.This proposal was approved

    by the European Parliament in March 2014, and, assuming that a compromise

    can be reached in the course of this year, is expected to come into force in 2017.

    It should be noted however that signiﬁcant differences still exist between the

    Commission, Council and Parliament, so that a consensus text in 2015 is not

    yet a certainty.

    7.6.4 Challenges Ahead

    Yet, when the Regulation was ﬁrst being discussed in 2011, “big data” was

    not yet a widely recognised issue. Today, we know that big data, and big

    data analytics, fundamentally challenge the concept of “personal data”. Big

    data analytics allows seemingly anonymous data to be linked together and

    correlated in order to allow individual persons to be identiﬁed. A recent

    Opinion from the Article 29 Working Party – Europe’s pre-eminent data

    protection body – recognises the value of IoT, but also the potential intrusions

    it can generate to privacy. In this Opinion, statements are made that alarmed

    businesses around the world, as what is suggested may put a lock on many

    current developments in the ﬁeld.

    7.6 Towards a PositiveApproach in Dealing with Privacy in IoTDataAnalytics

    255

    Legal uncertainty remains on many issues, even if it is clear that current

    law also applies to IoT applications used to collect or analyse personal data.

    Business are looking for guidance on this, as big data is a subject of interest

    to many, and companies around the world are looking into the opportunities

    offered by big data, big data generation, collection, and analytics.

    As already noted above, the European Data Protection Supervisor Peter

    Hustinx has stressed the importance of investment in solid privacy and

    data protection, and recognizes the role of “soft law” on this point. These

    investments can drive the innovation, development and deployment of IoT,

    and are a pre-condition for European (co-)sponsored research.

    7.6.5 Way Forward

    A way forward could include the habit/obligation of a Privacy Impact Assess-

    ment in the design stage of new IoT products and services, and conscious

    implementation of Privacy Enhancing Technologies and Methods from the

    outset when thinking of which (and how) data to collect, store, and share.

    This approach would ensure that new ideas are not hamstrung by regulation,

    but rather that a culture of privacy awareness and advance consideration

    is promoted: the impact of any new IoT solution on individuals should be

    considered prior to deployment, rather than as an issue that may require ﬁxing

    afterwards.

    We need IoTto deal with certain societal challenges.As IoTin combination

    with big data analytics brings a paradigm shift in ways that data can be related

    to people, it will take a number of years to come to a better understanding on

    how to deal with this.

    Legislation related to consumer protection, ranging from product safety,

    to product reliability, product information reliability and personal data pro-

    tection, tends to be static and oblivious to rapid technology shifts. We need
    to

    ensurethattheapplicationofthelawreﬂectsanunderstandingofthesensitivity

    of data in a big data and big data analytics context.

    From an innovation and deployment perspective, it will be important to

    design products and services in such a way that they can continue to serve

    (local?) society even if values and choices are different in different markets,

    and/or change over time.

    This requires transparency (what data are collected, in what way, how are

    they stored and unlocked, and who has access to it), accountability (if someone

    isnotusingthedatainacorrect,authorizedway–whoisaccountablefortaking

    action), and choice (can I adapt the settings related to IoTin my environment
    to

    256

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    my speciﬁc legal and cultural preferences?).This goes beyond mere regulatory

    actions, and requires greater awareness of where sensitive issues may emerge,

    and the implementation of robust and ﬂexible technological solutions that can

    be tailored to reﬂect these changes in society.

    7.6.6 Conclusions and Outlook

    It is highly important to ensure that our European privacy approach does not

    prevent the use of data, but rather that it prevents abuse of data – simply

    because:

    • Increasingly almost all data will be relatable to persons, from the outset,

    and we need to ﬁnd a way to deal with that responsibly;

    • We cannot afford not using data at large scale, both from societal

    perspective, and as there is clear commercial (thus economic) value;

    If Europe wants to beneﬁt from the emerging opportunities arising with

    IoT – and it is the opinion of the authors that this is a boat Europe cannot

    afford to miss – we will need to use data in a responsible way (both collecting,

    storage and sharing – and actively ﬁght abuse).

    “Going ethical” when building IoT products and services can bring us new

    growth and innovation and helps us to create a world we want our children

    to live in, respecting European values, including privacy but also and perhaps

    more importantly transparency and choice. The law cannot do it all for us. It
    is

    our own standards and ethics that will transform the world. Hence, legislation

    enabling, supporting and promoting these priorities is required.

    Ethicalbehaviorisaculturalthing:itneedstobeembraced,lived,inevery

    aspect of the business. It needs to be talked about and to be an explicit value.

    Ethics is a living thing and can only thrive when welcomed and constantly

    encouraged.

    Acknowledgment

    Part of the work described in Section 7.3 Cloud-Based IoT Big Data Plat-

    form has been carried out in the scope of the Horizon 2020 iKaaS project

    (iKaaS.com) (Grant Agreement number 643262).

    Bibliography

    [1] P. Barnaghi, A. Sheth, and C. Henson. “From Data to Actionable

    Knowledge: Big Data Challenges in the Web of Things”, IEEE Intelli-

    gent Systems, vol. 28, no. 6, pp. 6–11, Nov/Dec. 2013.

    Bibliography

    257

    [2] J. Gama, I. Zliobaite,A. Bifet, M. Pechenizkiy,A. Bouchachia. “Asurvey

    on concept drift adaptation”, ACM Computer Surveys 46, 4, article 44,

    2014.

    [3] P. Barnaghi et al. I. Borthwick. (editor), “Digital Technology Adoption

    in the Smart Built Environment”, IET Sector Technical Brieﬁng, The

    Institution of Engineering and Technology (IET),Technical report, March

    2015.

    [4] H. Karl and A. Willig. “Protocols and Architectures for Wireless Sensor

    Networks”, Wiley-Blackwell, 2007.

    [5] S. Nastic, S. Sehic, H. L. Truong, S. Dustdar. “Provisioning Software-

    deﬁned IoT Cloud Systems”, The 2nd Int. Conf. on Future Internet of

    Things and Cloud (FiCloud-2014), 2014.

    [6] M. Compton et al, “The SSN ontology of the W3C semantic sensor

    network incubator group”, Web Semantics: Science, Services and Agents

    on the World Wide Web, vol. 17, pp. 25–32, 2012.

    [7] J. Lin, E. Keogh, S. Lonardi. et al., “A Symbolic Representation of Time

    Series, with Implications for Streaming Algorithms”, Proceedings of the

    8th ACM SIGMOD workshop on Research issues in data mining and

    knowledge, 2003, pp. 2–11.

    [8] Y. Bengio,A. Courville, P. Vincent. “Representation Learning:AReview

    and New Perspectives”, IEEE Trans. PAMI, special issue Learning Deep

    Architectures, 2013.

    [9] P. Barnaghi, A. Sheth, A. Singh, M. Hauswirth. “Physical-Cyber-

    Social Computing: Looking Back, Looking Forward”, Guest Editors

    Introduction, IEEE Internet Computing, May/June, 2015.

    [10] Cisco, “Cisco Visual Networking Index: Global Mobile Data Trafﬁc

    ForecastUpdate2014–2019WhitePaper,”03-Feb-2015. [Online].Avail-

    able:http://www.cisco.com/c/en/us/solutions/collateral/service-provider

    /visual-networking-index-vni/white paper c11-520862.html.[Accessed:

    23-May-2015].

    [11] HM Government, “Personalised health and care 2020: a framework

    foraction,”13-Nov-2014.[Online].Available:https://www.gov.uk/gover

    nment/publications/personalised-health-and-care-2020/using-data-and-t

    echnology-to-transform-outcomes-for-patients-and-citizens. [Accessed:

    23-May-2015].

    [12] A. Bassi, M. Bauer, M. Fiedler, T. Kramp, R. van Kranenburg, S. Lange,

    and S. Meissner, Eds., Enabling things to talk: designing IoT solutions

    with the IoT architectural reference model; [Iot-A, Internet of things –

    architecture]. Heidelberg: Springer, 2013.

    258

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    [13] H. R. Schindler, J. Cave, N. Robinson, V. Horvath, P. Hackett, S.

    Gunashekar, M. Botterman, S. Forge, and H. Graux, Europe’s policy

    options for a dynamic and trustworthy development of the Internet of

    Things: SMART 2012/0053. Santa Monica, CA: RAND Corporation,

    2013.

    [14] EC: European Political Strategy Centre, “Ethics, science and technol-

    ogy,” 25-Mar-2015. [Online]. Available: http://ec.europa.eu/epsc/ege en

    .htm. [Accessed: 23-May-2015].

    [15] E. Niehaus, M. Herselman, and A. N. Babu, “Principles of Neuroempiri-

    cism and generalization of network topology for health service delivery,”

    Indian J. Med. Inform., vol. 4, no. 1, 2009.

    [16] O. Ferrer-Roca, R. Tous, and R. Milito, “Big and Small Data: The Fog,”

    2014, pp. 260–261.

    [17] C. Thuemmler, J. Mueller, S. Covaci, T. Magedanz, S. de Panﬁlis, T.

    Jell, and A. Gavras, “Applying the Software-to-Data Paradigm in Next

    Generation E-Health Hybrid Clouds,” in Proceedings of the 2013 10th

    International Conference on Information Technology: New Generations,

    Washington, DC, USA, 2013, pp. 459–463.

    [18] S. Nunna, A. Kousarida, M. Ibrahim, M. Dillinger, C. Thuemmler,

    H. Feussner, and A. Schneider, “Enabling Real-Time Context-Aware

    Collaboration through 5G and Mobile Edge Computing,” in Proceedings

    of Information Technology New Generations 2015, 2015.

    [19] R. Vargheese and H. Dahir, “An IoT/IoE enabled architecture frame-

    work for precision on shelf availability: Enhancing proactive shopper

    experience,” 2014, pp. 21–26.

    [20] N. Khan, “Fog Computing: Better Solutions for IT,” Int. J. Eng. Tech.

    Res., vol. 3, no. 2, Feb. 2015.

    [21] R. Bond, “Big Data and Healthcare,” Charles Russell Speachlys.

    [Online].Available: http://www.charlesrussellspeechlys.com/updates/pu

    blications/commercial-new/big-data-and-healthcare/?UTM SOURCE=

    MONDAQ&UTM MEDIUM=SYNDICATION&UTM CAMPAIGN=

    VIEW-ORIGINAL. [Accessed: 23-May-2015].

    [22] Deloitte, “Big data revolution: six trends unlocking the power of health

    care analytics,” A view from the Center, 10-Feb-2014. [Online]. Avail-

    able: http://blogs.deloitte.com/centerforhealthsolutions/2014/02/big-dat

    a-revolution-six-trends-unlocking-the-power-of-health-care-analytics.ht

    ml#.VWB75HuJgb4. [Accessed: 23-May-2015].

    Bibliography

    259

    [23] C. Tan, L. Sun, and K. Liu, “Big Data Architecture for Pervasive Health-

    care: A Literature Review,” presented at the 23rd European Conference

    on Information Systems, Muenster, 2015.

    [24] MarketsAndMarkets, “Healthcare Mobility Solutions Market by Prod-

    ucts & Services (Mobile Devices, Mobile Apps, Enterprise Plat-

    forms),Application (Patient Care, Operations, Workforce Management),

    End Users (Payers, Providers, Patients) – Global Forecast to 2020,”

    May 2015.

    [25] MarketsAndMarkets, “Global Healthcare Cloud Computing Market

    worth $5.4 Billion by 2017.” [Online].Available: http://www.marketsand

    markets.com/PressReleases/cloud-computing-healthcare.asp

    [26] F. Fernandez and G. C. Pallis. “Opportunities and challenges of the

    Internet of Things for healthcare: Systems engineering perspective,”

    in Wireless Mobile Communication and Healthcare (Mobihealth), 2014

    EAI 4th International Conference on, 2014, pp. 263–266.

    [27] A. Banafa, “Fog Computing: From the Center to the Edge of the Cloud,”

    New Trends in Hi Tech, 22-Aug-2014.

    [28] M. Ectors, “Fog Computing Might Save Operators From an IoT Data

    Tsunami,” DZone: Smart Content for Tech Professionals, 07-Feb-2014.

    [29] Data Protection Working Party, “Opinion 4/2007 on the concept of

    personal data.” 20-Jun-2007.

    [30] A. Paulin. “Towards Self-Service Government – A Study on the Com-

    putability of Legal Eligibilities,” J. Univers. Comput. Sci., vol. 19,

    no. 12, pp. 1761–1791, Jun. 2013.

    [31] E. Bertino, G. Ghinita, and A. Kamra. Access control for databases

    concepts and systems. Boston: Now, 2011.

    [32] A. Paulin, “Towards the Foundation for Read-Write Governance of

    Civilizations,” in Third International Conference on Software, Services

    and Semantic Technologies S3T 2011, vol. 101, D. Dicheva, Z. Markov,

    and E. Stefanova, Eds. Berlin, Heidelberg: Springer, 2011, pp. 95–102.

    [33] A. Paulin and T. Welzer. “A Universal System for Fair Non-Repudiable

    Certiﬁed e-Mail without a Trusted Third Party,” Comput. Secur., 2013.

    [34] L. Sanchez, R. Ramdhany, A. Gluhak, S. Krco, E. Theodoridis, D.

    Pﬁsterer, L. Mu˜noz; J. A. Galache, P. Sotres, J. R. Santana, V. Gutierrez.

    SmartSantander: IoT Experimentation over a Smart City Testbed.

    [35] NEC public safety whitepaper [Online]: http://www.nec.com/en/global/

    solutions/safety/pdf/Safer Cities WP.pdf

    260

    IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts

    [36] Chan,AntoniB.,Z-SJLiang,andNunoVasconcelos.“Privacypreserving

    crowd monitoring: Counting people without people models or tracking.”

    IEEE Conference on Computer Vision and Pattern Recognition (CVPR),

    2008.

    [37] NEC IoT Broker component [Online]: https://github.com/Aeronbroker/

    Aeron

    [38] M. Bauer and S. Longo. “Geographic Service Discovery for the Internet

    of Things.” Ubiquitous Computing and Ambient Intelligence. Person-

    alisation and User Adapted Services. Springer International Publishing,

    2014. 424–431.

    [39] Cisco IoT Forecast [Online]: http://share.cisco.com/internet-ofthings

    .html

    [40] H. Soliman, K. Sudan, A. Mishra. A smart forest-ﬁre early detection

    sensory system: Another approach of utilizing wireless sensor and neural

    networks, IEEE Sensors, vol., no., pp. 1900, 1904, 1–4 Nov. 2010.

    [41] NEC water leak detection service [Online]: http://www.nec.com/en/

    global]/solutions/waterloss-management/

    [42] G. Orwell. Nineteen Eighty-Four. A novel. London: Secker & Warburg,

    1949.

    [43] G. Farvell., http://www.csmonitor.com/Commentary/Monitor-Political-

    Cartoons, retrieved 10 Jan. 2015.

    '
  inline_citation: '>'
  journal: River Publishers eBooks
  limitations: '>'
  pdf_link: https://api.taylorfrancis.com/content/chapters/oa-edit/download?identifierName=doi&identifierValue=10.1201/9781003337454-7&type=chapterpdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'IoT Analytics: Collect, Process, Analyze, and Present Massive Amounts of
    Operational Data – Research and Innovation Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/access.2023.3294985
  analysis: '>'
  authors:
  - Devika Menon
  - B. Anand
  - Chiranji Lal Chowdhary
  citation_count: 1
  full_citation: '>'
  full_text: '>

    IEEE.org IEEE Xplore IEEE-SA IEEE Spectrum More Sites 404: Page Not Found The
    page you were looking for could not be found. Browse or search IEEE Xplore to
    continue. Email us at onlinesupport@ieee.org for further assistance. © Copyright
    2024 IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Access
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6287639/6514899/10182252.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: 'Digital Twin: Exploring the Intersection of Virtual and Physical Worlds'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.36227/techrxiv.24045951.v1
  analysis: '>'
  authors:
  - Nwamaka U. Okafor
  citation_count: 0
  full_citation: '>'
  full_text: '>

    LOG IN SIGN UP TechRxiv 9,104,714 views 4,234,902 downloads About TechRxiv TechRxiv
    (pronounced "tech archive") is an open, moderated preprint server for unpublished
    research in the areas of engineering, computer science, and related technology.
    https://www.techrxiv.org/ Public Documents 9033 Members by author by title by
    keyword Filter All Sort by Most Recent BIOENGINEERING 865 COMMUNICATION, NETWORKING
    AND BROADCAST TECHNOLOGIES 2267 COMPONENTS, CIRCUITS, DEVICES AND SYSTEMS 1058
    COMPUTING AND PROCESSING 3333 ENGINEERED MATERIALS, DIELECTRICS AND PLASMAS 246
    ENGINEERING PROFESSION 541 FIELDS, WAVES AND ELECTROMAGNETICS 845 GENERAL TOPICS
    FOR ENGINEERS 643 GEOSCIENCE 265 NUCLEAR ENGINEERING 69 PHOTONICS AND ELECTROOPTICS
    342 POWER, ENERGY AND INDUSTRY APPLICATIONS 1192 ROBOTICS AND CONTROL SYSTEMS
    874 TRANSPORTATION 382 AEROSPACE 264 SIGNAL PROCESSING AND ANALYSIS 1935 OOC ADC:
    A Novel Three-Step Technique for Analog-to-Digital Conversion Guo-Liu Zhang March
    22, 2024 This paper explore the Off-on Cycle ADC (OOC ADC), an innovative analog-to-digital
    conversion (ADC) technique that significantly simplifies the analog-to-digital
    conversion process by accomplishing it through just three steps: inputting the
    analog signal, triggering the probe’s dip-and-reset motion (PDR), and outputting
    the binary digital signal. Initially, the paper establishes a theoretical foundation
    for subsequent ADC design by introducing the Off-on Cycle principle (OOC principle)
    in binary encoding rules. Subsequently, it illustrates the design concepts and
    operational principles of the OOC ADC through the illustrative example of a 4-bit
    precision OOC ADC design. Finally, the paper compares the superior performance
    of the OOC ADC over existing ADCs in terms of conversion rate, resolution, process
    complexity, and power consumption. The research findings in this paper have the
    potential to drastically reduce the technical difficulties involved in analog-to-digital
    conversion, facilitate technological advancements in the realm of digital signal
    processing. Smooth Scenario-Based Model Predictive Control for Autonomous Collision
    Avoidance in... Dhanika Mahipala and 1 more March 25, 2024 The Scenario-Based
    Model Predictive Control (SB-MPC) is an autonomous collision avoidance algorithm
    primarily designed for open and coastal waters. One of the challenges in adapting
    SB-MPC for autonomous inland waterway collision avoidance is the inability to
    use a derivative based optimization strategy due to non-smooth components in its
    cost function. Hence, we propose a novel algorithm, Smooth Scenario-Based Model
    Predictive Control (Smooth-SBMPC) specifically designed for highly constrained
    and complex navigational environments inherent to inland waterways. The effectiveness
    of Smooth-SBMPC is validated through a comprehensive simulation study, providing
    insights into its performance in complex navigational environments. Geometrical
    Pruning of the First Order Regular Perturbation Kernels of the Manakov Eq... Astrid
    Barreiro and 2 more March 25, 2024 We propose an approach for constraining the
    set of nonlinear coefficients of the conventional first-order regular perturbation
    (FRP) model of the Manakov Equation. We identify the largest contributions in
    the FRP model and provide geometrical insights into the distribution of their
    magnitudes in a three-dimensional space. As a result, a multi-plane hyperbolic
    constraint is introduced. A closed-form upper bound on the constrained set of
    nonlinear coefficients is given. We also report on the performance characterization
    of the FRP with multiplane hyperbolic constraint and show that it reduces the
    overall complexity with minimal penalties in accuracy. For a 120 km standard single-mode
    fiber transmission, at 60 Gbaud with DP-16QAM, a complexity reduction of 93% is
    achieved with a performance penalty below 0.1 dB. Dynamic Selection of Physical
    Channels for Adaptive Improvement of Link Quality Using... Ryan S. Westafer and
    3 more March 25, 2024 This paper describes integration of a software defined antenna
    (SDA) and a software defined radio (SDR) to enable dynamic and automatic selection
    of physical propagation channels. The SDA, an agile aperture antenna (A3), provides
    monolithic microdiversity, i.e. multiple antenna states within a single structure
    and within a space having maximum dimension of approximately one wavelength. In
    this way physical channel selection occurs outside, and therefore augmenting,
    the front-end electronics. The independent controllable parameters for channel
    access include: frequency, polarization (full Poincaré sphere), and pattern (in
    two dimensions). Several different tests were conducted to maximize a quality
    figure of merit calculated by the radio. Both library-based and evolutionary search
    techniques were used, resulting in short term channel improvements on the order
    of 10 dB, and long term fully optimized improvements on the order of 20 dB. Dataset
    for OPEC Crude Oil Trade Network Saumya Vilas Roy and 1 more March 25, 2024 Quantification
    and analysis of global oil trade networks reveals deep insights into a nation''s
    development and influence at a global scale. Further, it allows us to predict
    future trends and changes to adapt state policy as the crude oil market influences
    the balance of power among the developed and emerging economies alike as it is
    central for energy needs as well for industrial progress. This document is a dataset
    descriptor for the dataset of crude oil exports from OPEC nations to importing
    nations/regions from a period of (2016-2022) structured for easy formation of
    nodes and edges sourced from various sources referenced below also it contains
    the average closing price per barrel and the global demand of crude oil during
    a fiscal year to note and understand complex relations between the global oil
    trade.The data-set is available at https://dx.doi.org/10.21227/m8ds-nd06.The authors
    can be contacted for the access to dataset as well. Passive Actuator-Less Gripper
    for Pick-and-Place of a Piece of Fabric Akira Seino and 3 more March 25, 2024
    In this paper, we propose a Passive Actuator-Less Gripper (PALGRIP) for picking
    a piece of fabric from a stack of fabric parts and placing the picked fabric part.
    The picking of a piece of fabric from a stack is a simple but difficult process
    to automate. The proposed gripper can pick a piece of fabric from the stack by
    simply pressing the fingertips of the gripper against the stack. The fingers are
    closed and opened by the relative motion between the fingers and the housing of
    the gripper. The grasping motion of the gripper is generated by two mechanisms:
    a passive pinching mechanism and a selflocking mechanism. These mechanisms allow
    the fingers to perform open and close movements and to maintain the fingers in
    either open or closed state. The kinematics of the mechanisms are analyzed to
    design the gripper. The relation between the movement of the fingers and the force
    required to operate the gripper is also investigated through static force analysis
    and the experiment. Finally, experiments using PALGRIP are conducted, and the
    experimental results illustrate how the pick-and-place operations are carried
    out using the prototype of PALGRIP. The proposed gripper allows the robot to automate
    fabric pick-andplace operations easily by attaching it to the robot''s endpoint.
    Triaxial 3D-Channeled Soft Optical Sensor for Tactile Robots Matteo Lo Preti and
    3 more March 19, 2024 Soft optical transducers have the potential to fulfill the
    need for advanced tactile sensing in robotics. We present a fingertipshaped soft
    sensor with optically transparent channels that relies on soft materials and sensor
    morphology to measure an applied triaxial force. The proposed 3D-channeled sensor
    has a volume of 2.5 cm3 , and experimental results reveal a fifteen-fold increase
    in voltage compared to its bulk analogous, showcasing a sensitivity of 0.34 N/mV
    and 0.09 N/mV to tangential and normal forces. A prototype with a diameter of
    2 mm (0.4x) indicates the feasibility of scaling down the sensor. Force magnitude
    is estimated with a linear model and then decomposed into its Fxy and Fz with
    an R2 of 0.93 and 0.98 within a sensing range of 4.05 N and 8.50 N, respectively.
    A coordinate transformation from a covariant to a cartesian reference frame is
    used to retrieve the direction of the tangential component of the force. The sensor
    was integrated into a compliant robotic hand as a proof-of-concept to demonstrate
    its real-time operation and suitability for grasping, paving the way for advancements
    in soft tactile sensors that can be embedded in soft robots. Distributed Nonlinear
    Model Predictive Control for a Quadrotor UAV Bilal Mubdir and 1 more March 19,
    2024 A Distributed Nonlinear Model Predictive Control (DNMPC) approach is proposed
    to control the simplified decoupled dynamics of a quadrotor UAV. The performance
    of DNMPC is compared, in terms of tracking and execution time, to that of standard
    control configurations based on centralized MPC and PID control aiming to show
    the suitability of each configuration in terms of performance and the practicality
    of using a particular configuration in real-time applications. The results show
    the advantage of using DN-MPC in terms of ease of tuning and computational cost
    over more centralized feedback control approaches. Indoor Localization based on
    Short-Range Radar and Rotating Landmarks Kolja Thormann and 2 more March 19, 2024
    A novel concept for indoor self-localization based on relative position measurements
    to rotating artificial landmarks (with known positions) using short-range radar
    is proposed. This includes a complete processing pipeline for extracting distance
    and angle measurements from the raw radar data, which consists of a neural network
    for distance estimation, a basic angle-of-arrival estimator, and a particle filter
    for position tracking. Due to the ability of radar to measure range rate, i.e.,
    the velocity in the direction of a detection, it is possible to robustly detect
    the landmarks by detecting and localizing their micro-Doppler pattern. This mean
    localization is possible even under difficult conditions (e.g., light changes).
    Experiments with a wheeled mobile robot and common office fans as landmarks demonstrate
    the effectiveness of the approach for indoor localization. Planning Stories Neurally
    Rachelyn Farrell and 1 more March 19, 2024 Symbolic planning algorithms and large
    language models have different strengths and weaknesses for story generation,
    suggesting hybrid models might leverage advantages from both. Others have proposed
    using a language model in combination with a partial order planning style algorithm
    to avoid the need for a handwritten symbolic domain of actions. This paper offers
    a complementary approach. We use a state space planning algorithm to plan coherent
    multi-agent stories in symbolic domains, with a language model acting as a guide
    to estimate which events are worth exploring first. We evaluate an initial implementation
    of this method on a set of benchmark problems and find that the LLM''s guidance
    is helpful to the planner in most domains. Automated Loop Fusion for Image Processing
    Madushan Abeysinghe and 3 more March 19, 2024 In this paper, we develop a method
    for automatically selecting groups of loops to fuse in an image processing data
    flow graph, here referred to as a "fusing configuration". The method is designed
    for use on Digital Signal Processors (DSP), many of which rely on statically scheduled
    Very Long Instruction Word architecture. Selection is guided by a heuristic instruction
    scheduler that serves as a performance model for a candidate configuration. We
    show that for synthetically generated graphs of size 2 to 10 nodes, this approach
    is capable of selecting the optimal fusing configuration in 80% of graphs and
    selects a configuration that achieves within 10% of the performance of the optimal
    configuration for 90% of graphs. A Lyapunov-based Approach to Nonlinear Programming
    and Its Application to Nonlinear M... Kyunghwan Choi and 1 more March 19, 2024
    A tuning-parameter-free and matrix-inversionfree solution of nonlinear programming
    (NLP) problems is proposed. The key idea is to design an update law based on Lyapunov
    analysis to satisfy the first-order necessary conditions for optimality. To this
    aim, first, the Lyapunov function is defined as the summation of the norms of
    these conditions. Then, the desired optimization variables and Lagrange multipliers,
    which minimize the Lyapunov function the most, are found analytically, thereby
    rapidly approaching the necessary conditions. The proposed method neither requires
    tuning parameters nor matrix inversions; thus, it can be implemented easily with
    less iterations and computational load than conventional methods, such as sequential
    quadratic programming (SQP) and augmented Lagrangian method (ALM). The effectiveness
    of the proposed method is applied to and validated by using it to solve a nonlinear
    model predictive torque control (NMPTC) problem in electrical drives. The results
    are compared with those of SQP and ALM. Vectorized Highly Parallel Density-based
    Clustering for Applications with Noise Joseph Xavier Arnold and 7 more March 19,
    2024 Clustering in data mining involves grouping similar objects into categories
    based on their characteristics. As the volume of data continues to grow and advancements
    in highperformance computing evolve, a critical need has emerged for algorithms
    that can efficiently process these computations and exploit the various levels
    of parallelism offered by modern supercomputing systems. Exploiting Single Instruction
    Multiple Data (SIMD) instructions enhances parallelism at the instruction level
    and minimizes data movement within the memory hierarchy. To fully harness a processor''s
    SIMD capabilities and achieve optimal performance, adapting algorithms for better
    compatibility with vector operations is necessary. In this paper, we introduce
    a vectorized implementation of the Density-based Clustering for Applications with
    Noise (DBSCAN) algorithm suitable for the execution on both shared and distributed
    memory systems. By leveraging SIMD, we enhance the performance of distance computations.
    Our proposed Vectorized HPDBSCAN (VHPDBSCAN) demonstrates a performance improvement
    of up to two times over the state-of-the-art parallel version, Highly Parallel
    DBSCAN (HPDBSCAN), on the ARM-based A64FX processor on two different datasets
    with varying dimensions. Additionally, we evaluate VHPDBSCAN''s energy consumption
    on the A64FX and Intel Xeon processors. The results show that the proposed implementation
    reduces energy consumption by a factor of two on the A64FX Central Processing
    Unit (CPU) and by approximately 19.5% on the Intel Xeon 8368 CPU compared to previous
    methods. UWB Security and Enhancements K. Reaz and 13 more March 19, 2024 Ultra-Wideband
    (UWB) technology re-emerges as a groundbreaking ranging technology with its precise
    microlocation capabilities and robustness. However, the security aspects of UWB
    technology demand thorough scrutiny due to its widespread use in both consumer
    and industrial sectors. This white paper highlights the security dimensions of
    UWB technology, focusing in particular on the intricacies of device fingerprinting
    for authentication, examined through the lens of state-of-the-art machine learning
    techniques. Furthermore, we explore various potential enhancements to the UWB
    standard that could realize a sovereign UWB data network. We argue that UWB data
    communication holds significant potential in healthcare and ultra-secure environments,
    where the use of the common unlicensed 2.4 GHz band-centric wireless technology
    is limited or prohibited. A sovereign UWB network could serve as an alternative,
    providing secure localization and short-range data communication in such environments.
    Data-Driven Insights: Boosting Algorithms to Uncover Electricity Theft Patterns
    in AM... Inam Ullah Khan and 3 more March 19, 2024 This study introduces a sophisticated
    supervised machine learning method for electric theft detection utilizing a customized
    Histogram Gradient Boosting (HGB) algorithm. Comprehensive preprocessing, including
    imputation, normalization, outlier management, and resampling, ensures the timeseries
    data is accurately prepared for analysis. The SMOTE-ENN algorithm corrects class
    imbalances, preparing the data for the feature optimization stage where crucial
    features are selected and extracted. The HGB algorithm, enhanced through Bayesian
    optimization, is central to the training process, resulting in a model that precisely
    classifies electricity consumption patterns as genuine or fraudulent. The robustness
    of the model is assessed against other recognized boosting methods, such as Adaptive
    Boosting (ADB), Gradient Boosting Decision Tree (GBDT), and LightGBM, alongside
    various ensemble and traditional machine learning models. Utilizing key performance
    metrics like accuracy, F1 score, and AUC for validation, the proposed model yields
    very promising results, with a 93% accuracy, 95% F1 score, and 98% AUC, outperforming
    the comparison group under similar dataset and hyperparameter conditions. This
    underscores the model''s potential as a highly accurate tool for combating electricity
    theft within an advanced metering infrastructure (AMI). Software Metrics in Agile
    Software Development: A Review Report Muhammad Faizan Berlas March 19, 2024 Modern
    software systems intensively use the Agile software development processes for
    their development and maintenance. The Agile development methodology encourages
    customer satisfaction, early incremental delivery, and overall development simplicity.
    Agile development methods accept changes in requirements and technology and use
    a more adaptive or iterative approach to planning. With the adaptation of Agile
    process models in the development of modern software systems, there is a need
    for continuous improvement in the Agile processes. Agile development processes
    are modified and upgraded by utilizing software metrics. There are several proposed
    software metrics for measuring performance and quality in Agile software development.
    These include customer satisfaction, story point estimation, velocity, test coverage,
    defects in production, and other metrics. Each software metric has its own merits
    and demerits. This research aims to provide a comprehensive review of published
    research work on software metrics. Specifically, it summarizes the software metrics
    used for measuring the performance of Agile process models. This research paper
    will help understand the usefulness of various software metrics used in Agile
    development, and it will serve as a foundation for future research in software
    metrics for Agile software development. Model-Based Systems Engineering Applied
    to Engineering Learning Analytic Systems (ELA... Pallavi Singh and 2 more March
    19, 2024 Engineering education is a complex that involves multiple stakeholders,
    including students, educators, administrators, and industry partners. It is continuously
    evolving to meet the demands of modern industry and society. The traditional teaching
    and learning methodologies are being replaced by a more integrated skillset that
    focuses on developing students'' cognitive, social, and emotional skills. The
    shift towards this integrated approach is gaining momentum, and it is important
    to have a framework that has been proven to solve complex systems. The usage of
    systems engineering tools to model engineering education systems is not often
    seen. In this paper, a novel application of Model-Based Systems Engineering using
    Systems Modeling Language (SysML) to develop an Engineering Learning Analytic
    System (ELAS) framework that consists of multi-dimensional elements related to
    educational systems. The core of this study involves a rigorous Requirements Verification
    and Validation (V&V) process to ensure stakeholder needs which systematically
    were map with system capabilities. ELAS model simulations provided predictive
    insights into soft skill development, enabling decision-making via targeted interventions
    that could significantly enhance students'' skill sets. ELAS highlights that a
    data-driven approach, enabled by SysML, significantly enhances the ability to
    enact timely by relevant interventions at various levels of the educational management
    process. The proposed ELAS model offers a strategic blueprint for continuous improvement
    within educational institutions, demonstrating a pathway toward a responsive and
    self-improving educational system. The refining of the ELAS model, for broadening
    simulation scopes, and further integrating predictive analytics into administrative
    decision-making processes is an ongoing endeavor. Multi-Discounting Reinforcement
    Learning Based on Reward Decomposition Pengbin Chen and 4 more March 18, 2024
    A document by pengbin chen. Click on the document to view its contents. ← Previous
    1 2 3 4 5 6 7 8 9 … 501 502 Next → TechRxiv | Powered by Authorea.com Home About
    Submission Guidelines FAQs Terms of Use Privacy Policy Contact Us'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://www.techrxiv.org/articles/preprint/Advances_and_Challenges_in_IoT_Sensors_Data_Handling_and_Processing_in_Environmental_Monitoring_Systems/24045951/1/files/42163443.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Advances and Challenges in IoT Sensors Data Handling and Processing in Environmental
    Monitoring Systems
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1109/jiot.2019.2894196
  analysis: '>'
  authors: []
  citation_count: 0
  full_citation: '>'
  full_text: '>

    This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Subscribe Donate Cart Create Account
    Personal Sign In Personal Sign In * Required *Email Address *Password Forgot Password?
    Sign In Don''t have a Personal Account? Create an IEEE Account now. Create Account
    Learn more about personalization features. IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved.'
  inline_citation: '>'
  journal: IEEE Internet of Things Journal
  limitations: '>'
  pdf_link: https://ieeexplore.ieee.org/ielx7/6488907/8614370/08620612.pdf
  publication_year: 2018
  relevance_score1: 0
  relevance_score2: 0
  title: 2018 IndexIEEE Internet of Things JournalVol. 5
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.36227/techrxiv.19642977
  analysis: '>'
  authors:
  - Chintan Patel
  - Shubham Vyas
  - Pallabi Saikia
  - Denish kalariya
  - naman parmar
  citation_count: 0
  full_citation: '>'
  full_text: '>

    LOG IN SIGN UP TechRxiv 9,104,714 views 4,234,902 downloads About TechRxiv TechRxiv
    (pronounced "tech archive") is an open, moderated preprint server for unpublished
    research in the areas of engineering, computer science, and related technology.
    https://www.techrxiv.org/ Public Documents 9033 Members by author by title by
    keyword Filter All Sort by Most Recent BIOENGINEERING 865 COMMUNICATION, NETWORKING
    AND BROADCAST TECHNOLOGIES 2267 COMPONENTS, CIRCUITS, DEVICES AND SYSTEMS 1058
    COMPUTING AND PROCESSING 3333 ENGINEERED MATERIALS, DIELECTRICS AND PLASMAS 246
    ENGINEERING PROFESSION 541 FIELDS, WAVES AND ELECTROMAGNETICS 845 GENERAL TOPICS
    FOR ENGINEERS 643 GEOSCIENCE 265 NUCLEAR ENGINEERING 69 PHOTONICS AND ELECTROOPTICS
    342 POWER, ENERGY AND INDUSTRY APPLICATIONS 1192 ROBOTICS AND CONTROL SYSTEMS
    874 TRANSPORTATION 382 AEROSPACE 264 SIGNAL PROCESSING AND ANALYSIS 1935 OOC ADC:
    A Novel Three-Step Technique for Analog-to-Digital Conversion Guo-Liu Zhang March
    22, 2024 This paper explore the Off-on Cycle ADC (OOC ADC), an innovative analog-to-digital
    conversion (ADC) technique that significantly simplifies the analog-to-digital
    conversion process by accomplishing it through just three steps: inputting the
    analog signal, triggering the probe’s dip-and-reset motion (PDR), and outputting
    the binary digital signal. Initially, the paper establishes a theoretical foundation
    for subsequent ADC design by introducing the Off-on Cycle principle (OOC principle)
    in binary encoding rules. Subsequently, it illustrates the design concepts and
    operational principles of the OOC ADC through the illustrative example of a 4-bit
    precision OOC ADC design. Finally, the paper compares the superior performance
    of the OOC ADC over existing ADCs in terms of conversion rate, resolution, process
    complexity, and power consumption. The research findings in this paper have the
    potential to drastically reduce the technical difficulties involved in analog-to-digital
    conversion, facilitate technological advancements in the realm of digital signal
    processing. Smooth Scenario-Based Model Predictive Control for Autonomous Collision
    Avoidance in... Dhanika Mahipala and 1 more March 25, 2024 The Scenario-Based
    Model Predictive Control (SB-MPC) is an autonomous collision avoidance algorithm
    primarily designed for open and coastal waters. One of the challenges in adapting
    SB-MPC for autonomous inland waterway collision avoidance is the inability to
    use a derivative based optimization strategy due to non-smooth components in its
    cost function. Hence, we propose a novel algorithm, Smooth Scenario-Based Model
    Predictive Control (Smooth-SBMPC) specifically designed for highly constrained
    and complex navigational environments inherent to inland waterways. The effectiveness
    of Smooth-SBMPC is validated through a comprehensive simulation study, providing
    insights into its performance in complex navigational environments. Geometrical
    Pruning of the First Order Regular Perturbation Kernels of the Manakov Eq... Astrid
    Barreiro and 2 more March 25, 2024 We propose an approach for constraining the
    set of nonlinear coefficients of the conventional first-order regular perturbation
    (FRP) model of the Manakov Equation. We identify the largest contributions in
    the FRP model and provide geometrical insights into the distribution of their
    magnitudes in a three-dimensional space. As a result, a multi-plane hyperbolic
    constraint is introduced. A closed-form upper bound on the constrained set of
    nonlinear coefficients is given. We also report on the performance characterization
    of the FRP with multiplane hyperbolic constraint and show that it reduces the
    overall complexity with minimal penalties in accuracy. For a 120 km standard single-mode
    fiber transmission, at 60 Gbaud with DP-16QAM, a complexity reduction of 93% is
    achieved with a performance penalty below 0.1 dB. Dynamic Selection of Physical
    Channels for Adaptive Improvement of Link Quality Using... Ryan S. Westafer and
    3 more March 25, 2024 This paper describes integration of a software defined antenna
    (SDA) and a software defined radio (SDR) to enable dynamic and automatic selection
    of physical propagation channels. The SDA, an agile aperture antenna (A3), provides
    monolithic microdiversity, i.e. multiple antenna states within a single structure
    and within a space having maximum dimension of approximately one wavelength. In
    this way physical channel selection occurs outside, and therefore augmenting,
    the front-end electronics. The independent controllable parameters for channel
    access include: frequency, polarization (full Poincaré sphere), and pattern (in
    two dimensions). Several different tests were conducted to maximize a quality
    figure of merit calculated by the radio. Both library-based and evolutionary search
    techniques were used, resulting in short term channel improvements on the order
    of 10 dB, and long term fully optimized improvements on the order of 20 dB. Dataset
    for OPEC Crude Oil Trade Network Saumya Vilas Roy and 1 more March 25, 2024 Quantification
    and analysis of global oil trade networks reveals deep insights into a nation''s
    development and influence at a global scale. Further, it allows us to predict
    future trends and changes to adapt state policy as the crude oil market influences
    the balance of power among the developed and emerging economies alike as it is
    central for energy needs as well for industrial progress. This document is a dataset
    descriptor for the dataset of crude oil exports from OPEC nations to importing
    nations/regions from a period of (2016-2022) structured for easy formation of
    nodes and edges sourced from various sources referenced below also it contains
    the average closing price per barrel and the global demand of crude oil during
    a fiscal year to note and understand complex relations between the global oil
    trade.The data-set is available at https://dx.doi.org/10.21227/m8ds-nd06.The authors
    can be contacted for the access to dataset as well. Passive Actuator-Less Gripper
    for Pick-and-Place of a Piece of Fabric Akira Seino and 3 more March 25, 2024
    In this paper, we propose a Passive Actuator-Less Gripper (PALGRIP) for picking
    a piece of fabric from a stack of fabric parts and placing the picked fabric part.
    The picking of a piece of fabric from a stack is a simple but difficult process
    to automate. The proposed gripper can pick a piece of fabric from the stack by
    simply pressing the fingertips of the gripper against the stack. The fingers are
    closed and opened by the relative motion between the fingers and the housing of
    the gripper. The grasping motion of the gripper is generated by two mechanisms:
    a passive pinching mechanism and a selflocking mechanism. These mechanisms allow
    the fingers to perform open and close movements and to maintain the fingers in
    either open or closed state. The kinematics of the mechanisms are analyzed to
    design the gripper. The relation between the movement of the fingers and the force
    required to operate the gripper is also investigated through static force analysis
    and the experiment. Finally, experiments using PALGRIP are conducted, and the
    experimental results illustrate how the pick-and-place operations are carried
    out using the prototype of PALGRIP. The proposed gripper allows the robot to automate
    fabric pick-andplace operations easily by attaching it to the robot''s endpoint.
    Triaxial 3D-Channeled Soft Optical Sensor for Tactile Robots Matteo Lo Preti and
    3 more March 19, 2024 Soft optical transducers have the potential to fulfill the
    need for advanced tactile sensing in robotics. We present a fingertipshaped soft
    sensor with optically transparent channels that relies on soft materials and sensor
    morphology to measure an applied triaxial force. The proposed 3D-channeled sensor
    has a volume of 2.5 cm3 , and experimental results reveal a fifteen-fold increase
    in voltage compared to its bulk analogous, showcasing a sensitivity of 0.34 N/mV
    and 0.09 N/mV to tangential and normal forces. A prototype with a diameter of
    2 mm (0.4x) indicates the feasibility of scaling down the sensor. Force magnitude
    is estimated with a linear model and then decomposed into its Fxy and Fz with
    an R2 of 0.93 and 0.98 within a sensing range of 4.05 N and 8.50 N, respectively.
    A coordinate transformation from a covariant to a cartesian reference frame is
    used to retrieve the direction of the tangential component of the force. The sensor
    was integrated into a compliant robotic hand as a proof-of-concept to demonstrate
    its real-time operation and suitability for grasping, paving the way for advancements
    in soft tactile sensors that can be embedded in soft robots. Distributed Nonlinear
    Model Predictive Control for a Quadrotor UAV Bilal Mubdir and 1 more March 19,
    2024 A Distributed Nonlinear Model Predictive Control (DNMPC) approach is proposed
    to control the simplified decoupled dynamics of a quadrotor UAV. The performance
    of DNMPC is compared, in terms of tracking and execution time, to that of standard
    control configurations based on centralized MPC and PID control aiming to show
    the suitability of each configuration in terms of performance and the practicality
    of using a particular configuration in real-time applications. The results show
    the advantage of using DN-MPC in terms of ease of tuning and computational cost
    over more centralized feedback control approaches. Indoor Localization based on
    Short-Range Radar and Rotating Landmarks Kolja Thormann and 2 more March 19, 2024
    A novel concept for indoor self-localization based on relative position measurements
    to rotating artificial landmarks (with known positions) using short-range radar
    is proposed. This includes a complete processing pipeline for extracting distance
    and angle measurements from the raw radar data, which consists of a neural network
    for distance estimation, a basic angle-of-arrival estimator, and a particle filter
    for position tracking. Due to the ability of radar to measure range rate, i.e.,
    the velocity in the direction of a detection, it is possible to robustly detect
    the landmarks by detecting and localizing their micro-Doppler pattern. This mean
    localization is possible even under difficult conditions (e.g., light changes).
    Experiments with a wheeled mobile robot and common office fans as landmarks demonstrate
    the effectiveness of the approach for indoor localization. Planning Stories Neurally
    Rachelyn Farrell and 1 more March 19, 2024 Symbolic planning algorithms and large
    language models have different strengths and weaknesses for story generation,
    suggesting hybrid models might leverage advantages from both. Others have proposed
    using a language model in combination with a partial order planning style algorithm
    to avoid the need for a handwritten symbolic domain of actions. This paper offers
    a complementary approach. We use a state space planning algorithm to plan coherent
    multi-agent stories in symbolic domains, with a language model acting as a guide
    to estimate which events are worth exploring first. We evaluate an initial implementation
    of this method on a set of benchmark problems and find that the LLM''s guidance
    is helpful to the planner in most domains. Automated Loop Fusion for Image Processing
    Madushan Abeysinghe and 3 more March 19, 2024 In this paper, we develop a method
    for automatically selecting groups of loops to fuse in an image processing data
    flow graph, here referred to as a "fusing configuration". The method is designed
    for use on Digital Signal Processors (DSP), many of which rely on statically scheduled
    Very Long Instruction Word architecture. Selection is guided by a heuristic instruction
    scheduler that serves as a performance model for a candidate configuration. We
    show that for synthetically generated graphs of size 2 to 10 nodes, this approach
    is capable of selecting the optimal fusing configuration in 80% of graphs and
    selects a configuration that achieves within 10% of the performance of the optimal
    configuration for 90% of graphs. A Lyapunov-based Approach to Nonlinear Programming
    and Its Application to Nonlinear M... Kyunghwan Choi and 1 more March 19, 2024
    A tuning-parameter-free and matrix-inversionfree solution of nonlinear programming
    (NLP) problems is proposed. The key idea is to design an update law based on Lyapunov
    analysis to satisfy the first-order necessary conditions for optimality. To this
    aim, first, the Lyapunov function is defined as the summation of the norms of
    these conditions. Then, the desired optimization variables and Lagrange multipliers,
    which minimize the Lyapunov function the most, are found analytically, thereby
    rapidly approaching the necessary conditions. The proposed method neither requires
    tuning parameters nor matrix inversions; thus, it can be implemented easily with
    less iterations and computational load than conventional methods, such as sequential
    quadratic programming (SQP) and augmented Lagrangian method (ALM). The effectiveness
    of the proposed method is applied to and validated by using it to solve a nonlinear
    model predictive torque control (NMPTC) problem in electrical drives. The results
    are compared with those of SQP and ALM. Vectorized Highly Parallel Density-based
    Clustering for Applications with Noise Joseph Xavier Arnold and 7 more March 19,
    2024 Clustering in data mining involves grouping similar objects into categories
    based on their characteristics. As the volume of data continues to grow and advancements
    in highperformance computing evolve, a critical need has emerged for algorithms
    that can efficiently process these computations and exploit the various levels
    of parallelism offered by modern supercomputing systems. Exploiting Single Instruction
    Multiple Data (SIMD) instructions enhances parallelism at the instruction level
    and minimizes data movement within the memory hierarchy. To fully harness a processor''s
    SIMD capabilities and achieve optimal performance, adapting algorithms for better
    compatibility with vector operations is necessary. In this paper, we introduce
    a vectorized implementation of the Density-based Clustering for Applications with
    Noise (DBSCAN) algorithm suitable for the execution on both shared and distributed
    memory systems. By leveraging SIMD, we enhance the performance of distance computations.
    Our proposed Vectorized HPDBSCAN (VHPDBSCAN) demonstrates a performance improvement
    of up to two times over the state-of-the-art parallel version, Highly Parallel
    DBSCAN (HPDBSCAN), on the ARM-based A64FX processor on two different datasets
    with varying dimensions. Additionally, we evaluate VHPDBSCAN''s energy consumption
    on the A64FX and Intel Xeon processors. The results show that the proposed implementation
    reduces energy consumption by a factor of two on the A64FX Central Processing
    Unit (CPU) and by approximately 19.5% on the Intel Xeon 8368 CPU compared to previous
    methods. UWB Security and Enhancements K. Reaz and 13 more March 19, 2024 Ultra-Wideband
    (UWB) technology re-emerges as a groundbreaking ranging technology with its precise
    microlocation capabilities and robustness. However, the security aspects of UWB
    technology demand thorough scrutiny due to its widespread use in both consumer
    and industrial sectors. This white paper highlights the security dimensions of
    UWB technology, focusing in particular on the intricacies of device fingerprinting
    for authentication, examined through the lens of state-of-the-art machine learning
    techniques. Furthermore, we explore various potential enhancements to the UWB
    standard that could realize a sovereign UWB data network. We argue that UWB data
    communication holds significant potential in healthcare and ultra-secure environments,
    where the use of the common unlicensed 2.4 GHz band-centric wireless technology
    is limited or prohibited. A sovereign UWB network could serve as an alternative,
    providing secure localization and short-range data communication in such environments.
    Data-Driven Insights: Boosting Algorithms to Uncover Electricity Theft Patterns
    in AM... Inam Ullah Khan and 3 more March 19, 2024 This study introduces a sophisticated
    supervised machine learning method for electric theft detection utilizing a customized
    Histogram Gradient Boosting (HGB) algorithm. Comprehensive preprocessing, including
    imputation, normalization, outlier management, and resampling, ensures the timeseries
    data is accurately prepared for analysis. The SMOTE-ENN algorithm corrects class
    imbalances, preparing the data for the feature optimization stage where crucial
    features are selected and extracted. The HGB algorithm, enhanced through Bayesian
    optimization, is central to the training process, resulting in a model that precisely
    classifies electricity consumption patterns as genuine or fraudulent. The robustness
    of the model is assessed against other recognized boosting methods, such as Adaptive
    Boosting (ADB), Gradient Boosting Decision Tree (GBDT), and LightGBM, alongside
    various ensemble and traditional machine learning models. Utilizing key performance
    metrics like accuracy, F1 score, and AUC for validation, the proposed model yields
    very promising results, with a 93% accuracy, 95% F1 score, and 98% AUC, outperforming
    the comparison group under similar dataset and hyperparameter conditions. This
    underscores the model''s potential as a highly accurate tool for combating electricity
    theft within an advanced metering infrastructure (AMI). Software Metrics in Agile
    Software Development: A Review Report Muhammad Faizan Berlas March 19, 2024 Modern
    software systems intensively use the Agile software development processes for
    their development and maintenance. The Agile development methodology encourages
    customer satisfaction, early incremental delivery, and overall development simplicity.
    Agile development methods accept changes in requirements and technology and use
    a more adaptive or iterative approach to planning. With the adaptation of Agile
    process models in the development of modern software systems, there is a need
    for continuous improvement in the Agile processes. Agile development processes
    are modified and upgraded by utilizing software metrics. There are several proposed
    software metrics for measuring performance and quality in Agile software development.
    These include customer satisfaction, story point estimation, velocity, test coverage,
    defects in production, and other metrics. Each software metric has its own merits
    and demerits. This research aims to provide a comprehensive review of published
    research work on software metrics. Specifically, it summarizes the software metrics
    used for measuring the performance of Agile process models. This research paper
    will help understand the usefulness of various software metrics used in Agile
    development, and it will serve as a foundation for future research in software
    metrics for Agile software development. Model-Based Systems Engineering Applied
    to Engineering Learning Analytic Systems (ELA... Pallavi Singh and 2 more March
    19, 2024 Engineering education is a complex that involves multiple stakeholders,
    including students, educators, administrators, and industry partners. It is continuously
    evolving to meet the demands of modern industry and society. The traditional teaching
    and learning methodologies are being replaced by a more integrated skillset that
    focuses on developing students'' cognitive, social, and emotional skills. The
    shift towards this integrated approach is gaining momentum, and it is important
    to have a framework that has been proven to solve complex systems. The usage of
    systems engineering tools to model engineering education systems is not often
    seen. In this paper, a novel application of Model-Based Systems Engineering using
    Systems Modeling Language (SysML) to develop an Engineering Learning Analytic
    System (ELAS) framework that consists of multi-dimensional elements related to
    educational systems. The core of this study involves a rigorous Requirements Verification
    and Validation (V&V) process to ensure stakeholder needs which systematically
    were map with system capabilities. ELAS model simulations provided predictive
    insights into soft skill development, enabling decision-making via targeted interventions
    that could significantly enhance students'' skill sets. ELAS highlights that a
    data-driven approach, enabled by SysML, significantly enhances the ability to
    enact timely by relevant interventions at various levels of the educational management
    process. The proposed ELAS model offers a strategic blueprint for continuous improvement
    within educational institutions, demonstrating a pathway toward a responsive and
    self-improving educational system. The refining of the ELAS model, for broadening
    simulation scopes, and further integrating predictive analytics into administrative
    decision-making processes is an ongoing endeavor. Multi-Discounting Reinforcement
    Learning Based on Reward Decomposition Pengbin Chen and 4 more March 18, 2024
    A document by pengbin chen. Click on the document to view its contents. ← Previous
    1 2 3 4 5 6 7 8 9 … 501 502 Next → TechRxiv | Powered by Authorea.com Home About
    Submission Guidelines FAQs Terms of Use Privacy Policy Contact Us'
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://www.techrxiv.org/articles/preprint/A_Futuristic_Survey_on_Learning_Techniques_for_Internet_of_Things_IoT_Security_Developments_Applications_and_Challenges/19642977/1/files/34888401.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'A Futuristic Survey on Learning Techniques for Internet of Things (IoT)
    Security : Developments, Applications, and Challenges'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.1051/itmconf/20235602008
  analysis: '>'
  authors:
  - T. Padma
  - S. Aruna
  - J. Sujipriya
  - Madiha Zainab
  citation_count: 0
  full_citation: '>'
  full_text: '>

    By using this website, you agree that EDP Sciences may store web audience measurement
    cookies and, on some pages, cookies from social networks. More information and
    setup OK Journals Books Conferences EDPS Account All issuesSeriesForthcomingAbout
    Search Menu All issues Volume 56 (2023) ITM Web Conf., 56 (2023) 02008 Abstract
    Open Access Issue ITM Web Conf. Volume 56, 2023 First International Conference
    on Data Science and Advanced Computing (ICDSAC 2023) Article Number 02008 Number
    of page(s) 12 Section Data Science DOI https://doi.org/10.1051/itmconf/20235602008
    Published online 09 August 2023 ITM Web of Conferences 56, 02008 (2023) Blockchain
    Based Solutions for Milk Procurement Management and Adulteration Detection T.
    Padma, S. Aruna*, J. Sujipriya and M. Zainab Department of MCA, Sona College of
    Technology, Salem, Tamil Nadu, India * Corresponding author: arunamca@sonatech.ac.in
    Abstract In our day-to-day life, milk is a fundamental component that is rudimentary
    for many food products. Consuming milk regularly is very important because it
    is a mixture of various macro and micronutrients and is a source of proteins,
    fats, carbohydrates, and vitamins. Particularly in our nation, women’s empowerment
    and milk production are closely related. Furthermore, rural Indian communities
    rely heavily on small holder dairy farms for their livelihoods, and women play
    an important role in milk production. The dairy sector is estimated to contribute
    around 6% of the country’s agricultural GDP, with the value of milk production
    in India exceeding 200 million ton by the year 2023 [1]. Milk is a highly perishable
    commodity, when not handled properly it is susceptible to microbial spoilage.
    The milk after production must be processed properly to retain its quality till
    consumption. Nowadays, many milk vendors are adulterating the milk for financial
    gain. Consumers have the rights to obtain good and safe milk, as it is largely
    consumed by people of all age groups. Supply chain process of a small holder dairy
    farming has been examined recently in Salem, Tamil Nadu, India and it has been
    observed that the current process in dairy involves the accumulated milk from
    dairy farmers are being poured into the milk cane, then being detected and sent
    to a larger container where it is mixed with all the other milk. In most cases,
    it would be impossible to separate fresh milk from un-fresh milk. Therefore, the
    objective of this research work aims to develop a Blockchain and IoT based solution
    for milk procurement and adulteration detection there by providing a complete
    milk traceability data to the consumers from production to consumption, and establishing
    a trust in providing quality milk to the society. © The Authors, published by
    EDP Sciences, 2023 This is an Open Access article distributed under the terms
    of the Creative Commons Attribution License 4.0, which permits unrestricted use,
    distribution, and reproduction in any medium, provided the original work is properly
    cited. Table of Contents Article contents AbstractPDF (455.5 KB)References Metrics
    Show article metrics Services Same authors - Google Scholar - EDP Sciences database
    Recommend this article Download citation Related Articles Autism Spectrum Disorder
    Detection Using Enhanced Convolutional Neural Network and Wearable Sensors ITM
    Web of Conferences 56, 05018 (2023) Implementation of a multi-stage intrusion
    detection systems framework for strengthening security on the internet of things
    MATEC Web of Conferences 392, 01106 (2024) Environmental and Economical Impact
    of Blockchain E3S Web of Conferences 399, 04003 (2023)     More Bookmarking Mendeley
    Reader''s services Email-alert ITM Web of Conferences eISSN: 2271-2097 Mentions
    légales Contacts Privacy policy A Vision4Press website'
  inline_citation: '>'
  journal: ITM web of conferences
  limitations: '>'
  pdf_link: https://www.itm-conferences.org/articles/itmconf/pdf/2023/06/itmconf_icdsac2023_02008.pdf
  publication_year: 2023
  relevance_score1: 0
  relevance_score2: 0
  title: Blockchain Based Solutions for Milk Procurement Management and Adulteration
    Detection
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.31428/10317/10416
  analysis: '>'
  authors:
  - Marouane Salhaoui
  citation_count: 0
  full_citation: '>'
  full_text: ">\n \n  \n \nvrbvnjnnbbttbbtbt  \n\"SMART IOT MONITORING AND REAL-TIME\
    \ CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL \nRECOGNITION AND CLOUD/EDGE COMPUTING\
    \ \nSERVICES\" \n \nPrograma de Doctorado: ENERGÍAS RENOVABLES Y \nEFICIENCIA\
    \ ENERGÉTICA \n \n \n \n \nAutor: Marouane Salhaoui \n \nCartagena (2021) \n \n\
    i \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \n \n \n \n \n \n\
    \ \n \n \nABDELMALEK ESSAADI UNIVERSITY \nFACULTY OF SCIENCE AND TECHNIQUES \n\
    TANGER / MOROCCO \n \nPOLYTECHNIC UNIVERSITY OF CARTAGENA \nUPCT / SPAIN \n \n\
    \ \nDOCTORAL THESIS (Year 2021) \n \nPresented By: \n \nMAROUANE SALHAOUI \n \n\
    Directors:  \n \nAntonio Guerrero-González, Mounir Arioua  \n \nCo-Directors:\
    \ \n \nFrancisco J. Ortiz, Ahmed El Oualkadi \n \nThesis Title: \n \n\"SMART IOT\
    \ MONITORING AND REAL-TIME CONTROL \nBASED ON AUTONOMOUS ROBOTS, VISUAL RECOGNITION\
    \ \nAND CLOUD/EDGE COMPUTING SERVICES\" \n \n \nAccredited research institution:\
    \ \n \n• Laboratoire des Technologies de l’Information et de la Communication\
    \ de ENSA de \nTanger (Morocco) \n• Departamento de Automática, Ingeniería Eléctrica\
    \ y Tecnología Electrónica, UPCT \nCartagena (Spain) \n \nii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nAbstract \n \nIn the fourth industrial revolution\
    \ in which we are immersed, new \ntechnologies are being introduced in production\
    \ processes, such as the use of \nUnmanned Vehicles (UVs) data collection in large\
    \ surfaces, and the use of the \nIndustrial Internet of Things (IIoT). The main\
    \ keys to integrate this new \ntechnology in the industry is to face the challenge\
    \ of making the IT network \ncompatible with its machines, including interoperability,\
    \ fog and cloud \ncomputing, security, decreasing latency and improving data accuracy\
    \ and \nquality of service. \nSmart industrial platforms require multiple synchronized\
    \ processes that \nrequire low latency and higher reliability to achieve the necessary\
    \ performance. \nIn addition, Artificial Intelligence (AI) methods applied to\
    \ IIoT must be able to \naddress these issues as well as other parameters such\
    \ as network deployment \nand resource management. \nThe issues of high-latency\
    \ and unreliable links between the cloud and \nIndustrial IoT endpoints are significant\
    \ challenges. Each fog and edge application \nmay have different latency requirements\
    \ and may generate different types of \ndata and network traffic.  Such generated\
    \ data can be photos received from an \nUV system. The latter can be connected\
    \ to other control system, being used both \nto perform enhancements and to make\
    \ decisions based on the captured photos. \nThis type of connection is sensitive\
    \ in terms of accuracy and latency, as the whole \nplatform must decide quickly\
    \ and with certainty. \nOne of the solutions to overcome the latency challenge\
    \ is the fog/edge \narchitecture. This architecture can also be a viable solution\
    \ regarding the \ninteroperability barrier between interconnected systems. Fog\
    \ computing extends \ncomputation and storage to the edge of the network and presents\
    \ an effective tool \nfor integrating new complex interconnected processing systems.\
    \   \nThe constraint of interoperability can be overcome by adopting advanced\
    \ \nsoftware deployed in the edge and fog installed in an IoT gateway. This software\
    \ \ninteracts simultaneously with the different systems involved through different\
    \ \nprotocols. However, the choice of an IoT gateway is crucial in terms of latency\
    \ \nand accuracy, as it is at the heart of processing and transmitting data to\
    \ the \ndifferent systems and platforms and considered the interface of junction\
    \ between \nthe physical level and cloud. The latter also affects performance\
    \ as it must ensure \nthat data is transferred, processed and returned at speeds\
    \ that meet the needs of \nthe application. \n \niii \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nWe address all these challenges by considering appropriate\
    \ protocols and \nsoftware for interoperability and connectivity constraints and\
    \ we discuss the \nperformance some appropriate IoT devices capable of providing\
    \ minimal \nresponse time. \nDeep Learning (DL) services can be deployed near\
    \ requesting users and the \ncloud only intervenes when additional processing\
    \ is required, significantly \nreducing the latency and cost of sending data to\
    \ the cloud for processing. In this \nthesis, we propose novel approaches to solve\
    \ the latency issue by deploying \nintelligence at the edge that pushes DL computations\
    \ from the cloud to the edge \nenabling various distributed, low-latency and reliable\
    \ intelligent services. \nThe main benefit of the proposed approaches is the integration\
    \ of cloud \nservices into a control loop to improve a platform’s decision making\
    \ and the \nperformance of an industrial control system. Cloud AI services are\
    \ also \nintegrated into a drone control loop as an input that helps improve the\
    \ \nmonitoring capability to find and track stationary and mobile objects. \n\
    In this work, we evaluate the latency and accuracy of different systems \ninvolved\
    \ and we propose an intelligent algorithm to select the appropriate AI \ntechnology\
    \ for the scenario to be monitored. This proved to be crucial in deciding \nthe\
    \ best source of artificial intelligence to be used to achieve the specified goals\
    \ \nat each stage in real time. The proposed intelligent algorithms offer a compromise\
    \ \nbetween latency and accuracy. \n \n \n \niv \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nResumen \n \nEn la cuarta revolución industrial en\
    \ la que estamos inmersos, se están \nintroduciendo nuevas tecnologías en los\
    \ procesos productivos, como el uso de \nvehículos autónomos (UVs) para recogida\
    \ de datos en grandes superficies y el \nuso del Internet Industrial de las Cosas\
    \ (IIoT). Las principales claves para integrar \nesta nueva tecnología en la industria\
    \ es afrontar el reto de compatibilizar la red \ninformática con sus máquinas,\
    \ incluyendo la interoperabilidad, computación en \nla niebla/nube/borde (fog/cloud/edge\
    \ computing), la seguridad, la disminución \nde la latencia y la mejora de la\
    \ precisión de los datos y la calidad del servicio. \nLas plataformas industriales\
    \ inteligentes requieren múltiples procesos \nsincronizados que exigen una baja\
    \ latencia y una mayor fiabilidad para lograr el \nrendimiento necesario. Además,\
    \ los métodos de Inteligencia Artificial (IA) \naplicados a la IIoT deben ser\
    \ capaces de abordar estas cuestiones, así como otros \nparámetros como el despliegue\
    \ de la red y la gestión de recursos. \nLos problemas de alta latencia y enlaces\
    \ poco fiables entre la nube y los \npuntos finales del IoT industrial son retos\
    \ importantes. Cada aplicación de niebla \ny borde puede tener diferentes requisitos\
    \ de latencia y puede generar diferentes \ntipos de datos y tráfico de red.  Estos\
    \ datos generados pueden ser imágenes \nrecibidas de un sistema UV, por ejemplo.\
    \ Este sistema puede a su vez conectarse \na otro sistema de control, utilizándose\
    \ tanto para realizar mejoras en el proceso \ncomo para tomar decisiones basadas\
    \ en las imágenes capturadas. Este tipo de \nconexión es sensible en términos\
    \ de precisión y latencia, ya que toda la \nplataforma debe decidir con rapidez\
    \ y seguridad. \nUna de las soluciones para superar el reto de la latencia es\
    \ la arquitectura \nbasada en la niebla/borde (fog/edge). Esta arquitectura también\
    \ puede ser una \nsolución viable en cuanto a la barrera de interoperabilidad\
    \ entre los sistemas \ninterconectados. La computación en la niebla extiende la\
    \ computación y el \nalmacenamiento al borde de la red y presenta una herramienta\
    \ eficaz para \nintegrar nuevos sistemas complejos de procesamiento interconectados.\
    \   \nLa limitación de la interoperabilidad puede superarse adoptando un \nsoftware\
    \ avanzado desplegado en el borde y la niebla instalado en una pasarela \nde IoT.\
    \ Este software interactúa simultáneamente con los distintos sistemas \nimplicados\
    \ a través de diferentes protocolos. Sin embargo, la elección de una \npasarela\
    \ IoT es crucial en términos de latencia y precisión, ya que está en el centro\
    \ \ndel procesamiento y la transmisión de datos a los diferentes sistemas y \n\
    plataformas y se considera la interfaz de unión entre el nivel físico y la nube.\
    \ Esta \núltima también afecta al rendimiento, ya que debe garantizar que los\
    \ datos se \n \nv \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ntransfieran,\
    \ procesen y devuelvan a velocidades que satisfagan las necesidades \nde la aplicación.\
    \ \nAbordamos todos estos retos teniendo en cuenta los protocolos y el software\
    \ \napropiados para la interoperabilidad y las restricciones de conectividad,\
    \ y \nanalizamos el rendimiento de algunos dispositivos IoT apropiados capaces\
    \ de \nproporcionar un tiempo de respuesta mínimo. \nLos servicios de Deep Learning\
    \ (DL) pueden desplegarse cerca de los \nusuarios que los solicitan y la nube\
    \ solo interviene cuando se requiere un \nprocesamiento adicional, reduciendo\
    \ significativamente la latencia y el coste de \nenviar los datos a la nube para\
    \ su procesamiento. En esta tesis, proponemos \nenfoques novedosos para resolver\
    \ el problema de la latencia mediante el \ndespliegue de inteligencia en el borde\
    \ que empuja los cálculos de DL desde la \nnube hasta el borde permitiendo varios\
    \ servicios inteligentes distribuidos, de \nbaja latencia y fiables. \nLa principal\
    \ ventaja de los enfoques propuestos es la integración de los \nservicios en la\
    \ nube en un lazo de control para mejorar la toma de decisiones de \nuna plataforma\
    \ y el rendimiento de un sistema de control industrial. Los servicios \nde IA\
    \ en la nube también se integran en un lazo de control donde interviene un \n\
    dron como una entrada que ayuda a mejorar la capacidad de monitorización para\
    \ \nencontrar y rastrear objetos estacionarios y móviles. \nEn este trabajo, evaluamos\
    \ la latencia y la precisión de los diferentes sistemas \nimplicados y proponemos\
    \ un algoritmo inteligente para seleccionar la tecnología \nde IA adecuada para\
    \ el escenario a vigilar. Esto resulta crucial para decidir cuál \nes la mejor\
    \ fuente de inteligencia artificial que debe utilizarse para alcanzar los \nobjetivos\
    \ especificados en cada escenario en tiempo real. Los algoritmos \ninteligentes\
    \ propuestos ofrecen un compromiso entre latencia y precisión. \n \n \n \nvi \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n صخلملا \n \n \n يفعمج\
    \ مادختسا لثم ، جاتنلإا تايلمع يف ةديدج تاينقت لاخدإ متي ، اهيف كراشن يتلا ةعبارلا\
    \ ةيعانصلا ةروثلا \nةيسيئرلا حيتافملا لثمتت .ءايشلأل يعانصلا تنرتنلإا مادختساو\
    \ ، ةعساو قطانم يف ةلوهأملا ريغ تابكرملا تانايب \n ةهجاوم يف ةعانصلا يف ةديدجلا\
    \ ايجولونكتلا هذه جمدلةقفاوتم تامولعملا ايجولونكت ةكبش لعج يف لثمتملا يدحتلا \n\
    ينمزلا ريخأتلا ليلقتو نملأاو ةيباحسلاو ةيبابضلا ةبسوحلاو يليغشتلا قفاوتلا ةيناكمإ\
    \ كلذ يف امب ، اهتزهجأ عم \nةمدخلا ةدوجو تانايبلا ةقد نيسحتو )نومكلا(  \n \nةددعتم\
    \ ةنمازتم تايلمع ةيكذلا ةيعانصلا تاصنملا بلطتتىلعأ ةيقوثومو ضفخنم ينمزريخأت بجوتست\
    \ يتلاو ، \nءايشلأا تنرتنإ ىلع ةقبطملا يعانطصلاا ءاكذلا بيلاسأ نوكت نأ بجي ، كلذ\
    \ ىلإ ةفاضلإاب .مزلالا ءادلأا قيقحتل \nدراوملا ةرادإو ةكبشلا تيبثت لثم ىرخأ تاملعم\
    \ ىلإ ةفاضلإاب تلاكشملا هذه ةجلاعم ىلع ةرداق  \n   \nاورلا تلاكشم دعتءايشلأا تنرتنإو\
    \ ةيباحسلا ةياهنلا طاقن نيب يلاع ينمزريخأت تاذ و اهب قوثوملاريغ طب \nعاونأ هنع\
    \ جتني دقو ةفلتخم نومك تابلطتم ةفاحلاو بابضلا تاقيبطت نم قيبطت لكل نوكي دق .ريبك\
    \ يدحت ةيعانصلا \nيتلا تانايبلا هذه نوكت نأ نكمي .تاكبشلا ربع ةلوادتملا تانايبلا\
    \ نم ةفلتخم نم ةملتسملا روصلا نم اهؤاشنإ مت \nتانيسحت ءارجلإ همادختسا متي ثيح\
    \ ، رخآ مكحت ماظنب ريخلأا اذه ليصوت نكمي .ةلوهأملا ريغ تابكرملا ماظن \nبجي ثيح\
    \ ، نومكلاو ةقدلا ثيح نم ساسح لاصتلاا نم عونلا اذه .ةطقتلملا روصلا ىلع ًءانب تارارقلا\
    \ ذاختلاو \nفنملا يساسلأا ماظنلا ىلعدكؤم لكشبو ةعرسب ررقي نأ هلمكأب ذ  \n \nيف\
    \ ةتبثم ، بابضلاو ةفاحلا يف ةرشتنم ةمدقتم جمارب دامتعا للاخ نم يليغشتلا قفاوتلا\
    \ دويق ىلع بلغتلا نكمي \nتلاوكوتورب للاخ نم ةكراشملا ةفلتخملا ةمظنلأا عم نمازتم\
    \ لكشب جمانربلا اذه لعافتي .ءايشلأا تنرتنإ ةباوب \n كلذ عمو .ةفلتخمإف ،اهنإ ثيح\
    \ ، ةقدلاو ينمزلاريخأتلاب قلعتي اميف ةيمهلأا غلاب رمأ ءايشلأا تنرتنإ ةباوب رايتخا\
    \ ن \nةقبطلا( ةيداملا ةقبطلا نيب عطاقتلا ةهجاو ربتعت يتلاو ، ةفلتخملا ىنبلاو ةمظنلأا\
    \ ىلإ اهلقنو تانايبلا ةجلاعم بلق \nباحسلاو )يرايعملا لاصتلاا جذومن يف ةقبط ىندأ،ىلولأانمضت\
    \ نأ بجي هنلأ ءادلأا ىلع اًضيأ ةريخلأا هذه رثأت .ة \n قيبطتلا تاجايتحا يبلت تاعرسب\
    \ اهتداعإو اهتجلاعمو تانايبلا لقن \n \nلاصتلاا دويقو يليغشتلا قفاوتلل ةبسانملا\
    \ جماربلاو تلاوكوتوربلا يف رظنلا للاخ نم تايدحتلا هذه لك عم لماعتن  \nيشلأا تنرتنإ\
    \ ةزهجأ ضعب ءادأ شقاننوينمزلا ريخأتلا نم ىندلأا دحلا ريفوت ىلع ةرداقلا ةبسانملا\
    \ ءا  \n \nىلإ ةجاحلا دنع لاإ ةباحسلا لخدتت لاو ، ةبولطملا نيمدختسملا ةمظنأ نم\
    \ برقلاب قيمعلا ملعتلا تامدخ رشن نكمي \nملل ةباحسلا ىلإ تانايبلا لاسرإ ةفلكتو\
    \ ينمزلا ريخأتلا نم ريبك لكشب للقي امم ، ةيفاضإ ةجلاعمهذه يف .ةجلاع \nتاباسح عفدت\
    \ يتلا ةفاحلا ىلع ءاكذلا رشن للاخ نم ينمزلا ريخأتلا ةلكشم لحل ةديدج بيلاسأ حرتقن\
    \ ، ةحورطلأا \nضفخنم ينمز ريخأت تاذو ةعزومو ةقوثومو ةعونتم ةيكذ تامدخ حيتي امم\
    \ ةفاحلا ىلإ ةباحسلا نم قيمعلا ملعتلا  \n \n ةحرتقملا قرطلل ةيسيئرلا ةدئافلا لثمتتيف\
    \ رارقلا عنص ةيلمع نيسحتل مكحتلا ةقلح يف ةيباحسلا تامدخلا جمد يف \nكذلا تامدخ\
    \ جمد اًضيأ متي .يعانصلا مكحتلا ماظن ءادأو يساسلأا ماظنلايف مكحتلا ةقلح يف ةيباحسلا\
    \ يعانطصلاا ءا \nةتباثلا ءايشلأا ىلع روثعلل ةبقارملا ةردق نيسحت ىلع دعاسي لخدمك\
    \ ةلوهأملا ريغ تابكرملا اهعبتتو ةكرحتملاو  \n  \nءاكذلا ةينقت ديدحتل ةيكذ ةيمزراوخ\
    \ حرتقنو ةينعملا ةفلتخملا ةمظنلأا ةقدو ينمزلا ريخأتلا مييقتب موقن ، لمعلا اذه\
    \ يف \nيعانطصلاا ءاكذلل ردصم لضفأ ديدحت يف مساح رمأ اذه نأ تبث .هتبقارم دارملا\
    \ ويرانيسلل ةبسانملا يعانطصلاا \nلأا قيقحتل همادختسلااطسو لاح ةحرتقملا ةيكذلا\
    \ تايمزراوخلا مدقت .يلعفلا تقولا يف ةلحرم لك يف ةبولطملا فاده \nةقدلاو نومكلا\
    \ نيب  \n \n \n \nvii \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \nList of Acronyms  \nAI Artificial Intelligence  \nAIS Automatic Identification\
    \ System \nANN Artificial Neural Network  \nAPI Application programming interfaces\
    \ \nASV Autonomous Surface Vehicle \nAUV Autonomous Underwater Vehicle \nCAN Controller\
    \ area network \nCCM Cloud custom model \nCGM Cloud General Model \nCoAP Constrained\
    \ Application Protocol \nCPS cyber-physical systems \nCPU Central processing unit\
    \  \nCSMA/CD with NDBA Carrier Sense Multiple Access / Collision Detection \n\
    with Non-Destructive Bitwise Arbitration \nCV Computer vision \nDAyRA División\
    \ de Automatización y Robótica Autónoma \nDNNs Deep Neural Networks \nDP Deep\
    \ Learning \nDPM Dynamic Position Mode  \nDVL Doppler Velocity Logger \n \nviii\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nECM Edge custom model\
    \ \nEI Edge Intelligence  \nERP enterprise resource planning \nFN False Negative\
    \ \nFP False Positive \nGPS Global Positioning System \nGPU Graphics Processing\
    \ Unit \nHD High-definition \nHVAC Heating, Ventilating, and Air Conditioning\
    \ \nIaaS Infrastructure-as-a-Service  \nIETF The Internet of Engineering Task\
    \ \nILSVRC ImageNet Large Scale Visual Recognition Challenge \nIM Inspection Mode\
    \  \nIMARS IBM multimedia analysis and retrieval system \nIoS Internet of services\
    \ \nIoT Internet of things \nIoU Intersection on union \nIPM Image Processing\
    \ Algorithm \nIUCN International Union for the Conservation of Nature \nIUNO Interface\
    \ for Unmanned Drones \nM2M machine-to-machine \nMASS Maritime Autonomous Surface\
    \ Ships  \nMES manufacturing execution systems \n \nix \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nML Machine Learning  \nMLaaS Machine Learning as a service\
    \  \nMMM Main Mission Mode \nMPA Marine Protected Area \nMQTT The Message Queuing\
    \ Telemetry Transport \nND Not detected \nNFC Near Field Communication  \nNIC\
    \ network interface controller  \nOPC UA Open Platform Communications Unified\
    \ Architecture  \nOWD One-way delay \nPaaS Platform as-a-Service \nPC-G PC Gateway\
    \ \nPID Proportional–Integral–Derivative \nPV Process Variables \nQoS Quality\
    \ of Service  \nRFID Radio frequency identification  \nRPI-G Raspberry PI Gateway\
    \ \nRTD Round-trip delay time \nS-G Siemens Gateway \nSAAO Smart algorithm for\
    \ autonomy optimization \nSaaS Software-as-a-Service \nSAR Synthetic Aperture\
    \ Radar \nSHDL ScatterNet hybrid deep learning \n \nx \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nSISO single-input–single-output \nSOA Service-oriented\
    \ architecture \nSP Set Points \nSVM Support vector machine \nTAS Time-aware scheduler\
    \  \nTM Tracking Mode  \nTP True Positive \nTSN Time sensitive networking \nUAV\
    \ Unmanned Autonomous Vehicle \nUVs Unmanned vehicles \nVPL Visual Programming\
    \ Language  \nWFQ weighted fair queuing \nWSN Wireless Sensor Network  \nWVR Watson\
    \ Visual Recognition \n \n \n \nxi \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nList of Publications  \nThe work presented in this thesis has appeared\
    \ in the articles reported below.  \nJournal papers:  \n(J1) Salhaoui Marouane;\
    \ Guerrero-González Antonio; Arioua Mounir; Ortiz, \nFrancisco J.; El Oualkadi\
    \ Ahmed; Torregrosa Carlos L. 2019. \"Smart Industrial IoT \nMonitoring and Control\
    \ System Based on UAV and Cloud Computing Applied to \na Concrete Plant\" Sensors\
    \ 19, no. 15: 3316. https://doi.org/10.3390/s19153316  \n \n(J2) Salhaoui Marouane;\
    \ Molina-Molina J. C.; Guerrero-González Antonio; Arioua \nMounir; Ortiz Francisco\
    \ J. 2020. \"Autonomous Underwater Monitoring System for \nDetecting Life on the\
    \ Seabed by Means of Computer Vision Cloud Services\" \nRemote Sens. 12, no. 12:\
    \ 1981. https://doi.org/10.3390/rs12121981  \n \n(J3) Molina-Molina J. C.; Salhaoui\
    \ Marouane; Guerrero-González, Antonio; Arioua, \nMounir. 2021. \"Autonomous Marine\
    \ Robot Based on AI Recognition for \nPermanent Surveillance in Marine Protected\
    \ Areas\" Sensors 21, no. 8: 2664. \nhttps://doi.org/10.3390/s21082664  \n \n\
    (J4) Benbarrad, Tajeddine; Salhaoui Marouane; Kenitar Soukaina B.; Arioua \nMounir.\
    \ 2021. \"Intelligent Machine Vision Model for Defective Product Inspection \n\
    Based \non \nMachine \nLearning\" J. \nSens. \nActuator \nNetw. 10, \nno. \n1:\
    \ \n7. \nhttps://doi.org/10.3390/jsan10010007  \n \nInternational conference papers:\
    \  \n(C1) Marouane Salhaoui, Mounir Arioua, Otman Chakkor, and Jihane Elaasri.\
    \ 2017. \nPerformance Evaluation Survey of WSN Physical Layer. In Proceedings\
    \ of the 2nd \nInternational Conference on Computing and Wireless Communication\
    \ Systems \n(ICCWCS'17). Association for Computing Machinery, New York, NY, USA,\
    \ Article \n68, 1–5. DOI: https://doi.org/10.1145/3167486.3167557 \n \n(C2) Marouane\
    \ Salhaoui, Mounir Arioua, Antonio Guerrero-González, María \nSocorro García-Cascales,\
    \ \"An IoT Control System for Wind Power Generators\", \n17th International Conference,\
    \ IPMU, Published in Information Processing and \nManagement of Uncertainty in\
    \ Knowledge-Based Systems. Applications, \nSpringer, Cádiz, Spain, 2018. https://doi.org/10.1007/978-3-319-91479-4_39\
    \ \n \nxii \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n(C3) Soukaina\
    \ Bakhat Kenitar, Salhaoui Marouane, Arioua Mounir, Ali Younes, and \nA. Guerrero\
    \ Gonzalez. 2018. Evaluation of the MQTT Protocol Latency over \nDifferent Gateways.\
    \ In Proceedings of the 3rd International Conference on Smart \nCity Applications\
    \ (SCA '18). Association for Computing Machinery, New York, NY, \nUSA, Article\
    \ 87, 1–5. DOI: https://doi.org/10.1145/3286606.3286864   \n \n(C4) Soukaina B.K.,\
    \ Ali Y., Mounir A., Marouane Salhaoui. (2019) Latency \nAssessment of MQTT Protocol\
    \ in Transferring Data from the Field to the Cloud \nOver Different Gateways.\
    \ In: Ben Ahmed M., Boudhir A., Younes A. (eds) \nInnovations in Smart Cities\
    \ Applications Edition 2. SCA 2018. Lecture Notes in \nIntelligent \nTransportation\
    \ \nand \nInfrastructure. \nSpringer, \nCham. \nhttps://doi.org/10.1007/978-3-030-11196-0_71\
    \  \n \n(C5) S. B. Kenitar, M. Arioua, A. Younes, M. Radi and Marouane Salhaoui,\
    \ \n\"Comparative Analysis of Energy Efficiency and Latency of Fog and Cloud \n\
    Architectures,\" 2019 International Conference on Sensing and Instrumentation\
    \ in \nIoT Era (ISSI), 2019, pp. 1-5, doi: 10.1109/ISSI47111.2019.9043738. \n\
    \ \n(C6) Yassine Yazid, Imad Ez-zazi, Marouane Salhaoui, Mounir Arioua, El Oualkadi\
    \ \nAhmed, Antonio Guerrero González. Extensive Analysis of Clustered Routing\
    \ \nProtocols For Heteregeneous Sensor Networks. Third International Conference\
    \ on \nComputing and Wireless Communication Systems, ICCWCS 2019, April 24-25,\
    \ \n2019, \nFaculty \nof \nSciences, \nIbn \nTofaïl \nUniversity \n-Kénitra- \n\
    Morocco. \nhttp://dx.doi.org/10.4108/eai.24-4-2019.2284208 \n \n(C7) Marouane\
    \ Salhaoui, Molina-Molina, J. C, A. Guerrero-González, Antonio; \nArioua, Mounir;\
    \ Ortiz, Francisco J.; El Oualkadi, Ahmed. Edge-Cloud Architectures \nUsing UAVs\
    \ Dedicated To Industrial IoT Monitoring And Control Applications. \nIEEE- International\
    \ Symposium on Advanced Electrical and Communication \nTechnologies ISAECT2020,\
    \ November 25th-27th, 2020 Ibn Tofail University, \nMorocco \n \n(C8) Benbarrad\
    \ Tajeddine; Salhaoui Marouane; Arioua Mounir. Impact of Standard \nImage Compression\
    \ on the Performance of Image Classification with Deep \nLearning. ICDATA21 (International\
    \ Conference on Digital Age & Technological \nAdvances for sustainable development),\
    \ 2021. 29 - 30 June 2021 Marrakech, \nMorocco. \n \n \n \nxiii \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \nContents  \n \n \nAbstract  \n\
    \ \nResumen \n \n صخلملا \n \nList of Acronyms  \n \nList of Publications  \n\
    \ \n1. Introduction   \n \n1.1 \nBackground \n \n1.1.1 Applications  \n1.1.2 IoT\
    \ Monitoring and Control \n1.1.3. Advantages of Using AI in the cloud \n1.1.4.\
    \ Constraints \n \n1.2 \nMotivation \n \n1.3 \nObjectives and contributions  \n\
    \ \n1.4 \nThesis organization  \n \n2. Performance analysis of IoT Monitoring\
    \ and Control System Based on \nUV, machine vision and artificial intelligence\
    \   \n \n2.1 \nIntroduction  \n \n2.2 \nUV IoT architecture  \n2.2.1. Most Common\
    \ IoT Architectures \n2.2.2. IoT Monitoring and Control Architecture Based on\
    \ Unmanned \nVehicles \n2.2.3 IoT Gateway Capabilities \n \nxiv \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n2.3 \nUV & IoT Protocols \n \n2.3.1\
    \ UV Protocols \n2.3.2 IoT Protocols \n2.3.3 Industrial protocols \n2.3.4 OPC\
    \ UA protocol \n \n \n3. Performance and latency assessment using AI for UV  \
    \ \n \n3.1. Introduction  \n \n3.2. Related works \n \n3.3. Artificial Intelligence\
    \ and Machine Vision \n3.3.1 Artificial Intelligence \n \n3.3.1.2 Inference Versus\
    \ Training \n3.3.1.3 Methods of Machine Learning \n3.3.1.4 Convolutional Neural\
    \ Network for Object Recognition \n \n3.4. Cloud-Edge DL \n \n3.4.1 Cloud AI at\
    \ the edge \n3.4.2 Evaluating performance of an object detection model \n \n3.5.\
    \ Latency Assessment  \n \n3.5.1 Latency between Two Terminals \n3.5.2 OPC UA\
    \ Architecture and delay assessment \n3.5.3 UAV System Delay \n \n4. Energy Efficiency\
    \ and Latency of Smart IoT Monitoring and Control \nSystems Based on cloud Computing\
    \ and Intelligent Machine Vision \n \n4.1 Smart Industrial IoT Monitoring and\
    \ Control Systems Based on cloud \nComputing and Intelligent Machine Vision \n\
    \ \n4.2 Autonomous Underwater Monitoring System for Detecting Life on the Seabed\
    \ \nby Means of Computer Vision Cloud Services \n \nxv \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n4.3 Autonomous Marine Robot Based on AI Recognition\
    \ for Permanent \nSurveillance in Marine Protected Areas \n \n4.4 An IoT Control\
    \ System for Wind Power Generators \n \n5. Conclusions and future work  \n \n\
    5.1 Contributions summary  \n5.2 Future Works  \n \nBibliography  \n \n \nxvi\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nList of Tables \
    \ \n \n \nTable 2.1. Main protocols used in the IoT field \nTable 2.2. Comparison\
    \ of Internet of Things (IoT) protocols \nTable 4.1. Confusion matrix. \nTable\
    \ 4.2. Specification of each machine environment. \nTable 4.3. RTD test of 5200\
    \ samples from the OPC UA client to the OPC UA server (PLC) \nover different clients\
    \ through different machines. \nTable 4.4. RTD Test of 200 photos sent from the\
    \ IoT gateway to the AR.Drone 2.0. \nTable 4.5. RTD test of 100 samples from the\
    \ IoT gateway to IBM Watson over different \nmachines.  \nTable 4.6. Speed Test\
    \ over the three gateways (S-G, RPI-G, PC-G). \nTable 4.7. GPS coordinates of\
    \ the area explored. \nTable 4.8. Accuracy measurement in different platforms.\
    \ \nTable 4.9. Latency measurement in different platforms. \nTable 4.10. Definition\
    \ of mission stages. \nTable 4.11. AI source preferences according to mission\
    \ stage. \nTable 4.12. RTD test of 300 samples of the Edge and Cloud model. \n\
    Table 4.13. Experimental SAAO results \nTable 4.14. Summary of SAAO logs during\
    \ the experiment \n \n \n \nxvii \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nList of Figures \n  \n \nFigure 1.1. A three-layer IoT architecture based\
    \ on: Device, Edge and Cloud for \nPredictive Maintenance (PM) [8]. \nFigure 1.2\
    \ Major limitations of current IoT platforms \nFigure 1.3 Mapping of interoperability\
    \ levels to OSI layers \nFigure 1.4.  Automation Pyramid vs Automation Network\
    \ [43] \nFigure 1.5. Capabilities comparison of cloud, on-device and edge intelligence\
    \ [40] \nFigure 2.1. Most common IoT architectures \nFigure 2.2. UV-IoT Architecture\
    \ \nFigure 2.3. Wiring diagrams in vehicles before and after the appearance of\
    \ CAN \nFigure 2.4. Controller area network bus node \nFigure 2.5. Node of the\
    \ CAN bus system \nFigure 2.6. Comparison of protocols for the exchange of messages:\
    \ (a) MQTT; (b) \nMODBUS TCP. \nFigure 2.7. The IEEE model (a); compared to the\
    \ HTTP (b); the CoAP (c); the MODBUS \nTCP (d); and the MQTT (e). \nFigure 2.8.\
    \ OPC UA in the automation pyramid \nFigure 2.9. Architecture of the OPC UA Server\
    \ \nFigure 3.1. Node-Red Platform \nFigure 3-2: Deep learning in the context of\
    \ artificial intelligence \nFigure 3-3. Connections to a neuron in the brain.\
    \ xi, wi, f (·), and b are the activations, \nweights, nonlinear function, and\
    \ bias, respectively \nFigure 3.4 Simple neural network example and terminology.\
    \ (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nFigure\
    \ 3.5. Training and inference comparison \nFigure 3.6. Six-level rating for edge\
    \ intelligence \nFigure 3.7. IoU equation, Red is ground truth bounding box and\
    \ green is predicted \nbounding box \nFigure 3.8. Latency between two terminals\
    \ in a network \nFigure 3.9. OPC UA delay in OPC UA client server in an Ethernet\
    \ network \nFigure 3.10 Video transmission system delay sources. \nFigure 4.1:\
    \ Proposed UAV-IIoT Platform \nFigure 4.2. Development design of autonomous IIoT\
    \ flight \nFigure 4.3. Node-RED flow in the IoT gateway including the path from\
    \ the PLCs to the \nUAV, from the UAV to IBM Watson, and from Watson to the control\
    \ center. \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \nFigure 4.5. AR.Drone 2.0 mission in the concrete plant. \nFigure\
    \ 4.6. Communication process in the fog layer. \nFigure 4.7. Path used by the\
    \ drone to execute the mission in a concrete plant. \nFigure 4.8. Dataset used\
    \ to train the custom model in WVR service: (a) Shows images \nused to train the\
    \ Mixed class; (b) Shows Images used to train the Normal class. \nFigure 4.9.\
    \ Watson visual recognition test of new images not used in the training phase.\
    \ \nFigure 4.10. Node-RED flow and WVR results of an UAV photo. \nFigure 4.11.\
    \ OPC UA delay in OPC UA client server in an Ethernet network. \n \nxviii \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.12. Node-RED flow\
    \ used to calculate round trip latency (OPC UA Client to the \nOPC UA Server).\
    \ \nFigure 4.13. OPC UA client-server RTD to read one bit through different machines.\
    \ \nFigure 4.14. (a) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the S-G; \n(b) Simulation results of CPU load (%) versus OPC UA RTD (ms)\
    \ in the RPI-G. \nFigure 4.15. Probability density function of the delay of the\
    \ drone connected to the \ngateway when successive pictures from PC-G and RPI-G\
    \ are taken. \nFigure 4.16. Probability density function of the delay of the drone\
    \ connected to the \ngateway when successive pictures from S-G are taken. \nFigure\
    \ 4.17. CPU Load while taking successive photos and writing them in a folder in\
    \ \nthe PC-G. \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a folder in \nthe RPI-G. \nFigure 4.19. CPU Load while taking successive\
    \ photos and writing them in a folder in \nthe S-G. \nFigure 4.20. Probability\
    \ density function estimation of IBM WVR latency to classify an \nimage located\
    \ in the IoT gateway. \nFigure 4.21. Proposed AUV-IoT Platform \nFigure 4.22.\
    \ Proposed hardware architecture. \nFigure 4.23. Node intercommunications and\
    \ concurrent threads in the IoT gateway. \nFigure 4.24. Communication between\
    \ platforms. \nFigure 4.25. Fan mussel recognition training: defining a fan mussel\
    \ bounding box in \ndifferent cloud services. \nFigure 4.26. Pictures used for\
    \ custom CV model training. \nFigure 4.27. New specimen detection using the IBM\
    \ Python API. \nFigure 4.28. Triangular similarity using a single camera [47].\
    \ \nFigure 4.29. Closed control loop for object detection and tracking. \nFigure\
    \ 4.30. Basic closed-loop system with sensor and actuator delays. \nFigure 4.31.\
    \ Mission generated in IUNO and uploaded into AUV. \nFigure 4.32. Deploying the\
    \ platform to initiate the mission. AUV submarine connected \nto a buoy via a\
    \ DSL cable. \nFigure 4.33. Specimen detection and positioning in IUNO. \nFigure\
    \ 4.34. Communication edge cloud. (a) Training and inference in the cloud; (b)\
    \ \ntraining in the cloud, inference in the edge. \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \nFigure 4.36. Edge architecture\
    \ latency in the proposed platform. \nFigure 4.37. Cloud-based custom models for\
    \ detecting new specimens. \nFigure 4.38. BUSCAMOS-VIGIA framework. \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \nFigure 4.40. Platform’s communications in the tracking\
    \ algorithm. \nFigure 4.41. SAAO diagram. \nFigure 4.42. Calculation of acceptable\
    \ latency limits. Main ASV camera point of view. \nFigure 4.43. Comparison of\
    \ three different clouds vision API detection of boat in Los \nNietos port (Murcia,\
    \ Spain). \nFigure 4.44. Types and number of vessels used to train the vision\
    \ custom models. \nFigure 4.45. Performance of the cloud custom model object detection\
    \ in discerning \ndifferent boat types. \n \nxix \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.46. Performance differences between the Edge\
    \ and the cloud custom models. \nFigure 4.47. Cloud and edge custom models for\
    \ detecting new vessels. \nFigure 4.48. Latency of more than 300 samples. \nFigure\
    \ 4.49. Images analysed. Cloud/edge results comparison \nFigure 4.50. Scale experiment.\
    \ Equivalence of area and distance from integral reserve \n(Islas Hormigas) to\
    \ base station (right) and equivalent area in Mar Menor (left). \nFigure 4.51:\
    \ Edge (left) / cloud (right) trained model recognition tests. \nFigure 4.52.\
    \ Start of mission (MMM) of surveillance of area equivalent to integral \nreserve.\
    \ \nFigure 4.53. (a) Stopped vessel detected. Start TM mode. (b) Tracking Mode\
    \ (TM) test \nduring the experiment.  \nFigure 4.54. Wind energy IoT communication\
    \ architecture \nFigure 4.55. Hardware Setup \nFigure 4.56. Data flow between\
    \ different systems and across different protocols. \nFigure 4.57. Checking OPC\
    \ UA connection using UaExpert Software \nFigure 4.58. Communication between the\
    \ PLC 1512 and IBM Cloud through OPC UA \nprotocol using Node-RED installed the\
    \ industrial Gateway IOT2040. \nFigure 4.59. Dashboard Data of wind Sensors in\
    \ the IoT2040 Gateway \nFigure 4.60. Dashboard data wind sensors in the IBM Watson\
    \ Platform. \n \n \n1 \n \n \nCHAPTER 1 \n \n \n \n--------------------------------------------------\
    \ \n \nIntroduction \n \n-------------------------------------------------- \n\
    \ \n \n \n \nThis chapter presents the background, motivation and main contributions\
    \ of \nthis thesis. It presents an overview of using computer vision and AI in\
    \ IoT \nmonitoring and its applications. The limitations are highlighted of using\
    \ AI in \nIoT monitoring and control and its main constraints as motivations for\
    \ the \npresented work. Subsequently, the main contributions of this thesis are\
    \ \npresented. Finally, the organization of this thesis is detailed. \n \n2.3\
    \ \nBackground  \n \nEmerging new market demands and autonomous technologies such\
    \ as IoT \nare moving the environment of manufacturing companies towards smart\
    \ \nfactories.  The fundamental idea of IoT is a system where physical objects\
    \ are \nenhanced with embedded electronics (RFID tags, sensors, etc.) and connected\
    \ to \nthe Internet. Thus, IoT is based on both smart objects and smart networks\
    \ [1]. The \ndevices in the IoT network can be employed for collecting information\
    \ based on \nthe use cases. These include retail, manufacturing industries, autonomous\
    \ \nvehicles, smart grid, etc. These IoT devices can be used for tasks such as\
    \ tracking \nitems and objects, remote monitoring, and fully autonomous robots.\
    \ It is reported \nthat the amount of IoT devices has been growing every year\
    \ with the predicted \nnumber of devices by 2025 reaching 75.44 billion [2]. \n\
    \ \n2 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe use of IoT has\
    \ become ubiquitous and IoT devices are common in many \nfields. The integration\
    \ of IT and Operational Technology (OT) in the Industrial \nInternet of Things\
    \ (IIoT) enables the “smart factory” concept. IIoT uses IoT \ndevices and sensors\
    \ to monitor machines and environments to ensure the highest \nperformance of\
    \ equipment and processes. \nIn practice, IoT has stimulated the factories and\
    \ the governments to launch \nan evolutionary journey toward the fourth industrial\
    \ revolution called Industry \n4.0. The first industrial revolution started with\
    \ the introduction of mechanical \nmanufacturing equipment, followed by a second\
    \ that entailed the mass \nproduction of goods.  Since the beginning of the 1970's\
    \ and until today, the \nincreasing automation and control of manufacturing processes\
    \ through the use \nof electronics and computers is considered the third revolution\
    \ (digital \nrevolution). Leveraging IoT technology in the manufacturing environment\
    \ leads \nto the fourth stage of industrialization [3]. \nAt the heart of IoT\
    \ and smart manufacturing is the basic principle of Industry \n4.0, products being\
    \ manufactured, components and production machines must \ncollect and share data\
    \ in real time. This leads to a shift from centralized factory \ncontrol systems\
    \ to decentralized intelligence.  \n The exchange of real-time data and information\
    \ between different devices \nand parties is the key element of smart factories;\
    \ this data could represent the \nstate of production. Therefore, the next generation\
    \ of smart factories will need to \nbe able to adapt, almost in real time, to\
    \ constantly technological options and \nregulations [4].  \nTo perform effective\
    \ predictive maintenance (PM), massive amounts of data \nare collected, processed\
    \ and ultimately analyzed by machine learning (ML) \nalgorithms. ML can be used\
    \ on collected data to make predictions. Indeed, the \naccuracy of ML models depends\
    \ primarily on the data collected. \nTraditionally, IoT sensors transmit their\
    \ data readings to the cloud for \nprocessing and modeling. Processing and transmitting\
    \ massive amounts of data \nbetween IoT devices and infrastructure comes at a\
    \ cost. Edge computing, in \nwhich sensors and intermediate nodes can process\
    \ data, can reduce data \ntransmission costs and increase processing speed. These\
    \ techniques can reduce \nthe amount of data sent to the cloud for processing,\
    \ however there are potential \naccuracy trade-offs when ML algorithms use reduced\
    \ data sets. Another \napproach is to move ML algorithms closer to the data to\
    \ reduce the amount of \ndata transmitted [5]. \nVisual recognition technologies\
    \ based on artificial intelligence (AI) and the \nInternet of Things (IoT) can\
    \ offer a detection capacity close to human capabilities \n[6]. The AI cloud services\
    \ allows training of customized ML models that are able \nto classify the received\
    \ data or detect individual objects in a given image along \nwith their bounding\
    \ box and label. There are many different cloud APIs for \ncomputer vision, e.g.,\
    \ IBM, Google, Microsoft Azure and Amazon. They all \n \n3 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nprovide fairly similar capabilities, although some emphasize\
    \ object recognition, \nAmazon, or building custom models, like Microsoft Azure\
    \ and IBM.  \nThe strength of these cloud APIs is their ability to develop custom\
    \ models \nrapidly and download trained custom models to deploy them on the edge\
    \ for \nreal-time applications and low-latency requirements [7-8]. \nWhen computing\
    \ is deployed at the edge for real-time data processing, \naccuracy is also of\
    \ paramount importance. Further, it is also clear that for data \nreduction, the\
    \ edge or device is mainly exploited. However, since the initial \ntraining is\
    \ computationally intensive, the cloud is still used in most of the \nproposed\
    \ techniques for model training. In cases where a dedicated edge node is \nnot\
    \ available, network devices can also be exploited.  \n \n1.1.1 APPLICATIONS \
    \ \n \nMany fields and industries are using IoT as part of their architecture\
    \ today. \nIn the following, we will look at some of them and how IoT can be used\
    \ to further \nimprovements. \n \nA. Smart Factory  \n \nThe main concept of Industry\
    \ 4.0 is smart manufacturing and IIoT, where the \ncomponent, product and machine\
    \ will exchange data on the basis of real time [9]. \nSince exchange of data between\
    \ different devices in real time is the main element \nof smart factory, this\
    \ information can be considered as control, production status, \nsupplier and\
    \ customer order feedback information, material movement, \nsimulation. Smart\
    \ factory will provide the customer with service and smart \nproduct, which will\
    \ be connected to a network based on IoT. The smart factory \ngathers and scans\
    \ data from a related smart application and the product. \n \nB. Smart Vehicles\
    \  \n \nA fully autonomous vehicle can be defined as a vehicle that is capable\
    \ of \nperceiving its environment, deciding on a route to its destination and\
    \ driving it. \nIt is a smart car or robocar that uses a variety of sensors, computer\
    \ processors \nand databases such as maps to take over some or all of the driving\
    \ functions of \nhuman operators. In a few words, an autonomous (or driverless)\
    \ car can also be \ndefined as a vehicle that relies on a combination of Internet\
    \ of Things (IoT) \ndevices (e.g., sensors, cameras, and lidars), appropriate\
    \ software, and artificial \nintelligence to move without a human operator [10].\
    \ \n \nC. Smart grid  \n \n \n4 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nToday most of the power supply system is manually operated, and due to \n\
    some human error, there is loss of power. These small losses result in massive\
    \ \noutrage of power supply. This loss can be brought under control, and a 100%\
    \ \nefficient power transfer system can be designed using IoT, and it is known\
    \ as the \nSmart grid. It is a fully automated system based on blockchain technology,\
    \ which \nis entirely robust & encrypted. This power is divided into channels\
    \ for each \nindividual, and this channel is wholly encrypted with its stash key,\
    \ which is to \nbe decrypted. This results in an equalized power supply throughout\
    \ the grid \nwithout any power loss [11]. Given that millions of end users will\
    \ be involved in \nthe processes and information flows of smart grids, the high\
    \ scalability of these \nmethods becomes an important issue. To solve these problems,\
    \ cloud computing \nservices emerge as a viable solution by providing reliable,\
    \ distributed and \nredundant capabilities on a global scale. Moreover, the implementation\
    \ of an \nintelligent network application on top of mixed cloud and edge processing\
    \ \nmiddleware is able to achieve higher performance by leveraging edge node \n\
    processing and data aggregation to reduce communication with the cloud \nenvironment\
    \ [12]. \n \n \nD. Monitoring environmental parameters   \n \nEnvironmental monitoring,\
    \ as an integral part of smart campuses, is an \napplication that describes any\
    \ activity in a surrounding area to monitor the \nquality of an environment [13].\
    \ It is used in the assessment of any risk that may \nbe posed to the environment\
    \ and humans. The applications of IoT in \nenvironmental monitoring are vast:\
    \ Industrial site monitoring, seabed \nmonitoring, sea or ocean monitoring, environmental\
    \ protection, extreme weather \nmonitoring, \nwater \nsafety, \nendangered \n\
    species \nprotection, \ncommercial \nagriculture, etc. In these applications,\
    \ sensors detect and measure every type of \nenvironmental change [14]. \n \n\
    E. Smart Waste Management  \n \nOne of the major issues that modern cities are\
    \ facing is waste management. \nIt consists of multiple processes like managing\
    \ and monitoring waste, transport, \ncollection, disposal, etc. These processes\
    \ are costly and time-consuming. One can \noptimize these processes to reduce\
    \ cost, which can be used for solving other \nissues that smart cities can be\
    \ deal with. For instance, various sensors can be \ninstalled in places like trucks\
    \ or cans of garbage, which can detect type and \namount of garbage [15]. \n \n\
    F. Smart agriculture  \n \n \n5 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThanks to the IoT, it is possible to meet the food needs of a constantly \n\
    growing population. The analysis of smart agriculture data, i.e., land condition,\
    \ \nweather situation, and soil type, collected from the IoT network, can provide\
    \ \npractical information if used in combination with the data captured by sensors,\
    \ \nwhich measure the level of water resources, heat, humidity, chemicals, water\
    \ \nstress, pump condition, etc. This allows farmers to use fertilizers, water\
    \ and \npesticides in the most accurate amounts, at precise positions and with\
    \ efficient \nscheduling to improve crop yields. Smarter water use, such as monitoring\
    \ and \nsupervising the capacity, location, timing and period of water flow based\
    \ on data \nanalysis, increases irrigation efficiency and thus reduces costs [16].\
    \ \n \nG.  Smart Home  \n \nTo reduce user’s interference in controlling and monitoring\
    \ home settings as \nwell as home appliances, smart home is an emerging application\
    \ [17]. A smart \nhome provides many features for the user like measuring home\
    \ conditions (i.e., \nlight intensity, temperature, heating, etc.), operate home’s\
    \ Heating, Ventilating, \nand Air Conditioning (HVAC) appliances and control them\
    \ with reduced human \ninteraction [18]. Paper [19] presents an example of procedure\
    \ to develop a smart \nhome by combining IoT with cloud computing and web services,\
    \ use a platform \nfor implanting intelligence in actuators as well as in sensors\
    \ and facilitates \ninteraction within smart things using cloud services.  \n\
    \ \nH. Weather Forecasting  \n \nTo predict the state of the atmosphere for a\
    \ future time and for a given \nlocation, weather forecasting is very important.\
    \ Weather forecasting and \nmonitoring consist of a collection of data, assimilation\
    \ of data, and forecast \npresentation. Sensors at weather station used to sense\
    \ humidity, temperature \nwind speed, the moisture of soil, the intensity of light,\
    \ radiation, etc. Data coming \nfrom these sensors is huge in size and difficult\
    \ to monitor. The integration of this \nsensor infrastructure with cloud increases\
    \ its storage and computational \ncapabilities. It also provides effective solutions\
    \ for monitoring and presentation \nof data [20].  \n \nI. Health Care  \n \n\
    Sensors of pervasive healthcare applications make use of cloud computing \nand\
    \ IoT to allows a machine-to-machine communication regardless of the \nlocation\
    \ [21]. Nowadays, in modern hospitals, various body sensors are used to \nmeasure\
    \ and monitor physiological data of the patients. This sensitive collected \n\
    data is maintained for future diagnosis of patient. In some hospitals, this data\
    \ is \nmaintained at the local database. Due to this, doctors who are called to\
    \ handle \n \n6 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncritical cases\
    \ unable to analyze disease. After visiting to the patient only they can \ngive\
    \ proper treatment. However, using the cloud service, this issue can be solved\
    \ \ni.e., data of patients can be maintained and shared with doctors who are abroad,\
    \ \nso that they can treat the patient, independent of location [22].  \n \n1.1.2\
    \ IoT monitoring and controlling \n \nThe rising trends of the Internet of Things\
    \ (IoT) paradigm are attracting \nincreasing attention from both academia and\
    \ industry for their highly emerging \napplications of smartly connecting the\
    \ surrounding things or objects without \nhuman intervention [23]. Collecting\
    \ information from the surrounding \nenvironment to analyze, control, and making\
    \ correct action is the main idea for   \nIoT. To interchange data, IoT resources\
    \ using internet makes use of multiple \ninterconnected technologies like wireless\
    \ sensor network (WSN) and radio \nfrequency identification (RFID). IoT consists\
    \ of smart objects, which can be read, \nlocate, address, and control through\
    \ the internet using RFID, wireless LAN, or   \nsome other means [24]. In recent\
    \ time, IoT is getting more attention due to the \nadvancement of wireless technology.\
    \ The basic idea is due to variety of objects \nsuch as Sensors, RFID, actuators,\
    \ Near Field Communication (NFC), mobile \nphones, etc., which can interact with\
    \ each other by having a distinct address. \nArtificial Intelligence (AI) may\
    \ greatly support Internet of things in different \nways for physical (PHY), data\
    \ link (MAC), network, transport, and application \nlayers. AI cloud computing\
    \ is the fusion of machine learning (ML) capabilities of \nAI with cloud-based\
    \ computing environments, enabling connected, and intuitive \nexperiences. AI\
    \ has become more affordable through the use of cloud platforms. \nThe affordable\
    \ cost, coupled with cloud providers promoting AI as having a \nwidespread value,\
    \ leads to concerns that the technology will be misapplied. \nThere are different\
    \ IoT architectures adopted in research and development \nworks. The three-layer\
    \ IoT architecture shown in Figure 1.1, consists of a sensing \nor device layer,\
    \ which is also call as physical object layer whose main purpose is \nsensing\
    \ and data collection [25]. The second layer is the edge layer, its role is to\
    \ \nperform data transmission over the network, including sometimes being \nresponsible\
    \ for preprocessing and data storage before sending the data to the \ncloud. The\
    \ edge layer is also an appropriate place for ML deployment, allowing \nthe frameworks\
    \ to be implemented using hybrid architectures. \nA layer exists for the primary\
    \ processing of data. Data can be stored and \nprocessed by high-performance servers.\
    \ Predictive maintenance (PM) can \nmonitor machine health to determine likely\
    \ component failure. ML optimization \nmodels are deployed to help make intelligent\
    \ decisions about which production \nparameters to monitor. \n \n \n7 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 1.1. A three-layer IoT architecture\
    \ based on: Device, Edge and Cloud for Predictive \nMaintenance (PM) [25]. \n\
    \ \n \n1.1.3. Advantages of Using AI in the cloud \n \nAI technology is being\
    \ applied in most cloud services to drive interest in \napplication development.\
    \ Typical offerings combine the ability to leverage AI \nservices at a lower cost\
    \ with important data management systems that provide \nthe source of the data,\
    \ and thus the source of the models.  \nCloud-based AI solutions are different;\
    \ however, they have some \ncommonalities, as well as benefits and limitations.\
    \ First of all, the great benefit is \nthat these systems are inexpensive to operate.\
    \ To drive an AI application, \npayment can be made per hour used of each service.\
    \ This is perhaps the largest \nbenefit of cloud AI, really bringing AI down to\
    \ the level of a basic enabling \ntechnology. \nPublic clouds also offer cheap\
    \ data storage. Real databases or storage systems \ncan be leveraged as data input\
    \ into AI applications. Finally, they all provide SDKs \nand APIs that allow us\
    \ to integrate AI features directly into applications, and they \nsupport most\
    \ programming languages. \nWhile AI is a technology that allows a machine to simulate\
    \ human behavior, \nML is a subset of AI that allows a machine to automatically\
    \ learn from prior data \nwithout explicit programming. ML as a service (MLaaS)\
    \ is an umbrella concept \n \n8 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nof various cloud-based platforms that cover most infrastructure issues such\
    \ as \ndata pre-processing, model training, and model evaluation, with further\
    \ \nprediction. \nML offers several advantages, including accurate predictions,\
    \ speed, \nautomation, and scalability [26]. The ML method uses algorithms to\
    \ analyze data, \nfind rules and abstract the rules into models to classify and\
    \ predict unknown \ndata. It can significantly enhance the efficiency of data\
    \ processing and the \naccuracy of prediction results by applying machine learning\
    \ methods to \nmonitoring complex IIoT data. Furthermore, it can also detect abnormal\
    \ \nconditions of the IIoT to the greatest extent possible and reduce the loss\
    \ of \nproperties and lives [27]. On the one hand, Deep learning (DL) structures\
    \ the \nalgorithms into multiple layers in order to create an “artificial neural\
    \ network \n(ANN)”. Complex DL models are being developed, and in addition, CE\
    \ research \nis accelerating to provide more computational resources for DL models\
    \ to \nsupport more applications [28]. Prior to the use of ML in IIoT, the cognitive\
    \ ability \n(to learn the environment) of machines was simply a predefined heuristic.\
    \ \nHowever, sophisticated ML algorithms have improved the cognitive capability\
    \ \nby finding patterns in the data and making predictions [29]. \n \n1.1.4. Constraints\
    \ \n \nIoT is a novel paradigm to interconnect massive wireless devices, which\
    \ has \nthe potentials to be applied in diverse applications and fields. However,\
    \ due to a \nhuge number of wireless devices in IoT networks, many technical challenges\
    \ \nneed to be addressed, Figure 1.2 presents some limitations of current IoT\
    \ \nplatforms. \n \nFigure 1.2 Major limitations of current IoT platforms \n \n\
    \ \n9 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nBased on the presented\
    \ limitations, there are imperative directions that have \nto be considered in\
    \ the future for IoT research studies. \n \nA. Scalability  \n \nThe growing idea\
    \ of IoT which generates a tremendous amount of data for \nprocessing and storage\
    \ guide to enormous leap in the forthcoming year, and \nhence it becomes insistent\
    \ on making the scalable system. The vast application of \nIoT has increased the\
    \ number of devices being connected to the internet, which \nmeets the concern\
    \ to consider various complications that are arising in \nconnectivity [25]. Different\
    \ sources like the internet, social media, machine, and \nmany other devices generate\
    \ data. Thus, special attention must be given for \ntransportation, access, storage,\
    \ and processing of these large sets of structured \nand unstructured digital\
    \ data [25].  \n \nB. Interoperability  \n \nAs the data sharing among smart devices\
    \ is increasing day by day, it is \nnecessary to manage these data transfer properly\
    \ among the system [30]. \nInteroperability can be considered as the potentiality\
    \ of two systems to \ncommunicate, exchange information, or program, or transfer\
    \ the data among \neach other and to implement the given data [31]. It is the\
    \ exchange of information \namong different computers through wide area networks\
    \ or local area networks. \nIt is critical for IoT as most of the communication\
    \ takes place as a machine to \nmachine [32]. \n \nC. Real-Time (Delay)  \n \n\
    Meeting real-time latency requirements depends on how data is collected \nand\
    \ processed [33]. This becomes more severe as IoT applications that involve \n\
    rich data types such as images evolve. In addition, developing real-time analytics\
    \ \nin the cloud is nearly impossible to achieve. \nA variety of IoT applications\
    \ require local analytics. For instance, in the \ncontext of IIoT, to quickly\
    \ turn on or off a piece of equipment in a production \nenvironment can prevent\
    \ a catastrophic situation. Analytics depend on ML \nalgorithms that are computationally\
    \ expensive for some tiny sensors. In addition, \nthe power consumption of small\
    \ sensors has been one of the main concerns even \nbefore the emergence of ML\
    \ in IoT. Thus, achieving the goal of real-time with a \nsensor cloud architecture\
    \ seems ambitious. \nThe limited computational capacity of sensor nodes is a major\
    \ challenge. \nTherefore, a hybrid architecture to implement computationally intensive\
    \ tasks \nsuch as training on the cloud and model deployment for prediction on\
    \ the \nsensing node has emerged. However, this approach also presents challenges\
    \ in \n \n10 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nthe case where\
    \ models require retraining based on new data. In this case, all new \ndata must\
    \ be moved to the cloud, which incurs costs in terms of latency, energy \nconsumption,\
    \ and network resource usage [34]. \n \nD. Accuracy  \n \nThere are many possibilities\
    \ for designing a Neural Network (NN) model, \nprovided that different hyperparameters\
    \ in the network provide a different level \nof accuracy. Particularly, a high\
    \ accuracy model requires more memory than a \nlow accuracy model due to the number\
    \ of parameters. The metric used to \nmeasure accuracy depends on the domain in\
    \ which the ML algorithm is applied. \nIn IIoT, a traditional approach to data\
    \ collection is to stream data from \nsensing devices to the cloud where it is\
    \ processed and modeled. Sensing devices \ngenerate huge amounts of data, continuously\
    \ or periodically, often in a very short \nperiod of time. For instance, in one\
    \ second, thousands of records can be generated \nby one machine [35]. According\
    \ to the Cisco cloud index (2013-2018), an \nautomated facility can generate one\
    \ terabyte of data per hour. For this purpose, \napproaches such as sampling,\
    \ compression, filtering are used to reduce the size \nof data. These techniques\
    \ reduce the amount of data transmitted to the cloud. \nHowever, there are potential\
    \ accuracy trade-offs for ML models that use reduced \ndatasets, as the accuracy\
    \ of ML models depends primarily on the data collected. \nThe accuracy of models\
    \ trained on reduced data should also be a concern \nwhen optimizing for energy\
    \ consumption and latency. This is more important in \ndeep learning approaches\
    \ that require more data to be trained. \nIn current IIoT systems based on edge\
    \ computing, edge devices can only \nperform lightweight computing tasks. To enable\
    \ edge devices and servers to \nperform more complex tasks with higher data processing\
    \ performance and lower \nlatency, edge intelligence (EI) is applied to the IIoT\
    \ edge to make the devices and \nservers intelligent. However, an AI model can\
    \ be trained to make predictions and \ndecisions with high accuracy; however significant\
    \ amounts of training and \nverification data are required. For edge devices,\
    \ training and operating the AI \nmodel is challenging due to limited computing\
    \ and storage resources. \n \nE. Security  \n \nAs the IoT trend inflates multiple\
    \ interconnections and device heterogeneity, \nit eventually generates cyber-attacks.\
    \ Thus, data security is one of the most \ncritical issues. As there is an increase\
    \ in the number of connected devices, there \nare possibilities of cyber-physical\
    \ security vulnerabilities that can be exploited by \nvarious attackers [36].\
    \ Security is a key pillar of the internet, which is the main \nchallenge of IoT.\
    \  \nTherefore, it is necessary to learn from these incidents: industries are\
    \ now the \ntarget of attackers and there is an urgent need to address this issue.\
    \ IIoT is \n \n11 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nsometimes thought\
    \ of as the integration of operational technology (OT) and \ninformation technology\
    \ (IT), with OT comprising the factory network where \nmanufacturing is performed\
    \ and IT comprising the enterprise network [37]. \nThese two components have different\
    \ security requirements, which must be \naddressed to prevent compromise of the\
    \ IIoT infrastructure. \n \n1.2 Motivation  \n \nAlthough IoT has been widely\
    \ used in the above applications, a number of \ncritical limitations have hindered\
    \ the use of AI in various implementations. These \nlimitations tend to mainly\
    \ affect the system response time and the efficiency of \nthe proposed solution.\
    \ The various aspects of DL that need to be improved in an \nIoT concept include\
    \ smart algorithms with improved efficiency and support for \nbetter platforms.\
    \ For this reason, the following issues had to be investigated to \novercome these\
    \ limitations of using AI in IoT architecture. \n \nA. Interoperability \n \n\
    Recent advances in manufacturing technology, such as industrial internet, \ncyber–physical\
    \ systems, AI (Artificial Intelligence), and machine learning have \ndriven the\
    \ evolution of manufacturing architectures into integrated networks of \nautomation\
    \ devices, services, and enterprises. One of the resulting challenges of \nthis\
    \ evolution is the increased need for interoperability at different levels of\
    \ the \nmanufacturing ecosystem. Interoperability means the ability of two or\
    \ more \nparties, machine or human, to make a perfect exchange of content.  \n\
    The IoT is a dynamic global network infrastructure with self-configuring \ncapabilities\
    \ based on interoperable, standard communication protocols, enabling \nall objects\
    \ to communicate with each other. The application of IoT to the \nindustrial domain\
    \ has given rise to a new research area called the Industrial \nInternet of Things\
    \ (IIoT). IIoT is a new service-oriented industrial ecosystem that \nuses networked\
    \ interconnection of industrial resources, data interoperability, \nand system\
    \ interoperability to enable flexible resource allocation, rational \nprocess\
    \ optimization, on-demand process execution, and rapid adaptation of \nenvironments\
    \ [38]. In general, interoperability is defined as the ability of \nheterogeneous\
    \ networks, applications, or computer components to exchange and \nuse information,\
    \ i.e., to speak and comprehend each other [39]. Suited to the IoT \ncontext,\
    \ this refers to the ability of heterogeneous components to exchange and \nshare\
    \ data and functions to achieve a desired goal (defined by a use case or \napplication),\
    \ regardless of the communication protocol used or the format of the \nexchanged\
    \ data.  \nUp to only a few years ago the communication systems for industrial\
    \ \nautomation aimed only at real-time performance suitable for industry and \n\
    \ \n12 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmaintainability based\
    \ on international standards [40]. The Industry 4.0 concept \nhas the flexibility\
    \ to achieve interoperability between the different industrial \nengineering systems.\
    \ To connect the different industrial equipment and systems, \nthe same standards\
    \ and safety levels are required. Open Platform \nCommunications Unified Architecture\
    \ (OPC UA) is a machine-to-machine \n(M2M) communications protocol developed to\
    \ create inter-operable and reliable \ncommunications and is now generally accepted\
    \ as standard in industrial plant \ncommunications [41].  \nThe domain extends\
    \ from software, devices, and control systems on the \nfactory floor to Internet-based\
    \ cloud platforms that provide various on-demand \nservices. \nA successful implementation\
    \ of interoperability in smart manufacturing \nwould therefore result in efficient\
    \ communication and error-free data exchange \nbetween machines, sensors, actuators,\
    \ users, systems and platforms. The \narchitecture and platforms used by machines\
    \ and software packages are a major \nchallenge in this regard. A better understanding\
    \ of the subject can be obtained by \nstudying industry-specific communication\
    \ protocols and their respective logical \nsemantics.  \nTo be more precise and\
    \ in accordance with [42], three levels of \ninteroperability can be specified\
    \ to achieve horizontal interoperability between \ndifferent components, each\
    \ level covering a different facet of interoperability and \ncommunication: \n\
    \ \n• Technological interoperability is given if the two components are physically\
    \ \nconnected to each other and can transmit any type of information on the \n\
    transmission layer [42]. This level of interoperability concerns the lower \n\
    transmission layers of the OSI model (i.e., the physical, data link, network and\
    \ \ntransport layers) and the corresponding protocols. \n \n• Syntactic interoperability\
    \ is ensured if the data format, including encodings, \nas well as the communication\
    \ interface format are clearly defined and agreed \nupon between the two components\
    \ [42]. The abstract term \"communication \ninterface format\" refers to the protocol\
    \ used on the application layer and \nprovided as communication interface by the\
    \ respective component. As with \ntechnological interoperability, it is not necessarily\
    \ required that the two \ncomponents agree on the same protocol, as long as there\
    \ is a possibility of \nadapting two different protocols (the same applies to\
    \ the format and encoding \nof the data embedded in the protocol(s)). \n \n• Semantic\
    \ interoperability is ensured if both components agree on the same \ninformation\
    \ model describing the topic of the exchanged information as well \nas the provided\
    \ communication interfaces [42] (i.e., the meaning of the \nexchanged messages\
    \ with respect to the used protocol). \n \n13 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 1.3 depicts the mapping of these three interoperability\
    \ levels defined \nin [42] to the OSI layers. It should be noted that this mapping\
    \ is not strict and that \nthe boundaries between the OSI layers may vary depending\
    \ on the \nimplementation of the application concerned. \n \n \nFigure 1.3 Mapping\
    \ of interoperability levels to OSI layers \n \n \nThe evolution from traditional\
    \ hierarchical models of enterprise control \nsystem integration, or automation\
    \ pyramid, to integrated networks of smart \ndevices, \ncloud \nservices, \nand\
    \ \nextended \nenterprises \nrequires \nseamless \ncommunication and information\
    \ exchange between heterogeneous and \ntraditionally silent systems (Figure 1.4).\
    \  \nDifferent types of interoperability problems may arise, due to the diverse\
    \ \nnature of interactions in the emerging automation networks. Thus, there is\
    \ a need \nfor vertical interoperability between devices and shop floor automation\
    \ services, \nas well as horizontal interoperability between enterprises and cloud\
    \ service \nplatforms. \n \n \n \n \n14 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 1.4. Automation Pyramid vs Automation Network [43] \n\
    \ \n \nB. Low-latency and ultra-Reliability \n \nThe industrial smart facility\
    \ requires multiple synchronized processes that \nrequire low latency and higher\
    \ reliability to achieve the necessary performance \n[44]. Furthermore, AI methods\
    \ applied to IIoT must be able to address these \nissues as well as other parameters\
    \ such as network deployment and resource \nmanagement [45]. Nevertheless, the\
    \ competence and usefulness of DL-based IIoT \nscenarios are still in the evolutionary\
    \ phase, requiring exclusively the strict low-\nlatency and ultra-reliability\
    \ requirements of IIoT. Therefore, further research \nefforts are needed in this\
    \ direction to establish a theoretical and practical \nbackground for DL-IIoT\
    \ to ensure low-latency and ultra-reliable communication. \nFast and efficient\
    \ computing is another key feature that can affect not only \nlatency and reliability\
    \ but also many other performance parameters in smart \nindustries. As mentioned\
    \ earlier, IIoT requires powerful and useful tools to \ncompute big data obtained\
    \ from various processes and analyze them on specific \nplatforms including servers,\
    \ transmission media, and storage. \nIntelligence at the edge should push DL computations\
    \ from the cloud to the \nedge as much as possible, enabling various distributed,\
    \ low-latency and reliable \nintelligent services, as shown in Figure 1.5. \n\
    \ \n15 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nDL services can be\
    \ deployed close to the requesting users and the cloud only \nintervenes when\
    \ additional processing is required [46], which significantly \nreduces the latency\
    \ and cost of sending data to the cloud for processing. \n \n \n \nFigure 1.5.\
    \ Capabilities comparison of cloud, on-device and edge intelligence [47] \n \n\
    Currently, hybrid cloud-edge computing is used to perform fast and efficient \n\
    computation and provides a comprehensible computing infrastructure for IIoT. \n\
    It is considered appropriate to use the edge-based computing infrastructure due\
    \ \nto its ability to reduce latency and improve the learning process in the network.\
    \ \nNonetheless, the integration of distributed and edge computing infrastructure\
    \ \nfor IIoT remains an open research issue [48]. Particularly, the coupled realization\
    \ \nof distributed and parallel learning for edge-based designs requires further\
    \ \noptimization to attain higher productivity, self-organization, and lower runtime.\
    \ \n \n \nC- Energy consumption of mobile IoT devices \n \nRobotic engineering\
    \ systems are deployed in industry today and are \nconsidered vital to the progress\
    \ of humanity from an industrial perspective in \nthe new digital age. \nThe Internet\
    \ of Robotic Things (IoRT) empowers robotic objects in different \nenvironments\
    \ to be active players in various applications and to share and \nexchange information\
    \ with other robotic objects, IIoT devices and humans. IoRT \napplications are\
    \ developing in parallel with IIoT advancements, combining \ninformation technology\
    \ (IT) used for data-centric computing and operational \n \n16 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ntechnology (OT) used in enterprise and\
    \ industrial operations integrating \nsupervisory control and data acquisition\
    \ (SCADA) systems and programmable \nlogic controllers (PLCs), where industrial\
    \ applications are increasingly \nintegrated, and where new smart connectivity\
    \ networks are used.  \nTransferring large datasets to a central cloud is an energy-intensive\
    \ \noperation, and new computing paradigms are being used and implemented for\
    \ \nIoRT applications. Smart connectivity networks can facilitate the transfer\
    \ and \nprocessing of information in an energy-efficient and high-performance\
    \ manner. \nHowever, deployed batteries have a specific charge rate and, therefore,\
    \ the \noperating time of robots is limited. Autonomous mobile robots are powered\
    \ by \nbatteries mounted on their platforms to provide energy to the on-board\
    \ sensors, \nmicrocontrollers, peripheral modules and servos.  \nDevelopments\
    \ in IoT, AI, and connectivity technology [49] enable IoRT \napplications to reduce\
    \ power consumption and improve energy efficiency, \nresulting in lower costs\
    \ and latency. Energy efficiency, real-time processing, \ncomputation, and analysis\
    \ efficiency of IoRT devices, efficient task offloading, \nand intelligent service\
    \ response time of other IoRT devices and agents must be \naddressed by developing\
    \ new collaborative processing techniques at the edge. \nAlong with ensuring dynamic\
    \ network/resource slice management, dynamic \ndevice management, and the necessary\
    \ containment between different IoRT \ndevices and different complex applications.\
    \ \n \n1.3 Objectives and contributions \n \nThe objective of this thesis is to\
    \ develop and evaluate a real-time IoT \nframework capable of connecting AI cloud\
    \ services with different industrial \nsystems and platforms, trying to overcome\
    \ the limitations and challenges \nshowed in previous sections. Therefore, the\
    \ required systems and networks must \nensure the optimal trade-off between response\
    \ time and system accuracy, \nkeeping in mind that cloud computing is introduced\
    \ in the control loop. In this \ncontext, the main objectives of this work are:\
    \ \n \n1. The design of an IoT architecture to enable interoperable systems \n\
    connecting different IoT devices using different protocols and technologies, \n\
    together with the different proposed systems and networks. To this end, some \n\
    considerations were considered: \n \n \n- \nProtocols and software suitable for\
    \ interoperability and connectivity \nconstraints: The interoperability challenge\
    \ can be overcome by using \nadvanced software deployed in the IoT gateway, which\
    \ can be considered \nas the junction interface between the physical and cloud\
    \ worlds. This \n \n17 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    software must interact simultaneously with the different systems \ninvolved through\
    \ different protocols.  \n \n- \nThe appropriate devices capable of providing\
    \ minimal response time: The \nchoice of an IoT gateway is crucial in terms of\
    \ latency and accuracy, as it \nis at the heart of processing and transmitting\
    \ data to the different systems \nand platforms. \n \n \n2. To further improve\
    \ the trade-off between latency and accuracy, the \nfollowing points are considered:\
    \ \n \n- \nThe most efficient cloud computing solutions for each use case: The\
    \ \nimplemented cloud services must ensure that data is transferred, \nprocessed\
    \ and returned at speeds that meet the needs of the application. \n \n- \nFlexibility\
    \ to use AI models in the edge and the cloud for improved \nperformance: The ability\
    \ to deploy the cloud AI models at the edge can \nfacilitate the use of cloud\
    \ technologies in different sectors. In addition, the \nhybrid cloud/edge architecture\
    \ must ensure a real-time control loop for \nrelevant latency and accuracy. \n\
    \ \nContributions:  \n \nThe main innovative contribution of this thesis is to\
    \ include cloud services in \na control loop, to improve the decision making of\
    \ a factory and improve the \nperformance of an industrial control system.  \n\
    Cloud AI services can also be integrated into a drone control loop as an input\
    \ \ncontributing to improve the monitoring capability to find and track stationary\
    \ \nand moving objects. To this end, the work in this thesis has been divided\
    \ into \nseveral parts depending on the scenario used. Thus, several contributions\
    \ could \nbe enumerated: \n \n1. The validation of the IoT architecture proposed\
    \ in this thesis in the industry \nas a way to control and monitor the status\
    \ of devices and systems integrating \nIoT protocols and edge-computing \n \n\
    2. The Introduction of cloud services computer vision (CV) techniques as a part\
    \ \nof the industrial control loop to improve the operation of the production\
    \ \nprocess in a factory. \n \n3. The integration of CV cloud services into the\
    \ control loop of a drone for \nmonitoring and seeking for a new object using\
    \ the drone's cameras. \n \n18 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n4. The demonstration of that a hybrid AI cloud architecture can solve the\
    \ \nproblem of latency and accuracy of the control system. Choosing the correct\
    \ \nAI CV cloud services is crucial in terms of latency and accuracy of the control\
    \ \nsystem, as the systems need to respond in real time with accuracy.  \n \n\
    5. The use of edge computing topology to reduce latency in low-bandwidth \nenvironments.\
    \ Cloud computing topology improves accuracy at the expense \nof increased latency.\
    \ To meet the system’s requirements, in this thesis, a smart \nalgorithm to optimize\
    \ autonomy is propose and developed. This Is done by \nselecting the appropriate\
    \ AI technology for the scenario being monitored. \nThis proved to be crucial\
    \ in deciding the best source of artificial intelligence \nto be used to achieve\
    \ the specified objectives in each stage in real time. The \nproposed smart algorithms\
    \ ensure a trade-off between latency and accuracy. \n \n6. The validation of the\
    \ proposed IoT architecture for an autonomous marine \nrobot for protection and\
    \ permanent surveillance in marine protected areas \nbased on AI cloud recognition\
    \ services. \n \n \n2.5 Thesis organization \n \nThis thesis is organized and\
    \ divided into 5 chapters. This first chapter has \nbeen dedicated to the presentation\
    \ of IoT, especially Industrial IoT, and the \nchallenges faced in using an IoT\
    \ architecture as the one presented in this thesis. \nMoreover, we discuss the\
    \ constraints and benefits of using AI in the cloud and \nfinally the main motivations\
    \ and contributions of this thesis have also been \nrevealed. The core of this\
    \ thesis is detailed in the following chapters:  \n \n \nChapter 2: Outlines the\
    \ IoT Monitoring and Control Architecture Based on \nUnmanned Vehicles and defines\
    \ some of the protocols adopted in Industrial IoT. \nIt describes also the types\
    \ of IoT architectures, and the use of computer vision \nand AI at the edge using\
    \ cloud services. \n \nChapter 3: This chapter provides an overview of the different\
    \ solutions \nproposed to employ artificial intelligence for monitoring systems\
    \ in an IoT \narchitecture. We start with a review of the state of the art for\
    \ the different AI \ntechniques used for an interoperable IoT architecture. Then,\
    \ a comparison \nbetween the different proposed methods is highlighted. We discuss\
    \ the different \nmethods and factors used to appraise the latency and accuracy\
    \ of the proposed \n \n19 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nAI models and finally a latency assessment for an unmanned vehicle IoT \n\
    architecture. \n \nChapter 4: This chapter focuses on monitoring and control applications\
    \ in a \nIoT architecture. This chapter presents different applications using\
    \ advanced \ndevices and robots to control and monitor areas using computer vision\
    \ and AI \ncloud services. The proposed AI approaches are compared in terms of\
    \ latency \nand accuracy to validate their performance.  \nThe first application\
    \ was about a wind power system connected to the IBM \ncloud for monitoring. The\
    \ second application was to feed results from AI services \nin the cloud into\
    \ an industrial control loop. The AI results come from an \nunmanned aerial vehicle\
    \ camera taking images of materials being transported in \na concrete plant. The\
    \ other application, proposes an AUV model system designed \nto track a species\
    \ of Mediterranean fan mussel, using cloud computing services \nwith edge computing\
    \ as alternative processing units. \nThe latter, proposes an autonomous marine\
    \ robot for protection and \npermanent surveillance in marine protected areas\
    \ based on AI cloud recognition \nservices. \n \nChapter 5: Summarizes the contributions\
    \ of the whole thesis and outlines \nsome directions for future work. \n  \n \n\
    \ \n \n20 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 2 \n \n \n \n-------------------------------------------------- \n \nPerformance\
    \ analysis of IoT Monitoring \nand Control System Based on UV, \nMachine Vision\
    \ and Artificial \nIntelligence \n--------------------------------------------------\
    \ \n \n \n \n \n2.1 Introduction  \n \nAutonomous vehicles have played an increasingly\
    \ important role in \nmonitoring different environments, they are now considered\
    \ one of the best \nremote sensing techniques for collecting data over large areas.\
    \ They are now used \nin different sectors as detection tools to proactively solve\
    \ or prevent many \nproblems. In industry, as an example, unmanned aerial vehicles\
    \ (UAVs) can be \nused for inspections [50], to quantify production and monitor\
    \ construction \nprocesses [51] \nand help make decisions.  \nAutonomous underwater\
    \ vehicles (AUVs) are widely used in various marine \napplications: visual inspection\
    \ of infrastructures [52], aquaculture [53], marine \nbiodiversity mapping [54],\
    \ marine geoscience [55], and visual monitoring of \nmarine life [56] and recovery\
    \ of autonomous underwater vehicles [57]. \nUSVs are currently the subject of\
    \ a number of publications related to ocean \nmonitoring applications related\
    \ to weather/storm forecasting and disaster \n \n21 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nmanagement [58]. They can play a critical role in disaster\
    \ research [59] by \nreplacing rescue teams in remote and dangerous areas [60],\
    \ or by monitoring \ncovered environmental areas such as water bodies [61], or\
    \ by performing long-\nterm monitoring [62]. AI has the potential to be a powerful\
    \ tool and be deployed \nfor marine area surveillance by detecting and recognizing\
    \ vessels through \nartificial intelligence (AI)-based image recognition services.\
    \ \nComputer vision (CV) has particularly improved the field of object detection\
    \ \nand image classification. Visual recognition systems can reach impressive\
    \ \nperformances, thanks to the latest developments in neural networks, in particular\
    \ \ndeep learning (DL). Although all the developed DL algorithms can be deployed\
    \ \nin the cloud, the present cloud computing systems are unable to manage and\
    \ \nanalyze the massive amount of computing power and data. Edge intelligence\
    \ is \nenvisioned to replace DL computing in the cloud, providing a variety of\
    \ reliable, \nlow latency, distributed intelligent services. \n The IoT gateway\
    \ is used to connect the autonomous vehicles and control \nsystems to the internet\
    \ and cloud services, it is able to connect the sensor network \nto the cloud\
    \ computing infrastructure and perform edge and fog computing and \nserves as\
    \ a bridge between sensor networks and cloud services.  \nIntegrating autonomous\
    \ robots into the IoT represents an interoperability \nchallenge, as every IoT\
    \ system has its own communications protocol. Moreover, \na small error or delay\
    \ beyond the tolerated limit could result in a disaster for \nvarious applications.\
    \ The IoT gateway must not only address the challenge of \ninteroperability of\
    \ interconnected systems but also process and transmit data in \nreal-time. \n\
    The current cloud computing system is increasingly unable to cope with the \n\
    massive amount of data it receives [63]. Edge computing, which is composed of\
    \ \nsmart nodes and could take the place of cloud processing, is expected to solve\
    \ \nthis problem since it is closer to the users than the cloud [64]. These smart\
    \ nodes \nrange from smart gateways to offsite ruggedized nodes, to on-premises\
    \ heavy \nstorage nodes and data center servers at the edge. \nNew architectures\
    \ have recently been proposed to address the latency issue. \nA hybrid cloud/edge\
    \ architecture can provide a real-time control loop for better \nlatency and accuracy\
    \ and meet several system requirements. \nThis chapter begins with a description\
    \ of the architecture of three IoT layers, \nand its main components, from data\
    \ detection to its processing. It describes \nseparately the technology used in\
    \ each layer for different use cases. We discuss \nthe use of computer vision\
    \ techniques at the edge and in the cloud, and the effect \nof interoperability\
    \ and real-time requirements. Finally, we end the chapter by \npresenting the\
    \ different cloud APIs used. \n \n2.2 UV IoT architecture \n \n \n22 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2.2.1. Most Common IoT Architectures \n\
    \ \n1. Common IoT Architectures \n \nOne of the main challenges in the technology\
    \ domain to support the \ndeployment of IoT systems is to define a reference architecture\
    \ that supports both \ncurrent and future features. Therefore, such an architecture\
    \ must be: -scalable, -\ninteroperable, -distributive, -able to operate with few\
    \ resources (Computational \npower) -secure so as not to allow unauthorized access.\
    \ \nCurrently, a single reference architecture does not exist, and creating one\
    \ is \nvery complicated regardless of many standardization efforts. One of the\
    \ main \nproblems is related to the natural fragmentation of possible applications,\
    \ each of \nwhich depends on many different variables and design specifications.\
    \ Figure 2.1 \ndescribes some of the most common IoT architectures. \n \n \nFigure\
    \ 2.1. Most common IoT architectures [67] \n \n2. Three-Layer architecture  \n\
    \ \n- Perception, represents the physical layer of the objects and includes all\
    \ the \nfeatures. \n- Network, that stands for the communication layer responsible\
    \ for the \ntransmission of data to the application layer through various protocols\
    \ and \ntechnologies. \n- The application, which is the application layer in which\
    \ the software offering a \nspecific service is implemented. \n \n \n23 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n \n3. Service-oriented architecture\
    \ \n \nIt represents the four-layer IoT architecture based on SoA, in which there\
    \ is \nthe perception layer, the network layer, the service layer and finally\
    \ the \napplication layer. The SoA is designed to coordinate services and enable\
    \ the reuse \nof hardware and software components. Generally, SoA is based on\
    \ a component \nmodel, which can be designed to connect different functional units\
    \ of \napplications through interfaces and protocols [65-66-67]. \nSoA can be\
    \ easily integrated into the IoT architecture, by extending the three-\nlayer\
    \ architecture, by adding a new layer between the network layer and the \napplication\
    \ layer, called the service layer, which provides services to support the \napplication\
    \ layer. \n \n4. Middleware Architecture \n \nAnother important and very common\
    \ architecture in IoT is the middleware-\nbased IoT architecture or five-layer\
    \ architecture [68]. A five-layer is composed of \nfive levels: perception layer,\
    \ network layer, middleware layer, application layer, \nand business layer. \n\
    Middleware is gaining more and more importance in recent years due to its \nmajor\
    \ role in simplifying the development of new services and integrating legacy \n\
    technologies into new ones.  \nA proposed IoT architecture has to consider many\
    \ factors such as reliability, \ninteroperability, scalability, quality of service,\
    \ etc. In this regard, middleware \nbased IoT architectures help create applications\
    \ more efficiently; they act as a \nconnection between users, data and applications.\
    \ \nMiddleware, in general, is a software or programming service that can \nprovide\
    \ an interposed abstraction between IoT technologies and applications. In \nmiddleware,\
    \ the details of the different technologies are hidden, and standard \ninterfaces\
    \ are provided to allow developers to focus on application development \nwithout\
    \ regard to compatibility between applications and infrastructures. \nMiddleware\
    \ architecture has various advantages, as it can support various \napplications,\
    \ standard protocols, provides standard interfaces and can run on \nvarious operating\
    \ systems and platforms. Middleware plays an important role in \nstandardization,\
    \ providing portability and standard protocols to enable \ninteroperability and\
    \ interaction of services between heterogeneous networks, \ndevices and applications.\
    \ \nMiddleware supports distributed computing and provides a stable high-\nlevel\
    \ interface for applications. \nRegardless, the middleware layer has some critical\
    \ functionality, such as \naggregation and filtering of data received from hardware\
    \ devices, information \nretrieval and device access control for applications.\
    \ \n \n24 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn summary,\
    \ depending on the application, it may be necessary to add \nadditional layers\
    \ or adapt the architecture to the specific application to be \nrealized. An architecture\
    \ can be realized by being adapted to the context of \nexisting IoT architectures,\
    \ such as a server-based architecture, or an architecture \nbuilt from scratch\
    \ such as cloud-based architectures, Edge computing-based \narchitectures, or\
    \ Social Internet of Things (SIoT) architectures [67]. \n \n2.2.2. IoT Monitoring\
    \ and Control Based on Unmanned Vehicles \n \nA drone monitoring system is developed\
    \ as a control system to reduce the \ntime and cost of inspection. The integration\
    \ of drones or unmanned vehicles into \nthe IoT architecture can be presented\
    \ in three layers (Figure 2.2), with drones \nbeing part of the first layer as\
    \ the data generation layer. The first layer can also \ncontain a control system\
    \ connected to a central collection point, which is the IoT \ngateway. The second\
    \ layer is edge/fog computing for computation, storage and \ncommunications. The\
    \ last layer is a cloud back-end with image processing \ntechniques. The Edge/fog\
    \ layer connects the control layer to the drone system, \nthe drone system to\
    \ the cloud, and finally the cloud to the control system. \n \nIn general, the\
    \ Three-Layer architecture can be defined as below:  \n \n• Generation and control\
    \ layer: this represents the physical layer of the objects \nand includes all\
    \ the control systems. \n• Network and data communication layer (Edge/Fog): this\
    \ is the \ncommunication layer responsible for transmitting data to the visualization\
    \ \nand processing layer through various technologies and protocols, can also\
    \ be \nused as a processing layer in case of real time applications. \n• The visualization\
    \ and processing layer, which represents the application layer \nin which the\
    \ software offering a specific service is actually implemented or \nmay just be\
    \ an interface to analyze and visualize the data received from the \nconnected\
    \ systems. \n \n \n \n25 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \n \nFigure 2.2. Industrial UV-IoT Architecture \n \n \nThe control system\
    \ (controllers) receives data from remote or connected \nsensors that measure\
    \ the process variables’ (PVs) setpoints (SP). When the system \ndetects a trend\
    \ change between PVs and SP, the change is routed to the \nprogrammable logic\
    \ controllers (PLCs) and the central point (IoT gateway) to \ntrigger the UV system’s\
    \ reaction. \nThe traditional monitoring system illustrated by humans is replaced\
    \ by a \nremote computing algorithm in the cloud and a UV system, in that the\
    \ UV camera \nserves as an additional monitoring sensor that is processed in the\
    \ cloud to imitate \nthe visual inspection of an operator. The UV can navigate\
    \ to a specific point to \noversee the process using the front camera. The UV\
    \ system is triggered \nautomatically by responding to sensor data from the monitoring\
    \ system and data \nanalyzed in the IoT gateway. The IoT gateway receives the\
    \ captured photos and \nsends them to the cloud, which adopts deep learning techniques\
    \ to analyze and \nsend the results to the IoT gateway and the control system\
    \ to confirm the \nanomaly and make the necessary changes. \n \n2.2.3 IoT Gateway\
    \ Capabilities \n \nThe IoT gateway is capable of connecting the sensor network\
    \ to the cloud \ninfrastructure, performing edge computing, and serving as a bridge\
    \ between the \nsensor networks and cloud services [69]. \n \n26 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nIn the IoT gateway, various software and\
    \ APIs can be installed to establish \nthe connection with different parts of\
    \ each IoT layer. It also allows collecting, \nprocessing, and transmitting the\
    \ data and results to other systems for further \nprocessing or decision making.\
    \ \n In the IoT gateway, various IoT software and APIs, drone libraries and AI\
    \ \nmodels can be installed. These packages are required to ensure the transmission\
    \ \nof data between the different systems according to the protocols involved.\
    \ Since \neach IoT system has its own communication protocol, the IoT gateway\
    \ has to \nsupport different communication protocols, which presents an interoperability\
    \ \nchallenge. \nAn IoT gateway can be defined as a physical device with software\
    \ programs \nand protocols that mediate between smart devices, sensors, controllers\
    \ and the \ncloud. The IoT gateway provides the necessary connectivity, security\
    \ and \nmanageability, while some of the existing devices cannot share data with\
    \ the \ncloud [70]. \n \n2.4 \nUV & IoT Protocols \n \n2.3.1 UV Protocols \n \n\
    Unmanned vehicles (UVs) are widely used for civilian and military \napplications.\
    \ They can be used for remote sensing, transportation, scientific \nresearch,\
    \ search and rescue, and armed attacks. They can be used in applications \nwhere\
    \ human presence is dangerous, or in repetitive surveillance and monitoring \n\
    tasks. Unmanned vehicles can be equipped with sensors, cameras, \ncommunication\
    \ equipment and weapons.  \nUVs are primarily equipped with omni-directional antennas,\
    \ although \ndirectional antennas can also be used to increase the gain of the\
    \ \ntransmitter/receiver, at the cost of designing a mechanism to control the\
    \ direction \nof the antenna.  \nUnmanned vehicles (UVs) can operate autonomously\
    \ or be remotely piloted \nby ground teams. UVs can communicate with the base\
    \ station using different \nprotocols, depending on the network structure and\
    \ the design of the UV system. \nCANbus (CANopen, NMEA2000), Ethernet and WiFi\
    \ (TCP/IP, UDP), RS232, are \nthe most commonly used protocols in autonomous vehicles.\
    \ In this section we \nwill mainly address the CANbus protocol. \n \n \n• CAN\
    \ Protocol \n \nBack in the 1980s, progress in automotive electronics had made\
    \ the number \nof devices that were suddenly required in vehicles grow in a worrying\
    \ way. All \nthese devices had to be connected in some way, generally to each\
    \ other, causing \n \n27 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nan alarming increase in the amount of wiring that had to be introduced into\
    \ a \nvehicle (As shown in Figure 2.3). All this led to problems of assembly,\
    \ \nstandardization of equipment, connections and weight. \nIn February 1986,\
    \ Robert Bosch presented CAN (Controller Area Network) \nat the Society of Automotive\
    \ Engineers (SAE) as a solution to the problem of \nwiring in vehicles. Intel,\
    \ as a manufacturer, and Mercedes-Benz, as a collaborator \nin the development\
    \ project, also worked together on developing the bus. \n \n \nFigure 2.3. Wiring\
    \ diagrams in vehicles before and after the appearance of CAN \n \nIn 1987, Intel\
    \ released the first CAN integrated, followed shortly after by \nPhilips Semiconductors.\
    \ After several improvements and disputes with other \nmanufacturers, it became\
    \ a standard (version 2.0) in 1993, the specifications of \nwhich are reflected\
    \ in ISO11898. Although CAN was initially developed for the \nautomotive industry,\
    \ its robustness and the efficiency of its protocol have \nallowed its entry into\
    \ many industrial applications requiring high transfer rates \nand high reliability\
    \ in the face of errors. Manufacturers in fields as diverse as \nelevators (Kone\
    \ in Finland) and textile machinery have used CAN in their \nproducts. \n \n \n\
    28 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nCAN Characteristics\
    \  \n \nCAN is one of the widest known vehicle bus standards for vehicle networks.\
    \ \nIt is very popular in industrial and automotive applications because of an\
    \ \naffordable and flexible design, which reduces the number of wires. For example,\
    \ \nthe number of wires has been reduced by 40% in the Peugeot 307, which \nincorporates\
    \ two CAN buses [71]. CAN is a message-based protocol; the packets \nhave no information\
    \ about the sender and receiver of the messages, and each \nnode can read the\
    \ messages transmitted over the bus. Functions supported by \nthe protocol in\
    \ the automotive domain are automatic start/stop, parking \nassistance, electric\
    \ parking brakes, collision avoidance, automatic lane detection, \netc. Figure\
    \ 2.4 shows a CAN bus node. It includes a central processing unit (CPU), \nthe\
    \ CAN controller and a transceiver. The function of the CPU is to decode the \n\
    received messages and decide which messages to transmit. Each node can send \n\
    or receive messages, but not simultaneously. A message or frame consists of an\
    \ \nID and a data payload of up to eight bytes (64 bits). \n \n \nFigure 2.4.\
    \ Controller area network bus node \n \nThe network uses two cables as a transmission\
    \ medium. The two cables are \nCAN High and CAN Low. All the system nodes connected\
    \ to the CAN bus \nthrough the corresponding hardware interface. All nodes share\
    \ the same data \nchannel. Each node consists of a CAN Transceiver, CAN Controller\
    \ and CPU as \nshown in Figure 2.5. \n \n \n29 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 2.5. Node of the CAN bus system \n \nThe CAN protocol is\
    \ optimized for short messages and uses a CSMA/CD \nwith NDBA (Carrier Sense Multiple\
    \ Access / Collision Detection with Non-\nDestructive Bitwise Arbitration) arbitration\
    \ access method. A node that needs to \ntransmit a message waits until the bus\
    \ is free and then starts to send the identifier \nof its message bit by bit.\
    \  \n \n2.3.2 IoT Protocols \n \nThere are a large number of protocols that can\
    \ be used in the IoT. Table 1 \nshows some of the most commonly used protocols,\
    \ grouped according to the \nISO/OSI model. Each has advantages and disadvantages,\
    \ and their use must be \nevaluated based on the application. The choice of which\
    \ protocol to use is \ndetermined by the size of the network, the energy consumption\
    \ of each node, \nand the transmission speed needed for a given application. For\
    \ instance, the IPv6 \nprotocol was born first to solve the problem of address\
    \ space (which, with the \nold IPv4 protocol, was about to run out) and second\
    \ to ensure scalability of \nsystems. Nevertheless, this protocol is designed\
    \ for wired networks. To address \nwireless sensor networks (WSN), the 6LoWPAN\
    \ protocol [72] was created. \n \nTable 2.1. Main protocols used in the IoT field\
    \ \nApplication Layer \nCoAP, MQTT, AMQP, XMPP, DSS \nService Discovery: mDMS,\
    \ DNS-SD, SSDP \nSecurity: TLS, DTLS \nTransport Layer \nTCP, UDP \nNetwork Layer\
    \ \nAddressing: IPv4/IPv6                Routing: RPL, CORPL, CARP, etc. \n \n\
    30 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nAdaption Layer \n6LoWPAN,\
    \ 6TiSCH, 6Lo, etc. \nData Link Layer \nIEEE 802.15.4       IEEE 802.15.1    \
    \ LPWAN      RFID, NFC  \n(ZigBee, etc.)        (Bluetooth)    (LoRaWAN, etc.)\
    \  \nIEEE 802.11      IEEE 802.3      IEEE 1901  \n(Wi-Fi)      (Ethernet)   \
    \   (PLC)      Z-Wave \nPhysical Layer \n \n \nIoT devices can support various\
    \ interoperable communication protocols, \nwhether Internet-related or service-related,\
    \ and can communicate with other \ndevices of different genre and infrastructure.\
    \  \n \n2-3-3. Industrial Protocols \n \nEtherCat, CANOpen, Modbus/Modbus TCP,\
    \ Ethernet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and Wireless\
    \ HART are the \nmost frequently used industrial protocols [18]. Until a few years\
    \ ago, \ncommunication systems for industrial automation only aimed at industry-\n\
    specific real-time performance and maintainability based on international \nstandards\
    \ [73]. The Industry 4.0 concept has the flexibility to provide \ninteroperability\
    \ between different industrial engineering systems. To connect \ndifferent industrial\
    \ equipment and systems, the same standards and security \nlevels are needed.\
    \ Open Platform Communications Unified Architecture (OPC \nUA) is a machine-to-machine\
    \ (M2M) communication protocol developed to \ncreate interoperable and reliable\
    \ communications and is now widely accepted as \na standard in industrial plant\
    \ communications [74]. \nAnother important industrial protocol that is still largely\
    \ used in most plants \nis MODBUS TCP exclusively for synchronous polling communications;\
    \ this \nsolution is compatible with most industrial control systems and SCADA-type\
    \ \napplications. However, if asynchronous event-based communications are \nrequired,\
    \ MQTT complements MODBUS TCP operations. The Message Queuing \nTelemetry Transport\
    \ (MQTT) is a lightweight, publish-subscribe network \nprotocol that transports\
    \ messages between IoT devices. An Industrial Internet of \nThings (IIoT) environment\
    \ integrates an event-based message-oriented protocol, \ni.e., MQTT, with a polling-based\
    \ request–response protocol, intended for \nindustrial applications, i.e., MODBUS\
    \ TCP.  \nMODBUS meets industrial requirements, primarily for remote control,\
    \ \nmonitoring and automation functions. MQTT works in parallel with MODBUS \n\
    TCP and complements its functions, however, cannot replace MODBUS [75]. \n \n\
    31 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nHTTP can also be used\
    \ in conjunction with MODBUS, as a web-based real-\ntime data monitoring system\
    \ that uses MODBUS TCP communications, in which \nall data is displayed in a real-time\
    \ graph in a web browser, which is refreshed at \nregular intervals using HTTP\
    \ polling communications [76]. \nThese protocols use the client–server communication\
    \ architecture. MQTT \nuses the publish–subscribe model and is message-oriented,\
    \ whereas HTTP uses \nthe request–response model and is a document-oriented protocol.\
    \ Thus, HTTP is \none-to-one (peer-to-peer), and MQTT is one-to-many. \nThe figure\
    \ 2.6 illustrates a comparison between the MODBUS philosophy \nand the MQTT philosophy\
    \ from a message exchange perspective. The MODBUS \nrequest uses a TCP connection\
    \ and employs a frame format based on an \noptimized application layer message\
    \ structure dedicated to telecontrol and \nmonitoring. The case is different with\
    \ MQTT; while the first client (publisher) \ngenerates an event using four messages,\
    \ the second client (subscriber) consumes \nthis event in six messages. \n \n\
    \ \nFigure 2.6. Comparison of protocols for the exchange of messages: (a) MQTT;\
    \ (b) \nMODBUS TCP. \n \n \nThe Internet of Engineering Task (IETF) has developed\
    \ a lighter application \nprotocol (Constrained Application Protocol (CoAP)) for\
    \ constrained IoT devices \noperating in lossy environments.    \nBased on UDP,\
    \ CoAP is an efficient and lightweight protocol compared to \nother IoT protocols\
    \ such as MQTT, HTTP, etc. CoAP also achieves reliable \ncommunication between\
    \ nodes in wireless sensor networks, along with features \nsuch as resource discovery,\
    \ resource observation, congestion control, etc. These \n \n32 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \ncapabilities of CoAP have enabled CoAP\
    \ to be implemented in various domains \nranging from home automation to health\
    \ management systems [77]. \nCoAP uses a specific infrastructure—namely, 6LoWPAN\
    \ (IEEE802.15.4)—\nwhich employs IPv6 in the network layer. Both HTTP and MQTT\
    \ use an \ninexpensive and available communication infrastructure, which is Internet\
    \ or \nIntranet in wireless mode (Wi-Fi—IEEE 802.11) or wire mode (Ethernet—\n\
    IEEE802.3) —which may employ either IPv4 or IPv6 in the network layer. In the\
    \ \ntransport layer, HTTP and MQTT protocols use TCP port numbers 80 and 1883,\
    \ \nrespectively. However, CoAP uses UDP port number 5683. Given that MQTT is\
    \ \nevent-based, it is a message-oriented protocol. Thus, CoAP mimics HTTP in\
    \ \nusing polling-based messaging, but in a shorter time and smaller frame-size,\
    \ \ntable 2 depicts more the difference between these protocols. \n \nTable 2.2.\
    \ Comparison of Internet of Things (IoT) protocols \nFeature \n \nHTTP \nCoAP\
    \ \nMQTT \nMODBUS TCP \ninfrastructure \nnetwork layer \ntransport layer \ntransport\
    \ port \nmodel \npattern \nmechanism \nmethodology \nparadigm \nquality level\
    \ \nstandard \nencoding \nsecurity \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n80,\
    \ 443 \nsynchronous \nrequest-response \none-to-one \ndocument-oriented \nlong\
    \ polling-based \none level \nIETF (RFC7230) \nASCII text \nSSL, TLS \n6LoWPAN\
    \ \nIPv6 \nUDP \n5683 \nAsynchronous \nboth \none-to-one \ndocument-oriented \n\
    polling-based \ntwo: CON or NON \nIETF (RFC7252) \nRESTful (Binary) \nDTLS  \n\
    Ethernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n1883, 8883 \nasynchronous \npublish-subscribe\
    \ \none-to-many \nmessage-oriented \nevent-based \nthree: QoS 0, 1, 2 \nISO/IEC,\
    \ OASIS \nUTF-8 (Binary) \nSSL, TLS \nEthernet, Wi-Fi \nIPv4 or IPv6 \nTCP \n\
    502, 802 \nSynchronous \nRequest-response \none-to-one \nbyte-oriented \npolling-based\
    \ \none level \nmodbus.org \nBinary \nTLS \n \nIn Figure 2.7, a comparison between\
    \ the different protocols is conducted \nbased on the protocol communication model\
    \ in the original IEEE model. CoAP \nruns over the connection less UDP in the\
    \ transport layer, whereas in the network \nlayer, CoAP uses either IPv6 or 6LoWPAN.\
    \ When CoAP uses IPv6, it is necessary \nfor it to use Ethernet or Wi-Fi for the\
    \ data link and physical layers, respectively. \nWhen CoAP uses 6LoWPAN, it employs\
    \ IEEE 802.15.4e for the data link and \nphysical layers. \nThe MODBUS TCP and\
    \ the MQTT protocols are both in the same level in the \nIEEE model. While the\
    \ MODBUS TCP uses a byte-encoded frame format for the \nuser data, which is intended\
    \ for industrial applications, the MQTT protocol \nencodes the user data in UTF-8.\
    \ \nThe content (payload) of HTTP may vary according to the type of transferred\
    \ \ndata, called content-type, which could be plain text, PDF application, HTML,\
    \ \nXML, GIF image or audio. For the exchange of data using HTTP, XML is used,\
    \ \nwhich handles verbose plain text for solving interoperability issues. However,\
    \ \n \n33 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nfor CoAP, the\
    \ efficient XML interchange (EXI) [78] is used, which encodes \nverbose XML documents\
    \ in binary format, if interoperability is considered [75]. \nThis is normally\
    \ used for constrained devices to increase the performance \nand decrease the\
    \ consumed power. Hence, CoAP is suitable for constrained \ndevices in IoT-based\
    \ wireless sensor networks that employ IPv6-based \ninfrastructure. However, it\
    \ needs a gateway to exchange data over the Internet. \n \n \n \nFigure 2.7. The\
    \ IEEE model (a); compared to the HTTP (b); the CoAP (c); the MODBUS \nTCP (d);\
    \ and the MQTT (e). \n \nIn summary, there are many IoT protocols, and event-based\
    \ protocols are of \nconsiderable interest for data transfer in the form of notifications\
    \ to complement \nthe MODBUS TCP protocol. This MODBUS protocol is polling-based,\
    \ \nsynchronous, request-response, and optimized for control and monitoring in\
    \ \nindustrial applications, it can establish an IIoT environment. MQTT can \n\
    complement MODBUS TCP with its asynchronous model, event-based \nparadigm, and\
    \ publish-subscribe model. On the other hand, CoAP requires a \nspecific infrastructure,\
    \ and a gateway to move data over the Internet, which adds \nadditional costs\
    \ and causes complications for the environment. \n \n2-3-4. OPC UA Protocol \n\
    \ \nThe Internet's ubiquity is unfortunately only one aspect of this new era,\
    \ not \neven the main one. The most studied topic is the utopian \"single protocol\"\
    \ (i.e., \naccepted by any application market, industry and consumer) that could\
    \ \nintelligently and flexibly describe methods and data. There are several examples\
    \ \nof shared and widely used protocols in specific application markets, and \n\
    probably in the industry the most accepted protocol that harmonizes machine-\n\
    to-machine (M2M) interaction is OPC UA (Open Process Communications \n \n34 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nUnified Architecture). The\
    \ OPC Foundation achieved great success with the \n\"OPC Classic\" protocol and\
    \ is now offering the OPC UA protocol as a more \npowerful successor for its platform-independent\
    \ architecture. \nOPC systems, particularly the latest OPC UA version, plays an\
    \ important \npart in current industrial environments, and more specifically to\
    \ sustain the \nupcoming IIoT environments [79-80]. Basically, they provide a\
    \ standard way to \nestablish a reliable and secure data exchange between industrial\
    \ devices from \nmultiple providers and software systems. This provides us with\
    \ an interface or \ngateway that allows us to interact directly with PLC. In fact,\
    \ OPC UA can be \nconsidered the basic protocol for harmonizing different industrial\
    \ automation \nnetworks and systems [73]. \nAs shown in Figure 2.8, OPC UA has\
    \ been designed to facilitate the exchange \nof information across the hierarchy\
    \ of systems that commonly coexist in industry: \ncontrol systems; manufacturing\
    \ execution systems (MES); enterprise resource \nplanning (ERP); and, finally,\
    \ field devices. OPC UA has a message-based \ncommunication and a service-oriented\
    \ architecture (SOA) with clients and \nservers connected to any types of networks.\
    \ \n \n \nFigure 2.8. OPC UA in the automation pyramid \n \n \nFigure 2.9 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called Address Space.  \n \n35 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nNodes are accessible by clients\
    \ using OPC UA services (interfaces and \nmethods) [80]. In other words, the OPC\
    \ UA address space is the information \nmodel for the communication: real hardware\
    \ devices or real software “objects” \n(sensors, actuators, software applications,\
    \ etc.) are available for OPC UA \ncommunication only if they are modelled, added\
    \ to the address space and finally \ndiscovered by the OPC UA clients. In the\
    \ OPC UA API, there is a discovery \nservice that can be used to find available\
    \ OPC UA servers and to explore their \naddress space. Clearly, the OPC UA communication\
    \ stack converts the calls to \nthe OPC UA API to proper messages for the underlying\
    \ network layers. \n \n \nFigure 2.9. Architecture of the OPC UA Server \n \n\
    \ \nA client application may use the OPC UA client API (application program \n\
    interface) in order to send/receive OPC UA service requests/responses to/from\
    \ \nthe OPC UA server. From the programmer point of view, the OPC UA client API\
    \ \nis like an interface that decouples the client application code from the client\
    \ OPC \nUA communication stack. \n  \n \n \n \n36 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nCHAPTER 3 \n \nRelated works and evaluation of the\
    \ \nlatency of the proposed architecture \n--------------------------------------------------\
    \ \n \n \n1- Introduction  \n \nOne of the main concerns of IoT is the interconnectivity\
    \ and integration of \ndifferent systems in the same architecture. Different challenges\
    \ can arise when it \ncomes to achieving this interconnectivity. \n Ensuring reliable\
    \ communications with all the devices and platforms \ninvolved is a major challenge\
    \ due to the diversity of protocols used in each \nconnected part. Interoperability\
    \ is considered as the primary issue to be solved, \nespecially when new technology\
    \ solutions need to be connected to existing \nnetworks. In addition, most IoT\
    \ architectures need to react in real time while \nensuring the highest level\
    \ of accuracy. Delay in connections affects not only the \ndecision-making, but\
    \ also the energy consumption for different energy \nconstrained devices [81].\
    \ \nThe use of new technologies and their connection to existing networks is \n\
    increasing. Different protocols, APIs and software have been introduced to \n\
    facilitate the interaction of connected systems and services. Node-RED, which\
    \ is \nan effective option for applications to prototype some IoT connectivity,\
    \ is a \ngraphical tool created by IBM to wire together hardware devices, APIs\
    \ and online \nservices. \nPython is also considered a programming tool for IoT\
    \ projects, which has \nbuilt-in support for scientific computing. Its use is\
    \ growing fastest in data science \nand machine learning. Versatility, stable\
    \ libraries with great support and ease of \nuse are its main advantages [82].\
    \ These platforms can be good solutions for \ninteroperability, as they have most\
    \ of the libraries that can facilitate connections \nbetween different systems.\
    \ \n \n37 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nThe communication\
    \ protocols of the IoT platform allow different devices to \ncommunicate and share\
    \ their data with controllers or decision centers. IoT \nplatforms offer the ability\
    \ to select the type of communication technologies based \non the needs of the\
    \ application. However, not all protocols can be used in all \nscenarios. \nIndustry\
    \ now faces the challenge of making the IT network compatible with \nits machines,\
    \ including interoperability, fog/cloud computing, security, latency, \nand quality\
    \ of service. One of the proposed solutions is smarter IoT gateways \n[83], which\
    \ are the bridges between the traditional network and sensor networks \n[84].\
    \ The IoT gateway provides the necessary connectivity, security, and \nmanageability,\
    \ while some of the existing devices cannot share data with the \ncloud [85].\
    \ \nMost of IoT gateways can support all the necessary tools and protocols \n\
    needed to provide communication, computation and storage. The IoT gateway \ncan\
    \ affect the performance of an IoT system in terms of latency and accuracy, \n\
    especially when different software and APIs are implemented. It can be \nconnected\
    \ to the physical layers and transmit the received data to be processed \nin the\
    \ cloud. Using the cloud for AI solutions has its advantages and \ndisadvantages.\
    \ The IoT gateway can be used to implement cloud-based AI \nmodels at the edge\
    \ for processing and decision making, which makes the choice \nof IoT gateway\
    \ selection so crucial for a high-performance IoT architecture. \n \n2- Related\
    \ works \n \n \n2-1 Industrial Protocols  \n \n \nEtherCat, CANOpen, Modbus/Modbus\
    \ TCP, EtherNet/IP, PROFIBUS, \nPROFINET, DeviceNet, IEEE802.11, ISA100.11a, and\
    \ Wireless HART are the \nmost frequently used industrial protocols [86]. Due\
    \ to the incompatible \ninformation models for the data and services of the different\
    \ protocols, \ninteroperability between the different systems with different protocols\
    \ is always \ndifficult. The Industry 4.0 concept has the flexibility to achieve\
    \ interoperability \nbetween the different industrial engineering systems. To\
    \ connect the different \nindustrial equipment and systems, the same standards\
    \ and safety levels are \nrequired. Open Platform Communications Unified Architecture\
    \ (OPC UA) is a \nmachine-to-machine (M2M) communications protocol developed to\
    \ create inter-\noperable and reliable communications and is now generally accepted\
    \ as standard \nin industrial plant communications [87]. OPC UA is an independent\
    \ service-\noriented architecture that integrates all the functionality of the\
    \ individual OPC \nClassic specifications into one extensible framework [88].\
    \ OPC UA enable to \n \n38 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nconnect sub-manufacturing systems and ensure real-time communication \nbetween\
    \ devices and can be deployed in a service-oriented architecture for the \noptimization\
    \ of industrial applications [89]. \n \nOPC UA can allocate all manufacturing\
    \ resources, including embedded \nsystems, to specific areas and extensible computing\
    \ nodes through the address \nspace and a pre-defined model. It solves the problem\
    \ of unified access to the \ninformation of different systems [10]. Infrastructure\
    \ protocols have been \nproposed in many studies; for instance, in [90-91] an\
    \ edge IoT gateway was \ndeveloped to extend the connectivity of MODBUS devices\
    \ to IoT by storing the \nscanned data from MODBUS devices locally and then transferring\
    \ the changes \nvia an MQTT publisher to MQTT clients via a broker. \n \n2-2 Visual\
    \ Programming Languages \n \nVisual Programming Languages (VPL) are widely used\
    \ in IoT applications, \nin [92], a survey on Visual Programming Languages (VPL)\
    \ for IoT was proposed. \nThe analysis mainly focused on comparing them on the\
    \ basis of the programming \nenvironment, project repository, licensing, and supported\
    \ platforms. Some of \nthem are Open-Source platforms, while others are proprietary.\
    \ Among the Open-\nSource platforms (Node-RED, Modkit, miniBloq, NooDL, NETLab,\
    \ Ardublock, \nand Scratch), only some can be programmed using a Web interface\
    \ and executed \non some dockers or on-cloud virtual machines. \nIn addition to\
    \ being open source and having the possibility of adding new \nmodules and functionalities,\
    \ Visual Programming Language (VPL) IoT platforms \nshould exhibit a number of\
    \ non-functional requirements \nThey should demonstrate the capabilities of robustness,\
    \ availability (in terms \nof availability and fault tolerance), scalability,\
    \ security, full respect for privacy, \ninteroperability and openness, etc. \n\
    There are tools that make it easier for devices and their functionality to be\
    \ \ncomposed and combined at a higher level with IoT applications. For the device\
    \ \nlevel, an example of a tool is Node-RED that supports IoT application \ndevelopment\
    \ with a visual flow programming approach (Figure 3.1). Node-RED \nprovides an\
    \ integrated view of the application and the network and interacts \nsimultaneously\
    \ with the different systems involved through different protocols. \nIn [73] Node-RED\
    \ is used in both the IIoT gateway and the Cloud application, \nwhere a methodology\
    \ is proposed to measure delay metrics in OPC UA systems \nto study the impact\
    \ that QoS parameters have on the communication delay from \nthe production line\
    \ to the Cloud and vice versa.  \n \n \n39 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.1. Node-Red Platform \n \nIn [93] Node-RED is proposed\
    \ and applied in an IoT application for oil \nleakage detection in wind turbine\
    \ bearings. In [94], a new method introduced to \nmigrate Node-RED workflows into\
    \ a decentralized execution environment, so \nthat such workflow scan run on Edge\
    \ networks, where nodes are extremely \ntransient in nature. \nThe programming\
    \ of IoT applications is carried out in several ways, using \ndifferent tools\
    \ [95]. For example, in the Google IoT platform, various \nprogramming languages,\
    \ such as Java, Node.js, Python, PHP, Go, Ruby, and C#, \ncan be utilized to program\
    \ data flows from devices to dashboards. In these cases, \ndata flows are deployed\
    \ using programming languages. \n \n2.3 IoT architecture for Robots \n \nImplementing\
    \ an Industry 4.0 architecture requires integration of the latest \ntechnologies,\
    \ for example, IIoT, cyber-physical systems, additive manufacturing, \nbig data\
    \ and data analytics, cyber-security, cloud and edge computing, \naugmented and\
    \ virtual reality, as well as autonomous robots and vehicles [96]. \nA typical\
    \ cloud robotics architecture is based on two elements: the cloud \nplatform and\
    \ its associated equipment and the bottom facility. Bottom facilities \nusually\
    \ encompass all kinds of mobile robots, unmanned aerial vehicles, \nmachines,\
    \ and other equipment [97]. The next generation of robots will include \ninterconnected\
    \ industrial robots [98], cobots [99] and autonomous land vehicles \n(AGVs) [100].\
    \ Cobots support human workers in various tasks, while robots can \ncarry out\
    \ specific tasks, such as looking for objects or transporting tools. \nUnmanned\
    \ Vehicles (UVs) are among the emerging robot technologies that \nleverage the\
    \ power of perception science and are now the preferred remote \n \n40 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nsensing system for gathering data over\
    \ long distances in difficult-to-access \nenvironments [101]. Drone cameras can\
    \ collect remotely sensed images from \ndifferent areas safely and efficiently.\
    \ \nUnmanned vehicles can be deployed in air (Unmanned Aerial Vehicles – \nUAV),\
    \ at the sea surface (Autonomous Surface Vehicles – ASV) or in the water \ncolumn\
    \ (Autonomous Underwater Vehicles – AUV). \nUAVs can save time and money in different\
    \ sectors, such as agriculture, \npublic safety, inspection and maintenance, transportation\
    \ and autonomous \ndelivery systems. This technological revolution was conceived\
    \ to make people’s \nlives easier and to provide machine-to-machine communications\
    \ without human \nintervention [102]. They can be used to check a given installation\
    \ or production \nareas, to transmit data, monitor construction processes, and\
    \ detect anomalies. \nFor instance, in [103], drones’ platform was deployed to\
    \ detect trees and \nbuildings close to power lines. They can also be deployed\
    \ to monitor oil, gas and \nwater pipelines. \nUAVs combined with digital image\
    \ processing have been applied to crack \nassessment as a cost-effective and time-effective\
    \ solution, instead of visual \nobservation [104]. In [105], Machine Learning\
    \ Techniques were used to estimate \nNitrogen nutrition levels in corn crops (Zea\
    \ mays). The work described in [106] \nintroduced a real-time drone surveillance\
    \ system to identify violent individuals \nin public areas by a ScatterNet hybrid\
    \ deep learning (SHDL) network. In [107], \nthe images from a drone camera were\
    \ processed by the bag-of-words algorithm \nto detect crops, soils and flooded\
    \ areas, with MATLAB to program the feature \nextraction algorithm. In [108],\
    \ a solution was proposed to detect a final target \nusing the drone’s camera.\
    \ The system implemented image processing algorithms \nusing the open-source computer\
    \ vision library OpenCV. Cloud solutions like \nGoogle AI, Amazon Web Services,\
    \ and IBM Watson offer on-demand access to \ntheir image recognition services\
    \ to connect with other systems on the internet. \nThe authors in [109] propose\
    \ to move computationally demanding object \nrecognition to a remote computing\
    \ cloud, instead of implementing it on the drone \nitself, by means of a cloud-based\
    \ approach that allows real-time performance \nwith hundreds of object categories.\
    \  \n \n2.4. Applications in Marine field \n \nMarine scientists and robotic engineers\
    \ now have at their disposal a \nheterogeneous collection of robotic vehicles,\
    \ including AUVs, deep-sea landing \nvehicles, unmanned/autonomous surface vehicles,\
    \ remotely operated vehicles, \nand gliders/drifters [110]. These robotic vehicles\
    \ are untethered, self-propelled, \nself-navigating vehicles that can operate\
    \ autonomously from a shore or vessel for \na period of hours to a few days and\
    \ carry scientific payloads to perform sampling \nin the marine environment [111].\
    \  \n \n41 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nDirect vision\
    \ or camera vision is the simplest way to acquire a wealth of \ninformation from\
    \ aquatic environments and plays a vital role in underwater \nrobots. AUVs equipped\
    \ with the most recent cameras are now capable of \ncollecting massive amounts\
    \ of data from the seabed [112]. Computer vision \nalgorithms for underwater robotic\
    \ systems are attracting attention due to \nsignificant advances in vision capacities.\
    \  \nThe authors of [113] propose a stereo-imaging technique for recovering \n\
    underwater images by considering the visibility coefficients. This stereo-imaging\
    \ \napproach was realized using real-time algorithms and was implemented in \n\
    AUVs. The authors of [114] propose the new Qu index, which is used to assess \n\
    the similarity of structures and colors in underwater images. The authors of [115]\
    \ \nintroduce a human perception technique, the High-Dynamic Range Visual \nDifference\
    \ Predictor 2, to predict both overall image quality and artefact \nvisibility.\
    \ The authors of [116] propose a real-time system for object recognition \nin\
    \ acoustic images. A 3D acoustic camera is implemented to produce range \nimages\
    \ of the underwater area [117]. The authors of [118] propose a system for \nautomatic\
    \ interpretation of 3D objects based on 2D image data generated by a \nsector\
    \ scanning sonar unit. Their overall interpretation achieves a success rate of\
    \ \n86% for underwater objects seen in various conditions. \n \nArtificial intelligence\
    \ and machine learning have been proposed to enhance \nAUV missions and analyze\
    \ their data. The authors of [119] describe a system for \nautomatically detecting\
    \ pipelines and other objects on the seabed. Artificial \nneural networks are\
    \ applied to classify, in real time, the pixels of the input image \nof the objects\
    \ into various classes. The authors of [120] propose CNN to learn a \nmatching\
    \ function that can be trained from labelled sonar images after pre-\nprocessing\
    \ to produce matching and non-matching pairs. The authors of [121] \ndescribe\
    \ a DL method to assist in identifying fish species on underwater images. \n \n\
    Collaboration between the QUT University of Australia, Google and the \nGreat\
    \ Barrier Reef Foundation developed the world’s first underwater robotics \nsystem\
    \ specifically designed for coral reef environments [122]. Using real-time \n\
    computer vision, processed on board the robot, it can identify harmful starfish\
    \ \nwith 99.4% accuracy [122]. Marine researchers and robotics specialists tested\
    \ the \neffectiveness of a CV system in identifying sea creatures and found it\
    \ be around \n80% accurate. The system can even be 93% accurate if enough data\
    \ is used to train \nthe algorithm [123]. \n \nUnmanned surface vehicles (USVs)\
    \ are the main investigation areas of \nmaritime autonomous surface ships (MASSs),\
    \ being used in surveillance, \nresearch, scientific investigation and security.\
    \ USVs are defined as self-contained \nunmanned, untethered vessels that can transit\
    \ on the surface of the water \nautonomously or be remotely controlled [124].\
    \ \n \n42 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nThrough\
    \ detailed maps and satellite navigation, an ASV can detect and avoid \nstatic\
    \ obstacles. For in instance, in [125] a performed approach was proposed \nusing\
    \ Google Maps to build a map of static obstacles. \n \nTo respond quickly and\
    \ effectively to the challenges of a highly dynamic \nenvironment, the ASV needs\
    \ on-board logic to monitor the scene, identify critical \nsituations, and perform\
    \ appropriate route modifications [126]. An outstanding \nfeature is its capacity\
    \ to recognize an obstacle at a safe distance and avoid a \ncollision by changing\
    \ its course. Kristan et al. [126] proposed a new graphical \nmodel that supplies\
    \ fast and continuous obstacle image-map estimation from a \nsingle video stream\
    \ captured on-board a USV. \nIn order to ensure accurate detection and tracking\
    \ of objects at sea, \nautonomous vessels require a range of sensing capabilities.\
    \ Radar can provide \nsuch an overview, although certain small vessels and floating\
    \ objects are \nchallenging to recognize. Computer vision by onboard cameras can\
    \ be used for \nthis as a reasonable alternative to a human lookout [127]. The\
    \ work proposed in \n[128] examines the technical challenges of marine image processing\
    \ and artificial \nvision problems for video streams generated by cameras. These\
    \ challenges \ninclude the dynamic nature of the background, the lack of static\
    \ cues, the \npresence of small faraway objects, and lighting effects. Authors\
    \ of [129] propose \na method of identifying and tracking vessels using video\
    \ streams of existing port \nand river surveillance systems. The method detects\
    \ all types of moving vessels, \noperates under varying lighting conditions, and\
    \ assigns a unique identifier to \neach vessel detected. \nIn [130], a monocular\
    \ camera mounted on a USV was used, automatic feature \nextraction and tracking\
    \ filter algorithms are applied for real-time vision-based \ndetection and tracking.\
    \ The approach aims to detect and track another surface \nvessel by deploying\
    \ computer vision techniques. \nNovel technology has already been deployed on\
    \ autonomous craft as part of \nthe Marine 4.0 concept, where AI, cloud, and edge\
    \ technologies are of great \nimportance. For instance, the IBM-funded project,\
    \ the Mayflower Autonomous \nShip (MAS), will use the IBM power servers, IBM Watson\
    \ AI, cloud, and edge \ncomputing technologies to navigate autonomously and avoid\
    \ ocean hazards as \nit travels from Plymouth (England, UK) to Plymouth (Massachusetts,\
    \ USA) [131] \n, thus expanding knowledge of the ocean and removing barriers to\
    \ marine \nresearch. In [132], a Google Cloud Machine Learning Engine is used\
    \ to deploy an \nAI-based object classification system: a software suite for detecting,\
    \ identifying, \nand tracking surface objects. It makes ships safer and more efficient\
    \ by \nautomatically analyzing data from a number of new sensors, along with the\
    \ \nship’s own automatic identification system (AIS) and radar. \nVision and image\
    \ processing applications can benefit from cloud computing, \nas many are data-\
    \ and compute-intensive. By remotely locating storage and \n \n43 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprocessing capabilities in the cloud,\
    \ image processing applications can be \ndeployed remotely and paid for by the\
    \ user in pay-as-you-go or pay-per-use \nbusiness models.  \nOverall, cloud, edge\
    \ and hybrid vision processing solutions each provide \nboth strengths and weaknesses;\
    \ assessing the capabilities of each will allow the \nselection of an optimal\
    \ strategy for any specific design situation. \n \n3. Artificial Intelligence\
    \ and Machine Vision \n \nArtificial intelligence (AI) is the intelligence achieved\
    \ by machines. The \nresearch field of AI is defined as the study of \"intelligent\
    \ agents\": any device that \nsenses its environment and performs actions that\
    \ maximize its chances of \nachieving a given goal [133].  In common parlance,\
    \ the term \"artificial \nintelligence\" is applied when a machine mimics the\
    \ \"cognitive\" functions that \nhumans associate with other human minds, such\
    \ as \"learning\" and \"problem \nsolving\". Capabilities currently classified\
    \ as AI include autonomous driving of \ncars, human speech understanding, high-level\
    \ competition in strategic gaming \nsystems, intelligent routing in content delivery\
    \ networks, military simulations, \nand complex data interpretation. \nThe central\
    \ problems of AI research include learning, planning, reasoning, \nknowledge,\
    \ communication, natural language processing, perception, and the \nability to\
    \ move and manipulate objects [134]. \nAs AI applications are recently also designed\
    \ for commercial solutions, it is \nobliged to deal with the wide availability\
    \ of GPUs (graphics processing units), \nwhich make parallel processing ever faster,\
    \ cheaper and more powerful. \nComputer processors are designed to handle just\
    \ about anything. Central \nprocessing units (CPUs), however, they are very limited\
    \ and, as such, can only \nperform certain mathematical calculations. Very complicated\
    \ combinations are \nimpractical because of the very long processing time. GPUs,\
    \ on the other hand, \nhave become so specialized that they outperform traditional\
    \ processors when it \ncomes to rendering large amounts of complex calculations.\
    \ GPUs offer 10 to 100 \ntimes the computational power of traditional CPUs, which\
    \ is one of the main \nreasons graphics cards are currently being used to power\
    \ some of the most \nadvanced neural networks responsible for deep learning [135].\
    \ \nDeep neural networks (DNNs), also known as deep learning (DL), are part \n\
    of the broad field of AI, which is the science and engineering of creating \n\
    intelligent machines with the ability to achieve goals like humans. Machine \n\
    learning is the subfield of computer science that, according to Arthur Samuel\
    \ in \n1959, gives \"computers the ability to learn without being explicitly \n\
    programmed\"[136]. Evolving from the study of pattern recognition and \ncomputational\
    \ learning theory in artificial intelligence, machine learning \nexplores the\
    \ study and construction of algorithms capable of learning from and \n \n44 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nmaking predictions about data\
    \ [137] by building a model from sample inputs. \nThe relationship between deep\
    \ learning and the whole of artificial intelligence is \nillustrated in Figure\
    \ 3.2. In other words, DL is the study of artificial neural \nnetworks and related\
    \ machine learning algorithms that contain more than one \nhidden layer (Figure\
    \ 3.5).  \n \n \n \nFigure 3.2. Deep learning in the context of artificial intelligence\
    \ \n \nThe upside of an efficient Machine Learning Algorithm is clear. Instead\
    \ of \nthe laborious and haphazard approach of creating a separate, customized\
    \ \nprogram to solve each individual problem in a domain, the single machine \n\
    learning algorithm simply has to learn, through a process called training, to\
    \ \nhandle each new problem. The brain is now considered the best \"machine\"\
    \ we \nknow for understanding and solving problems, so it is perfectly natural\
    \ to look \nto it for a machine learning approach. Therefore, a brain-inspired\
    \ computation is \na kind of algorithm or program that has some aspects of its\
    \ basic functionality or \nform inspired by the way the brain works. \nScientists\
    \ believe that the main computational component of the brain is the \nneuron.\
    \ There are about 86 billion neurons in the average human brain. The \nneurons\
    \ themselves are connected by a number of elements that enter them, \ncalled dendrites,\
    \ and one element that exits them, called an axon, as shown in \nFigure 3.3. The\
    \ neuron accepts signals that arrive via the dendrites, computes on \nthese signals\
    \ and outputs a signal to the axon. These input and output signals are \ncalled\
    \ activations. The axon of a neuron branches and is connected to the \ndendrites\
    \ of many other neurons. The connection between a branch of the axon \nand a dendrite\
    \ is called a synapse. It is estimated that there are 1014 to 1015 \nsynapses\
    \ in the average human brain [138]. A key feature of the synapse is that \nit\
    \ can scale the signal (xi) that passes through it, as shown in Figure 3.3.  \n\
    \ \n \n45 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 3.3.\
    \ Connections to a neuron in the brain. xi, wi, f (·), and b are the activations,\
    \ \nweights, nonlinear function, and bias, respectively \n \nThis scaling factor\
    \ can be called a weight (wi), and the brain is thought to \nlearn by changing\
    \ the weights associated with synapses. Thus, having different \nweights results\
    \ in different responses to an input. It is important to note that \nlearning\
    \ is the adjustment of weights in response to a learning stimulus, whereas \n\
    the organization (what we might think of as the program) of the brain remains\
    \ \nunchanged. This characteristic marks the brain as an excellent source of \n\
    inspiration for a machine learning algorithm. \nAs shown in figure 3.2, Within\
    \ the paradigm of brain-inspired computing \nexists a subarea called spiking computation.\
    \ The inspiration in this subarea is \ntaken from the fact that communication\
    \ in dendrites and axons are spike-shaped \npulses and that the information that\
    \ is transmitted is not based only on the \namplitude of the spike. Rather, it\
    \ also depends on the time at which the pulse \narrives and that the computation\
    \ that takes place in the neuron is a function not \nonly of a single value, but\
    \ of the pulse width and the temporal relationship \nbetween the different pulses.\
    \ In contrast to spiking computing, another sub-area \nof brain-inspired computing\
    \ is called neural networks, which is the focus of most \nresearch articles. \n\
    Neural networks are based on the notion that the computation of a neuron \nconsists\
    \ of a weighted sum of input values. These weighted sums reflect the \nscaling\
    \ of values by the synapses and the combination of those values in the \nneuron.\
    \ Moreover, the neuron does not simply produce this weighted sum, as \nthe computation\
    \ associated with a cascade of neurons would otherwise be a \nsimple linear algebra\
    \ operation. There is instead a functional operation within \nthe neuron that\
    \ is being performed on the combined inputs.   \nFigure 3.4 presents a diagrammatic\
    \ picture of a computational neural \nnetwork.  The neurons in the input layer\
    \ receive some values and propagate them \nto the neurons in the middle layer\
    \ of the network, which is also frequently called \n \n46 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \na “hidden layer.” The weighted sums from one or more\
    \ hidden layers are \nultimately propagated to the output layer, which presents\
    \ the final outputs of the \nnetwork to the user. To align brain-inspired terminology\
    \ with neural networks, \nthe outputs of the neurons are often referred to as\
    \ activations, and the synapses \nare often referred to as weights as shown in\
    \ Figure 3(a). \n \n \n \nFigure 3.4 Simple neural network example and terminology.\
    \  (a) Neurons and synapses. \n(b) Compute weighted sum for each layer. \nAccording\
    \ to Figure 3.3, the computation of each layer can be expressed as \nfollow: \
    \ \n\U0001D44C\U0001D457= f (∑\n\U0001D44A\U0001D456\U0001D457 \n3\n\U0001D456\
    =1\n\U0001D465\U0001D456 + \U0001D44F)                                       \
    \          (3.1) \n \nWhere Wij, xi and yj are the weights, input activations,\
    \ and output activations, \nrespectively, and f (⋅) is a nonlinear function. The\
    \ bias term b is omitted from \nFigure 3.3 for simplicity. \n \n3.1 Inference\
    \ Versus Training \n \nThe IoT data can be used to train the machine learning\
    \ model and inference \nbefore technical professionals can begin to design a system\
    \ that integrates a \nmachine learning inference server with the IoT, the relationship\
    \ between how IoT \ndata can be used for training the machine learning model and\
    \ inference must be \nunderstood. Figure 3.6 compare the training with inference.\
    \ \n \n• Training \n \nTraining is the process of creating a machine learning\
    \ algorithm. Training \nimplies the use of a deep learning framework (e.g., TensorFlow)\
    \ and a training \ndataset (Figure 3.5). IoT data supplies a source of training\
    \ data that data scientists \n \n47 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand engineers can use to train machine learning models for a diversity of\
    \ use \ncases, from fault detection to consumer intelligence. \n \n \nFigure 3.5.\
    \ Training and inference comparison \n \n• Inference \n \nInference relates to\
    \ the process of using a trained machine learning algorithm \nto make a prediction.\
    \ IoT data can be used as input to a trained machine learning \nmodel, which enables\
    \ predictions that can provide guidance to decision-making \nlogic on the device,\
    \ at the edge gateway or elsewhere in the IoT system. \n \n2.4.2 Methods of Machine\
    \ Learning \n \nTwo of the most widely adopted machine learning methods are supervised\
    \ \nlearning and unsupervised learning. machine learning – about 70 percent –\
    \ is \nsupervised learning. Unsupervised learning accounts for 10 to 20 percent.\
    \ Semi-\nsupervised and reinforcement learning are two other technologies that\
    \ are \nsometimes used [139]. \n \n• Supervised learning  \n \nSupervised learning\
    \ algorithms are trained using labeled examples, typically \nan input where the\
    \ desired output is known. For example, a computer might \nhave data points labeled\
    \ \"R\" (works) or \"F\" (failure). The learning algorithm is \n \n48 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nprovided with a set of inputs along with\
    \ the corresponding correct outputs, and \nthe algorithm learns by comparing its\
    \ actual output with the correct outputs to \nfind errors. It then modifies the\
    \ model accordingly.  \nBy means of methods such as regression, classification,\
    \ prediction and \ngradient boosting, supervised learning uses patterns to predict\
    \ label values in \nadditional unlabeled data. \n \n• Unsupervised learning  \n\
    \ \nUnsupervised learning is used with data that have no historical labels. The\
    \ \nsystem is not told the \"correct answer\". The algorithm is supposed to find\
    \ out \nwhat it is shown. The goal is to explore the data and find some structure\
    \ in it. \nUnsupervised learning performs well on transactional data. For instance,\
    \ it can \nidentify customer segments with similar attributes that later can be\
    \ treated in \nsimilar ways in marketing campaigns. Alternatively, it can find\
    \ the main \nattributes that separate customer segments from each other. Popular\
    \ techniques \ninclude nearest neighbor mapping, self-organizing maps, k-means\
    \ clustering and \nsingular value decomposition. These algorithms are also used\
    \ to recommend \nitems, segment text topics, and identify data outliers. \n \n\
    • Semi-supervised learning  \n \nSemi-supervised learning is used for the same\
    \ applications as supervised \nlearning. But it uses both labeled and unlabeled\
    \ data for training: usually a small \namount of labeled data with a large amount\
    \ of unlabeled data (unlabeled data is \nless expensive and costs less effort\
    \ to acquire). This type of learning can be used \nwith methods such as regression,\
    \ classification and prediction. Semi-supervised \nlearning is useful when the\
    \ cost associated with labeling is too high to allow a \nfully labeled training\
    \ process. Some of the earliest examples of this type include \nidentifying a\
    \ person's face on a webcam. \n \n• Reinforcement learning  \n \nReinforcement\
    \ learning is often used in the areas of robotics, gaming and \nnavigation with\
    \ reinforcement learning, the algorithm discovers, via trial and \nerror which\
    \ actions produce the greatest rewards. This type of learning has three \nmain\
    \ constituents: the agent (the learner or decision maker), the environment \n\
    (everything the agent interacts with) and the actions (what the agent can do).\
    \ The \ngoal is for the agent to choose the actions that maximize the expected\
    \ reward in \na given time. The agent will reach the goal much faster if it follows\
    \ a good policy. \nThus, the goal of reinforcement learning is to learn the best\
    \ policy. \n \n \n \n49 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n3.2 Convolutional Neural Network for Object Recognition \n \nSeveral deep\
    \ learning architectures, such as deep neural networks, deep \nconvolutional neural\
    \ networks, deep neural networks, and recurrent neural \nnetworks, have been applied\
    \ to fields such as audio recognition, computer vision, \nautomatic speech recognition,\
    \ natural language processing, and bioinformatics, \nwhere they have been shown\
    \ to produce state-of-the-art results on a variety of \ntasks. Deep neural networks\
    \ have demonstrated their ability to outperform other \nmachine learning algorithms\
    \ in tasks such as object recognition in the field of \ncomputer vision. \nApplying\
    \ computer vision to automatically detect objects is an extremely \nchallenging\
    \ task. Noise disturbance, complex background, occlusion, scale and \nattitude\
    \ changes, low resolution, and other factors strongly influence object \ndetection\
    \ capabilities. Conventional object detection methods, based on the \nhand-crafted\
    \ feature, are not robust to lighting changes, occlusions and \nvariations in\
    \ scale or lack of good generalization ability [140]. Unlike handmade \nfeatures,\
    \ which are designed in advance by human experts to extract a particular \nset\
    \ of chosen properties, the features extracted by CNN are learned from the data.\
    \ \nThe core idea behind this is to learn object models from raw pixel data rather\
    \ than \nusing hand-set features, as in traditional recognition approaches. Training\
    \ these \ndeep models usually requires large training datasets, although this\
    \ problem has \nalso been surmounted by new large-scale labelled datasets such\
    \ as ImageNet \n[141]. \nA convolutional neural network (CNN) works by combining\
    \ different layers \nof neurons that extract certain characteristics from the\
    \ image. Each layer learns a \ndifferent level of abstraction, and in the end\
    \ gives a prediction of whether the \nobject was detected or not [142]. Different\
    \ online resources on deep CNN \narchitectures and vision-related datasets have\
    \ been implemented and are \navailable on the internet.  \nCNN-based methods have\
    \ achieved significant advances in computer vision. \nIn the 2012 ImageNet Large\
    \ Scale Visual Recognition Challenge (ILSVRC) [143], \nHinton and his student\
    \ Krizhevsky [141] applied CNN to image classification \nand achieved a winning\
    \ top-5 test error rate of 15.3%, compared to the 26.2% \nachieved by the second-best\
    \ entry. Applying various convolutional filters, CNN \nmodels can capture the\
    \ high-level representation of the input data, making it \nhighly popular for\
    \ CV tasks. The breakthrough and rapid adoption of DL in 2012 \nbrought into existence\
    \ modern and highly accurate object detection algorithms \nand methods, such as\
    \ the regions with CNN features (R-CNN) method [144], fast \nR-CNN [145], faster\
    \ R-CN [146], RetinaNet [147] and fast yet highly accurate \nmethods like SSD\
    \ [148] and YOLO [149]. CNN-based methods can provide more \naccurate target boxes\
    \ and multi-level semantic information for identification and \nlocalization.\
    \ However, handcrafted features are complementary and can be \ncombined with CNN\
    \ for improved performance [150]. \n \n50 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nBy using the cloud infrastructure, it becomes possible to apply CNN\
    \ \ntechniques which are used in most object detection cloud services [151]. There\
    \ \nare two ways that can help leverage these techniques for a particular application.\
    \ \nThe first one consists of employing our own data and a framework in our own\
    \ \nmachine and training our custom model for custom object detection. The second\
    \ \nis to use cloud services through an API, which is a suite of machine learning\
    \ (ML) \nproducts and CV software development services that allows developers\
    \ with \nlimited ML expertise to train high-quality models specific to the needs\
    \ of their \nproject.  \n \n3.3 Deep Learning for Object Detection \n \nIn the\
    \ last decade, prominent applications like robotics, video surveillance, \nscene\
    \ understanding, and self-driving systems have initiated a significant \namount\
    \ of computer vision research. Thanks to the advancement of neural \nnetworks,\
    \ particularly deep learning, visual recognition systems have achieved \nimpressive\
    \ outcomes, especially in object detection. \nObject detection is the process\
    \ of identifying the instance of the class to which \nthe object belongs and estimating\
    \ its location by outputting the bounding box \naround the object [151]. Although\
    \ object detection and image classification both \nshare a common technical challenge,\
    \ they must handle significant numbers of \nhighly variable objects. Object detection\
    \ is more complex than image \nclassification due to the fact that it must identify\
    \ the precise location of the object \nof interest [152]. Being one of the main\
    \ computer vision issues, object detection is \ncapable of providing useful insights\
    \ for the semantic understanding of images \nand videos [153]. Object detection,\
    \ i.e., the detection of the positions and \ncategories of multiple instances\
    \ of objects in a single image, is a major challenge \nin a diverse set of applications\
    \ such as self-driving vehicles and robotics [154, \n155,156].  \nObject recognition\
    \ efficiency is steadily increasing, with advanced computer \nvision techniques\
    \ working successfully on a wide range of objects. Most of these \ntechniques\
    \ are based on deep learning with convolutional neural networks and \nhave achieved\
    \ impressive performance improvements in a variety of recognition \nproblems [157].\
    \ \n \n3.4 Cloud-Edge DL \n \nPublic clouds have emerged as a new opportunity\
    \ to deliver compute-\nintensive applications. A public cloud refers to a networked\
    \ set of computers that \nfurnish a variety of computing and storage resources\
    \ and offer the appearance of \nunlimited computing capacity on demand at a nominal\
    \ price and under a flexible \npricing model [158-159]. Deep Learning (DL) technology\
    \ is popular nowadays \n \n51 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthanks to its good results in the fields of object detection, image classification\
    \ and \nnatural language processing. The easy availability of powerful data sets\
    \ and \ngraphic processing units are the main reasons for DL’s present popularity.\
    \ \nSeveral smart DL-based applications and services have changed all kinds of\
    \ \npeople’s lives because of the significant advantages of deep learning in the\
    \ \ncomputer vision (CV) fields [160-161]. CV seeks to enable computer systems\
    \ to \nautomatically identify and understand the visual world, simulating human\
    \ \nvision [162]. Algorithms for visual perception tasks have been developed,\
    \ \nincluding (i) object recognition to identify specific objects in image data,\
    \ (ii) object \ndetection to locate semantic objects of a given class, and (iii)\
    \ scene understanding, \nto parse an image into meaningful segments for analysis\
    \ [163]. All these \nalgorithm techniques can be deployed in the cloud.  \nEdge\
    \ computing is progressively being merged with artificial intelligence \n(AI)\
    \ and is intended to migrate DL computation from the cloud to the edge, \nthereby\
    \ enabling distributed, reliable and low-latency intelligent services [161]. \n\
    DL services are implemented nearby the service requests and the cloud is only\
    \ \ninvolved when extra processing is needed [164]. Both the cloud and edge \n\
    computing are considered adequate platforms to incorporate artificial \nintelligence\
    \ approaches.  \n \n3.5 Cloud AI at the Edge \n \nCloud computing is also impacting\
    \ many applications that currently rely on \nlocal storage and processing power.\
    \ Cloud computing provides computing \nresources in the form of a service or application\
    \ over a network. Its services are \ngenerally divided into three categories:\
    \ Platform as-a-Service (PaaS), \nInfrastructure-as-a-Service (IaaS) and Software-as-a-Service\
    \ (SaaS). By remotely \nlocating storage and processing capacity, image processing\
    \ applications and \nmachine vision systems can be performed remotely and paid\
    \ for on a pay-per-\ndemand or pay-per-use business model. Cloud-based systems\
    \ optimally aim to \nautomatically balance and distribute processing loads. \n\
    Building a visual recognition model is a difficult and time-consuming task. \n\
    In addition, the training of deep neural networks demand access to massive data\
    \ \nand computing power, however this issue has also been overcome by new large-\n\
    scale tagged datasets such as ImageNet [165]. Fortunately, there are many ready-\n\
    to-run solutions on the market where these neural networks are often trained by\
    \ \nlower-cost and more powerful clusters of cloud GPUs. \nThese solutions were\
    \ developed by several companies such as Google, \nAmazon, Microsoft, IBM, and\
    \ others, and are provided in the form of application \nprogramming interfaces\
    \ (APIs) which can be integrated into various application. \nVision pre-trained\
    \ models are either hosted for private use or offered as public \nservices for\
    \ deep learning in the cloud [165]. To use the pre-trained cloud-based \n \n52\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nmodels, application\
    \ developers employ the cloud-exposed APIs to offload deep \nlearning inference\
    \ tasks to the hosting server. \n \nThe advantage of a customized AI model is\
    \ the possibility to train it \naccording to the use case, in addition to detecting\
    \ the location of objects in the \nimage. The AI model can be trained to identify\
    \ different types of objects and their \nposition in an image. The trained custom\
    \ object detection model in the cloud can \nbe further implemented in an IoT gateway,\
    \ as the cloud service supports the edge \ncomputing option. \nEdge computing\
    \ has recently been envisioned to push cloud computing \nservices closer to IoT\
    \ devices and data sources. Edge computing is designed to \ndrive low-latency\
    \ data processing by migrating computing capacity from the \ncloud data centre\
    \ to the edge [166-167]. Influential cloud computing vendors, \nsuch as Google\
    \ [168] and Microsoft Azure [169], have released service platforms \nto drive\
    \ intelligence to the edge, allowing end devices to execute machine \nlearning\
    \ inference locally with pre-formed models. \nFigure 3.6 describes the six different\
    \ ways of using edge intelligence for ML \napplications, in which the edge can\
    \ be combined with the cloud or used alone for \nthe entire application process.\
    \ In this paper, we adopt two main methods: the \ncloud intelligence method, in\
    \ which training and inferencing are both performed \nin the cloud, and the Level\
    \ 3 method, with on-device inference and cloud \ntraining. \n \n \nFigure 3.6.\
    \ Six-level rating for edge intelligence [170] \n \n \n \n \n \n53 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n3.6  Evaluating performance of an object\
    \ detection model \n \nRapid advances in DL and improvements in device capabilities,\
    \ \nincorporating image sensor resolution, and optics, power consumption, memory\
    \ \ncapacity and computing power, have enhanced the cost-effectiveness and \n\
    efficiency of accelerating the spread of vision-based applications. Compared to\
    \ \ntraditional CV techniques, the DL allows CV engineers to achieve greater task\
    \ \naccuracy [171]. The neural networks used in DL are trained rather than \n\
    programmed; therefore, applications using this method often require less expert\
    \ \nanalysis and tuning and leverage the large amount of video data already present\
    \ \nin current systems. \nThe potential of cloud-based platforms is expected to\
    \ be exploited in the \nfuture for the development of computationally intensive\
    \ CNN applications [172]. \nThe obvious advantage is the possibility of creating\
    \ intelligent systems with \nlonger battery life, because the intense calculations\
    \ are performed elsewhere. \nWide and deep CNNs present a major challenge for\
    \ deployment and \nexecution on resource-constrained devices. Cloud computing\
    \ not only enables \nthe handling of massive amounts of data, but also takes advantage\
    \ of the benefit \nof high computing efficiency at a negligible cost. World leaders\
    \ such as Google, \nAmazon, IBM, and Microsoft offer the public highly scalable,\
    \ fast, and flexible \ncloud computing facilities to train CNN’s resource-hungry\
    \ architectures. The \ncloud environment also facilitates setting up libraries\
    \ for both researchers and \nnew practitioners. \nIn computer vision, one of the\
    \ most powerful algorithms is object detection, \nwhich aids in the classification\
    \ and localization of objects. Object detection is \nmore complicated due to the\
    \ fact that it requires drawing a bounding box around \neach object in the image.\
    \ \nMultiple deep learning algorithms exist for object detection like RCNN: Fast\
    \ \nRCNN, Faster RCNN, YOLO, Mask RCNN, etc. Moreover, Azure Custom Vision, \n\
    Google cloud and IBM Watson services allow users to load an image dataset to \n\
    classify or define the bounding box for each desired object in the image for \n\
    training. \nThe objective of an object detection model is to perform object classification\
    \ \nand localization, the former is to identify whether an object is present in\
    \ the \nimage and the class of the object, and the latter is to predict the boundary\
    \ box \ncoordinates around the object when an object is present in the image.\
    \ \nClassification models are evaluated on accuracy, precision, and recall, while\
    \ \nfor object detection, the concept of intersection over union (IoU) is employed\
    \ \n(Figure 3.7).  \nPrecision indicates the fraction of identified classifications\
    \ that are correct, \nwhile recall indicates the fraction of actual classifications\
    \ that are correctly \nidentified. IoU (intersection on union) is a measure of\
    \ how well a model predicts \n \n54 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nthe location of objects and is evaluated using the area of overlap of the\
    \ predicted \nbounding box regions and the ground truth, defined as follows: \n\
    \ \n\U0001D43C\U0001D45C\U0001D448 =\n\U0001D434\U0001D45F\U0001D452\U0001D44E\
    \ \U0001D45C\U0001D453 \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\
    \U0001D45D\n\U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\
    \U0001D45B\U0001D456\U0001D45C\U0001D45B                                     \
    \              (3.2) \n \n \n \n \nFigure 3.7. IoU equation, Red is ground truth\
    \ bounding box and green is \npredicted bounding box \n \nPrecision indicates\
    \ the fraction of identified detections that were correct, and \nrecall indicates\
    \ the fraction of actual detections that were correctly \nidentified. FP (False\
    \ Positive) represents the number of negative samples judged \nto be positive,\
    \ TP (True Positive) is the number of positive samples judged to be \npositive,\
    \ and FN (False Negative) is the number of positive samples judged to be \nnegative.\
    \ \n \n\U0001D443\U0001D45F\U0001D452\U0001D450\U0001D456\U0001D460\U0001D456\U0001D45C\
    \U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\U0001D443+\U0001D447\U0001D443\
    \                                                 (3.3) \n \n\U0001D445\U0001D452\
    \U0001D450\U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441\
    +\U0001D447\U0001D443                                                  (3.4) \n\
    \ \n \n4. Latency Assessment  \n \nOne of the important challenges to overcome\
    \ is the high-latency and \nunreliable link issues between the cloud and the IIoT\
    \ terminals. Fog computing \nextends computing and storage to the network edge\
    \ and is not only considered \nfor computation and storage, but also as a way\
    \ of integrating new systems \ncapable of interconnecting urgent and complex processing\
    \ systems. However, \neach fog and edge application may have different latency\
    \ requirements and may \ngenerate different types of data and network traffic\
    \ [173].  \n \n \n \n55 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n4-1 Latency between Two Terminals \n \nLatency is the time network traffic\
    \ delayed by the system processing, or the \ntotal time needed to send a network\
    \ packet from the application on one server to \nthe application on another server\
    \ through the network interface controller (NIC), \nnetwork (cable, Wi-Fi etc.),\
    \ and into an application on another server (or client). \nTo assess the latency\
    \ between two terminals, most approaches use the round-trip \ndelay time (RTD)\
    \ or the one-way delay (OWD). The latency in the context of \nnetworking is the\
    \ time spent by propagation through the network support and \nhardware of the\
    \ adapter, as well as the software execution times (application and \nOS) (Figure\
    \ 3.8). \n \n \n \nFigure 3.8. Latency between two terminals in a network \n \n\
    The hardware latency inside switches and on wires can be easily identified \n\
    from the switch specifications, length of the wires, and the maximal transmission\
    \ \ndata rates, while the software latency imposed by processing a packet in the\
    \ \nsoftware stack is more arduous to evaluate. Several parameters like system\
    \ \nworkload, operating system and executed application influence software latency.\
    \ \nEquation 3.5 defines the RTD between two terminals in a network, where tA\
    \ \nand tB are the software latency of the terminals A and B respectively, and\
    \ tH \nmarks the hardware latency of switches and wires connecting the terminals\
    \ A \nand B.  \n \n\U0001D445\U0001D447\U0001D437 = 2 \U0001D442\U0001D44A\U0001D437\
    \ = 2 \U0001D461\U0001D434 + 2 \U0001D461\U0001D43B + 2 \U0001D461\U0001D435 \
    \                                (3.5) \n \nTo accurately calculate OWD (by dividing\
    \ the round-trip time by two), the \nconfiguration of the test systems must be\
    \ perfectly symmetrical, meaning they \n \n56 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nmust be running the same software, using the same settings, and have\
    \ equal \nnetwork and system performance. \n \n4-2 OPC UA Architecture and delay\
    \ assessment  \n \nA client application may use the OPC UA client API (application\
    \ program \ninterface) in order to send/receive OPC UA service requests or responses\
    \ to or \nfrom the OPC UA server. From the programmer point of view, the OPC UA\
    \ client \nAPI is like an interface that decouples the client application code\
    \ from the client \nOPC UA communication stack. \n \nIn this section, we analyze\
    \ the delays involved in client-server OPC UA \ncommunications in a switched Ethernet\
    \ network. This model serves to define in \ndetail the non-deterministic sources\
    \ of end-to-end delay. The proposed model is \nbased on time delays defined in\
    \ [174-175] in an Ethernet-based network. Figure \n3.9 shows the round-trip data\
    \ path from an OPC UA server in PLC automate to \nan OPC UA client on the IoT\
    \ gateway and the hardware OWD required. \n \n \n \nFigure 3.9. OPC UA delay in\
    \ OPC UA client server in an Ethernet network \n \nWe consider the end-to-end\
    \ network delay in the switches and wires from \nthe client request to the server,\
    \ which can be divided into three categories, the \nframe transmission delay (dt),\
    \ the time required to transmit all of the packet’s \nbits to the link, the propagation\
    \ delay (dl), the time for one bit to propagate from \nsource to destination at\
    \ propagation speed of the link, and the switching delays \n(ds), which depend\
    \ on the route through the network to the server. \nThe transmission delay depends\
    \ on the length of packet L and capacity of \nlink C. The propagation delay is\
    \ related to the distance between two switches \nand the propagation speed of\
    \ the link S.  \n \n57 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n\U0001D451\U0001D459 =\n\U0001D437\n\U0001D446  , \U0001D451\U0001D461\
    \ =\n\U0001D43F\n\U0001D436                                                  \
    \      \n(3.6) \n \nThe switch delay is defined as the time for one bit to traverse\
    \ from switch \ninput port to the switch output port. It is divided into four\
    \ delays: the first is the \nswitch input delay (dSin), the delay of the switch\
    \ ingress port, including the \nreception of the PHY and MAC latency. The second\
    \ is the switch output delay \n(dSout), the delay of the switch egress port, including\
    \ the transmission PHY and \nMAC latency. The third delay is the switch queuing\
    \ delay (dSq), the time a frame \nwaits in the egress port of a switch to start\
    \ the transmission onto the link. The last \nis the switch processing delay (dSp),\
    \ the time required to examine the packet’s \nheader and determine where to direct\
    \ the packet is part of the processing delay.  \n \n\U0001D451\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D446\U0001D456\U0001D45B + \U0001D451\U0001D446\U0001D45D\
    \ + \U0001D451\U0001D446\U0001D45C\U0001D462\U0001D461 + \U0001D451\U0001D446\U0001D45E\
    (\U0001D461)                                     (3.7) \n \nThe hardware end-to-end\
    \ delay dCS presented as a request from an endpoint \nserver S to the destination\
    \ endpoint in a client C can be expressed as the sum of \nthe delays of all the\
    \ switches and links in the path, n being the number of links \nand n − 1 the\
    \ number of switches along the path.  \n \n\U0001D451\U0001D436\U0001D446(\U0001D461\
    ) = \U0001D451\U0001D461 + ∑\n(\U0001D451\U0001D459,\U0001D456) + ∑\n\U0001D45B\
    −1 \U0001D451\U0001D460,\U0001D456(\U0001D461) \n\U0001D456=1\n \n\U0001D45B\n\
    \U0001D456=1\n                                   (3.8) \n \nFigure 2.8 reveals\
    \ the architecture of the OPC UA server. The server \napplication is the code\
    \ that implements the server function. Real objects are \nphysical or software\
    \ objects that are accessible by the OPC UA server or \ninternally maintained\
    \ by it, such as physical devices and diagnostic counters. \nParticular objects,\
    \ such as Nodes, are used by OPC UA servers to represent real \nobjects, their\
    \ definitions and references; all nodes are called AddressSpace. \nNodes are accessible\
    \ by clients using OPC UA services (interfaces and methods) \n[176]. \n \nIn the\
    \ case of m number of requests from clients to the nodes in the OPC UA \nserver,\
    \ the overall hardware end-to-end delay of the OPC UA client-server (dCS) \ncommunication\
    \ over an Ethernet network, when there are m requests from the \nclient to the\
    \ server, is presented as: \n \n\U0001D461\U0001D43B = \U0001D451\U0001D436\U0001D446\
    (\U0001D461) =  ∑\n(\U0001D451\U0001D461,\U0001D457) + ∑\n(\U0001D451\U0001D459\
    ,\U0001D456) + ∑\n\U0001D45B−1(\U0001D451\U0001D460,\U0001D456)\n\U0001D456=1\n\
    \U0001D45B\n\U0001D456=1\n\U0001D45A\n\U0001D457=1\n                         \
    \    (3.9) \n \n \n \n58 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nBy analyzing all the delays mentioned in the hardware, we admit that the \n\
    end-to-end delay on Ethernet network is deterministic, except the delay in the\
    \ \nswitch queue, which depends on the link utilization. The packet queuing delay\
    \ \nincreases in a frequently used link. \nBy investigating the hardware delays\
    \ for an OPC UA client/server \ncommunication in an Ethernet network, we conclude\
    \ that it is hard to define \nexactly the hardware delay on the account of the\
    \ queuing delay. In that case, \nwhen it comes to complex processes with real-time\
    \ requirements, OPC UA \nreaches its limits. Different ways of defining this delay\
    \ exist, for example QoS \ntechniques such as WFQ (weighted fair queuing) or strict\
    \ priority [177]; \nnevertheless, there is always a certain amount of delay and\
    \ jitter that limits real-\ntime performance. Time sensitive networking (TSN)\
    \ provides mechanisms for \nthe transmission of time-sensitive data over Ethernet\
    \ networks. The adoption of \nOPC-UA over TSN will also drive this paradigm in\
    \ the world of deterministic \nand real-time machine to machine communications.\
    \ TSN provides mechanisms \nfor the transmission of time-sensitive data over Ethernet\
    \ networks. With \nEthernet’s limitations in terms of traffic prioritization,\
    \ the TSN working group \nhas developed the time-aware scheduler (TAS), defined\
    \ in 802.1Qbv [178]. TAS \nis based on TDMA, which solves the problem of synchronization\
    \ and traffic \npriority in the Ethernet. By using this technique, queuing delay\
    \ can be completely \neliminated, hence the end-to-end latency becomes deterministic.\
    \ This technique \nwas adopted in [179] to evaluate OPC UA performance on TSN\
    \ with the most \ncommonly used communication technologies. \n \n3-3 UAV System\
    \ Delay \n \nThere are several ways to introduce latency in a drone’s video compression\
    \ \nand transmission system. The end-to end delay in the system can be divided\
    \ into \nseven categories (Figure.3.10): Tcap is the capture time, Tenc the time\
    \ required to \nencode, the resulting transmission delay is Ttx, Tnw is the delay\
    \ network when \nthe drone is connected to the remote ground station via a network,\
    \ Trx is due to \nthe ground station also being wirelessly connected to a network,\
    \ Tdec is the \ndecoding delay at the reception station, and Tdisp is the display\
    \ latency.  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D45B\
    \U0001D464 + \U0001D447\U0001D45F\U0001D465 + \U0001D447\U0001D451\U0001D452\U0001D450\
    \ + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D                       \
    \          (3.10) \n \n \n \n \n \n59 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 3.10 Video transmission system delay sources. \n \nNote\
    \ that when the drone is communicating directly with the ground station, \nno\
    \ network is involved and there is only a single transmission delay (Tnw = 0 \n\
    and Trx = 0).  \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D    \
    \                                    (3.11) \n \nIn the H.264 system, each video\
    \ frame is organized into slices which are in \nturn divided into non-overlapping\
    \ blocks and macro-blocks (two-dimensional \nunit of a video frame). Every slice\
    \ is independently encoded and can decode itself \nwithout reference to another\
    \ slice. The main advantage of this system is that it is \nnot required to wait\
    \ for the entire frame to be captured before starting to encode. \nAs soon as\
    \ one slice is captured, the encoding process can start, and slice \ntransmission\
    \ can begin. This technique has a consistent effect on the overall \nlatency as\
    \ it influences all the system latencies from encoding to display. \nTheoretically,\
    \ we define the overall latency by the number of slices N, \nalthough in practice\
    \ this may not be the case due to setting up and processing \nindividual slices.\
    \  \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D + \U0001D441. (\U0001D447\
    \U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465 + \U0001D447\U0001D451\
    \U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\U0001D45D)   \
    \                               (3.12) \n \nIn order to efficiently transmit and\
    \ minimize the bandwidth, it is important \nto use video compression techniques,\
    \ although the slice technique also has an \neffect on the compression ratio.\
    \ The higher the number of slices, the faster they \ncan be encoded and transmitted,\
    \ although as this number increases, the number \nof bits used for a slice and\
    \ the effective slice transmission time also increase. \nOther types of delay\
    \ also affect the overall delay. Some factors can be \nadjusted when a UAV system\
    \ is used. For example, Tcap depends on the frame \nrate of the UAV camera, the\
    \ higher the frame rate, the shorter the capture time. \nTx relies on the available\
    \ data bandwidth of the transmission channel, while \nTdisp (video capture) is\
    \ based on the refresh rate of the display. \n \n \n \n \n \n \n60 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \n \n \n \n \n \nCHAPTER 4 \n \n--------------------------------------------------\
    \ \n \nEnergy Efficiency and Latency of Smart \nIoT Monitoring and Control Systems\
    \ \nBased on cloud Computing and \nIntelligent Machine Vision \n \n \n--------------------------------------------------\
    \ \n \n \n \n \nI. Smart Industrial IoT Monitoring and Control \nSystems Based\
    \ on cloud Computing and Intelligent \nMachine Vision \n \n61 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n1. Introduction   \n \nIndustry 4.0 is the information-intensive\
    \ transformation trend towards \nautomation and data exchange of manufacturing\
    \ technologies and processes \nincluding, robotics, cyber-physical systems (CPS),\
    \ the Internet of things (IoT), the \nInternet of services (IoS), cloud manufacturing,\
    \ big data and augmented reality \n[180]. Industry 4.0, the Fourth Industrial\
    \ Revolution, has already made \nsignificant changes to manufacturing and production\
    \ industries and offers a \nwealth of opportunities. Nevertheless, numerous issues\
    \ are also becoming the \nfocus of active research. These relate to concerns about\
    \ delays, data security, \ndevice communication and service availability. The\
    \ lack of ubiquitous \ninteroperability between heterogeneous devices is also\
    \ a major concern. \nAttempting to achieve seamless interoperability is further\
    \ complicated by the \nlong life of typical industrial equipment, to which costly\
    \ upgrades or \nreplacements are required to operate with the latest technologies\
    \ [181].  \nDue to the interactions between servers and IoT devices, massive amounts\
    \ of \ndata need to be transmitted through the IoT network, raising significant\
    \ data \ntransmission overhead to the network. As a number of IIoT systems are\
    \ time \nsensitive, the large increase in network traffic causes high network\
    \ latency and \nlarge packet loss, significantly affecting the performance of\
    \ IIoT systems. Fog \ncomputing is a potential middleware that can be very useful\
    \ for various \nindustrial scenarios. Since industrial processes require most\
    \ tasks to be carried \nout locally due to time and security limitations. Fog\
    \ computing can reduce and \nrefine large industrial data locally, before it is\
    \ sent to the cloud. Also, it can \nprovide local processing support with acceptable\
    \ latency for robots and actuators \nin a manufacturing industry [182]. However,\
    \ each fog and edge application may \nhave different latency requirements and\
    \ may generate different types of data and \nnetwork traffic [183]. \nRecent advances\
    \ in robotics, geomatics, and computer vision technologies \nhave made it possible\
    \ to capture an enormous amount of visual data using low-\ncost unmanned aerial\
    \ vehicles (UAVs). As a kind of flexible, fast and low-cost \ndata acquisition\
    \ system, UAVs have demonstrated great capabilities in \nperforming numerous mapping,\
    \ surveying and remote sensing tasks with very \nhigh-resolution data [184]. \n\
    UAVs have been widely used in manufacturing companies to monitor \njobsites in\
    \ real time and to provide high-definition (HD) images and video to \nidentify\
    \ changes and solve or prevent many problems [185]. They have also been \nused\
    \ for maintenance, inspection and tasks that are dangerous, inaccessible or \n\
    costly from the ground [186]. The integration of UAVs in the IoT represents an\
    \ \ninteroperability challenge, since each IoT system has its own communication\
    \ \n \n62 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nprotocol. Besides,\
    \ a small delay or error beyond the tolerated limit could result \nin a disaster\
    \ for various applications, such as manufacturing and monitoring of \naircraft\
    \ and UAVs.  \nUAVs technology has undergone a significant transformation and\
    \ has found \napplications in different fields, the off-board base station gives\
    \ them higher \ncomputational capacity and the ability to carry out more complex\
    \ actions using \nhigh-level programming languages, or leveraging services from\
    \ computer vision \ntools by acquiring, processing, analyzing and understanding\
    \ digital images in \nreal-time.  \nCrack assessment systems for concrete structures\
    \ are constantly improving \nthanks to computer vision technologies and UAVs.\
    \ UAVs combined with digital \nimage processing have been applied to crack assessment\
    \ as a cost-effective and \ntime-effective solution, instead of visual observation\
    \ [187]. Image recognition \ntechnology has a great potential in various industries\
    \ and has been improved by \ndeep learning and machine learning image recognition\
    \ systems (TensorFlow, \nand MATLAB) or image processing techniques such as computer\
    \ algorithms for \ndigital image processing. \n \nConcrete batching plant also\
    \ is a critical process, which is susceptible to \nchanges of mixed materials.\
    \ Due to some errors in the discharge and filtering \nprocess, these materials\
    \ are sometimes mixed incorrectly, which affects the \nquality and consistency\
    \ of the concrete. The drone's camera and cloud-based \nservices can identify\
    \ the condition of the aggregates being transported on the \nconveyor belts so\
    \ that adjustments can be made to the production process. \n \nImage processing\
    \ has become a significant asset for UAVs systems and not \nonly in industry.\
    \ Capturing footage and videos generates a huge amount of data, \nfor which cloud\
    \ computing is vital [188]. \nComputing capabilities can be extended to the cloud,\
    \ taking advantage of the \nservices offered, and saving the cost and energy consumption\
    \ of an embedded \nUAV system. While the fog can be responsible for technical\
    \ assistance between \nhumans and machines, information transparency, interoperability,\
    \ decentralized \ndecision-making, information security, and data analysis.  \n\
    The rest of this chapter is organized as follows, we introduce the proposed \n\
    the three-layer IIoT-based UAV architecture, then we define the different \nprotocols\
    \ and applications used to connect the different systems. Following, we \ndiscuss\
    \ three-layer architecture latency using different IoT gateways in the fog \n\
    layer.  \n \n2. System model \n \n \n63 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nA three-layer IIoT-based UAV architecture (Industrial IoT) is considered\
    \ in \nthis work. An IIoT monitoring and control system based on a UAV integrated\
    \ \ninto traditional industrial control system architecture. The first layer consists\
    \ of \ntwo different systems, the first is industrial control system connected\
    \ to \nindustrial sensors, actuators and PLCs, and the second is the UAV monitoring\
    \ \nsystem. The second layer is the fog computing layer for storage, computing\
    \ and \ncommunications. The last layer is a cloud computing layer with image processing\
    \ \nservices. Communication between the layers and systems is provided by the\
    \ IoT \ngateway installed in the fog layer, which links securely in real time\
    \ the industrial \ncontrol layer to the UAV system, the UAV system to the cloud,\
    \ and finally the \ncloud to the industrial control system. We validated our design\
    \ proposal in an \nindustrial concrete manufacturing plant as a case study with\
    \ the aim of \nimproving production and reducing costs. \n \n \nFigure 4.1: Proposed\
    \ UAV-IIoT Platform \n \nThe control system receives data from remote or connected\
    \ sensors that \nmeasure set points (SP) of process variables (PV). When the system\
    \ detects a \nchange in trend between the PVs and SPs, the change is routed to\
    \ PLCs and the \nIoT Gateway that triggers the UAV system's reaction. The UAV\
    \ goes to a specific \npoint to supervise the process using the front camera.\
    \ Once the images are \ncaptured, the IoT Gateway receives them and sends them\
    \ to the cloud, which \nadopts deep learning techniques to analyze and send the\
    \ results to the IoT \nGateway and the control system to confirm the anomaly.\
    \ The fog layer is \nresponsible for communications between all other layers;\
    \ it automatically makes \ndecisions based on the results and data received and\
    \ transmits the results to other \napplications and layers. The fog layer, presented\
    \ as an IoT gateway, can support \nall the necessary tools and protocols to ensure\
    \ storage, communication and \ncomputing. Between the different layers of the\
    \ IIoT-UAV proposed architecture, \nthere are different network protocols (Figure\
    \ 4.2). In the first layer, the industrial \nsensors of the control system are\
    \ connected to a PLC that acts as an OPC UA \n \n64 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nserver, which routes the sensor data to the IoT Gateway\
    \ using the OPC UA \nprotocol. The IoT gateway integrates an OPC UA client installed\
    \ in Node-RED. \nNode-RED can also communicate with cloud services using IBM Visual\
    \ \nRecognition Nodes (WVR), which sends the UAV’s images to the cloud using \n\
    Internet protocols. The Ar.Drone Node.js library installed in the IoT Gateway\
    \ can \ncommunicate with Node-RED using the Exec node, which launches the UAV\
    \ \nmission and establishes the wireless connection between the UAV and the IoT\
    \ \ngateway using the Wi-Fi protocol. \n \n \nFigure 4.2. Development design of\
    \ autonomous IIoT flight \n \nNode-RED can connect all systems in the proposed\
    \ architecture using a wide \nrange of nodes. The OPC UA server installed in the\
    \ control system (PLC), \ncommunicates with the OPC UA Node-RED client node, which\
    \ reads the sensor \nvalues and launches the UAV program using the Exec node if\
    \ certain conditions \nare met. While receiving new images from the UAV, Node-RED\
    \ send them to the \ncloud for recognition or storage, using the Watson Visual\
    \ Recognition and \nCloudant nodes respectively. Ultimately, based on the results\
    \ received from the \nWVR node, a message is sent to the industrial control system\
    \ using the OPC UA \nnodes to adjust the concrete plant's production. Figure 4.3\
    \ shows the Node-RED \nflow and the connections between the nodes. \n \n \n65\
    \ \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.3. Node-RED\
    \ flow in the IoT gateway including the path from the PLCs to the \nUAV, from\
    \ the UAV to IBM Watson, and from Watson to the control center. \n \n \n2.1. Use\
    \ Case description   \n \nConcrete batching plants form part of the construction\
    \ sector. Their many \nimportant components include cement and bins, aggregate,\
    \ aggregate batchers, \ncement silos, dust collectors, conveyors, mixers, heaters,\
    \ and control panels. \nConcrete plants involve a human–machine interaction between\
    \ the operator and \nthe control system. The operator inputs the concrete formula\
    \ by specifying the \nquantities of material to be mixed and this data is processed\
    \ by a control system \nso that the correct amount of material is conveyed to\
    \ the mixer (Figure 4.4). The \nmaterials used in the concrete plant are cement,\
    \ admixtures, aggregates, and \nwater. The quality and uniformity of the concrete\
    \ depend on the slump value, air \ncontent, water-cement ratio, and homogeneity.\
    \ \n \n \nFigure 4.4. SCADA Industrial concrete plant with a typical concrete\
    \ formula. \n \nTraditionally, microwave sensors have been used in aggregate bins\
    \ to \nmeasure the aggregate water content and then adjust the formula as required\
    \ to \n \n66 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \ncontrol concrete\
    \ quality. Aggregates of different sizes are stored in bins for \ndifferent formulas.\
    \ Due to some errors during the filtering and unloading \nprocess, these materials\
    \ are sometimes mixed incorrectly, affecting concrete \nconsistency and quality.\
    \ Both the UAV camera and the IBM WVR service in the \ncloud can track the state\
    \ of the aggregate materials being transported on the \nconveyor belts with the\
    \ aim of adjusting the production process. \nThe cloud service is used to classify\
    \ normal and mixed aggregates. The role \nof the UAV in this is to take pictures\
    \ when materials are being transported on the \nbelts before they reach the mixer.\
    \ The cloud classifies each image sent by the \ndrone and returns the results\
    \ to the IoT gateway as a score between 0.0 and 1.0 \nfor each class. This result\
    \ is sent to the PLC after being processed in the IoT \nGateway. Using these results,\
    \ any excess amount of a material can be measured, \nand the necessary adjustments\
    \ can be made to obtain the final formula. This \noperation eliminates wasted\
    \ time and allows the desired formula to be obtained \nbefore the final mixing.\
    \ The proposed approach is considered a cost-effective \nsolution and eliminates\
    \ repeated and unnecessary operator controls, traditional \nmonitoring and control\
    \ systems. \n \n2.2. UAV Mission Planning  \n \nThe novelty of the proposed IoT\
    \ control system is that it provides real-time \ninteraction between an industrial\
    \ control system, UAVs and the cloud. Based on \nthe input information from the\
    \ concrete plant, the UAV can interact and execute \nthe mission automatically\
    \ and provide the necessary photos to the cloud to \ncompute and analyze the data\
    \ by deep learning methods and send the result back \nto the control system for\
    \ decision-making. The drone mission (Figure 4.5) is split \ninto three paths:\
    \ planning the mission, taking photos, and returning to the \nstarting point.\
    \  \nThe drone takes off at position (x, y), climbs to a certain altitude, hovers,\
    \ \nreturns to the start, and lands. The autonomous flight library was based on\
    \ the \nAR.Drone library [189] , which is an implementation of networking protocols\
    \ for \nthe Parrot AR Drone 2.0. This library has four features: a camera projection,\
    \ an \nextended Kalman filter, a PID Controller to control drone position, back-\n\
    projection to estimate distance to an object, and a VSLAM to improve the drone\
    \ \nposition estimates [190-191]. The AR. Drone 2.0 is equipped with sensors with\
    \ \nautomatic stabilization features and precise controls, two cameras, a 60-fps\
    \ \nvertical QVGA camera for measuring ground speed and a 1280 × 720 at 30 fps\
    \ \nresolution front camera with a 92◦ (diagonal) field of view, three-axis \n\
    magnetometer with 6◦ precision, three-axis accelerometer with +/-50 mg \nprecision,\
    \ Ultrasound sensors to measure height, three-axis gyroscope with \n2000◦/s precision,\
    \ and a pressure sensor with +/-10 Pa precision. The drone can \nmonitor its own\
    \ position and mapping (SLAM), robustness and controls. \n \n \n67 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.5. AR.Drone 2.0 mission in\
    \ the concrete plant. \n \nUAVs are easy to deploy, flexible, can quickly change\
    \ position in a time-\ncritical situation and can be quickly configured. Integrating\
    \ them into a control \nsystem accelerates the production chain by responding\
    \ in real time to the various \nchallenges of the control system thanks to the\
    \ cloud services. Figure 4.6 details \nthe communication process between the different\
    \ parts of the proposed \napproach, including the industrial control system, UAVs\
    \ and the cloud, and data \nflows between the different nodes. Two main applications\
    \ are installed in the IoT \ngateway: the Node.js application and the Node-RED\
    \ application. The former \ncontrols the drone, while the latter facilitates communication.\
    \ \nNode-RED controls the flow by reading data from the OPC UA node, which \n\
    is connected to the automation control system. In case a certain issue is confirmed\
    \ \nby the PLC, Node-RED triggers the UAV mission executed by Node.js. The \n\
    UAV's mission (figure 4.5-4.7) is divided into three parts: planning the mission,\
    \ \ntaking pictures and returning to the starting point. The WVR Node and the\
    \ \nCloudant Node receive the images and send them to the IBM cloud for \nprocessing\
    \ and storage. Node-RED collects the classification scores of each new \nimage\
    \ from the cloud and processes them in the IoT gateway before transmitting \n\
    the evaluation to the control system using OPC UA. \n \n \n68 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nFigure 4.6. Communication process in the fog layer. \n\
    \ \n3. Results and Discussion \n \nThe drone in the worksite (concrete batching\
    \ plant) is located in the base \nstation, which is at a distance from the conveyor\
    \ belts the conveyor belts and is \nalways ready to respond to the new demands\
    \ of the industrial control system. \nThe UAV carried out 10 test missions over\
    \ three days in a real concrete plant in \nCartagena, Spain. The first step was\
    \ to fly automatically over a distance of about \n130 m to position the UAV at\
    \ the beginning of the conveyor belts. Then, the UAV \nmoved over the conveyors,\
    \ took pictures and sent them to the IoT gateway. The \nlast step was to bring\
    \ the UAV back to the starting point (Workstation) (Figure \n4.7). \n \nFigure\
    \ 4.7. Path used by the drone to execute the mission in a concrete plant. \n \n\
    \ \n \n \n69 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n3.1. IBM Watson\
    \ Image Recognition Training  \nOff-board image processing techniques were selected\
    \ due to the asset of the \ncloud services. IBM’s Watson visual recognition (WVR)\
    \ service analyzes the \ncontent of images from the drone camera transmitted through\
    \ the IoT gateway \n(Figure 4.1). MATLAB, OpenCV or TensorFlow could also have\
    \ been used as the \ncontrol system; however, the cloud completes the computing\
    \ activities and \nprovides an efficient time and cost optimization. The WVR service\
    \ can classify \nand train visual content using machine learning techniques. \n\
    WVR is based in part on the technology developed for the IBM multimedia \nanalysis\
    \ and retrieval system (IMARS) [192], supplemented by “deep features” \nthat are\
    \ extracted on Caffe software [193]. The WVR service extracts feature \nvectors\
    \ from a particular layer of a Caffe network for all the supplied examples \n\
    and uses them to train a one-versus-all support vector machine (SVM) model for\
    \ \neach class. The feature extraction process is therefore equivalent to “inferencing”\
    \ \nwith the neural network, but the SVM learning process is less CPU intensive\
    \ than \ninferencing [194]. \nThe Watson service generally accepts a maximum of\
    \ 10,000 images or 100 MB \nper .zip file and a minimum of 10 images per .zip\
    \ file, with different angles and \nscenarios to obtain the maximum precision.\
    \ The service recommends that the \nimages be at least 224 × 224 pixels and contain\
    \ at least 30% of the subject matter. \nIn order to train the custom model, we\
    \ used a dataset of the images captured by \nthe UAV camera from the field of\
    \ practice in different positions. In addition, we \nroughly divided the use case\
    \ into two parts: a mixed material set and a normal \nmaterial set (Figure 4.8).\
    \ \n \n \n                                    (a)                            \
    \                                    (b) \nFigure 4.8. Dataset used to train the\
    \ custom model in WVR service: (a) Shows images \nused to train the Mixed class;\
    \ (b) Shows Images used to train the Normal class. \n \nIn the training stage\
    \ we used the dataset images to create two new classes, a \nMixed class, and a\
    \ Normal class. These classes were grouped to define a single \ncustom model.\
    \ In the testing stage, the results of the Watson tests are shown as a \nconfidence\
    \ score for the image in the range of 0 to 1. A higher score indicates that \n\
    \ \n70 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nthe class is more likely\
    \ to be depicted in the image. The scores are considered as \na threshold for\
    \ action, and the confidence score are based on training images, \nevaluation\
    \ images, and the types of criteria of the desired classification. Figure \n4.9\
    \ shows the test of three different new images and the results of each class score.\
    \ \nWVR recognized the difference between the images according to the density\
    \ of \nthe normal material on the conveyors. For instance, the confidence score\
    \ for the \ntest-3 .jpg image is 0.92 for the normal class, indicating the greater\
    \ likelihood of \nthis class being in the image. \n \n \nFigure 4.9. Watson visual\
    \ recognition test of new images not used in the training \nphase. \n \n3.1.1\
    \ WVR Performance Evaluation \n \nTo assess the performance of the WVR, we used\
    \ a formula to calculate the \naccuracy as defined by equation (4.1). In our case,\
    \ we tested a data set of more \nthan 100 photos and obtained a final detection\
    \ accuracy of 87.28%. The \nmisclassified cases are listed in Table 4.1, which\
    \ represents the confusion matrix. \nOn the basis of a large number of tests with\
    \ new images not used in the training \nphase, a threshold for each score class\
    \ was defined, a decision was made, and the \norder was sent to the industrial\
    \ control system to adjust the quantities of material \nbeing transported on the\
    \ conveyor belts. \n \n \n                      \n\U0001D434\U0001D450\U0001D450\
    \U0001D462\U0001D45F\U0001D44E\U0001D450\U0001D466 =\n\U0001D447\U0001D443 + \U0001D447\
    \U0001D441\n\U0001D447\U0001D443 + \U0001D447\U0001D441 + \U0001D439\U0001D443\
    \ + \U0001D439\U0001D441 \n            \n(4.1) \n \n \nWhere TP is the number\
    \ of positive samples judged to be positive, FP \nrepresents the number of negatives\
    \ samples that are judged to be positive, FN is \nthe number of positive samples\
    \ judged to be negative, and TN the number of \nnegative samples judged negative.\
    \ \n \n \n71 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nTable 4.1.\
    \ Confusion matrix \n \nPredictive Positive \nPredictive Negative \nTrue Positive\
    \ \n58 (TP) \n6 (FN) \nTrue Negative \n9 (FP) \n45  (TN) \n \nAfter training the\
    \ WVR model in the cloud, the WVR Node can send the new \nphotos received in the\
    \ IoT gateway to the cloud service (Figure 4.10). The cloud \nservice classifies\
    \ the new photos and returns the results to the WVR node as a \nscores for each\
    \ class, which are then analyzed and sent to the PLC via the OPC \nUA protocol.\
    \ Figure 4.10 shows the results obtained from the WVR node in Node-\nRED. \n \n\
    Figure 4.10. Node-RED flow and WVR results of an UAV photo \n \n3.2. Delay Assessment\
    \ in the Proposed Platform \nThis section presents the RTD time metrics of the\
    \ IoT gateway connections in \nits conditions of use and highlights the crucial\
    \ role of the IoT gateway in terms \nof latency. In this application, the IoT\
    \ gateway is connected to different systems \nwith different transmitted data.\
    \ Below, we evaluate this difference by using three \ngateways with different\
    \ performances. Each IoT gateway has its own software \nand hardware components\
    \ to process the data with different processing times. \nTable 4.2 shows the specification\
    \ of each of the three selected platforms. \n \nTable 4.2. Specification of each\
    \ machine environment. \n \nSiemens Gateway \nIOT2040 \nRaspberry Pi 3 \nModel\
    \ B \nToshiba \nSATELLITE C870 \nEthernet \n2 x 10/100 Ethernet \nRJ45 \n10/100\
    \ BaseT Ethernet \nsocket \n10/100 BaseT \nEthernet RJ-45 \nProcessor \nIntel\
    \ Quark x1020 \n400 MHz \n1.2 GHz Quad-Core ARMv7 \nIntel Core i3 2348-M \nCPU\
    \ 2.3GHz \nOperation \nSystem \nLinux Kernel 4-4-18 \nYocto Standard \nLinux Raspbian\
    \ 4.14.79-v7+ \n \nWindows 7 \nProfessional \nRAM \n1 GB \n1 GB \n8 GB \nDisk\
    \ Memory \n32 GB \n16 GB \n500 GB \n \n \n72 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n3.2.1. OPC Experimental Method and Results \n \nA case study was\
    \ used to define the latency of the OPC UA client-server \narchitecture. The experimental\
    \ set-up was based on an industrial plant and \nsoftware in addition to three\
    \ different IoT-based platforms. The industrial control \nsystem deployed as an\
    \ OPC UA server uses a Siemens S7-1512 with embedded \nOPC UA communication stack.\
    \ The OPC UA client is implemented using Node-\nRED OPC UA client node in the\
    \ three different devices, the IoT gateway IOT2040 \nfrom Siemens (S-G), a PC\
    \ computer Toshiba SATELLITE (PC-G), and a Raspberry \nPi 3 Model B (RPI-G) (Figure\
    \ 4.11). In the first step of the latency study, we \ncompared the RTD with the\
    \ three different devices considered as OPC UA client \nattached to the same Siemens\
    \ S7-1512 OPC UA server network. \n \n \nFigure 4.11. OPC UA delay in OPC UA client\
    \ server in an Ethernet network. \n \nThe given application is deployed in a local\
    \ network and is based on a typical \nuse case which consists in reading a bit\
    \ from the OPC UA server. All the RTD \nmeasurements were performed on the same\
    \ network. Under these conditions, we \nconsider that RTD delay is derived mainly\
    \ from the Tx software latency of the \nsoftware stack of device X (Equation3.4)\
    \ assuming an insignificant hardware \nlatency tH of the wires and the switch.\
    \ \nAn MX machine is defined as well as a pair of software setup SW and a \nhardware\
    \ setup HW : \n           \U0001D440\U0001D465 = (\U0001D43B\U0001D464,\U0001D446\
    \U0001D464)                                              (4.2) \n \nThe hardware\
    \ setup HW is defined as the set of all hardware elements in this \nmachine and\
    \ the software setup SW is defined as the set of all software elements \n[195].\
    \ \n \n \U0001D43B\U0001D464 = {\U0001D440\U0001D452\U0001D45A\U0001D45C\U0001D45F\
    \U0001D466,\U0001D443\U0001D45F\U0001D45C\U0001D450\U0001D452\U0001D460\U0001D460\
    \U0001D45C\U0001D45F, \U0001D441\U0001D43C\U0001D436 … }                     \
    \               (4.3) \n                                     \U0001D446\U0001D464\
    \ = {\U0001D434\U0001D45D\U0001D45D\U0001D459\U0001D456\U0001D450\U0001D44E\U0001D461\
    \U0001D456\U0001D45C\U0001D45B, \U0001D442\U0001D446, \U0001D437\U0001D45F\U0001D456\
    \U0001D463\U0001D452\U0001D45F\U0001D460 … }                                 \
    \    (4.4) \n \n73 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nIn order to\
    \ measure latency, a timestamp contained in an injection node in Node-\nRED was\
    \ used (Figure 4.12). In every request, the timestamp request is saved by \na\
    \ function node. The latency L is defined as the difference between the timestamp\
    \ \nof the server response and the client timestamp request saved in the first\
    \ function \nnode. Hence, latency L is measured as : \n \n\U0001D43F = \U0001D447\
    \U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461 − \U0001D447\
    \U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\U0001D45B\U0001D460\U0001D452\
    \ = \U0001D445\U0001D447\U0001D437)                                      (4.5)\
    \ \n \n \nFigure 4.12. Node-RED flow used to calculate round trip latency (OPC\
    \ UA Client to the \nOPC UA Server). \n \nThe latency results are summarized in\
    \ Table 4.3, showing the minimal and \nmaximal values, RTD average, and the standard\
    \ deviation calculated for each fog \ncomputing machine. The OPC UA requests were\
    \ repeated each second to read \nthe one-bit value in the OPC UA server (Figure\
    \ 4.12). All the samples were \nthoroughly checked for the same architecture on\
    \ different days in an \nexperimental campaign with more than 5000 valid samples.\
    \ S-G gateway latency \nis higher than in the RPI-G and PC-G gateways, approximately\
    \ three times that \nof the RPI-G and seven times that of the S-G. This difference\
    \ is evident in the \nprobability density function as shown in Figure 4.13. The\
    \ shapes of the RPI-G \nand the PC-G are almost the same with a single peak, while\
    \ the S-G shape is \nnarrower and scattered over a large time area. \n \nTable\
    \ 4.3. RTD test of 5200 samples from the OPC UA client to the OPC UA server (PLC)\
    \ \nover different clients through different machines. \n \nClient Test \nEnvironment\
    \ \nData Type \nAverage \nStandard \nDeviation \nMinimum \nLatency \nMaximum \n\
    Latency \nS-G \nBOOL (1 bit) \n23.160 ms \n23.56 ms \n19 ms \n878 ms \nRPI-G \n\
    BOOL (1 bit) \n8.22 ms \n3.48 ms \n5 ms \n76 ms \nPC-G \nBOOL (1 bit) \n3.288\
    \ ms \n2.65 ms \n0 ms \n32 ms \n \n74 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.13. OPC UA client-server RTD to read one bit through\
    \ different machines. \n \nIn order to analyze this large difference in the recorded\
    \ RTD between RPI-G \nand S-G, we continuously monitored the CPU load for 5 min\
    \ during the OPC UA \nchannel' s RTD. The RPI-G and S-G gateways were tested individually\
    \ in the \nsame network conditions and running only Node-RED, which runs the OPC\
    \ UA \nclient. The computed CPU usage was calculated as the average of all cores\
    \ of the \nRPI-G and S-G gateways (see figure 4.14). \n \n \n \nFigure 4.14. (a)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in \nthe S-G; (b)\
    \ Simulation results of CPU load (%) versus OPC UA RTD (ms) in the \nRPI-G. \n\
    \ \nGiven the analogy of a similar situation [196], which assumes that the larger\
    \ \nthe RTD pattern peaks the higher the probability they are due to the higher\
    \ CPU \nload, although the recorded CPU load patterns are not only due to the\
    \ OPC UA \nclient implemented in Node-RED. Nonetheless, we compared the impact\
    \ of CPU \nusage in the RTD as regards the same conditions in the two gateways.\
    \ It should \n \n75 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nbe noted that\
    \ the impact of Node.js can be estimated to be around 10% of the \nprocessing\
    \ power of the gateway used in the demonstration case, and the number \nof devices\
    \ connected to the gateway linearly increases CPU and memory usage \n[73]. \n\
    There is always intense use of CPU in the S-G RTD when high latency is \ndetected.\
    \ The S-G peaks sometimes exceed 400 ms (Figure 4.14, Table 4.3) while \nin the\
    \ RPI-G they do not exceed 80 ms. Furthermore, the average CPU load of the \n\
    RPI-G is much lower than that of the S-G. The average value of the CPU load in\
    \ \nthe S-G is around 8%, while in the RPI-G it is around 1.7% and the number\
    \ of \ndevices connected to the gateway linearly increases the CPU load. \n \n\
    3.2.2. UAV Experimental Results \n \nThe streaming quality of the proposed Node.js\
    \ application was measured \nunder certain conditions of use to compare the response\
    \ time on different IoT \ngateways in the same configurations and conditions.\
    \ The transmission channel, \nframe rates and compression techniques were the\
    \ same in all the tests on the \nrecording of camera images and saving them to\
    \ a folder in the IoT gateway. The \nimage frames were captured and registered\
    \ in a buffer before being sent to the \ngateway. Encoding was performed by FFMPEG\
    \ codec, and the received frames \nwere decoded in the gateway before being saved\
    \ on the gateway disk. \n \n• Codec Latency \n \nThe AR.Drone library [197] uses\
    \ the basic H264 profile (MPEG4.10 AVC) for \nhigh quality streaming and video\
    \ recording. The Baseline profile was targeted at \napplications in which a minimum\
    \ of computational complexity and a maximum \nof error robustness are required.\
    \ H.264/MPEG4-AVC baseline supports two slice-\ncoding types (I and P slice types),\
    \ designed for progressive video such as video \nconferencing, video-over-IP,\
    \ and mobile applications [198]. The simplest is \nthe I slice, in which all macro-blocks\
    \ are coded without referring to any other \npictures in the video sequence. Previously\
    \ coded images are used to form a \nprediction signal for macro-blocks of the\
    \ predictive-coded P [199]. \nTheoretically, based on Equation (3.12), UAV delay\
    \ can be estimated by: \n \n\U0001D447 = \U0001D447\U0001D450\U0001D44E\U0001D45D\
    \ + 2. (\U0001D447\U0001D452\U0001D45B\U0001D450 + \U0001D447\U0001D461\U0001D465\
    \ + \U0001D447\U0001D451\U0001D452\U0001D450 + \U0001D447\U0001D451\U0001D456\U0001D460\
    \U0001D45D)                                  (4.6) \n \n \nThe experiments focus\
    \ on the mission delay generated by taking pictures in \na concrete production\
    \ plant. We measured the time needed for the drone to \nconnect with the IoT gateway,\
    \ take a picture and save it in a file in the IoT \ngateway (WriteFile function\
    \ from Node.js). Table 4.4 shows the results of an \nAR.Drone 2.0 mission with\
    \ around 200 images on the Node.js application, \n \n76 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntriggered from Node-RED. The latencies in both machines\
    \ are expressed in \nmilliseconds and calculated in the Node.js application. \n\
    \ \nTable 4.4. RTD Test of 200 photos sent from the IoT gateway to the AR.drone\
    \ \n2.0. \n \nThe results provided in Table 4.4 shows the large difference in\
    \ terms of \nlatency between RPI-G, S-G and PC-G. The average RPI-G latency is\
    \ almost three \ntimes that of PC-G, and RPI-G standard deviation is much higher\
    \ than in PC-G. \nNote that these tests were made with an image resolution of\
    \ 640 × 360 px, frame \nrate of 5 fps and a codec with H264 baseline. \nOn the\
    \ other hand, the S-G results are consistently different from those of PC-\nG\
    \ and RPI-G; the average S-G latency is very high, while the standard deviation\
    \ \nis lower than RPI-G. \nFigure 4.15 shows the probability density function\
    \ of the delay of the drone \nconnected to the gateway when successive pictures\
    \ from PC-G and RPI-G are \ntaken. While Figure 4.16 shows the probability density\
    \ function of the delay of \nthe drone connected to the gateway when successive\
    \ pictures from S-G are taken. \nHere, the distributions are clearly different,\
    \ the data spreading of the PC-G \ndistribution covers a narrower range, with\
    \ a larger spread in the S-G and RPI-G \ndistributions. \n \n \nFigure 4.15. Probability\
    \ density function of the delay of the drone connected to \nthe gateway when successive\
    \ pictures from PC-G and RPI-G are taken. \n \nClient Test \nEnvironment \nConnection\
    \ \nEstablished \nAverage  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum\
    \ \nLatency \nS-G \n11429 ms \n1229.92 ms \n365.71 ms \n160 ms \n2906 ms \nRPI-G\
    \  \n5348 ms \n317.76 ms \n411.18 ms \n12 ms \n1706 ms \nPC-G  \n4562 ms \n132.72\
    \ ms \n35.90 ms \n4 ms \n230 ms \n \n77 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.16. Probability density function of the delay of the\
    \ drone connected to \nthe gateway when successive pictures from S-G are taken.\
    \ \n \nFigure 4.17, figure 4.18 and figure 4.19 compare the CPU load of the same\
    \ \nprogram implemented in the IoT gateways. The program continuously takes \n\
    images from the drone and stores them in a file in the gateway. The first time\
    \ \nperiod (red interval) in all three graphs shows the first connection between\
    \ the \ndrone and the gateways, while the rest of the time period is the time\
    \ of execution \nof the Node.js program in the gateways. \n \n \nFigure 4.17.\
    \ CPU Load while taking successive photos and writing them in a \nfolder in the\
    \ PC-G. \n \n \nFigure 4.18. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the RPI-G. \n \n78 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.19. CPU Load while taking successive photos and writing\
    \ them in a \nfolder in the S-G. \n \nThe three IoT gateways have different environmental\
    \ specifications. Figures \n4.17-4.19 show these differences in terms of CPU usage\
    \ in the three gateways \nwhile executing the mission. In S-G, it increases from\
    \ 3% to 100%, while in RPI-\nG, the CPU load increases from 2% to 60%. In the\
    \ PC-G gateway the average CPU \nload while executing the mission was around 20%.\
    \ This difference is justified \nmainly by the numbers of cores implemented in\
    \ each gateway processor. S-G \nused a 400 MHz Intel Quark ×1020 processor with\
    \ a single core, while RPI-G used \na 1.2 GHz Quad-Core ARMv7 processor with four\
    \ cores. Furthermore, RPI-G and \nPC-G both support the Graphics Processing Unit\
    \ (GPU), while S-G does not. \n \n3.2.3. Watson Experimental Method \n \nThe IBM\
    \ Watson visual recognition service uses deep neural networks to \nanalyze images\
    \ and is currently operated in a data center in Dallas (USA). \nMultiple servers\
    \ are used to ensure high throughput and reliability. Node-RED \nprovides a node\
    \ to connect to the WVR service which takes an image as input \nand produces a\
    \ set of image labels as output. \nThe experiments carried out were based on Equation\
    \ 4.5 and used the Node-\nRED flow. The latency results are summarized in Table\
    \ 4.5, the RTD average, \nstandard deviation, minimal and maximal values calculated\
    \ for each fog \ncomputing machine.  \nThe experiment was repeated for one sample\
    \ field case image less than a data \nblock size of 154,076 bytes. All the samples\
    \ were carefully and thoroughly \nchecked for the same architecture on the same\
    \ day. Each experimental campaign \nhad around 100 valid samples for each machine.\
    \ Between each 100 requests, the \nnext request is triggered at the time of receiving\
    \ the results of the previous \nrequest from the WVR. \n \n \n79 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.5. RTD test of 100 samples from\
    \ the IoT gateway to IBM Watson over different \nmachines.  \n \n \nThe results\
    \ reported in Table 4 display the differences between the different \nfog machines.\
    \ The average RPI-G and PC-G scores are lower than the S-G. \nHowever, RPI-G is\
    \ faster than S-G and has a larger standard deviation, while PC-\nG is faster\
    \ than RSP-G with a low standard deviation. The probability density \nfunction\
    \ estimates of the WVR delay for the three gateway machines are given in \n(Figure\
    \ 4.20). In this case, the probability density of the S-G has almost the same\
    \ \ncurvature as that of RPI-G, while the probability density of PC-G is larger.\
    \ \n \n \nFigure 4.20. Probability density function estimation of IBM WVR latency\
    \ to classify an \nimage located in the IoT gateway. \n \nGiven that the WVR node\
    \ in Node-RED relies on the HTTP protocol to send \nthe images to the cloud, we\
    \ performed another test using SpeedTest to measure \nthe HTTP throughput between\
    \ the web server and the client over the three \ngateways considered as clients\
    \ (on the same day with the same network \nconditions). The results obtained in\
    \ Table 4.6 indicate similar results for the \ndownload, while the S-G upload\
    \ is lower than the other gateways. \n \n \nClient Test \nEnvironment \nAverage\
    \  \nStandard \nDeviation  \nMinimum \nLatency \nMaximum \nLatency \nS-G \n1913.18\
    \ ms \n522.17 ms \n1454 ms \n5594 ms \nRPI-G \n1373.09 ms \n453.64 ms \n1080 ms\
    \ \n5151 ms \nPC-G \n1129.29 ms \n181.97 ms \n980 ms \n2491 ms \n \n80 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nTable 4.6. Speed Test over the three gateways\
    \ (S-G, RPI-G, PC-G) \nMachine \nPing \nDownload \nUpload \nS-G \n169.4 ms \n\
    16.3 Mbps \n9.5 Mbps \nRPI-G \n96.4 ms \n17.6 Mbps \n13.8 Mbps \nPC-G \n55.7 ms\
    \ \n17.5 Mbps \n12.3 Mbps \n \n \n \nII.  Autonomous Underwater Monitoring System\
    \ for \nDetecting Life on the Seabed by Means of \nComputer Vision Cloud Services\
    \ \n \n \n1. General introduction \n \nThe world's seas, as a valuable asset and\
    \ a vital part of its ecology, must be \nprotected as an essential source of life,\
    \ food and wealth. This implies monitoring \nsystems to ensure their condition\
    \ and sustainable management, which involves \nsurveying chemical and physical\
    \ parameters related to water quality, such as \ndissolved oxygen, nitrates, salinity,\
    \ temperature, density and chlorophyll levels, \namong others. Other purposes\
    \ of seabed monitoring are the detection and \nconservation of archaeological\
    \ artifacts and the monitoring of the state of marine \nflora and fauna, including\
    \ particularly sensitive endangered species [200]. \nStudies have been carried\
    \ out in different regions of the Mediterranean, \nparticularly in the Mar Menor,\
    \ a zone of particular interest due to its exceptional \nenvironment. Studies\
    \ have been carried out in different regions of the \nMediterranean, particularly\
    \ in the Mar Menor, a zone of particular interest due \nto its exceptional environment.\
    \  \nThe Mar Menor in southeast Spain, with unique salinity and temperature \n\
    characteristics, is Europe’s largest Salt Lake, with an area of 180 km2. It is\
    \ a \nvaluable resource with a remarkable ecosystem and a wide range of habitats\
    \ for \nendangered species. It has been the subject of numerous scientific studies\
    \ when \nit was recently contaminated biologically and chemically by torrential\
    \ rains \ncontaining large amounts of fresh water and agricultural runoff from\
    \ the \nsurrounding farmland, which affected its flora and fauna [200]. It also\
    \ shelters \nconsiderable plankton and phytobenthic populations during the warm\
    \ season. \nAll these factors have affected many of its indigenous species. \n\
    27 types of habitats of special interest have been inventoried in the Mar \nMenor\
    \ and its surroundings, eight of which are of priority [201]. Protected \nspecies\
    \ are also abundant and include seagrass meadows (Cymodocea nodosa \nand Ruppia\
    \ cirrhosa), marine fauna of special interest, such as seahorses \n \n81 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \n(Hippocampus ramulosus) or\
    \ toothed carp (Aphanius iberus), large quantities of \nfan mussels (Pinna nobilis)\
    \ and a wide range of seabirds [202]. The fan mussel is \nan endemic bivalve mollusc,\
    \ the largest in the Mediterranean and the second \nlargest in the world. The\
    \ International Union for the Conservation of Nature \n(IUCN) has included Pinna\
    \ nobilis in its updated list of critically endangered \nspecies due to parasitic\
    \ diseases [203]. In 2019, the discovery of a series of \nspecimens in the Mar\
    \ Menor confirmed that this natural area was a refuge for \nthis endangered species\
    \ on the verge of extinction along the entire Mediterranean \ncoastline and that\
    \ it was therefore essential for its monitoring. Although such \nmonitoring can\
    \ be carried out from manned vessels, it is time-consuming, \nlaborious and costly\
    \ and can be carried out much more effectively by AUVs [204]. \nAUVs are now widely\
    \ in use for a variety of tasks, including oceanographic \nsurveys, mine clearance,\
    \ demining and bathymetric data collection in marine and \nriver environments\
    \ [205]. They are valuable for mapping underwater \nenvironments and are playing\
    \ an increasing role in marine development [8]. \nThey now have power sources\
    \ and an intelligent control system that can perform \nautonomously programmed\
    \ tasks with appropriate decision-making capabilities \n[200]. Advances in computer\
    \ science, sensor technology, new materials and \nadvanced algorithms have significantly\
    \ increased their performance, although \nmany issues remain to be resolved [206,207].\
    \ \nAlong with the challenges and difficulties of an autonomous robot \nnavigating\
    \ in an unstructured environment, the marine environment has its own \nlimitations,\
    \ not only because of the currents but also because of the difficulty of \ngeolocating\
    \ the submerged AUV. The absence of communication networks and \nthe complexity\
    \ of real-time connection is also a drawback and could be a \ndetermining factor\
    \ not only for transmitting exploration results, but also for \nleveraging increased\
    \ computing capacity and information management when \nnecessary, such as artificial\
    \ intelligence (AI) provided by cloud computing \nservices.  \nSome AUV architectures\
    \ imply the technological challenge of a high \nprocessing, connection and communication\
    \ capacity. This necessitates an \narchitecture that is capable of integrating\
    \ with a nearby base station, the Internet \nand cloud architectures. The information\
    \ gathered during an operation also \nentails interpretation, which can be crucial\
    \ for decision making. This means that \nnot only the local connection is important,\
    \ as well as the connection with web \nservices (cloud computing, data centers,\
    \ etc.). The latter can be used to create \nwizards for specific purposes and\
    \ processes to which complex and specific tasks \ncan be delegated. \nWe propose\
    \ and assess an AUV system designed to collect and interpret \nunderwater images\
    \ in Mar Menor in order to trace the fan mussel population in \nreal time, using\
    \ georeferenced mosaics generated from the images by an \nautomatic processing\
    \ method. \n \n \n82 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    \ \n \n \n2. System model \n \nThe proposed AUV-IoT architecture is structured\
    \ in three layers, with the \nAUV being in the data generation and pre-processing\
    \ layer. The first layer \nconsists of an AUV composed of different sensors and\
    \ blocks for data generation, \nconversion and pre-processing (figure 4.21). The\
    \ pre-processing system is \ndeployed in an IoT gateway installed in the head\
    \ box and connected to the \ncamera by a switch. The IoT Gateway is defined as\
    \ an edge node. Another layer \nis the data communication layer with the cloud\
    \ via Wi-Fi or 4G networks. The \nlast layer is a back-end cloud with image processing\
    \ techniques. \n \nFigure 4.21. Proposed AUV-IoT Platform \n \nAs shown in Figure\
    \ 4.22, the three layers are made up of different electronic \ndevices with access\
    \ to software services, the physical layer is constituted by a \nvariety of electronic\
    \ devices interconnected by three different networks \naccording to their functionality:\
    \ The Internet/cloud network, the Ethernet \nnetwork and the CAN (controller area\
    \ network). The CAN network is composed \nof one master and four slave nodes.\
    \ Each node consists of an electronic card \nspecifically designed for this vehicle\
    \ and its assigned tasks, and has as a core a \nPIC 18F4685 microcontroller, working\
    \ at a frequency of 25 MHz. \n \n \n83 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.22. Proposed hardware architecture. \n \nThe CAN network\
    \ is the fieldbus that interconnects the elements dedicated \nto instrumentation,\
    \ measurement and actuation. It connects equipment devoted \nto specific processes\
    \ (inputs/outputs, sensor reading, engine control). The CAN \nnetwork has a master/slave\
    \ configuration, and the elements of this network \ncommunicate via the CAN field\
    \ bus, using the CANopen protocol at a speed of \n250 kbps, sufficient for real-time\
    \ exchange of process information. This protocol \nis particularly robust and\
    \ immune to electromagnetic interference, a feature that \nmakes it ideal for\
    \ this vehicle. \nThe CAN network consists of four slave nodes and a master. Each\
    \ node \nconsists of an electronic board specially designed for this vehicle and\
    \ the tasks \nassigned to it, and has a PIC 18F4685 microcontroller as its core,\
    \ operating at a \nfrequency of 25 MHz. The main functions of each node are as\
    \ follows: \n \n• \nNode 1 (in the head of the vehicle) manages its movement,\
    \ lighting, \ncamera power, tilt reading (pitch and roll) and the acquisition\
    \ of inertial \nunit variables. \n• \nNode 2 (DVL: Doppler velocity logger) manages\
    \ data acquisition \nand body tilt reading (pitch and roll). \n• \nNode 3 governs\
    \ GPS reading, engine management and control \n(propulsion, rudder and dive).\
    \ \n• \nNode 4 monitors marine instrumentation sensors (side-scan sonar, \nimage\
    \ sonar, microUSBL) and their energy management. \n• \nThe master node consists\
    \ of a National Instrument single-board \nRemote Input/Output (NI sbRIO) 9606\
    \ (the main vehicle controller). Its \nfunction in this network is to collect\
    \ process information from each of the \nnodes and send commands. It is the link\
    \ with the superior Ethernet \nnetwork. \n \n84 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nThe Ethernet network permits higher data transfer\
    \ rates between devices and \nis formed by the AUV sbRIO control system, IP camera,\
    \ IoT gateway, and the 4G \nrouter. All of these are connected to the buoy via\
    \ an umbilical cable. \nEthernet/DSL (Digital Subscriber Line) gateways are used\
    \ owing to the number \nof wires in the umbilical cable connecting the vehicle\
    \ to the surface buoy (only \ntwo wires are available for data).  \nAs at least\
    \ four cables are used with Ethernet, and only two with DSL, the \nEthernet protocol\
    \ is converted to DSL before and after the umbilical cable by the \nDSL to Ethernet\
    \ gateways. The local bandwidth is 100.0 Mbps, with latencies of \nless than 1\
    \ ms. \nThe Internet/cloud network connects the vehicle to the cloud. The 4G router\
    \ \nintegrated in the surface buoy ensures the connection to the cloud. The aim\
    \ of \nthis network is the communication of the IoT gateway with the cloud and\
    \ \ncommunication of sbRIO control system with IUNO (Interface for Unmanned \n\
    Drones) fleet management software. The IUNO software platform was designed \n\
    at the Automation and Autonomous Robotics Division (DAyRA) of the \nPolytechnic\
    \ University of Cartagena. The platform is intended to manage the \nintegrated\
    \ control of multiple unmanned marine vehicles with the aim of \nsimplifying maritime\
    \ operations. The results obtained from each vehicle, \nregardless of its characteristics,\
    \ facilitate the success of the operation with a high \ndegree of automation [200].\
    \ AEGIR is the name of the AUV developed by \nDAyRA, and it is the main vehicle\
    \ used in this paper; its structure is described in \nFigure 4.22. \n \n3.1. IoT\
    \ Gateway: The Edge Node and Connection to the Cloud \n \nThe implemented IoT\
    \ gateway is capable of connecting the sensor network \nto the cloud computing\
    \ infrastructure, performing edge computing and serving \nas a bridge between\
    \ the sensor networks and the cloud services [208]. \nExperiments were carried\
    \ out using Python installed in the IoT gateway. \nThe Python program employed\
    \ serves as an interface to communicate with \nthe submarine sensors and actuators,\
    \ the cloud computer vision APIs and the \nunderwater controller (Figure 4.23).\
    \ \n \n \n85 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.23.\
    \ Node intercommunications and concurrent threads in the IoT \ngateway. \n \n\
    Python has a built-in support for scientific computing. Its use is growing \n\
    fastest in data science and machine learning [209]. Versatility, the stability\
    \ of \nlibraries with great support, and ease of use are its main benefits [210].\
    \ The IoT \ngateway also features Open-source Computer Vision (OpenCV) which is\
    \ a \nlibrary of programming functions mainly for real-time CV. In our application,\
    \ \nOpenCV is used for live video streaming over an Ethernet network connected\
    \ to \nthe prospective IP camera (model Sony SNC-CH110) installed in the head\
    \ box. \nAll the Python cloud libraries required for image recognition are installed\
    \ in the \nIoT gateway. \nWhereas the Python program in the IoT gateway is started\
    \ (Algorithm 1), \nconnection is established with the camera by the Real-Time\
    \ Streaming Protocol \n(RTSP). The Python program in the IoT gateway is executed\
    \ to run four threads \n(tasks) at the same time (Figure 4.24). \nThe first thread\
    \ is tasked with capturing and streaming video images from \nthe IP camera to\
    \ the IoT gateway internal memory. If a specimen is detected using \nthe cloud\
    \ object detection service, the AUV’s movements are adjusted to focus \nthe camera\
    \ on the object. The distance between the detected specimen and the \nvehicle\
    \ is computed in the IoT gateway and employed to steer the AUV to track \nits\
    \ position. The AUV’s heading and mission control commands are routed via \nTCP/IP\
    \ (Transmission Control Protocol/Internet Protocol) to the sbRIO controller \n\
    in the head box, which is connected to several nodes via a CAN bus protocol. \n\
    Each node is connected to a different group of sensors and actuators.  \nThe cloud\
    \ service used in this case is the vision object detection service, \nwhich allows\
    \ training of customized machine learning models that are able to \ndetect individual\
    \ objects in a given image along with their bounding box and \nlabel. There are\
    \ many different cloud APIs for computer vision, e.g., IBM, Google, \nMicrosoft\
    \ Azure and Amazon. They all provide fairly similar capabilities, \nalthough some\
    \ emphasize object recognition, Amazon, or building custom \n \n86 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmodels, like Microsoft Azure and IBM.\
    \ The strength of these cloud APIs is their \nability to develop custom models\
    \ rapidly and download trained custom models \nto deploy them on the edge for\
    \ real-time applications and low-latency \nrequirements [211-212]. \nTo appraise\
    \ the effectiveness of the suggested platform, we assessed its \noverall latency,\
    \ in order to act quickly when an underwater specimen is detected \nand control\
    \ the AUV mission according to the cloud results of each photo. The \nPython program\
    \ is divided into four threads; however, the response time of the \ncloud services\
    \ takes significantly longer, depending on different factors. Figure \n4.23 presents\
    \ clearly the connection between the IoT gateway and the different \nsystems.\
    \ Each thread of the IoT gateway is responsible for synchronously \ntriggering\
    \ a task and ensures maintenance of the connection. \n \n3. The AUV-IoT Architecture\
    \ Development \n \nIn this section, we itemize and outline the development of\
    \ the above-\nmentioned IoT-AUV autonomous system and its network protocols, portraying\
    \ \nfive main blocks, namely, the IoT gateway, the IP camera, the AUV control\
    \ \nsystem, the AUV control station and the cloud.  \nThe overall mission is triggered\
    \ in the AUV control station by setting the \ndesired waypoints and activating\
    \ the AUV engines and IP camera streaming. The \nIoT gateway in the head box connects\
    \ the AUV nodes and the IP camera with \ncloud services. The IoT gateway receives\
    \ image data from the IP camera in the \nsubmarine’s head box and sensor data\
    \ from the body box. Likewise, the IoT \ngateway seizes the image processing results\
    \ from the cloud for each sent photo. \nIf a fan mussel is detected, the results\
    \ contain its delimitation box in the image \nand the percentage of image accuracy.\
    \ When a fan mussel is detected using the \ncloud API (Application Programming\
    \ Interface), the IoT gateway links up with \nthe main controller to modify the\
    \ submarine’s mission and track the specimen \ndetected. \nThe submarine’s new\
    \ mission is based on the results received from the cloud \nAPI and the algorithm\
    \ processed in the IoT gateway. The algorithm implemented \nin the IoT gateway\
    \ is in charge of adjusting AUV movements to keep the targeted \nspecimen in the\
    \ centre of the field of view. The distance to the detected specimen \nis computed\
    \ using the cloud API and a triangular similarity algorithm [213-214].  \nThe\
    \ desired mission modifications are routed to the main controller to handle \n\
    the engines and vehicle heading. In this case, the AUV’s manual tracking control\
    \ \nis replaced by an automatic specimen detection system using the cloud APIs\
    \ and \nthe distance measurement algorithm implemented in the IoT gateway. A specific\
    \ \narea is explored based on a specific mission with settled waypoints. The tracking\
    \ \nalgorithm in the IoT gateway is triggered automatically if the forward camera\
    \ \ndetects a specimen (Figure 4.24). \n \n87 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \n \nFigure 4.24. Communication between platforms. \nThe IoT gateway’s\
    \ main function is to acquire the camera image, timing the \nshot according to\
    \ the AUV’s depth and speed, to obtain photographic mosaics \nwith overlapping\
    \ images. The IoT gateway receives the captured images and \nforwards them to\
    \ the cloud, which uses advanced learning techniques to analyse \nthe results\
    \ and send them to the IoT gateway. The obtained results from the cloud \nare\
    \ exploited to adjust the new underwater mission to pinpoint the specimen’s \n\
    exact location. This is described in Algorithm 1, as well as in the flowchart\
    \ in \nFigure 4.23. \n \nAlgorithm 1. Specimen tracking algorithm \nStart () \n\
    Step 1:  \n     While (mission has not started) {}         \nStep 2: \n     If\
    \ (mission has ended) \n         {End()} \n     Else \n         {Acquire frame\
    \ and send to cloud} \n         {Get the answer} \n         If (accuracy > 20%)\
    \  \n             {Go to step 3} \n         Else \n             {Go to step 2}\
    \ \nStep 3: \n     {Calculate the bounding box centre of detected object} \n \
    \    {Calculate the distance between the centre of the detected nacre bounding\
    \ box (C1) and \n      the center of the captured frame (C2)} \n     {Conversion\
    \ of distance (C = C2–C1) into degrees (new heading and tilt setpoint)} \n   \
    \  {Send command to sbRIO with new heading and tilt setpoint.} \n     If (C==0)\
    \  \n          {Go to step 4} \n \n88 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n     Else \n          {Go to step 3} \nStep 4: \n     {Send the command\
    \ to sbRIO to set the speed (fixed speed setpoint)} \n     {Take images I1 and\
    \ I2 in two different positions, where P1 and P2 are the pixel widths \n     \
    \ of the objects detected in both images} \n     {Calculate the distance using\
    \ the following equations. \n \n \n \n  \n     where F = 2.34 mm is the focal\
    \ distance, W is the width of the real detected object \n     If (the distance\
    \ D calculated > 2m) \n          {Go to step 4} \n     Else \n          {Go to\
    \ step 5} \nStep 5: \n     {Get accuracy of the specimen image} \n     If (accuracy\
    \ ≥ 80%)  \n          {Save point, save picture and resume mission} \n       \
    \   {Send command to sbRIO to save specimen’s position} \n     Else \n       \
    \   {Go back to the main mission without saving. It is not a specimen} \n    \
    \      {Go to Step 2} \nEnd () \n \n3.3. AUV Control \n \nThe most relevant characteristics\
    \ of the AUV used in the experiment are as \nfollows: the vehicle is physically\
    \ divided into two compartments (head and \nbody), consisting of five thrusters\
    \ (two for propulsion, two for depth control and \none for the rudder) and weighs\
    \ 170 kg. This vehicle is capable of submerging to \n200 m and has 7-hour autonomy.\
    \ Its two battery blocks (one supplies power to \nthe electronics and sensors\
    \ and the second to the thrusters) are reconfigurable to \n24V for greater autonomy\
    \ or to 48V for greater power and cruising speed. It can \nmove at 4 knots and\
    \ perform long-term missions while locating and identifying \nsubmerged targets,\
    \ photogrammetry and sonar inspection of the seabed. It is \nequipped with the\
    \ following devices: image sonar, side scan sonar, micro-USBL \n(UltraShort BaseLine)\
    \ for acoustic positioning, an inertial unit, GPS (Global \nPositioning System),\
    \ a DVL (Doppler Velocity Logger) for measuring \nunderwater movements, a camera\
    \ and a depth meter. \nAs shown in Figure 4.23, our underwater vehicle has a number\
    \ of elements \nand devices interconnected through different networks. While the\
    \ IoT gateway \nis in charge of recognition and communications with the camera\
    \ and the cloud, \nthe sbRIO controller is the AUV’s main control backbone. The\
    \ National \nInstrument sbRIO 9606 embedded controller integrates a real-time\
    \ processor \nwith a reconfigurable FPGA through its LabVIEW environment [215-216].\
    \ It \ncomprises Ethernet, CAN and I/O connectivity, as well as a 400-MHz CPU,\
    \ \n \n89 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n256MB DRAM,\
    \ 512MB storage, and other features listed in [215-216]. A consistent \ncode for\
    \ the sbRIO controller was fully developed in the LabVIEW environment \nfor AUV\
    \ management, control and command. \nThe modules in the sbRIO’s vehicle control\
    \ program comprise these operations: \n• CAN bus (reading and writing interface):\
    \ There are a number of nodes \nconnected to the vehicle's CAN bus, whose network\
    \ master is the sbRIO. Each \nof the nodes has a series of sensors and actuators\
    \ connected. The function of \nthese blocks is to receive information and send\
    \ commands to the different \nnodes through the CANopen protocol. The type of\
    \ data received or sent will \ndepend on the function of the node. \n• TCP/IP\
    \ \n(reading \nand \nwriting \ninterface): \nThis \nmanages \nTCP/IP \ncommunications\
    \ for receiving commands from IUNO and the IoT gateway, \nas well as sending navigation\
    \ information from the vehicle to the rest of the \nequipment on the Ethernet\
    \ network. \n• Data manipulation: This is responsible for adapting the data formats\
    \ from the \ndifferent sources (CAN, inertial unit, IUNO) to a common format within\
    \ the \nprogram and vice versa: e.g., conversion of latitude received through\
    \ the \nCAN network interface (UINT8 array type, extracted from a buffer) to I32\
    \ \ndata type. \n• Data saving: This saves the process and navigation information\
    \ in the sbRIO \nin TDMS (Technical Data Management Streaming) format files. TDMS\
    \ is a \nbinary measurement file format, focused on storing information in the\
    \ \nsmallest possible space. It can be exported to several formats (csv, xls,\
    \ txt, \netc.). \n• Heading \ncontrol/depth \ncontrol/velocity \ncontrol/heading\
    \ \ntilt \ncontrol: \nManagement of the different control loops for heading, depth,\
    \ velocity and \nhead tilt. These take on special importance in automatic or semi-automatic\
    \ \nnavigation modes. \n• Thruster control: As a result of the previous timed\
    \ loop, a heading, depth or \nposition setpoint is obtained. In this module, they\
    \ are processed to obtain as \na result a PWM (Pulse-Width Modulation) value to\
    \ be applied to each of the \nvehicle’s engines. \n• Automatic (IUNO)/manual mode\
    \ navigation: AEGIR developed at the \nDivision of Automation and Autonomous Robotics\
    \ (DAyRA) of the \nPolytechnic University of Cartagena, and the Ocean Server AUV\
    \ IVER2. \nIUNO’s capabilities and characteristics. An AEGIR vehicle can be handled\
    \ in \nboth modes: manual and automatic. This timed loop is in charge of selecting\
    \ \nthe appropriate navigation source. Only the automatic mode is considered in\
    \ \nthis paper. \n• Mission management: Once the mission created in IUNO is downloaded,\
    \ this \nmodule manages each of the waypoints to which the vehicle must navigate,\
    \ \ndispatching the different navigation commands for the heading control/depth\
    \ \ncontrol/position control timed loops. This module also handles the main \n\
    \ \n90 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nnavigation mode in\
    \ normal operations and the specimen tracking navigation \nmode, as described\
    \ in Section 7. \n \n4. Artificial Intelligence and Vision-Based Object Recognition\
    \ \n \n4.1 Object Detection Training in the Cloud \n \nThe Mar Menor, as the largest\
    \ saltwater lake in Europe with a wide range of \nflora, requires constant monitoring.\
    \ The 4G network covers the entire zone and \nconnects a large area to the Internet\
    \ to take full advantage of cloud computing \nservices. As described above, AUVs\
    \ are a complete fan mussel monitoring system \nthanks to being interconnected\
    \ to the latest cloud computing services. \nBesides the general object detection\
    \ models provided by cloud services, \ncertain others can be used to create their\
    \ own custom object detection model to \nidentify items and their location in\
    \ an image. Object detection models can be \ntrained to recognize objects that\
    \ are important to the user in specific domains. \nObject detection training data\
    \ is the set of object labels and locations in each \ntrained image. The tag or\
    \ label identifies what the object is. The location identifies \nwhere it is in\
    \ the image. It is also possible to identify more than one object in an \nimage.\
    \ Cloud services offer users a friendly interface to develop and deploy \ncustom\
    \ CV models. We identify the location by drawing a bounding box around \nthe object\
    \ and providing the top and left pixel coordinates of that box, along with \n\
    the width and height in pixels (Figure 4.25). \n \n \nFigure 4.25. Fan mussel\
    \ recognition training: defining a fan mussel bounding \nbox in different cloud\
    \ services. \nIn the case study, we trained about 90 photos on the same data set\
    \ in Azure, \nGoogle and IBM Watson cloud services, all of which offer nearly\
    \ the same service \nfor custom object detection. The training photos are a mix\
    \ of our own photos and \nothers from Creative Commons sources [217] (Figure 4.26).\
    \ The system is very \nsimilar to custom classification, except that this service\
    \ identifies the location of \nthe items in the image. The response also includes\
    \ a classification label for each \nitem detected and an identification confidence\
    \ score. \n \n \n91 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.26.\
    \ Pictures used for custom CV model training. \nAfter creating a custom object\
    \ detection model and completing the training, \nwe tested its fan mussel detection\
    \ capacity in other images using the Python \ncloud API, as shown in Figure 4.27.\
    \ \nThe trained vision model successfully identified a new specimen in the image\
    \ \nand also its location and its probability percentage score. The blue bounding\
    \ box \nis drawn by the Python program using the results received from the cloud.\
    \ \nAccording to the results and the AUV navigation sensor data, the proposed\
    \ \nAlgorithm 1 can estimate the distance between the AUV head box and the \n\
    detected specimen. \n \n \nFigure 4.27. New specimen detection using the IBM Python\
    \ API. \n5. Visual Servo Control and Distance Estimation \nVisual servo control\
    \ consists of computer vision data usage to control the \nAUV’s motion [218].\
    \ Related works on underwater vision tracking and visual \nservo control for autonomous\
    \ underwater vehicles have shown that vision and \nvisual servo control are imperative\
    \ in developing AUV systems, as the vision–\n \n92 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nAUV combination yields substantial benefits. Several\
    \ studies on underwater \ntracking focus on visual servoing, such as autonomous\
    \ alignment and dynamic \npositioning [218-219], pipeline following and planet\
    \ target tracking [220]. With \nthe advent of machine vision and deep learning,\
    \ it is currently viable to specify \nthe object to be tracked. ML object tracking\
    \ has already been tested in different \nunderwater applications, such as fish\
    \ tracking and diver following and tracking \n[221-222].  \nTo perform underwater\
    \ vision tracking in Mar Menor and track the \nunderwater Pinna nobilis species,\
    \ the fan mussel tracking algorithm is solved \nusing the object recognition cloud\
    \ API incorporated in the AUV control loop. \nThrough this algorithm, we verify\
    \ that a specimen has been detected, and from \nthere we calculate the coordinates\
    \ of its center (x, y). In this scenario, the AUV \nreduces speed, and a PID (Proportional–Integral–Derivative)\
    \ controller will keep \nthe object in the centre of the frame by adjusting AUV\
    \ yaw and head tilt to keep \nthe camera centred on the object detected [223-224].\
    \  \nWhen more than one specimen is detected, the system follows the one with\
    \ \nthe highest score. The x and y coordinates are adopted as information in the\
    \ object \ntracking process. To make the system effectual, the port and starboard\
    \ engines \nand AUV head tilt are adjusted to track the object using the object’s\
    \ coordinates \nas feedback. The thrust motors follow the position changes of\
    \ the object’s \ncoordinates by means of PID controllers. When the detected object\
    \ is centred, its \ndistance from the AUV camera is computed using the cloud API\
    \ results and a \ntriangular similarity algorithm [213-214]: \n \n    \U0001D437\
    \ = \U0001D44A \U0001D439\n\U0001D443\n \n(4.7) \n \nwhere P is the width of\
    \ the object in pixels and W is the width of the object itself. \nThe camera focal\
    \ distance F is fixed and the apparent P is obtained from the \ncloud results.\
    \ To obtain W and estimated distance D, a minimum of two pictures \nare required\
    \ at different distances from the object for calibration, as presented in \nFigure\
    \ 4.28 and Algorithm 1. \n \n \n93 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.28. Triangular similarity using a single camera [225]. \n(\U0001D437\
    \ +  ∆\U0001D451) \U0001D443\U0001D4611 = \U0001D437 \U0001D443\U0001D4612 =\
    \ \U0001D44A \U0001D439 \n(4.8) \n \n\U0001D437 =\n(∆\U0001D451 \U0001D443\U0001D461\
    1)\n(\U0001D443\U0001D4612− \U0001D443\U0001D4611)                           \
    \                                                                  (4.9) \n  \n\
    The cloud object detection API and the tracking algorithm are fully \nimplemented\
    \ using Python. The entire Python program is processed in the IoT \ngateway while\
    \ yaw and tilt are processed in the sbRIO main controller. The \noutput data coordinates\
    \ from the cloud are used to keep the AUV automatically \nfocused on the object\
    \ itself in the desired position. \nThe sbRIO main controller drives the robot’s\
    \ movements to keep the target’s \nbounding box in the centre of the camera image.\
    \ The IoT gateway continuously \nsends coordinate errors (distance, X position,\
    \ Y position) to this controller, so that \nthese data become the input for the\
    \ closed loop for tilt, heading and speed \nadjustments (Figure 4.29). \n \nFigure\
    \ 4.29. Closed control loop for object detection and tracking. \nFigure 29 presents\
    \ the modules and process involved in detecting \nand tracking the target. In\
    \ the object detection algorithm block, the \nsystem aims to keep the target in\
    \ the centre of the image. When the \nrelative size of the target has been obtained\
    \ from the object detection \nAPI, these control loops are kept operative while\
    \ the speed is \ngradually increased to calculate the estimated distance by means\
    \ of \nthe similarity triangulation algorithm. From then on, tilt, heading, \n\
    speed and control loops keep the target in the centre until the vehicle \nis at\
    \ the desired distance. The tilt and heading closed control loop \n \n94 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nwere successfully tested in\
    \ calm waters and slow currents, although \ndifficulties were encountered with\
    \ stronger currents. \nServo Control Latency \nThe visual system is required to\
    \ provide real-time results from the control \nloop with very low latencies. The\
    \ principal concern is the ability to detect the \ntarget and aim the camera at\
    \ the centre of the image. To obtain effective real-time \ncontrol, the delays\
    \ involved in initially detecting the target and those of the \nsensor and actuator\
    \ while tracking the object must be minimised (Figure 4.30) \n[226]. Three distinct\
    \ types of delay are involved. The first is actuator delays, \nwhich occur in\
    \ the feedforward loop when the delay is in the robot itself. The \nsecond type\
    \ is sensor delays in the feedback path of a closed-loop system, derived \nfrom\
    \ a sensor delay. This delay is present in any real-time control system with \n\
    visual feedback and depends on the amount of visual processing required. The \n\
    third type is transportation delays, or pure time delays, usually due to long-\n\
    distance communications. \n \nFigure 4.30. Basic closed-loop system with sensor\
    \ and actuator delays. \nTo reliably assess the servo control latencies, we modelled\
    \ the basic closed-\nloop system with sensor and actuator delays, as shown in\
    \ Figure 4.30. Y(s) is the \noutput signal and R(s) is the reference signal. The\
    \ sensor and actuator delays are \nrepresented, respectively, as \nand \nin the\
    \ frequency domain, the \n(undelayed) sensor dynamics by H(s), the (undelayed)\
    \ plant dynamics by G(s), \nand the controller by C(s). \nThe most important delays\
    \ in a control loop with visual feedback are those \ncaused by the sensor, and\
    \ the delay time directly affects the dynamic stability of \nthe control system.\
    \ System stability is determined by the poles of the \ninput/output transfer function,\
    \ i.e., the roots of the denominator. For a single-\ninput–single-output (SISO)\
    \ system, the denominator (characteristic equation of \nthe system) is simply\
    \ 1+ the loop gain, so that any stability analysis would \nincorporate the total\
    \ actuator and sensor delay to determine stability bounds. \n \n\U0001D44C(\U0001D460\
    )\n\U0001D445(\U0001D460) = \n\U0001D436(\U0001D460)\U0001D43A(\U0001D460)\U0001D452\
    −\U0001D460(\U0001D447\U0001D44E)\n1 + \U0001D436(\U0001D460)\U0001D43A(\U0001D460\
    ) \U0001D452−\U0001D460(\U0001D447\U0001D44E)\U0001D43B(\U0001D460) \U0001D452\
    −\U0001D460(\U0001D447\U0001D460)                                            \
    \    (4.10) \n \n95 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \n \nand the\
    \ characteristic equation is: \n \n1 + C(s)G(s)H(s)\U0001D452−\U0001D460(\U0001D447\
    \U0001D44E+\U0001D447\U0001D460)  = 0 \n(4.11) \n \nThe effects of stability can\
    \ be analysed by studying the conditions of marginal \nstability. From the above\
    \ equation, the following expressions are deduced: \n \n|\U0001D436(\U0001D457\
    ⍵)\U0001D43A(\U0001D457⍵)\U0001D43B(\U0001D457⍵)||\U0001D452−\U0001D457\U0001D714\
    \U0001D447| = 1 \n(4.12) \n \n \n\U0001D43F(\U0001D436(\U0001D457⍵)\U0001D43A\
    (\U0001D457⍵)\U0001D43B(\U0001D457⍵))\U0001D43F(\U0001D452−\U0001D457\U0001D714\
    \U0001D447) = 180º  \n(4.13) \n \nAs \n = 1 for all \n, the magnitude of the system\
    \ is not affected by the delay. \nHowever, as L \nradians, it is clear that the\
    \ phase margin for a system \nwith a time delay decreases as the time delay increases,\
    \ leading to instability and \nthus constraining the bandwidth achievable in the\
    \ face of delays. \nOne way to deal with the pernicious effect of known or unknown\
    \ delays is \nto detune first-order gains. With a PID controller, this is performed\
    \ by reducing \nthe proportional gain (P) to levels where the system remains stable.\
    \ This \napproach has the disadvantage that the resulting response is slowed down\
    \ and, \ntherefore, the overall performance of the system is worsened. The servo\
    \ control \nmust ensure a compromise between performance and stability. The performance\
    \ \nis proportional to the value of the gain of the corrector; however, above\
    \ a certain \nvalue, the corrector tends to destabilize the system. \n \n5. Exploration\
    \ Case Study \n \nThe experimental exploration mission was carried out with the\
    \ objective of \ndetermining the viability of the previously described approaches\
    \ in detecting fan \nmussel specimens in an area of 250 m x 100 m in the Mar Menor\
    \ (with the \ncoordinates of Table 4.7). A cloud architecture approach (Figure\
    \ 4.34-a) and a \nhybrid approach, a combination of cloud architecture (main mission)\
    \ and edge \narchitecture (tracking mission) were adopted (Figure 4.34-b). The\
    \ aim of the \nhybrid approach was to take advantage of edge architecture’s lower\
    \ latency and \nfavourable cloud precision. The tests achieved in the previous\
    \ section lead us to \nconclude that the results of Azure custom vision are more\
    \ pertinent to our use \ncase application (in terms of latency and accuracy);\
    \ therefore, we decided to \nadopt both the cloud and edge Azure models for the\
    \ mission described below. \nTable 4.7. GPS coordinates of the area explored.\
    \ \n \n96 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nCorner \nLatitude\
    \ \nLongitude \nNorth east \n37.697635º −0.780121º \nNorth west 37.697635º −0.782876º\
    \ \nSouth west 37.696825º −0.782876º \nSouth east \n37.696825º −0.780121º \n \n\
    Our sailing operation started in a vessel equipped with a robotic arm that \n\
    placed the vehicle in the water. After defining the coordinates of the inspection\
    \ \narea, the mission was planned on IUNO software (Figure 4-31) according to\
    \ the \nweather forecast, the time available and the width of the vehicle’s search\
    \ path. \n \nFigure 4.31. Mission generated in IUNO and uploaded into AUV. \n\
    The AUV employed for the experiment was connected to the buoy as shown \nin Figure\
    \ 4-32. The control station on board the vessel was connected to the AUV \nby\
    \ 4G communications. The different systems were checked before the AUV was \n\
    placed in the water: control, lighting, thrusters, 4G communications, vision,\
    \ etc. \nAfter successfully validating the systems, the vehicle was launched,\
    \ and the \nmission was transferred from IUNO to the AUV. \nWe initiated the main\
    \ mission using the first approach (cloud architecture for \ndetection and tracking).\
    \ The AUV started to explore the area for possible \nspecimens. The average depth\
    \ of the inspection area was 5.02 m and the vehicle \nremained at an average height\
    \ of 2.01 m above the seabed. \nThe first of the six sweeps (Figure 4.31) was\
    \ completed without detecting any \npossible specimens. The first fan mussel was\
    \ detected with 63% accuracy in the \nsecond track, when the AUV switched to the\
    \ secondary mission mode to track it \n(object location in the frame and distance\
    \ calculation). However, this turned out \nto be quite impractical due to the\
    \ high latency of the cloud connection. A timeout \nexception occurred during\
    \ the tracking mission and the algorithm chose to ignore \nit and resume the main\
    \ mission. As described in Section 6, the detection fails if a \ndeadline is missed\
    \ due to transmission delays, which affects the dynamic \nstability of the control\
    \ system. The technical team therefore decided to abort the \n \n97 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nmission, return to the starting point\
    \ and launch the same mission in the “hybrid” \nmode. \n \n \nFigure 4.32. Deploying\
    \ the platform to initiate the mission. AUV submarine \nconnected to a buoy via\
    \ a DSL cable. \nThe hybrid mission mode was initiated, and the cloud connection\
    \ was used \nto process the photos sent during the main tracking mission. On the\
    \ second \nsweep, the cloud results in the gateway indicated the presence of a\
    \ specimen with \n64% probability. The vehicle switched to the tracking mode.\
    \ At this point, the \nAUV began manoeuvring to place the target in the centre\
    \ of the image, while the \ninference was switched to the edge model in the IoT\
    \ gateway instead of the cloud \nto reduce latency. The AUV was able to follow\
    \ the suspected specimen up to a \ndistance of 2.13 m. The accuracy of the analysed\
    \ image at this distance was 83.8%, \nusing the trained edge model. For greater\
    \ certainty, the inference was switched \nto the cloud for the last picture to\
    \ confirm the find. In this hybrid mode, the edge \nwas used to speed up tracking\
    \ and AUV response. At this point, the AUV ended \nthe secondary mission mode,\
    \ registered the find as positive, saved its coordinates \nand resumed the main\
    \ mission (Figure 4.33). \n \n \nFigure 4.33. Specimen detection and positioning\
    \ in IUNO. \n \n98 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nNo further\
    \ specimens were detected until the fourth sweep, when another \nwas detected\
    \ with 38% probability. Once again, the vehicle switched to tracking \nmode, centred\
    \ the target in the image and performed the approach manoeuvre \nas before. After\
    \ halting at 2.06 m from the target, the recognition algorithm \nindicated that\
    \ the target was a fan mussel with 59% probability. As the minimum \nconfirmation\
    \ requirement in terms of the probable detection threshold at this \nstage is\
    \ 80%, the target was ignored, and the main mission was resumed. Due to \nthe\
    \ real-time communications, the target was in fact found not to be a fan mussel\
    \ \nbut a dark-coloured rock. On the sixth sweep, the mission and inspection were\
    \ \ncompleted after detecting one target specimen and discarding another possible\
    \ \ndetection that turned out to be a rock. \n \n6. Performance \n \nCloud and\
    \ edge computing are considered adequate platforms to \nincorporate artificial\
    \ intelligence approaches. This paper primarily focuses on the \nissues related\
    \ to the real-time constraints of using an AI cloud in both \nenvironments. Our\
    \ AUV system is designed to collect and interpret underwater \nimages to track\
    \ the fan mussel population in real time by an automatic processing \nmethod.\
    \ This automated approach is based on DL image processing techniques, \nsuch as\
    \ CNN, to detect the position of a possible specimen in a captured photo. \nThe\
    \ IoT gateway algorithm establishes the connection between the AUV control \n\
    system and cloud image processing techniques. The results of our proposed \nsystem\
    \ are compared with cloud and edge image processing in terms of latency \nand\
    \ certainty. Therefore, we aim to compare the response time between the cloud\
    \ \nand edge inference. \nMicrosoft Azure cloud was first compared with IBM and\
    \ Google clouds, as \nshown in Figure 4.34 [227-229]. The second comparison evaluated\
    \ the same cloud \nservice with inference in the edge and comparing the same results\
    \ in the cloud. \n \n \n                                                     \
    \         (a)                                                                (b)\
    \ \n \n99 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nFigure 4.34.\
    \ Communication edge cloud. (a) Training and inference in the \ncloud; (b) training\
    \ in the cloud, inference in the edge. \nWe describe the various network connections\
    \ and the performance metrics \nfor the architectures given in Figure 4.34. We\
    \ first assessed the delay between the \ndifferent terminals in the cloud architecture\
    \ and then compared it to that of the \nedge computing architecture. We evaluated\
    \ the performance of each trained \nmodel in the cloud and in the edge. Below,\
    \ we compare the performance of each \narchitecture, using LattePanda as an IoT\
    \ gateway, with a 1.8-GHz Intel quad-core \nprocessor, 4 GB RAM and 64 GB on-board\
    \ flash memory. \n6.1. Delay Assessment in the Proposed Platforms \nFigures 4.35\
    \ and 4.36 exhibit the different data flows via the various \ncommunication networks\
    \ for the cases of cloud and edge computing. From data \nacquisition (sensors)\
    \ to actuators, the information flow goes through different \nnetworks: CAN and\
    \ Ethernet in the case of edge architecture, and the Internet \nand DSL for the\
    \ cloud architecture. This represents the difference in latency \nbetween the\
    \ two modes and highlights the critical points in each case. \nThe highest latency\
    \ expected in the case of edge computing is Tinference, and the Tcloud \nis the\
    \ one expected in the cloud. \n6.1.1. Cloud Architecture \nIn the adopted cloud\
    \ architecture, all the generated images are sent to the \ncloud services and\
    \ the inference is performed entirely in the cloud. This makes \nthe application\
    \ fully dependent on the cloud results in order to make the \nnecessary adjustments,\
    \ which are crucial in the case of intermittent connectivity. \nFigure 4.35 shows\
    \ the different delays in the use case process. \n \nFigure 4.35. Latency in the\
    \ proposed platform within the cloud architecture. \n \n100 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nThe response time in the system can be divided into delays,\
    \ as modelled in \nEquation (4.14): \n \n\U0001D447 = \U0001D447\U0001D45B\U0001D44E\
    \U0001D463 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    1 + \U0001D447\U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\
    \U0001D462\U0001D451 + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D461\
    2 + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.14) \n \n \nwhere: \n(1) Tnav is the navigation sensor time, \n(2) Tsb1\
    \ is the acquisition time of the sensor data in sbRIO, \n(3) Tgt1 is the processing\
    \ time of the first and second threads in the IoT gateway \npresented, \n(4) Tby1\
    \ is the transmission time from the AUV to the buoy, \n(5) Tcloud is the time\
    \ needed to send photos to the cloud and receive the response \nresults, \n(6)\
    \ Tby2 is the transmission time of cloud results to the AUV, \n(7) Tgt2 is the\
    \ processing time of the first, second, and third threads in the IoT \ngateway\
    \ presented, \n(8) Tsb2 is the IoT gateway data acquisition time in sbRIO, and\
    \ \n(9) Tact is the actuation time. \nWhen the AUV starts up the IP camera stream,\
    \ the Tsens value can be expressed \nin two ways depending on the data stream,\
    \ according to Equations (15) and (16): \n \n\U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 = {\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1  if  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\n\U0001D447\
    \U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E if \U0001D447\U0001D45B\
    \U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F1 < \U0001D447\U0001D450\U0001D44E\
    \U0001D45A\U0001D452\U0001D45F\U0001D44E  \n(4.15) \n \n\U0001D447 = \U0001D447\
    \U0001D460\U0001D452\U0001D45B\U0001D460 + \U0001D447\U0001D454\U0001D4611 + \U0001D447\
    \U0001D44F\U0001D4661 + \U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ + \U0001D447\U0001D44F\U0001D4662 + \U0001D447\U0001D454\U0001D4612 + \U0001D447\
    \U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461 \n(4.16) \n \n\
    \ \nTcloud is composed of three different delays: Trequest is the transmission\
    \ time of each \nphoto to the cloud, Tinference is the processing time of the\
    \ transmitted photo in the \ncloud service, and Tresponse is the time from the\
    \ cloud to the buoy. \n \n\U0001D447\U0001D450\U0001D459\U0001D45C\U0001D462\U0001D451\
    \ = \U0001D447\U0001D45F\U0001D452\U0001D45E\U0001D462\U0001D452\U0001D460\U0001D461\
    \ + \U0001D447\U0001D43C\U0001D45B\U0001D453\U0001D452\U0001D45F\U0001D452\U0001D45B\
    \U0001D450\U0001D452 + \U0001D447\U0001D45F\U0001D452\U0001D460\U0001D45D\U0001D45C\
    \U0001D45B\U0001D460\U0001D452 \n(4.17) \n \n6.1.2. Edge Architecture \nIn the\
    \ edge architecture, the data remains in the local machine and the images \nare\
    \ not sent to the cloud; however, the application needs a minimal connection \n\
    to the cloud to report usage, which is suitable for intermittent connectivity.\
    \ The \ncloud connection is almost negligible; instead of sending photos to the\
    \ cloud for \nprocessing, the model uploads to the local IoT gateway and performs\
    \ the \ntreatment. We therefore neglect the cloud connection in this architecture\
    \ and only \nconsider the connections in the AUV. \n \n101 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nFigure 4.36. Edge architecture latency in the proposed\
    \ platform. \nIn the edge model deployed in the IoT gateway, the overall response\
    \ time of \nthe edge architecture in the AUV over the Ethernet and CAN networks\
    \ is \nmodelled as: \n \n\U0001D447 = \U0001D447\U0001D460\U0001D452\U0001D45B\
    \U0001D460 + \U0001D447\U0001D460\U0001D44F1 + \U0001D447\U0001D454\U0001D461\
    \ + \U0001D447\U0001D460\U0001D44F2 + \U0001D447\U0001D44E\U0001D450\U0001D461\
    \ \n(4.18) \n \nWhere Tsens is expressed as: \n \n\U0001D447\U0001D460\U0001D452\
    \U0001D45B\U0001D460 = {     \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1   if.  \U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\
    \U0001D460\U0001D44F1 > \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\
    \U0001D44E\n\U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E\
    \    if.\U0001D447\U0001D45B\U0001D44E\U0001D463 + \U0001D447\U0001D460\U0001D44F\
    1 < \U0001D447\U0001D450\U0001D44E\U0001D45A\U0001D452\U0001D45F\U0001D44E  \n\
    (4.19) \n \nTgt in this case depends on Tthreads executing the 4 threads in the\
    \ IoT \ngateway and the custom model Tinference uploaded from the cloud. \n \n\
    \U0001D447\U0001D454\U0001D461 = \U0001D447\U0001D461ℎ\U0001D45F\U0001D452\U0001D44E\
    \U0001D451\U0001D460 + \U0001D447\U0001D456\U0001D45B\U0001D453\U0001D452\U0001D45F\
    \U0001D452\U0001D45B\U0001D450\U0001D452 \n(4.20) \n \n6.2. Metrics \nThe Azure\
    \ Custom Vision, Google cloud and Watson IBM services allow \nusers to load a\
    \ set of image data and define the bounding box of each desired \nobject in the\
    \ image. To train the model effectively, the images must be varied and \nas close\
    \ as possible to the data on which the predictions will be made. Camera \nangle,\
    \ blurring, background, lighting, size, low resolution and type are all \nimportant\
    \ variations of the image that affect the training process. \nOnce the training\
    \ was completed, we calculated the model’s performance \nusing new image datasets\
    \ (i.e., not included in the training dataset), shown in \nTable 8. Precision\
    \ indicates the fraction of identified classifications that are \n \n102 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \ncorrect, while recall indicates\
    \ the fraction of actual classifications that are \ncorrectly identified. IoU\
    \ (intersection over union) is a metric of how successfully \na model predicts\
    \ the objects’ locations and is gauged using the area of \noverlapping regions\
    \ of the predicted and ground truth bounding boxes, defined \nas: \n \n\U0001D43C\
    \U0001D45C\U0001D448 = \U0001D434\U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453\
    \ \U0001D442\U0001D463\U0001D452\U0001D45F\U0001D459\U0001D44E\U0001D45D\n\U0001D434\
    \U0001D45F\U0001D452\U0001D44E \U0001D45C\U0001D453 \U0001D448\U0001D45B\U0001D456\
    \U0001D45C\U0001D45B  \n \n  (4.21) \n \nUnlike IBM in Azure Custom Vision and\
    \ Google cloud, the AI model can be \nexported in different formats (TensorFlow,\
    \ Docker) specially adapted to edge \ndevices, as opposed to in the cloud. The\
    \ model trained for cloud use is different \nfrom that trained for the edge as\
    \ regards accuracy and response time. We used \nthe same photos to train and test\
    \ the trained models for both edge and cloud use \nin the trials. Figure 4.37\
    \ shows some differences in terms of the accuracy of new \nphotos not used in\
    \ the training phase. The five tests clearly show the limits of \neach example;\
    \ for instance, in test 3, the picture was blurred, and Google cloud \ncould not\
    \ detect the mussel, while Microsoft detected it with 83% accuracy and \nIBM only\
    \ 15% accuracy. In test 2, all three clouds detected an unknown red object \n\
    stuck in the sub-bottom as a mussel with different percentages, which shows the\
    \ \nlimitation of the models regarding colour changes. \n \n \nFigure 4.37. Cloud-based\
    \ custom models for detecting new specimens. \n \n103 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nIn order to evaluate the performance of the proposed\
    \ object detection \nmodels, in both the cloud and edge, we used the following\
    \ standard performance \nmetrics: \n \n\U0001D45D\U0001D45F\U0001D452\U0001D450\
    \U0001D456\U0001D460\U0001D456\U0001D45C\U0001D45B =\n\U0001D447\U0001D443\n\U0001D439\
    \U0001D443+\U0001D447\U0001D443 \n \n(4.22) \n \n\U0001D45F\U0001D452\U0001D450\
    \U0001D44E\U0001D459\U0001D459 =\n\U0001D447\U0001D443\n\U0001D439\U0001D441+\U0001D447\
    \U0001D443 \n \n(4.23) \nwhere precision indicates the fraction of identified\
    \ detections that were correct, \nand recall indicates the fraction of actual\
    \ detections that were correctly identified. \nFP (False Positive) represents\
    \ the number of negative samples judged to be \npositive, TP (True Positive) is\
    \ the number of positive samples judged to be \npositive, and FN (False Negative)\
    \ is the number of positive samples judged to be \nnegative. \nTable 4.8. Accuracy\
    \ measurement in different platforms. \n \nTP \nFP \nFN \nPrecision \nRecall \n\
    IoU \nIBM \n28 \n2 \n8 \n0.933333 \n0.777778 \n0.82506 \nGoogle \n22 \n3 \n13\
    \ \n0.916666 \n0.611111 \n0.83364 \nAzure cloud \n33 \n4 \n3 \n0.891892 \n0.916667\
    \ \n0.86601 \nAzure edge \n24 \n3 \n11 \n0.888889 \n0.666667 \n0.678634 \n \n\
    The accuracy measurement tests were performed on all three cloud \nplatforms.\
    \ We also adopted the Azure edge model as it shows a better IoU metric \nscore\
    \ than Google. The accuracy test was performed on more than thirty photos \nof\
    \ mussels detected by our AUV camera, using the same photos in the three \ndifferent\
    \ clouds. The results given in Table 8 clearly show the difference between \n\
    the AI cloud services. \n6.3. Latency Evaluation \nSince most of the cloud APIs\
    \ are based on the HTTP protocol, we performed \na total of 100 HTTP throughput\
    \ tests using SpeedTest between the web server \nand the IoT gateway installed\
    \ in the AUV. The tests were performed in the Mar \nMenor experimental area through\
    \ the 4G connection. The average results of the \ntests carried out in this experimental\
    \ area were as follows: round trip delay: 66ms; \ndownload: 16.6 Mbps; upload:\
    \ 19.3 Mbps. The average size of the image sent \nfrom the AUV to the cloud was\
    \ approximately 194 kb. \nThe local network which connects the vehicle, and the\
    \ buoy presents a low \nfixed latency. This was measured by a 100-automated-delay\
    \ measurement \ncampaign. The average latencies between the IoT gateway and the\
    \ different \n \n104 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    devices in the vehicle’s Ethernet network were as follows: sbRIO: 0.9ms; camera:\
    \ \n1.1ms; 4G router (buoy): 1.2 ms. \nThe latency results are summarized in Table\
    \ 4.9, where average, minimum \nand maximum response time values are calculated\
    \ for each endpoint \narchitecture. The experimental set-up was based on Azure\
    \ and IBM cloud \narchitectures, plus another edge architecture using a custom\
    \ model formed by \nAzure and processed by the IoT gateway. Although IBM Watson\
    \ and Azure \ncustom vision are available worldwide, the locations of the deployments\
    \ differ; \nWatson is deployed in the U.S. and South Korea [226], while Google\
    \ cloud and \nAzure are deployed in various locations around the world [227, 228].\
    \ In this case, \nthe Azure and Google cloud services are deployed in Western\
    \ Europe, while IBM \nis in Dallas, USA. All the samples in each architecture\
    \ were thoroughly verified \nin an experimental campaign with over 100 valid samples.\
    \ The experiments \ncarried out were based on Equations (4.14) and (4.16) and\
    \ Python software. The \nlatter was employed to measure the overall latency. \n\
    Table 4.9. Latency measurement in different platforms. \n \nTotal Response \n\
    \ time (ms) \nCloud response  \ntime (ms) \nIoT Computing  \ntime (ms) \nCapturing\
    \ and \nwriting time (ms) \n \nMin \nMax \nMean \nMin \nMax \nMean \nMin \nMax\
    \ \nMean \nMin \nMax \nMean \nIBM \n1407 \n4060 \n2064 \n1280 \n3896 \n1935 \n\
    0 \n0 \n0 \n93 \n192 \n129 \nGoogle \n1291 \n4384 \n1696 \n1160 \n4071 \n1520\
    \ \n0 \n0 \n0 \n92 \n196 \n130 \nAzure \n1298 \n4572 \n1703 \n1171 \n4435 \n1571\
    \ \n0 \n0 \n0 \n92 \n196 \n131 \nAzure \nedge \n623 \n687 \n634 \n0 \n0 \n0 \n\
    523 \n595 \n532 \n93 \n194 \n130 \n \nThe results reported in Table 9 show the\
    \ differences between the proposed \narchitectures in terms of latency. Despite\
    \ the fact that image processing in edge \ncomputing is performed on the IoT gateway,\
    \ the total response time is \nsignificantly lower than the latency obtained with\
    \ cloud computing. The faster \nrunning time of the custom AI detection model\
    \ ensures real-time tracking and \nnavigation adjustment. Edge average response\
    \ time is almost three times less \nthan that of the cloud. However, the edge\
    \ model is less accurate than the cloud \nmodel; in fact, the edge model loaded\
    \ from the cloud is optimized as far as \npossible to meet the requirements of\
    \ tiny device platforms. \n \n \n \n \n \n \n105 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \n \nIII. System 3. Autonomous Marine Robot Based on\
    \ AI \nRecognition for Permanent Surveillance in Marine \nProtected Areas \n \n\
    1. Introduction  \n  \nThere are unique areas in the marine environment that must\
    \ be protected due \nto their singular characteristics and high environmental\
    \ value. These habitats are \nparticularly sensitive to alteration or disturbance\
    \ by humans, changes in the \necosystem or changes in climate. One of the legal\
    \ tools for their protection is the \ndeclaration of the area as a Marine Protected\
    \ Area (MPA), which legally allows \nfor the establishment of a scenario of maximum\
    \ protection [229]. The main \npurpose of MPAs is to regenerate fishing resources,\
    \ preserve natural resources, \nconserve marine species and recover ecosystems.\
    \ \nA marine reserve is defined as a category of marine protected area with legal\
    \ \nprotection mainly against fishing or development. The main limits as a general\
    \ \nrule are professional fishing (with the exception of a few authorized boats)\
    \ and \ndiving (also with authorized exceptions), while recreational fishing,\
    \ underwater \nfishing and anchoring are totally prohibited. These activities\
    \ in marine reserves \nmust be monitored by the authorities to guarantee the care\
    \ of the ecosystem by \nlaw [230]. A marine reserve can be made up of a single\
    \ area or different non-\nadjacent areas and contains at least one integral reserve,\
    \ which is a natural space \nwith high ecological and biological value due to\
    \ a unique and delicate ecosystem \nsensitive to any alterations. \nThe restrictions\
    \ are even stricter in integral reserves: all activities are \nforbidden, with\
    \ the exception of authorized scientific activities and sailing at a \nlimited\
    \ speed. In Spain there are a total of eleven marine reserves [231], four are\
    \ \non islets, islands and reefs far from inhabited areas and ports, and the rest\
    \ are on \nthe coast or near inhabited areas. The surveillance of areas far from\
    \ the coast is a \nreal challenge: inspection vehicles must be autonomous and\
    \ must not be \ncompromised by the risk of going adrift. Long-distance communications\
    \ with the \nland-based station must be fluid and stable, especially if 4G or\
    \ 5G coverage is not \navailable, as in most marine areas far from the coast and\
    \ in the video surveillance \nscenario, image transmission requires a highly stable\
    \ bandwidth. All these \nrestrictions are a major challenge for the surveillance\
    \ of marine reserves on the \nhigh seas. \nSeveral measures have been adopted\
    \ for the monitoring and surveillance of \nmarine reserves. The materials and\
    \ human resources are available to carry out \n \n106 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \nroutine inspections or to set up devices to detect illegal\
    \ fishing. In general, all \nmarine reserves are equipped with vessels, georeferenced\
    \ cameras, night vision \nbinoculars, telescopes and ROVs, among others [231].\
    \ However, all these \nmeasures and means have the same disadvantage: the lack\
    \ of a permanent \npresence. Despite the measures adopted, it is not possible\
    \ to permanently \nmonitor the nature reserve with these means, and the identification\
    \ and arrest of \noffenders is practically incidental. This is why it is very\
    \ difficult to obtain records \nof those who have accessed protected areas and\
    \ to obtain real-time alerts to \nidentify those responsible in the event of damage\
    \ or alteration of the ecosystem. \nUnfortunately, even with the above-described\
    \ means and resources illegal \nactivities such as anchoring or poaching still\
    \ take place. \nProtecting remote marine areas with the currently available means\
    \ is not \nenough for their full protection, especially in integral reserves.\
    \ The challenges are \nquite demanding and even more so in permanent surveillance.\
    \ Autonomous \nSurface Vehicles (ASV) are ideal in this scenario for autonomous\
    \ navigation, but \nthere is also another issue. In order to monitor remote marine\
    \ reserves, the \ncapacity to detect and identify specific types of vessels is\
    \ required. Detection and \nidentification by humans is difficult to equal in\
    \ this scenario and only visual \nrecognition technologies based on artificial\
    \ intelligence (AI) and the Internet of \nThings (IoT) can offer a detection capacity\
    \ close to human capabilities. \nThere are also other issues, mainly water quality,\
    \ pollution and the effect on \nthe ecosystem. In a previous work we proposed\
    \ an autonomous system \nconsisting of an autonomous solar-powered marine robot\
    \ with specialized \nsensing systems [232], designed to carry out long-term observation\
    \ missions in \nshallow water, collecting georeferenced oceanic data to monitor\
    \ and analyse \nphysical-chemical water parameters. \nWe therefore consider permanent\
    \ surveillance and inspection of marine \nreserves to be vital. For this, we introduce\
    \ the concept of the \"watchdog\"; a \nwatchdog roams around an area (for example,\
    \ a fenced-in area around a house). \nAs soon as an intruder is detected, the\
    \ watchdog alerts the owner and deters the \nintruder from entering. If he enters\
    \ the premises, the guard dog chases him out. \nThis concept, applied to autonomous\
    \ navigation by means of ASV craft together \nwith the concepts of Industry 4.0\
    \ applied to marine environments, gives us a \npowerful proposal for the permanent\
    \ surveillance of marine reserves. \nThis paper proposes and evaluates an autonomous\
    \ marine vehicle based on \nartificial intelligence, designed to recognize and\
    \ classify vessels considered as \npotential risks according to their type and\
    \ activity. Its main goal is to track and \nfollow them in real time to obtain\
    \ information (identification and position, video \nrecording, etc) using automatic\
    \ image recognition. When a vessel classified by \nthe algorithms as a potential\
    \ risk inside an integral reserve is detected and \nremains in the same position\
    \ for a certain period, it could mean illegal activity. \nIn the experiment, the\
    \ proposed Autonomous Guard based on the ASV was \n \n107 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ntested in this scenario in order to recognize, follow\
    \ and identify vessels based on \nan autonomous navigation and AI image recognition.\
    \ \nThe series of requirements for this include the following factors: it cannot\
    \ \nalter the ecosystem, so its energy source must be totally renewable; its capacity\
    \ \nto detect and recognise target vessels must be precise and reliable, the ability\
    \ to \ndistinguish between different types, and most importantly, the detection\
    \ capacity \nshould not compromise the ASV’s autonomy. \nThere are radar-based\
    \ detection AUVs with fast and accurate detection \nsystems, but this is not enough\
    \ for precise recognition and identification [233]. In \n[234] SAR (Synthetic\
    \ Aperture Radar) images are used together with deep \nlearning (DL) algorithms\
    \ to detect and recognize ships by means of a powerful \nCPU and local graphics\
    \ cards and low computational time, but these have a high-\npower consumption,\
    \ which is incompatible with a stand-alone vehicle. Due to \nthe inevitable vibration\
    \ and constant movement of the autonomous vehicle it is \nadvisable to use single\
    \ board devices and CPUs. This type of solution is suitable \nfor fixed surveillance\
    \ stations, but not for autonomous vehicles, whose autonomy \nis compromised.\
    \ On the other hand, fixed stations are not applicable in this case \ndue to several\
    \ factors, such as limited monitoring range, low reaction capacity, \nexposure\
    \ to environmental conditions and marine environments (in case of \nbuoys), ecosystem\
    \ alteration (in case of installations on islets or reefs), among \nothers. In\
    \ [236] a unified energy management framework was used to enable a \nsustainable\
    \ edge computing paradigm powered by distributed renewable energy \nresources.\
    \ Edge computing technologies significantly simplify local computing \ncapacity\
    \ and increase energy efficiency, while maintaining low latency. AI-based \ntechnologies\
    \ such as edge and cloud computing have proven to be accurate in \nterms of recognition\
    \ results and data analysis [236-238]. In [239] hybrid use of \ncloud/edge technologies\
    \ is considered optimal, significantly reducing the \npercentage of local computing\
    \ by deriving most of the calculation to remote \n(cloud) servers and highly optimised\
    \ algorithms through suitable and specific \ntraining processes. \nAs the paper’s\
    \ main contribution and novelty, we propose a hybrid \nCloud/Edge technology,\
    \ optimised for high image recognition accuracy, \nminimum power consumption and\
    \ low latency, in order to increase vehicle \nautonomy and efficiency, increase\
    \ the likelihood of mission success and security \nduring autonomous surveillance\
    \ missions in marine reserves with MASS. High \npower consumption compromises\
    \ vehicle autonomy during image recognition \nand identification, and high latency\
    \ compromises the control and tracking \nalgorithms. To select the most appropriate\
    \ technology according to the scenario \nand circumstances, we propose the SAAO\
    \ (Smart Algorithm for Autonomy \nOptimization by selecting the proper AI technology\
    \ according to the current scenario). \nThis algorithm is optimized to select\
    \ the appropriate technology (cloud or edge \ncomputing) according to the situation\
    \ and circumstances. \n \n \n108 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n2. Proposed Platform for Surveillance in Marine Protected Areas \n \nThe BUSCAMOS-VIGIA\
    \ ASV was developed by DAyRA (División de \nAutomatización y Robótica Autónoma)\
    \ group at the UPCT. One of its achievements \nis described in [232], where we\
    \ gave the ASV the capability to make long-term \nmissions to acquire data from\
    \ multiparameter probes in the Mar Menor (Murcia, \nSpain) on factors to decide\
    \ the urgency in inspecting a specific area based on \nfuzzy logic. \n \n2.1.\
    \ The ASV–IoT Architecture Development \n \nA framework of this description together\
    \ with the hardware and software \narchitecture in the proposed system are shown\
    \ in Figure 4.38: \n \n \nFigure 4.38. BUSCAMOS-VIGIA framework. \nThe framework\
    \ represents the whole system as follows: it is structured into \ntwo main blocks:\
    \ the ASV block, Communication base station AP (Access Point) \nblock and Cloud/Internet\
    \ block. The first represents the logic or physical \nelements included in the\
    \ vehicle, and the second collects the elements in the \n \n109 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nremote station and cloud computing server.\
    \ Each main block is classified into \nlayers. The ASV block is divided into 4\
    \ layers: The Energy layer, \nSensors/Actuators layer, Navigation control layer,\
    \ and Edge layer. The energy \nlayer is formed of the elements that provide energy\
    \ and autonomy to the vehicle. \nAs can be seen, the batteries can be charged\
    \ in two ways: through photovoltaic \ntechnology (during navigation - so as to\
    \ extend the vehicle’s range - or in port) \nor through an AC source, when solar\
    \ power is not enough, or a quick charge is \nneeded when moored. The next layer\
    \ is the Sensors / Actuators layer, with the \ndifferent detection elements, which\
    \ provide information to the upper layers in \nthe framework (such as GPS, inertial\
    \ unit, LiDAR and cameras). Here also are the \nrudder and thrusters. The upper\
    \ layer is for Navigation and Control and consists \nof a NI cRIO controller (National\
    \ Instrument Compact Remote Input Output) \n9022 model and its peripheral elements\
    \ and modules. The elements in this layer \nare responsible for autonomous navigation\
    \ and use information from the sensors \nin the lower layer and the AI image recognition\
    \ response obtained from the IoT \nGateway in the upper layer. The cRIO controller\
    \ is formed of a main body, based \non a processor and FPGA, together with a reconfigurable\
    \ chassis, with a series of \nmodules necessary for several communication protocols\
    \ to command and \nacquire data from the lower layer, such as CAN-NMEA2000, I2C,\
    \ RS232 and \nRS485, according to the current hardware architecture. There are\
    \ also a serial of \ncode block and algorithms, described in Section 3.3. The\
    \ Upper or Edge layer is \nformed by the IoT Gateway where on-board AI takes place\
    \ by running the \nalgorithms in charge of the camera’s image processing and analysing\
    \ system. \nThe second main block, called “Cloud / Internet”, contains just one\
    \ layer in \nthe highest position of the framework, called the Cloud layer, containing\
    \ not only \nthe AI services, but also information and resources provided in real\
    \ time from \nauthorities and services, which are essential for planning or modifying\
    \ the ASV \nmission. Also found here is the IUNO (Interface for Unmanned drones)\
    \ software. \nThe IUNO software platform was also designed by the DAyRA group\
    \ of the \nPolytechnic University of Cartagena. The platform manages the integrated\
    \ \ncontrol of multiple unmanned marine vehicles with the aim of simplifying \n\
    maritime operations. The results obtained from each vehicle, regardless of its\
    \ \ncharacteristics, facilitate the success of the operation with a high degree\
    \ of \nautomation. This software has already been used in previous experiments\
    \ and \noperations, such as [223,239], and is the only point with human intervention.\
    \ \nActivities such as mission planning or remote supervision are commanded and\
    \ \nmanaged from here.  \nBetween the ASV and Cloud/Internet blocks we find the\
    \ Communications \nbase station AP block, containing the Radio link layer. This\
    \ provides high \nwideband, low latency and long-range WiFi communications between\
    \ the \nvehicle and the land. It is formed by two Ubiquiti ROCKET M2 2.4 GHz modules\
    \ \n(one on land and another in the vehicle) and its antennas, with Ubiquiti airMAX\
    \ \nconnection. Due to the characteristics of the communications scenario, the\
    \ land \n \n110 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nantenna is\
    \ the sector type and the on-board is omnidirectional. The land station \nis connected\
    \ to the Internet. This layer is especially crucial in areas where 4G-5G \ncover\
    \ is not available, as in most integral reserves. \nThere is an extra block in\
    \ both the ASV and Cloud/Internet main blocks called \nthe AI (Artificial Intelligence)\
    \ block. As explained in Section 4, it is formed of the \nAzure Cloud general\
    \ model, Azure cloud custom model and Azure Edge custom \nmodel for AI recognition\
    \ according to the smart algorithm criteria described in \nSection 4.4. \nThe\
    \ most relevant characteristics of the ASV used in the experiment \ndescribed\
    \ in this paper are as follows: the vehicle is 5 meters long. It has a robust\
    \ \nstructure that protects the devices from the weather, as well as a sunroof.\
    \ The \ninside of the vessel is subdivided into two sections by means of a bulkhead.\
    \ In \nthe stern are the elements related to power and propulsion: Block of 8\
    \ 100Ah \nbatteries configured in 2 parallel lines, providing 48V nominal power\
    \ and 14h \nautonomy. Two electric outboard motors, Torqeedo C4.0 Cruise model,\
    \ allow it \nto sail at a maximum speed of 6 knots. It has two racks, located\
    \ on the starboard \nand port sides. In the starboard rack are the IoT Gateway\
    \ (LattePanda single \nboard computer, with 1.8-GHz Intel quad-core processor,\
    \ 4 GB RAM and 64 GB \non-board flash memory) and the WiFi communications elements,\
    \ energy \nmanagement of different equipment, photovoltaic regulator and electrical\
    \ panel. \nThe main elements of the port rack are: the NI cRIO 9022 (National\
    \ Instruments \nCompact Remote Input Output) controller, the rudder controller\
    \ and the \nelectronic periphery. It is equipped with side-scan sonar, echo sounder,\
    \ GPS, \ninertial unit and radar. It also has 4 LiDAR-Lite 3 (Garmin) in both\
    \ bands, bow \nand stern, as safety elements for obstacle detection. It has a\
    \ solar roof formed by \n5 Enecom HF 130 panels that extend the autonomy of the\
    \ vessel according to the \nenvironmental conditions, connected to a photovoltaic\
    \ regulator and its battery \npack. The battery pack can also be charged by AC\
    \ chargers. In terms of vision, \nthe ASV is equipped with an AXIS P5534-E PTZ\
    \ camera (in the bow) with 18x \noptical and 12x digital zoom (total 216x), with\
    \ a resolution of 1280x720p, as well \nas three additional Ubiquiti Air Cam cameras\
    \ in the stern on both starboard and \nport. Its renewable energy source does\
    \ not leave a carbon footprint and it thus \nhas no environmental impact, which\
    \ makes it suitable for permanent navigation \nin marine reserves, particularly\
    \ in integral reserves. Figure 4.39 shows a picture \nof the BUSCAMOS-VIGIA vehicle.\
    \   \n \n \n111 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.39.\
    \ BUSCAMOS-VIGIA ASV. \n2.2 Implemented Vessel recognition and tracking algorithm\
    \ \nIn this section, we outline and itemize the development of the above-\nmentioned\
    \ IoT-ASV autonomous system, specifically the algorithm related with \noverall\
    \ mission management and its stages, vessel recognition system and the \nimplemented\
    \ tracking algorithm. It has five main blocks, namely, the IoT \ngateway, the\
    \ IP cameras, the ASV control system, the remote-control station and \nthe cloud/edge\
    \ AI image recognition source. \nThe overall mission is planned and triggered\
    \ by IUNO software in the cloud \nbase station by setting either the desired area\
    \ of inspection or the desired \nwaypoints. The navigation controller consists\
    \ of four navigation modes: Main \nMission Mode (MMM), where the vehicle navigates\
    \ by following preprogramed \ntracks, Dynamic Position Mode (DPM), where the vehicle\
    \ stays at specific GPS \ncoordinates while maintaining a fixed heading, Tracking\
    \ Mode (TM), where the \nASV follows a target (vessel) until specific conditions\
    \ are met, and finally, \nInspection Mode (IM), where once the target has been\
    \ reached, the vehicle stays \nat a fixed distance and heading from it, in order\
    \ to obtain and classify general \ninformation about it. Depending on the current\
    \ navigation mode, there will be a \nserial of priorities, targets and outputs,\
    \ as seen in Table 4.10: \nTable 4.10. Definition of mission stages. \n \nStage\
    \ 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \nMode (FBM) \nStage\
    \ 3 \nTracking Mode \n(TM) \nStage 4 \nInspection Mode (IM) \nPriority \nAccuracy\
    \ \n(recognition) \nLatency \nLatency \nBoth accuracy \n(recognition) and \nlatency.\
    \ \n \n112 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nTarget \nVessel\
    \ \nrecognition \nand \nclassification \nBounding box \nstudy (size and \npositions)\
    \ for a \ndetermined \nperiod. \nRemain in the \nsame position \nwith fixed \n\
    heading \n \nReach target \nvessel within \ndefined limits \nStay at a fixed distance\
    \ \nfrom target and \nheading it. \nObtain general and \nadditional information\
    \ \nabout target vessel. \nOutput \nIs the target \na risk \nvessel? (YES \n/\
    \ NO) \nIs the target \nvessel in the \nsame position?  \n(YES / NO) \nAlerts.\
    \ \nTarget has been \nreached inside \ndefined limits? \n(YES / NO). \nAlerts.\
    \ Save \ninformation. \nAlerts. Obtain \ninformation of target \nvessel. Video\
    \ \nstreaming. Save \ninformation. \n \nThe navigation mode will change according\
    \ to the scenario and the current \nstage of the general mission, as specified\
    \ in Algorithm 2 and Figure 4.38. The IoT \ngateway connects the navigation controller\
    \ and IP cameras with cloud services. \nDuring the entire mission, the IoT gateway\
    \ receives image data from the IP \ncameras and sensors (through the cRIO controller).\
    \ If a vessel is detected, the \nresults contain its classification (according\
    \ to the trained AI models), a bounding \nbox in the images (centre, relative\
    \ X-Y position, and size) and accuracy \n(percentage). Likewise, the IoT gateway\
    \ receives the image processing results \nfrom the AI recognition source for each\
    \ photo sent. The AI source (edge or cloud \ncomputing) to analyze images is determined\
    \ by the “Smart algorithm for autonomy \noptimization by selecting the proper\
    \ AI technology according to the current scenario” \n(SAAO) described in Section\
    \ 4.4. The AI source uses advanced learning \ntechniques to analyse the results\
    \ and sends them to the IoT gateway. The results \nobtained from the AI source\
    \ are used according to the specific target of each \nmission stage as described\
    \ in Table 10. This process is carried out throughout the \nmission. \nOnce the\
    \ mission starts (MMM), BUSCAMOS-VIGIA ASV follows the \ndefined mission whilst\
    \ analysing images until a vessel is detected. The AI source \nthen classifies\
    \ it according to the trained AI models to determine the risk level. \nThe mission\
    \ mode then moves to the next stage, the Fixed Buoy Mode (FBM).  \nIn FBM, if\
    \ the vessel has been detected with a camera other than the bow \ncamera, the\
    \ vehicle will initially change its heading (stern: +180°, starboard: +90°, \n\
    port: -90°) until the vessel is detected with the bow camera. IoT image processing\
    \ \nis used with the navigation controller to perform heading modifications to\
    \ keep \nthe detected vessel in the centre of the bow camera. Once the heading\
    \ points to \n \n113 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    the target vehicle, BUSCAMOS-VIGIA ASV will remain in that heading, \nregardless\
    \ of the detected vessel’s behaviour. The ASV can act as a fixed buoy or \nstay\
    \ in same position and heading. This mode is used to study the target’s \nbehaviour\
    \ by analysing the bounding box (size and position) of the processed \nimages\
    \ for a specific period to determine whether the target vessel is immobile \n\
    in the same position, which could mean a potential risk as it could be fishing\
    \ or \nanchored in a protected area. \nAt this point, the mission changes to Tracking\
    \ Mode (TM). The ASV starts \nnavigating and tracking the target by using the\
    \ bounding box’s analysed image \ncollection to fix and update the heading. The\
    \ IoT gateway links up with the main \ncontroller to modify the heading according\
    \ to the target’s position in the image, \nkeeping it in the centre of the bow\
    \ camera’s field of vision. It will continue in this \nmode until LiDAR detects\
    \ the target at a specific distance or if it leaves the \nprotected area. If the\
    \ TM is successful and the target is reached, several actions \ncan take place,\
    \ such us saving the vessel’s position or generating remote alerts. \nWhen the\
    \ target is reached, the last stage, Inspection Mode (IM) starts. The \nASV will\
    \ remain at a fixed distance from the target vehicle and heading as long \nas\
    \ possible. The objective of this stage is to obtain information about the target\
    \ \nand generate alerts in the remote base station. \nThis is described in Algorithm\
    \ 2, as well as in the flowchart in Figure 4.40. \n \n \n \nAlgorithm 2. Vessel\
    \ recognition and tracking algorithm. \nStart () \nStep 1:  \n    While (mission\
    \ has not started) {}    \n    {Starts Main Mission Mode (MMM)}      \nStep 2:\
    \ \n    If (mission has ended) \n        {End ()} \n    Else \n        {Navigate\
    \ follow defined mission} \n        {Select the right AI image recognition source\
    \ (AIsource) trough SAAO} \n        {Acquire frames from 4 cameras and send to\
    \ AIsource} \n        {Get the answer of every frame and add label with camera\
    \ position (bow, stern, \nstarboard, port) of detected vessel, called camera position\
    \ (CP)} \n        If ((accuracy of detected vessel > acceptable limits) AND (type\
    \ of vessel == \nclassified as potential \n        risk)) \n            {Go to\
    \ step 3} \n        Else \n            {Go to step 2} \nStep 3: \n{Starts Fixed\
    \ Buoy Mode (FBM)}      \n \n114 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n{Get the answer of every frame and add label with camera position (bow, stern,\
    \ \nstarboard, port) of detected vessel, called camera position (CP)} \n    Switch\
    \ (CP) \n        Case (CP == bow)  \n             If (accuracy < accuracy results\
    \ acceptable)  \n                {Discard detected vessel. No risk.}         \
    \                \n                {Go to step 2} \n            Else \n      \
    \          {Set new heading pointing detected vessel. Keep current position and\
    \ \nheading} \n                {Start study of target behaviour by analysing bounding\
    \ box of images for a \nspecific period} \n                 If (Detected vessel\
    \ is in the same position)  \n                    {Discard detected vessel. No\
    \ risk}                         \n                    {Go to step 2} \n      \
    \          Else \n                    {Target vessel in the same position. Risk\
    \ (anchoring, fishing)}                         \n                    {Go to step\
    \ 4} \n        Case (CP == stern) \n            {Vehicle turns +180º} \n     \
    \       {Go to step 3} \n        Case (CP == starboard) \n            {Vehicle\
    \ turns +90º} \n            {Go to step 3} \n        Case (CP == port) \n    \
    \        {Vehicle turns -90º} \n            {Go to step 3}    \n        Default:\
    \ \n            {Go to step 2}    \nStep 4: \n    {Start Tracking Mode (TM)} \n\
    \    {Navigate to track target vessel}      \n    {Acquire new frame from bow\
    \ camera and send to AIsource}  \n    {Calculate the bounding box center and vessel\
    \ position in order to fix heading \nwhile tracking} \n    If (LiDAR detects vessel\
    \ at 20m) \n        {Stop navigation. Target reached}  \n        {Go to step 5}\
    \ \n    Else If (vessel leaves integral reserve while tracking) \n        {Target\
    \ not reached}  \n        {Go to step 2} \n    Else  \n        {Go to step 4}\
    \ \nStep 5: \n    {Starts Inspection Mode (IM)} \n    {Acquire new frame from\
    \ bow camera and send to AIsource}  \n \n115 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n    {Calculate the bounding box centre and vessel position in order\
    \ to fix heading and \nkeep distance} \n    While (Target vessel is stopped) \n\
    \    {Record videos, save vessel’s position, obtain additional information, send\
    \ \ndata and alerts to cloud station} \n    If (Vessel starts moving) \n     \
    \   {Stage finished. Information collected} \n        {Go to Step 2} \nSecurity\
    \ Step:     \n    If (Energy == 25%) \n        {Return back to port area. Send\
    \ alert to cloud station} \n    If (Energy == 50%)  \n        {Send alert to cloud\
    \ station} \nEnd () \n \n \n \n \nFigure 4.40. Platform’s communications in the\
    \ tracking algorithm. \n2.3. ASV control \nAs shown in Figure 4.38, our marine\
    \ vehicle has a number of elements and \ndevices interconnected through different\
    \ networks. While the IoT gateway is in \ncharge of image recognition and communications\
    \ with the camera and the cloud, \nthe cRIO controller is the ASV’s main control\
    \ backbone. The National Instrument \ncRIO 9022 controller includes a real-time\
    \ processor and reprogrammable FPGA \nthrough its LabVIEW environment [240], as\
    \ well as a chassis that can be \nreconfigured according to the project architecture.\
    \ By default, it comprises two \nEthernet ports, USB port and serial connectivity.\
    \ For this architecture, the chassis \n \n116 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nhas been equipped with several modules that enable CAN-NMEA2000,\
    \ I2C, \nRS232 and RS485 communications. Its specifications are a 533-MHz CPU,\
    \ 256MB \nDRAM, 2GB storage, one Ethernet port and other features listed in [241].\
    \ A \nconsistent code for the cRIO controller was fully developed in the LabVIEW\
    \ \nenvironment for ASV management, control and command. \nThe software modules\
    \ in the cRIO’s vehicle control program comprise these \nmain operations, as shown\
    \ in Figure 4.38: \n \n• Commands management: It allows cRIO dispatch commands\
    \ from cloud \nstation, such as receive and launch main mission after definition\
    \ trough IUNO \nsoftware, stop it, or execute safety manoeuvres \n• Propulsion\
    \ and rudder control: Management of the different control loops for \nboth propulsion\
    \ and rudder, according to the obtained setpoint from Mission \nexecution control\
    \ module. \n• Incidents management: Security module that manages different actions\
    \ \ndepending on the incidents that may occur during the mission, such as loss\
    \ \nof communications or the impossibility of continuing the defined trajectories\
    \ \ndue to external conditions, such as strong winds or rough seas. \n• Mission\
    \ execution control: This module manages navigation to each of the \nprogrammed\
    \ waypoints, according to the running mission, by dispatching \nthe different\
    \ navigation commands for the heading and position control loops \nwith the information\
    \ received from sensors and IoT image analysis algorithm.  \n• Energy efficiency\
    \ manager: The vehicle contains some non-critical navigation \ndevices that can\
    \ be disconnected in the event of energy and autonomy being \ncompromised. This\
    \ module executes the disconnection if required. \n \n3. Smart algorithm for autonomy\
    \ optimization by selecting the \nproper AI technology according to the current\
    \ scenario (SAAO)  \n \nMaritime Autonomous Surface Ships (MASS) have to guarantee\
    \ a series of \nrequirements in order to fulfil their purpose, in particular,\
    \ autonomy and \nsecurity, while accuracy and latency in the image analysis are\
    \ vital in the \nsurveillance of marine reserves through AI-based visual recognition.\
    \  \nAs defined previously, the surveillance mission is divided into four stages\
    \ in \norder to optimize them according to the objectives and a series of priorities\
    \ to \nattend to each stage, as defined in Table 10. Optimizing the mission execution\
    \ \nmeans accomplishing it in the minimum time possible and with the highest \n\
    guarantee of success, or in other words, execute every stage of the mission in\
    \ the \nmost efficient manner possible. An efficient mission means making the\
    \ most of \nthe energy available, a limited and essential resource for autonomous\
    \ vehicles. \nThe restrictive objective is to save energy and guarantee the success\
    \ of the \n \n117 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \nmission and\
    \ its security by taking the appropriate decisions in real time, which \nis the\
    \ crucial task of the proposed AI hybrid cloud/edge SAAO algorithm. \nIn stages\
    \ where accuracy is a priority, optimizing mission execution means \nusing AI\
    \ to obtain the best recognition results, detecting vessels that are a \npotential\
    \ risk to the marine reserve with the maximum precision and success. On \nthe\
    \ other hand, once the potential target has been detected and identified, \noptimizing\
    \ the mission in stages in which latency is a priority means obtaining \naccurate\
    \ results as fast as possible as setpoint for the heading controller block.  \n\
    As a single board low-power CPU is used to extend ASV autonomy, SAAO \nis designed\
    \ to be efficient and executed in platforms where energy is a limitation. \nUsing\
    \ both cloud and edge computing technologies to analyze images at the \nsame time\
    \ will entail extra consumption and increased latency in the image \nanalysis,\
    \ especially in edge computing, where CPU resources are limited. Balance \nis\
    \ the key to efficient and successful decision-making. These decisions are related\
    \ \nto selecting the best AI source technology for the success of every stage,\
    \ all of \nwhich have a series of priorities for optimizing the mission execution,\
    \ as shown \nin Table 4.11: \nTable 4.11. AI source preferences according to mission\
    \ stage. \n \nStage 1 \nMain \nMission \nMode \n(MMM) \nStage 2 \nFixed Buoy \n\
    Mode (FBM) \nStage 3 \nTracking \nMode (TM) \nStage 4 \nInspection \nMode (IM)\
    \ \nPriority \nAccuracy \n(recognition) \nLatency \nLatency \nBoth accuracy \n\
    (recognition) \nand latency. \nPreference \nAzure Cloud \nCustom \nModel \nAzure\
    \ Edge \nCustom \nModel \nAzure Edge \nCustom \nModel \nAzure Cloud \nGeneral\
    \ Model \nAlternativ\ne \nAzure Edge \nCustom \nModel \nAzure Cloud \nCustom \n\
    Model \nAzure \nCloud \nCustom \nModel \nAzure Edge \nCustom Model \n \nIn normal\
    \ conditions latency is adequate in edge models and accuracy is \nsuitable in\
    \ cloud models. That is the reason why there is a logic preference in \nevery\
    \ stage according to the defined priority, provided that accuracy is good \nenough.\
    \ Knowing when and what to offload while maintaining real-time \napplication Quality\
    \ of Service (QoS) requirements are the challenges to \novercome. Depending on\
    \ the mission stage, accuracy and latency results, a \ntechnique of offloading\
    \ to edge computing device (IoT gateway) or remote cloud \nservices is performed\
    \ to complete its execution, as shown in Figure 4.41. \n \n118 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \nBasically, intelligent offloading can\
    \ be used as an optimization-based \napproach with constraints such as bandwidth,\
    \ network latency, accuracy \nrequirements or monetary cost. In this application,\
    \ latency and accuracy have \nbeen defined as critical throughout the process,\
    \ and that is why the output results \nof the AI source are linked as inputs to\
    \ the SAAO algorithm after analysing the \nimages.  \nThe decision to offload\
    \ or not depends on hardware capabilities, data size, \nthe deep neural network\
    \ (DNN) model to be used and network quality, among \nother factors. These factors\
    \ can be measured indirectly through latency and \naccuracy. Latency and accuracy\
    \ are the main elements to be considered in this \noptimization approach. Figure\
    \ 4.41 shows the SAAO diagram: \n \nFigure 4.41. SAAO diagram. \nThis diagram\
    \ describes how the SAAO works. The latency and accuracy \nobtained from the previous\
    \ analysis are analyzed according to the mission stage \nand the defined AI source\
    \ preference. In the stages where latency is the priority, \nthe accuracy result\
    \ is analyzed to check whether it is within acceptable limits. \nThis means that\
    \ they should at least be able to identify the target and obtain its \nrelative\
    \ coordinates in the analyzed image in order to obtain the bounding box \ncoordinates\
    \ and use them as a setpoint for the heading control loop. There is no \npoint\
    \ in using a fast AI source if the algorithm cannot detect the target in its \n\
    analysis. This is the critical line for accuracy. \nIn stages where accuracy is\
    \ the priority, latency is analyzed in order to select \nthe preferred or alternative\
    \ AI source. The latency results may vary significantly \ndepending on several\
    \ factors, such us the percentage of bandwidth used, \n \n119 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \ndistance from ship to base station, or weather conditions,\
    \ among others. With \nlatency not being the priority in these stages, it has\
    \ to be low enough to obtain an \nacceptably fast response, especially in the\
    \ last stage, where the general cloud \nmodel is used to obtain general information\
    \ about the target vessel. Latency is \nalso crucial to keep the target in the\
    \ centre of the vision field. \nLatency average is updated for edge and cloud\
    \ model with each new \nanalysis. This determines acceptable limits for latency\
    \ dynamically, considering \nparameters such as network quality and bandwidth\
    \ indirectly. \n \n \nFigure 4.42. Calculation of acceptable latency limits. Main\
    \ ASV camera point of \nview. \n= \U0001D443\U0001D45B − \U0001D443\U0001D45B\
    −1 \n(4.24) \n\U0001D447 = \U0001D447\U0001D45B − \U0001D447\U0001D45B−1 \n(4.25)\
    \ \n\U0001D445\U0001D446 = \U0001D437\U0001D435\U0001D436\U0001D436\n\U0001D447\
    \  \n(4.26) \n \nFigure 4.42 shows the difference of position between 2 consecutive\
    \ analysed \nimages. From each successfully analysed image, the bounding box of\
    \ the detected \nvessel, its relative coordinates in the image, as well as its\
    \ timestamp are obtained. \nBy knowing the distance between bounding box centres\
    \ (BBC) and the time \ndifference between analyses (T), the relative speed (RS)\
    \ at which the target moves \nin the image can be obtained. During the time lapse\
    \ between the analysis of 2 \nconsecutive images we can approximate the relative\
    \ speed of displacement of the \ntarget vessel and the ASV as a constant value,\
    \ due to the considerable inertia of \nvessels at sea. With this information,\
    \ it is calculated when the target BBC will \nleave the range of vision, and SAAO\
    \ can determine the selection of the preferred \nor alternative source of AI with\
    \ regard to latency. \n \n120 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nSeveral factors affect SAAO decisions, and they can be measured indirectly\
    \ \nthrough latency and accuracy. Low latency and high accuracy are always \n\
    desirable results, but every AI cloud or edge platform has its advantages and\
    \ \nhandicaps, and we cannot always achieve both simultaneously. Balance and \n\
    effective decision making are the keys to make a mission efficient and successful.\
    \ \n \n4. Experiments and Results  \n4.1. AI recognition and proposed algorithm\
    \ for autonomy optimization  \n \nFigure 4.43 shows an example of three different\
    \ cloud vision APIs analyzing \nthe same image, with different types of boats\
    \ in a port. All three cloud services \nmanaged to detect most of the boats in\
    \ the image. The bounding box location is \naccurate, although the cloud response\
    \ cannot exactly specify the type of each \nboat. Our objective is not only to\
    \ detect each boat in the image but also to group \nthem into more specific categories.\
    \ The general model offered by the cloud has \nits limits in this regard. \n \n\
    \ \nFigure 4.43. Comparison of three different clouds vision API detection of\
    \ boat in \nLos Nietos port (Murcia, Spain). \n4.1.1. Custom model training for\
    \ detection specific vessels \nThe advantage of the customized model is the possibility\
    \ of training it \naccording to the use case, in addition to detecting the location\
    \ of objects in the \nimage. Our model has been trained to identify different\
    \ types of vessels and their \nposition in an image. We created our own custom\
    \ object detection model to be \nimplemented in the proposed IoT gateway using\
    \ the Azure cloud service, as it \nsupports the edge computing technologies and\
    \ gives a better performance than \nthe other solutions [242]. More than 600 photos\
    \ of different types of vessels found \naround the inspection area in the experiment\
    \ have been used to train the custom \nmodel. The model has been trained to recognize\
    \ 7 different types of vessels \n(Figure 4.44). The position of each vessel in\
    \ the image was identified by drawing \na bounding box around the object and providing\
    \ the top and left pixel \ncoordinates of the box, along with the width and height\
    \ in pixels. \n \n \n121 \n \nSmart IoT Monitoring and Real-Time Control Based\
    \ On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nFigure 4.44. Types and number of vessels used to train the vision custom models.\
    \ \nAzure can retrain our model in different ways, by quick training or advanced\
    \ \ntraining by specifying the training computation time. The more time and pictures\
    \ \nused train the model in the platform, the better the results and performance\
    \ will \nbe.  \nFigure 4.45 shows the detection testing of new photos not used\
    \ in the training \nphase. The cloud trained model was able to differentiate between\
    \ different types \nof boats, as for instance a man fishing in a kayak. The model\
    \ detected the \nsituation perfectly by the training photos. \n \nFigure 4.45.\
    \ Performance of the cloud custom model object detection in discerning \ndifferent\
    \ boats types. \n4.1.2. Cloud and Edge custom models. \nIn the proposed architecture,\
    \ we put forward the LattePanda IoT gateway \nrunning under Windows 10 LTSB OS,\
    \ where the trained edge model has been \ndeployed by using Microsoft Azure. Azure\
    \ offers the possibility of choosing \nbetween different object detection custom\
    \ model domains, namely General, \nLogo, Products on shelves and General Compact.\
    \ The General domain is trained \nto be used only in the cloud (Cloud Custom Model),\
    \ while the General Compact \ndomain is trained to be used in Edge devices (Edge\
    \ Custom Model). The model \nperformance varies by the selected domain; models\
    \ generated by General \nCompact domains can be exported to run locally, so they\
    \ are lightweight models \n \n122 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nand optimized for the constraints of real-time object detection on edge devices,\
    \ \nalthough they are less accurate than the General domain. \nFigure 4.46 shows\
    \ the training performance of 600 photos using the 7-hour \ntraining budget. The\
    \ edge and cloud models were trained with the same number \nof photos and training\
    \ budget. The figure 4.46 shows the difference between the \ntwo models after\
    \ the training. \n \nFigure 4.46. Performance differences between the Edge and\
    \ the cloud custom \nmodels. \nAs the models generated by the compact domains\
    \ are optimized for the constraints \nof real-time classification on edge and\
    \ mobile devices, they are slightly less accurate than \na standard domain with\
    \ the same amount of training data. Figure 4.47 clearly shows the \ndifference\
    \ between the custom model for cloud and edge uses, i.e. between the edge-\ntrained\
    \ model and the cloud-trained model. As can be seen, the distance from the object\
    \ \nto the ships' cameras affects the model’s percentage of accuracy. For instance,\
    \ as shown \nin case 3 in the figure 4.47, the cloud model was able to recognize\
    \ the vessel in the \ndistance accurately, while the edge model was not. \n \n\
    123 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n \nFigure 4.47. Cloud\
    \ and edge custom models for detecting new vessels. \n \n4.2. Latency assessment\
    \ in edge and cloud custom models \nPerforming powerful DNNs (Deep Neural Networks)\
    \ with real-time execution \nrequirements on edge devices is still a challenge,\
    \ regardless of the hardware \nacceleration and compression techniques deployed.\
    \ Considering offloading the \nDNN computation from local devices to more powerful\
    \ entities such as the cloud \nis a common scenario. Today, the cloud offers an\
    \ edge model for deployment on \ntiny devices, however, cloud models are also\
    \ needed to provide satisfactory \nperformance. Another important factor to consider\
    \ is that the cloud is known to \nfacilitate storage, computational complexity\
    \ and the energy load on the edge and \non local devices. Nevertheless, the cloud\
    \ servers are topologically and spatially \ndistant from the local stations, which\
    \ causes significant communication latency. \nReal-time inference is absolutely\
    \ required for many applications. For instance, \nframes from an autonomous vehicle’s\
    \ camera must be processed rapidly to \nidentify and evade obstacles, or a voice-based\
    \ solution must have a rapid analysis \nand understanding of the user's input\
    \ to provide a feedback. However, \ntransferring data to the cloud for inference\
    \ or training may result in more queues \nand delays in transmission from the\
    \ network and cannot meet the stringent \nrequirements of low end-to-end latency\
    \ required for real-time interactive \napplications. For example, experiments\
    \ have revealed that offloading a camera \nframe to Amazon Web Services and performing\
    \ a computer vision task requires \nmore than 200ms of end-to-end data [243].\
    \ \nIn this use case, Azure Custom Vision's used service works in Western \nEurope.\
    \ The experiments were carried out in the IoT gateway mentioned above \nby using\
    \ Python programming language. The results of the latency are \nsummarized in\
    \ Table 4.12, including: average latency, standard deviation, and \nthe minimum\
    \ and maximum values calculated for each model. The time that the \ncloud model\
    \ needs to send the photos to the cloud for processing and get the \n \n124 \n\
    \ \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nresults back has been measured.\
    \ Given that the trained edge model is migrated \nas a TensorFlow lite program,\
    \ the photos are analyzed at the IoT gateway instead \nof being sent to the cloud.\
    \ The performance of the edge models varies with the \noperating platform; hence\
    \ the inference time may vary. All samples were \ncarefully and thoroughly checked\
    \ for the same data on the same day. The \nexperiment was repeated using the same\
    \ data for both cloud and edge models. \nEach experimental campaign had about\
    \ 300 different valid samples. \n \nTable 4.12. RTD test of 300 samples of the\
    \ Edge and Cloud model. \n \nMin \nlatency (s) \nMax \nlatency (s) \nAverage \
    \ \n(s) \nVariance  \n(s2) \nStandard \ndeviation \n(s) \nCloud \nModel \n0.805\
    \ \n5.298 \n1.412 \n0.872 \n0.934 \nEdge \nModel \n0.213 \n0.896 \n0.336 \n0.012\
    \ \n0.108 \n \nThe results reported in Table 12 show the latency differences between\
    \ edge \nand cloud models on the same machine. The average cloud model score is\
    \ higher \nthan the edge model by more than 1s. However, the variance of the edge\
    \ model \nis almost null compared to the cloud model, which is close to 900ms,\
    \ which \njustifies the edge model’s better stability in time than compared to\
    \ the cloud \nmodel. \nFigure 4.48 compares the experimental latency results of\
    \ both edge and cloud \nmodel. The edge model shows more stability and all values\
    \ do not exceed the 1s \nlatency. Cloud model can sometimes extend beyond 4s.\
    \ According to the cloud \nlatency results, they can be classified into two ranges.\
    \ The first extends for about \n1 and 2 seconds, while the second extends for\
    \ around 4 and 5 seconds. In \naddition, there is a band where no data has been\
    \ registered, between \napproximately 2.5 and 3.5 seconds. \n \n \n \n125 \n \n\
    Smart IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual\
    \ Recognition and Cloud/Edge \nComputing Services \nFigure 4.48. Latency of more\
    \ than 300 samples. \n \nThe cloud model’s apparent processing time instability\
    \ can be explained by \nthe internet connection volatility as the photos have\
    \ to be sent to the cloud model \non remote servers for processing, unlike the\
    \ edge model in which all photos are \nprocessed on board or at the local station.\
    \  \nThe cloud and edge models are different in terms of accuracy, even though\
    \ \nthey are trained on the same reference images. In contrast to latency, the\
    \ cloud \nmodel is more accurate, which eventually makes it challenging to choose\
    \ \nbetween both models. Real-time and high accuracy are both essential. However,\
    \ \nin an autonomous marine vehicle where computing power is limited and \nenvironmental\
    \ conditions are variable, low latency and high accuracy in every \nanalysis are\
    \ not guaranteed. The aim is to find an acceptable performance \ncompromise, considering\
    \ the evolution of the ongoing mission phases, as \ndescribed in detail in the\
    \ next section. \n4.3. Experimental test and results (SAAO Algorithm) \nIn order\
    \ to test the decision making of the SAAO algorithm, an experiment \nwas carried\
    \ out based on the analysis of a 1.5-hour video filmed in the Bay of \nCartagena.\
    \ The most interesting results were from a 2-minute sequence of a \nfishing boat,\
    \ whose results were analysed as described below. A 10-second \nextract of the\
    \ analysis is shown in this experiment. \nFor the experiment, this video was used\
    \ as the image source for the IoT \nGateway device, replacing the \"Cameras\"\
    \ block shown in Figure 438. The \ncaptures extracted by the IPM (Image processing\
    \ algorithm) were analysed in \nthree different scenarios. First, only an edge\
    \ computing analysis was carried out, \nrecording latency and accuracy results,\
    \ without the intervention of SAAO. The \nexperiment was then repeated with the\
    \ same images analysed using cloud \ncomputing. Finally, the SAAO algorithm was\
    \ tested in making decisions on the \nmost suitable AI source for the analysis\
    \ of the next image, based on the results \nobtained, and for each of the four\
    \ stages, as shown in Table 4.13 and Figure 4.49. \nTable 4.13. Experimental SAAO\
    \ results \nNº \nSampl\ne \nEdge \nCloud \nSAAO answer for next analysis \nLat\
    \ \n(s) \nAcc \n(%) \nLat \n(s) \nAcc \n(%) \nMM\nM \nFBM \nTM \nIM \n1 \n0.447\
    \ \nND \n1.412 \n16.7 \nCCM \nCCM \nCCM \nCGM \n2 \n0.418 \n64.3 \n1.814 \n68.7\
    \ \nCCM \nECM \nECM \nCGM \n3 \n0.324 \n19.5 \n2.816 \n50.5 \nECM \nECM \nECM\
    \ \nCGM \n4 \n0.356 \n47.9 \n1.313 \n65.8 \nCCM \nECM \nECM \nCGM \n5 \n0.403\
    \ \n23.1 \n4.211 \n33.8 \nECM \nECM \nECM \nECM \n6 \n0.392 \n36.8 \n1.284 \n\
    55.7 \nCCM \nECM \nECM \nECM \n \n126 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nND – Not detected \nCCM – Cloud custom model \nECM – Edge custom\
    \ model \nCGM – Cloud General Model \n \n \nFigure 4.49. Images analysed. Cloud/edge\
    \ results comparison \nAs can be seen in Figure 4.49, there is a difference between\
    \ the edge and cloud \nmodels when detecting the same image. Sometimes the difference\
    \ between the \ntwo percentages is not so significant, while in other cases there\
    \ is a notable \ndifference, especially when the boat is at a distance, which\
    \ sometimes \ncomplicates the detection by using the edge model as seen in the\
    \ example of \nPhoto 1, or the latency results were high, in cloud computing mostly.\
    \ These \nvalues condition the SAAO response, with different decision making in\
    \ each \nstage, according to the preferred or alternative AI source. Special attention\
    \ to \nImages 1 and 5, where the low accuracy in the edge model and the high latency\
    \ \nin the cloud model conditioned SAAO's decision for the alternative AI model.\
    \ In \nImage 6, the alternative AI model (according to Table 11) has also been\
    \ selected \nin IM (Stage 4), due to the risk of losing the bounding box’s centre\
    \ of the target \nin the range of vision. \n4.4 Experiment of BUSCAMOS-VIGIA with\
    \ SAAO \nAs mentioned in the Introduction, the complexity of autonomous \nsurveillance\
    \ varies significantly in different scenarios in the Spanish Network of \nMarine\
    \ Reserves. The Cabo de Palos and Islas Hormigas Marine Reserve [244] in \nthe\
    \ Region of Murcia (Figure 4.50) has medium complexity according to the \npreviously\
    \ defined criteria.  \n \n127 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \nThis reserve covers an area of 18.98 km2 and is a zone with high biodiversity\
    \ \nand prairies of oceanic posidonia and rocky coralligenous beds, as well as\
    \ \nremarkable marine dynamics. This is a natural underwater area that contains\
    \ an \nintegral reserve in the surroundings of Hormiga Island, El Bajo, El Mosquito\
    \ and \nthe islets of El Hormigón and La Losa. \nThis marine reserve is very near\
    \ the Mar Menor, the largest saltwater lagoon \nin Europe, which was selected\
    \ as the scenario for the case study as the water there \nis usually calm, and\
    \ winds are light (Figure 4.50). \n \n \nFigure 4.50. Scale experiment. Equivalence\
    \ of area and distance from integral reserve \n(Islas Hormigas) to base station\
    \ (right) and equivalent area in Mar Menor (left) \n \nThe test exploration mission\
    \ was carried out to survey a marine space with a \nsurface and distance to the\
    \ base station equivalent to the Cabo de Palos and Islas \nHormigas Marine Reserve.\
    \ The objective was to detect, track and identify \nsuspicious vessels within\
    \ the area to validate the proposed architecture and the \nSAAO algorithm. The\
    \ defined inspection area has a radius of 915 m, with a \nsurface area of 2.63\
    \ km2 and a centre at coordinates 37.689634° N and 0.787109° \nW. To avoid detecting\
    \ vessels outside the test area due to the vision field, the area \ncovered by\
    \ the main mission was reduced by a radius of 100m, as shown in \nFigure 4.52.\
    \ The mission was planned on the IUNO platform.  \nThe recognition system was\
    \ tested in port before the mission through the \nmain bow camera to ensure that\
    \ both Azure cloud and edge AI sources worked \nas expected (Figure 4.51). A fishing\
    \ boat, a recreational boat and a sailing boat \nwere detected by the edge model,\
    \ and an extra sailing boat by the cloud model, \nwith better accuracy in all\
    \ detections.  \n \n \n \n128 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nFigure 4.51: Edge (left) / cloud (right) trained model recognition tests.\
    \ \n \nThe ASV was remotely monitored and supervised from the fishing boat used\
    \ \nas the auxiliary vessel for safety reasons during the entire mission. The\
    \ auxiliary \nvessel was also used to verify the detection, recognition and tracking\
    \ capabilities \nimplemented, as explained below. The different systems (control,\
    \ lighting, \nthrusters, \ncommunications, \nvision, \netc \n(control, \nlighting,\
    \ \nthrusters, \ncommunications, vision, etc) were tested before the BUSCASMOS-VIGIA\
    \ \nmission. After successful validation, the mission was transferred from IUNO\
    \ to \nthe ASV and launched and the vehicle headed for the starting point. Surveillance\
    \ \nof the area began following the previously defined route (Figure 4.52). From\
    \ the \nfirst point of the mission to the fifth sweep in the Main Mission Mode\
    \ (MMM) no \nincidents or detections occurred.   \n \n \nFigure 4.52. Start of\
    \ mission (MMM) of surveillance of area equivalent to integral \nreserve. \n \n\
    \ \n129 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \nThe technical team\
    \ on board the fishing boat remained at a specific point in \nthe fifth sweep\
    \ to study the ASV’s behaviour. The fishing boat was detected by \nBUSCAMOS-VIGIA\
    \ (Figure 4.53-a) and classified as a possible risk. According to \nSAAO logs\
    \ during this stage all image analysis was performed by the cloud-\ntrained model\
    \ except for one case in which the edge-trained model was used due \nto high latency.\
    \ The target vessel’s behaviour was studied to determine if it was \nstationary,\
    \ according to the rules defined Stage 2, Fixed Buoy Mode (FBM). The \nregisters\
    \ showed that only the edge model was used. The bounding boxes of all \nthe analyzed\
    \ images were determined as the accuracy was high enough at this \nstage. After\
    \ the FBM stage, when the results determined that the target vessel \nwas stationary,\
    \ the Tracking Mode (TM) stage began. The technical team on \nboard the target\
    \ vessel then started the motors to verify the tracking capabilities \n(Figure\
    \ 4.53-b). \n \n \n \n                         (a)                           \
    \                                                (b) \nFigure 4.53. (a) Stopped\
    \ vessel detected. Start TM mode. (b) Tracking Mode (TM) test \nduring the experiment.\
    \  \n \nThe ASV successfully reached the target. As in FBM, only the edge model\
    \ \nwas used by the SAAO during all the TM. The vehicle stopped over 15m away\
    \ \nand changed to Inspection Mode (IM), the last mission stage. \nThe results\
    \ obtained from the Azure Cloud AI General Model on additional \ninformation about\
    \ the target vessel were as follows: the three people on board \nwere detected.\
    \ The automatically generated sentences “a group of people on a boat” \nand “a\
    \ group of people riding on the back of a boat in the water” by the cloud general\
    \ \nmodel were useful for obtaining details of the target vessel without the need\
    \ to \nview cameras in real time and without human intervention. At this stage,\
    \ the \nrecords show that the SAAO used both the cloud general model and the edge-\n\
    trained model. The cloud results were not fast enough to determine the target\
    \ \nvessel’s bounding box in some cases. Table 4.14 shows a summary of the SAAO\
    \ \nlogs during the experiment: \n \nTable 4.14. Summary of SAAO logs during the\
    \ experiment \n \n130 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    Stage \nEdge (custom model) \nCloud (custom and general \nmodel) \nSAAO answers\
    \  \nAv. \nLat \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetect\n-ions \nAv. \nLat\
    \ \n(s) \nAv.  \nAcc \n(%) \nNº \nuses \nDetections \nUse of the preferred \n\
    AI source (%) \nMMM \n0.22\n0 \n21 \n1 \n1 \n1.52\n1 \n34 \n2414 \n1 \n99.95 \n\
    FBM \n0.20\n5 \n31 \n58 \n58 \n- \n- \n0 \n- \n100.00 \nTM \n0.23\n1 \n39 \n436\
    \ \n436 \n- \n- \n0 \n- \n100.00 \nIM \n0.21\n8 \n57 \n29 \n27 \n1.58\n9 \n68\
    \ \n92 \n88 \n76.03 \n \nWhen the fishing boat left the area, BUSCAMOS-VIGIA ended\
    \ the IM stage \nand continued with the planned mission (in MMM) until the eighth\
    \ sweep was \ncompleted. The vessel was then commanded to return to port and no\
    \ further \nincidents were registered during the rest of the mission. \n \n \n\
    \ \nIV. An IoT Control System for Wind Power Generators \n \n1. Introduction \
    \  \n \nAs an important source of energy in different countries, renewable energy\
    \ is \nwidely used today, renewable electricity generation in 2018 was 6.1% higher\
    \ than \nin 2017, representing about 16% of global power generation, as reported\
    \ in \nIRENA (2017) [245]. This percentage is expected to double in the next 15\
    \ years \nand 65% of energy use could come from renewable resources by 2050. Wind\
    \ and \nsolar energy production in 2018 increased by 11% and 28%, respectively.\
    \ \nAltogether, these two sources of energy remain dominant in the growth of \n\
    renewable generation, accounting for 73% of growth since 2014 [245]. \nPresent\
    \ machines used for manufacturing already support digital or analog \nsensing\
    \ connected to a central control station to be monitored via a wired \nEthernet\
    \ system [246]. These systems, nevertheless, are not usually connected to \nthe\
    \ Internet [247]. This is the era that meets the important evolution of the \n\
    industry and the Internet. In order to be able to follow this important evolution\
    \ \nof wind energy, it is necessary to enforce the capacity of the Internet to\
    \ assess all \n \n131 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    data collected from the different industrial elements, sensors, actuators, motors,\
    \ \netc. \nA \nvariety \nof \nadvanced \ntechnologies \nsuch \nas \nintelligent\
    \ \nrobots, \ncommunication systems (e.g., 5G), and the Internet of Things (IoT)\
    \ are expected \nto enhance the fourth industrial revolution [248]. IoT connects\
    \ a number of \npeople, devices, processes, and data, enabling them to communicate\
    \ with each \nother seamlessly. IoT can therefore help improve different processes\
    \ to make \nthem more measurable and quantifiable by gathering and processing\
    \ large \namounts of data [249]. IoT can potentially improve the quality of life\
    \ in different \nareas. In the energy sector, IoT can be deployed to increase\
    \ energy efficiency, \nexpand the share of renewable energy, limit the environmental\
    \ impacts of energy \nuse [250], and to have a clear vision of the entire system,\
    \ in real-time, without the \nnecessity of physically being in the area of the\
    \ installation. This will consequently \nreduce waiting times and decrease unnecessary\
    \ costs.  \nThe idea of the IoT is to treat each object as a thing, the renewable\
    \ energy \nresource is considered an object and is assigned a unique IP address,\
    \ where all \ndata gathered by sensors and actuators can be measured, analyzed\
    \ and managed, \nthrough the cloud-based platforms. The communication protocols\
    \ of the IoT \nplatform allow the different devices to communicate and share their\
    \ data with \nthe controllers or decision centers. The IoT platforms offer the\
    \ flexibility to select \nthe type of communication technologies according to\
    \ the needs of the \napplication. Each of these communication technologies has\
    \ specific features and \ncan be carried out through wired and wireless networks,\
    \ including, but not \nlimited to, RS485, Wi-Fi, Bluetooth, ZigBee [251] and cellular\
    \ technology such as \nLTE-4G and 5G networks [252]. The IoT is considered one\
    \ of the complex \nsystems, and this complexity is due to the interactions in\
    \ the environment, an \ninterconnection of the IoT components and the number of\
    \ networks and \nprotocols that are involved. The IoT gateway is the component\
    \ that allows these \ndifferent networks to communicate [253]. \nThe data analysis\
    \ is performed for decision making about the functioning of \nthe application.\
    \ As needed, data analysis can be accomplished offline or in real \ntime. When\
    \ analyzing off-line, the stored data is first collected and then \nvisualized\
    \ on site using visualization tools installed in the IoT gateway or in a \nbase\
    \ station). However, In the case of real-time analysis, cloud or edge servers\
    \ \nare used to perform the visualization, e.g. stream analysis [254].  \nThe\
    \ rest of this chapter is organized as follows. We present a study of related\
    \ \nwork in the field of IoT solutions in the renewable energy sector. We then\
    \ \nintroduce the system model and the different protocols and applications used\
    \ to \nconnect the wind energy control system to the cloud. Following, we describe\
    \ the \nproposed hardware and software used to connect the system to the cloud.\
    \   \nFinally, the possibilities that can be done using the data transmitted offline\
    \ at the \nIoT gateway and in real time in the cloud. \n \n \n132 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n2. Modelling System Architecture \n \n\
    Within a wind energy system, a wind turbine converts wind energy into \nelectrical\
    \ energy. First it consists of a rotor, that transforms the aerodynamic \nthrust\
    \ into rotation movement, second a Multiplier, that adapts the rotation \nspeed\
    \ to the speed of the generator, then also an Alternator, that transforms the\
    \ \nrotation energy into electrical energy, and finally a Dump to the grid, that\
    \ injects \nenergy into the electrical network. \nThe wind energy system consists\
    \ of sensors, motors and actuators to be \nmonitored and controlled continuously.\
    \ The system must guarantee a safe and \nreliable operation, monitor the components\
    \ and variables, verify that the \nvariables are in an allowable range and must\
    \ perform fault detection and \nprediction. In a wind turbine, a yaw-guiding motor\
    \ turns the nacelle to face the \nwind, and the movement of the motor depends\
    \ on data from wind direction \nsensors. In fact, predictive analysis will alert\
    \ operators in advance if a component \nneeds to be repaired or inspected.  \n\
    New technologies such as IoT, machine learning, cloud, large data can \nfacilitate\
    \ better use of resources and help harness clean energy along with \noptimization.\
    \ IoT has an important impact on the energy sector, especially wind \nenergy,\
    \ given that this technology is applied to inaccessible environments and \nremote\
    \ areas. \nThe general architecture of an IoT system is composed mainly of three\
    \ parts, \nthe first one is the data generation and control system where it is\
    \ connected to \nthe devices and sensors, secondly it is the IoT gateway where\
    \ the main programs \nand protocols are installed to communicate the received\
    \ data, and finally, the \ncloud service, which reports all the data coming from\
    \ the wind energy system \nthrough the IoT gateway.  \n \n \n133 \n \nSmart IoT\
    \ Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n \nFigure 4.54 : Wind energy IoT communication\
    \ architecture \n \nIn this proposal we present two of the most important sensors\
    \ used in a wind \nenergy system, which are the wind energy direction sensor (Anemometer)\
    \ and \nthe wind speed sensor (Vane). Also proposed in this architecture, the\
    \ Siemens \ntechnology, using two types of PLCs: the PLC 1214 and the PLC 1512\
    \ and an \nindustrial gateway IoT2040 which is the first in the Siemens market\
    \ and can \nexecute different tasks, as handling the data received from the PLCs\
    \ before \nsending it to the cloud or to other machines and systems.  \n \n \n\
    Figure 4.55. Hardware Setup \n \n \n134 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe connected sensors are directly connected to the Siemens PLC 1214\
    \ to \nmonitor the wind status and send a command to the engine generator to change\
    \ \nthe direction of the blades in order to maximize the use of the system. \n\
    Furthermore, it permits the operation to be shut down in the event of a strong\
    \ \nwind flow. In parallel, power quality can be monitored and displayed using\
    \ the \nSENTRON PAC (3200), which delivers the important data for evaluating the\
    \ \nquality of an electrical network. All information received in the sensors\
    \ PLC 1214 \nis transmitted to the PLC 1512 using the industrial communication\
    \ standard \nPROFINET via Ethernet. \nThis solution allows to connect a legacy\
    \ network, presented by the old PLC \n1214 by using another powerful PLC 1512\
    \ with more capabilities to connect to \nanother network, which speaks more communication\
    \ protocols. The OPC \nUnified Architecture (UA) is an independent service-oriented\
    \ architecture that \nintegrates all the functionality of the individual OPC Classic\
    \ specifications into \nan extensible framework [255]. OPC UA is also a machine-to-machine\
    \ \ncommunication protocol, developed to create a reliable, secure, and interoperable\
    \ \ncommunication protocol. OPC-UA uses a client-server architecture, the servers\
    \ \nare applications that present information following the OPC-UA information\
    \ \nmodel, and the clients are applications that retrieve information from the\
    \ servers \nby reading and browsing the information model. In each server is defined\
    \ an \naddress space containing nodes of the OPC-UA model, these nodes represent\
    \ \nphysical objects or software [256]. the Siemens PLC 1512 comes with an OPC\
    \ UA \nserver implemented, which permits the communication with OPC UA clients\
    \ \nsuch as HMI panels, SCADA systems, etc. The OPC UA client is implemented in\
    \ \nthis application in the Siemens IOT2040 gateway, through the application Node-\n\
    RED that has a sample set of nodes that can be used for the communication \nbetween\
    \ different protocols and platforms. It is a programming tool for wiring \ntogether\
    \ hardware devices, APIs and online services, it is a solution to control \nflows\
    \ to be designed and managed graphically [257]. Figure 4.56 shows the setup \n\
    application and the different components from the wind sensors to the cloud \n\
    platform. \n \n \nFigure 4.56. Data flow between different systems and across\
    \ different protocols. \n \n \n \n135 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nThe OPC UA client implemented in the UAExpert software can \ncommunicates\
    \ with the OPC UA server in the Siemens PLC, its role is to check \nand read all\
    \ the information related to the communication with the PLC, so as to \nshow the\
    \ information model of the UA server, such as labels, blocks, etc (Figure \n4.57).\
    \ This application needs to control the two variables of the speed sensor and\
    \ \nthe orientation sensor. UaExpert can read the NodeID of each variable, which\
    \ is \nthe most important ID used in Node-RED in order to be connected to the\
    \ PLC \nOPC UA server. \n \n \nFigure 4.57 . Checking OPC UA connection using\
    \ UaExpert Software \n \nWe implemented mainly four different nodes for each sensor,\
    \ in order to read \nthe data information from the PLC 1512 and then forward it\
    \ to the cloud for \nvisualization (Figure 4.58). In the first blue node (Inject\
    \ Node) we have \nintroduced the topic, used to connect with the variable Orientation\
    \ in the PLC, \nthis topic is also called Node-ID that can be taken from the software\
    \ UaExpert. \nWe then connected the Inject Node to the OPC UA Client Node that\
    \ has the \naddress of the PLC server to which we want to connect, and finally\
    \ we linked the \nIBM Watson IoT Node that has all the information about our variables\
    \ created in \nour IBM Bluemix cloud account. \n \n \n136 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n \nFigure 4.58. Communication between the PLC 1512 and\
    \ IBM Cloud \nthrough OPC UA protocol using Node-RED installed the industrial\
    \ \nGateway IOT2040. \n \nC. Discussion and Results \n \n \nFigure 4.59. Dashboard\
    \ Data of wind Sensors in the IoT2040 Gateway \n \nAfter having all the information\
    \ about our sensors in the IoT2040 gateway \n(Figure 4.59), we have created an\
    \ account in IBM Bluemix, then we created a \ndevice in this account, which is\
    \ the IoT2040 gateway in order to connect it to the \nIBM Watson node in Node-RED.\
    \ IBM allows to create different boards, and for \neach board it is possible to\
    \ create cards that present your data and each data is a \nrepresentation for\
    \ your devices, sensors, actuators, or other. In the IBM Watson \nIoT Platform,\
    \ we created the board Wind-Energy, in order to present in a real-\ntime the two\
    \ wind sensors (Figure 4.60). \n \n \n137 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n \nFigure 4.60 : Dashboard data wind sensors in the IBM Watson Platform\
    \ \n \n \n \n \n138 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n \nCHAPTER\
    \ 5 \n \n-------------------------------------------------- \n \nConclusions and\
    \ Future Work \n \n \n \nThe lack of interoperability between Internet of Things\
    \ (IoT) devices \nsignificantly increases the complexity and cost of implementing\
    \ IoT and \nintegrating it into existing industrial systems and autonomous robots.\
    \ The quest \nfor seamless interoperability is further complicated by the long\
    \ lifespan of typical \nindustrial equipment, which requires costly upgrades or\
    \ replacements to support \nthe latest technologies. Integrating new and old technologies\
    \ into the IoT \npresents an interoperability challenge, as each IoT system has\
    \ its own \ncommunication protocol. In addition, a small error or delay beyond\
    \ the tolerated \nlimit could result in a disaster for various applications. IoT\
    \ gateways provide an \neffective solution for data communication, security and\
    \ manageability, and serve \nas a bridge between sensor networks and cloud services.\
    \ While the \nenvironmental specifications of each IoT gateway are crucial when\
    \ it comes to \napplications that require efficient computing performance. Cloud\
    \ services can \nhandle many cases efficiently, although latency is a major challenge\
    \ due to the \ninteraction between different systems. Unmanned vehicles (UVs)\
    \ now have great \npotential for many applications. At every stage of many surveillance\
    \ and tracking \nmissions using UVs, priority must be given to either accuracy\
    \ or latency. \nHowever, in some scenarios, stability of measurements and results\
    \ is difficult to \nensure, and certainty is far from guaranteed. Edge computing\
    \ topology reduces \nlatency to support IoT performance in low-bandwidth environments\
    \ and \nmitigates overall network congestion. Cloud computing topology improves\
    \ \naccuracy at the expense of increased latency. This proved crucial in deciding\
    \ the \nbest source of artificial intelligence to use to achieve the specified\
    \ goals at each \nstage in real time. \nAzure Custom Vision, Google cloud, and\
    \ IBM Watson services allow users \nto load a set of images and train them into\
    \ a custom AI model. However, to date, \n \n139 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \njust some of the cloud services allow trained AI models\
    \ to be exported in different \nformats (TensorFlow, Docker) specifically tailored\
    \ for devices, as opposed to the \ncloud. The model trained for use in the cloud\
    \ is different from the one trained for \nthe edge in terms of accuracy and response\
    \ time.  \nThe main contributions of this thesis are summarized in this chapter,\
    \ and the \neminent obtained results are discussed. Then, we emphasize the most\
    \ research \nlines that this thesis opens and can be considered as the future\
    \ works of the work \ndescribed in this report.  \n \n1. Contributions’ summary\
    \ \n \nThe main contributions of this thesis and the eminent results obtained\
    \ are \nsummarized. We highlight the most important research directions that this\
    \ thesis \nopens and that can be considered as future work of the work described\
    \ in this \nreport.  \nIn this thesis, different contributions are proposed to\
    \ address the issues of \nsupervision, interoperability, latency and detection\
    \ accuracy for object tracking.  \nThese contributions can be grouped into four\
    \ main axes. The first one, an \ninteroperable architecture and reliable real-time\
    \ communication have been \nproposed to improve the production process of a concrete\
    \ plant. In the second, \nan AUV model system designed to track a Mediterranean\
    \ fan mussel species, \nusing cloud services with edge computing as alternative\
    \ processing units. In the \nthird line, we propose an intelligent algorithm to\
    \ optimize the autonomy of an \nautonomous marine robot by selecting the appropriate\
    \ AI technology for \nprotection and continuous monitoring in marine protected\
    \ areas. Finally, In the \nfourth, the line focuses on proposing an IoT solution\
    \ to supervise in real time a \nwind system in the cloud. \nIn the first part\
    \ of this thesis, we have introduced a model designed to \nmonitor the smart industrial\
    \ Internet of things based on an unmanned aerial \nvehicle, leveraging cloud computing\
    \ services and using fog computing as a \nbridge between the different IIoT layers.\
    \  \n \n• The proposed model can monitor the condition of a concrete plant \n\
    production line and the condition of the materials transported on \nconveyor belts\
    \ to control the process.  \n• The results reveal the effectiveness of integrating\
    \ drones with deep \nlearning cloud services for processing and analyzing photos\
    \ acquired in \nreal-time.  \n• We demonstrate how to overcome the challenge of\
    \ interoperability using \nfog and Node-RED computation on the IoT gateway.  \n\
    • Node-RED interacts simultaneously with the different systems involved \nthrough\
    \ different protocols. \n \n140 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n• The period of time available to the control system to decide and adjust\
    \ the \nformula is assessed and estimated, depending on the quantity ordered by\
    \ \nthe customer and the composition of the formula. Given these points, the \n\
    overall latency of the proposed solution is acceptable for plant control \ndecisions.\
    \ \n• The Siemens IoT gateway S-G is expected to provide better performance \n\
    in an industrial setting, although it has less capacity than Raspberry \ngateway\
    \ RPI-G.  \n• The second work outlines an AUV model system designed to track a\
    \ \nMediterranean fan mussel species, using cloud services with edge \ncomputing\
    \ as alternative processing units. \n• An innovative algorithm was proposed to\
    \ autonomously track the target \nspecies without human intervention by integrating\
    \ the object detection \nsystem into the AUV control loop. \n• The proposed model\
    \ is capable of detecting, tracking and georeferencing \nspecimens with IUNO software.\
    \ \n• The obtained results highlight the system’s effectiveness and feature the\
    \ \nasset of combining an AUV with deep learning cloud services for \nprocessing\
    \ and analyzing photos.  \n• Although cloud-based architecture automatically distributes\
    \ and balances \nprocessing loads, we overcame latency challenges in the tracking\
    \ process \nby using edge computing in the IoT gateway.  \n• The IoT gateway installed\
    \ in the AUV replaces the cloud processing unit \nby virtue of the interaction\
    \ between the different AUV components. We \nintegrated cloud-based ML services\
    \ into the AUV system to achieve a \ncompletely autonomous pre-programmed search\
    \ mission with relevant \naccuracy.  \n• Furthermore, with the aim of ensuring\
    \ that data is transferred, processed \nand returned at speeds that meet the needs\
    \ of the application, the two \nobject detection services were implemented in\
    \ the cloud and compared in \nterms of latency and accuracy.  \n• The obtained\
    \ experimental results clearly justify the proposed hybrid \ncloud/edge architecture\
    \ and highlight the combination of the system \nperformances that ensure a real-time\
    \ control loop for relevant latency and \naccuracy. \n• Addressing system requirements,\
    \ lower latency and improved cloud \naccuracy, our solution on AUV servo control\
    \ ensures a balance between \nperformance and stability. The hybrid cloud/edge\
    \ architecture is therefore \nrecommended to ensure a real-time control loop and\
    \ achieve consistent \nresults.  \n \n \n141 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \nIn the third part, we have presented an autonomous marine robot for\
    \ \ncontinuous protection and surveillance of marine protected areas based on\
    \ AI \nrecognition.  \n \n• The robot was designed to survey and inspect marine\
    \ reserves using AI-\nbased image recognition services, looking for vessels conducting\
    \ \nsuspicious activities. \n• Azure cloud computing and Azure edge computing\
    \ services were used \nfor image analysis, each with their own advantages and\
    \ disadvantages, \nmainly related to accuracy and latency.  \n• To meet the system\
    \ requirements, we proposed and developed an \nintelligent algorithm to optimize\
    \ the autonomy by selecting the \nappropriate AI technology for the monitored\
    \ scenario.  \n• The proposed intelligent algorithm (SAAO) provides a trade-off\
    \ between \nlatency and accuracy. \n \nIn the fourth part of this thesis, we have\
    \ performed a control system using a \nsmart IoT gateway to create a connection\
    \ between an industrial case and the \ncloud.  \n \n• We have provided a solution\
    \ for a wind energy system in order to \nvisualize in a real-time and remotely\
    \ the different components and devices \ninside a wind turbine control system.\
    \  \n• We proposed, the IOT2040 gateway from Siemens, and we have installed, \n\
    several tools that helped us connect our device’s information.  \n• It is simple\
    \ to connect each sensor information of the wind turbine to the \ncloud by using\
    \ the tool Node-RED, and through different communication \nprotocols like OPC\
    \ UA. This solution can really ease the control system of \nwind energy, by collecting,\
    \ saving and communicating relevant data in \nreal-time.  \n• With the help of\
    \ an IoT gateway, analyzed data can be transferred from \nthe cloud to the control\
    \ system and to the devices. \n \n2. Future Works  \n \nThe research conducted\
    \ in this thesis can be extended in future work. Below \nwe present most of the\
    \ possible future contributions: \n \n• Introducing new devices into drones, so\
    \ that they can not only track \nobjects but also interact with them. \n• Introducing\
    \ swarm of drones connected as IOT-drone device and \ncoordinated to perform swarm\
    \ operations. \n \n142 \n \nSmart IoT Monitoring and Real-Time Control Based On\
    \ Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services \n\
    • New technologies can be implemented in drones to track and catch \ndetected\
    \ objects. \n• More research is needed in terms of accuracy when tracking a moving\
    \ \nobject. \n \n \n \n \n143 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n \nReferences \n \n \n \n1- \nG. Miragliotta, A. Perego, and A. Tumino, “Internet\
    \ of Things: Smart Present or Smart Future?” \nItaly, 2012.  \n2- \nStatista.\
    \ IoT: Number of Connected Devices Worldwide 2012–2025; Statista: Hamburg, Germany,\
    \ \n2019. \n3- \nH. Kagermann, W. Wahlster, and J. Helbig, “Recommendations for\
    \ implementing the strategic \ninitiative INDUSTRIE 4.0,” 2013. \n4- \n25. A.\
    \ Azevedo and A. Almeida, “Factory Templates for Digital Factories Framework,”\
    \ Robot. \nComput. Integr. Manuf., vol. 27, no. 4, pp. 755–771, Aug. 2011. \n\
    5- \n46. \nT. Hafeez, L. Xu and G. Mcardle, \"Edge Intelligence for Data Handling\
    \ and Predictive \nMaintenance \nin \nIIOT,\" \nin \nIEEE \nAccess, \nvol. \n\
    9, \npp. \n49355-49371, \n2021, \ndoi: \n10.1109/ACCESS.2021.3069137. \n6- \n\
    Molina-Molina, J.C.; Salhaoui, M.; Guerrero-González, A.; Arioua, M. Autonomous\
    \ Marine Robot \nBased on AI Recognition for Permanent Surveillance in Marine\
    \ Protected Areas. Sensors 2021, 21, \n2664. https://doi.org/10.3390/s21082664\
    \ \n7- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence:\
    \ Paving the Last Mile of \nArtificial Intelligence with Edge Computing. Proc.\
    \ IEEE 2019, 107.  \n8- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis,\
    \ M. A Comparative Taxonomy and Survey \nof Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2. \n9- \nY. Zhong, Xun Xu, Eberhard Klotz, Stephen\
    \ T. Newman. Intelligent Manufacturing in the Context \nof Industry 4.0: A Review.\
    \ Elservier, https://doi.org/10.1016/J.ENG.2017.05.015 \n10- \nK. \nKritayakirana\
    \ \nand \nJ. \nC. \nGerdes, “Autonomous \nvehicle \ncontrol \natthe \nlimits \n\
    of \nhandling,”International Journal of Vehicle AutonomousSystems, vol. 10, no.\
    \ 4, pp. 271–296, 2012. \n11- \nS. E.Collier, “The emerging enernet: Convergence\
    \ of the smart grid with the internet of things”, \nIEEE Industry Applications\
    \ Magazine, 23(2), 12-16, 2016. \n12- \nCarvalho O., Garcia M., Roloff E., Carreño\
    \ E.D., Navaux P.O.A. (2018) IoT Workload Distribution \nImpact Between Edge and\
    \ Cloud Computing in a Smart Grid Application. In: Mocskos E., \nNesmachnow S.\
    \ (eds) High Performance Computing. CARLA 2017. Communications in Computer \n\
    and Information Science, vol 796. Springer, Cham. https://doi.org/10.1007/978-3-319-73353-1_14\
    \ \n13- \nS. Marstijepovic and S. Williams, \"Environmental monitoring and field\
    \ surveillance reference \nguide.pdf\". \n14- \nXu, G.; Shi, Y.; Sun, X.; Shen,\
    \ W. Internet of Things in Marine Environment Monitoring: A Review. \nSensors\
    \ 2019, 19, 1711. https://doi.org/10.3390/s19071711 \n15- \nC. Perera, A. Zaslavsky,\
    \ P. Christen, & D. Georgakopoulos, “Sensing as a service model for smart \ncities\
    \ supported by internet of things”, Transactions on Emerging Telecommunications\
    \ \nTechnologies, 25(1), 81-93, 2014. \n16- \nAkhtar, M.N.; Shaikh, A.J.; Khan,\
    \ A.; Awais, H.; Bakar, E.A.; Othman, A.R. Smart Sensing with Edge \nComputing\
    \ in Precision Agriculture for Soil Assessment and Heavy Metal Monitoring: A Review.\
    \ \nAgriculture 2021, 11, 475. https://doi.org/10.3390/agriculture11060475 \n\
    17- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things for\
    \ smart home: Challenges and \nsolutions”, Journal of Cleaner Production, 140,\
    \ 1454-1464, 2017. \n18- \nR. Sfar, E. Natalizio, Y. Challal, &Z. Chtourou, “A\
    \ roadmap for security challenges in the Internet of \nThings”, Digital Communications\
    \ and Networks, 118-137, 2018. \n19- \nM. Soliman, T. Abiodun, T. Hamouda, J.\
    \ Zhou, & C. H. Lung, “Smart home: Integrating internet of \nthings with web services\
    \ and cloud computing”, In Cloud Computing Technology and Science \n(CloudCom),\
    \ 2013 IEEE 5th International Conference on (Vol. 2, pp. 317-320). 2013. \n \n\
    144 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n20- \nD. Miorandi,\
    \ S. Sicari, F. De Pellegrini, & I. Chlamtac, “Internet of things: Vision, applications\
    \ and \nresearch challenges”, Ad Hoc Networks, 10(7), 1497-1516, 2012. \n21- \n\
    F. Firouzi, A. M. Rahmani, K. Mankodiya, M. Badaroglu, G. V. Merrett, P. Wong,\
    \ & B. Farahani, \n“Internet-of-Things and big data for smarter healthcare: from\
    \ device to architecture, applications \nand analytics”, 2018. \n22- \nS. K.Dash,\
    \ J. P. Sahoo, S. Mohapatra, & S. P. Patil,“Sensor-cloud: assimilation of wireless\
    \ sensor \nnetwork and the cloud”, Advances in Computer Science and Information\
    \ Technology. Networks \nand Communications, 455-464, 2012. \n23- \nL. Atzori,\
    \ A. Iera, and G. Morabito, “The Internet of Things: A survey,” Comput. Netw.,\
    \ vol. 54, no. \n15, pp. 2787–2805, Oct. 2010. \n24- \nM. Kavre, A. Gadekar and\
    \ Y. Gadhade, \"Internet of Things (IoT): A Survey,\" 2019 IEEE Pune Section \n\
    International Conference (PuneCon), 2019, pp. 1-6, doi: 10.1109/PuneCon46936.2019.9105831.\
    \ \n25- \nEdge Computing Task Group.Introduction to Edge Computing in IIoT.Accessed:\
    \ Aug. 2, 2021. \n[Online]. \nAvailable: \nhttps://www.iiconsortium.org/pdf/Introduction_to_Edge_Computing_in_IIoT%_2018-06-18.pdf\
    \ \n26- \nLi, L. Lyu, X. Liu, X. Zhang, and X. Lyu, ‘‘FLEAM: A federated learn-ing\
    \ empowered architecture to \nmitigate \nDDoS \nin \nindustrial \nIoT,’’ \n2020,\
    \ \narXiv:2012.06150. \n[Online]. \nAvailable: \nhttp://arxiv.org/abs/2012.06150\
    \ \n27- \nDong, G. Qin, and H. Tian, ‘‘Enhancing data monitoring scheme based\
    \ on reinforcement learning \nin IIoT systems,’’ inProc. 12th Int. Conf.Commun.\
    \ Softw. Netw. (ICCSN), Jun. 2020, pp. 69–72. \n28- \nF. Wang, M. Zhang, X. Wang,\
    \ X. Ma, and J. Liu, ‘‘Deep learning for edgecomputing applications: A \nstate-of-the-art\
    \ survey,’’IEEE Access, vol. 8, pp. 58322–58336, 2020 \n29- \nChen, J. Wan, Y.\
    \ Lan, M. Imran, D. Li, and N. Guizani, ‘‘Improvingcognitive ability of edge intelligent\
    \ \nIIoT through machine learning,’’IEEE Netw., vol. 33, no. 5, pp. 61–67, Sep.\
    \ 2019. \n30- \nI. Yaqoob, E. Ahmed, I. A. T. Hashem, A. I. A. Ahmed, A. Gani,\
    \ M. Imran & M. Guizani, “Internet of \nthings architecture: Recent advances,\
    \ taxonomy, requirements, and open challenges”, IEEE \nwireless communications,\
    \ 24(3), 10-16, 2017. \n31- \nM. Diaz, C. Martín, & B. Rubio, “State-of-the-art,\
    \ challenges, and open issues in the integration of \nInternet of things and cloud\
    \ computing”, Journal of Network and Computer Applications, 67, 99-\n117, 2016.\
    \ \n32- \nL. R. Stojkoska, &K. V. Trivodaliev, “A review of Internet of Things\
    \ for smart home: Challenges and \nsolutions”, Journal of Cleaner Production,\
    \ 140, 1454-1464, 2017. \n33- \nLa, Quang Duy. Ngo, Mao V. Dinh, Thinh Quang.\
    \ Quek, Tony Q.S. Shin, Hyundong. Enabling \nintelligence in fog computing to\
    \ achieve energy and latency reduction. Digital Communications \nand Networks.\
    \ https://doi.org/10.1016/j.dcan.2018.10.008 \n34- \nDong, G. Qin, and H. Tian,\
    \ ‘‘Enhancing data monitoring scheme based on reinforcement learning \nin IIoT\
    \ systems,’’ in Proc. 12th Int. Conf.Commun. Softw. Netw. (ICCSN), Jun. 2020,\
    \ pp. 69–72. \n35- \nD. Xu and L. Duan, ‘‘Big data for cyber physical systems\
    \ in indus-try 4.0: A survey,’’Enterprise Inf. \nSyst., vol. 13, no. 2, pp. 148–169,\
    \ Feb. 2019. \n36- \nS. E.Collier, “The emerging enernet: Convergence of the smart\
    \ grid with the internet of things”, \nIEEE Industry Applications Magazine, 23(2),\
    \ 12-16, 2016. \n37- \nA. C. Panchal, V. M. Khadse and P. N. Mahalle, \"Security\
    \ Issues in IIoT: A Comprehensive Survey of \nAttacks on IIoT and Its Countermeasures,\"\
    \ 2018 IEEE Global Conference on Wireless Computing \nand Networking (GCWCN),\
    \ 2018, pp. 124-130, doi: 10.1109/GCWCN.2018.8668630. \n38- \nE. Sisinni, A. Saifullah,\
    \ S. Han, U. Jennehag, and M. Gidlund,“Industrial Internet of Things: \nChallenges,\
    \ opportunities, and direc-tions,”IEEE Trans. Ind. Informat., vol. 14, no. 11,\
    \ pp. 4724–\n4734,Nov. 2018. \n39- \nN. L. Tsilias, “Open Innovation and Interoperability,”\
    \ inOpening standards: The global politics of \ninteroperability,L. DeNardis,\
    \ Ed. Cambridge, MA, USA: MIT Press, 2011,pp. 97–117. \n40- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109. \n41- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of\
    \ combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6. \n42- \nG. Hatzivasilis, I. G.\
    \ Askoxylakis, G. Alexandris, D. Anicic,A. Br ̈oring, V. Kulkarni, K. Fysarakis,\
    \ and G. \nSpanoudakis,“The Interoperability of Things: Interoperable solutions\
    \ as an enabler for IoT and \nWeb 3.0,” in23rd IEEE International Workshop on\
    \ Computer Aided Modeling and Design of \nCommunication Links and Networks, CAMAD\
    \ 2018, Barcelona, Spain, September 2018, pp. 1–7. \n \n145 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n43- \nMonostori, L.; Kádár, B.; Bauernhansl, T.; Kondoh,\
    \ S.; Kumara, S.; Reinhart, G.; Sauer, O.; Schuh, G.; \nSihn, W.; Ueda, K. Cyber-physical\
    \ systems in manufacturing. CIRP Ann. 2016, 65, 621–641. \n44- \nX. Zuo, Y. Cui,\
    \ M. Wang, T. Xiao, and X. Wang, “Low-latencynetworking: Architecture, techniques,\
    \ \nand opportunities,”IEEE InternetComput., vol. 22, no. 5, pp. 56–63, 2018.\
    \ \n45- \nM. Bennis, M. Debbah, and H. V. Poor, “Ultrareliable and Low-latencyWireless\
    \ Communication: \nTail, risk, and scale,”Proceedings of theIEEE, vol. 106, no.\
    \ 10, pp. 1834–1853, 2018 \n46- \nKang, J. Hauswald, C. Gaoet al., “Neurosurgeon:\
    \ CollaborativeIntelligence Between the Cloud and \nMobile Edge,” inProc. 22nd\
    \ Int.Conf. Archit. Support Program. Lang. Oper. Syst. (ASPLOS \n2017),2017, pp.\
    \ 615–629. \n47- \nXiaofei Wang, Senior Member, IEEE, Yiwen Han, Student Member,\
    \ IEEE, Victor C.M. Leung, Fellow, \nIEEE, Dusit Niyato,Fellow, IEEE, Xueqiang\
    \ Yan, Xu Chen, Member, IEEE. Convergence of Edge \nComputing and Deep Learning:\
    \ A Comprehensive Survey. arXiv:1907.08349v3 [cs.NI]  28 Jan 2020 \n48- \nZ. Li,\
    \ J. Kang, R. Yu, D. Ye, Q. Deng, and Y. Zhang, “ConsortiumBlockchain for Secure\
    \ Energy trading \nin Industrial Internet of Things,”IEEE Trans. Ind. Informat.,\
    \ vol. 14, no. 8, pp. 3690–3700, 2017. \n49- \nAlsamhi, S. H., Ma, O., and Ansari,\
    \ M. S. (2019b). Survey on artificial intelligence-based techniques \nfor emerging\
    \ robotic communication. Telecommun. Syst. 72, 483–503. doi: 10.1007/s11235-019-\n\
    00561-z \n50- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for\
    \ overhead power line inspection using \nan unmanned aerial vehicle RELIFO project.\
    \ In Proceedings of the International Conference on \nUnmanned Aircraft Systems\
    \ (ICUAS), Atlanta, GA, USA, 28–31 May 2013; pp. 244–252. \n51- \nKim, H.; Lee,\
    \ J.; Ahn, E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using\
    \ a UAV \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.  \n52-\
    \ \nGeneration and Processing of Simulated Underwater Images for Infrastructure\
    \ Visual Inspection \nwith UUVs. Sensors 2019, 19, 5497.  \n53- \nBao, J.; Li,\
    \ D.; Qiao, X.; Rauschenbach, T. Integrated navigation for autonomous underwater\
    \ \nvehicles in aquaculture: A review. Inf. Process. Agric. 2020, 7, 139–151.\
    \  \n54- \nBarrett, N.; Seiler, J.; Anderson, T.; Williams, S.; Nichol, S.; Hill,\
    \ N. Autonomous Underwater Vehicle \n(AUV) for mapping marine biodiversity in\
    \ coastal and shelf waters: Implications for Marine \nManagement. In Proceedings\
    \ of the OCEANS’10 IEEE Conference, Sydney, Australia, 24−27 May \n2010. \n55-\
    \ \nWynn, R.B.; Huvenne, V.A.I.; le Bas, T.P.; Murton, B.; Connelly, D.P.; Bett,\
    \ B.J.; Ruhl, H.A.; Morris, K.J.; \nPeakall, J.; Parsons, D.R.; et al. Autonomous\
    \ Underwater Vehicles (AUVs): Their past, present and \nfuture contributions to\
    \ the advancement of marine geoscience. Mar. Geol. 2014.  \n56- \nCorgnati, L.;\
    \ Marini, S.; Mazzei, L.; Ottaviani, E.; Aliani, S.; Conversi, A.; Griffa, A.\
    \ Looking inside the \nOcean: Toward an Autonomous Imaging System for Monitoring\
    \ Gelatinous Zooplankton. Sensors \n2016, 16, 2124. \n57- \nLiu, S.; Xu, H.; Lin,\
    \ Y.; Gao, L. Visual Navigation for Recovering an AUV by Another AUV in Shallow\
    \ \nWater. Sensors 2019, 19, 1889.  \n58- \nJorge, V.A.M.; Granada, R.; Maidana,\
    \ R.G.; Jurak, D.A.; Heck, G.; Negreiros, A.P.F.; Dos Santos, D.H.; \nGonçalves,\
    \ L.M.G.; Amory, A.M. A Survey on Unmanned Surface Vehicles for Disaster Robotics:\
    \ \nMain Challenges and Directions. Sensors 2019, 19, 702. \n59- \nNuţă, I.; Orban,\
    \ O.; Grigore, L. Development and Improvement of Technology in Emergency \nResponse.\
    \ Procedia Econ. Financ. 2015, 32, 603–609. \n60- \nBellingham, J.G.; Rajan, K.\
    \ Robotics in Remote and Hostile Environments. Science 2007, 318, 1098–\n1102.\
    \ \n61- \nMarques, F.; Lourenço, A.; Mendonça, R.; Pinto, E.; Rodrigues, P.; Santana,\
    \ P.; Barata, J. A critical \nsurvey on marsupial robotic teams for environmental\
    \ monitoring of water bodies. In Proceedings \nof the OCEANS 2015, Genova, Italy,\
    \ 19–22 October 2015; pp. 1–6. \n62- \nColey, K. Unmanned Surface Vehicles: The\
    \ Future of Data-Collection. Ocean. Chall. 2015, 21, 14–\n15. \n63- \nMoysiadis,\
    \ V.; Sarigiannidis, P.; Moscholios, I. Towards Distributed Data Management in\
    \ Fog \nComputing. Wirel. Commun. Mob. Comput. 2018, 2018. [Google Scholar] [CrossRef]\
    \ \n64- \nG. Plastiras, M. Terzi, C. Kyrkou and T. Theocharidcs, \"Edge Intelligence:\
    \ Challenges and \nOpportunities of Near-Sensor Machine Learning Applications,\"\
    \ 2018 IEEE 29th International \nConference on Application-specific Systems, Architectures\
    \ and Processors (ASAP), 2018, pp. 1-7, \ndoi: 10.1109/ASAP.2018.8445118. \n \n\
    146 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous Robots,\
    \ Visual Recognition and Cloud/Edge \nComputing Services \n65- \n Miorandi, D.\
    \ ; Sicari, S.; De Pellegrini, F.; Chlamtac, I. Internet of Things. Ad Hoc Netw.2012,10,\
    \ \n1497–1516.  \n66- \nXu, L.D. Enterprise systems: State-of-the-art and future\
    \ trends. IEEE Trans. Ind. Informat.2011,7, \n630–640. \n67- \nLombardi, M.; Pascale,\
    \ F.; Santaniello, D. Internet of Things: A General Overview between \nArchitectures,\
    \ Protocols and Applications. Information 2021, 12, 87.  \n68- \nNgu, A.H.H.;\
    \ Gutierrez, M.; Metsis, V.; Nepal, S.; Sheng, M.Z. Iot middleware: A survey on\
    \ issues \nand enabling technologies. IEEE Internet Things J.2016,4, 1.  \n69-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316.  \n70- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141. \n71- \nNavet, N.; Simonot-Lion, F.; Delong, C. In-Vehicle Communication\
    \ Networks: A Historical \nPerspective and Review; Apple Academic Press: Palm\
    \ Bay, FL, USA, 2017; pp. 50–51. \n72- \n[33] Colakovi ́c, A.; Hadžiali ́c, M.\
    \ Internet of Things (IoT): A review of enabling technologies, \nchallenges, and\
    \ open research issues.Comput. Netw.2018,144, 17–39.  \n73- \nFerrari, P.; Flammini,\
    \ A.; Rinaldi, S.; Sisinni, E.; Malara, D.M.M. Impact of Quality of Service on\
    \ Cloud \nBased Industrial IoT Applications with OPC UA. Electronics 2018, 7,\
    \ 109.  \n74- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation\
    \ of combining OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things\
    \ system. In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS),\
    \ Geneva, Switzerland, 6–9 June 2017; pp. 1–6.  \n75- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Future Internet 2019, 11, 66. \n76- \nTrancă, D.-C.; Pălăcean, A.V.; Mihu, A.C.;\
    \ Rosner, D. ZigBee based wireless modbus aggregator for \nintelligent industrial\
    \ facilities. In Proceedings of the IEEE 25th Telecommunication Forum, \nBelgrade,\
    \ Serbia, 21–22 November 2017.  \n77- \nTariq, M.A.; Khan, M.; Raza Khan, M.T.;\
    \ Kim, D. Enhancements and Challenges in CoAP—A Survey. \nSensors 2020, 20, 6391.\
    \  \n78- \nKäbisch, S.; Peintner, D. W3C Recommendation Canonical EXI. 2018. Available\
    \ online: \nhttps://www.w3.org/TR/exi-c14n/ (accessed on 4 February 2019). \n\
    79- \nCavalieri, S.; Stefano, D.D.; Salafia, M.G.; Scroppo, M.S. A web-based platform\
    \ for OPC UA \nintegration in IIoT environment. In Proceedings of the 2017 22nd\
    \ IEEE International Conference \non Emerging Technologies and Factory Automation\
    \ (ETFA), Limassol, Cyprus, 12–15 September \n2017; pp. 1–6. \n80- \nCavalieri,\
    \ S.; Chiacchio, F. Analysis of OPC UA performances. Comput. Stand. Interfaces\
    \ 2013, 36, \n165–177.  \n81- \nGu, Xiaohui et al. “Energy-Optimal Latency-Constrained\
    \ Application Offloading in Mobile-Edge \nComputing.” Sensors (Basel, Switzerland)\
    \ vol. 20,11 3064. 28 May. 2020, doi:10.3390/s20113064 \n82- \nNetguru. Available\
    \ online: https://www.netguru.com/blog/why-is-python-good-for-research-\nbenefits-of-the-programming-language\
    \ (accessed on 3 May 2020). \n83- \nChen, S.; Xu, H.; Liu, D.; Hu, B.; Wang, H.\
    \ A Vision of IoT: Applications, Challenges, and \nOpportunities with China Perspective.\
    \ IEEE Internet Things J. 2014, 1.  \n84- \nSuárez-Albela, M.; Fernández-Caramés,\
    \ T.M.; Fraga-Lamas, P.; Castedo, L. A Practical Evaluation of \na High-Security\
    \ Energy-Efficient Gateway for IoT Fog Computing Applications. Sensors 2017, 17,\
    \ \n1978. [ \n85- \nFerrández-Pastor, F.J.; García-Chamizo, J.M.; Nieto-Hidalgo,\
    \ M.; Mora-Pascual, J.; Mora-Martínez, \nJ. Developing Ubiquitous Sensor Network\
    \ Platform Using Internet of Things: Application in \nPrecision Agriculture. Sensors\
    \ 2016, 1141.  \n86- \nGutiérrez, C.S.V.; Juan, L.U.S.; Ugarte, I.Z.; Vilches,\
    \ V.M. Time-Sensitive networking for \nrobotics. arXiv 2018, arXiv:1804.07643v2.\
    \  \n87- \nForsstrom, S.; Jennehag, U. A performance and cost evaluation of combining\
    \ OPC-UA and \nMicrosoft Azure IoT Hub into an industrial Internet-of-Things system.\
    \ In the Proceedings of the \n2017 Global Internet of Things Summit (GIoTS), Geneva,\
    \ Switzerland, 6–9 June 2017; pp. 1–6. \n88- \nOPC Foundation. Available online:\
    \ https://opcfoundation.org/about/opc-technologies/opc-\nua/ (accessed on 14 September\
    \ 2018). \n \n147 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n89- \nGirbea,\
    \ A.; Suciu, C.; Nechifor, S.; Sisak, F. Design and implementation of a service-oriented\
    \ \narchitecture for the optimization of industrial applications. IEEE Trans.\
    \ Ind. Inform. 2014, 10, 185–\n196. \n90- \nChen, B.; Wan, J.; Shu, L.; Li, P.;\
    \ Mukherjee, M.; Yin, B. Smart Factory of Industry 4.0: Key \nTechnologies, Application\
    \ Case, and Challenges. IEEE Access 2017, 6, 6505–6519 \n91- \nJaloudi, S. Communication\
    \ Protocols of an Industrial Internet of Things Environment: A \nComparative Study.\
    \ Futur. Internet 2019, 11, 66. \n92- \nRay, P.P. A Survey on Visual Programming\
    \ Languages in Internet of Things. Sci. \nProgram. 2017, 2017, 1231430.  \n93-\
    \ \nBröring, A.; Seeger, J.; Papoutsakis, M.; Fysarakis, K.; Caracalli, A. Networking-Aware\
    \ IoT Application \nDevelopment. Sensors 2020, 20, 897. https://doi.org/10.3390/s20030897\
    \ \n94- \nChris Simpkin, Ian Taylor, Daniel Harborne, Graham Bent, Alun Preece,\
    \ Raghu K. Ganti, Efficient \norchestration of Node-RED IoT workflows using a\
    \ Vector Symbolic Architecture, Future \nGeneration Computer Systems, Elsevier,\
    \ Volume 111, 2020, Pages 117-131, ISSN 0167-\n739X,https://doi.org/10.1016/j.future.2020.04.005.\
    \ \n95- \nYasumoto, K.; Yamaguchi, H.; Shigeno, H. Survey of Real-time Processing\
    \ Technologies of IoT \nData Streams. J. Inf. Process. 2016, 24, 195–202.  \n\
    96- \nFernández-Caramés, T.M.; Fraga-Lamas, P. A Review on Human-Centered IoT-Connected\
    \ Smart \nLabels for the Industry 4.0. IEEE Access 2017, 6, 25939–25957.  \n97-\
    \ \nWan, J.; Tang, S.; Yan, H.; Li, D.; Wang, S.; Vasilakos, A.V. Cloud Robotics:\
    \ Current Status and \nOpen Issues. IEEE Access 2016, 4, 2797–2807.  \n98- \n\
    Robla-Gömez, S.; Becerra, V.M.; Llata, J.R.; González-Sarabia, E.; Ferrero, C.T.;\
    \ Pérez-Oria, J. \n‘Working together: A review on safe human-robot collaboration\
    \ in industrial environments. IEEE \nAccess 2017, 5, 26754–26773.  \n99- \nKoch,\
    \ P.J.; van Amstel, M.; Dębska, P.; Thormann, M.A.; Tetzlaff, A.J.; Bøgh, S.;\
    \ Chrysostomou, D. A \nSkill-based Robot Co-worker for Industrial Maintenance\
    \ Tasks. In Proceedings of the 27th \nInternational Conference on Flexible Automation\
    \ and Intelligent Manufacturing (FAIM 2017), \nModena, Italy, 27–30 June 2017.\
    \  \n100- \nAndreasson, H.; Bouguerra, A.; Cirillo, M.; Dimitrov, D.N.; Driankov,\
    \ D.; Karlsson, L.; Lilienthal, A.J.; \nPecora, F.; Saarinen, J.P.; Sherikov,\
    \ A.; et al. Autonomous transport vehicles: Where we are and \nwhat is missing.\
    \ IEEE Robot. Autom. Mag. 2015, 22, 64–75.] \n101- \nAlsamhi, S.H.; Ma, O.; Ansari,\
    \ M.S.; Gupta, S.K. Collaboration of Drone and Internet of Public \nSafety Things\
    \ in Smart Cities: An Overview of QoS and Network Performance \nOptimization.\
    \ Drones 2019, 3, 13.  \n102- \nSoorki, M.N.; Mozaffari, M.; Saad, W.; Manshaei,\
    \ M.H.; Saidi, H. Resource Allocation for Machine-\nto-Machine Communications\
    \ with Unmanned Aerial Vehicles. In Proceedings of the 2016 IEEE \nGlobecom Workshops\
    \ (GC Wkshps), Washington, DC, USA, 4–8 December 2016; pp. 1–6.  \n103- \nLarrauri,\
    \ J.I.; Sorrosal, G.; Gonzalez, M. Automatic system for overhead power line inspection\
    \ using \nan unmanned aerial vehicle RELIFO project. In Proceedings of the International\
    \ Conference on \nUnmanned Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May\
    \ 2013; pp. 244–252.  \n104- \nKim, H.; Lee, J.; Ahn, E.; Cho, S.; Shin, M.; Sim,\
    \ S.-H. Concrete Crack Identification Using a UAV \nIncorporating Hybrid Image\
    \ Processing. Sensors 2017, 17, 2052. \n105- \nArroyo, J.A.; Gomez-Castaneda,\
    \ C.; Ruiz, E.; de Cote, E.M.; Gavi, F.; Sucar, L.E. UAV Technology and \nMachine\
    \ Learning Techniques applied to the Yield Improvement in Precision Agriculture.\
    \ In \nProceedings of the IEEE Mexican Humanitarian Technology Conference (MHTC),\
    \ Puebla, Mexico, \n29–31 March 2017.  \n106- \nSingh, A.; Patil, D.; Omkar, S.N.\
    \ Eye in the Sky: Real-time Drone Surveillance System (DSS) for \nViolent Individuals\
    \ Identification using ScatterNet Hybrid Deep Learning Network. In Proceedings\
    \ \nof the IEEE Computer Vision and Pattern Recognition (CVPR) Workshops, Salt\
    \ Lake City, UT, USA, \n18–22 June 2018.  \n107- \nManohar, A.; Sneha, D.; Sakhuja,\
    \ K.; Dwivedii, T.R.; Gururaj, C. Drone based image processing \nthrough feature\
    \ extraction. In Proceedings of the 2017 2nd IEEE International Conference on\
    \ \nRecent Trends in Electronics Information & Communication Technology (RTEICT),\
    \ Bangalore, \nIndia, 19–20 May 2017.  \n108- \nJunaid, A.B.; Konoiko, A.; Zweiri,\
    \ Y.; Sahinkaya, M.N.; Seneviratne, L. Autonomous Wireless Self-\nCharging forMulti-Rotor\
    \ Unmanned Aerial Vehicles. Energies 2017, 10, 803. \n \n148 \n \nSmart IoT Monitoring\
    \ and Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n109- \nLee, J.; Wang, J.; Crandall, D.; Sabanovic, S.;\
    \ Fox, G. Real-Time Object Detection for Unmanned \nAerial Vehicles based on Cloud-based\
    \ Convolutional Neural Networks. In Proceedings of the First \nIEEE International\
    \ Conference on Robotic Computing, Taichung, Taiwan, 10–12 April 2017. \n110-\
    \ \nSilva, E.; Martins, A.; Dias, A.; Matos, A.; Olivier, A.; Pinho, C.; Silva,\
    \ E.; de Sá, F.A.; Ferreira, H.; Silva, \nH.; et al. Strengthening marine and\
    \ maritime research and technology. In Proceedings of the \nOCEANS 2016 MTS/IEEE\
    \ Monterey, Monterey, CA, USA, 19–23 September 2016; pp. 1–9.  \n111- \nNicholson,\
    \ J.; Healey, A. The present state of autonomous underwater vehicle (AUV) applications\
    \ \nand technologies. Mar. Technol. Soc. J. 2008, 42, 44–51.  \n112- \nWeidner,\
    \ N.; Rahman, S.; Li, A.Q.; Rekleitis, I. Underwater cave mapping using stereo\
    \ vision. In \nProceedings of the IEEE International Conference on Robotics and\
    \ Automation, Singapore, 29 \nMay–3 June 2017; pp. 5709–5715.  \n113- \nRoser,\
    \ M.; Dunbabin, M.; Geiger, A. Simultaneous underwater visibility assessment,\
    \ enhancement \nand improved stereo. In Proceedings of the IEEE International\
    \ Conference on Robotics and \nAutomation, Hong Kong, China, 31 May–7 June 2014;\
    \ pp. 1–8.  \n114- \nLu, H.; Li, Y.; Xu, X.; He, L.; Dansereau, D.; Serikawa,\
    \ S. Underwater image descattering and quality \nassessment. In Proceedings of\
    \ the IEEE International Conference on Image Processing, Phoenix, \nAZ, USA, 25–28\
    \ September 2016; pp. 1998–2002.  \n115- \nLu, H.; Serikawa, S. Underwater scene\
    \ enhancement using weighted guided median filter. In \nProceedings of the IEEE\
    \ International Conference on Multimedia and Expo, Chengdu, China, 14–\n18 July\
    \ 2014; pp. 1–6. \n116- \nForesti, G.L.; Murino, V.; Regazzoni, C.S.; Trucco,\
    \ A. A Voting-Based Approach for Fast Object \nRecognition in Underwater Acoustic\
    \ Images. IEEE J. Ocean. Eng. 1997, 22, 57–65.  \n117- \nHansen, R.K.; Andersen,\
    \ P.A. 3D Acoustic Camera for Underwater Imaging. Acoust. \nImaging 1993, 20,\
    \ 723–727.  \n118- \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar\
    \ imagery using qualitative feature \nmatching. IEEE J. Ocean. Eng. 1994, 19,\
    \ 391–405. \n119- \nForesti, G.L.; Gentili, S. A Vison Based System for Object\
    \ Detection In Underwater Images. Int. J. \nPattern Recognit. Artif. Intell. 2000,\
    \ 14, 167–188. \n120- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching\
    \ via Deep Learning. In Proceedings \nof the 2017 European Conference on Mobile\
    \ Robots (ECMR), Paris, France, 6–8 September 2017.  \n121- \nVillon, S.; Mouillot,\
    \ D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger, S. A Deep\
    \ \nLearning method for accurate and fast identification of coral reef fishes\
    \ in underwater \nimages. Ecol. Inform. 2018.  \n122- \nQut University. Available\
    \ online: https://www.qut.edu.au/news?id=135108 (accessed on 3 May \n2020). \n\
    123- \nPiechaud, N.; Hunt, C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated\
    \ identification of \nbenthic epifauna with computer vision. Mar. Ecol. Prog.\
    \ Ser. 2019, 615, 15–30.  \n124- \nGelin, C. Introduction. In A High-Rate Virtual\
    \ Instrument of Marine Vehicle Motions for \nUnderwater Navigation and Ocean Remote\
    \ Sensing. Springer Series on Naval Architecture, Marine \nEngineering, Shipbuilding\
    \ and Shipping; Springer: Berlin/Heidelberg, Germany, 2013; Volume 1. \n125- \n\
    Heidarsson, H.K.; Sukhatme, G.S. Obstacle detection from overhead imagery using\
    \ self-supervised \nlearning for autonomous surface vehicles. In Proceedings of\
    \ the 2011 IEEE/RSJ International \nConference on Intelligent Robots and Systems,\
    \ San Francisco, CA, USA, 25–30 September 2011; \npp. 3160–3165. \n126- \nKristan,\
    \ M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast Image-Based Obstacle Detection from\
    \ Unmanned \nSurface Vehicles. IEEE Trans. Cybern. 2015, 46, 641–654 \n127- \n\
    Blanke, M.; Hansen, S.; Stets, J.D.; Koester, T.; Brøsted, J.E.; Llopart Maurin,\
    \ A.; Nykvist, N.; Bang, J. \nOutlook for navigation—comparing human performance\
    \ with a robotic solution. In Proceedings \nof the 1st International Conference\
    \ on Maritime Autonomous Surface Ships (ICMASS 2018), Busan, \nKorea, 8–9 November\
    \ 2018.  \n128- \nPrasad, D.K.; Prasath, C.K.; Rajan, D.; Rachmawati, L.; Rajabaly,\
    \ E.; Quek, C. Challenges in video-\nbased object detection in maritime scenario\
    \ using computer vision. arXiv 2016, arXiv:1608.0107. \nAvailable online: https://arxiv.org/abs/1608.01079\
    \ (accessed on 17 November 2020). \n129- \nWawrzyniak, N.; Hyla, T.; Popik, A.\
    \ Vessel Detection and Tracking Method Based on Video \nSurveillance. Sensors\
    \ 2019, 19, 5230.  \n130- \nCho, Y.; Park, J.; Kang, M.; Kim, J. Autonomous detection\
    \ and tracking of a surface ship using \nonboard monocular vision. In Proceedings\
    \ of the 2015 12th International Conference on \nUbiquitous Robots and Ambient\
    \ Intelligence (URAI), Goyang, Korea, 28–30 October 2015. \n \n149 \n \nSmart\
    \ IoT Monitoring and Real-Time Control Based On Autonomous Robots, Visual Recognition\
    \ and Cloud/Edge \nComputing Services \n131- \nIBM \nBoards \nthe \nMayflower\
    \ \nAutonomous \nShip \nProject. \nAvailable \nonline: https://newsroom.ibm.com/2019-10-16-IBM-Boards-the-Mayflower-Autonomous-Ship-\n\
    Project (accessed on 17 November 2020). \n132- \nGoogle and Rolls-Royce Partner\
    \ on Autonomous Ships. Available online: https://maritime-\nexecutive.com/article/google-and-rolls-royce-partner-on-autonomous-ships\
    \ (accessed on 17 \nNovember 2020). \n133- \nHansen, R.K.; Andersen, P.A. 3D Acoustic\
    \ Camera for Underwater Imaging. Acoust. \nImaging 1993, 20, 723–727.  \n134-\
    \ \nLane, D.M.; Stoner, J.P. Automatic interpretation of sonar imagery using qualitative\
    \ feature \nmatching. IEEE J. Ocean. Eng. 1994, 19, 391–405. \n135- \nForesti,\
    \ G.L.; Gentili, S. A Vison Based System for Object Detection In Underwater Images.\
    \ Int. J. \nPattern Recognit. Artif. Intell. 2000, 14, 167–188. \n136- \nVillon,\
    \ S.; Mouillot, D.; Chaumont, M.; Darling, E.S.; Subsolb, G.; Claverie, T.; Villéger,\
    \ S. A Deep \nLearning method for accurate and fast identification of coral reef\
    \ fishes in underwater \nimages. Ecol. Inform. 2018.  \n137- \nPiechaud, N.; Hunt,\
    \ C.; Culverhouse, P.F.; Foster, N.L.; Howell, K.L. Automated identification of\
    \ \nbenthic epifauna with computer vision. Mar. Ecol. Prog. Ser. 2019, 615, 15–30.\
    \  \n138- \nValdenegro-Toro, M. Improving Sonar Image Patch Matching via Deep\
    \ Learning. In Proceedings \nof the 2017 European Conference on Mobile Robots\
    \ (ECMR), Paris, France, 6–8 September 2017.  \n139- \nGelin, C. Introduction.\
    \ In A High-Rate Virtual Instrument of Marine Vehicle Motions for \nUnderwater\
    \ Navigation and Ocean Remote Sensing. Springer Series on Naval Architecture,\
    \ Marine \nEngineering, Shipbuilding and Shipping; Springer: Berlin/Heidelberg,\
    \ Germany, 2013; Volume 1. \n140- \nHeidarsson, H.K.; Sukhatme, G.S. Obstacle\
    \ detection from overhead imagery using self-supervised \nlearning for autonomous\
    \ surface vehicles. In Proceedings of the 2011 IEEE/RSJ International \nConference\
    \ on Intelligent Robots and Systems, San Francisco, CA, USA, 25–30 September 2011;\
    \ \npp. 3160–3165. \n141- \nKristan, M.; Kenk, V.S.; Kovacic, S.; Pers, J. Fast\
    \ Image-Based Obstacle Detection from Unmanned \nSurface Vehicles. IEEE Trans.\
    \ Cybern. 2015, 46, 641–654 \n142- \nGu, J.; Wang, Z.; Kuen, J.; Ma, L.; Shahroudy,\
    \ A.; Shuai, B.; Liu, T.; Wang, X.; Wang, G.; Cai, J.; et al. \nRecent advances\
    \ in convolutional neural networks. Pattern Recognit. 2018, 77 \n143- \n48. Krizhevsky,\
    \ A.; Sutskever, I.; Hinton, G.E. ImageNet classification with deep convolutional\
    \ neural \nnetworks. In Proceedings of the International Conference on Neural\
    \ Information Processing \nSystems, Lake Tahoe, NV, USA, 3–8 December 2012; pp.\
    \ 1097–1105. \n144- \n Deng, J.; Dong, W.; Socher, R.; Li, L.J.; Li, K.; Li, F.F.\
    \ ImageNet: A large-scale hierarchical image \ndatabase. In Proceedings of the\
    \ Computer Vision and Pattern Recognition, 2009 (CVPR 2009), \nMiami, FL, USA,\
    \ 20–25 June 2009; pp. 248–255.  \n145- \n50. Girshick, R. Fast R-CNN. In Proceedings\
    \ of the 2015 IEEE International Conference on Computer \nVision (ICCV), Santiago,\
    \ Chile, 7–13 December 2015.  \n146- \n Ren, S.; He, K.; Girshick, R.; Sun, J.\
    \ Faster R-CNN: Towards Real-Time Object Detection with Region \nProposal Networks.\
    \ IEEE Trans. Pattern Anal. Mach. Intell. 2017, 39, 1137–1149.  \n147- \n Lin,\
    \ T.; Goyal, P.; Girshick, R.; He, K.; Dollár, P. Focal Loss for Dense Object\
    \ Detection. In \nProceedings of the 2017 IEEE International Conference on Computer\
    \ Vision (ICCV), Honolulu, HI, \nUSA, 21–26 July 2017. \n148- \n53.  Liu, W.;\
    \ Anguelov, D.; Erhan, D.; Szegedy, C.; Reed, S.; Fu, C.Y.; Berg, A.C. SSD: Single\
    \ shot \nmultibox detector. In Proceedings of the European Conference on Computer\
    \ Vision, Amsterdam, \nThe Netherlands, 11–14 October 2016; pp. 21–37. \n149-\
    \ \n54. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only look once:\
    \ Unified, real-time object \ndetection. In Proceedings of the IEEE Conference\
    \ on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas, NV, USA,\
    \ 27–30 June 2016; pp. 779–788.  \n150- \nGhidoni, P.L.N.S.; Brahnam, S. Handcrafted\
    \ vs. non-handcrafted features for computer vision \nclassification. Pattern Recognit.\
    \ 2017, 71, 158–172. \n151- \nPathak, A.R.; Pandey, M.; Rautaray, S. Application\
    \ of Deep Learning for Object Detection. In \nProceedings of the International\
    \ Conference on Computational Intelligence and Data Science \n(ICCIDS 2018), Gurugram,\
    \ India, 7–8 April 2018. \n152- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li, X.\
    \ Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n153- \n58. Zhao, Z.; Zheng, P.; Xu, S.; Wu, X. Object\
    \ Detection with Deep Learning: A Review. IEEE Trans. \nNeural Netw. Learn. Syst.\
    \ 2019, 30, 3212–3232.  \n \n150 \n \nSmart IoT Monitoring and Real-Time Control\
    \ Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing Services\
    \ \n154- \nDahlkamp, H.; Kaehler, A.; Stavens, D.; Thrun, S.; Bradski, G.R. Self\
    \ supervised monocular road \ndetection in desert terrain. In Proceedings of the\
    \ Robotics: Science and Systems, Philadelphia, PA, \nUSA, 16–19 August 2006. \n\
    155- \n Chen, C.; Seff, A.; Kornhauser, A.; Xiao, J. Deep Driving: Learning affordance\
    \ for direct perception \nin autonomous driving. In Proceedings of the 2015 IEEE\
    \ International Conference on Computer \nVision (ICCV), Santiago, Chile, 7–13\
    \ December 2015; pp. 2722–2730.  \n156- \nChen, X.; Ma, H.; Wan, J.; Li, B.; Xia,\
    \ T. Multi-view 3D object detection network for autonomous \ndriving. In Proceedings\
    \ of the 2017 IEEE International Conference on Computer Vision (ICCV), \nHonolulu,\
    \ HI, USA, 21–26 July 2017; pp. 6526–6534. \n157- \nCoates, A.; Ng, A.Y. Multi-camera\
    \ object detection for robotics. In Proceedings of the 2010 IEEE \nInternational\
    \ Conference on Robotics and Automation, Anchorage, AK, USA, 3–7 May 2010; pp.\
    \ \n412–419. \n158- \nArmbrust, M.; Fox, A.; Griffith, R.; Joseph, A.D.; Katz,\
    \ R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, \nA.; Stoica, I.; et al.\
    \ A view of cloud computing. Commun. ACM 2010, 53, 50–58.  \n159- \n63. Kenitar,\
    \ S.B.; Arioua, M.; Younes, A.; Radi, M.; Salhaoui, M. Comparative Analysis of\
    \ Energy \nEfficiency and Latency of Fog and Cloud Architectures. In Proceedings\
    \ of the 2019 International \nConference on Sensing and Instrumentation in IoT\
    \ Era (ISSI), Lisbon, Portugal, 29–30 August 2019; \nIEEE: Piscataway, NJ, USA,\
    \ 2020.  \n160- \n64. Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. You only\
    \ look once: Unified, real-time object \ndetection. In Proceedings of the IEEE\
    \ Conference on Computer Vision and Pattern Recognition \n(CVPR 2016), Las Vegas,\
    \ NV, USA, 27–30 June 2016; pp. 779–788.  \n161- \nWang, X.; Victor, C.M.; Niyato,\
    \ D.; Yan, X.; Chen, X. Convergence of Edge Computing and Deep \nLearning: A Comprehensive\
    \ Survey. IEEE Commun. Surv. Tutor. 2020, 22, 869–904.  \n162- \nComputer Vision,\
    \ WikiPedia. Available online: https://en.wikipedia.org/wiki/Computer_vision \n\
    (accessed on 18 June 2020). \n163- \nFeng, X.; Jiang, Y.; Yang, X.; Du, M.; Li,\
    \ X. Computer Vision Algorithms and Hardware \nImplementations: A Survey. Integration\
    \ 2019, 69, 309–320.  \n164- \nKang, Y.; Hauswald, J.; Gao, C.; Rovinski, A.;\
    \ Mudge, T.; Mars, J.; Tang, L. Neurosurgeon: \nCollaborative Intelligence Between\
    \ the Cloud and Mobile Edge. In Proceedings of the 22nd \nInternational Conference\
    \ on Architectural Support for Programming Languages and Operating \nSystems (ASPLOS\
    \ 2017), Xi’an, China, 8–12 April 2017; pp. 615–629.  \n165- \nRussakovsky, O.;\
    \ Deng, J.; Su, H.; Krause, J.; Satheesh, S.; Ma, S.; Huang, Z.; Karpathy, A.;\
    \ Khosla, A.; \nBernstein, M.; et al. ImageNet Large Scale Visual Recognition\
    \ Challenge. Int. J. Comput. Vis. 2015, \n115, 211–252. \n166- \nZhou, Z.; Chen,\
    \ X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving the Last\
    \ Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019, 107.\
    \  \n167- \nSikeridis, D.; Papapanagiotou, I.; Rimal, B.P.; Devetsikiotis, M.\
    \ A Comparative  Taxonomy and \nSurvey of Public Cloud Infrastructure Vendors.\
    \ arXiv 2018, arXiv:1710.01476v2.  \n168- \nGoogle Cloud. Available online: https://cloud.google.com/vision/?hl=en\
    \ (accessed on 3 May \n2020). \n169- \nAzure. Available online: https://azure.microsoft.com/en-au/services/cognitive-services/computer-\n\
    vision/ (accessed on 3 May 2020). \n170- \nZhou, Z.; Chen, X.; Li, E.; Zeng, L.;\
    \ Luo, K.; Zhang, J. Edge Intelligence: Paving the Last Mile of \nArtificial Intelligence\
    \ with Edge Computing. Proc. IEEE 2019, 107. \n171- \nO’Mahony, N.; Campbell,\
    \ S.; Carvalho, A.; Harapanahalli, S.; Hernandez, G.V.; Krpalkova, L.; Riordan,\
    \ \nD.; Walsh, J. Deep Learning vs. Traditional Computer Vision. In Advances in\
    \ Computer Vision; Arai, \nK., Kapoor, S., Eds.; Springer: Cham, Switzerland,\
    \ 2020; Volume 943.  \n172- \nStefanini, M.; Lancellotti, R.; Baraldi, L.; Calderara,\
    \ S.A. Deep-learning-based approach to VM \nbehavior Identification in Cloud Systems.\
    \ In Proceedings of the 9th International Conference on \nCloud Computing and\
    \ Services Science, Crete, Greece, 2–4 May 2019; pp. 308–315. \n173- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55 \n174- \nKurose, J.F.; Ross, K.W. Computer Networking: A Top-Down\
    \ Approach, 6th ed.; Pearson: London, \nUK, 2012.  \n175- \nThangamuthu, S.; Concer,\
    \ N.; Cuijpers, P.J.L.; Lukkien, J.J. Analysis of ethernet-switch traffic shapers\
    \ \nfor in-vehicle networking applications. In Proceedings of the 2015 Design,\
    \ Automation Test in \nEurope Conference Exhibition (DATE), Grenoble, France,\
    \ 9–13 March 2015; pp. 55–60 \n \n151 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n176- \nCavalieri, S.; Chiacchio, F. Analysis of OPC UA performances.\
    \ Comput. Stand. Interfaces 2013, 36, \n165–177 \n177- \nGutiérrez, C.S.V.; Juan,\
    \ L.U.S.; Ugarte, I.Z.; Vilches, V.M. Time-Sensitive networking for \nrobotics.\
    \ arXiv 2018, arXiv:1804.07643v2.  \n178- \nIEEE standard for local and metropolitan\
    \ area networks—Bridges and bridged networks-\namendment 25: Enhancements for\
    \ scheduled traffic. In IEEE Std 802.1Qbv-2015 (Amendment to \nIEEE Std 802.1Q-2014\
    \ as amended by IEEE Std 802.1Qca-2015, IEEE Std 802.1Qcd-2015, and IEEE \nStd\
    \ 802.1Q-2014/ Cor 1-2015); IEEE: New York, NY, USA, 2016; pp. 1–57. \n179- \n\
    Bruckner, D.; Blair, R. OPC, UA, TSN: A New Solution for Industrial Communication.\
    \ 2018. Available \nonline: https://www.automationworld.com/sites/default/files/opc_ua_tsn_whitepaper_1.pdf\
    \ (acce\nssed on 13 May 2019). \n180- \nTatum, M.C.; Liu, J. Unmanned Aerial Vehicles\
    \ in the Construction Industry. In Proceedings of the \nUnmanned Aircraft System\
    \ Applications in Construction, Creative Construction Conference, \nPrimosten,\
    \ Croatia, 19–22 June 2017. \n181- \nSisinni, E.; Saifullah, A.; Han, S.; Jennehag,\
    \ U.; Gidlund, M. Industrial Internet of Things: Challenges, \nOpportunities,\
    \ and Directions. IEEE Trans. Ind. Inform. 2018, 14, 4724–4734.   \n182- \nAazam,\
    \ M.; Zeadally, S.; Harras, K.A. Deploying Fog Computing in Industrial Internet\
    \ of Things and \nIndustry 4.0. IEEE Trans. Ind. Inform. 2018.   \n183- \nSvorobej,\
    \ S.; Endo, P.T.; Bendechache, M.; Filelis-Papadopoulos, C.; Giannoutakis, K.M.;\
    \ Gravvanis, \nG.A.; Tzovaras, D.; Byrne, J.; Lynn, T. Simulating Fog and Edge\
    \ Computing Scenarios: An Overview \nand Research Challenges. Future Internet\
    \ 2019, 11, 55.  . \n184- \nLarrauri, J.I.; Sorrosal, G.; Gonzalez, M. Automatic\
    \ system for overhead power line inspection using \nan unmanned aerial vehicle\
    \ RELIFO project. In Proceedings of the International Conference on \nUnmanned\
    \ Aircraft Systems (ICUAS), Atlanta, GA, USA, 28–31 May [32] 2013; pp. 244–252.\
    \   32. \nIndustrial \nSkyworks. \nDrone \nInspections \nServices. \nAvailable\
    \ \nonline: \nhttps://industrialskyworks.com/droneinspections-services (accessed\
    \ on 21 April 2019). \n185- \nSoria, P.R.; Bevec, R.; Arrue, B.C.; Ude, A.; Ollero,\
    \ A. Extracting Objects for Aerial Manipulation on \nUAVs Using Low Cost Stereo\
    \ Sensors. Sensors 2016, 16, 700.      \n186- \nLagkas, T.; Argyriou, V.; Bibi,\
    \ S.; Sarigiannidis, P. UAV IoT Framework Views and Challenges: \nTowards Protecting\
    \ Drones as “Things”. Sensors 2018, 18, 4015.     \n187- \nKim, H.; Lee, J.; Ahn,\
    \ E.; Cho, S.; Shin, M.; Sim, S.-H. Concrete Crack Identification Using a UAV\
    \ \nIncorporating Hybrid Image Processing. Sensors 2017, 17, 2052.   \n188- \n\
    Sara Mahmoud, Nader Mohamed, Jameela Al-Jaroodi, Integrating UAVs into the Cloud\
    \ Using the \nConcept of the Web of Things. Article in Journal of Robotics, published\
    \ January 2015. DOI\n \n10.1155/2015/631420 \n189- \nGithub. Available online:\
    \ https://github.com/felixge/node-ar-drone (accessed on 14 September \n2018).\
    \ \n190- \nGithub. \nAvailable \nonline: https://github.com/eschnou/ardrone-autonomy\
    \ (accessed \non \n14 \nSeptember 2018). \n191- \nEngel, J.; Sturm, J.; Cremers,\
    \ D. Accurate Figure Flying with a Quadrocopter Using Onboard Visual \nand Inertial\
    \ Sensing. In Proceedings of the International Conference on Intelligent Robot\
    \ Systems \n(IROS), Algarve, Portugal, 7–12 October 2012; p. 240. [Google Scholar]\
    \ \n192- \nSmith, J.R.; Cao, L.; Codella, N.C.F.; Hill, M.L.; Merler, M.; Nguyen,\
    \ Q.-B.; Pring, E.; Uceda-Sosa, R.A. \nMassive-scalelearning of image and video\
    \ semantic concepts. IBM J. Res. Dev. 2015, 59, 7-1–7-13. \n193- \nCaffe. Available\
    \ online: http://caffe.berkeleyvision.org (accessed on 14 September 2018). \n\
    \ \n194- \nBhattacharjee, B.; Hill, M.L.; Wu, H.; Chandakkar, P.S.; Smith, J.R.;\
    \ Wegman, M.N. Distributed \nlearning of deep feature embeddings for visual recognition\
    \ tasks. IBM J. Res. Dev. 2017, 61, 4-1. \n[Google Scholar] [CrossRef] \n195-\
    \ \nPuttnies, H.; Konieczek, B.; Heller, J.; Timmermann, D.; Danielis, P. Algorithmic\
    \ approach to estimate \nvariant software latencies for latency-sensitive networking.\
    \ In Proceedings of the 2016 IEEE 7th \nAnnual Information Technology, Electronics\
    \ and Mobile Communication Conference (IEMCON), \nVancouver, BC, Canada, 13–15\
    \ October 2016; pp. 1–7. [Google Scholar] \n196- \nNakutis, Z.; Deksnys, V.; Jarusevicius,\
    \ I.; Dambrauskas, V.; Cincikas, G.; Kriauceliunas, A. Round-Trip \nDelay \nEstimation\
    \ \nin \nOPC \nUA \nServer-Client \nCommunication \nChannel. Elektron \nElektrotechnika\
    \ 2016, 22, 80–84.  \n197- \nGithub. Available online: https://github.com/felixge/node-ar-drone\
    \ (accessed on 14 September \n2018). \n \n152 \n \nSmart IoT Monitoring and Real-Time\
    \ Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge \nComputing\
    \ Services \n198- \nKeith Jack,Digital Television (DTV).  in Digital Video and\
    \ DSP, 2008. ScienceDirect. \nhttps://doi.org/10.1016/B978-0-7506-8975-5.00008-X\
    \ \n199- \nMarpe, D.; Wiegand, T.; Heinrich Hertz Institute (HHI); Sullivan, G.J.\
    \ The H.264/MPEG4 Advanced \nVideo Coding Standard and its Applications. IEEE\
    \ Commun. Mag. 2006, 8, 134–143. [Google \nScholar] [CrossRef] \n200- \nGonzález-Reolid,\
    \ I.; Molina-Molina, J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \n\
    Autonomous Solar-Powered Marine Robotic Observatory for Permanent Monitoring of\
    \ Large \nAreas of Shallow Water. Sensors 2018, 18, 3497. [Google Scholar] [CrossRef]\
    \ [PubMed] \n201- \nBoletín Oficial de la Región de Murcia, Numero 298, Viernes,\
    \ 27 de Diciembre de 2019, Página \n36008, 8089 Decreto-Ley N° 2/2019, de 26 de\
    \ Diciembre, de Protección Integral del Mar Menor. \nAvailable \nonline: https://www.borm.es/services/anuncio/ano/2019/numero/8089/pdf?id=782206\
    \ (accesse\nd on 18 June 2020). \n202- \nInforme Integral Sobre el Estado Ecológico\
    \ del Mar Menor; Comité de Asesoramiento Científico \ndel Mar Menor: Murcia, Spain,\
    \ 2017. \n203- \nKersting, D.; Benabdi, M.; Čižmek, H.; Grau, A.; Jimenez, C.;\
    \ Katsanevakis, S.; Öztürk, B.; Tuncer, S.; \nTunesi, L.; Vázquez-Luis, M.; et\
    \ al. Pinna nobilis. IUCN Red List Threat. Species 2019, \ne.T160075998A160081499.\
    \ \nAvailable \nonline: https://www.iucnredlist.org/species/160075998/160081499\
    \ (accessed on 19 June 2020). \n[CrossRef] \n204- \nBelando, M.D.; García-Muñoz,\
    \ M.R.; Ramos-Segura, A.; Franco-Navarro, I.J.; García-Moreno, P.; \nRuiz-Fernández,\
    \ J.M. Distribución y Abundancia de las Praderas de MACRÓFITOS bentónicos y las\
    \ \nPoblaciones de Nacra (Pinna nobilis) en el Mar Menor; Informe del Instituto\
    \ Español de \nOceanografía y la Asociación de Naturalistas del Sureste: Murcia,\
    \ Spain, 2014; 60p. [Google \nScholar] \n205- \nPaull, L.; Seto, M.; Saeedi, S.;\
    \ Leonard, J.J. Navigation for Underwater Vehicles; Springer: \nBerlin/Heidelberg,\
    \ Germany, 2018. [Google Scholar] [CrossRef] \n206- \nLiu, X.; Xu, X.; Liu, Y.;\
    \ Wang, L. Kalman filter for cross-noise in the integration of SINS and \nDVL.\
    \ Math. Probl. Eng. 2014, 2014, 1–8. [Google Scholar] [CrossRef] \n207- \nPaull,\
    \ L.; Saeedi, S.; Seto, M.; Li, H. AUV navigation and localization: A review.\
    \ IEEE J. Ocean. \nEng. 2014, 39, 131–149. [Google Scholar] [CrossRef] \n208-\
    \ \nSalhaoui, M.; Guerrero-Gonzalez, A.; Arioua, M.; Ortiz, F.J.; El Oualkadi,\
    \ A.; Torregrosa, C.L. Smart \nindustrial iot monitoring and control system based\
    \ on UAV and cloud computing applied to a \nconcrete plant. Sensors 2019, 19,\
    \ 3316. [Google Scholar] [CrossRef] \n209- \nStackoverflow. \nAvailable \nonline:\
    \ https://stackoverflow.blog/2017/09/14/python-growing-\nquickly/ (accessed on\
    \ 3 May 2020). \n210- \nNetguru. Available online: https://www.netguru.com/blog/why-is-python-good-for-research-\n\
    benefits-of-the-programming-language (accessed on 3 May 2020). \n211- \nZhou,\
    \ Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J. Edge Intelligence: Paving\
    \ the Last Mile of \nArtificial Intelligence with Edge Computing. Proc. IEEE 2019,\
    \ 107. [Google Scholar] [CrossRef] \n212- \nSikeridis, D.; Papapanagiotou, I.;\
    \ Rimal, B.P.; Devetsikiotis, M. A Comparative Taxonomy and Survey \nof Public\
    \ Cloud Infrastructure Vendors. arXiv 2018, arXiv:1710.01476v2. [Google Scholar]\
    \ \n213- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian: We watch for\
    \ potentialobstacles while you \nare walking andconducting smartphone activities.\
    \ PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n214- \nMegalingam,\
    \ R.K.; Shriram, V.; Likhith, B.; Rajesh, G.; Ghanta, S. Monocular distance estimation\
    \ \nusing pinhole camera approximation to avoid vehicle crash and back-over accidents.\
    \ In \nProceedings of the 2016 10th International Conference on Intelligent Systems\
    \ and Control (ISCO), \nCoimbatore, India, 7–8 January 2016; IEEE: Coimbatore,\
    \ India. [Google Scholar] [CrossRef] \n215- \nNational \nInstruments. \nAvailable\
    \ \nonline: https://www.ni.com/es-es/support/model.sbrio-\n9606.html (accessed\
    \ on 3 May 2020). \n216- \nNational Instruments. Available online: https://www.ni.com/en-us/shop/labview.html\
    \ (accessed \non 3 May 2020). \n217- \nMarine Species. Available online: http://www.marinespecies.org/\
    \ (accessed on 2 June 2020). \n218- \nShi, W.; Cao, J.; Zhang, Q.; Li, Y.; Xu,\
    \ L. Edge computing: Vision and challenges. IEEE Internet Things \nJ. 2016, 3,\
    \ 637–646. [Google Scholar] [CrossRef] \n \n153 \n \nSmart IoT Monitoring and\
    \ Real-Time Control Based On Autonomous Robots, Visual Recognition and Cloud/Edge\
    \ \nComputing Services \n219- \nKrupinski, S.; Desouche, R.; Palomeras, N.; Allibert,\
    \ G.; Hua, M.D. Pool Testing of AUV Visual \nServoing for Autonomous Inspection.\
    \ IFAC-PapersOnLine 2015, 48, 274–280. [Google Scholar] \n[CrossRef] \n220- \n\
    Kumar, G.S.; Unnikrishnan, V.; Painumgal, M.N.V.; Kumar, C.; Rajesh, K.H.V. Autonomous\
    \ \nUnderwater Vehicle for Vision Based Tracking. Procedia Comput. Sci. 2018.\
    \ [Google Scholar] \n[CrossRef] \n221- \nIslam, M.J.; Fulton, M.; Sattar, J. Towards\
    \ a Generic Diver-Following Algorithm: Balancing \nRobustness and Efficiency in\
    \ Deep Visual Detection. IEEE Robot. Autom. Lett. 2019, 4, 113–120. \n[Google\
    \ Scholar] [CrossRef] \n222- \nYosafat, R.; Machbub, C.; Hidayat, E.M.I. Design\
    \ and Implementation of Pan-Tilt for Face Tracking. \nIn Proceedings of the International\
    \ Conference on System Engineering and Technology, Shah \nAlam, Malaysia, 2–3\
    \ October 2017. [Google Scholar] \n223- \nZhang, B.; Huang, J.; Lin, J. A Novel\
    \ Algorithm for Object Tracking by Controlling PAN/TILT \nAutomatically. In Proceedings\
    \ of the ICETC 2nd International Conference on Intelligent System \n2010, Shanghai,\
    \ China, 22–24 June 2010; Volume VI, pp. 596–602. [Google Scholar] \n224- \nGonzález,\
    \ A.G.; Coronado, J. Tratamiento de los retrasos del procesamiento visual en el\
    \ sistema \nde control de un cabezal estereoscópico. In XX Jornadas de Automática:\
    \ Salamanca, 27, 28 y 29 \nde Septiembre; Universidad de Salamanca: Salamanca,\
    \ Spain; pp. 83–87. \n225- \nKim, D.; Han, K.; Sim, J.S.; Noh, Y. Smombie Guardian:\
    \ We watch for potentialobstacles while you \nare walking andconducting smartphone\
    \ activities. PLoS ONE 2018, 13, e0197050. [Google \nScholar] [CrossRef] \n226-\
    \ \nIBM. \nAvailable \nonline: https://cloud.ibm.com/docs/services/visual-recognition?topic=visual-\n\
    recognition-object-detection-overview (accessed on 3 May 2020). \n227- \nGoogle\
    \ Cloud. Available online: https://cloud.google.com/vision/?hl=en (accessed on\
    \ 3 May \n2020). \n228- \nAzure. \nAvailable \nonline: https://azure.microsoft.com/en-au/services/cognitive-\n\
    services/computer-vision/ (accessed on 3 May 2020). \n229- \nMarine protected\
    \ areas in Europe’s seas. An overview and perspectives for the future. European\
    \ \nEnvironment \nAgency. \nNo \n3/2015. \nISSN \n1977-8449. \nAvailable \nonline:\
    \ \nhttps://www.eea.europa.eu/publications/marine-protected-areas-in-europes (accessed\
    \ on 17 \nNovember 2020) \n230- \nLey 3/2001, de Pesca Marítima del Estado. Boletín\
    \ Oficial del Estado del Gobierno de España.  \nAvailable online: https://www.boe.es/eli/es/l/2001/03/26/3/con\
    \ (accessed on 17 November 2020) \n231- \nGobierno \nde \nEspaña. \nReservas \n\
    Marinas \nde \nEspaña. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-pesqueros/reservas-marinas-de-\n\
    espana/(accessed on 17 November 2020) \n232- \nGonzález-Reolid, I.; Molina-Molina,\
    \ J.C.; Guerrero-González, A.; Ortiz, F.J.; Alonso, D. An \nAutonomous Solar-Powered\
    \ Marine Robotic Observatory for Permanent Monitoring of Large \nAreas of Shallow\
    \ Water. Sensors 2018, 18, 3497; doi:10.3390/s18103497. \n233- \nA. Manjunath,\
    \ Y. Liu, B. Henriques and A. Engstle, \"Radar Based Object Detection and Tracking\
    \ for \nAutonomous Driving,\" 2018 IEEE MTT-S International Conference on Microwaves\
    \ for Intelligent \nMobility (ICMIM), Munich, 2018, pp. 1-4, doi: 10.1109/ICMIM.2018.8443497\
    \ \n234- \nYang-Lang Chang, Amare Anagaw, Lena Chang, Yi Chun Wang, Chih-Yu Hsiao\
    \ and Wei-Hong Lee. \nShip Detection Based on YOLOv2 for SAR Imagery. Remote Sens.\
    \ 2019, 11, 786; \ndoi:10.3390/rs11070786 \n235- \nWei Li, Ting Yang, Flavia C.\
    \ Delicato, Paulo F. Pires, Zahir Tari, Samee U. Khan, and Albert Y. Zomaya. \n\
    On Enabling Sustainable Edge Computing with Renewable Energy Resources. IEEE \n\
    Communications Magazine. May 2018, 10.1109/MCOM.2018.1700888 \n236- \nJ. Lee,\
    \ J. Wang, D. Crandall, S. Šabanović and G. Fox, \"Real-Time, Cloud-Based Object\
    \ Detection \nfor Unmanned Aerial Vehicles,\" 2017 First IEEE International Conference\
    \ on Robotic Computing \n(IRC), Taichung, 2017, pp. 36-43, doi: 10.1109/IRC.2017.77.\
    \ \n237- \nK. Zhang, S. Leng, Y. He, S. Maharjan and Y. Zhang, \"Mobile Edge Computing\
    \ and Networking for \nGreen and Low-Latency Internet of Things,\" in IEEE Communications\
    \ Magazine, vol. 56, no. 5, pp. \n39-45, May 2018, doi: 10.1109/MCOM.2018.1700882.\
    \ \n \n154 \n \nSmart IoT Monitoring and Real-Time Control Based On Autonomous\
    \ Robots, Visual Recognition and Cloud/Edge \nComputing Services \n238- \nAkar\
    \ E., Marques O., Andrews W.A., Furht B. (2019) Cloud-Based Skin Lesion Diagnosis\
    \ System \nUsing Convolutional Neural Networks. In: Arai K., Bhatia R., Kapoor\
    \ S. (eds) Intelligent \nComputing. CompCom 2019. Advances in Intelligent Systems\
    \ and Computing, vol 997. \nSpringer, Cham. https://doi.org/10.1007/978-3-030-22871-2_70\
    \ \n239- \nMarouane Salhaoui, J. Carlos Molina-Molina, Antonio Guerrero-González,\
    \ Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater Monitoring System\
    \ for Detecting Life on the Seabed \nby Means of Computer Vision Cloud Services.\
    \ Journal, Remote Sensing MDPI, 2020. \n240- \nNational Instruments. Available\
    \ online: https://www.ni.com/en-us/shop/labview.html (accessed \non 17 Nov 2020).\
    \ \n241- \nNational Instruments. Available online: https://www.ni.com/es-es/support/model.crio-9022.html\
    \ \n(accessed on 17 Nov 2020).  \n242- \nMarouane Salhaoui, J. Carlos Molina-Molina,\
    \ Antonio Guerrero-González, Mounir Arioua, \nFrancisco J Ortiz, Autonomous Underwater\
    \ Monitoring System for Detecting Life on the Seabed \nby Means of Computer Vision\
    \ Cloud Services. Journal, Remote Sensing MDPI, 2020. \n243- \nM. Satyanarayanan,\
    \ “The emergence of edge computing,” Computer, vol. 50, no. 1, pp. 30–39, \n2017.\
    \ \n244- \nGobierno de España - Reservas Marinas de España. Cabo de Palos – Islas\
    \ Hormigas: Características. \nAvailable \nonline: \nhttps://www.mapa.gob.es/es/pesca/temas/proteccion-recursos-\n\
    pesqueros/reservas-marinas-de-espana/cabo-de-palos-islas-\nhormigas/caracteristicas/default.aspx\
    \ (accessed on 17 Nov 2020). \n245- \nIRENA - International Renewable Energy Agency.\
    \ Available online : https://www.irena.org, 07 \nJanuary 2021. \n246- \nMönks,\
    \ U., Trsek, H., Dürkop, L., Geneiß, V., Lohweg, V.: Towards distributed intelligent\
    \ \nsensor and information fusion. Mechatronics 34, 63–71 (2016). https://doi.org/10.1016/j.\
    \ \nmechatronics.2015.05.005 \n247- \nDhondge, K., Shorey, R., Tew, J.: HOLA:\
    \ heuristic and opportunistic link selection \nalgorithm for energy efficiency\
    \ in Industrial Internet of Things (IIoT) systems. In: \nCOMSNETS 2016 - Workshop\
    \ on Wild and Crazy Ideas on the Interplay Between IoT and \nBig Data. IEEE (2016)\
    \ \n248- \nDatta, S.K.; Bonnet, C. MEC and IoT Based Automatic Agent Reconfiguration\
    \ in Industry 4.0. In \nProceedings of the 2018 IEEE International Conference\
    \ on Advanced Networks and \nTelecommunications Systems (ANTS), Indore, India,\
    \ 16–19 December 2018; pp. 1–5. 7.  \n249- \nShrouf, F.; Ordieres, J.; Miragliotta,\
    \ G. Smart factories in Industry 4.0:  A review of the concept and \nof energy\
    \ management approached in production based on the Internet of Things paradigm.\
    \ In \nProceedings of the 2014 IEEE International Conference on Industrial Engineering\
    \ and Engineering \nManagement (IEEM), Selangor Darul Ehsan, Malaysia, 9–12 December\
    \ 2014; pp. 697–701. \n250- \nHossein Motlagh, N.; Mohammadrezaei, M.; Hunt, J.;\
    \ Zakeri, B. Internet of Things (IoT) and the \nEnergy Sector. Energies 2020,\
    \ 13, 494. \n251- \nAyesha Hafeez, Nourhan H. Kandil, Ban Al-Omar, T. Landolsi,\
    \ and A. R. Al-Ali, \"Smart \nHome Area Networks Protocols within the Smart Grid\
    \ Context\", Journal of Communications Vol. \n9, No. 9, September 2014 \n252-\
    \ \nLi, S.; Da Xu, L.; Zhao, S. 5G Internet of Things: A survey. J. Ind. Inf.\
    \ Integr. 2018, 10, 1–9 \n253- \nAhmed B. Altamimi and Rabie A. Ramadan, \"Towards\
    \ internet of things modeling: a gateway \napproach\", \nSpringer, \nComplex \n\
    Adapt \nSyst \nModel \n(2016) \n4:25, \nDOI \nhttps://doi.org/10.1186/s40294-016-0038-3\
    \ \n254- \nWatson Internet of Things. Securely Connect with Watson IoT Platform.\
    \ 2019. Available online: \nhttps://www.ibm.com/internet-of-things/solutions/iot-platform/watson-iot-platform\
    \  (accessed \non 15 October 2019). \n255- \n “The OPC Unified Architecture (UA)”\
    \ [Online]. Available: https://opcfoundation.org/about/opc-\ntechnologies/opc-ua/\
    \ \n256- \nThomas Bangemann, StamatisKarnouskos, Roberto Camp, Oscar Carlsson,MatthiasRiedl,\
    \ \nStuart McLeod, Robert Harrison, Armando W. ColomboandPetrStluka, “State of\
    \ the Art in \nIndustrial Automation”, Industrial Cloud-Based Cyber-Physical Systems,\
    \ Springer International \nPublishing Switzerland 2014, DOI: 10.1007/978-3-319-05624-1_2\
    \ \n257- \nNode-RED, Low-code programming for event-driven applications. [Online].\
    \ Available:  \nhttps://nodered.org/  \n"
  inline_citation: '>'
  journal: ''
  limitations: '>'
  pdf_link: https://repositorio.upct.es/bitstream/10317/10416/1/msa.pdf
  publication_year: 2021
  relevance_score1: 0
  relevance_score2: 0
  title: Smart IoT monitoring and real-time control based on autonomous robots, visual
    recognition and cloud/edge computing services
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- DOI: https://doi.org/10.19101/ijatee.2021.876002
  analysis: '>'
  authors: []
  citation_count: 0
  full_citation: '>'
  full_text: '>

    ACCENTS Journals A Unit of ACCENTS (Publisher of Peer Reviewed Open Access Journals)
    About ACCENTS  Journals Special Issue Conferences   ADL  Contact Us International
    Journal of Advanced Technology and Engineering Exploration (IJATEE) ISSN (Print):2394-5443    ISSN
    (Online):2394-7454 Volume-9 Issue-97 December-2022 Full-Text PDF Paper Title :
    Internet of things (IoT) fusion with cloud computing: current research and future
    direction Author Name : Manzoor Ansari, Syed Arshad Ali and Mansaf Alam Abstract
    : The internet of things (IoT) has been a major buzzword in recent years, with
    the potential to connect a huge number of devices to the internet and each other.
    The integration of all of these devices and data sources into a cohesive system
    is one of the key challenges involved in the development of the IoT. Cloud integration
    is one approach that can be used to achieve this, and there are several different
    cloud-based IoT platforms available. As consequences, IoT and cloud computing
    has drastically changed the environment of technological development. A synergistic
    strategy that combines the strengths of these two breakthrough technologies into
    one package is estimated to provide enormous benefits. Despite these advantages,
    the integration of such technologies poses numerous issues and challenges. An
    in-depth analysis of each of these technologies is discussed, along with the advantages,
    challenges, and limitations associated with convergent approach. The preferred
    reporting items for systematic reviews and meta-analyses (PRISMA) method has been
    used to identify all relevant articles from the literature, and the most relevant
    articles have been included for further analysis. The relevant articles have been
    analysed using the method of the Bibliometric network, such as co-authorship analysis,
    term co-occurrence. Furthermore, taxonomy of IoT-based cloud applications has
    been discussed and quality of service (QoS) factors-based analysis for each applications
    domain has been done. In this review, we take a look at some of the most popular
    IoT cloud integration platforms and compare their features and capabilities. In
    addition, we have investigated a variety of related technologies and anticipated
    future developments. Keywords : Internet of things (IoT), Cloud computing, Edge
    computing, Bibliometric analysis, Preferred reporting items for systematic reviews
    and meta-analyses (PRISMA), Real-world applications. Cite this article : Ansari
    M, Ali SA, Alam M. Internet of things (IoT) fusion with cloud computing: current
    research and future direction . International Journal of Advanced Technology and
    Engineering Exploration. 2022; 9(97):1812-1845. DOI:10.19101/IJATEE.2021.876002.
    References : [1]Stergiou C, Psannis KE, Kim BG, Gupta B. Secure integration of
    IoT and cloud computing. Future Generation Computer Systems. 2018; 78:964-75.
    [Crossref] [Google Scholar] [2]Mahdavinejad MS, Rezvan M, Barekatain M, Adibi
    P, Barnaghi P, Sheth AP. Machine learning for internet of things data analysis:
    a survey. Digital Communications and Networks. 2018; 4(3):161-75. [Crossref] [Google
    Scholar] [3]Mocrii D, Chen Y, Musilek P. IoT-based smart homes: a review of system
    architecture, software, communications, privacy and security. Internet of Things.
    2018; 1:81-98. [Crossref] [Google Scholar] [4]https://www.insiderintelligence.com/insights/internet-of-things-devices-examples/#:~:text=Insider%20Intelligence%20forecasts%203.74%20billion,some%20specific%20devices%20and%20examples.
    Accessed 14 October 2022. [5]Gubbi J, Buyya R, Marusic S, Palaniswami M. Internet
    of things (IoT): a vision, architectural elements, and future directions. Future
    Generation Computer Systems. 2013; 29(7):1645-60. [Crossref] [Google Scholar]
    [6]Patel KK, Patel SM, Scholar P. Internet of things-IoT: definition, characteristics,
    architecture, enabling technologies, application & future challenges. International
    Journal of Engineering Science and Computing. 2016; 6(5): 6122-31. [Google Scholar]
    [7]Viriyasitavat W, Anuphaptrirong T, Hoonsopon D. When blockchain meets Internet
    of things: characteristics, challenges, and business opportunities. Journal of
    Industrial Information Integration. 2019; 15:21-8. [Crossref] [Google Scholar]
    [8]Aazam M, Khan I, Alsaffar AA, Huh EN. Cloud of things: integrating internet
    of things and cloud computing and the issues involved. In proceedings of 11th
    international Bhurban conference on applied sciences & technology Islamabad, Pakistan
    2014 (pp. 414-9). IEEE. [Crossref] [Google Scholar] [9]Khan S, Shakil KA, Alam
    M. Cloud-based big data analytics—a survey of current research and future directions.
    Big Data Analytics. 2018: 595-604. [Crossref] [Google Scholar] [10]Ali SA, Affan
    M, Alam M. A study of efficient energy management techniques for cloud computing
    environment. In 9th international conference on cloud computing, data science
    & engineering (confluence) 2019 (pp. 13-8). IEEE. [Crossref] [Google Scholar]
    [11]Fang J, Ma A. IoT application modules placement and dynamic task processing
    in edge-cloud computing. IEEE Internet of Things Journal. 2020; 8(16):12771-81.
    [Crossref] [Google Scholar] [12]Wang L, Von LG, Younge A, He X, Kunze M, Tao J,
    et al. Cloud computing: a perspective study. New Generation Computing. 2010; 28(2):137-46.
    [Crossref] [Google Scholar] [13]Jiang J, Li Z, Tian Y, Al-nabhan N. A review of
    techniques and methods for IoT applications in collaborative cloud-fog environment.
    Security and Communication Networks. 2020; 2020:1-15. [Crossref] [Google Scholar]
    [14]https://www.oxfordlearnersdictionaries.com/definition/english/internet-of
    things#:~:text=%5Bsingular%5D,enabling%20them%20to%20share%20data. Accessed 14
    October 2022. [15]Paul B. Internet of things (IoT), three-layer architecture,
    security issues and counter measures. In ICT analysis and applications 2022 (pp.
    23-34). Springer, Singapore. [Google Scholar] [16]Al-qaseemi SA, Almulhim HA,
    Almulhim MF, Chaudhry SR. IoT architecture challenges and issues: lack of standardization.
    In future technologies conference 2016 (pp. 731-8). IEEE. [Crossref] [Google Scholar]
    [17]https://www.scc.com/insights/it-solutions/data-centre modernisation/the-three-layers-of-computing-cloud-fog-and-edge.
    Accessed 14 October 2022. [18]Kolhar M, Al-turjman F, Alameen A, Abualhaj MM.
    A three layered decentralized IoT biometric architecture for city lockdown during
    COVID-19 outbreak. IEEE Access. 2020; 8:163608-17. [Crossref] [Google Scholar]
    [19]Mrabet H, Belguith S, Alhomoud A, Jemai A. A survey of IoT security based
    on a layered architecture of sensing and data analysis. Sensors. 2020; 20(13):1-19.
    [Crossref] [Google Scholar] [20]Ramya R, Ramamoorthy S. Survey on edge intelligence
    in IoT-based computing platform. Ambient Communications and Computer Systems.
    2022: 549-61. [Crossref] [Google Scholar] [21]Mell P, Grance T. The NIST definition
    of cloud computing. NIST Special Publication. 2011:1-3. [Google Scholar] [22]Armbrust
    M, Fox A, Griffith R, Joseph AD, Katz R, Konwinski A, et al. A view of cloud computing.
    Communications of the ACM. 2010; 53(4):50-8. [Google Scholar] [23]Khan S, Ali
    SA, Hasan N, Shakil KA, Alam M. Big data scientific workflows in the cloud: challenges
    and future prospects. Cloud Computing for Geospatial Big Data Analytics. 2019:1-28.
    [Crossref] [Google Scholar] [24]Gong C, Liu J, Zhang Q, Chen H, Gong Z. The characteristics
    of cloud computing. In 39th international conference on parallel processing workshops
    2010 (pp. 275-9). IEEE. [Crossref] [Google Scholar] [25]Rashid A, Chaturvedi A.
    Cloud computing characteristics and services: a brief review. International Journal
    of Computer Sciences and Engineering. 2019; 7(2):421-6. [Crossref] [Google Scholar]
    [26]Moghaddam FF, Rohani MB, Ahmadi M, Khodadadi T, Madadipouya K. Cloud computing:
    vision, architecture and characteristics. In IEEE control and system graduate
    research colloquium 2015 (pp. 1-6). IEEE. [Crossref] [Google Scholar] [27]Ali
    SA, Alam M. A relative study of task scheduling algorithms in cloud computing
    environment. In 2nd international conference on contemporary computing and informatics
    2016 (pp. 105-11). IEEE. [Crossref] [Google Scholar] [28]Shakil KA, Alam M. Cloud
    computing in bioinformatics and big data analytics: current status and future
    research. In big data analytics 2018 (pp. 629-40). Springer, Singapore. [Crossref]
    [Google Scholar] [29]Cao K, Liu Y, Meng G, Sun Q. An overview on edge computing
    research. IEEE Access. 2020; 8:85714-28. [Crossref] [Google Scholar] [30]Shi W,
    Cao J, Zhang Q, Li Y, Xu L. Edge computing: vision and challenges. IEEE Internet
    of Things Journal. 2016; 3(5):637-46. [Crossref] [Google Scholar] [31]Zhao Z,
    Lin P, Shen L, Zhang M, Huang GQ. IoT edge computing-enabled collaborative tracking
    system for manufacturing resources in industrial park. Advanced Engineering Informatics.
    2020; 43:1-12. [Google Scholar] [32]Papcun P, Kajati E, Cupkova D, Mocnej J, Miskuf
    M, Zolotova I. Edge‐enabled IoT gateway criteria selection and evaluation. Concurrency
    and Computation: Practice and Experience. 2020; 32(13):1-9. [Crossref] [Google
    Scholar] [33]Alrawahi AS, Lee K, Lotfi A. Trading of cloud of things resources.
    In proceedings of the second international conference on internet of things, data
    and cloud computing 2017 (pp. 1-7). ACM. [Crossref] [Google Scholar] [34]Gannon
    D, Barga R, Sundaresan N. Cloud-native applications. IEEE Cloud Computing. 2017;
    4(5):16-21. [Crossref] [Google Scholar] [35]Li KC, Gupta BB, Agrawal DP. Recent
    advances in security, privacy, and trust for internet of things (IoT) and cyber-physical
    systems (CPS). CRC Press; 2021. [Google Scholar] [36]Kapoor S, Panda SN. Integrating
    cloud with IoT-cloud IoT. In real-life applications of the internet of things
    2022 (pp. 273-93). Apple Academic Press. [Google Scholar] [37]Fortino G, Guerrieri
    A, Savaglio C, Spezzano G. A review of internet of things platforms through the
    IoT-A reference architecture. In international symposium on intelligent and distributed
    computing 2022 (pp. 25-34). Springer, Cham. [Crossref] [Google Scholar] [38]Hou
    L, Zhao S, Xiong X, Zheng K, Chatzimisios P, Hossain MS, et al. Internet of things
    cloud: architecture and implementation. IEEE Communications Magazine. 2016; 54(12):32-9.
    [Crossref] [Google Scholar] [39]Asghari P, Rahmani AM, Javadi HH. Internet of
    things applications: a systematic review. Computer Networks. 2019; 148:241-61.
    [Crossref] [Google Scholar] [40]Shukla S, Hassan M, Tran DC, Akbar R, Paputungan
    IV, Khan MK. Improving latency in internet-of-things and cloud computing for real-time
    data transmission: a systematic literature review. Cluster Computing. 2021:1-24.
    [Crossref] [Google Scholar] [41]Kotha HD, Gupta VM. IoT application: a survey.
    International Journal of Engineering & Technology. 2018; 7(2.7):891-6. [Google
    Scholar] [42]Botta A, De DW, Persico V, Pescapé A. Integration of cloud computing
    and internet of things: a survey. Future Generation Computer Systems. 2016; 56:684-700.
    [Crossref] [Google Scholar] [43]Díaz M, Martín C, Rubio B. State-of-the-art, challenges,
    and open issues in the integration of internet of things and cloud computing.
    Journal of Network and Computer Applications. 2016; 67:99-117. [Crossref] [Google
    Scholar] [44]Dang LM, Piran MJ, Han D, Min K, Moon H. A survey on internet of
    things and cloud computing for healthcare. Electronics. 2019; 8(7):1-49. [Crossref]
    [Google Scholar] [45]Malik A, Om H. Cloud computing and internet of things integration:
    architecture, applications, issues, and challenges. In sustainable cloud and energy
    services 2018 (pp. 1-24). Springer, Cham. [Crossref] [Google Scholar] [46]Amairah
    A, Al-tamimi BN, Anbar M, Aloufi K. Cloud computing and internet of things integration
    systems: a review. In international conference of reliable information and communication
    technology 2018 (pp. 406-14). Springer, Cham. [Crossref] [Google Scholar] [47]Atlam
    HF, Alenezi A, Alharthi A, Walters RJ, Wills GB. Integration of cloud computing
    with internet of things: challenges and open issues. In international conference
    on internet of things (iThings) and green computing and communications (GreenCom)
    and cyber, physical and social computing (CPSCom) and smart data (SmartData) 2017
    (pp. 670-5). IEEE. [Crossref] [Google Scholar] [48]Cavalcante E, Pereira J, Alves
    MP, Maia P, Moura R, Batista T, et al. On the interplay of internet of things
    and cloud computing: a systematic mapping study. Computer Communications. 2016;
    89:17-33. [Crossref] [Google Scholar] [49]Selçuk AA. A guide for systematic reviews:
    PRISMA. Turkish Archives of Otorhinolaryngology. 2019; 57(1):57-8. [Crossref]
    [Google Scholar] [50]Moher D, Liberati A, Tetzlaff J, Altman DG. Reprint-preferred
    reporting items for systematic reviews and meta-analyses: the PRISMA statement.
    Physical Therapy. 2009; 89(9):873-80. [Crossref] [Google Scholar] [51]Pilkington
    A, Meredith J. The evolution of the intellectual structure of operations management-1980–2006:
    a citation/co-citation analysis. Journal of Operations Management. 2009; 27(3):185-202.
    [Crossref] [Google Scholar] [52]Garfield E. From the science of science to scientometrics
    visualizing the history of science with HistCite software. Journal of Informetrics.
    2009; 3(3):173-9. [Crossref] [Google Scholar] [53]Gmür M. Co-citation analysis
    and the search for invisible colleges: a methodological evaluation. Scientometrics.
    2003; 57(1):27-57. [Crossref] [Google Scholar] [54]Osareh F. Bibliometrics, citation
    analysis and co-citation analysis: a review of literature I. LIBRI. 1996; 46(3):149-58.
    [Crossref] [Google Scholar] [55]Van EN, Waltman L. Software survey: VOSviewer,
    a computer program for bibliometric mapping. Scientometrics. 2010; 84(2):523-38.
    [Crossref] [Google Scholar] [56]Pflanzner T, Kertész A. A taxonomy and survey
    of IoT cloud applications. EAI Endorsed Transactions on Internet of Things. 2018;
    3(12):1-14. [Google Scholar] [57]Nancy AA, Ravindran D, Raj VPD, Srinivasan K,
    Gutierrez RD. IoT-cloud-based smart healthcare monitoring system for heart disease
    prediction via deep learning. Electronics. 2022; 11(15):1-19. [Crossref] [Google
    Scholar] [58]Singh PD, Dhiman G, Sharma R. Internet of things for sustaining a
    smart and secure healthcare system. Sustainable Computing: Informatics and Systems.
    2022. [Crossref] [Google Scholar] [59]Sahay MR, Sukumaran MK, Amarnath S, Palani
    TN. Environmental monitoring system using IoT and cloud service at real-time.
    EasyChair Preprint. 2019; 5(968):1-8. [Google Scholar] [60]Helal AA, Villaça RS,
    Santos CA, Colistete JR. An integrated solution of software and hardware for environmental
    monitoring. Internet of Things. 2022. [Crossref] [Google Scholar] [61]Lova RK,
    Vijayaraghavan V. A self-powered, real-time, NRF24L01 IoT-based cloud-enabled
    service for smart agriculture decision-making system. Wireless Personal Communications.
    2022; 124(1):207-36. [Crossref] [Google Scholar] [62]Quy VK, Hau NV, Anh DV, Quy
    NM, Ban NT, Lanza S, et al. IoT-enabled smart agriculture: architecture, applications,
    and challenges. Applied Sciences. 2022; 12(7):1-19. [Crossref] [Google Scholar]
    [63]Liu C, Ke L. Cloud assisted internet of things intelligent transportation
    system and the traffic control system in the smart city. Journal of Control and
    Decision. 2022:1-14. [Crossref] [Google Scholar] [64]Jiang D. The construction
    of smart city information system based on the internet of things and cloud computing.
    Computer Communications. 2020; 150:158-66. [Crossref] [Google Scholar] [65]Haghnegahdar
    L, Joshi SS, Dahotre NB. From IoT-based cloud manufacturing approach to intelligent
    additive manufacturing: industrial internet of things-an overview. The International
    Journal of Advanced Manufacturing Technology. 2022; 119:1461-78. [Crossref] [Google
    Scholar] [66]Sigov A, Ratkin L, Ivanov LA, Xu LD. Emerging enabling technologies
    for industry 4.0 and beyond. Information Systems Frontiers. 2022:1-11. [Crossref]
    [Google Scholar] [67]Hu JX, Chen CL, Fan CL, Wang KH. An intelligent and secure
    health monitoring scheme using IoT sensor based on cloud computing. Journal of
    Sensors. 2017; 2017:1-12. [Crossref] [Google Scholar] [68]Nasser N, Emad-ul-haq
    Q, Imran M, Ali A, Razzak I, Al-helali A. A smart healthcare framework for detection
    and monitoring of COVID-19 using IoT and cloud computing. Neural Computing and
    Applications. 2021:1-15. [Crossref] [Google Scholar] [69]Bao Y, Qiu W, Tang P,
    Cheng X. Efficient, revocable, and privacy-preserving fine-grained data sharing
    with keyword search for the cloud-assisted medical IoT system. IEEE Journal of
    Biomedical and Health Informatics. 2021; 26(5):2041-51. [Crossref] [Google Scholar]
    [70]Farid F, Elkhodr M, Sabrina F, Ahamed F, Gide E. A smart biometric identity
    management framework for personalised IoT and cloud computing-based healthcare
    services. Sensors. 2021; 21(2):1-18. [Crossref] [Google Scholar] [71]Anuradha
    M, Jayasankar T, Prakash NB, Sikkandar MY, Hemalakshmi GR, Bharatiraja C, et al.
    IoT enabled cancer prediction system to enhance the authentication and security
    using cloud computing. Microprocessors and Microsystems. 2021; 80:1-23. [Crossref]
    [Google Scholar] [72]Ming FX, Habeeb RA, Md NFH, Gani AB. Real-time carbon dioxide
    monitoring based on IoT & cloud technologies. In proceedings of the 8th international
    conference on software and computer applications 2019 (pp. 517-21). [Crossref]
    [Google Scholar] [73]Singh R, Gaur N, Bathla S. IoT based air pollution monitoring
    device using raspberry pi and cloud computing. In 4th international conference
    on electronics, communication and aerospace technology 2020 (pp. 702-7). IEEE.
    [Crossref] [Google Scholar] [74]Mi J, Sun X, Zhang S, Liu N. Residential environment
    pollution monitoring system based on cloud computing and internet of things. International
    Journal of Analytical Chemistry. 2022; 2022:1-8. [Crossref] [Google Scholar] [75]Phasinam
    K, Kassanuk T, Shinde PP, Thakar CM, Sharma DK, Mohiddin M, et al. Application
    of IoT and cloud computing in automation of agriculture irrigation. Journal of
    Food Quality. 2022; 2022:1-8. [Crossref] [Google Scholar] [76]Uddin MA, Dey UK,
    Tonima SA, Tusher TI. An IoT-based cloud solution for intelligent integrated rice-fish
    farming using wireless sensor networks and sensing meteorological parameters.
    In IEEE 12th annual computing and communication workshop and conference 2022 (pp.
    568-73). IEEE. [Crossref] [Google Scholar] [77]Namee K, Kamjumpol C, Pimsiri W.
    Development of smart vegetable growing cabinet with IoT, edge computing and cloud
    computing. In 2nd international conference on image processing and machine vision
    2020 (pp. 47-52). [Crossref] [Google Scholar] [78]Hundera NW, Jin C, Geressu DM,
    Aftab MU, Olanrewaju OA, Xiong H. Proxy-based public-key cryptosystem for secure
    and efficient IoT-based cloud data sharing in the smart city. Multimedia Tools
    and Applications. 2022; 81(21):29673-97. [Crossref] [Google Scholar] [79]Hojjati
    A, Nasar W, Mishra D, Alaliyat S, Hameed IA. Cloud-based smart IoT sustainable
    solution for waste sorting and management. In international symposium on system
    integration 2022 (pp. 218-24). IEEE. [Crossref] [Google Scholar] [80]Hussain MA,
    Nikhil K, Kalyan KY. IoT based smart dustbin monitoring with tracking system using
    atmega 2560 microcontroller. In fifteenth international conference on information
    processing 2019 (pp. 1-6). IEEE. [Crossref] [Google Scholar] [81]Garbugli A, Sabbioni
    A, Corradi A, Bellavista P. TEMPOS: QoS management middleware for edge cloud computing
    FaaS in the internet of things. IEEE Access. 2022; 10:49114-27. [Crossref] [Google
    Scholar] [82]Qader G, Junaid M, Abbas Q, Mubarik MS. Industry 4.0 enables supply
    chain resilience and supply chain performance. Technological Forecasting and Social
    Change. 2022. [Crossref] [Google Scholar] [83]Venticinque S, Amato A. A methodology
    for deployment of IoT application in fog. Journal of Ambient Intelligence and
    Humanized Computing. 2019; 10(5):1955-76. [Crossref] [Google Scholar] [84]Kim
    S, Kim S. User preference for an IoT healthcare application for lifestyle disease
    management. Telecommunications Policy. 2018; 42(4):304-14. [Crossref] [Google
    Scholar] [85]Jimenez F, Torres R. Building an IoT-aware healthcare monitoring
    system. In 34th international conference of the Chilean computer science society
    2015 (pp. 1-4). IEEE. [Crossref] [Google Scholar] [86]Suciu G, Suciu V, Martian
    A, Craciunescu R, Vulpe A, Marcu I, et al. Big data, internet of things and cloud
    convergence–an architecture for secure e-health applications. Journal of Medical
    Systems. 2015; 39(11):1-8. [Crossref] [Google Scholar] [87]Alshammari H, El-ghany
    SA, Shehab A. Big IoT healthcare data analytics framework based on fog and cloud
    computing. Journal of Information Processing Systems. 2020; 16(6):1238-49. [Google
    Scholar] [88]Firouzi F, Farahani B, Marinšek A. The convergence and interplay
    of edge, fog, and cloud in the AI-driven internet of things (IoT). Information
    Systems. 2022. [Crossref] [Google Scholar] [89]Arvaree T, Perumal T. IoT based
    car pollution detection using cloud computing. International Journal of Environmental
    Science and Development. 2021; 12(8):226-31. [Crossref] [Google Scholar] [90]Li
    H, Wang H, Yin W, Li Y, Qian Y, Hu F. Development of a remote monitoring system
    for henhouse environment based on IoT technology. Future Internet. 2015; 7(3):329-41.
    [Crossref] [Google Scholar] [91]Kim NS, Lee K, Ryu JH. Study on IoT based wild
    vegetation community ecological monitoring system. In seventh international conference
    on ubiquitous and future networks 2015 (pp. 311-6). IEEE. [Crossref] [Google Scholar]
    [92]Asha P, Natrayan LB, Geetha BT, Beulah JR, Sumathy R, Varalakshmi G, et al.
    IoT enabled environmental toxicology for air pollution monitoring using AI techniques.
    Environmental Research. 2022. [Crossref] [Google Scholar] [93]Qian X, Wang X.
    Content-centric IoT-based air pollution monitoring. Wireless Personal Communications.
    2022; 123(4):3213-22. [Crossref] [Google Scholar] [94]Misra NN, Dixit Y, Al-mallahi
    A, Bhullar MS, Upadhyay R, Martynenko A. IoT, big data and artificial intelligence
    in agriculture and food industry. IEEE Internet of Things Journal. 2020; 9(9):1-19.
    [Crossref] [Google Scholar] [95]Perumal MS, Manimozhi B, Dandamudi H, Durairaj
    VB, Jawaharlalnehru A. Ultra-reliable low latency communication technique for
    agriculture wireless sensor networks. Arabian Journal of Geosciences. 2021; 14(13):1-9.
    [Crossref] [Google Scholar] [96]Mekala MS, Viswanathan P. A novel technology for
    smart agriculture based on IoT with cloud computing. In international conference
    on I-SMAC (IoT in social, mobile, analytics and cloud) (I-SMAC) 2017 (pp. 75-82).
    IEEE. [Crossref] [Google Scholar] [97]Liu S, Guo L, Webb H, Ya X, Chang X. Internet
    of things monitoring system of modern eco-agriculture based on cloud computing.
    IEEE Access. 2019; 7:37050-8. [Crossref] [Google Scholar] [98]Aiswarya A, Anantapalli
    R, Singh R, Nandhini S. Detection and regulation of soil moisture and nutrients
    using cloud computing and internet of things in agriculture. Journal of Computational
    and Theoretical Nanoscience. 2019; 16(8):3183-6. [Crossref] [Google Scholar] [99]Rathor
    S, Kumari S. Smart agriculture system using IoT and cloud computing. In 5th international
    conference on information systems and computer networks 2021 (pp. 1-4). IEEE.
    [Crossref] [Google Scholar] [100]Montori F, Bedogni L, Bononi L. A collaborative
    internet of things architecture for smart cities and environmental monitoring.
    IEEE Internet of Things Journal. 2017; 5(2):592-605. [Crossref] [Google Scholar]
    [101]Zia T, Liu P, Han W. Application-specific digital forensics investigative
    model in internet of things (IoT). In proceedings of the 12th international conference
    on availability, reliability and security 2017 (pp. 1-7). [Crossref] [Google Scholar]
    [102]Distefano S, Longo F, Scarpa M. QoS assessment of mobile crowdsensing services.
    Journal of Grid Computing. 2015; 13(4):629-50. [Crossref] [Google Scholar] [103]Zeng
    X, Garg SK, Strazdins P, Jayaraman PP, Georgakopoulos D, Ranjan R. IOT sim: a
    simulator for analysing IoT applications. Journal of Systems Architecture. 2017;
    72:93-107. [Crossref] [Google Scholar] [104]Duttagupta S, Kumar M, Ranjan R, Nambiar
    M. Performance prediction of IoT application: an experimental analysis. In proceedings
    of the 6th international conference on the internet of things 2016 (pp. 43-51).
    ACM. [Crossref] [Google Scholar] [105]Chen S, Liu B, Chen X, Zhang Y, Huang G.
    Framework for adaptive computation offloading in IoT applications. In proceedings
    of the 9th Asia-Pacific symposium on internetware 2017 (pp. 1-6). ACM. [Crossref]
    [Google Scholar] [106]Lee C, Wang C, Kim E, Helal S. Blueprint flow: a declarative
    service composition framework for cloud applications. IEEE Access. 2017; 5:17634-43.
    [Crossref] [Google Scholar] [107]Akbar A, Kousiouris G, Pervaiz H, Sancho J, Ta-shma
    P, Carrez F, et al. Real-time probabilistic data fusion for large-scale IoT applications.
    IEEE Access. 2018; 6:10015-27. [Crossref] [Google Scholar] [108]Sun X, Ansari
    N. Traffic load balancing among brokers at the IoT application layer. IEEE Transactions
    on Network and Service Management. 2017; 15(1):489-502. [Crossref] [Google Scholar]
    [109]Pustišek M, Kos A. Approaches to front-end IoT application development for
    the ethereum blockchain. Procedia Computer Science. 2018; 129:410-9. [Crossref]
    [Google Scholar] [110]Alodib M. QoS-Aware approach to monitor violations of SLAs
    in the IoT. Journal of Innovation in Digital Ecosystems. 2016; 3(2):197-207. [Crossref]
    [Google Scholar] [111]Han SN, Crespi N. Semantic service provisioning for smart
    objects: integrating IoT applications into the web. Future Generation Computer
    Systems. 2017; 76:180-97. [Crossref] [Google Scholar] [112]Huo Y, Qiu P, Zhai
    J, Fan D, Peng H. Multi-objective service composition model based on cost-effective
    optimization. Applied Intelligence. 2018; 48(3):651-69. [Crossref] [Google Scholar]
    [113]Huo L, Wang Z. Service composition instantiation based on cross-modified
    artificial bee colony algorithm. China Communications. 2016; 13(10):233-44. [Crossref]
    [Google Scholar] [114]Temglit N, Chibani A, Djouani K, Nacer MA. A distributed
    agent-based approach for optimal QoS selection in web of object choreography.
    IEEE Systems Journal. 2017; 12(2):1655-66. [Crossref] [Google Scholar] [115]De
    DM, Giaretta A, Dragoni N, Bucchiarone A, Mazzara M. Cyber-storms come from clouds:
    security of cloud computing in the IoT era. Future Internet. 2019; 11(6):1-30.
    [Crossref] [Google Scholar] [116]Rath M, Satpathy J, Oreku GS. Artificial intelligence
    and machine learning applications in cloud computing and internet of things. In
    artificial intelligence to solve pervasive internet of things issues 2021 (pp.
    103-23). Academic Press. [Crossref] [Google Scholar] [117]Farahzadi A, Shams P,
    Rezazadeh J, Farahbakhsh R. Middleware technologies for cloud of things: a survey.
    Digital Communications and Networks. 2018; 4(3):176-88. [Crossref] [Google Scholar]
    [118]Sethi P, Sarangi SR. Internet of things: architectures, protocols, and applications.
    Journal of Electrical and Computer Engineering. 2017; 2017:1-26. [Crossref] [Google
    Scholar] [119]Sonkoly B, Haja D, Németh B, Szalay M, Czentye J, Szabó R, et al.
    Scalable edge cloud platforms for IoT services. Journal of Network and Computer
    Applications. 2020; 170:1-18. [Crossref] [Google Scholar] [120]Ray PP. A survey
    of IoT cloud platforms. Future Computing and Informatics Journal. 2016; 1(1-2):35-46.
    [Crossref] [Google Scholar] [121]Hoffmann JB, Heimes P, Senel S. IoT platforms
    for the internet of production. IEEE Internet of Things Journal. 2018; 6(3):4098-105.
    [Crossref] [Google Scholar] [122]Ray PP, Kumar N. SDN/NFV architectures for edge-cloud
    oriented IoT: a systematic review. Computer Communications. 2021; 169:129-53.
    [Crossref] [Google Scholar] [123]Lu Y, Xu X. Cloud-based manufacturing equipment
    and big data analytics to enable on-demand manufacturing services. Robotics and
    Computer-Integrated Manufacturing. 2019; 57:92-102. [Crossref] [Google Scholar]
    [124]Alam M, Ara K, Javed MS, Ansari M. Detect and filter traffic attack through
    cloud trace back and neural network, imperial college. In the 2014 international
    conference of data mining and knowledge engineering London, UK 2014 (pp. 2-4).
    [Google Scholar] [125]Noura M, Atiquzzaman M, Gaedke M. Interoperability in internet
    of things: taxonomies and open challenges. Mobile Networks and Applications. 2019;
    24(3):796-809. [Crossref] [Google Scholar] [126]Gill SS, Tuli S, Xu M, Singh I,
    Singh KV, Lindsay D, et al. Transformative effects of IoT, blockchain and artificial
    intelligence on cloud computing: evolution, vision, trends and open challenges.
    Internet of Things. 2019; 8:1-33. [Crossref] [Google Scholar] [127]Adi E, Anwar
    A, Baig Z, Zeadally S. Machine learning and data analytics for the IoT. Neural
    Computing and Applications. 2020; 32(20):16205-33. [Crossref] [Google Scholar]
    [128]Savaglio C, Fortino G, Gravina R, Russo W. A methodology for integrating
    internet of things platforms. In IEEE international conference on cloud engineering
    2018 (pp. 317-22). IEEE. [Crossref] [Google Scholar] Terms & Conditions Privacy
    Policy Support us Advertise with us FAQ Feedback Invitation E-mail Alert Facebook
    Twitter Linked In © ACCENTS. All rights reserved.'
  inline_citation: '>'
  journal: International journal of advanced technology and engineering exploration
  limitations: '>'
  pdf_link: https://www.accentsjournals.org/PaperDirectory/Journal/IJATEE/2022/12/10.pdf
  publication_year: 2022
  relevance_score1: 0
  relevance_score2: 0
  title: 'Internet of things (IoT) fusion with cloud computing: current research and
    future direction'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'

- analysis: '>'
  authors:
  - Zhaxalikov A.
  - Mombekov A.
  - Sotsial Z.
  citation_count: '0'
  description: This research paper aims to design an energy-efficient surveillance
    camera utilizing the ESP32-CAM module, incorporating Wi-Fi connectivity, and using
    3D printed custom case made from ABS plastic. The central goal is to determine
    the most effective video streaming protocol for transmitting real-time data to
    a web-based interface that manages the camera. The camera prototype is developed
    through a technical feasibility study and prototype construction methods, with
    a primary focus on assessing power consumption across various protocols including
    HTTP, RTP, RTSP, and WebSocket. The findings indicate that WebSocket emerges as
    one of the most optimal and power-efficient protocols for streaming video from
    the ESP32-CAM web server to a client device. This superiority arises from WebSocket's
    browser-based approach, enabling full-duplex communication through a single TCP
    connection, thereby facilitating real-time interaction between the client and
    server.
  doi: 10.1016/j.procs.2023.12.147
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords References Procedia Computer Science Volume 231, 2024,
    Pages 721-726 Surveillance Camera Using Wi-Fi Connection Author links open overlay
    panel Arnas Zhaxalikov a, Alibek Mombekov a, Zhuldyz Sotsial a Show more Add to
    Mendeley Share Cite https://doi.org/10.1016/j.procs.2023.12.147 Get rights and
    content Under a Creative Commons license open access Abstract This research paper
    aims to design an energy-efficient surveillance camera utilizing the ESP32-CAM
    module, incorporating Wi-Fi connectivity, and using 3D printed custom case made
    from ABS plastic. The central goal is to determine the most effective video streaming
    protocol for transmitting real-time data to a web-based interface that manages
    the camera. The camera prototype is developed through a technical feasibility
    study and prototype construction methods, with a primary focus on assessing power
    consumption across various protocols including HTTP, RTP, RTSP, and WebSocket.
    The findings indicate that WebSocket emerges as one of the most optimal and power-efficient
    protocols for streaming video from the ESP32-CAM web server to a client device.
    This superiority arises from WebSocket''s browser-based approach, enabling full-duplex
    communication through a single TCP connection, thereby facilitating real-time
    interaction between the client and server. Previous article in issue Next article
    in issue Keywords networkprotocolsmicrocontrollerserverIPWeb SocketHTTPclient
    View PDF References [1] B. Dietrich, S. Iff, J. Profelt, T. Albers, K. Blaschke
    Development of a local air surveillance system for security purposes: design and
    core characteristics European Journal for Security Research, 2 (2017), pp. 71-81
    CrossRefGoogle Scholar [2] H.T. Nguyen, B. Bhanu, A. Patel, R. Diaz Design and
    optimization of the videoweb wireless camera network EURASIP Journal on Image
    and Video Processing (2010), pp. 1-13 2010 CrossRefGoogle Scholar [3] P. Selvam,
    K. Nikhil, R. Ranjitha, A. Mounika, S. Reddy, S. Reddy Surveillance monitoring
    using ESP32-CAM module International journal of creative research thoughts (2022)
    Google Scholar [4] Y. Ye, S. Ci, A.K. Katsaggelos, Y. Liu, Y. Qian Wireless video
    surveillance: A survey IEEE Access, 1 (2013), pp. 646-660 View in ScopusGoogle
    Scholar [5] D. Miljković Active noise control: From analog to digital—last 80
    years 2016 39th International Convention on Information and Communication Technology,
    Electronics and Microelectronics (MIPRO), IEEE (2016), pp. 1151-1156 View in ScopusGoogle
    Scholar [6] R. Alshalawi, M.O. Khozium A case study of IP camera monitoring traffic
    verification International Journal of Advanced Research, 8 (12) (2020), pp. 1-11
    View in ScopusGoogle Scholar [7] M. Spadacini, S. Savazzi, M. Nicoli Wireless
    home automation networks for indoor surveillance: technologies and experiments
    EURASIP Journal on Wireless Communications and Networking (2014), pp. 1-17 2014
    Google Scholar [8] O. Elharrouss, N. Almaadeed, S. Al-Maadeed A review of video
    surveillance systems Journal of Visual Communication and Image Representation,
    77 (2021), Article 103116 View PDFView articleView in ScopusGoogle Scholar [9]
    A.I. Adrian, P. Ismet, P. Petru An overview of intelligent surveillance systems
    development 2018 International Symposium on Electronics and Telecommunications
    (ISETC), IEEE (2018), pp. 1-6 CrossRefView in ScopusGoogle Scholar [10] V. Tsakanikas,
    T. Dagiuklas Video surveillance systems-current status and future trends Computers
    & Electrical Engineering, 70 (2018), pp. 736-753 View PDFView articleView in ScopusGoogle
    Scholar Cited by (0) © 2023 The Author(s). Published by Elsevier B.V. Part of
    special issue 14th International Conference on Emerging Ubiquitous Systems and
    Pervasive Networks / 13th International Conference on Current and Future Trends
    of Information and Communication Technologies in Healthcare (EUSPN/ICTH 2023)
    Edited by Elhadi Shakshuki Download full issue Other articles from this issue
    ContractArmor: Attack Surface Generator for Smart Contracts 2024 Ferda Özdemir
    Sönmez, William J. Knottenbelt View PDF Automatic Accident Detection System Using
    IoT Compared to the Systems that a Traffic Centre Uses for Accident Detection
    2024 Dimitrios Zavantis, …, Lumbarda Hasimi View PDF Bundle AI: An Application
    of Multiple Constraint Knapsack Problem (MCKP) Through Genetic Algorithm (GA)
    2024 Angel Nicole Carloman, …, Orven E.Llantos View PDF View more articles Recommended
    articles About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Procedia Computer Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Surveillance Camera Using Wi-Fi Connection
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Windisch D.
  - Kelling J.
  - Juckeland G.
  - Bieberle A.
  citation_count: '1'
  description: 'In this article, a new version of the Real-time Image Stream Algorithms
    (RISA) data processing suite is introduced. It now features online detector data
    acquisition, high-throughput data dumping and enhanced real-time data processing
    capabilities. The achieved low-latency real-time data processing extends the application
    of ultrafast electron beam X-ray computed tomography (UFXCT) scanners to real-time
    scanner control and process control. We implemented high performance data packet
    reception based on data plane development kit (DPDK) and high-throughput data
    storing using both hierarchical data format version 5 (HDF5) as well as the adaptable
    input/output system version 2 (ADIOS2). Furthermore, we extended RISA''s underlying
    pipelining framework to support the fork-join paradigm. This allows for more complex
    workflows as it is necessary, e.g. for online data processing. Also, the pipeline
    configuration is moved from compile-time to runtime, i.e. processing stages and
    their interconnections can now be configured using a configuration file. In several
    benchmarks, RISA is profiled regarding data acquisition performance, data storage
    throughput and overall processing latency. We found that using direct IO mode
    significantly improves data writing performance on the local data storage. We
    could further prove that RISA is now capable of concurrently receiving, processing
    and storing data from up to 768 detector channels (3072 MB/s) at 8000 fps on a
    single-GPU computer in real-time. Program summary: Program Title: GLADOS/RISA
    CPC Library link to program files: https://doi.org/10.17632/65sx747rvm.2 Developer''s
    repository link: https://codebase.helmholtz.cloud/risa Licensing provisions: Apache-2.0
    Programming language: C++ Journal reference of previous version: Comput. Phys.
    Commun. 219 (2017) 353-360 [1] Does the new version supersede the previous version?:
    Yes. Reasons for the new version: Extended capabilities for real-time operation
    with latest UFXCT hardware. Summary of revisions: (i) Add forking and joining
    of processing pipeline branches (ii) Add runtime (re-)configuration of pipeline
    stages and connections (iii) Add UDP receiver stage to acquire detector data in
    real-time (iv) Add high-throughput data dumping Nature of problem: Ultrafast electron
    beam X-ray computed tomography scanners stream multiple Gigabytes of raw data
    per second via Ethernet to a control computer. Receiving the data with low latency,
    real-time image-based control would become possible. For this, data need to be
    captured from the network, stored on disk, reconstructed and post-processed concurrently.
    The current total data rate of up to 3072 MB/s requires high-throughput solutions
    for each of these tasks. Solution method: Using a pipeline scheme, RISA processes
    incoming raw data in distinct stages (sources, processors, sinks). These are implemented
    in GPU kernels and are executed concurrently to exploit data parallelism as well
    as task parallelism. To capture detector data, we implemented a UDP packet capturing
    stage based on DPDK [2] which acts as a source stage. By allowing the pipeline
    to fork up into multiple branches, we concurrently acquire, store and process
    the data. For storing these data, we use the HDF5 format [3]. We achieve the required
    data rates by writing in direct IO mode onto an SSD array in RAID 0 configuration.
    Additional comments including restrictions and unusual features: RISA provides
    a set of general-purpose processing stages which are suitable for generic image
    stream processing. References: [1] Frust T., et al., Comput. Phys. Commun. 219
    (2017) 353-360 [2] Data Plane Development Kit, https://www.dpdk.org/ [3] Hierarchical
    Data Format Version 5, https://www.hdfgroup.org/solutions/hdf5/'
  doi: 10.1016/j.cpc.2023.108719
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. State of the art and related work
    3. Implementation of the online data-processing software 4. Performance analysis
    5. Summary and conclusions CRediT authorship contribution statement Declaration
    of Competing Interest Acknowledgements Data availability References Show full
    outline Cited by (1) Figures (16) Show 10 more figures Tables (2) Table 1 Table
    2 Computer Physics Communications Volume 287, June 2023, 108719 Real-time data
    processing for ultrafast X-ray computed tomography using modular CUDA based pipelines☆,☆☆
    Author links open overlay panel Dominic Windisch a, Jeffrey Kelling b, Guido Juckeland
    b, André Bieberle b Show more Share Cite https://doi.org/10.1016/j.cpc.2023.108719
    Get rights and content Under a Creative Commons license open access Abstract In
    this article, a new version of the Real-time Image Stream Algorithms (RISA) data
    processing suite is introduced. It now features online detector data acquisition,
    high-throughput data dumping and enhanced real-time data processing capabilities.
    The achieved low-latency real-time data processing extends the application of
    ultrafast electron beam X-ray computed tomography (UFXCT) scanners to real-time
    scanner control and process control. We implemented high performance data packet
    reception based on data plane development kit (DPDK) and high-throughput data
    storing using both hierarchical data format version 5 (HDF5) as well as the adaptable
    input/output system version 2 (ADIOS2). Furthermore, we extended RISA''s underlying
    pipelining framework to support the fork-join paradigm. This allows for more complex
    workflows as it is necessary, e.g. for online data processing. Also, the pipeline
    configuration is moved from compile-time to runtime, i.e. processing stages and
    their interconnections can now be configured using a configuration file. In several
    benchmarks, RISA is profiled regarding data acquisition performance, data storage
    throughput and overall processing latency. We found that using direct IO mode
    significantly improves data writing performance on the local data storage. We
    could further prove that RISA is now capable of concurrently receiving, processing
    and storing data from up to 768 detector channels (3072 MB/s) at 8000 fps on a
    single-GPU computer in real-time. Program summary Program Title: GLADOS/RISA CPC
    Library link to program files: https://doi.org/10.17632/65sx747rvm.2 Developer''s
    repository link: https://codebase.helmholtz.cloud/risa Licensing provisions: Apache-2.0
    Programming language: C++ Journal reference of previous version: Comput. Phys.
    Commun. 219 (2017) 353-360 [1] Does the new version supersede the previous version?:
    Yes. Reasons for the new version: Extended capabilities for real-time operation
    with latest UFXCT hardware. Summary of revisions: (i) Add forking and joining
    of processing pipeline branches (ii) Add runtime (re-)configuration of pipeline
    stages and connections (iii) Add UDP receiver stage to acquire detector data in
    real-time (iv) Add high-throughput data dumping Nature of problem: Ultrafast electron
    beam X-ray computed tomography scanners stream multiple Gigabytes of raw data
    per second via Ethernet to a control computer. Receiving the data with low latency,
    real-time image-based control would become possible. For this, data need to be
    captured from the network, stored on disk, reconstructed and post-processed concurrently.
    The current total data rate of up to 3072 MB/s requires high-throughput solutions
    for each of these tasks. Solution method: Using a pipeline scheme, RISA processes
    incoming raw data in distinct stages (sources, processors, sinks). These are implemented
    in GPU kernels and are executed concurrently to exploit data parallelism as well
    as task parallelism. To capture detector data, we implemented a UDP packet capturing
    stage based on DPDK [2] which acts as a source stage. By allowing the pipeline
    to fork up into multiple branches, we concurrently acquire, store and process
    the data. For storing these data, we use the HDF5 format [3]. We achieve the required
    data rates by writing in direct IO mode onto an SSD array in RAID 0 configuration.
    Additional comments including restrictions and unusual features: RISA provides
    a set of general-purpose processing stages which are suitable for generic image
    stream processing. References [1] Frust T., et al., Comput. Phys. Commun. 219
    (2017) 353-360 [2] Data Plane Development Kit, https://www.dpdk.org/ [3] Hierarchical
    Data Format Version 5, https://www.hdfgroup.org/solutions/hdf5/ Previous article
    in issue Next article in issue Keywords Real-time analysisHigh-speed imagingData
    processing pipelineImage stream processing 1. Introduction Ultrafast X-ray computed
    tomography (UFXCT) is a sophisticated imaging technique primarily used for non-invasive
    investigations of multi-phase flows to enhance fundamental understanding of complex
    flows in technical apparatuses. In the past, UFXCT was successfully applied in
    many fields of investigation, e.g. bubbly flow in bubble column reactors [1],
    [2], [3], gas-liquid distribution in centrifugal pumps [4], packed bed reactors
    [5] and fluidized beds [6]. A novel application for UFXCT is dynamic object tracking
    by adapting the scanner position based on real-time evaluated images as conceptualized
    in [7]. UFXCT was initially introduced in [8]. It is based on deflecting an electron
    beam along a semicircular tungsten target. Upon hitting the target, an X-ray radiation
    source spot is created which then moves along one of two circular paths on the
    target. The electron beam is deflected at up to 8000 Hz. Concentric to the target,
    X-ray sensitive detector pixels are statically arranged in form of two rings defining
    two discrete scanning planes. As the detector pixels are constantly sampled at
    a frequency of 2 MHz, projections from different angular source positions can
    be acquired without any mechanical movement. These projections are finally used
    to reconstruct non-superimposed cross-sectional images. Tracking passing objects
    between both imaging planes, e.g. rising gas bubbles, allows determining their
    axial velocities. Up to now, the detector electronics are operated in so-called
    offline mode. That is, while scanning, data are temporarily stored on the detector
    hardware and only after finishing the entire scan, data can be downloaded and
    reconstructed afterwards. This leaves the UFXCT system with a couple of limitations:
    • total acquisition duration is limited to 30 seconds by the available memory
    of 2 GB per detector module; • real-time imaging and also real-time image-based
    control is not possible because data are available only after finishing the scan;
    and • sequentially downloading the data after each scan increases turn-around
    time between consecutive scans. Thus, UFXCT would greatly benefit from operating
    in so-called online mode, i.e. transferring and processing the detector data in
    real-time (as sketched in Fig. 1). With this, novel applications like dynamic
    image-based control of both the scanner and the scanned process become possible.
    To achieve this operating mode we need to: • modify the detector hardware to transfer
    its data during scanning, • simultaneously acquire and store detector data in
    real-time, and • concurrently reconstruct and analyze the detector data. Download
    : Download high-res image (182KB) Download : Download full-size image Fig. 1.
    Processing steps from acquiring a raw sinogram to reconstructing the image in
    online mode. The necessary detector hardware modifications were already realized
    [9]. This article presents the latest developments in the corresponding data processing
    suite RISA (Real-time Image Stream Algorithms) with respect to real-time operation.
    The updated RISA code is applicable for both current and next generation UFXCT
    systems with more detector channels than today. Moreover, its modular architecture
    qualifies RISA as a general-purpose image processing suite for further imaging
    techniques like wire-mesh sensors [10], micro-focus CT [11] or video camera streams.
    However, our explicit design goals are defined as: 1. Capturing incoming detector
    data without loss in a flexible and scalable way for application on different
    detector configurations. We target processing data from up to 768 detector channels
    (3072 MB/s in total). 2. Assembling up to 8000 fps from the incoming detector
    data, then reconstructing and post-processing the data with low latency such that
    image-based control algorithms can be employed. The goal is a total latency below
    5 ms which was shown to be suitable for image-based object tracking in [7]. 3.
    Concurrently storing the assembled projection data (see “FanSinogram” in Fig.
    1) on fast local storage such that data can be archived and analyzed after the
    scan. After reviewing the state of the art in section 2, we describe the extended
    pipelining framework (section 3.1) and data processing pipeline (section 3.2)
    with subsections on data transmission, storage and processing. Finally, corresponding
    performance benchmarks are evaluated in section 4. 2. State of the art and related
    work UFXCT detectors comprise multiple detector modules. Each module contains
    16 X-ray sensitive pixels whose signals are constantly sampled with 2 MS/s at
    16 bit depth yielding a total data rate of 512 MBit/s (64 MB/s) per module. Up
    to 48 modules are used in one detector assembly. Sampling, digitization and data
    handling are controlled by a field-programmable gate array (FPGA) on each module.
    The detector modules are connected to a control PC using a 48x1 GbE to 1x40 GbE
    network switch (HUAWEI CE5850-48T4S2Q-HI). A proprietary software controls data
    download and electron beam deflection. With the latest detector hardware implementation
    shown in [9], the detector modules now operate in online mode, i.e. sending their
    data as UDP packets with a latency below 1 μs. Transmitting the data via network
    adds an additional delay as calculated using (1) with S Bytes payload data per
    packet, H Bytes of overhead per packet (for protocol headers) and C Bytes per
    second network speed. Using UDP/IPv4 packets over 1 GbE, i.e. C = 125 MB/s and
    H = 46 B, equation (1) yields a delay between 2 μs and 72 μs for the range of
    supported packet sizes S (160 B to 8992 B). Transmission delay is therefore negligible
    with respect to the goal of a total delay less than 5 ms. Combining detector data
    from multiple detector modules and projection source angles, so-called sinograms
    are composed (see Fig. 1). After a series of pre-processing steps, data of each
    raw sinogram is used to reconstruct one cross-sectional image as shown in Fig.
    1 using filtered backprojection (FBP). The basis for the required real-time data
    processing code was introduced in [12]. There, it was shown that a single-GPU
    system can provide the required computing power for real-time image reconstruction
    using a GPU-based pipeline approach. However, lacking an online mode detector,
    real-time performance could not be tested yet. Furthermore, additional requirements
    arise from online operation: 1. Receiving Ethernet packets from multiple senders
    requires high performance packet processing to sort the intertwined data streams
    back into coherent data arrays, i.e. sinograms. 2. Data processing needs to be
    controllable asynchronously during execution to tune parameters, trigger events
    (e.g. storing of data) and stop the program dynamically. 3. Data need to be processed
    and stored simultaneously to allow for both in-situ as well as post-scan data
    processing. Therefore, forking and joining multiple concurrent pipeline streams
    is required. 4. Meta-data (e.g. scanner settings, experiment parameters) and optional
    further data streams (e.g. sensor data sampled synchronously to the image data)
    must be stored alongside acquired detector data for post-scan data interpretation.
    Related work for these requirements is discussed in sections 2.1 to 2.3. 2.1.
    Network packet handling Detector data is transferred as one stream of UDP packets
    per detector module. For detector modules generating G Bytes per second and a
    configured packet size of S Bytes, the total rate of packets per second R is calculated
    by (2) Equation (2) yields a maximum expected packet rate of 19.2 Mpps for , MB/s
    and B which is the smallest configurable packet size. Handling such large numbers
    of Ethernet packets on a general purpose CPU is not straightforward. Receiving
    a single Ethernet packet using the default network stack takes up to 10000 CPU
    cycles, allowing a maximum sustained packet rate of about 0.3 Mpps on a 3 GHz
    CPU [13]. For high-performance applications, it is therefore common to move away
    from the operating system''s default network stack which generally relies on interrupts
    and requires computationally costly transitions between user-space and kernel-space.
    There are different approaches to increase performance of network packet processing,
    e.g. • moving the application into kernel-space; • communicating with a special
    kernel module via shared memory (e.g. netmap [14]); or • user-space network interface
    card (NIC) drivers with direct communication to the NIC (e.g. data plane development
    kit (DPDK) [15], Snabb [16]). From these approaches, user-space drivers generally
    provide the best performance with up to 78 Mpps per thread [17]. Of these, DPDK
    already supports most high-speed (i.e. ≥10 GBit/s) NICs [18]. The drawbacks with
    respect to the standard network stack are potentially more complicated APIs and
    restricting access to the NIC to a single application. In our case, the NICs receive
    queue only needs to be accessed by RISA. We therefore decided to use DPDK for
    network packet handling (see section 3.2.1). 2.2. Parallel pipelining frameworks
    Processing data streams in a set of discrete processing steps, which can be executed
    concurrently on consecutive elements of the stream, can significantly increase
    compute resource utilization and therefore overall performance. Similarly, processing
    multiple parts of a stream element, i.e. individual pixels in an image stream,
    parallelly within one processing step can increase throughput significantly. These
    concepts are combined in GPU-based stream processing frameworks which provide
    memory management, pipeline definition and execution. Existing frameworks (e.g.
    [12], [19], [20], [21], [22], [23], [24], [25], [26], [27]) target a variety of
    use-cases with vastly different characteristics regarding targeted hardware, data
    structure, throughput, latency, flexibility and ease-of-use. Real-time control
    using UFXCT, however, requires a high-throughput, low-latency solution which can
    only be achieved using a local compute node. Unfortunately, solutions for standalone
    real-time data stream processing using GPUs are sparse and often specifically
    designed for the use-case (e.g. [28], [29]). Consequently, there is no de-facto
    standard framework for such applications. From available frameworks, both the
    Generic Library for Asynchronous Data Operations and Streaming framework (GLADOS,
    [12]), which is already used in the first version of RISA, and the UFO framework
    [25], [26] are potential candidates. RISA currently implements stages for GLADOS,
    which provides a pipeline framework for user-defined pipeline stage implementations
    in the C++ language. GLADOS supports execution of stages on both the host and/or
    CUDA-capable devices, i.e. GPUs. For this, GLADOS implements a memory pool manager
    which supports both host memory and device memory and allows passing references
    to either one between stages. In its current version, GLADOS stages may only consume
    one input stream and produce a single output stream, i.e. forking or joining of
    streams is not supported. The configuration of a pipeline is static only allowing
    for compile-time configuration. A similar open-source framework, called UFO, was
    introduced by Vogelgesang et al. in [25], [26]. Initially developed for high-speed
    real-time image processing for synchroton radiation imaging, UFO provides a pipelining
    framework (“ufo-core”) alongside stage implementations for data acquisition and
    processing (“ufo-filters”). UFO is implemented in C using glib for object oriented
    programming and OpenCL for execution on co-processor devices like GPUs. It supports
    joining of streams and offers limited support for forking providing a copy stage.
    Asynchronous control is provided using GObject introspection. Neither framework
    is applicable for real-time operation on UFXCT data in its current version. Therefore,
    we decided to extend the GLADOS framework (see section 3.1) because the required
    modifications can be implemented with native C++ features without relying on an
    external library like glib. This way, we can also re-use and extend many already
    implemented CUDA kernels from the initial RISA version (see section 3.2) which
    already cover most UFXCT-specific processing steps. 2.3. Data storage frameworks
    The received data from the UFXCT detector should be stored in a commonly available
    format which also allows for storing multiple data streams alongside meta-data
    within one data container. One commonly used framework for such requirements is
    the adaptable input/output system version 2 (ADIOS2) [30]. It is based on writing
    data in a step-based manner. Within such a step, all the respective data (e.g.
    the current sinogram along of reading additional sensors) can be stored. Additionally,
    meta-data can be added as attributes within the file. ADIOS2 provides high-level
    APIs in C++, Python and Matlab for reading and writing structured data and meta-data
    on top of engines targeting storage formats like its native binary-pack version
    4 (BP4) or HDF5 or transports for streaming data. Another widely used format is
    the hierarchic data format version 5 (HDF5) [31]. It also allows to store datasets
    (or groups thereof) alongside meta-data. There are HDF5 implementations available
    for many programming and scripting languages. For our processing pipeline, we
    implemented both an ADIOS2 and an HDF5 data dumper (see section 3.2.2). 3. Implementation
    of the online data-processing software 3.1. Enhanced pipelining framework - GLADOS
    3.1.1. Fork-join paradigm We extended GLADOS to support the fork-join paradigm.
    With this, each pipeline stage may produce one or more output streams and consume
    one or more input streams. For this, each stage exposes a given number of input
    and output ports which are implemented as separate thread-safe queues. To associate
    the appropriate ports, the previously created stages can be connected as shown
    in Listing 1. Download : Download high-res image (64KB) Download : Download full-size
    image Listing 1. GLADOS pipeline creation and execution. 3.1.2. Observer pattern
    The second enhancement of GLADOS is the support of the observer pattern. For this,
    a so-called subject holds a list of observers that will be notified immediately
    about state changes. Every pipeline stage can act as an observer by implementing
    an update(glados::Subject s) method, which can be called asynchronously to update
    stage parameters. With this, the configured data processing pipeline can be controlled
    and reconfigured at runtime after the initial configuration. To control the pipeline
    using runtime configuration files, we added a FileObserver subject. It monitors
    a file for changes and notifies all its attached observers, i.e. stage implementations,
    about changes to the file contents by calling their update method. These then
    perform implementation-specific actions, e.g. update filter values, start or stop
    dumping data to disk or set a stop flag. Listing 2 shows how to establish the
    subject-observer-relation. Download : Download high-res image (64KB) Download
    : Download full-size image Listing 2. Establishing the subject-observer relations.
    3.2. Data processing and storage - RISA The Real-time Image Stream Algorithms
    (RISA) framework implements different processing stages and runtime pipeline building
    on top of GLADOS. The new version now includes support for multiple inputs and
    outputs on many stage implementations as well as runtime reconfiguration using
    the subject-observer capabilities of GLADOS. Additionally, stage implementations
    are moved into separate RISA-compatible shared libraries which are loaded at runtime.
    RISA defines an interface for implementing RISA-compatible libraries. This allows
    a more flexible deployment and licensing of (possibly proprietary) processing
    steps in precompiled library files. An overview of currently implemented stages
    is given in Table 1. Table 1. Overview of implemented stages in RISA. Library
    Category Description libRISA_Core Generic image processing Masking, filtering,
    Fourier-transform, matrix operations Long-term storage Write complete 2D image
    stream into multipage TIFF files Short-term storage Write latest image as JPEG
    preview or in shared host memory  libRISA_UFXCT UFXCT offline loader Loading proprietary
    UFXCT raw data formats UFXCT online loader Capture UDP packets streamed from detector
    (see section 3.2.1) UFXCT image reconstruction Resorting, pre-processing, error
    correction and backprojection  libRISA_ROOF Control Image segmentation, object
    recognition and image-based control The initial version of RISA [12] defined a
    static pipeline configuration at compile time. For a more flexible and user-friendly
    operation we moved to runtime pipeline configuration. For this, we added a utility
    to create, connect, validate, and execute a user-defined pipeline based on a configuration
    file parsed at runtime. Listing 3 shows a minimal working example of RISA. Download
    : Download high-res image (40KB) Download : Download full-size image Listing 3.
    Minimal implementation of the RISA runtime pipeline configuration. 3.2.1. Data
    reception To retrieve UDP packets from the network interface card (NIC) and compose
    sinograms from the payload data, a new source stage UDPLoader is implemented.
    Retrieving the packets from the NIC uses the Data Plane Development Kit (DPDK).
    It takes exclusive control of the NICs receive queue using a user-space driver
    with direct hardware access. This bypasses the operating systems network stack
    for all received Ethernet packets. Conversely, only a few configuration commands
    need to be sent to the detector modules and therefore do not need high performance
    packet sending. For this reason, the NICs transmission queue remains controlled
    by the operating system allowing for easier sending of configuration and control
    messages to the detector modules using the familiar AF_INET sockets. DPDK is used
    within the UDPLoader which consumes one stream of UDP packets per detector module
    and reassembles the payload data into sinograms. The flow of data is structured
    as shown in Fig. 2. The NIC is configured to use one DPDK receive queue using
    rte_eth_rx_queue_setup during its initialization. After starting the receive queue
    with rte_eth_dev_start, Ethernet frames are received on the NIC and buffered in
    its receive queue located in pinned memory. New messages are polled from the NIC
    using the rte_eth_rx_burst() function of DPDK which runs in a pinned, real-time
    scheduled thread. The received messages are returned as rte_membuf objects which
    include basic meta data, such as the total length of the message. Further meta
    data, such as the senders IP address and the UDP header fields can be easily accessed
    using their respective byte offset directly on the Ethernet frame''s raw data.
    The FPGAs send an 8-byte incrementing packet ID in the beginning of the UDP payload.
    Given this packet ID as well as the senders IP address, the remaining payload
    of data is copied into its respective position in the sinogram buffer. With each
    copied patch of data, the counter of completed parts per sinogram is incremented.
    When all parts of a sinogram are filled, the complete sinogram is copied into
    an image buffer on the GPU asynchronously. Afterwards, the glados::Image object
    holding the data is pushed into the processing queue. From this queue, images
    are taken using glados::Queue::take() to be processed by the connected processing
    stage. Download : Download high-res image (407KB) Download : Download full-size
    image Fig. 2. Data flow from receiving Ethernet packets to pushing frames into
    the processing pipeline. 3.2.2. Data storing Besides copying raw data from the
    sinogram buffer in host memory to the device memory as shown in Fig. 2, raw data
    may also be stored on disk concurrently. For that, two data dumpers are implemented
    in RISA. First, an ADIOS2 dumper using its native data format BP4. As shown in
    Listing 4, it writes two fixed size adios::variables: the raw data and its respective
    index. Download : Download high-res image (86KB) Download : Download full-size
    image Listing 4. Implementation of data dumping with ADIOS2. The second implemented
    data dumper uses the HDF5 library. To write data in a similar step-wise approach,
    the data fields are written in so-called chunks. The chunk size is set to the
    size of a single sinogram. This way, for each new acquired sinogram, the dataset
    is extended by one chunk and the new data is appended to the existing variable.
    The sinogram IDs are written in a similar manner. Download : Download high-res
    image (139KB) Download : Download full-size image Listing 5. Implementation of
    data dumping using HDF5. 3.2.3. Real-time image analysis and process control With
    the updated GLADOS capabilities the real-time data processing and image reconstruction
    pipeline configuration is enhanced as sketched in Fig. 3. Download : Download
    high-res image (244KB) Download : Download full-size image Fig. 3. Processing
    pipeline for real-time image reconstruction. Gray background indicates processing
    stages running on GPU. Dashed arrows are optional paths ((1): store data, (2):
    download reconstructed images from GPU, (3) post-process data). Being able to
    join multiple streams, loading of reference and dark signals becomes now dynamic,
    i.e. these signals are loaded as image streams instead of statically loading files
    as in the initial RISA version (see Fig. 1). This generic approach not only allows
    to pre-process the data more dynamically but also allows dynamically loading reference
    datasets, e.g. for a scanner-position dependent reference signal. Also, defect
    detector pixels can now be identified and interpolated dynamically. Using the
    new subject-observer feature of GLADOS, the pipeline stages can now be controlled
    during its execution. This enables triggering of data storing (see (1) in Fig.
    3) and modification of stage settings past the initial configuration. The reconstructed
    images can be downloaded from the GPU into shared memory to be displayed in a
    GUI, stored in long-term storage (see (2) in Fig. 3) or post-processed (see (3)
    in Fig. 3). Depending on the experiment, online post-processing may be essential,
    e.g. when image-based control is required. To extract necessary information from
    the images in real-time, RISA provides a set of general purpose image processing
    stages. Since the usage of these stages may differ widely between experiments,
    we shall only show two possible example configurations in Fig. 4, Fig. 5. Note
    that the image reconstruction (as shown in Fig. 3) is not shown in detail. Download
    : Download high-res image (145KB) Download : Download full-size image Fig. 4.
    Example post processing configuration: subtract background from image and apply
    filter and mask to get a region of interest. Download : Download high-res image
    (139KB) Download : Download full-size image Fig. 5. Example post processing configuration:
    apply dynamic image mask followed by laplace filter to get edges of the image.
    4. Performance analysis The performance benchmarks were evaluated on a computer
    primary configured with components for maximum PCIe bus performance, i.e. using
    PCIe version 4 and providing non-shared lanes for each PCIe device (GPU, NIC and
    RAID). An SSD RAID system with four M.2 SSDs was setup to achieve sufficient sustained
    write speed for storing the incoming data flow. Main specifications are listed
    in Table 2. Table 2. Benchmark system specifications. Component Specification
    CPU AMD EPYC 7343 (16 × 3.9 GHz) GPU NVIDIA GTX 3080 (10 GB VRAM) Mainboard Supermicro
    H12SSL-i NIC Mellanox ConnectX-5 RAM 4 x 32 GB Samsung M393A4K40DB3-CWE (DDR4,
    3200 MHz) RAID Controller HighPoint SSD7505 with 4x Samsung 980 PRO 2TB NVME M.2
    SSD OS Ubuntu 20.04 (5.13.0-27-generic) GCC 10.3.0 NVCC 11.6 CUDA driver 510.47.03
    The data was generated in a testbench configuration containing up to 48 FPGA modules
    (as described in [9]) connected to a HUAWEI CE5850-48T4S2Q-HI network switch.
    These FPGA modules are functionally equivalent to actual UFXCT detector modules
    but generate only dummy data, however, with the parameters described above (2
    MS/s, 16 bit per channel, 16 channels per FPGA module). Unless otherwise stated,
    for each benchmark, we ran the default reconstruction pipeline as shown in Fig.
    3 for 60 s using a scan rate of 2000 Hz and a reconstruction image grid of pixels.
    In our benchmarks, we profiled • data transmission to uncover the optimal UDP
    packet size, • data acquisition to evaluate the data dumpers performance, • latency
    to evaluate real-time analysis suitability, and • GPU utilization to assess processing
    capacity. 4.1. Data transmission Loss-free data transmission is the basis for
    operating the UFXCT in online mode. The total data rate is determined by the number
    of detector modules with their fixed data rate of 64 MB/s each. However, the UDP
    packet size for data transfer is configurable. Sorting of packets into sinograms
    requires a packet size such that the number of samples per sinogram is divisible
    by the number of samples per packet. This prevents multiple copies from the sinogram
    data buffer. Using our typical scan rate of 2000 Hz, we acquire samples per sinogram.
    Therefore, we evaluated the transmission performance for these suitable packet
    sizes: 160 B (5 samples), 256 B (8 samples), 320 B (10 samples), 512 B (16 samples),
    640 B (20 samples), 800 B (25 samples), 1280 B (40 samples) and 8000 B (250 samples).
    Note that 1280 B and 8000 B are the largest possible packet sizes for regular
    Ethernet frames (MTU 1500) and jumbo frames (MTU 9000), respectively, that allow
    for dividing into 1000 samples without remainder. As can be seen from the results
    in Fig. 6, the overhead for UDP packet sizes below 1280 B limits the system performance
    leading to packet loss. The results for 8000 B are not shown but also achieve
    the maximum data rate of 3072 MB/s. Thus, we selected 8000 B as default packet
    size for all further benchmarks. Download : Download high-res image (48KB) Download
    : Download full-size image Fig. 6. Loss-free data rate vs. used packet size. The
    dashed line shows the target data rate of 3072 MB/s. Results for 8000 B reach
    the target rate and are omitted for clarity. 4.2. Data acquisition The SSD RAID
    array achieves a sustained write speed of about 1700 MB/s in buffered IO mode.
    However, when using direct IO, i.e. opening the file handle with O_DIRECT | O_SYNC
    flags, the sustained write speed increases to about 6000 MB/s which is sufficient
    for the real-time storage of our target data rate of 3072 MB/s. This throughput
    improvement is expected as operating system caching is bypassed. This caching
    may reduce performance when bundling writes into larger chunks (i.e. buffering)
    becomes more expensive than direct streaming from user-managed buffers. To profile
    data storage, we started the pipeline in the basic reconstruction mode (as shown
    in Fig. 3). After 10 s of execution, we triggered storing 120000 sinograms (i.e.
    a data acquisition interval of 60 s) and evaluated the stored data regarding missing
    sinograms. Results are shown as parity plot in Fig. 7. Download : Download high-res
    image (79KB) Download : Download full-size image Fig. 7. Stored vs. received data
    rate. Our benchmarks have shown that ADIOS2 cannot store data above 1700 MB/s
    on our system. This matches the sustained write speed of the used SSD RAID array
    using buffered IO. Unfortunately, using direct IO imposes restrictions on memory
    alignment, offsets within the file handle as well as write block size. Due to
    these restrictions ADIOS2 does not support direct IO for its native format BP4.
    Its successor, BP5, was released in ADIOS 2.8 and offers experimental support
    for direct IO; however, so far only with marginal performance improvements for
    our use case. The HDF5 implementation does natively support direct IO. Still,
    it is important to align the data buffers to be written, e.g. using posix_memalign
    on unix systems, for maximum performance. Any non-aligned buffers would be copied
    internally into aligned buffers which severely reduces performance. As can be
    seen from Fig. 7, the HDF5 dumper could match the incoming data rate for every
    configuration. 4.3. Latency Data from the FPGA modules are timestamped in the
    DPDK receiver thread on the first received part of a sinogram using chrono::high_resolution_clock.
    This timestamp passes the entire processing pipeline. The evaluated latency is
    defined as the duration between the start time stamp and the time stamp after
    finishing the reconstruction of the image. Note that our definition of latency
    therefore inherently includes the acquisition time per sinogram because we start
    timing on the first part of the sinogram but processing can only start after receiving
    the complete sinogram. This total latency is stored in a histogram with a class
    width of 0.1 ms. As shown in Fig. 8, latency for the default scanning rate of
    2000 Hz is about 1 ms. Looking at the distribution of latencies for different
    scan rates reveals an even latency per scan rate across a wide range of numbers
    of FPGA modules. The large latency for 1000 Hz scan rate is explained by the acquisition
    time of one sinogram which itself takes 1 ms. As explained above, this leads to
    a perceived latency increase. However, the goal of less than 5 ms latency was
    achieved for all test configurations. Download : Download high-res image (68KB)
    Download : Download full-size image Fig. 8. Latency distribution when using different
    numbers of FPGA modules in total for different scan rates. Error bars show minimum
    / maximum for 99% of measurements. 4.4. GPU utilization To evaluate the system
    processing capability, the overall GPU utilization was profiled for different
    scan rates and different numbers of detector modules. For this, we monitored the
    GPU utilization with nvidia-smi during steady-state operation of the processing
    pipeline. As can be seen in Fig. 9, with increasing scan rate, the overall GPU
    compute utilization increases; however, it does not reach 100% on the used processing
    computer. Download : Download high-res image (77KB) Download : Download full-size
    image Fig. 9. GPU resource utilization as reported by nvidia-smi for different
    scan rates. Note that results for (8 < number of FPGAs < 48) are located between
    the plotted graphs and are omitted for clarity. Contrary, the GPU memory utilization
    reduces with increasing scan rate because the raw sinogram sizes decreased with
    increasing scan rate. However, the used buffer sizes (i.e. number of elements
    per buffer) remained constant in our benchmarks. For the selected hardware configuration
    the overall GPU utilization leaves reserves for more complex pipelines. The pipeline
    buffer sizes are user configurable and can be tuned when reaching the GPU memory
    limit. 4.5. GPU utilization per kernel We further analyzed the distribution of
    necessary compute resources among the GPU kernels using nsys. In [12] the filtered
    backprojection (backProjectNearest) processing stage was evaluated as the main
    bottle neck for the total throughput of the pipeline. As shown in Fig. 10, with
    increasing size of raw data (up to px per sinogram) and a constant reconstruction
    grid size of , an increase in computing resources necessary in the evaluateDetectors
    kernel is observed. This kernel is used to identify defect detector pixels based
    on their respective signal statistics (mean, variation) compared to neighboring
    pixels which requires comparatively expensive calculations and thread synchronization
    within the GPU kernel. Download : Download high-res image (75KB) Download : Download
    full-size image Fig. 10. Relative GPU resource utilization as reported by nsys
    for different number of FPGA modules. Note that only the two kernels with the
    largest resource utilization are shown. Results for (1000 < scan rate < 8000)
    are located between the plotted graphs and are omitted for clarity. All further
    kernels required less than 10% resources. Contrary, when increasing the scan rate
    the backProjectNearest kernel again requires the most resources (see Fig. 11).
    This again is expected behavior, because backProjectNearest works on constant
    size reconstructed images with increasing frequency, whereas the total amount
    of data to analyse by evaluateDetectors remains constant for all scan rates. Download
    : Download high-res image (83KB) Download : Download full-size image Fig. 11.
    Relative GPU resource utilization as reported by nsys for different scan rates.
    Note that only the two kernels with the largest resource utilization are shown.
    Results for (8 < number of FPGAs < 48) are located between the plotted graphs
    and are omitted for clarity. All further kernels required less than 10% resources.
    For low scan rates, i.e. large sinogram sizes, it may be useful to optimize the
    evaluateDetectors kernel. 5. Summary and conclusions In this paper, we presented
    an updated version of the generic library for asynchronous data operations and
    streaming (GLADOS) and its usage for real-time data processing of ultrafast X-ray
    computed tomography in the Real-time Image Stream Algorithms (RISA) software.
    With the new capabilities of GLADOS and RISA we can now significantly extent possible
    application fields for UFXCT. The fully user-configurable processing pipeline
    can now be easily applied to real-time data acquisition, data pre- and post-processing
    and image-based control. Our benchmarks have shown consistent performance with
    image reconstruction latencies typically about 1 ms. The tested computer configuration
    captured data and reconstructed images from the maximum number of detector modules
    supported by our network switch (48 FPGA modules) with a total data transfer rate
    of up to 3072 MB/s and imaging rates up to 8000 fps. With this data processing
    setup, we are able to operate our current as well as future generation ultrafast
    X-ray CT detectors. Further, due to its generic stage implementations, RISA may
    be easily adapted for the use with other imaging techniques, e.g. wire-mesh sensors.
    CRediT authorship contribution statement Dominic Windisch: Conceptualization,
    Data curation, Investigation, Software, Validation, Visualization, Writing – original
    draft. Jeffrey Kelling: Data curation, Software, Writing – review & editing. Guido
    Juckeland: Funding acquisition, Project administration, Writing – review & editing.
    André Bieberle: Conceptualization, Funding acquisition, Project administration,
    Writing – review & editing. Declaration of Competing Interest The authors declare
    that they have no known competing financial interests or personal relationships
    that could have appeared to influence the work reported in this paper. Acknowledgements
    Financial support by Deutsche Forschungsgemeinschaft (DFG) is gratefully acknowledged
    (BI 1770/2-1). The authors acknowledge the German Federal Ministry of Education
    and Research (BMBF, 01/S18026A-F) for funding the competence center for Big Data
    and AI “ScaDS.AI Dresden/Leipzig”. Data availability Benchmark results for real-time
    UFXCT data processing (Original Data) (rodare.hzdr.de) References [1] M. Banowski,
    A. Patmonoaji, D. Lucas, U. Hampel Int. J. Multiph. Flow, 96 (2017), pp. 144-160,
    10.1016/j.ijmultiphaseflow.2017.07.012 View PDFView articleView in ScopusGoogle
    Scholar [2] M. Neumann-Kipping, A. Bieberle, U. Hampel Int. J. Multiph. Flow,
    130 (2020), Article 103340, 10.1016/j.ijmultiphaseflow.2020.103340 View PDFView
    articleView in ScopusGoogle Scholar [3] R. Kipping, H. Kryk, U. Hampel Chem. Eng.
    Sci., 229 (2021), Article 116056, 10.1016/j.ces.2020.116056 View PDFView articleView
    in ScopusGoogle Scholar [4] T. Schäfer, M. Neumann-Kipping, A. Bieberle, M. Bieberle,
    U. Hampel J. Fluids Eng., 142 (4) (01 2020), Article 041502, 10.1115/1.4045497
    https://asmedigitalcollection.asme.org/fluidsengineering/article-pdf/142/4/041502/6477356/fe_142_04_041502.pdf
    View in ScopusGoogle Scholar [5] J. Sohr, M. Schubert, S. Flechsig, E.Y. Kenig,
    U. Hampel Chem. Ing. Tech., 91 (1–2) (2019), pp. 139-144, 10.1002/cite.201800069
    https://onlinelibrary.wiley.com/doi/pdf/10.1002/cite.201800069 View in ScopusGoogle
    Scholar [6] M. Bieberle, F. Barthel, U. Hampel Chem. Eng. J., 189–190 (2012),
    pp. 356-363, 10.1016/j.cej.2012.02.028 View PDFView articleView in ScopusGoogle
    Scholar [7] D. Windisch, M. Bieberle, A. Bieberle, U. Hampel Trans. Inst. Meas.
    Control, 42 (4) (2020), pp. 691-703, 10.1177/0142331219858048 View in ScopusGoogle
    Scholar [8] F. Fischer, U. Hampel Nucl. Eng. Des., 240 (9) (2010), pp. 2254-2259,
    10.1016/j.nucengdes.2009.11.016 experiments and CFD Code Applications to Nuclear
    Reactor Safety (XCFD4NRS) View PDFView articleView in ScopusGoogle Scholar [9]
    D. Windisch, O. Knodel, G. Juckeland, U. Hampel, A. Bieberle IEEE Trans. Nucl.
    Sci., 68 (12) (2021), pp. 2779-2786, 10.1109/TNS.2021.3123837 View in ScopusGoogle
    Scholar [10] H.-M. Prasser, A. Böttger, J. Zschau Flow Meas. Instrum., 9 (1998),
    pp. 111-119 View PDFView articleView in ScopusGoogle Scholar [11] P. Porombka,
    S. Boden, D. Lucas, U. Hampel Exp. Fluids, 62 (1) (2020), p. 5, 10.1007/s00348-020-03091-6
    Google Scholar [12] T. Frust, M. Wagner, J. Stephan, G. Juckeland, A. Bieberle
    Comput. Phys. Commun., 219 (2017), pp. 353-360, 10.1016/j.cpc.2017.05.025 View
    PDFView articleView in ScopusGoogle Scholar [13] P. Emmerich Demystifying network
    cards Chaos Computer Club e.V. https://doi.org/10.5446/34880 (2017) Google Scholar
    [14] L. Rizzo 2012 USENIX Annual Technical Conference (USENIX ATC 12), USENIX
    Association, Boston, MA (2012), pp. 101-112 View in ScopusGoogle Scholar [15]
    Linux foundation, data plane development kit https://www.dpdk.org/ (2022) Google
    Scholar [16] SnabbCo, Snabb https://github.com/snabbco/snabb (2022) Google Scholar
    [17] Linux foundation, data plane development kit, performance reports http://core.dpdk.org/perf-reports/
    (2022) Google Scholar [18] Linux foundation, data plane development kit, supported
    nics http://core.dpdk.org/supported/nics/ (2022) Google Scholar [19] A. Katsifodimos,
    S. Schelter 2016 IEEE International Conference on Cloud Engineering Workshop (IC2EW)
    (2016), p. 193, 10.1109/IC2EW.2016.56 Google Scholar [20] Y. Allusse, P. Horain,
    A. Agarwal, C. Saipriyadarshan Gpucv G. Bebis, R. Boyle, B. Parvin, D. Koracin,
    P. Remagnino, F. Porikli, J. Peters, J. Klosowski, L. Arns, Y.K. Chun, T.-M. Rhyne,
    L. Monroe (Eds.), Advances in Visual Computing, Springer Berlin Heidelberg, Berlin,
    Heidelberg (2008), pp. 430-439 CrossRefView in ScopusGoogle Scholar [21] G.A.
    Elliott, B.C. Ward, J.H. Anderson Gpusync 2013 IEEE 34th Real-Time Systems Symposium
    (2013), pp. 33-44, 10.1109/RTSS.2013.12 View in ScopusGoogle Scholar [22] A. Koliousis,
    M. Weidlich, R. Castro Fernandez, A.L. Wolf, P. Costa, P. Pietzuch Saber Proceedings
    of the 2016 International Conference on Management of Data, SIGMOD ''16, Association
    for Computing Machinery, New York, NY, USA (2016), pp. 555-569, 10.1145/2882903.2882906
    View in ScopusGoogle Scholar [23] R. Mokso, C.M. Schlepütz, G. Theidel, H. Billich,
    E. Schmid, T. Celcer, G. Mikuljan, L. Sala, F. Marone, N. Schlumpf, M. Stampanoni
    J. Synchrotron Radiat., 24 (6) (2017), pp. 1250-1259, 10.1107/S1600577517013522
    View in ScopusGoogle Scholar [24] T. Bicer, D. Gursoy, R. Kettimuthu, I.T. Foster,
    B. Ren, V. De Andrede, F. De Carlo 2017 IEEE 13th International Conference on
    e-Science (e-Science) (2017), pp. 59-68, 10.1109/eScience.2017.53 View in ScopusGoogle
    Scholar [25] M. Vogelgesang, S. Chilingaryan, T. dos Santos Rolo, A. Kopmann Proceedings
    of the 14th IEEE Conference on High Performance Computing and Communication and
    the 9th IEEE International Conference on Embedded Software and Systems (HPCC-ICESS)
    (HPCC ’12) (2012), pp. 824-829 CrossRefView in ScopusGoogle Scholar [26] M. Vogelgesang,
    T. Farago, T.F. Morgeneyer, L. Helfen, T. dos Santos Rolo, A. Myagotin, T. Baumbach
    J. Synchrotron Radiat., 23 (5) (2016), pp. 1254-1263, 10.1107/S1600577516010195
    View in ScopusGoogle Scholar [27] G. Mencagli, M. Torquati, A. Cardaci, A. Fais,
    L. Rinaldi, M. Danelutto IEEE Trans. Parallel Distrib. Syst., 32 (11) (2021),
    pp. 2748-2763, 10.1109/TPDS.2021.3073970 View in ScopusGoogle Scholar [28] D.
    vom Bruch J. Instrum., 15 (06) (2020), Article C06010, 10.1088/1748-0221/15/06/C06010
    View in ScopusGoogle Scholar [29] H. Kang, S.-W. Lee, E.-S. Lee, S.-H. Kim, T.G.
    Lee Biomed. Opt. Express, 6 (12) (2015), pp. 4650-4660, 10.1364/BOE.6.004650 https://opg.optica.org/boe/abstract.cfm?URI=boe-6-12-4650
    View in ScopusGoogle Scholar [30] W.F. Godoy, N. Podhorszki, R. Wang, C. Atkins,
    G. Eisenhauer, J. Gu, P. Davis, J. Choi, K. Germaschewski, K. Huck, A. Huebl,
    M. Kim, J. Kress, T. Kurc, Q. Liu, J. Logan, K. Mehta, G. Ostrouchov, M. Parashar,
    F. Poeschel, D. Pugmire, E. Suchyta, K. Takahashi, N. Thompson, S. Tsutsumi, L.
    Wan, M. Wolf, K. Wu, S. Klasky SoftwareX, 12 (2020), Article 100561, 10.1016/j.softx.2020.100561
    View PDFView articleView in ScopusGoogle Scholar [31] Q. Koziol, D. Robinson U.
    O. of Science, Hdf5 https://doi.org/10.11578/dc.20180330.1 (3 2018) Google Scholar
    Cited by (1) Unlocking Insights: A Cloud Tool for Data Visualisation in a Smart
    Meter Project 2023, Processes ☆ The review of this paper was arranged by Prof.
    David W. Walker. ☆☆ This paper and its associated computer program are available
    via the Computer Physics Communications homepage on ScienceDirect (http://www.sciencedirect.com/science/journal/00104655).
    © 2023 The Author(s). Published by Elsevier B.V. Recommended articles A hybrid
    model to calculate the spin wave excitations in ferromagnetic/non-magnetic multilayers
    Computer Physics Communications, Volume 287, 2023, Article 108683 Abdelmajid Lekdadri,
    Hassan Lassri View PDF A 1-D/3-D coupling approach for compressible non-equilibrium
    two-phase flows using the Baer-Nunziato model based on the Finite-Volume framework
    Computer Physics Communications, Volume 288, 2023, Article 108724 Frédéric Daude
    View PDF Compatible and energy conserving multi-material arbitrary Lagrangian
    Eulerian scheme for multi-group radiation hydrodynamics simulations Computer Physics
    Communications, Volume 287, 2023, Article 108695 C.D. Sijoy View PDF Show 3 more
    articles Article Metrics Citations Citation Indexes: 1 Captures Readers: 6 View
    details About ScienceDirect Remote access Shopping cart Advertise Contact and
    support Terms and conditions Privacy policy Cookies are used by this site. Cookie
    settings | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier
    B.V., its licensors, and contributors. All rights are reserved, including those
    for text and data mining, AI training, and similar technologies. For all open
    access content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Computer Physics Communications
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Real-time data processing for ultrafast X-ray computed tomography using modular
    CUDA based pipelines
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Kurniawan D.
  - Ashar M.
  - Ar Rosyid H.
  citation_count: '0'
  description: The level of dependence on data communication in the modern era is
    increasing exponentially. The internet of things (IoT) plays a very important
    role in the advancement of the industrial revolution 4.0 that utilizes data communication
    systems. IoT deployments require data communication protocols, such as hypertext
    transfer protocol (HTTP), and message queuing telemetry transport (MQTT) as well
    as network communication protocols (wireless) to meet the network needs of devices
    with limited resources. Optimization of data communication in IoT is needed to
    maintain the quality of sending and receiving data in real time. This research
    proposes a hybrid NarrowBand-IoT (NB-IoT) protocol designed using NarrowBand communication
    network technology with optimization of data communication using MQTT and HTTP
    protocols. In this research, the hybrid NB-IoT protocol has the best packet loss
    value of 0.010% against the HTTP NB-IoT protocol which has a value of 0.017%,
    and the MQTT NB-IoT protocol of 0.024%. The hybrid NB-IoT protocol has a latency
    value of 8.7 seconds compared to the HTTP NB-IoT protocol which has a latency
    of 10.9 seconds. Meanwhile, the throughput value of the hybrid NB-IoT protocol
    is 158906.1 byte/s and is better than the MQTT NB-IoT protocol which is only 158898.6
    bytes/s.
  doi: 10.11591/ijece.v13i3.pp2827-2836
  full_citation: '>'
  full_text: '>

    "USER Username Password Remember me CITATION ANALYSIS Academia.edu Dimensions
    Google Scholar Scimagojr Scholar Metrics Scilit Scinapse Scopus QUICK LINKS Editorial
    Boards Abstracting and Indexing Focus and Scope Author Guideline Online Submission
    Peer Review Process Publication Fee Publication Ethics The Best Journal Contact
    Us Apply as Reviewer  JOURNAL CONTENT Search Search Scope      All Authors Title
    Abstract Index terms Full Text      Browse By Issue By Author By Title INFORMATION
    For Readers For Authors For Librarians HOME ABOUT LOGIN REGISTER SEARCH CURRENT
    ARCHIVES ANNOUNCEMENTS Home > Vol 13, No 3 > Kurniawan Hybrid NarrowBand-internet
    of things protocol for real time data optimization Denny Kurniawan, Muhammad Ashar,
    Harits Ar Rosyid  Abstract  The level of dependence on data communication in the
    modern era is increasing exponentially. The internet of things (IoT) plays a very
    important role in the advancement of the industrial revolution 4.0 that utilizes
    data communication systems. IoT deployments require data communication protocols,
    such as hypertext transfer protocol (HTTP), and message queuing telemetry transport
    (MQTT) as well as network communication protocols (wireless) to meet the network
    needs of devices with limited resources. Optimization of data communication in
    IoT is needed to maintain the quality of sending and receiving data in real time.
    This research proposes a hybrid NarrowBand-IoT (NB-IoT) protocol designed using
    NarrowBand communication network technology with optimization of data communication
    using MQTT and HTTP protocols. In this research, the hybrid NB-IoT protocol has
    the best packet loss value of 0.010% against the HTTP NB-IoT protocol which has
    a value of 0.017%, and the MQTT NB-IoT protocol of 0.024%. The hybrid NB-IoT protocol
    has a latency value of 8.7 seconds compared to the HTTP NB-IoT protocol which
    has a latency of 10.9 seconds. Meanwhile, the throughput value of the hybrid NB-IoT
    protocol is 158906.1 byte/s and is better than the MQTT NB-IoT protocol which
    is only 158898.6 bytes/s.  Keywords  hybrid NarrowBand-internet of things; hypertext
    transfer protocol; message queuing telemetry transport; NarrowBand-internet of
    things Protocol;  Full Text: PDF   DOI: http://doi.org/10.11591/ijece.v13i3.pp2827-2836   This
    work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International
    License. International Journal of Electrical and Computer Engineering (IJECE)
    p-ISSN 2088-8708, e-ISSN 2722-2578 This journal is published by the Institute
    of Advanced Engineering and Science (IAES) in collaboration with Intelektual Pustaka
    Media Utama (IPMU)."'
  inline_citation: '>'
  journal: International Journal of Electrical and Computer Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Hybrid NarrowBand-internet of things protocol for real time data optimization
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Fathurohman M.A.A.
  - Sumitra I.D.
  - Daud A.R.
  citation_count: '0'
  description: The monitoring system is an essential component for broiler closed-house
    farmers. This design aims to implement an efficient monitoring system using Wireless
    Sensor Network (WSN) technology and the Internet of Things (IoT). This system
    system enhances chicken coop monitoring and supports online learning at Broiler
    Teaching Farm. It comprises six sensor nodes and one controller node (gateway).
    Each sensor node is equipped with a DHT22 sensor for temperature and humidity,
    an MQ-135 sensor for NH3 gas concentration, and anemometers for wind speed monitoring.
    Communication between nodes is facilitated by NRF24L01 modules, with the primary
    node employing an ESP32 and each sensor node using an ATmega328P. The data collected,
    including temperature, humidity, NH3 gas levels, and wind speed, is wirelessly
    transmitted to the controller node via the WSN. The controller node then forwards
    this data to a web-based service using the HTTP protocol. The information is presented
    in a user-friendly, real-time web platform, offering valuable insights. Moreover,
    the system can maintain weekly performance records and coop administration records.
    Furthermore, this implementation represents a significant contribution to the
    field of animal farming and serves as a foundation for future research and development
    of livestock monitoring systems. The system offers operators real-time data for
    prompt decisions on the chicken coop's status. It's integrated with an online
    poultry farming course at Broiler Teaching Farm, allowing students to gain insights
    into the latest technology in broiler chicken farming. This integration should
    improve broiler closed-house monitoring, enhancing education quality and environmental
    management for students and instructors.
  doi: 10.1109/ICSPIS59665.2023.10402746
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 9th International Confer... Integration
    of Wireless Sensor Network and IoT for Enhanced Broiler Closed-House Monitoring:
    A Case Study at Broiler Teaching Farm Publisher: IEEE Cite This PDF Muhammad Aldi
    Aulia Fathurohman; Irfan Dwiguna Sumitra; Andre Rivianda Daud All Authors 5 Full
    Text Views Abstract Document Sections I. Introduction II. Background Study III.
    Existing System IV. Proposed System V. System Design Show Full Outline Authors
    Figures References Keywords Metrics Abstract: The monitoring system is an essential
    component for broiler closed-house farmers. This design aims to implement an efficient
    monitoring system using Wireless Sensor Network (WSN) technology and the Internet
    of Things (IoT). This system system enhances chicken coop monitoring and supports
    online learning at Broiler Teaching Farm. It comprises six sensor nodes and one
    controller node (gateway). Each sensor node is equipped with a DHT22 sensor for
    temperature and humidity, an MQ-135 sensor for NH3 gas concentration, and anemometers
    for wind speed monitoring. Communication between nodes is facilitated by NRF24L01
    modules, with the primary node employing an ESP32 and each sensor node using an
    ATmega328P. The data collected, including temperature, humidity, NH3 gas levels,
    and wind speed, is wirelessly transmitted to the controller node via the WSN.
    The controller node then forwards this data to a web-based service using the HTTP
    protocol. The information is presented in a user-friendly, real-time web platform,
    offering valuable insights. Moreover, the system can maintain weekly performance
    records and coop administration records. Furthermore, this implementation represents
    a significant contribution to the field of animal farming and serves as a foundation
    for future research and development of livestock monitoring systems. The system
    offers operators real-time data for prompt decisions on the chicken coop’s status.
    It’s integrated with an online poultry farming course at Broiler Teaching Farm,
    allowing students to gain insights into the latest technology in broiler chicken
    farming. This integration should improve broiler closed-house monitoring, enhancing
    education quality and environmental management for students and instructors. Published
    in: 2023 9th International Conference on Signal Processing and Intelligent Systems
    (ICSPIS) Date of Conference: 14-15 December 2023 Date Added to IEEE Xplore: 23
    January 2024 ISBN Information: DOI: 10.1109/ICSPIS59665.2023.10402746 Publisher:
    IEEE Conference Location: Bali, Indonesia Funding Agency: SECTION I. Introduction
    The importance of temperature conditions as it serves as a basis for the farmer’s
    decision-making to maintain a comfortable range for the chickens; Traditionally,
    this temperature is manually measured using mercury-based or electronic thermometers,
    and recording such data for further analysis takes considerable time. Additionally,
    the coop’s air quality, influenced by the ammonia gas produced through chicken
    manure fermentation, plays a significant role in the chickens’ growth, disease
    resistance, mortality rates, and feed intake, impacting their overall growth rate
    [1]. There are three main objectives of this research project: The first is to
    provide accurate and real-time information to operators, enabling them to make
    timely decisions regarding the condition of the chicken coop. The second one is
    integrating the system with online courses open to anyone interested in learning
    about poultry cages, as well as an e-learning platform from the Broiler Teaching
    Farm. This platform will provide students with valuable knowledge about the latest
    technology in broiler farming. As a result, students participating in the chicken
    course will be able to access web-based data without having to go directly to
    the lab or chicken coop. According to this design, it is expected that the online
    course services and online learning system at Broiler Teaching Farm can efficiently
    utilize broiler closed-house monitoring, thereby enhancing the quality of teaching
    and environmental management for students and instructors. SECTION II. Background
    Study The poultry industry significantly contributes to the global economy, with
    broiler chicken farming being one of the most profitable sectors. However, monitoring
    broiler closed-house farms is a challenging task, as it requires continuous monitoring
    of environmental factors such as temperature, humidity, and ammonia gas concentration.
    Traditional monitoring methods are time-consuming, labor-intensive, and often
    result in inaccurate data. Therefore, there is a need for an efficient and reliable
    monitoring system that can provide real-time data on the environmental conditions
    of the chicken coop. In recent years, many kinds of research have been done on
    smart poultry farms using IoT and WSN in different countries [2]–[7]. In a series
    of studies conducted by various researchers, the potential of IoT (Internet of
    Things) technology in poultry farming has been extensively explored. Sitaram et
    al. highlighted the utilization of IoT for monitoring critical environmental factors,
    such as temperature, humidity, light, and ammonia gas in poultry farms, with the
    aim of enhancing chicken health and productivity through sensor-based monitoring
    and data transmission via the GPRS network [2]. Similarly, Hambali et al. emphasized
    the implementation of IoT and Wireless Sensor Network (WSN) technology in chicken
    farms in Brunei, focusing on reducing chicken mortality and improving overall
    farm productivity by monitoring factors such as temperature, humidity, air quality,
    lighting, and feeding [3]. Additionally, Jayarajan et al. discussed a poultry
    farm management system that harnesses wireless sensor network technology to optimize
    environmental conditions, minimize labor requirements, and increase egg production
    [4]. This system continuously monitors variables including temperature, humidity,
    air quality, and light intensity while also automating feeding processes and conserving
    chicken feed. Furthermore, Rahmatulloh et al. proposed the development of smart
    chicken coops in Indonesia through the application of IoT technology. Their objective
    is to address issues related to temperature and humidity control through integrated
    systems that incorporate Node MCU microcontrollers, DHT22 sensors, relays, and
    the Blynk application [5]. In their research, Shanmugapriya et al. also focused
    on automating the management of critical poultry farm variables, encompassing
    heat, moisture, air quality, illumination, drying, and food feeding, through the
    use of wireless sensor networks and IoT technology to reduce broiler chicken mortality
    rates and enhance overall productivity [6]. The Internet of Things (IoT) has emerged
    as a promising technology for monitoring and controlling various systems. IoT-based
    monitoring systems have been developed for various applications, including environmental
    monitoring in poultry farms [8]. Wireless sensor networks (WSN) are an advanced
    technology that swiftly connects sensors and sensing nodes to the primary system
    load [9]. Moreover, WSNs are ideal for acquiring long-term environmental data
    representing the Internet of Things (IoT) and typically exhibit low power consumption
    [10]. The available options for wireless transmission media include radio frequency
    (RF), optical communication (laser), and infrared. Among these, radio frequency-based
    communication is the most suitable for most WSN applications [11]. Furthermore,
    using WSN technology in combination with IoT is an effective solution for monitoring
    environmental conditions in poultry farms [12]. SECTION III. Existing System Most
    poultry farms in Indonesia continue to follow traditional poultry farming techniques.
    These farms rely on manual daily tasks to monitor various environmental factors
    such as temperature, humidity, air quality, and wind speed. However, the Broiler
    Teaching Farm have adopted a more advanced approach using an intensive production
    system with automated technology to control the climate of a closed-house environment.
    Observing multiple factors within closed broiler chicken houses is essential as
    the chickens’ well-being and performance are greatly affected by environmental
    conditions. Heat stress may arise from high temperatures, infections from excessive
    humidity, and respiratory issues from elevated ammonia levels. Additionally, improper
    wind speed can lead to stress and diseases in the birds. Analyzing and monitoring
    these parameters allows us to anticipate avian ailments, including bird flu and
    other diseases, which could result in severe consequences. This practice ensures
    that the chickens have maximum comfort, reduced stress, minimized disease risks,
    and improved productivity and success in broiler poultry farming. However, a challenge
    remains as there is currently no proper system to monitor NH3 gas in the closed-house.
    It is important to note that NH3 levels must be less than ten ppm is the ideal
    limit for ammonia exposure in closed broiler houses [13]. The recommended to keep
    the ammonia levels below 25 ppm in closed broiler houses to ensure the health
    of both birds and humans [13]. Unfortunately, this process still depends on human
    intervention, and errors can occur. SECTION IV. Proposed System Numerous studies
    conducted by different researchers have extensively delved into the potential
    of IoT (Internet of Things) technology within the poultry farming domain [2]–[7].
    For instance, Sitaram et al. underscored the application of IoT for the surveillance
    of critical environmental parameters, including temperature, humidity, light,
    and ammonia gas in poultry farms. Their focus was on augmenting chicken health
    and productivity through sensor-based monitoring and data transmission using the
    GPRS network [2]. Similarly, Hambali et al. stressed the integration of IoT and
    Wireless Sensor Network (WSN) technology in chicken farms in Brunei, with a primary
    objective of mitigating chicken mortality and enhancing overall farm efficiency.
    This was achieved through the monitoring of factors such as temperature, humidity,
    air quality, lighting, and feeding [3]. The difference between previous studies
    and this research lies in the focus of this study. In this research, the emphasis
    is placed on monitoring a poultry farm measuring 1440 m 2 with dimensions of 120
    meters in length and 12 meters in width, accommodating 23,000 chickens. Consequently,
    there is a need for monitoring equipment capable of overseeing the entire expanse
    of the coop. In this study, six sensor nodes were strategically placed, the monitoring
    system displays data from each specific spot while also presenting the average
    data from all the spots, allowing monitoring to be conducted through a web administrator
    interface as well as a web-based Learning Management System (LMS) for students.
    The foundation of this prototype consisted of a closed-house grill production
    system. The study centered around four essential determinants of productivity
    within the poultry facility: temperature, humidity, ammonia concentration, and
    wind velocity. In order to enhance the monitoring process, the system employed
    the Internet of Things (IoT), Wireless Sensor Networks (WSN), and online services.
    The primary benefits of the proposed system encompass a decrease in labor requirements
    and an enhancement in the efficiency of poultry stocking. It facilitates the provision
    of precise and up-to-date information to operators, empowering them to make prompt
    decisions about the chicken coop’s state. Furthermore, the gathered data is analyzed
    to forecast avian illnesses such as bird flu and other diseases that may result
    in significant ramifications. Furthermore, it functioned as a pedagogical tool
    for students, offering them vital knowledge on the most recent advancements in
    broiler farming technology. Implementing this feature enabled participants enrolled
    in the poultry course to retrieve web-based information, reducing the necessity
    of physically visiting the laboratory or chicken coop. SECTION V. System Design
    The proposed block diagram for the entire system is shown in Fig. 1. The system
    comprises six sensor nodes and one master node that acts as a gateway. Each sensor
    node is responsible for obtaining temperature, humidity, NH3 levels, and wind
    speed data. The gathered information is then sent to the master node, which acts
    as a gateway. Afterward, the master node transmits the data to a web server hosted
    online via a WiFi connection connected to the internet. Fig. 1. System diagram
    Show All Below in Fig. 2 is the proposed block diagram for a single node. The
    system comprises three essential modules: the temperature and humidity sensor
    module, the air quality sensor module, and the anemometer sensor module. All sensors
    are connected to the ATMega328P. The ATMega328P gathers thermal parameters through
    the temperature and humidity sensor module, NH3 levels from the air quality sensor
    module, and wind speed from the anemometer sensor module. Afterward, it sent the
    data to the ESP32 via the radio transceiver module. The ESP32 is connected to
    the internet network through WiFi. It collects data from the ATMega328P and through
    HTTP requests using the GET method, ESP32 send the data to the hosted web server.
    The web server receives the request, extracts and processes the data, and stores
    it in the MySQL database. Fig. 2. Single node diagram Show All A. Ammonia Sensor
    Module The ammonia sensor modules carry out the collection of ammonia concentration
    in the air. In this particular design, the sensor employed is the MQ-135, and
    it gathers data at regular intervals, transmitting it to the ATMega328P. The MQ-135
    sensor used in the study has an analog voltage range of 0-5 V, converted to binary
    numbers 0-1024 through an Analog-to-Digital Converter (ADC). To obtain the ADC
    reading data from the MQ-135 sensor, researchers utilized the equation provided
    in reference [14], [15]: VRL=ADC ( 5 1024 ) (1) View Source Rs=( VC VRL −1)RL
    (2) View Source ppm=a (Rs / Ro ) b (3) View Source Where VRL: Voltage of Load
    Resistance ADC: Analog Digital Converter RL: Load Resistance VC: Voltage Collector
    Rs: Value of sensor resistance at various gas concentrations. Ro: sensor resistance
    at 100ppm of gas in the clean air a: Scaling Factor b: Exponent B. Wind Sensor
    Module The wind sensor modules carry out the collection of wind speed in the coop.
    In this particular design, the sensor used is the Anemometer SEN0170 DFROBOT,
    which gathers data at regular intervals and sends it to the ATMega328P. The wind
    speed is determined based on the voltage output curve via ADC ranging from 0 to
    30 m/s which can be seen in Table 1 [16], [17]. TABLE I Relationship Between Speed
    and Output Value C. Temperature and Humidity Sensor Module The temperature and
    humidity sensor modules carry out the collection of temperature and humidity at
    regular intervals. In this specific design, the DHT22 sensor is utilized. The
    temperature readings range from − 40 ∘ C to 80 ∘ C , while the humidity readings
    range from 0% to 100%. Additionally, the sensor’s accuracy is approximately ±
    0.5 ∘ C [18]. D. Radio Transceiver Module The radio transceiver modules transmit
    all sensor data from ATMega328P to The ESP 32. In this design, the module uses
    NRF24L01+PA+LNA. The module is a radio wave-based wireless technology that works
    at 2.4 GHz frequency and maximum distance transmitted at 200-300m line of sight
    [19]. E. Node Sensor Design The following Fig. 3 shows the design of the node
    sensor. The temperature and humidity sensors are on the side of the case, while
    the nh3 sensor is in the case itself and faces downwards. The wind sensor is separate
    from the case and connected using a cable. Fig. 3. Desain of node sensor Show
    All F. Overview of the Full System Design Fig. 4 shows the full system design
    for 1440 m 2 closed house chicken coop, which the master node (white box) is placed
    near the door. Furthermore, each sensor node (red box) is 17 meters away, and
    the farthest distance from the master node (white box) is 102 meters. The sensor
    node is placed at bird height, approximately 20 cm from the bottom, because this
    distance is needed to detect ammonia [20]. Fig. 4. Full system design Show All
    SECTION VI. Implementation To upload sketches to ATMega328P and ESP32, the software
    used is Arduino IDE, and the hardware used is USB to TTL CH340. Furthermore, the
    software for managing MySQL database is phpMyAdmin, as well as Cronjob for the
    scheduler in the cPanel provided by the hosting service provider. A. Circuit Diagram
    1) Node Master Below in Fig. 5 is the connection of the ESP32 that act as a gateway.
    The unused pins on ESP32 are given output as blank pins for further development.
    Additionally, The CE pin on the NRF24L01 is connected to IO4 (digital pin 4) on
    the ESP32, while the CSN pin is connected to IO5 (digital pin 5). To ensure that
    both devices, the ESP32 and NRF24L01, receive power at the correct voltage, an
    AMS1117 3.3V component is used to step down the voltage from a 5V power source.
    This is essential to ensure stable and safe performance of both devices in this
    project. Fig. 5. Node master circuit diagram Show All 2) Node Sensor In Fig. 6
    below, the connection of the ATMega328P to various sensors for data collection
    is illustrated. The ammonia sensor is connected to PCO (analog pin 0), while the
    wind sensor is linked to analog PC1 (pin 1). The temperature and humidity sensor(DHT22)
    and the MQ-135 sensor are attached to PD2 (digital pin 2). The anemometer sensor
    requires a 12V power supply to operate. To step down the voltage from 12V to the
    5V required by the ATMega328P, MQ-135, and DHT22, a voltage regulator IC7805 is
    used as the power source. Furthermore, the NRF24L01 sensor module requires a 3.
    3V supply voltage, for which an AMS11173.3V voltage regulator is employed. The
    NRF24L01 sensor module connected to the ATMega328P, the CE pin on the NRF24L01
    to PB1 (digital pin 9) on the ATMega328P, while the CSN pin on the NRF24L01 is
    connected to PBO (digital pin 8) on the ATMega328P. Fig. 6 Node sensor circuit
    diagram Show All B. Hardware System 1) Node Sensor Below in Fig. 7, the program
    starts with the “START” block, performing initialization tasks, including library
    inclusion for SPI, RF24, RF24Network, and DHT. It also defines necessary pins
    and variables. After that, the program sets up the configuration for the DHT22
    sensor, initializes the RF24 radio module, and initiates communication via RF24Network
    at a data rate of 2Mbps. Subsequently, the program retrieves data from multiple
    sensors to gather environmental information. The “Read Sensor” block retrieves
    analog data from the MQ-135 gas sensor linked to the analog input AO. The sensor’s
    resistance is determined by converting the analog value into voltage (VRL), which
    is then used to determine its resistance (RS). The concentration of NH3 gas is
    determined in parts per million (PPM) using established constants (Ro) and the
    RS value. Additionally, the program also reads data from the DHT22 sensor to obtain
    humidity (h) and temperature (t) values in the “Calculate Humidity and Temperature”
    block. Meanwhile, in the “Calculate Wind Speed” block, the program reads analog
    data from an anemometer connected to analog input A1. The analog voltage value
    is converted into wind speed (w) based on specific calibration. When all environmental
    data has been acquired, the program moves to the “Prepare Data String” block.
    In this block, a header is constructed to identify the data transmission source
    uniquely. The headers range from Spot1 to Spot6, denoted by numerical values 01
    to 06. The temperature, humidity, PPM (parts per million) data and wind speed
    is consolidated into a unified string, with a separator denoted by the symbol
    “#”, effectively distinguishing each number. The program then advances to the
    “Update RF24 Network and Send Data” block, where the data string (send) is converted
    into a character array (text) and transmitted via RF24 Network to the master node
    with node identification 00. A temporal delay is incorporated during this procedure
    to guarantee seamless data transmission. Upon transmitting the data, the program
    proceeds to the “Read Sensor” block, initiating a continual repetition of the
    process as mentioned above. The program can continuously monitor sensor values
    and periodically transmit data through RF24 Network to the master node for subsequent
    processing or analysis. Fig. 7. Node sensor flow diagram Show All 2) Node Master
    Below in Fig. 8, the program starts from “START” and then checks the WiFi connection
    with the specified SSID and password. If the connection is successful (WiFi Connected),
    the program proceeds to the next step: check if any data is available from the
    RF24 Network. If data is available (Data Available), the program processes the
    data by separating and extracting the values for each variable. Next, the program
    uses the HTTP Client to send the data to the designated host through the HTTP
    protocol. After the data is sent, the program introduces a 500-millisecond delay
    before returning to checking the available data from the RF24. Fig. 8. Node master
    flow diagram Show All C. Database Configuration The database has two tables to
    receive data from sensors: the “data_realtime_sensor” table and the “data_log_sensor”
    table. The “data_realtime_sensor” table contains all the sensor data sent, and
    it is configured to use the update data command to prevent the continuous addition
    of data from the sensors. On the other hand, the “data_log_sensor” table stores
    all sensor data inputted every 4 hours. In cPanel, a feature called “cronjob”
    allows users to schedule and automate the execution of programs or scripts at
    specified time intervals. In this context, the Cronjob executes a PHP program
    containing commands to insert sensor data into the “data_log_sensor” table every
    4 hours. This cronjob feature will automatically execute the PHP program at the
    specified time intervals, making administrative tasks easier and ensuring consistent
    program execution. SECTION VII. Results and Discussion The web interface of the
    administrator displays Fig. 9 below. This system facilitates the delivery of accurate
    and upto-date information to operators. The operator can access the average temperature,
    humidity, ammonia levels, and wind speed values. Additionally, the operator can
    retrieve sensor data at each designated spot from spot1 to spot6. The system’s
    automated data logging feature eliminates the need for manual recording of temperature,
    humidity, ammonia levels, and wind speed by the operator. The system efficiently
    captures and stores this information automatically every hour. Furthermore, the
    operator can activate the ammonia system when ammonia levels reach a high threshold.
    Fig. 9 Administrator data log web interface Show All Moreover, the web interface
    of the LMS displays Fig. 10 below. This interface allows not only animal husbandry
    students but also participants of the chicken farming courses to access all the
    necessary data without the need to visit the chicken coop (lab) physically. The
    LMS presents data from sensors and other relevant information from the chicken
    coop in a direct and easily accessible manner. This integration enables students
    and course participants to retrieve the required data through the LMS platform
    conveniently. Fig. 10. LMS web interface Show All SECTION VIII. Conclusion and
    Future Work This design’s implementation has resulted in a broiler closed-house
    monitoring system and has proven its effectiveness in enhancing monitoring capabilities
    and supporting online learning initiatives. Integrating WSN and IoT technologies
    in this system provides accurate and effective monitoring for managers and educators,
    enabling prompt response to unfavorable conditions. Furthermore, this implementation
    represents a significant contribution to the field of animal farming and serves
    as a foundation for future research and development of livestock monitoring systems.
    In the future, data obtained from the coop can be subjected to data analytics
    to foresee bird diseases that could severely impact the productivity of the poultry
    farm ecosystem. This foresight will enable farmers to take appropriate actions
    proactively. The designed monitoring system offers several advantages. Firstly,
    the system provides accurate and real-time information to operators, enabling
    them to make timely decisions regarding the condition of the chicken coop. Secondly,
    the system is integrated with an online course that is open to anyone interested
    in learning about poultry farming, as well as an e-learning platform for the Broiler
    Teaching Farm, allowing students to gain insights into the latest technology in
    broiler chicken farming. With this design, it is expected that the online course
    services and online learning system at Broiler Teaching Farm can efficiently utilize
    broiler closed-house monitoring, thereby enhancing the quality of teaching and
    environmental management for students and instructors. In the future, the data
    collected from the barn can be analyzed using data analytics to predict bird diseases
    like bird flu and others that can have devastating effects on the poultry farm
    ecosystem’s productivity, helping farmers take appropriate actions before it happens.
    To enhance the accuracy of disease detection and prediction, innovative technology
    such as thermal imaging camera devices can be incorporated. These devices are
    used to monitor and detect changes in the maximum surface temperature (MST) of
    chickens, allowing for even more precise early warning systems and proactive measures
    to protect the health of the poultry flock. ACKNOWLEDGMENT We appreciate the support
    from Universitas Komputer Indonesia and Universitas Padjadjaran. Authors Figures
    References Keywords Metrics More Like This Smart farm and monitoring system for
    measuring the Environmental condition using wireless sensor network - IOT Technology
    in farming 2020 5th International Conference on Innovative Technologies in Intelligent
    Systems and Industrial Applications (CITISIA) Published: 2020 A low consumption
    real time environmental monitoring system for smart cities based on ZigBee wireless
    sensor network 2015 International Wireless Communications and Mobile Computing
    Conference (IWCMC) Published: 2015 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: ICSPIS 2023 - Proceedings of the 9th International Conference on Signal
    Processing and Intelligent Systems
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Integration of Wireless Sensor Network and IoT for Enhanced Broiler Closed-House
    Monitoring: A Case Study at Broiler Teaching Farm'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wang M.
  - Liu F.
  - Bi X.
  - Zhu J.
  - Zhang Z.
  - Zhou S.
  citation_count: '0'
  description: The design and implementation scheme of game engine is proposed for
    the campus digital twin system. The system integrates various sensor data and
    three-dimensional models generated by drone tilt photography technology, providing
    users with a real-time and highly realistic simulation of the campus environment.
    It mainly uses the WiFi microcontroller ESP8266 to remotely transmit data from
    current sensors ACS712, smoke sensors MQ2 and MQ135 and immersion sensors by using
    the MQTT protocol via message queue. On the backend, it uses Python scripts to
    parse the uploaded data and store it separately in MySQL and Redis databases.
    It writes the backend programs by using the Springboot framework and provides
    the corresponding application program interface API. The front-end adopts the
    advanced Unreal engine 5 for display and uses the VaRest plugin to send HTTP requests
    to the back-end, so as to obtain the real-time data for rendering. This article
    provides the detailed introduction to the design, implementation and optimization
    process of the system and verifies its effectiveness. In addition, it extensively
    discusses the basic technologies, definitions and methods which are involved in
    developing the digital twin system.
  doi: 10.1109/ICSECE58870.2023.10263411
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 IEEE International Confe... Design
    and Implementation of Campus Digital Twin System Based on Game Engine Publisher:
    IEEE Cite This PDF Min Wang; Fengshuo Liu; Xiaotian Bi; Jiyang Zhu; Zikang Zhang;
    Sijia Zhou All Authors 98 Full Text Views Abstract Document Sections I. Introduction
    II. Research Status of Digital Twin III. Researches on Key Technology V. System
    Implementation VI. Conclusions Authors Figures References Keywords Metrics Abstract:
    The design and implementation scheme of game engine is proposed for the campus
    digital twin system. The system integrates various sensor data and three-dimensional
    models generated by drone tilt photography technology, providing users with a
    real-time and highly realistic simulation of the campus environment. It mainly
    uses the WiFi microcontroller ESP8266 to remotely transmit data from current sensors
    ACS712, smoke sensors MQ2 and MQ135 and immersion sensors by using the MQTT protocol
    via message queue. On the backend, it uses Python scripts to parse the uploaded
    data and store it separately in MySQL and Redis databases. It writes the backend
    programs by using the Springboot framework and provides the corresponding application
    program interface API. The front-end adopts the advanced Unreal engine 5 for display
    and uses the VaRest plugin to send HTTP requests to the back-end, so as to obtain
    the real-time data for rendering. This article provides the detailed introduction
    to the design, implementation and optimization process of the system and verifies
    its effectiveness. In addition, it extensively discusses the basic technologies,
    definitions and methods which are involved in developing the digital twin system.
    Published in: 2023 IEEE International Conference on Sensors, Electronics and Computer
    Engineering (ICSECE) Date of Conference: 18-20 August 2023 Date Added to IEEE
    Xplore: 29 September 2023 ISBN Information: DOI: 10.1109/ICSECE58870.2023.10263411
    Publisher: IEEE Conference Location: Jinzhou, China SECTION I. Introduction With
    the rapid development of information technology and the widespread application
    of Internet of Things technology, the digital twin technology, as a typical digital
    technology, has received widespread attention in various fields. The digital twin
    system provides a digital virtual model for the real world through simulation,
    thereby achieving monitoring, analysis, and optimization of the real world. Campus,
    as an important social component, its safety and operational status are related
    to the safety of teachers and students'' lives and property. Therefore, the research
    and design of a campus digital twin system based on game engines has important
    practical significance. This article aims to design and implement a campus digital
    twin system based on game engines, which utilizes Internet of Things technology
    to collect real-time sensor data within the campus. The data is analyzed and processed
    through the back-end programs, and visualized using the Unreal 5 engine in the
    front-end. Through this system, the real-time monitoring and early warning of
    various security hazards on campus can be achieved, which can improve the level
    of campus security management and provide the technical support for the future
    development of campus intelligence. SECTION II. Research Status of Digital Twin
    A. Definition of Digital Twin In 2002, The University of Michigan established
    a PLM (Product Lifecycle Management) center. Professor Michael Grieves published
    \"Conceptual Idea for PLM\" to the industry, proposing for the first time a PLM
    (Product Lifecycle Management) conceptual model in which \"virtual digital representations
    equivalent to physical products\" are proposed, resulting in descriptions of real
    and virtual spaces. Professor Michael Grieves mentioned that the prerequisite
    for driving this model is that each system consists of two systems: one is an
    existing physical system, and the other is a new virtual system that contains
    all the information of the physical system. It means that it is no longer static
    who expresses who, but two systems - virtual systems and real systems - will be
    connected to each other throughout the entire lifecycle. In 2006, Dr. Michael
    Grieves published another work called \"Product Life Cycle Management: Driving
    Next Generation Lean Thinking\". In this article, he gave the second digital twin
    the \"Information Mirror Model\", which later evolved into the term \"digital
    twin\". B. Researches of Digital Twin The United States regards digital twins
    as the core carrier for the landing of Industrial Internet, focusing on the application
    of military industry and large-scale equipment; Germany promotes Asset Management
    Shell (AAS) under the Industry 4.0 architecture, with a focus on digitalization
    of manufacturing and urban management; The UK has established the Digital Building
    UK Center, targeting digital twin cities and creating a national level twin. In
    2020, the US Industrial Internet Consortium (IIC) and the German Industry 4.0
    Platform jointly released the white paper on digital twins, which will bring digital
    twins into the industrial internet of things technology system. Since 2019, the
    Chinese government has successively issued relevant documents to promote the development
    of digital twin technology. Digital twins are included in the \"14th Five Year
    Plan\" as an important development direction for building a digital China. The
    Industrial Internet Alliance (IIC) has also set up a digital twin ad hoc group
    to carry out research on the digital twin technology industry, promote the formulation
    of relevant standards, and accelerate the application and promotion of the industry.
    At present, digital twins in China are still in the initial stage, and the most
    enterprises are still in the visualization stage. The overall technology is still
    rapidly evolving. In the short term, the giants such as Tencent and Alibaba are
    also accelerating their digital twin layout, and the industry competition will
    further intensify. Alibaba has aggregated the multi-dimensional urban data, built
    an \"urban brain\" intelligent twin platform, and provided an integrated solution
    for smart parks, which has been implemented in Xiaoshan District, Hangzhou; Huawei
    has launched a fertile land digital twin platform to create a digital innovation
    model for the urban scenarios and business under the empowerment of 5G+AI. With
    the gradual maturity of industry standards and systems, and the continuous growth
    of landing projects, the digital twin industry is expected to produce leading
    enterprises, and the market concentration ratio is expected to continue to improve.
    Since 2018, the WG15 working group of ISO/TC 184/SC 4 has promoted the development
    and validation of the \"Manufacturing Oriented Digital Twin System Framework\"
    series of standards (ISO23247). In November 2020, ISO/IEC JTC 1''s SC41 was renamed
    as the Internet of Things and Digital Twin Subcommittee, and the WG6 Digital Twin
    Working Group was established to coordinate and promote international standardization
    of digital twins. Zhuang Cunbo et al. [1] summarized the basic connotation of
    product digital twins in intelligent manufacturing, proposed the architecture
    of product digital twins, and elaborated on the implementation methods of product
    digital twins in the product design, manufacturing, and service stages. Beijing
    University of Aeronautics and Astronautics [2] has taken the lead in integrating
    digital twin technology into manufacturing workshops. It has conducted exploratory
    research on its operation mode, model construction theory, and application in
    the digital twin workshop, elaborating on its system architecture, operation mode,
    and key implementation technologies. At the same time, it has explored the theory
    and implementation methods of physical information integration in the workshop,
    and proposed the \"four modernizations, four possibilities, and eight uses\" digital
    twin model construction criteria. The scholars such as Weyer [3] believe that
    the research on digital twins should focus on the multidisciplinary collaborative
    simulation. This literature proposes a conceptual framework aimed at overcoming
    current technological barriers in digital continuity, real-world synchronization,
    and multidisciplinary fields. Qi and the other scholars [4] believe that digital
    twins enable the manufacturers to manage the real-time and bidirectional mapping
    between physical objects and digital representations, paving the way for network
    physical integration. They also propose that the digital twin technology can be
    combined with the precise analysis and prediction functions of big data, and that
    digital twins and big data complement each other to help the development of intelligent
    manufacturing. Eckhart and Ekelhart [5] believe that digital twins have opened
    up the new possibilities in monitoring, simulating, optimizing, and predicting
    the state of Cyber Physical Systems (CPS), and that CPS''s fully functional virtual
    replicas also play an important role in protecting system security. C. Application
    of Digital Twin At present, the industrial manufacturing and smart cities are
    the main application areas of digital twin technology. In industrial manufacturing,
    the digital twins simulate the operation of equipment in production and manufacturing
    through simulation experiments and validation of product development processes,
    predict fault points and probability during maintenance, improve product reliability,
    and reduce costs and risks. In terms of smart cities, the digital twins can build
    a digital twin version of a city, which can conduct global recognition, real-time
    analysis, and state perception of the city, solving problems such as urban management,
    planning, and services through monitoring, simulation, and control of the city.
    The digital twin technology can also be used in the medical field for surgical
    simulation and human organ simulation. Through digital twin technology, doctors
    can simulate the surgical process in a computer simulation environment and optimize
    the surgical scheme. It can be used to develop and test medical devices to improve
    their safety and efficiency. In agriculture, the digital twin technology is used
    for crop growth simulation, soil analysis, and irrigation optimization. In education
    and entertainment, the digital twin technology is used for virtual experiments
    and game development in the field of education and entertainment. With the development
    of artificial intelligence, the Internet of Things, big data and other technologies,
    as well as the vigorous development of global machinery manufacturing, aerospace,
    smart cities and other industries, it has played a huge role in promoting the
    development of digital twin industries.Gartner has listed digital twins as one
    of the top ten strategic technology trends for the year (2017-2019) for three
    consecutive years, believing that it will generate disruptive innovation in the
    next five years. At the same time, it predicts that by 2021, half of large industrial
    enterprises will use digital twins, thereby increasing their efficiency by 10%;
    By 2024, over 25% of the new digital twins will be adopted as binding features
    for new IOT native business applications. According to Markets and Markets forecasts,
    the size of the digital twin market will increase from 3.1billionin2020to 48.2
    billion in 2026, with a compound annual growth rate of 58%. SECTION III. Researches
    on Key Technology This article proposes a campus digital twin system that utilizes
    the ESP8266 microcontroller, MQTT protocol, multiple sensors, MySQL and Redis
    databases, Springboot backend framework, REST API, Unreal Engine 5, and VaRest
    plugin, combined with the unmanned aerial vehicle tilt photography technology
    for 3D modeling, to provide users with the real-time and real campus environment
    simulation. It adopts ESP8266 Wi Fi microcontroller and MQTT protocol.ESP8266
    is a low-cost Wi Fi microcontroller that integrates TCP/IP protocol stack and
    microprocessor functionality, making it ideal for Internet of Things (IoT) applications.
    The MQTT protocol is a lightweight publish subscribe network protocol designed
    for IoT devices with limited processing power, memory, and network bandwidth.
    It runs over TCP/IP and enables efficient communication between IoT devices and
    cloud servers or other devices. ESP8266 is programmed to read sensor data and
    transmit it to the server through the MQTT protocol [6]. Various sensors are used
    in the design system, such as current sensor ACS712 based on Hall effect, smoke
    sensor MQ2, air quality sensor MQ135, and capacitive immersion sensor. ACS712
    is a linear current sensor based on the Hall effect, which can measure AC and
    DC currents. It provides an analog voltage output proportional to the measured
    current. MQ2 and MQ135 are semiconductor gas sensors that can detect various gases.
    MQ2 [7] is used to detect combustible gases and smoke, while MQ135 [8] is used
    to monitor air quality. Both sensors provide analog outputs corresponding to gas
    concentration. The capacitive immersion sensor detects the presence of water by
    measuring the change in capacitance between two conductive plates when immersed
    in water. These sensors are used in the campus digital twin system to monitor
    current, gas, and water leakage conditions. The sytem has two databases: MySQL
    relational database and Redis memory data structure storage. MySQL is an open
    source relational database management system (RDBMS) that uses Structured Query
    Language (SQL) for data definition, operation, and retrieval [9]. It is widely
    used due to its performance, scalability, and ease of use. Redis is an in memory
    data structure storage that can be used as a database, cache, and message broker.
    It provides fast access to data structures such as strings, lists, sets, and hashes,
    and supports various data eviction strategies. In the proposed system, MySQL is
    used to store historical sensor data, while Redis stores real-time data for quick
    access and processing. The proposed system adopts Springboot backend framework
    and REST API implementation. Springboot is a Java based framework for building
    standalone, production level applications with minimal configuration. The system
    adopts Springboot to implement backend programs and exposes REST APIs, which follow
    a stateless client server architecture and use standard HTTP methods to achieve
    communication between the front-end and back-end [10]. Unreal Engine 5 and VaRest
    plugin are proposed for HTTP communication.Unreal Engine 5 is a cutting-edge game
    engine developed by Epic Games, providing powerful real-time rendering capabilities,
    advanced physical simulations, and powerful development tools. It is used to create
    a visually appealing immersive front-end for the campus digital twin system. The
    VaRest plugin is an extension of the Unreal Engine, which enables HTTP communication
    between game engines and external services. In the proposed system, it is used
    to send HTTP requests to the backend REST API, obtain real-time data, and render
    in the Unreal Engine 5 environment. Modeling takes advantages of using drone tilt
    photography technology.Unmanned aerial vehicle (UAV) tilt photography technology
    is a method of generating three-dimensional models by using UAVs to capture ground
    targets from different angles and heights. This technology captures photos from
    multiple perspectives and utilizes optical principles and geometric relationships
    to concatenate these photos, thereby generating high-precision and high-resolution
    3D models. In the campus digital twin system, unmanned aerial vehicle tilt photography
    technology is used to model campus buildings, roads, and other infrastructure.
    These generated 3D models are imported into Unreal Engine 5 to visualize the campus
    environment and provide a background for real-time data rendering [11]. The 3D
    model generated through drone tilt photography technology has a high degree of
    realism and detail. Compared with traditional modeling methods, drone tilt photography
    technology can quickly and efficiently establish three-dimensional models of complex
    environments. In addition, with the development of drone technology, it has significant
    advantages in terms of cost and ease of use, providing a high-quality three-dimensional
    environment for digital twin systems. Figure 1. System architecture diagram Show
    All The workflow of the campus digital twin system includes real-time data collection
    by sensor nodes, packaging through the ESP8266 microcontroller, and transmitting
    to the backend server using the MQTT protocol [13]-[14]. The server receives and
    parses data, which is stored in MySQL and Redis databases. When the current end
    requests data, the backend service based on Springboot provides a REST API interface.
    At the same time, use drone tilt photography technology to model and import Unreal
    Engine 5. Finally, the front-end display module renders in real-time through the
    Unreal Engine 5 and communicates with the backend REST API to achieve visual display
    of campus environment simulation. SECTION V. System Implementation A. Data Acquisition
    and Transmission Module In this design, ACS712 current sensor is used to convert
    the obtained AC current into analog voltage signal, which is sent to ESP-8266
    chip through A0 port. The data is sampled and processed, and then communicated
    wirelessly through WiFi module. The system circuit is shown in Figure 2. MQ2 smoke
    sensor is used to monitor the concentration of smoke in the environment, in order
    to detect fire hazards in a timely manner. MQ2 sensor is based on SnO2 material
    and has high sensitivity and good selectivity. As the concentration of smoke increases,
    the conductivity of SnO2 materials also increases, thereby achieving detection
    of smoke concentration. This sensor plays an important role in fire warning systems.
    The system circuit is shown in Figure 3. Figure 2. ACS712 circuit diagram Show
    All Figure 3. MQ-2 circuit diagram Show All MQ135 air quality sensor is used to
    detect harmful gases in the air, such as carbon dioxide, ammonia, hydrogen sulfide,
    etc., to evaluate air quality. The MQ135 sensor utilizes specific chemical reactions
    to respond to different types of harmful gases in the air. Its sensitivity and
    selectivity are optimized by adjusting electrode materials and operating conditions
    to meet the needs of environmental monitoring. The system circuit is shown in
    Figure 4. Figure 4. MQ-135 circuit diagram Show All Capacitive immersion sensor
    is used to detect water accumulation on the ground and warn of flood disaster
    risks. The capacitive immersion sensor is based on the principle of capacitance
    and senses changes in water level by detecting changes in capacitance values.
    When the water level rises, the capacitance value on the sensor will change, enabling
    monitoring of water accumulation. This sensor is widely used in fields such as
    reservoirs, rivers, and urban drainage systems. The digital twin system on this
    campus utilizes electromagnetic relays to achieve reverse control between virtual
    engine 5 user operations and real-world devices. By communicating with the backend
    server through a virtual engine, user operation information is sent to the ESP8266
    microcontroller, which then controls the electromagnetic relay to perform corresponding
    actions, such as turning on or off the circuit. This integration solution achieves
    seamless integration between virtual operations and real device control, providing
    an interactive experience. The system circuit is shown in Figure 5. Figure 5.
    Relay circuit diagram Show All ESP8266 WiFi microcontroller and MQTT protocol
    are used in the proposed system.The ESP8266 Wi Fi microcontroller, as a highly
    integrated IoT SoC, plays a key role in the digital twin system of our campus
    due to its low power consumption, low cost, and high performance. In the system,
    ESP8266 is responsible for packaging the data collected by sensor nodes and sending
    it to the backend server through a wireless network. To ensure real-time communication
    and data transmission stability, a lightweight message transmission protocol MQTT
    based on publish/subscribe mode was adopted. The MQTT protocol is designed for
    low bandwidth, high latency, or unstable network environments, communicating through
    TCP/IP networks to achieve reliable data transmission between devices and applications.
    By comprehensively utilizing the ESP8266 microcontroller and MQTT protocol, the
    system has achieved efficient and reliable data transmission in the field of the
    Internet of Things [15]. B. Data Parsing and Storage Module In this study, the
    key to implementing the Python data parsing section is to process sensor data
    and store it effectively. Firstly, establish a connection between the Python end
    and the MQTT server through the paho mqtt library, and subscribe to specific topics
    to receive sensor data. After receiving sensor data, the data is presented in
    string form and needs to be segmented and parsed. Using Python''s string split
    function, data is segmented based on specific delimiters to extract various data
    fields.During the parsing process, dirty data may be encountered, such as formatting
    errors or incomplete data. To ensure data quality, it is necessary to clean and
    process dirty data. According to the characteristics of sensor data in this study,
    we choose to skip dirty data for processing.After data cleaning is completed,
    store the data in Redis and MySQL databases. Utilize redis py and pymysql libraries
    to implement data storage operations. According to business needs, choose to store
    data in Redis cache or MySQL database to achieve efficient data access and queries.For
    sensor data, methods such as statistics and average value calculation, storage
    optimization, and threshold setting are used for optimization processing, effectively
    reducing data storage space waste while ensuring accurate restoration of hazardous
    events. Finally, use the Java side to query MySQL or other relational database
    to realize the backtracking and presentation of historical data for visual presentation
    in the game engine. To meet the storage requirements of real-time and historical
    data in the campus digital twin system, we have adopted MySQL and Redis databases.
    MySQL, as a relational database, is suitable for storing historical data, while
    Redis, as an in memory database, is suitable for storing real-time data.Use Python''s
    pymysql library to interact with MySQL databases. Firstly, establish a database
    connection and then create a data table to store the data collected by the sensor.
    Each record includes fields such as sensor type, data value, timestamp, etc. When
    uploading sensor data, parse the data through Python and insert the parsed data
    into the corresponding data table. In addition, data query functions can be implemented
    on the Java backend for querying historical data and displaying it in a virtual
    engine.Use Python''s Redis py library to interact with the Redis database. When
    uploading sensor data, store the data in Redis. To avoid excessive memory usage,
    an expiration time can be set. On the Java backend, sensor data can be quickly
    obtained by accessing the Redis database. As Redis is an in memory database, data
    reading speed is very fast, and sensor data can be displayed in real-time in game
    engines to improve user experience. C. Backend Program Design and Interface Implementation
    The Springboot framework, which is a lightweight and fast development framework
    based on Spring. It has features such as automatic configuration, built-in servers,
    and independent operation, which can help us quickly build and deploy backend
    applications. The backend program is mainly responsible for processing requests
    from the front-end, accessing databases, and responding to data. To realize these
    functions, we need to create components such as controller, service layer and
    data access layer. By implementing the REST API interface, the front-end can easily
    request sensor data and system status information. The REST API has good scalability
    and ease of use, following the RESTful style and implementing resource operations
    through HTTP methods such as GET, POST, PUT, DELETE, etc. We have defined a series
    of API interfaces for functions such as obtaining sensor data, querying historical
    data, and controlling devices [16]. To ensure the security and reliability of
    data transmission, we use JSON format for data encapsulation and transmission.
    JSON has good cross platform compatibility and is easy to parse, which can meet
    the data exchange needs between the front-end and back-end. The backend structure
    is shown in Figure 6. Figure 6. Backend architecture diagram Show All D. Oblique
    Photography and 3D Reconstruction Image acquisition adopts the Dajiang Elf 4 Pro
    drone, takes high-resolution photos in a field shaped manner based on a pre designed
    route to ensure clear and recognizable ground targets.Conduct route planning in
    the drone flight control software, setting parameters such as shooting interval,
    flight altitude, and overlap to ensure complete coverage of ground targets. In
    this article, the Tianzi method is used for shooting. The captured image sequence
    is shown in Figure 7. Figure 7. Collected image sequence Show All Firstly, the
    image preprocessing is required for aerial triangle solving, including geometric
    correction, radiometric correction, and image enhancement, to improve the accuracy
    and effectiveness of subsequent 3D reconstruction.Then submit aerial triangulation,
    using the overlapping areas between adjacent photos, perform aerial triangulation
    through feature point matching and beam adjustment calculation, and obtain camera
    pose and ground control point coordinates. Finally, a three-dimensional point
    cloud is generated, and based on the results of aerial triangulation, a multi
    view stereo matching algorithm is used to generate high-precision three-dimensional
    point cloud data. As shown in Figure 8. Figure 8. 3D point cloud generation Show
    All The first step of the three-dimensional reconstruction is to construct a triangular
    mesh, filtering, smoothing, and optimizing the generated 3D point cloud to construct
    a 3D triangular mesh model that represents the details of terrain and buildings.The
    second step is texture mapping. The pixel values of the original photos are projected
    onto the triangular mesh, and texture mapping is performed to generate a 3D model
    with true texture and color [17]. The reconstruction effect is shown in Figure
    9. Figure 9. 3D reconstruction result Show All E. Front-end Display and Data Rendering
    In Unreal 5 scene construction, the Cesium plugin is used to load the imported
    3D model. Regarding the layout of vegetation on campus, replant it to ensure its
    authenticity. At the same time, set the precise positions of each sensor and bind
    them with the corresponding effects to meet the data monitoring needs. When setting
    the operating range of the electromagnetic relay, ensure that it is successfully
    bound to the backend API to achieve reverse control between user operation and
    the real world [18]. In VaRest plugin configuration and usage,firstly, download
    the VaRest plugin from the Unreal Engine Market and install it into the project.
    Enable plugins in project settings to ensure their normal operation.Create HTTP
    request in the blueprint, call the \"Create HTTP Request\" node of the VaRest
    library to create a new HTTP request. Specify the request method (such as GET
    or POST) and target URL, and set the request header and body according to the
    requirements.Request callback and processing is to add a callback function to
    the request to handle the response returned by the server. In the callback function,
    parse the response content (such as JSON format data) and map it to the corresponding
    function or effect in the game. The VaRest plugin supports asynchronous requests
    and can be executed during game execution. By setting appropriate delay times
    and event triggering conditions, ensure that game performance is not affected
    by HTTP requests [19]. The specific process is shown in Figure 10. Figure 10.
    VaRest workflow diagram Show All In Unreal Engine 5, data rendering and display
    convert real-time or historical sensor data into realistic game scenes. Firstly,
    parse the JSON format data obtained from the backend server through blueprint
    or C++coding. Then, create game objects (such as light sources, particle effects,
    etc.) in the scene, map the parsed data to the attributes of these objects, and
    dynamically adjust the attributes based on real-time data. Next, use the UMG system
    to create a data dashboard and present the data in graphical or textual form.
    Finally, achieve scene and user interaction, such as adding triggers or collision
    objects to view detailed information and providing visual and audio feedback.
    Through these steps, Unreal Engine 5 can efficiently present sensor data [20].
    As shown in Figure 11, when smoke is detected, render flames and smoke within
    the scene. Figure 11. Game engine-rendered fire scene Show All SECTION VI. Conclusions
    This study implemented an intelligent campus environment with real-time monitoring
    and interaction functions through Unreal Engine 5, Internet of Things technology,
    and sensor data. Various sensor devices are used to collect data, and it used
    the MQTT protocol for data communication, and combined MySQL and Redis databases
    to complete data storage and querying. In Unreal Engine 5, it utilized the Cesium
    plugin and VaRest plugin for 3D scene construction, data rendering, and display,
    enabling sensor data to be presented to users in a more intuitive and realistic
    manner. It can optimize and expand in the following areas of introducing more
    types of sensors to improve monitoring range and accuracy; combining virtual reality
    or augmented reality technology to further enhance the realism and user experience
    of the scene, and using artificial intelligence and machine learning technology
    to analyze historical data and achieve intelligent warning and decision-making
    assistance functions. ACKNOWLEDGMENT This paper is supported by Beijing City University
    College Student Innovation and Entrepreneurship Training Program Project. Authors
    Figures References Keywords Metrics More Like This A message passing protocol
    for small-scale distributed real-time systems Proceedings World Automation Congress,
    2004. Published: 2004 Shift-exchange Synchronization Protocol(SESP) in hard real
    time system 2017 IEEE 2nd Advanced Information Technology, Electronic and Automation
    Control Conference (IAEAC) Published: 2017 Show More IEEE Personal Account CHANGE
    USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile
    Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS
    Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT
    Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use |
    Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy
    A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 IEEE International Conference on Sensors, Electronics and Computer
    Engineering, ICSECE 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Implementation of Campus Digital Twin System Based on Game Engine
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wang E.
  - Tayebi P.
  - Song Y.T.
  citation_count: '0'
  description: In this paper, we explore the potential of utilizing Digital Twin (DT)
    technology for real-Time data storage and processing in emergency healthcare.
    Focusing on Internet of Things (IoT) and cloud computing technologies, we investigate
    various enabling technologies, including cloud platforms, data transmission formats,
    and storage file formats, to develop a feasible DT storage solution for emergency
    healthcare. Through our analysis, we find Amazon AWS to be the most suitable cloud
    platform due to its sophisticated real-Time data processing and analytical tools.
    Additionally, we determine that the MQTT protocol is suitable for real-Time medical
    data transmission, and FHIR is the most appropriate medical file storage format
    for emergency healthcare situations.We propose a cloud-based DT storage solution,
    in which real-Time medical data is transmitted to AWS IoT Core, processed by Kinesis
    Data Analytics, and stored securely in AWS HealthLake. Despite the feasibility
    of the proposed solution, challenges such as insufficient access control, lack
    of encryption, and vendor conformity must be addressed for successful practical
    implementation. Future work may involve incorporating Hyperledger Fabric technology
    and HTTPS protocol to enhance security, while the maturation of DT technology
    is expected to resolve vendor conformity issues. By addressing these challenges,
    our proposed DT storage solution has the potential to improve data accessibility
    and decision-making in emergency healthcare settings.
  doi: 10.1109/SERA57763.2023.10197705
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 IEEE/ACIS 21st Internati... Cloud-based
    Digital Twins Storage in Emergency Healthcare Publisher: IEEE Cite This PDF Erdan
    Wang; Pouria Tayebi; Yeong-Tae Song All Authors 160 Full Text Views Abstract Document
    Sections I. Introduction II. Related Works III. Enabling Technologies IV. Discussion
    on Our Proposal V. Conclusion and Future Work Authors Figures References Keywords
    Metrics Footnotes Abstract: In this paper, we explore the potential of utilizing
    Digital Twin (DT) technology for real-time data storage and processing in emergency
    healthcare. Focusing on Internet of Things (IoT) and cloud computing technologies,
    we investigate various enabling technologies, including cloud platforms, data
    transmission formats, and storage file formats, to develop a feasible DT storage
    solution for emergency healthcare. Through our analysis, we find Amazon AWS to
    be the most suitable cloud platform due to its sophisticated real-time data processing
    and analytical tools. Additionally, we determine that the MQTT protocol is suitable
    for real-time medical data transmission, and FHIR is the most appropriate medical
    file storage format for emergency healthcare situations.We propose a cloud-based
    DT storage solution, in which real-time medical data is transmitted to AWS IoT
    Core, processed by Kinesis Data Analytics, and stored securely in AWS HealthLake.
    Despite the feasibility of the proposed solution, challenges such as insufficient
    access control, lack of encryption, and vendor conformity must be addressed for
    successful practical implementation. Future work may involve incorporating Hyperledger
    Fabric technology and HTTPS protocol to enhance security, while the maturation
    of DT technology is expected to resolve vendor conformity issues. By addressing
    these challenges, our proposed DT storage solution has the potential to improve
    data accessibility and decision-making in emergency healthcare settings. Published
    in: 2023 IEEE/ACIS 21st International Conference on Software Engineering Research,
    Management and Applications (SERA) Date of Conference: 23-25 May 2023 Date Added
    to IEEE Xplore: 03 August 2023 ISBN Information: ISSN Information: DOI: 10.1109/SERA57763.2023.10197705
    Publisher: IEEE Conference Location: Orlando, FL, USA SECTION I. Introduction
    In contemporary emergency healthcare, there is a scarcity of effective methods
    for sharing patient information between physicians in the Emergency Department
    (ED) and paramedics in an ambulance. Consequently, patient demographics, chief
    complaints, vital signs, treatment responses, and other medical data are typically
    transmitted through verbal or written reports. This mode of communication could
    potentially result in miscommunication or the omission of crucial medical information,
    particularly in time-sensitive situations such as myocardial infarctions. Traditional
    Electronic Health Record (EHR) and Electronic Medical Record (EMR) systems can
    store and share static medical records but lack the capability to process and
    share real-time medical data, such as electrocardiograms (EKG) and peripheral
    capillary oxygen saturation (SpO2). Employing patients'' Digital Twins (DT) could
    address this challenge, as DT can store, process, analyze, and share data in real-time.
    Moreover, paramedics might leverage patients'' DTs to simulate treatment and medication
    responses. Although the definition of digital twins varies according to different
    authors'' perspectives, the fundamental concepts remain consistent. Digital twins
    represent virtual replicas of physical objects that facilitate sharing, analyzing,
    optimizing, and predicting the performance of their real-world counterparts [1].
    Fundamentally, digital twins comprise the digital model of a physical object,
    historical data, and real-time data. Real-time data processing (unidirectional
    or bidirectional) is a critical element that differentiates DT from other digital
    approaches, such as simulation and digital modeling. DT enables bidirectional
    human-out-of-the-loop communication between the physical system and the virtual
    model. Data transfer from a physical object to the DT is processed, analyzed,
    and evaluated, potentially offering predictions for the object''s performance
    and status. Additionally, data feedback from the DT to the physical object can
    facilitate notifications or control actions. Within an emergency healthcare context,
    DT could be employed to store and share a patient''s real-time vital sign data
    from the ambulance and static medical records, including demographics, chief complaints,
    treatments, and medications. Furthermore, DT offers potential simulation and estimation
    capabilities, which could be pivotal in determining patient treatment and medication
    choices. This paper presents a cloud-based DT solution to address the challenges
    of storing patients'' medical information (both real-time and static) in emergency
    healthcare settings. The subsequent sections of the paper encompass a review of
    related works, an examination of the enabling technologies, a discussion of the
    proposed solution, and a conclusion. SECTION II. Related Works A. Digital Twins
    and Healthcare Although Digital Twins (DT) represent a relatively nascent technology,
    researchers have already investigated its application within the healthcare domain,
    yielding promising outcomes. Song et al. [2] conducted a survey on the utilization
    of DT in personal healthcare, proposing its use for assessing and maintaining
    individual health. They argued that the quality of a DT is contingent upon the
    completeness, update frequency, and accuracy of the observed data, which encompasses
    personalized risk factors such as behavior, vital signs, or symptoms. Xie et al.
    [3] applied DT and data mining techniques to electroencephalogram (EEG) data and
    medical history from the SEER database of patients, subsequently providing health
    status and feedback. Luis F. Rivera et al. [4] outlined their vision for implementing
    DT in precision medicine, developing a reference model that capitalizes on DT
    capabilities, self-adaptive systems, and autonomic computing to engineer intelligent
    and flexible software systems for healthcare. The authors also delineated internal
    structures for DT to support precision medicine methodologies in the context of
    continuous monitoring and personalized, data-driven medical treatments. B. Internet
    of Things and Cloud Computing Various technologies can facilitate DT implementation,
    including the Internet of Things (IoT), cloud computing platforms, edge computing,
    APIs and integration platforms, machine learning and AI, and blockchain and distributed
    ledger technologies. This paper specifically concentrates on IoT and cloud computing
    as enablers of DT storage. Khaled et al. [5] designed a motor and wind turbine
    DT model using Simscape and Simulink, subsequently deploying the DT model on the
    Amazon AWS cloud. Saad et al. [6] proposed a cloud-based DT solution for power
    grid distribution systems, importing DT models into the AWS Lambda function and
    employing AWS Greengrass at the edge to extend cloud system functionality to IoT
    devices. Wang et al. [7] suggested an AWS-based Mobile Digital Twin (MDT) solution
    for personalized adaptive cruise control. The MDT (Fig. 1), comprising multiple
    DTs and interactions among them, represents a relatively comprehensive IoT and
    cloud solution for DT. The concept of cloud-based DT was validated and tested,
    with results demonstrating the feasibility of real-time DT implementation based
    on IoT and cloud computing technologies. Fig. 1. MDT cloud solution proposed by
    Wang et al. [7] Show All SECTION III. Enabling Technologies The focus of this
    paper is on identifying a practical and viable solution for storing Digital Twins
    (DT) in emergency healthcare. To this end, several technologies pertinent to DT
    cloud storage are surveyed, including cloud platforms, data transmission formats,
    and file storage formats. A. Cloud Platforms Table I and Table II presents the
    results of the cloud platform survey. The table juxtaposes DT storage-related
    technologies from three major cloud service providers. In terms of services for
    medical file storage and processing, Amazon offers Healthcare Lake services, Microsoft
    Azure features Azure API for FHIR, and Google Cloud provides the Google Cloud
    Healthcare API. These services facilitate the storage, management, and analysis
    of health data in the cloud while adhering to standards such as FHIR, DICOM, and
    HL7. TABLE I. The Survey of Cloud Services TABLE II. The Survey of Cloud Services
    (CONTINUED) Regarding DT services, Amazon introduces AWS IoT TwinMaker, Microsoft
    supplies Azure Digital Twins and Digital Twin Definition Language, and Google
    offers Supply Chain Twin. These services enable the creation, visualization, and
    management of digital twins for IoT devices and systems, allowing for real-time
    synchronization, enhanced analytics, predictive maintenance, and improved decision-making.
    Real-time data stream processing is a vital component for storing and processing
    real-time data generated by medical devices in emergency healthcare settings.
    Amazon provides Kinesis data streams/analytics, Microsoft offers Azure Stream
    Analytics, and Google features Cloud Streaming Analytics. These services ensure
    efficient and reliable data processing and analysis, empowering data-driven decision-making
    and rapid response to changing conditions. In emergency healthcare environments,
    all data transmission and storage must comply with HIPAA regulations. This necessitates
    the encryption and validation of data generated by medical devices. While none
    of the surveyed cloud platforms offer specific IoMT services, they all assert
    that their IoT services comply with HIPAA. Each cloud platform has signed a standard
    Business Associate Addendum (BAA), implying that the services listed under the
    BAA adhere to HIPAA regulations. B. Data Transmission Format In emergency healthcare
    settings, the Message Queuing Telemetry Transport (MQTT) protocol ensures real-time
    transmission of data streams generated by medical equipment. MQTT is a lightweight,
    publish-subscribe messaging protocol designed for efficient and reliable communication
    between IoT devices, even in constrained or low-bandwidth environments. C. Storage
    File Format Upon arriving at the cloud platforms, the real-time medical data stream
    is subjected to various processing steps and directed to two distinct destinations.
    The first destination entails immediate real-time processing and transmission
    to the Emergency Department (ED) of the recipient hospital. Conversely, the second
    destination involves the storage of the data within the Digital Twin (DT) residing
    in the cloud. The real-time medical data may be stored in one of two file formats
    within the DT. 1) HL7 C-CDA Health Level Seven Consolidated Clinical Document
    Architecture (HL7 C-CDA) is a standard for the exchange of electronic health information
    in a structured, interoperable format. It builds upon the Clinical Document Architecture
    (CDA) standard, which defines the structure and semantics of clinical documents,
    such as discharge summaries, progress notes, and history and physical reports.
    C-CDA is a part of the broader HL7 framework, a set of international standards
    for the exchange, integration, sharing, and retrieval of electronic health information.
    HL7 C-CDA provides a unified approach to structuring clinical documents by consolidating
    multiple CDA implementation guides into a single, harmonized standard. 2) HL7
    FHIR HL7 FHIR (Fast Healthcare Interoperability Resources) is a modern, web-based
    standard for exchanging healthcare information between systems in a secure, efficient,
    and interoperable manner. FHIR is designed to address the complexities and challenges
    of healthcare data exchange, making it easier for healthcare organizations to
    share and integrate patient data. SECTION IV. Discussion on Our Proposal Upon
    examining the enabling technologies discussed in the preceding section, several
    observations can be made. All three cloud platforms demonstrate their suitability
    for constructing DT storage in emergency healthcare. However, since our study
    primarily focuses on the storage of real-time data within DT, Amazon AWS offers
    more sophisticated and powerful real-time data processing and analytical tools
    compared to Microsoft Azure and Google Cloud. Consequently, we have selected AWS
    as the cloud platform upon which we will construct our DT storage solution. The
    MQTT protocol is deemed appropriate for transmitting real-time medical data, and
    as for the medical file storage format, FHIR is better suited for emergency healthcare
    scenarios due to its granularity, flexibility, and efficient API, which makes
    it an optimal choice for real-time data storage and exchange in most situations.
    Figure 2 illustrates the proposed cloud-based DT storage solution for emergency
    healthcare. Data generated by medical equipment in an ambulance is transmitted
    to a Raspberry Pi, which converts the data into MQTT messages. These messages
    are subsequently sent to the IoT Gateway of AWS IoT Core within the AWS cloud.
    The IoT gateway forwards messages to the SNS Topic, a fully managed, scalable
    messaging service that enables the transmission of messages or notifications to
    multiple subscribers via a centralized \"topic\" that supports various protocols,
    such as email, SMS, and HTTP(S). Data entering the IoT core is also routed to
    AWS Kinesis through forwarding rules. Kinesis creates a tabular representation
    of the data that can be queried by Kinesis Data Analytics. A web server deployed
    on Amazon EC2 receives the data stream from Kinesis Data Stream, and handheld
    devices in the ED of the recipient hospital can access the web server to view
    real-time patient medical data. The Kinesis Data Stream may also be transmitted
    to an AWS Lambda function that converts the data stream into FHIR files, which
    are subsequently received and stored by AWS HealthLake. Fig. 2. Proposed cloud-based
    DT storage solution Show All Although the proposed solution appears viable, several
    challenges must be addressed before practical implementation can occur: Inadequate
    access control may allow unauthorized and potentially malicious actors to gain
    control of a cloud-based DT. This issue may be resolved in future work by incorporating
    Hyperledger Fabric technology. The absence of encryption may lead to unintentional
    personal health data leakage, potentially violating HIPAA regulations. This issue
    can be addressed by implementing the HTTPS protocol. A lack of vendor conformity
    may impede the adoption of the solution. While DT is a rapidly evolving technology,
    its maturity has not yet been fully realized. As the technology readiness level
    of DT becomes more established, this issue is expected to resolve itself. SECTION
    V. Conclusion and Future Work This paper presents an extensive literature review
    on the intersection of digital twins (DT), healthcare, the Internet of Things
    (IoT), and cloud computing. The study surveys a wide range of enabling technologies,
    encompassing DT services offered by cloud platforms, data transmission protocols,
    and storage file formats. Through a comprehensive analysis of the surveyed findings,
    the paper suggests a cloud-based DT storage solution for emergency healthcare
    scenarios, emphasizing the development of a viable and pragmatic approach. Future
    research endeavors will focus on refining and optimizing the proposed solution,
    with a particular emphasis on adherence to the Health Insurance Portability and
    Accountability Act (HIPAA) regulations. The refined solution may incorporate advanced
    security technologies, such as blockchain-based Hyperledger Fabric, ultimately
    evolving into a Digital Twin as a Service (DTaaS) offering. Authors Figures References
    Keywords Metrics Footnotes More Like This On the Off-Chip Memory Latency of Real-Time
    Systems: Is DDR DRAM Really the Best Option? 2018 IEEE Real-Time Systems Symposium
    (RTSS) Published: 2018 Work-in-Progress: Lock-Based Software Transactional Memory
    for Real-Time Systems 2018 IEEE Real-Time Systems Symposium (RTSS) Published:
    2018 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 2023 IEEE/ACIS 21st International Conference on Software
    Engineering Research, Management and Applications, SERA 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Cloud-based Digital Twins Storage in Emergency Healthcare
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Muse P.
  - Mercy Shalinie S.
  - Stanly H.
  citation_count: '0'
  description: Efficient log analysis involves collecting, evaluating, and managing
    raw data from computer-generated records. As security vulnerabilities increase,
    the analysis of logs has become vital and crucial in multidisciplinary domains.
    Maintaining and analyzing the log is a pivotal part of every organization as tons
    of logs are generated every millisecond. However, anomaly detection and log parsing
    addressed so far, rely on a time-consuming training algorithm based on a Machine
    Learning framework. The proposed method detects anomalies from real-time data
    generated from the data centre without the need for a training algorithm. Detection
    and visualization of malicious activities are done by Elasticsearch, Logstash,
    and Kibana (ELK) framework. The process of shipping, parsing, indexing, and anomaly
    detection is carried out using an unsupervised machine learning algorithm which
    gives a clear inference to detect bots and perform unique log session classification.
    A real-time Apache HTTP Server log is accessed and anomalous behavior is identified
    based on the incoming requests. Experiments on real-time data show that 13.76%
    of anomalies are detected on per weekly basis.
  doi: 10.1109/PCEMS58491.2023.10136101
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 2nd International Confer... Online
    Log Analysis(OLA) for Malicious User Activities Publisher: IEEE Cite This PDF
    Poongkuyil Muse; Mercy Shalinie S; Hamil Stanly All Authors 75 Full Text Views
    Abstract Document Sections I. Introduction II. Related Works III. Proposed Methodology-Ola
    Framework IV. Results and Discussion VI. Conclusion and Future Works Authors Figures
    References Keywords Metrics Abstract: Efficient log analysis involves collecting,
    evaluating, and managing raw data from computer-generated records. As security
    vulnerabilities increase, the analysis of logs has become vital and crucial in
    multidisciplinary domains. Maintaining and analyzing the log is a pivotal part
    of every organization as tons of logs are generated every millisecond. However,
    anomaly detection and log parsing addressed so far, rely on a time-consuming training
    algorithm based on a Machine Learning framework. The proposed method detects anomalies
    from real-time data generated from the data centre without the need for a training
    algorithm. Detection and visualization of malicious activities are done by Elasticsearch,
    Logstash, and Kibana (ELK) framework. The process of shipping, parsing, indexing,
    and anomaly detection is carried out using an unsupervised machine learning algorithm
    which gives a clear inference to detect bots and perform unique log session classification.
    A real-time Apache HTTP Server log is accessed and anomalous behavior is identified
    based on the incoming requests. Experiments on real-time data show that 13.76%
    of anomalies are detected on per weekly basis. Published in: 2023 2nd International
    Conference on Paradigm Shifts in Communications Embedded Systems, Machine Learning
    and Signal Processing (PCEMS) Date of Conference: 05-06 April 2023 Date Added
    to IEEE Xplore: 02 June 2023 ISBN Information: DOI: 10.1109/PCEMS58491.2023.10136101
    Publisher: IEEE Conference Location: Nagpur, India SECTION I. Introduction Logs
    are historical records in the form of a systemgenerated textual data file that
    records the time-stamped events that occur in the system. Log files are unstructured
    records that store information about the state of the application program. Logs
    are generated automatically to maintain a record of events on the server. Logs
    are raw data that are more complex to analyze. Extracting the semantic information
    from the log files is even more tedious. These logs exist in the form of records
    in a text file, database, or on a remote web service. These log data are also
    called audit logs, audit records, audit trails, or event logs. Log records help
    developers to maintain the execution of the application, along with the usage
    pattern. Any deviation in the expected outcome can be identified with these logs.
    It helps in identifying the errors, the cause of errors, and the ways to eliminate
    them. Logs provide information about various factors, like the origin of the users,
    requests for each page made by a user, frequency of users visiting the same page,
    and an overview of web traffic, which helps in the surveillance of the system.
    Log data provide an overview of web traffic as well as the end-user interaction
    with the application. Such a scenario can be found in user behaviors while using
    a different application. It helps companies use their websites and address customers
    more efficiently. Apart from the error messages, a typical log record consists
    of a timestamp, message, status code, and id if any. An effective logging system
    manages the maintenance of the environment, and error-free infrastructure and
    thereby requires only less time to fix errors. Log analysis is the method of analyzing
    log entries and drafting useful knowledge from them. Log analytics includes searching
    for patterns in logs, analyzing those patterns to gain operational insights, and
    finally visualizing them for a better understanding of the working environment.
    Log analysis discloses relevant information on security, server functionalities,
    and user behavior. It helps in extracting semantic information from logs to derive
    the root cause of system errors that assist in taking business decisions. Log
    Data Analysis helps to measure internal safety, understand information security
    threats, diagnose systems, or networks, and understand end users’ behavior. Log
    Data Analysis gives information about, measuring internal safety as well as external
    guidance and auditing, understanding and responding to information security threats,
    diagnosing systems, computers, or networks for bugs, and understanding the behavior
    of end users. Elastic Stack and Security Information and Event Management (SIEM)
    technology supports threat detection, investigation, and response to threats.
    It helps in analyzing both near real-time and historical security events. It also
    enhances endpoint security by prevention, detection, and response across the entire
    network. ELK analytic engine tool overcomes the need for a training algorithm.
    ELK tool can detect and inspect anomalies in logs. Any anomalous behavior can
    be identified automatically, like, an increase in log rate which denote Distributed
    Denial of Service (DDoS)attack where continuous requests are made by bots or scripts.
    The rest of this paper is organized as follows. Section II briefly discusses the
    related work of log analysis. Section III discusses the steps involved in OLA
    that help to detect malicious activities. In section IV, the details of the results
    and discussion are discussed. Finally, Section V briefs the conclusion and future
    work. SECTION II. Related Works A typical log analysis consists of parsing, clustering,
    and finding outliers as the main task. ML Algorithms are employed to recognize
    interesting patterns in log data and to identify anomalies. The real-time analysis
    mainly focuses on cluster management. This process is accomplished by Skopik et
    al. [l] in four major pipelines. Clustering is done by Incremental event clustering
    technique which is a fully unsupervised technique that makes use of density and
    character-based clustering for effective grouping of similar logs. String similarity
    and N-Gram analysis are encountered to group similar events. The sequence alignment
    method is used to generate cluster templates. A parser module generates tree-like
    structures of the log lines. Time series analysis, correlation analysis, and sequence
    analysis are performed to detect anomalies. The main disadvantage of the Cluster-tree-based
    approach is that whenever an online log is encountered, the tree structure increases
    tremendously resulting in a negative influence on the performance of online log
    analysis. In the work proposed by Han et al. [2], the ROEAD framework performs
    log analysis for large-scale systems, where anomalies in HDFS logs are analyzed.
    Robust Feature Extraction (RFE) generates a feature matrix by extracting valuable
    features from log events using NLP thereby removing the noises in the log. The
    removal of noises includes cleaning log data, vectorization, and matching log
    lines using cosine similarity. The Online Evolving Anomaly Detection (OEAD) algorithm
    uses the feature vector matrix to detect anomalies. Online Evolving SVM (OE-SVM)
    machine learning algorithm was used to generate decision hyperplanes to differentiate
    categories. The L-weight vector and the G-max value of the feature vector are
    the main parameters in evaluating the performance. The accuracy decreases when
    G is too small resulting in fluctuation of the vector as the learning rate is
    too large. In contrast, a large G makes the vector converge slowly. Xiao et al.
    [4] proposed a Log Parser based on Vectorization (LPV) for both online and offline
    logs. This paper determines the similarity between two logs or templates exclusively
    for log parsing alone. This paper is limited to performing only parsing of tokens
    and patterns in the log line. The semantics of the log tokens are not considered.
    That is, the parser matches only the IP address but does not verify if it is a
    valid IP address. Also, the parsing template is limited to only a few public datasets
    like Blue Gene/L (BGL), HighPerformance Computing (HPC), and Hadoop Distributed
    File System (HDFS) Datasets. The efficiency of the LPV method is improved compared
    to Spell and Drain. Pan et al. [6] proposed a statistical learning algorithm to
    evaluate the confidence of prediction results in the field of system log anomaly
    detection. Two predictors were implemented based on logistic regression and support
    vector machines. Following this, experiments are carried out on the HDFS log dataset.
    A hyperplane using SVM is constructed to separate the anomalous logs. When a new
    instance is located above the hyperplane, it is reported as an anomaly. VennAbers
    predictors apply isotonic regression to transform the predicted results into probabilities.
    They calculate the label probability distribution of a set of samples and provide
    an evaluation of the validity of predictive labels with a degree of certainty.
    Meng et al. [7] proposed Log2 Vec that combines a logspecific word embedding method
    to accurately extract the semantic information of logs, with an OOV word processor
    to embed OOV words into vectors at runtime. log2Vec proposes the LSWE (Log Specific
    Word Embedding) method to extract semantic information from specific logs. The
    semantic information is collected by predicting the target word similar to the
    synonym or antonym of the word. log2Vec handles the classification of two logs
    having two different words with the same semantic and categorizes them. Thus,
    Log2Vec works well in extracting the semantic information from logs and categorizing
    them without failure prediction and root cause analysis. Xie et al. [8] proposed
    LogM for failure prediction and diagnosis on unstructured logs. LogM makes use
    of CAB net model to extract the semantic information and temporal dynamics of
    the sequential log data for failure prediction. This model aggregates logs that
    are involved in the same failure from different components. This correlation is
    enhanced to detect the root cause of the failure detection. LogM is trained with
    fewer logs, which gives better accuracy when similar events happen in real time.
    Using Siamese LSTM to detect semantic similarity between logs indicating failure
    of the nodes. All the techniques above consume more time during log processing
    at the time of cluster template generation. Typical anomaly detection in log analysis
    always follows a traditional pipeline - log collection, log parsing, log classification,
    and finally anomaly is detected based on the template that matches it. Some methods
    simply classify the logs into clusters. And whenever a new log is encountered,
    it checks with existing templates. If a suitable match is not found, it creates
    a new template as in [6]. The hyperplane is also used to separate normal logs
    and anomaly logs using SVM. Some methods classify the log into anomaly groups
    and match the logs having anomalies as in [8]. Lexical information is extracted
    as in [7, 8], providing semantic information about the logs in terms of classification.
    Words depicting the same semantics, but different words are also enhanced as in
    [7]. Hassan et al. [11] proposed an ELK tool to analyze the DNS traffic of the
    network with minimal data from accessing only three websites in three days. Only
    traffic analysis is achieved by showing a count of requests over a time period
    is visualized. Repeated requests and DNS tunneling (malware detection) are not
    analyzed. Bajer et al. [12] proposed ELK for the analysis and visualization of
    IOT data. IoT device data is transferred as signals from a Modbus TCP connection.
    However, the Node.js application was used to periodically read data from the device
    instead of logstash. Azure machine learning is used to identify patterns and correlations
    between data. This is now enhanced in logstash. Uday et al. [15] propose the identification
    of the defect in the health system that shows the status of the system and its
    location in a real-time environment. However, for a healthrelated application,
    intimation to the admin via email can be sent when the status of the system is
    critical. This can be achieved using open source ElastAlert plugin on integration
    with ELK. The proposed OLA framework captures the following key contributions
    to anomaly detection: The framework is tested on a real-time server dataset, collected
    from the data centre of Thiagarajar College of Engineering, Madurai. Apache HTTP
    web server log is used as the dataset. OLA framework works in an unsupervised
    manner using the ELK framework to detect un-trusted user anomalies without the
    need for a training algorithm. OLA framework provides visual results of the classification
    of trusted and un-trusted user agents. Capture unique user activity in a session
    and classify them separately. SECTION III. Proposed Methodology-Ola Framework
    ELK Stack is a combination of three open-source products namely Elasticsearch,
    Logstash, and Kibana. The ELK stack implements a centralized log management system
    to identify problems with applications or servers. It is a powerful tool that
    helps in finding issues on multiple servers within a specific time frame. ELK
    uses a data collection framework called Beats that deals with a large amount of
    data. Some similar frameworks include RabbitMQ and Kafka which deal with buffering
    and resilience. The logs are aggregated from different systems and applications
    which are then analyzed and visualized for monitoring anomalies. It results in
    faster troubleshooting and efficient security analytics. ELK Stack provides a
    simple yet robust log analysis solution to gain information on failure diagnosis,
    application performance, and infrastructure monitoring. The workflow pipeline
    of the ELK stack is further discussed and illustrated in Figure 1. The steps involved
    in the logging system are explained in the following five subsections. Fig. 1
    ELK Stack Framework Show All A. Shipping Logs Filebeat is a lightweight framework
    for forwarding and centralizing log data. It fetches data from multiple input
    locations and outputs them to a single location. Logs are shipped into logstash
    which processes the data. Filebeat adopts multiple input paths along with a single
    output path. Thus, logs from similarly configured servers can be sent to a single
    logstash instance. In the proposed work, real-time Apache HTTP server logs are
    used. In the configuration, the logs are stashed by collectively pushing to logstash
    port: 5044. B. Parsing Logs Logstash collects, processes, and forwards the data
    in terms of pipelines. Each pipeline consists of an input plugin, filter plugin,
    and output plugin. The input takes data from any source in structured or unstructured
    form. The filter plugin parses the log lines and finds patterns in them. Some
    filter plugins include grok, aggregate, elapsed, CSV, mutate, etc. The output
    plugin gives a Javascript Object Notation (JSON) result of the patterns found
    in a structured form. Log parsing translates any unstructured log into key-value
    pair of valuable features. The features include IP address, user agent, timestamp,
    and request method. The configuration setup of a logstash instance is shown in
    Figure 2. GROK is a logstash plugin to parse unstructured logs. Different kinds
    of logs like Syslog, web server logs, apache logs, and MySQL logs can be parsed.
    Grok matches the logs with the grok pattern and gives a structured result. A grok
    pattern is represented as %{SYNTAX: IDENTIFIER}. Figure 3 represents the result
    of the log parsing using GROK. The left column in the figure represents the GROK
    Syntax and the right column in the figure represents the features extracted after
    parsing. The user agent feature gives a detailed description of the device, the
    OS, and the browser used to send the request. This data is further useful in detecting
    untrusted user request anomalies in further sections. C. Indexing Logs Elasticsearch
    is a NoSQL Database based on the Lucene search engine and is built with Rpresentational
    State Transfer (RSTful) APIs. It provides schema-free, RST, and JSONbased distributed
    document storage that also supports the geolocation of IP addresses. Elasticsearch
    is a popular tool offering solutions on growing critical business needs and used
    by vendors like Walmart to gain business analytics to track insights into customer
    purchasing trends, SoftBank to prevent fraud and security threats, and GoDaddy
    to enhance user experience. The processed data is now stored in elasticsearch.
    This tool performs storing, searching, filtering, and querying a large capacity
    of data for insights. Kibana console is used to perform CRUD to the indices as
    in Table 1. Table I Elasticsearch Rest API D. User Activity Analysis 1) Classification
    of Unique Log Sessions: Aggregate is a logstash filter to aggregate information
    among events of the same IP. This filter helps in tracking user behavior during
    their logged time in the application. The classification of log analysis is performed
    on a single machine. Requests between login and logout are categorized into groups
    by introducing a new mapping variable trap-id’. Whenever a user logs in, the trap-id
    is incremented. Any further request made by the same user, during the login time,
    results in updating the trap-id. When logged out, the trap-id is set to 0. Again,
    when another user logs in, the trap-id is incremented. Thus Algorithm-l outlines
    the implementation of the classification of unique login sessions of unique users.
    Fig. 2 Logstash Configuration for shipping logs from Filebeat Show All Fig. 3
    Result of parsed log represented as key-value pair Show All E. Anomaly Detection
    1) Classification of Untrusted User Requests: Mutate is a logstash filter that
    runs specific commands while parsing a log. It performs CRUD operations by renaming,
    removing, adding, and modifying fields in log events. This filter plays a major
    role in simple anomaly detection in log files by just adding a field bot This
    ‘‘bot’’ field holds two values 0 or 1, indicating 0 as a trusted source and 1
    as the untrusted source. The identification of untrusted user anomalies is illustrated
    using Algorithm 2. Every time a request from a user is initiated, logstash looks
    for trusted user agents in the log message. Ifthe request comes from trusted agents
    like Chrome, Microsoft, Firefox, or Yandex Browser containing the word ‘‘bot’’
    in the user agent, such logs are considered as requests from untrusted sources
    and identified as bot:1. While the other case is identified as bot:0. This is
    because bots like GoogleBot, FacebookBot, YandexBot are used to increase insights
    of the website. Even scripts generating requests are also considered bots, as
    they are untrusted. Scripts are generated from Python, Java, and postman when
    the application is under testing. Developers use scripts to test the application,
    load balancing, and responsiveness of the application. Algorithm 1: Classification
    of Unique Log Session input: List of [message] of parsed logs in Sequential Order
    output: Unique Log Session 1 N= Number of total logs 2 for i=1 to N do 3 trapid
    ← clientip[i] 4 trap ← 0 5 ifrequest[i] = ‘‘login’’ then 6 trap incremented by
    1 7 map[trap] ← trap 8 trap ← map[trap] 9 else if request[i] = ‘‘logout’’ then
    10 trap ← map[trap] 11 map [trap] ← 0 12 else 13 trap ← map[trap]? map[trap]:
    0 14 endif 15 endfor Algorithm 2: Classification of Untrusted User Anomaly input:
    List of [message] of parsed logs in Sequential Order output: Bot anomaly classification
    N= Number of total logs for i=1 to N do if trusted-useragent in message[i] if
    message[i] has(bot, crawl, spider) bot ← 1 else bot ← 0 endif els e bot ← 1 endif
    endfor SECTION IV. Results and Discussion Kibana is a tool used to visualize and
    explore the log data. It uses visuals like histograms, line graphs, pie charts,
    heat maps, and a built-in map. Geographical information like IP addresses can
    be easily visualized using maps to gather details about region-specific information.
    Visualizing the data introduces new patterns and trends to discover any significant
    events or errors in the data. The Kibana Dashboard gives a section-wise report
    on real-time data. Kibana also uses search queries and filters to obtain a particular
    event from the data. A. Dataset OLA framework evaluates a real-time HTTP Apache
    server log dataset collected from the datacentre in Thiagarajar College of Engineering.
    The dataset is comprised of 4,38,600 log lines that are collected over a week.
    The size of the log is 122.079 MB. The log lines are unlabeled and unstructured
    that include main fields like clientip, timestamp, request, method, status, packets
    responded, etc, that help in understanding anomalous behavioral patterns for analyzing
    the server application. B. Untrusted Vs Trusted User Classification Kibana visualizes
    the percentage of the bot requests and trusted requests in a pie chart. This information
    can be extracted within any time frame in kibana. As per the result obtained,
    the percentage of bots is lesser than the trusted requests, even though there
    are numerous bot requests captured. In day-to-day life, there is an increase in
    bot requests, as they are also used to manually increase the application rating.
    This gives false information about user insights. Fig. 4 Result of Trusted Vs
    Untrusted Request Classification Show All Figure 4 shows the percentage of untrusted
    user requests. We have created two visualizations with the keyword ‘bot’. In Figure
    5, the visualization was added with a filter bot:1, showing the user agents of
    the bot requests. As a result, we have found that there is an enormous request
    initiated from BingBot, GoogleBot, FacebookBot, Spider, and YandexBot. Requests
    made by the Top 5 bot agents are shown in Figure 5. We also visualize the list
    of trusted requests. Figure 6 image shows the insights of the trusted user agents.
    Here, the visualization was added with a filter bot:0, only showing the user agents
    of the trusted requests. As a result, it is found that the requests from Mozilla
    Firefox, Google, Android, Yandex, and Opera are found to be trustworthy. Requests
    made by the top 5 trusted agents are shown in Figure 6. By analyzing the logs,
    it is found that the number of requests from malicious users is found to be 13.76%
    which is less compared to benign users which accounted for 86.24%. This analysis
    helps the administrator of the data centre to efficiently manage and monitor real-time
    logs and thereby identify malicious requests that are being spontaneously generated
    by an adversary to take control of the server and respond to untrusted user queries.
    OLA framework helps the administrators to strengthen the security parameters and
    resist malicious activities initiated by untrusted users. Fig. 5 Requests made
    by Top 5 Untrusted Bot Agents Show All Fig. 6 Requests made by Top 5 Trusted Bot
    Agents Show All C. Classification of Unique Log Session Unique logged-session
    classification is performed on a single machine. The result obtained is much similar
    to the classification made manually. Figure 7 shows the trap-id of each request
    made. The trap-id is 0 for un-logged requests. In Figure 8, the trap-id is the
    same for every request made by the same IP address in a logged session. Whenever
    a login request is encountered from an IP address, trap-id for that IP is incremented.
    The same IP address accessing other requests after login will have the same trap-id.
    This trap-id is set to 0 when the user logs out. This classification gives the
    unique activities done by each user. With this classification, we can analyze
    the unique activities of each user that gives insights about their usage of accessing
    the website. Fig. 7 trap(ID) for unique user session Show All Fig. 8 Result of
    single trap(ID) of 10.1292.1 during the logged session Show All The comparison
    of datasets from existing works [2], [9] is listed in Table 2. HDFS and BGL datasets
    are run on the OLA framework and the resulting outputs are highlighted in Table
    2. OLA framework was able to detect 13.76% of anomalies for real-time log data
    collected over a week. Comparatively, the OLA framework was able to detect more
    anomalies than the existing techniques. Table II Comparative Analysis of Anomaly
    Detection SECTION VI. Conclusion and Future Works Systematic log analysis helps
    organizations to be cautious of anomalous behavior. In this paper, we have proposed
    an ELK framework, a methodical log analysis substructure, which performs log operations
    like shipping, parsing, and indexing to detect and visualize anomalous behavior
    without the need for a time-consuming training algorithm. Parsing logs use a GROK
    filter to parse the unstructured log string to a structured format for extracting
    the features. The mutate and aggregate plugin is used in anomaly detection. The
    user-agent plugin extracts device details and browser details. The OLA framework
    made use of a real-time HTTP Apache Server log dataset for log analysis. It detected
    untrusted user request anomalies using the mutate plugin by matching only trusted
    user agents. We have classified the login session activity of every user using
    the aggregate plugin. This work can be extended in the future by providing alert
    information to the administrator whenever an anomaly is detected using the supervised
    machine learning approach in ELK Stack. Authors Figures References Keywords Metrics
    More Like This Research on 5G Signal Processing System Based on Computer Intelligent
    Machine Learning Algorithm 2023 IEEE 5th International Conference on Civil Aviation
    Safety and Information Technology (ICCASIT) Published: 2023 Design of Real-Time
    System Based on Machine Learning for Snoring and OSA Detection ICASSP 2022 - 2022
    IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
    Published: 2022 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase
    Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS
    PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA:
    +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE
    Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 2nd International Conference on Paradigm Shifts in Communications
    Embedded Systems, Machine Learning and Signal Processing, PCEMS 2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Online Log Analysis(OLA) for Malicious User Activities
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Singh P.K.
  - Singh B.
  - Parikh P.
  - Joshi M.
  citation_count: '0'
  description: In the current digital era, entrepreneurship has become a key differentiating
    reason in an extremely disruptive and competitive business environment to absorb
    constantly growing consumer demands. However, there is a need to comprehend the
    nuisances of digital entrepreneurship and its conceptual framework to navigate
    the associate businesses. IoT has a strong transformative potential to impact
    such entrepreneurship businesses. This paper discusses about the basic concept
    of IoT and briefly presents its security architecture. IoT connects diverse business
    entities and ‘things’ with real time data which is analyzed and combined with
    supplementary data in the cloud over varying platforms. This paper brings out
    briefly about some key platforms and their applications in entrepreneurship businesses.
    In this digital environment cognitive computing, artificial intelligence, machine
    learning and many other emerging technologies are driving new business capabilities
    with significant opportunities. Some prominent advantages of IoT platforms have
    been outlined in this paper. Different IoT application over distinct platforms
    are contributing to transform consumers’ lives and changing their entrepreneurship
    business operations. Yet, these platforms are beleaguered with certain challenges
    which have been briefly discussed in this paper. Today, almost 40 billion ‘things’
    are connected over the Internet. IoT appliances are likely to generate approximately
    180 zettabytes data annually by 2025. Massive entrepreneurship business activities
    in future will need powerful and sophisticated analytical engines to support it.
    By highlighting some significant future prospects of IoT supported entrepreneurship
    businesses, the paper has been concluded.
  doi: 10.1007/978-981-19-9876-8_18
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart Proceedings of International Conference
    on Recent Innovations in Computing pp 219–234Cite as Home Proceedings of International
    Conference on Recent Innovations in Computing Conference paper Emerging IoT Platforms
    Facilitate Entrepreneurship Businesses Praveen Kumar Singh, Bindu Singh, Pulkit
    Parikh & Mohil Joshi  Conference paper First Online: 03 May 2023 263 Accesses
    Part of the book series: Lecture Notes in Electrical Engineering ((LNEE,volume
    1001)) Abstract In the current digital era, entrepreneurship has become a key
    differentiating reason in an extremely disruptive and competitive business environment
    to absorb constantly growing consumer demands. However, there is a need to comprehend
    the nuisances of digital entrepreneurship and its conceptual framework to navigate
    the associate businesses. IoT has a strong transformative potential to impact
    such entrepreneurship businesses. This paper discusses about the basic concept
    of IoT and briefly presents its security architecture. IoT connects diverse business
    entities and ‘things’ with real time data which is analyzed and combined with
    supplementary data in the cloud over varying platforms. This paper brings out
    briefly about some key platforms and their applications in entrepreneurship businesses.
    In this digital environment cognitive computing, artificial intelligence, machine
    learning and many other emerging technologies are driving new business capabilities
    with significant opportunities. Some prominent advantages of IoT platforms have
    been outlined in this paper. Different IoT application over distinct platforms
    are contributing to transform consumers’ lives and changing their entrepreneurship
    business operations. Yet, these platforms are beleaguered with certain challenges
    which have been briefly discussed in this paper. Today, almost 40 billion ‘things’
    are connected over the Internet. IoT appliances are likely to generate approximately
    180 zettabytes data annually by 2025. Massive entrepreneurship business activities
    in future will need powerful and sophisticated analytical engines to support it.
    By highlighting some significant future prospects of IoT supported entrepreneurship
    businesses, the paper has been concluded. Keywords Entrepreneurship Digital Business
    IoT Platforms Data Technologies AIoT Architecture Security Risks Gateway HTTP
    Operation Access provided by University of Nebraska-Lincoln. Download conference
    paper PDF 1 Introduction Proliferation of Internet of Things (IoT) platforms and
    their associated protocols have potential to transform the entrepreneurship businesses.
    A massive amount of IoT devices are connected in different sizes, shapes, standards,
    configurations and protocols. Accomplishing real entrepreneurship businesses outcome
    with IoT needs a resolute effort. IoT devices are likely to generate 180 zettabytes
    of annual data by 2025. Such mammoth data will need the most powerful analytical
    and sophisticated engines that the world would have ever witnessed. An IoT platform
    can be referred as a suite of apparatuses which enables installation of varying
    apps to monitor, manage and control the devices that are connected to a shared
    server. It also facilitates the connected equipment to share their data with one
    another. An enterprise oriented IoT platform permits entrepreneurship businesses
    to sync and streamline their devices to produce a business insight needs to acquire
    the craving output. In order to do so, an IoT platform aligns strategically to
    the business entrepreneurships current as well as future requirements. Many entrepreneurship
    businesses have amended their way they used to operate by adopting IoT platforms.
    Weather we look at business-to-business (B2B) or business-to-consumer (B2C) to
    realize the decision alacrity, IoT technologies possess the ability to transform
    users’ both social and personal aspects of lives and to answer precarious business
    queries with better flexibility and more profound data insights. Transformation
    of an entrepreneurship business through an IoT platform is not only about a mindset,
    it has also become a mandatory need on how we understand and perceive the business
    ecosystem as a whole. Deployment of IoT platforms warrant placement of a large
    number of high-resolution data sensors to enable new entrepreneurship business
    models which otherwise are primarily driven through the physical products in the
    industry. It also drives a tremendous pressure on entrepreneurs to contemplate
    their ventures on IoT platforms to enable their businesses on such business models
    which potentially hold better prospects for them. The orchestration of these entrepreneurship
    business ecosystems can leverage these IoT platforms to re-define their customer
    value.  2 Entrepreneurship Businesses An entrepreneur is someone who organizes
    a business and then continues as an active contributor in that business operation.
    Entrepreneurs launch and carry on operating their own companies. Entrepreneurs
    finance their ventures through different sources like loans from investors, money
    from their close families or their own savings. It brings out the necessity and
    significance of a viable financial plan and a meticulous appreciation of the inherent
    risks involved in a successful entrepreneurship business. Entrepreneurship is
    about developing an idea for any exclusive or an occupied business. Learning about
    it and gaining experiences in varied business roles. It includes accounting, finance,
    marketing and management. It is about making a business plan, identifying and
    establishing sources for funding, recruiting talents with requisite skills of
    both workers and managers, testing, creating a support system, implementing and
    maintaining its company’s products. It is also about devise business strategies
    to launch their products or services to attract new as well as retaining existing
    customers. After the entrepreneur has established the business, it’s about seeking
    out different ways to raise the revenue. It could be also by indulging into new
    ventures as well as in product lines. There are certain factors which assume significance
    in the path to accomplishments of the business entrepreneurs. These include political,
    legal considerations, taxation and the availability of desired capital to establish
    as well as to scale up the business entrepreneurships. Nation’s political situations
    and law of the land become a critical factor to offer a conducive environment
    to facilitate the growth of such entrepreneurships. A heavy taxation imposed by
    the governments reduces the business profits and affects the business viability
    for the entrepreneurs. Likewise, depending upon the nature of entrepreneurships,
    a minimum quantum of capital becomes mandatory to support the business operations.
    In its absence, no entrepreneurship can thrive to its potential. Entrepreneurial
    Businesses generate employments and contribute in reduction of the nation’s unemployment
    rate supporting indirectly the nation’s economy. Besides, as their entrepreneurship
    business grow, additional positions build up and in a way that contribute significantly
    in poverty reduction as well. Entrepreneurial Businesses craft changes as they
    offer products which facilitate a solution to the people’s routine lives. Entrepreneur’s
    ideas and ambitions often become game-changer while carrying out business operations
    and impact these businesses all across the world. Entrepreneurial Businesses also
    assist in extending help to the societies. 3 The Internet of Things (IoT) and
    Its Platforms The IoT facilitates real time information to the business entrepreneurs.
    It offers an insight about operations that when effectively responded can enable
    their business organizations more efficient. IT administrators, developers, investors,
    shareholders and the other associated stakeholders in the entrepreneurships must
    have an adequate understanding of IoT, how it operates, requirements, its usage,
    tradeoffs and also on how to implement its devices, data networks and infrastructures.
    Significance of IoT can be measured in different forms. It often involves data
    collection on processes, behavior and other related business environments. Many
    IoT devices undertake required actions to improve, correct or else to employ this
    data to endorse certain changes as required in business operations. 3.1 The Internet
    of Things (IoT) Dedicated devices also referred as things and deployed to share
    the real time varying applications data in a network on Internet are known as
    Internet of Things (IoT). These devices conceptually can include everything right
    from speakers to office premise networks, cars, plethora of appliances in shopping
    malls, shipping labels, academic institutes, airports, etc. They may include smart
    sensors, security systems, electric bulbs, industrial machineries and all such
    items which can communicate through the Internet and can work along with it. IoT
    isn’t a sole device, technology or software. It is a mix of networks, devices,
    computing resources, stacks and software tools. IoT terminology understanding
    generally begins with the IoT appliances themselves. Certain key IoT concepts
    which are applicable to business entrepreneurships are enumerated in succeeding
    paragraphs. 3.1.1 The Real Time Data Business enterprises regularly deal with
    images, documents, spreadsheets, videos, Power Points and a lot of other types
    of digital information. IoT devices generate enormous data that usually reflects
    one or even more physical stipulations in the realistic scenario. A network connected
    with IoT devices enables an entrepreneur to acquaint with real time business operations.
    It can also facilitate to the business entrepreneurs to exercise their control
    on the business activities. 3.1.2 The Essential Need of Instant Business Operations
    Where usual data transactions in business operations may subsist for even days
    or weeks with sometimes no utilization, IoT devices ought to deliver data instantly
    in most of the data processing cases without making any delay. It highlights the
    significance of the mandatory need of adequate availability of bandwidth in the
    associated data network. The connectivity assumes importance especially in IoT
    supported business environments where most of the data processing demands real
    time data transmission to prevent any substantial economic losses. 3.1.3 The Resultant
    Data IoT supported business projects are mostly defined by data operational requirements
    for business purposes to necessitate the IoT network deployment at different scales.
    In several cases, data of an IoT network becomes an element of the associated
    control loop to contribute in the source and outcome goal. For instance, a sensor
    conveys a homeowner about their front door gets unlocked, and thereby the homeowner
    could employ an actuator which is essentially an IoT device. Such IoT devices
    are meant to convert control signals in the data network into real time actions
    as a resultant to enable the homeowner to lock the door remotely. Infrastructure
    demands in an IoT data networks are extensive. Processing and security add new
    complexities in the entrepreneurship businesses. IoT platforms address these issues
    with Software as Service (SaaS) data network architectures. Its adoption eradicates
    number of associated network issue which are usually required for edge computing
    gateways and some other IoT applications. A basic IoT Software as a Service (SaaS)
    data network has been illustrated in Fig. 1. IoT can support greatly and to the
    far reaching entrepreneur’s business objectives. Millions of sensors in an IoT
    network can produce incredibly vast quantum of unprocessed data that may become
    far too much to the humans to evaluate and to act upon. Progressively, large IoT
    projects become the nucleus of big data operational initiatives, for example artificial
    intelligence (AI) and machine learning (ML) projects. The data accumulated from
    huge IoT device operations can be analyzed to process and initiate crucial business
    projections. It can also be employed to train AI-based systems for the real time
    business data transactions through the vast array of sensors. Simultaneously,
    back-end data operations analysis warrant considerable computing power and storage
    space. Such massive business data computation can be processed in centralized
    databases, public clouds or these may be distributed over numerous edge computing
    localities which are close to the places where data collection is done. Fig. 1
    A basic IoT SaaS data network architecture Full size image 3.2 The Internet of
    Things (IoT) Platforms The proliferation of colossal amount of IT devices in business
    over the Internet of Things (IoT) platforms is likely to turn out a boon in entrepreneurships.
    It’s not that just two devices are connected in the industrial ecosystem in it,
    rather a plethora of IT peripherals lead to a complexity which needs dedicated
    efforts to manage it out. These numerous IoT devices can be in all shapes, configurations,
    sizes, network protocols, standards, etc. It necessitates a viable platform that
    can facilitate its connectivity to the industrial ecosystem as well as within
    the ecosystem themselves. Though, there are lots of open source and free IoT platforms
    are available to the business startups, however there is a need to do a thorough
    examination by the entrepreneurs before the pick the most suitable one for their
    entrepreneurship venture. Some of the key industrial IoT platforms are being discussed
    in the succeeding paragraphs. 3.2.1 Link Management Platforms This platform deals
    with the IoT system networking components and to facilitate its users the most
    suitable software and hardware for its effective functioning of the entire network
    linked devices in the online mode of Internet connectivity. All such data networks
    are established in the backdrop of already available infrastructure and it can
    have other wireless communication modes of Internet connectivity such as Wi-Fi
    to support the impending IoT infrastructure. 3.2.2 Apparatus Management Platforms
    This IoT platform is about the physical connectivity of the associated hardware
    while ensuring that they remain connected in the data network and the security
    of the IoT network too is intact. In this IoT platform, users are constantly updated
    about the IoT apparatus, any changes in the network hardware and it also facilitates
    the equipment metrics with its continuous updating. In case of any network equipment
    failure, it provisions an alert to replace the affected hardware. This provision
    also assists users in routine maintenance of the IoT networks irrespective of
    the amount of devices connected in the network. This platform is therefore meant
    to upkeep and for appropriate maintenance of the network devices. 3.2.3 Cloud
    Platforms Weather it is a data crunching or data storage, a data cloud is meant
    to be a data sharing facility to the users connected with that data cloud storage
    system. It signifies about the fact that the cloud holds all the benefits of a
    shared data facility. It does not require a physical connectivity and it facilitates
    the security of the data transmission and its further scaling if required, in
    the data network. Business entrepreneurs can establish the similar cloud system
    to generate the entire back-end connectivity of the IoT system which can take
    care of data processing and the required storage in the network. 3.2.4 Application
    Support Platforms This platform enables users to acquire an IoT system in shortest
    feasible timeframe which is an integrated IoT ecosystem. It facilitates users
    inclusive data network access support system weather its software, an apparatus,
    network support system for the ease of network deployment against a quick turnaround.
    This platform id widely used by the new business entrepreneurs to support their
    digital ventures with a single window operation management. It offers a turnkey
    solution along with the requirement of manpower, network configuration hardware
    and maintenance. One important thing needs to be understood here that all the
    above IoT platforms should not be seen in isolation. It’s not only just the collection
    of data by employing these platforms; data management and its integration emanated
    from the different IoT platforms assume significance. In entrepreneurship, there
    may be a requirement of adding the business data from varying sources like websites,
    social media, mails, voice enabled devices, etc. It may increase the complexity
    of the IoT platforms to manage such volatile business data. Diverse business entrepreneurs
    collect and archive a huge quantum of business data. Figure 2 illustrates its
    utility in diverse business enterprises duly supported by IoT platforms. Latest
    technologies of data science and predictive analysis enhance the productive utility
    of such data on IoT platforms and bring efficiency, transparency, better system
    throughput and enrich the customer experiences. An IoT platform facilitates businesses
    with required infrastructure to link their assets, analyze and collect data in
    details with industry rating security protocols. The strength of an IoT platform
    is its ability to integrate data from innumerable sources to convert them in a
    coherent valuable business data. Fig. 2 Business enterprises supported by IoT
    platforms Full size image 4 The Key Benefits of IoT in Entrepreneurships IoT has
    considerably impacted the business entrepreneurships. With an extensive increase
    in IoT devices, big data bases accessibility, sharing of a colossal amount of
    data enables business entrepreneurs to gain insight on their customer responses
    as well as on product performances. IoT facilitates the constant optimization
    in business practices and even influences employees’ engagements. In certain entrepreneurships,
    IoT can facilitate to direct the systems in supply chains to independently execute
    transactions with certain pre-defined conditions. There are so many new exciting
    technologies which exhibit the IoT future as an incredibly versatile to meet the
    aspirations of both the business entrepreneurs as well as the consumers. Though,
    there are innumerable business advantages and opportunities in entrepreneurship
    businesses, some of the key benefits are being enumerated in succeeding paragraphs.
    4.1 Reduced Operative Cost Establishing an IoT supported business model is a quite
    deliberate affair. If one intends to put entire required IoT infrastructure in
    an entrepreneurship, then the operative cost may go out of proportion to make
    it a viable business model. The best option in such case is to employ Software
    as a Service (SaaS) model which takes care of the upkeep and the maintenance issues
    inclusively. 4.2 Enhanced System Performance In order to work effectively, a real
    time data sharing is the basic prerequisite for any organization. Based on the
    information received, an appropriate response is provided to the stakeholders.
    Availability of an IoT platform ensures the requisite predictive analysis can
    be performed by collecting the required data from the varying sources. It facilitates
    in optimization of the resources to accomplish relatively better maintenance to
    economize the project costs of the business entrepreneurships. 4.3 Augmented Security
    In an IoT data network, data sharing devices hold only a limited security capability.
    However, once supported by the IoT ecosystem due to its peculiar network architecture
    and security provisions put in place, a required wherewithal is provided to these
    equipment. There is a procedure in place for identity management and a secure
    authentication mechanism to thwart any probable cyber security attacks and address
    the system security vulnerabilities. 4.4 Supports to New Business Models Combination
    of a business and the IoT ecosystem leads to re-engineering the entire commerce
    activities. It develops and discovers many new revenue schemes and business models
    to support the new business ventures of the entrepreneurs. Partnering with different
    business ecosystems through the IoT platforms can open new avenues to business
    organizations. For instance, IBM partnering with General Motors offers a new transaction
    and marketing experience to automakers through the IoT supported mechanism in
    place. Analysis of the huge data from a vast sensor provides required insight
    to facilitate better optimization of resources and system performance. 4.5 Better
    Customer Experience Uses of IoT transform the people experiences of the different
    services manifold offered through the business operations. For example employing
    IoT cloud through IBM platform by a global business leader in escalator and the
    elevator industry, KONE could optimize and monitor its management for millions
    of escalators, elevators, turnstiles and doors in cities worldwide. By connecting
    all their elevators with the cloud and by attending them carefully, by scrutinizing,
    KONE could do the due maintenance of all the required elevators. Likewise, there
    are numerous other sectors and business entrepreneurships in which IoT supported
    ecosystems offer much better experiences to customers to best of their satisfaction.
    Combining IoT with some other emerging technologies such as 5G, AI, Robotics,
    ML and so on offer endless possibilities for entrepreneurship businesses. Entire
    commercial activities are gradually powered by IoT wherein security of the business
    ecosystem is being strengthened every day. Huge manufacturing productions are
    linked to a remote monitoring operational system through IoT. Utility enterprises
    can remotely accumulate data from the smart meters with associated infrastructure.
    Health care maneuvers can employ IoT to converse a patient’s live status to the
    physicians remotely. Farmers can manage their harvest through analysis enabled
    through IoT. It has become an amazing asset to the widespread entrepreneurship
    businesses. IoT allows entrepreneurs to assist better their customers as well
    as in managing their workforces to improve their services, products and business
    processes. 5 Proposed Security Architecture IoT devices are prone to a multiple
    potentially harmful cyber-attacks which may include weak DNS systems, botnet attacks
    and many other such attacks. It can make way to ingress ransomware, malware, probable
    attack vectors, etc. due to unsecured and unauthorized devices over the data network
    and it can be the hazard for physical security. Security risks also carry analogous
    threats to an establishment’s compliance posture. IoT is still under evolution.
    There are different design standards, configurations, operating as well as securing
    an IoT data infrastructure. Today, many business entrepreneurs pick IoT devices
    for their applications which follow existing technological standards like IPv6,
    Bluetooth Wi-Fi, Z-Wave, ZigBee and other data connectivity standards. In fact,
    further compliance standards emerge from industry like the IEEE 2413-2019 standards
    employed for an IoT data architectural framework. This standard is presently used
    for a widespread IoT architectural framework in diverse applications like healthcare,
    transportation, utility and other domains. It also conforms to the prevalent international
    data standard like ISO/IEC 42010:2011. An example of the proposed IoT system is
    illustrated in Fig. 3. Initially, data is converged to an IoT gateway emanated
    from number of sources through antennas, sensors microcontrollers, etc. Collected
    data is processed through the IoT hub for further data analysis. The desired data
    analytics is done through varying user interfaces like human, machine or even
    against diverse business application analytics to aggregate it with a viable business
    output data which can be commercially utilized in business applications. Fig.
    3 An example of an IoT system Full size image However, there are some distinct
    IoT data network architectural issues which concerns primarily to the network
    security. In an IoT network, there are varying infrastructural requirements which
    may include diverse sensors, its locations and quantities, power connectivity,
    management tools, network configuration and interfaces. It demands adequate latency
    and bandwidth considerations. There may be a need to extensively deploy extra
    computing resources to handle additional processing or to employ add on resources
    like the cloud. Since, the data handled by the IoT network may be confidential
    and sensitive, there is a need to ensure adequate safeguards against data theft,
    snooping and hacking. Encryption may be a viable option for IoT data protection.
    A provision is also needed to prevent malicious alterations to machine configurations
    and hacking. Security entails diverse software tools and conventional security
    mechanisms like intrusion detection as well as prevention systems and firewalls.
    Figure 4 illustrates the proposed IoT architecture module which includes communication
    bus, data network, an analytics and the aggregation platform. In this proposal,
    management of different IoT agents, network managers and application requests
    are processed. There is a sensor which detects the transmitted data and communicates
    it through the data bus. A due data analysis is performed by the network and the
    aggregated data ensures enhanced data security with seamless data integration
    in the IoT network. Fig. 4 Proposed IoT architecture modules Full size image The
    above mentioned data aggregation and the network integration ensures that network
    infrastructure, devices and tools are added to support interoperability with prevalent
    applications and systems like ERP and systems management. It will need a careful
    forecast and testing of proof of principle with appropriate IoT platforms and
    tools. The suggested IoT architecture will also entail a comprehensive understanding
    on how IoT data should be employed and analyzed. It will be done in an application
    layer with associated analytical tools. It may consist of training engines, AI,
    Robotics and ML modeling and rendering tools or visualization. There is a need
    to examine the various security threats, their mitigation and implementation.
    Table 1 illustrates the different security threats at device (Physical) level,
    varying risks, alleviation and their possible implementations. Proposed IoT architecture
    exhibits how to deal with the security threats identified in the entrepreneurship
    businesses. There are primarily four focal areas wherein such security threats
    exist like data sources, data transmission, event processing and presentation.
    It is significant that the proposed IoT architecture segregates the gateway and
    device capabilities. These way users will have leverage with more secure gateway
    mechanisms by using secure protocols which demands greater dispensation overheads.
    Table 1 Examination of proposed architecture Full size table 6 Challenges and
    Future Scope Significance of an IoT platform is beyond any qualm in the entrepreneurships.
    There are numerous factors which prove the worth of IoT in business enterprises.
    However, its implementation is as challenging as any other cloud-based technical
    platform to facilitate its network solutions. A business entrepreneurship has
    to go through the series of processes which may turn out quite cumbersome to them.
    Scale of deployment, degree of security required at different terminals, numbers
    of user nodes, data network architectures and so on are some of the indicative
    parameters which will dictate the degree of challenges confronted in its implementation.
    Some of the key challenges faced in IoT implementation are enumerated in succeeding
    paragraphs. 6.1 Project Designing Even though IoT appliances readily apply an
    array of standards, like 5G or Wi-Fi, currently there are no noteworthy international
    standards which can steer the implementation and design a foolproof IoT network
    architectures. There are no rulebooks to elucidate how to move toward in an IoT
    project. It permits a tremendous flexibility in project design; however it also
    permits for major design oversights and flaws. IoT projects should ideally be
    led through IT staff who are well conversed with IoT, although such expertise
    too is a self-evolving process. Eventually, there is no alternate for well measured
    design, careful and demonstrated presentation based on proof of projects and a
    committed testing. 6.2 Data Network Support IoT data flows through an IP enabled
    network. While considering the IoT apparatus effect on data network bandwidth
    to ensure that sufficient, steadfast bandwidth becomes accessible, congested data
    networks with high latency and dropped data packets may result in delayed IoT
    data transmission. It may entail certain architectural alterations in the data.
    For instance, instead passing complete IoT data over the Internet, an entrepreneur
    may choose to deploy an edge data computing architecture which preprocesses and
    stores locally the raw data prior to passing only processed data over a centralized
    location for further analysis. 6.3 Retaining and Storage of Data IoT devices generate
    colossal amounts of data that is simply multiplied based on number of network
    associated devices. This data becomes valuable asset for entrepreneurs to be stored
    and duly secured. Unlike conventional business data like contracts and emails,
    IoT data becomes extremely time sensitive. For instance, an automobile’s road
    data state or speed reported on preceding day or earlier may not have any significance
    for today or next month. It means IoT data may possess a fundamentally diverse
    lifecycle than conventional business data. This needs considerable efforts in
    data security and storage capacity. 6.4 Data Security and Privacy IoT projects
    warrant implementation of a secure network configuration. A suitable well planned
    IoT network security has also direct connotations for data regulatory compliances.
    While proliferation of IoT devices increase, the threat of IoT data network being
    compromised may also get proportionately enlarged. A lesser secure apparatus can
    endanger the entire IoT data network’s ecosystem. With remote monitoring and sensors
    in a core IoT data network, there may always be an issue of privacy to ownership
    and access of data. Compliance becomes a complex issue especially in live applications.
    IoT devices are likely to continue to grow. The future years will witness billions
    of added IoT devices over the Internet. It will be augmented by a blend of technologies
    supported by 5G connectivity. A countless new startups are emerging all across
    key industries. There is a tremendous future scope of IoT platforms as various
    technologies in IT domain and their associated applications are comparatively
    new and hold enormous growth prospects. In future, there is a likelihood of an
    enhanced and reevaluated IoT security commencing with primary device design by
    business implementation and selection. All such devices will include better security
    features which will be default enabled. Prevalent security tools like intrusion
    prevention and detection will incorporate strong support for IoT data architectures
    with ample active remediation and logging credentials. Concurrently, IoT device
    administrative tools are likely to progressively address IoT device security weaknesses
    and emphasize more on security auditing. In addition, certain aspects of IoT and
    AI are converging for a hybrid artificial intelligence of things (AIoT). It may
    create a platform which will be much more capable with human–machine interface
    and having an advanced learning capability. IoT data volumes are likely to continue
    to rise which translates into better revenue opportunities for entrepreneurship
    businesses. 7 Conclusion Implementation of IoT is considered a way forward to
    the entrepreneur businesses. However, at the same time it also holds enormous
    challenges to deal with. An IoT enabled business facilitates any entrepreneur
    to connect with embedded tags and sensors, share their data, to control and monitor
    their business ecosystem remotely and to carry out many associated predictive
    analysis. The most heartening part of these IoT platforms enabled entrepreneurship
    businesses is about its accuracy and the processing speed at which the business
    data will be shared. IoT enabled solutions aim to assist in synergizing the use
    cases to proliferate economies of entrepreneurs to scale up and to provide security
    to the businesses. It can also identify the most appropriate technical solution
    in the core network to meet the constant growing business demands. In immediate
    future, there is a likelihood of a re-evaluation and enhancement of IoT security
    at varying segments to include the device designs of business entrepreneurs and
    their business implementations. These devices are likely to incorporate more resilient
    security features to augment their customer’s trust. Existing security tools on
    IoT platforms like an intrusion detection system includes support for prevalent
    IoT architectures which incorporate a comprehensive logging as well as an active
    remediation mechanism. Also, IoT platform management tools increasingly emphasize
    on periodic security audits to automatically address some inherent security vulnerabilities.
    In addition, certain aspects of IoT and AI are converge to demonstrate an artificial
    intelligence of things (AIoT) technique. This technology intends to combine the
    data-gathering abilities of IoT with other decision-making and computing capabilities
    of IoT platforms and AI in entrepreneurship businesses. AIoT has potential to
    create a platform which will be capable of machine-human interactions besides
    certain advanced learning capabilities. IoT data volumes are likely to continue
    to grow which translates into fresh businesses revenue opportunities for entrepreneurs.
    These business data will increasingly drive AI and ML initiatives for multiple
    entrepreneurships. It is also considered a promising transformation strategy in
    long-term for entrepreneurship businesses across many sectors. While implementation
    of IoT platforms in entrepreneurships may have challenging prospects, however
    with appropriate integration with suitable solution businesses partners, entrepreneurs
    can be benefited from the immense business potential through IoT platforms. References
    Metallo C, Agrifoglio R, Schiavone F, Mueller J (2018) Understanding business
    model in the Internet of Things industry. Technol Forecast Soc Chang 136(23):298–306
    Article   Google Scholar   Ben-Hafaïedh C, Micozzi A, Pattitoni P (2022) Incorporating
    non-academics in academic spin-off entrepreneurial teams: the vertical diversity
    that can make the difference. R&D Manage 52(1):67–78 Article   Google Scholar   Ande
    R, Adebisi B, Hammoudeh M, Saleem J (2020) Internet of Things: evolution and technologies
    from a security perspective. Sustain Cities Soc 54:101728 Article   Google Scholar   Chalmers
    D, MacKenzie N, Carter S (2021) Artificial intelligence and entrepreneurship:
    implications for venture creation in the fourth industrial revolution. Entrep
    Theor Pract 45(5):1028–1053 Article   Google Scholar   Chen H, Tian Z (2022) Environmental
    uncertainty, resource orchestration and digital transformation: a fuzzy-set QCA
    approach. J Bus Res 139(24):184–193 Article   Google Scholar   Senyo PK, Liu K,
    Effah J (2019) Digital business ecosystem: literature review and a framework for
    future research. Int J Inf Manage 47(5):52–64 Article   Google Scholar   Corvello
    V, De Carolis M, Verteramo S, Steiber A (2021) The digital transformation of entrepreneurial
    work. Int J Entrep Behav Res 28(5):183–195. https://doi.org/10.1108/IJEBR-01-2021-0067
    Article   Google Scholar   Del Giudice M (2016) Discovering the Internet of Things
    (IoT) within the business process management: a literature review on technological
    revitalization. Bus Process Manag J 22(2):263–270 Article   Google Scholar   Fossen
    F, Sorgner A (2021) Digitalization of work and entry into entrepreneurship. J
    Bus Res 125(4):548–563 Article   Google Scholar   Jabbari J, Roll S, Bufe S, Chun
    Y (2022) Cut me some slack! An exploration of slack resources and technology mediated
    human capital investments in entrepreneurship. Int J Entrep Behav Res 28(5):1310–1346.
    https://doi.org/10.1108/IJEBR-10-2020-0731 Article   Google Scholar   Kraus S,
    Palmer C, Kailer N, Kallinger F, Spitzer J (2019) Digital entrepreneurship: a
    research agenda on new business models for the twenty-first century. Int J Entrep
    Behav Res 25(2):353–375 Google Scholar   Matricano D, Castaldi L, Sorrentino M,
    Candelo E (2021) The behavior of managers handling digital business transformations:
    theoretical issues and preliminary evidence from firms in the manufacturing industry.
    Int J Entrep Behav Res 28(5):1292–1309. https://doi.org/10.1108/IJEBR-01-2021-0077
    Article   Google Scholar   Effiom L, Edet SE (2020) Financial innovation and the
    performance of small and medium scale enterprises in Nigeria. J Small Bus Entrep
    34(7):1–34. https://doi.org/10.1080/08276331.2020.1779559 Article   Google Scholar   Laughlin
    C, Bradley L, Stephens S (2022) Exploring entrepreneurs business related social
    media typologies: a latent class analysis approach. Int J Entrep Behav Res 28(5):1245–1272
    Article   Google Scholar   Trabucchi D, Buganza T (2021) Entrepreneurial dynamics
    in two-sided platforms: the influence of sides in the case of Friendz. Int J Entrep
    Behav Res 28(5):1184–1205. https://doi.org/10.1108/IJEBR-01-2021-0076 Article   Google
    Scholar   Masood T, Sonntag P (2020) Industry 4.0: adoption challenges and benefits
    for SMEs. Comput Ind 121(10):32–61 Google Scholar   Troise C, Corvello V, Ghobadian
    A, O’Regan N (2022) SME’s agility in the digital transformation era: antecedents
    and impact in VUCA environments. Technol Forecast Soc Chang 174(19):121–227. https://doi.org/10.1016/j.techfore.2021.121227
    Article   Google Scholar   Upadhyay N, Upadhyay S, Dwivedi YK (2021) Theorizing
    artificial intelligence acceptance and digital entrepreneurship model. Int J Entrep
    Behav Res 28(5):1138–1166. https://doi.org/10.1108/IJEBR-01-2021-0052 Article   Google
    Scholar   Download references Author information Authors and Affiliations IIIT,
    Lucknow, India Praveen Kumar Singh, Bindu Singh, Pulkit Parikh & Mohil Joshi Corresponding
    author Correspondence to Praveen Kumar Singh . Editor information Editors and
    Affiliations Computer Science and IT Department, Central University of Jammu,
    Jammu, Jammu and Kashmir, India Yashwant Singh Department of Computer Science,
    KIET Group of Institutions, Ghaziabad, Uttar Pradesh, India Pradeep Kumar Singh
    Department of Electrical Engineering, Indian Institute of Technology Patna, Patna,
    Bihar, India Maheshkumar H. Kolekar School of Artificial Intelligence, Indian
    Institute of Technology Delhi, New Delhi, Delhi, India Arpan Kumar Kar IDMEC,
    Polytechnic Institute of Castelo Branco, Castelo Branco, Portugal Paulo J. Sequeira
    Gonçalves Rights and permissions Reprints and permissions Copyright information
    © 2023 The Author(s), under exclusive license to Springer Nature Singapore Pte
    Ltd. About this paper Cite this paper Singh, P.K., Singh, B., Parikh, P., Joshi,
    M. (2023). Emerging IoT Platforms Facilitate Entrepreneurship Businesses. In:
    Singh, Y., Singh, P.K., Kolekar, M.H., Kar, A.K., Gonçalves, P.J.S. (eds) Proceedings
    of International Conference on Recent Innovations in Computing. Lecture Notes
    in Electrical Engineering, vol 1001. Springer, Singapore. https://doi.org/10.1007/978-981-19-9876-8_18
    Download citation .RIS.ENW.BIB DOI https://doi.org/10.1007/978-981-19-9876-8_18
    Published 03 May 2023 Publisher Name Springer, Singapore Print ISBN 978-981-19-9875-1
    Online ISBN 978-981-19-9876-8 eBook Packages Intelligent Technologies and Robotics
    Intelligent Technologies and Robotics (R0) Share this paper Anyone you share the
    following link with will be able to read this content: Get shareable link Provided
    by the Springer Nature SharedIt content-sharing initiative Publish with us Policies
    and ethics Download book PDF Download book EPUB Sections Figures References Abstract
    Introduction Entrepreneurship Businesses The Internet of Things (IoT) and Its
    Platforms The Key Benefits of IoT in Entrepreneurships Proposed Security Architecture
    Challenges and Future Scope Conclusion References Author information Editor information
    Rights and permissions Copyright information About this paper Publish with us
    Discover content Journals A-Z Books A-Z Publish with us Publish your research
    Open access publishing Products and services Our products Librarians Societies
    Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan
    Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility
    statement Terms and conditions Privacy policy Help and support 129.93.161.219
    Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Lecture Notes in Electrical Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Emerging IoT Platforms Facilitate Entrepreneurship Businesses
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Jha S.
  - Tripathy D.
  citation_count: '1'
  description: In a distributed system, fog computing (FC) is an emerging computer
    technique. The goal of FC is to position cloud-based services in close proximity
    to endpoints. The method is meant to meet the minimal latency requirement for
    Iot - based healthcare equipment. There is a wide range of healthcare data volumes
    produced by Iot - based healthcare equipment. Network congestion and increased
    delay are the direct effects of this massive influx of data. Patient information
    is rendered useless and insufficient for end-users when round-trip time delays
    rise due to huge data transfer and increasing hop counts between IoTs and cloud
    servers. In the healthcare industry, real-time data is essential for time-sensitive
    applications. The medical IoT devices and their users have stringent requirements
    for latency, and traditional cloud servers just can't provide them. Therefore,
    it is important to decrease network delay, compute latency, and communications
    latency while transmitting data through the Internet of Things. FC allows data
    to be stored, processed, and analyzed in the cloud and at the network's edge,
    where the latency is lower. This article proposes an innovative approach to solving
    the aforementioned issue. It combines an FC-based analytical model with a hybrid
    fuzzy-based RL algorithm. High latency in healthcare IoTs, between users and cloud
    servers, is something that has to be mitigated. Allocation and selection of data
    packets in an IoT-FC setting are handled with the help of a fuzzy inference system,
    reinforcement learning, and neural network evolution techniques provided by the
    suggested smart FC model parameters and algorithms. The method is put through
    its paces on the iFogSim (Net-Beans) as well as Spyder simulations (Python). The
    acquired findings demonstrated that the suggested strategy outperformed the state-of-the-art
    techniques.
  doi: 10.1109/INOCON57975.2023.10101176
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2023 2nd International Confer... Low Latency
    Consistency based Protocol for Fog Computing Systems using CoAP with Machine Learning
    Publisher: IEEE Cite This PDF Surbhi Jha; Divya Tripathy All Authors 1 Cites in
    Paper 55 Full Text Views Abstract Document Sections I. Introduction II. Literature
    Review III. Proposed Model IV. Experimental Results V. Conclusion Authors Figures
    References Citations Keywords Metrics Abstract: In a distributed system, fog computing
    (FC) is an emerging computer technique. The goal of FC is to position cloud-based
    services in close proximity to endpoints. The method is meant to meet the minimal
    latency requirement for Iot - based healthcare equipment. There is a wide range
    of healthcare data volumes produced by Iot - based healthcare equipment. Network
    congestion and increased delay are the direct effects of this massive influx of
    data. Patient information is rendered useless and insufficient for end-users when
    round-trip time delays rise due to huge data transfer and increasing hop counts
    between IoTs and cloud servers. In the healthcare industry, real-time data is
    essential for time-sensitive applications. The medical IoT devices and their users
    have stringent requirements for latency, and traditional cloud servers just can’t
    provide them. Therefore, it is important to decrease network delay, compute latency,
    and communications latency while transmitting data through the Internet of Things.
    FC allows data to be stored, processed, and analyzed in the cloud and at the network’s
    edge, where the latency is lower. This article proposes an innovative approach
    to solving the aforementioned issue. It combines an FC-based analytical model
    with a hybrid fuzzy-based RL algorithm. High latency in healthcare IoTs, between
    users and cloud servers, is something that has to be mitigated. Allocation and
    selection of data packets in an IoT-FC setting are handled with the help of a
    fuzzy inference system, reinforcement learning, and neural network evolution techniques
    provided by the suggested smart FC model parameters and algorithms. The method
    is put through its paces on the iFogSim (Net-Beans) as well as Spyder simulations
    (Python). The acquired findings demonstrated that the suggested strategy outperformed
    the state-of-the-art techniques. Published in: 2023 2nd International Conference
    for Innovation in Technology (INOCON) Date of Conference: 03-05 March 2023 Date
    Added to IEEE Xplore: 19 April 2023 ISBN Information: DOI: 10.1109/INOCON57975.2023.10101176
    Publisher: IEEE Conference Location: Bangalore, India SECTION I. Introduction
    Making smarter choices about how much money the government should spend on transportation
    might benefit from analysing data on the state of downtown streets and avenues.
    In general, roadways and avenues are repaired as soon as a resident reports a
    problem or when a significant occurrence takes place. However, cities don’t often
    have true reactive systems that can identify the many issues with the pavement
    that need to be fixed [1]. An Internet of Things (IoT) generates vast amounts
    of on-site data that have enormous potential and may provide useful information,
    enabling a fresh wave of innovative applications. However, it has become very
    difficult to create a scalable desktop workstation and provide a thorough process
    for analyzing IoT streams of data with less latencies and more intelligence because
    to the exponential growth of site IoT data streams [2]. IoT and cloud computing
    are becoming more complex technology applications that are employed extensively
    in a variety of industries and areas, including healthcare, transportation, business,
    environmental monitoring, smart cities, gaming, home automation, and security.
    The term “Fog computing” refers to the expansion of the cloud computing and Internet
    of Things paradigms to the network edge. By lowering latency when carrying out
    any form of job, cloud technology plays a significant role in offering quicker
    reaction times and enhancing network traffic. Fog computing’s primary goal is
    to share the load of the cloud while reducing latency. Fog computing has sometimes,
    nonetheless, been unable to provide sufficient and precise findings, which has
    decreased the efficacy and quality of performance activities. Because of this,
    machine learning (ML) may be utilised to speed up the processes of data transmission
    across fog nodes. With true processing and communication procedures that may be
    established in accordance with user expectations, it aids in enhancing the architectural
    sequence of Fog nodes [3]. An connected network of computer nodes called an Internet
    of Things (IoT) allows data to be sent and received without the involvement of
    a person. IoT devices have significantly increased as a consequence of the great
    advancements in software and communication technologies over the last two decades.
    The Internet of Things (IoT) devices have essentially permeated each realm of
    human health, heralding a new age of intelligent technologies. But the quick growth
    has caused security issues. Scalability is a problem with the fundamental method
    of handling IoT data in the cloud. Congestion occurs, data bottlenecks, and extended
    reaction times to security risks lead to a cloud-centric approach. By moving processing
    to the network edge, fog computing solves these problems. The present study offers
    a thorough analysis of machine learning (ML) techniques inspired by artificial
    intelligence (AI), fog computing, and IoT development. It explores IoT data expansion
    solutions, investigates security issues with fog computing, and looks at ML strategies
    for detecting abnormalities and assaults. It also discusses long-term goals for
    research in the vital area for IoT security [4]. In order to speed up response
    times for latency-sensitive queries, fog computing has the potential to process
    user requests close to the users. Despite its benefits, the effectiveness of fog
    computing is significantly decreased by factors including resource heterogeneity
    and constraints, as well as its unpredictable and dynamic character. Predicting
    the fog’s dynamic behaviour and allocating resources properly is thus crucial
    [5]. The internet, big data, cloud computing, embedded systems, and wireless sensor
    networks are the primary technologies that make up the Internet of Things. A vast
    network of linked devices makes up this system. These gadgets collect and distribute
    data. However, many IoT devices lack adequate security, and fraudsters profit
    from this. As cloud computing allows data storage on cloud storage and fog computing
    provides us with a number of services to access data as well as support for cloud
    servers, the two approaches may be used together to transport safe data in IoT
    devices [6]. Internet of Things (IoT) technologies often generate enormous volumes
    of data, and there may already be billions of internet-connected gadgets. All
    of this data transmission will use up bandwidth and burden the cloud. The promising
    technology of fog computing (FC) may address the problem of compute and networking
    constraints in massive IoT applications. By supplying computing storage and power
    to the network’s edge, this technology enhances cloud computing. It still has
    performance and security problems, however. Machine learning (ML) draws attention
    as a result of helping FC resolve its problems. Utilizing ML to enhance FC applications-such
    as resource management, security, reduce latency, and reduce power consumption-has
    been more and more popular recently. The use of intelligent FC to problems in
    industrial 4.0, bioinformatics, blockchain, and vehicular communication systems
    was also examined. This study will throw light on current research that used ML
    in an FC setting due to its crucial function in the FC paradigm. Background information
    on ML and FC is also provided. In this study, the examined research were divided
    into three categories based on their intended use of machine learning. Sum-up
    tables were used to compare and evaluate these research in-depth [7]. A key enabling
    technology for networks in the future is fog computing. In order for fog computing
    to handle the burden of many developing applications such as IoT, blockchain,
    and big data while experiencing excessive latency or expensive bandwidth usage,
    it expands cloud services to its network edge. Designing an incentive system for
    the supplier of the fog computing service is crucial for achieving the technology’s
    maximum potential. We have seen a continuous increase in the use of machine learning
    over the last several years, not only for improving cloud computing application
    but also for delivering fog services like better resource management, increased
    security, decreased energy usage, latency, and traffic modelling. Our present
    research intends to fill this gap in the literature by investigating the function
    of deep learning in the fog computing paradigm. For its intended objectives, machine
    learning applications employed in fog computing need high tiers of services, comprehensive
    analytics, a strong end-user, and intelligent responses [8]. One important enabling
    technology for next networks is fog computing. Fog computing can enable different
    new applications like IoT, big data and blockchain with low delay and low bandwidth
    usage costs by extending cloud services to a network edge. Designing an incentive
    system for cloud computing service providers is crucial if fog computing is to
    realise its full potential. A possible design for an incentive system is the auction.
    Designing an ideal auction that optimises money for the provider while maintaining
    crucial IR and IC features, however, is difficult. In order to allocate resources
    in fog computing, this paper discusses the construction of an optimum auction
    using deep learning [9]. The time we now find ourselves in calls for the fusion
    of fog machine learning,computing, cloud computing and IoT to investigate new
    technical solutions. By bringing resource-intensive functions like compute, communications,
    storing, and analysis closer to the end users, fog computing is a new architecture
    designed to reduce network loads at the cloud and the main network. Computer scientists
    study machine learning, a branch in artificial intelligence (AI) which gives computers
    the capacity to learn without explicitly programmed. Depending on algorithm sensing
    to gather sensor data, IoT has the capacity to decide and act autonomously. The
    whole range of machine learning-related algorithmic techniques will be covered
    by these integrated capabilities. In this article, the authors examine how machine
    learning techniques have been used to object recognition, text detection in images,
    and enhanced requirement fulfilment in fog computing [10]. SECTION II. Literature
    Review It involves employing sensors in daily-driving automobiles and linking
    these to a fog-computing infrastructure over a V2I network. The system uses Machine
    Learning Algorithms (MLA) to compare the degree of roughness to a flat reference
    in order to identify and categorise the primary road issues or abnormal circumstances
    in streets and avenues. An instrumented car used accelerometry sensors to collect
    the reference, and a semi communication system to transmit the data. To choose
    the optimal method for managing the collected data, the system used these data
    to compare an Artificial Neural Network (supervised MLA) as well as a K-Nearest
    Neighbor (supervised MLA). This technique enables it to map the locations with
    the most severe abnormalities and show the condition of the streets [11]. We propose
    the Kubernetes-based scalable fog computing platform (KFIML), which combines machine
    learning (ML)-based applications with large data streaming processing. Additionally,
    we provide a complete workflow for IoT data processing, which includes data access
    and transmission, big data handling, online machine learning, long-term storage,
    and surveillance. A clustered testbed with a IoT, broker servers, worker nodes,
    master node and a local database server is used to practically verify the platform.
    On our testbed, we can handle larger and control containerized software frameworks
    by utilising the lightweight orchestration technology Kubernetes. The sophisticated
    data flow frameworks, such Apache Flink, used by the big data processing level
    to offer both stream processors and statistics with minimal latency. In order
    to provide real-time predictive analysis of IoT data streams, the stated long
    short-term memory (LSTM)-based ML processes are also used on the online ML layer.
    The trials on a practical smart grid use case show that the container-based KFIML
    platform scales well with Kubernetes to effectively handle larger on-site IoT
    data streams with reduced latency and run ML-based apps [12]. By examining the
    most recent ML approach adaptations in certain important Fog computing aspects
    (security, Resource management and computational improvement), this work attempted
    to offer a thorough evaluation of the function of machine learning [13]. In order
    to examine the quality of e-healthcare systems, we developed a framework that
    uses machine learning techniques for data categorization in fog computing. Additionally,
    a comparison study has been conducted to show how well the various methods for
    data categorization work. According to simulation findings, Support Vector Machine
    and K-Nearest Neighbor classifiers outperform all other classifiers examined,
    and fog performs much better than cloud [14]. We evaluate techniques to predictive
    resource management based on machine learning in a fog environment. resource allocation,
    scheduling, application placement, Resource provisioning,,load balancing and task
    offloading are the six sub-areas that make up resource management. Based on the
    objective criteria, tools, datasets, and used strategies, the evaluated resources
    management approaches are examined [15]. This research paper shows multiple methods
    for detecting an intrusion and anomalies in cloud systems powered by IoT. The
    effectiveness, precision, performance, efficiency,recall, and detection rate of
    each approach utilised to find intrusions and anomalies are also compared [16].
    An interfering pattern in the receiver antenna is described in this article in
    detail. For a professional in digital signal processing, the new possibilities
    of computer vision for the development of oscillograms are discussed. For the
    interplay of a digital signal processing expert and disturbance with pattern recognition
    utilising a smartphone, a novel strategy is suggested. At the design phase, the
    proposed system’s architecture is described in accordance with three standards.
    A smartphone method has been developed and is available for viewing. It has been
    shown that pattern recognition may be used effectively to identify different forms
    of interference utilising fog and cloud computing, and particular examples are
    given [17]. The findings revealed that, with the exception of those that focused
    on security problems, not all research employed the same performance indicator.
    Due to the diverse character of the FC paradigm, it can be concluded that the
    simulations of the suggested ML models are insufficient [18]. In this article,
    the uses of X-rays in dental care are briefly discussed. The new computer-based
    display options for panoramic photos for dentists are explained. With the help
    of the Internet of Things, a novel method of doctor-X-ray image interaction is
    offered. At the design stage, a definition of the structure is provided using
    three criteria. A smartphone app has been created. Deep learning has been shown
    to be successful in identifying tooth damage in fog data centers and cloud technologies
    [19]. The IoT-based business health information system, dubbed IoTPulse, is suggested
    in this study to forecast alcoholism by giving real-time data in a fog computing
    environment. To train machine learning models, we data collected from 300 alcohol
    abusers in Punjab, India. When IoTPulse’s performance is compared to prior work
    utilising a variety of measures, such as accuracy, sensitivity, specificity, and
    precision, an increase of 7%, 4%, 12%, and 12%, respectively, is shown. Finally,
    IoTPulse is tested using QoS parameters for latency, network bandwidth, energy,
    and reaction time in a real fog environment based on FogBus, which increases performance
    by 19.56%, 18.36%, 19.53%, and 21.56%, respectively [20]. SECTION III. Proposed
    Model By examining how the suggested IoT stacks up against existing multi fog
    implementations built with a deep-learning approach, we may draw some important
    conclusions. Another of the application layer protocols for limited devices is
    known as the Application Protocol (coap Protocol (CoAP). Protocols enable the
    constraining gadgets to talk to one another through the web. Designing inside
    the same restrict network makes advantage of this method. End-to-end identification,
    privacy, and other similar uses are also possible with this method. CoAP’s primary
    function is to facilitate communication between constrained devices through the
    interchange of small data packets. Fig. 1. System Architecture Show All Fig. 2.
    CoAP protocol Show All Fig. 3. Message header format of CoAP Show All CoAP is
    quite similar to the HTTP protocol and supports the same kinds of responses as
    HTTP (GET, POST, PUT, and DELETE). Fig. 2 depicts the CoAP protocol’s structure.
    For consistency, the options, token, and payload parameters of this protocol are
    all contained inside a standardized header length of 4 bytes. The CoAP client
    uses a response/request mechanism to communicate with the server [15], [16]. A
    sample CoAP message header is shown in Fig. 3. The letter T stands for the message
    type, and the value of TKL indicates the length of the token field that may vary.
    The CoAP protocol allows for both dependable and unreliable communication. CoAP
    supports four distinct message types: confirmable (CON), non-confirmable (NON),
    acknowledge (ACK), and reset (RST). In secure communication, the CON message is
    sent from one device to another, and the recipients respond with an ACK. When
    a message is marked as NON, the recipient will not respond with an ACK. Retransmission
    occurs when the sender resends a message to the recipient because they did not
    get an acknowledgment of receipt (ACK) within a certain amount of time. The CON
    message format is shown in Fig. 4a), and the NON message format is shown in Fig.
    4b). Receipt confirmation (CON) messages are sent by the receiver to the sender
    to indicate that they have received the communication. In the NON message format,
    the recipient doesn’t really reply with an acknowledgement to the sender. Fig.
    4. Confirmable message Show All Programs providing system integration, interoperable
    facilities, authentication and authorisation services, and so on all make use
    of this protocol. Using the CoAP protocols, we are able to ensure that data is
    sent quickly and safely between the gadgets. The CoAP’s uses are outlined in the
    following, Using HTTP for Interoperability: The RESTful compatibility of sensing
    devices with the world wide web and other nodes is made possible by the proxy-based
    CoAP protocol used by smartphones. If we look at the healthcare system, for instance,
    we see that physicians and patients exchange medical records openly. CoAP protocol
    is used in such programs to boost compatibility and reduce resource use (especially
    memory and electricity). At last, a convenient resource close to the desired IoT
    gadget is chosen. The optimal resources may be chosen quickly and readily thanks
    to the index as well as cluster structure. With the right number of clusters determined,
    the clustering process may be completed more quickly and with more precision.
    Computational cost is measured and characterized as following for the different
    quantities of levels and processes in this investigation: P v s (i) =(1−μ)×O(N)+μ×O(N)=O(N)
    (1) View Source Where O(N) represents the sum of iterations for resources shortlisting
    μ∈[0,1] and then S S upd with respect to the fx as follows, S S upd =arg( max
    i p εid x i ( f x ( P V S n )))=O(N) (2) View Source Where O(N) represents the
    sum of iterations for SSupd it serves as a repository of almost ideal matches
    for characteristics that are comparable. When resources are grouped together,
    it becomes difficult to do updates using the provided technique since it creates
    new, smaller groups. SECTION IV. Experimental Results We tested things out in
    the ContikiOS emulator, Cooja. With the help of the Contiki operating system,
    Cooja can mimic an Internet of Things network with few devices. Cooja’s ability
    to emulate devices outside of the self-imposed constraints is a major selling
    point. Hardware simulation of limited-capacity devices’ specifications and processing
    power is also available. Cooja allows users to submit the binary image file of
    a limited device (node) for simulation. The uploaded code is subsequently run
    by virtual nodes inside the simulation environment. For our tests, we use a wide
    range of client and server counts. Equal to the number of servers is the total
    number of clients. California’s CoAP implementation allows for both CoCoA and
    mlCoCoA to be selected as the client’s preferred CC method. Erbium is a version
    of CoAP used by the servers, which are all hosted by the same Device running ContikiOS
    and connected through the Cooja emulator. Each client is an own Ubuntu process
    that uses UDP, IP, and Ethernet to talk to remote servers through the CoAP protocol.
    Each machine is a hub for Moteiv10’s TMote Sky motes. Cooja is a server simulator
    that runs on the operating system Ubuntu. CoAP, UDP, uIPv6, RPL, SICSlowpan, and
    CSMA based on nullRDC and the IEEE 802.15.4 physical layer compose the server’s
    virtual network for communicating with clients, and they transfer data at 250
    kbps across the 2.4 GHz radio band using a maximum data rate of 2.4 GHz. The layers
    of the Contiki network implemented in this research are shown in Figure 1. Fig.
    5. Execution Time Show All Fig. 6. Dela Show All SECTION V. Conclusion The term
    “fog computing” refers to a developing kind of computer technology that functions
    in a decentralized setting. The goal of FC is to provide the benefits of cloud
    computing to devices that are on the edge of the network. It is anticipated that
    the technique would satisfy the minimal latency criterion for healthcare Internet
    of Things (IoT) devices. The Internet of Things (IoT) devices used in healthcare
    provide varying amounts of healthcare data. Because of the massive number of data,
    there is a high level of data traffic, which leads in congestion on the network
    and increased delay. The rise in round-trip time delay that occurs as a result
    of big data transmission and huge hop counts among IoTs and cloud servers renders
    healthcare data useless and unsuitable for end-users. Time-sensitive healthcare
    applications demand real-time data. The lowest latency requirements that healthcare
    IoT devices and end-users have are impossible for traditional cloud servers to
    meet. For this reason, there has to be a reduction in the latencies associated
    with communication, computing, and network for the transmission of IoT data. FC
    makes it possible for data to be stored, processed, and analyzed at the network
    edge, hence reducing the high latency that would otherwise be experienced. This
    article offers a fresh approach to solving the issue that was described before.
    An analytical model and a hybrid fuzzy-based reinforcement learning method are
    both included into this FC environment. The considerable latency that now exists
    between healthcare IoTs, end users, and cloud servers has to be reduced. For the
    purpose of data packet allocation and selection in an Internet of Things–based
    FC environment, the intelligent FC analytical model and algorithm that was suggested
    makes use of a fuzzy inference system in conjunction with reinforcement learning
    and neural network evolution methodologies. The strategy is validated by running
    simulations on the iFogSim (Net-Beans) and Spyder simulators (Python). The findings
    that were collected suggested that the proposed technique performed more effectively
    than the other approaches that are already in use. Authors Figures References
    Citations Keywords Metrics More Like This Reinforcement Learning for Optimizing
    Delay-Sensitive Task Offloading in Vehicular Edge–Cloud Computing IEEE Internet
    of Things Journal Published: 2024 Low-latency Patient Monitoring Service for Cloud
    Computing Based Healthcare System by Applying Reinforcement Learning 2022 IEEE
    8th International Conference on Computer and Communications (ICCC) Published:
    2022 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details
    PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2023 2nd International Conference for Innovation in Technology, INOCON
    2023
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Low Latency Consistency based Protocol for Fog Computing Systems using CoAP
    with Machine Learning
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sharma K.
  - Malik A.
  citation_count: '0'
  description: Recently, a number of smart devices are connected through the Internet
    to achieve data processing and generation. The data generated from the cloud server
    demand robust and reliable data storage and protection for unauthorized data access.
    Additionally, the processed data demands for avast range of processing power to
    tangible effective information for processing. The different business process
    comprises of technologies to increase efficiency and performance with the reduced
    cost of operation in the IoT devices. The data processing leads to the data handledwith
    the edge computing technology. The technological procession deal with the response
    time improved cost-saving bandwidth and battery life those significantly impacts
    on safety and privacy in the organization. This paper presented a Virtual Environment
    Based HTTP server model termed as (VEnvMQTT) for effective data processing in
    the edge computing architecture of the IoT environment. The proposed VEnvMQTT
    model comprises of the actuators and IoT server data. The proposed VEnvMQTT model
    evaluates the data collected from the sensor at an effective level of processing
    time with edge computing technology. The analysis of the simulation results expressed
    thatthe proposed VEnvMQTTmodel achieves a reduced latency of 24.566ms which is
    ~20% minimal to the existing MQTT model.
  doi: null
  full_citation: '>'
  full_text: '>'
  inline_citation: '>'
  journal: International Journal of Intelligent Systems and Applications in Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Virtual Edge Computing Architecture Model for the Real-Time Data Server in
    the IoT Environment
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Halim D.K.
  - Hutagalung S.
  citation_count: '8'
  description: Internet of Things (IoT) provides data processing and machine learning
    techniques with access to physical world data through sensors, namely telemetry
    data. Acquiring sensor data through IoT faces challenges such as connectivity
    and proper measurement requiring domain-specific knowledge, that results in data
    quality problems. Data sharing is one solution to this. In this work, we propose
    IoT Telemetry Data Hub (IoT TeleHub), a general framework and semantic for telemetry
    data collection and sharing. The framework is principled on abstraction, layering
    of elements, and extensibility and openness. We showed that while the framework
    is defined specifically for telemetry data, it is general enough to be mapped
    to existing IoT platforms with various use cases. Our framework also considers
    the machine-readable and machine-understandable notion in regard to resource-constrained
    IoT devices. We also present IoThingsHub, an IoT platform for real-time data sharing
    based on the proposed framework. The platform demonstrated that the framework
    could be implemented with existing technologies such as HTTP, MQTT, SQL, NoSQL.
  doi: 10.1186/s40537-021-00549-0
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Search Get published
    Explore Journals Books About Login Journal of Big Data About Articles Submission
    Guidelines Submit manuscript Research Open access Published: 04 January 2022 Towards
    data sharing economy on Internet of Things: a semantic for telemetry data Dareen
    K. Halim & Samuel Hutagalung  Journal of Big Data  9, Article number: 1 (2022)
    Cite this article 4210 Accesses 13 Citations Metrics Abstract Internet of Things
    (IoT) provides data processing and machine learning techniques with access to
    physical world data through sensors, namely telemetry data. Acquiring sensor data
    through IoT faces challenges such as connectivity and proper measurement requiring
    domain-specific knowledge, that results in data quality problems. Data sharing
    is one solution to this. In this work, we propose IoT Telemetry Data Hub (IoT
    TeleHub), a general framework and semantic for telemetry data collection and sharing.
    The framework is principled on abstraction, layering of elements, and extensibility
    and openness. We showed that while the framework is defined specifically for telemetry
    data, it is general enough to be mapped to existing IoT platforms with various
    use cases. Our framework also considers the machine-readable and machine-understandable
    notion in regard to resource-constrained IoT devices. We also present IoThingsHub,
    an IoT platform for real-time data sharing based on the proposed framework. The
    platform demonstrated that the framework could be implemented with existing technologies
    such as HTTP, MQTT, SQL, NoSQL. Introduction Data plays a significant role in
    allowing businesses to gain competitive advantages and enabling researchers to
    develop new and better insights, algorithms, and technologies [1,2,3]. With the
    advancement of Internet of Things (IoT) technologies and its growth in adoptions
    [4, 5], the number of physical world data measured and digitized is also increasing
    [6]. Telemetry data is one particular type of physical world data widely used
    and associated with sensor readings in IoT applications [7]. Numerous works are
    using telemetry data with machine learning or other analytic methods for various
    domain-specific applications, such as predictions of energy demand on smart grid
    systems [8,9,10,11], room ambient modeling for green buildings [12,13,14], and
    indoor positioning [15,16,17,18]. The process of logging (or collecting) physical
    world data with IoT faces many challenges, one of them being that proper physical
    measurements mostly require domain-specific knowledge. For example, measuring
    room temperature and humidity for efficient HVAC conditioning purposes requires
    proper sensors’ positioning and calibration [19, 20]. Similarly, in the agricultural
    field, the measurements of the condition of the crops must also be appropriately
    performed lest the collected data may not provide any helpful insight [21,22,23].
    Another example is energy consumption monitoring, where some methods require tapping
    into the power line, which may introduce hazards if done inappropriately [24,
    25]. Connectivity is also one of the main problems with IoT data logging, where
    we expect IoT devices to maintain periodic logging when facing disconnections
    [26,27,28]. ‘Store-then-send when the connection is available’ is a standard method
    but is not always applicable to IoT devices with limited resources. Failure to
    implement proper countermeasures against disconnection may result in missing sensor
    data points, resulting in difficulties during data processing and analysis [29,30,31].
    While methods like data imputation [32,33,34] can alleviate this problem, complete
    data points are always more beneficial. Paired with the lack of domain-specific
    knowledge during measurements, it may compromise the data quality even further.
    Data sharing is one possible solution to the data quality problem. However, extensive
    works on IoT systems and IoT architectures led to a vast range of devices, architectures,
    logical elements, and data formats. Data sharing itself hence boils down to a
    semantic interoperability problem [35]. W3C Semantic Sensor Network (SSN) [36]
    is one widely used ontologies conforming to W3C Semantic Web technologies for
    representing elements in sensor networks. FIESTA-IoT proposed an IoT ontology
    by combining various aspects from SSN, DUL, IoT-lite, WGS84, Time, and M3-lite
    taxonomy [37]. Gyrard et al. [38] devised a formal methodology namely SEG 3.0
    for unifying IoT data, enriching those data with semantics, and representing them
    as services. UbiRoad [39] worked on application-specific semantics for intelligent
    transportation systems by defining semantic interoperability between car-embedded
    devices and roadside devices. Semantics for time series data is proposed in [40].
    They developed DS-Ontology, a semantic model for IoT data streams, along with
    the required tools added to existing Time Series Databases (TSDBs). Matos et al.
    [41] views data sharing and interoperability as a subset of context sharing, in
    that context sharing emphasizes the understandability of data for human users.
    Their review of a large number of IoT context-sharing platforms shows that the
    widely varying platform architecture can be broken down into general building
    blocks. From a broader view, the works mentioned above on semantics also promote
    virtualizing devices and separating hardware from software. This idea, introduced
    as IoT virtualization, is a concept where different services and applications
    share the same underlying infrastructure, particularly IoT devices [42]. It allows
    faster development of applications, as well as reducing the cost associated with
    deploying hardware. Works such as [42,43,44] propose various architectures for
    virtualizing IoT devices as services. By sharing devices, IoT virtualization inherently
    also promotes data sharing. Scalability, efficient resource utilization [42, 43]
    and reliability [45] are other key factors promoted by IoT virtualization. We
    observe two things from the previous works on data semantics and IoT virtualization.
    First, works that propose general semantics and architectures tend to be very
    broad thus do not define particular data structures aside from the semantics.
    Meanwhile, application or data type-specific semantics tends to lose generality
    in their discussion. Second, while they propose general semantics and architectures,
    most define their generality in terms of application use case. In this work, we
    narrow our focus to data sharing framework and semantic specifically for telemetry
    data. We kept our framework and semantic, IoT Telemetry Data Hub (IoT TeleHub)
    as general as possible. Thus, the contributions of this paper are as follows:
    We proposed IoT Telemetry Data Hub (IoT TeleHub), a general framework and semantic
    for collecting and sharing telemetry data. This is discussed further in later
    sections in which we build our framework and semantic on three principles, (a)
    abstraction, (b) layering of elements, and (c) extensibility and openness. We
    demonstrate the universality of the proposed framework and semantic by mapping
    it to several IoT data sharing and virtualization platforms. We present a prototype
    that implements the proposed framework and semantics. The prototype serves as
    a proof-of-concept for the framework. The rest of this paper is structured as
    follows. Section \"Related works on IoT virtualization and sharing\" discusses
    previous works and their implications for this work. We present our proposed framework
    and semantic in \"Proposed framework and semantic—IoT TeleHub\" section and discuss
    the mapping into existing data sharing and virtualization frameworks in \"Mapping
    of existing virtualization and sharing platforms\" section. The prototype implementation
    is discussed in Prototype as an implementation of the framework\" section. We
    describe our works view on machine-readable and machine-understandable notion
    in \"Discussion\" section.  Lastly, \"Conclusion, limitation and opportunities
    for future research\" section concludes this paper. Related works on IoT virtualization
    and sharing This section reviews related works, where we first discuss about interoperability
    of IoT platforms, then followed by related works on IoT virtualization and data
    sharing. We discuss the implication of the earlier works for our work, i.e., how
    we incorporate the main ideas of those works into our proposed framework and semantic.
    Interoperability of IoT platforms There is a large and growing number of IoT platforms
    proposed by industries and academics. Alongside, there are also growing numbers
    of infrastructure, architecture, protocols, standards, semantics [35] that are
    local to each platform or some of the platforms. While this variability allows
    better innovations to flourish, it also introduces IoT interoperability problems.
    [35] classifies IoT interoperability into (1) device, (2) network, (3) syntactical,
    (4) semantic, and (5) (cross) platform interoperability problems. Among these
    problems, we see that solving semantic and cross-platform interoperability provides
    a faster approach to unifying the varying platforms. Both semantic and cross-platform
    interoperability can be defined at higher abstraction levels. Hence changes to
    existing platforms can be kept minimal. W3C defines Semantic Sensor Network (SSN)
    and is one widely adopted ontology, aiming at interoperability between IoT platforms
    that implement the standard [36]. FIESTA-IoT combines aspects from various ontologies
    from W3C’s SSN, IoT-lite, DUL, WGS84, Time, and M3-lite taxonomy [37]. It emphasizes
    on annotating the different ontologies used by the IoT platforms to reduce required
    changes and maximize interoperability. Gyrard et al. [38] proposed SEG 3.0, a
    complete and formal methodology for unifying IoT data with semantic web technologies,
    applying context information on the data, and finally representing them as services.
    This complete methodology ensures semantic interoperability but requires changes
    on multiple layers and elements for existing IoT platforms. De Matos et al. [41]
    highlights the importance of context information for data, and proposes a general
    architecture for context sharing platforms. The architecture’s complexity is due
    to its attempt to cover different data formats, context formats and applications.
    Zeng et al. [40] narrow their focus on semantic models for time series data, considering
    time series databases (TSDB) as the underlying storage solution. They developed
    SE-TSDB, a semantic-establishing tool suite that runs on top of TSDBs. While this
    solution works well on platforms with TSDBs as their storage solution, it may
    lose generality when we consider a more extensive range of platforms that use
    other storage technologies. Based on the previous works above, we infer these
    crucial points to incorporate into our framework and semantic: Semantic and cross-platform
    interoperability at higher levels of abstraction. Minimize changes to existing
    platforms and semantics. Trade-offs between case-specific semantics and generality.
    IoT virtualization and data sharing In this subsection we discuss various works
    on IoT architectures that promote data sharing and virtualization of IoT elements.
    Benazzouz et al. [44] introduces a general system architecture for sharing IoT
    devices. It consists of (1) a heterogeneous layer where IoT devices reside, (2)
    a middleware layer that covers an IoT gateway functionality for handling the heterogeneity
    of IoT devices, and (3) an application layer that provides uniform access for
    end-users. The architecture regards IoT devices as services from which end users
    can access the device resources. FogFlow [43] is a framework for scalable programming
    of IoT services that utilize both cloud and edge computing. It introduces the
    concept of a virtual device to integrate existing yet varying IoT devices into
    the framework. In short, the existing devices can be ported to the FogFlow framework
    by representing them as virtual devices according to FogFlow format. Gyrard et
    al. [38] through their SEG 3.0 methodology described a set of formal steps to
    build interoperable systems that work with heterogeneous data sources. The first
    two steps in that methodology are the composing step which transforms data with
    heterogeneous formats into a common format, and the modeling step that annotates
    the data with semantic web technologies. They treat IoT devices virtually as data
    producers that provide certain data formats that must be taken into consideration
    in the composing step. Samaniego et al. [46] represents various elements in an
    IoT system as virtual resources, which are abstractions of physical and virtual
    entities. Based on that concept of virtual resources, they propose an IoT architecture
    consisting of three layers, i.e., the physical layer, the hardware abstraction
    layer (HAL), and the view abstraction layer (VAL). The physical layer is the actual
    IoT devices, represented virtually in the system as HAL. By representing the actual
    IoT devices as HAL, the system gains a uniform access to all the devices, easing
    the management of those devices. The end users of the system see the accessible
    resources through the VAL that controls what users can see and with which access
    levels. The work highlights the concept of abstracting system elements to simplify
    the management of resources. Ogawa et al. [42] proposes a similar concept of IoT
    virtualization for efficient resource usage in the context of a smart city. They
    propose an architecture for applications to share IoT nodes by consolidating the
    nodes data and exposing them as functions. Specifically, these three layers comprise
    the architecture; (1) Gateway, on which the IoT nodes data are pooled and possibly
    pre-processed, (2) Function layer that provides access to the pooled data in certain
    formats, and (3) Application that utilizes the Function layer. The architecture
    also incorporates containerization to improve resource utilization and performance.
    We derive the following points from the above-mentioned works. Virtual device
    concept to address IoT devices heterogeneity, and due to the ease of management
    of virtual representation of resources. Clear layering of services and their responsibilities.
    Proposed framework and semantic—IoT TeleHub In this section, we start discussing
    our proposed framework, IoT TeleHub, by its general architecture. We then discuss
    how the framework promotes the key aspects, (a) abstraction, (b) layering of elements,
    and (c) extensibility and openness in the said architecture. Figure 1 depicts
    the IoT TeleHub proposed framework. Nodes are physical IoT devices connected to
    the core framework. To maintain generality, we do not specify the connection method
    between the nodes and the core framework or whether the core framework is implemented
    on-site or in the cloud. Intermediary elements such as gateways are grouped in
    the “edge and end devices region”. Fig. 1 IoT TeleHub general architecture Full
    size image The core framework consists of three main elements as follows. Device
    management layer: Deals with the virtualization of the nodes. This layer is responsible
    for the hardware-software abstraction of IoT devices by defining the node virtual
    representation. Data management layer: Responsible for the “data channel” to which
    the nodes send their telemetry data. This layer handles nodes initial connection,
    nodes authentication, and the telemetry data sent by the nodes. To perform these
    tasks, it relies on the node virtual representation defined in the device management
    layer. This layer defines the data storage format for the telemetry data. Service
    layer: Provides service to applications, which at its most basic form is access
    to the telemetry data in a usable and shareable format. This layer defines the
    data semantic, separated from the data management layer’s data storage format.
    IoT applications sit on top of the core framework, either separated from the framework
    or as a part of the framework, i.e., the extended framework. The extended framework
    part is optional. We include the applications as the extended framework to preserve
    the generality of the whole framework. That is, we intend to have this framework
    applicable to a wide range of IoT platforms. Some IoT sharing platforms may only
    provide elements up to the service layer, allowing users to build on top of the
    provided services. In that case, the extended framework element is unnecessary.
    Other platforms may include their applications on top of their services, regarded
    as the extended framework. Hence, by separating the application-specific aspect
    into the extended framework, we can define the layers in the core framework to
    cover only main functionalities shared by all IoT platforms. From here onward,
    we use the term framework to refer to our proposed framework, IoT TeleHub, and
    the term platform to refer to existing IoT platform. Virtual node representation
    IoT devices are represented logically as virtual nodes in our framework, allowing
    the separation of the actual hardware details from the system. This approach provides
    two benefits, (1) abstraction and (2) security. As the devices are represented
    as logical entities, different hardware can be dealt with in the same manner,
    i.e., we can represent an ARM-based microcontroller and an Intel-based mini PC
    similarly. Masking hardware details fortifies the devices against the reconnaissance
    step of security attacks. Masking hardware is by no means a complete security
    solution as we cannot solely rely on the obscurity of hardware details, and other
    security measures have to be incorporated. Discussion on more robust security
    measures is out of the scope of this work. A more powerful IoT device may take
    advantage of logical representation by representing itself as multiple nodes.
    For instance, a Raspberry Pi 4 is connected with several sensors that are grouped
    logically. We can run multiple processes on the Raspberry Pi; each accesses a
    different group of sensors and connects with the system as a different virtual
    node. Again, this provides complete abstraction of the underlying hardware while
    allowing logical separation of sensor arrays to ease the analysis later. Fig.
    2 Label and tag in IoT TeleHub virtual node measurements Full size image We describe
    our virtual node representation format as shown in Fig. 2. There are three mandatory
    fields defined in the format. Uniquely namespaced ID. Required to correctly identify
    every node in the framework, particularly for data sharing. Access token. Provides
    virtual nodes with access to the data management layer. List of measurements.
    Measurements correspond to the physical phenomenon measured by the node, e.g.,
    temperature, humidity, occupancy, wind velocity, current consumption, and other
    telemetry data. Each measurement is defined by label and tag fields. The label
    field contains a string used to identify the measurement in a human-understandable
    format. The tag field contains a string that distinguishes the telemetry value
    sent by the nodes. This scheme helps in describing the data in a human-understandable
    format while allowing the most efficient data format for transmission. For instance,
    as illustrated in Fig. 2 we can use the label “Average Temperature” to describe
    our ambient temperature measurement, where the IoT node annotates the value it
    transmits with the tag “t”. Saving several bytes of characters in resource-constrained
    IoT setups is significant. For example, in a SigFox enabled device where the maximum
    uplink payload size is 12 bytes [47]. Data storage format and layering of concerns
    In the IoT TeleHub framework, we characterize telemetry data as time-series data,
    i.e., one-dimensional data. Data for each measurement on each node is stored separately,
    allowing flexibility in the logging method. That is, we store each measurement’s
    telemetry data as an array of ts-val pairs. ts is the timestamp and val is the
    value of the telemetry data. With this structure, an IoT node may have different
    sensors logging at different periods. Figure 3 shows an example of the data storage
    format for an energy harvesting controller. The node maintains two measurements,
    the “Power Consumption” and the “Power Harvested”, represented in a virtual node
    format shown in the left side of the figure. Data for each node is stored in a
    distinct object keyed by the unique identifier (should be identical to the virtual
    node representation). Furthermore, data for each measurement is stored in an array
    keyed by the measurement’s tag field. During operation, the node may send the
    two measurements together or separately as seen fit. Fig. 3 Data storage format
    in IoT TeleHub Full size image Service layer and data sharing semantic Our framework
    broadly defines the service layer as the data translation layer but does not define
    translation formats as it limits generality. For instance, consider the case where
    the service layer needs to provide the stored measurements to an application layer.
    It could directly return the list of measurements keyed by the tag as shown in
    the data storage format in Fig. 3, and let the application layer query further
    which label does the tag correspond to from the virtual node record. Another way
    is the service layer could perform the label and tag matching from the virtual
    node record, then send it along with the measurement data to the application layer.
    Despite the trivial difference, this example illustrates how different platforms
    may adopt different data translation formats. Thus, defining an exact data translation
    format will remove the generality of our service layer. We propose data sharing
    functionality on the service layer by defining data sharing semantic. We describe
    data sharing functionality as allowing read access to nodes data owned by specific
    users. In other words, the sharing is on a node basis. For that, we 1. extend
    the virtual node representation with owner identifier and public flag fields,
    2. introduce sharing relationships between nodes and users, and 3. define a set
    of methods for data sharing. Owner identifier describes the owner of a node, while
    public flag specifies whether a node is open for sharing. Figure 4 depicts this
    idea. Each entry in the node-user relational table is described as follows. access_id:
    a unique identifier for each node-user relationship. node_id: the unique identifier
    of the node being shared. req_user_id: the unique identifier of the user being
    granted access to the node data. permission: read or write permission. Earlier,
    we described that data sharing functionality is limited to read. This field is
    left for future use if write or more complex permissions are required. Fig. 4
    Data sharing semantic with extended virtual node format and relationship table
    Full size image We define our data sharing semantic to allow explicit sharing.
    That is, users can declare the discoverability of their nodes as public or private.
    Private nodes are only visible to their owners, while public nodes can be discovered
    by other users and have their data shared. We define the following methods to
    complete the data sharing semantic: Set_node_public/private: set nodes discoverability
    as public or private. List_public_nodes: list all nodes whose discoverability
    is public, along with selected fields of the virtual node representation. Request_access:
    request data sharing access for a specific node. The request will be shown to
    the user who owns the node. List_access_requests: list all data sharing access
    requests for a user. Grant_access: grant data-sharing access for a particular
    node to the requesting user. Create a new entry in the relationship table. Reject_access:
    reject data sharing access for a particular node. With this data sharing semantic,
    the data sharing process is real-time and flexible. It removes the need to grant
    access to the physical devices to the requesting parties or manually download
    the data and send them over. Please note that the data sharing semantic does not
    interfere with the translation functionality of the service layer. IoT platforms
    may adopt this data sharing framework and define their service layer’s data translation
    on the same level as the data sharing. We explore this further in our prototype
    described in the ‘Prototype as an implementation of the framework’ section. Extensibility
    and openness Summarizing the proposed framework and semantic, we have defined:
    1. Device management, data management, and service layers in the general architecture.
    We have discussed each layer’s basic functionalities and the respective data formats.
    2. Extensible data formats. We consider most fields in the data formats as metadata,
    which allows the incorporation of more functionalities to the framework by adding
    more metadata to the basic formats presented in this work. For instance, we can
    extend the virtual node format by adding node description, sensor types associated
    with each measurement, unit metrics, or location identifiers to better index IoT
    nodes [48]. Similarly, we can add measurement metadata to the data sharing semantic
    to have more fine-grained access sharing. The proposed framework and semantic
    promote openness for interoperability between various platforms and applications,
    shown in Fig. 5. First, the service layer can allow applications to access required
    data through public application programming interfaces (API). Second, the data
    sharing functionality we defined in the service layer can also communicate with
    the data sharing functionality in other platforms. We can attain cross-platform
    sharing by exchanging the output of the List_public_nodes method, appended with
    a unique identifier of each platform. Fig. 5 Openness of the proposed framework
    for cross-platform data sharing Full size image Different data schema is a very
    possible case for cross-platform data sharing, hence we describe further how our
    data sharing semantics approaches such a problem in the following two scenarios.
    Data sharing in the same platform/framework (ours). The proposed framework treats
    telemetry data as collection of one-dimensional time series data, i.e. arrays
    of timestamp-value pairs. In that sense, the general data schema is rigid. However,
    we allow flexibility in terms of users can freely specify what and how many ‘data
    fields’ to be stored in the system, per node. The data sharing semantic only defines
    whether other users can access the data from other user’s nodes. There is no difference
    in the stored data format aside from the aforementioned ‘data fields’. This applies
    to other platforms that fully adopt our framework as well. Cross-platform data
    sharing. We assume an extreme case of platforms storing telemetry data with a
    schema different from our framework. In that case, those platforms can still adopt
    our data sharing semantics since it only specifies whether certain nodes are available
    for sharing and which users have access to the shared nodes, decoupled from how
    the data schema is represented to other platforms. The service layer is the one
    responsible for translating the different data schema between platforms, commonly
    in the form of API calls. Mapping of existing virtualization and sharing platforms
    In this section, we map our framework to three architectures or frameworks introduced
    in previous works by Gyrard et al. [38], Ogawa et al. [42], and Guth et al. [49].
    These three works were selected as our framework’s mapping targets due to their
    architectures covering aspects that we intend to highlight from our framework,
    which is detailed further throughout this section. The mapping is only intended
    to demonstrate the generality of our framework and does not imply that our framework
    is better than those proposed in other works. In particular, we would like to
    highlight a unique point of our framework through the mapping. That is, while
    the framework defines the layers and data formats specifically for the case of
    telemetry data, it is still general enough to be mapped to multiple other frameworks
    or platforms that cover a wide range of use cases. Another unique point of the
    framework lies in how we consider and incorporate the machine-readable and machine-understandable
    aspect in this work, which is detailed further in the Discussion section. Fig.
    6 Mapping of the proposed framework and the semantic interoperability architecture
    in [38] Full size image Figure 6 depicts the 12 layers architecture introduced
    in the semantic interoperability architecture by Gyrard et al. [38] and its mapping
    against our framework. This architecture provides an interesting comparison due
    to the number of its fine-grained layering of functionalities, as opposed to the
    three main layers defined in our core framework, IoT TeleHub. While it is clear
    that the fine-grained layers defined in [38] provide much better separation of
    IoT platform functionalities, some smaller platforms might not necessarily need
    such details. Those platforms might better adopt simpler reference architecture
    with fewer layers like IoT TeleHub. By mapping our framework to the architecture
    introduced by Gyrard et al. [38], we would like to show that IoT TeleHub with
    fewer layers can cover parts of or all of the 12 layers defined in [38]. Hence,
    platforms that reference our framework can evolve their functional layers as the
    platforms grow, with sufficiently clear distinction between layers. The device
    management and data management layers in our framework are equal, thus might be
    mapped in no specific order. We describe the mapping as follows. Hardware and
    Communication layer. Responsible for getting data from IoT devices and sending
    them to the Internet. Maps to our Node as the physical IoT device. Middleware
    and Ontology layer. Responsible for harmonizing existing platforms and defining
    unified data models. Maps to the device management layer in IoT TeleHub. The heterogeneity
    of devices or platforms as data providers can be abstracted into virtual nodes.
    Data and Linking layer. Consolidates and enriches data from heterogeneous sources.
    Maps to the data management layer which serves as the “data channel” in IoT TeleHub.
    The data enrichment is actually defined in virtual node representation in the
    device management layer. However, as the data management layer also works with
    the virtual node representation during data consolidation, we map the enrichment
    functionality to this layer as well. Reasoning and Querying layer. Responsible
    for selecting data and, if required, deducing information from the data. Maps
    to the service layer that provides access to data in our framework. The service
    layer could provide various data formats to upper layers that may involve just
    data queries or even some data processing. Security layer. Maps to every layer
    in our framework as each functionality requires security. For instance, the data
    management layer in IoT TeleHub performs node authentication before accepting
    data from the sending parties, while the device management layer provides abstraction
    of the actual hardware types. Validation layer. Maps to every layer in our framework
    as the layers are dependent on semantics described by other layers. Service layer.
    Straightforwardly mapped to the service layer in our framework that provides data
    access to upper layers (e.g. Application layer) or other platforms. Visualization
    layer. It provides user interfaces and maps to the Application in our framework.
    Fig. 7 Mapping of the proposed framework and the IoT device virtualization architecture
    in [42] Full size image The architecture for IoT device virtualization proposed
    in [42] discussed an interesting notion of effectively sharing IoT devices between
    applications, and introduced a minimal yet functional architecture along with
    its deployment in a microservices-driven setup. As opposed to the previous mapping
    to [38], in this mapping we instead expand the layers in Ogawa et al. ’s architecture.
    This shows that our framework is mapped properly to a minimal device sharing architecture
    that has been proven to work. Furthermore, we expand the definition of IoT devices
    sharing on a cross-platform basis. That is, our framework provides a reference
    for individual IoT platforms that also accommodates cross-platform sharing. This
    mimics the typical real world use case where different institutions and organizations
    have their own platforms, but require interoperability with other platforms. Our
    framework maps straightforwardly to the IoT device virtualization architecture
    [42], as shown in Fig. 7. Sensors and Applications map to Nodes and Applications
    in our framework, respectively. Function components that provide common APIs also
    map directly to our service layer. Lastly, the Gateway component that performs
    data pooling functionality is represented by our framework’s device management
    layer and data management layer. Lastly, we map our framework to a reference IoT
    architecture presented by Guth, et al. [49]. While they do not explicitly discuss
    IoT platforms for data sharing, it provides a general architecture that most IoT
    platforms adhere to. We show through this mapping that our data sharing semantic
    can be adopted to existing platforms, regardless of the platforms having data
    sharing capability or not. The IoT integration middleware in the reference architecture
    is described broadly and covers most of the functionalities in IoT platforms.
    Thus our core framework maps directly to it, as shown in Fig. 8. We deduce that
    our framework is general in the sense that it fits into the IoT integration middleware.
    However, more detailed work is required to incorporate the data sharing semantic
    into each platform rather than mapping it to the reference architecture. Fig.
    8 Mapping of the proposed framework and the IoT reference architecture in [49]
    Full size image Prototype as an implementation of the framework In this section,
    we present IoThingsHub, an IoT platform built for real-time data sharing. We discuss
    IoThingsHub architectures and show how we implement IoThingsHub based on our framework
    with existing web technologies. Lastly, we briefly present IoThingsHub features
    and its data sharing function. IoThingsHub architecture Figure 9 depicts IoThingsHub
    architecture on the left and our framework on the right side. The mapping between
    elements is shown with color-coding, i.e., elements with the same color. IoThingsHub
    utilizes a NoSQL database to keep the telemetry data and SQL relational database
    for the rest, detailed in the next subsection. Precisely, IoThingsHub comprises
    of four main elements: 1. Node. A typical IoT device that is intended to connect
    to the platform. 2. Web API Core Module. This module covers the device management
    layer and the service layer functionalities. It provides HTTP API to the Web Frontend.
    The figure shows that users represent the Node as a virtual node via the Web Frontend
    to access the Web API Core Module. We still consider the direct logical connection
    between the Node and the Web API Core Module as Web Frontend is just one of the
    methods to communicate with the Web API Core Module. 3. Node Core Module. This
    module covers the data management layer functionality. It listens on HTTP and
    MQTT connections. Nodes can send telemetry data to the Node Core Module after
    they are virtually represented in the platform. Nodes must always attach their
    access tokens with the telemetry data for authentication. The Node Core Module
    will store the telemetry data according to the credentials in the access token.
    4. Web Frontend. The application that connects to the service layer. We will discuss
    this next in IoThingsHub features. Fig. 9 IoThingsHub architecture mapping to
    the proposed framework Full size image Figure 10 describes the IoThingsHub platform
    implementation in more detail. We used these technologies to build the platform:
    MySQL Community Server v8.0 for the relational database, and MongoDB v4.4 for
    the NoSQL database. We also used Redis v5 for its in-memory storage and messaging
    functions. NodeJS to build the WebAPI Core Module and the Node Core Module as
    we characterize that our platform operations are IO-heavy, and the asynchronous
    nature of NodeJS fits that. We used the ExpressJS framework for building the API
    endpoints. Socket IO for real-time communication between the WebAPI Core Module
    and the Web frontend (only for real-time widgets) running on web browsers. Mosquitto
    MQTT broker for MQTT communication between the Nodes and the Node Core Module.
    NGINX as the proxy server, routing all traffic into the internal elements. Those
    endpoints are the WebAPI Core HTTP endpoints, the Node Core HTTP endpoints, the
    routing of MQTT streams into Mosquitto MQTT broker, the Web frontend static files,
    and the Socket IO endpoints. Fig. 10 IoThingsHub technical architecture Full size
    image Based on the detailed architecture, we describe further the technical implementation
    of these IoThingsHub’s elements as follows. The WebAPI Core Module connects with
    both MySQL and MongoDB, and listens to HTTP API requests from the Web frontend.
    It utilizes Redis in-memory storage to keep a list of active Web frontend clients
    that has ‘Dashboard’ pages with real-time Widgets open. This list will be used
    for propagating real-time telemetry updates to the Web frontend via Socket IO.
    The real-time update to the Web frontend does not affect the data logging process,
    i.e., the telemetry data will still be stored in MongoDB whether the Web frontend
    clients list is empty or not. The Node Core Module connects with both MySQL and
    MongoDB, and accepts telemetry data sent via HTTP from the Nodes. It also subscribes
    to the Mosquitto broker on selected channels, listening to telemetry data from
    the Nodes. For each telemetry data received, the Node Core Module saves it to
    MongoDB accordingly and checks in Redis in-memory storage whether there are any
    active Web frontend clients waiting for real-time data. If so, the Node Core Module
    sends the information to the WebAPI Core Module via Redis messaging service, which
    then propagates the data to the corresponding Web frontend clients. SQL and NoSQL
    in IoThingsHub In the implementation, we used NoSQL only for nodes’ telemetry
    data because we needed the flexibility in storing those telemetry data. For instance,
    a user wants to store temperature and humidity data, while another user intends
    to store luminance, ambient noise, and humidity data. The widely varying type
    and number of ‘data fields’ that each user and each node requires led to NoSQL
    as the storage solution. However, adhering to the data storage format in Fig.
    3, we kept some rigidity enforced via the data management layer. That is, the
    only flexible part in the NoSQL data format is the list of ‘data fields’. The
    content of those data fields are rigidly formatted as an array of timestamp-value
    pairs. The SQL stores information for Users, Projects, Nodes, and Widgets. Particularly,
    the Nodes information contains the node unique ID, the ownership (which user owns
    the node), and the ‘data fields’. We enforce the rigidity of the SQL on the NoSQL
    database in this manner: For each node registered to the system, the device management
    layer creates a new entry in the SQL database, and instructs the data management
    layer to create a corresponding entry in the NoSQL database, sharing the same
    node ID and ‘data fields’. Each Widget entry in the SQL database stores information
    of which nodes and which ‘data fields’ that it will display. When querying data
    for the Widget, the service layer will query the NoSQL database based on the information
    in the Widget. Hence, the actual IoT node must send their telemetry data in accordance
    with the SQL database, else their data will not be shown in the Widgets (hence
    inaccessible). For instance, a node is registered with two data fields, ‘luminance’
    and ‘noise’. A Widget is created to show those two fields as a time series data.
    The actual IoT node should send its telemetry data marked as ‘luminance’ and ‘noise’,
    else it will not be stored in the NoSQL, or even displayed in the Widget. IoThingsHub
    features Users connect their IoT nodes to IoThingsHub and view their data in a
    customizable dashboard. We explain IoThingsHub use cases and features with these
    four entities in the platform: 1. User. A typical user in a system that is allowed
    to login and access IoThingsHub. A user may own multiple Nodes and multiple Projects.
    2. Node. A virtual representation of IoT nodes. It follows the virtual node format
    discussed in the framework. Users can access the nodes they own as shown in Fig.
    11. Note that there is a “group icon” on Nodes with public discoverability. Figure
    12 shows a dialog for creating a new virtual node representation in IoThingsHub.
    3. Project. A virtual representation for an IoT system. Nodes can be added under
    one or more Projects, where their data is accessible for the Project. Each Project
    is assigned a dashboard that holds multiple Widgets and assigned a secret MQTT
    channel for nodes to send their data. Figure 13 shows an example of a Project
    page containing the project details and list of nodes added under that Project.
    As in the Node, Project name is also uniquely namespaced with the username. 4.
    Widget. A typical IoT widget for displaying nodes data in various forms. Users
    may add, modify, and remove Widgets to their interests. Per the writing of this
    paper, there are three widget types available in IoThingsHub; (1) time series
    line graph, (2) real-time line graph, and (3) real-time value. Figure 14 displays
    an example of a Project’s dashboard, containing two real-time value Widgets and
    one time series line graph Widget. Fig. 11 IoThingsHub—list of nodes owned by
    a user Full size image Fig. 12 IoThingsHub—an example of create node dialog Full
    size image Fig. 13 IoThingsHub—an example of a project page Full size image Fig.
    14 IoThingsHub—an example of a project’s dashboard page Full size image Fig. 15
    IoThingsHub—an example of nodes sharing page Full size image Users can browse
    other user’s public nodes via the Sharing menu and request access to any node
    of interest, as shown in Fig. 15. Users can also view a list of access requests
    from other users and either approve or deny the requests. In the example shown
    in Fig. 15, the user discovers three public nodes from other users and receives
    one access request for the node named “ceadmin/energy01” that he or she owns.
    After receiving approval from the node owner, the requesting user may use the
    requested node’s data in their project dashboard. Figure 16 shows an example of
    a user named “CE Admin” displaying the data from a shared node named ”dareenh/testing01_nodejs”.
    It displays the data in the time series line graph Widget, which is entirely local
    to “CE Admin”. Fig. 16 IoThingsHub—displaying shared nodes data in local widgets
    Full size image Fig. 17 Considering context in the proposed semantic Full size
    image Discussion This section highlights the main idea that underlies our proposed
    framework and semantics. That is, how we view and consider the machine-readable
    and machine-understandable notions in this work, which is defined specifically
    in the domain of physical-world telemetry data over IoT. We based our framework
    and semantics on the concept that physical-world data points provide meaningful
    information as a group, which at its simplest form is a time series. We consider
    the machine-readable notion in the sense that a machine-readable (syntactic) format
    should be as compact and as natural as possible for the machine to process and
    transceive. The compactness aspect is reflected in the use of labels and tags
    to separate the human-readable and machine-readable format as shown in Fig. 2.
    As depicted in Fig. 3, the data storage format advocates storing measurements
    as separated arrays of timestamp-value pairs. The array data structure comes naturally
    as we perceive telemetry data as time series, and it is a simple yet versatile
    data structure that can be manipulated freely and quickly by computers. Similarly,
    we consider the machine-understandable aspect in how to incorporate context into
    the device and data-related semantics in a flexible way, without compromising
    the performance. This is represented in the virtual node representation and the
    data storage format, most notably by the use of labels and tags. As shown in Fig.
    3, both node representation and data storage formats allow addition of context
    information flexibly without affecting their basic functionality. For example,
    in the virtual node representation, we can add fields regarding location, ownership,
    device characteristics (e.g., remote or stationed) in the same level as the node
    ID field. Going further, the measurement fields can be extended by measurement
    unit, method, and collection period fields as discussed by Zeng et al. [40]. All
    this contextual information is separated from the measurement data that the nodes
    must send, allowing bandwidth saving. If required, contextual information can
    also be added into each telemetry data point without burdening the node. Consider
    the case of a fleet of data loggers on solar panel units sending measurements
    to an edge gateway that communicates with a central server. The data loggers send
    only necessary measurements to the gateway, which then append the data with contextual
    information such as weather conditions before sending it to the central server.
    This idea is illustrated in Fig. 17. Conclusion , limitations and opportunities
    for future research In this work, we proposed IoT Telemetry Data Hub (IoT TeleHub),
    a general IoT framework and semantic for telemetry data collection and sharing.
    We presented three core layers that constitute the framework by defining their
    functionality and respective data semantics, i.e., device management layer, data
    management layer, and service layer. For interoperability with existing IoT platforms,
    the defined data semantics only covers parts related to telemetry data sharing.
    We characterized telemetry data as time-series data and defined the respective
    data storage semantic. IoT devices are abstracted as virtual nodes in our framework
    to provide separation of hardware and software. We demonstrated two unique points
    of our work. First, the framework’s generality by mapping the framework to several
    existing IoT platforms. It shows that our framework can map well to existing platforms
    if performed on a one-on-one basis. Second, we designed the framework while considering
    the machine-readable and machine-understandable notion in regard to the performance
    aspect of resource-constrained IoT devices, e.g., bandwidth, battery, and computational
    power. Lastly, we presented IoThingsHub, an IoT platform for real-time data sharing,
    developed based on the presented framework. We built the platform with existing
    technologies such as HTTP, MQTT, SQL, NoSQL. It demonstrates the data sharing
    service with a nodes-users relational table that is detached from the data collection
    and storage. Future works may extend the framework and semantic by adding context
    information and various metadata into the virtual node representation. These extra
    fields allow better understanding and indexing of the nodes and data shared in
    the platform. Furthermore, we can employ more fine-grained sharing by extending
    the nodes-users relational table with a list of measurements. Availability of
    data and materials Data generated during the study by the platform operation are
    available from the corresponding author on a reasonable request. The platform
    that implements the framework is hosted under the university’s domain, and available
    internally. Abbreviations API: Application Programming Interface IoT: Internet
    of Things MQTT: MQ Telemetry Transport TSDB: Time Series Database W3C: World Wide
    Web Consortium References L’Heureux A, Grolinger K, Elyamany HF, Capretz MAM.
    Machine learning with big data: challenges and approaches. IEEE Access. 2017;5:7776–97.
    https://doi.org/10.1109/ACCESS.2017.2696365. Article   Google Scholar   Tsai C-W,
    Lai C-F, Chao H-C, Vasilakos AV. Big data analytics: a survey. J Big Data. 2015;2(1):21.
    https://doi.org/10.1186/s40537-015-0030-3. Article   Google Scholar   Kubina M,
    Varmus M, Kubinova I Use of big data for competitive advantage of company. Procedia
    Economics and Finance 2015;26:561–565. https://doi.org/10.1016/S2212-5671(15)00955-7.4th
    World Conference on Business, Economics and Management (WCBEM-2015). Statista:
    Number of Internet of Things (IoT) Connected Devices Worldwide from 2019 to 2030.
    https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/.
    Cisco: Cisco Annual Internet Report (2018–2023) White Paper. https://www.cisco.com/c/en/us/solutions/collateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html.
    Statista: Data Volume of Internet of Things (IoT) Connections Worldwide in 2019
    and 2025. https://www.statista.com/statistics/1017863/worldwide-iot-connected-devices-data-size/.
    Morais CMd, Sadok D, Kelner J. An iot sensor and scenario survey for data researchers.
    J Brazil Comput Soc. 2019;25(1):4. https://doi.org/10.1186/s13173-019-0085-7.
    Article   Google Scholar   Hossain E, Khan I, Un-Noor F, Sikander SS, Sunny MSH.
    Application of big data and machine learning in smart grid, and associated security
    concerns: a review. IEEE Access. 2019;7:13960–88. https://doi.org/10.1109/ACCESS.2019.2894819.
    Article   Google Scholar   Shapi MKM, Ramli NA, Awalin LJ. Energy consumption
    prediction by using machine learning for smart building: case study in Malaysia.
    Dev Built Environ. 2021;5:100037. https://doi.org/10.1016/j.dibe.2020.100037.
    Article   Google Scholar   Zhang Y, Huang T, Bompard EF. Big data analytics in
    smart grids: a review. Energy Inform. 2018;1(1):8. https://doi.org/10.1186/s42162-018-0007-5.
    Article   Google Scholar   Seethalakshmi P, Venkatalakshmi K. Prediction of energy
    demand in smart grid using deep neural networks with optimizer ensembles. In:
    2020 Fourth International Conference on Computing Methodologies and Communication
    (ICCMC), 2020:pp. 1–5. https://doi.org/10.1109/ICCMC48092.2020.ICCMC-000109. Karyono
    K, Abdullah BM, Cotgrave AJ, Bras A. The adaptive thermal comfort review from
    the 1920s, the present, and the future. Dev Built Environ. 2020;4:100032. https://doi.org/10.1016/j.dibe.2020.100032.
    Article   Google Scholar   Tushar W, Wijerathne N, Li W-T, Yuen C, Poor HV, Saha
    TK, Wood KL. Internet of things for green building management: disruptive innovations
    through low-cost sensor technology and artificial intelligence. IEEE Signal Process
    Mag. 2018;35(5):100–10. https://doi.org/10.1109/MSP.2018.2842096. Article   Google
    Scholar   Alawadi S, Mera D, Fernández-Delgado M, Alkhabbas F, Olsson CM, Davidsson
    P. A comparison of machine learning algorithms for forecasting indoor temperature
    in smart buildings. Energy Syst. 2020. https://doi.org/10.1007/s12667-020-00376-x.
    Article   Google Scholar   Rusli A, Halim DK Towards an integrated hybrid mobile
    application for smart campus using location-based smart notification. In: 2019
    International Conference on Engineering, Science, and Industrial Applications
    (ICESI), 2019:pp. 1–6. https://doi.org/10.1109/ICESI.2019.8863022. Halim D, Rusli
    A. Wi-fi based indoor localization for location-based smart notification. IJNMT
    (International Journal of New Media Technology). 2020;7(1):43–50. https://doi.org/10.31937/ijnmt.v7i1.1628.
    Article   Google Scholar   Sun D, Wei E, Ma Z, Wu C, Xu S. Optimized cnns to indoor
    localization through ble sensors using improved pso. Sensors. 2021. https://doi.org/10.3390/s21061995.
    Article   Google Scholar   Sadowski S, Spachos P. Rssi-based indoor localization
    with the internet of things. IEEE Access. 2018. https://doi.org/10.1109/ACCESS.2018.2843325.
    Article   Google Scholar   Stefanoiu A-M, Woloszyn M, Jay A, Wurtz E, Buhé, C.:
    A methodology to assess the ambient temperature of a building using a limited
    number of sensors. Energy Procedia 78, 1944–1949,. 6th International Building
    Physics Conference. IBPC. 2015;2015. https://doi.org/10.1016/j.egypro.2015.11.377.
    Yan X, Liu C, Li M, Hou A, Fan K, Meng Q. Climate compensation and indoor temperature
    optimal measuring point energy saving control in vav air-conditioning system.
    Energies. 2019. https://doi.org/10.3390/en12224398. Article   Google Scholar   Popović
    T, Latinović N, Pečić A, Zečević Z̆arko, Krstajić B, Djukanović S. Architecting
    an IoT-enabled platform for precision agriculture and ecological monitoring: a
    case study. Comput Electr Agric. 2017;140:255–65. https://doi.org/10.1016/j.compag.2017.06.008.
    Article   Google Scholar   Kassal P, Steinberg MD, Steinberg IM. Wireless chemical
    sensors and biosensors: a review. Sens Actuators B Chem. 2018;266:228–45. https://doi.org/10.1016/j.snb.2018.03.074.
    Article   Google Scholar   Villa-Henriksen A, Edwards GTC, Pesonen LA, Green O,
    Sørensen CAG. Internet of things in arable farming: implementation, applications,
    challenges and potential. Biosyst Eng. 2020;191:60–84. https://doi.org/10.1016/j.biosystemseng.2019.12.013.
    Article   Google Scholar   Gopinath R, Kumar M, Prakash Chandra Joshua C, Srinivas
    K. Energy management using non-intrusive load monitoring techniques—state-of-the-art
    and future research directions. Sustain Cities Soc. 2020;62:102411. https://doi.org/10.1016/j.scs.2020.102411.
    Article   Google Scholar   Benedá T, Manera LT. Non-intrusive and intrusive energy
    monitoring methods overview and their relation with household appliances state
    sensors devices. In: Iano, Y., Arthur, R., Saotome, O., Vieira Estrela, V., Loschi,
    H.J. (eds.) Proceedings of the 4th Brazilian Technology Symposium (BTSym’18),
    2019:pp. 407–415. Springer, Cham. Mumtaz S, Alsohaily A, Pang Z, Rayes A, Tsang
    KF, Rodriguez J. Massive internet of things for industrial applications: addressing
    wireless iiot connectivity challenges and ecosystem fragmentation. IEEE Ind Electr
    Mag. 2017;11(1):28–33. https://doi.org/10.1109/MIE.2016.2618724. Article   Google
    Scholar   Khan WZ, Rehman MH, Zangoti HM, Afzal MK, Armi N, Salah K. Industrial
    internet of things: recent advances, enabling technologies and open challenges.
    Comput Electr Eng. 2020;81:106522. https://doi.org/10.1016/j.compeleceng.2019.106522.
    Article   Google Scholar   Moore SJ, Nugent CD, Zhang S, Cleland I. IoT reliability:
    a review leading to 5 key research directions. CCF Trans Pervasive Comput Interact.
    2020;2(3):147–63. https://doi.org/10.1007/s42486-020-00037-z. Article   Google
    Scholar   Karkouch A, Mousannif H, Moatassime HA, Noel T. A model-driven architecture-based
    data quality management framework for the internet of things. In: 2016 2nd International
    Conference on Cloud Computing Technologies and Applications (CloudTech), 2016:pp.
    252–259. https://doi.org/10.1109/CloudTech.2016.7847707. Fekade B, Maksymyuk T,
    Kyryk M, Jo M. Probabilistic recovery of incomplete sensed data in IoT. IEEE Internet
    Things J. 2018;5(4):2282–92. https://doi.org/10.1109/JIOT.2017.2730360. Article   Google
    Scholar   Azimi I, Pahikkala T, Rahmani AM, Niela-Vilén H, Axelin A, Liljeberg
    P. Missing data resilient decision-making for healthcare IoT through personalization:
    a case study on maternal health. Future Gener Comput Syst. 2019;96:297–308. https://doi.org/10.1016/j.future.2019.02.015.
    Article   Google Scholar   Liu Y, Dillon T, Yu W, Rahayu W, Mostafa F. Missing
    value imputation for industrial IoT sensor data with large gaps. IEEE Internet
    Things J. 2020;7(8):6855–67. https://doi.org/10.1109/JIOT.2020.2970467. Article   Google
    Scholar   Khan SI, Hoque ASML. Sice: an improved missing data imputation technique.
    J Big Data. 2020;7(1):37. https://doi.org/10.1186/s40537-020-00313-w. Article   Google
    Scholar   Osman MS, Abu-Mahfouz AM, Page PR. A survey on data imputation techniques:
    water distribution system as a use case. IEEE Access. 2018;6:63279–91. https://doi.org/10.1109/ACCESS.2018.2877269.
    Article   Google Scholar   Noura M, Atiquzzaman M, Gaedke M. Interoperability
    in internet of things: taxonomies and open challenges. Mobile networks and applications.
    2019;24(3):796–809. https://doi.org/10.1007/s11036-018-1089-9. Article   Google
    Scholar   W3C: Semantic Sensor Network Ontology. https://www.w3.org/TR/vocab-ssn/.
    Agarwal R, Fernandez DG, Elsaleh T, Gyrard A, Lanza J, Sanchez L, Georgantas N,
    Issarny V. Unified iot ontology to enable interoperability and federation of testbeds.
    In: 2016 IEEE 3rd World Forum on Internet of Things (WF-IoT), 2016;pp. 70–75.
    https://doi.org/10.1109/WF-IoT.2016.7845470. Gyrard A, Serrano M. Connected smart
    cities: Interoperability with seg 3.0 for the internet of things. In: 2016 30th
    International Conference on Advanced Information Networking and Applications Workshops
    (WAINA), 2016;p. 796–802. https://doi.org/10.1109/WAINA.2016.151. Terziyan V,
    Kaykova O, Zhovtobryukh D. Ubiroad: Semantic middleware for context-aware smart
    road environments. In: 2010 Fifth International Conference on Internet and Web
    Applications and Services, 2010:p. 295–302 . https://doi.org/10.1109/ICIW.2010.50.
    Zeng W, Zhang S, Yen I-L, Bastani F. Invited paper: Semantic iot data description
    and discovery in the iot-edge-fog-cloud infrastructure. In: 2019 IEEE International
    Conference on Service-Oriented System Engineering (SOSE), 2019:pp. 106–10609.https://doi.org/10.1109/SOSE.2019.00024.
    de Matos E, Tiburski RT, Moratelli CR, Johann Filho S, Amaral LA, Ramachandran
    G, Krishnamachari B, Hessel F. Context information sharing for the internet of
    things: a survey. Comput Netw. 2020;166:106988. https://doi.org/10.1016/j.comnet.2019.106988.
    Article   Google Scholar   Ogawa K, Kanai K, Nakamura K, Kanemitsu H, Katto J,
    Nakazato H. Iot device virtualization for efficient resource utilization in smart
    city iot platform. In: 2019 IEEE International Conference on Pervasive Computing
    and Communications Workshops (PerCom Workshops), 2019;pp. 419–422. https://doi.org/10.1109/PERCOMW.2019.8730806.
    Cheng B, Solmaz G, Cirillo F, Kovacs E, Terasawa K, Kitazawa A. italic fogflow
    /italic : Easy programming of iot services over cloud and edges for smart cities.
    IEEE Internet Things J. 2018;5(2):696–707. https://doi.org/10.1109/JIOT.2017.2747214.
    Article   Google Scholar   Benazzouz Y, Munilla C, Günalp O, Gallissot M, Gürgen
    L. Sharing user iot devices in the cloud. In: 2014 IEEE World Forum on Internet
    of Things (WF-IoT), 2014;p. 373–374. https://doi.org/10.1109/WF-IoT.2014.6803193.
    Sekine H, Kanai K, Katto J, Kanemitsu H, Nakazato H. Iot-centric service function
    chainingorchestration and its performance validation. In: 2021 IEEE 18th Annual
    Consumer Communications Networking Conference (CCNC), 2021;pp. 1–4. https://doi.org/10.1109/CCNC49032.2021.9369538.
    Samaniego M, Deters R. Management and internet of things. Procedia Computer Science
    2016:94, 137–143. https://doi.org/10.1016/j.procs.2016.08.022.The 11th International
    Conference on Future Networks and Communications (FNC 2016) / The 13th International
    Conference on Mobile Systems and Pervasive Computing (MobiSPC 2016) / Affiliated
    Workshops. Sigfox: Sigfox Payload. https://build.sigfox.com/payload. Zhang WE,
    Sheng QZ, Mahmood A, Tran DH, Zaib M, Hamad SA, Aljubairy A, Alhazmi AAF, Sagar
    S, Ma C. The 10 research topics in the internet of things. In: 2020 IEEE 6th International
    Conference on Collaboration and Internet Computing (CIC), 2020;pp. 34–43. https://doi.org/10.1109/CIC50333.2020.00015.
    Guth J, Breitenbücher U, Falkenthal M, Fremantle P, Kopp O, Leymann F, Reinfurt
    L. A detailed analysis of iot platform architectures: concepts, similarities,
    and differences. In: Di Martino B, Li K-C, Yang LT, Esposito A, editors. Internet
    of everything: algorithms, methodologies, technologies and perspectives. Singapore:
    Springer; 2018. p. 81–101. Chapter   Google Scholar   Download references Acknowledgements
    The authors would like to thank you Universitas Multimedia Nusantara for supporting
    this work, in particular for the infrastructure required for the implementation.
    Funding Not applicable. Author information Dareen K Halim and Samuel Hutagalung
    are equally contributed to this work. Authors and Affiliations Dept. of Computer
    Engineering, Universitas Multimedia Nusantara, Jl. Scientia Boulevard, Tangerang,
    Indonesia Dareen K. Halim & Samuel Hutagalung Contributions DH has initiated and
    made the first draft of this paper. Both authors read and approved the final manuscript.
    Corresponding author Correspondence to Dareen K. Halim. Ethics declarations Ethics
    approval and consent to participate Not applicable. Consent for publication Not
    applicable. Competing interests The authors declare that they have no competing
    interests. Additional information Publisher''s Note Springer Nature remains neutral
    with regard to jurisdictional claims in published maps and institutional affiliations.
    Rights and permissions Open Access This article is licensed under a Creative Commons
    Attribution 4.0 International License, which permits use, sharing, adaptation,
    distribution and reproduction in any medium or format, as long as you give appropriate
    credit to the original author(s) and the source, provide a link to the Creative
    Commons licence, and indicate if changes were made. The images or other third
    party material in this article are included in the article''s Creative Commons
    licence, unless indicated otherwise in a credit line to the material. If material
    is not included in the article''s Creative Commons licence and your intended use
    is not permitted by statutory regulation or exceeds the permitted use, you will
    need to obtain permission directly from the copyright holder. To view a copy of
    this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and
    permissions About this article Cite this article Halim, D.K., Hutagalung, S. Towards
    data sharing economy on Internet of Things: a semantic for telemetry data. J Big
    Data 9, 1 (2022). https://doi.org/10.1186/s40537-021-00549-0 Download citation
    Received 28 August 2021 Accepted 10 December 2021 Published 04 January 2022 DOI
    https://doi.org/10.1186/s40537-021-00549-0 Share this article Anyone you share
    the following link with will be able to read this content: Get shareable link
    Provided by the Springer Nature SharedIt content-sharing initiative Keywords Internet
    of Things Data sharing Data semantic Interoperability Platform Framework Download
    PDF Download ePub Sections Figures References Abstract Introduction Related works
    on IoT virtualization and sharing Proposed framework and semantic—IoT TeleHub
    Mapping of existing virtualization and sharing platforms Prototype as an implementation
    of the framework Discussion Conclusion , limitations and opportunities for future
    research Availability of data and materials Abbreviations References Acknowledgements
    Funding Author information Ethics declarations Additional information Rights and
    permissions About this article Advertisement Support and Contact Jobs Language
    editing for authors Scientific editing for authors Leave feedback Terms and conditions
    Privacy statement Accessibility Cookies Follow SpringerOpen By using this website,
    you agree to our Terms and Conditions, Your US state privacy rights, Privacy statement
    and Cookies policy. Your privacy choices/Manage cookies we use in the preference
    centre. © 2024 BioMed Central Ltd unless otherwise stated. Part of Springer Nature."'
  inline_citation: '>'
  journal: Journal of Big Data
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Towards data sharing economy on Internet of Things: a semantic for telemetry
    data'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Gooseff M.N.
  - McKnight D.M.
  - Doran P.T.
  - Fountain A.
  citation_count: '4'
  description: The McMurdo Dry Valleys (MDVs; 77.50°S, 162.25°E) make up the largest
    ice-free region of Antarctica at ~3500 km2. Their position near the coast of the
    Ross Sea provides for a milder climate than much of the rest of the continent.
    Alpine and piedmont glaciers in the MDVs melt during the austral summer providing
    water to down gradient streams and terminal lakes on valley floors. There are
    currently 14 meteorological stations and 17 stream gauges operating across the
    MDVs, some with continuous records that go back to 1969. This relatively high
    density of monitoring stations reflects the fact that glaciers of different sizes
    and elevation ranges are the main source of water to streams. Thus, each glacier
    represents a different watershed. The bulk of these records start in the late
    1980s/early 1990s. These data collection activities directly support research
    endeavours of the McMurdo Dry Valleys Long Term Ecological Research project, as
    well as a host of other science groups working in the MDVs. As such, both real
    time data and archived data from these sites is available through the online database
    interface of the project (http://mcmlter.org).
  doi: 10.1002/hyp.14623
  full_citation: '>'
  full_text: '>

    "UNCL: University Of Nebraska - Linc Acquisitions Accounting Search within Login
    / Register Hydrological Processes RESEARCH AND OBSERVATORY CATCHMENTS: THE LEGACY
    AND THE FUTURE Full Access Long-term stream hydrology and meteorology of a Polar
    Desert, the McMurdo Dry Valleys, Antarctica Michael N. Gooseff,  Diane M. McKnight,  Peter
    T. Doran,  Andrew Fountain First published: 30 May 2022 https://doi.org/10.1002/hyp.14623
    Funding information US National Science Foundation, Grant/Award Number: 9211773
    9813061 9810219 0096250 0423595 0832755 1041742 1115245 1637708 SECTIONS PDF TOOLS
    SHARE Abstract The McMurdo Dry Valleys (MDVs; 77.50°S, 162.25°E) make up the largest
    ice-free region of Antarctica at ~3500 km2. Their position near the coast of the
    Ross Sea provides for a milder climate than much of the rest of the continent.
    Alpine and piedmont glaciers in the MDVs melt during the austral summer providing
    water to down gradient streams and terminal lakes on valley floors. There are
    currently 14 meteorological stations and 17 stream gauges operating across the
    MDVs, some with continuous records that go back to 1969. This relatively high
    density of monitoring stations reflects the fact that glaciers of different sizes
    and elevation ranges are the main source of water to streams. Thus, each glacier
    represents a different watershed. The bulk of these records start in the late
    1980s/early 1990s. These data collection activities directly support research
    endeavours of the McMurdo Dry Valleys Long Term Ecological Research project, as
    well as a host of other science groups working in the MDVs. As such, both real
    time data and archived data from these sites is available through the online database
    interface of the project (http://mcmlter.org). 1 SITE AND PROCESS DESCRIPTION
    The McMurdo Dry Valleys (MDVs) make up the largest ice-free region of Antarctica
    (Figure 1). The landscape is a mosaic of alpine, piedmont and terminal glaciers,
    exposed soils and rocky outcrops, streams, and ice-covered ponds and lakes (Figure
    2). The climate of the MDVs region is cold (mean annual air temperature of −19.6°C;
    Obryk et al., 2020) and dry (<10 mm snow water equivalent on the valley floors;
    Fountain et al., 2010). In the austral summer, surface energy balance is great
    enough to generate melt from the glaciers, which feeds streams, many of which
    eventually convey water to closed-basin lakes on the valley floors. Streams derive
    more than 95% of their flow from glacial melt (remainder is snow patch melt) and
    flow for 6–10 weeks on average (late November to mid February; Wlostowski et al.,
    2016), activating the extensive microbial mats along streambeds. This polar desert
    landscape has been studied intensively within the McMurdo Dry Valleys Long Term
    Ecological Research (MCM LTER) project since 1993. Like other LTER projects, MCM
    LTER participants collect core monitoring data and conduct short- and long-term
    experiments. FIGURE 1 Open in figure viewer PowerPoint Map of the McMurdo Dry
    Valleys region and the locations of ecosystem studies conducted by the McMurdo
    Dry Valleys long-term ecological research project (map generated by Eric Parrish)
    FIGURE 2 Open in figure viewer PowerPoint Images of (a) Wright Valley and the
    Onyx River looking upstream towards the coast, (b) the lost seal stream gage with
    a flume and overflow notch in its control structure, and (c) Taylor glacier meteorological
    station The seasonal meteorology of the MDVs revolves from the dark, cold austral
    winter (JJA) with air temperatures regularly around −40°C, to the spring (SO)
    with the onset of sunlight (generally reaching the valley floors for extended
    periods of the day in mid-November) and warming air temperatures, to the austral
    summer (NDJF) with peak solar radiation for the year and air temperatures around
    0°C, to the fall (MAM) with fading light and cooling air temperatures (Doran et
    al., 2002; Obryk et al., 2020). The MDVs, especially Taylor Valley, experience
    strong foehn wind events blowing down-valley (>20 m/s; Nylen et al., 2004; Speirs
    et al., 2010). These wind events are most common in the winter months and induce
    increases in air temperature and reductions of relative humidity. These high wind
    events promote aeolean transport of sediment, microbes, and algal mat material
    as a key vector of landscape connectivity moving these materials among landscape
    units (Šabacká et al., 2012). Snow falls in all seasons in the MDVs, though winter
    snow is typically consolidated into patches in topographic lees across the landscape
    due to wind redistribution (Eveland et al., 2013). These patches sublimate and
    melt through the austral summer. Active layers (seasonally thawed ground) are
    shallow across the MDVs, expanding under and adjacent to streams and lakes (Conovitz
    et al., 2006; Northcott et al., 2009). Permafrost is generally found to be >100 m
    deep across most of the MDVs, though recent airborne geophysics studies suggest
    that a deep briny groundwater system may exist under some of the MDVs (Mikucki
    et al., 2015). Thawed hyporheic zones adjacent to streams actively exchange stream
    water providing an important location of biogeochemical transformations prior
    to water and solutes entering lakes, including nutrient cycling (Gooseff et al.,
    2004; Koch et al., 2010; Kohler et al., 2018; McKnight et al., 2004), and weathering
    of the streambed sediments (Gooseff et al., 2002; Nezat et al., 2001). Across
    the MDV streams there are 16 established transects at which algal mats are sampled
    regularly to track biomass changes and diatom community dynamics (Kohler et al.,
    2016). Research personnel can only access the MDVs from October to February of
    a given field season. In a few cases, science groups have deployed during Winter
    Fly In, accessing the MDVs in August, and in 1 year a group stayed as late as
    April. Field teams access remote locations via helicopter typically on day trips
    from McMurdo Station or one of the several field camps established by the US Antarctic
    Program in Taylor Valley. Two primary data collection networks described here
    are the stream gaging network (17 current gages) and meteorological stations (14
    current stations). Because streamflow is primarily generated by glacial melt,
    each gage provides an estimate of streamflow from a portion of a glacier (see
    Bergstrom et al., n.d.). Many of the closed-basin lakes are fed by multiple streams.
    Thus, gaging these streams provides a means towards estimating a component of
    the water mass balance of the lakes. Meteorological stations are distributed across
    elevations and land surface types to estimate surface energy balances (i.e., dry
    ground vs. glacier surface) and provide basic weather and climate data. Some are
    also set up adjacent to lakes to estimate surface energy balance of lake ice-covers.
    2 HYDROLOGIC INSTRUMENTATION AND MEASUREMENTS Early science in the MDVs included
    the installation and operation of a stream gage on the Onyx River just above its
    mouth at Lake Vanda by a group of New Zealand scientists in 1968. The Onyx River
    is the largest stream in the MDVs and in Antarctica (Figure 2a). Soon after establishing
    the Onyx River at Vanda gage, another gage was installed near its headwater lake
    (Onyx at Lower Wright), approximately 25 km upstream. The Onyx River at Vanda
    gage has been operated continuously since 1969 (field personnel depart in early
    February and data loggers run well-beyond this; Chinn & Mason, 2015). In the early
    1990s other gages were established on glacial meltwater streams across the MDVs
    by MCM LTER researchers, though several have been removed or relocated due to
    lake level rise or damage from glacier movement. The entire Onyx River flow records
    and those of the LTER stream gages are available from the MCM LTER database. All
    17 stream gages presently measure and report water stage, water temperature, and
    electrical conductivity on a 15-min frequency. Each stream gage contains a control
    cross-section: a flume, a low rock weir with a notch, a v-notch weir, or a gabion
    and a small gage house located adjacent to the stream where dataloggers, conoflow,
    N2 tank, and power supplies are contained and protected from the elements. Stage
    at the control section is measured by bubbling N2 gas through a conoflow gas pressure
    purge/regulation system connected to a pressure transducer (either a PSS-1 or
    PSS-2 model from Paroscientific Corporation [Redmond, WA USA] or an Accubar model
    from Sutron Corporation [Sterling, VA USA], accuracy of 0.2 hPa), making up a
    bubbling gage (Sauer & Turnipseed, 2010). This approach reduces the need for electronic
    sensors in the stream. Outlet orifices of the tubes from the conoflows are fixed
    to flumes or to rebar established near the control cross sections. Elevations
    of points of zero flow (i.e., lowest point of control cross section), orifices,
    and other points of interest are measured in relationship to established benchmarks
    at each control cross-section at the start and end of each flow season. In the
    past, water temperature was measured with Campbell Scientific CS 107 probes (accuracy
    of 0.01°C). Recently these were removed so that stream water temperature and electrical
    conductivity are both being measured with Campbell Scientific CS-547A sensors
    (as of 2019; accuracy of EC measurement is 5% and 0.2°C for temperature). Sensors
    are controlled by either Campbell Scientific CR-10X or CR-1000 data loggers (depending
    on the gage). Power is supplied by solar chargers and 12 V batteries. Stream gages
    are ‘opened’ in mid-November and ‘closed’ in late January. In addition to running
    levels at gages, these activities include swapping of data storage modules and
    deployment of new N2 tanks in November. Stream gages run year-round, but flow
    seasons cease in February or March each year. Dataloggers run through the winter
    but N2 is exhausted before the beginning of the next flow season. Data gaps are
    present due to field sensor failures, freeze up of sensors, and so on. In the
    records these gaps are noted with indicators (i.e., ‘Nan’) or no entry within
    the csv file containing the data set. Data collected after one flow season ends
    (February or March) and the next begins (November/December) are not included in
    the data archives. During the austral summer, the MCM LTER stream team maintains
    the gaging network, makes manual discharge measurements, and collects stream water
    samples for chemical analysis. The manual measurements of discharge are used to
    generate a rating curve for each gage. At high enough flows, discharge measurements
    are made by wading methods, and at low flows, they are made using small portable
    Baski flumes (Englewood, CO, USA; accuracy depends on stage measurements made
    within the flume). Water temperature and electrical conductivity are measured
    during stream gage visits during the flow season using YSI (Yellow Springs Inc.;
    Yellow Springs, OH USA) portable field metres (as provided by the US Antarctic
    programme, so not necessarily the same model each season) for comparison to time
    series data collected by the data logger. All-time series gage data are currently
    processed (i.e., stages/temperatures/electrical conductivities are corrected and
    flows calculated) using Aquarius software (Aquatic Informatics; Vancouver, BC
    Canada). Historic flow data work-ups using USGS protocols (Sauer, 2002) and Automated
    DAta Processing System (ADAPS) software have been integrated into Aquarius as
    well. Stream hydrograph data (i.e., after processing) are rated as excellent,
    good, fair, or poor in adherence with US Geological Survey guidelines (Sauer,
    2002). Uncertainties for these ratings are 2, 5, 8, and 10%, respectively, depending
    on conditions of the gage at the time of or between visits, and/or the quality
    of the discharge measurement made during a visit. 3 METEOROLOGIC INSTRUMENTATION
    AND MEASUREMENTS The longest meteorological record in the MDVs comes from the
    Lake Hoare site, established in 1987 (prior to the initiation of the MCM LTER).
    Expansion of the meteorological station network was substantial in 1994 when protocols
    and common measurements were developed (Doran et al., 1995). Meteorological stations
    are deployed on top of several glaciers (Commonwealth, Canada, Howard, and Taylor
    Glaciers) in Taylor Valley to measure the surface energy balance of the glacier
    ice. Some of the meteorological stations established adjacent to major lakes of
    the MDVs with the goal of quantifying much of the surface energy balance of the
    lake ice covers. Meteorological stations measure several common parameters: air
    temperature (with Campbell Scientific CS 107 sensor), relative humidity (with
    Campbell Scientific 207 Phys-Chem transducers, with an accuracy of 5% at 25°C
    for the operating range of 12%–100%), wind speed and direction (currently measured
    with RM Young 05103 sensor, which has a wind speed accuracy of 1.5% and direction
    accuracy of 4%), and incoming solar radiation flux (with a Licor LI-200 pyranometer
    [Lincoln, NE USA], with a cosine-corrected silicon photodiode and maximum uncertainty
    of 5%). All parameters are recorded on a 15-min interval, however, wind speed
    and direction are measured at higher frequencies and statistics (e.g., mean wind
    speed, gust speed) are reported on 15-min intervals. At some of the glacier sites
    both incoming and outgoing long-wave (Eppley PIR pyrgeometer, uncertainty of 5
    Wm−2) and shortwave (Eppley SPP pyranometer, uncertainty of 10 Wm−2) radiation
    have been and/or are currently being measured. Some stations deployed on soils
    also include soil moisture and temperature sensors deployed at 0, 5, and 10 cm
    depths (Campbell Scientific CS655 with a 3% accuracy for water content and 0.5°C
    accuracy for soil temperature; and Decagon 5TM with a 3% accuracy for water content
    and 1°C accuracy for soil temperature). Several met stations also have sonic ranging
    sensors (Campbell Scientific SR50 with an accuracy of 1 cm) pointed at the ground
    from a high cross arm to measure the accumulation and ablation of snow. Precipitation
    gages (OTT Pluvio precipitation gage with an accuracy of 0.05 mm) are deployed
    at two locations in Taylor Valley. All sensors are calibrated on a regular schedule.
    ACKNOWLEDGEMENTS Numerous collaborators, students, postdocs and technicians have
    collected these field data over several decades. The support of logistical and
    helicopter support contractors facilitated these data collections in Antarctica
    since 1993 through the US Antarctic Program: Antarctic Support Associates, Raytheon
    Polar Services, Antarctic Support Contractors, Petroleum Helicopters, Inc., and
    Air Center Helicopters. The McMurdo LTER team also gratefully acknowledges the
    support of our New Zealand collaborators who operated the Onyx River gages for
    25 years prior to the start of the McMurdo LTER project. FUNDING INFORMATION The
    McMurdo LTER team gratefully acknowledges the funding support from the National
    Science Foundation for the initial LTER grant and subsequent renewals to date
    (award numbers 9211773, 9813061, 9810219, 0096250, 0423595, 0832755, 1041742,
    1115245, and 1637708). Open Research REFERENCES Volume36, Issue6 June 2022 e14623
    This article also appears in: Research and Observatory Catchments: the Legacy
    and the Future Figures References Related Information Recommended Permafrost distribution
    and active‐layer depths in the McMurdo Dry Valleys, Antarctica James G. Bockheim,  Iain
    B. Campbell,  Malcolm McLeod Permafrost and Periglacial Processes Polar Climates
    Roger G. Barry International Encyclopedia of Geography: People, the Earth, Environment
    and Technology, [1] McMurdo Dry Valleys of Antarctica Robert A. Wharton Eos, Transactions
    American Geophysical Union Climate From the McMurdo Dry Valleys, Antarctica, 1986–2017:
    Surface Air Temperature Trends and Redefined Summer Season M. K. Obryk,  P. T.
    Doran,  A. G. Fountain,  M. Myers,  C. P. McKay Journal of Geophysical Research:
    Atmospheres Snow in the McMurdo Dry Valleys, Antarctica Andrew G. Fountain,  Thomas
    H. Nylen,  Andrew Monaghan,  Hassan J. Basagic,  David Bromwich International
    Journal of Climatology Download PDF Additional links ABOUT WILEY ONLINE LIBRARY
    Privacy Policy Terms of Use About Cookies Manage Cookies Accessibility Wiley Research
    DE&I Statement and Publishing Policies Developing World Access HELP & SUPPORT
    Contact Us Training and Support DMCA & Reporting Piracy OPPORTUNITIES Subscription
    Agents Advertisers & Corporate Partners CONNECT WITH WILEY The Wiley Network Wiley
    Press Room Copyright © 1999-2024 John Wiley & Sons, Inc or related companies.
    All rights reserved, including rights for text and data mining and training of
    artificial technologies or similar technologies."'
  inline_citation: '>'
  journal: Hydrological Processes
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Long-term stream hydrology and meteorology of a Polar Desert, the McMurdo
    Dry Valleys, Antarctica
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Wang X.
  - Wan B.
  - Zhou W.
  - Niu H.
  - Feng S.
  citation_count: '0'
  description: In order to improve the regulation ability of adjustable load resources,
    realize the aggregation, sharing and regulation of "source-load-storage"regulation
    resources in the region, and improve the adjustable load management ability, the
    criteria and methods for accessing the operation system of load resource aggregators
    to the regulation center are proposed according to the safety protection requirements
    of power monitoring system and the communication ability of multi type load resource
    aggregators. To meet the security access of multiple resources, combined with
    different access modes of load resources, a network security protection mechanism
    combining software and hardware is proposed. Digital certificate, data encryption,
    situation awareness, analysis and early warning and other technologies are used
    to build security protection strategies for private network and different access
    modes such as Internet, wireless and optical fiber, so as to adapt to the security
    access of multiple resources. An interaction mode based on standardized data format,
    using web services (restful HTTPS), file interaction and 104 protocol could be
    established to adapt multi type adjustable load resource model and safe interaction
    of real-time data..
  doi: 10.1088/1742-6596/2189/1/012030
  full_citation: '>'
  full_text: '>

    "We value your privacy Clicking the \"Accept All\" button means you are accepting
    analytics and third-party cookies. We use cookies to optimise site functionality
    and give you the best possible experience. To control which cookies are set, click
    \"Customize\". Privacy and Cookies policy Customize Accept All Skip to content
    IOP Science home Accessibility Help Search Journals Books Publishing Support Login
    Journal of Physics: Conference Series PAPER • THE FOLLOWING ARTICLE IS OPEN ACCESS
    Research on technical scheme for multi type load resource information access Xin
    Wang1,2, Bo WAN1,2, Wei Zhou1,2, Huaitong Niu1,2 and Sibo Feng1,2 Published under
    licence by IOP Publishing Ltd Journal of Physics: Conference Series, Volume 2189,
    2021 International Conference on Communication Technology and Information Technology
    (ICCTIT 2021) 03/12/2021 - 05/12/2021 Harbin Citation Xin Wang et al 2022 J. Phys.:
    Conf. Ser. 2189 012030 DOI 10.1088/1742-6596/2189/1/012030 Download Article PDF
    References Article metrics 45 Total downloads MathJax Turn on MathJax Share this
    article Article and author information Abstract In order to improve the regulation
    ability of adjustable load resources, realize the aggregation, sharing and regulation
    of \"source-load-storage\" regulation resources in the region, and improve the
    adjustable load management ability, the criteria and methods for accessing the
    operation system of load resource aggregators to the regulation center are proposed
    according to the safety protection requirements of power monitoring system and
    the communication ability of multi type load resource aggregators. To meet the
    security access of multiple resources, combined with different access modes of
    load resources, a network security protection mechanism combining software and
    hardware is proposed. Digital certificate, data encryption, situation awareness,
    analysis and early warning and other technologies are used to build security protection
    strategies for private network and different access modes such as Internet, wireless
    and optical fiber, so as to adapt to the security access of multiple resources.
    An interaction mode based on standardized data format, using web services (restful
    HTTPS), file interaction and 104 protocol could be established to adapt multi
    type adjustable load resource model and safe interaction of real-time data.. Export
    citation and abstract BibTeX RIS Previous article in issue Content from this work
    may be used under the terms of the Creative Commons Attribution 3.0 licence. Any
    further distribution of this work must maintain attribution to the author(s) and
    the title of the work, journal citation and DOI. Show References Abstract References
    You may also like JOURNAL ARTICLES Trading Model and Development Path of Demand-Side
    Resource Aggregators An optimal dispatch model based on load aggregator associated
    with energy hub Optimal utilization of load side power and heat resources based
    on aggregator mode Equilibrium Analysis on the Main Energy and Ancillary Service
    Joint Market Considering Load Aggregators A two-stage optimal sensor placement
    method for multi-type structural response reconstruction Multi-type Adjustable
    Loads Aggregation Control Strategy for Industrial Parks Senior Aerospace Engineer
    Lawrence Livermore National Laboratory PhD & Master fellowships in Physics Vienna
    Doctoral School in Physics Scientific Managing Director (m/f/d) GSI Helmholzzentrum
    fuer Schwerionenforschung GmbH More jobs Post a job IOPSCIENCE Journals Books
    IOP Conference Series About IOPscience Contact Us Developing countries access
    IOP Publishing open access policy Accessibility IOP PUBLISHING Copyright 2024
    IOP Publishing Terms and Conditions Disclaimer Privacy and Cookie Policy PUBLISHING
    SUPPORT Authors Reviewers Conference Organisers This site uses cookies. By continuing
    to use this site you agree to our use of cookies. IOP Publishing Twitter page
    IOP Publishing Facebook page IOP Publishing LinkedIn page IOP Publishing Youtube
    page IOP Publishing WeChat QR code IOP Publishing Weibo page"'
  inline_citation: '>'
  journal: 'Journal of Physics: Conference Series'
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Research on technical scheme for multi type load resource information access
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Asri H.
  - Jarir Z.
  citation_count: '1'
  description: 'Nowadays, sensors and mobile phones remain important tools for gathering
    real-time data about human''s behaviors and context information; in order to make
    predictions and advanced preventions of outcomes and diseases. In the specific
    field of healthcare, real-time decisions are in need to save lives and to make
    people''s lives easier and healthier. In the present paper, we propose a new e-monitoring
    system for real-time miscarriage prediction that use real time risk factors of
    miscarriage prediction; which are collected from both healthcare sensors and mobile
    phones. The challenge of this study is to gather real-time risk factors to make
    predictions and to propose a model for real time decisions; instead of using only
    echography because it is often too late to save baby''s life. We used two categories
    of data: data coming from wearables (collected using IoT technologies) and data
    collected from mobile phones. A mobile phone application that we created collects
    all risk factors (every 60 s) for analysis and process. Data generated contains
    real-world data of real pregnant woman for testing and validating the proposed
    model in term of efficiency and effectiveness. Our dataset of 15 features that
    represent risk factors of miscarriage, presents an important source that can be
    used in future researches for further applications. The proposed dataset is available
    in Mendeley repository through the following link: http://dx.doi.org/10.17632/5sbmhh6t3r.1.'
  doi: 10.1016/j.procs.2022.07.114
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords References Cited by (1) Procedia Computer Science Volume
    203, 2022, Pages 763-768 Real-time miscarriage prediction: A comprehensive real-world
    dataset and a new model Author links open overlay panel Hiba Asri, Zahi Jarir
    Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.procs.2022.07.114
    Get rights and content Under a Creative Commons license open access Abstract Nowadays,
    sensors and mobile phones remain important tools for gathering real-time data
    about human''s behaviors and context information; in order to make predictions
    and advanced preventions of outcomes and diseases. In the specific field of healthcare,
    real-time decisions are in need to save lives and to make people''s lives easier
    and healthier. In the present paper, we propose a new e-monitoring system for
    real-time miscarriage prediction that use real time risk factors of miscarriage
    prediction; which are collected from both healthcare sensors and mobile phones.
    The challenge of this study is to gather real-time risk factors to make predictions
    and to propose a model for real time decisions; instead of using only echography
    because it is often too late to save baby''s life. We used two categories of data:
    data coming from wearables (collected using IoT technologies) and data collected
    from mobile phones. A mobile phone application that we created collects all risk
    factors (every 60 s) for analysis and process. Data generated contains real-world
    data of real pregnant woman for testing and validating the proposed model in term
    of efficiency and effectiveness. Our dataset of 15 features that represent risk
    factors of miscarriage, presents an important source that can be used in future
    researches for further applications. The proposed dataset is available in Mendeley
    repository through the following link: http://dx.doi.org/10.17632/5sbmhh6t3r.1.
    Previous article in issue Next article in issue Keywords Big DataMiscarriageDatasetPredictionReality
    MiningSensors View PDF References [1 PC Arck, M Rücke, M Rose, et al. Early risk
    factors for miscarriage: a prospective cohort study in pregnant women Reprod Biomed
    Online, 17 (1) (2008), pp. 101-113, 10.1016/S1472-6483(10)60300-8 View PDFView
    articleView in ScopusGoogle Scholar [2 N. Ozawa, K. Ogawa, A. Sasaki, M. Mitsui,
    S. Wada, H. Sago Maternal age, history of miscarriage, and embryonic/fetal size
    are associated with cytogenetic results of spontaneous early miscarriages Journal
    of assisted reproduction and genetics, 36 (4) (2019), pp. 749-757 CrossRefView
    in ScopusGoogle Scholar [3 A. Garcıa-Enguıdanos, M.E. Calle, J. Valero, S. Luna,
    V. Domınguez-Rojas Risk factors in miscarriage: a review European Journal of Obstetrics
    & Gynecology and Reproductive Biology, 102 (2) (2002), pp. 111-119 View PDFView
    articleView in ScopusGoogle Scholar [4 S. Feodor Nilsson, P.K. Andersen, K. Strandberg-Larsen,
    A.M. Nybo Andersen Risk factors for miscarriage from a prevention perspective:
    a nationwide follow-up study BJOG: An International Journal of Obstetrics & Gynaecology,
    121 (11) (2014), pp. 1375-1385 CrossRefView in ScopusGoogle Scholar [5 A. Oliver,
    C. Overton Diagnosis and management of miscarriage The Practitioner, 258 (2014),
    pp. 25-28 1771 View in ScopusGoogle Scholar [6 H. Asri, H. Mousannif, H. Al Moatassime
    Reality mining and predictive analytics for building smart applications Journal
    of Big Data, 6 (1) (2019), pp. 1-25 Google Scholar [7 H. Asri, H. Mousannif, H.
    Al Moatassime Real-time miscarriage prediction with SPARK Procedia computer science,
    113 (2017), pp. 423-428 View PDFView articleView in ScopusGoogle Scholar [8 H.
    Asri, H. Mousannif, H. Al Moatassime Big data analytics in healthcare: case study-miscarriage
    prediction International Journal of Distributed Systems and Technologies (IJDST),
    10 (4) (2019), pp. 45-58 CrossRefView in ScopusGoogle Scholar [9 H. Asri, H. Mousannif,
    H. Al Moatassime, T. Noel Big data in healthcare: challenges and opportunities
    2015 International Conference on Cloud Technologies and Applications (CloudTech),
    IEEE (2015, June), pp. 1-7 CrossRef [10 H. Asri IoT and Reality Mining for Real-Time
    Disease Prediction IoT and Smart Devices for Sustainable Environment, Springer,
    Cham (2022), pp. 85-102 CrossRefView in ScopusGoogle Scholar [11 H. Asri, H. Mousannif,
    H. Al Moatassime, J. Zahir Big data and reality mining in healthcare: promise
    and potential International Conference on Image and Signal Processing, Springer,
    Cham (2020, June), pp. 122-129 CrossRefView in Scopus [12 H. Asri, H. Mousannif,
    H. Al Moatassime Comprehensive miscarriage dataset for an early miscarriage prediction
    Data in brief, 19 (2018), pp. 240-243 View PDFView articleView in ScopusGoogle
    Scholar [13 JF Thayer, F Åhs, M Fredrikson, JJ Sollers, TD. Wager A meta-analysis
    of heart rate variability and neuroimaging studies: Implications for heart rate
    variability as a marker of stress and health Neurosci Biobehav Rev, 36 (2) (2012),
    pp. 747-756, 10.1016/j.neubiorev.2011.11.009 View PDFView articleView in ScopusGoogle
    Scholar [14 O Anselem, D Floret, V Tsatsaris, F Goffinet, O. Launay Influenza
    infection and pregnancy [French;English] Grippe au cours de la grossesse Press
    Medicale, 42 (11) (2013), pp. 1453-1460, 10.1016/j.lpm.2013.01.064 View PDFView
    articleView in ScopusGoogle Scholar [15 & E.Y. Wong, R. Ray, D.L. Gao, K.J. Wernli,
    W. Li, E.D. Fitzgibbons, D.B. Thomas Physical activity, physical exertion, and
    miscarriage risk in women textile workers in Shanghai, China American journal
    of industrial medicine, 53 (5) (2010), pp. 497-505 CrossRefView in ScopusGoogle
    Scholar [16 J Nizard, G Guettrot-Imbert, G Plu-Bureau, et al. Pathologies maternelles
    chroniques et pertes de grossesse. Recommandations françaises J Gynecol Obstet
    Biol la Reprod, 43 (2014), pp. 865-882, 10.1111/1471-0528.12694 View PDFView articleView
    in ScopusGoogle Scholar [17 D. Bollier, The Promise and Peril of Big data. 2010,
    pp. 1–66. Google Scholar [18 Toma C, Veleva Z, Tiitinen A, et al. High and low
    BMI increase the risk of miscarriage after IVF /ICSI and FET. 2008;23:878-884.
    Google Scholar [19 P. Women Food Safety for Pregnant Women Intern Med News, 38
    (2005), p. 79, 10.1016/S1097- 8690(05)72089-8 Google Scholar [20 Hiba Asri HIBA
    ASRI_ Miscarriage Prediction Risk Factors” Mendeley Data (2021), p. V1, 10.17632/5sbmhh6t3r.1
    Google Scholar [21 H. Asri Big Data and IoT for real-time miscarriage prediction
    A clustering comparative study Procedia Computer Science, 191 (2021), pp. 200-206
    View PDFView articleView in ScopusGoogle Scholar Cited by (1) Wearables and Sustainable
    Development: Exploring Future Implications for the Green Jobs and Green Labor
    Market 2023, Procedia Computer Science Show abstract © 2022 The Author(s). Published
    by Elsevier B.V. Part of special issue 17th International Conference on Future
    Networks and Communications / 19th International Conference on Mobile Systems
    and Pervasive Computing / 12th International Conference on Sustainable Energy
    Information Technology (FNC/MobiSPC/SEIT 2022), August 9-11, 2022, Niagara Falls,
    Ontario, Canada Edited by Elhadi Shakshuki Download full issue Other articles
    from this issue Paving the Way Towards Collective Intelligence at the IoT Edge
    2022 Nawaz Mohamudally View PDF Automated Machine Learning based Elderly Fall
    Detection Classification 2022 Firdous Kausar, …, Taif AlBadi View PDF Predicting
    The Throughput Of Next Generation IEEE 802.11 WLANs In Dense Deployments 2022
    Rajasekar Mohan, …, Manikandan J View PDF View more articles Recommended articles
    Article Metrics Citations Citation Indexes: 1 Captures Readers: 11 View details
    About ScienceDirect Remote access Shopping cart Advertise Contact and support
    Terms and conditions Privacy policy Cookies are used by this site. Cookie settings
    | Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Procedia Computer Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'Real-time miscarriage prediction: A comprehensive real-world dataset and
    a new model'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Vornicu F.D.
  - Ungureanu F.
  citation_count: '0'
  description: This paper presents the design and implementation of an online tool
    which gives users an easy way to access all of the programmable devices in a laboratory,
    as they are connected in the same spot, together with data acquisition modules.
    This tool focuses on inter-connectivity, automation, and real-time data acquisition
    and for the moment it is running in a private network. The LabVIEW Application
    Server, the web services developed for the involved devices and the web application
    developed using LabVIEW NXG 5.1 are the main modules of this control and measurement
    tool. The web application communicates with the devices directly through HTTP
    Methods provided by the web services. Both the web services and the web application
    are wrapped into an installer which makes them easily accessible on any machine.
  doi: 10.1109/ICCC54292.2022.9805940
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 23rd International Carpa... TestBench
    Configurator - A Tool for Control and Measurements via Online Interface Publisher:
    IEEE Cite This PDF Floris-Diana Vornicu; Florina Ungureanu All Authors 35 Full
    Text Views Abstract Document Sections I. INTRODUCTION II. System Architecture
    III. VISA Sessions IV. Web Services V. Web Application and User Interface Show
    Full Outline Authors Figures References Keywords Metrics Abstract: This paper
    presents the design and implementation of an online tool which gives users an
    easy way to access all of the programmable devices in a laboratory, as they are
    connected in the same spot, together with data acquisition modules. This tool
    focuses on inter-connectivity, automation, and real-time data acquisition and
    for the moment it is running in a private network. The LabVIEW Application Server,
    the web services developed for the involved devices and the web application developed
    using LabVIEW NXG 5.1 are the main modules of this control and measurement tool.
    The web application communicates with the devices directly through HTTP Methods
    provided by the web services. Both the web services and the web application are
    wrapped into an installer which makes them easily accessible on any machine. Published
    in: 2022 23rd International Carpathian Control Conference (ICCC) Date of Conference:
    29 May 2022 - 01 June 2022 Date Added to IEEE Xplore: 27 June 2022 ISBN Information:
    DOI: 10.1109/ICCC54292.2022.9805940 Publisher: IEEE Conference Location: Sinaia,
    Romania SECTION I. INTRODUCTION In the last decade, the Industry 4.0 and Industrial
    Internet of Things concepts have brought to the forefront the holistic approach
    of industrial manufacturing by connecting physical production and related operations
    with digital technology and access to real-time insights across products, different
    devices and events. For example, the Competence Centre Automation from Dusseldorf
    developed Flex-IOT platform which succeeded to implement remote labs in the light
    of Industry 4.0 [1]. The engineers develop different types of tools, software
    or hardware-based, aiming to streamline their work and business. Regardless of
    the nature of these tools, it is certain that their development takes time and
    risks. Creating a brand new product involves lots of testing, to make sure that
    everything works according to standards, keeping everyone involved safe. This
    context has led to bringing together all of the devices needed for testing and
    measuring into one simple interface in a web application. Most applications that
    addressed this topic were primarily aimed at implementing virtual labs for education
    and were mainly developed based on equipment and software environments provided
    by National Instruments [2] [3] [4] [5]. Naturally, similar technical approaches
    have been adopted in industry and research centers [6] [7]. The TestBench Configurator
    tool presented in this paper arose out of practical necessity from a testing laboratory.
    Having to develop safe products that require usage of high voltage units (e.g.
    800V at 45kW) involves building a safe environment for testing and validation.
    In a laboratory with multiple devices that work at the same time, from different
    spots, it would be much more easier and safer to put them all together and easily
    keep track of the measurements and behaviour. Not having to touch the buttons
    of multiple high voltage (HV) devices reduces the risk of being injured as one
    can access them from far away keeping a safe distance. LabVIEW SP1 2020 Base Development
    [8] offers multiple facilities for data transfer; one stable way of bringing together
    all of information for every programmable device in the laboratory: building dedicated
    web services that serve as online resources. A web service that is especially
    build for a device includes build-in drivers (a.k.a virtual instruments) that
    can perform measurements (read like interrogations) or send instructions, both
    through VISA (Virtual Instrument Software Architecture) Sessions. Each device
    connected to the machine that runs the server is seen as a standalone resource,
    therefore each of them has an unique connection string, making sure that connections
    are independent, not interfering with one another. Given the fact that a laboratory
    may have multiple identical devices each of the web service open independent sessions
    that use the unique connection string. The actions performed by the web services
    depend on the received HTTP Request. HTTP requests are sent from the web application,
    as HTTP GET or POST methods. The data between the web services and the web application
    flows in the form of JSON (JavaScript Object Notation) Objects of variant forms,
    depending on the web service, the HTTP method or the information required from
    the web service. The use of the JSON objects facilitates the data transfer, as
    it is a standardized format. Separating the functionalities into web services
    helps future development and additions of new devices. As an effect of this matter,
    whenever a new type of device is needed, two actions are required: building and
    deploying a new web service and creating a new interfaces in the web application.
    Inside the same laboratory several testing and validation environments can be
    build, requiring different setups. In order to be able to separate those environments,
    the TestBench Configurator separates the setups in different Test Stands, two
    at the moment. Through this separation, users can not use the same devices at
    the same time, but they can still change the configuration (e.g. moving a device
    from a test stand to another as long as there is no other user using that device).
    In order to monitor and track the changes inside the laboratory’s configurations
    there are web services especially serving those needs. They provide logging and
    measurements/commands history for any type of the available devices. Thereby,
    they help observing potential problems as well. The last but not the least layer
    of this project is the user interface (UI) provided by the web application. It
    contains multiple indicators and control buttons trying to reproduce the physical
    interface of the current device. The web application is built using LabVIEW NXG
    5.1 which provides an easy way to build an interface by just dragging and dropping
    various graphic elements. The demo installer, containing the web services and
    web application, is currently deployed on a c-DAQ controller form National Instruments
    with Windows 7 Embedded (x32 bit) in a company’s laboratory in Iasi, Romania.
    SECTION II. System Architecture Fig. 1. System architecture Show All Any newly
    developed idea requires an architecture, a logical organization and placement
    of the components involved: hardware devices (electronic loads, power supplies
    etc.), stand-alone web services to serve as resources and management of users
    and configurations, a web application that bring everything together in one simple
    interface, a web server to host the web services and the web application as shown
    in Fig 1. The devices and the web server (that will host the application and the
    web services) have to be connected to the same machine running an operating system.
    The installer includes all of the software tools required, therefore the only
    actions to be performed before getting started is to run the installer and connect
    the devices according to the configuration (via USB, GPIB, ETHERNET etc.). LabVIEW
    offers the possibility to create an installer that will run the web services onto
    the NI Application Server on a specified port, or on the NI Web Server which is
    similar to the previous one; they start a server onto the current machine, hosting
    inside your local network. The architecture that seemed to fit best into the context
    of using the LabVIEW software facilities was a combination of a layered and service
    oriented architecture, resulting into a graphic representation as the one depicted
    in Fig. 2. The path between web application and a hardware device is represented
    by a web service (through HTTP Methods). Data will flow further inside the web
    application making its way to the human user using the UI online page. SECTION
    III. VISA Sessions VISA Sessions are the base mean of communication to a VISA
    Resource. A VISA Resource is any instrument/device inside your system. Through
    a session there is a communication channel opened to parse messages between the
    program and the device [9] [10]. These messages represent commands from a program
    and responses from the device, based on the nature of the command. For example,
    reading commands such as the classic \" *IDN? \" will trigger the device to respond
    with a string containing \" [ Manufacturer ], [ Model ], [ Serial Number ], [
    Firmware Level ], [ Options ] \". Different programmable devices have their own
    special commands, so that using the same commands on all the device will cause
    errors. Withal, there is a set of commands that are common to every programmable
    device but they to do not provide proper information such as voltage, on/off status
    etc. Behind every HTTP Method on every LabVIEW-built web service there is a *.vi
    file that bases all of its interaction with a certain type of device on VISA Sessions.
    Each of them opens a session, has an exchange of messages and closes that sessions
    safely. It is very important to not let the program overlap VISA Sessions or errors
    will occur. Fig. 2. Layered and service oriented architecture Show All SECTION
    IV. Web Services The functionalities of LabVIEW 2020 SP1 provides an easy way
    to create web resources as web services. Web services added to a project can be
    deployed using an *.exe file that gives the developer the possibility to choose
    the NI Server type: NI Application Server (with a given port number such as 8001
    or 8002 etc.) or NI Web Server. Between the two of them, NI Web Server is the
    new way to host web services and web applications. For the web applications it
    is enough to build the app using LabVIEW NXG and copy-paste the build directory
    inside the directory of the NI Web Server [11] . It will automatically make the
    application available at a URI of the developers’ choice, as NI Web Server can
    be configured to have a custom domain name (e.g. http://168.192.0.1/WebApplication/index.html).
    Each of the two were tested and were proved to work, as long as the web application
    is located on the same server as the web services therefore no CORS (C.O.R.S -
    Cross Origin Resource Sharing) policy will appear. In order to keep the web services
    and web application as independent as possible there is a set of services that
    are used inside the project, each of them will be detailed in the next subsections.
    A. Config Web Service The \"config\" web service serves as a manager for the current
    configuration of a test stand. The configuration is stored in *.txt files on the
    server as a series of JSON Objects containing the \"Id\" of the test stand (currently
    there are 2 test stands), the \"User\" that is currently using the test stand
    and \"Locked\" parameter that marks the fact that there is already another user
    using the devices configured on the current test stand. Methods available: \"/config/\"
    (GET) returns the current configuration of the test stands, a list of 2 JSON Objects
    as described above; \"/config/updateConfig\" (POST) lock/unlocks a certain test
    stand according to a users activity; B. Devices Web Service This web service is
    dedicated to devices management. As it was previously mentioned, testing and validating
    a product involves multiple devices at the same time. In order to facilitate the
    access to the device that a user needs, the concept of a \"Virtual Test Stand\"
    is suitable. It simulates stacking the required devices on one another, making
    it easy to follow measurements and changing test parameters. For the flexibility
    of the test stand, the devices web service keeps tracks of all the devices and
    how they are used/split into test stands. The devices list is also stored in a
    *.txt file on the server, as a list of JSON Objects each of them having the following
    keys: \"Id\" (unique for each devices), \"Taken\" (marks the test stand that uses
    the device), \"Manufacturer\" (each manufacturer has a unique id that is used
    inside the connection string for USB VISA Sessions), \"Model\" (the device’s model/category),
    \"Connection Type\" (helps building the connection string, as they have different
    formats based on the communication), \"Serial No.\" (serial number of the device),
    \"Custom\" (USB-connected devices include a pair of \"manufacturerId::modelId\",
    for TCP-connected devices the format is \"IPAddress::portNumber::SOCKET\". Methods
    available: \"/devices/all\" (GET) returns the list of devices as described above;
    \"/devices/byConnectionType?Connection={value}\" (GET) returns the list of devices
    based on the \"Connection Type\"; \"/devices/byTS?TS={value}\" (GET) returns the
    list of de-vices based on the test stand they currently belong to; \"/devices/connections\"
    (GET) returns all types of connections available (e.g. USB, TCPIP); \"/devices/models\"
    (GET) return all models available (e.g. IT6532, DP832); \"/devices/update\" (POST)
    given a JSON Object with an \"Id\", \"Field\" and \"Value\" will change the value
    of the field for the selected device; The other services are dedicated to measurements
    and control for each manufacturer. Behind every HTTP Method there is a virtual
    instrument that processes the request. When it comes to measurements and control,
    VISA Sessions are the main characters. As described in the VISA Sessions section,
    handling these sessions requires special attention as they can block the device
    if used incorrectly, therefore each one is treated with care. Requests are handled
    using a state machine depending on the parameters of the request and the nature
    of the action that is required (reading measurements or performing a command).
    The \"Rigol Web Service\" and \"InteproSystems Web Service\" are similar to \"Itech
    Web Service\" therefore only the last one will be detailed. Itech Web Service
    is dedicated to devices from Itech, featuring power supplies and electronic loads.
    Methods available: \"/itech/IT6500?Action={value}&Resource={value} (POST) based
    on the \"Action\" parameter the resource will perform either a set of measurements
    (for Action=’READ’ or Action=\"ReadwLoad\" for when the IT6500 device has both
    functionalities: electronic load and power supply) or a certain command (for Action=\"WRITE\"
    e.g.\"VOLT 4.3\"); \"/itech/IT8800\"Action={value}&Resource={value} (POST) similar
    to the one above, it returns either measurements either success of a given command;
    SECTION V. Web Application and User Interface The Web Application was build using
    LabVIEW NXG 5.1, a powerful software module that brings together third-party code
    and functionality, making it easy to customize and configure the applications.
    In this case, it offers support for building web application that calls for LabVIEW
    developed web services and generate HTML and JavaScript code that makes it easily
    deploy-able just by copy-pasting the build directory on the desired server. The
    web application itself is not complicated, being found in a limited number of
    states as it follows: logging in, choosing a test stand, editing a test stand,
    changing the test stand, logging out. In order to keep the functionality in one
    piece a tab control was used, according to the state the application finds itself
    into. Fig. 3. Choosing a test stand Show All It can serve an unknown number of
    users, but giving the fact that only two test stands are available, only two users
    are recommended (Fig. 3). A user will provide a username and a common password
    in order to access the application. As it is deployed into the company’s intranet,
    the security of the web application was not required. Once the user logs in, he
    can access a test stand to use, if this is available (in case another user is
    already using a certain test stand, it instantly becomes unavailable to other
    users). Once the test stand is chosen, it will display a stack of HTML frames
    containing devices’ interfaces according to the existing configuration of for
    the selected test stand, as it is presented in Fig. 4. The user can edit the configuration
    in real time being able to change the devices if others are available (not in
    use): any device from the full devices list can be selected if it is not currently
    in use (Fig. 5). Once the configurations are over, the user can perform measurement
    and commands with the needed device as long as this is correctly connected to
    the chassis that runs the server on which the web services and web application
    are hosted on. If any of the device is not connecting according to the configuration
    (e.g. it is connected via Ethernet but it is configured as using an USB connection)
    its interface will grey-out not letting the user to use it until it is properly
    configured/connected. Furthermore, for high voltage instruments the specified
    interface will turn red and ask for additional confirmation on potentially dangerous
    commands (e.g. VOLT 700). SECTION VI. Conclusion and Future Works In this paper,
    the design and implementation of an online tool for control and measurement in
    an industrial testing laboratory in Iasi is presented. The LabVIEW ability to
    create installers makes it easily portable on any laptop, personal computer or
    controller running a minimum Windows 7 Embedded with access to the Internet. At
    the moment, the project is stable, in use, the connections do not mix and the
    users are becoming more familiar with it. As further developments, the authors
    will be concerned with the extended testing and functionality. An idea for this
    feature implies exploring the facilities that System Link from Nation Instruments
    brings as it is also a solution for bringing live data into a common online interface.
    As LabVIEW supports building web resources that can communicate with the hardware,
    future work will focus on including those functionalities and bringing the possibility
    to configure data acquisition channels and signal processing. Fig. 4. The stack
    of currently configured devices Show All Fig. 5. Changing the current configuration
    of a test stand Show All Authors Figures References Keywords Metrics More Like
    This Demand bound server: Generalized resource reservation for hard real-time
    systems 2011 Proceedings of the Ninth ACM International Conference on Embedded
    Software (EMSOFT) Published: 2011 Exploiting Aperiodic Server to Improve Aperiodic
    Responsiveness for LET-Based Real-Time Systems 2017 IEEE International Symposium
    on Parallel and Distributed Processing with Applications and 2017 IEEE International
    Conference on Ubiquitous Computing and Communications (ISPA/IUCC) Published: 2017
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: 2022 23rd International Carpathian Control Conference, ICCC 2022
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: TestBench Configurator-A Tool for Control and Measurements via Online Interface
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Ech-Chkaf A.
  - Oussous S.A.
  - El Allali A.
  - Beloualid S.
  - El Harrouti T.
  - El Aidi S.
  - Bajit A.
  - Chaoui H.
  - Tamtoui A.
  citation_count: '1'
  description: The smart city is a new urban development idea whose purpose is to
    improve people’s quality of life while also protecting the environment by utilizing
    new technologies that rely on an ecosystem of objects and services to make cities
    more adaptable and efficient. And the Internet of Things (IoT) is at the heart
    of practically all smart city gadgets and solutions. Data cannot be collected
    and presented in the different ways required by the city without it. It allows
    smart city sensors to regulate lighting, water and waste management, sound and
    air quality sensors, parking management, etc. Real-time data from buildings, streets,
    and infrastructure can now be actionable and valuable to all parties involved
    due to the IoT. In our work, we developed an intelligent and secure IoT Smart
    energy platform to monitor and control energy use in various parts of a smart
    city, utilizing the CoAP communication protocol to transport data from smart meters
    to a web server. We also used different topologies such as STAR, TREE, MESH, and
    CLUSTER to optimize the performance of our platform in terms of execution time
    and memory consumption, and we evaluated the impact of the ECIES security protocol
    compared to other security protocols such as AES-SHA256, RSA, and EEECC.
  doi: 10.1007/978-3-030-98741-1_41
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Log in Find a journal
    Publish with us Track your research Search Cart International Conference of Reliable
    Information and Communication Technology IRICT 2021: Advances on Intelligent Informatics
    and Computing pp 498–511Cite as Home Advances on Intelligent Informatics and Computing
    Conference paper Applying an Enhanced Elliptic Curve Integrated Encryption Scheme
    ECIES to Enhance Smart Energy IoT Platform Security Based on Constrained Protocol
    Ayoub Ech-Chkaf, Salma Ait Oussous, Abdelhadi El Allali, Siham Beloualid, Taoufiq
    El Harrouti, Sanaa El Aidi, Abderrahim Bajit, Habiba Chaoui & Ahmed Tamtoui  Conference
    paper First Online: 30 March 2022 873 Accesses 1 Citations Part of the book series:
    Lecture Notes on Data Engineering and Communications Technologies ((LNDECT,volume
    127)) Abstract The smart city is a new urban development idea whose purpose is
    to improve people’s quality of life while also protecting the environment by utilizing
    new technologies that rely on an ecosystem of objects and services to make cities
    more adaptable and efficient. And the Internet of Things (IoT) is at the heart
    of practically all smart city gadgets and solutions. Data cannot be collected
    and presented in the different ways required by the city without it. It allows
    smart city sensors to regulate lighting, water and waste management, sound and
    air quality sensors, parking management, etc. Real-time data from buildings, streets,
    and infrastructure can now be actionable and valuable to all parties involved
    due to the IoT. In our work, we developed an intelligent and secure IoT Smart
    energy platform to monitor and control energy use in various parts of a smart
    city, utilizing the CoAP communication protocol to transport data from smart meters
    to a web server. We also used different topologies such as STAR, TREE, MESH, and
    CLUSTER to optimize the performance of our platform in terms of execution time
    and memory consumption, and we evaluated the impact of the ECIES security protocol
    compared to other security protocols such as AES-SHA256, RSA, and EEECC. Keywords
    IoT Smart energy platform CoAP IoT protocol STAR TREE MESH CLUSTER topologies
    AES-SHA256 RSA-SHA256 EEECC ECIES security protocols Access provided by University
    of Nebraska-Lincoln. Download conference paper PDF 1 Introduction Smart city initiatives
    around the world are being enabled by new IoT applications. It enables remote
    monitoring, management, and control of devices, as well as the extraction of fresh
    insights and actionable data from huge quantities of real-time data. A high degree
    of information technology integration and a broad application of information resources
    are two of the most important characteristics of a smart city. Moreover, smart
    technology, smart industry, smart services, smart management, and smart grid are
    all vital components of urban growth for a smart city [1]. IoT has an important
    role which is presented in sensor’s installation, then connect them to the internet
    via a protocol for transmitting data and enabling the communication, to generate
    a huge amount of data to be collected, transferred and examined to distribute
    results, and to obtain for example intelligent recognition, monitoring, and managing
    the energy production and consumption in a changing area. With the help of IoT,
    Smart cities must have three characteristics: they must be instrumented, networked,
    and smart. Then, at this advanced degree of IoT development, Smart City can be
    constructed by combining all of these intelligent components. The rapid expansion
    of it and IoT applications has created science and engineering issues that necessitate
    creative research from academia and business, particularly for the development
    of efficient, flexible, and dependable Smart Cities based on IoT [2]. A smart
    grid component is a modern electrical grid that employs analog or digital data
    and communication technology to make the most efficient use of widely available
    energy resources [3]. Renewable energy is an important topic in the study because
    of its wide availability, usability, and environmental responsibility, and the
    use of the smart grid in renewable energy expands its potential. This combination
    helps in the proper use of renewable sources, which is a big issue [4]. The present
    work attempts to develop an IoT smart energy platform to monitor and control the
    energy consumption of any area in a city while using the sustainability factor
    as a goal to ensure a green living lifestyle using the CoAP protocol, which is
    a customized web transfer protocol designed for IoT devices with limited resources,
    and it’s made for M2M applications like smart energy [5, 6]. Then, we studied
    the impact of the ECIES security algorithm in our platform, by applying a set
    of topologies STAR, TREE, MESH, and CLUSTER to choose the appropriate topology
    for each zone in terms of memory consumption and execution time. Star topology
    is composed of a single network coordinator and one or more terminal devices that
    only interact with the coordinator, and it establishes centralized management
    for network operations and makes it simple to add a new node [7]. A Tree is based
    on a child-parent relationship, where the coordinator is connected to routers
    that can also be connected to others or leaf nodes [8]. Mesh is different, it
    has no hierarchical relationship, the communication is more flexible, and it is
    characterized by its increased reliability as more alternate pathways become accessible
    [9]. The Cluster is the most complex since it is a combination of the other topologies,
    then it can handle a large volume of traffic. In addition, it also has a hierarchy
    of child parents like a tree [10]. 2 Smart Grid IoT Platform and Aims The objective
    of our work is to develop an intelligent and secure smart grid IoT platform for
    a smart city in real-time, which is used to collect, analyze and control the energy
    consumption in each area in the smart city such as tourist area, industrial area,
    commercial area, etc. As shown in Fig. 1, we used IoT smart meter nodes for each
    zone to measure the amount of energy consumed over a specified period, and then,
    we send data to the CoAP server via routers. The CoAP server sends the data to
    the webserver for modeling and analysis. This analysis provides an overview of
    our city’s energy consumption and allows us to discover which areas are consuming
    more energy and the reason, to improve the consumption in the different areas
    of the city, as well as to choose the topology that suits it. To accomplish this
    task, we employed four distinct topologies, in which the IoT smart meter nodes
    are connected directly to the coordinator, or each End device is connected to
    the coordinator via routers that operate as an intermediary. And to guarantee
    the security of the data that circulates, we have added the ECIES security layer.
    Fig. 1. IoT smart grid platform architecture based on CoAP protocol. Full size
    image 3 Methodology To model and improve effective energy management by adopting
    environmental resources to control and power modern life devices in smart cities
    and contribute to better air quality and lower environmental nuisance, we used
    an IoT platform model interested in handling resource analysis and optimization
    needs by collecting stable and accurate information. And to avoid any kind of
    data loss, this data must be secured. Data security has become an important topic.
    The majority of the data we use is insecure. As a result, we must search for solutions
    to secure them. And cryptography is one of several methods for securing information
    [11]. Elliptic Curve Cryptography (ECC) is a type of cryptography that can be
    used to encrypt data, create digital signatures, and manage key exchanges. ECC
    cryptography is considered the most suitable current successor to the Cryptosystem
    since it employs shorter keys and signatures for the same degree of security as
    RSA and allows for extremely quick key generation, key agreement, and signatures
    [12]. Moreover, it offers a range of approaches that rely on the mathematics of
    elliptic curves over finite fields, including ECC encryption algorithms and hybrid
    encryption schemes such as the ECIES Elliptic Curve Integrated Encryption Scheme,
    integrated and EEECC Energy-efficient Elliptic Curve cryptography, to ensure that
    authentication and key distribution issues are solved [13]. The present algorithms
    are known as hybrid cryptosystems since they combine symmetric and asymmetric
    techniques. The ECIES is the most well of the hybrid cryptosystems based on ECC,
    it may be found in various cryptographic standards as a result [14]. It is a public
    key encryption system that is based on the ElGamal encryption algorithm and is
    developed for Elliptic curve groups. It is ANSI X9.63 and ISO/IEC 15946-3 standardized,
    as well as IEEE P1363a. In addition, adaptively selected plaintext and chosen-ciphertext
    attacks are protected by this method. It combines encryption, key exchange, and
    digital signature capabilities. Because it is a hybrid scheme that uses a public
    key system to transmit a session key for use by a symmetric cryptosystem, it is
    dubbed Integrated Encryption Scheme [15]. The ECIES standard mixes ECC-based asymmetric
    cryptography with symmetric ciphers to offer data encryption and decryption using
    an EC private key and an EC public key. It employs ECC cryptography (public key
    cryptosystem) in conjunction with a key-derivation function, symmetric encryption,
    and the MAC algorithm. For decryption, the ECIES produces the original plaintext
    message by combining the output of the encryption with the recipient’s private
    key [16]. Finally, our work is based on this security algorithm to ensure authentication,
    confidentiality, and availability of data in good condition. 4 Related Works The
    authors provide secure and lightweight authentication algorithms for IoT devices
    based on this notion [16]. The devices in the perception layer are mutually authenticated
    with the system''s gateway, in a centralized network paradigm. A mutual authentication
    approach that employs symmetric key negotiation with Elliptic Curve Diffie-Hellman
    (ECDH) in the registration part of the protocol to preserve device credentials
    while minimizing device calculation costs. After the authentication, the sensor
    devices and the gateway form a key agreement based on symmetric-key cryptography.
    Furthermore, in the registration step of the preceding protocol, the Elliptic
    Curve Integrated Encryption Scheme (ECIES) approach is employed to avoid the risk
    of a man-in-the-middle attack (MITM). The protocols are subjected to an informal
    security verification, which shows that they are resistant to perception layer
    assaults. After the protocol has been simulated in the Cooja simulator under the
    Contiki OS environment, the performance of the protocol has been evaluated using
    metrics such as execution time, communication cost, and calculation cost. Furthermore,
    as compared to existing protocols, the suggested system is lightweight since it
    has a cheap calculation cost and a faster execution time. Second, the authors
    give a survey of ECC in the context of lightweight cryptography in their article
    [17]. The goal of this work is to establish the parameters that make an ECC-based
    system lightweight and useful in limited situations. The key factors examined
    in ECC designs for lightweight realizations are systematically reviewed in representative
    works. As a result, this work establishes the concept and specifications for elliptic
    curve lightweight cryptography for the first time. Based on those works, and from
    the previous work [18], which we created a smart grid platform for a smart city
    that aims to monitor and analyze energy consumption, using smart meter IoT nodes
    for each area. First, from the comparison performed on the data sent by the IoT
    nodes in terms of execution time and memory occupancy using the CoAP and MQTT
    protocols, we concluded that the CoAP protocol is better than the other one because
    it uses a small packet size, it consumes less memory and it takes less time to
    execute. Then, we studied the impact of the topologies in terms of execution time
    and memory consumption, with and without security. The test is done on the following
    security protocols RSA-SHA256 and ECC, and we focused our study on the impact
    of the ECC to compare it with RSA. From this study, we found that ECC is better
    than RSA since it offers high data security, as well as it is fast, efficient,
    and consumes little memory thanks to its small size keys. The present work is
    a continuity of the previous work, we aim to achieve the same objectives as the
    previous, but this time we will focus our study on the impact of another security
    algorithm that ECC uses which is ECIES that must be compared with AES-SHA256 and
    EEECC to choose the best one using multi topologies. 5 The Proposed Approach Our
    approach is focused on developing an IoT smart grid platform for a smart city,
    which collects, analyzes, and manages energy usage in each zone. To fix that,
    we employed IoT smart meters to quantify the quantity of energy spent in each
    zone; using the CoAP protocol. Moreover, it is based on different parts, where
    each zone uses one or more topologies. The use of these topologies is based on
    several criteria like surface, smart meter’s number, and the distance between
    smart meters, routers, and coordinators. For securing our data circulates between
    them, we added the ECIES algorithm. We choose to work with the CoAP protocol because
    it is asynchronous takes little time to execute and consumes less memory compared
    to MQTT according to these works [19, 20]. However, ECC is considered the most
    modern and secure protocol, it is a combination of the EEECC algorithm and the
    ECIES algorithm. And since it generates keys and computes message signatures faster
    than the RSA algorithm, additionally, it is capable to provide the same level
    of security as RSA. We decided to study the impact of the ECIES algorithm to approve
    that it is the best in terms of memory consumption and execution time, by doing
    tests. Then we compared it with AES-SHA256 which is a security protocol faster
    in processing with high performance, low resource and memory requirements, as
    well as the possibility of encrypting and decrypting a large amount of data quickly
    compared to RSA [21], because it uses symmetric encryption with a smaller key
    size in which the sender and receiver of a communication share a single common
    key to encrypt and transmit the information. 6 Discussion and Results To achieve
    the goal of our work, we made many tests for studying the performance of our platform
    in terms of execution time and memory consumption using different topologies Start,
    Tree, Mesh, and Cluster, with and without security layers. In this section, we
    will discuss the results obtained to choose the best security layer. So, we focused
    to work with four versions of security: secured with RSA-SHA256, AES-SHA256, EEECC,
    and ECIES, using the CoAP protocol. Firstly, Fig. 2 shows the results of all versions
    of the security layer mentioned before in terms of execution time by each type
    of topology. According to these results, we observed that the ECIES algorithm
    takes little time to execute which is the opposite of EEECC and RSA-SHA256. For
    AES-SHA256, we can say that it is almost the same as ECIES. Secondly, Fig. 3 shows
    the results of all versions of the security layer in terms of memory consumption
    by topologies. From these results, we found that RSA- SHA256 consumes a lot of
    memory compared to ECIES. Moreover, ECIES consumes also more memory compared to
    EEECC and AES-SHA256. Thirdly, Fig. 4 shows the average execution time and the
    average memory consumption for each topology by different versions of security.
    From these tests, we found that EEECC takes a lot of time to execute compared
    to the others, and ECIES is the least time-consuming. However, for the average
    memory consumption by topology and security layer, we found that RSA consumes
    more, then ECIES, AES-SHA256, and EEECC is the less consuming. Additionally, Table
    1 shows the average execution time according to the type of topology and security
    version, where we found that ECIES takes less time, On the other hand, RSA-SHA256
    and EEECC take more time to execute. However, Table 2 represents the average memory
    consumption by topology and security, we found that RSA-SHA256 consumes a lot
    of memory than the others. Fourthly, Table 3 represents the gain of execution
    time by topology and security layer, and Table 4 shows the memory consumption
    gain by topology and security layer, we found that ECIES saves time compared to
    RSA-SHA256, AES-SHA256, and EEECC, on the other hand at the level of memory consumption,
    we found that ECIES saves memory compared to RSA-SHA256 but it causes a loss of
    memory compared to AES-SHA256. From all these results, we can deduce that ECIES
    is the suitable security algorithm for our platform. Since RSA-SHA256 takes time
    to execute and consumes a lot of memory, it causes us a great loss. Moreover,
    ECIES takes more time compared to RSA-SHA256, which also causes a loss, even if
    it consumes less memory. As for AES-SHA256, since it is symmetric, it can cause
    problems in managing several keys when we have a lot of keys, as well as being
    vulnerable to attacks. From this, we can conclude that ECIES is the best security
    algorithm because it is more efficient and has a higher security level. Fig. 2.
    Execution time with and without security by topologies. Full size image Fig. 3.
    Memory consumption with and without security by topologies. Full size image Fig.
    4. Average Execution time and memory consumption with and without security by
    topology. Full size image Table 1. Average time execution for the IoT smart grid
    platform. Full size table Table 2. Average memory consumption for the IoT smart
    grid platform. Full size table Table 3. The gain of the execution time of ECIES
    compared to AES, RSA, and EEECC by topology. Full size table Table 4. The gain
    of memory consumption of ECIES compared to AES, RSA and EEECC by topology. Full
    size table 7 Conclusion and Perspectives In this work, we created a smart grid
    platform for a smart city that aims to monitor and analyze energy consumption,
    using smart meter nodes for each zone. This work is done with the CoAP protocol
    to study the impact of topologies and different types of security on the functioning
    of our platform because the goal was to apply an enhanced Elliptic Curve Integrated
    Encryption Scheme ECIES to enhance Smart Energy in IoT Platform. So, the results
    show that ECIES is the most suitable. In the next work, we will improve this platform
    by working on the optimization of the costs of transmission of electrical energy,
    in order to propose a model that reduces costs and greenhouse gas emissions. And
    we will apply the Zigbee protocol to compare it with CoAP, as well as we will
    integrate the Blockchain. References Serban, A.C., Lytras, M.D.: Artificial intelligence
    for smart renewable energy sector in Europe smart energy infrastructures for next
    generation smart cities. IEEE Access 8, 77364–77377 (2020). https://doi.org/10.1109/AC-CESS.2020.2990123
    Article   Google Scholar   Mohammed, T.-H.: Smart city and IoT. Futur. Gener.
    Comput. Syst. 76, 159–162 (2017). https://doi.org/10.1016/j.future.2017.03.034
    Article   Google Scholar   Vineetha, C.P., Babu, C.A.: Smart grid challenges,
    issues and solutions. In: 2014 International Conference on Intelligent Green Building
    and Smart Grid (IGBSG), pp. 1–4 (2014). https://doi.org/10.1109/IGBSG.2014.6835208
    Sharma, H., Kaur, G.: Optimization and simulation of smart grid distributed generation:
    a case study of university campus. In: 2016 IEEE Smart Energy Grid Engineering
    (SEGE), pp. 153–157 (2016). https://doi.org/10.1109/SEGE.2016.7589517 Bellavista,
    P., Zanni, A.: Towards better scalability for IoT-cloud interactions via combined
    exploitation of MQTT and CoAP. In: 2016 IEEE 2nd International Forum on Research
    and Technologies for Society and Industry Leveraging a better tomorrow (RTSI),
    pp. 1–6 (2016). https://doi.org/10.1109/RTSI.2016.7740614 Kayal, P., Perros, H.:
    A comparison of IoT application layer protocols through a smart parking implementation.
    In: 2017 20th Conference on Innovations in Clouds, Internet and Networks (ICIN),
    Paris, pp. 331–336 (2017). https://doi.org/10.1109/ICIN.2017.7899436 Pramono,
    S., Putri, A.O., Warsito, E., Basuki, S.B.: Comparative analysis of star topology
    and multihop topology outdoor propagation based on Quality of Service (QoS) of
    wireless sensor network (WSN). In: 2017 IEEE International Conference on Communication,
    Networks, and Satellite (Comnetsat), pp. 152–157 (2017). https://doi.org/10.1109/COMNETSAT.2017.8263591
    Celtek, S.A., Durdu, A., Kurnaz, E.: Design and simulation of the hierarchical
    tree topology based wireless drone networks. In: 2018 International Conference
    on Artificial Intelligence and Data Processing (IDAP), pp. 1–5 (2018). https://doi.org/10.1109/IDAP.2018.8620755
    Yu, L., Kin-Fai, T., Xiangdong, Q., Ying, L., Xuyang, D.: Wireless Mesh Networks
    in IoT networks. In: 2017 International Workshop on Electromagnetics: Applications
    and Student Innovation Competition, pp. 183–185 (2017). https://doi.org/10.1109/iWEM.2017.7968828
    Ouadou, M., Zytoune, O., Aboutajdine, D., ElHillali, Y., Menhaj-Rivenq, A.: Improved
    Cluster-tree topology adapted for indoor environment in Zigbee Sensor Network.
    Procedia Comput. Sci. 94, 272–279 (2016). https://doi.org/10.1016/j.procs.2016.08.041
    Article   Google Scholar   Di Matteo, S., Baldanzi, L., Crocetti, L., Nannipieri,
    P., Fanucci, L., Saponara, S.: Secure elliptic curve crypto-processor for real-time
    IoT applications. Energies 14(15), 4676 (2021). https://doi.org/10.3390/en14154676
    Article   Google Scholar   Sadkhan, S.B.: Elliptic curve cryptography- status,
    challenges, and future trends. In: 2021 7th International Engineering Conference
    “Research & Innovation amid Global Pandemic” (IEC), pp. 167–171 (2021). https://doi.org/10.1109/IEC52205.2021.9476090
    Salim, A., Abbas, A., Abdul, B.M.: Data security for cloud computing based on
    elliptic curve integrated encryption scheme (ECIES) and modified identity-based
    cryptography (MIBC). In: International Journal of Applied Information Systems
    (IJAIS) – ISSN: 2249-0868 Foundation of Computer Science FCS, New York, USA, vol.
    10, no.6 (Mar 2016). www.ijais.org Vinchoo, M.M., Kadam, S.S., Shaikh, I.A., Vora,
    D., Nayak, D.: Grey Immune: Security in hybrid cloud. In: 2017 International Conference
    on Intelligent Sustainable Systems (ICISS), pp. 492–495 (2017). https://doi.org/10.1109/ISS1.2017.8389460
    Milen, S., Marina, S.: Practical book cryptography for developers. https://cryptobook.nakov.com/
    Oh, J., Yu, S., Lee, J., Son, S., Kim, M., Park, Y.: A secure and lightweight
    authentication protocol for IoT-based smart homes. Sensors 21, 1488 (2021). https://doi.org/10.3390/s21041488
    Article   Google Scholar   Lara-Nino, C.A., Diaz-Perez, A., Morales-Sandoval,
    M.: Elliptic curve lightweight cryptography: a survey. IEEE Access 6, 72514–72550
    (2018). https://doi.org/10.1109/ACCESS.2018.2881444 Article   Google Scholar   Rao,
    V., Prema, K.V.: Lightweight authentication and data encryption scheme for IoT
    applications. In: 2020 IEEE International Conference on Distributed Computing,
    VLSI, Electrical Circuits and Robotics (DISCOVER), pp. 12–17 (2020). https://doi.org/10.1109/DISCOVER50404.2020.9278048
    Yachou, M., et al.: Applying lightweight elliptic curve cryptography ECC to smart
    energy IOT platforms based on the CoAP protocol. In: The International Conference
    on Information, Communication & Cybersecurity (ICI2C 21). https://doi.org/10.1007/978-3-030-91738-8_20
    ElAidi, S., Bajit, A., Barodi, A., Chaoui, H., Tamtaoui, A.: An optimized security
    vehicular Internet of Things-IoT-application layer protocols MQTT and COAP based
    on crypto- graphic elliptic-curve. In: 2020 IEEE 2nd International Conference
    on Electronics, Control, Optimization and Computer Science, ICECOCS 2020, pp.
    9314579 (2020) Google Scholar   El Aidi, S., Bajit, A., Barodi, A., Chaoui, H.,
    Tamtaoui, A.: An advanced encryption cryptographically-based securing applicative
    protocols MQTT and CoAP to optimize medical-IOT supervising platforms. Lect. Notes
    Data Eng. Commun. Technol. 72, 111–121 (2021) Article   Google Scholar   Download
    references Author information Authors and Affiliations Laboratory of Advanced
    Systems Engineering (ISA), National School of Applied Sciences, Ibn Tofail University,
    Kenitra, Morocco Ayoub Ech-Chkaf, Salma Ait Oussous, Abdelhadi El Allali, Siham
    Beloualid, Sanaa El Aidi, Abderrahim Bajit & Habiba Chaoui Department of Computer
    Science, Logistics and Mathematics (ILM) Engineering Science Laboratory National
    School of Applied Sciences, Ibn Tofail University, Kenitra, Morocco Taoufiq El
    Harrouti Laboratory of Advanced Systems National Institute of Posts and Telecommunications,
    SC Department, Mohammed V University, Rabat, Morocco Ahmed Tamtoui Corresponding
    author Correspondence to Ayoub Ech-Chkaf . Editor information Editors and Affiliations
    Birmingham City University, Birmingham, UK Faisal Saeed School of Computing, Universiti
    Utara Malaysia (UUM), Sintok, Kedah, Malaysia Fathey Mohammed Department of Computer
    Science, School of Computing, Universiti Teknologi Malaysia, Skudai, Malaysia
    Fuad Ghaleb Rights and permissions Reprints and permissions Copyright information
    © 2022 The Author(s), under exclusive license to Springer Nature Switzerland AG
    About this paper Cite this paper Ech-Chkaf, A. et al. (2022). Applying an Enhanced
    Elliptic Curve Integrated Encryption Scheme ECIES to Enhance Smart Energy IoT
    Platform Security Based on Constrained Protocol. In: Saeed, F., Mohammed, F.,
    Ghaleb, F. (eds) Advances on Intelligent Informatics and Computing. IRICT 2021.
    Lecture Notes on Data Engineering and Communications Technologies, vol 127. Springer,
    Cham. https://doi.org/10.1007/978-3-030-98741-1_41 Download citation .RIS.ENW.BIB
    DOI https://doi.org/10.1007/978-3-030-98741-1_41 Published 30 March 2022 Publisher
    Name Springer, Cham Print ISBN 978-3-030-98740-4 Online ISBN 978-3-030-98741-1
    eBook Packages Intelligent Technologies and Robotics Intelligent Technologies
    and Robotics (R0) Share this paper Anyone you share the following link with will
    be able to read this content: Get shareable link Provided by the Springer Nature
    SharedIt content-sharing initiative Publish with us Policies and ethics Download
    book PDF Download book EPUB Sections Figures References Abstract Introduction
    Smart Grid IoT Platform and Aims Methodology Related Works The Proposed Approach
    Discussion and Results Conclusion and Perspectives References Author information
    Editor information Rights and permissions Copyright information About this paper
    Publish with us Discover content Journals A-Z Books A-Z Publish with us Publish
    your research Open access publishing Products and services Our products Librarians
    Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC
    Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy
    rights Accessibility statement Terms and conditions Privacy policy Help and support
    129.93.161.219 Big Ten Academic Alliance (BTAA) (3000133814) - University of Nebraska-Lincoln
    (3000134173) © 2024 Springer Nature"'
  inline_citation: '>'
  journal: Lecture Notes on Data Engineering and Communications Technologies
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Applying an Enhanced Elliptic Curve Integrated Encryption Scheme ECIES to
    Enhance Smart Energy IoT Platform Security Based on Constrained Protocol
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Chen H.
  - Wang S.
  - Tan W.
  - Luo J.
  citation_count: '3'
  description: With the increasing trend of population aging in our country, how to
    take care of the elderly has become the focus of attention from all walks of life.
    In order to reduce the occurrence of incidents that the elderly did not receive
    timely assistance due to falling, this article designed a smart vest system with
    STM32 single-chip microcomputer as the main control chip, which uses ultrasonic
    sensors to obtain the distance between the elderly and obstacles to realize the
    anti-collision reminder function. Connect the six-axis acceleration sensor for
    fall detection and control the ejection of the airbag to complete the fall protection
    function. At the same time, the alarm information is sent to the target associated
    mobile phone through the GSM network, and the HTTP communication protocol is used
    to communicate with the OneNET platform (China Mobile Internet of Things Open
    Platform) carry out data interaction and realize the function of positioning for
    help. The system also uses human heart rate sensors and body temperature sensors
    to collect real-time data on the physiological state of the elderly; this system
    adds a strong guarantee for the health and safety of the elderly.
  doi: 10.1109/ITOEC53115.2022.9734661
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2022 IEEE 6th Information Tec... STM32-based
    Anti-fall Smart Vest System for the Elderly Publisher: IEEE Cite This PDF Han
    Chen; Shuqun Wang; Wanrou Tan; Jie Luo All Authors 2 Cites in Papers 331 Full
    Text Views Abstract Document Sections I. Introduction II. System Overall Design
    III. System Hardware Design and Implementation IV. System Software Design V. Conclusions
    Authors Figures References Citations Keywords Metrics Abstract: With the increasing
    trend of population aging in our country, how to take care of the elderly has
    become the focus of attention from all walks of life. In order to reduce the occurrence
    of incidents that the elderly did not receive timely assistance due to falling,
    this article designed a smart vest system with STM32 single-chip microcomputer
    as the main control chip, which uses ultrasonic sensors to obtain the distance
    between the elderly and obstacles to realize the anti-collision reminder function.
    Connect the six-axis acceleration sensor for fall detection and control the ejection
    of the airbag to complete the fall protection function. At the same time, the
    alarm information is sent to the target associated mobile phone through the GSM
    network, and the HTTP communication protocol is used to communicate with the OneNET
    platform (China Mobile Internet of Things Open Platform) carry out data interaction
    and realize the function of positioning for help. The system also uses human heart
    rate sensors and body temperature sensors to collect real-time data on the physiological
    state of the elderly; this system adds a strong guarantee for the health and safety
    of the elderly. Published in: 2022 IEEE 6th Information Technology and Mechatronics
    Engineering Conference (ITOEC) Date of Conference: 04-06 March 2022 Date Added
    to IEEE Xplore: 23 March 2022 ISBN Information: ISSN Information: DOI: 10.1109/ITOEC53115.2022.9734661
    Publisher: IEEE Conference Location: Chongqing, China SECTION I. Introduction
    Countries all over the world are facing serious aging problems, and the physical
    and mental health of the elderly has become the focus of attention from all walks
    of life. [1] Among the elderly over 65 in China, an average of 3–4 out of 10 people
    have had a fall. The biggest impact of a fall is fractures. Among them, hip fractures
    are the most serious, which is also called “the last fracture in life.” The mortality
    rate is as high as 20%-30%, and the disability rate is high. With the increase
    of age, the risk of falling increases year by year. Therefore, it is extremely
    important to design an intelligent system for the elderly. The anti-fall smart
    vest system for the elderly based on STM32 designed in this paper uses the principle
    of ultrasonic distance measurement, and then controls the buzzer to sound to achieve
    the anti -collision reminder function. Fall detection detects the human body acceleration
    through the acceleration sensor, sets multi-level thresholds, and judges whether
    the human body has fallen or not. Calculate the human body acceleration vector
    assignment SVM, variation index and the angle when the body falls. When the system
    judges that the elderly is falling, the airbag will pop up to protect the elderly''s
    neck, back and hip joints. The positioning for help is through GPS and GSM. The
    network is realized, when an accident occurs to the elderly, an alarm message
    is sent to the guardian''s mobile phone and the position of the elderly is uploaded
    to the OneNET platform. At the same time, the real-time detection of human physiological
    conditions provides a strong guarantee for the health and safety of the elderly.
    SECTION II. System Overall Design The system is a shape of a vest, STM32 as the
    main control chip, and is equipped with an ultrasonic sensor to measure the distance
    between the obstacle and the user in real time. When the safety distance is exceeded,
    the buzzer will alarm to complete the anti-collision reminder function. When the
    value collected by the six -axis acceleration sensor exceeds the warning value,
    the fall detection module will send an alarm signal to the main control chip to
    control the airbag to pop out to protect the elderly. The positioning help module
    sends an alarm message to the guardian''s mobile phone through the GSM network,
    and uploads the location information of the elderly to the OneNET platform through
    GPS positioning. The guardian can view the specific location of the elderly through
    the “Device Cloud” APP or OneNET webpage, so that the elderly can be rescued in
    time. At the same time, the system uses temperature and heart rate sensors to
    monitor the body temperature and heart rate of the elderly in real time. When
    an abnormality occurs, it can also send an alarm message to the guardian''s mobile
    phone. Fig 1 is a diagram of system function modules. Fig. 1. T. System overall
    block diagram. Show All SECTION III. System Hardware Design and Implementation
    A. Anti-Collision Reminder Module In the anti-collision reminder module, the system
    uses the ultrasonic sensor and anti-collision alarm in Fig 1 to achieve. This
    system chooses HC-SR04 ultrasonic ranging module and buzzer to realize. In the
    range of 2cm-500cm, it can show good non-contact distance sensing efficiency,
    and has a range accuracy value of up to 0.3cm [2]. The module automatically sends
    8 40khz square waves and automatically detects whether there is a signal return.
    If there is a signal return, it outputs a high level through the IO port ECHO.
    The high level duration is the time from the ultrasonic wave to the return. The
    ultrasonic sensor is used to measure the distance S between the elderly and the
    obstacle. When the distance meets: 10cm<S<20cm, the buzzer acts as an anti-collision
    alarm to alert the elderly with visual impairments that they are close to the
    object; when S<10cm, The buzzer alarms quickly. When the distance S<20cm is measured
    again after 5s, it can be considered that the user needs to be close to the object,
    and the buzzer will no longer alarm. B. Fall Monitoring Module In order to more
    accurately judge the acceleration of the elderly when they fall and in their daily
    life, this system uses the world''s first integrated 6-axis motion processing
    component introduced by InvenSense. It integrates a three-axis MEMS gyroscope,
    and a three-axis MEMS plus Speedometer. [3] The output of the MPU6050 six-axis
    acceleration sensor is digital data, which can be directly transmitted to the
    single-chip microcomputer for processing without an A/D converter, which can reduce
    the energy consumption, error and volume of the entire system. [4] The MPU6050
    sensor can monitor the body acceleration of the elderly in real time. This feature
    will make the judgment of the elderly fall more accurate. The STM32 single-chip
    microcomputer is connected to the MPU6050 acceleration sensor through the IIC
    interface. The acceleration value and attitude angle collected by the MPU6050
    are transmitted to the STM32 single-chip microcomputer for post-processing. After
    calculating the human body acceleration vector amplitude SVM, CV (the coefficient
    of variation) and the attitude angle ω, When the three indexes exceed the set
    thresholds, it is judged that the old man has fallen. C. Airbag Pop-Up Module
    In the fall detection module shown in Fig 1, the pop-up of an airbag is included.
    The execution plan of this module is mainly composed of geared motor, compression
    spring insurance, gas cylinder, control circuit and spring piercing device (including
    steel needle, compression spring, spring bin, fixing frame, compression spring
    screw), and the overall structure is shown in Fig 2. The geared motor cooperates
    with the drive to realize the large torsion rotation of the single-chip microcomputer
    electric signal, pull the compression spring to protect, and the compression spring
    converts the elastic potential energy into the kinetic energy of the linear motion
    of the steel needle. The main body of the compression spring insurance is a hollow
    steel ball (Fig 3), which is pulled out by the geared motor to provide strong
    torque. After theoretical calculations and many experiments, a cylindrical compression
    spring magazine was designed so that the steel needle can eject and pierce the
    cylinder in a very short time without exposing the needle. The physical map is
    shown in the figure (Fig 4) Fig. 2. Structure diagram of gas cylinder device Show
    All Fig. 3. Details of compression spring insurance Show All Fig. 4. Physical
    image of gas cylinder device Show All D. Airbag Protection Module The fall detection
    module in Fig 1 contains airbag protection. The entire wearable fall protection
    safety air is composed of a bladder out of a vest and a cushioning inner bladder.
    The outsourcing vest is equipped with an airbag ejection module, a power supply
    module, a main control module, a fall warning module (ultrasonic module), an airbag
    ejection module, a distress module, etc.; the vest is worn in the form of a buckle,
    which is convenient for users to wear. In the overall vest; when the cushioning
    bag is inflated, the Velcro is opened and quickly wraps the upper torso and buttocks
    of the human body. Fig 5 shows the effect of the airbag pop-up. Fig. 5. Airbag
    pop-up renderings Show All E. Positioning and Rescuing Module In the positioning
    and distress module in Figure 1, the positioning function will be realized through
    GPS, and the distress function will be realized through the GSM network. This
    system uses SIM868 module to realize. The distress function is connected to SIM868‧s
    U_TXD through the STM32''s PA3 port, and the PA2 port is connected to U_RXD. STM32
    sends commands to SIM868 through the serial port, “AT+CMGS” enters the short message
    sending mode, then sends the “phone number”, and finally transmits the content
    of the short message. Among them, because Chinese text messages are to be sent,
    the phone number and content sent need to be converted into Unicode codes, and
    unicode encoding is used for data transmission. The positioning module is connected
    to SIM868''s U_TXD through STM32''s PA3 port, PA2 is connected to U_RXD, and PA10
    is connected to GPS_TXD. STM32 controls SIM868, allows SIM868 to collect GPS data
    through AT commands, then converts them into latitude and longitude in the program,
    encapsulates the data into JSON strings, and adds HTTP headers to upload the data
    to the OneNET platform. Among them, adding the APIKEY of the product created on
    OneNET into the HTTP header allows SIM868 to upload the data to the self-developed
    product corresponding to OneNET. The uploaded data can see the corresponding map
    location in the Location data stream of OneNET. F. Physiological Condition Monitoring
    Module In the physiological state monitoring module in Figure 1, the DS18B20 temperature
    sensor and Pulsesensor pulse and heart rate sensor are used to achieve. The PA0
    port of STM32 is connected to the DQ port of DS18B20 through a 10KΩ pull-up resistor
    to monitor the body temperature of the elderly in real time and compare it with
    the normal body temperature. The AD pin of the Pulsesensor is transmitted to the
    PB1 port of the STM32 single-chip microcomputer, converted into pulses, reshaped,
    counted, and finally converted into the number of pulses of 1 min through the
    formula, and the number of pulses can be measured in real time, so as to monitor
    the elderly in real time Heart rate pulse. SECTION IV. System Software Design
    A. Fall Detection Algorithm Design In the process of realizing the function of
    the fall detection module, the algorithm is written using the principle of the
    inclination acceleration sensor monitoring. The algorithm generally adopts the
    idea of multi-level detection, [5] which has high reliability and accuracy. By
    setting multi -level thresholds, the human body''s posture is judged whether it
    falls down or not [6]. This system uses 3 values to judge whether the old man
    falls. Using the MPU6050, the acceleration ax, ay, az of the x, y, and z axes
    can be obtained, so as to calculate the human body acceleration vector amplitude
    value SVM, which reflects the violent degree of human motion. (SVM= α 2 x + α
    2 y + α 2 z − − − − − − − − − − − √ ) In the specified time window, when the dispersion
    of SVM is large, the coefficient of variation (CV) will be higher. The variation
    index is defined as follows: SD= x ¯ = 1 n ∑ i=1 n x i 1 n ∑ i=1 n ( x i − x ¯
    ) 2 ) − − − − − − − − − − − − − √ CV= x ¯ SD View Source n is the number of samples
    in the time window; xi is the SVM value calculated in the time window; is the
    average value of the SVM; SD is the standard deviation. The angle of the human
    body will change on the x and y axis during a fall, [7] and the angle ω is used
    to reflect the fall during the fall. When the value of ω increases, the change
    of the body angle also increases. We use the angle to make the final judgment.
    The definition of co is: ω= ω 2 x + ω 2 y − − − − − − √ View Source After many
    experiments and due to the low activity frequency of the elderly, we set the threshold
    of SVM to 1.5g. Because in statistics, the larger the value of CV, the greater
    the degree of dispersion. We use CV to make the second judgment. When the human
    body falls, the SVM changes drastically, and the degree of dispersion is very
    large. Several experiments have shown that the value of CV is greater than 0.20
    when the elderly falls, while in daily activities, the value of CV is lower than
    0.19. Therefore, the CV fall threshold is set to 0.20. [8] In order to ensure
    the accuracy of judging the fall of the elderly, we set when the CV continuously
    exceeds 0.20 in the three time windows of T but the angle ω does not exceed the
    threshold, it is judged that the elderly is exercising vigorously for a long time
    instead of falling; but the CV is in 3 consecutive times If the angle ω exceeds
    0.2 in the window and the angle ω is used as the secondary judgment, if the angle
    ω continuously exceeds the threshold within 30 sampling points, it is considered
    that a fall event has occurred. Otherwise, it is considered that the elderly did
    not fall. The algorithm flow is shown in Fig 6: Fig. 6. Flowchart of fall detection
    algorithm Show All B. Positioning and Rescuing Module This system uses the SIM868
    module to complete the positioning and distress function. The SIM868 module is
    a complete quad-band GSM/GPRS module, which combines GNSS technology for satellite
    navigation. Its GSM can realize the function of sending short messages through
    AT commands. The HTTP protocol is used in the help function. The system writes
    messages and POST messages to the OneNET website. In the HTTP body, APIKEY is
    used as the authorization key to access the API interface open on the OneNET platform,
    and the ID is used to identify the corresponding device. The latitude and longitude
    obtained by SIM868 are uploaded to the data stream of the OneNET platform in the
    form of key-value pairs in the json format. Use the cellular data of the SIM card
    to transfer data between the device and the server. Both the OneNET platform and
    its derived “device cloud” APP will display the map location corresponding to
    the GPS. The module is in AT command state by default, and the baud rate is 115200.
    Fig. 7. Schematic diagram of positioning data transmission Show All SECTION V.
    Conclusions This paper designs an anti-fall smart vest system for the elderly
    based on STM32, which uses ultrasonic sensors to complete the anti -collision
    reminder function. The acceleration sensor monitors and analyzes the data in real
    time, and proposes a more accurate fall detection algorithm, and when the elderly
    has a tendency to fall, the airbag can be popped up to protect the neck, back
    and hip joints of the elderly. Fig 8 is the upper body effect diagram. The location
    of the old man''s fall can be obtained through the SIM868 module. Fig 9 is the
    “Device Cloud” APP location page. The alarm message can be sent to the guardian''s
    mobile phone within 10s, as shown in Fig 10. The temperature and heart pulse sensors
    are used to monitor the physiological status of the elderly in real time. If there
    is an abnormality, the guardian can also be notified in time. The system takes
    the shape of a vest and is easy to wear, which can protect the safety of the elderly
    and call for help in time when an accident occurs. Fig. 8. Upper body renderings
    Show All Fig. 9. In-app positioning page Show All Fig. 10. Schematic diagram of
    receiving sms Show All ACKNOWLEDGMENT This research was supported by the Students''
    Innovatio n and Entrepreneurship Training Project of China under Grant No.202110656052.
    Authors Figures References Citations Keywords Metrics More Like This IoT-based
    Real-Time System for Tracking and Monitoring the Health of Soldier 2023 Second
    International Conference on Electronics and Renewable Systems (ICEARS) Published:
    2023 The Dependable Responsive Multithreaded Processor for Distributed Real-Time
    Systems IEEE Micro Published: 2012 Show More IEEE Personal Account CHANGE USERNAME/PASSWORD
    Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS Profile Information
    COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help?
    US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow
    About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination
    Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy A not-for-profit
    organization, IEEE is the world''s largest technical professional organization
    dedicated to advancing technology for the benefit of humanity. © Copyright 2024
    IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE 6th Information Technology and Mechatronics Engineering Conference,
    ITOEC 2022
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: STM32-based Anti-fall Smart Vest System for the Elderly
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Liu X.
  - Jiang J.
  citation_count: '2'
  description: The paper expects to improve the efficiency and intelligence of somatosensory
    recognition technology in the application of physical education teaching practice.
    Firstly, the combination of induction recognition technology and the Internet
    is used. Secondly, through the Kinect sensor, bone data are acquired. Finally,
    the hidden Markov model (HMM) is used to simulate the experimental data. On the
    simulation results, a gait recognition algorithm is proposed. The gait recognition
    algorithm is used to identify the motion behaviour, and the results are displayed
    in the Web (World Wide Web) end built by the cloud server. Meantime, in view of
    the existing problems in the practice of physical education, combined with the
    establishment and operation of the Digital Twins (DTs) system, the camera source
    recognition architecture is carried out since the twin network and the two network
    branches share weights. This paper analyses these problems since the application
    of somatosensory recognition technology and puts forward the improvement methods.
    For the single problem of equipment in physical education, this paper puts forward
    the monitoring and identification function of the cloud server. It is to transmit
    data through Hypertext Transfer Protocol (HTTP) and locate and collect data through
    a monitoring terminal. For the lack of comprehensiveness and balance of sports
    plans, this paper proposes a scientific training plan and process customization
    based on Body Mass Index (BMI), analyses real-time data in the cloud, and makes
    scientific customization plans according to different students' physical conditions.
    Moreover, 25 participants are invited to carry out the exercise detection and
    analysis experiment, and the joint monitoring of their daily movements is tested.
    This process has completed the design of a feasible and accurate platform for
    information collection and processing, which is convenient for managers and educators
    to comprehensively and scientifically master and manage the physical level and
    training of college students. The proposed method improves the recognition rate
    of the camera source to some extent and has important exploration significance
    in the field of action recognition.
  doi: 10.1155/2022/3683216
  full_citation: '>'
  full_text: '>

    "Journals Publish with us Publishing partnerships About us Blog Advances in Civil
    Engineering Journal overview For authors For reviewers For editors Table of Contents
    Special Issues Advances in Civil Engineering/ 2022/ Article On this page Abstract
    Introduction Materials and Methods Results Conclusions Data Availability Conflicts
    of Interest References Copyright Related Articles Special Issue Digital Twins
    in Civil Engineering View this Special Issue Research Article | Open Access Volume
    2022 | Article ID 3683216 | https://doi.org/10.1155/2022/3683216 Show citation
    Digital Twins by Physical Education Teaching Practice in Visual Sensing Training
    System Xinran Liu1and Ji Jiang 1 Show more Academic Editor: Zhihan Lv Received
    18 Oct 2021 Accepted 24 Nov 2021 Published 11 Jan 2022 Abstract The paper expects
    to improve the efficiency and intelligence of somatosensory recognition technology
    in the application of physical education teaching practice. Firstly, the combination
    of induction recognition technology and the Internet is used. Secondly, through
    the Kinect sensor, bone data are acquired. Finally, the hidden Markov model (HMM)
    is used to simulate the experimental data. On the simulation results, a gait recognition
    algorithm is proposed. The gait recognition algorithm is used to identify the
    motion behaviour, and the results are displayed in the Web (World Wide Web) end
    built by the cloud server. Meantime, in view of the existing problems in the practice
    of physical education, combined with the establishment and operation of the Digital
    Twins (DTs) system, the camera source recognition architecture is carried out
    since the twin network and the two network branches share weights. This paper
    analyses these problems since the application of somatosensory recognition technology
    and puts forward the improvement methods. For the single problem of equipment
    in physical education, this paper puts forward the monitoring and identification
    function of the cloud server. It is to transmit data through Hypertext Transfer
    Protocol (HTTP) and locate and collect data through a monitoring terminal. For
    the lack of comprehensiveness and balance of sports plans, this paper proposes
    a scientific training plan and process customization based on Body Mass Index
    (BMI), analyses real-time data in the cloud, and makes scientific customization
    plans according to different students’ physical conditions. Moreover, 25 participants
    are invited to carry out the exercise detection and analysis experiment, and the
    joint monitoring of their daily movements is tested. This process has completed
    the design of a feasible and accurate platform for information collection and
    processing, which is convenient for managers and educators to comprehensively
    and scientifically master and manage the physical level and training of college
    students. The proposed method improves the recognition rate of the camera source
    to some extent and has important exploration significance in the field of action
    recognition. 1. Introduction In recent years, people’s demand for data application
    in the process of sports and training has been increasing. In the practice of
    physical education and training, somatosensory recognition technology based on
    visual sensing systems has attracted more and more attention and research [ 1].
    After 2010, college students’ physical health problems were more prominent, showing
    a downward trend year by year, and the development of college physical education
    has urgent reform requirements [ 2]. The state and government attach great importance
    to the physical fitness of college students and the development of physical education
    in colleges and universities. Accordingly, with the application of big data and
    the rise of visual technology, the demand for more intelligent and scientific
    technology is also more urgent [ 3]. Based on the motion somatosensory recognition
    technology of visual sensing, the Kinect bone tracking technology without identification
    points has been widely developed and applied because of its low cost, portability,
    easy implementation, and no identification points [ 4]. In computational mechanics,
    the introduction of the concept and technology of the Digital Twins (DTs) system
    can achieve real-time safety monitoring and early warning of solid structures.
    The DTs system can not only be applied to civil structures. Similarly, it can
    also be applied to the field of sports science. The system can not only track
    and monitor the gait in real time but also optimize and improve the computer simulation
    recognition technology. It is one of the methods used. DTs are of great help to
    the modification and improvement of structural system redesign and provide a more
    reliable basis. Source identification of digital images is an important part of
    image extraction. Source identification of digital images (i.e., imaging equipment
    identification) refers to a given graph, which determines imaging and identifies
    types through scientific and technological means and methods. The camera source
    is identified by the identification architecture of the DTs network. Firstly,
    the fingerprint of the camera is extracted from the twin network. Secondly, the
    residual network of attention mechanism is added to extract features, and the
    camera source recognition can be realized. Finally, the expected effect of the
    sample number is achieved. The application of visual sensing technology mainly
    focuses on three fields: visual monitoring, interface perception, and content
    retrieval. In the field of elaboration and analysis, all aspects of the human
    motion process are discussed and analysed by analogy. The identification and understanding
    of motion behaviours are analysed, but some studies on motion representation are
    relatively simple. In the research based on the characteristics of the human model,
    the angle between the various parts of the human body and the trajectory of bone
    joints are collected and calculated to achieve a more accurate description of
    the movement and avoid the error caused by the change of the scene. This method
    mainly describes the state of each part of the human body in a three-dimensional
    space [ 5]. In view of the current development and in-depth development of human
    visual sensing motion recognition technology, it is increasingly necessary to
    conduct detailed analysis in related fields. Firstly, after the sample data, algorithm
    model, and motion behaviour characteristics are analysed, the vision sensor training
    system is designed. Secondly, the collected experimental data are tested in the
    training system. Finally, through the DTs network, the camera source identification
    method is proposed. The research aims to provide a certain experience for the
    further development of the perspective sensor training system in physical education
    practice. 2. Materials and Methods 2.1. Construction of Kinect V2 System Using
    Physical Education Practice 2.1.1. Introduction to Kinect V2 Kinect V2 is a new
    Kinect for Windows product released by Microsoft in 2014. Kinect is a 3D somatosensory
    camera with a microphone array, infrared transmitter and receiver, and RGB (RGB
    colour mode) camera. The image of the human part separated from the background
    is input into the human part recognition model trained by the cluster system,
    and the 25-node human model is output, and the bone data are output at the speed
    of 30 f/s. Its official system includes driver, original sensing data flow development
    interface, user interface, and file data, which can be developed twice. The device
    uses Time of Flight technology to obtain depth image information by calculating
    the projected infrared and the return time of reflection. Then, through the corresponding
    algorithm, the coordinate information of human joint points segmented from the
    background image is estimated. Among them, the bone data output by RGB intelligent
    camera provides the basis for human motion recognition and solves the problem
    of data extraction in computer vision. Kinect V2 components and functions are
    shown in Table 1. Table 1  Kinect V2 components and functions. 2.1.2. Kinect V2
    Hardware Requirements System CPU (Central Processing Unit) uses an Intel 7-generation
    processor, dx11 (DirectX11), with a 64-bit operating system. The hardware composition
    is shown in Figure 1.    Figure 1  Kinect V2 hardware composition diagram. In
    Figure 1, the CPU is the core of the computer, and the computer acts as an “intermediary”
    in the Kinect V2 hardware. Kinect V2 stores the bone data related to the human
    body and the user’s personal information on the card reader and sends it to the
    computer. The computer sends this information to the cloud space. When users visit
    the website, they can see their own information on the computer monitor. 2.1.3.
    Kinect V2 Application Principle Kinect V2 equipment first uses the infrared receiver
    to receive the infrared light emitted by the infrared transmitter. By collecting
    the encoded infrared spectrum, the depth image is processed frame by frame. Then,
    the device separates the characters and background to obtain the colour image
    of human motion. Finally, the data are transmitted through Kinect V2. The data
    flow process is shown in Figure 2.    Figure 2  The data stream of Kinect V2.
    (1) Depth Imaging. Among the three cameras of Kinect V2, RGB camera is used to
    collect RGB images, also known as colour camera. Two other cameras (infrared transmitters
    and infrared cameras) are used to form a depth sensing device. The depth measurement
    technology in Kinect V2 is a 3D detection technology based on PrimeSense, which
    obtains depth information through the optical principle. The infrared ray emitted
    by the infrared transmitter goes to the different reference planes of the specified
    scene, and the diffraction grating divides it into multiple beams. The infrared
    spectrum forms some speckle patterns in these planes, and different speckle patterns
    show different depth values to determine the depth information. Assuming that
    it points to the infrared emitter in the x-axis positive direction and to the
    object in the z-axis positive direction, the coordinate system conforms to the
    right-handed spiral rule. Measuring the parallax of t’ in the image, there are
    In equations (1) and (2), Zo is the depth distance from the real sensor to the
    object, A is the baseline length, e is the focal length of the sensor, C is the
    displacement distance of point o, and c is the parallax of the infrared image
    [ 6]. Combining equations (1) and (2), there is The depth distance Zo is obtained
    from the above equation. Using the same principle, there are In equations (4)
    and (5), the abscissa of o point is Xo, the ordinate of o point is Yo, the abscissa
    and ordinate of original coordinate are Xt and Yt, respectively, and the correction
    term is δy. The three-dimensional coordinates of o point are calculated, represents
    the depth distance from the real sensor to the object, and represents the depth
    of the reference plane. (2) Bone Recognition. Skeleton recognition is a process
    of extracting the required information from noise, that is, the process of removing
    interference information except the human body in the picture. The identification
    process is shown in Figure 3.    Figure 3  Kinect V2 recognition process. Kinect
    V2 uses the Poisson equation to filter the noise to determine the existence of
    feature points on the body surface [ 7]. By grasping the angle and direction of
    the surface around the feature point, it determines the spatial position of its
    existence and forms a distance field near the point to obtain a relatively smooth
    shape. 2.2. Overall Network Architecture for Source Identification of DTs Camera
    DTs play an important role in the camera source identification of the Kinect V2
    system. Twins parasitize in digital time and space in computers, such as entity
    space-time and twin brothers in the corresponding digital space-time. DTs have
    two evolution paths. One is Product Lifecycle Management (PLM) to DTs. The other
    is from Physical Twins (PTs) to DTs. The establishment of DTs corresponding to
    entities marks the improvement of computer numerical simulation and simulation
    concept and technology and is a breakthrough in computational mechanics. Generally,
    DTs have five life stages: (1) Design phase: in this stage, DTs can be optimized
    by finite element decomposition, which determines the design scheme of the solid
    structure. In DTs, the layout optimization can determine the design scheme of
    mechanical sensors in the structure. (2) Manufacturing phase: in this phase, less
    computation will focus on manufacturing changes to the design, and DTs will be
    checked as the entity structure changes to ensure synchronization with the entity.
    (3) Operational phase: in this stage, the calculation of the design is relatively
    large and the most complex. This stage mainly focuses on Tokyo load identification
    to carry out calculation related to safety monitoring. Because of high difficulty,
    large quantity, and high complexity, the real-time repeated calculation is needed.
    (4) Maintenance phase: in this phase, the amount of computation is concentrated
    mainly before maintenance and is closely related to the previous phase. Real-time
    safety assessment does not hinder the proposal and proposal of maintenance. (5)
    Retirement phase: in this stage, there are calculation of retirement decision
    and calculation of rehabilitation. The calculation of decision-making is like
    the calculation of maintenance suggestions in the previous stage, and the calculation
    of rehabilitation is like the calculation in the design stage. After the comprehensive
    analysis of a declaration cycle and the calculation of the optimal design, suggestions
    for improvement of the redesign are proposed. In order to realize the identification
    of the camera source, this paper designs an identification architecture based
    on a twin network. The overall structure is shown in Figure 4. The virtual frame
    is two branch networks of twin network sharing weights. In the designed twin network,
    two samples are needed to enter, the reference image P1 and the test image P2.
    The input two images are filtered to obtain the camera reference mode noise and
    the image to be tested. The pattern noise extracted from the reference image P1
    is the “fingerprint” of the camera. Using the residual network with an attention
    mechanism, two noise image features are extracted. By calculating the distance
    between the feature vectors, the similarity between the noise information of the
    image to be measured and the “fingerprint” information of the camera C is measured
    to determine whether the image P2 can be seen as shot by the camera C and realize
    the camera source discrimination.    Figure 4  DTs network modelling for camera
    source recognition. For the accuracy of camera source identification, seven different
    camera models are selected. The test images with different resolutions are unified
    into 224 × 224 image blocks to verify the performance of the designed method.
    The recognition accuracy and receiver operating characteristic curve are used
    as evaluation indexes to measure the performance of image source recognition.
    The recognition accuracy is defined as the ratio of the number of correct images
    to the number of all recognized images. 2.3. Motion Category and Representation
    Human movement can be divided into three types based on three different levels
    of complexity, namely, action, behaviour, and action [ 8]. Among them, “action”
    is the most basic movement, the basic elements of movement, and the necessary
    basis for the formation of other complex movements. The time sequence is short,
    and the geometric and statistical methods are commonly used for identification.
    “Behaviour” refers to the sequence of several continuous actions. Its time scale
    is larger than that of “action,” and it can clearly show the purpose of human
    motion. It is usually identified by statistics. “Behaviour” may contain multiple
    “action,” and the relationship between each action and state needs to be considered
    and linked in the recognition process. Finally, “action” is the most complex,
    which is realized through motion. However, it is not a simple mechanical combination
    of individual motion, but a complete and purposeful motion system with different
    degrees of complexity. Probability statistics and artificial intelligence algorithms
    are usually used to identify, among which the Bayesian network is the representative
    method. The behaviour process extracted from the video sequence containing human
    motion that can reasonably and appropriately represent the motion data is called
    motion representation. In the process of motion recognition, motion representation
    is an extremely important step. Different occasions and environments need to choose
    different methods for motion representation. When the motion scene is a large
    scene, it is necessary to carry out remote camera and monitoring; only the trajectory
    of the moving target is extracted. When the motion situation is small, such as
    gesture recognition, it is necessary to model the limb joints of the moving target
    in two-dimensional (2D) or 3D. In general, four criteria are used to measure the
    pros and cons of motion representation [ 9], namely, compactness, completeness,
    continuity, and uniqueness [ 10]. Most of the current motion representation can
    only meet part of the above metrics. Generally, there are two representation methods,
    one based on appearance and the other based on the human model. The representation
    method based on representation is to analyse and represent the motion by directly
    using the colour information or grey information in the image. This method of
    directly using image information is relatively simple. Yamato et al. (2016) took
    the two-dimensional network feature as the motion feature [ 11] and divided the
    whole image into several networks by binarization of the image extracted from
    the moving target. They calculated the proportion of the number of target pixels
    in each network in the whole grid, thus representing the movement of the target.
    Another representation method is based on human contour information or region
    information. Kale et al. (2017) adopted a gait recognition method based on human
    contour information [ 12]. They first extract the human contour, calculate the
    contour width, and use the width vector as the feature vector to complete the
    recognition. There is also an apparent representation method based on motion information
    (optical flow, target trajectory, speed, etc.). However, due to a large amount
    of calculation and insufficient robustness of this method, Psarrou et al. (2017)
    used spatiotemporal trajectory technology to represent behaviour and further used
    the Markov process to model [ 13]. 2.4. Identification Method Technology 2.4.1.
    Template-Based The template-based method is to transform the motion image sequence
    into a single or a set of static templates and realize recognition by matching
    the sample template to be identified and the known template. The matching method
    is to directly match the sample of the template to be identified and the known
    template and obtain the category of the known template with the smallest distance
    as the recognition result. Bobick and Davis (2018) transformed the image sequence
    into MEI (motion energy image) and MHI (motion history image) and used Mahalanobis
    distance to measure the similarity between templates [ 14]. MEI represents the
    coverage and intensity of motion, and MHI represents the time change of motion.
    Due to the different duration of motion in the same mode, template time warping
    becomes very necessary. Arie et al. (2016) linearized the template sequence before
    matching and then matched it by voting [ 15]. The duration of action is often
    random in the process of movement, so the linear time regulation method cannot
    completely solve the problem. 2.4.2. Based on Probability Network As the most
    important motion recognition method at present, the method based on probability
    network can fully consider the dynamic process existing in the motion process.
    Different from the template-based recognition method, the method based on probability
    network can model the subtle changes in time and space scales through the probability
    method, so it has good robustness. At present, there are two kinds of probabilistic
    networks: dynamic Bayesian network and hidden Markov model. The hidden Markov
    model, as a special form of dynamic Bayesian network, has been used as a conditional
    random field in behaviour recognition [ 16]. Because it can avoid the independence
    assumption in the usual probability model, it is currently used most widely. 2.4.3.
    Grammar-Based Technology The grammar technique is also called the syntax technique.
    Because of its advantages of understanding complex structures and utilizing prior
    information, there are more and more opportunities for motion recognition. Huber
    et al. (2016) used the deterministic syntax of adding orders to identify discrete
    events [ 17]. Cho et al. (2017) used statistical grammatical reasoning to solve
    automatic identification [ 18]. Ivanov and Bobick (2016) used the technology of
    instant grammar to identify the behaviour interaction of multiagents [ 19] and
    divided the identification problem into two levels. The bottom layer was the candidate
    feature detected by the independent probability event detector, which generated
    random syntactic analysis services for context-free. 2.5. Hidden Markov Model
    It is the simplest dynamic Bayesian network based on training and evaluation in
    the probability and statistics model. In this paper, this algorithm is used to
    study the recognition of motion. In the hidden Markov model, the state is not
    directly visible but is visible by using the output dependence of a specific observation
    value. The model includes two random processes, as shown in Figure 5.    Figure
    5  The process diagram double random about the hidden Markov model (HMM). The
    hidden Markov model has two parts. The first is the Markov chain, and the output
    through this process is the state sequence. The other is the random process of
    the output corresponding to the observation value sequence and the state sequence.
    Usually, hidden Markov models are defined by five parameters. 2.5.1. N Hidden
    States The hidden Markov model (HMM) is a probability model about time series.
    It describes the process of randomly generating unobservable state random sequences
    from a hidden Markov chain and then generating an observation from each state
    to generate an observation random sequence. Hidden Markov states satisfy Markov
    properties and are actually hidden states in Markov models. However, these states
    cannot be obtained by direct observation and can be specifically represented by
    θ1, θ2, θ3, ..., θn. 2.5.2. M Observable States M is the number of observed values
    corresponding to a specific state, which can directly observe the state associated
    with the hidden state in the model. V1, V2, V3, ..., Vm are defined as the observed
    M observations, and Qt is defined as the observed value of t at any time. 2.5.3.
    Initial State Probability Matrix Π The initial state probability matrix represents
    the probability matrix of the implicit state at the initial time. For instance,
    when the initial state probability matrix defining Π = (Π1, Π2, Π3…, Πn), 2.5.4.
    Implicit State Transition Probability Matrix A The implicit state transition probability
    matrix A describes the transition probability between states in the HMM. If defining
    A = (aij)NN, than there is At time t, when state θt is established, Equation (7)
    indicates the probability of the observation state being at time t and the implicit
    state of t + 1. 2.5.5. Observation State Transition Probability Matrix B The probability
    of θj is observed when the implicit state is θj at t. B represents the observation
    matrix of the observation value; defining B = (bjk)NM, there is Therefore, in
    the hidden Markov model, there are Briefly, 2.6. Hidden Markov Algorithm 2.6.1.
    Viterbi Algorithm The Viterbi algorithm is an algorithm that uses the dynamic
    programming idea to calculate the hidden Markov chain model prediction so as to
    find the optimal path problem. Define the observation sequence O = O1O2O3…OT,
    λ = (A, B, Π), with P = (Q, O | λ) as the maximum premise, and find the specific
     = , , …, sequence. δ(i) is defined as the maximum probability of O1,O2,O3, …,
    Ot obtained at time t at the state q1, q2, …, qt, when qt = θi. Initialize: Reasoning:
    Ending is as follows: Optimal path is as follows: 2.6.2. Baum–Welch Algorithm
    This algorithm can solve the parameter estimation problem in the hidden Markov
    model [ 20] and can easily calculate the model-related parameters: The idea of
    the dynamic algorithm can be used to obtain λ = (A, B, Π) by making the maximum
    value of P = (O | λ) to the local optimal solution. ξ (i, j) is defined as the
    probability of θi at time t when the training sequence O and the model parameter
    λ are known, and the Markov chain state θi and t + 1 are defined as follows: Reasoning
    is as follows: Thus, it is probable that The reevaluation equations are 2.7. Motion
    Recognition under Hidden Markov Model In the process of restoring motion recognition,
    all action sequences are divided into N segments on average so that they correspond
    to the N state in the hidden Markov model one by one and N state transition sequences
    are generated for the sequences. The transition process is shown in Figure 6.    Figure
    6  The process of sequence conversion (S1 represents the distance of the first
    leg, S2 represents the distance of the second leg, S3 represents the distance
    of the third leg, and Sn represents the distance of the n-th leg). The number
    of t frame states qi in the m sequence and the number of t + 1 frame states qj
    are represented by equations The number of frames 1 in the m state sequence and
    the state qi is represented by an equation In the probability of the initial state,
    there is According to the above equation, the number of transitions between two
    adjacent frames in all state sequences is calculated to obtain the transition
    probability A0 of the initial state. There is The Baum–Welch algorithm is used
    to learn the parameters, and the initial parameters are input into the hidden
    Markov model for parameter training. Through this process, the maximum motion
    action is selected as the recognition result. The training and recognition process
    is shown in Figure 7.    Figure 7  The process of training and recognition. 2.8.
    Technical Architecture The system collects the bone motion data of the target
    in real time through the camera of Kinect V2 [ 21]. Skeleton data after coordinate
    mapping to get smooth data, using space vector method to calculate the angle characteristics
    between bone joints and using HMM model to collect the motion characteristics
    of data model training [ 22], select the maximum output probability, so as to
    realize a reliable real-time training system design and output. 2.8.1. Data Collection
    The camera of Kinect V2 is used to obtain the motion data of the target, and the
    bone data flow is applied to the subsequent skeletal motion recognition. 2.8.2.
    Bone Algorithm Processing The data collected from the previous layer are filtered
    to obtain smoother bone data [ 23], and the angle characteristics of bone joints
    by spatial vector algorithm are calculated. 2.8.3. Motion Recognition The data
    of predefined motion actions in the previous layer are collected and calculated
    to obtain the initial parameters of HMM, and the motion action model is trained
    to obtain the output probability of many hidden Markov models. The maximum output
    probability is selected as the recognition result by comparison. 2.8.4. Application
    Through the different training movements identified by the previous layer, the
    data generated in the process (movement time, movement number, performance settlement,
    etc.) are stored and uploaded to the cloud server [ 24]. The scientific analysis
    and management of the system are carried out, and the scientific training plan
    that meets the target characteristics is finally generated. The architecture is
    shown in Figure 8.    Figure 8  The system of architecture. 2.9. Software Design
    The system software architecture is divided into four layers, including data layer,
    skeleton algorithm layer, motion recognition layer, and motion performance layer.
    The software client uses TCP/IP (Transmission Control Protocol/Internet Protocol)
    communication protocol to communicate with the cloud server [ 25]. The client
    function design is shown in Table 2. Table 2  Client functionality. Figure 9 shows
    the software design process.    Figure 9  The process of software design. 3. Results
    3.1. Bone Joint Confusion Experiment Motion recognition design is based on bone
    joint data acquisition. In order to ensure that cameras and software can collect
    and analyse all the joints, five daily behaviours were monitored and analysed,
    including sitting, standing, pouring water, drinking water, and using the phone.
    In the experiment, 100 groups of samples were collected for each of the five behaviours,
    a total of 500 groups. 40 groups of components were extracted from the samples
    collected by each behaviour, and other samples were tested according to the standard
    template library. The matrix results obtained according to the test results are
    shown in Table 3. Table 3  Matrix results. According to the results of sample
    confusion, the actual motion and template have played a good classification and
    comparison results, and the identification of behaviour representation features
    is feasible. Due to the similarity between the behavioural characteristics of
    some actions and the joint angle, there is a low degree of recognition. 3.2. Training
    System Test In order to test the feasibility of the system, 20 men and 5 women
    were invited to participate in the test for 3 days. In the three days, 25 people
    used this system for training in the morning and afternoon, once a day, and a
    total of 250 data samples were obtained. Sample analysis results are shown in
    Table 4. Table 4  Test results. Through the comparative analysis of the recognition
    rate and accuracy, it is found that the training system has a high recognition
    rate of motion and can accurately measure and analyse the joint angle and motion
    trajectory for motion recognition. Among them, the accuracy of sit-up and squat
    is the highest, which can meet the requirements of the market. In contrast, the
    accuracy rate in monitoring and measuring the standing long jump is low, which
    may be due to the error in the range of sight. Additionally, the distance between
    the take-off points and the monitoring point also has a certain impact on the
    accuracy. The specific results are shown in Table 5. Table 5  Accuracy at different
    take-off points and monitoring points. Table 5 shows that the closer the distance
    between the take-off point and the monitoring point, the higher the accuracy obtained.
    The greater the distance between the take-off point and the monitoring point,
    the lower the accuracy obtained. The comparison of recognition rate and accuracy
    is shown in Figure 10.    Figure 10  Comparison of recognition rate and accuracy
    rate. In view of the low error and accuracy in the test of this standing long
    jump project, the actual situation and test situation of the standing long jump
    test are compared. The details are shown in Figure 11.    Figure 11  Comparison
    of standing long jump sample results. According to the results, the data results
    can maintain a certain accuracy between 1.25 and 1.75 meters, while the data are
    not accurate beyond the subrange. The analysis shows that the scene measurement
    environment may bring light interference to the Kinect V2 camera based on the
    TOF (Time of Light) principle, resulting in a lack of accuracy. Meanwhile, there
    may also be site installation location defects and test groups of individual body
    differences in force majeure. The skeletal confusion experiment is to ensure that
    the camera and simulation software can collect and analyse data. The training
    system test experiment is to check the accuracy of all the collected data in the
    test system. After analysis, it is found that the accuracy of the standing long
    jump is the lowest. And then, the standing long jump is tested again. Figure 12
    is the comparison of the proposed method and the baseline method for camera source
    recognition accuracy.    Figure 12  Comparison of recognition accuracy between
    traditional camera source recognition method and visual sensor training system
    (%). Figure 12 shows that the average accuracy of camera source identification
    using the basic sensor mode noise identification method is 93%. When Alexnet is
    used as the branch network of the twin network for camera source recognition,
    the recognition accuracy is generally low. The method is greatly affected by the
    number of samples in the dataset, and the network is more inclined to learn the
    features related to image content. It is proved that the use of the neural network
    without pretreatment for camera source recognition may not be as good as the effect
    of camera source recognition by sensor mode noise. The method designed is used
    for experiments, and the average accuracy reaches 97%, which is 4% higher than
    that of the sensor-based noise identification method. The recognition method designed
    not only is more convenient and automatic than traditional methods but also has
    a certain improvement in recognition rate. 4. Conclusions With the continuous
    development of the global economy and the reduction of trade barriers, it provides
    a broad platform for the rapid development of international trade. International
    trade is the participation of countries in the world in the international division
    of labour and an important means to realize the smooth progress of social reproduction.
    Meantime, international trade is also an important medium for economic, political,
    and cultural exchanges between countries, and it plays an important role in production
    and life. So, it is necessary to add the use of data to educational practice.
    Besides, with the rapid development of visual sensing technology, it has the research
    and development conditions to realize nonwearable sensor monitoring and training
    system. In this paper, a visual sensor training system is designed by using joint
    data and an algorithm model to collect and analyse the characteristics of motion
    behaviour. Finally, the visual sensing training system for physical education
    practice that can complete data collection without wearing is realized, and the
    collected data are uploaded to the cloud through the Internet. Meanwhile, the
    proposed method combines the identification method of sensor mode noise with deep
    learning and proposes a camera source identification method by DTs network. The
    recognition results are judged by the similarity measure of the twin network and
    compared with the experimental results, which proves that the method has better
    recognition rate advantages. The data are analysed using the national health standards,
    and reasonable and scientific training plans are developed according to different
    sports data sources. The software designed in this paper also has defects. The
    software only simulates the research scene, and there are some differences between
    the simulated scene and the real conditions. Therefore, when the simulation experiment
    is carried out, the problems that appeared are not very comprehensive. The corresponding
    hardware equipment needs to be under suitable temperature and light, not exceeding
    30 degrees; otherwise, it will affect the operating speed of the hardware. The
    hardware equipment mentioned in this paper needs to be in a suitable light environment
    to ensure complete accuracy. Therefore, the necessary conditions, such as shading
    of hardware equipment, will be improved in the subsequent research. The management
    system developed in this paper is intended to solve the problems of old mechanism
    and malpractice in physical education in colleges and universities and is committed
    to realizing the scientific, integrated, and standardized management of physical
    education and sports training for college students. Data Availability The data
    used to support the findings of this study are available from the corresponding
    author upon request. Conflicts of Interest The authors declare that they have
    no conflicts of interest. References J. Ting, H. Ting, and D. Tan, “Kinect-based
    badminton motion analysis using intelligent adaptive range of movement Index,”
    IOP Conference Series: Materials Science and Engineering, vol. 7, pp. 12–17, 2019.
    View at: Publisher Site | Google Scholar S. X. Zuo, “Exploration on the reform
    of college physical education curriculum and the promotion of students’ physical
    health,” Industrial & Science Tribune, vol. 20, no. 66, pp. 170-171, 2021. View
    at: Google Scholar L. Wang, Y. A. Zhang, and L. Wang, “Foreign research progress
    on the influence of screen time on Teenagers’ physical health in recent 10 years,”
    Journal of Physical Education, vol. 23, no. 2, pp. 138–144, 2016. View at: Google
    Scholar F. Yusuke, M. Keisuke, and A. Isao, “Development of virtual reality cycling
    training and assessment system to investigate the effect of cycling motions in
    rehabilitative training,” The Proceedings of JSME annual Conference on Robotics
    and Mechatronics (Robomec), vol. 2, pp. 37–40, 2017. View at: Google Scholar L.
    Li, L. Han, and J. G. Xu, “Human model structure segmentation based on semantic
    and geometric features,” Application Research of Computers, vol. 33, no. 1, pp.
    316–320, 2016. View at: Google Scholar T. Kato, H. Hino, and N. Murata, “Multi-frame
    image super resolution based on sparse coding,” Neural Networks, C, vol. 66, pp.
    64–78, 2015. View at: Publisher Site | Google Scholar S. D. Du, “Solution of the
    first boundary value problem of Poisson equation based on finite difference method,”
    Bulletin of Science and Technology, vol. 34, no. 4, pp. 21–24, 2018. View at:
    Google Scholar M. U. Islam, H. Mahmud, and F. B. Ashraf, “Yoga posture recognition
    by detecting human joint points in real time using Microsoft Kinect,” in Proceedings
    of the IEEE Region 10 Humanitarian Technology Conference, pp. 668–673, Dhaka,
    Bangladesh, December 2017. View at: Publisher Site | Google Scholar V. Parameswaran
    and R. Chellappa, “Quasi-invariants for human action representation and recognition,”
    in Proceedings of the 2002 International Conference on Pattern Recognition, vol.
    7, pp. 307–310, IEEE Computer Society Press, Quebec City, QC, Canada, August 2017.
    View at: Publisher Site | Google Scholar B. Reily, H. Zhang, and W. Hoff, “Real-time
    gymnast detection and performance analysis with a portable 3D camera,” Computer
    Vision and Image Understanding, vol. 159, pp. 154–163, 2017. View at: Publisher
    Site | Google Scholar J. Yamato, J. Ohya, and K. Ishii, “Recognizing human action
    in time sequential images using Hidden Markov model,” in Proceedings of the CVPR,
    IEEE, vol. 18, pp. 379–385, Champaign, IL, USA, June 1992. View at: Publisher
    Site | Google Scholar A. Kale, N. Rajagopalan, N. Cuntoor, and V. Kruger, “Gait-based
    recognition of humans using continuous HMMs,” in Proceedings of the Fifth IEEE
    International Conference on Automatic Face Gesture Recognition, vol. 21, pp. 321–326,
    IEEE Computer Society Press, Washington D.C., USA, 2017. View at: Google Scholar
    A. Psarrou, G. Gong, and M. Walter, “Recognition of human gestures and behaviour
    based on motion trajectories,” Image and Vision Computing, vol. 20, no. 5, pp.
    349–358, 2017. View at: Publisher Site | Google Scholar F. Bobick and W. Davis,
    “The recognition of human movement using temporal templates,” IEEE Transactions
    on Pattern Analysis and Machine Intelligence, vol. 15, no. 3, pp. 257–267, 2018.
    View at: Publisher Site | Google Scholar B. Arie, Z. Wang, P. Pandit, and S. Rajaram,
    “Human activity recognition using multidimensional indexing,” IEEE Transactions
    on Pattern Analysis and Machine Intelligence, vol. 24, no. 8, pp. 1091–1104, 2016.
    View at: Publisher Site | Google Scholar J. Lafferty, A. Mccallum, and F. Pereira,
    “Conditional random fields: probabilistic models for segmenting and labelling
    sequence data,” in Proceedings of the 18th International Conference on Machine
    Learning, vol. 7, pp. 282–289, Williamstown, MA, USA, January 2001. View at: Google
    Scholar M. Huber, A. L. Seitz, M. Leeser, and D. Sternad, “Validity and reliability
    of Kinect skeleton for measuring shoulder joint angles: a feasibility study,”
    Physiotherapy, vol. 101, no. 4, pp. 389–393, 2016. View at: Publisher Site | Google
    Scholar K. Cho, H. Cho, and K. Um, “Human action recognition by inference of stochastic
    regular grammars,” Lecture Notes in Computer Science, vol. 3138, pp. 388–396,
    2017. View at: Publisher Site | Google Scholar A. Ivanov and F. Bobick, “Recognition
    of visual activities and interactions by stochastic parsing,” IEEE Trans PAMI,
    vol. 22, no. 8, pp. 852–872, 2016. View at: Publisher Site | Google Scholar G.
    Nguyen and T. Phung, “Reducing over-smoothness in HMM-based speech synthesis using
    exemplar-based voice conversion,” EURASIP Journal on Audio Speech and Music Processing,
    vol. 1, pp. 76–89, 2017. View at: Publisher Site | Google Scholar M. Gu and L.
    Q. Ge, “Natural gamma spectrum processing based on variable parameter double exponential
    smoothing method,” Computer techniques for geophysical and geochemical exploration,
    vol. 6, pp. 506–509, 2018. View at: Google Scholar S. Yohei, Y. Takeshi, and T.
    Hiroshi, “Generation of point light source date for animated hologram with motion
    capture using KinectV2,” ITW Technical Report, vol. 40, no. 11, pp. 67–69, 2016.
    View at: Publisher Site | Google Scholar R. Noel, A. Salekin, and R. Islam, “A
    natural user interface classroom based on Kinect,” IEEE Learning Technology, vol.
    13, no. 4, pp. 59–61, 2017. View at: Google Scholar G. Rogers and H. Christensen,
    “A conditional random field model for place and object classification,” in Proceedings
    of the IEEEE International Conference on Robotics and Automation, vol. 300, pp.
    766–772, Saint Paul, MN, USA, May 2012. View at: Publisher Site | Google Scholar
    J. Yin, G. Tian, and F. Zhou, “Human activity representation and recognition based
    on temporal order histogram in intelligent space,” Chinese Journal of Computers,
    vol. 37, no. 2, pp. 470–479, 2016. View at: Publisher Site | Google Scholar Copyright
    Copyright © 2022 Xinran Liu and Ji Jiang. This is an open access article distributed
    under the Creative Commons Attribution License, which permits unrestricted use,
    distribution, and reproduction in any medium, provided the original work is properly
    cited. More related articles Sensor and Attitude Analysis of Track and Field Training
    Action Recognition Based on Artificial Intelligence Chaonan Liu | Zenghui Chang
    Sports Action Recognition Based on Deep Learning and Clustering Extraction Algorithm
    Ming Fu | Qun Zhong | Jixue Dong Dynamic Recognition and Analysis of Gait Contour
    of Dance Movements Based on Generative Adversarial Networks Junlin Ren | Jae-Keun
    Park Research on Sports Dance Movement Detection Based on Pose Recognition Tang
    Tang | Min Hyun-Joo PDF Download Citation Download other formats Order printed
    copies Views 393 Downloads 815 Citations 2 Related articles Stage Performance
    Characteristics of Minority Dance Based on Human Motion Recognition Yuzhu Shi
    Method of Analyzing and Managing Volleyball Action by Using Action Sensor of Mobile
    Device Xu Sun | Kai Zhao | ... | Xinlong Jin Digital Media Design for Dynamic
    Gesture Interaction with Image Processing Xiaoli Xiong | Yongguang Hou About Us
    Contact us Partnerships Blog Journals Article Processing Charges Print editions
    Authors Editors Reviewers Partnerships Hindawi XML Corpus Open Archives Initiative
    Fraud prevention Follow us: Privacy PolicyTerms of ServiceResponsible Disclosure
    PolicyCookie PolicyCopyrightModern slavery statementCookie Preferences"'
  inline_citation: '>'
  journal: Advances in Civil Engineering
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Digital Twins by Physical Education Teaching Practice in Visual Sensing Training
    System
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Bruno A.
  - Aury J.M.
  - Engelen S.
  citation_count: '2'
  description: 'Background: One of the main advantages of the Oxford Nanopore Technology
    (ONT) is the possibility of real-time sequencing. This gives access to information
    during the experiment and allows either to control the sequencing or to stop the
    sequencing once the results have been obtained. However, the ONT sequencing interface
    is not sufficient to explore the quality of sequencing data in depth and existing
    quality control tools do not take full advantage of real-time data streaming.
    Results: Herein, we present BoardION, an interactive web application to analyze
    the efficiency of ONT sequencing runs. The interactive interface of BoardION allows
    users to easily explore sequencing metrics and optimize the quantity and the quality
    of the data generated during the experiment. It also enables the comparison of
    multiple flowcells to assess library preparation protocols or the quality of input
    samples. Conclusion: BoardION is dedicated to people who manage ONT sequencing
    instruments and allows them to remotely and in real time monitor their experiments
    and compare multiple sequencing runs. Source code, a Docker image and a demo version
    are available at http://www.genoscope.cns.fr/boardion/.'
  doi: 10.1186/s12859-021-04161-0
  full_citation: '>'
  full_text: '>

    "Your privacy, your choice We use essential cookies to make sure the site can
    function. We also use optional cookies for advertising, personalisation of content,
    usage analysis, and social media. By accepting optional cookies, you consent to
    the processing of your personal data - including transfers to third parties. Some
    third parties are outside of the European Economic Area, with varying standards
    of data protection. See our privacy policy for more information on the use of
    your personal data. Manage preferences for further information and to change your
    choices. Accept all cookies Skip to main content Advertisement Search Explore
    journals Get published About BMC Login BMC Bioinformatics Home About Articles
    Submission Guidelines Collections Join The Board Submit manuscript Software Open
    access Published: 13 May 2021 BoardION: real-time monitoring of Oxford Nanopore
    sequencing instruments Aimeric Bruno, Jean-Marc Aury & Stefan Engelen   BMC Bioinformatics  22,
    Article number: 245 (2021) Cite this article 4523 Accesses 2 Citations 34 Altmetric
    Metrics Abstract Background One of the main advantages of the Oxford Nanopore
    Technology (ONT) is the possibility of real-time sequencing. This gives access
    to information during the experiment and allows either to control the sequencing
    or to stop the sequencing once the results have been obtained. However, the ONT
    sequencing interface is not sufficient to explore the quality of sequencing data
    in depth and existing quality control tools do not take full advantage of real-time
    data streaming. Results Herein, we present BoardION, an interactive web application
    to analyze the efficiency of ONT sequencing runs. The interactive interface of
    BoardION allows users to easily explore sequencing metrics and optimize the quantity
    and the quality of the data generated during the experiment. It also enables the
    comparison of multiple flowcells to assess library preparation protocols or the
    quality of input samples. Conclusion BoardION is dedicated to people who manage
    ONT sequencing instruments and allows them to remotely and in real time monitor
    their experiments and compare multiple sequencing runs. Source code, a Docker
    image and a demo version are available at http://www.genoscope.cns.fr/boardion/.
    Background Since 2014, Oxford Nanopore Technologies (ONT) has launched a range
    of nanopore sequencing devices, from the portable MinION device to the flexible,
    high-throughput PromethION sequencer. The ONT technology allows the sequencing
    of long DNA or RNA molecules with a read accuracy of currently 96% [1] and already
    has a wide range of applications [2,3,4,5,6,7]. Unlike traditional next-generation
    sequencing platforms, which provide data at the end of the sequencing experiment,
    ONT sequencing data is generated in real time. Users can access time-critical
    information [8] and thus be able to stop an analysis once the result is obtained.
    This eventually allows washing and reusing of the flowcells [9]. However, the
    ONT interface (MinKnow) does not provide enough interactivity and reporting to
    thoroughly explore the quality of the sequencing data. In addition, almost all
    quality control tools such as MinIONQC [10], pycoQC [11], NanoPack [12] and ToulligQC
    [13] do not take full advantage of the real-time capability of the ONT instrument
    as they analyze the sequencing data at the end of the run. Herein, we introduce
    BoardION, an interactive web application for real-time evaluation of ONT sequencing
    runs. BoardION offers the possibility for sequencing platforms to remotely and
    simultaneously monitor all their ONT devices (MinION, Mk1C, GridION and PromethION).
    It also allows the comparison of several sequencing experiments to assess the
    library’s preparations or the quality of the input samples. In addition, we compare
    BoardION and Minotour [14] which is currently the only software able to process
    the data in real-time. Implementation BoardION is organized in two components,
    the first one is dedicated to the preprocessing of the files generated by the
    ONT basecaller (guppy) and the second one is a dynamic web application, the central
    part of BoardION, which allows the visualization and comparison of sequencing
    metrics. BoardION can be installed and used directly from the source code or via
    a docker image containing all the necessary dependencies. Documentation, github
    and dockerhub repositories, as well as an interactive demo version of BoardION
    are available at http://www.genoscope.cns.fr/boardion/. Data preprocessing Assessment
    of an in-progress run is performed by using information contained in the sequencing
    summary file generated by the guppy basecaller, but this file is not directly
    read and load by the web application. Indeed, the sequencing summary can be quite
    large (more than 10 GB) and will become larger in the future with the increase
    of the throughput. Instead, a preprocessing tool analyzes it periodically to generate
    lightweight datasets that contain only the metrics of interest. On each launch,
    the software searches for the sequencing summary files in the input folder and
    uses the presence of the final_summary.txt file to detect completed experiments.
    This preprocessing step, developed in C++, uses the seekg function of the iostream
    library to directly access and process only newlines. With these optimizations,
    statistics can be computed and updated in the web application every minute. For
    each flowcell, the preprocessing script generates five small files (< 3 MB): four
    containing statistics calculated every 10 min and one containing the read length
    distribution. The C++ software also creates a file listing all the flowcells,
    their status (completed or not) and the latest metrics. The cpu time and memory
    usage of the preprocessing script are correlated with the number of reads of a
    run. It takes one minute and 60 Mo on average to process a single run and less
    than 5 min and 100 Mo on our largest PromethION run (83 M reads). BoardION web
    application We developed a web application because it has the advantage of being
    easily accessible regardless of the user''s configuration. Thus, users can remotely
    and simultaneously monitor all the sequencing runs of their ONT devices. The BoardION
    web application is based on the R shiny package [15] that allows us to describe
    the content of the interface and the relationships between the elements of the
    application. It also uses ggplot2 [16] and plotly R library [17] to create dynamic
    JavaScript graphs. The memory usage of the web application is dependent on the
    use of the interface, but generally requires less than 400 Mo. The BoardION application
    computes widely used metrics such as yield, translocation speed, read length and
    quality. All graphs, dynamically generated, can be exported and saved as images.
    The interface is divided into three tabs: «Run in progress» that emphasizes the
    sequencing experiments currently in-progress, «Run archive» that allows users
    to accurately evaluate a given experiment across all stored experiments and «Sequencing
    overview» that compares metrics from all sequencing experiments (in progress or
    finished). The «Run in progress» tab displays an overview of the main sequencing
    metrics (read length, yield, quality, translocation speed …) in real time for
    all runs being sequenced (Fig. 1). Metrics are plotted cumulatively from the start
    of the experiment to assess the overall efficiency or every ten minutes to quickly
    detect a drop in quality. This dashboard allows users to follow the in-progress
    runs and to investigate more precisely a given experiment using the « Run archive»
    tab. Fig. 1 BoardION «Run in progress» tab. A first panel lists sequencing metrics
    of all in-progress experiments. Below, each panel is dedicated to one of these
    experiments. Users can open the panels to display the throughput, the read length
    distribution and important metrics of each experiment. The throughput can be plotted
    cumulatively from the start of the run or every ten minutes. All graphs are interactive
    as users can also zoom or display popup above the mouse to highlight particular
    values. In the example, the panel of the first experiment is opened while the
    second is minimized Full size image The «Run archive» tab contains the results
    of in-progress and finished runs (Fig. 2). Metrics are displayed through dynamic
    and customizable graphs as users can select the metrics to plot. These metrics
    can be observed temporally to analyze the run quality according to experiment
    time or spatially on the channel grid of the flowcell, to detect the presence
    of bubbles or contaminants, which can reduce the efficiency of the sequencing
    experiment. Fig. 2 BoardION «Run archive» tab. Channel view panel: distribution
    on the flowcell channel grid of a metric chosen by the user. Customizable plot
    panel: the variation of the chosen metric is represented as a function of the
    elapsed time and colored according to the quality. In this example, yield and
    read length distribution panels are minimized Full size image The « Sequencing
    overview» tab is dedicated to the comparison of sequencing metrics from multiple
    flowcells (Fig. 3). This tab is flexible and the user can interactively choose
    between stored flowcells and proposed metrics and add them to current plots. The
    first panel gives an overview of the sequencing metrics for all stored sequencing
    runs and allows users to follow the evolution of the ONT technology according
    to the releases of new protocols, pores, sequencers or basecallers. Next panels
    are dedicated to the comparison of multiple runs by following a sequencing metric
    (yield, read size, translocation speed …) over run time or depicting read size
    distribution of several runs. Fig. 3 BoardION «Sequencing overview» tab. Run overview
    panel in which users can select run metrics to compare according to the run date.
    Here, the panel shows the monthly variation of the run yields. In run comparison
    panel users can select several runs to compare read length distributions and all
    other metrics over run time Full size image Results and discussion Real-time monitoring
    Generally, «Run in progress» and «Run archive» tabs are used to monitor ongoing
    sequencing experiments. During the sequencing, the consumption of reagents leads
    to a decrease in the translocation speed that can affect the read quality or the
    yield [1]. Indeed, ONT recommends keeping the translocation rate above 300 bases
    per second [18]. Thanks to its real-time capability, BoardION allows the users
    to detect a decrease of the translocation rate, and then add reagents (refueling)
    at the right time to avoid an irreversible drop in effectiveness. Figure 4 shows
    an example of a PromethION run, refueled after 20 h, following the observation
    of a decrease in translocation speed as well as read length and base quality.
    After refueling, the sequencing experiment recovers an optimal translocation rate,
    generates longer and higher-quality reads and finally achieves a yield of 83 Gb.
    In addition, BoardION allows sequencing platforms to define metric thresholds
    (speed, quality or yield) below which a flowcell must be refueled or washed to
    sequence a new sample. Fig. 4 a, c, d Examples of customizable graphs for a refueled
    run: the metrics (yield, speed and median size) are calculated (sum or average)
    in ten minutes slices and displayed in function of the elapsed time. b Number
    of reads (color scale) of a given quality (y axis) generated during the sequencing
    experiment (x axis). Dotted black lines have been added manually and highlight
    the refueling time (1200, 1650 and 2450 mn). The plots show a drop of the median
    read size (d) and quality (b) after 500 mn of sequencing at a speed behind 260
    b/s (c). The first refuel at 1200 mn restores initial speed (c) and median size
    (d) but also an almost initial yield per ten minutes (400 Mb vs. 460 Mb, plot
    a). The last two refuels were made when reaching a translocation rate around 300
    b/s as recommended by ONT support Full size image Comparison of flowcells We compare
    four flowcells, where two strains of the same species were sequenced using different
    library sizes. We observe that the yield is not the same between the two strains
    (Fig. 5a). In contrast, the yield is the same for a given strain even if the size
    of the library is different (Fig. 5c). Library preparation like flowcell F2 seems
    to be a better option for generating longer reads. One main advantage of the ONT
    technology is the ability to sequence very long DNA fragments (> 30 kb). As an
    illustration, we also used BoardION to compare long-reads library preparation
    protocols of ONT and Circulomics by sequencing the same genotype of a plant. With
    the Circulomics protocol the peak at a read size of 5 kb is almost removed (Fig.
    5d). This protocol generates a higher proportion of bases in reads longer than
    10 kb. Nevertheless, the ONT protocol generates almost twice more bases than the
    Circulomics protocol (Fig. 5b). Another usage of the run comparison panel is the
    possibility to compare in real time the yield and the read size distribution of
    simultaneous runs being sequenced (Fig. 5e). Fig. 5 Examples of metrics and plots
    depicted by the run comparison panel of the sequencing overview tab. The panel
    allows us to compare runs according to yield and read length. a Ten minutes cumulative
    yield of four runs. b Cumulative yield from the sequencing start of two runs.
    c Number of bases contained in reads of a particular length of four runs. d Percent
    of bases contained in reads of a particular length of two runs. e Cumulative yield
    from the experiment start of three runs being sequenced Full size image Discussion
    and future developments Like BoardION, the ONT sequencing interface Minknow2 displays
    real-time information on translocation speed, yield, read length and quality but
    adds graphs on temperature, voltage, pores states, barcodes distribution and reference
    coverage. Nevertheless, the graphs lack interactivity to fully explore the quality
    of the run. In contrast, BoardION provides interactivity to plot all the metrics
    cumulatively from the start of the run, every ten minutes, according to the channel
    grid of the flowcells or to correlate the metrics using customizable panels. Furthermore,
    BoardION adds some functionalities such as storing statistics of all sequenced
    runs, the comparison of the metrics of these runs and the possibility to remotely
    and simultaneously monitor the runs of many ONT devices. Minknow is a great application
    to monitor a single run, but BoardION is dedicated to the monitoring and the comparison
    of all the runs performed in a given facility. MinoTour is currently the only
    platform able to process the ONT sequencing data in real-time. The platform is
    composed of a database to store sequencing metrics and a web user interface. The
    interface displays metrics describing run efficiency (yield, read length and quality,
    rate, pore activity) and alignment to a reference genome (coverage). Users can
    also setup alerts to be informed when a threshold is reached. We tested minoTour
    to compare its functionalities with BoardION. Installation of minoTour on unix
    is quite hard for biologists without strong computer skills. MinoTour developers
    propose to upload data on their server but due to web transfer this solution does
    not allow a real time analysis of data and is problematic in term of confidentiality.
    In contrast, the docker image of BoardION is easy to install and platform independent.
    We tested minoTour using data provided by the minoTour platform. Unlike BoardION,
    minoTour offers the possibility to explore the signal of the runs and the coverage
    obtained on the sequenced genome. However, BoardION has some additional features
    such as comparison of runs, overview of all runs and customizable plots that allow
    users to thoroughly explore their sequencing experiments. Furthermore, we did
    not succeed to upload our own sequencing data on the minoTour server. It seems
    that minoTour has not been updated since 2017, so, as ONT technology evolves quickly,
    minoTour seems to be currently unusable on recent ONT sequencing data. Several
    applications can take advantages of all ONT generated data (assembly, structural
    variation) but others need only high quality data (identification, SNV, epigenetics).
    Guppy basecalling report distinguishes pass and fail reads (quality threshold
    of 7). It will be useful to report metrics for pass reads in order to help sequencing
    platforms to optimize the pass yield. It will also be useful to report the yield
    of each sample of barcoding runs to assess barcoding efficiency and evaluate the
    generated data obtained for each sample. We aim to add an alert feature that sends
    emails to users when a threshold is reached for a metric. With this feature, the
    sequencing platforms will be able to configure their own alert thresholds in order
    to react faster in case of sequencing problems or to stop a run once a yield is
    obtained. We also want to add a report generator to export readable documents
    containing all metrics and graphs computed by BoardION. Conclusion BoardION is
    an interactive web application for real-time monitoring of ONT sequencing runs.
    The application can be installed via the Docker distribution. BoardION’s dynamic
    and interactive interface allows users to explore sequencing metrics easily and
    to optimize in real time the quantity and the quality of the generated data. It
    also offers the possibility of comparing several sequencing experiments, which
    can be useful to analyze sequencing conditions and follow the evolution of the
    ONT technology. We believe BoardION will help sequencing platforms to establish
    the best sequencing guidelines for different types of samples. Availability and
    requirements Project name: BoardION. Project home page: https://github.com/institut-de-genomique/BoardION.
    Operating system(s): Platform independent. Programming language: c++, R. Other
    requirements: R library shiny 1.4.0.2, plotly 4.9.2.1 and ggplot2 3.3.1. License:
    CeCILL. Any restrictions to use by non-academics: no. Availability of data and
    materials Not applicable. Abbreviations ONT: Oxford Nanopore Technology DNA: Deoxyribo
    nucleic acid GB: Giga bytes MB: Mega bytes SNV: Single nucleotid variation References
    Tyler AD, et al. Evaluation of Oxford Nanopore’s minion sequencing device for
    microbial whole genome sequencing applications. Sci Rep. 2018;8:10931. Article   Google
    Scholar   Jain M, et al. The Oxford Nanopore MinION: delivery of nanopore sequencing
    to the genomics community. Genome Biol. 2016;17:239. Article   Google Scholar   Jain
    M, et al. Nanopore sequencing and assembly of a human genome with ultra-long reads.
    Nat Biotechnol. 2018;36:338–45. Article   CAS   Google Scholar   Kono N, et al.
    Nanopore sequencing: review of potential applications in functional genomics.
    Dev Growth Differ. 2019;61:12608. Article   Google Scholar   Rousseau-Gueutin
    M, et al. Long-read assembly of the Brassica napus reference genome Darmor-bzh.
    GigaScience. 2020;9(12):137. Article   Google Scholar   Sessegolo C, et al. Transcriptome
    profiling of mouse samples using nanopore sequencing of cDNA and RNA molecules.
    Sci Rep. 2019;9:14908. Article   Google Scholar   Simpson JT, et al. Detecting
    DNA cytosine methylation using nanopore sequencing. Nat Methods. 2017;14:407–10.
    Article   CAS   Google Scholar   Petersen LM, et al. Third generation sequencing
    in the clinical laboratory: exploring the advantages and 2 challenges of nanopore
    sequencing. J Clin Microbiol. 2019. https://doi.org/10.1128/JCM.01315-19. Article   PubMed   PubMed
    Central   Google Scholar   Euskirchen P, et al. Same-day genomic and epigenomic
    diagnosis of brain tumors using real-time nanopore sequencing. Acta Neuropathol.
    2017;134:691–703. Article   CAS   Google Scholar   Lanfear R, et al. MinIONQC:
    fast and simple quality control for MinION sequencing data. Bioinformatics. 2019;35(3):523–5.
    Article   CAS   Google Scholar   Leger A, et al. pycoQC, interactive quality control
    for Oxford Nanopore Sequencing. J Open Source Softw. 2019;4(34):1236. Article   Google
    Scholar   De Coster W, et al. NanoPack: visualizing and processing long-read sequencing
    data. Bioinformatics. 2018;34(15):2666–9. Article   Google Scholar   Laffay B,
    et al. ToulligQC: a post sequencing QC tool for Oxford Nanopore sequencers. Github.
    https://github.com/GenomicParisCentre/toulligQC. Accessed 10 Jan 2020. Loose M.
    minoTour: Real time data analysis tools for the MinION sequencing platform. Github;
    2015. https://github.com/minoTour/minoTour. Accessed 1 Oct 2020. Chang W, et al.
    Shiny: web application framework for R. R package version 1.4.0. 2019. https://CRAN.R-project.org/package=shiny.
    Wickham H. ggplot2: elegant graphics for data analysis. Springer; 2009. Book   Google
    Scholar   Sievert C. plotly for R. 2018. https://plotly-r.com. Oxford Nanopore
    Technologies. Refuelling a sequencing run. 2019. https://community.nanoporetech.com/posts/refuelling-a-sequencing-ru.
    Accessed 11 Mar 2020. Download references Acknowledgements The authors are grateful
    to the Oxford Nanopore staff for technical help and for granting Genoscope access
    to the PromethION Early Access Programme (PEAP). We thank the France Génomique
    Infrastructure (www.france-genomique.org) for its support. We also thank Frédérick
    Gavory, Paul Mielle and Thomas Mejean for their insight and support and Corinne
    Cruaud for testing the tool in real conditions. Funding This work was supported
    by the Genoscope, the Commissariat à l''Energie Atomique et aux Energies Alternatives
    (CEA) and France Génomique (ANR-10-INBS-09-08). Author information Authors and
    Affiliations Génomique Métabolique, Genoscope, Institut François Jacob, CEA, CNRS,
    Univ Evry, Université Paris-Saclay, 91057, Evry, France Aimeric Bruno, Jean-Marc
    Aury & Stefan Engelen Contributions AB designed and implemented the application,
    and wrote the manuscript. SE designed the application, tested it on datasets,
    wrote the manuscript and supervised the project. JMA wrote the manuscript and
    supervised the project. All authors read and approved the final manuscript. Corresponding
    author Correspondence to Stefan Engelen. Ethics declarations Ethics approval and
    consent to participate Not applicable. Consent for publication Not applicable.
    Competing interests The authors declare no competing interests. J.-M.A. received
    travel and accommodation expenses to speak at ONT conferences. Additional information
    Publisher''s Note Springer Nature remains neutral with regard to jurisdictional
    claims in published maps and institutional affiliations. Rights and permissions
    Open Access This article is licensed under a Creative Commons Attribution 4.0
    International License, which permits use, sharing, adaptation, distribution and
    reproduction in any medium or format, as long as you give appropriate credit to
    the original author(s) and the source, provide a link to the Creative Commons
    licence, and indicate if changes were made. The images or other third party material
    in this article are included in the article''s Creative Commons licence, unless
    indicated otherwise in a credit line to the material. If material is not included
    in the article''s Creative Commons licence and your intended use is not permitted
    by statutory regulation or exceeds the permitted use, you will need to obtain
    permission directly from the copyright holder. To view a copy of this licence,
    visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public
    Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies
    to the data made available in this article, unless otherwise stated in a credit
    line to the data. Reprints and permissions About this article Cite this article
    Bruno, A., Aury, JM. & Engelen, S. BoardION: real-time monitoring of Oxford Nanopore
    sequencing instruments. BMC Bioinformatics 22, 245 (2021). https://doi.org/10.1186/s12859-021-04161-0
    Download citation Received 05 January 2021 Accepted 04 May 2021 Published 13 May
    2021 DOI https://doi.org/10.1186/s12859-021-04161-0 Share this article Anyone
    you share the following link with will be able to read this content: Get shareable
    link Provided by the Springer Nature SharedIt content-sharing initiative Keywords
    Nanopore sequencing Real-time monitoring Web application Download PDF Sections
    Figures References Abstract Background Implementation Results and discussion Conclusion
    Availability of data and materials Abbreviations References Acknowledgements Funding
    Author information Ethics declarations Additional information Rights and permissions
    About this article Advertisement BMC Bioinformatics ISSN: 1471-2105 Contact us
    General enquiries: journalsubmissions@springernature.com Read more on our blogs
    Receive BMC newsletters Manage article alerts Language editing for authors Scientific
    editing for authors Policies Accessibility Press center Support and Contact Leave
    feedback Careers Follow BMC By using this website, you agree to our Terms and
    Conditions, Your US state privacy rights, Privacy statement and Cookies policy.
    Your privacy choices/Manage cookies we use in the preference centre. © 2024 BioMed
    Central Ltd unless otherwise stated. Part of Springer Nature."'
  inline_citation: '>'
  journal: BMC Bioinformatics
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: 'BoardION: real-time monitoring of Oxford Nanopore sequencing instruments'
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Baig M.J.A.
  - Iqbal M.T.
  - Jamil M.
  - Khan J.
  citation_count: '31'
  description: An open-source P2P energy trading platform facilitates energy trading
    amongst the peers. The proposed system provides real time data acquisition, monitoring
    and control of self-generated energy at a remote location. The trading activities
    are done on a web interface that uses a private Ethereum blockchain. A smart contract
    is deployed on the Ethereum blockchain and the trading activities performed on
    the web interface are recorded on a tamper-proof blockchain network. An internet
    of things platform is used to monitor and control the self-generated energy. Energy
    data is collected and processed by means of ESP32-S2 microcontrollers using field
    instrumentation devices which are connected to the voltage source and load. An
    open-source decentralized Peer-to-Peer (P2P) energy trading system, designed on
    the blockchain and internet of things (IoT) architecture is proposed. The hardware
    setup includes a relay, a current sensor, a voltage sensor, a Wi-Fi router and
    ESP32-S2 microcontroller. For data transfer the Message Queuing Telemetry Transport
    (MQTT) protocol is used over a local network. ESP32-S2 is set up as MQTT client
    and Node-Red IoT server is used as MQTT broker. Hypertext Transfer Protocol (http)
    request method is implemented to connect the Node-Red server with the web interface
    developed using React.JS library. The system design, implementation, testing,
    and results are presented in this paper.
  doi: 10.1016/j.egyr.2021.08.190
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract Keywords 1. Introduction 2. A brief overview of technologies
    3. The system description 4. Components of proposed peer to peer energy trading
    platform 5. Web interface and node-red IoT server 6. Implementation methodology
    7. Hardware design and implementation 8. Experimental setup for the proposed peer-to-peer
    energy trading platform 9. Testing and results 10. Conclusion 11. Future work
    CRediT authorship contribution statement Declaration of Competing Interest Acknowledgments
    References Show full outline Cited by (31) Figures (20) Show 14 more figures Tables
    (1) Table 1 Energy Reports Volume 7, November 2021, Pages 5733-5746 Research paper
    Design and implementation of an open-Source IoT and blockchain-based peer-to-peer
    energy trading platform using ESP32-S2, Node-Red and, MQTT protocol Author links
    open overlay panel Mirza Jabbar Aziz Baig a, M. Tariq Iqbal a, Mohsin Jamil a,
    Jahangir Khan b Show more Add to Mendeley Share Cite https://doi.org/10.1016/j.egyr.2021.08.190
    Get rights and content Under a Creative Commons license open access Abstract An
    open-source P2P energy trading platform facilitates energy trading amongst the
    peers. The proposed system provides real time data acquisition, monitoring and
    control of self-generated energy at a remote location. The trading activities
    are done on a web interface that uses a private Ethereum blockchain. A smart contract
    is deployed on the Ethereum blockchain and the trading activities performed on
    the web interface are recorded on a tamper-proof blockchain network. An internet
    of things platform is used to monitor and control the self-generated energy. Energy
    data is collected and processed by means of ESP32-S2 microcontrollers using field
    instrumentation devices which are connected to the voltage source and load. An
    open-source decentralized Peer-to-Peer (P2P) energy trading system, designed on
    the blockchain and internet of things (IoT) architecture is proposed. The hardware
    setup includes a relay, a current sensor, a voltage sensor, a Wi-Fi router and
    ESP32-S2 microcontroller. For data transfer the Message Queuing Telemetry Transport
    (MQTT) protocol is used over a local network. ESP32-S2 is set up as MQTT client
    and Node-Red IoT server is used as MQTT broker. Hypertext Transfer Protocol (http)
    request method is implemented to connect the Node-Red server with the web interface
    developed using React.JS library. The system design, implementation, testing,
    and results are presented in this paper. Previous article in issue Next article
    in issue Keywords Peer-to-Peer (P2P)Ethereum blockchainMessage Queuing Telemetry
    Transport (MQTT)Hypertext Transfer Protocol (http)Internet of things (IoT) 1.
    Introduction The proliferation of Distributed Energy Resources (DER) such as Photovoltaics
    (PV) systems, Battery Energy Storage Systems (BESS), Electric Vehicles (EV), Wind
    Energy Conversion System (WECS) along with advancements in information and communication
    systems technologies, has introduced a new electricity market (Alskaif et al.,
    2021). A significant demand for electric energy and the availability of low-cost
    renewable energy technologies has raised the number of prosumers in the electricity
    market. As a result, a considerable interest of selling or sharing electrical
    energy has been witnessed in the electricity market (Baig et al., 2020). Blockchain
    and internet of things has given a new shape to electricity market. Rather than
    rely on centralized authority, peers can now perform transactions on their own.
    Blockchain technology and the Internet of Things can boost the efficiency of peer-to-peer
    energy trading platforms. Now, consumers can buy energy on local energy markets,
    instead of having to buy it from utilities. Blockchain and internet of things-based
    energy trading platforms can be more efficient and controllable for prosumers.
    The immutable blockchain ledger can also provide a transparent energy and funds
    usage data in real-time. As the residential sector is increasingly adopting distributed
    energy resources, several new market approaches will be necessary. Market participants
    now prefer distributed generation and to sell electrical power, contrarily to
    the conventional electricity market. This emerging concept of prosumers now requires
    a state-of-the-art platform for energy trading. A platform that can provide full
    trading autonomy, the financial security and pricing liberty and to choose the
    best suitable time for trading sessions. The direct exchange of energy amongst
    consumers and prosumers is known as P2P energy trading. Over the past few years,
    peer-to-peer (P2P) trading has become an only option for consumers to participate
    actively in energy market. Peers can trade excess energy production with peers
    through peer-to-peer energy trading, which is beneficial for both parties (Soto
    et al., 2021). Consequently, their investment can yield a return. An important
    part of peer-to-peer energy trading is that it helps prosumers to trade their
    energy similar to goods and services. In addition, energy trading on a peer-to-peer
    basis can also help reduce peak demand on the grid, lowering the need for reserves,
    and reducing network outages (Tushar et al., 2020a). As described by the GridWise
    Architecture Council, P2P is also defined as transactive energy (TE), a system
    for dynamically managing supply and demand across the electric grid. The P2P platform
    industry is expected to generate revenues of over $4 billion by 2026 (AlAshery
    et al., 2021). A blockchain-based P2P energy trading system is presented in AlAshery
    et al. (2021). The system includes bilateral contracts, the Vickrey-Clarke-Groves
    (VCG) mechanism, an electronic commerce platform, and the ability to trade with
    the main grid. This multi-layered mechanism accommodates changes in electricity
    generation and consumption preferences. Furthermore, the VCG mechanism minimizes
    market power by ensuring that bids are truthful and transparent. To compensate
    for the disadvantage of VCG, namely, the unbalanced budget, different remedies
    are also proposed. In their description of the trading framework, the authors
    described it as multi-settlement and quasi-ideal. To evaluate the execution of
    proposed P2P frameworks and the solutions for the VCG’s inability to maintain
    balanced budgets, the authors conducted several case studies. An energy trading
    market concept that is fully P2P is presented in Alskaif et al. (2021), the study
    incorporates two methods of identifying market preferences. In the first strategy,
    excess supply and demand are matched, whereas in the subsequent method, the distance
    between participants is considered. Moreover, the two strategies are evaluated
    and compared in terms of the effect they have on the price and amount of traded
    locally energy. The study explains how P2P energy trading market can be developed
    onto the blockchain in a decentralized manner. The authors emphasized on P2P energy
    trading model for private houses, integrating electric heating model and optimization
    model. Electricity can be purchased and sold locally by plug-in hybrid electric
    vehicles (PHEVs) in smart grids by using a peer-to-peer (P2P) approach. The authors
    provide incentives to PHEVs so that local electricity demand balances with local
    fleets of PHEVs instead of traditional methods that distribute electricity long
    distances and through complex electricity networks. As part of the study, the
    authors examine a promising consortium blockchain technology to enhance transaction
    security without requiring any mediator. The proposed system illustrates the detailed
    operations of localized P2P electricity trading with the consortium blockchain
    method (PETCON). To maximize social welfare, an iterative double auction mechanism
    is used to determine the price of electricity and the amount of electricity traded
    among PHEVs. Using PETCON, authors increase security and privacy of transactions.
    The application of the double auction mechanism to a real map of Texas shows that
    social welfare can be maximized while protecting PHEV privacy (Kang et al., 2017).
    In another research article, an energy trade system that employs P2P energy trading
    while simultaneously considering demand response is presented. The energy market
    is conceptualized as a non-cooperative Stackelberg game amongst prosumers and
    auctioneers. Prosumers, as buyers, maximize social welfare by solving optimization
    problems. The auctioneer also boosts the average social welfare of sellers. The
    authors proposed a unique Stackelberg Equilibrium (SE) that is the ideal solution
    to the optimization problem. Blockchain technology is used by the authors to implement
    the proposed algorithm, which provides enhanced security and privacy protection,
    and demonstrates the feasibility of the P2P energy trading approach. This blockchain-based
    energy trading approach is also measured for throughput, latency, and running
    time (Doan et al., 2021). A latest research presents simulations results of P2P
    energy trading based on real-world data by introducing a market mechanism and
    a decentralized market clearing method with the blockchain integration. Markets
    and blockchain are two key components of the proposed platform. The market layer
    is based on a short-term pool-supported auction and is cleared through a unique
    decentralized Ant-Colony Optimization procedure. Using this market procedure,
    players’ privacy is preserved, and they can trade products between different time
    periods. Blockchain technologies facilitate real-time settlements through automated
    processes, security, and the implementation of smart contracts. In this study,
    the authors simulated energy trading, clearing markets, smart contract operation,
    and blockchain-based settlement conducted through a platform based on real-world
    data (Esmat et al., 2021). Ref. Vieira and Zhang (2021) examine the possibilities
    for self-governing peer-to-peer energy trading from within microgrids utilizing
    blockchain technologies and auction mechanisms. A continuous double auction framework
    and a uniform-priced double-sided auction framework are designed that both employ
    Ethereum’s smart contract functionality. A/B tests were performed on a real-time
    data to validate the proposed design. To compare the two frameworks, the authors
    presented a number of cost analyses. The authors emphasized a P2P trading platform
    that incorporates blockchain technologies and agent-based systems could revamp
    the current centralized energy grid. During peak hours, a central power system
    can decrease energy demand of its customers by using a peer-to-peer (P2P) energy
    trading approach. As a result, a cooperative Stackelberg game is devised, in which
    the central power system acts as the leader that determines a price during the
    peak demand period to compensate for prosumers not consuming energy from it. By
    contrast, prosumers act as followers and form coalitions with neighbors to take
    part in peer-to-peer energy trading to meet their energy needs in reaction to
    the leader’s decision. Stackelberg’s proposed game is examined for its properties.
    Because of the stability of prosumers’ coalitions, the game uses a unique and
    stable Stackelberg equilibrium. At equilibrium, the leader formulates its strategy
    using a closed-form expression, while the prosumers select their coalition structure.
    Peer-to-peer (P2P) energy trading is suggested in this paper to lower the total
    electricity demand of a central power system during peak hours. In this study,
    the authors propose an algorithm that facilitates the equilibrium solution between
    the centralized and the prosumer power systems. The proposed scheme has been proven
    beneficial in numerous case studies (Tushar et al., 2020b). With the help of Ethereum’s
    blockchain and smart contracts, the authors enabled peer-to-peer (P2P) energy
    trading amongst consumers and producers. Smart contracts reside on a blockchain
    shared by the participants, thus guaranteeing exact execution of trades, and keeping
    immutable records of transactions. The system eliminates the high costs and overheads
    of conventional server-based P2P energy trading. The study implements, Microgrid
    dynamic pricing to balance total supply and total demand, preventing double sales,
    automatic and autonomous operation (Song et al., 2021). A wealth of literature
    review has been carried out as a part of this research and some is presented here
    in this paper. Our research has not found any publications referring to the usage
    of a locally installed Node-Red IoT server for monitoring and controlling energy
    in a Peer-to-Peer energy trading system design. Moreover, the use of ESP32-S2
    micro-controller in our design, ensures that a local participants of P2P energy
    trading network can visualize the state of the process by visualizing data information
    on the Node-Red dashboard. A private Ethereum’s blockchain is also integrated
    with a web interface developed using React.JS library for performing trading activities
    on a locally installed server. This not only helps in performing trading activities
    but also to maintain the tamper-proof records of energy trading sessions. Both
    the servers are fully automated and interconnected with each other by means of
    http request method. The proposed platform is locally installed on a machine and
    can be accessed remotely. This article presents a novel peer-to-peer trading platform,
    with the following key contributions: • This paper presents an innovative Peer-to-Peer
    energy trading platform design using open-source resources with real time settlements,
    technical and economic efficiency. • Design and installation of server on a local
    machine and communication channel makes it useful for remote locations with no
    internet access. • Implementation of a Peer-to-Peer energy trading platform by
    installing a decentralized web interface, Ethereum blockchain, locally installed
    Node-Red IoT server hosted on a local network is the main feature. The fact that
    an open source, peer-to-peer energy trading network has never been seen before
    is novel to the best of our understanding. • After a thorough review of the available
    research, we present a straightforward and unique approach to the design and implementation
    of an IoT and blockchain-based open source P2P energy trading platform. Any future
    participant planning to carry out such an exercise will find this paper a useful
    guide. The remaining parts of the paper are arranged as follows. Section 2 of
    the paper presents an overview of the technologies used in this paper including
    blockchain, internet of things and MQTT protocol. Section 3 describes a brief
    overview of the proposed open-source IoT and blockchain-based Peer-to-Peer (P2P)
    energy trading platform. Section 4 represents the details of the components used
    for the design and implementation of the propose P2P energy trading platform.
    This includes ESP32-S2 microcontroller, relay, current sensor, voltage sensor,
    Energy storage system (ESS)/ battery and load. In Section 5 we discussed the web
    interface and IoT server and http request method to connect the servers. Node-Red
    flow, based on Node-Red visual programing language are also discussed in this
    section. Section 6 depicts the implementation methodology used in this paper.
    It describes how the required data is collected and energy trading sessions are
    performed. As a part of Section 7 system design, implementation and experimental
    setup are discussed. Section 8 includes the testing and results of the proposed
    P2P energy trading platform. In Section 9 discussion about the key features of
    the system is presented. In Section 10, we conclude the paper and Section 11 depicts
    the future work direction. 2. A brief overview of technologies Throughout Section
    2, the major technologies incorporated into the design and implementation of our
    proposed open-source peer-to-peer energy trading platform are briefly introduced.
    Ethereum blockchain and internet of things (IoT) are two of the technologies upon
    which P2P energy trading platform is based, as well as Message Queuing Telemetry
    Transport (MQTT), a lightweight protocol for IoT data transfer. 2.1. Blockchain
    technology A blockchain is made up of blocks put together in the form of a chain.
    Data from each of the participants in the network is stored in these blocks (Al-Fuqaha
    et al., 2015). This is done in a block format, called a set of transactions. Following
    their formation, these transactions are grouped into blocks and connected to one
    another in chains — along with the time stamp (Baig et al., 2020). These blocks
    are records of data that are continuously added into a distributed ledger called
    a blockchain (Tapscott and Tapscott, 2016). An additional layer of security is
    provided by this chain mechanism, even the smallest modifications invalidate subsequent
    blocks. Furthermore, if only the hash of the last block is verified, the validity
    of entire chain can be ascertained. Initial applications of blockchain were used
    to track economic transactions without requiring trusted intermediaries (such
    as banks). Even if its origins are in economic transactions, like Bitcoin, the
    blockchain has proven to be an applicable technology to other fields, when distributed
    approaches are the choice to centralized ones. For energy purchases or sales,
    blocks can be organized into tables with details such as seller ID, buyer ID,
    amount of transferred energy, duration, timestamp, and power profile (Di Silvestre
    et al., 2018). As part of this study, we have used a local Ethereum blockchain,
    which is provided by Ganache graphical user interface (GUI). Ganache GUI is a
    personal Ethereum blockchain which can be used for distributed application development.
    It ensures that dApps can be developed, deployed, and tested in a deterministic
    and secure environment (Ganache GUI documentation, 2021). Users can deploy smart
    contract and run tests using Ganache. Ganache also provides 10 accounts with 100
    fake Ethers in each account. These Ethers and accounts can be used to perform
    test runs. To manage the wallet and to perform transaction MetaMask is used which
    is a google chrome extension. Peers willing to use P2P energy trading platform
    can be connected to each other on a blockchain server using remote procedure call
    (RPC) protocol. Fig. 1 shows the overview of Ganache GUI, a local Ethereum blockchain
    used as a part of this research. The digital address of each account can be seen
    in Fig. 1 with 100 ETHS in each account. Each account is also associated with
    a unique private key that ensures the security of wallet. Download : Download
    high-res image (400KB) Download : Download full-size image Fig. 1. Blockchain
    server. 2.2. Internet of Things (IoT) In this high-tech age, the Internet of Things
    (IoT) has changed many traditional ways of living. IoT has allowed cities, homes,
    pollution control, energy conservation, smart transportation, and industries to
    undergo amazing transformations. We can sense the Internet of Things everywhere
    we go, constantly increasing our quality of life. Overall, IoT encompasses a wide
    variety of smart systems, structures, devices, and sensors (Kumar et al., 2019).
    Internet of Things (IoT) combines sensor, computing, embedded, and communication
    technologies. The Internet of Things aims to offer smooth services to anyone,
    anywhere, at any time. IoT is bringing the fourth major revolution following the
    internet and Information and Communication Technologies (ICT). Researchers and
    developers predict IoT will improve society’s well-being and industries more than
    the internet and ICT (Swamy and Kota, 2020). Basically, the internet of things
    (IoT) lets electronic, sensor, and software devices to interconnect with each
    other, as well as an operator, to facilitate the collection and sharing of real
    time data (Al-Fuqaha et al., 2015, Sultana and Wahid, 2019). It allows physical
    devices to be made smarter through the transformation of traditional forms into
    smart ones (Al-Fuqaha et al., 2015). Smart energy management systems, smart emergency
    response systems, smart healthcare systems, smart transportation and industrial
    automation, smart homes and smart cities, etc. have been developed in the recent
    years, utilizing the IoT model (Al-Fuqaha et al., 2015, Sultana and Wahid, 2019).
    Also shown in Fig. 2, various smart platforms are connected with an IoT platform.
    Node-Red has been selected for use as a preferred IoT platform. Locally installed
    Node-Red server on a private machine ensures platform’s security and privacy.
    Node-RED allows users to replace common coding tasks with visual drag-and-drop
    to connect web services and gadgets. Various components are linked together to
    create a flow using Node-Red editor. Download : Download high-res image (196KB)
    Download : Download full-size image Fig. 2. Internet of things platform. 2.3.
    Message Queuing Telemetry Transport (MQTT) protocol A lightweight data communication
    for machine-to-machine interaction can be achieved using Message Queuing Telemetry
    Transport (MQTT) protocol (Al-Fuqaha et al., 2015). MQTT’s 2-byte fixed header
    makes it ideal for internet of things applications, since it can handle applications
    having low bandwidths, low computing power, little memory, and low batteries,
    which are common in IoT applications (Kodali and Soratkal, 2016, Sahadevan et
    al., 2017). Andy Stanford–Clark of IBM and Arlen Nipper of Arcom (now Eurotech)
    initially developed MQTT protocol and now the Organization for the Advancement
    of Structured Information Standards (OASIS) recognize MQTT as an open standard
    (Dhar and Gupta, 2016). For the purpose of implementing MQTT, TCP/IP connection
    is required, with wired or wireless local area networks (Nuratch, 2018, Lawrence
    O. Aghenta and Tariq Iqbal, 2020). As part of the MQTT protocol, message delivery
    is graded according to Quality of Service (QoS) levels 0 through 2. As a result,
    the MQTT protocol is ideal for IoT applications with limited resources as a reliable
    data transfer protocol (Al-Fuqaha et al., 2015, Kodali and Soratkal, 2016, Sahadevan
    et al., 2017, Lawrence O. Aghenta and Tariq Iqbal, 2020). MQTT is therefore considered
    preferable to other protocols like REST, CoAP, API and HTTP, etc. MQTT also uses
    TCP/IP to communicate, only CoAP uses UDP (Al-Fuqaha et al., 2015, Lawrence O.
    Aghenta and Tariq Iqbal, 2020, Sultana and Wahid, 2019). There is an extensive
    discussion of the properties, benefits, and drawbacks of various IoT protocols,
    like MQTT, HTTP and CoAP in Al-Fuqaha et al. (2015) and Sultana and Wahid (2019).
    For the proposed open-source IoT and blockchain-based Peer-to-Peer Energy trading
    platform we have used MQTT, IPv4, TCP and IEEE 802.11 IoT protocol. MQTT protocol
    is used to transfer data from ESP32-S2 (MQTT client) to Node-Red IoT server. Whereas,
    personal smart devices (MQTT clients) can be used to subscribe topics to visualize
    data on Node-Red IoT server. An overview of the MQTT protocol is shown in Fig.
    3. Download : Download high-res image (138KB) Download : Download full-size image
    Fig. 3. Overview of MQTT protocol. 3. The system description Throughout this section,
    the authors describe the architecture of the proposed open-source P2P energy trading
    platform. The system configuration in Fig. 4. shows a web interface hosted on
    a local machine to perform energy trading tasks. The web interface is connecting
    to the Node-Red server used to monitor and control energy. Http request method
    is implemented to connect the two servers, so that an energy trading process can
    take place. To develop the communication link between the various components of
    the proposed system a Wi-Fi router is used. For system security, user authentication
    is set up on the router. Only authorized user can access the network. Energy storage
    system (ESS) represents a battery which is connected to a DC load. ESP32-S2 (MQTT
    client) publishes the sensor data (voltage and current) to Node-Red IoT server
    (MQTT Broker) after processing. This configuration also demonstrates a relay device
    that facilitates energy trading sessions. On receiving an energy demand, it starts
    energy transfer process and after the demand is successfully fulfilled it halts
    the process. This is done by means of an algorithm without any human intervention.
    The participating peers can access the system using personal devices on the same
    network. Download : Download high-res image (204KB) Download : Download full-size
    image Fig. 4. P2P energy trading platform architecture. 4. Components of proposed
    peer to peer energy trading platform 4.1. Sensors 4.1.1. ACS 712 hall effect current
    sensor ACS 712 Hall effect current sensor is used to measure load current using
    Hall Effect principle. It provides voltage isolation of 2.1 kVRMS and a low resistance
    conductor that is integrated into the sensor. Hall ICs convert the magnetic field
    generated by copper conductors into proportional output voltages by converting
    the current flowing through the copper conductors. As a result, an output voltage
    is produced which is proportional to the measured AC or DC current (Current Sensors
    ICs, 2021). This module is available to sense the current of 05 A, 20 A and 30
    A with the output sensitivity range of 66 mV/A to 185 mV/A at a supply voltage
    of 5VDC. It uses the ACS712ELCTR chip as its central component (Current Sensors
    ICs, 2021). To measure analog signals, the ESP32-S2 uses a maximum range 3.3VDC
    supply, so by connecting the Vcc pin ACS-712 Hall effect current sensor with the
    3.3 V pin of this sensor and selecting appropriate value of sensitivity accuracy
    of measured values is ensured. As a part of this study, we have used 20 A DC module.
    4.1.2. Voltage sensor ESP32 is a 13-bit device, and its ADC pins are capable to
    read 3.3 V. To convert the bus voltage of the proposed open-source P2P energy
    trading platform to the readable signal range of ESP32-S2 ADC pins, a simple voltage
    divider circuit is used in this project. Eq. (1) shows the voltage divider equation.
    (1) where ESP32-S2 ADC voltage (3.3) and Source voltage or Battery voltage (12
    V), Whereas and are calculated using and as a reference. With voltage divider
    circuit, the bus voltage of 12 V is converted to 3.3 V, which ensures the proposed
    design is capable to sense the bus voltage of the proposed platform. 4.2. ESP32-S2
    micro-controller ESP32-S2 a single core Wi-Fi microcontroller is designed by ESPRESSIF
    and featured with high performance, low power consumption, and a vast array of
    I/O (inputs and outputs). An integrated product featuring extremely low power
    consumption and 2.4 GHz Wi-Fi on a system-on-chip solution makes it ideal for
    IoT applications. The Wi-Fi solution is offered by this chip fully complies with
    the IEEE 802.11b/g/n protocol. There is a 32-bit Xtensa® LX7 processor on this
    chip that operates at 240 MHz. This device has a rich set of peripheral interfaces
    including I2S, I2C, UART, SPI interface, LED PWM, LCD, camera interface, ADC,
    touch sensor, DAC and temperature sensor, in addition to 43 GPIOs (General Purpose
    Inputs and Outputs). In addition, it supports full-speed USB On-The-Go (OTG),
    which allows USB communications (ESP32-S2-WROOM product details, 2021). 4.3. Wi-Fi
    router (communication channel) For data communication on the TCP/IP Wireless Network
    between ESP32-S2 (MQTT Client) and Node-Red server (MQTT Broker) and web interface
    we have used D-Link Router (DI-524 Airplus G). To establish a local Wi-Fi connection
    network, the router is used, since the ESP32-S2 microcontroller used in this project
    is compatible with TCP/IP and IEEE 802.11b/g/n Wi-Fi standards (Lawrence O. Aghenta
    and Tariq Iqbal, 2020, ESP32-S2-WROOM product details, 2021). In this way ESP32-S2
    publishes sensor data to Node-Red IoT server over MQTT protocol. Wi-Fi network
    connections is restricted to authorized persons using service set identifier (SSID)
    and password. For the successful testing and to obtain required results, we have
    also used a 12 V, 7.2 Ah/20HR battery as source voltage and 12 V, 50 W DC light
    bulb as load. We have also developed and interactive user interface to perform
    energy transactions using React.JS and a Node-Red server is set up to monitor
    and control the self-generated energy. More details about the server are presented
    in the following section of the paper. Table 1. presents the name of the components
    used to design an open-source P2P energy trading platform. Table 1. Components
    used in P2P energy trading platform. Module used Purpose of module in the design
    React.JS library To develop web interface of the system Node-Red server To monitor
    and control self-generated energy Ganache GUI To deploy local Ethereum blockchain
    ESP32-S2 Microcontroller Read sensors value and publish sensors data over MQTT
    ACS-712 hall effect current sensor To measure load current Voltage sensor To measure
    the voltage Relay To start or stop energy transfer 12 V, 7.2 Ah/20HR battery Source
    voltage 12 V, 50 W DC light bulb To serve as load Electric wires To connect the
    components of proposed design Jumper wires To connect the components of proposed
    design Breadboard Build the circuit 5. Web interface and node-red IoT server We
    have used React.JS (an open-source tool used to create user interfaces for web
    applications) library to create front-end/web interface for the proposed open-source
    P2P energy trading platform which is also locally installed on the system and
    accessible from http://localhost:3000/ and is integrated with MetaMask and Ganache
    GUI. The smart contract has been deployed on the local Ethereum blockchain. Reloading
    is made faster with the virtual document object model (DOM) since the virtual
    DOM allows rendering to be sped up. The React.JS framework is also used by many
    real-time applications, including Facebook and Netflix (Saundariya et al., 2021).
    The source code used for web interface, connectivity with Ganache GUI and smart
    contract are extensions of Ethereum Marketplace Step-by-Step Tutorial (2021) to
    develop an appropriate P2P energy trading platform. The detailed installation
    guide on the basic concept can be found at How to Build (2021). Participating
    peers of the proposed open-source P2P energy trading platform can access the user
    interface at http://localhost:3000/ to perform energy trading tasks. Fig. 5. shows
    an interactive and user-friendly interface developed for the P2P energy trading
    with a MetaMask plugin. The user interface is linked with local Ethereum blockchain
    on which smart contract is deployed. All the transaction performed are saved on
    an immutable blockchain network. As shown in Fig. 5. participating peers can bid
    their energy requirement and in response the peers with access energy can also
    post a selling notification with price and quantity of energy. This allows the
    buyer to buy energy on a most suitable price, which may be less than the bidding
    price of the buyer. The user interface developed for P2P energy trading platform
    is integrated with Ganache GUI a private Ethereum blockchain which can be accessed
    through MetaMask. Peers can access their respective wallets using MestaMask plugin.
    Once the peers perform any type of transaction on the user interface MetaMask
    plugin will pop up automatically on the screen and peers will reconfirm the amount
    charged for their particular transaction, that might be the energy purchasing
    price or gas used. Gas is a fee Ethereum charges to successfully perform the transactions
    on a blockchain network. Ethereum blockchain network charges a fraction of Ether
    in terms of fee. The price of gas is expressed in gwei, a unit of ETH, and each
    gwei equals 0.000000001 ETH (10-9 ETH). Rather than saying that your gas costs
    0.000000001 ether, you might say it costs 1 gwei (Ethereum Gas Fees, 2021). The
    MetaMask notification is shown in Fig. 6 is linked with http://localhost:3000/
    and allows to access accounts on a local Ethereum blockchain. For the security
    of the system the peers on the P2P energy trading platform use their own password
    to access the platform as shown in Fig. 6, in addition each account is associated
    with a unique private key, which allows the user to access their Ethereum wallets.
    The proposed system incorporates the features of a fully decentralized network,
    the participating peers have full liberty to decide the energy quantity and price
    without the involvement of any central authority. Peers can also delete the posted
    bid/offer if for some reason the transaction is not complete. Download : Download
    high-res image (276KB) Download : Download full-size image Fig. 5. Web interface
    of proposed P2P platform with MetaMask add on. Download : Download high-res image
    (128KB) Download : Download full-size image Fig. 6. MetaMask plugin. Node-RED
    an open-source solution was developed by IBM Emerging Technology. This web application
    is based upon Node.js (a server-side java scripting platform). Node-RED runs locally
    on http://localhost:1880. It also offers options to quickly build a live data
    dashboard using Node-RED user interface module. The user interface is accessible
    from http://localhost:1880/ui using a local browser (Kodali and Anjum, 2018).
    Node-Red flow can be made by using simple drag and drop options and flow can also
    be saved, import and export as a JSON file. Fig. 7 shows a Node-Red flow programmed
    using Node-Red visual programming language. The voltage, current, power and battery
    state f charge (SoC) data are transferred via MQTT protocol from the hardware
    components of the system and can be visualized on Node-Red user interface. Node-Red
    server is also installed on a local machine. Download : Download high-res image
    (256KB) Download : Download full-size image Fig. 7. Node-Red flow for data acquisition.
    For the fully automation of the P2P energy trading platform, we have implemented
    Hypertext Transfer Protocol (HTTP) request method. There are different http request
    methods like, DELETE, POST, PUT, GET, HEAD, OPTIONS, PATCH. We have used http
    POST method to catch the request from http://localhost:3000/. Once the participant
    peer of P2P energy trading platform sends a buy request to purchase energy, the
    amount of energy will be posted to Node-Red server and if the required amount
    of energy is greater than zero, it will be transferred automatically using a computer
    algorithm. The algorithm is implemented in the function node on Node-Red flow
    that will compare the energy demand with the amount of energy being transferred.
    Once the required amount of energy is transferred it will send a turn off message
    to the relay. In this way we have attained a fully automated P2P energy trading
    model on a local blockchain using open-source technology. Fig. 8. shows a Node-Red
    flow that facilitate energy trading with a http request node to get the value
    of required energy from the web interface of the proposed P2P energy trading platform.
    Once the Node-Red https request node gets the energy demand from the web interface
    and then the attached function node converts the JSON string into the raw value
    to compare with the MQTT energy node using the other function node shown in Fig.
    8 attached directly with MQTT energy node. When the energy demand and energy transferred
    amounts are equal, compared by implementing the algorithm in the function node
    it will actuate the relay to stop energy transfer process. Download : Download
    high-res image (145KB) Download : Download full-size image Fig. 8. Node-Red flow
    to facilitate energy trading. 6. Implementation methodology As a part of implementing
    the proposed open-source P2P energy trading platform current, voltage, and battery
    state of charge (SoC) data are measured and processed. Electrical wires are used
    to connect the current and voltage sensors to the system. The ESP32-S2 allows
    the measurement and collection of data using the Arduino IDE programs. ESP32-S2
    micro-controller has been programmed using Arduino IDE programs. Download : Download
    high-res image (481KB) Download : Download full-size image The PubSubClient MQTT
    library is used to configure ESP32-S2 micro-controller as an MQTT client and the
    measured and collected data are transferred to locally installed Node-Red server
    (MQTT Broker) via MQTT protocol over TCP/IP Wi-Fi communication link. Node-Red
    server receives data and displays it on the Node-Red dashboard. Algorithm 1 shows
    the pseudocode that encapsulates the data flow process. In Algorithm 1 pseudocode
    (line 1 to line 8) explains ESP32-S2 pins read the sensors values and calculate
    the values of battery state of charge (SoC), power, and energy. It also shows
    the connection process of ESP32-S2 with Wi-Fi and the MQTT broker. The process
    regarding the publishing of data to the MQTT broker is also shown in this part
    of the pseudocode. Line 9 to 13 presents the establishment of an ESP32-S2 connection
    with Wi-Fi and displays the connection status on the Arduino serial monitor with
    a data sampling time of 100 milli seconds. In this way data and information are
    processed and made available to facilitate energy trading process. In Algorithm
    2 pseudocode for energy trading process is explained. Once the peer shows the
    desire to buy energy and starts the process using the web interface of the proposed
    P2P energy trading platform. The information about amount of energy required is
    collected at Node-Red server and energy trading process will start. The algorithm
    then compares the amount of energy being transferred and required energy. Once
    the energy demand is fulfilled the relay will automatically disconnect the system
    and energy transfer process will stop. Download : Download high-res image (178KB)
    Download : Download full-size image 7. Hardware design and implementation In this
    section of the paper the authors have described the hardware design and implementation
    of the proposed P2P energy trading platform. We have used a voltage sensor to
    measure the real time storage battery voltage. This is done by means of voltage
    divider rule explained in Section 4.1.2 of this paper. The current sensor shown
    in Fig. 9 is used to measure current drawn by the load and the relay shown will
    start/stop the trading sessions automatically. ESP32-S2 micro-controller depicted
    in Fig. 9 is used to collect and process data and to control relay operation.
    Download : Download high-res image (409KB) Download : Download full-size image
    Fig. 9. Hardware design for the proposed P2P energy trading platform. Download
    : Download high-res image (317KB) Download : Download full-size image Fig. 10.
    Experimental setup for the proposed P2P energy trading platform. 8. Experimental
    setup for the proposed peer-to-peer energy trading platform As described in Section
    7 the design of proposed open-source P2P energy trading platform is set up for
    operation. The complete experimental setup of the system is shown in Fig. 10.
    This set up also uses a battery and load to practically demonstrate the energy
    transfer operation. The battery acting as source voltage of the system, is connected
    with the inputs of voltage sensors, while relay and the current sensor are set
    up between the battery and the load in series connection. The data can be collected
    by ESP32-S2 microcontroller using the sensors output pins and onwards transferred
    to the locally installed Node-Red IoT server. Node-Red IoT server receives energy
    demand form the web interface developed to initiate trading sessions and start
    energy transfer process automatically. The Node-Red is also connected with web
    interface to perform energy trading tasks (explained in Section 5 of this paper).
    Download : Download high-res image (317KB) Download : Download full-size image
    Fig. 11. Energy demands posted by the buyers. Download : Download high-res image
    (466KB) Download : Download full-size image Fig. 12. Available Energy posted by
    sellers. Download : Download high-res image (301KB) Download : Download full-size
    image Fig. 13. Blockchain status on server. 9. Testing and results The proposed
    open-source P2P energy trading platform has been tested to obtain the required
    results. Fig. 17 shows a flow chart of the proposed system. The flow chart gives
    a brief overview of complete energy trading process. The designed P2P energy trading
    setup is for 10 peers, there is no transaction delay, and the designed server
    can easily handle all requests. The participants may face delay in transactions
    on a public blockchain network like bitcoin due to a large ledger. However, in
    the proposed system, the ledger is small and maintained on a private server. It
    can process transactions immediately. Download : Download high-res image (340KB)
    Download : Download full-size image Fig. 14. Details of block 64 on the blockchain
    server. Download : Download high-res image (300KB) Download : Download full-size
    image Fig. 15. Details of block 63 on the blockchain server. Download : Download
    high-res image (82KB) Download : Download full-size image Fig. 16. Successful
    transaction status on web interface. Download : Download high-res image (780KB)
    Download : Download full-size image Fig. 17. Flow chart of proposed P2P energy
    trading platform. 9.1. Results The web interface incorporated with private Ethereum
    blockchain is developed using React.JS library and is connected to Node-Red server,
    and to the hardware side of the proposed open-source P2P energy trading platform.
    Once a peer bids energy demand, in response the other peers on the platform can
    post the available energy at their premises and the price they are willing to
    sell the energy on the web interface details explained in Section 5Fig. 5 of this
    paper. This gives the buyer an opportunity to choose amongst the various available
    options even with a greater amount of energy as required at a lesser price. All
    the energy demands posted by the peers will appear in the energy demand section
    as shown in Fig. 11. The other peers on the P2P energy trading platform can visualize
    the bids on HMIs (dashboards). In response they can post the available energy
    on the web interface at the price of their own choice. The amount of energy available
    to sell will show up in the buy energy section of the web interface. If a participating
    peer of the energy trading platform changes his mind after posting any trading
    action, there is also an option to delete. In Fig. 11 serial no. 4, a peer is
    willing to buy 1 Whr of energy at a price of 1 ETH. In response of his bid, he
    has an option to buy say 2 Whr of energy for 1 ETH, as shown in Fig. 12 serial
    no.12. Similarly, another participating peer (serial no 5 Fig. 11) of the proposed
    P2P energy trading platform willing to buy 2 Wh of energy at a price of 3 ETH.
    Whereas, he has the option to buy the required amount of energy at lesser price
    as shown in Fig. 12 serial no. 13. This platform gives an option to both buyers
    and seller to sell energy at their desired price according to the market response.
    All the trading actions performed by the peers on the web interface will appear
    on the local Ethereum blockchain. We have performed 66 transactions using the
    web interface and all the transactions are recorded on the blockchain server.
    The blocks are mined with the timestamps and can be explored to get the details
    of the transaction performed. Fig. 13 depicts, 66 blocks are formed in response
    of different trading tasks performed using web interface. Fig. 14 shows details
    of block 63. 0xB4C003Ed923FC3F971Deb 44d8d54e5ECEF50D189 is the address where
    the smart contract is deployed. The energy demand posted by the seller (0x27b62Dd
    1eD0394018B22c2D38b13E01C83e8b862) using the web interface and this will appear
    on the blockchain. A small amount of gas is used a fee to deploy the transaction
    on the blockchain server. A unique id is assigned to this transaction called transaction
    hash and can be seen in block 63 as TX 0x5955b6430bcfe2155abc1a 403d066e33610c4cf834bce48b4b0a32c2277e6c5d.
    Function in each block shows a product is created to sell in the energy market
    in response of the action performed at web interface. In Fig. 15 the inside details
    of block 64 are shown. When we explore block 64 of the blockchain, where a buyer
    purchases the required amount of energy with a buyer ID 0x83Aa632ECcB70d36F3d6566eB378c440902496b7
    the function now shows purchase product and an amount of 5 ETH has been charged
    with a some gas as a fee. The block 64 mined in response of energy purchased.
    It also has a unique transaction hash assigned to it. Once the trading sessions
    is complete it is recorded on the blockchain and can also be visualized on the
    web interface of the proposed P2P energy trading platform as shown in Fig. 16.
    After collecting the sensor data ESP32-S2 microcontroller transmits data to Node-Red
    IoT server which is responsible for monitoring and control of energy. The data
    collected and processed by ESP32-S2 microcontroller can be visualized on Node-Red
    dashboard as shown in Fig. 18. The On and Off buttons shown here are developed
    here to initiate or stop energy trading sessions using Node-Red dashboard only.
    Download : Download high-res image (273KB) Download : Download full-size image
    Fig. 18. Node-Red dashboard. The proposed P2P energy trading platform can be used
    for a small community of 10 houses within the range of local communication link
    setup through the Wi-Fi router, which can be increased and decreased depending
    on the community’s need. The Wi-Fi router used for the current project has a range
    of 328 Feet indoor and 1312 Feet outdoor. Discussion This section describes a
    few of the key characteristics of the proposed open-source IoT and blockchain-based
    Peer-to-Peer energy trading platform realized after successful testing of the
    system: • Blockchain and IoT based P2P energy trading platform The proposed open-source
    P2P energy trading platform is based on IoT platform and a private Ethereum blockchain.
    The proposed platform introduces vital components that a blockchain-based P2P
    energy trading system should include for proper energy monitoring, energy metering
    and money transaction in a decentralized manner. This includes blockchain-based
    web interface, Node-Red IoT server, ESP32-S2 microcontroller, Field instrumentation
    devices and MQTT protocol communication channel. • Energy Trading A web interface
    is developed for Human machine interactions. Real time settlements can be done
    using the web interface. This web interface can be accessed remotely to perform
    energy trading tasks. • Ethereum Blockchain: A private Ethereum blockchain has
    been used to deploy smart contract and maintain digital ledger of transactions.
    All the trading activities performed using the web interface are recorded on an
    immutable blockchain network with timestamps with all the security features of
    blockchain. • Fast Transactions: The proposed P2P energy trading platform can
    perform transaction on a blockchain network immediately. There is no delay in
    the transactions and system can handle all requests easily. • Data Acquisition:
    The proposed system is capable of data acquisition using field instrumentations
    devices commonly available in the market. • Monitoring and Control: Locally installed
    Node-Red IoT server is used to monitor and control self-generated power. Peers
    can monitor the available energy and are able to transfer energy in response to
    a buy call. • Security: The proposed P2P energy trading platform is restricted
    to authorized users only. To access the Ethereum wallet MetaMask require login
    credentials plus Ethereum wallet itself has a unique private key for each user
    which ensures authorized access to the funds and platform. To add to this local
    Wi-Fi network also require user authentication credentials. • Central Server:
    After implementing proposed P2P energy trading platform, there is no need for
    central servers to support the energy trading. • The ease of use of the system:
    The proposed P2P energy trading system is developed in user friendly manner. The
    participant of the platform does not require any training to use the system. 10.
    Conclusion In the current era where energy consumers are now becoming prosumers
    and a large amount of energy is generated by renewable energy resources particularly
    by using solar photovoltaic (PV) panels. The participants of energy market are
    exploring different ways to sell self-generated energy and looking for such platforms
    which can help them to get returns on their investment in renewable energy resources.
    Peer-to-Peer energy trading platforms are such platforms which makes renewable
    energy more accessible to everyone and participants can make better use of self-generated
    energy. Such platforms can help to grow renewable energy resources and can reduce
    extra burden on the power system. Also, the participants of P2P energy trading
    platform can get profit on their investment. In this article, the authors presented
    an advanced open-source P2P energy trading platform using internet of things and
    blockchain. We have demonstrated both the software and hardware implementations
    of our proposed P2P energy trading platform. The software implementation is done
    by installing web interface hosted on a local machine using React. JS library
    with Ganache GUI a private Ethereum blockchain. The web interface facilitates
    all the trading activities which are recorded on a blockchain network. For data
    monitoring and energy control we have used Node-Red server that is also hosted
    on a local machine. In hardware implementation we have used ESP32-S2 microcontroller
    with field instrumentation devices. From the testing and results we proved that
    the proposed P2P energy trading platform works perfectly. The system operates
    in a decentralized manner and all the transactions are documented on digital ledger.
    The system performs all the trading sessions properly and monitors energy data
    accurately. Although, the system has been tested on a small storage 12 V battery
    and 50 W load, customization of the system is also possible to facilitate energy
    trading to fulfill the energy needs of a household. 11. Future work As a future
    work the authors aim to implement this project to the remote location with poor/no
    electricity network and no internet access. Particularly smaller communities with
    abundant renewable energy sources. This project aims to facilitate such parts
    of the world where people are living without electricity or have electricity for
    shorter period during the whole day. We plan to add auto sale and purchase features
    along with full electrical connection details for a remote site in Pakistan. The
    increased range of communication link setup for this decentralized network is
    also the part of future work extension. Details will be published in future papers.
    CRediT authorship contribution statement Mirza Jabbar Aziz Baig: Methodology,
    Software and hardware implementation, Data curation, Writing – original draft.
    M. Tariq Iqbal: Conceptualization, Resources, Supervision, Funding acquisition,
    Writing – review & editing. Mohsin Jamil: Co-Supervision, Writing – review & editing.
    Jahangir Khan: Co-Supervision, Writing – review & editing. Declaration of Competing
    Interest The authors declare that they have no known competing financial interests
    or personal relationships that could have appeared to influence the work reported
    in this paper. Acknowledgments The authors would like to thank Mirpur University
    of Science and Technology (MUST), Mirpur-10250, Azad Jammu and Kashmir, Pakistan,
    and Higher Education Commission (HEC), Islamabad-44000, Pakistan for providing
    an opportunity to carry out this research under Human Resource Development program.
    References Al-Fuqaha et al., 2015 Al-Fuqaha A., Guizani M., Mohammadi M., Aledhari
    M., Ayyash M. Internet of things: A survey on enabling technologies, protocols,
    and applications IEEE Commun. Surv. Tutor., 17 (4) (2015), pp. 2347-2376, 10.1109/COMST.2015.2444095
    Fourthquarter View in ScopusGoogle Scholar AlAshery et al., 2021 AlAshery M.K.,
    et al. A blockchain-enabled multi-settlement quasi-ideal peer-to-peer trading
    framework IEEE Trans. Smart Grid, 12 (1) (2021), pp. 885-896, 10.1109/TSG.2020.3022601
    View in ScopusGoogle Scholar Alskaif et al., 2021 Alskaif T., Crespo-Vazquez J.L.,
    Sekuloski M., v. Leeuwen G., Catalao J.P.S. Blockchain-based fully peer-to-peer
    energy trading strategies for residential energy systems IEEE Trans. Ind. Inform.
    (2021) https://doi-org.qe2a-proxy.mun.ca/10.1109/TII.2021.3077008 Google Scholar
    Baig et al., 2020 Baig M.J.A., Iqbal M.T., Jamil M., Khan J. IoT And blockchain
    based peer to peer energy trading pilot platform 2020 11th IEEE Annual Information
    Technology, Electronics and Mobile Communication Conference (IEMCON) (2020), pp.
    0402-0406, 10.1109/IEMCON51383.2020.9284869 Google Scholar Current Sensors ICs,
    2021 Current sensors ICs (2021) Available online: https://www.digikey.ca/en/products/detail/allegro-microsystems/ACS712ELCTR-20A-T/1284594
    [Accessed on June 23, 2021] Google Scholar Dhar and Gupta, 2016 Dhar P., Gupta
    P. Intelligent parking cloud services based on IoT using MQTT protocol 2016 International
    Conference on Automatic Control and Dynamic Optimization Techniques (ICACDOT)
    (2016), pp. 30-34, 10.1109/ICACDOT.2016.7877546 View in ScopusGoogle Scholar Di
    Silvestre et al., 2018 Di Silvestre M.L., Gallo P., Ippolito M.G., Sanseverino
    E.R., Zizzo G. A technical approach to the energy blockchain in microgrids IEEE
    Trans. Ind. Inf., 14 (11) (2018), pp. 4792-4803, 10.1109/TII.2018.2806357 View
    in ScopusGoogle Scholar Doan et al., 2021 Doan H.T., Cho J., Kim D. Peer-to-peer
    energy trading in smart grid through blockchain: A double auction-based game theoretic
    approach IEEE Access, 9 (2021), pp. 49206-49218, 10.1109/ACCESS.2021.3068730 View
    in ScopusGoogle Scholar Esmat et al., 2021 Esmat A., de Vos M., Ghiassi-Farrokhfal
    Y., Palensky P., Epema D. A novel decentralized platform for peer-to-peer energy
    trading market with blockchain technology Appl. Energy, 282 (2021), Article 116123,
    10.1016/j.apenergy.2020.116123 View PDFView articleView in ScopusGoogle Scholar
    ESP32-S2-WROOM product details, 2021 Esp32-S2-WROOM product details (2021) Available
    online: https://www.espressif.com/sites/default/files/documentation/esp32_datasheet_en.pdf
    [Accessed on June 24, 2021] Google Scholar Ethereum Gas Fees, 2021 Ethereum gas
    fees (2021) Available online: https://ethereum.org/en/developers/docs/gas/ [Accessed
    on June 30, 2021] Google Scholar Ethereum Marketplace Step-by-Step Tutorial, 2021
    Ethereum marketplace step-by-step tutorial (2021) Available online: https://github.com/dappuniversity/marketplace
    [Accessed on May 30, 2021] Google Scholar Ganache GUI documentation, 2021 Ganache
    GUI documentation (2021) Available online: https://www.trufflesuite.com/docs [Accessed
    on June 23, 2021] Google Scholar How to Build, 2021 How to build a blockchain
    app with ethereum, web3.js & solidity smart contracts (2021) Available online:
    https://www.dappuniversity.com/articles/how-to-build-a-blockchain-app [Accessed
    on May 30, 2021] Google Scholar Kang et al., 2017 Kang J., Yu R., Huang X., Maharjan
    S., Zhang Y., Hossain E. Enabling localized peer-to-peer electricity trading among
    plug-in hybrid electric vehicles using consortium blockchains IEEE Trans. Ind.
    Inf., 13 (6) (2017), pp. 3154-3164, 10.1109/TII.2017.2709784 View in ScopusGoogle
    Scholar Kodali and Anjum, 2018 Kodali R.K., Anjum A. Iot based HOME automation
    using node-RED 2018 Second International Conference on Green Computing and Internet
    of Things (ICGCIoT) (2018), pp. 386-390, 10.1109/ICGCIoT.2018.8753085 View in
    ScopusGoogle Scholar Kodali and Soratkal, 2016 Kodali R.K., Soratkal S. MQTT Based
    home automation system using ESP8266 2016 IEEE Region 10 Humanitarian Technology
    Conference (R10-HTC) (2016), pp. 1-5, 10.1109/R10-HTC.2016.7906845 Google Scholar
    Kumar et al., 2019 Kumar S., Tiwari P., Zymbler M. Internet of things is a revolutionary
    approach for future technology enhancement: a review J. Big Data, 6 (2019), p.
    111, 10.1186/s40537-019-0268-2 Google Scholar Lawrence O. Aghenta and Tariq Iqbal,
    2020 Lawrence O. Aghenta S., Tariq Iqbal M. Design and implementation of a low-cost,
    open source IoT-based SCADA system using ESP32 with OLED, ThingsBoard and MQTT
    protocol AIMS Electron. Electr. Eng., 4 (1) (2020), pp. 57-86, 10.3934/ElectrEng.2020.1.57
    Google Scholar Nuratch, 2018 Nuratch S. Applying the MQTT protocol on embedded
    system for smart sensors/actuators and IoT applications 2018 15th International
    Conference on Electrical Engineering/Electronics, Computer, Telecommunications
    and Information Technology (ECTI-CON) (2018), pp. 628-631, 10.1109/ECTICon.2018.8619981
    View in ScopusGoogle Scholar Sahadevan et al., 2017 Sahadevan A., Mathew D., Mookathana
    J., Jose B.A. An offline online strategy for IoT using MQTT 2017 IEEE 4th International
    Conference on Cyber Security and Cloud Computing (CSCloud) (2017), pp. 369-373,
    10.1109/CSCloud.2017.34 View in ScopusGoogle Scholar Saundariya et al., 2021 Saundariya
    K., Abirami M., Senthil K.R., Prabakaran D., Srimathi B., Nagarajan G. Webapp
    service for booking handyman using mongodb, express JS, react JS, node JS 2021
    3rd International Conference on Signal Processing and Communication (ICPSC) (2021),
    pp. 180-183, 10.1109/ICSPC51351.2021.9451783 View in ScopusGoogle Scholar Song
    et al., 2021 Song J.G., Seon Kang E., Shin H.W., Jang J.W. A smart contract-based
    P2P energy trading system with dynamic pricing on ethereum blockchain Sensors,
    21 (6) (2021), p. 1985 [Online]. Available: http://dx.doi.org/10.3390/s21061985
    CrossRefGoogle Scholar Soto et al., 2021 Soto E.A., Bosman L.B., Wollega E., Leon-Salas
    W.D. Peer-to-peer energy trading: A review of the literature Appl. Energy, 283
    (2021), Article 116268, 10.1016/j.apenergy.2020.116268 View PDFView articleView
    in ScopusGoogle Scholar Sultana and Wahid, 2019 Sultana T., Wahid K.A. Choice
    of application layer protocols for next generation video surveillance using internet
    of video things IEEE Access, 7 (2019), pp. 41607-41624, 10.1109/ACCESS.2019.2907525
    View in ScopusGoogle Scholar Swamy and Kota, 2020 Swamy S.N., Kota S.R. An empirical
    study on system level aspects of internet of things (IoT) IEEE Access, 8 (2020),
    Article 188082-188134, 10.1109/ACCESS.2020.3029847 Google Scholar Tapscott and
    Tapscott, 2016 Tapscott D., Tapscott A. Blockchain revolution: How the technology
    behind bitcoin is changing money business and the world (2016) Google Scholar
    Tushar et al., 2020a Tushar W., Saha T.K., Yuen C., Smith D., Poor H.V. Peer-to-peer
    trading in electricity networks: An overview IEEE Trans. Smart Grid, 11 (4) (2020),
    pp. 3185-3200, 10.1109/TSG.2020.2969657 View in ScopusGoogle Scholar Tushar et
    al., 2020b Tushar W., et al. Grid influenced peer-to-peer energy trading IEEE
    Trans. Smart Grid, 11 (2) (2020), pp. 1407-1418, 10.1109/TSG.2019.2937981 View
    in ScopusGoogle Scholar Vieira and Zhang, 2021 Vieira G., Zhang J. Peer-to-peer
    energy trading in a microgrid leveraged by smart contracts Renew. Sustain. Energy
    Rev., 143 (2021), Article 110900, 10.1016/j.rser.2021.110900 View PDFView articleView
    in ScopusGoogle Scholar Cited by (31) Blockchain-based management of demand response
    in electric energy grids: A systematic review 2023, Energy Reports Show abstract
    Intelligent solar panel monitoring system and shading detection using artificial
    neural networks 2023, Energy Reports Show abstract Machine learning and internet
    of things in industry 4.0: A review 2023, Measurement: Sensors Show abstract Blockchain
    technology for distributed generation: A review of current development, challenges
    and future prospect 2023, Renewable and Sustainable Energy Reviews Show abstract
    Energy sharing and trading on a novel spatiotemporal energy network in Guangdong-Hong
    Kong-Macao Greater Bay Area 2022, Applied Energy Citation Excerpt : The proposed
    strategy can improve the overall economic performance of each building. Baig et
    al. [32] designed an IoT and blockchain based P2P energy trading platform for
    decentralized energy trading with automation, digitalization and security. Energy
    policy and economic incentives can play essential roles to support the renewable
    energy sharing and energy paradigm transition. Show abstract Economic Pricing
    in Peer-to-Peer Electrical Trading for a Sustainable Electricity Supply Chain
    Industry in Thailand 2024, Energies View all citing articles on Scopus © 2021
    The Authors. Published by Elsevier Ltd. Recommended articles Comprehensive analysis
    of the variables influencing the techno-economic optimization of medium temperature
    linear Fresnel collectors Energy Reports, Volume 7, 2021, pp. 5747-5761 Freddy
    Ordóñez, …, Rafael Soria View PDF Regulating data sharing across MQTT environments
    Journal of Network and Computer Applications, Volume 174, 2021, Article 102907
    Pietro Colombo, …, Engin Deniz Tümer View PDF Taking MQTT and NodeMcu to IOT:
    Communication in Internet of Things Procedia Computer Science, Volume 132, 2018,
    pp. 1611-1618 Monika Kashyap, …, Neeti Gupta View PDF Show 3 more articles Article
    Metrics Citations Citation Indexes: 30 Captures Readers: 164 View details About
    ScienceDirect Remote access Shopping cart Advertise Contact and support Terms
    and conditions Privacy policy Cookies are used by this site. Cookie settings |
    Your Privacy Choices All content on this site: Copyright © 2024 Elsevier B.V.,
    its licensors, and contributors. All rights are reserved, including those for
    text and data mining, AI training, and similar technologies. For all open access
    content, the Creative Commons licensing terms apply."'
  inline_citation: '>'
  journal: Energy Reports
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design and implementation of an open-Source IoT and blockchain-based peer-to-peer
    energy trading platform using ESP32-S2, Node-Red and, MQTT protocol
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Sun L.
  - Chen Y.
  - Cheng Q.
  - Zhu B.
  - Chen C.
  - Hou X.
  citation_count: '1'
  description: In order to solve the problem of interconnection and communication
    security of distributed energy resources (DER) monitoring system with different
    ownership, the virtual power plant (VPP) can effectively monitor and control DERs.
    this paper constructs the information model of DER monitoring terminal based on
    IEC 61850-7-420, and studies the XMPP mapping to realize the information model
    and real-time data communication service. The built-in security mechanisms TLS
    (Transport Layer Security) and SASL (simple authentication and security layer)
    of XMPP can ensure the security of information transmission. This paper builds
    a test platform to test the transmission performance of XMPP mapping, and the
    results show that XMPP can meet the security communication requirements of DER
    monitoring system.
  doi: 10.1109/ICCEAI52939.2021.00013
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2021 International Conference... Communication
    Application of Distributed Energy Resources Monitoring System Based on XMPP Publisher:
    IEEE Cite This PDF Lingyan Sun; Yu Chen; Qian Cheng; Baihan Zhu; Changming Chen;
    Xiaoning Hou All Authors 1 Cites in Paper 126 Full Text Views Abstract Document
    Sections I. Introduction II. Communication Requirements of Der Monitoring System
    III. Information Model of Der Monitoring Terminal IV. Information Mapping of Der
    Monitoring Terminal Based on XMPP V. Test Verification Show Full Outline Authors
    Figures References Citations Keywords Metrics Abstract: In order to solve the
    problem of interconnection and communication security of distributed energy resources
    (DER) monitoring system with different ownership, the virtual power plant (VPP)
    can effectively monitor and control DERs. this paper constructs the information
    model of DER monitoring terminal based on IEC 61850-7-420, and studies the XMPP
    mapping to realize the information model and real-time data communication service.
    The built-in security mechanisms TLS (Transport Layer Security) and SASL (simple
    authentication and security layer) of XMPP can ensure the security of information
    transmission. This paper builds a test platform to test the transmission performance
    of XMPP mapping, and the results show that XMPP can meet the security communication
    requirements of DER monitoring system. Published in: 2021 International Conference
    on Computer Engineering and Artificial Intelligence (ICCEAI) Date of Conference:
    27-29 August 2021 Date Added to IEEE Xplore: 04 October 2021 ISBN Information:
    DOI: 10.1109/ICCEAI52939.2021.00013 Publisher: IEEE Conference Location: Shanghai,
    China Funding Agency: SECTION I. Introduction Virtual power plant (VPP) can realize
    cross regional aggregation of distributed energy resources (DER) through measurement,
    communication and other technologies without changing the grid connection form
    of distributed energy resources (DER), so as to maximize the overall benefits
    of power grid. In order to give full play to the benefits of DERs, VPP is often
    used to achieve effective monitoring of DERs. However, DERs is widely distributed
    and has various means of communication. In order to effectively solve the communication
    and security problems between different ownership DERs from power enterprises
    and power energy providers, it is necessary to establish the information model
    and communication service model of DERs monitoring system, so as to realize the
    interconnection between different ownership of DERs and the timely and effective
    monitoring and management of DERs by VPP. IEC 61850 standard standardizes the
    communication service of distribution monitoring equipment through information
    model and communication service mapping. In the aspect of information model, IEC
    61850-7-420 standardizes the logical equipment and logical nodes of DER. Reference
    [1] proposes the specific design and implementation of general interface of DER
    based on IEC 61850–7-420, and reference [2] studied the mapping of logical nodes
    defined by IEC 61850-7-420 to physical devices of CIM model, and establishes the
    CIM model of DER electrical connection point and fuel cell. In terms of communication
    service, IEC 61850-7-2 defines abstract communication service interface (ACSI).
    In terms of data transmission, on the one hand, it is communication medium. Operation
    and control specification for distributed resources connected to distribution
    network stipulates that the communication channel should adopt optical fiber special
    network, distribution network carrier, wireless private network and wireless public
    network, optical fiber is the most ideal choice because of its fast transmission
    speed and long transmission distance; on the other hand, communication mapping
    is the most ideal choice. On the other hand, the existing communication mapping
    protocol is mainly used. Including MMS, IEC 61850-5-101/104, Web Services, GOOSE
    and XMPP, among which MMS, Web Services, IEC 60870-5-101/104 and other protocols
    have not effectively solved the communication security problems in the distribution
    network. Considering the storage and calculation capacity of distribution terminals,
    It is difficult to solve the security problems by IEC 62351 standard when using
    GOOSE communication in distribution network[3]. Meanwhile, 101/104 mapping and
    GOOSE in IEC 61850 only support some ACSI service models[4]. In the distribution
    Internet of things, XMPP, MQTT, HTTP, COAP and other service mapping protocols
    are used to solve the interconnection problem of terminals, but MQTT is relatively
    complex; the real-time performance of HTTP protocol is poor; COAP protocol is
    not suitable for the DER monitoring scenario; in order to effectively realize
    the interconnection of terminal equipments of distribution network, IEC TC57 working
    group has formulated IEC 61850 8–2 protocol about XMPP, reference [5] and reference
    [6] are concerned with the mapping method and implementation of XMPP. The application
    of XMPP in distributed feeder automation is studied in [7], which proves that
    XMPP can satisfy the slow distributed FA. The reference [3] proposed a mapping
    scheme based on the combination of XMPP and GOOSE over UDP, which verified that
    the mapping scheme could meet the real-time requirements of distributed FA, but
    the application of XMPP in the DER monitoring system is still to be further studied.
    According to the requirements and characteristicsof grid connected DER, this paper
    studies the communication application of DER based on XMPP, establishes the information
    model of DER monitoring terminal based on the logical node of DER defined by IEC
    61850-7-420, uses the working mechanism of XMPP to realize the interconnection
    of different power enterprises, and solves the security problem of DER communication
    through the built-in security mechanism of XMPP. Finally, a test system is built
    to verify the transmission performance of XMPP. SECTION II. Communication Requirements
    of Der Monitoring System DER refers to a small-scale power generation system with
    power less than 50MW, which is relatively dispersed and compatible with the surrounding
    environment and connected in the distribution network, the capacity of DER in
    low voltage distribution network is generally not more than 10MVA [8]. In distribution
    network, the distributed DER achieves unified scheduling through VPP. Normally,
    the analog quantity, status quantity and other data of DER are acquired through
    supervisory control and data acquisition (SCADA) system and sent to VPP regularly.
    It realizes efficient aggregation and optimization utilization of distributed
    DER through VPP. When the DER monitoring equipment detects abnormal data or an
    isolated operation state, the switch controlled at the connection point or the
    public connection point is disconnected to prevent the rejection, misoperation
    and reclosing of the distribution network caused by the DERs. When the detected
    data is restored to normal, the DER monitoring equipment will communicate to the
    control center to request the resumption of connection. and restore the connection
    of DERs within the specified time. In order to unify the technology of DER access
    to distribution network, state grid corporation of China combines the current
    situation of DERs in China, refer to IEEE 1547 and DER standards of Germany, the
    United States and other countries, the DER specification applicable to 35kV and
    below in China has been formulated (reference [9]–[10]). and DER specifications
    applicable to 10kV and below (reference [11]–[13]), providing normative requirements
    for DER access to distribution network in China. The fastest isolation time required
    is 200ms, for specific requirements, please refer to [14]. There are a large number
    of DER terminal devices. In order to meet the requirements of practical application,
    different power enterprises and power energy suppliers have extended the protocol
    based on serial communication. Due to the different understanding of each manufacturer,
    private information model and communication mechanism are formed, resulting in
    the poor ability of exchanging information and correctly using information among
    devices of the same or different manufacturers, unable to realize interoperability,
    in order to effectively realize VPP monitoring and management of DER monitoring
    terminal, it is necessary to establish standard information model and standard
    service mapping. SECTION III. Information Model of Der Monitoring Terminal General
    technology of information modeling is recognized as the most effective method
    of management information exchange. It provides standardized semantics, syntax
    and hierarchy for data exchanged between different devices and systems. IEC TC57
    working group formulates IEC 61850–7 series of standards provide international
    standard support for the standardization of information model of substation automation,
    large hydropower plants and DER. The information modeling in distribution automation
    still needs further research. A. Analysis of Information Interaction Requirements
    of Der Monitoring Terminals DER monitoring system is divided into three layers:
    main station layer, terminal layer and power layer. The main station layer is
    the VPP based on DER, which mainly analyzes and processes the data from the DER
    monitoring terminal, and then issues control commands. The terminal layer is the
    DER monitoring terminal, which completes the processing of the collected data
    of electric energy meter, detector or sensor, uploads the collected data and executes
    the control commands of the main station layer. The power layer is mainly DER
    equipments. The main functions of DER monitoring system are: (1) monitoring function
    for teleindication, remote communication, remote control, (2) alarm and protection,
    (3) historical data storage and query, (4) configuration file receiving and refreshing.
    In the system shown in Fig. 1, if DER is abnormal, the roles involved in the realization
    of fault isolation and recovery function of DER include: DER, protection device
    (DER and distribution network connection protection), DER monitoring terminal
    and VPP. Next, combined with the fault handling and recovery process of DER, the
    process of information interaction of DER is analyzed. Figure1. Der fault removal
    and recovery timing diagram Show All B. Modeling of Der Monitoring Terminal In
    order to standardize the information model, the distribution automation system
    can meet different functional requirements by creating or expanding new logical
    nodes. Different combinations of logical nodes can realize different functions.
    IEC 61850-7-420 defines the logical nodes related to DER, and makes corresponding
    combinations according to the functions of DER monitoring terminals, the specific
    description of logical nodes is defined in IEC 61850-7-420. IEC TC57 working group
    to develop IEC 61850-7-420 based on LPHD, LLN0, relevant logical node at electrical
    connection point and logical node of logical equipments of DER power generation
    system, the DER logical nodes of reciprocating engine, fuel cell, photovoltaic
    system is established by expanding or building new logical nodes. The DER monitoring
    system realizes the monitoring of the DER by monitoring the ECP of the DER equipment
    and the DER unit controller. The related logical nodes are shown in Tab. 1. The
    DEROpMode attribute of DOPA authorizes the operation mode, while different attributes
    of DOPM represent different operation modes. The logical nodes realize different
    functions through different attributes [15]. Based on the logical nodes defined
    by IEC 61850-7-4 and IEC 61850-7-420, the information model of DER monitoring
    terminals is established. The information model of DER monitoring terminals is
    shown in Fig. 2. In order to be compatible with different types of DER terminals,
    it is necessary to decompose the application function and establish the standard
    information object model and service model with appropriate logical nodes, but
    the established model needs to be transmitted through the standard mapping mechanism
    and specific communication protocol. Figure2. Der monitoring terminal information
    modeling Show All SECTION IV. Information Mapping of Der Monitoring Terminal Based
    on XMPP XMPP is an open source real-time communication protocol based on extensible
    markup language (XML), which can realize interconnection. Its built-in security
    protocol ensures communication security. At present, XMPP has been standardized
    in IEC 61850-8-2, but how to use it in distribution network still needs to be
    studied. A. Mapping Mechanism of Xmpp When XMPP is used for information model
    mapping, bilateral application association should be adopted. First, TCP / IP
    connection is established, and XML stream is opened through TCP. Once TCP connection
    is established, The XMPP client and XMPP server need to STARTTLS negotiate based
    on TLS to ensure the security of the transmitted data. After security authentication,
    the unique jabber identifier (JID) of XMPP client and XMPP server should be determined,
    The JID is obtained through the communication between the client and the server,
    and the server needs to ensure that the JID conforms to the address format defined
    in [XMPP-ADDR1. XMPP adopts C / S and S / S mode in DER monitoring system, and
    adopts TCP / IP connection. The architecture of XMPP in DER monitoring system
    is shown in Fig. 4. Different information is mapped into different message stranzas.
    XMPP defines three different message stranzas (XML), namely < message >, < iq
    >, < presence >) [16], information is encapsulated as a message stranzas and transmitted
    in an XMT, stream when mapping. Figure3. Xmpp architecture in der system title
    Show All XMPP adopts message confirmation mechanism and heartbeat mechanism to
    ensure the reliability and stability of communication, and adopts message delivery
    receipts (XEP-0184) to ensure the reliability of data transmission. When the network
    is blocked or the communication is unstable, the confirmation message may be lost
    or delayed, By adding the session identifier (session_ID) and message number (message_ID)
    attributes, the session_ID remains the same in the same session. Each time a message
    is confirmed, it contains a message_ID. The acknowledgement message of each message
    can be determined by the message_ID order. The sender judges the accuracy of the
    data by comparing the message sequence number (message_next) defined by the receiver
    to ensure the reliability of the data transmission between the sender and the
    receiver. B. Information Safety In order to ensure the communication security
    of the DER monitoring system, it is necessary to implement effective security
    protection for XMPP from client to server and server to server. XMPP achieves
    the security of XMPP communication through built-in TLS and SASL security mechanisms.
    TLS is located in the transmission layer, mainly used for the encryption of communication
    channel, which is divided into two layers, and the upper layer can realize security
    authentication. The lower level cipher group can be used provide a reliable mechanism
    to ensure the integrity of data. TLS can realize the functions of certificate
    authentication, data encryption and decryption, and prevent eavesdropping and
    preventing middleman attacks in information transmission. Since the external mechanism
    of SASL is adopted on the certificate during the negotiation of TLS and authentication
    information needs to be sent during SASL negotiation, so the STARTTLS negotiation
    based on TLS should be completed before SASL negotiation. STARTTLS negotiation
    and SASL negotiation are required for the specific information flow of the business,
    refer to the [6]. SASL provides authentication and data security services, which
    provides a variety of authentication mechanisms (such as GSSAPI, PLAIN, etc.),
    and SASL not only supports the extension of the old mechanism of new protocols,
    but also adds new mechanisms. XMPP protocol can use any mechanism through the
    interface of SASL abstraction layer. SASL involves authentication and authorization.
    The authorization identity identifier is the identity of the client. If it is
    empty, the client is the identity associated with the server; if it contains the
    authorization identity, the client represents the identity represented by the
    string. The client and server can choose the appropriate authentication mechanism
    through SASL negotiation to complete the authentication. At the same time, SASL
    mechanism also provides the data security service that supports the data integrity
    and data confidentiality service. The security of XMPP information transmission
    can be realized through the built-in TLS and SASL. SECTION V. Test Verification
    In order to verify the real-time performance of XMPP transmission information
    model and service mapping, the test system as shown in Figure 5 is built, which
    is composed of 8 SICOM3000 ethernet switches, 1 router, 7 PCs and related software.
    PC1 is installed with instant messaging server openfire to simulate XMPP server,
    and uses Web page to realize management and configuration, which can support tens
    of thousands of terminals online at the same time, PC2-PC7 is used as the client
    of XMPP. PC2 and PC7 are used to simulate the DER monitoring terminals. The transmission
    delay of XMPP is tested by sending and receiving data between PC2 and PC7. PC3
    and PC6 are used to simulate the other online users of the server. PC8 and pC9
    are used to simulate the background traffic. 512 online users are simulated in
    the test system to produce the background traffic in the network. The development
    language of XMPP client is Java, and the program development is based on Smack
    class library for secondary development. Figure4. Xmpp test system Show All XMPP''s
    delay test adopts ping-pong test method. Divide the time difference between PC2''s
    receiving data packet and sending data packet by 2 as the data transmission time,
    and send 5000 groups of messages of different sizes. Test whether there is secure
    encryption and the transmission delay of different message sizes with 30% load
    rate of secure encryption is shown in Fig. 6. It can be seen from the figure that
    the transmission delay with secure encryption is affected by XMPP service when
    the load rate is 30%, the average transmission delay with secure encryption increases
    with the increase of message size. Figure5. With or without security encryption
    and a load rate of 30% for different message size transmission delays Show All
    The usual XMPP packets are in the thousands of bytes [7]. Taking message size
    as 8244 bytes as an example, the average transmission delay is 7.56ms, the maximum
    transmission delay is 38.5ms, the main frequency of CPU is 2.50Hz, and the processor
    is PC of Intel Core i5-7200U for encryption and decry ption delay test. The average
    transmission delay of encryption and decryption is 0.34ms, When converted to the
    core board of DER monitoring terminals using Freescale MCIMX283/287 processor
    and main frequency of CPU of 454MHz, the average transmission delay of encryption
    and decryption is about 1.92ms after conversion according to CPU main frequency.
    The complete transmission delay includes encryption delay, link transmission delay
    and decryption delay of receiving end when XMPP is used for information transmission.
    Therefore, the complete encryption and decryption average transmission delay of
    8244 bytes message is 11.4ms. According to section 1.2, it can be seen that the
    response time of DER protection action is less than 200ms, while the average transmission
    delay of 8244 bytes is 11.4ms and the maximum transmission delay is 42.34ms. It
    can meet the communication requirements of the DER monitoring system. When the
    network is blocked, the transmission delay increases with the increase of network
    load rate, the load rate of distributed control is generally not more than 30%
    [14], the average transmission delay is not more than 20ms and the maximum transmission
    delay is 88.94ms, which still meets the real-time requirements of DER monitoring
    system communication. IEC 61850-5-101/104 is recommended for the communication
    of DER in the functional specification for monitoring systems of distributed resources
    interconnected with distribution network. The reference [17] introduces the use
    of GOOSE mechanism to transmit real-time control data in DER, Although IEC 61850-5-101/104
    and GOOSE mechanism are better in real-time, they do not solve the problem of
    communication security effectively. In this paper, XMPP server processing delay
    and link transmission delay increase the transmission delay time when XMPP is
    used for information transmission, but its transmission delay still meets the
    communication requirements of the DER monitoring system. Because the distributed
    control load rate is generally no more than 30% [18], After testing, the realtime
    performance of XMPP can still meet the real-time requirements of DER monitoring
    system. Meanwhile, the internal security mechanism TLS can ensure the security
    of communication channel, SASL can realize authentication. In contrast, XMPP can
    meet the requirements of the DER monitoring system under the premise of ensuring
    security. SECTION VI. Conclusion DER has a wide distribution area and various
    communication conditions. The grid-connected monitoring system needs to solve
    the communication security problems among the control center, VPP and DER equipments
    and realize the interconnection of DER equipments from different manufacturers.
    This paper is based on IEC 61850–7 -420 establishes the information model of DER
    monitoring terminals, studies the communication mapping of XMPP in DER monitoring
    system, and solves the security problem of information transmission of DER monitoring
    system through the built-in TLS and SASL mechanism of XMPP. The test results show
    that the transmission delay of XMPP can meet the requirements of DER monitoring
    system, and provides a safe and effective mapping method for DER monitoring terminals.
    The next stage will be further improved the communication performance of XMPP
    in specific engineering applications is studied. ACKNOWLEDGMENT The work was supported
    by Key project of smart grid technology and equipment of national key research
    and development plan of China (No. 2016YFB0900600) and Technology Projects of
    State Grid Corporation of China (No. 52094017000W). Authors Figures References
    Citations Keywords Metrics More Like This T-Pack: Timed Network Security for Real
    Time Systems 2021 IEEE 24th International Symposium on Real-Time Distributed Computing
    (ISORC) Published: 2021 Static Security Optimization for Real-Time Systems IEEE
    Transactions on Industrial Informatics Published: 2009 Show More IEEE Personal
    Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED
    DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION
    TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732
    981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility
    | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap |
    IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s largest
    technical professional organization dedicated to advancing technology for the
    benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - 2021 International Conference on Computer Engineering and
    Artificial Intelligence, ICCEAI 2021
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Communication application of distributed energy resources monitoring system
    based on XMPP
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Zhang Q.
  - Cui Z.
  - Yan L.
  - Xia Z.
  - Wang H.
  citation_count: '0'
  description: Electrical resistance tomography (ERT) is an efficient tomographic
    technique for the online imaging of industrial processes, primarily due to its
    advantages of non-radiation, realtime visualization and specific capability in
    performing measurements on opaque fluids. In the case of industrial applications,
    it requires that both the ERT hardware and software should be as reliable and
    flexible as possible. However, most ERT systems still employ the integrated platform,
    i.e., the measurement system and image reconstruction computer being placed in
    a short-distance, usually via a serial communication. It is usually not a good
    choice to employ the integrated platform, wherever the intrinsic safety is required.
    Therefore, an ERT platform that can realize remote data perception, dynamic data
    transmission and real-time data analysis is presented, which features Internet
    of Things (IoT) capability. The combination of the ERT system and the IoT provides
    a convenient and standardized interface between the on-site ERT hardware and remote
    monitoring devices. The measurements are made by the dedicated ERT hardware, which
    can be sent via Ethernet to and further processed by a highperformance workstation/server.
    The server performs the image reconstruction algorithms and data post-processing
    tasks. The HTTP protocol is also deployed in the server, from which the tomographic
    images and numerical data can be synchronously queried and displayed on the remote
    clients. Experimental results showed that the average signal-to-noise ratio of
    the system can achieve 66.9 dB at the applied frequency of 128 kHz, and the acquisition
    rate can reach 60 frames per second. The Web can be updated in every 0.1 second
    from a smart device. In the long term test, the proposed platform has also demonstrated
    high reliability and performance.
  doi: 10.1109/I2MTC50364.2021.9459820
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2021 IEEE International Instr... Design
    and Implementation of IoT Platform for Electrical Resistance Tomography System
    Publisher: IEEE Cite This PDF Qian Zhang; Ziqiang Cui; Long Yan; Zihan Xia; Huaxiang
    Wang All Authors 81 Full Text Views Abstract Document Sections I. Introduction
    II. System Design III. Results and Discussions IV. Conclusions Authors Figures
    References Keywords Metrics Footnotes Abstract: Electrical resistance tomography
    (ERT) is an efficient tomographic technique for the online imaging of industrial
    processes, primarily due to its advantages of non-radiation, realtime visualization
    and specific capability in performing measurements on opaque fluids. In the case
    of industrial applications, it requires that both the ERT hardware and software
    should be as reliable and flexible as possible. However, most ERT systems still
    employ the integrated platform, i.e., the measurement system and image reconstruction
    computer being placed in a short-distance, usually via a serial communication.
    It is usually not a good choice to employ the integrated platform, wherever the
    intrinsic safety is required. Therefore, an ERT platform that can realize remote
    data perception, dynamic data transmission and real-time data analysis is presented,
    which features Internet of Things (IoT) capability. The combination of the ERT
    system and the IoT provides a convenient and standardized interface between the
    on-site ERT hardware and remote monitoring devices. The measurements are made
    by the dedicated ERT hardware, which can be sent via Ethernet to and further processed
    by a high-performance workstation/server. The server performs the image reconstruction
    algorithms and data post-processing tasks. The HTTP protocol is also deployed
    in the server, from which the tomographic images and numerical data can be synchronously
    queried and displayed on the remote clients. Experimental results showed that
    the average signal-to-noise ratio of the system can achieve 66.9 dB at the applied
    frequency of 128 kHz, and the acquisition rate can reach 60 frames per second.
    The Web can be updated in every 0.1 second from a smart device. In the long term
    test, the proposed platform has also demonstrated high reliability and performance.
    Published in: 2021 IEEE International Instrumentation and Measurement Technology
    Conference (I2MTC) Date of Conference: 17-20 May 2021 Date Added to IEEE Xplore:
    28 June 2021 ISBN Information: ISSN Information: DOI: 10.1109/I2MTC50364.2021.9459820
    Publisher: IEEE Conference Location: Glasgow, United Kingdom Funding Agency: SECTION
    I. Introduction ELECTRICAL resistance tomography (ERT) is a tomographic imaging
    technique for monitoring the multiphase flow status in the industrial processes.
    The underlying working principle of ERT is that it could provide the qualitative
    estimation on the internal structures of investigated flows by collecting inter-electrode
    impedance from its sensor array [1]. Many researchers have discussed the feasibility
    of ERT in the industrial processes, including the fluidization [2], separation
    [3], [4], mixing [5], [6] and conveying processes [7], [8]. In the past decades,
    most ERT systems are still restricted to laboratory environments, where the image
    reconstruction computer and measurement system can be placed next to the investigated
    pipe/vessel. The massive deployments of ERT instruments in the industrial environment
    have never been reported, which is partly due to the limitation in system structure
    and data link distance. The tomographic systems that optimize for laboratory use
    often adopt easy-to-implement and a high-rate serial interface for data communication,
    including CY7C68013a (Cypress Inc.), FT232R (FDTI Chip Inc.), FireWire (IEEE 1394),
    RS-232 transceivers. Also, it is a common measure to integrate the measurement,
    image reconstruction and data post-processing functions into one system, in which
    the data transmission between measurement hardware and image reconstruction hardware
    can be achieved by the internal buses, i.e., the PXI/CPCI and PCMIA bus [9]. To
    achieve a higher data link, i.e., above 1 Mbps, the distance between the instrument
    and the host computer should be within the range of 20 meters. In addition, the
    hardware drivers for high-speed USB and FireWire [10] interfaces usually require
    frequent updates as the operating system, especially that the latest Windows OS
    (operating system) requires additional driver signature verification [11]. Therefore,
    the tomographic instruments that do not have as large amounts as the commercial
    electronics will suffer from the difficulties in maintaining a series of valid
    drivers for the latest OS. The aforementioned problems necessitate the development
    of a reliable and scalable electrical tomography platform that is capable of long-distance,
    high-rate data link. The rapid development of the information systems based on
    embedded hardware, Ethernet, and Web technologies offers an alternative method
    to access the tomographic measurements and images from a remote place. The combination
    of transmission control protocol/internet protocol (TCP/IP) and embedded hardware
    has extensively and profoundly changed the structure and operating mode of modern
    instruments. Recently, the development of the Internet of things (IoT) has provided
    several advantages, in that it is implemented on many standard hardware and software
    modules and has high connectivity between instruments, computers and many embedded
    devices [20]. Considering the complexity of the tomographic instrument, it is
    also preferred to employ multiple modules to implement the different functions.
    The IoT platform also provides convenience for this purpose. For example, the
    high-performance workstations that incorporate the computation-intensive iterative
    image reconstruction algorithms of image processing is not necessarily to be implemented
    on-site. The information technology has been employed in the various measurement
    systems and instruments, as summarized in Table I. However, it can be found that
    these configurations are still restricted to laboratory use and biomedical impedance
    measurements. The visual GUI is either C/C++ or MATLAB based specific program,
    which is not a good choice for remote transmission and industrial applications.
    Table I Review of specifications for electrical tomography systems published in
    the literature. The aim of this research is to develop a reliable and scalable
    ERT system with the efficient data and user interface via Ethernet. The following
    sections briefly discuss the system design, system integration, real-time signal
    processing and remote monitoring. SECTION II. System Design Fig. 1 depicts the
    distributed structure of IoT featured ERT system. The system consists of the ERT
    sensor, data acquisition system (DAS) and data processing system (DPS), an embedded
    Web server and multiple remote clients. Fig. 1. Schematic of iot featured ERT
    system. Show All A. ERT Hardware The ERT hardware is designed to interrogate the
    interchannel impedances between the multi-electrode sensor arrays installed on
    the peripheral of investigated processes. By applying an AC signal through a pair
    of electrodes, the resultant potential differences between all other electrode
    pairs can be obtained by the measuring circuits. The measured impedances and their
    changes depend on the distributions of the mixture under study. In the case of
    16-electrode sensor, a complete measurement set consists 104 measurements i.e.,
    nM = nE(nE - 3)/2. The data acquisition and processing system is demonstrated
    in Fig. 2. The data are transimitted via Ethernet in the form of data frame, which
    consists of frame header, the ERT measurements and the frame tail. By employing
    the proper data check scheme, data integrity can be guaranteed. As for the data
    post-processing, the cross-correlation algorithm [21] based on Fast Fourier Transform
    (FFT) and the phase volume fraction calculation based on reconstructed measurements
    are implemented. The data frames as TCP packets are then sent to the Web server
    database via the Ethernet interface. Fig. 2. The data receiving and post-processing
    on the embedded server. Show All B. Web Interface Web technology is implemented
    in the platform, primarily due to its real-time visualization and OS independent
    capabilities. By connecting the ERT hardware via the Web interface, all the information
    can be stored in the database. The workflow of Web platform is shown in Fig. 3.
    It mainly contains three parts, i.e., Web interface, Web server and Web browser.
    The interaction and Get/Response communication between the Web front and back
    ends are implemented by using the TCP/IP protocol. The data interaction format
    in the Web sever is JSON, which is a string-based approach in the Web platform.
    The hyper text transfer protocol (HTTP) and the common gateway interface (CGI)
    are implemented in the Web server. HTTP is one of the foundation of data communication,
    making it possible to traverse all the database information. The CGI is employed
    as the back-end program and is implemented in the hypertext preprocessor (PHP)
    scripts It provides the functions of form processing, database access, dynamic
    page content generation. The CGI functions as the communication tool between the
    database and server. Once a client request is received, i.e., the request to access
    the measurements, the Web server will immediately call the corresponding PHP scripts
    according to the received keywords. The database executes the key statements in
    PHP and returns the objects to the front end. Fig. 3. Web server data processing
    block diagram. Show All The communications between the server and the database
    are generally based on the standard TCP, as shown in Fig. 4. The Socket interface
    (Socket) is utilized to monitor port data between TCP Client and TCP Server. To
    establish a connection between the Server and Clients, the required APIs in the
    server include socket () , bind () , listen () , accept () , while the APIs Socket
    () and Connect () are needed to be excuted in the Client. There is a block to
    improve the network utilization in the TCP server. And, a series of read and write
    operations are performed once the a connection between the server and client is
    established. In this way, the end-to-end byte streams between the ports of clients
    and servers are realized. As cross-domain data interaction is needed, a Web browser
    asynchronous request technology is implemented by using Ajax. There exist litter
    interference to the Web server through Ajax function; thus, the Web interface
    can send and retrieve data from a server asynchronously with the dynamic performance.
    Likewise, the user interface can send key-words/commands to the Web server through
    the Ajax function, realizing the command transmission from the Web platform to
    the ERT system. In the front-end, the Web site provides the Web pages through
    hyper text markup language (HTML) and Javascript. Fig. 4. Multi-client tcp/ip
    client/server application. Show All The use of HTML enables the visualization
    of measurements and configurations from the ERT hardware. The web browser is responsible
    for parsing the HTML and presenting it as Web page contents. JavaScript is a lightweight
    scripting language that adds interaction, dynamic effects and behaviours to the
    Web page. It requires no configuration on the client side. SECTION III. Results
    and Discussions A. SNR Performance The SNR performance of measurement system is
    calculated from n consecutive measurements in each channel x i (x=1 , 2, …, 13)
    according to the formula below: SNR(j)=−20lg[ 1 μ 1 n ∑ i=1 n ( x i −μ ) 2 − −
    − − − − − − − − − − √ ] (1) View Source where SNR(j) is the SNR of j measurement
    channel (j=1 , 2, …, 13), μ represents the mean value of x i , and n is the number
    of measurement and selected as 1000 in this case. The measurements are obtained
    from the ERT sensor that filled with the conductivity materials, i.e., saline
    water. Fig. 5 shows the calculated SNR data from the ERT system, of which the
    average SNR is 66.9 dB for the applied frequency of 128 kHz. B. Web Platform Test
    The experiment set-up is shown in Fig. 6. In the previous system, ERT data and
    images are processed with an image reconstruction software in a host PC, namely
    ETest, which is implemented in Visual C++ . The ETest software has functions include
    the USB communication, image reconstruction algorithms, cross-correlation velocity
    calculation, data log and replay. Usually, it is limited to the on-site monitoring
    and not suitable for remote applications, due to the limitation of USB interface.
    Fig. 5. SNR performance. Show All Fig. 6. Iot featured ERT system. Show All In
    comparison, the IoT featured ERT system sends the raw measurements and data via
    Ethernet interface. The Web server parses the raw data by using the PHP scripts,
    and provides the dynamic content and results on the side of clients at an updating
    speed of 0.1 second. A fixed URL is employed as the identity to locate network
    resources in the HTTP server. And, the data can be accessed from the remote clients
    via a web browser. Fig. 7. Web browser content on a PC client. Show All Fig. 7
    depicts the web page containing two dynamical charts and corresponding texts.
    The main configuration parameters of the ERT system are shown on the Web browser
    in the clients. It supports the multiple devices to monitor the measured flow
    velocity and phase fraction, simultaneously. It is possible to display the results
    in different time spans, i.e., one minute, one hour or one day, which shows a
    certain data storage capacity. Besides, it also allows the clients to download
    historical data from the browser for local analysis. The files can be saved in
    the formats of PDF, CSV, JPG, etc. As compared with the previous system, the IoT
    featured ERT platform offers some distinct capabilities, including the large database,
    multiple clients and remote access. In addition, the system is not limited to
    a specific operating system, which help extend the of application range of ERT
    technology. SECTION IV. Conclusions In this paper, an IoT featured ERT platform
    that utilizes the embedded hardware and Ethernet protocols is presented, which
    is implemented in the scalable and distributed structure. The IoT platform provides
    a convenient and standardized interaction between the parts of the system. The
    data can be collected from sensors by ERT hardware, and at the same time, processed.
    The tomographic measurements can be simultaneously displayed on the multiple remote
    clients, i.e. the ubiquitous computers and smart devices. The server has large
    data storage capabilities and computation capability and requires only light-weighted
    clients to demonstrate tomographic images and data. Future work will focus on
    the adaptability to other tomographic systems, improvements on the web processing
    performance and the functions. ACKNOWLEDGMENT The authors would like to thank
    all the anonymous reviewers for their insightful comments and valuable suggestions.
    Authors Figures References Keywords Metrics Footnotes More Like This Hardware
    implementation of session initiation protocol servers and clients 2009 IEEE Symposium
    on Computers and Communications Published: 2009 The solution of ethernet based
    on hardware protocol stack W5300 and FPGA Proceedings of 2011 International Conference
    on Electronic & Mechanical Engineering and Information Technology Published: 2011
    Show More IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT
    OPTIONS VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES
    PROFESSION AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678
    4333 WORLDWIDE: +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact
    Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics
    Reporting | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE
    is the world''s largest technical professional organization dedicated to advancing
    technology for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Conference Record - IEEE Instrumentation and Measurement Technology Conference
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Implementation of IoT Platform for Electrical Resistance Tomography
    System
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Rath P.K.
  - Mahapatro N.
  - Sahoo S.
  - Chinara S.
  citation_count: '4'
  description: Sensor network and Internet of Things are the emerging paradigms for
    data collection and monitoring purpose today. It has significant application in
    industry and academic research. Body Sensor Network (BSN) has found a lot of research
    attention recently due to its demand in healthcare management and hospital automation.
    In this paper a health monitoring system has been proposed for assisting doctors
    and patients within a hospital. The key focus of the work is on the convenience,
    reliability, efficiency and scalability of the system. Real time data monitoring,
    doctor prescription management, data sourcing from hospitals for medical analysis
    are the typical contributions discussed in the paper. The work has been analyzed
    using network simulations to determine the performance of the proposed architecture.
    Two different communication protocols and their performance have been analyzed
    to determine the best choice for the proposed hospital management system.
  doi: 10.1109/ICCCIS51004.2021.9397186
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Conferences >2021 International Conference... Design
    and Performance Analysis of an IoT Based Health Monitoring System for Hospital
    Management Publisher: IEEE Cite This PDF Prabin Kumar Rath; Neelam Mahapatro;
    Subham Sahoo; Suchismita Chinara All Authors 3 Cites in Papers 207 Full Text Views
    Abstract Document Sections I. Introduction II. System Architecture III. Network
    Efficiency Analysis IV. Network Reliability Analysis Conclusion Authors Figures
    References Citations Keywords Metrics Abstract: Sensor network and Internet of
    Things are the emerging paradigms for data collection and monitoring purpose today.
    It has significant application in industry and academic research. Body Sensor
    Network (BSN) has found a lot of research attention recently due to its demand
    in healthcare management and hospital automation. In this paper a health monitoring
    system has been proposed for assisting doctors and patients within a hospital.
    The key focus of the work is on the convenience, reliability, efficiency and scalability
    of the system. Real time data monitoring, doctor prescription management, data
    sourcing from hospitals for medical analysis are the typical contributions discussed
    in the paper. The work has been analyzed using network simulations to determine
    the performance of the proposed architecture. Two different communication protocols
    and their performance have been analyzed to determine the best choice for the
    proposed hospital management system. Published in: 2021 International Conference
    on Computing, Communication, and Intelligent Systems (ICCCIS) Date of Conference:
    19-20 February 2021 Date Added to IEEE Xplore: 12 April 2021 ISBN Information:
    DOI: 10.1109/ICCCIS51004.2021.9397186 Publisher: IEEE Conference Location: Greater
    Noida, India SECTION I. Introduction Within the domain of IoT, Wireless sensor
    network (WSN) [1] serves the purpose of data aggregation. It is a collection of
    sensor nodes which are spatially scattered at different physical locations and
    source the collected data to a central server for organization, management and
    analysis of the data. Each sensor node usually consists of a group of essential
    sensors to collect the required data and a network module to interact with the
    server. A similar variety of such a network consisting of nodes with healthcare
    sensors that adopts the IEEE 802.15.6 standard is known as Body sensor network
    (BSN) [2], [3]. It has a wide application in the hospitals for monitoring and
    management of critical health data of patients. In case of a BSN, the sensor nodes
    are often referred as wearable computing devices that remain attached to the patient’s
    body and monitor vital body parameters and movements. BSN can be scaled to a broader
    network that can help in management and organization of patients’ data within
    the hospital. Such a network architecture can improve the convenience of doctors
    and hospital authorities in handling the critical health data of patients. Furthermore,
    patients can get in touch with the doctor remotely through the network thus facilitating
    a good doctor-patient relationship. The development of such a system, typically
    for hospitals demands two basic requirements i.e. reliability and efficiency.
    Hospital being a public institution has a possibility of getting high network
    traffic. Hence, the system should be reliable enough to handle the high frequency
    medical sensor data collected from multiple nodes, with least packet loss [4]
    within the network. Real time monitoring of health data is an essential requirement
    for surveillance of patients with critical health conditions. Hence, the system
    should be efficient enough to deliver the data over the network with least latency.
    The proposed health monitoring system in this paper as shown in Fig. 1 focuses
    on the above requirements to develop a cost effective and optimal healthcare management
    architecture for hospitals. Fig. 1: Architecture of the proposed Healthcare system
    for Hospitals. Show All IoT based healthcare monitoring systems with a BSN architecture
    have been developed earlier by many researchers. Ingole et al [5] designed a health
    monitoring system using only temperature and heart rate measuring units. They
    proposed a methodology to display real time sensor data as a single value but
    did not show a continuous data containing past few values. The work also did not
    focus on interaction between patients and doctors in a hospital. Chauhan et al
    [6] proposed a similar healthcare system where they used sensors such as ECG,
    pulse and temperature with an interactive mobile application for doctors and patients.
    However, they did not use any effective communication protocol for data transmission
    which should be given importance in an IoT based application to ensure scalability
    of the system. Kamal et al [7] in their work on health monitoring system developed
    a prototype of sensor node and used Ethernet along with other wired methods of
    communication between sensor node and server. But this method is not feasible
    and efficient in a hospital with large number of patients. The healthcare system
    proposed by Swamy et al [8] used body temperature, heart rate and blood oxygen
    level for live data monitoring of subjects along with an android app for doctors
    and patients. But they did not focus on the analysis of the architecture and use
    of effective protocol for data transmission. A comparison among previous work
    and the proposed work in this paper is briefly described in Table I. TABLE I:
    Comparison with previous work The healthcare system proposed in this paper discusses
    the development of an IoT solution for hospitals incorporating the following aspects
    Development of a prototype BSN node for data collection and logging. An efficient
    and reliable network architecture connecting BSN nodes, routers, local servers
    and cloud platforms. Analysis of the application features and performance using
    simulations and experiments. SECTION II. System Architecture The proposed healthcare
    system is a three tier architecture for handling the health data of patients within
    a hospital. BSN node constitute the third tier computing units and remain attached
    to the patient’s body. It collects data to send it to a nearby router which appears
    within the WiFi (IEEE 802.11) range of the node. The usual arrangement of patients
    within a hospital follows the order as shown in Fig. 1. A hospital is divided
    into different rooms, each room consists of a number of beds and each bed is assigned
    to a specific patient. In the proposed architecture, data from the nodes within
    a room are collected by routers i.e. one present in each of the rooms. These routers
    are connected to a central server through wired connections (IEEE 802.3) forming
    a hospital LAN. The central server of a hospital represents the second tier of
    computing unit within the network. It facilitates web and mobile app services
    for doctors and patients within the hospital. The central server is connected
    to a cloud server for large scale storage and management purpose. Cloud server
    represents the first tier of computing unit and stores information coming from
    multiple hospitals. It is responsible for large scale data backup, management
    and analysis. A. BSN node The Body Sensor Unit (BSU) of the designed prototype
    has sensors for collecting temperature, pulse and Electroencephalography (EEG)
    [9] data from a patient. The developed node for the experiment has these three
    sensors but it is not limited and additional sensors can be added to the node
    based on their availability at the hospital and requirements of the patient. The
    Body Central Unit (BCU) uses a Raspberry Pi as the principal computing device
    of the BSN node. It has an on-board WiFi module that connects to nearby routers
    for data transmission. The EEG sensor estimates the value of attention, meditation,
    drowsiness and relaxation of a patient wearing the device. The EEG data are received
    by the BCU via a receiver dongle. Arduino Nano micro-controller is used for collecting
    temperature and pulse data from respective sensors. These data are received by
    the BCU via an UART serial port. After receiving data from sensors, BCU integrates
    them to form a data packet and sends them to the central server via a nearby router.
    Fig. 2 shows the BSN node prototype developed for collection of health data. An
    11.1V Li-Po battery has been used as the power source and the output is stepped
    down to usable 5V that powers the BSN node. Fig. 2: Prototype BSN node for health
    data collection. Show All Fig. 3: Functions of central server. Show All B. Central
    Server Functionality The data coming from numerous BSN nodes are processed and
    organized in a central server (Tier 2). It is a computer system with relatively
    high computing power and acts as a storage and management unit for the hospital.
    Fig. 3 represents the main functionalities of the central server. 1) Doctor’s
    Portal A website has been developed which can be used by doctors to remotely monitor
    a patient’s situation. The technologies adopted to develop the website are HTML,
    CSS, JavaScript, Bootstrap for front-end service and PHP for back-end service.
    The routers along with the central server form a LAN within the hospital and the
    doctor’s portal website is reachable on this LAN. The connections to the website
    are secured with a custom SSL certificate using HTTPS. After successful authentication
    with a doctor’s credentials, the portal shows the list of patients currently assigned
    to the doctor. Fig. 4 is a snapshot of doctor portal which displays a list of
    the patients. On clicking the \"Details\" button, the doctor can visualize the
    patient’s health data in real time. After observing conditions of a patient, the
    doctor can provide prescription and advises through the portal. Later, patients
    can refer to their prescription using an android application. Instead of memorizing
    each and every advice, patients can view and refer to their prescription at any
    time through a mobile app. Doctors in a hospital usually communicate with many
    patients and hence the portal can help them in management of prescriptions and
    advices. This facilitates better doctor patient relationship within the hospital.
    Fig. 4: List of patients at Doctor’s portal. Show All 2) Android app for patients
    An android app has been designed for the patients admitted to the hospital. Patients
    are provided with a unique id and each are assigned a BSN node. The login credentials
    for using android app are provided to the patients by the hospital authorities.
    The login interface for the patients has been developed as a mobile app as shown
    in Fig. 5a. After successful authentication by central server, patients are allowed
    to view the prescription and advices along with name of their doctor. Thus, patients
    will always have digital access to information as shown in Fig. 5b. 3) Database
    construction The database maintained in the central server stores the data collected
    from the BSN nodes in an organized manner. The database used in this work is MySQL.
    It is an open source tool for handling database related functionalities and can
    be scaled to large storage systems. Fig. 6 shows various tables and their roles
    in the database used for the proposed healthcare application. Fig. 5: Android
    app for patients. Show All Fig. 6: Database of central server. Show All 4) BSN
    data Management The server manager receives the data coming from the BSN nodes
    and executes different data transactions with the database. It maintains a dynamic
    list of active node ids that are currently sourcing valid data to the central
    server. Whenever a node stops sending data due to some failure, the server side
    validation fails and it waits for a pre-defined timeout period after which the
    node id is removed from the active node list. This ensures that the network does
    not feed false data to the system. The validated data is then written to the server
    database. Whenever a request for patient data visualization is received from the
    doctor’s portal, the corresponding node id of the patient is first searched in
    the active node list. If found, the incoming data is directly forwarded to the
    doctor’s portal using WebSocket protocol [10] without any query to the database.
    This ensures real-time data visualization at doctor’s portal. The procedures for
    BSN data management are run on parallel threads to ensure high CPU utilization
    and low computational latency at the central server. Algorithm 1 shows a pseudo
    code of the procedures used for BSN data management. 5) Real time data visualization
    The web page of the doctor’s portal maintains a fixed size queue as a buffer to
    store the real-time sensor data coming from server manager. Each sensor is assigned
    its own queue for holding data over a fixed time horizon. The graph visualizations
    on the web page are updated at a frequency of 5Hz during which the data present
    in the queues are shown on the graphs. A cropped snapshot (shown only for heart
    pulse data) of real time patient data visualization in the doctor’s portal is
    shown in Fig. 7. Algorithm 1: Procedures for BSN data management SECTION III.
    Network Efficiency Analysis Use of proper communication protocol is essential
    to ensure efficient data transmission within a network. Data transmission experiments
    between central server and the BSN node were carried out using two communication
    protocols i.e. MQTT [11] and CoAP [12]. Their efficiency were determined based
    on average time delay incurred for the transmission. The central server was configured
    with Ubuntu 18.04 having 8GB RAM, Intel i5 8th gen processor and 1TB disk space.
    A. Communication protocols and experiment setups 1) MQTT Message Queuing Telemetry
    Transport (MQTT) is a TCP based application layer protocol that adopts a publisher
    subscriber mechanism in order to perform reliable data transmission. It is a light
    weight communication protocol for small sensors and mobile devices inherently
    designed for unstable networks. In the experiment setup, central server subscribed
    to the sensor data published by the BSN node. The MQTT broker was installed at
    the central server and managed low level data transmission between BSN node and
    Server manager (Section II(B)). Throughout the experiments, the Quality of Service(QoS)
    factor of MQTT was set to 1. Fig. 7: Real time data visualization. Show All 2)
    CoAP Constrained Application Protocol (CoAP) is an application layer protocol
    specifically designed for wireless sensor networks with critical circumstances
    like low bandwidth and high congestion. It uses a request-response model based
    on UDP protocol. In the experiment setup, CoAP has been set to use \"confirmable
    messages\" in order to ensure transmission reliability. B. Efficiency of Communication
    protocols The network generates data packets containing sensor data information.
    A sample structure of a JSON data packet generated from the network is shown in
    Fig. 8. In order to estimate the size of generated data packets, a Wireshark [13]
    analysis was performed during data transmission experiments. It was observed that
    after inclusion of protocol headers to the packets by different network layers,
    the packet size of data generated within the network lie in the range of 50-300
    Bytes. Even with addition of more sensors the packet size is not expected to be
    more than 1000 Bytes. Fig. 8: Example of a JSON data packet. Show All TABLE II:
    Data packet analysis at central server Table II shows results of the experiments
    between tier 2 and tier 3 (Fig. 1) of the proposed network architecture. The distance
    between BSN node and local router was approximately 12 meters. The net distance
    between the central server and the BSN node was approximately 150 meters. Each
    experiment was conducted 10 times where average transmission time τ and the standard
    deviation σ were estimated for sending 1000 number of packets continuously from
    BSN node to the central server. The average transmission time for the experiments
    were evaluated at the central server using Equation 1 where tfirst and tlast are
    first packet timestamp and last packet timestamp respectively. Avg Transmission
    time= t last − t first Total number of packets (1) View Source From the results
    of the experiments, it was observed that efficiency of MQTT is better than CoAP.
    Furthermore, a similar experiment using MQTT was performed between tier 1 and
    tier 2 (Fig. 1) of the architecture. The cloud server was facilitated using Microsoft
    Azure [14] app service deployed at Southeast Asia data centre located in Singapore
    (≈ 3000 Km from the central server location). The MQTT broker was installed at
    the cloud server which subscribed to the data published by the central server.
    Table III shows the Average transmission time evaluated for sending 1000 number
    of packets from central server to the cloud server. TABLE III: Performance of
    MQTT for data transmission to cloud server. SECTION IV. Network Reliability Analysis
    Reliability of a network can be analyzed, when it is observed under high traffic
    conditions. Network simulation tools are software which can be used to test the
    performance of a WSN under high traffic scenarios. A simulation of the proposed
    healthcare system was performed in order to observe and analyze the packet transmission
    reliability between tier 2 and tier 3 (Fig. 1) of the proposed network architecture.
    For this purpose, NS3 simulator [15] was used which mimics the real world networking
    principles and provides a virtual analysis of data transmission through the network.
    The NS3 simulator contains many inbuilt functions for setting topology of network,
    protocols to be used, energy of all nodes in the network and other essential network
    parameters. A list of few parameters particularly essential for the simulation
    of the proposed healthcare system are shown below: Number of rooms. Number of
    BSN nodes per room. Maximum data transmission rate for wired and wireless mediums.
    Router processing delay. BSN packet generation frequency. Size of packet. For
    setting up the network topology, a total of 100 rooms were created for the hospital.
    The data transmission rate for wireless communication was set to 300 Mbps as per
    the convention of WiFi (IEEE 802.11). Delay in processing time of router was set
    to 3ms. BSN packet generation frequency was set to 10Hz. Keeping these fixed parameters,
    the network was simulated by varying the number of sensors per room and packet
    size parameters. The performance of the network was observed and results were
    recorded in terms of Packet Delivery Ratio (PDR). Fig. 9: Throughput of MQTT and
    CoAP. Show All Fig. 10: PDR of MQTT and CoAP. Show All PDR was evaluated using
    Equation 2 where xi is the total number of packets sent by ith node, N is the
    total number of nodes in the topology and y is the total number of packets received
    at the central server. PDR= y ∑ N i=1 x i (2) View Source Throughput of the network
    is the average number of packets received at the central server per unit time.
    Both PDR and throughput measure the reliability of a network under heavy traffic
    conditions. Simulations were performed using MQTT and CoAP protocols to find out
    the better one for the proposed healthcare system. Both Throughput and PDR depend
    hugely on the generated packet size. Although the packet size of data generated
    from BSN nodes are relatively small but in order to determine the worst case bottleneck
    conditions, synthetic packets with arbitrarily large packet size (i.e. up to 15000
    Bytes) were also simulated within the network. Fig. 9 shows the throughput of
    the network with respect to variation in packet size with 10 BSN nodes per room.
    The maximum achievable throughput is 100 rooms * 10 nodes per room * 10Hz = 104
    packets per second, however for visualization purpose, in Fig. 9 it has been linearly
    scaled down to a range of 0 to 10. Results indicate that on increasing packet
    size beyond 4000 Bytes, MQTT outperforms CoAP. Fig. 10 shows the variation of
    PDR with respect to variation in packet size. Results of this simulation indicate
    that for packet size less than 2000 Bytes, MQTT provides a better packet delivery
    ratio than CoAP. On increasing packet size further, CoAP shows better performance
    than MQTT. From the experiments in Section III and the simulations on throughput
    and PDR, it was observed that MQTT provides more promising results over CoAP.
    Additionally a more specific simulation experiment was performed using the MQTT
    protocol to observe Packet Loss Rate (PLR) within the network. The packet loss
    rate was obtained using Equation 3. PLR(in%)=(1− No. of successful transmissions
    No. of total transmissions )∗100 (3) View Source Fig. 11: PLR vs Packet size using
    MQTT. Show All Fig. 12: PLR vs Number of sensor nodes per room using MQTT. Show
    All Fig. 11 shows the variation of PLR with respect to packet size with 10 BSN
    nodes per room. The simulations indicate that packet loss rate does not change
    significantly for packet size variations when it is small and lies in the range
    of a few hundred Bytes. Fig. 12 shows the variation of PLR with respect to number
    of BSN nodes per room for a fixed packet size of 78 Bytes. On increasing the number
    of BSN nodes per room, the channel congestion increases and hence PLR also increases.
    It was observed that a maximum of 30 nodes per room is feasible for keeping PLR
    under an acceptable limit. Conclusion An IoT based healthcare system was developed
    for use in hospital management. Efficiency and reliability of the proposed network
    architecture were analyzed using two different communication protocols MQTT and
    CoAP. For small packet size in the range of 50 to 1000 Bytes, efficiency of MQTT
    was found to be better than CoAP in transmitting data from BSN nodes to the central
    server. MQTT also outperformed CoAP in the high traffic simulation experiments
    with small packet size transmissions. Hence, MQTT was considered to be the optimal
    communication protocol for the proposed healthcare system. The analysis and discussions
    presented in the paper were mostly done between tier 2 and tier 3 of the proposed
    network architecture. As a scope of future work, a more detailed analysis will
    be done on the communication to tier 1 of the architecture. Different medical
    data analysis methods using machine learning tools will be deployed on cloud server
    for autonomous health data monitoring. Real time data coming from BSN nodes will
    also be monitored for unusual variations and emergency alerts will be sent to
    doctors for immediate patient assistance. The entire IoT system will be deployed
    at a local hospital for evaluating the real-world performance of the system. Authors
    Figures References Citations Keywords Metrics More Like This Transparent Synchronization
    Protocols for Compositional Real-Time Systems IEEE Transactions on Industrial
    Informatics Published: 2012 Global Reliability-Aware Power Management for Multiprocessor
    Real-Time Systems 2010 IEEE 16th International Conference on Embedded and Real-Time
    Computing Systems and Applications Published: 2010 Show More IEEE Personal Account
    CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS VIEW PURCHASED DOCUMENTS
    Profile Information COMMUNICATIONS PREFERENCES PROFESSION AND EDUCATION TECHNICAL
    INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE: +1 732 981 0060 CONTACT
    & SUPPORT Follow About IEEE Xplore | Contact Us | Help | Accessibility | Terms
    of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy
    Policy A not-for-profit organization, IEEE is the world''s largest technical professional
    organization dedicated to advancing technology for the benefit of humanity. ©
    Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: Proceedings - IEEE 2021 International Conference on Computing, Communication,
    and Intelligent Systems, ICCCIS 2021
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Design and Performance Analysis of an IoT Based Health Monitoring System
    for Hospital Management
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Garola A.R.
  - Manduchi G.
  - Gottardo M.
  - Cavazzana R.
  - Recchia M.
  - Taliercio C.
  - Luchetta A.
  citation_count: '8'
  description: The RFX-mod2 Nuclear Fusion experiment is an upgrade of RFX-mod, which
    was shutdown in 2016. Among the other improvements in the machine structure and
    diagnostics, a larger number of electromagnetic probes (EMs) is foreseen to provide
    more information about plasma instabilities and to allow an improved real-time
    plasma control. An analog-to-digital converter (ADC) architecture able to provide,
    at the same time, both transient recording and real-time streaming, as well as
    field-programmable gate array (FPGA)-based time integration of the inputs, is
    foreseen in RFX-mod2. Transient recording provides full-speed data acquisition
    (up to 1 MSample/s) by recording data in local memory and reading memory content
    after the plasma discharge. Real-time streaming of the subsampled data is required
    for active control. The chosen technology is based on the XILINX Zynq architecture
    that provides, in the same chip, a multicore Advanced RISC Machines (ARM) processor
    tightly coupled to an FPGA. Time-critical functions are carried out by the FPGA,
    such as the management of the circular data buffer, low-pass filtering for subsampling
    of the samples to be streamed, and digital integration. Other functions are carried
    out by the processor, such as the management of the configuration setting, received
    via Transmission Control Protocol (TCP)/IP or Hypertext Transfer Protocol (HTTP),
    the data readout of acquired samples in transient recording buffers, and network
    data streaming of data collected for active real-time plasma control.
  doi: 10.1109/TNS.2020.3035146
  full_citation: '>'
  full_text: '>

    "This website utilizes technologies such as cookies to enable essential site functionality,
    as well as for analytics, personalization, and targeted advertising purposes.
    To learn more, view the following link: Privacy Policy Manage Preferences IEEE.org
    IEEE Xplore IEEE SA IEEE Spectrum More Sites Donate Cart Create Account Personal
    Sign In Browse My Settings Help Access provided by: University of Nebraska - Lincoln
    Sign Out All Books Conferences Courses Journals & Magazines Standards Authors
    Citations ADVANCED SEARCH Journals & Magazines >IEEE Transactions on Nuclear ...
    >Volume: 68 Issue: 2 A Zynq-Based Flexible ADC Architecture Combining Real-Time
    Data Streaming and Transient Recording Publisher: IEEE Cite This PDF Andrea Rigoni
    Garola; Gabriele Manduchi; Marco Gottardo; Roberto Cavazzana; Mauro Recchia; Cesare
    Taliercio; Adriano Luchetta All Authors 9 Cites in Papers 395 Full Text Views
    Abstract Document Sections I. Introduction II. ANACLETO Framework for SoC Development
    III. Flexible ADC SoC Implementation IV. Noise Requirements in ADC Stage for Digital
    Integration V. Proof-of-Concept Implementation: Fast Streamed Event-Driven Data
    Acquisition for the NIO Negative Ion Beam Show Full Outline Authors Figures References
    Citations Keywords Metrics Abstract: The RFX-mod2 Nuclear Fusion experiment is
    an upgrade of RFX-mod, which was shutdown in 2016. Among the other improvements
    in the machine structure and diagnostics, a larger number of electromagnetic probes
    (EMs) is foreseen to provide more information about plasma instabilities and to
    allow an improved real-time plasma control. An analog-to-digital converter (ADC)
    architecture able to provide, at the same time, both transient recording and real-time
    streaming, as well as field-programmable gate array (FPGA)-based time integration
    of the inputs, is foreseen in RFX-mod2. Transient recording provides full-speed
    data acquisition (up to 1 MSample/s) by recording data in local memory and reading
    memory content after the plasma discharge. Real-time streaming of the subsampled
    data is required for active control. The chosen technology is based on the XILINX
    Zynq architecture that provides, in the same chip, a multicore Advanced RISC Machines
    (ARM) processor tightly coupled to an FPGA. Time-critical functions are carried
    out by the FPGA, such as the management of the circular data buffer, low-pass
    filtering for subsampling of the samples to be streamed, and digital integration.
    Other functions are carried out by the processor, such as the management of the
    configuration setting, received via Transmission Control Protocol (TCP)/IP or
    Hypertext Transfer Protocol (HTTP), the data readout of acquired samples in transient
    recording buffers, and network data streaming of data collected for active real-time
    plasma control. Published in: IEEE Transactions on Nuclear Science ( Volume: 68,
    Issue: 2, February 2021) Page(s): 245 - 249 Date of Publication: 02 November 2020
    ISSN Information: DOI: 10.1109/TNS.2020.3035146 Publisher: IEEE SECTION I. Introduction
    RFX-mod [1] is a medium-size toroidal plasma multi-configuration machine (major
    radius R=2.0 m, minor radius a=0.46 m, operated up to 2 MA current reversed field
    pinch (RFP) configuration or 0.5 T tokamak). The experiment was shut down in 2016
    and is now being upgraded as RFX-mod2 [2]. A major foreseen development is a substantial
    improvement of the magnetic measurement system. In the new experiment configuration,
    many of the electromagnetic (EM) sensors will be moved inside the vacuum vessel
    widening their usable signal bandwidth up to 200 kHz in order to providing better
    plasma control. Moreover, the total number of the new magnetic pick-up coil sensors
    will be increased with the aim of improved spatial resolution [3]. In order to
    collect the magnetic field measurements from EM probes, an analog integration
    system [4] was implemented in RFX-mod, followed by two separate sets of analog-to-digital
    converter (ADC) channels, one for precision offline transient data and the other
    for real-time control. Reimplementing the same front-end for an increased number
    of channels is costly, requiring enhanced analog integration and duplication in
    ADC channels. A more compact and cost-effective solution is being investigated
    [5], using a field-programmable gate array (FPGA) to handle ADC conversion and
    providing a set of online functions directly performed at the FPGA logic level,
    including the numeric integration in real time, recording at the same time the
    dB/dt signals deriving directly from EM coils needed to study the magneto hydrodynamic
    (MHD) processes taking place into the plasma [6], [7]. The possibility of directly
    acquiring the time derivative of the EM fields, that is, the direct signals from
    EM probes, was not present in the previous system, acquiring integrated signals
    in order to reduce the number of required ADC channels. This fact introduced a
    severe limitation in the derivative control required for MHD stabilization because
    of the bad quality of the computed time derivative. The proposed approach will
    further reduce the number of ADC channels by merging high-frequency transient
    recording in local memory (up to 1 MHz) and lower frequency streaming (up to 10
    kHz) required for real-time plasma control and having a single ADC channel performing
    both. In RFX-mod, a fixed subset of signals from EM probes was used for the active
    plasma control, requiring a new set of ADC converters with respect to the transient
    recorders used for data acquisition. In RFX-mod2, it will be possible to reuse
    any ADC channel from EM probes for real-time plasma control, the actual number
    possibly limited by other factors not related to the ADC devices, such as network
    bandwidth or control computation load. The flexibility provided by the FPGA also
    allows the inclusion of more sophisticated triggering mechanisms and a deeper
    integration with the timing systems. Examples of triggering mechanism are given
    by the acquisition of fast transients requiring high-speed sampling only in a
    given, dynamic region of interest (ROI). This feature has been implemented in
    the first proof-of-concept device described in Section III. Deeper integration
    with the timing systems imply the ability of getting the clock and the trigger
    signals not only from digital inputs, but also from the specifically coded signal
    carrying both clock and trigger information (timing highway) [8]. Such signals
    were used in the RFX-mod timing systems to distribute a synchronous clock and
    asynchronous triggers and a timing device was required for every ADC rack to extract
    the clock and the trigger signals. The timing device is no more required for a
    rack hosting the new ADC devices because the ADC devices can directly extract
    timing information from the timing highway. The adoption of a system-on-chip (SoC)-based
    technology exploiting both an Advanced RISC Machines (ARM)-based processing unit
    and an FPGA logic unit provides the flexibility of a configurable device for real-time
    operations and as well as the possibility of deploying software components directly
    on-board. The Red Pitaya board [9] is currently used for the development of the
    architecture. A different solution is, however, foreseen for the production system
    integrating an external ADC section with the Zynq-based SoC board. An ADC front-end,
    already used in other applications of real-time plasma control [10], was initially
    considered, but its noise characteristics, and, in particular, the noise dependence
    on frequency proved to limit the quality of digital integration. For this reason,
    a different ADC stage is being considered, as explained in Section IV. The article
    is organized as follows: Section II introduces the reasons for the choice of the
    Zynq SoC and summarizes the development process. The complete development is orchestrated
    by the ANACLETO [11] framework providing a seamless integration of the different
    components (VIVADO XILINX tool, compilers, makefiles, etc.) required for both
    FPGA hardware description language (HDL) programming and GNU Linux driver development.
    Section III presents the implementation of the ADC flexible architecture providing
    support for signal integration, subsampling for real-time streaming, ROI detection,
    and timing extraction. Section IV presents the required ADC noise characteristics
    and discusses the limitations found in existing implementation, along with possible
    solutions. Section V presents a proof-of-concept system developed under ANACLETO
    on the Red Pitaya board and providing streamed event-driven high-speed data acquisition.
    Even if not covering all the presented features, this system has been successfully
    adopted in the negative ion optimization (NIO)-negative ion beam experiment [12],
    a satellite experiment of RFX for the study of additional heating in fusion devices.
    SECTION II. ANACLETO Framework for SoC Development As stated before, in order
    to improve the controllability of RFX-mod2, the design of a new ADC architecture
    able to provide both transient recording and real-time streaming is required.
    The transient recorder functionality will provide full-speed data acquisition
    (up to 2 MSample/s) by recording data in local memory and reading back the memory
    content after the plasma discharge. At the same time, the real-time streaming
    is required when the target signal is used in active control because such data
    must be promptly available in the closed-loop feedback. In this case, a 10-kHz
    subsampled version is streamed out toward the control units. The solution proposed
    comes from the adoption of the technology based on the XILINX Zynq architecture
    that provides in the same chip a multicore ARM processor tightly coupled to an
    FPGA. The combined usage of FPGA and a processing unit (running GNU Linux) allows
    partitioning of the system functionalities into time-critical components mapped
    onto the FPGA, letting the processor address less critical and possibly more complex
    functions. Critical and noncritical functions have been implemented using HDL
    development for the first ones, and C or C++ code development for the others.
    In addition, a GNU Linux driver must be written, acting as a bridge between the
    FPGA functions and the outside world. Several tools are available from XILINX,
    including the VIVADO framework for the development and integration of the HDL
    code into the Zynq architecture, the toolchain required to compile the driver
    and the support code in the dual-core ARM processor and the linux code for that
    processor. Even if various components are available, getting them from the proper
    sources over the network, installing the tools and building the toolchain is a
    complicated and error-prone process. The ANACLETO framework provides an effective
    solution by transparently orchestrating the download and the installation of the
    required components and toolchain, letting the developer concentrate on the specific
    aspects of his/her project. The project-specific tasks, that is, the development
    of the HDL code for the FPGA components and their assembly into the firmware project
    cannot, of course, be carried out by the ANACLETO, but the framework provides
    useful hints for the development of the linux driver. This is achieved by ANACLETO
    by recognizing in the FPGA project what are the components used for the communication
    with the processor, and producing generic driver templates implementing the communication
    with the I/O components defined in the FPGA project. Any combination of the following
    is supported by ANACLETO. I/O registers. Input and/or output FIFOs. Input and/or
    output direct memory access (DMA). ANACLETO recognizes the I/O registers, FIFOs,
    and DMA controllers defined in the FPGA project (available as IPs in the XILINX
    toolbox), modifies the device tree produced by VIVADO, and produces the corresponding
    source code driver template. Of course, no specific functionality can be provided
    in the driver templates, except for the input and output data flow management.
    Starting from the template, the developer will implement the specific functions,
    but he can ignore, to a large extent, the intricacies required for the I/O data
    transfer such as Interrupt handler programming and DMA engine configuration. SECTION
    III. Flexible ADC SoC Implementation The first implementation of the flexible
    ADC architecture has been carried out on a Red Pitaya board, using the in-board
    ADC channels. Even if not intended to represent the final application, development
    of FPGA logic on Red Pitaya offers the advantage of a ready-to-use ADC channel
    for development and first tests. Most of the firmware will be retained in the
    final implementation, using a different ADC front-end. The time-critical functions
    carried out by the FPGA in this context are: The management of a circular data
    buffer and the DMA transfer in RAM of pre- and post-trigger samples after the
    trigger has been received. Anti-aliasing filtering and subsequent subsampling
    of the samples to be streamed. The resulting samples are enqueued in an FIFO accessed
    by the processor. Digital integration for deriving magnetic field measurements
    from EM probe signals. Observe that, in this case, a single ADC stage will generate
    two ADC channels. ROI detection in case ADC triggers are derived from the signal
    itself (e.g., over a given signal level threshold). Clock and trigger extraction
    in case a highway signal is provided by the timing system, encoding both clock
    and triggers. The less critical functions that will be carried out by the processor
    unit are: The management of the configuration setting, received via Transmission
    Control Protocol (TCP)/IP or Hypertext Transfer Protocol (HTTP). The processor
    validates the configuration and writes the appreciate registers in the FPGA. Offline
    data readout of acquired samples in transient recording and communication via
    TCP/IP with the central data acquisition system. Network data streaming of subsampled
    data read from the FIFO and sent in User Datagram Protocol (UDP) packets to the
    active plasma control system. In addition to preconfigured blocks from the XILINX
    toolbox for data buffering, DMA engine, I/O FIFO, and registers, three blocks
    implemented in Very High Speed Integrated Circuit Hardware Description Language
    (VHDL) carry out the underlying logic. The first block provides the management
    of clock and triggers that may be either directly derived from the digital inputs
    or rebuild by properly decoding the timing highway input signal. The second block
    provides programmable input signal elaboration such as low-pass filtering for
    subsampling and integration. The third block will handle the triggering logic
    and the circular buffer holding pre- and post-trigger samples. In particular,
    the trigger may be derived from the external signals (via the first block) or
    derived from the input signal (e.g., when the input level is greater than a given
    threshold). Communication of subsamples streamed data for real-time plasma control
    is achieved using the XILINX AXI Stream FIFO. The Xilinx AXI Stream FIFO is a
    Xilinx free software IP that implement a read/write FIFO queue with a well-defined
    communication protocol. A properly connected Interrupt Request (IRQ) line is used
    to trigger events to the processing unit together with the related set of status
    and enable registers. In this way, data samples are readily available to the linux
    processor and will be sent using low-latency ( <100 μs ) UDP communication to
    computing nodes carrying out real-time plasma control. Communication of the data
    acquired at high speed in the ROI is carried out by a DMA engine, using circular
    DMA buffers in order to minimize the number of data copies. In this case, data
    will be sent to the central data acquisition system via TCP/IP as soon as an ROI
    has been acquired. Fig. 1 shows the main blocks of the ADC device: the external
    ADC circuitry, communicating with the FPGA via a serial Low Voltage Differential
    Signaling (LVDS) link; the FPGA logic communicating with the processor via registers,
    FIFO, and DMA; the processor components, in kernel and user space. Fig. 1. Logic
    design of the flexible ADC structure. Show All SECTION IV. Noise Requirements
    in ADC Stage for Digital Integration The Red-Pitaya board, hosting two fast ADC
    inputs, is currently used for the development of the HDL code and the GNU Linux
    drivers. Even if it represents a flexible and cheap solution for development,
    Red-Pitaya is not foreseen in the final production stage. In particular, the strict
    requests in terms of electrical insulation and noise shape, in order to carry
    out digital integration, are not met by the converters mounted in this device.
    A first prototype has been implemented using a compact and cost-effective front-end
    and ADC conversion solution based on the Advanced Telecommunications Computing
    Architecture (ATCA)-multiin–multiout (MIMO) ISOL [13] architecture that was used
    for the plasma column vertical stabilization at Joint European Torus (JET) tokamak
    experiment. The ADC stage is composed by a plug-in component mounting a 18-bit
    SAR converter from the analog devices (AD7641) that acquire signals from a fully
    differential input in the range 2.048 V at a maximum rate of 2 MSamples/s. The
    analog input is initially filtered by one pole, 100-kHz passive component connected
    to an input range adapter (THS4520), then the ADC converter (AD7641) is configured
    to operate using a four-wire communication protocol, and the electrical insulation
    is applied to the digital serial data output. The module is completely insulated
    from the FPGA and the power is supplied through a dc/dc converter. A custom logic
    has been developed in FPGA to implement the used LVDS serial communication protocol.
    The noise introduced by the ADC front-end proved not acceptable for performing
    numerical integration over a period of some (<10) s, that is the expected requested
    integration period in RFX-mod2. The reason is due to the introduced 1/f -shaped
    noise, as shown in Fig. 2, causing unavoidable integration shift. We also measured
    the noise after bypassing the low-pass filter and the impedance adapter, also
    shown in Fig. 2, that turned out to be one order of magnitude lower. In a test
    performed under this condition, the quality of reconstruction of an applied magnetic
    field collected by an EM probe and integrated in FPGA turned out to be acceptable
    (Fig. 3; observe that some drift is still visible for longer times, due to the
    remaining 1/f -shaped noise). A set of candidate components, whose noise characteristics
    are compatible with the latter noise level, has been considered for the antialiasing
    filter, the impedance adapter, and the ADC converter and the selected components
    will be used for the development of a new ADC front-end component. Fig. 2. Noise
    spectra. Show All Fig. 3. Test of numerical integrated signal from actual probe
    with real field applied. Show All SECTION V. Proof-of-Concept Implementation:
    Fast Streamed Event-Driven Data Acquisition for the NIO Negative Ion Beam Another
    desired topics for a data acquisition (DAQ) device is the possibility to increase
    the level of details during acquisition based on particular events. It is not
    uncommon to have an observed quantity that changes rapidly in time and then lasts
    steady or possibly in a noninteresting state for long periods. An example of this
    is the breakdown event that occurs in the accelerator grids of an ion source,
    leading to a very fast transient change in the measured currents and voltages
    of the grid power supply. In this case, fast data acquisition must be triggered
    by the event itself, acquiring data for a short time window around the event occurrence.
    This technique has been applied to NIO experiment [12], a small radio-frequency
    negative ions beam source with a high-voltage electrostatic particle accelerator
    stage composed of grids. In certain conditions, break-down events [14] appear
    on the high-voltage gaps of the grids causing a high current discharges of the
    power supply feeding the accelerator. A subset of the FPGA functionality described
    in Section III has been implemented in a Red Pitaya device, namely the trigger
    logic to detect the occurrence of the event, the pre- and post-trigger sampling
    logic, and the FIFO/DMA data transfer to computer memory via the GNU Linux driver.
    In this case, data are streamed and when an event is detected and data collected
    at 5-MHz sampling speed along the corresponding time window, the data block is
    passed, either via FIFO or DMA, to the linux driver and then, in turn, to a program
    in the ARM processor that communicates the newly acquired data block to the central
    data acquisition system via TCP/IP. The results are displayed in Fig. 4, showing
    the events acquired during a beam generation lasting 2 h. Each time window lasts
    1 ms, and one enlarged event is displayed in the lower part of Fig. 4. Fig. 4.
    Figure example. Show All SECTION VI. Conclusion The architecture of a new flexible
    ADC device has been presented, aiming at reducing the number of actual ADC channels
    by integrating high-speed transient recording and data streaming for real-time
    plasma control. In addition, the same ADC will be used to acquire both magnetic
    fields and their time derivatives, providing FPGA-based digital integration for
    the derivation of the former. This new architecture is foreseen to be applied
    at the RFX-mod2 experiment, providing a significant cost reduction with respect
    to the duplication of devices for transient recording and streaming. Moreover,
    performing digital integration in place of the analog one before ADC conversion
    improves the quality of plasma control that can now rely on original time-derivative
    signals. The use of the ANACLETO framework proved to be extremely useful in the
    development process and shortened quite a bit the learning time for new developers.
    ACKNOWLEDGMENT The authors wish to thank Yaman Umuroglu and the Xilinx FINN team
    for the support on network quantization, Paolo Franz and David Terranova for providing
    all the experimental QSH data set and the magnetic field reconstructions, Nicola
    Pomaro for the internal revision, and all the staff of the RFX consortium. Authors
    Figures References Citations Keywords Metrics More Like This On-Chip Real-Time
    Correction for a 20-ps Wave Union Time-To-Digital Converter (TDC) in a Field-Programmable
    Gate Array (FPGA) IEEE Transactions on Nuclear Science Published: 2012 A Real-Time
    NetFlow-based Intrusion Detection System with Improved BBNN and High-Frequency
    Field Programmable Gate Arrays 2012 IEEE 11th International Conference on Trust,
    Security and Privacy in Computing and Communications Published: 2012 Show More
    IEEE Personal Account CHANGE USERNAME/PASSWORD Purchase Details PAYMENT OPTIONS
    VIEW PURCHASED DOCUMENTS Profile Information COMMUNICATIONS PREFERENCES PROFESSION
    AND EDUCATION TECHNICAL INTERESTS Need Help? US & CANADA: +1 800 678 4333 WORLDWIDE:
    +1 732 981 0060 CONTACT & SUPPORT Follow About IEEE Xplore | Contact Us | Help
    | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting
    | Sitemap | IEEE Privacy Policy A not-for-profit organization, IEEE is the world''s
    largest technical professional organization dedicated to advancing technology
    for the benefit of humanity. © Copyright 2024 IEEE - All rights reserved."'
  inline_citation: '>'
  journal: IEEE Transactions on Nuclear Science
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: A Zynq-Based Flexible ADC Architecture Combining Real-Time Data Streaming
    and Transient Recording
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
- analysis: '>'
  authors:
  - Mahbub M.
  - Hossain M.M.
  - Gazi M.S.A.
  citation_count: '17'
  description: This software development is focused on the design of an intelligent
    lighting and ventilation system capable of sensing human presence to control the
    lighting and monitoring humidity, temperature, CO2, and smoke to ensure efficient
    ventilation and accidents caused by fire and smoke. This article develops an embedded
    system with ready-to-deploy software for intelligent lighting and ventilation
    with HTTP protocol based real-time monitoring through smartphones or PCs. Moreover,
    the designed system can log real-time sensor data into a cloud server through
    which the client can also monitor real-time data from anywhere in the world.
  doi: 10.1016/j.comnet.2020.107673
  full_citation: '>'
  full_text: '>

    "Skip to main content Skip to article Journals & Books Search Register Sign in
    Brought to you by: University of Nebraska-Lincoln View PDF Download full issue
    Outline Abstract BetaPowered by GenAIQuestions answered in this article Keywords
    1. Introduction 2. Review of the current systems 3. The framework, architecture,
    and software architecture of the prescribed system 4. Evaluation of the system
    5. Impact of the system 6. Scope for further research and development 7. Conclusion
    Declaration of Competing Interest References Vitae Show full outline Cited by
    (22) Figures (7) Show 1 more figure Tables (2) Table Table 1 Computer Networks
    Volume 184, 15 January 2021, 107673 Software Article Cloud-Enabled IoT-based embedded
    system and software for intelligent indoor lighting, ventilation, early stage
    fire detection and prevention Author links open overlay panel Mobasshir Mahbub
    a, M. Mofazzal Hossain b, Md. Shamrat Apu Gazi c Show more Share Cite https://doi.org/10.1016/j.comnet.2020.107673
    Get rights and content Abstract This software development is focused on the design
    of an intelligent lighting and ventilation system capable of sensing human presence
    to control the lighting and monitoring humidity, temperature, CO2, and smoke to
    ensure efficient ventilation and accidents caused by fire and smoke. This article
    develops an embedded system with ready-to-deploy software for intelligent lighting
    and ventilation with HTTP protocol based real-time monitoring through smartphones
    or PCs. Moreover, the designed system can log real-time sensor data into a cloud
    server through which the client can also monitor real-time data from anywhere
    in the world. Previous article in issue Next article in issue Questions answered
    in this article BetaPowered by GenAI This is generative AI content and the quality
    may vary. Learn more. What is the role of an intelligent indoor monitoring system?
    What is the potential application of the system in a densely populated area? How
    can users monitor the indoor environment? How does the system trigger automated
    lighting? How can users monitor the sensor data? Keywords IoTCloudIndoor lightingVentilationSmoke-fire
    detection and prevention Code metadata Current Code version V1.0 Permanent link
    to code/repository used of this code version https://github.com/ELS-COMNET/COMNET-2020-190
    Legal Code License MIT Code Versioning system used none Software Code Language
    used For example c++, html, etc. Compilation requirements, Operating environments
    & dependencies Sketch compiler If available Link to developer documentation/manual
    Not available Support email for questions mbsrmhb@gmail.com 1. Introduction An
    intelligent indoor monitoring system plays a significant role in ensuring a comfortable
    and high quality of life [1]. An intelligent indoor monitoring system consists
    of several subsystems based on IoT technologies that are suitable for different
    purposes, such as surveillance, environmental monitoring, and automatic appliance
    controlling. Consider a platform through which the users can observe and monitor
    the current status of a home, office, or any indoor (room) environment and automate
    appliances to do certain tasks, for example, turn on the ventilation system, or
    automatically control the lights sensing the presence of the human, etc. This
    work develops an embedded system and software through which the lighting system
    of an indoor environment can be automated (controlling the on and off) sensing
    the presence and absence of the human. Moreover, the system has integrated sensors
    to detect temperature, humidity, CO2, and smoke to automate the ventilation and
    fire prevention system. The users are capable of monitoring the indoor environment
    through the web pages of the ESP HTTP server and a dedicated cloud server. 2.
    Review of the current systems H. Jiang et al. [2] designed an IoT-based system
    for indoor temperature, humidity, dust particles, and light intensity detection
    and control regarding appliances according to the sensed data. M. J. Rodrigues
    et al. [3] have developed an IoT and WSN based system to monitor the indoor environmental
    conditions to maintain a safe and healthy environment to prevent respiratory distress.
    The system is capable of sensing humidity, temperature, and CO2 gas particles.
    V. R. Shinde et al. [4] have developed a cloud and IoT-based system for indoor
    and outdoor environmental monitoring. A. Firmansah et al. [5] developed a system
    based on WSN that can detect temperature and light to control the lighting system.
    J. Jose et al. [6] proposed IoT and LPWAN based system which is capable to detect
    and measure CO2 in indoor premises to ensure safe health. Additionally, the works
    [7], [8], [9], [10], [11], [12] proposed, designed, and developed similar kinds
    of the system to automate indoor lighting, air quality monitoring, and ventilation.
    All of these reviewed systems and most of the relevant research works and publications
    have not published their developed source code as open-source software. Moreover,
    most of the current systems are dedicated to doing either sensing of light for
    automated lighting or air quality monitoring for ventilation. As opposed to this,
    this work integrates both the automatic lighting system and ventilation in a single
    embedded system and software platform. 3. The framework, architecture, and software
    architecture of the prescribed system 3.1. Components Arduino Mega 2560 Rev3 [13]
    ESP8266 Module [14] GSM SIM900A Module [15] Relay Module [16] DHT11 Temperature
    and Humidity Sensor [17] PIR Motion Sensor [18] MQ-135 Gas Sensor [19] 3.2. System
    functional framework The embedded system consists of five functional or operational
    units. These are – Sensing, Data processing or analysis, Communication, Visualization,
    and Execution units. The sensing unit consists of a PIR sensor, an MQ-135 gas
    sensor, and a DHT11 sensor. This unit will sense the surrounding environment and
    pass the sensed data to the MCU (Microcontroller Unit). The data processing or
    analysis unit consists of an MCU that will process the data from each sensor and
    compare it with the predefined threshold for intelligent lighting, ventilation,
    and early-stage fire prevention. Moreover, this unit will lead the communication,
    visualization, and execution unit as well. The communication unit consists of
    two distinct communication modules or device one is the ESP8266 Wi-Fi connectivity
    module for cloud and HTTP web protocol and another one is the GSM900A module for
    SMS. The visualization unit is dedicated to representing data over cloud, web
    browser (HTTP), and SMS. The execution unit will perform its task of turning the
    light on and off, controlling the ventilation, and turn on and off the water sprinkler
    when the pre-defined threshold satisfies. Fig. 1 shows the functional framework
    of the embedded system. Download : Download high-res image (478KB) Download :
    Download full-size image Fig. 1. Functional framework of the proposed embedded
    system. 3.3. Embedded circuit design The embedded circuit is designed using Arduino
    Mega as a microcontroller, ESP8266 module for Wi-Fi connectivity and GSM module,
    PIR sensor, DHT11 sensor, MQ-135 sensor, lighting system, ventilation system,
    water sprinkler, and two indicator LEDs (green and blue). Fig. 2 shows the embedded
    circuit design of the autonomous system. Download : Download high-res image (927KB)
    Download : Download full-size image Fig. 2. The detailed circuit design of the
    proposed embedded system. 3.4. Description of the system The prescribed system
    is needed to be deployed in the indoor environment for sensing and actuating.
    The sensors integrated with the system sense data from the surrounding environment
    and the data is analyzed and processed by the MCU (computation unit). PIR motion
    detection sensor will detect the infra-red signal radiated from human bodies when
    a human presence is detected within the detection perimeter of the sensor and
    then the system will trigger the automated lighting. The system is also capable
    of computing the energy consumption of the autonomous lighting system. The DHT11
    sensor will sense the temperature and humidity of the indoor environment. MQ-135
    sensor is integrated with the embedded unit to observe and measure the amount
    of CO2 and fire/smoke present in the surrounding environment. Comparing the sensed
    data of DHT11 (temperature and humidity) and MQ-135 (CO2) sensor with the threshold
    defined in the computation subsystem (MCU) the system is capable of automatically
    triggering on or off the ventilation system and detecting and measuring the amount
    of smoke or fire the system will trigger on or off the water sprinkler. There
    are two indicator LEDs in the embedded system, of which one will indicate that
    the system is running or not (green LED) another will glow if motion is detected
    and remained in the detection perimeter (blue LED). Moreover, the system is capable
    of transmitting SMS to a dedicated mobile phone if it detects any vulnerable situation
    such as a higher amount of smoke or fire (according to the threshold defined in
    the computation unit). Clients or users are also capable of monitoring the sensor
    data of each sensor through the web pages using mobile phones, smartphones, or
    PCs with the help of the ESP8266 Wi-Fi module (Web pages are deployed into the
    ESP8266 HTTP Server). Moreover, the system is capable to log the sensor data in
    cloud storage such as “Google Drive” in its “Google Sheet”. Users are enabled
    to monitor and observe the real-time environmental condition anywhere of the world
    through the integration of cloud-based data storage. 3.5. Software architecture
    (Development of the source code of the system) The source code of the system or
    software is written in C++ language using the “Sketch” IDE (Integrated Development
    Environment). Fig. 3 shows the flowchart of the source code to the corresponding
    embedded system. Download : Download high-res image (483KB) Download : Download
    full-size image Fig. 3. Flowchart of the program. Table 1 shows the source code
    architecture of the prescribed embedded system and software (for better realization).
    Table 1. Program architecture. Programming Steps 1. Including the required headers
    2. Defining the pins of each sensor and modules 3. Defining the purpose of each
    pin (Input/output) 4. Defining variables that will contain the received data of
    each sensor of sensor nodes 5. Define initial codes for the ESP8266 module 6.
    Defining functional codes for the ESP8266 module 7. Comparing each sensor data
    with the threshold 8. If sensor data satisfy the threshold loop 9. Send SMS to
    the user''s mobile phone via GSM module 10. Depending on the threshold start the
    certain automated task 11. Setup and design of webpage for the ESP8266 module
    12. Cloud storage configuration (if want to store and visualize data using cloud
    storage) 4. Evaluation of the system The following figures visualize the test
    run results of the developed embedded system of autonomous lighting and ventilation.
    Fig. 4 shows the main page which appears first when a user accesses the system.
    Download : Download high-res image (218KB) Download : Download full-size image
    Fig. 4. The main page of the HTTP server. Fig. 5 shows the real-time-sensed data
    by each sensor. This page can be accessed from the main page by tapping the link
    named “Sensors Data.” Download : Download high-res image (204KB) Download : Download
    full-size image Fig. 5. The page for monitoring the sensor data. Forthcoming figure
    (Fig. 6) visualizes the real-time logged data (“Google Sheet” of “Google Drive”)
    of all sensors over a cloud platform. Download : Download high-res image (612KB)
    Download : Download full-size image Fig. 6. Real-time data of each sensor through
    the cloud. Fig. 7 shows the SMS transmitted by the system when an anomaly that
    means smoke and fire detected. Download : Download high-res image (72KB) Download
    : Download full-size image Fig. 7. SMS to the user from the system. 5. Impact
    of the system The significant advantage of the developed system is that it has
    an embedded circuit design with ready-to-deploy software or code. The developers
    can easily deploy the source code of software to an Arduino or relevant types
    of MCU (microcontroller unit) based systems. Being an open-source development,
    developers can also modify the system for their desired work, e.g., they can add
    more appliances to the system to enable the appliances to perform the automated
    tasks simply by modifying and adding certain codes of the system or software.
    Most importantly this system and software have a user-friendly ecosystem through
    which users can monitor the indoor environmental conditions from the nearby premises
    of the system or anywhere of the world. Moreover, an adequate ventilation system
    is required to avoid respiratory stress to maintain a healthy condition. The system
    has integrated smoke and fire detection to prevent accidents caused by the fire
    which further leads the system to be more eco-friendly and user-friendly. 6. Scope
    for further research and development The device can be installed in multiple rooms
    of a house, a flat, a multi-storied building, or apartments or rooms of an office
    with decentralized, centralized, or mixed monitoring approaches. The system might
    be deployed to the rooms of industrial premises with certain modifications such
    as the integration of more gas sensors that can detect more gases. Cloud analytics
    and visualization techniques may be adopted for better visualization of sensor
    data with different approaches of plots. Machine Learning techniques may be utilized
    within the system to analyze sensor data to predict any accident that can be caused
    by the fire in the future. Research can be performed to develop and enhance the
    system to deploy it in a densely populated area where buildings are closer to
    one another to prevent a massive accident caused by gases and fire. As the core
    system consists of automated lighting, ventilation, fire detection, and prevention
    it might be highly assistive to secure livelihood. Dedicated UI (User Interface)
    for PC and/or Smartphone may be developed through which the user can monitor or
    observe the sensor data accessing the system (By connecting with the ESP8266 Module).
    7. Conclusion This work developed a user-friendly embedded system and software
    for autonomous lighting and ventilation systems for indoor premises such as rooms
    of houses and offices based on the IoT. The system developed in this work is tested
    in a single room considering a single light and ventilation system. The developed
    system can be deployed on a large scale which means in each room of a home or
    an apartment or even in every room of a large office. Future researches required
    to be performed regarding the large scale deployment of the system, enhancement
    of the sensing and actuating devices, etc. Declaration of Competing Interest The
    authors declare that they have no known competing financial interests or personal
    relationships that could have appeared to influence the work reported in this
    paper. References [1] V.S. Gunge, P.S. Yalagi Smart home automation: a literature
    review Int. J. Comput. Appl. (2016) Google Scholar [2] Huarong Jiang, Yong Li,
    Dong Li Indoor environment monitoring system based on LinkIt One and Yeelink platform
    2016 2nd IEEE International Conference on Computer and Communications (ICCC),
    Chengdu (2016), pp. 933-937, 10.1109/CompComm.2016.7924841 View in ScopusGoogle
    Scholar [3] M. Jacob Rodrigues, O. Postolache, F. Cercas Indoor air quality monitoring
    system to prevent the triggering of respiratory distress 2019 International Conference
    on Sensing and Instrumentation in IoT Era (ISSI), Lisbon, Portugal (2019), pp.
    1-6, 10.1109/ISSI47111.2019.9043669 Google Scholar [4] V.R. Shinde, P.P. Tasgaonkar,
    R.D. Garg Environment monitoring system through Internet of Things(IOT) 2018 International
    Conference on Information, Communication, Engineering and Technology (ICICET),
    Pune (2018), pp. 1-4, 10.1109/ICICET.2018.8533835 Google Scholar [5] A. Firmansah,
    Aripriharta, I.M. Wirawan, H.W. Herwanto, I. Fadlika, Muladi Design and experimental
    validation of the self-powered IoT for indoor temperature-humidity monitoring
    2019 International Conference on Electrical, Electronics and Information Engineering
    (ICEEIE), Denpasar, Bali, Indonesia (2019), pp. 139-143, 10.1109/ICEEIE47180.2019.8981426
    Google Scholar [6] J. Jose, T. Sasipraba Indoor air quality monitors using IOT
    sensors and LPWAN 2019 3rd International Conference on Trends in Electronics and
    Informatics (ICOEI), Tirunelveli, India (2019), pp. 633-637, 10.1109/ICOEI.2019.8862647
    View in ScopusGoogle Scholar [7] N. Adnan, N. Kamal, K. Chellappan An IoT based
    smart lighting system based on human activity 2019 IEEE 14th Malaysia International
    Conference on Communication (MICC), Selangor, Malaysia (2019), pp. 65-68, 10.1109/MICC48337.2019.9037601
    View in ScopusGoogle Scholar [8] K. MATSUI A proposal and implementation of networked
    lighting system considering indoor comfort and energy efficiency 2018 IEEE 7th
    Global Conference on Consumer Electronics (GCCE), Nara (2018), pp. 285-286, 10.1109/GCCE.2018.8574786
    Google Scholar [9] N.H. Motlagh, S.H. Khajavi, A. Jaribion, J. Holmstrom An IoT-based
    automation system for older homes: a use case for lighting system 2018 IEEE 11th
    Conference on Service-Oriented Computing and Applications (SOCA), Paris (2018),
    pp. 1-6, 10.1109/SOCA.2018.8645771 Google Scholar [10] J. Esquiagola, M. Manini,
    A. Aikawa, L. Yoshioka, M. Zuffo Monitoring indoor air quality by using IoT technology
    2018 IEEE XXV International Conference on Electronics, Electrical Engineering
    and Computing (INTERCON), Lima (2018), pp. 1-4, 10.1109/INTERCON.2018.8526380
    Google Scholar [11] M.F.M. Firdhous, B.H. Sudantha, P.M. Karunaratne IoT enabled
    proactive indoor air quality monitoring system for sustainable health management
    2017 2nd International Conference on Computing and Communications Technologies
    (ICCCT), Chennai (2017), pp. 216-221, 10.1109/ICCCT2.2017.7972281 View in ScopusGoogle
    Scholar [12] J. Molnár, T. Lorinc, O. Slavko Design and implementation of an intelligent
    air quality sensor 2019 IEEE International Conference on Modern Electrical and
    Energy Systems (MEES), Kremenchuk, Ukraine (2019), pp. 74-77, 10.1109/MEES.2019.8896527
    View in ScopusGoogle Scholar [13] Z. Adel, A.A. Hamou, S. Abdellatif Design of
    Real-time PID tracking controller using Arduino Mega 2560for a permanent magnet
    DC motor under real disturbances 2018 International Conference on Electrical Sciences
    and Technologies in Maghreb (CISTEM), Algiers (2018), pp. 1-5, 10.1109/CISTEM.2018.8613560
    Google Scholar [14] R.S. Rosli, M.H. Habaebi, M.R. Islam Characteristic analysis
    of received signal strength indicator from ESP8266 WiFi transceiver module 2018
    7th International Conference on Computer and Communication Engineering (ICCCE),
    Kuala Lumpur (2018), pp. 504-507, 10.1109/ICCCE.2018.8539338 View in ScopusGoogle
    Scholar [15] Z. Yuan, Z. Zhang, X. Han, Zhenglu, D. Wang Remote monitor of farmland
    irrigation three-phase motor based on the GSM module 2015 Fifth International
    Conference on Instrumentation and Measurement, Computer, Communication and Control
    (IMCCC), Qinhuangdao (2015), pp. 1779-1782, 10.1109/IMCCC.2015.378 View in ScopusGoogle
    Scholar [16] L.M. Gabriel, G. Fujita A module-based educational platform for transformer
    differential digital relay design and experimentation 2018 IEEE PES Asia-Pacific
    Power and Energy Engineering Conference (APPEEC), Kota Kinabalu (2018), pp. 724-729,
    10.1109/APPEEC.2018.8566334 View in ScopusGoogle Scholar [17] Y. Li, J. He Design
    of indoor environment monitoring system based on WiFi 2018 2nd IEEE Advanced Information
    Management, Communications, Electronic and Automation Control Conference (IMCEC),
    Xi''an (2018), pp. 1-1845, 10.1109/IMCEC.2018.8469580 Google Scholar [18] K. Lai,
    B. Ku, C. Wen Using cooperative PIR sensing for human indoor localization 2018
    27th Wireless and Optical Communication Conference (WOCC), Hualien (2018), pp.
    1-5, 10.1109/WOCC.2018.8372703 View in ScopusGoogle Scholar [19] R. Firdaus, M.A.
    Murti, I. Alinursafa Air quality monitoring system based Internet of Things (IoT)
    using LPWAN LoRa 2019 IEEE International Conference on Internet of Things and
    Intelligence System (IoTaIS), BALI, Indonesia (2019), pp. 195-200, 10.1109/IoTaIS47347.2019.8980437
    View in ScopusGoogle Scholar Cited by (22) Preparation and thermal responsiveness
    of microencapsulated fluorinated liquids for automatic fire extinguishing 2024,
    Heliyon Show abstract Applications of internet of things (IoT) and sensors technology
    to increase food security and agricultural Sustainability: Benefits and challenges
    2024, Ain Shams Engineering Journal Show abstract Early indoor occluded fire detection
    based on firelight reflection characteristics 2022, Fire Safety Journal Citation
    Excerpt : Early indoor fire detection can effectively prevent damage and minimize
    losses [1–3]. Show abstract An Intelligent IoT-Cloud-Based Air Pollution Forecasting
    Model Using Univariate Time-Series Analysis 2024, Arabian Journal for Science
    and Engineering Devising an Iot-Integrated Fire Detection System for Textile Industry
    ⋆ 2023, SSRN FCM-SWA: Hybrid Intelligent Approach Combining Fuzzy C-Means and
    Sperm Whales Algorithm for Cyber-Attack Detection in IoT Networks 2023, Research
    Square View all citing articles on Scopus Mobasshir Mahbub is currently engaged
    in MSc Engineering in Electrical and Electronic Engineering under the Department
    of Electrical and Electronic Engineering at Ahsanullah University of Science and
    Technology, Dhaka, Bangladesh. He graduated (September 2018) in Electronic and
    Telecommunication Engineering under the Department of Electronics and Communications
    Engineering at East West University, Dhaka, Bangladesh with an outstanding academic
    performance (Merit Scholarship and Dean''s List Award). His fields of interest
    are Circuit Design & Analysis, Embedded Electronics, IoT, IoT Security, IoT-Enabled
    Intelligent Gadgets, Robotics, Microcontroller Interfacing, Wireless Communications,
    Data Communication, UAV-Aided Communication, PCB Designing, etc. He served as
    a Project Engineer, in Transport Network Rollout Department under the Technology
    Division of Robi Axiata Ltd., a renowned telecom operator of Bangladesh. He has
    four (two accepted and two on-review) book chapter (Springer, IGI Global), fourteen
    research paper publications in reputed international journals (Elsevier, Springer,
    EAI), and four conference publications in reputed international conferences (IEEE
    Sponsored). He served as an organizer, instructor, and keynote speaker in several
    workshops, seminars, and webinars on Microcontroller Interfacing, Embedded System,
    IoT, and Robotics (EWU, ULAB, and AUST). He has been serving as a reviewer for
    journals of reputed publishers such as Springer, IEEE, Wiley, and Emerald and
    served as reviewer for several international conferences. He obtained certifications
    and training in IoT, Computer Networking, Routing & Switching, Software Defined
    Networking (SDN) and Network Function Virtualization (NFV), Network Security,
    PCB Designing, Industrial IoT on Google Cloud, Digital Marketing, and Google Analytics
    related courses from Cisco, Huawei, Intel, Microsoft, Google, UCI, GATech, Coursera,
    Alison, Cybrary, and Udemy. He is currently engaged in research on the above mentioned
    topics Dr. M. Mofazzal Hossain has been serving as professor and head of Department
    of Electrical and Electronic Engineering & Department of Electronics and Telecommunication
    Engineering, University of Liberal Arts Bangladesh. He received his B.Sc. Eng.
    degree in Electrical and Electronic Engineering from Bangladesh University of
    Engineering and Technology, Dhaka, and Masters and Ph.D. from Kanazawa University,
    Japan in 1993, 2000 and 2003 respectively. He started his career as a Lecturer
    in EEE Department at Chittagong University of Engineering and Technology since
    27 April 1994 and served there as an Assistant Professor till April 2008. From
    May 2008 to December 2018, he worked at East West University, Dhaka in the capacity
    like Chairperson of ECE Department and Dean, Faculty of Sciences and Engineering.
    Dr. Hossain worked at Tokyo Institute of Technology, Japan as a visiting postdoctoral
    research fellow from November 2005 to November 2007. Dr Hossain''s research interest
    includes renewable energy, antenna engineering and plasma technology. He has published
    more than 70 articles in peer reviewed International Journals and Conferences.
    He is a member of IEEE and IEB. He is the member of editorial board of Journal
    of Electrical and Electronic Systems. He served as international advisory committee
    member in different international conferences. Md. Shamrat Apu Gazi is currently
    an MSc student at the East West University, Bangladesh and received his BSc in
    Electronic & Telecommunication Engineering from the same institute in 2018. He
    served as an intern in Nara Institute Science and Technology, Japan with a funding
    of JASSO. His research interests are IoT, Machine Learning, Network Automation,
    and Mobile Edge Computing. View Abstract © 2020 Elsevier B.V. All rights reserved.
    Recommended articles Experimental investigations on gaseous hydrogen supplemented
    Aleurites Fordii biodiesel in a direct injection diesel engine for performance
    enhancement and reduction in emissions Materials Today: Proceedings, Volume 46,
    Part 20, 2021, pp. 11140-11148 Ranjit P.S., …, Sreeramulu Mahesh G. View PDF Experimental
    investigation on heat transfer on laminar flow over combination of blocks mounted
    on rectangular channel Materials Today: Proceedings, Volume 46, Part 17, 2021,
    pp. 7839-7843 V. Dinesh Kumar, …, K.D. Jaganathan View PDF Neural network-based
    photovoltaic generation capacity prediction system with benefit-oriented modification
    Energy, Volume 223, 2021, Article 119748 Fang Yuan Xu, …, Hao Tian Zhang View
    PDF Show 3 more articles Article Metrics Citations Citation Indexes: 15 Captures
    Readers: 54 Mentions News Mentions: 1 View details About ScienceDirect Remote
    access Shopping cart Advertise Contact and support Terms and conditions Privacy
    policy Cookies are used by this site. Cookie settings | Your Privacy Choices All
    content on this site: Copyright © 2024 Elsevier B.V., its licensors, and contributors.
    All rights are reserved, including those for text and data mining, AI training,
    and similar technologies. For all open access content, the Creative Commons licensing
    terms apply."'
  inline_citation: '>'
  journal: Computer Networks
  limitations: '>'
  relevance_score1: 0
  relevance_score2: 0
  title: Cloud-Enabled IoT-based embedded system and software for intelligent indoor
    lighting, ventilation, early stage fire detection and prevention
  verbatim_quote1: '>'
  verbatim_quote2: '>'
  verbatim_quote3: '>'
